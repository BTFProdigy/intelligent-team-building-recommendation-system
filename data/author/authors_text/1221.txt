Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing, pages 177?180,
Sydney, July 2006. c?2006 Association for Computational Linguistics
POC-NLW Template for Chinese Word Segmentation 
 
 
Bo Chen 
chb615@gmail.com 
Weiran Xu 
xuweiran@263.net 
Tao Peng 
ppttbupt@gmail.com 
Jun Guo 
guojun@bupt.edu.cn 
Pattern Recognition and Intelligent System Lab 
Beijing University of Posts and Telecommunications 
Beijing 100876, P. R. China 
 
  
 
Abstract 
In this paper, a language tagging tem-
plate named POC-NLW (position of a 
character within an n-length word) is pre-
sented. Based on this template, a two-
stage statistical model for Chinese word 
segmentation is constructed. In this 
method, the basic word segmentation is 
based on n-gram language model, and a 
Hidden Markov tagger based on the 
POC-NLW template is used to imple-
ment the out-of-vocabulary (OOV) word 
identification. The system participated in 
the MSRA_Close and UPUC_Close 
word segmentation tracks at SIGHAN 
Bakeoff 2006. Results returned by this 
bakeoff are reported here. 
1 Introduction 
In Chinese word segmentation, there are two 
problems still remain, one is the resolution of 
ambiguity, and the other is the identification of 
so-called out-of-vocabulary (OOV) or unknown 
words. In order to resolve these two problems, a 
two-stage statistical word segmentation strategy 
is adopted in our system. The first stage is op-
tional, and the whole segmentation can be ac-
complished in the second stage. In the first stage, 
the n-gram language model is employed to im-
plement basic word segmentation including dis-
ambiguation. In the second stage, a language 
tagging template named POC-NLW (position of 
a character within an n-length word) is intro-
duced to accomplish unknown word identifica-
tion as template-based character tagging. 
The remainder of this paper is organized as 
follows. In section 2 and section 3, a briefly de-
scription of the main methods adopted in our 
system is given. Results of our system at this 
bakeoff are reported in section 4. At last, conclu-
sions are derived in section 5. 
2 The Basic Word Segmentation Stage 
In the first stage, the basic word segmentation is 
accomplished. The key issue in this stage is the 
ambiguity problem, which is mainly caused by 
the fact that a Chinese character can occur in dif-
ferent word internal positions in different words 
(Xue, 2003). A lot of machine learning tech-
niques have been applied to resolve this problem, 
the n-gram language model is one of the most 
popular ones among them (Fu and Luke, 2003; 
Li et al, 2005). As such, we also employed n-
gram model in this stage.  
When a sentence is inputted, it is first seg-
mented into a sequence of individual characters 
(e.g. ASCII strings, basic Chinese characters, 
punitions, numerals and so on), marked as C1,n. 
According to the system?s dictionary, several 
word sequences W1,m will be constructed as can-
didates. The function of the n-gram model is to 
find out the best word sequence W* corresponds 
to C1,n, which has the maximum integrated prob-
ability, i.e., 
trigramforWWWP
bigramforWWP
CWPW
m
i
iii
W
m
i
ii
W
nm
W
m
m
m
?
?
=
??
=
?
?
?
=
1
21
1
1
,1,1
*
),|(maxarg
)|(maxarg
)|(maxarg
,1
,1
,1
 
177
The Maximum Likelihood method was used to 
estimate the word n-gram probabilities used in 
our model, and the linear interpolation method 
(Jelinek and Mercer, 1980) was applied to 
smooth these estimated probabilities. 
3 The OOV Word Identification Stage 
The n-gram method is based on the exiting grams 
in the model, so it is good at judging the connect-
ing relationship among known words, but does 
not have the ability to deal with unknown words 
in substance. Therefore, another OOV word 
identification model is required.  
OOV words are regarded as words that do not 
exist in a system?s machine-readable dictionary, 
and a more detailed definition can be found in 
(Wu and Jiang, 2000). In general, Chinese word 
can be created through compounding or abbrevi-
ating of most of existing characters and words. 
Thus, the key to solve the OOV word identifica-
tion lies on whether the new word creation 
mechanisms in Chinese language can be ex-
tracted. Therefore, a POC-NLW language tag-
ging template is introduced to explore such in-
formation on the character-level within words. 
3.1 The POC-NLW Template 
Many character-level based works have been 
done for the Chinese word segmentation, includ-
ing the LMR tagging methods (Xue, 2003; Na-
kagawa. 2004), the IWP mechanism (Wu and 
Jiang, 2000). Based on these previous works, this 
POC-NLW template was derived. Assume that 
the length of a word is the number of component 
characters in it, the template is consist of two 
component: Lmax and a Wl-Pn tag set. Lmax to de-
note the maximum length of a word expressed by 
the template; a Wl-Pn tag denotes that this tag is 
assigned to a character at the n-th position within 
a l-length word, . Apparently, the 
size of this tag set is  
ln ,,2,1 L=
2/)1( maxmax LL ?+
For example, the Chinese word ??? ? is 
tagged as: 
 ? W2P1, ? W2P2 
and ????? is tagged as: 
 ? W3P1, ? W3P2, ? W3P3 
In the example, two words are tagged by the 
template respectively, and the Chinese character 
??? has been assigned two different tags.  
In a sense, the Chinese word creation mecha-
nisms could be extracted through statistics of the 
tags for each character on a certain large corpus.  
On the other hand, while a character sequence 
in a sentence is tagged by this template, the word 
boundaries are obvious. Meanwhile, the word 
segmentation is implemented.  
In addition, in this template, known words and 
unknown words are both regarded as sequences 
of individual characters. Thus, the basic word 
segmentation process, the disambiguation proc-
ess and the OOV word identification process can 
be accomplished in a unified process. Thereby, 
this model can also be used alone to implement 
the word segmentation task. This characteristic 
will make the word segmentation system much 
more efficient. 
3.2 The HMM Tagger 
Form the description of POC-NLW template, it 
can be found that the word segmentation could 
be implemented as POC-NLW tagging, which is 
similar to the so-called part-of-speech (POS) 
tagging problem. In POS tagging, Hidden 
Markov Model (HMM) was applied as one of the 
most significant methods, as described in detail 
in (Brants, 2000). The HMM method can achieve 
high accuracy in tagging with low processing 
costs, so it was adopted in our model. 
According to the definition of POC-NLW 
template, the state set of HMM corresponds to 
the Wl-Pn tag set, and the symbol set is com-
posed of all characters. However, the initial state 
probability matrix and the state transition prob-
ability matrix are not composed of all of the tags 
in the state set. To express more clearly, we de-
fine two subset of the state set: 
? Begin Tag Set (BTS): this set is con-
sisted of tag which can occur in the beg-
ging position in a word. Apparently, these 
tags must have the Wl-P1 form.  
? End Tag Set (ETS): correspond to BTS, 
tags in this set should occur in the end po-
sition, and their form should be like Wl-Pl. 
Apparently, the size of BTS is Lmax as well as 
of ETS. Thus, the initial state probability matrix 
corresponds to BTS instead of the whole state set. 
On the other hand, because of the word internal 
continuity, if the current tag Wl-Pn is not in ETS, 
than the next tag must be Wl-P(n+1). In other 
words, the case in which the transition probabil-
ity is need is that when the current tag is in ETS 
and the next tag belongs to BTS. So, the state 
transition matrix in our model corresponds to 
BTSETS ? . 
178
The probabilities used in HMM were defined 
similarly to those in POS tagging, and were es-
timated using the Maximum Likelihood method 
from the training corpus. 
In the two-stage strategy, the output word se-
quence of the first stage is transferred into the 
second stage. The items in the sequence, includ-
ing individual characters and words, which do 
not have a bigram or trigram relationship with 
the surrounding items, are picked out with its 
surrounding items to compose several sequences 
of items. These item sequences are processed by 
the HMM tagger to form new item sequences. At 
last, these processed items sequences are com-
bined into the whole word sequence as the final 
output. 
4 Results and Analysis 
4.1 System 
The system submitted at this bakeoff was a two-
stage one, as describe at beginning of this paper. 
The model used in the first stage was trigram, 
and the Lmax of the template used in the second 
stage was set to 7. 
In addition to the tags defined in the template 
before, a special tag is introduced into our Wl-Pn 
tag set to indicate all those characters that occur 
after the Lmax-th position in an extremely long 
(longer than Lmax) word., formulized as WLmax-
P(Lmax+1). And then, there are 28 basic tags 
(from W1-P1 to W7-P7) and the special one W7-
P8.  
For instance, using the special tag, the word 
???????????? (form the MSRA 
Corpus ) is tagged as: 
? W7-P1  ? W7-P2  ? W7-P3  ? W7-P4 
? W7-P5  ? W7-P6  ? W7-P7  ? W7-P8 
? W7-P8  ? W7-P8 
4.2 Results at SIGHAN Bakeoff 2006 
Our system participated in the MSRA_Close and 
UPUC_Close track at the SIGHAN Bakeoff 
2006. The test results are as showed in Table 1. 
 
Corpus MSRA UPUC 
F-measure 0.951 0.918 
Recall 0.956 0.932 
Precision 0.947 0.904 
IV Recall 0.972 0.969 
OOV Recall 0.493 0.546 
OOV Precision 0.569 0.757 
Table 1. Results at SIGHAN Bakeoff 2006 
 
The performances of our system on the two 
corpuses can rank in the half-top group among 
the participated systems.  
We notice that the accuracies on known word 
segmentation are relatively better than on OOV 
words segmentation. This appears somewhat un-
expected. In the close experiments we had done 
on the PKU and MSR corpuses of SIGHAN 
Bakeoff 2005, the relative performance of OOV 
Recall was much more outstanding than of the F-
measure. 
We think this is due to the inappropriate pa-
rameters used in n-gram model, which over-
guarantees the performance of basic word seg-
mentation. It can be seen on the IV Recall (high-
est in UPUC_Close track). For only the best out-
put sequence of the n-gram model is transferred 
to the HMM tagger, some potential unknown 
words may be miss-split in the early stage. Thus, 
the OOV Recall is not very good, and this also 
affects the overall performance. 
On the other hand, the performances of OOV 
identification on UPUC are much better than on 
MSRA, while the performances of overall seg-
mentation accuracy on UPUC are worse than on 
MSRA. This phenomenon also happened in our 
experiments on the Bakeoff 2005 corpuses of 
PKU and MSR. In the PKU test data, the rate of 
OOV words according is 0.058 while in MSR is 
0.026. Thus, it can be conclude that the more 
unknown words occur, the more significant abil-
ity of OOV words identification appears.  
In addition, the relative performance of OOV 
Precision are much better. This demonstrates that 
the OOV identification ability of our system is 
appreciable. In other words, the POC-NLW tag-
ging method introduced is effective to some ex-
tent. 
5 CONCLUSION AND FURTHER 
WORK 
In this paper, a POC-NLW template is presented 
for word segmentation, which aims at exploring 
the word creation mechanisms in Chinese lan-
guage by utilizing the character-level informa-
tion to. A two-stage strategy was applied in our 
system to combine the n-gram model based word 
segmentation and OOV word identification im-
plemented by a HMM tagger. Test results show 
that the method achieved high performance on 
word segmentation, especially on unknown 
words identification. Therefore, the method is a 
practical one that can be implemented as an inte-
179
gral component in actual Chinese NLP applica-
tions.  
From the results, it can safely conclude that 
method introduced here does find some charac-
ter-level information, and the information could 
effectively conduct the word segmentation and 
unknown words identification. For this is the first 
time we participate in this bakeoff, and the work 
has been done as a integral part of another sys-
tem during the past two months, the implementa-
tion of the segmentation system we submitted is 
coarse. A lot of improvements, on either theo-
retical methods or implementation techniques, 
are required in our future work, including the 
smoothing techniques in the n-gram model and 
the HMM model, the refine of the features ex-
traction method and the POC-NLW template it-
self, the more harmonious integration strategy 
and so on.  
Acknowledgements 
This work is partially supported by NSFC 
(National Natural Science Foundation of China) 
under Grant No.60475007, Key Project of Chi-
nese Ministry of Education under Grant 
No.02029 and the Foundation of Chinese Minis-
try of Education for Century Spanning Talent. 
References 
Andi Wu, and Zixin Jiang. 2000. Statistically-
enhanced new word identification in a rule-based 
Chinese system. Proceedings of the 2nd Chinese 
Language Processing Workshop, 46-51. 
Frederick Jelinek, and Robert L. Mercer. 1980. Inter-
polated Estimation of Markov Source Parameters 
from Sparse Data. Proceedings of Workshop on 
Pattern Recognition in Practice, Amsterdam, 381-
397. 
Guohong Fu, and Kang-Kwong Luke. 2003. A Two-
stage Statistical Word Segmentation System for 
Chinese. Proceedings of the Second SIGHAN 
Workshop on Chinese Language Processing, 156-
159. 
Heng Li, Yuan Dong, Xinnian Mao, Haila Wang, and 
Wu Liu. 2005. Chinese Word Segmentation in 
FTRD Beijing. Proceedings of the Fourth SIGHAN 
Workshop on Chinese Language Processing, 150-
153. 
Nianwen Xue. 2003. Chinese Word Segmentation as 
Character Tagging. International Journal of Com-
putational Linguistics and Chinese Language Pro-
cession, 8(1):29?48. 
Tetsuji Nakagawa. 2004. Chinese and Japanese Word 
Segmentation Using Word-Level and Character-
Level Information. Proceedings of the 20th Inter-
national Conference on Computational Linguistics, 
466?472. 
Thorsten Brants. 2000. TnT ? A Statistical Part-of-
Speech Tagger. Proceedings of the Sixth Confer-
ence on Applied Natural Language Processing 
ANLP-2000, 224?231. 
180
Chinese NER Using CRFs and Logic for the Fourth SIGHAN Bakeoff ?
Xiaofeng YU Wai LAM Shing-Kit CHAN Yiu Kei WU Bo CHEN
Information Systems Laboratory
Department of Systems Engineering & Engineering Management
The Chinese University of Hong Kong
Shatin, N.T., Hong Kong
{xfyu,wlam,skchan,ykwu,bchen}@se.cuhk.edu.hk
Abstract
We report a high-performance Chinese NER
system that incorporates Conditional Random
Fields (CRFs) and first-order logic for the fourth
SIGHAN Chinese language processing bake-
off (SIGHAN-6). Using current state-of-the-
art CRFs along with a set of well-engineered
features for Chinese NER as the base model,
we consider distinct linguistic characteristics in
Chinese named entities by introducing various
types of domain knowledge into Markov Logic
Networks (MLNs), an effective combination of
first-order logic and probabilistic graphical mod-
els for validation and error correction of enti-
ties. Our submitted results achieved consistently
high performance, including the first place on the
CityU open track and fourth place on the MSRA
open track respectively, which show both the at-
tractiveness and effectiveness of our proposed
model.
1 Introduction
We participated in the Chinese named entity recognition
(NER) task for the fourth SIGHAN Chinese language
processing bakeoff (SIGHAN-6). We submitted results
for the open track of the NER task. Our official re-
sults achieved consistently high performance, including
the first place on the CityU open track and fourth place on
the MSRA open track. This paper presents an overview
of our system due to space limit. A more detailed de-
scription of our model is presented in (Yu et al, 2008).
Our Chinese NER system combines the strength of two
graphical discriminative models, Conditional Random
?The work described in this paper is substantially supported
by grants from the Research Grant Council of the Hong Kong
Special Administrative Region, China (Project Nos: CUHK
4179/03E, CUHK4193/04E, and CUHK4128/07) and the Di-
rect Grant of the Faculty of Engineering, CUHK (Project Codes:
2050363 and 2050391). This work is also affiliated with the
Microsoft-CUHK Joint Laboratory for Human-centric Comput-
ing and Interface Technologies.
Fields (CRFs) and Markov Logic Networks (MLNs).
First, we employ CRFs, a discriminatively trained undi-
rected graphical model which has been shown to be an
effective approach to segmenting and labeling sequence
data, as our base system. Second, we model the linguis-
tic and structural information in Chinese named entity
composition. We exploit a variety of domain knowledge
which can capture essential characteristics of Chinese
named entities into Markov Logic Networks (MLNs), a
powerful combination of first-order logic and probability,
to (1) validate and correct errors made in the base sys-
tem and (2) find and extract new entity candidates. These
domain knowledge is easy to obtain and can be well and
concisely formulated in first-order logic and incorporated
into MLNs.
2 Conditional Random Fields as Base
Model
Conditional Random Fields (CRFs) (Lafferty et al, 2001)
are undirected graphical models trained to maximize the
conditional probability of the desired outputs given the
corresponding inputs. CRFs have been shown to perform
well on Chinese NER shared task on SIGHAN-4 (Zhou et
al. (2006), Chen et al (2006a), Chen et al (2006b)). We
employ CRFs as the base model in our framework. In this
base model, we design features similar to the state-of-the-
art CRF models for Chinese NER. We use character fea-
tures, word segmentation features, part-of-speech (POS)
features, and dictionary features, as described below.
Character features: These features are the current char-
acter, 2 characters preceding the current character and 2
following the current character. We extend the window
size to 7 but find that it slightly hurts. The reason is that
CRFs can deal with non-independent features. A larger
window size may introduce noisy and irrelevant features.
Word segmentation and POS features: We train our
own model for conducting Chinese word segmentation
and POS tagging. We employ a unified framework to
integrate cascaded Chinese word segmentation and POS
tagging tasks by joint decoding that guards against vi-
102
Sixth SIGHAN Workshop on Chinese Language Processing
olations of those hard-constraints imposed by segmenta-
tion task based on dual-layer CRFs introduced by Shi and
Wang (2007).
We separately train the Chinese word segmentation
and POS tagging CRF models using 8-month and 2-
month PKU 2000 corpus, respectively. The original PKU
2000 corpus contains more than 100 different POS tags.
To reduce the training time for POS tagging experiment,
we merge some similar tags and obtain only 42 tags fi-
nally. For example, {ia, ib, id, in, iv}?i. We use
the same features as described in (Shi and Wang, 2007),
except that we do not use the HowNet features for word
segmentation. Instead, we use max-matching segmenta-
tion features based on a word dictionary. This dictionary
contains 445456 words which are extracted from People?s
Daily corpus (January-June, 1998), CityU, MSRA, and
PKU word segmentation training corpora in SIGHAN-6.
For decoding, we first perform individual decoding for
each task. We then set 10-best segmentation and POS
tagging results for reranking and joint decoding in order
to find the most probable joint decodings for both tasks.
Dictionary features: We obtain a named entity dictio-
nary extracted from People?s Daily 1998 corpus and PKU
2000 corpus, which contains 68305 PERs, 28408 LOCs
and 55596 ORGs. We use the max-matching algorithm
to search whether a string exists in this dictionary.
In summary, we list the features used for our CRF base
model in Table 1. Besides the unigram feature template,
CRFs also allow bigram feature template. With this tem-
plate, a combination of the current output token and pre-
vious output token (bigram) is automatically generated.
We use CRF++ toolkit (version 0.48) (Kudo, 2005) in
our experiments. We find that setting the cut-off threshold
f for the features not only decreases the training time, but
improves the NER performance. CRFs can use the fea-
tures that occurs no less than f times in the given training
data. We set f = 5 in our system.
We extend the BIO representation for the chunk tag
which was employed in the CoNLL-2002 and CoNLL-
2003 evaluations. We use the BIOES representation in
which each character is tagged as either the beginning of
a named entity (B tag), a character inside a named en-
tity (I tag), the last character in an entity (E tag), single-
character entities (S tag), or a character outside a named
entity (O tag). We find that BIOES representation is
more informative and yields better results than BIO rep-
resentation.
3 Markov Logic Networks as Error
Correction Model
Even though the CRF model is able to accommodate a
large number of well-engineered features which can be
easily obtained across languages, some NEs, especially
Table 1: Feature template for CRF model.
Character features (1.1) Cn, n ? [?2, 2]
(1.2) CnCn+1, n ? [?2, 1]
Word features (1.3) Wn, n ? [?3, 3]
(1.4) WnWn+1, n ? [?3, 2]
POS features (1.5) Pn, n ? [?3, 3]
(1.6) PnPn+1, n ? [?3, 2]
Dictionary features (1.7) Dn, n ? [?2, 2]
(1.8) DnDn+1, n ? [?2, 1]
(1.9) D?1D+1
LOCs and ORGs are difficult to identify due to the lack
of linguistic or structural characteristics.
We incorporate domain knowledge that can be well
formulated into first-order logic to extract entity candi-
dates from CRF results. Then, the Markov Logic Net-
works (MLNs), an undirected graphical model for statis-
tical relational learning, is used to validate and correct
the errors made in the base model.
MLNs conduct relational learning by incorporating
first-order logic into probabilistic graphical models under
a single coherent framework (Richardson and Domingos,
2006). Traditional first-order logic is a set of hard con-
straints in which a world violates even one formula has
zero probability. The advantage of MLNs is to soften
these constraints so that when the fewer formulae a world
violates, the more probable it is. MLNs have been applied
to tackle the problems of gene interaction discovery from
biomedical texts and citation entity resolution from cita-
tion texts with state-of-the-art performance (Riedel and
Klein (2005), Singla and Domingos (2006)).
We use the Alchemy system (Beta version) (Kok et al,
2005) in our experiment, which is a software package
providing a series of algorithms for statistical relational
learning and probabilistic logic inference, based on the
Markov logic representation.
3.1 Domain Knowledge
We extract 165 location salient words and 843 organiza-
tion salient words from Wikipedia and the LDC Chinese-
English bi-directional NE lists compiled from Xinhua
News database. We also make a punctuation list which
contains 18 items and some stopwords which Chinese
NEs cannot contain. We extract new NE candidates from
the CRF results according to the following consideration:
? If a chunk (a series of continuous characters) occurs in the
training data as a PER or a LOC or an ORG, then this
chunk should be a PER or a LOC or an ORG in the testing
data. In general, a unique string is defined as a PER, it
cannot be a LOC somewhere else.
? If a tagged entity ends with a location salient word, it is a
LOC. If a tagged entity ends with an organization salient
word, it is an ORG.
103
Sixth SIGHAN Workshop on Chinese Language Processing
Table 2: Statistics of NER training and testing corpora.
Corpus Training NEs PERs/LOCs/ORGs Testing NEs PERs/LOCs/ORGs
CityU 66255 16552/36213/13490 13014 4940/4847/3227
MSRA 37811 9028/18522/10261 7707 1864/3658/2185
NEs: Number of named entities; PERs: Number of person names;
LOCs: Number of location names; ORGs: Number of organization names.
Table 3: OOV Rate of NER testing corpora.
Corpus Overall (IVs/OOVs/OOV-Rate) PER (IVs/OOVs/OOV-Rate) LOC (IVs/OOVs/OOV-Rate) ORG (IVs/OOVs/OOV-Rate)
CityU 6660/6354/0.4882 1062/3878/0.7850 3947/900/0.1857 1651/1576/0.4884
MSRA 6056/1651/0.2142 1300/564/0.3026 3343/315/0.0861 1413/772/0.3533
IVs: number of IV (named entities in vocabulary); OOVs: number of OOV
(named entities out of vocabulary); OOV-Rate: ratio of named entities out of vocabulary.
? If a tagged entity is close to a subsequent location salient
word, probably they should be combined together as a
LOC. The closer they are, the more likely that they should
be combined.
? If a series of consecutive tagged entities are close to a sub-
sequent organization salient word, they should probably
be combined together as an ORG because an ORG may
contain multiple PERs, LOCs and ORGs.
? Similarly, if there exists a series of consecutive tagged en-
tities and the last one is tagged as an ORG, it is likely that
all of them should be combined as an ORG.
? Entity length restriction: all kinds of tagged entities can-
not exceed 25 Chinese characters.
? Stopword restriction: intuitively, all tagged entities cannot
comprise any stopword.
? Punctuation restriction: in general, all tagged entities can-
not span any punctuation.
? Since all NEs are proper nouns, the tagged entities should
end with noun words.
? For a chunk with low conditional probabilities, all the
above assumptions are adopted.
3.2 First-Order Logic Construction
All the above domain knowledge can also be formulated
as first-order logic to construct the structure of MLNs.
First-order formulae are recursively constructed from
atomic formulae using logical connectives and quanti-
fiers. Atomic formulae are constructed using constants,
variables, functions, and predicates.
For example, we use the predicate organization(
candidate) to specify whether a candidate is an ORG.
If ??I?/China Government? is mis-tagged as a
LOC by the CRF model, but it contains the organization
salient word ??/Government?. The corresponding
formula endwith(r, p)?orgsalientword(p)
?organization(r) means if a tagged entity r ends
with an organization salient word p, then it is extracted as
a new ORG entity. Typically only a small number (e.g.,
10-20) of formulae are needed. We declare 14 predi-
cates and 15 first-order formulae according to the domain
knowledge mentioned in Section 3.1.
3.3 Training and Inference for Named Entity
Correction
Each extracted new NE candidate is represented by one
or more strings appearing as arguments of ground atoms
in the database. The goal of NE prediction is to deter-
mine whether the candidates are entities and the types of
entities (query predicates), given the evidence predicates
and other relations that can be deterministically derived
from the database.
We extract all the NEs from the official training cor-
pora, and then convert them to the first-order logic repre-
sentation according to the domain knowledge. The MLN
training database that consists of predicates, constants,
and ground atoms was built automatically. We also ex-
tract new entity candidates from CRF results and con-
struct MLN testing database in the same way.
During MLN learning, each formula is converted to
Conjunctive Normal Form (CNF), and a weight is learned
for each of its clauses. These weights reflect how often
the clauses are actually observed in the training data. In-
ference is performed by grounding the minimal subset
of the network required for answering the query pred-
icates. Conducting maximum a posteriori (MAP) in-
ference which finds the most likely values of a set of
variables given the values of observed variables can be
performed via approximate solution using Markov chain
Monte Carlo (MCMC) algorithms. Gibbs sampling can
be adopted by sampling each non-evidence variable in
turn given its Markov blanket, and counting the fraction
of samples that each variable is in each state.
4 Experiment Details
4.1 Data and Preprocessing
The training corpora provided by the SIGHAN bakeoff
organizers were in the CoNLL two column format, with
one Chinese character per line and hand-annotated named
entity chunks in the second column. The CityU corpus
was traditional Chinese. We converted this corpus to sim-
plified Chinese and we used UTF-8 encoding in all the
experiments so that all the resources (e.g., word dictio-
nary and named entity dictionary) are compatible in our
104
Sixth SIGHAN Workshop on Chinese Language Processing
Table 4: Official results on CityU andMSRA open tracks.
Precision Recall F?=1
CityU
PER 97.21% 95.26% 96.23
LOC 92.35% 93.42% 92.88
ORG 88.05% 66.44% 75.73
Overall 93.42% 87.43% 90.33
MSRA
PER 98.33% 94.58% 96.42
LOC 93.97% 93.36% 93.66
ORG 92.80% 84.39% 88.40
Overall 94.71% 91.11% 92.88
system.
Table 2 shows the statistics of NER training and testing
corpora and Table 3 shows the OOV (Out of Vocabulary)
rate of NER testing corpora 1. The number of NEs in
CityU corpus is almost twice as many as that in MSRA
corpus. The OOV rate in CityU corpus is much higher
than in MSRA corpus for PERs, LOCs and ORGs. These
numbers indicate that NER on CityU corpus is much
more difficult to handle.
4.2 Model Development
We performed holdout methodology to develop our
model. We randomly selected 5000 sentences fromCityU
training corpus for development testing and the rest for
training. We did the same thing for MSRA training cor-
pus.
To avoid overfitting for CRF model, we penalized
the log-likelihood by the commonly used zero-mean
Gaussian prior over the parameters. Also, the MLNs
were trained using a Gaussian prior with zero mean and
unit variance on each weight to penalize the pseudo-
likelihood, and with the weights initialized at the mode
of the prior (zero).
We found an optimal value for the parameter c 2 for
CRFs. Using held-out data, we tested all c values, c ?
[0.2, 2.2], with an incremental step of 0.4. Finally, we set
c = 1.8 for CityU corpus and c = 1.0 for MSRA corpus.
5 Official Results
Table 4 presents the results obtained on the official CityU
and MSRA test sets. Our results are consistently good:
we obtained the first place on the CityU open track (90.33
overall F-measure) and fourth place on the MSRA open
track (92.88 overall F-measure) respectively. The lower
1The NER on the PKU corpus was cancelled by the orga-
nizer due to the tagging inconsistency of this corpus.
2This parameter trades the balance between overfitting and
underfitting. With larger c value, CRF tends to overfit to the give
training corpus. The results will significantly be influenced by
this parameter
F-measure obtained on CityU corpus can be attributed to
the higher OOV rate of this corpus.
6 Conclusion
We have described a Chinese NER system incorporating
probabilistic graphical models and first-order logic which
achieves state-of-the-art performance on the open track of
SIGHAN-6. We exploited domain knowledge which can
capture the essential features of Chinese NER and can
be concisely formulated in MLNs, allowing the training
and inference algorithms to be directly applied to them.
Our proposed framework can also be extendable to NER
for other languages, due to the simplicity of the domain
knowledge we could access.
References
Aitao Chen, Fuchun Peng, Roy Shan, and Gordon Sun. Chi-
nese named entity recognition with conditional probabilistic
models. In 5th SIGHAN Workshop on Chinese Language
Processing, Australia, July 2006.
Wenliang Chen, Yujie Zhang, and Hitoshi Isahara. Chinese
named entity recognition with conditional random fields. In
5th SIGHAN Workshop on Chinese Language Processing,
Australia, July 2006.
Stanley Kok, Parag Singla, Matthew Richardson, and Pedro
Domingos. The Alchemy system for statistical relational
AI. Technical report, Department of Computer Science and
Engineering, University of Washington, Seattle, WA, 2005.
http://www.cs.washington.edu/ai/alchemy.
Taku Kudo. CRF++: Yet another CRF tool kit.
http://crfpp.sourceforge.net/, 2005.
John Lafferty, Andrew McCallum, and Fernando Pereira. Con-
ditional random fields: Probabilistic models for segment-
ing and labeling sequence data. In Proceedings of ICML-
01, pages 282?289. Morgan Kaufmann, San Francisco, CA,
2001.
Matthew Richardson and Pedro Domingos. Markov logic net-
works. Machine Learning, 62(1-2):107?136, 2006.
Sebastian Riedel and Ewan Klein. Genic interaction extraction
with semantic and syntactic chains. In Proceedings of the
Learning Language in Logic Workshop (LLL-05), pages 69?
74, 2005.
Yanxin Shi and Mengqiu Wang. A dual-layer CRFs based
joint decoding method for cascaded segmentation and label-
ing tasks. In Proceedings of IJCAI-07, pages 1707?1712,
Hyderabad, India, 2007.
Parag Singla and Pedro Domingos. Entity resolution with
Markov logic. In Proceedings of ICDM-06, pages 572?582,
Hong Kong, 2006.
Xiaofeng Yu, Wai Lam, and Shing-Kit Chan. A framework
based on graphical models with logic for Chinese named en-
tity recognition. In Proceedings of IJCNLP-08, Hyderabad,
India, 2008. To appear.
Junsheng Zhou, Liang He, Xinyu Dai, and Jiajun Chen. Chinese
named entity recognition with a multi-phase model. In 5th
SIGHAN Workshop on Chinese Language Processing, Aus-
tralia, July 2006.
105
Sixth SIGHAN Workshop on Chinese Language Processing
