Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic
Evaluation (SemEval 2013), pages 617?621, Atlanta, Georgia, June 14-15, 2013. c?2013 Association for Computational Linguistics
UC3M: A kernel-based approach to identify and classify DDIs in 
biomedical texts. 
 
Daniel Sanchez-Cisneros 
Universidad Carlos III de Madrid 
Avda. de la Universidad, 30 
28911 Legan?s - Madrid - Spain 
dscisner@inf.uc3m.es 
 
 
Abstract 
The domain of DDI identification is 
constantly showing a rise of interest from 
scientific community since it represents a 
decrease of time and healthcare cost. In this 
paper we purpose a new approach based on 
shallow linguistic kernel methods to identify 
DDIs in biomedical manuscripts. The 
approach outlines a first step in the usage of 
semantic information for DDI identification. 
The system obtained an F1 measure of 0.534. 
1 Introduction 
In recent years a new discipline appeared in the 
biomedical domain for processing pharmacological 
manuscripts related to drug substances. This 
discipline is the so called Pharmacovigilance, and 
takes care of the management and control of Drug-
Drug interactions (DDI) among other faculties. A 
DDI occurs when one drug influences the effect 
level or activity of another drug. 
Some events such as BioCreative1 and BioNLP2 
establish a benchmark of comparison in the field of 
natural language processing applied to biomedical 
domain. This is the case of Semeval 2013: 
Extraction of Drug-Drug Interactions from 
BioMedical Texts3, where our system has been 
evaluated.  
The field of DDI extraction from biomedical 
text has been faced from different perspectives 
such as rule-based approaches, SVM approaches 
and kernel-methods approaches, among others.  
                                                          
1 http://www.biocreative.org/ 
2 http://2013.bionlp-st.org/ 
3 http://www.cs.york.ac.uk/semeval-2013/task9/ 
Segura-Bedmar et al (2010) proposed an 
approach to extract DDI from biomedical texts 
based on Shallow Linguistic (SL) Kernel (Giuliano 
et al, 2006) methods obtaining an F1 measure of 
60,01%. The system was evaluated over a 
DrugDDI dataset created in 2010 that contains 579 
biomedical documents collected from the 
pharmacological database DrugBank4. The dataset 
contains a total of 3,160 DDIs. 
Recently, the DDIExtraction2011 task5 
compared the latest advances in Information 
Extraction techniques applied to the DDI 
identification. The event provided a benchmark 
forum of 10 different approaches.  The evaluation 
of the systems was made over the DrugDDI 
dataset. We now describe the most relevant works.  
Thomas et al (2011) developed a system by 
combining a preprocessing phase based on 
Charniak-Lease (Lease, Charniak, 2005) and 
Stanford (Marneffe et al, 2006) parsers, with a 
classification phase based on SL kernel (Giuliano 
et al, 2006), k-Band Shortest Path Spectrum 
(kBSPS) kernel (Airola et al, 2008), All Path 
Graphic (APG) kernel (Tikk et al, 2010) and case-
based reasoning (CBR) (Aamodt, Plaza, 1994) 
techniques. The system obtained a F1 measure of 
65.7%.  
Chowdhury et al (2011) presented a system 
combining a preprocessing phase based on 
Stanford parser and SPECIALIST (Browne, 2000) 
lexicon tool, with a classification phase based on 
Featured-Based kernel such as SL kernel and Tree-
Based kernel such as Dependency tree (DT) kernel 
(Culotta and Sorensen, 2004) and Phrase Structure 
Tree (PST) kernel (Moschitti, 2004). The system 
achieved an F1 of 63.7%. 
                                                          
4 http://www.drugbank.ca/ 
5 http://labda.inf.uc3m.es/DDIExtraction2011/ 
617
Bj?rne et al (2011) proposed a different 
approach by combining a preprocessing phase 
based on a collection of features and n-grams; with 
a classification based on support vector machine 
(SVM) (Vapnik, 1995). The SVM methods 
perform classification tasks by building 
hyperplanes in a multidimensional space that 
divide cases of different classes (binary 
classification). The system yielded an F1 measure 
of 62.99%. 
Kernel methods seem to be the best choice for 
extracting DDI since they obtained the highest 
results. Thus, we decided to use kernel methods to 
identify and classify DDI in our system. 
Furthermore, we hypothesize that using semantic 
features of pharmacological substances, can 
provide valuable knowledge in the classification 
phase. Therefore, we decide to integrate semantic 
information in the classification process of kernel 
methods. 
In this paper we present a kernel-based approach 
to identify and classify DDIs in biomedical text by 
using SL kernels. In section 2 we describe the 
system used for identifying DDIs. Section 3 
present the results obtained by the system and a 
little comparison with other approaches. In section 
4 we expose some conclusions obtained and ideas 
for future work.   
 
2 Description of the systems  
The system (see figure 1) is divided in three 
phases: (i) in the first phase the system makes a 
preprocessing of the documents in order to extract 
grammatical and semantic information about each 
word of the text. (ii) The second phase makes the 
classification of whether a pair of drugs is a DDI or 
not by using SL kernel methods. (iii) In the third 
phase, the system classifies all DDIs into the 
purpose type (advice, effect, mechanism, int) using 
SL kernel methods. 
The corpus is processed sentence by sentence, 
using the identification tag provided for each 
sentence. 
2.1 Preprocessing 
In this phase we make a preprocessing of the 
documents to obtain linguistic and semantic 
information about the words and entities contained 
in the text. Since linguistic and semantic 
Figure 1: Architecture of the system. 
 
618
approaches are based on different types of 
information, our participation in the task will be 
separated in two runs: first run will be based on 
linguistic information and second run will be based 
on semantic information. 
Firstly, we process each sentence and obtain 
linguistic information about part-of-speech  (PoS) 
tagging and lemmatization for each word contained 
in the text. To do so we use the Stanford parser6 by 
using the GATE analyzer7. The result of this step is 
a list of words and PoS tags, but entity concepts 
are missing. Therefore, we make a multiword 
entities processing to keep the words related to the 
same concept together. For example, the entity 
beta-adrenergic receptor blocker is processed by 
Stanford parser as three different annotations 
nodes: beta-adrenergic as type JJ; receptor as type 
NN; and blocker as type NNS. Thus we unify the 
three words into an only one concept beta-
adrenergic_receptor_blocker as type NNP. This 
information corresponds to the linguistic approach 
of our participation in the task (see figure 2b). 
On the other hand, we process the text and 
collect semantic information about Anatomical 
Therapeutic Chemical (ATC) identification for 
each drug found in the text. The ATC code is a 
widely used classification system provided from 
WHO collaborating centre for Drug statistics 
methodology. The classification divides drugs in 
groups at five different levels according to the 
organ or system on which they act, and their 
                                                          
6 http://nlp.stanford.edu/software/lex-parser.shtml. 
7 http://gate.ac.uk. 
therapeutic, pharmacological and chemical 
properties. The system obtains the ATC code of 
the drugs by searching the drug entities in the ATC 
Index resource8. Then, we associate the ATC code 
results with the drug entity. This information 
corresponds to the semantic approach of our 
participation in the task. 
2.2 Identification of DDI 
In this phase the system will predict whether a 
pair of drugs is a DDI or not by the use of Shallow 
linguistic Kernel methods. To do so we use the 
jSRE tool9.  
In one hand, the linguistic approach is based on 
shallow linguistic information such as PoS tagging 
and lemmatization. Therefore, the information 
introduced into the SL kernel model consists of: 
token_identifier, ATC_code, token_lemmatization, 
POS_tag, entity_type and entity_label; as show in 
figure 2b.   
On the other hand, the semantic approach uses 
the semantic information of drugs (ATC codes) to 
increase the available knowledge in the kernel 
classification process. To do so, we trained a SL 
kernel model by replacing the token value with the 
ATC code value. In case of a non-drug token, we 
replace the token value with 0. This way the 
information introduced to the SL kernel model 
consists of: token_identifier, ATC_code, 
token_lemmatization, POS_tag, entity_type and 
entity_label; as show in figure 2c. 
                                                          
8 http://www.whocc.no/atc_ddd_index/ 
9 http://hlt.fbk.eu/en/technology/jSRE 
Figure 2a: Example of separated multiword entity. 
 
Figure 2b: Example of linguistic input token into the SL kernel. 
 
Figure 2c: Example of semantic input token into the SL kernel. 
 
619
 2.3 Type classification of DDI 
In the third phase, the system makes a 
classification of DDIs to determine the type of the 
interaction. To do so, the system face the 
classification task as a machine learning task, and 
use SL kernel methods. Hence, we train one SL 
kernel model for each possible values of DDI type: 
advice, effect, mechanism, int. To train the kernel 
models we separate by type each DDI of the 
training dataset.  The result is four groups of 
training dataset, where the correspondent type 
class value are set to 1, and 0 otherwise. Once we 
trained the kernel models, each DDI go through 
four different prediction processes. The conflictive 
cases are solved by frequency of appearance. This 
step is the same for both linguistic and semantic 
approach. Finally, we collect the results and 
generate the task output format. 
 
3 Results  
The best result in DDI detection and classification 
(macro-average score) were obtained by the 
linguistic approach (run 2), achieving a F1 measure 
of 0.534. 
  
 
 
 
Focusing on DDI detection results, we can see 
that linguistic approach also overcome the 
semantic approach, obtaining a F1 score of 0.676 
and 0.537 respectively. This can be explained since 
the SL kernel optimizes linguistic information 
rather than semantic information. Therefore, ATC 
code format is not appropriate for SL kernel. 
However, the score obtained by the linguistic 
approach using SL kernel with multiword entities 
processing seems to be higher than the average 
results obtained in DDIExtraction 2011 task. This 
may be due to the great improvement that 
DrugDDI corpus suffered since the last 
competition, by enriching the information of each 
entity. 
Finally, we have a word to notice the decrease 
of the results from DDI detection evaluation to 
DDI detection and classification evaluation. This 
could be due to the complexity of the DDI type 
classification task. However, the final result of 
macro-average score shows huge margin of 
improvement.  
 
4 Conclusion and future work 
In this paper we present a kernel based approach to 
identify and classify DDIs by using SL kernel. The 
result obtained by the system achieves 0.534 F1 
measure. From linguistic approach and semantic 
approach purposed for the participation in the task, 
the linguistic approach shows better results. 
However, we can not discard semantic information 
since we may have not used the appropriate 
semantic information for a shallow linguistic 
kernel.  
Thus, a possible future work could be the 
research in semantic information processing to 
help in the classification process. Therefore, 
another future work could be the integration of 
pharmacological ontologies in the classification 
process since they increase the knowledge 
available for the classification task.  
 
Acknowledgments 
This work has been funded by MA2VICMR 
project (S2009/TIC-1542) and MULTIMEDICA 
project10 (TIN 2010-20644-C03-01). 
 
References  
Aamodt A., Plaza E. 1994. Case-Based Reasoning: 
Foundational Issues, Methodological Variations, and 
System Approaches. AI Communications 7(1), P 39?
59.  
Airola, A., Pyysalo, S., Bj?rne, J., Pahikkala, T., Ginter, 
F., Salakoski, T. 2008. Allpaths graph kernel for 
protein-protein interaction extraction with evaluation 
of cross-corpus learning. BMC Bioinformatics, 9 
S11, S2.  
Bj?rne J., Airola A., Pahikkala T., Salakoski T. 2011. 
Drug-Drug interaction extraction from biomedical 
                                                          
10 http://labda.inf.uc3m.es/multimedica/ 
Table 1: Results obtained by the system. 
 
620
texts with SVM and RLS classifiers. Proceedings of 
DDIExtraction2011, SEPLN 2011.  
Browne A.C., McCray A.T., Srinivasan S. 2000. The 
SPECIALIST Lexicon. NLM, Bethesda.  
Chowdhury MFM, Lavelli A. 2011. Drug-drug 
Interaction Extraction Using Composite Kernels. 
Proceedings of DDIExtraction2011, SEPLN 2011. 
Giuliano C, Lavelli A, Romano L. 2006. Exploiting 
shallow linguistic information for relation extraction 
from biomedical literature. Proceedings of EACL 
2006.  
Culotta A., Sorensen J. 2004. Dependency tree kernels 
for relation extraction. Proceedings of the 42nd 
annual metting of the Association for Computational 
Linguistics. 
Lease, M., Charniak, E. 2005. Parsing biomedical liter-
ature. Proceedings of IJCNLP?05.  
Marneffe M.C., MacCartney B., Manning C.D. 2006. 
Generating Typed Dependency Parses from Phrase 
Structure Parses. Proceedings of LREC 2006.  
Moschitti, A. 2004. A study on convolution kernels for 
shallow semantic parsing. Proceedings of the 42nd 
Annual Meeting of the Association for 
Computational Linguistics. ACL ?04. 
Segura-Bedmar, I., Mart?nez, P., Pablo-S?nchez, C.d. 
2010. Using a shallow linguistic kernel for drug-drug 
interaction extraction. BMC BioInformatics. 
Thomas P., Neves M., Solt I., Tikk D., Leser U. 2011. 
Relation Extraction for Drug-Drug Interaction using 
Ensemble Learning. Proceedings of DDIExtrac-
tion2011, SEPLN 2011. 
Tikk, D., Thomas, P., Palaga, P., Hakenberg, J., Leser, 
U. 2010. A comprehensive benchmark of kernel 
methods to extract protein-protein interactions from 
literature. PLoS Comput Biol 6. 
Vapnik, V.N. 1995. The nature of statistical learning 
theory. Springer-Verlag New York. 
621
Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic
Evaluation (SemEval 2013), pages 622?627, Atlanta, Georgia, June 14-15, 2013. c?2013 Association for Computational Linguistics
UEM-UC3M: An Ontology-based named entity recognition system for 
biomedical texts. 
 
 
Daniel Sanchez-Cisneros Fernando Aparicio Gali 
Universidad Carlos III de Madrid Universidad Europea de Madrid 
Avda. de la Universidad, 30 C/ Tajo, s/n. Urb. El Bosque 
28911 Legan?s - Madrid - Spain 28670-Villaviciosa de Od?n- (Madrid) 
dscisner@inf.uc3m.es fernando.aparicio@uem.es 
  
  
 
 
 
Abstract 
Drug name entity recognition focuses on 
identifying concepts appearing in the text that 
correspond to a chemical substance used in 
pharmacology for treatment, cure, prevention 
or diagnosis of diseases. This paper describes 
a system based on ontologies for identifying 
the chemical substances in biomedical text. 
The system achieves an F-1 measure of 0.529 
in the task.  
1 Introduction 
Named entity recognition (NER) involves 
processing text and identifying certain occurrences 
of words belonging to particular categories of 
named entities. In recent years, much attention has 
been paid to the problem of recognizing gene and 
protein mentions in biomedical abstracts for 
different purposes such as information extraction, 
relation extraction or information retrieval. In this 
case we focus on the pharmacological domain. 
Furthermore, some initiatives have promoted the 
evaluation of different systems of named entity 
recognition and relation extraction in the 
pharmacological domain. This is the case of 
Semeval 2013: Recognition and classification of 
drug names task1 (Segura-Bedmar et al, 2013), 
where the system presented in this communication 
has been evaluated. 
                                                          
1 http://www.cs.york.ac.uk/semeval-
2013/task9/data/uploads/task-9.1-drug-ner.pdf 
  Following the annotation guidelines of the task, a 
drug is a substance that is used in the treatment, 
cure, prevention or diagnosis of disease. Moreover, 
each drug name entity can be classified in four 
different types: drug, brand, drug_n and group. 
Our system uses biomedical ontologies and 
external resources (containing biomedical 
information) as input to determine whether we are 
treating a drug name entity or not.  
  The resource integration seems to represent an 
improvement since the knowledge available for 
identifying entities is higher. Some biomedical 
resources such as Drugbank2, Kegg3, Pubchem4 or 
Drugs.com5 focus on providing a compound of 
information collected from different sources.  
  Section 2 exposes some related work in the field 
of NER. In section 3 we describe the system used 
for identifying drug name entities. Section 4 
presents the results obtained by the system and a 
little comparison with other approaches. In section 
5 we outline some conclusions obtained and ideas 
for future work.  
 
2 Related work 
The field of NER has been very studied in recent 
years, and has been faced in many approaches. 
Since text structures are frequently used to 
characterize documents in text mining algorithms, 
there only stand out those based in terms and 
                                                          
2 http://www.drugbank.ca/ 
3 http://www.genome.jp/kegg/ 
4 http://pubchem.ncbi.nlm.nih.gov/ 
5 http://www.drugs.com/ 
622
Figure 1: Architecture of the system. 
concepts. This is due to that concept-based systems 
represent the semantic content with a smaller 
number of characteristics, opposite to the term-
based systems based on characters or words. 
Concept-based and term-based representations 
mainly differ in the implicit or explicit appearance, 
respectively, of the words identified in the 
document. This fact implies that concept-based 
extraction techniques are more complex, requiring 
the use of more advanced computational linguistics 
techniques and a greater dependence on knowledge 
domain. 
  One reference system that focuses on concept 
recognition in the biomedical domain is MetaMap 
(Aronson, 2001). MetaMap is a program developed 
by the National Library of Medicine (NLM) that 
uses the UMLS Metathesaurus for annotating the 
concepts in a given text. The program is designed 
to obtain the concept that best fits a particular 
phrase, finding its origin in an attempt to improve 
the retrieval of biomedical literature indexed in 
MEDLINE/PubMed. MetaMap is a program with 
many strengths, such as the power of linguistic 
analysis, the high performance setting possibilities 
and the variety of processing algorithms included. 
On the other hand, MetaMap shows some 
weaknesses such as the algorithms developing 
focused on English grammar texts, or high 
processing time lapse due to the complexity of the 
algorithms (not suitable for real-time systems). 
Metamap analysis time periods goes from less than 
a minute for short simple text to long hours for 
complex sentences. 
  Gimli (Campos et al, 2013) is an open source and 
high-performance solution for biomedical named 
entity recognition on scientific documents, 
supporting the automatic recognition of gene, 
proteins, DNA, RNA, and cell domain names. This 
tool implements a machine learning approach 
based on conditional random fields (CRF).  
  On the other hand, there exists a more recent 
concept extraction techniques based on ontologies. 
Ontologies link concept labels to their 
interpretations, ie specifications of their meanings 
including concept definitions and relations to other 
concepts. Apart from relations such as isa and 
part-of, generally present in almost any domain, 
ontologies also model domain-specific relations, eg 
clinically-associated-with and has-manifestation 
are specific associations for the biomedical 
domain. Therefore, ontologies reflect the structure 
of the domain and constrain the potential 
interpretations of terms. Thus, ontologies can 
provide rich concept knowledge of domain specific 
name entities. This is the case of Open Biomedical 
Annotator (OBA) (Jonquet et al, 2009), an 
impressive annotation system using ontologies, 
which provides online access for users and for 
other systems as a Web service. There are other 
examples of utilities for extracting concepts using 
ontologies (e.g. Terminizer (Hancock et al, 2009), 
Whatizit (Rebholz-Schuhmann et al, 2008) or 
Reflect (Pafilis et al, 2009)). However, the 
magnitude of ontologies and resources integrated 
under the OBA Web service is difficult to reach by 
other systems (Whetzel et al, 2011): in three years 
623
(from 2008 to 2011), they have increased from 72 
to 260 biomedical ontologies. 
  The concept recognition tool used by the OBA 
system -in order to find ontology concepts 
matching the terms extracted from texts- is called 
Mgrep. Although Mgrep is not a free tool, some 
results are presented in (Jonquet et al, 2008). A 
comparison between Mgrep and MetaMap can also 
be found in (Shah et al, 2009), where they make 
an evaluation over a biological and disease terms 
dictionaries with precision (0.87 to 0.71 
respectively) and recall (1548 to 1730 recovered 
terms respectively) metrics. Thus, we decided to 
use Mgrep for identifying drug name entities in the 
system. 
 
3 Description of the system  
The system (see figure 1) is divided in two phases: 
(i) in one hand, the system must scan drug name 
entities without specifying any further information. 
This is the so-called entity identification process; 
(ii) on the other hand, the system classifies by 
using a rule-based process the type of the entities 
discovered previously. This is the so-called entity 
classification process. 
The corpus is processed sentence by sentence, 
using the identification tag provided for each 
sentence.  
 
 
 
 
3.1 Entity identification process  
In this phase we analyze each sentence of the 
corpus with Mgrep analyzer. This tool allows us to 
set the ontologies we want to use in the analysis. 
All additional ontologies used in the analysis 
increases the computational complexity required.  
 
The ontologies used in this first drug name 
identification phase belong to UMLS collection, 
and more specifically to the pharmacological 
domain: 
? Master Drug Data Base6 (MDDB): National 
Drug Data File ontology provides a codified 
drug dictionary, drug vocabulary, and drug 
pricing for prescription drugs and medication-
based over-the-counter products in the United 
States. It supports the ever-changing world of 
drug information in healthcare. 
? National Drug File7 (NDF): this ontology 
contains information about a comprehensive 
set of drug database elements and clinical 
information approved by the U.S. Food and 
Drug Administration (FDA), and dietary 
supplements information. 
? National Drug Data File (NDDF): this is an 
extension of the NDF ontology that includes 
chemical ingredients, clinical kinetics, 
diseases, dose forms, pharmaceutical 
preparations, physiological effects and 
                                                          
6 http://www.medispan.com/medi-span-electronic-drug-
file.aspx 
7 http://www.fdbhealth.com/fdb-medknowledge/ 
Figure 2a: Result of analysis with the Mgrep analyzer. 
Figure 2b: Example of multiword drug entity divided. 
624
therapeutic categories. 
? Ontology for Drug Discovery Investigations: 
this ontology contains information about 
description of drug discovery investigations 
from OBO8 relation ontology. 
? MESH Thesaurus9: this ontology contains sets 
of terms naming descriptors in a hierarchical 
structure. There exist 26,853 descriptors and 
over 213,000 entry terms in 2013 MeSH. 
 
For each drug name entity identified the Mgrep 
analyzer provides information about the ontology 
concept recognized, term information, snippet of 
original text (see figure 2a). After identifying drug 
name entities we noticed some errors in the 
recognized concepts, thus we held a post-
processing of the analysis results. Some entities are 
recognized by several ontologies at the same time, 
so it is necessary to filter repeated instances. 
Biomedical complex name entities are not 
identified. To solve this, we join compound name 
entities by following the charoffset of the sentence. 
The system only links two or more drug entities 
that were next to each other, without punctuation 
between them. For example, potassium chloride 
(see figure 2b) is recognized separately in 
potassium and chloride, so we group it as 
potassium chloride concept.  
As a result of this process we obtain a list of 
clear drug name entities that conforms our run 1 
approach in the task. However, we elaborate a 
second filter based in a gazetteer containing terms 
with no useful meaning for our drug name entity 
identification purpose. This gazetteer contains 
terms such as agent, compound and blocker. The 
results of this second filter conforms our run 2 
approach in the task. As a result of entity 
identification phase we obtain a list of drug name 
entities, but they are not identified as any type yet.  
3.2 Entity classification process  
In this phase we classify the list of pharmaceutical 
terms obtained from analysis phase. To do so, we 
elaborate a rule-based system following the 
annotation methods described in the task 
guidelines. This annotation method was based in 
biomedical resources, such as DrugBank, for 
determining aspects as if the drug entity is 
                                                          
8 http://www.obofoundry.org/ro/ 
9 http://www.nlm.nih.gov/pubs/factsheets/mesh.html 
approved for human use, or if the drug entity is 
registered as a brand name. We can organize the 
general rules of the classification process by 
resources used: 
? DrugBank: These rules search the drug entity 
in DrugBank resource and obtain several 
information: 
o Drug information: information about 
approval state of the drug (approved, 
experimental, illicit). A rule classifies 
a drug entity as drug_n when 
experimental or illicit state is found in 
a drug, otherwise the drug entity is 
catalogued as drug type. 
o Synonym list: list of possible 
registered names of the entity. A 
recursive process searches each 
synonym in DrugBank (obviating the 
synonym list this time), and applies the 
rules as if original drug entity were 
treated. The result of the recursive 
process affect to the original drug 
entity. 
o Brand name list: list of registered 
commercial brand names of the entity. 
If a drug name entity is found in the 
brand name list, then it is catalogued 
as a brand type. 
o Categories: information about general 
category of drug. If the drug is found 
as a category, then it is classified as 
group type. 
? Pubchem: These rules search the drug entity 
and obtain information of drug identification 
and compound information and IUPAC name. 
? ATC Index10: These rules look for the drug 
entity in ATC Index resource and determine 
whether the entity is drug or group depending 
on the level of ATC code found.  
? Kegg: These rules search the drug entity in this 
resource and obtain information of drug 
categories. If the drug is found as a category, 
then it is classified as group type. 
? MeSH11:  These rules search information about 
MeSH tree categories classification of the drug 
entity. If the drug is found as a category, then 
it is classified as group type. Another rule 
makes a na?ve processing of the MeSH 
                                                          
10 http://www.whocc.no/atc_ddd_index/ 
11 http://www.ncbi.nlm.nih.gov/mesh/67055162 
625
description text to evaluate if the drug entity 
were used in humans. If this information is 
found in the text, then the drug entity is 
classified as a drug type. 
  
The described rules are representative examples 
of the complete rule-based system. There were 
assigned priorities to the rules, since some rules are 
more certain to describe a drug type than others. 
Thus, if a drug entity is found to be approved for 
using in humans after processing the MeSH text, 
but when looking the DrugBank state is found as 
illicit state, then the drug is classified as drug_n 
type since DrugBank offers a certain state of the 
drug, instead of a natural text description that may 
be classified as a false positive. Depending on the 
values collected on these biomedical resources the 
rule-based system determines whether the type of 
an entity is a drug, group, brand or drug_n. 
 
 
4 Results 
The best result in entity identification (exact 
matching) obtained by the system correspond to 
run 2, achieving a F1 measure of 0.609. On the 
other hand, the best results achieved in strict 
matching (boundary and type evaluation) 
correspond to run 2 again, with 0.529 F1 score. 
 
 
 
 
 
These results contrast with the result obtained by 
run 1, achieving a F1 measure of 0.528 and 0.458 
in entity identification and strict matching 
evaluation respectively. Thus we can quantify the 
advantage of using a filter based on gazetteer in an 
average increment of 0.079 F1 measure. 
We have noticed that the higher results are 
obtained in partial matching evaluation because of 
the relaxed conditions of the charoffset. This seems 
reasonable since complex multiword entity is hard 
to parse and define an exact charoffset. 
On the other hand, we also noticed that 
evaluating the classification of the type decrement 
the best results obtained by the system from 0.609 
to 0.529 of F1 score. This indicates that there is 
still a lot of improvement work in the rule-based 
system for type classification. A little error 
analysis was done in a set of 10 documents of the 
training dataset. The results show errors in 
conflictive entities that show multiples categories 
in DrugBank resource. Thus, for example cocaine 
drug entity contains tags of illicit and approved in 
DrugBank database, so the system classify this 
entity as drug_n instead of drug.  
 
5 Conclusions and future work 
In this paper we present a system for drug name 
entity recognition based on ontologies as 
participation for ?Semeval 2013: Recognition and 
classification of drug names? task. The system is 
based on integration of biomedical resources for 
identification and classification of pharmacological 
entities. The best result of the system obtained an 
F1 measure of 0.529.  
The usage of ontologies in named entity 
recognition task seems to be a good choice since 
we can select specific ontologies. A possible future 
work includes an improvement of rule-based 
system, including a bigger collection of biomedical 
resources.  The entity classification could increase 
the results by creating an hybrid approach between 
rule-based methods and machine learning 
techniques. On the other hand, in the entities 
identification task, the system could include other 
biomedical text analyzers and establish a vote 
system. This would improve whether we consider 
an entity or not. Finally, in error analysis were 
noticed problems related to rule-based module. 
Therefore, an insightful improve could pass 
through making a context analysis in order to clear 
the ambiguity surrounding the drug entity.  
 
Acknowledgments 
This work has been funded by MA2VICMR 
project (S2009/TIC-1542) and MULTIMEDICA 
project12 (TIN 2010-20644-C03-01). 
 
References  
                                                          
12 http://labda.inf.uc3m.es/multimedica/ 
Table 1: Results obtained by the system. 
 
626
Aronson, A.R. 2001. Effective mapping of biomedical 
text to the UMLS Metathesaurus: the MetaMap 
program.Proc AMIA Symp. 17?21.4.  
Campos, D., Matos, S., Oliveira J.L.. 2013. Gimli: open 
source and high-performance biomedical name 
recognition. BMC Bioinformatics 14:54.  
Hancock, D., Morrison N., Velarde G., Field D. 2009. 
Terminizer - Assisting Mark-Up of Text Using 
Ontological Terms. Nature Precedings.  
Jonquet C., Musen M.A., Shah N. 2008. A System for 
Ontology-Based Annotation of Biomedical Data. 
Data Integration in the Life Sciences, Springer Berlin 
Heidelberg, Berlin, Heidelberg, pp. 144?152. 
Jonquet, C., Shah N.H., Musen M.A. 2009. The Open 
Biomedical Annotator, Summit on Translat 
Bioinforma. 56?60.  
Pafilis E., O?Donoghue S.I., Jensen L.J., Horn H., Kuhn 
M., Brown N.P., et al 2009. Reflect: augmented 
browsing for the life scientist. Nature Biotechnology, 
27, 508?510.  
Rebholz-Schuhmann D., Arregui M., Gaudan S., Kirsch 
H., Jimeno A. 2008. Text processing through Web 
services: calling Whatizit. Bioinformatics. 24, 296?
298.  
Segura-Bedmar I., Mart?nez P., Herrero-Zazo M. 2013. 
SemEval-2013 Task 9 : Extraction of Drug-Drug 
Interactions from Biomedical Texts (DDIExtraction 
2013). Proceedings of Semeval 2013.  
Shah N.H., Bhatia N., Jonquet C., Rubin D., Chiang 
A.P., Musen M.A. 2009. Comparison of concept 
recognizers for building the Open Biomedical 
Annotator. BMC Bioinformatics.10, S14. 
 
 
Whetzel P.L., Noy N.F., Shah N.H., Alexander P.R., 
Nyulas C., Tudorache T., et al 2011. BioPortal: 
enhanced functionality via new Web services from 
the National Center for Biomedical Ontology to 
access and use ontologies in software applications. 
Nucleic Acids Research. 39, W541?W545.  
 
627
