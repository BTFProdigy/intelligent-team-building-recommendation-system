Proceedings of the EACL 2009 Workshop on Language Technologies for African Languages ? AfLaT 2009, pages 9?16,
Athens, Greece, 31 March 2009. c?2009 Association for Computational Linguistics
The SAWA Corpus: a Parallel Corpus English - Swahili
Guy De Pauw
CNTS - Language Technology Group, University of Antwerp, Belgium
School of Computing and Informatics, University of Nairobi, Kenya
guy.depauw@ua.ac.be
Peter Waiganjo Wagacha
School of Computing and Informatics, University of Nairobi, Kenya
waiganjo@uonbi.ac.ke
Gilles-Maurice de Schryver
African Languages and Cultures, Ghent University, Belgium
Xhosa Department, University of the Western Cape, South Africa
gillesmaurice.deschryver@ugent.be
Abstract
Research in data-driven methods for Ma-
chine Translation has greatly benefited
from the increasing availability of paral-
lel corpora. Processing the same text in
two different languages yields useful in-
formation on how words and phrases are
translated from a source language into a
target language. To investigate this, a par-
allel corpus is typically aligned by linking
linguistic tokens in the source language to
the corresponding units in the target lan-
guage. An aligned parallel corpus there-
fore facilitates the automatic development
of a machine translation system and can
also bootstrap annotation through projec-
tion. In this paper, we describe data col-
lection and annotation efforts and prelim-
inary experimental results with a parallel
corpus English - Swahili.
1 Introduction
Language technology applications such as ma-
chine translation can provide an invaluable, but
all too often ignored, impetus in bridging the dig-
ital divide between the Western world and Africa.
Quite a few localization efforts are currently un-
derway that improve ICT access in local African
languages. Vernacular content is now increasingly
being published on the Internet, and the need for
robust language technology applications that can
process this data is high.
For a language like Swahili, digital resources
have become increasingly important in everyday
life, both in urban and rural areas, particularly
thanks to the increasing number of web-enabled
mobile phone users in the language area. But most
research efforts in the field of natural language
processing (NLP) for African languages are still
firmly rooted in the rule-based paradigm. Lan-
guage technology components in this sense are
usually straight implementations of insights de-
rived from grammarians. While the rule-based
approach definitely has its merits, particularly in
terms of design transparency, it has the distinct
disadvantage of being highly language-dependent
and costly to develop, as it typically involves a lot
of expert manual effort.
Furthermore, many of these systems are decid-
edly competence-based. The systems are often
tweaked and tuned towards a small set of ideal
sample words or sentences, ignoring the fact that
real-world language technology applications have
to be principally able to handle the performance
aspect of language. Many researchers in the field
are quite rightly growing weary of publications
that ignore quantitative evaluation on real-world
data or that report incredulously high accuracy
scores, excused by the erroneously perceived reg-
ularity of African languages.
In a linguistically diverse and increasingly com-
puterized continent such as Africa, the need for a
more empirical approach to language technology
is high. The data-driven, corpus-based approach
described in this paper establishes such an alter-
native, so far not yet extensively investigated for
African languages. The main advantage of this
9
approach is its language independence: all that is
needed is (linguistically annotated) language data,
which is fairly cheap to compile. Given this data,
existing state-of-the-art algorithms and resources
can consequently be re-used to quickly develop ro-
bust language applications and tools.
Most African languages are however resource-
scarce, meaning that digital text resources are few.
An increasing number of publications however are
showing that carefully selected procedures can in-
deed bootstrap language technology for Swahili
(De Pauw et al, 2006; De Pauw and de Schryver,
2008), Northern Sotho (de Schryver and De Pauw,
2007) and smaller African languages (Wagacha et
al., 2006a; Wagacha et al, 2006b; De Pauw and
Wagacha, 2007; De Pauw et al, 2007a; De Pauw
et al, 2007b).
In this paper we outline on-going research on
the development of a parallel corpus English -
Swahili. The parallel corpus is designed to boot-
strap a data-driven machine translation system for
the language pair in question, as well as open up
possibilities for projection of annotation.
We start off with a short survey of the different
approaches to machine translation (Section 2) and
showcase the possibility of projection of annota-
tion (Section 3). We then concentrate on the re-
quired data collection and annotation efforts (Sec-
tion 4) and describe preliminary experiments on
sentence, word and morpheme alignment (Sec-
tions 5 and 6). We conclude with a discussion of
the current limitations to the approach and provide
pointers for future research (Section 7).
2 Machine Translation
The main task of Machine Translation (MT) can
be defined as having a computer take a text in-
put in one language, the Source language (SL),
decode its meaning and re-encode it producing as
output a similar-meaning text in another language,
the Target language (TL). The idea of building
an application to automatically convert text from
one language to an equivalent text-meaning in
a second language traces its roots back to Cold
War intelligence efforts in the 1950?s and 60?s for
Russian-English text translations. Since then a
large number of MT systems have been developed
with varying degrees of success. For an excellent
overview of the history of MT, we refer the reader
to Hutchins (1986).
The original dream of creating a fully automatic
MT system has long since been abandoned and
most research in the field currently concentrates
on minimizing human pre- and post-processing ef-
fort. A human translator is thus considered to
work alongside the MT system to produce faster
and more consistent translations.
The Internet brought in an interesting new di-
mension to the purpose of MT. In the mid 1990s,
free on-line translation services began to surface
with an increasing number of MT vendors. The
most famous example is Yahoo!?s Babelfish , of-
fering on-line versions of Systran to translate En-
glish, French, German, Spanish and other Indo-
European languages. Currently Google.inc is also
offering translation services. While these systems
provide far from perfect output, they can often
give readers a sense of what is being talked about
on a web page in a language (and often even char-
acter set) foreign to them.
There are roughly three types of approaches to
machine translation:
1. Rule-based methods perform translation us-
ing extensive lexicons with morphological,
syntactic and semantic information, and large
sets of manually compiled rules, making
them very labor intensive to develop.
2. Statistical methods entail the collection and
statistical analysis of bilingual text corpora,
i.e. parallel corpora. The technique tries
to find the highest probability translation of
a sentence or phrase among the exponential
number of choices.
3. Example-based methods are similar to sta-
tistical methods in that they are parallel cor-
pus driven. An Example-Based Machine
Translator (EBMT) scans for patterns in both
languages and relates them in a translation
memory.
Most MT systems currently under development
are based on methods (2) and/or (3). Research
in these fields has greatly benefited from the in-
creasing availability of parallel corpora, which are
needed to bootstrap these approaches. Such a par-
allel corpus is typically aligned by linking, either
automatically or manually, linguistic tokens in the
source language to the corresponding units in the
target language. Processing this data enables the
development of fast and effective MT systems in
both directions with a minimum of human involve-
ment.
10
English Swahili English Swahili
Sentences Sentences Words Words
New Testament 7.9k 189.2k 151.1k
Quran 6.2k 165.5k 124.3k
Declaration of HR 0.2k 1.8k 1.8k
Kamusi.org 5.6k 35.5k 26.7k
Movie Subtitles 9.0k 72.2k 58.4k
Investment Reports 3.2k 3.1k 52.9k 54.9k
Local Translator 1.5k 1.6k 25.0k 25.7k
Full Corpus Total 33.6k 33.6k 542.1k 442.9k
Table 1: Overview of the data in the SAWA Corpus
3 Projection of Annotation
While machine translation constitutes the most
straightforward application of a parallel corpus,
projection of annotation has recently become an
interesting alternative use of this type of resource.
As previously mentioned, most African languages
are resource-scarce: annotated data is not only un-
available, but commercial interest to develop these
resources is limited. Unsupervised approaches
can be used to bootstrap annotation of a resource-
scarce language (De Pauw and Wagacha, 2007; De
Pauw et al, 2007a) by automatically finding lin-
guistic patterns in large amounts of raw text.
Projection of annotation attempts to achieve the
same goal, but through the use of a parallel cor-
pus. These techniques try to transport the annota-
tion of a well resourced source language, such as
English, to texts in a target language. As a natu-
ral extension of the domain of machine translation,
these methods employ parallel corpora which are
aligned at the sentence and word level. The di-
rect correspondence assumption coined in Hwa et
al. (2002) hypothesizes that words that are aligned
between source and target language, must share
linguistic features as well. It therefore allows for
the annotation of the words in the source language
to be projected unto the text in the target language.
The following general principle holds: the closer
source and target language are related, the more
accurate this projection can be performed. Even
though lexical and structural differences between
languages prevent a simple one-to-one mapping,
knowledge transfer is often able to generate a well
directed annotation of the target language.
This holds particular promise for the annotation
of dependency analyses for Swahili, as exempli-
fied in Figure 1, since dependency grammar fo-
root The cat fell into the water
root Paka alianguka ndani ya maji
main
dt subj pp dt
comp
main
subj pp
comp
??
Figure 1: Projection of Dependency Analysis An-
notation
cuses on semantic relationships, rather than core
syntactic properties, that are much more trouble-
some to project across languages. The idea is that
a relationship that holds between two words in the
source language (for instance the subj relationship
between cat and fell), also holds for the corre-
sponding linguistic tokens in the target language,
i.e. paka and alianguka.
In the next section we describe data collection
and preprocessing efforts on the SAWA Corpus,
a parallel corpus English - Swahili (cf. Table 1),
which will enable this type of projection of anno-
tation, as well as the development of a data-driven
machine translation system.
4 Data Collection and Annotation
While digital data is increasingly becoming avail-
able for Swahili on the Internet, sourcing useful
11
Figure 2: Manual word alignment using the UMIACS interface
bilingual data is far from trivial. At this stage in
the development of the MT system, it is paramount
to use faithfully translated material, as this benefits
further automated processing. The corpus-based
MT approaches we wish to employ, require word
alignment to be performed on the texts, during
which the words in the source language are linked
to the corresponding words in the target language
(also see Figures 1 and 2).
But before we can do this, we need to perform
sentence-alignment, during which we establish an
unambiguous mapping between the sentences in
the source text and the sentences in the target text.
While some data is inherently sentence-aligned,
other texts require significant preprocessing before
word alignment can be performed.
The SAWA Corpus currently consists of a rea-
sonable amount of data (roughly half a million
words in each language), although this is not
comparable to the resources available to Indo-
European language pairs, such as the Hansard cor-
pus (Roukos et al, 1997) (2.87 million sentence
pairs). Table 1 gives an overview of the data avail-
able in the SAWA Corpus. For each segment it lists
the number of sentences and words in the respec-
tive languages.
4.1 Sentence-aligned Resources
We found digitally available Swahili versions of
the New Testament and the Quran for which we
sourced the English counterparts. This is not a
trivial task when, as in the case of the Swahili
documents, the exact source of the translation is
not provided. By carefully examining subtle dif-
ferences in the English versions, we were how-
ever able to track down the most likely candidate.
While religious material has a specific register and
may not constitute ideal training material for an
open-ended MT system, it does have the advan-
tage of being inherently aligned on the verse level,
facilitating further sentence alignment. Another
typical bilingual text is the UN Declaration of Hu-
man Rights, which is available in many of the
world?s languages, including Swahili. The manual
sentence alignment of this text is greatly facilitated
by the fixed structure of the document.
The downloadable version of the on-line dictio-
nary English-Swahili (Benjamin, 2009) contains
individual example sentences associated with the
dictionary entries. These can be extracted and
used as parallel data in the SAWA corpus. Since
at a later point, we also wish to study the specific
linguistic aspects of spoken language, we opted
to have some movie subtitles manually translated.
These can be extracted from DVDs and while the
12
language is compressed to fit on screen and con-
stitutes scripted language, they nevertheless pro-
vide a reasonable approximation of spoken lan-
guage. Another advantage of this data is that it
is inherently sentence-aligned, thanks to the tech-
nical time-coding information. It also opens up
possibilities for MT systems with other language
pairs, since a commercial DVD typically contains
subtitles for a large number of other languages as
well.
4.2 Paragraph-aligned Resources
The rest of the material consists of paragraph-
aligned data, which was manually sentence-
aligned. We obtained a substantial amount of data
from a local Kenyan translator. Finally, we also
included Kenyan investment reports. These are
yearly reports from local companies and are pre-
sented in both English and Swahili. A major dif-
ficulty was extracting the data from these docu-
ments. The company reports are presented in col-
orful brochures in PDF format, meaning automatic
text exports require manual post-processing and
paragraph alignment (Figure 3). They neverthe-
less provide a valuable resource, since they come
from a fairly specific domain and are a good sam-
ple of the type of text the projected MT system
may need to process in a practical setting.
The reader may note that there is a very diverse
variety of texts within the SAWA corpus, ranging
from movie subtitles to religious texts. While it
certainly benefits the evaluation to use data from
texts in one specific language register, we have
chosen to maintain variety in the language data at
this point. Upon evaluating the decoder at a later
stage, we will however investigate the bias intro-
duced by the specific language registers in the cor-
pus.
4.3 Word Alignment
All of the data in the corpus was subsequently
tokenized, which involves automatically cleaning
up the texts, conversion to UTF-8, and splitting
punctuation from word forms. The next step in-
volved scanning for sentence boundaries in the
paragraph-aligned text, to facilitate the automatic
sentence alignment method described in Section 5.
While not necessary for further processing, we
also performed manual word-alignment annota-
tion. This task can be done automatically, but it
is useful to have a gold-standard reference against
which we can evaluate the automated method.
Figure 3: Text Extraction from Bilingual Invest-
ment Report
Monitoring the accuracy of the automatic word-
alignment method against the human reference,
will allow us to tweak parameters to arrive at the
optimal settings for this language pair.
We used the UMIACS word alignment interface
(Hwa and Madnani, 2004) for this purpose and
asked the annotators to link the words between the
two sentences (Figure 2). Given the linguistic dif-
ferences between English and Swahili, this is by
no means a trivial task. Particularly the morpho-
logical richness of Swahili means that there is a lot
of convergence from words in English to words
in Swahili (also see Section 6). This alignment
was done on some of the manual translations of
movie subtitles, giving us a gold-standard word-
alignment reference of about 5,000 words. Each
annotator?s work was cross-checked by another
annotator to improve correctness and consistency.
5 Alignment Experiments
There are a number of packages available to
process parallel corpora. To preprocess the
paragraph-aligned texts, we used Microsoft?s
bilingual sentence aligner (Moore, 2002). The
13
Precision Recall F(? = 1)
39.4% 44.5% 41.79%
Table 2: Precision, Recall and F-score for the
word-alignment task using GIZA++
output of the sentence alignment was conse-
quently manually corrected. We found that 95% of
the sentences were correctly aligned with most er-
rors being made on sentences that were not present
in English, i.e. instances where the translator de-
cided to add an extra clarifying sentence to the di-
rect translation from English. This also explains
why there are more Swahili words in the paragraph
aligned texts than in English, while the situation is
reversed for the sentence aligned data.
For word-alignment, the state-of-the-art method
is GIZA++ (Och and Ney, 2003), which imple-
ments the word alignment methods IBM1 to IBM5
and HMM. While this method has a strong Indo-
European bias, it is nevertheless interesting to see
how far we can get with the default approach used
in statistical MT.
We evaluate by looking at the word alignments
proposed by GIZA++ and compare them to the
manually word-aligned section of the SAWA Cor-
pus. We can quantify the evaluation by calculat-
ing precision and recall and their harmonic mean,
the F-score (Table 2). The former expresses how
many links are correct, divided by the total num-
ber of links suggested by GIZA++. The latter is
calculated by dividing the number of correct links,
by the total number of links in the manual annota-
tion. The underwhelming results presented in Ta-
ble 2 can be attributed to the strong Indo-European
bias of the current approaches. It is clear that extra
linguistic data sources and a more elaborate explo-
ration of the experimental parameters of GIZA++
will be needed, as well as a different approach to
word-alignment. In the next section, we describe
a potential solution to the problem by defining the
problem on the level of the morpheme.
6 Alignment into an Agglutinating
Language
The main problem in training a GIZA++ model for
the language pair English - Swahili is the strong
agglutinating nature of the latter. Alignment pat-
terns such as the one in Figures 1 and 2 are not
impossible to retrieve. But no corpus is exhaus-
tive enough to provide enough linguistic evidence
Precision Recall F(? = 1)
50.2% 64.5% 55.8%
Table 3: Precision, Recall and F-score for the
morpheme/word-alignment task using GIZA++
to unearth strongly converging alignment patterns,
such as the one in Example 1.
(1) I have turned him down
Nimemkatalia
Morphologically deconstructing the word how-
ever can greatly relieve the sparse data problem for
this task:
(2) I have turned him down
Ni- me- m- katalia
The isolated Swahili morphemes can more eas-
ily be linked to their English counterparts, since
there will be more linguistic evidence in the par-
allel corpus, linking for example ni to I and m
to him. To perform this kind of morphological
analysis, we developed a machine learning system
trained and evaluated on the Helsinki corpus of
Swahili (Hurskainen, 2004). Experimental results
show that the data-driven approach achieves state-
of-the-art performance in a direct comparison with
a rule-based method, with the added advantage of
being robust to word forms for previously unseen
lemmas (De Pauw and de Schryver, 2008). We
can consequently use morphological deconstruc-
tion as a preprocessing step for the alignment task,
similar to the method described by Goldwater and
McClosky (2005), Oflazer (2008) and Stymne et
al. (2008).
We have no morphologically aligned parallel
data available, so evaluation of the morphology-
based approach needs to be done in a roundabout
way. We first morphologically decompose the
Swahili data and run GIZA++ again. Then we re-
compile the Swahili words from the morphemes
and group the word alignment links accordingly.
Incompatible linkages are removed. The updated
scores are presented in Table 3. While this cer-
tainly improves on the scores in Table 2, we need
to be aware of the difficulty that the morphological
preprocessing step will introduce in the decoding
phase, necessitating the introduction of a language
model that not only works on the word level, but
14
also on the level of the morpheme.
For the purpose of projection of annotation, this
is however not an issue. We performed a prelim-
inary experiment with a dependency-parsed En-
glish corpus, projected unto the morphologically
decompounded tokens in Swahili. We are cur-
rently lacking the annotated gold-standard data to
perform quantitative evaluation, but have observed
interesting annotation results, that open up pos-
sibilities for the morphological analysis of more
resource-scarce languages.
7 Discussion
In this paper we presented parallel corpus collec-
tion work that will enable the construction of a
machine translation system for the language pair
English - Swahili, as well as open up the possibil-
ity of corpus annotation through projection. We
are confident that we are approaching a critical
amount of data that will enable good word align-
ment that can subsequently be used as a model for
an MT decoding system, such as the Moses pack-
age (Koehn et al, 2007). While the currently re-
ported scores are not yet state-of-the-art, we are
confident that further experimentation and the ad-
dition of more bilingual data as well as the intro-
duction of extra linguistic features will raise the
accuracy level of the proposed MT system.
Apart from the morphological deconstruction
described in Section 6, the most straightforward
addition is the introduction of part-of-speech tags
as an extra layer of linguistic description, which
can be used in word alignment model IBM5. The
current word alignment method tries to link word
forms, but knowing that for instance a word in the
source language is a noun, will facilitate linking
it to a corresponding noun in the target language,
rather than considering a verb as a possible match.
Both for English (Ratnaparkhi, 1996) and Swahili
(De Pauw et al, 2006), we have highly accurate
part-of-speech taggers available.
Another extra information source that we have
so far ignored is a digital dictionary as a seed for
the word alignment. The kamusiproject.org elec-
tronic dictionary will be included in further word-
alignment experiments and will undoubtedly im-
prove the quality of the output.
Once we have a stable word alignment mod-
ule, we will further conduct learning curve exper-
iments, in which we train the system with grad-
ually increasing amounts of data. This will pro-
vide us with information on how much more data
we need to achieve state-of-the-art performance.
This additional data can be automatically found
by parallel web mining, for which a few sys-
tems have recently become available (Resnik and
Smith, 2003).
Furthermore, we will also look into the use
of comparable corpora, i.e. bilingual texts that
are not straight translations, but deal with the
same subject matter. These have been found to
work as additional material within a parallel cor-
pus (McEnery and Xiao, 2007) and may further
help improve the development of a robust, open-
ended and bidirectional machine translation sys-
tem for the language pair English - Swahili. The
most innovative prospect of the parallel corpus is
the annotation of dependency analysis in Swahili,
not only on the syntactic level, but also on the
level of the morphology. The preliminary exper-
iments indicate that this approach might provide a
valuable technique to bootstrap annotation in truly
resource-scarce languages.
Acknowledgments
The research presented in this paper was made
possible through the support of the VLIR-IUC-
UON program and was partly funded by the SAWA
BOF UA-2007 project. The first author is funded
as a Postdoctoral Fellow of the Research Founda-
tion - Flanders (FWO). We are greatly indebted to
Dr. James Omboga Zaja for contributing some of
his translated data, to Mahmoud Shokrollahi-Far
for his advice on the Quran and to Anne Kimani,
Chris Wangai Njoka and Naomi Maajabu for their
annotation efforts.
References
M. Benjamin. 2009. The Kamusi Project. Available at:
http://www.kamusiproject.org (Accessed: 14 Jan-
uary 2009).
G. De Pauw and G.-M. de Schryver. 2008. Improv-
ing the computational morphological analysis of a
Swahili corpus for lexicographic purposes. Lexikos,
18:303?318.
G. De Pauw and P.W. Wagacha. 2007. Bootstrapping
morphological analysis of G??ku?yu? using unsuper-
vised maximum entropy learning. In Proceedings
of the eighth INTERSPEECH conference, Antwerp,
Belgium.
G. De Pauw, G.-M. de Schryver, and P.W. Wa-
gacha. 2006. Data-driven part-of-speech tagging of
15
Kiswahili. In P. Sojka, I. Kopec?ek, and K. Pala, edi-
tors, Proceedings of Text, Speech and Dialogue, 9th
International Conference, volume 4188 of Lecture
Notes in Computer Science, pages 197?204, Berlin,
Germany. Springer Verlag.
G. De Pauw, P.W. Wagacha, and D.A. Abade. 2007a.
Unsupervised induction of Dholuo word classes
using maximum entropy learning. In K. Getao
and E. Omwenga, editors, Proceedings of the First
International Computer Science and ICT Confer-
ence, pages 139?143, Nairobi, Kenya. University of
Nairobi.
G. De Pauw, P.W. Wagacha, and G.-M. de Schryver.
2007b. Automatic diacritic restoration for resource-
scarce languages. In Va?clav Matous?ek and Pavel
Mautner, editors, Proceedings of Text, Speech and
Dialogue, Tenth International Conference, volume
4629 of Lecture Notes in Computer Science, pages
170?179, Heidelberg, Germany. Springer Verlag.
G.-M. de Schryver and G. De Pauw. 2007. Dictio-
nary writing system (DWS) + corpus query package
(CQP): The case of Tshwanelex. Lexikos, 17:226?
246.
S. Goldwater and D. McClosky. 2005. Improving sta-
tistical MT through morphological analysis. In Pro-
ceedings of the Human Language Technology Con-
ference and Conference on Empirical Methods in
Natural Language Processing, pages 676?683, Van-
couver, Canada.
Google. 2009. Google Translate. Available
at http://www.google.com/translate (Accessed: 14
January 2009.
A. Hurskainen. 2004. HCS 2004 ? Helsinki Corpus of
Swahili. Technical report, Compilers: Institute for
Asian and African Studies (University of Helsinki)
and CSC.
W.J. Hutchins. 1986. Machine translation: past,
present, future. Ellis, Chichester.
R. Hwa and N. Madnani. 2004. The UMI-
ACS Word Alignment Interface. Available at:
http://www.umiacs.umd.edu/?nmadnani/alignment/
forclip.htm (Accessed: 14 January 2009).
R. Hwa, Ph. Resnik, A. Weinberg, and O. Kolak. 2002.
Evaluating translational correspondence using anno-
tation projection. In Proceedings of the 40th Annual
Meeting of the Association for Computational Lin-
guistics, pages 392?399, Philadelphia, PA, USA.
Ph. Koehn, H. Hoang, A. Birch, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,
and E. Herbst. 2007. Moses: Open source toolkit
for statistical machine translation. In Annual Meet-
ing of the Association for Computational Linguistics
(ACL), demonstration session, Prague, Czech Re-
public.
A.M. McEnery and R.Z Xiao. 2007. Parallel and
comparable corpora: What are they up to? In In-
corporating Corpora: Translation and the Linguist.
Translating Europe. Multilingual Matters, Cleve-
don, UK.
R.C. Moore. 2002. Fast and accurate sentence align-
ment of bilingual corpora. In Proceedings of the 5th
Conference of the Association for Machine Transla-
tion in the Americas on Machine Translation: From
Research to Real Users, volume 2499 of Lecture
Notes in Computer Science, pages 135?144, Berlin,
Germany. Springer Verlag.
F.J. Och and H. Ney. 2003. A systematic comparison
of various statistical alignment models. Computa-
tional Linguistics, 29(1):19?51.
K. Oflazer. 2008. Statistical machine translation into
a morphologically complex language. In Compu-
tational Linguistics and Intelligent Text Processing,
pages 376?388, Berlin, Germany. Springer Verlag.
A. Ratnaparkhi. 1996. A maximum entropy model for
part-of-speech tagging. In E. Brill and K. Church,
editors, Proceedings of the Conference on Empiri-
cal Methods in Natural Language Processing, pages
133?142. Association for Computational Linguis-
tics.
Ph. Resnik and N.A. Smith. 2003. The web as a par-
allel corpus. Computational Linguistics, 29(1):349?
380.
S. Roukos, D. Graff, and D. Melamed. 1997.
Hansard French/English. Available at:
http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?
catalogId=LDC95T20 (Accessed: 14 January
2009).
S. Stymne, M. Holmqvist, and L. Ahrenberg. 2008.
Effects of morphological analysis in translation be-
tween German and English. In Proceedings of the
Third Workshop on Statistical Machine Translation,
pages 135?138, Columbus, USA.
P.W. Wagacha, G. De Pauw, and K. Getao. 2006a.
Development of a corpus for G??ku?yu? using machine
learning techniques. In J.C. Roux, editor, Proceed-
ings of LREC workshop - Networking the develop-
ment of language resources for African languages,
pages 27?30, Genoa, Italy, May, 2006. European
Language Resources Association, ELRA.
P.W. Wagacha, G. De Pauw, and P.W. Githinji. 2006b.
A grapheme-based approach for accent restoration
in G??ku?yu?. In Proceedings of the Fifth International
Conference on Language Resources and Evaluation,
pages 1937?1940, Genoa, Italy, May, 2006. Euro-
pean Language Resources Association, ELRA.
Yahoo! 2009. Babelfish. Available at
http://babelfish.yahoo.com (Accessed: 14 January
2009).
16
Proceedings of the 2014 Workshop on the Use of Computational Methods in the Study of Endangered Languages, pages 68?72,
Baltimore, Maryland, USA, 26 June 2014. c?2014 Association for Computational Linguistics
 
InterlinguaPlus Machine Translation Approach for Under-Resourced Languages: Ekegusii & Swahili  Edward O. Ombui1, 2, Peter W. Wagacha2 and Wanjiku Ng?ang?a2 1 Computer Science Dept. Africa Nazarene University (Kenya) eombui@anu.ac.ke 2 School of Computing and Informatics, University of Nairobi (Kenya) waiganjo@uonbi.ac.ke, wanjiku.nganga@uonbi.ac.ke  Abstract This paper elucidates the InterlinguaPlus design and its application in bi-directional text translations between Ekegusii and Kiswahili languages unlike the traditional translation pairs, one-by-one. Therefore, any of the languages can be the source or target language. The first section is an overview of the project, which is followed by a brief review of Machine Translation. The next section discusses the implementation of the system using Carabao?s open machine translation framework and the results obtained. So far, the translation results have been plausible particularly for the resource-scarce local languages and clearly affirm morphological similarities inherent in Bantu languages.  Keywords: Machine Translation, InterlinguaPlus, Ekegusii  1. Introduction Development of language applications for local languages in Africa requires innovative approaches since many of these languages are resource scarce. By this we mean that electronic language resources such as digital corpora, electronic dictionaries, spell checkers, annotators, and parsers are hardly available. These languages are also predominately spoken rather than written. Moreover, they are generally used in environments where there are other competing languages like English and French which have been well documented over the years with properly defined grammars, unlike the local languages with poorly defined grammars and dictionaries. This has been a major setback in the development of technologies for African languages. The presence of diacritics in most of these languages has also contributed to the complexity involved in the development of language technology applications. (Ombui & Wagacha, 2007).     Nevertheless, there is pioneering work with the South African languages, which includes the definition of proper language grammars and development of a national language policy framework to encourage the utilization of the 
indigenous languages as official languages (NLPF, 2003).   In this paper, we consider two Bantu languages in Kenya namely Ekegusii and Swahili. There are approximately two million Ekegusii language speakers (KNBS, 2009). Swahili is widely spoken in East and Central Africa and is one of the official languages of the African Union with lots of printed resources.  For the work that we are reporting, we have adopted the InterlinguaPlus approach using the Carabao open machine translation framework (Berman, 2012). In this approach, all similar meaning words, synonyms, from each language and across the languages existing in the system are stored under the same category and assigned an identical family number. These words are also tagged with numbered lexical information1. For example, Egetabu (a book) [1=N; 2=SG; 5=No]. Tag1 stands for the part of speech (1-POS), Noun, tag2 for number (2-No.), Singular, and tag5 indicates whether the noun is animate or inanimate etc. An amalgamation of the word?s family identification number and tag numbers form a unique ID for the word. In addition, a novel way of only storing the base forms of each word and having a different table containing affixes that inflect the word drastically reduces the lexical database size and development time in general. This approach is implemented through the manual encoding of the sequence rules for the two languages. Preliminary results are encouraging and clearly reveal similarities in the language structure of Ekegusii and Swahili. The advantage of this approach is that the translation is bidirectional and maintains the semantic approach to translation just as a human translator. In addition, it is suitable for rapid generation of domain specific translations for under-resourced languages. 
                                                1 Grammatical, Stylistic and Semantic tags 
68
 2. Machine Translation Over the history of MT, several techniques and approaches have continued to be developed despite previous discouraging reports (ALPAC, 1966). The major approaches and methodologies include: Rule-based and Corpus-based, Direct translation and indirect translation (i.e. transfer-based and Interlingua-based) (Hutchins, 1993 & Hutchins, 1994). With the introduction of Artificial Intelligence technology in MT, more recent approaches have been proposed including alignment template approach to Statistical MT (Och & Ney, 2004), Knowledge-based approach (Nirenburg et al., 1992),  Human in loop, and Hybrid methods (Groves & Way, 2006).  One of the strengths of the InterlinguaPlus approach (Berman, 2012) is that it preserves semantic information of the lexicon. Therefore, translation is primarily based on semantic equivalents between the lexicons of these languages.  As a result, the traditional language pair-based translation is replaced by bidirectional translations between the languages existing in the system. Any language can be the source or a target language.  Consequently, the lexical database size is drastically reduced and the task of building multiple dictionaries is concentrated in constructing just one Interlingua lexical database.  This kind of approach is evidently advantageous when building machine translation applications for under-resourced African languages because it expedites the process of adding a new language with minimal effort especially when adding languages of similar grammatical makeup, which could reuse some of the existing grammar rules. 3. Implementation Figure 1 below illustrates the translation process in the Ekegusii Machine Translation (EMT) system. The user inputs a sentence, which is parsed into its constituent tokens. These tokens are then matched and mapped to their equivalent target-language tokens using the Family and mapping Identification numbers respectively. In addition, the sequence2 e.g. Subject+Verb+Object is parsed into elements (lexical units) and authenticated against the elements of the analyzed sentence.  If it is valid, the elements are mapped according to the sequence and modified by the corresponding                                                 2 Set of elements, which refer to tokens that have specified features e.g. grammatical data, style, word-order, etc. 
sequence in the target language. Some of the features that can be modified include deleting or adding a new element. E.g. He ate a mango.[eng:SVO]. A+li+kula  Embe . Note that Swahili and generally the local African languages do not have determiners. Therefore, when translating from Eng-Swa, the English determiner is dropped. However, it is added if the translation is vice-versa. This is made possible by assigning a locally unique identity number, preserved across languages in the database, to each lexical unit of a sequence. The sequence manager in the system uses these identity numbers to appropriately handle lexical holes and the source/target of each transformation.  
  Figure1: EMT?s MR-PDF  Subject (S1); Verb (V1); Object (O1); Determinant (det); delimiter (del).  The above process, MR-PDF3, is an acronym for the five translation stages (explained below) with the last two stages shifted at the beginning so as to give it an easy-to-remember name. We will use example 1, English to Ekegusii SVO phrase to elucidate the process. Example 1 He ate a mango.  Stage 1: Parsing The sentence is analyzed syntactically according to its constituent structures i.e. tokens including syntax delimiters like question marks, exclamation marks etc. He + ate + a + mango. Ss1:[He] Sv1:[ate] Det:[a] So1:[Mango] del:[.] It is worth noting that at this stage, the parts of speech have not yet been identified. Stage 2: Source Language Dictionary Lookup Each token from stage 1 is looked up in the respective source language dictionary to check whether it exists in that language. In case it is not                                                 3 Mapping (M), Rules (R), Parsing (P), Dictionary look-up (D), Family word-match (F). 
69
 found, the word is left untagged and passed-on as it is to the next stages up to the output.   Stage 3: Family word-match Every morpheme is examined considering all possible combination of affixes to it and each configuration stored. These are then aligned with the corresponding target language dictionary entities.  [He]= [Ere]  [ate]= [ariete] Past form of eat=karia  [a]= [a] yields the same token if an equivalent is not found in the target language. [Mango]= [Riembe] Singular, noun. All other delimiters, e.g. question marks (?), comas (,) are presented as they appeared in the source string. From the above example, all possible modifiers of the verb ?to eat? are generated i.e. eat, ate, eaten, eats, eating, and matched with the corresponding verb in Ekegusii dictionary i.e. Karia, ariete, nkoria, etc.  The tricky part of it is that one may not always have an equivalent number of modified verbs in the target or source dictionaries. To resolve this ambiguity, the program picks the modified verb with the best match in the target language dictionary i.e. in terms of matching lexical or style information e.g. the type of tense, number, animation, gender etc.  If we refer to the same example above, the following is examined as shown in Table 1and Table 2.  Language Morpheme Part Of  Speech ?Modified Morphemes? English Eat Verb Ate; eaten; eating, eats, etc. Ekegusii Ria Verb Karia, ariete, nkoriare, etc. Table 1: Lexical information  ?Modified Morphemes? Tense Number Ate  Past Singular or Plural Eating  Present continuous  Singular or plural Mbariete Past Plural Ariete Past Singular Table 2: Style information  Language: English  Ate [tense-past; number-any] 
It is apparent that both dictionaries are used to provide grammatical information, semantic data and potential equivalents in the target language during this stage.  Stage 4: Mapping At the mapping stage, the Source text is validated against all existing sequences trees in the language. Only the most complete and detailed tree is picked. From example 1 above, the most appropriate sequence tree will be as follows and illustrated in figure 2.   He ate a mango   Ri-embe a-rie-te [PN] + [V] + [Det] + [N] [N] + [V]                  Figure 2: Sequence tree  The elements in the source sequence will map exactly into the [N] + [V] sequence. At this point all the redundant guesses are eliminated and disambiguation occurs. There are more comparisons and checks - like subject and style checks, etc.   Stage 5: Apply Rules. The elements in the source sequence are modified by the corresponding sequence in the target language. The affixes are attached, or some new elements added or others completely deleted. Each element?s unique identity is used to map the source sequence to the equivalent target sequence identities. Remember that Ekegusii does not have determiners and therefore it is dropped. From the example above, the noun is then modified by adding the singular prefix- ri, (noun class 13) while the verb is modified by concatenating the subject- a (singular pronoun) to the verb- rie and finally adding the suffix- te (Past tense). The final sentence then becomes as shown below Riembe ariete -> ri-embe a-rie-te   In case it is converted to plural, the noun prefix will change to- ama (noun class 6) and the pronoun to- ba while maintaining the past tense suffix- te  
S 
Verb rie Noun embe 
70
 Amaembe bariete -> Ama-embe ba-rie-te Finally, the sentence word order is rearranged according to the best fitting sequence tree in the target language sequence table. 4. Results The results gotten so far are plausible. The word order is correct as per the programmed sequence rules for each language e.g. English: This is a book; Ekegusii. Eke n?egetabu; Kiswahili: Hiki ni kitabu. In addition, the bidirectional functionality is often more than 50% accurate on the wider domains and about 90% accurate on specific domains, in our case the obituary?s domain. This evaluation is based on phrase level. Besides, once a phrase text has been translated, it can also be used as the source text and the translator will yield the exact translation as the initial source text. This therefore makes a strong case for the high intelligibility of the system. The idea of storing only the word base forms and having a separate table for the affixes has drastically reduced the lexical database size as well as the building time. It was also noted that there is need for careful configuration of the rule units4 for the affixes and lexicon otherwise the translation will be inaccurate. If we are to use the example above, the canonical5 form will be as follows:  English: FID-144 Book [POS: N; Number: SG; Animation: No]. However, for Ekegusii, there is need for additional rules units to indicate the noun class6 because the nouns inflection is dependent on the noun class, otherwise the machine translator might concatenate the wrong prefix. Therefore, the English example above will be matched as follows. Ekegusii: FID-144 tabu [POS: N; Animation: No, EkeNC7: 8/9].   Consequently, the translator compares the rule units of the word with the rule units of the modifiers8 in the affixes table and picks the most matching affix,  in this case the prefix ?ege? [POS: N; Number: SG; Animation: No, EkeNC9:8/9], ensuing n  accurate translated word ?egetabu?. On the contrary, if the Ekegusii rule units were not added or wrongly configured, the translation will be bizarre e.g. ?Omotabu? which is an invalid Ekegusii name. In fact, the prefix                                                 4 A tag bearing any piece of grammatical data: part of speech, number contrast, gender, conjugation pattern, etc. 5 Base form of the word before any inflection 6 There are about 17 Ekegusii noun classes 7 Ekegusii Noun Class 8 In this case, Prefixes 9 Ekegusii Noun Class 
?omo? [EkeNC: 1] is often reserved for singular human10 nouns.  The results obtained also expound the diversity of Ekegusii language linguistic rules11 as compared to English. Most Indo-European languages, specifically English, espouse the SVO12 sentence structure rule. However, in Ekegusii both SVO and VOS rules are valid sentence structure rules. For example, English: Mum ate mangoes [SVO]. Ekegusii: 1.Omog?ina nariete amaembe [SVO]. 2. Nariete amaembe Omong?ina [VOS]. Interestingly, the Ekegusii sequence and grammar rules that were copied and pasted to Swahili with minimal alteration resulted in almost precise translations between the two languages. This inevitably affirms the similarity in the language structure of the two languages and the ease in defining, constructing and translating between local languages as compared to/or from English. The project demonstrations made so far to peers and students have generated a lot of enthusiasm in African languages research and given a good indication of the reception of technology in a familiar language platform. 5. Conclusion The InterlinguaPlus approach is good particularly for under-resourced languages in terms of generating rapid translations that give a good gist of the meaning in the second language. Although it takes some time to write the grammar rules for a new language at the beginning, it however takes a relatively shorter time when adding languages of similar grammatical makeup. Therefore, the approach is very feasible especially when considering under-resourced languages which may not be afforded the appropriate finances and sufficient political will to have technological resources built for them. The lexical database building methodology, whereby words and their grammatical data are stored in respective families and assigned a unique identification, provides an excellent way of reducing the chances of ambiguity that may exist in the phonetic disparities inherent in these local languages.   The InterlinguaPlus approach employed in the Carabao Open MT framework forms a good foundation to scale existing language resources                                                 10 Professions, etc. 11 Sequence and grammar rules 12 Subject, Verb, Object 
71
 to many other under-resourced languages using minimal effort i.e. the number of rules written for a language and consequently the time taken to develop a new language. 6. References Automatic Language Processing Advisory Committee (ALPAC). 1966. Languages and Machines: Computers in Translation and Linguistics. National Academy of Sciences, National Research Council, 1966. (Publication 1416).   Declan Groves, and Andy Way. 2006. Hybrid Data-Driven Model of MT. ttp://citeseerx.ist.psu.edu/showciting?cid=5495125 (Retrieved March 15, 2014)  Declan Groves. Bringing Humans into the Loop: Localization with Machine Translation at Trasl?n  http://citeseerx.ist.psu.edu/viewdoc/versions?doi=10.1.1.210.2867 (Retrieved March 15, 2014)  Edward Ombui, and Peter Wagacha. 2007. Machine Translation for Kenyan Local Languages. In Proceedings of COSCIT conference. Nairobi, Kenya.  Franz J. Och, and Hermann Ney. 2004. The Alignment Template Approach to Statistical Machine Translation. http://acl.ldc.upenn.edu/J/J04/J04-4002.pdf (Retrieved January 25, 2014)  
John W. Hutchins. 1993. Latest Developments in Machine Translation Technology: Beginning a New Era in MT Research. MT Summit (1993), pp. 11-34.  John W. Hutchins. 1994. Research Methods and System Designs in Machine Translation: A Ten-Year Review, 1984-1994. http://www.mt-archive.info/BCS-1994-Hutchins.pdf (Retrieved August 1, 2013)  Kenya National Bureau of Statistics (KNBS, 2009). Ethnic Affiliation http://www.knbs.or.ke/censusethnic.php. (Retrieved September 6, 2013)  National Language Policy Framework. 2003. Retrieved from the Department of Arts and Culture website of South Africa.  https://www.dac.gov.za/sites/default/files/LPD_Language%20Policy%20Framework_English_0.pdf   Sergei Nirenburg, Jaime Carbonell, Masaru Tomita, and Kenneth Goodman. 1992. Machine Translation: A Knowledge-Based Approach. http://acl.ldc.upenn.edu/J/J93/J93-1013.pdf (Retrieved November 22, 2013)  Vadim Berman. 2012. Inside Carabao: Language Translation Software for XXI Century. Retrieved from the LinguaSys website  http://www.linguasys.com/web_production/PDFs/InsideCarabaoWhitePaper.pdf.   
72
