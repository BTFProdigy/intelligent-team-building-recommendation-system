Proceedings of SPEECHGRAM 2007, pages 17?24,
Prague, Czech Republic, June 2007. c?2007 Association for Computational Linguistics
Dialogue System Localization with the GF Resource Grammar Library
Nadine Perera
Department of Man Machine Interaction
BMW Group Research and Technology
Munich, Germany
nadine.perera@bmw.de
Aarne Ranta
Department of Computing Science
Chalmers University of Technology
and Go?teborg University
Gothenburg, Sweden
aarne@cs.chalmers.se
Abstract
We present two experiments in the localiza-
tion of spoken dialogue systems. The do-
main of the dialogue system is an MP3 ap-
plication for automobiles. In the first expe-
riment, a grammar in Nuance GSL format
was rewritten in Grammatical Framework
(GF). Within GF, the grammar was extended
from two to six languages, giving a baseline
for semantically complete grammars. In the
second experiment, the German version of
this baseline GF grammar was extended with
the goal to restore the coverage of the origi-
nal Nuance grammar.
1 Credits
Part of this work was done under the TALK1 re-
search project, funded by EU FP6 [ref. 507802].
The Nuance grammar was written by Jochen
Steigner, Peter Poller, and Rosemary Stegmann. The
first GF experiment was made together with Bjo?rn
Bringert. The Spanish grammar was written to-
gether with Libertad Tansini.
2 Introduction
Spoken dialogue systems for cars emerged in the late
1990s with the appearance of advanced information
and communication systems. Driving a car is a clas-
sical visual manual task, as the driver should keep
his hands on the steering wheel and his glance on the
surrounding traffic and the street. Speech interaction
is very well-suited for secondary-level tasks such as
handling information and entertainment systems.
The current spoken dialogue system in
the automobiles of the BMW Group is a
1Tools for Ambient Linguistic Knowledge, www.talk-
project.org
Command&Control-based system (Hagen et
al., 2004). For the interaction with the entertain-
ment and information functions of the iDrive system
(Haller, 2003), the paradigm pursued is You-Can-
Speak-What-You-See, i.e. every menu item or
option that is shown on screen can be spoken.
The localization of that spoken dialogue system
for currently eight languages is done manually by
translators, without advanced automation methods
or special tools. The Command&Control-based
approach has its disadvantages, as the system can
only handle a fix set of commands. This makes
it difficult for system novices to interact with the
dialogue system because they may not know the
commands they need to say to reach their goal.
Advanced conversational dialogue systems that
allow a more flexible input and let the user decide
about the form and the amount of the communi-
cated information are being investigated. In order
to implement such a flexible spoken dialogue sys-
tem in the automobiles of the BMW Group, not only
one dialogue system, but at least eight would have
to be built - one for each language. The different,
localized versions of the system would have to be
designed in a way that allows for the generic ad-
dition of use cases, i.e. changes and additions to
the German grammar (which is viewed as the ini-
tial source grammar) must be ported to the localized
versions consistently and without the need to change
the whole localized grammar.
2.1 Grammar Writing
Linguistic experts who write grammars for compa-
nies whose focus is not in language technology usu-
ally have to possess profound technical competence
and programming skills in addition to linguistic ex-
pertise. For those grammar engineers who are com-
puter scientists or engineers with little university ed-
17
ucation in linguistics, a programming paradigm en-
abling them to avoid dealing with the morphologi-
cal inflection paradigms of several languages would
certainly be welcome. Writing consistent grammars
for multiple languages is quite challenging: Writing
one grammar requires the grammar engineer to be
at least a fluent speaker of the language the gram-
mar covers. If he also knows another language quite
well, he may be able to localize a grammar from that
language to his native language. This implies that
for every language which requires a localized gram-
mar, a person who knows the source language and is
a native speaker of the target language is needed. At
the moment, there is no commercial tool available
that helps grammar engineers with the localization
of spoken dialogue systems.
2.2 The Nuance SAMMIE grammar
Within the TALK project, an in-car spoken dialogue
system for the MP3 domain was created and inte-
grated into a BMW 3-Series Coupe (Becker et al,
2007). For the speech understanding component,
a German corpus named SAMMIE (SAarbru?cken
Multi-Modal Interface Experiment) was collected
by Saarland University and DFKI2 using a Wizard
of Oz experiment.
A grammar in Nuance GSL format was written to
specify well-formed sentences complying with the
corpus data. The GSL formalism is a variant of
BNF (context-free grammar), with Extended BNF
additions such as disjunctions and Kleene closures.
The grammar was structured according to syntacti-
cal motivations and interaction type coherence. To
minimize overgeneration, nonterminals were instan-
tiated with usual grammatical features. For instance,
genitive definite forms of artist expressions were
generated by the disjunction
NP_ARTIST_CASE_GEN[
(DET_NUM_SING_CASE_GEN_GEND_NEUT
N_ARTIST_NUM_SING_CASE_GEN_GEND_MASC)
(DET_NUM_SING_CASE_GEN_GEND_FEM
N_ARTIST_NUM_SING_CASE_DATIV_GEND_FEM)]
For a more detailed description of the grammar, see
(Becker et al, 2007).
The German Sammie grammar in Nuance for-
mat (NuanceGer) was checked and extended contin-
uously while the dialogue system was built. User
2German Research Center for Artificial Intelligence
evaluation results were analyzed and missing utter-
ances were added to the grammar. In addition to
that, an English version of the grammar, called ?Nu-
anceEng? here, was built by a near-native speaker of
English. This grammar is the starting point for our
experiments. Figure 1 shows a graph of the gram-
mar development for the first experiment, Figure 2
for the second experiment.
2.3 Outline of the paper
Section 3 gives an introduction to GF and its re-
source grammar library, by working through the im-
plementation of a fragment of the Sammie gram-
mar. Section 4 describes the first experiment, in
which a baseline Sammie grammar was ported to six
languages. Section 5 describes the second experi-
ment, in which the German grammar was extended
towards the coverage of the original grammar. Sec-
tion 6 concludes with statistics on the experiments,
related work, and some general lessons learnt.
3 Multilingual grammars in GF
GF (Grammatical Framework, (Ranta, 2004)) is a
grammar formalism based on ideas from type the-
ory and functional programming. Originally de-
signed for written technical documents, GF focuses
on language-independent semantic representations
and their multilingual renderings. These features
have proved useful in dialogue systems as well, and
a support for dialogue applications is completed by
translators from GF to various speech recognition
formats, such as Nuance (Bringert, 2007).
A grammar, in the sense of GF, has an abstract
syntax and a set of concrete syntaxes. The abstract
syntax is a semantic description of an application
domain. Each concrete syntax is a mapping of the
semantics into a language, typically a natural lan-
guage. To give an example from the GF implemen-
tation of the Sammie grammar, the abstract syntax
has objects such as
identify ( currently_playing_object )
The six concrete syntaxes map the abstract object
into the strings
vad heter den ha?r sa?ngen
wie hei?t dieses lied
comment s?appelle cette chanson
como se llama esta cancio?n
mika? on ta?ma?n laulun nimi
what is the name of this song
18
of Swedish, German, French, Spanish, Finnish, and
English, respectively.
The abstract syntax is specified by a set of cate-
gories (cat) and constructor functions (fun), in
the same way as an inductive family of datatypes in
a functional programming language. Here is a frag-
ment of the Sammie abstract syntax, with five cate-
gories and five constructor functions:
cat
Action ; ToIdentify ; Object ;
Playlist ; Artist ;
fun
create : Action ;
identify : ToIdentify -> Action ;
play : Object -> Action ;
remove : Playlist -> Object -> Action ;
currently_playing_object : ToIdentify ;
The concrete syntax is specified by defining a lin-
earization type (lincat) for each category, as
well as a linearization function (lin) for each con-
structor. A baseline concrete syntax can be obtained
by just assigning the type of strings to each category,
and defining:
lincat
Action, ToIdentify,
Object, Playlist, Artist = Str ;
lin
create = ["create a new playlist"] ;
identify x = x ;
play = "play" ++ x :
remove x y = "remove"++ y ++"from"++ x ;
currently_playing_object =
["what is the name of this song"] ;
A concrete syntax like this is essentially a system
of templates with chunks of canned text. While it
is easy to produce for small applications, it does
not scale up well, especially in languages that have
rich morphology and require agreement in syntactic
structures. Thus GF also supports user-defined pa-
rameter types, which can be used to control inflec-
tion and word order in linearization. For instance,
the German version of the above grammar needs a
type of Case, and the linearization of Object and
Playlist depends on case:
lincat
Object, Playlist = Case => Str ;
lin
remove x y = "nimm" ++ y ! Acc ++
"aus" ++ x ! Dat ++ "heraus"
3.1 The GF resource grammar library
Having to think about parameters requires linguis-
tic knowledge from the grammar writer. Moreover,
accurate descriptions tend to become long and com-
plex. The GF solution to this problem is a resource
grammar library. Like any software library, this
library can be used via a high-level API (an abstract
syntax for linguistic structures) that hides the im-
plementation details (the concrete syntaxes for each
language). The GF resource grammar library is cur-
rently available for 10?15 languages (10 languages
support the full API, 5 just parts of it). Its first ap-
plications were in the domain of written technical
language (Burke and Johannisson, 2005, Caprotti et
al., 2006), but its use was extended to spoken dia-
logue systems in the TALK project (Johansson 2006,
Ljunglo?f & al. 2006).
Let us rewrite the Sammie grammar fragment by
using the library,
lincat
Action = Phr ; -- phrase
ToIdentify = QS ; -- question
Object, Playlist,
Artist = NP ; -- noun phrase
lin
create = imperative (mkVP create_V2
(indef (mkCN new_A playlist_N))) ;
identify x = mkPhr x ;
play x = imperative (mkVP play_V2 x) ;
remove x y =
imperative (mkVP remove_V3 y x);
currently_playing_object =
mkQS whatSg_IP (mkNP name_N2
(mkNP this_Quant song_N)) ;
This grammar uses the language-independent
resource grammar API with categories such
as Phr, QS, NP and constructors such as
mkVP, indef, this_Quant. The ones
provided by the resource grammar are syntactic
combination rules and structural words, which are
independent of the domain of application.
In addition to the resource API ele-
ments, a concrete syntax also needs a lex-
icon of domain-specific words, such as
new_A, play_V2, remove_V3 above.
The resource library provides for each language
a set of operations for constructing lexical entries
with all morphosyntactic information they need.
Thus the three mentioned objects are defined as
follows in English:
new_A = regA "new" ;
play_V2 = dirV2 (regV "play") ;
remove_V3 = dirV3
(regV "remove") from_Prep ;
Here are the German definitions:
19
new_A = regA "neu" ;
play_V2 = dirV2 (regV "spielen") ;
remove_V3 = dirV3
(prefixV "heraus" nehmen_V) aus_Prep ;
The lexicon definitions are gathered into a separate
interface module, which the concrete syntax mod-
ule depends on. All that is needed to add a new lan-
guage to the system is a new implementation of the
interface module, with lexical entries belonging to
that language.
3.2 Beyond baseline grammars
A baseline multilingual grammar system can be
obtained by defining the syntax in a language-
independent way using the resource API, and only
letting the lexical entries vary from one language
to another. Such a system is guaranteed to be
grammatically correct, as regards to word order
and agreement. But the different languages of-
ten come out unidiomatic. For instance, the
above rule for currently_playing_object
produces the translations
vad a?r namnet pa? den ha?r sa?ngen
was ist der name von diesem lied
quel est le nom de cette chanson
mika? on ta?ma?n laulun nimi
what is the name of this song
These translations are OK for Finnish and English,
but very clumsy for the rest of the languages, which
have special verbs for expressing the name of a sub-
ject (the proper forms were shown above; the clos-
est corresponding English idiom is what is this song
called).
Fortunately, GF is a functional programming lan-
guage that permits functions, instead of just words,
to appear in an interface. An improved way to im-
plement the rule above is
lin currently_playing_object =
mkQS (what_name
(mkNP this_Quant song_N))
where the function what_name has different im-
plementations in different languages: here, for in-
stance, German and English:
what_name x =
mkQCl how_IAdv (pred hei?en_V x)
what_name x =
mkQCl whatSg_IP (mkNP (regN2 "name") x)
A similar refinement is needed in the GF Sam-
mie grammar to express imperatives. A baseline,
language-independent definition would be
imperative vp = UttImpSg vp
which produces the second-person singular impera-
tive form of a verb phrase. In German, as shown by
the corpus collected for Sammie, both the familiar
singular and the polite imperative are appropriate,
and should be accepted in user input. GF has the
variants construct to express such free variation:
imperative vp = variants {
UttImpSg vp ;
UttImpPol vp
}
When extending the different languages of the Sam-
mie grammar in GF, above the baseline, adding vari-
ants was the prominent method used.
3.3 Using GF in dialogue systems
In the TALK project, GF was used for building vari-
ous components of dialogue systems at three differ-
ent sites. The most relevant features of GF in this
work were the following:
? a common abstract syntax guarantees that the
same semantics is implemented for all lan-
guages
? the resource grammar library makes it easier to
port systems to new languages
? the GF grammar compiler supports the produc-
tion of many other formats from the GF source
The first two features have been covered in the pre-
ceding sections. The third feature, the grammar
compiler, is what in practice can integrate GF in the
work flow of different projects. Language models
for speech recognition are the most crucial formats
in dialogue systems. GF supports several such for-
mats, including the GSL format used in the Nuance
system, which in turn is used in the Sammie dia-
logue system. Porting the Sammie grammar to new
languages with GF would thus automatically pro-
duce the required speech recognition grammars.
4 The first experiment
The starting point of the work was Nuance-Sammie,
a pair of hand-written Nuance grammars used in the
Sammie system, one for English (NuanceEng) and
one for German (NuanceGer). The goal was to pro-
duce GF-Sammie, a GF grammar with the same cov-
erage as Nuance-Sammie, but for more languages.
20
This was to be produced by using the resource gram-
mar library, and share as much code as possible be-
tween the languages.
The experiment was aimed to test the hypotheses
that a grammar for basic communication is easy to
produce using the library; adding a new language
should be a matter of a few hours.
Figure 1: First experiment: The baseline grammar
development. The modules on the left are hand-
written Nuance grammars used in the Sammie sys-
tem. The module in the middle is a GF abstract
syntax defining the semantics implicit in the Nuance
grammars. The modules on the right are GF con-
crete syntaxes implementing the semantics in a min-
imal but complete way.
4.1 The phases of the work
Before the baseline grammar, an abstract syntax
must of course be produced. It was written by Bjo?rn
Bringert on the basis of NuanceEng, which was
richly commented with information indicating what
actions should be covered by the grammar. The ab-
stract syntax was produced in five hours, which in-
cludes the work needed to write a string-based En-
glish concrete syntax to test the abstract syntax.
To prepare for a multilingual localization, the
string-based English concrete syntax was first glob-
alized by rewriting it in terms of the recource gram-
mar API and moving lexical items and some other
obviously English-dependent constructs to an inter-
face. This work took two hours.
After the globalization, the grammar was local-
ized by writing new instances of the interface. This
was done for Swedish, Finnish, French, and Ger-
man. The work took half an hour for each language.
Did we now have a satisfactory baseline gram-
mar for five languages? This was tested by gen-
erating sentences in all languages, and led to some
fine-tuning to get satisfactory (grammatical and id-
iomatic) results. But now we did have a grammar
that permitted user input in five languages, with the
same semantics as NuanceEng, but with more lim-
ited variation in expressions. Spanish was added
later to the system. Summary of the time consump-
tion for this work is as follows:
? abstract syntax and string-based English: 5h
? globalized English by use of resource API: 2h
? five new languages: 5h
A baseline grammar, as we have defined it, covers
the abstract syntax with a minimal, grammatically
correct and stylistically acceptable concrete syntax.
Such a grammar can be used for communication by
users who are willing to learn to speak in a certain
way. Notice that this can still be richer than a Com-
mand&Control system, because the dialogue man-
ager is based on the language-independent abstract
syntax and works quite as well with a minimal con-
crete syntax.
The next phase was to grow the coverage of one
of the baseline grammars, SammieGer Baseline, to
match the corpus defined by NuanceGer. This work
was expected to take a few days, as carried out by a
non-linguist programmer who first had to learn GF.
5 The second experiment
As expected, the SammieGer Baseline grammar
covered less user utterances than the NuanceGer
grammar. The purpose of our experiment was to find
out how much time and effort a GF-novice grammar
engineer needed to extend the SammieGer Baseline
grammar to match the coverage of the NuanceGer
grammar. The top level grammars involved can be
seen in Figure 2.
Figure 2: Second experiment: The SammieGer
Baseline was extended to SammieGer Extended, to
match the coverage of the original NuanceGer.
21
5.1 Experimental plan
For the extension of the SammieGer Baseline gram-
mar, we were in the fortunate position of already
having a grammar at hand that defined the termi-
nal symbols and the grammar rules which the Sam-
mieGer Extended grammar would have to include.
We planned the extension experiment in the follow-
ing way: Comparing the coverage of SammieGer
with the original NuanceGer grammar by generating
sentences from the Nuance grammar and checking
if they are covered by the GF grammar. If a gener-
ated sentence is grammatically correct but contains
words that are missing in the lexicon, the GF lexicon
has to be extended. If the syntactic structure is not
covered, the concrete syntax has to be extended, and
if the semantic structure of the sentence is missing
in the abstract grammar, it has to be added.
5.2 Adding words to the lexicon
Before generating sentences from the NuanceGer
grammar, we started with a simple word count. The
NuanceGer grammar contained 463 single words,
counting all inflected forms of the same stem indi-
vidually. The SammieGer Baseline grammar con-
tained 100 words, so it was clear that our first action
had to be the extension of the SammieGer lexicon.
Wherever this was possible using the variants con-
struct (cf. Section 3.2), i.e. when adding a word that
is a synonym of a word which was already modeled
in the SammieGer grammar, this was most comfort-
able. 46 words could be added in this fashion, this
time counting morphological infinitive forms that
added more than one inflected form to the grammar.
In fact, the 46 infinitive forms extended the word
count to 215, so that the adding of 46 infinitives ex-
tended the grammar by 115 inflected word forms.
Some of these words had to be added because
the starting point for the SammieGer Baseline gram-
mar was in fact an English (NuanceEng) grammar.
When translating from German to English, some
words got lost, for instance, the words ?Sa?nger? and
?Sa?ngerin? united to the word ?singer? in English,
as there is no gender distinction in English. The
word ?Sa?ngerin? is missing in the SammieGer Base-
line grammar, as ?Sa?nger? only becomes translated
to ?singer?.
Another source of words are verbs with their re-
spective removable prefixes. German is rich in pre-
fixes that can be combined with verbs to gain new
meanings, for instance ?an-gehen?, ?auf-gehen?,
?aus-gehen? [...], which are all related verbs shar-
ing word stem and inflection paradigms, but each
mean something else. These prefixes can be severed
from the verb in certain utterances, and fortunately,
GF accounts for that. By extending play V (cmp.
above) to:
play_V2 = variants {
dirV2 (regV "spielen") ;
dirV2 (prefixV "ab" (regV "spielen"))
} ;
the extended grammar is able to parse an utterance
like ?spiele einen Titel von U2 ab? (?play a title by
U2?), as well as an utterance without the ?ab? in the
end. The linearization rules in GF place the severed
prefix in the syntactically correct position.
There were also words missing from the Sam-
mieGer Baseline grammar that could not be included
with a simple variants construct. They were added to
the lexicon under new identifiers and integrated into
the concrete grammar by writing new linearization
rules. In order to accomodate some of the missing
words, new abstract syntax rules had to be defined.
5.3 Adding rules to the concrete grammar
One example of additions to the concrete syntax are
the rules for interrogative and infinitive forms. Ut-
terances follow certain patterns which are also re-
flected in the NuanceGer grammar (see Table 1 for
an overview). In the Baseline SammieGer, only
the imperative construct was modeled. The detour
we took in localizing the system over English ac-
counts for one missing utterance type: the infinitive
and the imperative type are identical in English, but
not in German. The interrogative forms are phrased
like questions, but contain an implicit but politely
expressed imperative. We managed to include the
other utterance types by adding four rules to the con-
crete SammieGer grammar and renaming rule iden-
tifiers in one referenced library grammar.
5.4 Adding rules to the abstract grammar
Some user intentions modeled in the NuanceGer
grammar were missing in the abstract SammieGer
Baseline grammar, for instance scrolling a list pre-
sented on the screen up or down. These additions
22
Table 1: Utterances Types. The types of user utterances for German and English. Note that the imperative
and the infitive forms in are the same in English, but not in German.
Type German Example English Example
Imperative Spiele Vertigo von U2. Play Vertigo by U2.
Interrogative Kannst du Vertigo von U2 spielen? Can you play Vertigo by U2?
Indicative Ich mo?chte Vertigo von U2 ho?ren. I want to listen to Vertigo by U2.
Infinitive Vertigo von U2 spielen. Play Vertigo by U2.
took one day to accomplish. Summary of the time
needed for the grammar extension is as follows:
? Installing and learning GF: 4 days
? Adding words: 3 days
? Adding concrete syntax rules: 3 days
? Adding abstract syntax rules: 1 day
6 Results
In this section, we compare the SammieGer Base-
line/Extended and the NuanceGer grammar.
The goal set for the first experiment to build pro-
totypical grammars for six languages was fulfilled
quite successfully. However, the aim of the second
experiment to match the coverage of the NuanceGer
grammar with the SammieGer Extended grammar
was not reached as quickly as we had hoped. It
took a substantial time for the programmer to learn
GF well, and the the development cycle was slowed
down by fairly long compilation times. The resource
library was difficult to navigate and contained some
bugs that were fixed during the experiment, which
caused waiting time. Nevertheless, the SammieGer
Extended grammar?s coverage increased consider-
ably compared to SammieGer Baseline. Moreover,
most of the extensions made to the German gram-
mar can be ported to the other languages with very
little work, due to the common resource library API.
6.1 Statistics
The original German grammar NuanceGer was writ-
ten in approximately 18 days. In the GF experi-
ments, 12 hours were needed to create the six base-
line grammars from the NuanceEng original, and
about 7 days for the SammieGer Extended grammar
(not counting the time needed for installation and
learning to use GF). If we sum up the SammieGer
Baseline and the SammieGer Extended grammar
writing time, we end up with 8 days for the Sam-
mieGer combined. This is faster than the 18 days
spent on the original NuanceGer grammar, but we
had of course the advantage of already having Nu-
anceGer available: its authors had to start from
scratch and continuously add words and rules af-
ter user evaluations. Moreover, the full coverage
of NuanceGer was not reached, mostly because of
colloquial forms of speech that were not covered by
the resource library. Statistics of the coverage of the
three grammars (SammieGer Baseline, SammieGer
Extended, and NuanceGer) can be seen in Table 2.
6.2 Related work
The idea of generating speech recognition gram-
mars from higher-level formats was first imple-
mented in the Regulus system (Rayner et al, 2006).
The source format of Regulus is a unification-based
grammar formalism, and the target is GSL (the for-
mat used in Nuance); GF supports many other for-
mats as well, such as the SLF format used in HTK
(Young et al, 2005); see (Bringert, 2007). Regulus
also has a resource grammar library currently cover-
ing five languages.
GF was previously used for dialogue system lo-
calization in the TALK project, where seven lan-
guages were covered (Johansson, 2006, Ljunglo?f et
al., 2006).
6.3 Conclusion
GF provides elegant solutions for many grammar
writing challenges. Based on the concept of one ab-
stract and many concrete grammars for different lan-
guages, GF is well-suited for localization tasks and
fast prototyping in multiple languages. One disad-
vantage of GF is that it is quite difficult to get a grasp
23
Table 2: Statistics of SammieGer Baseline, SammieGer Extended, and the original Nuance.
Grammar Baseline Extended Original
top-level constructors 18 23 ?23
syntactic categories 17 17 419
German - specific source code 4kB 18kB 200kB
German + generic source code 14kB 33kB 200kB
Nuance code 18kB 31kB 200kB
distinct words 100 325 463
of the framework quickly, compared to the concept
of a context free grammar format in BNF or EBNF
form which is easier to understand, for computer sci-
entists as well as for linguists. As GF is more of
a programming language than a grammar format, it
implements much more constructs than BNF, which
also makes it more powerful. That power can be
seen in the comparison of source code size between
NuanceGer and SammieGer Extended in Table 2.
The elegance of the many resource files that hide
the complexity leads to difficulties in error detection,
as there is a tree of resource grammars referencing
other grammars and to the novice programmer, it is
not always transparent where an error occurred. This
is of course a problem with all high-level program-
ming languages using libraries. A more intuitive
IDE and faster compilation times could improve the
system?s usability significantly.
Grammatically correct utterances can be modeled
nicely in the GF resource grammar library, which
also eliminated some of the grammatical errors
present in the original hand-coded Nuance grammar.
However, some spoken language oriented rules were
not covered by the library, and were implemented
by brute force by using strings in GF. In this expe-
riment, the resource grammar was taken as it was
(apart from bug fixes), and no new functions were
added to it.
References
T. Becker, N. Blaylock, C. Gerstenberger, A. Korthauer,
N. Perera, M. Pitz, P. Poller, J. Schehl, F. Steffens, R.
Stegmann, and J. Steigner (Editor). 2007. TALK De-
liverable D5.3: In-Car Showcase Based on TALK Li-
braries.
B. Bringert. 2007. Speech Recognition Grammar
Compilation in Grammatical Framework. SPEECH-
GRAM 2007, Prague, 29 June 2007.
D. Burke and K. Johannisson. 2005. Translating For-
mal Software Specifications to Natural Language / A
Grammar-Based Approach. P. Blache, E. Stabler, J.
Busquets and R. Moot (eds). Logical Aspects of Com-
putational Linguistics (LACL 2005). LNCS/LNAI
3407, pages 51?66.
O. Caprotti. 2007. WebALT! Deliver Mathematics Ev-
erywhere. Proceedings of SITE 2006. Orlando March
20-24.
E. Hagen, T. Said, and J. Eckert. 2004. Spracheingabe
im neuen BMW 6er. ATZ.
R. Haller. 2003. The Display and Control Concept
iDrive - Quick Access to All Driving and Comfort
Functions. ATZ/MTZ Extra (The New BMW 5-
Series), pages 51?53.
A. Ranta. 2004. Grammatical Framework: A type-
theoretical grammar formalism. Journal of Functional
Programming,14(2):145?189.
M. Johansson. 2006. Globalization and Localization of
a Dialogue System using a Resource Grammar. Mas-
ter?s thesis, Go?teborg University.
P. Ljunglo?f, G. Amores, R. Cooper, D. Hjelm, O. Lemon,
P. Mancho?n, G. Pe?rez, and A. Ranta. 2006. Multi-
modal Grammar Library. TALK Talk and Look: Tools
for Ambient Linguistic Knowledge IST-507802 Deliv-
erable 1.2b
M. Rayner, P. Bouillon, B. A. Hockey, and N.
Chatzichrisafis. 2006. REGULUS: A Generic Mul-
tilingual Open Source Platform for Grammar-Based
Speech Applications. In Proceedings of LREC, 24-26
May 2006, Genoa, Italy.
S. Young, G. Evermann, M. Gales, T. Hain, D. Kershaw,
G. Moore, J. Odell., D. Ollason, D. Povey, V. Valtchev,
and P. Woodland. 2005. The HTK Book (for HTK Ver-
sion 3.3). Cambridge University Engineering Depart-
ment.
24
XML and Multilingual Document Authoring: Convergent Trends 
Marc l )ymctman Veronika Lux  
Xerox  Research  Centre Europe 
6, chemin  de Maupertu is  
38240 Meylan,  France 
{ dymetman, lux  } @xrce .xerox .com 
Aarne Ranta  
Depar tment  of  Comput ing  Science 
Chahners  Univers i ty  of  Techno logy  
and GOteborg Univers i ty  
S-412 96 GOteborg,  Sweden 
aarne @ cs.chahners,  e 
Abstract 
Typical al)proaches to XML authoring view a XML doc- 
urnent as a mixture of structure (the tags) and surlhce 
(texl between the tags). We advoeale a radical approach 
where the surface disappears from lhe XML documenl 
altogether to be handled exclusively by rendering mech- 
anisms. This move is based on the view that the author's 
choices when authoring XML docutnciHs are best seen 
as language-i~eutral semantic decisions, that lhe SlftlC- 
lure can then be viewed as inlerlingual content, and that 
the textual oulpul  should be derived from this co)lien\[ by 
language-sl~ecific realization mechanisms, lhus assimi- 
lating XML aufllol'ing lo Mullilingual Document Amhof  
ing. However, slandard XMI, tools have imporlant lhni- 
tations when used for such a ptu'pose: (1) they are weak 
at propagating semanlic dependencies belween dil'ferenl 
parts of the st,'ucture, and, (2) current XMI. rendering 
tools are ill-suited for handling the grammatical combi- 
nation of lextual units. We present two relalcd proposals 
for overcoming these limitalions: one (GI:) origitmting 
in the Iradilion of malhemalical proof edilors and con- 
slruct ivc type lhcery,  the other  (IG), a special i?at ion o f  
l)elinite Clause (_\]ranllllars strongly inspired by (iF. 
1 Introduction 
The typical al3pl'oacll to XML authoring views an XML 
doctmlcnt as a mixture of wee-like strttctttre, expressed 
througll balanced labelled parentheses (tim lags), and 
of sul:face, expressed llu'ough free lexi interspersed be- 
tween lhe tags (PCI)ATA). A l)octunent Type l)elini- 
lion (DTD) is roughly similar to a coiitext-free gram- 
mar j with exactly one predelined terminal. It delines a 
set o1' well-formed structures, (hat is, a la,guage over 
trees, where each nonterminal node can dominate ither 
the empty string, or a sequence of occurrences of nonter- 
minal nodes and of 111o terminal node pcdata. The ter- 
minal pcdata  has a specM status: it can in turn dominate 
any characler string (subjecl to certain reslrictions on the 
characters allowed). Authoring is typically seen as a top- 
down interactive process of step-wise refinement of the 
root nonterminal (corresponding to the whole document) 
where the aulhor  ileratively chooses arule for expanding 
IBu( see (l'rescod, 1998) lbr an inleresfing discussion oflhe differ- 
enccs. 
a nonlerminal aheady present in the tree, 2 and where in 
addition the author can choose an arbitrary sequence of 
characters (roughly) for expanding lhe pcdata  node. 
One can observe the following trends in the XML 
world: 
A move towards more typing of the surface: 
Schemas (W3C, 1999a), which are an inlluemial 
proposal for the ieplacenlent of I)TD's, provide for 
types such as f loat ,  boolean, uri, etc., instead o\[" 
the single type pcdata; 
A move, aheady constitulive of the main lmlpose 
of XMl, its opposed l(1 HTML for instance, towards 
clearer separation between content and form, where 
the original XML document is responsible for con- 
lent, and powerful styling lnechanisms (e.g. XSI.T 
(W3C, 1999b)) are available for rendering 111o doc- 
tlll/en\[ \[o lhe end-user .  
We advocate an approach in which these two moves 
are radicali?cd in tile folk)wing ways: 
Strongly typed, surface-free XML documents. The 
whole content of the document is a trcc whore each node 
is labelled and typed. For inlernal nodes, lhe lype is just  
the usual nonierminal name (or category), and Ille label 
is a name for the expansion chosen for this nonlernfinal, 
lhat is, an identifier of which rule was chosen to expand 
ibis nonterminal. For leaves, lhe type is a semanlically 
specilic category such as Integer, Animal, etc., and lhe 
label is a specilic concept of this type, such as three or 
dog)  
Styling responsible for producing tim text itself. 
The styling mechanisnl is not only responsible for ren- 
dering the layout of the lext (typography, order and pre- 
sentation of lhe elements), but also for producing the text 
itse!ffrom 111o document content. 
What are (he motiw~tions behind this proposal? 
Autlmring choices carry language-independent 
meaning. First, let us note that lhe expansion choices 
2We arc ignoring here tl~e aspecls of lhis process relating to lhe 
regular ,mlure of Ihe righ(-halld sides of rules, but Ihese parliculars are 
uncssenlial lo the nlaill g:lfgtllllOnl. 
3Note Ihat lnlcgcr is of"logical type" e, whereas Animal is of log- 
ical lype (c, t): lhe,'c is no reslriction on lhe denotalional s alus of 
leaves. 
243 
<!ELEMENT R isk  (Caut ion  I Warn ing)  > r i sk - ru le l :  R i sk  --> Caut ion  
r i sk - ru le2 :  R i sk  --> Warn ing  
<!ELEMENT Caut ion  ( . . .  I . . .  I . . .  ) > caut ion - ru le l :  
caut ion - ru le2 :  
caut ion - ru le3 :  
Caut ion  --> .., 
Caut ion  --> ... 
Caut ion  --> ... 
Figure 1 : Context-flee rules (shown on the right) corresponding to the aircraft DTD (shown on the left); for illustration 
purposes, we have assumed that there are in turn three semantic varieties of cautious. The rule identitier on the left 
can be seen as a semantic label for each expansion choice (in practice, the rule identifiers are given mnemonic names 
directly related to their meauing). 
made during the authoring of an XML document gener- 
ally carry language-independent meaning. For instance, 
the DTD for an aircraft maintenance manual might be 
legally required to distinguish between risk instructions 
of two kinds: caut  ion (risk related to material damages) 
and warn ing (risk to the operator). Or a D~'I) describing 
a personal list of contacts might provide a choice of gen- 
der (male, female) ,  title (dr, p ro f ,  de fau l t ) ,  country 
(ger, fra,...), etc. Each such authoring choice, which 
formally consists in selecting among different rules for 
expanding the same nonterminal (see Figure 1), corre- 
sponds to a semantic decision which is independent of 
the language chosen for expressing the document. A 
given DTD has an associated expressive space of tree 
structures which fall under its explicit control, and the 
author is situating herself in this space through top-down 
expansion choices. There is then a tension between on 
the one hand these cxplicitely controlled choices, which 
should be rendered differently in different languages 
(thus ger  as Germany, Allemagne, Deutschland .... and 
Warning by a paragraph starting with Warnillg! ...; At- 
tention, Danger! ...; Achtung, Lebensgefahr! ...), and 
on the other hand the uncontrolled inclusion in the XML 
document of free PCDATA strings, which are written in 
a specific language. 
Surface-fi'ce XML documents. We propose to com- 
pletely remove these surface strings from the XML doc- 
ument, and replace them with explicit meaning labels. 4
The tree structure of the document then becomes the sole 
repository of content, and can be viewed as a kind of in- 
terlingua for describing a point in the expressive space 
of tile DTD (a strongly domain-dependent space); it is 
then the responsability of the language-specific rendering 
mechanisms to "display" such content in each individual 
language where the document is needed. 
XML and Multil ingual Document Authoring. In 
this conception, XML authoring has a strong connection 
to the enterprise of Multilingual Document Authoring in 
which the author is guided in the specilication of the 
document content, and where the system is responsible 
4There are autlmring situations in which it may be necessary for 
the user to introduce new selllalllic labels eorleSl)onding lo expres- 
sive needs not foreseen by lhe creator of the original I)TD. To handle 
such situations, it is useflfl to view the l)TI)'s as open-ended objecls 1o 
which new semantic labels and types can be added at authoring time. 
for generating from this content extual output in several 
languages imultaneously (see (Power and Scott, 1998; 
Hartley and Paris, 1997; Coch, 1996)). 
Now there are some obvious problems with this view, 
due to the current limitations of XML tools. 
Limitations of XML for multilingual document au- 
thoring. The first, possibly most serious, limitation 
originates in the fact that a standard DTD is severely re- 
stricted in the semantic dependencies it can express be- 
tween two subtrces in the document structure. Thus, if 
in the description of a contact, a city of residence is in- 
cluded, one may want to constrain such an information 
depending on the country of residence; or, in the air- 
craft maintenance manual example, one might want to 
automatically include some warning in case a dangerous 
chemical is mentioned somewhere lse in the document. 
Because DTD's are essentially ofcontcxt-fi'ce expressive 
power, the only communication between a subtree and its 
environment has to be mediated through the name of the 
nonterminal rooting this subtree (for instance the nonter- 
minal Country) ,  which presents a bottleneck to informa- 
tion ilow. 
The second limitation comes fi'om the fact that the cur- 
rent styling tools for rendering an XML document, such 
as CSS (Cascading Style Sheets), which arc a strictly 
layout-oriented language, or XSLT (XSL transformation 
language), which is a more generic tool for transforming 
an XML document into another one (such as a display- 
oriented HTML file) are poorly adapted to linguistic pro- 
cessing. In particulm, it seems difficult in such for- 
malisms to express uch basic grammatical facts as ntun- 
ber or gender agreement. But such problems become 
central as soon as semantic elements corresponding to 
textual units below the sentence level have to be com- 
bined and rendered linguistically. 
We will present two related proposals for overcom- 
ing these limitations. The first, the Grammatical Frame- 
work (GF)(Ranta, 2000), originates in constructive type- 
theory (Martin-L6f, 1984; Ranta, 1994) and in mathe- 
matical proof editors (Magnusson and Nordstr6m, 1994). 
The second, h~teraction Grammars (IG), is a specializa- 
tion of Definite Clause Grammars trongly inspired by 
GF. The two approaches present certain lk)rmal differ- 
ences that will not be examined in detail in this papeh 
244 
but they share a number of important assumptions: 
? The semantic representations are strrmgly O'ped 
trees, and rich dependencies between subtrees can 
be specilied; 
? The abstract tree is independe,lt of tile different ex- 
tual realization hmguages; 
? Tim surface realization in each language is obtained 
by a semalltics-driven compositional process; that 
is, the surface realizations are constructed by a 
bottom-up recursive process which associates ur- 
face realizations to abstract ree nodes by recur- 
sively combining the realizations of daugthcr nodes 
to obtain the realization of the mother node. 
? The grammars are revelwible, that is, can be used 
both for generation and for parsing; 
? The authoring process is an interactive process 
of repeatedly asking the author to further specify 
nodes in the absmlct ree of which only the type is 
known at the 1)oint of interacti(m (tyFe re/itlemeHt). 
This process is mediated througll text in the lan- 
guage of the author, showing the types t(5 be relined 
as specially highlighted textual units. 
2 GF  ~ the  Grammat ica l  F ramework  
The Grammatical Framework (GF; (Ranta, 2000)) is a 
special-purpose programming hmguage combining co~z- 
strttctive type thee O, with an annotation hmguage for 
concrete syntax. A grammar, in the sense of GF, delines, 
on one hand, an abstract s3,1ttax (a system of types and 
typed syntax trees), and on the other hand, a mapping {51 
tile abstract syntax into a co,icicle sy, tta.v. The abstract 
syntax has cotCtlot 3, declarations, uch as 
cat  Count ry  ; ca t  C i ty  ; 
and combinator (orfttnctiolO dechuations, uch as 
fun Get : Country ; fun Fra : Country ; 
fun Ham : C i ty  ; fun Par : C i ty  ; 
fun cap : Country -> C i ty  ; 
The type of a combinator can be either a basic type, such 
as the type C i ty  of the combinator Ham, or a function 
type, such as the type of the combinator cap. Syntax 
trees formed by combinators of functioll types are con> 
plex functional terlns, such as 
cap Fra 
of type City. 
"file concrete syntax part of a GF grammar gives lit~- 
earization rules, which assign strings (or, in general, 
more complex linguistic objects) to syntax trees. For the 
abstract syntax above, we may lmve 
fin Ger = "Germany" ; f in Fra = "France" ; 
l in Ham = "Hamburg" ; l in Par : "Paris" ; 
lin cap Co = "the capita l  of" ++ Co ; 
Thus tile linearization of cap Fra is 
the capital  of France 
2.1 GF inXMI ,  
Functional terms have a straightforward encoding in 
XML, l'el~resenting a term of tile forna 
.\[ (11  . . .  ( I ,~  
by the XML object 
<J'> ct', . . .  a',, < / f> 
where each e~ is tile encoding of a i. In this encoding, 
cap Fra is 
<cap> 
<Fra> 
</Fra> 
</cap> 
Tile simple encoding does not pay attention to the 
types (51' the objects, and has no interesting DTI). To 
express type distinctions, we will hence use a slightly 
more complicated representation, i  which the category 
and combinator declarations of GF are represented as 
DTDs in XML, so that GF type dlecking becomes equiv- 
alent ,a, itll XML validatiom The represelm~tion f the GF 
grallllllaf o1' tile previous ection is tile DTI) 
<!ELEMENT Country (Ger \[ Fra)  > 
<!ELEMENT Get EMPTY > 
<!ELEMENT Fra EMPTY > 
<!ELEMENT City (Ham I Par I (cap,Country))> 
<!ELEMENT Ham EMPTY > 
<!ELEMENT Par EMPTY > 
<!ELEMENT cap EMPTY > 
In this DTD, each category is represented as an EI,E- 
MENT dclinition, listing all combinators producing trees 
of that category. The combinators themselves are repre- 
sented as EMPTY elements. The XML representation f 
the capital (51' France is 
<City> 
<cap /> 
<Country> 
<Fra /> 
</Country> 
</City> 
which is a wdid XML object w.r.t, tile given DTD. 
The latter encoding of GF in XML enjoys two impor- 
tant properties: 
? All well-typed GF trees are represented by valid 
XML objects. 
? An XML represents a unique GF tree. 
The tirst property guarantees that type checking in the 
sense of GF (and type theory) can be used for validation 
of XML objects. The second property guarantees that GF 
objects can be stored in tim XML format. (The second 
property is already gt, aranteed by tile simpler encoding, 
which ignores types.) 
()ther prope,'ties one would desire are the followillg: 
245 
? All valid XML objects represent well-typed GF 
trees. 
? A DTD represents a unique GF abstract grammar. 
These properties cannot be satislied, in general. The rea- 
son is that GF grammars may contain dependent types, 
i.e. types depending on objects. We will retnrn to this 
notion shortly. But let us first consider the use of GF for 
nmltilingual generation. 
2.2 Multilingualgeneration i GF 
Multilingual generation i  GF is based on parallel gram- 
mars': two (or more) GF grammars are parallel, if they 
have the same abstract syntax. They may differ in con- 
crete syntax. A grammar parallel to the one above is de- 
fined by the concrete syntax 
param Case = hem \[ gen ; 
oper noml : Str -> Case => Str = 
ks -> tbl {{nom} => s, {gen} -> s+"n"} ; 
oper nom2 :S t r  -> Case => Str 
ks -> tbl 
{{nom} => s+"ki", {gen} -> s+"gin"} ; 
l incat Country = Case => Str ; 
l incat City = Case => St r ;  
lin Ger = noml "Saksa" ; 
lin Fra = noml "Ranska" ; 
lin Ham = noml "Hampuri" ; 
l in Par = noml "Pari isi" ; 
l in cap Co = 
tbl {c => Co!gen ++ 
nora2 "p~iikaupun" ! c} ; 
This grammar renders GF objects in Finnish. In addition 
to linearization rules, it has rules introducing parameters 
and operations, and rules detining the linearization O,pes" 
corresponding to basic types: the linearization type el' 
Country, for instance is not just string (Str), but a func- 
tion fl'om cases to strings. 
Not only the linearization rules proper, but also param- 
eters and linearization types wwy a lot fl'om one hmguage 
to another. In our example, we have the paralnetre of ease 
with two values (in larger granunars for Finnish, as many 
as 16 may be required!), and two patterns for inflecting 
Finnish nouns. The syntax tree cap Fra produces the 
strings 
Ranskan p~fikaupunki 
Ranskan p~kaupung in  
which are the nominative and the genitive form, respec- 
tively. 
2.3 Del)endent types 
DTDs in XML are capable of representing simple types, 
i.e. types without dependencies. Even a simple type sys- 
tem can contribute a lot to the semantic ontrol of doc- 
uments. For instance, the above grammar permits the 
formation of the English noun phrase 
the capital  of France 
but not of 
the capital  of Paris 
Both of these expressions would be well-formed w.r.t. 
an "ordinary" granunar, in which both France and Paris 
would be classitied simply as noun phrases. 
Dependent types are types depending on objects of 
other types. An example is the following alternative dec- 
laration of Country and City: 
cat Country ; cat City (Co:Country) ; 
Under tiffs definition, there are no objects of type City 
(which is no longer a well-formed type), but of types 
City Ger and City Fra. Tlms we define e.g. 
fun Ham : City Ger ; fun Par : City Fra ; 
fun cap : (Co:Country) -> City Co ; 
Observe the use of the variable Co in the type of the com- 
binator capital: the variable is bound to the argument 
type and then used in the value type. The capital of a 
country is by definition a city of the same country. This 
involves a generalization o1' function types with depen- 
dent types. 
Now consider a simplified format ()f postal addresses: 
an address is a pair of a country and a city. The GF rule 
is either 
fun addr : Country  -> C i ty  -> Address ; 
i i n  addr  Co C = C ++ " , "  ++ Co ; 
using simple types or 
fun addr : 
(Co:Country)  -> C?ty Co -> Address ; 
&in addr  Co C = C ++ " , "  ++ Co ; 
using dependent types. The invalid address 
Hamburg, France 
is well-typed by the former definition but not by the lat- 
ter. Using the laUer delinition gives a simple mechanism 
of semantic ontrol ot' addresses. The same idea can ob- 
viously be exlended to full addresses with street names 
and numbers. Such dependencies cannot, however, be 
expressed in DTDs: both of the address rules above cor- 
respond to one and the same ELEMENT definition, 
<!ELEMENT Address (addr, Country, City) > 
This example 
enoughlbr GF 
<Address> 
<addr /> 
<Country> 
<Fra /> 
</Country> 
<City> 
<Ham /> 
</City> 
</Address> 
also shows Illat XML validity is not 
well-formedness: the object 
246 
is valid w.r.t, the DTD, but the corresponding Ot-; object 
addr  Fra  ttam 
is not well-typed. 
2.4 Computation rules 
In addition to categories and cornbinators, GF grammars 
may contain definitions, uch as 
def  cap Fra  = Par ; 
Definitions belong to the abstract syntax. They define 
a normal form for syntax trees (recursively replace de- 
fienda by definientes), as well as a paraphrase relation 
(sameness of normal tbrm). These notions are, of course 
reflected in the concrete syntax: the addresses 
the capital of France, France 
Par i s ,  F rance  
are paraphrases, and the latter is the normal form of the 
former. 
= . . . .  - - , -  , - - -  1 
\[U"e m IE'~i ml~w ml?pu?i's ~lum= ~J II 
 Nll 
I\[ "''~ ~ ~ ~ I / l l  
I I ~h~1- ~ul~f  ~ / / 1 1  
I I  lt'~eore~. Fc? aH numbers ?, there e?ists a rtlOcer u ' such I / /11 
I I  ~hat ~.L~ ~,~n~ U~ ,,'. ~-o~f. C~-.id~. ~,~'bitr ,  a~u I / /  
11 nuliJer x. '?z3re<~? . Ik.nce, "for' a l l  r i J~2rs ~, there ex is ts  a I l l  II 
l i  ~-,4,c,r'e~. Pot  tous lore rBc~hoes ;4. i l  e~i~te ~.~mbre  ~: ' .~ \ [ / I1  
j \ [  x ,  ~ r~. ,  ~.111~\] (~  t~.: n~',-~, ~- ~ ~-ooql II//1/ 
I\[ m~oon L~,u:~oUil l  " " t~- (~-  n~, u =(~.'ql II j i l l  
I I  e t~oH lukux~ik4} l  . . . . . .  I . . . . . . . .  . v .  I I I l l / I t  
I \[ <Text > crh,ua~w,-o411 ~,~. (, ,:- \[~, r,, q I I I l l / I /  
I I <Pr*~> <E--:ist/> <0c~ll E~t , / i ' .  ~ -_ ~ , ,  ~-_ (~ =11 I I IM II 
</Prop> <~r'oo> </ @tEll _ . . 
I . . . .  ta ~ ~_l~m H 
, .................................... Ill.,,,  411Lt 
?~a ~ Proof (Exist  !lat (','..'>:' q l l?l . l  0:~s~ r,, s: ~" ~ ' ,~  tl I i i-\]1t 
-- ~iI1_:_'. ~ ,_ t%: t~:F??~) \ ] l l l~  
Figure 2: GF session for editing a mathematical proof 
text. 
2.5 GF editing tools 
An editing tool has been implemented for GF, using 
metavariables to represent yet undefined parts of expres- 
sions. The user can work on any metavariable, in various 
different ways, e.g. 
? by choosing a combinator f om a menu, 
? by entering a string that is parsed, 
? by reading a previously defined object from a file, 
? by using an automatic search of suitable instantia- 
tions. 
These functionalities and their metatheory have been 
used for about a decade in a number of syntax edi- 
tors for constructive type theory, usually known as proof 
editors (Magnusson and NordstrOm, 1994). From this 
point of view, the GF editor is essentially a proof edi- 
tor together with supplementary views, provided by the 
concrete syntax. The current implementation of GF 
is a plugin module of the proof editor Alfa (Hallgren, 
2000). The window dump in Figure 2 shows a GF ses- 
sion editing a mathematical proof. Five views are pro- 
vided: abstract syntax in type-theoretical notation, En- 
glish, French, Finnish, and XML. One metavariable is
seen, expecting the user to find a Proof  of the proposi- 
tion that there exists a number .r' such that a', is smaller 
than x', where x is an arbitrary number given in the con- 
text (for the sake of Universal Introduction). 
3 IG : Interaction Grammars 
We have just described an approach to solving the limita- 
tions of usual XML tools for multilingual document au- 
thoring which originates in the tradition of constructive 
type-theory and mathematical proof editors. We will now 
sketch an approach strongly inspired by GF but which 
formally is more in the tradition of logic-programming 
based unification grammars, and which is currently un-. 
der development at Xerox Research Centre Europe (see 
(Brun et al, 2000) for a more extended escription of 
this project). 
Definite Clause Grammars, or DCG's, (Pereira and 
Warren, 1980), are possibly the simplest unification- 
based extension of context-free grammars, and have 
good reversibility properties which make them adapted 
both to parsing and to generation. A typical view of what 
a DCG rule looks like is the following: 5
a(a l (B ,C  . . . .  )) ---> 
<text l> ,  
b(B), 
<text2>,  
e(c ) ,  
<text3>, 
{constraints (B,C,...)}. 
This rule expresses the fact that (1) some abstract 
structure a l  (B, C . . . .  ) is in category a if the structure 
B is in category b, the structure C in category c..... and 
furthermore a certain number of constraints are satisfied 
by the structures B, C .... ; (2) if the structures B, C .... can 
be "rendered" by character strings St r ingB,  Str ingC,  
.... then the structure a l (B ,C . . . .  ) can be rendered by 
the string obtained by concatenating the text <text:t> 
(that is, a certain constant sequence of terminals), then 
St r ingB,  then <text2>, then Str ingC,  etc. 
In this formalism, a grammar for generating English 
addresses (see preceding section) might look like: 
SReminder: according to the usual ogic programming conventions, 
lowercase letters denote predicates and functors, whereas uppercase 
letters denote metavariables that will be instantiated with terms. 
247 
address(addr(Co,C)) --> city(C), ",", 
country(Co). 
country(fra) --> "France". 
country(get) --> "Germany". 
city(par) --> "Paris" 
city(cap(Co)) --> "the capital of", 
country(Co). 
The analogies with the GF grammars of the previous 
section arc clear. What is traditionally called a cate- 
gory (or nonterminal, or predicate) in the logic program- 
ruing terminology, can also be seen as a type (address,  
country ,  c i ty )  and functors uch as get,  par,  addr, 
cap can be seen as combinators. 
If, in this DCG, we "forget" all the constant strings 
by replacing them with the empty string, we obtain the 
following "abstract grammar": 
address(addr(Co,C)) --> city(C), country(Co). 
country(fra) --> \[\]. 
country(ger) --> \[\]. 
city(par) --> \[\]. 
city(cap(Co)) --> country(Co). 
which is in fact equivalent to the definite clause pro- 
gram: 6 
address (addr (Co ,C) )  : -  c i ty (C) ,  count ry (Co) .  
count ry ( f ra ) .  
country(ger) . 
city(par) . 
city(cap(Co)) :- country(Co). 
This program is language-independent andrecursively 
dclines a set el' well-formed trees to which it assigns 
types (thus cap( f ra )  is a well-formed tree o1' type 
city). 
As they stand, such definite clause grammars and pro- 
grams, although suitable Ibr simple generation tasks, are 
not directly adapted for the process of interactive multi- 
lingual document authoring. In order to make them more 
appropriate for that task, we need to specialize and adapt 
DCGs in the way that we now describe. 
Parallel grammars.  The tirst move is to allow for 
parallel English, French ..... grammars, which all have 
the same underlying abstract gralnmar (program). So in 
addition to the Englisb grammar given above, we have 
tim French grammar: 
address(addr(Co,C)) --> city(C), ",", 
country(Co). 
country(fra) --> "la France". 
country(get) --> "l'Allemagne". 
city(par) --> "Paris". 
city(cap(Co)) --> "la capitale de", 
country(Co) . 
6hl the sense that rewriling the llOntCI'nlilull goal 
address  (addr (Co ,C) ) to the empty siring in lhe I)CG is equivalent 
|o proving the goal address  (addr (Co, C) ) in the program (l)cransart 
and Maluszynski, 1993). 
Dependent  Categor ies .  The grammars we have given 
arc delicient in one importaut respect: there is no de- 
pendency between the city and the country in the salne 
address. In order to remedy this problem, a stan- 
dard logic programming move would he to reformulate 
the abstract grammar (and similarly for the language- 
dependent ones) as: 
address (addr (Co ,C) )  - -> c i ty (C ,Co) ,  
count ry (Co) .  
count ry ( f ra )  - -> \ [ \ ] .  
count ry (ger )  - -> \ [ \ ] .  
c i ty (par , f ra )  - -> \ [ \ ] .  
c i ty (cap(Co) ,Co)  - -> count ry (Co) .  
The expression c i ty (C ,  Co) is usually read as the re- 
lation "C is a city of Co", which is line for computational 
purposes, but this reading obscures the notion that the 
object C is being typed as a c i ty ;  more precisely, it is 
being typed as a c i ty  of Co. In order to make this read- 
ing more apparent, we will write the grammar as: 
address(addr(Co,C)) --> cityc0(C), 
country(Co). 
country(fra) --> \[\]. 
country(ger) --> \[\]. 
cityf~(par) --> \[\]. 
cityco(cap(Co)) --> country(Co). 
That is, we allow the categories to be indexed by terms 
(a move which is a kind of "currying" ot' a relation into 
a type for its first argument). Dependent categories are 
similar to the dependent types of constructive type the- 
ory. 
Heterogeneous trees. Natural language authoring is 
different from natural language generation in one cru- 
cial respect. Whenever the abstract ree to be generated 
is incomplete (for instance the tree cap(Co)),  that is, 
has some leaves which are yet uninstantiated variables, 
the generation process should not proceed with noude- 
terministically enumerating texts for all the possible in- 
stantiations of the initial incomplete structure. Instead it 
should display to the author as much of the text as it can 
in its present "knowledge state", and enter into an inter- 
action with the author to allow her to further refine the 
incomplete structure, that is, to further instantiate some 
of the uninstantiated leaves. To this purpose, it is use- 
ful to introduce along with the usual combinators (addr, 
f ra ,  cap, etc.) new combinators of arity 0 called type- 
names, which are notated type, and are of type type.  
These combiuators are allowed to stand as leaves (e.g. in 
the tree cap(country) )  and the trees thus obtained are 
said to be heterogeneous. The typenames are treated by 
the text generation process as if they were standard se- 
mantic units, that is, they are associated with text trails 
which arc generated "at their proper place" in the gen- 
erated output. These text units are specially phrased and 
highlighted to indicate to the author that some choice has 
to be made to reline the underlying type (e.g. obtaining 
248 
the text "la capimle de PAYS"). This choice has the efl'ect 
of further instantiating the incomplete tree with "true" 
combinators, and the gmmration process is iterated. 
Extended senmntics-driven eompositionality. The 
simple DCG view presented at the beginning of this sec- 
tion sees the process of generating text from an abstract 
structure as basically a compositional process on strings, 
that is, a process where strings are recursively associated 
with subtrees and concatenated to l~roduce strings at the 
next subtree level. But such a direct process of construct- 
ing strings Ires well-known limitations when the seman- 
tic and syntactic levels do not have such a direct corre- 
spondence (simple example: ordering a list of modifiers 
around a noun). We are currently experimenting with a 
powerful extension of string compositionality where the 
objects compositionally associated with abstract subtrees 
are not strings, but syntactic representations with rich in- 
ternal structure. The text itself is obtained fiom the syn- 
tactic representation associated with the total tree by Siln- 
ply enumerating its leaves. 
The picture we get of an IG grammar is tinally the 
following: 
aD,. . (al(B,C . . . .  ) ) -Syn  - -> 
bE,...(B)-SynB, 
CF,...(C)-SynC, 
{const ra in ts (B ,C , . . . ,D ,E ,F , . . . )} ,  
{compose_engl ish(SynB,  SynC, Syn)}.  
The rule shown is a rule for English: the syntactic 
representations are hmguage dependent; Parallel rules 
for tim other hmguages are obtained by replacing the 
compose eng l ' i sh  constraint (which is tmique to this 
rule) by constraints appropriate to the other hmguages 
under consideration. 
4 Conclusion 
XML-based authoring tools are more and more widely 
used in the business community for supporting the pro- 
duction of technical documentation, controlling their 
quality and improving their reusability. In this paper, 
we have stressed the connections between these practices 
and current research in natural anguage genenttion and 
authoring. We have described two related fornmlisms 
which are proposals for removing some of the limitations 
of XML DTD's when used for tim production of multi- 
lingual texts. 
From a compt, tational inguist's point of view, there 
might be little which seems novel or exciting in XML 
representations. Still XML has a great potential as a lin- 
gua.franca and in driving a large community of users 
towards authoring practices where content is becoming 
more and more explicit. There may be a great opportu- 
nity here for researchers in natural hmguage generation 
to connect o a growing sot, rce of applications. 
Acknowledgements 
Thanks for contributions, discussions and comments to 
Ken Beesley, Caroline Brtm, Jean-Pierre Chanod, Marie- 
Hdl8ne Corrdard, Pierre Isabelle, Bengt Nordstr6m, Syl- 
vain Pogodalla nd Annie Zaenen. 
References 
C. Brun, M. l)ymetman, and V. Lux. 2000. l)ocument 
structure and multilinguat authoring. In Proceedings of 
First h~telwatiomd Natural lzmguage Generation Confer- 
ence (INLG '2000), Mitzpe P, amon, Israel, June. 
J. Coch. 1996. Evahmting and comparing three text production 
tech,fiqucs. In Proceedhtgs ofthe 16th huernational Confe.r- 
ettce on Conqmtational Linguistics. 
1: l)eransart and J. Maluszynski. 1993. A Gramntatical View 
of Logic Programming. MIT Press. 
Thonms llallgren. 2000. Alfa Home Page. Awfilable fi'om 
http ://wm~. cs. chalmers, se/~hallgren/Alfa/ 
A. ltartley and C. Paris. 1997. Multilingual document produc- 
tion: fiom support for translating to support for authoring. 
In Machine Translation, Special Issue on New 7bols.for Htt- 
man 7)'anslators, pages 109-128. 
L. Magnusson and B. NordslrOm. 1994. The ALF proof editor 
and its proof engine. In Lecture Notes in Conqmler Science 
806. SpringeL 
P. Martin-L6f. 1984. hmdlionistic 7\]ype 7heoo,. Bibliopolis, 
Naples. 
W. Pardi. 1999. XML in Action. Microsoft Press. 
Femando C. N. Pereira and David II. D. Warren. 1980. Deft- 
nite clause grammars for language analysis. Artificial huel- 
ligence, 13:231-278. 
P,. Power and D. Scott. 1998. Multilingual authoring using 
feedback texts. In ProceedhTgs of the 17th h~ternational 
Confelwnce on Comlmtatiom~l linguistics and 36th Annual 
Meeting of the Association for Computational Lhlguislics, 
pages 1053-1059. 
P. Prescod. 1998. Fornmlizing SGMI, and XML In- 
stances and Schemata with Forest Automata Theory. 
http : //m~w. prescod, net/f orest/shorttut/. 
A. Ranta. 1994. 7~vpe-Theorelical Grammar. Oxford Univer- 
sity Press. 
Aarne Ranm. 2000. GF Work Page. Awfilablc fi'om 
h'c t;p://m,m, cs.  chalmers, se/~aarne/(IF/ 
pub/work- index/ 
W3C, 1998. Exlensible Marktq~ Language (XML) 1.0, Febru- 
ary. W3C recommendation. 
W3C, 1999a. XML Schema - l'art h Strltctttres, Part 2 : 
Datatypes -, l)ecembe,. W3C Working draft. 
W3C, 1999b. XSL Transformations (XSLT), Novcmbe,; W3C 
recommendation. 
249 
Proceedings of the EACL 2009 Demonstrations Session, pages 9?12,
Athens, Greece, 3 April 2009. c?2009 Association for Computational Linguistics
Grammatical Framework Web Service
Bjo?rn Bringert? and Krasimir Angelov and Aarne Ranta
Department of Computer Science and Engineering
Chalmers University of Technology and University of Gothenburg
{bringert,krasimir,aarne}@chalmers.se
Abstract
We present a web service for natural language
parsing, prediction, generation, and translation
using grammars in Portable Grammar Format
(PGF), the target format of the Grammatical
Framework (GF) grammar compiler. The web
service implementation is open source, works
with any PGF grammar, and with any web
server that supports FastCGI. The service ex-
poses a simple interface which makes it pos-
sible to use it for interactive natural language
web applications. We describe the function-
ality and interface of the web service, and
demonstrate several applications built on top
of it.
1 Introduction
Current web applications often consist of JavaScript
code that runs in the user?s web browser, with server-
side code that does the heavy lifting. We present a web
service for natural language processing with Portable
Grammar Format (PGF, Angelov et al, 2008) gram-
mars, which can be used to build interactive natural lan-
guage web applications. PGF is the back-end format
to which Grammatical Framework (GF, Ranta, 2004)
grammars are compiled. PGF has been designed to al-
low efficient implementations.
The web service has a simple API based solely on
HTTP GET requests. It returns responses in JavaScript
Object Notation (JSON, Crockford, 2006). The server-
side program is distributed as part of the GF software
distribution, under the GNU General Public License
(GPL). The program is generic, in the sense that it can
be used with any PGF grammar without any modifica-
tion of the program.
2 Grammatical Framework
Grammatical Framework (GF, Ranta, 2004) is a type-
theoretical grammar formalism. A GF grammar con-
sists of an abstract syntax, which defines a set of ab-
stract syntax trees, and one or more concrete syntaxes,
which define how abstract syntax trees are mapped to
(and from) strings. The process of producing a string
?Now at Google Inc.
(or, more generally, a feature structure) from an ab-
stract syntax tree is called linearization. The oppo-
site, producing an abstract syntax tree (or several, if the
grammar is ambiguous) from a string is called parsing.
In a small, semantically oriented application gram-
mar, the sentence ?2 is even? may correspond to the
abstract syntax tree Even 2. In a larger, more syn-
tactically oriented grammar, in this case the English
GF resource grammar (Ranta, 2007), the same sen-
tence can correspond to the abstract syntax tree PhrUtt
NoPConj (UttS (UseCl (TTAnt TPres ASimul)
PPos (PredVP (UsePN (NumPN (NumDigits (IDig
D 2)))) (UseComp (CompAP (PositA even A))))))
NoVoc.
2.1 Portable Grammar Format (PGF)
Portable Grammar Format (PGF, Angelov et al, 2008)
is a low-level format to which GF grammars are com-
piled. The PGF Web Service loads PGF files from disk,
and uses them to serve client requests. These PGF files
are normally produced by compiling GF grammars, but
they could also be produced by other means, for exam-
ple by a compiler from another grammar formalism.
Such compilers currently exist for context-free gram-
mars in BNF and EBNF formats, though they compile
via GF.
2.2 Parsing and Word Prediction
For each concrete syntax in a PGF file, there is a pars-
ing grammar, which is a Parallel Multiple Context Free
Grammar (PMCFG, Seki et al, 1991). The PGF inter-
preter uses an efficient parsing algorithm for PMCFG
(Angelov, 2009) which is similar to the Earley algo-
rithm for CFG. The algorithm is top-down and incre-
mental which makes it possible to use it for word com-
pletion. When the whole sentence is known, the parser
just takes the tokens one by one and computes the chart
of all possible parse trees. If the sentence is not yet
complete, then the known tokens can be used to com-
pute a partial parse chart. Since the algorithm is top-
down it is possible to predict the set of valid next tokens
by using just the partial chart.
The prediction can be used in applications to guide
the user to stay within the coverage of the grammar. At
each point the set of valid next tokens is shown and the
user can select one of them.
9
Figure 1: Translator interface. This example uses
the Bronzeage grammar, which consists of simple
syntactic rules along with lexica based on Swadesh
lists. Demo at http://digitalgrammars.com/
translate.
The word prediction is based entirely on the gram-
mar and not on any additional n-gram model. This
means that it works with any PGF grammar and no ex-
tra work is needed. In addition it works well even with
long distance dependencies. For example if the subject
is in a particular gender and the verb requires gender
agreement, then the the correct form is predicted, inde-
pendently on how far the verb is from the subject.
3 Applications
Several interactive web applications have been built
with the PGF Web Service. They are all JavaScript pro-
grams which run in the user?s web browser and send
asynchronous HTTP requests to the PGF Web Service.
3.1 Translator
The simplest application (see Figure 1) presents the
user with a text field for input, and drop-down boxes for
selecting the grammar and language to use. For every
change in the text field, the application asks the PGF
Web Service for a number of possible completions of
the input, and displays them below the text field. The
user can continue typing, or select one of the sugges-
tions. When the current input can be parsed completely,
the input is translated to all available languages.
3.2 Fridge Poetry
The second application is similar in functionality to the
first, but it presents a different user interface. The in-
terface (see Figure 2) mimics the popular refrigerator
magnet poetry sets. However, in contrast to physical
fridge magnets, this application handles inflection au-
tomatically and only allows the construction of gram-
matically correct sentences (as defined by the selected
grammar). It also shows translations for complete in-
puts and allows the user to switch languages.
Figure 2: Fridge poetry screenshot. Demo at http:
//digitalgrammars.com/fridge.
Figure 3: Reasoning screenshot. Demo at http://
digitalgrammars.com/mosg.
3.3 Reasoning
Another application is a natural language reasoning
system which accepts facts and questions from the
users, and tries to answer the questions based on the
facts given. The application uses the PGF Web Service
to parse inputs. It uses two other web services for se-
mantic interpretation and reasoning, respectively. The
semantic interpretation service uses a continuation-
based compositional mapping of abstract syntax terms
to first-order logic formulas (Bringert, 2008). The rea-
soning service is a thin layer on top of the Equinox the-
orem prover and the Paradox model finder (Claessen
and So?rensson, 2003).
4 API
Below, we will show URI paths for each function,
for example /pgf/food.pgf/parse. Arguments
to each function are given in the URL query string,
in application/x-www-form-urlencoded
(Raggett et al, 1999) format. Thus, if the service is
running on example.com, the URI for a request to
parse the string ?this fish is fresh? using the FoodEng
concrete syntax in the food.pgf grammar would
10
be: http://example.com/pgf/food.pgf/
parse?input=this+fish+is+fresh&from=
FoodEng. The functions described below each accept
some subset of the following arguments:
from The name of the concrete syntax to parse with
or translate from. Multiple from arguments can
be given, in which case all the specified languages
are tried. If omitted, all languages (that can be
used for parsing) are used.
cat The name of the abstract syntax category to parse
or translate in, or generate output in. If omitted,
the start category specified in the PGF file is used.
to The name of the concrete syntax to linearize or
translate to. Multiple to arguments can be given,
in which case all the specified languages are used.
If omitted, results for all languages are returned.
input The text to parse, complete or translate. If
omitted, the empty string is used.
tree The abstract syntax tree to linearize.
limit The maximum number of results to return.
All results are returned in UTF-8 encoded JSON or
JSONP format. A jsonp argument can be given to
each function to invoke a callback function when the
response is evaluated in a JavaScript interpreter. This
makes it possible to circumvent the Same Origin Policy
in the web browser and call the PGF Web Service from
applications loaded from another server.
4.1 Grammar List
/pgf retrieves a list of the available PGF files.
4.2 Grammar Info
/pgf/grammar.pgf, where grammar.pgf is the
name of a PGF file on the server, retrieves information
about the given grammar. This information includes
the name of the abstract syntax, the categories in the
abstract syntax, and the list of concrete syntaxes.
4.3 Parsing
/pgf/grammar.pgf/parse parses an input string
and returns a number of abstract syntax trees. Optional
arguments: input, from, cat.
4.4 Completion
/pgf/grammar.pgf/complete returns a list of
predictions for the next token, given a partial input.
Optional arguments: input, from, cat, limit. If
limit is omitted, all results are returned.
4.5 Linearization
/pgf/grammar.pgf/linearize accepts an ab-
stract syntax tree, and returns the results of lineariz-
ing it to one or more languages. Mandatory arguments:
tree. Optional arguments: to.
4.6 Random Generation
/pgf/grammar.pgf/random generates a number
of randomly generated abstract syntax trees for the se-
lected grammar. Optional arguments: cat, limit. If
limit is omitted, one tree is returned.
4.7 Translation
/pgf/grammar.pgf/translate performs text
to text translation. This is done by parsing, followed
by linearization. Optional arguments: input, from,
cat, to.
5 Application to Controlled Languages
The use of controlled languages is becoming more pop-
ular with the development of Web and Semantic Web
technologies. Related projects include Attempto (At-
tempto, 2008), CLOnE (Funk et al, 2007), and Com-
mon Logic Controlled English (CLCE) (Sowa, 2004).
All these projects provide languages which are subsets
of English and have semantic translations into first or-
der logic (CLCE), OWL (CLOnE) or both (Attempto).
In the case of Attempto, the translation is into first order
logic and if it is possible to the weaker OWL language.
The general idea is that since the controlled language
is a subset of some other language it should be under-
standable to everyone without special training. The op-
posite is not true - not every English sentence is a valid
sentence in the controlled language and the user must
learn how to stay within its limitations. Although this
is a disadvantage, in practice it is much easier to re-
member some subset of English phrases rather than to
learn a whole new formal language. Word suggestion
functionality such as that in the PGF Web Service can
help the user stay within the controlled fragment.
In contrast to the above mentioned systems, GF is
not a system which provides only one controlled lan-
guage, but a framework within which the developer can
develop his own language. The task is simplified by the
existence of a resource grammar library (Ranta, 2007)
which takes care of all low-level details such as word
order, and gender, number or case agreement. In fact,
the language developer does not have to be skilled in
linguistics, but does have to be a domain expert and
can concentrate on the specific task.
Most controlled language frameworks are focused
on some subset of English while other languages re-
ceive very little or no attention. With GF, the con-
trolled language does not have to be committed to only
one natural language but could have a parallel grammar
with realizations into many languages. In this case the
user could choose whether to use the English version
or, for example, the French version, and still produce
the same abstract representation.
6 Implementation
The PGF Web Service is a FastCGI program written in
Haskell. The program is a thin layer on top of the PGF
11
interpreter, which implements all the PGF functional-
ity, such as parsing, completion and linearization. The
web service also uses external libraries for FastCGI
communication, and JSON and UTF-8 encoding and
decoding.
The main advantage of using FastCGI instead of
plain CGI is that the PGF file does not have to be
reloaded for each request. Instead, each PGF file is
loaded the first time it is requested, and after that, it is
only reloaded if the file on disk is changed.
7 Performance
The web service layer introduces minimal overhead.
The typical response time for a parse request with a
small grammar, when running on a typical current PC,
is around 1 millisecond. For large grammars, response
times can be on the order of several seconds, but this is
entirely dependent on the PGF interpreter implementa-
tion.
The server is multi-threaded, with one lightweight
thread for each client request. A single instance of the
server can run threads on all cores of a multi-core pro-
cessor. Since the server maintains no state and requires
no synchronization, it can be easily replicated on mul-
tiple machines with load balancing. Since all requests
are cacheable HTTP GET requests, a caching proxy
could be used to improve performance if it is expected
that there will be repeated requests for the same URI.
8 Future Work
The abstract syntax in GF is based on Martin
Lo?f?s (1984) type theory and supports dependent types.
They can be used go beyond the pure syntax and to
check the sentences for semantic consistency. The cur-
rent parser completely ignores dependent types. This
means that the word prediction will suggest comple-
tions which might not be semantically meaningful.
In order to improve performance for high-traffic ap-
plications that use large grammars, the web service
could cache responses. As long as the grammar is not
modified, identical requests will always produce iden-
tical responses.
9 Conclusions
We have presented a web service for grammar-based
natural language processing, which can be used to build
interactive natural language web applications. The web
service has a simple API, based on HTTP GET requests
with JSON responses. The service allows high levels of
performance and scalability, and has been used to build
several applications.
References
Krasimir Angelov. 2009. Incremental Parsing with Par-
allel Multiple Context-Free Grammars. In European
Chapter of the Association for Computational Lin-
guistics.
Krasimir Angelov, Bjo?rn Bringert, and Aarne
Ranta. 2008. PGF: A Portable Run-Time For-
mat for Type-Theoretical Grammars. Journal
of Logic, Language and Information, submit-
ted. URL http://www.cs.chalmers.se/
?bringert/publ/pgf/pgf.pdf.
Attempto. 2008. Attempto Project Homepage -
http://attempto.ifi.uzh.ch/site/. URL http://
attempto.ifi.uzh.ch/site/.
Bjo?rn Bringert. 2008. Delimited Contin-
uations, Applicative Functors and Natu-
ral Language Semantics. URL http:
//www.cs.chalmers.se/?bringert/
publ/continuation-semantics/
continuation-semantics.pdf.
Koen Claessen and Niklas So?rensson. 2003. New
Techniques that Improve MACE-style Model Find-
ing. In Workshop on Model Computation
(MODEL). URL http://www.cs.chalmers.
se/?koen/pubs/model-paradox.ps.
Douglas Crockford. 2006. The application/json Media
Type for JavaScript Object Notation (JSON). RFC
4627 (Informational). URL http://www.ietf.
org/rfc/rfc4627.txt.
Adam Funk, Valentin Tablan, Kalina Bontcheva,
Hamish Cunningham, Brian Davis, and Siegfried
Handschuh. 2007. CLOnE: Controlled Language for
Ontology Editing. In Proceedings of the Interna-
tional Semantic Web Conference (ISWC 2007). Bu-
san, Korea.
Per Martin-Lo?f. 1984. Intuitionistic Type Theory. Bib-
liopolis, Naples.
Dave Raggett, Arnaud Le Hors, and Ian Jacobs.
1999. HTML 4.01 Specification. Technical report,
W3C. URL http://www.w3.org/TR/1999/
REC-html401-19991224/.
Aarne Ranta. 2004. Grammatical Framework: A
Type-Theoretical Grammar Formalism. Jour-
nal of Functional Programming, 14(2):145?189.
URL http://dx.doi.org/10.1017/
S0956796803004738.
Aarne Ranta. 2007. Modular Grammar Engineering
in GF. Research on Language and Computation,
5(2):133?158. URL http://dx.doi.org/10.
1007/s11168-007-9030-6.
Hiroyuki Seki, Takashi Matsumura, Mamoru Fujii,
and Tadao Kasami. 1991. On multiple context-
free grammars. Theoretical Computer Science,
88(2):191?229. URL http://dx.doi.org/
10.1016/0304-3975(91)90374-B.
John Sowa. 2004. Common Logic Controlled En-
glish. Draft. URL http://www.jfsowa.com/
clce/specs.htm.
12
Proceedings of the EACL 2009 Demonstrations Session, pages 57?60,
Athens, Greece, 3 April 2009. c?2009 Association for Computational Linguistics
Grammar Development in GF
Aarne Ranta and Krasimir Angelov and Bjo?rn Bringert?
Department of Computer Science and Engineering
Chalmers University of Technology and University of Gothenburg
{aarne,krasimir,bringert}@chalmers.se
Abstract
GF is a grammar formalism that has a
powerful type system and module system,
permitting a high level of abstraction and
division of labour in grammar writing. GF
is suited both for expert linguists, who
appreciate its capacity of generalizations
and conciseness, and for beginners, who
benefit from its static type checker and,
in particular, the GF Resource Grammar
Library, which currently covers 12 lan-
guages. GF has a notion of multilingual
grammars, enabling code sharing, linguis-
tic generalizations, rapid development of
translation systems, and painless porting
of applications to new languages.
1 Introduction
Grammar implementation for natural languages is
a challenge for both linguistics and engineering.
The linguistic challenge is to master the complex-
ities of languages so that all details are taken into
account and work seamlessly together; if possible,
the description should be concise and elegant, and
capture the linguist?s generalizations on the level
of code. The engineering challenge is to make
the grammar scalable, reusable, and maintainable.
Too many grammars implemented in the history of
computational linguistics have become obsolete,
not only because of their poor maintainability, but
also because of the decay of entire software and
hardware platforms.
The first measure to be taken against the ?bit
rot? of grammars is to write them in well-defined
formats that can be implemented independently
of platform. This requirement is more or less an
axiom in programming language development: a
?Now at Google Inc.
language must have syntax and semantics specifi-
cations that are independent of its first implemen-
tation; otherwise the first implementation risks to
remain the only one.
Secondly, since grammar engineering is to a
large extent software engineering, grammar for-
malisms should learn from programming language
techniques that have been found useful in this re-
spect. Two such techniques are static type sys-
tems and module systems. Since grammar for-
malism implementations are mostly descendants
of Lisp and Prolog, they usually lack a static type
system that finds errors at compile time. In a com-
plex task like grammar writing, compile-time er-
ror detection is preferable to run-time debugging
whenever possible. As for modularity, traditional
grammar formalisms again inherit from Lisp and
Prolog low-level mechanisms like macros and file
includes, which in modern languages like Java and
ML have been replaced by advanced module sys-
tems akin in rigour to type systems.
Thirdly, as another lesson from software en-
gineering, grammar writing should permit an in-
creasing use of libraries, so that programmers can
build on ealier code. Types and modules are essen-
tial for the management of libraries. When a new
language is developed, an effort is needed in creat-
ing libraries for the language, so that programmers
can scale up to real-size tasks.
Fourthly, a grammar formalism should have a
stable and efficient implementation that works
on different platforms (hardware and operating
systems). Since grammars are often parts of larger
language-processing systems (such as translation
tools or dialogue systems), their interoperability
with other components is an important issue. The
implementation should provide compilers to stan-
dard formats, such as databases and speech recog-
nition language models. In addition to interoper-
ability, such compilers also help keeping the gram-
mars alive even if the original grammar formalism
57
ceases to exist.
Fifthly, grammar formalisms should have rich
documentation; in particular, they should have
accessible tutorials that do not demand the read-
ers to be experts in a linguistic theory or in com-
puter programming. Also the libraries should be
documented, preferably by automatically gener-
ated documentation in the style of JavaDoc, which
is guaranteed to stay up to date.
Last but not least, a grammar formalism, as well
its documentation, implementation, and standard
libraries, should be freely available open-source
software that anyone can use, inspect, modify, and
improve. In the domain of general-purpose pro-
gramming, this is yet another growing trend; pro-
prietary languages are being made open-source or
at least free of charge.
2 The GF programming language
The development of GF started in 1998 at Xe-
rox Research Centre Europe in Grenoble, within a
project entitled ?Multilingual Document Author-
ing? (Dymetman & al. 2000). Its purpose was
to make it productive to build controlled-language
translators and multilingual authoring systems,
previously produced by hard-coded grammar
rules rather than declarative grammar formalisms
(Power & Scott 1998). Later, mainly at Chalmers
University in Gothenburg, GF developed into a
functional programming language inspired by ML
and Haskell, with a strict type system and oper-
ational semantics specified in (Ranta 2004). A
module system was soon added (Ranta 2007), in-
spired by the parametrized modules of ML and
the class inheritance hierarchies of Java, although
with multiple inheritance in the style of C++.
Technically, GF falls within the class of so-
called Curry-style categorial grammars, inspired
by the distinction between tectogrammatical and
phenogrammatical structure in (Curry 1963).
Thus a GF grammar has an abstract syntax defin-
ing a system of types and trees (i.e. a free algebra),
and a concrete syntax, which is a homomorphic
mapping from trees to strings and, more generally,
to records of strings and features. To take a simple
example, the NP-VP predication rule, written
S ::= NP VP
in a context-free notation, becomes in GF a pair of
an abstract and a concrete syntax rule,
fun Pred : NP -> VP -> S
lin Pred np vp = np ++ vp
The keyword fun stands for function declara-
tion (declaring the function Pred of type NP ->
VP -> S), whereas lin stands for linearization
(saying that trees of form Pred np vp are con-
verted to strings where the linearization of np is
followed by the linearization of vp). The arrow
-> is the normal function type arrow of program-
ming languages, and ++ is concatenation.
Patterns more complex than string concatena-
tion can be used in linearizations of the same pred-
ication trees as the rule above. Thus agreement
can be expressed by using features passed from the
noun phrase to the verb phrase. The noun phrase
is here defined as not just a string, but as a record
with two fields?a string s and an agreement fea-
ture a. Verb-subject inversion can be expressed by
making VP into a discontinuous constituent, i.e.
a record with separate verb and complement fields
v and c. Combining these two phenomena, we
write
vp.v ! np.a ++ np.s ++ vp.c
(For the details of the notation, we refer to doc-
umentation on the GF web page.) Generalizing
strings into richer data structures makes it smooth
to deal accurately with complexities such as Ger-
man constituent order and Romance clitics, while
maintaining the simple tree structure defined by
the abstract syntax of Pred.
Separating abstract and concrete syntax makes
it possible to write multilingual grammars,
where one abstract syntax is equipped with several
concrete syntaxes. Thus different string configura-
tions can be mapped into the same abstract syntax
trees. For instance, the distinction between SVO
and VSO languages can be ignored on the abstract
level, and so can all other {S,V,O} patterns as well.
Also the differences in feature systems can be ab-
stracted away from. For instance, agreement fea-
tures in English are much simpler than in Arabic;
yet the same abstract syntax can be used.
Since concrete syntax is reversible between lin-
earization and parsing (Ljunglo?f 2004), multilin-
gual grammars can be used for translation, where
the abstract syntax works as interlingua. Experi-
ence from translation projects (e.g. Burke and Jo-
hannisson 2005, Caprotti 2006) has shown that the
interlingua-based translation provided by GF gives
good quality in domain-specific tasks. However,
GF also supports the use of a transfer component if
the compositional method implied by multilingual
grammars does not suffice (Bringert and Ranta
58
2008). The language-theoretical strenght of GF is
between mildly and fully context-sensitive, with
polynomial parsing complexity (Ljunglo?f 2004).
In addition to multilingual grammars, GF is
usable for more traditional, large-scale unilin-
gual grammar development. The ?middle-scale?
resource grammars can be extended to wide-
coverage grammars, by adding a few rules and
a large lexicon. GF provides powerful tools for
building morphological lexica and exporting them
to other formats, including Xerox finite state tools
(Beesley and Karttunen 2003) and SQL databases
(Forsberg and Ranta 2004). Some large lexica
have been ported to the GF format from freely
available sources for Bulgarian, English, Finnish,
Hindi, and Swedish, comprising up to 70,000 lem-
mas and over two million word forms.
3 The GF Resource Grammar Library
The GF Resource Grammar Library is a com-
prehensive multilingual grammar currently imple-
mented for 12 languages: Bulgarian, Catalan,
Danish, English, Finnish, French, German, Italian,
Norwegian, Russian, Spanish, and Swedish. Work
is in progress on Arabic, Hindi/Urdu, Latin, Pol-
ish, Romanian, and Thai. The library is an open-
source project, which constantly attracts new con-
tributions.
The library can be seen as an experiment on how
far the notion of multilingual grammars extends
and how GF scales up to wide-coverage gram-
mars. Its primary purpose, however, is to provide
a programming resource similar to the standard li-
braries of various programming languages. When
all linguistic details are taken into account, gram-
mar writing is an expert programming task, and
the library aims to make this expertise available to
non-expert application programmers.
The coverage of the library is comparable to the
Core Language Engine (Rayner & al. 2000). It has
been developed and tested in applications ranging
from a translation system for software specifica-
tions (Burke and Johannisson 2005) to in-car dia-
logue systems (Perera and Ranta 2007).
The use of a grammar as a library is made pos-
sible by the type and module system of GF (Ranta
2007). What is more, the API (Application Pro-
grammer?s Interface) of the library is to a large ex-
tent language-independent. For instance, an NP-
VP predication rule is available for all languages,
even though the underlying details of predication
vary greatly from one language to another.
A typical domain grammar, such as the one in
Perera and Ranta (2007), has 100?200 syntactic
combinations and a lexicon of a few hundred lem-
mas. Building the syntax with the help of the li-
brary is a matter of a few working days. Once it
is built for one language, porting it to other lan-
guages mainly requires writing the lexicon. By
the use of the inflection libraries, this is a matter of
hours. Thus porting a domain grammar to a new
language requires very effort and also very little
linguistic knowledge: it is expertise of the appli-
cation domain and its terminology that is needed.
4 The GF grammar compiler
The GF grammar compiler is usable in two ways:
in batch mode, and as an interactive shell. The
shell is a useful tool for developers as it provides
testing facilities such as parsing, linerization, ran-
dom generation, and grammar statistics. Both
modes use PGF, Portable Grammar Format,
which is the ?machine language? of GF permit-
ting fast run-time linearization and parsing (An-
gelov & al. 2008). PGF interpreters have been
written in C++, Java, and Haskell, permitting an
easy embedding of grammars in systems written
in these languages. PGF can moreover be trans-
lated to other formats, including language mod-
els for speech recognition (e.g. Nuance and HTK;
see Bringert 2007a), VoiceXML (Bringert 2007b),
and JavaScript (Meza Moreno and Bringert 2008).
The grammar compiler is heavily optimizing, so
that the use of a large library grammar in small
run-time applications produces no penalty.
For the working grammarian, static type check-
ing is maybe the most unique feature of the GF
grammar compiler. Type checking does not only
detect errors in grammars. It also enables aggres-
sive optimizations (type-driven partial evaluation),
and overloading resolution, which makes it pos-
sible to use the same name for different functions
whose types are different.
5 Related work
As a grammar development system, GF is compa-
rable to Regulus (Rayner 2006), LKB (Copestake
2002), and XLE (Kaplan and Maxwell 2007). The
unique features of GF are its type and module sys-
tem, support for multilingual grammars, the large
number of back-end formats, and the availability
of libraries for 12 languages. Regulus has resource
59
grammars for 7 languages, but they are smaller in
scope. In LKB, the LinGO grammar matrix has
been developed for several languages (Bender and
Flickinger 2005), and in XLE, the Pargram gram-
mar set (Butt & al. 2002). LKB and XLE tools
have been targeted to linguists working with large-
scale grammars, rather than for general program-
mers working with applications.
References
[Angelov et al2008] K. Angelov, B. Bringert, and
A. Ranta. 2008. PGF: A Portable Run-Time Format
for Type-Theoretical Grammars. Chalmers Univer-
sity. Submitted for publication.
[Beesley and Karttunen2003] K. Beesley and L. Kart-
tunen. 2003. Finite State Morphology. CSLI Publi-
cations.
[Bender and Flickinger2005] Emily M. Bender and
Dan Flickinger. 2005. Rapid prototyping of scal-
able grammars: Towards modularity in extensions
to a language-independent core. In Proceedings of
the 2nd International Joint Conference on Natural
Language Processing IJCNLP-05 (Posters/Demos),
Jeju Island, Korea.
[Bringert and Ranta2008] B. Bringert and A. Ranta.
2008. A Pattern for Almost Compositional Func-
tions. The Journal of Functional Programming,
18(5?6):567?598.
[Bringert2007a] B. Bringert. 2007a. Speech Recogni-
tion Grammar Compilation in Grammatical Frame-
work. In SPEECHGRAM 2007: ACL Workshop on
Grammar-Based Approaches to Spoken Language
Processing, June 29, 2007, Prague.
[Bringert2007b] Bjo?rn Bringert. 2007b. Rapid Devel-
opment of Dialogue Systems by Grammar Compi-
lation. In Simon Keizer, Harry Bunt, and Tim Paek,
editors, Proceedings of the 8th SIGdial Workshop on
Discourse and Dialogue, Antwerp, Belgium, pages
223?226. Association for Computational Linguis-
tics, September.
[Bringert2008] B. Bringert. 2008. Semantics of the GF
Resource Grammar Library. Report, Chalmers Uni-
versity.
[Burke and Johannisson2005] D. A. Burke and K. Jo-
hannisson. 2005. Translating Formal Software
Specifications to Natural Language / A Grammar-
Based Approach. In P. Blache and E. Stabler and
J. Busquets and R. Moot, editor, Logical Aspects
of Computational Linguistics (LACL 2005), volume
3492 of LNCS/LNAI, pages 51?66. Springer.
[Butt et al2002] M. Butt, H. Dyvik, T. Holloway King,
H. Masuichi, and C. Rohrer. 2002. The Parallel
Grammar Project. In COLING 2002, Workshop on
Grammar Engineering and Evaluation, pages 1?7.
URL
[Caprotti2006] O. Caprotti. 2006. WebALT! Deliver
Mathematics Everywhere. In Proceedings of SITE
2006. Orlando March 20-24.
[Copestake2002] A. Copestake. 2002. Implementing
Typed Feature Structure Grammars. CSLI Publica-
tions.
[Curry1963] H. B. Curry. 1963. Some logical aspects
of grammatical structure. In Roman Jakobson, edi-
tor, Structure of Language and its Mathematical As-
pects: Proceedings of the Twelfth Symposium in Ap-
plied Mathematics, pages 56?68. American Mathe-
matical Society.
[Dymetman et al2000] M. Dymetman, V. Lux, and
A. Ranta. 2000. XML and multilingual docu-
ment authoring: Convergent trends. In COLING,
Saarbru?cken, Germany, pages 243?249.
[Forsberg and Ranta2004] M. Forsberg and A. Ranta.
2004. Functional Morphology. In ICFP 2004,
Showbird, Utah, pages 213?223.
[Ljunglo?f2004] P. Ljunglo?f. 2004. The Expressivity
and Complexity of Grammatical Framework. Ph.D.
thesis, Dept. of Computing Science, Chalmers Uni-
versity of Technology and Gothenburg University.
[Meza Moreno and Bringert2008] M. S. Meza Moreno
and B. Bringert. 2008. Interactive Multilingual
Web Applications with Grammarical Framework. In
B. Nordstro?m and A. Ranta, editors, Advances in
Natural Language Processing (GoTAL 2008), vol-
ume 5221 of LNCS/LNAI, pages 336?347.
[Perera and Ranta2007] N. Perera and A. Ranta. 2007.
Dialogue System Localization with the GF Resource
Grammar Library. In SPEECHGRAM 2007: ACL
Workshop on Grammar-Based Approaches to Spo-
ken Language Processing, June 29, 2007, Prague.
[Power and Scott1998] R. Power and D. Scott. 1998.
Multilingual authoring using feedback texts. In
COLING-ACL.
[Ranta2004] A. Ranta. 2004. Grammatical Frame-
work: A Type-Theoretical Grammar Formal-
ism. The Journal of Functional Programming,
14(2):145?189.
[Ranta2007] A. Ranta. 2007. Modular Grammar Engi-
neering in GF. Research on Language and Compu-
tation, 5:133?158.
[Rayner et al2000] M. Rayner, D. Carter, P. Bouillon,
V. Digalakis, and M. Wire?n. 2000. The Spoken
Language Translator. Cambridge University Press,
Cambridge.
[Rayner et al2006] M. Rayner, B. A. Hockey, and
P. Bouillon. 2006. Putting Linguistics into Speech
Recognition: The Regulus Grammar Compiler.
CSLI Publications.
60
Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 645?653,
Avignon, France, April 23 - 27 2012. c?2012 Association for Computational Linguistics
Smart Paradigms and the Predictability and Complexity of Inflectional
Morphology
Gre?goire De?trez and Aarne Ranta
Department of Computer Science and Engineering
Chalmers University of Technology and University of Gothenburg
Abstract
Morphological lexica are often imple-
mented on top of morphological paradigms,
corresponding to different ways of building
the full inflection table of a word. Compu-
tationally precise lexica may use hundreds
of paradigms, and it can be hard for a lex-
icographer to choose among them. To au-
tomate this task, this paper introduces the
notion of a smart paradigm. It is a meta-
paradigm, which inspects the base form and
tries to infer which low-level paradigm ap-
plies. If the result is uncertain, more forms
are given for discrimination. The number
of forms needed in average is a measure
of predictability of an inflection system.
The overall complexity of the system also
has to take into account the code size of
the paradigms definition itself. This pa-
per evaluates the smart paradigms imple-
mented in the open-source GF Resource
Grammar Library. Predictability and com-
plexity are estimated for four different lan-
guages: English, French, Swedish, and
Finnish. The main result is that predictabil-
ity does not decrease when the complex-
ity of morphology grows, which means that
smart paradigms provide an efficient tool
for the manual construction and/or auto-
matically bootstrapping of lexica.
1 Introduction
Paradigms are a cornerstone of grammars in the
European tradition. A classical Latin grammar
has five paradigms for nouns (?declensions?) and
four for verbs (?conjugations?). The modern ref-
erence on French verbs, Bescherelle (Bescherelle,
1997), has 88 paradigms for verbs. Swedish
grammars traditionally have, like Latin, five
paradigms for nouns and four for verbs, but a
modern computational account (Hellberg, 1978),
aiming for more precision, has 235 paradigms for
Swedish.
Mathematically, a paradigm is a function that
produces inflection tables. Its argument is a word
string (either a dictionary form or a stem), and
its value is an n-tuple of strings (the word forms):
P : String? Stringn
We assume that the exponent n is determined by
the language and the part of speech. For instance,
English verbs might have n = 5 (for sing, sings,
sang, sung, singing), whereas for French verbs in
Bescherelle, n = 51. We assume the tuples to
be ordered, so that for instance the French sec-
ond person singular present subjunctive is always
found at position 17. In this way, word-paradigm
pairs can be easily converted to morphogical lex-
ica and to transducers that map form descriptions
to surface forms and back. A properly designed
set of paradigms permits a compact representation
of a lexicon and a user-friendly way to extend it.
Different paradigm systems may have different
numbers of paradigms. There are two reasons for
this. One is that traditional paradigms often in fact
require more arguments than one:
P : Stringm ? Stringn
Here m ? n and the set of arguments is a subset
of the set of values. Thus the so-called fourth verb
conjugation in Swedish actually needs three forms
to work properly, for instance sitta, satt, suttit for
the equivalent of sit, sat, sat in English. In Hell-
berg (1978), as in the French Bescherelle, each
paradigm is defined to take exactly one argument,
and hence each vowel alternation pattern must be
a different paradigm.
The other factor that affects the number of
paradigms is the nature of the string operations
645
allowed in the function P . In Hellberg (1978),
noun paradigms only permit the concatenation of
suffixes to a stem. Thus the paradigms are iden-
tified with suffix sets. For instance, the inflection
patterns bil?bilar (?car?cars?) and nyckel?nycklar
(?key?keys?) are traditionally both treated as in-
stances of the second declension, with the plural
ending ar and the contraction of the unstressed
e in the case of nyckel. But in Hellberg, the
word nyckel has nyck as its ?technical stem?, to
which the paradigm numbered 231 adds the sin-
gular ending el and the plural ending lar.
The notion of paradigm used in this paper al-
lows multiple arguments and powerful string op-
erations. In this way, we will be able to reduce
the number of paradigms drastically: in fact, each
lexical category (noun, adjective, verb), will have
just one paradigm but with a variable number of
arguments. Paradigms that follow this design will
be called smart paradigms and are introduced
in Section 2. Section 3 defines the notions of
predictability and complexity of smart paradigm
systems. Section 4 estimates these figures for four
different languages of increasing richness in mor-
phology: English, Swedish, French, and Finnish.
We also evaluate the smart paradigms as a data
compression method. Section 5 explores some
uses of smart paradigms in lexicon building. Sec-
tion 6 compares smart paradigms with related
techniques such as morphology guessers and ex-
traction tools. Section 7 concludes.
2 Smart paradigms
In this paper, we will assume a notion of paradigm
that allows multiple arguments and arbitrary com-
putable string operations. As argued in (Ka-
plan and Kay, 1994) and amply demonstrated in
(Beesley and Karttunen, 2003), no generality is
lost if the string operators are restricted to ones
computable by finite-state transducers. Thus the
examples of paradigms that we will show (only
informally), can be converted to matching and re-
placements with regular expressions.
For example, a majority of French verbs can
be defined by the following paradigm, which
analyzes a variable-size suffix of the infinitive
form and dispatches to the Bescherelle paradigms
(identified by a number and an example verb):
mkV : String? String51
mkV(s) =
? conj19finir(s), if s ends ir
? conj53rendre(s), if s ends re
? conj14assie?ger(s), if s ends e?ger
? conj11jeter(s), if s ends eler or
eter
? conj10ce?der(s), if s ends e?der
? conj07placer(s), if s ends cer
? conj08manger(s), if s ends ger
? conj16payer(s), if s ends yer
? conj06parler(s), if s ends er
Notice that the cases must be applied in the given
order; for instance, the last case applies only to
those verbs ending with er that are not matched
by the earlier cases.
Also notice that the above paradigm is just
like the more traditional ones, in the sense that
we cannot be sure if it really applies to a given
verb. For instance, the verb partir ends with ir
and would hence receive the same inflection as
finir; however, its real conjugation is number 26
in Bescherelle. That mkV uses 19 rather than
number 26 has a good reason: a vast majority of
ir verbs is inflected in this conjugation, and it is
also the productive one, to which new ir verbs are
added.
Even though there is no mathematical differ-
ence between the mkV paradigm and the tradi-
tional paradigms like those in Bescherelle, there
is a reason to call mkV a smart paradigm. This
name implies two things. First, a smart paradigm
implements some ?artificial intelligence? to pick
the underlying ?stupid? paradigm. Second, a
smart paradigm uses heuristics (informed guess-
ing) if string matching doesn?t decide the matter;
the guess is informed by statistics of the distribu-
tions of different inflection classes.
One could thus say that smart paradigms are
?second-order? or ?meta-paradigms?, compared
to more traditional ones. They implement a
lot of linguistic knowledge and intelligence, and
thereby enable tasks such as lexicon building to
be performed with less expertise than before. For
instance, instead of ?07? for foncer and ?06?
for marcher, the lexicographer can simply write
?mkV? for all verbs instead of choosing from 88
numbers.
In fact, just ?V?, indicating that the word is
a verb, will be enough, since the name of the
paradigm depends only on the part of speech.
This follows the model of many dictionaries and
646
methods of language teaching, where character-
istic forms are used instead of paradigm identi-
fiers. For instance, another variant of mkV could
use as its second argument the first person plural
present indicative to decide whether an ir verb is
in conjugation 19 or in 26:
mkV : String2 ? String51
mkV(s, t) =
? conj26partir(s), if for some x, s =
x+ir and t = x+ons
? conj19finir(s), if s ends with ir
? (all the other cases that can be rec-
ognized by this extra form)
? mkV(s) otherwise (fall-back to the
one-argument paradigm)
In this way, a series of smart paradigms is built
for each part of speech, with more and more ar-
guments. The trick is to investigate which new
forms have the best discriminating power. For
ease of use, the paradigms should be displayed to
the user in an easy to understand format, e.g. as a
table specifying the possible argument lists:
verb parler
verb parler, parlons
verb parler, parlons, parlera, parla, parle?
noun chien
noun chien, masculine
noun chien, chiens, masculine
Notice that, for French nouns, the gender is listed
as one of the pieces of information needed for
lexicon building. In many cases, it can be in-
ferred from the dictionary form just like the in-
flection; for instance, that most nouns ending e
are feminine. A gender argument in the smart
noun paradigm makes it possible to override this
default behaviour.
2.1 Paradigms in GF
Smart paradigms as used in this paper have been
implemented in the GF programming language
(Grammatical Framework, (Ranta, 2011)). GF is
a functional programming lnguage enriched with
regular expressions. For instance, the following
function implements a part of the one-argument
French verb paradigm shown above. It uses a case
expression to pattern match with the argument s;
the pattern _ matches anything, while + divides a
string to two pieces, and | expresses alternation.
The functions conj19finir etc. are defined
elsewhere in the library. Function application is
expressed without parentheses, by the juxtaposi-
tion of the function and the argument.
mkV : Str -> V
mkV s = case s of {
_ + "ir" -> conj19finir s ;
_ + ("eler"|"eter")
-> conj11jeter s ;
_ + "er" -> conj06parler s ;
}
The GF Resource Grammar Library1 has
comprehensive smart paradigms for 18 lan-
guages: Amharic, Catalan, Danish, Dutch, En-
glish, Finnish, French, German, Hindi, Italian,
Nepalese, Norwegian, Romanian, Russian, Span-
ish, Swedish, Turkish, and Urdu. A few other lan-
guages have complete sets of ?traditional? inflec-
tion paradigms but no smart paradigms.
Six languages in the library have comprehen-
sive morphological dictionaries: Bulgarian (53k
lemmas), English (42k), Finnish (42k), French
(92k), Swedish (43k), and Turkish (23k). They
have been extracted from other high-quality re-
sources via conversions to GF using the paradigm
systems. In Section 4, four of them will be used
for estimating the strength of the smart paradigms,
that is, the predictability of each language.
3 Cost, predictability, and complexity
Given a languageL, a lexical category C, and a set
P of smart paradigms for C, the predictability of
the morphology of C in L by P depends inversely
on the average number of arguments needed to
generate the correct inflection table for a word.
The lower the number, the more predictable the
system.
Predictability can be estimated from a lexicon
that contains such a set of tables. Formally, a
smart paradigm is a family Pm of functions
Pm : String
m ? Stringn
where m ranges over some set of integers from 1
to n, but need not contain all those integers. A
lexicon L is a finite set of inflection tables,
L = {wi : String
n | i = 1, . . . ,ML}
1 Source code and documentation in http://www.
grammaticalframework.org/lib.
647
As the n is fixed, this is a lexicon specialized to
one part of speech. A word is an element of the
lexicon, that is, an inflection table of size n.
An application of a smart paradigm Pm to a
word w ? L is an inflection table resulting from
applying Pm to the appropriate subset ?m(w) of
the inflection table w,
Pm[w] = Pm(?m(w)) : String
n
Thus we assume that all arguments are existing
word forms (rather than e.g. stems), or features
such as the gender.
An application is correct if
Pm[w] = w
The cost of a word w is the minimum number of
arguments needed to make the application correct:
cost(w) = argmin
m
(Pm[w] = w)
For practical applications, it is useful to require
Pm to be monotonic, in the sense that increasing
m preserves correctness.
The cost of a lexicon L is the average cost for
its words,
cost(L) =
ML?
i=1
cost(wi)
ML
where ML is the number of words in the lexicon,
as defined above.
The predictability of a lexicon could be de-
fined as a quantity inversely dependent on its cost.
For instance, an information-theoretic measure
could be defined
predict(L) =
1
1 + log cost(L)
with the intuition that each added argument cor-
responds to a choice in a decision tree. However,
we will not use this measure in this paper, but just
the concrete cost.
The complexity of a paradigm system is de-
fined as the size of its code in a given coding
system, following the idea of Kolmogorov com-
plexity (Solomonoff, 1964). The notion assumes
a coding system, which we fix to be GF source
code. As the results are relative to the coding
system, they are only usable for comparing def-
initions in the same system. However, using GF
source code size rather than e.g. a finite automa-
ton size gives in our view a better approximation
of the ?cognitive load? of the paradigm system,
its ?learnability?. As a functional programming
language, GF permits abstractions comparable to
those available for human language learners, who
don?t need to learn the repetitive details of a finite
automaton.
We define the code complexity as the size of
the abstract syntax tree of the source code. This
size is given as the number of nodes in the syntax
tree; for instance,
? size(f(x1, . . . , xn)) = 1 +
n?
i=1
size(xi)
? size(s) = 1, for a string literal s
Using the abstract syntax size makes it possible
to ignore programmer-specific variation such as
identifier size. Measurements of the GF Resource
Grammar Library show that code size measured
in this way is in average 20% of the size of source
files in bytes. Thus a source file of 1 kB has the
code complexity around 200 on the average.
Notice that code complexity is defined in a way
that makes it into a straightforward generaliza-
tion of the cost of a word as expressed in terms
of paradigm applications in GF source code. The
source code complexity of a paradigm application
is
size(Pm[w]) = 1 +m
Thus the complexity for a word w is its cost plus
one; the addition of one comes from the applica-
tion node for the function Pm and corresponds to
knowing the part of speech of the word.
4 Experimental results
We conducted experiments in four languages (En-
glish, Swedish, French and Finnish2), presented
here in order of morphological richness. We used
trusted full form lexica (i.e. lexica giving the com-
plete inflection table of every word) to compute
the predictability, as defined above, in terms of
the smart paradigms in GF Resource Grammar Li-
brary.
We used a simple algorithm for computing the
cost c of a lexicon L with a set Pm of smart
paradigms:
2This choice correspond to the set of language for which
both comprehensive smart paradigms and morphological
dictionaries were present in GF with the exception of Turk-
ish, which was left out because of time constraints.
648
? set c := 0
? for each word wi in L,
? for each m in growing order for which
Pm is defined:
if Pm[w] = w, then c := c+m, else try
with next m
? return c
The average cost is c divided by the size of L.
The procedure presupposes that it is always
possible to get the correct inflection table. For
this to be true, the smart paradigms must have a
?worst case scenario? version that is able to gen-
erate all forms. In practice, this was not always
the case but we checked that the number of prob-
lematic words is so small that it wouldn?t be sta-
tistically significant. A typical problem word was
the equivalent of the verb be in each language.
Another source of deviation is that a lexicon
may have inflection tables with size deviating
from the number n that normally defines a lex-
ical category. Some words may be ?defective?,
i.e. lack some forms (e.g. the singular form
in ?plurale tantum? words), whereas some words
may have several variants for a given form (e.g.
learned and learnt in English). We made no ef-
fort to predict defective words, but just ignored
them. With variant forms, we treated a prediction
as correct if it matched any of the variants.
The above algorithm can also be used for help-
ing to select the optimal sets of characteristic
forms; we used it in this way to select the first
form of Swedish verbs and the second form of
Finnish nouns.
The results are collected in Table 1. The sec-
tions below give more details of the experiment in
each language.
4.1 English
As gold standard, we used the electronic version
of the Oxford Advanced Learner?s Dictionary of
Current English3 which contains about 40,000
root forms (about 70,000 word forms).
Nouns. We considered English nouns as hav-
ing only two forms (singular and plural), exclud-
ing the genitive forms which can be considered to
be clitics and are completely predictable. About
3available in electronic form at http://www.eecs.
qmul.ac.uk/?mpurver/software.html
one third of the nouns of the lexicon were not in-
cluded in the experiment because one of the form
was missing. The vast majority of the remaining
15,000 nouns are very regular, with predictable
deviations such as kiss - kisses and fly - flies which
can be easily predicted by the smart paradigm.
With the average cost of 1.05, this was the most
predictable lexicon in our experiment.
Verbs. Verbs are the most interesting category
in English because they present the richest mor-
phology. Indeed, as shown by Table 1, the cost
for English verbs, 1.21, is similar to what we got
for morphologically richer languages.
4.2 Swedish
As gold standard, we used the SALDO lexicon
(Borin et al 2008).
Nouns. The noun inflection tables had 8
forms (singular/plural indefinite/definite nomina-
tive/genitive) plus a gender (uter/neuter). Swedish
nouns are intrinsically very unpredictable, and
there are many examples of homonyms falling un-
der different paradigms (e.g. val - val ?choice? vs.
val -valar ?whale?). The cost 1.70 is the highest
of all the lexica considered. Of course, there may
be room for improving the smart paradigm.
Verbs. The verbs had 20 forms, which in-
cluded past participles. We ran two experiments,
by choosing either the infinitive or the present in-
dicative as the base form. In traditional Swedish
grammar, the base form of the verb is considered
to be the infinitive, e.g. spela, leka (?play? in
two different senses). But this form doesn?t dis-
tinguish between the ?first? and the ?second con-
jugation?. However, the present indicative, here
spelar, leker, does. Using it gives a predictive
power 1.13 as opposed to 1.22 with the infinitive.
Some modern dictionaries such as Lexin4 there-
fore use the present indicative as the base form.
4.3 French
For French, we used the Morphalou morpholog-
ical lexicon (Romary et al 2004). As stated in
the documentation5 the current version of the lex-
icon (version 2.0) is not complete, and in par-
ticular, many entries are missing some or all in-
flected forms. So for those experiments we only
4http://lexin.nada.kth.se/lexin/
5http://www.cnrtl.fr/lexiques/
morphalou/LMF-Morphalou.php#body_3.4.11,
accessed 2011-11-04
649
Table 1: Lexicon size and average cost for the nouns (N) and verbs (V) in four languages, with the percentage of
words correctly inferred from one and two forma (i.e. m = 1 and m ? 2, respectively).
Lexicon Forms Entries Cost m = 1 m ? 2
Eng N 2 15,029 1.05 95% 100%
Eng V 5 5,692 1.21 84% 95%
Swe N 9 59,225 1.70 46% 92%
Swe V 20 4,789 1.13 97% 97%
Fre N 3 42,390 1.25 76% 99%
Fre V 51 6,851 1.27 92% 94%
Fin N 34 25,365 1.26 87% 97%
Fin V 102 10,355 1.09 96% 99%
included entries where all the necessary forms
were presents.
Nouns: Nouns in French have two forms (sin-
gular and plural) and an intrinsic gender (mascu-
line or feminine), which we also considered to be
a part of the inflection table. Most of the unpre-
dictability comes from the impossibility to guess
the gender.
Verbs: The paradigms generate all of the sim-
ple (as opposed to compound) tenses given in tra-
ditional grammars such as the Bescherelle. Also
the participles are generated. The auxiliary verb
of compound tenses would be impossible to guess
from morphological clues, and was left out of
consideration.
4.4 Finnish
The Finnish gold standard was the KOTUS lexi-
con (Kotimaisten Kielten Tutkimuskeskus, 2006).
It has around 90,000 entries tagged with part
of speech, 50 noun paradigms, and 30 verb
paradigms. Some of these paradigms are rather
abstract and powerful; for instance, grade alterna-
tion would multiply many of the paradigms by a
factor of 10 to 20, if it was treated in a concate-
native way. For instance, singular nominative-
genitive pairs show alternations such as talo?talon
(?house?), katto?katon (?roof?), kanto?kannon
(?stub?), rako?raon (?crack?), and sato?sadon
(?harvest?). All of these are treated with one and
the same paradigm, which makes the KOTUS sys-
tem relatively abstract.
The total number of forms of Finnish nouns and
verbs is a question of definition. Koskenniemi
(Koskenniemi, 1983) reports 2000 for nouns and
12,000 for verbs, but most of these forms result by
adding particles and possessive suffixes in an ag-
glutinative way. The traditional number and case
count for nouns gives 26, whereas for verbs the
count is between 100 and 200, depending on how
participles are counted. Notice that the definition
of predictability used in this paper doesn?t depend
on the number of forms produced (i.e. not on n
but only on m); therefore we can simply ignore
this question. However, the question is interesting
if we think about paradigms as a data compression
method (Section 4.5).
Nouns. Compound nouns are a problem for
morphology prediction in Finnish, because inflec-
tion is sensitive to the vowel harmony and num-
ber of syllables, which depend on where the com-
pound boundary goes. While many compounds
are marked in KOTUS, we had to remove some
compounds with unmarked boundaries. Another
peculiarity was that adjectives were included in
nouns; this is no problem since the inflection pat-
terns are the same, if comparison forms are ig-
nored. The figure 1.26 is better than the one re-
ported in (Ranta, 2008), which is 1.42; the reason
is mainly that the current set of paradigms has a
better coverage of three-syllable nouns.
Verbs. Even though more numerous in forms
than nouns, Finnish verbs are highly predictable
(1.09).
4.5 Complexity and data compression
The cost of a lexicon has an effect on learnabil-
ity. For instance, even though Finnish words have
ten or a hundred times more forms than English
forms, these forms can be derived from roughly
the same number of characteristic forms as in En-
glish. But this is of course just a part of the truth:
it might still be that the paradigm system itself is
much more complex in some languages than oth-
650
Table 2: Paradigm complexities for nouns and verbs
in the four languages, computed as the syntax tree size
of GF code.
language noun verb total
English 403 837 991
Swedish 918 1039 1884
French 351 2193 2541
Finnish 4772 3343 6885
ers.
Following the definitions of Section 3, we have
counted the the complexity of the smart paradigm
definitions for nouns and verbs in the different
languages in the GF Resource Grammar Library.
Notice that the total complexity of the system is
lower than the sum of the parts, because many
definitions (such as morphophonological transfor-
mations) are reused in different parts of speech.
The results are in Table 2.
These figures suggest that Finnish indeed has a
more complex morphology than French, and En-
glish is the simplest. Of course, the paradigms
were not implemented with such comparisons in
mind, and it may happen that some of the differ-
ences come from different coding styles involved
in the collaboratively built library. Measuring
code syntax trees rather than source code text neu-
tralizes some of this variation (Section 3).
Finally, we can estimate the power of smart
paradigms as a data compression function. In a
sense, a paradigm is a function designed for the
very purpose of compressing a lexicon, and one
can expect better compression than with generic
tools such as bzip2. Table 3 shows the compres-
sion rates for the same full-form lexica as used
in the predictability experiment (Table 1). The
sizes are in kilobytes, where the code size for
paradigms is calculated as the number of con-
structors multiplied by 5 (Section 3). The source
lexicon size is a simple character count, similar to
the full-form lexicon.
Unexpectedly, the compression rate of the
paradigms improves as the number of forms in
the full-form lexicon increases (see Table 1 for
these numbers). For English and French nouns,
bzip2 is actually better. But of course, unlike
the paradigms, it also gives a global compression
over all entries in the lexicon. Combining the
two methods by applying bzip2 to the source code
gives, for the Finnish verb lexicon, a file of 60 kB,
which implies a joint compression rate of 227.
That the compression rates for the code can be
higher than the numbers of forms in the full-form
lexicon is explained by the fact that the gener-
ated forms are longer than the base forms. For
instance, the full-form entry of the Finnish verb
uida (?swim?) is 850 bytes, which means that the
average form size is twice the size of the basic
form.
5 Smart paradigms in lexicon building
Building a high-quality lexicon needs a lot of
manual work. Traditionally, when one is not writ-
ing all the forms by hand (which would be almost
impossible in languages with rich morphology),
sets of paradigms are used that require the lexi-
cographer to specify the base form of the word
and an identifier for the paradigm to use. This has
several usability problems: one has to remember
all the paradigm identifiers and choose correctly
from them.
Smart paradigm can make this task easier, even
accessible to non-specialist, because of their abil-
ity to guess the most probable paradigm from a
single base form. As shown by Table 1, this is
more often correct than not, except for Swedish
nouns. If this information is not enough, only a
few more forms are needed, requiring only prac-
tical knowledge of the language. Usually (92% to
100% in Table 1), adding a second form (m = 2)
is enough to cover all words. Then the best prac-
tice for lexicon writing might be always to give
these two forms instead of just one.
Smart paradigms can also be used for an auto-
matic bootstrapping of a list of base forms into a
full form lexicon. As again shown by the last col-
umn of Table 1, one form alone can provide an
excellent first approximation in most cases. What
is more, it is often the case that uncaught words
belong to a limited set of ?irregular? words, such
as the irregular verbs in many languages. All new
words can then be safely inferred from the base
form by using smart paradigms.
6 Related work
Smart paradigms were used for a study of Finnish
morphology in (Ranta, 2008). The present paper
can be seen as a generalization of that experiment
to more languages and with the notion of code
651
Table 3: Comparison between using bzip2 and paradigms+lexicon source as a compression method. Sizes in
kB.
Lexicon Fullform bzip2 fullform/bzip2 Source fullform/source
Eng N 264 99 2.7 135 2.0
Eng V 245 78 3.2 57 4.4
Swe N 6,243 1,380 4.5 1,207 5.3
Swe V 840 174 4.8 58 15
Fre N 952 277 3.4 450 2.2
Fre V 3,888 811 4.8 98 40
Fin N 11,295 2,165 5.2 343 34
Fin V 13,609 2,297 5.9 123 114
complexity. Also the paradigms for Finnish are
improved here (cf. Section 4.4 above).
Even though smart paradigm-like descriptions
are common in language text books, there is to
our knowledge no computational equivalent to the
smart paradigms of GF. Finite state morphology
systems often have a function called a guesser,
which, given a word form, tries to guess either
the paradigm this form belongs to or the dictio-
nary form (or both). A typical guesser differs
from a smart paradigms in that it does not make
it possible to correct the result by giving more
forms. Examples of guessers include (Chanod
and Tapanainen, 1995) for French, (Hlava?c?ova?,
2001) for Czech, and (Nakov et al 2003) for Ger-
man.
Another related domain is the unsupervised
learning of morphology where machine learning
is used to automatically build a language mor-
phology from corpora (Goldsmith, 2006). The
main difference is that with the smart paradigms,
the paradigms and the guess heuristics are imple-
mented manually and with a high certainty; in un-
supervised learning of morphology the paradigms
are induced from the input forms with much lower
certainty. Of particular interest are (Chan, 2006)
and (Dreyer and Eisner, 2011), dealing with the
automatic extraction of paradigms from text and
investigate how good these can become. The main
contrast is, again, that our work deals with hand-
written paradigms that are correct by design, and
we try to see how much information we can drop
before losing correctness.
Once given, a set of paradigms can be used in
automated lexicon extraction from raw data, as in
(Forsberg et al 2006) and (Cle?ment et al 2004),
by a method that tries to collect a sufficient num-
ber of forms to determine that a word belongs to a
certain paradigm. Smart paradigms can then give
the method to actually construct the full inflection
tables from the characteristic forms.
7 Conclusion
We have introduced the notion of smart
paradigms, which implement the linguistic
knowledge involved in inferring the inflection of
words. We have used the paradigms to estimate
the predictability of nouns and verbs in English,
Swedish, French, and Finnish. The main result
is that, with the paradigms used, less than two
forms in average is always enough. In half of the
languages and categories, one form is enough to
predict more than 90% of forms correctly. This
gives a promise for both manual lexicon building
and automatic bootstrapping of lexicon from
word lists.
To estimate the overall complexity of inflection
systems, we have also measured the size of the
source code for the paradigm systems. Unsurpris-
ingly, Finnish is around seven times as complex
as English, and around three times as complex as
Swedish and French. But this cost is amortized
when big lexica are built.
Finally, we looked at smart paradigms as a data
compression method. With simple morphologies,
such as English nouns, bzip2 gave a better com-
pression of the lexicon than the source code us-
ing paradigms. But with Finnish verbs, the com-
pression rate was almost 20 times higher with
paradigms than with bzip2.
The general conclusion is that smart paradigms
are a good investment when building morpho-
logical lexica, as they ease the task of both hu-
man lexicographers and automatic bootstrapping
652
methods. They also suggest a method to assess
the complexity and learnability of languages, re-
lated to Kolmogorov complexity. The results in
the current paper are just preliminary in this re-
spect, since they might still tell more about par-
ticular implementations of paradigms than about
the languages themselves.
Acknowledgements
We are grateful to the anonymous referees for
valuable remarks and questions. The research
leading to these results has received funding from
the European Union?s Seventh Framework Pro-
gramme (FP7/2007-2013) under grant agreement
no FP7-ICT-247914 (the MOLTO project).
References
[Beesley and Karttunen2003] Kenneth R. Beesley and
Lauri Karttunen. 2003. Finite State Morphology.
CSLI Publications.
[Bescherelle1997] Bescherelle. 1997. La conjugaison
pour tous. Hatier.
[Borin et al008] Lars Borin, Markus Forsberg, and
Lennart Lo?nngren. 2008. Saldo 1.0 (svenskt as-
sociationslexikon version 2). Spra?kbanken, 05.
[Chan2006] Erwin Chan. 2006. Learning probabilistic
paradigms for morphology in a latent class model.
In Proceedings of the Eighth Meeting of the ACL
Special Interest Group on Computational Phonol-
ogy and Morphology, SIGPHON ?06, pages 69?78,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
[Chanod and Tapanainen1995] Jean-Pierre Chanod
and Pasi Tapanainen. 1995. Creating a tagset,
lexicon and guesser for a french tagger. CoRR,
cmp-lg/9503004.
[Cle?ment et al004] Lionel Cle?ment, Beno??t Sagot,
and Bernard Lang. 2004. Morphology based au-
tomatic acquisition of large-coverage lexica. In
Proceedings of LREC-04, Lisboa, Portugal, pages
1841?1844.
[Dreyer and Eisner2011] Markus Dreyer and Jason
Eisner. 2011. Discovering morphological
paradigms from plain text using a dirichlet process
mixture model. In Proceedings of the Conference
on Empirical Methods in Natural Language Pro-
cessing, EMNLP ?11, pages 616?627, Stroudsburg,
PA, USA. Association for Computational Linguis-
tics.
[Forsberg et al006] Markus Forsberg, Harald Ham-
marstro?m, and Aarne Ranta. 2006. Morpholog-
ical Lexicon Extraction from Raw Text Data. In
T. Salakoski, editor, FinTAL 2006, volume 4139 of
LNCS/LNAI.
[Goldsmith2006] John Goldsmith. 2006. An Algo-
rithm for the Unsupervised Learning of Morphol-
ogy. Nat. Lang. Eng., 12(4):353?371.
[Hellberg1978] Staffan Hellberg. 1978. The Morphol-
ogy of Present-Day Swedish. Almqvist & Wiksell.
[Hlava?c?ova?2001] Jaroslava Hlava?c?ova?. 2001. Mor-
phological guesser of czech words. In Va?clav Ma-
tous?ek, Pavel Mautner, Roman Moucek, and Karel
Taus?er, editors, Text, Speech and Dialogue, volume
2166 of Lecture Notes in Computer Science, pages
70?75. Springer Berlin / Heidelberg.
[Kaplan and Kay1994] R. Kaplan and M. Kay. 1994.
Regular Models of Phonological Rule Systems.
Computational Linguistics, 20:331?380.
[Koskenniemi1983] Kimmo Koskenniemi. 1983.
Two-Level Morphology: A General Computational
Model for Word-Form Recognition and Production.
Ph.D. thesis, University of Helsinki.
[Kotimaisten Kielten Tutkimuskeskus2006]
Kotimaisten Kielten Tutkimuskeskus. 2006.
KOTUS Wordlist. http://kaino.kotus.
fi/sanat/nykysuomi.
[Nakov et al003] Preslav Nakov, Yury Bonev, and
et al2003. Guessing morphological classes of un-
known german nouns.
[Ranta2008] Aarne Ranta. 2008. How pre-
dictable is Finnish morphology? an experi-
ment on lexicon construction. In J. Nivre and
M. Dahllo?f and B. Megyesi, editor, Resource-
ful Language Technology: Festschrift in Honor
of Anna Sa?gvall Hein, pages 130?148. University
of Uppsala. http://publications.uu.se/
abstract.xsql?dbid=8933.
[Ranta2011] Aarne Ranta. 2011. Grammatical Frame-
work: Programming with Multilingual Grammars.
CSLI Publications, Stanford. ISBN-10: 1-57586-
626-9 (Paper), 1-57586-627-7 (Cloth).
[Romary et al004] Laurent Romary, Susanne
Salmon-Alt, and Gil Francopoulo. 2004. Standards
going concrete: from LMF to Morphalou. In The
20th International Conference on Computational
Linguistics - COLING 2004, Gene`ve/Switzerland.
coling.
[Solomonoff1964] Ray J. Solomonoff. 1964. A formal
theory of inductive inference: Parts 1 and 2. Infor-
mation and Control, 7:1?22 and 224?254.
653
Proceedings of the Demonstrations at the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 41?44,
Gothenburg, Sweden, April 26-30 2014.
c?2014 Association for Computational Linguistics
Speech-Enabled Hybrid Multilingual Translation for Mobile Devices
Krasimir Angelov
University of Gothenburg
krasimir@chalmers.se
Bj
?
orn Bringert
Google Inc
bringert@google.com
Aarne Ranta
University of Gothenburg
aarne@chalmers.se
Abstract
This paper presents an architecture and a
prototype for speech-to-speech translation
on Android devices, based on GF (Gram-
matical Framework). From the user?s
point of view, the advantage is that the
system works off-line and yet has a lean
size; it also gives, as a bonus, gram-
matical information useful for language
learners. From the developer?s point of
view, the advantage is the open architec-
ture that permits the customization of the
system to new languages and for special
purposes. Thus the architecture can be
used for controlled-language-like transla-
tors that deliver very high quality, which
is the traditional strength of GF. However,
this paper focuses on a general-purpose
system that allows arbitrary input. It cov-
ers eight languages.
1 Introduction
Many popular applications (apps) on mobile
devices are about language. They range
from general-purpose translators to tourist phrase
books, dictionaries, and language learning pro-
grams. Many of the apps are commercial and
based on proprietary resources and software. The
mobile APIs (both Android and iOS) make it easy
to build apps, and this provides an excellent way to
exploit and demonstrate computational linguistics
research, perhaps not used as much as it could.
GF (Grammatical Framework, (Ranta, 2011)) is
a grammar formalism designed for building multi-
lingual grammars and interfacing them with other
software systems. Both multilinguality and inter-
facing are based on the use of an abstract syntax,
a tree structure that captures the essence of syntax
and semantics in a language-neutral way. Transla-
tion in GF is organized as parsing the source lan-
guage input into an abstract syntax tree and then
linearizing the tree into the target language. Here
is an example of a simple question, as modelled by
an abstract syntax tree and linearized to four lan-
guages, which use different syntactic structures to
express the same content:
Query (What Age (Name ?Madonna?))
English: How old is Madonna?
Finnish: Kuinka vanha Madonna on?
French: Quel ?age a Madonna?
Italian: Quanti anni ha Madonna?
In recent years much focus in GF has been
put on cloud applications (Ranta et al., 2010) and
on mobile apps, for both Android (D?etrez and
Enache, 2010) and iOS (Djupfeldt, 2013). They
all implement text-based phrasebooks, whereas
Alum?ae and Kaljurand (2012) have built a speech-
enabled question-answering system for Estonian.
An earlier speech translation system in GF is pre-
sented in Bringert (2008).
All embedded GF systems are based on a
standardized run-time format of GF, called PGF
(Portable Grammar Format; Angelov et al. 2009,
Angelov 2011). PGF is a simple ?machine lan-
guage?, to which the much richer GF source lan-
guage is compiled by the GF grammar compiler.
PGF being simple, it is relatively straightforward
to write interpreters that perform parsing and lin-
earizations with PGF grammars. The first mobile
implementations were explicitly designed to work
on small devices with limited resources. Thus they
work fine for small grammars (with up to hun-
dreds of rules and lexical entries per language), but
they don?t scale up well into open-domain gram-
mars requiring a lexicon size of tens of thousands
of lemmas. Moreover, they don?t support out-of-
grammar input, and have no means of choosing
between alternative parse results, which in a large
grammar can easily amount to thousands of trees.
A new, more efficient and robust run-time sys-
tem for PGF was later written in C (Angelov,
2011). Its performance is competitive with the
41
state of the art in grammar-based parsing (Angelov
and Ljungl?of, 2014). This system uses statisti-
cal disambiguation and supports large-scale gram-
mars, such as an English grammar covering most
of the Penn Treebank. In addition, it is lean
enough to be embedded as an Android application
even with full-scale grammars, running even on
devices as old as the Nexus One from early 2010.
Small grammars limited to natural language
fragments, such as a phrasebook, are usable when
equipped with predictive parsing that can suggest
the next words in context. However, there is no
natural device for word suggestions with speech
input. The system must then require the user to
learn the input language; alternatively, it can be
reduced to simple keyword spotting. This can
be useful in information retrieval applications, but
hardly in translation. Any useful speech-enabled
translator must have wide coverage, and it cannot
be restricted to just translating keywords.
In this paper, we show a mobile system that
has a wide coverage and translates both text and
speech. The system is modular and could be eas-
ily adapted to traditional GF applications as well:
since the PGF format is the same, one can combine
any grammar with any run-time PGF interpreter.
The rest of the paper is organized as follows:
Section 2 describes the system?s functionalities
from the user?s point of view. Section 3 explains
the technology from the developer?s point of view.
Section 4 presents some preliminary results on the
usability of the system, and discusses some ways
of improving it. Section 5 concludes.
A proper quantitative evaluation of the transla-
tion quality has to wait till another occasion, and
will be more properly done in a context that ad-
dresses hybrid GF-based translation as a research
topic. Early attempts in this area have not yet con-
verged into a stable methodology, but we believe
that setting translation in the context of a practical
use case, as here, can help identify what issues to
focus on.
2 Functionalities
The app starts with the last-used language pair pre-
selected for input and output. It waits for speech
input, which is invoked by touching the micro-
phone icon. Once the input is finished, it appears
in text on the left side of the screen. Its translation
appears below it, on the right, and is also rendered
as speech (Figure 1 (a)).
(a) (b)
Figure 1: Translation between various languages
with (a) speech (b) text input.
The source and target languages are selected by
the two drop-down lists on the top of the screen.
The icon with two arrows to the right of the lan-
guage selectors allows the two languages to be
swapped quickly.
The speech recognition and text-to-speech
(TTS) is done using public Android APIs. On
most devices, these make use of Google?s speech
recognizer and synthesizer, which are available in
both online and offline versions. The offline en-
gines tend to have a reduced choice of languages
and reduced quality compared to the online en-
gines, but don?t require an internet connection.
Alternatively, the user can select the keyboard
mode. The microphone icon is then changed to a
keyboard icon, which opens a software keyboard
and shows a text field for entering a new phrase.
Once the phrase is translated, it is shown on the
screen but also sent to TTS (Figure 1 (b)).
If the input consists of a single lexical unit,
the user can open a dictionary description for the
word. The resulting screen shows the base form
of the word, followed by a list of possible transla-
tions. The target language is shown on the top of
the screen and it can be changed to see the transla-
tions in the other languages (Figure 2 (a)). Touch-
ing one of the translations opens a full-form in-
flection table together with other grammatical in-
formation about the word, such as gender and verb
valency (Figure 2 (b)).
Finally, the translator also works as an input
mode for other apps such as SMS. It provides a
soft keyboard, which is similar to the standard An-
droid keyboard, except that it has two more keys
allowing the entered phrase to be translated in-
place from inside any other application.
42
(a) (b)
Figure 2: (a) Results of dictionary lookup. (b) Va-
lency and the inflection table for a Bulgarian verb.
3 Technology
3.1 Run-time processing
The core of the system is the C runtime for PGF
(Angelov, 2011). The runtime is compiled to na-
tive code with the Android NDK and is called via
foreign function interface from the user interface,
which is implemented in Java.
The main challenge in using the runtime on mo-
bile devices is that even the latest models are still
several times slower that a modern laptop. For in-
stance, just loading the grammars for English and
Bulgarian, on a mobile device initially took about
28 seconds, while the same task is a negligible
operation on a normal computer. We spent con-
siderable time on optimizing the grammar loader
and the translator in general. Now the same gram-
mar, when loaded sequentially, takes only about
5-6 seconds. Furthermore, we made the grammar
loader parallel, i.e. it loads each language in par-
allel. The user interface runs in yet another thread,
so while the grammar is loading, the user can al-
ready start typing or uttering a sentence. In addi-
tion, we made it possible to load only those lan-
guages that are actually used, i.e. only two at a
time instead of all eight at once.
Parsing is a challenge in itself. As the grammars
grow bigger, there tends to be more and more need
for disambiguation. This is performed by a statis-
tical model, where each abstract syntax tree node
has weight. We used the method of Angelov and
Ljungl?of (2014) to find the best tree.
Moreover, since any sound grammar is likely to
fail on some input, there is need for robustness.
This has been solved by chunking the input into
maximal parsable bits. As a result, the translations
are not always grammatically correct, because de-
Bulgarian 26664 French 19570
Chinese 17050 German 9992
English 65009 Hindi 33841
Finnish 57036 Swedish 24550
Table 1: Lexical coverage (lemmas)
pendencies between chunks, such as agreement,
get lost. This kind of errors are familiar to anyone
who has used a statistical system such as Google
translate. In the GF system it is easy to avoid them,
provided the parse is complete.
3.2 The language component
The language-specific component of the app is the
PGF grammar, which contains both the grammars
proper and the probabilistic model of the abstract
syntax. The app can be adaptad to a different PGF
grammar by changing a few lines of the source
code. Hence any grammar written in GF is readily
usable as the language component of an app. But
here we focus on the large-scale grammar meant
for robust translation.
The core of the grammar is the GF Resource
Grammar Library (Ranta, 2009), which currently
covers 29 languages. Of these, 8 have been ex-
tended with more syntax rules (about 20% in ad-
dition to the standard library) and a larger lexi-
con. Table 1 shows the list of languages together
with the size of the lexicon for each of them. The
abstract syntax is based on English lemmas and
some split word senses of them. The other lan-
guages, having fewer words than English, are thus
incomplete. Unknown words are rendered by ei-
ther showing them in English (if included in the
English lexicon) or just returning them verbatim
(typical for named entities).
The lexicon has been bootstrapped from various
freely available sources, such as linked WordNets
and the Wiktionary. Parts of the lexicon have been
checked or completely written manually.
4 First results
The most striking advantage of the translation app
is its lean size: currently just 18Mb for the whole
set of 8 languages, allowing translation for 56
language pairs. This can be compared with the
size of about 200Mb for just one language pair
in Google?s translation app used off-line. The
Apertium off-line app is between these two, using
around 2MB per language pair.
43
The speed is still an issue. While the app
now loads smoothly on modern hardware (such
as Nexus 5 phones), translation is usually much
slower than in Google and Apertium apps. The
speed depends heavily on the complexity of the
source language, with Finnish and French the
worst ones, and on sentence length. Only with
short sentences (under ten words) from Bulgarian,
Chinese, English, and Swedish, does the translator
deliver satisfactory speed. On the other hand, long
sentences entered via speech are likely to con-
tain speech recognition errors, which makes their
translation pointless anyway.
Translating single words is based on a simpler
algorithm (dictionary lookup) and is therefore im-
mediate; together with the grammatical informa-
tion displayed, this makes single word translation
into the most mature feature of the app so far.
The translation quality and coverage are rea-
sonable in phrasebook-like short and simple sen-
tences. The app has exploited some idiomatic con-
structions of the earlier GF phrasebook (D?etrez
and Enache, 2010), so that it can correctly switch
the syntactic structure and translate e.g. how old
are you to French as quel ?age as-tu. In many other
cases, the results are unidiomatic word-to-word
translations but still grammatical. For instance,
hur mycket ?ar klockan, which should give what is
the time, returns how mighty is the bell. Such short
idioms are typically correct in Google?s translation
app, and collecting them into the GF resources will
be an important future task.
On the plus side, grammar-based translation is
more predictable than statistical. Thus (currently)
when using Google translate from Swedish to En-
glish, both min far ?ar svensk and its negation min
far ?ar inte svensk come out as the positive sen-
tence my father is Swedish. With grammar-based
translation, such semantic errors can be avoided.
5 Conclusion
We have presented a platform for mobile transla-
tion apps based on GF grammars, statistical dis-
ambiguation, and chunking-based robustness, en-
hanced by Android?s off-the-shelf speech input
and output. The platform is demonstrated by a
system that translates fairly open text between 8
languages, with reasonable performance for short
sentences but slow parsing for longer ones, with
moreover lower quality due to more parse errors.
The processing modules, user interface, and the
language resources are available as open source
software and thereby usable for the community
for building other systems with similar function-
alities. As the app is a front end to a grammati-
cal language resource, it can also be used for other
language-aware tasks such as learning apps; this is
illustrated in the demo app by the display of inflec-
tion tables. The app and its sources are available
via http://www.grammaticalframework.org.
References
Tanel Alum?ae and Kaarel Kaljurand. 2012. Open and
extendable speech recognition application architec-
ture for mobile environments. The Third Interna-
tional Workshop on Spoken Languages Technologies
for Under-resourced Languages (SLTU 2012), Cape
Town, South Africa.
Krasimir Angelov and Peter Ljungl?of. 2014. Fast
statistical parsing with parallel multiple context-free
grammars. In European Chapter of the Association
for Computational Linguistics, Gothenburg.
Krasimir Angelov, Bj?orn Bringert, and Aarne Ranta.
2009. PGF: A Portable Run-Time Format for Type-
Theoretical Grammars. Journal of Logic, Language
and Information, 19(2), pp. 201?228.
Krasimir Angelov. 2011. The Mechanics of the Gram-
matical Framework. Ph.D. thesis, Chalmers Univer-
sity of Technology.
Bj?orn Bringert. 2008. Speech translation with Gram-
matical Framework. In Coling 2008: Proceedings of
the workshop on Speech Processing for Safety Crit-
ical Translation and Pervasive Applications, pages
5?8, Manchester, UK, August. Coling 2008 Orga-
nizing Committee.
Gr?egoire D?etrez and Ramona Enache. 2010. A frame-
work for multilingual applications on the android
platform. In Swedish Language Technology Confer-
ence.
Emil Djupfeldt. 2013. Grammatical framework on the
iphone using a C++ PGF parser. Technical report,
Chalmers Univerity of Technology.
Aarne Ranta, Krasimir Angelov, and Thomas Hallgren.
2010. Tools for multilingual grammar-based trans-
lation on the web. In Proceedings of the ACL 2010
System Demonstrations, ACLDemos ?10, pages 66?
71, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.
Aarne Ranta. 2009. The GF resource grammar library.
Linguistic Issues in Language Technology.
Aarne Ranta. 2011. Grammatical Framework: Pro-
gramming with Multilingual Grammars. CSLI Pub-
lications, Stanford. ISBN-10: 1-57586-626-9 (Pa-
per), 1-57586-627-7 (Cloth).
44
Proceedings of the ACL 2010 System Demonstrations, pages 66?71,
Uppsala, Sweden, 13 July 2010. c?2010 Association for Computational Linguistics
Tools for Multilingual Grammar-Based Translation on the Web
Aarne Ranta and Krasimir Angelov and Thomas Hallgren
Department of Computer Science and Engineering
Chalmers University of Technology and University of Gothenburg
aarne@chalmers.se, krasimir@chalmers.se, hallgren@chalmers.se
Abstract
This is a system demo for a set of tools for
translating texts between multiple languages
in real time with high quality. The translation
works on restricted languages, and is based on
semantic interlinguas. The underlying model
is GF (Grammatical Framework), which is an
open-source toolkit for multilingual grammar
implementations. The demo will cover up to
20 parallel languages.
Two related sets of tools are presented: gram-
marian?s tools helping to build translators for
new domains and languages, and translator?s
tools helping to translate documents. The
grammarian?s tools are designed to make it
easy to port the technique to new applications.
The translator?s tools are essential in the re-
stricted language context, enabling the author
to remain in the fragments recognized by the
system.
The tools that are demonstrated will be ap-
plied and developed further in the European
project MOLTO (Multilingual On-Line Trans-
lation) which has started in March 2010 and
runs for three years.
1 Translation Needs for the Web
The best-known translation tools on the web are
Google translate1 and Systran2. They are targeted to
consumers of web documents: users who want to find
out what a given document is about. For this purpose,
browsing quality is sufficient, since the user has in-
telligence and good will, and understands that she uses
the translation at her own risk.
Since Google and Systran translations can be gram-
matically and semantically flawed, they don?t reach
publication quality, and cannot hence be used by
the producers of web documents. For instance, the
provider of an e-commerce site cannot take the risk that
the product descriptions or selling conditions have er-
rors that change the original intentions.
There are very few automatic translation systems ac-
tually in use for producers of information. As already
1www.google.com/translate
2www.systransoft.com
noted by Bar-Hillel (1964), machine translation is one
of those AI-complete tasks that involves a trade-off be-
tween coverage and precision, and the current main-
stream systems opt for coverage. This is also what web
users expect: they want to be able to throw just any-
thing at the translation system and get something useful
back. Precision-oriented approaches, the prime exam-
ple of which is METEO (Chandioux 1977), have not
been popular in recent years.
However, from the producer?s point of view, large
coverage is not essential: unlike the consumer?s tools,
their input is predictable, and can be restricted to very
specific domains, and to content that the producers
themselves are creating in the first place. But even in
such tasks, two severe problems remain:
? The development cost problem: a large amount
of work is needed for building translators for new
domains and new languages.
? The authoring problem: since the method does
not work for all input, the author of the source text
of translation may need special training to write in
a way that can be translated at all.
These two problems have probably been the main
obstacles to making high-quality restricted language
translation more wide-spread in tasks where it would
otherwise be applicable. We address these problems by
providing tools that help developers of translation sys-
tems on the one hand, and authors and translators?i.e.
the users of the systems?on the other.
In the MOLTO project (Multilingual On-Line Trans-
lation)3, we have the goal to improve both the devel-
opment and use of restricted language translation by an
order of magnitude, as compared with the state of the
art. As for development costs, this means that a sys-
tem for many languages and with adequate quality can
be built in a matter of days rather than months. As
for authoring, this means that content production does
not require the use of manuals or involve trial and er-
ror, both of which can easily make the work ten times
slower than normal writing.
In the proposed system demo, we will show how
some of the building blocks for MOLTO can already
now be used in web-based translators, although on a
3 www.molto-project.eu
66
Figure 1: A multilingual GF grammar with reversible
mappings from a common abstract syntax to the 15 lan-
guages currently available in the GF Resource Gram-
mar Library.
smaller scale as regards languages and application do-
mains. A running demo system is available at http:
//grammaticalframework.org:41296.
2 Multilingual Grammars
The translation tools are based on GF, Grammati-
cal Framework4 (Ranta 2004). GF is a grammar
formalism?that is, a mathematical model of natural
language, equipped with a formal notation for writ-
ing grammars and a computer program implementing
parsing and generation which are declaratively defined
by grammars. Thus GF is comparable with formalism
such as HPSG (Pollard and Sag 1994), LFG (Bresnan
1982) or TAG (Joshi 1985). The novel feature of GF is
the notion of multilingual grammars, which describe
several languages simultaneously by using a common
representation called abstract syntax; see Figure 1.
In a multilingual GF grammar, meaning-preserving
translation is provided as a composition of parsing and
generation via the abstract syntax, which works as an
interlingua. This model of translation is different from
approaches based on other comparable grammar for-
malisms, such as synchronous TAGs (Shieber and Sch-
abes 1990), Pargram (Butt & al. 2002, based on LFG),
LINGO Matrix (Bender and Flickinger 2005, based
on HPSG), and CLE (Core Language Engine, Alshawi
1992). These approaches use transfer rules between
individual languages, separate for each pair of lan-
guages.
Being interlingua-based, GF translation scales up
linearly to new languages without the quadratic blow-
up of transfer-based systems. In transfer-based sys-
4www.grammaticalframework.org
tems, as many as n(n? 1) components (transfer func-
tions) are needed to cover all language pairs in both di-
rections. In an interlingua-based system, 2n + 1 com-
ponents are enough: the interlingua itself, plus trans-
lations in both directions between each language and
the interlingua. However, in GF, n + 1 components
are sufficient, because the mappings from the abstract
syntax to each language (the concrete syntaxes) are
reversible, i.e. usable for both generation and parsing.
Multilingual GF grammars can be seen as an imple-
mentation of Curry?s distinction between tectogram-
matical and phenogrammatical structure (Curry
1961). In GF, the tectogrammatical structure is called
abstract syntax, following standard computer science
terminology. It is defined by using a logical frame-
work (Harper & al. 1993), whose mathematical basis
is in the type theory of Martin-Lo?f (1984). Two things
can be noted about this architecture, both showing im-
provements over state-of-the-art grammar-based trans-
lation methods.
First, the translation interlingua (the abstract syntax)
is a powerful logical formalism, able to express se-
mantical structures such as context-dependencies and
anaphora (Ranta 1994). In particular, dependent types
make it more expressive than the type theory used in
Montague grammar (Montague 1974) and employed in
the Rosetta translation project (Rosetta 1998).
Second, GF uses a framework for interlinguas,
rather than one universal interlingua. This makes the
interlingual approach more light-weight and feasible
than in systems assuming one universal interlingua,
such as Rosetta and UNL, Universal Networking Lan-
guage5. It also gives more precision to special-purpose
translation: the interlingua of a GF translation system
(i.e. the abstract syntax of a multilingual grammar) can
encode precisely those structures and distinctions that
are relevant for the task at hand. Thus an interlingua
for mathematical proofs (Hallgren and Ranta 2000) is
different from one for commands for operating an MP3
player (Perera and Ranta 2007). The expressive power
of the logical framework is sufficient for both kinds of
tasks.
One important source of inspiration for GF was the
WYSIWYM system (Power and Scott 1998), which
used domain-specific interlinguas and produced excel-
lent quality in multilingual generation. But the gener-
ation components were hard-coded in the program, in-
stead of being defined declaratively as in GF, and they
were not usable in the direction of parsing.
3 Grammars and Ontologies
Parallel to the first development efforts of GF in the
late 1990?s, another framework idea was emerging in
web technology: XML, Extensible Mark-up Language,
which unlike HTML is not a single mark-up language
but a framework for creating custom mark-up lan-
5www.undl.org
67
guages. The analogy between GF and XML was seen
from the beginning, and GF was designed as a for-
malism for multilingual rendering of semantic content
(Dymetman and al. 2000). XML originated as a format
for structuring documents and structured data serializa-
tion, but a couple of its descendants, RDF(S) and OWL,
developed its potential to formally express the seman-
tics of data and content, serving as the fundaments of
the emerging Semantic Web.
Practically any meaning representation format can
be converted into GF?s abstract syntax, which can then
be mapped to different target languages. In particular
the OWL language can be seen as a syntactic sugar for
a subset of Martin-Lo?f?s type theory so it is trivial to
embed it in GF?s abstract syntax.
The translation problem defined in terms of an on-
tology is radically different from the problem of trans-
lating plain text from one language to another. Many
of the projects in which GF has been used involve pre-
cisely this: a meaning representation formalized as GF
abstract syntax. Some projects build on previously ex-
isting meaning representation and address mathemati-
cal proofs (Hallgren and Ranta 2000), software speci-
fications (Beckert & al. 2007), and mathematical exer-
cises (the European project WebALT6). Other projects
start with semantic modelling work to build meaning
representations from scratch, most notably ones for di-
alogue systems (Perera and Ranta 2007) in the Euro-
pean project TALK7. Yet another project, and one clos-
est to web translation, is the multilingual Wiki sys-
tem presented in (Meza Moreno and Bringert 2008).
In this system, users can add and modify reviews of
restaurants in three languages (English, Spanish, and
Swedish). Any change made in any of the languages
gets automatically translated to the other languages.
To take an example, the OWL-to-GF mapping trans-
lates OWL?s classes to GF?s categories and OWL?s
properties to GF?s functions that return propositions.
As a running example in this and the next sec-
tion, we will use the class of integers and the
two-place property of being divisible (?x is divis-
ible by y?). The correspondences are as follows:
Class(pp:integer ...)
m
cat integer
ObjectProperty(pp:div
domain(pp:integer)
range(pp:integer))
m
fun div :
integer -> integer -> prop
4 Grammar Engineer?s Tools
In the GF setting, building a multilingual translation
system is equivalent to building a multilingual GF
6EDC-22253, webalt.math.helsinki.fi
7IST-507802, 2004?2006, www.talk-project.org
grammar, which in turn consists of two kinds of com-
ponents:
? a language-independent abstract syntax, giving
the semantic model via which translation is per-
formed;
? for each language, a concrete syntax mapping ab-
stract syntax trees to strings in that language.
While abstract syntax construction is an extra task com-
pared to many other kinds of translation methods, it is
technically relatively simple, and its cost is moreover
amortized as the system is extended to new languages.
Concrete syntax construction can be much more de-
manding in terms of programming skills and linguis-
tic knowledge, due to the complexity of natural lan-
guages. This task is where GF claims perhaps the high-
est advantage over other approaches to special-purpose
grammars. The two main assets are:
? Programming language support: GF is a modern
functional programming language, with a pow-
erful type system and module system supporting
modular and collaborative programming and reuse
of code.
? RGL, the GF Resource Grammar Library, im-
plementing the basic linguistic details of lan-
guages: inflectional morphology and syntactic
combination functions.
The RGL covers fifteen languages at the moment,
shown in Figure 1; see also Khegai 2006, El Dada and
Ranta 2007, Angelov 2008, Ranta 2009a,b, and Enache
et al 2010. To give an example of what the library
provides, let us first consider the inflectional morphol-
ogy. It is presented as a set of lexicon-building func-
tions such as, in English,
mkV : Str -> V
i.e. function mkV, which takes a string (Str) as its ar-
gument and returns a verb (V) as its value. The verb
is, internally, an inflection table containing all forms
of a verb. The function mkV derives all these forms
from its argument string, which is the infinitive form. It
predicts all regular variations: (mkV "walk") yields
the purely agglutinative forms walk-walks-walked-
walked-walking whereas (mkV "cry") gives cry-
cries-cried-cried-crying, and so on. For irregular En-
glish verbs, RGL gives a three-argument function tak-
ing forms such as sing,sang,sung, but it also has a fairly
complete lexicon of irregular verbs, so that the nor-
mal application programmer who builds a lexicon only
needs the regular mkV function.
Extending a lexicon with domain-specific vocabu-
lary is typically the main part of the work of a con-
crete syntax author. Considerable work has been put
into RGL?s inflection functions to make them as ?in-
telligent? as possible and thereby ease the work of the
68
users of the library, who don?t know the linguistic de-
tails of morphology. For instance, even Finnish, whose
verbs have hundreds of forms and are conjugated in
accordance with around 50 conjugations, has a one-
argument function mkV that yields the correct inflection
table for 90% of Finnish verbs.
As an example of a syntactic combination function
of RGL, consider a function for predication with two-
place adjectives. This function takes three arguments: a
two-place adjective, a subject noun phrase, and a com-
plement noun phrase. It returns a sentence as value:
pred : A2 -> NP -> NP -> S
This function is available in all languages of RGL, even
though the details of sentence formation are vastly dif-
ferent in them. Thus, to give the concrete syntax of the
abstract (semantical) predicate div x y (?x is divisi-
ble by y?), the English grammarian can write
div x y = pred
(mkA2 "divisible" "by") x y
The German grammarian can write
div x y = pred
(mkA2 "teilbar" durch_Prep) x y
which, even though superficially using different forms
from English, generates a much more complex struc-
ture: the complement preposition durch Prep takes
care of rendering the argument y in the accusative case,
and the sentence produced has three forms, as needed
in grammatically different positions (x ist teilbar durch
y in main clauses, ist x teilbar durch y after adverbs,
and x durch y teilbar ist in subordinate clauses).
The syntactic combinations of the RGL have their
own abstract syntax, but this abstract syntax is not the
interlingua of translation: it is only used as a library for
implementing the semantic interlingua, which is based
on an ontology and abstracts away from syntactic struc-
ture. Thus the translation equivalents in a multilingual
grammar need not use the same syntactic combinations
in different languages. Assume, for the sake of argu-
ment, that x is divisible by y is expressed in Swedish
by the transitive verb construction y delar x (literally,
?y divides x?). This can be expressed easily by using
the transitive verb predication function of the RGL and
switching the subject and object,
div x y = pred (mkV2 "dela") y x
Thus, even though GF translation is interlingua-based,
there is a component of transfer between English and
Swedish. But this transfer is performed at compile
time. In general, the use of the large-coverage RGL as a
library for restricted grammars is called grammar spe-
cialization. The way GF performs grammar specializa-
tion is based on techniques for optimizing functional
programming languages, in particular partial evalua-
tion (Ranta 2004, 2007). GF also gives a possibility to
run-time transfer via semantic actions on abstract syn-
tax trees, but this option has rarely been needed in pre-
vious applications, which helps to keep translation sys-
tems simple and efficient.
Figure 2: French word prediction in GF parser, sug-
gesting feminine adjectives that agree with the subject
la femme.
As shown in Figure 1, the RGL is currently avail-
able for 15 languages, of which 12 are official lan-
guages of the European Union. A similar number of
new languages are under construction in this collabo-
rative open-source project. Implementing a new lan-
guage is an effort of 3?6 person months.
5 Translator?s Tools
For the translator?s tools, there are three different use
cases:
? restricted source
? production of source in the first place
? modifying source produced earlier
? unrestricted source
Working with restricted source language recognizable
by a GF grammar is straightforward for the translating
tool to cope with, except when there is ambiguity in the
text. The real challenge is to help the author to keep in-
side the restricted language. This help is provided by
predictive parsing, a technique recently developed for
GF (Angelov 2009)8. Incremental parsing yields word
predictions, which guide the author in a way similar
to the T9 method9 in mobile phones. The difference
from T9 is that GF?s word prediction is sensitive to the
grammatical context. Thus it does not suggest all exist-
ing words, but only those words that are grammatically
correct in the context. Figure 2 shows an example of
the parser at work. The author has started a sentence as
la femme qui remplit le formulaire est co (?the woman
who fills the form is co?), and a menu shows a list of
words beginning with co that are given in the French
grammar and possible in the context at hand; all these
words are adjectives in the feminine form. Notice that
the very example shown in Figure 2 is one that is diffi-
cult for n-gram-based statistical translators: the adjec-
tive is so far from the subject with which it agrees that
it cannot easily be related to it.
Predictive parsing is a good way to help users pro-
duce translatable content in the first place. When mod-
ifying the content later, e.g. in a wiki, it may not be
optimal, in particular if the text is long. The text can
8 Parsing in GF is polynomial with an arbitrary exponent
in the worst case, but, as shown in Angelov 2009, linear in
practice with realistic grammars.
9www.t9.com
69
Pred known A (Rel woman N (Compl
fill V2 form N))
the woman who fills the form is known
la femme qui remplit le formulaire est connue
??
Pred known A (Rel man N (Compl fill V2
form N))
the man who fills the form is known
l? homme qui remplit le formulaire est connu
Figure 3: Change in one word (boldface) propagated to
other words depending on it (italics).
contain parts that depend on each other but are located
far apart. For instance, if the word femme (?woman?) in
the previous example is changed to homme, the preced-
ing article la has to be changed to l?, and the adjective
has to be changed to the masculine form: thus con-
nue (?known?) would become connu, and so on. Such
changes are notoriously difficult even for human au-
thors and translators, and can easily leave a document
in an inconsistent state. This is where another utility
of the abstract syntax comes in: in the abstract syntax
tree, all that is changed is the noun, and the regener-
ated concrete syntax string automatically obeys all the
agreement rules. The process is shown in Figure 3. The
one-word change generating the new set of documents
can be performed by editing any of the three represen-
tations: the tree, the English version, or the French ver-
sion. This functionality is implemented in the GF syn-
tax editor (Khegai & al. 2003).
Restricted languages in the sense of GF are close to
controlled languages, such as Attempto (Fuchs & al.
2008); the examples shown in this section are actually
taken from a GF implementation that generalizes At-
tempto Controlled English to five languages (Angelov
and Ranta 2009). However, unlike typical controlled
languages, GF does not require the absence of ambigu-
ity. In fact, when a controlled language is generalized
to new languages, lexical ambiguities in particular are
hard to avoid.
The predictive parser of GF does not try to resolve
ambiguities, but simply returns all alternatives in the
parse chart. If the target language has exactly the same
ambiguity, it remains hidden in the translation. But if
the ambiguity does make a difference in translation, it
has to be resolved, and the system has to provide a pos-
sibility of manual disambiguation by the user to guar-
antee high quality.
The translation tool snapshot in Figure 2 is from
an actual web-based prototype. It shows a slot in an
HTML page, built by using JavaScript via the Google
Web Toolkit (Bringert & al. 2009). The translation
is performed using GF in a server, which is called via
HTTP. Also client-side translators, with similar user in-
terfaces, can be built by converting the whole GF gram-
mar to JavaScript (Meza Moreno and Bringert 2008).
6 The Demo
In the demo, we will show
? how a simple translation system is built and com-
piled by using the GF grammar compiler and the
resource grammar library
? how the translator is integrated in a web page
? how the translator is used in a web browser by
means of an integrated incremental parser
A preliminary demo can be seen in http://
grammaticalframework.org:41296. All the
demonstrated tools are available as open-source soft-
ware from http://grammaticalframework.
org.
The work reported here is supported by MOLTO
(Multilingual On-Line Translation. FP7-ICT-247914).
References
Alshawi, H. (1992). The Core Language Engine. Cam-
bridge, Ma: MIT Press.
Angelov, K. (2008). Type-Theoretical Bulgarian
Grammar. In B. Nordstro?m and A. Ranta (Eds.),
Advances in Natural Language Processing (Go-
TAL 2008), Volume 5221 of LNCS/LNAI, pp. 52?
64. URL http://www.springerlink.com/
content/978-3-540-85286-5/.
Angelov, K. (2009). Incremental Parsing with Parallel
Multiple Context-Free Grammars. In Proceedings of
EACL?09, Athens.
Angelov, K. and A. Ranta (2009). Implementing Con-
trolled Languages in GF. In Proceedings of CNL-
2009, Marettimo, LNCS. to appear.
Bar-Hillel, Y. (1964). Language and Information.
Reading, MA: Addison-Wesley.
Beckert, B., R. Ha?hnle, and P. H. Schmitt (Eds.) (2007).
Verification of Object-Oriented Software: The KeY
Approach. LNCS 4334. Springer-Verlag.
Bender, E. M. and D. Flickinger (2005). Rapid
prototyping of scalable grammars: Towards mod-
ularity in extensions to a language-independent
core. In Proceedings of the 2nd International
Joint Conference on Natural Language Process-
ing IJCNLP-05 (Posters/Demos), Jeju Island, Ko-
rea. URL http://faculty.washington.
edu/ebender/papers/modules05.pdf.
Bresnan, J. (Ed.) (1982). The Mental Representation of
Grammatical Relations. MIT Press.
Bringert, B., K. Angelov, and A. Ranta (2009). Gram-
matical Framework Web Service. In Proceedings of
EACL?09, Athens.
70
Butt, M., H. Dyvik, T. H. King, H. Masuichi,
and C. Rohrer (2002). The Parallel Grammar
Project. In COLING 2002, Workshop on Gram-
mar Engineering and Evaluation, pp. 1?7. URL
http://www2.parc.com/isl/groups/
nltt/pargram/buttetal-coling02.pdf.
Chandioux, J. (1976). ME?TE?O: un syste`me
ope?rationnel pour la traduction automatique des bul-
letins me?te?reologiques destine?s au grand public.
META 21, 127?133.
Curry, H. B. (1961). Some logical aspects of gram-
matical structure. In R. Jakobson (Ed.), Structure of
Language and its Mathematical Aspects: Proceed-
ings of the Twelfth Symposium in Applied Mathemat-
ics, pp. 56?68. American Mathematical Society.
Dada, A. E. and A. Ranta (2007). Implementing an
Open Source Arabic Resource Grammar in GF. In
M. Mughazy (Ed.), Perspectives on Arabic Linguis-
tics XX, pp. 209?232. John Benjamin?s.
Dean, M. and G. Schreiber (2004). OWL Web On-
tology Language Reference. URL http://www.
w3.org/TR/owl-ref/.
Dymetman, M., V. Lux, and A. Ranta (2000).
XML and multilingual document author-
ing: Convergent trends. In COLING,
Saarbru?cken, Germany, pp. 243?249. URL
http://www.cs.chalmers.se/?aarne/
articles/coling2000.ps.gz.
Enache, R., A. Ranta, and K. Angelov (2010). An
Open-Source Computational Grammar for Roma-
nian. In A. Gelbukh (Ed.), Intelligent Text Process-
ing and Computational Linguistics (CICLing-2010),
Iasi, Romania, March 2010, LNCS, to appear.
Fuchs, N. E., K. Kaljurand, and T. Kuhn (2008).
Attempto Controlled English for Knowledge Rep-
resentation. In C. Baroglio, P. A. Bonatti,
J. Ma?uszyn?ski, M. Marchiori, A. Polleres, and
S. Schaffert (Eds.), Reasoning Web, Fourth Inter-
national Summer School 2008, Number 5224 in
Lecture Notes in Computer Science, pp. 104?124.
Springer.
Hallgren, T. and A. Ranta (2000). An exten-
sible proof text editor. In M. Parigot and
A. Voronkov (Eds.), LPAR-2000, Volume 1955
of LNCS/LNAI, pp. 70?84. Springer. URL
http://www.cs.chalmers.se/?aarne/
articles/lpar2000.ps.gz.
Harper, R., F. Honsell, and G. Plotkin (1993). A
Framework for Defining Logics. JACM 40(1), 143?
184.
Joshi, A. (1985). Tree-adjoining grammars: How
much context-sensitivity is required to provide rea-
sonable structural descriptions. In D. Dowty,
L. Karttunen, and A. Zwicky (Eds.), Natural Lan-
guage Parsing, pp. 206?250. Cambridge University
Press.
Khegai, J. (2006). GF Parallel Resource Grammars and
Russian. In Coling/ACL 2006, pp. 475?482.
Khegai, J., B. Nordstro?m, and A. Ranta (2003).
Multilingual Syntax Editing in GF. In A. Gel-
bukh (Ed.), Intelligent Text Processing and
Computational Linguistics (CICLing-2003),
Mexico City, February 2003, Volume 2588 of
LNCS, pp. 453?464. Springer-Verlag. URL
http://www.cs.chalmers.se/?aarne/
articles/mexico.ps.gz.
Martin-Lo?f, P. (1984). Intuitionistic Type Theory.
Napoli: Bibliopolis.
Meza Moreno, M. S. and B. Bringert (2008). Inter-
active Multilingual Web Applications with Gram-
marical Framework. In B. Nordstro?m and A. Ranta
(Eds.), Advances in Natural Language Processing
(GoTAL 2008), Volume 5221 of LNCS/LNAI, pp.
336?347. URL http://www.springerlink.
com/content/978-3-540-85286-5/.
Montague, R. (1974). Formal Philosophy. New
Haven: Yale University Press. Collected papers
edited by Richmond Thomason.
Perera, N. and A. Ranta (2007). Dialogue System
Localization with the GF Resource Grammar
Library. In SPEECHGRAM 2007: ACL Workshop
on Grammar-Based Approaches to Spoken Lan-
guage Processing, June 29, 2007, Prague. URL
http://www.cs.chalmers.se/?aarne/
articles/perera-ranta.pdf.
Pollard, C. and I. Sag (1994). Head-Driven Phrase
Structure Grammar. University of Chicago Press.
Power, R. and D. Scott (1998). Multilingual authoring
using feedback texts. In COLING-ACL.
Ranta, A. (1994). Type Theoretical Grammar. Oxford
University Press.
Ranta, A. (2004). Grammatical Framework: A
Type-Theoretical Grammar Formalism. The Jour-
nal of Functional Programming 14(2), 145?
189. URL http://www.cs.chalmers.se/
?aarne/articles/gf-jfp.ps.gz.
Ranta, A. (2009a). Grammars as Software Li-
braries. In Y. Bertot, G. Huet, J.-J. Le?vy, and
G. Plotkin (Eds.), From Semantics to Computer
Science. Cambridge University Press. URL
http://www.cs.chalmers.se/?aarne/
articles/libraries-kahn.pdf.
Ranta, A. (2009b). The GF Resource Gram-
mar Library. In Linguistic Issues in Lan-
guage Technology, Vol. 2. URL http:
//elanguage.net/journals/index.
php/lilt/article/viewFile/214/158.
Rosetta, M. T. (1994). Compositional Translation.
Dordrecht: Kluwer.
Shieber, S. M. and Y. Schabes (1990). Synchronous
tree-adjoining grammars. In COLING, pp. 253?258.
71
Proceedings of the 8th Workshop on Asian Language Resources, pages 153?160,
Beijing, China, 21-22 August 2010. c?2010 Asian Federation for Natural Language Processing
________________________________ 
1 
 http://www.grammaticalframework.org  
2 In given example code ?fun? and ?cat? belongs to abstract syntax,  ?lin? and ?lincat? belongs to concrete syntax 
 
An Open Source Urdu Resource Grammar 
Shafqat M Virk 
Department of Applied IT 
University of Gothenburg  
virk@chalmers.se 
Muhammad Humayoun 
Laboratory of Mathmatics 
University of Savoie 
mhuma@univ-savoie.fr 
Aarne Ranta 
Department of CS & Eng 
 University of Gothenburg  
aarne@chalmers.se 
 
 
 
Abstract 
 
We develop a grammar for Urdu in 
Grammatical Framework (GF). GF is a 
programming language for defining 
multilingual grammar applications. GF 
resource grammar library currently 
supports 16 languages. These grammars 
follow an Interlingua approach and 
consist of morphology and syntax 
modules that cover a wide range of 
features of a language. In this paper we 
explore different syntactic features of the 
Urdu language, and show how to fit them 
in the multilingual framework of GF. We 
also discuss how we cover some of the 
distinguishing features of Urdu such as, 
ergativity in verb agreement (see Sec 
4.2).  The main purpose of GF resource 
grammar library is to provide an easy 
way to write natural language 
applications without knowing the details 
of syntax, morphology and lexicon. To 
demonstrate it, we use Urdu resource 
grammar to add support for Urdu in the 
work reported in (Angelov and Ranta, 
2010) which is an implementation of 
Attempto (Attempto 2008) in GF.  
 
1. Introduction 
 
Urdu is an Indo-European language of the Indo-
Aryan family, widely spoken in south Asia. It is 
a national language of Pakistan and one of the 
official languages of India. It is written in a 
modified Perso-Arabic script from right to left. 
As regards vocabulary, it has a strong influence 
of Arabic and Persian along with some 
borrowing from Turkish and English. Urdu is an 
SOV language having fairly free word order. It 
is closely related to Hindi as both originated 
from the dialect of Delhi region called khari boli 
(Masica, 1991). 
We develop a grammar for Urdu that addresses 
problems related to automated text translation 
using an Interlingua approach and provide a way 
to precisely translate text. This is described in 
Section 2. Then we describe different levels of 
grammar development including morphology 
(Section 3) and syntax (Section 4). In Section 6, 
we discuss an application in which a semantics-
driven translation system is built upon these 
components. 
 
2. GF (Grammatical Framework) 
 
GF (Grammatical Framework, Ranta 2004) is a 
tool for working with grammars, implementing a 
programming language for writing grammars 
which in term is based on a mathematical theory 
about languages and grammars1. Many 
multilingual dialog and text generation 
applications have been built using GF. GF 
grammars have two levels the abstract and the 
concrete syntax2. The abstract syntax is 
language independent and is common to all 
languages in GF grammar library. It is based on 
common syntactic or semantic constructions, 
which work for all the involved languages on an 
appropriate level of abstraction. The concrete 
syntax is language dependent and defines a 
mapping from abstract to actual textual 
representation in a specific language2. GF uses 
the term ?category? to model different parts of 
speech (e.g verbs, nouns adjectives etc.). An 
abstract syntax defines a set of categories, as 
well as a set of tree building functions. Concrete 
syntax contains rules telling how these trees are 
linearized. Separating the tree building rules 
(abstract syntax) from linearization rules 
(concrete syntax) makes it possible to have 
multiple concrete syntaxes for one abstract. This 
153
  
 
makes it possible to parse text in one language 
and translate it to multiple languages. 
Grammars in GF can be roughly classified into 
two kinds: resource grammars and application 
grammars. Resource grammars are general 
purpose grammars (Ranta, 2009a) that try to 
cover the general aspects of a language 
linguistically and whose abstract syntax encodes 
syntactic structures. Application grammars, on 
the other hand, encode semantic structures, but 
in order to be accurate they are typically limited 
to specific domains. However, they are not 
written from scratch for each domain, but they 
use resource grammars as libraries (Ranta 
2009b).  
Previously GF had resource grammars for 16 
languages: English, Italian, Spanish, French, 
Catalan, Swedish, Norwegian, Danish, Finish, 
Russian, Bulgarian, German, Interlingua (an 
artificial language), Polish, Romanian and 
Dutch. Most of these languages are European 
languages. We developed resource grammar for 
Urdu making it the 17th in total and the first 
south Asian language. Resource grammars for 
several other languages (e.g. Arabic, Turkish, 
Persian, Maltese and Swahili) are under 
construction. 
 
3. Morphology 
 
In GF resource grammars a test lexicon of 350 
words is provided for each language. These 
words are built through lexical functions. The 
rules for defining Urdu morphology are 
borrowed from (Humayoun et el., 2006), in 
which Urdu morphology was developed in the 
Functional Morphology toolkit (Forsberg and 
Ranta, 2004). Although it is possible to 
automatically generate equivalent GF code from 
it, we wrote the rules of morphology from 
scratch in GF, to receive better abstractions than 
are possible in generated code. Furthermore, we 
extend this work by including compound words. 
However, the details of morphology are beyond 
the scope of this paper, and its focus is on 
syntax. 
 
4. Syntax 
 
While morphological analysis deals with the 
formation and inflection of individual words, 
syntax shows how these words (parts of speech) 
are grouped together to build well formed 
phrases. In this section we show how this works 
and is implemented for Urdu. 
 
4.1 Noun Phrases (NP) 
 
When nouns are to be used in sentences as part 
of speech, then there are several linguistic 
details which need to be considered. For 
example other words can modify a noun, and 
nouns have characteristics such as gender, 
number etc. When all such required details are 
grouped together with the noun, the resulting 
structure is known as noun phrase (NP). The 
basic structure of Urdu noun phrase is, ?(M) H 
(M)? according to (Butt M., 1995), where (M) is 
a modifier and (H) is the head of a NP. Head is 
the word which is compulsory and modifiers can 
or cannot be there. In Urdu modifiers are of two 
types pre-modifiers i.e modifiers that come 
before the head for instance (  kali: bli: 
?black cat?), and post-modifiers which come 
after the head for instance (	 
  tm sb ?you 
all?). In GF resource library we represent NP as 
a record 
 
lincat NP : Type = {s : NPCase => Str ; a : 
Agr} ; 
 
where 
 
NPCase = NPC Case | NPErg | NPAbl                   
               |NPIns|NPLoc1NPLoc2 
               |NPDat;|NPAcc  
Case = Dir | Obl | Voc ; 
Agr = Ag Gender Number UPerson ; 
Gender = Masc | Fem ; 
UPerson = Pers1| Pers2_Casual 
                 | Pers2_Familiar | Pers2_Respect 
                 | Pers3_Near | Pers3_Distant; 
Number = Sg | Pl ; 
 
Thus NP is a record with two fields, ?s? and ?a?. 
?s? is an inflection table and stores different 
forms of a noun.  
The Urdu NP has a system of syntactic cases 
which is partly different from the morphological 
cases of the category noun (N). The case 
markers that follow nouns in the form of post-
positions cannot be handled at lexical level 
154
  
 
through morphological suffixes and are thus 
handled at syntactic level (Butt et el., 2002). 
Here we create different forms of a noun phrase 
to handle case markers for Urdu nouns. Here is a 
short description of the different cases of NP : 
 
? NPC Case: this is used to retain the 
original case of Noun 
? NPErg: Ergative case with case marker 
?ne: ?? 
? NPAbl: Ablative with case marker ?se: 
?	? 
? NPIns: Instrumental case with case 
marker ?se: ?	? 
? NPLoc1: Locative case with case 
marker ?mi: ? ?? 
? NPLoc2: Locative case with case 
marker ?pr ? 
? NPDat: Dative case with case marker 
?k? ? 
? NPAcc: Accusative case with case 
marker ?k? ? 
   
And ?a? (Agr in the code sample given in 
previous column) is the agreement feature of the 
the noun that is used for selecting the 
appropriate form of other categories that agree 
with nouns.   
A noun is converted to an intermediate category 
common noun (CN; also known as N-Bar) 
which is then converted to NP category. CN 
deals with nouns and their modifiers.  As an 
example consider adjectival modification:  
 
fun AdjCN   : AP -> CN  -> CN ;    
 
lin  AdjCN ap cn = { 
      s = \\n,c =>  
           ap.s ! n ! cn.g ! c ! Posit ++ cn.s ! n ! c ; 
      g = cn.g 
      } ; 
 
The linearization of AdjCN gives us common 
nouns such as ( ??? ??n ?a pani: ?cold 
water?) where a CN ( pani: ?water?) is 
modified by an AP ( ???  , ??n ?a ?cold?).  
Since Urdu adjectives also inflect in number, 
gender, case and degree, we need to concatenate 
the appropriate form of adjective that agrees 
with common noun. This is ensured by selecting 
the corresponding forms of adjective and 
common noun from their inflection tables using 
selection operator (?!?). Since CN does not 
inflect in degree but the adjective does, we fix 
the degree to be positive (Posit) in this 
construction. Other modifiers include possibly 
adverbs, relative clauses, and appositional 
attributes.  
A CN can be converted to a NP using different 
functions: common nouns with determiners; 
proper names; pronouns; and bare nouns as mass 
terms: 
 
 fun DetCN   : Det -> CN -> NP  (e.g the boy) 
fun UsePN   : PN -> NP (e.g John) 
fun UsePron : Pron -> NP  (e.g he) 
fun MassNP     : CN -> NP (e.g milk) 
 
These different ways of building NP?s, which 
are common in different languages, are defined 
in the abstract syntax of the resource grammar, 
but the linearization of these functions is 
language dependent and is therefore defined in 
the concrete syntaxes.   
   
4.2 Verb Phrases (VP) 
 
A verb phrase is a single or a group of words 
that act as a predicate. In our construction Urdu 
verb phrase has following structure 
 
lincat VP = { 
       s    : VPHForm => {fin, inf: Str} ; 
      obj  : {s : Str ; a : Agr} ;  
      vType : VType ; 
      comp : Agr => Str; 
      embComp : Str ; 
      ad  : Str  } ;  
 
where 
 
VPHForm =  
   VPTense VPPTense Agr  
    | VPReq HLevel | VPStem 
 
and 
 
  VPPTense = VPPres |VPPast |VPFutr; 
 HLevel = Tu |Tum |Ap |Neutr 
 
155
  
 
In GF representation a VP is a record with 
different fields. The most important field is ?s? 
which is an inflectional table and stores different 
forms of Verb.  
At VP level we define Urdu tenses by using a 
simplified tense system, which has only three 
tenses, named VPPres, VPPast, VPFutr. In case 
of VPTense for every possible combination of 
VPPTense and agreement (gender, number, 
person) a tuple of two string values {fin, inf : 
Str} is created. ?fin?  stores the coupla (auxiliary 
verb) , and ?inf? stores corresponding form of 
verb. VPStem is a special tense which stores the 
root form of verb. This form is used to create the 
full set of Urdu tenses at clause level (tenses in 
which the root form of verb is used, i.e. 
perfective and progressive tenses). Handling 
tenses at clause level rather than at verb phrase 
level simplifies the VP and results in a more 
efficient grammar.  
The resource grammar has a common API 
which has a much simplified tense system, 
which is close to Germanic languages. It is 
divided into tense and anteriority. There are only 
four tenses named as present, past, future and 
conditional, and two possibilities of anteriority 
(Simul , Anter). This means it creates 8 
combinations. This abstract tense system does 
not cover all the tenses in Urdu. We have 
covered the rest of tenses at clause level, even 
though these tenses are not accessible by the 
common API, but still can be used in language 
specific modules. 
Other forms for verb phrases include request 
form (VPReq), imperative form (VPImp). There 
are four levels of requests in Urdu. Three of 
them correspond to (t? , tm 
 , a:p ?Proceedings of the 7th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities, pages 107?115,
Sofia, Bulgaria, August 8 2013. c?2013 Association for Computational Linguistics
Multilingual access to cultural heritage content
on the Semantic Web
Dana Danne?lls and Aarne Ranta and Ramona Enache
University of Gothenburg and Chalmers University of Technology
SE-412 96 Gothenburg, Sweden
{dana.dannells, aarne.ranta, ramona.enache}@chalmers.se
Mariana Damova and Maria Mateva
Ontotext
Sofia 1784, Bulgaria
{mariana.damova,maria.mateva}@ontotext.com
Abstract
As the amount of cultural data avail-
able on the Semantic Web is expand-
ing, the demand of accessing this
data in multiple languages is increas-
ing. Previous work on multilingual
access to cultural heritage informa-
tion has shown that at least two dif-
ferent problems must be dealt with
when mapping from ontologies to nat-
ural language: (1) mapping multilin-
gual metadata to interoperable knowl-
edge sources; (2) assigning multilin-
gual knowledge to cultural data. This
paper presents our effort to deal with
these problems. We describe our expe-
riences with processing museum data
extracted from two distinct sources,
harmonizing this data and making its
content accessible in natural language.
We extend prior work in two ways.
First, we present a grammar-based sys-
tem that is designed to generate co-
herent texts from Semantic Web on-
tologies in 15 languages. Second, we
describe how this multilingual system
is exploited to form queries using the
standard query language SPARQL. The
generation and retrieval system builds
on W3C standards and is available for
further research.
1 Introduction
As the amount of cultural data available on
the Semantic Web is expanding (Dekkers et
al., 2009; Brugman et al, 2008), the demand
of accessing this data in multiple languages
is increasing (Stiller and Olensky, 2012).
There have been several applications that
applied Natural Language Generation (NLG)
technologies to allow multilingual access to
Semantic Web ontologies (Androutsopoulos
et al, 2001; O?Donnell et al, 2001; Androut-
sopoulos and Karkaletsis, 2005; Androut-
sopoulos and Karkaletsis, 2007; Davies, 2009;
Bouayad-Agha et al, 2012). The above au-
thors have shown it is necessary to have
an extensive lexical and syntactic knowl-
edge when generating multilingual natu-
ral language from Semantic Web ontologies.
However, because previous applications are
mainly concerned with two or three lan-
guages, it is still not clear how to minimize
the efforts in assigning lexical and syntactic
knowledge for the purpose of enhancing au-
tomatic generation of adequate descriptions
in multiple languages.
This paper presents our work on mak-
ing Cultural Heritage (CH) content avail-
able on the Semantic Web and accessible in
15 languages using the Grammatical Frame-
work, GF (Ranta, 2011). The objective of
our work is both to form queries and to
retrieve semantic content in multiple lan-
guages. We describe our experiences with
processing museum data extracted from two
different sources, harmonizing this data and
making its content accessible in natural lan-
guage (NL). The generation and retrieval sys-
tem builds on the World Wide Web Consor-
tium (W3C) standards and is available for
further research.1
The remainder of this paper is structured
as followed. We present the related work in
Section 2. We describe the underlying tech-
1The generation and retrieval system is available
online: http://museum.ontotext.com/
107
nology in Section 3. We provide a detailed
description of the data and present the ap-
proach taken to make this data accessible in
the Linked Open Data (LOD) in Section 4. We
outline the multilingual approach and dis-
cuss the challenges we faced in Section 5.
We discuss the results in Section 6. We end
with some conclusions and pointers to future
work in Section 7.
2 Related work
Lately there has been a lot of interest in en-
abling multilingual access to cultural her-
itage content that is available on the Se-
mantic Web. Androutsopoulos et al (2001)
and O?Donnell et al (2001) have shown that
accessing ontology content in multiple lan-
guages requires extensive linguistic data as-
sociated with the ontology classes and prop-
erties. However, they did not attempt to gen-
erate descriptions in real time from a large set
of ontologies.
Similar to Bouayad-Agha et al (2012), our
system relies on a multi-layered ontology ap-
proach for generating multilingual descrip-
tions. In contrast to Dekkers et al (2009) and
Brugman et al (2008) whose systems make
use of Google translation services, which are
data driven, our system is grammar driven.
Moreover, we present a multilingual
grammar-based approach to SPARQL
(SPARQL Protocol and RDF Query Lan-
guage) (Garlik and Andy, 2013). The method
differs from the verbalization methods pre-
sented by Ngonga Ngomo et al (2013) and
Ell et al (2012) in that it realizes the ontology
content rather than the ontology axioms.
Thus providing a more natural realization of
the query language.
3 The technological infrastructure
Although the architecture of the Semantic
Web and Linked Open Data provides access
to distributed data sets,2 many of the re-
sources available in these sets are not accessi-
ble because of cross-language meta-data. To
overcome this limitation, the knowledge rep-
resentation infrastructure adopted in our ap-
proach is designed as a Reason-able View of
2http://linkeddata.org
the Web of Data. The Reason-able View is a
compound dataset composed of several Re-
source Description Frameworks (RDFs). To
query such a compound dataset, the user has
to be intimately familiar with the schemata
of each single composing dataset. That is
why the Reason-able View approach is ex-
tended with the so called ontological refer-
ence layer, which introduces a unification on-
tology, mapped to the schemata of all single
datasets from a given Reason-able View and
thus provides a mechanism for efficient ac-
cess and navigation of the data.
3.1 Museum Reason-able View (MRV)
The Museum Reason-able View is an as-
sembly of cultural heritage dominated RDF
datasets (Danne?lls et al, 2011). It is loaded
into OWLIM-SE (Bishop et al, 2011) with in-
ference preformed on the data with respect to
OWL Horst (ter Horst, 2005).
3.2 The ontological reference layer
The Museum Reason-able View gathers:
(a) datasets from LOD, including DBpe-
dia;3 (b) the unification ontology PROTON,4
an upper-level ontology, consisting of 542
classes and 183 properties; (c) two cultural
heritage specific ontologies: (i) CIDOC-CRM
(Crofts et al, 2008),5 consisting of 90 classes
and 148 properties; (ii) Museum Artifacts
Ontology (MAO),6 developed for mapping
between museum data and the K-samso?k
schema.7 It has 10 classes and 20 properties;
(d) the Painting ontology,8 an application on-
tology developed to cover detailed informa-
tion about painting objects in the framework
3DBPedia, structured information from Wikipedia:
http://dbpedia.org.
4http://www.ontotext.com/
proton-ontology
5http://www.cidoc-crm.org/
6It is just a coincidence that this ontology has the
same name as the Finnish MAO (Hyvyonen et al,
2008), which also describes museum artifacts for the
Finnish museums.
7K-samso?k http://www.ksamsok.se/
in-english/), the Swedish Open Cultural Her-
itage (SOCH), provides a Web service for applications
to retrieve data from cultural heritage institutions or
associations with cultural heritage information.
8http://spraakdata.gu.se/svedd/
painting-ontology/painting.owl
108
of the Semantic Web. It contains 197 classes
and 107 properties of which 24 classes are
equivalent to classes from the CIDOC-CRM
and 17 properties are sub-properties of the
CIDOC-CRM properties.
3.3 Grammatical Framework (GF)
The Grammatical Framework (GF) (Ranta,
2004) is a grammar formalism targeted to-
wards parsing and generation. The key fea-
ture of GF is the distinction between an ab-
stract syntax, representing the domain, and
concrete syntaxes, representing lineariza-
tions in various target languages, natural or
formal.
GF comes with a resource grammar li-
brary (RGL) (Ranta, 2009) which aids the
development of new grammars for specific
domains by providing syntactic operations
for basic grammatical constructions (Ranta,
2011). More than 30 languages are available
in the RGL. Our application targets 15 of
those, including: Bulgarian, Catalan, Dan-
ish, Dutch, English, Finnish, French, Hebrew,
Italian, German, Norwegian, Romanian, Rus-
sian, Spanish, and Swedish.
4 Cultural heritage data
The data we have been experimenting with
to enable multilingual descriptions of mu-
seum objects and answering to queries over
them is a subset of the Gothenburg City Mu-
seum (GCM) database,9 and a subset of the
DBpedia dataset. Because these two datasets
are very different in size and nature, the pre-
processing of each set differs substantially. In
the following we describe each of the sets and
the pre-processing steps in more details.
4.1 Gothenburg City Museum (GCM)
The set from the GCM contains 48 painting
records. Its content, both the metadata and
data that were originally in Swedish, were
translated to English. An example of a record
from GCM is shown in Table 1.
4.2 DBpedia
The set from DBpedia contains 662 painting
records, the data covers at least 5 languages,
9http://stadsmuseum.goteborg.se/wps/
portal/stadsm/english
Record field Value
Field nr. 4063
Prefix GIM
Object nr. 8364
Search word painting
Class nr 353532
Classification Gothenburg portrait
Amount 1
Producer E.Glud
Produced year 1984
Length cm 106
Width cm 78
Description oil painting
represents a studio indoors
History Up to 1986 belonged to Datema
AB, Flo?jelbergsg 8, Gbg
Material oil paint
Current keeper 2
Location Polstja?rnegatan 4
Package nr. 299
Registration 19930831
Signature BI
Search field Bilder:TAVLOR PICT:GIM
Table 1: A painting object representation from the
GCM database.
the metadata is in English. An example of a
record from DBpedia is shown in Table 2.
4.3 Transition of data to the MRV
Making the museum data available through
the knowledge infrastructure required trans-
lations of the record fields and values, and
mapping to a unified ontology. This process
also required pre-processing of the free text
fields such as Description and History (see Ta-
ble 1) to enrich the data content.
To make the DBpedia data accessible
through the knowledge infrastructure, it re-
quired some preprocessing, cleaning, and
mapping to the Painting ontology for data
consistency. This unification was needed to
use a consistent SPARQL queries from where
NL descriptions could be generated.
Firstly, we attempted to clean data noise
and results that would make a single paint-
ing reappear in the query results. Then, we
transformed year and size strings into only
numbers. For each painter, museum and
painting literal we had a single representa-
tion in the data. All names were normalized,
for example, Salvador Dal?? was converted
109
<result>
<binding name=?painting?>
<uri>http://dbpedia.org/resource/
Virgin of the Rocks</uri> </binding>
<binding name=?museum?>
<literal xml:lang=?en?>Muse?e du Louvre
</literal> </binding>
<binding name=?author?>
<literal xml:lang=?en?>da Vinci, Leonardo
</literal> </binding>
<binding name=?height?>
<literal datatype=
?http://www.w3.org/2001/XMLSchema#int?>
190</literal> </binding>
<binding name=?width?>
<literal datatype=
?http://www.w3.org/2001/XMLSchema#int?>
120</literal>mateva </binding>
<binding name=?title?>
<literal xml:lang=?en?>London version
</literal> </binding>
<binding name=?type?>
<literal xml:lang=?fr?>Huile sur panneau
</literal> </binding>
<binding name=?year?>
<literal datatype=
?http://www.w3.org/2001/XMLSchema#int?>
1495</literal> </binding> </result>
Table 2: A painting object representation from
DBpedia
to Salvador Dal . For different Uniform Re-
source Identifiers (URIs) pointing to the same
painting, we used the OWL (W3C, 2012)
construct owl:sameAs. With this construct we
were able to keep the data linked in the other
graphs in the LOD cloud.
5 Multilingual linked data
Our application is targeted towards lay users
who wish to formulate queries and retrieve
information in any language. Such users do
not have any knowledge about ontologies or
semantic data processing. For us it was there-
fore necessary to enable interactions in a sim-
ple use.
The work towards making Semantic Web
data accessible to different users required
lexicalizations of ontology classes, proper-
ties and individuals (literal strings associated
with a certain class).
Following the GF mechanism, lexicaliza-
tions is accomplished through linearizations
of functions. Linearization of functions varies
depending on the language.
5.1 Lexicalizations of classes and
properties
Most of the ontology classes defined in our
grammar are linearized with noun phrases
in the concrete syntaxes. These were trans-
lated manually by a native speaker of the
language. Examples from four languages are
shown below. In the examples we find the
following RGL constructions: mkCN (Com-
mon noun) and mkN (Noun).
Class: Painting
Swe. mkCN (mkN "ma?lning");
Fre. mkCN (mkN "tableau");
Fin. mkCN (mkN "maalaus");
Ger. mkCN mkN "Bild"
"Bilder" neuter;
Class: Portrait
Swe. mkCN (regGenN "portra?tt"
neutrum);
Fre. mkCN (mkN "portrait");
Fin. mkCN (mkN "muoto"
(mkN "kuva"));
Ger. mkCN (mkN "Portra?t"
"Portra?ts" neuter);
Two of the ontology classes that are not
linearized with a noun phrase are: Year and
Size. These are linearized with prepositional
phrases in which the preposition is language
dependent. Below are some examples which
show how the Year string, i.e. YInt function, is
realized in six languages. In the examples we
find the following RGL constructions: mkAdv
(Verb Phrase modifying adverb), Prep (Prepo-
sition) and symb (Symbolic).
Bul. YInt i = mkAdv prez_Prep
(symb (i.s ++ year_Str));
Fin. YInt i = mkAdv (prePrep
nominative "vuonna") (symb i);
Fre. YInt i = mkAdv en_Prep (symb i);
Ger. YInt i = mkAdv in_Prep (symb i);
Swe. YInt i = mkAdv noPrep
(symb ("a?r" ++ i.s));
Rus. YInt i = mkAdv in_Prep
(symb (i.s ++ godu_Str));
The ontology properties are defined with
operations in the concrete syntaxes. Because
110
Table 3: The amount of lexicalized literals in a
subset of the MRV
Class literals
Title 662
Painter 116
Museum 104
Place 22
an ontology property is linearized differently
depending on how it is realized in the target
language, these operations are of type: verbs
(e.g. paint V2), adverbs (e.g. painted A) and
prepositions (e.g. Prep). Examples from three
languages are shown below.
Swe. paint_V2 : V2 = mkV2 "ma?la";
painted_A : A = mkA "ma?lad";
at_Prep = mkPrep "pa?" ;
Fin. paint_V2 = mkV2 "maalata";
painted_A = mkA "maalattu";
Ger. paint_V2 : V2 = mkV2
(mkV "malen");
painted_A : A = mkA "gemalt";
at_Prep = in_Prep ;
The above functions correspond to three
ontological properties, namely painted by,
painted and created in. This approach to ontol-
ogy lexicalization permits variations regard-
ing the lexical units the ontology properties
should be mapped to. It allows to make prin-
cipled choices about the different realizations
of an ontology property.
5.2 Lexicalizations of literals
The part of the MRV to which we provide
translations for consists of 906 individuals,
their distribution across four classes is pro-
vided in Table 3. The lexical units assigned to
paining titles, painters and museum literals
are by default the original strings as they ap-
pear in the data. The majority of strings are
given in English. However, because without
translations of the name entities the results
can become artificial and for some languages
ungrammatical, we run a script that trans-
lates museum literals from Wikipedia auto-
matically.
Automatic translation was done by:
(1) curling for Web pages for a museum
string; (2) extracting the retrieved trans-
Table 4: The number of automatically translated
museum names from Wikipedia
Language Translated names
Bulgarian 26
Catalan 63
Danish 33
Dutch 81
Finnish 40
French 94
Hebrew 46
Italian 94
German 99
Norwegian 50
Romanian 27
Russian 87
Spanish 89
Swedish 58
lated entry for each string; (3) reducing
the retrieved list by removing duplicated
and ambiguous entries. This process was
repeated for each language.
As a result of the translation process, a
list of lexical pairs was created for each lan-
guage. Museum literals were then linearized
automatically by consulting the created list
for each language. In the cases where no
translation was found, the original string, as
it appears in the dataset was used.
Unfortunately, the amount of the trans-
lated museum names was not equal for all
languages. The distribution of the translated
names is given in Table 4. Below follow some
examples of how museum names are repre-
sented in the grammar:
Swe. MGothenburg_City_Museum =
mkMuseum "Go?teborgs stadsmuseum";
MMus_e_du_Louvre =
mkMuseum "Louvren";
Ita. MGothenburg_City_Museum =
mkMuseum
"museo municipale di Goteburgo";
MMus_e_du_Louvre =
mkMuseum "Museo del Louvre";
Fre. MGothenburg_City_Museum =
mkMuseum
"muse?e municipal de Go?teborg";
MMus_e_du_Louvre =
mkMuseum "Muse?e du Louvre";
Cat. MGothenburg_City_Museum =
mkMuseum "Gothenburg_City_Museum";
MMus_e_du_Louvre =
111
mkMuseum "Museu del Louvre";
Ger. MGothenburg_City_Museum =
mkMuseum "Gothenburg_City_Museum";
MMus_e_du_Louvre =
mkMuseum "Der Louvre ";
Where the construct mkMuseum has been
defined to build a noun phrase from a given
string. A special case of mkMuseum appears
in four languages: Italian, Catalan, Spanish
and French, where a masculine gender is as-
signed to the museum string to get the cor-
rect inflection form of the noun.
5.3 Realization of sentences
To generate sentences from a set of classes
we had to make different judgements about
how to order the different classes. Below we
provide an example of a sentence lineariza-
tion from four languages. The sentence com-
prises four semantic classes: Painting, Mate-
rial, Painter and Year. In the examples we find
following RGL constructors: mkText (Text),
mkS (Sentence), mkCl (Clause), mkNP (Noun
Phrase), and mkVP (Verb Phrase).
Ita. s1 : Text = mkText (mkS
(mkCl painting (mkVP (mkVP (mkVP
(mkVP dipinto_A) material.s)
(SyntaxIta.mkAdv by8agent_Prep
(title painter.long))) year.s))) ;
Fre. s1 : Text = mkText
(mkS anteriorAnt
(mkCl painting (mkVP (mkVP (mkVP
(passiveVP paint_V2) material.s)
(SyntaxFre.mkAdv by8agent_Prep
(title painter.long))) year.s))) ;
Ger. s1 : Text = mkText
(mkS pastTense
(mkCl painting (mkVP (mkVP
(mkVP (passiveVP paint_V2) year.s)
(SyntaxGer.mkAdv von_Prep
(title painter.long))) material.s)));
Rus. s1 : Text = mkText
(mkS pastTense
(mkCl painting (mkVP (mkVP (mkVP
(passiveVP paint_V2)
(SyntaxRus.mkAdv part_Prep
(title painter.long
masculine animate)))
material.s) year.s))) ;
Some of the distinguishing differences be-
tween the languages are: in Finnish the use
of an active voice, in Italian, present tense,
in French, past participle, in Spanish, present
simple. The order of the categories is also dif-
ferent. In German the material string appears
at the end of the sentence as opposed to the
other languages where year is often the last
string.
5.4 Realizations of texts
The text grammar has been designed to gen-
erate a coherent natural language descrip-
tions from a selected set of the returned
triples. More specifically, our grammar cov-
ers eight concepts that are most commonly
used to describe a painting, including: Title,
Painter, Painting type, Material, Colour, Year,
Museum and Size. In the grammar mod-
ule called TextPainting they are defined as
categories and are captured in one function
DPainting which has the following represen-
tation in the abstract syntax.
DPainting :
Painting -> Painter ->
PaintingType -> OptColours ->
OptSize -> OptMaterial ->
OptYear -> OptMuseum -> Description;
In the function DPainting five arguments
have been implemented as optional, i.e.
OptColour, OptSize, OptMaterial, OptYear and
OptMuseum. Each of these categories can be
left out in a text.
In the current implementation we limited
the length of a description to three sentences.
A minimal description consists of only one
sentences. Below follow some examples of
texts generated in English to exemplify the
different descriptions we are able to generate
from one single function call with a varying
number of instantiated parameters.
? Interior was painted on canvas by Edgar
Degas in 1868. It measures 81 by 114 cm
and it is painted in red and white. This
painting is displayed at the Philadelphia
Museum of Art.
? Interior was painted by Edgar Degas in
1868. It measures 81 by 114 cm. This
painting is displayed at the Philadelphia
Museum of Art.
? Interior was painted on canvas by Edgar
Degas in 1868. It is painted in red and
white. This painting is displayed at the
Philadelphia Museum of Art.
112
Figure 1: A semantic tree realization of nine ontology classes
? Interior was painted by Edgar Degas. It
measures 81 by 114 cm and it is painted
in red and white. This painting is dis-
played at the Philadelphia Museum of
Art.
? Interior was painted on canvas by Edgar
Degas. It measures 81 by 114 cm and it is
painted in red and white.
? Interior was painted by Edgar Degas in
1868. This painting is displayed at the
Philadelphia Museum of Art.
? Interior was painted by Edgar Degas.
5.5 Multilingual querying
Semantic Web technologies offer the tech-
nological backbone to meet the requirement
of integrating heterogeneous data easily, but
they are still more adapted to be consumed
by computers than by humans. As a con-
sequence, to retrieve semantic content from
the knowledge base the user must: 1. mas-
ter SPARQL, the query language for RDF;
2. have knowledge about each integrated
dataset in the knowledge base.
Ngonga Ngomo et al (2013) have shown
that realizations of SPARQL queries in natu-
ral language enhance the user understanding
of the formulated queries and the retrieved
results.
We have implemented an extra SPARQL
module that allow us to map from any
of the 15 supported languages to SPARQL
and from SPARQL to any of the 15 sup-
ported languages. The grammar reuses a
more generic query module that allows to
form both domain specific and domain in-
dependent queries. Some examples of the
queries that can be formulated with the
multilingual grammar and transformed to
SPARQL are:
1. Some X
2. All About X
3. Show everything about X
4. All X painted by Y
5. Some X painted on Y
6. What is the material of X
7. Show everything about all X that are painted
on Y
In GF, realization of SPARQL queries is
done by introducing new parameters, for ex-
ample:
QPainter p = {
wh1 = "?author";
prop = p ;
wh2 ="painting:createdBy ?painter.
?painter rdfs:label ?author ."} ;
The function QPainter defined to formulate
a query such as who painted Mona Lisa? has
been added two additional parameters, i.e.
wh1 and wh2. With these parameters it is pos-
sible to formulate SPARQL queries such as
the one below.
SELECT ?author
WHERE {
?painting rdf:type
painting:Painting ;
painting:createdBy ?painter ;
rdfs:label ?title
FILTER (str(?title)="Mona_Lisa").
?painter rdfs:label ?author.
}
113
Figure 2: Multilingual generation results
5.6 Multilingual text generation
Our approach allows different texts to be
generated depending on the information that
is available in the ontology. A minimal de-
scription consists of three classes: a title, a
painter and a painting type. A complete de-
scription consists of nine classes, as illus-
trated in Figure 1. With only one function
DPainting our system is able to generate 16
different text variants. Figure 2 illustrates a
generation results in 15 languages.
6 Discussion
The majority of the challenges in the produc-
tion of the CH data pool stemmed from the
very nature of the Linked Open Data. The
data in the LOD cloud are notoriously noisy
and inconsistent.
The multilingual labels from the FactForge
datasets and more precisely from DBpedia,
are not always available in all the supported
languages. Although DBpedia in its large
pool of data provides access to multilingual
content, it is inconsistent. Many of the entries
it contains are missing translations. There is a
mixture of numeric and string literals. There
are many duplications, most of them occur
because the same ID appears in different lan-
guages. The content of the data is verbose, for
example place-names and museum-names
are represented with one string, for example:
?Rijksmuseum, Amsterdam?, instead of two
different strings linked by two separate con-
cepts, i.e. Museum and Place. This kind of in-
consistent data representation had an impact
on the translation of museum names.
Another problem was that not all art ob-
jects are uniformly described with the same
set of characteristics. For instance, some
paintings were missing a title or a painter
name. Because we constructed the grammar
in such a way that disallows absence of this
information, we had to replace titles with
id numbers and empty painter names with
the string unknown. Moreover, the data con-
tained many duplications. This occurred be-
cause some of the property assertions were
presented with different strings and trig-
gered many RDF triples.
We also faced many linguistic challenges
on different levels. Lexicalizations of ontol-
ogy classes and properties regarding use
of compounds, variations of verbs, adverbs
and prepositions. On sentence level, order of
classes, variations of tense and voice. On both
sentence and discourse levels, aggregation
variations and use of coreference elements.
7 Conclusions
We presented an ontology-based multilin-
gual application developed in the Gram-
matical Framework and a cross-language re-
trieval system that uses this application for
generating museum object descriptions in
the Semantic Web.
The generation and retrieval system builds
on W3C standards. It covers semantic data
from the Gothenburg City Museum database
and DBpedia. The grammar enables descrip-
tions of paintings and answering to queries
over them, covering 15 languages for base-
line functionality.
114
Acknowledgment
This research has been supported by
MOLTO, the European Union?s Seventh
Framework Programme (FP7/2007-2013)
under grant agreement FP7-ICT-247914.
References
S. Kallonis Androutsopoulos and V. Karkaletsis.
2005. Exploiting OWL ontologies in the mul-
tilingual generation of object descriptions. In
The 10th European Workshop on NLG, pages 150?
155, Aberdeen, UK.
J. Oberlander Androutsopoulos and V. Karkalet-
sis. 2007. Source authoring for multilingual
generation of personalised object descriptions.
Natural Language Engineering, 13(3):191?233.
Ion Androutsopoulos, Vassiliki Kokkinaki, Agge-
liki Dimitromanolaki, Jo Calder, Jon Oberl, and
Elena Not. 2001. Generating multilingual per-
sonalized descriptions of museum exhibits: the
M-PIRO project. In Proceedings of the Interna-
tional Conference on Computer Applications and
Quantitative Methods in Archaeology.
B. Bishop, A. Kiryakov, D. Ognyanoff, I. Peikov,
Z. Tashev, and R. Velkov. 2011. OWLIM: A
family of scalable semantic repositories. Se-
mantic Web Journal, Special Issue: Real-World Ap-
plications of OWL.
Nadjet Bouayad-Agha, Gerard Casamayor, Si-
mon Mille, Marco Rospocher, Horacio Saggion,
Luciano Serafini, and Leo Wanner. 2012. From
Ontology to NL: Generation of multilingual
user-oriented environmental reports. Lecture
Notes in Computer Science, 7337.
Hennie Brugman, Ve?ronique Malaise?, and Laura
Hollink. 2008. A common multimedia annota-
tion framework for cross linking cultural her-
itage digital collections. In International Confer-
ence on Language Resources and Evaluation.
Nick Crofts, Martin Doerr, Tony Gill, Stephen
Stead, and Matthew Stiff, 2008. Definition of the
CIDOC Conceptual Reference Model.
Dana Danne?lls, Mariana Damova, Ramona
Enache, and Milen Chechev. 2011. A Frame-
work for Improved Access to Museum
Databases in the Semantic Web. In Recent Ad-
vances in Natural Language Processing (RANLP).
Language Technologies for Digital Humanities and
Cultural Heritage (LaTeCH).
Rob Davies. 2009. EuropeanaLocal ? its role
in improving access to Europe?s cultural her-
itage through the European digital library. In
Proceedings of IACH workshop at ECDL2009 (Eu-
ropean Conference on Digital Libraries), Aarhus,
September.
Makx Dekkers, Stefan Gradmann, and Carlo
Meghini. 2009. Europeana outline func-
tional specification for development of an op-
erational european digital library. Technical
report. Europeana Thematic Network Deliv-
erables 2.5. Contributors and peer reviewers:
Europeana.net WP2 Working Group members,
Europeana office.
Basil Ell, Denny Vrandec?ic?, and Elena Sim-
perl. 2012. SPARTIQULATION ? Verbalizing
SPARQL queries. In Proceedings of ILD Work-
shop, ESWC 2012.
Steve Harris Garlik and Seaborne Andy, 2013.
SPARQL 1.1 Query Language, March. http:
//www.w3.org/TR/sparql11-query/.
E Hyvyonen, E. Maekelae, M. Salminen, A. Valo,
K. Viljanen, S. Saarela, M. Junnila, and S. Ket-
tula. 2008. Museum finland. In Finnihs Mu-
seum on the Semantic Web.
Axel-Cyrille Ngonga Ngomo, Lorenz Bu?hmann,
Christina Unger, Jens Lehmann, and Daniel
Gerber. 2013. Sorry, i don?t speak sparql: trans-
lating sparql queries into natural language. In
Proceedings of the 22nd international conference
on World Wide Web, WWW ?13, pages 977?
988, Republic and Canton of Geneva, Switzer-
land. International World Wide Web Confer-
ences Steering Committee.
Michael J. O?Donnell, Chris Mellish, Jon Oberlan-
der, and Alistair Knott. 2001. ILEX: An archi-
tecture for a dynamic hypertext generation sys-
tem. Natural Language Engineering, 7(3):225?
250.
Aarne Ranta. 2004. Grammatical Framework, a
type-theoretical grammar formalism. Journal of
Functional Programming, 14(2):145?189.
Aarne Ranta. 2009. The GF resource gram-
mar library. The on-line journal Linguistics
in Language Technology (LiLT), 2(2). http:
//elanguage.net/journals/index.
php/lilt/article/viewFile/214/158.
Aarne Ranta. 2011. Grammatical Framework: Pro-
gramming with Multilingual Grammars. CSLI
Publications, Stanford. ISBN-10: 1-57586-626-9
(Paper), 1-57586-627-7 (Cloth).
J. Stiller and M. Olensky. 2012. Europeana: A
multilingual trailblazer. In The W3C Workshop:
The Multilingual Web - Linked Open Data and
Multilingual Web-LT Requirements, Dublin.
H. J. ter Horst. 2005. Combining RDF and Part
of OWL with Rules: Semantics, Decidability,
Complexity. In Proceedings of The Semantic Web
ISWC, volume 3729 of LNCS, pages 668?684,
Heidelberg. Springer Berlin.
W3C, 2012. OWL Web Ontology Language
Overview, December. http://www.w3.org/
TR/owl2-overview/.
115
Proceedings of the EACL 2014 Workshop on Type Theory and Natural Language Semantics (TTNLS), pages 1?9,
Gothenburg, Sweden, April 26-30 2014.
c?2014 Association for Computational Linguistics
Types and Records for Predication
Aarne Ranta
Department of Computer Science and Engineering, University of Gothenburg
aarne@chalmers.se
Abstract
This paper studies the use of records
and dependent types in GF (Grammatical
Framework) to build a grammar for pred-
ication with an unlimited number of sub-
categories, also covering extraction and
coordination. The grammar is imple-
mented for Chinese, English, Finnish, and
Swedish, sharing the maximum of code
to identify similarities and differences be-
tween the languages. Equipped with a
probabilistic model and a large lexicon,
the grammar has also been tested in wide-
coverage machine translation. The first
evaluations show improvements in parsing
speed, coverage, and robustness in com-
parison to earlier GF grammars. The study
confirms that dependent types, records,
and functors are useful in both engineer-
ing and theoretical perspectives.
1 Introduction
Predication is the basic level of syntax. In logic, it
means building atomic formulas by predicates. In
linguistics, it means building sentences by verbs.
Categorial grammars (Bar-Hillel, 1953; Lambek,
1958) adapt logical predication to natural lan-
guage. Thus for instance transitive verbs are cat-
egorized as (n\s/n), which is the logical type
n? n? s with the information that one argument
comes before the verb and the other one after. But
most approaches to syntax and semantics, includ-
ing (Montague, 1974), introduce predicate cate-
gories as primitives rather than as function types.
Thus transitive verbs are a category of its own, re-
lated to logic via a semantic rule. This gives more
expressive power, as it permits predicates with dif-
ferent syntactic properties and variable word order
(e.g. inversion in questions). A drawback is that
a grammar may need a large number of categories
and rules. In GPSG (Gazdar et al., 1985), and later
in HPSG (Pollard and Sag, 1994), this is solved
by introducing a feature called subcat for verbs.
Verbs taking different arguments differ in the sub-
cat feature but share otherwise the characteristic of
being verbs.
In this paper, we will study the syntax and se-
mantics of predication in GF, Grammatical Frame-
work (Ranta, 2011). We will generalize both over
subcategories (as in GPSG and HPSG), and over
languages (as customary in GF). We use depen-
dent types to control the application of verbs to
legitimate arguments, and records to control the
placement of arguments in sentences. The record
structure is inspired by the topological model of
syntax in (Diderichsen, 1962).
The approach is designed to apply to all lan-
guages in the GF Resource Grammar Library
(RGL, (Ranta, 2009)), factoring out their typolog-
ical differences in a modular way. We have tested
the grammar with four languages from three fam-
ilies: Chinese, English, Finnish, and Swedish. As
the implementation reuses old RGL code for all
parts but predication, it can be ported to new lan-
guages with just a few pages of new GF code. We
have also tested it in wide coverage tasks, with a
probabilistic tree model and a lexicon of 60,000
lemmas.
We will start with an introduction to the abstrac-
tion mechanisms of GF and conclude with a sum-
mary of some recent research. Section 2 places
GF on the map of grammar formalisms. Section 3
works out an example showing how abstract syn-
tax can be shared between languages. Section 4
shows how parts of concrete syntax can be shared
as well. Section 5 gives the full picture of predi-
cation with dependent types and records, also ad-
dressing extraction, coordination, and semantics.
Section 6 gives preliminary evaluation. Section 7
concludes.
1
2 GF: an executive summary
GF belongs to a subfamily of categorial grammars
inspired by (Curry, 1961). These grammars make
a distinction between tectogrammar, which spec-
ifies the syntactic structures (tree-like representa-
tions), and phenogrammar, which relates these
structures to linear representations, such as se-
quences of characters, words, or phonemes. Other
formalisms in this family include ACG (de Groote,
2001) and Lambda grammars (Muskens, 2001).
GF inherits its name from LF, Logical Frame-
works, which are type theories used for defin-
ing logics (Harper et al., 1993). GF builds on
the LF called ALF, Another Logical Framework
(Magnusson, 1994), which implements Martin-
L?of?s higher-level type theory (first introduced
in the preface of (Martin-L?of, 1984); see Chap-
ter 8 of (Ranta, 1994) for more details). Before
GF was introduced as an independent formalism
in 1998, GF-like applications were built as plug-
ins to ALF (Ranta, 1997). The idea was that the
LF defines the tectogrammar, and the plug-in de-
fines the phenogrammar. The intended application
was natural language interfaces to formal proof
systems, in the style of (Coscoy et al., 1995).
GF was born via two additions to the natural
language interface idea. The first one was multi-
linguality: one and the same tectogrammar can
be given multiple phenogrammars. The second
addition was parsing: the phenogrammar, which
was initially just linearization (generating strings
from type theoretical formulas), was reversed to
rules that parse natural language into type theory.
The result was a method for translation, which
combines parsing the source language with lin-
earization into the target language. This idea was
indeed suggested in (Curry, 1961), and applied
before GF in the Rosetta project (Landsbergen,
1982), which used Montague?s analysis trees as
tectogrammar.
GF can be seen as a formalization and gener-
alization of Montague grammar. Formalization,
because it introduces a formal notation for the
linearization rules that in Montague?s work were
expressed informally. Generalization, because of
multilinguality and also because the type system
for analysis trees has dependent types.
Following the terminology of programming lan-
guage theory, the tectogrammar is in GF called
the abstract syntax whereas the phenogrammar is
called the concrete syntax. As in compilers and
logical frameworks, the abstract syntax encodes
the structure relevant for semantics, whereas the
concrete syntax defines ?syntactic sugar?.
The resulting system turned out to be equiv-
alent to parallel multiple context-free gram-
mars (Seki et al., 1991) and therefore parsable
in polynomial time (Ljungl?of, 2004). Compre-
hensive grammars have been written for 29 lan-
guages, and later work has optimized GF pars-
ing and also added probabilistic disambiguation
and robustness, resulting in state-of-the-art perfor-
mance in wide-coverage deep parsing (Angelov,
2011; Angelov and Ljungl?of, 2014).
3 Example: subject-verb-object
sentences
Let us start with an important special case of predi-
cation: the subject-verb-object structure. The sim-
plest possible rule is
fun PredTV : NP -> TV -> NP -> S
that is, a function that takes a subject NP, a tran-
sitive verb TV, and an object NP, and returns a
sentence S. This function builds abstract syntax
trees. Concrete syntax defines linearization rules,
which convert trees into strings. The above rule
can give rise to different word orders, such as SVO
(as in English), SOV (as in Hindi), and VSO (as in
Arabic):
lin PredTV s v o = s ++ v ++ o
lin PredTV s v o = s ++ o ++ v
lin PredTV s v o = v ++ s ++ o
where ++ means concatenation.
The above rule builds a sentence in one step.
A more flexible approach is to do it in two steps:
complementation, forming a VP (verb phrase)
from the verb and the object, and predication
proper that provides the subject. The abstract syn-
tax is
fun Compl : TV -> NP -> VP
fun Pred : NP -> VP -> S
These functions are easy to linearize for the SVO
and SOV orders:
lin Compl v o = v ++ o -- SVO
lin Compl v o = o ++ v -- SOV
lin Pred s vp = s ++ vp -- both
where -- marks a comment. However, the VSO
order cannot be obtained in this way, because the
two parts of the VP are separated by the subject.
The solution is to generalize linearization from
strings to records. Complementation can then re-
turn a record that has the verb and the object as
separate fields. Then we can also generate VSO:
2
lin Compl v o = {verb = v ; obj = o}
lin Pred s vp = vp.verb ++ s ++ vp.obj
The dot (.) means projection, picking the value
of a field in a record.
Records enable the abstract syntax to abstract
away not only from word order, but also from
whether a language uses discontinuous con-
stituents. VP in VSO languages is one example.
Once we enable discontinuous constituents, they
turn out useful almost everywhere, as they enable
us to delay the decision about linear order. It can
then be varied even inside a single language, if it
depends on syntactic context (as e.g. in German;
cf. (M?uller, 2004) for a survey).
The next thing to abstract away from is inflec-
tion and agreement. Given the lexicon
fun We, She : NP
fun Love : TV
we can build the abstract syntax tree
Pred We (Compl Love She)
to represent we love her. If we swap the subject
and the object, we get
Pred She (Compl Love We)
for she loves us. Now, these two sentences are
built from the same abstract syntax objects, but
no single word is shared between them! This is
because the noun phrases inflect for case and the
verb agrees to the subject.
In contrast to English, Chinese just reorders the
words:
women ai ta - ?we love her?
ta ai women - ?she loves us?
Thus the above rules for SVO languages work as
they are for Chinese. But in English, we must in-
clude case and agreement as features in the con-
crete syntax. Thus the linearization of an NP is
a record that includes a table producing the case
forms, and agreement as an inherent feature:
lin She = {
s = table {
Nom => "she" ;
Acc => "her"
} ;
a = {n = Sg ; p = P3} ;
}
The agreement feature (field a) is itself a record,
with a number and a gender. In other languages,
case and agreement can of course have different
sets of values.
Verbs likewise include tables that inflect them
for different agreement features:
lin Love = {
s = table {
{n = Sg ; p = P3} => "loves" ;
_ => "love"
}
}
We can now define English linearization:
lin Compl v o =
{s = table {a => v.s ! a ++ o.s ! Acc}}
lin Pred s vp =
{s = s.s ! Nom ++ vp.s ! np.a}
using the same type of records for VP as for TV,
and a one-string record for S. The Compl rule
passes the agreement feature to the verb of the VP,
and selects the Acc form of the object (with ! de-
noting selection from a table). The Pred rule se-
lects the Nom form of the subject, and attaches to
this the VP form selected for np.a, i.e. the agree-
ment feature of the subject.
4 Generalized concrete syntax
To see the full power of GF, we now take a look
at its type and module system. Figure 1 shows a
complete set of grammar modules implementing
transitive verb predication for Finnish and Chinese
with a maximum of shared code.
The first module in Figure 1 is the abstract syn-
tax Pred, where the fun rules are preceded by
a set of cat rules defining the categories of the
grammar, i.e. the basic types. Pred defines five
categories: S, Cl, NP, VP, and TV. S is the top-
level category of sentences, whereas Cl (clause) is
the intermediate category of predications, which
can be used as sentences in many ways?here, as
declaratives and as questions.
The concrete syntax has corresponding lincat
rules, which equip each category with a lineariza-
tion type, i.e. the type of the values returned
when linearizing trees of that category. The mod-
ule PredFunctor in Figure 1 contains four such
rules. In lincat NP, the type Case => Str is
the type of tables that produce a string as a func-
tion of a case, and Agr is the type of agreement
features.
When a GF grammar is compiled, each lin rule
is type checked with respect to the lincats of the
categories involved, to guarantee that, for every
fun f : C
1
? ??? ?C
n
?C
we have
lin f : C
?
1
? ??? ?C
?
n
?C
?
3
abstract Pred = {
cat S ; Cl ; NP ; VP ; TV ;
fun Compl : TV -> NP -> VP ; fun Pred : TV -> NP -> Cl ;
fun Decl : Cl -> S ; fun Quest : Cl -> S ;
}
incomplete concrete PredFunctor of Pred = open PredInterface in {
lincat S = {s : Str} ; lincat Cl = {subj,verb,obj : Str} ;
lincat NP = {s : Case => Str ; a : Agr} ;
lincat VP = {verb : Agr => Str ; obj : Str} ; lincat TV = {s : Agr => Str} ;
lin Compl tv np = {verb = tv.s ; obj = np.s ! objCase} ;
lin Pred np vp = {subj = np.s !subjCase ; verb = vp.verb ! np.a ; obj = vp.obj} ;
lin Decl cl = {s = decl cl.subj cl.verb cl.obj} ;
lin Quest cl = {s = quest cl.subj cl.verb cl.obj} ;
}
interface PredInterface = {
oper Case, Agr : PType ;
oper subjCase, objCase : Case ;
oper decl, quest : Str -> Str -> Str -> Str ;
}
instance PredInstanceFin of PredInterface = { concrete PredFin of Pred =
oper Case = -- Nom | Acc | ... ; PredFunctor with
oper Agr = {n : Number ; p : Person} ; (PredInterface =
oper subjCase = Nom ; objCase = Acc ; PredInstanceFin) ;
oper decl s v o = s ++ v ++ o ;
oper quest s v o = v ++ "&+ ko" ++ s ++ o ;
}
instance PredInstanceChi of PredInterface = { concrete PredChi of Pred =
oper Case, Agr = {} ; PredFunctor with
oper subjCase, objCase = <> ; (PredInterface =
oper decl s v o = s ++ v ++ o ; PredInstanceChi) ;
oper quest s v o = s ++ v ++ o ++ "ma" ;
}
Figure 1: Functorized grammar for transitive verb predication.
where A
?
is the linearization type of A. Thus lin-
earization is a homomorphism. It is actually
an instance of denotational semantics, where the
lincats are the domains of possible denota-
tions.
Much of the strength of GF comes from us-
ing different linearization types for different lan-
guages. Thus English needs case and agreement,
Finnish needs many more cases (in the full gram-
mar), Chinese needs mostly only strings, and so
on. However, it is both useful and illuminating to
unify the types. The way to do this is by the use
of functors, also known as a parametrized mod-
ules.
PredFunctor in Figure 1 is an example; func-
tors are marked with the keyword incomplete. A
functor depends on an interface, which declares
a set of parameters (PredInterface in Figure
1). A concrete module is produced by giving
an instance to the interface (PredInstanceFin
and PredInstanceChi).
The rules in PredFunctor in Figure 1 are de-
signed to work for both languages, by varying the
definitions of the constants in PredInterface.
And more languages can be added to use it. Con-
sider for example the definition of NP. The expe-
rience from the RGL shows that, if a language
has case and agreement, its NPs inflect for case
and have inherent agreement. The limiting case
of Chinese can be treated by using the unit type
({} i.e. the record type with no fields) for both
features. This would not be so elegant for Chinese
alone, but makes sense in the code sharing context.
Discontinuity now appears as another useful
generalization. With the lincat definition in
PredFunctor, we can share the Compl rule in all
of the languages discussed so far. In clauses (Cl),
we continue on similar lines: we keep the subject,
the verb, and the object on separate fields. Notice
that verb in Cl is a plain string, since the value of
Agr gets fixed when the subject is added.
The final sentence word order is created as the
last step, when converting Cl into S. As Cl is dis-
continuous, it can be linearized in different orders.
In Figure 1, this is used in Finnish for generat-
ing the SVO order in declaratives and VSO on
questions (with an intervening question particle ko
glued to the verb). It also supports the other word
4
orders of Finnish (Karttunen and Kay, 1985).
By using an abstract syntax in combination with
unordered records, parameters, and functors for
the concrete syntax, we follow a kind of a ?prin-
ciples and parameters? approach to language vari-
ation (Chomsky, 1981). The actual parameter set
for the whole RGL is of course larger than the one
shown here.
Mathematically, it is possible to treat all differ-
ences in concrete syntax by parameters, simply by
declaring a new parameter for every lincat and
lin rule! But this is both vacuous as a theory and
an unnecessary detour in practice. It is more il-
luminating to keep the functor simple and the set
of parameters small. If the functor does not work
for a new language, it usually makes more sense to
override it than to grow the parameter list, and GF
provides a mechanism for this. Opposite to ?prin-
ciples and parameters?, this is ?a model in which
language-particular rules take over the work of pa-
rameter settings? (Newmeyer, 2004). A combina-
tion of the two models enables language compari-
son by measuring the amount of overrides.
5 The full predication system
So far we have only dealt with one kind of verbs,
TV. But we need more: intransitive, ditransitive,
sentence-complement, etc. The general verb cate-
gory is a dependent type, which varies over argu-
ment type lists:
cat V (x : Args)
The list x : Args corresponds to the subcat fea-
ture in GPSG and HPSG. Verb phrases and clauses
have the same dependencies. Syntactically, a
phrase depending on x : Args has ?holes? for
every argument in the list x. Semantically, it is a
function over the denotations of its arguments (see
Section 5.3 below).
5.1 The code
Figure 2 shows the essentials of the resulting
grammar, and we will now explain this code. The
full code is available at the GF web site.
1. Argument lists and dependent categories.
The argument of a verb can be an adjectival phrase
(AP, become old), a clause (Cl, say that we go), a
common noun (CN, become a president), a noun
phrase (NP, love her), a question (QCl, wonder
who goes), or a verb phrase (VP, want to go). The
definition allows an arbitrary list of arguments.
For example, NP+QCl is used in verbs such as ask
(someone whether something).
What about PP (prepositional phrase) comple-
ments? The best approach in a multilingual set-
ting is to treat them as NP complements with des-
ignated cases. Thus in Figure 2.5, the lineariza-
tion type of VP has fields of type complCase.
This covers cases and prepositions, often in com-
bination. For instance, the German verb lieben
(?love?) takes a plain accusative argument, fol-
gen (?love?) a plain dative, and warten (?wait?)
the preposition auf with the accusative. From the
abstract syntax point of view, all of them are NP-
complement verbs. Cases and prepositions, and
thereby transitivity, are defined in concrete syntax.
The category Cl, clause, is the discontinuous
structure of sentences before word order is deter-
mined. Its instance Cl (c np O) corresponds to
the slash categories S/NP and S/PP in GPSG.
Similarly, VP (c np O) corresponds to VP/NP
and VP/PP, Adv (c np O) to Adv/NP (preposi-
tions), and so on.
2. Initial formation of verb phases. A VP is
formed from a V by fixing its tense and polarity.
In the resulting VP, the verb depends only on the
agreement features of the expected subject. The
complement case comes from the verb?s lexical
entry, but the other fields?such as the objects?
are left empty. This makes the VP usable in both
complementation and slash operations (where the
subject is added before some complement).
VPs can also be formed from adverbials, ad-
jectival phrases, and common nouns, by adding a
copula. Thus was in results from applying UseAdv
to the preposition (i.e. Adv/NP) in, and expands to
a VP with ComplNP (was in France) and to a slash
clause with PredVP (she was in).
3. Complementation, VP slash formation, re-
flexivization. The Compl functions in Figure 2.3
provide each verb phrase with its ?first? comple-
ment. The Slash functions provide the ?last?
complement, leaving a ?gap? in the middle. For
instance, SlashCl provides the slash clause used
in the question whom did you tell that we sleep.
The Refl rules fill argument places with reflexive
pronouns.
4. NP-VP predication, slash termination, and
adverbial modification. PredVP is the basic NP-
VP predication rule. With x = c np O, it be-
comes the rule that combines NP with VP/NP to
form S/NP. SlashTerm is the GPSG ?slash termi-
5
1. Argument lists and some dependent categories
cat Arg ; Args -- arguments and argument lists
fun ap, cl, cn, np, qcl, vp : Arg -- AP, Cl, CN, NP, QCl, VP argument
fun O : Args -- no arguments
fun c : Arg -> Args -> Args -- one more argument
cat V (x : Args) -- verb in the lexicon
cat VP (x : Args) -- verb phrase
cat Cl (x : Args) -- clause
cat AP (x : Args) -- adjectival phrase
cat CN (x : Args) -- common noun phrase
cat Adv (x : Args) -- adverbial phrase
2. Initial formation of verb phases
fun UseV : (x : Args) -> Temp -> Pol -> V x -> VP x -- loved (X)
fun UseAP : (x : Args) -> Temp -> Pol -> AP x -> VP x -- was married to (X)
fun UseCN : (x : Args) -> Temp -> Pol -> CN x -> VP x -- was a son of (X)
fun UseAdv : (x : Args) -> Temp -> Pol -> Adv x -> VP x -- was in (X)
3. Complementation, VP slash formation, reflexivization
fun ComplNP : (x : Args) -> VP (c np x) -> NP -> VP x -- love her
fun ComplCl : (x : Args) -> VP (c cl x) -> Cl x -> VP x -- say that we go
fun SlashNP : (x : Args) -> VP (c np (c np x)) -> NP -> VP (c np x) -- show (X) to him
fun SlashCl : (x : Args) -> VP (c np (c cl x)) -> Cl x -> VP (c np x) -- tell (X) that..
fun ReflVP : (x : Args) -> VP (c np x) -> VP x -- love herself
fun ReflVP2 : (x : Args) -> VP (c np (c np x)) -> VP (c np x) -- show (X) to herself
4. NP-VP predication, slash termination, and adverbial modification
fun PredVP : (x : Args) -> NP -> VP x -> Cl x -- she loves (X)
fun SlashTerm : (x : Args) -> Cl (c np x) -> NP -> Cl x -- she loves + X
5. The functorial linearization type of VP
lincat VP = {
verb : Agr => Str * Str * Str ; -- finite: would,have,gone
inf : VVType => Str ; -- infinitive: (not) (to) go
imp : ImpType => Str ; -- imperative: go
c1 : ComplCase ; -- case of first complement
c2 : ComplCase ; -- case of second complement
vvtype : VVType ; -- type of VP complement
adj : Agr => Str ; -- adjective complement
obj1 : Agr => Str ; -- first complement
obj2 : Agr => Str ; -- second complement
objagr : {a : Agr ; objCtr : Bool} ; -- agreement used in object control
adv1 : Str ; -- pre-verb adverb
adv2 : Str ; -- post-verb adverb
ext : Str ; -- extraposed element e.g. that-clause
}
6. Some functorial linearization rules
lin ComplNP x vp np = vp ** {obj1 = \\a => appComplCase vp.c1 np}
lin ComplCl x vp cl = vp ** {ext = that_Compl ++ declSubordCl cl}
lin SlashNP2 x vp np = vp ** {obj2 = \\a => appComplCase vp.c2 np}
lin SlashCl x vp cl = vp ** {ext = that_Compl ++ declSubordCl cl}
7. Some interface parameters
oper Agr, ComplCase : PType -- agreement, complement case
oper appComplCase : ComplCase -> NP -> Str -- apply complement case to NP
oper declSubordCl : Cl -> Str -- subordinate question word order
Figure 2: Dependent types, records, and parameters for predication.
6
nation? rule.
5. The functorial linearization type of VP.
This record type contains the string-valued fields
that can appear in different orders, as well as the
inherent features that are needed when comple-
ments are added. The corresponding record for Cl
has similar fields with constant strings, plus a sub-
ject field.
6. Some functorial linearization rules. The
verb-phrase expanding rules typically work with
record updates, where the old VP is left un-
changed except for a few fields that get new val-
ues. GF uses the symbol ** for record updates.
Notice that ComplCl and SlashCl have exactly
the same linearization rules; the difference comes
from the argument list x in the abstract syntax.
7. Some interface parameters. The code
in Figure 2.5 and 2.6 is shared by different lan-
guages, but it depends on an interface that declares
parameters, some of which are shown here.
5.2 More constructions
Extraction. The formation of questions and rel-
atives is straighforward. Sentential (yes/no) ques-
tions, formed by QuestCl in Figure 3.1, don?t in
many languages need any changes in the clause,
but just a different ordering in final linearization.
Wh questions typically put one interrogative (IP)
in the focus, which may be in the beginning of the
sentence even though the corresponding argument
place in declaratives is later. The focus field in
QCl is used for this purpose. It carries a Boolean
feature saying whether the field is occupied. If its
value is True, the next IP is put into the ?normal?
argument place, as in who loves whom.
Coordination. The VP conjunction rules in
Figure 3.2 take care of both intransitive VPs (she
walks and runs) and of verb phrases with argu-
ments (she loves and hates us). Similarly, Cl con-
juction covers both complete sentences and slash
clauses (she loves and we hate him). Some VP
coordination instances may be ungrammatical, in
particular with inverted word orders. Thus she is
tired and wants to sleep works as a declarative,
but the question is not so good: ?is she tired and
wants to sleep. Preventing this would need a much
more complex rules. Since the goal of our gram-
mar is not to define grammaticality (as in formal
language theory), but to analyse and translate ex-
isting texts, we opted for a simple system in this
case (but did not need to do so elsewhere).
5.3 Semantics
The abstract syntax has straightforward denota-
tional semantics: each type in the Args list of a
category adds an argument to the type of denota-
tions. For instance, the basic VP denotation type is
Ent -> Prop, and the type for an arbitrary sub-
category of VP x is
(x : Args) -> Den x (Ent -> Prop)
where Den is a type family defined recursively
over Args,
Den : Args -> Type -> Type
Den O t = t
Den (c np xs) t = Ent -> Den xs t
Den (c cl xs) t = Prop -> Den xs t
and so on for all values of Arg. The second ar-
gument t varies over the basic denotation types of
VP, AP, Adv, and CN.
Montague-style semantics is readily available
for all rules operating on these categories. As a
logical framework, GF has the expressive power
needed for defining semantics (Ranta, 2004). The
types can moreover be extended to express selec-
tional restrictions, where verb arguments are re-
stricted to domains of individuals. Here is a type
system that adds a domain argument to NP and
VP:
cat NP (d : Dom)
cat VP (d : Dom)(x : Args)
fun PredVP : (d : Dom) -> (x : Args)
-> NP d -> VP d x -> Cl x
The predication rule checks that the NP and the
VP have the same domain.
6 Evaluation
Coverage. The dependent type system for verbs,
verb phrases, and clauses is a generalization of
the old Resource Grammar Library (Ranta, 2009),
which has a set of hard-wired verb subcategories
and a handful of slash categories. While it cov-
ers ?all usual cases?, many logically possible ones
are missing. Some such cases even appear in the
Penn treebank (Marcus et al., 1993), requiring ex-
tra rules in the GF interpretation of the treebank
(Angelov, 2011). An example is a function of type
V (c np (c vp O)) ->
VPC (c np O) -> VP (c np O)
which is used 12 times, for example in This is de-
signed to get the wagons in a circle and defend
the smoking franchise. It has been easy to write
conversion rules showing that the old coverage is
preserved. But it remains future work to see what
new cases are covered by the increased generality.
7
1. Extraction.
cat QCl (x : Args) -- question clause
cat IP -- interrogative phrase
fun QuestCl : (x : Args) -> Cl x -> QCl x -- does she love him
fun QuestVP : (x : Args) -> IP -> VP x -> QCl x -- who loves him
fun QuestSlash : (x : Args) -> IP -> QCl (c np x) -> QCl x -- whom does she love
lincat QCl = Cl ** {focus : {s : Str ; isOcc : Bool}} -- focal IP, whether occupied
2. Coordination.
cat VPC (x : Args) -- VP conjunction
cat ClC (x : Args) -- Clause conjunction
fun StartVPC : (x : Args) -> Conj -> VP x -> VP x -> VPC x -- love or hate
fun ContVPC : (x : Args) -> VP x -> VPC x -> VPC x -- admire, love or hate
fun UseVPC : (x : Args) -> VPC x -> VP x -- [use VPC as VP]
fun StartClC : (x : Args) -> Conj -> Cl x -> Cl x -> ClC x -- he sells and I buy
fun ContClC : (x : Args) -> Cl x -> ClC x -> ClC x -- you steal, he sells and I buy
fun UseClC : (x : Args) -> ClC x -> Cl x -- [use ClC as Cl]
Figure 3: Extraction and coordination.
Multilinguality. How universal are the con-
crete syntax functor and interface? In the stan-
dard RGL, functorization has only been attempted
for families of closely related languages, with Ro-
mance languages sharing 75% of syntax code and
Scandinavian languages 85% (Ranta, 2009). The
new predication grammar shares code across all
languages. The figure to compare is the percent-
age of shared code (abstract syntax + functor + in-
terface) of the total code written for a particular
language (shared + language-specific). This per-
centage is 70 for Chinese, 64 for English, 61 for
Finnish, and 76 for Swedish, when calculated as
lines of code. The total amount of shared code is
760 lines. One example of overrides is negation
and questions in English, which are complicated
by the need of auxiliaries for some verbs (go) but
not for others (be). This explains why Swedish
shares more of the common code than English.
Performance. Dependent types are not inte-
grated in current GF parsers, but checked by post-
processing. This implies a loss of speed, be-
cause many trees are constructed just to be thrown
away. But when we specialized dependent types
and rules to nondependent instances needed by the
lexicon (using them as metarules in the sense of
GPSG), parsing became several times faster than
with the old grammar. An analysis remains to do,
but one hypothesis is that the speed-up is due to
fixing tense and polarity earlier than in the old
RGL: when starting to build VPs, as opposed to
when using clauses in full sentences. Dependent
types made it easy to test this refactoring, since
they reduced the number of rules that had to be
written.
Robustness. Robustness in GF parsing is
achieved by introducing metavariables (?ques-
tion marks?) when tree nodes cannot be con-
structed by the grammar (Angelov, 2011). The
subtrees under a metavariable node are linearized
separately, just like a sequence of chunks. In
translation, this leads to decrease in quality, be-
cause dependencies between chunks are not de-
tected. The early application of tense and polarity
is an improvement, as it makes verb chunks con-
tain information that was previously detected only
if the parser managed to build a whole sentence.
7 Conclusion
We have shown a GF grammar for predication al-
lowing an unlimited variation of argument lists: an
abstract syntax with a concise definition using de-
pendent types, a concrete syntax using a functor
and records, and a straightforward denotational se-
mantics. The grammar has been tested with four
languages and shown promising results in speed
and robustness, also in large-scale processing. A
more general conclusion is that dependent types,
records, and functors are powerful tools both for
computational grammar engineering and for the
theoretical study of languages.
Acknowledgements. I am grateful to Krasimir
Angelov and Robin Cooper for comments, and
to Swedish Research Council for support under
grant nr. 2012-5746 (Reliable Multilingual Dig-
ital Communication).
8
References
K. Angelov and P. Ljungl?of. 2014. Fast statistical pars-
ing with parallel multiple context-free grammars. In
Proceedings of EACL-2014, Gothenburg.
K. Angelov. 2011. The Mechanics of the Grammatical
Framework. Ph.D. thesis, Chalmers University of
Technology.
Y. Bar-Hillel. 1953. A quasi-arithmetical notation for
syntactic description. Language, 29:27?58.
N. Chomsky. 1981. Lectures on Government and
Binding. Mouton de Gruyter.
Y. Coscoy, G. Kahn, and L. Thery. 1995. Extract-
ing text from proofs. In M. Dezani-Ciancaglini and
G. Plotkin, editors, Proc. Second Int. Conf. on Typed
Lambda Calculi and Applications, volume 902 of
LNCS, pages 109?123.
H. B. Curry. 1961. Some logical aspects of grammat-
ical structure. In Roman Jakobson, editor, Structure
of Language and its Mathematical Aspects: Pro-
ceedings of the Twelfth Symposium in Applied Math-
ematics, pages 56?68. American Mathematical So-
ciety.
Ph. de Groote. 2001. Towards Abstract Categorial
Grammars. In Association for Computational Lin-
guistics, 39th Annual Meeting and 10th Conference
of the European Chapter, Toulouse, France, pages
148?155.
P. Diderichsen. 1962. Element?r dansk grammatik.
Gyldendal, K?benhavn.
G. Gazdar, E. Klein, G. Pullum, and I. Sag. 1985. Gen-
eralized Phrase Structure Grammar. Basil Black-
well, Oxford.
R. Harper, F. Honsell, and G. Plotkin. 1993. A Frame-
work for Defining Logics. JACM, 40(1):143?184.
L. Karttunen and M. Kay. 1985. Parsing in a free
word order language. In D. Dowty, L. Karttunen,
and A. Zwicky, editors, Natural Language Pars-
ing, Psychological, Computational, and Theoretical
Perspectives, pages 279?306. Cambridge University
Press.
J. Lambek. 1958. The mathematics of sentence struc-
ture. AmericanMathematical Monthly, 65:154?170.
J. Landsbergen. 1982. Machine translation based
on logically isomorphic Montague grammars. In
COLING-1982.
P. Ljungl?of. 2004. The Expressivity and Com-
plexity of Grammatical Framework. Ph.D.
thesis, Dept. of Computing Science, Chalmers
University of Technology and Gothenburg Uni-
versity. http://www.cs.chalmers.se/
~
peb/
pubs/p04-PhD-thesis.pdf.
L. Magnusson. 1994. The Implementation of ALF - a
Proof Editor based on Martin-L?of?s Monomorphic
Type Theory with Explicit Substitution. Ph.D. thesis,
Department of Computing Science, Chalmers Uni-
versity of Technology and University of G?oteborg.
M. P. Marcus, B. Santorini, and M. A. Marcinkiewicz.
1993. Building a Large Annotated Corpus of En-
glish: The Penn Treebank. Computational Linguis-
tics, 19(2):313?330.
P. Martin-L?of. 1984. Intuitionistic Type Theory. Bib-
liopolis, Napoli.
R. Montague. 1974. Formal Philosophy. Yale Univer-
sity Press, New Haven. Collected papers edited by
Richmond Thomason.
S. M?uller. 2004. Continuous or Discontinuous Con-
stituents? A Comparison between Syntactic Analy-
ses for Constituent Order and Their Processing Sys-
tems. Research on Language and Computation,
2(2):209?257.
R. Muskens. 2001. Lambda Grammars and the
Syntax-Semantics Interface. In R. van Rooy and
M. Stokhof, editors, Proceedings of the Thirteenth
Amsterdam Colloquium, pages 150?155, Amster-
dam. http://let.uvt.nl/general/people/
rmuskens/pubs/amscoll.pdf.
F. J. Newmeyer. 2004. Against a parameter-setting
approach to language variation. Linguistic Variation
Yearbook, 4:181?234.
C. Pollard and I. Sag. 1994. Head-Driven Phrase
Structure Grammar. University of Chicago Press.
A. Ranta. 1994. Type Theoretical Grammar. Oxford
University Press.
A. Ranta. 1997. Structures grammaticales dans le
franc?ais math?ematique. Math?ematiques, informa-
tique et Sciences Humaines, 138/139:5?56/5?36.
A. Ranta. 2004. Computational Semantics in Type
Theory. Mathematics and Social Sciences, 165:31?
57.
A. Ranta. 2009. The GF Resource Grammar
Library. Linguistics in Language Technology,
2. http://elanguage.net/journals/index.
php/lilt/article/viewFile/214/158.
A. Ranta. 2011. Grammatical Framework: Program-
ming with Multilingual Grammars. CSLI Publica-
tions, Stanford.
H. Seki, T. Matsumura, M. Fujii, and T. Kasami. 1991.
On multiple context-free grammars. Theoretical
Computer Science, 88:191?229.
9
Proceedings of the 5th Workshop on South and Southeast Asian NLP, 25th International Conference on Computational Linguistics, pages 55?64,
Dublin, Ireland, August 23-29 2014.
Developing an interlingual translation lexicon using WordNets
and Grammatical Framework
Shafqat Mumtaz Virk
University of Gothenburg,
University of Eng. & Tech. Lahore
virk.shafqat@gmail.com
K.V.S. Prasad
Chalmers University of Technology
prasad@chalmers.se
Aarne Ranta
University of Gothenburg
aarne@chalmers.se
Krasimir Angelov
University of Gothenburg
krasimir@chalmers.se
Abstract
The Grammatical Framework (GF) offers perfect translation between controlled subsets
of natural languages. E.g., an abstract syntax for a set of sentences in school mathematics
is the interlingua between the corresponding sentences in English and Hindi, say. GF
?resource grammars? specify how to say something in English or Hindi; these are re-
used with ?application grammars? that specify what can be said (mathematics, tourist
phrases, etc.). More recent robust parsing and parse-tree disambiguation allow GF to
parse arbitrary English text. We report here an experiment to linearise the resulting
tree directly to other languages (e.g. Hindi, German, etc.), i.e., we use a language-
independent resource grammar as the interlingua. We focus particularly on the last part
of the translation system, the interlingual lexicon and word sense disambiguation (WSD).
We improved the quality of the wide coverage interlingual translation lexicon by using
the Princeton and Universal WordNet data. We then integrated an existing WSD tool
and replaced the usual GF style lexicons, which give one target word per source word,
by the WordNet based lexicons. These new lexicons and WSD improve the quality of
translation in most cases, as we show by examples. Both WordNets and WSD in general
are well known, but this is the first use of these tools with GF.
1 Introduction
1.1 Translation via an interlingua
Interlingual translation scales easily up to a large number of languages. Google translate, for
example, deals with all pairs of 60 languages mostly by using English as a pivot language. In
this way, it can do with just 2 * 59 = 118 sets of bilingual training data, instead of 60 * 59 =
3540 sets. It would be hard to collect and maintain so many pairs, and in many cases, there is
very little data to be found.
The roots of an inter-lingua are perhaps in the medieval idea of a universal grammar (Lyons,
1968), in which a universal representation of meaning can be expressed. Translating via this
interlingua then also means that meaning is conserved in going from the source to the tar-
get language. In recent decades, this idea appears in (Curry, 1961) where the interlingua is
called tectogrammar, in the Rosetta project (Rosetta, 1994), building on the semantic models
of (Montague, 1974), and in the UNL (Universal Networking Language) project.
Incidentally, interlingua is also the heart of modern compiler technology. For instance, the
GNU Compiler Collection (Stallman, 2001) uses a shared tree representation to factor out the
majority of compilation phases between a large number of source and target languages. Compiler
writers save work, and semantics is preserved by design. A compiler, then, is built as a pipeline
with parsing from a source language to an abstract syntax tree, which is analyzed and
optimized in the language-independent phases, and finally linearized to a target language.
This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and
proceedings footer are added by the organizers. License details: http://creativecommons.org/licenses/by/4.
0/
55
It is easy to see an analogy between this pipeline and the way a human language translator
could work. But how to make it real? How to scale up to the full size of natural languages?
1.2 WordNets
In current machine translation research, interlingual methods are marginal, despite the wide use
of pivot languages in systems like Google translate. Closest to the mainstream perhaps is the
development of linked WordNets. The original Princeton Wordnet for English (Miller, 1995) de-
fines a set of word senses, which many other wordnets map to other languages. Implementations
of this idea are Finnish (Lind?n and Carlson., 2010) and Hindi (Hindi-WordNet, 2012).
In the linked Wordnet approach, the Princeton WordNet senses work as an interlingua, albeit
only on the level of the lexicon. (Lind?n and Carlson., 2010) give strong arguments why in fact
this is a good way to go, despite the often emphasized fact that different languages divide the
world in different ways, so that the senses of their word don?t map one to one. The evidence from
the English-Finnish case shows that 80% of the mappings are one-to-one and un-problematic.
As this part of the lexicon can be easily reused, linguists and system builders can concentrate
their effort on the remaining 20%.
The Universal WordNet (de Melo and Weikum, 2009) works on the same lines. Building on
the Princeton WordNet, it populates the mappings to over 200 different languages by collecting
data from different sources (such as the Wikipedia) and using supervised machine learning
techniques to propagate the knowledge and infer more of it. What makes it a particularly
interesting resource is that it is freely available under the most liberal licenses, as is the original
Princeton WordNet,
1.3 GF
Grammatical Framework (GF)(Ranta, 2004) is a grammar formalism tool based on Martin
L?f?s type theory (Martin-L?f, 1982). It can be seen as a tool to build interlingua based trans-
lation systems. GF works like a compiler: the source language is parsed to an abstract syntax
tree, which is then linearized to the target language. The parsing and linearization component
are defined by using Parallel Multiple Context-Free Grammars (PMCFG, (Seki et al., 1991),
(Ljungl?f, 2004)), which give GF an expressive power between mildly and fully context-sensitive
grammars. Thus GF can easily handle with language-specific variations in morphology, word
order, and discontinuous constituents, while maintaining a shared abstract syntax.
Historically, the main use of GF has been in controlled language implementations, e.g., (Ranta
and Angelov, 2010; Angelov and Enache, 2010; Ranta et al., 2012) and natural language
generation, e.g., (Dymetman et al., 2000), both applied in multilingual settings with up to 15
parallel languages. In recent years, the coverage of GF grammars and the processing performance
has enabled open-domain tasks such as treebank parsing (Angelov, 2011) and hybrid translation
of patents (Enache et al., 2012). The general purpose Resource Grammar Library (RGL)(Ranta,
2011) has grown to 30 languages. It includes the major European languages, South Asian
languages like Hindi/Urdu (Prasad and Shafqat, 2012), Nepali and Punjabi (Shafqat et al.,
2011), the Southeast Asian language Thai, and Japanese and Chinese.
However, GF has yet not been exploited for arbitrary text parsing and translation. To do
this, we have to meet several challenges: robust parsing, parse-tree disambiguation, word sense
disambiguation, and development of a wide-coverage interlingual translation lexicon. This paper
focuses on the latter two. We report first a method of using the WordNets (Princeton and
Universal) to build an interlingual full-form, multiple sense translation lexicon. Then, we show
how these lexicons together with a word sense disambiguation tool can be plugged in a translation
pipeline. Finally, we describe an experimental setup and give many examples to highlight the
effects of this work.
56
1.4 South Asian languages
While the work described here can apply to any language, it is particularly interesting for South
Asian languages. In these languages, statistical tools do not have much bilingual training data to
work on, so Google translate and similar tools are not as useful as they are with better resourced
languages. At the same time, there is an urgent and widely recognised need for translations from
English to the various languages of South Asia. Fortunately, word nets are being built for many
of them, so that the techniques described here can be applied.
2 From Universal WordNet to a GF Lexicon
The original Princeton WordNet (Miller, 1995) defines a set of word senses, and the Universal
WordNet (de Melo and Weikum, 2009) maps them to different languages. In this multilingual
scenario, the Princeton WordNet senses can be seen as an abstract representation, while the
Universal WordNet mappings can be seen as concrete representation of those senses in different
languages. GF grammars use very much the same technique of one common abstract and
multiple parallel concrete representations to achieve multilingualism. Due to this compatibility,
it is easy to build a multilingual GF lexicon using data from those two resources (i.e. Princeton
and Universal WordNets). This section briefly describes the experiment we did to build one
abstract and multiple concrete GF lexicons for a number of languages including German, French,
Finnish, Swedish, Hindi, and Bulgarian. The method is very general, so can be used to build a
similar lexicon for any other language for which data is available in the Universal WordNet.
2.1 GF Abstract Lexicon
The Princeton WordNet data is distributed in the form of different database files. For each of
the four lexical categories (i.e. noun, verb, adjective, and adverb), two files named ?index.pos?
and ?data.pos? are provided, where ?pos? is noun, verb, adj and adv. Each of the ?index.pos?
files contains all words, including synonyms of the words, found in the corresponding part of
speech category. Each of the ?data.pos? files contains information about unique senses belonging
to the corresponding part of speech category. For our purposes, there were two possible choices
to build an abstract representation of the lexicon:
1. To include all words of the four lexical categories, and also their synonyms (i.e. to build
the lexicon from ?index.pos? files)
2. To include only unique senses of the four categories with one word per sense, but not the
synonyms (i.e. to build the lexicon from the data.pos? files)
To better understand this difference, consider the words ?brother? and ?buddy?. The word
?brother? has five senses with sense offsets ?08111676?, ?08112052?, ?08112961?, ?08112265? and
?08111905? in the Princeton WordNet 1.7.11, while the word ?buddy? has only one sense with the
sense offset ?08112961?. Choosing option (1) means that we have to include the following entries
in our abstract lexicon.
brother_08111676_N
brother_08112052_N
brother_08112961_N
brother_08112265_N
brother_08111905_N
buddy_08112961_N
We can see that the sense with the offset ?08112961? is duplicated in the lexicon: once with
the lemma ?brother? and then with the lemma ?buddy?. However, if we choose option (2), we
end up with the following entries.
1We choose WordNet 1.7.1, because the word sense disambiguator that we are using in our translation pipeline
is based on WordNet 1.7.1
57
brother_08111676_N
brother_08112052_N
brother_08112265_N
brother_08111905_N
buddy_08112961_N
Since the file ?data.noun? lists the unique senses rather than the words, their will be no
duplication of the senses. However, the choice has an obvious effect on the lexicon coverage, and
depending on whether we want to use it as a parsing or as a linearization lexicon, the choice
becomes critical. Currently, we choose option (2) for the following two reasons:
1. The Universal WordNet provides mappings for synsets (i.e. unique senses) but not for the
individual synonyms of the synsets. If we choose option (1), as mentioned previously, we
have to list all synonyms in our abstract representation. But, as translations are available
only for synsets, we have to put the same translation against each of the synonyms of the
synset in our concrete representations. This will not gain us anything (as long as we use
these lexicon as linearization lexicons), but will increase the size of the lexicon and hence
may have reduce the processing speed of the translation system.
2. At the current stage of our experiments we are using these lexicons as linearization lexicons,
so one translation of each unique sense is enough.
Our abstract GF lexicon covers 91516 synsets out of around 111,273 synsets in the WordNet
1.7.1. We exclude some of the synsets with multi-word lemmas. We consider them more of a
syntactic category rather than a lexical category, and hence deal with them at the syntax level.
Here, we give a small segment of our abstract GF lexicon.
abstract LinkedDictAbs = Cat ** {
fun consecutive_01624944_A : A ;
fun consequently_00061939_Adv : Adv ;
fun conservation_06171333_N : N ;
fun conspire_00562077_V : V ;
fun sing_01362553_V2 : V2 ;
........
}
The first line in the above given code states that the module ?LinkedDictAbs? is an abstract
representation (note the keyword ?abstract?). This module extends (achieved by ?**? operator)
another module labeled ?Cat2? which, in this case, has definitions for the morphological categories
?A?, ?Adv?, ?N? and ?V?. These categories correspond to the ?adjective?, ?adverb?, ?noun?, and ?verb?
categories in the WordNet respectively. However, note that in GF resource grammars we have
a fine-grained morphological division for verbs. We sub-categorize them according to their
valencies i.e ?V? is for intransitive, and ?V2? for transitive verbs. We refer to (Bringert et al.,
2011) for more details on these divisions.
Each entry in this module is of the following general type:
fun lemma_senseOffset_t : t ;
Keyword ?fun? declares each entry as a function of the type ?t?. The function name is composed
of lemma, sense offset and a type ?t?, where lemma and sense offset are same as in the Princeton
WordNet, while ?t? is one of the morphological types in GF resource grammars.
This abstract representation will serve as a pivot for all concrete representations, which are
described next.
2This module has definitions of different morphological and syntactic categories in the GF resource grammar
library
58
2.2 GF Concrete Lexicons
We build the concrete representations for different languages using the translations obtained
from the Universal WordNet data and GF morphological paradigms (D?trez and Ranta, 2012;
Bringert et al., 2011). The Universal WordNet translations are tagged with a sense offset from
WordNet 3.03 and also with a confidence score. As, an example consider the following segment
form the Universal WordNet data, showing German translations for the noun synset with offset
?13810818? and lemma ?rest? (in the sense of ?remainder?).
n13810818 Rest 1.052756
n13810818 Abbrand 0.95462
n13810818 Ruckstand 0.924376
Each entry is of the following general type.
posSenseOffset translation confidence-score
If we have more than one candidate translation for the same sense (as in the above case),
we select the best one (i.e. with the maximum confidence score) and put it in the concrete
grammar. Next, we give a small segment from the German concrete lexicon.
concrete LinkedDictGer of LinkedDictAbs = CatGer ** open
ParadigmsGer, IrregGer,Prelude in {
lin consecutive_01624944_A = mkA "aufeinanderfolgend" ;
lin consequently_00061939_Adv = mkAdv "infolgedessen" ;
lin conservation_06171333_N = mkN "Konservierung" ;
lin conspire_00562077_V = mkV "anzetteln" ;
lin sing_01362553_V2 = mkV2 (mkV "singen" ) ;
......
}
The first line declares ?LinkedDictGer? to be the concrete representation of the previously
defined abstract representation (note the keyword ?concrete? at the start of the line). Each entry
in this representation is of the following general type:
lin lemma_senseOffset_t = paradigmName "translation" ;
Keyword ?lin? declares each entry to be a linearization of the corresponding function in the
abstract representation. ?paradigmName? is one of the morphological paradigms defined in the
?ParadigmsGer? module. So in the above code, ?mkA?, ?mkAdv?, ?mkN?, ?mkV? and ?mkV2? are
the German morphological paradigms4 for different lexical categories of ?adjective?, ?adverb?,
?noun?, ?intransitive verb?, and ?transitive verb? respectively. ?translation? is the best possible
translation obtained from the Universal WordNet. This translation is passed to a paradigm as
a base word, which then builds a full-form inflection table. These tables are then used in the
linearization phase of the translation system (see section 3)
Concrete lexicons for all other languages were developed using the same procedure. Table 1
gives some statistics about the coverage of these lexicons.
Language Number of Entries Language Number of Entries
Abstract 91516 German 49439
French 38261 Finnish 27673
Swedish 23862 Hindi 16654
Bulgarian 12425
Table 1: Lexicon Coverage Statistics
3However, in our concrete lexicons we match them to WordNet 1.7.1 for the reasons mentioned previously
4See (Bringert et al., 2011) for more details on these paradigms
59
3 System architecture
Figure 1 shows an architecture of the translation pipeline. The architecture is inter-lingual
and uses the Resource Grammar Library (RGL) of Grammatical Framework (Ranta, 2011) as
the syntax and semantics component, Penn Treebank data for parse-tree disambiguation and
IMS(It Makes Sense)(Zhong and Ng, 2010) as a word sense disambiguation tool. Even though
the syntax, semantics and parse-tree disambiguation are not the main topics of this paper,
we give the full architecture to show where the work reported in this paper fits. Internal GF
resources (e.g. resource grammars and dictionaries) are shown in rectangles while the external
components (e.g. PennTreebank and IMS(Zhong and Ng, 2010): a wide coverage word sense
disambiguation system for arbitrary text.) are shown in double-stroked rectangles.
With reference to Figure 1: The input is parsed using English resource grammar (EngRG)
and a comprehensive English dictionary (DictEng). If the input is syntactically ambiguous the
parser will return more than one parse-tree. These trees are disambiguated using a statistical
model build from the PennTreebank data. The best tree is further processed using the input
from the IMS to tag the lexical nodes with best sense identifiers. This tree is finally linearized
to the target language using the target language resource grammar (TLRG) together with the
target language lexicon (LinkedDict) discussed in section 2.
Inp
ut
Parsing
EngRG+DictEng
Pa
rse
-Tr
ee
s
Parse Tree 
Disambigu
ation
Be
st-
Tre
e
Word 
Sense 
Disambigu
ation
Linearizati
on
Sense-Ta
gged-Tre
e
IMS
TLRG+LinkedDict
Out
put
Penn Treebank
EngRG: English Resource Grammar
TLRG: Target Language Resource Grammar
Figure 1: The translation pipeline.
4 Experimental Setup and Evaluation
Our experimental setup is as follows: We take some English text as source, and translate it to a
target language (German and Hindi in these experiments) by passing it through the translation
pipeline described in section 3. To show the usefulness of the lexicons described in section 2 and
for comparison, we translate the same source twice: with and without word sense disambiguation.
For the first attempt, we used exactly the same translation pipeline as shown in Figure 1,
except that to overcome the deficiencies of our existing parse-tree disambiguator, for some of
the examples, we used trees directly from the PennTreebank, which are supposed to be correct.
However, this should not damage the claims made in this paper which is about developing
wide coverage interlingual translation lexicons and then using them for WSD in an interlingual
translation pipeline.
For the second attempt, we plugged out the word sense disambiguation form the translation
pipeline and used our old GF style lexicons (one target word per source word irrespective of its
sense) in the linearization phase.
Finally, we compared both candidate translations to see if we have gained anything. We did
both manual and automatic evaluations to confirm our findings.
For a set of 25 sentences for English-German pair we got marginal BLEU score improvements
(from 0.3904 to 0.399 with ?old? and ?new? dictionaries). Manual inspection, however, was much
more encouraging, and explained the reasons for very low improvements in the BLEU scores in
some cases. The reason was that even if the word sense disambiguation, and hence, our new
60
lexicon gives a better lexical choice, it will still be considered ?wrong? by the evaluation tool if the
gold-standard has a different choice. It was also observed that there were cases where the ?old?
lexicon produced a much better translation than the ?new? one. The reasons for this are obvious.
The word sense disambiguator has its own limitations and is known to make mistakes. Also, as
explained in Section 5, the lexicon cannot be guaranteed to always give the right translation.
Next, we give a number of example sentence with comments5 to show that how the new
lexicons improved the quality of translations, and also give some examples where it worked the
other way around.
4.1 German
1. Source He increases the board to seven
Without WSD er erh?ht das Brett nach einigen sieben
With WSD er vergr??ert die Beh?rde nach einigen sieben
Comments das Brett is a wooden board (wrong); erh?ht means ?to raise?. while
vergr??ert means ?increases the size?. Note the wrong preposition choice (?to? should
be zu rather than nach). Also, an indefinite determiner (einige, some) has been
wrongly added to the cardinal number is used as a noun phrase.
2. Source the index uses a base of 100 in 1,982
Without WSD das Verzeichnis verwendet eine Base nach einige 100 in einigen
1982
With WSD der [index_11688271_N] nutzt einen Operationsbasis von einigen
100 in einigen 1982
Comments Note the untranslated word in the WSD version. Base means a chemical base,
the wrong meaning here. Operationsbasis is not the best choice, but acceptable.
3. Source fear is the father of panic
With WSD Angst ist der Papa von Angst
Comment The traditional hilarious example, saying ?fear is fear?s daddy?.
4.2 Hindi
To represent Hindi, we use an IPA style alphabet, with the usual values and conventions.
Retroflexed sounds are written with a dot under the letter: ?, ?, and ? (a flap) are com-
mon, while ? and ? occur in Sanskritised Hindi (though many dialects pronounce them n and
?). The palatalised spirant is shown ? and aspirated stops are shown thus: kh. A macron over a
vowel denotes a long vowel, and ?, nasalisation. In Hindi, e and o are always long, so the macron
is dropped. Finally, we use ? to mean the nasal homorganic with the following consonant.
Here are examples from our evaluation showing that the WSD system works well; the versions
without WSD merely pick the first synonym in the lexicon.
1. Source Mr Baris is a lawyer in New York .
Without WSD Mr Baris New York m? k?n?n k? pa??it h?
With WSD Mr Baris New York m? vak?l h?
Word order Mr Baris New York in lawyer is
Comments k?n?n k? pa??it is ?expert/teacher in law?, while vak?l means ?lawyer?.
2. Source we don?t depend on pharmaceutical companies for our support
Without WSD ham au?adh?ya sahy?g? par ham?re bhara? p??a? ke liye nah??
nirte h??.
5For the comments on German, we are indebted to Erzsebet Galgoczy and Wolfgang Ahrendt, our colleagues
and German informants.
61
With WSD ham au?adh?ya ka?pan? par ham?re nirv?h vyay ke liye nah?? ?te h??.
Word order We pharmaceutical companies on our subsistence expenditure for
not ??? do
Comments sahy?g? means ?company? in the sense of ?colleagues?, nirv?h vyay means
?subsistence expenditure? , while bhara? p??a? means ?weight bearing?. The penul-
timate word in both versions is nonsense, and the lexicons need to be debugged.
3. Source you may recall that a triangle is also a polygon
Without WSD tum "recall may" ho ki ?r?yengl "also" bahubhuj h?
With WSD tum smara? kar sakte ho ki triko? bh? bahubhuj h?
Word order You recall do can that triangle also polygon is
Comments The version without WSD has several missing words. The WSD version of
?recall? is not idiomatic, but understandable.
It should be noted that the coverage of the Hindi lexicon is lowest of all the lexicons given
in Table 1. The result is that many sentences have missing words in the translations. Also,
there is considerable interference with Urdu words (some stemming from the shared base
grammar (Prasad and Shafqat, 2012)). Further, some mappings coming from the Universal
WordNet data are in roman, as opposed to Devanagari (the usual script for Hindi, and what
the grammar is based on), so these need to be transcribed. Finally, idiomatic phrases are
a problem (?before the law? is likely to be rendered ?(temporally) before the law? rather
than ?in the eyes of the law?).
5 The next steps
Since the Universal WordNet mappings are produced from parallel data by machine learning
techniques, the translations are not always accurate and do not always make the best possible
choice. This leaves a window for improvement in the quality of the reported lexicons. One
way of improvement is the manual inspection/correction, not an easy task for a wide-coverage
lexicon with around 100 thousand entries, but not impossible either. This would be a one-time
task with a strong impact on the quality of the lexicon. Another way is to use manually built
WordNets, such as the Finnish and Hindi WordNets. In our work, the availability of some of
these resources was an issue, so we leave it for the future. Further, as mentioned in Section 4,
the Hindi lexicon has some script-related issues which should be fixed in future.
When it comes to interlingua-based arbitrary machine translation, an important concern is
the size of lexicons. We are aware of the fact that the size of our lexicons is not comparable to
some of the other similar systems such as ATLAS-II (Fujitsu), where the size of lexicons is in
millions. We have plan to extend the size of lexicons using some of the other publicly available
resources (such as Hindi WordNet) and/or using parallel corpus. The development of bilingual
lexicons form parallel corpus have been previously explored (Delpech et al., 2012; Qian et al.,
2012), and the same ideas can be applied in our case.
6 Conclusion
We have shown how to use existing lexical resources such as WordNets to develop an interlingual
translation lexicon in GF, and how to use it for the WSD task in an arbitrary text translation
pipeline. The improvements in the translation quality (lexical), shown by examples in Section
4, are encouraging and motivate further work in this direction. However, it should be noted
that there is still a lot of work to be done (especially in the open domain text parsing and
parse-tree disambiguation phases of the translation pipeline) to bring the translation system to
a competitive level. For the reasons noted in the introduction, we expect our techniques to be
particularly useful for South Asian languages.
62
References
Angelov, K. (2011). The Mechanics of the Grammatical Framework. PhD thesis, Chalmers University
Of Technology. ISBN 978-91-7385-605-8.
Angelov, K. and Enache, R. (2010). Typeful Ontologies with Direct Multilingual Verbalization. In Fuchs,
N. and Rosner, M., editors, CNL 2010, Controlled Natural Language.
Bringert, B., Hallgren, T., and Ranta., A. (2011). GF resource grammar library synopsis.
www.grammaticalframework.org/lib/doc/synopsis.html.
Curry, H. B. (1961). Some logical aspects of grammatical structure. In Jakobson, R., editor, Structure of
Language and its Mathematical Aspects: Proceedings of the Twelfth Symposium in Applied Mathematics,
pages 56?68. American Mathematical Society.
de Melo, G. and Weikum, G. (2009). Towards a Universal Wordnet by learning from combined evidence.
In Proceedings of the 18th ACM Conference on Information and Knowledge Management (CIKM 2009),
pages 513?522, New York, NY, USA. ACM.
Delpech, E., Daille, B., Morin, E., and Lemaire, C. (2012). Extraction of domain-specific bilingual lexicon
from comparable corpora: Compositional translation and ranking. In Proceedings of COLING 2012,
pages 745?762, Mumbai, India. The COLING 2012 Organizing Committee.
D?trez, G. and Ranta, A. (2012). Smart paradigms and the predictability and complexity of inflectional
morphology. In EACL, pages 645?653.
Dymetman, M., Lux, V., and Ranta, A. (2000). XML and multilingual document authoring: Conver-
gent trends. In Proc. Computational Linguistics COLING, Saarbr?cken, Germany, pages 243?249.
International Committee on Computational Linguistics.
Enache, R., Espa?a-Bonet, C., Ranta, A., and M?rquez, L. (2012). A hybrid system for patent translation.
In Proceedings of the 16th Annual Conference of the European Association for Machine Translation
(EAMT12), Trento, Italy.
Hindi-WordNet (2012). Hindi Wordnet. 2012. Universal Word?Hindi Lexicon.
http://www.cfilt.iitb.ac.in.
Lind?n, K. and Carlson., L. (2010). Finnwordnet?wordnet p? finska via ?vers?ttning. Lexi-
coNordica?Nordic Journal of Lexicography, 17:119?140.
Ljungl?f, P. (2004). The Expressivity and Complexity of Grammatical Framework. PhD thesis, Dept. of
Computing Science, Chalmers University of Technology and Gothenburg University. http://www.cs.
chalmers.se/~peb/pubs/p04-PhD-thesis.pdf.
Lyons, J. (1968). Introduction to theoretical linguistics. Cambridge: Cambridge University Press.
Martin-L?f, P. (1982). Constructive mathematics and computer programming. In Cohen, Los, Pfeif-
fer, and Podewski, editors, Logic, Methodology and Philosophy of Science VI, pages 153?175. North-
Holland, Amsterdam.
Miller, G. A. (1995). Wordnet: A lexical database for English. Communications of the ACM, 38:39?41.
Montague, R. (1974). Formal Philosophy. Yale University Press, New Haven. Collected papers edited
by Richmond Thomason.
Prasad, K. V. S. and Shafqat, M. V. (2012). Computational evidence that Hindi and Urdu share a
grammar but not the lexicon. In The 3rd Workshop on South and Southeast Asian NLP, COLING.
Qian, L., Wang, H., Zhou, G., and Zhu, Q. (2012). Bilingual lexicon construction from comparable
corpora via dependency mapping. In Proceedings of COLING 2012, pages 2275?2290, Mumbai, India.
The COLING 2012 Organizing Committee.
Ranta, A. (2004). Grammatical Framework: A Type-Theoretical Grammar Formalism. The Journal of
Functional Programming, 14(2):145?189. http://www.cse.chalmers.se/~aarne/articles/gf-jfp.
pdf.
Ranta, A. (2011). Grammatical Framework: Programming with Multilingual Grammars. CSLI Publica-
tions, Stanford. ISBN-10: 1-57586-626-9 (Paper), 1-57586-627-7 (Cloth).
63
Ranta, A. and Angelov, K. (2010). Implementing Controlled Languages in GF. In Proceedings of CNL-
2009, Athens, volume 5972 of LNCS, pages 82?101.
Ranta, A., D?trez, G., and Enache, R. (2012). Controlled language for everyday use: the MOLTO
phrasebook. In CNL 2012: Controlled Natural Language, volume 7175 of LNCS/LNAI.
Rosetta, M. T. (1994). Compositional Translation. Kluwer, Dordrecht.
Seki, H., Matsumura, T., Fujii, M., and Kasami, T. (1991). On multiple context-free grammars. Theo-
retical Computer Science, 88:191?229.
Shafqat, M., Humayoun, M., and Aarne, R. (2011). An open source Punjabi resource grammar. In Pro-
ceedings of the International Conference Recent Advances in Natural Language Processing 2011, pages
70?76, Hissar, Bulgaria. RANLP 2011 Organising Committee. http://aclweb.org/anthology/R11-1010.
Stallman, R. (2001). Using and Porting the GNU Compiler Collection. Free Software Foundation.
Zhong, Z. and Ng, H. T. (2010). It makes sense: A wide-coverage word sense disambiguation system
for free text. In Proceedings of the ACL 2010 System Demonstrations, pages 78?83, Uppsala, Sweden.
Association for Computational Linguistics. http://www.aclweb.org/anthology/P10-4014.
64
