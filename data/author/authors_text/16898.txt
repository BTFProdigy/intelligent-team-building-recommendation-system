First Joint Conference on Lexical and Computational Semantics (*SEM), pages 59?64,
Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational Linguistics
Statistical Thesaurus Construction for a Morphologically Rich Language 
 
Chaya Liebeskind, Ido Dagan and Jonathan Schler                    
Computer Science Department 
Bar-Ilan University 
Ramat-Gan, Israel 
liebchaya@gmail.com, dagan@cs.biu.ac.il, schler@gmail.com 
 
 
 
 
 
Abstract 
Corpus-based thesaurus construction for Mor-
phologically Rich Languages (MRL) is a com-
plex task, due to the morphological variability 
of MRL. In this paper we explore alternative 
term representations, complemented by cluster-
ing of morphological variants. We introduce a 
generic algorithmic scheme for thesaurus con-
struction in MRL, and demonstrate the empiri-
cal benefit of our methodology for a Hebrew 
thesaurus. 
1 Introduction 
Corpus-based thesaurus construction has been an 
active research area (Grefenstette, 1994; Curran 
and Moens, 2002; Kilgarriff, 2003; Rychly and 
Kilgarriff, 2007). Typically, two statistical ap-
proaches for identifying semantic relationships 
between words were investigated: first-order, co-
occurrence-based methods which assume that 
words that occur frequently together are topically 
related (Schutze and Pederson, 1997) and second-
order, distributional similarity methods (Hindle, 
1990; Lin, 1998; Gasperin et al 2001; Weeds and 
Weir, 2003; Kotlerman et al, 2010), which suggest 
that words occurring within similar contexts are 
semantically similar (Harris, 1968).  
While most prior work focused on English, we 
are interested in applying these methods to MRL. 
Such languages, Hebrew in our case, are character-
ized by highly productive morphology which may 
produce as many as thousands of word forms for a 
given root form.    
Thesauri usually provide related terms for each 
entry term (denoted target term). Since both target 
and related terms correspond to word lemmas, sta-
tistics collection from the corpus would be most 
directly applied at the lemma level as well, using a 
morphological analyzer and tagger (Linden and 
Piitulainen, 2004; Peirsman et al, 2008; Rapp, 
2009). However, due to the rich and challenging 
morphology of MRL, such tools often have limited 
performance. In our research, the accuracy of a 
state-of-the-art modern Hebrew tagger on a cross 
genre corpus was only about 60%. 
Considering such limited performance of mor-
phological processing, we propose a schematic 
methodology for generating a co-occurrence based 
thesaurus in MRL. In particular, we propose and 
investigate three options for term representation, 
namely surface form, lemma and multiple lemmas, 
supplemented with clustering of term variants. 
While the default lemma representation is depend-
ent on tagger performance, the two other represen-
tations avoid choosing the right lemma for each 
word occurrence. Instead, the multiple-lemma rep-
resentation assumes that the right analysis will ac-
cumulate enough statistical prominence throughout 
the corpus, while the surface representation solves 
morphological disambiguation "in retrospect", by 
clustering term variants at the end of the extraction 
process. As the methodology provides a generic 
scheme for exploring the alternative representation 
levels, each corpus and language-specific tool set 
might yield a different optimal configuration. 
2 Methodology  
Thesauri usually contain thousands of entries, 
termed here target terms. Each entry holds a list of 
related terms, covering various semantic relations. 
In this paper we assume that the list of target terms 
59
is given as input, and focus on the process of ex-
tracting a ranked list of candidate related terms 
(termed candidate terms) for each target term. The 
top ranked candidates may be further examined 
(manually) by a lexicographer, who will select the 
eventual related terms for the thesaurus entry. 
Our methodology was applied for statistical 
measures of first order similarity (word co-
occurrence). These statistics consider the number 
of times each candidate term co-occurs with the 
target term in the same document, relative to their 
total frequencies in the corpus. Common co-
occurrence metrics are Dice coefficient (Smadja et 
al, 1996), Pointwise Mutual Information (PMI) 
(Church and Hanks, 1990) and log-likelihood test 
(Dunning, 1993). 
2.1 Term Representation 
Statistical extraction is affected by term 
representation in the corpus. Usually, related terms 
in a thesaurus are lemmas, which can be identified 
by morphological disambiguation tools. However, 
we present two other approaches for term 
representation (either a target term or a candidate 
related term), which are less dependent on 
morphological processing.  
Typically, a morphological analyzer produces 
all possible analyses for a given token in the cor-
pus. Then, a Part Of Speech (POS) tagger selects 
the most probable analysis and solves morphology 
disambiguation. However, considering the poor 
performance of the POS tagger on our corpus, we 
distinguish between these two analysis levels. 
Consequently, we examined three levels of term 
representation: (i) Surface form (surface) (ii) Best 
lemma, as indentified by a POS tagger (best), and 
(iii) All possible lemmas, produced by a morpho-
logical analyzer (all). 
2.2 Algorithmic Scheme 
We used the following algorithmic scheme for the-
saurus construction. Our input is a target term in 
one of the possible term representations (surface, 
best or all). For each target term we retrieve all the 
documents in the corpus where the target term ap-
pears. Then, we define a set of candidate terms that 
consists of all the terms that appear in all these 
documents (this again for each of the three possible 
term representations). Next, a co-occurrence score 
between the target term and each of the candidates 
is calculated. Then, candidates are sorted, and the 
highest rated candidate terms are clustered into 
lemma-oriented clusters. Finally, we rank the clus-
ters according to their members' co-occurrence 
scores and the highest rated clusters become relat-
ed terms in the thesaurus. 
Figure 1 presents the algorithm?s pseudo code. 
The notion rep(term) is used to describe the possi-
ble term representations and may be either surface, 
best or all. In our experiments, when 
rep(target_term)=best, the correct lemma was 
manually assigned (assuming a lexicographer in-
volvement with each thesaurus entry in our set-
ting). While, when rep(word)=best, the most prob-
able lemma is assigned by the tagger (since there 
are numerous candidates for each target term we 
cannot resort the manual involvement for each of 
them).  The two choices for rep(term) are inde-
pendent, resulting in nine possible configurations 
of the algorithm for representing both the target 
term and the candidate terms. Thus, these 9 con-
figurations cover the space of possibilities for term 
representation. Exploring all of them in a systemat-
ic manner would reveal the best configuration in a 
particular setting.  
Figure 1: Methodology implementation algorithm 
2.3 Clustering 
The algorithm of Figure 1 suggests clustering the 
extracted candidates before considering them for 
the thesaurus. Clustering aims at grouping together 
related terms with the same lemma into clusters, 
using some measure of morphological equivalence. 
Accordingly, an equivalence measure between re-
lated terms needs to be defined, and a clustering 
Input: target term, corpus, a pair of values for 
rep(target_term) and rep(word) 
Output: clusters of related terms 
 
target_term   rep(target_term) 
docs_list   search(target_term) 
FOR doc IN docs_list 
    FOR word IN doc 
        add rep(word) to candidates 
    ENDFOR 
ENDFOR 
compute co-occurrence scores for all candidates 
sort(candidates) by score 
clusters  cluster(top(candidates)) 
rank(clusters) 
related terms  top(clusters) 
60
algorithm needs to be selected. Each obtained clus-
ter is intended to correspond to the lemma of a sin-
gle candidate term. Obviously, clustering is mostly 
needed for surface-level representation, in order to 
group all different inflections of the same lemma. 
Yet, we note that it was also found necessary for 
the lemma-level representations, because the tag-
ger often identifies slightly different lemmas for 
the same term.  
The equivalence measure is used for building a 
graph representation of the related terms. We rep-
resented each term by a vertex and added an edge 
between each pair of terms that were deemed 
equivalent. We investigated alternative equiva-
lence measures for measuring the morphological 
distance between two vertices in our graph. We 
considered the string edit distance measure and 
suggested two morphological-based equivalence 
measures. The first measure, given two vertices' 
terms, extracts all possible lemmas for each term 
and searches for an overlap of at least one lemma. 
The second measure considers the most probable 
lemma of the vertices' terms and checks whether 
these lemmas are equal. The probability of a lem-
ma was defined as the sum of probabilities for all 
morphological analyses containing the lemma, us-
ing a morpho-lexical context-independent proba-
bilities approximation (Goldberg et al, 2008). The 
clustering was done by finding the connected com-
ponents in our graph of terms using the JUNG1 
implementation (WeakComponentVertexClusterer 
algorithm with default parameters). The connected 
components are expected to correspond to different 
lemmas of terms. Hierarchical clustering methods 
(Jain et al, 1999) were examined as well (Single-
link and Complete-link clustering), but they were 
inferior.  
After applying the clustering algorithm, we re-
ranked the clusters aiming to get the best clusters 
at the top of clusters list. We investigated two scor-
ing approaches for cluster ranking; maximization 
and averaging. The maximization approach assigns 
the maximal score of the cluster members as the 
cluster score. While the averaging approach as-
signs the average of the cluster members' scores as 
the cluster score. The score obtained by either of 
the approaches may be scaled by the cluster length, 
to account for the accumulative impact of all class 
                                                           
1
 http://jung.sourceforge.net/  
members (corresponding to morphological variants 
of the candidate term).  
3 Case Study: Cross-genre Hebrew 
Thesaurus 
Our research targets the construction of a cross 
genre thesaurus for the Responsa project 2 . The 
corpus includes questions posed to rabbis along 
with their detailed rabbinic answers, consisting of 
various genres and styles. It contains 76,710 arti-
cles and about 100 million word tokens, and was 
used for previous IR and NLP research (Choueka, 
1972; Fraenkel, 1976; Choueka et al, 1987; Kernel 
et al 2008). 
Unfortunately, due to the different genres in the 
Responsa corpus, available tools for Hebrew pro-
cessing perform poorly on this corpus. In a prelim-
inary experiment, the POS tagger (Adler and 
Elhadad, 2006) accuracy on the Responsa Corpus 
was less than 60%, while the accuracy of the same 
tagger on modern Hebrew corpora is ~90% (Bar-
Haim et al, 2007).  
For this project, we utilized the MILA Hebrew 
Morphological Analyzer3 (Itai and Wintner, 2008; 
Yona and Wintner, 2008) and the (Adler and 
Elhadad 2006) POS tagger for lemma representa-
tion. The latter had two important characteristics: 
The first is flexibility- This tagger allows adapting 
the estimates of the prior (context-independent) 
probability of each morphological analysis in an 
unsupervised manner, from an unlabeled corpus of 
the target domain (Goldberg et al, 2008). The se-
cond advantage is its mechanism for analyzing un-
known tokens (Adler et al, 2008). Since about 
50% of the words in our corpora are unknown 
(with respect to MILA's lexicon), such mechanism 
is essential.  
For statistics extraction, we used Lucene4. We 
took the top 1000 documents retrieved for the tar-
get term and extracted candidate terms from them. 
Dice coefficient was used as our co-occurrence 
measure, most probable lemma was considered for 
clustering equivalence, and clusters were ranked 
based on maximization, where the maximal score 
was multiplied by cluster size. 
 
                                                           
2
 Corpus kindly provided - http://www.biu.ac.il/jh/Responsa/ 
3
 http://mila.cs.technion.ac.il/mila/eng/tools_analysis.html 
3
 http://mila.cs.technion.ac.il/mila/eng/tools_analysis.html 
4
 http://lucene.apache.org/ 
 i .il
4 lucene.apache.org/ 
 
61
4 Evaluation 
4.1 Dataset and Evaluation Measures 
The results reported in this paper were obtained 
from a sample of 108 randomly selected terms 
from a list of 5000 terms, extracted from two pub-
licly available term lists: the University of Haifa?s 
entry list5 and Hebrew Wikipedia entries6. 
In our experiments, we compared the perfor-
mance of the alternative 9 configurations by four 
commonly used IR measures: precision (P), rela-
tive recall (R), F1, and Average Precision (AP). 
The scores were macro-averaged. We assumed that 
our automatically-generated candidate terms will 
be manually filtered, thus, recall becomes more 
important than precision. Since we do not have any 
pre-defined thesaurus, we evaluated the relative-
recall. Our relative-recall considered the number of 
suitable related terms from the output of all meth-
ods as the full set of related terms. As our system 
yielded a ranked sequence of related terms clusters, 
we also considered their ranking order. Therefore, 
we adopted the recall-oriented AP for ranking 
(Voorhees and Harman, 1999). 
4.2  Annotation Scheme 
The output of the statistical extraction is a ranked 
list of clusters of candidate related terms. Since 
manual annotation is expensive and time consum-
ing, we annotated for the gold standard the top 15 
clusters constructed from the top 50 candidate 
terms, for each target term. Then, an annotator 
judged each of the clusters' terms. A cluster was 
considered as relevant if at least one of its terms 
was judged relevant7. 
4.3 Results 
Table 1 compares the performance of all nine term 
representation configurations. Due to data sparse-
ness, the lemma-based representations of the target 
term outperform its surface representation. How-
ever, the best results were obtained from candidate 
representation at the surface level, which was 
complemented by grouping term variants to lem-
mas in the clustering phase. 
                                                           
5 http://lib.haifa.ac.il/systems/ihp.html 
6 http://he.wikipedia.org 
7
 This was justified by empirical results that found only a few 
clusters with some terms judged positive and others negative  
All best surface Candidate 
  Target 
26.68 29.37 36.59 R 
Surface 18.71 21.09 24.29 P 21.99 24.55 29.20 F1 
14.13 15.83 20.87 AP 
36.97 39.88 46.70 R 
Best 
lemma 
20.94 23.08 25.03 P 
26.74 29.24 32.59 F1 
19.32 20.86 26.84 AP 
42.13 42.52 47.13 R 
All 
 lemmas 
21.23 22.47 23.72 P 
28.24 29.40 31.56 F1 
21.14 22.99 27.86 AP 
Table 1: Performances of the nine configuratrions 
 
Furthermore, we note that the target representa-
tion by all possible lemmas (all) yielded the best R 
and AP scores, which we consider as most im-
portant for the thesaurus construction setting. The 
improvement over the common default best lemma 
representation, for both target and candidate, is 
notable (7 points) and is statistically significant 
according to the two-sided Wilcoxon signed-rank 
test (Wilcoxon, 1945) at the 0.01 level for AP and 
0.05 for R.  
5 Conclusions and Future Work 
We presented a methodological scheme for ex-
ploring alternative term representations in statisti-
cal thesaurus construction for MRL, complemented 
by lemma-oriented clustering at the end of the pro-
cess. The scheme was investigated for a Hebrew 
cross-genre corpus, but can be generically applied 
in other settings to find the optimal configuration 
in each case. 
We plan to adopt our methodology to second 
order distributional similarity methods as well. In 
this case there is an additional dimension, namely 
feature representation, whose representation level 
should be explored as well. In addition, we plan to 
extend our methods to deal with Multi Word Ex-
pressions (MWE). 
Acknowledgments 
This work was partially supported by the 
PASCAL-2 Network of Excellence of the Europe-
an Community FP7-ICT-2007-1-216886. 
 
62
References  
 
Adler Meni and Michael Elhadad. 2006. An Unsuper-
vised Morpheme-Based HMM for Hebrew Morpho-
logical Disambiguation, in Proceedings of COLING-
ACL, Sydney, Australia. 
Adler Meni, Yoav Goldberg, David Gabay and Michael 
Elhadad. 2008. Unsupervised Lexicon-Based Resolu-
tion of Unknown Words for Full Morphological 
Analysis, in Proceedings of ACL. 
Bar-Haim Roy, Khalil Sima'an, and Yoad Winter. 2007. 
Part-of-speech tagging of Modern Hebrew text. Nat-
ural Language Engineering, 14(02):223.251. 
Choueka, Yaacov. 1972. Fast searching and retrieval 
techniques for large dictionaries and concordances. 
Hebrew Computational Linguistics, 6:12?32, July.  
Choueka, Y., A.S. Fraenkel, S.T. Klein and E. Segal. 
1987. Improved techniques for processing queries in 
full-text systems. Proceedings of the 10th annual in-
ternational ACM SIGIR conference on Research and 
development in information retrieval. 
Church, K. W., and Hanks, P. 1990. Word association 
norms, mutual information and lexicography. Com-
putational Linguistics 16(1): 22?29. 
Curran, James R. and Marc Moens. 2002. Improve-
ments in automatic thesaurus extraction. In Proceed-
ings of the ACL-SIGLEX Workshop on Unsupervised 
Lexical Acquisition, pages 59?67, Philadelphia, PA. 
Dunning, T.E. 1993. Accurate methods for the statistics 
of surprise and coincidence. Computational Linguis-
tics 19, 61?74 (1993). 
Fraenkel, Aviezri S. 1976. All about the Responsa re-
trieval project ? what you always wanted to know but 
were afraid to ask. Jurimetrics Journal, 16(3):149?
156, Spring. 
Gasperin, C., Gamallo, P., Agustini, A., Lopes, G., and 
de Lima, V. 2001. Using syntactic contexts for meas-
uring word similarity. In the Workshop on Semantic 
Knowledge Acquisition and Categorisation (ESSLI 
2001), Helsinki, Finland. 
Goldberg Yoav, Meni Adler and Michael Elhadad, 
2008. EM Can Find Pretty Good HMM POS-Taggers 
(When Given a Good Start), in Proceedings of ACL. 
Grefenstette, G. 1994. Explorations in Automatic The-
saurus Construction. Kluwer Academic Publishers, 
Boston, USA 
Harris, Zelig S. 1968. Mathematical Structures of Lan-
guage. John Wiley, New York. 
Hindle, D. 1990. Noun classification from predicate 
argument structures. In Proceedings of ACL. 
Itai Alon and Shuly Wintner. 2008. Language Re-
sources for Hebrew. Language Resources and Evalu-
ation 42(1):75-98, March 2008. 
Jain, A. K., M. N. Murty, P. J. Flynn. 1999. Data Clus-
tering: A Review. ACM Computing Surveys 
31(3):264-323. 
Kerner Yaakov HaCohen, Ariel Kass, Ariel Peretz. 
2008. Combined One Sense Disambiguation of Ab-
breviations. In Proceedings of ACL (Short Papers), 
pp. 61-64. 
Kilgarriff, Adam. 2003. Thesauruses for natural lan-
guage processing. In Proceedings of the Joint Con-
ference on Natural Language Processing and 
Knowledge Engineering, pages 5?13, Beijing, China. 
Kotlerman Lili, Dagan Ido, Szpektor Idan, and 
Zhitomirsky-Geffet Maayan. 2010. Directional Dis-
tributional Similarity for Lexical Inference. Natural 
Language Engineering, 16(4):359?389.  
Linden Krister, and Jussi Olavi Piitulainen. 2004.  Dis-
covering Synonyms and Other Related Words. In 
Proceedings of COLING 2004 : CompuTerm 2004: 
3rd International Workshop on Computational Ter-
minology, Pages 63-70, Geneva, Switzerland 
Lin, D. 1998. Automatic retrieval and clustering of 
similar words. In Proceedings of COLING-ACL. 
Peirsman Yves, Kris Heylen, and Dirk Speelman. 2008. 
Putting things in order. first and second order con-
texts models for the calculation of semantic similari-
ty. In Actes des 9i`emes Journ?ees internationales 
d?Analyse statistique des Donn?ees Textuelles (JADT 
2008), pages 907?916. 
Rapp, R. 2009. The Automatic Generation of Thesauri 
of Related Words for English, French, German, and 
Russian, International Journal of Speech Technolo-
gy, 11, 3-4, 147-156. 
Rychly, P. and Kilgarriff, A. 2007. An efficient algo-
rithm for building a distributional thesaurus (and oth-
er Sketch Engine developments). In Proceedings of 
ACL-07, demo session. Prague, Czech Republic. 
Schutze Hinrich and Jan 0. Pederson. 1997. A 
cooccurrence-based thesaurus and two applications 
to information retrieval. Information Processing 
and Management, 33(3):307-318. 
Smadja, F., McKeown, K.R., Hatzivassiloglou, V. 1996. 
Translating collocations for bilingual lexicons: A sta-
tistical approach. Computational Linguistics 22, 1?38 
63
Voorhees E.M. and D. Harman. 1999. Overview of the 
seventh text retrieval conference . In Proceedings of 
the Seventh Text Retrieval 73 Conference, 1999. 
NIST Special Publication. 58. 
Weeds, J., and Weir, D. 2003. A general  framework for 
distributional similarity. In Proceedings of EMNLP, 
Sapporo, Japan. 
Wilcoxon F. 1945. Individual comparisons by ranking 
methods. Biometrics Bulletin, 1:80?83. 
Yona Shlomo and Shuly Wintner. 2008. A Finite-State 
Morphological Grammar of Hebrew.  Natural Lan-
guage Engineering 14(2):173-190, April 2008. Lan-
guage Resources and Evaluation 42(1):75-98, March 
2008. 
 
64
Proceedings of the 7th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities, pages 29?35,
Sofia, Bulgaria, August 8 2013. c?2013 Association for Computational Linguistics
Semi-automatic Construction of Cross-period Thesaurus
Chaya Liebeskind, Ido Dagan, Jonathan Schler
Computer Science Department
Bar-Ilan University
Ramat-Gan, Israel
liebchaya@gmail.com, dagan@cs.biu.ac.il, schler@gmail.com
Abstract
Cross-period (diachronic) thesaurus con-
struction aims to enable potential users to
search for modern terms and obtain se-
mantically related terms from earlier pe-
riods in history. This is a complex task not
previously addressed computationally. In
this paper we introduce a semi-automatic
iterative Query Expansion (QE) scheme
for supporting cross-period thesaurus con-
struction. We demonstrate the empirical
benefit of our scheme for a Jewish cross-
period thesaurus and evaluate its impact on
recall and on the effectiveness of lexicog-
rapher manual effort.
1 Introduction and Background
In the last decade, there is a growing interest in ap-
plying Natural Language Processing (NLP) meth-
ods to historical texts due to the increased avail-
ability of these texts in digital form (Sporleder,
2010; Sa?nchez-Marco et al, 2011; Piotrowski,
2012). The specific linguistic properties of histor-
ical texts, such as nonstandard orthography, gram-
mar and abbreviations, pose special challenges for
NLP. One of this challenges, which has not been
addressed so far, is the problem of bridging the
lexical gap between modern and ancient language.
In this paper, we address the interesting task
of cross-period thesaurus (a.k.a. diachronic the-
saurus) construction. A thesaurus usually contains
thousands of entries, denoted here as target terms.
Each entry includes a list of related terms, cover-
ing various semantic relations. A cross-period the-
saurus aims to enable the potential user to search
for a modern term and get related terms from ear-
lier periods. Thus, in a cross-period thesaurus
the target terms are modern while their related
terms are ancient. In many cases, while the actual
modern term (or its synynom) does not appear in
earlier historical periods, different aspects of that
term were mentioned. For example, in our Jewish
historical corpora, the modern term birth control,
has no equivalent ancient term, However, different
contraceptive methods were described in our his-
torical texts that are semantically similar to birth
control. Thus, a related term is considered sim-
ilar to the target term when it refers to the same
concept.
The goal of our research is to support con-
structing a high-quality publishable thesaurus, as
a cultural resource on its own, alongside being
a useful tool for supporting searches in the do-
main. Since the precision of fully automatically-
constructed thesauri is typically low (e.g. (Mi-
halcea et al, 2006)), we present a semi-automatic
setting for supporting thesaurus construction by a
domain expert lexicographer. Our recall-oriented
setting assumes that manual effort is worthwhile
for increasing recall as long as it is being utilized
effectively.
Corpus-based thesaurus construction is an ac-
tive research area (Curran and Moens, 2002; Kil-
garriff, 2003; Rychly? and Kilgarriff, 2007; Liebe-
skind et al, 2012; Zohar et al, 2013). Typi-
cally, two statistical approaches for identifying se-
mantic relatedness between words were investi-
gated: first-order (co-occurrence-based) similarity
and second-order (distributional) similarity (Lin,
1998; Gasperin et al, 2001; Weeds and Weir,
2003; Kotlerman et al, 2010). In this research,
we focus on statistical measures of first-order sim-
ilarity (see Section 2). These methods were found
to be effective for thesaurus construction as stand-
alone methods and as complementary to second-
order methods (Peirsman et al, 2008). First-order
measures assume that words that frequently occur
together are topically related (Schu?tze and Peder-
sen, 1997). Thus, co-occurrence provides an ap-
propriate approach to identify highly related terms
for the thesaurus entries.
29
In general, there are two types of historically-
relevant corpora: ancient corpora of ancient lan-
guage, and modern corpora with references and
mentions to ancient language (termed here mixed
corpora). Since in our setting the thesaurus? target
terms are modern terms, which do not appear in
ancient corpora, co-occurrence methods would be
directly applicable only over a mixed corpus. In
a preliminary experiment, we applied the Liebe-
skind et al (2012) algorithmic scheme, which ap-
plies first-order similarity and morphological as-
pects of corpus-based thesaurus construction, on
a mixed corpus of our historical domain. We ob-
served that the target terms had low frequency in
this corpus. Since statistical co-occurrence mea-
sures have poor performance over low statistics,
the experiment?s results were not satisfactory. We
therefore looked for ways to increase the number
of documents in the statistical extraction process,
and decided that applying query expansion (QE)
techniques might be a viable solution.
We recognized two potential types of sources
of lexical expansions for the target terms. The
first is lexical resources available over the inter-
net for extracting different types of semantic rela-
tions (Shnarch et al, 2009; Bollegala et al, 2011;
Hashimoto et al, 2011). The second is lists of
related terms extracted from a mixed corpus by
a first-order co-occurrence measure. These lists
contain both ancient and modern terms. Although
only ancient terms will be included in the final
thesaurus, modern terms can be utilized for QE
to increase thesaurus coverage. Furthermore, ex-
panding the target term with ancient related terms
enables the use of ancient-only corpora for co-
occurrence extraction.
Following these observations, we present an it-
erative interactive QE scheme for bootstrapping
thesaurus construction. This approach is used to
bridge the lexical gap between modern and ancient
terminology by means of statistical co-occurrence
approaches. We demonstrate the empirical advan-
tage of our scheme over a cross-period Jewish do-
main and evaluate its impact on recall and on the
effectiveness of the lexicographer manual effort.
The remainder of this paper is organized as fol-
lows: we start with a description of the statistical
thesaurus construction method that we utilize in
our scheme. Our main contribution of the itera-
tive scheme is described in Section 3, followed by
a case-study in Section 4 and evaluation and sum-
mary in Sections 5 and 6.
2 Automatic Thesaurus Construction
Automatic thesaurus construction focuses on the
process of extracting a ranked list of candidate
related terms (termed candidate terms) for each
given target term. We assume that the top ranked
candidates will be further examined (manually) by
a lexicographer, who will select the eventual re-
lated terms for the thesaurus entry.
Statistical measures of first-order similarity
(word co-occurrence), such as Dice coefficient
(Smadja et al, 1996) and Pointwise Mutual In-
formation (PMI) (Church and Hanks, 1990), were
commonly used to extract ranked lists of candi-
date related terms. These measures consider the
number of times in which each candidate term co-
occurs with the target term, in the same document,
relative to their total frequencies in the corpus.
In our setting, we construct a thesaurus for a
morphologically rich language (Hebrew). There-
fore, we followed the Liebeskind et al (2012) al-
gorithmic scheme designed for these cases, sum-
marized below. First, our target term is repre-
sented in its lemma form. For each target term we
retrieve all the corpus documents containing this
given target term. Then, we define a set of candi-
date terms, which are represented in their surface
form, that consists of all the terms in all these doc-
uments. Next, the Dice co-occurrence score be-
tween the target term and each of the candidates
is calculated, based on their document-level statis-
tics in the corpus. After sorting the terms based on
their scores, the highest rated candidate terms are
clustered into lemma-based clusters. Finally, we
rank the clusters by summing the co-occurrence
scores of their members and the highest rated clus-
ters constitute the candidate terms for the given
target term, to be presented to a domain expert.
3 Iterative Semi-automatic Scheme for
Cross-period Thesaurus Construction
As explained in Section 1, our research focuses
on a semi-automatic setting for supporting cross-
period thesaurus construction by a lexicographer.
In this work, we assume that a list of modern tar-
get terms is given as input. Then, we automatically
extract a ranked list of candidate related terms for
each target term using statistical measures, as de-
tailed in Section 2. Notice that at this first step re-
lated terms can be extracted only from the mixed
30
corpora, in which the given (modern) target term
may occur. Next, a lexicographer manually se-
lects, from the top ranked candidates, ancient re-
lated terms for the thesaurus entry as well as terms
for QE. The QE terms may be either ancient or
modern terms from the candidate list, or terms
from a lexical resource. Our iterative QE scheme
iterates over the QE terms. In each iteration, a QE
term replaces the target term?s role in the statistics
extraction process. Candidate related terms are
extracted for the QE term and the lexicographer
judges their relevancy with respect to the original
target term. Notice that if the QE term is modern,
only the mixed corpora can be utilized. However,
if the QE term is ancient, the ancient corpora are
also utilized and may contribute additional related
terms.
The algorithmic scheme we developed for the-
saurus construction is illustrated in Figure 1. Our
input is a modern target term. First, we au-
tomatically extract candidates by statistical co-
occurrence measures, as described in Section 2.
Then, a domain-expert annotates the candidates.
The manual selection process includes two de-
cisions on each candidate (either modern or an-
cient): (i) whether the candidate is related to the
target term and should be included in its thesaurus
entry, and (ii) whether this candidate can be used
as a QE term for the original target term. The
second decision provides input to the QE process,
which triggers the subsequent iterations. Follow-
ing the first decision we filter the modern terms
and include only ancient ones in the actual the-
saurus.
The classification of a candidate term as ancient
or modern is done automatically by a simple clas-
sification rule: If a term appears in an ancient cor-
pus, then it is necessarily an ancient term; other-
wise, it is a modern term (notice that the converse
is not true, since an ancient term might appear in
modern documents).
In parallel to extracting candidate related terms
from the corpus, we extract candidate terms also
from our lexical resources, and the domain expert
judges their fitness as well. Our iterative process
is applied over the expansions list. In each itera-
tion, we take out an expansion term and automat-
ically extract related candidates for it. Then, the
annotator selects both ancient related terms for the
thesaurus and suitable terms, either modern or an-
cient, for the expansion list for further iterations.
Figure 1: Semi-automatic Algorithmic Scheme
For efficiency, only new candidates that were not
judged in pervious iterations are given for judge-
ment. The stopping criterion is when there are no
additional expansions in the expansions list.
Since the scheme is recall-oriented, the aim of
the annotation process is to maximize the the-
saurus coverage. In each iteration, the domain
expert annotates the extracted ranked list of can-
didate terms until k sequential candidates were
judged as irrelevant. This stopping criterion for
each iteration controls the efforts to increase recall
while maintaining a low, but reasonable precision.
In our setting, we extract ancient related terms
for modern terms. Therefore, in order to utilize
co-occurrence statistics extraction, our scheme re-
quires both ancient and mixed corpora, where
the first iteration utilizes only the mixed corpora.
Then, our iterative scheme enables subsequent it-
erations to utilize the ancient corpora as well.
4 Case Study: Cross-period Jewish
Thesaurus
Our research targets the construction of a cross-
period thesaurus for the Responsa project1. The
corpus includes questions on various daily issues
posed to rabbis and their detailed rabbinic an-
swers, collected over fourteen centuries, and was
used for previous IR and NLP research (Choueka
et al, 1971; Choueka et al, 1987; HaCohen-
Kerner et al, 2008; Liebeskind et al, 2012; Zohar
et al, 2013).
The Responsa corpus? documents are divided to
four periods: the 11th century until the end of the
15th century, the 16th century, the 17th through
the 19th centuries, and the 20th century until to-
1Corpus kindly provided: http://biu.ac.il/jh/Responsa/
31
day. We considered the first three periods as our
ancient corpora along with the RaMBaM (Hebrew
acronym for Rabbi Mosheh Ben Maimon) writ-
ings from the 12th century. For the mixed corpus
we used the corpus? documents from the last pe-
riod, but due to relatively low volume of modern
documents we enriched it with additional modern
collections (Tchumin collection 2, ASSIA (a Jour-
nal of Jewish Ethics and Halacha), the Medical-
Halachic Encyclopedia3, a collection of questions
and answers written by Rabbi Shaul Israeli4, and
the Talmudic Encyclopedia (a Hebrew language
encyclopedia that summarizes halachic topics of
the Talmud in alphabetical order). Hebrew Wik-
tionary was used as a lexical resource for syn-
onyms.
For statistics extraction, we applied (Liebeskind
et al, 2012) algorithmic scheme using Dice coef-
ficient as our co-occurrence measure (see Section
2). Statistics were calculated over bigrams from
corpora consisting of 81993 documents.
5 Evaluation
5.1 Evaluation Setting
We assessed our iterative algorithmic scheme by
evaluating its ability to increase the thesaurus cov-
erage, compared to a similar non-iterative co-
occurrence-based thesaurus construction method.
In our experiments, we assumed that it is worth
spending the lexicographer?s time as long as it is
productive, thus, all the manual annotations were
based on the lexicographer efforts to increase re-
call until reaching the stopping criterion.
We used Liebeskind et al (2012) algorithmic
scheme as our non-iterative baseline (Baseline).
For comparison, we ran our iterative scheme, cal-
culated the average number of judgments per tar-
get term (88) and set the baseline stopping crite-
rion to be the same number of judgements per tar-
get. Thus, we ensured that the number of judge-
ments for our iterative algorithm and for the base-
line is equal, and thus coverage increase is due to a
better use of lexicographer?s effort. For complete-
ness, we present the results of the non-iterative al-
gorithm with the stopping criterion of the iterative
algorithm, when reaching k (k=10 was empirically
2http://www.zomet.org.il/?CategoryID=170
3http://medethics.org.il/website/index.php/en/research-
2/encyclopedia-of-jewish-medical-ethics
4http://www.eretzhemdah.org/data/uploadedfiles/ebooks/14-
sfile.pdf
Method RT R Pro J
First-iteration 50 0.31 0.038 1307
Baseline 63 0.39 0.024 2640
Iterative 151 0.94 0.057 2640
Table 1: Results Comparison
selected in our case) sequential irrelevant candi-
dates (First-iteration).
To evaluate our scheme?s performance, we used
several measures: total number of ancient related
terms extracted (RT), relative recall (R) and pro-
ductivity (Pro). Since we do not have any pre-
defined thesaurus, our micro-averaged relative-
recall considered the number of ancient related
terms from the output of both methods (baseline
and iterative) as the full set of related terms. Pro-
ductivity was measured by dividing the total num-
ber of ancient related terms extracted (RT) by the
total number of the judgments performed for the
method (J).
5.2 Results
Table 1 compares the performance of our semi-
automatic iterative scheme with that of the base-
line over a test set of 30 modern target terms. Our
iterative scheme increases the average number of
extracted related terms from 2.1 to 5, i.e., increas-
ing recall by 240%. The relative recall of the first-
iteration (0.31) is included in the relative recall of
both the baseline and our iterative method. Iterat-
ing over the first iteration increases recall by 300%
(from 50 to 151 terms), while adding more judge-
ments to the non-iterative method increases recall
only by 26% (to 63 terms). The productivity of the
iterative process is higher even than the productiv-
ity of the first iteration, showing that the iterative
process optimizes the lexicographer?s manual ef-
fort.
Table 2 shows examples of thesaurus target
terms and their ancient related terms, which were
added by our iterative scheme5. Since the related
terms are ancient Halachic terms, we explain them
rather than translate them to English.
We further analyze our scheme by comparing
the use of ancient versus modern terms in the itera-
tive process. Although modern related terms were
not included in our cross-period thesaurus, in the
judgement process the lexicographer judged their
5To facilitate readability we use a transliteration of He-
brew using Roman characters; the letters used, in Hebrew
lexico-graphic order, are abgdhwzxTiklmns`pcqrs?t.
32
Figure 2: The extraction of ancient terms versus modern terms in the iterative process
Target term Related term
zkwiwt iwcrim (copyright) hsgt gbwl (trespassing)
iwrd lamnwt xbrw ([competitively] enter his friend?s profession)
`ni hmhpk bxrrh (a poor man is deciding whether to buy a cake and another
person comes and takes it)
hmtt xsd (euthanasia) rwb gwssin lmith (most dying people die)
xii s?`h (living for the moment)
hpsqt hriwn (abortion) xwtkin h`wbr (killing the fetus)
hwrg nps? (killing a person)
rwdp (pursuer, a fetus endangering its mother?s life)
tiknwn hms?pxh (birth control) s?lws? ns?im ms?ms?wt bmwk (three types of women allowed to use cotton di-
aphragm)
ds? mbpnim wzwrh mbxwc (withdrawal method)
hprt xwzh (breach of contract) biTwl mqx (cancelling a purchase)
dina dgrmi (indirect damage)
mqx t`wt (erroneous bargain)
srwb pqwdh (insubordination) mwrd bmlkwt (rebel against the sovereign [government])
imrh at pik (to disobey)
Avner and khni Nob (a biblical story: king Saul ordered to slay Ahimilech to-
gether with 85 priests. Avner, the captain of Saul?s guard, disobeyed the order.)
Table 2: Examples for the iterative scheme?s contribution
relevancy too. In Figure 2, we report the number
of modern related terms in comparison to the num-
ber of ancient related terms for each iteration. In
parallel, we illustrate the number of ancient expan-
sions in proportion to the number of modern ex-
pansions. The x-axis? values denote the iterations,
while the y-axis? values denote the number of ex-
pansions and related terms respectively. For each
iteration, the expansions chart presents the expan-
sions that were extracted while the related terms
chart presents the extracted related terms, of which
the ancient ones were included in the thesaurus.
Since the input for our scheme is a modern target
terms, the first iteration extracted more modern re-
lated terms than ancient terms and utilized more
modern expansions than ancient. However, this
proportion changed in the second iteration, prob-
ably thanks to the ancient expansions retrieved in
the first iteration.
Although there are often mixed results on
the effectiveness of QE for information retrieval
(Voorhees, 1994; Xu and Croft, 1996), our results
show that QE for thesaurus construction in an iter-
ative interactive setting is beneficial for increasing
thesaurus? coverage substantially.
6 Conclusions and Future Work
We introduced an iterative interactive scheme for
cross-period thesaurus construction, utilizing QE
techniques. Our semi-automatic algorithm signif-
icantly increased thesaurus coverage, while op-
timizing the lexicographer manual effort. The
scheme was investigated for Hebrew, but can be
generically applied for other languages.
We plan to further explore the suggested scheme
by utilizing additional lexical resources and QE
algorithms. We also plan to adopt second-order
distributional similarity methods for cross-period
thesaurus construction.
33
References
D. Bollegala, Y. Matsuo, and M. Ishizuka. 2011.
A web search engine-based approach to mea-
sure semantic similarity between words. Knowl-
edge and Data Engineering, IEEE Transactions on,
23(7):977?990.
Yaacov Choueka, M. Cohen, J. Dueck, Aviezri S.
Fraenkel, and M. Slae. 1971. Full text document
retrieval: Hebrew legal texts. In SIGIR, pages 61?
79.
Yaacov Choueka, Aviezri S. Fraenkel, Shmuel T. Klein,
and E. Segal. 1987. Improved techniques for pro-
cessing queries in full-text systems. In SIGIR, pages
306?315.
Kenneth Ward Church and Patrick Hanks. 1990. Word
association norms, mutual information, and lexicog-
raphy. Comput. Linguist., 16(1):22?29, March.
James R. Curran and Marc Moens. 2002. Improve-
ments in automatic thesaurus extraction. In Pro-
ceedings of the ACL-02 workshop on Unsupervised
lexical acquisition - Volume 9, ULA ?02, pages 59?
66, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.
Caroline Gasperin, Pablo Gamallo, Alexandre Agus-
tini, Gabriel Lopes, Vera De Lima, et al 2001. Us-
ing syntactic contexts for measuring word similarity.
In Workshop on Knowledge Acquisition and Catego-
rization, ESSLLI, Helsinki, Finland.
Yaakov HaCohen-Kerner, Ariel Kass, and Ariel Peretz.
2008. Combined one sense disambiguation of ab-
breviations. Proceedings of ACL08: HLT, Short Pa-
pers, pages 61?64.
Chikara Hashimoto, Kentaro Torisawa, Stijn
De Saeger, Junichi Kazama, and Sadao Kuro-
hashi. 2011. Extracting paraphrases from definition
sentences on the web. In Proceedings of the 49th
Annual Meeting of the Association for Computa-
tional Linguistics (ACL), pages 1087?1097.
Adam Kilgarriff. 2003. Thesauruses for natu-
ral language processing. In Proceedings of the
Joint Conference on Natural Language Processing
and Knowledge Engineering, pages 5?13, Beijing,
China.
Lili Kotlerman, Ido Dagan, Idan Szpektor, and Maayan
Zhitomirsky-geffet. 2010. Directional distributional
similarity for lexical inference. Nat. Lang. Eng.,
16(4):359?389, October.
Chaya Liebeskind, Ido Dagan, and Jonathan Schler.
2012. Statistical thesaurus construction for a mor-
phologically rich language. In *SEM 2012: The
First Joint Conference on Lexical and Computa-
tional Semantics, pages 59?64, Montre?al, Canada,
7-8 June. Association for Computational Linguis-
tics.
Dekang Lin. 1998. Automatic retrieval and clustering
of similar words. In Proceedings of the 36th Annual
Meeting of the Association for Computational Lin-
guistics and 17th International Conference on Com-
putational Linguistics - Volume 2, ACL ?98, pages
768?774, Stroudsburg, PA, USA. Association for
Computational Linguistics.
Rada Mihalcea, Courtney Corley, and Carlo Strappa-
rava. 2006. Corpus-based and knowledge-based
measures of text semantic similarity. In Proceedings
of the 21st national conference on Artificial intelli-
gence - Volume 1, AAAI?06, pages 775?780. AAAI
Press.
Yves Peirsman, Kris Heylen, and Dirk Speelman.
2008. Putting things in order. First and second order
context models for the calculation of semantic sim-
ilarity. In 9es Journe?es internationales d?Analyse
statistique des Donne?es Textuelles (JADT 2008).
Lyon, France.
Michael Piotrowski. 2012. Natural language process-
ing for historical texts. Synthesis Lectures on Hu-
man Language Technologies, 5(2):1?157.
Pavel Rychly? and Adam Kilgarriff. 2007. An ef-
ficient algorithm for building a distributional the-
saurus (and other sketch engine developments). In
Proceedings of the 45th Annual Meeting of the ACL
on Interactive Poster and Demonstration Sessions,
ACL ?07, pages 41?44, Stroudsburg, PA, USA. As-
sociation for Computational Linguistics.
Cristina Sa?nchez-Marco, Gemma Boleda, and Llu??s
Padro?. 2011. Extending the tool, or how to anno-
tate historical language varieties. In Proceedings of
the 5th ACL-HLT Workshop on Language Technol-
ogy for Cultural Heritage, Social Sciences, and Hu-
manities, LaTeCH ?11, pages 1?9, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Hinrich Schu?tze and Jan O. Pedersen. 1997. A
cooccurrence-based thesaurus and two applications
to information retrieval. Inf. Process. Manage.,
33(3):307?318, May.
Eyal Shnarch, Libby Barak, and Ido Dagan. 2009. Ex-
tracting lexical reference rules from wikipedia. In
Proceedings of the Joint Conference of the 47th An-
nual Meeting of the ACL and the 4th International
Joint Conference on Natural Language Processing
of the AFNLP: Volume 1 - Volume 1, ACL ?09, pages
450?458, Stroudsburg, PA, USA. Association for
Computational Linguistics.
Frank Smadja, Kathleen R. McKeown, and Vasileios
Hatzivassiloglou. 1996. Translating collocations for
bilingual lexicons: a statistical approach. Comput.
Linguist., 22(1):1?38, March.
Caroline Sporleder. 2010. Natural language process-
ing for cultural heritage domains. Language and
Linguistics Compass, 4(9):750?768.
34
Ellen M. Voorhees. 1994. Query expansion using
lexical-semantic relations. In Proceedings of the
17th annual international ACM SIGIR conference
on Research and development in information re-
trieval, SIGIR ?94, pages 61?69, New York, NY,
USA. Springer-Verlag New York, Inc.
Julie Weeds and David Weir. 2003. A general frame-
work for distributional similarity. In Proceedings of
the 2003 conference on Empirical methods in nat-
ural language processing, EMNLP ?03, pages 81?
88, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.
Jinxi Xu and W. Bruce Croft. 1996. Query expan-
sion using local and global document analysis. In
Proceedings of the 19th annual international ACM
SIGIR conference on Research and development in
information retrieval, SIGIR ?96, pages 4?11, New
York, NY, USA. ACM.
Hadas Zohar, Chaya Liebeskind, Jonathan Schler, and
Ido Dagan. 2013. Automatic thesaurus construction
for cross generation corpus. Journal on Comput-
ing and Cultural Heritage (JOCCH), 6(1):4:1?4:19,
April.
35
