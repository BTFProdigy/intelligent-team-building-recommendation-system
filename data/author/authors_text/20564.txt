Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 664?674,
Avignon, France, April 23 - 27 2012. c?2012 Association for Computational Linguistics
Modeling Inflection and Word-Formation in SMT
Alexander Fraser? Marion Weller? Aoife Cahill? Fabienne Cap?
?Institut fu?r Maschinelle Sprachverarbeitung ?Educational Testing Service
Universita?t Stuttgart Princeton, NJ 08541
D?70174 Stuttgart, Germany USA
{fraser,wellermn,cap}@ims.uni-stuttgart.de acahill@ets.org
Abstract
The current state-of-the-art in statistical
machine translation (SMT) suffers from is-
sues of sparsity and inadequate modeling
power when translating into morphologi-
cally rich languages. We model both in-
flection and word-formation for the task
of translating into German. We translate
from English words to an underspecified
German representation and then use linear-
chain CRFs to predict the fully specified
German representation. We show that im-
proved modeling of inflection and word-
formation leads to improved SMT.
1 Introduction
Phrase-based statistical machine translation
(SMT) suffers from problems of data sparsity
with respect to inflection and word-formation
which are particularly strong when translating to
a morphologically rich target language, such as
German. We address the problem of inflection
by first translating to a stem-based representation,
and then using a second process to inflect these
stems. We study several models for doing
this, including: strongly lexicalized models,
unlexicalized models using linguistic features,
and models combining the strengths of both of
these approaches. We address the problem of
word-formation for compounds in German, by
translating from English into German word parts,
and then determining whether to merge these
parts to form compounds.
We make the following new contributions: (i)
we introduce the first SMT system combining
inflection prediction with synthesis of portman-
teaus and compounds. (ii) For inflection, we com-
pare the mostly unlexicalized prediction of lin-
guistic features (with a subsequent surface form
generation step) versus the direct prediction of
surface forms, and show that both approaches
have complementary strengths. (iii) We com-
bine the advantages of the prediction of linguis-
tic features with the prediction of surface forms.
We implement this in a CRF framework which
improves on a standard phrase-based SMT base-
line. (iv) We develop separate (but related) pro-
cedures for inflection prediction and dealing with
word-formation (compounds and portmanteaus),
in contrast with most previous work which usu-
ally either approaches both problems as inflec-
tional problems, or approaches both problems as
word-formation problems.
We evaluate on the end-to-end SMT task of
translating from English to German of the 2009
ACL workshop on SMT. We achieve BLEU score
increases on both the test set and the blind test set.
2 Overview of the translation process for
inflection prediction
The work we describe is focused on generaliz-
ing phrase-based statistical machine translation to
better model German NPs and PPs. We particu-
larly want to ensure that we can generate novel
German NPs, where what we mean by novel is
that the (inflected) realization is not present in the
parallel German training data used to build the
SMT system, and hence cannot be produced by
our baseline (a standard phrase-based SMT sys-
tem). We first present our system for dealing with
the difficult problem of inflection in German, in-
cluding the inflection-dependent phenomenon of
portmanteaus. Later, after performing an exten-
sive analysis of this system, we will extend it
664
to model compounds, a highly productive phe-
nomenon in German (see Section 8).
The key linguistic knowledge sources that we
use are morphological analysis and generation of
German based on SMOR, a morphological ana-
lyzer/generator of German (Schmid et al 2004)
and the BitPar parser, which is a state-of-the-art
parser of German (Schmid, 2004).
2.1 Issues of inflection prediction
In order to ensure coherent German NPs, we
model linguistic features of each word in an NP.
We model case, gender, and number agreement
and whether or not the word is in the scope of
a determiner (such as a definite article), which
we label in-weak-context (this linguistic feature
is necessary to determine the type of inflection of
adjectives and other words: strong, weak, mixed).
This is a diverse group of features. The number
of a German noun can often be determined given
only the English source word. The gender of a
German noun is innate and often difficult to deter-
mine given only the English source word. Case
is a function of the slot in the subcategorization
frame of the verb (or preposition). There is agree-
ment in all of these features in an NP. For instance
the number of an article or adjective is determined
by the head noun, while the type of inflection of an
adjective is determined by the choice of article.
We can have a large number of surface forms.
For instance, English blue can be translated as
German blau, blaue, blauer, blaues, blauen. We
predict which form is correct given the context.
Our system can generate forms not seen in the
training data. We follow a two-step process: in
step-1 we translate to blau (the stem), in step-2 we
predict features and generate the inflected form.1
2.2 Procedure
We begin building an SMT system by parsing the
German training data with BitPar. We then extract
morphological features from the parse. Next, we
lookup the surface forms in the SMOR morpholog-
ical analyzer. We use the morphological features
in the parse to disambiguate the set of possible
SMOR analyses. Finally, we output the ?stems?
of the German text, with the addition of markup
taken from the parse (discussed in Section 2.3).
1E.g., case=nominative, gender=masculine, num-
ber=singular, in-weak-context=true; inflected: blaue.
We then build a standard Moses system trans-
lating from English to German stems. We obtain
a sequence of stems and POS2 from this system,
and then predict the correct inflection using a se-
quence model. Finally we generate surface forms.
2.3 German Stem Markup
The translation process consists of two major
steps. The first step is translation of English
words to German stems, which are enriched with
some inflectional markup. The second step is
the full inflection of these stems (plus markup)
to obtain the final sequence of inflected words.
The purpose of the additional German inflectional
markup is to strongly improve prediction of in-
flection in the second step through the addition of
markup to the stems in the first step.
In general, all features to be predicted are
stripped from the stemmed representation because
they are subject to agreement restrictions of a
noun or prepositional phrase (such as case of
nouns or all features of adjectives). However, we
need to keep all morphological features that are
not dependent on, and thus not predictable from,
the (German) context. They will serve as known
input for the inflection prediction model. We now
describe this markup in detail.
Nouns are marked with gender and number: we
consider the gender of a noun as part of its stem,
whereas number is a feature which we can obtain
from English nouns.
Personal pronouns have number and gender an-
notation, and are additionally marked with nom-
inative and not-nominative, because English pro-
nouns are marked for this (except for you).
Prepositions are marked with the case their ob-
ject takes: this moves some of the difficulty in pre-
dicting case from the inflection prediction step to
the stem translation step. Since the choice of case
in a PP is often determined by the PP?s meaning
(and there are often different meanings possible
given different case choices), it seems reasonable
to make this decision during stem translation.
Verbs are represented using their inflected surface
form. Having access to inflected verb forms has a
positive influence on case prediction in the second
2We use an additional target factor to obtain the coarse
POS for each stem, applying a 7-gram POS model. Koehn
and Hoang (2007) showed that the use of a POS factor only
results in negligible BLEU improvements, but we need ac-
cess to the POS in our inflection prediction models.
665
input decoder output inflected merged
in
in<APPR><Dat> in
im
die<+ART><Def> dem
contrast Gegensatz<+NN><Masc><Sg>Gegensatz Gegensatz
to zu<APPR><Dat> zu
zur
the die<+ART><Def> der
animated lebhaft<+ADJ><Pos> lebhaften lebhaften
debate Debatte<+NN><Fem><Sg> Debatte Debatte
Table 1: Re-merging of prepositions and articles after
inflection to form portmanteaus, in dem means in the.
step through subject-verb agreement.
Articles are reduced to their stems (the stem itself
makes clear the definite or indefinite distinction,
but lemmatizing involves removing markings of
case, gender and number features).
Other words are also represented by their stems
(except for words not covered by SMOR, where
surface forms are used instead).
3 Portmanteaus
Portmanteaus are a word-formation phenomenon
dependent on inflection. As we have discussed,
standard phrase-based systems have problems
with picking a definite article with the correct
case, gender and number (typically due to spar-
sity in the language model, e.g., a noun which
was never before seen in dative case will often
not receive the correct article). In German, port-
manteaus increase this sparsity further, as they
are compounds of prepositions and articles which
must agree with a noun.
We adopt the linguistically strict definition of
the term portmanteau: the merging of two func-
tion words.3 We treat this phenomena by split-
ting the component parts during training and re-
merging during generation. Specifically for
German, this requires splitting the words which
have German POS tag APPRART into an APPR
(preposition) and an ART (article). Merging is re-
stricted, the article must be definite, singular4 and
the preposition can only take accusative or dative
case. Some prepositions allow for merging with
an article only for certain noun genders, for exam-
ple the preposition inDative is only merged with
the following article if the following noun is of
masculine or neuter gender. The definite article
3Some examples are: zum (to the) = zu (to) + dem (the)
[German], du (from the) = de (from) + le (the) [French] or al
(to the) = a (to) + el (the) [Spanish].
4This is the reason for which the preposition + article in
Table 2 remain unmerged.
must be inflected before making a decision about
whether to merge a preposition and the article into
a portmanteau. See Table 1 for examples.
4 Models for Inflection Prediction
We present 5 procedures for inflectional predic-
tion using supervised sequence models. The first
two procedures use simple N-gram models over
fully inflected surface forms.
1. Surface with no features is presented with an
underspecified input (a sequence of stems), and
returns the most likely inflected sequence.
2. Surface with case, number, gender is a hybrid
system giving the surface model access to linguis-
tic features. In this system prepositions have addi-
tionally been labeled with the case they mark (in
both the underspecified input and the fully spec-
ified output the sequence model is built on) and
gender and number markup is also available.
The rest of the procedures predict morpholog-
ical features (which are input to a morphological
generator) rather than surface words. We have de-
veloped a two-stage process for predicting fully
inflected surface forms. The first stage takes a
stem and predicts morphological features for that
stem, based on the surrounding context. The aim
of the first stage is to take a stem and predict
four morphological features: case, gender, num-
ber and type of inflection. We experiment with
a number of models for doing this. The sec-
ond stage takes the stems marked with morpho-
logical features (predicted in the first stage) and
uses a morphological generator to generate the
full surface form. For the second stage, a modified
version of SMOR (Schmid et al 2004) is used,
which, given a stem annotated with morphologi-
cal features, generates exactly one surface form.
We now introduce our first linguistic feature
prediction systems, which we call joint sequence
models (JSMs). These are standard language
models, where the ?word? tokens are not repre-
sented as surface forms, but instead using POS
and features. In testing, we supply the input as a
sequence in underspecified form, where some of
the features are specified in the stem markup (for
instance, POS=Noun, gender=masculine, num-
ber=plural), and then use Viterbi search to find the
most probable fully specified form (for instance,
POS=Noun, gender=masculine, number=plural,
666
output decoder input prediction output prediction inflected forms gloss
haben<VAFIN> haben-V haben-V haben have
Zugang<+NN><Masc><Sg> NN-Sg-Masc NN-Masc.Acc.Sg.in-weak-context=false Zugang access
zu<APPR><Dat> APPR-zu-Dat APPR-zu-Dat zu to
die<+ART><Def> ART-in-weak-context=true ART-Neut.Dat.Pl.in-weak-context=true den the
betreffend<+ADJ><Pos> ADJA ADJA-Neut.Dat.Pl.in-weak-context=true betreffenden respective
Land<+NN><Neut><Pl> NN-Pl-Neut NN-Neut.Dat.Pl.in-weak-context=true La?ndern countries
Table 2: Overview: inflection prediction steps using a single joint sequence model. All words except verbs and
prepositions are replaced by their POS tags in the input. Verbs are inflected in the input (?haben?, meaning
?have? as in ?they have?, in the example). Prepositions are lexicalized (?zu? in the example) and indicate which
case value they mark (?Dat?, i.e., Dative in the example).
case=nominative, in-weak-context=true).5
3. Single joint sequence model on features. We
illustrate the different stages of the inflection pre-
diction when using a joint sequence model. The
stemmed input sequence (cf. Section 2.3) contains
several features that will be part of the input to
the inflection prediction. With the exception of
verbs and prepositions, the representation for fea-
ture prediction is based on POS-tags.
As gender and number are given by the heads
of noun phrases and prepositional phrases, and
the expected type of inflection is set by articles,
the model has sufficient information to compute
values for these features and there is no need to
know the actual words. In contrast, the prediction
of case is more difficult as it largely depends on
the content of the sentence (e.g. which phrase is
object, which phrase is subject). Assuming that
verbs and prepositions indicate subcategorization
frames, the model is provided crucial information
for the prediction of case by keeping verbs (recall
that verbs are produced by the stem translation
system in their inflected form) and prepositions
(the prepositions also have case markup) instead
of replacing them with their tags.
After having predicted a single label with val-
ues for all features, an inflected word form for the
stem and the features is generated. The prediction
steps are illustrated in Table 2.
4. Using four joint sequence models (one for
each linguistic feature). Here the four linguistic
feature values are predicted separately. The as-
sumption that the different linguistic features can
be predicted independently of one another is a rea-
5Joint sequence models are a particularly simple HMM.
Unlike the HMMs used for POS-tagging, an HMM as used
here only has a single emission possibility for each state,
with probability 1. The states in the HMM are the fully
specified representation. The emissions of the HMM are the
stems+markup (the underspecified representation).
sonable linguistic assumption to make given the
additional German markup that we use. By split-
ting the inflection prediction problem into 4 com-
ponent parts, we end up with 4 simpler models
which are less sensitive to data sparseness.
Each linguistic feature is modeled indepen-
dently (by a JSM) and has a different input rep-
resentation based on the previously described
markup. The input consists of a sequence of
coarse POS tags, and for those stems that are
marked up with the relevant feature, this feature
value. Finally, we combine the predicted fea-
tures together to produce the same final output as
the single joint sequence model, and then generate
each surface form using SMOR.
5. Using four CRFs (one for each linguistic fea-
ture). The sequence models already presented are
limited to the n-gram feature space, and those that
predict linguistic features are not strongly lexi-
calized. Toutanova et al(2008) uses an MEMM
which allows the integration of a wide variety of
feature functions. We also wanted to experiment
with additional feature functions, and so we train
4 separate linear chain CRF6 models on our data
(one for each linguistic feature we want to pre-
dict). We chose CRFs over MEMMs to avoid the
label bias problem (Lafferty et al 2001).
The CRF feature functions, for each German
word wi, are in Table 3. The common feature
functions are used in all models, while each of the
4 separate models (one for each linguistic feature)
includes the context of only that linguistic feature.
We use L1 regularization to eliminate irrelevant
feature functions, the regularization parameter is
optimized on held out data.
6We use the Wapiti Toolkit (Lavergne et al 2010) on 4
x 12-Core Opteron 6176 2.3 GHz with 256GB RAM to train
our CRF models. Training a single CRF model on our data
was not tractable, so we use one for each linguistic feature.
667
Common lemmawi?5...wi+5 , tagwi?7...wi+7
Case casewi?5...wi+5
Gender genderwi?5...wi+5
Number numberwi?5...wi+5
in-weak-context in-weak-contextwi?5...wi+5
Table 3: Feature functions used in CRF models (fea-
ture functions are binary indicators of the pattern).
5 Experimental Setup
To evaluate our end-to-end system, we perform
the well-studied task of news translation, us-
ing the Moses SMT package. We use the En-
glish/German data released for the 2009 ACL
Workshop on Machine Translation shared task on
translation.7 There are 82,740 parallel sentences
from news-commentary09.de-en and 1,418,115
parallel sentences from europarl-v4.de-en. The
monolingual data contains 9.8 M sentences.8
To build the baseline, the data was tokenized
using the Moses tokenizer and lowercased. We
use GIZA++ to generate alignments, by running
5 iterations of Model 1, 5 iterations of the HMM
Model, and 4 iterations of Model 4. We sym-
metrize using the ?grow-diag-final-and? heuris-
tic. Our Moses systems use default settings. The
LM uses the monolingual data and is trained as
a five-gram9 using the SRILM-Toolkit (Stolcke,
2002). We run MERT separately for each sys-
tem. The recaser used is the same for all systems.
It is the standard recaser supplied with Moses,
trained on all German training data. The dev set
is wmt-2009-a and the test set is wmt-2009-b, and
we report end-to-end case sensitive BLEU scores
against the unmodified reference SGML file. The
blind test set used is wmt-2009-blind (all lines).
In developing our inflection prediction sys-
tems (and making such decisions as n-gram order
used), we worked on the so-called ?clean data?
task, predicting the inflection on stemmed refer-
ence sentences (rather than MT output). We used
the 2000 sentence dev-2006 corpus for this task.
Our contrastive systems consist of two steps,
the first is a translation step using a similar
Moses system (except that the German side is
stemmed, with the markup indicated in Sec-
7http://www.statmt.org/wmt09/translation-task.html
8However, we reduced the monolingual data (only) by
retaining only one copy of each unique line, which resulted
in 7.55 M sentences.
9Add-1 smoothing for unigrams and Kneser-Ney
smoothing for higher order n-grams, pruning defaults.
tion 2.3), and the second is inflection prediction
as described previously in the paper. To derive
the stem+markup representation we first parse
the German training data and then produce the
stemmed representation. We then build a sys-
tem for translating from English words to Ger-
man stems (the stem+markup representation), on
the same data (so the German side of the parallel
data, and the German language modeling uses the
stem+markup representation). Likewise, MERT
is performed using references which are in the
stem+markup representation.
To train the inflection prediction systems, we
use the monolingual data. The basic surface form
model is trained on lowercased surface forms,
the hybrid surface form model with features is
trained on lowercased surface forms annotated
with markup. The linguistic feature prediction
systems are trained on the monolingual data pro-
cessed as described previously (see Table 2).
Our JSMs are trained using the SRILM Toolkit.
We use the SRILM disambig tool for predicting
inflection, which takes a ?map? that specifies the
set of fully specified representations that each un-
derspecified stem can map to. For surface form
models, it specifies the mapping from stems to
lowercased surface forms (or surface forms with
markup for the hybrid surface model).
6 Results for Inflection Prediction
We build two different kinds of translation sys-
tem, the baseline and the stem translation system
(where MERT is used to train the system to pro-
duce a stem+markup sequence which agrees with
the stemmed reference of the dev set). In this sec-
tion we present the end-to-end translation results
for the different inflection prediction models de-
fined in Section 4, see Table 4.
If we translate from English into a stemmed
German representation and then apply a unigram
stem-to-surface-form model to predict the surface
form, we achieve a BLEU score of 9.97 (line 2).
This is only presented for comparison.
The baseline10 is 14.16, line 1. We compare
this with a 5-gram sequence model11 that predicts
10This is a better case-sensitive score than the baselines
on wmt-2009-b in experiments by top-performers Edinburgh
and Karlsruhe at the shared task. We use Moses with default
settings.
11Note that we use a different set, the ?clean data? set, to
determine the choice of n-gram order, see Section 7. We use
668
surface forms without access to morphological
features, resulting in a BLEU score of 14.26. In-
troducing morphological features (case on prepo-
sitions, number and gender on nouns) increases
the BLEU score to 14.58, which is in the same
range as the single JSM system predicting all lin-
guistic features at once.
This result shows that the mostly unlexicalized
single JSM can produce competitive results with
direct surface form prediction, despite not having
access to a model of inflected forms, which is the
desired final output. This strongly suggests that
the prediction of morphological features can be
used to achieve additional generalization over di-
rect surface form prediction. When comparing the
simple direct surface form prediction (line 3) with
the hybrid system enriched with number, gender
and case (line 4), it becomes evident that feature
markup can also aid surface form prediction.
Since the single JSM has no access to lexical
information, we used a language model to score
different feature predictions: for each sentence of
the development set, the 100 best feature predic-
tions were inflected and scored with a language
model. We then optimized weights for the two
scores LM (language model on surface forms)
and FP (feature prediction, the score assigned by
the JSM). This method disprefers feature predic-
tions with a top FP-score if the inflected sen-
tence obtains a bad LM score and likewise dis-
favors low-ranked feature prediction with a high
LM score. The prediction of case is the most
difficult given no lexical information, thus scor-
ing different prediction possibilities on inflected
words is helpful. An example is when the case of
a noun phrase leads to an inflected phrase which
never occurs in the (inflected) language model
(e.g., case=genitive vs. case=other). Applying
this method to the single JSM leads to a negligible
improvement (14.53 vs. 14.56). Using the n-best
output of the stem translation system did not lead
to any improvement.
The comparison between different feature pre-
diction models is also illustrative. Performance
decreases somewhat when using individual joint
sequence models (one for each linguistic feature)
compared to one single model (14.29, line 6).
The framework using the individual CRFs for
a 5-gram for surface forms and a 4-gram for JSMs, and the
same smoothing (Kneser-Ney, add-1 for unigrams, default
pruning).
1 baseline 14.16
2 unigram surface (no features) 9.97
3 surface (no features) 14.26
4 surface (with case, number, gender features) 14.58
5 1 JSM morphological features 14.53
6 4 JSMs morphological features 14.29
7 4 CRFs morphological features, lexical information 14.72
Table 4: BLEU scores (detokenized, case sensitive) on
the development test set wmt-2009-b
each linguistic feature performs best (14.72, line
7). The CRF framework combines the advantages
of surface form prediction and linguistic feature
prediction by using feature functions that effec-
tively cover the feature function spaces used by
both forms of prediction. The performance of the
CRF models results in a statistically significant
improvement12 (p < 0.05) over the baseline. We
also tried CRFs with bilingual features (projected
from English parses via the alignment output by
Moses), but obtained only a small improvement of
0.03, probably because the required information
is transferred in our stem markup (also a poor im-
provement beyond monolingual features is con-
sistent with previous work, see Section 8.3). De-
tails are omitted due to space.
We further validated our results by translating
the blind test set from wmt-2009, which we have
never looked at in any way. Here we also had
a statistically significant difference between the
baseline and the CRF-based prediction, the scores
were 13.68 and 14.18.
7 Analysis of Inflection-based System
Stem Markup. The first step of translating
from English to German stems (with the markup
we previously discussed) is substantially easier
than translating directly to inflected German (we
see BLEU scores on stems+markup that are over
2.0 BLEU higher than the BLEU scores on in-
flected forms when running MERT). The addition
of case to prepositions only lowered the BLEU
score reached by MERT by about 0.2, but is very
helpful for prediction of the case feature.
Inflection Prediction Task. Clean data task re-
sults13 are given in Table 5. The 4 CRFs outper-
form the 4 JSMs by more than 2%.
12We used Kevin Gimpel?s implementation of pairwise
bootstrap resampling with 1000 samples.
1326,061 of 55,057 tokens in our test set are ambiguous.
We report % surface form matches for ambiguous tokens.
669
Model Accuracy
unigram surface (no features) 55.98
surface (no features) 86.65
surface (with case, number, gender features) 91.24
1 JSM morphological features 92.45
4 JSMs morphological features 92.01
4 CRFs morphological features, lexical information 94.29
Table 5: Comparing predicting surface forms directly
with predicting morphological features.
training data 1 model 4 models
7.3 M sentences 92.41 91.88
1.5 M sentences 92.45 92.01
100000 sentences 90.20 90.64
1000 sentences 83.72 86.94
Table 6: Accuracy for different training data sizes of
the single and the four separate joint sequence models.
As we mentioned in Section 4, there is a spar-
sity issue at small training data sizes for the sin-
gle joint sequence model. This is shown in Ta-
ble 6. At the largest training data sizes, model-
ing all 4 features together results in the best pre-
dictions of inflection. However using 4 separate
models is worth this minimal decrease in perfor-
mance, since it facilitates experimentation with
the CRF framework for which the training of a
single model is not currently tractable.
Overall, the inflection prediction works well for
gender, number and type of inflection, which are
local features to the NP that normally agree with
the explicit markup output by the stem transla-
tion system (for example, the gender of a com-
mon noun, which is marked in the stem markup,
is usually successfully propagated to the rest of
the NP). Prediction of case does not always work
well, and could maybe be improved through hier-
archical labeled-syntax stem translation.
Portmanteaus. An example of where the sys-
tem is improved because of the new handling of
portmanteaus can be seen in the dative phrase
im internationalen Rampenlicht (in the interna-
tional spotlight), which does not occur in the par-
allel data. The accusative phrase in das interna-
tionale Rampenlicht does occur, however in this
case there is no portmanteau, but a one-to-one
mapping between in the and in das. For a given
context, only one of accusative or dative case is
valid, and a strongly disfluent sentence results
from the incorrect choice. In our system, these
two cases are handled in the same way (def-article
international Rampenlicht). This allows us to
generalize from the accusative example with no
portmanteau and take advantage of longer phrase
pairs, even when translating to something that will
be inflected as dative and should be realized as a
portmanteau. The baseline does not have this ca-
pability. It should be noted that the portmanteau
merging method described in Section 3 remerges
all occurrences of APPR and ART that can techni-
cally form a portmanteau. There are a few cases
where merging, despite being grammatical, does
not lead to a good result. Such exceptions require
semantic interpretation and are difficult to capture
with a fixed set of rules.
8 Adding Compounds to the System
Compounds are highly productive in German and
lead to data sparsity. We split the German com-
pounds in the training data, so that our stem trans-
lation system can now work with the individual
words in the compounds. After we have trans-
lated to a split/stemmed representation, we deter-
mine whether to merge words together to form a
compound. Then we merge them to create stems
in the same representation as before and we per-
form inflection and portmanteau merging exactly
as previously discussed.
8.1 Details of Splitting Process
We prepare the training data by splitting com-
pounds in two steps, following the technique of
Fritzinger and Fraser (2010). First, possible split
points are extracted using SMOR, and second, the
best split points are selected using the geometric
mean of word part frequencies.
compound word parts gloss
Inflationsrate Inflation Rate inflation rate
auszubrechen aus zu brechen out to break (to break out)
Training data is then stemmed as described in
Section 2.3. The formerly modifying words of the
compound (in our example the words to the left
of the rightmost word) do not have a stem markup
assigned, except for two cases: i) they are nouns
themselves or ii) they are particles separated from
a verb. In these cases, former modifiers are rep-
resented identically to their individual occurring
counterparts, which helps generalization.
8.2 Model for Compound Merging
After translation, compound parts have to be
resynthesized into compounds before inflection.
Two decisions have to be taken: i) where to
670
merge and ii) how to merge. Following the work
of Stymne and Cancedda (2011), we implement
a linear-chain CRF merging system using the
following features: stemmed (separated) surface
form, part-of-speech14 and frequencies from the
training corpus for bigrams/merging of word and
word+1, word as true prefix, word+1 as true suf-
fix, plus frequency comparisons of these. The
CRF is trained on the split monolingual data. It
only proposes merging decisions, merging itself
uses a list extracted from the monolingual data
(Popovic et al 2006).
8.3 Experiments
We evaluated the end-to-end inflection system
with the addition of compounds.15 As in the in-
flection experiments described in Section 5, we
use a 5-gram surface LM and a 7-gram POS
LM, but for this experiment, they are trained on
stemmed, split data. The POS LM helps com-
pound parts and heads appear in correct order.
The results are in Table 7. The BLEU score of the
CRF on test is 14.04, which is low. However the
system produces 19 compound types which are
in the reference but not in the parallel data, and
therefore not accessible to other systems. We also
observe many more compounds in general. The
100-best inflection rescoring technique previously
discussed reached 14.07 on the test set. Blind
test results with CRF prediction are much better,
14.08, which is a statistically significant improve-
ment over the baseline (13.68) and approaches the
result we obtained without compounds (14.18).
Correctly generated compounds are single words
which usually carry the same information as mul-
tiple words in English, and are hence likely un-
derweighted by BLEU. We again see many in-
teresting generalizations. For instance, take the
case of translating English miniature cameras to
the German compound Miniaturkameras. minia-
ture camera or miniature cameras does not occur
in the training data, and so there is no appropri-
ate phrase pair in any system (baseline, inflec-
tion, or inflection&compound-splitting). How-
ever, our system with compound splitting has
learned from split composita that English minia-
14Compound modifiers get assigned a special tag based on
the POS of their former heads, e.g., Inflation in the example
is marked as a non-head of a noun.
15We found it most effective to merge word parts during
MERT (so MERT uses the same stem references as before).
1 1 JSM morphological features 13.94
2 4 CRFs morphological features, lexical information 14.04
Table 7: Results with Compounds on the test set
ture can be translated as German Miniatur- and
gets the correct output.
9 Related Work
There has been a large amount of work on trans-
lating from a morphologically rich language to
English, we omit a literature review here due to
space considerations. Our work is in the opposite
direction, which primarily involves problems of
generation, rather than problems of analysis.
The idea of translating to stems and then in-
flecting is not novel. We adapted the work of
Toutanova et al(2008), which is effective but lim-
ited by the conflation of two separate issues: word
formation and inflection.
Given a stem such as brother, Toutanova et. al?s
system might generate the ?stem and inflection?
corresponding to and his brother. Viewing and
and his as inflection is problematic since a map-
ping from the English phrase and his brother to
the Arabic stem for brother is required. The situ-
ation is worse if there are English words (e.g., ad-
jectives) separating his and brother. This required
mapping is a significant problem for generaliza-
tion. We view this issue as a different sort of prob-
lem entirely, one of word-formation (rather than
inflection). We apply a ?split in preprocessing and
resynthesize in postprocessing? approach to these
phenomena, combined with inflection prediction
that is similar to that of Toutanova et. al. The
only work that we are aware of which deals with
both issues is the work of de Gispert and Marin?o
(2008), which deals with verbal morphology and
attached pronouns. There has been other work
on solving inflection. Koehn and Hoang (2007)
introduced factored SMT. We use more complex
context features. Fraser (2009) tried to solve the
inflection prediction problem by simply building
an SMT system for translating from stems to in-
flected forms. Bojar and Kos (2010) improved on
this by marking prepositions with the case they
mark (one of the most important markups in our
system). Both efforts were ineffective on large
data sets. Williams and Koehn (2011) used uni-
fication in an SMT system to model some of the
671
agreement phenomena that we model. Our CRF
framework allows us to use more complex con-
text features.
We have directly addressed the question as to
whether inflection should be predicted using sur-
face forms as the target of the prediction, or
whether linguistic features should be predicted,
along with the use of a subsequent generation
step. The direct prediction of surface forms is
limited to those forms observed in the training
data, which is a significant limitation. How-
ever, it is reasonable to expect that the use of
features (and morphological generation) could
also be problematic as this requires the use of
morphologically-aware syntactic parsers to anno-
tate the training data with such features, and addi-
tionally depends on the coverage of morpholog-
ical analysis and generation. Despite this, our
research clearly shows that the feature-based ap-
proach is superior for English-to-German SMT.
This is a striking result considering state-of-the-
art performance of German parsing is poor com-
pared with the best performance on English pars-
ing. As parsing performance improves, the per-
formance of linguistic-feature-based approaches
will increase.
Virpioja et al(2007), Badr et al(2008), Luong
et al(2010), Clifton and Sarkar (2011), and oth-
ers are primarily concerned with using morpheme
segmentation in SMT, which is a useful approach
for dealing with issues of word-formation. How-
ever, this does not deal directly with linguistic fea-
tures marked by inflection. In German these lin-
guistic features are marked very irregularly and
there is widespread syncretism, making it difficult
to split off morphemes specifying these features.
So it is questionable as to whether morpheme seg-
mentation techniques are sufficient to solve the in-
flectional problem we are addressing.
Much previous work looks at the impact of us-
ing source side information (i.e., feature func-
tions on the aligned English), such as those
of Avramidis and Koehn (2008), Yeniterzi and
Oflazer (2010) and others. Toutanova et. al.?s
work showed that it is most important to model
target side coherence and our stem markup also
allows us to access source side information. Us-
ing additional source side information beyond the
markup did not produce a gain in performance.
For compound splitting, we follow Fritzinger
and Fraser (2010), using linguistic knowledge en-
coded in a rule-based morphological analyser and
then selecting the best analysis based on the ge-
ometric mean of word part frequencies. Other
approaches use less deep linguistic resources
(e.g., POS-tags Stymne (2008)) or are (almost)
knowledge-free (e.g., Koehn and Knight (2003)).
Compound merging is less well studied. Popovic
et al(2006) used a simple, list-based merging ap-
proach, merging all consecutive words included
in a merging list. This approach resulted in too
many compounds. We follow Stymne and Can-
cedda (2011), for compound merging. We trained
a CRF using (nearly all) of the features they used
and found their approach to be effective (when
combined with inflection and portmanteau merg-
ing) on one of our two test sets.
10 Conclusion
We have shown that both the prediction of sur-
face forms and the prediction of linguistic features
are of interest for improving SMT. We have ob-
tained the advantages of both in our CRF frame-
work, and also integrated handling of compounds,
and an inflection-dependent word formation phe-
nomenon, portmanteaus. We validated our work
on a well-studied large corpora translation task.
Acknowledgments
The authors wish to thank the anonymous review-
ers for their comments. Aoife Cahill was partly
supported by Deutsche Forschungsgemeinschaft
grant SFB 732. Alexander Fraser, Marion Weller
and Fabienne Cap were funded by Deutsche
Forschungsgemeinschaft grant Models of Mor-
phosyntax for Statistical Machine Translation.
The research leading to these results has received
funding from the European Community?s Seventh
Framework Programme (FP7/2007-2013) under
grant agreement Nr. 248005. This work was sup-
ported in part by the IST Programme of the Euro-
pean Community, under the PASCAL2 Network
of Excellence, IST-2007-216886. This publica-
tion only reflects the authors? views. We thank
Thomas Lavergne and Helmut Schmid.
References
Eleftherios Avramidis and Philipp Koehn. 2008. En-
riching Morphologically Poor Languages for Statis-
tical Machine Translation. In Proceedings of ACL-
672
08: HLT, pages 763?770, Columbus, Ohio, June.
Association for Computational Linguistics.
Ibrahim Badr, Rabih Zbib, and James Glass. 2008.
Segmentation for English-to-Arabic statistical ma-
chine translation. In Proceedings of ACL-08: HLT,
Short Papers, pages 153?156, Columbus, Ohio,
June. Association for Computational Linguistics.
Ondr?ej Bojar and Kamil Kos. 2010. 2010 Failures in
English-Czech Phrase-Based MT. In Proceedings
of the Joint Fifth Workshop on Statistical Machine
Translation and MetricsMATR, pages 60?66, Upp-
sala, Sweden, July. Association for Computational
Linguistics.
Ann Clifton and Anoop Sarkar. 2011. Combin-
ing morpheme-based machine translation with post-
processing morpheme prediction. In Proceed-
ings of the 49th Annual Meeting of the Associa-
tion for Computational Linguistics: Human Lan-
guage Technologies, pages 32?42, Portland, Ore-
gon, USA, June. Association for Computational
Linguistics.
Adria` de Gispert and Jose? B. Marin?o. 2008. On the
impact of morphology in English to Spanish statisti-
cal MT. Speech Communication, 50(11-12):1034?
1046.
Alexander Fraser. 2009. Experiments in Morphosyn-
tactic Processing for Translating to and from Ger-
man. In Proceedings of the Fourth Workshop on
Statistical Machine Translation, pages 115?119,
Athens, Greece, March. Association for Computa-
tional Linguistics.
Fabienne Fritzinger and Alexander Fraser. 2010. How
to Avoid Burning Ducks: Combining Linguistic
Analysis and Corpus Statistics for German Com-
pound Processing. In Proceedings of the Fifth
Workshop on Statistical Machine Translation, pages
224?234. Association for Computational Linguis-
tics.
Philipp Koehn and Hieu Hoang. 2007. Factored
Translation Models. In Proceedings of the 2007
Joint Conference on Empirical Methods in Natural
Language Processing and Computational Natural
Language Learning (EMNLP-CoNLL), pages 868?
876, Prague, Czech Republic, June. Association for
Computational Linguistics.
Philipp Koehn and Kevin Knight. 2003. Empirical
methods for compound splitting. In EACL ?03:
Proceedings of the 10th conference of the European
chapter of the Association for Computational Lin-
guistics, pages 187?193, Morristown, NJ, USA. As-
sociation for Computational Linguistics.
John Lafferty, Andrew McCallum, and Fernando
Pereira. 2001. Conditional random fields: Prob-
abilistic models for segmenting and labeling se-
quence data. In Proceedings of the International
Conference on Machine Learning, pages 282?289.
Morgan Kaufmann, San Francisco, CA.
Thomas Lavergne, Olivier Cappe?, and Franc?ois Yvon.
2010. Practical very large scale CRFs. In Proceed-
ings the 48th Annual Meeting of the Association for
Computational Linguistics (ACL), pages 504?513.
Association for Computational Linguistics, July.
Minh-Thang Luong, Preslav Nakov, and Min-Yen
Kan. 2010. A Hybrid Morpheme-Word Represen-
tation for Machine Translation of Morphologically
Rich Languages. In Proceedings of the 2010 Con-
ference on Empirical Methods in Natural Language
Processing, pages 148?157, Cambridge, MA, Octo-
ber. Association for Computational Linguistics.
Maja Popovic, Daniel Stein, and Hermann Ney. 2006.
Statistical Machine Translation of German Com-
pound Words. In Proceedings of FINTAL-06, pages
616?624, Turku, Finland. Springer Verlag, LNCS.
Helmut Schmid, Arne Fitschen, and Ulrich Heid.
2004. SMOR: A German Computational Morphol-
ogy Covering Derivation, Composition, and Inflec-
tion. In 4th International Conference on Language
Resources and Evaluation.
Helmut Schmid. 2004. Efficient Parsing of Highly
Ambiguous Context-Free Grammars with Bit Vec-
tors. In Proceedings of Coling 2004, pages 162?
168, Geneva, Switzerland, Aug 23?Aug 27. COL-
ING.
Andreas Stolcke. 2002. SRILM - An Extensible Lan-
guage Modeling Toolkit. In International Confer-
ence on Spoken Language Processing.
Sara Stymne and Nicola Cancedda. 2011. Produc-
tive Generation of Compound Words in Statistical
Machine Translation. In Proceedings of the Sixth
Workshop on Statistical Machine Translation, pages
250?260, Edinburgh, Scotland UK, July. Associa-
tion for Computational Linguistics.
Sara Stymne. 2008. German Compounds in Factored
Statistical Machine Translation. In Proceedings of
GOTAL-08, pages 464?475, Gothenburg, Sweden.
Springer Verlag, LNCS/LNAI.
Kristina Toutanova, Hisami Suzuki, and Achim
Ruopp. 2008. Applying Morphology Generation
Models to Machine Translation. In Proceedings of
ACL-08: HLT, pages 514?522, Columbus, Ohio,
June. Association for Computational Linguistics.
Sami Virpioja, Jaakko J. Va?yrynen, Mathias Creutz,
and Markus Sadeniemi. 2007. Morphology-aware
statistical machine translation based on morphs in-
duced in an unsupervised manner. In PROC. OF
MT SUMMIT XI, pages 491?498.
Philip Williams and Philipp Koehn. 2011. Agree-
ment constraints for statistical machine translation
into German. In Proceedings of the Sixth Workshop
on Statistical Machine Translation, pages 217?226,
Edinburgh, Scotland, July. Association for Compu-
tational Linguistics.
Reyyan Yeniterzi and Kemal Oflazer. 2010. Syntax-
to-Morphology Mapping in Factored Phrase-Based
673
Statistical Machine Translation from English to
Turkish. In Proceedings of the 48th Annual Meet-
ing of the Association for Computational Linguis-
tics, pages 454?464, Uppsala, Sweden, July. Asso-
ciation for Computational Linguistics.
674
Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 579?587,
Gothenburg, Sweden, April 26-30 2014.
c
?2014 Association for Computational Linguistics
How to Produce Unseen Teddy Bears:
Improved Morphological Processing of Compounds in SMT
Fabienne Cap, Alexander Fraser
CIS, University of Munich
{cap|fraser}@cis.uni-muenchen.de
Marion Weller
IMS, University of Stuttgart
wellermn@ims.uni-stuttgart.de
Aoife Cahill
Educational Testing Service
acahill@ets.org
Abstract
Compounding in morphologically rich
languages is a highly productive process
which often causes SMT approaches to
fail because of unseen words. We present
an approach for translation into a com-
pounding language that splits compounds
into simple words for training and, due
to an underspecified representation, allows
for free merging of simple words into
compounds after translation. In contrast to
previous approaches, we use features pro-
jected from the source language to predict
compound mergings. We integrate our ap-
proach into end-to-end SMT and show that
many compounds matching the reference
translation are produced which did not ap-
pear in the training data. Additional man-
ual evaluations support the usefulness of
generalizing compound formation in SMT.
1 Introduction
Productive processes like compounding or inflec-
tion are problematic for traditional phrase-based
statistical machine translation (SMT) approaches,
because words can only be translated as they have
occurred in the parallel training data. As paral-
lel training data is limited, it is desirable to ex-
tract as much information from it as possible. We
present an approach for compound processing in
SMT, translating from English to German, that
splits compounds prior to training (in order to ac-
cess the individual words which together form the
compound) and recombines them after translation.
While compound splitting is a well-studied task,
compound merging has not received as much at-
tention in the past. We start from Stymne and Can-
cedda (2011), who used sequence models to pre-
dict compound merging and Fraser et al. (2012)
who, in addition, generalise over German inflec-
tion. Our new contributions are: (i) We project
features from the source language to support com-
pound merging predictions. As the source lan-
guage input is fluent, these features are more re-
liable than features derived from target language
SMT output. (ii) We reduce compound parts to
an underspecified representation which allows for
maximal generalisation. (iii) We present a detailed
manual evaluation methodology which shows that
we obtain improved compound translations.
We evaluated compound processing both on
held-out split data and in end-to-end SMT. We
show that using source language features increases
the accuracy of compound generation. Moreover,
we find more correct compounds than the base-
lines, and a considerable number of these com-
pounds are unseen in the training data. This is
largely due to the underspecified representation we
are using. Finally, we show that our approach im-
proves upon the previous work.
We discuss compound processing in SMT in
Section 2, and summarise related work in Sec-
tion 3. In Section 4 we present our method for
splitting compounds and reducing the component
words to an underspecified representation. The
merging to obtain German compounds is the sub-
ject of Section 5. We evaluate the accuracy of
compound prediction on held-out data in Section 6
and in end-to-end SMT experiments in Section 7.
We conclude in Section 8.
2 Dealing with Compounds in SMT
In German, two (or more) single words (usually
nouns or adjectives) are combined to form a
compound which is considered a semantic unit.
The rightmost part is referred to as the head while
all other parts are called modifiers. EXAMPLE (1)
lists different ways of joining simple words into
compounds: mostly, no modification is required
(A) or a filler letter is introduced (B). More rarely,
a letter is deleted (C), or transformed (D).
579
Werkzeug
Handel
Obst
Kiste
fruit
box
trading
tool Handelswerkzeug
ObstkisteWerkzeugkiste
Obsthandel fruittrading
tool
boxKiste
Werkzeug
Obst
Handel
splitting training
splitting training
testing re?combination
testing re?combination
Figure 1: Compound processing in SMT allows the synthesis of compounds unseen in the training data.
EXAMPLE (1)
(A) Haus+Boot = Hausboot (?house boat?)
(B) Ort+s+Zeit = Ortszeit (?local time?)
(C) Kirche-e+Turm = Kirchturm (?church tower?)
(D) Kriterium+Liste = Kriterienliste (?criteria list?)
German compounds are highly productive,
1
and
traditional SMT approaches often fail in the face
of such productivity. Therefore, special process-
ing of compounds is required for translation into
German, as many compounds will not (e.g. Haus-
boot, ?house boat?) or only rarely have been seen
in the training data.
2
In contrast, most compounds
consist of two (or more) simple words that occur
more frequently in the data than the compound as
a whole (e.g. Haus (7,975) and Boot (162)) and of-
ten, these compound parts can be translated 1-to-
1 into simple English words. Figure 1 illustrates
the basic idea of compound processing in SMT:
imagine, ?Werkzeug? (?tool?) occurred only as a
modifier of e.g. ?Kiste? (?box?) in the training
data, but the test set contains ?tool? as a simple
word or as the head of a compound. Splitting com-
pounds prior to translation model training enables
better access to the component translations and al-
lows for a high degree of generalisation. At test-
ing time, the English text is translated into the split
German representation, and only afterwards, some
sequences of simple words are (re-)combined into
(possibly unseen) compounds where appropriate.
This merging of compounds is much more chal-
lenging than the splitting, as it has to be applied
to disfluent MT output: i.e., compound parts may
not occur in the correct word order and even if they
do, not all sequences of German words that could
form a compound should be merged.
3 Related Work
Compound processing for translation into a com-
pounding language includes both compound split-
1
Most newly appearing words in German are compounds.
2
~30% of the word types and ~77% of the compound
types we identified in our training data occurred ? 3 times.
ting and merging, we thus report on previous ap-
proaches for both of these tasks.
In the past, there have been numerous attempts
to split compounds, all improving translation qual-
ity when translating from a compounding to a non-
compounding language. Several compound split-
ting approaches make use of substring corpus fre-
quencies in order to find the optimal split points of
a compound (e.g. Koehn and Knight (2003), who
allowed only ?(e)s? as filler letters). Stymne et al.
(2008) use Koehn and Knight?s technique, include
a larger list of possible modifier transformations
and apply POS restrictions on the substrings, while
Fritzinger and Fraser (2010) use a morphological
analyser to find only linguistically motivated sub-
strings. In contrast, Dyer (2010) presents a lattice-
based approach to encode different segmentations
of words (instead of finding the one-best split).
More recently, Macherey et al. (2011) presented
a language-independent unsupervised approach in
which filler letters and a list of words not to be split
(e.g., named entities) are learned using phrase ta-
bles and Levenshtein distance.
In contrast to splitting, the merging of com-
pounds has received much less attention in the
past. An early approach by Popovi?c et al. (2006)
recombines compounds using a list of compounds
and their parts. It thus never creates invalid Ger-
man compounds, but on the other hand it is limited
to the coverage of the list. Moreover, in some con-
texts a merging in the list may still be wrong, cf.
EXAMPLE (3) in Section 5 below. The approach
of Stymne (2009) makes use of a factored model,
with a special POS-markup for compound mod-
ifiers, derived from the POS of the whole com-
pound. This markup enables sound mergings of
compound parts after translation if the POS of the
candidate modifier (X-Part) matches the POS of
the candidate compound head (X): Inflations|N-
Part + Rate|N = Inflationsrate|N (?inflation rate?).
In Stymne and Cancedda (2011) the factored ap-
580
Gas|Traum      8.34Gastraum        3.74Gast|Raum    8.59
4) Disambiguation
...
...
...
Amerikanische Medien ...
Tim Baumeister besiegt ...
Der Gastraum des ...
0) Original Text
...
(S(NP(ADJA Amerikanische) (NN Medien)...))
...(S(NP(PN(NE Tim)(NE Baumeister))(VV besiegt)...))
...
(S(NP(ART Der) (NN Gastraum) (ART des)...))
1) Bitpar Parsed Text
> amerikanische
> Gastraum
> BaumeisterBau<NN>Meister<+NN>Baumeister<+NPROP>
Gast<NN>Raum<+NN>Gas<NN>Traum<+NN>
amerikanisch<+ADJ>
3) SMOR Analysis
amerikanische Medien ...ADJA NN
NETim Baumeister besiegt ...NE VV
ARTNNARTder Gastraum des ...
...
...
...
2) True Casing
Figure 2: Compound splitting pipeline 1) The original text is parsed with BITPAR to get unambiguous POS tags,
2) The original text is then true-cased using the most frequent casing for each word and BITPAR tags are added,
3) All words are analysed with SMOR, analyses are filtered using BITPAR tags (only bold-faced analyses are kept),
4) If several splitting options remain, the geometric mean of the word (part) frequencies is used to disambiguate them.
proach was extended to make use of a CRF se-
quence labeller (Lafferty et al., 2001) in order
to find reasonable merging points. Besides the
words and their POS, many different target lan-
guage frequency features were defined to train the
CRF. This approach can even produce new com-
pounds unseen in the training data, provided that
the modifiers occurred in modifier position of a
compound and heads occurred as heads or even as
simple words with the same inflectional endings.
However, as former compound modifiers were left
with their filler letters (cf. ?Inflations?), they can
not be generalised to compound heads or simple
words, nor can inflectional variants of compound
heads or simple words be created (e.g. if ?Rate?
had only been observed in nominative form in the
training data, the genitive ?Raten? could not be
produced). The underspecified representation we
are using allows for maximal generalisation over
word parts independent of their position of oc-
currence or inflectional realisations. Moreover,
their experiments were limited to predicting com-
pounds on held-out data; no results were reported
for using their approach in translation. In Fraser
et al. (2012) we re-implemented the approach of
Stymne and Cancedda (2011), combined it with
inflection prediction and applied it to a transla-
tion task. However, compound merging was re-
stricted to a list of compounds and parts. Our
present work facilitates more independent com-
bination. Toutanova et al. (2008) and Weller et
al. (2013) used source language features for target
language inflection, but to our knowledge, none of
these works applied source language features for
compound merging.
4 Step 1: Underspecified Representation
In order to enhance translation model accuracy,
it is reasonable to have similar degrees of mor-
phological richness between source and target lan-
guage. We thus reduce the German target lan-
guage training data to an underspecified represen-
tation: we split compounds, and lemmatise all
words (except verbs). All occurrences of simple
words, former compound modifiers or heads have
the same representation and can thus be freely
merged into ?old? and ?new? compounds after
translation, cf. Figure 1 above. So that we can later
predict the merging of simple words into com-
pounds and the inflection of the words, we store
all of the morphological information stripped from
the underspecified representation.
Note that erroneous over-splitting might make
the correct merging of compounds difficult
3
(or even impossible), due to the number of
correct decisions required. For example, it
requires only 1 correct prediction to recom-
bine ?Niederschlag|Menge? into ?Niederschlags-
menge? (?amount of precipitation?) but 3 for
the wrong split into ?nie|der|Schlag|Menge?
(?never|the|hit|amount?). We use the compound
splitter of Fritzinger and Fraser (2010), who have
shown that using a rule-based morphological anal-
yser (SMOR, Schmid et al. (2004)) drastically re-
duced the number of erroneous splits when com-
pared to the frequency-based approach of Koehn
and Knight (2003). However, we adapted it to
work on tokens: some words can, depending on
their context, either be interpreted as named enti-
ties or common nouns, e.g., ?Dinkelacker? (a Ger-
man beer brand or ?spelt|field?).
4
We parsed the
training data and use the parser?s decisions to iden-
tify proper names, see ?Baumeister? in Figure 2.
After splitting, we use SMOR to reduce words to
lemmas, keeping morphological features like gen-
der or number, and stripping features like case, as
illustrated for ?
?
Olexporteure? (?oil exporters?):
3
In contrast, they may not hurt translation quality in the
other direction, where phrase-based SMT is likely to learn
the split words as a phrase and thus recover from that error.
4
Note that Macherey et al. (2011) blocked splitting of
words which can be used as named entities, independent of
context, which is less general than our solution.
581
No. Feature Description Example
Experiment
SC T TR
1SC surface form of the word string: Arbeit<+NN><Fem><Sg> X X
2SC main part of speech of the word (from the parser) string: +NN X X
3SC word occurs in a bigram with the next word frequency: 0 X X
4SC word combined to a compound with the next word frequency: 10,000 X X X
5SC word occurs in modifier position of a compound frequency: 100,000 X X
6SC word occurs in a head position of a compound frequency: 10,000 X X
7SC word occurs in modifier position vs. simplex string: P>W (P= 5SC, W= 100,000) X
8SC word occurs in head position vs. simplex string: S<W (S= 6SC, W= 100,000) X
7SC+ word occurs in modifier position vs. simplex ratio: 10 (10**ceil(log10(5SC/W))) X X
8SC+ word occurs in head position vs. simplex ratio: 1 (10**ceil(log10(6SC/W))) X X
9N different head types the word can combine with number: 10,000 X X
Table 1: Target language CRF features for compound merging. SC = features taken from Stymne and Cancedda
(2011), SC+ = improved versions, N = new feature. Experiments: SC = re-implementation of Stymne and Cancedda (2011),
T= use full Target feature set, TR = use Target features, but only a Reduced set.
EXAMPLE (2)
?l<+NN><Neut><Sg> Exporteur<+NN> <Masc><Pl>
?l<NN>Exporteur<+NN><Masc><Nom><Pl>compound
headmodifier
While the former compound head (?Exporteure?)
automatically inherits all morphological features
of the compound as a whole, the features of the
modifier need to be derived from SMOR in an ad-
ditional step. We need to ensure that the repre-
sentation of the modifier is identical to the same
word when it occurs independently in order to ob-
tain full generalisation over compound parts.
5 Step 2: Compound Merging
After translation from English into the underspec-
ified German representation, post-processing is re-
quired to transform the output back into fluent,
morphologically fully specified German. First,
compounds need to be merged where appropriate,
e.g., ?Hausboote? (?house boats?):
Haus<+NN><Neut><Sg> + Boot<+NN><Neut><Pl>
? Haus<NN>Boot<+NN><Neut><Pl> (merged)
and second, all words need to be inflected:
Haus<NN>Boot<+NN><Neut><Acc><Pl>
? Hausbooten (inflected)
5.1 Target Language Features
To decide which words should be combined, we
follow Stymne and Cancedda (2011) who used
CRFs for this task. The features we derived from
the target language to train CRF models are listed
in Table 1. We adapted features No. 1-8 from
Stymne and Cancedda (2011). Then, we modi-
fied two features (7+8) and created a new feature
indicating the productivity of a modifier (9N).
5.2 Projecting Source Language Features
We also use new features derived from the English
source language input, which is coherent and flu-
ent. This makes features derived from it more reli-
able than the target language features derived from
disfluent SMT output. Moreover, source language
features might support or block merging decisions
in unclear cases, i.e., where target language fre-
quencies are not helpful, either because they are
very low or they have roughly equal frequency dis-
tributions when occurring in a compound (as mod-
ifier or head) vs. as a simple word.
In Table 2, we list three types of features:
1. Syntactic features: different English noun
phrase patterns that are aligned to German
compound candidate words (cf. 10E-13E)
2. The POS tag of the English word (cf. 14E)
3. Alignment features, derived from word
alignments (cf. 15E-18E)
The examples given in Table 2 (10E-13E) show
that English compounds often have 1-to-1 corre-
spondences to the parts of a German compound.
Knowing that two consecutive German simple
words are aligned to two English words of the
same noun phrase is a strong indicator that the
German words should be merged:
EXAMPLE (3)
should be merged:
ein erh?ohtes verkehrs aufkommen sorgt f?ur chaos
?an increased traffic volume causes chaos?
(S...(NP(DT An)(VN increased)(NN traffic)(NN volume))..)))
should not be merged:
f?ur die finanzierung des verkehrs aufkommen
?pay for the financing of transport?
(VP(V pay)(PP(IN for)(NP(NP(DT the)(NN financing))
(PP(IN of)(NP(NN transport)..))
In the compound reading of ?verkehr + aufkom-
men?, the English parse structure indicates that
the words aligned to ?verkehr? (?traffic?) and
582
No. Feature Description Type
10E
word and next word are aligned from a noun phrase in the English source sentence:
(NP(NN traffic)(NN accident))? Verkehr (?traffic?) + Unfall (?accident?)
true/false
11E
word and next word are aligned from a gerund construction in the English source sentence:
(NP(VBG developing)(NNS nations))? Entwicklung (?development?) + L?ander (?countries?)
true/false
12E
word and next word are aligned from a genitive construction in the English source sentence:
(NP(NP(DT the)(NN end))(PP(IN of)(NP(DT the)(NN year))? Jahr (?year?) + Ende(?end?)
true/false
13E
word and next word are aligned from an adjective noun construction in the English source sentence:
(NP (ADJ protective)(NNS measures))? Schutz (?protection?) + Ma?nahmen (?measures?)
true/false
14E print the POS of the corresponding aligned English word string
15E
word and next word are aligned 1-to-1 from the same word in the English source sentence, e.g.,
beef
?
?
Rind(?cow?)
Fleisch(?meat?)
true/false
16E like 15E, but the English word contains a dash, e.g., Nobel ? Prize
?
?
Nobel(?Nobel?)
Preis(?prize?)
true/false
17E like 15E, but also considering 1-to-n and n-to-1 links true/false
18E like 16E, but also considering 1-to-n and n-to-1 links true/false
Table 2: List of new source language CRF features for compound merging.
?aufkommen? (?volume?), are both nouns and
part of one common noun phrase, which is a strong
indicator that the two words should be merged
in German. In contrast, the syntactic relation-
ship between ?pay? (aligned to ?aufkommen?)
and ?transport? (aligned to ?verkehr?) is more dis-
tant
5
: merging is not indicated.
We also use the POS of the English words to
learn (un)usual combinations of POS, indepen-
dent of their exact syntactic structure (14E). Re-
consider EXAMPLE (3): NN+NN is a more com-
mon POS pair for compounds than V+NN.
Finally, the alignment features (15E-18E) pro-
mote the merging into compounds whose align-
ments indicate that they should not have been split
in the first place (e.g., Rindfleisch, 15E).
5.3 Compound Generation and Inflection
So far, we reported on how to decide which sim-
ple words are to be merged into compounds, but
not how to recombine them. Recall from EXAM-
PLE (1) that the modifier of a compound some-
times needs to be transformed, before it can be
combined with the head word (or next modifier),
e.g., ?Ort?+?Zeit? = ?Ortszeit? (?local time?).
We use SMOR to generate compounds from a
combination of simple words. This allows us to
create compounds with modifiers that never oc-
curred as such in the training data. Imagine that
?Ort? occurred only as compound head or as a
single word in the training data. Using SMOR, we
are still able to create the correct form of the mod-
ifier, including the required filler letter: ?Orts?.
This ability distinguishes our approach from pre-
5
Note that ?f?ur etwas aufkommen? (lit. ?for sth. arise?,
idiom.: ?to pay for sth.?) is an idiomatic expression.
vious approaches: Stymne and Cancedda (2011)
do not reduce modifiers to their base forms
6
(they
can only create new compounds when the modifier
occurred as such in the training data) and Fraser et
al. (2012) use a list for merging.
Finally, we use the system described in Fraser
et al. (2012) to inflect the entire text.
6 Accuracy of Compound Prediction
We trained CRF models on the parallel training
data (~40 million words)
7
of the EACL 2009
workshop on statistical machine translation
8
us-
ing different feature (sub)sets, cf. the ?Exper-
iment? column in Table 1 above. We exam-
ined the reliability of the CRF compound predic-
tion models by applying them to held-out data:
1. split the German wmt2009 tuning data set
2. remember compound split points
3. predict merging with CRF models
4. combine predicted words into compounds
5. calculate f-scores on how properly the
compounds were merged
Table 3 lists the CRF models we trained, together
with their compound merging accuracies on held-
out data. It can be seen that using more features
(SC?T?ST) is favourable in terms of precision
and overall accuracy and the positive impact of us-
ing source language features is clearer when only
reduced feature sets are used (TR vs. STR).
However, these accuracies only somewhat cor-
relate with SMT performance: while being trained
and tested on clean, fluent German language, the
6
They account for modifier transformations by using char-
acter n-gram features (cf.EXAMPLE (1)).
7
However, target language feature frequencies are derived
from the monolingual training data, ~146 million words.
8
http://www.statmt.org/wmt09
583
exp to be all correct wrong wrong not merging
precision recall f-score
merged merged merged merged merged wrong
SC 1,047 997 921 73 121 3 92.38% 88.13% 90.21%
T 1,047 979 916 59 128 4 93.56% 87.40% 90.38%
ST 1,047 976 917 55 126 4 93.95% 87.58% 90.66%
TR 1,047 893 836 52 204 5 93.62% 80.00% 86.27%
STR 1,047 930 866 58 172 6 93.12% 82.95% 87.74%
Table 3: Compound production accuracies of CRF models on held-out data: SC: re-implementation of Stymne
and Cancedda (2011); T: all target language features, including a new one (cf. Table 1); ST = all Source and Target language
features; TR: only a reduced set of target language features; STR: TR, plus all source language features given in Table 2.
exp BLEU SCORES #compounds found
mert.log BLEU RTS all ref new new*
RAW 14.88 14.25 1.0054 646 175 n.a. n.a.
UNSPLIT 15.86 14.74 0.9964 661 185 n.a. n.a.
SC 15.44 14.45 0.9870 882 241 47 8
T 15.56 14.32 0.9634 845 251 47 8
ST 15.33 14.51 0.9760 820 248 46 9
TR 15.24 14.26 0.9710 753 234 44 5
STR 15.37 14.61 0.9884 758 239 43 7
#compounds in reference text: 1,105 1,105 396 193
Table 4: SMT results. Tuning scores (mert.log) are on merged but uninflected data (except RAW).
RTS: length ratio; all: #compounds produced; ref: reference matches; new: unknown to parallel data; new*: unknown to
target language data. bold face indicates statistical significance wrt. the RAW baseline, SC, T and TR.
models will later be applied to disfluent SMT out-
put and might thus lead to different results there.
Stymne and Cancedda (2011) dealt with this by
noisifying the CRF training data: they translated
the whole data set using an SMT system that was
trained on the same data set. This way, the train-
ing data was less fluent than in its original format,
but still of higher quality than SMT output of un-
seen data. In contrast, we left the training data as
it was, but strongly reduced the feature set for CRF
model training (e.g., no more use of surface words
and POS tags, cf. TR and STR in Table 3) instead.
7 Translation Performance
We integrated our compound processing pipeline
into an end-to-end SMT system. Models were
trained with the default settings of the Moses SMT
toolkit, v1.0 (Koehn et al., 2007) using the data
from the EACL 2009 workshop on statistical ma-
chine translation. All compound processing sys-
tems are trained and tuned identically, except us-
ing different CRF models for compound predic-
tion. All training data was split and reduced
to the underspecified representation described in
Section 4. We used KenLM (Heafield, 2011) with
SRILM (Stolcke, 2002) to train a 5-gram language
model based on all available target language train-
ing data. For tuning, we used batch-mira with ?-
safe-hope? (Cherry and Foster, 2012) and ran it
separately for every experiment. We integrated the
CRF-based merging of compounds into each itera-
tion of tuning and scored each output with respect
to an unsplit and lemmatised version of the tuning
reference. Testing consists of:
1. translation into the split, underspecified
German representation
2. compound merging using CRF models
to predict recombination points
3. inflection of all words
7.1 SMT Results
We use 1,025 sentences for tuning and 1,026 sen-
tences for testing. The results are given in Table 4.
We calculate BLEU scores (Papineni et al., 2002)
and compare our systems to a RAW baseline (built
following the instructions of the shared task) and a
baseline very similar to Fraser et al. (2012), using
a lemmatised representation of words for decod-
ing, re-inflecting them after translation, but with-
out compound processing (UNSPLIT). Table 4
shows that only UNSPLIT and STR (source lan-
guage and a reduced set of target language fea-
tures) are significantly
9
improving over the RAW
baseline. They also significantly outperform all
other systems, except ST (full source and target
language feature set). The difference between STR
(14.61) and the UNSPLIT baseline (14.74) is not
statistically significant.
9
We used pair-wise bootstrap resampling with sample size
1000 and p-value 0.05, from: http://www.ark.cs.cmu.edu/MT
584
group ID example reference english UNSPLIT STR
lexically 1a: perfect match Inflationsrate Inflationsrate inflation rate 185 239
matches 1b: inflection wrong Rohstoffpreisen Rohstoffpreise raw material prices 40 44
the 2a: merging wrong Anwaltsbewegung Anw?altebewegung lawyers movement 5 9
reference 2b: no merging Polizei Chef Polizeichef police chief 101 54
correct 3a: compound Zentralbanken Notenbank central banks 92 171
translation 3b: no compound pflanzliche
?
Ole Speise?ol vegetable oils 345 291
wrong 4a: compound Haushaltsdefizite Staatshaushalts state budget 12 42
translation 4b: no compound Ansporn Linien Nebenlinien spur lines 325 255
Total number of compounds in reference text: 1,105 1,105
Table 5: Groups for detailed manual compound evaluation and results for UNSPLIT and STR.
reference English source UNSPLIT baseline STR
Teddyb?aren teddy bear 4b
Teddy tragen
1a
Teddyb?aren
(Teddy, to bear) (teddy bear)
Emissionsreduktion emissions reduction 3b
Emissionen Reduzierung
3a
Emissionsverringerung
(emissions, reducing) (emission decrease)
Geldstrafe fine 4b
sch?onen
3a
Bu?geld
(fine/nice) (monetary fine)
Tischtennis table tennis 2b
Tisch Tennis
4a
Spieltischtennis
(table, tennis) (play table tennis)
Kreditkartenmarkt credit-card market 2b
Kreditkarte Markt
4a
Kreditmarkt
(credit-card, market) (credit market)
Rotationstempo rotation rate 2b
Tempo Rotation
4a
Temporotation
(rate, rotation) (rate rotation)
Table 6: Examples of the detailed manual compound analysis for UNSPLIT and STR.
Compound processing leads to improvements at
the level of unigrams and as BLEU is dominated
by four-gram precision and length penalty, it does
not adequately reflect compound related improve-
ments. We thus calculated the number of com-
pounds matching the reference for each experi-
ment and verified whether these were known to
the training data. The numbers in Table 4 show
that all compound processing systems outperform
both baselines in terms of finding more exact refer-
ence matches and also more compounds unknown
to the training data. Note that STR finds less ref-
erence matches than e.g. T or ST, but it also pro-
duces less compounds overall, i.e. it is more pre-
cise when producing compounds.
However, as compounds that are correctly com-
bined but poorly inflected are not counted, this is
only a lower bound on true compounding perfor-
mance. We thus performed two additional manual
evaluations and show that the quality of the com-
pounds (Section 7.2), and the human perception of
translation quality is improving (Section 7.3).
7.2 Detailed Evaluation of Compounds
This evaluation focuses on how compounds in the
the reference text have been translated.
10
We:
10
In another evaluation, we investigated the 519 com-
pounds that our system produced but which did not match
the reference: 367 were correct translations of the English,
1. manually identify compounds in German
reference text (1,105 found)
2. manually perform word alignment of these
compounds to the English source text
3. project these English counterparts of com-
pounds in the reference text to the decoded
text using the ??print-alignment-info? flag
4. manually annotate the resulting tuples, us-
ing the categories given in Table 5
The results are given in the two rightmost columns
of Table 5: besides a higher number of reference
matches (cf. row 1a), STR overall produces more
compounds than the UNSPLIT baseline, cf. rows
2a, 3a and 4a. Indirectly, this can also be seen from
the low numbers of STR in category 2b), where
the UNSPLIT baseline produces much more (101
vs. 54) translations that lexically match the refer-
ence without being a compound. While the 171
compounds of STR of category 3a) show that our
system produces many compounds that are correct
translations of the English, even though not match-
ing the reference (and thus not credited by BLEU),
the compounds of categories 2a) and 4a) contain
examples where we either fail to reproduce the
correct compound or over-generate compounds.
We give some examples in Table 6: for ?teddy
bear?, the correct German word ?Teddyb?aren? is
87 contained erroneous lexemes and 65 were over-mergings.
585
missing in the parallel training data and instead
of ?B?ar? (?bear?), the baseline selected ?tragen?
(?to bear?). Extracting all words containing the
substring ?b?ar? (?bear?) from the original parallel
training data and from its underspecified split
version demonstrates that our approach is able
to access all occurrences of the word. This leads
to higher frequency counts and thus enhances
the probabilities for correct translations. We can
generalise over 18 different word types containing
?bear? (e.g. ?polar bears?, ?brown bears?, ?bear
skin?, ?bear fur?) to obtain only 2:
occurrences in raw training data: B?ar (19), B?aren
(26), B?arendienst (42), B?arenfarmen (1), B?arenfell (2),
B?arengalle(1), B?arenhaut (1), B?arenmarkt (1), Braunb?ar
(1), Braunb?aren (3), Braunb?arengebiete (1), Braunb?ar-
Population (1), Eisb?aren(18), Eisb?arenpopulation (2),
Eisb?arenpopulationen (1), Schwarzb?ar (1), Schwarzb?aren (1)
?b?ar? occurring in underspecified split data:
B?ar<+NN><Masc><Sg> (94)
B?ar<+NN><Masc><Pl> (29)
?Emissionsverringerung? (cf. Table 6) is a typ-
ical example of group 3a): a correctly translated
compound that does not lexically match the ref-
erence, but which is semantically very similar to
the reference. The same applies for ?Bu?geld?,
a synonym of ?Geldstrafe?, for which the UN-
SPLIT baseline selected ?sch?onen? (?fine, nice?)
instead. Consider also the wrong compound pro-
ductions, e.g. ?Tischtennis? is combined with
the verb ?spielen? (?to play?) into ?Spieltischten-
nis?. In contrast, ?Kreditmarkt? dropped the mid-
dle part ?Karte? (?card?), and in the case of ?Tem-
porotation?, the head and modifier of the com-
pound are switched.
7.3 Human perception of translation quality
We presented sentences of the UNSPLIT baseline
and of STR in random order to two native speak-
ers of German and asked them to rank the sen-
tences according to preference. In order to pre-
vent them from being biased towards compound-
bearing sentences, we asked them to select sen-
tences based on their native intuition, without re-
vealing our focus on compound processing.
Sentences were selected based on source lan-
guage sentence length: 10-15 words (178 sen-
tences), of which either the reference or our
system had to contain a compound (95 sen-
tences). After removing duplicates, we ended up
with 84 sentences to be annotated in two subse-
(a) Fluency: without reference sentence
? = 0.3631
person 1
STR UNSPLIT equal
p
e
r
s
o
n
2
STR 24 6 7 37
UNSPLIT 5 16 9 30
equal 6 2 9 17
35 24 25 84
(b) Adequacy: with reference sentence
? = 0.4948
person 1
STR UNSPLIT equal
p
e
r
s
o
n
2
STR 23 4 5 32
UNSPLIT 4 21 7 32
equal 5 3 12 20
32 28 24 84
Table 7: Human perception of translation quality.
quent passes: first, without being given the refer-
ence sentence (approximating fluency), then, with
the reference sentence (approximating adequacy).
The results are given in Table 7. Both annotators
preferred more sentences of our system overall,
but the difference is clearer for the fluency task.
8 Conclusion
Compounds require special attention in SMT, es-
pecially when translating into a compounding lan-
guage. Compared with the baselines, all of our ex-
periments that included compound processing pro-
duced not only many more compounds matching
the reference exactly, but also many compounds
that did not occur in the training data. Taking
a closer look, we found that some of these new
compounds could only be produced due to the un-
derspecified representation we are using, which al-
lows us to generalise over occurrences of simple
words, compound modifiers and heads. Moreover,
we demonstrated that features derived from the
source language are a valuable source of informa-
tion for compound prediction: experiments were
significantly better compared with contrastive ex-
periments without these features. Additional man-
ual evaluations showed that compound processing
leads to improved translations where the improve-
ment is not captured by BLEU.
Acknowledgements
This work was supported by Deutsche For-
schungsgemeinschaft grants Models of Mor-
phosyntax for Statistical Machine Translation
(Phase 2) and Distributional Approaches to Se-
mantic Relatedness. We thank the anonymous re-
viewers for their comments and the annotators.
586
References
Colin Cherry and George Foster. 2012. Batch Tun-
ing Strategies for Statistical Machine Translation. In
HLT-NAACL?12: Proceedings of the Human Lan-
guage Technology Conference of the North Ameri-
can Chapter of the Association for Computational
Linguistics, volume 12, pages 34?35. Association
for Computational Linguistics.
Chris Dyer. 2010. A Formal Model of Ambiguity and
its Applications in Machine Translation. Phd disser-
tation, University of Maryland, USA.
Alexander Fraser, Marion Weller, Aoife Cahill, and Fa-
bienne Cap. 2012. Modeling Inflection and Word
Formation in SMT. In EACL?12: Proceedings of the
13th Conference of the European Chapter of the As-
sociation for Computational Linguistics, pages 664?
674. Association for Computational Linguistics.
Fabienne Fritzinger and Alexander Fraser. 2010. How
to Avoid Burning Ducks: Combining Linguistic
Analysis and Corpus Statistics for German Com-
pound Processing. In Proceedings of the Fifth Work-
shop on Statistical Machine Translation, pages 224?
234. Association for Computational Linguistics.
Kenneth Heafield. 2011. KenLM: Faster and Smaller
Language Model Queries. In Proceedings of the
Sixth Workshop on Statistical Machine Translation,
Edinburgh, UK, July. Association for Computational
Linguistics.
Philipp Koehn and Kevin Knight. 2003. Empirical
Methods for Compound Splitting. In EACL ?03:
Proceedings of the 10th Conference of the European
Chapter of the Association for Computational Lin-
guistics, pages 187?193, Morristown, NJ, USA. As-
sociation for Computational Linguistics.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
Source Toolkit for Statistical Machine Translation.
In ACL?07: Proceedings of the 45th Annual Meet-
ing of the Association for Computational Linguis-
tics, Demonstration Session, pages 177?180. Asso-
ciation for Computational Linguistics.
John Lafferty, Andrew McCallum, and Fernando
Pereira. 2001. Conditional Random Fields: Prob-
abilistic Models for Segmenting and Labeling Se-
quence Data. In ICML?01: Proceedings of the 18th
International Conference on Machine Learning.
Klaus Macherey, Andrew M. Dai, David Talbot,
Ashok C. Popat, and Franz Och. 2011. Language-
independent Compound Splitting with Morpholog-
ical Operations. In ACL ?11: Proceedings of the
49th annual meeting of the Association for Compu-
tational Linguistics, pages 1395?1404. Association
for Computational Linguistics.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: A Method for Automatic
Evaluation of Machine Translation. In ACL?02:
Proceedings of the 40th Annual Meeting of the As-
sociation for Computational Linguistics, pages 311?
318. Association for Computational Linguistics.
Maja Popovi?c, Daniel Stein, and Hermann Ney. 2006.
Statistical Machine Translation of German Com-
pound Words. In FinTAL?06: Proceedings of the
5th International Conference on Natural Language
Processing, pages 616?624. Springer Verlag.
Helmut Schmid, Arne Fitschen, and Ulrich Heid.
2004. SMOR: A German Computational Morphol-
ogy Covering Derivation, Composition and Inflec-
tion. In LREC ?04: Proceedings of the 4th Confer-
ence on Language Resources and Evaluation, pages
1263?1266.
Andreas Stolcke. 2002. SRILM ? an Extensible Lan-
guage Modelling Toolkit. In ICSLN?02: Proceed-
ings of the international conference on spoken lan-
guage processing, pages 901?904.
Sara Stymne and Nicola Cancedda. 2011. Productive
Generation of Compound Words in Statistical Ma-
chine Translation. In EMNLP?11: Proceedings of
the 6th Workshop on Statistical Machine Transla-
tion and Metrics MATR of the conference on Em-
pirical Methods in Natural Language Processing,
pages 250?260. Association for Computational Lin-
guistics.
Sara Stymne, Maria Holmqvist, and Lars Ahrenberg.
2008. Effects of Morphological Analysis in Transla-
tion between German and English. In ACL?08: Pro-
ceedings of the 3rd workshop on statistical machine
translation of the 46th annual meeting of the Associ-
ation for Compuational Linguistics, pages 135?138.
Association for Computational Linguistics,.
Sara Stymne. 2009. A Comparison of Merging Strate-
gies for Translation of German Compounds. In
EACL ?09: Proceedings of the Student Research
Workshop of the 12th conference of the European
Chapter of the Association for Computational Lin-
guistics, pages 61?69. Association for Computa-
tional Linguistics.
Kristina Toutanova, Hisami Suzuki, and Achim Ruopp.
2008. Applying Morphology Generation Models to
Machine Translation. In ACL?08: Proceedings of
the 46th Annual Meeting of the Association for Com-
putational Linguistics: Human Language Technolo-
gies, pages 514?522. Association for Computational
Linguistics.
Marion Weller, Alexander Fraser, and Sabine
Schulte im Walde. 2013. Using Subcatego-
rization Knowledge to Improve Case Prediction for
Translation to German. In ACL?13: Proceedings
of the 51st Annual Meeting of the Association
for Computational Linguistics, pages 593?603.
Association for Computational Linguistics.
587
Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 71?78,
Baltimore, Maryland USA, June 26?27, 2014. c?2014 Association for Computational Linguistics
CimS ? The CIS and IMS joint submission to WMT 2014
translating from English into German
Fabienne Cap_, Marion Weller_f, Anita Rammf, Alexander Fraser_
_ CIS, Ludwig-Maximilian University of Munich ? (cap|fraser)@cis.uni-muenchen.de
f IMS, University of Stuttgart ? (wellermn|ramm)@ims.uni-stuttgart.de
Abstract
We present the CimS submissions to the
2014 Shared Task for the language pair
EN?DE. We address the major problems
that arise when translating into German:
complex nominal and verbal morphol-
ogy, productive compounding and flex-
ible word ordering. Our morphology-
aware translation systems handle word
formation issues on different levels of
morpho-syntactic modeling.
1 Introduction
In our shared task submissions, we focus on the
English to German translation direction: we ad-
dress different levels of productivity of the Ger-
man language, i.e., nominal and verbal inflec-
tion and productive word formation, which lead
to data sparsity and thus confuse classical SMT
systems.
Our basic goal is to make the two languages
as morphosyntactically similar as possible. We
use a parser and a morphological analyser to re-
move linguistic features from German that are
not present in English and reorder the English
input to make it more similar to the German sen-
tence structure. Prior to training, all words are
lemmatised and compounds are split into single
words. This is not only beneficial for word align-
ment, but it also allows us to generalise over in-
flectional variants of the same lexemes and over
single words which could occur in one place as a
standalone word and in another place as part of
a compound. Translation happens in two steps:
first, we translate from English into split, lemma-
tised German and then, we perform compound
merging and generation of inflection as a post-
processing step. This way, we are able to cre-
ate German compounds and inflectional vari-
ants that have not been seen in the parallel train-
ing data.
In this paper, we investigate the performance of
well-established source-side reordering, nomi-
nal re-inflection and compound processing sys-
tems on an up-to-date shared task. In addition,
we present experimental results on a verbal in-
flection component and a syntax-based variant
including source-side reordering.
2 Related Work
Re-Inflection The two-step translation ap-
proach we use was described by e.g. Toutanova
et al. (2008) and Jeong et al. (2010), who use
a number of morphological and syntactic
features derived from both source and target
language. More recently, Fraser et al. (2012)
describe a similar approach for German using
different CRF-based feature prediction models,
one for each of the four grammatical features
to be predicted for German words in noun
phrases, namely number, gender, case and
definiteness. This approach also handles word-
formation issues such as portmanteau splitting
and compounding. Weller et al. (2013) added
subcategorization information in combination
with source-side syntactic features in order to
improve the prediction of case.
De Gispert and Mari?o (2008) generate verbal
inflection for translation from English into Span-
ish. They use classifiers trained not only on tar-
get language but also on source language fea-
tures, which is even more crucial for the predic-
tion of verbs than it is for nominal inflection.
More recently, Williams and Koehn (2011)
translate directly into target language surface
forms. Agreement within NPs and PPs, and also
between subject and verb is considered during
the decoding process: they use string-to-tree
translation, where the target language (German)
morphology is expressed as a set of unification
constraints automatically learned from a mor-
phologically annotated German corpus.
71
Compound Processing Compound splitting
for SMT has been addressed by numerous dif-
ferent groups, for translation from German
to English, e.g. using corpus-based frequen-
cies (Koehn and Knight, 2003), using POS-
constraints (Stymne et al., 2008), a lattice-based
approach propagating the splitting decision to
the decoder (Dyer, 2009), a rule-based morpho-
logical analyser (Fritzinger and Fraser, 2010) or
unsupervised, language-independent segmen-
tation (Macherey et al., 2011).
Compound processing in the other translation
direction, however, has been much less investi-
gated. Popovic? et al. (2006) describe a list-based
approach, in which words are only re-combined
if they have been seen as compounds in a huge
corpus. However this approach is limited to
the list?s coverage. The approach of Stymne
(2009) overcomes this coverage issue by mak-
ing use of a POS-markup which distinguishes
former compound modifiers from former heads
and thus allows for their adequate recombina-
tion after translation. An extension of this ap-
proach is reported in Stymne and Cancedda
(2011) where a CRF-model is used for compound
prediction. In Cap et al. (2014) their approach
is extended through using source-language fea-
tures and lemmatisation, allowing for maximal
generalisation over compound parts.
Source-side Reordering One major problem in
English to German translation is the divergent
clausal ordering: in particular, German verbs
tend to occur at the very end of clauses, whereas
English sticks to a rigid SVO order in most cases.
Collins et al. (2005), Fraser (2009) and Gojun
and Fraser (2012) showed that restructuring the
source language so that it corresponds to the ex-
pected structure of the target language is helpful
for SMT.
3 Inflection Prediction
German has a rich morphology, both for nom-
inal and verbal inflection. It requires differ-
ent forms of agreement, e.g., for adjectives and
nouns or verbs and their subjects. Traditional
phrase-based SMT systems often get such agree-
ments wrong. In our systems, we explicitly
model agreement using a two-step approach:
first we translate from English into lemmatised
German and then generate fully inflected forms
in a second step. In this section, we describe our
nominal inflection component and first experi-
mental steps towards verbal re-inflection.
3.1 Noun Phrase Inflection
Prior to training, the German data is re-
duced to a lemmatised representation contain-
ing translation-relevant morphological features.
For nominal inflection, the lemmas are marked
with number and gender: gender is considered
as part of the lemma, whereas number is indi-
rectly determined by the source-side, as we ex-
pect nouns to be translated with their appro-
priate number value. We use a linear chain
CRF (Lafferty et al., 2001) to predict the mor-
phological features (number, gender, case and
strong/weak). The features that are part of the
lemma of nouns (number, gender) are propa-
gated over the rest of the linguistic phrase. In
contrast, case depends on the role of the NP in
the sentence (e.g. subject or direct/indirect ob-
ject) and is thus to be determined entirely from
the respective context in the sentence. The value
for strong/weak depends on the combination of
the other features. Based on the lemma and the
predicted features, inflected forms are then gen-
erated using the rule-based morphological anal-
yser SMOR (Schmid et al., 2004). This system is
described in more detail in Fraser et al. (2012).
3.2 Verbal Inflection
German verbs agree in number and person with
their subjects. We thus have to derive this in-
formation from a noun phrase in nominative
case (= the subject) near the verb. This informa-
tion comes from the nominal inflection predic-
tion described in section 3.1. We predict tense
and mode of the verb using a maximum-entropy
classifier which is trained on English and Ger-
man contextual information. After deriving all
information needed for the generation of the
verbs, the inflected forms are generated with
SMOR.
4 Compound Processing
In English to German translation, compound
processing is more difficult than in the oppo-
site direction. Not only do compounds have to
be split accurately, but they also have to be put
together correctly after decoding. The disflu-
ency of MT output and the difficulty of deciding
which single words should be merged into com-
pounds make this task even more challenging.
72
(split+lem.)
Training
Parallel Training Data
LanguageModel
TranslationModel
English text
....
....
....
Target Training Data
....
....
....
....
....
....
German text
German text
....
....
....
tooltradefruit box Werkzeug KisteHandelObst
Werkzeug KisteObst Handel
Parallel Training Data
....
....
....
....
....
....
ObsthandelWerkzeugkiste
Target Training Data
German text
Pre?Processing
Obsthandel....
....
....
Werkzeugkiste
....
....
....
tool boxfruit trade
English text German text
Post?processing 
....
....ObstkisteObsthandel
German(fluent)
Testing
inputEnglish
....fruit tradefruit box
(split+lem.)
(split+lem.)
lemmatisesplit
splitlemmatise ....
....
RecombineRe?inflect
German
(split+lem.)
....
output
Obst KisteObst Handel
Decoder
Figure 1: Pipeline overview of our primary CimS-CoRI system.
We combine compound processing with in-
flection prediction (see Section 3) and thus ex-
tend the two-step approach respectively: com-
pounds are split and lemmatised simultane-
ously, again using SMOR. This allows for maxi-
mal generalisation over former compound parts
and independently occurring simple words. We
use this split representation for training. Af-
ter decoding, we re-combine words into com-
pounds again, using our extended CRF-based
approach, which is based on Stymne and Can-
cedda (2011), but includes source-language fea-
tures and allows for maximal generalisation
through lemmatisation. More details can be
found in Cap et al. (2014). We then use SMOR
to generate sound German compounds (includ-
ing morphological transformations such as in-
troduction or deletion of filler letters). Finally,
the whole text including the newly-created com-
pounds, is re-inflected using the nominal in-
flection prediction models as described in Sec-
tion 3.1 above. This procedure allows us to create
compounds that have not been seen in the par-
allel training data, and also inflectional variants
of seen compounds. See Figure 1 for an overview
of our compound processing pipeline.
4.1 Portmanteaus
Portmanteaus are a special kind of compound.
They are a fusion of a preposition and a defi-
nite article (thus not productive) and their case
must agree with the case of the noun. For ex-
ample, ?zum? can be split into ?zu? + ?dem? =
to+theDati ve . They introduce additional spar-
sity to the training data: imagine a noun oc-
curred with its definite article in the training
data, but not with the portemanteau required at
testing time. Splitting portemanteaus allows a
phrase-based SMT system to access phrases cov-
ering nouns and their corresponding definite ar-
ticles. In a post-processing step, definite articles
are then re-merged with their preceding prepo-
sitions to restore the original portmanteau, see
(Fraser et al., 2012) for details. This generalisa-
tion effect is even larger as we not only split port-
manteaus, but also lemmatise the articles.
5 System descriptions
Our shared task submissions include different
combinations of the inflection and compound
processing procedures as described in the pre-
vious two sections. We give an overview of all
our systems in Table 1. Note that we did not
re-train the compound processing CRFs on the
new dataset, but used our models trained on the
2009 training data instead. However, this does
not hurt performance, as the CRF we use is not
trained on surface forms, but only frequencies
and source-side features instead. See (Fraser et
al., 2012) and (Cap et al., 2014) for more details
on how we trained the respective CRFs. In con-
trast, the verbal classifier has been trained on
WMT 2014 data.
6 Experimental Settings
In all our systems, we only used data distributed
for the shared task. All available German data
was morphologically analysed with SMOR. For
lemmatisation of the German training data, we
disambiguated SMOR using POS tags we ob-
tained through parsing the German section of
the parallel training data with BitPar (Schmid,
73
No. apprart nominal compound verbal source-sidesplitting inflection processing inflection reordering
CimS-RI X X
CimS-CoRIP X X X
CimS-RIVe X X X
CimS-CoRIVe X X X X
CimS-Syntax-RORI X X X
Table 1: Overview of our submission systems.RI = nominal Re-Inflection, Co = Compound process-
ing, Ve = Verbal inflection, RO = source-side Re-Ordering. Syntax = syntax-based SMT P = primary
submission.
2004) and tagging the big monolingual training
data using RFTagger (Schmid and Laws, 2008)1.
Note that we did not normalise German lan-
guage e.g. with respect to old vs. new writing
convention etc. as we did in previous submis-
sions (e.g. (Fraser, 2009)).
For the compound prediction CRFs using syn-
tactic features derived from the source language,
we parsed the English section of the parallel
data using EGRET, a re-implementation of the
Berkeley-Parser by Hui Zhang2. Before training
our models on the English data, we normalised
all occurrences of British vs. American English
variants to British English. We did so for train-
ing, tuning and testing input.
Language Model We trained 5-gram language
models based on all available German monolin-
gual training data from the shared task (roughly
1.5 billion words) using the SRILM toolkit (Stol-
cke, 2002) with Kneser-Ney smoothing. We then
used KenLM (Heafield, 2011) for faster process-
ing. For each of our experiments, we trained
a separate language model on the whole data
set, corresponding to the different underspeci-
fied representations of German used in our ex-
periments, e.g. lemmatised for CimS-RI, lemma-
tised with split compounds for CimS-CoRI, etc.
Phrase-based Translation model We per-
formed word alignment using the multithreaded
GIZA++ toolkit (Och and Ney, 2003; Gao and
Vogel, 2008). For translation model training and
decoding, we used the Moses toolkit (Koehn
et al., 2007) to build phrase-based statistical
machine translation systems, following the
instructions for the baseline system for the
shared task, using only default settings.
1We could not parse the whole monolingual dataset due
to time-constraints and thus used RFTagger as a substitute.
2available from https://sites.google.com/
site/zhangh1982/egret.
Syntax-based Translation model As a variant
to the phrase-based systems, we applied the in-
flection prediction system to a string-to-tree sys-
tem with GHKM extraction (Galley et al. (2004),
Williams and Koehn (2012)). We used the same
data-sets as for the phrase-based systems, and
applied BitPar (Schmid, 2004) to obtain target-
side trees. For this system, we used source-side
reordering according to Gojun and Fraser (2012)
relying on parses obtained with EGRET3.
Tuning For tuning of feature weights, we used
batch-mira with ??safe-hope? (Cherry and Foster,
2012) until convergence (or maximal 25 runs).
We used the 3,000 sentences of newstest2012 for
tuning. Each experiment was tuned separately,
optimising Bleu scores (Papineni et al., 2002)
against a lemmatised version of the tuning ref-
erence. In the compound processing systems we
integrated the CRF-based prediction and merg-
ing procedure into each tuning iteration and
scored each output against the same unsplit and
lemmatised reference as the other systems.
Testing After decoding, the underspecified
representation has to be retransformed into
fluent German text, i.e., compounds need to
be re-combined and all words have to be re-
inflected. The whole procedure can be divided
into the following steps:
1a) translation into lemmatised German
representation (RI, RIVe)
1b) translation into split and lemmatised
German (CoRi, CoRIVe)
2) compound merging (CoRI, CoRIVe):
3) nominal inflection prediction and gen-
eration of full forms using SMOR (all)
4) verbal re-inflection (RIVe, CoRIVe)
5) merging of portmanteaus (all)
3Note that we observed some data-related issues on the
Syntax-RORI experiments that we hope to resolve in the
near future.
74
Experiment mert.log Bleu ci Bleu cs Bleu ci Bleu csnews2012 news2013 news2013 news2014 news2014
raw 16.52 18.62 17.61 17.80 17.25
CimS-RI 18.51 19.23 18.38 18.33 17.75
CimS-CoRIP 18.36 19.13 18.25 18.51 17.87
CimS-RIVe 19.08 18.89 18.06 17.86 17.31
CimS-CoRIVe 18.69 18.60 17.77 17.38 16.78
CimS-Syntax-RORI 18.26 19.04 18.17 18.15 17.59
Table 2: Bleu scores for all CimS-submissions of the 2014 shared task. ci = case-insensitive, cs = case-
sensitive; P = primary submission.
After these post-processing steps, the text was
automatically recapitalised and detokenised, us-
ing the tools provided by the shared task, which
we trained on the whole German dataset. We cal-
culated Bleu (Papineni et al., 2002) scores using
the NIST script version 13a.
7 Results
We evaluated our systems with the 3,000 sen-
tences of last year?s newstest2013 and also the
2,737 sentences of the 2014 blind test set for the
German-English language pair. The Bleu scores
of our systems are given in Table 2, where raw
denotes our baseline system which we ran with-
out any pre- or postprocessing whatsoever. Note
that the big gap in mert.log scores between raw
and the CimS-systems comes from the fact that
raw is scored against the original (i.e. fully in-
flected) version of the tuning reference, while the
CimS-systems are scored against the stemmed
tuning reference.
As for the Bleu scores of the test sets, we ob-
serve similar improvements for the CimS-RI and
CimS-CoRI systems of +0.5/0.6 with respect to
the raw baseline as we did in previous experi-
ments (Cap et al., 2014)4. In contrast, our sys-
tems incorporating verbal prediction inflection
(CimS-RIVe/CoRIVe) cannot yet catch up with
the performance of the well-investigated nom-
inal inflection and compound processing sys-
tems (CimS-RI/CoRI). We attribute this partly to
the positive influence we assume fully inflected
verbs to have in nominal inflection prediction
models, but as the verb processing systems are
still under development, there might be other is-
sues we have not discovered yet. We plan to re-
4We will have a closer look at the data from a compound
processing view in Section 7.1 below.
visit these systems and improve them.
Finally, the syntax-based reordering system
yields scores that are competitive to those of
CimS-RI/CoRI. While Syntax-RORI so far only in-
corporates source-side reordering and nominal
re-inflection, we plan to investigate further ex-
tensions of this approach in the future.
7.1 Additional Evaluation
We manually screened the filtered 2014 test set
and identified 3,456 German compound tokens,
whereof 862 did not occur in the parallel training
data and thereof, 244 did not even occur in the
monolingual training data. For each of our sys-
tems, we calculated the number of compound
reference matches they produced. The results
are given in Table 3.
system ref new
raw 827 0
CimS-RI . 864 5
CimS-CoRIP 1,064 109
CimS-RIVe 853 5
CimS-CoRIVe 1,070 122
CimS-Syntax-RORI 900 20
Table 3: Numbers of compounds produced by
the systems that matched the reference (ref ) and
did not occur in the parallel training data (new).
The compound processing systems (with Co
in the name) generate many more correct com-
pounds than comparable systems without com-
pound handling. Compared to the raw base-
line, CoRI/CoRIVe did not only produce 237/243
more reference matches, but also 109/122 com-
pounds that matched the reference but did not
occur in the parallel training data. A lookup of
those 109/122 compounds in the monolingual
training data (consisting of roughly 1.5 billion
words) revealed, that 8/6 of them did not oc-
75
cur there either5. These were thus not accessi-
ble to a list-based compound merging approach
either. This result also shows that despite the
fact that CoRIVe does not yield a competitive
translation quality performance yet, the com-
pound processing component seems to bene-
fit from the verbal inflection and it is definitely
worth more investigation in the future.
Moreover, it can be seen from Table 3 that
the re-inflection systems (*RI*) produce more
reference matches than the raw baseline. In-
terestingly, they even produce some reference
matches that have not been seen in the par-
allel training data due to inflectional variation,
and in the case of the syntax-based system due
to a naive list-based compound merging: even
though it has not been trained on a split repre-
sentation of German text, it might occasionally
occur that two German nouns occur next to each
other in the MT output. If so, these two words are
merged into a compound, using a list-based ap-
proach, similar to Popovic? et al. (2006).
8 Reordering
For the system CimS-Syntax-RORI, English data
parsed with EGRET was reordered using scripts
written for parse trees produced by the con-
stituent parser (Charniak and Johnson, 2005),
using a model we trained on the standard Penn
Treebank sections. Unfortunately, the reorder-
ing scripts could not be straightforwardly ap-
plied to EGRET parses and require more signifi-
cant modifications than we first expected.
We thus decided to parse the Europarl data
(v7) with (Charniak and Johnson, 2005) instead
and run our reordering scripts on it (CimS-RO).
For evaluation purposes, we build a baseline sys-
tem raw? which has been trained only on Eu-
roparl. Tuning and testing setup is the same as
for the systems described in Section 6 with the
difference that the weights have been tuned on
newstest2013. The evaluation results are shown
in Table 4. Similarly to previous results reported
in (Gojun and Fraser, 2012), the CimS-RO system
shows an improvement of 0.5 Bleu points when
compared to the raw? baseline .
5Namely: Testflugzeugen (test airplanes), Medientri-
bunal (media tribunal), RBS-Mitarbeiter (RBS worker),
Schulmauersanierung (school wall renovation), Anti-
Terror-Organisationen (anti-terror organisations), and
Tabakimpfstoffe (tobacco-plant-created vaccines) in both
and in CoRI also Hand-gep?ckgeb?hr (hand luggage fee)
and Haftungsstreitigkeiten (liability litigation).
Experiment mert.log Bleu ci Bleu csnews2013 news2014 news2014
raw? 16.87 16.25 15.31
CimS-RO 17.76 16.81 15.81
Table 4: Evaluation of the reordering system
trained on Europarl v7.
9 Summary
We presented the CimS systems, a set of
morphology-aware translation systems cus-
tomised for translation from English to German.
Each system operates on a different level of
morphological description, be it nominal inflec-
tion, verbal inflection, compound processing
or source-side reordering. Some of the systems
are well-established (RI, CoRI and RO), others
are still under developement (RIVe, CoRIVe and
Syntax-RORI). However, all of them, with the ex-
ception of CoRIVe, lead to improved translation
quality when evaluated against a contrastive
baseline without linguistic processing. In an
additional evaluation, we could show that the
compound processing systems are able to create
a considerable number of compounds unseen
in the parallel training data.
In the future, we will investigate further com-
binations and extensions of our morphological
components, including reordering, compound
processing and verbal inflection. There are still
many many interesting challenges to be solved
in all of these areas, and this is especially true for
verbal inflection.
Acknowledgments
This work was supported by Deutsche For-
schungsgemeinschaft grants Models of Mor-
phosyntax for Statistical Machine Translation
(Phase 2) and Distributional Approaches to Se-
mantic Relatedness. We would like to thank
Daniel Quernheim for sharing the workload of
preprocessing the data with us.
Moreover, we thank Edgar Hoch from the IMS
system administration for generously providing
us with disk space and all our colleagues at IMS,
especially Fabienne Braune, Junfei Guo, Nina
Seemann and Jason Utt for postponing their ex-
periments to let us use most of IMS? computing
facilities for a whole week. Thank you each beau-
coup!
76
References
Fabienne Cap, Alexander Fraser, Marion Weller, and
Aoife Cahill. 2014. How to Produce Unseen
Teddy Bears: Improved Morphological Processing
of Compounds in SMT. In Proceedings of EACL
2014.
Eugene Charniak and Mark Johnson. 2005. Coarse-
to-fine n-best parsing and MaxEnt discriminative
reranking. In Proceedings of the 43rd Annual Meet-
ing on Association for Computational Linguistics
(ACL), Ann Arbor, Michigan.
Colin Cherry and George Foster. 2012. Batch Tun-
ing Strategies for Statistical Machine Translation.
In Proceedings of HLT-NAACL 2012.
Michael Collins, Philipp Koehn, and Ivona Kuc?erov?.
2005. Clause restructuring for statistical machine
translation. In Proceedings ACL 2005.
Chris Dyer. 2009. Using a maximum entropy model
to build segmentation lattices for MT. In Proceed-
ings of HLT-NAACL 2009.
Alexander Fraser, Marion Weller, Aoife Cahill, and Fa-
bienne Cap. 2012. Modeling Inflection and Word
Formation in SMT. In Proceedings of EACL 2012.
Alexander Fraser. 2009. Experiments in Morphosyn-
tactic Processing for Translation to and from Ger-
man. In Proceedings of WMT 2009.
Fabienne Fritzinger and Alexander Fraser. 2010.
How to Avoid Burning Ducks: Combining Lin-
guistic Analysis and Corpus Statistics for Ger-
man Compound Processing. In Proceedings of
WMT@ACL2010.
Michel Galley, Mark Hopkins, Kevin Knight, and
Daniel Marcu. 2004. What?s in a Translation Rule?
In Proceedings of HLT-NAACL 2004.
Qin Gao and Stephan Vogel. 2008. Parallel imple-
mentations of word alignment tool. In ACL 2008:
Proceedings of the Workshop on Software Engineer-
ing, Testing, and Quality Assurance for Natural
Language Processing.
Adri? De Gispert and Jos? B. Mari?o. 2008. On the
impact of morphology in English to Spanish statis-
tical MT. Speech Communication.
Anita Gojun and Alexander Fraser. 2012. Determin-
ing the placement of German verbs in English-to-
German SMT. In Proceedings of EACL 2012.
Kenneth Heafield. 2011. KenLM: Faster and Smaller
Language Model Queries. In Proceedings of WMT
2011.
Minwoo Jeong, Kristina Toutanova, Hisami Suzuki,
and Chris Quirk. 2010. A discriminative lexicon
model for complex morphology. In Proceedings of
AMTA 2010.
Philipp Koehn and Kevin Knight. 2003. Empirical
Methods for Compound Splitting. In Proceedings
of EACL 2003.
Philipp Koehn, Hieu Hoang, Alexandra Birch,
Chris Callison-Burch, Marcello Federico, Nicola
Bertoldi, Brooke Cowan, Wade Shen, Christine
Moran, Richard Zens, Chris Dyer, Ondrej Bojar,
Alexandra Constantin, and Evan Herbst. 2007.
Moses: Open Source Toolkit for Statistical Ma-
chine Translation. In Proceedings of ACL 2007
(Demo Session).
John Lafferty, Andrew McCallum, and Fernando
Pereira. 2001. Conditional Random Fields: Prob-
abilistic Models for Segmenting and Labeling Se-
quence Data. In ICML?01.
Klaus Macherey, Andrew M. Dai, David Talbot,
Ashok C. Popat, and Franz Och. 2011. Language-
independent Compound Splitting with Morpho-
logical Operations. In Proceedings of ACL 2011.
Franz Josef Och and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment
models. Computational Linguistics, 29(1):19?51,.
Kishore Papineni, Salim Roukos, Todd Ward, and
Wei-Jing Zhu. 2002. Bleu: A Method for Automatic
Evaluation of Machine Translation. In Proceedings
of ACL 2002.
Maja Popovic?, Daniel Stein, and Hermann Ney. 2006.
Statistical Machine Translation of German Com-
pound Words. In Proceedings of FinTAL 2006.
Helmut Schmid and Florian Laws. 2008. Estimation
of conditional probabilities with decision trees and
an application to fine-grained pos tagging. In Pro-
ceedings of COLING 2008.
Helmut Schmid, Arne Fitschen, and Ulrich Heid.
2004. SMOR: A German Computational Morphol-
ogy Covering Derivation, Composition and Inflec-
tion. In Proceedings of LREC 2004.
Helmut Schmid. 2004. Efficient Parsing of Highly
Ambiguous Context-Free Grammars with Bit Vec-
tors. In Proceedings of Coling 2004.
Andreas Stolcke. 2002. SRILM ? an Extensible Lan-
guage Modelling Toolkit. In Proceedings of ICSLN
2002.
Sara Stymne and Nicola Cancedda. 2011. Pro-
ductive Generation of Compound Words in Sta-
tistical Machine Translation. In Proceedings of
WMT@EMNLP?11.
Sara Stymne, Maria Holmqvist, and Lars Ahrenberg.
2008. Effects of Morphological Analysis in Transla-
tion between German and English. In Proceedings
of WMT 2008.
Sara Stymne. 2009. A Comparison of Merging Strate-
gies for Translation of German Compounds. In
Proceedings of EACL 2009 (Student Workshop).
77
Kristina Toutanova, Hisami Suzuki, and Achim
Ruopp. 2008. Applying Morphology Generation
Models to Machine Translation. In Proceedings of
HLT-ACL 2008.
Marion Weller, Alexander Fraser, and Sabine
Schulte im Walde. 2013. Using Subcatego-
rization Knowledge to Improve Case Prediction for
Translation to German. In Proceedings of ACL?13.
Philip Williams and Philipp Koehn. 2011. Agreement
constraints for statistical machine translation into
German. In Proceedings of WMT 2011.
Philip Williams and Phillipp Koehn. 2012. GHKM-
Rule Extraction and Scope-3 Parsing in Moses. In
Proceedings of WMT 2007.
78
Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 163?170,
Baltimore, Maryland USA, June 26?27, 2014.
c?2014 Association for Computational Linguistics
Large-scale Exact Decoding: The IMS-TTT submission to WMT14
?
Daniel Quernheim
IMS
University of Stuttgart
daniel@ims.uni-stuttgart.de
Fabienne Cap
CIS
Ludwig-Maximilian University of Munich
cap@cis.uni-muenchen.de
Abstract
We present the IMS-TTT submission to
WMT14, an experimental statistical tree-
to-tree machine translation system based
on the multi-bottom up tree transducer in-
cluding rule extraction, tuning and decod-
ing. Thanks to input parse forests and
a ?no pruning? strategy during decoding,
the obtained translations are competitive.
The drawbacks are a restricted coverage
of 70% on test data, in part due to ex-
act input parse tree matching, and a rela-
tively high runtime. Advantages include
easy redecoding with a different weight
vector, since the full translation forests can
be stored after the first decoding pass.
1 Introduction
In this contribution, we present an implementation
of a translation model that is based on `MBOT
(the multi bottom-up tree transducer of Arnold and
Dauchet (1982) and Lilin (1978)). Intuitively, an
MBOT is a synchronous tree sequence substitution
grammar (STSSG, Zhang et al. (2008a); Zhang et
al. (2008b); Sun et al. (2009)) that has discon-
tiguities only on the target side (Maletti, 2011).
From an algorithmic point of view, this makes the
MBOT more appealing than STSSG as demon-
strated by Maletti (2010). Formally, MBOT is
expressive enough to express all sensible trans-
lations (Maletti, 2012)
1
. Figure 2 displays sam-
ple rules of the MBOT variant, called `MBOT,
?
This work was supported by Deutsche Forschungsge-
meinschaft grants Models of Morphosyntax for Statistical
Machine Translation (Phase 2) and MA/4959/1?1.
1
A translation is sensible if it is of linear size increase
and can be computed by some (potentially copying) top-down
tree transducer.
that we use (in a graphical representation of the
trees and the alignment). Recently, a shallow ver-
sion of MBOT has been integrated into the popular
Moses toolkit (Braune et al., 2013). Our imple-
mentation is exact in the sense that it does abso-
lutely no pruning during decoding and thus pre-
serves all translation candidates, while having no
mechanism to handle unknown structures. (We
added dummy rules that leave unseen lexical ma-
terial untranslated.) The coverage is thus limited,
but still considerably high. Source-side and target-
side syntax restrict the search space so that decod-
ing stays tractable. Only the language model scor-
ing is implemented as a separate reranker
2
. This
has several advantages: (1) We can use input parse
forests (Liu et al., 2009). (2) Not only is the out-
put optimal with regard to the theoretical model,
also the space of translation candidates can be ef-
ficiently stored as a weighted regular tree gram-
mar. The best translations can then be extracted
using the k-best algorithm by Huang and Chiang
(2005). Rule weights can be changed without the
need for explicit redecoding, the parameters of the
log-linear model can be changed, and even new
features can be added. These properties are espe-
cially helpful in tuning, where only the k-best al-
gorithm has to be re-run in each iteration. A model
in similar spirit has been described by Huang et al.
(2006); however, it used target syntax only (using
a top-down tree-to-string transducer backwards),
and was restricted to sentences of length at most
25. We do not make such restrictions.
The theoretical aspects of `MBOT and their use
in our translation model are presented in Section 2.
Based on this, we implemented a machine transla-
tion system that we are going to make available to
2
Strictly speaking, this does introduce pruning into the
pipeline.
163
the public. Section 4 presents the most important
components of our `MBOT implementation, and
Section 5 presents our submission to the WMT14
shared translation task.
2 Theoretical Model
In this section, we present the theoretical genera-
tive model that is used in our approach to syntax-
based machine translation: the multi bottom-up
tree transducer (Maletti, 2011). We omit the tech-
nical details and give graphical examples only to
illustrate how the device works, but refer to the lit-
erature for the theoretical background. Roughly
speaking, a local multi bottom-up tree transducer
(`MBOT) has rules that replace one nonterminal
symbol N on the source side by a tree, and a se-
quence of nonterminal symbols on the target side
linked to N by one tree each. These trees again
have linked nonterminals, thus allowing further
rule applications.
Our `MBOT rules are obtained automatically
from data like that in Figure 1. Thus, we (word)
align the bilingual text and parse it in both the
source and the target language. In this manner we
obtain sentence pairs like the one shown in Fig-
ure 1. To these sentence pairs we apply the rule
extraction method of Maletti (2011). The rules
extracted from the sentence pair of Figure 1 are
shown in Figure 2. Note the discontiguous align-
ment of went to ist and gegangen, resulting in dis-
contiguous rules.
The application of those rules is illustrated in
Figure 3 (a pre-translation is a pair consisting of a
source tree and a sequence of target trees). While
it shows a synchronous derivation, our main use
case of `MBOT rules is forward application or in-
put restriction, that is the calculation of all target
trees that can be derived given a source tree. For
a given synchronous derivation d, the source tree
generated by d is s(d), and the target tree is t(d).
The yield of a tree is the string obtained by con-
catenating its leaves.
Apart from `MBOT application to input trees,
we can even apply `MBOT to parse forests and
even weighted regular tree grammars (RTGs)
(F?ul?op and Vogler, 2009). RTGs offer an ef-
ficient representation of weighted forests, which
are sets of trees such that each individual tree is
equipped with a weight. This representation is
even more efficient than packed forests (Mi et al.,
2008) and moreover can represent an infinite num-
ber of weighted trees. The most important prop-
erty that we utilize is that the output tree language
is regular, so we can represent it by an RTG (cf.
preservation of regularity (Maletti, 2011)). In-
deed, every input tree can only be transformed into
finitely many output trees by our model, so for a
given finite input forest (which the output of the
parser is) the computed output forest will also be
finite and thus regular.
3 Translation Model
Given a source language sentence e and corre-
sponding weighted parse forest F (e), our trans-
lation model aims to find the best corresponding
target language translation g?;
3
i.e.,
g? = argmax
g
p(g|e) .
We estimate the probability p(g|e) through a log-
linear combination of component models with pa-
rameters ?
m
scored on the derivations d such that
the source tree of d is in the parse forest of e and
the yield of the target tree reads g. With
D(e, g) = {d | s(d) ? F (e) and yield(t(d)) = g},
we thus have:
4
p(g|e) ?
?
d?D(e,g)
11
?
m=1
h
m
(d)
?
m
Our model uses the following features h
m
(?) for a
derivation:
(1) Translation weight normalized by source root
symbol
(2) Translation weight normalized by all root
symbols
(3) Translation weight normalized by leaves on
the source side
(4) Lexical translation weight source? target
(5) Lexical translation weight target? source
(6) Target side language model: p(g)
(7) Number of words in g
(8) Number of rules used in the derivation
(9) Number of gaps in the target side sequences
(10) Penalty for rules that have more lexical ma-
terial on the source side than on the target side
or vice versa (absolute value)
3
Our main translation direction is English to German.
4
While this is the clean theoretical formulation, we make
two approximations to D(e, g): (1) The parser we use returns
a pruned parse forest. (2) We only sum over derivations with
the same target sentence that actually appear in the k-best list.
164
SNP
NNP
Max
VP
VBD
went
NP
NN
home
S-TOP
PN-SB-Nom.Sg.Masc
NE-HD-Nom.Sg.Masc
Max
VAFIN-HD-Sg
ist
VP-OC/pp
PP-MO/V
APPR-AC
nach
ADJD-HD-Pos/N
hause
VVPP-HD
gegangen
Figure 1: Aligned parsed sentences.
NP
NNP
Max
?
(
PN-SB-Nom.Sg.Masc
NE-HD-Nom.Sg.Masc
Max
)
VBD
went
?
(
VAFIN-HD-Sg
ist
,
VVPP-HD
gegangen
)
NP
NN
home
?
(
PP-MO/V
APPR-AC
nach
ADJD-HD-Pos/N
hause
)
VP
VBD NP
?
(
VAFIN-HD-Sg
,
VP-OC/pp
PP-MO/V VVPP-HD
)
S
NP VP
?
(
S-TOP
PN-SB-Nom.Sg.Masc VAFIN-HD-Sg VP-OC/pp
)
Figure 2: Extracted rules.
(11) Input parse tree probability assigned to s(t)
by the parser of e
The rule weights required for (1) are relative
frequencies normalized over all extracted rules
with the same root symbol on the left-hand side. In
the same fashion the rule weights required for (2)
are relative frequencies normalized over all rules
with the same root symbols on both sides. The
lexical weights for (4) and (5) are obtained by mul-
tiplying the word translations w(g
i
|e
j
) [respec-
tively, w(e
j
|g
i
)] of lexically aligned words (g
i
, e
j
)
across (possibly discontiguous) target side se-
quences.
5
Whenever a source word e
j
is aligned
to multiple target words, we average over the word
translations:
6
h
4
(d)
=
?
lexical item
e occurs in s(d)
average {w(g|e) | g aligned to e}
4 Implementation
Our implementation is very close to the theoretical
model and consists of several independent compo-
5
The lexical alignments are different from the links used
to link nonterminals.
6
If the word e
j
has no alignment to a target word, then
it is assumed to be aligned to a special NULL word and this
alignment is scored.
nents, most of which are implemented in Python.
The system does not have any dependencies other
than the need for parsers for the source and tar-
get language, a word alignment tool and option-
ally an implementation of some tuning algorithm.
A schematic depiction of the training and decod-
ing pipeline can be seen in Figure 4.
Rule extraction From a parallel corpus of
which both halves have been parsed and word
aligned, multi bottom-up tree transducer rules are
extracted according to the procedure laid out in
(Maletti, 2011). In order to handle unknown
words, we add dummy identity translation rules
for lexical material that was not present in the
training data.
Translation model building Given a set of
rules, translation weights (see above) are com-
puted for each unique rule. The translation model
is then converted into a source, a weight and a tar-
get model. The source model (an RTG represented
in an efficient binary format) is used for decod-
ing and maps input trees to trees over rule iden-
tifiers representing derivations. The weight model
and the target model can be used to reconstruct the
weight and the target realization of a given deriva-
tion.
165
Composing 3 rules:
VP
VBD NP
?
(
VAFIN-HD-Sg
,
VP-OC/pp
PP-MO/V VVPP-HD
)
VBD
went
?
(
VAFIN-HD-Sg
ist
,
VVPP-HD
gegangen
)
NP
NN
home
?
(
PP-MO/V
APPR-AC
nach
ADJD-HD-Pos/N
hause
)
Obtained pre-translation:
VP
VBD
went
NP
NN
home
?
(
VAFIN-HD-Sg
ist
,
VP-OC/pp
PP-MO/V
APPR-AC
nach
ADJD-HD-Pos/N
hause
VVPP-HD
gegangen
)
Figure 3: Synchronous rule application.
Figure 4: Our machine translation system.
166
Decoder The decoder transforms a forest of in-
put sentence parse trees to a forest of transla-
tion derivations by means of forward application.
These derivations are trees over the set of rules
(represented by rule identifiers). One of the most
useful aspects of our model is the fact that decod-
ing is completely independent of the weights, as
no pruning is performed and all translation candi-
dates are preserved in the translation forest. Thus,
even after decoding, the weight model can be
changed, augmented by new features, etc.; even
the target model can be changed, e.g. to support
parse tree output instead of string output. In all
of our experiments, we used string output, but it is
conceivable to use other realizations. For instance,
a syntactic language model could be used for out-
put tree scoring. Also, recasing is extremely easy
when we have part-of-speech tags to base our de-
cision on (proper names are typically uppercase,
as are all nouns in German).
Another benefit of having a packed representa-
tion of all candidates is that we can easily check
whether the reference translation is included in the
candidate set (?force decoding?). The freedom to
allow arbitrary target models that rewrite deriva-
tions is related to current work on interpreted reg-
ular tree grammars (Koller and Kuhlmann, 2011),
where arbitrary algebras can be used to compute a
realization of the output tree.
k-best extractor From the translation derivation
RTGs, a k-best list of derivations can be extracted
(Huang and Chiang, 2005) very efficiently. This
is the only step that has to be repeated if the rule
weights or the parameters of the log-linear model
change. The derivations are then mapped to tar-
get language sentences (if several derivations re-
alize the same target sentence, their weights are
summed) and reranked according to a language
model (as was done in Huang et al. (2006)). This
is the only part of the pipeline where we deviate
from the theoretical log-linear model, and this is
where we might make search errors. In principle,
one could integrate the language model by inter-
section with the translation model (as the stateful
MBOT model is closed under intersection with fi-
nite automata), but this is (currently) not computa-
tionally feasible due to the size of models.
Tuning Minimum error rate training (Och,
2003) is implemented using Z-MERT
7
(Zaidan,
7
http://cs.jhu.edu/
?
ozaidan/zmert/
2009). A set of source sentences has to be (forest-
)parsed and decoded; the translation forests are
stored on disk. Then, in each iteration of Z-MERT,
it suffices to extract k-best lists from the transla-
tion forests according to the current weight vector.
5 WMT14 Experimental setup
We used the training data that was made avail-
able for the WMT14 shared translation task on
English?German
8
. It consists of three parallel cor-
pora (1.9M sentences of European parliament pro-
ceedings, 201K sentences of newswire text, and
2M sentences of web text) and additional mono-
lingual news data for language model training.
The English half of the parallel data was parsed
using Egret
9
which is a re-implementation of the
Berkeley parser (Petrov et al., 2006). For the Ger-
man parse, we used the BitPar parser (Schmid,
2004; Schmid, 2006). The BitPar German gram-
mar is highly detailed, which makes the syntac-
tic information contained in the parses extremely
useful. Part-of-speech tags and category label are
augmented by case, number and gender informa-
tion, as can be seen in the German parse tree in
Figure 1. We only kept the best parse for each
sentence during training. After parsing, we pre-
pared three versions of the German corpus: a)
RAW, with no morphological post-processing; b)
UNSPLIT, using SMOR, a rule-based morpho-
logical analyser (Schmid et al., 2004), to reduce
words to their base form; c) SPLIT, using SMOR
to reduce words to their base form and split com-
pound nouns. After translation, compounds were
merged again, and words were re-inflected. Pre-
vious experiments using SMOR to lemmatise and
split compounds in phrase-based SMT showed im-
proved translation performances, see (Cap et al.,
2014a) for details.
We then trained three 5-gram language models
on monolingual data using KenLM
10
(Heafield,
2011; Heafield et al., 2013 to appear) for the
three setups. For SPLIT and UNSPLIT, we were
only able to use the German side of the parallel
data, since parsing is a prerequisite for our mor-
phological post-processing and we did not have
the resources to parse more data. For RAW, we
additionally used the monolingual German data
8
http://www.statmt.org/wmt14/
translation-task.html
9
https://sites.google.com/site/
zhangh1982/egret
10
http://kheafield.com/code/kenlm/
167
system BLEU BLEU-cased TER
RAW 17.0 16.4 .770
UNSPLIT 16.4 15.8 .773
SPLIT 16.3 15.7 .773
Table 1: BLEU and TER scores of the submitted
systems.
that was distributed for the shared task. Word
alignment for all three setups was achieved using
GIZA++
11
. As usual, we discarded sentence pairs
where one sentence was significantly longer than
the other, as well as those that were too long or too
short.
For tuning, we chose the WMT12 test set (3,003
sentences of newswire text), available as part
of the development data for the WMT13 shared
translation task. Since our system had limited cov-
erage on this tuning set, we limited ourselves to
the first a subset of sentences we could translate.
When translating the test set, our models used
parse trees delivered by the Egret parser. After
translation, recasing was done by examining the
output syntax tree, using a simple heuristics look-
ing for nouns and sentence boundaries. Since cov-
erage on the test set was also limited, we used the
systems as described in (Cap et al., 2014b)
12
as a
fallback to translate sentences that our system was
not able to translate.
6 Results
We report the overall translation quality, as listed
on http://matrix.statmt.org/, mea-
sured using BLEU (Papineni et al., 2002) and
TER (Snover et al., 2006), in Table 1.
We assume that the poor performance of UN-
SPLIT and SPLIT compared to RAW is due to the
fact that we use a significantly smaller language
model (as explained above) for these two settings.
A detailed analysis will follow after the end of the
manual evaluation period.
7 Conclusion and further work
We presented our submission to the WMT14
shared translation task based on a novel, promising
?full syntax, no pruning? tree-to-tree approach to
statistical machine translation, inspired by Huang
11
https://code.google.com/p/giza-pp/
12
We use raw as described in (Cap et al., 2014b) as a fall-
back for RAW, RI for UNSPLIT and CoRI for SPLIT.
et al. (2006). There are, however, still major draw-
backs and open problems associated with our ap-
proach. Firstly, the coverage can still be signifi-
cantly improved. In these experiments, our model
was able to translate only 70% of the test sen-
tences. To some extent, this number can be im-
proved by providing more training data. Also,
more rules can be extracted if we not only use the
best parse for rule extraction, but multiple parse
trees, or even switch to forest-based rule extrac-
tion (Mi and Huang, 2008). Finally, the size of the
input parse forest plays a role. For instance, if we
only supply the best parse to our model, transla-
tion will fail for approximately half of the input.
However, there are inherent coverage limits.
Since our model is extremely strict, it will never
be able to translate sentences whose parse trees
contain structures it has never seen before, since
it has to match at least one input parse tree ex-
actly. While we implemented a simple solution to
handle unknown words, the issue with unknown
structures is not so easy to solve without breaking
the otherwise theoretically sound approach. Pos-
sibly, glue rules can help.
The second drawback is runtime. We were
able to translate about 15 sentences per hour on
one processor. Distributing the translation task
on different machines, we were able to translate
the WMT14 test set (10k sentences) in roughly
four days. Given that the trend goes towards par-
allel programming, and considering the fact that
our decoder is written in the rather slow language
Python, we are confident that this is not a major
problem. We were able to run the whole pipeline
of training, tuning and evaluation on the WMT14
shared task data in less than one week. We are cur-
rently investigating whether A* k-best algorithms
(Pauls and Klein, 2009; Pauls et al., 2010) can help
to guide the translation process while maintaining
optimality.
Thirdly, currently the language model is not in-
tegrated, but implemented as a separate rerank-
ing component. We are aware that this might in-
troduce search errors, and that an integrated lan-
guage model might improve translation quality
(see e.g. Chiang (2007) where 3?4 BLEU points
are gained by LM integration). Some research on
this topic already exists, e.g. (Rush and Collins,
2011) who use dual decomposition, and (Aziz et
al., 2013) who replace intersection with an upper
bound which is easier to compute.
168
References
Andr?e Arnold and Max Dauchet. 1982. Morphismes
et bimorphismes d?arbres. Theoret. Comput. Sci.,
20(1):33?93.
Wilker Aziz, Marc Dymetman, and Sriram Venkatap-
athy. 2013. Investigations in exact inference for
hierarchical translation. In Proc. 8th WMT, pages
472?483.
Fabienne Braune, Nina Seemann, Daniel Quernheim,
and Andreas Maletti. 2013. Shallow local multi-
bottom-up tree transducers in statistical machine
translation. In Proc. 51th ACL, pages 811?821.
Fabienne Cap, Alexander Fraser, Marion Weller, and
Aoife Cahill. 2014a. How to Produce Unseen
Teddy Bears: Improved Morphological Processing
of Compounds in SMT. In Proc. 14th EACL.
Fabienne Cap, Marion Weller, Anita Ramm, and
Alexander Fraser. 2014b. CimS ? The CIS and IMS
joint submission to WMT 2014 translating from En-
glish into German. In Proc. 9th WMT.
David Chiang. 2007. Hierarchical phrase-based trans-
lation. Computat. Linguist., 33(2):201?228.
Zolt?an F?ul?op and Heiko Vogler. 2009. Weighted tree
automata and tree transducers. In Manfred Droste,
Werner Kuich, and Heiko Vogler, editors, Hand-
book of Weighted Automata, EATCS Monographs
on Theoret. Comput. Sci., chapter 9, pages 313?403.
Springer.
Kenneth Heafield, Ivan Pouzyrevsky, Jonathan H.
Clark, and Philipp Koehn. 2013 (to appear). Scal-
able modified Kneser-Ney language model estima-
tion. In Proc. 51st ACL.
Kenneth Heafield. 2011. KenLM: faster and smaller
language model queries. In Proc. 6th WMT, pages
187?197.
Liang Huang and David Chiang. 2005. Better k-best
parsing. In Proc. IWPT, pages 53?64.
Liang Huang, Kevin Knight, and Aravind Joshi. 2006.
Statistical syntax-directed translation with extended
domain of locality. In Proc. 7th Conf. AMTA, pages
66?73.
Alexander Koller and Marco Kuhlmann. 2011. A gen-
eralized view on parsing and translation. In Proc.
IWPT, pages 2?13.
Eric Lilin. 1978. Une g?en?eralisation des transducteurs
d??etats finis d?arbres: les S-transducteurs. Th
`ese
3`eme cycle, Universit?e de Lille.
Yang Liu, Yajuan L?u, and Qun Liu. 2009. Improving
tree-to-tree translation with packed forests. In Proc.
47th ACL, pages 558?566.
Andreas Maletti. 2010. Why synchronous tree sub-
stitution grammars? In Proc. HLT-NAACL, pages
876?884.
Andreas Maletti. 2011. How to train your multi
bottom-up tree transducer. In Proc. 49th ACL, pages
825?834.
Andreas Maletti. 2012. Every sensible extended top-
down tree transducer is a multi bottom-up tree trans-
ducer. In Proc. HLT-NAACL, pages 263?273.
Haitao Mi and Liang Huang. 2008. Forest-based trans-
lation rule extraction. In Proc. EMNLP, pages 206?
214.
Haitao Mi, Liang Huang, and Qun Liu. 2008. Forest-
based translation. In Proc. 46th ACL, pages 192?
199. ACL.
Franz Josef Och. 2003. Minimum error rate training
in statistical machine translation. In Proc. 41st ACL,
pages 160?167.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei
jing Zhu. 2002. BLEU: a method for automatic
evaluation of machine translation. In Proc. 40th
ACL, pages 311?318.
Adam Pauls and Dan Klein. 2009. K-best A* parsing.
In Proc. 47th ACL, pages 958?966.
Adam Pauls, Dan Klein, and Chris Quirk. 2010. Top-
down k-best A* parsing. In Proc. 48th ACL, pages
200?204.
Slav Petrov, Leon Barrett, Romain Thibaux, and Dan
Klein. 2006. Learning accurate, compact, and in-
terpretable tree annotation. In Proc. COLING-ACL,
pages 433?440.
Alexander M. Rush and Michael Collins. 2011. Ex-
act decoding of syntactic translation models through
lagrangian relaxation. In Proc. 49th ACL, pages 72?
82.
Helmut Schmid, Arne Fitschen, and Ulrich Heid.
2004. SMOR: A German Computational Morphol-
ogy Covering Derivation, Composition and Inflec-
tion. In Proc. 4th LREC.
Helmut Schmid. 2004. Efficient parsing of highly am-
biguous context-free grammars with bit vectors. In
Proc. 20th COLING, pages 162?168.
Helmut Schmid. 2006. Trace prediction and recov-
ery with unlexicalized PCFGs and slash features. In
Proc. 44th ACL.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciulla, and John Makhoul. 2006. A study of
translation edit rate with targeted human annotation.
In Proc. AMTA.
Jun Sun, Min Zhang, and Chew Lim Tan. 2009. A non-
contiguous tree sequence alignment-based model for
statistical machine translation. In Proc. 47th ACL,
pages 914?922.
169
Omar F. Zaidan. 2009. Z-MERT: A fully configurable
open source tool for minimum error rate training of
machine translation systems. The Prague Bulletin of
Mathematical Linguistics, 91:79?88.
Min Zhang, Hongfei Jiang, Aiti Aw, Haizhou Li,
Chew Lim Tan, and Sheng Li. 2008a. A tree
sequence alignment-based tree-to-tree translation
model. In Proc. 46th ACL, pages 559?567.
Min Zhang, Hongfei Jiang, Haizhou Li, Aiti Aw, and
Sheng Li. 2008b. Grammar comparison study
for translational equivalence modeling and statistical
machine translation. In Proc. 22nd COLING, pages
1097?1104.
170
Proceedings of the First Workshop on Computational Approaches to Compound Analysis, pages 81?90,
Dublin, Ireland, August 24 2014.
Distinguishing Degrees of Compositionality in Compound Splitting
for Statistical Machine Translation
Marion Weller
1,2
, Fabienne Cap
2
, Stefan M?uller
1
Sabine Schulte im Walde
1
, Alexander Fraser
2
1
IMS, University of Stuttgart
{wellermn;muellesn;schulte}@ims.uni-stuttgart.de
2
CIS, Ludwig-Maximilian University of Munich
{cap;fraser}@cis.uni-muenchen.de
Abstract
The paper presents an approach to morphological compound splitting that takes the degree of
compositionality into account. We apply our approach to German noun compounds and particle
verbs within a German?English SMT system, and study the effect of only splitting compositional
compounds as opposed to an aggressive splitting. A qualitative study explores the translational
behaviour of non-compositional compounds.
1 Introduction
In German, as in many other languages, two (or more) simplex words can be combined to form a com-
pound. This is a productive process, leading to a potentially infinite number of sound German com-
pounds. As a consequence, many NLP applications suffer from coverage issues for compounds which
do not appear or appear only infrequently in language resources. However, while many compounds are
not covered, their component words are often found in lexical resources or training data. Compound
processing allows access to these component words and thus can overcome these sparsity issues.
We use Statistical Machine Translation (SMT) as an example application for compound processing.
Our SMT system translates from German to English, where compounds are usually split in the German
source language prior to training and decoding. The benefits are obvious: vocabulary size is reduced
and the languages are adjusted in terms of granularity, as exemplified by the compound Holzzaun. This
fencewoodenHolzzaun HolzZaun woodenfence
1:1 alignment1:n alignment
results in better alignment quality and model estimation.
Compound splitting also enables the translation of com-
pounds not occurring in the parallel data, if the parts have
been seen and can thus be translated individually. However, these assumptions only hold for compo-
sitional compounds like Holzzaun (?wooden fence?), whose meanings can be derived from the mean-
ings of their constituents, namely Holz (?wood?) and Zaun (?fence?). In contrast, the splitting of non-
compositional compounds may lead to translation errors: e.g. the meaning of J?agerzaun (?lattice fence?)
cannot be represented by the meanings of its constituents J?ager (?hunter?) and Zaun (?fence?). Here, an
erroneous splitting of the compound can lead to wrong generalizations or translation pairs, such as J?ager
? lattice, in the absence of other evidence about how to translate J?ager. When splitting compounds
for SMT, two important factors should thus be considered: (1) whether a compound is compositional
and should be split, and if so (2) how the compound should be split. Most previous approaches mainly
focused on the second task, how to split a compound, e.g. using frequency statistics (Koehn and Knight,
2003) or a rule-based morphology (Fritzinger and Fraser, 2010), and all of them showed improved SMT
quality for compound splitting. The decision about whether the compound is compositional and should
be split at all has not received much attention in the past.
In this work, we examine the effect of only splitting compositional compounds, in contrast to splitting
all compounds. To this end, we combine (A) an approach relying on the distributional similarity be-
tween compounds and their constituents, to predict the degree of compositionality and thus to determine
whether to split the compound with (B) a combination of morphological and frequency-based features
This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer
are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/
81
to determine how to split a compound. We experiment with this novel semantically-informed compound
splitting on the source-side data of a German-English SMT system. As far as we know, we are the first
to study the impact of compositionality-aware compound splitting in SMT. We evaluate our systems on
a standard and on a specifically created test set, both for noun compounds and particle verbs. Our re-
sults show that phrase-based SMT is generally robust with regard to over-splitting non-compositional
compounds, with the exception of low-frequency words. This is in line with corresponding assumptions
from previous work. Furthermore, we present a small-scale study about the translational behaviour of
non-compositional compounds, which can surprisingly often be translated component-wise.
2 Related Work
We combine morphology-based compound splitting with distributional semantics to improve phrase-
based SMT. Here, we discuss relevant work of compound splitting in SMT and distributional semantics.
2.1 Compound Splitting in SMT
Compound splitting in SMT is a well-studied task. There is a wide range of previous work, including
purely string- and frequency-based approaches, but also linguistically-informed approaches. All lines
of research improved translation performance due to compound splitting. In Koehn and Knight (2003),
compounds are split through the identification of substrings from a corpus. The splitting is performed
without linguistic knowledge (except for the insertion of the filler letters ?(e)s?), which necessarily leads
to many erroneous splittings. Multiple possible splitting options are disambiguated using the frequencies
of the substrings. Starting from Koehn and Knight (2003), Stymne (2008) covers more morphological
transformations and imposes POS constraints on the subwords. Nie?en and Ney (2000) and Fritzinger
and Fraser (2010) perform compound splitting by relying on morphological analysers to identify suitable
split points. This has the advantage of returning only linguistically motivated splitting options, but the
analyses are often ambiguous and require disambiguation: Nie?en and Ney (2000) use a parser for
context-sensitive disambiguation, and Fritzinger and Fraser (2010) use corpus frequencies to find the best
split for each compound. Other approaches use a two-step word alignment process: first, word alignment
is performed on a split representation of the compounding language. Then, all former compound parts
for which there is no aligned counterpart in the non-compounding language are merged back to the
compound again. Finally, word alignment is re-run on this representation. See Koehn and Knight (2003)
for experiments on German, DeNeefe et al. (2008) for Arabic and Bai et al. (2008) for Chinese. This
blocks non-compositional compounds from being split if they are translated as one simplex English word
in the training data (e.g. Heckensch?utze, lit. ?hedge|shooter?; ?sniper?) and aligned correctly. However,
cases like J?agerzaun, ?lattice fence? are not covered.
In the present work, we identify compounds with a morphological analyser, disambiguated with corpus
frequencies. Moreover, we restrict splitting to compositional compounds using distributional semantics.
We are not aware of any previous work that takes semantics into account for compound splitting in SMT.
2.2 Distributional Semantics and Compounding
Distributional information has been a steadily increasing, integral part of lexical semantic research over
the past 20 years. Based on the distributional hypothesis (Firth, 1957; Harris, 1968) that ?you shall know
a word by the company it keeps?, distributional semantics exploits the co-occurrence of words in corpora
to explore the meanings and the similarities of the words, phrases, sentences, etc. of interest.
Among many other tasks, distributional semantic information has been utilised to determine the degree
of compositionality (or: semantic transparency) of various types of compounds, most notably regarding
noun compounds (e.g., Zinsmeister and Heid (2004), Reddy et al. (2011), Schulte im Walde et al. (2013),
Salehi et al. (2014)) and particle verbs (e.g., McCarthy et al. (2003), Bannard (2005), Cook and Stevenson
(2006), K?uhner and Schulte im Walde (2010), Bott and Schulte im Walde (2014), Salehi et al. (2014)).
Typically, these approaches rely on co-occurrence information from a corpus (either referring to bags-
of-words, or focusing on target-specific types of features), and compare the distributional features of
the compounds with those of the constituents, in order to predict the degree of compositionality of the
82
OutputInput
Preprocessing 
Step 1:   Identify Component Words Similarity ScoresStep 2:  Predict sitional CompoundsStep 3: Split Compo?
0.311
0.825
0.015
0.725
Holzzaun woodenfence
Holz
Zaun Zaun
Holz
J?gerzaun lattice fenceJ?gerZaun J?gerzaun
SMT
Figure 1: Semantically-informed compound processing in SMT.
compound. The underlying assumption is that a compound which is similar in meaning to a constituent
(as in Holzzaun?Zaun (?wooden fence???fence?) but not in L?owenzahn?Zahn (?lion|tooth (dandelion)??
?tooth?)) is also similar to the constituent with regard to co-occurrence information.
Most related to this work on noun compounds, Reddy et al. (2011) relied on window-based distribu-
tional models to predict the compositionality of English noun compounds, and Schulte im Walde et al.
(2013) compared window-based against syntax-based distributional models to predict the composition-
ality of German noun compounds. Zinsmeister and Heid (2004) used subcategorising verbs to predict
compound?head similarities of German noun compounds. Most recently, Salehi et al. (2014) extended
the previous approaches to take multi-lingual co-occurrence information into account, regarding English
and German noun compounds, and English particle verbs.
3 Methodology
We integrate our semantically-informed compound splitting as a pre-processing step to the German
source language of an SMT system. See Figure 1 for an illustration of our compound processing pipeline.
3.1 Target Compounds
German compounds are combinations of two (or more) simplex words. In some cases, a morphological
transformation is required: for example, when combining the two nouns Ausflug (?excursion?) and Ziel
(?destination?) ? Ausflugsziel (?excursion destination?), a filler letter (here: ?s?) needs to be inserted.
Other such transformations include more filler letters or the deletion/substitution of letters.
Noun compounds are formed of a head noun and a modifier, which can consist of nouns, verbs, adjec-
tives or proper nouns.
Particle verbs are productive compositions of a base verb and a prefix particle, whose part-of-speech
varies between open-class nouns, adjectives, and verbs, and closed-class prepositions and adverbs. In
comparison to noun compounds, the constituents of German particle verbs exhibit a much higher degree
of ambiguity: Verbs in general are more ambiguous than nouns, and the largest sub-class of particles
(those with a preposition particle) is highly ambiguous by itself (e.g. Lechler and Ro?deutscher (2009)
and Springorum (2011)). For example, in anknabbern (?to nibble partially?), the particle an expresses a
partitive meaning , whereas in ankleben (?to glue onto sth.?) an has a topological meaning (to glue sth.
onto an implicit background). In addition, particle verb senses may be transparent or opaque with respect
to their base verbs. For example, abholen ?fetch? is rather transparent with respect to its base verb holen
?fetch?, whereas anfangen ?begin? is more opaque with respect to fangen ?catch?. In contrast, einsetzen
has both transparent (e.g. ?insert?) and opaque (e.g. ?begin?) verb senses with respect to setzen ?put/sit
(down)?. The high degree of ambiguity makes particle verbs a challenge for NLP. Moreover, particle
and base verb can occur separately (er f?angt an: ?he begins?) or in one word (dass er anf?angt: ?that he
begins?), depending on the clausal type. This makes consistent treatment of particle verbs difficult.
3.2 Identification of Component Parts
We use the rule-based morphological analyser SMOR (Schmid et al., 2004) to identify compounds and
their constituents in our parallel training data (cf. Section 4). It relies on a large lexicon of word lemmas
and feature rules for productive morphological processes in German, i.e., compounding, derivation and
83
inflection. In this paper, we will not consider splitting into derivational affixes (as needed for, e.g., Arabic
and Turkish), but instead identify simplex words that may also occur independently. Moreover, we only
keep noun compounds and particle verbs consisting of two constituents. The resulting set consists of
93,299 noun compound types and 3,689 particle verb types.
3.3 Predicting Compositionality based on Distributional Similarity
Starting from this set of compounds as derived from our parallel training data, we collected distributional
co-occurrence information from two large German web corpora and the machine translation training data:
(i) the German COW corpus (Sch?afer and Bildhauer (2012), ?9 billion words), (ii) the SdeWaC (Faa?
and Eckart (2013), ?880 million words), (iii) our MT parallel corpus (?40 million words) and (iv) MT
language model training data (?146 million words). We relied on earlier work and used the 20,000 most
frequent nouns from the SdeWaC as co-occurrence features, looking into a window of 20 words to the left
and to the right of our target compounds and their constituents. We thus obtained a co-occurrence matrix
of all compounds and their constituents with the 20,000 selected nouns. As co-occurrence strength (i.e.,
how strong is a co-occurrence between a target word and a co-occurring noun), we collected frequencies
and transformed them into local mutual information (LMI) values, cf. Evert (2005). Finally, we calcu-
lated the distributional similarity between the compounds and their constituents, relying on the standard
measure cosine. The cosine value is then used to predict the degree of compositionality between the
respective compound?constituent pairs. For example, the cosine value of the pair Baumschule?Baum
1
is
0.38, while the cosine value of the pair Baumschule?Schule is only 0.01.
3.4 Semantically-Informed Compound Splitting
In the two preceding sections, we described how we identified component words and calculated distribu-
tional compositionality scores for all of the compounds found in our training data. Here, we give details
on how we include the semantic information into the compound splitting process. Recall that we only
want to split compositional compounds and keep non-compositional compounds together.
The splitting decision (to split/not split a compound) is based on the compositionality score of the
compound that takes into account either one or both of the compound?constituent cosine values: if the
predicted degree of compositionality is high, the compound is split. We consider and combine four dif-
ferent criteria: i) only the compound?modifier similarity (mod); (ii) only the compound?head similarity
(head); a combination of the compound?modifier and the compound?head similarities, relying on (iii) the
geometric mean (geom) or (iv) on the arithmetic mean (arith). We used different thresholds for each of
these criteria throughout our experiments, with a specific focus on distinguishing the contributions of the
modifiers vs. the heads in the splitting decision, following insights from recent work in psycholinguistic
studies (Gagn?e and Spalding, 2009; Gagn?e and Spalding, 2011) as well as in computational approaches
on noun compounding (Reddy et al., 2011; Schulte im Walde et al., 2013). Furthermore, we compare
the effects of splitting with regard to two types of compounds, noun compounds and particle verbs: Both
types are very productive and can generate a potentially infinite number of new forms.
4 Experimental Setting
This section gives an overview on the technical details of the SMT system and our data sets. Compound
splitting is applied to all source-language data, i.e. the parallel data used to train the model, as well as
the input for parameter tuning and testing.
2
Translation Model Moses is a state-of-the-art toolkit for phrase-based SMT systems (Koehn et al.,
2007). We use it with default settings to train a translation model and we do so separately for each of the
different compound splittings. Word alignment is performed using GIZA++ (Och and Ney, 2003). Fea-
ture weights are tuned using Batch-Mira (Cherry and Foster, 2012) with ?-safe-hope? until convergence.
Training Data Our parallel training data contains the Europarl corpus (version 4, cf. Koehn (2005))
and also newspaper texts, overall ca. 1.5 million sentences
3
(roughly 44 million words). In addition, we
1
Baum|schule: ?tree|school? (tree nursery)
2
Compounds not contained in the parallel data are always split, as they cannot be translated otherwise.
3
Data from the shared task of the EACL 2009 workshop on statistical machine translation: www.statmt.org/wmt09
84
use an English corpus of roughly 227 million words (including the English part of the parallel data) to
build a target-side 5-gram language model with SRILM (Stolcke, 2002) in combination with KENLM
(Heafield, 2011). For parameter tuning, we use 1,025 sentences of news data.
Standard Test set 1,026 sentences of news data (test set from the 2009 WMT Shared Task): this set is
to measure the translation quality on a standard SMT test and make it comparable to other work.
Noun/Verb Test set As our main focus lies on sentences containing compounds, we created a second
test set which is rich in compounds. From the combined 2008-2013 Shared Task test sets, we extracted
all sentences containing at least one noun compound for which we have compound-constituent similarity
scores. Moreover, we excluded sentences containing nouns that are not in the parallel training data: such
compounds can only be translated when split which allows to translate their components. The final test
set consists of 2,574 sentences. Similarly, we also created a set rich in particle verbs (855 sentences).
Opaque Test set As the two first test sets mainly contain compositional compounds, we use a third test
set consisting of sentences with only non-compositional compounds. The underlying compounds were
chosen based on a list containing noun compounds and human ratings for compositionality (von der
Heide and Borgwaldt (2009)). As before, the compounds must have occurred in the parallel data. The
result is a list of 14 compounds, of which 11 have a low modifier-compound similarity and 3 have a low
head-compound similarity. We then extracted sentences containing these compounds (5 per compound =
70 in total) from German newspaper data
4
. In contrast to the other sets, we use this test set in a qualitative
study, to approximate the translation quality by counting the number of correctly translated compounds.
5 SMT Results
In this section, we present and discuss the results of our machine translation experiments. We first report
results for two test sets in terms of a standard evaluation metric (BLEU) and then continue with a small-
scale qualitative study on the translational behaviour of non-compositional compounds.
5.1 Compound Splitting within a Standard SMT Task
BLEU (Papineni et al., 2002) is a common metric to automatically measure the quality of SMT output
by comparing n-gram matches of the SMT output with a human reference translation. Table 1 lists the
results for our SMT-systems: we report on different compound-constituent scores and thresholds, for
noun compounds and particle verbs respectively. Note that BLEU scores are not comparable across dif-
nouns particle verbs
stand. noun stand. verb
baseline 21.00 21.08 21.00 20.29
a
g
g
r
DIST 22.00 22.02 21.02 20.11
FREQ 22.04 21.88 21.11 20.21
0
.
0
5
head 21.77 21.58 ? ?
mod. 22.01 21.74 ? ?
geom. 21.99 21.71 ? ?
arith. 21.95 21.95 ? ?
0
.
1
head 21.91 21.69 21.11 20.24
mod. 22.01 21.63 20.98 20.43
geom. 22.06 21.90 21.12 20.55
arith. 22.05 21.73 21.08 20.34
0
.
1
5
head 21.80 21.67 21.10 20.09
mod. 21.71 21.77 21.00 20.25
geom. 21.78 21.64 20.84 20.30
arith. 22.00 21.77 21.24 20.40
0
.
2
head 21.78 21.51 ? ?
mod. 21.78 21.45 ? ?
geom. 21.76 21.54 ? ?
arith. 22.02 21.79 ? ?
Table 1: BLEU scores for all compound-
constituent variations.
ferent test sets, but only illustrate system differences
within one test set. We compare our systems to the
scores of a baseline system (without compound process-
ing) and an aggressive split system in which all noun
compounds and particle verbs are split. The labels DIST
and FREQ indicate how several possible splittings were
disambiguated: DIST means we chose the splitting option
having the higher geometric mean of the two compound-
constituent scores, assuming that the variant expressing a
higher compositionality score leads to the more probable
splitting analysis. For FREQ, the decision is based on the
geometric mean of corpus frequencies of the respective
components of the compound, as is common practise for
the disambiguation of multiple splitting options in SMT
(Koehn and Knight, 2003; Fritzinger and Fraser, 2010).
In terms of BLEU, there is little difference for these two
variants. For further experiments, we thus decided to al-
ways use FREQ for disambiguation, assuming that com-
ponents chosen by frequency are potentially better repre-
4
www.ims.uni-stuttgart.de/forschung/ressourcen/korpora/hgc.html
85
rating compound gloss mod. head translation
HIGHLY Staats|bankrott nation|bankruptcy 0.4779 0.6527 national bankruptcy
COMP. Staats|gebilde nation|structure 0.6955 0.3431 national structure
MEDIUM Industrie|staat industry|nation 0.0258 0.1488 industrial nation
COMP. Staats|kasse nation|cash box 0.0718 0.2757 public purse, treasury
LOW Staats|spitze nation|top 0.0024 0.0040 top/head of state
COMP. Staats|monotheismus nation|monotheism 0.0071 0.0071 national monotheism
Table 2: Examples for different compound-constitutent score ranges: HIGH: highly compositional,
MEDIUM: cases of doubt, LOW: highly non-compositional, according to their scores.
sented in the training data. Thus, we first use frequencies to determine the best split option in the case
of several possibilities, and then we apply distributional semantics to determine whether to split at all.
The remainder of Table 1 reports on different variants of the semantically-informed splitting criteria we
used. The notation head/mod/geom/arith indicates which (combination of) compound-constituent scores
were applied as criterion, with the threshold indicated by the vertical number. We performed the first
set of experiments with different thresholds for noun compounds, and then applied the medium-range
thresholds to the particle verbs. Generally, there are no considerable differences between the systems
with semantically restricted splitting and the aggressive split systems, even though there seems to be a
slightly positive effect for particle verbs. Having a closer look, we find that for noun compounds on the
standard test set, the best results (threshold: 0.1) are at the same level as the aggressive split systems;
with some small losses in BLEU on some of the other settings.
5.2 Discussion
All settings clearly outperform the baseline system (without compound processing). This indicates that
phrase-based SMT is rather robust with regard to non-semantic splitting as it is can often recover from
over-splitting by translating the word sequence as a phrase. This is in line with previous observations
of Koehn and Knight (2003). The results for the noun test set, which is biased towards containing more
nominal compounds, even suggests that less splitting might harm the system, as the BLEU scores tend
to drop when increasing the threshold. For particle verbs,
5
the picture is slightly different: first, splitting
only particle verbs does not lead to a considerable improvement over the baseline, as in the case of noun
compounds. For the verb test set, it even leads to a drop in BLEU. However, a more restricted splitting
leads to improved BLEU scores, even though not significantly better than the un-split baseline system.
Even though the handling of particle verbs needs to be refined in terms of dealing with their structural
behaviour (split vs. unsplit depending on the sentence structure) or ambiguities of the particle verb,
we consider this an encouraging result indicating that particle verbs can benefit from a semantically-
informed splitting process.
There are several possible reasons why a more restricted splitting might not lead to an improvement,
even though the idea of splitting only compositional compounds is intuitive and straightforward.
Inconsistent Splitting Compositionality is a continuum rather than a binary decision, with the scores of
many (compositional) compounds being in the medium range. Thus, it happens that some compounds
containing a certain constituent are split, whereas others are not: such inconsistent splittings do not
contribute to the generalization compound splitting aims for. Table 2 gives examples for compounds
with different degrees of compositionality, which illustrate this issue: for Industriestaat (?industrial
nation?) and Staatskasse (?public purse?) in the middle part of the table, a splitting decision based on
the head scores for thresholds of 0.15 or 0.2 leads to inconsistent splitting. Only compounds with high
scores, as the examples at the top of Table 2 are always split. The bottom part gives examples with
comparatively low compound-constituent scores that would benefit from splitting, but which will not be
split in any of our systems.
5
Note that there are considerably less particle verbs than noun compounds in the standard test set and the parallel data.
86
compound gloss translation unsplit f split f
Seehunde sea|dogs seals seals 5 seals 5
Flohmarkt flea|market flea market flea market 5 flea market 5
Kopfsalat head|salad lettuce lettuce 5 lettuce 5
Handtuch hand|cloth towel towel 5 towel 5
Kronleuchter crown|candelabra chandelier chandelier 5 crown leuchter 5
G?urteltiere belt|animal armadillo armadillos 5 belt animals 5
Wasserhahn water|rooster tap
water tap 2
tap 5
water supply 3
Meerschweinchen
sea|piglet guinea pig
guinea pig 4
guinea pig 5
sea pig 1
Taschenbuch pocket|book paperback
paper back 3
paperback 5
pocket book 2
Kronkorken crown|cork crown cap *kronkorken 5 crown corks 5
Taschenlampe pocket|lamp flashlight
pocket lamp 4
*taschenlampe 5
bag lamp 1
Fleischwolf meat|wolf meat grinder *fleischwolf 5 meat wolf 5
Marienk?afer Mary|bug ladybug *marienk?afer 5 *marie k?afer 5
Blockfl?oten block|flute recorder
block might 4
*blockfl?oten 5
bloc might 1
Table 3: correct vs. wrong ? Translation of non-compositional compounds (opaque test set) without
being split (unsplit) vs. being split prior to translation. ?*? highlights untranslated compounds.
Coverage of Opaque Compounds Another relevant factor concerns the frequency ranges of compounds
that are most interesting for this approach. High/mid frequency compounds are usually well-covered by
the training data of an SMT system, and in most cases they are translated correctly even if they have
been split erroneously. This is due to the fact that split compounds can be learned and translated as a
phrase if there were enough instances for the system to learn a valid translation. In the case of low-
frequency compounds, the system is less likely to learn a correct translation from the parallel data.
However, low-frequency compounds are not well covered by the system and splitting should thus be
highly beneficial. Newly created, i.e. highly compositional compounds, tend to be of low frequency, as
is illustrated by the example of Staatsmonotheismus (freq=1 in the parallel data) in Table 2. However,
a wrong splitting decision for a non-compositional compound of low frequency is likely to lead to an
incorrect translation as the SMT system has better statistics for the individual parts than for the sequence
of the compounds constituents. We assume that for low-frequency compounds the distributional similar-
ity scores are generally less reliable, even though using LMI helps to minimize this. To a certain extent,
we expect non-compositional compounds ?which are typically considered as lexicalized? to occur with
higher frequencies than novel compositional compounds.
6
Furthermore, there are considerably more
compositional than non-compositional compounds in standard text. Thus, being in favor of splitting in
the case of low-frequency words should be reasonable in most contexts.
6 A Closer Look at Translating Opaque Compounds
In this section, we compare the translations of non-compositional compounds when they are unsplit
and when they are split. We use a small test set containing 70 sentences, 5 for each of the 14 non-
compositional compounds (see Section 4). Then we conduct a small-scale qualitative analysis focusing
on the correct translation of opaque compounds.
Table 3 reports on correct translations for the non-compositional compounds for an experiment where
they have been split or not split (unsplit) prior to translation. Even though all compounds occurred in
the parallel data, five (which are marked with ?*?) cannot be translated by the unsplit system due to not
being aligned correctly. The other compounds are translated correctly (marked with ?+? in Table 3).
In the course of our study, we found that many of the correct translations remain the same (seals, flea
market, lettuce, towel). In the case of guinea pig, paperback and tap there are mixed results of correct and
incorrect translations. Only in the cases of chandelier (?crown leuchter?) and armadillo (?belt animal?),
6
It has to be noted, though, that the model is influenced by the somewhat different domain of the parallel data (European
Parliament proceedings, a standard data set for SMT).
87
compound gloss translation compound gloss translation
B?arlauch bear|leek bear leek Handtasche hand|bag handbag
Baumschule tree|school tree nursery Hirschk?afer stag|beetle stag beetle
L?owenanteil lion|share lion?s share H?uttenk?ase cottage|cheese cottage cheese
Fliegenpilz fly|mushroom fly agaric Kronkorken crown|cork crown cap
Flohmarkt flea|market flea market Teelicht tea|light tea candle
Table 4: Examples for (near) literal translation of non-compositional compounds.
which were translated correctly with the unsplit system, all translations obtained with the split system are
wrong. Somewhat surprisingly, in some cases there even is a benefit from splitting the non-compositional
compounds: Kronkorken, previously not translated at all, is correctly generated as crown cork. For other
previously untranslated words, Fleischwolf and Taschenlampe, literal translations of the constituents
are given: while meat wolf (instead of meat grinder) is probably not understandable, the translation of
Taschenlampe as pocket lamp is certainly preferable to the untranslated compound.
Due to the observed unexpected translational behaviour of 2 of the 14 non-compositional compounds
(Flohmarkt and Kronkorken), which can be translated literally and thus ?in theory? benefit from splitting,
we present a small study illustrating that this phenomenon is not as rare as one would intuitively expect.
This study is not meant to be comprehensive, but rather to point out that the translational behaviour of
non-compositional compounds can correspond to that of compositional compounds; Table 4 lists a few
such examples. We assume that this behaviour is due to the fact that English and German are similar
languages with a similar background. Thus, the ?images? used in non-compositional words often tend to
be similar. For some of the compounds (e.g. Flohmarkt) this is even true for some Romance languages,
too (IT: mercato delle pulci, FR: march?e aux puces) .
Generally, the SMT system should even be able to handle cases where the translation of one part is
not strictly literal (e.g. cap?cork or agaric?mushroom). In comparison to a dictionary, which only lists
few translations, the translation model offers a large choice of translation options that are not always
strictly synonymous, but can cover a large range of related meanings. In combination with the target-
side language model, this could allow to ?guess? good translations of such compounds. However, the
component-wise translation of non-compositional compounds only works if the source- and target lan-
guage compounds contain the same number of constituents. For example, consider translating the word
Faultier (lazy|animal: ?sloth?): even if the SMT system offers the translation faul?sloth, it would also
need to produce a translation for the constituent tier, probably resulting in something like sloth animal.
In conclusion, while phrase-based SMT is often able to recover from over-splitting by translating
a word sequence as a phrase, this is not always necessary for opaque compounds as they can have a
literal or near-literal translation. Thus, for explicitly handling non-compositional compounds in SMT, a
monolingual estimation of compositionality is not the only relevant factor. The translational behaviour
of compounds should also be taken into account.
7 Conclusion and Future Work
We studied the impact of compositionality in German-English SMT by restricting compound splitting to
compositional compounds. The decision about compositionality is based on the distributional similarity
between a compound and its constituents. We experimented with different threshold/score combinations
on a standard and a specifically created test set. Our results indicate that phrase-based SMT is very robust
with regard to over-splitting non-compositional noun compounds, with the exception of low-frequency
compounds. Furthermore, we studied the translational behaviour of non-compositional compounds with
a special focus on the fact that non-compositional compounds can in some cases be translated component-
wise, leading to the conclusion that a monolingual estimation of compositionality is not sufficient for an
optimal explicit handling of compounds in SMT applications.
The relatively low impact of distinguishing the degree of compositionality might also be due to the fact
that the task of translating noun compounds can be considered ?easy?, as the split components always
occur adjacently. In contrast, handling other types of non-compositional structures (e.g. noun-verb or
preposition-noun-verb combinations which are non-compositional) is a challenging task for future work.
88
Acknowledgements
This work was funded by the DFG Research Projects ?Distributional Approaches to Semantic Related-
ness? (Marion Weller, Stefan M?uller) and ?Models of Morphosyntax for Statistical Machine Transla-
tion ? Phase 2? (Fabienne Cap, Alexander Fraser, Marion Weller) and the DFG Heisenberg Fellowship
SCHU-2580/1-1 (Sabine Schulte im Walde).
References
Ming-Hong Bai, Keh-Jiann Chen, and Jason S Chang. 2008. Improving word alignment by adjusting chinese word
segmentation. In IJCNLP?08: Proceedings of the 3rd International Joint Conference on Natural Language
Processing, pages 249?256.
Collin Bannard. 2005. Learning about the Meaning of Verb?Particle Constructions from Corpora. Computer
Speech and Language, 19:467?478.
Stefan Bott and Sabine Schulte im Walde. 2014. Optimizing a Distributional Semantic Model for the Prediction
of German Particle Verb Compositionality. In Proceedings of the 9th Conference on Language Resources and
Evaluation, Reykjavik, Iceland.
Colin Cherry and George Foster. 2012. Batch tuning strategies for statistical machine translation. In HLT-
NAACL?12: Proceedings of the Human Language Technology Conference of the North American Chapter of the
Association for Computational Linguistics, volume 12, pages 34?35.
Paul Cook and Suzanne Stevenson. 2006. Classifying Particle Semantics in English Verb-Particle Constructions.
In Proceedings of the ACL/COLING Workshop on Multiword Expressions: Identifying and Exploiting Underly-
ing Properties, pages 45?53, Sydney, Australia.
Steve DeNeefe, Ulf Hermjakob, and Kevin Knight. 2008. Overcoming vocabulary sparsity in mt using lattices.
In AMTA?08: Proceedings of the 8th Biennial Conference of the Association for Machine Translation in the
Americas.
Stefan Evert. 2005. The Statistics of Word Co-Occurrences: Word Pairs and Collocations. Ph.D. thesis, Institut
f?ur Maschinelle Sprachverarbeitung, Universit?at Stuttgart.
Gertrud Faa? and Kerstin Eckart. 2013. SdeWaC ? a Corpus of Parsable Sentences from the Web. In Proceedings
of the International Conference of the German Society for Computational Linguistics and Language Technology,
pages 61?68, Darmstadt, Germany.
John R. Firth. 1957. Papers in Linguistics 1934-51. Longmans, London, UK.
Fabienne Fritzinger and Alexander Fraser. 2010. How to Avoid Burning Ducks: Combining Linguistic Analysis
and Corpus Statistics for German Compound Processing. In Proceedings of the Fifth Workshop on Statistical
Machine Translation, pages 224?234. Association for Computational Linguistics.
Christina L. Gagn?e and Thomas L. Spalding. 2009. Constituent Integration during the Processing of Compound
Words: Does it involve the Use of Relational Structures? Journal of Memory and Language, 60:20?35.
Christina L. Gagn?e and Thomas L. Spalding. 2011. Inferential Processing and Meta-Knowledge as the Bases for
Property Inclusion in Combined Concepts. Journal of Memory and Language, 65:176?192.
Zellig Harris. 1968. Distributional Structure. In Jerold J. Katz, editor, The Philosophy of Linguistics, Oxford
Readings in Philosophy, pages 26?47. Oxford University Press.
Kenneth Heafield. 2011. Kenlm: faster and smaller language model queries. In EMNLP?11: Proceedings of the
6th workshop on statistical machine translation within the 8th Conference on Empirical Methods in Natural
Language Processing, pages 187?197.
Philipp Koehn and Kevin Knight. 2003. Empirical methods for compound splitting. In EACL ?03: Proceedings of
the 10th Conference of the European Chapter of the Association for Computational Linguistics, pages 187?193,
Morristown, NJ, USA. Association for Computational Linguistics.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke
Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan
Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In ACL?07: Proceedings of the
45th Annual Meeting of the Association for Computational Linguistics, Demonstration Session, pages 177?180.
89
Philipp Koehn. 2005. Europarl: a parallel corpus for statistical machine translation. In MT Summit?05: Proceed-
ings of the 10th machine translation summit, pages 79?86.
Natalie K?uhner and Sabine Schulte im Walde. 2010. Determining the Degree of Compositionality of German Par-
ticle Verbs by Clustering Approaches. In Proceedings of the 10th Conference on Natural Language Processing,
pages 47?56, Saarbr?ucken, Germany.
Andrea Lechler and Antje Ro?deutscher. 2009. German Particle Verbs with auf. Reconstructing their Composition
in a DRT-based Framework. Linguistische Berichte, 220.
Diana McCarthy, Bill Keller, and John Carroll. 2003. Detecting a Continuum of Compositionality in Phrasal
Verbs. In Proceedings of the ACL-SIGLEX Workshop on Multiword Expressions: Analysis, Acquisition and
Treatment, pages 73?80, Sapporo, Japan.
Sonja Nie?en and Hermann Ney. 2000. Improving SMT quality with morpho-syntactic analysis. In COLING?00:
Proceedings of the 18th International Conference on Computational Linguistics, pages 1081?1085. Morgan
Kaufmann.
Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models.
Computational Linguistics, 29(1):19?51,.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. Bleu: A method for automatic evaluation
of machine translation. In ACL?02: Proceedings of the 40th Annual Meeting of the Association for Computa-
tional Linguistics, pages 311?318.
Siva Reddy, Diana McCarthy, and Suresh Manandhar. 2011. An Empirical Study on Compositionality in Com-
pound Nouns. In Proceedings of the 5th International Joint Conference on Natural Language Processing, pages
210?218, Chiang Mai, Thailand.
Bahar Salehi, Paul Cook, and Timothy Baldwin. 2014. Using Distributional Similarity of Multi-Way Translations
to Predict Multiword Expression Compositionality. In Proceedings of EACL 2014.
Roland Sch?afer and Felix Bildhauer. 2012. Building Large Corpora from the Web Using a New Efficient Tool
Chain. In Proceedings of the 8th International Conference on Language Resources and Evaluation, pages
486?493, Istanbul, Turkey.
Helmut Schmid, Arne Fitschen, and Ulrich Heid. 2004. Smor: A German computational morphology covering
derivation, composition and inflection. In LREC ?04: Proceedings of the 4th Conference on Language Resources
and Evaluation, pages 1263?1266.
Sabine Schulte im Walde, Stefan M?uller, and Stephen Roller. 2013. Exploring Vector Space Models to Predict the
Compositionality of German Noun-Noun Compounds. In Proceedings of the 2nd Joint Conference on Lexical
and Computational Semantics, pages 255?265, Atlanta, GA.
Sylvia Springorum. 2011. DRT-based Analysis of the German Verb Particle ?an?. Leuvense Bijdragen, 97:80?
105.
Andreas Stolcke. 2002. SRILM ? an extensible language modelling toolkit. In ICSLN?02: Proceedings of the
international conference on spoken language processing, pages 901?904.
Sara Stymne. 2008. German compounds in factored statistical machine translation. In GoTAL ?08: Proceedings
of the 6th International Conference on Natural Language Processing, pages 464?475. Springer Verlag.
Claudia von der Heide and Susanne Borgwaldt. 2009. Assoziationen zu Unter, Basis und Oberbegriffen. In
Proceedings of the 9th Norddeutsches Linguistisches Kolloquium, pages 51?74.
Heike Zinsmeister and Ulrich Heid. 2004. Collocations of Complex Nouns: Evidence for Lexicalisation. In
Proceedings of Konvens, Vienna, Austria.
90
