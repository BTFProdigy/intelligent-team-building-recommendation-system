Proceedings of the NAACL HLT Workshop on Computational Approaches to Linguistic Creativity, pages 40?46,
Boulder, Colorado, June 2009. c?2009 Association for Computational Linguistics
Automatic?Generation?of?Tamil?Lyrics?for?Melodies
Ananth?Ramakrishnan?A Sankar?Kuppan Sobha?Lalitha?Devi
AU?KBC?Research?Centre
MIT?Campus,?Anna?University
Chennai,?India
AU?KBC?Research?Centre
MIT?Campus,?Anna?University
Chennai,?India
AU?KBC?Research?Centre?
MIT?Campus,?Anna?University
Chennai,?India
ananthrk@au?kbc.org sankar@au?kbc.org sobha@au?kbc.org
Abstract
This ?paper ?presents ?our ?on?going ?work ? to?
automatically ? generate ? lyrics ? for ? a ? given?
melody, ? for ? phonetic ? languages ? such ? as?
Tamil.?We?approach?the?task?of?identifying?
the?required?syllable?pattern?for?the?lyric?as?
a?sequence?labeling?problem?and?hence?use?
the?popular?CRF++?toolkit ? for? learning. ?A?
corpus?comprising?of?10?melodies?was?used?
to?train?the?system?to?understand?the?syllable?
patterns.?The?trained?model?is?then?used?to?
guess?the?syllabic?pattern?for?a?new?melody?
to?produce?an?optimal?sequence?of?syllables.?
This?sequence?is?presented?to?the?Sentence?
Generation?module?which?uses?the?Dijkstra's?
shortest ?path?algorithm?to?come?up?with?a?
meaningful ? phrase ? matching ? the ? syllabic?
pattern.
1 Introduction
In?an?attempt?to?define?poetry?(Manurung,?2004),?
provides?three?properties?for?a?natural?language?arti?
fact?to?be?considered?a?poetic?work,?viz.,?Meaning?
fulness?(M),?Grammaticality?(G)?and?Poeticness?(P).?
A?complete?poetry?generation?system?must?generate?
texts?that?adhere?to?all?the?three?properties.?In?this?
work,?our?attempt?would?be?to?generate?meaningful?
lyrics?that?match?the?melody?and?the?poetic?aspects?
of?the?lyric?will?be?tackled?in?future?works.?
According?to?on?line?resources?such?as ?How?to?
write ? lyrics? (Demeter, ? 2001), ? the ? generated ? lyric?
must?have?Rhythm,?Rhyme?and?Repetition.?
One?of?the?recent?attempts?for?automatically?gen?
erating ? lyrics ? for ? a ? given ? melody ? is ? the ? Tra?la?
Lyrics?system?(Oliveira?et?al.,?2007).?This?system?
uses?the ?ABC? notation?(Gonzato,?2003)?for?repre?
senting?melody?and?the?corresponding?suite?of?tools?
for?analyzing?the?melodies.?The?key?aspect?of?the?
system ? is ? its ? attempt ? to ? detect ? the ? strong ? beats?
present?in?the?given?melody?and?associating?words?
with?stressed?syllables? in? the?corresponding?posi?
tions.?It?also?evaluates?three?lyric?generation?strate?
gies ? (Oliveira ? et ? al., ? 2007) ? ? ? random?
words+rhymes, ? sentence ? templates+rhymes ? and?
grammar+rhymes.??Of?these?strategies,?the?sentence?
templates+rhymes?approach?attempts?for?syntactical?
coherence?and?the?grammar+rhymes?approach?uses?
a?grammar?to?derive?Portuguese?sentence?templates.?
From?the?demo?runs?presented,?we?see?that?the?sys?
tem?can?generate?grammatical?sentences?(when?us?
ing?an?appropriate?strategy).?However,?there?is?no?
attempt?to?bring?Meaningfulness?in?the?lyrics.
2 Lyric?Generation?for?Tamil
Tamil,?our?target?language?for?generating?lyrics,?is?a?
phonetic? language. ?There? is ? a ?one?to?one? relation?
between?the?grapheme?and?phoneme.?We?make?use?
of?this?property?in?coming?up?with?a?generic?repre?
sentation?for?all?words?in?the?language.?This?repre?
sentation,?based?on?the?phonemic?syllables,?consists?
40
of? the? following? three? labels: ?Kuril? (short ?vowel,?
represented?by?K), ?Nedil? (long?vowel,?represented?
by?N)?and?Mei?(consonants,?represented?by?M).??For?
example,?the?word?thA?ma?rai?(lotus)?will?be?repre?
sented ? as ? N?K?N? (long ? vowel ? followed ?by ? short?
vowel?followed?by?another?long?vowel).?This?repre?
sentation?scheme,?herein?after?referred?as?KNM?rep?
resentation,?is?used?throughout?our?system???train?
ing,?melody?analysis?and?as?input?to?the?sentence?
generation?module.
3 Approach
Our ? approach ? to ? generating ? lyrics ? for ? the ? given?
melody?is?a?two?step?process?(Figure?1).?The?first?
step?is?to?analyze?the?input?melody?and?output?a?se?
ries ? of ? syllable ? patterns ? in ?KNM? representation?
scheme ? along ? with ? tentative ? word ? and ? sentence?
boundary.?The?subsequent?step?involves?filling?the?
syllable ?pattern ?with ?words ? from? the ? corpus ? that?
match?the?given?syllable?pattern?and?any?rhyme?re?
quirements.?We?approach?the?first?aspect?as?a?Se?
quence ? Labeling ? problem ? and ? use ? the ? popular?
CRF++ ? toolkit ? (Kudo, ? 2005) ? to ? label ? the ? input?
melody?in ?ABC? notation ?(Gonzato,?2003)? with?ap?
propriate?syllable?categories?(Kuril,?Nedil?and?Mei).?
This?system?is?trained?with?sample?film?songs?and?
their?corresponding?lyrics?(in ?KNM? scheme)?as?in?
put.?The?trained?model?is?then?used?to?label?the?giv?
en?input?melody.?The?syllable?pattern,?thus?generat?
ed?for?the?input?melody,?is?provided?to?a?Sentence?
Generation?Module?that?finds?suitable?lyrics?satisfy?
ing ? the ? following ? constraints: ? a.) ? Words ? should?
match?the?syllable?pattern?b.)The?sequence?of?words?
should?have?a?meaning.?We?achieve?this?by?using?
the?popular?Dijkstra's?Shortest?Path?Algorithm?(Cor?
men?et?al.,?1990)?against?a?pre?built?corpus?of?Uni?
gram?and?Bigram?of?Words.
4 Melody?Analysis
The?goal?of?the?Melody?Analysis?is?to?analyze?the?
input?melody?and?suggest?a?possible?KNM?represen?
tation?scheme?that?will?match?the?melody.?Since?our?
representation?of?melody?is?based?on?the?ABC?Nota?
tion?(Gonzato,?2003),?which?is?textual,?we?approach?
this?problem?as?labeling?the?ABC?notation?using?the?
KNM?representation?scheme.
Figure?1.?System?Approach
4.1 Characteristics?of?Melody
Every?melody?follows?a?Meter,?which?provides?the?
basic?design?principles?in?music.?Some?of?the?most?
frequently?used?meters?we?encountered?in?the?film?
songs?that?we?used?are?2/4,?3/4,?4/4,?6/8,?9/8?and?
12/8???that?indicate?the?number?of?Notes?played?in?
41
the?given?interval.?Each?Note?is?represented?by?the?
character?set?A,?B,?C,?D,?E,?F?and?G???which?are?
called?as?main?notes?and?A#,?C#,?D#,?F#?and?G#???
which?are?called?Sharp?Notes.?Thus,?for?any?given?
Meter?in?the?melody,?we?can?find?the?sequence?of?
Notes?with?the?corresponding?duration?for?which?the?
Note?is?played?in?that?meter.
For?the?purpose?of?generating?lyrics,?we?need?to?
fit?one?syllable?for?each?of?the?notes?in?the?melody.
4.2 Conditional?Random?Fields
Conditional ?Random?Fields(CRF) ? (Lafferty?et ?al.,?
2001)?is?a?Machine?Learning?technique?that?has?per?
formed?well?for?sequence?labeling?problems?such?as?
POS?tagging,?Chunking?and?Named?Entity?Recogni?
tion. ? It ? overcomes ? the ? difficulties ? faced ? in ? other?
techniques?like?Hidden?Markov?Models(HMM)?and?
Maximum?Entropy?Markov?Model(MEMM).
(Lafferty ?et ? al., ?2001) ?define?Conditional ?Ran?
dom?Fields?as?follows:??Let?G?=?(V,?E)?be?a?graph?
such?that?Y?=?(Yv)?v???V,?so?that?Y?is?indexed?by?the?
vertices?of ?G.?Then?(X,Y)?is?a?conditional?random?
field?in?case,?when?conditioned?on ?X, ?the?random?
variables?Yv?obey?the?Markov?property?with?respect?
to ? the ? graph: ? p(Yv|X,Yw,w?v) ? = ?p(Yv|X,Yw,w~v),?
where?w~v?means?that?w?and?v?are?neighbors?in?G?.
Here?X?denotes?a?sentence?and?Y?denotes?the?label?se?
quence.?The?label?sequence?y?which?maximizes?the?like?
lihood?probability?p?(y|x)?will?be?considered?as?the?cor?
rect ? sequence, ?while ? testing ? for ?new?sentence ?x ?with?
CRF?model??.?The?likelihood?probability?p?(y|x)?is?ex?
pressed?as?follows.
where??k?and??k?are?parameters?from?CRF?model???
and?fk?and?gk?are?the?binary?feature?functions?that?we?
need?to?give?for? training? the ?CRF? model.?This? is?
where?we?integrate?the?specific?features?of?the?prob?
lem?into?the?machine?learning?models?like?CRF.?
4.3 Feature?Templates
There?are?three?models?that?need?to?be?learnt,?viz,?
labeling?notes?with?KNM?scheme,?identifying?word?
boundaries ? and ? identifying ? line ? boundaries. ? We?
present?below?the?features?used?to?learn?each?of?the?
above.
4.3.1 Learning?KNM?labels
In?addition?to?the?labels?K,?N?and?M,?there?are?also?
other?non?syllable?features?that?need?to?be?identified?
in?the?melody.?Thus,?the?complete?list?of?labels?in?
clude,?K,?N,?KM,?NM,?TIE,?OPEN,?CLOSE,?PRE?
and?BAR.?
K???short?vowel
N???long?vowel
KM???short?vowel?followed?by?consonant
NM???long?vowel?followed?by?consonants
TIE???presence?of?a?Tie?in?the?meter
OPEN???opening?of?a?tie
CLOSE???closing?of?a?tie
PRE???Note?that?follows?a?tie
BAR???End?of?meter.
The?following?are?the?list?of?features?considered:
? Current?Note
? Previous?Note?+?Current?Note?+?Next?Note
? Previous?to?previous?Note?+?Previous?Note?
+?Current?Note?+?Next?Note?+?Next?to?next?
Note
? Current?Note/Duration
? Previous ? Note/Duration ? + ? Current?
Note/Duration?+?Next?Note/Duration
? Previous?to?previous?Note/Duration?+?Pre?
vious?Note/Duration?+?Current?Note/Dura?
tion?+?Next?Note/Duration?+?Next?to?next?
Note/Duration.
42
4.3.2 Word?Boundary
Another?important?aspect?in?analyzing?the?melody?is?
to?spot?potential?word?boundaries.?While?in?many?
cases,?the?presence?of?bars?could?indicate?potential?
word?boundaries,?there?are?also?cases?where?a?given?
word?can?span?a?bar?(especially?due?to?the?presence?
of?Ties).??Hence,?we?need?to?explicitly?train?our?sys?
tem?to?identify?potential?word?boundaries.?The?fea?
tures?used?to?identify?the?boundaries?of?words?are?
mostly?the?same?as?for?learning?the?KNM?labels,?but?
with?the?addition?of?considering?two?more?previous?
notes?along?with?their?durations.?
4.3.3 Sentence?Boundary
As?with?Word?Boundary? ,we?cannot?assume?sen?
tence?boundaries?based?on?the?musical?notation?and?
hence?we?also?train?our?system?to?identify?potential?
sentence?boundaries.?Sentence?boundary?identifica?
tion?happens?after?the?word?boundaries?are?identi?
fied?and?hence?this?additional?feature?is?used?along?
with ? the ? above?mentioned ? features ? for ? sentence?
boundary?training.?
5 Sentence?Generation
The?goal?of?the?Sentence?Generation?module?is?to?
generate?a?meaningful?phrase?that?matches?the?input?
pattern?given?in ?KNM? scheme.?For?example,?given?
an? input ?pattern?such?as ?'KMKM? NKM? ?NKN', ? it?
should?generate?a?phrase?consisting?of?three?words?
each?of?them?matching?their?respective?pattern.
5.1 Corpus?selection?and?pre?processing
Since ? we ? are ? interested ? in ? generating ? lyrics ? for?
melody,? the?corpus?we?chose?consisted?mainly?of?
poems?and?short ? stories. ?The?only?pre?processing?
involved ? was ? to ? remove ? any ? special ? characters?
(such?as??(?),?$?%?&,?etc.)?from?the?text.?From?this?
corpus, ? we ? index ? all ? Unigram ? and ? Bigram ? of?
Words.?Each?word?is?marked?with?its?KNM?syllable?
pattern?and?their?frequency?of?occurrence?in?the?cor?
pus.?The?Bigram?list?contains?only?the?frequency?of?
occurrence.?
5.2 Graph?Construction
Given?an?input?pattern?(say ?'KMKM?NKM?NKN'),?
we?construct?a?directed?graph?with?the?list?of?words?
satisfying?each?pattern,?as?represented?by?Figure?2.
Figure?2.?Graph?Construction
The?edge?from?word?Wij?(of,?say?pattern?KMKM)?to?
Wrs ?(of,?say?pattern?NKM)?is?weighted?based?on?the?
frequency?values?collected?from?the?corpus?and?is?
calculated?as?follows:
????????????????????????#?(Wij?followed?by?Wrs)?
P(Wrs?/?Wij)?=???___________________????(Eqn.?1)
????????????????????????????????#?(Wij)
Since? the?Shortest?Path?Algorithm?picks? the?path?
with?the?least?cost,?we?need?to?weight?the?edges?in?
such?a?way?that?a?higher?probability?sequence?gets?
the?least?cost?(C).?Thus,?we?measure?Cost(Wrs/Wij)?
as:
Cost(Wrs/Wij)?=?1???P(Wrs/Wij) (from?Eqn.?1)????(Eqn.?2)
By?default,?the?cost?from?the?START?node?to?the?
first?list?of?words?and?the?cost?from?the?last?list?of?
words?to?END?node?is?fixed?as?1.
5.3 Preferential?selection?of?paths
One?of?the?shortcomings?of?using?the?Shortest?Path?
Algorithm?is?that,?for?the?given?input?pattern?and?the?
given?Corpus,? the?algorithm?will ?always?generate?
the?same?phrase?(with?the?least?cost).?In?addition?to?
43
this?problem,?when?the?melody?demands,?we?need?
to?generate?rhyming?words.?Lastly,?we?need?to?han?
dle?the?case?where?the?corpus?may?not?have?a?phrase?
that?matches?the?complete?pattern.?We?tackle?all?the?
above?issues?by?biasing?the?Shortest?Path?Algorithm?
by?changing?the?cost?of?the?edges.?
5.3.1 Bias?initial?word
In?order?to?generate?different?phrases?for?the?same?
pattern?(say?KMKM??NKM??NKN),?we?pick?a?random?
word?that?matches?the?initial?pattern?(KMKM)?and?
fix?the?cost?of?the?edge?from?START?to?the?random?
word?to?0.?As?the?default?cost?from?START?to?all?
leading?words?is?1,?this?biases?the?algorithm?to?find?
a?pattern?that?starts?with?the?random?word.?Howev?
er,?if?there?exists?a?phrase,?whose??overall?cost??is?
still ? less ? than ? the ? one ? starting ? with ? the ? random?
phrase,?the?algorithm?will?output?the?same?phrase.?
In?order?to?avoid?this,?we?provide?multiple?random?
words?and?pick?the?one?that?truly?generates?a?unique?
phrase.
5.3.2 Rhyming?Words
When?there?is?a?need?to?generate?phrases?that?rhyme?
with?any?previously?generated?phrases,?especially?in?
line?endings,?we?use?the?same?biasing?technique?to?
prefer?certain?words?over?others.?The?motivation?to?
concentrate?on?line?endings?is?based?on?our?assump?
tion?that?the?notes?in?melody?would?be?similar?for?
the ? rhyming ? words ? and ? thus ? our ? representation?
scheme?involving?Mei(M)?(consonants)?would?han?
dle ? the ? stressed? syllables. ?The ?path? finding?algo?
rithm,?can?take?as?input?a?word?and?a?position,?with?
which?the?new?phrase?should?rhyme?in?the?given?po?
sition.?In?this?case,?we?generate?all?the?words?that?
rhyme?with?the?given?word?by?using?the?Maximum?
substring ? matching ? technique. ? That ? is, ? the ? word?
with?the?maximum?substring?common?to?the?input?
word,?in?word?endings,?is?considered?as?a?rhyming?
word. ? For ? example, ? given ? an ? input ? word ? 'kOyil'?
(temple),?the?rhyming?words?would?be?'vAyil'?(gate)?
and? 'veyil' ? (sun). ?As?can?be?seen,?both? the?words?
have?the?suffix? 'yil' ?common?with?the?input?word.?
Thus,?as?earlier,?the?cost?of?the?edges?in?the?paths?
leading?to?such?rhyming?words?will?be?set?to?0,?thus?
biasing?the?algorithm?to?pick?these?paths.?One?an?
other?way?would?be?have?only?those?nodes?corre?
sponding? to ? the ? rhyming?words ? (discarding?other?
non?rhyming?words).?However,? in?the?case?where?
no?rhyming?words?are?present?in?the?corpus,?this?ap?
proach?can?lead?to?a?graph?with?an?incomplete?path.?
Hence?we?use? the ?approach?of ?biasing? the ?graph?
paths?that?can?pick?the?rhyming?words,? if?present?
and?provide?a?non?rhyming?word,?if?none?was?avail?
able.
5.3.3 Edit?Distance?Matching
There?can?also?be?cases?when?there?is?no?phrase?that?
exactly?matches? the?given?input?pattern?sequence,?
though?the?corpus?might?contain?individual?words?
matching?each?pattern?in?the?sequence.?In?this?case,?
we?relax?the?matches?using?the ?Edit?Distance?met?
ric.?Thus,?for?the?given?pattern ?NKN, ?we?also?list?
words?that?match ?NKK, ?KKN,?etc.?Since?the?input?
patterns ? are ? deemed? to ? fit ? the ? given ? melody, ? an?
Edit?Distance?Matching?can?turn?up?words?that?need?
not?match?the?given?melody?and?hence?should?be?
used?only?when?there?are?no?phrases?matching?the?
input?pattern.?Another?approach,?though?practically?
not?possible,?is?to?have?a??big?enough?corpus??that?
contains?at?least?one?phrase?matching?each?pattern.
6 Experiments
We ? conducted ? the ? experiments ? as ? two ? separate?
steps,?one?for?the ?CRF? engine?and?another?for?the?
Sentence?Generation?module.
For?the?CRF?engine,?we?collected?and?used?Tamil?
film ? songs' ? tune ? and ? lyrics, ? as ? they ? were ? easily?
available?from?the?web.?The?tunes?were?converted?
to?the?ABC?notation?and?their?lyrics?were?converted?
to?the?KNM?representation?scheme.?The?notes?from?
the?tune?and?the?syllables?in?the?corresponding?lyric?
44
(in ? their ? respective ? representation ? schemes) ? were?
manually ? mapped ? with ? each ? other. ? An ? example?
training? file ? for ? the ?CRF? engine? for ? learning? the?
KNM?representation?scheme?is?presented?below:
Note Duration Label
B ? K
C ? N
B ? K
A ? KM
G ? K
? 0 tie
[ 0 open
A ? pre
G ? K
] 0 close
B 4 K
Table?1.?KNM?scheme?learning???training?file
Similarly,?for?the?word?boundary?identification,?the?
same?input?is?used?but?with?the?labels?corresponding?
to?word?boundaries?such?as?W?B?(word?beginning),?
W?I?(word?intermediate),?etc.?(Table?2):
Note Duration Label
B ? W?B
C ? W?I
B ? W?I
A ? W?I
G ? W?B
? 0 Tie
[ 0 open
A ? pre
G ? W?I
] 0 close
B 4 W?I
Table?2.?Word?boundary?learning???training?file
For?sentence?boundary?identification,?the?output?
from?the?word?boundary?identification?is?used?and?
hence?it?is?run?after?the?word?boundary?identifica?
tion?is?complete.?Thus,?the?input?to?the?CRF?engine?
in?this?case?would?be?like?the?one?in?(Table?3),?with?
labels?corresponding?to?sentence?boundary?such?as?
S?B?(sentence?beginning)?and?S?I?(sentence?interme?
diate):
Note Duration Word?
Boundary
Sentence?
Boundary
B ? W?B S?B
c ? W?I S?I
B ? W?I S?I
A ? W?I S?I
G ? W?B S?I
? 0 Tie S?I
[ 0 Open S?I
A ? Pre S?I
G ? W?I S?I
] 0 close S?I
B 4 W?I S?B
Table?3.?Sentence?boundary?learning???training?file
For ? the ?Sentence?Generation ?module, ?we ?used?
short?stories,?poems?and?Tamil?lyrics?across?various?
themes?such?as?love,?appreciation?of?nature,?patrio?
tism,?etc.?From?this,?all?the?special?characters?were?
removed?and?the?list?of?Unigram?and?Bigram?Words?
were?collected?along?with?their?frequencies.
Based?on?the?limited?experiments?performed?on?
the?trained?CRF?model,?we?observe?that?the?feature?
set?presented?for?Syllable?identification?seem?to?per?
form? reasonably ? and ? identifies ? the ? syllables ?with?
70%?accuracy?for?manually?tagged?melodies.?How?
ever,?we?could?not?objectively?evaluate? the?Word?
and?Sentence?Boundary?identification?process?as?the?
resulting?boundaries?can?also?be?considered?as?valid?
boundaries. ? In ? general, ? the ? word ? and ? sentence?
boundaries?are?the?choice?of?the?lyricist?and?hence?
the?results?can?be?considered?as?another?valid?way?
to?generate?lyric.?Also,?we?feel?that?the?number?of?
training?samples?(10?melodies)?supplied?for?training?
45
the ?CRF?engine? is ?very? less ? for ? it ? to ? reasonably?
learn ? the ? nuances ? that ? are ? present ? in ? real?word?
lyrics.
Some?of?the?syllable?patterns?identified?from?the?
tune?and?the?corresponding?sentences?generated?are?
given?below:
Pattern:?'KK?KK?KKK
?????NKKM?KMKK'
Output:??????????
??????????????
Translation:?In?small?age
???????????I?recollected
As?the?syllable?patterns?get?longer,?we?had?to?re?
sort?to?using?Edit?Distance?in?order?to?find?matching?
sentences.?One?such?output?is?presented?below:
Pattern:??KMKMKM?KMKM?NKN
?????????????NKMKM?NMKKM?NKN?
Output:????????????????
?????????????????????
Translation:?We?can?see?here?in?Tamil
???????????????????Proclaiming?aloud
7 Limitations?and?Future?Work?
From?the?initial?set?of?experiments,?we?see?that?it?is?
possible?to?generate?a?syllable?pattern?that?closely?
matches?the?input?tune.?Currently,?we?do?not?consid?
er? ?the?identification?of?strong?beats?in?the?melody?
and?are?expecting?the?presence?of?Mei?(M)?to?take?
care?of?stressed?syllables.?We?also?expect?the?same?
strategy?to?work?for?other?South?Indian?languages?as?
well. ?The?current ?Lyric ?Generation?algorithm? ? is?
simplistic,?in?that?it?can?generate?short?meaningful?
phrases, ? but ? generating ? longer ? phrases ? require?
adding?constraints ? (such? as ?closest ?matching?pat?
terns)?that?defeats?the?purpose?of?matching?with?the?
tune. ?Also, ? the ? current ?method?generates ?phrases?
that?are?independent?of?the?previous?phrases.?This?
leads ? to ? lyrics ? that ? are ? meaningful ? in ? parts, ? but?
meaningless?on?the?whole.
Future?work?can?involve?introducing??semantic ?
similarity??across?phrases?in?a?lyric,?thereby?gener?
ating?lyrics?that?provide?a?coherent?meaning.?Also,?
experiments ? can ? be ? conducted ?with ?different ? do?
main?corpus?to?generate?lyrics?for?a?given?situation?
(such?as?Love,?Death,?Travel,?etc.)? ?Other?sentence?
generation?strategies,?such?as?an?Evolutionary?Algo?
rithm? (as?suggested?in?(Manurung,?2004))?can?also?
be?attempted.?Once?a?coherent?meaningful?lyric?is?
generated,?further?improvements?can?be?towards?in?
corporating?poetic?aspects?in?the?lyric.
References?
Demeter. ? 2001. ?How ? to ? write ? Lyrics ?
http://everything2.com/index.pl?node=How ? to ? write?
lyrics.?
Guido?Gonzato.?2003. ?The?ABCPlus?Project? http://abc?
plus.sourceforge.net.
Hanna?M.?Wallach.?2004. ?Conditional?Random?Fields:?
An ? Introduction. ? Technical ? Report ? MS?CIS?04?21.?
Department ?of ?Computer ?and? Information ?Science,?
University?of?Pennsylvania.
Hisar ? Maruli ? Manurung. ? 2004. ?An ? evolutionary? ap?
proach?to?poetry?generation.?Ph.D.?Thesis,?University?
of?Edinburg.
Hugo?R.?Goncalo?Oliveira,?F.?Amilcar?Cardoso,?and?F.?
Camara?Perreira.?2007. ?Tra?La?Lyrics:?An?approach?
to?generate?text?based?on?rhythm.?Proceedings?of?the?
Fourth ? International ? Joint ? Workshop ? on ? Computa?
tional?Creativity,?IJWCC'07,?London:47?54.
Hugo?R.?Goncalo?Oliveira,?F.?Amilcar?Cardoso,?and?F.?
Camara ?Perreira. ?2007. ?Exploring?difference?strate?
gies?for?the?automatic?generation?of?song?lyrics?with?
Tra?La?Lyrics.?Proceedings?of?the?Portuguese?Confer?
ence ? on ? Artificial ? Intelligence ? (EPIA ? 2007),?
Guimar?es,?Portugal:57?68
John ? Lafferty, ? Andrew ? McCallum, ? and ? Fernando?
Pereira. ? 2001. ?Conditional? Random? Fields: ? Proba?
bilistic?Models?for?Segmenting?and?Labeling?Sequence ?
data. ? ?Proceedings ? of ? the ? Eighteenth ? International?
Conference ? on ? Machine ? Learning ? (ICML ? 2001),?
Williams?College,?Willamstown,?MA,?USA:282?289
Taku ?Kudo. ?2005. ?CRF++:?Yet?Another ?CRF? toolkit.?
http://crfpp.sourceforge.net.
Thomas?H.?Cormen.,?Charles?E.?Leiserson.,?Ronald?L.?
Rivest. ? 1990. ?Introduction? to ? Algorithms. ? Prentice?
Hall:?527?531.
46
Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,
pages 1824?1833, Dublin, Ireland, August 23-29 2014.
A Generic Anaphora Resolution Engine for Indian Languages 
 
 
Sobha Lalitha Devi 
AU-KBC Research Centre 
MIT Campus of Anna 
University, Chennai, India 
sobha@au-kbc.org 
Vijay Sundar Ram 
AU-KBC Research Centre 
MIT Campus of Anna 
University, Chennai, India 
sundar@au-kbc.org 
Pattabhi RK Rao 
AU-KBC Research Centre 
MIT Campus of Anna 
University, Chennai, India 
pattabhi@au-kbc.org 
 
  
 
Abstract 
In this paper, we present a generic anaphora engine for Indian languages, which are mostly resource -
poor languages.  We have analysed the similarit ies and variations between pronouns and their agreement 
with antecedents in Indian languages. The generic algorithm developed uses the morphological richness 
of Indian  languages. The machine learn ing approach uses the features which can  handle major Indian 
languages. We have tested the system with Indo-Aryan and Dravidian  languages namely  Bengali, Hindi 
and Tamil. The results are encouraging. 
1 Introduction 
Natural language has different types of anaphoric expressions and these expressions bring elegance 
and make the natural language text interesting to read. Anaphoric expression in a discourse refers to 
another item in a discourse. The task of resolving anaphors with its referent, antecedent is called as 
anaphora resolution. Anaphora resolution is required in most of the NLP applications to achieve re-
quired performance. The importance of anaphora resolution in various tasks is demonstrated by re-
searchers by integrating anaphora resolution with answer extraction system, automatic summarization 
system, relation extraction system, document similarity identifier etc.  
Most of the anaphora resolution systems are developed for particular languages. The researchers 
have analyzed anaphors across languages at various levels such as syntactic, semantic, discourse, 
structured, and unstructured features. But there are very few attempts for language independent ap-
proaches. In this paper, we present a generic anaphora resolution engine for Indian languages. We 
have come up with a language independent engine, which takes shallow parsed text as input. The mor-
phological richness of Indian languages is tapped to come up with a language independent anaphora 
resolution engine.  
Early works in anaphora resolution by Hobbs (1978), Carbonell and Brown (1988), Rich and Lu-
perFoy (1988) etc. were mentioned as knowledge intensive approach, where syntactic, semantic in-
formation, world knowledge and case frames were used. Centering theory, a discourse based approach 
for anaphora resolution was presented by Grosz (1977), Joshi and Kuhn (1979), Joshi and Weinstein 
(1981), Strube and Hahn (1999). Salience feature based approaches were presented by Lappin and 
Leass (1994), Kennedy Boguraev (1996) and Sobha et al., (2000). Indicator based resolution methods 
were presented by Mitkov (1997, 1998). One of the early works using machine learning technique was 
Dagan Itai?s (1990) unsupervised approach based on co-occurrence words. With the use of machine 
learning techniques researchers work on anaphora resolution and noun phrase anaphora resolution si-
multaneously. The other machine learning approaches for anaphora resolution were the following. 
Aone and Bennett (1995), McCarty and Lahnert (1995), Soon et al. , (2001), Ng and Cardia (2002) had 
used decision tree based classifier. Daelman and Van de Bosh (2005), Hendrickx et al., (2008), Reca-
sen (2009) had used TiMBL, a memory based learning approach. Anaphora resolution using CRFs 
was presented by McCallum and Wellner (2003) for English, Li et al., (2008) for Chinese and Sobha 
This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer 
are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/  
1824
et al., (2011, 2013) for English and Tamil. Expectation Maximization (EM) was used for anaphora 
resolution by Charniak and Elsner (2009). Wich et al., (2012) demonstrated a coreference resolution in 
a large scale using discriminative hierarchical model.  
In Indian languages anaphora resolution engines are demonstrated only in few languages such as 
Hindi, Bengali, Tamil, and Malayalam. Most of the Indian languages do not have parser and other so-
phisticated pre-processing tools. The earliest work in Indian language, Vasisth was a rule based multi-
lingual anaphora resolution platform by Sobha and Patnaik (2000, 2002), where the authors had ex-
ploited the morphological richness of Malayalam and Hindi. Prasad and Strube (2000), Uppalapu et 
al., (2009) and Dekwale et al., (2013) had presented different approaches using Centering theory for 
Hindi. Dutta et al (2008) had presented a Hindi anaphora resolution system using Hobbs? algorithm. 
Murthy et al., (2007) had presented a comparison on Tamil anaphora resolution using multi-linear re-
gression and salience factor based approach. Sobha et al., (2007) presented a salience factor based 
with limited shallow parsing of text. Akilandeswari et al., (2013) used CRFs for resolution of third  
person pronoun and Akilandeswari et al., (2012) presented a work on resolution of ?atu?, third person 
neuter pronoun in Tamil. Balaji et al. , (2012) presented resolution using two stage bootstrapping ap-
proach. The author had used UNL representation. Ram et al., (2013) used Tree CRFs for anaphora 
resolution for Tamil with features from dependency parsed text. 
One of the earliest multilingual anaphora resolution systems was presented by Aone and Mckee 
(1993), where the authors had used Global discourse world which contained syntactic, semantic, rhe-
torical and other information. They demonstrated the system for English, Spanish and Japanese. 
Mitkov (1998) extended the indicators based approach for other languages and presented it for Eng-
lish, Polish and Arabic. As mentioned earlier, Vasisth was the only multilingual attempt for Indian 
language anaphora. SemEval-2010 Task 1: Coreference resolution in Multiple Language, a tool con-
test accelerated the research in multilingual anaphora resolution. The contest had six languages, name-
ly, English, German, Italian, Dutch, Spanish and Catalan. There were six participants, among them 
only two participants presented results for all six languages. The systems presented in the contest were 
RelaxCor, Corry, SUCRE, BART, TANL-1 and UBIU (Recasens et al., 2010).  The multilingual ana-
phora resolution in Indian languages was re-initiated by Anaphora Resolution in Indian languages, the 
tool contest conducted as a part of ICON 2011 (Sobha et al., 2011). The contest had three languages, 
namely, Hindi, Bengali and Tamil. There were four participants and all the four submitted results for 
Bengali. Tamil and Hindi had two participants. This task boosted the anaphora resolution work in 
Bengali. Senapati et al., (2013) presented a work on Bengali anaphora resolution by customizing Gui-
TAR and BART tool was customized for Bengali by Sikdar et al., (2013). In all the above published 
multilingual systems, there was a language dependent module plugged in. In the present work, we 
have tried to come up with an approach without using language specific modules. We have developed 
a generic anaphora engine as the system is designed to work for different languages.  We have over-
come the agreement problem with the PNG information obtained from in-depth morphological analy-
sis and PNG agreement heuristic rules.  These rules are capable of filtering the possible candidate an-
tecedents for an anaphor (pronouns) using the PNG information across languages.  
The rest of the paper is organised as follows: In the following section we have described nature of 
Indian languages and variation in antecedent-anaphor agreement in Indian languages.  Section 3, we 
have explained our approach towards generic engine by overcoming the variation in antecedent-
anaphor agreements. In section 4, we have presented our experiment and results. And the last is the 
conclusion section. 
2  Characteristics of Indian Language Anaphora 
Indian languages are morphologically rich and verb-final languages. These languages have relatively 
free word order and clausal structures are more fixed order. Indian languages fall under the following 
broader families of languages, Indo-Aryan, Dravidian and Tibeto-Burman. Indo-Aryan family in-
cludes languages such as Hindi, Bengali, Marathi, Punjabi etc, Dravidian includes languages such as 
Telugu, Kannada, Malayalam, Tamil, Tibeto-Burman includes languages such as Bodo, Manipuri etc. 
Dravidian languages are highly agglutinated and have rich productive suffixation than the Indo-Aryan 
languages. Plural marker and case markers get affixed to the nouns and tense markers and Person, 
Number, Gender (PNG) markers affix with verbs. In certain Indo-Aryan languages such as Hindi, case 
1825
markers occur as postpositions following the nouns. These postpositions are handled in the preprocess-
ing stage to occur in the noun morphological analysis. Indian languages vary largely in the distinction 
of Number (singular/plural) and Gender in pronouns. Few of the Indian languages and their details of 
Number and Gender Distinction in those languages are presented in table 1.  
 
Language Number Distinction  
(singular/plural) 
Gender Distinction 
Hindi Yes No 
Sanskrit Yes Yes 
Punjabi Yes No 
Gujarati  Yes No 
Assamese Yes No 
Bengali Yes No distinction for Masculine and Fe-
minine. But there is animate- inani-
mate distinction.  
Oriya Yes No 
Telugu Yes Masculine and others 
Kannada Yes Yes 
Malayalam Yes Yes 
Tamil Yes Yes 
Table 1: Variation of Pronouns with respect to Number and Gender 
The similarities and variations between languages in the number-gender characteristics of the pro-
nouns is presented in Table 1. In the number characteristics the languages are similar whereas in the 
gender characteristics there are variations. The information in the table 1 brings forth the challenges in 
capturing the anaphor-antecedent PNG agreement for a generic anaphora resolution engine.    
With example 1, 2 and 3, we have demonstrated the variation in Gender, Number distinction in pro-
nouns in Tamil (Ta), Bengali (Bn) and Hindi (Hi).  
 
Example 1 
Ta:a) raamum       giithavum     cakotharan-cakothari.  
      Ram(N)+inc   Gita(N)+inc   brother   -sister.  
      (Ram and Gita are brothers and sisters.)  
 
   b) avan    elzhaam    vakuppu     padikkiraan. 
      He(PN)  seventh(N) standard(N) study(V)+present+3sm   
     (He studies in seventh standard.) 
 
   c) aval     paththaam vakuppu     padikkiraal. 
      she(PN)  tenth(N)  standard(N) study(V)+present+3sf 
    (She studies in tenth standard.) 
Example 2 
Bn:a) raam o giita bhai-bon. 
   b) se shapton shreni te pore. 
   c) se doshom shreni te pore. 
 
Example 3 
Hi:a) raam aur giitaa bhaii-bahan hai.  
   b) vaha satavIM kakshaa meM paTataa hai. 
   c) vaha aaTaviM kakshaa meM paTatii hai.  
 
Example 1 has three Tamil sentences. The second and third sentence has pronouns 'avan' he and 'aval' 
she, the third person masculine and the third person feminine pronouns respectively. Masculine pro-
noun in second sentence refers to the masculine noun 'raam' and the feminine pronoun in the third sen-
tence refers to the feminine noun 'Gita' in the first sentence. Here the masculine and feminine pro-
1826
nouns have a clear distinction. The three Tamil sentences in example 1 are translated to Bengali and 
Hindi. The Bengali translation is presented in example 2 and Hindi translation is presented in example 
3. In example 2, the second and third sentence has 'se', the third person pronoun. In the second sen-
tence, the pronoun 'se' refers to the masculine noun 'raam' and ?se? in the third sentence refers to femi-
nine noun 'giitaa' in the first sentence. Here the third person pronoun does not have mascu-
line/feminine distinction. Similarly in example 3, which has the Hindi translation, 'vaha', the third per-
son pronoun does not have gender distinction. In sentence 2 of example 3, 'vaha' refers to the mascu-
line noun and in sentence 3, 'vaha' refers to the feminine noun.  
These variations in Number and Gender distinction in pronouns pose challenges in coming up with 
a generic anaphoric engine. The pronoun and its agreement with its antecedents vary between the lan-
guages and to handle the agreement we require a language dependent mapping. 
3 Generic Anaphora Resolution Engine  
Most of the Indian languages are resource poor languages. The  morphological richness of these lan-
guages, help in building various high end NLP applications such as machine translation, anaphora res-
olution etc., with limited shallow parsed information without using sophisticated parsing tools. In this 
work we have tried to build a generic anaphora resolution engine using shallow parsed text. Similari-
ties between Indian languages, described in the previous section, are tapped to come up with a generic 
approach for anaphora resolution in Indian languages. The variation in the antecedent-anaphor agree-
ment mentioned in the section above is handled by an in-depth morphological analysis of the text. We 
have used CRFs, a linear graphical machine learning algorithm to resolve the antecedents. 
3.1 Preprocessing of Data 
We perform limited shallow parsing on the training and testing data. Both the data are pre-processed 
with morphological analyzer, Part-of-Speech (POS) tagger, Chunker, Clause boundary identifier and 
Named Entity Recognizer. Here morphological analysis, Part-of-Speech tagging, Chunking are obliga-
tory.  Clause boundary identification and Named Entity Recognition are optional pre-processing tasks. 
These two tasks add information, which can be used as constraint features in the machine learning ap-
proach. In this work, we perform a detailed morphological analysis for a given word.  This is ex-
plained in the following section. The preprocessing tools available in Indian Language ?Indian Lan-
guage Machine Translation (IL-ILMT) consortium are used. 
3.2 Detailed Morphological Analysis 
We perform an in-depth morphological analysis for a given word. In the in-depth morphological anal-
ysis we analyse both inflectional and derivational morphology. The in-depth morphological analysis 
gives the suffix (case markers with the nouns, tense-aspect-model with the verbs) and PNG characte-
ristics of the words. These suffix information is used in the syntactic feature and verb suffix feature for 
the machine learning technique which are described further in section 3.4. The post-position occurring 
with the nouns, its syntactic association with the noun is identified in morphological processing stage 
and information is used as syntactic feature.  
The morphological analyser identifies the root word, its lexical category, gender, number, person, 
case (direct/oblige), case markers if the word is a noun and tense markers (vibhakthi as called in In-
dian traditional grammar) if the word is a verb and the suffixes.  Gender information holds information 
such as 'm' ? masculine, 'f' ? feminine, 'n' ? neuter, 'mf' ? can be a masculine or feminine, 'fn' ? femi-
nine or neuter as in Telugu and 'any' ? can be any gender.  Number information can be singular, plural, 
dual or any. Person information can be 1st person, 2nd person, 3rd person or any.  We have explained it 
further with following example words and its analysed output in table 2. 
 
S.No Language Word Analysis of the Word 
1 Ta jaanukku  ?John(N)+dative? <fs af='jaan,n,m,sg,3,d,ukku,ukku'> 
2 Ta viittil  ?house(N)+locative? <fs af='viitu,n,any,sg,3,d,il,il'> 
3 Ta avanaal ?he(pn)+INS? <fs af='avan,pn,m,sg,3,d,aal,aal'> 
4 Ta avalukku ?he(pn)+dative?  <fs af='aval,pn,f,sg,3,d,ukku,ukku'> 
5 Hi adhikaarii  ?officer (N)? <fs af='adhikaarii,n,m,sg,3,d,,'> 
1827
6 Hi siitaa ?sita (N)? <fs af='siitaa,n,f,sg,3,d,,'> 
7 Hi uskaa ?he/she/it (pn)?  <fs af='vaha,pn,any,sg,3,d,kaa,kaa'> 
8 Hi ve ?they (pn)? <fs af='vaha,pn,any,pl,3,d,,'> 
9 Bn chele ?boy (N)? <fs af=?chele,n,m,sg,3,d,,'> 
10 Bn meyze ?girl (N)? <fs af=?meyze,n,m,sg,3,d,,'> 
11 Bn se ?he/she (PN)? <fs af='se,pn,mf,sg,3,d,,'> 
Table 2: Words and in-depth analysis 
In the table 2, we have presented nouns and pronouns from Hindi (Hi), Bengali (Bn) and Tamil (Ta) 
and their in-depth analysis. The first word ' jaanukku' is a masculine singular noun. So the analysis has 
'm,sg,3?. The second word 'viittil' is a neuter singular noun and its analysis has 'n,sg,3'. The third word 
is third person masculine and the fourth word is a feminine pronoun, so the analysis are ?m,sg,3? and 
?f,sg,3? respectively. The words in the Fifth and sixth example are Hindi nouns with masculine and 
feminine gender respectively. The seventh example is third person singular and eighth example is third  
person plural word from Hindi. Hindi pronouns do not have gender distinction.  The gender, number, 
person for the two pronouns are 'any,sg,3' and 'any,pl,3' respectively. 'any' in the gender slot shows the 
pronoun can refer to a noun phrase with any gender including neuter gender. The ninth and tenth ex-
ample words are Bengali nouns ?boy? and ?girl?, with masculine and feminine gender respectively. The 
eleventh word is a Bengali third person masculine and feminine pronoun. The gender, number, person 
in the morphological analysis has 'mf,sg,3'. This pronoun can refer to both masculine and feminine 
noun in Bengali. 
3.3 Data Format 
After pre-processing, the data is presented in a column format. The following are the columns infor-
mation. First column has sentence id, followed by word id, POS tag, chunk tag, in-depth morphologi-
cal analysis, clause information and Named Entity information.  The training data has an additional 
column having the antecedent-anaphor agreement information.  
3.4 Architecture of the Engine 
The engine works independent of language. We have used heuristic rule based algorithm to select the 
candidate noun phrases for a given pronoun and machine learning techniques based approach to filter 
the exact antecedent noun phrase.  As every supervised machine learning approach, this approach also 
has training and testing phase. The architecture of our approach for training and testing is given in fig-
ure1 and 2 respectively.  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 1: Training phase          Figure 2: Testing phase 
Preprocessed Input Data 
Extraction of Features and identi-
fication of antecedent with CRFs 
Engine 
Selection of possible Candidates  
Language Model  
Language 
Model 
Preprocessed Input Data 
Extraction of Features and tagging 
with CRFs Engine 
Selection of possible Candidates  
Antecedent Marked Output 
1828
Selection of Candidate Noun Phrases for Antecedent 
Both the training and testing phase has selection of the possible candidates. The noun phrases which 
agree with the pronoun in PNG should be selected as possible candidates for its antecedent. In training 
phase, the noun phrases which match with PNG of the pronoun and occur in between the anaphor and 
the antecedent are collected for each pronoun and given for training using the machine learning algo-
rithm. The exact anaphor and antecedent pair forms positive pair and other noun phrases and anaphor 
form negative pairs for learning. In the testing phase all the noun phrases that match in PNG with the 
pronouns are collected from the current sentence and four prior sentences. The gender distinction and 
anaphor-antecedent agreement varies widely among Indian languages. In order to have a language in-
dependent engine, these variations have to be dynamically captured and the rules for checking PNG 
agreement have to be generated. We have used the gender information from the morphological analy-
sis extracted with a set of heuristic rules to capture the variation in PNG agreement. The heuristic rules 
describe the possible genders that can match with the gender of the pronoun that varies between lan-
guages. The heuristic rules are presented below. 
 
1. If the gender of the pronoun is ?m?, then the nouns having masculine gender are cho sen as candidate antece-
dents. 
2. If the gender of the pronoun is ?f?, then the nouns with femin ine gender are chosen as candidate antecedents.  
3. If the gender of the pronoun is ?n?, then the nouns having neuter gender are chosen as candidate antecedents. 
4. If the gender of the pronoun is ?mf?, then the nouns with gender ?mf?, ?m? and ?f? are chosen as candidate 
antecedents and the nouns with gender ?mf? is given importance. 
5. If the gender of the pronoun is ?fn? is the gender of the pronoun, then nouns with ?fn? are  chosen as candi-
date antecedents. 
6. If the gender of the pronoun is ?any?, then all the nouns are considered for candidate antecedent set and the 
nouns with gender ?any? is given higher priority. 
  
Once the possible candidates for antecedents for the anaphors are selected, they are given for train-
ing/testing using the machine learning technique.  Here we have used CRFs, a linear graphical tech-
nique to learn and identify the antecedents.  
Anaphora Resolver 
The core anaphora engine uses CRFs, a machine learning technique. In the training phase the system is 
provided with annotated data and the features for learning. After the system learns, a model file is 
generated as output. In the testing phase any unseen text is given for the automatic anaphora resolu-
tion. In our approach we have modeled this as a binary classification task. The machine has to classify 
whether the given candidate antecedent is the real antecedent or not based on the features of the candi-
date antecedents and the pronoun. The features for learning are extracted from the shallow parsed data. 
The feature extraction module extracts these features for all possible candidate antecedent and pro-
noun pairs from the shallow parsed data.  The features used for learning are described below. Here we 
have used the freely available open source CRFs (Kudo, 2005).  
Features for Learning  
The features required for this task are identified from shallow parsed input sentences. The features for 
all possible candidate antecedent and pronoun pairs are obtained by preprocessing the input sentences 
with in-depth morphological analyser, POS tagger, and chunker, clause boundary identifier and 
Named Entity recognizer, where the last two preprocessing tasks are optional.  The features identified 
can be classified as positional features, syntactic features and constraint features.  
 
a) Positional Features:  The occurrence of the candidate antecedent is noted. Is it in the same sentence 
where the pronoun occurs or in the prior sentences? Prior four sentences from the current sentence are 
considered.  
 b) Syntactic Features:  
Syntactic Role: The syntactic role of the candidate noun phrases in the sentence is a key feature. 
The syntactic role of the noun phrases such as subject, object, indirect object, are obtained from the 
1829
case suffix affixed with the noun phrase. We consider Nominative and Dative cases for subject and 
other cases for object, the position and the other cases for indirect object. 
Linguistic Characteristics: POS tag and chunk information of Candidate NP, suffixes affixed with 
the noun. 
c) Verb Suffixes: The suffixes which show the gender which gets attached to the verb. 
d) Nature of NP:  Whether the candidate NP (probable antecedent) is Possessive or Existential.  
e) Constraint Features: The constraint features are obtained from clause boundary and named entities 
recognized.  
The position of the candidate NP with respect to clause boundary such as is candidate NP in current 
clause or immediate clause or non-immediate clause. 
The Named Entity tags associated with the candidate NPs help the learning algorithm to learn con-
straints that types of NEs that can be its possible antecedents. 
f) Combination of the above said features. 
The features for learning have been identified based on the characteristics of the pronouns. For exam-
ple constraint feature (current-clause) and syntactic feature (subject) helps in identifying the antece-
dent of the reflexives. For relative anaphors the constraint feature (immediate-clause) and syntactic 
feature (subject) help in identifying the antecedent. 
4 Experiment, Results and Discussion 
We have tested our approach using the dataset provided in ?Anaphora Resolution for Indian Lan-
guage?, a tool contest conducted as a part of ICON 2011. The tool contest had three languages namely 
Tamil, Hindi and Bengali. The dataset is presented in column format with the following information 
viz. line index, word index, word, its POS and chunking information, followed by Named Entity in-
formation.  We have enriched the dataset with in-depth morphological analysis. Table 3 presents the 
statistics of the ICON 2011 tool contest dataset. 
 
Language Training Data Testing Data 
 Bengali  Hindi  Tamil  Bengali  Hindi  Tamil 
Total Number of Pronouns 814  835  925  494  507  609 
Number of Anaphoric Pronouns 476  557  580  283  344  348 
Number of Non-Anaphoric Pronouns 338  278  345  211  163  261 
Table 3: Statistics of ICON 2011 Dataset 
MUC, B3, BLANC, CEAF are the common scorers available for coreference resolution, where the co-
reference chains are being evaluated. Anaphora resolution is generally evaluated with performance 
measures such as Precision, Recall and F-measure. In this work, we have measured the performance 
with Precision, Recall and F-Measure and it is presented in table 4. 
 
Example 4 
Ta: aalluNar  rosaiyya  villavil          kalanthukkoNtaar. avar                        athil   uraiyaRRinaal.  
      Governor  Rosiah     function+loc join+past+3SH .     He(gender neutral) this    gave_lecture 
     (Governor  Rosiah joined the function. He gave the lecture there.) 
 
In above example 4, ?avar? (third honorific singular pronoun) in the second sentence, refers to a mas-
culine noun phrase ?aalluNar rosaiyya? in the previous sentence. The honorific pronoun can also refer 
to a feminine pronoun.  This possibility of referring to both the gender introduces more errors.  
In Hindi, most of the pronouns such as ?vaha? (he/she/it), ?usa? (he/she/it), ?unhone? (he/she hono-
rofic) and ?khuda? (himself) etc., do not have gender distinction and can be used to refer to antece-
dents of both feminine and masculine. PNG agreement adds more challenges in anaphora resolution, 
due to which the system gives more false positives. In our algorithm we were able to reduce the num-
ber of false positives and obtained better precision by having positional features and the verb suffixes 
as learning features. For languages such as Hindi, we observe that there is necessity of having verb 
1830
analysis in the text processing component. If we have this information as pre-processed data to the 
resolution engine, it can reduce ambiguity and improve the anaphora resolution. 
As it is seen from the results table we have obtained lesser scores for Bengali. In Bengali third person 
pronouns such as ?ami? (I), ?t?mi/tui/apni? (you), ?se/tini? (he/she),  ?amra? (we), ?tara/tnara? (they),  
do not have masculine, feminine distinction, but there is animacy distinction. And also the verb has no 
gender agreement. This adds more challenge to anaphora resolution engine and hence lesser scores 
than other languages. We identify the animacy feature in the morphological analysis stage for all the 
languages, but for Bengali language it is not robust and it affects in the anaphora resolution. For such 
languages the order of NPs and syntactic roles play major role in anaphora resolution. The use of fea-
tures such as Named Entities helps in improving the resolution of pronouns referring to person and 
location. The addition of clause boundary information improves resolution by adding structural con-
straints. 
5 Conclusion 
We have presented a generic anaphora resolution engine, which can be used for all Indian languages. 
The three languages, Hindi, Bengali, and Tamil, we have chosen are the most spoken languages be-
longing to two major language families of India, namely belonging to Indo-Aryan and Dravidian fami-
lies respectively. Though the Indian languages have similarities, they vary in Person, Number, Gender 
distinction, which pose a challenge in building language independent engine. The engine is language 
independent as it uses the information from the in-depth morphological analysis. It is specifically de-
signed in such a way that it is scalable and allows plug-n-play architecture. The core anaphora resolu-
tion engine uses CRFs a machine learning technique. This uses feature based learning and we have 
provided syntactic and positional based features obtained from in-depth morphological analysis. We 
have obtained encouraging evaluation results. The major contributions of this work are the following: 
a) Our attempt is first of its kind in Indian languages to develop a single generic engine, using ma-
chine learning. 
b) It is a known fact that most of the Indian languages are resource poor, hence we have used very 
minimal resources, only shallow parsing has been used.  
c) The results obtained are comparable to other reported works. 
Reference 
Akilandeswari A., and Sobha Lalitha Devi. (2013). Conditional Random Fields Based Pronominal Resolution in  
Tamil. International Journal on Computer Science and Engineering, Vol. 5 Issue 6 pp 601?610. 
Akilandeswari A, Bakiyavathi T and Sobha Lalitha Devi, (2012), "atu Difficult Pronominal in Tamil", In  Pro-
ceedings of Lrec 2012, Istanbul 
Aone C., and McKee D. (1993).A Language-Independent Anaphora Resolution System for Understanding Mul-
tilingual Texts. In proceeding of ACL 1993, pp 156-163. 
Aone C., and  Bennett S. (1995). Evaluating automated and manual acquisit ion of anaphora resolution strategies. 
In: 33rd Annual Meeting of the Association for Computational Linguistics, pp. 122-129. 
Balaji J., Geetha T.V., Ranjan i Parthasarathi R.,  Karky M. (2012).Two-Stage Bootstrapping for Anaphora Reso-
lution In: Proceedings of COLING 2012 , pp 507?516. 
Carbonell J. G., and Brown R. D. (1988).   Anaphora resolution: A multi-strategy approach. In: 12th International 
Conference on Computational Linguistics, 1988, pp. 96-101. 
Charniak, E., and Elsner, M. (2009).  EM Works for Pronoun Anaphora Resolution. In Proceedings of the Con-
ference of the European Chapter of the Association for Computational Linguistics (EACL 2009), Athens, 
Greece.  
Daelemans, W. and van den Bosch, A. (2005). Memory-based language processing. Cambridge University 
Press, Cambridge  
Dagan I., and Itai. A. (1990). Automatic processing of large corpora for the resolution of anaphora references. 
In: 13th conference on Computational linguistics, Vol. 3, Helsinki, Fin land, pp.330-332. 
1831
Dakwale. P., Mujadia. V.,  Sharma. D.M. (2013). A Hybrid Approach for Anaphora Resolution in Hindi. In: 
Proc of International Joint Conference on Natural Language Processing , Nagoya, Japan, pp.977?981. 
Dutta. K., Prakash. N. and Kaushik. S. (2008). Resolving Pronominal Anaphora in Hindi using Hobbs ? algo-
rithm,? Web Journal of Formal Computation and Cognitive Linguistics, Issue 10, 2008. 
Li., F., Shi., S., Chen., Y., and Lv, X. (2008). Chinese Pronominal Anaphora Resolution Based on Conditional 
 Random Fields. In: International Conference on Computer Science and Software Engineering , Wash-
ington, DC, USA, pp. 731-734. 
Hendrickx I., Hoste V., and Daelemans W. (2008). Semantic and syntactic features for Dutch coreference resolu-
tion. In Gelbukh A. (Ed.), CICLing-2008 conference, Vol. 4919 LNCS, Berlin, Springer Verlag, pp. 731-734.  
Hobbs J. (1978). Resolving pronoun references. Lingua 44, pp. 339-352. 
Grosz, B. J. (1977). The representation and use of focus in dialogue understanding. Technical Report 151, SRI 
International, 333 Ravenswood Ave, Menlo Park, Ca. 94025.  
Joshi A. K., and Kuhn S. (1979). Centered logic: The role of entity centered sentence representation in natural 
language inferencing. In: International Joint Conference on Artificial Intelligence . 
Joshi A. K., and Weinstein S. (1981). Control o f inference: Role of some aspects of discourse structure ? center-
ing?, In: International Joint Conference on Artificial Intelligence, pp. 385-387. 
Kennedy, C., Boguraev, B. (1996) Anaphora for Everyone: Pronominal Anaphora Resolution without a Parser. 
In: 16th International Conference on Computational Linguistics COLING?96 , Copenhagen, Denmark, pp. 
113?118. 
Lappin S., and Leass H. J. (1994). An algorithm for pronominal anaphora resolution. Computational Linguistics 
20 (4), pp. 535-561. 
McCallum A., and Wellner. B. (2003). Toward conditional models of identity uncertainty wit h application to 
proper noun coreference. In Proceedings of the IJCAI Workshop on Information Integration on the Web , pp. 
79?84. 
McCarthy, J. F. and Lehnert, W. G. (1995). Using decision trees for coreference resolution. In C. Mellish (Ed.), 
Fourteenth International Conference on Artificial Intelligence, pp. 1050-1055  
Mitkov R. (1998). Robust pronoun resolution with limited knowledge. In: 17th International Conference on 
Computational Linguistics (COLING? 98/ACL?98), Montreal, Canada,  pp. 869-875.  
Mitkov, R. (1997). "Factors in anaphora resolution: they are not the only things that matter. A case study based 
on two different approaches". In Proceedings of the ACL'97/EACL'97 workshop on Operational factors in 
practical, robust anaphora resolution, Madrid, Spain. 
Murthy K.N., Sobha L, Muthukumari B. (2007). Pronominal Resolution in Tamil Using Machine Learning A p-
proach. The First  Workshop on Anaphora Resolution (WAR I) , Ed Christer Johansson, Cambridge Scholars 
Publishing, 15 Angerton Gardens, Newcastle, NE5 2JA, UK, pp.39-50. 
Ng V., and Card ie C. (2002). Improv ing machine learning approaches to  coreference resolution. In. 40th 
Annual Meeting of the Association for Computational Linguistics, pp. 104-111.  
Prasad R., and Strube,M.,(2000). Discourse Salience and Pronoun Resolution in  Hindi, Penn Working Papers in 
Linguistics, Vol 6.3, pp. 189-208. 
Ram, R.V.S. and Sobha Lalitha Devi. (2013)."Pronominal Resolution in Tamil Using Tree CRFs", In Proceed-
ings of 6th Language and Technology Conference, Human Language Technologies as a challenge for Com-
puter Science and Linguistics - 2013, Poznan, Po land 
Recasens M., M`arquez L., Sapena E., Mart?I M.A., Taul? e M., Hoste V., Poesio M., Versley Y. (2010). SemEv-
al-2010 Task 1: Coreference Resolution in Mult iple Languages. In Proceedings of the 5th International Work-
shop on Semantic Evaluation, ACL 2010 , Uppsala, Sweden, .pages 1?8. 
Recasens M., Hovy E. (2009). A  Deeper Look into Features for Coreference Resolution. Lalitha Devi, S., Bra n-
co, A. and Mitkov, R. (eds.), Anaphora Processing and Applications (DAARC 2009) , LNAI 5847, Springer-
Verlag Berlin Heidelberg, pp 535-561. 
Rich, E. and LuperFoy S., (1988) An architecture for anaphora resolution. In: Proceedings of the Second Confe-
rence on Applied Natural Language Processing , Austin, Texas. 
1832
Senapati A., Garain U. (2013). GuiTAR-based Pronominal Anaphora Resolution in Bengal. In: Proceedings of 
51st Annual Meeting of the Association for Computational Linguistics, Sofia, Bulgaria pp 126?130. 
Sikdar U.K, Ekbal A., Saha S., Uryupina O., Poesio M. (2013). Adapting a State-of-the-art Anaphora Resolution 
System for  Resource-poor Language. In proceedings of International Joint Conference on Natural Language 
Processing, Nagoya, Japan pp 815?821. 
Sobha L. and Patnaik B. N. (2000). Vasisth: An Anaphora Resolution System for Indian Languages. In Proceed-
ings of International  Conference on Artificial and Computational Intelligence for Decision, Control and 
Automation in Engineering and Industrial Applications, Monastir, Tunisia. 
Sobha L. and Patnaik,B.N. (2002). Vasisth: An anaphora resolution system for Malayalam and Hindi. In  Pro-
ceedings of Symposium on Translation Support Systems. 
Sobha L. (2007). Resolution of Pronominals in  Tamil. Computing Theory  and Applicat ion, The IEEE Computer 
Society Press, Los Alamitos, CA, pp. 475-79. 
Sobha L., Pralayankar P. (2008). Algorithm for Anaphor Resolution in Sanskrit. In  Proceedings of  2nd Sanskrit 
Computational Linguistics Symposium, Brown University, USA, 2008. 
Sobha, Lalitha Devi., Vijay Sundar Ram and Pattabhi RK Rao. (2011). Resolution of Pronominal Anaphors u s-
ing Linear and Tree CRFs. In. 8th DAARC, Faro, Portugal, 2011. 
Sobha L., Sivaji Bandyopadhyay, Vijay Sundar Ram R., and Akilandeswari A. (2011). NLP Tool Contest 
@ICON2011 on Anaphora Resolution in Indian Languages.  In: Proceedings of  ICON 2011. 
Soon W. H., Ng, and Lim D. (2001). A  machine learn ing approach to coreference resolution of noun phrases. 
Computational Linguistics 27 (4), pp.521-544. 
Strube, M. and Hahn U., (1999). Functional centering: Grounding referential coherence in information structure. 
Computational Linguistics, 25(3) pp 309?344 
Taku Kudo. 2005. CRF++, an open source toolkit for CRF, http://crfpp.sourceforge.net . 
Uppalapu. B., and Sharma, D.M. (2009). Pronoun Resolution For Hindi. In: Proceedings of 7th Discourse Ana-
phora and Anaphor Resolution Colloquium (DAARC 09) , pp. 123-134. 
Wick M., Singh S., and McCallum A. (2012).  A Discriminative Hierarchical Model fo r Fast Coreferenc e At 
Large Scale. In : Proceedings of ACL 2012. 
1833
Proceedings of the NAACL HLT 2010 Second Workshop on Computational Approaches to Linguistic Creativity, pages 31?39,
Los Angeles, California, June 2010. c?2010 Association for Computational Linguistics
An alternate approach towards meaningful lyric generation in Tamil 
Ananth Ramakrishnan A Sobha Lalitha Devi 
AU-KBC Research Centre 
MIT Campus of Anna University 
Chennai, India 
AU-KBC Research Centre 
MIT Campus of Anna University
Chennai, India 
ananthrk@au-kbc.org sobha@au-kbc.org 
Abstract 
This paper presents our on-going work to 
improve the lyric generation component of 
the Automatic Lyric Generation system for 
the Tamil Language. An earlier version of 
the system used an n-gram based model to 
generate lyrics that match the given melody. 
This paper identifies some of the deficien-
cies in the melody analysis and text genera-
tion components of the earlier system and 
explains the new approach used to tackle 
those drawbacks. The two central approach-
es discussed in this paper are: (1) An im-
proved mapping scheme for matching melo-
dy with words and (2) Knowledge-based 
Text Generation algorithm based on an ex-
isting Ontology and Tamil Morphology Ge-
nerator. 
1 Introduction 
In an attempt to define poetry (Manurung, 2004), 
provides three properties for a natural language 
artifact to be considered a poetic work, viz., Mea-
ningfulness (M), Grammaticality (G) and Poetic-
ness (P). A complete poetry generation system 
must generate texts that adhere to all the three 
properties. (Ananth et. al., 2009) explains an ap-
proach for automatically generating Tamil lyrics, 
given a melody, which attempts to generate mea-
ningful lyrics that match the melody.  
The existing approach (Ananth et. al., 2009) to au-
tomatically generate Tamil lyrics that match the 
given tune in ABC format (Gonzato, 2003) in-
volves two steps. The first step is to analyze the 
input melody and output a series of possible sylla-
ble patterns in KNM representation scheme - a 
scheme for representing all words in the language, 
where, K stands for Kuril ((C)V, where V is a 
short vowel), N stands for Nedil ((C)V, where V is 
a long vowel) and M stands for Mei or Ottru (con-
sonants) - that match the given melody, along with 
tentative word and sentence boundary. This melo-
dy analysis system was trained with sample film 
songs and their corresponding lyrics collected from 
the web. The tunes were converted to ABC Nota-
tion (Gonzato, 2003) and their lyrics were 
represented in KNM scheme. The trained model 
was then used to label the given input melody. 
The subsequent step uses a Sentence Generator 
module to generate lines that match the given syl-
lable pattern with words satisfying the following 
constraints: a) Words should match the syllable 
pattern and b) The sequence of words should have 
a meaning. This was achieved by using n-Gram 
models learnt from a Tamil text corpus.  
Though the system manages to generate sentences 
that match the syllable pattern, it has the following 
limitations: 
1) When no words are found matching a given 
syllable pattern, alternate patterns that are 
close to the given pattern, as suggested by the 
Edit Distance Algorithm, are considered. This 
algorithm treats the syllable patterns as strings 
for finding close patterns and hence, can pro-
vide choices that do not agree with the input 
melody. 
2) The Sentence Generation is based on the n-
Gram model learnt from a text corpus. This 
can result in sentences that do not have a cohe-
rent meaning. Also, since only bi-grams are 
considered, it can generate sentences that are 
ungrammatical due to Person-Number-Gender 
(PNG) agreement issues. 
This paper is an attempt to propose alternate ap-
proaches in order to overcome the above limita-
tions. 
31
2 Limitations of existing approach 
2.1 Finding close matches to syllable patterns 
In the existing system, when no words are found 
matching the given syllable pattern (either due to a 
small corpus or rarity of the pattern), the closest 
patterns are considered as alternatives. The closest 
match to a given syllable pattern is generated based 
on the Edit Distance algorithm. For example, if the 
input sequence is given as "NKN" (long vowel - 
short vowel - long vowel) and if no words are 
found matching NKN, closest matches for NKN 
are generated. Thus, if an edit distance of 1 is con-
sidered, the alternate pattern choices are "KKN", 
"NKM", "NNN", "NMN", etc. However, not all of 
these syllable patterns can fit the original music 
notes. 
As an example, consider the Tamil word ?thA-ma-
rai? (lotus) that fits the pattern NKN. Suppose no 
words that match the pattern NKN was present in 
the corpus and other close patterns were opted for, 
we get: 
Pat. Word Meaning Match 
KKN tha-va-Lai Frog No match 
NKM thA-ba-m Longing No match 
NNN kO-sA-lai Cow Hut Close Match 
NMN pA-p-pA Child No match 
Table 1. Alternative patterns for ?NKN? 
None of the above words can be used in the place 
of ?thA-ma-rai?, a good fit for a NKN pattern, as 
they don?t phonetically match (except for a close-
but-not-exact ?kO-sA-lai?) and hence cannot be 
used as part of the lyric without affecting the in-
tended melody.  
2.2 Ungrammatical or meaningless genera-
tion 
The Sentence Generation algorithm was based on 
the n-Gram model built from a text corpus. Given 
that n-Gram based generation schemes have in-
built bias towards shorter strings, it can end-up 
generating meaningless and ungrammatical sen-
tences. As observed in (Ananth et.al., 2009), we 
can get sentences such as: 
(* avan-He-3sm  nadandhu-walk sendrAlY-3sf) 
(He reached by walking) 
Here, the subject avan (He), which is a 3rd person, 
singular, masculine noun, does not agree with the 
verb sendrAlY , which is 3rd person, singular, femi-
nine. Thus, the noun and the verb do not agree on 
the gender. The correct sentence should be: 
(avan-3sm nadandhu sendrAn-3sm) 
This is happening because the bi-gram score for 
could be greater than 
. 
Similar disagreements can happen for other aspects 
such as person or number. Though performing a 
joint probability across words would help in reduc-
ing such errors, it would slow down the generation 
process. 
In addition to the above ungrammatical generation 
problem, the system can also generate meaningless 
sentences. Though, some of them can be consi-
dered as a poetic license, most of them were just 
non-sensical. For example, consider the following 
sentence generated by the n-Gram sentence genera-
tion system: 
(adhu-that idhu-this en-my) 
(that this my) 
The above sentence does not convey any coherent 
meaning. 
2.3 Ability to control theme/choice of words 
Given the nature of the Sentence generation algo-
rithm, it is not possible for the program to hand-
pick specific words and phrases. That is, the whole 
generation process is guided by the probability 
values and hence it is not possible to bias the algo-
rithm to produce utterances belonging to a particu-
lar theme.  
In the subsequent sections, we explain the alterna-
tive approaches to tackle the above limitations. 
32
3 Closest Syllable Patterns 
The existing approach uses the KNM Notation for 
representing all words in the language. This pho-
netic representation is at the most basic level, i.e., 
alphabets, and hence can be used to represent all 
words in the language. The KNM notation is gen-
erated by the melody analyzer and is used through-
out the system for generating sentences. Though 
this representation scheme is at the most basic lev-
el, it does not help in cases where we are looking 
for alternate or close matches. Thus, we need to 
come up with a representation scheme at a higher 
level of abstraction that will help us in providing 
valid choices without compromising the require-
ments of the melody. To this end, we hereby pro-
pose to use elements from classic poetry metric 
rules in Tamil Grammar (Bala et. al., 2003) as de-
fined in the oldest Tamil Grammar work, Tholkap-
piyam (Tholkappiyar, 5th Century B.C.). 
3.1 Meter in classical Tamil Poetry  
Meter is the basic rhythmic structure of a verse and 
the basic term that refers to Tamil meter is pA. 
Each line in the poem is called an adi, which, in 
turn, is made up of a certain number of metrical 
feet known as the ceer (words/tokens). Each ceer
is composed of a certain metrical units called asai
(syllables) which are made up of letters (vowels 
and consonants) that have certain intrinsic 
length/duration, known as mAthirai. The above 
entities are known as the core structural compo-
nents of a Tamil poem (Rajam, 1992)  
The basic metrical unit asai is mostly based on 
vowel length. There are two basic types of asai: 
nEr asai (straightness) and niRai asai (in a row; 
array). The nEr asai has the pattern (C)V(C)(C)
and niRai asai, (C)VCV(C)(C). These longest-
matching basic asai patterns are expanded to 
represent non-monosyllabic words, but for our 
needs, we use these two basic asai patterns for the 
new representation scheme. 
3.2 asai-based Representation Scheme  
In the new representation scheme, the constituents 
of the KNM representation scheme are converted 
to nEr or niRai asai before being sent to the Sen-
tence Generator module. The Sentence Generator 
module, in turn, makes use of this new representa-
tion scheme for picking words as well as for find-
ing alternatives. In this new representation scheme, 
a nEr asai is represented as Ne and a niRai asai is 
represented as Ni. 
The following table illustrates the mapping re-
quired for converting between the two representa-
tion schemes: 
KNM Representation asai representation 
K Ne 
KM(0?.2) Ne 
N Ne 
NM(0?2) Ne 
KK Ni 
KKM(0?2) Ni 
KN Ni 
KNM(0?2) Ni 
Table 2. KNM to asai representation 
For example, an output line such as, for example, 
?KK  KK  KKK? in the old representation scheme 
will be converted as ?Ni  Ni  NiNe? in the new re-
presentation based on asai. This means that the 
line should contain three ceer(words/tokens) and 
the first word should be a nirai asai, second word 
should be a nirai asai and the third word contains 
two syllables with a nirai asai followed by nEr 
asai. 
This new representation scheme helps in coming 
up with alternatives without affecting the metrical 
needs of the melody as the alternatives have the 
same mAthirai (length/duration). Thus, if we are 
given a pattern such as ?NiNe?, we have several 
valid choices such as ?KKK? (originally given), 
?KKMK?, ?KKMKM?, ?KKN?, ?KKMN? and 
?KKMNM?. We can use words that match any of 
the above patterns without compromising the dura-
tion imposed by the original music note. This way 
of choosing alternatives is much better than using 
the Edit Distance algorithm as it is based on the 
original meter requirements as against matching 
string patterns. 
To use the previous example of ?thA-ma-rai? (lo-
tus) (NKN) in this new representation scheme, we 
get, ?NeNi? and all the following words will 
match: 
33
Word KNM scheme 
nE-ra-lai (straight wave) NKN 
Sa-nj-nja-la-m (doubt) KMKKM 
Ma-ng-ka-la-m (auspicious) KMKKM 
a-m-bi-kai (goddess) KMKN 
vE-ng-ka-ta-m (Venkatam ? a 
name) 
NMKKM 
Table 3. NKN alternatives using asai representation 
The above (valid) choices such as KMKKM, 
NMKKM, etc. are not possible with just using the 
Edit Distance algorithm. Thus, the architecture of 
the system now consists of a new component for 
this conversion (Figure 1) 
Figure 1. System Approach with new ASAI converter 
4 Knowledge-based Sentence Generation 
The goal of the Sentence Generation module is to 
generate sentences matching the input pattern giv-
en in the new asai representation scheme. The ex-
isting system generated sentences based on the n-
Gram language model created from a text corpus 
of poems and film songs. However, as explained 
earlier, this can result in ungrammatical or mea-
ningless sentences being generated. In order to 
overcome this limitation, the Sentence Generation 
module is completely overhauled using a know-
ledge-based approach. A Tamil Morphology gene-
rator component, built in-house, is used to generate 
grammatically correct sentences from this know-
ledge base. 
4.1 Knowledge Base 
The knowledge base consists of: (a) set of verbs 
along with their selectional restriction rules (b) 
hand-coded sub-categorization Ontology with 
nouns and (c) list of adjectives and adverbs learned 
from a text corpus.  
4.1.1 Verbs and Selectional Restrictions 
Selectional restriction is defined as the right of the 
verb to select its arguments. Verb is the nucleus of 
a sentence and has the nature of choosing its argu-
ments. Any particular verb can take its arguments 
only according to its selectional restriction con-
straints. When these constraints are violated, the 
meaning of the sentence is affected. This violation 
of selectional restriction rules may lead to semanti-
cally wrong sentences or figurative usages. Cor-
rectness of a sentence not only depends on the syn-
tactic correctness, but also with the semantic inter-
pretation of the sentence. 
4.1.2 Syntactic Classification 
Verbs can be broadly classified into three divi-
sions, viz., monadic, dyadic and triadic verbs.   
Monadic verbs can have only one argument - the 
subject. Dyadic verbs can have two arguments -
subject and object. Triadic verbs can take three 
arguments - subject, direct and indirect objects. 
But there is no strict rule that the triadic verbs 
should have all three arguments or the dyadic verbs 
should have the two arguments filled. There can be 
overlaps between these groups of verbs. Triadic 
verb can drop the indirect object and have a Prepo-
sitional Phrase (PP) attached with the sentence. 
Dyadic verb can drop the object and still give a 
valid sentence. The verbs are grouped according to 
the sub-categorization information of the subject 
and object nouns. The sub-categorization features 
are explained in the following section. At present, 
we are using only Monadic and Dyadic verbs for 
our sentence generation purposes. 
4.1.3 Sub-Categorization 
Sub-categorization features explain the nature of 
the noun. The subject and object nouns are ana-
34
lyzed using these features. These features may in-
clude the type of noun, its characteristics, state etc. 
Sub-categorization information includes the fea-
tures such as [?animate], [?concrete], [?edible] 
etc.  
Some of the features and the meanings are listed 
below: 
[+animate] All animals, human beings 
[+human] All human beings 
[+female] Animals/human beings of 
feminine gender 
[+solid] Things that are in solid state 
[+vehicle] All vehicles 
[+concrete] Things that physically exist 
[-concrete] Things that do not physically 
exist 
[+edible] Things that can be eaten 
[-edible] Things that cannot be eaten 
[+movable] Things that are movable 
[-movable] Things that are not movable 
Table 4. Sub-categorization Features 
4.1.4 Ontology of Nouns 
The sub-categorization features are used in the 
formulation of general Ontology of Nouns. It is 
made with respect to the usage of language. The 
Ontology that is developed has the following sa-
lient features: 
? It is a language-based Ontology originally 
developed for English and has been cus-
tomized for Tamil 
? Nodes in the Ontology are the actual sub-
categorization features of Nouns 
? It is made according to the use of nouns in 
the Tamil language 
? Each node will have a list of nouns as en-
tries for that node 
The complete Ontology can be found in (Arulmoz-
hi, et. al., 2006) 
4.1.5 Contents of Knowledge Base 
At present, the knowledge-base consists of 116 
unique verbs, 373 selectional restriction rules and 
771 Nouns in the Ontology. 
The verbs list includes both cognitive as well as 
non-cognitive verbs. Examples of verbs include 
pAr (to see), kelY (to listen), vA (to come), thEtu
(to search), piti (to catch), po (to go), kal (to learn), 
etc. 
The selectional restriction rules are stored as fol-
lows: 
Verb=>subject_category;subject_case=>object_c
ategory;object_case. 
When a verb does not take any object, the keyword 
[no_obj] is used to denote the same. In addition to 
the subject and object categories, the rule also con-
tains the appropriate case markers to be used for 
the subject and object nouns. This additional in-
formation is stored for use by the Morph Genera-
tion component. 
Some examples of selectional restriction rules are 
given below: 
pAr=>[+living,+animate,+vertebrate,+mammal,
+human];NOM=>[no_obj]  
pAr=>[+living,+animate,+vertebrate,+mammal,
+human];NOM=> 
[+living,+animate,+vertebrate,+mammal,+human
];ACC 
pi-
ti=>[+living,+animate,+vertebrate,+mammal,+h
uman];NOM=>[living,+concrete,+movable,+artif
act,+solid,+instrument,-
vehicle,+implements];NOM 
pi-
ti=>[+living,+animate,+vertebrate,+mammal,+h
uman];NOM=>[no_obj]  
Here, ACC, NOM, DAT, etc. denote the case mark-
ers to be used for the subject and object nouns. 
The 771 Nouns are stored across several files ac-
cording to their position in the Ontology. An On-
tology map is used to determine the list of nouns 
present in a particular node position. 
35
4.1.6 Adjectives and Adverbs 
In addition to the verbs and nouns mentioned 
above, the knowledge-base also contains a list of 
adjective-noun and adverb-verb bi-grams learnt 
from a text corpus. This information is used to 
augment the Sentence Generator with words from 
these POS categories.  
4.2 Tamil Morphological Generator 
Tamil is a densely agglutinative language and dis-
plays a unique structural formation of words by the 
addition of suffixes representing various senses or 
grammatical categories, to the roots or stems. The 
senses such as person, number, gender and case are 
linked to a noun root in an orderly fashion. The 
verbal categories such as transitive, causative, 
tense and person, number and gender are added to 
a verbal root or stem. Thus, with the given know-
ledge-base and a Tamil Morphological generator 
component one can generate grammatically correct 
sentences. 
We use the Tamil Morphological Generator com-
ponent (Menaka et. al., 2010) to generate inflec-
tions of subject/object nouns with appropriate 
number & case and the verbs with person, number 
and gender suffixes.  
4.3 Sentence Generation 
Given a line in asai representation scheme, the 
sentence generation module is responsible for ge-
nerating a grammatically correct and meaningful 
sentence matching the given asai scheme. It 
achieves the same by using the knowledge-base 
along with the Tamil Morphology Generator com-
ponent (Figure 2). In addition to the asai represen-
tation, the module also accepts the tense in which 
the sentence must be written. The rest of the para-
meters such as person, gender and case are auto-
matically deduced by the module.  
Figure 2. Sentence Generator module 
The algorithm for generating a matching sentence 
is as follows: 
1. Pick a selectional restriction rule, R in random
2. For each noun, SUB_N in subject_category of 
rule, R: 
2.1 Guess the gender for SUB_N based on sub-
ject_category 
2.2 For each noun, OBJ_N in object_category: 
2.2.1 Use Morphology Generator component 
to get morphed nouns & verbs based on tense, per-
son, gender and case. 
2.2.2 Generate sentences of the form [SUB_N] 
[OBJ_N] [VERB]  
2.2.3 Add adjectives or adverbs, if needed 
2.2.4 Repeat words, if needed 
2.2.4 Add to list of sentences generated  
  
3. Check the list of sentences against the asai pat-
tern. If matches, return sentence. Otherwise, go to 
step 1. 
Table 5. Sentence Generation Algorithm 
36
Details about steps such as matching against asai
pattern, gender identification, word repetition and 
adding adjectives/adverbs are explained below. 
4.3.1 Matching against asai pattern 
The list of sentences generated from the module 
are compared against the given asai pattern. The 
matching could either be an exact match or a re-
ordered match. That is, since Tamil is a relatively 
free word-order language, the generated sentence 
can also be re-ordered, if required, to match the 
given asai pattern. However, when adjectives or 
adverbs are added to the sentence, they need to 
maintain their position in front of the noun or verb 
respectively and hence they are not re-ordered. For 
now, we do not weight the sentences and hence 
return the first matching sentence. 
4.3.2 Gender Identification 
As noted in the algorithm, the gender needs to be 
automatically guessed. In Tamil, the gender of the 
subject is denoted by the appropriate suffix in the 
verb. If a personal pro-noun such as nAnY (I) or nI
(you) is used as subject, then any of masculine or 
feminine gender can be used without affecting the 
grammatical correctness of the verb. In this case, 
the program uses the default value of masculine 
gender. If the subject is not a personal pronoun, the 
gender for the verb is guessed based on the sub-
ject_category of the subject noun. If the sub-
ject_category explicitly mentions [+human, 
+living, +female,?], then feminine gender is re-
turned. If the subject_category explicitly mentions 
[+human, +living, -female,?], then masculine 
gender is returned. Otherwise, if [+human, 
+living,?] is present, but there is no explicit men-
tion of +female or ?female, it defaults to honorific 
suffix. In all other cases, neuter gender is returned.  
4.3.3 Adding adjectives and adverbs 
The Sentence Generator module using the selec-
tional restriction rules can only create sentences of 
the form ?[subject] [object] [verb]?. However, 
typical lyrics will not always contain just three 
word sentences and thus, the ability to put more 
words in a sentence generated by our system is 
required. In such cases, a look-up list of adjectives 
and adverbs is used for filling the additional words 
required by the syllable pattern. This look-up list is 
generated from a POS-tagged text corpus from 
which the list of adjective-noun, adverb-verb bi-
grams are added to the look-up list. Whenever a 
sentence needs more than three words, this look-up 
list is consulted to generate sentences that add the 
relevant adjectives to subject or object nouns and 
relevant adverbs before the verb. Each possible 
combination of such sentences is generated and 
added to the list of sentences.   
4.3.4 Word repetition 
An additional approach to handle lines with more 
than three words is to repeat certain words already 
present in the ?[subject] [object] [verb]? output. If 
an adjective or adverb is already added to the sen-
tence, then preference for repetition is given to the 
adjective/adverb subject to the constraints of the 
input asai scheme. Otherwise, the verb is chosen 
for repetition. Finally, the subject and object nouns 
are considered.  
5 Experiments 
The goal of the experiment was to validate whether 
the sentences generated using the Knowledge-
based approach are more grammatical and mea-
ningful than the n-Gram approach. In order to test 
this hypothesis, a set of 10 syllable patterns was 
given to the old n-Gram system and 30 sentences 
were generated from them. The new knowledge-
based approach was also given the syllable patterns 
and the resulting 32 sentences were collected. In 
order to avoid any bias, these 62 sentences were 
interleaved in a single document and this document 
was given to five human evaluators for scoring 
each sentence. The scoring methodology is as fol-
lows: 
Score Meaning 
1 Incorrect 
2 Grammatically perfect, but no mean-
ing at all 
3 Grammatically correct but only par-
tially meaningful 
4 Both Grammar and Meaning are only 
partially correct 
5 Perfect 
Table 6. Scoring methodology 
Based on the scores given by the human evalua-
tors, the sentences generated using the n-Gram ap-
37
proach scored an average of 2.06, whereas the sen-
tences generated using the knowledge-based ap-
proach scored an average of 4.13. This clearly de-
monstrates that the new approach results in consis-
tently more grammatical and meaningful sen-
tences.  
A break-down of statistics based on the scores giv-
en by each evaluator is given below (Table 7): 
E-1 E-2 E-3 E-4 E-5 
Avg. Score 
(KB)*
4.5 4.38 4.06 4.09 3.63 
Avg. Score (n-
G) *
2.37 1 3.3 2.13 1.5 
# Sentences 
scoring 5 (KB) 
25 25 23 20 14 
# Sentences 
scoring 5 (n-G) 
6 0 14 1 0 
# Sentences 
scoring 1 (KB) 
2 0 7 4 7 
# Sentences 
scoring 1 (n-G) 
16 30 11 19 25 
Table 7. Detailed Statistics 
*KB = Knowledge-based approach and n-G = n-
Gram based approach. 
A subset of syllable patterns given to the system 
and the sentences generated by the system are giv-
en below: 
Input NM KKMKMKMK 
KMNM 
Intermediate Form Ne NiNeNeNe NeNe 
Sentences 
(nAm-we arangathukku-stadium  vanthOm-came) 
(We came to the stadium) 
(nee-You siraichAlaikku-prison vanthAi-came) 
(You came to the prison) 
Input NN KKNN NMNM 
Intermediate Form NeNe NiNeNe NeNe 
Sentences 
(* rAjA-King  nadanathai-dance  kEttAr-listen) 
(The King listened to the dance) 
(neengal-You  piditheergal-caught  kaiyai-hand) 
(You caught the hand) 
Here, the sentence ?rAjA-King  nadanathai-dance  
kEttAr-listened? (The King listened to the dance) is  
generated due to the fact that the noun dance is 
taken from the Ontology node ?content? that also 
contains nouns for music, drama, etc. for which the 
verb listen matches perfectly. Thus, this semanti-
cally meaningless sentence is generated due to the 
present sub-categorization levels of the nouns On-
tology. In addition to this, Ontology based genera-
tion can also create semantically meaningless sen-
tences when a verb has more than one sense and 
the appropriate sense is not taken into considera-
tion. 
The next sentence ?neengal-You  piditheergal-
caught  kaiyai-hand? (You caught the hand) is an 
example of a sentence in which the verb and object 
noun were re-ordered to match the input pattern. 
6 Limitations and Future Work  
From the initial set of experiments, we see that the 
knowledge-based approach results in generating 
grammatically correct and mostly meaningful sen-
tences. Also, unlike the Edit Distance algorithm, 
the new asai representation scheme consistently 
provides valid choices and alternatives for syllable 
patterns, thus resulting in better coverage. 
We are also currently working on introducing co-
hesion across multiple lines of the verse by (a) 
grouping related verbs, (b) using semantically re-
lated verbs (such as Synonym, Antonym, Hy-
ponym, etc.) from previous sentences and (c) pick-
ing rules that can result in using the same subject 
or object. 
The main drawback of the current knowledge-
based approach is the lack of poetic sentences and 
hence the poetic aspect of the verse needs im-
provement. Although we attempt to introduce 
structural poeticness by rhyme and repetition, the 
content aspect of the poem remains a bottleneck 
given our approach of using selectional restriction 
rules that does not lend well for figurative sen-
tences. 
38
References  
Ananth Ramakrishnan, Sankar Kuppan, and Sobha Lali-
tha Devi. 2009. Automatic Generation of Tamil Lyr-
ics for Melodies. Proceedings of the Workshop on 
Computational Approaches to Linguistic Creativity, 
CALC'09, Boulder, Colorado:40-46. 
Arulmozhi P, Sobha. L. 2006. Semantic Tagging for 
Language Processing. 34th All India conference for 
Dravidian Linguistics (June 22-24, 2006), Trivan-
drum, India. 
Bala Sundara Raman L, Ishwar S, and Sanjeeth Kumar 
Ravindranath. 2003. Context Free Grammar for Nat-
ural Language Constructs ? An implementation for 
Venpa Class of Tamil Poetry. 6th International Tamil 
Internet Conference and Exhibition, Tamil Internet 
2003 (August 22-24, 2003), Chennai, India. 
Guido Gonzato. 2003. The ABCPlus Project
http://abcplus.sourceforge.net. 
Hisar Maruli Manurung. 2004. An evolutionary ap-
proach to poetry generation. Ph.D. Thesis, Universi-
ty of Edinburg. 
Menaka S, Vijay Sundar Ram, and Sobha Lalitha Devi. 
2010. Morphological Generator for Tamil. Proceed-
ings of the Knowledge Sharing event on Morpholog-
ical Analysers and Generators (March 22-23, 2010), 
LDC-IL, Mysore, India:82-96. 
Rajam V.S. 1992. A Reference Grammar of Classical 
Tamil Poetry (150 B.C.-pre-5th/6th century A.D.). 
Memoirs of the American Philosophical Society, 
Philadelphia: 113-240. 
Tholkaappiyar. 5th Century B.C. Tholkaapiyam - 
http://www.tamil.net/projectmadurai/pub/pm0100/tol
kap.pdf. 
39
Proceedings of the 4th International Workshop on Cross Lingual Information Access at COLING 2010, pages 11?15,
Beijing, August 2010
How to Get the Same News from Different Language News 
Papers 
T. Pattabhi R. K Rao 
AU-KBC Research Centre 
Anna University Chennai 
 
Sobha Lalitha Devi 
AU-KBC Research Centre 
Anna University Chennai  
sobha@au-kbc.org 
 
Abstract 
This paper presents an ongoing work on 
identifying similarity between documents 
across News papers in different 
languages. Our aim is to identify similar 
documents for a given News or event as 
a query, across languages and make cross 
lingual search more accurate and easy. 
For example given  an event or News in 
English, all the English news documents 
related to the query are retrieved as well 
as in other languages such as Hindi, 
Bengali, Tamil, Telugu, Malayalam, 
Spanish. We use Vector Space Model, a 
known method for similarity calculation, 
but the novelty is in identification of 
terms for VSM calculation. Here a robust 
translation system is not used for 
translating the documents. The system is 
working with good recall and precision. 
1 Introduction 
In this paper we present a novel method for 
identifying similar News documents from 
various language families such as Indo-
European, Indo- Aryan and Dravidian. The 
languages considered from the above language 
families are English, Hindi, Bengali, Tamil, 
Telugu, Malayalam and Spanish. The News 
documents in various languages are obtained 
using a crawler. The documents are represented 
as vector of terms. 
 Given a query in any of the language mentioned 
above, the documents relevant to the query are 
retrieved. The first two document retrieved in the 
language of the query is taken as base for the 
identification of similar documents. The 
documents are converted into terms and the 
terms are translated to other languages using 
bilingual dictionaries. The terms thus obtained is 
used for similarity calculation. The paper is 
further organized as follows.  In the following 
section 2, related work is described. In section 3, 
the algorithm is discussed. Section 4 describes 
experiments and results.  The paper concludes 
with section 5. 
2 Related Work 
In the past decade there has been significant 
amount of work done on finding similarity of 
documents and organizing the documents 
according to their content. Similarity of 
documents are identified using different methods 
such as Self-Organizing Maps (SOMs) 
(Kohonen et al 2000; Rauber, 1999), based on 
Ontologies and taxanomy (Gruber, 1993; Resnik, 
1995), Vector Space Model (VSM) with 
similarity measures like Dice similarity, 
Jaccard?s similarity, cosine similarity (Salton, 
1989). 
    Many similarity measures were developed, 
such as information content (Resnik, 1995) 
mutual information (Hindle, 1990), Dice 
coefficient (Frakes and Baeza-Yates, 1992), 
cosine coefficient (Frakes and Baeza-Yates, 
1992), distance-based measurements (Lee et al, 
1989; Rada et al, 1989), and feature contrast 
model (Tversky, 1977). McGill etc. surveyed 
and compared 67 similarity measures used in 
information retrieval (McGill et al, 1979). 
11
3 Methodology 
Similarity is a fundamental concept. Two 
documents can be said to be similar if both the 
documents have same content, describing a topic 
or an event or an entity. Similarity is a measure 
of degree of resemblance, or commonality 
between the documents. 
    In this work we have used Vector Space 
Model (VSM) for document representation. In 
VSM the documents are represented as vectors 
of unique terms. Here we have performed 
experiments by creating three types of document 
vector space models. In the first case we have 
taken all unique words in the document 
collection for vector of terms. In the second case 
we take the terms after removing all stop words. 
In the third case we have taken a sequence of 
words as terms. After the document model is 
built we use cosine similarity measure to identify 
the degree of similarity between documents.  
    In this work we have taken documents from 
the languages mentioned in the previous section. 
For the purpose of identifying similar documents 
across the languages we use map of term vectors 
of documents from English to other languages. 
Using the term vector map we can identify 
similar documents for various languages. 
3.1 Similarity analyser 
    The main modules are i) Document vector 
creator ii) Translator and iii) Similarity 
identifier.  
a) Document Vector Creator: Each document 
is represented as vector of terms. Here we take 
three types of term vectors. In the first type a 
single word is taken as a term which is the 
standard implementation of VSM. In the second 
type single words are taken but the stop words 
are removed. 
    In the third type each term is a sequence of 
words, where we define the number of words in 
the sequence as 4. This moving window of 4 is 
obtained by performing many experiments using 
different combinations of words. So our term of 
vector is defined as a set of four consecutive 
words, where the last three words in the 
preceding sequence is considered as the first 
three words in the following sequence. For 
example if a sentence has 10 words (w), the 
vector of terms for this sentence is w1w2w3w4, 
w2w3w4w5, w3w4w5w6, w4w5w6w7, 
w5w6w7w8, w6w7w8w9, w7w8w9w10. The 
weights of the terms in the vector are the term 
frequency and inverse document frequency (tf-
idf). While creating document vectors, for Indian 
languages which are highly agglutinative and 
morphologically rich we use morphological 
analyzer to reduce the word into its root and it is 
used for document vector creation.  
    The first two experiments are the standard 
VSM implementation. The third experiment 
differs in the way the terms are taken for 
building the VSM. For building the VSM model 
which is common for all language document 
texts, it is essential that there should be 
translation/transliteration tool. First the terms are 
collected from individual language documents 
and a unique list is formed. The unique list of 
words is then translated using the translator 
module.  
b) Word by Word Translator: In this module, 
the terms from English documents are taken and 
are translated to different languages. The 
translation is done word by word with the use of 
bilingual and multilingual synset dictionaries. 
This translation creates a map of terms from 
English to different languages. We have used 
bilingual dictionaries from English to Spanish, 
Hindi, Tamil, Telugu, and Malayalam 
dictionaries. Also we have used multilingual 
synset dictionaries for English, Tamil, Telugu, 
Hindi, and Malayalam. For each pair of bilingual 
dictionaries there are more than 100K root 
words. Since in this work we do not require 
syntactically and semantically correct translation 
of the sentences we adopted word to word 
translation. Hence we did not use any other 
system such as SMT for English to Indian 
languages. Named entities require transliteration. 
Here we have used a transliteration tool. This 
tool uses rule based approach, based on the 
phoneme match.  The transliteration tool 
produces all possible transliteration outputs. 
Here we take into consideration the top five best 
possible outputs. For example the name ?Lal 
Krishna Advani? would get transliterations in 
Indian languages as ?laala krishna athvaani?, 
?laala krishna advaani?.  
     c) Similarity Identifier: The similarity 
identifier module takes the query in the form 
document as input and identifies all relevant 
12
documents. The similarity identifier uses cosine 
similarity measure over documents vector 
creator. The cosine similarity measure is the dot 
product of two vectors and is between 0 and 1 
value. The more it is closer to 1, the similarity is 
more.  The formula of cosine similarity is as 
follows: 
            Sim(S1,S2)tj = ? (W1j x W2j ) -- (1) 
Where, 
  tj is a term present in both vectors S1and S2. 
  W1j is the weight of term tj in S1 and 
  W2j is the weight of term tj in S2. 
 
The weight of term tj in the vector S1 is 
calculated by the formula given by equation (2), 
below. 
 
Wij=(tf*log(N/df))/[sqrt(Si12+Si22+?+Sin2)]                                                            
                                                           --(2) 
Where, 
  tf = term frequency of term tj  
  N=total number of documents in the collection 
  df = number of documents in the collection that 
          the term tj occurs in. 
  sqrt represents square root 
The denominator 
  [sqrt(Si12+Si22+??+Sin2)] is the cosine 
normalization factor. This cosine normalization 
factor is the Euclidean length of the vector Si, 
where ?i? is the document number in the 
collection and Sin2 is the square of the product 
of (tf*log(N/df)) for term  in the vector Si. 
4 Experiments and Results 
We have performed three experiments with two 
different data sets. The first data set was 
collected by crawling the web for a single day?s 
news articles and obtained 1000 documents from 
various online news magazines in various 
languages. The test set was taken from Times of 
India, The Hindu for English, BBC, Dinamani, 
Dinamalar for Tamil, Yahoo for Telugu, 
Matrubhumi for Malayalam, BBC and Dainik 
Jagran for Hindi and BBC for Spanish. The 
distribution of documents in the first set for 
various languages is as follows: 300 English, 
200 Tamil, 150 Telugu, 125 Hindi, 125 
Malayalam, 50 Spanish. The figure 1 given 
below shows the language distribution in this 
first set.  
The number of similar documents were 600 in 
this set.  
English
Tamil
Telugu
Hindi
Malyalam
Spanish
 
Figure 1. Data Distribution of Set 1 
    In the second data set we have taken news 
documents of one week time duration. This 
consisted of 9750 documents. The language 
distribution for this data set is shown in figure 2. 
This second data set consisted of 5350 similar 
documents.  
        
English
Tamil
Telugu
Hindi
Malayalam
Spanish
      
Figure 2. Data Distribution of Set 2 
In the first experiment we took all the unique 
words (separated by white space) as terms for 
building the document vector. In the second 
experiment the terms taken were same as the 
first experiment, except that all the stop words 
were removed. In the third experiment, the terms 
taken for document vector creation were four 
consecutive words.  The results obtained for 
three experiments for data set 1 is shown in 
Table 1. And results for data set 2 are shown in 
Table 2.  Table 3 shows the similarity 
identification for various languages. 
    Here we take a news story document as a 
query and perform similarity analysis across all 
documents in the document collection to identify 
similarly occurring news stories. In the first data 
set in the gold standard there are 600 similar 
pairs of documents. And in the second data set 
there are 5350 similar pairs of documents in the 
gold standard. 
    It is observed that even though there were 
more similar documents which could have been 
identified, but the system could not identify 
those documents. The cosine measure for those  
13
unidentified documents was found to be lower 
than 0.8. We have taken 0.8 as the threshold for 
documents to be considered similar. In the 
documents which were not identified by the 
system, the content described consisted of less 
number of words. These were mostly two 
paragraph documents; hence the similarity score 
obtained was less than the threshold. In 
experiment three, we find that the number of 
false positives is decreased and also the number 
of documents identified similar is increased. This 
is because, in this case the system sees for terms 
of four words and hence single word matches are 
reduced. This reduces false positives. The other 
advantage of this is the words get the context, in 
a sense that the words in each sequence are not 
independent. The words get an order and are 
sensitive to that order. This solves sense 
disambiguation. Hence we find that it is solving 
the polysemy problem to some extent.  The 
system can be further improved by creating 
robust map files between terms in different 
languages. The bilingual dictionaries also need 
to be improved. 
    In our work, since we are using a sequence of 
words as terms for document vectors, we do not 
require proper, sophisticated translation systems. 
A word by word translation would suffice to get 
the desired results.  
 
 
Table 1. Similarity Results on Data Set 1 
 
Table 2. Similarity Results on Data Set 2  
    Table 3.Similarity Results Data Set with Ex:3 
5 Conclusion 
Here we have shown how we can identify 
similar News document in various languages. 
The results obtained are encouraging; we obtain 
an average precision of 97.8% and recall of 
94.3%. This work differs from previous works in 
two aspects: 1) no language preprocessing of the 
documents is required and 2) terms taken for 
VSM are a sequence of four words.  
References 
Frakes, W. B. and Baeza-Yates, R., editors 1992. 
Information Retrieval, Data Structure and 
Algorithms. Prentice Hall. 
T. R. Gruber. 1993. A translation approach to 
portable ontologies, Knowledge Acquisition, 
5(2):199?220. 
Hindle, D. 1990. Noun classification from predicate-
argument structures. In Proceedings of  ACL-90, 
pages 268?275, Pittsburg, Pennsylvania. 
Kohonen, Teuvo Kaski, Samuel Lagus, Krista 
Salojarvi, Jarkko Honkela, Jukka Paatero,Vesa 
Saarela, Anti.  2000. Self organisation of a massive 
document collection, IEEE Transactions on Neural 
Networks, 11(3): 574-585. 
Lee, J. H., Kim, M. H., and Lee, Y. J. 1989. 
Information retrieval based on conceptual distance 
in is-a hierarchies. Journal of Documentation, 
49(2):188?207. 
McGill et al, M. 1979. An evaluation of factors 
affecting document ranking by information 
retrieval systems. Project report, Syracuse 
University School of Information Studies. 
Rauber, Andreas Merkl, Dieter. 1999. The SOMLib 
digital library system,  In the Proceedings of the 
3rd European Conference on Research and 
Advanced Technology for Digital Libraries 
(ECDL'99), Paris, France. Berlin: 323-341. 
Lang Gold 
Std 
similar 
docs 
System 
Identifi
ed 
correct 
System 
Identifi
ed 
wrong 
Prec 
% 
Rec 
% 
Eng 1461 1377 30 97.86 94.25 
Span 732 690 15 97.87 94.26 
Hin 588 554 11 98.05 94.22 
Mal 892 839 19 97.78 94.05 
Tam 932 880 22 97.56 94.42 
Tel 745 703 17 97.63 94.36 
AVG 97.79 94.26 
Exp 
No 
Gold std 
Similari
ty 
System 
Identified 
Correct 
System 
Identified 
Wrong 
Pre
c 
% 
Rec 
% 
1 600 534 50 91.4 89.0 
2 600 547 44 92.5 91.2 
3 600 565 10 98.3 94.2 
Exp 
No 
Gold 
Standard 
Similarity 
System 
Identified 
Correct 
System 
Identifi
ed 
Wrong 
Prec 
% 
Rec 
% 
1 5350 4820 476 91.0 90.0 
2 5350 4903 410 92.3 91.6 
3 5350 5043 114 97.8 94.3 
14
Rada, R., Mili, H., Bicknell, E., and Blettner, M. 
1989. Development and application of a metric on 
semantic nets. IEEE Transaction on Systems, Man, 
and Cybernetics, 19(1):17?30. 
P. Resnik. 1995. Using information content to 
evaluate semantic similarity in taxonomy, 
Proceedings of IJCAI: 448?453. 
Salton, Gerald. 1989. Automatic Text Processing: The 
Transformation, Analysis and Retrieval of 
Information by Computer, Reading, MA: Addison 
Wesley 
Tversky, A. 1977. Features of similarity. 
Pychological Review, 84:327?352. 
 
 
15
Proceedings of the 15th Conference on Computational Natural Language Learning: Shared Task, pages 93?96,
Portland, Oregon, 23-24 June 2011. c?2011 Association for Computational Linguistics
Hybrid Approach for Coreference Resolution 
 
 
First Author: Sobha, Lalitha Devi., Pattabhi, RK Rao., Vijay Sundar Ram, R. 
Second Author: Malarkodi, CS., Akilandeswari, A. 
AU-KBC Research Centre, 
MIT Campus of Anna University, 
Chrompet, Chennai, India. 
sobha@au-kbc.org 
 
 
 
 
 
 
Abstract 
This paper describes our participation in 
the CoNLL-2011 shared task for closed 
task. The approach used combines refined 
salience measure based pronominal 
resolution and CRFs for non-pronominal 
resolution. In this work we also use 
machine learning based approach for 
identifying non-anaphoric pronouns. 
1 Introduction 
In this paper we describe our system, used in the 
CoNLL-2011 shared task ?Modeling Unrestricted 
Coreference in OntoNotes?. The goal of this task is 
to identify coreference chains in a document. The 
coreference chains can include names, nominal 
mentions, pronouns, verbs that are coreferenced 
with a noun phrases.  
The coreferents are classified into two types, 
pronominal and non-pronominal referents. We use 
two different approaches using machine learning 
and salience factor in the resolution of the above 
two types. Pronominal resolution is done using 
salience factors and Non-Pronominals using 
machine learning approach. Pronominal resolution 
refers to identification of a Noun phrase (NP) that 
is referred by a pronominal and Non-Pronominals 
are NP referring to another NP. In the next section 
we describe the system in detail. 
2 System Description 
In this section we give a detailed description of our 
system. The task is divided into two sub-tasks. 
They are 
    i) Pronominal resolution 
   ii) Non-pronominal resolution 
2.1 Pronominal Resolution 
Here we have identified salience factors and 
assigned weights for each factor.  Before resolving 
the pronouns we identify whether a given pronoun 
is anaphoric or not. In example, (1) below, the 
pronoun ?It?, does not refer to any entity, and it is 
a pleonastic ?it?. 
(1) ?It will rain today? 
In identifying the non-anaphoric pronouns such 
as ?it? we use a CRFs engine, a machine learning 
approach. We build a language model using the 
above ML method to identify the non-anaphoric 
pronouns and the features used in training are word 
and it?s POS in a window of five (two preceding 
and two following words to the pronoun). After the 
non-anaphoric pronoun identification, we resolve 
the anaphoric pronouns using a pronominal 
resolution system. Though we use salience factors 
based on the Lappin and Leass (1994), we have 
substantially deviated from the basic algorithm and 
have also used factors from Sobha (2008), where 
named entity and ontology are considered for 
resolution. 
For identifying an antecedent for a pronoun we 
consider all the noun phrases before the pronoun in 
93
the current sentence and in the four sentences 
preceding the current sentence. Those noun 
phrases which agree in PNG with the pronoun are 
considered as the possible candidates. The PNG is 
obtained using the gender data work of Shane 
Bergsma and Dekang Lin (2006). The possible 
candidates are scored based on the salience factors 
and ranked. The salience factors considered here 
are presented in the table 1. 
 
Salience Factors Weights 
Current Sentence 
(sentence in which 
pronoun occurs) 
100 
For the preceding 
sentences up to four 
sentences from the 
current sentence 
Reduce sentence score 
by 10 
Current Clause 
(clause in which 
pronoun occurs) 
100 ? for possessive 
pronoun 
50 ? for non-possessive 
pronouns  
Immediate Clause 
(clause preceding or 
following the current 
clause) 
50 ? for possessive  
pronoun 
100 ? for non-
possessive pronouns 
Non-immediate 
Clause (neither the 
current or immediate 
clause) 
50 
Possessive NP 65 
Existential NP 70 
Subject 80 
Direct Object 50 
Indirect Object 40 
Compliment of PP 30 
  
Table 1: Salience Factors and weights 
 
Improving pronominal resolution Using Name 
Entity (NE) and WordNet: Pronouns such as 
?He?, ?She?, ?I? and ?You? can take antecedents 
which are animate and particularly having the NE 
tag PERSON. Similarly the pronoun ?It? can never 
take an animate as the antecedent. From the 
WordNet we obtain the information of noun 
category such as ?person?, ?object?, ?artifact?, 
?location? etc. Using the NE information provided 
in the document and the category information in 
WordNet, the irrelevant candidates are filtered out 
from the possible candidates. Thus the antecedent 
and pronoun category agrees. 
The highest ranked candidate is considered as 
the antecedent for the particular pronoun. 
In TC and BC genres, the pronouns ?I? and 
?you? refer to the speakers involved in the 
conversation. For these pronouns we identify the 
antecedent using heuristic rules making use of the 
speaker information provided. 
2.2 Non-pronominal Coreference resolution 
In identifying the Non-pronominal as said earlier, 
we have used a CRFs based machine learning 
approach. CRFs are well known for label 
sequencing tasks such as Chunking, Named Entity 
tagging (Lafferty et al 2001; Taku Kudo 2005). 
Here we have CRFs for classification task, by 
using only the current state features and not the 
features related to state transition. The features 
used for training are based on Soon et al(2001). 
We have changed the method of deriving, values 
of the features such as String match, alias, from the 
Soon el al method and found that our method is 
giving more result.  The features used in our work 
are as follows. 
a) Distance feature ? same as in Soon et al
b) Definite NP - same as in Soon et al
c) Demonstrative NP ? same as in Soon et al
d) String match ? (Not as Soon et althe possible 
values are between 0 and 1. This is calculated as 
ratio of the number of words matched between the 
NPs and the total number of words of the anaphor 
NP. Here we consider the NP on the left side as 
antecedent NP and NP on the right side as anaphor 
NP. 
e) Number Agreement ? We use the gender data 
file (Bergsma and Lin, 2006) and also the POS 
information 
f) Gender agreement ? We use the gender data 
file (Bergsma and Lin, 2006) 
g) Alias feature ? (Not as in Soon et al the alias 
feature takes the value 0 or 1. This is obtained 
using three methods, 
     i) Comparing the head of the NPs, if both are 
same then scored as 1 
     ii) If both the NPs start with NNP or NNPS 
POS tags, and if they are same then scored as 1 
     iii) Looks for Acronym match, if one is an 
acronym of other it is scored as 1 
h) Both proper NPs ? same as Soon et al  
i )  NE tag information. 
94
The semantic class information (noun category) 
obtained from the WordNet is used for the filtering 
purpose. The pairs which do not have semantic 
feature match are filtered out. We have not used 
the appositive feature described in Soon et al
(2001), since we are not considering appositives 
for the coreference chains.  
The feature template for CRF is defined in such 
a way that more importance is given to the features 
such as the string match, gender agreement and 
alias feature. The data for training is prepared by 
taking all NPs between an anaphor and antecedent 
as negative NPs and the antecedent and anaphor as 
positive NP. 
The core CRFs engine for Non-pronominal 
resolution system identifies the coreferring pairs of 
NPs. The Coreferring pairs obtained from 
pronominal resolution system and Non-pronominal 
system are merged to generate the complete 
coreference chains. The merging is done as 
follows: A member of a coreference pair is 
compared with all the members of the coreference 
pairs identified and if it occurs in anyone of the 
pair, then the two pairs are grouped.  This process 
is done for all the members of the identified pairs 
and the members in each group are aligned based 
on their position in the document to form the chain. 
3 Evaluation   
In this section we present the evaluation of the 
complete system, which was developed under the 
closed task, along with the independent evaluation 
of the two sub-modules. 
a) Non-anaphoric detection modules 
b) Pronominal resolution module 
The data used for training as well as testing was 
provided CoNLL-2001 shared task (Pradhan et al, 
2011), (Pradhan et al, 2007) organizers. The 
results shown in this paper were obtained for the 
development data. 
The non-anaphoric pronoun detection module is 
trained using the training data. This module was 
evaluated using the 91files development data. The 
training data contained 1326 non-anaphoric 
pronouns. The development data used for 
evaluation had 160 non-anaphoric pronouns. The 
table 2 shows the evaluation, of the non-anaphoric 
pronoun detection module. 
The Pronominal resolution module was also 
evaluated on the development data. The filtering of 
non-anaphoric pronouns helped in the increase in 
precision of the pronoun resolution module. The 
table 3 shows the evaluation of pronoun resolution 
module on the development data. Here we show 
the results without the non-anaphor detection and 
with non-anaphor detection. 
 
Type of 
pronoun 
Actual 
(gold 
standard
) 
System 
identified 
Correctly 
Accuracy 
(%) 
Anaphoric 
Pronouns 
939 908 96.6 
Non-
anaphoric 
pronouns 
160 81 50.6 
Total 1099 989 89.9 
   Table 2: Evaluation of Non-anaphoric pronoun 
 
System 
type 
Total 
Anap
horic 
Pron
ouns 
System 
identifi
ed 
pronou
ns 
System 
correctl
y 
Resolv
ed 
Pronou
ns 
Prec
isio
n 
(%) 
Without 
non-
anaphoric 
pronoun 
detection 
939 1099 693 63.1 
With non-
anaphoric 
pronoun 
detection 
939 987 693 70.2 
  Table 3: Evaluation of Pronominal resolution    
module 
 
The output of the Non-pronominal resolution 
module, merged with the output of the pronominal 
resolution module and it was evaluated using 
scorer program of the CoNLL-2011. The 
evaluation was done on the development data, 
shown in the table 4. 
On analysis of the output we found mainly three 
types of errors. They are 
 
a) Newly invented chains ? The system identifies 
new chains that are not found in the gold standard 
annotation. This reduces the precision of the 
95
system. This is because of the string match as one 
of the features. 
 
Metri
c 
Mention 
Detection 
Coreference 
Resolution 
Rec  Prec F1 Rec Prec F1 
MUC 68.1 61.5 64.6 52.1 49.9 50.9 
BCU
BED 
68.1 61.5 64.6 66.6 67.6 67.1 
CEA
FE 
68.1 61.5 64.6 42.8 44.9 43.8 
Avg 68.1 61.5 64.6 53.8 54.1 53.9 
Table 4: Evaluation of the Complete System 
 
b) Only head nouns in the chain ? We observed 
that system while selecting pair for identifying 
coreference, the pair has only the head noun 
instead of the full phrase. In the phrase ?the letters 
sent in recent days?, the system identifies ?the 
letters? instead of the whole phrase. This affects 
both the precision and recall of the system. 
c) Incorrect merging of chains ? The output 
chains obtained from the pronominal resolution 
system and the non-pronominal resolution system 
are merged to form a complete chain. When the 
antecedents in the pronominal chain are merged 
with the non-pronominal chains, certain chains are 
wrongly merged into single chain. For example 
?the chairman of the committee? is identified as 
coreferring with another similar phrase ?the 
chairman of executive board? by the non-
pronominal resolution task. Both of these are 
actually not referring to the same person. This 
happens because of string similarity feature of the 
non-pronominal resolution. This merging leads to 
building a wrong chain. Hence this affects the 
precision and recall of the system. 
4 Conclusion 
We have presented a coreference resolution system 
which combines the pronominal resolution using 
refined salience based approach with non-
pronominal resolution using CRFs, machine 
learning approach. In the pronominal resolution, 
initially we identify the non-anaphoric pronouns 
using CRFs based technique. This helps in 
improving the precision. In non-pronominal 
resolution algorithm, the string match feature is an 
effective feature in identifying coreference. But, 
this feature is found to introduce errors. We need 
to add additional contextual and semantic feature 
to reduce above said errors.  The results on the 
development set are encouraging.  
References  
Shane Bergsma, and Dekang Lin. 2006. Bootstrapping 
Path-Based Pronoun Resolution. In Proceedings of 
the Conference on Computational Lingustics / 
Association for Computational Linguistics 
(COLING/ACL-06), Sydney, Australia, July 17-21, 
2006. 
John Lafferty, Andrew McCallum, Fernando Pereira.   
2001. Conditional Random Fields: Probabilistic  
Models for Segmenting and Labeling Sequence Data.   
In Proceedings of the Eighteenth International   
Conference on Machine Learning (ICML-2001).  
282-289. 
S. Lappin and H. Leass. 1994. An Algorithm for 
Pronominal Anaphora Resolution. Computational 
Linguistics, 20(4):535?562, 1994. 
Sameer Pradhan, Lance Ramshaw, Mitchell Marcus, 
Martha Palmer, Ralph Weischedel, Nianwen Xue. 
2011. CoNLL-2011 Shared Task: Modeling 
Unrestricted Coreference in OntoNotes. In 
Proceedings of the Fifteenth Conference on 
Computational Natural Language Learning (CoNLL 
2011). 
Sameer Pradhan and Lance Ramshaw and Ralph 
Weischedel and Jessica MacBride and Linnea 
Micciulla. 2007. Unrestricted Coreference: 
Identifying Entities and Events in OntoNotes. In 
Proceedings of the IEEE International Conference on 
Semantic Computing (ICSC)". Irvine, CA, 
September 17-19, 2007.  
Sobha, L. 2008. Anaphora Resolution Using Named 
Entity and Ontology. In Proceedings of the Second 
Workshop on Anaphora Resolution (WAR II), Ed 
Christer Johansson, NEALT Proceedings Series, Vol. 
2 (2008) Estonia. 91-96. 
W. M. Soon, H. T. Ng, and D. C. Y. Lim. 2001. A 
Machine Learning Approach to Coreference 
Resolution of Noun Phrases. Computational 
Linguistics, 27(4):521?544. 
Taku Kudo. 2005. CRF++, an open source toolkit for   
CRF, http://crfpp.sourceforge.net . 
96
Proceedings of the 2014 Joint Meeting of SIGMORPHON and SIGFSM, pages 37?45,
Baltimore, Maryland USA, June 27 2014. c?2014 Association for Computational Linguistics
Automatic Conversion of Dialectal Tamil Text to Standard Written 
Tamil Text using FSTs 
 
Marimuthu K 
AU-KBC Research Centre, 
MIT Campus of Anna University, 
Chrompet, Chennai, India. 
marimuthuk@live.com 
Sobha Lalitha Devi 
AU-KBC Research Centre, 
MIT Campus of Anna University, 
Chrompet, Chennai, India. 
sobha@au-kbc.org 
 
  
 
Abstract 
We present an efficient method to auto-
matically transform spoken language text 
to standard written language text for var-
ious dialects of Tamil. Our work is novel 
in that it explicitly addresses the problem 
and need for processing dialectal and 
spoken language Tamil. Written language 
equivalents for dialectal and spoken lan-
guage forms are obtained using Finite 
State Transducers (FSTs) where spoken 
language suffixes are replaced with ap-
propriate written language suffixes. Ag-
glutination and compounding in the re-
sultant text is handled using Conditional 
Random Fields (CRFs) based word 
boundary identifier. The essential Sandhi 
corrections are carried out using a heuris-
tic Sandhi Corrector which normalizes 
the segmented words to simpler sensible 
words. During experimental evaluations 
dialectal spoken to written transformer 
(DSWT) achieved an encouraging accu-
racy of over 85% in transformation task 
and also improved the translation quality 
of Tamil-English machine translation 
system by 40%. It must be noted that 
there is no published computational work 
on processing Tamil dialects. Ours is the 
first attempt to study various dialects of 
Tamil in a computational point of view. 
Thus, the nature of the work reported 
here is pioneering. 
1 Introduction 
With the advent of Web 2.0 applications, the fo-
cus of communication through the Internet has 
shifted from publisher oriented activities to user 
oriented activities such as blogging, social media 
chats, and discussions in online forums. Given 
the unmediated nature of these services, users 
conveniently share the contents in their native 
languages in a more natural and informal way. 
This has resulted in bringing together the con-
tents of various languages. More often these con-
tents are informal, colloquial, and dialectal in 
nature. The dialect is defined as a variety of a 
language that is distinguished from other varie-
ties of the same language by features of phonol-
ogy, grammar, and vocabulary and by its use by 
a group of speakers who are set off from others 
geographically or socially. The dialectal varia-
tion refers to changes in a language due to vari-
ous influences such as geographic, social, educa-
tional, individual and group factors. The dialects 
vary primarily based on geographical locations. 
They also vary based on social class, caste, 
community, gender, etc. which differ phonologi-
cally, morphologically, and syntactically (Ha-
bash and Rambow, 2006). Here we study spoken 
and dialectal Tamil language and aim to auto-
matically transform them to standard written lan-
guage. 
Tamil language has more than 70 million 
speakers worldwide and is spoken mainly in 
southern India, Sri Lanka, Singapore, and Ma-
laysia. It has 15 known dialects 1  which vary 
mainly based on geographic location and reli-
gious community of the people. The dialects 
used in southern Tamil Nadu are different from 
the dialects prevalent in western and other parts 
of Tamil Nadu. Sri Lankan Tamil is relatively 
conservative and still retains the older features of 
Tamil2. So its dialect differs considerably from 
the dialects spoken elsewhere. Tamil dialect is 
also dependent on religious community. The var-
                                                 
1
http://en.wikipedia.org/wiki/Category:Tamil_dialects 
2 www.lmp.ucla.edu 
37
iation of dialects based on caste is studied and 
described by A.K. Ramanujan (1968) where he 
observed that Tamil Brahmins speak a very dis-
tinct form of Tamil known as Brahmin Tamil 
(BT) which varies greatly from the dialects used 
in other religious communities. While perform-
ing a preliminary corpus study on Tamil dialects, 
we found that textual contents in personal blogs, 
social media sites, chat forums, and comments, 
comprise mostly dialectal and spoken language 
words similar to what one can hear and use in 
day-to-day communication. This practice is 
common because the authors intend to establish a 
comfortable communication and enhance intima-
cy with their audiences. This activity produces 
informal, colloquial and dialectal textual data. 
These dialectal and spoken language usages will 
not conform to the standard spellings of Literary 
Tamil (LT). This causes problems in many text 
based Natural Language Processing (NLP) sys-
tems as they generally work on the assumption 
that the input is in standard written language. To 
overcome this problem, these dialectal and spo-
ken language forms need to be converted to 
Standard Written language Text (SWT) before 
doing any computational work with them. 
Computational processing of dialectal and 
spoken language Tamil is challenging since the 
language has motley of dialects and the usage in 
one dialect varies from other dialects from very 
minimal to greater extents. It is also very likely 
that multiple spoken-forms of a given word with-
in a dialect which we call as ?variants? may cor-
respond to single canonical written-form word 
and a spoken-form word may map to more than 
one canonical written-form. These situations ex-
ist in all Tamil dialects. In addition, it is very 
likely to encounter conflicts with the spoken and 
written-forms of one dialect with other dialects 
and vice versa. Most importantly, the dialects are 
used mainly in spoken communication and when 
they are written by users, they do not conform to 
standard spoken-form spellings and sometimes 
inconsistent spellings are used even for a single 
written-form of a word. In other words Schiff-
man (1988) noted that every usage of a given 
spoken-form can be considered as Standard Spo-
ken Tamil (SST) unless it has wrong spellings to 
become nonsensical. 
Few researchers have attempted to transform 
the dialects and spoken-forms of languages to 
standard written languages. Habash and Rambow 
(2006) developed MAGEAD, a morphological 
analyzer and generator for Arabic dialects where 
the authors made use of root+pattern+features 
representation for the transformation of Arabic 
dialects to Modern Standard Arabic (MSA) and 
performed morphological analysis. In the case of 
Tamil language, Umamaheswari et al. (2011) 
proposed a technique based on pattern mapping 
and spelling variation rules for transforming col-
loquial words to written-language words. The 
reported work considered only a handful of rules 
for the most common spoken forms. So this ap-
proach will fail when dialectal variants of words 
are encountered because it is more likely that the 
spelling variation rules of the spoken language 
vary from the rules of dialectal usages. This limi-
tation hinders the possibility of the system to 
generalize. Alternatively, performing a simple 
list based mapping between spoken and written 
form words is also inefficient and unattainable. 
Spoken language words exhibit fairly regular 
pattern of suffixations and inflections within a 
given paradigm (Schiffman, 1999). So we pro-
pose a novel method based on Finite State 
Transducers for effectively transforming dialec-
tal and spoken Tamil to standard written Tamil. 
We make use of the regularity of suffixations and 
model them as FSTs. These FSTs are used to 
perform transformation which produces words in 
standard literary Tamil. 
Our experimental results show that DSWT 
achieves high precision and recall values. In ad-
dition, it improves the translation quality of ma-
chine translation systems when unknown words 
occur mainly due to colloquialism. This im-
provement gradually increases as the unknown 
word rate increases due to colloquial and dialec-
tal nature of words. 
Broadly, DSWT can be used in a variety of 
NLP applications such as Morphological Analy-
sis, Rule-based and Statistical Machine Transla-
tion (SMT), Information Retrieval (IR), Named-
Entity Recognition (NER), and Text-To-Speech 
(TTS). In general, it can be used in any NLP sys-
tem where there is a need to retrieve written lan-
guage words from dialectal and spoken language 
Tamil words. 
The paper is further organized as follows: In 
section 2, the challenges in processing Tamil di-
alects are explained. Section 3 explains the cor-
pus collection and study. Section 4 explains the 
peculiarities seen in spoken and dialectal Tamil. 
Section 5 introduces the system architecture of 
DSWT. Section 6 describes conducted Experi-
mental evaluations and the results. Section 7 dis-
cusses about the results and the paper concludes 
with a conclusion section. 
38
2 Challenges in Processing Tamil Di-
alects 
Tamil, a member of Dravidian language family, 
is highly inflectional and agglutinative in nature. 
The phenomenon of agglutination becomes much 
pronounced in dialects and spoken-form com-
munication where much of the phonemes of suf-
fixes get truncated and form agglutinated words 
which usually have two or more simpler words in 
them. A comprehensive study on the Grammar 
of Spoken Tamil for various syntactic categories 
is presented in Schiffman (1979) and Schiffman 
(1999). Various dialects are generally used in 
spoken discourse and while writing them people 
use inconsistent spellings for a given spoken lan-
guage word. The spelling usages primarily de-
pend on educational qualification of the authors. 
Sometimes, the authors intentionally use certain 
types of spelling to express satire and humor. 
Due to this spelling and dialectal variation 
many-to-one mapping happens where all the va-
riants correspond to single canonical written 
form. This is illustrated with the dialectal and 
spelling variants of the verb ?paarkkiReen? (see) 
in Fig 1. 
 
Figure 1. many-to-one mapping 
 
For the words that belong to the above case, 
there is no hard rule that a particular pattern of 
spelling will be used and referred to while the 
text is written by people. In addition to this map-
ping, one-to-many mapping is also possible 
where a single spoken form maps to multiple 
canonical written forms. 
 
 
 
 
 
 
 
Figure 2. one-to-many mapping 
 
In the case of one-to-many mapping, multiple 
written language words will be obtained. Choos-
ing a correct written language word over other 
words is dependent on the context where the di-
alectal spoken language word occurs. In some 
cases, the sentence may be terminated by punc-
tuations such as question marks which can be 
made use of to select an appropriate written lan-
guage word. To achieve correct selection of a 
word, an extensive study has to be conducted and 
is not the focus of this paper. In the current work 
we are interested in obtaining as many possible 
mappings as possible. Many-to-one mapping 
occurs mainly due to dialectal and spelling varia-
tions of spoken-forms whereas one-to-many 
mapping happens because a single spoken-form 
may convey different meanings in different con-
texts. Dialectal spoken forms of many-to-one and 
one-to-many mappings are more prevalent than 
one-to-one mapping where a dialectal spoken 
form maps to exactly one written form word. 
3 Data Collection and Corpus Study 
The dialectal spoken form of a language is pri-
marily used for colloquial and informal commu-
nication among native speakers. They are also 
commonly seen in personal blogs, social media 
chats and comments, discussion forums etc. Giv-
en this informal nature of the language usage, 
such a variety is not used in formal print and 
broadcasting media as they mainly use standard 
literary Tamil. 
In our preliminary study, we found that textual 
contents in personal blogs, tweets, and chats 
have significantly large number of dialectal and 
spoken language words than those are found in 
other standard online resources such as news 
publishers, entertainment media websites etc. 
Since we focus on processing various Tamil 
dialects and their spoken language variants, we 
have collected publicly available data from the 
above mentioned online resources for this work. 
The collected data belongs to authors from 
various geographic locations where different 
Tamil dialects exist. The textual contents in the 
selected resources mainly contain movie reviews, 
narratives, travel experiences, fables, poems, and 
sometimes an informal discourse, all in a casual 
and colloquial manner. Further, we were able to 
collect variants of spoken forms which vary with 
respect to person, social status, location, com-
munity, gender, age, qualification etc. 
 
 
 
enga 
engee 
(where) 
 
engaL 
(ours) 
39
Though Tamil language has 15 dialects, in this 
work, we focused only on 5 dialects namely, 
Central Tamil dialect, Madurai Tamil, Tirunelve-
li Tamil, Brahmin Tamil, Kongu Tamil and 
common spoken language forms. In Table 1, we 
present the corpus distribution with respect to the 
dialects and the number of dialectal and spoken 
language words. 
 
Name of the Tamil 
Dialect 
No. of  Dialectal 
words 
Central Tamil dialect 584 
Madurai Tamil 864 
Tirunelveli Tamil 2074 
Brahmin Tamil 2286 
Kongu Tamil 910 
Common Spoken Forms 5810 
Table 1. Corpus distribution among dialects 
 
We performed an in-depth study on the collected 
data and found some peculiarities which exist in 
some dialects. Some of the observed peculiarities 
are described in Section 4. 
4 Tamil Dialects and their Peculiarities 
Some dialectal words have totally different 
meaning in SST and in other dialects or in stan-
dard literary Tamil. For instance, consider the 
following dialectal sentence (Tirunelveli Tamil) 
 
ela,    inga   vaala. 
Hey   here   come 
?Hey come here!? 
 
The words ?ela? and ?vaala? convey different 
meanings in different contexts and dialects. In 
SST they denote ?leaf? and ?tail? respectively 
while in Tirunelveli Tamil dialect they convey 
the meaning ?hey? and ?come? respectively. 
Though these ambiguities are resolved when 
the context is considered, they make the trans-
formation task challenging since this is a word-
level task and no context information is taken 
into account during transformation. 
The example in table 2, illustrates spelling 
based variants where the variants map to single 
canonical written form. We observed that the 
most common form of spoken-language usage is 
the use and representation of ?enRu? (ADV) as 
four variants which are shown in Table 2. 
 
 
 
Spoken form 
Variants 
Written form 
Equivalent 
[Noun/Pronoun/Verb] 
+ ?nu? 
[Noun/Pronoun/Verb] + 
?enRu? 
[Noun/Pronoun/Verb] 
+ ?nnu? 
[Noun/Pronoun/Verb] + 
?enRu? 
[Noun/Pronoun/Verb] 
+ ?unu? 
[Noun/Pronoun/Verb] + 
?enRu? 
[Noun/Pronoun/Verb] 
+ ?unnu? 
[Noun/Pronoun/Verb] + 
?enRu? 
Table 2. Spoken variants and written language 
 
The dialectal variants of the verb ?vanthaarkaL? 
(they came) is illustrated in table 3. 
 
Dialectal variants Written form Equivalent 
[Verb] + ?aaka?  [Verb] + ?aarkaL?  
[Verb] + ?aangka? [Verb] + ?aarkaL?  
Table 3. Dialectal variants & written language 
 
It can be observed from Table 3 that the di-
alectal suffixes vary from each other but they all 
map to same written form suffix. Despite the di-
alectal variation, they all convey the same mean-
ing. But they vary syntactically. The ?aaka? suf-
fix functions as adverbial marker in standard lite-
rary Tamil whereas it acts as person, number, 
gender (PNG) marker in Madurai Tamil dialect. 
5 System Architecture 
In this section we describe our system architec-
ture which is depicted in Figure 3. Our dialectal 
spoken to written transformer (DSWT) has three 
main components namely, Transformation En-
gine, CRF word boundary identifier and heuristic 
Sandhi corrector. 
 Transformation Engine contains FSTs 
for the dialectal and spoken language 
to standard written language transfor-
mation. The resultant words may be 
agglutinated and is decomposed with 
the help of  CRF boundary identifier. 
 CRF Word Boundary Identifier mod-
ule identifies the word boundaries in 
agglutinated words and splits them in-
to a set of constituent simpler words. 
 Heuristic Sandhi Corrector module 
makes necessary spelling changes to 
the segmented constituent words and 
standardizes them to canonical and 
meaningful simpler words. 
40
 
Figure 3. System Architecture 
 
5.1 Transformation Engine 
The function of Transformation engine is to 
transform dialectal and spoken language words 
into standardized literary Tamil words, similar to 
the official form of Tamil that is used in gov-
ernment publications such as official memoran-
dums, news and print media, and formal political 
speeches. 
Modeling FSTs for Transformation 
Given the regular pattern of inflections within a 
paradigm, we use paradigm based approach for 
the variation modeling. Specifically, the dialectal 
usages, spoken language forms and their variants 
are modeled as ?root+spoken-language-suffix? 
where it will get transformed into ?root+written-
language-suffix? after transformation. We had 
used AT&T's FSM library3 for generating FSTs. 
The FST shown in Fig. 4 shows the state transi-
tions for some spoken language words. 
 
 
Figure 4. Sample FST 
 
It can be observed from Figure 4 that spoken 
and dialectal words are processed in right to left 
fashion. This way of processing is adopted since 
                                                 
3 http://www2.research.att.com/~fsmtools/fsm/ 
the number of unique suffixation is few when 
compared to the number of root words. This will 
make the suffix matching faster and hence 
achieves quick transformation. This makes FSTs 
as an efficient tool for dialectal or variation mod-
eling. 
 
Algorithm for Transformation 
The algorithm that is used to transform dialectal 
and spoken language text is given below. 
 
1: for each dialectal/spoken-language word 
2:   check possible suffixations in FST 
3:      for each suffixation 
4:        if  FST accepts & generates written  
               language equivalents for all suffixes 
5:          return (root + written-language-suffix) 
6:       else 
7:         return dialectal/spoken-language-word 
8: for each agglutinated & compound word 
9:     do CRF word boundary identification 
10:       for each constituent word (CW) 
11:           do Sandhi Correction 
12:              return simple constituent words 
 
5.2 Decomposition of Agglutinated and 
Compound Words using CRF 
Since Tamil is a morphologically rich language, 
the phenomenon of agglutination and compound-
ing in standard written language Tamil is high 
and very common. It is also present in dialectal 
and spoken language Tamil. This poses a number 
of challenges to the development of NLP sys-
tems. To solve these challenges, we segment the 
agglutinated and compound words into simpler 
constituent words. This decomposition is 
achieved using two components namely  
41
  
Agglutinated word  or 
Compound Word 
Boundary Identification  
and Word Segmentation 
Sandhi Correction Functions 
No Change Insertion Deletion Substitution 
nampuvathillaiyenRu 
(will not be believing) 
nampuvath 
illai 
yenRu 
 
illai 
nampuvathu  
 
enRu 
 
muththokuppukaLutaya 
(comprising of three 
volumes) 
muth 
thokuppukaL 
utaya 
 
thokuppukaL 
utaya 
  muu 
Table 4. Boundary identification and Sandhi Correction 
Table 4 clearly manifests the boundary of a constituent word within a compound or an agglutinated 
word which may contain one or more word-boundaries. It is observed that for ?n? constituent words in 
a compound or an agglutinated word, there exists exactly (n-1) shared word-boundaries where (n>0). 
 
CRF word boundary identifier and Heuristic 
Sandhi Corrector. We have developed the word 
boundary identifier for boundary identification 
and segmentation as described in Marimuthu et 
al. (2013) and heuristic rule based Sandhi correc-
tor for making spelling changes to the segmented 
words. 
 
CRF Word-Boundary Identifier 
CRF based word-boundary identifier marks the 
boundaries of simpler constituent words in ag-
glutinated and compound words and segments 
them. CRFs are a discriminative probabilistic 
framework for labeling and segmenting sequen-
tial data. They are undirected graphical models 
trained to maximize a conditional probability 
(Lafferty et al., 2001). 
Generally word-boundary identification is stu-
died extensively for languages such as Chinese 
and Japanese but the necessity for Indian lan-
guages was not considered until recently. Al-
though there is no standard definition of word-
boundary in Chinese, Peng et al. (2004) describe 
a robust approach for Chinese word segmenta-
tion using linear-chain CRFs where the flexibili-
ty of CRFs to support arbitrary overlapping fea-
tures with long-range dependencies and multiple 
levels of granularity are utilized by integrating 
the rich domain knowledge in the form of mul-
tiple lexicons of characters and words into the 
framework for accurate word segmentation. 
In case of Japanese, though the word bounda-
ries are not clear, Kudo et al. (2004) used CRFs 
for Japanese morphological analysis where they 
show how CRFs can be applied to situations 
where word-boundary ambiguity exists. 
Marimuthu et al. (2013) worked on word 
boundary identification and segmentation in Ta-
mil where they model the boundary identification 
as a sequence labeling task [i.e. a tagging task]. 
The absence of word-boundary ambiguity in 
Tamil language favors the boundary identifica-
tion task and predominantly eliminates the need 
for providing further knowledge to CRFs such as 
multiple lexicons as in the case of Chinese word 
segmentation. Hence we have used word level 
features alone for training the CRFs. 
 
Sandhi Correction using Word-level Contex-
tual Rules 
Word-level contextual rules are the spelling 
rules in which each constituent word of an agglu-
tinated or compound word is dependent either on 
the previous or the next or both constituent 
words to give a correct meaning. 
After boundary identification, suppose an ag-
glutinated or a compound word is split into three 
constituent words, Sandhi correction for the first 
constituent word is dependent only on the second 
constituent word while the second word's Sandhi 
correction depends on both first and third consti-
tuent word whereas the third constituent word's 
Sandhi correction depends on second constituent 
word alone. 
Sandhi correction is performed using these 
rules to make necessary spelling changes to the 
boundary-segmented words in order to normalize 
them to sensible simpler words. It is accom-
plished using three tasks namely insertion, dele-
tion, and substitution as described in Marimuthu 
et al. (2013). 
For instance, after boundary identification the 
word ?nampuvathillaiyenRu? (will not be believ-
ing) will be boundary marked and Sandhi cor-
rected as shown in the Table 4 above. 
 
Advantages of Word boundary Identification 
Morphological Analysis of simpler words is 
much easier than analyzing agglutinated and 
compound words.  
42
 
 
 
Tamil Dialects No. of dialectal words Precision (%) Recall (%) F-Measure (%) 
Central Tamil dialect 584 88.0 89.3 88.6 
Madurai Tamil 864 85.2 87.5 85.3 
Tirunelveli Tamil 2074 83.4 88.6 85.9 
Brahmin Tamil 2286 87.3 89.5 88.4 
Kongu Tamil 910 89.1 90.4 89.7 
Common Spoken Forms 5810 86.0 88.3 87.1 
Table 5. Direct Evaluation Results 
 
So the word-boundary identifier eases the task of 
morphological analyzer in identifying the indi-
vidual morphemes. In addition, it nullifies the 
unknown words category if it occurs due to ag-
glutination and compounding. As a result, it im-
proves the recall of the morphological analyzer 
and any advanced NLP system. For example, 
with Tamil, SMT models usually perform better 
when the compound words are broken into their 
components. This 'segmentation' gives the word 
alignment greater resolution when matching the 
groupings between the two languages. 
6 Experimental Evaluation 
Here we perform evaluation of the performance 
of DSWT with test corpus of 12528 words. We 
perform two types of evaluations: direct and indi-
rect evaluation. 
In direct evaluation, we evaluate the system 
using gold standard. In indirect evaluation the 
system is evaluated using machine translation 
application. The aim in indirect evaluation is to 
understand the effect of dialectal and spoken lan-
guage transformation in machine translation. 
 
6.1 Direct Evaluation 
We evaluate DSWT performance using the 
standard evaluation metrics: Precision, Recall, 
and F-measure. Precision and Recall values are 
calculated separately for each dialect using a 
gold standard.  They are calculated using the cas-
es described below: 
 
A: The dialectal or spoken language transforma-
tion yields one or many correct standard written 
language words. 
B: The dialectal or spoken language transforma-
tion yields at least one correct standard written 
language word. 
C: The dialectal or spoken language transforma-
tion yields no output. 
D: Number of dialectal or spoken language 
words given as input. 
Precision is then calculated as: A/(D-C) 
Recall is calculated as: (A+B)/D 
F-Measure is the harmonic mean of Precision 
and Recall. 
The obtained results for the considered 5 Tamil 
dialects and common spoken language forms are 
summarized in Table 5 above. 
6.2 Indirect Evaluation 
For indirect evaluation, we had used DSWT with 
Google Translate (GT) to measure the influence 
of DSWT in Tamil-English machine translation, 
and evaluated the improvement. 
Our test data had 100 Tamil sentences which 
are of dialectal and colloquial in nature. At first, 
we used GT to translate these sentences to Eng-
lish. This is Output1. Then we used our DSWT 
to transform the dialectal sentences into standard 
written Tamil. After this, the standard sentences 
were translated to English using GT. This cor-
responds to Output2. 
We then performed subjective evaluations of 
Output1 and Output2 with the help of three na-
tive Tamil speakers whose second language is 
English. The three evaluation scores for each 
sentence in Output1 and Output2 are averaged. 
The obtained scores are shown in Table 6. 
 
Subjective Evaluation 
Scores before  dialectal 
Transformation 
Subjective Evaluation 
Scores after dialectal 
Transformation 
No. of 
sentences 
Achieved 
Scores 
No. of 
Sentences 
Achieved 
Scores 
20 0 4 0 
70 1 14 1 
8 2 28 2 
2 3 30 3 
0 4 24 4 
Table 6. Subjective evaluation results 
 
We used a scoring scale of  0-4 where 
0 ? no translation happened. 
 
 
43
Before performing Dialectal Transformation Task After performing Dialectal Transformation Task 
Dialectal Spoken Tamil Google Translate results Standardized Written Tamil Google Translate results 
. 
(otanee  vanthuru) 
vanturu otane. (?) . 
(utanee  vanthuvitu) 
Come immediately. (?) 
. 
(otanee  vanthurula) 
vanturula otane. (?) . 
(utanee  vanthuvitu) 
Come immediately. (?) 
. 
(avanga  vanthaanga) 
she had come. (?) . 
(avarkaL  vanthaarkaL) 
They came. (?) 
. 
(avuka vanthaaka) 
avuka to come. (?) . 
(avarkaL  vanthaarkaL) 
They came. (?) 
Table 7. Tamil-English Google Translate results before and after dialectal text transformation 
Sentences marked as (?) are incorrectly translated into English and those that are marked as (?) may 
be partially correct. The sentences that are marked as (?) are the correct English translations. 
 
1 ? lexical translation of few words happen     
        and no meaning can be inferred from the  
        translation output. 
2 ? complete lexical translations happen and  
        some meaning can be inferred from the  
        translation output. 
3 ? meaning can be inferred from translation 
        output but contains some grammatical 
        errors. 
4 ? complete meaning is understandable with  
        very minor errors. 
 
It can be observed from the results in Table 6 
that GT failed to translate dialectal and spoken 
language sentences. But the failure got mitigated 
after transformation causing dramatic improve-
ment in translation quality. The following Table 
illustrates few examples where the translation 
quality has improved after transforming dialectal 
spoken language. 
It must be noted from Table 7 that after the 
transformation of dialectal spoken language, all 
the sentences were able to achieve their English 
equivalents during machine translation. This 
suggests that almost all word categories in Tamil 
can achieve improved translations if the words 
are given as standard simple written language 
words. This experiment emphasizes the impor-
tance of feeding the machine translation systems 
with standard written language text to achieve 
quality translations and better results. 
7 Results and Discussion 
We observe that the achieved accuracy is higher 
for Kongu Tamil dialect when compared to other 
dialects. This is because words in this dialect are 
rarely polysemous in nature. But the number of 
polysemous words is high in the case of Madurai 
and Tirunelveli Tamil dialect and this resulted in 
low accuracy of transformation. 
While performing transformation, the possible 
causes for ending up with unknown words may 
be due to the absence of suffix patterns in FSTs, 
errors in input words, uncommonly transliterated 
words, and English acronyms. The standard writ-
ten language words convey a particular meaning 
in standard literary Tamil and completely differ-
ent meaning in dialectal usages. For instance, 
consider the verb ?vanthaaka?. In standard lite-
rary Tamil, this is used in the imperative sense 
?should come? while in Tirunelveli Tamil dialect 
it is used in the sense ?somebody came?. 
8 Conclusion and Future Work 
We have presented a dialectal and spoken lan-
guage to standard written language transformer 
for Tamil language and evaluated its perfor-
mance directly using standard evaluation metrics 
and indirectly using Google Translate for Tamil 
to English machine translation. The achieved 
results are encouraging. 
There is no readily available corpus for 
processing dialectal and spoken Tamil texts and 
we have collected the dialectal and spoken lan-
guage corpus for developmental and evaluation 
tasks. This corpus can be made use of for devel-
oping other NLP applications. 
In case of one-to-many mapping, multiple 
written language forms will be emitted as out-
puts. Hence, determining which written-form of 
word to be adopted over other resultant written-
forms has to be done based on the meaning of the 
whole sentence in which the spoken-language 
word occurs. This will be the focus of our future 
direction of the work. 
 
44
References 
A. K. Ramanujan. 1968. Spoken and Written Tamil, 
the verb. University of Chicago. Pages 74. 
Fuchun Peng, Fangfang Feng and Andrew McCallum. 
2004.Chinese Segmentation and New Word Detec-
tion using Conditional Random Fields, Computer 
Science Department Faculty Publication Series. 
Paper 92. University of Massachusetts ? Amherst. 
Harold F. Schiffman. 1979. A Grammar of Spoken 
Tamil, Christian Literature Society, Madras, India. 
Pp. i-viii, 1-104. 
Harold F. Schiffman. 1988. Standardization or res-
tandardization: The case for ?Standard? Spoken 
Tamil, Language in Society, Cambridge University 
Press, United States of America. Pages 359-385. 
Harold F. Schiffman. 1999. A Reference Grammar of 
Spoken Tamil, Cambridge University Press, Pp. i-
xxii,1-232. 
J. Lafferty, A. McCallum, and F. Pereira. 2001. Con-
ditional Random Fields: Probabilistic Models for 
Segmenting and Labeling Sequence Data. In Pro-
ceedings of the 18th International Conference on 
Machine Learning, pages 282?289. 
Marimuthu K., Amudha K., Bakiyavathi T. and Sobha 
Lalitha Devi. 2013. Word Boundary Identifier as a 
Catalyzer and Performance Booster for Tamil 
Morphological Analyzer, in proceedings of 6th 
Language and Technology Conference, Human 
Language Technologies as a challenge for Com-
puter Science and Linguistics, Poznan, Poland. 
Milton Singer and Bernard S. Cohn. 2007. The Struc-
ture of Variation: A Study in Caste Dialects, Struc-
ture and Change in Indian Society, University of 
Chicago, Chapter 19, pages 461-470. 
Nizar Habash and Owen Rambow. 2006. MAGEAD: 
A Morphological Analyzer and Generator for the 
Arabic Dialects, In proceedings of the 21st Interna-
tional Conference on Computational Linguistics 
and 44th Annual Meeting of the ACL, Sydney, Aus-
tralia. Pages 681-688 
Sajib Dasgupta and Vincent Ng. 2007. Unsupervised 
Word Segmentation for Bangla, In proceedings of 
the Fifth International Conference on Natural Lan-
guage Processing(ICON), Hyderabad, India. 
Taku Kudo, Kaoru Yamamoto and Yuji Matsumoto. 
2004. Applying Conditional Random Fields to Jap-
anese Morphological Analysis, In proceedings of 
Empirical Methods on Natural Language 
Processing, Barcelona, Spain. 
Umamaheswari E, Karthika Ranganathan, Geetha TV, 
Ranjani Parthasarathi, and Madhan Karky. 2011. 
Enhancement of Morphological Analyzer with 
compound, numeral and colloquial word handler, 
Proceedings of ICON-2011: 9th International Con-
ference on Natural Language Processing, Macmil-
lan Publishers, India. 
 
 
45
