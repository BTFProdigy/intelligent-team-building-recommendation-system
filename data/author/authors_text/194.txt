Paraphrastic Grammars
Claire Gardent
CNRS-LORIA, Nancy
France
Claire.Gardent@loria.fr
Marilisa Amoia
Computational Linguistics
University of Saarbruecken
Germany
amoia@coli.uni-sb.de
Evelyne Jacquey
CNRS-ATILF, Nancy
France
Evelyne.Jacquey@atilf.fr
Abstract
Arguably, grammars which associate natural lan-
guage expressions not only with a syntactic but
also with a semantic representation, should do so in
a way that capture paraphrasing relations between
sentences whose core semantics are equivalent. Yet
existing semantic grammars fail to do so. In this pa-
per, we describe an ongoing project whose aim is
the production of a ?paraphrastic grammar? that is,
a grammar which associates paraphrases with iden-
tical semantic representations. We begin by propos-
ing a typology of paraphrases. We then show how
this typology can be used to simultaneously guide
the development of a grammar and of a testsuite de-
signed to support the evaluation of this grammar.
1 Introduction
A salient feature of natural language is that it allows
paraphrases that is, it allows different verbalisations
of the same content. Thus although the various ver-
balisations in (1) may have different pragmatic or
communicative values (with respect for instance to
topicalisation, presuppositions or focus/ground par-
titioning), they all share a core semantic content, the
content approximated by a traditional montagovian
compositional semantics.
(1) a. La croisie`re cou?te cher.
Lit. the cruse is expensive
b. Le cou?t de la croisie`re est e?leve?.
Lit. the cost of the cruse is high
c. La croisie`re a un cou?t e?leve?
Lit. the cruse has a high cost
Linguists have long noticed the pervasiveness of
paraphrases in natural language and attempted to
caracterise it. Thus for instance Chomsky?s ?trans-
formations? capture the relation between one core
meaning (a deep structure in Chomsky?s terms) and
several surface realisations (for instance, between
the passive and the active form of the same sen-
tence) while (Mel?c?uk, 1988) presents sixty para-
phrastic rules designed to account for paraphrastic
relations between sentences.
More recently, work in information extraction
(IE) and question answering (QA) has triggered a
renewed research interest in paraphrases as IE and
QA systems typically need to be able to recognise
various verbalisations of the content. Because of the
large, open domain corpora these systems deal with,
coverage and robustness are key issues and much on
the work on paraphrases in that domain is based on
automatic learning techniques. For instance, (Lin
and Pantel, 2001) acquire two-argument templates
(inference rules) from corpora using an extended
version of the distributional analysis in which paths
in dependency trees that have similar arguments are
taken to be close in meaning. Similarly, (Barzi-
lay and Lee, 2003) and (Shinyanma et al, 2002)
learn sentence level paraphrase templates from a
corpus of news articles stemming from different
news source. And (Glickman and Dagan, 2003) use
clustering and similarity measures to identify sim-
ilar contexts in a single corpus and extract verbal
paraphrases from these contexts.
Such machine learning approaches have known
pros and cons. On the one hand, they produce large
scale resources at little man labour cost. On the
other hand, the degree of descriptive abstraction of-
fered by the list of inference or paraphrase rules they
output is low.
We chose to investigate an alternative research di-
rection by aiming to develop a ?paraphrastic gram-
mar? that is, a grammar which captures the para-
phrastic relations between linguistic structures1 .
Based on a computational grammar that associates
natural language expressions with both a syntactic
and a semantic representation, a paraphrastic gram-
1As we shall briefly discuss in section 4, the grammar is de-
veloped with the help of a meta-grammar (Candito, 1999) thus
ensuring an additional level of abstraction. The metagrammar
is an abstract specification of the linguistic properties (phrase
structure, valency, realisation of grammatical functions etc.)
encoded in the grammar basic units. This specification is then
compiled to automatically produce a specific grammar.
mar is a grammar that moreover associates para-
phrases with the same semantic representation. That
is, contrary to machine learning based approaches
which relate paraphrases via sentence patterns, the
paraphrastic grammar approach relates paraphrases
via a common semantic representation. In this way,
the paraphrastic approach provides an interesting al-
ternative basis for generation from conceptual rep-
resentations and for the inference-based, deep se-
mantic processing of the kind that is ultimately
needed for high quality question answering.
Specifically, we aim at developing a paraphras-
tic grammar for French, based on the Tree Adjoin-
ing Grammar (TAG) developed for this language by
Anne Abeille? (Abeille?, 2002).
The paper is structured as follows. We start
by proposing a typology of the paraphrastic means
made available by natural language. We then show
how this typology can be used to develop a testsuite
for developing and evaluating a paraphrastic gram-
mar. Finally, we highlight some of the issues arising
when developing a paraphrastic grammar.
2 Classifying paraphrases
A paraphrastic grammar should capture the vari-
ous means made available by natural language to
support paraphrasing. But what are those means?
We distinguish here between three main classes
namely, parallel, shuffling and definitional para-
phrastic means.
Parallel paraphrastic means. A parallel para-
phrase can hold either between two non predica-
tive lexical units (words or multi word expressions)
modulo negation or between two predicative units
of identical arity. If it holds between predicative
units, the mapping linking grammatical functions
(subject, objects, etc.) and thematic roles (agent,
theme, etc.) must be the same. Depending on
whether or not negation is involved, semantic equiv-
alence will futhermore obtain either through syn-
onymy or through antonymy.
As illustrated in Figure 1, synonymy can be fur-
ther divided in a number of cases depending on var-
ious morphological and syntactic criteria. The clas-
sification criteria used involve :
? Syntactic category: Do the synonyms have the
same syntactic category?
? Morphological relatedness: Do the synonyms
contain words that are morphologically re-
lated?
? Form: Are the synonyms simple lexical units
or multi word expressions?
As for antonymy, we distinguish between trans
and intracategorial antonymy:
(2) Jean est lent/Jean n?est pas rapide.
Jean is slow/Jean is not fast.
lent/rapide, intracategorial
Jean a cesser de fumer/Jean ne fume plus.
Jean has stopped smoking/Jean smokes no
more.
cesse de/ne . . . plus, transcategorial
Shuffling paraphrastic means. When a seman-
tic equivalence holds between predicative units with
distinct grammatical functions/thematic role link-
ing, we speak of shuffling paraphrases. Such para-
phrases can be realised either by means of argument
preserving alternations (in the sense of Beth Levin,
cf. (4)) or using a converse construction (cf. 3)2.
(3) a Jean donne un livre a` Marie.
Jean gives a book to Marie.
Marie rec?oit un livre de Jean
Jean receives a book from Marie.
b Jean est le parent de Marie.
Jean is the parent of Marie.
Marie est l?enfant de Jean.
Marie is the child of Jean.
(4) a. Cette cle? ouvre le coffre fort
This key opens the safe.
Le coffre fort s?ouvre avec cette cle?
The safe opens with this key.
b. Jean mange une pomme
Jean eats an apple.
une pomme est mange?e par Jean
An apple is eaten by Jean.
Il a e?te? mange? une pomme par Jean.
There has been an apple eaten by Jean.
c. L?eau remplit la cruche
The water fills the jug .
La cruche se remplit d?eau
The jug fills with water.
On remplit la cruche d?eau
One fills the jug with water.
d. Le laboratoire fusionne avec l?entreprise
The laboratory merges with the firm.
le laboratoire et l?entreprise fusionnent
The laboratory and the firm merge.
e. Jean frappe le mur avec un baton
Jean hit the wall with a stick.
2Obviously, the english translations do not reflect the ac-
ceptability of the french equivalent.
Same synt. Same morph. Form Example
categories family
yes no word/word policier, flic
yes yes word/mwe conseiller, donner conseil
yes no word/mwe s?exprimer sur, donner son avis sur
yes no mwe/mwe donner carte blanche a`, laisser tout pouvoir
no yes word/word construire, construction
no no word/word candidature a`, briguer
Figure 1: Synonymy
Jean frappe le baton sur le mur.
Jean hit the stick on the wall.
f. Je fournis des livres a` Jean
I provide books to Jean.
Je fournis Jean en livre
I provide Jean with books.
Definitional paraphrastic means. Third, we call
?definitional paraphrases? semantic equivalences
that hold between a lexical unit and a phrase con-
sisting of more than one lexical unit. The phrase
in this case, defines the meaning of the lexical unit.
Since definitions are notoriously difficult to decide
upon, we restrict ourselves here to such definitions
as can be given by derivational morphology that is,
definitions based on a word that is morphologically
linked to the definiendum (cf. 5).
(5) a. Le conducteur de la BMW est chauve
The driver of the BMW is bald.
La personne qui conduit la BMW est
chauve
The person who drives the BMW is bald.
b. Cet outil est parame?trable
This tool is parameterisable.
Cet outil peut e?tre parame?tre?
This tool can be parameterised.
3 Developing a paraphrase testsuite
Based on the above typology, we can systematically
construct a testsuite for developing and evaluating
a paraphrastic grammar. Indeed, when developing
a grammar, it is necessary to have some means of
assessing both the coverage of the grammar (does
it generate all the sentences of the described lan-
guage?) and its degree of overgeneration (does it
generate only the sentences of the described lan-
guage?) While corpus driven efforts along the PAR-
SEVAL lines (Black et al, 1991) are good at giving
some measure of a grammar coverage, they are not
suitable for finer grained analysis and in particular,
for progress evaluation, regression testing and com-
parative report generation. Another known method
consists in developing and using a test suite that is,
a set of negative and positive items against which
the grammar can be systematically tested. For en-
glish, there is for instance the 15 year old Hewlett-
Packard test suite, a simple text file listing test sen-
tences and grouping them according to linguistics
phenomena (Flickinger et al, 1987); and more re-
cently, the much more sophisticated TSNLP (Test
Suite for Natural Language Processing) which in-
cludes some 9500 test items for English, French and
German, each of them being annotated with syntac-
tic and application related information (Oepen and
Flickinger, 1998).
Yet because they do not take into account the se-
mantic dimension, none of these tools are adequate
for evaluating the paraphrastic power of a gram-
mar. To remedy this, we propose to develop a para-
phrase test suite based on the paraphrase typology
described in the previous section. In such a testsuite,
test items pair a semantic representation with a set
of paraphrases verbalising this semantics. The con-
struction and annotation of the paraphrases reflects
the paraphrase typology. In a first phase, we concen-
trate on simple, non-recursive predicate/argument
structure. Given such a structure, the construction
and annotation of a test item proceeds as follows.
First, a ?canonical verbalisation? is produced in
which the predicate is realised by the ?canonical
verb? for the given concept3 and the arguments by
the canonical nouns.
Next variants are produced by systematically try-
ing to create parallel, shuffling and definitional para-
phrases. Each of the variant is furthermore anno-
tated with labels caracterising the type of paraphras-
ing involved. Here is an example. Suppose the input
semantics is:
apply(e), agent(e,jean), theme(e,job), failure(e)
for which the canonical verbalisation is:
(6) Jean a candidate? sans succe`s sur le poste
Jean has applied in vain for the job.
3Like in a thesaurus, we assume that amongst a set of syn-
onyms, one lexical unit is ?canonical? and the others not. The
canonical unit is sometimes called a descriptor.
The parallel synonyms4 that can be used are the
following:5
candidater candidature +pred-N
poser sa +pred-vsupV
candidature
briguer +pred-V
sans succe`s e?chouer +mod-V
e?tre sans succe`s +mod-beAdv
ne pas e?tre retenu +mod-Vanton
For shuffling synonymy, two alternations are
available: the active/passive alternation for ?poser?
and the active/locative one for ?e?chouer?. There is
no converse construction. Neither is there any defi-
nition given by derivational morphology for any of
the terms occurring in the canonical verbalisation.
Based on these facts, the following variants and an-
notations can be constructed.
(7) a. Jean a brigue? le poste sans succe`s
Jean has asked for the job in vain.
+pred-Vsyn
b. Jean a pose? sa candidature sur le poste sans
succe`s
Jean has submitted his application for the
job in vain.
+pred-vsupN
c. La candidature pose?e par Jean sur le poste
a e?te? sans succe`s
The application submitted by Jean for the
job was in vain.
+pred-partAdj, +mod-beAdv
d. La candidature pose?e par Jean sur le poste
a e?choue?
The application submitted by Jean for the
job failed.
+pred-partAdj, +mod-V
e. La candidature de Jean sur le poste a e?te?
sans succe`s
Jean?s application for the job was in vain.
+pred-N, +mod-beAdv
f. La candidature de Jean sur le poste n?a pas
e?te? retenue
4As has been abundantly argued by linguists, real synonyms
are extremely rare. By synonyms, we in fact refer here to the
notion of quasi-synonyms used for instance in WordNet that is,
words that are interchangeable in a restricted set of contexts.
5The labels are the ones used for annotation. They carac-
terise variations with respect to the canonical realisation. For
instance, +pref-N indicates that the main predicate (realised by
a verb in the canonical verbalisation) is realised as a noun.
Jean?s application for the job was not suc-
cessful.
+pred-N, +mod-Vanton
g. La candidature de Jean sur le poste a
e?choue?
Jean?s application for the job failed.
+pred-N, +mod-V
h. Jean a e?choue? dans sa candidature sur le
poste.
Jean failed in his application for the job.
+pred-N, +mod-V-altLoc
Thus the typology of paraphrastic means help
guide the construction of the various paraphrases
contained in a single item. There remains the ques-
tion of how to choose the particular items of the
testsuite. In other words: which semantic repre-
sentations should we use to populate the test suite
and on the basis of which criteria? The basic aim
here is to cover the various types of possible seman-
tic combinations and the constraints they are sub-
ject to at the syntactic (realisation) level. If, as Beth
Levin argues, syntax is a reflex of semantic proper-
ties, then different semantic contents should be sub-
ject to varying syntactic constraints and the test suite
ought to cover these various types of interactions.
Accordingly test items are constructed whose main
predicate vary along the following dimensions :
(1) WordNet Verb Family; (2) Aspect; (3) Arite?
That is, items are constructed for each word-
Net family (the french WordNet counts roughly 170
such families). Within a given family, we attempt
to find examples with distinct aspectual categories
(state, accomplishment and process). Finally, given
a WN family and an aspectual category, items will
vary with respect to the arity of the main predicate
and the types of their arguments e.g., predicates of
arity one (run, cost, sleep), of arity two with non
propositional arguments (eat, hit, dug), of arity two
with a propositional argument (say, promise etc.),
etc.
4 A paraphrastic grammar
?Semantic grammars? already exist which describe
not only the syntax but also the semantics of nat-
ural language. Thus for instance, (Copestake and
Flickinger, 2000; Copestake et al, 2001) describes
a Head Driven Phrase Structure Grammar (HPSG)
which supports the parallel construction of a phrase
structure (or derived) tree and of a semantic repre-
sentation and (Dalrymple, 1999) show how to equip
Lexical Functional grammar (LFG) with a glue se-
mantics.
These grammars are both efficient and large scale
in that they cover an important fragment of the nat-
ural language they describe and can be processed by
parsers and generators in almost real time. For in-
stance, the LFG grammar parses sentences from the
Wall Street Journal and the ERG HPSG grammar
will produce semantic representations for about 83
per cent of the utterances in a corpus of some 10
000 utterances varying in length between one and
thirty words. Parsing times vary between a few ms
for short sentences and several tens of seconds for
longer ones.
Nonetheless, from a semantics viewpoint, these
grammars fail to yield a clear account of the para-
phrastic relation. Here is a simple example illustrat-
ing this shortcoming. Suppose we parse the follow-
ing paraphrases where a lexical definition (driver ?
person who drives) is involved:
(8) a. The person who drives the car is mad.
b. The driver of the car is mad.
When given these sentences, the LKB system
based on the ERG HPSG grammar returns semantic
representations which can be sketched as follows6:
(9) a. the(x, person(x) ? the(y, car(y) ?
drive(e,x,y) ? mad(x)))
a. the(y, car(y) ? the(x, driver(x,y) ? of(x,y))
? mad(x))
In other words, the grammar associates with
these paraphrases semantic representations which
are very different. It could be argued of course
that although these representations are syntactically
distinct, they can be inferred, given the appropri-
ate knowledge, to be semantically equivalent. But
a solution that avoids placing such extra burden on
the inferencing component is obviously better. In
short, one important shortcoming of existing large
scale semantic grammars is that they do not assign
semantically equivalent sentences, the same seman-
tic representation.
By contrast, we propose to develop a grammar
which whereever possible assigns identical seman-
tic representations to paraphrases and whose devel-
6These semantic representations have been simplified for
better readibility. The real representations output by the LKB
are the following:
prpstn(def(x,person(x)?prpstn(def(y,car(y),
drive(e1,v1,x,y,v2),v3)), mad(e2,x,v4),v5)
prpstn(def(x,person(x)?prpstn(def(y,car(y),
drive(e1,v1,x,y,v2),v3)), mad(e2,x,v4),v5)
prpstn(def(y,car(y)?prpstn(def(x, driver(x,y) ? of(e1,x,y,v1),
mad(e2,x,v2,v3)))))
opment is based both on semantic and syntactic con-
siderations.
4.1 Linguistic framework
Our grammar is couched within the Feature-Based
Tree Adjoining grammar (FTAG) formalism. An
FTAG consists of a set of (auxiliary or initial) ele-
mentary trees and two tree composition operations:
substitution and adjunction. Substitution is the stan-
dard tree operation used in phrase structure gram-
mars while adjunction is an operation which inserts
an auxiliary tree into a derived tree. To account for
the effect of these insertions, two feature structures
(called top and bottom) are associated with each
tree node in FTAG. The top feature structure en-
codes information that needs to be percolated up the
tree should an adjunction take place. In contrast, the
bottom feature structure encodes information that
remains local to the node at which adjunction takes
place.
The language chosen for semantic representa-
tion is a flat semantics along the line of (Bos,
1995; Copestake et al, 1999; Copestake et al,
2001). However because we are here focusing on
paraphrases rather than fine grained semantic dis-
tinctions, the underspecification and the descrip-
tion of the scope relations permitted by these se-
mantics will here be largely ignored and flat se-
mantics will be principally used as a convenient
way of describing predicate/arguments and modi-
fiers/modified relationships. Thus the semantic rep-
resentations we assume are simply set of literals of
the form P n(x1, . . . , xn) where P n is a predicate
of arity n and xi is either a constant or a unifica-
tion variable whose value will be instantiated during
processing.
Semantic construction proceeds from the derived
tree (Gardent and Kallmeyer, 2003) rather than ?
as is more common in TAG ? from the derivation
tree. This is done by associating each elementary
tree with a semantic representation and by deco-
rating relevant tree nodes with unification variables
and constants occuring in associated semantic rep-
resentation. The association between tree nodes and
unification variables encodes the syntax/semantics
interface ? it specifies which node in the tree pro-
vides the value for which variable in the final se-
mantic representation.
As trees combine during derivation, (i) variables
are unified ? both in the tree and in the associated
semantic representation ? and (ii) the semantics of
the derived tree is constructed from the conjunction
of the semantics of the combined trees. A simple
example will illustrate this.
NPj
John
name(j,john)
S
NP?x1 VP
V NP?x2 NPm
loves Mary
love(x1,x2) name(m,mary)
Figure 2: ?John loves Mary?
Suppose the elementary trees for ?John?, ?loves?
and ?Mary? are as given in Fig. 2 where a downar-
row (?) indicates a substitution node and Cx/Cx ab-
breviate a node with category C and a top/bottom
feature structure including the feature-value pair {
index : x}. On substitution, the root node of the tree
being substituted in is unified with the node at which
substitution takes place. Further, when derivation
ends, the top and bottom feature structures of each
node in the derived tree are unified. Thus in this
case, x1 is unified with j and x2 with m. Hence, the
resulting semantics is:
love(j, m), name(j, john), name(m, mary)
4.2 The signature of the semantic
representation language
Let us now come back to the paraphrases given in
example 1. To produce an identical semantic rep-
resentation of these three sentences, we first need to
ensure that synonyms be assigned the same concept.
That is, we need to fix a concept inventory and to
use this inventory in a consistent way in particular,
by assigning synonyms the same concept.
For non predicative units, we use WordNet synset
numbers or when working within a restricted do-
main with a well defined thesaurus, the descriptors
of that thesaurus.
To represent the semantics of predicative units,
we use FrameNet inventory of frames and frame el-
ements (C.Johnson et al, 2002). FrameNet is an on-
line lexical resource for English based on the prin-
ciples of Frame Semantics. In this approach, a word
evokes a frame i.e., a simple or a complex event, and
each frame is associated with a number of frame el-
ements that is, a number of participants fulfilling a
given role in the frame. Finally each frame is as-
sociated with a set of target words, the words that
evoke that frame.
Thus FrameNet associates synonyms with an
identical concept namely, the frame evoked by those
synonyms. We make use of this feature and instead
of choosing our own semantic predicates and re-
lations, draw on FrameNet frames and frame ele-
ments. For instance, the paraphrases in example 1
are taken to evoke the FrameNet COMMERCE frame
and to instantiate two of its frame elements namely,
GOODS and MONEY. The semantic representation
they will be assigned will therefore be the follow-
ing:
commerce(e,g,m), cruise(g), goods(e,g), high(m),
money(e,m)
4.3 Capturing paraphrastic relations
Given the basic signature provided by FrameNet
(and any extension of it that will prove necessary
to account for the data), the grammar must then
specify a compositional semantics which will de-
rive identical representations for the types of para-
phrases captured by our typology. In essence, this
implies assigning the same semantic representations
to synonyms, converses and alternations. Con-
cretely, this involves two different subtasks : first,
a modeling of the synonymic relation between syn-
tactically divergent constructs (e.g., between a pred-
icative noun, a support verb construction and a verb)
and second, the identification of the synonymic sets
(which are the words and multi word expressions
that stand in a parallel, shuffling or definitional para-
phrastic relation?).
Modeling intercategorial synonymic links. A
first investigation of Anne Abeille??s TAG for French
suggests that modeling the synonymic relations
across syntactic constructs is reasonably straightfor-
ward. For instance, as Figures 3, 4 and 5 show, the
FTAG trees assigned on syntactic grounds by Anne
Abeille? FTAG to predicative nouns, support verb
constructions and transitive verbs can be equiped
with a flat semantics in such a way as to assign
the three sentences in 1 a unique semantic rep-
resentation namely the one given above. Gener-
ally, the problem is not so much to state the cor-
respondances between synonymic but syntactically
different constructs as to do this in a general way
while not overgeneralising. To address this prob-
lem, we are currently working on developing a
metagrammar in the sense of (Candito, 1999). This
metagrammar allows us to factorise both syntac-
tic and semantic information. Syntactic informa-
tion is factorised in the usual way. For instance,
there will be a class NOVN1 which groups together
all the initial trees representing the possible syntac-
tic configurations in which a transitive verb with
two nominal arguments can occur. But addition-
nally there will be semantic classes such as, ?bi-
nary predicate of semantic type X? which will be
associated with the relevant syntactic classes for in-
stance, NOVN1 (the class of transitive verbs with
nominal arguments), BINARY NPRED (the class of
binary predicative nouns), NOVSUPNN1 , the class
of support verb constructions taking two nominal
arguments. By further associating semantic units
(e.g., ?cost?) with the appropriate semantic classes
(e.g., ?binary predicate of semantic type X?), we
can in this way capture both intra and intercategorial
paraphrasing links in a general way.
Constructing paraphrastic sets. Depending on
the type of paraphrastic means involved, construct-
ing a paraphrastic set (the set of all lexical items re-
lated by a paraphrastic link be it parallel, shuffling
or definitional) is more or less easy as resources for
that specific means may or may not be readily avail-
able.
Cases of intracategorial synonymy are relatively
straigthtforward as several electronic synonym dic-
tionnaries for french are available (Ploux, 1997).
Multi word expressions however remain a problem
as they are often not or only partially included in
such dictionnaries. For these or for a specific do-
main, basic synonymic dictionaries can be comple-
mented using learning methods based on distribu-
tional similarity (Pereira et al, 1993; Lin, 1998).
techniques.
For intercategorial synonymy involving a deriva-
tional morphology link, some resources are avail-
able which however are only partial in that they only
store morphological families that is, sets of items
that are morphologically related. Lexical semantics
information still need to be included.
Intercategorial synonymy not involving a deriva-
tional morphology link has been little studied and
resources are lacking. However as for other types
of synonymy, distributional analysis and clustering
techniques can be used to develop such resources.
For shuffling paraphrases, french alternations are
partially described in (Saint-Dizier, 1999) and a re-
source is available which describes alternation and
the mapping verbs/alternations for roughly 1 700
verbs. For complementing this database and for
converse constructions, the LADL tables (Gross,
1975) can furthermore be resorted to, which list
detailed syntactico-semantic descriptions for 5 000
verbs and 25 000 verbal expressions. In particu-
lar, (Gross, 1989) lists the converses of some 3 500
predicative nouns.
S
GNG ? V GAdvM ?
coute
GNX S:Commerce GAdvY
D NX ? (S,G):goods cher
la (S,M):money Y:High
NX
croisiere
X:Cruise
Figure 3: La croisie`re cou?te cher
S
GNG ? VSup? GN
a D? NGMGNX
cout
D NX ? D S:Commerce
la un (S,M):money
NX (S,G):goods
croisiere N
X:Cruise ? NY Adj
eleve
Y:High
Figure 4: La croisie`re a un cou?t e?leve?
5 Conclusion
Besides the development and evaluation of a core
paraphrastic testsuite and grammar for French, we
plan to investigate two main issues. First, how pre-
cisely should a metagrammar be structured to best
describe a paraphrastic grammar? And second: is
it possible to extract from the kind of inference
rules automatically derived in machine learning ap-
proach, information that can be used to specify this
metagrammar?
6 Acknowledgments.
This paper is based upon work suppported in part by
the project ?Des connaissances a` leurs re?alisation en
langue? within the CNRS funded TCAN program.
SGNY ? Cop GAdjY ?
GNY est eleve
D NY ? Y:High
le
NM
N GP
cout P? GNG ?
S:Commerce
(S,M):money P GNX
(S,G):goods de D NX
la croisiere
X:Cruise
Figure 5: Le cou?t de la croisie`re est e?leve?
References
A. Abeille?. 2002. Une Grammaire Electronique du
Franais. CNRS Editions.
R. Barzilay and L. Lee. 2003. Learning to
paraphrase: an unsupervised approahc using
mutliple-sequence alignment. In Proceedings of
NAACL-HLT.
A. Black, S. Abney, D. Flickinger, C. Gdaniec,
R. Grishman, P. Harrison, D. Hindel, R. INgria,
F. Jelinek, F. Klaavans, M. Liberman, M. Mar-
cus, S. Roukos, B. Santorini, and T. Strzalkowski.
1991. A procedure for quantitatively comparing
the syntactic coverage of english grammars. In
Proceedings of teh 4th DARPA Speech and Natu-
ral Language Workshop.
J. Bos. 1995. Predicate logic unplugged. In Paul
Dekker and Martin Stokhof, editors, Proceedings
of the 10th Amsterdam Colloquium, pages 133?
142.
M.H Candito. 1999. Un outil multilingue de gener-
ation de ltag : application au francais et a l?italien.
TAL, 40(1).
C.Johnson, C. Fillmore, M. Petruckand C. Baker,
M. Ellsworth, and J. Ruppenhofer. 2002.
Framenet: Theory and practice. Technical report,
Berkeley.
Ann Copestake and Dan Flickinger. 2000. An open
source grammar development environment and
broad-coverage English grammar using HPSG.
In Proceedings of the 2nd International Con-
ference on Language Resources and Evaluation,
Athens, Greece.
A. Copestake, D. Flickinger, I. Sag, and C. Pollard.
1999. Minimal Recursion Semantics. An Intro-
duction. Manuscript, Stanford University.
A. Copestake, A. Lascarides, and D. Flickinger.
2001. An algebra for semantic construction in
constraint-based grammars. In Proceedings of
the 39th Annual Meeting of the Association for
Computational Linguistics, Toulouse, France.
M. Dalrymple. 1999. Semantics and syntax in lexi-
cal functional grammar. MIT Press.
D. Flickinger, J. Nerbonne, I. Sag, and T. Wasow.
1987. Towards evaluation of nlp systems. Tech-
nical report, Hewlett-Packard Laboratories.
C. Gardent and L. Kallmeyer. 2003. Semantic con-
struction in ftag. In Proceedings of EACL, Bu-
dapest, Hungary.
O. Glickman and I. Dagan. 2003. Identifying lexi-
cal paraphrases from a single corpus: a case study
for verbs. In Proceedings of Recent Advances in
Natural Language Processing.
M. Gross. 1975. Me?thodes en syntase. Masson,
Paris.
G. Gross. 1989. Les constructions converses du
francais. CNRS Editions.
Dekang Lin and Patrick Pantel. 2001. Discovery of
inference rules for question answering. Natural
Language Engineering.
D. Lin. 1998. Automatic retrieval and clustering of
similar words. In Proceedings of ACL/COLING,
pages 768?774.
I. Mel?c?uk. 1988. Paraphrase et lexique dans la
thorie linguistique sens-texte. Lexique, 6:13?54.
S. Oepen and D. Flickinger. 1998. Towards sys-
tematic grammar profiling. test suite technology
10 years after. Computer Speech and Language,
12:411?435.
F. Pereira, N. Tishby, and L. Lee. 1993. Distribu-
tional clustering of english words. In Proceed-
ings of the ACL, pages 183?190.
S. Ploux. 1997. Modlisation et traitement infor-
matique de la synonymi. Linguisticae Investiga-
tiones, XXI(1).
P. Saint-Dizier, 1999. Alternations and Verb Se-
mantic Classes for French: analysis and class
formation, chapter 5. Kluwer.
Y. Shinyanma, S. Sekine, K. Sudo, and R. Grish-
man. 2002. Automatic paraphrase acquisition
from news articles. In Proceedings of HLT.
Adjective based inference?
Marilisa Amoia
INRIA/Universite? de Nancy 1 &
University of the Saarland
Saarbru?cken Germany
amoia@coli.uni-sb.de
Claire Gardent
CNRS/Loria
Campus Scientifique BP 239
54506 Vandoeuvre-les-Nancy, France
claire.gardent@loria.fr
Abstract
In this paper, we propose a fine grained
classification of english adjectives geared
at modeling the distinct inference patterns
licensed by each adjective class. We show
how it can be implemented in description
logic and illustrate the predictions made
by a series of examples. The proposal has
been implemented using Description logic
as a semantic representation language and
the prediction verified using the DL theo-
rem prover RACER.
Topics: Textual Entailment, Adjectival Semantics
1 Introduction
Understanding a text is one of the ultimate goals
of computational linguistics. To achieve this goal,
systems need to be developed which can construct
a meaning representation for any given text and
which furthermore, can reason about the meaning
of a text. As is convincingly argued in (Ido Dagan
and Magnini, 2005), one of the major inference
task involved in that reasoning is the entailment
recognition task:
Does text T1 entail text T2?
Indeed entailment recognition can be used to
determine whether a text fragment answers a
question (e.g., in question answering application),
whether a query is entailed by a relevant document
(in information retrieval), whether a text fragment
entails a specific information nugget (in informa-
tion extraction), etc.
Because the Pascal RTE challenge focuses on
real text, the participating systems must be robust
that is, they must be able to handle unconstrained
?We thank la Re?gion Lorraine, INRIA and the University
of Sarrebruecken for partially funding the research presented
in this paper.
input. Most systems therefore are based on sta-
tistical methods (e.g., stochastic parsing and lex-
ical distance or word overlap for semantic simi-
larity) and few provide for a principled integra-
tion of lexical and compositional semantics. On
the other hand, one of the participant teams has
shown that roughly 50% of the RTE cases could
be handled correctly by a system that would ade-
quately cover semantic entailments that are either
syntax based (e.g., active/passive) or lexical se-
mantics based (e.g., bicycle/bike). Given that the
overall system accuracies hovered between 50 and
60 percent with a baseline of 50 %1, this suggests
that a better integration of syntax, compositional
and lexical semantics might improve entailment
recognition accuracy.
In this paper, we consider the case of adjectives
and, building on approaches like those described
in (Raskin and Nirenburg, 1995; Peters and Pe-
ters, 2000), we propose a classification of adjec-
tives which can account for the entailment patterns
that are supported by the interaction of their lexi-
cal and of their compositional semantics. We start
by defining a classification schema for adjectives
based on their syntactic and semantic properties.
We then associate with each class a set of axioms
schemas which translate the knowledge about lex-
ical relations (i.e. antonymy) the adjectives of the
class are involved in by extracting this information
from WordNet (Miller, 1998) and a set of seman-
tic construction rules and we show that these cor-
rectly predicts the observed entailment patterns.
For instance, the approach will account for the fol-
lowing (non)-entailment cases:
(1) a. John frightened the child
|= The child is afraid
150% of the cases were true entailment and 50% were
false ones, hence tossing a coin would get half of the cases
right.
20 KRAQ06
b. Peter claims that John is a murderer
|= John is an alledged murderer
6|= John is a murderer
c. This is a fake bicycle
|= This is a false bike
|= This is not a real bike
6|= This is a bike
d. John is not awake
|= John sleeps
6|= John does not sleep
The approach is implemented using Description
Logic as a semantic representation language and
tested on a hand-built semantic test suite of ap-
proximately 1 000 items. In the latter part of the
paper we discuss this testsuite and the philosophy
behind it.
2 A fine grained classification for
adjectives
As mentioned above, we propose a classification
of adjectives based on their lexical, their model
theoretic and their morpho-derivational properties.
To facilitate the link with compositional semantics
(the construction of a meaning representation for
sentences containing adjectives), we also take into
account syntactic properties such as the predica-
tive/attributive or the static/dynamic distinction.
We now detail each of these properties. The over-
all categorisation system is given in Figure 1.
2.1 Model theoretic properties
The main criteria for classification are given by
(Kamp, 1975; Kamp and Partee, 1995) seman-
tic classification of adjectives which is based on
whether it is possible to infer from the Adj+N
combination the Adj or the N denotation.
Intersective adjectives (e.g., red) licence the
following inference inference patterns:
A + N |= A
A + N |= N
For instance, if X is a red car then X is a car and
X is red
Subsective adjectives (e.g., big) licence the
following inference pattern:
A + N |= N
For instance, if X is a big mouse, then X is a mouse
but it is not necessarily true X is big
Privative adjectives licence the inference pattern:
A + N |= ?N
For instance, if X is a fake gun then X is not a gun
Plain non-subsective adjectives (e.g., alledged)
do not licence any inference
For instance, if X is an alleged murderer then it is
unknown whether X is a murderer or not
2.2 Lexical semantics
From the lexical semantics literature, we take
one additional classification criterion namely
antonymy. As described in (Cruse, 1986), this
term covers different kinds of opposite polarity re-
lations between adjectives namly, binary opposi-
tion, contraries and multiple oppositions.
Binary oppositions covers pairs such as wet/dry
which license the following inference pattern:
A1 ? ?A2 ? ?A1 ? A2
So that in particular:
wet ? ?dry ? ?wet ? dry
Contraries are pairs such as long/short where the
implication is unidirectional:
A1 |= ?A2 ? ?A1 6|= A2
A2 |= ?A1 ? ?A2 6|= A1
and in particular:
long |= ?short ? ?long 6|= short
short |= ?long ? ?short 6|= long
Multiple oppositions involve a finite set of adjec-
tives (e.g., linguistic/economic/mathematical/... )
which are pairwise mutually exclusive. For a set
of opposed adjectives A1 . . . An, the following ax-
ioms schemas will be licensed:
?i, j s.t. 1 ? i, j ? and i 6= j
Ai |= ?Aj and ?Ai 6|= Aj
2.2.1 Derivational morphology
We also take into account related forms that is,
whether there exists a verb (Va) or a noun that is
semantically related to the adjectives being con-
sidered. Moreover, for nominalizations we distin-
guish whether the morphologically related noun is
an event noun (Ne), a noun denoting a theta role
of the related verb (N?) or a non-event noun (Na).
As we shall see, this permits capturing entail-
ment relations between sentences containing mor-
phoderivational variants such as for instance :
21 KRAQ06
(2) a. John is asleep (Adj ? Va)
|= John sleeps
b. John is absent (Adj ? N?)
|= John is the absentee
c. John is deeply asleep (Adj ? Ne)
|= John?s sleep is deep
2.2.2 Syntactic properties
To better support the syntax/semantic interface,
we refine the adjectives classes distinguishable on
the basis of the above criteria with the following
syntactic ones taken from (Quirk et al, 1985).
Attributiveness/Predicativeness. English adjec-
tives can be divided in adjectives which can be
used only predicatively (such as alone), adjectives
which can be used only attributively (such as me-
chanical in mechanical enginner) and adjectives
which can be used in both constructions such as
red.
Modifiability by very. We distinguish between
adjectives such as nice which can be modified by
very (i.e. very nice) and adjectives such as alleged
which cannot (*very alleged).
Gradability. We distinguish between adjectives
such as big which express gradable properties and
have comparative and superlative forms (bigger,
biggest) and adjectives such as rectangular which
don?t (*more rectangular).
Staticity/Dynamicity. Dynamic adjectives can be
used in imperative constructions and in the pro-
gressive form (Be reasonable, He is being reason-
able), static adjectives cannot (*Be short, He is be-
ing short).
3 Semantic Classes and textual
entailment recognition
In order to build our classification, we have anal-
ysed a set of about 300 english adjectives each
of which was manually mapped to the WordNet
synset correspondent to the more frequent mean-
ing of the adjective. In some case, when an ad-
jective presents polysemic forms which belong to
different semantic classes more than one form has
been considered. For example, for the adjective
civil we consider two senses/forms civil1 (syn-
onym of polite, as in civil man) and civil2 (as in
civil engineer) which belong to different semantic
classes, the first being intersective and the second
subsective. As Figure 1 shows, the proposed clas-
sification includes 15 adjective classes, each with
distinct syntactic and semantic properties.
To account for these differences, we define for
each class a set of axiom schemas capturing the
model theoretic, lexical semantics and morpho-
derivational properties of that class. Lexical se-
mantics and morpho-derivational information are
derived from WordNet. For example, the axioms
describing antonymy are obtained by extracting
from WordNet the antonyms of a particular adjec-
tive and then by considering the direction of the
entailment relevant for the class the adjective be-
longs to:
asleep ? wake vs. polite <rude
Morpho-derivational information are derived from
WordNet by extracting the derivationally related
forms for the given adjective and then iterating the
extraction on nouns and verbs in order to obtain
information about their antonyms and hyponyms.
For scalar adjective like tall, WordNet contains
also a relation is a value of which offers a
pointer to the noun concept the adjective is a value
of. Moreover, WordNet links the noun concept to
a list of attributes which describe the scalar prop-
erty it represents. For example, the adjective tall
is a value of {stature,height} and attributes
of {stature,height} are tall and short.
Based on some basic syntactic patterns, we then
show that these axioms predict the observed tex-
tual entailment patterns for that class.
Before we illustrate this approach by means of
some example, we first show how we capture log-
ical entailment between NL semantic representa-
tions in a description logic setting.
3.1 Using description logic to check
entailment between NL sentences
As argued in (Gardent and Jacquey, 2003), de-
scription logic (DL) is an intuitive framework
within which to perform lexical reasoning: it is
efficient (basic versions of description logics are
decidable), it is tailored to reason about complex
taxonomies (taxonomies of descriptions) and it
is equipped with powerful, freely available auto-
mated provers (such as RACER, (Volker Haarslev,
2001)). For these reasons, we are here exploring a
DL encoding of the entailment recognition task for
the set of examples we are considering.The partic-
ular language we assume has the following syntax.
C, D ? A|>|?|?A | C u D | C unionsq D | ?R.C | ?R.C
The semantics of this language is given below with
? the domain of interpretation and I the interpre-
tation function which assigns to every atomic con-
22 KRAQ06
Adjective Class Predicative/Attributive Modifiable by very Gradability static/dynamic Antonymy Related forms Semantic class
Class 1: afloat predicative-only - - static multi-opposition Va , Ne , N? intersective
Class 2: asleep predicative-only + - static binary-opposition Va , Ne , N? intersective
Class 3: polite both + + dynamic contraries Na intersective
Class 4: dry both + + static binary-opposition Va , Ne , N? intersective
Class 5: open both - - dynamic binary-opposition Va , Ne , N? intersective
Class 6: male both - - static multi-opposition Na , Ne , intersective
Class 7: authentic both + - static binary-opposition Ne intersective
Class 8: big both + + static contraries Ne subsective
Class 9: good both + + dynamic contraries Ne subsective
Class 10: cultural attributive-only - - static multi-opposition Na subsective
Class 11: recent attributive-only + - static multi-opposition Ne subsective
Class 12: fake both - - static binary-opposition Va ,Ne privative
Class 13: former attributive-only - - static multi-opposition privative
Class 14: questionable both + - static contraries Va , Ne plain non-subsective
Class 15: alleged attributive-only - - static contraries Va plain non-subsective
Figure 1: Classes of Adjectives
cept A, a set AI ? ? and to every atomic role R
a binary relation RI ? ? ? ?.
>I = ?
?I = ?
(?A)I = ?\AI
(C u D)I = CI ? DI
(C unionsq D)I = CI ? DI
(?R.C)I = {a ? ? | ?b(a, b) ? RI ? b ? CI}
(?R.C)I = {a ? ? | ?b ? CI ? (a, b) ? RIn}
Now one basic problem with using DL to check
entailment between NL expressions, is that DL
formulae are ?directional? in that they refer to a
given set of individuals. For instance the sentence
The boat is floating might be represented by either
of the two formulae given in 3 but these two for-
mulae do not stand in an entailment relation (since
they refer to different kind of objects namely float-
ing event of a boat in 3a and boats that float in 3b).
(3) a. float u?theme.boat
b. boat u?theme?1.float
To remedy this shortcoming, we introduce the
notion of a rotation. Given a DL formula which
only contains conjunction (disjunction is trans-
lated in DL as different formulas)
? = ui=1,n Eventi uj=1,m ?Rj .Typej
a rotation of this formula is defined as:
1. ?
2. ?j ? {1, ..., m} :
Typej u ?R?1j .(ui=1,nEventi u1<k<j,j<k<m
?Rk.Typek)
so that the formula:
Event1u Event2 u ...u Eventn u?R1.Type1 u?R2.Type2 ...
u?Rn.Typen
corresponds to the following n Rotations each of
which describe the same situation from the point
of view of a particular type
0. Event u?R1.Type1 u?R2.Type2 ... u?Rn.Typen
? Event
1. Type1 u?R?11 .(Event u?R2.Type2 ... u?Rn.Typen)
? Type1
2. Type2 u?R?12 .(Event u?R1.Type1 ... u?Rn.Typen)
? Type2
...
n. Typen u?R?1n .(Event u?R1.Type1 ... u?Rn?1.Typen?1)
? Typen
So for example, the sentence Mary knows that
John is the inventor of the radio will be repre-
sented as a predicate logic formula
?x1mary(x1) ? ?x2john(x2) ? ?x3radio(x3) ? ?e1know(e1) ?
?agent(e1, x1)??topic(e1 , e2)??e2invent(e2)?agent(e2 , x2)?
patient(e2 , x3)
the denotation of this PL formula corresponds to
the set of individuals {x1, x2, x3} ? {e1, e2}. The
corresponding DL representation will be the un-
derspecified representation
know u? agent.mary u? topic.( invent u?agent.john u? pa-
tient.radio)
the denotation of which corresponds to the set
{e1} and all its rotations which permit to access
the other sets of individuals asserted in the sen-
tence. Thus for example, the set {x1} which
describes the individual Mary can be accessed
through the following rotation:
Rotation1: mary u? agent?1.(know u? topic.( invent
u?agent.john u? patient.radio))
Finally, we say that an arbitrary for-
mula/representation ?1 implies the formula
?2 iff it is possible to find a rotation Rotationi of
?1 the denotation of which describes a subset of
the denotation of ?2:
Definition
?1 |= ?2 iff ?i.Rotationi(?1) v ?2 (1)
23 KRAQ06
3.2 Example class axioms and derivations
We now illustrate our approach by looking at two
classes in more detail namely, class 1 and class 8.
3.2.1 Class 1
Syntactically, Class 1 contains adjectives like
adrift,afloat,aground which can only be used pred-
icatively, are non gradable and cannot be modified
by very. Semantically, they behave like intersec-
tive adjectives which enter in multiple opposition
relations with other adjectives. They are further-
more morphologically derived from verbs and can
be nominalized. To reflect these semantic proper-
ties we use the following axioms.
Model theoretic semantics. Adjectives of class
1 are intersective adjective. They will thus li-
cence the correponding inference patterns namely:
A + N |= A (2)
A + N |= N (3)
Lexical semantics. Adjectives of class 1 enter in
multiple opposition relations. Hence For instance:
afloat |= ? aground ?? afloat 6|= aground
aground |= ? afloat ?? aground 6|= afloat
sunken |= ? afloat ?? afloat 6|= sunken
afloat |= ? sunken ?? sunken 6|= afloat
Morpho-derivational semantics. Adjectives in
Class 1 can be related to both nouns and verbs.
Thus, for example the adjective afloat in WordNet
is related to the noun floating which is related to
the verb float, by assuming that the semantics as-
signed to the verb float is float(e), theme(e,a), the
adjective afloat is assigned the following seman-
tics:
afloat ? ? Theme?1.float
This is encoded in the following axiom schemas:
MDR 1. Adj1 < ? Adj2 If Adj1 = Anto(Adj2)
e.g., afloat < ? sunken
MDR 2. Adj1 ? ? Theme?1.V1 If Adj1 is related to V1
e.g.,afloat ? ? Theme?1.float
MDR 3. V1 < ? V2 If V1 = Anto(V2)
e.g., float < ? sink
MDR 4. N1 ? V1 If Adj1 is related to an evt denoting N1
e.g., floating ? float
MDR 5. N1 < ? N2 If N1 is an antonym of N2
e.g., floating < ? sinking
MDR 6. N11 ? ? Theme?1.V1 If Adj1 is related to a
noun N11 denoting the theme role of the verb V1
e.g., floater ? ? Theme?1.float
We make the following assumptions about the
syntax/semantic interface that is, about the seman-
tic representations associated with given sentence
patterns.
SCR 1. NP toBe Adj
ADJ u NP
SCR 2. NP toBe clearly Adj
ADJ u NP
SCR 3. Ni[+event] of NP is clear
V i u ?theme.NP
SCR 4. Nii[-event] is clear
?theme?1.V i
SCR 5. NP toBe V[+ing].
V u ?Theme.NP
Given the above axiom schemas and semantic
constructions rules, the following inference pat-
terns can be handled:
1. ADJ1 + N |= N
Ex. This boat is afloat. |= This is a boat.
2. ADJ1 + N |= ADJ1
Ex. This boat is afloat. |= This is afloat.
3. ADJ1 + N 6|= ? N
Ex. The boat is afloat. 6|= This not a boat.
4. ADJ1 + N |= ? ADJ2 u N
Ex. The boat is afloat. |= The boat is not sunken.
5. ? ADJ1 + N 6|= ADJ2 u N
Ex. The boat is not afloat. 6|= The boat is sunken.
6. ADJ1 + N |= N u?theme?1.V 1
Ex. The boat is afloat. |= The boat is the floater.
7. ADJ1 + N |= V1 u?theme.N
Ex. The boat is afloat. |= The boat is floating.
8. ADJ1 + N |= N1 u?theme.N
Ex. This boat is clearly afloat. |= The floating of the
boat is clear.
9. ADJ1 + N |= N u?theme?1.N1
Ex. This boat is clearly afloat. |= The floating of the
boat is clear (or the boat is the floating object).
10. ? (ADJ1 + N) |= ? (V1 u?theme.N) 6|= ? N
Ex. This is not a floating boat. 6|= This is not a boat.
11. ? (ADJ1 + N) 6|= ? Adj1
Ex. This is not a floating boat. 6|= This is not afloat.
12. ? (ADJ1 + N) 6|= ? V1
Ex. This is not a floating boat. 6|= This is not floating.
13. ? (ADJ1 + N) 6|= ? N1
Ex. This is not a floating boat. 6|= This is not a floating.
14. ? (ADJ1 + N) 6|= ? ? theme?1.V1
Ex. This is not a floating boat. 6|= This is not the floater.
15. ? (ADJ1 + N) 6|= ? ? theme.N
Ex. This is not a floating boat. 6|= This is not a floating.
24 KRAQ06
In the inference patterns 10 to 15, the negation
of the adjective-noun compound ? (ADJ1 + N) is
syntactically blocked, as the adjectives in this class
are used predicative only, however the equivalent
representation V1 u?theme.N can be used to mo-
tivate the inferences.
The following show in more detail how the first
three of the above (non) entailments are recog-
nised.
(4) a. The boat is afloat.
b. |= The boat is floating.
4a ? Boat u Afloat (by SCR 1) A
4b ? Float u?Theme.Boat (by SCR 5) B
Afloat ? ?Theme?1.F loat (by MDR 2) C
1 ? Boat u?Theme?1.F loat (from A and C) D
D |= B (By Defn 1) E
(5) a. The boat is afloat.
b. |= The boat is the floater.
5a ? Boat u Afloat (by SCR 1) A
5b ? Boat u?Theme?1.f loat (by SCR 4) B
Afloat ? ?Theme?1.F loat (by MDR 2) C
A |= B (from B und C) D
(6) a. The boat is afloat.
b. |= The boat is not sinking.
6a ? Boat u Afloat (by SCR 1) A
6b ? ? sink u?Theme.boat (by SCR 5) B
Afloat ? ?Theme?1.F loat (by MDR 2) C
Boat u?Theme?1.F loat (from A and C) D
float u?Theme.boat (By Defn 1) E
E |= B (by MDR 1) F
3.2.2 Class 8.
Class 8 contains adjectives like
big,fast,tall,deep which can be used attribu-
tively and predicatively, are gradable, can be
modified by very. Semantically, they are classified
as subsective adjectives and their antonyms are
contraries. They are morphologically related
to nouns which describe the particular property
denoted by the adjectives and to nouns of which
they are attributes.
Model theoretic semantics. Adjectives of
class 8 are subsective adjective. They will thus li-
cence the correponding inference patterns namely:
A + N 6|= A (4)
A + N |= N (5)
Lexical semantics. The Adjectives of class 8 en-
ter in contrary opposition relations. Hence, the fol-
lowing axioms schemas will be licensed:
Ai |= ?Anto(Ai) and ?Ai 6|= Anto(Ai)
(6)
For instance:
long |= ? small ?? long 6|= small
deep |= ? shallow ?? deep 6|= shallow
Morpho-derivational semantics. Adjectives in
Class 8 can be related to nouns but not to
verbs. Moreover, such adjectives are mapped
in WordNet to noun concepts through two dif-
ferent links: derivationally related to
and is a value of. For example, the adjec-
tive tall in WordNet is derivationally related to the
noun tallness and is a value of the concept noun
height. The adjectives in this class describe grad-
able properties so that their semantics corresponds
to:
has-property(Related Noun u?has-measure.Top)
in which the role has-measure account for the
value of the scalar property described by the adjec-
tive, which remain underspecified (Top) if the ad-
jective is used without a reference to the value of
measure. When the value of the measure is speci-
fied, for example by combining the adjective with
a noun, as for example in This is a tall man, then
the noun is assigned as a value of the measure role:
man u?has-property.(tallness
u?has-measure.man)
which translate This is tall as a man.
This is encoded in the following axiom
schemas:
MDR 1. Adj1 < ? Adj2 If Adj1 = Anto(Adj2)
Ex. tall < ? short
MDR 2. Adj1 < ? has property.(N1 u?has measure.Top)
If Adj1 is related to a noun N1 denoting the property
described by Adj1
Ex. tall < ? has property.(tallness
u?has measure.Top)
MDR 3. N1 < ? N2 If N1=Anto(N2)
Ex. tallness < ? shortness
MDR 4. N1 ? N? u?has value.Adj1
If Adj1 is an attribute of the noun N?
Ex. tallness ? height u?has value.tall
MDR 5. N2 ? N? u?has value.Adj2
If Adj2 is an attribute of the noun N?
Ex. shortness ? height u?has value.short
MDR 6. N1 < N? If N1 is an hyponym of N?
Ex. tallness < height
25 KRAQ06
MDR 7. N2 < N? If N2 is an hyponym of N?
Ex. shortness < height
MDR 8. Adj11 < Adj1 If Adj1 is a
scalar attribute with value less then Adj11 (hyponymy
is not defined for adjectives)
Ex. giant < tall
For the moment, we don?t account for the se-
mantics of comparatives forms of adjectives but
we will do that in the feature, by also introducing a
representation for scales as described in (Kennedy,
2005).
We make the following assumptions about the
semantic representations associated with basic
sentence patterns.
SCR 1. NP toBe Adj
NP u? has property.(N1 u?has measure.NP)
SCR 2. That toBe Det Adj NP
NP u? has property.(N1 u?has measure.NP)
SCR 3. NP toBe clearly Adj
NP u? has property.(N1 u?has measure.NP)
SCR 4. N1 of NP is clear
NP u? has property.(N1 u?has measure.NP)
SCR 5. The Adj N? of NP
NP u? has property.(N? u? has value.Adj
u?has measure.NP )
SCR 6. NP1 toBe Adj as a N
NP1 u N u?has property.(N? u? value.Adj u?
has measure.N)
SCR 7. NP1 toBe NP2[+measure] Adj
NP1 u?has property.(N? u? value.Adj u?
has measure.NP2)
SCR 8. NP1 toBe NP2[+measure] Adj N
NP1 u N u?has property.(N? u?has value.Adj u?
has measure.NP2)
Given the above axioms, the following exam-
ples can be handled:
(7) (a) John is a 1.50 meter tall man.
|= (b) John is 1.50 meter tall.
7a ? John u Man u?has property.(height A
uhas value.tall uhas measure(1.50 meter) )
(by SCR 8)
7b |= John u?has property.(height uhas value.tall B
uhas measure(1.50 meter) )
(by SCR 7 and from A)
A |= B C
(8) (a) John is a 1.50 meter tall man. 6|= (b) John
is a tall man.
8a ? John u Man u?has property.(height A
uhas value.tall uhas measure(1.50 meter) )
(by SCR 8)
8b |= John u Man u?has property.(height u B
has value.tall uhas measure(man) )
(by SCR1 and from A)
A 6|= B C
4 Implementation
For each of the 15 classes, we have specified a set
of axioms schemas, some basic semantic construc-
tion rules and a set of inference patterns which
could be deduced to follow from both of these.
The axioms schemas were implemented in De-
scription Logic using RACER and for each infer-
ence pattern identified, the corresponding Descrip-
tion Logic query was checked to verify that the
proposed axioms and semantic construction rules
did indeed correctly predict the deduced inference
patterns.
5 Further work and evaluation
The main contribution of this work is a detailed
analysis of the interactions between derivational
morphology, lexical and compositional semantics
and of their impact on the entailment patterns li-
censed by sentences containing adjective or their
related nouns/verbs.
To turn this analysis into a computational sys-
tem, its components need to be integrated into a
semantic analyser and the behaviour of that anal-
yser tested against a collection of data. We are
currently working on developing such an anal-
yser within a symbolic grammar framework. We
have also started to develop an evaluation test
suite geared towards entailment recognition be-
tween sentence pairs containing adjectives. At the
moment, the test suite contains about 1 000 infer-
ence pairs. Each item in the TestSuite (see fig. 2)
is annotated with a judgement about the truth of
the entailment between the pair of sentences, with
the type of inference involved and with the speci-
fication of adjective involved. Moreover, each ad-
jective is annotated with the WordNet sense corre-
sponding to the given class.
The idea behind this test suite is similar to
that underlying the creation of the TSNLP (Test
suite for natural language processing) (see (Oepen
and Netter, 1995)) or the Eurotra testsuites (see
(Arnold and des Tombe, 1987)) namely, to pro-
vide a benchmark against which to evaluate and
compare existing semantic analyzers. Thus this
26 KRAQ06
<pair id="1" value="TRUE" class="[CLASS1]" inference="Adj/Verb">
<t>The boat is <sn n="1"> afloat </sn>.</t>
<h>The boat is floating.</h>
</pair>
<pair id="2" value="FALSE" class="[CLASS6]" inference="Antonymy">
<t>This is not a <sn n="1"> rectangular </sn> table.</t>
<h>This is a <sn n="1"> round </sn> table </h>
</pair>
<pair id="3" value="TRUE" class="[CLASS8]" inference="Adj/Noun">
<t>The line is 2 meter <sn n="1"> long </sn>.</t>
<h>The length of the line is 2 meter.</h>
</pair>
<pair id="4" value="FALSE" class "[subs/intersective]" inference="Attr/Pred">
<t>The treasurer is <sn n="2"> present </sn>.</t>
<h>This is the <sn n="1"> present </sn> treasurer.</h>
</pair>
Figure 2: TestSuite
test suite illustrates the semantic and syntactic be-
haviour of adjectives and their related verbs/nouns
with respect to textual entailment. One could
imagine other test suites illustrating the seman-
tic behaviour of verbs, of quantifiers, of discourse
connectives, etc. Just as the TSNLP still proves
useful in supporting the development of new sym-
bolic parsers/grammars, hand built test suites of
artificial examples might prove useful in improv-
ing the accuracy of semantic analyser wrt textual
entailment. Indeed the Pascal RTE challenge has
shown that existing systems fares rather poortly at
the textual entailment task. Providing a set of hand
crafted semantic test suites might help in remedy-
ing this shortcoming.
Beside implementing and evaluating the anal-
ysis of adjectives presented in this paper, we are
also working on refining this analysis by combin-
ing it with a detailed analysis of noun semantics so
as to handle (non) entailments such as:
(9)
Lyon is the gastronomical capital of France
6|= Lyon is the capital of France
References
D.J. Arnold and Luis des Tombe. 1987. Basic Theory
and methodology in Eurotra. Cambridge University
Press.
DA. Cruse. 1986. Lexical Semantics. Cambridge Uni-
versity Press.
Claire Gardent and Evelyne Jacquey. 2003. Lexical
reasoning. In Proceedings of the ICON?03 (Inter-
national Conference on Natural Language Process-
ing), Mysore, India.
Oren Glickman Ido Dagan and Bernardo Magnini.
2005. The PASCAL Recognising Textual Entailment
Challenge.
Hans Kamp and Barbara Partee. 1995. Prototype the-
ory and compositionality. Cognition, (57):129?191.
Hans Kamp. 1975. Two theories about adjectives. In
Edward L. Keenan (ed.), Formal Semantics of Nat-
ural Language, pages 123?155. Cambridge Univer-
sity Press.
Christofer Kennedy. 2005. Vagueness and grammar:
The semantics of relative and absolute gradable ad-
jectives. Ms., pages 129?191, June.
K. J. Miller. 1998. Modifiers in wordnet. In
C. Fellbaum (ed.), WordNet An Electronic Lexical
Database. Cambridge, MA, The MIT Press.
Stephan Oepen and Klaus Netter. 1995. TSNLP -
test suites for natural language processing. Gronin-
gen, The Netherlands. Conference on Linguistic
Databases.
I. Peters and W. Peters. 2000. The Treatment of Adjec-
tives in SIMPLE: Theoretical Observations. Athens.
R. Quirk, S. Greenbaum, G. Leech, and J. Svartvik.
1985. A Comprehensive Grammar of the English
Language. Longman.
V. Raskin and S. Nirenburg. 1995. Lexical Semantics
of Adjectives, a micro-theory of adjectival meaning.
MCCS Report.
Ralf Mo?ller Volker Haarslev. 2001. Description of the
racer system and its applications. In Proceedings
International Workshop on Description Logics (DL-
2001, Stanford, USA.
27 KRAQ06
Proceedings of the Workshop on Textual Entailment and Paraphrasing, pages 185?192,
Prague, June 2007. c?2007 Association for Computational Linguistics
A first order semantic approach to adjectival inference
Marilisa Amoia
INRIA/Universite? de Nancy 1 &
University of the Saarland
Saarbru?cken, Germany
amoia@coli.uni-saarland.de
Claire gardent
CNRS/Loria
Campus Scientifique BP 239
54506 Vandoeuvre-les-Nancy, France
claire.gardent@loria.fr
Abstract
As shown in the formal semantics litera-
ture, adjectives can display very different
inferential patterns depending on whether
they are intersective, privative, subsective
or plain non-subsective. Moreover, many
of these classes are often described using
second order constructs. In this paper, we
adopt Hobbs?s ontologically promiscuous
approach and present a first order treatment
of adjective semantics which opens the way
for a sophisticated treatment of adjectival
inference. The approach was implemented
and tested using first order automated rea-
soners.
1 Introduction
As has often been observed, not all of natural lan-
guage meaning can be represented by first order
logic. There are expressions such as, most, former,
I didn?t whose meaning intuitively involve higher-
order constructs.
Nevertheless, as (Hobbs, 1985) and others have
argued, semantic representations for natural lan-
guage need not be higher-order in that ontological
promiscuity can solve the problem. That is, by reify-
ing all objects that can be predicated of, it is possible
to retain a semantic representation scheme for NL
that is first-order.
This observation is crucial for computational ap-
plications for two reasons. First, logics that goes be-
yond first order are highly undecidable. Second and
more importantly, there is no off the shelf higher or-
der automated reasoners that could be put to use to
reason about the meaning of higher-order formulae.
In this paper, we present a semantics for adjec-
tives that adopts an ontologically promiscuous ap-
proach and thereby supports first order inference for
all types of adjectives including extensional ones.
Indeed, traditional semantic classifications of ad-
jectives such as (Chierchia and Connell-Ginet, 1990;
Kamp, 1975; Kamp and Partee, 1995) subdivide
adjectives into two classes namely extensional vs.
intensional adjectives, the latter grouping together
adjectives which intuitively denote functions from
properties to properties, i.e. second order objects.
We present a compositional semantics for ad-
jectives which both (i) defines a first order repre-
sentation and (ii) integrates interactions with other
sources of linguistic information such as lexical se-
mantics and morpho-derivational relations. We then
show that the proposed semantics correctly predicts
the inferential patterns observed to hold of the var-
ious adjective subclasses identified in the literature
(Chierchia and Connell-Ginet, 1990; Kamp, 1975;
Kamp and Partee, 1995; Amoia and Gardent, 2006).
This paper is structured as follows. We start by
presenting a classification of adjectives which is mo-
tivated by the different inferential patterns observed.
We then propose a compositional semantics for each
class and show that it correctly predicts their inferen-
tial behaviour. We conclude with a brief discussion
of related work and pointers for further research.
2 Inferential patterns and adjective classes
In the literature (Chierchia and Connell-Ginet, 1990;
Kamp, 1975; Kamp and Partee, 1995; Amoia and
185
Gardent, 2006), adjectives are usually divided into
four main classes namely, intersective, subsective,
privative and plain non subsective depending on
whether or not the [Adj N]AP phrase entails the
properties expressed by the noun and/or the adjec-
tive. More specifically, each of the four classes is
characterised as follows.
Intersective adjectives. This class includes com-
mon categorical (e.g., red, rectangular, French) and
tautological (e.g., real, present) adjectives. It is char-
acterised by the inferential patterns:
[A N] |= N
[A N] |= A
For instance, saying that there is a red table im-
plies both that there is something red and that there
is a table.
Subsective adjectives form an ontologically het-
erogeneous class including for instance denominal
(e.g., gastronomical) and measure (e.g. big) adjec-
tives. They are characterised by the fact that the [Adj
N]AP phrase does not entail the Adj property:
[A N] |= N
[A N] 6|= A
For instance, a big mouse is a mouse but is not
big. Instead it is ?big for a mouse?. In other words,
?bigness? cannot be directly inferred as, e.g. a big
mouse and a big elephant are big in very different
ways.
Privative adjectives denote adjectives such that
the [Adj N]AP phrase entails the negation of the N
property:
[A N] |= ?N
For instance, the former king is not the king and a
fake weapon is not a weapon.
Plain non-subsective adjectives are adjectives
which preclude any inference wrt to the N property:
[A N] |= (N ? ?N)
[A N] 6|= A
Thus, if Peter is an alleged murderer, it is impos-
sible to know whether or not he is a murderer.
Now, the class of intensional adjectives groups to-
gether adjectives with a syntactic and semantic id-
iosyncratic behaviour. Syntactically, intensional ad-
jectives are not gradable (e.g. cannot be modified
by very) and most of them can only be used attribu-
tively (He is a former president but not The presi-
dent is former). Semantically, they are usually taken
to denote second order properties, i.e. functions of
the type ??e,t?, ?e,t??.
Intensional adjectives include denominal (or rela-
tional) adjectives (e.g polar bear, atomic scientist),
manner (or adverbial) adjectives (e.g. a poor liar, a
fast car), emotive (e.g. a poor man) and modals, i.e.
all adjectives which are related to adverbs, quanti-
fiers or determiners (e.g. a feeble excuse, the specific
reason, a fake nose, etc.).
3 Assigning FOL Representation to
Intensional adjectives
We now show how adjectives can be assigned an ap-
propriate first order logic representation which ap-
propriately reflects their inferential behaviour.
Following Hobbs, we adopt a promiscuous ontol-
ogy and assume that for every predication that can
be made in natural language, there corresponds an
?eventuality?. As Hobbs has argued, this allows for
higher order predications to remain first order in that
they become predications over (first order) eventual-
ities.
Thus, in the domain there are entities which are
either eventualities or individuals and relations be-
tween individuals. Moreover like Hobbs, we assume
a model to describe a platonic universe containing
everything that can be spoken about whether or not
these things exist in the real world. To express exis-
tence in the real world, a special predicate (Exists)
is introduced.
We use the following notation:
? ei, for eventuality variables,
? xi, for individuals,
? Pi, for properties of individuals.
And the following types:
? e will denote the type of individuals,
? ev the type of eventualities and
186
? t a truth value.
3.1 The intuition
As shown in section 2, the semantics of [Adj N]AP
phrases has very different inferential properties de-
pending on the type of the adjective Adj. The differ-
ences stem from three main points.
The number of individuals introduced by the
[Adj N]AP phrase. Thus, the red table evokes a
single individual x which is both red and a table
whilst the gastronomical book refers to a book x
which is about the gastronomy concept y. More gen-
erally, the variables predicated of by the noun and by
the adjective can refer either to the same or to two
distinct individual(s).
The properties licensed by the adjective and the
noun to contribute to the meaning of the [Adj
N]AP phrase. Depending on the adjective type,
the properties denoted by Adj and N will contribute
either directly or indirectly to the meaning of the
[Adj N]AP phrase. Thus in an intersective [Adj
N]AP phrase, the meaning contributed by Adj and
N are simply the properties they denote. By con-
trast, the privative fake forces the negation of the N
property to be part of the Adj N meaning whilst the
subsective gastronomical induces a relation to the
morphoderivationally related noun concept (about
gastronomy) to be included in the the Adj N mean-
ing. More generally, the properties that compose the
meaning of the Adj N phrase can be the denotation
of Adj and/or N, the negation of N, its denotation in
the past or some property derived from it.
The existence in the real world of the entity de-
noted by the NP. In all cases the [Adj N]AP
phrase denotes a set of individuals but whilst in most
cases the [Adj N]AP phrase is neutral with respect
to the existence in the real world of these individ-
uals, plain non-subsective [Adj N]AP phrases (e.g.
alleged murderer) explicitly question it (an alleged
murderer may or not exist in the real world).
3.2 The semantics of nouns
In designing a semantics for adjectives, we assume
a semantics for nouns which reflect their possible
interactions with the different types of adjectives
(1) a. noun: ?Pol?e?x.[Pol(table(e)) ? e = x]
As we shall shortly see, the additional lambda
variable e is imposed by the treatment of adjective
semantics we propose and more specifically by the
necessity to sometimes distinguish between the indi-
vidual described by the noun and the individual de-
scribed by the adjective. The variable Pol accounts
for the polarity of the noun, i.e. whether it occurs
with the negation or not.
We give here also the semantics assigned to the
pronouns someone/something which will be used in
the derivations throughout this paper:
(2) a. someone/something: ?P?x.P (x)
3.3 The semantics of the copula
Following the proposal of Mantague, we assign a
unique representation for both the uses of the cop-
ula in identity statements (e.g. John is Mary ?
john=mary) and in predicative assertions (e.g. John
is a man ? man(john)):
(3) a. be: ?K?x.K(?y(x = y))
In the case of predicative assertions in which the
predicate is an adjective (e.g. John is brave), we
adjust the type of the argument of the copula in the
following way:
(4) a. be Adj: be(Adj(?Pol?e?x.true))
3.4 The semantics of adjectives
Given such a representation for nouns, we represent
adjectives using the schema given in Figure 1.
Briefly, schema 1 captures the observations made
in section (3.1) as follows. First it introduces an ex-
istential quantification (in the platonic universe) over
not one but two variables (ea and en) ? depending on
how the formula is instantiated (and in particular on
the value of R1 and R2) these two variables may or
not denote the same object. This accounts for the
first observation according to which an [Adj N]AP
phrase may refer to either one or two individuals.
Second, the meaning of the [Adj N]AP phrase is a
function not of the Adj and N meaning but rather of
properties derived from these meanings (A? for Adj
and N , as modified by its three arguments, for N).
This accounts for the second observation.
Third, the use of the exists predicate will permit
distinguishing between existence in the universe of
discourse and existence in the real world.
187
?N?x?ea?en.[A?(ea) ? R1(x, ea) ? R2(en, ea) ? N(Pol)(en)(x)]
with A? the property licensed by the adjective, R1, R2 two arbitrary relations licensed by the adjective,
N the property denoted by the noun and Pol a polarity argument of value either ?S.S or ?S.?S
Figure 1: Semantics schema for all adjectives
We now show how this general schema receives
different instantiations depending on the adjectival
class being considered; and how each instantiation
predicts the correct inferential pattern for the four
adjectival classes.
3.4.1 Intersective adjectives
The semantic representation of an [Adj N]AP ad-
jectival phrase involving an intersective adjective is
given in Figure 2 together with the derivation of the
[Adj N]AP phrase red table. As can be seen, in this
case, the relation R1 holding between the lambda
bound variable x and the entity introduced by the
adjective is one of identity. Similarly, the entity en
introduced is equated with x and the relation R2
is ?x, y.true (i.e. there is no modifying relation
between ea and en). Hence the [Adj N]AP phrase
licenses in effect a single entity x and the resulting
semantics is the traditional ?x.[A(x) ? N(x)] with
A the semantics of the adjective and N that of the
noun. Assuming further that determiners have the
semantics:
a/the ?P?Q?x.[P (?S.S)(x) ? Q(x)]
then the semantics of Something is a red table is
(5) ?x?ea?en.[red(ea)?x = ea?table(en)?en =
x]
which correctly entails that there is an entity x
which is both red and a table i.e.,
(5) |= ?x.[red(x)] something is red
(5) |= ?x.[table(x)] something is a table
3.4.2 Subsective adjectives
As recalled above, subsective adjectives are char-
acterised by the fact that the [Adj N]AP phrase en-
tails N but not A. Relatedly, the adjective phrase in-
troduces not one but two individuals, one linked to
the adjective and the other to the noun. For instance,
the phrase the gastronomical book refers to a book
x which is about the gastronomy concept en.
Thus in such cases, we take the R2 relation hold-
ing between x, the NP quantified variable, and ea,
the entity introduced by the adjective, to be distinct
from identity, while the R1 relation is empty.
(6) ?x?ea?en.[gastronomy(ea)?about(en, ea)?
book(en) ? en = x]
This ensures that the NP refers to two entities, one
bound by the determiner and licenced by N, the other
existentially quantified and licensed by A. For in-
stance, the sentence John read every gastronomical
books is interpreted as meaning that John read all
books that are about gastronomy.
More generally, this ensures that [A N] 6|= A (and
in fact, adjectives like gastronomical cannot be used
predicatively), e.g.
(6) |= something is a book
|= ?x.[book(x)]
(6) |= something is about gastronomy
|= ?x?ea.[about(x, ea) ? gastronomy(ea)]
(6) 6|= something is a book and a gastronomy
6|= ?x[book(x) ? gastronomy(x)]
(6) 6|= something is gastronomical
6|= ?x[gastronomical(x)]
As shown in (Amoia and Gardent, 2006), subsec-
tive adjectives can be further divided into at least
four classes. Because of space restrictions, we only
show here how to represent two of these subclasses
namely denominal (e.g. gastronomical) and mea-
sure subsective adjectives (e.g. big). In both cases,
the idea is to decompose the meaning of the adjec-
tives into a finer grained lexical meaning. Depend-
ing on the lexical meaning involved, this decompo-
sition induces different instantiation patterns for the
188
Intersective Adjectives
?N?x?ea?en.[A(ea) ? x = ea ? N(?S.S)(en)(x)]
Red table
?N?x?ea?en.[red(ea) ? x = ea ? N(?S.S)(en)(x)](?Pol?e?x.[Pol(table(e)) ? e = x])
? ?x?ea?en.[red(ea) ? x = ea ? table(en) ? en = x])
? ?x.[red(x) ? table(x)])
Figure 2: Semantics of Intersective Adjectives
Subsective Adjectives
?N?x?ea?en.[A?(ea) ? R2(en, ea) ? N(?S.S)(en)(x)]
with A? an arbitrary complex relation derived from the lexical meaning of the adjective and
R2 a relation other than identity
Gastronomical book
?N?x?ea?en.[gastronomy(ea) ? about(en, ea) ? N(?S.S)(en)(x)](?Pol?e?x.[Pol(book (e)) ? e = x])
? ?x?ea?en.[gastronomy(ea) ? about(en, ea) ? book(en) ? en = x])
Figure 3: Semantics of Subsective Adjectives
R relation mentioned in the general schema for ad-
jective semantic representation.
Thus, the meaning of the adjectival phrase
containing an adjective of measure, e.g. big mouse
will be represented as:
?N?x?ea?en.[size(ea) ? highFor(ea, C)
?has(en, ea) ? N(?S.S)(en)(x)]
(?Pol?e?x.[mouse(e) ? e = x])
? ?x?ea?en.[size(ea) ? highFor(ea, C)
?has(en, ea) ? mouse(en) ? en = x])
where C is a contextually given parameter which de-
termine the scale size is measured against. In this
case, C would be, e.g. ?mouse? so that the formula
above can be glossed as x is a mouse with a size ea
which is high for a mouse. In particular, Daisy is
a big mouse entails that Daisy is a mouse and that
Daisy is big for a mouse, but not that Daisy is big.
3.4.3 Privative adjectives
As seen above, privative adjectives entail that the
entity described by the NP is not N, e.g. a fake gun is
not a gun. For such adjectives, it is the entity intro-
duced by the adjective that is being quantified over,
hence ea is identified with x (cf. Figure 4). Fur-
ther, the N property is either denied or subject to a
modality (former, potential). As shown in Figure 4,
this is accounted for by providing the appropriate re-
lation R (e.g. R2 being the relation time introduced
by former or R1 being the identity relation x = ea
introduced by fake).
This representation presupposes that each sen-
tence in which such modality adjectives do not occur
has a default value for time and/or modality. Thus,
for instance that
(7) John is a former president. 6|= John is the pres-
ident.
(8) John is a possible president. 6|= John is the pres-
ident.
can only be accounted for if the base forms are
assigned the following default representations:
(7) ?ea?x [president(x) ? time(x, ea)
?present(ea)]
(8) ?ea?x [president(x) ? mod(x, ea)
?possible(ea)]
3.4.4 Plain non-subsective adjectives
Finally, plain non-subsective adjectives fail to
make any prediction about the existence of an in-
189
Privative Adjectives (e.g., fake,potential,former,future)
(e.g. fake, fictitious)
?N?x?ea?en.[A(ea) ? x = ea ? N(?S.?S)(en)(x)] OR
?N?x?ea?en.[A?(ea) ? mod/time(ea, en) ? N(?S.S)(en)(x)]
with R2 being the relation mod/time specifying the modality or the time indicated by the adjective
Fake gun
?N?x?ea?en.[fake(ea) ? x = ea ? N(?S.?S)(en)(x)](?Pol?e?x.[Pol(gun(e)) ? e = x])
? ?x?ea?en.[fake(ea) ? x = ea ? ?gun(en) ? en = x])
Former president
?N?x?ea?en.[former (ea) ? time(en, ea) ? N(?S.S)(en)(x)]
(?Pol?e?x.[Pol(president(e)) ? e = x])
? ?x?ea?en[former(ea) ? time(x, ea) ? president(en) ? x = en]
Figure 4: Semantics of Privative Adjectives
dividual having the N property. Thus for instance,
if John is an alleged murderer, there might or might
not exist a murderer.
To account for this fact, we follow Hobbs? ap-
proach in distinguishing between existence in the
universe of discourse and existence in the real world.
Thus, the logical existential connective ? is used to
denote existence in the discourse world while the
special predicate Exists is used to denote existence
in the real world. We assume further a theory that
permits determining when an individual exists in the
universe of discourse and when it exists in the real
world.
Given these caveats, the semantics of plain non-
subsective adjectives is as indicated in Figure 5 and
simply specifies that the alleged murderer is an in-
dividual x which exists in the universe of discourse
(but not necessarily in the real world) and which is
alleged to be a murderer. Moreover, as stated in
(Hobbs, 1985), we assume that the alleged predi-
cate is existentially opaque in its second argument.
That is, an alleged predication does not imply the
existence in the real world of its second argument.
4 Implementation
The semantics of adjectives presented in this paper
was tested using (Blackburn and Bos, 2005) compu-
tational semantics framework.
First, based on the classification of 300 English
adjectives presented in (Amoia and Gardent, 2006),
which identifies 17 different adjectival subclasses
for the four main classes proposed by (Kamp, 1975;
Kamp and Partee, 1995), we have built a test suite of
about 150 examples in the following way. We have
chosen for each class a representant adjective and
written for it the set of sentence pairs (H/T) illus-
trating the inference patterns displayed by the class
the adjective belongs to. In particular, we have built
examples which test:
1. whether the adjective partecipates in both pred-
icative and attributive constructions, so that the
resulting sentences (H and T) are paraphrastic,
2. whether the two sentences contain adjectives
which are synonyms,
3. what kind of antonymic relation links the given
adjective with its antonym,
4. which of the three inference patterns described
in (Kamp and Partee, 1995) holds for the given
adjective,
5. hyperonymy,
6. derivational morphology.
For instance, the test suite contains for an adjec-
tive such as fake, belonging to a subclass of the pri-
vative adjectives, the H/T pairs in (9).
(9) a. H:This is a fake gun / T:This gun is fake
190
Plain non subsective Adjectives (e.g., alleged)
?N?x?ea?en.[A?(ea, en) ? x = ea ? N(?S.S)(en)(en)]
with R1 being the identity relation between x and ea and R2 being the relation
introduced by the adjective A?(ea, en)
Alleged murderer
?N?x?ea?en.[alleged(ea, en) ? x = ea ? N(?S.S)(en)(en)](?Pol?e?x.[Pol(murderer (e)) ? e = x])
? ?x?ea?en.[alleged(ea, en) ? x = ea ? murderer(en) ? en = en])
Figure 5: Semantics of plain non-subsective Adjectives
b. H:This is a fake gun / T:This is a false gun
c. H:This is a fake gun / T:This gun is not gen-
uine
d. H:This is not a fake gun |= This gun is real
e. H:This is a fake gun / T:This is a gun
f. H:This is a fake gun / T:This is not a gun
g. H:This is a fake gun / T:This is fake
h. H:This is a fake gun / T:This is a fake
weapon
i. H:This is a fake gun / T:This gun is a coun-
terfeit
Second, a grammar fragment was implemented
which integrates the semantics of nouns and adjec-
tives presented here. This grammar fragment was
then used together with the appropriate lexicon to
automatically associate with each sentence of the
test suite a representation of its meaning.
Third, lexical Knowledge pertaining to each class
of adjectives is captured through a set of axioms de-
scribing the specific lexical relationships adjectives
are involved in.
Synonymy is captured introducing equality axioms
which describe the equivalence of the two proper-
ties expressed by the two adjectives Adj1 and Adj2
asserting:
?e[Adj1(e) ? Adj2(e)]
Hyponymy (for example big/giant vs.
small/minuscule) is captured by introducing
the axioms such as:
?e[Adj1(e) ? Adj2(e)]
Antonymy is captured by introducing different ax-
ioms depending on the type of opposition relation in
which the adjectives are involved, i.e. binary, con-
trary or multiple opposition. The axiom below for
example introduces a binary antonymic relation:
?e[Adj1(e) ? ? Adj2(e)]
Fourth, entailment (H|=T) was checked for each
sentence pair using the first order theorem provers
available in the system and the results compared
with the expected result. A first evaluation shows
that the methodology proposed yields the expected
results: we could correctly predict all the inferen-
tial patterns presented above from 1 to 5 (136 pairs,
89%). The results for other patterns, describing mor-
phoderivational relations of adjectives, depend on
the amount of information implemented in the gram-
mar which for the moment is very limited.
5 Perspectives and Comparison with
related works
The approach presented here lays the basis for a
computational treatment of adjectival inference in
that it provides a fine grained characterisation of the
various types of inferential patterns licenced by ad-
jectives.
In future work, we believe three main points are
worth investigating.
First, previous work (Amoia and Gardent, 2006)
has shown that the classification presented here can
be further detailed and even finer-grained classes
identified thereby permitting the creation of syn-
tactically and semantically homogeneous adjectival
191
classes. The advantages of identifying such ho-
mogeneous classes has been well demonstrated for
verbs. It permits structuring the lexicon and facil-
itates development and maintenance. Based on the
idea that syntax (and in particular, so-called syntac-
tic alternations) helps define such classes, we are
currently investigating in how far adjectival syntax
helps further refine adjectival classes.
Second, the proposed classification need to be ap-
plied and combined with ontological and lexical se-
mantic information. That is, each adjective should
be classified wrt the 4 types of model theoretic se-
mantics described here and related to such a lexical
semantics ontology as e.g., WordNet, the MikroKos-
mos ontology of the SIMPLE lexicon.
Thus (Raskin and Nirenburg, 1995) describe the
methodology used to encode adjectival entries in the
lexicon of the MikroKosmos semantic analyser. The
MikroKosmos lexicon contains 6,000 entries for En-
glish and 1,500 entries for Spanish adjectives. Ad-
jectives are organised in an ontology which distin-
guishes between the following three main adjectival
classes: (i) Scalar Adjectives, which are rep-
resented as property-value pairs, (ii) Denominal
Adjectives, (e.g. atomic, civil, gastronom-
ical) represented as nouns and (iii) Deverbal
Adjectives, (e.g. eager, abusive, readable) is re-
lated to the meaning of the verb they are derived to.
The classification of adjectives proposed in SIM-
PLE (SIMPLE, 2000) is also ontology-based. A
lexical entry for an adjective is characterised by a
set of semantic and syntactic information. Seman-
tic information describes: (i) the hierarchy of onto-
logical properties expressed by the particular adjec-
tive, for example the adjective expresses the prop-
erty of COLOUR and this is a physical property; (ii)
whether the adjective is intersective or subsective;
(iii) whether the adjective has a persistent duration
(i.e. is stable) or not. Moreover, syntactic informa-
tion describes adjectival features such as (i) predica-
tive/attributive usage, and (ii) gradability.
SIMPLE has actually added semantic information
to approximately 3,500 lexical entries (about 10,000
senses) for each of the 12 European languages con-
sidered in the project.
It would be interesting to see whether any of these
resources can be used to create an adjective lexicon
rich enough to support both syntactic processing and
semantic inference.
Finally, a third point of interest concerns the in-
tegration of the compositional semantics proposed
here for adjectives into a robust semantic processing
system. We plan to integrate this semantics into the
CCG2Sem semantic parsing system (Bos, 2005) and
to investigate in how far, this would help deal with
entailment recognition.
References
Marilisa Amoia and Claire Gardent. 2006. Adjective
based inference. In Proceedings of KRAQ?06 (Knowl-
edge and Reasoning for Answering Questions), Trento,
Italy.
Patrick Blackburn and Johan Bos. 2005. Representation
and Inference for Natiral Language. A first Course in
Computational Semantics. CSLI Studies in Computa-
tional Linguistics.
Johan Bos. 2005. Towards wide-coverage semantic in-
terpretation. In In Proceedings of the Sixth Interna-
tional Workshop on Computational Semantics IWCS-
6, pages 42?53.
G. Chierchia and S. Mc Connell-Ginet. 1990. Mean-
ing and Grammar: An Introduction to Semantics. The
MIT Press, Cambridge, MA.
Jerry R. Hobbs. 1985. Ontological promiscuity. In
Proceedings of the 23rd Annual Meeting of the As-
sociation for Computational Linguistics, pages 61?69,
Chicago, Illinois, July.
Hans Kamp and Barbara Partee. 1995. Prototype theory
and compositionality. Cognition, (57):129?191.
Hans Kamp. 1975. Two theories about adjectives. In
Edward L. Keenan (ed.), Formal Semantics of Natu-
ral Language, pages 123?155. Cambridge University
Press.
V. Raskin and S. Nirenburg. 1995. Lexical Semantics
of Adjectives, a micro-theory of adjectival meaning.
MCCS Report.
Specification Group SIMPLE. 2000. Specification sim-
ple work package 2. Linguistic specifications deliver-
able d2.1.
192
First Joint Conference on Lexical and Computational Semantics (*SEM), pages 482?486,
Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational Linguistics
SB: mmSystem - Using Decompositional Semantics for Lexical
Simplification
Marilisa Amoia
Department of Applied Linguistics
University of Saarland
m.amoia@mx.uni-saarland.de
Massimo Romanelli
DFKI GmBH
Saarbrcken, Germany
romanell@dfki.de
Abstract
In this paper, we describe the system we sub-
mitted to the SemEval-2012 Lexical Simplifi-
cation Task. Our system (mmSystem) com-
bines word frequency with decompositional
semantics criteria based on syntactic structure
in order to rank candidate substitutes of lexical
forms of arbitrary syntactic complexity (one-
word, multi-word, etc.) in descending order
of (cognitive) simplicity. We believe that the
proposed approach might help to shed light on
the interplay between linguistic features and
lexical complexity in general.
1 Introduction
Lexical simplification is a subtask of the more gen-
eral text simplification task which attempts at re-
ducing the cognitive complexity of a text so that
it can be (better) understood by a larger audience.
Text simplification has a wide range of applications
which includes applications for the elderly, learners
of a second language, children or people with cog-
nitive deficiencies, etc.
Works on text simplification mostly focus on re-
ducing the syntactic complexity of the text (Sid-
dharthan, 2011; Siddharthan, 2006) and only little
work has addressed the issue of lexical simplifica-
tion (Devlin, 1999; Carroll et al, 1999).
The Lexical Simplification Task (Specia et al,
2012) proposed within the SemEval-2012 is the first
attempt to explore the nature of the lexical simpli-
fication more systematically. This task requires par-
ticipating systems, given a context and a target word,
to automatically generate a ranking of substitutes,
i.e. lexical forms conveying similar meanings to
the target word, such that cognitively simpler lexi-
cal forms are ranked higher than more difficult ones.
In this paper, we describe the system we sub-
mitted to the SemEval-2012 Lexical Simplification
Task. In order to rank the candidate substitutes of a
lexical form in descending order of simplicity, our
system (mmSystem) combines word frequency with
decompositional semantics criteria based on syntac-
tic structure. The mmSystem achieved an average
ranking if compared with the other participating sys-
tems and the baselines. We believe that the approach
proposed in this paper might help to shed light on
the interplay between linguistic features and cogni-
tive complexity in general.
2 The Lexical Simplification Task
The SemEval-2012 Lexical Simplification Task re-
quires participating systems to automatically gen-
erate a ranking of lexical forms conveying similar
meanings on cognitive simplicity criteria and can be
defined as follows. Given a short text C called the
context and which generally corresponds to a sen-
tence, a target word T and a list LS of candidate
substitutes for T , i.e. a list of quasi-synonyms of the
target word, the task for a system consists in pro-
viding a ranking on LS such that the original list of
substitutes is sorted over simplicity, from the cogni-
tively simplest to the cognitively most difficult lexi-
cal form.
As the examples from (1) to (3) show, the Lexical
Simplification Task includes substitutes of different
syntactic complexity which might vary from simple
one-word substitutes as in (1) (the lexical forms that
482
can function as substitutes include content words,
i.e. nouns (n), verbs (v), adjectives (a) and adverbs
(r)) to collocations, negated forms as in (2) or even
definition-like paraphrases as for instance wind and
knock the breath out of in example (3).
(1)
C: He suggested building an experimental hy-
pertext ?web? for the worldwide.a community
of physicists who used CERN and its publica-
tions.
T: worldwide.a
LS: worldwide, global, international
(2)
C: Go to hell! she remembers Paul yelling at
her shortly.r after their wedding.
T: shortly.r
LS: soon, a little, just, almost immediately,
shortly, not long
(3)
C: Now however she was falling through that
skylight, the strong dark figure that had ap-
peared out of nowhere falling through with her,
his arms tightly entwined about her, his shoul-
der having winded.v her.
T: winded.v
LS: knock her breathless, knock the wind out
of, choke, wind, knock the breath out of, knock
the air out of
The organizers of the Lexical Simplification Task
provide a corpus of 300 trial and 1710 test sentences
defining the context of the target word and the as-
sociated list of candidate substitutes. To produce a
gold standard, 5 human annotators manually ranked
the list of substitutes associated to each context. Fi-
nally, a scoring algorithm is provided for comput-
ing agreement between the output of the system and
the manually ranked gold standard. The scoring al-
gorithm is based on the Kappa measure for inter-
annotator agreement.
3 The mmSystem
Our aim by participating in the SemEval-2012 Lexi-
cal Simplification Task (Task 1) was to investigate
the nature of lexical simplicity/complexity and to
identify the linguistic features that are responsible
for it. The system we have developed is a first step
in this direction. The idea behind our framework
is the following. We build on previous work (De-
vlin, 1999; Carroll et al, 1999) that approximate
simplicity with word frequency, such that the cog-
nitively simpler lexical form is the one that is more
frequent in the language. While this definition might
easily apply to one-word substitutes or collocations,
it poses some problems in the case of multi-word-
expressions or of syntactically more complex lexi-
cal forms (e.g. definition like paraphrases) like those
proposed in the substitute lists in the SemEval-2012
Task 1.
Our approach builds on the baseline definition of
simplicity based on word frequency and integrates
it with (de)compositional semantics considerations.
Therefore, in order to operationalize the notion of
simplicity in our system we adopt different strategies
depending on the syntactic complexity of the lexical
form that forms the substitute.
? In the case of one-word substitutes or common
collocations we use the frequency associated by
WordNet (Fellbaum, 1998) to the lexical form
as a metric to rank the substitutes, i.e. the
substitute with the highest frequency is ranked
higher. For instance, the lexical item intelligent
is ranked lower than clever as it has a lower
frequency in the language (as defined in Word-
Net).
? In the case of multi-words or syntactic complex
substitutes, we apply so-called relevance rules.
Those are based on (de)compositional semantic
criteria and attempt to identify a unique content
word in the substitute that better approximates
the whole lexical form. Thus, we assign to the
whole lexical form the frequency associated to
this most relevant content word and use it for
ranking the whole substitute. For instance, rel-
evance rules assign to multi-word substitutes
such as most able or not able the same fre-
quency, and namely that associated with the
content word able.
483
3.1 Implementation
In this section we describe in more details the im-
plementation of the mmSystem. The system design
can be summarized as follows.
Step 1: POS-Tagging In the first step, context and
the associated substitutes are parsed1 so to ob-
tain a flat representation of their syntax. Ba-
sically at this level, we collect Part-Of-Speech
information for all content words in the context
as well as in the substitute list.
Step 2: Relevance Rules In the second step, de-
pending on the syntactic representation of the
substitutes, the system selects a relevance rule
that identifies the one-word lexical form that
will be used for representing the meaning of the
whole substitute.
Step 3: Word Sense Tagging The system ap-
plies word sense tagging and assigns a Word-
Net sense to the target words and their can-
didate substitutes. In this step, we rely
on the SenseRelate::TargetWord package (Pat-
wardhan et al, 2005) and use the Lesk algo-
rithm (Lesk, 1986) for word sense disambigua-
tion.
Step 4: Substitute Ranking Following (Carroll et
al., 1999) that pointed out that rare words gen-
erally have only one sense, in order to associate
a frequency index to each candidate substitute
(wi), we use the number of senses associated
by WordNet to a lexical item of a given part
of speech, as an approximation of its frequency
(fi). Further, we extract from WordNet the fre-
quency of the word sense (fwnsi) associated to
the lexical item wi at step 3. Words not found in
WordNet it assigned a null frequency (fi = 0,
fwnsi = 0). Finally, we rank the substitute in
the following way:
? if f1 6= f2
w1 < w2, if f1 > f2 and
w2 < w1 otherwise,
? else if f1 = f2
w1 < w2, if fwns1 > fwns2 and
w2 < w1 otherwise.
Input:
Sentence 993: ?It is light.a and easy to use.?
Substitutes: portable;unheavy;not heavy;light
Step 1: POS-Tagging
portable#A; unheavy#A; not#Neg heavy#A; light#A
Step 2: Relevance Rules
portable#A; unheavy#A; heavy#A#; light#A
Step 3: WSD
portable#A#wns:2; unheavy#A#wns:?; heavy#A#wns:2;
light#A#wns:25
Step 4: Ranking
portable#f:2; unheavy#f:0; heavy#f:27; light#f:25
not heavy < light < portable < unheavy
Gold Ranking:
light < not heavy < portable < unheavy
Table 1: Example of mmSystem processing steps.
Table 1 shows an example of data processing.
3.2 Relevance Rules
Relying on previous work on compositional seman-
tics of multi-word-expression (Reddy et al, 2011;
Venkatapathy and Joshi, 2005; Baldwin et al, 2003)
we defined a set of hand-written rules to assign the
relevant meaning to a complex substitute. Relevance
rules are used to decompose the meaning of a com-
plex structure and identify the most relevant word
conveying the semantics of the whole, so that the
frequency associated to the whole lexical form is ap-
proximated by the frequency of this most relevant
form:
? a one-word lexical item is mapped to itself, e.g.
run.v ? run.v
? a multi-word lexical form including only one
content word is mapped to this content word,
e.g. not.Neg nice.a? nice.a or
be.Cop able.a? able.a
? in the case of a multi-word lexical item includ-
ing more than one content word, we take into
account the syntactic structure of the lexical
item and apply heuristics to decide which con-
tent word is more relevant for the meaning of
the whole. The heuristics we used are based
on the empirical analysis of the trial data set
provided by the Task 1 organizers that contains
1We used the Stanford Parser (Klein and Manning, 2003).
484
about 300 contexts. As an example consider a
lexical item including a verb construction with
structure V1 + to + V2 that is mapped by our
rules to the second verb form V2, e.g. try.V1 to
escape.V2 ? escape.V2.
Table 2 shows some examples of relevance rules de-
fined in the mmSystem.
Syntax Example R Form
V + Prep engage for V
Cop + Adj be able Adj
Cop + V be worried V
Adv + V anxiously anticipate Adv
Adj+N adnormal growth Adj
N1 + N2 death penalty N1
N1 + PrepOf + N2 person of authority N2
V+N take notice N
V1+to+V2 try to escape V2
Table 2: Example of relevance rules.
These relevance rules allow for a preliminary in-
vestigation of the nature of lexical complexity. For
instance, we found that in many cases, it is the mod-
ifying element of a complex expression that is re-
sponsible for a shift in lexical complexity:
(4) a. lie<say falsely<say untruthfully
b. sample< typical sample < representative
sample
4 Results
The Task 1 overall result can be found in (Specia
et al, 2012). The mmSystem achieved an average
ranking (score=0.289) if compared with the other
participating systems and the baselines that corre-
sponds to an absolute inter-annotator agreement be-
tween system output and golden-standard around
66%. Interestingly none of the systems achieved
an absolute agreement higher than 75% in this task.
This confirms that lexical simplification still remains
a difficult task and that the nature of the phenomena
underlying it should be better explored.
Table 3 shows the performance of our system per
syntactic category. The values are a bit higher than
in the official results of Task 1 as the system version
used for submission was buggy, however the rank-
ing of our system with respect to the other partici-
pating systems remains the same. Interestingly, the
best score were achieved for adverbs (0.352) and ad-
jectives (0.342). This can be explained with the fact
that the decompositional semantics of these category
is better accounted for by our rules.
The relative low performance achieved by the
mmSystem can be explained by the fact that our
rules only select one content word and use its fre-
quency for ranking. This metric alone is clearly not
enough to explain all cases of lexical simplification.
As an example of the complexity of this issue, con-
sider the interplay of negation and compositional se-
mantics: The negation of a very frequent verb form
might not be so simple to understand as its antonym,
e.g. don?t, not remember/forget vs. omit to, fail to
remember/forget. We believe, that a more system-
atic analysis of the lexical semantics involved in lex-
ical simplicity might improve the performance of the
system.
Noun Verb Adj Adv TOT
cAgr: 0.5 0.5 0.5 0.5 0.5
aAgr: 0.658 0.658 0.671 0.676 0.665
Score: 0.316 0.315 0.342 0.352 0.329
Table 3: mmSystem scores per syntactic category. In the
table cAgr represents the agreement by chance, aAgr is
the absolute inter-annotator agreement between system
output and gold ranking and score is the normalized sys-
tem score. These values corresponds to P(A) and P(E)
observed in the data.
5 Conclusion
In this paper we presented the mmSystem for lexical
simplification we submitted to the SemEval-2012
Task 1. The system combines simplification strate-
gies based on word frequency with decompositional
semantic criteria. The mmSystem achieved an aver-
age performance. The aim of our work was in fact
a preliminary investigation of the interplay between
(de)compositional semantics and lexical or cognitive
simplicity in general. Doubtlessly much remain to
be done in order to provide a more efficient formal-
ization of such effects. In future work, we want to
perform a wider corpus analysis and study the im-
pact of other linguistic features such as lexical se-
mantics on lexical simplicity.
485
References
Timothy Baldwin, Colin Bannard, Takaaki Tanaka, and
Dominic Widdows. 2003. An empirical model of
multiword expression decomposability. In Proceed-
ings of the ACL 2003 workshop on Multiword expres-
sions: analysis, acquisition and treatment - Volume 18,
MWE ?03, pages 89?96, Stroudsburg, PA, USA. Asso-
ciation for Computational Linguistics.
John Carroll, Guido Minnen, Darren Pearce, Yvonne
Canning, Siobhan Devlin, and John Tait. 1999. Sim-
plifying text for language-impaired readers. In In Pro-
ceedings of the 9th Conference of the European Chap-
ter of the Association for Computational Linguistics
(EACL, pages 269?270.
S. Devlin. 1999. Simplifying natural language for apha-
sic readers. Ph.D. thesis, University of Sunderland,
UK.
Christiane Fellbaum. 1998. WordNet: An Electronic
Lexical Database. Cambridge, MA: MIT Press.
Dan Klein and Christopher D. Manning. 2003. Accu-
rate unlexicalized parsing. In Proceedings of the 41st
Meeting of the Association for Computational Linguis-
tics, pages 423?430.
M. Lesk. 1986. Automatic sense disambiguation using
machine readable dictionaries: How to tell a pine cone
from a ice cream cone. In Proceedings of SIGDOV
?86.
Siddharth Patwardhan, Satanjeev Banerjee, and Ted Ped-
ersen. 2005. Senserelate::targetword - a generalized
framework for word sense disambiguation. In Pro-
ceedings of the Demonstration and Interactive Poster
Session of the 43rd Annual Meeting of the Association
for Computational Linguistics, pages 73?76, Ann Ar-
bor, MI.
Siva Reddy, Diana McCarthy, and Suresh Manandhar.
2011. An empirical study on compositionality in com-
pound nouns. In Proceedings of the International
Joint Conference on Natural Language Processing
2011 (IJCNLP-2011), Thailand.
Advaith Siddharthan. 2006. Syntactic simplification ant
text cohesion. Research on Language and Computa-
tion, 4(1):77?109.
Advaith Siddharthan. 2011. Text simplification using
typed dependencies: A comparision of the robustness
of different generation strategies. In Proceedings of
the 13th European Workshop on NLG.
Lucia Specia, Sujay K. Jauhar, and Rada Mihalcea.
2012. Semeval-2012 task 1: English lexical simplifi-
cation. In Proceedings of the 6th International Work-
shop on Semantic Evaluation (SemEval 2012), Mon-
treal, Canada.
Sriram Venkatapathy and Aravind K. Joshi. 2005. Mea-
suring the relative compositionality of verb-noun (v-n)
collocations by integrating features. In Proceedings of
the conference on Human Language Technology and
Empirical Methods in Natural Language Processing,
HLT ?05, pages 899?906, Stroudsburg, PA, USA. As-
sociation for Computational Linguistics.
486
Proceedings of the 7th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities, pages 84?89,
Sofia, Bulgaria, August 8 2013. c?2013 Association for Computational Linguistics
Using Comparable Collections of Historical Texts for Building a
Diachronic Dictionary for Spelling Normalization
Marilisa Amoia
Saarland University
m.amoial@mx.uni-saarland.de
Jose Manuel Martinez
Saarland University
j.martinez@mx.uni-saarland.de
Abstract
In this paper, we argue that compara-
ble collections of historical written re-
sources can help overcoming typical chal-
lenges posed by heritage texts enhanc-
ing spelling normalization, POS-tagging
and subsequent diachronic linguistic anal-
yses. Thus, we present a comparable cor-
pus of historical German recipes and show
how such a comparable text collection to-
gether with the application of innovative
MT inspired strategies allow us (i) to ad-
dress the word form normalization prob-
lem and (ii) to automatically generate a
diachronic dictionary of spelling variants.
Such a diachronic dictionary can be used
both for spelling normalization and for ex-
tracting new ?translation? (word forma-
tion/change) rules for diachronic spelling
variants. Moreover, our approach can be
applied virtually to any diachronic collec-
tion of texts regardless of the time span
they represent. A first evaluation shows
that our approach compares well with
state-of-art approaches.
1 Introduction
The study of heritage documents has been one
of the regular sources of knowledge in the Hu-
manities, specially in history-related disciplines.
The last years have witnessed an increased interest
in approaches combining NLP and corpus-based
techniques in the Humanities (Piotrowski, 2012)
as they can provide new insights and/or a more
consistent and reliable account of findings.
Until recently, research efforts have been fo-
cused on building diachronic corpora (e.g. Old
Bailey Online project (Hitchcock et al, 2012)
and its follow-up, the Old Bailey Corpus (Huber,
2007), the Bonn Corpus of Early New High Ger-
man (Diel et al, 2002) or the GerManC (Scheible
et al, 2011b) for German and many others). Such
resources are generally annotated with shallow
metadata (e.g. year of publication, author, ge-
ographical location) for allowing fast retrieval.
However, the annotation of richer linguistic and
semantic information still poses a series of chal-
lenges that have to be overcome, such as (i)
the noise introduced by deviant linguistic data
(spelling/orthography variation, lack of sentence
boundaries, etc.) typical of this kind of material,
due to the lack of standardized writing conventions
in terms of words and punctuation and hence (ii)
the higher error rates obtained when applying stan-
dard NLP methods.
Further, standardization of spelling variation in
historical texts can be broken down at least into
two subproblems:
1. the old word forms often differ from the mod-
ern orthography of the same items. Consider,
for instance, the diachronic variants of the
third person singular of present tense of the
verb werden in German (which means ?be-
come? as full verb, or is used as auxiliary
verb to build the future): wirt, wirdt, wirdet
vs wird; (Piotrowski, 2012) and
2. the denomination of certain objects may re-
sult completely different from that used in
the modern language due to historical reasons
(e.g. adoption of foreign language terms,
semantic shift). Consider, as an example,
the German historical/modern variants of the
word lemon (e.g. Limonie/Zitrone) or of the
word woman (e.g. Weib/Frau).
Previous approaches to spelling normalization
of historical texts have focused on the first sub-
problem. Two main strategies that have been ap-
plied:
? a rule based strategy, in which the transla-
tion of historical variants into modern forms
84
is performed on the ground of manually writ-
ten or semi-automatically gathered rules (cf.
(Pilz et al, 2008), (Bollmann et al, 2011));
? a string similarity strategy, in which a semi-
automatic attempt is made to link histori-
cal variants with modern dictionary entries
following string similarity (cf. (Giusti et
al., 2007), (Kunstmann and Stein, 2007),
(Dipper, 2010), (Hendrickx and Marquilhas,
2011), (Gotscharek et al, 2011)) or pho-
netic conflation strategies (cf. (Koolen et al,
2006), (Jurish, 2008) ).
These approaches have the disadvantage of end-
ing up relying on a time-specific dictionary of vari-
ants, e.g. they can cope with variants realized in
texts stemming from the same period of time for
which they have been created but may result inap-
propriate for texts belonging to other time spans.
Moreover, to our knowledge, there is currently
no approach to spelling normalization that can ad-
dress successfully the second subproblem stated
above ? the recognition of paraphrastic variations
realized as completely different strings or consist-
ing of semantic shifts.
As it has been often noted, the problem of stan-
dardizing diachronic variants can be understood as
a translation operation, where instead of translat-
ing between two different languages, translation
takes place between two diachronic varieties of the
same language. Inspired by experiments done for
interlinguistic translation (Rapp et al, 2012), the
idea is to use diachronic comparable corpora to
automatically produce a dictionary of diachronic
spelling variants even including semantic shifts,
regardless of the historical variants at stake.
In short, we first build a comparable histori-
cal corpus made up of recipe repertoires published
in the German language during the Early Modern
Age along with a contemporary comparable cor-
pus. Second, we address the problem of recog-
nizing and translating different variants by relay-
ing on MT techniques based on string similarity as
well as on semantic similarity measures. Finally,
we automatically extract a diachronic dictionary
of spelling and semantic variants which also pro-
vides a canonical form.
This paper is organized as follows. Section
2 presents the comparable corpus of German
recipes. Section 3 describes the approach used for
generating the dictionary of diachronic spelling
variants. Section 4 shows the results of a prelimi-
nary evaluation. Finally, in Section 5 we conclude
by discussing some final remarks.
2 The Historical Comparable Corpus of
German Recipes
The text collection encoded in our corpus spans
two hundred years and includes samples from 14
cook books written in German between 1569 and
1729. The core of the recipe corpus was compiled
as part of a PhD work in the field of Translation
Studies (cf. (Wurm, 2007)). This corpus has been
aligned resulting into two comparable corpora:
? a historical comparable dataset algned at
recipe level providing multiple versions of
the same dish across the time span of the core
corpus;
? a contemporary comparable dataset provid-
ing contemporary German versions for each
recipe.
In order to produce the historical comparable com-
ponent we proceeded in the following way:
? first, we classified the core recipes by main
ingredient and cooking method (e.g. chicken,
roast). These two parameters form the crite-
ria to consider the recipes aligned, then;
? we collected as many as possible diachronic
versions/variants of the same recipe by also
searching online resources providing collec-
tions of historical texts.
The historical component of the corpus (core and
comparable) contains a total of 430 recipes and
about 45.000 tokens. This dataset constitutes the
object of study for subsequent research, provid-
ing a representative sample of German during the
Early Modern Age in this specific domain. More-
over, language and genre evolution can be traced
thanks to its comparable nature.
Regarding the compilation of the contemporary
German comparable corpus, we collected a set of
recipes belonging to the same register but repre-
senting contemporary German language. These
recipes were collected from Internet sources and
filtered by geographical criteria (only the ones cat-
egorized as belonging to the cuisine of German
speaking regions were selected). The corpus con-
tains around 1500 recipes and over 500.000 to-
kens, which have been also aligned with their
85
Figure 1: A text excerpt from Wecker 1679.
comparable historical counterparts according to
the same parameters explained above. This sub-
set alows not only to compare historical recipes
with their modern versions but also to use them as
a reference corpus to extract standard word forms.
2.1 Digitization Strategy
The corpus has been manually transcribed. The
transcription can be regarded as a diplomatic one,
since it tries to preserve as many features of the
original as possible. Some standardization has
been performed at punctuation and hyphenation
level but no spellchecking or word separation has
been carried out. The corpus is encoded in UTF-8
and we have used a TEI-compatible XML format
to store both text and metadata.
2.2 Annotations
The corpus currently includes some shallow
semantic annotation describing text structure
(e.g. recipe, title, and body) and providing a
basic classification of recipes based on the main
ingredient and recipe type. The figure 2 below
shows an example of semantic annotation.
3 Building a Diachronic Dictionary of
Spelling Variants
Our spelling normalization strategy aims at solv-
ing both subproblems discussed in the Introduc-
tion. In order to extract the mapping between
diachronic variants by also capturing paraphrases
and semantic shifts, we apply two different strate-
gies one based on string similarity and the other
based on semantic similarity measures.
Our workflow can be summarized as follows:
1. In a first step, we relay on clustering tech-
niques based on string similarity measures
<recipe id=?26? author=?Deckhardt? year=?1611?
language=?german? ingredient=?Erdbeere?
cookingMethod=?Mus?>
<title> Ein Erdbeermuhs zumachen. < /title>
<body> <seg type=?newline?>
Nimb Erdbeer
</seg>
<seg type=?newline?/ >
treibe es durch mit Weine
</seg>
<seg type=?newline?>
thue Zucker darein
</seg>
<seg type=?newline?>
darnach man es gerne su?sse haben wil
</seg>
...
< /body>
< /recipe>
Figure 2: Comparable diachronic corpus: an ex-
ample of annotation.
to identify a set of diachronic variations of
the same word form. In this phase, cluster-
ing corresponds to the extraction of ?similar
strings?.
2. In the second step, we address the problem of
finding semantic variants, i.e. those variants
that are not realized as similar strings by ap-
plying paraphrase recognition techniques to
identify different denominations of the same
object.
3. Finally, we integrate the results of both
phases and generate a dictionary of di-
achronic variants, that is used to extract the
normalized spelling for each word in the cor-
pus. We assume that the normalized word
form corresponds to the most modern variant
found in the dictionary.
3.1 String Similarity
In the first step, we extract comparable recipes
from different decades and from the corpus of
modern recipes. Then we apply clustering tech-
niques to find spelling variations. The fact that
we use comparable texts for clustering, should re-
duces the errors as all tokens come from similar
terminological fields.
We apply agglomerative hierarchical clustering
as implemented in the R statistical programming
environment with the average agglomeration
method. As a string similarity measure, we use
the standard Levenshtein edit distance as imple-
mented in the R package Biostrings. In order to
86
build the dictionary, we select clusters that have
a string similarity greater than 65%. Figure 3
shows an example of diachronic dictionary entries
generated with this approach.
Hu?hner: Hu?ner 1574, Hu?nern 1574,
hu?ner 1574, Hu?nner 1611
und: vnd 1569, vnnd 1569,
vnd 1679, und 1698
magsts: magst 1574, magstu 1602,
magst 1679
lasst: lassen 1679, lassets 1682,
la?ssets 1715
Muscatenblu?h: Muscatblu? 1569, Mus-
catenblu?h 1715
Figure 3: Diachronic Dictionary.
For each list of diachronic variants gathered at
this point, we extracted the most recent variant and
used it as normalized form.
3.2 Semantic similarity
In order to cluster paraphrastic variants and se-
mantic shifts, we apply a slightly modified ver-
sion of Lin?s algorithm (Lin, 1998) based on the
assumption that words sharing similar contexts
should have similar semantics. Contrary to Lin, in
our approach we do not perform any dependency
analysis of the corpus data and compute semantic
similarity between strings simply in terms of the
mutual information of trigrams.
The semantic similarity strategy we imple-
mented can be summarized as follows:
? We start by generating a list of trigrams from
the corpus.
? We assign to each pair of tokens in the corpus
a value for their mutual information.
? We assign to each pair of tokens in the corpus
a value for their similarity.
? For each token in the corpus, we extract the N
most similar tokens and take the most modern
one as the normalized form.
The mutual information I for a pair of tokens t1
and t2 is defined as:
I(t1, t2) = log ?t1,?,t2???,?,???t1,?,????,?,t2? , with
? t1, ?, t2 ? the frequency of the occurrence of
the trigram t1,*,t2 in the corpus, ? ?, ?, ? ? the
total number of trigrams in the corpus, ? t1, ?, ? ?
the number of trigrams with t1 as first token and
? ?, ?, t2 ? the number of trigrams with t2 as last
token.
Semantic similarity between tokens is defined
in terms of their mutual information:
sim(t1, t2) =
?
Tt1?Tt2
I(t1,?)+I(t2,?)
?
I(t1,?)+
?
I(w2,?)
,
with Tt1 = {(v, w) : I(t1.w) > 0} and Tt2 =
{(v, w) : I(t2.w) > 0}, the sets of token pairs
that form trigrams with t1 or t2 as first element
and such that they have positive mutual informa-
tion values.
4 Evaluation
In order to evaluate the performance of our nor-
malization strategy, we extracted a subset of
recipes from the corpus for testing purposes. This
subcorpus includes 32 comparable recipes on how
to roast a chicken that have been written in a time
period ranging from 1569 to 1800 reaching a size
of 7103 words (about 8% of whole corpus). We
take as reference the results yielded by TreeTag-
ger1 (Schmid, 1994), the state-of-art POS-tagger
for German, regarding lemmatization and POS-
tagging.
First, we tagged the subcorpus on the non-
normalized word forms. The performance of POS-
tagging, in this case, is around 80%, which is
higher than the one observed in similar experi-
ments (cf. (Scheible et al, 2011a)) on other his-
torical corpora of German. We believe the reason
for this is the relative syntactic simplicity of recipe
texts in comparison to other kind of texts (dramas,
sermons, letters, scientific or legal texts).
The tagger?s poor performance is due to the ex-
istence of lexical items unknown to the system
(around 27%), on the one hand, and the high in-
consistency of the spelling, on the other hand.
Our strategy to circumvent this problem consists
of providing a modern word form to all histori-
cal word variants that we obtained from the pre-
viously discussed diachronic dictionary. We ex-
pected, that after the two normalization steps dis-
cussed in Section 3, the performance of the tag-
ging process should improve.
1The TreeTagger was trained on the Tu?Ba-D/Z treebank.
Its performance is about 97.4% on newspaper texts and 78%
on texts containing unknown words.
87
Strategy Lemma POS
no-norm 73% 80%
string-similarity 81% 81.4%
semantic similarity 82.5% 82%
Table 1: Evaluation Results.
Therefore, we repeated the experiment, first, on
the test subcorpus normalized by using the di-
achronic dictionary generated with first normaliza-
tion strategy, i.e. the one based on string similarity
measure and, second, on the normalized version
obtained after using the second strategy based on
semantic similarity.
Table 1 summarizes the results of a preliminary
evaluation of our strategy.
After string similarity normalization, the tagger
was able to identify all lemmas except for 1358
tokens (19% of unknown tokens). While POS-
tagging improved to 81.4%.
The semantic similarity step improved the per-
formance of lemmatization and POS reaching
82.5% and 82% respectively.
Despite the fact that our experiments refer to
very few data and to a restricted domain, we be-
lieve they are promising and show that our strat-
egy, the integration of string similarity and seman-
tic similarity measures can lead to a high quality
automatic spelling normalization and outperform
state-of-art approaches.
5 Conclusion
In this paper we have presented a comparable
corpus of historical German recipes and shown
that such comparable resources can help remov-
ing sources of noise typical of these text types
that hinder standard NLP manipulation of such
material. The old German recipes corpus is, to
our knowledge, one of the first attempts2 to build
a comparable historical corpus of German. The
corpus is accessible through a web interface and
allows sophisticated queries according to differ-
ent levels of annotation: 1) historical word forms;
2) modern normalized forms; 3) lemmas on top
of normalized forms; 4) part-of-speech, and, last
but not least; 5) semantics, namely main ingre-
dient and cooking method. Further, we describe
an innovative strategy for word form normaliza-
2We are aware of only one similar project (Bartsch et al,
2011) aimed at building a comparable corpus of German texts
for three main periods Old High, Middle High and Early New
High German. However, those corpora are not yet available.
tion that integrate string similarity measure with
semantic similarity thereby being able to cope not
only with formal spelling variations but also with
paraphrastic variations and semantic shift. More-
over, this method can be applied to any compara-
ble diachronic corpus, regardless of the time span
at stake. A preliminary evaluation has shown that
such a strategy may outperform state-of-art ap-
proaches.
References
Nina Bartsch, Stefanie Dipper, Birgit Herbers, Sarah
Kwekkeboom, Klaus-Peter Wegera, Lars Eschke,
Thomas Klein, and Elke Weber. 2011. An-
notiertes Referenzkorpus Mittelhochdeutsch (1050-
1350). Poster session at the 33rd annual meeting of
the German Linguistic Society (DGfS-2011) (Ab-
stract, Poster) .
Marcel Bollmann, Florian Petran, and Stefanie Dip-
per. 2011. Applying Rule-Based Normalization to
Different Types of Historical Texts ? An Evalua-
tion. In Proceedings of the 5th Language & Tech-
nology Conference: Human Language Technologies
as a Challenge for Computer Science and Linguis-
tics, Poznan?, November.
Marcel Diel, Bernhard Fisseni, Winfried Lenders,
and Hans-Christian Schmitz. 2002. XML-
Kodierung des Bonner Fru?hneuhochdeutschkorpus.
IKP-Arbeitsbericht NF 02, Bonn .
Stefanie Dipper. 2010. Pos-tagging of historical
language data: First experiments. In Semantic
Approaches in Natural Language Processing. Pro-
ceedings of the 10th Conference on Natural Lan-
guage Processing (KONVENS-10), pages 117?121,
Saarbru?cken.
Rafael Giusti, Arnaldo Candido Jr, Marcelo Muniz,
L??via Cucatto, and Sandra Alu??sio. 2007. Auto-
matic Detection of Spelling Variation in Historical
Corpus : An Application to Build a Brazilian Por-
tuguese Spelling Variants Dictionary. In Proceed-
ings of the Corpus Linguistics Conference, pages 1?
20.
A. Gotscharek, U. Reffle, C. Ringlstetter, K. U. Schulz,
and A. Neumann. 2011. Towards information re-
trieval on historical document collections: the role
of matching procedures and special lexica. IJDAR,
14(2):159?171.
Iris Hendrickx and Rita Marquilhas. 2011. From old
texts to modern spellings: an experiment in auto-
matic normalisation. Journal for Language Technol-
ogy and Computational Linguistics, 26(2):65?76.
Tim Hitchcock, Robert Shoemaker, Clive Emsley,
Sharon Howard, and Jamie McLaughliin. 2012.
The Old Bailey Proceedings Online, 1674-1913
(version 7.0).
Magnus Huber. 2007. The Old Bailey Proceed-
ings, 1674-1834. Evaluating and annotating a cor-
pus of 18th- and 19th-century spoken English. In
88
Meurman-Solin. Anneli and Arja Nurmi, editors,
Annotating Variation and Change, volume 1. Re-
search Unit for Variation, Contacts and Change
in English (VARIENG), University of Helsinki,
Helsinki.
Bryan Jurish. 2008. Finding canonical forms
for historical German text. In Angelika Storrer,
Alexander Geyken, Alexander Siebert, and Kay-
Michael Wu?rzner, editors, Text Resources and Lex-
ical Knowledge. Selected Papers from the 9th Con-
ference on Natural Language Processing KONVENS
2008, pages 27?38. Mouton de Gruyter, Berlin /
New York.
Marijn Koolen, Frans Adriaans, Jaap Kamps, and
Maarten de Rijke. 2006. A cross-language ap-
proach to historic document retrieval. In Mounia
Lalmas, Andy MacFarlane, Stefan Rueger, Anasta-
sios Tombros, Theodora Tsikrika, Alexei Yavlinsky,
editor, Advances in Information Retrieval, volume
3936, pages 407?419. Lecture Notes in Computer
Science, Berlin/Heidelberg: Springer.
Pierre Kunstmann and Achum Stein. 2007. Le
Nouveau Corpus d?Amsterdam. In Pierre Kunst-
mann Achim Stein, editor, Le Nouveau Corpus
d?Amsterdam. Actes de l?atelier de Lauterbad, 23-
26 fe?vrier 2006, pages 9?27. Stuttgart, Germany:
Steiner.
Vladimir I. Levenshtein. 1965. Binary codes capa-
ble of correcting deletions, insertions, and reversals.
Doklady Akademii Nauk SSSR, 163(4):845?848.
Dekang Lin. 1998. Automatic retrieval and clustering
of similar words.
Thomas Pilz, Andrea Ernst-Gerlach, Sebastian Kemp-
ken, Paul Rayson, and Dawn Archer. 2008. The
Identification of Spelling Variants in English and
German Historical Texts: Manual or Automatic?
Literary and Linguistic Computing, 23(1):65?72,
April.
Michael Piotrowski. 2012. Natural Language Pro-
cessing for Historical Texts, volume 5. Morgan &
Claypool Publishers, September.
Reinhard Rapp, Serge Sharoff, and Bogdan Babych.
2012. Identifying word translations from compa-
rable documents without a seed lexicon. In LREC,
pages 460?466.
Silke Scheible, Richard J. Whitt, Martin Durrell, and
Paul Bennett. 2011a. Evaluating an f-the-shelfS-
tagger on Early Modern German text. In Proceed-
ings of the 5th ACL-HLT Workshop on Language
Technology for Cultural Heritage, Social Sciences,
and Humanities, number June, pages 19?23, Port-
land, Oregon. Association for Computational Lin-
guistics.
Silke Scheible, Richard J. Whitt, Martin Durrell, and
Paul Bennett. 2011b. A gold standard corpus
of early modern german. In Linguistic Annotation
Workshop, pages 124?128.
Helmut Schmid. 1994. Probabilistic part-of-speech
tagging using decision trees. In Proceedings of
International Conference on New Methods in Lan-
guage Processing, Manchester, UK.
Andrea Wurm. 2007. Translatorische
Wirkung: ein Beitrag zum Versta?ndnis von
U?bersetzungsgeschichte als Kulturgeschichte am
Beispiel deutscher U?bersetzungen franzo?sischer
Kochbu?cher in der Fru?hen Neuzeit. Ph.D. thesis,
Universita?t des Saarlandes, Saarbru?cken.
89
