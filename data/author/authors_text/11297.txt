Coling 2008: Companion volume ? Posters and Demonstrations, pages 145?148
Manchester, August 2008
Online-Monitoring of Security-Related Events
Martin Atkinson, Jakub Piskorski, Bruno Pouliquen
Ralf Steinberger, Hristo Tanev, Vanni Zavarella
Joint Research Centre of the European Commission
Institute for the Protection and Security of the Citizen
Via Fermi 2749, 21027 Ispra (VA), Italy
firstname.lastname@jrc.it
Abstract
This paper presents a fully operational
real-time event extraction system which is
capable of accurately and efficiently ex-
tracting violent and natural disaster events
from vast amount of online news articles
per day in different languages. Due to the
requirement that the system must be mul-
tilingual and easily extendable, it is based
on a shallow linguistic analysis. The event
extraction results can be viewed on a pub-
licly accessible website.
1 Introduction
Gathering information about violent and natural
disaster events from online news is of paramount
importance to better understand conflicts and to
develop global monitoring systems for the auto-
matic detection of precursors for threats in the
fields of conflict and health. This paper reports
on a fully operational live event extraction system
to detect information on violent events and natural
disasters in large multilingual collections of online
news articles collected by the news aggregation
system Europe Media Monitor (Best et al, 2005),
http://press.jrc.it/overview.html.
Although a considerable amount of work on the
automatic extraction of events has been reported,
it still appears to be a lesser studied area in com-
parison to the somewhat easier tasks of named-
entity and relation extraction. Two comprehensive
examples of the current functionality and capabil-
ities of event extraction technology dealing with
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
the identification of disease outbreaks and con-
flict incidents are given in (Grishman et al, 2002)
and (King and Lowe, 2003) respectively. The most
recent trends and developments in this area are re-
ported in (Ashish et al, 2006)
In order to be capable of processing vast
amounts of textual data in real time (as in the case
of EMM)we follow a linguistically lightweight ap-
proach and exploit clustered news at various pro-
cessing stages (pattern learning, information fu-
sion, geo-tagging, etc.). Consequently, only a tiny
fraction of each text is analysed. In a nutshell, our
system deploys simple 1 and 2-slot extraction pat-
terns to identify event-relevant entities. These pat-
terns are semi-automatically acquired in a boot-
strapping manner by using clustered news data.
Next, information about events scattered over dif-
ferent documents is integrated by applying voting
heuristics. The results of the core event extraction
system are integrated into a real-world global mon-
itoring system. Although we mainly cover the se-
curity domain, the techniques deployed in our sys-
tem can be applied to other domains, such as for
instance tracking business-related events for risk
assessment.
In the remaining part of this paper we give a
brief overview of the real-time event extraction
processing chain and describe the particularities of
selected subcomponents. Finally, the online appli-
cation is presented.
2 Real-time Event Extraction Process
The real-time event extraction processing chain is
depicted in Figure 1. First, news articles are gath-
ered by dedicated software for electronic media
monitoring, namely the EMM system (Best et al,
2005). EMM receives an average of 50,000 news
articles per day from about 1,500 news sources in
145
over 40 languages, and regularly checks for up-
dates of news. Secondly, the input data is grouped
into news clusters ideally including documents
on one topic or event. Then, clusters describing
security-related events are selected using keyword-
based heuristics. For each such cluster, the system
tries to detect and extract only the main event by
analysing all documents in the cluster.
EMM
News
Clustering / 
Geo Tag
Text Pre-
Processing 
Pattern 
Matching
Information 
Aggregation 
Events
NEXUS
Figure 1: Real-time processing chain.
Next, each cluster is processed by our core event
extraction engine. For each detected violent event,
it produces a frame, whose main slots are: date and
location, number of killed, injured or kidnapped
people, actors, type of event, weapons used, etc.
In an initial step, each document in the cluster
is linguistically pre-processed in order to produce
a more abstract representation of the texts. This
encompasses: fine-grained tokenisation, sentence
splitting, matching of known named entities, la-
belling of key terms and phrases like action words
(e.g. kill, shoot) and person groups.
Once texts are grouped into clusters and lin-
guistically pre-processed, the pattern engine ap-
plies a cascade of extraction grammars (consisting
of 1 and 2-slot extraction patterns) on each docu-
ment within a cluster. For creating extraction pat-
terns, we apply a blend of machine learning and
knowledge-based techniques. The extraction pat-
terns are matched against the first sentence and the
title of each article from the cluster. By processing
only the top sentence and the title, the system is
more likely to capture facts about the most impor-
tant event in the cluster. Even if we fail to detect
a single piece of information in one document in a
cluster, the same information is likely to be found
in another document of the cluster, where it may
be expressed in a different way.
Finally, since information about events is scat-
tered over different articles, the last step con-
sists of cross-document cluster-level information
fusion, i.e., we aggregate and validate information
extracted locally from each single article in the
same cluster. For this purpose, simple voting-like
heuristics are deployed.
Every ten minutes, EMM clusters the articles
found during the last four hours. The event extrac-
tion engine analyses each of these clusters. The
event information is thus always up-to-date. The
output of the event extraction engine constitutes
the input for a global monitoring system.
3 Geo-tagging Clusters
Challenges for geo-tagging clusters are that place
names can be homographic with person names and
with other place names. We solve the former am-
biguity by first identifying person names found
in our automatically populated database of known
people and organisations. For the latter ambiguity,
we adopted a cluster-centric approach by weight-
ing all place names found in a cluster and by select-
ing the one with the highest score. For each cluster,
we thus first establish all possible candidate loca-
tions by looking up in the texts all place, province,
region and country names found in a multilingual
gazetteer (including name variants). The weights
of the locations are then based on the place name
significance (e.g., a capital city scores higher than
a village) and on the place name hierarchy (i.e. if
the province or region to which the place belongs
are also mentioned in the text, it scores higher).
4 Pattern Acquisition
For pattern acquisition, we deploy a weakly super-
vised bootstrapping algorithm (Tanev and Oezden-
Wennerberg, 2008) similar in spirit to the one de-
scribed in (Yangarber, 2003), which involves some
manual validation. Contrary to other approaches,
the learning phase exploits the knowledge to which
cluster the news items belong. Intuitively, this
guarantees better precision of the learned patterns.
In particular, for each event-specific semantic role
(e.g. killed), a separate cycle of learning iterations
is executed (usually up to three) in order to learn
1-slot extraction patterns. Each cluster includes ar-
ticles from different sources about the same news
story. Therefore, we assume that each entity ap-
pears in the same semantic role (actor, victim, in-
jured) in the context of one cluster. An auto-
matic procedure for syntactic expansion comple-
ments the learning. This procedure accepts a man-
ually provided list of words which have identical
(or similar) syntactic usage patterns (e.g. killed,
assassinated, murdered, etc.). It then generates
new patterns from the old ones by substituting for
each other the words in the list. After 1-slot pat-
terns are acquired, some of them are used to man-
ually create 2-slot patterns like X shot Y.
146
5 Pattern matching engine
In order to guarantee that massive amounts of tex-
tual data can be processed in real time, we have
developed ExPRESS (Piskorski, 2007), an effi-
cient extraction pattern engine, which is capable of
matching thousands of patterns against MB-sized
texts within seconds. The pattern specification lan-
guage is a blend of two previously introduced IE-
oriented grammar formalisms, namely JAPE used
in GATE (Cunningham et al, 2000) and XTDL,
used in SPROUT (Dro?zd?zy?nski et al, 2004).
A single pattern is a regular expression over flat
feature structures (FS), i.e., non-recursive typed
feature structures without structure sharing, where
features are string-valued and ? unlike in XTDL
types ? are not organised in a hierarchy. Each such
regular expression is associated with a list of FSs
which constitute the output specification. Like in
XTDL, we deploy variables and functional oper-
ators for forming slot values and for establishing
contact with the ?outer world?. Further, we adapted
JAPEs feature of associating patterns with mul-
tiple actions, i.e., producing multiple annotations
(possibly nested). An empirical comparison of the
run-time behaviour of the new formalism against
the other 2 revealed that significant speed-ups can
be achieved (at least 30 times faster). ExPRESS
comes with a pool of highly efficient core linguis-
tic processing resources (Piskorski, 2008).
6 Information Aggregation
Once single pieces of information are extracted by
the pattern engine, they are merged into event de-
scriptions by applying an information aggregation
algorithm. This algorithm assumes that each clus-
ter reports at most one main event of interest. It
takes as input the text entities extracted from one
news cluster with their semantic roles and consid-
ers the sentences from which these entities are ex-
tracted. If one and the same entity has two roles as-
signed, a preference is given to the role assigned by
the most reliable group of patterns (e.g., 2-slot pat-
terns are more reliable). Another ambiguity which
has to be resolved arises from the contradictory in-
formation which news sources give about the num-
ber of victims. We use an ad-hoc heuristic for
computing the most probable estimation for these
numbers, i.e., firstly the largest group of numbers
which are close to each other is selected and sec-
ondly the number closest to the average in that
group is chosen. After this estimation is com-
puted, the system discards from each news clus-
ter all the articles whose reported victim numbers
significantly differ from the estimated numbers for
the whole cluster. Additionally, some victim arith-
metic is applied, i.e., a small taxonomy of person
classes is used to sum victim numbers (e.g., gun-
men and terrorists belong to the same class ofNon-
GovernmentalArmedGroup).
7 Event Classification
After the single pieces of information are assem-
bled into the event description, an event classifica-
tion is performed. Some of the most used event
classes are Terrorist Attack, Bombing, Shooting,
Air Attack, etc. The classification algorithm uses
a blend of keyword matching and domain spe-
cific rules. As an example, consider the following
domain-specific rule: if the event description in-
cludes named entities, which are assigned the se-
mantic role kidnapped, as well as entities which
are assigned the semantic role released, then the
type of the event is Hostage Release, rather than
Kidnapping. If the event refers to kidnapped peo-
ple and at the same time the news articles contain
words like video or videotape, then the event type
is Hostage Video Release. The second rule has a
higher priority, therefore it impedes the Hostage
Release rule to fire erroneously, when the release
of a hostage video is reported.
8 Monitoring Events
The core event extraction engine for English is
fully operational since December 2007. There are
two online applications running on top of it which
allow monitoring events. The first one is a dedi-
cated webpage using the Google Maps JavaScript
API (see Figure 2). It is publicly accessible at:
http://press.jrc.it/geo?type=event
&format=html&language=en and provides
an instant overview of what is occurring where in
the world. A small problem with this application
is that it overlays and hides events that are close to
each other.
The second application shows the same events
using the Google Earth client application. The
geo-located data is transmitted via the Keyhole
Markup Language (KML) format
1
supported di-
rectly by Google Earth.
2
The application is re-
1
http://code.google.com/apis/kml/documentation/
2
In order to run it, start Google Earth with KML:
http://press.jrc.it/geo?type=event&format=kml&language=en
147
Figure 2: Event visualisation with Google Maps
stricted to displaying at most half the globe, but
it allows expanding overlaid events.
Since it is important for stakeholders to be
quickly and efficiently informed about the type and
gravity of the event, various icons are used to rep-
resent the type or group of events visually (see Fig-
ure 3). We use general forms of icons for violent
events and specific forms of icons for natural and
man-made disasters. For violent events, the gen-
eral form represents the major consequence of the
event, except for kidnappings, where specific icons
are used. Independently of the type of event, all
icons are sized according to the damage caused,
i.e. it is dependent on the number of victims in-
volved in the event. Also, to highlight the events
with a more significant damage, a border is drawn
around the icon to indicate that a threshold of peo-
ple involved has been passed.
The online demo is available for English, Italian
and French. We are currently working on adapt-
ing the event extraction engine to other languages,
including Russian, Spanish, Polish, German and
Arabic. A more thorough description of the sys-
tem can be found in (Tanev et al, 2008; Piskorski
et al, 2008).
References
Ashish, N., D. Appelt, D. Freitag, and D. Zelenko. 2006.
Proceedings of the workshop on Event Extraction and Syn-
thesis, held in conjunction with the AAAI 2006 conference.
Menlo Park, California, USA.
Best, C., E. van der Goot, K. Blackler, T. Garcia, and
D. Horby. 2005. Europe Media Monitor. Technical Re-
port EUR 22173 EN, European Commission.
Cunningham, H., D. Maynard, and V. Tablan. 2000. JAPE: a
Java Annotation Patterns Engine (Second Edition). Tech-
nical Report, CS?00?10, University of Sheffield, Depart-
ment of Computer Science.
?
Kidnap
K
A
Arrest
R
Release
V
Video
V
Man
Made
?Violent EventUndefined Violent EventKilled Violent EventInjured Violent EventKindnapped Violent EventArrest Hostage Release VideoRelease Violent EventNo Consequneces
Man Made
Disaster
Man Made 
Fire
Man Made
Explosion
ND
!
Natural
Dister
Volcanic 
Eruption
Tsunami Earthquake Landslide
?
Avalanche Tropical
Storm
Lightning
Strike
Storm
Snow
Storm
Flood Wild Fire
Heatwave
Key to Symbols
Consequence Significance (number of people involved)
No Circle  = up to 10 Red Circle = More than 100Yellow Circle= between 10 and 100
Humanitarian
Crisis
Trial
Unclassified
Figure 3: Key to event type icons and magnitude
indicators
Dro?zd?zy?nski, W., H.-U. Krieger, J. Piskorski, U. Sch?afer,
and F. Xu. 2004. Shallow Processing with Unification
and Typed Feature Structures ? Foundations and Appli-
cations. K?unstliche Intelligenz, 2004(1):17?23.
Grishman, R., S. Huttunen, and R. Yangarber. 2002. Real-
time Event Extraction for Infectious Disease Outbreaks.
Proceedings of the Human Language Technology Confer-
ence (HLT) 2002.
King, G. and W. Lowe. 2003. An Automated Information
Extraction Tool for International Conflict Data with Per-
formance as Good as Human Coders: A Rare Events Eval-
uation Design. International Organization, 57:617?642.
Piskorski, J., H. Tanev, M. Atkinson, and E. Van der Goot.
2008. Cluster-centric Approach to News Event Extraction.
In Proceedings of MISSI 2008, Wroclaw, Poland.
Piskorski, J. 2007. ExPRESS Extraction Pattern Recogni-
tion Engine and Specification Suite. In Proceedings of the
International Workshop Finite-State Methods and Natu-
ral language Processing 2007 (FSMNLP?2007), Potsdam,
Germany.
Piskorski, J. 2008. CORLEONE ? Core Linguistic Entity
Online Extraction. Technical report 23393 EN, Joint Re-
search Centre of the European Commission, Ispra, Italy.
Tanev, H. and P. Oezden-Wennerberg. 2008. Learning to
Populate an Ontology of Violent Events (in print). In
Fogelman-Soulie, F. and Perrotta, D. and Piskorski, J. and
Steinberger, R., editor, NATO Security through Science Se-
ries: Information and Communication Security. IOS Press.
Tanev, H., J. Piskorski, and M. Atkinson. 2008. Real-
Time News Event Extraction for Global Crisis Monitor-
ing. In Proceedings of the 13
th
International Conference
on Applications of Natural Language to Information Sys-
tems (NLDB 2008, Lecture Notes in Computer Science Vol.
5039), pages 207?218. Springer-Verlag Berlin Heidelberg.
Yangarber, R. 2003. Counter-Training in Discovery of Se-
mantic Patterns. In Proceedings of the 41
st
Annual Meet-
ing of the ACL.
148
Proceedings of the Demonstrations at the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 65?68,
Gothenburg, Sweden, April 26-30 2014.
c?2014 Association for Computational Linguistics
Event Extraction for Balkan Languages
Vanni Zavarella, Dilek K?uc? ?uk, Hristo Tanev
European Commission
Joint Research Centre
Via E. Fermi 2749
21027 Ispra (VA), Italy
first.last@jrc.ec.europa.eu
Ali H?urriyeto
?
glu
Center for Language Studies
Radboud University Nijmegen
P.O. Box 9103
NL-6500 HD Nijmegen
a.hurriyetoglu@let.ru.nl
Abstract
We describe a system for real-time detec-
tion of security and crisis events from on-
line news in three Balkan languages: Turk-
ish, Romanian and Bulgarian. The system
classifies the events according to a fine-
grained event type set. It extracts struc-
tured information from news reports, by
using a blend of keyword matching and
finite-state grammars for entity recogni-
tion. We apply a multilingual methodol-
ogy for the development of the system?s
language resources, based on adaptation
of language-independent grammars and on
weakly-supervised learning of lexical re-
sources. Detailed performance evaluation
proves that the approach is effective in de-
veloping real-world semantic processing
applications for relatively less-resourced
languages.
1 Introduction
We describe a real-time event extraction system
for three less-resourced languages: Bulgarian, Ro-
manian and Turkish
1
. The goal of event extraction
is to identify instances of a specified set of event
types in natural language texts, and to retrieve
database-like, structured information about event
participants and attributes: these are the entities
that are involved in the event and fill type-specific
event roles (Ashish et al., 2006). For example,
in the fragment ?Three workers were injured in
a building collapse?, the phrase ?three workers?
will be assigned a semantic role Injured of the
event type ManMadeDisaster template.
Gathering and tracking such information over
time from electronic news media plays a crucial
1
While belonging to three distant language families,
namely Slavic, Romance and Turkic, respectively, they are
spoken in the same geopolitical area, the Balkans.
role for the development of open-source intelli-
gence systems, particularly in the context of global
news monitoring of security threats, mass emer-
gencies and disease outbreaks (Yangarber et al.,
2005). In this view, it has been proved that be-
ing able to rely on highly multilingual text mining
tools and language resources is of paramount im-
portance, in order to achieve an unbiased coverage
of global news content (Steinberger, 2012).
The system language components include fi-
nite state-based entity extraction grammars and
domain-specific semantic lexica. These are
adapted to the target language from existing
language-independent resources or built by using
semi-supervised machine learning algorithms, re-
spectively. Most importantly, the lexical acquisi-
tion methods we put into place neither make use
of any language knowledge nor require to have an-
notated corpora available.
Section 2 outlines the main processing stages of
the application. In Section 3 we describe the meth-
ods applied to acquire and adapt the system?s lan-
guage knowledge bases. Finally, in Section 4 we
report on an evaluation on event type classification
and on the extraction of slot fillers for event tem-
plates, and we briefly discuss system performance
and prospective improvements.
2 System Architecture
As depicted in Figure 1 (Tanev et al., 2009), first
news feeds are clustered, upstream of the event
extraction engine, by applying similarity metrics
over meta data (named entities, locations, cate-
gories) extracted from single articles by dedicated,
multilingual software.
Event extraction begins by preprocessing the ti-
tle and first three sentences of each article within
a cluster. This encompasses: fine-grained tok-
enization, sentence splitting, domain-specific dic-
tionary look-up (i.e. matching of key terms in-
dicating numbers, quantifiers, person titles, per-
65
Meta-Data Creation
Real Time Clusterer
Geo-Locating
Core Linguistic Analysis
Cascaded Event 
Extraction  Grammar 
Application
Entity Role 
Disambiguator
Victim 
Arithmetic
Event Type 
Classifier
Event Description
Assembly
News
News
News
News
News
Figure 1: Event extraction processing chain
son groups descriptors like civilians, policemen
and Shiite), and finally morphological analysis,
simply consisting of lexicon look-up on large
domain-independent morphological dictionaries
from the MULTEXT project (Erjavec, 2004). Sub-
sequently, a multi-layer cascade of finite-state ex-
traction grammars in the ExPRESS formalism
(Piskorski, 2007) is applied on such more ab-
stract representation of the article text, in order
to: a)identify entity referring phrases, such as
persons, person groups, organizations, weapons,
etc. b) assign them to event specific roles by lin-
ear combination with event triggering surface pat-
terns. For example, in the text ?Iraqi policemen
shot dead an alleged suicide bomber? the gram-
mar should extract the phrase ?Iraqi policemen?
and assign to it the semantic role Perpetrator,
while the phrase ?alleged suicide bomber? should
be extracted as Dead. We use a ?lexicon? of 1/2-
slot patterns of the form:
<DEAD[Per]> was shot by <PERP>
<KIDNAP[Per]> has been taken hostage
where each slot position is assigned an event-
specific semantic role and includes a type restric-
tion (e.g. Person) on the entity which may fill
the slot.
Finally, we aggregate and validate information
extracted locally from each single article in the
same cluster, such as entity role assignment, vic-
tim counts and event type.
We categorize the main event from each cluster
with respect to a fine-grained event type set, shown
in Table 1.
The event classification module consists of a
blend of keyword matching, event role detection
and a set of rules controlling their interaction.
First, for each event type, we deploy: a) a list
of weighted regular expression keyword patterns:
each pattern match is awarded the corresponding
weight, and an event type is triggered when the
weight sum exceeds a defined threshold; b) a set of
boolean pattern combinations: OR pattern lists are
combined by the AND operator, each pattern is a
restricted regular expression and conjunctions are
restricted by proximity constraints. For example
in order to detect TerroristAttack we use the fol-
lowing combination (translated here in English):
(?bomb? OR ?explosion? OR....) AND (?terrorist?
OR ?Al Qaida? OR..).
Besides the event TYPE, the other main
slots of an output event frame include:
TYPE, DEAD, DEAD-COUNT, ARRESTED,
ARRESTED-COUNT, PERPETRATOR, WEAPON,
etc.
The system will be demonstrated using a KML-
aware earth browser
2
. Figure 2 shows a sample
output event template.
3 Development of language resources
The system?s language components are:
Event grammar rules They consist of regular
expressions over flat feature structures whose el-
ements include, among the others, semantic types
from the domain lexica. We use them to locally
parse semantic entities such as person names, per-
son group descriptions, and their clausal combi-
nation with verbal event patterns (see Section 2).
Grammars in target languages are compiled by
adapting the existing rules from source languages,
such as English, while the bulk of grammar devel-
opment mostly consists of providing suitable lexi-
cal resources.
Semantic dictionaries Domain-specific lexica,
listing a number of (possibly multi-word) expres-
sions sub-categorized into semantic classes rel-
evant for the event domain, with limited or no
linguistic annotation, are used by entity recogni-
tion grammar rules. Such lexica were created us-
ing the weakly supervised terminology extraction
algorithm LexiClass (Ontopopulis), described in
(Tanev et al., 2009). In order to enforce syntactic
2
E.g. Google Earth. Notice that Geocoding is cur-
rently performed at the level of article text by a language-
independent algorithm which is not yet integrated within the
event detection process, while Document Creation Date is
currently used as the event Date slot filler.
66
Figure 2: A sample output template of the system
constraints (e.g. Case) into event clause rules for
Romanian language, we have enriched learnt lex-
ical entries for the semantic classes with morpho-
logical annotations, using MULTEXT resources.
For Turkish, as we do not currently perform mor-
phological analysis, we have rather included com-
mon inflected forms of the applicable lexical en-
tries, resulting in larger lexica.
Event triggering patterns They are also ac-
quired semi-automatically, starting with a set of
seed examples and an article clustering, by deploy-
ing the paraphrase learning algorithm described in
(Tanev et al., 2008). For Bulgarian, the grammar,
semantic dictionaries and event patterns were cre-
ated simultaneously, following a semi-automatic
approach, described in (Tanev and Steinberger,
2013). In particular, we learned a list of terms
referring to people, institutions and organizations
and the corresponding pre- and post-modifiers
(about 5000 terms). In the same manner, we
learned about 550 surface patterns for killing, in-
juring, kidnapping and arresting actions, together
with a 4 level grammar cascade.
Keyword terms The keyword sets used in the
event type definitions, namely the OR lists in
the boolean pattern combinations (see Section 2
above), can be viewed as instances of some more
abstract semantic classes, that a domain expert
uses to model a target event scenario. These
classes are semi-automatically acquired using the
LexiClass algorithm, and then manually com-
Table 1: Event type set
AirMissileAttack Landslide
ArmedConflict LightningStrike
Arrest ManMadeDisaster
Assassination MaritimeAccident
Avalanche PhysicalAttack
BioChemicalAttack Robbery
Bombing Shooting
Disorder/Protest/Mutiny Stabbing
Earthquake Storm
Execution TerroristAttack
Explosion TropicalStorm
Floods Tsunami
HeatWave Vandalism
HeavyWeaponsFire VolcanicEruption
HostageVideoRelease Wildfire
HumanitarianCrisis WinterStorm
Kidnapping NONE
bined. As Turkish is an agglutinative language,
we have frequently added wildcards at the ends of
keywords to cover possible inflected forms.
4 Experiments and Evaluation
System performance is evaluated on three differ-
ent extractive tasks, carried out on the titles and
first three sentences of single news articles: event
type classification, event role name/description ex-
traction and victim counting.
We collected test corpora of 52, 126 and 115
news articles for Bulgarian, Romanian and Turk-
ish, respectively, spanning over a time range of 2
months
3
. For each article in the gold standard, we
3
Articles were manually selected using news aggregators
such as Google News. Type distribution resulted in zeroes for
67
Table 2: System performance in single article extraction mode.
Lang
Type Dead Injured Arrested Kidnapped Perpetrator Weapon
MRR mF MF MSE mF MF MSE mF MF MSE mF MF MSE mF MF mF MF
BG 0.34 0.27 0.68 17.08 0.44 0.6 108.82 0.22 1.0 7.69 0.4 0.5 0.71 0.0 0.0 0.39 1.0
RO 0.22 0.48 0.73 36.53 0.46 0.97 18.57 0.39 0.82 80.5 0.2 1.0 2.14 0.07 0.67 0.1 0.2
TR 0.66 0.73 0.79 16.41 0.85 0.91 0.24 0.31 0.36 52.17 0.4 0.33 0.82 0.25 0.67 0.77 1.0
annotated: a list of applicable types, ordered by
relevance, for the main event reported in the arti-
cle; the set of all the names/descriptions occurring
in the text for each applicable event role, merging
morphological variants; the cumulative count for
the roles Dead, Injured, Kidnapped and Arrested.
Event type classification is evaluated by apply-
ing an adapted version of the mean reciprocal rank
(MRR) score, used in Information Retrieval to
evaluate processes producing a list of relevance or-
dered query responses. In our case, the MRR for a
set of N articles is:
MRR =
1
|N |
N
?
i=1
1
rank
i
where rank is the rank of the system type re-
sponse within the gold standard type list for each
article.
For each role name/description extraction sepa-
rately, we compute standard Precision, Recall and
F1-measure on system responses, based on partial,
n-gram match with gold standard responses, ignor-
ing morphological suffixes.
Finally, we record the root Mean Squared Er-
ror (MSE) of system output victim count values
against gold standard, over all applicable roles.
Table 2 summarizes the evaluation results. mF
and MF columns for each role description task
represent respectively the micro and macro aver-
age F1-measure over the test set.
Overall, the performance figures are in line with
previous evaluations on other languages (Tanev et
al., 2009). This proves the methodology is ef-
fective on adapting the system to new languages
even with little lexical and syntactical proximity.
Turkish system consistently outperforms the oth-
ers, and it also underwent the most resource devel-
opment cycles: this suggests that applying learn-
ing iterations, alternated with human filtering, to
the language resources, can increase system ac-
curacy, eventually making it usable for real-world
applications. System accuracy is still unreliable
for victim counting. One of the main reasons for
large errors in victim counting is that the system
some less frequent event types.
interprets historical victim statistics reported in ar-
ticles as event instances. We are currently imple-
menting temporal and discourse heuristics to mit-
igate this problem.
Acknowledgments
This study is supported in part by a postdoctoral
research grant from T
?
UB
?
ITAK and by the Dutch
national program COMMIT.
References
Naveen Ashish, Doug Appelt, Dayne Freitag, and
Dmitry Zelenko. 2006. Proceedings of the work-
shop on event extraction and synthesis. Technical
report, AAAI.
Tomaz Erjavec. 2004. MULTEXT-East morphosyn-
tactic specifications.
Jakub Piskorski. 2007. ExPRESS?extraction pattern
recognition engine and specification suite. In Pro-
ceedings of the International Workshop Finite-State
Methods and Natural language Processing.
Ralf Steinberger. 2012. A survey of methods to ease
the development of highly multilingual text mining
applications. Language Resources and Evaluation,
46(2):155?176.
Hristo Tanev and Josef Steinberger. 2013. Semi-
automatic acquisition of lexical resources and gram-
mars for event extraction in Bulgarian and Czech. In
Proceedings of the 4th Biennial International Work-
shop on Balto-Slavic Natural Language Processing,
pages 110?118.
Hristo Tanev, Jakub Piskorski, and Martin Atkinson.
2008. Real-time news event extraction for global
crisis monitoring. In E. Kapetanios, V. Sugumaran,
and M. Spiliopoulou, editors, Natural Language and
Information Systems, volume 5039 of Lecture Notes
in Computer Science, pages 207?218.
Hristo Tanev, Vanni Zavarella, Jens Linge, Mijail
Kabadjov, Jakub Piskorski, Martin Atkinson, and
Ralf Steinberger. 2009. Exploiting Machine Learn-
ing Techniques to Build an Event Extraction Sys-
tem for Portuguese and Spanish. Linguam?atica,
1(2):55?66.
Roman Yangarber, Lauri Jokipii, Antti Rauramo, and
Silja Huttunen. 2005. Extracting information about
outbreaks of infectious epidemics. In Proceedings
of the HLT/EMNLP.
68
Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic
Evaluation (SemEval 2013), pages 58?63, Atlanta, Georgia, June 14-15, 2013. c?2013 Association for Computational Linguistics
FSS-TimEx for TempEval-3: Extracting Temporal Information from Text
Vanni Zavarella
Joint Research Centre
European Commission
21027 Ispra, Italy
vanni.zavarella
@jrc.ec.europa.eu
Hristo Tanev
Joint Research Centre
European Commission
21027 Ispra, Italy
hristo.tanev
@jrc.ec.europa.eu
Abstract
We describe FSS-TimEx, a module for the
recognition and normalization of temporal ex-
pressions we submitted to Task A and B of
the TempEval-3 challenge. FSS-TimEx was
developed as part of a multilingual event ex-
traction system, Nexus, which runs on top of
the EMM news processing engine. It consists
of finite-state rule cascades, using minimalis-
tic text processing stages and simple heuris-
tics to model the relations between events and
temporal expressions. Although FSS-TimEx
is already deployed within an IE application
in the medical domain, we found it useful to
customize its output to the TimeML standard
in order to have an independent performance
measure and guide further developments.
1 Introduction
The FSS-TimEx (Finite State-based Shallow Time
Extractor) system participating in TempEval-3 is in-
tegrated in the event extraction engine Nexus (Tanev
et al, 2008), developed at the EC?s Joint Research
Center for extracting event information from on-line
news articles gathered by the Europe Media Mon-
itor (EMM) news aggregation and analysis family
of applications(Steinberger et al, 2009). Nexus is
highly multilingual1 and easily portable across do-
mains through semi-automatic learning of lexical re-
sources. In the domain of epidemiological surveil-
lance, the event extraction task required a particu-
larly deep temporal information analysis, in order to
1Currently, it covers English, French, Italian, Spanish, Por-
tuguese, Turkish, Russian, Arabic.
detect temporal relations among event reports and
mitigate the classical event duplication problem. As
an example, from a report like:
The overall death toll has risen to 160
since the beginning of the year, after 2
patients in Gulu and 2 in Masindi died on
Tue 5 Dec 2000.
a system might be prevented to wrongly sum up the
two victim counts (160+4) only if it is made aware of
the inclusion relation between the first time interval
and the date, which in turn implies normalizing the
two temporal expressions.
Currently, FSS-TimEx is deployed for French,
English and Italian and extensions are foreseen for
further languages. Given such requirements for mul-
tilinguality, we developed FSS-TimEx using a lin-
guistically light-weight approach, applying shallow
processing modules only. On the other hand, as we
need to extract highly structured information out of
the detected temporal expressions, to be used in the
subsequent normalization phase, we mostly opted
for a rule-based approach, using finite-state gram-
mar cascades, rather than machine learning meth-
ods. Nonetheless, some of the required lexicons
were semi-automatically learned.
In our participation in Tasks A and B of the
TempEval-3, we experimented with adapting an ex-
isting timex recognition module for the English lan-
guage, to Spanish.
We first describe our system in 2,3 and 4, then in
5 we show and shortly discuss the results for Task
A and Task B, and conclude with some thoughts on
prospective developments.
58
2 System Modules
The system makes use of cascades of finite-state
grammar rules applied to the output of a set of shal-
low text processing modules.
Text Processing Modules. These include tok-
enization, sentence splitting, domain-specific dictio-
nary look-up and morphological analysis, which are
all part of the CORLEONE (Core Linguistic Entity
Online Extraction) engine (Piskorski, 2008). Mor-
phological analysis purely consists of matching text
tokens over full-form entries of a dictionary from the
MULTEXT project (Erjavec, 2004), which encodes
rich morphological features in a cross-lingual stan-
dard. Consequently, no PoS-tagging or parsing is
performed upstream of the extraction grammars.
Finite-State Grammar Engine. We use the Ex-
PRESS finite-state grammar engine (Piskorski,
2007). Grammars in the ExPRESS formalism con-
sist of cascades of pattern-action rules, whose left-
hand side (LHS) are regular expressions over flat
feature structures (FFS) and the right-hand side
(RHS) consists of a list of FFS (see Figure 1 be-
low for an example). Variable binding from LHS to
RHS, as well as string processing and Boolean op-
erators on the RHS, allow to impose relatively com-
plex constraints in the form of Boolean-valued pred-
icates.
Weakly-supervised Learning of Lexical Re-
sources. In order to determine the Class feature
for the event extraction task, we experimented with
using a language-independent method for weakly-
supervised lexical acquisition. The algorithm takes
as input a small set of seed terms, an unannotated
text corpus and a parameter for the number of boot-
strapping iterations: it then learns a ranked list of
further terms, which are likely to belong to the same
class, based on distributional n-gram features and
term clustering (Tanev et al, in press). Although
manual post-filtering is required, output term accu-
racy is reasonably high, and very high for top ranked
terms.
3 Event and Event Feature Detection
(Task B)
Although Nexus is a high precision event extraction
system, we have not deployed it to model the event
detection task. The reason is that Nexus is cus-
tomized to recognize a number of highly domain-
specific event types (e.g. Armed Conflict,
Earthquake,Terrorist Attack) and will
necessarily perform low in recall given the general,
domain-independent definition of events in Task
B. Instead, we tentatively used a small set of
language-dependent finite-state rules to model verb
phrase structure. Rules take as input MULTEXT
morphological tokens and detect verb phrases along
with a number of VP features, including Tense,
which is used by the temporal normalizer to ground
event modifying temporal expressions (see 4.2).
Class attribute was encoded in the morphologi-
cal dictionary by using the output of the machine
learning method sketched above: for each TimeML
Event Class (Pustejovsky et al, 2003), we provided
seed verb forms for all of its sub-classes, performed
multi-class learning, and used the main Class label
to annotate the union of output forms in the lexicon,
after some manual cleaning.
The OCCURRENCE class was used as the default
Class value for event verb forms, and it was overrid-
den whenever a more specific event Class value was
present2.
We do not cover event nominal forms, as after
some tests event referring and non-event referring
noun classes appeared too difficult to tell apart by
machine learning methods. Consequently, we ex-
pect system recall in Task B to be heavily limited.
4 Temporal Expressions (Task A)
FSS-TimEx?s temporal expression processing con-
sists of two stages.
In the Recognition phase, temporal expressions
are detected and segmented in text and a more ab-
stract representation of them is filled for further
processing. Local parsing of timexes is performed
by a cascade of hand-coded, partially language-
dependent finite-state grammar rules using the Ex-
PRESS engine, resulting in an intermediate fea-
2Otherwise, we chose randomly among alternative values of
Class-ambiguous event expressions.
59
rule :> ( (lex & [TYPE:"temp_signal", SURFACE:#signal, NORMALIZED:"INCLUDED"]
| lex & [TYPE:"temp_signal", NORMALIZED:"DURING"])
lex & [TYPE:"quantifier", NORMALIZED:#mod]? determiner?
lex & [TYPE:"temp_mod", OP:#op, REF_TYPE:#ref_type]
( (lex & [TYPE: "numeral", NORMALIZED:#amount1]
lex & [TYPE: "numeral", NORMALIZED:#amount2]?)
| token & [TYPE: "any_natural_number", SURFACE:#amount1]
lex & [TYPE:"time_unit", NUM:"p", GRAN:#gran]):x
-> x: period & [DIR:#op,REF_TYPE:#ref_type,MOD:#mod,GRAN:#gran,QUANT:#amount,SIGNAL:#signal]
& #amount := ConcForSum(#amount1,#amount2).
Figure 1: Sample recognition rule
ture structure-like representation, which is subse-
quently used by a language-independent Normaliza-
tion stage to compute exact values of the time ex-
pressions, according to the TimeML standard.
We judge that such a strict coupling of recognition
and normalization is better achieved through feature
extraction rules than by deploying two separate pro-
cesses3.
4.1 Recognizing Temporal Expressions
A cascade of around 90 rules is deployed for the En-
glish language. These comprise lower-level rules, in
charge of modelling language constructions in the
target language, and typization rules that check the
attribute configuration of lower-level rule output and
return a corresponding structure, typed according to
an intermediate annotation type set, exporting all at-
tribute values relevant for normalization.
As an example, the rule shown in Figure1 detects
single-boundary period expressions (e.g. in the pre-
vious four weeks or during the next five days).
Notice that the rule output type is the non
TimeML-compliant period (i.e. an anchored time
duration). This is an intermediate annotation type
which is subsequently converted into a TimeML
type (Duration) during the Normalization phase.
The temporal lexicon referenced by the gram-
mar contains around 300 entries for the English lan-
guage, classified into as many as 24 types, each de-
scribed by a small attribute list. Sample entries from
the English lexicon are listed in Figure 2.
This lexicon structure (types and attributes) was
applied as such to the Spanish language; lexicon
population was manually done in one day of work,
by first translating lexical triggers (e.g. day, month
3This architecture is very close to the one proposed by the
ITA-Chronos system (Negri, 2007).
monday | TYPE:day_name | NORMALIZED:Monday
weeks | TYPE:time_unit | GRAN:week | NUM:p
night | TYPE:day_period_name | NORMALIZED:NI
ago | TYPE:temp_adv | OP:- | REF_TYPE:speaker
last | TYPE:temp_mod | OP:- | REF_TYPE:speaker
since | TYPE:temp_signal | NORMALIZED:BEGIN
early | TYPE:mod | NORMALIZED:START
Figure 2: Sample lexicon entries
names, numerals) and then gathering more func-
tional entries (temporal adverbs, modifiers, etc.) by
running test rules on large corpora. It turned out that,
by using a parallel lexicon structure, we could re-
duce the cross-lingual re-arrangement of extraction
rules for the Spanish grammar, minimizing the work
cost to only 2 days, excluding fine tuning.
4.2 Normalization
Normalization is a fully language-independent pro-
cess, working with calendar representations of tem-
poral expressions4 built out of the output feature
structures from the Recognition phase. It comprises
two sub-processes:
Anchor selection. First, anchor selection deter-
mines and maintains a reference time for relative
timex resolution, starting by using the Article Cre-
ation Date and updating it along the resolution pro-
cess according to a simple search heuristic: select
the closest preceding resolved timex with a compat-
ible level of granularity. We experimented with two
alternative settings for this, one restricting the search
to timexes within the same sentence, the other span-
ning over the whole article text: we noticed a sys-
tematic gain in normalization accuracy with the for-
mer setting and we used it for Task A.
4The normalization is entirely implemented in Java code.
60
Timex-Event mapping. For certain timex
classes5 we need to resort to Tense information
from event-referring verb phrases in order to dis-
ambiguate between future and past interpretation.
For this purpose, a simple, syntax-free heuristic is
implemented to compute a mapping from each time
expression onto the event it modifies, which just
uses a weighted token distance metric, promoting
events preceding the timex over those following it.
Finally, calendar arithmetic is used to resolve and
normalize the value of relative timexes.
5 Results6
5.1 Temporal Expression Extraction
For English, our system scored in the middle range
over all participant systems on relaxed match F1
measure. Strict match figures are not indicative: in-
deed, temporal signals (like on in on Friday) were
systematically included in the extracted extent, con-
trary to the TIMEX3 tag specification, because this
is required by finite-state parsing of the IE system
with which FSS-TimEx was integrated.
Compared to the best performing system (BestEN
in Table1), our approach mainly suffered from rela-
tively low recall. Although such a rate of false neg-
atives can be expected from a rule-based approach,
in our case it was mostly due to two main ?bugs? in
the normalization code: first, in the process of tun-
ing system output types to TimeML, we erroneously
discarded date expressions introduced by temporal
signals, like in from now; secondly, we do not nor-
malize single adverbial expressions (currently), al-
though they are detected by grammar rules.
We outperformed in Precision the best F1 system.
Many false positives were all coming from a single
article, where the word season in flu season was sys-
tematically annotated as an event in the gold stan-
dard. This kind of context-based inference seems to
be out of reach for our rule-based, local parsing ap-
proach.
The major flaw in porting the system to Span-
ish language was a 28% Recall drop. Main types
5E.g. what we refer to as relativeTime or
relativeOffset, like on Thursday and this weekend, re-
spectively.
6Results were obtained in 1.89 and 1.97 seconds of com-
putation time respectively for English and Spanish data, on an
Intel Core i3 M380 2.53GHz processor.
of false negatives included fuzzy expressions (e.g.
hace tiempo), and compositional expressions.
Performance in timex classification and normal-
ization still falls behind top scoring systems. Finite-
state techniques can only parse local constructions,
greedily consuming as long text spans as possible:
therefore we systematically miss clausal relations
like in: The day before Raymond Roth was pulled
where we wrongly parsed a fully specified, relative
timex The day before. Similar cases resulted at the
same time in incorrect Type assignment, like in
Two years after his brain-cancer diagnosis where
we wrongly detect a Date type expression (Two
years after).
Inaccurate event Tense attribute extraction
sometimes caused wrong timex Value normaliza-
tion. One noticeable source of such an error is re-
ported speech, which temporarily changes the dis-
course utterance time and that we do not attempt
to model in our anchor selection procedure. Inter-
estingly, we noticed that even in cases when both
timex-event mapping, and event Tense were cor-
rect,Value normalization was not. For example, in:
Northern Ireland?s World Cup qualifier with Russia
has been postponed until 15:00 GMT Saturday, one
can see that a shallow approach like ours, with no ac-
cess to lexico-semantic knowledge, cannot pick up
the implicit future tense interpretation of the event
verb.
5.2 Event and Event Attribute Extraction
Results for Spanish (Table 2) show that a small set
of rules were sufficient to detect event verbal expres-
sions with high precision. The task was much harder
for English, where morphological derivation is less
often marked and given that we were not performing
any PoS disambiguation.
Our main aim for Task B exercise was evaluating
the performance of semi-automatic methods for verb
classification, and to see how much verb tense in-
formation could help normalizing time expressions.
Class attribute performance is rather poor, even
considering that 7% of false hits in English were due
to a bug in the MULTEXT lexicon causing the fre-
quent form said not to be annotated as REPORTING
event. A high rate of overlapping occurs among
verb classes, causing our attempt to ?lexicalize? the
Class attribute, rather than trying to compute it
61
Recognition Normalization
Relaxed Strict Value Type
System F1 P R F1 P R F1 A F1 A
EN 0.85 0.90 0.80 0.49 0.52 0.46 0.58 0.68 0.69 0.81
BestEN 0.90 0.89 0.91 0.79 0.78 0.80 0.78 0.86 0.80 0.88
ES 0.65 0.86 0.52 0.49 0.65 0.39 0.50 0.77 0.62 0.95
BestES 0.90 0.96 0.84 0.85 0.90 0.80 0.85 0.94 0.87 0.97
Table 1: Performance of Temporal Expression Extraction and Normalization.
Recognition Class Tense
System F1 P R F1 A F1 A
EN 0.65 0.63 0.67 0.43 0.66 0.39 0.60
BestEN 0.81 0.81 0.81 0.72 0.89 0.60 0.73
ES 0.58 0.90 0.42 0.26 0.45 0.49 0.84
BestES 0.89 0.92 0.86 0.85 0.96 0.87 0.98
Table 2: Performance of Event and Event Attribute Extraction.
from context features of verb instances, to be unfea-
sible. Tense attribute performance7 was too low to
draw any conclusion on its impact on the Normal-
ization task. However, for Spanish its accuracy (A
in Figure 2) was higher and yet this did not result in
increased timex Value scores8.
6 Conclusion
The main positive outcome of our participation in
TempEval-3 was that we were able to build a system
with acceptable performance on Task A for Span-
ish, after a relatively quick adaptation from an ex-
isting English system. Recall was the bottleneck
of such an experiment, while precision figures did
not drop significantly, and Normalization accuracy
even increased for Spanish9, suggesting that a devel-
oper may be able to iteratively add language-specific
rules so as to reduce false negatives, without endan-
gering overall system precision.
A major flaw of our finite-state, local parsing ap-
proach is in recognizing event-anchored time ex-
pressions. In order to address this, our timex recog-
nition rules must be further tuned to the TimeML
7Tense figures are unofficial, as we did not manage to ex-
port this attribute value because of a bug in the submitted sys-
tem. However, we were able to reproduce the evaluation on a
fixed system.
8We do not have independent performance figures of the
timex-event mapping, although this mechanism was invariable
across the two languages.
9Due to low F1 for timex entity extraction.
standard in order to fully isolate temporal signals,
and event detection recall must be significantly in-
creased so as to cover event nominalizations. The
detection of event referring expressions according
to the general, context-independent definition in
TimeML is not our main research target, however
we plan to use statistical classification methods to
increase the performance on this task as this is a
prerequisite to achieve a reliable evaluation of our
event-timex mapping heuristic. Event Tense extrac-
tion should be increased with the same purpose.
Acknowledgments
Many thanks to Maud Ehrmann for several useful
discussions on the ontology of temporal entities and
the TimeML standard.
References
Tomaz Erjavec. 2004. MULTEXT -
East Morphosyntactic Specifications.
URL:http://nl.ijs.si/ME/V3/msd/html/.
Silja Huttunen, Roman Yangarber, and Ralph Grishman.
2002. Diversity of Scenarios in Information Extrac-
tion. Proceedings of the Third International Confer-
ence On Language Resources And Evaluation, Las
Palmas.
Matteo Negri. 2007. Dealing with Italian Temporal Ex-
pressions: The ITA-Chronos System. Proceedings of
EVALITA 2007, Workshop held in conjunction with
AI*IA 2007.
62
Piskorski, Jakub. 2007. ExPRESS Extraction Pat-
tern Recognition Engine and Specification Suite. In
In Proceedings of the International Workshop Finite-
State Methods and Natural language Processing 2007
(FSMNLP2007), Postdam, Germany.
Piskorski, Jakub. 2008. CORLEONE Core Linguis-
tic Entity Online Extraction. Technical Report, EN
23393, Joint Research Center of the European Com-
mission, Ispra, Italy.
James Pustejovsky, Jos M. Castao, Robert Ingria, Roser
Sauri, Robert J. Gaizauskas, Andrea Setzer, Graham
Katz, and Dragomir R. Radev. 2003. TimeML: Ro-
bust Specification of Event and Temporal Expressions
in Text. In Mark T. Maybury, editor New Directions in
Question Answering, pages 2834. AAAI Press, 2003.
Pustejovsky, J., P. Hanks, R. Sauri, A. See, R.
Gaizauskas, A. Setzer, D. Radev, B. Sundheim, D.
Day, L. Ferro, et al 2003. The TimeBank corpus.
In Corpus Linguisticsvolume 2003, 40.
Steinberger Ralf, Bruno Pouliquen & Erik van der Goot.
2009. An introduction to the Europe Media Monitor
Family of Applications. In Fredric Gey, Noriko Kando
& Jussi Karlgren (eds.): Information Access in a Mul-
tilingual World - Proceedings of the SIGIR 2009 Work-
shop (SIGIR-CLIR?2009), pp.1-8.
Tanev Hristo, Piskorski Jakub, Atkinson Martin.
2008. Real-Time News Event Extraction for
Global Crisis Monitoring. In Proceedings of NLDB
2008,2008:207218.
Hristo Tanev and Vanni Zavarella. in press. Multilin-
gual Learning and Population of Event Ontologies. A
Case Study for Social Media. In Paul Buitelaar and
Philipp Cimiano editors Towards the Multilingual Se-
mantic Web, Springer.
Naushad UzZaman, Hector Llorens, James F. Allen,
Leon Derczynski, Marc Verhagen, James Pustejovsky.
2012. TempEval-3: Evaluating Events, Time Expres-
sions, and Temporal Relations. arXiv:1206.5333v1.
Verhagen, M., R. Sauri, T. Caselli, and J. Pustejovsky
2010. SemEval-2010 task 13: TempEval-2. In Pro-
ceedings of the 5th International Workshop on Seman-
tic Evaluation, 5762, Association for Computational
Linguistics.
63
Proceedings of the 2nd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis, ACL-HLT 2011, pages 28?36,
24 June, 2011, Portland, Oregon, USA c?2011 Association for Computational Linguistics
Creating Sentiment Dictionaries via Triangulation
Josef Steinberger,
Polina Lenkova, Mohamed Ebrahim,
Maud Ehrmann, Ali Hurriyetoglu,
Mijail Kabadjov, Ralf Steinberger,
Hristo Tanev and Vanni Zavarella
EC Joint Research Centre
21027, Ispra (VA), Italy
Name.Surname@jrc.ec.europa.eu
Silvia Va?zquez
Universitat Pompeu Fabra
Roc Boronat, 138
08018 Barcelona
silvia.vazquez@upf.edu
Abstract
The paper presents a semi-automatic approach
to creating sentiment dictionaries in many lan-
guages. We first produced high-level gold-
standard sentiment dictionaries for two lan-
guages and then translated them automatically
into third languages. Those words that can
be found in both target language word lists
are likely to be useful because their word
senses are likely to be similar to that of the
two source languages. These dictionaries can
be further corrected, extended and improved.
In this paper, we present results that verify
our triangulation hypothesis, by evaluating tri-
angulated lists and comparing them to non-
triangulated machine-translated word lists.
1 Introduction
When developing software applications for senti-
ment analysis or opinion mining, there are basi-
cally two main options: (1) writing rules that assign
sentiment values to text or text parts (e.g. names,
products, product features), typically making use of
dictionaries consisting of sentiment words and their
positive or negative values, and (2) inferring rules
(and sentiment dictionaries), e.g. using machine
learning techniques, from previously annotated doc-
uments such as product reviews annotated with an
overall judgment of the product. While movie or
product reviews for many languages can frequently
be found online, sentiment-annotated data for other
fields are not usually available, or they are almost
exclusively available for English. Sentiment dictio-
naries are also mostly available for English only or,
if they exist for other languages, they are not com-
parable, in the sense that they have been developed
for different purposes, have different sizes, are based
on different definitions of what sentiment or opinion
means.
In this paper, we are addressing the resource bot-
tleneck for sentiment dictionaries, by developing
highly multilingual and comparable sentiment dic-
tionaries having similar sizes and based on a com-
mon specification. The aim is to develop such dic-
tionaries, consisting of typically one or two thou-
sand words, for tens of languages, although in this
paper we only present results for eight languages
(English, Spanish, Arabic, Czech, French, German,
Italian and Russian). The task raises the obvious
question how the human effort of producing this re-
source can be minimized. Simple translation, be it
using standard dictionaries or using machine trans-
lation, is not very efficient as most words have two,
five or ten different possible translations, depending
on context, part-of-speech, etc.
The approach we therefore chose is that of trian-
gulation. We first produced high-level gold-standard
sentiment dictionaries for two languages (English
and Spanish) and then translated them automatically
into third languages, e.g. French. Those words that
can be found in both target language word lists (En
Fr and Es Fr) are likely to be useful because their
word senses are likely to be similar to that of the
two source languages. These word lists can then be
used as they are or better they can be corrected, ex-
tended and improved. In this paper, we present eval-
uation results verifying our triangulation hypothesis,
by evaluating triangulated lists and comparing them
28
to non-triangulated machine-translated word lists.
Two further issues need to be addressed. The
first one concerns morphological inflection. Auto-
matic translation will yield one word form (often,
but not always the base form), which is not suffi-
cient when working with highly inflected languages:
A single English adjective typically has four Spanish
or Italian word forms (two each for gender and for
number) and many Russian word forms (due to gen-
der, number and case distinctions). The target lan-
guage word lists thus need to be expanded to cover
all these morphological variants with minimal effort
and considering the number of different languages
involved without using software, such as morpho-
logical analysers or generators. The second issue
has to do with the subjectivity involved in the human
annotation and evaluation effort. First of all, it is im-
portant that the task is well-defined (this is a chal-
lenge by itself) and, secondly, the inter-annotator
agreement for pairs of human evaluators working on
different languages has to be checked in order to get
an idea of the natural variation involved in such a
highly subjective task.
Our main field of interest is news opinion min-
ing. We would like to answer the question how cer-
tain entities (persons, organisations, event names,
programmes) are discussed in different media over
time, comparing different media sources, media in
different countries, and media written in different
languages. One possible end product would be a
graph showing how the popularity of a certain en-
tity has changed over time across different languages
and countries. News differs significantly from those
text types that are typically analysed in opinion min-
ing work, i.e. product or movie reviews: While a
product review is about a product (e.g. a printer)
and its features (e.g. speed, price or printing qual-
ity), the news is about any possible subject (news
content), which can by itself be perceived to be pos-
itive or negative. Entities mentioned in the news can
have many different roles in the events described.
If the method does not specifically separate positive
or negative news content from positive or negative
opinion about that entity, the sentiment analysis re-
sults will be strongly influenced by the news context.
For instance, the automatically identified sentiment
towards a politician would most likely to be low if
the politician is mentioned in the context of nega-
tive news content such as bombings or disasters. In
our approach, we therefore aim to distinguish news
content from sentiment values, and this distinction
has an impact on the sentiment dictionaries: unlike
in other approaches, words like death, killing, award
or winner are purposefully not included in the sen-
timent dictionaries as they typically represent news
content.
The rest of the paper is structured as follows: the
next section (2) describes related work, especially
in the context of creating sentiment resources. Sec-
tion 3 gives an overview of our approach to dic-
tionary creation, ranging from the automatic learn-
ing of the sentiment vocabulary, the triangulation
process, the expansion of the dictionaries in size
and regarding morphological inflections. Section 4
presents a number of results regarding dictionary
creation using simple translation versus triangula-
tion, morphological expansion and inter-annotator
agreement. Section 5 summarises, concludes and
points to future work.
2 Related Work
Most of the work in obtaining subjectivity lexicons
was done for English. However, there were some
authors who developed methods for the mapping of
subjectivity lexicons to other languages. Kim and
Hovy (2006) use a machine translation system and
subsequently use a subjectivity analysis system that
was developed for English. Mihalcea et al (2007)
propose a method to learn multilingual subjective
language via cross-language projections. They use
the Opinion Finder lexicon (Wilson et al, 2005)
and two bilingual English-Romanian dictionaries to
translate the words in the lexicon. Since word am-
biguity can appear (Opinion Finder does not mark
word senses), they filter as correct translations only
the most frequent words. The problem of translat-
ing multi-word expressions is solved by translating
word-by-word and filtering those translations that
occur at least three times on the Web. Another ap-
proach in obtaining subjectivity lexicons for other
languages than English was explored in Banea et al
(2008b). To this aim, the authors perform three dif-
ferent experiments, with good results. In the first
one, they automatically translate the annotations of
the MPQA corpus and thus obtain subjectivity an-
29
notated sentences in Romanian. In the second ap-
proach, they use the automatically translated entries
in the Opinion Finder lexicon to annotate a set of
sentences in Romanian. In the last experiment, they
reverse the direction of translation and verify the as-
sumption that subjective language can be translated
and thus new subjectivity lexicons can be obtained
for languages with no such resources. Finally, an-
other approach to building lexicons for languages
with scarce resources is presented in Banea et al
(2008a). In this research, the authors apply boot-
strapping to build a subjectivity lexicon for Roma-
nian, starting with a set of seed subjective entries,
using electronic bilingual dictionaries and a training
set of words. They start with a set of 60 words per-
taining to the categories of noun, verb, adjective and
adverb obtained by translating words in the Opin-
ion Finder lexicon. Translations are filtered using a
measure of similarity to the original words, based on
Latent Semantic Analysis (Landauer and Dumais,
1997) scores. Wan (2008) uses co-training to clas-
sify un-annotated Chinese reviews using a corpus
of annotated English reviews. He first translates
the English reviews into Chinese and subsequently
back to English. He then performs co-training using
all generated corpora. Banea et al (2010) translate
the MPQA corpus into five other languages (some
with a similar ethimology, others with a very differ-
ent structure). Subsequently, they expand the fea-
ture space used in a Naive Bayes classifier using the
same data translated to 2 or 3 other languages. Their
conclusion is that expanding the feature space with
data from other languages performs almost as well
as training a classifier for just one language on a
large set of training data.
3 Approach Overview
Our approach to dictionary creation starts with semi-
automatic way of colleting subjective terms in En-
glish and Spanish. These pivot language dictionaries
are then projected to other languages. The 3rd lan-
guage dictionaries are formed by the overlap of the
translations (triangulation). The lists are then man-
ually filtered and expanded, either by other relevant
terms or by their morphological variants, to gain a
wider coverage.
3.1 Gathering Subjective Terms
We started with analysing the available English
dictionaries of subjective terms: General Inquirer
(Stone et al, 1966), WordNet Affect (Strapparava
and Valitutti, 2004), SentiWordNet (Esuli and Se-
bastiani, 2006), MicroWNOp (Cerini et al, 2007).
Additionally, we used the resource of opinion words
with associated polarity from Balahur et al (2009),
which we denote as JRC Tonality Dictionary. The
positive effect of distinguishing two levels of inten-
sity was shown in (Balahur et al, 2010). We fol-
lowed the idea and each of the emloyed resources
was mapped to four categories: positive, negative,
highly positive and highly negative. We also got
inspired by the results reported in that paper and
we selected as the base dictionaries the combination
of MicroWNOp and JRC Tonality Dictionary which
gave the best results. Terms in those two dictionar-
ies were manually filtered and the other dictionar-
ies were used as lists of candidates (their highly fre-
quent terms were judged and the relevant ones were
included in the final English dictionary). Keeping in
mind the application of the dictionaries we removed
at this step terms that are more likely to describe bad
or good news content, rather than a sentiment to-
wards an entity. In addition, we manually collected
English diminishers (e.g. less or approximately), in-
tensifiers (e.g. very or indeed) and invertors (e.g.
not or barely). The English terms were translated to
Spanish and the same filtering was performed. We
extended all English and Spanish lists with the miss-
ing morphological variants of the terms.
3.2 Automatic Learning of Subjective Terms
We decided to expand our subjective term lists by
using automatic term extraction, inspired by (Riloff
and Wiebe, 2003). We look at the problem of ac-
quisition of subjective terms as learning of seman-
tic classes. Since we wanted to do this for two dif-
ferent languages, namely English and Spanish, the
multilingual term extraction algorithm Ontopopulis
(Tanev et al, 2010) was a natural choice.
Ontopopulis performs weakly supervised learning
of semantic dictionaries using distributional similar-
ity. The algorithm takes on its input a small set of
seed terms for each semantic class, which is to be
learnt, and an unannotated text corpus. For example,
30
if we want to learn the semantic class land vehicles,
we can use the seed set - bus, truck, and car. Then
it searches for the terms in the corpus and finds lin-
ear context patterns, which tend to co-occur imme-
diately before or after these terms. Some of the
highest-scored patterns, which Ontopopulis learned
about land vehicles were driver of the X, X was
parked, collided with another X, etc. Finally, the
algorithm searches for these context patterns in the
corpus and finds other terms which tend to fill the
slot of the patterns (designated by X). Considering
the land vehicles example, new terms which the sys-
tem learned were van, lorry, taxi, etc. Ontopop-
ulis is similar to the NOMEN algorithm (Lin et al,
2003). However, Ontopopulis has the advantage to
be language-independent, since it does not use any
form of language-specific processing, nor does it use
any language-specific resources, apart from a stop
word list.
In order to learn new subjective terms for each
of the languages, we passed the collected subjective
terms as an input to Ontopopulis. For English, we
divided the seed set in two classes: class A ? verbs
and class B ? nouns and adjectives. It was necessary
because each of these classes has a different syn-
tactic behaviour. It made sense to do the same for
Spanish, but we did not have enough Spanish speak-
ers available to undertake this task, therefore we put
together all the subjective Spanish words - verbs, ad-
jectives and nouns in one class. We ran Ontopopulis
for each of the three classes - the class of subjective
Spanish words and the English classes A and B. The
top scored 200 new learnt terms were taken for each
class and manually reviewed.
3.3 Triangulation and Expansion
After polishing the pivot language dictionaries we
projected them to other languages. The dictionaries
were translated by Google translator because of its
broad coverage of languages. The overlapping terms
between English and Spanish translations formed
the basis for further manual efforts. In some cases
there were overlapping terms in English and Span-
ish translations but they differed in intensity. There
was the same term translated from an English posi-
tive term and from a Spanish very positive term. In
these cases the term was assigned to the positive cat-
egory. However, more problematic cases arose when
the same 3rd language term was assigned to more
than one category. There were also cases with dif-
ferent polarity. We had to review them manually.
However, there were still lots of relevant terms in the
translated lists which were not translated from the
other language. These complement terms are a good
basis for extending the coverage of the dictionaries,
however, they need to be reviewed manually. Even if
we tried to include in the pivot lists all morpholog-
ical variants, in the triangulation output there were
only a few variants, mainly in the case of highly in-
flected languages. To deal with morphology we in-
troduced wild cards at the end of the term stem (*
stands for whatever ending and for whatever char-
acter). This step had to be performed carefully be-
cause some noise could be introduced. See the Re-
sults section for examples. Although this step was
performed by a human, we checked the most fre-
quent terms afterwards to avoid irrelavant frequent
terms.
4 Results
4.1 Pivot dictionaries
We gathered and filtered English sentiment terms
from the available corpora (see Section 3.1). The
dictionaries were then translated to Spanish (by
Google translator) and filtered afterwards. By ap-
plying automatic term extraction, we enriched the
sets of terms by 54 for English and 85 for Spanish,
after evaluating the top 200 candidates suggested by
the Ontopolulis tool for each language. The results
are encouraging, despite the relevance of the terms
(27% for English and 42.5% for Spanish where
some missing morphological variants were discov-
ered) does not seem to be very high, considering the
fact that we excluded the terms already contained
in the pivot lists. If we took them into account, the
precision would be much better. The initial step re-
sulted in obtaining high quality pivot sentiment dic-
tionaries for English and Spanish. Their statistics
are in table 1. We gathered more English terms than
Spanish (2.4k compared to 1.7k). The reason for
that is that some translations from English to Span-
ish have been filtered. Another observation is that
there is approximately the same number of negative
terms as positive ones, however, much more highly
negative than highly positive terms. Although the
31
Language English Spanish
HN 554 466
N 782 550
P 772 503
HP 171 119
INT 78 62
DIM 31 27
INV 15 10
TOTAL 2.403 1.737
Table 1: The size of the pilot dictionaries. HN=highly
negative terms, N=negative, P=positive, HP=highly posi-
tive, INV=invertors, DIM=diminishers, INV=invertors.
frequency analysis we carried out later showed that
even if there are fewer highly positive terms, they are
more frequent than the highly negative ones, which
results in almost uniform distribution.
4.2 Triangulation and Expansion
After running triangulation to other languages the
resulted terms were judged for relevance. Native
speakers could suggest to change term?s category
(e.g. negative to highly negative) or to remove it.
There were several reasons why the terms could
have been marked as ?non-sentiment?. For instance,
the term could tend to describe rather negative news
content than negative sentiment towards an entity
(e.g. dead, quake). In other cases the terms were
too ambiguous in a particular language. Examples
from English are: like or right.
Table 2 shows the quality of the triangulated dic-
tionaries. In all cases except for Italian we had only
one annotator assessing the quality. We can see that
the terms were correct in around 90% cases, how-
ever, it was a little bit worse in the case of Russian
in which the annotator suggested to change category
very often.
Terms translated from English but not from Span-
ish are less reliable but, if reviewed manually, the
dictionaries can be expanded significantly. Table 3
gives the statistics concerning these judgments. We
can see that their correctness is much lower than in
the case of the triangulated terms - the best in Italian
(54.4%) and the worst in Czech (30.7%). Of course,
the translation performance affects the results here.
However, this step extended the dictionaries by ap-
proximately 50%.
When considering terms out of context, the most
common translation error occurs when the original
word has several meanings. For instance, the En-
glish word nobility refers to the social class of no-
bles, as well as to the quality of being morally good.
In the news context we find this word mostly in the
second meaning. However, in the Russian triangu-
lated list we have found dvoryanstvo , which refers
to a social class in Russian. Likewise, we need to
keep in mind that a translation of a monosemantic
word might result polysemantic in the target lan-
guage, thereby leading to confusion. For example,
the Italian translation of the English word champion
campione is more frequently used in Italian news
context in a different meaning - sample, therefore
we must delete it from our sentiment words list for
Italian. Another difficulty we might encounter es-
pecially when dealing with inflectional languages is
the fact that a translation of a certain word might be
homographic with another word form in the target
language. Consider the English negative word ban-
dit and its Italian translation bandito, which is more
frequently used as a form of the verb bandire (to an-
nounce) in the news context. Also each annotator
had different point of view on classifying the bor-
derline cases (e.g. support, agreement or difficult).
Two main reasons are offered to explain the low
performance in Arabic. On the one hand, it seems
that some Google translation errors will be repeated
in different languages if the translated words have
the same etymological root. For example both words
? the English fresh and the Spanish fresca ? are
translated to the Arabic as YK
Yg. meaning new. The
Other reason is a more subtle one and is related to
the fact that Arabic words are not vocalized and to
the way an annotator perceive the meaning of a given
word in isolation. To illustrate this point, consider
the Arabic word ? J. ?A
	
J ?? @ , which could be used
as an adjective, meaning appropriate, or as a noun,
meaning The occasion. It appears that the annotator
would intuitively perceive the word in isolation as a
noun and not as an adjective, which leads to disre-
garding the evaluative aspects of a given word.
We tried to include in the pivot dictionaries all
morphological variants of the terms. However, in
highly inflected languages there are much more vari-
ants than those translated from English or Spanish.
32
We manually introduced wild cards to capture the
variants. We had to be attentive when compiling
wild cards for languages with a rich inflectional sys-
tem, as we might easily get undesirable words in the
output. To illustrate this, consider the third person
plural of the Italian negative word perdere (to lose)
perdono, which is also homographic with the word
meaning forgiveness in English. Naturally, it could
happen that the wildcard captures a non-sentiment
term or even a term with a different polarity. For in-
stance, the pattern care% would capture either care,
careful, carefully, but also career or careless. That
is way we perform the last manual checking after
matching the lists expanded by wildcards against a
large number of texts. The annotators were unable
to check all the variants, but only the most frequent
terms, which resulted in reviewing 70-80% of the
term mentions. This step has been performed for
only English, Czech and Russian so far. Table 5
gives the statistics. By introducing the wildcards,
the number of distinct terms grew up significantly
- 12x for Czech, 15x for Russian and 4x for En-
glish. One reason why it went up also for English
is that we captured compounds like: well-arranged,
well-balanced, well-behaved, well-chosen by a sin-
gle pattern. Another reason is that a single pat-
tern can capture different POSs: beaut% can cap-
ture beauty, beautiful, beautifully or beautify. Not
all of those words were present in the pivot dictio-
naries. For dangerous cases like care% above we
had to rather list all possible variants than using a
wildcard. This is also the reason why the number
of patterns is not much lower than the number of
initial terms. Even if this task was done manually,
some noise was added into the dictionaries (92-94%
of checked terms were correct). For example, highly
positive pattern hero% was introduced by an anno-
tator for capturing hero, heroes, heroic, heroical or
heroism. If not checked afterwards heroin would
score highly positively in the sentiment system. An-
other example is taken from Russian: word meaning
to steal ukra% - might generate Ukraine as one most
frequent negative word in Russian.
4.3 How subjective is the annotation?
Sentiment annotation is a very subjective task. In ad-
dition, annotators had to judge single terms without
any context: they had to think about all the senses of
Metric Percent Agreement Kappa
HN 0.909 0.465
N 0.796 0.368
P 0.714 0.281
HP 0.846 0
N+HN 0.829 0.396
P+HP 0.728 0.280
ALL 0.766 0.318
Table 6: Inter-annotator agreement on checking the trian-
gulated list. In the case of HP all terms were annotated as
correct by one of the annotators resulting in Kappa=0.
Metric Percent Agreement Kappa
HN 0.804 0.523
N 0.765 0.545
P 0.686 0.405
HP 0.855 0.669
N+HN 0.784 0.553
P+HP 0.783 0.559
ALL 0.826 0.614
Table 7: Inter-annotator agreement on checking the can-
didates. In ALL diminishers, intensifiers and invertors
are included as well.
the term. Only if the main sense was subjective they
agreed to leave it in the dictionary. Another sub-
jectivity level was given by concentrating on distin-
guishing news content and news sentiment. Defining
the line between negative and highly negative terms,
and similarly with positive, is also subjective. In the
case of Italian we compared judgments of two anno-
tators. The figures of inter-annotator agreement of
annotating the triangulated terms are in table 6 and
the complement terms in table 7. Based on the per-
cent agreement the annotators agree a little bit less
on the triangulated terms (76.6%) compared to the
complement terms (82.6%). However, if we look at
Kappa figures, the difference is clear. Many terms
translated only from English were clearly wrong
which led to a higher agreement between the annota-
tors (0.318 compared to 0.614). When looking at the
difference between positive and negative terms, we
can see that there was higher agreement on the neg-
ative triangulated terms then on the positive ones.
33
Language Triangulated Correct Removed Changed category
Arabic 926 606 (65.5%) 316 (34.1%) 4 (0.4%)
Czech 908 809 (89.1%) 68 (7.5%) 31 (3.4%)
French 1.085 956 (88.1%) 120 (11.1%) 9 (0.8%)
German 1.053 982 (93.3%) 50 (4.7%) 21 (2.0%)
Italian 1.032 918 (89.0%) 36 (3.5%) 78 (7.5%)
Russian 966 816 (84.5%) 49 (5.1%) 101 (10.4%)
Table 2: The size and quality of the triangulated dictionaries. Triangulated=No. of terms coming directly from triangu-
lation, Correct=terms annotated as correct, Removed=terms not relevant to sentiment analysis, Change category=terms
in wrong category (e.g., positive from triangulation, but annotator changed the category to highly positive).
Language Terms Correct Removed Changed category
Czech 1.092 335 (30.7%) 675 (61.8%) 82 (7.5%)
French 1.226 617 (50.3%) 568 (46.3%) 41 (3.4%)
German 1.182 548 (46.4%) 610 (51.6%) 24 (2.0%)
Italian 1.069 582 (54.4%) 388 (36.3%) 99 (9.3%)
Russian 1.126 572 (50.8%) 457 (40.6%) 97 (8.6%)
Table 3: The size and quality of the candidate terms (translated from English but not from Spanish). Terms=No. of
terms translated from English but not from Spanish, Correct=terms annotated as correct, Removed=terms not relevant
to sentiment analysis, Change category=terms in wrong category (e.g., positive in the original list, but annotator
changed the category to highly positive).
Language Terms Correct Removed Changed category
Czech 2.000 1.144 (57.2%) 743 (37.2%) 113 (5.6%)
French 2.311 1.573 (68.1%) 688 (29.8%) 50 (2.1%)
German 2.235 1.530 (68.5%) 660 (29.5%) 45 (2.0%)
Italian 2.101 1.500 (71.4%) 424 (20.2%) 177 (8.4%)
Russian 2.092 1.388 (66.3%) 506 (24.2%) 198 (9.5%)
Table 4: The size and quality of the translated terms from English. Terms=No. of (distinct) terms translated from En-
glish, Correct=terms annotated as correct, Removed=terms not relevant to sentiment analysis, Change category=terms
in wrong category (e.g., positive in the original list, but annotator changed the category to highly positive).
Language Initial terms Patterns Matched terms
Count Correct Checked
Czech 1.257 1.063 15.604 93.0% 74.4%
English 2.403 2.081 10.558 93.8% 81.1%
Russian 1.586 1.347 33.183 92.2% 71.0%
Table 5: Statistics of introducing wild cards and its evaluation. Initial terms=checked triangulated terms extended by
relevant translated terms from English, Patterns=number of patterns after introducing wildcards, Matched terms=terms
matched in the large corpus - their count and correctness + checked=how many mentions were checked (based on the
fact that the most frequent terms were annotated).
34
4.4 Triangulation vs. Translation
Table 4 present the results of simple translation from
English (summed up numbers from tables 2 and 3).
We can directly compare it to table 2 where only
results of triangulated terms are reported. The per-
formance of triangulation is significantly better than
the performance of translation in all languages. The
highest difference was in Czech (89.1% and 57.2%)
and the lowest was in Italian (89.0% and 71.4%).
As a task-based evaluation we used the triangu-
lated/translated dictionaries in the system analysing
news sentiment expressed towards entities. The sys-
tem analyses a fixed word window around entity
mentions. Subjective terms are summed up and the
resulting polarity is attached to the entity. Highly
negative terms score twice more than negative, di-
minishers lower and intensifiers lift up the score. In-
vertors invert the polarity but for instance inverted
highly positive terms score as only negative pre-
venting, for instance, not great to score as worst.
The system searches for the invertor only two words
around the subjective term.
We ran the system on 300 German sentences
taken from news gathered by the Europe Media
Monitor (EMM)1. In all these cases the system at-
tached a polarity to an entity mention. We ran it with
three different dictionaries - translated terms from
English, raw triangulated terms (without the man-
ual checking) and the checked triangulated terms.
This pilot experiment revealed the difference in per-
formance on this task. When translated terms were
used there were only 41.6% contexts with correct
polarity assigned by the system, with raw triangu-
lated terms 56.5%, and with checked triangulated
terms 63.4%. However, the number does not contain
neutral cases that would increase the overall perfor-
mance. There are lots of reasons why it goes wrong
here: the entity may not be the target of the sub-
jective term (we do not use parser because of deal-
ing with many languages and large amounts of news
texts), the system can miss or apply wrongly an in-
vertor, the subjective term is used in different sense,
and irony is hard to detect.
1http://emm.newsbrief.eu/overview.html
4.5 State of progress
We finished all the steps for English, Czech and Rus-
sian. French, German, Italian and Spanish dictio-
naries miss only the introduction of wild cards. In
Arabic we have checked only the triangulated terms.
For other 7 languages (Bulgarian, Dutch, Hungarian,
Polish, Portuguese, Slovak and Turkish) we have
only projected the terms by triangulation. However,
we have capabilities to finish all the steps also for
Bulgarian, Dutch, Slovak and Turkish. We haven?t
investigated using more than two pivot languages for
triangulation. It would probably results in more ac-
curate but shortened dictionaires.
5 Conclusions
We presented our semi-automatic approach and cur-
rent state of work of producing multilingual senti-
ment dictionaries suitable of assessing the sentiment
in news expressed towards an entity. The triangula-
tion approach works significantly better than simple
translation but additional manual effort can improve
it a lot in both recall and precision. We believe that
we can predict the sentiment expressed towards an
entity in a given time period based on large amounts
of data we gather in many languages even if the per-
case performance of the sentiment system as on a
moderate level. Now we are working on improving
the dictionaries in all the discussed languages. We
also run experiments to evaluate the system on vari-
ous languages.
Acknowledgments
We thank Alexandra Balahur for her collaboration
and useful comments. This research was partly sup-
ported by a IULA-Universitat Pompeu Fabra grant.
35
References
Alexandra Balahur, Ralf Steinberger, Erik van der Goot,
and Bruno Pouliquen. 2009. Opinion mining from
newspaper quotations. In Proceedings of the Work-
shop on Intelligent Analysis and Processing of Web
News Content at the IEEE / WIC / ACM International
Conferences on Web Intelligence and Intelligent Agent
Technology (WI-IAT).
A. Balahur, R. Steinberger, M. Kabadjov, V. Zavarella,
E. van der Goot, M. Halkia, B. Pouliquen, and
J. Belyaeva. 2010. Sentiment analysis in the news.
In Proceedings of LREC?10.
C. Banea, R. Mihalcea, and J. Wiebe. 2008a. A boot-
strapping method for building subjectivity lexicons for
languages with scarce resources. In Proceedings of
LREC.
C. Banea, R. Mihalcea, J. Wiebe, and S. Hassan.
2008b. Multilingual subjectivity analysis using ma-
chine translation. In Proceedings of EMNLP.
C. Banea, R. Mihalcea, and J. Wiebe. 2010. Multilingual
subjectivity: Are more languages better? In Proceed-
ings of COLING.
S. Cerini, V. Compagnoni, A. Demontis, M. Formentelli,
and G. Gandini. 2007. Micro-WNOp: A gold stan-
dard for the evaluation of automatically compiled lex-
ical resources for opinion mining. In Andrea Sanso`,
editor, Language resources and linguistic theory: Ty-
pology, second language acquisition, English linguis-
tics. Franco Angeli, Milano, IT.
A. Esuli and F. Sebastiani. 2006. SentiWordNet: A pub-
licly available resource for opinion mining. In Pro-
ceeding of the 6th International Conference on Lan-
guage Resources and Evaluation, Italy, May.
S.-M. Kim and E. Hovy. 2006. Extracting opinions,
opinion holders, and topics expressed in online news
media text. In Proceedings of the ACL Workshop on
Sentiment and Subjectivity in Text.
T. Landauer and S. Dumais. 1997. A solution to plato?s
problem: The latent semantic analysis theory of the ac-
quisition, induction, and representation of knowledge.
Psychological Review, 104:211?240.
W. Lin, R. Yangarber, and R. Grishman. 2003. Boot-
strapped learning of semantic classes from positive
and negative examples. In Proceedings of the ICML-
2003 Workshop on The Continuum from Labeled to
Unlabeled Data, Washington DC.
R. Mihalcea, C. Banea, and J. Wiebe. 2007. Learning
multilingual subjective language via cross-lingual pro-
jections. In Proceedings of ACL.
E. Riloff and J. Wiebe. 2003. Learning extraction pat-
terns for subjective expressions. In Proceeding of
the Conference on Empirical Methods in Natural Lan-
guage Processing.
P.J. Stone, D.C. Dumphy, M.S. Smith, and D.M. Ogilvie.
1966. The general inquirer: a computer approach to
content analysis. M.I.T. studies in comparative poli-
tics, M.I.T. Press, Cambridge, MA.
C. Strapparava and A. Valitutti. 2004. WordNet-Affect:
an affective extension of wordnet. In Proceeding of the
4th International Conference on Language Resources
and Evaluation, pages 1083?1086, Lisbon, Portugal,
May.
H. Tanev, V. Zavarella, J. Linge, M. Kabadjov, J. Pisko-
rski, M. Atkinson, and R.Steinberger. 2010. Exploit-
ing machine learning techniques to build an event ex-
traction system for portuguese and spanish. Lingua-
matica: Revista para o Processamento Automatico das
Linguas Ibericas.
X. Wan. 2008. Co-training for cross-lingual sentiment
classification. In Proceedings of the Joint Confer-
ence of the 47th Annual Meeting of the Association
for Computational Linguistics and 4th International
Joint Conference on Natural Language Processing of
the Asian Federation of Natural Language Processing.
T. Wilson, J. Wiebe, and P. Hoffman. 2005. Recognizing
contextual polarity in phrase-level sentiment analysis.
In Proceedings of HLT-EMNLP.
36
