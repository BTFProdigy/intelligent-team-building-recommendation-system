CMDMC: A Diachronic Digital Museum of Chinese Mandarin
Hou Min1, Zou Yu1, Teng Yonglin1, He Wei
Wang Yan
1
1,2, Liu Jun1,2, and Wu Jiyuan1,2
1
Monitoring and Research Center at Communication University of China
Broadcast Media Language Branch, National Language Resources
2
Beijing 100024, China
School of Literature, Communication University of China
{houmin, zouiy, tengyonglin, hewei}@cuc.edu.cn?
forget1812@sina.com, {aaa_0119, wjy__00}@163.com
Abstract
Modern Chinese Mandarin has gone 
through near a hundred years, it is very 
important to store its representative 
sample in digital form permanently. In 
this paper, we propose a Chinese Man-
darin Digital Multi-modal Corpus 
(CMDMC), which is a digital speech 
museum with diachronic, opened, cross-
media and sharable features. It has over 
3460 hours video and audio files with 
metadata tagging. The materials, which 
were generated by the authoritative 
speakers (e.g. announcers at TV or radio 
station) with normality, are required 
samples if we can get them. Based on 
this resource, we also intend to analyze 
the syntactic correlations of prosodic 
phrase in broadcasting news speech, and 
compare the phonetic and prosodic fea-
tures in movie dialogues among several 
same-name movies in different histori-
cal eras.
1 Introduction
Modern Chinese Mandarin has gone through 
near a hundred years. As language changes as 
society develops, Mandarin must be periodically 
marked with the different features of different 
historical eras. It is very important to design and 
construct a Chinese Mandarin Digital Multi-
modal Corpus (CMDMC), and store its repre-
sentative sample in digital form permanently.
It?s international trend to establish large-scale 
natural language corpus, and many countries 
pay more attention to research and preserve 
their national language. For instance, the Lin-
guistic Data Consortium (LDC) is an open con-
sortium of universities, companies and govern-
ment research laboratories. It creates, collects 
and distributes speech and text databases, lex-
icons, and other resources for research and de-
velopment purposes1. Since its foundation, the 
LDC has delivered data to 197 member institu-
tions and 458 non-member institutions. Moreo-
ver, European Language Resources Association 
(ELRA)2
The paper is organized as follows: Section 2 
describes the resources and data processing of 
our CMDMC. The experiment and evaluation is 
designed and carried out in section 3. Section 4 
is dedicated to analyze the syntactic correlations 
of prosodic phrase in broadcast news speech on 
CNR (China National Radio), and compare the 
is the driving force to make available 
the language resources for language engineering 
and to evaluate language engineering technolo-
gies. In order to achieve this goal, ELRA is ac-
tive in identification, distribution, collection, 
validation, standardization, improvement, in 
promoting the production of language resources, 
in supporting the infrastructure to perform eval-
uation campaigns and in developing a scientific 
field of language resources and evaluation. In
this paper, we intend to establish the CMDMC 
with the goal of showing the history of the de-
velopment of Chinese Mandarin, and represen-
tation the real character in different historical 
eras.
1 The Linguistic Data Consortium (LDC),
http://www.ldc.upenn.edu.
2 European Language Resources Association (EL-
RA), http://www.elra.info/.
phonetic and prosodic features in movie dialo-
gues. Finally, some conclusions and outlines of 
our future work are given in section 5.
2 General Description of CMDMC
In order to show the history of the development 
of Chinese Mandarin, and representation the 
real character in different historical periods, the 
CMDMC, which is a dynamic miniature model 
(or speech museum) with diachronic, opened, 
cross-media and sharable features, is designed
and constructed by Broadcast Media Language 
Branch of National Language Resources 
Monitor & Research Center at Communication 
University of China.
In China, announcers in Radio & TV stations, 
as well as movie or stage actors, are the authori-
ty of the national language standardization. 
Therefore, the speech in radio, television and 
movie can be taken as the paradigm and repre-
sentative of Mandarin. They can reflect the 
phonetic situation of that era. All of these are 
the source of the sample data for CMDMC.
2.1 Description of Resources
In order to fully demonstrate the development 
of Chinese Mandarin by the past 100 years, we 
try to collect all the video or audio materials in 
different periods. Therefore, a state-of-the-art 
classification is defined based on the corpora 
that we got.
Language styles: According to characteristic 
speaking styles of different media, there are 
three categories was defined, such as broadcast 
media language, movie or drama dialogue, and 
the dialogue in folk art (e.g. xiangsheng, ping-
shu etc.) and so on. To sum up, the three speak-
ing styles accounted for about 64.9%, 27.2%
and 7.9% of total corpora, respectively.
Mediums: The materials can be divided into 
audio, video, text and image/picture. The audio 
or video files are the main materials in our cor-
pus, and the aligned texts are transcribed based 
on the audio or video. The documents of image 
are subsidiary corpora.
Historical eras: Based on the characteristics 
of social and language changes, we also define 
six historical stages of Chinese Mandarin: 1) 
Before1949 (or 1919-1949), it is a theoretical
stage for corpora collection. In fact, the earliest 
speech materials, which we can collect, is re-
leased in 1932; 2) 1949-1965; 3) 1966-1977; 4) 
1978-1989; 5) 1990-1999; 6) 2000 to today.
Table 1 shows the distribution of detailed data
in different eras.
Eras
Broadcast 
media
(hours)
Movie 
/drama
(hours)
Folk 
art
(hours)
Percent
of total
(%)
1932-49 39.3 1.1 
1949-65 5.2 191.4 20 6.2 
1966-77 17.5 93.0 3.2 
1978-89 52.4 145.9 75.5 7.9 
1990-99 43.5 137.5 11.5 5.6 
2000-- 2131.5 337.0 167.1 76.0 
Total 2250.1 944.1 274.1
Table 1: The distribution of video and audio 
materials in different eras.
2.2 Data Processing
The data processing includes metadata tagging, 
text transcription and aligning, phonetic and 
prosodic annotation, POS and syntactic tagging
and so on.
As for labeling prosodic phrase boundaries, 
we strictly dependent on the prosodic criteria 
and perception by using the wave files and their 
transcriptions, which use many prosodic fea-
tures such as F0 contour, energy contour etc. At 
the same time, some spoken phenomena are 
considered.
3 Experiment and Evaluation
Firstly, in order to investigate the correlations 
between prosody and syntax, about 13 hours 
speech materials were selected to segment and 
label, including break index, stress index and 
summary of emotional tendentiousness etc.
Before the real annotation, six transcribers have 
been trained in accordance with the prosodic 
labeling conventions, until a high consistency of 
prosodic annotation can be carried out.
According to above experiment and annota-
tion, the number of occurrences of the various 
boundaries was calculated in table 2.
Secondly, we also designed a perception ex-
periment to determine phonetic diversification
for elimination as much as possible the subjec-
tivity which could be caused by the different 
personal intuition of language. Ten people at-
tended the perception experiment of this study:
3 men and 7 women. The average age is 25 
years. Nearly all of them were graduates major-
ing in linguistics. During the experiment, the 
participants were asked to discriminate 12 para-
graphs of random materials and judge the natu-
ralness, pitch, and speech rate of the sentences 
produced in each paragraph. These 12 para-
graphs consisted of 4 from 21 paragraphs of the 
1995 version, 4 from 21 paragraphs of the 1975 
version and 4 from modern materials. 
Boundaries
Types Index Marker Frequency
PW 1 /1, /1+ 55237
PP 2 /2 28867
C-PP 2 /2* 5976
IP 3 /3 7147
IG 4 /4 2781
MEC 5 /5 1770
Table 2: Distribution of all boundaries. The PW, 
PP, C-PP, IP, IG and MEC are the abbreviation of 
prosodic word, normal prosodic phrase, complex 
prosodic phrase, intonational phrase, intonational 
group and meaning expression cluster respectively.
In the perceptive procedure, we disordered all 
these materials for experiment, and three choic-
es were given to these ten people: 1) natural, in 
conformity with the standard of modern Manda-
rin; 2) fairly natural, close to the standard of 
modern Mandarin; 3) unnatural, a little stagy. 
Every paragraph was released twice with an 
interval of 10 seconds. After one hour of conti-
nuous work, a 10-minute break was given.
Only the results with at least a 90% agree-
ment rate were considered for analysis. 
4 Related Works
Based on this resource, we intend to analyze the 
syntactic correlations of prosodic phrase in 
broadcasting news speech on CNR, and com-
pare the phonetic and prosodic features in 
movie dialogues among several same-name 
movies in different historical eras.
4.1 Correlation between Syntax & Prosody
In English, there is a strong correlation between 
prosodic phrase boundaries and syntactic phrase 
boundaries (Price et al 1991). That is to say, 
prosodic phrase boundaries can play an impor-
tant role in understanding utterance as punctua-
tion marks do in written language. An investiga-
tion propose that boundary strength according to 
the measure, which the boundary strength is 
applied to syntactic structures and the phrase 
structure is viewed as an immediate constituen-
cy tree exclusively, corresponds much more 
closely to empirical prosodic boundary strength 
than does syntactic boundary strength according 
to a standard measure (Abney, 1992). In Greek, 
some study indicated that prosodic phrasing has 
a 95% identification rate, and a major effect on 
final tonal boundaries (Botinis et al 2004).
In Chinese, some researchers also proposed a 
statistical model to predict prosodic words from 
lexical words. In their model, both length of the 
word and the tagging from POS are two essen-
tial features to predict prosodic words, and the 
results showed approximately 90% of prediction 
for prosodic words (Chen at el. 2004).
What the correlation between syntax and 
prosody is in Chinese broadcasting news speech?
In order to investigate the syntactic correlations 
of prosodic phrase in real read speech on radio, 
we chose the representative speech materials 
from Xinwen he Baozhi Zhaiyao (News and 
Newspapers Summary) from CMDMC, which is 
a very famous broadcast news program of CNR.
This news program contains more syntactic, 
semantic and prosodic information, speaking
styles and high quality voice in real context. 
Therefore, 908 programs, which contain 454 
hours speech data from January 2006 to June 
2008, were selected for pre-processing. After 
the pre-processing step, we selected two fe-
male?s 13 hours speech materials (one female 
announcer?s material forms the main data, and 
another one?s is supplemented for comparable 
data) as a core database, which segmentation, 
transcription and prosodic annotation (including 
break index, stress index and summary of emo-
tional tendentiousness etc) was made by six 
transcribers. 
According to the characteristic of broadcast-
ing news speech, a new prosodic hierarchical 
structure (Zou et al 2009) and two different 
types of prosodic phrase (i.e. the normal prosod-
ic phrase and the complex prosodic phrase) 
boundaries were defined and used in our data 
labeling.
Top pitch value Bottom pitch value
Categories Location N SD Mean N SD Mean
PW Left 3478 3.917 16.1 3253 4.761 8.5
Right 3701 4.894 14.7 3165 5.457 9.9
PP Left 1741 3.891 14.7 1718 4.302 6.2
Right 627 3.481 16.5 492 5.077 9.3
C-PP Left 314 4.085 13.5 317 4.135 4.8
Right 361 3.616 17.9 285 5.092 10.0
IP Left 536 4.817 12.9 456 5.575 3.9
Right 531 3.019 18.8 473 3.720 13.8
IG Left 211 4.363 11.4 203 6.055 4.7
Right 229 2.377 19.4 185 2.927 15.0
MEC Left 104 4.238 8.1 95 4.937 2.6
Right 22 2.178 18.7 12 2.893 16.2
Table 3: The distribution of pitch on different boundaries. The phonetic acoustic data of each 
syllable was extracted by Praat script, and the foundational frequency was normalized by semi-
tones, the normalization formula is ST=12*log (F0/Fref)/log2 (the female?s reference frequency 
is 100Hz). (?top? is the mean of the highest pitch value at the first tone and the fourth tone; 
?bottom? is the mean of the lowest pitch value at the third tone and the fourth tone; ?N? refers 
the number of samples; ?SD? is the abbreviation of standard deviation)
In the further step, we selected 100 minutes 
speech materials from core annotated data, and 
investigated its features of pitch and duration at 
boundary (Zou et al 2010). The detailed data 
are shown in table 3 and 4 respectively.
Boundaries
Types Marker N Mean SD
PW /1 or/1+ 118 65.2 61.714
PP /2 659 97.6 84.140
C-PP /2* 193 108.7 82.483
IP /3 877 343.2 138.906
IG /4 375 699.2 254.287
MEC /5 31 771.0 208.580
Table 4: The mean of silent pause duration at
boundaries.
There are two ways of representation to pitch 
feature at prosodic boundary: Firstly, the pitch 
contour is un-continuity; secondly, the pitch 
resetting of the declination contour (de Pijper et 
al 1994). According to Table 3, we can find that 
there is a few resetting of bottom pitch value at 
PW boundary, that is to say, the bottom of the
PW boundary right is 1.4 semitones higher than 
that of its left. At other boundaries, the bottom 
pitch values at right side are much higher than 
that at left side, for instance, there is 3.1, 5.2, 
9.9, 11.3 and 13.6 semitones resetting from PP 
to MEC boundary successively. Especially, at 
the IP boundary its resetting has about two 
times than that of C-PP boundary. This shows 
that there are very obvious prosodic feature at 
various boundaries in broadcasting news speech.
Generally, we know that 90ms is the floor of 
threshold for perceiving the silent pause. From 
Table 4, the mean of silent pause duration from 
long to short followed by MEC > IG > IP > C-
PP > PP > PW. Except there is no perceived 
silent pause at PW boundary, the other bounda-
ries have obvious silent pause that can be per-
ceived. The length of silent pause at PP and C-
PP are 97.6ms and 108.7ms respectively, and 
the length at IP has over three times longer than 
that at C-PP. According to this, we propose that 
the PP and C-PP lie in the same position at the 
prosodic hierarchical structure, and the C-PP is 
a special prosodic phrase.
From our core data we got 6728 C-PPs. Ac-
cording to the C-PP that contains the number of 
PW, we divided them into four categories, such 
as three-PW, four-PW, five-PW and six-PW. 
The distribution of them is shown in Table 5.
After preliminary analysis we found that the 
C-PP, which contains three PWs, has a simple 
syntactic structure although it is absolute major-
ity in the number, and that is compose of four 
PWs should be done for correlations of prosody 
and syntax. There are about 6 types of prosodic 
structure if the C-PP contains four PWs. The 
detail data of this type C-PP followed in table 6.
From the data, we know that the fourth type, 
which is (A+B) +(C+D), is the most, and that is 
composed by (A+B) +C+D is the least in all of 
the six types. Although there are just six types 
of prosodic structure that can be found, there are 
more than 985 syntactic categories in this 1835 
C-PPs. There are 23 types which occur more 
than 10 times, and most of them occur only one 
time. To some extent, it can explain that the 
syntactic structure is more complex than the 
prosodic one.
An example of prosodic and syntactic struc-
tures in the utterance, which is ou1 yang2 yu3 
hang2 yi4 zhi1 shou3 jin3 jin0 bao4 zhu4 lou2 
ti1 de0 lan2 gan1 (Ouyang Yuhang held fast to 
the staircase railing with one hand), is given in 
figure 1. The left side of figure is the prosodic 
structure, and the syntactic one lies at the right 
side.
In figure 1, there is a little difference of jin3 
jin0 bao4 zhu4 lou2 ti1 de0 lan2 gan1 (???
??????) between its prosodic structure 
?A+(B+C+D)? and its syntactic structure ?[VP 
[VP jin3jin0/adv bao4zhu4/v] [NP [AP 
lou2ti1/n de0/u] [NP lan2gan1/n]]]?, but the 
differences between its prosodic and syntactic 
structure are obvious because the jin3 jin0 is 
stressed in speech for semantic expression.
Categories Example Num.
Three-PW ??/1+ ??/1 ??/2* 4433
Four-PW ???/1+ ??/1 ??/1 ??/2* 1835
Five-PW ??/1 ??/2 ??/1 ??/1 ??/2* 414
Six-PW ?/1+ ??/1 ??/2 ??/1 ??/2 ??/2* 46
Total 6728
Table 5: The distribution of four kinds of C-PP
Types Example Num. Percent (%)
A+(B+C)+D ?/1+ ??/1 ??/2 ??/2* 441 24.03
A+(B+C+D) ??/1+ ?/1 ?/1 ???/2* 495 26.98
A+B+(C+D) ??/1+ ??/1+ ??/1 ??/2* 97 5.29
(A+B)+(C+D) ?/1 ??/2 ??/1 ??/2* 529 28.83
(A+B+C)+D ??/1 ??/1 ??/2 ??/2* 259 14.11
(A+B)+C+D ?/1 ??/2 ??/2 ??/2* 14 0.76
Total 1835 100
Table 6: The distribution of prosodic type in C-PP of four-PW
Figure 1: An example of (a) prosodic structure vs. (b) syntactic structure in an utterance: ou1 yang2 
yu3 hang2 yi4 zhi1 shou3 jin3 jin0 bao4 zhu4 lou2 ti1 de0 lan2 gan1 (Ouyang Yuhang held fast to 
the staircase railing with one hand).
Figure 2: The pitch contour of the same utterance.
Figure 2 shows the pitch contour of the same 
utterance. In this utterance, there is a nesting 
structure at jin3 jin0 bao4 zhu4 lou2 ti1 de0 
lan2 gan1 (held fast to the staircase railing)
based on the length of perceived silent pause. 
Furthermore, the pitch declination trend within 
the C-PP is obvious despite small resetting be-
tween zhu4 and lou2. So we suggest that there is 
a stable prosodic pattern within a C-PP in 
broadcasting news speech.
Conversely, what is the correlation between 
the prosody and syntax? From above analysis, 
we know that the conjunction and particle, such
as?(de0), ?(deng3),?(he2), ?(dan4) and so 
on, more likely attached to the end of left struc-
ture or the beginning of right one and form a 
prosodic word. If it has just four lexical words 
including the conjunction or particle they form a 
prosodic word by itself. That is to say, it has 
very great flexibility in prosodic structures for 
conjunctions and particles, such as ? ?
(zhan4)/1+ ??(quan2guo2)/1 ??(shi1di4)/1 
???(mian4ji1 de0)/2* (occupy/1+ country-
wide/1everglade/1 acreage/2*)?, ??(he2)/1 ?
? (she4hui4)/2 ? ? (jiu4zhu4)/1 ? ?
(zhi4du4)/2* (and/1 social/2 assistance/1 sys-
tem/2*)? and so on.
4.2 Diachronic Comparative Phonetic and 
Prosodic Analysis in Movie Dialogues
Which diachronic phonetic changes happened in 
Mandarin by the past 100 years? We also ana-
lyze and compare the phonetic features of Chi-
nese Mandarin among several same-name mov-
ies in different historical eras from CMDMC
(Wang et al 2010). In order to minimize the 
divergence of the variables and maximize the 
reliability of conclusions, we chose two pairs of 
same-name movies screened in different histori-
cal periods. These movies are: Pingyuan Youji-
dui (The Plains Guerrillas) shot in 1955 and 
1975, Dujiang Zhencha Ji (Reconnaissance 
across the Yangtze River) shot in 1954 and 1974 
respectively.
Pitch Feature: In the analysis of pitch, we 
put aside the stresses and the neutral tone syl-
lables, and make the statistical investigations on 
the top pitch value and the bottom pitch value of 
the syllables.
Figure 3: The pitch data of 1955 and 1975 ver-
sion in the Plains Guerrillas. The fundamental 
frequency also was normalized by semitones;
the male?s reference frequency is 50Hz.
Figure 3 shows that the mean of the top pitch 
value in the 1950s? materials is lower than that 
of 1970s?. In the 1955 version, the leading cha-
racter, Speaker A, possesses a mean value of the 
top pitch value which is 20.9 semitones. This 
value is lower than that of 1975s? by a differ-
ence of 0.9 semitones. The negative character, 
Speaker B, has a mean value of the top pitch 
value which is 24.5 semitones in the 1955 ver-
sion. The value in the 1975 version is 27 semi-
tones, with a difference of 2.5 semitones left, 
also showing that the value in the 1975 version 
is comparatively high. Comparing the data of 
the bottom pitch value in the 1955 version with 
that in the 1975 version, we know that these 
data seem closer than the top pitch value, but 
still the higher ones belong to the 1975 version. 
That the bottom pitch value is higher tells us 
that the whole pitch register is raised.
Furthermore, we can easily see from Figure 3
that the pitch range of the same character in the 
1975 version is wider. Speaker A of the 1955 
version has a pitch range of 4.8 semitones. In 
contrast, the same character in the 1975 version 
has a pitch range of 6 semitones. Speaker C of
the 1955 version has 4 semitones pitch range, 
but in the 1975 version, he has 5.9 semitones 
pitch range. The gap between them is 1.9 semi-
tones. Through this comparison, we find that the 
pitch range in the 1975 version is wider than 
that in the 1955 version in the whole. 
To some extent, the speaking, both the top
pitch value and the bottom pitch value in the 
1975 version are higher. This proves that, on the 
whole, the pitch of the 1970s? materials is high-
er and more unnatural than that of 50s? because 
of the effect by the Cultural Revolution era.
And this also proves the feeling of the partici-
pants in the perceptional experiment at section 3 
about the 1970s? materials, that is, the 1970s?
Mandarin has a loud and sonorous voice; the 
characters pronounce harder; the general pitch is 
higher.
Duration feature: In the respect of duration, 
we also compared and analyzed the presenters?
speech on TV in 20053
According to table 7, there is a little differ-
ence of the durations mean among them (fol-
lowing four tones), especially it?s very closely 
between the 1975 and the 2005, and those of the 
1975 version are a few longer than those of the 
1955 version. But, except the first tone (Sig. 
=.077), the differences of the duration means 
between the others, which is in the 1955, the 
with the materials ex-
tracted from the movie dialogues the 1955 and 
the 1975. Table 7 is the relevant data.
3 In this work, we just chose the male?s speech data 
from Zou (2007).
1975 and the 2005, are significant (Sig. 
=.000, .000, .002?.05 respectively).
mean SD N
Movie:1955 T1 153.6 69.5 243
T2 136.8 58.1 242
T3 132.8 58.7 321
T4 133.5 52.0 539
Movie:1975 T1 177.8 72.1 258
T2 155.5 52.0 263
T3 152.5 57.6 289
T4 156.7 59.9 505
TV: 2005 T1 163.1 65.7 1471
T2 156.0 66.5 1743
T3 156.8 67.6 1054
T4 145.9 62.3 2652
Table 7: The duration mean of four tones in 
movie dialogues (1955 and 1975) vs. that of
presenters? spoken language on TV in 2005(ms).
Demonstrations of the four-syllable pro-
sodic words: The comparative pitch contour of 
two four-syllable prosodic words, which are 
?bu2 yao4 lu4 mian4? (don?t appear) and ?gan4
shen2 me0 de0? (What are you doing?), are 
shown in Figure 4 and 5, respectively.
Figure 4: The pitch contour of ?bu2 yao4 lu4
mian4? (don?t appear)
Figure 5: The pitch contour of ?gan4 shen2 me0
de0? (What are you doing?)
By observing the above two figures, we find 
that the pitch contour of the 1975 and that of the 
1955 are almost identical except the latter is 
always lower than the former. This may explain 
that although the Mandarin has gone through a 
hundred years, the pitch pattern is relatively 
stable.
5 Conclusions and Future Work
This paper proposes to design a Chinese 
Mandarin Digital Multi-modal Corpus
(CMDMC). Through this corpus, the historical 
trace of Mandarin development can be followed;
the fresh and alive data and material resources 
can be drawn up for the modern researchers and 
successors. We also intend to analyze the syn-
tactic correlations of prosodic phrase in broad-
casting news speech, and compare the phonetic 
and prosodic features in movie dialogues among 
several same-name movies in different histori-
cal eras. The contributions are as follows.
Firstly, the syntactic structure is more com-
plex than the prosodic structure, some conjunc-
tion and particle, such as de0, deng3, he2, dan4
and so on, more likely attached to the end of left 
structure or the beginning of right one and form 
a prosodic word, if the number of lexical words 
mismatch the prosodic words. Otherwise, they 
have almost similar structure.
Secondly, the speech of 1970s in last century 
is greatly influenced by the special era. People 
usually use exaggerated voice, pronounce hard 
and raise the pitch unnaturally, giving others a 
taste of lecturing and ordering. In contrast, the 
speech of Mandarin in 1950s is more natural 
and close to the daily life pronunciation and 
intonation. Even so, the pitch patterns have no 
big changes, and this may explain that the pitch
patterns are comparatively stable in Chinese 
Mandarin.
Future research will include treatment of cor-
relation between syntax and prosody within IP
or IG, ideally comparing the diachronic phonet-
ic or prosodic changes in Mandarin by the past 
100 years. Additionally, we would like to tackle 
the problem of data management, update and 
periodical increasing as time passes.
6 Acknowledgements
This work was supported by the Department of 
Science and Technology at Ministry of Educa-
tion (No. 107118), and ?211? Key Projects of 
Communication University of China (No. 
21103010105, 21103010106). We would like to 
thank the anonymous reviewers for their in-
sightful comments.
References
Abney, S. 1992. Prosodic Structure, Performance 
Structure and Phrase Structure. Proceedings of 5th 
Darpa Workshop on Speech & Natural Language.
Botinis, A., Ganetsou, S., Griva, M., and Bizani, H.
2004. Prosodic Phrasing and Syntactic Structure 
in Greek. Proceedings of FONETIK 2004, Dept. 
of Linguistics, Stockholm University.
Chen, Keh-jiann, Tseng, Chiu-yu, Peng, Hua-jiu and 
Chen, Chi-ching. 2004. Predicting Prosodic 
Words from Lexical Words -- A First Step to-
wards Predicting Prosody from Text . Proceed-
ings of the 4th International Symposium on Chi-
nese Spoken Language Processing (ISCSLP 2004).
Hong Kong, 173-176.
de Pijper, J. R., and Sanderman, A. A. 1994. On the 
Perceptual Strength of Prosodic Boundaries and 
its Relation to Suprasegmental Cues. Journal of 
the Acoustical Society of America, 96(4), 2037-
2047.
Price, P., Ostendorf, M., Shattuck-Hufnagel, S., and 
Fong, C. 1991. The Use of Prosody in Syntactic 
Disambiguation. Journal of the Acoustic Society 
of American, 90, 2956-2970.
Wang Yan, Liu Jun, Kan Minggang, Hou Min, Zou 
Yu. 2010. Phonetic Diachronic Diversification in 
Mandarin: A Case of the Same Movie?s Dialogue 
in 1950s and 1970s. Proc. of YWCL 2010, Wuhan, 
Hubei, Oct 10-13. (Accepted)
Zou Yu. 2007. A Formal Study on Prosody of Pre-
senter's Spoken Language Based on Broadcast 
Speech Corpus. PhD thesis, Communication Uni-
versity of China.
Zou Yu, He Wei, Zhang Yuqiang, Hou Min and Zhu 
Weibin. 2009. A Special Prosodic Phrasing in 
Broadcasting News Programs. Computational 
Sciences and Optimization: Theory, Simulation 
and Experiment (Vol. 2), Sanya, Hainan, China, 
24-26 April, 406-408.
Zou Yu, Wu Jiyuan, He Wei, Hou Min, Teng Yon-
glin. 2010. Syntactic Correlations of Prosodic 
Phrase in Broadcasting News Speech. The 6th 
IEEE International Conference on Natural Lan-
guage Processing and Knowledge Engineering 
(NLP-KE 2010), Beijing, China, Aug. 21-23.
The SAU Report for the 1st CIPS-SIGHAN-ParsEval-2010 
Qiaoli Zhou Wenjing 
Lang 
Yingying 
Wang 
Yan Wang Dongfeng Cai
Knowledge Engineering Research Center,Shenyang Aerospace 
University,Shenyang,China 
Qiaoli_z@yahoo.com.cn 
 
Abstract 
This paper presents our work for 
participation in the 2010 CIPS-SIGHAN 
evaluation on two tasks which are Event 
Description Sub-sentence (EDSs) 
Analysis and Complete Sentence (CS) 
Parsing in Chinese Parsing. The paper 
describes the implementation of our 
system as well as the results we have 
achieved and the analysis. 
1 Introduction 
The paper describes the parsing system of SAU 
in 1st CLPS-SIGHAN evaluation task 2. We 
participate in two tasks - EDS Analysis and CS 
Parsing. The testing set only provides 
segmentation results, therefore, we divide our 
system into the following subsystems: (1) Part-
of-Speech (POS) tagging system, we mainly 
make use of Conditional Random Fields (CRFs) 
model for POS tagging; (2) parsing system, the 
paper adopts divide-and-conquer strategy to 
parsing, which uses CCRFs model for parsing 
and adopts searching algorithm to build trees in 
decoding; (3) head recognition system, which 
also makes use of CCRFs model. 
The rest of the paper is organized as follows: 
Section 2 describes the POS tagging system; 
Section 3 describes the structure of our parsing 
system; Section 4 describes head recognition 
system in parsing tree; Section 5 presents the 
results of our system and the analysis; Section 6 
concludes the paper. 
2 Part-of-Speech Tagging 
We use CRFs model and post-processing 
method for POS tagging. In the first step, we tag 
POS based on CRFs. The second step is the 
post-processing after tagging, which is 
correcting by using dictionary drawn from 
training set. The system architecture of POS 
tagging is shown in Figure 1. 
2.1 Features 
Feature selection significantly influences the 
performance of CRFs. We use the following 
features in our system. 
Atom Template 
word(-2) , word(-1) , word(0) , word(1) , word(2) 
prefix( word (0) ) ,suffix( word(0) ) 
includeDot1(word ( 0 )) 
includeDot2(word ( 0 )) 
Complex Template 
word(-1)& word(0) ? word(0)& word(1) 
word(0)& prefix( word (0) ) 
word(0)& suffix( word(0) ) 
word(0)& includeDot1(word ( 0 )) 
word(0)& includeDot2(word ( 0 )) 
Table 1: Feature templates used in POS tagger. 
word(i) represents the ith word, prefix( word (i) ) 
represents the first character of the ith word, 
suffix( word (i) ) represents the last character of  
the ith word, ncludeDot1(word ( i)) represents 
the ith word containing ?? ? or not, and 
includeDot2(word ( i)) represnts the ith word 
containing ?.? or not. 
2.2 Post-processing 
The post-processing module adopts the 
following processing by analyzing the errors 
from tagging result based on CRFs. We firstly 
need to build two dictionaries which are single 
class word dictionary and ambiguity word 
dictionary before the post-processing. The 
single class word dictionary and ambiguity 
word dictionary are built by drawing from 
training set. 
 
The single class word is the word having 
single POS in training set, and the ambiguity 
word is the word having multi POS in training 
set. Besides, we build rules for words with 
distinctive features aiming at correcting errors, 
such as ???, numbers and English characters, 
etc. 
Figure 2 shows the post-processing step after 
POS tagging by CRFs model. As shown in 
Figure 2, we respectively post-process single 
class words and ambiguity words according to 
CRF score. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
(1) Single class word processing module 
The post-processing of single class words 
consults the single class word dictionary and 
CRFs score. When the score from CRFs is 
higher than 0.9, we take the POS from CRFs as 
the final POS; otherwise, POS of the word is 
corrected by the POS in the single class word 
dictionary. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
2 
3 
1 
N 
CRF Primary result 
Word class? 
Ambiguity word 
Single class word 
Unknown word 
End 
Rule base 
Figure2: Post-processing architecture after CRF labeling 
Single class word 
processing module 
Ambiguity word 
processing module 
Unknown word 
processing module 
Training 
corpus 
Features selection 
Parameter estimation 
CRF model
Testing 
corpus 
POS tagger based 
on CRF 
Primary reco- 
gnition result 
Post-processing 
POS 
Result 
Figure 1: System architecture of POS tagging
(2) Ambiguity word processing module 
The post-processing of ambiguity words 
consults the ambiguity word dictionary and 
CRFs score. When the POS from CRFs belongs 
to the POS of the word in the ambiguity word 
dictionary, we take the POS from CRFs as the 
final POS; otherwise, we examine the score of 
CRF, if the score is less than 0.4, the final POS 
of the word is the POS who has the highest 
score (has highest frequency), or else taking 
POS from CRF as the final POS. 
(3) Unknown word processing module 
The unknown words are the words not in 
training set. By analyzing the examples, we find 
that there are great deals of person names, 
location names, organization names and 
numbers, etc. And the words have 
characteristics when building word, therefore, 
we set up rules for processing. 
2.3 Experiment results 
 Table 2 shows the comparative experimental 
results of POS tagging using two methods. 
Table 2: Comparative POS tagging results 
3 Parsing system 
The paper uses divide-and-conquer strategy 
(Shiuan 1996 et al, Braun 2000 et al, Lyon 
1997 et al)for parsing. Firstly, we recognize 
MNP for an input sentence, which divide the 
sentence into two kinds of parts. One kind is 
MNPs, and the other one is frame which is a 
new sentence generating by replacing MNP 
using its head word. Secondly, we use parsing 
approach based on chunking (Abney, 1991, Erik 
Tjong and Kim Sang, 2001) and a searching 
algorithm in decoding. Thirdly, we combine the 
parsing trees of MNPs and frame, which obtains 
the full parsing tree of the original sentence. 
Figure 3 shows the architecture of paring 
system. 
3.1 MNP recognition 
Maximal Noun Phrase (MNP) is the noun 
phrase which is not contained by any other noun 
phrases. We use Berkeley parser (2009 1.0) for 
MNP recognition. We first use Berkeley parser 
to parse sentences after POS tagging, and then 
we tag MNPs from the parsing results. As the 
following example: 
Berkeley parser result: dj[ ??/nS vp[ ??/v 
vp[ ??/v np[ pp[ ?/p np[ ??/nS ??/n ] ] ?
/uJDE ??/n ] ] ] ] 
MNP recognition result: ??/nS ??/v ??
/v np[ ?/p ??/nS ??/n ?/uJDE ??/n ]  
The results of MNP recognition EDSs 
analysis and CS parsing are as table3: 
 
 P R F 
EDSs 85.3202% 85.998% 85.6578% 
CS 77.7102% 79.2782% 78.4864% 
Table 3: Results of MNP recognition 
3.2 Head recognition of MNP and 
generation of frame 
 In this paper, the new sentence in which MNPs 
are replaced by their head word is defined as the 
sentence?s frame. The head of MNPs is 
identified after MNP recognition and then they 
are used to replace the original MNP, and 
finally the sentence?s frame is formed. We use 
the rules to recognize the head of MNP. Usually, 
the last word of MNP is the head of the phrase, 
which can represent the MNP in function. For 
example: ?[?/r ??/n] ??/ad ??/v ??/v 
[?? /v ?? /v ? /u ?? /n]? ? In this 
sentence? ? /r?? /n? and ? ??/v ??/v 
?/u ??/n? are MNPs. If we omit the 
modifier in MNP, for example ?[??/n] ??
/ad ??/v ??/v [??/n]??, the meaning of 
the sentence will not be changed. Because the 
head can represent the syntax function of MNP, 
we can use the head for parsing, which can 
avoid the effect of the modifier of MNP on 
parsing and reduce the complexity of parsing. 
Method EDSs precision 
CS 
precision
CRF 92.83% 89.42% 
CRF +  
post-processing 93.96% 91.05% 
However, the components of MNP are 
complicated, not all of the last word of MNP 
can be the head of MNP. The paper shows that 
if MNP has parentheses, we can use the last 
word before parentheses as the head. When the 
last word of MNP is ???, we use the second last 
word as the head.  
3.3 Chunking with CRFs 
The accuracy of chunk parsing is highly 
dependent on the accuracy of each level of  
 
chunking. This section describes our approach 
to the chunking task. A common approach to 
the chunking problem is to convert the problem 
into a sequence tagging task by using the 
?BIEO? (B for beginning, I for inside, E for 
ending, and O for outside) representation. 
This representation enables us to use the 
linear chain CRF model to perform chunking, 
since the task is simply assigning appropriate 
labels to sequence. 
3.3.1 Features 
Table 4 shows feature templates used in the 
whole levels of chunking. In the whole levels of 
chunking, we can use a rich set of features 
because the chunker has access to the 
information about the partial trees that have 
been already created (Yoshimasa et al, 2009). It 
uses the words and POS tags around the edges 
of the covered by the current non-terminal 
symbol. 
Table 4: Feature templates used in parsing system.  
W represents a word, P represents the part-of-speech 
of the word, C represents the sum of the chunk 
containing the word, F represents the first word of 
the chunk containing the word, L represents the last 
word of the chunk containing the word, S represents 
that the word is a non-terminal symbol or not. Wj is 
the current word; Wj-1 is the word preceding Wj, Wj+1 
is the word following Wj. 
 
 
 
 
 
 
 
 
3.4 Searching for the Best Parse 
The probability for an entire parsing tree is 
computed as the product of the probabilities 
output by the individual CRF chunkers: 
0
(y / )
h
i i
i
score p x
=
=?  
We use a searching algorithm to find the highest 
probability derivation. CRF can score each 
chunker result by A* search algorithm, 
therefore, we use the score as the probability of 
each chunker. We do not give pseudo code, but 
the basic idea is as figure 4. 
 
 
1: inti parser(sent) 
2: Parse(sent, 1, 0) 
    3: 
    4: function Parse(sent, m, n) 
    5:  if sent is chunked as a complete sentence 
    6:     return m 
    7:  H = Chunking(sent, m/n) 
    8:   for h?H do 
    9:    r = m * h.probability 
    10:     if r?n then 
    11:        sent2 = Update(sent, h) 
    12:        s = Parse(sent2, r, n) 
    13:        if s?n then n = s 
    14:    return n 
15: function Chunking(sent, t) 
    16: perform chunking with a CRF chunker and 
return a set of chunking hypotheses whose  
17: probabilities are greater than t. 
18: function Update(sent, h) 
19:  update sequence sent according to chunking 
hypothesis h and return the updated sequence. 
Figure 4: Searching algorithm for the best parse  
 
It is straightforward to introduce beam search 
in this search algorithm?we simply limit the 
number of hypotheses generated by the CRF 
chunker. We examine how the width of the 
beam affects the parsing performance in the 
Word Unigrams W-2 , W-1, W0, W1, W2,
Word Bigrams W-2W-1, W-1W0, W0W1, 
W1W2, W0W-2, W0W2,  
Word Trigrams W0W-1W-2, W0W1W2
POS Unigrams P-3, P-2 , P-1 , P0 , P1, P2, P3,
POS Bigrams P-3P-2, P-2P-1, P-1P0, P0P1, 
P1P2, P2P3, P0P-2, P0P2,
POS Trigrams P-3P-2P-1, P-2P-1P0, P-1P0P1, 
P0P1P2, P1P2P3
Word & POS W0P0, W0P-1, W0P1,
Word & WordCount W0C0
Word & FirstWord W0F0 , W-1F0
Word & LastWord W0L0, W1L0
Word & Symbol W0S0
Chunk Model
 frame 
MNPs
sentence 
MNP Recognition parsing tree
Search
CRF Chunker
Figure3: Parsing system architecture 
experiments. We experiment beam width and 
we adopt the beam width of 4 at last. 
3.5 Head Finding 
Head finding is a post process after parsing in 
our system. The paper uses method combining 
statistics and rules to find head. The selected 
statistical method is CRF model. The first step 
is to train a CRF classifier to classify each 
context-free production into several categories. 
Then a rule-based method is used to post 
process the identification results and gets the 
final recognition results. The rule-based post-
processing module mainly uses rule base and 
case base to carry out post-processing. 
3.6 Head finding based on CRFs 
The head finding procedure proceeds in the 
bottom-up fashion, so that the head words of 
productions in lower layers could be used as 
features for the productions of higher layers 
(Xiao chen et al 2009). 
 
Atom template Definition 
CurPhraseTag The label of the current word 
LCh_Word The left most child 
RCh_Word The right most child 
LCh_Pos The POS of the left most child
MCh_Pos The POS of the middle child 
RCh_Pos The POS of the right most child
NumCh The number of children 
CurPhraseTag 1 ? The labels of the former phrase and the latter 
Table 5: Atom templates for Head finding 
 
Table 6: Complex templates for Head finding 
 
The atom templates are not sufficient for 
labeling context; therefore, we use some 
complex templates by combining the upper 
atom templates for more effectively describing 
context. When the feature function is fixed, the 
atom templates in complex templates are 
instantiated, which will generate features. 
The final feature templates are composed of 
the atom templates and the complex templates. 
The feature templates of the head recognition in 
phrases contain 24 types. 
3.7 Head Finding based on rules 
Through the analysis of error examples, we 
found that some CRFs recognition results are 
clearly inconsistent with the actual situation; we 
can use rules to correct these errors, thus 
forming a rule base. Example-base is a chunk-
based library built through analysis and 
processing on the training corpus. The 
Example-base is composed of all the bottom 
chunk and high-level chunk in training corpus. 
High-level phrases are the bottom chunk 
replaced by heads. 
3.8 Experiment results of head finding 
Table 7 shows the comparative experiment 
results of head recognition. 
 
Table7: Comparative results of head recognition 
4 Experiment of parsing system 
We perform experiments on the training set and 
testing set of Tsinghua Treebank provided by 
CIPS-SIGHAN-ParsEval-2010. For the direct 
fluence of parsing result by the length of 
sentence, we count the length distribution of 
corpus. 
in
Table 8 shows that the length of training set 
and testing set of EDSs is mostly less than 20 
words. The length of training set of CS is evenly 
distributed, while the length of testing set is 
between 30 and 40 words. 
Complex Template 
CurPhraseTag/ NumCh, CurPhraseTag/ LCh_Word, 
CurPhraseTag/LCh_Pos, 
CurPhraseTag/LCh_Pos/RCh_Pos, 
CurPhraseTag/NumCh/LCh_Pos/ RCh_Pos, 
CurPhraseTag/NumCh/LCh_Word/LCh_Pos/MCh_
Pos/RCh_Word/RCh_Pos,  
LCh_Word/LCh_Pos, CurPhraseTag/MCh_Pos, 
NumCh/LCh_Pos/ MCh_Pos/ RCh_Pos, 
 CurPhraseTag/ NumCh/ MCh_Pos, 
CurPhraseTag/LCh_Word/LCh_Pos/MCh_Pos/RCh
_Word/RCh_Pos,  
LCh_Word/ LCh_Pos, LCh_Pos/ MCh_Pos, 
 CurPhraseTag/NumCh, RCh_Word/RCh_Pos,  
NumCh/LCh_Word/LCh_Pos/MCh_Pos/RCh_Word
/RCh_Pos 
 Total Num 
Wrong 
Num Precision 
CRFs 7035 93 98.68% 
CRFs + 
rule-base+ 
case-base 
7035 74 98.95% 
The paper adopts divide-and-conquer strategy 
to parsing; therefore, we conduct the 
frame whose length is less than 5 words, the frame 
length distribution of training set is 9.17% higher 
than the testing set; for the frame whose length is 
more than 5 words and less than 10 words, the 
training set is 7.65% lower than testing; and for the 
frame whose length is between 10 words and 20 
words, the testing set is 20.09% higher compared 
with the training set. From another aspect, in 
testing set, CS is 46.2% lower compared with 
EDSs for frame whose length is less than 5. 
Therefore, the complexity of frame in CS is higher 
than in EDSs. 
comparative experiment of MNP parsing and 
frame parsing. In addition, the results of MNP 
parsing and frame parsing depend on the length 
largely, so we list the length distribution of 
MNP and frame of EDSs and CS as table 9 and 
table 10. 
 
As shown in Table 8, 9 and 10, the length 
distribution of testing set shows that the paring unit 
length of EDSs is reduced to less than 10 from less 
than 20 in original sentence and CS is reduced to 
less than 20 from between 30 and 40 after dividing 
an original sentence into MNPs parts and frame 
part. The above data indicate the divide-and-
conquer strategy reduces the complexity of 
sentences significantly. 
Table 8: Length distribution of EDSs and CS 
 EDSs CS 
length training set 
testing 
set 
training 
set 
testing 
set 
[0, 10) 50.68% 64.30% 10.59% 0 
[10,20) 37.27% 29.50% 27.55% 0 
[20,30) 8.64% 5.40% 26.37% 79.9%
[30,40) 2.31% 0.60% 16.63% 20.1%
40? 1.10% 0.20% 18.86% 0 
 
We define Simple MNP (SMNP) whose 
length is less than 5 words and Complete MNP 
(CMNP) whose length is more than 5 words. 
 We can conclude that the parsing result of CS 
is lower than EDSs from Table 11, which is due 
to the higher complexity of MNP and frame in CS 
compared with EDSs from the results of Table 9 
and Table 10. In addition, we obtain about 1% 
improvement compared with Berkeley parser in 
MNP and Frame parsing result in EDSs from 
Table 11 and Table 12, which indicates that our 
method is effective for short length parsing units. In 
particular, Table 12 shows that our result is 1.8% 
higher than Berkeley parser in the frame parsing of 
CS. Due to the non-consistent frame length 
distribution of training set and testing set in CS 
from Table 10, we find that Berkeley parser largely 
depends on training set compared with our method. 
Table 9: Length distribution of MNP  
 EDSs CS 
length training set 
testing 
set 
training 
set 
testing 
set 
[0,5) 55.30% 62.46% 55.42% 59.45%
[5,10) 32.66% 29.69% 32.57% 30.77%
[10,20) 10.03% 6.75% 10.03% 8.65%
20? 2.00% 1.09% 1.98% 1.12%
 
Table 9 shows the length distribution of MNP 
in training set and testing set of sub-sentence is 
consistent in basic, but the SMNP distribution 
of EDSs is 3.01% less than CS, which 
illuminates the complexity of MNP in CS is 
higher than in EDSs. 
 
 EDSs CS 
length training set 
testing 
set 
training 
set 
testing 
set 
[0,5) 45.84% 47.20% 10.17% 1.00%
[5,10) 43.58% 44.00% 24.14% 10.80%
[10,20) 9.98% 8.70% 41.31% 62.20%
20? 0.60% 0.10% 24.38% 26.00%
To more fairly compare the performance of 
our proposed method, the comparative results 
are shown as Table 13, the first one (Model01) 
is combination method of MNP pre-processing 
and chunk-based, and the chunk-based result 
which adopts CCRFs method with searching 
algorithm; the second one (Berkeley) is the 
parsing result of Berkeley parser; the third one 
(Model02) also is combination method of MNP 
pre-processing and chunk-based, and the chunk-
based result which adopts CCRFs method only; 
and the lase one (Model03) is the chunk-based 
result which adopts CCRFs method with 
searching algorithm. 
Table 10: Length distribution of frame 
 
Table 10 shows the length distribution of frame 
in training set and testing set of EDSs is consistent 
in basic, while the CS is non-consistent. For the 
  
    
 method P R F 
Berkeley 87.5746% 87.8365% 87.7053% 
EDSs 
Proposed Method 88.5752% 88.6341% 88.6047% 
Berkeley 84.4755% 84.9182% 84.6963% CS 
Proposed Method 84.7535% 85.046% 84.8995% 
Table 11: Comparative results of MNP parsing 
 
 method P R F 
Berkeley 91.3411% 91.1823% 91.2617% 
EDSs 
Proposed Method 92.4669% 92.0765% 92.2713% 
Berkeley 85.4388% 85.3023% 85.3705% 
CS 
Proposed Method 87.3357% 87.0357% 87.1854% 
Table12: Comparative results of Frame parsing 
 
 P R F 
Model 01 85.42% 85.35% 85.39%
Berkeley 84.56% 84.62% 84.59%
Models 02 85.31% 85.30% 85.31%
Models 03 83.99% 83.77% 83.88%
Table13: Comparative results of EDSs 
 
dj constituent fj constituent overall F 
P R P R F F F 
Model 01 78.64% 78.73% 78.69% 70.22% 71.62% 70.91% 74.80% 
Berkeley 78.37% 78.16% 78.26% 69.43% 72.42% 70.89% 74.58% 
Models 02 78.18% 78.30% 78.24% 70.20% 70.98% 70.59% 74.41% 
Models 03 77.38% 77.41% 77.39% 70.39% 70.01% 70.24% 73.82% 
Table14: Comparative results of CS 
 
From Table 13, we can see that Model01 
performance in EDSs is improved by 0.08% 
than Model02, and the searching algorithm 
helps little in EDSs analysis. From Table 14, we 
can see that Model01 performance in CS is 
improved by 0.4% than Model02, better than 
Berkeley parser result with search algorism. 
Overall, in EDSs analysis, Model01 
performance is improved by 0.8% than 
Berkeley parser, and in overall F-measure of CS, 
Model01 performance is 0.22% higher than 
Berkeley parser. From Table 13 and 14, We can 
see that Model01 performance in EDSs is 
improved by 1.51% than Model03 and the 
Model01 in CS is improved by 0.98% than 
Model03, and the MNP pre-processing helps. 
5 Conclusions 
We participate in two tasks - EDS Analysis 
and CS Parsing in CLPS-SIGHAN- ParsEval-
2010. We use divide-and-conquer strategy for 
parsing and a chunking-based discriminative 
approach to full parsing by using CRF for 
chunking. As we all know, CRF is effective for  
chunking task. However, the chunking result in 
the current level is based on the upper level in 
the chunking-based parsing approach, which 
will enhance ambiguity problems when the 
input of the current level contains non-terminal 
symbols, therefore, the features used in 
chunking is crucial. This paper, for effectively 
using the information of partial trees that have 
been already created, keeps the terminal 
symbols in the node containing non-terminal 
symbols for features. Our experiments show 
that these features are effective for ambiguity 
problems. 
We suppose that MNP pre-processing before 
statistical model can significantly simplify the 
analysis of complex sentences, which will have 
more satisfatory results compared with using 
statistical model singly. The current results 
show that the MNP pre-processing does 
simplify the complex sentences. However, the 
performance of MNP recognition and the 
parsing of MNP need to be improved, which 
will be our next work. 
References 
Yoshimasa Tsuruoka, Jun?ichi Tsujii, Sophia 
Anaiakou. 2009. Fast Full Parsing by Linear-
Chain Conditional Random Fields. In 
Proceedings of EACL?09, pages 790-798.  
Xiao chen, Changning Huang, Mu li, Chunyu Kit. 
2009. Better Parser Combination. In CIPS-
ParsEval-2009, pages 81-90. 
Abney, S.. 1991. Parsing by chunks, Principle-Based 
Parsing, Kluwer Academic Publishers. 
Erik Tjong, Kim Sang. 2000. Transforming a 
chunker to a parser. In J.Veenstra W.daelemans, 
K Sima? an and J. Zavrek, editors, Computational 
Linguistics in the Netherlands 2000, Rodopi, page 
177-188.  
P.L. Shiuan, C.T.H. Ann. 1996. A Divided-and-
Conquer Strategy for Parsing. In Proc. of the 
ACL/SIGPARSE 5th International Workshop on 
Parsing Technologies. Santa Cruz, USA, 1996, 
pages 57-66 
C. Braun, G. Neumann, J, Piskorski. 2000. A Divide-
and-Conquer Strategy for Shallow Parsing of 
German Free Texts. In Proc. of ANLP-2000. 
Seattle, Washington, 2000, pages 239-246. 
C.Lyon, B.Dickerson. 1997. Reducing the 
Complexity of Parsing by a Method of 
Decomposition International Workshop on 
Parsing Technology, 1997, pages 215-222. 
Qiaoli Zhou, Xin Liu, Xiaona Ren, Wenjing Lang, 
Dongfeng Cai. 2009. Statistical parsing based on 
Maximal Noun Phrase pre-processing. In CIPS-
ParsEval-2209. 
P.L. Shiuan, C.T.H. Ann. A Divide-and-Conquer 
Strategy for Parsing. In: Proc. of the 
ACL/SIGPARSE 5th International Workshop on 
Parsing Technologies. Santa Cruz, USA, 1996. 
57-66. 
C. Braun, G. Neumann, J. Piskorski. A Divide-and-
Conquer Strategy for Shallow Parsing of German 
Free Texts. In: Proc. of ANLP-2000. Seattle, 
Washington, 2000. 239-246. 
C. Lyon, B. Dickerson. Reducing the Complexity of 
Parsing by a Method of Decomposition. 
International Workshop on Parsing Technology. 
1997. 215-222. 
