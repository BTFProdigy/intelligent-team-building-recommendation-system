Proceedings of NAACL HLT 2009: Short Papers, pages 49?52,
Boulder, Colorado, June 2009. c?2009 Association for Computational Linguistics
Modeling Dialogue Structure with  Adjacency Pair Analysis and Hidden Markov Models  Kristy Elizabeth Boyer*1 Robert Phillips1,2 Eun Young Ha1 Michael D.  Wallis1,2 Mladen A.  Vouk1 James C. Lester1  1Department of Computer Science North Carolina State University Raleigh, NC, USA  2Applied Research Associates Raleigh, NC, USA  *keboyer@ncsu.edu  Abstract 
Automatically detecting dialogue structure within corpora of human-human dialogue is the subject of increasing attention.  In the do-main of tutorial dialogue, automatic discovery of dialogue structure is of particular interest because these structures inherently represent tutorial strategies or modes, the study of which is key to the design of intelligent tutor-ing systems that communicate with learners through natural language.  We propose a methodology in which a corpus of human-human tutorial dialogue is first manually an-notated with dialogue acts.  Dependent adja-cency pairs of these acts are then identified through ?2 analysis, and hidden Markov mod-eling is applied to the observed sequences to induce a descriptive model of the dialogue structure.       
1 Introduction Automatically learning dialogue structure from corpora is an active area of research driven by a recognition of the value offered by data-driven ap-proaches (e.g., Bangalore et al, 2006).  Dialogue structure information is of particular importance when the interaction is centered around a learning task, such as in natural language tutoring, because techniques that support empirical identification of dialogue strategies can inform not only the design of intelligent tutoring systems (Forbes-Riley et al, 2007), but also contribute to our understanding of 
the cognitive and affective processes involved in learning through tutoring (VanLehn et al, 2007).        Although traditional top-down approaches (e.g., Cade et al, 2008) and some empirical work on analyzing the structure of tutorial dialogue (Forbes-Riley et al, 2007) have yielded significant results, the field is limited by the lack of an auto-matic, data-driven approach to identifying dialogue structure.  An empirical approach to identifying tutorial dialogue strategies, or modes, could ad-dress this limitation by providing a mechanism for describing in succinct probabilistic terms the tuto-rial strategies that actually occur in a corpus.      Just as early work on dialogue act interpretation utilized hidden Markov models (HMMs) to capture linguistic structure (Stolcke et al, 2000), we pro-pose a system that uses HMMs to capture the structure of tutorial dialogue implicit within se-quences of already-tagged dialogue acts.  This ap-proach operates on the premise that at any given point in the tutorial dialogue, the collaborative in-teraction is in a dialogue mode that characterizes the nature of the exchanges between tutor and stu-dent.  In our model, a dialogue mode is defined by a probability distribution over the observed sym-bols (e.g., dialogue acts and adjacency pairs).      Our previous work has noted some limitations of first-order HMMs as applied to sequences of individual dialogue acts (Boyer et al, in press).  Chief among these is that HMMs allow arbitrarily frequent transitions between hidden states, which does not conform well to human intuition about how tutoring strategies are applied.  Training an HMM on a sequence of adjacency pairs rather than individual dialogue acts is one way to generate a 
49
more descriptive model without increasing model complexity more than is required to accommodate the expanded set of observation symbols.  To this end, we apply the approach of Midgley et al (2006) for empirically identifying significant adja-cency pairs within dialogue, and proceed by treat-ing adjacency pairs as atomic units for the purposes of training the HMM.   2 Corpus Analysis This analysis uses a corpus of human-human tuto-rial dialogue collected in the domain of introduc-tory computer science.  Forty-three learners interacted remotely with a tutor through a key-board-to-keyboard remote learning environment yielding 4,864 dialogue moves.    The tutoring corpus was manually tagged with dialogue acts designed to capture the salient char-acteristics of the tutoring process (Table 1).  Tag Act Example Q Question Where should I  declare i? EQ Evaluation Question How does that look? S Statement You need a  closing brace. G Grounding Ok.  EX Extra-Domain You may use  your book. PF Positive Feedback Yes, that?s right. LF Lukewarm Feedback Sort of. NF Negative Feedback No, that?s not right. Table 1. Dialogue Act Tags  The correspondence between utterances and dia-logue act tags is one-to-one.  Compound utterances (i.e., a single utterance comprising more than one dialogue act) were split by the primary annotator prior to the inter-rater reliability study.1      The importance of adjacency pairs is well-established in natural language dialogue (e.g., Schlegoff & Sacks, 1973), and adjacency pair analysis has illuminated important phenomena in tutoring as well (Forbes-Riley et al, 2007).  For the current corpus, bigram analysis of dialogue acts yielded a set of commonly-occurring pairs.  How-ever, as noted in (Midgley et al, 2006), in order to                                                            1 Details of the study procedure used to collect the corpus, as well as Kappa statistics for inter-rater reliability, are reported in (Boyer et al, 2008). 
establish that two dialogue acts are truly related as an adjacency pair, it is important to determine whether the presence of the first member of the pair is associated with a significantly higher prob-ability of the second member occurring.  For this analysis we utilize a ?2 test for independence of the categorical variables acti and acti+1 for all two-way combinations of dialogue act tags.  Only pairs in which speaker(acti)?speaker(acti+1) were consid-ered.  Other dialogue acts were treated as atomic elements in subsequent analysis, as discussed in Section 3.  Table 2 displays a list of the dependent pairs sorted by descending (unadjusted) statistical significance; the subscript indicates tutor (t) or stu-dent (s).  acti acti+1 P(acti+1|       acti) P(acti+1|    ?acti) ?2 val p-val EQs PFt 0.48 0.07 654 <0.0001 Gs Gt 0.27 0.03 380 <0.0001 EXs EXt 0.34 0.03 378 <0.0001 EQt PFs 0.18 0.01 322 <0.0001 EQt Ss 0.24 0.03 289 <0.0001 EQs LFt 0.13 0.01 265 <0.0001 Qt Ss 0.65 0.04 235 <0.0001 EQt LFs 0.07 0.00 219 <0.0001 Qs St 0.82 0.38 210 <0.0001 EQs NFt 0.08 0.01 207 <0.0001 EXt EXs 0.19 0.02 177 <0.0001 NFs Gt 0.29 0.03 172 <0.0001 EQt NFs 0.11 0.01 133 <0.0001 Ss Gt 0.16 0.03 95 <0.0001 Ss PFt 0.30 0.10 90 <0.0001 St Gs 0.07 0.04 36 <0.0001 PFs Gt 0.14 0.04 34 <0.0001 LFs Gt 0.22 0.04 30 <0.0001 St EQs 0.11 0.07 29 <0.0001 Gt EXs 0.07 0.03 14 0.002 St Qs 0.07 0.05 14 0.0002 Gt Gs 0.10 0.05 9 0.0027 EQt EQs 0.13 0.08 8 0.0042 Table 2. Dependent Adjacency Pairs 3 HMM on Adjacency Pair Sequences The keyboard-to-keyboard tutorial interaction re-sulted in a sequence of utterances that were anno-tated with dialogue acts.  We have hypothesized that a higher-level dialogue structure, namely the tutorial dialogue mode, overlays the observed dia-logue acts.  To build an HMM model of this struc-
50
ture we treat dialogue mode as a hidden variable and train a hidden Markov model to induce the dialogue modes and their associated dialogue act emission probability distributions.    An adjacency pair joining algorithm (Figure 1) was applied to each sequence of dialogue acts.  This algorithm joins pairs of dialogue acts into atomic units according to a priority determined by the strength of the adjacency pair dependency.  Sort adjacency pair list L by descending statistical significance For each adjacency pair (act1, act2) in L         For each dialogue act sequence (a1, a2, ?, an)          in the corpus                 Replace all pairs (ai=act1, ai+1=act2) with a                 new single act (act1act2) Figure 1.  Adjacency Pair Joining Algorithm     Figure 2 illustrates the application of the adja-cency pair joining algorithm on a sequence of dia-logue acts.  Any dialogue acts that were not grouped into adjacency pairs at the completion of the algorithm are treated as atomic units in the HMMianalysis.   Original Dialogue Act Sequence: Qs - St - LFt - St - St - Gs - EQs - LFt - St - St - Qs - St After Adjacency Pair Joining Algorithm: QsSt - LFt - St - StGs - EQsLFt - St - St - QsSt Figure 2.  DA Sequence Before/After Joining     The final set of observed symbols consists of 39 tags: 23 adjacency pairs (Table 2) plus all individ-ual dialogue acts augmented with a tag for the speaker (Table 1).      It was desirable to learn n, the best number of hidden states, during modeling rather than specify-ing this value a priori.  To this end, we trained and ten-fold cross-validated seven models (each featur-ing randomly-initialized parameters) for each number of hidden states n from 2 to 15, inclusive.2  The average log-likelihood was computed across all seven models for each n, and this average log-                                                           2 n=15 was chosen as an initial maximum number of states because it comfortably exceeded our hypothesized range of 3 to 7 (informed by the tutoring literature).  The Akaike Infor-mation Criterion measure steadily worsened above n = 5, con-firming no need to train models with n > 15. 
likelihood ln was used to compute the Akaike In-formation Criterion, a maximum-penalized likeli-hood estimator that penalizes more complex models (Scott, 2002).  The best fit was obtained with n=4 (Figure 3).  The transition probability distribution among hidden states is depicted in Figure 4, with the size of the nodes indicating rela-tive frequency of each hidden state; specifically, State 0 accounts for 63% of the corpus, States 1 and 3 account for approximately 15% each, and State 2 accounts for 7%.  
  Figure 3.  Dialogue Act Emission Probability  Distribution by Dialogue Mode3 4 Discussion and Future Work This exploratory application of hidden Markov models involves training an HMM on a mixed in-put sequence consisting of both individual dialogue acts and adjacency pairs.  The best-fit HMM con-sists of four hidden states whose emission symbol probability distributions lend themselves to inter-pretation as tutorial dialogue modes.  For example, State 0 consists primarily of tutor statements and positive feedback, two of the most common dia-logue  acts  in our corpus.  The transition probabili- 
51
 Figure 4.  Transition Probability Distribution4  ties also reveal that State 0 is highly stable; a self-transition is most likely with probability 0.835.  State 3 is an interactive state featuring student re-flection in the form of questions, statements, and requests for feedback.  The transition probabilities show that nearly 60% of the time the dialogue transitions from State 3 to State 0; this may indi-cate that after establishing what the student does or does not know in State 3, the tutoring switches to a less collaborative ?teaching? mode represented by State 0.        Future evaluation of the HMM presented here will include comparison with other types of graphical models.  Another important step is to correlate the dialogue profile of each tutoring ses-sion, as revealed by the HMM, to learning and af-fective outcomes of the tutoring session.  This type of inquiry can lead directly to design recommenda-tions for tutorial dialogue systems that aim to maximize particular learner outcomes.  In addition, leveraging knowledge of the task state as well as surface-level utterance content below the dialogue act level are promising directions for refining the descriptive and predictive power of these models.      Acknowledgements  This research was supported by the National Science Foundation under Grants REC-0632450, IIS-0812291, CNS-0540523, and GRFP.  Any opinions, findings, and conclusions or recommendations ex-pressed in this material are those of the 
authors and do not necessarily reflect the views of the National Science Foundation.  References Boyer, K.E., Phillips, R., Wallis, M., Vouk, M., & Lester, J. (2008).  Balancing cognitive and moti-vational scaffolding in tutorial dialogue.  Pro-ceedings of the 9th International Conference on Intelligent Tutoring Systems, Montreal, Canada, 239-249. Boyer, K.E., Ha, E.Y., Wallis, M., Phillips, R., Vouk, M. & Lester, J. (in press).  Discovering tutorial dialogue strategies with hidden Markov models.  To appear in Proceedings of the 14th International Conference on Artificial Intelligence in Educa-tion, Brighton, U.K. Bangalore, S., DiFabbrizio, G., Stent, A. (2006).  Learning the structure of task-driven human-human dialogs.  Proceedings of ACL, Sydney, Australia, 201-208. Cade, W., Copeland, J., Person, N., & D'Mello, S. (2008). Dialog modes in expert tutoring. Proceed-ings of the 9th International Conference on Intel-ligent Tutoring Systems, Montreal, Canada, 470-479.  Forbes-Riley, K., Rotaru, M., Litman, D. J., & Tetreault, J. (2007). Exploring affect-context de-pendencies for adaptive system development. Proceedings of NAACL HLT, Companion Volume, 41-44.  Midgley, T. D., Harrison, S., & MacNish, C. (2007). Empirical verification of adjacency pairs using dialogue segmentation. Proceedings of the 7th SIGdial Workshop on Discourse and Dialogue, 104-108.  Schlegoff, E.A., Sacks, H. (1973).  Opening up clos-ings.  Semiotica, 8(4), 289-327. Scott, S. L. (2002). Bayesian methods for hidden Markov models: Recursive computing in the 21st century. Journal of the American Statistical Asso-ciation, 97(457), 337-351. Stolcke, A., Coccaro, N., Bates, R., Taylor, P., Van Ess-Dykema, C., Ries, K., Shirberg, E., Jurafsky, D., Martin, R., Meteer, M. (2000).  Dialog act modeling for automatic tagging and recognition of conversational speech.  Computational Linguistics 26(3), 339-373. VanLehn, K., Graesser, A., Jackson, G.T., Jordan, P., Olney, A., Rose, C.P. (2007). When are tutorial dialogues more effective than reading? Cognitive Science, 31(1), 3-62.  
52
Proceedings of the NAACL HLT Workshop on Innovative Use of NLP for Building Educational Applications, pages 19?26,
Boulder, Colorado, June 2009. c?2009 Association for Computational Linguistics
Inferring Tutorial Dialogue Structure with Hidden Markov Modeling 
 
 
Kristy 
Elizabeth  
  Boyera 
Eun Young  
 Haa 
     Robert  
Phillipsab 
 Michael     
     D.  
  Wallisab 
Mladen A.  
 Vouka 
James C.  
 Lestera 
 
 
aDepartment of Computer Science, North Carolina State University 
bApplied Research Associates 
Raleigh, NC, USA 
 
{keboyer, eha, rphilli, mdwallis, vouk, lester}@ncsu.edu 
 
 
 
Abstract 
The field of intelligent tutoring systems has 
seen many successes in recent years.  A 
significant remaining challenge is the 
automatic creation of corpus-based tutorial 
dialogue management models.  This paper 
reports on early work toward this goal.  We 
identify tutorial dialogue modes in an 
unsupervised fashion using hidden Markov 
models (HMMs) trained on input 
sequences of manually-labeled dialogue 
acts and adjacency pairs.  The two best-fit 
HMMs are presented and compared with 
respect to the dialogue structure they 
suggest; we also discuss potential uses of 
the methodology for future work. 
1 Introduction 
 
The field of intelligent tutoring systems has made 
great strides toward bringing the benefits of one-
on-one tutoring to a wider population of learners.  
Some intelligent tutoring systems, called tutorial 
dialogue systems, support learners by engaging in 
rich natural language dialogue, e.g., (Graesser et 
al. 2003; Zinn, Moore & Core 2002; Evens & 
Michael 2006; Aleven, Koedinger & Popescu 
2003; Litman et al 2006; Arnott, Hastings & 
Allbritton 2008; VanLehn et al 2002).  However, 
creating these systems comes at a high cost: it 
entails handcrafting each pedagogical strategy the 
tutor might use and then realizing these strategies 
in a dialogue management framework that is also 
custom-engineered for the application.  It is hoped 
that the next generation of these systems can 
leverage corpora of tutorial dialogue in order to 
provide more robust dialogue management models 
that capture the discourse phenomena present in 
effective natural language tutoring.   
The structure of tutorial dialogue has 
traditionally been studied by manually examining 
corpora and focusing on cognitive and 
motivational aspects of tutorial strategies (e.g., 
Lepper et al 1993; Graesser, Person & Magliano 
1995).  While these approaches yielded 
foundational results for the field, such analyses 
suffer from two serious limitations:  manual 
approaches are not easily scalable to different or 
larger corpora, and the rigidity of handcrafted 
dialogue structure tagging schemes may not 
capture all the phenomena that occur in practice.   
In contrast, the stochastic nature of dialogue 
lends itself to description through probabilistic 
models.  In tutorial dialogue, some early work has 
adapted language processing techniques, namely n-
gram analyses, to examine human tutors? responses 
to student uncertainty (Forbes-Riley & Litman 
2005), as well as to find correlations between local 
tutoring strategies and student outcomes (Boyer et 
al. 2008).  However, this work is limited by its 
consideration of small dialogue windows. 
Looking at a broader window of turns is often 
accomplished by modeling the dialogue as a 
Markov decision process.  With this approach, 
19
techniques such as reinforcement learning can be 
used to compare potential policies in terms of 
effectiveness for student learning.  Determining 
relevant feature sets (Tetreault & Litman 2008) 
and conducting focussed experiments for localized 
strategy effectiveness (Chi et al 2008) are active 
areas of research in this line of investigation.  
These approches often fix the dialogue structures 
under consideration in order to compare the 
outcomes associated with those structures or the 
features that influence policy choice.    
    In contrast to treating dialogue structure as a 
fixed entity, one approach for modeling the 
progression of complete dialogues involves 
learning the higher-level structure in order to infer 
succinct probabilistic models of the interaction.  
For example, data-driven approaches for 
discovering dialogue structure have been applied to 
corpora of human-human task-oriented dialogue 
using general models of task structure (Bangalore, 
Di Fabbrizio & Stent 2006).  Encouraging results 
have emerged from using a general model of the 
task structure to inform automatic dialogue act 
tagging as well as subtask segmentation.  
    Our current work examines a modeling 
technique that does not require a priori knowledge 
of the task structure:  specifically, we propose to 
use hidden Markov models (HMMs) (Rabiner 
1989) to capture the structure of tutorial dialogue 
implicit within sequences of tagged dialogue acts.  
Such probablistic inference of discourse structure 
has been used in recent work with HMMs for topic 
identification (Barzilay & Lee 2004) and related 
graphical models for segmenting multi-party 
spoken discourse (Purver et al 2006).  
Analogously, our current work focuses on 
identifying dialogic structures that emerge during 
tutorial dialogue.  Our approach is based on the 
premise that at any given point in the tutorial 
dialogue, the collaborative interaction is ?in? a 
dialogue mode (Cade et al 2008) that characterizes 
the nature of the exchanges between tutor and 
student; these modes correspond to the hidden 
states in the HMM.  Results to date suggest that 
meaningful descriptive models of tutorial dialogue 
can be generated by this simple stochastic 
modeling technique.  This paper focuses on the 
comparison of two first-order HMMs:  one trained 
on sequences of dialogue acts, and the second 
trained on sequences of adjacency pairs.   
 
2 Corpus Analysis 
The HMMs were trained on a corpus of human-
human tutorial dialogue collected in the domain of 
introductory computer science.  Forty-three 
learners interacted remotely with one of fourteen 
tutors through a keyboard-to-keyboard remote 
learning environment yielding 4,864 dialogue 
moves. 
2.1 Dialogue Act Tagging 
The tutoring corpus was manually tagged with 
dialogue acts designed to capture the salient 
characteristics of the tutoring process (Table 1). 
 
Tag Act Example 
Q Question Where should I  
Declare i? 
EQ Evaluation Question How does that look? 
S Statement You need a  
closing brace. 
G Grounding Ok.  
EX Extra-Domain You may use  
your book. 
PF Positive Feedback Yes, that?s right. 
LF Lukewarm Feedback Sort of. 
NF Negative Feedback No, that?s not right. 
Table 1. Dialogue Act Tags 
 
    The correspondence between utterances and 
dialogue act tags is one-to-one; compound 
utterances were split by the primary annotator prior 
to the inter-rater reliability study.1  This dialogue 
act tagging effort produced sequences of dialogue 
acts that have been used in their un-altered forms 
to train one of the two HMMs presented here 
(Section 3).      
2.2 Adjacency Pair Identification 
In addition to the HMM trained on sequences of 
individual dialogue acts, another HMM was 
trained on sequences of dialogue act adjacency 
pairs.  The importance of adjacency pairs is well-
established in natural language dialogue (e.g., 
Schlegoff & Sacks 1973), and adjacency pair 
analysis has illuminated important phenomena in 
tutoring as well (Forbes-Riley et al 2007).  The 
                                                           
1 Details of the study procedure used to collect the corpus, as 
well as Kappa statistics for inter-rater reliability, are reported 
in (Boyer et al 2008). 
20
intuition behind adjacency pairs is that certain 
dialogue acts naturally occur together, and by 
grouping these acts we capture an exchange 
between two conversants in a single structure.  
This formulation is of interest for our purposes 
because when treating sequences of dialogue acts 
as a Markov process, with or without hidden states, 
the addition of adjacency pairs may offer a 
semantically richer observation alphabet.   
    To find adjacency pairs we utilize a ?2 test for 
independence of the categorical variables acti and 
acti+1 for all sequential pairs of dialogue acts that 
occur in the corpus.  Only pairs in which 
speaker(acti) ? speaker(acti+1) were considered.  
Table 2 displays a list of all dependent adjacency 
pairs sorted by descending (unadjusted) statistical 
significance; the subscript on each dialogue act tag 
indicates tutor (t) or student (s). 
    An adjacency pair joining algorithm was applied 
to join statistically significant pairs of dialogue 
acts (p<0.01) into atomic units according to a 
priority determined by the strength of the statistical 
significance.  Dialogue acts that were ?left out? of 
adjacency pair groupings were treated as atomic 
elements in subsequent analysis.  Figure 1 
illustrates the application of the adjacency pair 
joining algorithm on a sequence of dialogue acts 
from the corpus. 
 
 
Figure 1.  DA Sequence Before/After Joining 
3 HMM of Dialogue Structure 
A hidden Markov model is defined by three 
constituents:  1) the set of hidden states (dialogue 
modes), each characterized by its emission 
probability distribution over the possible 
observations (dialogue acts and/or adjacency 
pairs), 2) the transition probability matrix among 
observations (dialogue acts and/or adjacency 
pairs), 2) the transition probability matrix among 
 
acti acti+1 
P(acti+1|   
    acti) 
P(acti+1| 
   ?acti) 
?2 
val p-val 
EQs PFt 0.48 0.07 654 <0.0001 
Gs Gt 0.27 0.03 380 <0.0001 
EXs EXt 0.34 0.03 378 <0.0001 
EQt PFs 0.18 0.01 322 <0.0001 
EQt Ss 0.24 0.03 289 <0.0001 
EQs LFt 0.13 0.01 265 <0.0001 
Qt Ss 0.65 0.04 235 <0.0001 
EQt LFs 0.07 0.00 219 <0.0001 
Qs St 0.82 0.38 210 <0.0001 
EQs NFt 0.08 0.01 207 <0.0001 
EXt EXs 0.19 0.02 177 <0.0001 
NFs Gt 0.29 0.03 172 <0.0001 
EQt NFs 0.11 0.01 133 <0.0001 
Ss Gt 0.16 0.03 95 <0.0001 
Ss PFt 0.30 0.10 90 <0.0001 
St Gs 0.07 0.04 36 <0.0001 
PFs Gt 0.14 0.04 34 <0.0001 
LFs Gt 0.22 0.04 30 <0.0001 
St EQs 0.11 0.07 29 <0.0001 
Gt EXs 0.07 0.03 14 0.002 
St Qs 0.07 0.05 14 0.0002 
Gt Gs 0.10 0.05 9 0.0027 
EQt EQs 0.13 0.08 8 0.0042 
Table 2. All Dependent Adjacency Pairs 
 
hidden states, and 3) the initial hidden state 
(dialogue mode) probability distribution.   
3.1  Discovering Number of Dialogue Modes 
In keeping with the goal of automatically 
discovering dialogue structure, it was desirable to 
learn n, the best number of hidden states for the 
HMM, during modeling.  To this end, we trained 
and ten-fold cross-validated seven models, each 
featuring randomly-initialized parameters, for each 
number of hidden states n from 2 to 15, inclusive.2  
The average log-likelihood fit from ten-fold cross-
                                                           
2 n=15 was chosen as an initial maximum number of states 
because it comfortably exceeded our hypothesized range of 3 
to 7 (informed by the tutoring literature).  The Akaike 
Information Criterion measure steadily worsened above n = 5, 
confirming no need to train models with n > 15. 
21
validation was computed across all seven models 
for each n, and this average log-likelihood ln was 
used to compute the Akaike Information Criterion, 
a maximum-penalized likelihood estimator that 
prefers simpler models (Scott 2002).  This 
modeling approach was used to train HMMs on 
both the dialogue act and the adjacency pair input 
sequences. 
3.2  Best-Fit Models 
The input sequences of individual dialogue acts 
contain 16 unique symbols because each of the 8 
dialogue act tags (Table 1) was augmented with a 
label of the speaker, either tutor or student.  The 
best-fit HMM for this input sequence contains 
nDA=5 hidden states.  The adjacency pair input 
sequences contain 39 unique symbols, including all 
dependent adjacency pairs (Table 2) along with all 
individual dialogue acts because each dialogue act 
occurs at some point outside an adjacency pair.  
The best-fit HMM for this input sequence contains 
nAP=4 hidden states.  In both cases, the best-fit 
number of dialogue modes implied by the hidden 
states is within the range of what is often 
considered in traditional tutorial dialogue analysis 
(Cade et al 2008; Graesser, Person & Magliano 
1995).   
4 Analysis 
Evaluating the impact of grouping the dialogue 
acts into adjacency pairs requires a fine-grained 
examination of the generated HMMs to gain 
insight into how each model interprets the student 
sessions.     
4.1 Dialogue Act HMM 
Figure 2 displays the emission probability 
distributions for the dialogue act HMM.  State 0DA, 
Tutor Lecture,3 is strongly dominated by tutor 
statements with some student questions and 
positive tutor feedback.  State 1DA constitutes 
Grounding/Extra-Domain, a conversational state 
consisting of acknowledgments, backchannels, and 
discussions that do not relate to the computer 
science task.  State 2DA, Student Reflection, 
                                                           
3 For simplicity, the states of each HMM have been named 
according to an intuitive interpretation of the emission 
probability distribution.   
generates student evaluation questions, statements, 
and positive and negative feedback.  State 3DA is 
comprised of tutor utterances, with positive 
feedback occurring most commonly followed by 
statements, grounding, lukewarm feedback, and 
negative feedback.  This state is interpreted as a 
Tutor Feedback mode.  Finally, State 4DA, Tutor 
Lecture/Probing, is characterized by tutor 
statements and evaluative questions with some 
student grounding statements.   
 
 
Figure 2.  Emission Probability Distributions for 
Dialogue Act HMM 
 
    The state transition diagram (Figure 3) illustrates 
that Tutor Lecture (0DA) and Grounding/Extra-
Domain (1DA) are stable states whose probability of 
self-transition is high:  0.75 and 0.79, respectively.  
Perhaps not surprisingly, Student Reflection (2DA) 
is most likely to transition to Tutor Feedback (3DA) 
with probability 0.77.  Tutor Feedback (3DA) 
transitions to Tutor Lecture (0DA) with probability 
0.60, Tutor Lecture/Probing (4DA) with probability 
0.26, and Student Reflection (2DA) with probability 
0.09.  Finally, Tutor Lecture/Probing (4DA) very 
often transitions to Student Reflection (2DA) with 
probability 0.82. 
 
22
 
Figure 3. Transition diagram for dialogue act HMM 
4.2 Adjacency Pair HMM 
Figure 4 displays the emission probability 
distributions for the HMM that was trained on the 
input sequences of adjacency pairs.  State 0AP, 
Tutor Lecture, consists of tutorial statements, 
positive feedback, and dialogue turns initiated by 
student questions.  In this state, student evaluation 
questions occur in adjacency pairs with positive 
tutor feedback, and other student questions are 
answered by tutorial statements.  State 1AP, Tutor 
Evaluation, generates primarily tutor evaluation 
questions, along with the adjacency pair of tutorial 
statements followed by student acknowledgements.  
State 2AP generates conversational grounding and 
extra-domain talk; this Grounding/Extra-Domain 
state is dominated by the adjacency pair of student 
grounding followed by tutor grounding.  State 3AP 
is comprised of several adjacency pairs:  student 
questions followed by tutor answers, student 
statements with positive tutor feedback, and 
student evaluation questions followed by positive 
feedback.  This Question/Answer state also 
generates some tutor grounding and student 
evaluation questions outside of adjacency pairs.   
 
 
Figure 4.  Emission Probability Distributions for 
Adjacency Pair HMM 
 
 
Figure 5. Transition diagram for adjacency pair HMM 
0DA 
3DA 
2DA 
1DA 
4DA 
p > 0.5 
0.1 ? p ? 0.50 
0.05 ? p < 0.1 
0AP 
3AP 
2AP 
1AP 
p > 0.5 
0.1 ? p ? 0.50 
0.05 ? p < 0.1 
23
 4.3 Dialogue Mode Sequences 
In order to illustrate how the above models fit the 
data, Figure 6 depicts the progression of dialogue 
modes that generate an excerpt from the corpus. 
 
 
Figure 6.  Best-fit sequences of hidden states 
In both models, the most commonly-occurring 
dialogue mode is Tutor Lecture, which generates 
45% of observations in the dialogue act model and 
around 60% in the adjacency pair model.  
Approximately 15% of the dialogue act HMM 
observations are fit to each of states Student 
Reflection, Tutor Feedback, and Tutor 
Lecture/Probing.  This model spends the least 
time, around 8%, in Grounding/Extra Domain.  
The adjacency pair model fits approximately 15% 
of its observations to each of Tutor Evaluation and 
Question/Answer, with around 8% in 
Grounding/Extra-Domain.   
4.4 Model Comparison 
While the two models presented here describe the 
same corpus, it is important to exercise caution 
when making direct structural comparisons.  The 
models contain neither the same number of hidden 
states nor the same emission symbol alphabet; 
therefore, our comparison will be primarily 
qualitative.  It is meaningful to note, however, that 
the adjacency pair model with nAP=4 achieved an 
average log-likelihood fit on the training data that 
was 5.8% better than the same measure achieved 
by the dialogue act model with nDA=5, despite the 
adjacency pair input sequences containing greater 
than twice the number of unique symbols.4   
                                                           
4 This comparison is meaningful because the models depicted 
here provided the best fit among all sizes of models trained for 
the same input scenario. 
    Our qualitative comparison begins by examining 
the modes that are highly similar in the two 
models.  State 2AP generates grounding and extra-
domain statements, as does State 1DA.  These two 
states both constitute a Grounding/Extra-Domain 
dialogue mode.  One artifact of the tutoring study 
design is that all sessions begin in this state due to 
a compulsory greeting that signaled the start of 
each session.  More precisely, the initial state 
probability distribution for each HMM assigns 
probability 1 to this state and probability 0 to all 
other states.     
    Another dialogue mode that is structurally 
similar in the two models is Tutor Lecture, in 
which the majority of utterances are tutor 
statements.  This mode is captured in State 0 in 
both models, with State 0AP implying more detail 
than State 0DA because it is certain in the former 
that some of the tutor statements and positive 
feedback occurred in response to student questions.  
While student questions are present in State 0DA, no 
such precise ordering of the acts can be inferred, as 
discussed in Section 1.    
    Other states do not have one-to-one 
correspondence between the two models.  State 
2DA, Student Reflection, generates only student 
utterances and the self-transition probability for the 
state is very low; the dialogue usually visits State 
2DA for one turn and then transitions immediately 
to another state.  Although this aspect of the model 
reflects the fact that students rarely keep the floor 
for more than one utterance at a time in the corpus, 
such quick dialogue mode transitions are 
inconsistent with an intuitive understanding of 
tutorial dialogue modes as meta-structures that 
usually encompass more than one dialogue turn.  
This phenomenon is perhaps more accurately 
captured in the adjacency pair model.  For 
example, the dominant dialogue act of State 2DA is 
a student evaluation question (EQs).  In contrast, 
these dialogue acts are generated as part of an 
adjacency pair by State 3AP; this model joins the 
student questions with subsequent positive 
feedback from the tutor rather than generating the 
question and then transitioning to a new dialogue 
mode.  Further addressing the issue of frequent 
state transitions is discussed as future work in 
Section 6. 
     
24
5 Discussion and Limitations 
Overall, the adjacency pair model is preferable for 
our purposes because its structure lends itself more 
readily to interpretation as a set of dialogue modes 
each of which encompasses more than one 
dialogue move.  This structural property is 
guaranteed by the inclusion of adjacency pairs as 
atomic elements.  In addition, although the set of 
emission symbols increased to include significant 
adjacency pairs along with all dialogue acts, the 
log-likelihood fit of this model was slightly higher 
than the same measure for the HMM trained on the 
sequences of dialogue acts alone.  The remainder 
of this section focuses on properties of the 
adjacency pair model. 
    One promising result of this early work emerges 
from the fact that by applying hidden Markov 
modeling to sequences of adjacency pairs, 
meaningful dialogue modes have emerged that are 
empirically justified.  The number of these 
dialogue modes is consistent with what researchers 
have traditionally used as a set of hypothesized 
tutorial dialogue modes.  Moreover, the 
composition of the dialogue modes reflects some 
recognizable aspects of tutoring sessions:  tutors 
teach through the Tutor Lecture mode and give 
feedback on student knowledge in a Tutor 
Evaluation mode.  Students ask questions and state 
their own perception of their knowledge in a 
Question/Answer mode.  Both parties engage in 
?housekeeping? talk containing such things as 
greetings and acknowledgements, and sometimes, 
even in a controlled environment, extra-domain 
conversation occurs between the conversants in the 
Grounding/Extra-Domain mode.   
    Although the tutorial modes discovered may not 
map perfectly to sets of handcrafted tutorial 
dialogue modes from the literature (e.g., Cade et 
al. 2008), it is rare for such a perfect mapping to 
exist even between those sets of handcrafted 
modes.  In addition, the HMM framework allows 
for succinct probabilistic description of the 
phenomena at work during the tutoring session:  
through the state transition matrix, we can see the 
back-and-forth flow of the dialogue among its 
modes. 
6 Conclusions and Future Work 
Automatically learning dialogue structure is an 
important step toward creating more robust tutorial 
dialogue management systems.  We have presented 
two hidden Markov models in which the hidden 
states are interpreted as dialogue modes for task-
oriented tutorial dialogue.  These models were 
learned in an unsupervised fashion from manually-
labeled dialogue acts.  HMMs offer concise 
stochastic models of the complex interaction 
patterns occurring in natural language tutorial 
dialogue.  The evidence suggests this 
methodology, which as presented requires only a 
sequence of dialogue acts as input, holds promise 
for automatically discovering the structure of 
tutorial dialogue.   
    Future work will involve conducting evaluations 
to determine the benefits gained by using HMMs 
compared to simpler statistical models.  In 
addition, it is possible that more general types of 
graphical models will prove useful in overcoming 
some limitations of HMMs, such as their arbitrarily 
frequent state transitions, to more readily capture 
the phenomena of interest.  The descriptive insight 
offered by these exploratory models may also be 
increased by future work in which the input 
sequences are enhanced with information about the 
surface-level content of the utterance.  In addition, 
knowledge of the task state within the tutoring 
session can be used to segment the dialogue in 
meaningful ways to further refine model structure.   
    It is also hoped that these models can identify 
empirically-derived tutorial dialogue structures that 
can be associated with measures of effectiveness 
such as student learning (Soller & Stevens 2007).  
These lines of investigation could inform the 
development of next-generation natural language 
tutorial dialogue systems.   
Acknowledgments 
Thanks to Marilyn Walker and Dennis Bahler for 
insightful early discussions on the dialogue and machine 
learning aspects of this work, respectively.  This 
research was supported by the National Science 
Foundation under Grants REC-0632450, IIS-0812291, 
CNS-0540523, and GRFP.  Any opinions, findings, and 
conclusions or recommendations expressed in this 
material are those of the authors and do not necessarily 
reflect the views of the National Science Foundation. 
25
 
References 
Aleven, V., K. Koedinger, and O. Popescu. 2003. A 
tutorial dialog system to support self-explanation: 
Evaluation and open questions. Proceedings of the 
11th International Conference on Artificial 
Intelligence in Education: 39-46. 
Arnott, E., P. Hastings, and D. Allbritton. 2008. 
Research methods tutor: Evaluation of a dialogue-
based tutoring system in the classroom. Behavioral 
Research Methods 40(3): 694-698. 
Bangalore, S., Di Fabbrizio, G., and Stent, A. 2006. 
Learning the structure of task-driven human-human 
dialogs.  Proceedings of the 21st International 
Conference on Computational Linguistics and 44th 
Annual Meeting of the ACL: 201-208. 
Barzilay, R., and Lee, L. 2004. Catching the drift: 
Probabilistic content models, with applications to 
generation and summarization.  Proceedings of 
NAACL HLT: 113?120. 
Boyer, K. E., Phillips, R., Wallis, M., Vouk, M., and 
Lester, J. 2008. Balancing cognitive and 
motivational scaffolding in tutorial dialogue.  
Proceedings of the 9th International Conference on 
Intelligent Tutoring Systems: 239-249. 
Cade, W., Copeland, J., Person, N., and D'Mello, S. 
2008. Dialog modes in expert tutoring.  Proceedings 
of the 9th International Conference on Intelligent 
Tutoring Systems: 470-479. 
Chi, M., Jordan, P., VanLehn, K., and Hall, M. 2008. 
Reinforcement learning-based feature selection for 
developing pedagogically effective tutorial dialogue 
tactics.  Proceedings of the 1st International 
Conference  on Educational Data Mining: 258-265. 
Evens, M., and J. Michael. 2006. One-on-one tutoring 
by humans and computers. Lawrence Erlbaum 
Associates, Mahwah, New Jersey. 
Forbes-Riley, K., and Litman, D. J. 2005. Using 
bigrams to identify relationships between student 
certainness states and tutor responses in a spoken 
dialogue corpus. Proceedings of the 6th SIGdial 
Workshop on Discourse and Dialogue: 87-96. 
Forbes-Riley, K., Rotaru, M., Litman, D. J., and 
Tetreault, J. 2007. Exploring affect-context 
dependencies for adaptive system development. 
Proceedings of NAACL HLT: 41-44. 
Graesser, A., G. Jackson, E. Mathews, H. Mitchell, A. 
Olney, M. Ventura, and P. Chipman. 2003. 
Why/AutoTutor: A test of learning gains from a 
physics tutor with natural language dialog. 
Proceedings of the Twenty-Fifth Annual Conference 
of the Cognitive Science Society: 1-6. 
Graesser, A. C., N. K. Person, and J. P. Magliano. 1995. 
Collaborative dialogue patterns in naturalistic one-
to-one tutoring. Applied Cognitive Psychology 9(6): 
495?522. 
Lepper, M. R., M. Woolverton, D. L. Mumme, and J. L. 
Gurtner. 1993. Motivational techniques of expert 
human tutors: Lessons for the design of computer-
based tutors. Pages 75-105 in S. P. Lajoie, and S. J. 
Derry, editors. Computers as cognitive tools. 
Lawrence Erlbaum Associates, Hillsdale, New 
Jersey. 
Litman, D. J., C. P. Ros?, K. Forbes-Riley, K. VanLehn, 
D. Bhembe, and S. Silliman. 2006. Spoken versus 
typed human and computer dialogue tutoring. 
International Journal of Artificial Intelligence in 
Education 16(2): 145-170. 
Purver, M., Kording, K. P., Griffiths, T. L., and 
Tenenbaum, J. B. 2006. Unsupervised topic 
modelling for multi-party spoken discourse.  
Proceedings of the 21st International Conference on 
Computational Linguistics and 44th Annual Meeting 
of the ACL: 17-24. 
Rabiner, L. R. 1989. A tutorial on hidden Markov 
models and selected applications in speech 
recognition. Proceedings of the IEEE 77(2): 257-
286. 
Schlegoff, E., and H. Sacks. 1973. Opening up closings. 
Semiotica 7(4): 289-327. 
Scott, S. L. 2002. Bayesian methods for hidden Markov 
models: Recursive computing in the 21st century. 
Journal of the American Statistical Association 
97(457): 337-352. 
Soller, A., and R. Stevens. 2007. Applications of 
stochastic  analyses for collaborative learning and 
cognitive assessment. Pages 217-253 in G. R. 
Hancock, and K. M. Samuelsen, editors. Advances 
in latent variable mixture models. Information Age 
Publishing. 
Tetreault, J. R., and D. J. Litman. 2008. A 
reinforcement learning approach to evaluating state 
representations in spoken dialogue systems. Speech 
Communication 50(8-9): 683-696. 
VanLehn, K., P. W. Jordan, C. P. Rose, D. Bhembe, M. 
Bottner, A. Gaydos, M. Makatchev, U. 
Pappuswamy, M. Ringenberg, and A. Roque. 2002. 
The architecture of Why2-atlas: A coach for 
qualitative physics essay writing. Proceedings of 
Intelligent Tutoring Systems Conference: 158?167. 
Zinn, C., Moore, J. D., and Core, M. G. 2002. A 3-tier 
planning architecture for managing tutorial dialogue.  
Proceedings of the 6th International Conference on 
Intelligent Tutoring Systems: 574-584. 
26
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 1190?1199,
Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational Linguistics
An Affect-Enriched Dialogue Act Classification Model  for Task-Oriented Dialogue 
Kristy  Elizabeth  Boyer Joseph F. Grafsgaard Eun Young  Ha Robert  Phillips* James C.  Lester  Department of Computer Science North Carolina State University Raleigh, NC, USA  * Dual Affiliation with Applied Research Associates, Inc. Raleigh, NC, USA  {keboyer, jfgrafsg, eha, rphilli, lester}@ncsu.edu 
 
 
Abstract 
Dialogue act classification is a central chal-lenge for dialogue systems. Although the im-portance of emotion in human dialogue is widely recognized, most dialogue act classifi-cation models make limited or no use of affec-tive channels in dialogue act classification. This paper presents a novel affect-enriched dialogue act classifier for task-oriented dia-logue that models facial expressions of users, in particular, facial expressions related to con-fusion. The findings indicate that the affect-enriched classifiers perform significantly bet-ter for distinguishing user requests for feed-back and grounding dialogue acts within textual dialogue. The results point to ways in which dialogue systems can effectively lever-age affective channels to improve dialogue act classification.  1 Introduction Dialogue systems aim to engage users in rich, adaptive natural language conversation. For these systems, understanding the role of a user?s utter-ance in the broader context of the dialogue is a key challenge (Sridhar, Bangalore, & Narayanan, 2009). Central to this endeavor is dialogue act classification, which categorizes the intention be-hind the user?s move (e.g., asking a question, providing declarative information). Automatic dia-logue act classification has been the focus of a 
large body of research, and a variety of approach-es, including sequential models (Stolcke et al, 2000), vector-based models (Sridhar, Bangalore, & Narayanan, 2009), and most recently, feature-enhanced latent semantic analysis (Di Eugenio, Xie, & Serafin, 2010), have shown promise. These models may be further improved by leveraging regularities of the dialogue from both linguistic and extra-linguistic sources. Users? expressions of emotion are one such source. Human interaction has long been understood to include rich phenomena consisting of verbal and nonverbal cues, with facial expressions playing a vital role (Knapp & Hall, 2006; McNeill, 1992; Mehrabian, 2007; Russell, Bachorowski, & Fernandez-Dols, 2003; Schmidt & Cohn, 2001). While the importance of emotional expressions in dialogue is widely recognized, the majority of dia-logue act classification projects have focused either peripherally (or not at all) on emotion, such as by leveraging acoustic and prosodic features of spo-ken utterances to aid in online dialogue act classi-fication (Sridhar, Bangalore, & Narayanan, 2009). Other research on emotion in dialogue has in-volved detecting affect and adapting to it within a dialogue system (Forbes-Riley, Rotaru, Litman, & Tetreault, 2009; L?pez-C?zar, Silovsky, & Griol, 2010), but this work has not explored leveraging affect information for automatic user dialogue act classification. Outside of dialogue, sentiment anal-ysis within discourse is an active area of research (L?pez-C?zar et al, 2010), but it is generally lim-
1190
ited to modeling textual features and not multi-modal expressions of emotion such as facial ac-tions. Such multimodal expressions have only just begun to be explored within corpus-based dialogue research (Calvo & D'Mello, 2010; Cavicchio, 2009).   This paper presents a novel affect-enriched dia-logue act classification approach that leverages knowledge of users? facial expressions during computer-mediated textual human-human dia-logue. Intuitively, the user?s affective state is a promising source of information that may help to distinguish between particular dialogue acts (e.g., a confused user may be more likely to ask a ques-tion). We focus specifically on occurrences of stu-dents? confusion-related facial actions during task-oriented tutorial dialogue.  Confusion was selected as the focus of this work for several reasons. First, confusion is known to be prevalent within tutoring, and its implications for student learning are thought to run deep (Graesser, Lu, Olde, Cooper-Pye, & Whitten, 2005). Second, while identifying the ?ground truth? of emotion based on any external display by a user presents challenges, prior research has demonstrated a correlation between particular faci-al action units and confusion during learning (Craig, D'Mello, Witherspoon, Sullins, & Graesser, 2004; D'Mello, Craig, Sullins, & Graesser, 2006; McDaniel et al, 2007). Finally, automatic facial action recognition technologies are developing rap-idly, and confusion-related facial action events are among those that can be reliably recognized auto-matically (Bartlett et al, 2006; Cohn, Reed, Ambadar, Xiao, & Moriyama, 2004; Pantic & Bartlett, 2007; Zeng, Pantic, Roisman, & Huang, 2009). This promising development bodes well for the feasibility of automatic real-time confusion detection within dialogue systems.  2 Background and Related Work 2.1 Dialogue Act Classification Because of the importance of dialogue act classifi-cation within dialogue systems, it has been an ac-tive area of research for some time. Early work on automatic dialogue act classification modeled dis-course structure with hidden Markov models, ex-perimenting with lexical and prosodic features, and applying the dialogue act model as a constraint to 
aid in automatic speech recognition (Stolcke et al, 2000). In contrast to this sequential modeling ap-proach, which is best suited to offline processing, recent work has explored how lexical, syntactic, and prosodic features perform for online dialogue act tagging (when only partial dialogue sequences are available) within a maximum entropy frame-work (Sridhar, Bangalore, & Narayanan, 2009). A recently proposed alternative approach involves treating dialogue utterances as documents within a latent semantic analysis framework, and applying feature enhancements that incorporate such infor-mation as speaker and utterance duration (Di Eugenio et al, 2010). Of the approaches noted above, the modeling framework presented in this paper is most similar to the vector-based maximum entropy approach of Sridhar et al (2009). Howev-er, it takes a step beyond the previous work by in-cluding multimodal affective displays, specifically facial expressions, as features available to an af-fect-enriched dialogue act classification model. 2.2 Detecting Emotions in Dialogue Detecting emotional states during spoken dialogue is an active area of research, much of which focus-es on detecting frustration so that a user can be automatically transferred to a human dialogue agent (L?pez-C?zar et al, 2010). Research on spo-ken dialogue has leveraged lexical features along with discourse cues and acoustic information to classify user emotion, sometimes at a coarse grain along a positive/negative axis (Lee & Narayanan, 2005). Recent work on an affective companion agent has examined user emotion classification within conversational speech (Cavazza et al, 2010). In contrast to that spoken dialogue research, the work in this paper is situated within textual dialogue, a widely used modality of communica-tion for which a deeper understanding of user af-fect may substantially improve system performance. While many projects have focused on linguistic cues, recent work has begun to explore numerous channels for affect detection including facial ac-tions, electrocardiograms, skin conductance, and posture sensors (Calvo & D'Mello, 2010). A recent project in a map task domain investigates some of these sources of affect data within task-oriented dialogue (Cavicchio, 2009). Like that work, the current project utilizes facial action tagging, for 
1191
which promising automatic technologies exist (Bartlett et al, 2006; Pantic & Bartlett, 2007; Zeng, Pantic, Roisman, & Huang, 2009). However, we leverage the recognized expressions of emotion for the task of dialogue act classification.  2.3 Categorizing Emotions within Dialogue and Discourse Sets of emotion taxonomies for discourse and dia-logue are often application-specific, for example, focusing on the frustration of users who are inter-acting with a spoken dialogue system (L?pez-C?zar et al, 2010), or on uncertainty expressed by students while interacting with a tutor (Forbes-Riley, Rotaru, Litman, & Tetreault, 2007). In con-trast, the most widely utilized emotion frameworks are not application-specific; for example, Ekman?s Facial Action Coding System (FACS) has been widely used as a rigorous technique for coding fa-cial movements based on human facial anatomy (Ekman & Friesen, 1978).  Within this framework, facial movements are categorized into facial action units, which represent discrete movements of mus-cle groups. Additionally, facial action descriptors (for movements not derived from facial muscles) and movement and visibility codes are included. Ekman?s basic emotions (Ekman, 1999) have been used in recent work on classifying emotion ex-pressed within blog text (Das & Bandyopadhyay, 2009), while other recent work (Nguyen, 2010) utilizes Russell?s core affect model (Russell, 2003) for a similar task. During tutorial dialogue, students may not fre-quently experience Ekman?s basic emotions of happiness, sadness, anger, fear, surprise, and dis-gust. Instead, students appear to more frequently experience cognitive-affective states such as flow and confusion (Calvo & D'Mello, 2010). Our work leverages Ekman?s facial tagging scheme to identi-fy a particular facial action unit, Action Unit 4 (AU4), that has been observed to correlate with confusion (Craig, D'Mello, Witherspoon, Sullins, & Graesser, 2004; D'Mello, Craig, Sullins, & Graesser, 2006; McDaniel et al, 2007).   2.4 Importance of Confusion in Tutorial Dia-logue Among the affective states that students experience during tutorial dialogue, confusion is prevalent, and its implications for student learning are signif-
icant. Confusion is associated with cognitive dise-quilibrium, a state in which students? existing knowledge is inconsistent with a novel learning experience (Graesser, Lu, Olde, Cooper-Pye, & Whitten, 2005). Students may express such confu-sion within dialogue as uncertainty, to which hu-man tutors often adapt in a context-dependent fashion (Forbes-Riley et al, 2007). Moreover, im-plementing adaptations to student uncertainty with-in a dialogue system can improve the effectiveness of the system (Forbes-Riley et al, 2009).  For tutorial dialogue, the importance of under-standing student utterances is paramount for a sys-tem to positively impact student learning (Dzikovska, Moore, Steinhauser, & Campbell, 2010). The importance of frustration as a cogni-tive-affective state during learning suggests that the presence of student confusion may serve as a useful constraining feature for dialogue act classi-fication of student utterances. This paper explores the use of facial expression features in this way.  3 Task-Oriented Dialogue Corpus The corpus was collected during a textual human-human tutorial dialogue study in the domain of introductory computer science (Boyer, Phillips, et al, 2010). Students solved an introductory com-puter programming problem and carried on textual dialogue with tutors, who viewed a synchronized version of the students? problem-solving work-space. The original corpus consists of 48 dia-logues, one per student. Each student interacted with one of two tutors. Facial videos of students were collected using built-in webcams, but were not shown to the tutors. Video quality was ranked based on factors such as obscured foreheads due to hats or hair, and improper camera position result-ing in students? faces not being fully captured on the video. The highest-quality set contained 14 videos, and these videos were used in this analysis. They have a total running time of 11 hours and 55 minutes, and include dialogues with three female subjects and eleven male subjects.  3.1 Dialogue act annotation The dialogue act annotation scheme (Table 1) was applied manually. The kappa statistic for inter-annotator agreement on a 10% subset of the corpus was ?=0.80, indicating good reliability.   
1192
Table 1. Dialogue act tags and relative frequencies across fourteen dialogues in video corpus Student Dialogue Act Example Rel. Freq. EXTRA-DOMAIN (EX) Little sleep deprived today .08 GROUNDING (G) Ok or Thanks .21 NEGATIVE FEEDBACK WITH ELABORATION (NE) I?m still confused on what this next for loop is doing. .02 NEGATIVE FEEDBACK (N) I don?t see the diff. .04 POSITIVE FEEDBACK WITH ELABORATION (PE) 
It makes sense now that you explained it, but I never used an else if in any of my other programs .04 POSITIVE FEEDBACK (P) Second part complete. .11 QUESTION (Q) Why couldn?t I have said if (i<5) .11 STATEMENT (S) i is my only index .07 
REQUEST FOR FEEDBACK (RF) So I need to create a new method that sees how many elements are in my array? .16 RESPONSE (RSP) You mean not the length but the contents .14 UNCERTAIN FEEDBACK WITH ELABORATION (UE) I?m trying to remember how to copy arrays .008 UNCERTAIN FEEDBACK (U) Not quite yet .008  3.2 Task action annotation The tutoring sessions were task-oriented, focusing on a computer programming exercise. The task had several subtasks consisting of programming mod-ules to be implemented by the student. Each of those subtasks also had numerous fine-grained goals, and student task actions either contributed or did not contribute to the goals. Therefore, to obtain a rich representation of the task, a manual annota-tion along two dimensions was conducted (Boyer, Phillips, et al, 2010). First, the subtask structure was annotated hierarchically, and then each task action was labeled for correctness according to the requirements of the assignment. Inter-annotator agreement was computed on 20% of the corpus at the leaves of the subtask tagging scheme, and re-
sulted in a simple kappa of ?=.56. However, the leaves of the annotation scheme feature an implicit ordering (subtasks were completed in order, and adjacent subtasks are semantically more similar than subtasks at a greater distance); therefore, a weighted kappa is also meaningful to consider for this annotation. The weighted kappa is ?weighted=.80. An annotated excerpt of the corpus is displayed in Table 2.   Table 2. Excerpt from corpus illustrating annota-tions and interplay between dialogue and task 13:38:09 Student: How do I know where to end? [RF] 13:38:26 Tutor: Well you told me how to get how many elements in an array by using .length right? 13:38:26 Student: [Task action:  Subtask 1-a-iv, Buggy] 13:38:56 Tutor: Great 13:38:56 Student: [Task action: Subtask 1-a-v, Correct] 13:39:35 Student: Well is it "array.length"? [RF]  **Facial Expression: AU4 13:39:46 Tutor: You just need to use the correct array name 13:39:46 Student: [Task action:  Subtask 1-a-iv, Buggy] 3.3 Lexical and Syntactic Features In addition to the manually annotated dialogue and task features described above, syntactic features of each utterance were automatically extracted using the Stanford Parser (De Marneffe et al, 2006). From the phrase structure trees, we extracted the top-most syntactic node and its first two children. In the case where an utterance consisted of more than one sentence, only the phrase structure tree of the first sentence was considered. Individual word tokens in the utterances were further processed with the Porter Stemmer (Porter, 1980) in the NLTK package (Loper & Bird, 2004). Our prior work has shown that these lexical and syntactic features are highly predictive of dialogue acts dur-ing task-oriented tutorial dialogue (Boyer, Ha et al 2010).  
1193
4 Facial Action Tagging An annotator who was certified in the Facial Ac-tion Coding System (FACS) (Ekman, Friesen, & Hager, 2002) tagged the video corpus consisting of fourteen dialogues. The FACS certification process requires annotators to pass a test designed to ana-lyze their agreement with reference coders on a set of spontaneous facial expressions (Ekman & Rosenberg, 2005). This annotator viewed the vide-os continuously and paused the playback whenever notable facial displays of Action Unit 4 (AU4: Brow Lowerer) were seen. This action unit was chosen for this study based on its correlations with confusion in prior research (Craig, D'Mello, Witherspoon, Sullins, & Graesser, 2004; D'Mello, Craig, Sullins, & Graesser, 2006; McDaniel et al, 2007). To establish reliability of the annotation, a se-cond FACS-certified annotator independently an-notated 36% of the video corpus (5 of 14 dialogues), chosen randomly after stratification by gender and tutor. This annotator followed the same method as the first annotator, pausing the video at any point to tag facial action events. At any given time in the video, the coder was first identifying whether an action unit event existed, and then de-scribing the facial movements that were present. The annotators also specified the beginning and ending time of each event. In this way, the action unit event tags spanned discrete durations of vary-ing length, as specified by the coders. Because the two coders were not required to tag at the same point in time, but rather were permitted the free-dom to stop the video at any point where they felt a notable facial action event occurred, calculating agreement between annotators required discretiz-ing the continuous facial action time windows across the tutoring sessions. This discretization was performed at granularities of 1/4, 1/2, 3/4, and 1 second, and inter-rater reliability was calculated at each level of granularity (Table 3). Windows in which both annotators agreed that no facial action event was present were tagged by default as neu-tral. Figure 1 illustrates facial expressions that dis-play facial Action Unit 4. 
  Table 3. Kappa values for inter-annotator agree-ment on facial action events  Granularity  ? sec ? sec ? sec 1 sec Presence of AU4 (Brow Lowerer)  .84 .87 .86 .86   
  
  Figure 1. Facial expressions displaying AU4 (Brow Lowerer)  Despite the fact that promising automatic ap-proaches exist to identifying many facial action units (Bartlett et al, 2006; Cohn, Reed, Ambadar, Xiao, & Moriyama, 2004; Pantic & Bartlett, 2007; Zeng, Pantic, Roisman, & Huang, 2009), manual annotation was selected for this project for two reasons. First, manual annotation is more robust than automatic recognition of facial action units, and manual annotation facilitated an exploratory, comprehensive view of student facial expressions during learning through task-oriented dialogue. Although a detailed discussion of the other emo-tions present in the corpus is beyond the scope of this paper, Figure 2 illustrates some other sponta-neous student facial expressions that differ from those associated with confusion.    
1194
   
  Figure 2. Other facial expressions from the corpus 5 Models The goal of the modeling experiment was to de-termine whether the addition of confusion-related facial expression features significantly boosts dia-logue act classification accuracy for student utter-ances.  5.1 Features We take a vector-based approach, in which the fea-tures consist of the following:  Utterance Features ? Dialogue act features: Manually annotated dialogue act for the past three utterances. These features include tutor dialogue acts, annotated with a scheme analogous to that used to annotate student utterances (Boyer et al, 2009). ? Speaker: Speaker for past three utterances ? Lexical features: Word unigrams ? Syntactic features: Top-most syntactic node and its first two children  Task-based Features ? Subtask: Hierarchical subtask structure for past three task actions (semantic pro-gramming actions taken by student) ? Correctness: Correctness of past three task actions taken by student ? Preceded by task: Indicator for whether the most recent task action immediately pre-ceded the target utterance, or whether it 
was immediately preceded by the last dia-logue move  Facial Expression Features ? AU4_1sec: Indicator for the display of the brow lowerer within 1 second prior to this utterance being sent, for the most recent three utterances ?  AU4_5sec: Indicator for the display of the brow lowerer within 5 seconds prior to this utterance being sent, for the most recent three utterances ? AU4_10sec: Indicator for the display of the brow lowerer within 10 seconds prior to this utterance being sent, for the most recent three utterances  5.2 Modeling Approach A logistic regression approach was used to classify the dialogue acts based on the above feature vec-tors. The Weka machine learning toolkit (Hall et al, 2009) was used to learn the models and to first perform feature selection in a best-first search. Lo-gistic regression is a generalized maximum likeli-hood model that discriminates between pairs of output values by calculating a feature weight vec-tor over the predictors.  The goal of this work is to explore the utility of confusion-related facial features in the context of particular dialogue act types. For this reason, a specialized classifier was learned by dialogue act. 5.3 Classification Results The classification accuracy and kappa for each specialized classifier is displayed in Table 4. Note that kappa statistics adjust for the accuracy that would be expected by majority-baseline chance; a kappa statistic of zero indicates that the classifier performed equal to chance, and a positive kappa statistic indicates that the classifier performed bet-ter than chance. A kappa of 1 constitutes perfect agreement. As the table illustrates, the feature se-lection chose to utilize the AU4 feature for every dialogue act except STATEMENT (S). When consid-ering the accuracy of the model across the ten folds, two of the affect-enriched classifiers exhibit-ed statistically significantly better performance. For GROUNDING (G) and REQUEST FOR FEEDBACK (RF), the facial expression features significantly 
1195
improved the classification accuracy compared to a model that was learned without affective features.  6 Discussion Dialogue act classification is an essential task for dialogue systems, and it has been addressed with a variety of modeling approaches and feature sets. We have presented a novel approach that treats facial expressions of students as constraining fea-tures for an affect-enriched dialogue act classifica-tion model in task-oriented tutorial dialogue. The results suggest that knowledge of the student?s confusion-related facial expressions can signifi-cantly enhance dialogue act classification for two types of dialogue acts, GROUNDING and REQUEST FOR FEEDBACK.   Table 4. Classification accuracy and kappa for spe-cialized DA classifiers. Statistically significant differences (across ten folds, one-tailed t-test) are shown in bold.    Classifier with AU4 Classifier without AU4  Dialogue Act % acc ? % acc ? p-value EX 90.7 .62 89.0 .28 >.05 G 92.6 .76 91 .71 .018 P 93 .49 92.2 .40 >.05 Q 94.6 .72 94.2 .72 >.05 S Not chosen in feat. sel. 93 .22 n/a RF 90.7 .62 88.3 .53 .003 
RSP 93 .68 95 .75 >.05 NE * *  N * * PE * * U * * UE * * *Too few instances for ten-fold cross-validation. 
6.1 Features Selected for Classification Out of more than 1500 features available during feature selection, each of the specialized dialogue act classifiers selected between 30 and 50 features in each condition (with and without affect fea-tures). To gain insight into the specific features that were useful for classifying these dialogue acts, it is useful to examine which of the AU4 history features were chosen during feature selection.  For GROUNDING, features that indicated the presence of absence of AU4 in the immediately preceding utterance, either at the 1 second or 5 se-cond granularity, were selected. Absence of this confusion-related facial action unit was associated with a higher probability of a grounding act, such as an acknowledgement. This finding is consistent with our understanding of how students and tutors interacted in this corpus; when a student experi-enced confusion, she would be unlikely to then make a simple grounding dialogue move, but in-stead would tend to inspect her computer program, ask a question, or wait for the tutor to explain more. For REQUEST FOR FEEDBACK, the predictive features were presence or absence of AU4 within ten seconds of the longest available history (three turns in the past), as well as the presence of AU4 within five seconds of the current utterance (the utterance whose dialogue act is being classified). This finding suggests that there may be some lag between the student experiencing confusion and then choosing to make a request for feedback, and that the confusion-related facial expressions may re-emerge as the student is making a request for feedback, since the five-second window prior to the student sending the textual dialogue message would overlap with the student?s construction of the message itself.    Although the improvements seen with AU4 fea-tures for QUESTION, POSITIVE FEEDBACK, and EXTRA-DOMAIN acts were not statistically reliable, examining the AU4 features that were selected for classifying these moves points toward ways in which facial expressions may influence classifica-tion of these acts (Table 5).      
1196
Table 5. Number of features, and AU4 features selected, for specialized DA classifiers  Dialogue Act # fea-tures selected AU4 features selected G 43 One utterance ago: AU4_1sec, AU4_5sec 
RF 37 Three utterances ago: AU4_10sec Target utterance: AU4_5sec EX 50 Three utterances ago: AU4_1sec P 36 Current utterance: AU4_10sec Q 30 One utterance ago: AU4_5sec  6.2 Implications The results presented here demonstrate that lever-aging knowledge of user affect, in particular of spontaneous facial expressions, may improve the performance of dialogue act classification models. Perhaps most interestingly, displays of confusion-related facial actions prior to a student dialogue move enabled an affect-enriched classifier to rec-ognize requests for feedback with significantly greater accuracy than a classifier that did not have access to the facial action features. Feedback is known to be a key component of effective tutorial dialogue, through which tutors provide adaptive help (Shute, 2008). Requesting feedback also seems to be an important behavior of students, characteristically engaged in more frequently by women than men, and more frequently by students with lower incoming knowledge than by students with higher incoming knowledge (Boyer, Vouk, & Lester, 2007). 6.3 Limitations The experiments reported here have several nota-ble limitations. First, the time-consuming nature of manual facial action tagging restricted the number of dialogues that could be tagged. Although the highest quality videos were selected for annotation, other medium quality videos would have been suf-ficiently clear to permit tagging, which would have increased the sample size and likely revealed sta-tistically significant trends. For example, the per-
formance of the affect-enriched classifier was bet-ter for dialogue acts of interest such as positive feedback and questions, but this difference was not statistically reliable.  An additional limitation stems from the more fundamental question of which affective states are indicated by particular external displays. The field is only just beginning to understand facial expres-sions during learning and to correlate these facial actions with emotions. Additional research into the ?ground truth? of emotion expression will shed additional light on this area. Finally, the results of manual facial action annotation may constitute up-per-bound findings for applying automatic facial expression analysis to dialogue act classification. 7 Conclusions and Future Work Emotion plays a vital role in human interactions. In particular, the role of facial expressions in human-human dialogue is widely recognized. Facial ex-pressions offer a promising channel for under-standing the emotions experienced by users of dialogue systems, particularly given the ubiquity of webcam technologies and the increasing number of dialogue systems that are deployed on webcam-enabled devices. This paper has reported on a first step toward using knowledge of user facial expres-sions to improve a dialogue act classification mod-el for tutorial dialogue, and the results demonstrate that facial expressions hold great promise for dis-tinguishing the pedagogically relevant dialogue act REQUEST FOR FEEDBACK, and the conversational moves of GROUNDING. These early findings highlight the importance of future work in this area. Dialogue act classifica-tion models have not fully leveraged some of the techniques emerging from work on sentiment anal-ysis. These approaches may prove particularly use-ful for identifying emotions in dialogue utterances. Another important direction for future work in-volves more fully exploring the ways in which af-fect expression differs between textual and spoken dialogue. Finally, as automatic facial tagging tech-nologies mature, they may prove powerful enough to enable broadly deployed dialogue systems to feasibly leverage facial expression data in the near future.    
1197
Acknowledgments This work is supported in part by the North Caroli-na State University Department of Computer Sci-ence and by the National Science Foundation through Grants REC-0632450, IIS-0812291, DRL-1007962 and the STARS Alliance Grant CNS-0739216. Any opinions, findings, conclusions, or recommendations expressed in this report are those of the participants, and do not necessarily represent the official views, opinions, or policy of the Na-tional Science Foundation.  References  A. Andreevskaia and S. Bergler. 2008. When specialists and generalists work together: Overcoming do-main dependence in sentiment tagging. Proceed-ings of the Annual Meeting of the Association for Computational Linguistics and Human Language Technologies (ACL HLT), 290-298.  M.S. Bartlett, G. Littlewort, M. Frank, C. Lainscsek, I. Fasel, and J. Movellan. 2006. Fully Automatic Facial Action Recognition in Spontaneous Behav-ior. 7th International Conference on Automatic Face and Gesture Recognition (FGR06), 223-230.  K.E. Boyer, M. Vouk, and J.C. Lester. 2007. The influ-ence of learner characteristics on task-oriented tu-torial dialogue. Proceedings of the International Conference on Artificial Intelligence in Educa-tion, 365?372.  K.E. Boyer, E.Y. Ha, R. Phillips, M.D. Wallis, M. Vouk, and J.C. Lester. 2010. Dialogue act model-ing in a complex task-oriented domain. Proceed-ings of the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), 297-305.  K.E. Boyer, R. Phillips, E.Y. Ha, M.D. Wallis, M.A. Vouk, and J.C. Lester. 2009. Modeling dialogue structure with adjacency pair analysis and hidden Markov models. Proceedings of the Annual Con-ference of the North American Chapter of the As-sociation for Computational Linguistics: Short Papers, 49-52.  K.E. Boyer, R. Phillips, E.Y. Ha, M.D. Wallis, M.A. Vouk, and J.C. Lester. 2010. Leveraging hidden dialogue state to select tutorial moves. Proceed-ings of the NAACL HLT 2010 Fifth Workshop on Innovative Use of NLP for Building Educational Applications, 66-73. R.A. Calvo and S. D?Mello. 2010. Affect Detection: An Interdisciplinary Review of Models, Methods, and Their Applications. IEEE Transactions on Affec-tive Computing, 1(1): 18-37. 
M. Cavazza, R.S.D.L. C?mara, M. Turunen, J. Gil, J. Hakulinen, N. Crook, et al 2010. How was your day? An affective companion ECA prototype. Proceedings of the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), 277-280.  F. Cavicchio. 2009. The modulation of cooperation and emotion in dialogue: the REC Corpus. Proceed-ings of the ACL-IJCNLP 2009 Student Research Workshop, 43-48.  J.F. Cohn, L.I. Reed, Z. Ambadar, J. Xiao, and T. Mori-yama. 2004. Automatic Analysis and Recognition of Brow Actions and Head Motion in Spontaneous Facial Behavior. IEEE International Conference on Systems, Man and Cybernetics, 610-616. S.D. Craig, S. D?Mello, A. Witherspoon, J. Sullins, and A.C. Graesser. 2004. Emotions during learning: The first steps toward an affect sensitive intelli-gent tutoring system. In J. Nall and R. Robson (Eds.), E-learn 2004: World conference on E-learning in Corporate, Government, Healthcare, & Higher Education, 241-250.  D. Das and S. Bandyopadhyay. 2009. Word to sentence level emotion tagging for Bengali blogs. Proceed-ings of the ACL-IJCNLP Conference, Short Pa-pers, 149-152.  S. Dasgupta and V. Ng. 2009. Mine the easy, classify the hard: a semi-supervised approach to automatic sentiment classification. Proceedings of the 46th Annual Meeting of the ACL and the 4th IJCNLP, 701-709.  B. Di Eugenio, Z. Xie, and R. Serafin. 2010. Dialogue Act Classification, Higher Order Dialogue Struc-ture, and Instance-Based Learning. Dialogue & Discourse, 1(2): 1-24.  M. Dzikovska, J.D. Moore, N. Steinhauser, and G. Campbell. 2010. The impact of interpretation problems on tutorial dialogue. Proceedings of the 48th Annual Meeting of the Association for Com-putational Linguistics, Short Papers, 43-48.  S. D?Mello, S.D. Craig, J. Sullins, and A.C. Graesser. 2006. Predicting Affective States expressed through an Emote-Aloud Procedure from AutoTu-tor?s Mixed- Initiative Dialogue. International Journal of Artificial Intelligence in Education, 16(1): 3-28. P. Ekman. 1999. Basic Emotions. In T. Dalgleish and M. J. Power (Eds.), Handbook of Cognition and Emotion. New York: Wiley. P. Ekman, W.V. Friesen. 1978. Facial Action Coding System. Palo Alto, CA: Consulting Psychologists Press. P. Ekman, W.V. Friesen, and J.C. Hager. 2002. Facial Action Coding System: Investigator?s Guide. Salt Lake City, USA: A Human Face. 
1198
P. Ekman and E.L. Rosenberg (Eds.). 2005. What the Face Reveals: Basic and Applied Studies of Spon-taneous Expression Using the Facial Action Cod-ing System (FACS) (2nd ed.). New York: Oxford University Press. K. Forbes-Riley, M. Rotaru, D.J. Litman, and J. Tetreault. 2007. Exploring affect-context depend-encies for adaptive system development. The Con-ference of the North American Chapter of the Association for Computational Linguistics and Human Language Technologies (NAACL HLT), Short Papers, 41-44.  K. Forbes-Riley, M. Rotaru, D.J. Litman, and J. Tetreault. 2009. Adapting to student uncertainty improves tutoring dialogues. Proceedings of the 14th International Conference on Artificial Intelli-gence in Education (AIED), 33-40.  A.C. Graesser, S. Lu, B. Olde, E. Cooper-Pye, and S. Whitten. 2005. Question asking and eye tracking during cognitive disequilibrium: comprehending illustrated texts on devices when the devices break down. Memory & Cognition, 33(7): 1235-1247.  S. Greene and P. Resnik. 2009. More than words: Syn-tactic packaging and implicit sentiment. Proceed-ings of the 2009 Annual Conference of the North American Chapter of the ACL and Human Lan-guage Technologies (NAACL HLT), 503-511.  M. Hall, E. Frank, G. Holmes, B. Pfahringer, P. Reute-mann, and I.H. Witten. 2009. The WEKA data mining software: An update. SIGKDD Explora-tions, 11(1): 10?18.  R. Iida, S. Kobayashi, and T. Tokunaga. 2010. Incorpo-rating extra-linguistic information into reference resolution in collaborative task dialogue. Proceed-ings of the 48th Annual Meeting of the Associa-tion for Computational Linguistics, 1259-1267.  M.L. Knapp and J.A. Hall. 2006. Nonverbal Communi-cation in Human Interaction (6th ed.). Belmont, CA: Wadsworth/Thomson Learning. C.M. Lee, S.S. Narayanan. 2005. Toward detecting emotions in spoken dialogs. IEEE Transactions on Speech and Audio Processing, 13(2): 293-303.  R. L?pez-C?zar, J. Silovsky, and D. Griol. 2010. F2?New Technique for Recognition of User Emotion-al States in Spoken Dialogue Systems. Proceed-ings of the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), 281-288.  B.T. McDaniel, S. D?Mello, B.G. King, P. Chipman, K. Tapp, and A.C. Graesser. 2007. Facial Features for Affective State Detection in Learning Envi-ronments. Proceedings of the 29th Annual Cogni-tive Science Society, 467-472. D. McNeill. 1992. Hand and mind: What gestures reveal about thought. Chicago: University of Chicago Press. 
A. Mehrabian. 2007. Nonverbal Communication. New Brunswick, NJ: Aldine Transaction. T. Nguyen. 2010. Mood patterns and affective lexicon access in weblogs. Proceedings of the ACL 2010 Student Research Workshop, 43-48.  M. Pantic and M.S. Bartlett. 2007. Machine Analysis of Facial Expressions. In K. Delac and M. Grgic (Eds.), Face Recognition, 377-416. Vienna, Aus-tria: I-Tech Education and Publishing. J.A. Russell. 2003. Core affect and the psychological construction of emotion. Psychological Review, 110(1): 145-172. J.A. Russell, J.A. Bachorowski, and J.M. Fernandez-Dols. 2003. Facial and vocal expressions of emo-tion. Annual Review of Psychology, 54, 329-49. K.L. Schmidt and J.F. Cohn. 2001. Human Facial Ex-pressions as Adaptations: Evolutionary Questions in Facial Expression Research. Am J Phys An-thropol, 33: 3-24. V.J. Shute. 2008. Focus on Formative Feedback. Re-view of Educational Research, 78(1): 153-189.  V.K.R Sridar, S. Bangalore, and S.S. Narayanan. 2009. Combining lexical, syntactic and prosodic cues for improved online dialog act tagging. Computer Speech & Language, 23(4): 407-422. Elsevier Ltd.  A. Stolcke, K. Ries, N. Coccaro, E. Shriberg, R. Bates, D. Jurafsky, et al 2000. Dialogue Act Modeling for Automatic Tagging and Recognition of Con-versational Speech. Computational Linguistics, 26(3): 339-373.  C. Toprak, N. Jakob, and I. Gurevych. 2010. Sentence and expression level annotation of opinions in us-er-generated discourse. Proceedings of the 48th Annual Meeting of the Association for Computa-tional Linguistics, 575-584.  T. Wilson, J. Wiebe, and P. Hoffmann. 2009. Recogniz-ing Contextual Polarity: An Exploration of Fea-tures for Phrase-Level Sentiment Analysis. Computational Linguistics, 35(3): 399-433.  Z. Zeng, M. Pantic, G.I. Roisman, and T.S. Huang. 2009. A Survey of Affect Recognition Methods: Audio, Visual, and Spontaneous Expressions. IEEE Transactions on Pattern Analysis and Ma-chine Intelligence, 31(1): 39-58. 
1199
Proceedings of the NAACL HLT 2010 Workshop on Computational Linguistics and Writing, pages 56?64,
Los Angeles, California, June 2010. c?2010 Association for Computational Linguistics
Exploring Individual Differences in Student Writing with a  
Narrative Composition Support Environment 

Julius Goth and Alok Baikadi and Eun Ha and Jonathan Rowe and Bradford Mott 
and James Lester 
Department of Computer Science 
North Carolina State University 
Raleigh, NC, USA 
{jgoth, abaikad, eha, jprowe, bwmott, lester}@ncsu.edu 
 
 
 
Abstract 
Novice writers face significant challenges as 
they learn to master the broad range of skills 
that contribute to composition. Novice and 
expert writers differ considerably, and devis-
ing effective composition support tools for 
novice writers requires a clear understanding 
of the process and products of writing. This 
paper reports on a study conducted with more 
than one hundred middle grade students inter-
acting with a narrative composition support 
environment. The texts are found to pose im-
portant challenges for state-of-the-art natural 
language processing techniques.  Furthermore, 
the study investigates the language usage of 
middle grade students, the cohesion and co-
herence of the resulting texts, and the relation-
ship between students? language arts skills 
and their writing processes.  The findings sug-
gest that composition support environments 
require robust NLP tools that can account for 
the variations in students? writing in order to 
effectively support each phase of the writing 
process. 
1 Introduction 
Writing is fundamentally complex.  Writers must 
simultaneously consider a constellation of factors 
during composition, including writing task re-
quirements, knowledge of audience, domain 
knowledge, language usage, and tone (Hayes and 
Flower, 1981).  Furthermore, effective writing 
involves sophisticated higher-order cognitive 
skills, such as synthesis of ideas, critical thinking, 
and self-regulation.  Text genres, such as narrative 
or expository texts, also introduce distinct re-
quirements and conventions (Hayes and Flower, 
1981). 
Because writing itself is complex, learning to 
write poses significant challenges for students.  
The central role of writing in communication, 
knowledge organization, and sensemaking points 
to the need to devise methods and tools with which 
writing skills can be effectively taught and learned 
(Graham, 2006).  Intelligent tutoring systems 
(VanLehn, 2006) offer a promising means for de-
livering tailored writing support to students.  How-
ever, developing intelligent tutors to scaffold 
student writing poses a number of technical and 
pedagogical hurdles.  Texts written by novice writ-
ers are likely to exhibit significant variation in 
grammar, cohesion, coherence, and content qual-
ity; these characteristics are likely to be problem-
atic for analysis by current natural language 
processing tools.  Furthermore, students? individ-
ual differences in language arts skills, writing self-
efficacy, domain knowledge, and motivation can 
have pedagogical implications.  An effective intel-
ligent writing tutor must do more than just parse 
and understand student texts; it must also provide 
tailored feedback that fosters effective writing 
processes and enhances student motivation for 
writing.  
This paper explores several key questions for 
the design of intelligent composition support tools 
for novice writers.  First, it investigates the per-
formance of current syntactic parsing tools on a 
corpus of narrative texts written by middle grade 
students during interactions in a narrative composi-
56
tion support environment.  A narrative composi-
tion support environment aims to support the prin-
cipal processes of writing, such as planning, 
revision, and text production.  The second question 
the paper explores is how middle school students? 
language art skills affect the cohesion and coher-
ence of texts produced during interactions with a 
narrative composition support environment.  Third, 
the paper investigates how middle school students? 
language art skills affect their writing processes 
during interactions in a narrative composition sup-
port environment.  Studying the interactions be-
tween the environment?s support mechanisms and 
students? individual differences provides insights 
into the affordances and limitations of novices? 
writing abilities, as well as implications for the 
design of intelligent tutors for narrative writing.  
The study presented here investigates novice 
writers? composition processes during interactions 
with a narrative composition support environment.  
In the study, 127 middle grade students interacted 
with the NARRATIVE THEATRE fable composition 
support environment.  The NARRATIVE THEATRE 
uses a multimedia interface to guide students as 
they select key elements of their fable (e.g., moral, 
setting, characters), prompts students through an 
explicit, timed story planning process, and allows 
students to review their earlier planning decisions 
at any point during writing of the main text.  Stu-
dents? literacy ratings and log data from interac-
tions with the NARRATIVE THEATRE environment 
are analyzed to investigate the differences between 
high- and low-skill students and their practice of 
key composition processes in the NARRATIVE 
THEATRE environment, including planning, text 
production, and revision.  Coh-Metrix (Graesser et 
al., 2004) was also used to analyze the cohesion 
and coherence characteristics of the students? fa-
bles.  The observations from this study offer im-
portant implications for the design of intelligent 
composition support tools for novice writers. 
2 Related Work 
Since Hayes and Flower first proposed their semi-
nal model of writing nearly thirty years ago (1981), 
a rich body of work has investigated the cognitive 
functions supporting written composition.  Founda-
tional results are now in place on the core proc-
esses of writing, including idea generation 
(Galbraith et al, 2009), text production (Berninger 
et al, 2002), and revision (McCutchen et al, 
1997).  Furthermore, a detailed account of the 
composition process has begun to emerge across a 
range of writing experience levels (Graham et al, 
2002) and text genres (Langer, 1985).  
Particularly important for the design of compo-
sition support tools for novices is the emergence of 
a consensus account of the characteristics of nov-
ice writers? narrative composition processes.  Em-
pirical studies have suggested that notable 
differences exist between novice and expert writ-
ers, such as novices? use of knowledge-telling 
practices versus experts? use of knowledge-
transformation practices during text production 
(Bereiter and Scardamalia, 1987).  However, it has 
been argued that even novice writers can employ 
high-level knowledge-transformation processes 
when situated within an appropriate task environ-
ment with effective writing scaffolds (Cameron 
and Moshenko, 1996).  Other work has found that 
students? domain and linguistic knowledge influ-
ences the coherence and quality of their expository 
writings (DeGroff, 1987).  These findings under-
score the importance of investigating methods for 
effective and engaging writing instruction targeted 
at novice writers, as well as automated tools to 
tailor feedback and scaffolding to individual stu-
dents. 
In addition to grounding their work in the writ-
ing research literature, designers of composition 
support tools will likely need to avail themselves 
of the full gamut of natural language processing 
techniques to analyze students? texts with regard to 
syntax, semantics, and discourse.  However, in 
texts produced by novice writers, grammatical 
errors and incoherent discourse abound, which 
may present serious challenges for natural lan-
guage processing since the majority of current 
NLP tools have been developed for well-formed 
texts.  While existing NLP tools have been suc-
cessfully used in writing support systems designed 
for expert writers (Mahlow and Piotrowski, 2009), 
common structural issues in novice compositions 
are likely to prove problematic for current tools.  
However, recent work has begun to explore tech-
niques for handling ill-formed texts that are similar 
to those produced by novice writers.  For example, 
Gamon et al conducted a word-level analysis of 
texts written by non-native English speakers 
(2008).  Focusing on two types of errors (deter-
miners and prepositions), they use decision-tree 
57
classifiers in combination with a language model 
trained on a large English corpus to detect and 
correct erroneous selection of words.  Wagner et 
al. investigated the detection of grammatical mal-
formedness of individual sentences (2007).  They 
found it effective to combine a shallow approach 
that uses n-grams and a deep approach that uses 
syntactic parse results.  Higgins et al explored the 
overall coherence of texts written by students 
(2004).  Using support vector machines, their sys-
tem identified the portions of text that resulted in 
coherence breakdowns with regard to relatedness 
to the essay question and relatedness between dis-
course elements. 
To date, a relatively small number of intelligent 
tutoring systems have been developed to support 
student learning in the language arts, and even 
fewer have sought to specifically address writing.  
Sourcer?s Apprentice is a web-based learning envi-
ronment to help high school students gather, evalu-
ate, and integrate information for writing essays 
about history topics (Britt et al, 2004), although 
Sourcer?s Apprentice did not seek to apply NLP 
tools to understand or scaffold students? composi-
tions directly.  Other work on intelligent tutoring 
for language arts, such as Project LISTEN (Mo-
stow and Aist, 2001) and REAP (Heilman et al, 
2007), has addressed vocabulary learning and read-
ing comprehension. 
3 Narrative Corpus Acquisition 
To investigate narrative composition in novice 
writers, a study was conducted with more than one 
hundred middle grade students using a narrative 
composition support environment.  The 
NARRATIVE THEATRE (Figure 1) is an interactive 
environment designed to capture both the process 
and products of writing.1 Targeting a user popula-
tion of sixth grade students (age typically 12 years) 
and the genre of fables, the NARRATIVE THEATRE 
enables students to create stories in an environment 
that was specifically designed to scaffold novices? 
composition activities during a timed story plan-
                                                 
1 The version of the NARRATIVE THEATRE used in the study 
reported in this paper is the forerunner of a more general 
creativity support environment.  It is under development in our 
laboratory that will employ NLP techniques and intelligent 
graphics generation. The study reported here was conducted to 
inform the design of the creativity enhancement environment 
and intelligent tutoring systems to support composition. 
Figure 1.  Narrative Theatre fable composition support environment. 
58
ning and writing process.  The NARRATIVE 
THEATRE employs a multimedia interface created 
with Adobe's Flash? development platform and 
AIR runtime environment.  Its design was inspired 
by a worksheet that is widely used as part of the 
Grade 6 writing curriculum. 
During the planning phase, students select a 
moral, a setting, a cast of characters, and a set of 
objects for the story they will create.  The system 
provides nine different morals, four settings, ten 
characters, and twenty objects from which students 
may choose.  Each setting is accompanied by a 
visual representation, which can be enlarged by 
clicking on the image to highlight salient features 
of the setting.  Characters and objects are also visu-
ally represented by static graphics, which were 
designed to be neutral in gender and expression in 
order to allow students creative choice when filling 
narrative roles with the characters.  
Once the choices have been made, students are 
presented with a screen that allows them to view 
their planning decisions and begin structuring their 
fable.  The planning area allows students to make 
notes about what they would like to have happen 
during the beginning, middle, and ending.  The top 
of the page contains windows that display the set-
ting, characters, and objects that were chosen ear-
lier, and that can provide more information via a 
mouseover.  Students craft a plan for the beginning 
(setting and characters are introduced), middle 
(conflict and problem), and end (conflict resolu-
tion) of their stories.  For each of the three major 
segments of the story, they formulate a textual 
plan.  After the planning information is entered, the 
students may begin writing (Figure 1).  They then 
create the actual prose, which is entered as raw 
text.  The writing and revision phase are supported 
with a spell-correction facility.  All student activi-
ties including interface selections and the text 
streams from planning and writing are logged and 
time-stamped. 
During the study, a total of 127 sixth-grade 
middle school students (67 males, 60 females) 
participated in the study.  The students ranged in 
age from 10 to 13.  Approximately 38% of the 
students were Caucasian, 27% African-American, 
17% Hispanic or Latino, 6% Asian, 2% American 
Indian, and the remaining 10% were of mixed or 
other descent.  Students participated as part of their 
Language Arts class.  The study spanned two days 
for each student involved.  On the first day, the 
students were seated at a computer and asked to fill 
out a pre-experiment questionnaire, which required 
approximately twenty minutes.  On the second day, 
the students were again assigned to a computer.  
They were presented with the NARRATIVE 
THEATRE interface, which asked them to enter a 
unique identification number.  Once correctly en-
tered, the students were presented with a short 
instructional video that described the features and 
operation of the interface.  They were given fifteen 
minutes to complete the planning activity, which 
included choosing a setting, main characters, 
props, and deciding the beginning, middle, and end 
of their story.  Once planning was completed, or 
time ran out, the students were given another 
thirty-five minutes to write their fable.  After their 
fable was completed, the students were asked to 
complete a post-experiment questionnaire.  This 
survey was also allotted twenty minutes for com-
pletion.  In total, the study lasted ninety minutes. 
4 Findings 
Three categories of analyses were performed on 
the NARRATIVE THEATRE corpus: an analysis of 
natural language processing tool performance 
(specifically, an analysis of syntactic parsers), an 
analysis of coherence and cohesion in the written 
texts using the automated cohesion metric tool 
Coh-Metrix (Graesser et al, 2004), and an analysis 
of students? writing processes.  
As part of an investigation of students? individ-
ual differences in writing, students? language arts 
skills were measured by their scores from the prior 
year?s End-of-Grade reading test.  Subjective rat-
ings of writing ability were also obtained for each 
student from their teachers.  The reading scores 
were used in the presented analyses because they 
were obtained through systematic testing, but it is 
interesting to note that the objective reading scores 
and subjective writing scores were found to be 
strongly correlated by calculating the Spearman?s 
correlation coefficient2, rho = .798, p < .0001.  The 
high correlation suggests that reading scores can 
serve as a reasonable indicator of language arts 
skills.   
                                                 
2 Spearman?s correlation coefficient was used because of the 
ordinal nature of the reading and writing measures (Myers and 
Well, 2003).  
59
4.1 Natural Language Processing 
Two syntactic parsing tools were used to analyze 
students? fables and develop an initial account of 
the performance of current natural language proc-
essing tools on a corpus of novice-generated narra-
tive texts. The Link Grammar Parser (Temperley, 
1995) and Stanford Parser (Klein and Manning, 
2003) were run on the entire corpus, and their per-
formance recorded. 
Link parsing provides insight into the number of 
grammatically malformed sentences observed in 
each fable.  Link grammars center on the notion of 
linkable entities directly combined with one an-
other, as opposed to tree-like structures.  Link pars-
ers attempt to identify one or more syntactically 
valid representations, where each entity is paired 
with another.  Passages were split into sentences 
using OpenNLP, and then run against the Link 
Grammar Parser (Temperley, 1995).  If a sentence 
had no suitable link based on the parser (e.g., ?Last 
dog I saw a great movie?), it was considered ?bro-
ken? because it lacked an appropriate linkage.  A 
ratio of sentences without appropriate linkage to 
total sentence count was used to characterize the 
link parser?s performance on each student?s fable. 
On average, the Link Grammar Parser found 
linkages for 41% of sentences (SD=.22).  Interest-
ingly, reading level was shown to have a marginal 
effect on the link parser?s success rate,  
F(2,110) = 5.78, p = .06.  Post hoc Tukey?s tests 
revealed that above-grade level readers were mar-
ginally more likely to write linkable sentences than 
at-grade level readers, p = .07.  The effect was 
strongly significant between above-grade level 
readers and below-grade level readers, p = .003. 
The Stanford parser was used to investigate the 
frequency with which sentences could be success-
fully parsed.  A parsing failure was noted any time 
the tool was forced to fall back to a PCFG parse.  
On average, the Stanford parser produced a parse 
for 91% of students? sentences.  A significant ef-
fect of reading grade-level on Stanford parser suc-
cess rate was observed, F(2,110) = 4.41, p = .015.  
Post hoc tests showed that above-grade level read-
ers wrote significantly more sentences that could 
be parsed than below-grade level readers, p = .02.  
There was also a marginal difference observed 
between below-grade level readers and at-grade 
level readers, p = .08. 
Gender was not found to have an effect on the 
percentage of linkable sentences, nor the number 
of Stanford parser failures. 
4.2 Individual Differences and Written Texts 
Several analyses were conducted to investigate 
individual differences in students? written texts.  
Analyses focused on writing length, cohesion 
characteristics, coherence characteristics, and 
spelling errors.  Fable lengths were measured in 
characters (M = 1346, SD = 601). 
A marginal effect of reading grade-level on fa-
ble length was observed, F(2,110) = 2.89, p = .06.  
Post hoc tests showed that at-grade level readers 
tended to write longer fables than below-grade 
level readers, p = .10.  Gender was also found to 
have a significant effect on writing length.  Spe-
cifically, females tended to write longer fables than 
males, F(1,110) = 4.41, p = .04. 
Table 1. The effects of reading grade-level on select Coh-Metrix features. 
* denotes p < .1 and ** denotes p < .05 
Coh-Metrix feature Below-Grade  At-Grade  Above-Grade  F(2, 110) = 
Hypernym, nouns 5.9 (0.93)  6.17 (0.81)  6.53 (0.43)  1.24 Below-Above** 
Hypernym, verbs 1.44 (0.18)  1.49 (0.18)  1.48 (0.17)  3.72  
Causal cohesion 0.83 (0.09)  0.87 (0.1)  0.39 (0.16)  3.70 Below-Above** 
At-Above** 
LSA, paragraph to paragraph 0.34 (0.19)  0.45 (0.22)  0.49 (0.18)  3.89 Below-Above** 
Below-At* 
LSA, sentence to sentence 0.21 (0.14)  0.24 (0.11)  0.22 (0.09)  0.48  
Personal pronoun usage 107 (35.88)  101 (29.98)  89 (19.37)  2.25 Below-Above* 
Pronoun to noun phrase ratio 0.36 (0.12)  0.35 (0.10)  0.30 (0.06)  2.21  
    
60
To investigate cohesion and coherence in stu-
dents? fables, the corpus was analyzed with Coh-
Metrix, a tool for analyzing the cohesion, 
language, and readability of texts (Graesser et al, 
2004).  At the core of Coh-Metrix is a lexical ana-
lyzer, syntactic parser, part-of-speech tagger, and 
reference corpora (for LSA) that processes text and 
returns linguistic and discourse related features.  
Coh-Metrix measures several types of cohesion, as 
well as concreteness, connectives, diversity in lan-
guage, and syntactic complexity.  Concreteness is 
measured using the hypernym depth values re-
trieved from the WordNet lexical taxonomy, and 
averaged across noun and verb categories. 
Results from an analysis of reading grade-levels 
and Coh-Metrix features are presented in Table 1.  
Interestingly, above-grade level students were ob-
served to have lower causal cohesion scores than 
at-grade level or below-grade level students.  The 
converse is found in an examination of paragraph-
to-paragraph LSA scores, which are often used to 
measure semantic cohesion.  Below-grade level 
readers tended to have lower semantic cohesion 
scores than at-grade level readers.  LSA scores on 
adjacent sentences and all combinations of sen-
tences were not significant across any of the 
groups.  Sentence-to-sentence LSA scores were 
also not significant across groups.  
Gender did not have a significant effect on 
causal cohesion, hypernym depth of verbs, or 
paragraph-to-paragraph LSA values.  However, 
gender was found to have a significant effect on 
hypernym depth of nouns, F(1,110) = 15.96,  
p = .0001.  Males tended to use more concrete 
nouns in their writing passages, with an average 
difference of .6 in hypernym depth. The ratio of 
pronouns to noun phrases was also significant be-
tween genders, F(1,110) = 10.19, p = .002. Fe-
males had a 38% pronoun to NP ratio whereas 
males were at 32%.  Gender had a significant ef-
fect on sentence-to-sentence LSA scores, F(1,110) 
= 19.9, p = .0001.  Males tended to have a higher 
LSA score across adjacent sentences (M = .27, SD 
= .11) than females (M = .18, SD = .1).  Finally, 
gender had a significant effect on personal pronoun 
incidence score, F(1,110) = 9.12, p = .003.  Fe-
males used personal pronouns as 11.1% of their 
content whereas males used them as 9.3% of their 
content. 
An examination of the number of spelling errors 
remaining in student fables, as well as students? 
usage of the built-in spelling corrector, was con-
ducted.  However, no significant effects were ob-
served across reading level or gender.  
4.3 Individual Differences and Writing  
Processes 
Several features in the student interaction logs 
were chosen to investigate key aspects of students? 
writing processes.  Specifically, these features 
include planning length, planning and writing time, 
revision behavior, pauses in text production, and 
reviews of prior planning decisions.  
On average, students spent 665 seconds plan-
ning their fables and 2199 seconds writing their 
fables (SD = 535).  Students also typed 537 charac-
ters on average while planning their fables (SD = 
254).  No significant effect of reading level was 
observed on planning length, but reading level did 
have a significant effect on time spent in the plan-
ning phase, F(2,110) = 12.76, p < .0001.  Below-
grade level readers spent significantly more time 
Table 2. The effects of reading grade-level on writing process characteristics. 
* denotes p < .1, ** denotes p < .05, and *** denotes p < .01. 
 
Writing process feature Below-Grade  At-Grade  Above-Grade  F(2, 110) = 
Avg length of deletion, planning 21.30 (8.31)  28.18 (11.14)  30.99 (12.37)  8.34 Below-Above*** 
Below-At*** 
Avg length of deletion, writing 23.42 (9.26)  27.74 (10.28)  33.06 (16.80)  5.18 Below-Above*** 
Mouseovers/min 0.19 (0.15)  0.09 (0.07)  0.07 (0.05)  11.81 Below-Above*** 
Below-At*** 
5+ second revision count, planning 9.14 (6.62)  5.43 (4.43)  2.37 (2.36)  12.70 Below-Above*** 
Below-At*** 
At-Above* 
5+ second revision count, writing 18.04 (7.84)  14.21 (7.81)  13.37 (7.52)  3.83 Below-Above* 
Below-At* 
 
61
on planning than at-grade level readers, p = .001, 
as well as above-grade level readers, p < .0001.  
There were also significant differences in writing 
time across reading level groups, F(2, 110) = 6.47, 
p = .002.  Below-grade level readers took signifi-
cantly more time composing their fables than at-
grade level readers, p = .05.  Also, below-grade 
level readers took significantly more time to write 
their fables than above-grade level readers, 
p = .003. 
Females tended to write longer passages in the 
planning section than males F(1,110) = 4.68,  
p = .03.  Time spent on the planning section was 
lower among females than males, F(1,110) = 3.92, 
p = .05.  Females also spent less time on the writ-
ing section than males, F(1,110) = 3.87, p = .05. 
Students? revision behaviors were gauged using 
a heuristic that measures edit distances between 
successive snapshots of fables collected at one-
minute intervals during composition.  Each minute, 
a static snapshot of student?s fable progress was 
taken and logged.  Edit distances between succes-
sive snapshots of students? fables were measured 
using the Google Diff, Match and Patch tools to 
make ?before? and ?after? comparisons (Google, 
2009).  Comparing two successive snapshots of a 
single fable, a revision was defined as any inser-
tion of text that occurred before the tail end of the 
fable.  
The effects of reading level on revision in both 
the planning and writing stages is presented in 
Table 2.  During the writing stage, a significant 
effect of grade-level was observed on average revi-
sion length between below-grade level readers and 
at-grade level readers, as well as between below-
grade level readers and above-grade level readers.  
Within the planning section, at-grade level readers 
revised more text than below-grade level readers, 
and above-grade level readers revised more text 
than at-grade level readers.  Self-efficacy for writ-
ing was found to be significantly correlated with 
average revision length in both the planning, r = 
.21, p = .03, and writing, r = .31, p = .001, stages. 
Pauses between successive keystrokes were 
investigated during both the planning and writing 
stages of NARRATIVE THEATRE interactions.  For 
the purpose of this work, a pause is defined as a 
keystroke made five or more seconds after the 
preceding keystroke.  Keystroke pauses were cate-
gorized as either an appendage or a revision, de-
pending on whether they occurred before the tail 
end of the passage (revision) or after the tail end 
(appendage).  For the planning section, below-
grade readers paused significantly more often than 
at-grade readers.  Also, at-grade readers paused 
before revising significantly more often than 
above-grade readers.  The effects of reading level 
on a number of writing process subscores are 
shown in Table 2. 
Gender had a significant effect on pauses prior 
to revision in the writing phase, F(1,110) = 3.26, 
p = .07.  Females paused on more occasions than 
males.  However, no gender effect was found for 
pause behavior during the planning phase. 
During the planning and writing stages of 
NARRATIVE THEATRE interactions, students could 
review their prior planning selections?including 
characters, objects, and settings?by hovering the 
mouse over the respective region near the top of 
the screen (mouseover).  Upon hovering the mouse 
over the appropriate region, a graphical illustration 
of the student?s planning selection was presented.  
Mouseover instances were recorded to obtain in-
sight into idea generation, or instances where the 
student was contemplating what to write next.  
Mouseovers were calculated in terms of average 
mouseovers over time (in minutes).  The effects of 
reading ability on mouseover behaviors are shown 
in Table 2.  
For the mouseover metric, reading level had a 
significant effect on the mouseover rate.  Below-
grade level learners tended to use the mouseover 
feature on a more frequent basis than both at-grade 
level and above-grade level readers.  There was not 
a significant difference between at-grade level and 
above-grade level groups.  
The effect of gender on mouseover rate was sig-
nificant, F(1,110) = 9.93, p = .002.  Males used the 
mouseover feature on fewer occasions than fe-
males. 
5 Discussion 
The performance of the two parsers differed 
widely.  The Stanford Parser was able to parse over 
90% of fables, but the Link Grammar Parser was 
only successful for about 40% of the fables.  While 
parser failure is not always indicative of poor 
grammaticality, every sentence that failed on the 
Stanford Parser contained either misspelled words 
or run-on sentences.  Many of these were indicated 
by errors in the sentence segmentation as well.  
62
There were also indications that students? language 
arts skills may influence the grammaticality of 
their written sentences; significant effects of read-
ing level were found on both the Stanford Parser?s 
success rate and the Link parser?s success rate.  
The fact that below-grade level students consti-
tuted a considerable proportion of the study?s stu-
dent population suggests that pedagogical writing 
support tools should be capable of handling the 
variations inherent in students? writings, and lever-
age natural language processing results to inform 
tutorial feedback. 
Paragraph-to-paragraph LSA scores tended to 
increase with reading level.  This has implications 
for semantic cohesion (Graessar, 2004) and indi-
cates that students with a higher reading assess-
ment score produce stories that satisfy this 
particular dimension of cohesion.  However, the 
converse was true for the Coh-Metrix measure of 
causal cohesion, where above-grade level students 
actually produced the lowest cohesion scores.  One 
possible explanation could stem from differences 
in vocabulary skills between above- and below-
grade level students; students who exercise a larger 
vocabulary may be penalized by Coh-Metrix?s 
cohesion metric.  Alternatively, the result may be 
related to the fact that below-grade level students 
tend to produce less text (Graessar, 2004).  Clearly, 
students? individual differences in language arts 
ability affect the cohesiveness of the texts they 
write, but additional investigation is necessary to 
develop a clear understanding of the relationship 
between cohesion and language arts ability, as well 
as the implications for tailoring tutoring. 
With regard to the writing process, the average 
length per revision was significantly greater for 
students of higher reading skill-levels. There is a 
possibility that this may be associated with more 
elaborate revision processes, which requires further 
investigation. It should be noted that the revision 
finding was more salient for the planning stage of 
NARRATIVE THEATRE interactions.  This result 
may also indicate that below-grade level readers 
were somewhat less thorough when planning their 
fables.  Further, differences in mouseover behavior 
were found across reading levels, apparently indi-
cating a decline in the rate of mouseovers as read-
ing level increased. This finding may be the result 
of below-grade level students experiencing diffi-
culties in idea generation, or a lack of motivation. 
Finally, the number of pauses prior to revision was 
found to decrease as reading level increased.  This 
result may point to difficulties with text production 
for lower language arts skill students.  Difficulty 
translating ideas into text may point to a need for 
intelligent writing tutors to help reduce lower read-
ing level students? cognitive load during writing. 
6 Conclusions and Future Work 
We have presented a study conducted with middle 
grade students to investigate the process and prod-
ucts of writing in a narrative composition support 
environment.  The study found significant varia-
tions in syntactic parser performance associated 
with students? language arts abilities, as well as 
relationships between students? reading level and 
the grammaticality of their writing.  For example, 
the stories of below-grade readers had a lower 
level of semantic cohesion than at-grade level 
readers, but surprisingly, above-grade level stu-
dents? writings exhibited lower causal cohesion 
than both at-grade and below-grade level students.  
Reading level had a significant effect on time spent 
in the planning phase, and below-grade level read-
ers spent more time composing fables than at-
grade level readers.  There were also gender differ-
ences, with females spending less time in both the 
planning and writing phases.  There were also dif-
ferences with respect to revision, with above-grade 
readers revising more than below-grade readers. 
The study highlights important issues about how 
to design composition support tools.  Composition 
support tools that are sensitive to students? indi-
vidual writing abilities seem likely to be most ef-
fective.  Natural language processing is critical for 
analyzing students? texts and informing the content 
of adaptive tutorial feedback.  Intelligent writing 
tutors should utilize natural language processing 
techniques that can robustly handle the variations 
in students? writings, and deliver tailored scaffold-
ing informed by analyses of students? texts and 
writing processes.  
The findings suggest that several directions exist 
for future work.  Additional analysis is necessary 
to investigate the correctness of syntactic parses.  
Further investigation of students? individual differ-
ences in writing at the discourse and narrative lev-
els is also necessary.  Results from these analyses 
should then be used to inform the design of tech-
niques for adaptive tutorial feedback in narrative 
composition support environments. 
63
Acknowledgements 
The authors wish to thank members of the North 
Carolina State University IntelliMedia Group for 
their assistance with the NARRATIVE THEATRE.  
This research was supported by the National Sci-
ence Foundation under Grant IIS-0757535.  Any 
opinions, findings, and conclusions or recommen-
dations expressed in this material are those of the 
authors and do not necessarily reflect the views of 
the National Science Foundation. 
References  
C. Bereiter and M. Scardamalia. 1987. The Psychology 
of Written Composition. Lawrence Erlbaum Associ-
ates, Hillsdale, NJ.  
V. W. Berninger, K. Vaughan, R. D. Abbott, K. Begay, 
K. B. Coleman, G. Curtain, J. M. Hawkins, and S. 
Graham. 2002. Teaching spelling and composition a-
lone and together: Implications for the simple view 
of writing. Journal of Educational Psychology, 
94(2):291?304.  
M. A. Britt, P. Wiemer-Hasting, A. Larson, and C. Per-
fetti. 2004. Automated feedback on source citation in 
essay writing. International Journal of Artificial In-
telligence in Education, 14(3?4):359?374. 
C. A. Cameron and B. Moshenko. 1996. Elicitation of 
knowledge transformational reports while children 
write narratives. Canadian Journal of Behavioural 
Science, 28(4):271?280. 
L. J. C. DeGroff. 1987. The influence of prior 
knowledge on writing, conferencing, and revising. 
Elementary School Journal, 88(2):105?118.  
L. Flower and J. Hayes. 1981. A cognitive process 
theory of writing. College Composition and Commu-
nication, 32(4):365?387.  
D. Galbraith, J. Hallam, T. Olive, and N. Le Bigot. 
2009. The role of different components of working 
memory in writing. In Proceedings of Annual Con-
ference of the Cognitive Science Society, Amsterdam, 
The Netherlands.  
M. Gamon, J. Gao, C. Brockett, A. Klementiev, W. B. 
Dolan, D. Belenko, and L. Vanderwende. 2008. Us-
ing contextual speller techniques and language 
modeling for ESL error correction. In Proceedings of 
the International Joint Conference on Natural Lan-
guage Processing, pages 449?456, Hyderabad, India.  
Google Diff Match and Patch [Software]. Available 
from http://code.google.com/p/google-diff-match-
patch/ 
A. C. Graesser, D. S. McNamara, M. M. Louwerse, and 
Z. Cai. 2004. Coh-Metrix: Analysis of text on cohe-
sion and language. Behavior Research Methods In-
struments and Computers, 36(2):193?202.  
S. Graham. 2006. Strategy instruction and the teaching 
of writing: A meta-analysis. In C. A. MacArthur, S. 
Graham, and J. Fitzgerald, editors, Handbook of writ-
ing research. Guilford Press, New York, NY, pages 
187?207.   
S. Graham, K. R. Harris, and B. F. Chorzempa. 2002. 
Contribution of spelling instruction to the spelling, 
writing, and reading of poor spellers. Journal of Edu-
cational Psychology, 94(4):669?686.  
J. Hayes. 1996. A new framework for understanding 
cognition and affect in writing. In C. M. Levy and S. 
Ransdell, editors, The Science of Writing: Theories, 
Methods, Individual Differences, and Applications. 
Lawrence Erbaum Associates, Mahwah, NJ, pages 1?
28.  
M. Heilman, K. Collins-Thompson, J. Callan, and M. 
Eskenazi. 2007. Combining lexical and grammtical 
features to improve readability measures for first and 
second language texts. In Proceedings of Human 
Language Technology Conference, pages 460?467, 
Rochester, NY.  
D. Higgins, J. Bustein, D. Marcu, and C. Gentile. 2004. 
Evaluating multiple aspects of coherence in student 
essays. In Proceedings of Human Language Tech-
nology conference/North American chapter of the 
Association for Computational Linguistics, pages 
185?192, Boston, MA.  
J. A. Langer. 1985. Children's sense of genre: A study 
of performance on parallel reading and writing 
Tasks. Written Communication, 2(2):157?187.  
C. Mahlow and M. Piotrowski. 2009. LingURed: Lan-
guage-aware editing functions based on NLP re-
sources. In Proceedings of International 
Multiconference on Computer Science and Informa-
tion Technology, pages 243?250, Mragowo, Poland.  
D. McCutchen, M. Francis, and S. Kerr. 1997. Revising 
for meaning: Effects of knowledge and strategy. 
Journal of Educational Psychology, 89(4):667?676.  
J. Mostow and G. Aist. 2001. Evaluating tutors that 
listen: an overview of project LISTEN. In K. Forbus 
and P. Feltovich, editors, Smart Machines in Educa-
tion. MIT Press, Cambridge, MA, USA, pages 169?
234.  
J. Myers and A. Well. 2003. Research Design and Sta-
tistical Analysis. Erlbaum, Mahwah, NJ. 
K. VanLehn. 2006. The behavior of tutoring systems. 
International Journal of Artificial Intelligence in 
Education, 16(3):227?265.  
J. Wagner, J. Foster, and J. Van Genabith. 2007. A 
comparative evaluation of deep and shallow 
approaches to the automatic detection of common 
grammatical errors. In Proceedings of 2007 Joint 
Conference on Empirical Methods in Natural Lan-
guage Processing and Computational Natural Lan-
guage Learning, pages 112?121, Prague, Czech 
Republic. 
64
Proceedings of the NAACL HLT 2010 Fifth Workshop on Innovative Use of NLP for Building Educational Applications, pages 66?73,
Los Angeles, California, June 2010. c?2010 Association for Computational Linguistics
Leveraging Hidden Dialogue State to Select Tutorial Moves  Kristy Elizabeth    Boyera Robert    Phillipsab Eun Young Haa Michael D.    Wallisab Mladen A.   Vouka James C. Lestera   aDepartment of Computer Science, North Carolina State University bApplied Research Associates Raleigh, NC, USA  {keboyer, rphilli, eha, mdwallis, vouk, lester}@ncsu.edu    Abstract 
A central challenge for tutorial dialogue systems is selecting an appropriate move given the dialogue context. Corpus-based approaches to creating tutorial dialogue management models may facilitate more flexible and rapid development of tutorial dialogue systems and may increase the effectiveness of these systems by allowing data-driven adaptation to learning contexts and to individual learners. This paper presents a family of models, including first-order Markov, hidden Markov, and hierarchical hidden Markov models, for predicting tutor dialogue acts within a corpus. This work takes a step toward fully data-driven tutorial dialogue management models, and the results highlight important directions for future work in unsupervised dialogue modeling. 1 Introduction A central challenge for dialogue systems is selecting appropriate system dialogue moves (Bangalore, Di Fabbrizio, & Stent, 2008; Frampton & Lemon, 2009; Young et al, 2009). For tutorial dialogue systems, which aim to support learners during conceptual or applied learning tasks, selecting an appropriate dialogue move is particularly important because the tutorial approach could significantly influence cognitive and affective outcomes for the learner (Chi, Jordan, VanLehn, & Litman, 2009). The strategies implemented in tutorial dialogue systems have historically been based on handcrafted rules 
derived from observing human tutors (e.g., Aleven, McLaren, Roll, & Koedinger, 2004; Evens & Michael, 2006; Graesser, Chipman, Haynes, & Olney, 2005; Jordan, Makatchev, Pappuswamy, VanLehn, & Albacete, 2006). While these systems can achieve results on par with unskilled human tutors, tutorial dialogue systems have not yet matched the effectiveness of expert human tutors (VanLehn et al, 2007). A more flexible model of strategy selection may enable tutorial dialogue systems to increase their effectiveness by responding adaptively to a broader range of contexts. A promising method for deriving such a model is to learn it directly from corpora of effective human tutoring. Data-driven approaches have shown promise in task-oriented domains outside of tutoring (Bangalore et al, 2008; Hardy et al, 2006; Young et al, 2009), and automatic dialogue policy creation for tutoring has been explored recently (Chi, Jordan, VanLehn, & Hall, 2008; Tetreault & Litman, 2008). Ultimately, devising data-driven approaches for developing tutorial dialogue systems may constitute a key step towards achieving the high learning gains that have been observed with expert human tutors.  The work presented in this paper focuses on learning a model of tutorial moves within a corpus of human-human dialogue in the task-oriented domain of introductory computer science. Unlike the majority of task-oriented domains that have been studied to date, our domain involves the separate creation of a persistent artifact by the user (the student). The modification of this artifact, in our case a computer program, is the focus of the dialogues. Our corpus consists of textual dialogue utterances and a separate synchronous stream of 
66
task actions. Our goal is to extract a data-driven dialogue management model from the corpus, as evidenced by predicting system (tutor) dialogue acts.  In this paper, we present an annotation approach that addresses dialogue utterances and task actions, and we propose a unified sequential representation for these separate synchronous streams of events. We explore the predictive power of three stochastic models ? first-order Markov models, hidden Markov models, and hierarchical hidden Markov models ? for predicting tutor dialogue acts in the unified sequences. By leveraging these models to capture effective tutorial dialogue strategies, this work takes a step toward creating data-driven tutorial dialogue management models. 2 Related Work Much of the research on selecting system dialogue acts relies on a Markov assumption (Levin, Pieraccini, & Eckert, 2000). This formulation is often used in conjunction with reinforcement learning (RL) to derive optimal dialogue policies (Frampton & Lemon, 2009). Sparse data and large state spaces can pose serious obstacles to RL, and recent work aims to address these issues (Ai, Tetreault, & Litman, 2007; Henderson, Lemon, & Georgila, 2008; Heeman, 2007; Young et al, 2009). For tutorial dialogue, RL has been applied to selecting a state space representation that best facilitates learning an optimal dialogue policy (Tetreault & Litman, 2008). RL has also been used to compare specific tutorial dialogue tactic choices (Chi et al, 2008).  While RL learns a dialogue policy through exploration, our work assumes that a flexible, good (though possibly not optimal) dialogue policy is realized in successful human-human dialogues. We extract this dialogue policy by predicting tutor (system) actions within a corpus. Using human dialogues directly in this way has been the focus of work in other task-oriented domains such as finance (Hardy et al, 2006) and catalogue ordering (Bangalore et al, 2008). Like the parse-based models of Bangalore et al, our hierarchical hidden Markov models (HHMM) explicitly capture the hierarchical nesting of tasks and subtasks in our domain. In other work, this level of structure has been studied from a slightly different perspective as conversational game (Poesio & Mikheev, 1998).  
For tutorial dialogue, there is compelling evidence that human tutoring is a valuable model for extracting dialogue system behaviors. The CIRCSIM-TUTOR (Evens & Michael, 2006), ITSPOKE (Forbes-Riley, Rotaru, Litman, & Tetreault, 2007; Forbes-Riley & Litman, 2009), and KSC-PAL (Kersey, Di Eugenio, Jordan, & Katz, 2009) projects have made extensive use of data-driven techniques based on human corpora. Perhaps most directly comparable to the current work are the bigram models of Forbes-Riley et al; we explore first-order Markov models, which are equivalent to bigram models, for predicting tutor dialogue acts.  In addition, we present HMMs and HHMMs trained on our corpus. We found that both of these models outperformed the bigram model for predicting tutor moves. 3 Corpus and Annotation The corpus was collected during a human-human tutoring study in which tutors and students worked to solve an introductory computer programming problem (Boyer et al, in press). The dialogues were effective: on average, students exhibited a 7% absolute gain from pretest to posttest (N=48, paired t-test p<0.0001).  The corpus contains 48 textual dialogues with a separate, synchronous task event stream. Tutors and students collaborated to solve an introductory computer programming problem using an online tutorial environment with shared workspace viewing and textual dialogue. Each student participated in exactly one tutoring session. The corpus contains 1,468 student utterances, 3,338 tutor utterances, and 3,793 student task actions. In order to build the dialogue model, we annotated the corpus with dialogue act tags and task annotation labels. 3.1 Dialogue Act Annotation  We have developed a dialogue act tagset inspired by schemes for conversational speech (Stolcke et al, 2000), task-oriented dialogue (Core & Allen, 1997), and tutoring (Litman & Forbes-Riley, 2006). The dialogue act tags are displayed in Table 1. Overall reliability on 10% of the corpus for two annotators was ?=0.80.   
67
 Table 1. Dialogue act tags 
DA? Description?
Stu.?Rel.?Freq.?
Tut.?Rel.?Freq.? ??ASSESSING?QUESTION?(AQ)? Request?for?feedback?on?task?or?conceptual?utterance.? .20? .11? .91?EXTRA?DOMAIN?(EX)? Asides?not?relevant?to?the?tutoring?task.? .08? .04? .79?GROUNDING?(G)? Acknowledgement/thanks? .26? .06? .92?LUKEWARM?CONTENT?FEEDBACK?(LCF)? Negative?assessment?with?explanation.? .01? .03? .53?LUKEWARM?FEEDBACK?(LF)? Lukewarm?assessment?of?task?action?or?conceptual?utterance.? .02? .03? .49?NEGATIVE?CONTENT?FEEDBACK?(NCF)?
Negative?assessment?with?explanation.? .01? .10? .61?
NEGATIVE?FEEDBACK?(NF)? Negative?assessment?of?task?action?or?conceptual?utterance.? .05? .02? .76?POSITIVE?CONTENT?FEEDBACK?(PCF)? Positive?assessment?with?explanation.? .02? .03? .43?POSITIVE?FEEDBACK?(PF)? Positive?assessment?of?task?action?or?conceptual?utterance.? .09? .16? .81?QUESTION?(Q)? Task?or?conceptual?question.? .09? .03? .85?STATEMENT?(S)? Task?or?conceptual?assertion.? .16? .41? .82?
3.2 Task Annotation The dialogues focused on the task of solving an introductory computer programming problem. The task actions were recorded as a separate but synchronous event stream. This stream included 97,509 keystroke-level user task events. These events were manually aggregated and annotated for subtask structure and then for correctness. The task annotation scheme was hierarchical, reflecting the nested nature of the subtasks. An excerpt from the task annotation scheme is depicted in Figure 1; the full scheme contains 66 leaves. The task annotation scheme was designed to reflect the different depth of possible subtasks nested within the overall task. Each labeled task action was also judged for correctness according to the requirements of the task, with categories CORRECT, BUGGY, INCOMPLETE, and DISPREFERRED (technically 
correct but not accomplishing the pedagogical goals of the task). Each group of task keystrokes that occurred between dialogue utterances was tagged, possibly with many subtask labels, by a human judge. A second judge tagged 20% of the corpus in a reliability study for which one-to-one subtask identification was not enforced (giving judges maximum flexibility to apply the tags). To ensure a conservative reliability statistic, all unmatched subtask tags were treated as disagreements. The resulting unweighted kappa statistic was ?simple= 0.58, but the weighted Kappa ?weighted=0.86 is more meaningful because it takes into account the ordinal nature of the labels that result from sequential subtasks. On task actions for which the two judges agreed on subtask tag, the agreement statistic for correctness was ?simple=0.80. 
 Figure 1. Portion of task annotation scheme 3.3 Adjacency Pair Joining Some dialogue acts establish an expectation for another dialogue act to occur next (Schegloff & Sacks, 1973). Our previous work has found that identifying the statistically significant adjacency pairs in a corpus and joining them as atomic observations prior to model building produces more interpretable descriptive models. The models reported here were trained on hybrid sequences of dialogue acts and adjacency pairs. A full description of the adjacency pair identification methodology and joining algorithm is reported in (Boyer et al, 2009). A partial list of the most highly statistically significant adjacency pairs, 
68
which for this work include task actions, is displayed in Table 2.   Table 2. Subset of significant adjacency pairs CORRECTTASKACTION?CORRECTTASKACTION;??EXTRADOMAINS?EXTRADOMAINT;?GROUNDINGS?GROUNDINGT;?ASSESSINGQUESTIONT?POSITIVEFEEDBACKS;??ASSESSINGQUESTIONS?POSITIVEFEEDBACKT;?QUESTIONT?STATEMENTS;?ASSESSINGQUESTIONT?STATEMENTS;?EXTRADOMAINT?EXTRADOMAINS;?QUESTIONS?STATEMENTT;?NEGATIVEFEEDBACKS?GROUNDINGT;?INCOMPLETETASKACTION?INCOMPLETETASKACTION;?POSITIVEFEEDBACKS?GROUNDINGT;??BUGGYTASKACTION?BUGGYTASKACTION 4 Models We learned three types of models using cross-validation with systematic sampling of training and testing sets. 
4.1 First-Order Markov Model The simplest model we discuss is the first-order Markov model (MM), or bigram model (Figure 2). A MM that generates observation (state) sequence o1o2?ot is defined in the following way. The observation symbols are drawn from the alphabet ?={?1, ?2, ?, ?M}, and the initial probability distribution is ?=[?i] where ?i is the probability of a sequence beginning with observation symbol ?i. The transition probability distribution is A=[aij], where aij is the probability of observation j occurring immediately after observation i. 
 Figure 2. Time-slice topology of MM  We trained MMs on our corpus of dialogue acts and task events using ten-fold cross-validation to produce a model that could be queried for the next predicted tutorial dialogue act given the history.  
4.2 Hidden Markov Model A hidden Markov model (HMM) augments the MM framework, resulting in a doubly stochastic structure (Rabiner, 1989). For a first-order HMM, the observation symbol alphabet is defined as above, along with a set of hidden states S={s1,s2,?,sN}. The transition and initial probability distributions are defined analogously to MMs, except that they operate on hidden states 
rather than on observation symbols (Figure 3). That is, ?=[?i] where ?i is the probability of a sequence beginning in hidden state si. The transition matrix is A=[aij], where aij is the probability of the model transitioning from hidden state i to hidden state j. This framework constitutes the first stochastic layer of the model, which can be thought of as modeling hidden, or unobservable, structure. The second stochastic layer of the model governs the production of observation symbols: the emission probability distribution is B=[bik] where bik is the probability of state i emitting observation symbol k. 
 Figure 3. Time-slice topology of HMM  The notion that dialogue has an overarching unobservable structure that influences the observations is widely accepted. In tutoring, this overarching structure may correspond to tutorial strategies. We have explored HMMs? descriptive power for extracting these strategies (Boyer et al, 2009), and this paper explores the hypothesis that HMMs provide better predictive power than MMs on our dialogue sequences. We trained HMMs on the corpus using the standard Baum-Welch expectation maximization algorithm and applied state labels that reflect post-hoc interpretation (Figure 4).  
 Figure 4. Portion of learned HMM 
69
4.3 Hierarchical Hidden Markov Model Hierarchical hidden Markov models (HHMMs) allow for explicit representation of multilevel stochastic structure. A complete formal definition of HHMMs can be found in (Fine, Singer, & Tishby, 1998), but here we present an informal description.  HHMMs include two types of hidden states: internal nodes, which do not produce observation symbols, and production nodes, which do produce observations. An internal node includes a set of substates that correspond to its potential children, S={s1, s2, ?, sN}, each of which is itself the root of an HHMM. The initial probability distribution ?=[?i] for each internal node governs the probability that the model will make a vertical transition to substate si from this internal node; that is, that this internal node will produce substate si as its leftmost child. Horizontal transitions are governed by a transition probability distribution similar to that described above for flat HMMs. Production nodes are defined by their observation symbol alphabet and an emission probability distribution over the symbols; HHMMs do not require a global observation symbol alphabet. The generative topology of our HHMMs is illustrated in Figure 5. 
 Figure 5. Generative topology of HHMM  HHMMs of arbitrary topology can be trained using a generalized version of the Baum-Welch algorithm (Fine et al, 1998). Our HHMMs featured a pre-specified model topology based on known task/subtask structure. A Bayesian view of a portion of the best-fit HHMM is depicted in Figure 6.  This model was trained using five-fold cross-validation to address the absence of symbols from the training set that were present in the testing set, a sparsity problem that arose from splitting the data hierarchically. 
Figure 6. Portion of learned HHMM 
70
5 Results We trained and tested MMs, HMMs, and HHMMs on the corpus and compared prediction accuracy for tutorial dialogue acts by providing the model with partial sequences from the test set and querying for the next tutorial move. The baseline prediction accuracy for this task is 41.1%, corresponding to the most frequent tutorial dialogue act (STATEMENT). As depicted in Figure 7, a first-order MM performed worse than baseline (p<0.001)1 at 27% average prediction accuracy (
? 
? ? MM=6%). HMMs performed better than baseline (p<0.0001), with an average accuracy of 48% (
? 
? ? HMM=3%). HHMMs averaged 57% accuracy, significantly higher than baseline (p=0.002) but weakly significantly higher than HMMs (p=0.04), and with high variation (
? 
? ? HHMM=23%). 
 Figure 7. Average prediction accuracies of three model types on tutor dialogue acts  To further explore the performance of the HHMMs, Figure 8 displays their prediction accuracy on each of six labeled subtasks. These subtasks correspond to the top level of the hierarchical task/subtask annotation scheme. The UNDERSTAND THE PROBLEM subtask corresponds to the initial phase of most tutoring sessions, in which the student and tutor agree to some extent on a problem-solving plan. Subtasks 1, 2, and 3 account for the implementation and debugging of three distinct modules within the learning task, and Subtask 4 involves testing and assessing the student?s finalized program. The EXTRA-DOMAIN subtask involves side conversations whose topics are outside of the domain.  The HHMM performed as well as or better (p<0.01) than baseline on the first three in-domain subtasks. The performance on SUBTASK 4 was not distinguishable from baseline (p=0.06); relatively few students reached this subtask. The model did                                                 1 All p-values in this section were produced by two-sample one-tailed t-tests with unequal sample variances. 
not outperform baseline (p=0.40) for the UNDERSTAND THE PROBLEM subtask, and qualitative inspection of the corpus reveals that the dialogue during this phase of tutoring exhibits limited regularities between students.  
 Figure 8. Average prediction accuracies of HHMMs by subtask 6 Discussion The results support our hypothesis that HMMs, because of their capacity for explicitly representing dialogue structure at an abstract level, perform better than MMs for predicting tutor moves. The results also suggest that explicitly modeling hierarchical task structure can further improve prediction accuracy of the model. The below-baseline performance of the bigram model illustrates that in our complex task-oriented domain, an immediately preceding event is not highly predictive of the next move. While this finding may not hold for conversational dialogue or some task-oriented dialogue with a more balanced distribution of utterances between speakers, the unbalanced nature of our tutoring sessions may not be as easily captured.  In our corpus, tutor utterances outnumber student utterances by more than two to one. This large difference is due to the fact that tutors frequently guided students and provided multi-turn explanations, the impetus for which are not captured in the corpus, but rather, involve external pedagogical goals. The MM, or bigram model, has no mechanism for capturing this layer of stochastic behavior. On the other hand, the HMM can account for unobserved influential variables, and the HHMM can do so to an even greater extent by explicitly modeling task/subtask structure. Considering the performance of the HHMM on individual subtasks reveals interesting properties of our dialogues. First, the HHMM is unable to outperform baseline on the UNDERSTAND THE PROBLEM subtask. To address this issue, our ongoing work investigates taking into account 
71
student characteristics such as incoming knowledge level and self-confidence. On all four in-domain subtasks, the HHMM achieved a 30% to 50% increase over baseline. For extra-domain dialogues, which involve side conversations that are not task-related, the HHMM achieved 86% prediction accuracy on tutor moves, which constitutes a 115% improvement over baseline. This high accuracy may be due in part to the fact that out-of-domain asides were almost exclusively initiated by the student, and tutors rarely engaged in such exchanges beyond providing a single response. This regularity likely facilitated prediction of the tutor?s dialogue moves during out-of-domain talk. We are aware of only one recent project that reports extensively on predicting system actions from a corpus of human-human dialogue. Bangalore et al?s (2008) flat task/dialogue model in a catalogue-ordering domain achieved a prediction accuracy of 55% for system dialogue acts, a 175% improvement over baseline. When explicitly modeling the hierarchical task/subtask dialogue structure, they report a prediction accuracy of 35.6% for system moves, approximately 75% above baseline (Bangalore & Stent, 2009). These findings were obtained by utilizing a variety of lexical and syntactic features along with manually annotated dialogue acts and task/subtask labels. In comparison, our HHMM achieved an average 42% improvement over baseline using only annotated dialogue acts and task/subtask labels. In ongoing work we are exploring the utility of additional features for this prediction task. Our best model performed better than baseline by a significant margin. The absolute prediction accuracy achieved by the HHMM was 57% across the corpus, which at first blush may appear too low to be of practical use. However, the choice of tutorial move involves some measure of subjectivity, and in many contexts there may be no uniquely appropriate dialogue act. Work in other domains has dealt with this uncertainty by maintaining multiple hypotheses (Wright Hastie, Poesio, & Isard, 2002) and by mapping to clustered sets of moves rather than maintaining policies for each possible system selection (Young et al, 2009). Such approaches may prove useful in our domain as well, and may help to more fully realize 
the potential of a learned dialogue management model.  7 Conclusion and Future Work Learning models that predict system moves within a corpus is a first step toward building fully data-driven dialogue management models. We have presented Markov models, hidden Markov models, and hierarchical hidden Markov models trained on sequences of manually annotated dialogue acts and task events. Of the three models, the hierarchical models appear to perform best in our domain, which involves an intrinsically hierarchical task/subtask structure.  The models? performance points to promising future work that includes utilizing additional lexical and syntactic features along with fixed user (student) characteristics within a hierarchical hidden Markov modeling framework. More broadly, the results point to the importance of considering task structure when modeling a complex domain such as those that often accompany task-oriented tutoring. Finally, a key direction for data-driven dialogue management models involves learning unsupervised dialogue act and task classification models.   Acknowledgements.  This work is supported in part by the North Carolina State University Department of Computer Science and the National Science Foundation through a Graduate Research Fellowship and Grants CNS-0540523, REC-0632450 and IIS-0812291. Any opinions, findings, conclusions, or recommendations expressed in this report are those of the participants, and do not necessarily represent the official views, opinions, or policy of the National Science Foundation. References  Ai, H., Tetreault, J. R., & Litman, D. J. (2007). Comparing user simulation models for dialog strategy learning. Proceedings of NAACL HLT, Companion Volume, Rochester, New York. 1-4.  Aleven, V., McLaren, B., Roll, I., & Koedinger, K. (2004). Toward tutoring help seeking: Applying cognitive modeling to meta-cognitive skills. Proceedings of ITS, 227-239.  Bangalore, S., Di Fabbrizio, G., & Stent, A. (2008). Learning the structure of task-driven human-human dialogs. IEEE Transactions on Audio, Speech, and Language Processing, 16(7), 1249-1259.  
72
Bangalore, S., & Stent, A. J. (2009). Incremental parsing models for dialog task structure. Proceedings of the EACL, 94-102.  Boyer, K. E., Phillips, R., Ha, E. Y., Wallis, M. D., Vouk, M. A., & Lester, J. C. (2009). Modeling dialogue structure with adjacency pair analysis and hidden Markov models. Proceedings of NAACL HLT (Short Papers), 19-26. Boyer, K. E., Phillips, R., Ingram, A., Ha, E. Y., Wallis, M. D., Vouk, M. A., & Lester, J. C. (In press). Characterizing the effectiveness of tutorial dialogue with hidden Markov models. Proceedings of ITS, Pittsburgh, Pennsylvania.  Chi, M., Jordan, P., VanLehn, K., & Hall, M. (2008). Reinforcement learning-based feature selection for developing pedagogically effective tutorial dialogue tactics. Proceedings of EDM, Montreal, Canada. 258-265.  Chi, M., Jordan, P., VanLehn, K., & Litman, D. (2009). To elicit or to tell: Does it matter? Proceedings of AIED, 197-204.  Core, M., & Allen, J. (1997). Coding dialogs with the DAMSL annotation scheme. AAAI Fall Symposium on Communicative Action in Humans and Machines, 28?35.   Evens, M., & Michael, J. (2006). One-on-one tutoring by humans and computers. Mahwah, New Jersey: Lawrence Erlbaum Associates. Fine, S., Singer, Y., & Tishby, N. (1998). The hierarchical hidden Markov model: Analysis and applications. Machine Learning, 32(1), 41-62.  Forbes-Riley, K., Rotaru, M., Litman, D. J., & Tetreault, J. (2007). Exploring affect-context dependencies for adaptive system development. Proceedings of NAACL HLT (Short Papers), 41-44.  Forbes-Riley, K., & Litman, D. (2009). Adapting to student uncertainty improves tutoring dialogues. Proceedings of AIED, 33-40.  Frampton, M., & Lemon, O. (2009). Recent research advances in reinforcement learning in spoken dialogue systems. The Knowledge Engineering Review, 24(4), 375-408.  Graesser, A. C., Chipman, P., Haynes, B. C., & Olney, A. (2005). AutoTutor: An intelligent tutoring system with mixed-initiative dialogue. IEEE Transactions on Education, 48(4), 612-618.  Hardy, H., Biermann, A., Inouye, R. B., McKenzie, A., Strzalkowski, T., Ursu, C., Webb, N., & Wu, M. (2006). The Amiti?s system: Data-driven techniques for automated dialogue. Speech Communication, 48(3-4), 354-373.  Heeman, P. A. (2007). Combining reinforcement learning with information-state update rules. Proceedings of NAACL HLT, 268-275.  
Henderson, J., Lemon, O., & Georgila, K. (2008). Hybrid reinforcement/supervised learning of dialogue policies from fixed data sets. Computational Linguistics, 34(4), 487-511.  Jordan, P., Makatchev, M., Pappuswamy, U., VanLehn, K., & Albacete, P. (2006). A natural language tutorial dialogue system for physics. Proceedings of FLAIRS, 521-526.  Kersey, C., Di Eugenio, B., Jordan, P., & Katz, S. (2009). KSC-PaL: A peer learning agent that encourages students to take the initiative. Proceedings of the NAACL HLT Workshop on Innovative use of NLP for Building Educational Applications, Boulder, Colorado. 55-63.  Levin, E., Pieraccini, R., & Eckert, W. (2000). A stochastic model of human-machine interaction for learning dialog strategies. IEEE Transactions on Speech and Audio Processing, 8(1), 11-23.  Litman, D., & Forbes-Riley, K. (2006). Correlations between dialogue acts and learning in spoken tutoring dialogues. Natural Language Engineering, 12(2), 161-176.  Poesio, M., & Mikheev, A. (1998). The predictive power of game structure in dialogue act recognition: Experimental results using maximum entropy estimation. Proceedings of ICSLP, 90-97.  Rabiner, L. R. (1989). A tutorial on hidden Markov models and selected applications in speech recognition. Proceedings of the IEEE, 77(2), 257-286.  Schegloff, E., & Sacks, H. (1973). Opening up closings. Semiotica, 7(4), 289-327.  Stolcke, A., Ries, K., Coccaro, N., Shriberg, E., Bates, R., Jurafsky, D., Taylor, P., Martin, R., Van Ess-Dykema, C., & Meteer, M. (2000). Dialogue act modeling for automatic tagging and recognition of conversational speech. Computational Linguistics, 26(3), 339-373.  Tetreault, J. R., & Litman, D. J. (2008). A reinforcement learning approach to evaluating state representations in spoken dialogue systems. Speech Communication, 50(8-9), 683-696.  VanLehn, K., Graesser, A. C., Jackson, G. T., Jordan, P., Olney, A., & Rose, C. P. (2007). When are tutorial dialogues more effective than reading? Cognitive Science, 31(1), 3-62.  Wright Hastie, H., Poesio, M., & Isard, S. (2002). Automatically predicting dialogue structure using prosodic features. Speech Communication, 36(1-2), 63-79.  Young, S., Gasic, M., Keizer, S., Mairesse, F., Schatzmann, J., Thomson, B., & Yu, K. (2009). The hidden information state model: A practical framework for POMDP-based spoken dialogue management. Computer Speech and Language, 24(2), 150-174.  
73
Proceedings of the SIGDIAL 2011: the 12th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 49?58,
Portland, Oregon, June 17-18, 2011. c?2011 Association for Computational Linguistics
The Impact of Task-Oriented Feature Sets on  HMMs for Dialogue Modeling   Kristy Elizabeth Boyer  Eun Young Ha   Robert Phillips*   James Lester   Department of Computer Science North Carolina State University *Dual affiliation with Applied Research Associates, Inc. Raleigh, North Carolina, USA {keboyer, eha, rphilli, lester}@ncsu.edu 
  
Abstract 
Human dialogue serves as a valuable model for learning the behavior of dialogue systems. Hidden Markov models? sequential structure is well suited to modeling human dialogue, and their theoretical underpinnings are consistent with the conception of dialogue as a stochastic process with a layer of implicit, highly influen-tial structure. HMMs have been shown to be effective for a variety of descriptive and pre-dictive dialogue tasks. For task-oriented dia-logue, understanding the learning behavior of HMMs is an important step toward building unsupervised models of human dialogue. This paper examines the behavior of HMMs under six experimental conditions including different task-oriented feature sets and preprocessing approaches. The findings highlight the im-portance of providing HMM learning algo-rithms with rich task-based information. Additionally, the results suggest how specific metrics should be used depending on whether the models will be employed primarily in a de-scriptive or predictive manner.  1 Introduction Human dialogue serves as a valuable model for learning the behavior of dialogue systems. For this reason, corpus-based approaches to dialogue man-agement tasks have been an increasingly active area of research (Bangalore, Di Fabbrizio, & Stent, 2006; Di Eugenio, Xie, & Serafin, 2010; Georgila, Lemon, Henderson, & Moore, 2009; Rotaru & Litman, 2009). Modeling the dialogue policies that 
humans employ permits us to directly extract con-versational and task-based expertise. These tech-niques hold great promise for scaling gracefully to large corpora, and for transferring well across do-mains.    The richness and flexibility of human dialogue introduce nondeterministic and complex patterns that present challenges for machine learning ap-proaches. One approach that has been successfully employed in dialogue modeling is the hidden Mar-kov model (HMM) (Rabiner, 1989). These models are well suited to the sequential nature of dialogue (Stolcke et al, 2000). Moreover, their theoretical underpinnings are consistent with the conception of dialogue as a stochastic process whose observations are influenced by a layer of implicit, yet highly rel-evant, structure (Boyer et al, 2009; Woszczyna & Waibel, 1994).  HMMs have been shown to perform well on important dialogue management tasks such as au-tomatic dialogue act classification (Stolcke et al, 2000). Our work has employed HMMs for a differ-ent goal: learning dialogue policies, or strategies, from corpora (Boyer, Phillips, et al, 2010; Boyer, Phillips, Ingram, et al, in press). This work can be viewed from two perspectives. First, a descriptive goal of the work is to learn models that describe the nature of human dialogues in succinct probabilistic terms, in a way that facilitates important qualitative investigations. The second and complementary goal is predictive: learning models that accurately pre-dict the dialogue moves of humans, in order to cap-ture a dialogue policy that can be used within a system.   
49
Both of these goals are of paramount im-portance in tutorial dialogue, in which tutors and students engage in dialogue in support of a learning task (Boyer, Ha, et al, 2010; VanLehn et al, 2007). Descriptive modeling represents a critical step to-ward more fully understanding the phenomena that contribute to the high effectiveness of human tutor-ing, which has to date been unmatched by tutorial dialogue systems. Predictive models, on the other hand, may be used directly as dialogue policies within systems.  The HMMs considered here were learned from an annotated corpus of textual human-human tuto-rial dialogue. In this domain, HMMs have been shown to correspond qualitatively to widely held conceptions of tutorial dialogue strategies, and ad-jacency pair analysis before model learning has been shown to enhance this qualitative correspond-ence (Boyer et al, 2009). Moreover, HMMs can identify in an unsupervised fashion structural com-ponents that correlate with student knowledge gain (Boyer, Phillips, Ingram, et al, in press).  However, to date, several important questions have not been explored. The answers to these ques-tions have implications for learning HMMs for task-oriented dialogues. The questions include the following: 1) How reliably does the HMM learning framework converge to the hyperparameter N, the best-fit number of hidden states? 2) What are the effects of preprocessing approaches, specifically, adjacency pair analysis, on the resulting HMMs? 3) How do different feature sets for task-oriented dialogue impact the descriptive fit and predictive power of learned HMMs? This paper addresses these questions. The findings suggest that model stability and predictive power benefit from the richest possible input sequences, which include not only dialogue acts but also information about the task state and the absence of particular tutor dia-logue moves. Additionally, we find that traditional measures of HMM goodness-of-fit may not identify the most highly predictive models under some con-ditions. 2 Background HMMs have been used for dialogue modeling tasks for many years. Early work utilized HMMs to model underlying linguistic structure for the pur-poses of identifying speech acts and reducing per-plexity for speech recognition (Stolcke et al, 2000; 
Woszczyna & Waibel, 1994). These projects treat-ed underlying dialogue structure as the hidden lay-er, and dialogue utterances as observations. This treatment is analogous to the work presented in this paper, except that our observations are dialogue act tags only, rather than being constituent words in each utterance. Our goals are also different: to cre-ate a qualitatively interpretable model of dialogue structure that corresponds to widely accepted no-tions of task-oriented dialogue, and to learn a high-ly predictive dialogue policy from a human-human dialogue corpus.  HMMs rely on treating dialogue as a sequential Markov process in which each observation depends only on a finite set of preceding observations. Some other approaches that rely on this assumption treat dialogue as a Markov decision process or partially observable Markov decision process, in which state changes are associated with actions and rewards (e.g., Young et al, 2010). Such work focuses on learning an optimal policy, typically utilizing a combination of human and simulated dialogue cor-pora. Reinforcement learning techniques can then be applied to learn the optimal policy based on the observed rewards. In contrast, we start with a rich corpus of human-human dialogue, which may have poor coverage in some areas (though the dialogue act tags were empirically derived and therefore mit-igate this problem to some extent), and subsequent-ly learn a model that explains the variance in that human corpus as well as possible. Capturing the dialogue policy implicit within a corpus of human-human dialogue has been ex-plored in other work in a catalogue-ordering do-main (Bangalore, Di Fabbrizio, & Stent, 2006). That work utilized maximum entropy modeling to predict human agents? dialogue moves within a vector-based framework. Although a vector-based approach differs in many regards from the sequen-tial HMM approach described here, both approach-es assume a dependence only on a finite history. HMMs accomplish this through graphical depend-encies, while vector-based approaches accomplish it by including features for a restricted window of left-hand context. The results of this catalogue-ordering project highlight how challenging it is to predict human agents? dialogue moves in a task-oriented domain. 
50
3 Corpus  The corpus was collected during a human-human tutoring study. Students solved an introductory computer programming problem in the Java pro-gramming language. Tutors were located in a sepa-rate room and communicated with students through textual dialogue while viewing a synchronized view of the student?s problem-solving workspace. Forty-eight students interacted for approximately one hour each with a tutor. Students exhibited sta-tistically significant learning gains from pretest to posttest, indicating that the tutoring was effective (Boyer, Phillips, Ingram, et al, in press). The cor-pus contains 1,468 student moves and 3,338 tutor moves. Overlapping utterances, which are common in dialogue platforms such as instant messaging, were prevented by permitting only one user to con-struct a dialogue message at a time. Because the corpus is textual, utterances were segmented at tex-tual message boundaries except when the lead dia-logue annotator noted the presence of two separate dialogue acts within non-overlapping chunks of text. In these events the utterance was segmented by the primary annotator prior to being tagged by the second dialogue act annotator.  In addition to dialogue act annotation, the cor-pus was manually annotated for task structure and correctness (Section 3.2), and for delayed tutor feedback (Seciton 3.3). The appendix displays an excerpt from the annotated corpus.  3.1 Dialogue Act Annotation As part of prior work, the corpus was annotated with dialogue acts for both tutor (Boyer, Phillips, Ingram, et al, in press) and student (Boyer, Ha, et al, 2010) utterances (Table 1). One annotator tagged the entire corpus, while a second annotator independently tagged a randomly selected 10% of tutoring sessions. The inter-annotator agreement Kappa score was 0.80.  3.2 Task Annotation The corpus includes 97,509 keystroke-level task events (computer programming actions), all taken by the student. Tutors viewed synchronously, but could not edit, the computer program. The task ac-tions were manually clustered and labeled for sub-task structure (Boyer, Phillips, et al, 2010). The task structure annotation was hierarchical, with 
leaves corresponding to specific subtasks such as creating a temporary variable in order to swap two variables? values (subtask 3-c-iii-2). Each problem-solving cluster, or subtask, was then labeled for correctness (Table 2). These correctness labels are utilized in the models presented in this paper. The Kappa agreement statistic for the correctness anno-tation on 20% of the corpus was 0.80. Table 1. Dialogue act tags Dialogue Act Tutor Example ASSESSING Q. Which type should that be? EXTRA-DOMAIN A coordinator will be there soon. GROUNDING Ok. LUKEWARM FDBK That?s close. LUKEWARM CONTENT FDBK Almost there, but the second parameter isn?t quite right. NEGATIVE FDBK That?s not right. NEGATIVE CONTENT FDBK No, the counter has to be an int. POSITIVE  FDBK Perfect. POSITIVE CONTENT FDBK Right, the array is a local varia-ble. QUESTION Which approach do you prefer? RESPONSE It will be an int. STATEMENT They start at 0. Table 2. Task correctness tags Correctness Tag Description CORRECT Fully conforming to the require-ments of the task. BUGGY Violating the requirements of the task. These task events typically require tutorial remediation. INCOMPLETE Not violating, but not yet fulfilling, the requirements of the task. 
DISPREFERRED Technically fulfilling requirements but not utilizing the target con-cepts being tutored. These events typically require tutorial remediation. 3.3 Annotation for Delayed Tutor Feedback The dialogue act and task annotations reflect posi-tive evidence regarding what did occur in the dia-logues. An additional annotation was introduced for what did not occur?specifically, instances in which tutors did not to make a dialogue move in response to students? relevant task actions. The task in our corpus is computer programming, so bugs in the task correspond to errors either in syntax or se-
51
mantics of the computer program compared to the desired outcome. The human tutors were working with only one student at a time and were carefully monitoring student task actions during the dialogue, so we take the absence of a dialogue move at a rel-evant point to be an intentional choice by the tutor to delay feedback as part of the tutorial strategy. The automatic annotation for delayed feedback in-troduced two new event tags: NO-MENTION of cor-rectly completed subtasks, and NO-REMEDIATION of existing bugs within the task.  The intuition behind these tags is that within a learned dialogue policy, specifically modeling when not to intervene is crucial. Typically human tutors mention correctly completed subtasks, but at times other tutorial goals eclipse the importance of doing so. The NO-MENTION tag captures these in-stances. On the other hand, typically when working with novices, human tutors remediate an existing bug quickly. However, tutors may choose to delay this remediation for a variety of reasons such as remediating a different bug instead or asking a con-ceptual question to encourage the student to reflect on the issue. The NO-REMEDIATION tag captures these instances of the absence of remediation given that a bug was present. These two annotations for delayed feedback were performed automatically (Boyer, Phillips, Ha, et al, in press).  3.4 Adjacency Pair Modeling Prior work has demonstrated that adjacency pairs can be identified in an unsupervised fashion from a corpus (Midgley, Harrison, & MacNish, 2006). This technique relies on statistical analysis to de-termine the significant dependencies that exist be-tween pairs of dialogue acts, or in our task-oriented corpus, pairs of dialogue acts or task actions. After the pairs of dependent events are identified, they are joined within the corpus algorithmically (Boyer et al, 2009). Joining a pair of dependent moves in this way is equivalent to introducing a deterministic (probability=1) succession between observation symbols. This type of dependency cannot be learned in the traditional first-order HMM frame-work, but is desirable when two observations are strongly linked.1                                                             1 Enhanced HMM structures, such as autoregressive HMMs, which allow for direct graphical links between observation symbols, can learn such a dependency but only in stochastic terms. 
The experiment that is described in Section 4 utilizes different feature sets to learn and compare HMMs. Table 3 shows these feature sets and their most highly statistically significant adjacency pairs. Table 3. Experimental conditions and top three ad-jacency pairs (subscripts denote speaker, Student or Tutor) Condition Description Significant Adjacency Pairs DAONLY Dialogue acts only QS~RspT  GroundS~GroundT AssessQT~PosFdbkS 
DATASK Dialogue acts & task cor-rectness events 
QS~RspT CorrectTaskS~CorrectTaskS GroundS~GroundT 
DATASK-DELAY 
Dialogue acts, task correctness, & delayed feedback  
QS~RspT NoRemediateT~BuggyTaskS CorrectTaskS~CorrectTaskS 
4 Models HMMs were selected as the modeling framework for this work because their sequential nature is well suited to the structure of human dialogue, and their ?hidden? variable corresponds to widely held con-ceptions of dialogue as having an unobservable, but influential, layer of stochastic structure. For exam-ple, in tutoring, an ?explanation? mode is common, in which the tutor presents new information and the student provides acknowledgments or takes task actions accordingly. Although the presence of the ?explanation? goal is not directly observable in most dialogues, it may be inferred from the obser-vations. These sequences correspond to the input observations for learning an HMM.  4.1 Hidden Markov Models HMMs explicitly model hidden states within a doubly stochastic structure (Rabiner, 1989). A first-order HMM, in which each hidden state depends only on the immediately preceding hidden state, is defined by the following components: ? ? = {?1, ?2, ?, ?M}, the observation sym-bol alphabet ? S = {s1,s2,?,sN}, the set of hidden states 
52
? ?=[?i], i=1,?,N, the initial probability dis-tribution, where ?i is the probability of the model beginning in hidden state si in S  ? A=[aij], a transition probability distribution, where aij is the probability of the model transitioning from hidden state i to hidden state j for i,j=1,?,N ? B=[bik], an emission probability distribu-tion where bik is the probability of state i (i=1,?,N) emitting (or generating) obser-vation symbol k (k=1,?,M). 4.2 Dialogue Modeling with HMMs In this work, the observation symbol alphabet ? is given. For each experimental condition, ? is either 1) all dialogue act tags, 2) all dialogue acts plus task correctness tags, or 3) dialogue act, task cor-rectness, and delayed feedback tags. The transition probability distribution A, emission probability dis-tribution B, and initial probability distribution ? are learned by the standard Baum-Welch algorithm for optimizing HMM parameters (Rabiner, 1989). This algorithm is susceptible to becoming trapped in local optima, so our approach uses ten-time random restart with new initial parameters for each model to reduce the probability of selecting a model that represents only a local optimum.  The hyperparameter N, which is the best number of hidden states, is also learned rather than fixed. This process involves running the full HMM train-ing algorithm, including random restarts in ten-fold cross-validation, across the data and selecting the N that corresponds to the best mean goodness-of-fit measure. For HMMs, a typical goodness-of-fit measure is log-likelihood, which captures how like-ly the observations would be under the current model. The log is taken for practical reasons, to avoid numerical underflow. Higher log-likelihood corresponds to improved model fit. However, typi-cally it is desirable to penalize a higher number of hidden states, since increasing the model complexi-ty results in tradeoffs that may not be fully warrant-ed by the improvement in model fit. In this work, we utilize the Akaike Information Criterion (AIC), a standard penalized log-likelihood metric (Akaike, 1976).     
AIC = 2*N ? 2*ln(likelihood) Lower values of AIC indicate better model fit. 4.3 Experimental Conditions HMMs were learned using three separate feature sets, each providing a progressively more complete picture of the task-oriented dialogues: dialogue acts only (DAONLY), dialogue acts and task events (DATASK), and dialogue acts with both task cor-rectness events and tags for delayed tutor feedback (DATASKDELAY).  In addition to the three different feature sets, each condition included one of two types of pre-processing. Each type of model was trained on un-altered sequences of the annotated tags, which we refer to as the UNIGRAM condition. Additionally, each type of model was trained on sequences with statistically dependent adjacency pairs joined in a preprocessing step as described in Section 3.4. The UNIGRAM and ADJPAIR conditions were explored for each of the three feature sets, resulting in six experimental conditions. These conditions were chosen in order to explore the convergence behav-ior of HMMs under the different feature sets and preprocessing, and to compare measures of descrip-tive fit with measures of predictive power.  4.4 Learned HMMs Figures 1 and 2 show a subset of the DAONLY UNIGRAM model and the DATASKDELAY ADJPAIR model. These figures depict the structure of our HMMs: each hidden state is associated with an emission probability distribution over the possible observation symbols.  5 Goodness-of-Fit Curves The learning algorithm described in Section 4.2 was applied to input sequences under the six exper-imental conditions to learn the best-fit HMM pa-rameters. Figure 3 displays these AIC results, which are discussed in detail in the remainder of this section.   
53
 Figure 1. Subset of learned HMM (N=13) for DAONLY UNIGRAM condition  
 Figure 2. Subset of learned HMM (N=9) for DATASKDELAY ADJPAIR condition  5.1 Impact of Experimental Conditions  For the DAONLY condition, both the UNIGRAM and ADJPAIR models generally improve until N=12 or 13, after which the fit generally worsens. A differ-
ent pattern emerges for the DATASK condition, in which the UNIGRAM sequences are optimally fit to a model with 16 states, while the ADJPAIR se-quences are fit to a model with 8 states. Finally, for the DATASKDELAY condition, the UNIGRAM se-quences are best fit by a model with 10 hidden states, while the ADJPAIR sequences are fit best by 9. Typically, we see that ADJPAIR sequences are fit to slightly simpler models in terms of the hy-perparameter N, number of hidden states.   
Figure 3. Number of hidden states and cor-responding adjusted AIC, shifted to a mini-mum score of zero indicating the best-fit N 
Adjust
ed AIC
 
a) Dialogue ActsOnly (DAONLY) 
  N (number of hidden states) 
Adjust
ed AIC
 
b) Dialogue Act and Task Events (DATASK) 
  N (number of hidden states) 
Adjust
ed AIC
 
c) Dialogue Act, Task, & Delayed Feedback (DATASKDELAY)  
  N (number of hidden states) 
54
Stability in the hyperparameter N is an im-portant consideration because an underlying as-sumption of our work is that the hidden states correspond to unobserved stochastic structures of the real world process?that is, we hypothesize that a ?true? value for N exists. We would like models to exhibit decreasing variation in goodness of fit measures around this true N. To examine this stability we consider the three best AIC values for each condition and their corresponding Ns: the set {Nk-best | k=1,2,3}. The range of this set indicates how ?far apart? the best three Ns are: for example, in the DAONLY UNIGRAM condition, the top three models have Ns of {13,10,15}, yielding a range of 5. Intuitively, a small value for this metric indicates that the model has converged tightly on N.  Figure 4 shows the stability results for the six different experimental conditions. As shown in the figure, for the DATASK and DATASKDELAY condi-tions, the ADJPAIR models achieve the smallest range among the top three values of N; these mod-els converge most tightly to the ?best? value.   
 Figure 4. Stability of N (range of {N1best, N2best, N3best}) ? smaller implies tighter convergence to ?best? N 6 Predictive Analysis Section 5 presented an analysis of the goodness-of-fit curves of HMMs learned from the corpus. The measures of stability and discrimination for N cap-ture important aspects of the behavior of HMMs toward this parameter, which is conceived of as representing ?true? real-world stochastic behavior. In this way, Section 5 has presented a descriptive view of HMM dialogue models.  This section presents a predictive view of the models. Specifically, we consider prediction accu-racy, defined as the percent of tutor dialogue moves 
that the model is able to correctly predict given the dialogue history sequence up to that point.  6.1 Impact of Dependent Adjacency Pairs We first explore whether the preprocessing step of joining dependent adjacency pairs impacted predic-tion accuracy. The prediction accuracy of the best-fit model in each condition is displayed in Figure 5. This figure includes prediction accuracy on training data, which were used to learn model parameters, as well as prediction accuracy on testing data, which were withheld from model training.  
 Figure 5. Prediction accuracy for tutor moves  As shown in Figure 5, joining the adjacency pairs improved model performance on the training sets of all three conditions, indicating that the varia-tion within the training data was better explained by ADJPAIR models. (This measure of predictive power is different from a goodness-of-fit criterion as described in the previous section, a relationship that will be discussed further in Section 7.) In con-trast to the training set performance, the ADJPAIR models performed better than UNIGRAM models for the testing set only in the DATASKDELAY condi-tion.   6.2 Impact of Task-Oriented Feature Sets As illustrated in Figure 5, the three feature sets per-form similarly under the UNIGRAM condition. This performance is slightly above baseline (DAONLY and DATASK baselines = 0.38; DATASKDELAY baseline = 0.30), and diminishes little between the training and testing sets. In contrast, under the ADJPAIR condition, performance between condi-tions and across training and testing sets varies. The DATask model performs far better on predicting observations in the training than the testing set, 
55
suggesting possible overfitting to the training set. This relationship is discussed further in Section 7. The DATASKDELAY model performs well during both training and testing, though with a slight de-crease in accuracy on the testing set.   6.3 Relationship Between Predictive and De-scriptive Metrics Measures of fit such as log-likelihood and AIC cap-ture the likelihood of observing the data given a model. Predictive accuracy, on the other hand, measures the probability that the model can predict the next observation given a partial sequence. In general, we would expect these measures to corre-late well; however, there is not perfect correlation between these metrics because the mechanism by which log-likelihood (and thereby AIC) is derived involves maximizing likelihood over complete se-quences, while prediction is performed over partial sequences.  To examine how well AIC and prediction accu-racy correlate, Figure 6 displays these values for a subset of the models in the DAONLY UNIGRAM condition and the DATASKDELAY ADJPAIR condi-tion. These two conditions represent the extremes of the experimental conditions, with DAONLY con-taining the least information about the task-oriented dialogue while DATASKDELAY contains the most information.  As shown in Figure 6, the correlation for DAONLY UNIGRAM roughly conforms to what would be expected: lower AIC, indicating better model fit, is associated with the highest prediction accuracies. The relationship is less clear for the DATASKDELAY ADJPAIR condition. While its worst AIC is associated with the lowest prediction accuracy as expected, the best AIC is not associated with the highest prediction accuracy. This phenom-enon may be due to the lack of spread among AIC values overall for this condition; as seen in Figure 3, the DATASKDELAY ADJPAIR condition has the flattest AIC curve of all conditions, indicating that for this condition the difference between best-fit and worst-fit models is smaller than for any other condition. The inconsistent relationship between AIC and prediction accuracy, therefore, may be the product of noise surrounding a large set of ?good? models, whereas for the DAONLY UNIGRAM condi-tion, the set of good models is smaller.   
 7 Discussion The results suggest several important findings re-garding feature sets and preprocessing for learning HMMs of task-oriented dialogue. First, the models? convergence patterns to a best-fit N, number of hidden states, indicate that more information em-bedded within the sequences may correspond with a flatter goodness-of-fit curve. Adding more infor-mation to the input sequences may introduce some regularities that partly mitigate the limitations of even a poorly fit HMM. This additional infor-mation may come in the form of adjacency pairs discovered in an unsupervised fashion, which im-proved the stability of convergence on the best-fit N under the DATASK and DATASKDELAY condi-tions. This increased stability is likely due to the fact that under these conditions, leveraging adja-cency pair information augments the HMM?s struc-ture with contextual dependencies that could otherwise not be learned under the traditional HMM framework.  For predictive accuracy, the benefits of richer input sequences are also highlighted. The most highly predictive models included all three sources 
Predic
tion Ac
curacy
 a) DAOnly UNIGRAM Condition 
  AIC 
Predic
tion Ac
curacy
 b) DATASKDELAY ADJPAIR Condition  
  AIC Figure 6. Prediction accuracy vs. AIC 
56
of information: dialogue acts, task events, and de-layed feedback tags. However, with the addition of this rich information to the input sequences and the accompanying flatter goodness-of-fit curve as dis-cussed above, we noted an irregular pattern of cor-relation between goodness-of-fit and predictive accuracy that is worthy of future exploration. Spe-cifically, it appears that the most highly predictive DATASKDELAY ADJPAIR model, which is the most highly predictive of all models in all conditions, does not correspond to the best (lowest) AIC for that condition (Figure 3). This finding suggests that when a predictive task is the primary goal, a predic-tive metric should be used to select the best-fit model. Additional support for such an approach is provided by the close correspondence between training and testing set prediction accuracy. 8 Conclusion Understanding how HMMs behave under different feature sets is an important step toward learning effective models of task-oriented dialogue. This paper has examined how HMMs converge to a best number of hidden states under different experi-mental conditions. We have also considered how well HMMs under these conditions predict tutor dialogue acts within a corpus of task-oriented tutor-ing, a crucial step toward learning dialogue policies from human corpora. The findings highlight the importance of adding rich task-based features to the input sequences in order to learn HMMs that con-verge tightly on the best-fit number of hidden states. The results also indicate that caution should be used when utilizing traditional goodness-of-fit metrics, which are appropriate for descriptive ap-plications, if the goal is to learn a highly predictive model.  This line of research is part of a larger research program of learning unsupervised models of human task-oriented dialogue that can be used to define the behavior of dialogue systems. Developing a framework for learning a dialogue policy from hu-man corpora, as discussed here, is a critical step toward that goal. Future work should focus on un-supervised dialogue act classification, and address the challenges of user plan recognition.  
Acknowledgments. This work is supported in part by National Science Foundation through Grants REC-0632450, IIS-0812291, DRL-1007962 and the STARS 
Alliance Grant CNS-0739216. Any opinions, findings, conclusions, or recommendations expressed in this re-port are those of the participants, and do not necessarily represent the official views, opinions, or policy of the National Science Foundation. References Akaike, H. (1976). An information criterion (AIC). Math. Sci., 14(153), 5-9. Bangalore, S., Di Fabbrizio, G., & Stents, A. (2006). Learning the structure of task-driven human-human dialogs. Proceedings of ACL ?06, 201-208.  Boyer, K. E., Ha, E. Y., Phillips, R., Wallis, M. D., Vouk, M. A., & Lester, J. C. (2010). Dialogue Act Modeling in a Complex Task-Oriented Domain. Proceedings of SIGDIAL (pp. 297-305).  Boyer, K. E., Phillips, R., Ha, E. Y., Wallis, M. D., Vouk, M. A., & Lester, J. C. (in press). Learning a Tutorial Dialogue Policy for Delayed Feedback. Proceedings of the 24th International FLAIRS Con-ference. Boyer, K. E., Phillips, R., Ha, E. Y., Wallis, M. D., Vouk, M. A., & Lester, J. C. (2009). Modeling dia-logue structure with adjacency pair analysis and hid-den Markov models. Proceedings of NAACL HLT, Companion Volume, 49-52.  Boyer, K. E., Phillips, R., Ha, E. Y., Wallis, M. D., Vouk, M. A., & Lester, J. C. (2010). Leveraging Hidden Dialogue State to Select Tutorial Moves. Proceedings of the NAACL HLT 2010 Fifth Work-shop on Innovative Use of NLP for Building Educa-tional Applications (pp. 66-73). Boyer, K. E., Phillips, R., Ingram, A., Young, E., Wallis, M., Vouk, M., et al (in press). Investigating the Re-lationship Between Dialogue Structure and Tutoring Effectiveness: A Hidden Markov Modeling Ap-proach. International Journal of Artificial Intelli-gence in Education. Di Eugenio, B., Xie, Z., & Serafin, R. (2010). Dialogue Act Classification, Higher Order Dialogue Structure, and Instance-Based Learning. Dialogue & Dis-course, 1(2), 1-24.  Georgila, K., Lemon, O., Henderson, J., & Moore, J. D. (2009). Automatic annotation of context and speech acts for dialogue corpora. Natural Language Engi-neering, 15(3), 315-353.  Midgley, T. D., Harrison, S., & MacNish, C. (2006). Empirical verification of adjacency pairs using dia-logue segmentation. Proceedings of SIGDIAL, 104-108.  Rabiner, L. R. (1989). A tutorial on hidden Markov models and selected applications in speech recogni-tion. Proceedings of the IEEE, 77(2), 257-286.  
57
Rotaru, M., & Litman, D. J. (2009). Discourse Structure and Performance Analysis : Beyond the Correlation. Proceedings of SIGDIAL (pp. 178-187). Stolcke, A., Ries, K., Coccaro, N., Shriberg, E., Bates, R., Jurafsky, D., et al (2000). Dialogue Act Model-ing for Automatic Tagging and Recognition of Con-versational Speech. Computational Linguistics, 26(3), 339-373.  VanLehn, K., Graesser, A. C., Jackson, G. T., Jordan, P., Olney, A., & Rose, C. P. (2007). When Are Tutorial 
Dialogues More Effective Than Reading? Cognitive Science: A Multidisciplinary Journal, 30(1), 3-62.  Woszczyna, M., & Waibel, A. (1994). Inferring linguis-tic structure in spoken language. Proceedings of the International Conference on Spoken Language Pro-cessing (pp. 847-850). Young, S., Ga?i?, M., Keizer, S., Mairesse, F., Schatzmann, J., Thomson, B., et al (2010). The Hid-den Information State model: A practical framework for POMDP-based spoken dialogue management. Computer Speech & Language, 24(2), 150-174.   Appendix. Excerpt from task-oriented textual human-human tutoring corpus. Speaker Utterance or Event Tag Student: [Task action on subtask 3-c-i-4] BUGGY Student: [Task action on subtask 3-c-ii-5] CORRECT Tutor: [Does not provide remediation for existing bug] NOREMEDIATION Student: [Task action on subtask 3-c-iii-1] BUGGY Student: i don't remember off the top of my head how the swap function worked. most of the time i just copied and pasted it from some of my older code NEGATIVECONTENTFDBK Tutor: The easiest way to swap x and y is to make a tempo-rary variable  Student: Ok ACK Student: do i need to pass the entire array and the indecies of the items to swap? ASSESSQ Tutor:  if you want to use a seperate method to swap, then yes, you'll have to pass those things  POSCONTENTFDBK Tutor:  [Does not mention a correctly completed subtask]	 ? NOMENTIONCOMP Student: oh. i guess i could just swap it in the same method. it is problably easier that way, and less code. we were showed in class how to do it separately, but i had never thought of doing it the other way.  
STMT 
Student: [Task action on subtask 3-c-iii-2] DISPREFERRED Tutor:  Both ways work, but it?s definitely less code to just do it inside this method.  STMT Student: Ok ACK  
58
Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pages 247?256,
Seoul, South Korea, 5-6 July 2012. c?2012 Association for Computational Linguistics
Combining Verbal and Nonverbal Features to Overcome the ?Information Gap? in Task-Oriented Dialogue 
 Eun Young Ha, Joseph F. Grafsgaard, Christopher M. Mitchell,  Kristy Elizabeth Boyer, and James C. Lester Department of Computer Science North Carolina State University Raleigh, NC, USA {eha, jfgrafsg, cmmitch2, keboyer, lester}@ncsu.edu    Abstract Dialogue act modeling in task-oriented dialogue poses significant challenges. It is particularly challenging for corpora consisting of two interleaved communication streams: a dialogue stream and a task stream. In such corpora, information can be conveyed implicitly by the task stream, yielding a dialogue stream with seemingly missing information. A promising approach leverages rich resources from both the dialog and the task streams, combining verbal and non-verbal features. This paper presents work on dialogue act modeling that leverages body posture, which may be indicative of particular dialogue acts. Combining three information sources (dialogue exchanges, task context, and users? posture), three types of machine learning frameworks were compared. The results indicate that some models better preserve the structure of task-oriented dialogue than others, and that automatically recognized postural features may help to disambiguate user dialogue moves.  1 Introduction Dialogue act classification is concerned with understanding users? communicative intentions as reflected in their utterances. It is an important first step toward building automated dialogue systems. To date, the majority of work on dialogue act 
modeling has addressed spoken dialogue (Samuel et al, 1998; Stolcke et al, 2000; Surendran and Levow, 2006; Bangalore et al, 2008; Sridhar et al, 2009; Di Eugenio et al, 2010). However, with the increasing popularity of computer-mediated means of conversation, such as instant messaging and social networking services, automated analysis of textual dialogue holds much appeal. Dialogue act modeling for textual conversations has many practical application areas, which include web-based intelligent tutoring systems (Boyer et al, 2010a), chat-based online customer service (Kim et al, 2010), and social media analysis (Joty et al, 2011). Human interaction involves not only verbal communication but also nonverbal communication. Research on nonverbal communication (Knapp and Hall, 2006; Mehrabian, 2007; Russell et al, 2003) has identified a range of nonverbal cues, such as posture, gestures, eye gaze, and facial and vocal expressions. However, the utility of these nonverbal cues has not been fully explored within the context of dialogue act classification research. Previous research has leveraged prosodic cues (Sridhar et al, 2009; Stolcke et al, 2000) and facial expressions (Boyer et al, 2011) for automatic dialogue act classification, but other types of nonverbal cues remain unexplored. As a first step toward a dialogue system that learns its behavior from a human corpus, this paper proposes a novel approach to dialogue act classification that leverages information about users? posture. Posture has been found to be a significant indicator of a broad range of emotions (D?Mello and Graesser, 2010; Kapoor et al, 2007; Woolf et al, 2009). Based on the premise that emotion plays an 
247
important role in dialogue, this work hypothesizes that adding posture features will improve the performance of automatic dialogue act models.   The domain considered in this paper is task-oriented textual dialogue collected in a human tutoring study. In contrast to conventional task-oriented dialogue corpora (e.g., Carletta et al, 1997; Jurafsky et al, 1998; Ivanovic, 2008) in which conversational exchanges are carried out within a single channel of dialogue between the dialogue participants, the corpus used in this work utilizes two separate and interleaved streams of communication. One stream is the textual conversation between a student and a tutor (dialogue stream). The other is the student?s problem-solving activity (task stream). As will be described in Section 3, the interface used in the corpus collection was designed to allow the tutor to monitor the student?s problem-solving activities. Thus, the student?s problem-solving activities and the tutor?s monitoring of those activities functioned as an implicit communication channel. This characteristic of the corpus poses significant challenges for dialogue act modeling. First, because the dialogue stream and the task stream are interleaved, the dialogue stream alone may not be coherent. Second, since information can be exchanged implicitly via the task stream, the dialogue likely contains substantial information gaps1. Addressing these challenges, the dialogue act models described in this paper combine three sources of information: the verbal information from the dialogue stream, the task-related context from the task stream, and information about users? posture. This paper makes several contributions to the dialogue research community. First, it is the first effort to explore posture as a nonverbal cue for dialogue act classification. Second, the proposed approach is fully automatic and ready for real-world application. Third, this paper explicitly defines the notion of information gap in task-oriented dialogue consisting of multiple communication channels, which has only begun to be explored in the context of dialogue act classification (Boyer et al, 2010a). Finally, this                                                 1 In this paper, information gap is defined as the information that is missing from the explicit verbal exchanges between the dialogue participants but conveyed by the implicit task stream. 
paper examines adaptability of previous dialogue act classification approaches in conventional task-oriented domains by comparing three classifiers previously applied to dialogue act modeling for task-oriented dialogue. 2 Related Work A rich body of research has addressed data-driven approaches for dialogue act modeling. Russell et al (2003) applied a transformation-based learning approach for dialogue act tagging for spoken dialogue, using speaker direction, punctuation, marks, and cue phrases. Stolcke et al (2000) modeled the structure of dialogue as an HMM, treating the dialogue acts as the observations emitted from the hidden states of the learned HMM. More recently, Bangalore et al (2008) proposed a unified approach to task-oriented dialogue, in which both the user dialogue act classification and the system dialogue act selection were informed by a shared maximum entropy dialogue act classifier. Sridhar et al (2009) also used a maximum entropy model, exploring the utility of different representations of prosodic features. Di Eugenio et al (2010) used a memory-based classifier, in combination with a modified latent semantic analysis (LSA) technique by augmenting the original word-document matrix in LSA with rich linguistic features. While most work on dialogue act modeling has focused on spoken dialogue, a recent line of investigation has explored the analysis of textual conversation, such as asynchronous online chat conversation (Wu et al, 2005; Forsyth, 2007; Reitter et al, 2010; Joty et al, 2011) and synchronous online chat conversation   (Ivanovic, 2008; Kim et al, 2010; Boyer et al, 2010a). Wu et al (2005) proposed a transformation-based learning approach for an asynchronous chat posting domain, utilizing regular expression-based selection rules. For a similar domain, Forsyth (2007) applied neural networks and Na?ve Bayes classification technique using lexical cues. Ritter et al (2010) and Joty et al (2011) applied unsupervised learning approaches to dialogue act modeling for Twitter conversations, in which dialogue acts were automatically discovered by clustering raw utterances. Work by Ivanovic (2008) and Kim et al (2010) analyzed one-to-one synchronous online chat dialogue in a task-oriented 
248
customer service domain. Ivanovic (2008) applied maximum entropy, na?ve Bayes, and support vector machines using word n-gram features. Kim et al (2010) compared the CRF, HMM-SVM, and Na?ve Bayes classifiers using word n-grams and features extracted from the dialogue structure, in which CRF achieved the highest performance. Boyer et al (2010a) investigated dialogue act modeling for task-oriented tutorial dialogue, applying a logistic regression approach using lexical, syntactic, dialogue structure, and task structure features. Some previous dialogue act modeling work (Boyer et al, 2011; Sridhar et al, 2009; Stolcke et al, 2000) leveraged nonverbal information such as prosodic cues (Sridhar et al, 2009; Stolcke et al, 2000) and facial expressions (Boyer et al, 2011). Stolcke et al (2000) combined various prosodic features such as pitch, duration, and energy. Sridhar et al (2009) represented the sequence of prosodic features as n-grams. Boyer et al (2011) leveraged confusion-related facial expressions for tutorial dialogue. Like Boyer et al (2010a), this work addresses dialogue act classification for task-oriented textual conversation in a web-based tutoring domain. In contrast to Boyer et al (2010a), whose approach directly leveraged manually annotated features, making it challenging to apply the proposed model to a real-world system, the present work is fully automatic and ready for real-world application.  A novel feature of this work is its utilization of nonverbal cues carried by users? posture. This is the first dialogue act classification work that leverages posture information. 3 Data The corpus used in this paper consists of textual exchanges between a student and a tutor in a web-based remote-tutoring interface for introductory programming in Java. The corpus was collected from a series of six tutoring lessons, covering progressive topics in computer science over the course of four weeks. The tutoring interface consisted of four windows: a task window displaying the current programming task; a code window in which the student writes Java code; an output window for displaying the result of compiling and running the code; and a chat window for instant exchange of textual dialogue 
between the student and tutor. With this tutoring interface, the student and the tutor were able to exchange textual dialogue and share a synchronized view of the task. Apart from sending dialogue messages, the only action the tutor could perform to affect the student?s interface was advancing to the next programming task.  3.1 Data Collection The data collection conducted in Fall 2011 paired 42 students with one of four tutors for six forty-minute tutoring sessions on introductory computer science topics.  The students were chosen from a first-year engineering course and were pre-screened to filter out those with significant programming experience. The tutors were graduate students with previous tutoring or teaching experience in Java programming. Students were compensated for their participation with partial course credit. The students worked with the same tutor for the entire study. Each lesson consisted of between four and thirteen distinct subtasks. During each tutoring session, the dialogue text exchanged between the student and the tutor was logged to a database. Additional runtime data including content of the student?s Java code, the result (e.g., success or failure) of compiling and running the student?s code, and the IDs of the subtask were logged. All logged data were time-stamped at a millisecond precision. Students? body posture was recorded at a rate of 8 frames per second with a Kinect depth camera, which emits infrared rays to measure distance for each pixel in a depth image frame. The camera was positioned above the student?s computer monitor, ensuring the student?s upper body is centered in the recorded image. Tutors were not recorded. 3.2 Dialogue Act Annotation For the work described in this paper, a subset of the collected data was manually annotated, which include the first of the six tutoring lessons from 21 students. This corpus contains 2564 utterances (1777 tutor, 787 student). The average number of utterances per tutoring session was 122 (min = 74; max = 201). The average number of tutor utterances per session was 84.6 (min = 51; max = 137) and the average number of student utterances per session was 37.4 (min = 22; max = 64). 
249
Extending a previous annotation scheme used for similar task-oriented tutorial dialogue (Boyer et al, 2010b), the scheme used in this work consists of 13 dialogue act tags (Appendix). The dialogue turns that contained more than one dialogue function were segmented into multiple utterances before being assigned a dialogue act tag. The annotation scheme did not constrain any of the dialogue act tags as applying either to students? or tutors? utterances only; however, the resulting distribution of the tags in the annotated corpus show certain dialogue act tags were more relevant to either students? or tutors? utterances. Figure 1 depicts an excerpt from the corpus with the manually applied dialogue act annotations.  
 Three human annotators were trained to apply the scheme. The training consisted of an iterative process involving collaborative and independent tagging, followed by refinements of the tagging protocol. At the initial phase of training, the annotators tagged the corpus collaboratively. In later phases annotators tagged independently. To compute agreement between different annotators, 24% (5 of the 21 sessions) of the corpus were doubly annotated by two annotators. All possible 
pairs of the annotators participated in double annotation. The aggregate agreement was .80 in Cohen?s Kappa (Cohen, 1960). 3.3 Posture Estimation Posture has been found to be a significant indicator of a broad range of emotions such as anxiety, boredom, confusion, engaged concentration (or flow), frustration, and joy (D?Mello and Graesser, 2010; Kapoor et al, 2007; Woolf et al, 2009). Early investigations into posture utilized pressure-sensitive chairs which provided indirect measures of upper-body posture (D?Mello and Graesser, 2010; Kapoor et al, 2007; Woolf et al, 2009). Newer, computer vision-based techniques provide more detailed postural data (Sanghvi et al, 2011). The present work uses a posture estimation algorithm developed to automatically detect the head, mid torso, and lower torso through depth image recordings of seated individuals (Grafsgaard et al, 2012). With this estimation algorithm, posture is represented as a triple of head depth (distance between camera and head), mid torso depth, and lower torso depth. A dataset of depth camera recordings from the first of the six tutoring lessons consists of 512,977 depth image frames collected across 18.5 hours of computer-mediated human-human tutoring among 33 participants.2 For each depth image frame, the posture algorithm scanned through the three middle regions that corresponded to head, mid-torso, and lower-torso of the recorded person, and selected a single representative depth pixel from each region. The boundaries for each region were heuristically determined relying on the placement of the students? chairs in the middle of the depth recording view at a common distance. Given these constraints, the model was manually verified by two independent human judges to have 95.1% accuracy across 1,109 depth image snapshots corresponding to one-minute intervals across the dataset. The algorithm output for each depth image was labeled as erroneous if either judge found that any of the posture tracking points did not coincide with its target region. Example output of the algorithm is shown in Figure 2.  
                                                2 The other 9 sessions were not successfully recorded because of technical errors. 
Tutor: hang on :) [S] Tutor: When we show you example code, it is not the code you need to write. [S] Tutor: Look at the task again. [H] Student writes programming code Tutor: YUP [PF] Tutor: Perfect [PF] Tutor: OK. Go ahead and test. [DIR] Student: And I don't need anything in the parentheses? [Q] Tutor: Line 9 is correct. You do NOT need anything inside the parentheses. [A] Student: Ok [ACK] Student compiles and runs code successfully Tutor: Good. [PF]  Tutor: Moving on. [S] Tutor advances to the next task. Student writes programming code Tutor: Syntactically correct. But there is a logic error [LF] Tutor: When will the output statement display your request to the player? [Q] Student: AFTER they put in their name [A] Tutor: Exactly [PF] Figure 1. Corpus Excerpt with Dialogue Act Annotation 
250
4 Features For web-based one-to-one dialogue systems, it is important to achieve efficient runtime performance. To maximize real-world feasibility of the learned dialogue act classifiers, this work only considers the features that can be automatically extracted at runtime. In addition, the use of linguistic analysis software, such as a part-of-speech tagger and a syntactic parser, is intentionally restrained. One might argue that rich linguistic analysis may provide additional information to dialogue act classifiers, potentially improving the performance of learned models. However, there is a trade-off between additional information obtained by rich linguistic analysis and processing time. In addition, previous work (Boyer et al, 2010a) found part-of-speech and syntax features did not provide obvious benefit for dialogue act classification in a domain similar to the one considered in this work. The dialogue act classifiers described in this paper integrate four classes of features automatically extracted from three sources of information: the textual dialogue utterances, task-related runtime information logged into the database, and the images of the students recorded by depth cameras. Each feature class is explained in the following subsections. 4.1 Lexical Features Based on previous dialogue act classification research (Bangalore et al, 2008; Boyer et al, 2010a; Kim et al, 2010), this work utilizes word n-grams as features for dialogue act classification. In the experiment reported in Section 5, unigrams and 
bigrams were used. Adding higher order n-grams did not improve model accuracies. In our corpus (Section 3), the nature of the student dialogues is informal and utterances contain many typos. To remove undesirable noise in the data such as typos and rare words, n-grams were filtered out according to their frequency in the training data (i.e., n-grams that appear less than a predefined cutoff threshold in the training data are not included as features). The value of the cutoff threshold was empirically determined by testing the values between 0 and 10 on a development data set that consisted of 20% of randomly selected dialogue sessions. The value of 3 was selected as it yielded the highest classification accuracy. 4.2 Dialogue Context Features While lexical features characterize the intrinsic nature of individual utterances, the context of the utterance within a larger dialogue structure provides additional information about a given utterance in relation with other utterances. This work considers the following dialogue context features: ? Utterance Position: Specifies the relative position of an utterance at a given turn. The value of this feature indicates whether the utterance is the first one in a given turn, the second or later one in a given turn, or the given turn consists of a single utterance. ? Length: Specifies the number of a given utterance in terms of individual word tokens. ? Previous Author: Indicates whether the author of the previous utterance was student or tutor. ? Previous Tutor Dialogue Act: Specifies dialogue act of the most recent tutor utterance. The value of this feature is directly extracted from the manual annotation in the corpus, because in the broader context of our work, tutor dialogue moves will be determined by an external dialogue management module.   4.3 Task Context Features In our data, students? problem-solving activities (e.g., reading the problem description, writing computer programming code, and compiling and running the code) functioned as an implicit communication channel between students and tutors (Section 1). Because of the existence of this 
Figure 2. Automatically detected posture points (H = headDepth, M = midTorsoDepth, L = lowerTorsoDepth)  
 H 
 M  L 
251
implicit communication channel, the dialogue exchanges between students and tutors likely contain substantial information gaps. To overcome such information gaps, it is important to identify effective task context features. The present work leverages the following task context features, which can be automatically extracted during runtime: ? Previous Task Action: Specifies the type of the most recent problem-solving action performed by the student. The value could be message (writing a textual message to the tutor) code (writing code in the code window), or compile_run (compiling or running the code). ? Task Begin Flag: A binary feature that indicates whether a given utterance is the first one since the current problem task was posted.  ? Task Activity Flag: Another binary feature indicating that a given utterance was preceded by a student?s task activity. ? Last Compile/Run Status: Specifies the status (e.g., begin, stop, success, error, input sent) of the most recent compile/run action performed by the students.  In addition to the listed task context features, the utility of time information was also explored, such as the amount of time taken for previous coding activity and the elapsed time since the beginning of the current task. However, these features did not positively impact the performance of the learned models and were thus excluded. 4.4 Posture Features After preprocessing recorded image frames with the estimation algorithm (Section 3.3), students? postures were represented as tuples of three different integer values, each respectively representing head depth, mid torso depth, and lower torso depth. To extract posture features, the time window of n seconds directly preceding a given utterance was compared with the previous time window of the same size in terms of min, max, median, average, and variance of each depth value. The indicators of whether each of these values has increased, decreased or remained the same were considered as potential posture features. To avoid introducing errors to the model by insignificant changes in posture, an error tolerance ?  was allowed (i.e., the two compared postures 
were considered the same unless the amount of the change in the posture was greater than ?). Optimal values for n and ?  were empirically determined, selecting the values that maximized classification accuracy on the development data set. For n, the values between 0 and 60 were compared at an interval of 10. The value of 50 was selected for head depth and 60 for both mid torso depth and lower torso depth.  Similarly, the value of ?  was determined by comparing the values between 0 and 200 with an increment of 10. The selected value was 100.  All the potential posture features were examined in an informal experiment, in which each of the potential posture features were added to the combination of the lexical, the dialogue context, and the task context features. The posture features that improved the classification accuracy after adding them were included in the present dialogue act models. The selected posture features are min of head depth and max, median, and average of lower torso depth. None of the mid torso depth features were selected. 5 Experiment The goal of this experiment is twofold: (1) to evaluate the effectiveness of the feature classes and (2) to compare the performance of three classifiers: maximum entropy (ME), na?ve Bayes (NB), and conditional random field (CRF). These classifiers are chosen because they have been shown effective for dialogue act modeling in traditional task-oriented textual dialogue, in which conversational exchanges were carried out by a single channel of dialogue (Ivanovic, 2008; Kim et al, 2010). Previous result by Kim et al (2010) suggests a structured model such as CRF yields more accurate dialogue act model compared to unstructured models (e.g., Na?ve Bayes), because of its ability to model the sequential patterns in target classification labels. This experiment examines whether a similar finding is observed for our domain, which exhibits substantial information gaps due to the existence of an implicit communication channel, the task stream. 5.1 Dialogue Act Modeling All classifiers were built using the MALLET package (McCallum, 2002). This experiment used the manually annotated portion of the data 
252
described in Section 3. The original dialogue scheme (Section 3.2) was slightly modified by introducing an additional dialogue act, GR, in order to distinguish conventional expressions, such as greetings and thanks, from other information-delivering utterances. For this modified scheme, annotator agreement was 0.81 in Cohen?s Kappa on the doubly annotated portion of the corpus. 6 among the 21 dialogue sessions in the annotated data do not have accompanying images due to technical problems with the depth camera, thus these sessions were excluded from this experiment. Table 1 shows the distribution of the student dialogue act tags in the resulting corpus of 15 dialogues used in this experiment. The most frequent tag was A (answer), followed by ACK (acknowledgement) and Q (question). The features were extracted by aligning three sources of information (the textual dialogue corpus, the task-related runtime log data, and the recorded images) by timestamp. Word boundaries in the dialogue corpus were recognized by the surrounding white spaces and punctuations. The dialogue context features (D) leveraged in this paper includes previous tutor dialogue act. This feature takes the manually annotated value in the corpus, because this work assumes the existence of an external dialogue manager. However, since the external dialogue manager is not likely to achieve 100% accuracy in predicting human tutor dialogue acts, it would be informative to estimate a reasonable range of the accuracies of the student dialogue act model, taking into account the errors introduced by the dialogue manager. For this reason, two versions of the dialogue context features were considered in this experiment: one that leverages the full set of dialogue context features (D) and the other that excludes previous 
tutor dialogue act (D-). These respectively provide the maximum and the minimum expected accuracy of the student dialogue act model, when used with a dialogue manager. The models were trained and tested using five-fold cross validation, in which the 15 dialogue sessions were partitioned into 5 non-overlapping sets of the same size (i.e., 3 sessions per partition). Each set was used for testing exactly once. 5.2 Results Table 2 reports the average classification accuracies from the five-fold cross validation. The majority baseline accuracy for our data is .347, when the classifier always chooses the most frequent dialog act (A). The first group of rows in Table 3 report the accuracies of individual feature classes. All of the individual features performed better than the baseline. The improvement from the baseline was significant except for D- with CRF. The most powerful feature class was dialogue context class when the full set was used. The second group in Table 3 shows the effects of incrementally combining the feature classes. Adding dialogue act features to the lexical features (L + D) brought significant improvement in the classification accuracy for ME and CRF. Adding posture features (L + D + T + P) also improved the accuracy of ME by a statistically significant margin. The last group shows similar results for ME when the previous tutor dialogue act was excluded from the dialogue context, except that the improvement achieved by adding the posture features (L + D- + T + P) was not significant.  
Student Dialogue Act Distribution A (answer) 192 (34.7%) ACK (acknowledgement) 124 (22.4%) Q (question)  92 (16.6%)  S (statement) 76 (13.7%) GR (greeting and thanks) 52 (9.4%) C (clarification) 6 (1.0%) RF (request for feedback) 5 (.9%) RC (request confirmation) 2 (.4%) O (other) 5 (.9%) Total 554 Table 1. Student dialogue acts in the experiment data 
Features ME NB CRF 
 Indiv
idual  Lexical (L)     .696
**     .703**     .599**  Dialogue (D)     .711**     .715**     .696**  Dialogue- (D-)     .477**     .473**     .405  Task (T)     .405**     .396*      .386*  Posture (P)     .382*     .385*     .399* 
 Max  L + D     .772
??     .724     .692??  L + D + T     .777     .729     .694  L + D + T + P     .789?     .714     .682 
 Min  L + D-     .724
??     .681     .606  L + D- + T     .733     .671     .627  L + D- + T + P     .750     .676     .644 Table 2. Classification accuracies (*p < .05, **p < .01 compared to baseline; ??p < .01 compared to L; and ?p < .05 compared to L + D + T, with paired-samples t-test)  
253
The highest accuracy was achieved by ME when using all four classes of the features, with maximum (L + D + T + P) .789 and minimum (L + D- + T + P) .750. For both the maximum and the minimum conditions, the differences among the classifiers were significant (p < .01, one-way repeated measure ANOVA), with post-hoc Tukey HSD tests revealing ME was significantly better than both NB (p < .05) and CRF (p < .01). There was no significant difference between NB and CRF. 6 Discussion The experiment described in Section 5 compared the utility of lexical, dialogue context, task context, and posture features for dialogue act classification. The results indicate the effectiveness of these features. Particularly, adding the dialogue context and the posture features improved the accuracy of the maximum entropy model. Although the margin of improvement achieved by adding posture features was relatively small, the improvement was statistically significant (p < .05) for the maximum condition (L + D + T + P), which suggests that the users? posture during computer-mediated textual dialogue conveys important communicative messages. The experiment also compared three classifiers: maximum entropy, na?ve Bayes, and CRF. Interestingly, CRF was the worst-performing model for our data, contradicting the previous finding by Kim et al (2010), in which CRF (a structured classifier) performed significantly better than Na?ve Bayes (a non-structured classifier). This contradictive result suggests that, in our domain, the presence of an implicit communication channel resulted in substantial information gaps in the dialogue and it poses new challenges that were not encountered by conventional task-oriented domains consisting of a single communication channel.  The maximum entropy classifier achieved the best overall performance, reaching accuracy of .789. This is an encouraging result compared to previous work in a similar domain. Boyer et al (2010a) reported an accuracy of .628 for dialogue act classification in a similar domain. However, a direct comparison is not applicable since different data were used in their work. 
7 Conclusions and Future Work Dialogue act modeling for a task-oriented domain in which the dialogue stream is interleaved with the task stream poses significant challenges. With the goal of effective dialogue act modeling, this work leverages information about users? posture as non-verbal features. An experiment found that posture is a significant indicator of dialogue acts, in addition to lexical features, dialogue context, and task context. The experiment also compared three statistical classifiers: maximum entropy, naive Bayes, and CRF. The best performing model was maximum entropy. Using all features, the maximum entropy achieved .789 in accuracy. Several directions for future work are promising. First, given the encouraging finding that nonverbal information plays a significant role as a communicative means for task-oriented dialogue, various types of non-verbal information can be investigated, such as gesture and facial expressions. Second, incorporating richer task features, such as in our case, deep analysis of student code, may contribute to more accurate dialogue act modeling. Third, it is important to generalize the findings to a larger data set, including across other task-oriented domains.  Finally, the community is embracing a move toward annotation-lean approaches such as unsupervised or semi-supervised learning, which hold great promise for dialogue modeling. Acknowledgments This research was supported by the National Science Foundation under Grant DRL-1007962. Any opinions, findings, and conclusions expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation. References Bangalore, S., Di Fabbrizio, G., & Stent, A. (2008). Learning the structure of task-driven human-human dialogs. IEEE Transactions on Audio, Speech, and Language Processing, 16(7), 1249-1259. Boyer, K. E., Grafsgaard, J. F., Ha, E. Y., Phillips, R., & Lester, J. C. (2011). An affect-enriched dialogue act classification model for task-oriented dialogue. Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human 
254
Language Technologies (pp. 1190-1199). Portland, OR. Boyer, K. E., Ha, E. Y., Phillips, R., Wallis, M. D., Vouk, M. A., & Lester, J. C. (2010a). Dialogue Act Modeling in a Complex Task-Oriented Domain. Proceedings of the 11th Annual SIGDIAL Meeting on Discourse and Dialogue (pp. 297-305). Tokyo, Japan. Boyer, K. E., Phillips, R., Ingram, A., Ha, E. Y., Wallis, M., Vouk, M., & Lester, J. (2010b). Characterizing the effectiveness of tutorial dialogue with hidden markov models. Proceedings of the 10th international conference on Intelligent Tutoring Systems (pp. 55-64). Pittsburgh, PA. Carletta, J., Isard, A., Isard, S., Kowtko, J., Doherty-Sneddon, G., & Anderson, A. (1997). The reliability of a dialogue structure coding scheme. Computational Linguistics, 23, 13?31. Cavicchio, F. (2009). The modulation of cooperation and emotion in dialogue: The REC corpus. Proceedings of the ACL-IJCNLP 2009 Student Research Workshop (pp. 81 - 87). Suntec, Singapore. Cohen, J. (1960). A coefficient of agreement for nominal scales. Educational and Psychological Measurement, 20(1), 37 - 46. Di Eugenio, B., Xie, Z., & Serafin, R. (2010). Dialogue act classification, instance-based learning, and higher order dialogue structure. Dialogue and Discourse, 1(2), 81 - 104. D?Mello, S., & Graesser, A. (2010). Mining Bodily Patterns of Affective Experience during Learning. Proceedings of the 3rd International Conference on Educational Data Mining (pp. 31-40). Pittsburgh, PA. Forsyth, E. N. (2007). Improving Automated Lexical and Discourse Analysis of Online Chat Dialog. Master's thesis. Naval Postgraduate School. Grafsgaard, J. F., Boyer, K. E., Wiebe, E. N., & Lester, J. C. (2012). Analyzing Posture and Affect in Task-Oriented Tutoring. Proceedings of the 25th Florida Artificial Intelligence Research Society Conference (pp. 438-443). Marco Island, FL. Ivanovic, E. (2008). Automatic instant messaging dialogue using statistical models and dialogue acts. Master's thesis. The University of Melbourne. Joty, S. R., Carenini, G., & Lin, C.-Y. (2011). Unsupervised Modeling of Dialog Acts in Asynchronous Conversations. Proceedings of the 22nd International Joint Conference on Artificial 
Intelligence (pp. 1807-1813). Barcelona, Catalonia, Spain. Jurafsky, D., Bates, R., Coccaro, N., Martin, R., Meteer, M., Ries, K., Shriberg, E., et al (1998). Switchboard discourse language modeling project report. Baltimore, MD. Kapoor, A., Burleson, W., & Picard, R. W. (2007). Automatic prediction of frustration. International Journal of Human-Computer Studies, 65(8), 724-736. Kim, S. N., Cavedon, L., & Baldwin, T. (2010). Classifying dialogue acts in one-on-one live chats. Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing (pp. 862-871). Cambridge, MA. Knapp, M. L., & Hall, J. A. (2006). Nonverbal Communication in Human Interaction (6th ed.). Belmont, CA: Wadsworth/Thomson Learning. McCallum, A. K. (2002). MALLET: A Machine Learning for Language Toolkit. Available from  http://mallet.cs.umass.edu Mehrabian, A. (2007). Nonverbal Communication. New Brunswick, NJ: Aldine Transaction. Ritter, A., Cherry, C., & Dolan, B. (2010). Unsupervised modeling of twitter conversations. Proceedings of Human Language Technologies: The 2010 Annual Conference of the North American Chapter (pp. 172 - 180). Los Angeles, CA. Russell, J. A., Bachorowski, J. A., & Fernandez-dols, J. M. (2003). Facial and vocal expressions of emotion. Annual Review of Psychology, 54, 329-349. Sanghvi, J., Castellano, G., Leite, I., Pereira, A., McOwan, P. W., & Paiva, A. (2011). Automatic analysis of affective postures and body motion to detect engagement with a game companion. Proceedings of the 6th international conference on Human-robot interaction (pp. 305-312). Lausanne, Switzerland. Sridhar, R., Bangalore, S., & Narayanan, S. (2009). Combining lexical, syntactic and prosodic cues for improved online dialog act tagging. Computer Speech and Language, 23(4), 407 - 422. Stolcke, A., Ries, K., Coccaro, N., Shriberg, E., Bates, R., Jurafsky, D., Taylor, P., et al (2000). Dialogue act modeling for automatic tagging and recognition of conversational speech. Computational Linguistics, 26(3), 339-373. Surendran, D., & Levow, G.-A. (2006). Dialog act tagging with support vector machines and hidden 
255
Markov models. Proceedings of Interspeech (pp. 1950 - 1953). Pittsburgh, PA. Woolf, B., Burleson, W., Arroyo, I., Dragon, T., Cooper, D., & Picard, R. W. (2009). Affect-aware tutors recognising and responding to student affect. International Journal of Learning Technology, 4(3/4), 129-164. Wu, T., Khan, F. M., Fisher, T. A., Shuler, L. A., & Pottenger, W. M. (2005). Posting Act Tagging Using Transformation-Based Learning. In T. Y. Lin, S. Ohsuga, C.-J. Liau, X. Hu, & S. Tsumoto (Eds.), Foundations of Data Mining and knowledge Discovery (pp. 319 - 331). Springer. 
  
Appendix. Dialogue Act Annotation Scheme and Inter-rater Agreement Tag Description Frequency Agreement (k) H  Hint:  The tutor gives advice to help the student proceed with the task Tutor:     Student:     133 0 .50 DIR   Directive:  The tutor explicitly tells the student the next step to take Tutor:     Student:     121 0 .63 ACK   Acknowledgement:  Either the tutor or the student acknowledges previous utterance; conversational grounding Tutor:       Student:  41 175 .73 RC   Request for Confirmation:  Either the tutor or the student requests confirmation from the other participant (e.g., ?Make sense??) Tutor:       Student:  11 2 Insufficient data RF   Request for Feedback:  The student requests an assessment of performance or work from the tutor Tutor:     Student:    0 5 1.0 PF  Positive Feedback:  The tutor provides a positive assessment of the student?s performance Tutor:     Student:     327 0 .90 LF Lukewarm Feedback:  The tutor provides an assessment that has both positive and negative elements Tutor:      Student:    13 0 .80 NF Negative Feedback:  The tutor provides a negative assessment of the student?s performance Tutor:        Student:     1 0 .40 Q Question:  A question regarding the task that is not a direct request for confirmation or feedback Tutor:     Student:  327 120   .95 A Answer:  An answer to an utterance marked Q Tutor:       Student:  96 295 .94 C Correction:  Correction of a typo in a previous utterance Tutor:       Student:  10 6 .54 S  Statement:  A statement regarding the task that does not fit into any of the above categories Tutor:     Student:  681 174 .71 O Other: Other utterances, usually containing only affective content Tutor:     Student:  6 10 .69 
256
