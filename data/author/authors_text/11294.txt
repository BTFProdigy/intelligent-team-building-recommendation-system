Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 43?48,
Baltimore, Maryland USA, June 23-24, 2014.
c?2014 Association for Computational Linguistics
The Excitement Open Platform for Textual Inferences
Bernardo Magnini
?
, Roberto Zanoli
?
, Ido Dagan
?
, Kathrin Eichler
?
, G?unter Neumann
?
,
Tae-Gil Noh
?
, Sebastian Pado
?
, Asher Stern
?
, Omer Levy
?
?
FBK (magnini|zanoli@fbk.eu)
?
Heidelberg, Stuttgart Univ. (pado|noh@cl.uni-heidelberg.de)
?
DFKI (neumann|eichler@dfki.de)
?
Bar Ilan University (dagan|sterna3|omerlevy@cs.biu.ac.il)
Abstract
This paper presents the Excitement Open
Platform (EOP), a generic architecture and
a comprehensive implementation for tex-
tual inference in multiple languages. The
platform includes state-of-art algorithms,
a large number of knowledge resources,
and facilities for experimenting and test-
ing innovative approaches. The EOP is
distributed as an open source software.
1 Introduction
In the last decade textual entailment (Dagan et al.,
2009) has been a very active topic in Computa-
tional Linguistics, providing a unifying framework
for textual inference. Several evaluation exercises
have been organized around Recognizing Textual
Entailment (RTE) challenges and many method-
ologies, algorithms and knowledge resources have
been proposed to address the task. However, re-
search in textual entailment is still fragmented and
there is no unifying algorithmic framework nor
software architecture.
In this paper, we present the Excitement Open
Platform (EOP), a generic architecture and a com-
prehensive implementation for multilingual textual
inference which we make available to the scien-
tific and technological communities. To a large
extent, the idea is to follow the successful experi-
ence of the Moses open source platform (Koehn et
al., 2007) in Machine Translation, which has made
a substantial impact on research in that field. The
EOP is the result of a two-year coordinated work
under the international project EXCITEMENT.
1
A
consortium of four academic partners has defined
the EOP architectural specifications, implemented
the functional interfaces of the EOP components,
imported existing entailment engines into the EOP
1
http://www.excitement-project.eu
and finally designed and implemented a rich envi-
ronment to support open source distribution.
The goal of the platform is to provide function-
ality for the automatic identification of entailment
relations among texts. The EOP is based on a modu-
lar architecture with a particular focus on language-
independent algorithms. It allows developers and
users to combine linguistic pipelines, entailment al-
gorithms and linguistic resources within and across
languages with as little effort as possible. For ex-
ample, different entailment decision approaches
can share the same resources and the same sub-
components in the platform. A classification-based
algorithm can use the distance component of an
edit-distance based entailment decision approach,
and two different approaches can use the same set
of knowledge resources. Moreover, the platform
has various multilingual components for languages
like English, German and Italian. The result is an
ideal software environment for experimenting and
testing innovative approaches for textual inferences.
The EOP is distributed as an open source software
2
and its use is open both to users interested in using
inference in applications and to developers willing
to extend the current functionalities.
The paper is structured as follows. Section 2
presents the platform architecture, highlighting
how the EOP component-based approach favors
interoperability. Section 3 provides a picture of
the current population of the EOP in terms of both
entailment algorithms and knowledge resources.
Section 4 introduces expected use cases of the plat-
form. Finally, Section 5 presents the main features
of the open source package.
2 Architecture
The EOP platform takes as input two text portions,
the first called the Text (abbreviated with T), the
second called the Hypothesis (abbreviated with H).
2
http://hltfbk.github.io/
Excitement-Open-Platform/
43
Linguis'c)Analysis)Pipeline)(LAP))
Entailment)Core)(EC))
Entailment)Decision))Algorithm)(EDA))
Dynamic)and)Sta'c)Components)(Algorithms)and)Knowledge))
Linguis'c)Analysis)Components)
Decision)
1)
Raw)Data)
Figure 1: EOP architecture
The output is an entailment judgement, either ?En-
tailment? if T entails H, or ?NonEntailment? if the
relation does not hold. A confidence score for the
decision is also returned in both cases.
The EOP architecture (Pad?o et al., 2014) is based
on the concept of modularization with pluggable
and replaceable components to enable extension
and customization. The overall structure is shown
in Figure 1 and consists of two main parts. The
Linguistic Analysis Pipeline (LAP) is a series of
linguistic annotation components. The Entailment
Core (EC) performs the actual entailment recog-
nition. This separation ensures that (a) the com-
ponents in the EC only rely on linguistic analysis
in well-defined ways and (b) the LAP and EC can
be run independently of each other. Configuration
files are the principal means of configuring the EOP.
In the rest of this section we first provide an intro-
duction to the LAP, then we move to the EC and
finally describe the configuration files.
2.1 Linguistic Analysis Pipeline (LAP)
The Linguistic Analysis Pipeline is a collection of
annotation components for Natural Language Pro-
cessing (NLP) based on the Apache UIMA frame-
work.
3
Annotations range from tokenization to
part of speech tagging, chunking, Named Entity
Recognition and parsing. The adoption of UIMA
enables interoperability among components (e.g.,
substitution of one parser by another one) while
ensuring language independence. Input and output
of the components are represented in an extended
version of the DKPro type system based on UIMA
3
http://uima.apache.org/
Common Analysis Structure (CAS) (Gurevych et
al., 2007; Noh and Pad?o, 2013).
2.2 Entailment Core (EC)
The Entailment Core performs the actual entail-
ment recognition based on the preprocessed text
made by the Linguistic Analysis Pipeline. It con-
sists of one or more Entailment Decision Algo-
rithms (EDAs) and zero or more subordinate com-
ponents. An EDA takes an entailment decision
(i.e., ?entailment? or ?no entailment?) while com-
ponents provide static and dynamic information for
the EDA.
Entailment Decision Algorithms are at the top
level in the EC. They compute an entailment deci-
sion for a given Text/Hypothesis (T/H) pair, and
can use components that provide standardized al-
gorithms or knowledge resources. The EOP ships
with several EDAs (cf. Section 3).
Scoring Components accept a Text/Hypothesis
pair as an input, and return a vector of scores.
Their output can be used directly to build minimal
classifier-based EDAs forming complete RTE sys-
tems. An extended version of these components are
the Distance Components that can produce normal-
ized and unnormalized distance/similarity values
in addition to the score vector.
Annotation Components can be used to add dif-
ferent annotations to the Text/Hypothesis pairs. An
example of such a type of component is one that
produces word or phrase alignments between the
Text and the Hypothesis.
Lexical Knowledge Components describe se-
mantic relationships between words. In the
EOP, this knowledge is represented as directed
rules made up of two word?POS pairs, where
the LHS (left-hand side) entails the RHS (right-
hand side), e.g., (shooting star,Noun) =?
(meteorite,Noun). Lexical Knowledge Compo-
nents provide an interface that allows for (a) listing
all RHS for a given LHS; (b) listing all LHS for
a given RHS; and (c) checking for an entailment
relation for a given LHS?RHS pair. The interface
also wraps all major lexical knowledge sources cur-
rently used in RTE research, including manually
constructed ontologies like WordNet, and encyclo-
pedic resources like Wikipedia.
Syntactic Knowledge Components capture en-
tailment relationships between syntactic and
44
lexical-syntactic expressions. We represent such
relationships by entailment rules that link (option-
ally lexicalized) dependency tree fragments that
can contain variables as nodes. For example, the
rule fall of X =? X falls, or X sells Y to Z =?
Z buys Y from X express general paraphrasing pat-
terns at the predicate-argument level that cannot be
captured by purely lexical rules. Formally, each
syntactic rule consists of two dependency tree frag-
ments plus a mapping from the variables of the
LHS tree to the variables of the RHS tree.
4
2.3 Configuration Files
The EC components can be combined into actual
inference engines through configuration files which
contain information to build a complete inference
engine. A configuration file completely describes
an experiment. For example, it specifies the re-
sources that the selected EDA has to use and the
data set to be analysed. The LAP needed for data
set preprocessing is another parameter that can be
configured too. The platform ships with a set of
predefined configuration files accompanied by sup-
porting documentation.
3 Entailment Algorithms and Resources
This section provides a description of the Entail-
ment Algorithms and Knowledge Resources that
are distributed with the EOP.
3.1 Entailment Algorithms
The current version of the EOP platform ships with
three EDAs corresponding to three different ap-
proaches to RTE: an EDA based on transformations
between T and H, an EDA based on edit distance
algorithms, and a classification based EDA using
features extracted from T and H.
Transformation-based EDA applies a sequence
of transformations on T with the goal of making
it identical to H. If each transformation preserves
(fully or partially) the meaning of the original text,
then it can be concluded that the modified text
(which is actually the Hypothesis) can be inferred
from the original one. Consider the following sim-
ple example where the text is ?The boy was located
by the police? and the Hypothesis is ?The child
was found by the police?. Two transformations for
?boy? ? ?child? and ?located? ? ?found? do the
job.
4
Variables of the LHS may also map to null, when material
of the LHS must be present but is deleted in the inference step.
In the EOP we include a transformation based
inference system that adopts the knowledge based
transformations of Bar-Haim et al. (2007), while in-
corporating a probabilistic model to estimate trans-
formation confidences. In addition, it includes a
search algorithm which finds an optimal sequence
of transformations for any given T/H pair (Stern et
al., 2012).
Edit distance EDA involves using algorithms
casting textual entailment as the problem of map-
ping the whole content of T into the content of H.
Mappings are performed as sequences of editing
operations (i.e., insertion, deletion and substitu-
tion) on text portions needed to transform T into H,
where each edit operation has a cost associated with
it. The underlying intuition is that the probability
of an entailment relation between T and H is related
to the distance between them; see Kouylekov and
Magnini (2005) for a comprehensive experimental
study.
Classification based EDA uses a Maximum En-
tropy classifier to combine the outcomes of sev-
eral scoring functions and to learn a classification
model for recognizing entailment. The scoring
functions extract a number of features at various
linguistic levels (bag-of-words, syntactic dependen-
cies, semantic dependencies, named entities). The
approach was thoroughly described in Wang and
Neumann (2007).
3.2 Knowledge Resources
As described in Section 2.2, knowledge resources
are crucial to recognize cases where T and H use
different textual expressions (words, phrases) while
preserving entailment. The EOP platform includes
a wide range of knowledge resources, including lex-
ical and syntactic resources, where some of them
are grabbed from manual resources, like dictionar-
ies, while others are learned automatically. Many
EOP resources are inherited from pre-existing RTE
systems migrated into the EOP platform, but now
use the same interfaces, which makes them acces-
sible in a uniform fashion.
There are about two dozen lexical (e.g. word-
nets) and syntactic resources for three languages
(i.e. English, Italian and German). However,
since there is still a clear predominance of En-
glish resources, the platform includes lexical and
syntactic knowledge mining tools to bootstrap re-
sources from corpora, both for other languages and
45
EDA Accuracy / F1
Transformation-based English RTE-3 67.13%
Transformation-based English RTE-6 49.55%
Edit-Distance English RTE-3 64.38%
Edit-Distance German RTE-3 59.88%
Edit-Distance Italian RTE-3 63.50%
Classification-based English RTE-3 65.25%
Classification-based German RTE-3 63.75%
Median of RTE-3 (English) submissions 61.75%
Median of RTE-6 (English) submissions 33.72%
Table 1: EDAs results
for specific domains. Particularly, the EOP plat-
form includes a language independent tool to build
Wikipedia resources (Shnarch et al., 2009), as well
as a language-independent framework for building
distributional similarity resources like DIRT (Lin
and Pantel, 2002) and Lin similarity(Lin, 1998).
3.3 EOP Evaluation
Results for the three EDAs included in the EOP
platform are reported in Table 1. Each line rep-
resents an EDA, the language and the dataset
on which the EDA was evaluated. For brevity,
we omit here the knowledge resources used for
each EDA, even though knowledge configuration
clearly affects performance. The evaluations were
performed on RTE-3 dataset (Giampiccolo et al.,
2007), where the goal is to maximize accuracy. We
(manually) translated it to German and Italian for
evaluations: in both cases the results fix a refer-
ence for the two languages. The two new datasets
for German and English are available both as part
of the EOP distribution and independently
5
. The
transformation-based EDA was also evaluated on
RTE-6 dataset (Bentivogli et al., 2010), in which
the goal is to maximize the F1 measure.
The results of the included EDAs are higher than
median values of participated systems in RTE-3,
and they are competing with state-of-the-arts in
RTE-6 results. To the best of our knowledge, the
results of the EDAs as provided in the platform are
the highest among those available as open source
systems for the community.
4 Use Cases
We see four primary use cases for the EOP. Their
requirements were reflected in our design choices.
Use Case 1: Applied Textual Entailment. This
category covers users who are not interested in the
5
http://www.excitement-project.eu/
index.php/results
details of RTE but who are interested in an NLP
task in which textual entailment can take over part
of or all of the semantic processing, such as Ques-
tion Answering or Intelligent Tutoring. Such users
require a system that is as easy to deploy as possi-
ble, which motivates our offer of the EOP platform
as a library. They also require a system that pro-
vides good quality at a reasonable efficiency as
well as guidance as to the best choice of parame-
ters. The latter point is realized through our results
archive in the official EOP Wiki on the EOP site.
Use Case 2: Textual Entailment Development.
This category covers researchers who are interested
in Recognizing Textual Entailment itself, for exam-
ple with the goal of developing novel algorithms
for detecting entailment. In contrast to the first
category, this group need to look ?under the hood?
of the EOP platform and access the source code of
the EOP. For this reason, we have spent substantial
effort to provide the code in a well-structured and
well-documented form.
A subclass of this group is formed by researchers
who want to set up a RTE infrastructure for lan-
guages in which it does not yet exist (that is, al-
most all languages). The requirements of this class
of users comprises clearly specified procedures to
replace the Linguistic Analysis Pipeline, which are
covered in our documentation, and simple methods
to acquire knowledge resources for these languages
(assuming that the EDAs themselves are largely
language-independent). These are provided by the
language-independent knowledge acquisition tools
which we offer alongside the platform (cf. Section
3.2).
Use Case 3: Lexical Semantics Evaluation. A
third category consists of researchers whose pri-
mary interest is in (lexical) semantics.
As long as their scientific results can be phrased
in terms of semantic similarities or inference rules,
the EOP platform can be used as a simple and stan-
dardized workbench for these results that indicates
the impact that the semantic knowledge under con-
sideration has on deciding textual entailment. The
main requirement for this user group is the simple
integration of new knowledge resources into the
EOP platform. This is catered for through the defi-
nition of the generic knowledge component inter-
faces (cf. Section 2.2) and detailed documentation
on how to implement these interfaces.
46
Use Case 4: Educational Use. The fourth and
final use case is as an educational tool to support
academic courses and projects on Recognizing Tex-
tual Entailment and inference more generally. This
use case calls, in common with the others, for easy
usability and flexibility. Specifically for this use
case, we have also developed a series of tutorials
aimed at acquainting new users with the EOP plat-
form through a series of increasingly complexity
exercises that cover all areas of the EOP. We are
also posting proposals for projects to extend the
EOP on the EOP Wiki.
5 EOP Distribution
The EOP infrastructure follows state-of-the-art soft-
ware engineering standards to support both users
and developers with a flexible, scalable and easy to
use software environment. In addition to communi-
cation channels, like the mailing list and the issue
tracking system, the EOP infrastructure comprises
the following set of facilities.
Version Control System: We use GitHub,
6
a
web-based hosting service for code and documen-
tation storage, development, and issue tracking.
Web Site: The GitHub Automatic Page Genera-
tor was used to build the EOP web site and Wiki,
containing a general introduction to the software
platform, the terms of its license, mailing lists to
contact the EOP members and links to the code
releases.
Documentation: Both user and developer docu-
mentation is available from Wiki pages; the pages
are written with the GitHub Wiki Editor and hosted
on the GitHub repository. The documentation in-
cludes a Quick Start guide to start using the EOP
platform right away, and a detailed step by step
tutorial.
Results Archive: As a new feature for commu-
nity building, EOP users can, and are encouraged
to, share their results: the platform configuration
files used to produce results as well as contact infor-
mation can be saved and archived into a dedicated
page on the EOP GitHub repository. That allows
other EOP users to replicate experiments under
the same condition and/or avoid doing experiments
that have already been done.
6
https://github.com/
Build Automation Tool: The EOP has been de-
veloped as a Maven
7
multi-modules project, with
all modules sharing the same Maven standard struc-
ture, making it easier to find files in the project once
one is used to Maven.
Maven Artifacts Repository: Using a Maven
repository has a twofold goal: (i) to serve as an
internal private repository of all software libraries
used within the project (libraries are binary files
and should not be stored under version control sys-
tems, which are intended to be used with text files);
(ii) to make the produced EOP Maven artifacts
available (i.e., for users who want to use the EOP
as a library in their own code). We use Artifactory
8
repository manager to store produced artifacts.
Continuous Integration: The EOP uses Jenk-
ins
9
for Continuous Integration, a software develop-
ment practice where developers of a team integrate
their work frequently (e.g., daily).
Code Quality Tool: Ensuring the quality of the
produced software is one of the most important
aspects of software engineering. The EOP uses
tools like PMD
10
that can automatically be run
during development to help the developers check
the quality of their software.
5.1 Project Repository
The EOP Java source code is hosted on the EOP
Github repository and managed using Git. The
repository consists of three main branches: the
release branch contains the code that is supposed to
be in a production-ready state, whereas the master
branch contains the code to be incorporated into the
next release. When the source code in the master
branch reaches a stable point and is ready to be
released, all of the changes are merged back into
release. Finally, the gh-pages branch contains the
web site pages.
5.2 Licensing
The software of the platform is released under the
terms of General Public License (GPL) version
3.
11
The platform contains both components and
resources designed by the EOP developers, as well
as others that are well known and freely available
7
http://maven.apache.org/
8
http://www.jfrog.com/
9
http://jenkins-ci.org/
10
http://pmd.sourceforge.net
11
http://www.gnu.org/licenses/gpl.html
47
in the NLP research community. Additional com-
ponents and resources whose license is not compat-
ible with the EOP license have to be downloaded
and installed separately by the user.
6 Conclusion
This paper has presented the main characteristics
of Excitement Open Platform platform, a rich envi-
ronment for experimenting and evaluating textual
entailment systems. On the software side, the EOP
is a complex endeavor to integrate tools and re-
sources in Computational Linguistics, including
pipelines for three languages, three pre-existing
entailment engines, and about two dozens of lex-
ical and syntactic resources. The EOP assumes a
clear and modular separation between linguistic
annotations, entailment algorithms and knowledge
resources which are used by the algorithms. A
relevant benefit of the architectural design is that
a high level of interoperability is reached, provid-
ing a stimulating environment for new research in
textual inferences.
The EOP platform has been already tested in sev-
eral pilot research projects and educational courses,
and it is currently distributed as open source soft-
ware under the GPL-3 license. To the best of our
knowledge, the entailment systems and their con-
figurations provided in the platform are the best
systems available as open source for the commu-
nity. As for the future, we are planning several
initiatives for the promotion of the platform in the
research community, as well as its active experi-
mentation in real application scenarios.
Acknowledgments
This work was partially supported by the EC-
funded project EXCITEMENT (FP7ICT-287923).
References
Roy Bar-Haim, Ido Dagan, Iddo Greental, and Eyal
Shnarch. 2007. Semantic inference at the lexical-
syntactic level. In Proceedings of AAAI, pages 871?
876, Vancouver, BC.
Luisa Bentivogli, Peter Clark, Ido Dagan, Hoa Trang
Dang, and Danilo Giampiccolo. 2010. The Sixth
PASCAL Recognizing Textual Entailment Chal-
lenge. In Proceedings of TAC, Gaithersburg, MD.
Ido Dagan, Bill Dolan, Bernardo Magnini, and Dan
Roth. 2009. Recognizing textual entailment: Ratio-
nal, evaluation and approaches. Journal of Natural
Language Engineering, 15(4):i?xvii.
Danilo Giampiccolo, Bernardo Magnini, Ido Dagan,
and Bill Dolan. 2007. The Third PASCAL Recog-
nising Textual Entailment Challenge. In Proceed-
ings of the ACL-PASCAL Workshop on Textual En-
tailment and Paraphrasing, Prague, Czech Repub-
lic.
Iryna Gurevych, Max M?uhlh?auser, Christof M?uller,
J?urgen Steimle, Markus Weimer, and Torsten Zesch.
2007. Darmstadt knowledge processing repository
based on UIMA. In Proceedings of the First Work-
shop on Unstructured Information Management Ar-
chitecture (UIMA@GSCL 2007), T?ubingen, Ger-
many.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
Source Toolkit for Statistical Machine Translation.
In Proceedings of the ACL demo session, pages 177?
180, Prague, Czech Republic.
Milen Kouylekov and Bernardo Magnini. 2005. Rec-
ognizing textual entailment with tree edit distance al-
gorithms. In Proceedings of the First PASCAL Chal-
lenges Workshop on Recognising Textual Entailment,
pages 17?20, Southampton, UK.
Dekang Lin and Patrick Pantel. 2002. Discovery of
Inference Rules for Question Answering. Journal of
Natural Language Engineering, 7(4):343?360.
Dekang Lin. 1998. Automatic retrieval and clustering
of similar words. In Proceedings of ACL/COLING,
pages 768?774, Montr?eal, Canada.
Tae-Gil Noh and Sebastian Pad?o. 2013. Using
UIMA to structure an open platform for textual en-
tailment. In Proceedings of the 3rd Workshop on
Unstructured Information Management Architecture
(UIMA@GSCL 2013).
Sebastian Pad?o, Tae-Gil Noh, Asher Stern, Rui Wang,
and Roberto Zanoli. 2014. Design and realiza-
tion of a modular architecture for textual entailment.
Journal of Natural Language Engineering. doi:
10.1017/S1351324913000351.
Eyal Shnarch, Libby Barak, and Ido Dagan. 2009. Ex-
tracting lexical reference rules from Wikipedia. In
Proceedings of ACL-IJCNLP, pages 450?458, Sin-
gapore.
Asher Stern, Roni Stern, Ido Dagan, and Ariel Felner.
2012. Efficient search for transformation-based in-
ference. In Proceedings of ACL, pages 283?291,
Jeju Island, South Korea.
Rui Wang and G?unter Neumann. 2007. Recogniz-
ing textual entailment using a subsequence kernel
method. In Proceedings of AAAI, pages 937?945,
Vancouver, BC.
48
Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 104?107,
Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational Linguistics
BART: A Multilingual Anaphora Resolution System
Samuel Broscheit?, Massimo Poesio?, Simone Paolo Ponzetto?, Kepa Joseba Rodriguez?,
Lorenza Romano?, Olga Uryupina?, Yannick Versley?, Roberto Zanoli?
?Seminar fu?r Computerlinguistik, University of Heidelberg
?CiMeC, University of Trento
?Fondazione Bruno Kessler
?SFB 833, University of Tu?bingen
broscheit@cl.uni-heidelberg.de, massimo.poesio@unitn.it,
ponzetto@cl.uni-heidelberg.de, kepa.rodriguez@unitn.it,
romano@fbk.eu, uryupina@gmail.com,
versley@sfs.uni-tuebingen.de, zanoli@fbk.eu
Abstract
BART (Versley et al, 2008) is a highly mod-
ular toolkit for coreference resolution that
supports state-of-the-art statistical approaches
and enables efficient feature engineering. For
the SemEval task 1 on Coreference Resolu-
tion, BART runs have been submitted for Ger-
man, English, and Italian.
BART relies on a maximum entropy-based
classifier for pairs of mentions. A novel entity-
mention approach based on Semantic Trees is
at the moment only supported for English.
1 Introduction
This paper presents a multilingual coreference reso-
lution system based on BART (Versley et al, 2008).
BART is a modular toolkit for coreference resolution
that supports state-of-the-art statistical approaches
to the task and enables efficient feature engineer-
ing. BART has originally been created and tested
for English, but its flexible modular architecture en-
sures its portability to other languages and domains.
In SemEval-2010 task 1 on Coreference Resolution,
BART has shown reliable performance for English,
German and Italian.
In our SemEval experiments, we mainly focus on
extending BART to cover multiple languages. Given
a corpus in a new language, one can re-train BART
to obtain baseline results. Such a language-agnostic
system, however, is only used as a starting point:
substantial improvements can be achieved by incor-
porating language-specific information with the help
of the Language Plugin. This design provides ef-
fective separation between linguistic and machine
learning aspects of the problem.
2 BART Architecture
The BART toolkit has five main components: pre-
processing pipeline, mention factory, feature extrac-
tion module, decoder and encoder. In addition, an
independent LanguagePlugin module handles all the
language specific information and is accessible from
any component. The architecture is shown on Figure
1. Each module can be accessed independently and
thus adjusted to leverage the system?s performance
on a particular language or domain.
The preprocessing pipeline converts an input doc-
ument into a set of lingustic layers, represented
as separate XML files. The mention factory uses
these layers to extract mentions and assign their
basic properties (number, gender etc). The fea-
ture extraction module describes pairs of mentions
{M
i
,M
j
}, i < j as a set of features.
The decoder generates training examples through
a process of sample selection and learns a pairwise
classifier. Finally, the encoder generates testing ex-
amples through a (possibly distinct) process of sam-
ple selection, runs the classifier and partitions the
mentions into coreference chains.
3 Language-specific issues
Below we briefly describe our language-specific ex-
tensions to BART. These issues are addressed in
more details in our recent papers (Broscheit et al,
2010; Poesio et al, 2010).
3.1 Mention Detection
Robust mention detection is an essential component
of any coreference resolution system. BART sup-
ports different pipelines for mention detection. The
104
Parser
Dep-to-Const
Converter
Morphology
Preprocessing
Mention
Factory
Decoder
Basic features
Syntactic features
Knowledge-based
features
MaxEnt
Classifier
Mention
(with basic
 properties):
- Number
- Gender
- Mention Type
- Modifiers
Unannotated
Text
Coreference
Chains
LanguagePlugin
Figure 1: BART architecture
choice of a pipeline depends crucially on the avail-
ability of linguistic resources for a given language.
For English and German, we use the Parsing
Pipeline and Mention Factory to extract mentions.
The parse trees are used to identify minimal and
maximal noun projections, as well as additional fea-
tures such as number, gender, and semantic class.
For English, we use parses from a state-of-the-art
constituent parser (Petrov et al, 2006) and extract
all base noun phrases as mentions. For German,
the SemEval dependency tree is transformed to a
constituent representation and minimal and maxi-
mal phrases are extracted for all nominal elements
(pronouns, common nouns, names), except when the
noun phrase is in a non-referring syntactic position
(for example, expletive ?es?, predicates in copula
constructions).
For Italian, we use the EMD Pipeline and Men-
tion Factory. The Typhoon (Zanoli et al, 2009)
and DEMention (Biggio et al, 2009) systems were
used to recognize mentions in the test set. For each
mention, its head and extension were considered.
The extension was learned by using the mention an-
notation provided in the training set (13th column)
whereas the head annotation was learned by exploit-
ing the information produced by MaltParser (Nivre
et al, 2007). In addition to the features extracted
from the training set, such as prefixes and suffixes
(1-4 characters) and orthographic information (capi-
talization and hyphenation), a number of features ex-
tracted by using external resources were used: men-
tions recognized by TextPro (http://textpro.fbk.eu),
gazetteers of generic proper nouns extracted from
the Italian phone-book and Wikipedia, and other fea-
tures derived from WordNet. Each of these features
was extracted in a local context of ?2 words.
3.2 Features
We view coreference resolution as a binary classifi-
cation problem. Each classification instance consists
of two markables, i.e. an anaphor and potential an-
tecedent. Instances are modeled as feature vectors
(cf. Table 1) and are handed over to a binary clas-
sifier that decides, given the features, whether the
anaphor and the candidate are coreferent or not. All
the feature values are computed automatically, with-
out any manual intervention.
Basic feature set. We use the same set of rela-
tively language-independent features as a backbone
of our system, extending it with a few language-
specific features for each subtask. Most of them are
used by virtually all the state-of-the-art coreference
resolution systems. A detailed description can be
found, for example, in (Soon et al, 2001).
English. Our English system is based on a novel
model of coreference. The key concept of our model
is a Semantic Tree ? a filecard associated with each
discourse entity containing the following fields:
? Types: the list of types for mentions of a given
entity. For example, if an entity contains the
mention ?software from India?, the shallow
predicate ?software? is added to the types.
? Attributes: this field collects the premodifiers.
For instance, if one of the mentions is ?the ex-
pensive software? the shallow attribute ?expen-
sive? is added to the list of attributes.
? Relations: this field collects the prepositional
postmodifiers. If an entity contains the men-
tion ?software from India?, the shallow relation
?from(India)? is added to the list of relations.
105
For each mention BART creates such a filecard
using syntactic information. If the classifier decides
that both mentions are corefering, the filecard of
the anaphora is merged into the filecard of the an-
tecedent (cf. Section 3.3 below).
The SemanticTreeCompatibility feature
extractor checks whether individual slots of the
anaphor?s filecard are compatible with those of the
antecedent?s.
The StrudelRelatedness feature relies on
Strudel ? a distributional semantic model (Baroni et
al., 2010). We compute Strudel vectors for the sets
of types of the anaphor and the antecedent. The re-
latedness value is determined as the cosine between
the two.
German. We have tested extra features for Ger-
man in our previous study (Broscheit et al, 2010).
The NodeDistance feature measures the num-
ber of clause nodes (SIMPX, R-SIMPX) and preposi-
tional phrase nodes (PX) along the path between M
j
and M
i
in the parse tree.
The PartialMorphMatch feature is a sub-
string match with a morphological extension for
common nouns. In German the frequent use of
noun composition makes a simple string match for
common nouns unfeasible. The feature checks for
a match between the noun stems of M
i
and M
j
.
We extract the morphology with SMOR/Morphisto
(Schmid et al, 2004).
The GermanetRelatedness feature uses the
Pathfinder library for GermaNet (Finthammer and
Cramer, 2008) that computes and discretizes raw
scores into three categories of semantic relatedness.
In our experiments we use the measure from Wu and
Palmer (1994), which has been found to be the best
performing on our development data.
Italian. We have designed a feature to cover Ital-
ian aliasing patterns. A list of company/person des-
ignators (e.g., ?S.p.a? or ?D.ssa?) has been manually
crafted. We have collected patterns of name variants
for locations. Finally, we have relaxed abbreviation
constraints, allowing for lower-case characters in the
abbreviations. Our pilot experiments suggest that,
although a universal aliasing algorithm is able to re-
solve some coreference links between NEs, creating
a language-specific module boosts the system?s per-
formance for Italian substantially.
Basic feature set
MentionType(M
i
),MentionType(M
j
)
SemanticClass(M
i
), SemanticClass(M
j
)
GenderAgreement(M
i
,M
j
)
NumberAgreement(M
i
,M
j
)
AnimacyAgreement(M
i
,M
j
)
StringMatch(M
i
,M
j
)
Distance(M
i
,M
j
)
Basic features used for English and Italian
Alias(M
i
,M
j
)
Apposition(M
i
,M
j
)
FirstMention(M
i
)
English
IsSubject(M
i
)
SemanticTreeCompatibility(M
i
,M
j
)
StrudelRelatedness(M
i
,M
j
)
German
InQuotedSpeech(M
i
), InQuotedSpeech(M
j
)
NodeDistance(M
i
,M
j
)
PartialMorphMatch(M
i
,M
j
)
GermanetRelatedness(M
i
,M
j
)
Italian
AliasItalian(M
i
,M
j
)
Table 1: Features used by BART: each feature describes
a pair of mentions {M
i
,M
j
}, i < j, where M
i
is a can-
didate antecedent and M
j
is a candidate anaphor
3.3 Resolution Algorithm
The BART toolkit supports several models of coref-
erence (pairwise modeling, rankers, semantic trees),
as well as different machine learning algorithms.
Our final setting relies on a pairwise maximum en-
tropy classifier for Italian and German.
Our English system is based on an entity-mention
model of coreference. The key concept of our model
is a Semantic Tree - a filecard associated to each dis-
course entity (cf. Section 3.2). Semantic trees are
used for both computing feature values and guiding
the resolution process.
We start by creating a Semantic Tree for each
mention. We process the document from left to
right, trying to find an antecedent for each men-
tion (candidate anaphor). When the antecedent is
found, we extend its Semantic Tree with the types,
attributes and relations of the anaphor, provided
they are mutually compatible. Consider, for ex-
106
ample, a list of mentions, containing, among oth-
ers, ?software from India?, ?the software? and ?soft-
ware from China?. Initially, BART creates the fol-
lowing semantic trees: ?(type: software) (relation:
from(India))?, ?(type: software)? and ?(type: soft-
ware) (relation: from(China))?. When the second
mention gets resolved to the first one, their seman-
tic trees are merged to ?(type: software) (relation:
from(India)?. Therefore, when we attempt to resolve
the third mention, both candidate antecedents are re-
jected, as their relation attributes are incompatible
with ?from(China)?. This approach helps us avoid
erroneous links (such as the link between the second
and the third mentions in our example) by leveraging
entity-level information.
4 Evaluation
The system was evaluated on the SemEval task 1
corpus by using the SemEval scorer.
First, we have evaluated our mention detection
modules: the system?s ability to recognize both the
mention extensions and the heads in the regular set-
ting. BART has achieved the best score for men-
tion detection in German and has shown reliable
figures for English. For Italian, the moderate per-
formance level is due to the different algorithms
for identifying the heads: the MaltParser (trained
on TUT: http://www.di.unito.it/?tutreeb) produces a
more semantic representation, while the SemEval
scorer seems to adopt a more syntactic approach.
Second, we have evaluated the quality of our
coreference resolution modules. For German, BART
has shown better performance than all the other sys-
tems on the regular track.
For English, the only language targeted by all sys-
tems, BART shows good performance over all met-
rics in the regular setting, usually only outperformed
by systems that were tuned to a particular metric.
Finally, the Italian version of BART shows re-
liable figures for coreference resolution, given the
mention alignment problem discussed above.
5 Conclusion
We have presented BART ? a multilingual toolkit
for coreference resolution. Due to its highly modu-
lar architecture, BART allows for efficient language-
specific feature engineering. Our effort represents
the first steps towards building a freely available
coreference resolution system for many languages.
References
Marco Baroni, Brian Murphy, Eduard Barbu, and Mas-
simo Poesio. 2010. Strudel: A corpus-based semantic
model based on properties and types. Cognitive Sci-
ence, 34(2):222?254.
Silvana Marianela Bernaola Biggio, Claudio Giuliano,
Massimo Poesio, Yannick Versley, Olga Uryupina, and
Roberto Zanoli. 2009. Local entity detection and
recognition task. In Proc. of Evalita-09.
Samuel Broscheit, Simone Paolo Ponzetto, Yannick Ver-
sley, and Massimo Poesio. 2010. Extending BART to
provide a coreference resolution system for German.
In Proc. of LREC ?10.
Marc Finthammer and Irene Cramer. 2008. Explor-
ing and navigating: Tools for GermaNet. In Proc. of
LREC ?08.
Joakim Nivre, Johan Hall, Jens Nilsson, Atanas Chanev,
Gulsen Eryigit, Sandra Ku?bler, Svetoslav Marinov,
and Erwin Marsi. 2007. Maltparser: A language-
independent system for data-driven dependency pars-
ing. Natural Language Engineering, 13(2):95?135.
Slav Petrov, Leon Barett, Romain Thibaux, and Dan
Klein. 2006. Learning accurate, compact, and inter-
pretable tree annotation. In Proc. of COLING-ACL-06.
Massimo Poesio, Olga Uryupina, and Yannick Versley.
2010. Creating a coreference resolution system for
Italian. In Proc. of LREC ?10.
Helmut Schmid, Arne Fitschen, and Ulrich Heid. 2004.
SMOR: A German computational morphology cover-
ing derivation, composition and inflection. In Proc. of
LREC ?04.
Wee Meng Soon, Hwee Tou Ng, and Daniel Chung Yong
Lim. 2001. A machine learning approach to corefer-
ence resolution of noun phrases. Computational Lin-
guistics (Special Issue on Computational Anaphora
Resolution), 27(4):521?544.
Yannick Versley, Simone Paolo Ponzetto, Massimo Poe-
sio, Vladimir Eidelman, Alan Jern, Jason Smith,
Xiaofeng Yang, and Alessandro Moschitti. 2008.
BART: A modular toolkit for coreference resolution.
In Proceedings of the Linguistic Coreference Work-
shop at the International Conference on Language Re-
sources and Evaluation (LREC-2008).
Zhibiao Wu and Martha Palmer. 1994. Verb semantics
and lexical selection. In Proc. of ACL-94, pages 133?
138.
Roberto Zanoli, Emiliano Pianta, and Claudio Giuliano.
2009. Named entity recognition through redundancy
driven classifier. In Proc. of Evalita-09.
107
