Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 1?8
Manchester, August 2008
Two-Phased Event Relation Acquisition:
Coupling the Relation-Oriented and Argument-Oriented Approaches
Shuya Abe Kentaro Inui Yuji Matsumoto
Graduate School of Information Science,
Nara Institute of Science and Technology
{shuya-a,inui,matsu}@is.naist.jp
Abstract
Addressing the task of acquiring semantic
relations between events from a large cor-
pus, we first argue the complementarity be-
tween the pattern-based relation-oriented
approach and the anchor-based argument-
oriented approach. We then propose a two-
phased approach, which first uses lexico-
syntactic patterns to acquire predicate pairs
and then uses two types of anchors to iden-
tify shared arguments. The present results
of our empirical evaluation on a large-scale
Japanese Web corpus have shown that (a)
the anchor-based filtering extensively im-
proves the accuracy of predicate pair ac-
quisition, (b) the two types of anchors are
almost equally contributive and combining
them improves recall without losing accu-
racy, and (c) the anchor-based method also
achieves high accuracy in shared argument
identification.
1 Introduction
The growing interest in practical NLP applications
such as question answering, information extrac-
tion and multi-document summarization places in-
creasing demands on the processing of relations
between textual fragments such as entailment and
causal relations. Such applications often need to
rely on a large amount of lexical semantic knowl-
edge. For example, a causal (and entailment) rela-
tion holds between the verb phrases wash some-
thing and something is clean, which reflects the
commonsense notion that if someone has washed
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
something, this object is clean as a result of the
washing event. A crucial issue is how to ob-
tain and maintain a potentially huge collection of
such event relation instances. This paper addresses
the issue of how to automatically acquire such in-
stances of relations between events (henceforth,
event relation instances) from a large-scale text
collection.
Motivated by this issue, several research groups
have reported their experiments on automatic ac-
quisition of causal, temporal and entailment rela-
tions between event expressions (typically verbs
or verb phrases) (Lin and Pantel, 2001; Inui et
al., 2003; Chklovski and Pantel, 2005; Torisawa,
2006; Pekar, 2006; Zanzotto et al, 2006; Abe et
al., 2008, etc.). As we explain below, however,
none of these studies fully achieves the goal we
pursue in this paper.
An important aspect to consider in event relation
acquisition is that each event has arguments. For
example, the causal relation between wash some-
thing and something is clean can be represented
naturally as:
(1) wash(obj:X) ?
cause
is clean(subj:X),
where X is a logical variable denoting that the
filler of the object slot of the wash event should be
shared (i.e. identical) with the filler of the subject
slot of the is clean event.
To be more general, an instance of a given rela-
tion R can be represented as:
(2) pred
1
(arg
1
:X) ?
R
pred
2
(arg
2
:X),
where pred
i
is a natural language predicate, typ-
ically a verb or adjective, and X is a logical vari-
able denoting which argument of one predicate and
which argument of the other are shared. The goal
we pursue in this paper is therefore not only (a)
to find predicate pairs that are of a given relation
1
type, but also (b) to identify the arguments shared
between the predicates if any. We call the for-
mer subtask predicate pair acquisition and the lat-
ter shared argument identification. As we review
in the next section, however, existing state-of-the-
art methods for event relation acquisition are de-
signed to achieve only either of these two subtasks
but not both. In this paper, we propose a two-
phased method, which first uses lexico-syntactic
patterns to acquire predicate pairs for a given re-
lation type and then uses two kinds of anchors to
identify shared arguments.
2 Previous work
Existing methods for event relation acquisition can
be classified into two approaches, which we call
the pattern-based approach and anchor-based ap-
proach in this paper.
The common idea behind the pattern-based ap-
proach is to use a small number of manually se-
lected generic lexico-syntactic co-occurrence pat-
terns (LSPs or simply patterns). Perhaps the sim-
plest way of using LSPs for event relation acqui-
sition can be seen in the method Chklovski and
Pantel (2005) employ to develop their knowledge
resource called VerbOcean. Their method uses a
small number of manually selected generic LSPs
such as to ?Verb-X? and then ?Verb-Y?
1
to obtain
six types of semantic relations including strength
(e.g. taint ? poison) and happens-before (e.g.
marry ? divorce). The use of such generic patterns,
however, tends to be high recall but low precision.
Chklovski and Pantel (2005), for example, report
that their method obtains about 29,000 verb pairs
with 65.5% precision.
This low-precision problem requires an addi-
tional component for pruning extracted relations.
This issue has been addressed from a variety of
angles. For example, some devise heuristic sta-
tistical scores and report their impact on preci-
sion (Chklovski and Pantel, 2005; Torisawa, 2006;
Zanzotto et al, 2006). Another way is to incor-
porate a classifier trained with supervision. Inui
et al (2003), for example, use a Japanese generic
causal connective marker tame (because) and a
supervised classifier learner to separately obtain
four types of causal relations: cause, precondi-
tion, effect and means. More recently, Abe et
al. (2008) propose to extend Pantel and Pennac-
1
A ?? included in an LSP denotes, throughout this paper,
a variable slot to be filled with an event expression. The filler
of ?? denotes either the lexical or syntactic constraints on the
slot or an example that is to fill the slot.
chiotti (2006)?s Espresso algorithm, which induces
specific reliable LSPs in a bootstrapping man-
ner for entity-entity relation extraction, so that
the extended algorithm can apply to event rela-
tions. Their method learns a large number of rel-
atively specific patterns such as cannot ?find out
(something)? due to the lack of ?investigation? in a
boot-strapping fashion, which produces a remark-
able improvement on precision.
The anchor-based approach, on the other hand,
has emerged mainly in the context of paraphrase
and entailment acquisition. This approach uses in-
formation of argument fillers (i.e. anchors) of each
event expression as a useful clue for identifying
event relations. A popular way of using such ar-
gument information relies on the distributional hy-
pothesis (Harris, 1968) and identifies synonymous
event expressions by seeking a set of event expres-
sions whose argument fillers have a similar distri-
bution. Such algorithms as DIRT (Lin and Pantel,
2001) and TE/ASE (Szpektor et al, 2004) repre-
sent this line of research.
Another way of using argument information is
proposed by Pekar (2006), which identifies candi-
date verb pairs for the entailment relation by im-
posing criteria: (a) the two verbs must appear in
the same local discourse-related context and (b)
their arguments need to refer to the same par-
ticipant, i.e. anchor. For example, if a pair of
clauses Mary bought a house. and The house be-
longs to Mary. appear in a single local discourse-
related context, two pairs of verbs, buy(obj:X) ?
belong(subj:X) and buy(subj:X) ? belong(to:X) are
identified as candidate entailment pairs.
It is by now clear that the above two approaches,
which apparently have emerged somewhat inde-
pendently, could play a complementary role with
each other. Pattern-based methods, on the one
hand, are designed to be capable of discriminat-
ing relatively fine-grained relation types. For ex-
ample, the patterns used by Chklovski and Pan-
tel (2005) identify six relation types, while Abe
et al (2008) identify two of the four causal rela-
tion types defined by Inui et al (2003). However,
these methods are severely limited for the purpose
of shared argument identification because lexico-
syntactic patterns are not a good indication of
argument-shared structure in general. The anchor-
based approach, on the other hand, works well for
identifying shared arguments simply because it re-
lies on argument information in identifying syn-
onymous or entailment verb pairs. However, it has
no direct means to discriminate more fine-grained
2
specific relations such as causality and backward
presupposition. To sum up, the pattern-based ap-
proach tends to be rather relation-oriented while
the anchor-based approach tends to be argument-
oriented.
In spite of this complementarity, however, to our
best knowledge, the issue of how to benefit from
both approaches has never been paid enough at-
tention. An interesting exception could be found
in Torisawa (2006)?s method of combining verb
pairs extracted with a highly generic connective
pattern ?Verb-X? and ?Verb-Y? together with the
co-occurrence statistics between verbs and their ar-
guments. While the reported results for inference
rules with temporal ordering look promising, it is
not clear yet, however, whether the method ap-
plies to other types of relations because it relies
on relation-specific heuristics.
3 Two-phased event relation acquisition
3.1 The basic idea
The complementarity between the pattern-based
relation-oriented approach and the anchor-based
argument-oriented approach as discussed above
naturally leads us to consider combining them.
The method we explore in this paper is illustrated
in Figure 1. The overall process has two phrases:
predicate pair acquisition followed by shared ar-
gument identification. Given a relation type for ac-
quisition, we first acquire candidate predicate pairs
that are likely to be of the given relation exploiting
a state-of-the-art pattern-based method. We then,
in the second phase, seek anchors indicative of the
shared argument for each acquired predicate pair.
We consider two kinds of anchors: instance-based
anchors and type-based anchors. If anchors are
found, the predicate pair is verified and the asso-
ciated argument pair is identified as the shared ar-
gument; otherwise, the predicate pair is discarded.
As we demonstrate in the section for empirical
evaluation, this verification process boosts the ac-
curacy as well as identifying shared arguments.
3.2 Predicate pair acquisition
For predicate pair acquisition, we can choose
one from a range of state-of-the-art pattern-based
methods. Among others, in our experiments, we
adopted Abe et al (2008)?s method because it had
an advantage in that it was capable of learning pat-
terns as well as relation instances.
Abe et al (2008)?s method is based on Pan-
tel and Pennacchiotti (2006)?s Espresso algorithm,
which is originally designed to acquire relations
between entities. Espresso takes as input a small
number of seed instances of a given target rela-
tion and iteratively learns co-occurrence patterns
and relation instances in a bootstrapping manner.
Abe et al have made several extensions to it so
that it can be applied to event relations. Since the
details of this phase are not the focus of this paper,
we refer the reader to (Abe et al, 2008) for further
information.
3.3 Shared argument identification
For each of the predicate pairs acquired in the pre-
vious phase, in shared argument identification, we
use anchors to identify which argument is shared
between the predicate pair. To find anchors indica-
tive of shared arguments, we have so far examined
two methods. We detail each below.
3.3.1 Instance-based anchors
Inspired by Pekar (2006)?s way of using an-
chors for verb entailment acquisition, we assume
that if two related predicates have a shared argu-
ment, they must tend to appear in the same local
discourse-related context with the shared argument
filled with the same noun phrase (i.e. anchor).
As an example, let us consider discourse (2a) in
Figure 1. In this local discourse context, the noun
bread appears twice, and one bread fills the subject
slot of burn while the other fills the object slot of
bake. In such a case, we assume the two breads re-
fer to the same object, namely anchor, and the sub-
ject of burn and the object of bake are shared with
each other. We call such anchors instance-based
anchors for the sake of contrast with type-based
anchors, which we describe in 3.3.2.
We implement this assumption in the following
way. Given a pair of predicates Pred
1
and Pred
2
,
we search a corpus for tuples ?Pred
1
-Arg
1
; Pred
2
,
Arg
2
; Anc? satisfying the following conditions:
(a) Anchor word Anc is the head of a noun phrase
filling argument Arg
1
of Pred
1
appearing in a
Web page.
(b) Anc also fills argument Arg
2
of Pred
2
appear-
ing in the same Web page as above.
(c) Anc must not be any of those in the stop list.
(d) pmi(Pred
i
, Arg
i
) ? ?1.0 for i ? {1, 2}
For our experiments, we manually created the stop
list, which contained 219 words including pro-
nouns, numerals and highly generic nouns such as
3
Figure 1: Two-phased event relation acquisition
4
??? (thing)?, ??? (thing)? and ??? (time)?.
pmi(Pred
i
, Arg
i
) in condition (d) is the point-wise
mutual information between Pred
i
and Arg
i
. This
condition is imposed for pruning wrong anchors
misidentified due to parsing errors.
While Pekar carefully defines boundaries of lo-
cal discourse-related context, we simply assume
that every pair of predicates sharing an anchor in
a Web page is somewhat related ? unlike Pekar,
we do not impose such constraints as paragraph
boundaries. Nevertheless, as we show later in
the evaluation section, our assumption works pre-
cisely enough because the looseness of our dis-
course boundary constraint is compensated by the
constraints imposed by lexico-syntactic patterns.
We finally calculate an anchor set for each argu-
ment pair Pred
1
-Arg
1
and Pred
2
-Arg
2
by accumu-
lating the obtained tuples:
AnchorSet(Pred
1
-Arg
1
, Pred
2
-Arg
2
)
= {Arg|?Pred
1
-Arg
1
; Pred
2
-Arg
2
; Anc?}.
3.3.2 Type-based anchors
Let us consider sentences (3a) and (3b) in
Figure 1. These two sentences both contain pred-
icates bake and burn. In (3a), the noun bread fills
the object slot of bake, while in (3b) the same noun
bread fills the subject slot of burn. In such a case,
we assume the noun bread to be an anchor indi-
cating that the object of bake and the subject of
burn are shared with each other. We call such an-
chors type-based anchors because bread in (3a)
and bread in (3b) do not refer to the same object
but are identical just as type.
Given a pair of predicates Pred
1
and Pred
2
, we
search a corpus for sentences where Pred
1
and
Pred
2
co-occur, and calculate the frequency counts
of their argument fillers appearing in those sen-
tences:
? If argument Arg
1
of Pred
1
is filled by noun
Anc, increment the count of ?Pred
1
-Arg
1
;
Pred
2
; Anc?.
? If argument Arg
2
of Pred
2
is filled by noun
Anc, increment the count of ?Pred
1
; Pred
2
-
Arg
2
; Anc?.
We then identify the intersection between the filler
sets of Pred
1
-Arg
1
and Pred
2
-Arg
2
as the anchor
set of that argument pair. Namely,
AnchSet(Pred
1
-Arg
1
, Pred
2
-Arg
2
) = S
1
? S
2
,
where
S
1
= {Arg|?Pred
1
-Arg
1
; Pred
2
; Anc?},
S
2
= {Arg|?Pred
1
; Pred
2
-Arg
2
; Anc?}.
3.3.3 Application of anchor sets
We say an argument pair covered by anchors
only if any anchor is found for it. Analogously,
we say a predicate pair covered by anchors only if
any argument pair associated with it is covered by
anchors. In the phase of shared argument identifi-
cation, for each given predicate pair, we carry out
the following procedure:
1. Discard the predicate pair if it is not covered
by anchors.
2. Choose maximally k-most frequent argument
pairs associated with the predicate pair (k = 3
in our experiments).
3. Choose maximally l-most frequent anchors
for each chosen argument pair (l = 3).
4 Experiments
4.1 Settings
For an empirical evaluation, we used a sample
of approximately 500M sentences taken from the
Web corpus collected by Kawahara and Kuro-
hashi (2006). The sentences were dependency-
parsed with CaboCha (Kudo and Matsumoto,
2002), and co-occurrence samples of event men-
tions were extracted. Event mentions with patterns
whose frequency was less than 20 were discarded
in order to reduce computational costs.
In our experiments, we considered two of Inui et
al. (2003)?s four types of causal relations: action-
effect relations (Effect in Inui et al?s terminology)
and action-means relations (Means). An action-
effect relation holds between events x and y if and
only if non-volitional event y is likely to happen as
either a direct or indirect effect of volitional action
x. For example, the action X-ga undou-suru (X ex-
ercises) and the event X-ga ase-o-kaku (X sweats)
are considered to be in this type of relation. We
did not require the necessity for an effect. For ex-
ample, while nomu (drink) does not necessarily re-
sult in futsukayoi-ni naru (have a hangover), the
assessors judged this pair correct because one can
at least say that the latter sometimes happens as a
result of the former. An action-means relation, on
the other hand, holds between events x and y if and
only if volitional action y is likely to be done as a
part/means of volitional action x. For example, if
5
case a event-pair is X-ga hashiru (X runs) is con-
sidered as a typical action that is often done as a
part of the action X-ga undou-suru (X exercises).
For our experiments, we manually built a lex-
icon of over 12,000 verbs with volitionality la-
bels, obtaining 8,968 volitional verbs, 3,597 non-
volitional and 547 ambiguous. Volitional verbs
include taberu (eat) and kenkyu-suru (research),
while non-volitional verbs include atatamaru (get
warm), kowareru (to break-vi) and kanashimu (be
sad). Volitionality information was used as a fea-
ture of predicate slots in pattern-based predicate
pair acquisition.
4.2 Results and discussion
4.2.1 Predicate pair acquisition
We ran the extended Espresso algorithm start-
ing with 25 positive and 4 negative seed rela-
tion instances for the action-effect relation and 174
positive and 131 negative seed relations for the
action-means relation. As a result, we obtained
9,511 patterns with 22,489 relation instances for
action-effect and 14,119 co-occurrence patterns
with 13,121 relation instances for action-means
after 40 iterations of pattern and instance rank-
ing/selection. The threshold parameters for select-
ing patterns and instances were decided in a pre-
liminary trial. Some of the acquired instances are
shown in Table 1.
We next randomly sampled 100 predicate pairs
from each of four sections (1?500, 501?1500,
1501?3500 and 3500?7500) of the ranks of the ac-
quired pairs for each relation class. Two annotators
were asked to judge the correctness of each pred-
icate pair (i.e. 800 pairs in total). They judged a
predicate pair to be correct if they could produce
an appropriate relation instance from that pair by
adding some shared argument. For example, the
pair??? (hang/put/call) and???? (connect)
was judged correct because it could constitute such
a relation instance as:
(3) ??? (?:X) ?
effect
???? (?:X)
(X ? {?? })
make(obj:X) ?
effect
go-through(subj:X)
(X ? {phone-call})
Unfortunately, the two annotators did not agree
with each other very much. out of the 400 sam-
ples, they agreed only on 294 for action-effect and
297 for action-means. However, a closer look at
the results revealed that the judgements of the one
annotator were considerably but very consistently
Table 2: Accuracy and recall of relation classifica-
tion
LSPs covered by anchors
all top-N instance type combined
action-effect 400 254 175 169 254
269 185 144 143 206
(accuracy) (0.67) (0.72) (0.82) (0.84) (0.81)
(recall) (1.00) (0.68) (0.53) (0.53) (0.76)
action-means 400 254 178 176 254
280 193 143 140 200
(accuracy) (0.70) (0.75) (0.80) (0.79) (0.78)
(recall) (1.00) (0.68) (0.51) (0.50) (0.71)
more tolerant than the other. Assuming that the
judgements of the latter correct, the precision and
recall of those of the former would be 0.71 and
0.97 for action-effect, and 0.75 and 0.99 for action-
means. These figures indicate that the two annota-
tors agreed quite well with respect to the ?good-
ness? of a sample, while having different criteria
for strictness. For our evaluation, we decided to
lean to the strict side and considered a sample cor-
rect only if it was judged correct by both anno-
tators. The accuracy and recall achieved by the
pattern-based model is shown in the column ?all?
under ?LSPs? in Table 2.
We then applied the anchor-based methods de-
scribed in Section 3.3 to the above 800 sampled
predicate pairs. The results are shown in the col-
umn ?covered by anchors? of Table 2. Since the
tendency for both relation classes is more or less
the same, let us focus only on the results for action-
effect.
As shown in the column ?all? under ?LSPs? in
the table, the pattern-based method covered 269
out of the 400 predicate pairs sampled above. The
instance-based anchors (?instance?) covered 175
out of the 400 predicate pairs sampled above, and
144 of them were correct with respect to relation
type. We calculate its accuracy by dividing 144
by 175 and recall by dividing 144 by 269. These
figures indicate that the instance-based anchors
chose correct predicate pairs at a very high accu-
racy while sacrificing recall. The recall, however,
can be extensively improved without losing accu-
racy by combining the instance-based and type-
based anchors, where we considered a predicate
pair covered if it was covered by either of the
instance-based and type-based anchors. The re-
sults are shown in the column ?combined? under
?covered by anchors? in the same table. While the
type-based anchors exhibited the same tendency as
the instance-based anchors (namely, high accuracy
6
Table 1: Examples
Pred1 Arg1 Pred2 Arg2 Anc
action-effect begin(????) obj(?) finish(????) subj(?) installation(? ? ? ? ? ?),
transaction(????????)
action-effect design(??????) obj(?) be pretty(????) subj(?) logotype(??)
action-effect sleep(??) in(?) be sleep(???) in(?) bed(???), futon(??)
action-means cure(????) by(?) prescribe(????) obj(?) medicine(?)
action-means cure(????) obj(?) prescribe(????) for(?) patient(??)
action-means go home(????) by(?) drive(????) obj(?) car(?), car(???)
action-means use(????) obj(?) copy(?????) obj(?) file(????), data(???)
and low recall), their coverage reasonably differed
from each other, which contributed to the improve-
ment of recall.
To summarize so far, the pattern-based method
we adopted in the experiment generated a sub-
stantial number of predicate pairs with a accuracy
comparative to the state of the art. The accuracy
was, however, further boosted by applying both
instance-based and type-based anchors. This ef-
fect is particularly important because, to our best
knowledge, very few pattern-based relation acqui-
sition models have been reported to achieve as high
a accuracy as what we achieved. In the case of our
pattern-based model, for reference, the 254 highly
ranked pairs of the 400 samples included only 185
correct pairs, which is worse than the 206 pairs
covered by anchors for both accuracy and recall
(see the ?top-N? column under ?LSPs? in Table 2.
This difference also leads us to consider incor-
porating our anchor-based filtering into the boot-
strapping cycles of pattern-based predicate pair ac-
quisition.
4.2.2 Shared argument identification
We next investigated the accuracy of shared ar-
gument identification. For each of the aforemen-
tioned predicate pairs covered by anchors (the 254
pairs for action-effect and 254 for action-means),
we asked the same two annotators as above to
judge the correctness of the shared argument in-
formation. The results of combination are shown
in Table 3.
?arg-strict? shows the results of the strict judg-
ments where the shared argument was considered
to be correctly identified only when the most fre-
quent argument pair was judged correct, while
?arg-lenient? shows the results of the lenient judg-
ments where the shared argument was considered
to be correctly identified when either of the three
most frequent argument pairs was judged correct.
For judging the correctness of an argument pair,
we had three degrees of strictness. In the most
strict criterion (?anc-strict?), an argument pair was
judged correct only when its maximally three an-
chor words were all correct, while in ?anc-lenient?,
an argument pair was judged correct when any of
the three most frequent anchor words was correct.
In ?anc-any?, an argument pair was judged correct
as far as an annotator could think of any appropri-
ate anchor word for it. While the inter-annotator
agreement was not very high, with the kappa co-
efficient in the ?arg-strict? and ?anc-any? setting
0.47 for action-effect and 0.42 for action-effect),
one was again consistently more tolerant than the
other. For the same reason as argued in 4.2.1, we
considered an acquired relation correct only if both
annotators judged it correct.
In this experiment, predicate pairs that had been
judged wrong with respect to relation types were
all considered wrong in all the settings. The upper
bounds of accuracy, therefore, are given by those
in Table 2. For ?arg-?? with the ?combined? an-
chors, for example, the upper bound of accuracy
is 0.81. Since ?arg-lenient? with ?combined? and
?anc-lenient? achieved 0.76 accuracy, our method
turned out to be reasonably precise in identifying
argument pairs and their fillers. Paying attention
to ?arg-strict? and ?anc-strict?, on the other hand,
one can see a considerable drop from the lenient
case, which needs to be further investigated.
5 Conclusion and future work
Motivated by the complementarity between the
pattern-based relation-oriented approach and the
anchor-based argument-oriented approach to event
relation acquisition, we have explored a two-
phased approach, which first uses patterns to ac-
quire predicate pairs and then uses two types of
anchors to identify shared arguments, reporting on
the present results of our empirical evaluation. The
results have shown that (a) the anchor-based fil-
tering extensively improves the accuracy of pred-
icate pair acquisition, (b) the instance-based and
type-based anchors are almost equally contributive
and combining them improves recall without los-
7
Table 3: Accuracy of shared argument identification
action-effect action-means
anc-strict anc-lenient anc-any anc-strict anc-lenient anc-any
instance 0.64 0.71 0.71 0.61 0.66 0.66
arg-strict type 0.60 0.63 0.65 0.61 0.65 0.67
combined 0.60 0.65 0.66 0.58 0.62 0.64
instance 0.78 0.80 0.80 0.73 0.75 0.76
arg-lenient type 0.68 0.71 0.72 0.67 0.69 0.71
combined 0.74 0.76 0.77 0.71 0.73 0.74
ing accuracy, and (c) the anchor-based method also
achieves high accuracy in shared argument identi-
fication.
Our future direction will be two-fold. One is
evaluation. Clearly, more comprehensive evalu-
ation needs to be done. For example, the ac-
quired relation instances should be evaluated in
some task-oriented manner. The other intriguing
issue is how our anchor-based method for shared
argument identification can benefit from recent ad-
vances in coreference and zero-anaphora resolu-
tion (Iida et al, 2006; Komachi et al, 2007, etc.).
References
Abe, Shuya, Kentaro Inui, and Yuji Matsumoto. 2008.
Acquiring event relation knowledge by learning
cooccurrence patterns and fertilizing cooccurrence
samples with verbal nouns. In Proceedings of the
3rd International Joint Conference on Natural Lan-
guage Processing, pages 497?504.
Chklovski, Timothy and Patrick Pantel. 2005. Global
path-based refinement of noisy graphs applied to
verb semantics. In Proceedings of Joint Conference
on Natural Language Processing.
Harris, Zelling. 1968. Mathematical structures of
language. Interscience Tracts in Pure and Applied
Mathematics.
Iida, Ryu, Kentaro Inui, and Yuji Matsumoto. 2006.
Exploiting syntactic patterns as clues in zero-
anaphora resolution. In Proceedings of the 21st In-
ternational Conference on Computational Linguis-
tics and the 44th annual meeting of the ACL, pages
625?632. Association for Computational Linguis-
tics.
Inui, Takashi, Kentaro Inui, and Yuji Matsumoto. 2003.
What kinds and amounts of causal knowledge can
be acquired from text by using connective markers
as clues? In Proceedings of the 6th International
Conference on Discovery Science,, pages 180?193.
Kawahara, Daisuke and Sadao Kurohashi. 2006. A
fully-lexicalized probabilistic model for japanese
syntactic and case structure analysis. In Proceedings
of the Human Language Technology Conference of
the North American Chapter of the Association for
Computational Linguistics, pages 176?183.
Komachi, Mamoru, Ryu Iida, Kentaro Inui, and Yuji
Matsumoto. 2007. Learning based argument struc-
ture analysis of event-nouns in japanese. In Proceed-
ings of the Conference of the Pacific Association for
Computational Linguistics, pages 120?128.
Kudo, Taku and Yuji Matsumoto. 2002. Japanese de-
pendency analysis using cascaded chunking. In Pro-
ceedings of the 6th Conference on Natural Language
Learning 2002 (COLING 2002 Post-Conference
Workshops), pages 63?69.
Lin, Dekang and Patrick Pantel. 2001. Dirt: discovery
of inference rules from text. In Proceedings of the
seventh ACM SIGKDD international conference on
Knowledge discovery and data mining, pages 323?
328.
Pantel, Patrick and Marco Pennacchiotti. 2006.
Espresso: Leveraging generic patterns for automat-
ically harvesting semantic relations. In Proceedings
of the 21st International Conference on Computa-
tional Linguistics and 44th Annual Meeting of the
ACL, pages 113?120.
Pekar, Viktor. 2006. Acquisition of verb entailment
from text. In Proceedings of the Human Language
Technology Conference of the NAACL, Main Confer-
ence, pages 49?56.
Szpektor, Idan, Hristo Tanev, Ido Dagan, and Bonaven-
tura Coppola. 2004. Scaling web-based acquisition
of entailment relations. In Lin, Dekang and Dekai
Wu, editors, Proceedings of EMNLP 2004, pages
41?48, Barcelona, Spain. Association for Computa-
tional Linguistics.
Torisawa, Kentaro. 2006. Acquiring inference rules
with temporal constraints by using japanese coordi-
nated sentences and noun-verb co-occurrences. In
Proceedings of Human Language Technology Con-
ference/North American chapter of the Association
for Computational Linguistics annual meeting (HLT-
NAACL06), pages 57?64.
Zanzotto, Fabio Massimo, Marco Pennacchiotti, and
Maria Teresa Pazienza. 2006. Discovering asym-
metric entailment relations between verbs using se-
lectional preferences. In Proceedings of the 21st In-
ternational Conference on Computational Linguis-
tics and 44th Annual Meeting of the Association for
Computational Linguistics, pages 849?856.
8
Acquiring Event Relation Knowledge by Learning Cooccurrence Patterns
and Fertilizing Cooccurrence Samples with Verbal Nouns
Shuya Abe Kentaro Inui Yuji Matsumoto
Graduate School of Information Science,
Nara Institute of Science and Technology
{shuya-a,inui,matsu}@is.naist.jp
Abstract
Aiming at acquiring semantic relations be-
tween events from a large corpus, this paper
proposes several extensions to a state-of-the-
art method originally designed for entity re-
lation extraction, reporting on the present re-
sults of our experiments on a Japanese Web
corpus. The results show that (a) there are
indeed specific cooccurrence patterns use-
ful for event relation acquisition, (b) the
use of cooccurrence samples involving ver-
bal nouns has positive impacts on both re-
call and precision, and (c) over five thou-
sand relation instances are acquired from a
500M-sentence Web corpus with a precision
of about 66% for action-effect relations.
1 Introduction
The growing interest in practical NLP applications
such as question answering, information extraction
and multi-document summarization places increas-
ing demands on the processing of relations between
textual fragments such as entailment and causal rela-
tions. Such applications often need to rely on a large
amount of lexical semantic knowledge. For exam-
ple, a causal (and entailment) relation holds between
the verb phrases wash something and something is
clean, which reflects the commonsense notion that if
someone has washed something, this object is clean
as a result of the washing event. A crucial issue is
how to obtain and maintain a potentially huge col-
lection of such event relations instances.
Motivated by this background, several research
groups have reported their experiments on automatic
acquisition of causal, temporal and entailment re-
lations between event mentions (typically verbs or
verb phrases) (Lin and Pantel, 2001; Inui et al,
2003; Chklovski and Pantel, 2005; Torisawa, 2006;
Pekar, 2006; Zanzotto et al, 2006, etc.). The com-
mon idea behind them is to use a small number of
manually selected generic lexico-syntactic cooccur-
rence patterns (LSPs or simply patterns). to Verb-X
and then Verb-Y, for example, is used to obtain tem-
poral relations such as marry and divorce (Chklovski
and Pantel, 2005). The use of such generic patterns,
however, tends to be high recall but low precision,
which requires an additional component for pruning
extracted relations. This issue has been addressed in
basically two approaches, either by devising heuris-
tic statistical scores (Chklovski and Pantel, 2005;
Torisawa, 2006; Zanzotto et al, 2006) or training
classifiers for disambiguation with heavy supervi-
sion (Inui et al, 2003).
This paper explores a third way for enhancing
present LSP-based methods for event relation acqui-
sition. The basic idea is inspired by the following
recent findings in relation extraction (Ravichandran
and Hovy, 2002; Pantel and Pennacchiotti, 2006,
etc.), which aims at extracting semantic relations be-
tween entities (as opposed to events) from texts. (a)
The use of generic patterns tends to be high recall
but low precision, which requires an additional com-
ponent for pruning. (b) On the other hand, there are
specific patterns that are highly reliable but they are
much less frequent than generic patterns and each
makes only a small contribution to recall. (c) Com-
bining a few generic patters with a much larger col-
lection of reliable specific patterns boosts both pre-
497
cision and recall. Such specific patterns can be ac-
quired from a very large corpus with seeds.
Given these insights, an intriguing question is
whether the same story applies to event relation ac-
quisition as well or not. In this paper, we explore this
issue through the following steps. First, while previ-
ous methods use only verb-verb cooccurrences, we
use cooccurrences between verbal nouns and verbs
such as cannot ?find out (something)? due to the
lack of ?investigation? as well as verb-verb cooc-
currences. This extension dramatically enlarge the
pool of potential candidate LSPs (Section 4.1). Sec-
ond, we extend Pantel and Pennacchiotti (2006)?s
Espresso algorithm, which induces specific reliable
LSPs in a bootstrapping manner for entity relation
extraction, so that the extended algorithm can apply
to event relations (Sections 4.2 to 4.4). Third, we
report on the present results of our empirical experi-
ments, where the extended algorithm is applied to a
Japanese 500M-sentence Web corpus to acquire two
types of event relations, action-effect and action-
means relations (Section 5)
2 Related work
Perhaps a simplest way of using LSPs for event rela-
tion acquisition can be seen in the method Chklovski
and Pantel (2005) employ to develop VerbOcean.
Their method uses a small number of manually se-
lected generic LSPs such as to Verb-X and then Verb-
Y to obtain six types of semantic relations including
strength (e.g. taint ? poison) and happens-before
(e.g. marry ? divorce) and obtain about 29,000 verb
pairs with 65.5% precision.
One way for pruning extracted relations is to in-
corporate a classifier trained with supervision. Inui
et al (2003), for example, use a Japanese generic
causal connective marker tame (because) and a su-
pervised classifier learner to separately obtain four
types of causal relations: cause, precondition, effect
and means.
Torisawa (2006), on the other hand, acquires en-
tailment relations by combining the verb pairs ex-
tracted with a highly generic connective pattern
Verb-X and Verb-Y together with the cooccurrence
statistics between verbs and their arguments. While
the results Torisawa reports look promising, it is not
clear yet if the method applies to other types of rela-
tions because it relies on relation-specific heuristics.
Another direction from (Chklovski and Pantel,
2005) is in the use of LSPs involving nominalized
verbs. Zanzotto et al (2006) obtain, for example, an
entailment relation X wins ? X plays from such a
pattern as player wins. However, their way of using
nominalized verbs is highly limited compared with
our way of using verbal nouns.
3 Espresso
This section overviews Pantel and Pennacchiotti
(2006)?s Espresso algorithm. Espresso takes as input
a small number of seed instances of a given target
relation and iteratively learns cooccurrence patterns
and relation instances in a bootstrapping manner.
Ranking cooccurrence patterns For each given
relation instance {x, y}, Espresso retrieves the sen-
tences including both x and y from a corpus and
extracts from them cooccurrence samples. For ex-
ample, given an instance of the is-a relation such
as ?Italy,country?, Espresso may find cooccurrence
samples such as countries such as Italy and extract
such a pattern as Y such as X. Espresso defines the
reliability rpi(p) of pattern p as the average strength
of its association with each relation instance i in
the current instance set I , where each instance i is
weighted by its reliability r?(i):
rpi(p) = 1|I|
?
i?I
pmi(i, p)
max pmi ? r?(i) (1)
where pmi(i, p) is the pointwise mutual information
between i and p, and maxpmi is the maximum PMI
between all patterns and all instances.
Ranking relation instances Intuitively, a reliable
relation instance is one that is highly associated with
multiple reliable patterns. Hence, analogously to the
above pattern reliability measure, Espresso defines
the reliability r?(i) of instance i as:
r?(i) = 1|P |
?
p?P
pmi(i, p)
max pmi ? rpi(p) (2)
where rpi(p) is the reliability of pattern p, defined
above in (1), and maxpmi is as before. r?(i) and
rpi(p) are recursively defined, where r?(i) = 1 for
each manually supplied seed instance i1.
1For our extension, r?(i) = ?1 for each manually supplied
negative instance.
498
4 Event relation acquisition
Our primary concerns are whether there are in-
deed specific cooccurrence patterns useful for ac-
quiring event relations and whether such patterns
can be found in a bootstrapping manner analogous to
Espresso. To address these issues, we make several
extensions to Espresso, which is originally designed
for entity relations (not scoping event relations).
4.1 Cooccurences with verbal nouns
Most previous methods for event relation acquisition
rely on verb-verb cooccurrences because verbs (or
verb phrases) are the most typical device for refer-
ring to events. However, languages have another
large class of words for event reference, namely
verbal nouns or nominalized forms of verbs. In
Japanese, for example, verbal nouns such as kenkyu
(research) constitute the largest morphological cate-
gory used for event reference.
Japanese verbal nouns have dual statuses, as verbs
and nouns. When occurring with the verb suru (do-
PRES), verbal nouns function as a verb as in (1a).
On the other hand, when accompanied by case mark-
ers such as ga (NOMINATIVE) and o (ACCUSATIVE),
they function as a noun as in (1b). Finally, but even
more importantly, when accompanied by a large va-
riety of suffixes, verbal nouns constitute compound
nouns highly productively as in (1c).
(1) a. Ken-ga gengo-o kenkyu-suru
Ken-NOM language-ACC research-PRES
Ken researches on language.
b. Ken-ga gengo-no kenkyu-o yame-ta
Ken-NOM language-on research-ACC quit-PAST
Ken quitted research on language.
c. -sha (person):
e.g. kenkyu-sha (researcher)
-shitsu (place):
e.g. kenkyu-shitsu (laboratory)
-go (after):
e.g. kenkyu-go (after research)
These characteristics of verbal nouns can be made
use of to substantially increase both cooccurrence
instances and candidate cooccurrence patterns (see
Section 5.1 for statistics). For example, the verbal
noun kenkyu (research) often cooccurs with the verb
jikken (experiment) in the pattern of (2a). From
those cooccurrences, one may learn that jikken-suru
(to experiment) is an action that is often taken as a
part of kenkyu-suru (to research). In such a case, we
may consider a pattern as shown in (2b) useful for
acquiring part-of relations between actions.
(2) a. kenkyu-shitsu-de jikken-suru
research-place-in experiment-VERB
conduct experiments in the laboratory
b. (Act-X)-shitsu-de (Act-Y)-suru
(Act-X)-place-in (Act-X)-VERB
(Act-Y) is often done in doing (Act-X)
When functioning as a noun, verbal nouns are po-
tentially ambiguous between the event reading and
the entity/object reading. For example, the ver-
bal noun denwa (phone) in the context denwa-de
(phone-by) may refer to either a phone-call event
or a physical phone. While, ideally, such event-
hood ambiguities should be resolved before collect-
ing cooccurrence samples with verbal nouns, we
simply use all the occurrences of verbal nouns in
collecting cooccurrences in our experiments. It is
an interesting issue for future work whether event-
hood determination would have a strong impact on
the performance of event relation extraction.
4.2 Selection of arguments
One major step from the extraction of entity rela-
tions to the extraction of event relations is how to
address the issue of generalization. In entity rela-
tion extraction, relations are typically assumed to
hold between chunks like named entities or simply
between one-word terms, where the issue of deter-
mining the appropriate level of the generality of ex-
tracted relations has not been salient. In event rela-
tion extraction, on the other hand, this issue imme-
diately arises. For example, the cooccurrence sam-
ple in (3) suggests the action-effect relation between
niku-o yaku (grill the meat) and (niku-ni) kogeme-ga
tsuku ((the meat) gets brown)2.
(3) ( kogeme-ga tsuku ) -kurai niku-o yaku
a burn-NOM get -so that meat-ACC grill
grill the meat so that it gets brown
(grill the meat to a deep brown)
In this relation, the argument niku (meat) of the
verb yaku (grill) can be dropped and generalized
2The parenthesis in the first row of (3) indicates a subordi-
nate clause.
499
to something to grill; namely the action-effect rela-
tion still holds between X-o yaku (grill X) and X-ni
kogeme-ga tsuku (X gets brown). On the other hand,
however, the argument kogeme (a burn) of the verb
tsuku (get) cannot be dropped; otherwise, the rela-
tion would no longer hold.
One straightforward way to address this problem
is to expand each cooccurrence sample to those cor-
responding to different degrees of generalization and
feed them to the relation extraction model so that its
scoring function can select appropriate event pairs
from expanded samples. For example, cooccurrence
sample (3) is expanded to those as in (4):
(4) a. ( kogeme-ga tsuku ) -kurai niku-o yaku
a burn-NOM get -so that meat-ACC grill
b. ( tsuku ) -kurai niku-o yaku
get -so that meat-ACC grill
c. ( kogeme-ga tsuku ) -kurai yaku
a burn-NOM get -so that grill
d. ( tsuku ) -kurai yaku
get -so that grill
In practice, in our experiments (Section 5), we re-
strict the number of arguments for each event up to
one to avoid the explosion of the types of infrequent
candidate relation instances.
4.3 Volitionality of events
Inui et al (2003) discuss how causal rela-
tions between events should be typologized for
the purpose of semantic inference and classify
causal relations basically into four types ? Ef-
fect, Means, Precondition and Cause relations
? based primarily on the volitionality of in-
volved events. For example, Effect relations hold
between volitional actions and their resultative
non-volitional states/happenings/experiences, while
Cause relations hold between only non-volitional
states/happenings/experiences.
Following this typology, we are concerned with
the volitionality of each event mention. For our
experiments, we manually built a lexicon of over
12,000 verbs (including verbal nouns) with volition-
ality labels, obtaining 8,968 volitional verbs, 3,597
non-volitional and 547 ambiguous. Volitional verbs
include taberu (eat) and kenkyu-suru (research),
while non-volitional verbs include atatamaru (get
warm), kowareru (to break-vi) and kanashimu (be
sad). We discarded the ambiguous verbs in the ex-
periments.
4.4 Dependency-based cooccurrence patterns
The original Espresso encodes patterns simply as a
word sequence because entity mentions in the rela-
tions it scopes tend to cooccur locally in a single
phrase or clause. In event relation extraction, how-
ever, cooccurrence patterns of event mentions in the
relations we consider (causal relations, temporal re-
lations, etc.) can be captured better as a path on
a syntactic dependency tree because (i) such men-
tion pairs tend to cooccur in a longer dependency
path and (ii) as discussed in Section 4.2, we want
to exclude the arguments of event mentions from
cooccurrence patterns, which would be difficult with
word sequence-based representations of patterns.
A Japanese sentence can be analyzed as a se-
quence of base phrase (BP) chunks called bunsetsu
chunks, each which typically consists of one con-
tent (multi-)word followed by functional words. We
assume each sentence of our corpus is given a de-
pendency parse tree over its BP chunks. Let us call
a BP chunk containing a verb or verbal noun an
event chunk. We create a cooccurrence sample from
any pair of event chunks that cooccur if either (a)
one event chunk depends directly on the other, or
(b) one event chunk depends indirectly on the other
via one intermediate chunk. Additionally, we apply
the Japanese functional expressions dictionary (Mat-
suyoshi et al, 2006) to a cooccurrence pattern for
generalization.
In (5), for example, the two event chunks,
taishoku-go-ni (after retirement) and hajimeru (be-
gin), meet the condition (b) above and the depen-
dency path designated by bold font is identified as a
candidate cooccurrence pattern. The argument PC-o
of the verb hajimeru is excluded from the path.
(5) (taishoku-go-no tanoshimi)-ni PC-o hajimeru
retirement-after as a hobby PC-ACC begin
begin a PC as a hobby after retirement
5 Experiments
5.1 Settings
For an empirical evaluation, we used a sample
of approximately 500M sentences taken from the
500
Table 1: Examples of acuired cooccurrence patterns and relatio instances for the action-effect relation
freq cooccurrence patterns relation instances
94477 ?verb;action?temo?verb;effect?nai
(to do ?action? though ?effect? dose not happen)
sagasu::mitsukaru (search::be found),
asaru::mitsukaru (hunt::be found), purei-suru::kuria-
suru (play::finish)
6250 ?verb;action?takeredomo?verb;effect?nai
(to do ?action? though ?effect? dose not happen)
shashin-wo-toru::toreru (shot photograph::be shot),
meiru-wo-okuru::henji-ga-kaeru (send a mail::get an
answer)
1851 ?noun;action?wo-shitemo?verb;effect?nai
(to do ?action? though ?effect? dose not happen)
setsumei-suru::nattoku-suru (explain::agree), siai-
suru::katsu (play::win), siai-suru::makeru (play::lose)
1329 ?verb;action?yasukute?adjective;effect?
(to simply do ?action? and ?effect?)
utau::kimochiyoi (sing::feel good),
hashiru::kimochiyoi (run::feel good)
4429 ?noun;action?wo-kiite?verb;effect?
(to hear ?action? so that ?effect?)
setsumei-suru::nattoku-suru (explain::agree), setsumei-
suru::rikai-dekiru (explain::can understand)
Web corpus collected by Kawahara and Kuro-
hashi (2006). The sentences were dependency-
parsed with Cabocha (Kudo and Matsumoto, 2002),
and cooccurrence samples of event mentions were
extracted. Event mentions with patterns whose fre-
quency was less than 20 were discarded in order to
reduce computational costs. As a result, we obtained
34M cooccurrence tokens with 11M types. Note
that among those cooccurrence samples 15M tokens
(44%) with 4.8M types (43%) are those with ver-
bal nouns, suggesting the potential impacts of using
verbal nouns.
In our experiments, we considered two of Inui et
al. (2003)?s four types of causal relations: action-
effect relations (Effect in Inui et al?s terminology)
and action-means relations (Means). An action-
effect relation holds between events x and y if and
only if non-volitional event y is likely to happen as
either a direct or indirect effect of volitional action
x. For example, the action X-ga undou-suru (X exer-
cises) and the event X-ga ase-o kaku (X sweats) are
considered to be in this type of relation. A action-
means relation holds between events x and y if and
only if volitional action y is likely to be done as a
part/means of volitional action x. For example, if
case a event-pair is X-ga hashiru (X runs) is consid-
ered as a typical action that is often done as a part of
the action X-ga undou-suru (X exercises).
Note that in these experiments we do not differ-
entiate between relations with the same subject and
those with a different subject. However we plan to
conduct further experiments in the future that make
use of this distinction.
In addition, we have collected action-effect rela-
tion instances for a baseline measure. The baseline
consists of instances that cooccur with eleven pat-
terns that indicate action-effect relation. The dif-
ference between the extended Espresso and baseline
is caused by the low number and constant scores of
patterns.
5.2 Results
We ran the extended Espresso algorithm starting
with 971 positive and 1069 negative seed relation
instances for action-effect relation and 860 positive
and 74 negative seed relations for action-means re-
lation. As a result, we obtained 34,993 cooccurrence
patterns with 173,806 relation instances for the
action-effect relation and 23,281 coocurrence rela-
tions with 237,476 relation instances for the action-
means relation after 20 iterations of pattern rank-
ing/selection and instance ranking/selection. The
threshold parameters for selecting patterns and in-
stances were decided in a preliminary trial. Some
of the acquired patterns and instances for the action-
effect relation are shown in Table 1.
5.2.1 Precision
To estimate precision, 100 relation instances were
randomly sampled from each of four sections of the
ranks of the acquired instances for each of the two
relations (1?500, 501?1500, 1501?3500 and 3500?
7500), and the correctness of each sampled instance
was judged by two graduate students (i.e. 800 rela-
tion instances in total were judged).
Note that in these experiments we asked the asses-
sors to both (a) the degree of the likeliness that the
effect/means takes place and (b) which arguments
are shared between the two events. For example,
while nomu (drink) does not necessarily result in
501
futsukayoi-ni naru (have a hangover), the assessors
judged this pair correct because one can at least say
that the latter sometimes happens as a result of the
former. For criterion (b), as shown in Table 1, the
relation instances judged correct include both the X-
ga VP1::X-ga VP2 type (i.e. two subjects are shared)
and the X-o VP1::X-ga VP2 type (the object of the
former and the subject of the latter are shared). The
issue of how to control patterns of argument sharing
is left for future work.
The precision for the assessed samples are shown
in Figures 1 to 3. ?2 judges? means that an instance
is acceptable to both judges. ?1 judges? means that
it is an acceptable instance to at least one of the two
judges. ?strict? indicates correct instance relations
while ?lenient?3 indicates correct instance relations
? when a judge appends the right cases.
As a result of this strictness in judgement, the
inter-assessor agreement turned out to be poor. The
kappa statistics was 0.53 for the action-effect rela-
tions, 0.49 for the action-effect relations (=baseline)
and 0.55 for action-means relations.
The figures show that both types of relations were
acquired with reasonable precision not only for the
higher-ranked instances but also for lower-ranked
instances. It may seem strange that the precision
of the lower-ranked action-means instances is some-
times even better than the higher-ranked ones, which
may mean that the scoring function given in Section
3 did not work properly. While further investiga-
tion is clearly needed, it should also be noted that
higher-ranked instances tended to be more specific
than lower-ranked ones.
5.2.2 Effects of seed number
We reran the extended Espresso algorithm for the
action-effect relation, starting with 500 positive and
500 negative seed relation instances. The preci-
sion is shown in Figure 44. This precision is fairly
lower than that of action-effect relations with all
seed instances. Additionally, the number of seed in-
stances affects the precision of both higher-ranked
and lower-ranked instances. This result indicates
that while the proposed algorithm is designed to
work with a small seed set, in reality its performance
3If an instance is judged as ?strict? by one assessor and ?le-
nient? by the other, then the instance is assessed as ?lenient?.
4It was only judged by one assessor.
severely depends on the number of seeds.
5.2.3 Effects of using verbal nouns
We also examine the effect of using verbal nouns.
Of the 500 highest scored patterns for the action-
effect relation, 128 patterns include verbal noun
slots, and for action-means, 495 patterns. Hence,
the presence of verbal nouns greatly effects some
acquired instances. Additionally, to see the influ-
ence of frequency, of the 500 high frequent patterns
selected from the 2000 highest scored patterns for
action-effect relation, 177 include verbal noun slots,
and for action-means, 407 patterns. This result pro-
vides further evidence that the inclusion of verbal
nouns has a positive effect in this task.
5.2.4 Argument selection
According to our further investigation on argu-
ment selection, 49 instances (12%) of the correct
action-effect relation instances that are judged cor-
rect have a specific argument in at least one event,
and all of them would be judged incorrect (i.e. over-
generalized) if they did not have those arguments
(Recall the example of kogeme-ga tsuku (get brown)
in Section 4.2). This figure indicates that our method
for argument selection works to a reasonable degree.
However, clearly there is still much room for im-
provement. According to our investigation, up to
26% of the instances that are judged incorrect could
be saved if appropriate arguments were selected. For
example, X-ga taberu (X eats) and X-ga shinu (X
dies) would constitute an action-effect relation if the
former event took such an argument as dokukinoko-
o (toadstool-ACC). The overall precision could be
boosted if an effective method for argument selec-
tion method were devised.
6 Conclusion and future work
In this paper, we have addressed the issue of how
to learn lexico-syntactic patterns useful for acquir-
ing event relation knowledge from a large corpus,
and proposed several extensions to a state-of-the-art
method originally designed for entity relation ex-
traction, reporting on the present results of our em-
pirical evaluation. The results have shown that (a)
there are indeed specific cooccurrence patterns use-
ful for event relation acquisition, (b) the use of cooc-
currence samples involving verbal nouns has pos-
502
 0
 0.2
 0.4
 0.6
 0.8
 1
 0  1000  2000  3000  4000  5000  6000  7000  8000
pre
cis
ion
 [%
]
rank
strict (2 judged)
lenient (2 judged)
strict (1 judged)
lenient (1 judged)
Figure 1: action-effect
 0
 0.2
 0.4
 0.6
 0.8
 1
 0  1000  2000  3000  4000  5000  6000  7000  8000
pre
cis
ion
 [%
]
rank
strict (2 judged)
lenient (2 judged)
strict (1 judged)
lenient (1 judged)
Figure 2: action-means
 0
 0.2
 0.4
 0.6
 0.8
 1
 0  1000  2000  3000  4000  5000  6000  7000  8000
pre
cis
ion
 [%
]
rank
strict (2 judged)
lenient (2 judged)
strict (1 judged)
lenient (1 judged)
Figure 3: action-effect (baseline)
 0
 0.2
 0.4
 0.6
 0.8
 1
 0  1000  2000  3000  4000  5000  6000  7000  8000
pre
cis
ion
 [%
]
rank
system (strict)
system (lenient)
baseline (strict)
baseline (lenient)
half (strict)
half (lenient)
Figure 4: action-effect (half seed)
503
itive impacts on both recall and precision, and (c)
over five thousand relation instances are acquired
from the 500M-sentence Web corpus with a preci-
sion of about 66% for action-effect relations.
Clearly, there is still much room for exploration
and improvement. First of all, more comprehensive
evaluations need to be done. For example, the ac-
quired relations should be evaluated in terms of re-
call and usefulness. A deep error analysis is also
needed. Second, the experiments have revealed that
one major problem to challenge is how to optimize
argument selection. We are seeking a way to incor-
porate a probabilistic model of predicate-argument
cooccurrences into the ranking function for relation
instances. Related to this issue, it is also crucial
to devise a method for controlling argument shar-
ing patterns. One possible approach is to employ
state-of-the-art techniques for coreference and zero-
anaphora resolution (Iida et al, 2006; Komachi et
al., 2007, etc.) in preprocessing cooccurrence sam-
ples.
References
Timothy Chklovski and Patrick Pantel. 2005. Global
path-based refinement of noisy graphs applied to verb
semantics. In Proceedings of Joint Conference on Nat-
ural Language Processing (IJCNLP-05), pages 792?
803.
Ryu Iida, Kentaro Inui, and Yuji Matsumoto. 2006. Ex-
ploiting syntactic patterns as clues in zero-anaphora
resolution. In Proceedings of the 21st International
Conference on Computational Linguistics and the 44th
annual meeting of the ACL, pages 625?632.
Takashi Inui, Kentaro Inui, and Yuji Matsumoto. 2003.
What kinds and amounts of causal knowledge can be
acquired from text by using connective markers as
clues? In Proceedings of the 6th International Con-
ference on Discovery Science, pages 180?193. An ex-
tended version: Takashi Inui, Kentaro Inui, and Yuji
Matsumoto (2005). Acquiring causal knowledge from
text using the connective marker tame. ACM Trans-
actions on Asian Language Information Processing
(TALIP), 4(4):435?474.
Daisuke Kawahara and Sadao Kurohashi. 2006. A fully-
lexicalized probabilistic model for japanese syntactic
and case structure analysis. In Proceedings of the Hu-
man Language Technology Conference of the NAACL,
Main Conference, pages 176?183.
Mamoru Komachi, Ryu Iida, Kentaro Inui, and Yuji Mat-
sumoto. 2007. Learning based argument structure
analysis of event-nouns in japanese. In Proceedings
of the Conference of the Pacific Association for Com-
putational Linguistics (PACLING), pages 120?128.
Taku Kudo and Yuji Matsumoto. 2002. Japanese depen-
dency analysis using cascaded chunking. In CoNLL
2002: Proceedings of the 6th Conference on Natu-
ral Language Learning 2002 (COLING 2002 Post-
Conference Workshops), pages 63?69.
Dekang Lin and Patrick Pantel. 2001. DIRT - discov-
ery of inference rules from text. In Proceedings of
ACM SIGKDD Conference on Knowledge Discovery
and Data Mining 2001, pages 323?328.
Suguru Matsuyoshi, Satoshi Sato, and Takehito Utsuro.
2006. Compilation of a dictionary of japanese func-
tional expressions with hierarchical organization. In
Proceedings of the 21st International Conference on
Computer Processing of Oriental Languages, pages
395?402.
Patric Pantel and Marco Pennacchiotti. 2006. Espresso:
Leveraging generic patterns for automatically harvest-
ing semantic relations. In the 21st International Con-
ference on Computational Linguistics and 44th Annual
Meeting of the ACL, pages 113?120.
Viktor Pekar. 2006. Acquisition of verb entailment from
text. In Proceedings of the Human Language Tech-
nology Conference of the NAACL, Main Conference,
pages 49?56.
Deepak Ravichandran and Eduard Hovy. 2002. Learning
surface text patterns for a question answering system.
In Proceedings of the 21st International Conference
on Computational Linguistics and 40th Annual Meet-
ing of the Association for Computational Linguistics,
pages 41?47.
Kentaro Torisawa. 2006. Acquiring inference rules with
temporal constraints by using japanese coordinated
sentences and noun-verb co-occurrences. In Proceed-
ings of the Human Language Technology Conference
of the NAACL, Main Conference, pages 57?64.
Fabio Massimo Zanzotto, Marco Pennacchiotti, and
Maria Teresa Pazienza. 2006. Discovering asym-
metric entailment relations between verbs using selec-
tional preferences. In Proceedings of the 21st Interna-
tional Conference on Computational Linguistics and
44th Annual Meeting of the Association for Computa-
tional Linguistics, pages 849?856.
504
