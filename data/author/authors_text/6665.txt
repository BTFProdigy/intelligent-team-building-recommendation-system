Proceedings of the 4th ACL-SIGSEM Workshop on Prepositions, pages 38?44,
Prague, Czech Republic, June 2007. c?2007 Association for Computational Linguistics
Inferring the semantics of temporal prepositions in Italian
Tommaso Caselli          Valeria Quochi
ILC-CNR
Via Moruzzi, 1 56123, Pisa, Italy 
Dip. Linguistica ?T.Bolelli?, Universit? degli Studi di Pisa
Via S.ta Maria, 36, 56100, Pisa, Italy 
tommaso.caselli,valeria.quochi@ilc.cnr.it
Abstract
In this work we report on the results of a 
preliminary corpus study of Italian on the 
semantics of temporal prepositions, which 
is part of a wider project on the automatic 
recognition of temporal relations. The cor-
pus data collected supports our hypothesis 
that each temporal preposition can be asso-
ciated with one prototypical temporal rela-
tion, and that deviations from the prototype 
can be explained as determined by the oc-
currence of different semantic patterns. The 
motivation behind this approach is to im-
prove methods for temporal annotation of 
texts for content based access to informa-
tion. The corpus study described in this pa-
per led to the development of a preliminary 
set of heuristics for automatic annotation of
temporal relations in text/discourse. 
1 Introduction
In this work we report on the preliminary results 
of a corpus study, of contemporary Italian, on tem-
poral relations that hold between a temporal ad-
junct and an event as a way to determine the se-
mantics of temporal prepositions. We claim, fol-
lowing Schilder and Habel (2001), that the seman-
tics of temporal prepositions is rel (e, t), where rel
is used to indicate the temporal relation associated 
with a certain preposition, t represents the meaning 
of the Temporal Expression (timex), and e the 
meaning of the event description involved. 
Prepositions introducing a temporal adjunct are 
explicit signals of temporal relations. The ability to 
determine temporal relations between timexes in-
troduced by prepositions and events is fundamental 
for several NLP tasks like Open-Domain Question-
Answering systems (Hartrumpf et al 2006, and 
Pustejovsky et al 2002) and for Textual Entail-
ment and Reasoning.
The corpus data collected seems to support our 
hypothesis that each temporal preposition can be 
associated with one prototypical temporal relation, 
and that deviations from the prototype can be ex-
plained as determined the occurrences of different 
semantic pattern.
The work described in this paper is part of a lar-
ger project we are conducting on temporal dis-
course processing in Italian, as proposed in Mani 
and Pustejovsky (2004).
2 Background
This section presents a brief overview of the Ti-
meML specification language (Pustejovsky et al 
2005), which has been used as the starting point for 
this work, and some theoretical issues on Italian 
prepositions. 
2.1 TimeML
The TimeML specification language (Pustejovsky 
et al 2005) offers a guideline for annotation of 
timexes, events and their relations. Like other an-
notation schemes1, TimeML keeps separated tem-
poral expressions and events, tagged, respectively, 
with TIMEX3 and EVENT. In addition, two other 
tags are used: SIGNAL and LINK.
    The EVENT tag is used to annotate events, de-
fined as something which occur or happen, and 
                                                
1 Filatova and Hovy (2001), Schilder and Habel (2001), 
Setzer (2001). 
38
states, defined as situations in which something 
holds true.
    Temporal expressions, or timexes, like day times 
(noon, the evening, 1p.m?), dates of different 
granularity (yesterday, February 2 2007, last week, 
last spring, last centuries?), durations (five hours, 
in recent years?) and sets (twice a day?), are 
annotated with the TIMEX3 tag. This tag is based 
on specifications given by Ferro et al (2001) and 
Setzer (2001). Each timex is assigned to one of the 
following types: DATE, for calendar times, TIME, 
for times of the day, even if indefinites (e.g. ?the 
evening?), DURATION, for timexes expressing a 
duration, and SET, for sets of times. Each timex is 
further assigned a value, according to the ISO 8601 
specifications (for instance, 3 anni ?3 years? is 
normalized as ?P3Y?, i.e. a ?period of 3 years?).
   Function words which explicitly signal a relation 
between two elements (timex and event, timex and 
timex, or event and event) are tagged with SIG-
NAL. 
     Finally, the LINK tag is used to specify the re-
lation between two entities. It may indicate a tem-
poral relation (TLINK), a subordinating relation 
(SLINK) or an aspectual relation (ALINK). The 
TLINK tag, which is pivotal for the present work, 
comprises 15 relations, only 13 of which are purely 
temporal. The 13 relations can be seen as derived 
from Allen?s (1984) temporal logic, and 6 of them 
are binary relations - one being the inverse of the 
other. These relations (simultaneous, in-
cludes, is_included, during, 
inv_during, begin, end, begun_by, 
ended_by, before, after) make explicit the 
temporal relation holding between two elements. 
2.2 Temporal PPs in Italian
Italian prepositions can be divided into two main 
groups: monosyllabic like a, da, in, per, tra, -and 
polysyllabic ones like fino a ?up to?, dopo ?after?,, 
prima ?before??This difference at a surface level 
reflects a difference also at a semantic level: 
monosyllabic prepositions are either semantically 
empty elements (i.e. when they are particles pre-
selected by the VP), or they bear a very abstract 
relational meaning, which gets specialized on the 
basis of the co-text; polysyllabic prepositions, on 
the other hand, have a more specific meaning of 
their own. For instance, the preposition dopo ?af-
ter? always means ?subsequently, afterwards?, dis-
regarding its co-text; which makes the identifica-
tion of the relation between the elements involved 
an easier task. In addition to this, most prepositions, 
both polysyllabic and monosyllabic, belong to dif-
ferent semantic fields, e.g. spatial, temporal, man-
ner or other. 
    For the purpose of this work, any preposition 
followed by a timex, as defined in TimeML (Sec-
tion 2.1), is considered a temporal preposition. 
Consequently, we will speak of Temporal PP for 
any sequence of the form ?preposition + timex?. 
In Italian, as in many other languages, the form 
that Temporal PPs, or temporal adjuncts, may take 
is influenced by the aspect and actionality of the 
VP. In traditional grammars, for instance, it is 
claimed that they can be introduced by in if the 
lexical aspect denotes a telic event (e.g. (1)) and by 
per if the lexical aspect denotes a process or a par-
ticular subclass of telic events, i.e. achievements 
(e.g. (2)). Moreover, these kinds of Temporal PPs  
necessarily refer to the conclusion of the process 
denoted by the events and thus are incompatible 
with the progressive aspect:
1) a. Maria ha pulito la stanza in mezz?ora.
           [Maria cleaned the room in half an hour]
       b. La pizza arriva in cinque minuti.
           [The pizza will arrive in five minutes]
2) a. Marco ha lavorato per due ore.
           [Marco has worked for two hours]
b. Marco mi prest? il libro per due giorni.
    [Marco lend me his book for two days]
    The influence of the aspect and actionality of the 
VP has an impact also in the identification of their 
meaning. In particular, in example 1) a. the prepo-
sition signals that the event of cleaning the room 
lasted for half an hour, while in the example 1) b. 
the event of arriving takes place after five minutes 
from the utterance time. In example 1), thus, the 
same Temporal PP, i.e. IN + timex,  has two dif-
ferent meanings, signalled by the relations in-
cludes and after. The different temporal rela-
tions are determined by two different semantic pat-
terns: [DURATIVE_Verb] + in + [TIMEX type: 
DURATION] for 1) a, and [TELIC_Verb] + in + 
[TIMEX type: DURATION], for 1) b.
39
3 The corpus study
In order to verify our hypothesis that the most fre-
quent temporal relations represents the prototypical 
meaning of a temporal preposition2, a corpus study 
has been conducted. It is important to note that we 
do not refer to frequency tout court, but is fre-
quency with respect to a certain semantic pattern.     
Since we want to develop a system for automatic 
annotation of temporal relations, a 5 million word
syntactically shallow parsed corpus of contempo-
rary Italian, drawn from the PAROLE corpus, has 
been used3. 
    All occurrences of a prepositional chunk with 
their left contexts has then been automatically ex-
tracted and imported into a database structure us-
ing a dedicated chunkanalyser tool 4 . This auto-
matically generated DB was then augmented with 
ontological information from the SIMPLE Ontol-
ogy, by associating the head noun of each preposi-
tional chunk to its ontological type, and has been 
queried in order to extract all instances of Tempo-
ral PPs, by restricting the nouns headed by preposi-
tions to the type ?TIME?, which is defined in SIM-
PLE as ?all nouns referring to temporal expres-
sions? (SIMPLE Deliverable 2.1: 245). 
    To identify the meaning of temporal preposi-
tions, therefore, we considered sequences of the 
form:
   Fin Vb Chunk + Prep Chunk: semtype= TIME
where Fin Vb Chunk is a shallow syntactic con-
stituent headed by a finite verb and corresponds to 
the ?anchoring? event, and Prep Chunk is the 
prepositional phrase that represents an instance of 
a timex. To get a more complete picture of the dis-
tribution of Temporal PPs in text, we extracted 
sequences from zero up to a maximum of two in-
tervening chunks, obtaining a set of about 14,000 
such sequences.
    A first observation is about the distribution of 
the Temporal PPs. As illustrated in Table 1 (below) 
Temporal PPs tend to occur immediately after the 
event they are linked to.
                                                
2 We assume and extend Haspelmath?s (forth.) proposal on the 
explanatory and predictive power of frequency of use. 
3 The corpus was parsed with the CHUNK-IT shallow parser 
(Lenci et al 2003).
4 By courtesy of Ing. E. Chiavaccini.
Sequence Distance # Occurrences
Fin_Vb  + PP (Time) 0 5859
Fin_Vb + PP (Time) 1 4592
Fin_Vb + PP (Time) 2 3677
Table 1. Occurrences of Temporal PPs with respect 
to the distance from the event.
    The data in Table 1 show that Temporal PPs 
have a behavior similar to modifiers, like adjec-
tives anchoring on the time axis of the event they 
refer to. 
3.1 Annotating Temporal Relations
To identify the semantics of temporal prepositions, 
a subcorpus of 1057 sequences of Fin Vb Chunk + 
Prep Chunks (Time) was manually annotated by 
one investigator with temporal relations in a bot-
tom-up approach. 
     The tags used for the temporal relation annota-
tion were taken from the TimeML TLINK values 
(see Section 2.1). This will restrict the set of possi-
ble relations to a finite set. To ease the task, we 
excluded the inverse relations for includes, 
during, begin, and end. In order to understand 
the role of the co-text, we also marked the types of 
timexes according to the TimeML TIMEX3 tag 
(ibid.). In this annotation experiment we did not 
consider information from the VP because it will 
be relevant to explain the deviations from the pro-
totype.  
. To facilitate the assignment of the right temporal 
relation, we have used paraphrase tests. All the 
paraphrases used have the same scheme, based on 
the formula rel (e, t), illustrated in the 3):
3) The event/state of X is R timex.
where X stands for the event identified by the Fin 
Vb Chunk, R is the set of temporal relations and 
timex is the temporal expression of the Temporal 
PP. This means that the sequence in 4):
4) [[Vfin[Sono stato sposato]  [[ PP[per quatto 
anni]]
?I have been married for four years?
can be paraphrased as 5):
5) The state of ?being married? happened 
during four years.
40
The only temporal relation that is not para-
phrased in this way is simultaneous, which cor-
responds to 6):
6) The event/state X HAPPENS(-ED) AT 
timex.   
4  Results
Among the 1057 sequences in our sub-corpus, we 
found that only 37.46% (for a total of 449 ex-
cerpts) where real of instances of Temporal PPs, 
the others being either false positives or complex 
timexes, i.e. timexes realized by a sequence of a 
NP followed by a PP introduced by ?di? (of), as in 
the following example:
7) [NP[la notte]] [PP[di Natale]
       ?the Christmas night?
     In Table 2 (below) we report the temporal 
prepositions identified in the corpus:     
Temporal Preposition # occurrences
In ?in? 91
A ?at/on? 64
Da ?from/since/for? 37
Dopo ?after? 1
Attraverso ?through? 1
Di ?of? 43
Durante ?during? 5
Entro ?by? 9
Fino a ?up to? 6
Fino da ?since? 3
Oltre ?beyond? 1
Per ?for? 50
Tra ?in? 3
Verso ?towards? 1
Table 2. Instances of temporal prepositions in the 
corpus.
     The relative low number of real Temporal PPs 
can negatively influence the analysis and the iden-
tification of the semantics of the temporal preposi-
tions. In order to verify whether the data collected 
could represent a solid and consistent baseline for 
further analysis, we analysed all instances of false 
positive timexes. With the exception of a few 
cases, which could have been easily recognized by 
means of a Timex Grammar, we found out that 
482/608 instances are represented by nouns which 
have some sort of temporal value but whose as-
signment to the semantic type ?Time? in the On-
tology do not correspond to the given definition 
(Section 3), e.g: colazione ?breakfast?, scuola
?school?, presidenza ?presidency?, and many others. 
    Therefore, we performed a new extraction of 
sequences excluding all instances of false positives. 
The new results are very different since more than 
56.03% of all prepositional chunks are Temporal 
PPs. This provides support to the fact that the se-
quences extracted from the sub-corpus, though 
small in number, can be considered as a consistent 
starting point for identifying the semantics of tem-
poral prepositions. In particular, the prepositions 
presented in Table 2 correspond to the most fre-
quent prepositions which give rise to temporal re-
lations between timexes and events. Though small, 
the 449 sequences prove to be reliable: we have 
identified a total of 320 temporal relations, as illus-
trated in Table 3:
Temporal Relation # occurrences
Includes 87
During 72
Before 11
After 11
Imm_before 1
Imm_after 2
Simultaneous 5
Beginning 52
Ending 10
No Temporal Link 60
No Assigned 9
Table 3. Kinds of Temporal Relation Identified.
5 Inferring Preposition Semantics    
The analysis we propose for each single preposi-
tion provides information on its semantics. Such 
information is obtained on the basis of the fre-
quency5 with which a given temporal relation is 
associated or coded by that preposition. We claim, 
as already stated, that temporal relations coded by 
prepositions are signals of a certain semantic pat-
tern. Different temporal relations coded by the 
same preposition signal different semantic pattern. 
According to the frequency with which a temporal 
relation, or a semantic pattern, occurs, it is consid-
ered either as the prototypical (i.e. most frequent) 
meaning or as a deviation from the norm, whose 
                                                
5 Note that what counts is relative frequencies, and not 
absolute frequencies.
41
explanation relies in the analysis of the semantic 
pattern in which it occurs. It is for this reason that a 
major role in this analysis is played by the types of 
timexes which follow the preposition. Keeping 
track of their types, according to the TimeML clas-
sification (Section 2.1), is very useful mainly for 
cases where the same temporal preposition codes
different temporal relations depending on the type 
of the timex by which it is followed. In other 
words, it is a way to assess the semantic pattern 
which has been used to code that meaning. In the 
following sections we will focus on the semantics 
of the most frequent temporal prepositions, that is 
in ?in?, a ?at, on?, per ?for?6, da ?for, since, from?. 
Cases of low frequency temporal relations are not 
analyzed here because they would require both 
more data and a separate investigation.
5.1 Prepositions per and da
These two prepositions, although they encode dif-
ferent temporal relations, are presented in a unique 
subsection due to their extremely similar coherent 
distribution across temporal relations. In particular, 
the 80% (40/50) of per identifies a DURING tem-
poral relation, and 83.78% (31/37) of da identifies 
a BEGIN temporal relation. 
    From these data, we can represent the semantics 
of per as follows:
8) ?(e,??(t,?URIN G?e,?))
and that of da as:
9) ?(e,??(t,?EGIN ?e,t))
5.2 The Preposition in
The preposition in is by far the most used temporal 
preposition. In our corpus there are 91 occurrences 
of this preposition, distributed as follows:
INCLUDES (57/91: 62.63%)
DURING (19/91: 20.87%)
AFTER  (6/91: 6.59%)
BEGIN (3/91: 3.29%)
SIMULTANEOUS (2/91: 2.19%)
No LINK (2/91: 2.19%)
END (1/91: 1.09%)
                                                
6Note that the Italian preposition ?per? corresponds only 
to a subset of uses of the English preposition ?for? as in 
the example: 
a) Suon? per un?ora [She played for an hour.]
    Following our idea that the most frequent rela-
tion represents the prototypical meaning of the 
preposition; we claim that Temporal PPs intro-
duced by in tend to code a relation of inclusion, 
semantically represented as:
10) ?(e,??(t,?NCLU DES(?,? )).
     Since this preposition is not exclusively used 
with this meaning, the data forces us to provide an 
explanation for the other relations identified, in 
particular for DURING, AFTER and BEGIN. 
     Considering the DURING relation, we analyzed 
the types of timexes governed by the preposition 
but found that type distinctions did not help. Nev-
ertheless, we observed a clearcut regularity analys-
ing the normalized values of the timexes involved: 
we found that, whenever the timexes are definite 
quantified intervals of time (e.g. 2 days, 3 years, 
half an hour) or temporally anchored instants, in 
encodes the temporal relation of DURING, thus 
deviating from the default interpretation repre-
sented in 10). 
    The relation AFTER shares with DURING the 
restriction on the normalized values of the timexes. 
However, for the AFTER relation there is a strong 
contribution from the VP, as claimed in traditional 
grammars. In such cases, it is the actionality of the 
VP that forces the interpretation of in to express 
the AFTER relation. In fact, this relation appears to 
occur only with achievement verbs, which inher-
ently focus on the telos ? or ending point (see ex-
ample 1) b Section 1). 
   Finally, the BEGIN relation can be found only 
with aspectual verbs, e.g. iniziare ?begin? or 
riprendere ?resume?. In these cases the preposition 
does not really work as a temporal preposition, but 
more as a particle selected by the verb. 
5.3 The Preposition a
The preposition a presents a non-trivial distribu-
tion, which makes it difficult to identify a proto-
typical value:
INCLUDES (20/64: 31.25%)
No LINK (19/64: 29.68%)
BEGINS (7/64: 10.93%)
ENDS (4/64: 6.25%)
SIMULTANEOUS (2/64: 3.12%)
42
     However, with NoLINK relations the preposi-
tion a does not have a temporal value, rather it is 
used to express either quantities of time (and it 
usually corresponds to ?how many times an event 
occurs or happens?) or it can be considered as a 
particle selected by the VP. Therefore, if we ex-
clude the NoLINK relations, we can consider that  
a Temporal PP introduced by a typically expresses 
a relation of inclusion. Further support to this ob-
servation can be observed in the possibility of sub-
stituting a with in, at least in the temporal domain. 
The semantics of the preposition is the following:
11) ?(e,??(t,?NCLU DES(e,?) ).
    As for the BEGINS and ENDS relations, the 
behaviour is the same as for the preposition in, i.e. 
they are activated by aspectual verbs. 
6 Conclusion and Future Work
In this preliminary study we showed that preposi-
tions heading a Temporal PP can be associated 
with one default temporal relation and that devia-
tions from the norm are due to co-textual influ-
ences. The prototypical semantics of temporal 
prepositions can be represented as in 8)-11). 
    We also showed that the normalized values of 
timexes play a major role in the identification of 
temporal preposition semantics, more than the bare 
identification of their types. Instances of deviations 
from the prototypical meaning which could not be 
explained by differences in the timexes forced us 
to analyse the VPs, thus providing useful informa-
tion for the definition of the heuristics.
    An important result of this work is the definition 
of a preliminary set of heuristics for automatic an-
notation of temporal relations in text/discourse. 
Our study also suggests a possible refinement of 
the SIMPLE Ontology aimed at its usability for 
temporal relation identification; and it can be seen 
as a starting point for the development of a Timex 
Grammar.
In the next future we intend to implement this 
set of heuristics with a machine learning algorithm 
to evaluate their reliability. All wrongly annotated 
relations could be used for the identification of the 
relevant information to determine the contribution 
of the VP. 
Some issues are still open and need further re-
search, in particular it will be necessary to investi-
gate the role of some ?complex? Temporal PPs 
(e.g. in questo momento ?in this moment?, which 
can be paraphrased as ?now?), and how to extract 
the meaning of Temporal PPs as suggested in 
Schilder (2004).
References
Allen F. James. 1984. Towards a General Theory of 
Action and Time. Artificial Intelligence, (23):123-54
Ferro Lisa, Mani Inderjeet, Sundheim Beth and Wilson 
George. 2001. TIDES Temporal Annotation Guide-
lines: Version 1.0.2. MITRE Technical Report, MTR 
01W0000041 
Filatova, Elena and Hovy, Eduard. 2001. Assigning 
Time-Stamps To Event ?Clauses. Proceedings of the 
ACL Workshop on Temporal and Spatial Information, 
Toulouse, France, 6-1 July, pages 88-95
Haspelmath, Martin. 2007 (forthcoming). Frequency vs. 
iconicity in explaining grammatical asymmetries 
(ms).
Lassen Tine. 2006. An Ontology-Based View on Prepo-
sitional Senses. Proceedings of the Third ACL-
SIGSEM Workshop on Prepositions pages 45-50.
Lenci Alessandro, Montemagni Simonetta and Vito 
Pirrelli. 2003. CHUNK-IT. An Italian Shallow Parser 
for Robust Syntactic Annotation, in Linguistica Com-
putazionale (16-17).
Mani Inderjeet and James Pustejovsky. 2004. Temporal 
Discourse Models for Narrative Structure. ACL 
Workspoh on Discourse Annotation
Hartrumpf Sven, Helbig Hermann and Rainer Osswald. 
2006. Semantic Interpretation of Prepositions for 
NLP Applications. Proceedings of the Third ACL-
SIGSEM Workshop on Prepositions, pages 29-36.
Pustejovky James, Belanger Louis, Casta?o Jos?,  Gai-
zauskas Robert, Hanks Paul, Ingria Bob, Katz Gra-
ham, Radev Dragomir, Rumshisky Anna, Sanfilippo 
Antonio, Sauri Roser, Setzer Andrea, Sundheim Beth 
and Marc Verhagen, 2002. NRRC Summer Workshop 
on Temporal and Event Recognition for QA Systems.
Pustejovsky James, Ingria Robert, Saur? Roser, Casta?o 
Jos?, Littman Jessica, Gaizauskas Robert, Setzer An-
drea, Katz Graham and Inderjeet Mani. 2005. The 
Specification Language TimeML. The Language of 
Time: A Reader, Mani Inderjeet, Pustejovsky james 
and Robert Gaizauskas (eds), OUP. 
43
Ruimy N., et al 1998. The European LE-PAROLE Pro-
ject: The Italian Syntactic Lexicon. Proceedings of 
the LREC1998, Granada, Spain.
Saint-Dizier Patrick.2006. Syntax and Semantics of 
Prepositions, (ed.), Springer, Dordrecht, The Nether-
lands.
Schilder Frank and Habel Christopher. 2001. Semantic 
Tagging Of News Messages. Processing of the ACL 
Workshop on Temporal and Spatial Information, 
Toulouse, France, 6-1 July, pages 65-72
Schilder Frank. 2004 Extracting meaning fron Temporal 
Nouns and Temporal Prepositions. ACM Transac-
tions on Asian Language Information Processing, (3) 
1:33-50
Setzer Andrea. 2001. Temporal Information in News-
wire Article: an Annotation Scheme and Corpus
Study, Ph.D. Thesis, University of Sheffield. 
SIMPLE Work Package D2.1, available at < 
http://www.ub.es/gilcub/SIMPLE/simple.html>.
Van Eynde Frank. 2006. On the prepositions which in-
troduce an adjunct of duration. Proceedings of the 
Third ACL-SIGSEM Workshop on Prepositions pages 
73-80.
44
Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 27?32,
Uppsala, Sweden, 15-16 July 2010.
c
?2010 Association for Computational Linguistics
SemEval-2010 Task 7: Argument Selection and Coercion
James Pustejovsky and Anna Rumshisky and Alex Plotnick
Dept. of Computer Science
Brandeis University
Waltham, MA, USA
Elisabetta Jezek
Dept. of Linguistics
University of Pavia
Pavia, Italy
Olga Batiukova
Dept. of Humanities
Carlos III University of Madrid
Madrid, Spain
Valeria Quochi
ILC-CNR
Pisa, Italy
Abstract
We describe the Argument Selection and
Coercion task for the SemEval-2010 eval-
uation exercise. This task involves char-
acterizing the type of compositional oper-
ation that exists between a predicate and
the arguments it selects. Specifically, the
goal is to identify whether the type that
a verb selects is satisfied directly by the
argument, or whether the argument must
change type to satisfy the verb typing. We
discuss the problem in detail, describe the
data preparation for the task, and analyze
the results of the submissions.
1 Introduction
In recent years, a number of annotation schemes
that encode semantic information have been de-
veloped and used to produce data sets for training
machine learning algorithms. Semantic markup
schemes that have focused on annotating entity
types and, more generally, word senses, have
been extended to include semantic relationships
between sentence elements, such as the seman-
tic role (or label) assigned to the argument by the
predicate (Palmer et al, 2005; Ruppenhofer et al,
2006; Kipper, 2005; Burchardt et al, 2006; Subi-
rats, 2004).
In this task, we take this one step further and
attempt to capture the ?compositional history? of
the argument selection relative to the predicate. In
particular, this task attempts to identify the oper-
ations of type adjustment induced by a predicate
over its arguments when they do not match its se-
lectional properties. The task is defined as fol-
lows: for each argument of a predicate, identify
whether the entity in that argument position satis-
fies the type expected by the predicate. If not, then
identify how the entity in that position satisfies the
typing expected by the predicate; that is, identify
the source and target types in a type-shifting or co-
ercion operation.
Consider the example below, where the verb re-
port normally selects for a human in subject po-
sition, as in (1a). Notice, however, that through
a metonymic interpretation, this constraint can be
violated, as demonstrated in (1b).
(1) a. John reported in late from Washington.
b. Washington reported in late.
Neither the surface annotation of entity extents
and types nor assigning semantic roles associated
with the predicate would reflect in this case a cru-
cial point: namely, that in order for the typing
requirements of the predicate to be satisfied, a
type coercion or a metonymy (Hobbs et al, 1993;
Pustejovsky, 1991; Nunberg, 1979; Egg, 2005)
has taken place.
The SemEval Metonymy task (Markert and Nis-
sim, 2007) was a good attempt to annotate such
metonymic relations over a larger data set. This
task involved two types with their metonymic
variants: categories-for-locations (e.g., place-
for-people) and categories-for-organizations (e.g.,
organization-for-members). One of the limitations
of this approach, however, is that while appropri-
ate for these specialized metonymy relations, the
annotation specification and resulting corpus are
not an informative guide for extending the annota-
tion of argument selection more broadly.
In fact, the metonymy example in (1) is an in-
stance of a much more pervasive phenomenon of
type shifting and coercion in argument selection.
For example, in (2) below, the sense annotation
for the verb enjoy should arguably assign similar
values to both (2a) and (2b).
27
Figure 1: The MATTER Methodology
(2) a. Mary enjoyed drinking her beer.
b. Mary enjoyed her beer.
The consequence of this is that under current sense
and role annotation strategies, the mapping to a
syntactic realization for a given sense is made
more complex, and is in fact perplexing for a clus-
tering or learning algorithm operating over subcat-
egorization types for the verb.
2 Methodology of Annotation
Before introducing the specifics of the argument
selection and coercion task, we will briefly review
our assumptions regarding the role of annotation
in computational linguistic systems.
We assume that the features we use for encoding
a specific linguistic phenomenon are rich enough
to capture the desired behavior. These linguistic
descriptions are typically distilled from extensive
theoretical modeling of the phenomenon. The de-
scriptions in turn form the basis for the annota-
tion values of the specification language, which
are themselves the features used in a development
cycle for training and testing a labeling algorithm
over a text. Finally, based on an analysis and eval-
uation of the performance of a system, the model
of the phenomenon may be revised.
We call this cycle of development the MATTER
methodology (Fig. 1):
Model: Structural descriptions provide theoretically in-
formed attributes derived from empirical observations
over the data;
Annotate: Annotation scheme assumes a feature set that en-
codes specific structural descriptions and properties of
the input data;
Train: Algorithm is trained over a corpus annotated with the
target feature set;
Test: Algorithm is tested against held-out data;
Evaluate: Standardized evaluation of results;
Revise: Revisit the model, annotation specification, or algo-
rithm, in order to make the annotation more robust and
reliable.
Some of the current and completed annotation ef-
forts that have undergone such a development cy-
cle include PropBank (Palmer et al, 2005), Nom-
Bank (Meyers et al, 2004), and TimeBank (Puste-
jovsky et al, 2005).
3 Task Description
The argument selection and coercion (ASC) task
involves identifying the selectional mechanism
used by the predicate over a particular argument.
1
For the purposes of this task, the possible relations
between the predicate and a given argument are re-
stricted to selection and coercion. In selection, the
argument NP satisfies the typing requirements of
the predicate, as in (3):
(3) a. The spokesman denied the statement (PROPOSI-
TION).
b. The child threw the stone (PHYSICAL OBJECT).
c. The audience didn?t believe the rumor (PROPOSI-
TION).
Coercion occurs when a type-shifting operation
must be performed on the complement NP in order
to satisfy selectional requirements of the predicate,
as in (4). Note that coercion operations may apply
to any argument position in a sentence, including
the subject, as seen in (4b). Coercion can also be
seen as an object of a proposition, as in (4c).
(4) a. The president denied the attack (EVENT? PROPO-
SITION).
b. The White House (LOCATION ? HUMAN) denied
this statement.
c. The Boston office called with an update (EVENT?
INFO).
In order to determine whether type-shifting has
taken place, the classification task must then in-
volve (1) identifying the verb sense and the asso-
ciated syntactic frame, (2) identifying selectional
requirements imposed by that verb sense on the
target argument, and (3) identifying the semantic
type of the target argument.
4 Resources and Corpus Development
We prepared the data for this task in two phases:
the data set construction phase and the annotation
phase (see Fig. 2). The first phase consisted of
(1) selecting the target verbs to be annotated and
compiling a sense inventory for each target, and
(2) data extraction and preprocessing. The pre-
pared data was then loaded into the annotation in-
terface. During the annotation phase, the annota-
tion judgments were entered into the database, and
an adjudicator resolved disagreements. The result-
ing database was then exported in an XML format.
1
This task is part of a larger effort to annotate text with
compositional operations (Pustejovsky et al, 2009).
28
Figure 2: Corpus Development Architecture
4.1 Data Set Construction Phase: English
For the English data set, the data construction
phase was combined with the annotation phase.
The data for the task was created using the fol-
lowing steps:
1. The verbs were selected by examining the data
from the BNC, using the Sketch Engine (Kilgar-
riff et al, 2004) as described in (Rumshisky and
Batiukova, 2008). Verbs that consistently im-
pose semantic typing on one of their arguments
in at least one of their senses (strongly coercive
verbs) were included into the final data set: ar-
rive (at), cancel, deny, finish, and hear.
2. Sense inventories were compiled for each verb,
with the senses mapped to OntoNotes (Pradhan
et al, 2007) whenever possible. For each sense,
a set of type templates was compiled using a
modification of the CPA technique (Hanks and
Pustejovsky, 2005; Pustejovsky et al, 2004):
every argument in the syntactic pattern asso-
ciated with a given sense was assigned a type
specification. Although a particular sense is
often compatible with more than one semantic
type for a given argument, this was never the
case in our data set, where no disjoint types
were tested. The coercive senses of the chosen
verbs were associated with the following type
templates:
a. Arrive (at), sense reach a destination or goal : HU-
MAN arrive at LOCATION
b. Cancel, sense call off : HUMAN cancel EVENT
c. Deny, sense state or maintain that something is un-
true: HUMAN deny PROPOSITION
d. Finish, sense complete an activity: HUMAN finish
EVENT
e. Hear, sense perceive physical sound : HUMAN hear
SOUND
We used a subset of semantic types from the
Brandeis Shallow Ontology (BSO), which is a
shallow hierarchy of types developed as a part
of the CPA effort (Hanks, 2009; Pustejovsky
et al, 2004; Rumshisky et al, 2006). Types
were selected for their prevalence in manually
identified selection context patterns developed
for several hundred English verbs. That is,
they capture common semantic distinctions as-
sociated with the selectional properties of many
verbs. The types used for annotation were:
ABSTRACT ENTITY, ANIMATE, ARTIFACT, ATTITUDE,
DOCUMENT,DRINK,EMOTION,ENTITY,EVENT, FOOD,
HUMAN,HUMAN GROUP, IDEA, INFORMATION, LOCA-
TION,OBLIGATION,ORGANIZATION, PATH, PHYSICAL
OBJECT, PROPERTY, PROPOSITION,RULE, SENSATION,
SOUND, SUBSTANCE, TIME PERIOD, VEHICLE
This set of types is purposefully shallow and
non-hierarchical. For example, HUMAN is a
subtype of both ANIMATE and PHYSICAL OB-
JECT, but annotators and system developers
were instructed to choose the most relevant type
(e.g., HUMAN) and to ignore inheritance.
3. A set of sentences was randomly extracted for
each target verb from the BNC (Burnard, 1995).
The extracted sentences were parsed automati-
cally, and the sentences organized according to
the grammatical relation the target verb was in-
volved in. Sentences were excluded from the set
if the target argument was expressed as anaphor,
or was not present in the sentence. The seman-
tic head for the target grammatical relation was
identified in each case.
4. Word sense disambiguation of the target predi-
cate was performed manually on each extracted
sentence, matching the target against the sense
inventory and the corresponding type templates
as described above. The appropriate senses
were then saved into the database along with the
associated type template.
5. The sentences containing coercive senses of the
target verbs were loaded into the Brandeis An-
notation Tool (Verhagen, 2010). Annotators
were presented with a list of sentences and
asked to determine whether the argument in
the specified grammatical relation to the target
belongs to the type associated with that sense
in the corresponding template. Disagreements
were resolved by adjudication.
29
Coerion Type Verb Train Test
EVENT?LOCATION arrive at 38 37
ARTIFACT?EVENT cancel 35 35
finish 91 92
EVENT?PROPOSITION deny 56 54
ARTIFACT?SOUND hear 28 30
EVENT?SOUND hear 24 26
DOCUMENT?EVENT finish 39 40
Table 1: Coercions in the English data set
6. To guarantee robustness of the data, two addi-
tional steps were taken. First, only the six most
recurrent coercion types were selected; these
are given in table 1. Preference was given to
cross-domain coercions, where the source and
the target types are not related ontologically.
Second, the distribution of selection and co-
ercion instances were skewed to increase the
number of coercions. The final English data set
contains about 30% coercions.
7. Finally, the data set was randomly split in half
into a training set and a test set. The training
data has 1032 instances, 311 of which are co-
ercions, and the test data has 1039 instances,
314 of which are coercions.
4.2 Data Set Construction Phase: Italian
In constructing the Italian data set, we adopted the
same methodology used for the English data set,
with the following differences:
1. The list of coercive verbs was selected by exam-
ining data from the ItWaC (Baroni and Kilgar-
riff, 2006) using the Sketch Engine (Kilgarriff
et al, 2004):
accusare ?accuse?, annunciare ?announce?, arrivare ?ar-
rive?, ascoltare ?listen?, avvisare ?inform?, chiamare
?call?, cominciare ?begin?, completare ?complete?, con-
cludere ?conclude?, contattare ?contact?, divorare ?de-
vour?, echeggiare ?echo?, finire ?finish?, informare ?in-
form?, interrompere ?interrupt?, leggere ?read?, raggiun-
gere ?reach?, recar(si) ?go to?, rimbombare ?resound?,
sentire ?hear?, udire ?hear?, visitare ?visit?.
2. The coercive senses of the chosen verbs were
associated with type templates, some of which
are listed listed below. Whenever possible,
senses and type templates were adapted from
the Italian Pattern Dictionary (Hanks and Jezek,
2007) and mapped to their SIMPLE equiva-
lents (Lenci et al, 2000).
a. arrivare, sense reach a location: HUMAN arriva
[prep] LOCATION
b. cominciare, sense initiate an undertaking: HUMAN
comincia EVENT
c. completare, sense finish an activity: HUMAN com-
pleta EVENT
d. udire, sense perceive a sound : HUMAN ode SOUND
e. visitare, sense visit a place: HUMAN visita LOCA-
TION
The following types were used to annotate
the Italian dataset:
ABSTRACT ENTITY, ANIMATE, ARTIFACT, ATTITUDE,
CONTAINER, DOCUMENT, DRINK, EMOTION, ENTITY,
EVENT, FOOD, HUMAN, HUMAN GROUP, IDEA, IN-
FORMATION, LIQUID, LOCATION, ORGANIZATION,
PHYSICAL OBJECT, PROPERTY, SENSATION, SOUND,
TIME PERIOD, VEHICLE
The annotators were provided with a set of def-
initions and examples of each type.
3. A set of sentences for each target verb was ex-
tracted and parsed from the PAROLE sottoin-
sieme corpus (Bindi et al, 2000). They were
skimmed to ensure that the final data set con-
tained a sufficient number of coercions, with
proportionally more selections than coercions.
Sentences were preselected to include instances
representing one of the chosen senses.
4. In order to exclude instances that may have been
wrongly selected, a judge performed word sense
disambiguation of the target predicate in the ex-
tracted sentences.
5. Annotators were presented with a list of sen-
tences and asked to determine the usual seman-
tic type associated with the argument in the
specified grammatical relation. Every sentence
was annotated by two annotators and one judge,
who resolved disagreements.
6. Some of the coercion types selected for Italian
were:
a. LOCATION? HUMAN (accusare, annunciare)
b. ARTIFACT? HUMAN (annunciare, avvisare)
c. EVENT? LOCATION (arrivare, raggiungere)
d. ARTIFACT? EVENT (cominciare, completare)
e. EVENT? DOCUMENT (leggere, divorare)
f. HUMAN? DOCUMENT (leggere, divorare)
g. EVENT? SOUND (ascoltare, echeggiare)
h. ARTIFACT? SOUND (ascoltare, echeggiare)
7. The Italian training data contained 1466 in-
stances, 381 of which are coercions; the test
data had 1463 instances, with 384 coercions.
5 Data Format
The test and training data were provided in XML.
The relation between the predicate (viewed as
a function) and its argument were represented
by composition link elements (CompLink), as
30
shown below. The test data differed from the train-
ing data in the omission of CompLink elements.
In case of coercion, there is a mismatch between
the source and the target types, and both types
need to be identified; e.g., The State Department
repeatedly denied the attack:
The State Department repeatedly
<SELECTOR sid="s1">denied</SELECTOR>
the <TARGET id="t1">attack</TARGET>.
<CompLink cid="cid1"
compType="COERCION"
selector_id="s1"
relatedToTarget="t1"
sourceType="EVENT"
targetType="PROPOSITION"/>
When the compositional operation is selection,
the source and target types must match; e.g., The
State Department repeatedly denied the statement:
The State Department repeatedly
<SELECTOR sid="s2">denied</SELECTOR>
the <TARGET id="t2">statement</TARGET>.
<CompLink cid="cid2"
compType="SELECTION"
selector_id="s2"
relatedToTarget="t2"
sourceType="PROPOSITION"
targetType="PROPOSITION"/>
6 Results & Analysis
We received only a single submission for the
ASC task. The UTDMet system was an SVM-
based system with features derived from two main
sources: a PageRank-style algorithm over Word-
Net hypernyms used to define semantic classes,
and statistics from a PropBank-style parse of some
8 million documents from the English Gigaword
corpus. The results, shown in Table 2, were
computed from confusion matrices constructed for
each of four classification tasks for the 1039 link
instances in the English test data: determination
of argument selection or coercion, identification of
the argument source type, identification of the ar-
gument target type, and the joint identification of
the source/target type pair.
Clearly, the UTDMet system did quite well at
this task. The one immediately noticeable outlier
is the macro-averaged precision for the joint type,
which reflects a small number of miscategoriza-
tions of rare types. For example, eliminating the
single miscategorized ARTIFACT-LOCATION link
in the submitted test data bumps this score up to
a respectable 94%. This large discrepancy can ex-
plained by the lack of any coercions with those
types in the gold-standard data.
Prec. Recall Averaging
Selection vs. 95 96 (macro)
Coercion: 96 96 (micro)
Source Type: 96 96 (macro)
96 96 (micro)
Target Type: 100 100 (both)
Joint Type: 86 95 (macro)
96 96 (micro)
Table 2: Results for the UTDMet submission.
In the absence of any other submissions, it is
difficult to provide a point of comparison for this
performance. However, we can provide a base-
line by taking each link to be a selection whose
source and target types are the most common type
(EVENT for the gold-standard English data). This
yields micro-averaged precision scores of 69% for
selection vs. coercion, 33% for source type iden-
tification, 37% for the target type identification,
and 22% for the joint type.
The performance of the UTDMet system sug-
gests that most of the type coercions were identifi-
able based largely on examination of lexical clues
associated with selection contexts. This is in fact
to be expected for the type coercions that were the
focus of the English data set. It will be interesting
to see how systems perform on the Italian data set
and an expanded corpus for English and Italian,
where more subtle and complex type exploitations
and manipulations are at play. These will hope-
fully be explored in future competitions.
7 Conclusion
In this paper, we have described the Argument Se-
lection and Coercion task for SemEval-2010. This
task involves identifying the relation between a
predicate and its argument as one that encodes
the compositional history of the selection process.
This allows us to distinguish surface forms that di-
rectly satisfy the selectional (type) requirements of
a predicate from those that are coerced in context.
We described some details of a specification lan-
guage for selection, the annotation task using this
specification to identify argument selection behav-
ior, and the preparation of the data for the task.
Finally, we analyzed the results of the task sub-
missions.
31
References
M. Baroni and A. Kilgarriff. 2006. Large
linguistically-processed web corpora for multiple
languages. In Proceedings of European ACL.
R. Bindi, P. Baroni, M. Monachini, and E. Gola. 2000.
PAROLE-Sottoinsieme. ILC-CNR Internal Report.
Aljoscha Burchardt, Katrin Erk, Anette Frank, An-
drea Kowalski, Sebastian Pado, and Manfred Pinkal.
2006. The salsa corpus: a german corpus resource
for lexical semantics. In Proceedings of LREC,
Genoa, Italy.
L. Burnard, 1995. Users? Reference Guide, British Na-
tional Corpus. British National Corpus Consortium,
Oxford, England.
Marcus Egg. 2005. Flexible semantics for reinterpre-
tation phenomena. CSLI, Stanford.
P. Hanks and E. Jezek. 2007. Building Pattern Dictio-
naries with Corpus Analysis. In International Col-
loquium on Possible Dictionaries, Rome, June, 6-7.
Oral Presentation.
P. Hanks and J. Pustejovsky. 2005. A pattern dic-
tionary for natural language processing. Revue
Franc?aise de Linguistique Appliqu?ee.
P. Hanks. 2009. Corpus pattern analysis. CPA
Project Page. Retrieved April 11, 2009, from
http://nlp.fi.muni.cz/projekty/cpa/.
J. R. Hobbs, M. Stickel, and P. Martin. 1993. Interpre-
tation as abduction. Artificial Intelligence, 63:69?
142.
A. Kilgarriff, P. Rychly, P. Smrz, and D. Tugwell.
2004. The Sketch Engine. Proceedings of Euralex,
Lorient, France, pages 105?116.
Karin Kipper. 2005. VerbNet: A broad-coverage, com-
prehensive verb lexicon. Phd dissertation, Univer-
sity of Pennsylvania, PA.
A. Lenci, N. Bel, F. Busa, N. Calzolari, E. Gola,
M. Monachini, A. Ogonowski, I. Peters, W. Peters,
N. Ruimy, et al 2000. SIMPLE: A general frame-
work for the development of multilingual lexicons.
International Journal of Lexicography, 13(4):249.
K. Markert and M. Nissim. 2007. SemEval-2007
task 8: Metonymy resolution. In Eneko Agirre,
Llu??s M`arquez, and Richard Wicentowski, editors,
Proceedings of the Fourth International Workshop
on Semantic Evaluations (SemEval-2007), Prague,
Czech Republic, June. Association for Computa-
tional Linguistics.
A. Meyers, R. Reeves, C. Macleod, R. Szekely,
V. Zielinska, B. Young, and R. Grishman. 2004.
The NomBank project: An interim report. In HLT-
NAACL 2004 Workshop: Frontiers in Corpus Anno-
tation, pages 24?31.
Geoffrey Nunberg. 1979. The non-uniqueness of se-
mantic solutions: Polysemy. Linguistics and Phi-
losophy, 3:143?184.
M. Palmer, D. Gildea, and P. Kingsbury. 2005. The
proposition bank: An annotated corpus of semantic
roles. Computational Linguistics, 31(1):71?106.
S. Pradhan, E. Hovy, MS Marcus, M. Palmer,
L. Ramshaw, and R. Weischedel. 2007. Ontonotes:
A unified relational semantic representation. In
International Conference on Semantic Computing,
2007, pages 517?526.
J. Pustejovsky, P. Hanks, and A. Rumshisky. 2004.
Automated Induction of Sense in Context. In COL-
ING 2004, Geneva, Switzerland, pages 924?931.
J. Pustejovsky, R. Knippen, J. Littman, and R. Sauri.
2005. Temporal and event information in natural
language text. Language Resources and Evaluation,
39(2):123?164.
J. Pustejovsky, A. Rumshisky, J. Moszkowicz, and
O. Batiukova. 2009. GLML: Annotating argument
selection and coercion. IWCS-8: Eighth Interna-
tional Conference on Computational Semantics.
J. Pustejovsky. 1991. The generative lexicon. Compu-
tational Linguistics, 17(4).
A. Rumshisky and O. Batiukova. 2008. Polysemy
in verbs: systematic relations between senses and
their effect on annotation. In COLING Workshop
on Human Judgement in Computational Linguistics
(HJCL-2008), Manchester, England.
A. Rumshisky, P. Hanks, C. Havasi, and J. Pustejovsky.
2006. Constructing a corpus-based ontology using
model bias. In The 19th International FLAIRS Con-
ference, FLAIRS 2006, Melbourne Beach, Florida,
USA.
J. Ruppenhofer, M. Ellsworth, M. Petruck, C. Johnson,
and J. Scheffczyk. 2006. FrameNet II: Extended
Theory and Practice.
Carlos Subirats. 2004. FrameNet Espa?nol. Una red
sem?antica de marcos conceptuales. In VI Interna-
tional Congress of Hispanic Linguistics, Leipzig.
Marc Verhagen. 2010. The Brandeis Annotation Tool.
In Language Resources and Evaluation Conference,
LREC 2010, Malta.
32
