Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 745?751,
Baltimore, Maryland, USA, June 23-25 2014.
c?2014 Association for Computational Linguistics
Measuring metaphoricity
Jonathan Dunn
Department of Computer Science / Illinois Institute of Technology
jonathan.edwin.dunn@gmail.com
Abstract
This paper presents the first
computationally-derived scalar mea-
surement of metaphoricity. Each input
sentence is given a value between 0
and 1 which represents how metaphoric
that sentence is. This measure achieves
a correlation of 0.450 (Pearson?s R, p
<0.01) with an experimental measure of
metaphoricity involving human partici-
pants. While far from perfect, this scalar
measure of metaphoricity allows different
thresholds for metaphoricity so that
metaphor identification can be fitted for
specific tasks and datasets. When reduced
to a binary classification evaluation using
the VU Amsterdam Metaphor Corpus,
the system achieves an F-Measure of
0.608, slightly lower than the comparable
binary classification system?s 0.638 and
competitive with existing approaches.
1 Introduction
Metaphor is a cognitive phenomenon (Lakoff &
Johnson, 1980, 1999) which has a significant im-
pact on human reasoning abilities (Casasanto &
Jasmin, 2012; Johansson Falk & Gibbs, 2012)
and which, as a result, commonly appears in lan-
guage in the form of metaphoric expressions (e.g.,
Deignan, 2005). The most comprehensive non-
computational study of metaphoric expressions in
large corpora (Steen, et al, 2010) found that up
to 18.5% of words in the British National Cor-
pus were used metaphorically. This means that
metaphorically used words not only have very dif-
ferent interpretations than literally used words, but
they are also common enough to pose a significant
challenge for computational linguistics.
Starting with Wilks (1978), the problem of
metaphor has been approached as an identifica-
tion task: first identify or detect metaphoric ex-
pressions and then (1) prevent them from inter-
fering with computational treatments of literal ex-
pressions and (2) use them to gain additional in-
sight about a text (e.g., Carbonell, 1980; Neuman
& Nave, 2009). The identification or detection
task has been approached as a binary classification
problem: for a given unit of language (e.g., word,
phrase, sentence) decide whether it is metaphoric
or non-metaphoric. Wilks (1978) used selectional
restrictions for this purpose; Mason (2004) used
hand-crafted knowledge resources to detect sim-
ilar selectional mismatches; another approach is
to detect selectional mismatches using statistically
created resources (e.g., Shutova, et al 2013;
Shutova & Sun, 2013). A second general approach
to the binary classification problem has been to use
mismatches in properties like abstractness (Gandy,
et al, 2013; Assaf, et al, 2013; Tsvetkov, et al,
2013; Turney, et al, 2011), semantic similarity
(Li & Sporleder, 2010; Sporleder & Li, 2010),
and domain membership (Dunn, 2013a, 2013b) to
identify metaphoric units of language. A third ap-
proach has been to use forms of topic modelling
to identify linguistic units which represent both a
metaphoric topic and a literal topic (Strzalkowski,
2013; Bracewell, et al 2013; Mohler, et al, 2013).
The single constant across all of these ap-
proaches is that the task is viewed as a binary clas-
sification problem of distinguishing metaphoric
language from non-metaphoric language. This
binary distinction assumes a clear boundary be-
tween the two; in other words, it assumes that
metaphoricity is a discrete property. However,
three strands of theoretical research show that
metaphoricity is not a discrete property. First,
psycholinguistic studies of metaphor processing
show that there is no difference between the pro-
cessing of metaphoric and non-metaphoric lan-
guage (Coulson & Matlock, 2001; Gibbs, 2002;
Evans, 2010). The most plausible interpretation
745
of this psycholinguistic evidence is that most lin-
guistic units fall somewhere between metaphoric
and literal, so that metaphoricity is a scalar value
which influences processing gradually (and is dif-
ficult to uncover because of related factors like
salience; Giora, 2002). Second, linguistic stud-
ies of metaphor have found that the metaphoric-
ity of a linguistic unit can be predicted given
certain factors (Dunn, 2011, 2013c). Third, the
high frequency of metaphorically used language
implies that it is hard to set a boundary beyond
which a word is used metaphorically. In other
words, it seems clear that 18.5% of the BNC is not
highly metaphoric, but rather is the sort of slightly
metaphoric language that speakers are not con-
sciously aware of because it is used so frequently.
This paper introduces a system for produc-
ing a scalar measurement of metaphoricity which
places sentences anywhere between 0 (literal) and
1 (highly metaphoric). The goal is to produce a
computationally derived measurement that mod-
els the gradient nature of metaphoricity, with the
result that metaphors which are clearly and con-
sciously seen as metaphors score closer to 1 and
metaphors which are not realized by speakers to
be metaphoric score further from 1. This scalar
measurement approach has two advantages: (1) it
adheres more closely to the current theoretical un-
derstanding of metaphor, thus being more cogni-
tively accurate; (2) it allows applications to control
the threshold of metaphoricity when identifying
metaphor, thus allowing the treatment of metaphor
to be optimized for a given task.
2 Measuring Gradient Metaphoricity
An experiment was conducted to set a standard for
evaluating scalar measurements of metaphoricity.
A corpus of 60 sentences of varying metaphoric-
ity, drawn equally from four top-level domains
(PHYSICAL, MENTAL, SOCIAL, and ABSTRACT),
was created using the Corpus of Contemporary
American English. Each domain was represented
by five verbs and each verb by three sentences:
one literal, one slightly metaphoric, and one very
metaphoric (as judged by the author).
The selection of various domains, verbs, and
hypothesized metaphoricity levels helps to control
for other factors, like abstractness, which might be
only indirectly related to metaphoricity. It also en-
sures that the experiment covers a wide-range of
metaphors. It should be noted that the purpose
of the experiment is not to (1) test a three-way
distinction between metaphoricity levels (which is
simply used to ensure a representative selection
of metaphors) or (2) test the author?s intuitions
of metaphoricity. Rather, the purpose is to have
a representative selection of metaphors rated for
metaphoricity against which to test scalar mea-
surements of metaphoricity.
Three survey tasks were used. The first
tested speakers? ability to consistently separate
metaphoric and non-metaphoric sentences. Partic-
ipants were given a sentence and asked to iden-
tify it as ?Literal? or ?Metaphoric.? The second
task tested speakers? ability to consistently label
a given sentence as ?Not Metaphoric?, ?Slightly
Metaphoric?, and ?Very Metaphoric.? The addi-
tional label was added in order to provide partic-
ipants with a middle ground between metaphoric
and literal. The third task tested speakers? ability
to consistently rank three sentences according to
their metaphoricity. In order to ensure comparabil-
ity, each set of three sentences contained a literal, a
slightly metaphoric, and a very metaphoric use of
a single verb (e.g., three uses of ?butcher?). The
purpose of this task was to allow participants to
directly compare different uses of the same verb.
The surveys were conducted using the Mechan-
icalTurk platform. Each participant took a particu-
lar survey only once and the sentences to be rated
were drawn randomly from the corpus. Partici-
pants were given eight questions for the identifica-
tion and labeling tasks and four questions for the
ranking task. This was done in order to keep the
survey short and prevent participants from losing
interest. All participants were asked if they had at-
tended a primary or elementary school conducted
in English in order to ensure consistent language
ability. Further, a test question was positioned part
way through the survey to ensure that participants
read the prompts correctly. Only answers valid ac-
cording to these two tests are considered in the fol-
lowing results. Each task had 100 unique partici-
pants who gave valid answers, for a total of 300
participants. Participants did not see any domain
information for the sentence prompts.
For the first task, the binary identification task,
the metaphoricity of a sentence was computed by
taking the percentage of participants who iden-
tified it as metaphoric. Thus, if all participants
agreed that a sentence was metaphoric, then it re-
ceives a 1, while if half of the participants agreed,
746
then it receives a 0.5. The idea here is that high
metaphoricity is consciously available to partici-
pants, so that the more agreement there is about
metaphor the more the participants are aware of
the sentence?s metaphoricity and thus the higher
its metaphoricity value should be. The results of
this first experiment are summarized in Table 1
with the mean, standard deviation, and range of
the metaphoricity measurements. The results are
strong on the low end of the scale, with every
domain having sentences with either 0 values or
close to 0 values. The high end is more problem-
atic, with the highest values in each domain be-
ing below 0.9. This is a result of not having per-
fect agreement across all participants. However,
in spite of this, the measure makes a good distinc-
tion between utterances. For example, it assigns
the metaphoricity value of 0.833 to the sentence
in (1), but a metaphoricity value of only 0.153 to
the sentence in (2). This reflects a distinction in
metaphoricity, although the extreme top and bot-
tom of the scale are problematic.
(1) ?A lady on high heels clacked along, the type
my mother says invests all of her brainpower in her
looks.?
(2) ?The banks and the corporations in America
today have lots of money that they can invest right
now.?
Domain Mean Std. Dev. Range
Abstract 0.373 0.282 0.065?0.833
Mental 0.289 0.278 0.000?0.888
Physical 0.417 0.331 0.000?0.846
Social 0.389 0.351 0.000?0.812
All 0.367 0.316 0.000?0.888
Table 1: Metaphoricity by identification.
The second experiment asks participants to
label metaphoricity, this time including a dis-
tinction between slightly metaphoric and highly
metaphoric sentences. The purpose of this is not
to test a three-way distinction in metaphoricity
values, but rather to improve the scale by mov-
ing intermediate sentences out of the Literal or
Metaphoric categories. The metaphoricity values
for this experiment were calculated in the same
way: the percentage of participants who rated a
sentence as highly metaphoric. Thus, this mea-
surement also is based on the idea that more
participants will be consciously aware of highly
metaphoric sentences, with a third category avail-
able to allow an extra distinction to be made. This
measurement, summarized in Table 2, is more ac-
curate at the lower end of the scale, with many
sentences receiving a 0 because participants were
able to choose a category other than metaphoric.
At the same time, the values tend to be further
from 1 at the upper end of the scale. The sentence
in (2) above, for example, received a 0; however,
the sentence in (1) above received only a 0.571,
which, while high given the range of values, is still
far from 1. Thus, while the measurement makes
distinctions at the top of the scale, it does not ap-
proach 1.
Domain Mean Std. Dev. Range
Abstract 0.170 0.165 0.000?0.571
Mental 0.096 0.119 0.000?0.455
Physical 0.220 0.248 0.000?0.778
Social 0.258 0.281 0.000?0.769
All 0.186 0.222 0.000?0.778
Table 2: Metaphoricity by labelling.
The third task gathered ordering information by
presenting participants with three sentences, all of
which contained the same main verb. The par-
ticipants were asked to order the sentences from
the least metaphoric to the most metaphoric. The
purpose of this experiment was to give partici-
pants context in the form of other uses of a given
verb against which to make their judgments. The
metaphoricity value was computed by taking the
percentage of participants who identified a sen-
tence as the most metaphoric of the three given
sentences. This measurement, shown in Table 3,
has similar averages across domains, unlike the
previous measurements. It tends to be better than
the previous measures on the upper bound, likely
because of the contextual comparison it allows.
However, because sentences with the same main
verb were forced into a three-way ordering, par-
ticipants could not, for example, label two of the
sentences as equally metaphoric. Thus, it is possi-
ble that some of this advantage on the upper bound
is a result of the task itself.
Given these three experiments for measuring
the metaphoricity of sentences, Table 4 shows the
correlations between each measure using Pear-
son?s R. Each correlation is significant at the 0.01
level (2-tailed). The highest correlation is between
the first and second tasks, at 0.819. The lowest
is between the first and third (which differ in the
747
Domain Mean Std. Dev. Range
Abstract 0.333 0.211 0.056?0.773
Mental 0.331 0.175 0.071?0.632
Physical 0.331 0.235 0.050?0.941
Social 0.327 0.280 0.050?0.783
All 0.331 0.227 0.050?0.941
Table 3: Metaphoricity by ordering.
number of distinctions allowed) at 0.699. How-
ever, this is still a high correlation.
Task Identify Label Order
Identify ? 0.819 0.699
Label 0.819 ? 0.702
Order 0.699 0.702 ?
Table 4: Correlation between measurements.
This section has put forward a robust series of
scalar measurements of metaphoricity. Each ex-
periment had 100 participants and operationalized
the task of rating metaphoricity in different ways
across a representative section of domains, verbs,
and metaphoricity levels. The resulting highly cor-
related measures show that we have a good stan-
dard of metaphoricity against which to evaluate
computational models which produce scalar mea-
surements of metaphoricity. The next section in-
troduces such a system.
3 Description of the System
We approach the problem by starting with an exist-
ing binary identification system and converting it
to a scalar system. In principle any of the property-
based systems listed above could be converted in
this way. We have chosen to start with the do-
main interaction system (Dunn, 2013a, 2013b),
which performed competitively in an evaluation
with other systems (Dunn, 2013b). The original
system uses the properties of domain-membership
and event-status of concepts to identify metaphors
at the sentence-level using a logistic regression
classifier. The scalar version of the system will
have to evaluate the features in a different way.
The first step is to increase the robustness of the
system?s representation of sentences by adding ad-
ditional properties. We split the original system?s
domain membership feature into two: the domain
of a word?s referent and the domain of a word?s
sense. The idea is to capture cases like MINISTER,
in which a physical object (a human) is defined by
its social role (being a minister). The event-status
property is unchanged.
Several additional properties are added; these
properties were not used in the original system.
First, animacy-status allows a distinction to be
made between inanimate objects like rocks and
stones and animate or human objects. Second,
the fact-status property allows a distinction to be
made between objects which exist as such in-
dependently of humans (e.g., rocks and stones)
and those which exist to some degree dependent
on human consciousness (e.g., laws and ideas).
Third, the function-status property allows a dis-
tinction to be made between objects which en-
code a function (e.g., a screwdriver is specifically
an object meant to turn screws) and those which
do not encode a function (e.g., rocks are simply
objects). A finer distinction within the function-
status property distinguishes social functions (e.g.,
laws) from physical-use functions (e.g., screw-
drivers).
Following the original system, these properties
are taken from a knowledge-base and used to cre-
ate feature vectors. The text is first processed us-
ing Apache OpenNLP for tokenization, named en-
tity recognition, and part of speech tagging. Mor-
pha (Minnen, et al, 2001) is used for lemmati-
zation. At this point word sense disambiguation
is performed using SenseRelate (Pedersen & Kol-
hatkar, 2009), mapping the lexical words to the
corresponding WordNet senses. These WordNet
senses are first mapped to SynSets and then to con-
cepts in the SUMO ontology, using existing map-
pings (Niles & Pease, 2001, 2003).
Thus, each sentence is represented by the SUMO
concepts which it contains and each concept is
represented by its six concept properties. The fea-
tures used are computed as follows: First, the rela-
tive frequency of each value of each concept prop-
erty in the sentence is determined; Second, the
number of instances of the most common value for
each property is determined, as well as the number
of instances of all other values (both relativized to
the number of concepts present in the sentence).
Third, the number of types of values for each con-
cept property is determined, relative to the number
of possible types. This gives a total of 41 features
for each sentence.
These features were computed for each of
the sentences used in the experiments and then
748
the correlation between the features and the
metaphoricity measurements were computed us-
ing Pearson?s R. Those features which had a sig-
nificant positive relationship with the experimen-
tal results, shown in Table 5, were added to-
gether to create a rough computational measure of
metaphoricity and then converted so that they fall
between 0 and 1. The resulting computationally-
derived measure correlates significantly with each
of the experiments: 0.450, 0.416, and 0.337.
Properties Values
Domain of the Referent Mental
Domain of the Referent Other / Concepts
Event-Status State
Animacy-Status Undetermined
Animacy-Status Other / Concepts
Fact-Status Physical
Function-Status None
Domain of the Referent Types / Possible
Event-Status Types / Possible
Animacy-Status Types / Possible
Function-Status (negative) Types / Possible
Table 5: Predictive features.
4 Evaluation
A scalar measurement of metaphoricity allows
the threshold for metaphor in metaphor identifi-
cation tasks to be fitted for specific purposes and
datasets. The scalar system was evaluated on the
VU Amsterdam Metaphor Corpus (Steen, et al,
2010) which consists of 200,000 words from the
British National Corpus divided into four gen-
res (academic, news, fiction, and spoken; per-
formance on the spoken genre was not evaluated
for this task because it consists of many short
fragmentary utterances) and manually annotated
for metaphor by five raters. Previous evaluations
using this corpus (Dunn, 2013b) concluded that
prepositions annotated as metaphoric in the cor-
pus should not be considered metaphoric for com-
putational purposes. Thus, metaphorically used
prepositions have been untagged as metaphoric.
Further, we have also untagged the ambiguously
metaphoric sentences. Sentences with an insuffi-
ciently robust conceptual representation were re-
moved (e.g., fragments). The evaluation dataset
thus consists of 6,893 sentences, distributed as
shown in Table 6.
For the purposes of this evaluation, the thresh-
Subset Literal Metaphor Total
Academic 759 1,550 2,309
Fiction 1,215 1,389 2,604
News 366 1,614 1,980
Total 2,340 4,553 6,893
Table 6: Size of evaluation dataset in sentences.
old for metaphor was set independently for each
genre and tied to the number of sentences con-
taining metaphorically used words, as rated by
the annotators of the corpus. Thus, for the num-
ber x of metaphors in the genre, the x sentences
with the top metaphoricity values were identified
as metaphoric. This illustrates the flexibility of
such a scalar approach to metaphor identification.
The baseline results are taken from a binary classi-
fication evaluation of the corpus using the full set
of 41 features produced by the system and eval-
uated using the logistic regression algorithm with
100-fold cross-validation.
System Subset Prec. Recall F-Meas.
Scalar Acad. 0.578 0.686 0.578
Binary Acad. 0.649 0.682 0.623
Scalar News 0.712 0.822 0.712
Binary News 0.750 0.812 0.748
Scalar Fict. 0.554 0.582 0.554
Binary Fict. 0.632 0.633 0.630
Scalar All 0.608 0.703 0.608
Binary All 0.663 0.685 0.638
Table 7: Evaluation results.
The binary classification system, with access to
the full range of features, out-performs the scalar
measurement in most cases. It is important to note,
however, that the binary classification system re-
quires labelled training data and is restricted to a
single threshold of metaphoricity, in this case the
threshold embedded in the corpus by the raters.
The scalar system, however, was trained only on
the experimental data and was not influenced by
the evaluation corpus (except, of course, that it
had access to the number of metaphoric sentences
in the dataset, which is a parameter and not part
of the model itself). Further, it can be applied
to any English text without the need for labelled
training data. Thus, the scalar approach performs
competitively on a binary task (0.608 vs. 0.638
F-Measure) but can also produce scalar identifica-
tions, which binary systems cannot produce.
749
References
Assaf, D., Neuman, Y., Cohen, Y., Argamon, S.,
Howard, N., Last, M., Koppel, M. 2013. Why ?dark
thoughts? aren?t really dark: A novel algorithm for
metaphor identification. 2013 IEEE Symposium on
Computational Intelligence, Cognitive Algorithms,
Mind, and Brain: 60?65. Institute of Electrical and
Electronics Engineers.
Bracewell, D. B., Tomlinson, M. T., Mohler, M. 2013.
Determining the Conceptual Space of Metaphoric
Expressions. Proceedings of the 14th International
Conference on Computational Linguistics and Intel-
ligent Text Processing, Volume I: 487?500. Berlin,
Heidelberg: Springer-Verlag.
Carbonell, J. 1980. Metaphor - A Key to Extensible
Semantic Analysis. Proceedings of the 18th Meet-
ing of the Association for Computational Linguis-
tics: 17?21. Association for Computational Linguis-
tics.
Casasanto, D., Jasmin, K. 2012. The Hands of Time:
Temporal gestures in English speakers. Cognitive
Linguistics, 23(4): 643?674.
Coulson, S., Matlock, T. 2001. Metaphor and the
space structuring model. Metaphor & Symbol,
16(3), 295-316.
Deignan, A. 2005. Metaphor and Corpus Linguistics.
Amsterdam: John Benjamins.
Dunn, J. 2011. Gradient Semantic Intuitions of
Metaphoric Expressions. Metaphor & Symbol,
26(1), 53-67.
Dunn, J. 2013a. Evaluating the premises and results of
four metaphor identification systems. Proceedings
of the 14th International Conference on Computa-
tional Linguistics and Intelligent Text Processing,
Volume I: 471-486. Berlin, Heidelberg: Springer-
Verlag.
Dunn, J. 2013b. What metaphor identification systems
can tell us about metaphor-in-language. Proceed-
ings of the First Workshop on Metaphor in NLP: 1-
10. Association for Computational Linguistics.
Dunn, J. 2013c. How linguistic structure influences
and helps to predict metaphoric meaning. Cognitive
Linguistics, 24(1), 33-66.
Evans, V. 2010. Figurative language understanding in
LCCM Theory. Cognitive Linguistics, 21(4), 601-
662.
Gandy, L., Allan, N., Atallah, M., Frieder, O., Howard,
N., Kanareykin, S., Argamon, S. 2013. Automatic
Identification of Conceptual Metaphors With Lim-
ited Knowledge. Proceedings of the 27th Confer-
ence on Artificial Intelligence: 328?334. Associa-
tion for the Advancement of Artificial Intelligence.
Gibbs Jr., R. W. 2002. A new look at literal meaning in
understanding what is said and implicated. Journal
of Pragmatics, 34(4), 457-486.
Giora, R. 2002. Literal vs. figurative language: Dif-
ferent or equal? Journal of Pragmatics, 34(4), 487-
506.
Johansson Falck, M., Gibbs, Jr., R. W. 2012. Embod-
ied motivations for metaphorical meanings. Cogni-
tive Linguistics, 23(2): 251?272.
Lakoff, G., Johnson, M. 1980. Metaphors we live by.
Chicago: University Of Chicago Press.
Lakoff, G., Johnson, M. 1999. Philosophy in the
flesh: The embodied mind and its challenge to west-
ern thought. Chicago: University Of Chicago Press.
Li, L., Sporleder, C. 2010a. Linguistic Cues for Distin-
guishing Literal and Non-literal Usages. Proceed-
ings of the 23rd International Conference on Com-
putational Linguistics: Posters: 683-691. Associa-
tion for Computational Linguistics.
Li, L., Sporleder, C. 2010b. Using Gaussian Mix-
ture Models to Detect Figurative Language in Con-
text. Human Language Technologies: The 2010 An-
nual Conference of the North American Chapter of
the Association for Computational Linguistics: 297?
300. Association for Computational Linguistics.
Mason, Z. 2004. CorMet: A Computational, Corpus-
Based Conventional Metaphor Extraction System.
Computational Linguistics, 30(1), 23-44.
Minnen, G., Carroll, J., Pearce, D. 2001. Applied
morphological processing of English. Natural Lan-
guage Engineering, 7(3), 207-223.
Mohler, M., Bracewell, D., Tomlinson, M., Hinote,
D. 2013. Semantic Signatures for Example-Based
Linguistic Metaphor Detection. Proceedings of the
First Workshop on Metaphor in NLP: 27-35. Asso-
ciation for Computational Linguistics.
Neuman, Y., Nave, O. 2009. Metaphor-based meaning
excavation. Information Sciences, 179, 2719-2728.
Niles, I., Pease, A. 2001. Towards a standard upper
ontology. Proceedings of the International Confer-
ence on Formal Ontology in Information Systems:
2-9. Association for Computing Machinery.
Niles, I., Pease, A. 2003. Linking lexicons and on-
tologies: Mapping WordNet to the Suggested Upper
Merged Ontology. Proceedings of the 2003 Inter-
national Conference on Information and Knowledge
Engineering: 412-416. World Congress in Com-
puter Science, Computer Engineering, and Applied
Computing.
Pedersen, T., Kolhatkar, V. 2009. Word-
Net::SenseRelate::AllWords - A broad coverage
word sense tagger that maximimizes semantic re-
latedness. Proceedings of Human Language Tech-
nologies: The 2009 Annual Conference of the North
750
American Chapter of the Association for Computa-
tional Linguistics, Companion Volume: Demonstra-
tion Session: 17-20. Association for Computational
Linguistics.
Shutova, E., Sun, L. 2013. Unsupervised Metaphor
Identification using Hierarchical Graph Factoriza-
tion Clustering. Proceedings of Human Language
Technologies: The 2013 Annual Conference of the
North American Chapter of the Association for
Computational Linguistics: 978-988. Association
for Computational Linguistics.
Shutova, E., Teufel, S., Korhonen, A. 2013. Statis-
tical Metaphor Processing. Computational Linguis-
tics, 39(2), 301-353.
Steen, G. J., Dorst, A. G., Herrmann, J. B., Kaal, A. A.,
Krennmayr, T. 2010. Metaphor in usage. Cognitive
Linguistics, 21(4), 765-796.
Strzalkowski, T., Broadwell, G. A., Taylor, S., Feld-
man, L., Shaikh, S., Liu, T., Elliot, K. 2013. Robust
Extraction of Metaphor from Novel Data. Proceed-
ings of the First Workshop on Metaphor in NLP: 67-
76. Association for Computational Linguistics.
Tsvetkov, Y., Mukomel, E., Gershman, A. 2013.
Cross-Lingual Metaphor Detection Using Common
Semantic Features. Proceedings of the First Work-
shop on Metaphor in NLP: 45-51. Association for
Computational Linguistics.
Turney, P. D., Neuman, Y., Assaf, D., Cohen, Y.
2011. Literal and Metaphorical Sense Identifica-
tion Through Concrete and Abstract Context. Pro-
ceedings of the Conference on Empirical Methods
in Natural Language Processing: 680-690. Associ-
ation for Computational Linguistics.
Wilks, Y. 1978. Making preferences more active. Ar-
tificial Intelligence, 11(3), 197-223.
751
Proceedings of the First Workshop on Metaphor in NLP, pages 1?10,
Atlanta, Georgia, 13 June 2013. c?2013 Association for Computational Linguistics
What metaphor identification systems can tell us about
metaphor-in-language
Jonathan Dunn
Purdue University
West Lafayette, Indiana USA
jonathan.edwin.dunn@gmail.com
Abstract
This paper evaluates four metaphor identi-
fication systems on the 200,000 word VU
Amsterdam Metaphor Corpus, comparing re-
sults by genre and by sub-class of metaphor.
The paper then compares the rate of agree-
ment between the systems for each genre and
sub-class. Each of the identification systems
is based, explicitly or implicitly, on a the-
ory of metaphor which hypothesizes that cer-
tain properties are essential to metaphor-in-
language. The goal of this paper is to see what
the success or failure of these systems can tell
us about the essential properties of metaphor-
in-language. The success of the identification
systems varies significantly across genres and
sub-classes of metaphor. At the same time, the
different systems achieve similar success rates
on each even though they show low agree-
ment among themselves. This is taken to
be evidence that there are several sub-types
of metaphor-in-language and that the ideal
metaphor identification system will first de-
fine these sub-types and then model the lin-
guistic properties which can distinguish these
sub-types from one another and from non-
metaphors.
1 Introduction
The purpose of this paper is to evaluate four sys-
tems for identifying metaphor-in-language on the
large and representative VU Amsterdam Metaphor
Corpus (Steen, et al, 2010) and then to analyze the
correct and incorrect identifications in order to see
what they can tell us about the linguistic properties
of metaphor-in-language. The four metaphor identi-
fication systems include a word-level semantic simi-
larity measurement method (Sporleder and Li, 2009;
Li and Sporleder, 2010), a word-level abstract-
ness measurement method (Turney and Littmann,
2003; Turney, et al, 2011), a grammatical-relation-
level source-target mapping method (Shutova, 2010;
Shutova and Teufel, 2010; Shutova, Sun, and Ko-
rhonen, 2010; Shutova, Teufel, and Korhonen,
2013), and an utterance-level domain interaction
method (Dunn, 2013b).
2 The VU Amsterdam Metaphor Corpus
The VU Amsterdam Metaphor Corpus (Steen, et
al., 2010) consists of approximately 200,000 words
taken from the British National Corpus?s Baby Cor-
pus and divided into four genres: academic, news,
fiction, and conversation. It was manually annotated
for metaphoric uses of words by five analysts us-
ing a version of the MIP method (Pragglejaz Group,
2007). For the purposes of this study, the corpus
was divided into sentences, under the assumption
that each sentence represents an utterance. There
are 16,202 sentences in the corpus. Sentences which
contain at least one metaphoric use of a word are la-
beled as metaphoric sentences. This is done because
a metaphorically used word is not metaphoric except
in relation to its linguistic context; thus, a larger lin-
guistic unit like the sentence is necessary for reveal-
ing metaphorically used words.
The VU Amsterdam Corpus is annotated with
several sub-classes of metaphor-in-language. The
sub-classes included in this evaluation are MRW-
Met (a metaphoric use of a metaphor related word);
1
Table 1: Number of sentences with sufficient representation in each system.
System Non-Metaphor MRW-Met MRW-Lit PP Double WIDLII
Total 7,979 5,977 126 754 180 1,186
Similarity 4,300 4,274 104 612 153 855
Abstractness 6,851 5,497 118 723 174 1,090
Source-Target 6,256 5,391 121 719 178 1,070
Domain Interaction 6,770 5,588 122 729 178 1,115
MRW-Lit (a literal use of a metaphor related
word); PP (a possible personification resulting in a
metaphor related word); Double (a metaphor related
word which is involved in a double metaphor; for ex-
ample, personification and a conceptual metaphor);
WIDLII (possible metaphor related words which
were considered ambiguous between metaphoric
and non-metaphoric use).
Table 1 shows a break-down of the number of sen-
tences in each of these sub-classes in the corpus as a
whole and as represented by each of the metaphor
identification systems. Because each system uses
different linguistic properties to identify metaphor-
in-language and uses different methods to represent
those properties, the systems differ in how many
of the sentences are sufficiently represented. For
example, the semantic similarity measurement sys-
tem looks at pairwise similarity values while the ab-
stractness measurement system looks at values for
individual words. Thus, the abstractness system
could potentially have twice as many data points as
the similarity system. The numbers in Table 1 in-
clude only the sentences with a minimum number of
data points. The evaluation results below do not take
into account sentences for which a system has insuf-
ficient representation. However, it is important to
note that the systems differ in how many sentences
they adequately represent, which means that some
(for example, the similarity system) are less able to
identify metaphor-in-language because they have a
less robust representation of the linguistic utterance.
For the purposes of this study, metaphor identifi-
cation was conceptualized as a sentence-level task.
For example, the systems evaluated here could be
used within a larger computational semantic sys-
tem to separate metaphoric and non-metaphoric sen-
tences for purposes of reasoning. One result of this
choice is that some of the original systems need to
be slightly reconceptualized; thus, it is better to say
that these systems are inspired by the cited systems,
rather than strict reimplementations of those sys-
tems. The similarity and abstractness systems orig-
inally were meant to decide which uses of a given
verb are metaphoric and which are not metaphoric.
In the present study, however, metaphor is not lim-
ited to verbs and the systems do not know which
words in the sentence may be metaphoric (e.g., it
could be any noun or any verb, etc.). Thus, these
systems have been altered to determine whether
there are any metaphorically used words anywhere
in the sentence. Further, all of the reconceptual-
ized systems compared here involve training or seed
metaphors, even those which were originally unsu-
pervised systems.
3 Identifying Metaphor-in-Language
Using Semantic Similarity
The semantic similarity system (Sporleder and Li,
2009; Li and Sporleder, 2010) uses pairwise seman-
tic similarity to detect metaphoric uses of words. As
conceptualized in this study, the system is designed
to detect whether any of the words in the sentence
are used metaphorically without knowing in advance
which words are candidates for metaphoric use.
While the original system used Normalized
Google Distance (Cilibrasi and Vitanyi, 2007)
to measure semantic similarity, the evaluation in
this study used Iosif?s SemSim system (Iosif and
Potamianos, 2012). There were two main reasons
for not using the NGD measure: (1) SemSim offers
more control because the corpus used to determine
pairwise similarity is known and can be made simi-
lar to the test corpus; (2) SemSim is more transpar-
ent in terms of its methodology and its results are
more stable over time. For this evaluation we used
the Open American National Corpus (henceforth,
2
OANC (Ide and Suderman, 2004)), which consists
of 14 million words taken from spoken and writ-
ten contemporary American English, to determine
the pairwise similarity values. Both the test corpus
and OANC were lemmatized and had common func-
tion words removed. Pairwise similarities were de-
termined for all words in the test corpus which oc-
curred 10 or more times, for a total of 1,691 words.
SemSim?s contextual window was set at 2. As with
all systems discussed below, Morpha (Guido, Car-
roll, and Pearce, 2001) was used for lemmatization
and OpenNLP (Apache, 2011) was used for named
entity recognition.
The variables used in the original system had to
be changed slightly because no particular word in
the sentence is given a special focus. The follow-
ing variables were used: (1) the number of similar-
ity measurements for a given sentence; (2) the aver-
age similarity; (3) the standard deviation of similar-
ity, in order to see how much divergence there was
from the average; (4) the highest pairwise similarity;
(5) the lowest pairwise similarity; (6) the difference
between the highest and lowest pairwise similarity.
One of the weaknesses of this particular implemen-
tation of the system is that it only considers words
that are adjacent to one another (with function words
removed). While the original system also used the
average pairwise similarity between the candidate
word and all other words, this was not possible here
given that there were no words starting as candi-
dates.
4 Identifying Metaphor-in-Language
Using Word Abstractness
The word abstractness system uses a measurement
of word abstractness to identify highly abstract con-
texts which are posited to be more likely to contain
metaphors. In the reconceptualization of the system
evaluated here there is also a focus on disparities in
abstractness ratings within a given sentence, so that
the mixture of abstract and concrete words can be
used to detect possible metaphors.
The system first rates lexical items according to
how abstract they are, on a scale from 0 to 1, with
1 being the most abstract. The approach to rating
abstraction is taken from (Turney, et al, 2011); a list
of rated lexical items is available from the authors.
The system tags the words in the sentence with their
parts of speech and finds the abstractness rating for
each; if an abstractness rating is not available for a
particular word form, the system attempts to find a
match for its lemmatized form. All words not found
on the list of abstractness ratings after these searches
were removed.
For each sentence a feature vector was created
that consisted of twelve different combinations of
abstractness ratings: (1) the number of abstractness
ratings available for the sentence; (2) the average ab-
stractness for all words; (3) the standard deviation
of the abstractness for all words; (3)-(4) the average
and standard deviation for the abstractness of nouns;
(5)-(6) the average and standard deviation for the ab-
stractness of verbs; (7)-(8) the average and standard
deviation for the abstractness of adjectives and ad-
verbs; (9)-(10) the highest and lowest abstractness in
the sentence; (11) the difference between the highest
and lowest abstractness; (12) the difference between
the average abstractness for nouns and for verbs.
Empty slots in the feature vector (e.g., if there were
no adjectives) were filled with a value of 0.5 for ab-
stractness, following the original system.
5 Identifying Metaphor-in-Language
Using Source-Target Mappings
The source-target mapping system clusters verbs
and nouns using their distributional properties and
argues that abstract nouns will cluster according to
the metaphoric source domains to which they are
connected. The system moves from the linguistic
utterance to the underlying conceptual mapping by
assuming that the verb directly represents the source
domain in the metaphoric mapping and that nouns
(functioning as the subject and/or object of the verb)
directly represent the target. Thus, the system looks
at grammatical relations containing a verb and a
noun and generalizes from seed metaphors to other
metaphors involving words from the same clusters.
The first part of evaluating the source-target map-
ping approach to metaphor identification was to
cluster lexical items. The method for clustering
verbs is described in (Sun and Korhonen, 2009);
(Sun, Korhonen, and Krymolowski, 2008) provide
a resource of the most frequent 1,510 English verbs
in the Gigaword corpus divided into 170 clusters.
3
These clusters were used in the evaluation. The pro-
cedure used for clustering nouns in (Shutova, Teufel,
and Korhonen, 2013) is to include the frequency of
grammatical relations (subject, object, indirect ob-
ject), as annotated by the RASP parser, in a feature
vector. In evaluating the source-target system, we
took a different approach to obtaining noun clus-
ters. Starting with 8,752 nouns examined by Iosif?s
SemSim system (Iosif and Potamianos, 2012), we
used a pairwise similarity matrix (measured using
the Google-based Semantic Relatedness metric, as
computed by Iosif) for the feature vector used for
clustering nouns. The nouns were divided into 200
clusters using Weka?s (Witten and Frank, 2005) im-
plementation of the k-means algorithm.
The search for metaphors was performed on the
RASP-parsed version of the evaluation corpus. A to-
tal of 1,000 randomly selected metaphoric sentences
were used as seed metaphors; any relation between
two different clusters was accepted as a candidate.
Many of the seed metaphoric utterances contained
multiple grammatically related clusters (e.g., verb-
object) which were candidates for the metaphoric
material in the utterance. In this evaluation we have
erred on the side of inclusion by searching for all
possible candidates. A total of 903 grammatical re-
lations between clusters were identified in the seed
sentences; no attempt was made to trim this num-
ber down. While the original system removed verbs
which have loose selectional restrictions, such verbs
were not removed from the clusters here; the origi-
nal system focuses on preventing false positives, but
in the evaluation here the focus is on preventing false
negatives, which such a reduction would necessarily
create.
6 Identifying Metaphor-in-Language
Using Domain Interactions
The domain interaction system (Dunn, 2013b)
is a knowledge-based system unlike the previ-
ous distributional-semantic systems. It identifies
metaphoric utterances using properties of the con-
cepts pointed to by lexical items in the utterance.
The system has two stages: first, determining what
concepts are present in an utterance and what their
properties are; second, using these properties to
model metaphor.
The system maps lexical items to their WordNet
synsets (WordNet, 2011) using the part of speech
tags to maintain a four-way distinction between
nouns, verbs, adjectives, and adverbs. The system
then maps the WordNet synsets onto concepts in the
SUMO ontology (Niles and Pease, 2001) using the
mappings provided (Niles and Pease, 2003). This
is done using the assumption that each lexical item
is used in its default sense, so that no disambigua-
tion takes place. Once the concepts present in the
utterance have been identified in this manner, using
the concepts present in the SUMO ontology, the sys-
tem uses domain (ABSTRACT, PHYSICAL, SOCIAL,
MENTAL) and event-status (PROCESS, STATE, OB-
JECT) properties of each concept present in the ut-
terance. These are not present as such in the SUMO
ontology, but were developed following Ontologi-
cal Semantics (Nirenburg and Raskin, 2004) as a
knowledge-base specific to the system.
The domain interaction system was implemented
with a feature vector created using the properties
of the concepts referred to by lexical items in the
utterance. The feature vector uses the following
variables: (1) number of concepts in the utterance;
(2-5) number of instances of each type of domain
(ABSTRACT, PHYSICAL, SOCIAL, MENTAL); (6-
8) number of instances of each type of event sta-
tus (PROCESS, STATE, OBJECT); (9) number of in-
stances of the domain with the highest number of
instances; (10) number of instances of event-status
with the highest number of instances; (11) sum of
the individual domain variables minus (9); (12) sum
of individual event-status variables minus (10); (13)
number of domain types present at least once in the
utterance; (14) number of event-status types present
at least once in the utterance; (15) number of in-
stances of the main domain divided by the number
of concepts; (16) number of other domain instances
divided by the number of concepts; (17) number of
main event-status instances divided by the number
of concepts; (18) number of other event-status in-
stances divided by the number of concepts.
7 Evaluation Results
The evaluation results discussed in this section con-
sider only the sentences for which each system has
the minimum representation; for example, the se-
4
Table 2: Results for each system across all genres and sub-classes.
System True Positive False Positive True Negative False Negative F-Measure
Similarity 5,936 4,214 86 62 0.444
Abstractness 4,627 3,049 3,752 2,954 0.582
Source-Target 1,063 785 5,470 5,496 0.440
Domain Interaction 5,446 3,664 3,106 2,286 0.583
Table 3: Results for each system across all genres and sub-classes without Named Entity Recognition.
System True Pos. False Pos. True Neg. False Neg. F-Meas. Represented
Similarity 5,658 3,973 63 56 0.444 9,750
Abstractness 5,882 4,205 441 354 0.482 10,883
Source-Target 1,725 1,342 2,171 2,677 0.487 8,547
Domain Interaction 6,561 4,205 1,462 676 0.573 12,904
mantic similarity system had a minimum representa-
tion for many fewer sentences than does the abstract-
ness system, but those unrepresented sentences are
not held against the system. Three of the systems use
feature vectors: the semantic similarity, word ab-
stractness, and domain interaction systems. To make
the evaluation comparable all three systems are eval-
uated using Weka?s (Witten and Frank, 2005) imple-
mentation of the logistic regression algorithm, fol-
lowing (Turney, et al, 2011), using cross-validation
(100 folds) and a ridge estimator value of 0.2. The
evaluation of the source-target system searched for
the 903 seed relations in the RASP-parsed test cor-
pus. The sentences used as seeds were removed
from the test corpus before searching. For each
evaluation, the reported F-Measure is the weighted
average of the F-Measures for metaphors and non-
metaphors.
Table 2 shows the evaluation results for the four
systems on the entire corpus. The similarity system
has the highest number of true positives (5,936), but
also the highest number of false positives (4,214).
In fact, the similarity system identifies very few ut-
terances as non-metaphors and this makes the re-
sults rather unhelpful. The abstractness and do-
main interaction systems have similar F-measures
(0.582 and 0.583, respectively); both make a large
number of predictions for both metaphor and non-
metaphor, so that they attempt to distinguish be-
tween the two, but these predictions are not particu-
larly accurate. The source-target system stands out
here, as it does below, with a significantly smaller
number of false positives than the other systems
(785). At the same time, it also has a significantly
higher number of false negatives (5,496). The simi-
larity and source-target systems are on opposite ends
of the spectrum in terms of over-identifying and
under-identifying metaphor-in-language, and both
have similar F-measures (0.444 and 0.440, respec-
tively) which are lower than the abstractness and do-
main interaction systems.
In Table 3 the same results across all genres and
sub-types are presented for implementations with-
out Named Entity Recognition. The only system
which performs significantly differently is the ab-
stractness system, with an F-Measure of 0.482 with-
out vs. 0.582 with NER. This decline goes hand-in-
hand with the fact that the system with NER has suf-
ficient representation for a total of 14,454 sentences,
while without NER it has sufficient representation
for only 10,883 sentences.
Table 4 starts to break these results down further
by genre, in order to find out if the systems perform
differently on different sorts of texts. Every system
except for the similarity system (with F-measures of
0.444 and then 0.463) performs more poorly on fic-
tion than on the corpus as a whole. More interest-
ingly, within the fiction genre the similarity and ab-
stractness systems do not predict that any utterances
are non-metaphors, which makes their F-measures
largely meaningless. The source-target system con-
tinues to make a distinction between metaphor and
5
Table 4: Results for each system in the Fiction genre.
System True Positive False Positive True Negative False Negative F-Measure
Similarity 1,778 1,135 0 0 0.463
Abstractness 2,074 1,375 0 0 0.452
Source-Target 293 244 1,151 1,567 0.379
Domain Interaction 2,067 1,349 75 67 0.485
Table 5: Results for each system in the News genre.
System True Positive False Positive True Negative False Negative F-Measure
Similarity 1,806 292 0 0 0.796
Abstractness 1,940 321 0 0 0.792
Source-Target 348 61 262 1,352 0.321
Domain Interaction 1,956 324 0 0 0.792
non-metaphor within this genre, although the true
and false positives (293 and 243, respectively) are
much closer to one another than when looking at the
corpus as a whole.
Table 5 looks at the systems? performance within
the News genre. The similarity system, which above
made few predictions for non-metaphor continues
to predict only metaphors; the abstractness and do-
main interaction systems join it, predicting only
metaphors. The source-target system, on the other
hand, maintains a small number of false positives
(61), although continuing to show a large number of
false negatives (1,352). In terms of practical applica-
tions, the F-measures here do not adequately reflect
the fact that three of the four systems essentially fail
on this genre. One of the difficulties is the fact that
the News genre contains 1,708 metaphoric sentences
and 325 non-metaphoric sentences according to the
manual annotations in the VU Amsterdam Metaphor
Corpus; that means that 84% of the sentences are an-
notated as metaphoric.
Table 6 looks at the results within the Academic
genre. Here all systems make a distinction between
metaphor and non-metaphor; this is the first set on
which the similarity system has predicted a mean-
ingful number of non-metaphors. The source-target
system misses the most metaphors (1,321) but also
makes significantly fewer false positives (146 vs. the
next lowest 590 by the similarity system). The F-
measures do not adequately reflect the performance
of the systems for this genre.
Table 7 shows the results within the Conversation
genre. This is the reverse of the News genre: three of
the four systems make no predictions of metaphors.
This genre contains 1,958 utterances with at least
one metaphorically used word and 5,262 without.
Further, this genre contains many more short and/or
fragmentary sentences than the others. Even the
source-target system, which is the only system to
identify any metaphors, has more than twice as
many false positives as true positives (334 vs. 136,
respectively), which reverses its performance on the
three previous genres.
The initial conclusions we can draw from the
genre break-down is that (1) the F-measure does not
always reflect meaningful performance and thus that
the numbers of true and false positives and negatives
should be reported as well; and (2) that the perfor-
mance on the corpus as a whole disguises a large
amount of variation according to genre.
Table 8 shows the results for only the MRW-Met
sub-class in the corpus. This is the basic metaphor
sub-class in the corpus and the most common. The
systems perform better on this sub-class than on any
other. Interestingly, the source-target system makes
more false than true positives here (785 vs. 749) and
is the only system to make more false than true posi-
tives for this sub-class. It also makes more false neg-
atives than the other systems, although the abstract-
ness, source-target, and domain interaction systems
make a comparable number (3,971 and 3,990 and
3,386, respectively). The domain interaction system
6
Table 6: Results for each system in the Academic genre.
System True Positive False Positive True Negative False Negative F-Measure
Similarity 1,287 590 289 214 0.635
Abstractness 1,604 667 273 204 0.649
Source-Target 286 146 786 1,321 0.367
Domain Interaction 1,720 720 232 154 0.646
Table 7: Results for each system in the Conversation genre.
System True Positive False Positive True Negative False Negative F-Measure
Similarity 0 0 1,994 913 0.558
Abstractness 0 0 4,165 1,759 0.580
Source-Target 136 334 3,271 1,256 0.621
Domain Interaction 0 0 4,070 1,768 0.573
makes the most true positives, although all the F-
measures are comparable (the lowest is only 0.062
below the highest).
Table 9 shows the results for the ambiguous
metaphors, under the label WIDLII, and the results
are comparable to the results for all other sub-classes
except for the MRW-Met sub-class (thus, the other
sub-classes will not be discussed individually). The
similarity, abstractness, and domain interaction sys-
tems do not detect any of these sentences as con-
taining metaphorically used words. In some ways
this failure is acceptable because the original ana-
lysts were not convinced that these utterances con-
tained metaphors in the first place. The source-target
system has a very uncharacteristic performance on
this sub-class, with 5-times as many false positives
as true positives (785 vs. 157, respectively).
This is interesting because it is exactly the op-
posite of the other systems, which do not predict
any sentences to be metaphors at all. This differ-
ence is likely a result of the fact that the other three
systems rely on feature vectors that were trained
on the WIDLII / Non-Metaphor distinction, while
the source-target system uses seed grammatical re-
lations from other sub-classes as well (it shouldn?t
matter because the relations are hypothesized to rep-
resent conceptual metaphors for which the sub-class
distinction is not relevant; more seed metaphors
were not used because this would have removed
them from the evaluation). In other words, the
sub-class comparisons try to distinguish between
WIDLII metaphors and non-metaphors in the cor-
pus. The source-target system was trained on one
and only one set of seed metaphors; in other cases
this fact increased the system?s performance, but in
this case it had the opposite effect. It also shows that
non-metaphors are more likely to contain the seed
clusters than are ambiguous metaphors.
8 Error Analysis
The next question to ask is whether these four sys-
tems succeed and fail on the same metaphors. Each
system makes different assumptions and is based on
a different theory of what linguistic properties are
essential to metaphor-in-language, and thus can be
used to distinguish metaphor from non-metaphor.
Table 10: Agreement among the four metaphor identifi-
cation systems using Fleiss? Kappa.
Sub-set Full Reduced
Fiction 0.293 0.301
News 0.279 0.277
Academic 0.282 0.286
Conversation 0.259 0.286
MRW-Met 0.280 0.291
MRW-Lit 0.285 0.298
PP 0.293 0.290
Double 0.346 0.369
WIDLII 0.278 0.292
Table 10 shows the agreement between the four
7
Table 8: Results for each system in the MRW-Met Sub-Class.
System True Positive False Positive True Negative False Negative F-Measure
Similarity 2,141 1,841 2,459 2,133 0.536
Abstractness 1,505 1,287 5,514 3,971 0.537
Source-Target 749 785 5,470 3,990 0.499
Domain Interaction 2,202 1,895 4,875 3,386 0.561
Table 9: Results for each system in the WIDLII Sub-Class.
System True Positive False Positive True Negative False Negative F-Measure
Similarity 0 0 4,300 855 0.759
Abstractness 0 2 6,799 1,090 0.798
Source-Target 157 785 5,470 768 0.785
Domain Interaction 0 0 6,770 1,115 0.793
systems as measured by Fleiss? Kappa. In the first
column, under ?Full,? the predictions used to deter-
mine agreement differ slightly from the earlier pre-
dictions because all sentences were included, even
those for which a particular system lacked sufficient
representation. This was done in order to make
a comparison of the four systems possible (sen-
tences without representation could not be identified
as metaphors and thus defaulted to non-metaphors).
The sentences used as seeds for the source-target
system were removed for all systems. A possi-
ble cause for low agreement between the systems
is that if one system lacks sufficient representation
for a sentence, it will cause disagreement by its lack
of representation. The second column, under ?Re-
duced,? shows the agreement between the four sys-
tems for only those sentences for which all systems
had an adequate representation and which were not
used for seed metaphors (a total of 8,887 sentences
rather than the full 16,202). The results are simi-
lar, showing that the low agreement is not caused by
lack of sufficient representation.
All of the divisions, whether by genre or by sub-
class, have a similarly low level of agreement, with
a range from 0.259 to 0.293. The sub-class of Dou-
ble metaphors has a higher agreement of 0.346. This
low agreement is the case even though the systems
have similar overall performance on these particular
genres and sub-classes. In other words, even though
the systems make similar numbers of correct predic-
tions, the particular utterances for which metaphor is
correctly or incorrectly predicted are not the same.
This is an important point because if all four
systems succeeded and failed on the same utter-
ances then we could say that those particular ut-
terances were the cause of the failure and try to
model the properties of those utterances. What
seems to be happening is quite the opposite: each
system implements a particular model of metaphor-
in-language which makes specific explicit and im-
plicit assumptions about what metaphor-in-language
is and what properties are essential for distinguish-
ing metaphoric language from non-metaphoric lan-
guage. These different models seem to be succeed-
ing on those metaphors which fall within their scope
and failing on all others, which leads to disagree-
ment in the predictions of the systems.
9 Synthesizing the Systems
Several meta-systems were constructed using the re-
sults of the four systems on the sub-set of the cor-
pus for which each system had adequate representa-
tion (8,887 sentences). The first meta-system iden-
tified as metaphor only those sentences which the
two top-performing systems, the source-target map-
ping and the domain interaction systems, agreed
were metaphoric; the second only those sentences
which all four systems agreed were metaphoric; the
third only those sentences which a majority of sys-
tems agreed were metaphoric; the fourth those sen-
tences for which either the domain interaction or
8
Table 11: Results for meta-systems across all sentences with sufficient representation for all systems.
System True Positive False Positive True Negative False Negative F-Measure
Only top two agree 520 360 3,558 4,449 0.362
Only all agree 374 244 3,674 4,595 0.341
Majority vote 1,513 1,655 2,263 2,921 0.445
Top two inclusive 3,200 2,552 1,366 1,769 0.505
Top two, settled inc 2,689 2,164 1,754 2,280 0.501
Top two, settled exc 2,086 1,688 2,230 2,883 0.485
the source-target system identified as metaphor; the
fifth all sentences which the domain interaction and
source-target systems agreed were metaphoric, us-
ing the similarity and abstractness systems to resolve
disagreement. There are two versions of this last
meta-system: the inclusive version identifies dis-
puted sentences as metaphoric if either the similarity
or abstractness system does, and the exclusive ver-
sion only if the two agree.
Table 11 shows the results of the evaluations of
these meta-systems. The system with the fewest
false positives is the one which requires four-
way agreement before an utterance is identified as
metaphor; however, this also has the fewest true
positives. The performance of the exclusive meta-
system for the top two systems has a better propor-
tion of true to false positives, but also has an unfor-
tunately high number of false negatives. The major-
ity vote meta-system has more false than true pos-
itives and, thus, is not successful. The last three
meta-systems differ in how they resolve disagree-
ments between the top two systems; there is a con-
sistent trade-off between more true positives and
fewer false positives and all three have comparable
F-measures.
10 What This Tells Us About
Metaphor-in-Language
What can we learn about metaphor-in-language
from the successes and failures of these four
metaphor identification systems? First, there is a
significant difference between genres. The linguistic
properties which can distinguish metaphors in one
genre may not apply to other genres. Or, looked
at another way, different genres are more likely to
contain different types of metaphors (the types of
metaphor referred to here involve different sources
of metaphoric meaning and are not comparable to
the corpus?s sub-classes).
Second, the predictions of the four systems, re-
gardless of their accuracy, have a relatively low level
of agreement. This low level of agreement is consis-
tent across genres and sub-classes. This means that
the systems are succeeding and failing on different
metaphors. Each of the systems is based on a differ-
ent theory of metaphor-in-language. The combina-
tion of these two facts suggests that different types
of metaphor have different linguistic properties.
Most theories of metaphor conceive of it as a
single and coherent phenomenon, so that the pre-
dictions of competing theories are mutually exclu-
sive. The lack of agreement coupled with similar
success rates, however, suggests that these theories
of metaphor-in-language are not mutually exclusive
but rather apply to different types of metaphor-in-
language. If this is the case, then a more accu-
rate model of metaphor-in-language will start by
positing a number of different types of metaphor-
in-language, which differ in the source of their
metaphoric meaning, and then predicting what lin-
guistic properties can be used to distinguish among
these types and between them and non-metaphors.
Metaphor identification systems can be im-
proved by focusing on two important properties of
metaphor-in-language: First, metaphors are gradi-
ent, with some being much more metaphoric than
others (Dunn, 2011). One problem with the sys-
tems described in this paper is that they are forced
to draw an arbitrary line between two classes to rep-
resent a gradient phenomenon. Second, metaphoric
expressions receive their metaphoric meaning from
different sources (Dunn, 2013a). These different
types of metaphor-in-language have different prop-
erties and should be modeled individually.
9
References
Apache. 2011. OpenNLP
Briscoe, E., Carroll, J., Watson, R. ?The Second Release
of the RASP System.? Curran, J. (ed.) Proceedings
of COLING/ACL 2006 Interactive Presentation Ses-
sions 77-80 Association for Computational Linguis-
tics Stroudsburg, PA 2006
Cilibrasi, R. and Vitanyi, P. ?The Google similarity
distance.? Knowledge and Data Engineering, IEEE
Transactions on 19(3): 370?383 2007
Dunn, J. ?Gradient semantic intuitions of metaphoric
expressions? Metaphor & Symbol 26(1): 53-67 2011
Dunn, J. ?How linguistic structure influences and helps
to predict metaphoric meaning? Cognitive Linguistics
24(1): 33-66 2013
Dunn, J. ?Evaluating the premises and results of four
metaphor identification systems.? Gelbukh, A. (ed.)
Proceedings of CICLing 2013, LNCS 7816 471-486
Springer Heidelberg 2013
Guido, M., Carroll, J., Pearce, D. ?Applied morpholog-
ical processing of English.? Natural Language Engi-
neering 7(3): 207-223 2001
Ide, N. and Suderman, K. ?The American National Cor-
pus First Release.? Lino, M. Xavier, M., Ferreira, F.,
Costa, R., and Silva, R. (eds.) Proceedings of LREC-
2004 1681-1684 European Language Resources As-
sociation Paris 2004
Iosif, E. and Potamianos, A. ?SemSim: Resources for
Normalized Semantic Similarity Computation Using
Lexical Networks.? Calzolari, N., Choukri, K., De-
clerck, T., Doan, M., Maegaard, B., Mariani, J., Odijk,
J., Piperidis, S. (eds.) Proceedings of LREC-2012
3499-3504 European Language Resources Associa-
tion Paris 2012
Li, L. and Sporleder, C. ?Using Gaussian Mixture Mod-
els to Detect Figurative Language in Context.? Ka-
plan, R., Burstein, J., Harper, M., and Penn, G. (eds.)
Proceedings of HLT-NAACL-2010 297?300 Associ-
ation for Computational Linguistics Stroudsburg, PA
2010
Niles, I. and Pease, A. ?Towards a Standard Upper On-
tology? Welty, C. and Barry, C. (eds.) Proceedings of
FOIS-2001 2-9 Association for Computational Lin-
guistics Stroudsburg, PA 2001
Niles, I. and Pease, A. ?Linking Lexicons and On-
tologies: Mapping WordNet to the Suggested Upper
Merged Ontology.? Arabnia, H. (ed) Proceedings of
IEEE Intl Conf on Inf. and Knowl. Eng. (IKE 03) 412-
416 IEEE Press New York 2003
Nirenburg, S. and Raskin, V. Ontological Semantics
Cambridge, MA MIT Press 2004
Pragglejaz Group ?MIP: A method for identifying
metaphorically used words in discourse.? Metaphor
and Symbol 22(1): 139 2007
Princeton University WordNet 2012
Shutova, E. ?Models of Metaphor in NLP.? Hajiv, J.,
Carberry, S., Clark, S. and Nivre, J. (eds.) Proceedings
of ACL-2010 688?697 Association for Computational
Linguistics Stroudsburg, PA 2010
Shutova, E. and Teufel, S. ?Metaphor corpus anno-
tated for source ? target domain mappings.? Calzolari,
N., Choukri, K., Maegaard, B., Mariani, J., Odijk, J.,
Piperidis, S., Rosner, M. and Tapias, D. (eds.) Pro-
ceedings of LREC 2010 3255?3261 European Lan-
guage Resources Association Paris 2010
Shutova, E., Sun, L,. and Korhonen, A. ?Metaphor iden-
tification using verb and noun clustering.? Huang, C.
and Jurafsky, D. (eds.) Proceedings of COLING 2010
1002?1010 Tsinghua University Press Beijing 2010
Shutova, E., Teufel, S., and Korhonen, A. ?Statistical
Metaphor Processing.? Computational Linguistics 39
2013
Sporleder, C. and Li, L. ?Contextual idiom detection
without labelled data.? Koehn, P. and Mihalcea, R.
(eds.) Proceedings of EMNLP-09 315-323 Associ-
ation for Computational Linguistics Stroudsburg, PA
2009
Steen, G., Dorst, A., Herrmann, J., Kaal, A., and Kren-
nmayr, T. ?Metaphor in usage.? Cognitive Linguistics
21(4): 765-796 2010
Sun, L. and Korhonen, A. ?Improving verb clustering
with automatically acquired selectional preferences.?
Koehn, P. and Mihalcea, R. (eds.) Proceedings of
EMNLP-2009 638?647 Association for Computa-
tional Linguistics Stroudsburg, PA 2009
Sun, L., Korhonen, A., and Krymolowski, Y. ?Verb
Class Discovery from Rich Syntactic Data.? Gelbukh,
A. (ed) Proceedings of CICLING-2008, LNCS, vol.
4919 16-27 Springer Heidelberg 2008
Turney, P. and Littman, M. ?Measuring praise and crit-
icism: Inference of semantic orientation from asso-
ciation.? ACM Transactions on Information Systems
21(4): 315?346 2003
Turney, P., Neuman, Y, Assaf, D., and Cohen, Y. ?Literal
and Metaphorical Sense Identification through Con-
crete and Abstract Context.? Barzilay, R. and Johnson,
M. (eds.) Proceedings of EMNLP-2011 680?690 As-
sociation for Computational Linguistics Stroudsburg,
PA 2011
Witten, I. and Frank, E. Data Mining: Practical Ma-
chine Learning Tools and Techniques with Java Imple-
mentations Morgan Kaufmann San Francisco 2005
10
Proceedings of the Second Workshop on Metaphor in NLP, pages 27?32,
Baltimore, MD, USA, 26 June 2014.
c?2014 Association for Computational Linguistics
Multi-dimensional abstractness in cross-domain mappings
Jonathan Dunn
Department of Computer Science / Illinois Institute of Technology
jonathan.edwin.dunn@gmail.com
Abstract
Metaphor is a cognitive process that
shapes abstract target concepts by map-
ping them to concrete source concepts.
Thus, many computational approaches to
metaphor make reference, directly or in-
directly, to the abstractness of words and
concepts. The property of abstractness,
however, remains theoretically and empir-
ically unexplored. This paper implements
a multi-dimensional definition of abstract-
ness and tests the usefulness of each di-
mension for detecting cross-domain map-
pings.
1 Introduction
The idea of metaphor as cross-domain map-
ping goes back, at least, to Black (1954), who
made explicit an earlier implicit view that lin-
guistic metaphors depend upon non-linguistic
(i.e., conceptual) connections between networks
of concepts. Black?s premises were later em-
ployed to represent groups of related linguistic
metaphoric expressions using non-linguistic con-
ceptual metaphors (for example, Reddy, 1979,
and Lakoff & Johnson, 1980). Inherent in this
approach to representing metaphor is the idea
that metaphor is, at its core, a matter of cross-
domain mapping (e.g., Lakoff, 1993); in other
words, metaphor is a cognitive process that builds
or maps connections between networks of con-
cepts. The study of cognitive metaphor processes
has largely focused on content-specific representa-
tions of such mappings within a number of content
domains, such as TIME and IDEAS. Thus, a cross-
domain mapping may be represented as something
like ARGUMENT IS WAR.
Computational approaches to metaphor, how-
ever, have represented cross-domain mappings
using higher-level properties like abstractness
(Gandy, et al., 2013; Assaf, et al., 2013; Tsvetkov,
et al., 2013; Turney, et al., 2011), semantic
similarity (Li & Sporleder, 2010; Sporleder &
Li, 2010), domain membership (Dunn, 2013a,
2013b), word clusters that represent semantic sim-
ilarity (Shutova, et al. 2013; Shutova & Sun,
2013), and selectional preferences (Wilks, 1978;
Mason, 2004). Most of these approaches rely
on some concept of abstractness, whether directly
(e.g., in terms of abstractness ratings) or indi-
rectly (e.g., in terms of clusters containing abstract
words). Further, these approaches have viewed ab-
stractness as a one-dimensional scale between ab-
stract and concrete concepts, with metaphor cre-
ating mappings from concrete source concepts to
abstract target concepts.
Although both theoretical and computational
treatments of metaphor depend upon the concept
of abstractness, little has been done to either de-
fine or operationalize the notion. To fill this gap,
this paper puts forward a multi-dimensional def-
inition of abstractness and implements it in order
to test the usefulness of the dimensions of abstract-
ness for detecting cross-domain mappings.
2 Multi-dimensional abstractness
This approach recognizes four dimensions of ab-
stractness: Domain of the Referent, Domain of
the Sense, Fact-Status, and Function-Status, each
of which has a range of values from more ab-
stract to less abstract, as shown in Table 1. Do-
main refers to top-level categories in a hierarchi-
cal ontology as in, for example, ontological se-
mantics (Nirenburg & Raskin, 2004), which uses
four top-level domains: PHYSICAL, MENTAL, SO-
CIAL, ABSTRACT. Each concept belongs within a
certain domain so that, at the highest level, cross-
domain mappings can be represented as mappings
between, for example, a PHYSICAL concept and
an ABSTRACT concept. This dimension corre-
sponds most with the traditional one-dimensional
27
approach to abstractness.
Here we divide domain membership into two
types: (i) Domain of the Sense and (ii) Domain
of the Referent. The idea is that a concept may
refer to an object in one domain but define prop-
erties of that concept relative to another domain.
For example, the concept teacher refers to a PHYS-
ICAL object, a human who has physical proper-
ties. At the same time, the concept teacher is de-
fined or distinguished from other humans in terms
of SOCIAL properties, such as being focused on
the education of students. Thus, the referent of
the concept is within the PHYSICAL domain but
its sense is within the SOCIAL domain. This is
also true, for example, of countries (e.g., Mexico)
which refer to a PHYSICAL location but also to a
SOCIAL entity, the government and people who
reside in that physical location. It is important
to distinguish sense and reference when searching
for cross-domain mappings because many con-
cepts inherently map between different domains in
this way (and yet are not considered metaphoric).
Within both types of Domain, ABSTRACT is the
category with the highest abstractness and PHYSI-
CAL with the least abstractness.
Fact-Status is an ontological property as op-
posed to a domain within a hierarchical ontol-
ogy. It represents the metaphysical property of
a concept?s dependence on human consciousness
(Searle, 1995). In other words, PHYSICAL-FACTS
are those, like rocks and trees, which exist in the
external world independent of human perceptions.
NON-INTENTIONAL facts are involuntary human
perceptions such as pain or fear. INTENTIONAL
facts are voluntary products of individual human
consciousness such as ideas and opinions. COL-
LECTIVE facts are products of the consciousness
of groups of humans, such as laws and govern-
ments. Thus, all categories except for PHYSICAL-
FACTS are dependent on human consciousness.
NON-INTENTIONAL and INTENTIONAL facts de-
pend only on individuals, and in this sense are less
abstract than COLLECTIVE facts, which exist only
if a group of humans agrees to recognize their ex-
istence. This dimension of abstractness measures
how dependent on human consciousness and how
socially-constructed a concept is, with COLLEC-
TIVE facts being more socially-constructed (and
thus more society-dependent) than the others.
The final dimension of abstractness is Function-
Status, which reflects how embedded function in-
Property Value
Domain of the Referent Abstract
Mental
Social
Physical
Domain of the Sense Abstract
Mental
Social
Physical
Fact-Status Collective
Intentional
Non-Intentional
Physical
Function Institutional
Physical-Use
Non-Agentive
None
Event-Status Object
State
Process
Animacy Human
Animate
Inanimate
Undefined
Table 1: Concept properties and values.
formation is in the sense of a concept. Function in-
formation is human-dependent, being present only
as assumed by humans; thus, this dimension is
also related to how human-centric a particular con-
cept is. Many concepts have no function informa-
tion embedded in them, for example rock or tree,
and these are the least human-dependent. Some
concepts have NON-AGENTIVE functions, some-
times called NATURAL functions; for example, the
function of a heart is to pump blood. Some con-
cepts have PHYSICAL-USE functions, in which the
embedded function is a reflection of how humans
use a physical object; for example, the function
of a hammer is to drive nails. Finally, many
concepts have embedded within them INSTITU-
TIONAL functions, those which perform a social
function only insofar as a group of individuals
agree that the social function is performed. For
example, a group of individuals may declare that
certain taxes will be collected on income; but if
others do not consent to the performance of that
function then it is not performed (e.g., if the group
had no legal authority to do so). Thus, INSTITU-
TIONAL functions have the highest abstractness.
28
In addition to these dimensions of abstract-
ness, two properties are added in order to test
how they interact with these dimensions of ab-
stractness: Event-Status, distinguishing OBJECTS
from STATES and PROCESSES, and Animacy, dis-
tinguishing HUMANS from ANIMATE non-humans
and INANIMATE objects.
3 Implementation
The system has two main steps: first, the input
text is mapped to concepts in the Suggested Up-
per Merged Ontology (Niles & Pease, 2001); sec-
ond, features based on the ontological properties
of these concepts are used to represent the input
sentences as a feature vector. The text is processed
using Apache OpenNLP for tokenization, named
entity recognition, and part of speech tagging.
Morpha (Minnen, et al., 2001) is used for lemma-
tization. At this point word sense disambiguation
is performed using SenseRelate (Pedersen & Kol-
hatkar, 2009), mapping the lexical words to the
corresponding WordNet senses. These WordNet
senses are first mapped to SynSets and then to con-
cepts in the SUMO ontology, using existing map-
pings (Niles & Pease, 2003). Thus, the input to
the second part of the system is the set of SUMO
concepts which are pointed to by the input text.
The properties of these concepts are contained in
a separate knowledge-base developed for this sys-
tem and available from the author. Each concept
in SUMO has a value for each of the concept prop-
erties. This value is fixed and is the same across all
instances of that concept. Thus, SenseRelate dis-
ambiguates input text into WordNet synsets which
are mapped onto SUMO concepts, at which point
the mapping from concepts to concept properties
is fixed.
Feature Type Number
Relative value frequency 23
Main value / concepts 6
Other values / concepts 6
Number of value types 6
Total 41
Table 2: Concept properties and values.
The concept properties discussed above are
used to create a total of 41 features as shown in Ta-
ble 2: First, 23 features contain the total number of
instances of each possible value for the properties
in each sentence relative to the number of concepts
present. Second, 6 features contain the relative fre-
quency of the most common values of a property
(the ?main? value) and 6 features the relative fre-
quency of all the other values (the ?other? value).
Third, 6 features contain the number of types of
property values present in a sentence relative to the
number of possible types.
4 Evaluation of the Features
We evaluated these features in a binary classifi-
cation task using the VU Amsterdam Metaphor
Corpus (Steen, et al., 2010), which consists of
200,000 words from the British National Corpus
divided into four genres (academic, news, fiction,
and spoken; the spoken genre was not evaluated)
and annotated by five linguists. Metaphorically
used prepositions have been untagged, as have
ambiguously metaphoric sentences. Non-sentence
fragments have been removed (e.g., titles and by-
lines), along with very short sentences (e.g., ?He
said.?).
The first step was to evaluate the features
individually for their usefulness in detecting
metaphoric language, allowing us to ask theoreti-
cal questions about which dimensions of abstract-
ness are most related to metaphor. The Classifier-
SubSetEval feature in Weka (Hall, et al., 2009)
was used with the logistic regression classifier
on the full corpus with 10 fold cross-validation.
Three different search algorithms were used to en-
sure that the best possible combination of vari-
ables was found: the Greedy Stepwise, Linear For-
ward Selection, and Rank Search algorithms. The
final feature rating was computed by taking the re-
verse ranking given by the GreedyStepwise search
(e.g., the top ranked feature out of 41 is given a
41) and adding the number of folds for which that
feature was selected by the other two algorithms.
Table 3 below shows the top variables, arranged
by score.
An interesting finding from this selection pro-
cess is that each of the concept properties made the
list of the top 16 features in the form of the Prop-
erty: Other feature. In other words, the number of
minority values for each property is useful for de-
tecting cross-domain mappings. Next, each of the
values for the Function property was a top feature,
while only two of the Domain-Sense and one of
the Domain-Referent properties made the list. The
properties of Animacy and Fact are represented by
the number of types present in the utterance, and
29
Property Feature Score
Function Other Values 45.5
Fact-Status Other Values 41
Animacy Types 39.1
Fact-Status Collective 37.8
Event-Status Other Values 31
Function Non-Agentive 30.6
Animacy Other Values 29.8
Function Physical-Use 29.8
Fact-Status Types 28.3
Domain-Sense Abstract 27.1
Domain-Sense Other Values 25.1
Domain-Sense Mental 22.1
Domain-Referent Social 21.8
Function None 20.5
Function Institutional 17.1
Domain-Referent Other Values 12.8
Table 3: Top features.
Fact is also significant for the number of concepts
with the Collective value. These are interesting,
and unexpected, findings, because the most im-
portant properties for detecting metaphor are not
the traditional Domain-defined notions of abstract-
ness, either Sense or Referent, but rather those
notions of abstractness which are tied to a con-
cept?s degree of dependence on human conscious-
ness and degree of being socially-constructed.
Using these top 16 variables, a binary classifi-
cation task was performed on the entire VU Am-
sterdam Corpus, prepared as described above, us-
ing the logistic regression algorithm with 10 fold
cross-validation, giving the results shown below
in Table 4. These results show that while the full
set of 41 features performs slightly better than the
select set of the top 16, the performance gain is
fairly small. For example, the F-measure on the
full corpus raises from 0.629, using only the top
16 variables, to 0.649 using the full set of 41 vari-
ables. Thus, a similar performance is achieved
much more efficiently (at least, in terms of the
evaluation of the feature vectors; the top 16 vari-
ables still require many of the other variables in or-
der to be computed). More importantly, this shows
that the different dimensions of abstractness can
be used to detect cross-domain mappings, licens-
ing the inference that each of these operationaliza-
tions of abstractness represents an important and
independent property of cross-domain mappings.
Var. Corpus Prec. Recall F1
Select Full 0.655 0.629 0.629
All Full 0.672 0.691 0.649
Select Academic 0.655 0.682 0.600
All Academic 0.639 0.676 0.626
Select Fiction 0.595 0.597 0.592
All Fiction 0.642 0.642 0.642
Select News 0.749 0.813 0.743
All News 0.738 0.808 0.746
Table 4: Results of evaluation.
5 Relation between the dimensions of
abstractness
In order to determine the relationship between
these dimensions of abstractness, to be sure that
they are not measuring only a single scale, prin-
cipal components analysis was used to determine
how many distinct groups are formed by the prop-
erties and their values. The written subset of the
American and Canadian portions of the Interna-
tional Corpus of English, consisting of 44,189 sen-
tences, was used for this task. The corpus was
not annotated for metaphor; rather, the purpose
is to find the relation between the features across
both metaphor and non-metaphor, using the direct
oblimin rotation method.
# Main Features CL. Vari.
1 Domain-Sense: Types .834 18.7%
Domain-Ref.: Types .816
Event-Status: Types .808
2 Fact-Status: Main .778 14.2%
Fact-Status: Physical .774
3 Domain-Sense: Physical .509 11.1%
Domain-Ref.: Physical .548
Event-Status: Object .451
4 Fact-Status: Intentional .990 10.6%
Fact-Status: Collective .990
Fact-Status: Other .913
5 Domain-Sense: Abstract .997 6.6%
Domain-Ref.: Abstract .997
6 Domain-Sense: Main .851 5.8%
Domain-Ref.: Main .773
7 Function: Physical-Use .876 4.4%
8 Event-Status: Process .574 3.6%
9 Animacy: Main .800 2.9%
10 Function: Non-Agentive .958 2.4%
Table 5: Grouped features.
30
This procedure identified 10 components with
eigenvalues above 1 containing unique highest
value features, accounting for a cumulative 83.2%
of the variance. These components are shown in
Table 5 along with the component loadings of the
main features for each component and the amount
of variance which the component explains. All
features with component loadings within 0.100 of
the top feature are shown.
These components show two important results:
First, the division of the Domain property into
Sense and Referent is not necessary because the
two are always contained in the same compo-
nents; in other words, these really constitute a
single-dimension of abstractness. Second, Do-
main, Function, and Fact-Status are not contained
in the same components, but rather remain distin-
guishable dimensions of abstractness.
The important point of this analysis of the rela-
tions between features is that, even for those sys-
tems which do not represent abstractness in this
way (e.g., systems which use numeric scales in-
stead of nominal attributes), the dimensions of ab-
stractness used here do represent independent fac-
tors. In other words, there is more than one dimen-
sion of abstractness. Domain membership, which
corresponds most closely to the traditional one-
dimensional view, refers essentially to how con-
crete or physical a concept is. Thus, love is more
abstract than grass, but no distinction is possible
between love and war. Fact-Status refers to how
dependent on human consciousness a concept is.
PHYSICAL concepts do not depend upon humans
in order to exist. Thus, PHYSICAL concepts will be
represented with the same degree of abstractness
by both the Domain and Fact-Status properties.
However, Fact-Status adds distinctions between
abstract concepts. For example, ideas are not
physical, but laws are both non-physical and de-
pend upon complex social agreements. Function-
Status refers to how much of the definition of a
concept is dependent upon Function information
which is, ultimately, only present in human un-
derstandings of the concept. This dimension adds
distinctions between even physical concepts. For
example, canes are just as physical as sticks, but
cane embeds function information, that the object
is used to help a human to walk, and this function
information is dependent upon human conscious-
ness. These two additional and distinguishable di-
mensions of abstractness, then, operationalize how
dependent a concept is on human consciousness
and how socially-constructed it is.
Using the traditional one-dimensional approach
to abstractness, not all metaphors have abstract tar-
get concepts. For example, in the metaphoric ex-
pressions ?My car drinks gasoline? and ?My sur-
geon is a butcher,? the concepts CAR and SUR-
GEON are both PHYSICAL concepts in terms of
Domain, and thus not abstract. And yet these con-
cepts are the targets of metaphors. However, the
concept DRINKING, according to this system, has
an INTENTIONAL Fact-Status, because it is an ac-
tion which is performed purposefully, and thus is
an action which only sentient beings can perform.
It is more abstract, then, than a verb like uses,
which would not be metaphoric. The second ex-
ample, however, cannot be explained in this way,
as both SURGEON and BUTCHER would have the
same concept properties (they are not included in
the knowledge-base; both map to HUMAN). This
phrase occurs only twice in the 450+ million word
Corpus of Contemporary American English, how-
ever, and represents a rare exception to the rule.
6 Conclusions
This paper has examined the notion of abstract-
ness, an essential component of many theoreti-
cal and computational approaches to the cross-
domain mappings which create metaphoric lan-
guage. There are two important findings: First,
of the four posited dimensions of abstractness,
three were shown to be both (1) members of
separate components and (2) useful for detecting
metaphoric mappings. These three dimensions,
Domain Membership, Fact-Status, and Function-
Status, are different and distinguishable ways of
defining and operationalizing the key notion of
abstractness. Second, and perhaps more impor-
tantly, the Fact-Status and Function-Status di-
mensions of abstractness, which are not directly
present in the traditional one-dimensional view
of abstractness, were shown to be the most use-
ful for detecting metaphoric mappings. Al-
though more evidence is needed, this suggests
that cross-domain mappings are mappings from
less socially-constructed source concepts to more
socially-constructed target concepts and from less
consciousness-dependent source concepts to more
consciousness-dependent target concepts. This
multi-dimensional approach thus provides a more
precise definition of abstractness.
31
References
Assaf, D., Neuman, Y., Cohen, Y., Argamon, S.,
Howard, N., Last, M., Koppel, M. 2013. Why ?dark
thoughts? aren?t really dark: A novel algorithm for
metaphor identification. 2013 IEEE Symposium on
Computational Intelligence, Cognitive Algorithms,
Mind, and Brain: 60?65. Institute of Electrical and
Electronics Engineers.
Black, M. 1954. Metaphor. Proceedings of the Aris-
totelian Society, New Series, 55: 273-294.
Dunn, J. 2013a. Evaluating the premises and results of
four metaphor identification systems. Proceedings
of the 14th International Conference on Computa-
tional Linguistics and Intelligent Text Processing,
Volume I: 471-486. Berlin, Heidelberg: Springer-
Verlag.
Dunn, J. 2013b. What metaphor identification systems
can tell us about metaphor-in-language. Proceed-
ings of the First Workshop on Metaphor in NLP: 1-
10. Association for Computational Linguistics.
Gandy, L., Allan, N., Atallah, M., Frieder, O., Howard,
N., Kanareykin, S., Argamon, S. 2013. Automatic
Identification of Conceptual Metaphors With Lim-
ited Knowledge. Proceedings of the 27th Confer-
ence on Artificial Intelligence: 328?334. Associa-
tion for the Advancement of Artificial Intelligence.
Hall, M., Frank, E., Holmes, G., Pfahringer, B., Reute-
mann, P., Witten, I. H. 2009. The WEKA data min-
ing software. ACM SIGKDD Explorations Newslet-
ter, 11(1): 10.
Lakoff, G. 1993. The contemporary theory of
metaphor. Metaphor and thought, 2nd edition: 202-
251. Cambridge, UK: Cambridge Univ Press.
Lakoff, G., Johnson, M. 1980. Metaphors we live by.
Chicago: University Of Chicago Press.
Li, L., Sporleder, C. 2010a. Linguistic Cues for Distin-
guishing Literal and Non-literal Usages. Proceed-
ings of the 23rd International Conference on Com-
putational Linguistics: Posters: 683-691. Associa-
tion for Computational Linguistics.
Li, L., Sporleder, C. 2010b. Using Gaussian Mix-
ture Models to Detect Figurative Language in Con-
text. Human Language Technologies: The 2010 An-
nual Conference of the North American Chapter of
the Association for Computational Linguistics: 297?
300. Association for Computational Linguistics.
Mason, Z. 2004. CorMet: A Computational, Corpus-
Based Conventional Metaphor Extraction System.
Computational Linguistics, 30(1), 23-44.
Minnen, G., Carroll, J., Pearce, D. 2001. Applied
morphological processing of English. Natural Lan-
guage Engineering, 7(3), 207-223.
Niles, I., Pease, A. 2001. Towards a standard upper
ontology. Proceedings of the International Confer-
ence on Formal Ontology in Information Systems:
2-9. Association for Computing Machinery.
Niles, I., Pease, A. 2003. Linking lexicons and on-
tologies: Mapping WordNet to the Suggested Upper
Merged Ontology. Proceedings of the 2003 Inter-
national Conference on Information and Knowledge
Engineering: 412-416. World Congress in Com-
puter Science, Computer Engineering, and Applied
Computing.
Nirenburg, S., Raskin, V. 2004. Ontological Seman-
tics. Cambridge, MA: MIT Press.
Pedersen, T., Kolhatkar, V. 2009.
WordNet::SenseRelate::AllWords?A broad cover-
age word sense tagger that maximimizes semantic
relatedness. Proceedings of Human Language
Technologies: The 2009 Annual Conference of the
North American Chapter of the Association for
Computational Linguistics, Companion Volume:
Demonstration Session: 17-20. Association for
Computational Linguistics.
Reddy, M. 1979. The conduit metaphor: A case
of frame conflict in our language about language.
Metaphor and Thought, 1st edition: 284-310. Cam-
bridge, UK: Cambridge Univ Press.
Searle, J. 1995. The construction of social reality. New
York: The Free Press.
Shutova, E., Sun, L. 2013. Unsupervised Metaphor
Identification using Hierarchical Graph Factoriza-
tion Clustering. Proceedings of Human Language
Technologies: The 2013 Annual Conference of the
North American Chapter of the Association for
Computational Linguistics: 978-988. Association
for Computational Linguistics.
Shutova, E., Teufel, S., Korhonen, A. 2013. Statis-
tical Metaphor Processing. Computational Linguis-
tics, 39(2), 301-353.
Steen, G. J., Dorst, A. G., Herrmann, J. B., Kaal, A. A.,
Krennmayr, T. 2010. Metaphor in usage. Cognitive
Linguistics, 21(4), 765-796.
Tsvetkov, Y., Mukomel, E., Gershman, A. 2013.
Cross-Lingual Metaphor Detection Using Common
Semantic Features. Proceedings of the First Work-
shop on Metaphor in NLP: 45-51. Association for
Computational Linguistics.
Turney, P. D., Neuman, Y., Assaf, D., Cohen, Y.
2011. Literal and Metaphorical Sense Identifica-
tion Through Concrete and Abstract Context. Pro-
ceedings of the Conference on Empirical Methods
in Natural Language Processing: 680-690. Associ-
ation for Computational Linguistics.
Wilks, Y. 1978. Making preferences more active. Ar-
tificial Intelligence, 11(3), 197-223.
32
