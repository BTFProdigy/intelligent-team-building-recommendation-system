Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 321?324,
Uppsala, Sweden, 15-16 July 2010.
c
?2010 Association for Computational Linguistics
HeidelTime: High Quality Rule-based Extraction and Normalization of
Temporal Expressions
Jannik Str
?
otgen
Institute of Computer Science
University of Heidelberg
Heidelberg, Germany
stroetgen@uni-hd.de
Michael Gertz
Institute of Computer Science
University of Heidelberg
Heidelberg, Germany
gertz@uni-hd.de
Abstract
In this paper, we describe HeidelTime, a
system for the extraction and normaliza-
tion of temporal expressions. HeidelTime
is a rule-based system mainly using regu-
lar expression patterns for the extraction of
temporal expressions and knowledge re-
sources as well as linguistic clues for their
normalization. In the TempEval-2 chal-
lenge, HeidelTime achieved the highest F-
Score (86%) for the extraction and the best
results in assigning the correct value at-
tribute, i.e., in understanding the seman-
tics of the temporal expressions.
1 Introduction
Temporal annotation of documents, i.e., the ex-
traction and chronological ordering of events, is
crucial to many NLP applications, e.g., text sum-
marization or machine translation. In this paper,
we describe our system HeidelTime for the extrac-
tion and normalization of temporal expressions in
English documents. It was the best-performing
system in Task A for English of the TempEval-
2 challenge
1
. The purpose of this challenge was
to evaluate different systems for temporal tagging
as well as event and temporal relation extraction
since a competitive evaluation helps to drive for-
ward research, and temporal annotation is impor-
tant for many NLP tasks (Pustejovsky and Verha-
gen, 2009). The annotation scheme for tempo-
ral expressions, events, and relations is based on
TimeML, the ISO standard for temporal annota-
tion
2
.
Before using temporal information in other ap-
plications is possible, the first task to solve is to ex-
tract and normalize temporal expressions (Task A
of the challenge, annotated as Timex3). There
1
http://semeval2.fbk.eu/
2
http://www.timeml.org/
are two types of approaches to address this prob-
lem: rule-based and machine learning ones. We
decided to develop a rule-based system since nor-
malization can then be supervised in a much eas-
ier way. Furthermore, respective systems allow for
modular extensions.
Although we only participated in Task A, we do
not consider the extraction and normalization of
temporal expressions in isolation, but use temporal
information in combination with other extracted
facts, e.g., for the exploration of spatio-temporal
information in documents (Str?otgen et al, 2010).
One of our primary objectives is therefore to de-
velop a system that can be used in other scenar-
ios without any adaptations. Thus, we implement
HeidelTime as a UIMA
3
(Unstructured Informa-
tion Management Architecture) component to in-
tegrate the system into our existing document pro-
cessing pipeline. Another advantage of our tem-
poral tagger is that the user can choose between
a precision- and a recall-optimized rule set. In
the TempEval-2 challenge, both rule sets achieved
top scores in the extraction (F-scores of 86%) and
the precision-optimized set achieved the best re-
sults for assigning the correct value attributes to
the temporal expressions (85% accuracy).
The remainder of the paper is structured as fol-
lows: The system architecture is outlined in the
next section. In Section 3, we present the evalua-
tion results of HeidelTime in comparison to other
systems that participated in the challenge. We con-
clude our paper in Section 4.
2 System Architecture
In this section, the system architecture of Heidel-
Time is explained. First, UIMA and our UIMA-
based document processing pipeline are detailed,
followed by a description of the extraction and
normalization tasks, the functionality of the rules
3
http://uima.apache.org/
321
? ?
TempEval?2data
?????????rule?design?workflow???????????????task?workflow
Collection?Readers
TempEval?2?Reader
other?heterogeneoussources
otherCollection?Readers
Analysis?Engines
Sentence?Splitter
Tokenizer
POS?Tagger
HeidelTime
CAS?Consumers
TempEval?2File?Writer TempEval?2Evaluator otherConsumers
UIMA
?Docu
ment
?
Proc
essin
g?Pip
eline
other?Analysis?Engines
Figure 1: UIMA pipeline with two workflows, one
for rule design and one for using HeidelTime.
and the post-processing steps.
2.1 Document Processing Pipeline
HeidelTime is developed as a UIMA component
so that we are able to integrate our temporal tagger
into our existing document processing pipeline. It
is an extension of the temporal tagger we already
use for the extraction and exploration of spatio-
temporal information in documents (Str?otgen et
al., 2010). UIMA is widely used for process-
ing unstructured content such as audio, images, or
text. Different components can be combined to
create a pipeline of modular tools, and all com-
ponents use the same data structure, the Common
Analysis Structure (CAS). This allows to combine
tools that were not originally built to be used to-
gether, an advantage we are using for preprocess-
ing tasks as well.
In general, a UIMA pipeline consists of three
types of components, a Collection Reader for ac-
cessing the documents from a source and initializ-
ing a CAS object for each document. The analy-
sis of the documents is performed by Analysis En-
gines that add annotations to the CAS objects. Fi-
nally, CAS Consumers are used for final process-
ing, e.g., for storing the annotated information in
a database or performing an evaluation.
In Figure 1, the document processing pipeline
for designing and using our temporal tagger Hei-
delTime is depicted. The design workflow (left
arrows) contains the TempEval-2 Reader, which
reads the TempEval-2 data, initializes a CAS ob-
ject for each textual document and adds the anno-
tated data to the CAS. For the test set of the tem-
poral expression task, these include the sentence
and token information, and for the training set
also the gold standard Timex3 entities. Next, the
OpenNLP part-of-speech tagger
4
is used, which
assigns the corresponding part-of-speech (POS)
tag to each token. The information about sen-
tences, tokens, and POS tags is then used by
our temporal tagger HeidelTime for extracting and
normalizing temporal expressions mentioned in
the documents. The CAS Consumer TempEval-
2 File Writer is used for creating the files needed
for applying the scorer and which had to be sub-
mitted for evaluation. During the rule develop-
ment phase of HeidelTime, the CAS Consumer
TempEval-2 Evaluator was used, which compares
the gold standard Timex3 annotations with the
Timex3 annotations extracted by HeidelTime, re-
sulting in lists of true positives, false positives,
and false negatives. These lists were then used for
adapting existing or creating new rules.
On the right-hand side of Figure 1, a workflow
for using HeidelTime in other scenarios is shown.
This workflow reflects the fact that temporal tag-
ging is just one intermediate component of our
document processing pipeline. Here, the docu-
ments have to be split into sentences and tokens
using the two analysis engines Sentence Splitter
and Tokenizer. The POS tagger and HeidelTime
are used in the same way as described for the other
workflow. In addition, other Analysis Engines can
be used, e.g., for combining the extracted tempo-
ral information with spatial information. Finally,
CAS Consumers are used, e.g., for storing the
spatio-temporal information in a database.
2.2 Extraction and Normalization Tasks
Every temporal expression te can be viewed as
a three-tuple te
i
= ?e
i
, t
i
, v
i
?, where e
i
is the
expression itself as it occurs in the textual docu-
ment, t
i
represents the type of the expression, and
v
i
is the normalized value. There are four possi-
ble types, namely Date, Time, Duration, and Set.
The normalized value represents the temporal se-
mantics of an expression as it is specified by the
markup language TimeML, regardless of the ex-
pression used in the document. The goal of Hei-
delTime is to extract for every temporal expression
the expression e
i
and to correctly assign the type
and value attributes t
i
and v
i
, respectively.
For this, HeidelTime uses hand-crafted rules,
4
http://opennlp.sourceforge.net
322
Expression
resources
reMonth = ?(. . . |June|July|. . . )?
reSeason = ?(. . . |summer|. . . )?
Normalization
functions
normMonth(?June?) = ?06?
normSeason(?summer?) = ?SU?
Table 1: Examples for extraction and normaliza-
tion resources for months and seasons.
which are grouped into four types, namely the four
possible types of temporal expressions. More pre-
cisely, every rule is a triple of an expression rule,
a normalization function and the type information.
The extraction rules mainly consist of regular ex-
pression patterns. However, other features can be
used as well, e.g., a constraint what part-of-speech
the previous or next token has to have. Heidel-
Time contains resources for both the extraction
and the normalization tasks of the rules. For in-
stance, there are resources for weekdays, months,
or seasons, which are realized as regular expres-
sions and can be accessed by multiple extraction
rules. In addition, there are knowledge resources
for the normalization of such expressions. Exam-
ples are given in Table 1.
Algorithm 1 illustrates how rules are used in
HeidelTime. First, the rules are applied to ev-
ery sentence of a document, and extracted timexes
are added to the CAS object. Then, two post-
processing steps are executed to disambiguate un-
derspecified values and to remove invalid tempo-
ral expressions from the CAS. This functionality
is detailed in the next sections with a focus on the
linguistic clues for the normalization task.
Algorithm 1 ApplyRules.
foreach sentence in document
addDatesToCAS(date rules, CAS);
addTimesToCAS(time rules, CAS);
addDurationsToCAS(dur rules, CAS);
addSetsToCAS(set rules, CAS);
end foreach
foreach timex3 in CAS
disambiguateValues(CAS);
end foreach
removeInvalidsFromCAS(CAS);
2.3 Functionality of HeidelTime
There are many ways to textually describe tem-
poral expressions, either explicitly, implicitly or
relatively (Schilder and Habel, 2001). The extrac-
tion for all temporal expressions works in the same
way, but assigning the value attributes has to be
done differently. Explicit temporal expressions are
fully specified, i.e., the value attribute can directly
explicit temporal expressions
date r1 = (reMonth)
g1
(reDay)
g2
, (reFullY ear)
g3
norm r1(g1,g2,g3) = g3-normMonth(g1)-normDay(g2)
implicit temporal expressions
date r2 = (reHoliday)
g1
(reFullY ear)
g2
norm r2(g1,g2) = g2-normHoliday(g1)
Table 2: Extraction parts and normalization parts
of two sample rules.
be assigned using the corresponding normalization
function of the rule. For example, the explicit ex-
pression March 11, 1982 can be extracted with the
rule date r1 of Table 2 containing the resources
reMonth, reDay, and reFullY ear (regular ex-
pressions for possible month, day and year tokens
of a date phrase, respectively). The matched to-
kens can be accessed using the group ids so that
the normalization function can be called with the
extracted tokens resulting in the value 1982-03-11.
The value attribute of implicit expressions can
be assigned once the implicit temporal semantics
of such expressions is known. Holidays, for ex-
ample, can be extracted using date r2 with the
resource reHoliday and normalized using the
knowledge resource for normalization as shown in
Table 2. An example is Independence Day 2010
to which the value 2010-07-04 is assigned.
The normalization of relative expressions for
which a reference time is needed is the most chal-
lenging task. Examples are last June, just June
in phrases such as in June, or year-earlier in the
year-earlier results. To such expressions, Hei-
delTime assigns the values in an underspecified
format depending on the assumed reference time
and disambiguates them in a post-processing step.
The underspecified values for the examples are
UNDEF-last-June, UNDEF-June, and UNDEF-
REF-last-year, respectively. For the first two ex-
amples, the document creation time (dct) is as-
sumed to be the reference time while for the last
example the previously mentioned date is used for
reference. In news texts (as used in TempEval-2)
the dct is meaningful while other documents may
not contain such a reference time. Then, the previ-
ously mentioned date is used for all underspecified
values. The disambiguation of such expressions is
detailed in the next section.
2.4 Post-Processing
The first post-processing step is to disambiguate
underspecified value attributes (see Algorithm 1).
If the value starts with UNDEF-REF, the pre-
323
viously mentioned date is used for disambigua-
tion, otherwise the document creation time (dct)
if meaningful. The value UNDEF-last-June of
the previous section is disambiguated by calcu-
lating the June before the dct. More complex
are even less underspecified values like UNDEF-
June. Here, linguistic knowledge is used to dis-
ambiguate which June is meant: The tense of the
sentence is determined by using the part-of-speech
information of the tokens and checking the seman-
tics of the verbs in the sentence. This method iden-
tifies whether a sentence is past, present, or fu-
ture tense. E.g., the tense of the sentence In June,
new results will be published will be determined
to be future tense and the new value UNDEF-next-
June can be assigned instead of UNDEF-last-June
if past tense was identified. Such values are then
disambiguated using the methods described above.
If the reference time is assumed to be the
previously mentioned date all previous extracted
Timex3 are checked to be of the type Date. The
value v
ref
of the closest previously mentioned
date is then used for further disambiguation. For
example, UNDEF-REF-last-year is calculated by
subtracting one year from v
ref
. This can result in
a specific day but also in a specific quarter if the
last mentioned timex was a quarter.
The last post-processing step is to remove all
extracted timex annotations that are invalid. In-
valid are all expressions that are included in other
expressions. For instance, having the phrase June
11 the whole phrase is found by a rule as well as
just June. Since June is in June 11, it is removed.
3 Evaluation
In this section, we outline the evaluation of Hei-
delTime and compare our results with other sys-
tems that participated in the TempEval-2 challenge
Task A for English. For this challenge, we devel-
oped two rule sets, one precision- and one recall-
optimized set, reflecting the user?s choice between
precision and recall. The first set consists of 43
rules, 25 for dates, and 6 for times, durations, and
sets, respectively. The recall-optimized rule set
contains two more rules, one for dates and one for
durations. These rules are very general and thus
negatively influence precision.
Our results for the extraction in the two runs are
shown in Figure 2 together with the results of the
other participating systems. As one can see, both
our runs achieved the best F-score results (86%)
 
50
 
60
 
70
 
80
 
90
 
100
 
50
 
60
 
70
 
80
 
90
 
100
Prec
ision
 [%]
Recall [%]
Figure 2: Performance of participating systems
with an F-score contour for reference. Our runs
are shown as full circles.
with a precision of 90% (82%) and a recall of 82%
(91%) for the two sets.
HeidelTime, with the precision-optimized rule
set, was the best system in assigning the value at-
tributes (85% values are assigned correctly). In
addition, the type attribute was correctly assigned
to 96% of the extracted expressions.
4 Conclusions
HeidelTime achieves high quality results for the
extraction and normalization of temporal expres-
sions. The precision-optimized rule set achieved
the best results for interpreting the semantics of
the temporal expressions. In our opinion, this as-
pect, i.e., assigning the correct value attribute, is
crucial since the value is used for further analysis
of the documents, e.g., when ordering events or
doing a temporal analysis of documents.
The rule-based approach makes it possible to in-
clude further knowledge easily, e.g., to assign tem-
poral information directly to historic events.
References
James Pustejovsky and Marc Verhagen. 2009.
SemEval-2010 Task 13: Evaluating Events, Time
Expressions, and Temporal Relations (TempEval-2).
In Proceedings of the Workshop on Semantic Evalu-
ations (SEW-2009), pages 112?116. ACL.
Frank Schilder and Christopher Habel. 2001. From
Temporal Expressions to Temporal Information: Se-
mantic Tagging of News Messages. In Proceedings
of the ACL-2001 Workshop on Temporal and Spatial
Information Processing, pages 65?72. ACL.
Jannik Str?otgen, Michael Gertz, and Pavel Popov.
2010. Extraction and Exploration of Spatio-
Temporal Information in Documents. In GIR ?10,
pages 1?8. ACM.
324
Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic
Evaluation (SemEval 2013), pages 15?19, Atlanta, Georgia, June 14-15, 2013. c?2013 Association for Computational Linguistics
HeidelTime: Tuning English and Developing Spanish Resources
for TempEval-3
Jannik Stro?tgen Julian Zell Michael Gertz
Institute of Computer Science, Heidelberg University
Im Neuenheimer Feld 348, 69120 Heidelberg, Germany
{stroetgen,gertz}@uni-hd.de, j.zell@stud.uni-heidelberg.de
Abstract
In this paper, we describe our participation in
the TempEval-3 challenge. With our multi-
lingual temporal tagger HeidelTime, we ad-
dressed task A, the extraction and normaliza-
tion of temporal expressions for English and
Spanish. Exploiting HeidelTime?s strict sep-
aration between source code and language-
dependent parts, we tuned HeidelTime?s ex-
isting English resources and developed new
Spanish resources. For both languages, we
achieved the best results among all partici-
pants for task A, the combination of extraction
and normalization. Both the improved English
and the new Spanish resources are publicly
available with HeidelTime.
1 Introduction
The task of temporal annotation, which is addressed
in the TempEval-3 challenge, consists of three sub-
tasks: (A) the extraction and normalization of tem-
poral expressions, (B) event extraction, and (C) the
annotation of temporal relations (UzZaman et al,
2012). This makes sub-task A, i.e., temporal tag-
ging, a prerequisite for the full task of temporal an-
notating documents. In addition, temporal tagging
is important for many further natural language pro-
cessing and understanding tasks, and can also be ex-
ploited for search and exploration scenarios in infor-
mation retrieval (Alonso et al, 2011).
In the context of the TempEval-2 challenge (Ver-
hagen et al, 2010), we developed our temporal tag-
ger HeidelTime (Stro?tgen and Gertz, 2010), which
achieved the best results for the extraction and nor-
malization of temporal expressions for English doc-
uments. For our work on multilingual information
retrieval (e.g., Stro?tgen et al (2011)), we extended
HeidelTime with a focus on supporting the simple
integration of further languages (Stro?tgen and Gertz,
2012a). For TempEval-3, we now tuned Heidel-
Time?s English resources and developed new Span-
ish resources to address both languages that are part
of TempEval-3. As the evaluation results demon-
strate, HeidelTime outperforms the systems of all
other participants for the full task of temporal tag-
ging by achieving high quality results for the extrac-
tion and normalization for English and Spanish.
The remainder of the paper is structured as fol-
lows: We explain HeidelTime?s system architecture
in Section 2. Section 3 covers the tuning of Heidel-
Time?s English and the development of the Spanish
resources. Finally, we discuss the evaluation results
in Section 4, and conclude the paper in Section 5.
2 HeidelTime
HeidelTime is a multilingual, cross-domain tempo-
ral tagger. So far, it can process English, Ger-
man, and Dutch text. In previous work, we an-
alyzed domain-dependent challenges and demon-
strated that domain-sensitive strategies for normal-
izing temporal expressions result in significant nor-
malization improvements when switching between
news- and narrative-style documents (Stro?tgen and
Gertz, 2012b). Although TempEval-3 only ad-
dresses news documents, the tuned English and new
Spanish resources can be used to process news and
also narrative-style documents such as Wikipedia ar-
ticles with high extraction and normalization quality.
15
Architecture of HeidelTime. HeidelTime is a
rule-based system with a strict separation between
source code and language-dependent resources.
While the strategies for processing different do-
mains are part of the source code, resources con-
sist of files for (i) patterns, (ii) normalizations, and
(iii) rules. They are read by HeidelTime?s resource
interpreter and thus have to be developed based on
HeidelTime?s well-defined rule syntax.
The pattern files contain words and phrases,
which are typically used to express temporal ex-
pressions, e.g., names of months. The normaliza-
tion files contain normalization information about
the patterns, e.g., the value of a specific month?s
name. Finally, the rule files contain rules for date,
time, duration, and set expressions.
All rules have an extraction part and a normal-
ization part. The extraction part, in which the pat-
tern resources can be used for generalization, de-
fines the expressions that have to be matched in a
document. The normalization part normalizes the
context-independent content of the expression using
the normalization resources. While explicit tempo-
ral expressions (e.g., May 1st, 2013) can directly
be fully normalized, underspecified (November) and
relative (today, two weeks ago) expressions can only
be normalized in an underspecified manner. The full
normalization depends on the domain of the docu-
ment that is to be processed and the context of the
expression. For this, HeidelTime applies domain-
sensitive strategies to normalize such expressions
during its disambiguation phase, which is called af-
ter the extraction and the normalization phases.
The TempEval-3 data is from the news domain.
Here, HeidelTime usually uses the document cre-
ation time as reference time. The temporal relation
to it is identified based on the tense in the sentence.1
Preprocessing. HeidelTime requires sentence, to-
ken, and part-of-speech information. For this, the
TreeTagger (Schmid, 1994) is used. Since there is
a Spanish model for the TreeTagger, adding Spanish
preprocessing capabilities to HeidelTime was fairly
easy. A wrapper for the TreeTagger is also part of
the UIMA HeidelTime kit described next.
1For further details on HeidelTime?s rule syntax, its domain-
dependent normalization strategies, and its architecture in gen-
eral, we refer to Stro?tgen and Gertz (2012a).
UIMA HeidelTime kit. For processing Temp-
Eval-3 data, we used the UIMA version of Heidel-
Time, developed a collection reader and a CAS con-
sumer to read and write TempEval-3 input and out-
put data, and added both components to our UIMA
HeidelTime kit. This makes HeidelTime?s evalua-
tion results reproducible on the training and test sets.
3 HeidelTime for TempEval-3
In TempEval-3, we participated with one Spanish
and three English runs: For Spanish, we used our
newly developed resources. For English, we used
(i) HeidelTime 1.2, which was released in May
2012, (ii) a version containing several bug fixes and
improvements, which were implemented indepen-
dently from TempEval-3, and (iii) HeidelTime with
its new English resources tuned for TempEval-3.
In general, our goal when developing HeidelTime
resources is to achieve high quality normalization re-
sults. Thus, we only want to extract temporal ex-
pressions which can be normalized correctly with
high probability ? an issue, which will be further
looked at in the discussion in the evaluation section.
Before that, we next describe language-independent
adaptations to HeidelTime. Then, we present the
tuning of the English resources (Section 3.2) and the
development of the Spanish resources (Section 3.3).
3.1 General HeidelTime Adaptations
We performed the following language-independent
changes to HeidelTime:
(i) Weekday normalization: In news-style doc-
uments, extracted weekdays that are equal to the
weekday of the document creation time (dct) are
now normalized to the date of the dct independent
of the tense in the sentence.
(ii) Century/decade normalization: So far, decade
and century expressions were not correctly normal-
ized by HeidelTime according to TimeML, e.g.,
?199X? instead of ?199? for ?the 1990s?.
The first change is based on the intuitive assump-
tion that information in news-style documents is
temporally focused around the dct. In addition,
this assumption is supported by the English and the
Spanish training data. The second change is related
to the annotation standard. Both changes can thus
be generalized in a language-independent manner.
16
3.2 Tuning HeidelTime?s English Resources
Three training corpora were provided by the orga-
nizers: the Aquaint and TimeBank gold standard
corpora, and a large corpus referred to as silver stan-
dard, which was created by merging results of three
tools (Llorens et al, 2012). After a brief analysis,
we decided not to use the silver standard due to the
rather low annotation quality. Motivated by observa-
tions in the gold standard corpora, we performed the
following English-specific modifications in addition
to the general adaptations described above:
(i) REF-value expressions: expressions normal-
ized to past, present, or future are not consistently
annotated in the training data. Since such expres-
sions are rather less valuable for further tasks and
to avoid false positives, we removed some of those
patterns from the resources.
(ii) Ambiguous expressions: We added negative
rules for expressions such as may, march, and fall to
filter them out if they do not refer to a date.
(iii) Article/modifier: We allowed some more
combinations of articles and modifiers.
Note that HeidelTime was already a state-of-the-
art tool for English temporal tagging so that the
changes are rather minor.
3.3 Developing Spanish Resources
In this section, we explain the resource develop-
ment process for Spanish. Then, we detail language-
specific challenges we faced during this process.
Resource Development Process. So far, there
were no HeidelTime resources for Spanish, and we
thus started the development from scratch.
(i) Preprocessing: As mentioned in Section 2, we
use the TreeTagger with its Spanish module for sen-
tence, token, and part-of-speech annotation.
(ii) Translation of pattern files: Starting with Hei-
delTime?s English pattern resources, we developed
the Spanish pattern resources. The goal was that all
patterns that are frequently used to express tempo-
ral expressions are included in the resources. Note
that it is not important that the patterns are context
independent. The context in which a pattern should
occur can be defined within the rules.
(iii) Translation of normalization files: Similar to
the patterns, we translated the English normalization
files and adapted them to the new Spanish patterns.
(iv) Rule Development: Based on the English
rules for dates, times, durations, and sets, we de-
veloped similar Spanish rules. Using the Spanish
training corpus to check for partially matching pat-
terns, false positives, false negatives, and incorrect
normalizations, we then iteratively adapted the rules,
but also the pattern and normalization resources.
Challenges. Spanish as a Romance language is
rich in inflection. Nouns, adjectives, and determin-
ers are inflected with respect to number and gender.
During the development of the pattern and normal-
ization resources, this had to be taken into account.
As for nouns, there are many inflection forms of
verbs in Spanish, e.g., to represent tense. While
verbs are usually not part of temporal expressions,
the inflection of verbs has to be considered for the
normalization of ambiguous expressions such as el
lunes (Monday) or junio (June). As mentioned
above, in news-style documents, HeidelTime uses
the tense of the sentence to determine the relation
to the reference time, i.e., to decide whether the ex-
pression refers to a previous or upcoming date.
The tense is determined using part-of-speech in-
formation, and, if necessary, pattern information of
words with specific part-of-speech tags. For each
language, this information is defined in the pattern
resources. Unfortunately, the Spanish tag-set of the
TreeTagger module does not contain tags covering
tense information, e.g., all finite lexical verbs are
tagged as VLfin. Thus, we created regular expres-
sion patterns to match typical inflection patterns rep-
resenting tense information and check words tagged
as verbs by the tagger for these patterns.
However, due to the ambiguity of the Spanish in-
flection, we can only add patterns to detect future
tense. If no tense is identified, the year is set to the
year of the reference time. As detailed in the discus-
sion of the evaluation results described in Section 4,
identifying the correct relation to the reference time
is a frequent source of normalization errors.
4 Evaluation Results
Measures. For the extraction task, precision (P),
recall (R), and f1-score (F1) are used for strict and
relaxed matching. The value F1 and type F1 mea-
sures combine relaxed matching with correct nor-
malization. Systems are ranked by value F1 (value).
17
strict match relaxed match normalization
a) Aquaint P R F1 P R F1 value type
tuned 80.17 81.69 80.92 90.85 92.57 91.7 72.37 83.32
bug-fixed 77.56 81.17 79.32 88.28 92.40 90.30 70.21 82.03
1.2 73.32 81.17 77.05 83.46 92.40 87.70 67.87 79.67
b) TimeBank P R F1 P R F1 value type
tuned 85.39 84.15 84.76 92.16 90.83 91.49 79.01 88.74
bug-fixed 83.17 82.70 82.94 90.86 90.35 90.60 76.24 87.78
1.2 82.89 82.62 82.76 90.72 90.43 90.57 76.39 87.75
c) Spanish P R F1 P R F1 value type
new 90.53 81.26 85.65 96.23 86.38 91.04 84.10 89.40
Table 1: Results on training data ranked by value F1.
Results on Training Data. Table 1 shows the re-
sults on the Aquaint (a), TimeBank (b), and Spanish
training corpora (c). On both English corpora, Hei-
delTime?s TempEval-3 tuned version outperforms
the other two versions. The big differences between
the two English corpora are rather due to the better
annotation quality of TimeBank than due to different
challenges in the documents of the two corpora.
TempEval-3 Evaluation. The evaluation results
on the test data are presented in Table 2. For English,
HeidelTime?s TempEval-3 tuned version achieves
the best results, and all three HeidelTime versions
outperform the systems of the eight other partici-
pating teams with a total number of 21 submissions
(task A ranking measure value F1). For comparison,
the results of the next best system (NavyTime) is
listed in Table 2(a). For Spanish, we highly outper-
form the other two systems, as shown in Table 2(b).
Discussion. In order to be able to interpret Hei-
delTime?s results on the training and test data, we
performed an error analysis (TimeBank and Spanish
training corpus). The most important findings are:
(i) For a rule-based system, HeidelTime?s recall
is relatively low (many false negatives; FN). How-
ever, note that several FN are intentional. 55% and
29% of 117 and 149 FN in the English and Span-
ish training corpora are due to imprecise expressions
(some time; the latest period). These are difficult
to normalize correctly, e.g., some time can refer to
seconds or years. To guarantee high quality normal-
ization, we do not extract expressions that cannot be
normalized correctly with high probability.
(ii) There is a trade-off between precision and re-
call due to expressions referring to past, present, or
future (X REF). These are annotated either only in
some contexts or inconsistently throughout the train-
strict match relaxed match normalization
a) English P R F1 P R F1 value type
tuned 83.85 78.99 81.34 93.08 87.68 90.30 77.61 82.09
bug-fixed 80.77 76.09 78.36 90.00 84.78 87.31 72.39 79.10
1.2 80.15 76.09 78.07 89.31 84.78 86.99 72.12 78.81
next best* 78.72 80.43 79.57 89.36 91.30 90.32 70.97 80.29
b) Spanish P R F1 P R F1 value type
HeidelTime 90.91 80.40 85.33 96.02 84.92 90.13 85.33 87.47
TipSemB 88.51 77.39 82.57 93.68 81.91 87.40 71.85 82.04
jrc-1/2 65.83 39.70 49.53 86.67 52.26 65.20 50.78 62.70
Table 2: TempEval-3 task A evaluation results ranked by
value F1 (* next best: NavyTime).
ing data, and thus result in FN (21%/en; 34%/es) and
false positives (43% of 98 FP in English training and
43%/es of 35 FP in Spanish training corpora).
(iii) The main sources for incorrect value normal-
ization of underspecified expressions (Feb. 1; Mon-
day) are wrongly detected reference times or rela-
tions to them (e.g., due to wrong tense identifica-
tion), annotation errors in the corpora (e.g., last week
annotated as WXX instead of the week it is referring
to), granularity errors (e.g., a year ago can refer to a
day, month, quarter, or year), and ambiguities (e.g.,
the year can be a duration or a specific year).
(iv) Some expressions in the Spanish test set were
extracted and normalized correctly although no sim-
ilar expressions exist in the Spanish training data.
Here, the Spanish resources highly benefited from
the high quality English resources as starting point
of the development process, and from HeidelTime?s
language-independent normalization strategies.
(v) A reoccurring error in the English test set
is that HeidelTime matches and normalizes expres-
sions such as two days earlier while only two days
should be annotated according to TimeML. This re-
sults in a relaxed match with false type and value.
5 Conclusions & Ongoing Work
In this paper, we presented HeidelTime?s results in
the TempEval-3 temporal tagging task. For both lan-
guages, English and Spanish, we achieved the best
results of all participants (value F1). We showed that
adding a new language to HeidelTime can result in
high quality temporal tagging of the new language.
Currently, we are working on improving the Span-
ish tense detection to better normalize underspec-
ified temporal expressions. Furthermore, we will
make available HeidelTime resources for Arabic,
Italian, and Vietnamese (HeidelTime, 2013).
18
References
Omar Alonso, Jannik Stro?tgen, Ricardo Baeza-Yates, and
Michael Gertz. 2011. Temporal Information Re-
trieval: Challenges and Opportunities. In Proceedings
of the 1st International Temporal Web Analytics Work-
shop (TWAW 2011), pages 1?8.
HeidelTime. 2013. http://code.google.com/p/heideltime/.
Hector Llorens, Naushad UzZaman, and James F. Allen.
2012. Merging Temporal Annotations. In 19th Inter-
national Symposium on Temporal Representation and
Reasoning, TIME 2012, pages 107?113.
Helmut Schmid. 1994. Probabilistic Part-of-Speech Tag-
ging Using Decision Trees. In Proceedings of the In-
ternational Conference on New Methods in Language
Processing.
Jannik Stro?tgen and Michael Gertz. 2010. HeidelTime:
High Quality Rule-Based Extraction and Normaliza-
tion of Temporal Expressions. In Proceedings of the
5th International Workshop on Semantic Evaluation
(SemEval?10), pages 321?324.
Jannik Stro?tgen and Michael Gertz. 2012a. Multilingual
and Cross-domain Temporal Tagging. Language Re-
sources and Evaluation, Online first.
Jannik Stro?tgen and Michael Gertz. 2012b. Temporal
Tagging on Different Domains: Challenges, Strate-
gies, and Gold Standards. In Proceedings of the 8th
International Conference on Language Resources and
Evaluation, pages 3746?3753.
Jannik Stro?tgen, Michael Gertz, and Conny Junghans.
2011. An Event-centric Model for Multilingual Doc-
ument Similarity. In Proceeding of the 34rd Interna-
tional ACM SIGIR Conference on Research and De-
velopment in Information Retrieval (SIGIR?11), pages
953?962.
Naushad UzZaman, Hector Llorens, James F. Allen,
Leon Derczynski, Marc Verhagen, and James Puste-
jovsky. 2012. TempEval-3: Evaluating Events,
Time Expressions, and Temporal Relations. CoRR,
abs/1206.5333.
Marc Verhagen, Roser Sauri, Tommaso Caselli, and
James Pustejovsky. 2010. SemEval-2010 Task
13: TempEval-2. In Proceedings of the 5th In-
ternational Workshop on Semantic Evaluation (Sem-
Eval?10), pages 57?62.
19
