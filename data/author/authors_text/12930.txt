Proceedings of the 8th Workshop on Asian Language Resources, pages 88?94,
Beijing, China, 21-22 August 2010. c?2010 Asian Federation for Natural Language Processing
Word Segmentation for Urdu OCR System 
Misbah Akram 
National University of Computer 
and Emerging Sciences  
misbahakram@gmail.com 
Sarmad Hussain 
Center for Language Engineering,  
Al-Khawarizmi Institute of Computer 
Science, University of Engineering and 
Technology, Lahore, Pakistan 
sarmad.hussain@kics.edu.pk 
 
Abstract 
This paper presents a technique for word 
segmentation for the Urdu OCR system. 
Word segmentation or word tokeniza-
tion is a preliminary task for Urdu lan-
guage processing. Several techniques 
are available for word segmentation in 
other languages. A methodology is pro-
posed for word segmentation in this pa-
per which determines the boundaries of 
words given a sequence of ligatures, 
based on collocation of ligatures and 
words in the corpus. Using this tech-
nique, word identification rate of 
96.10% is achieved, using trigram prob-
abilities normalized over the number of 
ligatures and words in the sequence. 
1 Introduction 
Urdu uses Nastalique style of Arabic script 
for writing, which is cursive in nature.  Charac-
ters join together to form ligatures, which end 
either with a space or with a non-joining charac-
ter.  A word may be composed of one of more 
ligatures.  In Urdu, space is not used to separate 
two consecutive words in a sentence; instead 
readers themselves identify the boundaries of 
words, as the sequence of ligatures, as they read 
along the text. Space is used to get appropriate 
character shapes and thus it may even be used 
within a word to break the word into constituent 
ligatures (Naseem 2007, Durrani 2008). There-
fore, like other languages (Theeramunkong & 
Usanavasin, 2001; Wan and Liu, 2007; Khanka-
sikam & Muansuwan, 2005; Haruechaiyasak et 
al., 2008; Haizhou & Baosheng, 1998), word 
segmentation or word tokenization is a prelimi-
nary task for Urdu language processing. It has 
applications in many areas like spell checking, 
POS tagging, speech synthesis, information re-
trieval etc. This paper focuses on the word seg-
mentation problem from the point of view of 
Optical Character Recognition (OCR) System. 
As space is not visible in typed and scanned text, 
spacing cues are not available to the OCR for 
word separation and therefore segmentation has 
to be done more explicitly. This word segmenta-
tion model for Urdu OCR system takes input in 
the form of a sequence of ligatures recognized 
by an OCR to construct a sequence of words 
from them.   
2 Literature Review 
Many languages, e.g., English, French, 
Hindi, Nepali, Sinhala, Bengali, Greek, Russian, 
etc. segment text into a sequence of words using 
delimiters such as space, comma and semi colon 
etc., but on the other hand many Asian languag-
es like Urdu, Persian, Arabic, Chinese, 
Dzongkha, Lao and Thai have no explicit word 
boundaries. In such languages, words are seg-
mented using more advanced techniques, which 
can be categorized into three methods:   
 
(i) Dictionary/lexicon based approaches  
(ii) Linguistic knowledge based approaches  
(iii) Machine learning based approach-
es/statistical approaches  
(Haruechaiyasak et al, 2008) 
 
Longest matching (Poowarawan, 1986; Richard 
Sproat, 1996) and maximum matching (Sproat 
et al, 1996; Haizhou & Baosheng, 1998) are 
examples of lexicon based approaches. These 
techniques segment text using the lexicon. Their 
88
accuracy depends on the quality and size of the 
dictionary. 
N-Grams (Chang et al, 1992; Li Haizhou 
et al, 1997; Richard Sproat, 1996; Dai & Lee, 
1994; Aroonmanakun, 2002) and Maximum 
collocation (Aroonmanakun, 2002) are Linguis-
tic knowledge based approaches, which also 
rely very much on the lexicon. These approach-
es select most likely segmentation from the set 
of possible segmentations using a probabilistic 
or cost-based scoring mechanism. 
Word segmentation using decision trees 
(Sornlertlamvanich et al, 2000; Theeramun-
kong & Usanavasin, 2001) and similar other 
techniques fall in the third category of word 
segmentation techniques. These approaches use 
a corpus in which word boundaries are explicit-
ly marked. These approaches do not require dic-
tionaries. In these approaches ambiguity prob-
lems are handled by providing a sufficiently 
large set of training examples to enable accurate 
classification. 
A knowledge based approach has been 
adopted for earlier work on Urdu word segmen-
tation (Durrani 2007; also see Durrani and Hus-
sain 2010). In this technique word segmentation 
of Urdu text is achieved by employing know-
ledge based on the Urdu linguistics and script. 
The initial segmentations are ranked using min-
word, unigram and bigram techniques. It reports 
95.8 % overall accuracy for word segmentation 
of Urdu text. Mukund et al (2009) propose us-
ing character model along with linguistic rules 
and report 83% precision.  Lehal (2009) propos-
es a two stage process, which first uses Urdu 
linguistic knowledge, and then uses statistical 
information of Urdu and Hindi (also using 
transliteration into Hindi) in the second stage 
for words not addressed in the first stage, re-
porting an accuracy of 98.57%.   
These techniques use characters or words in 
the input, whereas an OCR outputs a series of 
ligatures.  The current paper presents work done 
using statistical methods as an alternative, 
which works with ligatures as input.   
3 Methodology 
Current work uses the co-occurrence in-
formation of ligatures and words to construct a 
statistical model, based on manually cleaned 
and segmented training corpora.  Ligature and 
word statistics are derived from these corpora. 
In the decoding phase, first all sequences of 
words are generated from input set of ligatures 
and ranking of these sequences is done based on 
lexical lookup. Top k sequences are selected for 
further processing, based on the number of valid 
words. Finally, the probability of each of the k 
sequences is calculated for the final decision. 
Details are described in the subsequent sections. 
3.1 Data collection and preparation 
An existing lexicon of 49630 unique words 
is used (derived from Ijaz et al 2007). The cor-
pus used for building ligature grams consists of 
half a million words. Of these, 300,000 words 
are taken from the Sports, Consumer Informa-
tion and Culture/Entertainment domains of the 
18 million word corpus (Ijaz et al 2007), 
100,000 words are obtained from Urdu-Nepali-
English Parallel Corpus (available at 
www.PANL10n.net), and another 100,000 
words are taken from a previously POS tagged 
corpus (Sajjad, 2007; tags of this corpus are re-
moved before further processing).  This corpus 
is manually cleaned for word segmentation er-
rors, by adding missing spaces between words 
and replacing spaces with Zero Width Non-
Joiner (ZWNJ) within words.  For the computa-
tion of word grams, the 18 million word corpus 
of Urdu is used (Ijaz et al 2007). 
3.2 Count and probability calculations 
Table 1 and Table 2 below give the counts 
for unigram, bigrams and trigram of the liga-
tures and the words derived from the corpora 
respectively. 
 
Ligature 
Tokens 
Ligature 
Unigram 
Ligature 
Bigrams 
Ligature 
Trigrams 
1508078 10215 35202 65962 
Table 1. Unigram, bigram and trigram counts of 
the ligature corpus 
Word 
Tokens 
Word 
Unigrams 
Word 
Bigrams 
Word 
Trigrams 
17352476 157379 1120524 8143982 
Table 2. Unigram, bigram and trigram counts of 
the word corpus 
After deriving word unigrams, bigrams, 
and trigrams, the following cleaning of corpus is 
89
performed.  In the 18 million word corpus, cer-
tain words are combined due to missing space, 
but are separate words. Some of these words 
occur with very high frequency in the corpus. 
For example ?????? (ho ga, ?will be?) exists as 
single word rather than two words due to miss-
ing space. To solve this space insertion problem, 
a list of about 700 words with frequency greater 
than 50 is obtained from the word unigrams. 
Each word of the list is manually reviewed and 
space is inserted, where required. Then these 
error words are removed from the word unigram 
and added to the word unigram frequency list as 
two or three individual words incrementing re-
spective counts.  
For the space insertion problem in word 
bigrams, each error word in joined-word list 
(700-word list) is checked. Where these error 
words occurs in a bigram word frequency list, 
for example ???? ????? (kiya ho ga ?will have 
done?) exists in the bigram list and contains 
????" " error word, then this bigram entry ???? ????? 
is removed from the bigram list and counts of 
? ?? ?? ? and ???? ??? are increased by the count of 
???? ?????. If these words do not exist in the word 
bigram list then they are added as a new bi-
grams with the count of ???? ?????. Same proce-
dure is performed for the word trigrams. 
The second main issue is with word-affixes, 
which are sometimes separated by spaces from 
the words. Therefore, in calculations, these are 
treated as separate words and exist as bigram 
entries in the list rather than a unigram entry. 
For example "??? ???" (sehat+mand, ?healthy?) 
exists as a bigram entry but in Urdu it is a single 
word.  To cope with this problem, a list of 
word-affixes is used. If any entry of word bi-
gram matches with an affix, then this word is 
combined by removing spurious space from it 
(and inserting ZWNJ, if required to maintain its 
glyph shape). Then this word is inserted in the 
unigram list with its original bigram count and 
unigram list updated accordingly. Same proce-
dure is performed if a trigram word matches 
with an affix.  
After cleaning, unigram, bigram and tri-
gram counts for both words and ligatures are 
calculated.  To avoid data sparseness One Count 
Smoothing (Chen & Goodman, 1996) is applied.  
3.3 Word sequences generation from input 
The input, in the form of sequence of liga-
tures is used to generate all possible words.  
These sequences are then ranked based on real 
words. For this purpose, a tree of these se-
quences is incrementally built. The first ligature 
is added as a root of tree, and at each level two 
to three additional nodes are added. For exam-
ple the second level of the tree contains the fol-
lowing tree nodes. 
? Current ligature forms a separate word, se-
parated with space, from the sequence at its 
parent, l1 l2 
? Current ligature concatenates, without a 
space, with the sequence at its parent, l1l2 
? Current ligature concatenates, without a 
space, with the sequence at its parent but 
with an additional, l1ZWNJl2  
For each node, at each level of the tree, a nu-
meric value is assigned, which is the sum of 
squares of the number of ligatures in each word 
which is in the dictionary.  If a word does not 
exist in dictionary then it does not contribute to 
the total sum. If a node-string has only one word 
and this word does not occur in the dictionary as 
a valid word then it is checked that this word 
may occur at the start of any dictionary entry. In 
this case numeric value is also assigned.   
After assignment, nodes are ranked ac-
cording to these values and best k (beam value) 
nodes are selected. These selected nodes are 
further ranked using statistical methods dis-
cussed below. 
3.4 Best word segmentation selection 
For selection of the most probable word 
segmentation sequence word and ligature mod-
els are used.  For word probabilities the follow-
ing is used. 
PW =      argmax ? SPw  
To reduce the complexity of computing, Mar-
kov assumption are taken to give bigram and 
trigram approximations (e.g., see Jurafsky & 
Martin 2006) as given below. 
PW =      argmax ? S? P w|w            PW =      argmax ? S? Pw|ww