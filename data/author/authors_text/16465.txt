Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 569?578,
Gothenburg, Sweden, April 26-30 2014.
c?2014 Association for Computational Linguistics
Semi-supervised learning of morphological paradigms and lexicons
Malin Ahlberg
Spr?akbanken
University of Gothenburg
malin.ahlberg@gu.se
Markus Forsberg
Spr?akbanken
University of Gothenburg
markus.forsberg@gu.se
Mans Hulden
University of Helsinki
mans.hulden@helsinki.fi
Abstract
We present a semi-supervised approach
to the problem of paradigm induction
from inflection tables. Our system ex-
tracts generalizations from inflection ta-
bles, representing the resulting paradigms
in an abstract form. The process is in-
tended to be language-independent, and
to provide human-readable generalizations
of paradigms. The tools we provide can
be used by linguists for the rapid cre-
ation of lexical resources. We evaluate the
system through an inflection table recon-
struction task using Wiktionary data for
German, Spanish, and Finnish. With no
additional corpus information available,
the evaluation yields per word form ac-
curacy scores on inflecting unseen base
forms in different languages ranging from
87.81% (German nouns) to 99.52% (Span-
ish verbs); with additional unlabeled text
corpora available for training the scores
range from 91.81% (German nouns) to
99.58% (Spanish verbs). We separately
evaluate the system in a simulated task of
Swedish lexicon creation, and show that
on the basis of a small number of inflection
tables, the system can accurately collect
from a list of noun forms a lexicon with in-
flection information ranging from 100.0%
correct (collect 100 words), to 96.4% cor-
rect (collect 1000 words).
1 Introduction
Large scale morphologically accurate lexicon con-
struction for natural language is a very time-
consuming task, if done manually. Usually, the
construction of large-scale lexical resources pre-
supposes a linguist who constructs a detailed mor-
phological grammar that models inflection, com-
pounding, and other morphological and phonolog-
ical phenomena, and additionally performs a man-
ual classification of lemmas in the language ac-
cording to their paradigmatic behavior.
In this paper we address the problem of lexicon
construction by constructing a semi-supervised
system that accepts concrete inflection tables as in-
put, generalizes inflection paradigms from the ta-
bles provided, and subsequently allows the use of
unannotated corpora to expand the inflection ta-
bles and the automatically generated paradigms.
1
In contrast to many machine learning ap-
proaches that address the problem of paradigm ex-
traction, the current method is intended to produce
human-readable output of its generalizations. That
is, the paradigms provided by the system can be
inspected for errors by a linguist, and if neces-
sary, corrected and improved. Decisions made by
the extraction algorithms are intended to be trans-
parent, permitting morphological system develop-
ment in tandem with linguist-provided knowledge.
Some of the practical tasks tackled by the sys-
tem include the following:
? Given a small number of known inflection ta-
bles, extract from a corpus a lexicon of those
lemmas that behave like the examples pro-
vided by the linguist.
? Given a large number of inflection tables?
such as those provided by the crowdsourced
lexical resource, Wiktionary?generalize the
tables into a smaller number of abstract
paradigms.
2 Previous work
Automatic learning of morphology has long been a
prominent research goal in computational linguis-
tics. Recent studies have focused on unsupervised
methods in particular?learning morphology from
1
Our programs and the datasets used, including the
evaluation procedure for this paper, are freely avail-
able at https://svn.spraakbanken.gu.se/clt/
eacl/2014/extract
569
unlabeled data (Goldsmith, 2001; Schone and Ju-
rafsky, 2001; Chan, 2006; Creutz and Lagus,
2007; Monson et al., 2008). Hammarstr?om and
Borin (2011) provides a current overview of unsu-
pervised learning.
Previous work with similar semi-supervised
goals as the ones in this paper include Yarowsky
and Wicentowski (2000), Neuvel and Fulop
(2002), Cl?ement et al. (2004). Recent machine
learning oriented work includes Dreyer and Eis-
ner (2011) and Durrett and DeNero (2013), which
documents a method to learn orthographic trans-
formation rules to capture patterns across inflec-
tion tables. Part of our evaluation uses the same
dataset as Durrett and DeNero (2013). Eskander
et al. (2013) shares many of the goals in this paper,
but is more supervised in that it focuses on learn-
ing inflectional classes from richer annotation.
A major departure from much previous work
is that we do not attempt to encode variation
as string-changing operations, say by string edits
(Dreyer and Eisner, 2011) or transformation rules
(Lind?en, 2008; Durrett and DeNero, 2013) that
perform mappings between forms. Rather, our
goal is to encode all variation within paradigms
by presenting them in a sufficiently generic fash-
ion so as to allow affixation processes, phonolog-
ical alternations as well as orthographic changes
to naturally fall out of the paradigm specification
itself. Also, we perform no explicit alignment of
the various forms in an inflection table, as in e.g.
Tchoukalov et al. (2010). Rather, we base our al-
gorithm on extracting the longest common subse-
quence (LCS) shared by all forms in an inflection
table, from which alignment of segments falls out
naturally. Although our paradigm representation
is similar to and inspired by that of Forsberg et al.
(2006) and D?etrez and Ranta (2012), our method
of generalizing from inflection tables to paradigms
is novel.
3 Paradigm learning
In what follows, we adopt the view that words
and their inflection patterns can be organized
into paradigms (Hockett, 1954; Robins, 1959;
Matthews, 1972; Stump, 2001). We essentially
treat a paradigm as an ordered set of functions
(f
1
, . . . , f
n
), where f
i
:x
1
, . . . , x
n
7? ?
?
, that is,
where each entry in a paradigm is a function from
variables to strings, and each function in a partic-
ular paradigm shares the same variables.
3.1 Paradigm representation
We represent the functions in what we call ab-
stract paradigm. In our representation, an ab-
stract paradigm is an ordered collection of strings,
where each string may additionally contain in-
terspersed variables denoted x
1
, x
2
, . . . , x
n
. The
strings represent fixed, obligatory parts of a
paradigm, while the variables represent mutable
parts. These variables, when instantiated, must
contain at least one segment, but may otherwise
vary from word to word. A complete abstract
paradigm captures some generalization where the
mutable parts represented by variables are instan-
tiated the same way for all forms in one particu-
lar inflection table. For example, the fairly simple
paradigm
x
1
x
1
+s x
1
+ed x
1
+ing
could represent a set of English verb forms, where
x
1
in this case would coincide with the infinitive
form of the verb?walk, climb, look, etc.
For more complex patterns, several variable
parts may be invoked, some of them discontinu-
ous. For example, part of an inflection paradigm
for German verbs of the type schreiben (to write)
verbs may be described as:
x
1
+e+x
2
+x
3
+en INFINITIVE
x
1
+e+x
2
+x
3
+end PRESENT PARTICIPLE
ge+x
1
+x
2
+e+x
3
+en PAST PARTICIPLE
x
1
+e+x
2
+x
3
+e PRESENT 1P SG
x
1
+e+x
2
+x
3
+st PRESENT 2P SG
x
1
+e+x
2
+x
3
+t PRESENT 3P SG
If the variables are instantiated as x
1
=schr,
x
2
=i, and x
3
=b, the paradigm corresponds to
the forms (schreiben, schreibend, geschrieben,
schreibe, schreibst, schreibt). If, on the other
hand, x
1
=l, x
2
=i, and x
3
=h, the same paradigm re-
flects the conjugation of leihen (to lend/borrow)?
(leihen, leihend, geliehen, leihe, leihst, leiht).
It is worth noting that in this representation, no
particular form is privileged in the sense that all
other forms can only be generated from some spe-
cial form, say the infinitive. Rather, in the cur-
rent representation, all forms can be derived from
knowing the variable instantiations. Also, given
only a particular word form and a hypothetical
paradigm to fit it in, the variable instantiations can
often be logically deduced unambiguously. For
example, let us say we have a hypothetical form
steigend and need to fit it in the above paradigm,
without knowing which slot it should occupy. We
570
may deduce that it must represent the present par-
ticiple, and that x
1
=st, x
2
=i, and x
3
=g. From this
knowledge, all other forms can subsequently be
derived.
Although we have provided grammatical in-
formation in the above table for illustrative pur-
poses, our primary concern in the current work is
the generalization from inflection tables?which
for our purposes are simply an ordered set of
word forms?to paradigms of the format dis-
cussed above.
3.2 Paradigm induction from inflection tables
The core component of our method consists of
finding, given an inflection table, the maximally
general paradigm that reflects the information in
that table. To this end, we make the assumption
that string subsequences that are shared by dif-
ferent forms in an inflection table are incidental
and can be generalized over. For example, given
the English verb swim, and a simple inflection ta-
ble swim#swam#swum,
2
we make the assump-
tion that the common sequences sw and m are ir-
relevant to the inflection, and that by disregarding
these strings, we can focus on the segments that
vary within the table?in this case the variation
i?a?u. In other words, we can assume sw and
m to be variables that vary from word to word
and describe the table swim#swam#swum as
x
1
+i+x
2
#x
1
+a+x
2
#x
1
+u+x
2
, where x
1
=sw and
x
2
=m in the specific table.
3.2.1 Maximally general paradigms
In order to generalize as much as possible from an
inflection table, we extract from it what we call the
maximally general paradigm by:
1. Finding the longest common subsequence
(LCS) to all the entries in the inflection table.
2. Finding the segmentation into variables of
the LCS(s) (there may be several) in the in-
flection table that results in
(a) The smallest number of variables. Two
segments xy in the LCS must be part of
the same variable if they always occur
together in every form in the inflection
table, otherwise they must be assigned
separate variables.
2
To save space, we will henceforth use the #-symbol as a
delimiter between entries in an inflection table or paradigm.
ring
rang
rung
[r]i[ng]
[r]a[ng]
[r]u[ng]
rng
?	Extract     LCS ?	Fit LCS      to table ?	Generalize     to paradigmsInput:inflectiontables
swim
swam
swum
swm
[sw]i[m]
[sw]a[m]
[sw]u[m]
x
1
+i+x
2
x
1
+a+x
2
x
1
+u+x
2
x
1
+i+x
2
x
1
+a+x
2
x
1
+u+x
2
?	Collapse     paradigms
x
1
+i+x
2
x
1
+a+x
2
x
1
+u+x
2
}} }}
Figure 1: Illustration of our paradigm generaliza-
tion algorithm. In step ? we extract the LCS sep-
arately for each inflection table, attempt to find
a consistent fit between the LCS and the forms
present in the table (step ?), and assign the seg-
ments that participate in the LCS variables (step
?). Finally, resulting paradigms that turn out to be
identical may be collapsed (step ?) (section 3.3).
(b) The smallest total number of infixed
non-variable segments in the inflection
table (segments that occur between vari-
ables).
3. Replacing the discontinuous sequences that
are part of the LCS with variables (every
form in a paradigm will contain the same
number of variables).
These steps are illustrated in figure 1. The
first step, extracting the LCS from a collection of
strings, is the well-known multiple longest com-
mon subsequence problem (MLCS). It is known
to be NP-hard (Maier, 1978). Although the num-
ber of strings to find the LCS from may be rather
large in real-world data, we find that a few sensible
heuristic techniques allow us to solve this problem
efficiently for practical linguistic material, i.e., in-
flection tables. We calculate the LCS by calculat-
ing intersections of finite-state machines that en-
code all subsequences of all words, using the foma
finite-state toolkit (Hulden, 2009).
3
While for most tables there is only one way
to segment the LCS in the various forms, some
ambiguous corner cases need to be resolved by
imposing additional criteria for the segmentation,
given in steps 2(a) and 2(b). As an example,
consider a snippet of a small conjugation table
for the Spanish verb comprar (to buy), com-
prar#compra#compro. Obviously the LCS is
compr?however, this can be distributed in two
different ways across the strings, as seen below.
3
Steps 2 and 3 are implemented using more involved
finite-state techniques that we plan to describe elsewhere.
571
comprar
compra
compro
{ x1
comprar
compra
compro
{
{
x1 x2(a) (b){ {x1 x2x1 {
The obvious difference here is that in the first
assignment, we only need to declare one vari-
able x
1
=compr, while in the second, we need
two, x
1
=comp, x
2
=r. Such cases are resolved by
choosing the segmentation with the smallest num-
ber of variables by step 2(a).
Remaining ambiguities are resolved by mini-
mizing the total number of infixed segments. As
an illustration of where this is necessary, consider
a small extract from the Swedish noun table segel
(sail): segel#seglen#seglet. Here, the LCS, of
which there are two of equal length (sege/segl)
must be assigned to two variables where either
x
1
=seg and x
2
=e, or x
1
=seg and x
2
=l:
segel
seglen
seglet
{ {x1 x2
segel
seglen
seglet
{ {x1 x2(a) (b)
However, in case (a), the number of infixed
segments?the l?s in the second and third form?
total one more than in the distribution in (b), where
only one e needs to be infixed in one form. Hence,
the representation in (b) is chosen in step 2(b).
The need for this type of disambiguation strat-
egy surfaces very rarely and the choice to mini-
mize infix length is largely arbitrary?although it
may be argued that some linguistic plausibility is
encoded in the minimization of infixes. However,
choosing a consistent strategy is important for the
subsequent collapsing of paradigms.
3.3 Collapsing paradigms
If several tables are given as input, and we extract
the maximally general paradigm from each, we
may collapse resulting paradigms that are identi-
cal. This is also illustrated in figure 1.
As paradigms are collapsed, we record the in-
formation about how the various variables were
interpreted prior to collapsing. That is, for the
example in figure 1, we not only store the result-
ing single paradigm, but also the information that
x
1
=r, x
2
=ng in one table and that x
1
=sw, x
2
=m
in another. This allows us to potentially recon-
struct all the inflection tables seen during learn-
Form Input Generalization
[Inf] kaufen x
1
+en
[PresPart] kaufend x
1
+end
[PastPart] gekauft ge+x
1
+t
[Pres1pSg] kaufe x
1
+e
[Pres1pPl] kaufen x
1
+en
[Pres2pSg] kaufst x
1
+st
[Pres2pPl] kauft x
1
+t
[Pres3pSg] kauft x
1
+t
[Pres3pPl] kaufen x
1
+en
. . . . . . . . .
x
1
= kauf
Table 1: Generalization from a German example
verb kaufen (to buy) exemplifying typical render-
ing of paradigms.
ing. Storing this information is also crucial for
paradigm table collection from text, fitting unseen
word forms into paradigms, and reasoning about
unseen paradigms, as will be discussed below.
3.4 MLCS as a language-independent
generalization strategy
There is very little language-specific information
encoded in the strategy of paradigm generaliza-
tion that focuses on the LCS in an inflection
table. That is, we do not explicitly prioritize
processes like prefixation, suffixation, or left-to-
right writing systems. The resulting algorithm
thus generalizes tables that reflect concatenative
and non-concatenative morphological processes
equally well. Tables 1 and 2 show the outputs of
the method for German and Arabic verb conjuga-
tion reflecting the generalization of concatenative
and non-concatenative patterns.
3.5 Instantiating paradigms
As mentioned above, given that the variable in-
stantiations of a paradigm are known, we may gen-
erate the full inflection table. The variable instan-
tiations are retrieved by matching a word form to
one of the patterns in the paradigms. For example,
the German word form b?ucken (to bend down)
may be matched to three patterns in the paradigm
exemplified in table 1, and all three matches yield
the same variable instantiation, i.e., x
1
=b?uck.
Paradigms with more than one variable may
be sensitive to the matching strategy of the vari-
ables. To see this, consider the pattern x
1
+a+x
2
and the word banana. Here, two matches are pos-
sible x
1
=b and x
2
=nana and x
1
=ban and x
2
=na.
In other words, there are three possible matching
572
Form Input Generalization
[Past1SG] katabtu (


I


.


J

?) x
1
+a+x
2
+a+x
3
+tu
[Past2SGM] katabta (


I


.


J

?) x
1
+a+x
2
+a+x
3
+ta
[Past2SGF] katabti (

I



.


J

?) x
1
+a+x
2
+a+x
3
+ti
[Past3SGM] kataba (

I
.


J

?) x
1
+a+x
2
+a+x
3
+a
[Past3SGF] katabat (


I


.


J

?) x
1
+a+x
2
+a+x
3
+at
. . . . . . . . .
[Pres1SG] aktubu (

I
.


J

?

@) a+x
1
+x
2
+u+x
3
+u
[Pres2SGM] taktubu (

I
.


J

?


K) ta+x
1
+x
2
+u+x
3
+u
[Pres2SGF] taktub??na (

	
?



J
.



J

?


K) ta+x
1
+x
2
+u+x
3
+??na
[Pres3SGM] yaktubu (

I
.


J

?

K


) ya+x
1
+x
2
+u+x
3
+u
[Pres3SGF] taktubu (

I
.


J?


K) ta+x
1
+x
2
+u+x
3
+u
. . . . . . . . .
x
1
= k (?), x
2
= t (

H), x
3
= b (H
.
)
Table 2: Generalization from an Arabic con-
jugation table involving the root /k-t-b/ from
which the stems katab (to write/past) and ktub
(present/non-past) are formed, conjugated in Form
I, past and present tenses. Extracting the longest
common subsequence yields a paradigm where
variables correspond to root radicals.
strategies:
4
1. shortest match (x
1
=b and x
2
=nana)
2. longest match (x
1
=ban and x
2
=na)
3. try all matching combinations
The matching strategy that tends to be success-
ful is somewhat language-dependent: for a lan-
guage with a preference for suffixation, longest
match is typically preferred, while for others
shortest match or trying all combinations may be
the best choice. All languages evaluated in this
article have a preference for suffixation, so in our
experiments we have opted for using the longest
match for the sake of convenience. Our imple-
mentation allows for exploring all matches, how-
ever. Even though all matches were to be tried,
?bad? matches will likely result in implausible in-
flections that can be discarded using other cues.
4 Assigning paradigms automatically
The next problem we consider is assigning the cor-
rect paradigms to candidate words automatically.
4
The number of matches may increase quickly for longer
words and many variables in the worst case: e.g. caravan
matches x
1
+a+x
2
in three different ways.
As a first step, we match the current word to a pat-
tern. In the general case, all patterns are tried for a
given candidate word. However, we usually have
access to additional information about the candi-
date words?e.g., that they are in the base form of
a certain part of speech?which we use to improve
the results by only matching the relevant patterns.
From a candidate word, all possible inflection
tables are generated. Following this, a decision
procedure is applied that calculates a confidence
score to determine which paradigm is the most
probable. The score is a weighted combination of
the following calculations:
1. Compute the longest common suffix for the
generated base form (which may be the input
form) with previously seen base forms. If of
equal length, select the paradigm where the
suffix occurs with higher frequency.
2. Compute frequency spread over the set of
unique word forms according to the follow-
ing formula:
?
w?set(W )
log(freq(w) + 1)
3. Use the most frequent paradigm as a tie-
breaker.
Step 1 is a simple memory-based approach,
much in the same spirit as van den Bosch and
Daelemans (1999), where we compare the current
base form with what we have seen before.
For step 2, let us elaborate further why the
frequency spread is computed on unique word
forms. We do this to avoid favoring paradigms
that have the same word forms for many or all
inflected forms. For example, the German noun
Ananas (pineapple) has a syncretic inflection with
one repeated word form across all slots, Ananas.
When trying to assign a paradigm to an unknown
word form that matches x
1
, it will surely fit the
paradigm that Ananas has generated perfectly
since we have encountered every word form in that
paradigm, of which there is only one, namely x
1
.
Hence, we want to penalize low variation of word
forms when assigning paradigms.
The confidence score calculated is not only ap-
plicable for selecting the most probable paradigm
for a given word-form; it may also be used to rank
a list of words so that the highest ranked paradigm
is the most likely to be correct. Examples of such
rankings are found in section 5.3.
573
0 50 100 150 200
Paradigms
0.70
0.75
0.80
0.85
0.90
0.95
1.00
Inflection table coverage
FI-NOUNS-ADJS
FI-VERBS
ES-VERBS
DE-NOUNS
DE-VERBS
Figure 2: Degree of coverage with varying num-
bers of paradigms.
5 Evaluation
To evaluate the method, we have conducted three
experiments. First we repeat an experiment pre-
sented in Durrett and DeNero (2013) using the
same data and experiment setup, but with our
generalization method. In this experiment, we
are given a number of complete inflection tables
scraped from Wiktionary. The task is to recon-
struct complete inflection tables from 200 held-out
base forms. For this task, we evaluate per form
accuracy as well as per table accuracy for recon-
struction. The second experiment is the same as
the first, but with additional access to an unlabeled
text dump for the language from Wikipedia.
In the last experiment we try to mimic the situa-
tion of a linguist starting out to describe a new lan-
guage. The experiment uses a large-scale Swedish
morphology as reference and evaluates how reli-
ably a lexicon can be gathered from a word list us-
ing only a few manually specified inflection tables
generalized into abstract paradigms by our system.
5.1 Experiment 1: Wiktionary
In our first experiment we start from the inflec-
tion tables in the development and test set from
Durrett and DeNero (2013), henceforth D&DN13.
Table 3 shows the number of input tables as well
as the number of paradigms that they result in af-
ter generalization and collapsing. For all cases,
the number of output paradigms are below 10%
of the number of input inflection tables. Figure
2 shows the generalization rate achieved with the
paradigms. For instance, the 20 most common re-
sulting German noun paradigms are sufficient to
model almost 95% of the 2,564 separate inflection
tables given as input.
As described earlier, in the reconstruction task,
the input base forms are compared to the abstract
Input: Output:
Data inflection abstract
tables paradigms
DE-VERBS 1827 140
DE-NOUNS 2564 70
ES-VERBS 3855 97
FI-VERBS 7049 282
FI-NOUNS-ADJS 6200 258
Table 3: Generalization of paradigms. The num-
ber of paradigms produced from Wiktionary in-
flection tables by generalization and collapsing of
abstract paradigms.
paradigms by measuring the longest common suf-
fix length for each input base form compared to
the ones seen during training. This approach is
memory-based: it simply measures the similarity
of a given lemma to the lemmas encountered dur-
ing the learning phase. Table 4 presents our results
juxtaposed with the ones reported by D&DN13.
While scoring slightly below D&DN13 for the
majority of the languages when measuring form
accuracy, our method shows an advantage when
measuring the accuracy of complete tables. In-
terestingly, the only case where we improve upon
the form accuracy of D&DN13 is German verbs,
where we get our lowest table accuracy.
Table 4 further shows an oracle score, giv-
ing an upper bound for our method that would
be achieved if we were always able to pick the
best fitting paradigm available. This upper bound
ranges from 99% (Finnish verbs) to 100% (three
out of five tests).
5.2 Experiment 2: Wiktionary and
Wikipedia
In our second experiment, we extend the previous
experiment by adding access to a corpus. Apart
from measuring the longest common suffix length,
we now also compute the frequency of the hy-
pothetical candidate forms in every generated ta-
ble and use this to favor paradigms that generate
a large number of attested forms. For this, we
use a Wikipedia dump, from which we have ex-
tracted word-form frequencies.
5
In total, the num-
ber of word types in the Wikipedia corpus was
8.9M (German), 3.4M (Spanish), 0.7M (Finnish),
and 2.7M (Swedish). Table 5 presents the results,
5
The corpora were downloaded and extracted as de-
scribed at http://medialab.di.unipi.it/wiki/
Wikipedia_Extractor
574
Data Per D&DN13 Per D&DN13 Oracle accuracy
table form per form (per table)
DE-VERBS 68.0 85.0 97.04 96.19 99.70 (198/200)
DE-NOUNS 76.5 79.5 87.81 88.94 100.00 (200/200)
ES-VERBS 96.0 95.0 99.52 99.67 100.00 (200/200)
FI-VERBS 92.5 87.5 96.36 96.43 99.00 (195/200)
FI-NOUNS-ADJS 85.0 83.5 91.91 93.41 100.00 (200/200)
Table 4: Experiment 1: Accuracy of reconstructing 200 inflection tables given only base forms from
held-out data when paradigms are learned from the Wiktionary dataset. For comparison, figures from
Durrett and DeNero (2013) are included (shown as D&DN13).
Data Per Per Oracle acc.
table form per form (table)
DE-VERBS 76.50 97.87 99.70 (198/200)
DE-NOUNS 82.00 91.81 100.00 (200/200)
ES-VERBS 98.00 99.58 100.00 (200/200)
FI-VERBS 92.50 96.63 99.00 (195/200)
FI-NOUNS-ADJS 88.00 93.82 100.00 (200/200)
Table 5: Experiment 2: Reconstructing 200 held-
out inflection tables with paradigms induced from
Wiktionary and further access to raw text from
Wikipedia.
where an increased accuracy is noted for all lan-
guages, as is to be expected since we have added
more knowledge to the system. The bold numbers
mark the cases where we outperform the result in
Durrett and DeNero (2013), which is now the case
in four out of five tests for table accuracy, scoring
between 76.50% for German verbs and 98.00% for
Spanish verbs.
Measuring form accuracy, we achieve scores
between 91.81% and 99.58%. The smallest im-
provement is noted for Finnish verbs, which has
the largest number of paradigms, but also the
smallest corpus.
5.3 Experiment 3: Ranking candidates
In this experiment we consider a task where we
only have a small number of inflection tables,
mimicking the situation where a linguist has man-
ually entered a few inflection tables, allowed the
system to generalize these into paradigms, and
now faces the task of culling from a corpus?in
this case labeled with basic POS information?the
candidate words/lemmas that best fit the induced
paradigms. This would be a typical task during
lexicon creation.
We selected the 20 most frequent noun
paradigms (from a total of 346), with one in-
flection table each, from our gold standard, the
Top-1000 rank Correct/Incorrect
TOP 10% 100/0 (100.0%)
TOP 50% 489/11 (97.8%)
TOP 100% 964/36 (96.4%)
Table 6: Top-1000 rank for all nouns in SALDO
Swedish lexical resource SALDO (Borin et al.,
2013). From this set, we discarded paradigms
that lack plural forms.
6
We also removed from
the paradigms special compounding forms that
Swedish nouns have, since compound informa-
tion is not taken into account in this experiment.
The compounding forms are part of the original
paradigm specification, and after a collapsing pro-
cedure after compound-form removal, we were
left with a total of 11 paradigms.
In the next step we ranked all nouns in SALDO
(79.6k lemmas) according to our confidence score,
which indicates how well a noun fits a given
paradigm. We then evaluated the paradigm assign-
ment for the top-1000 lemmas. Among these top-
1000 words, we found 44 that were outside the
20 most frequent noun paradigms. These words
were not necessarily incorrectly assigned, since
they may only differ in their compound forms; as
a heuristic, we considered them correct if they had
the same declension and gender as the paradigm,
and incorrect otherwise.
Table 6 displays the results, including a total ac-
curacy of 96.4%.
Next, we investigated the top-1000 distribution
for individual paradigms. This corresponds to the
situation where a linguist has just entered a new
inflection table and is looking for words that fit the
resulting paradigm. The result is presented in two
6
The paradigms that lack plural forms are subsets of other
paradigms. In other words: when no plural forms are attested,
we would need a procedure to decide if plural forms are even
possible, which is currently beyond the scope of our method.
575
10 20 30 40 50 60 70
Top ranked H%L
2
4
6
8
10
Error rate H%L
p_kikare
p_mening
p_flicka
10 20 30 40 50 60 70
Top ranked H%L
10
20
30
40
50
60
70
Error rate H%L
p_dike
p_akademi
p_vinge
p_nyckel
Figure 3: Top-1000: high and low precision paradigms.
error rate plots: figure 3 shows the low precision
and high precision paradigms in two plots, where
error rates range from 0-2% and 16-44% for the
top 100 words.
We further investigated the worst-performing
paradigm, p akademi (academy), to determine
the reason for the high error rate for this particular
item. The main source of error (334 out of 1000) is
confusion with p akribi (accuracy), which has no
plural. However, it is on semantic grounds that the
paradigm has no plural; a native Swedish speaker
would pluralize akribi like akademi (disregard-
ing the fact that akribi is defective). The second
main type of error (210 out of 1000) is confusion
with the unseen paradigm of parti (party), which
inflects similarly to akademi, but with a differ-
ence in gender?difficult to predict from surface
forms?that manifests itself in two out of eight
word forms.
6 Future work
The core method of abstract paradigm represen-
tation presented in this paper can readily be ex-
tended in various directions. One obvious topic of
interest is to investigate the use of machine learn-
ing techniques to expand the method to completely
unsupervised learning by first clustering similar
words in raw text into hypothetical inflection ta-
bles. The plausibility of these tables could then be
evaluated using similar techniques as in our exper-
iment 2.
We also plan to explore ways to improve the
techniques for paradigm selection and ranking. In
our experiments we have, for the sake of trans-
parency, used a fairly simple strategy of suffix
matching to reconstruct tables from base forms.
A more involved classifier may be trained for this
purpose. An obvious extension is to use a clas-
sifier based on n-gram, capitalization, and other
standard features to ascertain that word forms in
hypothetical reconstructed inflection tables main-
tain similar shapes to ones seen during training.
One can also investigate ways to collapse
paradigms further by generalizing over phonolog-
ical alternations and by learning alternation rules
from the induced paradigms (Koskenniemi, 1991;
Theron and Cloete, 1997; Koskenniemi, 2013).
Finally, we are working on a separate interactive
graphical morphological tool in which we plan to
integrate the methods presented in this paper.
7 Conclusion
We have presented a language-independent
method for extracting paradigms from inflection
tables and for representing and generalizing the
resulting paradigms.
7
Central to the process of
paradigm extraction is the notion of maximally
general paradigm, which we define as the in-
flection table, with all of the common string
subsequences forms represented by variables.
The method is quite uncomplicated and outputs
human-readable generalizations. Despite the rel-
ative simplicity, we obtain state-of-the art results
in inflection table reconstruction tasks from base
forms.
Because of the plain paradigm representation
format, we believe the model can be used prof-
itably in creating large-scale lexicons from a few
linguist-provided inflection tables.
7
The research presented here was supported by the
Swedish Research Council (the projects Towards a
knowledge-based culturomics, dnr 2012-5738, and Swedish
Framenet++, dnr 2010-6013), the University of Gothenburg
through its support of the Centre for Language Technology
and its support of Spr?akbanken, and the Academy of Finland
under the grant agreement 258373, Machine learning of
rules in natural language morphology and phonology.
576
References
Lars Borin, Markus Forsberg, and Lennart L?onngren.
2013. SALDO: a touch of yin to WordNet?s yang.
Language Resources and Evaluation, May. Online
first publication; DOI 10.1007/s10579-013-9233-4.
Erwin Chan. 2006. Learning probabilistic paradigms
for morphology in a latent class model. In Proceed-
ings of the Eighth Meeting of the ACL Special Inter-
est Group on Computational Phonology and Mor-
phology, pages 69?78. Association for Computa-
tional Linguistics.
Lionel Cl?ement, Bernard Lang, Beno??t Sagot, et al.
2004. Morphology based automatic acquisition of
large-coverage lexica. In LREC 04, pages 1841?
1844.
Mathias Creutz and Krista Lagus. 2007. Unsuper-
vised models for morpheme segmentation and mor-
phology learning. ACM Transactions on Speech and
Language Processing (TSLP), 4(1):3.
Gr?egoire D?etrez and Aarne Ranta. 2012. Smart
paradigms and the predictability and complexity of
inflectional morphology. In Proceedings of the 13th
EACL, pages 645?653. Association for Computa-
tional Linguistics.
Markus Dreyer and Jason Eisner. 2011. Discover-
ing morphological paradigms from plain text using
a Dirichlet process mixture model. In Proceedings
of the Conference on Empirical Methods in Natural
Language Processing, pages 616?627. Association
for Computational Linguistics.
Greg Durrett and John DeNero. 2013. Supervised
learning of complete morphological paradigms. In
Proceedings of NAACL-HLT, pages 1185?1195.
Ramy Eskander, Nizar Habash, and Owen Rambow.
2013. Automatic extraction of morphological lex-
icons from morphologically annotated corpora. In
Proceedings of the 2013 Conference on Empirical
Methods in Natural Language Processing, pages
1032?1043. Association for Computational Linguis-
tics.
Markus Forsberg, Harald Hammarstr?om, and Aarne
Ranta. 2006. Morphological lexicon extraction
from raw text data. In Advances in Natural Lan-
guage Processing, pages 488?499. Springer.
John Goldsmith. 2001. Unsupervised learning of the
morphology of a natural language. Computational
linguistics, 27(2):153?198.
Harald Hammarstr?om and Lars Borin. 2011. Unsuper-
vised learning of morphology. Computational Lin-
guistics, 37(2):309?350.
Charles F Hockett. 1954. Two models of grammati-
cal description. Morphology: Critical Concepts in
Linguistics, 1:110?138.
Mans Hulden. 2009. Foma: a finite-state compiler and
library. In Proceedings of the 12th Conference of the
European Chapter of the European Chapter of the
Association for Computational Linguistics: Demon-
strations Session, pages 29?32, Athens, Greece. As-
sociation for Computational Linguistics.
Kimmo Koskenniemi. 1991. A discovery procedure
for two-level phonology. Computational Lexicol-
ogy and Lexicography: A Special Issue Dedicated
to Bernard Quemada, 1:451?46.
Kimmo Koskenniemi. 2013. An informal discovery
procedure for two-level rules. Journal of Language
Modelling, 1(1):155?188.
Krister Lind?en. 2008. A probabilistic model for guess-
ing base forms of new words by analogy. In Compu-
tational Linguistics and Intelligent Text Processing,
pages 106?116. Springer.
David Maier. 1978. The complexity of some problems
on subsequences and supersequences. Journal of the
ACM (JACM), 25(2):322?336.
Peter H. Matthews. 1972. Inflectional morphology:
A theoretical study based on aspects of Latin verb
conjugation. Cambridge University Press.
Christian Monson, Jaime Carbonell, Alon Lavie, and
Lori Levin. 2008. Paramor: finding paradigms
across morphology. In Advances in Multilingual
and Multimodal Information Retrieval, pages 900?
907. Springer.
Sylvain Neuvel and Sean A Fulop. 2002. Unsuper-
vised learning of morphology without morphemes.
In Proceedings of the ACL-02 workshop on Morpho-
logical and phonological learning-Volume 6, pages
31?40. Association for Computational Linguistics.
Robert H Robins. 1959. In defence of WP. Transac-
tions of the Philological Society, 58(1):116?144.
Patrick Schone and Daniel Jurafsky. 2001.
Knowledge-free induction of inflectional mor-
phologies. In Proceedings of the second meeting
of the North American Chapter of the Association
for Computational Linguistics on Language tech-
nologies, pages 1?9. Association for Computational
Linguistics.
Gregory T. Stump. 2001. A theory of paradigm struc-
ture. Cambridge University Press.
Tzvetan Tchoukalov, Christian Monson, and Brian
Roark. 2010. Morphological analysis by mul-
tiple sequence alignment. In Multilingual Infor-
mation Access Evaluation I. Text Retrieval Experi-
ments, pages 666?673. Springer.
Pieter Theron and Ian Cloete. 1997. Automatic acqui-
sition of two-level morphological rules. In Proceed-
ings of the fifth conference on Applied natural lan-
guage processing, pages 103?110. Association for
Computational Linguistics.
577
Antal van den Bosch and Walter Daelemans. 1999.
Memory-based morphological analysis. In Proceed-
ings of the 37th Annual Meeting of the Association
for Computational Linguistics, pages 285?292. As-
sociation for Computational Linguistics.
David Yarowsky and Richard Wicentowski. 2000.
Minimally supervised morphological analysis by
multimodal alignment. In Proceedings of the 38th
Annual Meeting on Association for Computational
Linguistics, pages 207?216. Association for Com-
putational Linguistics.
578
NAACL-HLT Workshop on the Induction of Linguistic Structure, pages 8?15,
Montre?al, Canada, June 3-8, 2012. c?2012 Association for Computational Linguistics
Transferring Frames: Utilization of Linked Lexical Resources
Lars Borin
Markus Forsberg
Richard Johansson
Kaarlo Voionmaa
University of Gothenburg
first.last@svenska.gu.se
Kristiina Muhonen
Tanja Purtonen
University of Helsinki
first.last@helsinki.fi
Abstract
In our experiment, we evaluate the transfer-
ability of frames from Swedish to Finnish in
parallel corpora. We evaluate both the theo-
retical possibility of transferring frames and
the possibility of performing it using avail-
able lexical resources. We add the frame in-
formation to an extract of the Swedish side
of the Kotus and JRC-Acquis corpora using
an automatic frame labeler and copy it to the
Finnish side. We focus on evaluating the re-
sults to get an estimation on how often the
parallel sentences can be said to express the
same frame. This sheds light on the questions:
Are the same situations in the two languages
expressed using different frames, i.e. are the
frames transferable even in theory? How well
can the frame information of running text be
transferred from one language to another?
1 Introduction
To our knowledge, there is no ongoing effort to cre-
ate a framenet for Finnish. This experiment gives in-
formation on whether it is feasible to build a prelimi-
nary framenet for Finnish by transferring the frames
with their lexical units from Swedish. The building
of semantically annotated language resources from
scratch is a costly and time consuming effort. In
this experiment, we test the feasibility of utilizing
Swedish and Finnish lexical resources for building a
Finnish framenet.
Transferring lexical units from Swedish to
Finnish is possible because of the wordnet connec-
tions of both languages: both the Swedish wordnet
and the Finnish wordnet are linked to the Princeton
wordnet. This connection is described in more detail
in Section 2.
We evaluate the transferability of the frames and
their lexical units from Swedish to Finnish. In the
evaluation, we use Swedish?Finnish parallel corpora
to see whether the same sentence is expressed using
the same frames in both languages. Using parallel
corpora, we can evaluate not only the theoretically
similar content of frames in two different languages,
but also their use in actual texts.
The idea of semantic role transfer across paral-
lel corpora is not novel (see Section 2.3), but to our
knowledge, the use of linked lexical resources pro-
posed here is. The language pair Swedish?Finnish
is also one for which this methodology has not
been attempted earlier. With our experiment we
can see whether transferring the frame information
from Swedish to Finnish could work, given that the
languages are not demonstrably related, and struc-
turally quite different. The work presented here
consequently provides a data point for the evalua-
tion of the language-independence of this kind of
methodology, which can arguably only be convinc-
ingly demonstrated by actually attempting to apply it
on a range of typologically diverse languages (Ben-
der, 2011).
From a more practical point of view, there may
well be as much Finnish?Swedish as Finnish?
English parallel data, since Finnish and Swedish
are the two official languages of Finland, and all
public documents must by law be available in both
languages, and for practical reasons also a large
amount of other texts. In addition, despite their non-
relatedness and large structural differences, the two
8
languages have a long history of contact and bilin-
gualism. Finnish has borrowed words and struc-
tures from Swedish on a large scale, and the lexi-
cal semantics of the two languages have converged
in many domains. This means that we may expect
frames to transfer well across the two languages,
whereas the structural differences may make us
more pessimistic about the transferability of frame
elements.
2 Language Resources
2.1 Wordnet Connections
Wordnets are lexical databases that group words of
a language into synonym sets ? or synsets ? each
synset supposedly expressing one distinct concept in
the language. Wordnets further provide general def-
initions of the synsets, and encode the semantic rela-
tions between the synsets. Typically they are mono-
lingual, but efforts have been made to produce mul-
tilingual wordnets as well; see e.g. Vossen (1998).
FinnWordNet (Lind?n and Carlson, 2010) is a
wordnet for Finnish that complies with the format
of the Princeton WordNet (PWN) (Fellbaum, 1998).
It was built by translating the Princeton WordNet 3.0
synsets into Finnish by human translators. It is open
source and contains 117 000 synsets. The Finnish
translations were inserted into the PWN structure re-
sulting in a bilingual lexical database.
SweFN++ is an integrated open-source lexical
resource for Swedish (Borin et al, 2010; Borin,
2010). It includes the Swedish framenet (SweFN)
and Swesaurus, a Swedish wordnet. The wordnet
has been semi-automatically assembled from freely
available Swedish lexical resources (Borin and Fors-
berg, 2011), and part of it has been linked to the Core
WordNet, a 5000-synset subset of PWN. All re-
sources in SweFN++ are linked together on the word
sense level using the persistent sense identifiers of
the SweFN++ pivot resource SALDO, a large-scale
lexical-semantic resource (Borin et al, 2008; Borin
and Forsberg, 2009). Using these links, we can col-
lect a set of 434 frames and 2 694 word senses that
have a direct PWN ? Swedish wordnet ? SweFN
? FinnWordNet connection. Using these connec-
tions, we can transfer the frame information of the
words from Swedish to Finnish. We used the Korp
pipeline (Borin et al, 2012) to analyze the Swedish
part of the parallel text to get hold of the SALDO
sense identifiers. The analysis is not able to distin-
guish senses that do not differentiate themselves for-
mally (by different word forms or morphosyntactic
descriptions).
2.2 Framenet and the Semantic Labeler
Framenets are lexical databases that define seman-
tic relations. The best-known framenet is Berkeley
FrameNet which is based on the theory of frame se-
mantics (Fillmore, 1976). SweFN is built using the
same principles as the Berkeley Framenet (Ruppen-
hofer et al, 2006) of English. The frames are mostly
the same as in English.
In the experiment, we use an automatic seman-
tic role labeler for Swedish, developed by Johansson
et al (2012). The labeler is based on the Swedish
framenet and it uses the same frame and frame ele-
ment labels.
2.3 Related Work
From a methodological point of view, the first
question to ask should be whether the semantic
frames are meaningful in both languages: for in-
stance, if the Swedish FrameNet has defined a frame
SELF_MOTION and a list of associated frame ele-
ments (SELF_MOVER, GOAL, PATH etc.), does it
make sense to define an identical frame in a Finnish
FrameNet? This question has been studied by Pad?
(2007) for English?German and English?French,
and although most frames were cross-linguistically
meaningful, a number of interesting discrepancies
were found. Whether the number of discrepancies is
higher in a pair of more typologically different lan-
guages is an important question.
As far as we are aware, there has been no previ-
ous attempt in using multilingual WordNets or simi-
lar lexicons when deriving lexical units in frames in
new languages. The WordNet?FrameNet combina-
tion has seen some use in monolingual applications:
for instance, Burchardt et al (2005) and Johansson
and Nugues (2007) attempted to extend the coverage
of FrameNet by making use of WordNet. Pad? and
Lapata (2005a) used word alignment in sentence-
aligned parallel corpora to find possible lexical units
in new languages.
There have been several studies of the feasibil-
ity of automatically producing the role-semantic an-
9
notation in new languages, although never for lan-
guages as structurally dissimilar as Swedish and
Finnish. Pad? and Lapata (2005b) projected anno-
tation from English to German, and Johansson and
Nugues (2006) implemented a complete pipeline for
English?Swedish by (1) automatic annotation on the
English side; (2) annotation transfer; and (3) training
a Swedish semantic role labeler using the automati-
cally produced annotation.
3 Frames from Swedish to Finnish
3.1 Outline of the Experiment
We start off by locating such Swedish word senses
that are both represented in SweFN and linked to
PWN in two Finnish?Swedish parallel corpora. The
sentences that include such a word make up the eval-
uation data set. After this, the Swedish half is en-
riched with frame labels using the framenet-based
semantic role labeler for Swedish.
After running the semantic labeler on the evalu-
ation data, we pick the 20 most commonly occur-
ring frames from both corpora. For each of the
most common frames, we pick the 6 first occur-
rences for closer scrutiny. Due to the differing na-
ture of Swedish and Finnish, we make one change
before selecting the 20 most frequent frames: We ex-
clude the frame which is evoked (erroneously) only
by the Swedish indefinite articles en/ett ? homony-
mous with the numeral ?one?? among the 6 first oc-
currences. We take the 21st most frequent frame in-
stead because there are no articles in Finnish. To
sum up, the frames under examination are selected
based on the frequency of the frame, and the sen-
tences including the frame are selected in the order
in which they occur.
After picking 120 (6 x 20) sentences from both
corpora, the correctness of the semantic labeler is
manually checked. A linguist marks the correctness
of both the frame and the frame element label. At
this stage, the linguist does not consider the trans-
ferability of the frame, but merely checks the output
of the automatic role labeler, marking the frame and
the frame element either correct or incorrect. E.g
problematic analyses caused by polysemous words
are marked incorrect. We check the output of the
labeler before analyzing the transferability of the
frames because if the frame information is incorrect
in the Swedish text to begin with, there is no point
in transferring it to Finnish.
After checking the Swedish frame information,
the Swedish?Finnish parallel sentences are com-
pared. Two native Finnish speakers estimate,
whether the frame and frame element label is trans-
ferable to Finnish or not. Because FrameNet is
based on Frame Semantics (Fillmore, 1976), accord-
ing to which the meanings of most words can best be
understood by a description of a situation, the work-
ing hypothesis is that the semantic frames should be
more or less language neutral. Hence, the semantic
frame we assign for a certain situation in Swedish,
should be transferable to Finnish.
In addition to the theoretical frame transferability,
we also report the practical applicability of the trans-
fer via the wordnet connections. We check whether
the Swedish word is expressed in the Finnish par-
allel corpus with a word that has a direct link from
the Swedish wordnet to the Finnish wordnet via the
Princeton Wordnet. If there is no direct Wordnet link
from the Swedish word to the Finnish one, we re-
port whether the Finnish word used in the sentence
and the Finnish word linked to the Swedish word via
wordnets are in the same synset.
In sum, we manually evaluate whether the 20
most commonly occurring frames of the Swedish
test sentences are the same in the equivalent Finnish
sentences. After reporting whether the frames are
equivalent in both languages, we evaluate, how
many of the frame element labels can be transferred
to Finnish.
3.2 The Test Corpora
Presumably, transferability of the frames between
parallel corpora depends on the translation of the
corpus. Our hypothesis is that if the translator
follows the original expression very carefully, the
frames can be more similar than in a more freely
translated text. To see whether the transferability of
the frames varies according to a corpus, we used two
test corpora.
The test corpora consist of extracts from the
JRC-Acquis Corpus (Steinberger et al, 2006) and
the KOTUS Swedish?Finnish Parallel Corpus (Re-
search Institute for the Languages of Finland, 2004).
Both are Swedish?Finnish parallel corpora that are
sentence aligned. In both corpora, the text type is
10
formal: the former is a collection of legislative text
and the latter consists of press releases of different
Finnish companies.
4 Results
The evaluation consists of three parts: First and
foremost, we concentrate on estimating whether the
frame used in Swedish can be transferred to Finnish
even in theory. These results are presented in Sec-
tion 4.1. If the sentence is expressed using the same
frames, we also report how many of the frame ele-
ments encoded correctly in Swedish are realized in
Finnish (Section 4.2). In Section 4.3, we discuss the
possibility of transferring the frames via the word-
net connections. The results for the two different
corpora are presented separately enabling us to see
whether the text type impacts frame transferring.
4.1 Possibility of Transferring Frames
In Tables 1 and 2, the first column lists the 20 most
frequent frames of the evaluation corpora. The sec-
ond column shows that for all 20 frames, we took
the first six Swedish occurrences. The third column
shows how many of the Swedish frame labels are
correct. Finally, the right-most column portrays how
many of the correct Swedish frames can be trans-
ferred to Finnish. The result we are mostly inter-
ested in is the difference between the third and the
fourth columns.
As can be seen from Tables 1 and 2, most of
the correct labels for Swedish are transferable to
Finnish. In the JRC-Acquis corpus, the semantic la-
beler succeeded in 75%, and 72% of the frame la-
bels can be transferred to Finnish. The correspond-
ing success rates for the Kotus corpus are 80% and
72%.
Many of the words that are not correctly labeled
in Swedish occur in idiomatic expressions, and by
chance, some idioms are so frequent in the corpus
that they end up to our evaluation corpus. E.g. the
idiom tr?da i kraft / astua voimaan / come into effect
is expressed in the same way in both Swedish and
Finnish (lit. ?tread into force?). In both languages, a
verb usually belonging to the frame SELF_MOTION
is used in this idiom, but in the idiom, the meaning
of it cannot be said to be expressing self motion.
Some sentences in which the frames are consid-
Frame N Correct Correct
in Swe in Fin
Being_necessary 6 6 6
Calendric_unit 6 6 6
Capability 6 3 3
Coming_to_believe 6 0 0
Commitment 6 6 6
Deciding 6 6 6
Dimension 6 5 4
Leadership 6 6 6
Part_orientational 6 4 4
Political_locales 6 6 6
Possession 6 2 1
Questioning 6 1 1
Removing 6 6 6
Request 6 6 6
Scrutiny 6 6 6
Self_motion 6 0 0
Substance 6 4 4
Suitability 6 6 5
Text 6 5 5
Using 6 6 5
Total (N) 120 90 86
Total (%) 100 75 72
Table 1: Frames from the JRC-Acquis Corpus
Frame N Correct Correct
in Swe in Fin
Assistance 6 6 6
Attempt_suasion 6 6 6
Becoming 6 6 3
Business 6 6 6
Calendric_unit 6 6 6
Capability 6 3 3
Change_position_ 6 6 5
on_a_scale_increase
Commitment 6 5 5
Create_physical_artwork 6 0 0
Create_representation 6 1 1
Deciding 6 6 6
Dimension 6 3 2
Employing 6 6 6
Leadership 6 4 4
Measure_duration 6 6 6
People 6 6 6
Possession 6 3 1
Relative_time 6 5 5
Supporting 6 6 2
Transfer 6 6 6
Total (N) 120 96 85
Total (%) 100 80 72
Table 2: Frames from the Kotus Corpus
11
ered non-transferable already on a theoretical level
are expressed in Finnish completely without the
frame, as demonstrated in Example (1) and (2).
(1) Tillv?xten
growth
var
was
dock
still
mindre
smaller
?n
than
det
the
ursprungliga
original
m?let.
goal.
Still, growth was lower than what was the origi-
nal goal.
(2) Se
it
j?i
remained
kuitenkin
still
alkuper?ist?
original
tavoitetta
goal
heikommaksi.
weaker.
However, it remained weaker than what was the
original goal.
In the Swedish example (1), the word mindre
?smaller? is used when expressing the decrease of
economical growth. The word mindre fits the frame
DIMENSION, but it is used in a figurative way. The
Finnish parallel sentence could be expressed us-
ing the direct translation pienempi ?smaller? but the
translation is different. Mindre in the Finnish Ko-
tus corpus is translated as heikompi ?weaker?, which
is not expressing dimension even in a metaphorical
way.
When focusing only on the correct Swedish la-
bels, transferring frames seems to be beneficial, as
reported in Table 3. The success rate of a theoretical
possibility to use Swedish as a source language for
Finnish frames is 92%.
Correct Transferable Success %
Frames Frames
Kotus 90 86 96%
JRC-A 96 85 89%
Total 186 171 92%
Table 3: The Success Rate of Frame Transfer
Table 3 sums up the comparison of the two cor-
pora. The difference (7%) between the corpora is
not remarkable, so based on these test corpora, the
impact of the translation type is not big. In other
words, in both corpora, the correct Swedish frames
can be transferred to Finnish successfully.
4.2 Success of Transferring Frame Elements
When the sentence is expressed using the same
frames in both languages, we also report, how many
of the frame elements encoded correctly in Swedish
are realized in Finnish. These results are presented
in Tables 4 and 5. The numbers show how benefi-
cial it is to transfer the frame element labels of the
Swedish semantic labeler to Finnish.
The most common frame elements of the Swedish
corpora are listed in the first column. We scrutinize
such elements in detail which occur in the corpora
at least four times. The rest are added up and pre-
sented on the last lines of the tables. The second
column shows the frequency of the frame element,
while the third column gives the number of correct
frame element labels in the Swedish corpora. The
last column shows the number of transferable frame
elements.
As can be seen from Table 6 that sums up the re-
sults of the frame element transfer, frame element la-
bels do not transfer from Swedish to Finnish as well
as the frame labels. The success rate of the frame
transfer is 92%, where as the frame elements can be
successfully transferred in 83% of the cases.
In the Kotus corpus, 75% of the frame element la-
bels are transferable. However, there is a difference
between the two corpora: In the JRC-Acquis corpus,
91% of the elements can be transferred to Finnish.
4.3 Transferring Frames via Wordnets
Next we report how many of the Swedish frame-
evoking words are expressed using such words that
have the same wordnet identifier in Finnish. If the
parallel sentences are not expressed using words that
are equivalent in the wordnets, we examine whether
the words are in equivalent synsets. This informa-
tion is needed when estimating the usefulness of lex-
ical resources and their internal links in the frame
transferring.
In Tables 7 and 8, the first row displays the total
number of frame-evoking words. The second row
shows how many of the frames are transferable to
Finnish even in theory. The numbers on the third
row reflect the possibility of using the WordNet con-
nections in frame transferring; this number shows
how many of the words under examination are ex-
pressed both in Swedish and in Finnish with the
equivalent wordnet words. The fourth row shows
how many of the words are not directly linked with
each other but are located in equivalent synsets. On
the fifth row, we report how many of the words are
12
Frame N Correct Correct
Element in Swe in Fin
Entity 9 8 5
Speaker 8 2 2
Item 7 3 2
Theme 6 4 4
Supported 6 2 0
Recipient 6 5 5
Place 6 2 2
Whole 5 3 3
Landmark_occasion 5 5 5
Count 5 5 5
Content 5 4 4
Time_of_creation 4 0 0
Time 4 4 3
Supporter 4 1 1
Employer 4 0 0
Cognizer 4 4 4
Agent 4 2 2
Other (32 FEs) 60 35 20
Total (N) 152 89 67
Total (%) 100 59 44
Table 4: Frame Elements from the Kotus Corpus
Frame N Correct Correct
Element in Swe in Fin
Time 10 6 9
Speaker 9 2 2
Entity 9 7 5
Instrument 7 4 4
Theme 6 6 5
Evaluee 6 6 5
Ground 5 4 3
Final_category 5 5 4
Decision 5 2 2
Topic 4 0 0
Leader 4 2 2
Landmark_occasion 4 3 3
Dependent 4 4 3
Author 4 1 1
Other (32 FEs) 66 44 39
Total (N) 148 96 87
Total (%) 66 65 58
Table 5: Frame Elements from the JRC-Acquis Corpus
Correct Transferable Success %
Frame E. Frame E.
Kotus 89 67 75%
JRC-A 96 87 91%
Total 185 154 83%
Table 6: The Success Rate of Frame Element Transfer
Frame-evoking words 120
Transferable to Finnish 85
Same word as in FWN 37
In the same synset 2
Could be in the same synset 31
Table 7: Wordnet Links in the Kotus Corpus
Frame-evoking words 120
Transferable to Finnish 86
Same word as in FWN 41
In the same synset 0
Could be in the same synset 16
Table 8: Wordnet Links in the JRC-Acquis Corpus
synonyms of the word in question and could there-
fore be located in the same synset in the wordnets.
As can be seen in Tables 7 and 8, only 46% (37/85
and 41/86) of the theoretically transferable words
can be transferred to Finnish directly using the word-
net links. Our hypothesis was that we could get bet-
ter results when looking at all the words in a synset.
This appears to be a wrong assumption: There are
only 2 words that come from the same synset that
are not equivalent words used in the translations.
The numbers on the fifth rows are remarkably big,
especially when compared to the number of real-
ized synonyms on the fourth row. These 47 words
could (or should) be located in the same synset as the
words in question. If the wordnets were complete,
i.e. if all words that could be in the same synset
were in the same synset, the theoretically transfer-
able LUs would be 82% (70/85) and 65% (56/86).
5 Conclusion and Future Work
The main point of the experiment was to see if build-
ing a preliminary Finnish framenet and labeling se-
mantic roles for Finnish using Swedish resources
is feasible at all. In particular, we wanted to see
whether the same situations are expressed using the
same frames in both languages and whether it is pos-
sible to transfer the frames and frame elements with
their lexical units from one language to the other.
In our experiment, we have evaluated how well
the frames and frame elements can be transferred
from a Swedish corpus to its Finnish parallel corpus.
We have shown that in theory, 92% of the correct
Swedish frame labels and 83% of the correct frame
13
element labels can be transferred to Finnish.
We also investigated whether linked wordnets
could be used for the transfer of frame-evoking
words between Swedish and Finnish. The results
here are more ambiguous, however. On the one
hand, only about half of the words could be linked
in this way. On the other hand, it turns out that this
in part is because of many synsets being incomplete
in these wordnets which are still under construction.
Thus we should not dismiss out of hand the useful-
ness of lexical-semantic resources such as wordnets
for the task of cross-language frame transfer, but
rather explore further how the knowledge encoded
in them could be best put to use.
The result of our experiment encourages us to find
ways of performing frame transfer automatically.
This can be accomplished using a word aligned par-
allel corpus for Swedish and Finnish. The automatic
word alignment of Finnish is generally seen as a
complicated task because of the free constituent or-
der and rich morphology of Finnish. However, our
future work is to examine the success of using au-
tomatic word alignment, e.g. Giza++, in automat-
ically transferring the frame information from one
language to another.
Acknowledgements
The research presented here was supported by the
Swedish Research Council (the project Swedish
Framenet++, VR dnr 2010-6013) and by the Uni-
versity of Gothenburg through its support of the
Centre for Language Technology and its support of
Spr?kbanken (the Swedish Language Bank). The
work on linking the Swedish wordnet to the Prince-
ton Core WordNet was conducted with funding by
the European Commission through its support of
the META-NORD project under the ICT PSP Pro-
gramme, grant agreement no 270899. We would like
to thank the anonymous reviewers for their construc-
tive comments and Jyrki Niemi for his valuable help
with FinnWordNet.
References
Emily M. Bender. 2011. On achieving and evaluating
language-independence in NLP. Linguistic Issues in
Language Technology, 6(3).
Lars Borin and Markus Forsberg. 2009. All in the fam-
ily: A comparison of SALDO and WordNet. In Pro-
ceedings of the Nodalida 2009 Workshop on WordNets
and other Lexical Semantic Resources ? between Lexi-
cal Semantics, Lexicography, Terminology and Formal
Ontologies, Odense, Denmark.
Lars Borin and Markus Forsberg. 2011. Swesaurus ? ett
svenskt ordn?t med fria tyglar. LexicoNordica, 18:17?
39.
Lars Borin, Markus Forsberg, and Lennart L?nngren.
2008. The hunting of the BLARK ? SALDO, a freely
available lexical database for Swedish language tech-
nology. In Joakim Nivre, Mats Dahll?f, and Beata
Megyesi, editors, Resourceful language technology.
Festschrift in honor of Anna S?gvall Hein, number 7
in Acta Universitatis Upsaliensis: Studia Linguistica
Upsaliensia, pages 21?32. Uppsala University, Depart-
ment of Linguistics and Philology, Uppsala.
Lars Borin, Dana Dann?lls, Markus Forsberg,
Maria Toporowska Gronostaj, and Dimitrios Kokki-
nakis. 2010. The past meets the present in the
Swedish FrameNet++. In Proc. of EURALEX, pages
269?281, Leeuwarden. EURALEX.
Lars Borin, Markus Forsberg, and Johan Roxendal. 2012.
Korp ? the corpus infrastructure of Spr?kbanken. In
Proceedings of LREC 2012.
Lars Borin. 2010. Med Zipf mot framtiden ? en inte-
grerad lexikonresurs f?r svensk spr?kteknologi. Lexi-
coNordica, 17:35?54.
Aljoscha Burchardt, Katrin Erk, and Anette Frank. 2005.
A WordNet detour to FrameNet. In Proceedings of the
GLDV 2005 workshop GermaNet II, Bonn, Germany.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. Kluwer The MIT Press.
Charles J. Fillmore. 1976. Frame semantics and the na-
ture of language. Annals of the New York Academy of
Sciences: Conference on the Origin and Development
of Language and Speech, 280(1):20?32.
Richard Johansson and Pierre Nugues. 2006. A
FrameNet-based semantic role labeler for Swedish. In
Proc. of Coling/ACL.
Richard Johansson and Pierre Nugues. 2007. Using
WordNet to extend FrameNet coverage. In Proceed-
ings of the Workshop on Building Frame-semantic Re-
sources for Scandinavian and Baltic Languages, at
NODALIDA, pages 27?30, Tartu, Estonia.
Richard Johansson, Karin Friberg Heppin, and Dimitrios
Kokkinakis. 2012. Semantic role labeling with the
Swedish FrameNet. In Proceedings of LREC-2012.
Krister Lind?n and Lauri Carlson. 2010. FinnWordNet ?
WordNet p? finska via ?vers?ttning. LexicoNordica ?
Nordic Journal of Lexicography, 17:119?140.
14
Sebastian Pad? and Mirella Lapata. 2005a. Cross-
lingual bootstrapping for semantic lexicons: The case
of Framenet. In Proceedings of AAAI-05, pages 1087?
1092, Pittsburgh, United States.
Sebastian Pad? and Mirella Lapata. 2005b. Cross-
linguistic projection of role-semantic information. In
Proceedings of Human Language Technology Confer-
ence and Conference on Empirical Methods in Natu-
ral Language Processing, pages 859?866, Vancouver,
Canada.
Sebastian Pad?. 2007. Translational equivalence
and cross-lingual parallelism: The case of FrameNet
frames. In Proceedings of the NODALIDA Workshop
on Building Frame Semantics Resources for Scandina-
vian and Baltic Languages, Tartu, Estonia.
Research Institute for the Languages of Finland. 2004.
KFSPC: KOTUS Swedish-Finnish Parallel Corpus.
http://www.csc.fi/kielipankki.
Josef Ruppenhofer, Michael Ellsworth, Miriam R. L.
Petruck, Christopher R. Johnson, and Jan Scheffczyk.
2006. FrameNet II: Extended theory and practice. Un-
published Manuscript.
Ralf Steinberger, Bruno Pouliquen, Anna Widiger,
Camelia Ignat, Toma? Erjavec, Dan Tufis?, and D?niel
Varga. 2006. The JRC-Acquis: A multilingual
aligned parallel corpus with 20+ languages. In Pro-
ceedings of the Fifth International Conference on Lan-
guage Resources and Evaluation (LREC), pages 2142?
2147.
Piek Vossen, editor. 1998. EuroWordNet: a multilingual
database with lexical semantic networks for European
Languages. Kluwer Academic Publishers.
15
