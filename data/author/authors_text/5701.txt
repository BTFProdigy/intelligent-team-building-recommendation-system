Anaphora Resolution in Multi-Person Dialogues
Prateek Jain and Manav Ratan Mital and Sumit Kumar and Amitabha Mukerjee and Achla M. Raina
Indian Institute of Technology Kanpur,
Kanpur 208016 INDIA
{pjain,sumit,manavrm,amit,achla}@iitk.ac.in
Abstract
Anaphora resolution for dialogues is a difficult
problem because of the several kinds of com-
plex anaphoric references generally present in
dialogic discourses. It is nevertheless a criti-
cal first step in the processing of any such dis-
course. In this paper, we describe a system for
anaphora resolution in multi-person dialogues.
This system aims to bring together a wide array
syntactic, semantic and world knowledge based
techniques used for anaphora resolution. In
this system, the performance of the heuristics is
optimized for specific dialogues using genetic
algorithms, which relieves the programmer of
hand-crafting the weights of these heuristics. In
our system, we propose a new technique based
on the use of anaphora chains to enable reso-
lution of a large variety of anaphors, including
plural anaphora and cataphora.
1 Introduction
Anaphoric references abound in natural language dis-
courses and their resolution has often been identified as
the first step towards any serious discourse processing re-
lated tasks. However, any comprehensive anaphora reso-
lution scheme is expected to entail the use of rich seman-
tic and pragmatic knowledge representation and process-
ing, and is, therefore, a complex problem. As a result of
such problems, several heuristics-based approaches have
been developed and adopted over the years to achieve par-
tial solutions to the problem.
The pioneering work in the area of anaphora resolu-
tion was done by Hobbs (Jerry R. Hobbs, 1978) who
designed several early syntactic and semantic heuristics
for the same. (Hirst, 1981) discusses several early ap-
proaches to anaphora resolution in discourses. (Denber,
1998) and (Lappin and Leass, 1994) describe several syn-
tactic heuristics for reflexive, reciprocal and pleonastic
anaphora, among others. Often domain-specific heuris-
tics are used for anaphora resolution and fine tuned to
perform well on a limited corpus, such as in (Mitkov,
1998). (Ng and Cardie, 2002) proposes a machine learn-
ing approach to Anaphora Resolution but generally sta-
tistical learning approaches suffer from the problems of
small corpuses and corpus dependent learning. A more
general and comprehensive overview of state-of-the-art
in anaphora resolution is given in (Mitkov, 1999) and also
in (Mitkov et al, 2001).
Few systems have been developed that are specifically
aimed at the task of anaphora resolution in discourses.
ROSANA, an algorithm for anaphora resolution that fo-
cuses on robustness against information deficiency in the
parsed output, is described in (Stuckardt, 2001). MARS,
the Mitkov Anaphora Resolution System, is another au-
tomatic, knowledge-poor anaphora resolution system that
has been implemented for several languages including
English, Bulgarian and Japanese.
In this paper, we describe the design and implementa-
tion of Jepthah1, a rule-based system for resolving a wide
variety of anaphora occurring in multi-person dialogues
in English. In this system, we integrate several different
knowledge-poor constraints and heuristics, and operate
them over a naive character model of the entire dialogue
to perform effective anaphora resolution. In addition to
using standard heuristics, we have developed our own se-
mantic and pragmatic heuristics, specific to dialogue sit-
uations, that operate on this character model. There is
a weight assigned to each of these heuristics and these
weights are fine-tuned using a learning mechanism im-
plemented by genetic algorithms. We use the linguistic
feature of anaphoric chains, present in dialogues, to re-
solve a relatively large class of anaphora.
1name of a wise Isreali judge in the Bible
2 Jepthah
In Jepthah, we adopt an integrated approach towards re-
solving various different kinds of anaphors occurring in
dialogue situations. In this approach we fuse together
several heuristics with a new kind of computational lin-
guistic insight ? that of the deployment of anaphora
chains and we develop a graph-based technique for han-
dling the resolution of various anaphors. An anaphora
chain may be described as a referential chain compris-
ing series of mutually co-referential anaphoric elements,
generally of more than one type, headed by a referential
element.
The class of anaphors that we aim to resolve is
fairly large and includes pronouns, reflexives and deic-
tic anaphors. In terms of distribution, we are dealing with
anaphors in subject, object and modifier positions, pos-
sessive reflexive, and cataphora. It is may be mentioned
here that we deal only with unambiguous cases of plural
pronouns, such as both of us, two of you, etc. These are
the cases in which the domain of the pronouns is clearly
quantified, unlike the case of such instances as all of us
or they, etc.
2.1 Graph-theoretic Approach
The entire operation is centered around a graph formu-
lation of the resolution problem in the perspective of the
dialogue. We extract all the nouns and pronouns present
in the dialogue. Assume there are n nouns and p pro-
nouns in the dialogue. Let the ith noun be represented as
Ni, with i ? n and that Pi represents the ith pronoun,
with i ? p. Now, we construct a graph representation for
the problem as follows. Let G be the graph that we are
interested in formulating, comprising of a node for every
Ni and Pj .Let NGi be the node corresponding to the noun
Ni and PGj be the node corresponding to the pronoun Pj .
Thus, we can split the set of vertices of this graph VG into
two parts, the set consisting of NGi , ?i ? n and the set
consisting of PGj , ?j ? p. The set of edges EG for this
graph G comprises of two types of directed edges and is
constructed as follows. Construct a set of edges E1 which
includes a directed edge Ei?j from PGi to NGj , for all
pairs PGi and NGj . The other set E2 includes a directed
edge E?i?j from PGi to PGj for all pair of nodes PGi and
PGj such that i 6= j. Clearly, we have EG = E1 ? E2. Let
us define a property L on the paths in this graph as fol-
lows ? a path p satisfies the property L iff it consists of a
sequence of edges Ei ? EG (i ? length(p)) with exactly
one edge Ef from the set E1 and the condition that this is
the last edge in the sequence, i.e., Elength(p) ? Ef .
Intuitively, this graph represents the set of possible
anaphor-antecedent relationships. The set of possible ref-
erents of an anaphor represented by the node PGi in the
graph G consists of all possible distinct nodes NGk that
can be reached from PGi using paths that satisfy the prop-
erty L. Let this set be represented as Si. Note here
that paths as above of length ? 2 represent anaphoric
chains present in the dialogue. One or more edges in
these paths are from one anaphor to another and represent
co-reference amongst these anaphors. The antecedent
space of an anaphor Pi consists of all nouns and pronouns
whose corresponding nodes in the graph G are reachable
from PGi by traversing a single edge belonging to EG.
Now, the idea here is to process this antecedent space and
rank all the nodes in Si to determine the most likely an-
tecedent for the anaphor Pi. This ranking is done by at-
taching weights to the edges present in the graph.
Every edge is awarded a particular weight (less than
1.0), that is evaluated for every edge using a set of heuris-
tics described in section 2.4. The rank of each node NGk
in the set Si is determined by the total weight Wik for that
node. Wik is computed as follows ? let the weight Wp of
each path p be defined as the product of the weights of
all the edges lying on that path. Then, Wik is the sum of
the weights of all the paths from PGi to NGk , i.e.,
?
p Wp.
Hence, for anaphora resolution, we need to basically de-
sign an algorithm or a function to compute the weight for
each edge in the graph.
2.2 System Design
The input dialogue is passed to the front end which com-
prises of the Stanford Serialized Parser and PoS tagger.
The parser gives the best parse for every input sentence,
each of which are then subsequently processed. In the
first step we extract all the proper nouns present in the
dialogue and initialize our character model base and the
graph G that was explained in section 2.1. We then
take the sequence of parses corresponding to each sub-
sequent dialogue by a speaker and process them sequen-
tially. Techniques for anaphora resolution are then ap-
plied in two phases. In the first phase, a set of constraints
is applied to this graph, to prune out edges that represent
any unfeasible co-references. In the second phase, a set
of heuristics are applied to award weights to edges repre-
senting these relationships. After the processing is over
and all weights have been obtained, the permissible an-
tecedents for each anaphor are ranked and the most likely
antecedent for each is outputted. In case there is a plu-
ral anaphor, with quantification over x nouns, the top x
likely antecedents are outputted.
While processing the dialogue, a naive character build-
ing is implemented. This is done mainly by focusing on
the verbs in the sentences. The subject and object nouns
associated with these verbs are selected and their relation-
ship is put in the character model base associated with the
speaker of the corresponding dialogue. The system main-
tains an apriori knowledge base with it containing infor-
mation like ontology and functionalities of several nouns.
This combination of apriori and assimilated knowledge
is then used to apply certain semantic and pragmatic con-
straints/heuristics on the graph, as shown in the following
sections.
2.3 Constraints
We apply the set of restrictions prior to the set of prefer-
ences, thereby narrowing down the candidate set as early
as possible. The list of constraints that implement these
restrictions in Jepthah are listed as follows ?
1. Deictic Constraint: This is a set of simple con-
straints that are specific to dialogue settings because
in such settings we can have the concept of frames
of reference with regard to the various speakers in-
volved in the dialogue action.
2. Non-coreference (Mitkov, 1999): Syntactic fea-
tures present in a sentence often lend themselves
to be expressed as constraints on anaphora refer-
ence. These features are captured by our non-
coreference constraints which stipulate that certain
pairs of anaphor and noun phrases within the same
sentence cannot refer to the same antecedent.
3. Gender, Number and Person Agreement: This is
a low level constraint which requires that anaphors
and their antecedents must agree in gender, number
and person respectively.
4. Constraint on Reflexive Pronoun: A reflexive pro-
noun such as himself, herself, etc must refer to the
subject or the object of the verb in whose clause it
lies. In case of ellipsis, however, it may refer to the
subject or object of the next higher verb to which the
clause is attached.
5. Semantic Consistency (Mitkov, 1999): This con-
straint enforces same semantics of the antecedent as
the anaphor under consideration.
2.4 Heuristics
Each preference or heuristic, has a certain weight and
awards certain points to every anaphor-antecedent rela-
tionship. These points are a measure of the likelihood of
that anaphor-antecedent relationship. The weight of an
edge is the sum total of the weights awarded by each in-
dividual heuristic to the anaphor-antecedent relationship.
The heuristics used in our system are enumerated as fol-
lows ?
1. Definiteness (Lappin and Leass, 1994): Accord-
ing to this heuristic, nouns that are preceded by a
demonstrative pronoun or a definite article are more
likely to be antecedents and are awarded higher
credibilities.
2. Non-prepositional NP (Lappin and Leass, 1994):
This heuristic states that a noun phrase which occurs
within a prepositional phrase is less probable to be
an antecedent to an anaphor and consequently, it is
awarded less credibility.
3. Pleonastic (Lappin and Leass, 1994): This heuris-
tic is based on the observation that there exist some
syntactic patterns such that every it anaphor occur-
ring in any of those patterns must be pleonastic.
4. Syntactic Parallelism (Lappin and Leass, 1994):
As per this heuristic, preference is given to noun
phrases with the same syntactic function as the
anaphor.
5. Recency (Mitkov, 1999): This is a very simple
heuristic according to which, everything else being
comparable, a higher credibility is awarded to the
antecedent nearer to the anaphor.
6. Semantic Parallelism (Lappin and Leass, 1994):
This heuristic gives preference to those noun phrases
which have the same semantic role as the anaphor
in question. This is a useful heuristic and can be
implemented by a system that can identify semantic
roles.
7. Pragmatic Heuristics: We use certain pragmatic
heuristics that we have identified to be very spe-
cific to dialogue settings. These are of the following
kinds
? If one speaker asks a question, then the next
speaker is likely to be the antecedent of the you
that may occur in the former?s sentence.
? If a speaker makes an exclamation then he is
likely to be the antecedent of the you in the
speech of the speaker just before him.
8. Naive Character Building: This refers to a naive
character model that we have used to implement a
restricted knowledge-based representation of the di-
alogue, woven around all the noun entities that are
present in the dialogue. To this end, we use a certain
amount of world knowledge that is present apriori
with the system, in the form of ontology and func-
tionality of possible noun entities. For instance, we
associate actions with each character based on their
subject object relationship with the verbs that occur
in the dialogues. Now for an anaphor we see if a
possible antecedent has functionality of the action
associated with the anaphor, implied by the verb of
the sentence. if it is so, we then give higher credibil-
ity to this particular antecedent.
Table 1: Results
Corpus % Accuracy
Shaw?s play - Pygmalion 62
Shaw?s play - Man and Superman 67
Hand-Crafted Dialogue I 83
Hand-Crafted Dialogue II 81
2.5 Learning approach
In most systems ((Mitkov, 1998),(Lappin and Leass,
1994)) the weights that are assigned for different
anaphor-antecedent relationships are programmer depen-
dent. Fixing these values in a adhoc fashion can clearly
give rise to unstable behaviour. In our work, we use
manually tagged corpora to evaluate the effectiveness
of a given weight assignment; these can then be tuned
using Genetic Algorithms(Goldberg, 1989). We use 2-
point crossover and mutation which are used in Standard
Genetic Algorithm for Real Variables(Deb and Kumar,
1995).
3 Results
We used our system for anaphora resolution in the fol-
lowing types of dialogue corpora:
? Dialogues written manually, woven broadly in a stu-
dent environment
? Fragments from the plays by the writer G. B. Shaw
Our System gave nearly 65% accuracy on Shaw?s plays
and almost 80% accuracy on our own ?hand crafted? dia-
logues [Table:1]. In the table, the name ?hand-crafted di-
alogues? refers to sample dialogues that the authors wrote
themselves to test the performance of the system.
The genetic algorithms that we use help in fine-tuning
weights according to the particular corpus, and show ap-
preciable increase in accuracy.
4 Conclusions
We have implemented an automatic, knowledge-based
anaphora resolution system that works for dialogic dis-
courses. The lack of availability of any standard corpora
(Mitkov, 1999) is a major drawback in case of anaphora
resolution systems in general and those for dialogues in
particular. The original contribution of this system is
mainly two-fold. First, the anaphora resolution system
that we have implemented uses an innovative graph tech-
nique, based on the idea of anaphora chaining, that makes
it possible to resolve such references as cataphora and
plural anaphora. Secondly, we give an algorithm which
uses naive character building to apply various semantic
and world-knowledge based heuristics to the process of
anaphora resolution. The results obtained from the sys-
tem indicate a fairly high accuracy, though an extensive
evaluation of the various resolution algorithms as well as
the system as a whole remains to be done.
References
K. Deb and A. Kumar. 1995. Real-coded genetic al-
gorithms with simulated binary crossover: Studies on
multimodal and multiobjective problems. Complex
Systems, 9(6):431?454.
M. Denber. 1998. Automatic resolution of anaphora in
english. Technical report, Eastman Kodak Co., Imag-
ing Science Division.
D. E. Goldberg. 1989. Genetic Algorithms in Search,
Optimization, and Machine Learning. Addison-
Wesley Publishing Company, Reading, MA.
Graeme Hirst. 1981. Discourse-oriented anaphora
resolution in natural language understanding: A re-
view?. American Journal of Computational Linguis-
tics, 7(2):85?98, April-June.
Jerry R. Hobbs. 1978. Resolving pronoun references.
Lingua, 44:311?338.
Shalom Lappin and Herbert J. Leass. 1994. An algo-
rithm for pronominal anaphora resolution. Computa-
tional Linguistics, 20(4):535?561.
Ruslan Mitkov, Branimir Boguraev, and Shalom Lappin.
2001. An Introduction to the Special Issue on Com-
putational Anaphora Resolution. Computational Lin-
guistics, 27(4).
Ruslan Mitkov. 1998. Robust pronoun resolution with
limited knowledge. In COLING-ACL, pages 869?875.
R. Mitkov. 1999. Anaphora Resolution: The State
of the Art. Working paper (Based on the COL-
ING?98/ACL?98 tutorial on anaphora resolution).
Vincent Ng and Claire Cardie. 2002. Combining sample
selection and error-driven pruning for machine learn-
ing of coreference rules. In Proceedings of the 2002
Conference on Empirical Methods in Natural Lan-
guage Processing, Association for Computational Lin-
guistics.
Roland Stuckardt. 2001. Design and Enhanced Evalua-
tion of a Robust Anaphor Resolution Algorithm. Com-
putational Linguistics, 27(4):479?506, December.
Proceedings of the Workshop on Multiword Expressions: Identifying and Exploiting Underlying Properties, pages 28?35,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Detecting Complex Predicates in Hindi using POS Projection  
across Parallel Corpora 
 
Amitabha Mukerjee, Ankit Soni, and  
Dept. of Computer Science and Engg 
Indian Institute of Technology Kanpur 
Kanpur -208016, India 
amit@iitk.ac.in, 
ankit@iitk.ac.in 
 
Achla M Raina 
Dept. of Humanities and Social Sciences 
Indian Institute of Technology Kanpur 
Kanpur -208016, India 
achla@iitk.ac.in 
 
  
 
Abstract 
Complex Predicates or CPs are multi-
word complexes functioning as single 
verbal units. CPs are particularly 
pervasive in Hindi and other Indo-
Aryan languages, but an usage account 
driven by corpus-based identification 
of these constructs has not been 
possible since single-language systems 
based on rules and statistical 
approaches require reliable tools (POS 
taggers, parsers, etc.) that are 
unavailable for Hindi. This paper 
highlights the development of first 
such database based on the simple idea 
of projecting POS tags across an 
English-Hindi parallel corpus. The CP 
types considered include adjective-verb 
(AV), noun-verb (NV), adverb-verb 
(Adv-V), and verb-verb (VV) 
composites. CPs are hypothesized 
where a verb in English is projected 
onto a multi-word sequence in Hindi. 
While this process misses some CPs, 
those that are detected appear to be 
more reliable (83% precision, 46% 
recall). The resulting database lists 
usage instances of 1439 CPs in 4400 
sentences. 
1 Introduction 
A "pain in the neck" (Sag et al, 2002) for 
NLP in languages of the Indo-Aryan family 
(e.g. Hindi-Urdu, Bangla and Kashmiri) is the 
fact that most verbs (nearly half of all 
instances in Hindi) occur as complex  
 
predicates - multi-word complexes which 
function as a single verbal unit in terms of 
argument and event structure (Hook, 1993; 
Butt and Geuder, 2003; Raina and Mukerjee, 
2005).  Moreover, most of these languages 
being resource-poor, even a proper corpus-
based characterization of such CPs has 
remained an elusive goal. 
In this paper we construct the first corpus-
based lexicon of CPs in Hindi based on 
projecting POS tags across parallel English-
Hindi corpora. While such approaches 
sometimes leave out some CPs, the ones that 
are identified are seen to be quite robust. As a 
result, this appears to be a good first approach 
for identifying the majority of CPs along with 
usage data. Moreover, since the language 
specific input in the procedure is minimal, it 
can be easily extended to other languages with 
similar multi word expressions. 
2 Complex Predicates 
CPs are characterized by a predicate or host - 
typically a noun (N), adjective (A), verb (V), 
or adverb (Adv) - followed by a light verb  
(LV),  a grammaticalized version of a main 
verb, which contributes little telic significance 
to the composite predicate. As an example, the 
English verb "describe" may be rendered in 
Hindi as the Noun-Verb complex ?????? + 
???, varNan kar, "description + do". Analysis 
based on a non-CP lexicon might assign the 
verbal head as kar (do), whereas functional 
aspects such as the argument structure are 
determined by the noun host varNan 
"description". An example of a V-V CP may 
28
be ??? + ???, kar de "do+give", where the light 
verb de ?give? imposes a completive aspect on 
the action kar ?do?.  
Identifying such constructs is a significant 
hurdle for NLP tasks ranging from phrasal 
parsing (Ray et al, 2003, Shrivastava et al, 
2005), translation (where each complex may 
be treated as a lexical unit in the target 
language), predicate-argument analysis, to 
semantic delineation. In addition to the 
computational aspects, a mere listing of all 
CPs occurring in the corpus would provide an 
important resource for tasks such as 
constructing WordNets (Narayan et al,2002) 
and linguistic analysis of CPs (Butt and 
Geuder, 2003). 
Rule-based approaches to identifying CPs 
are not very effective since there do not seem 
to be any clear set of rules that can be used to 
distinguish CPs from non-CP constructs 
(contrast, for example, the composite CP 
??????? ??? anumati de "permission+give" with 
the non-composite N-V structure ?????? ??? 
kitaab de "give the book"). Even where such 
rules do exist, they depend on semantic 
properties such as the fact that book is a 
physical object which can be given in the 
physical sense (Raina and Mukerjee, 2005). 
However, in the translated form, the former 
may show up as a verb, whereas the latter 
invariably will be a N+V, so the tag projection 
would rule out the latter as a CP.  
Here we adopt a parallel corpus-based 
approach to creating a database of complex 
predicates in Hindi. The procedure can 
potentially be duplicated to most Indo-Aryan 
languages.  The motivation is that a CP may be 
translated as a direct verb in other languages, 
and POS Projection across Parallel Corpora 
then project a tag of Verb for this expression in 
the source language. Additional linguistic 
constraints are used to determine if the multi-
word cluster qualifies as a CP.  These include a 
check list of LVs that can occur with A, N, V 
and Adv constituents of a multi word 
predicate.  
Let us consider some examples from the CP 
lexicon constructed from the EMILLE parallel 
corpus (McEnery et al, 2000) of 200,000 
words, collected from leaflets prepared by the 
UK government for immigrants.  Examples of 
these different complexes may be: 
 
 
(1) N+V:  ????? + ??   varNan kar 
  ?description + do?: 
 
?????  ??   ???????     ?????????       ?? ?   ????  
paikej     yaa    prastut     ishtehaar        mein    jaise   
package   or    present     advertisement  in       as  
 
?????   ????   ???      ??,     ???     ????    
varNan     kiyaa   gayaa       ho       ThIk        vaisaa  
description do-past go-past be-pres exact  same 
 
??      ???? 
hii         hogaa 
emph    be-fut 
 
?It will be exactly as described on the package 
or the display advertisement.? 
  
(2) A+V: ??????? ?? upalabdh hai  
 ?available+ be?:   
 
??????   ????      ??      ???????        ???  
Sahaytaa   samiip          hii       upalabdh              hai  
Help         near        emph     available      be-pres 
 
?Help is available nearby.? 
 
(3) V+V :  ??? ??  soch le  ?think+take?: 
 
????  ??  ????  ??  ????   ?? ?   ??????    ???  
Pahle  har  pehluu  ke  baare-mein   achchhi    tarah  
First    every aspect-poss   about         good    way 
 
???     ????? ? 
soch      liijiye 
think      take-imp-hon 
 
?Think it through first.? 
 
(4) Adv+V  vaapas paa   ?return+obtain? 
 
??   ?????    ?????  ?? ? ????   ????     ????  
Aap  saamaan   badalne    mein  apne  puure  paise 
You   goods exchange-nom in      your   all     money 
 
????   ????   ??  ??????   ??    ????    ??? ?  
vaapas   paane   kaa     adhikar     kho    dete    hai  
return obtain-nom of      right      lose   give  be-pres     
 
?You loose your right to get your full money 
back in exchanging the goods. ? 
29
Of the four classes cited above, the NV and 
AV classes are the most productive. The AdvV 
class is highly restricted, confined to a few 
adverbs. The VV class is highly selective for 
its constituents, apparently driven by semantic 
considerations.  
Identifying CPs in text is crucial to 
processing since it serves as a clausal head, 
and other elements in the phrase are licensed 
by the complex as a whole and not by the 
verbal head.  The semantic import of the host-
verb complex varies along a composability 
continuum, at one end of which we have 
purely idiomatic CPs, while at the other end, 
the CPs may be recoverable from its 
constituents.  For example, ?????????+???, 
vyavhaar kar, "behave+do" has a sense of 
"use,treat" in English, reflecting clearly an 
idiomatic usage.   
Detecting CPs is made difficult by the 
differing degrees of productivity for different 
classes of open-class host, which reflects the 
applicability of unrestricted rules.  Also, verbs 
participating in CPs are very selective; e.g. in 
NV and AV CPs the verb is typically restricted 
to ho, kar and the like, whereas in VV 
constructs ho reflects auxiliary usage, but a 
different set of verbs appear. The open class 
word (host) tends to be uninflected, and only 
the light verb (LV) carries tense, agreement 
and aspect markers.  Even the host V 
participating in a VV CP is always uninflected. 
As an instance of the difficulty in detecting 
CPs, consider the so called permissive CP 
(Hook, 1993; Butt and Geuder, 2003), as in the 
karne+de ?do-nom +give? example here, 
where the host verb appears to be  inflected:  
 
(5)  Raam ne sitaa ko   kaam  karne     diyaa 
      Ram-erg  sita-acc  work  do-nom  give-past 
       ?Ram let Sita do the work?  
 
However, this does not actually reflect CP 
usage, and is better parsed as:  
 
(6) [S [NP raam ne] [VP [NP sitaa ko]                    
[VP kaam karne] [V  diyaa] VP] S] 
 
Another challenge for CP identification is 
that the constituents may be separated ? 
sometimes quite widely.   
3 CPs from Parallel Projection  
Identifying MWEs from corpora is clearly 
an area of increasing research emphasis. For 
resource-rich languages, one may use a parse 
tree and look for mutual information statistics 
in head-complement collocations, and also 
compare it with other "similar" collocations to 
determine if something is unusual about a 
given construct (Lin, 1999). As of now 
however, even POS-tagging remains a 
challenge for languages such as Hindi, thereby 
making it necessary to seek alternate methods. 
Parallel corpus based approaches to 
inducing monolingual part-of-speech taggers, 
base noun-phrase bracketers, named-entity 
taggers and morphological analyzers for 
French, Chinese and other languages have 
shown quite promising results (Yarowsky et 
al., 2001). These approaches use minimal 
linguistic input and have been increasingly 
effective with the growth in the availability of 
large parallel corpuses. The algorithm 
essentially attempts to word-align the target 
language sentences with the source language 
sentences and then use a probabilistic model 
try to project the linguistic information from 
the source language. Since these are statistical 
algorithms, the accuracy of results depends on 
the size of the corpus used.  
In our approach, we first use a similar 
approach to word-align an English-Hindi 
parallel corpus. The English sentences are 
tagged and the tags are projected to Hindi 
sentences. We observe that words which are 
tagged as verbs by projection and have POS 
tag as N, A, Adv or V in the Hindi lexicon, and 
are followed by an LV, are usually CPs.  
Clearly the CP detection is limited to those 
instances where a CP in the target language is 
translated as a single verb in English.  For 
example, a phrase such as ???? ??, jawaab de, 
"answer give", may be rendered in English 
either as the verb ?answer? or as the English 
CP "give answer".  In the latter case (an 
example appearing quite frequently in this 
corpus), the correct POS projection would 
label jawaab as [N answer], thus failing to 
detect the CP.  While this may not be 
significant in certain tasks (e.g. translation), it 
may be relevant in others (e.g. semantic 
processing).  
 
 
 
30
Furthermore, the POS tagging process is 
inherently biased towards projecting tags for 
frequently encountered constituents first, and 
this may lead to some constituents in certain 
CPs being flagged with their normal POS tags, 
resulting in missed CPs. However, this does 
not result in false positives, since non-CP 
constructs often fail on other criteria (e.g. list 
of LVs). 
For reasons discussed above, many CPs are 
not identifiable through parallel corpus 
methods.  Some examples include ??????? 
?????, ????? ?????, ????? ?????. Our database 
is therefore correspondingly thin for these 
types of CPs.  
With VV CPs, it is difficult to distinguish 
between CPs and other related structures such 
as the passive construct or serial verbs. These 
are illustrated below.  
 
(7) Passive 
 
???  ??   ??  ????  ??    ??  ?????  ???  
Aisa   bhii    ho   saktaa   hai      ki      credit  note 
 It     emph   be    can     aux     that   credit  note 
 
?????   ???   ??    ???? ?  ??   ???    ?? ? 
siraf      kuch    hii      dino         tak    kaam     me 
only       few    emph   days       for     use       in 
 
????    ??   ????   ?? ? 
laaya     jaa     sakta     ho 
bring    go       can       be  
 
?It is quite possible that the credit note can be 
put to use only for a few days.? 
 
(8) Serial verb 
 
??   ????  ????  ???? ?????   ??  ??? ? 
voh   laDkaa   mujhe  apni   kitaab     de   gayaa 
That    boy      me       own    book    give  go-past 
 
?That boy gave me his book and went away.? 
 
It appears that passive can be reliably ruled 
out using the root verb criterion for VVs, since 
the main verb in passive is always in an 
inflected form. No comparable formal criterion 
exists for the serial verb, where also the POS 
tagger will identify both constituents as verbs.  
However, these verbs are relatively rare 
compared to CPs.  
4 Hindi-English POS Projection  
4.1 Data Resources and Preprocessing  
We used the EMILLE1 corpus Hindi-English 
parallel corpus, with approximately 200,000 
words in non-sentenced aligned translations in 
Unicode 16 format (McEnery et al, 2000). The 
texts consist of different types of information 
leaflets originally in English, along with 
translations in Hindi, Bangla, Gujarati and a 
number of South Asian languages. Closer 
analysis of the corpus reveals that the corpus is 
not completely sentence aligned and also that 
the translations are not very correct in many 
cases. Hindi versions of the manuals tend to be 
more verbose than their English translations.  
For the word alignment algorithm we 
needed a sentence aligned corpus but due to 
the small size of the parallel corpus, the 
standard sentence alignment systems did not 
give very high accuracy levels. Therefore, the 
whole data was manually sentence aligned to 
produce a sentence aligned parallel corpus of 
about nine thousand sentences and 140 
thousand words which is used in this work. 
4.2 Word alignment 
We have used IBM models proposed by 
Brown (Brown et al, 1993) for word aligning 
the parallel corpus. The IBM models have 
been widely used in statistical machine 
translation. Given a Hindi sentence h, we seek 
the English sentence e that maximizes P(e | h); 
the "most likely? translation.  
 
Now P (e | h) = P (e) * P (h | e) / P (h) 
argmax-e P(e | h) = argmax-e P(e) * P(h | e). 
 
P (e) is modeled by the N-gram model .We are 
interested in P (h | e). We used the Giza++ tool 
kit (Och and Ney, 2000), based on the 
Expectation Maximization (EM) algorithm, to 
calculate these probability measures. At the 
end of this step, we have a word-to-word 
mapping between the English and Hindi 
sentences. A "NULL" is used in the English 
sentences to account for the unaligned Hindi 
words from the corresponding Hindi sentence.  
 
 
                                                     
1 http://bowland-files.lancs.ac.uk/corplang/emille/ 
31
Figure 1. Example of projection of POS tags from English to Hindi.  Here the phrase "shikaayat kar" is projected 
from the English "complain" and is tagged as V+V.  Since shikaayat is a N in the Hindi lexicon, this phrase is 
identified as an CP of N+V type. 
 
 
4.3 Tagging English Sentences 
The English sentences are POS-tagged using 
the Brill Tagger (Brill, 1994), a rule based 
tagger which uses more or less the same tags 
as the Penn Treebank project (Marcus, 1994). 
Since for our purposes, we did not need a very 
detailed subcategorization of the tag set for 
Hindi, the English tag set was reduced by 
merging the subcategorization tags of a few 
categories. Thus  all noun distinctions in the 
Pen Treebank tagset based on number, person 
etc  were merged in our treatment of the Noun 
class. Similarly in the case of verbs, we 
merged distinctions based on tense, person, 
aspect and participles etc. Subclasses of 
adverbs and case forms of pronouns were also 
merged. Rest of the POS categories were 
retained.  The ?NULL? word in the English 
sentences, used for unaligned Hindi words in 
the parallel corpus, was given a ?NULL? tag. 
4.4 Projection of Tags to Hindi 
The reduced English tags were projected to 
Hindi words based on the word alignments 
obtained earlier. A sample alignment and 
tagged projection is shown in Figure 1. As the 
figure shows, postpositional markers, which 
are relatively more frequent in Hindi are 
mapped to the ?NULL? word in the English 
sentence.  
Since the amount of training data is very 
small, the statistical word alignment algorithm 
is not adequate enough to align all words 
correctly. To overcome this weakness, we 
apply some filtering conditions to remove 
alignment errors, especially in smaller 
sentences.  This filtering is based on two 
parameters: a) Fertility count (rf), which is 
defined as the number of Hindi words an 
English word maps to, and b) Acceptance level 
(k), defined as the number of words acceptable  
in a sentence with fertility count greater than 
equal to rf.  These two parameters are selected 
to minimize errors in the groundtruth sample-
set, and the resulting filtering heuristics used 
are presented in Table 1.  
 
Table-1. Filtering Criteria 
 Sentence 
Length 
 
Fertility 
Count(rf) 
 
Acceptance 
Level(k) 
 
1. 1-5 2 1 
2. 5-10 3 2 
3. 10-15 3 3 
4. 15-20 4 3 
5. 20-25 4 3 
6. 25-35 4 3 
7. 35+ 4 3 
4.5 Identification of CP?s 
After the filtering is done we observe that the 
CP?s are usually translated as a direct verb in 
English. So if the projected tag of a Hindi 
word is Verb and the normal POS tag of the 
word in the Hindi dictionary is N, A, V or Adv 
and the word is followed by one of the 
members from the LV set, then we classify the 
multi word expression as N+V, A+V, V+V, or 
Adv+V CP respectively.   
4.6 Fragments of the CP Lexicon 
A sample fragment of the CP lexicon is shown 
in Figure-2. The whole corpus is available 
online2. Since we do not have a very 
comprehensive Hindi dictionary we are not 
able to classify many CP?s that are identified 
in their respective class. On a test with 4400 
sentences we identified a total of 1439 CPs  
                                                     
2 The lexicon is available online at  
http://www.cse.iitk.ac.in/users/language/CP-
database.htm 
 
32
Figure 2. Example of the CP lexicon for ?shikaayat kr? 
 
 
 
 
with the following distribution:  N+V: 788, 
A+V: 107, Adv+V: 18 and V+V: 526.  
4.7 Errors in CP identification 
CP identification in the test data set 
involved certain ground truth decisions such as 
excluding verbal composites with regular 
auxiliary verb ??, hai corresponding to the 
English finite verb ?be? and the progressive 
????? raha ?-ing (progressive)?. CPs with 
idiomatic usage were included, and so were the 
CPs with a passive verb, although the latter 
were not counted in computational scores. The 
testing was done on a small set of about 120 
groundtruth sentences in which the CP?s were 
carefully identified manually. We get a 
precision of about 82.5% and a recall of 40% 
with our CP finding algorithm. If the idiomatic 
CPs is not considered the recall goes upto 
46%.   
Several types of errors are observed in the 
corpus-derived results.  A False Negative 
(missed CP) error arising due to the English 
complex predicate is shown in Figure 3. A 
number of False Positives arise due to 
inadequacy in the Hindi dictionary ? the online 
dictionary of Hindi we used was missing many 
lexemes. A further problem is homography ? 
e.g. the word kii (do-past) appears both as an 
possessive marker, as well as the past-tense 
form for the verb kara (do), occurring 
frequently (with jaa, go) in adjectival clause 
constructions. This has been mis-tagged in 
about one in ten instances (approx 0.2% cases), 
with hosts such as shikaayat (complaint), baat 
(talk), dekhvaal (looking-after), madad (help) 
etc. Similarly, the word un can appear as a 
noun (wool) or a pronoun (he). Furthermore, 
while considerable care was taken to manually 
sentence align the parallel corpus, a number of 
typos and other problems remain, some of 
them show up as false positives.  
4.8 Discontinuous CP identification 
In the results above, we have made no 
attempt to identify discontinuous CPs, i.e., 
instances where other phonological material 
intervenes between the constituents of a CP, 
As an example, consider  
(9) ???? ??, jaanch ho, ?inspection-be? 
 
???  ???  ??  ????   ????    ??  ?? 
agar   kaar  kii    jaanch    pahale   hii       ho 
if       car  poss  inspection earlier emph happen 
 
????      ?? ,   ??    ???????    ?????? ? 
 chuki       hai         to      report      mangiye  
comp. be-present  then  report    ask-imp-hon 
 
 ?If the car has already been inspected 
please ask to see the report.? 
 
These separated multi-word expressions 
constitute some of the most difficult problems 
for any language ? for example, one may 
compare these with English phrasal verbs like 
?give up?, which can sometimes occur in 
discontinuity. However, owing to the relatively 
free word order in Hindi, the discontinuous 
CPs in Hindi are separated by a variety of 
structures ranging from simple emphatic or 
focal particles and negation markers  to clausal 
33
 
Figure 3. Here the projection process fails to detect the CP "shikaayat karna" since the English translation is also 
CP "make complaint".  Improvements in MWE detection in English can possibly help reduce such errors. 
 
 
 
Figure 4. A verb in the source language, ?inspected? projects to jaanch (inspection)+ ho (be) + chukaa hai (aux),    
although they are separated by the phrase pahale-bhi (already).  Thus, using source and target languages 
together. the parallel projection method may have the potential for discovering discontinuous CPs as well.  
 
 
 
 
 
 
 
constituents.  How these structures are to be 
encoded in a computational lexicon is a 
complex matter that takes us beyond CP 
identification (Villavicencio et al 2004). But 
while rule-based identification of such 
constructs is problematic, we feel that POS-tag 
projection holds considerable promise in this 
direction.   
In the algorithm above we have only 
considered the target language (Hindi) tags 
after the parallel tagging is completed.  If in 
addition, we also consider the source language 
tag and its radiation the CP probabilities may 
be redefined in a manner that helps capture 
some discontinuous CPs as well. Thus, if 
English ?complain? radiates to shikaayat and 
kara, the inherent CP can be detected even in 
the presence of an intermediate phrase.  An 
example from the POS-tagged data exhibiting 
discontinous CP detection is presented in 
Figure 4.   
5 Conclusion 
In this work we have presented a 
preliminary approach to a corpus-based 
lexicon of CPs in Hindi based on projecting 
POS tags across parallel English-Hindi 
corpora. Since the approach involves minimal 
linguistic analysis, it is easily extendable to 
other languages which exhibit similar CP 
constructs, provided the availability of a POS 
lexicon. 
Clearly, a number of problems will remain 
with any such approach.  The limitiations of 
the parallel POS tagging is that certain kinds of 
maps may never be found (as in parallel CPs in 
source and target languages).  On the other 
hand, some of our accuracies, we feel, would 
improve considerably given a larger parallel 
corpus and more refined use of a Hindi 
lexicon.   
In addition to the handling of discontinuous 
CPs hinted at above, another aspect that we 
would like to consider next is to tune some of 
the parameters of the parallel tagging 
algorithm, such as specifically tuning the 
distortion and fertility probabilities in 
situations (e.g. English verbs) that are likely to 
manifest CPs in Hindi.  
We feel that beyond the usefulness of this 
initial approach, the database of CPs 
constructed in this work may in itself be an 
important linguistic resource for Hindi.  
Furthermore, the approach can possibly be 
used to detect MWEs that radiate to a single 
lexical structure in another language, e.g. 
phrasal verbs in English.  
 
Acknowledgements We acknowledge a 
comment from an anonymous reviewer 
regarding discontinuous CPs which led us to 
investigate them (Figure 4 above).  However, it 
was not possible to report this important 
exception for the entire database.  
 
34
References 
Eric Brill.1994. Some advances in transformation-
based part of speech tagging, National 
Conference on Artificial Intelligence,p 722-727. 
Peter F. Brown,  Pietra, S. A. D., Pietra, V. J. D., & 
Mercer, R. L.. 1993. Computational Linguistics 
19(2), 263-311. 
Miriam Butt and Wilhelm Geuder. 2003. Light 
Verbs in Urdu and Grammaticalization., Trends 
in Linguistics Studies and Monographs, Vol 143, 
p295-350. 
Peter E. Hook. 1993.  Aspectogenesis and the 
Compound Verb in Indo-Aryan. Complex 
Predicates in South Asian Languages. 
Dekang Lin.1999. Automatic Identification of Non-
compositional Phrases,  Proceedings of the 37th 
Annual Meeting of the Association for 
Computational Linguistics, 317--324. 
Mitchell P. Marcus, Beatrice Santorini and Mary 
Ann Marcinkiewicz. 1994. Building a large 
annotated corpus of English: the Penn Treebank, 
Computational Linguistics 19(2), 313?330. 
A. M. McEnery, P. Baker, R. Gaizauskas, and H. 
Cunningham. 2000. EMILLE: Building a Corpus 
of South Asian Languages, Vivek, A Quarterly 
in Artiificial Intelligence, 13(3):p 23?32. 
D Narayan, D Chakrabarty, P Pande and  P 
Bhattacharyya. 2002. Experiences in Building 
the Indo Wordnet: A Wordnet for Hindi 
International Conference on Global WordNet 
Franz Josef Och and Hermann Ney. 2000. 
Improved statistical alignment models, in 
ACL00 p 440?447. 
Achla M. Raina and Amitabha Mukerjee. 2005. 
Complex predicates in the generative lexicon, 
Proceedings of GL?2005, Third International 
Workshop on Generative Approaches to the 
Lexicon, p210-221. 
Pradipta Ranjan  Ray, Harish V. Sudeshna Sarkar 
and Anupam Basu.. 2003. Part of Speech 
Tagging and Local Word Grouping Techniques 
for Natural Language Parsing in Hindi. In 
Proceedings of (ICON) 2003.  
Ivan Sag, Timothy Baldwin, Francis Bond, Ann 
Copestake and Dan Flickinger. 2002.  Multiword 
expressions: A pain in the neck for NLP 
,Proceedings of the 3rd International Conference 
on Intelligent Text Processing and 
Computational Linguistics (CICLing-2002) ,p1-
15. 
Manish Shrivastava, Nitin Agrawal, Smriti Singh 
and Pushpak Bhattacharya. 2005. Harnessing 
Morphological Analysis in POS Tagging Task, 
In Proceedings ICON 2005. 
Aline Villavicencio, Ann Copestake, Benjamin 
Waldron, and Fabre Lambeau. 2004. The Lexical 
Encoding of MWEs , Proceedings Second ACL 
Workshop on Multiword Expressions: 
Integrating Processing, p80-87.   
David Yarowsky, G. Ngai, and R. Wicentowski. 
2001. Inducing multilingual pos taggers and np 
bracketers via robust projection across aligned 
corpora, Proceedings of Human Language 
Technology Conference .p1 - 8.   
 
 
35
