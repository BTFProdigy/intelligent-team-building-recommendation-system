Layering and Merging Linguistic Annotations  Keith Suderman Department of Computer Science Vassar College Poughkeepsie, NY USA suderman@cs.vassar.edu 
Nancy Ide Department of Computer Science Vassar College Poughkeepsie, NY USA ide@cs.vassar.edu   Abstract The American National Corpus and its annotations are represented in a stand-off XML format compliant with the specifi-cations of ISO TC37 SC4 WG1?s Lin-guistic Annotation Framework. Because few systems that enable search and ac-cess of the corpus currently support stand-off markup, the project has devel-oped a SAX like parser that generates ANC data with annotations in-line, in a variety of output formats.  1 Introduction The American National Corpus (ANC) project1 recently released its 2nd release consisting of ap-proximately 22 million words of data, represent-ing a variety of genres of both written and spo-ken data. The corpus is annotated with several layers of automatically produced linguistic in-formation, including sentence and token bounda-ries, part of speech using two different POS tag-sets (a version of the Penn tagset2 and the Biber tagset3), and noun chunks and verb chunks.  ANC primary documents are plain text (UTF-16) documents and are treated as ?read only? resources. All annotations are represented in stand-off XML documents referencing spans in the primary data or other annotation documents, using the XCES4 implementation of the specifi-cations of ISO TC37 SC4?s Linguistic Annota-tion Framework (LAF) (Ide and Romary, 2004). Because few systems that enable search and ac-cess of the corpus currently support stand-off markup, the project has developed a parser that generates ANC data with annotations in-line, in a variety of output formats.                                                 1http:// americannationalcorpus.org 2http://americannationalcorpus.org/FirstRelease/gatetags.txt 3http://americannationalcorpus.org/FirstRelease/Biber-tags.txt 4http://www.xces.org 
This demonstration will show the ?life-cycle? of an ANC document, from acquisition of a document in any of a variety of formats (MS Word, PDF, HTML, etc.) through annotation and final representation in the stand-off format. The ANC tool for merging annotations of the user?s choice with the primary data to produce a single document with in-line annotations will also be demonstrated. 2 ANC Document Life-Cycle Documents to be included in the ANC are ac-quired in many different formats, including MS Word, PDF, HTML, Quark Express, etc. Proc-essing involves a series of steps, which are out-lined below.  2.1 Conversion from original format to ?rudimentary? XML The ANC receives documents in a variety of dif-ferent formats. The first step in processing is to convert the input documents into XCES XML with basic structural annotations included. The most common types of file formats encountered are: ? Microsoft Word. The release of OpenOf-fice 2 has greatly simplified the processing of MS Word documents.  OpenOffice uses XSL and XSLT stylesheets to export files to XML and ships with stylesheets to gen-erate DocBook and TEI-compliant for-mats. We modified the TEI stylesheet to create XCES XML. OpenOffice?s Java API enables us to automate and integrate OpenOffice with later processing steps. ? XML/SGML/HTML. processing of XML files typically involves using XSLT to map element names to XCES. SGML and HTML files typically require pre-processing to render them into valid XML, followed by the application of an XSLT stylesheet to convert them to XCES. 
89
? Quark Express. Several publishers pro-vided documents prepared for publication using Quark Express. Quark documents can be exported in XML, but doing so is worthwhile only if the creator of the document takes advantage of Quark?s style-definition facilities (which was not the case for any of the contributed Quark documents). We therefore exported the documents in RTF; however, many fonts and special characters are improperly ren-dered, and fairly extensive manual editing was therefore required to render the files into a format that could be used. Once ed-ited, the same procedures for MS Word documents are used to generate XCES.  ? PDF.  Bitmap PDF files are unusable for our purposes. Adobe Acrobat can generate plain text from PDF, although this process loses much of the formatting information that would be desirable to retain to facili-tate later processing. In some cases, liga-tures and other special characters are im-properly represented in the text version, and it is not always possible to automati-cally detect and convert them to conform to the original. PDF documents with two or more columns cannot, to our knowl-edge, be extracted without some mis-ordering of the text in the results. ? Other formats. Other formats in which the ANC has acquired documents include plain text and plain text that employed a variety of proprietary markup languages. These documents are processed on a case by case basis, using specialized scripts. 2.2 GATE processing and annotation We use the University of Sheffield?s GATE sys-tem5 for the bulk of ANC document processing and annotation, currently including tokenization, sentence splitting, part of speech tagging, noun chunking, and verb chunking.  Most annotations are produced using GATE?s built-in ANNIE components; we have, however, modified the ANNIE sentence splitter and created several Java plug-ins for use in GATE that perform basic bookkeeping, renaming of annotations/features, moving of annotations between annotation sets etc. We have also developed a scripting language (XORO6) for use with GATE to enable easy bulk                                                 5http://gate.ac.uk 6 http:// americannationalcorpus.org/xoro.html 
processing and re-processing of the entire cor-pus, or to apply selected annotation steps without having to load the files into a GATE corpus or data store. This eases iterative development as documents are added and tools are refined. 2.3 Creation of standoff annotation docu-ments  We have developed several custom processing resources that plug into GATE to generate stand-off annotations in the XCES implementation of the LAF format. The last step in our GATE pipe-line is to create the primary text document and generate all the required standoff annotation files. 3 Standoff Format  The ANC standoff format for annotations is a simple graph representation, consisting of one node set and one, or more, edge sets. The node set is represented by the text itself, with an im-plied node between each character. Each edge set is represented by an XML document and may contain one or more annotation types: logical structure, sentence boundaries, tokens, etc.  An ANC header file for each document is used to associate the source text with the standoff an-notation documents; for example: <cesHeader>   ...   <annotations>  <annotation type="content"    ann.loc="en_4065.txt">   Text content</annotation>  <annotation type="logical"    ann.loc="en_4065-logical.xml">   Logical structure</annotation>      <annotation type="s"    ann.loc="en_4065-s.xml">   Sentence boundaries</annotation>      <annotation type="hepple"    ann.loc="en_4065-hepple.xml">   Hepple POS tags</annotation>      <annotation type="biber"    ann.loc="en_4065-biber.xml">   Biber POS tags</annotation>      <annotation type="vp"    ann.loc="en_4065-vp.xml">   Verb chunks</annotation>      <annotation type="np"    ann.loc="en_4065-np.xml">   Noun chunks</annotation>   </annotations>       ... </cesHeader> ANC annotation documents are marked up with the XCES representation of the nodes and edge sets of the annotation graph. The following shows a segment of the document containing part of speech annotation: 
90
<cesAna xmlns="http://www.xces.org/schema/2003" version="1.0.4"> <struct type="tok" from="4" to="6">    <feat name="base" value="in"/>    <feat name="msd" value="IN"/> </struct> <struct type="tok" from="7" to="11">    <feat name="msd" value="DT"/>    <feat name="base" value="this"/> </struct> <struct type="tok" from="12" to="19">    <feat name="base" value="chapter"/>    <feat name="msd" value="NN"/> </struct> ... </cesAna> Each <struct> element represents an edge in the graph; values of the from and to attributes denote the nodes (between characters in the primary text document) over which the edge spans.  3.1 Annotating discontiguous spans Presently, the ANC includes standoff annotations that reference contiguous spans of data in the original (primary) document. However, we plan to add a wide variety of automatically-produced annotations for various linguistic phenomena to the ANC data, some of which will reference dis-contiguous regions of the primary data, or may reference annotations contained in other standoff documents. This is handled as follows: given an annotation graph, G, we create an edge graph G? whose nodes can themselves be annotated, thereby allowing for edges between the edges of the original annotation graph G. For example, consider the sentence ?My dog has fleas.? The standoff annotations for the to-kens would be:                     1 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 |M|y| |d|o|g| |h|a|s| |f|l|e|a|s|  <struct ? id="t1" from="0" to="2"/> <struct ? id="t2" from="3" to="6"/> <struct ? id="t3" from="7" to="10"/> <struct ? id="t4" from="11" to="16"/> Now consider the dependency tree generated by Minipar7 given in Figure 2. The tree can be represented by annotating the token elements in the standoff annotation document as follows:  <!-- Define some pseudo nodes --> <node type="root" id"E0" ref="t3"/> <node type="clone" id="E2" ref="t2"/>   <!-- Define edges in dependency tree --> <struct type="subj" id="s1"  from="t3" to="E2"/> <struct type="s" id="s2"  from="t3" to="t2"/>                                                 7http://www.cs.ualberta.ca/~lindek/minipar.htm 
<struct type="gen" id="gen"  from="t2" to="t1"/> <struct type="obj" id="obj"  from="t3" to="t4"/> 
 Figure 2. Dependency tree generated by Minipar.8 4 Creating In-line Annotation Docu-ments We have developed an ?XCES Parser?9 that im-plements the org.xml.sax.XMLReader interface to create ANC documents containing in-line an-notations in XML (or any other format).  The XCES parser works as follows: annota-tions to be loaded are selected with the org.xml.sax.XMLReader.setProperty() method. The selected annotation sets are then loaded into a single list in memory and sorted, first by offset and, if the offsets are the same, secondly by annotation type. At present, the or-dering of annotation types are hard coded into the parser; work is underway to make the XCES parser "schema aware" so that embedding speci-fications can be provided by the user. Once the text is loaded and sorted, the appropriate SAX2 events are generated and dispatched to the org.xml.sax.ContentHandler (if one has been reg-istered with the parser) in sequence to simulate the parsing of an XML document. While the parser will allow the programmer to specify an ErrorHandler, DTDHandler, or EntityResolver, at this time no methods from those interfaces will be invoked during parsing. In the current version of the XCES parser, when overlapping annotations are encountered, they are "truncated". For example: <s>Sentence <em>one.</s><s>Sentence</em> two.</s>                                                 8 Image generated by http://ai.stanford.edu/~rion/parsing/minipar_viz.html 9 http://americannationalcorpus.org/tools/index.html#xces-parser 
91
becomes <s>Sentence <em>one.</em></s><s>Sentence two.</s> Work is underway to provide the option to gen-erate milestones in CLIX/HORSE (DeRose, 2004) format to represent overlapping hierar-chies. 4.1 Using the XCES parser The XCES parser can be used in three ways: ? from the command line.  The xces-parser.jar file can be run as a command line program to print XML with inline an-notation to standard output. ? as the XML parser used by other applica-tions.  For example, Saxon10 can take the name of the parser to use to parse the source document as a command line pa-rameter.  This allows us to apply XSLT stylesheets to ANC documents without having to translate them into XML first. ? as a library for use in other Java applica-tions. For example, The ANC Tool11 is a graphical front end to the XCES parser. 4.2 The ANC tool The ANC Tool provides a graphical user inter-face for the XCES parser and is used to convert ANC documents to other formats.  Users specify their choice of annotations to be included. Cur-rently, the ANC Tool can be used to generate the following output formats: ? XML XCES format, suitable for use with the BNC?s XAIRA12 search and access in-terface; ? Text with part of speech tags appended to each word and separated by an under-score; ? WordSmith/MonoConc Pro format.  The ANC Tool uses multiple implementations of the org.xml.sax.DocumentHandler interface, one for each output format, which the XCES parser uses to generate the desired output. Addi-tional output formats can be easily generated by implementing additional interfaces. Of course, if the target application understands annotation graphs, there is no need to bother with the XCES parser or conversion to XML. For ex-ample, we provide several resources for GATE                                                 10 http://saxon.sourceforge.net/ 11 http:// americannationalcorpus.org/tools/anctool.html 12 http://sourceforge.net/projects/xaira 
that permit GATE to open and read ANC docu-ments with standoff annotations, or to load standoff annotations into an already loaded document. 5 Future Work  Currently the XCES parser is a proof of concept rather than a production grade tool. The parser is being augmented to invoke all the appropriate methods from the org.xml.sax.*Handler interfaces and throw the proper SAXExceptions at the appropriate times.  We are also providing for some level of SAX conformance, rather than simply ?doing what Xerces does?. 6 Conclusion The ANC has implemented an efficient pipeline for the processing of text into a corpus of ma-chine usable documents. For some document types this process is almost completely auto-mated and can be regarded as a Corpus-Builder-in-a Box: raw data goes in one end, and a fully annotated corpus with standoff annotations comes out the other.  The use of standoff annotations allows for an accurate representation of the ANC data as pro-vided by the contributors and allows us to easily provide several modular annotation sets that can be included or excluded by the end user as de-sired. By providing a SAX like parser for ANC documents, we are able to leverage a number of available XML tools without the restrictions im-posed by an XML representation of the docu-ments. For users who are not interested in XML or standoff annotations, the plain text version is preserved. 
References  DeRose, Steven J. (2004). Markup Overlap: A Re-view and a Horse. http://www.mulberrytech.com/ Extreme/Proceedings/html/2004/DeRose01/ EML2004DeRose01.html Ide, N., Romary, L. (2004). International standard for a linguistic annotation framework. Journal of Natural Language Engineering, 10:3-4, 211-225. 
92
Proceedings of the Linguistic Annotation Workshop, pages 1?8,
Prague, June 2007. c?2007 Association for Computational Linguistics
GrAF: A Graph-based Format for Linguistic Annotations 
Nancy Ide Department of Computer Science Vassar College Poughkeepsie, New York USA ide@cs.vassar.edu 
Keith Suderman Department of Computer Science Vassar College Poughkeepsie, New York USA suderman@cs.vassar.edu 
  Abstract In this paper we describe the Graph Anno-tation Format (GrAF) and show how it is used represent not only independent lin-guistic annotations, but also sets of merged annotations as a single graph. To demon-strate this, we have automatically trans-duced several different annotations of the Wall Street Journal corpus into GrAF and show how the annotations can then be merged, analyzed, and visualized using standard graph algorithms and tools. We also discuss how, as a standard graph rep-resentation, it allows for the application of well-established graph traversal and analysis algorithms to produce information about interactions and commonalities among merged annotations. GrAF is an extension of the Linguistic Annotation Framework (LAF) (Ide and Romary, 2004, 2006) developed within ISO TC37 SC4 and as such, implements state-of-the-art best practice guidelines for representing linguistic annotations. 1 Introduction Although linguistic annotation of corpora has a long history, over the past several years the need for corpora annotated for a wide variety of phe-nomena has come to be recognized as critical for the future development of language processing ap-plications. Considerable attention has been devoted to the development of means to represent annota-tions so that phenomena at different levels can be merged and/or analyzed in combination. A particu-
lar focus has been on the development of standards and best practices for representing annotations that can facilitate ?annotation interoperability?, that is, the use and re-use of annotations produced in dif-ferent formats and by different groups and to en-able easy adaptation to the input requirements of existing annotation tools. In this paper we describe the Graph Annotation Format (GrAF) and show how it is used represent not only independent linguistic annotations, but also sets of merged annotations as a single graph. We also discuss how, as a standard graph represen-tation, it allows for the application of well-established graph traversal and analysis algorithms to produce information about interactions and commonalities among merged annotations. GrAF is is an extension of the Linguistic Annotation Framework (LAF) (Ide and Romary, 2004, 2006) developed within ISO TC37 SC41 and as such, im-plements state-of-the-art best practice guidelines for representing linguistic annotations. This paper has several aims: (1) to show the generality of the graph model for representing lin-guistic annotations; (2) to demonstrate how the graph-based model enables merging and analysis of multi-layered annotations; and (3) to propose as the underlying model for linguistic annotations, due to its generality and the ease with which it is mapped to other formats. To accomplish this, we have automatically transduced several different annotations of the Wall Street Journal corpus into GrAF and show how the annotations can then be merged, analyzed, and visualized using standard graph algorithms and tools. Discussion of the                                                 1 International Standards Organization Technical Committee 37 Sub-Committee 4 for Language Resource Management. 
1
transduction process brings to light several prob-lems and concerns with current annotation formats and leads to some recommendations for the design of annotation schemes.  2 Overview Graph theory provides a well-understood model for representing objects that can be viewed as a con-nected set of more elementary sub-objects, to-gether with a wealth of graph-analytic algorithms for information extraction and analysis.  As a result, graphs and graph-analytic algorithms are playing an increasingly important role in language data analysis, including finding related web pages (Kleinberg, 1999; Dean and Henzinger, 1999; Brin, 1998; Grangier and Bengio, 2005), patterns of web access (McEneaney, 2001; Zaki, 2002), and the extraction of semantic information from text (Widdows and Dorow, 2002; Krizhanovsky, 2005; Nastase and Szpakowicz, 2006). Recently, there has been work that treats linguistic annotations as graphs (Cui et al, 2005; Bunescu and Mooney, 2006; Nguyen et al, 2007; Gabrilovich and Mark-ovitch, 2007) in order to identify, for example, measures of semantic similarity based on common subgraphs. As the need to merge and study linguistic anno-tations for multiple phenomena becomes increas-ingly important for language analysis, it is essential to identify a general model that can capture the relevant information and enable efficient and effec-tive analysis. Graphs have long been used to de-scribe linguistic annotations, most familiarly in the form of trees (a graph in which each node has a single parent) for syntactic annotation. Annotation Graphs (Bird and Liberman, 2001) have been widely used to represent layers of annotation, each associated with primary data, although the concept was not extended to allow for annotations linked to other annotations and thus to consider multiple annotations as a single graph. More recently, the Penn Discourse TreeBank released its annotations of the Penn TreeBank as a graph, accompanied by an API that provides a set of standard graph-handling functions for query and access 2 . The graph model therefore seems to be gaining ground as a natural and flexible model for linguistic anno-tations which, as we demonstrate below, can repre-                                                2 http://www.seas.upenn.edu/~nikhild/PDTBAPI/ 
sent all annotation varieties, even those that were not originally designed with the graph model as a basis. 2.1 LAF LAF provides a general framework for represent-ing annotations that has been described elsewhere in detail (Ide and Romary, 2004, 2006). Its devel-opment has built on common practice and conver-gence of approach in linguistic annotation over the past 15-20 years. The core of the framework is specification of an abstract model for annotations instantiated by a pivot format, into and out of which annotations are mapped for the purposes of exchange.          
 
Figure 1: Use of the LAF pivot format Figure 1 shows the overall idea for six different user annotation formats (labeled A ? F), which re-quires two mappings for each scheme?one into and one out of the pivot format, provided by the scheme designer. The maximum number of map-pings among schemes is therefore 2n, vs. n2-n mu-tual mappings without the pivot.  To map to the pivot, an annotation scheme must be (or be rendered via the mapping) isomorphic to the abstract model, which consists of (1) a referen-tial structure for associating stand-off annotations with primary data, instantiated as a directed graph; and (2) a feature structure representation for anno-tation content. An annotation thus forms a directed graph referencing n-dimensional regions of pri-mary data as well as other annotations, in which nodes are labeled with feature structures providing the annotation content. Formally, LAF consists of: ? A data model for annotations based on directed graphs defined as follows:  A graph of annota-tions G is a set of vertices V(G) and a set of edges E(G). Vertices and edges may be labeled 
Pivot   
A 
B 
C F 
E 
D 
2
with one or more features. A feature consists of a quadruple (G?, VE, K, V) where, G? is a graph, VE is a vertex or edge in G?, K is the name of the feature and V is the feature value. ?  A base segmentation of primary data that de-fines edges between virtual nodes located be-tween each ?character? in the primary data.3 The resulting graph G is treated as an edge graph G? whose nodes are the edges of G, and which serve as the leaf (?sink?) nodes. These nodes provide the base for an annotation or several layers of annotation. Multiple segmen-tations can be defined over the primary data, and multiple annotations may refer to the same segmentation. ? Serializations of the data model, one of which is designated as the pivot.  ? Methods for manipulating the data model. Note that LAF does not provide specifications for annotation content categories (i.e., the labels describing the associated linguistic phenomena), for which standardization is a much trickier matter. The LAF architecture includes a Data Category Registry (DCR) containing pre-defined data ele-ments and schemas that may be used directly in annotations, together with means to specify new categories and modify existing ones (see Ide and Romary, 2004).  2.2 GrAF  GrAF is an XML serialization of the generic graph structure of linguistic annotations described by LAF. A GrAF document represents the referential structure of an annotation with two XML elements: <node> and <edge>. Both <node> and <edge> elements may be labeled with associated annota-tion information. Typically, annotations describing a given object are associated with <node> ele-ments. Although some annotations, such as de-pendency analyses, are traditionally depicted with labeled edges, GrAF converts these to nodes in order to analyze both the annotated objects and the relations of a graph uniformly. Associating annota-tions with nodes also simplifies the association of an annotation (node) with multiple objects. 
                                                3 A character is defined to be a contiguous byte sequence of a specified length .For text, the default is UTF-16. 
 According to the LAF specification, an annota-tion is itself a graph representing a feature structure. In GrAF, feature structures are encoded in XML according to the specifications of ISO TC37 SC4 document 1884. The feature structure graph associ-ated with a given node is the corresponding  <node> element?s content. Note that the ISO specifications implement the full power of feature structures and define inheritance, unification, and subsumption mechanisms over the structures, thus enabling the representation of linguistic informa-tion at any level of complexity. The specifications also provide a concise format for representing sim-ple feature-value pairs that suffices to represent many annotations, and which, because it is suffi-cient to represent the vast majority of annotation information, we use in our examples. <edge> elements may also be labeled (i.e., as-sociated with a feature structure), but this informa-tion is typically not an annotation per se, but rather information concerning the meaning, or role, of the link itself. For example, in PropBank, when there is more than one target of an annotation (i.e., a node containing an annotation has two or more outgoing edges), the targets may be either co-referents or a ?split argument? whose constituents are not contiguous, in which case the edges collect an ordered list of constituents. In other case, the outgoing edges may point to a set of alternatives. To differentiate the role of edges in such cases, the edge may be annotated. Unlabeled edges default to pointing to an unordered list of constituents.  A base segmentation contains only <sink> elements (i.e., nodes with no outgoing edges), which are a sub-class of <node> elements. As noted above, the segmentation is an edge graph created from edges (spans) defined over primary data. The from and to attributes on <sink> ele-ments in the base segmentation identify the start and end points of these edges in the primary data. Each annotation document declares and associ-ates the elements in its content with a unique namespace. Figure 2 shows several XML frag-ments in GrAF format.  
                                                4 See ISO TC37 SC4 document N188, Feature Structures-Part 1: Feature Structure Representation (2005-10-01), available at http://www.tc37sc4.org/ 
3
Figure 2: GrAF annotations in XML 3 Transduction To test the utility of GrAF for representing annotations of different types produced by different groups, we transduced the Penn TreeBank (PTB), PropBank (PB), NomBank (NB), Penn Discourse TreeBank (PDTB), and TimeBank (TB) annotations of the Wall Street Journal (WSJ) corpus to conform to the specifications of LAF and GrAF. These annotations are represented in several different formats, including both stand-off and embedded formats. The details of the transduction process, although relatively mundane, show that the process is not always trivial. Furthermore, they reveal several seemingly harmless practices that can cause difficulties for transduction to any other format and, therefore, use by others. Consideration of these details is therefore informative for the development of best practice annotation guidelines. The Penn TreeBank annotations of the WSJ are embedded in the data itself, by bracketing compo-nents of syntactic trees. Leaf nodes of the tree are comprised of POS-word pairs; thus, the PTB in-cludes annotations for both morpho-syntax and syntax. To coerce the annotations into LAF/GrAF, it was necessary to  ? extract the text in order to create a primary data document; ? provide a primary segmentation reflecting the tokenization implicit in the PTB; ? separate the morpho-syntactic annotation from the syntactic annotation and render 
each as a stand-off document in GrAF for-mat, with links to the primary segmentation. NB, PB, and PDTB do not annotate primary data, but rather annotate the PTB syntax trees by providing stand-off documents with references to PTB Tree nodes. The format of the NB and PB stand-off annotations is nearly identical; consider for example the following PB annotation:  wsj/00/wsj_0003.mrg 18 18 gold include.01 p---a 14:1,16:1-ARG2 18:0-rel 19:1-ARG1 In GrAF, this becomes           Each line in the PB and NB stand-off files pro-vides a single annotation and therefore interpreted as an annotation node with a unique id. Each anno-tation is associated with a node with an edge to the annotated entity. The PB/NB comma notation (e.g., 14:1,16:1) denotes reference to more than one node in the PTB tree; in GrAF, a dummy node is created to group them so that if, for example, a NB annotation refers to the same node set, in a merged representation a graph minimization algorithm can collapse the dummy nodes while retaining the an-notations from each of PB and NB as separate nodes. Some interpretation was required for the trans-duction, for example, we assume that the sense number and morpho-syntactic descriptor are asso-ciated with the element annotated as ?rel? (vs. the ?gold? status that is associated with the entire proposition), an association that is automatically discernible from the structure. Also, because the POS/word pairs in the PTB leaf nodes have been split into separate nodes, we assume the PB/NB annotations should refer to the POS annotation rather than the string in the primary data, but either option is possible. Given the similarities of the underlying data models for the PDTB and LAF, creating GrAF-compliant structures from the PDTB data is rela-
role: ARG1 
role: ARG2 
cat: NP 
role: rel sns: 01 msd: p---a 
cat: NP cat: VBG cat: PP 
id: pb0003.18 status: gold 
Base segmentation: <seg:sink seg:id="42" seg:start="24"       seg:end="35"/> Annotation over the base segmentation: <msd:node msd:id=?16?>    <msd:f name=?cat? value=?NN?/> </msd:node>  <msd:edge from="msd:16" to="seg:42"/> Annotation over another annotation: <ptb:node ptb:id="23">    <ptb:f name="type" value="NP"/>    <ptb:f name="role" value="-SBJ"/> </ptb:node>  <ptb:edge from="ptb:23"to="msd:16"/>  
4
tively trivial.  This task is simplified even further because the PDTB API allows PDTB files to be loaded in a few simple steps, and allows the pro-grammer to set and query features of the node as well as iterate over the children of the node. So, given a node P that represents the root node of a PDTB tree, an equivalent graph G in GrAF format can be created by traversing the PDTB tree and creating matching nodes and edges in the graph G. Like the PTB, TimeBank annotation is embed-ded in the primary data by surrounding annotated elements with XML tags. TB also includes sets of ?link? tags at the end of each document, specifying relations among annotated elements. The same steps for rendering the PTB into GrAF could be followed for TB; however, this would result in a separate (and possibly different) primary data document. Therefore, it is necessary to first align the text extracted from TB with the primary data derived from PTB, after which the TB XML anno-tations are rendered in GrAF format and associated with the corresponding nodes in the base segmen-tation.  Note that in the current GrAF representation, TB?s tlink, slink, and alink annotations are applied to edges, since they designate relations among nodes. However, further consideration of the na-ture and use of the information associated with these links may dictate that associating it with a node is more appropriate and/or useful. Variations in tokenization exist among the dif-ferent annotations, most commonly for splitting contractions or compounds (?cannot? split into ?can? and ?not?, ?New York-based? split into ?New York?, ?-?, and ?based?, etc.). This can be handled by adding edges to the base segmentation (not necessarily in the same segmentation docu-ment) that cover the relevant sub-spans, and point-ing to the new edge nodes as necessary. Annota-tions may now reference the original span, the en-tire annotation, or any sub-part of the annotation, by pointing to the appropriate node. Alternative segmentations of the same span can be joined by a ?dummy? parent node so that when different anno-tations of the same data are later merged, nodes labeling a sub-graph covering the same span can be combined. For example, in Figure 3, if the PTB segmentation (in gray) is the base segmentation, an alternative segmentation of the same span (in black) is created and associated to the PTB seg-mentation via a dummy node. When annotations 
using each of the different segmentations are merged into a single graph, features associated with any node covering the same sub-tree (in bold) are applied to the dummy node (as a result of graph minimization), thus preserving the commonality in the merged graph.             Figure 3: Alternative segmentations 4 Merging Annotations Once they are in in GrAF format, merging annota-tions of the same primary data, or annotations ref-erencing annotations of the same primary data, in-volves simply combining the graphs for each anno-tation, starting with graph G describing the base segmentation and using the algorithm in Figure 4. Once merged, graph minimization, for which effi-cient algorithms exist (see, e.g., Cardon and Cro-chemore, 1982; Habib et al, 1999), can be applied to collapse identically-labeled nodes with edges to common subgraphs and eliminate dummy nodes such as the one in Figure 3. 
 Figure 4: Graph-merging algorithm 
cat: NP 
cat: PUNC type: hyphen cat: VBG N e w  Y o r k  -  b a s e d 
cat: JJ cat: NNP 
cat: ADJP 
role: alt role: alt 
Given a graph G : for each graph of annotations Gp do   for each vertex vp in Gp do   if vp is not a leaf in Gp then     add vp to G   for each edge (vi, vj) in Gp do   if vj is a leaf in Gp then     find corresponding vertex vg ? G    add a new edge (vi, vg) to G     else  add edge (vi, vj) to G 
5
5 Using the Graphs Because the GrAF format is isomorphic to input to many graph-analytic tools, existing software can be exploited; for example, we have generated graph diagrams directly from a merged graph in-cluding PTB, NB, and PB annotations using GraphViz5, which takes as its input a simple text file representation of a graph. Generating the input files to GraphViz involves simply iterating over the nodes and edges in the graph and printing out a suitable string representation. Figure 5 shows a segment of the GraphViz output generated from the PTB/NB/PB merged annotations (modified slightly for readability).  
 Figure 5: Fragment of GraphViz output Graph-traversal and graph-coloring algorithms can be used to identify and generate statistics concern-ing commonly annotated components in the merged graph. For example, we modified the merging algorithm to "color" the annotated nodes as the graphs are constructed to reflect the source of the annotation (e.g., PTB, NB, PB, etc.) and the annotation content itself. Colors are propagated via outgoing edges down to the base segmentation, so that each node in the graph can be identified by the source and type of annotation applied. The colored graph can then be used to identify common sub-graphs. So, for example, a graph traversal can identify higher-level nodes in PTB that cover the same spans as TB annotations, which in the merged graph are connected to sink nodes (tokens) only, thus effectively ?collapsing? the two annota-tions.  
                                                5 www.graphviz.org 
Traversal of the colored graph can also be used to generate statistics reflecting the interactions among annotations. As a simple example, we gen-erated a list of all nodes annotated as ARG0 by both PB and NB6, the ?related? element (a verb for PB, a nominalization for NB), the PTB annotation, and the set of sink nodes covered by the node, which reveals clusters of verb/nominalization pairs and can be used, for example, to augment semantic lexicons. Similar information generated via graph traversal can obviously provide a wealth of statis-tics that can in turn be used to study interactions among linguistic phenomena. Other graph-analytic algorithms?including common sub-graph analy-sis, shortest paths, minimum spanning trees, con-nectedness, identification of articulation vertices, topological sort, graph partitioning, etc.?may prove to be useful for mining information from a graph of annotations at multiple linguistic levels, possibly revealing relationships and interactions that were previously difficult to observe. We have, for example, generated frequent subgraphs of the PB and NB annotations using the IBM Frequent Subgraph Miner7 (Inokuchi et al, 2005). We are currently exploring several additional applications of graph algorithms to annotation analysis.  The graph format also enables manipulations that may be desirable in order to add information, modify the graph to reflect additional analysis, cor-rect errors, etc. For example, it may be desirable to delete or move constituents such as punctuation and parenthetical phrases under certain circum-stances, conjoin sub-graphs whose sink nodes are joined by a conjunction such as ?and?, or correct PP attachments based on information in the tree.  6 Discussion GrAF provides a serialization of annotations that follows the specifications of LAF and is therefore a candidate to serve as the LAF pivot format. The advantages of a pivot format, and, in general, the use of the graph model for linguistic annotations, are numerous. First, transduction of the various formats into GrAF, as described in section 4, de-manded substantial programming effort; similar effort would be required to transduce to any other                                                 6 The gray nodes in Figure 5 are those that have been ?col-ored? by both PB and NB. 7 http://www.alphaworks.ibm.com/tech/fsm 
6
format, graph-based or not. The role of the LAF pivot format is to reduce this effort across the com-munity by an order of magnitude, as shown in Figure 1. Whether or not GrAF is the pivot, the adoption of the graph model, at least for the pur-poses of exchange, would result in a similar reduc-tion of effort, since graph representations are in general trivially mappable. In addition to enabling the generation of input to a wide range of graph-handling software, the graph model for annotations is isomorphic to representa-tion formats used by emerging annotation frame-works, in particular, UIMA?s Common Analysis System8. It is also compatible with tools such as the PDTBAPI, which is easily generalized to han-dle graphs as well as trees. In addition, the graph model underlies Semantic Web formats such as RDF and OWL, so that any annotation graph is trivially transducable to their serializations (which include not only XML but several others as well), and which, as noted above, has spawned a flurry of research using graph algorithms to extract and ana-lyze semantic information from the web. A final advantage of the graph model is that it provides a sound basis for devising linguistic anno-tation schemes. For example, the PB and NB for-mat, although ultimately mappable to a graph rep-resentation, was not developed with the graph model as a basis. The format is ambiguous as to the relations among the parts of the annotation, in particular, the relation between the information at the beginning of the line providing the status (?gold?), sense number, and morpho-syntactic de-scription, and the rest of the annotation. Human interpretation can determine that the status (proba-bly) applies to the whole annotation, and the sense number and msd apply to the PTB lexical item be-ing annotated, as reflected in the graph-based rep-resentation given in section 3. This somewhat in-nocuous example demonstrates an all-too-pervasive feature of many annotation schemes: reliance on human interpretation to determine structural relations that are implicit in the content of the annotation. Blind automatic transduction of the format to any other format is therefore impos-sible, and the interpretation, although more or less clear in this example, is prone to human error. If the designers of the PB/NB format had begun with a graph-based model?i.e., had been forced to                                                 8 http://www.alphaworks.ibm.com/tech/uima 
?draw the circles and lines??this ambiguity would likely have been avoided. 7 Conclusion We have argued that a graph model for linguistic annotations provides the generality and flexibility required for representing linguistic annotations of different types, and provides powerful and well-established means to analyze these annotations in ways that have been previously unexploited. We introduce GrAF, an XML serialization of the graph model, and demonstrate how it can be used to rep-resent annotations originally made available in widely varying formats. GrAF is designed to be used in conjunction with the Linguistic Annotation Framework, which defines an overall architecture for representing layers of linguistic annotation. We show how LAF stand-off annotations in GrAF format can be easily merged and analyzed, and discuss the application of graph-analytic algo-rithms and tools. Linguistic annotation has a long history, and over the past 15-20 years we have seen increasing attention to the need for standardization as well as continuing development and convergence of best practices to enable annotation interoperability. Dramatic changes in technology, an in particular the development of the World Wide Web, have impacted both the ways in which we represent lin-guistic annotations and the urgency of the need to develop sophisticated language processing applica-tions that rely on them. LAF and GrAF are not based on brand new ideas, but rather reflect and make explicit what appears to be evolving as common best practice methodology.  References A. Cardon and Maxime Crochemore, 1982. Partitioning a graph in O(|A| log2 |V| ).Theoretical Computer Sci-ence, 19(1):85?98.  Akihiro Inokuchi, Takashi Washio, and Hiroshi Mo-toda, 2005. A General Framework for Mining Fre-quent Subgraphs from Labeled Graphs. Fundamenta Informaticae, 66:1-2, 53-82. Andrew A. Krizhanovsky, 2005. Synonym search in Wikipedia: Synarcher. http://www.citebase.org/abstract?id=oai:arXiv.org:cs/0606097 
7
Dat P.T Nguyen, Yutaka Matsuo, and Mitsuru Ishizuka, 2007. Exploiting Syntactic and Semantic Information for Relation Extraction from Wikipedia. IJCAI Workshop on Text-Mining & Link-Analysis (TextLink 2007). Dominic Widdows and Beate Dorow, 2002. A graph model for unsupervised lexical acquisition. Proceed-ings of the 19th International Conference on Compu-tational Linguistics, 1093-1099. Evgeniy Gabrilovich and Shaul Markovitch, 2007. Computing Semantic Relatedness Using Wikipedia-based Explicit Semantic Analysis. Proceedings of the 20th International Joint Conference on Artificial In-telligence, Hyderabad, India. Hang Cui, Renxu Sun, Keya Li, Min-Yen Kan and Tat-Seng Chua, 2005. Question answering passage re-trieval using dependency relations. SIGIR '05: Pro-ceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 400-407. Jeffrey Dean, Monika R. Henzinger, 1999. Finding re-lated pages in the World Wide Web. Computer Net-works, 31(11-16):1467?1479. John E. McEneaney, 2001. Graphic and numerical methods to assess navigation in hypertext. Interna-tional Journal of Human-Computer Studies, 55, 761-786.  Jon M. Kleinberg, 1999. Authoritative sources in a hy-per-linked environment. Journal of the ACM 46(5):604-632.  Michel Habib, Christophe Paul, Laurent Viennot, 1999. Partition refinement techniques: An interesting algo-rithmic tool kit. International Journal of Foundations of Computer Science, 10(2):147?170. Mohammed J. Zaki, 2002. Efficiently mining trees in a forest. Proceedings of SIGKDD?02. Nancy Ide and Laurent Romary, 2004. A Registry of Standard Data Categories for Linguistic Annotation. Proceedings of the Fourth Language Resources and Evaluation Conference (LREC), Lisbon, 135-39. Nancy Ide and Laurent Romary, 2004. International Standard for a Linguistic Annotation Framework. Journal of Natural Language Engineering, 10:3-4, 211-225. Nancy Ide and Laurent Romary, 2006.  Representing Linguistic Corpora and Their Annotations. Proceed-ings of the Fifth Language Resources and Evaluation Conference (LREC), Genoa, Italy. 
Razvan C. Bunescu and Raymond J. Mooney, 2007. Extracting relations from text: From word sequences to dependency paths. In Anne Kao and Steve Poteet (eds.), Text Mining and Natural Language Process-ing, Springer, 29-44. Sergey Brin, 1998. Extracting patterns and relations from the world wide web. Proceedings of the 1998 International Workshop on the Web and Databases, 172-183. Sisay Fissaha Adafre and Maar ten de Rijke, 2005. Dis-covering missing links in Wikipedia. Workshop on Link Discovery: Issues, Approaches and Applica-tions. Stephen Bird and Mark Liberman, 2001. A formal framework for linguistic annotation. Speech Commu-nication, 33:1-2, 23-60. Vivi Nastase and Stan Szpakowicz, 2006. Matching syntactic-semantic graphs for semantic relation as-signment. Proceedings of TextGraphs: the Second Workshop on Graph Based Methods for Natural Language Processing, 81-88. 
8
Proceedings of the Third Linguistic Annotation Workshop, ACL-IJCNLP 2009, pages 27?34,
Suntec, Singapore, 6-7 August 2009. c?2009 ACL and AFNLP
Bridging the Gaps:
Interoperability for GrAF, GATE, and UIMA
Nancy Ide
Department of Computer Science
Vassar College
Poughkeepsie, New York USA
ide@cs.vassar.edu
Keith Suderman
Department of Computer Science
Vassar College
Poughkeepsie, New York USA
suderman@anc.org
Abstract
This paper explores interoperability for
data represented using the Graph Anno-
tation Framework (GrAF) (Ide and Sud-
erman, 2007) and the data formats uti-
lized by two general-purpose annotation
systems: the General Architecture for Text
Engineering (GATE) (Cunningham, 2002)
and the Unstructured Information Man-
agement Architecture (UIMA). GrAF is
intended to serve as a ?pivot? to enable
interoperability among different formats,
and both GATE and UIMA are at least im-
plicitly designed with an eye toward inter-
operability with other formats and tools.
We describe the steps required to per-
form a round-trip rendering from GrAF to
GATE and GrAF to UIMA CAS and back
again, and outline the commonalities as
well as the differences and gaps that came
to light in the process.
1 Introduction
The creation of language data and linguistic anno-
tations remains a fundamental activity in the field
of language technology, in order to develop in-
creasingly sophisticated understanding and gener-
ation capabilities for the world?s languages. Sub-
stantial effort has been devoted to the creation of
resources for major languages, and new projects
are developing similar resources for less widely-
used languages; the cost and effort of resource cre-
ation, as well as the possibilities for linking multi-
lingual and multi-modal language data, demands
that resources and tools are reusable as well as
compatible in terms of their representation. Var-
ious representation standards and annotation tools
have emerged over the past decade and have con-
tributed to some convergence in practice, but at the
same time, there has been growing recognition that
interoperability among formats and tools, rather
than universal use of a single representation for-
mat, is more suited to the needs of the community
and language technology research in general.
This paper explores interoperability for data
represented using the Graph Annotation Frame-
work (GrAF) (Ide and Suderman, 2007) and the
data formats utilized by two general-purpose an-
notation systems: the General Architecture for
Text Engineering (GATE) (Cunningham, 2002)
and the Unstructured Information Management
Architecture (UIMA)1. UIMA and GATE are sim-
ilar in design and purpose: both represent docu-
ments as text plus annotations and allow users to
define pipelines of processes that manipulate the
document. However, there are some differences
in implementation and representation format that
prohibit direct exchange of data and annotations
between the two.
The Graph Annotation Framework (GrAF) (Ide
and Suderman, 2007) is intended to serve as a
?pivot? to enable interoperability among different
formats for data and linguistics annotations and
the systems that create and exploit them. In this
paper, we describe the steps required to perform
a round-trip rendering from GrAF to GATE and
GrAF to UIMA CAS and back again, and outline
the commonalities as well as the differences and
gaps that came to light in the process. In doing
so, we hope to shed some light on the design and
implementation choices that either contribute to
or impede progress toward interoperability, which
can feed future development.
2 Background
A handful of formats for linguistic data and
annotations have been proposed as standards
over the past ten years, including Annotation
Graphs (AG) (Bird and Liberman, 2001), and,
1http://www.oasis-open.org/committees/uima/
27
most recently, the Graph Annotation Framework
(GrAF) (Ide and Suderman, 2007). UIMA?s
Common Analysis System (CAS) also provides a
?common? way to represent annotations so that
they can be shared and reused among UIMA an-
notator components.
Annotation Graphs were introduced primarily
as a means to handle time-stamped speech data, in
large part to overcome the problem of overlapping
annotations that violate the strict tree structure of
XML-based schemes. However, AGs are limited
by the inability to represent hierarchical relations
among annotations (as, for instance, in a syntax
tree). AGs are used in GATE to represent standoff
annotations.
GrAF has been developed by the International
Standards Organization (ISO)?s TC37 SC4, as a
part of the Linguistic Annotation Framework (In-
ternational Standards Organization, 2008). GrAF
provides an XML serialization of an abstract data
model for annotations that is intended to serve as
a ?pivot? for transducing among user-defined and
tool input annotation formats. GrAF is intended to
function in much the same way as an interlingua
in machine translation: a common, abstract con-
ceptual representation into and out of which user-
and tool-specific formats are transduced, so that
a transduction of any specific format into and out
of GrAF accomplishes the transduction between
it and any number of other GrAF-conformant for-
mats. GrAF is currently an ISO Candidate Draft.
The UIMA framework is a data management
system that supports pipelined applications over
unstructured data. UIMA was originally de-
veloped by IBM and is currently under further
development by an OASIS technical commit-
tee2. Apache UIMA3 is an Apache-licensed open
source implementation of the UIMA specification
being developed as an Apache incubator project.
UIMA?s Common Analysis System (CAS) is used
to describe typed objects (annotations) associated
with a given text or other media, upon which pro-
cessing modules (?annotators?) operate.
2.1 Annotation models
Each of the formats described above is based on
some model of annotations and their relation to
the data they describe. The AG model consists of
sets of arcs defined over nodes corresponding to
2http://www.oasis-open.org/committees/uima/
3http://incubator.apache.org/uima/index.html
timestamps in primary data, each of which is la-
beled with an arbitrary linguistic description that
applies to that region. Multiple annotations over
the data produce multiple arcs; there is no provi-
sion for arcs associating annotations.
GrAF defines the regions to be annotated in pri-
mary data as the area bounded by two or more an-
chors. The definition of anchor and the number
of anchors needed to define a region depends on
the medium being annotated. The only assumption
that GrAF makes is that anchors have a natural or-
dering. For textual data GrAF uses character off-
sets for anchors, and two anchors bound each re-
gion. Regions serve as the leaf nodes of a directed
acyclic graph. Annotations in the form of feature
structures are associated with nodes in the graph,
including nodes associated with both regions and
other annotations, via edges in the graph. GrAF
can represent common annotation types such as
hierarchical syntax trees by allowing, for exam-
ple, a sentence annotation to have edges to con-
stituent annotations such as NP, VP, etc. As op-
posed to AGs, annotations typically label nodes
rather than edges in GrAF, although labeled edges
are allowed, and the information comprising the
annotations is represented using feature structures
rather than simple labels.
The underlying model of UIMA CAS is simi-
lar to GrAF?s, due to its hierarchical type system
and the use of feature structures to represent anno-
tation information. In fact, the GrAF model, con-
sisting of a directed acyclic graph whose nodes are
labeled with feature structures, provides the rele-
vant abstraction underlying UIMA CAS. In prin-
ciple, then, annotations represented in GrAF and
UIMA CAS are trivially mappable to one another.
The same is not true for AGs: in GrAF, annota-
tions can be directly linked to other annotations,
but in the AG model annotations are effectively in-
dependent layers linked to the primary data. As a
result, while it is possible to ?flatten? a GrAF rep-
resentation so that it can be represented as an AG,
it is not possible to take the round trip back into
GrAF without losing information about relations
among annotations. An AG can, of course, always
be represented in GrAF, since independent graphs
layered over data (possibly with shared anchors in
the data) are valid GrAF structures.
28
3 GrAF? UIMA? GrAF
Conversion of a GrAF data structure into UIMA
involves generating (1) a UIMA data structure (a
CAS), (2) a UIMA type system, and a specification
of type priorities.
The CAS consists of a subject of analysis (sofa),
which is the data (in our examples here, a text) it-
self, together with its annotations. The CAS XML
representation of the annotations is very similar to
the GrAF XML representation: each annotation is
identified by its start and end location in the data
expressed in terms of virtual nodes between each
character in the data, where the position before the
first character is node 0. The conversion of GrAF
anchors to UIMA indexes is therefore trivial.
3.1 UIMA Type Systems
A UIMA type system specifies the type of data
that can be manipulated by annotator components.
A type system defines two kinds of objects; types
and features. The type defines the kinds of data
that can be manipulated in a CAS, arranged in an
inheritance hierarchy. A feature defines a field,
or slot, within a type. Each CAS type specifies
a single supertype and a list of features that may
be associated with that type. A type inherits all
of the features from its supertype, so the features
that can be associated with a type is the union of
all features defined by all supertypes in the inher-
itance tree. A feature is a name/value pair where
the value can be one of UIMA?s built in primitive
types (boolean, char, int, etc.) or a reference to
another UIMA object. UIMA also allows feature
values to be arrays of either primitive types or ar-
rays of references to other objects.
UIMA defines a top level type uima.cas.TOP
which contains no features and serves as the
root of the UIMA type system inheritance tree.
The root type uima.cas.TOP is the supertype
of uima.cas.AnnotationBase, which is the super-
type of uima.tcas.Annotation, which in turn is
the supertype for org.xces.graf.uima.Annotation.
All UIMA annotations generated by GrAF use
org.xces.graf.uima.Annotation as their supertype.
Note that the UIMA type hierarchy is strictly an is-
a hierarchy; for example, there may be an annota-
tion type pos with subtypes penn pos, claws pos,
etc., indicating that each of these annotations are
a kind of part of speech annotation. The hierar-
chy does not reflect other kinds of relations such
as the relation between a ?lemma? annotation and
a ?pos? annotation (i.e., a lemma and a pos are
typically companion parts of a morpho-syntactic
description, but neither one is a morpho-syntactic
description), or constituency relations in syntactic
annotation schemes.
The GrAF Java API provides a Java class that
generates a valid UIMA type system given one or
more GrAF objects. The type system is generated
by iterating over all the nodes in the graph and cre-
ating a new type for each kind of annotation en-
countered (e.g., token, sentence, POS, etc.). Fea-
ture descriptions are generated for each type at the
same time.
One drawback of deriving a type system auto-
matically is that some of the power of UIMA type
systems is lost in the conversion. For example,
in the process of conversion, all feature values are
assumed to be strings, even though UIMA allows
specification of the type of a feature value. Since
in GrAF, feature values have been serialized from
the contents of an XML attribute, all feature values
are represented internally as strings; to convert a
feature value to any other representation would re-
quire that GrAF have some external knowledge of
the annotation format being deserialized. There-
fore, any type checking capability for feature value
types in UIMA is lost after automatic generation
of the type system. Similarly, it is not possible
to determine a supertype for an annotation if it is
more specific than org.xces.graf.uima.Annotation
from the information in the GrAF representation
alone, so in effect, it is not possible to derive
any meaningful type hierarchy without additional
knowledge. For example, it is not possible to in-
clude the information in the type system descrip-
tion that penn pos and claws pos are subtypes of
pos since this information is not represented in the
graph. Even in cases where this kind of informa-
tion is represented in the graph, it is not retriev-
able; for example, FrameNet annotation includes
a grammaticalFunction annotation whose children
are elements such as subject, object, etc.
However, there is no way to determine what the
parent-child relation is between nodes without a
priori knowledge of the annotation scheme.
Without a source of external knowledge, GrAF
does not attempt to make any assumptions about
the annotations and features in the graph. How-
ever, all of these problems are avoided by pro-
viding an XML Schema or other source of infor-
mation about the GrAF annotations that can be
29
used when generating the type system. The XML
schema can specify the type hierarchy, data types
and restricted ranges for feature values, etc. (see,
for example, the XCES (Ide et al, 2000) schema is
used for the data and annotations in the American
National Corpus (ANC)4.)
3.2 UIMA Views and Indexes
A UIMA CAS object may contain more than one
view of the artifact being annotated; for example, a
CAS may contain an audio stream as one view and
the transcribed text as another. Each view contains
a copy of the artifact, referred to as the subject of
analysis (sofa), and a set of indexes that UIMA an-
notators (processing modules) use to access data in
the CAS. Each index is associated with one CAS
type and indexes that type by its features?that is,
the features are the keys for the index.
The indexes are the only way for UIMA annota-
tors to access annotations in the CAS. It is neces-
sary to generate these indexes, which are not pro-
vided automatically within UIMA. The GrAF Java
API provides a module that generates the indexes
at the same time the it generates the type system
description. Since we do not know, and make no
assumptions about, which annotations might be
required by other annotators, all annotations are
indexed by all of their features.
3.3 Type Priorities
Type priorities in UIMA are used to determine
nesting relations when iterating over collections of
annotations. That is, if two annotations have the
same start and end offsets, then the order in which
they will be presented by an iterator is determined
by their type priority; the annotation with the high-
est priority will be presented first. Type priorities
are specified by an ordered listing of annotation
types, where order determines priority. In GrAF,
annotation nesting is implicit in the graph itself.
To generate an explicit type priority specifica-
tion for UIMA we must first obtain a list of all
annotation types that appear in the graph and then
sort the list based on the order they are encoun-
tered during a a depth first traversal of the graph.
During the depth first traversal a N x N precedence
matrix is constructed where N is the number of an-
notation types in the graph. If precedes[A,B] ==
true then A was encountered as an ancestor of B
in the depth first traversal. If precedes[A,B] ==
4http://www.anc.org
precedes[B,A] == true then it is assumed that the
annotation types have the same priority. Once the
list of annotation types has been collected and the
precedence matrix constructed, the matrix can be
used to to sort the annotation types:
int compare(Annotation A,
Annotation B,
PrecedenceMatrix m)
{
boolean AB = m.precedes(A,B);
boolean BA = m.precedes(B,A);
if (AB && BA)
{
return 0; // equal
}
else if (AB)
{
return -1; // A first.
}
else if (BA)
{
return 1; // B first.
}
// Neither AB or BA means A and
// B are not in connected
// components.
return 0;
}
Not all nodes in the graph may be reachable
in a depth first traversal, particularly if multiple
annotations formats have been merged together.
Therefore, after the initial traversal has been com-
pleted each node is checked to determine if it
has been visited. If not, then another traversal is
started from that node. This is repeated until all
nodes/annotations in the graph have been visited
at least once.
We have found that UIMA type priorities im-
pose some limitations because they cannot repre-
sent context sensitive annotation orderings. For
example, given
<!ELEMENT E1 (A,B)>
<!ELEMENT E2 (B,A)>
The order of A and B differs depending on whether
the parent annotation is E1 or E2. This type of re-
lationship cannot be expressed by a simple order-
ing of annotations.
3.4 Naming Conflicts
The annotation type names used when generat-
ing the UIMA type system are derived automat-
ically based on the annotation names used in
the graph. Annotations in GrAF may also be
grouped into named annotation sets and the gen-
30
<as type="POS">
<a label="token">
<fsr:fs type="PENN">
<fsr:f name="msd" fVal="NN"/>
</fsr:fs>
<fsr:fs type="CLAWS5">
<fsr:f name="msd" fVal="NN"/>
</fsr:fs>
</a>
</as>
Figure 1: GrAF representation of alternative POS
annotations
erated UIMA type name consists of a concatena-
tion of the nested annotation set names with the
annotation label appended. For example, multiple
part of speech annotations may be represented in
different annotation sets, as shown in Figure 1.5
For the above example, two types will
be generated: POS token PENN and
POS token CLAWS5. However, GrAF places
no restrictions on the names used for annotation
set names, annotation labels, or feature structure
types. Therefore, it is possible that the derived
type name is not a valid UIMA identifier, which
are required to follow Java naming conventions.
For example, Part-Of-Speech is a valid name
for an annotation label in GrAF, but because of
the hyphen it is not a valid Java identifier and
therefore not valid in UIMA.
To avoid the naming problem, a derived name
is converted into a valid UIMA identifier before
creating the UIMA type description. To permit
round trip engineering, that is, ensuring a GrAF?
UIMA?GrAF transformation results in the same
GrAF representation as the original, a NameMap
file is produced that maps a generated name to
the compatible UIMA name. NameMaps can be
used in a UIMA? GrAF conversion to ensure the
GrAF annotations and annotation sets created are
given the same names as they had in the original
GrAF representation.
3.5 Preserving the Graph Structure
While UIMA does not have any graph-specific
functionality, the value of a UIMA feature can
be an array of annotations, or more specifically,
an array of references to other annotations. In
5The use of the fVal attribute in this example is sub-
ject to change according to revisions of ISO/DIS 24610-1
Language Resource Management - Feature Structures - Part
1: Feature Structure Representation (International Standards
Organization, 2005), to which the representation of feature
structures in GrAF adheres.
this way, annotations can effectively ?point? to
other annotations in UIMA. We exploit this ca-
pability to preserve the structure of the original
graph in the UIMA representation, by adding two
features to each annotation: graf children
and graf ancestors. This information can be
used to recreate the GrAF representation, should
that ever be desired. It can also be used by UIMA
annotators that have been designed to use and/or
manipulate this information.
Although rarely used, GrAF permits edges in
the graph to be annotated in the same way that
nodes are. For UIMA conversion, if a graph con-
tains labeled edges it must be converted into an
equivalent graph without labeled edges. A graph
with labeled edges can be converted into an equiv-
alent graph without labeled edges, where a node
replaces the original edge. To preserve the origi-
nal graph structure, an attribute indicating that the
node is represented as a a labeled edge in GrAF is
included.
4 GrAF? GATE? GrAF
The conversion to/from GATE is much simpler
than conversion to UIMA, since GATE is type-
less and does not require the overhead of gener-
ating a type system or type priorities list. While
GATE does support annotation schemas, they are
optional, and annotations and features can be cre-
ated at will. GATE is also much more lenient
on annotation and feature names; names automat-
ically generated by GrAF are typically valid in
GATE.
Representing the graph structure in GATE is not
as straightforward as it is in UIMA. We have de-
veloped a plugin to GATE that loads GrAF stand-
off annotations into GATE, and a parallel plugin
that generates GrAF from GATE?s internal format.
As noted above, GATE uses annotation graphs to
represent annotations, However, because annota-
tion graphs do not provide for annotations of an-
notations, to transduce from GrAF to the GATE in-
ternal format it is necessary to ?flatten? the graph
so that nodes with edges to other nodes are mod-
ified to contain edges directly into the primary
data. GATE assigns a unique id value to every an-
notation, so it is possible to link annotations by
creating a special feature and referencing the par-
ent/child annotations by their GATE id values.
The greatest difficulty in a GrAF? GATE con-
version arises from the fact that in GATE, every
31
Figure 2: UIMA rendering of GrAF annotations
annotation is expected to have a start and end off-
set. In GrAF, a node may have multiple edges
to other nodes that cover disjoint regions of text.
For example, the FrameNet6 annotation for a given
verb typically includes edges to the associated role
fillers (e.g., agent, theme, instrument, etc.), which
are rarely contiguous in the text itself. Our current
solution to this problem is to give a start and end
offset that covers the smallest region of the text
covering the regions associated with all descen-
dants of the annotation, and recording the infor-
mation concerning the original graph structure in
attributes to enable reconversion into the original
GrAF representation.
5 Exploiting Interoperability
GrAF is intended to serve as the lingua franca for
data and annotations used in processing systems
such as GATE and UIMA. As such, it provides
a way for users to take advantage of each frame-
work?s strengths, e.g., UIMAs capabilities for de-
ploying analysis engines as services that can be
run remotely, and GATE?s wide array of process-
ing resources and capabilities for defining regu-
6http://framenet.icsi.berkeley.edu/
lar expressions over annotations (JAPE). It should
be noted that GATE provides wrappers to allow a
UIMA analysis engine to be used within GATE,
and to allow a GATE processing pipeline to be
used within UIMA. To share data and annota-
tions between the two systems, it is necessary to
construct a mapping descriptor to define how to
map annotations between the UIMA CAS and the
GATE Document, which operate similarly to the
converters from and to GrAF from data and an-
notations described above. However, one advan-
tage of using a GrAF representation as a pivot be-
tween the two systems is that when an annotation
schema is used with GrAF data, the conversion
from GATE to UIMA is more robust, reflecting the
true type description and type priority hierarchies.
Using GrAF as a pivot has more general ad-
vantages, for example, by allowing annotations
to be imported from and exported to a wide va-
riety of formats, and also enabling merging an-
notations from disparate sources into a single an-
notation graph. Figure 2 shows a rendering of
a Penn Treebank annotation (bracketed format)
and a FrameNet annotation (XML) that have been
transduced to GrAF, merged, and the transduced
32
Figure 3: GATE rendering of GrAF annotations
for use in UIMA. The same data is shown ren-
dered in GATE in Figure 3. The two ?views?
of the data consisting of overlaid annotations for
each annotation type are visible in each render-
ing. There are multiple possibilities for exploiting
and exploring merged annotations representing a
range of annotation types within these two frame-
works. For example, a UIMA analysis engine
could be developed to identify regions annotated
by both schemes, or all FrameNet elements that
are annotated as agent and also annotated with
Penn Treebank NP-OBJ, etc. In GATE, JAPE
rules could locate patterns in annotations obtained
from different sources, or named entity recogni-
tion rules could be enhanced with annotation in-
formation from data annotated in other formats.
It would also be possible to compare multiple an-
notations of the same type, such as different tok-
enizations, different POS taggings , etc.
As a final note, we point out that in addi-
tion to conversion to UIMA and GATE, annota-
tions from different sources (singly or merged in
any combination) can also be converted to sev-
eral other formats by using the GrAF Java API.
The API allows the user to select from among ex-
isting annotations and specify an output format
for their merged representation. Currently, in ad-
dition to GrAF, the following output formats are
supported: XML documents with inline annota-
tions; formats compatible with Monoconc Pro7
and Wordsmith Tools8; NLTK9; CONLL (B-I-E)
format; and UIMA CAS.10 So, for example, it is
possible to load a collection of standoff annota-
tion files and convert to XML, and then present
them to XML-aware applications as XML files
with inline annotations. As a result, we are be-
ginning to see possibilities for true interoperabil-
ity among not only major frameworks like UIMA
and GATE, but also applications with more limited
functionalities as well as in-house formats. This,
in turn, opens up the potential to mix and match
among tools for various kinds of processing as ap-
propriate to a given task. In general, the trans-
duction of ?legacy schemes? such as Penn Tree-
bank into GrAF greatly facilitates their use in ma-
jor systems such as UIMA and GATE, as well as
7http://www.athel.com/mono.html
8http://www.lexically.net/wordsmith/
9http://www.nltk.org/
10Note that to render GrAF into GATE, a plugin within the
GATE environment is used to perform the conversion.
33
Figure 4: Conversion capabilities
other applications and systems. Figure 4 shows
the conversion capabilities among a few annota-
tions schemes, GrAF, and UIMA and GATE.
All of our conversion tools and GATE plugins
are freely available for download with no restric-
tions at http://www.anc.org. The UIMA project
has received support to develop a UIMA? GrAF
conversion module, which should be available in
the near future.
6 Conclusion
Consideration of the transduction from a generic,
relatively abstract representation scheme such as
GrAF into the formats required for widely adopted
frameworks for creating and analyzing linguisti-
cally annotated data has several ramifications for
interoperability. First, it brings to light the kinds
of implementation choices that either contribute to
or impede progress toward interoperability, which
can feed future development. Second, our work
on converting GrAF to the formats supported by
UIMA and GATE shows that while minor differ-
ences exist, the underlying data models used by
the two frameworks are essentially the same, as
well as being very similar to the data model under-
lying GrAF. This is good news for interoperability,
since it means that there is at least implicit conver-
gence on the data model best suited for data and
annotations; the differences lie primarily in the
ways in which the model is serialized internally
and as output by different tools. It also means that
transduction among the various formats is possible
without loss of information.
We have shown that a UIMA?GrAF or GATE
? GrAF conversion is fairly straightforward; the
expressive power of GrAF can easily represent the
data models used by UIMA and GATE. On the
other hand, GrAF ? UIMA or GrAF ? GATE
transformations are less straightforward. Both
frameworks can represent graphs, but neither pro-
vides a standard representation that other compo-
nents are guaranteed to understand. Given that
powerful analysis algorithms for data in graphs are
well-established, there may be considerable ad-
vantage to using the graph as a general-purpose
format for use within various modules and ana-
lytic engines. In any case, the generality and flexi-
bility of the GrAF representation has already been
shown to be an effective means to exchange lin-
guistic data and annotations that exist in different
formats, as well as a model for development of an-
notation schemes in the future.
Acknowledgments
This work was supported by an IBM UIMA In-
novation Award and National Science Foundation
grant INT-0753069.
References
Steven Bird and Mark Liberman. 2001. A Formal
Framework for Linguistic Annotation. Speech Com-
munication, 33:1-2, 23-60.
Nancy Ide and Keith Suderman. 2007. GrAF:
A Graph-based Format for Linguistic Annotations.
Proceedings of the First Linguistic Annotation
Workshop, Prague, Czech Republic, June 28-29, 1-8.
International Standards Organization. 2008. Lan-
guage Resource Management - Linguistic Annota-
tion Framework. ISO Document WD 24611.
International Standards Organization. 2005. Language
Resource Management - Feature Structures - Part 1:
Feature Structure Representation. ISO Document
ISO/DIS 24610-1.
Nancy Ide, Patrice Bonhomme, and Laurent Ro-
mary. 2000. XCES: An XML-based Standard
for Linguistic Corpora. Proceedings of the Sec-
ond Language Resources and Evaluation Confer-
ence (LREC), Athens, Greece, 825-30.
Hamish Cunningham. 2002. GATE, a General Ar-
chitecture for Text Engineering. Computers and the
Humanities, 36:223-254
34
Proceedings of the Workshop on Open Infrastructures and Analysis Frameworks for HLT, pages 34?43,
Dublin, Ireland, August 23rd 2014.
The Language Application Grid Web Service Exchange Vocabulary
Nancy Ide
Department of Computer Science
Vassar College
Poughkeepsie, New York USA
ide@cs.vassar.edu
James Pustejovsky
Department of Computer Science
Brandeis University
Waltham, Massachusetts USA
jamesp@cs.brandeis.edu
Keith Suderman
Department of Computer Science
Vassar College
Poughkeepsie, New York USA
suderman@anc.org
Marc Verhagen
Department of Computer Science
Brandeis University
Waltham, Massachusetts USA
marc@cs.brandeis.edu
Abstract
In the context of the Linguistic Applications (LAPPS) Grid project, we have undertaken the def-
inition of a Web Service Exchange Vocabulary (WS-EV) specifying a terminology for a core
of linguistic objects and features exchanged among NLP tools that consume and produce lin-
guistically annotated data. The goal is not to define a new set of terms, but rather to provide a
single web location where terms relevant for exchange among NLP tools are defined and pro-
vide a ?sameAs? link to all known web-based definitions that correspond to them. The WS-EV
is intended to be used by a federation of six grids currently being formed but is usable by any
web service platform. Ultimately, the WS-EV could be used for data exchange among tools in
general, in addition to web services.
1 Introduction
There is clearly a demand within the community for some sort of standard for exchanging annotated lan-
guage data among tools.
1
This has become particularly urgent with the emergence of web services, which
has enabled the availability of language processing tools that can and should interact with one another,
in particular, by forming pipelines that can branch off in multiple directions to accomplish application-
specific processing. While some progress has been made toward enabling syntactic interoperability via
the development of standard representation formats (e.g., ISO LAF/GrAF (Ide and Suderman, 2014;
ISO-24612, 2012), NLP Interchange Format (NIF) (Hellmann et al., 2013), UIMA
2
Common Analysis
System (CAS)) which, if not identical, can be trivially mapped to one another, semantic interoperability
among NLP tools remains problematic (Ide and Pustejovsky, 2010). A few efforts to create repositories,
type systems, and ontologies of linguistic terms (e.g., ISOCat
3
, OLiA
4
, various repositories for UIMA
type systems
5
, GOLD
6
, NIF Core Ontology
7
) have been undertaken to enable (or provide) a mapping
among linguistic terms, but none has yet proven to include all requisite terms and relations or be easy
to use and reference. General repositories such as Dublin Core
8
, schema.org, and the Friend of a Friend
This work is licensed under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer
are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/
1
See, for example, proceedings of the recent LREC workshop on ?Language Technology Service Platforms: Synergies,
Standards, Sharing? (http://www.ilc.cnr.it/ltsp2014/).
2
https://uima.apache.org/
3
http://www.isocat.org
4
http://nachhalt.sfb632.uni-potsdam.de/owl/
5
E.g., http://www.julielab.de/Resources/Software/UIMA+type+system-p-91.html
6
http://linguistics-ontology.org
7
http://persistence.uni-leipzig.org/nlp2rdf/ontologies/nif-core/nif-core
8
http://dublincore.org
34
project
9
include some relevant terms, but they are obviously not designed to fully cover the kinds of
information found in linguistically annotated data.
In the context of the Linguistic Applications (LAPPS) Grid project (Ide et al., 2014), we have under-
taken the definition of a Web Service Exchange Vocabulary (WS-EV) specifying a terminology for a core
of linguistic objects and features exchanged among NLP tools that consume and produce linguistically
annotated data. The work is being done in collaboration with ISO TC37 SC4 WG1 in order to ensure
full community engagement and input. The goal is not to define a new set of terms, but rather to provide
a single web location where terms relevant for exchange among NLP tools are defined and provide a
?sameAs? link to all known web-based definitions that correspond to them. A second goal is to define
relations among the terms that can be used when linguistic data are exchanged. The WS-EV is intended
to be used by a federation of grids currently being formed, including the Kyoto Language Grid
10
, the
Language Grid Jakarta Operation Center
11
, the Xinjiang Language Grid, the Language Grid Bangkok
Operation Center
12
, LinguaGrid
13
, MetaNET/Panacea
14
, and LAPPS, but is usable by any web service
platform. Ultimately, the WS-EV could be used for data exchange among tools in general, in addition to
web services.
This paper describes the LAPPS WS-EV, which is currently under construction. We first describe the
LAPPS project and then overview the motivations and principles for developing the WS-EV. Because
our goal is to coordinate with as many similar projects and efforts as possible to avoid duplication, we
also describe existing collaborations and invite other interested groups to provide input.
2 The Language Application Grid Project
The Language Application (LAPPS) Grid project is in the process of establishing a framework that
enables language service discovery, composition, and reuse, in order to promote sustainability, manage-
ability, usability, and interoperability of natural language Processing (NLP) components. It is based on
the service-oriented architecture (SOA), a more recent, web- oriented version of the pipeline architecture
that has long been used in NLP for sequencing loosely-coupled linguistic analyses. The LAPPS Grid
provides a critical missing layer of functionality for NLP: although existing frameworks such as UIMA
and GATE provide the capability to wrap, integrate, and deploy language services, they do not provide
general support for service discovery, composition, and reuse.
The LAPPS Grid is a collaborative effort among US partners Brandeis University, Vassar College,
Carnegie-Mellon University, and the Linguistic Data Consortium at the University of Pennsylvania, and
is funded by the US National Science Foundation (NSF). The project builds on the foundation laid in
the NSF-funded project SILT (Ide et al., 2009), which established a set of needs for interoperability
and developed standards and best practice guidelines to implement them. LAPPS is similar in its scope
and goals to ongoing projects such as The Language Grid
15
, PANACEA/MetaNET
16
, LinguaGrid
17
, and
CLARIN
18
, which also provide web service access to basic NLP processing tools and resources and
enable pipelining these tools to create custom NLP applications and composite services such as question
answering and machine translation, as well as access to language resources such as mono- and multi-
lingual corpora and lexicons that support NLP. The transformative aspect of the LAPPS Grid is therefore
not the provision of a suite of web services, but rather that it orchestrates access to and deployment of
language resources and processing functions available from servers around the globe, and enables users
to easily add their own language resources, services, and even service grids to satisfy their particular
needs.
9
http://www.foaf-project.org
10
http://langrid.nict
11
http://langrid.portal.cs.ui.ac.id/langrid/
12
http://langrid.servicegrid-bangkok.org
13
http://www.linguagrid.org/
14
http://www.panacea-lr.eu
15
http://langrid.nict
16
http://panacea-lr.eu/
17
http://www.linguagrid.org/
18
http://www.clarin.eu/
35
The most distinctive innovation in the LAPPS Grid that is not included in other projects is the provision
of an open advancement (OA) framework (Ferrucci et al., 2009a) for component- and application-based
evaluation of NLP tools and pipelines. The availability of this type of evaluation service will provide an
unprecedented tool for NLP development that could, in itself, take the field to a new level of productivity.
OA involves evaluating multiple possible solutions to a problem, consisting of different configurations
of component tools, resources, and evaluation data, to find the optimal solution among them, and en-
abling rapid identification of frequent error categories, together with an indication of which module(s)
and error type(s) have the greatest impact on overall performance. On this basis, enhancements and/or
modifications can be introduced with an eye toward achieving the largest possible reduction in error rate
(Ferrucci et al., 2009; Yang et al., 2013). OA was used in the development of IBM?s Watson to achieve
steady performance gains over the four years of its development (Ferrucci et al., 2010); more recently,
the open-source OAQA project has released software frameworks which provide general support for
open advancement (Garduno et al., 2013; Yang et al., 2013), which has been used to rapidly develop
information retrieval and question answering systems for bioinformatics (Yang et al., 2013; Patel et al.,
2013).
The fundamental system architecture of the LAPPS Grid is based on the Open Service Grid Initiative?s
Service Grid Server Software
19
developed by the National Institute of Information and Communications
Technology (NICT) in Japan and used to implement Kyoto University?s Language Grid, a service grid
that supports multilingual communication and collaboration. Like the Language Grid, the LAPPS Grid
provides three main functions: language service registration and deployment, language service search,
and language service composition and execution. As noted above, the LAPPS Grid is instrumented
to provide relevant component-level measures for standard metrics, given gold-standard test data; new
applications automatically include instrumentation for component-level and end-to-end measurement,
and intermediate (component-level) I/O is logged to support effective error analysis.
20
The LAPPS
Grid also implements a dynamic licensing system for handling license agreements on the fly
21
, provides
the option to run services locally with high-security technology to protect sensitive information where
required, and enables access to grids other than those based on the Service Grid technology.
We have adopted the JSON-based serialization for Linked Data (JSON-LD) to represent linguistically
annotated data for the purposes of web service exchange. The JavaScript Object Notation (JSON) is a
lightweight, text-based, language-independent data interchange format that defines a small set of format-
ting rules for the portable representation of structured data. Because it is based on the W3C Resource
Definition Framework (RDF), JSON-LD is trivially mappable to and from other graph-based formats
such as ISO LAF/GrAF and UIMA CAS, as well as a growing number of formats implementing the
same data model. Most importantly, JSON- LD enables services to reference categories and definitions
in web-based repositories and ontologies or any suitably defined concept at a given URI.
The LAPPS Grid currently supports SOAP services, with plans to support REST services in the
near future. We provide two APIs: org.lappsgrid.api.DataSource, which provides data
to other services, and org.lappsgrid.api.WebService, for tools that annotate, transform, or
otherwise manipulate data from a datasource or another web service. All LAPPS services exchange
org.lappsgrid.api.Data objects consisting of a discriminator (type) that indicates how to inter-
pret the payload, and a payload (typically a utf-8 string) that consists of the JSON-LD representation.
Data converters included in the LAPPS Grid Service Engines map from commonly used formats to the
JSON-LD interchange format; converters are automatically invoked as needed to meet the I/O require-
ments of pipelined services. Some LAPPS services are pre-wrapped to produce and consume JSON-LD.
Thus, JSON-LD provides syntactic interoperability among services in the LAPPS Grid; semantic inter-
19
http://servicegrid.net
20
Our current user interface provides easy (re-)configuration of single pipelines; we are currently extending the interface
to allow the user to specify an entire range of pipeline configurations using configuration descriptors (ECD; (Yang et al.,
2013) to define a space of possible pipelines, where each step might be achieved by multiple components or services and each
component or service may have configuration parameters with more than one possible value to be tested. The system will then
automatically generate metrics measurements plus variance and statistical significance calculations for each possible pipeline,
using a service-oriented version of the Configuration Space Exploration (CSE) algorithm (Yang et al., 2013).
21
See (Cieri et al., 2014) for a description of how licensing issues are handled in the LAPPS Grid.
36
operability is provided by the LAPPS Web Service Exchange Vocabulary, described in the next section.
3 LAPPS Web Service Exchange Vocabulary
3.1 Motivation
The WS-EV addresses a relatively small but critical piece of the overall LAPPS architecture: it allows
web services to communicate about the content they deliver, such that the meaning?i.e., exactly what
to do with and/or how to process the data?is understood by the receiver. As such it performs the same
function as a UIMA type system performs for tools in a UIMA pipeline that utilize that type system,
or the common annotation labels (e.g., ?Token?, ?Sentence?, etc.) required for communication among
pipelined tools in GATE: these mechanisms provide semantic interoperability among tools as long as one
remains in either the UIMA or GATE world. To pipeline a tool whose output follows GATE conventions
with a tool that expects input that complies with a given UIMA type system, some mapping of terms and
structures is likely to be required.
22
This is what the WS-EV is intended to enable; effectively, it is a
meta-type-system for mapping labels assigned to linguistically annotated data so that they are understood
and treated consistently by tools that exchange them in the course of executing a pipeline or workflow.
Since web services included in LAPPS and federated grids may use any i/o semantic conventions, the
WS-EV allows for communication among any of them?including, for example, between GATE and
UIMA services
23
The ability to pipeline components from diverse sources is critical to the implementation of the OA
development approach described in the previous section, it must be possible for the developer to ?plug
and play? individual tools, modules, and resources in order to rapidly re-configure and evaluate new
pipelines. These components may exist on any server across the globe, consist of modules developed
within frameworks such as UIMA and GATE, and or be user-defined services existing on a local machine.
3.2 WS-EV Design
The WS-EV was built around the following design principles, which were compiled based on input from
the community:
1. The WS-EV will not reinvent the wheel. Objects and features defined in the WS-EV will be linked
to definitions in existing repositories and ontologies wherever possible.
2. The WS-EV will be designed so as to allow for easy, one-to-one mapping from terms designating
linguistic objects and features commonly produced and consumed by NLP tools that are wrapped
as web services. It is not necessary for the mapping to be object-to-object or feature-to-feature.
3. The WS-EV will provide a core set of objects and features, on the principle that ?simpler is better?,
and provide for (principled) definition of additional objects and features beyond the core to represent
more specialized tool input and output.
4. The WS-EV is not LAPPS-specific; it will not be governed by the processing requirements or
preferences of particular tools, systems, or frameworks.
5. The WS-EV is intended to be used only for interchange among web services performing NLP tasks.
As such it can serve as a ?pivot? format to which user and tool-specific formats can be mapped.
6. The web service provider is responsible for providing wrappers that perform the mapping from
internally-used formats to and/or from the WS-EV.
7. The WS-EV format should be compact to facilitate the transfer of large datasets.
22
Within UIMA, the output of tools conforming to different type systems may themselves require conversion in order to be
used together.
23
Figure 5 shows a pipeline in which both GATE and UIMA services are called; GATE-to-GATE and UIMA-to-UIMA
communication does not use the WS-EV, but it is used for communication between GATE and UIMA services, as well as other
services.
37
8. The WS-EV format will be chosen to take advantage, to the extent possible, of existing technologi-
cal infrastructures and standards.
As noted in the first principle, where possible the objects and features in the WS-EV are drawn from
existing repositories such as ISOCat and the NIF Core Ontology and linked to them via the owl:sameAs
property
24
or, where appropriate, rdfs:subClassOf
25
. However, many repositories do not include some
categories and objects relevant for web service exchange (e.g., ?token? and other segment descriptors),
do include multiple (often very similar) definitions for the same concept, and/or do not specify relations
among terms. We therefore attempted to identify a set of (more or less) ?universal? concepts by surveying
existing type systems and schemas ? for example, the Julie Lab and DARPA GALE UIMA type systems
and the GATE schemas for linguistic phenomena ? together with the I/O requirements of commonly
used NLP software (e.g., the Stanford NLP tools, OpenNLP, etc.). Results of the survey for token and
sentence identification and part-of-speech labeling
26
showed that even for these basic categories, no
existing repository provides a suitable set of categories and relations.
Perhaps more problematically, sources that do specify relations among concepts, such as the various
UIMA type systems and GATE?s schemas, vary widely in their choices of what is an object and what
is a feature; for example, some treat ?token? as an object (label) and ?lemma? and ?POStag? as asso-
ciated features, while others regard ?lemma? and/or ?POStag? as objects in their own right. Decisions
concerning what is an object and what is a feature are for the most part arbitrary; no one scheme is right
or wrong, but a consistent organization is required for effective web service interchange. The WS-EV
therefore defines an organization of objects and features for the purposes of interchange only. Where
possible, the choices are principled, but they are otherwise arbitrary. The WS-EV includes sameAs and
similarTo mappings that link to like concepts in other repositories where possible, thus serving primar-
ily to group the terms and impose a structure of relations required for web service exchange in one
web-based location.
In addition to the principles above, the WS-EV is built on the principle of orthogonal design, such that
there is one and only one definition for each concept. It is also designed to be very lightweight and easy
to find and reference on the web. To that end we have established a straightforward web site (the Web
Service Exchange Vocabulary Repository
27
), similar to schema.org, in order to provide web-addressable
terms and definitions for reference from annotations exchanged among web services. Our approach is
bottom-up: we have adopted a minimalist strategy of adding objects and features to the repository only
as they are needed as services are added to the LAPPS Grid. Terms are organized in a shallow ontology,
with inheritance of properties, as shown in Figure 1.
4 WS-EV and JSON-LD
References in the JSON-LD representation used for interchange among LAPPS Grid web services point
to URIs providing definitions for specific linguistic categories in the WS-EV. They also reference doc-
umentation for processing software and rules for processes such as tokenization, entity recognition, etc.
used to produce a set of annotations, which are often left unspecified in annotated resources (see for
example (Fokkens et al., 2013)). While not required for web service exchange in the LAPPS Grid, the
inclusion of such references can contribute to the better replication and evaluation of results in the field.
Figure 3 shows the information for Token, which defines the concept, identifies application types that
produce objects of this type, cross-references a similar concept in ISOCat, and provides the URI for use
in the JSON-LD representation. It also specifies the common properties that can be specified for a set
of Token objects, and the individual properties that can be associated with a Token object. There is no
requirement to use any or all of the properties in the JSON-LD representation, and we foresee that many
web services will require definition of objects and properties not included in the WS-EVR or elsewhere.
24
http://www.w3.org/TR/2004/REC-owl-semantics-20040210/#owl sameAs
25
http://www.w3.org/TR/owl-ref/#subClassOf-def
26
Available at http://www.anc.org/LAPPS/EP/Meeting-2013-09-26-Pisa/ep-draft.pdf
27
http://vocab.lappsgrid.org
38
Figure 1: Fragment of the WS-EV ontology (associated properties in gray)
We therefore provide mechanisms for (principled) definition of objects and features beyond the WS-
EVR. Two options exist: users can provide a URI where a new term or other documentation is defined,
or users may add a definition to the WS-EVR. In the latter case, service providers use the name space
automatically assigned to them at the time of registration, thereby avoiding name clashes and providing
a distinction between general categories used across services and more idiosyncratic categories.
Figure 2 shows a fragment of the JSON-LD representation that references terms in the WS-
EV. The context statement at the top identifies the URI that is to be prefixed to any unknown
name in order to identify the location of its definition. For the purposes of the example, the
text to be processed is given inline. Our current implementation includes results from each step
in a pipeline, where applicable, together with metadata describing the service applied in each step
(here, org.anc.lapps.stanford.SATokenizer:1.4.0) and identified by an internally-defined type (stan-
ford). The annotations include references to the objects defined in the WS-EV, in this example, To-
ken (defined at http://vocab.lappsgrid.org/Token) with (inherited) features id, start, end and specific
feature string, defined at http://vocab.lappsgrid.org/Token#id, http://vocab.lappsgrid.org/Token#start,
http://vocab.lappsgrid.org/Token#end, and http://vocab.lappsgrid.orgToken/#string, respectively. The
web page defining these terms is shown in Figure 3.
"@context" : "http://vocab.lappsgrid.org/",
"metadata" : { },
"text" : {
"@value" : "Some of the strongest critics of our welfare system..." }
"steps" : [ {
"metadata" : {
"contains" : {
"Token" : {
"producer" : "org.anc.lapps.stanford.SATokenizer:1.4.0",
"type" : "stanford"
}
}
},
"annotations" : [ {
"@type" : "Token",
"id" : "tok0",
"start" : 18,
"end" : 22,
"features" : {
string" : "Some" }
},
Figure 2: JSON-LD fragment referencing the LAPPS Grid WS-EV
39
Figure 3: Token definition in the LAPPS WS-EVR
4.1 Mapping to JSON-LD
As noted above in Section 1, existing schemes and systems for organizing linguistic information ex-
changed by NLP tools vary considerably. Figure 4 shows some variants for a few commonly used NLP
tools, which differ in terminology, structure, and physical format. To be used in the LAPPS Grid, tools
such as those in the list are wrapped so that their output is in JSON-LD format, which provides syntactic
interoperability, terms are mapped to corresponding objects in the WS-EV, and the object-feature rela-
tions reflect those defined in the WS-EV. Correspondingly, wrappers transduce the JSON-LD/WS-EV
representation to the format used internally by the tool on input. This way, the tools use their internal
format as usual and map to JSON-LD/WS-EV for exchange only.
40
Name Input Form Output Form Example
Stanford tagger pt n/a word pos opl box NN1
XML n/a XML inline <word id=?0? pos=?VB?>Let</word>
NaCTeM tagger pt n/a word/pos inline box/NN1
CLAWS (1) pt n/a word pos inline box NN1
CLAWS (2) pt n/a XML inline <w id=?2? pos=?NN1?>Type</w>
CST Copenhagen pt n/a word/pos inline box/NN1
TreeTagger pt? n/a word pos lem opl The DT the
TnT token opl word pos opl der ART
word (pos pr)+ opl Falkenstein NE 8.00 NN 1.99
Twitter NLP pt opl word pos conf opl smh G 0.9406
NLTK pt s, bls [(?word?, ?pos?)] inline [(?At?, ?IN?), (?eight?, ?CD?),]
OpenNLP splitter pt n/a sentences ospl I can?t tell you if he?s here.
OpenNLP tokenizer sent ospl tokens wss, ospl I can ?t tell you if he ?s here .
OpenNLP tagger token wss, ospl word pos ospl At IN eight CD o?clock JJ on IN
pt = plain text opl = one per line wss = white space separated
ospl = one sentence per line bps = blank line separated
Figure 4: I/O variants for common splitters, tokenizers, and POS taggers
For example, the Stanford POS tagger XML output format produces output like this:
<word id="0" pos="VB">Let</word>
This maps to the following JSON-LD/WS-EV representation:
{
"@type" : "Token",
"id" : 0",
"start" : 18,
"end" : 21,
"features" : {
"string" : "Let",
"pos" : "VB"
}
}
The Stanford representation uses the term ?word? as an XML element name, gives an id and pos
as attribute-value pairs, and includes the string being annotated as element content. For conversion to
JSON-LD/WS-EV, ?word? is mapped to ?Token?, the attributes id and pos map to features of the Token
object with the same names, and the element content becomes the value of the string feature. Because
the JSON-LD representation uses standoff annotation, the attributes start and end are added in order to
provide the offset location of the string in the original data.
Services that share a format other than JSON-LD need not map into and out of JSON-LD/WS-EV
when pipelined in the LAPPS Grid. For example, two GATE services would exchange GATE XML
documents, and two UIMA services would exchange UIMA CAS, as usual. This avoids unnecessary
conversion and at the same time allows including services (consisting of individual tools or composite
workflows) from other frameworks. Figure 5 gives an example of the logical flow in the LAPPS Grid,
showing conversions into and out of JSON-LD/WS-EV where needed.
Each service in the LAPPS Grid is required to provide metadata that specifies what kind of input is
required and what kind of output is produced. For example, any service as depicted in the flow diagram
in Figure 5 can require input of a particular format (gate, uima, json-ld) with specific content (tokens,
sentences, etc.). The LAPPS Grid uses the notion of discriminators to encode these requirements, and
the pipeline composer can use these discriminators to determine if conversions are needed and/or input
requirements are met. The discriminators refer to elements of the vocabulary.
5 Collaborations
The LAPPS Grid project is collaborating with several other projects in an attempt to harmonize the
development of web service platforms, and ultimately to participate in a federation of grids and ser-
vice platforms throughout the world. Existing and potential projects across the globe are beginning to
41
Figure 5: Logical flow through the LAPPS Grid (client-server communication not represented)
converge on common data models, best practices, and standards, and the vision of a comprehensive in-
frastructure supporting discovery and deployment of web services that deliver language resources and
processing components is an increasingly achievable goal. Our vision is therefore not for a monolithic
grid, but rather a heterogeneous configuration of federated grids that implement common strategies for
managing and inter-changing linguistic information, so that services on all of these grids are mutually
accessible.
To this end, the LAPPS Grid project has established a multi-way international collaboration among the
US partners and institutions in Asia, Australia, and Europe. The basis is a formal federation among the
LAPPS Grid, the Language Grid (Kyoto University, Japan), NECTEC (Thailand), grids operated by the
University of Indonesia and Xinjiang University (China), and LinguaGrid
28
, scheduled for implementa-
tion in January 2015. The connection of these six grids into a single federated entity will enable access
to all services and resources on any of these grids by users of any one of them and, perhaps most impor-
tantly, facilitate adding additional grids and service platforms to the federation. Currently, the European
META-NET initiative is committed to joining the federation in the near future.
In addition to the projects listed above, we are also collaborating with several groups on technical
solutions to achieve interoperability and in particular, on development of the WS-EV, the JSON-LD
format, and a corollary development of an ontology of web service types. These collaborators include
the Alveo Project (Macquarie University, Australia) (Cassidy et al., 2014), the Language Grid project,
and the Lider project
29
. We actively seek collaboration with others in order to move closer to achieving
a ?global laboratory? for language applications.
6 Conclusion
In this paper, we have given a brief overview of the LAPPS Web Service Exchange Vocabulary (WS-
EV), which provides a terminology for a core of linguistic objects and features exchanged among NLP
tools that consume and produce linguistically annotated data. The goal is to bring the field closer to
achieving semantic interoperability among NLP data, tools, and services. We are actively working to both
engage with existing projects and teams and leverage available resources to move toward convergence
of terminology in the field for the purposes of exchange, as well as promote an environment (the LAPPS
Grid) within which the WS-EV can help achieve these goals.
28
http://www.linguagrid.org/
29
http://www.lider-project.eu
42
Acknowledgements
This work was supported by National Science Foundation grants NSF-ACI 1147944 and NSF-ACI
1147912.
References
Steve Cassidy, Dominique Estival, Timothy Jones, Denis Burnham, and Jared Burghold. 2014. The Alveo Virtual
Laboratory: A Web based Repository API. In Proceedings of the Ninth International Conference on Language
Resources and Evaluation (LREC?14), Reykjavik, Iceland, may. European Language Resources Association
(ELRA).
Christopher Cieri, Denise DiPersio, , and Jonathan Wright. 2014. Intellectual property rights management with
web services. In Proceedings of the Workshop on Open Infrastructures and Analysis Frameworks for HLT,
Dublin, Ireland, August.
David Ferrucci, Eric Nyberg, James Allan, Ken Barker, Eric Brown, Jennifer Chu-Carroll, Arthur Ciccolo, Pablo
Duboue, James Fan, David Gondek, Eduard Hovy, Boris Katz, Adam Lally, Michael McCord, Paul Morarescu,
Bill Murdock, Bruce Porter, John Prager, Tomek Strzalkowski, Chris Welty, and Wlodek Zadrozny. 2009.
Towards the Open Advancement of Question Answering Systems. Technical report, IBM Research, Armonk,
New York.
David A. Ferrucci, Eric W. Brown, Jennifer Chu-Carroll, James Fan, David Gondek, Aditya Kalyanpur, Adam
Lally, J. William Murdock, Eric Nyberg, John M. Prager, Nico Schlaefer, and Christopher A. Welty. 2010.
Building Watson: An overview of the DeepQA project. AI Magazine, 31(3):59?79.
Antske Fokkens, Marieke van Erp, Marten Postma, Ted Pedersen, Piek Vossen, and Nuno Freire. 2013. Offspring
from reproduction problems: What replication failure teaches us. In Proceedings of the 51st Annual Meeting
of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1691?1701, Sofia, Bulgaria,
August. Association for Computational Linguistics.
Elmer Garduno, Zi Yang, Avner Maiberg, Collin McCormack, Yan Fang, and Eric Nyberg. 2013. CSE Frame-
work: A UIMA-based Distributed System for Configuration Space Exploration Unstructured Information Man-
agement Architecture. In Peter Klgl, Richard Eckart de Castilho, and Katrin Tomanek, editors, UIMA@GSCL,
CEUR Workshop Proceedings, pages 14?17. CEUR-WS.org.
Sebastian Hellmann, Jens Lehmann, S?oren Auer, and Martin Br?ummer. 2013. Integrating nlp using linked data.
In 12th International Semantic Web Conference, 21-25 October 2013, Sydney, Australia.
Nancy Ide and James Pustejovsky. 2010. What Does Interoperability Mean, Anyway? Toward an Operational
Definition of Interoperability. In Proceedings of the Second International Conference on Global Interoperability
for Language Resources. ICGL.
Nancy Ide and Keith Suderman. 2014. The Linguistic Annotation Framework: A Standard for Annotation Inter-
change and Merging. Language Resources and Evaluation.
Nancy Ide, James Pustejovsky, Nicoletta Calzolari, and Claudia Soria. 2009. The SILT and FlaReNet international
collaboration for interoperability. In Proceedings of the Third Linguistic Annotation Workshop, ACL-IJCNLP,
August.
Nancy Ide, James Pustejovsky, Christopher Cieri, Eric Nyberg, Di Wang, Keith Suderman, Marc Verhagen, and
Jonathan Wright. 2014. The language application grid. In Proceedings of the Ninth International Conference
on Language Resources and Evaluation (LREC?14), Reykjavik, Iceland, may. European Language Resources
Association (ELRA).
ISO-24612. 2012. Language Resource Management - Linguistic Annotation Framework. ISO 24612.
Alkesh Patel, Zi Yang, Eric Nyberg, and Teruko Mitamura. 2013. Building an optimal QA system automatically
using configuration space exploration for QA4MRE?13 tasks. In Proceedings of CLEF 2013.
Zi Yang, Elmer Garduno, Yan Fang, Avner Maiberg, Collin McCormack, and Eric Nyberg. 2013. Building optimal
information systems automatically: Configuration space exploration for biomedical information systems. In
Proceedings of the CIKM?13.
43
