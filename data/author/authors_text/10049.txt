Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 321?328
Manchester, August 2008
Improving Statistical Machine Translation using
Lexicalized Rule Selection
Zhongjun He1,2 and Qun Liu1 and Shouxun Lin1
1Key Laboratory of Intelligent Information Processing
Institute of Computing Technology
Chinese Academy of Sciences
Beijing, 100190, China
2Graduate University of Chinese Academy of Sciences
Beijing, 100049, China
{zjhe,liuqun,sxlin}@ict.ac.cn
Abstract
This paper proposes a novel lexicalized ap-
proach for rule selection for syntax-based
statistical machine translation (SMT). We
build maximum entropy (MaxEnt) mod-
els which combine rich context informa-
tion for selecting translation rules dur-
ing decoding. We successfully integrate
the MaxEnt-based rule selection models
into the state-of-the-art syntax-based SMT
model. Experiments show that our lexical-
ized approach for rule selection achieves
statistically significant improvements over
the state-of-the-art SMT system.
1 Introduction
The syntax-based statistical machine translation
(SMT) models (Chiang, 2005; Liu et al, 2006;
Galley et al, 2006; Huang et al, 2006) use rules
with hierarchical structures as translation knowl-
edge, which can capture long-distance reorderings.
Generally, a translation rule consists of a left-hand-
side (LHS) 1and a right-hand-side (RHS). The
LHS and RHS can be words, phrases, or even syn-
tactic trees, depending on SMT models. Transla-
tion rules can be learned automatically from par-
allel corpus. Usually, an LHS may correspond to
multiple RHS?s in multiple rules. Therefore, in sta-
tistical machine translation, the rule selection task
is to select the correct RHS for an LHS during de-
coding.
The conventional approach for rule selection is
to use precomputed translation probabilities which
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
1In this paper, we use LHS and source-side interchange-
ably (so are RHS and target-side).
are estimated from the training corpus, as well as a
n-gram language model which is trained on the tar-
get language. The limitation of this method is that
it ignores context information (especially on the
source-side) during decoding. Take the hierarchi-
cal model (Chiang, 2005) as an example. Consider
the following rules for Chinese-to-English transla-
tion 2:
(1) X ? ?? X
1
? X
2
, X
2
in X
1
?
(2) X ? ?? X
1
? X
2
, at X
1
?s X
2
?
(3) X ? ?? X
1
? X
2
, with X
2
of X
1
?
These rules have the same source-side, and all of
them can pattern-match all the following source
phrases:
(a) ?
in
[??
economic
??]
1
field
?
?s
[??]
2
cooperation
[cooperation]
2
in [the economic field]
1
(b) ?
at
[??]
1
today
?
?s
[??
meeting
?]
2
on
at [today]
1
?s [meeting]
2
(c) ?
with
[??]
1
people
?
?s
[??
support
?]
2
under
with [the support]
2
of [the people]
1
Given a source phrase, how does the decoder
know which rule is suitable? In fact, rule (1) and
rule (2) have different syntactic structures (the left
two trees of Figure 1). Thus rule (1) can be used
for translating noun phrase (a), and rule (2) can be
applied to prepositional phrase (b). The weakness
2In this paper, we use Chinese and English as the source
and target language, respectively.
321
NP
DNP
PP
?
X
1
?
X
2
X
2
of
X
1
PP
LCP
NP
?
X
1
?
X
2
at
X
1
?s
X
2
PP
LCP
NP
?
X
1
?
X
2
with
X
2
of
X
1
Figure 1: Syntactic structures of the same source-side in different rules.
of Chiang?s hierarchical model is that it cannot
distinguish different structures on the source-side.
The linguistically syntax-based models (Liu et al,
2006; Huang et al, 2006) can distinguish syntactic
structures by parsing source sentence. However,
as an LHS tree may correspond to different RHS
strings in different rules (the right two rules of Fig-
ure 1), these models also face the rule selection
problem during decoding.
In this paper, we propose a lexicalized approach
for rule selection for syntax-based statistical ma-
chine translation. We use the maximum entropy
approach to combine various context features, e.g.,
context words of rules, boundary words of phrases,
parts-of-speech (POS) information. Therefore, the
decoder can use rich context information to per-
form context-dependent rule selection. We build
a maximum entropy based rule selection (MaxEnt
RS) model for each ambiguous hierarchical LHS,
the LHS which contains nonterminals and corre-
sponds to multiple RHS?s in multiple rules. We
integrate the MaxEnt RS models into the state-of-
the-art hierarchical SMT system (Chiang, 2005).
Experiments show that the lexicalized rule se-
lection approach improves translation quality of
the state-of-the-art SMT system, and the improve-
ments are statistically significant.
2 Previous Work
2.1 The Selection Problem in SMT
Statistical machine translation systems usually
face the selection problem because of the one-to-
many correspondence between the source and tar-
get language. Recent researches showed that rich
context information can help SMT systems per-
form selection and improves translation quality.
The discriminative phrasal reordering models
(Xiong et al, 2006; Zens and Ney, 2006) pro-
vided a lexicalized method for phrase reordering.
In these models, LHS and RHS can be consid-
ered as phrases and reordering types, respectively.
Therefore the selection task is to select a reorder-
ing type for phrases. They use a MaxEnt model
to combine context features and distinguished two
kinds of reorderings between two adjacent phrases:
monotone or swap. However, our method is more
generic, we perform lexicalized rule selection for
syntax-based SMT models. In these models, the
rules with hierarchical structures can handle re-
orderings of non-adjacent phrases. Furthermore,
the rule selection can be considered as a multi-
class classification task, while the phrase reorder-
ing between two adjacent phrases is a two-class
classification task.
Recently, word sense disambiguation (WSD)
techniques improved the performance of SMT sys-
tems by helping the decoder perform lexical selec-
tion. Carpuat and Wu (2007b) integrated a WSD
system into a phrase-based SMT system, Pharaoh
(Koehn, 2004a). Furthermore, they extendedWSD
to phrase sense disambiguation (PSD) (Carpuat
and Wu, 2007a). Either the WSD or PSD system
combines rich context information to solve the am-
biguity problem for words or phrases. Their exper-
iments showed stable improvements of translation
quality. These are different from our work. On
one hand, they focus on solving the lexical am-
biguity problem, and use a WSD or PSD system
to predict translations for phrases which only con-
sist of words. However, we put emphasis on rule
selection, and predict translations for hierarchical
LHS?s which consist of both words and nontermi-
nals. On the other hand, they incorporated a WSD
or PSD system into a phrase-based SMT system
with a weak distortion model for phrase reorder-
ing. While we incorporate MaxEnt RS models
into the state-of-the-art syntax-based SMT system,
which captures phrase reordering by using a hier-
archical model.
322
Chan et al (2007) incorporated a WSD system
into the hierarchical SMT system, Hiero (Chi-
ang, 2005), and reported statistically significant
improvement. But they only focused on solving
ambiguity for terminals of translation rules, and
limited the length of terminals up to 2. Different
from their work, we consider a translation rule as a
whole, which contains both terminals and nonter-
minals. Moreover, they explored features for the
WSD system only on the source-side. While we
define context features for the MaxEnt RS models
on both the source-side and target-side.
2.2 The Hierarchical Model
The hierarchical model (Chiang, 2005; Chiang,
2007) is built on a weighted synchronous context-
free grammar (SCFG) . A SCFG rule has the fol-
lowing form:
X ? ??, ?,??(4)
where X is a nonterminal, ? is an LHS string con-
sists of terminals and nonterminals, ? is the trans-
lation of ?, ? defines a one-one correspondence
between nonterminals in ? and ?. For example,
(5) X ? ?????, economic development?
(6) X ? ? X
1
? X
2
? the X
2
of X
1
?
Rule (5) contains only terminals, which is simi-
lar to phrase-to-phrase translation in phrase-based
SMT models. Rule (6) contains both terminals
and nonterminals, which causes a reordering of
phrases. The hierarchical model uses the max-
imum likelihood method to estimate translation
probabilities for a phrase pair ??, ??, independent
of any other context information.
To perform translation, Chiang uses a log-linear
model (Och and Ney, 2002) to combine various
features. The weight of a derivation D is computed
by:
w(D) =
?
i
?
i
(D)
?
i(7)
where ?
i
(D) is a feature function and ?
i
is the fea-
ture weight of ?
i
(D). During decoding, the de-
coder searches the best derivation with the lowest
cost by applying SCFG rules. However, the rule
selections are independent of context information,
except the left neighboring n ? 1 target words for
computing n-gram language model.
3 Lexicalized Rule Selection
The rule selection task can be considered as a
multi-class classification task. For a source-side,
each corresponding target-side is a label. The max-
imum entropy approach (Berger et al, 1996) is
known to be well suited to solve the classification
problem. Therefore, we build a maximum entropy
based rule selection (MaxEnt RS) model for each
ambiguous hierarchical LHS. In this section, we
will describe how to build the MaxEnt RS mod-
els and how to integrate them into the hierarchical
SMT model.
3.1 The MaxEnt RS Model
Following (Chiang, 2005), we use ??, ?? to repre-
sent a SCFG rule extracted from the training cor-
pus, where ? and ? are source and target strings,
respectively. The nonterminals in ? and ? are rep-
resented by X
k
, where k is an index indicating
one-one correspondence between nonterminals in
source and target sides. Let us use f(X
k
) to rep-
resent the source text covered by X
k
, and e(X
k
)
to represent the translation of f(X
k
). Let C(?) be
the context information of source text matched by
?, and C(?) be the context information of target
text matched by ?. Under the MaxEnt model, we
have:
P
rs
(?|?, f(X
k
), e(X
k
)) =(8)
exp[
?
i
?
i
h
i
(C(?), C(?), f(X
k
), e(X
k
))]
?
?
?
exp[
?
i
?
i
h
i
(C(?
?
), C(?), f(X
k
), e(X
k
))]
where h
i
is a binary feature function, ?
i
is the fea-
ture weight of h
i
. The MaxEnt RS model com-
bines rich context information of grammar rules,
as well as information of the subphrases which
will be reduced to nonterminal X during decoding.
However, these information is ignored by Chiang?s
hierarchical model.
We design three kinds of features for a rule
??, ??:
? Lexical features, which are the words imme-
diately to the left and right of ?, and boundary
words of subphrase f(X
k
) and e(X
k
);
? Parts-of-speech (POS) features, which are
POS tags of the source words defined in lexi-
cal features.
? Length features, which are the length of sub-
phrases f(X
k
) and e(X
k
).
323
Side Type Name Description
W?
?1
The source word immediately to the left of ?
W?
+1
The source word immediately to the right of ?
WL
f(X
k
)
The first word of f(X
k
)
Lexical Features
WR
f(X
k
)
The last word of f(X
k
)
P?
?1
POS of W?
?1
P?
+1
POS of W?
+1
PL
f(X
k
)
POS of WL
f(X
k
)
POS Features
PR
f(X
k
)
POS of WR
f(X
k
)
Source-side
Length Feature LEN
f(X
k
)
Length of source subphrase f(X
k
)
WL
e(X
k
)
The first word of e(X
k
)Lexical Features
WR
e(X
k
)
The last word of e(X
k
)Target-side
Length Feature LEN
e(X
k
)
Length of target subphrase e(X
k
)
Table 1: Feature categories of the MaxEnt RS model.
Type Feature
W?
?1
=?? W?
+1
=b
Lexical Features WL
f(X
1
)
=?? WR
f(X
1
)
=?? WL
f(X
2
)
=?? WR
f(X
1
)
=??
WL
e(X
1
)
=economic WR
e(X
1
)
=field WL
e(X
2
)
=cooperation WR
f(X
1
)
=cooperation
P?
?1
=v W?
+1
=wjPOS Features
PL
f(X
1
)
=n PR
f(X
1
)
=n PL
f(X
2
)
=vn PR
f(X
2
)
=vn
Length Feature LEN
f(X
1
)
=2 LEN
f(X
2
)
=1 LEN
e(X
1
)
=2 LEN
e(X
2
)
=1
Table 2: Features of rule X ? ?? X
1
? X
2
, X
2
in the X
1
?.
??/v ?/p ??/n ??/n ?/ude ??/vn b/wj
strengthen
the
cooperation
in
the
economic
field
.
Figure 2: An training example for rule extraction.
Table 1 shows these features in detail.
These features can be easily gathered accord-
ing to Chinag?s rule extraction method (Chiang,
2005). We use an example for illustration. Fig-
ure 2 is a word-aligned training example with POS
tags on the source side. We can obtain a SCFG
rule:
(9) X ? ?? X
1
? X
2
, X
2
in the X
1
?
Where the source phrases covered by X
1
and X
2
are ??? ??? and ????, respectively. Table
2 shows features of this rule. Note that following
(Chiang, 2005), we limit the number of nontermi-
nals of a rule up to 2. Thus a rule may have 20
features at most.
After extracting features from the training cor-
pus, we use the toolkit implemented by Zhang
(2004) to train a MaxEnt RS model for each am-
biguous hierarchical LHS. We set iteration number
to 100 and Gaussian prior to 1.
3.2 Integrating the MaxEnt RS Models into
the SMT Model
We integrate the MaxEnt RS models into the SMT
model during the translation of each source sen-
tence. Thus the MaxEnt RS models can help the
decoder perform context-dependent rule selection
during decoding.
In (Chiang, 2005), the log-linear model com-
bines 8 features: the translation probabilities
P (?|?) and P (?|?), the lexical weights P
w
(?|?)
and P
w
(?|?), the language model, the word
penalty, the phrase penalty, and the glue rule
penalty. For integration, we add two new features:
? P
rs
(?|?, f(X
k
), e(X
k
)). This feature is
computed by the MaxEnt RS model, which
gives a probability that the model selecting a
target-side ? given an ambiguous source-side
?, considering context information.
? P
rsn
= exp(1). This feature is similar to
phrase penalty feature. In our experiments,
324
we find that some source-sides are not am-
biguous, and correspond to only one target-
side. However, if a source-side ?? is not am-
biguous, the first feature P
rs
will be set to 1.0.
In fact, these rules are not reliable since they
usually occur only once in the training corpus.
Therefore, we use this feature to reward the
ambiguous source-side. During decoding, if
an LHS has multiple translations, this feature
is set to exp(1), otherwise it is set to exp(0).
The advantage of our integration is that we need
not change the main decoding algorithm of a SMT
system. Furthermore, the weights of the new fea-
tures can be trained together with other features of
the translation model.
Chiang (2007) uses the CKY algorithm with a
cube pruning method for decoding. This method
can significantly reduce the search space by effi-
ciently computing the top-n items rather than all
possible items at a node, using the k-best Algo-
rithms of Huang and Chiang (2005) to speed up
the computation. In cube pruning, the translation
model is treated as the monotonic backbone of
the search space, while the language model score
is a non-monotonic cost that distorts the search
space (see (Huang and Chiang, 2005) for defini-
tion of monotonicity). Similarly, in the MaxEnt
RS model, source-side features form a monotonic
score while target-side features constitute a non-
monotonic cost that can be seen as part of the lan-
guage model.
For translating a source sentence F J
I
, the de-
coder adopts a bottom-up strategy. All derivations
are stored in a chart structure. Each cell c[i, j] of
the chart contains all partial derivations which cor-
respond to the source phrase f j
i
. For translating
a source-side span [i, j], we first select all possi-
ble rules from the rule table. Meanwhile, we can
obtain features of the MaxEnt RS models which
are defined on the source-side since they are fixed
before decoding. During decoding, for a source
phrase f j
i
, suppose the rule
X ? ?fk
i
X
1
f
j
t
, e
k
?
i
?
X
1
e
j
?
t
?
?(10)
is selected by the decoder, where i ? k < t ? j
and k + 1 < t, then we can gather features which
are defined on the target-side of the subphrase X
1
from the ancestor chart cell c[k + 1, t ? 1] since
the span [k + 1, t ? 1] has already been covered.
Then the new feature scores P
rs
and P
rsn
can be
computed. Therefore, the cost of the derivation can
be obtained. Finally, the decoding is completed
when the whole sentence is covered, and the best
derivation of the source sentence F J
I
is the item
with the lowest cost in cell c[I, J ].
4 Experiments
4.1 Corpus
We carry out experiments on two translation tasks
with different sizes and domains of the training
corpus.
? IWSLT-05: We use about 40,000 sentence
pairs from the BTEC corpus with 354k Chi-
nese words and 378k English words as our
training data. The English part is used to train
a trigram language model. We use IWSLT-04
test set as the development set and IWSLT-05
test set as the test set.
? NIST-03: We use the FBIS corpus as the
training corpus, which contains 239k sen-
tence pairs with 6.9M Chinese words and
8.9M English words. For this task, we train
two trigram language models on the English
part of the training corpus and the Xinhua
portion of the Gigaword corpus, respectively.
NIST-02 test set is used as the development
set and NIST-03 test set is used as the test set.
4.2 Training
To train the translation model, we first run
GIZA++ (Och and Ney, 2000) to obtain word
alignment in both translation directions. Then the
word alignment is refined by performing ?grow-
diag-final? method (Koehn et al, 2003). We use
the same method suggested in (Chiang, 2005) to
extract SCFG grammar rules. Meanwhile, we
gather context features for training the MaxEnt RS
models. The maximum initial phrase length is set
to 10 and the maximum rule length of the source-
side is set to 5.
We use SRI Language Modeling Toolkit (Stol-
cke, 2002) to train language models for both tasks.
We use minimum error rate training (Och, 2003) to
tune the feature weights for the log-linear model.
The translation quality is evaluated by BLEU
metric (Papineni et al, 2002), as calculated by
mteval-v11b.pl with case-insensitive matching of
n-grams, where n = 4.
4.3 Baseline
We reimplement the decoder of Hiero (Chiang,
2007) in C++, which is the state-of-the-art SMT
325
System IWSLT-05 NIST-03
Baseline 56.20 28.05
+ MaxEnt RS
SLex 56.51 28.26
PF 56.95 28.78
SLex+PF 56.99 28.89
SLex+PF+SLen 57.10 28.96
SLex+PF +SLen+TF 57.20 29.02
Table 3: BLEU-4 scores (case-insensitive) on IWSLT-05 task and NIST MT-03 task. SLex = Source-side
Lexical Features, PF = POS Features, SLen = Source-side Length Feature, TF = Target-side features.
system. During decoding, we set b = 100 to prune
grammar rules, ? = 10, b = 30 to prune X cells,
and ? = 10, b = 15 to prune S cells. For cube
pruning, we set the threshold ? = 1.0. See (Chi-
ang, 2007) for meanings of these pruning parame-
ters.
The baseline system uses precomputed phrase
translation probabilities and two trigram language
models to perform rule selection, independent of
any other context information. The results are
shown in the row Baseline of Table 3. For IWSLT-
05 task, the baseline system achieves a BLEU-4
score of 56.20. For NIST MT-03 task, the BLEU-
4 score is 28.05 .
4.4 Baseline + MaxEnt RS
As described in Section 3.2, we add two new fea-
tures to integrate the MaxEnt RS models into the
hierarchical model. To run the decoder, we share
the same pruning settings with the baseline system.
Table 3 shows the results.
Using all features defined in Section 3.1 to train
the MaxEnt RS models, for IWSLT-05 task, the
BLEU-4 score is 57.20, which achieves an abso-
lute improvement of 1.0 over the baseline. For
NIST-03 task, our system obtains a BLEU-4 score
of 29.02, with an absolute improvement of 0.97
over the baseline. Using Zhang?s significance
tester (Zhang et al, 2004) to perform paired boot-
strap sampling (Koehn, 2004b), both improve-
ments on the two tasks are statistically significant
at p < 0.05.
In order to explore the utility of the context fea-
tures, we train the MaxEnt RS models on different
feature sets. We find that POS features are the most
useful features since they can generalize over all
training examples. Moreover, length feature also
yields improvement. However, these features are
never used in the baseline.
NO. of NO. of NO. of
LHS H-LHS AH-LHS
NIST MT-03 163,097 148,671 95,424
Baseline 12,069 7,164 5,745
+MaxEnt RS
(All features) 12,655 10,306 9,259
Table 4: Number of possible source-sides of SCFG
rules for NIST-03 task and number of source-sides
of the best translation. H-LHS = Hierarchical
LHS, AH-LHS = Ambiguous hierarchical LHS.
5 Analysis
Table 4 shows the number of source-sides of
the SCFG rules for NIST-03 task. After extract-
ing grammar rules from the training corpus, there
are 163,097 source-sides match the test corpus,
91.15% are hierarchical LHS?s (H-LHS, the LHS
which contains nonterminals). For the hierarchi-
cal LHS?s, 64.18% are ambiguous (AH-LHS, the
H-LHS which has multiple translations). This in-
dicates that the decoder will face serious rule se-
lection problem during decoding. We also note the
number of the source-sides of the best translation
for the test corpus. For the baseline system, the
number of H-LHS only account for 59.36% of to-
tal LHS?s. However, by incorporating MaxEnt RS
models, that proportion increases to 81.44%, since
the number of AH-LHS increases. The reason is
that, we use the feature P
rsn
to reward ambiguous
hierarchical LHS?s. This has some advantages. On
one hand, H-LHS can capture phrase reorderings.
On the other hand, AH-LHS is more reliable than
non-ambiguous LHS, since most non-ambiguous
LHS?s occur only once in the training corpus.
In order to know how the MaxEnt RS models
improve the performance of the SMT system, we
326
study the best translation of Baseline and Base-
line+MaxEnt RS. We find that the MaxEnt RS
models improve translation quality in 2 ways.
5.1 Better Phrase reordering
Since the SCFG rules which contain nonterminals
can capture reordering of phrases, better rule se-
lection will produce better phrase reordering. For
example, the source sentence ?... [??????
??]
1
? [???? ???]
2
... ? is translated
as follows:
? Reference: ... the five permanent members of
the UN Security Council ...
? Baseline: ... the [United Nations Security
Council]
1
[five permanent members]
2
...
? +MaxEnt RS: ... [the five permanent
members]
2
of [the UN Security Council]
1
...
The source sentence is translated incorrectly by the
baseline system, which selects the rule
(11) X ? ? X
1
? X
2
, the X
1
X
2
?
and produces a monotone translation. In contrast,
by considering information of the subphrases X
1
and X
2
, the MaxEnt RS model chooses the rule
(12) X ? ? X
1
? X
2
, X
2
of X
1
?
and obtains a correct translation by swapping X
1
and X
2
on the target-side.
5.2 Better Lexical Translation
The MaxEnt RS models can also help the decoder
perform better lexical translation than the baseline.
This is because the SCFG rules contain terminals.
When the decoder selects a rule for a source-side,
it also determines the translations of the source ter-
minals. For example, the translations of the source
sentence ??????????? ?b? are
as follows:
? Reference I?m afraid this flight is full.
? Baseline: I?m afraid already booked for this
flight.
? +MaxEnt RS: I?m afraid this flight is full.
Here, the baseline translates the Chinese phrase
???? into ?booked? by using the rule:
(13) X ? ? X
1
??, X
1
booked?
The meaning is not fully expressed since the Chi-
nese word ??? is not translated. However, the
MaxEnt RS model obtains a correct translation by
using the rule:
(14) X ? ? X
1
??, X
1
full ?
However, we also find that some results pro-
duced by the MaxEnt RS models seem to decrease
the BLEU score. An interesting example is the
translation of the source sentence ??????
???:
? Reference1: What is the name of this street?
? Reference2: What is this street called?
? Baseline: What is the name of this street?
? +MaxEnt RS: What?s this street called?
In fact, both translations are correct. But the trans-
lation of the baseline fully matches Reference1.
Although the translation produced by the MaxEnt
RS model is almost the same as Reference2, as
the BLEU metric is based on n-gram matching,
the translation ?What?s? cannot match ?What is?
in Reference2. Therefore, the MaxEnt RS model
achieves a lower BLEU score.
6 Conclusion
In this paper, we propose a generic lexicalized ap-
proach for rule selection. We build maximum en-
tropy based rule selection models for each ambigu-
ous hierarchical source-side of translation rules.
The MaxEnt RS models combine rich context in-
formation, which can help the decoder perform
context-dependent rule selection during decod-
ing. We integrate the MaxEnt RS models into
the hierarchical SMT model by adding two new
features. Experiments show that the lexicalized
approach for rule selection achieves statistically
significant improvements over the state-of-the-art
syntax-based SMT system.
Furthermore, our approach not only can be used
for the formally syntax-based SMT systems, but
also can be applied to the linguistically syntax-
based SMT systems. For future work, we will ex-
plore more sophisticated features for the MaxEnt
RS models and integrate the models into the lin-
guistically syntax-based SMT systems.
327
Acknowledgements
We would like to show our special thanks to Hwee
Tou Ng, Liang Huang, Yajuan Lv and Yang Liu
for their valuable suggestions. We also appreciate
the anonymous reviewers for their detailed com-
ments and recommendations. This work was sup-
ported by the National Natural Science Foundation
of China (NO. 60573188 and 60736014), and the
High Technology Research and Development Pro-
gram of China (NO. 2006AA010108).
References
Berger, A. L., S. A. Della Pietra, and V. J. Della.
1996. A maximum entropy approach to natural lan-
guage processing. Computational Linguistics, page
22(1):39?72.
Carpuat, Marine and Dekai Wu. 2007a. How phrase
sense disambiguation outperforms word sense dis-
ambiguation for statistical machine translation. In
11th Conference on Theoretical and Methodological
Issues in Machine Translation, pages 43?52.
Carpuat, Marine and Dekai Wu. 2007b. Improving sta-
tistical machine translation using word sense disam-
biguation. In Proceedings of EMNLP-CoNLL 2007,
pages 61?72.
Chan, Yee Seng, Hwee Tou Ng, and David Chiang.
2007. Word sense disambiguation improves sta-
tistical machine translation. In Proceedings of the
45th Annual Meeting of the Association for Compu-
tational Linguistics, pages 33?40.
Chiang, David. 2005. A hierarchical phrase-based
model for statistical machine translation. In Pro-
ceedings of the 43rd Annual Meeting of the Associa-
tion for Computational Linguistics, pages 263?270.
Chiang, David. 2007. Hierarchical phrase-based trans-
lation. Computational Linguistics, pages 33(2):201?
228.
Galley, Michel, Jonathan Graehl, Kevin Knight, Daniel
Marcu, Steve DeNeefe, Wei Wang, and Ignacio
Thayer. 2006. Scalable inference and training of
context-rich syntactic translation models. In Pro-
ceedings of COLING-ACL 2006, pages 961?968.
Huang, Liang and David Chiang. 2005. Better k-
best parsing. In Proceedings of the 9th International
Workshop on Parsing Technologies.
Huang, Liang, Kevin Knight, and Aravind Joshi. 2006.
Statistical syntax-directed translation with extended
domain of locality. In Proceedings of the 7th Bi-
ennial Conference of the Association for Machine
Translation in the Americas.
Koehn, Philipp, Franz J. Och, and Daniel Marcu. 2003.
Statistical phrase-based translation. In Proceedings
of HLT-NAACL 2003, pages 127?133.
Koehn, Philipp. 2004a. Pharaoh: a beam search de-
coder for phrase-based statistical machine translation
models. In Proceedings of the Sixth Conference of
the Association for Machine Translation in the Amer-
icas, pages 115?124.
Koehn, Philipp. 2004b. Statistical significance tests for
machine translation evaluation. In Proceedings of
the 2004 Conference on Empirical Methods in Natu-
ral Language Processing (EMNLP), pages 388?395.
Liu, Yang, Qun Liu, and Shouxun Lin. 2006. Tree-
to-string alignment template for statistical machine
translation. In Proceedings of the 44th Annual Meet-
ing of the Association for Computational Linguistics,
pages 609?616.
Och, Franz Josef and Hermann Ney. 2000. Improved
statistical alignment models. In Proceedings of the
38th Annual Meeting of the Association for Compu-
tational Linguistics, pages 440?447.
Och, Franz Josef and Hermann Ney. 2002. Discrimina-
tive training and maximum entropy models for sta-
tistical machine translation. In Proceedings of the
40th Annual Meeting of the Association for Compu-
tational Linguistics, pages 295?302.
Och, Franz Josef. 2003. Minimum error rate training
in statistical machine translation. In Proceedings of
the 41st Annual Meeting of the Association for Com-
putational Linguistics, pages 160?167.
Papineni, K., S. Roukos, T. Ward, and W.-J. Zhu. 2002.
Bleu: a method for automatic evaluation of machine
translation. In Proceedings of the 40th Annual Meet-
ing of the Association for Computational Linguistics,
pages 311?318.
Stolcke, Andreas. 2002. Srilm ? an extensible lan-
guage modeling toolkit. In Proceedings of the Inter-
national Conference on Spoken language Process-
ing, volume 2, pages 901?904.
Xiong, Deyi, Qun Liu, and Shouxun Lin. 2006. Maxi-
mum entropy based phrase reordering model for sta-
tistical machine translation. In Proceedings of the
44th Annual Meeting of the Association for Compu-
tational Linguistics, pages 521?528.
Zens, Richard and Hermann Ney. 2006. Discrimina-
tive reordering models for statistical machine trans-
lation. In Proceedings of the Workshop on Statistical
Machine Translation, pages 55?63.
Zhang, Ying, Stephan Vogel, and Alex Waibel. 2004.
Interpreting bleu/nist scores: How much improve-
ment do we need to have a better system? In Pro-
ceedings of the Fourth International Conference on
Language Resources and Evaluation, pages 2051?
2054.
Zhang, Le. 2004. Maximum entropy model-
ing toolkit for python and c++. available at
http://homepages.inf.ed.ac.uk/s0450736/maxent too-
lkit.html.
328
Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 89?97,
Honolulu, October 2008. c?2008 Association for Computational Linguistics
Maximum Entropy based Rule Selection Model for
Syntax-based Statistical Machine Translation
Qun Liu1 and Zhongjun He1,2 and Yang Liu1 and Shouxun Lin1
1Key Laboratory of Intelligent Information Processing
Institute of Computing Technology, Chinese Academy of Sciences
Beijing, 100190, China
2Graduate University of Chinese Academy of Sciences
Beijing, 100049, China
{liuqun,zjhe,yliu,sxlin}@ict.ac.cn
Abstract
This paper proposes a novel maximum en-
tropy based rule selection (MERS) model
for syntax-based statistical machine transla-
tion (SMT). The MERS model combines lo-
cal contextual information around rules and
information of sub-trees covered by variables
in rules. Therefore, our model allows the de-
coder to perform context-dependent rule se-
lection during decoding. We incorporate the
MERS model into a state-of-the-art linguis-
tically syntax-based SMT model, the tree-
to-string alignment template model. Experi-
ments show that our approach achieves signif-
icant improvements over the baseline system.
1 Introduction
Syntax-based statistical machine translation (SMT)
models (Liu et al, 2006; Galley et al, 2006; Huang
et al, 2006) capture long distance reorderings by us-
ing rules with structural and linguistical information
as translation knowledge. Typically, a translation
rule consists of a source-side and a target-side. How-
ever, the source-side of a rule usually corresponds
to multiple target-sides in multiple rules. Therefore,
during decoding, the decoder should select a correct
target-side for a source-side. We call this rule selec-
tion.
Rule selection is of great importance to syntax-
based SMT systems. Comparing with word selec-
tion in word-based SMT and phrase selection in
phrase-based SMT, rule selection is more generic
and important. This is because that a rule not only
contains terminals (words or phrases), but also con-
NP
DNP
NP
X 1
DEG
NPB
NN
X 2
NN
NP
DNP
NP
X 1
DEG
NPB
NN
X 2
NN
X 1 X 2 levels X 2 standard of X 1
Figure 1: Example of translation rules
tains nonterminals and structural information. Ter-
minals indicate lexical translations, while nontermi-
nals and structural information can capture short or
long distance reorderings. See rules in Figure 1 for
illustration. These two rules share the same syntactic
tree on the source side. However, on the target side,
either the translations for terminals or the phrase re-
orderings for nonterminals are quite different. Dur-
ing decoding, when a rule is selected and applied to a
source text, both lexical translations (for terminals)
and reorderings (for nonterminals) are determined.
Therefore, rule selection affects both lexical transla-
tion and phrase reordering.
However, most of the current syntax-based sys-
tems ignore contextual information when they se-
lecting rules during decoding, especially the infor-
mation of sub-trees covered by nonterminals. For
example, the information of X 1 and X 2 is not
recorded when the rules in Figure 1 extracted from
the training examples in Figure 2. This makes the
decoder hardly distinguish the two rules. Intuitively,
information of sub-trees covered by nonterminals as
well as contextual information of rules are believed
89
NP
DNP
X 1 :NP DEG
NPB
X 2 :NN NN
NP
DNP
X 1 :NP DEG
NPB
X 2 :NN NN
industrial products manufacturing levels overall standard of the match
Figure 2: Training examples for rules in Figure 1
to be helpful for rule selection.
Recent research showed that contextual infor-
mation can help perform word or phrase selec-
tion. Carpuat and Wu (2007b) and Chan et
al. (2007) showed improvents by integrating word-
sense-disambiguation (WSD) system into a phrase-
based (Koehn, 2004) and a hierarchical phrase-
based (Chiang, 2005) SMT system, respectively.
Similar to WSD, Carpuat and Wu (2007a) used con-
textual information to solve the ambiguity prob-
lem for phrases. They integrated a phrase-sense-
disambiguation (PSD) model into a phrase-based
SMT system and achieved improvements.
In this paper, we propose a novel solution for
rule selection for syntax-based SMT. We use the
maximum entropy approach to combine rich con-
textual information around a rule and the informa-
tion of sub-trees covered by nonterminals in a rule.
For each ambiguous source-side of translation rules,
a maximum entropy based rule selection (MERS)
model is built. Thus the MERS models can help the
decoder to perform a context-dependent rule selec-
tion.
Comparing with WSD (or PSD), there are some
advantages of our approach:
? Our approach resolves ambiguity for rules with
multi-level syntactic structure, while WSD re-
solves ambiguity for strings that have no struc-
tures;
? Our approach can help the decoder perform
both lexical selection and phrase reorderings,
while WSD can help the decoder only perform
lexical selection;
? Our method takes WSD as a special case, since
a rule may only consists of terminals.
In our previous work (He et al, 2008), we re-
ported improvements by integrating a MERS model
into a formally syntax-based SMT model, the hier-
archical phrase-based model (Chiang, 2005). In this
paper, we incorporate the MERS model into a state-
of-the-art linguistically syntax-based SMT model,
the tree-to-string alignment template (TAT) model
(Liu et al, 2006). The basic differences are:
? The MERS model here combines rich informa-
tion of source syntactic tree as features since
the translation model is linguistically syntax-
based. He et al (2008) did not use this in-
formation.
? In this paper, we build MERS models for all
ambiguous source-sides, including lexicalized
(source-side which only contains terminals),
partially lexicalized (source-side which con-
tains both terminals and nonterminals), and un-
lexicalized (source-side which only contains
nonterminals). He et al (2008) only built
MERS models for partially lexicalized source-
sides.
In the TAT model, a TAT can be considered as a
translation rule which describes correspondence be-
tween source syntactic tree and target string. TAT
can capture linguistically motivated reorderings at
short or long distance. Experiments show that by
incorporating MERS model, the baseline system
achieves statistically significant improvement.
This paper is organized as follows: Section 2
reviews the TAT model; Section 3 introduces the
MERS model and describes feature definitions; Sec-
tion 4 demonstrates a method to incorporate the
MERS model into the translation model; Section 5
reports and analyzes experimental results; Section 6
gives conclusions.
2 Baseline System
Our baseline system is Lynx (Liu et al, 2006),
which is a linguistically syntax-based SMT system.
For translating a source sentence fJ1 = f1...fj ...fJ ,
Lynx firstly employs a parser to produce a source
syntactic tree T (fJ1 ), and then uses the source
syntactic tree as the input to search translations:
90
e?I1 = argmaxe?I1Pr(e
I
1|f
J
1 )(1)
= argmaxe?I1Pr(T (f
J
1 )|f
J
1 )Pr(e
I
1|T (f
J
1 ))
In doing this, Lynx uses tree-to-string alignment
template to build relationship between source syn-
tactic tree and target string. A TAT is actually a
translation rule: the source-side is a parser tree with
leaves consisting of words and nonterminals, the
target-side is a target string consisting of words and
nonterminals.
TAT can be learned from word-aligned, source-
parsed parallel corpus. Figure 4 shows three types
of TATs extracted from the training example in Fig-
ure 3: lexicalized (the left), partially lexicalized
(the middle), unlexicalized (the right). Lexicalized
TAT contains only terminals, which is similar to
phrase-to-phrase translation in phrase-based model
except that it is constrained by a syntactic tree on the
source-side. Partially lexicalized TAT contains both
terminals and non-terminals, which can be used for
both lexical translation and phrase reordering. Un-
lexicalized TAT contains only nonterminals and can
only be used for phrase reordering.
Lynx builds translation model in a log-linear
framework (Och and Ney, 2002):
P (eI1|T (f
J
1 )) =(2)
exp[
?
m ?mhm(e
I
1, T (f
J
1 ))]?
e? exp[
?
m ?mhm(e
I
1, T (f
J
1 ))]
Following features are used:
? Translation probabilities: P (e?|T? ) and P (T? |e?);
? Lexical weights: Pw(e?|T? ) and Pw(T? |e?);
? TAT penalty: exp(1), which is analogous to
phrase penalty in phrase-based model;
? Language model Plm(eI1);
? Word penalty I .
In Lynx, rule selection mainly depends on trans-
lation probabilities and lexical weights. These four
scores describe how well a source tree links to a tar-
get string, which are estimated on the training cor-
pus according to occurrence times of e? and T? . There
IP
NPB
NN NN NN
VP
VV VPB
VV
The incomes of city and village resident continued to grow
Figure 3: Word-aligned, source-parsed training example.
NN NPB
NN
X 1
NN NN
NPB
NN
X 1
NN
X 2
NN
X 3
city and village incomes of X 1 resident X 3 X 1 X 2
Figure 4: TATs learned from the training example in Fig-
ure 3.
are no features in Lynx that can capture contextual
information during decoding, except for the n-gram
language model which considers the left and right
neighboring n-1 target words. But this information
it very limited.
3 The Maximum Entropy based Rule
Selection Model
3.1 The model
In this paper, we focus on using contextual infor-
mation to help the TAT model perform context-
dependent rule selection. We consider the rule se-
lection task as a multi-class classification task: for
a source syntactic tree T? , each corresponding target
string e? is a label. Thus during decoding, when a
TAT ?T? , e??? is selected, T? is classified into label e??,
actually.
A good way to solve the classification problem is
the maximum entropy approach:
Prs(e?|T? , T (Xk)) =(3)
exp[
?
i ?ihi(e?, C(T? ), T (Xk))]
?
e??
exp[
?
i ?ihi(e??, C(T? ), T (Xk))]
91
where T? and e? are the source tree and target string of
a TAT, respectively. hi is a binary feature functions
and ?i is the feature weight of hi. C(T? ) defines local
contextual information of T? . Xk is a nonterminal in
the source tree T? , where k is an index. T (Xk) is the
source sub-tree covered by Xk.
The advantage of the MERS model is that it uses
rich contextual information to compute posterior
probability for e? given T? . However, the transla-
tion probabilities and lexical weights in Lynx ignore
these information.
Note that for each ambiguous source tree, we
build a MERS model. That means, if there are
N source trees extracted from the training corpus
are ambiguous (the source tree which corresponds
to multiple translations), thus for each ambiguous
source tree Ti (i = 1, ..., N ), a MERS model Mi
(i = 1, ..., N ) is built. Since a source tree may cor-
respond to several hundreds of target translations at
most, the feature space of a MERS model is not pro-
hibitively large. Thus the complexity for training a
MERS model is low.
3.2 Feature Definition
Let ?T? , e?? be a translation rule in the TAT model.
We use f(T? ) to represent the source phrase covered
by T? . To build a MERS model for the source tree T? ,
we explore various features listed below.
1. Lexical Features (LF)
These features are defined on source words.
Specifically, there are two kinds of lexical fea-
tures: external features f?1 and f+1, which
are the source words immediately to the left
and right of f(T? ), respectively; internal fea-
tures fL(T (Xk)) and fR(T (Xk)), which are
the left most and right most boundary words of
the source phrase covered by T (Xk), respec-
tively.
See Figure 5 (a) for illustration. In
this example, f?1=t??ga?o, f+1=zh?`za`o,
fL(T (X1))=go?ngye`, fR(T (X1))=cha?np??n.
2. Parts-of-speech (POS) Features (POSF)
These features are the POS tags of the source
words defined in the lexical features: P?1,
P+1, PL(T (Xk)), PR(T (Xk)) are the POS
tags of f?1, f+1, fL(T (Xk)), fR(T (Xk)), re-
VP
VV
t??ga?o
DNP
X 1 :NP
NN
go?ngye`
NN
cha?np??n
DEG
de
NPB
NN
zh?`za`o
(a) Lexical Features
VP
VV
t??ga?o
DNP
X 1 :NP
NN
go?ngye`
NN
cha?np??n
DEG
de
NPB
NN
zh?`za`o
(b) POS Features
DNP
X 1 :NP
2 words
DEG
de
NP
DNP
X 1 :NP DEG
de
(c) Span Feature (d) Parent Feature
NP
DNP
X 1 :NP DEG
de
NPB
(e) Sibling Feature
Figure 5: Illustration of features of theMERSmodel. The
source tree of the TAT is ? DNP(NP X 1 ) (DEG de)?.
Gray nodes denote information included in the feature.
92
spectively. POS tags can generalize over all
training examples.
Figure 5 (b) shows POS features. P?1=VV,
P+1=NN, PL(T (X1))=NN, PR(T (X1))=NN.
3. Span Features (SPF)
These features are the length of the source
phrase f(T (Xk)) covered by T (Xk). In Liu?s
TATmodel, the knowledge learned from a short
span can be used for a larger span. This is not
reliable. Thus we use span features to allow the
MERS model to learn a preference for short or
large span.
In Figure 5 (c), the span of X 1 is 2.
4. Parent Feature (PF)
The parent node of T? in the parser tree of the
source sentence. The same source sub-tree may
have different parent nodes in different training
examples. Therefore, this feature may provide
information for distinguishing source sub-trees.
Figure 5 (d) shows that the parent is a NP node.
5. Sibling Features (SBF)
The siblings of the root of T? . This feature con-
siders neighboring nodes which share the same
parent node.
In Figure 5 (e), the source tree has one sibling
node NPB.
Those features make use of rich information
around a rule, including the contextual information
of a rule and the information of sub-trees covered
by nonterminals. They are never used in Liu?s TAT
model.
Figure 5 shows features for a partially lexicalized
source tree. Furthermore, we also build MERS mod-
els for lexicalized and unlexicalized source trees.
Note that for lexicalized tree, features do not include
the information of sub-trees since there is no nonter-
minals.
The features can be easily obtained by modify-
ing the TAT extraction algorithm described in (Liu
et al, 2006). When a TAT is extracted from a
word-aligned, source-parsed parallel sentence, we
just record the contextual features and the features of
the sub-trees. Then we use the toolkit implemented
by Zhang (2004) to train MERS models for the am-
biguous source syntactic trees separately. We set the
iteration number to 100 and Gaussian prior to 1.
4 Integrating the MERS Models into the
Translation Model
We integrate the MERS models into the TAT model
during the translation of each source sentence. Thus
the MERS models can help the decoder perform
context-dependent rule selection during decoding.
For integration, we add two new features into the
log-linear translation model:
? Prs(e?|T? , T (Xk)). This feature is computed by
the MERS model according to equation (3),
which gives a probability that the model select-
ing a target-side e? given an ambiguous source-
side T? , considering rich contextual informa-
tion.
? Pap = exp(1). During decoding, if a source
tree has multiple translations, this feature is set
to exp(1), otherwise it is set to exp(0). Since
the MERS models are only built for ambiguous
source trees, the first feature Prs(e?|T? , T (Xk))
for non-ambiguous source tree will be set to
1.0. Therefore, the decoder will prefer to
use non-ambiguous TATs. However, non-
ambiguous TATs usually occur only once in the
training corpus, which are not reliable. Thus
we use this feature to reward ambiguous TATs.
The advantage of our integration is that we need
not change the main decoding algorithm of Lynx.
Furthermore, the weights of the new features can be
trained together with other features of the translation
model.
5 Experiments
5.1 Corpus
We carry out experiments on Chinese-to-English
translation. The training corpus is the FBIS cor-
pus, which contains 239k sentence pairs with 6.9M
Chinese words and 8.9M English words. For the
language model, we use SRI Language Modeling
Toolkit (Stolcke, 2002) with modified Kneser-Ney
smoothing (Chen and Goodman, 1998) to train two
tri-gram language models on the English portion of
93
No. of No. of No. of ambiguous
Type
TATs source trees source trees
% ambiguous
Lexicalized 333,077 16,367 14,380 87.86
Partially Lexicalized 342,767 38,497 28,397 73.76
Unlexicalized 83,024 7,384 5,991 81.13
Total 758,868 62,248 48,768 78.34
Table 1: Statistical information of TATs filtered by test sets of NIST MT 2003 and 2005.
System
Features
P (e?|T? ) P (T? |e?) Pw(e?|T? ) Pw(T? |e?) lm1 lm2 TP WP Prs AP
Lynx 0.210 0.016 0.081 0.051 0.171 0.013 -0.055 0.403 - -
+MERS 0.031 0.008 0.020 0.080 0.152 0.014 0.027 0.270 0.194 0.207
Table 2: Feature weights obtained by minimum error rate training on the development set. The first 8 features are used
by Lynx. TP=TAT penalty, WP=word penalty, AP=ambiguous TAT penalty. Note that in fact, the positive weight for
WP and AP indicate a reward.
the training corpus and the Xinhua portion of the Gi-
gaword corpus, respectively. NIST MT 2002 test set
is used as the development set. NIST MT 2003 and
NIST MT 2005 test sets are used as the test sets.
The translation quality is evaluated by BLEU met-
ric (Papineni et al, 2002), as calculated by mteval-
v11b.pl with case-insensitive matching of n-grams,
where n = 4.
5.2 Training
To train the translation model, we first run GIZA++
(Och and Ney, 2000) to obtain word alignment in
both translation directions. Then the word alignment
is refined by performing ?grow-diag-final? method
(Koehn et al, 2003). We use a Chinese parser de-
veloped by Deyi Xiong (Xiong et al, 2005) to parse
the Chinese sentences of the training corpus.
Our TAT extraction algorithm is similar to Liu et
al. (2006), except that we make some tiny modifica-
tions to extract contextual features for MERS mod-
els. To extract TAT, we set the maximum height of
the source sub-tree to h = 3, the maximum number
of direct descendants of a node of sub-tree to c = 5.
See (Liu et al, 2006) for specific definitions of these
parameters.
Table 1 shows statistical information of TATs
which are filtered by the two test sets. For each type
(lexicalized, partially lexicalized, unlexicalized) of
TATs, a great portion of the source trees are am-
biguous. The number of ambiguous source trees ac-
counts for 78.34% of the total source trees. This in-
dicates that the TAT model faces serious rule selec-
tion problem during decoding.
5.3 Results
We use Lynx as the baseline system. Then the
MERS models are incorporated into Lynx, and
the system is called Lynx+MERS. To run the
decoder, Lynx and Lynx+MERS share the same
settings: tatTable-limit=30, tatTable-threshold=0,
stack-limit=100, stack-threshold=0.00001. The
meanings of the pruning parameters are the same to
Liu et al (2006).
We perform minimum error rate training (Och,
2003) to tune the feature weights for the log-linear
model to maximize the systems?s BLEU score on the
development set. The weights are shown in Table 2.
These weights are then used to run Lynx and
Lynx+MERS on the test sets. Table 3 shows the
results. Lynx obtains BLEU scores of 26.15 on
NIST03 and 26.09 on NIST05. Using all features
described in Section 3.2, Lynx+MERS finally ob-
tains BLEU scores of 27.05 on NIST03 and 27.28
on NIST05. The absolute improvements is 0.90
and 1.19, respectively. Using the sign-test described
by Collins et al (2005), both improvements are
statistically significant at p < 0.01. Moreover,
Lynx+MERS also achieves higher n-gram preci-
sions than Lynx.
94
Test Set System BLEU-4
Individual n-gram precisions
1 2 3 4
NIST03
Lynx 26.15 71.62 35.64 18.64 9.82
+MERS 27.05 72.00 36.72 19.51 10.37
NIST05
Lynx 26.09 70.39 35.12 18.53 10.11
+MERS 27.28 71.16 36.19 19.62 10.95
Table 3: BLEU-4 scores (case-insensitive) on the test sets.
5.4 Analysis
The baseline system only uses four features for
rule selection: the translation probabilities P (e?|T? )
and P (T? |e?); and the lexical weights Pw(e?|T? ) and
Pw(T? |e?). These features are estimated on the train-
ing corpus by the maximum likelihood approach,
which does not allow the decoder to perform a con-
text dependent rule selection. Although Lynx uses
language model as feature, the n-gram language
model only considers the left and right n-1 neigh-
boring target words.
The MERS models combines rich contextual in-
formation as features to help the decoder perform
rule selection. Table 4 shows the effect of different
feature sets. We test two classes of feature sets: the
single feature (the top four rows of Table 4) and the
combination of features (the bottom five rows of Ta-
ble 4). For the single feature set, the POS tags are
the most useful and stable features. Using this fea-
ture, Lynx+MERS achieves improvements on both
the test sets. The reason is that POS tags can be gen-
eralized over all training examples, which can alle-
viate the data sparseness problem.
Although we find that some single features may
hurt the BLEU score, they are useful in combina-
tion of features. This is because one of the strengths
of the maximum entropy model is that it can in-
corporate various features to perform classification.
Therefore, using all features defined in Section 3.2,
we obtain statistically significant improvements (the
last row of Table 4). In order to know how the
MERS models improve translation quality, we in-
spect the 1-best outputs of Lynx and Lynx+MERS.
We find that the first way that theMERSmodels help
the decoder is that they can perform better selection
for words or phrases, similar to the effect of WSD
or PSD. This is because that lexicalized and partially
lexicalized TAT contains terminals. Considering the
Feature Sets NIST03 NIST05
LF 26.12 26.32
POSF 26.36 26.21
PF 26.17 25.90
SBF 26.47 26.08
LF+POSF 26.61 26.59
LF+POSF+SPF 26.70 26.44
LF+POSF+PF 26.81 26.56
LF+POSF+SBF 26.68 26.89
LF+POSF+SPF+PF+SBF 27.05 27.28
Table 4: BLEU-4 scores on different feature sets.
following examples:
? Source:
? Reference: Malta is located in southern Eu-
rope
? Lynx: Malta in southern Europe
? Lynx+MERS: Malta is located in southern Eu-
rope
Here the Chinese word ? ? is incor-
rectly translated into ?in? by the baseline system.
Lynx+MERS produces the correct translation ?is lo-
cated in?. That is because, the MERS model consid-
ers more contextual information for rule selection.
In the MERS model, Prs(in| ) = 0.09, which is
smaller than Prs(is located in| ) = 0.14. There-
fore, the MERS model prefers the translation ?is lo-
cated in?. Note that here the source tree (VV )
is lexicalized, and the role of the MERS model is
actually the same as WSD.
The second way that the MERS models help the
decoder is that they can perform better phrase re-
orderings. Considering the following examples:
95
? Source: [ ]1 [ ]2
...
? Reference: According to its [development
strategy]2 [in the Chinese market]1 ...
? Lynx: Accordance with [the Chinese market]1
[development strategy]2 ...
? Lynx+MERS: According to the [development
strategy]2 [in the Chinese market]1
The syntactic tree of the Chinese phrase ?
? is shown in Figure 6. How-
ever, there are two TATs which can be applied to the
source tree, as shown in Figure 7. The baseline sys-
tem selects the left TAT and produces a monotone
translation of the subtrees ?X 1 :PP? and ?X 2 :NPB?.
However, Lynx+MERS uses the right TAT and per-
forms correct phrase reordering by swapping the two
source phrases. Here the source tree is partially lex-
icalized, and both the contextual information and
the information of sub-trees covered by nontermi-
nals are considered by the MERS model.
6 Conclusion
In this paper, we propose a maximum entropy based
rule selection model for syntax-based SMT. We
use two kinds information as features: the local-
contextual information of a rule, the information of
sub-trees matched by nonterminals in a rule. During
decoding, these features allow the decoder to per-
form a context-dependent rule selection. However,
this information is never used in most of the current
syntax-based SMT models.
The advantage of the MERS model is that it can
help the decoder not only perform lexical selection,
but also phrase reorderings. We demonstrate one
way to incorporate the MERS models into a state-
of-the-art linguistically syntax-based SMT model,
the tree-to-string alignment model. Experiments
show that by incorporating the MERS models, the
baseline system achieves statistically significant im-
provements.
We find that rich contextual information can im-
prove translation quality for a syntax-based SMT
system. In future, we will explore more sophisti-
cated features for the MERS model. Moreover, we
will test the performance of the MERS model on
large scale corpus.
NP
DNP
PP DEG
NPB
in Chinese market of
development strategy
Figure 6: Syntactic tree of the source phrase ?
?.
NP
DNP
PP
X 1
DEG
NPB
X 2
NP
DNP
PP
X 1
DEG
NPB
X 2
X 1 X 2 X 2 X 1
Figure 7: TATs which can be used for the source phrase
? ?.
Acknowledgements
We would like to thank Yajuan Lv for her valuable
suggestions. This work was supported by the Na-
tional Natural Science Foundation of China (NO.
60573188 and 60736014), and the High Technology
Research and Development Program of China (NO.
2006AA010108).
References
Marine Carpuat and Dekai Wu. 2007a. How phrase
sense disambiguation outperforms word sense disam-
biguation for statistical machine translation. In 11th
Conference on Theoretical and Methodological Issues
in Machine Translation, pages 43?52.
Marine Carpuat and Dekai Wu. 2007b. Improving sta-
tistical machine translation using word sense disam-
biguation. In Proceedings of EMNLP-CoNLL 2007,
pages 61?72.
Yee Seng Chan, Hwee Tou Ng, and David Chiang. 2007.
Word sense disambiguation improves statistical ma-
chine translation. In Proceedings of the 45th Annual
96
Meeting of the Association for Computational Linguis-
tics, pages 33?40.
Stanley F. Chen and Joshua Goodman. 1998. An empir-
ical study of smoothing techniques for language mod-
eling. Technical Report TR-10-98, Harvard University
Center for Research in Computing Technology.
David Chiang. 2005. A hierarchical phrase-based model
for statistical machine translation. In Proceedings of
the 43rd Annual Meeting of the Association for Com-
putational Linguistics, pages 263?270.
M. Collins, P. Koehn, and I. Kucerova. 2005. Clause re-
structuring for statistical machine translation. In Proc.
of ACL05, pages 531?540.
Michel Galley, Jonathan Graehl, Kevin Knight, Daniel
Marcu, Steve DeNeefe, Wei Wang, and Ignacio
Thayer. 2006. Scalable inference and training of
context-rich syntactic translation models. In Proceed-
ings of COLING-ACL 2006, pages 961?968.
Zhongjun He, Qun Liu, and Shouxun Lin. 2008. Im-
proving statistical machine translation using lexical-
ized rule selection. In Proceedings of the 22nd In-
ternational Conference on Computational Linguistics
(Coling 2008), pages 321?328.
Liang Huang, Kevin Knight, and Aravind Joshi. 2006.
Statistical syntax-directed translation with extended
domain of locality. In Proceedings of the 7th Biennial
Conference of the Association for Machine Translation
in the Americas.
Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003.
Statistical phrase-based translation. In Proceedings of
HLT-NAACL 2003, pages 127?133.
Philipp Koehn. 2004. Pharaoh: a beam search decoder
for phrase-based statistical machine translation mod-
els. In Proceedings of the Sixth Conference of the
Association for Machine Translation in the Americas,
pages 115?124.
Yang Liu, Qun Liu, and Shouxun Lin. 2006. Tree-to-
string alignment template for statistical machine trans-
lation. In Proceedings of the 44th Annual Meeting of
the Association for Computational Linguistics, pages
609?616.
Franz Josef Och and Hermann Ney. 2000. Improved sta-
tistical alignment models. In Proceedings of the 38th
Annual Meeting of the Association for Computational
Linguistics, pages 440?447.
Franz Josef Och and Hermann Ney. 2002. Discrimina-
tive training and maximum entropy models for statis-
tical machine translation. In Proceedings of the 40th
Annual Meeting of the Association for Computational
Linguistics, pages 295?302.
Franz Josef Och. 2003. Minimum error rate training in
statistical machine translation. In Proceedings of the
41st Annual Meeting of the Association for Computa-
tional Linguistics, pages 160?167.
K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu. 2002.
Bleu: a method for automatic evaluation of machine
translation. In Proceedings of the 40th Annual Meet-
ing of the Association for Computational Linguistics,
pages 311?318.
Andreas Stolcke. 2002. Srilm ? an extensible lan-
guage modeling toolkit. In Proceedings of the Inter-
national Conference on Spoken language Processing,
volume 2, pages 901?904.
Deyi Xiong, Shuanglong Li, Qun Liu, Shouxun Lin, and
Yueliang Qian. 2005. Parsing the penn chinese tree-
bank with semantic knowledge. In Proceedings of
IJCNLP 2005, pages 70?81.
Le Zhang. 2004. Maximum entropy model-
ing toolkit for python and c++. available at
http://homepages.inf.ed.ac.uk/s0450736/maxent too-
lkit.html.
97
Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 161?164,
Columbus, Ohio, USA, June 2008. c?2008 Association for Computational Linguistics
Partial Matching Strategy for Phrase-based Statistical Machine Translation
Zhongjun He1,2 and Qun Liu1 and Shouxun Lin1
1Key Laboratory of Intelligent Information Processing
Institute of Computing Technology
Chinese Academy of Sciences
Beijing, 100190, China
2Graduate University of Chinese Academy of Sciences
Beijing, 100049, China
{zjhe,liuqun,sxlin}@ict.ac.cn
Abstract
This paper presents a partial matching strat-
egy for phrase-based statistical machine trans-
lation (PBSMT). Source phrases which do not
appear in the training corpus can be trans-
lated by word substitution according to par-
tially matched phrases. The advantage of this
method is that it can alleviate the data sparse-
ness problem if the amount of bilingual corpus
is limited. We incorporate our approach into
the state-of-the-art PBSMT system Moses and
achieve statistically significant improvements
on both small and large corpora.
1 Introduction
Currently, most of the phrase-based statistical ma-
chine translation (PBSMT) models (Marcu and
Wong, 2002; Koehn et al, 2003) adopt full matching
strategy for phrase translation, which means that a
phrase pair (f? , e?) can be used for translating a source
phrase f? , only if f? = f? . Due to lack of generaliza-
tion ability, the full matching strategy has some lim-
itations. On one hand, the data sparseness problem
is serious, especially when the amount of the bilin-
gual data is limited. On the other hand, for a certain
source text, the phrase table is redundant since most
of the bilingual phrases cannot be fully matched.
In this paper, we address the problem of trans-
lation of unseen phrases, the source phrases that
are not observed in the training corpus. The
alignment template model (Och and Ney, 2004)
enhanced phrasal generalizations by using words
classes rather than the words themselves. But the
phrases are overly generalized. The hierarchical
phrase-based model (Chiang, 2005) used hierar-
chical phrase pairs to strengthen the generalization
ability of phrases and allow long distance reorder-
ings. However, the huge grammar table greatly in-
creases computational complexity. Callison-Burch
et al (2006) used paraphrases of the trainig corpus
for translating unseen phrases. But they only found
and used the semantically similar phrases. Another
method is to use multi-parallel corpora (Cohn and
Lapata, 2007; Utiyama and Isahara, 2007) to im-
prove phrase coverage and translation quality.
This paper presents a partial matching strategy for
translating unseen phrases. When encountering un-
seen phrases in a source sentence, we search par-
tially matched phrase pairs from the phrase table.
Then we keep the translations of the matched part
and translate the unmatched part by word substitu-
tion. The advantage of our approach is that we alle-
viate the data sparseness problem without increasing
the amount of bilingual corpus. Moreover, the par-
tially matched phrases are not necessarily synony-
mous. We incorporate the partial matching method
into the state-of-the-art PBSMT system, Moses. Ex-
periments show that, our approach achieves statis-
tically significant improvements not only on small
corpus, but also on large corpus.
2 Partial Matching for PBSMT
2.1 Partial Matching
We use matching similarity to measure how well the
source phrases match each other. Given two source
phrases f?J1 and f? ?
J
1 , the matching similarity is com-
puted as:
161
?/P {I/N <?/N u?/V ??/N
issued warning to the American people
?/P /N <?/N ?5/V ?/N
bring advantage to the Taiwan people
Figure 1: An example of partially matched phrases with
the same POS sequence and word alignment.
SIM(f?J1 , f? ?
J
1 ) =
?J
j=1 ?(fj , f ?j)
J (1)
where,
?(f, f ?) =
{
1 if f = f ?
0 otherwise (2)
Therefore, partial matching takes full matching
(SIM(f? , f?) = 1.0) as a special case. Note that in
order to improve search efficiency, we only consider
the partially matched phrases with the same length.
In our experiments, we use a matching threshold
? to tune the precision of partial matching. Low
threshold indicates high coverage of unseen phrases,
but will suffer from much noise. In order to alleviate
this problem, we search partially matched phrases
under the constraint that they must have the same
parts-of-speech (POS) sequence. See Figure 1 for
illustration. Although the matching similarity of the
two phrases is only 0.2, as they have the same POS
sequence, the word alignments are the same. There-
fore, the lower source phrase can be translated ac-
cording to the upper phrase pair with correct word
reordering. Furthermore, this constraint can sharply
decrease the computational complexity since there
is no need to search the whole phrase table.
2.2 Translating Unseen Phrases
We translate an unseen phrase fJ1 according to the
partially matched phrase pair (f ?J1 , e?I1, a?) as follows:
1. Compare each word between fJ1 and f ?J1 to get
the position set of the different words: P =
{j|fj 6= f ?j , j = 1, 2, . . . , J};
2. Remove f ?j from f ?J1 and e?aj from e?I1, where
j ? P ;
3. Find the translation e for fj(j ? P ) from the
phrase table and put it into the position aj in
e?I1 according to the word alignment a?.
u
?U
-?
I
u
?
-?
?.?
arrived in Prague last evening
u
-?
arrived in
arrived in Thailand yesterday
Figure 2: An example of phrase translation.
Figure 2 shows an example. In fact, we create a
translation template dynamically in step 2:
?u X1 -? X2, arrived in X2 X1? (3)
Here, on the source side, each of the non-terminal
X corresponds to a single source word. In addition,
the removed sub-phrase pairs should be consistent
with the word alignment matrix.
Following conventional PBSMT models, we use
4 features to measure phrase translation quality: the
translation weights p(f? |e?) and p(e?|f?), the lexical
weights pw(f? |e?) and pw(e?|f?). The new constructed
phrase pairs keep the translation weights of their
?parent? phrase pair. The lexical weights are com-
puted by word substitution. Suppose S{(f ?, e?)} is
the pair set in (f? ?,e??,a?) which replaced by S{(f, e)}
to create the new phrase pair (f? ,e?,a?), the lexical
weight is computed as:
pw(f? |e?, a?)
=
pw(f? ?|e??, a?) ?
?
(f,e)?S{(f,e)} pw(f |e)?
(f ?,e?)?S{(f ?,e?)} pw(f ?|e?)
(4)
Therefore, the newly constructed phrase pairs can be
used for decoding as they have already existed in the
phrase table.
2.3 Incorporating Partial Matching into the
PBSMT Model
In this paper, we incorporate the partial matching
strategy into the state-of-the-art PBSMT system,
Moses1. Given a source sentence, Moses firstly
uses the full matching strategy to search all possi-
ble translation options from the phrase table, and
then uses a beam-search algorithm for decoding.
1http://www.statmt.org/moses/
162
Therefore, we do incorporation by performing par-
tial matching for phrase translation before decod-
ing. The advantage is that the main search algorithm
need not be changed.
For a source phrase f? , we search partially
matched phrase pair (f? ?, e??, a?) from the phrase table.
If SIM(f? , f? ?)=1.0, which means f? is observed in
the training corpus, thus e?? can be directly stored as a
translation option. However, if ? ? SIM(f? , f? ?) <
1.0, we construct translations for f? according to Sec-
tion 2.2. Then the newly constructed translations are
stored as translation options.
Moses uses translation weights and lexical
weights to measure the quality of a phrase transla-
tion pair. For partial matching, besides these fea-
tures, we add matching similarity SIM(f? , f? ?) as a
new feature. For a source phrase, we select top N
translations for decoding. In Moses, N is set by the
pruning parameter ttable-limit.
3 Experiments
We carry out experiments on Chinese-to-English
translation on two tasks: Small-scale task, the train-
ing corpus consists of 30k sentence pairs (840K +
950K words); Large-scale task, the training cor-
pus consists of 2.54M sentence pairs (68M + 74M
words). The 2002 NIST MT evaluation test data is
used as the development set and the 2005 NIST MT
test data is the test set. The baseline system we used
for comparison is the state-of-the-art PBSMT sys-
tem, Moses.
We use the ICTCLAS toolkit2 to perform Chinese
word segmentation and POS tagging. The training
script of Moses is used to train the bilingual corpus.
We set the maximum length of the source phrase
to 7, and record word alignment information in the
phrase table. For the language model, we use the
SRI Language Modeling Toolkit (Stolcke, 2002) to
train a 4-gram model on the Xinhua portion of the
Gigaword corpus.
To run the decoder, we set ttable-limit=20,
distortion-limit=6, stack=100. The translation qual-
ity is evaluated by BLEU-4 (case-sensitive). We per-
form minimum-error-rate training (Och, 2003) to
tune the feature weights of the translation model to
maximize the BLEU score on development set.
2http://www.nlp.org.cn/project/project.php?proj id=6
? 1.0 0.7 0.5 0.3 0.1
BLEU 24.44 24.43 24.86 25.31 25.13
Table 1: Effect of matching threshold on BLEU score.
3.1 Small-scale Task
Table 1 shows the effect of matching threshold on
translation quality. The baseline uses full matching
(?=1.0) for phrase translation and achieves a BLEU
score of 24.44. With the decrease of the matching
threshold, the BLEU scores increase. when ?=0.3,
the system obtains the highest BLEU score of 25.31,
which achieves an absolute improvement of 0.87
over the baseline. However, if the threshold con-
tinue decreasing, the BLEU score decreases. The
reason is that low threshold increases noise for par-
tial matching.
The effect of matching threshold on the coverage
of n-gram phrases is shown in Figure 3. When us-
ing full matching (?=1.0), long phrases (length?3)
face a serious data sparseness problem. With the de-
crease of the threshold, the coverage increases.
 0
 10
 20
 30
 40
 50
 60
 70
 80
 90
 100
 1  2  3  4  5  6  7
co
ve
ra
ge
 ra
tio
 on
 th
e t
es
t s
et
phrase length
?=1.0
?=0.7
?=0.5
?=0.3
?=0.1
Figure 3: Effect of matching threshold on the coverage of
n-gram phrases.
Table 2 shows the phrase number of 1-best out-
put under ?=1.0 and ?=0.3. When ?=1.0, the long
phrases (length?3) only account for 2.9% of the to-
tal phrases. When ?=0.3, the number increases to
10.7%. Moreover, the total phrase of ?=0.3 is less
than that of ?=1.0, since source text is segmented
into more long phrases under partial matching, and
most of the long phrases are translated from partially
matched phrases (the row 0.3? SIM <1.0).
3.2 Large-scale Task
For this task, the BLEU score of the baseline is
30.45. However, for partial matching method with
163
Phrase Length 1 2 3 4 5 6 7 total
?=1.0 19485 4416 615 87 12 2 1 24618
SIM=1.0 14750 2977 387 48 10 1 0?=0.3 0.3? SIM <1.0 0 1196 1398 306 93 17 12 21195
Table 2: Phrase number of 1-best output. ?=1.0 means full matching. For ?=0.3, SIM=1.0 means full matching,
0.3 ? SIM < 1.0 means partial matching.
?=0.53, the BLEU score is 30.96, achieving an ab-
solute improvement of 0.51. Using Zhang?s signif-
icant tester (Zhang et al, 2004), both the improve-
ments on the two tasks are statistically significant at
p < 0.05.
The improvement on large-scale task is less than
that on small-scale task since larger corpus relieves
data sparseness. However, the partial matching ap-
proach can also improve translation quality by using
long phrases. For example, the segmentation and
translation for the Chinese sentence ???L
?????? are as follows:
Full matching:
? | ?L? |? | |?? |?
long term | economic output | , but | the | trend | will
Partial matching:
? | ?L???? |?
but | the long-term trend of economic output | will
Here the source phrase ??L ?  ? ?
?? cannot be fully matched. Thus the decoder
breaks it into 4 short phrases, but performs an in-
correct reordering. Using partial matching, the long
phrase is translated correctly since it can partially
matched the phrase pair ??Lu7,???
the inevitable trend of economic development?.
3.3 Conclusion
This paper presents a partial matching strategy for
phrase-based statistical machine translation. Phrases
which are not observed in the training corpus can
be translated according to partially matched phrases
by word substitution. Our method can relieve data
sparseness problem without increasing the amount
of the corpus. Experiments show that our approach
achieves statistically significant improvements over
the state-of-the-art PBSMT system Moses.
In future, we will study sophisticated partial
matching methods, since current constraints are ex-
cessively strict. Moreover, we will study the effect
3Due to time limit, we do not tune the threshold for large-
scale task.
of word alignment on partial matching, which may
affect word substitution and reordering.
Acknowledgments
We would like to thank Yajuan Lv and Yang Liu
for their valuable suggestions. This work was sup-
ported by the National Natural Science Foundation
of China (NO. 60573188 and 60736014), and the
High Technology Research and Development Pro-
gram of China (NO. 2006AA010108).
References
C. Callison-Burch, P. Koehn, and M. Osborne. 2006.
Improved statistical machine translation using para-
phrases. In Proc. of NAACL06, pages 17?24.
D. Chiang. 2005. A hierarchical phrase-based model
for statistical machine translation. In Proc. of ACL05,
pages 263?270.
T. Cohn and M. Lapata. 2007. Machine translation by
triangulation: Making effective use of multi-parallel
corpora. In Proc. of ACL07, pages 728?735.
P. Koehn, F. J. Och, and D. Marcu. 2003. Statistical
phrase-based translation. In Proc. of HLT-NAACL03,
pages 127?133.
D. Marcu and W. Wong. 2002. A phrasebased joint
probabilitymodel for statistical machine translation. In
Proc. of EMNLP02, pages 133?139.
F. J. Och and H. Ney. 2004. The alignment template
approach to statistical machine translation. Computa-
tional Linguistics, 30:417?449.
F. J. Och. 2003. Minimum error rate training in statistical
machine translation. In Proc. of ACL03, pages 160?
167.
A. Stolcke. 2002. Srilm ? an extensible language model-
ing toolkit. In Proc. of ICSLP02, pages 901?904.
M. Utiyama and H. Isahara. 2007. A comparison of pivot
methods for phrase-based statistical machine transla-
tion. In Proc. of NAACL-HLT07, pages 484?491.
Y. Zhang, S. Vogel, and A. Waibel. 2004. Interpreting
bleu/nist scores: How much improvement do we need
to have a better system? In Proc. of LREC04, pages
2051?2054.
164
Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 121?124,
Suntec, Singapore, 4 August 2009. c?2009 ACL and AFNLP
Reducing SMT Rule Table with Monolingual Key Phrase
Zhongjun He? Yao Meng? Yajuan Lj ? Hao Yu? Qun Liu?
? Fujitsu R&D Center CO., LTD, Beijing, China
{hezhongjun, mengyao, yu}@cn.fujitsu.com
? Key Laboratory of Intelligent Information Processing
Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China
{lvyajuan, liuqun}@ict.ac.cn
Abstract
This paper presents an effective approach
to discard most entries of the rule table for
statistical machine translation. The rule ta-
ble is filtered by monolingual key phrases,
which are extracted from source text us-
ing a technique based on term extraction.
Experiments show that 78% of the rule ta-
ble is reduced without worsening trans-
lation performance. In most cases, our
approach results in measurable improve-
ments in BLEU score.
1 Introduction
In statistical machine translation (SMT) commu-
nity, the state-of-the-art method is to use rules that
contain hierarchical structures to model transla-
tion, such as the hierarchical phrase-based model
(Chiang, 2005). Rules are more powerful than
conventional phrase pairs because they contain
structural information for capturing long distance
reorderings. However, hierarchical translation
systems often suffer from a large rule table (the
collection of rules), which makes decoding slow
and memory-consuming.
In the training procedure of SMT systems, nu-
merous rules are extracted from the bilingual cor-
pus. During decoding, however, many of them are
rarely used. One of the reasons is that these rules
have low quality. The rule quality are usually eval-
uated by the conditional translation probabilities,
which focus on the correspondence between the
source and target phrases, while ignore the quality
of phrases in a monolingual corpus.
In this paper, we address the problem of reduc-
ing the rule table with the information of mono-
lingual corpus. We use C-value, a measurement
of automatic term recognition, to score source
phrases. A source phrase is regarded as a key
phrase if its score greater than a threshold. Note
that a source phrase is either a flat phrase consists
of words, or a hierarchical phrase consists of both
words and variables. For rule table reduction, the
rule whose source-side is not key phrase is dis-
carded.
Our approach is different from the previous re-
search. Johnson et al (2007) reduced the phrase
table based on the significance testing of phrase
pair co-occurrence in bilingual corpus. The ba-
sic difference is that they used statistical infor-
mation of bilingual corpus while we use that of
monolingual corpus. Shen et al (2008) pro-
posed a string-to-dependency model, which re-
stricted the target-side of a rule by dependency
structures. Their approach greatly reduced the rule
table, however, caused a slight decrease of trans-
lation quality. They obtained improvements by
incorporating an additional dependency language
model. Different from their research, we restrict
rules on the source-side. Furthermore, the system
complexity is not increased because no additional
model is introduced.
The hierarchical phrase-based model (Chiang,
2005) is used to build a translation system. Exper-
iments show that our approach discards 78% of the
rule table without worsening the translation qual-
ity.
2 Monolingual Phrase Scoring
2.1 Frequency
The basic metrics for phrase scoring is the fre-
quency that a phrase appears in a monolingual cor-
pus. The more frequent a source phrase appears in
a corpus, the greater possibility the rule that con-
tains the source phrase may be used.
However, one limitation of this metrics is that if
we filter the rule table by the source phrase with
lower frequency, most long phrase pairs will be
discarded. Because the longer the phrase is, the
less possibility it appears. However, long phrases
121
are very helpful for reducing ambiguity since they
contains more information than short phrases.
Another limitation is that the frequency metrics
focuses on a phrase appearing by itself while ig-
nores it appears as a substring of longer phrases.
It is therefore inadequate for hierarchical phrases.
We use an example for illustration. Considering
the following three rules (the subscripts indicate
word alignments):
R
1
:
Coling 2010: Poster Volume, pages 383?390,
Beijing, August 2010
Learning Phrase Boundaries
for Hierarchical Phrase-based Translation
Zhongjun HE Yao MENG Hao YU
Fujitsu R&D Center CO., LTD.
{hezhongjun, mengyao, yu}@cn.fujitsu.com
Abstract
Hierarchical phrase-based models pro-
vide a powerful mechanism to capture
non-local phrase reorderings for statis-
tical machine translation (SMT). How-
ever, many phrase reorderings are arbi-
trary because the models are weak on de-
termining phrase boundaries for pattern-
matching. This paper presents a novel
approach to learn phrase boundaries di-
rectly from word-aligned corpus without
using any syntactical information. We use
phrase boundaries, which indicate the be-
ginning/ending of phrase reordering, as
soft constraints for decoding. Experi-
mental results and analysis show that the
approach yields significant improvements
over the baseline on large-scale Chinese-
to-English translation.
1 Introduction
The hierarchial phrase-based (HPB) model (Chi-
ang, 2005) outperformed previous phrase-based
models (Koehn et al, 2003; Och and Ney, 2004)
by utilizing hierarchical phrases consisting of both
words and variables. Thus the HPB model has
generalization ability: a translation rule learned
from a phrase pair can be used for other phrase
pairs with the same pattern, e.g. reordering infor-
mation of a short span can be applied for a large
span during decoding. Therefore, the model cap-
tures both short and long distance phrase reorder-
ings.
However, one shortcoming of the HPB model is
that it is difficult to determine phrase boundaries
for pattern-matching. Therefore, during decod-
ing, a rule may be applied for all possible source
phrases with the same pattern. However, incorrect
pattern-matching will cause wrong translation.
Consider the following rule that is used to trans-
late the Chinese sentence in Figure 1 into English:
X ? ?XL de XR, XR in XL? (1)
The rule translates the Chinese word ?de? into
English word ?in?, and swaps the left sub-phrase
covered by XL and the right sub-phrase covered
by XR on the target side. However, XL may
pattern-match 5 spans on the left side of ?de? and
XR may pattern-match 3 spans on the right side.
Therefore, the rule produces 15 different deriva-
tions. However, 14 of them are incorrect.
The correct derivation Sc is shown in Figure 2,
while one of the wrong derivations Si is shown in
Figure 3. We observe that the basic difference be-
tween Sc and Si is the phrase boundary matched
by ?XR?. In Sc, XR matches the span [7, 9] and
moves it as a whole unit. While in Si, XR matches
the span [7, 8] and left the last word [9, 9] be trans-
lated separately. Similarly, other incorrect deriva-
tions are caused by inadequate pattern-matching
of XL and/or XR.
Previous research showed that phrases should
be constrained to some extent for improving trans-
lation quality. Most of the existing approaches uti-
lized syntactic information to constrain phrases to
respect syntactic boundaries. Chiang (2005) in-
troduced a constituent feature to reward phrases
that match a syntactic tree but did not yield signif-
icant improvement. Marton and Resnik (2008) re-
vised this method by distinguishing different con-
stituent syntactic types, and defined features for
each type to count whether a phrase matches or
crosses the syntactic boundary. This led to a sub-
stantial improvements. Gimpel and Smith (2008)
presented rich contextual features on the source
side including constituent syntactical features for
phrase-based translation. Cherry (2008) utilized
a dependency tree as a soft constraint to detect
syntactic cohesion violations for a phrase-based
383
?1
ta
?2
jiang
??3
chengwei
??4
yindu
????5
youshiyilai
?6
de
??7
shouwei
?8
n?
??9
zongtong
She1 will2 become3 the4 first5 female6 president7 in8 India?s9 history10
X[5,5]
X[4,5]
X[3,5]
X[2,5]
X[1,5]
X[7,7]
X[7,8]
X[7,9]
Figure 1: An example of Chinese-English translation. The rule X ? ?XL de XR, XR in XL?
pattern-matches 5 and 3 spans on the left and right of the Chinese word ?de?, respectively.
Sc ? ????? X, She will become X?
? ????? X[4,5]? X[7,9], She will become X[7,9] in X[4,5]?
? ????? ??????? ?? ??????,
She will become the first female president in India?s history?
Figure 2: The correct derivation with adequate pattern-matching of XR.
Si ? ????? X ??, She will become X president?
? ????? X[4,5]? X[7,8]??, She will become X[7,8] in X[4,5] president?
? ????? ??????? ?? ???? ???,
She will become the first female in India?s history president?
Figure 3: A wrong derivation with inadequate pattern-matching of XR.
system. Xiong et al (2009) presented a syntax-
driven bracketing model to predict whether two
phrases are translated together or not, using syn-
tactic features learned from training corpus. Al-
though these approaches differ from each other,
the main basic idea is the utilization of syntactic
information.
In this paper, we present a novel approach to
learn phrase boundaries for hierarchical phrase-
based translation. A phrase boundary indicates the
beginning or ending of a phrase reordering. Moti-
vated by Ng and Low (2004) that built a classifier
to predict word boundaries for word segmenta-
tion, we build a classifier to predict phrase bound-
aries. We classify each source word into one of the
4 boundary tags: ?b? indicates the beginning of a
phrase, ?m? indicates a word appears in the mid-
dle of a phrase, ?e? indicates the end of a phrase,
?s? indicates a single-word phrase.
We use phrase boundaries as soft constraints for
decoding. To do this, we incorporate our classifier
as a feature into the HPB model and propose an
efficient decoding algorithm.
Compared to the previous work, out approach
has the following advantages:
? Our approach maintains the strength of the
phrase-based models since it does not re-
quire any syntactical information. There-
fore, phrases do not need to respect syntactic
boundaries.
? The training instances are directly learned
from a word-aligned bilingual corpus, rather
than from manually annotated corpus.
384
? The decoder outputs phrase segmentation in-
formation as a byproduct, in addition to
translation result.
We evaluate our approach on large-scale
Chinese-to-English translation. Experimental re-
sults and analysis show that using phrase bound-
aries as soft constraints achieves significant im-
provements over the baseline system.
2 Previous Work
2.1 Learning Word Boundaries
In some languages, such as Chinese, words are not
demarcated. Therefore, it is a preliminary task to
determine word boundaries for a sentence, which
is the so-called word segmentation.
Ng and Low (2004) regarded word segmen-
tation as a classification problem. They labelled
each Chinese character with one of 4 possible
boundary tags: ?b?, ?m?, ?e? respectively indi-
cates the begin, the middle and the end of a word,
and ?s? indicates a single-character word. Their
segmenter was built within a maximum entropy
framework and trained on manually segmented
sentences.
Learning phrase boundaries is analogous to
word boundaries. The basic difference is that
the unit for learning word boundaries is charac-
ter while the unit for learning phrase boundaries
is word. In this paper, we adopt the boundary
tags presented by Ng and Low (2004) and build a
classifier to predict phrase boundaries within max-
imum entropy framework. We train it directly on a
word-aligned bilingual corpus, without any man-
ually annotation and syntactical information.
2.2 The Hierarchical Phrase-based Model
We built a hierarchical phrase-based MT system
(Chiang, 2007) based on weighted SCFG. The
translation knowledge is represented by rewriting
rules:
X ? ??, ?,?? (2)
where X is a non-terminal, ? and ? are source and
target strings, respectively. Both of them contain
words and possibly co-indexed non-terminals. ?
describes a one-to-one correspondence between
non-terminals in ? and ?.
Chiang (2007) used the standard log-linear
framework (Och and Ney, 2002) to combine var-
ious features:
Pr(e|f) ?
?
i
?ihi(?, ?) (3)
where hi(?, ?) is a feature function and ?i is
the weight of hi. Analogous to the previous
phrase-based model, Chiang defined the follow-
ing features: translation probabilities p(?|?) and
p(?|?), lexical weights pw(?|?) and pw(?|?),
word penalty, rule penalty, and a target n-gram
language model.
In this paper, we integrate a phrase boundary
classifier as an additional feature into the log-
linear model to provide soft constraint for pattern-
matching during decoding. The feature weights
are optimized by MERT algorithm (Och, 2003).
3 Learning Phrase Boundaries
We build a phrase boundary classifier (PBC)
within a maximum entropy framework. The PBC
predicts a boundary tag for each source word, con-
sidering contextual features:
Ptag(t|fj , F J1 ) =
exp(
?
i ?ihi(t, fj , F J1 ))?
t exp(
?
i ?ihi(t, fj , F J1 )
(4)
where, t ? {b, m, e, s}, fj is the jth word in
source sentence F J1 , hi is a feature function and
?i is the weight of hi.
To build PBC, we first present a method to rec-
ognize phrase boundaries and extract training ex-
amples from word-aligned bilingual corpus, then
we define contextual feature functions.
3.1 Phrase Boundary
During decoding, intuitively, words within a
phrase should be translated or moved together.
Therefore, a phrase boundary should indicate re-
ordering information. We assign one of the
boundary tags (b,m, e, s) to each word in source
sentences. Thus the word with tag b, e or s is a
phrase boundary. One question is that how to as-
sign boundary tag to a word? In this paper, we
recognize the largest source span which has the
monotone translation. Then we assign boundary
385
?? ?? ?
jointly held by
(a)
?? ??
a short visit
(b)
Figure 4: Illustration for monotone span (a) and
PM span (b).
tags to each word in the source span, according to
their position.
To do this, we first introduce some notations.
Given a bilingual sentence (F J1 , EI1) together with
word alignment matrix A, we use L(Aj) and
H(Aj) to represent the lowest and highest tar-
get word position which links to the source word
fj , respectively. Since the word alignment for fj
maybe ?one-to-many?, all the corresponding tar-
get words will appear in the span [L(Aj),H(Aj)].
we define a source span [j1, j2] (1 ? j1 ? j2 ?
J) a monotone span, iff:
1. ?(j, i) ? A, j1 ? j ? j2 ? L(Aj1) ? i ?
H(Aj2)
2. ?k1, k2 ? [j1, j2], k1 ? k2 ? H(Ak1) ?
L(Ak2)
The first condition indicates that
(F j2j1 , E
H(Aj2 )
L(Aj1 )
) is a phrase pair as described
previously in phrase-based SMT models. While
the second condition indicates that the lower
target bound linked to a source word cannot be
lower than any target word position linked to the
previous source word. Therefore, a monotone
span does not contain crossed links or internal
reorderings.
Considering that word alignments could be
very noisy and complex in real-world data, we de-
fine pseudo-monotone (PM) span by loosening the
second condition:
?k1, k2 ? [j1, j2], k1 ? k2 ? L(Ak1) ? L(Ak2)
(5)
This condition allows crossed links to some ex-
tent by loosening the bound of Ak1 from upper
to lower. Figure 4 (a) shows an example of
monotone span, in which the translation is mono-
tone. While Figure 4 (b) is not a monotone span
because there is a cross link between the upper
bound of ???? and the lower bound of ????
on the target side. However, it is a PM span ac-
cording to the definition. Note that in some cases,
a source word may not be contained in any phrase
pair, therefore we consider a single word span as
a PM span, specificly.
An interesting feature of PM span is that if two
PM spans are consecutive on both source side and
their corresponding target side, the two PM spans
can be combined as a larger PM span. Formally,
(F jj1 , E
i
i1)
?
(F j2j+1, Ei2i+1) = (F
j2
j1 , E
i2
i1 ) (6)
where [j1, j] and [j+1, j2] are PM spans, [i1, i]
and [i + 1, i2] are the target spans corresponding
to [j1, j] and [j+1, j2], respectively. For example,
Figure 4 (a) shows a PM phrase pair that consists
of two small PM pairs ???, jointly? and ???
?, held by?.
In this paper, we are interested in phrase re-
ordering boundaries for a source sentence. We de-
fine translation span (TS) the largest possible PM
span. A TS may consist of one or more PM spans.
According to our definition, cross links may ap-
pear within PM spans but do not appear between
PM spans within a TS. Therefore, TS is the largest
possible span that will be translated as a unit and
phrase reorderings may occur between TSs during
decoding.
To obtain phrase boundary examples from
word-aligned bilingual sentences, we first find all
possible TSs and then assign boundary tags to
each word. For a TS [j1, j2] (j1 < j2) that contain
more than two words, we assign ?b? to the first
word fj1 and ?e? to the last word fj2 , and ?m? to
the middle words fj (j1 < j < j2). For a single
word span TS [j, j], we assign ?s? to the word fj .
Figure 5 shows an example of labelling source
words with boundary tags. The source sentence is
segmented into 4 TSs. Using the phrase boundary
information to guide decoding, the decoder will
produce the correct derivation and translation as
shown in Figure 2.
386
??
?
?
?
?
?
?
?
??
?
??
?
?
TAG b m e b e s b m e
She
will
become
the first
female
president
in
India?s
history
Figure 5: Illustration for labelling the source
words with boundary tags. The solid boxes
present word alignments. The bordered boxes are
TSs.
3.2 Feature Definition
The features we used for the PS model are anal-
ogous to (Ng and Low, 2004). For a word W0,
we define the following contextual features with a
window of ?n?:
? The word feature Wn, which denotes the left
(right) n words of the current word W0;
? The part-of-speech (POS) feature Pn, which
denotes the POS tag of the word Wn.
For example, the tag of the word ??? (be-
come)? in Figure 5 is ?e?, indicating that it is
the end of a phrase. If we set the context window
n = 2, the features of the word ??? (become)?
are:
? W?2=? W?1=? W0=? ? W1=? ?
W2=????
? P?2=r P?1=d P0=v P1=ns P2=l
We collect TSs from bilingual sentences to-
gether with the contextual features and used a
MaxEnt toolkit (Zhang, 2004) to train a PBC.
? ? ??
b 0.78 0.10 1.2e-5
m 6.4e-8 0.75 5.4e-5
e 2.1e-8 0.11 0.87
s 0.22 0.04 0.13
Table 1: The TPM for a source sentence. The
highest probability of each word is in bold.
4 Phrase Boundary Constrained
Decoding
Give a source sentence, we can assign boundary
tags to each word by running the PBC. During
decoding, a rule is prohibited to pattern-match
across phrase boundaries. By doing this, the PBC
is integrated as a hard constraint. However, this
method will invalidate a large number of rules and
the decoder suffers from a risk that there are not
enough rules to cover the source sentence.
Alternatively, inspired by previous approaches,
we integrate the phrase boundary classifier as a
soft constraint by incorporating it as a feature into
the HPB model:
hpbc(F J1 ) = log(
J?
j=1
Ptag(t|fj , F J1 )) (7)
To perform translation, for each word fj in
a source sentence F J1 , we first compute all tag
probabilities Ptag(t|fj), where t ? (b,m, e, s),
j ? [1, J ], according to Equation 4. Therefore, we
build a 4? J tag-word probability matrix (TPM).
TPM [i, j] indicates the probability of the word
fj labelled with the tag ti. Table 1 shows the
TPM for a source text ??????.
Then we select rule options from the rule ta-
ble that can be used for translating the source text.
Since each rule option (f? , e?, a) 1 can be regarded
as a bilingual sentence with word alignments, thus
we find all TS in f? and assign an initial tag (IT)
for each source word. This procedure is analogous
to label phrase boundary tags for a word-aligned
bilingual sentence. For example, the following
rules are used for translating the Chinese sentence
in Table 1:
1We keep word alignments of a rule when it is extracted
from bilingual sentence.
387
X ? ??bX?1 , She X1? (8)
X1 ? ??b??e, will become? (9)
Since both the source sides of these two rules
are PM spans according to the word alignments,
the IT sequences for rule (8) and (9) are ?b *?2
and ?b e?, respectively. According to Table 1,
the initial hpbc score for these two rules can be
computed as follows:
h(7)pbc = log(Ptag(b|?)) = log(TPM [1, 1]) (10)
h(8)pbc = log(Ptag(b|?)) + log(Ptag(e|??))
= log(TPM [1, 2]) + log(TPM [3, 3]) (11)
Note that to keep the tag sequence valid, e.g.
?m? follows ?b? rather than ?s?, the ITs maybe
updated during decoding. The tag-updating
should be consistent with the definition of TS as
described in Section 3.1. Specifically, when the
non-terminal symbol X is derived from its cov-
ered span f(X), the boundary tags should be up-
dated.
When a tag of word fj is updated from tk1 to
tk2 , the PBC score should also be updated accord-
ing to TPM:
?PBC = log(TPM [k2, j])? log(TPM [k1, j])
(12)
The following is a derivation of the source sen-
tence in Table 1:
S ? ??bX?1 , She X1?
? ??b?b?m??e, She will become?
When X1 is derived, the tag of its left boundary
word ??? is updated from ?b? to ?m?. The reason
is that after derivation, the combined span forms
a larger PM span and the left boundary of f(X1)
should be updated.
As a result, the hpbc score is recomputed:
hpbc(F 31 ) = h
(7)
pbc + h
(8)
pbc +?PBC (13)
where,
?PBC = log(TPM [2, 2])? log(TPM [1, 2])
(14)
2We use ?*? as a tag of the non-terminal symbol ?X1?
since it has not been derived.
The decoding algorithm is efficient since the
computing of the PBC score is a procedure of
table-lookup.
5 Experiments
5.1 Experimental Setup
Our experiments were on Chinese-to-English
translation. The training corpus (77M+81M) we
used are from LDC 3. The evaluation metric is
BLEU (Papineni et al, 2002), as calculated by
mteval-v11b.pl with case-insensitive matching of
n-grams, where n = 4.
To obtain word alignments, we first ran
GIZA++ (Och and Ney, 2002) in both translation
directions and then refined it by ?grow-diag-final?
method (Koehn et al, 2003).
For the language model, we used the SRI Lan-
guage Modeling Toolkit (Stolcke, 2002) to train
two 4-gram models on xinhua portion of Giga-
Word corpus and the English side of the training
corpus.
The NIST MT03 test set is used to tune the fea-
ture weights of the log-linear model by MERT
(Och, 2003). We tested our system on the NIST
MT06 and MT08 test sets.
5.2 Results
The results are shown in Table 2. We tested vari-
ous settings of the context window. It is observed
that the small values of n (n = 1, 2) drop the
BLEU score, suggesting that perhaps there are not
enough contextual information. With more con-
textual information is used, the BLEU scores are
improved over all test sets. When n = 3, the most
significant improvements are obtained on MT06G
and MT08. The improvements over the baseline
are statistically significant at p < 0.01 by using
the significant test method described in (Koehn,
2004). While for MT06N, the optimized context
window size is n = 4 but the improvement is
not statistically significant. In most cases, with
n larger than 3, we do not obtain further improve-
ments because of the data sparseness for training
3LDC2002E18, LDC2002L27, LDC2002T01,
LDC2003E07, LDC2003E14, LDC2004T07, LDC2005E83,
LDC2005T06, LDC2005T10, LDC2005T34, LDC2006E24,
LDC2006E26, LDC2006E34, LDC2006E86, LDC2006E92,
LDC2006E93, LDC2004T08(HK News, HK Hansards).
388
System MT06G MT06N MT08
baseline 14.66 34.42 26.29
+PBC (n=1) 13.78 33.20 24.58
+PBC (n=2) 14.34 34.21 25.87
+PBC (n=3) 15.19* 34.63 27.25*
+PBC (n=4) 14.76 34.73 26.70
Table 2: Results on the test sets with different con-
text window (n) of the phrase boundary classifier.
The largest BLEU score on each test set is in bold.
MT06G: MT06 GALE set. MT06N: MT06 NIST
set. *: significantly better than the baseline at
p < 0.01.
the classifier.
6 Discussion
The experimental results show that the phrase
boundary constrained method improves the BLEU
score over the baseline system. Furthermore, we
are interested in how the PBC affects the transla-
tion results? We compared the outputs generated
by the baseline and ?+PBC (n = 3)? system and
found some interesting translations. For example,
the translations of a source sentence of NIST08
are as follows 4:
? Src: ?b1 ??m2 ?m3 ??m4 ??e5 ???b6
?m7 ??e8 ??b9??m10??e11
? Ref: US1 Treasury-Secretary2 Arrives-in3
China4 for-a-Visit-with5 Environment6 and7
Exchange-Rate8 as9 Focus10,11
? HPB: US1 Treasury2 in-environmental-
protection6 and7 visit5 China4 is9 key11
to-the-concern-of10 the-exchange-rate8
? +PBC: US1 Treasury2 arrived-in3 China4
for-a-visit5 environmental-protection6 and7
exchange-rate8 is9 concerned-about10 the-
key11
In the example, both ???? and ???? in the
source sentence are the concern of the ?visit?.
Therefore, the source span [6, 8] indicates a co-
hesive phrase, which should be translated as a
4The co-indexes of the words on the source and target
sentence indicate word alignments.
whole unit. However, the baseline translates the
spans [6, 7] and [8, 8] separately. It moves [6, 7]
before ?visit China? and [8, 8] after ?concern?.
This makes an mistake on phrase reordering. We
observe that the ?+PBC? system produces a bet-
ter translation. After incorporating the PBC as
a soft constraint, the system assigns a boundary
tag to each source word and segments the source
sentence into three TSs. According to our defi-
nition, TSs are encouraged as pseudo-monotone
translation unit during decoding. As a result, the
?+PBC? system discourages some arbitrary re-
ordering rules and produces more fluent transla-
tion.
7 Conclusion and Future Work
This paper presented a phrase boundary con-
strained method for hierarchical phrase-based
translation. A phrase boundary indicates begin
or end of a phrase reordering. We built a phrase
boundary classifier within a maximum entropy
framework and learned phrase boundary exam-
ples directly from word-aligned bilingual corpus.
We proposed an efficient decoding method to in-
tegrate the PBC into the decoder as a soft con-
straint. Experiments and analysis show that the
phrase boundary constrained method achieves sig-
nificant improvements over the baseline system.
The most advantage of the PBC is that it han-
dles both syntactic and non-syntactic phrases. In
the future, We would like to try different meth-
ods to determine more informative phrase bound-
aries, e.g. Xiong et al (2010) proposed a method
to learn translation boundaries from a hierarchical
tree that decomposed from word alignments using
a shift-reduce algorithm. In addition, we will try
more features as described in (Chiang et al, 2008;
Chiang et al, 2009), e.g. the length of the phrases
that covered by non-terminals.
References
Cherry, Colin. 2008. Cohesive phrase-based decoding
for statistical machine translation. In Proceedings
of the 46rd Annual Meeting of the Association for
Computational Linguistics: Human Language Tech-
nologies, page 72?80.
Chiang, David, Yuval Marton, and Philip Resnik.
389
2008. Online large-margin training of syntactic and
structural translation features. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing, page 224?233.
Chiang, David, Wei Wang, and Kevin Knight. 2009.
11,001 new features for statistical machine trans-
lation. In Proceedings of Human Language Tech-
nologies: the 2009 Annual Conference of the North
American Chapter of the Association for Computa-
tional Linguistics, page 218?226.
Chiang, David. 2005. A hierarchical phrase-based
model for statistical machine translation. In Pro-
ceedings of the 43rd Annual Meeting of the Associa-
tion for Computational Linguistics, pages 263?270.
Chiang, David. 2007. Hierarchical phrase-based
translation. Computational Linguistics, pages
33(2):201?228.
Gimpel, Kevin and Noah A. Smith. 2008. Rich
source-side context for statistical machine transla-
tion. In In Proceedings of the ACL-2008 Workshop
on Statistical Machine Translation (WMT-2008),
pages 9?17.
Koehn, Philipp, Franz J. Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Pro-
ceedings of HLT-NAACL 2003, pages 127?133.
Koehn, Philipp. 2004. Statistical significance tests for
machine translation evaluation. In Proceedings of
the 2004 Conference on Empirical Methods in Nat-
ural Language Processing (EMNLP), pages 388?
395.
Marton, Yuval and Philip Resnik. 2008. Soft syntac-
tic constraints for hierarchical phrased-based trans-
lation. In Proceedings of the 46rd Annual Meeting
of the Association for Computational Linguistics:
Human Language Technologies, pages 1003?1011.
Ng, Hweetou and Jinkiat Low. 2004. Chinese part-
of-speech tagging: One-at-a-time or all-at-once?
word-based or character-based? In Proceedings of
the 2004 Conference on Empirical Methods in Nat-
ural Language Processing (EMNLP 2004), pages
277?284.
Och, Franz Josef and Hermann Ney. 2002. Dis-
criminative training and maximum entropy models
for statistical machine translation. In Proceedings
of the 40th Annual Meeting of the Association for
Computational Linguistics, pages 295?302.
Och, Franz Josef and Hermann Ney. 2004. The align-
ment template approach to statistical machine trans-
lation. 30:417?449.
Och, Franz Josef. 2003. Minimum error rate training
in statistical machine translation. In Proceedings of
the 41st Annual Meeting of the Association for Com-
putational Linguistics, pages 160?167.
Papineni, K., S. Roukos, T. Ward, and W.-J. Zhu.
2002. Bleu: a method for automatic evaluation of
machine translation. In Proceedings of the 40th An-
nual Meeting of the Association for Computational
Linguistics, pages 311?318.
Stolcke, Andreas. 2002. SRILM ? An extensible lan-
guage modeling toolkit. In Proceedings of the Inter-
national Conference on Spoken language Process-
ing, volume 2, pages 901?904.
Xiong, Deyi, Min Zhang, Aiti Aw, and Haizhou Li.
2009. A syntax-driven bracketing model for phrase-
based translation. In ACL-IJCNLP 2009, page
315?323.
Xiong, Deyi, Min Zhang, and Haizhou Li. 2010.
Learning translation boundaries for phrase-based
decoding. In Human Language Technologies: The
2010 Annual Conference of the North American
Chapter of the ACL, page 136?144.
Zhang, Le. 2004. Maximum entropy model-
ing toolkit for python and c++. available at
http://homepages.inf.ed.ac.uk/s0450736/maxent too-
lkit.html.
390
Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 555?563,
MIT, Massachusetts, USA, 9-11 October 2010. c?2010 Association for Computational Linguistics
Maximum Entropy Based Phrase Reordering
for Hierarchical Phrase-based Translation
Zhongjun He Yao Meng Hao Yu
Fujitsu R&D Center CO., LTD.
15/F, Tower A, Ocean International Center, 56 Dongsihuan Zhong Rd.
Chaoyang District, Beijing, 100025, China
{hezhongjun, mengyao, yu}@cn.fujitsu.com
Abstract
Hierarchical phrase-based (HPB) translation
provides a powerful mechanism to capture
both short and long distance phrase reorder-
ings. However, the phrase reorderings lack of
contextual information in conventional HPB
systems. This paper proposes a context-
dependent phrase reordering approach that
uses the maximum entropy (MaxEnt) model
to help the HPB decoder select appropriate re-
ordering patterns. We classify translation rules
into several reordering patterns, and build a
MaxEnt model for each pattern based on var-
ious contextual features. We integrate the
MaxEnt models into the HPB model. Ex-
perimental results show that our approach
achieves significant improvements over a stan-
dard HPB system on large-scale translation
tasks. On Chinese-to-English translation,
the absolute improvements in BLEU (case-
insensitive) range from 1.2 to 2.1.
1 Introduction
The hierarchical phrase-based (HPB) model (Chi-
ang, 2005; Chiang, 2007) has been widely adopted
in statistical machine translation (SMT). It utilizes
synchronous context free grammar (SCFG) rules
to perform translation. Typically, there are three
types of rules (see Table 1): phrasal rule, a phrase
pair consisting of consecutive words; hierarchical
rule, a hierarchical phrase pair consisting of both
words and variables; and glue rule, which is used to
merge phrases serially. Phrasal rule captures short
distance reorderings within phrases, while hierar-
chical rule captures long distance reorderings be-
Type Constituent ExamplesWord Variable
PR
?
- X ? ???, one of?
HR
? ?
X ? ?X, ofX?
GR -
?
S ? ?SX, SX?
Table 1: A classification of grammar rules for the HPB
model. PR = phrasal rule, HR = hierarchical rule, GR =
glue rule.
tween phrases. Therefore, the HPB model outper-
forms conventional phrase-based models on phrase
reorderings.
However, HPB translation suffers from a limita-
tion, in that the phrase reorderings lack of contex-
tual information, such as the surrounding words of
a phrase and the content of sub-phrases that rep-
resented by variables. Consider the following two
hierarchical rules in translating a Chinese sentence
into English:
X ? ?X1  X2, X1 ?s X2? (1)
X ? ?X1  X2, X2X1? (2)
? ?d  !
with Russia ?s talks
talks with Russia
Both pattern-match the source sentence, but pro-
duce quite different phrase reorderings. The first
rule generates a monotone translation, while the sec-
ond rule swaps the source phrases covered by X1
and X2 on the target side. During decoding, the first
555
rule is more likely to be used, as it occurs more fre-
quently in a training corpus. However, the exam-
ple is not a noun possessive case because the sub-
phrase covered by X1 is not a noun but a preposi-
tional phrase. Thus, without considering informa-
tion of sub-phrases, the decoder may make errors on
phrase reordering.
Contextual information has been widely used to
improve translation performance. It is helpful to re-
duce ambiguity, thus guide the decoder to choose
correct translation for a source text. Several re-
searchers observed that word sense disambiguation
improves translation quality on lexical translation
(Carpuat and Wu, 2007; Chan et al, 2007). These
methods utilized contextual features to determine
the correct meaning of a source word, thus help an
SMT system choose an appropriate target transla-
tion.
Zens and Ney (2006) and Xiong et al (2006)
utilized contextual information to improve phrase
reordering. They addressed phrase reordering as
a two-class classification problem that translating
neighboring phrases serially or inversely. They built
a maximum entropy (MaxEnt) classifier based on
boundary words to predict the order of neighboring
phrases.
He et al (2008) presented a lexicalized rule selec-
tion model to improve both lexical translation and
phrase reordering for HPB translation. They built
a MaxEnt model for each ambiguous source side
based on contextual features. The method was also
successfully applied to improve syntax-based SMT
translation (Liu et al, 2008), using more sophisti-
cated syntactical features. Shen et al (2008) inte-
grated various contextual and linguistic features into
an HPB system, using surrounding words and de-
pendency information for building context and de-
pendency language models, respectively.
In this paper, we focus on improving phrase re-
ordering for HPB translation. We classify SCFG
rules into several reordering patterns consisting of
two variables X and F (or E) 1, such as X1FX2
and X2EX1. We treat phrase reordering as a classi-
fication problem and build a MaxEnt model for each
source reordering pattern based on various contex-
1We use F and E to represent source and target words, re-
spectively.
tual features. We propose a method to integrate the
MaxEnt models into an HPB system. Specifically:
? For hierarchical rules, we classify the source-
side and the target-side into 7 and 17 reordering
patterns, respectively. Target reordering pat-
terns are treated as possible labels. We then
build a classifier for each source pattern to pre-
dict phrase reorderings. This is different from
He et al (2008), in which they built a clas-
sifier for each ambiguous hierarchical source-
side. Therefore, the training examples for each
MaxEnt model is small and the model maybe
unstable. Here, we classify source hierarchical
phrases into 7 reordering patterns according to
the arrangement of words and variables. We
can obtain sufficient samples for each MaxEnt
model from large-scale bilingual corpus.
? For glue rules, we extend the HPB model by
using bracketing transduction grammar (BTG)
(Wu, 1996) instead of the monotone glue rule.
By doing this, there are two options for the de-
coder to merge phrases: serial or inverse. We
then build a classifier for glue rules to predict
reorderings of neighboring phrases, analogous
to Xiong et al (2006).
? We integrate the MaxEnt based phrase reorder-
ing models as features into the HPB model
(Chiang, 2005). The feature weights can be
tuned together with other feature functions by
MERT algorithm (Och, 2003).
Experimental results show that the presented method
achieves significant improvement over the baseline.
On Chinese-to-English translation tasks of NIST
evluation, improvements in BLEU (case-insensitive)
are 1.2 on MT06 GALE set, 1.8 on MT06 NIST set,
and 2.1 on MT08.
The rest of the paper is structured as follows: Sec-
tion 2 describes the MaxEnt based phrase reorder-
ing method. Section 3 integrates the MaxEnt mod-
els into the translation model. In Section 4, we re-
port experimental results. We analyze the presented
method and experimental results in Section 5 and
conclude in Section 6.
556
Source phrase Target phrase
X and
X ? with X
between X and
Figure 1: A source hierarchical phrase and its corre-
sponding target translation.
2 MaxEnt based Phrase Reordering
We regard phrase reordering as a pattern classifica-
tion problem. A reordering pattern indicates an ar-
rangement of words and variables. Although there
are a large amount of hierarchical rules may be ex-
tracted from bilingual corpus, these rules can be
classified into several reordering patterns (Section
2.1). In addition, we extend the HPB model with
BTG, that adding an inverted glue rule to merge
phrases inversely (Section 2.2). Therefore, the glue
rules are classified into two patterns: serial or in-
verse. We then build a MaxEnt phrase reordering
(MEPR) classifier for each source reordering pattern
(Section 2.3). In Section 2.4, we describe contextual
features.
2.1 Reordering Pattern Classification for
Hierarchical Rule
Hierarchical rule, consisting of both words and vari-
ables, is of great importance for the HPB model.
During decoding, words are used for lexical trans-
lation, and variables capture phrase reordering. We
may learn millions of hierarchical rules from a bilin-
gual corpus. Although these rules are different from
each other, they can be classified into several re-
ordering patterns according to the arrangement of
variables and words.
In this paper, we follow the constraint as de-
scribed in (Chiang, 2005) that a hierarchical rule
can have at most two variables and they cannot be
adjacent on the source side. We use ?X? to rep-
resent the variable, and ?F ? and ?E? to represent
word strings in source and target language, respec-
tively. Therefore, in a hierarchical rule, E is the lex-
ical translation of F , while the order of X and E
contains phrase reordering information.
For the hierarchical rule that contains one vari-
able (see Figure 1 for example), both the source and
the target phrases can be classified into three pat-
Source pattern Target pattern
XF XE
FX EX
FXF EXE
Table 2: A classification of the source side and the target
side for the hierarchical rule that contains one variable.
Source pattern Target pattern
X1EX2
X2EX1
X1X2E
X2X1E
EX1X2
X1FX2 EX2X1
X1FX2F X1EX2E
FX1FX2 X2EX1E
FX1FX2F EX1X2E
EX2X1E
EX1EX2
EX2EX1
EX1EX2E
EX2EX1E
Table 3: A classification of the source side and the target
side for the hierarchical rule that contains two variables.
terns (Table 2). To reduce the complexity of clas-
sification, we do not distinguish the order of word
strings. For example, we consider ?e1Xe2? and
?e2Xe1? as the same pattern ?EXE?, because the
target words are determined by lexical translation of
source words. Our focus is the order between X and
E. During decoding the phrases covered by X are
dynamically changed and the contextual information
of these phrases is ignored for pattern-matching of
hierarchical rules.
Analogously, for the hierarchical rule that con-
tains two variables, the source phrases are classified
into 4 patterns, while the target phrases are classified
into 14 patterns, as shown in Table 3. The pattern
number on the source side is less than that on the
target side, because on the source side, ?X1? always
appears before ?X2?, and they cannot be adjacent.
557
2.2 Reordering Pattern Classification for Glue
Rule
The HPB model used glue rule to combine phrases
serially. The reason is that in some cases, there are
no valid translation rules that cover a source span.
Therefore, the glue rule provides a default monotone
combination of phrases in order to complete a trans-
lation. This is not sufficient because in certain cases,
the order of phrases may be inverted on the target-
side.
In this paper, we extend the glue rule with BTG
(Wu, 1996), which consists of three types of rules:
X ? ?f? , e?? (3)
X ? ?X1X2, X1X2? (4)
X ? ?X1X2, X2X1? (5)
Rule 3 is a phrasal rule that translates a source
phrase f? into a target phrase e?. Rule 4 merges two
consecutive phrases in monotone order, while Rule
5 merges them in inverted order. During decod-
ing, the decoder first uses Rule 3 to produce phrase
translation, and then iteratively uses Rule 4 and 5 to
merge two neighboring phrases into a larger phrase
until the whole sentence is covered.
We replace the original glue rules in the HPB
model with BTG rules (see Table 4). We believe
that the extended HPB model can benefit from BTG
in the following aspects:
? In the HPB model, as we mentioned, hierarchi-
cal rules are constrained in that nonterminals
cannot be adjacent on the source side, i.e., the
source side cannot contain ?X1X2?. One rea-
son is that it will heavily increase the rule table
size. The other reason is that it can cause a spu-
rious ambiguity problem (Chiang, 2005). The
inverted glue rule in BTG, however, can solve
this problem.
? In the HPB model, only a monotone glue rule
is provided to merge phrases serially. In the ex-
tended HPB model, the combination of phrases
is classified into two types: monotone and in-
verse.
Analogous to Xiong et al (2006), to perform
context-dependent phrase reordering, we build a
Glue Rule Extended Glue Rule
S ? ?X,X? S ? ?X,X?
S ? ?SX, SX? X ? ?X1X2, X1X2?
- X ? ?X1X2, X2X1?
Table 4: Extending the glue rules in the HPB model with
BTG.
MaxEnt based classifier for glue rules to predict the
order of two neighboring phrases. In this paper, we
utilize more contextual features.
2.3 The MaxEnt based Phrase Reordering
Classifier
As described above, we classified phrase reorderings
into several patterns. Therefore, phrase reordering
can be regarded as a classification problem: for each
source reordering pattern, we treat the correspond-
ing target reordering patterns as labels.
We build a general classification model within the
MaxEnt framework:
Pme(T? |T?, ?, ?) =
exp(?i ?ihi(?, ?, f(X), e(X))
?
T? exp(
?
i ?ihi(?, ?, f(X), e(X))
(6)
where, ? and ? are the source and target side, re-
spectively. T?/T? is the reordering pattern of ?/?.
f(X) and e(X) are the phrases that covered by X
one the source and target side, respectively. Given
a source phrase, the model predicts a target reorder-
ing pattern, considering various contextual features
(Section 2.4).
According to the classification of reordering pat-
terns, there are 3 kinds of classifiers:
? P hr1me includes 3 classifiers for the hierarchical
rules that contain 1 variable. Each of the clas-
sifier has 3 labels;
? P hr2me includes 4 classifiers for the hierarchical
rules that contain 2 variables. Each of the clas-
sifier has 14 labels;
? P grme includes 1 classifier for the glue rules. The
classifier has 2 labels that predict a monotone
or inverse order for two neighboring phrases.
This classifier is analogous to (Xiong et al,
2006).
558
There are 8 classifiers in total. This is much fewer
than the classifiers in He et al (2008), in which a
classifier was built for each ambiguous hierarchical
source side. In this way, a classifier may face the
risk that there are not enough samples for training a
stable MaxEnt model. While our approach is more
generic, rather than training a MaxEnt model for a
specific hierarchical source side, we train a model
for a source reordering pattern. Thus, we reduce the
number of classifiers and can extract large training
examples for each classifier.
2.4 Feature definition
For a reordering pattern pair ?T?, T??, we design
three feature functions for phrase reordering classi-
fiers:
? Source lexical feature, including boundary
words and neighboring words. Boundary
words are the left and right word of the source
phrases covered by f(X), while neighboring
words are the words that immediately to the left
and right of a source phrase f(?);
? Part-of-Speech (POS) feature, POS tags of the
boundary and neighboring words on the source
side.
? Target lexical feature, the boundary words of
the target phrases covered by e(X).
These features can be extracted together with
translation rules from bilingual corpus. However,
since the hierarchical rule does not allow for adja-
cent variables on the source side, we extract features
for P grme by using the method described in Xiong et
al. (2006). We train the classifiers with a MaxEnt
trainer (Zhang, 2004).
3 Integrating the MEPR Classifier into the
HPB Model
The HPB model is built within the standard log-
linear framework (Och and Ney, 2002):
Pr(e|f) ?
?
i
?ihi(?, ?) (7)
where hi(?, ?) is a feature function and ?i is the
weight of hi. The HPB model has the following fea-
tures: translation probabilities p(?|?) and p(?|?),
lexical weights pw(?|?) and pw(?|?), word penalty,
phrase penalty, glue rule penalty, and a target n-
gram language model.
To integrate the MEPR classifiers into the transla-
tion model, the features of the log-linear model are
changed as follows:
? We add the MEPR classifier as a feature func-
tion to predict reordering pattern:
hme(T? |T?) =
?
Pme(T? |T?, ?, ?) (8)
During decoding, we first classify each source
phrase into one of the 8 source reordering pat-
terns and then use the corresponding MEPR
classifier to predict the possible target reorder-
ing pattern. Therefore, the contextual informa-
tion guides the decoder to perform phrase re-
ordering.
? We split the ?glue rule penalty? into two fea-
tures: monotone glue rule number and inverted
glue rule number. These features reflect pref-
erence of the decoder for using monotone or
inverted glue rules.
The advantage of our extension method is that the
weights of the new features can be tuned together
with the other features by MERT algorithm (Och,
2003).
We utilize a standard CKY algorithm for decod-
ing. Given a source sentence, the decoder searches
the best derivation from the bottom to top. For a
source span [j1, j2], the decoder uses three kinds of
rules: translation rules produce lexical translation
and phrase reordering (for hierarchical rules), mono-
tone rule merges any neighboring sub-spans [j1, k]
and [k + 1, j2] serially, and inverted rule swap them.
Note that when the decoder uses the monotone and
inverted glue rule to combine sub-spans, it merges
phrases that do not contain variables. Because the
CKY algorithm guarantees that the sub spans [j1, k]
and [k + 1, j2] have been translated before [j1, j2].
559
4 Experiments
We carried out experiments on four systems:
? HPB: replication of the Hiero system (Chiang,
2005);
? HPB+MEHR: HPB with MaxEnt based classi-
fier for hierarchical rules, as described in Sec-
tion 2.1;
? HPB+MEGR: HPB with MaxEnt based classi-
fier for glue rules, as described in Section 2.2;
? HPB+MER: HPB with MaxEnt based classifier
for both hierarchical and glue rules.
All systems were tuned on NIST MT03 and tested
on MT06 and MT08. The evaluation metric was
BLEU (Papineni et al, 2002) with case-insensitive
matching of n-grams, where n = 4.
We evaluated our approach on Chinese-to-
English translation. The training data contained
77M Chinese words and 81M English words.
These data come from 17 corpora: LDC2002E18,
LDC2002L27, LDC2002T01, LDC2003E07,
LDC2003E14, LDC2004T07, LDC2005E83,
LDC2005T06, LDC2005T10, LDC2005T34,
LDC2006E24, LDC2006E26, LDC2006E34,
LDC2006E86, LDC2006E92, LDC2006E93,
LDC2004T08 (HK News, HK Hansards).
To obtain word alignments, we first ran GIZA++
(Och and Ney, 2000) in both translation directions
and then refined the results using the ?grow-diag-
final? method (Koehn et al, 2003). For the lan-
guage model, we used the SRI Language Modeling
Toolkit (Stolcke, 2002) to train two 4-gram models
on the Xinhua portion of the GigaWord corpus and
the English side of the training corpus.
4.1 Statistical Information of Rules
Hierarchical Rules
We extracted 162M translation rules from the train-
ing corpus. Among them, there were 127M hi-
erarchical rules, which contained 85M hierarchical
source phrases. We classified these source phrases
into 7 patterns as described in Section 2.1. Table
5 shows the statistical information. We observed
that the most frequent source pattern is ?FXF ?,
Source Pattern Percentage (%)
XF 9.7
FX 9.7
FXF 46.1
X1FX2 3.7
X1FX2F 11.9
FX1FX2 11.8
FX1FX2F 7.1
Table 5: Statistical information of reordering pattern clas-
sification for hierarchical source phrases.
# Source
Target (%) FX XF FXF
EX 82.8 7 4.6
XE 6.4 82.4 2.9
EXE 10.8 10.6 92.5
Table 6: Percentage of target reordering pattern for each
source pattern containing one variable.
which accounted for 46.1% of the total. Interest-
ingly, ?X1FX2?, accounting for 3.7%, was the least
frequent pattern. Table 6 and Table 7 show the
distributions of reordering patterns for hierarchical
source phrases that contain one and two variables,
respectively. From both the tables, we observed
that for Chinese-to-English translation, the most fre-
quent ?reordering? pattern for a source phrase is
monotone translation (bold font in the tables).
Glue Rules
To train a MaxEnt classifier for glue rules, we ex-
tracted 65.8M reordering (monotone and inverse)
instances from the training data, using the algo-
rithm described in Xiong et al (2006). There were
63M monotone instances, accounting for 95.7%. Al-
though instances of inverse reordering accounted for
4.3%, they are important for phrase reordering.
4.2 Results
Table 8 shows the BLEU scores and decoding speed
of the four systems on MT06 (GALE set and NIST
set) and MT08. From the table, we made the follow-
ing observations:
560
# Source
Target (%) FX1FX2 FX1FX2F X1FX2 X1FX2F
EX1EX2 78.1 3.6 4.6 1.2
EX1EX2E 2.1 75.9 0.1 1.6
EX1X2 6.8 0.1 2.8 0.1
EX1X2E 1.8 11.2 0.1 2
EX2EX1 2.8 1.4 2 1.2
EX2EX1E 1.4 2.3 0.7 1.1
EX2X1 0.9 0.1 2.2 0.2
EX2X1E 1 1.1 0.9 1.0
X1EX2 1.9 0.1 71.2 3.3
X1EX2E 0.7 2.1 6 78.4
X1X2E 0.1 0.1 2.8 5.9
X2EX1 0.9 0.4 1.6 0.7
X2EX1E 1.5 1.5 2.6 2.4
X2X1E 0.1 0.04 2.2 0.8
Table 7: Percentage of target reordering pattern for each source pattern containing two variables.
System Test Data Speed06G 06N 08
HPB 14.19 33.93 25.85 8.7
HPB+MEHR 14.76 34.95 26.56 3.2
HPB+MEGR 15.09 35.72 27.34 2.7
HPB+MER 15.42 35.80 27.94 1.7
Table 8: BLEU percentage scores and translation speed (words/second) on test data. G=GALE set, N=NIST set. All
improvements are statistically significant (p < 0.01). Note that MT06G has one reference for each source sentence,
while the MT06N and MT08 have four references.
? The HPB+MEHR system achieved significant
improvements on all test sets compared to the
HPB system. The absolute increases in BLEU
scores ranging from 0.6 (on 06G) to 1.0 (on
06N) percentage points. This indicates that the
ME based reordering for hierarchical rules im-
proves translation performance.
? The HPB+MEGR system achieved significant
improvements over the HPB system. The ab-
solute increases in BLEU scores ranging from
0.9 (on 06G) to 1.8 (on 06N) percentage points.
The HPB+MEGR system overcomes the short-
coming of the HPB system by using both
monotone glue rule and inverted glue rule,
which merging phrases serially and inversely,
respectively. Furthermore, the HPB+MEGR
system outperformed the HPB+MEHR system.
? The HPB+MER system achieved the best per-
formances on all test sets, with absolute in-
creases of BLEU scores ranging from 1.2 (on
06G) to 2.1 (on 08). The system combin-
ing with ME based reordering for both hier-
archical and glue rules, outperformed both the
HPB+MEHR and HPB+MEGR systems.
? In addition, we found that the decoder takes
more time after adding the MEPR models (the
speed column of Table 8). The average transla-
tion speed of HPB+MER (1.7 words/second) is
about 5 times slower than the HPB system (8.7
words/second). One reason is that the MEPR
models utilized contextual information to com-
pute classification scores. Another reason is
that adding inverted glue rules increases search
space.
561
5 Analysis
Experiments showed that the presented approach
achieved significant gains on BLEU scores. Further-
more, we sought to explore what would happen af-
ter integrating the MEPR classifiers into the transla-
tion model. We compared the outputs of HPB and
HPB+MER and observed that the translation perfor-
mance are improved on phrase reordering. For ex-
ample, the translations of a source sentence in MT08
are as follows 2:
? Src: ?I1 ?2 ??3 .4 m?5 ??6
?7 ?m8 J?9 4010 ?11 ??12 13 
?14 Oy15
? Ref: At the end4 of last3 month3, the
South1 Korean1 government2 began5 a plan15
to provide9 400,00010 tonnes11 of rice12 as
aid14 to North8 Korea8
? HPB: South Korean government late last
month to start with 400,000 tons of rice aid to
the DPRK
? HPB+MER: Start at the end of last month,
South Korean government plans to provide
400,000 tons of rice in aid to the DPRK
The most obvious error that the baseline system
makes is the order of the time expression ???
., the end of last month?, which should be either
at the beginning or the end on target side. However,
the baseline produced a monotone translation by us-
ing the rule ??I ? X1, South Korean govern-
ment X1?. The HPB+MER system, however, moved
the time expression to the beginning of the sentence
by using the rule ??I ? X1, X1 South Ko-
rean government?. The reason is that the MaxEnt
phrase reordering classifier uses the contextual fea-
tures (e.g. the boundary words) of the phrase cov-
ered by X1 to predict the phrase reordering as X1E
for the source phrase FX1.
2The co-indexes of the words in the source and reference
sentence indicate word alignments.
6 Conclusions and Future Work
In this paper, we have proposed a MaxEnt based
phrase reordering approach to help the HPB decoder
select reordering patterns. We classified hierarchical
rules into 7 reordering patterns on the source side
and 17 reordering patterns on the target side. In ad-
dition, we introduced BTG to enhance the reorder-
ing of neighboring phrases and classified the glue
rules into two patterns. We trained a MaxEnt clas-
sifier for each reordering pattern and integrated it
into a standard HPB system. Experimental results
showed that the proposed approach achieved signif-
icant improvements over the baseline. The absolute
improvements in BLEU range from 1.2 to 2.1.
MaxEnt based phrase reordering provides a mech-
anism to incorporate various features into the trans-
lation model. In this paper, we only use a few fea-
ture sets based on standard contextual word and POS
tags. We believe that additional features will fur-
ther improve translation performance. Such features
could include syntactical features (Chiang et al,
2009). In the future, we will carry out experiments
on deeper features and evaluate the effects of differ-
ent feature sets.
References
Marine Carpuat and Dekai Wu. 2007. Improving statisti-
cal machine translation using word sense disambigua-
tion. In Proceedings of EMNLP-CoNLL 2007, pages
61?72.
Yee Seng Chan, Hwee Tou Ng, and David Chiang. 2007.
Word sense disambiguation improves statistical ma-
chine translation. In Proceedings of the 45th Annual
Meeting of the Association for Computational Linguis-
tics, pages 33?40.
David Chiang, Wei Wang, and Kevin Knight. 2009.
11,001 new features for statistical machine transla-
tion. In Proceedings of the North American Chapter
of the Association for Computational Linguistics - Hu-
man Language Technologies 2009 Conference, page
218?226.
David Chiang. 2005. A hierarchical phrase-based model
for statistical machine translation. In Proceedings of
the 43rd Annual Meeting of the Association for Com-
putational Linguistics, pages 263?270.
David Chiang. 2007. Hierarchical phrase-based trans-
lation. Computational Linguistics, pages 33(2):201?
228.
Zhongjun He, Qun Liu, and Shouxun Lin. 2008. Im-
proving statistical machine translation using lexical-
562
ized rule selection. In Proceedings of the 22nd In-
ternational Conference on Computational Linguistics,
pages 321?328.
Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003.
Statistical phrase-based translation. In Proceedings of
the 2003 Conference of the North American Chapter of
the Association for Computational Linguistics on Hu-
man Language Technology, pages 48?54.
Qun Liu, Zhongjun He, Yang Liu, and Shouxun Lin.
2008. Maximum entropy based rule selection model
for syntax-based statistical machine translation. In
Proceedings of the 2008 Conference on Empiri-
cal Methods in Natural Language Processing, page
89?97.
Franz Josef Och and Hermann Ney. 2000. Improved sta-
tistical alignment models. In Proceedings of the 38th
Annual Meeting of the Association for Computational
Linguistics, pages 440?447.
Franz Josef Och and Hermann Ney. 2002. Discrimina-
tive training and maximum entropy models for statis-
tical machine translation. In Proceedings of the 40th
Annual Meeting of the Association for Computational
Linguistics, pages 295?302.
Franz Josef Och. 2003. Minimum error rate training in
statistical machine translation. In Proceedings of the
41st Annual Meeting of the Association for Computa-
tional Linguistics, pages 160?167.
K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu. 2002.
Bleu: a method for automatic evaluation of machine
translation. In Proceedings of the 40th Annual Meet-
ing of the Association for Computational Linguistics,
pages 311?318.
Libin Shen, Jinxi Xu, Bing Zhang, Spyros Matsoukas,
and Ralph Weischedel. 2008. Effective use of linguis-
tic and contextual information for statistical machine
translation. In Proceedings of the 2009 Conference on
Empirical Methods in Natural Language Processing,
pages 72?80.
Andreas Stolcke. 2002. SRILM ? An extensible lan-
guage modeling toolkit. In Proceedings of the Inter-
national Conference on Spoken language Processing,
volume 2, pages 901?904.
Dekai Wu. 1996. A polynomial-time algorithm for sta-
tistical machine translation. In Proceedings of the
Thirty-Fourth Annual Meeting of the Association for
Computational Linguistics.
Deyi Xiong, Qun Liu, and Shouxun Lin. 2006. Max-
imum entropy based phrase reordering model for sta-
tistical machine translation. In Proceedings of the 44th
Annual Meeting of the Association for Computational
Linguistics, pages 521?528.
Richard Zens and Hermann Ney. 2006. Discriminative
reordering models for statistical machine translation.
In Proceedings of the Workshop on Statistical Machine
Translation, pages 55?63.
Le Zhang. 2004. Maximum entropy model-
ing toolkit for python and c++. available at
http://homepages.inf.ed.ac.uk/s0450736/maxent too-
lkit.html.
563
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 524?534,
Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational Linguistics
Improving Pivot-Based Statistical Machine Translation 
Using Random Walk 
 
Xiaoning Zhu1*
Conghui Zhu1, and Tiejun Zhao1 
, Zhongjun He2, Hua Wu2, Haifeng Wang2,  
Harbin Institute of Technology, Harbin, China1 
Baidu Inc., Beijing, China2 
{xnzhu, chzhu, tjzhao}@mtlab.hit.edu.cn 
{hezhongjun,wu_hua,wanghaifeng}@baidu.com 
 
 
 
 
 
                                                          
* This work was done when the first author was visiting Baidu. 
Abstract 
This paper proposes a novel approach that uti-
lizes a machine learning method to improve 
pivot-based statistical machine translation 
(SMT). For language pairs with few bilingual 
data, a possible solution in pivot-based SMT 
using another language as a "bridge" to gen-
erate source-target translation. However, one 
of the weaknesses is that some useful source-
target translations cannot be generated if the 
corresponding source phrase and target phrase 
connect to different pivot phrases. To allevi-
ate the problem, we utilize Markov random 
walks to connect possible translation phrases 
between source and target language. Experi-
mental results on European Parliament data, 
spoken language data and web data show that 
our method leads to significant improvements 
on all the tasks over the baseline system. 
1 Introduction 
Statistical machine translation (SMT) uses bilin-
gual corpora to build translation models. The 
amount and the quality of the bilingual data 
strongly affect the performance of SMT systems. 
For resource-rich language pairs, such as Chinese-
English, it is easy to collect large amounts of bi-
lingual corpus. However, for resource-poor lan-
guage pairs, such as Chinese-Spanish, it is difficult 
to build a high-performance SMT system with the 
small scale bilingual data available.  
The pivot language approach, which performs 
translation through a third language, provides a 
possible solution to the problem. The triangulation 
method (Wu and Wang, 2007; Cohn and Lapata, 
2007) is a representative work for pivot-based ma-
chine translation. With a triangulation pivot ap-
proach, a source-target phrase table can be 
obtained by combining the source-pivot phrase 
table and the pivot-target phrase table. However, 
one of the weaknesses is that some corresponding 
source and target phrase pairs cannot be generated, 
because they are connected to different pivot 
phrases (Cui et al, 2013). As illustrated in Figure 
1, since there is no direct translation between ??
?? henkekou? and ?really delicious?, the trian-
gulation method is unable to establish a relation 
between ???? henkekou? and the two Spanish 
phrases. 
To solve this problem, we apply a Markov ran-
dom walk method to pivot-based SMT system. 
Random walk has been widely used. For example, 
Brin and Page (1998) used random walk to dis-
cover potential relations between queries and doc-
uments for link analysis in information retrieval. 
Analogous to link analysis, the aim of pivot-based 
translation is to discover potential translations be-
tween source and target language via the pivot 
language.  
524
The goal of this paper is to extend the previous 
triangulation approach by exploring implicit trans-
lation relations using random walk method. We 
evaluated our approach in several translation tasks, 
including translations between European lan-
guages; Chinese-Spanish spoken language transla-
tion and Chinese-Japanese translation with English 
as the pivot language. Experimental results show 
that our approach achieves significant improve-
ments over the conventional pivot-based method, 
triangulation method. 
The remainder of this paper is organized as fol-
lows. In section 2, we describe the related work. 
We review the triangulation method for pivot-
based machine translation in section 3. Section 4 
describes the random walk models. In section 5 
and section 6, we describe the experiments and 
analyze the performance, respectively. Section 7 
gives a conclusion of the paper. 
2 Related Work 
Several methods have been proposed for pivot-
based translation. Typically, they can be classified 
into 3 kinds of methods: 
Transfer Method: Within the transfer frame-
work (Utiyama and Isahara, 2007; Wang et al, 
2008; Costa-juss? et al, 2011), a source sentence 
is first translated to n pivot sentences via a source-
pivot translation system, and then each pivot sen-
tence is translated to m target sentences via a piv-
ot-target translation system. At each step (source 
to pivot and pivot to target), multiple translation 
outputs will be generated, thus a minimum Bayes-
risk system combination method is often used to 
select the optimal sentence (Gonz?lez-Rubio et al, 
2011; Duh et al, 2011). A problem with the trans-
fer method is that it needs to decode twice. On one 
hand, the time cost is doubled; on the other hand, 
the translation error of the source-pivot translation 
system will be transferred to the pivot-target trans-
lation. 
Synthetic Method: A synthetic method creates 
a synthetic source-target corpus using source-pivot 
translation model or pivot-target translation model 
(Utiyama et al, 2008; Wu and Wang, 2009). For 
example, we can translate each pivot sentence in 
the pivot-target corpus to source language with a 
pivot-source model, and then combine the translat-
ed source sentence with the target sentence to ob-
tain a synthetic source-target corpus, and vice 
versa. However, it is difficult to build a high quali-
ty translation system with a corpus created by a 
machine translation system. 
Triangulation Method: The triangulation 
method obtains source-target model by combining 
source-pivot and pivot-target translation models 
(Wu and Wang, 2007; Cohn and Lapata 2007), 
which has been shown to work better than the oth-
er pivot approaches (Utiyama and Isahara, 2007). 
As we mentioned earlier, the weakness of triangu-
lation is that the corresponding source and target 
phrase pairs cannot be connected in the case that 
they connect to different pivot phrases. 
3 The Triangulation Method 
In this section, we review the triangulation method 
for pivot-based translation. 
With the two additional bilingual corpora, the 
source-pivot and pivot-target translation models 
can be trained. Thus, a pivot model can be ob-
tained by merging these two models. In the trans-
lation model, the phrase translation probability and 
the lexical weight are language dependent, which 
will be introduced in the next two sub-sections. 
Figure 1: An example of random walk on phrase table. The dashed line indicates an implicit relation 
in the phrase table. 
???? 
feichanghaochi 
really delicious 
very tasty 
 
???
henkekou 
realmente delicioso 
 
Chinese English Spanish 
muy delicioso 
 
525
3.1 Phrase Translation Probability 
The triangulation method assumes that there exist 
translations between phrases s  and phrase p  in 
source and pivot languages, and between phrase 
p  and phrase t  in pivot and target languages. 
The phrase translation probability ?  between 
source and target languages is determined by the 
following model: 
( | ) ( | , ) ( | )
          ( | ) ( | )
p
p
s t s p t p t
s p p t
? ? ?
? ?
=
=
?
?
       (1) 
3.2 Lexical Weight 
Given a phrase pair ( , )s t and a word alignment 
a  between the source word positions 1, ,i n= ?  
and the target word positions 0,1, ,j m= ? , the 
lexical weight of phrase pair ( , )s t  can be calcu-
lated with the following formula (Koehn et al 
2003) : 
( , )1
1
( | , ) ( | )
{ | ( , ) }
n
i j
i j ai
p s t a s t
j i j a?
?
? ?=
=
? ?? (2) 
In formula 2, the lexical translation probability 
distribution ( | )s t?  between source word s  and 
target word t  can be estimated with formula 3. 
'
'
( , )
( | )
( , )
s
count s t
s t
count s t
? =
?
            (3) 
Thus the alignment a  between the source 
phrase s  and target phrase t  via pivot phrase p  
is needed for computing the lexical weight. The 
alignment a  can be obtained as follows: 
1 2{( , ) | : ( , ) & ( , ) }a s t p s p a p t a= ? ? ?    (4) 
where 1a  and 2a  indicate the word alignment be-
tween the phrase pair ( , )s p  and ( , )p t , respec-
tively. 
The triangulation method requires that both the 
source and target phrases connect to the same piv-
ot phrase. Otherwise, the source-target phrase pair 
cannot be discovered. As a result, some useful 
translation relations will be lost. In order to allevi-
ate this problem, we propose a random walk model, 
to discover the implicit relations among the source, 
pivot and target phrases. 
4 Random Walks on Translation Graph 
For phrase-based SMT, all source-target phrase 
pairs are stored in a phrase table. In our random 
walk approach, we first build a translation graph 
according to the phrase table. A translation graph 
contains two types of nodes: source phrase and 
target phrase. A source phrase s  and a target 
phrase t  are connected if exists a phrase pair 
( , )s t  in the phrase table. The edge can be 
weighted according to translation probabilities or 
alignments in the phrase table. For the pivot-based 
translation, the translation graph can be derived 
from the source-pivot phrase table and pivot-target 
phrase table.  
Our random walk model is inspired by two 
works (Szummer and Jaakkola, 2002; Craswell 
and Szummer,2007). The general process of ran-
dom walk can be described as follows: 
Let ( , )G V E= be a directed graph with n  ver-
tices and m  edges. For a vertex v V? , ( )v?  de-
notes the set of neighbors of v  in G . A random 
walk on G  follows the following process: start at 
a vertex 0v , chose and walk along a random 
neighbor 1v , with 1 0( )v v?? . At the second step, 
start from 1v  and chose a random neighbor 2v , and 
so on. 
Let S be the set of source phrases, and P be the 
set of pivot phrases. Then the nodes V are the un-
ion of S and P. The edges E correspond to the rela-
tions between phrase pairs.  
Let R represent the binary relations between 
source phrases and pivot phrases. Then the 1-step 
translation ikR from node i to node k can be direct-
ly obtained in the phrase table. 
Define operator ?  to denote the calculation of 
relation R. Then 2-step translation ijR  from node i 
to node j can be obtained with the following for-
mula.  
ij ik kjR R R= ?                           (4) 
We use |0 ( | )tR k i  to denote a t-step translation 
relation from node i to node k. In order to calculate 
the translation relations efficiently, we use a ma-
trix A to represent the graph. A t step translation 
probability can be denoted with the following for-
mula. 
526
|0 ( | ) [ ]
t
t ikP k i A=                         (5) 
where A is a matrix whose i,k-th element is ikR . 
4.1 Framework of Random Walk Approach 
The overall framework of random walk for pivot-
based machine translation is shown in Figure 2. 
Before using random walk model, we have two 
phrase tables: source-pivot phrase table (SP phrase 
table) and pivot-target phrase table (PT phrase ta-
ble). After applying the random walk approach, we 
can achieve two extended phrase table: extended 
source-pivot phrase table (S?P? phrase table) and 
extended pivot-target phrase table (P?T? phrase 
table). The goal of pivot-based SMT is to get a 
source-target phrase table (ST phrase table) via SP 
phrase table and PT phrase table.  
Our random walk was applied on SP phrase ta-
ble or PT phrase table separately. In next 2 sub-
sections, we will explain how the phrase transla-
tion probabilities and lexical weight are obtained 
with random walk model on the phrase table. 
Figure 3 shows some possible decoding pro-
cesses of random walk based pivot approach. In 
figure 3-a, the possible source-target phrase pair 
can be obtained directly via a pivot phrase, so it 
does not need a random walk model. In figure 3-b 
and figure 3-c, one candidate source-target phrase 
pair can be obtained by random walks on source-
pivot side or pivot-target side. Figure 3-d shows 
that the possible source-target can only by ob-
tained by random walks on source-pivot side and 
pivot-target side. 
4.2 Phrase Translation Probabilities 
For the translation probabilities, the binary relation 
R is the translation probabilities in the phrase table. 
The operator ?  is multiplication. According to 
formula 5, the random walk sums up the probabili-
ties of all paths of length t between the node i and 
k. 
Figure 2: Framework of random walk based pivot translation. The ST phrase table was generated by combin-
ing SP and PT phrase table through triangulation method. The phrase table with superscript ??? means that it 
was enlarged by random walk. 
 
S?P?
Phrase Table
P?T? 
Phrase Table
 SP 
Phrase Table
PT 
Phrase Table
ST 
Phrase Table
S?T?
Phrase Table
Pivot without 
random walk
Pivot with 
random walkrandom walk
random walk
Figure 3: Some possible decoding processes of random walk based pivot approach. The ? stands for the 
source phrase (S); the ? represents the pivot phrase (P) and the ? stands for the target phrase (T). 
 
(a) Pivot without  
       random walk 
S P T 
(d) Random walk on   
     both sides 
S P T 
(b) Random walk on  
      source-pivot side 
S P T 
(c) Random walk on 
      pivot-target side 
S P T 
527
Take source-to-pivot phrase graph as an exam-
ple; denote matrix A contains s+p nodes (s source 
phrases and p pivot phrases) to represent the trans-
lation graph.  
( ) ( )ij s p s p
A g
+ ? +
? ?= ? ?                         (6) 
where ijg  is the i,j-th elements of matrix A. 
We can split the matrix A into 4 sub-matrixes: 
0
0
s s sp
ps p p
A
A
A
?
?
? ?
= ? ?
? ?
                      (7) 
where the sub-matrix [ ]sp ik s pA p ?=  represents the 
translation probabilities from source to pivot lan-
guage, and psA  represents the similar meaning. 
Take 3 steps walks as an example: 
Step1: 
0
0
s s sp
ps p p
A
A
A
?
?
? ?
= ? ?
? ?
 
Step2: 
2
0
0
sp ps s p
p s ps sp
A A
A
A A
?
?
?? ?
= ? ??? ?
 
Step3: 
3
0
0
s s sp ps sp
ps sp ps p p
A A A
A
A A A
?
?
? ?? ?
= ? ?? ?? ?
 
For the 3 steps example, each step performs a 
translation process in the form of matrix?s self-
multiplication.  
1. The first step means the translation from 
source language to pivot language. The matrix 
A is derived from the phrase table directly and 
each element in the graph indicates a transla-
tion rule in the phrase table.  
2. The second step demonstrates a procedure: S-
P-S?. With 2 steps random walks, we can find 
the synonymous phrases, and this procedure is 
analogous to paraphrasing (Bannard and 
Callison-Burch, 2005). For the example shown 
in  figure 1 as an example, the hidden relation 
between ???? henkekou? and ?????
feichanghaochi? can be found through Step 2. 
3. The third step describes the following proce-
dure: S-P-S?-P?. An extended source-pivot 
phrase table is generated by 3-step random 
walks. Compared with the initial phrase table 
in Step1, although the number of phrases is 
not increased, the relations between phrase 
pairs are increased and more translation rules 
can be obtained. Still for the example in Fig-
ure 1 , the hidden relation between ????
henkekou? and ?really delicious? can be gen-
erated in Step 3. 
4.3 Lexical Weights 
To build a translation graph, the two sets of phrase 
translation probabilities are represented in the 
phrase tables. However, the two lexical weights 
are not presented in the graph directly. To deal 
with this, we should conduct a word alignment 
random walk model to obtain a new alignment a 
after t steps. For the computation of lexical 
weights, the relation R can be expressed as the 
word alignment in the phrase table. The operator 
?  can be induced with the following formula. 
1 2{( , ) | : ( , ) & ( , ) }a x y p x z a z y a= ? ? ?         (8) 
where a1 and a2 represent the word alignment 
information inside the phrase pairs ( , )x y  and 
( , )y z respectively. An example of word 
alignment inducing is shown in Figure 4. With a 
new word alignment, the two lexical weights can 
be calculated by formula 2 and formula 3. 
Figure 4: An example of word alignment induction with 3 steps random walks 
?   ??   ?   ?   ? 
could   you   fill   out   this   form ?   ?   ??   ??   ?? 
please   fill   out   this   form 
?   ??   ?   ?   ? 
could   you   fill   out   this   form 
step 1 
step 2 
step 3 
528
5 Experiments 
5.1 Translation System and Evaluation Met-
ric 
In our experiments, the word alignment was ob-
tained by GIZA++ (Och and Ney, 2000) and the 
heuristics ?grow-diag-final? refinement rule. 
(Koehn et al, 2003). Our translation system is an 
in-house phrase-based system using a log-linear 
framework including a phrase translation model, a 
language model, a lexicalized reordering model, a 
word penalty model and a phrase penalty model, 
which is analogous to Moses (Koehn et al, 2007). 
The baseline system is the triangulation method 
based pivot approach (Wu and Wang, 2007).  
To evaluate the translation quality, we used 
BLEU (Papineni et al, 2002) as our evaluation 
metric. The statistical significance using 95% con-
fidence intervals were measured with paired boot-
strap resampling (Koehn, 2004). 
5.2 Experiments on Europarl 
5.2.1. Data sets 
We mainly test our approach on Europarl1
We perform our experiments on different trans-
lation directions and via different pivot languages. 
As a most widely used language in the world 
(Mydans, 2011), English was used as the pivot 
language for granted when carrying out experi-
ments on different translation directions. For trans-
lating Portuguese to Swedish, we also tried to 
perform our experiments via different pivot lan-
 corpus, 
which is a multi-lingual corpus including 21 Euro-
pean languages. Due to the size of the data, we 
only select 11 languages which were added to 
Europarl from 04/1996 or 01/1997, including Dan-
ish (da), German (de), Greek (el), English (en), 
Spanish (es), Finnish (fi), French (fr), Italian (it) 
Dutch (nl) Portuguese (pt) and Swedish (sv). In 
order to avoid a trilingual scenario, we split the 
training corpus into 2 parts by the year of the data: 
the data released in odd years were used for train-
ing source-pivot model and the data released in 
even years were used for training pivot-target 
model.  
                                                          
1 http://www.statmt.org/europarl/ 
guages. Table 1 and Table 2 summarized the train-
ing data. 
 
Language 
Pairs  
(src-pvt) 
Sentence 
Pairs # 
Language 
Pairs 
(pvt-tgt) 
Sentence 
Pairs # 
da-en 974,189 en-da 953,002 
de-en 983,411 en-de 905,167 
el-en 609,315 en-el 596,331 
es-en 968,527 en-es 961,782 
fi-en 998,429 en-fi 903,689 
fr-en 989,652 en-fr 974,637 
it-en 934,448 en-it 938,573 
nl-en 982,696 en-nl 971,379 
pt-en 967,816 en-pt 960,214 
sv-en 960,631 en-sv 869,254 
 
Table1. Training data for experiments using English as 
the pivot language. For source-pivot (src-pvt; xx-en) 
model training, the data of odd years were used. Instead 
the data of even years were used for pivot-target (pvt-
src; en-xx) model training. 
 
 
Language 
Pairs  
(src-pvt) 
Sentence 
Pairs # 
Language 
Pairs 
(pvt-tgt) 
Sentence 
Pairs # 
pt-da 941,876 da-sv 865,020 
pt-de 939,932 de-sv 814,678 
pt-el 591,429 el-sv 558,765 
pt-es 934,783 es-sv 827,964 
pt-fi 950,588 fi-sv 872,182 
pt-fr 954,637 fr-sv 860,272 
pt-it 900,185 it-sv 813,000 
pt-nl 945,997 nl-sv 864,675 
 
Table2. Training data for experiments via different piv-
ot languages. For source-pivot (src-pvt; pt-xx) model 
training, the data of odd years were used. Instead the 
data of even years were used for pivot-target (pvt-src; 
xx-sv) model training. 
 
Test Set Sentence # Reference # 
WMT06 2,000 1 
WMT07 2,000 1 
WMT08 2,000 1 
 
Table3. Statistics of test sets. 
529
 
Several test sets have been released for the 
Europarl corpus. In our experiments, we used 
WMT20062, WMT20073 and WMT20084 as our 
test data. The original test data includes 4 lan-
guages and extended versions with 11 languages 
of these test sets are available by the EuroMatrix5
5.2.2. Experiments on Different Translation 
Directions 
  
project. Table 3 shows the test sets. 
We build 180 pivot translation systems6
The baseline system was built following the tra-
ditional triangulation pivot approach. Table 4 lists 
the results on Europarl training data. Limited by 
 (including 
90 baseline systems and 90 random walk based 
systems) using 10 source/target languages and 1 
pivot language (English).  
                                                          
2 http://www.statmt.org/wmt06/shared-task/ 
3 http://www.statmt.org/wmt07/shared-task.html 
4 http://www.statmt.org/wmt08/shared-task.html 
5 http://matrix.statmt.org/test_sets/list 
6 Given N languages, a total of N*(N-1) SMT systems should 
be build to cover the translation between each language.  
the length of the paper, we only show the results 
on WMT08, the tendency of the results on 
WMT06 and WMT07 is similar to WMT08. 
Several observations can be made from the table.  
1. In all 90 language pairs, our method achieves 
general improvements over the baseline system.  
2. Among 90 language pairs, random walk 
based approach is significantly better than the 
baseline system in 75 language pairs. 
3. The improvements of our approach are not 
equal in different translation directions. The im-
provement ranges from 0.06 (it-es) to 1.21 (pt-da). 
One possible reason is that the performance is re-
lated with the source and target language. For ex-
ample, when using Finnish as the target language, 
the improvement is significant over the baseline. 
This may be caused by the great divergence be-
tween Uralic language (Finnish) and Indo-
European language (the other European language 
in Table4). From the table we can find that the 
translation between languages in different lan-
guage family is worse than that in some language 
family. But our random walk approach can im-
 TGT 
SRC 
da de el es fi fr it nl pt sv 
Baseline 
RW 
da - 
19.83 
20.15* 
20.46 
21.02* 
27.59 
28.29* 
14.76 
15.63* 
24.11 
24.71* 
20.49 
20.82* 
22.26 
22.57* 
24.38 
24.88* 
28.33 
28.87* 
Baseline 
RW 
de 
23.35 
23.69* 
- 
19.83 
20.05 
26.21 
26.70* 
12.72 
13.57* 
22.43 
22.78* 
18.82 
19.32* 
23.74 
24.11* 
23.05 
23.35* 
21.17 
21.27 
Baseline 
RW 
el 
23.24 
23.82* 
18.12 
18.49* 
- 
32.28 
32.48 
13.31 
14.08* 
27.35 
27.67* 
23.19 
23.63* 
20.80 
21.26* 
27.62 
27.86 
22.70 
23.15* 
Baseline 
RW 
es 
25.34 
26.07* 
19.67 
20.17* 
27.24 
27.52 
- 
13.93 
14.61* 
32.91 
33.16 
27.67 
27.92 
22.37 
22.85* 
34.73 
34.93 
24.83 
25.50* 
Baseline 
RW 
fi 
18.29 
18.63* 
13.20 
13.40 
14.72 
15.00* 
20.17 
20.48* 
- 
17.52 
17.84* 
14.76 
15.01 
15.50 
16.04* 
17.30 
17.68* 
16.63 
16.79 
Baseline 
RW 
fr 
25.67 
26.51* 
20.02 
20.45* 
26.58 
26.75 
37.50 
37.80* 
13.90 
14.75* 
- 
28.51 
28.71 
22.65 
23.33* 
33.81 
33.93 
24.64 
25.59* 
Baseline 
RW 
it 
22.63 
23.27* 
17.81 
18.40* 
24.24 
24.66* 
34.36 
35.42* 
13.20 
14.11* 
30.16 
30.48* 
- 
21.37 
21.81* 
30.84 
30.92* 
22.12 
22.64* 
Baseline 
RW 
nl 
22.49 
22.76 
19.86 
20.45* 
18.56 
19.10* 
24.69 
25.19* 
11.96 
12.63* 
21.48 
22.05* 
18.36 
18.67* 
- 
21.71 
22.13* 
19.83 
22.17* 
Baseline 
RW 
pt 
24.08 
25.29* 
19.11 
19.83* 
25.30 
26.20* 
36.59 
37.13* 
13.33 
14.21* 
32.47 
32.78* 
28.08 
28.44* 
21.52 
22.46* 
- 
22.90 
23.90* 
Baseline 
RW 
sv 
31.24 
31.75* 
20.26 
20.74* 
22.06 
22.59* 
29.21 
29.87* 
15.39 
16.13* 
25.63 
26.18* 
21.25 
21.81* 
22.30 
22.62* 
25.60 
26.09* 
- 
Table4. Experimental results on Europarl with different translation directions (BLEU% on WMT08). 
RW=Random Walk. * indicates the results are significantly better than the baseline (p<0.05). 
530
prove the performance of translations between dif-
ferent language families. 
5.2.3. Experiments via Different Pivot Lan-
guages 
In addition to using English as the pivot language, 
we also try some other languages as the pivot 
language. In this sub-section, experiments were 
carried out from translating Portuguese to Swedish 
via different pivot languages.  
Table 5 summarizes the BLEU% scores of dif-
ferent pivot language when translating from Por-
tuguese to Swedish. Similar to Table 4, our 
approach still achieves general improvements over 
the baseline system even if the pivot language has 
been changed. From the table we can see that for 
most of the pivot language, the random walk based 
approach gains more than 1 BLEU score over the 
baseline. But when using Finnish as the pivot lan-
guage, the improvement is only 0.02 BLEU scores 
on WMT08. This phenomenon shows that the piv-
ot language can also influence the performance of 
random walk approach. One possible reason for 
the poor performance of using Finnish as the pivot 
language is that Finnish belongs to Uralic lan-
guage family, and the other languages belong to 
Indo-European family. The divergence between 
different language families led to a poor perfor-
mance. Thus how to select a best pivot language is 
our future work. 
The problem with random walk is that it will 
lead to a larger phrase table with noises. In this 
sub-section, a pre-pruning (before random walk) 
and a post-pruning (after random walk) method 
were introduced to deal with this problem.  
We used a naive pruning method which selects 
the top N phrase pairs in the phrase table. In our 
experiments, we set N to 20. For pre-pruning, we 
prune the SP phrase table and PT phrase table be-
fore applying random walks. Post-pruning means 
that we prune the ST phrase table after random 
walks. For the baseline system, we also apply a 
pruning method before combine the SP and PT 
phrase table. We test our pruning method on pt-en-
sv translation task. Table 6 shows the results. 
With a pre- and post-pruning method, the ran-
dom walk approach is able to achieve further im-
provements. Our approach achieved BLEU scores 
of 25.11, 24.69 and 24.34 on WMT06, WMT07 
and WMT08 respectively, which is much better 
than the baseline and the random walk approach 
with pruning.  Moreover, the size of the phrase 
table is about half of the no-pruning method. 
When adopting a post-pruning method, the per-
formance of translation did not improved signifi-
cantly over the pre-pruning, but the scale of the 
phrase table dropped to 69M, which is only about 
2 times larger than the triangulation method. 
Phrase table pruning is a key work to improve 
the performance of random walk. We plan to ex-
plore more approaches for phrase table pruning. 
E.g. using significance test (Johnson et al, 2007) 
or monolingual key phrases (He et al, 2009) to 
filter the phrase table. 
 
 
Table5. Experimental results on translating from Portu-
guese to Swedish via different pivot language. 
RW=Random Walk. * indicates the results are signifi-
cantly better than the baseline (p<0.05). 
 
 
Table6. Results of Phrase Table Filtering 
 
trans 
language 
WMT 
06 
WMT 
07 
WMT 
08 
Baseline 
RW 
pt-da-sv 
23.40 
24.47* 
22.80 
24.21* 
22.49 
23.75* 
Baseline 
RW 
pt-de-sv 
22.72 
23.12* 
22.21 
23.26* 
21.76 
22.35* 
Baseline 
RW 
pt-el-sv 
22.53 
23.75* 
22.19 
23.22* 
21.37 
22.40* 
Baseline 
RW 
pt-en-sv 
23.54 
24.66* 
23.24 
24.22* 
22.90 
23.90* 
Baseline 
RW 
pt-es-sv 
23.58 
24.65* 
23.37 
24.10* 
22.80 
23.77* 
Baseline 
RW 
pt-fi-sv 
21.06 
21.17 
20.06 
20.42* 
20.26 
20.28 
Baseline 
RW 
pt-fr-sv 
23.55 
24.75* 
23.09 
24.15* 
22.89 
23.96* 
Baseline 
RW 
pt-it-sv 
23.65 
24.74* 
22.96 
24.18* 
22.79 
24.02* 
Baseline 
RW 
pt-nl-sv 
21.87 
23.06* 
21.83 
22.76* 
21.36 
22.29* 
 WMT 
06 
WMT 
07 
WMT 
08 
Phrase 
Pairs # 
Baseline 
+pruning 
23.54 
24.05
* 
23.24 
23.70
* 
22.90 
23.59
* 
46M 
32M 
RW 
+pre-pruning 
+post-pruning 
24.66 
25.11 
25.19
* 
24.22 
24.69 
24.79
* 
23.90 
24.34 
24.41
* 
215M 
109M 
69M 
531
5.3 Experiments on Spoken Language 
The European languages show various degrees of 
similarity to one another. In this sub-section, we 
consider translation from Chinese to Spanish with 
English as the pivot language. Chinese belongs to 
Sino-Tibetan Languages and English/Spanish be-
longs to Indo-European Languages, the gap be-
tween two languages is wide. 
A pivot task was included in IWSLT 2008 in 
which the participants need to translate Chinese to 
Spanish via English. A Chinese-English and an 
English-Spanish data were supplied to carry out 
the experiments. The entire training corpus was 
tokenized and lowercased. Table 7 and Table 8 
summarize the training data and test data. 
Table 9 shows the similar tendency with Table 4. 
The random walk models achieved BLEU% scores 
32.09, which achieved an absolute improvement of 
2.08 percentages points on BLEU over the base-
line.   
 
Corpus 
Sentence 
pair # 
Source 
word # 
Target 
word # 
CE 20,000 135,518 182,793 
ES 19,972 153,178 147,560 
 
Table 7: Training Data of IWSLT2008 
 
Test Set Sentence # Reference # 
IWSLT08 507 16 
 
Table8. Test Data of IWSLT2008 
 
System BLEU% phrase pairs # 
Baseline 30.01 143,790 
+pruning 30.25 108,407 
RW 31.57 2,760,439 
+pre-pruning 31.99 1,845,648 
+post-pruning 32.09* 1,514,694 
 
Table9. Results on IWSLT2008 
5.4 Experiments on Web Data 
The setting with Europarl data is quite artificial as 
the training data for directly translating between 
source and target actually exists in the original 
data sets. The IWSLT data set is too small to rep-
resent the real scenario. Thus we try our experi-
ment on a more realistic scenario: translating from 
Chinese to Japanese via English with web crawled 
data. 
All the training data were crawled on the web. 
The scale of Chinese-English and English-
Japanese is 10 million respectively. The test set 
was built in house with 1,000 sentences and 4 ref-
erences. 
 
System BLEU% phrase pairs # 
Baseline 28.76 4.5G 
+pruning 28.90 273M 
RW 29.13 46G 
+pre-pruning 29.44 11G 
+post-pruning 29.51* 3.4G 
 
Table10. Results on Web Data 
 
Table 10 lists the results on web data. From the 
table we can find that the random walk model can 
achieve an absolute improvement of 0.75 percent-
ages points on BLEU over the baseline.  
In this subsection, the training data contains 
parallel sentences with different domains. And the 
two training corpora (Chinese-English and Eng-
lish-Japanese) are typically very different. It 
means that our random walk approach is robust in 
the realistic scenario. 
6 Discussions 
The random walk approach mainly improves the 
performance of pivot translation in two aspects: 
reduces the OOVs and provides more hypothesis 
phrases for decoding.  
6.1 OOV 
Out-of-vocabulary (OOV 7
We count the OOVs when decoding with trian-
gulation model and random walk model on 
IWSLT2008 data. The statistics shows that when 
using triangulation model, there are 11% OOVs 
when using triangulation model, compared with 
9.6% when using random walk model. Less OOV 
often lead to a better result. 
) terms cause serious 
problems for machine translation systems (Zhang 
et al, 2005). The random walk model can reduce 
the OOVs. As illustrated in Figure 1, the Chinese 
phrase ????henkekou? cannot be connected to 
any Spanish phrase, thus it is a OOV term.  
                                                          
7 OOV refer to phrases here. 
532
6.2 Hypothesis Phrases 
To illustrate how the random walk method helps 
improve the performance of machine translation, 
we illustrate an example as follows: 
 
- Source: ? ? ? ?? 
              wo xiang yao zhentou 
- Baseline trans: Quiero almohada 
- Random Walk trans: Quiero una almohada 
 
For translating a Chinese sentence ??????
wo xiang yao zhentou? to Spanish, we can get two 
candidate translations. In this case, the random 
walk translation is better than the baseline system. 
The key phrase in this sentence is ??? zhentou?, 
figure 5 shows the extension process. In this case, 
the article ?a? is hidden in the source-pivot phrase 
table. The same situation often occurs in articles 
and prepositions. Random walk is able to discover 
the hidden relations (hypothesis phrases) among 
source, pivot and target phrases. 
 
 
 
 
 
 
 
 
 
 
7 Conclusion and Future Work 
In this paper, we proposed a random walk method 
to improve pivot-based statistical machine transla-
tion. The random walk method can find implicit 
relations between phrases in the source and target 
languages. Therefore, more source-target phrase 
pairs can be obtained than conventional pivot-
based method. Experimental results show that our 
method achieves significant improvements over 
the baseline on Europarl corpus, spoken language 
data and the web data.  
A critical problem in the approach is the noise 
that may bring in. In this paper, we used a simple 
filtering to reduce the noise. Although the filtering 
method is effective, other method may work better. 
In the future, we plan to explore more approaches 
for phrase table pruning. 
Acknowledgments 
We would like to thank Jianyun Nie, Muyun Yang 
and Lemao Liu for insightful discussions, and 
three anonymous reviewers for many invaluable 
comments and suggestions to improve our paper. 
This work is supported by National Natural Sci-
ence Foundation of China (61100093), and the 
Key Project of the National High Technology Re-
search and Development Program of China 
(2011AA01A207). 
References  
Colin Bannard and Chris Callison-Burch. 2005. Para-
phrasing with Bilingual Parallel Corpora. In Pro-
ceedings of the 43rd Annual Meeting of the 
Association for Computational Linguistics, pages 
597-604 
Sergey Brin and Lawrence Page. 1998. The Anatomy of 
a Large-Scale Hypertextual Web Search Engine. In 
Proceedings of the Seventh International World 
Wide Web Conference  
Trevor Cohn and Mirella Lapata. 2007. Machine Trans-
lation by Triangulation: Make Effective Use of Mul-
ti-Parallel Corpora. In Proceedings of 45th Annual 
Meeting of the Association for Computational Lin-
guistics, pages 828-735. 
Marta R. Costa-juss?, Carlos Henr?quez, and Rafael E. 
Banchs. 2011. Enhancing Scarce-Resource Language 
Translation through Pivot Combinations. In Proceed-
ings of the 5th International Joint Conference on 
Natural Language Processing, pages 1361-1365 
Nick Craswell and Martin Szummer. 2007. Random 
Walks on the Click Graph. In Proceedings of the 
30th annual international ACM SIGIR conference on 
Research and development in information retrieval, 
pages 239-246 
Yiming Cui, Conghui Zhu, Xiaoning Zhu, Tiejun Zhao 
and Dequan Zheng. 2013. Phrase Table Combination 
Deficiency Analyses in Pivot-based SMT. In Pro-
ceedings of 18th International Conference on Appli-
cation of Natural Language to Information Systems, 
pages 355-358. 
Kevin Duh, Katsuhito Sudoh, Xianchao Wu, Hajime 
Tsukada and Masaaki Nagata. 2011. Generalized 
Minimum Bayes Risk System Combination. In Pro-
ceedings of the 5th International Joint Conference 
on Natural Language Processing, pages 1356?1360 
Jes?s Gonz?lez-Rubio, Alfons Juan and Francisco 
Casacuberta. 2011. Minimum Bayes-risk System 
Figure 5: Phrase extension process. The dotted line 
indicates an implicit relation in the phrase table. 
??? 
ge zhentou 
?? 
zhentou 
pillow 
a pillow 
almohada 
una 
almohada 
533
Combination. In Proceedings of the 49th Annual 
Meeting of the Association for Computational Lin-
guistics, pages 1268?1277 
Zhongjun He, Yao Meng, Yajuan L?, Hao Yu and Qun 
Liu. 2009. Reducing SMT Rule Table with Mono-
lingual Key Phrase. In Proceedings of the ACL-
IJCNLP 2009 Conference Short Papers, pages 121-
124 
Howard Johnson, Joel Martin, George Foster, and Ro-
land Kuhn. 2007. Improving  translation quality by 
discarding most of the phrase table. In Proceedings 
of the 2007 Joint Conference on Empirical Methods 
in Natural Language Processing and Computational 
Natural Language Learning, pages 967?975. 
Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003. 
Statistical Phrase-Based Translation. In HLT-NAACL: 
Human Language Technology Conference of the 
North American Chapter of the Association for 
Computational Linguistics, pages 127-133 
Philipp Koehn. 2004. Statistical significance tests for 
machine translation evaluation. In Proceedings of the 
2004 Conference on Empirical Methods in Natural 
Language Processing (EMNLP), pages 388?395. 
Philipp Koehn. 2005. Europarl: A Parallel Corpus for 
Statistical Machine Translation. In Proceedings of 
MT Summit X, pages 79-86. 
Philipp Koehn, Hieu Hoang, Alexanda Birch, Chris 
Callison-Burch, Marcello Federico, Nicola Bertoldi, 
Brooke Cowan, Wade Shen, Christine Moran, Rich-
ard Zens, Chris Dyer, Ondrej Bojar, Alexandra 
Constantin, and Evan Herbst. 2007. Moses: Open 
Source Toolkit for Statistical Machine Translation. 
In Proceedings of the 45th Annual Meeting of the 
Association for Computational Linguistics, demon-
stration session, pages 177?180. 
Franz Josef Och and Hermann Ney. 2000. A compari-
son of alignment models for statistical machine 
translation. In Proceedings of the 18th International 
Conference on Computational Linguistics, pages 
1086?1090 
Kishore Papineni, Salim Roukos, Todd Ward and Wei-
Jing Zhu. 2002. BLEU: a Method for Automatic 
Evaluation of Machine Translation. In Proceedings 
of the 40th Annual Meeting of the Association for 
Computation Linguistics, pages 311-319 
Karl Pearson. 1905. The Problem of the Random Walk. 
Nature, 27(1865):294 
Mydans, Seth. 2011. Across cultures, English is the 
word. New York Times. 
Martin Szummer and Tommi Jaakkola. 2002. Partially 
Labeled Classification with Markov Random Walks. 
In Advances in Neural Information Processing Sys-
tems, pages 945-952 
Kristina Toutanova, Christopher D. Manning and An-
drew Y. Ng. 2004. Learning Random Walk Models 
for Inducting Word Dependency Distributions. In 
Proceedings of the 21st International Conference on 
Machine Learning.  
Masao Utiyama and Hitoshi Isahara. 2007. A Compari-
son of Pivot Methods for Phrase-Based Statistical 
Machine Translation. In Proceedings of Human 
Language Technology: the Conference of the North 
American Chapter of the Association for Computa-
tional Linguistics, pages 484-491 
Masao Utiyama, Andrew Finch, Hideo Okuma, Michael 
Paul, Hailong Cao, Hirofumi Yamamoto, Keiji Ya-
suda, and Eiichiro Sumita. 2008. The NICT/ATR 
speech Translation System for IWSLT 2008. In Pro-
ceedings of the International Workshop on Spoken 
Language Translation, pages 77-84 
Haifeng Wang, Hua Wu, Xiaoguang Hu, Zhanyi Liu, 
Jianfeng Li, Dengjun Ren, and Zhengyu Niu. 2008. 
The TCH Machine Translation System for IWSLT 
2008. In Proceedings of the International Workshop 
on Spoken Language Translation, pages 124-131 
Hua Wu and Haifeng Wang. 2007. Pivot Language Ap-
proach for Phrase-Based Statistical Machine Transla-
tion. In Proceedings of 45th Annual Meeting of the 
Association for Computational Linguistics, pages 
856-863.  
Hua Wu and Haifeng Wang. 2009. Revisiting Pivot 
Language Approach for Machine Translation. In 
Proceedings of the 47th Annual Meeting of the Asso-
ciation for Computational Linguistics and the 4th 
IJCNLP of the AFNLP, pages 154-162 
Ying Zhang, Fei Huang, Stephan Vogel. 2005. Mining 
translations of OOV terms from the web through 
cross-lingual query expansion. In Proceedings of the 
27th ACM SIGIR. pages 524-525 
 
 
534
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 147?152,
October 25-29, 2014, Doha, Qatar.
c?2014 Association for Computational Linguistics
Transformation from Discontinuous to Continuous Word Alignment
Improves Translation Quality
Zhongjun He
1
Hua Wu
1
Haifeng Wang
1
Ting Liu
2
1
Baidu Inc., No. 10, Shangdi 10th Street, Beijing, 100085, China
2
Harbin Institute of Technology, Harbin, China
{hezhongjun,wu hua,wanghaifeng}@baidu.com
tliu@ir.hit.edu.cn
Abstract
We present a novel approach to im-
prove word alignment for statistical ma-
chine translation (SMT). Conventional
word alignment methods allow discontin-
uous alignment, meaning that a source
(or target) word links to several target (or
source) words whose positions are dis-
continuous. However, we cannot extrac-
t phrase pairs from this kind of align-
ments as they break the alignment con-
sistency constraint. In this paper, we use
a weighted vote method to transform dis-
continuous word alignment to continuous
alignment, which enables SMT system-
s extract more phrase pairs. We carry
out experiments on large scale Chinese-
to-English and German-to-English trans-
lation tasks. Experimental results show
statistically significant improvements of
BLEU score in both cases over the base-
line systems. Our method produces a gain
of +1.68 BLEU on NIST OpenMT04 for
the phrase-based system, and a gain of
+1.28 BLEU on NIST OpenMT06 for the
hierarchical phrase-based system.
1 Introduction
Word alignment, indicating the correspondence
between the source and target words in bilingual
sentences, plays an important role in statistical
machine translation (SMT). Almost all of the SMT
models, not only phrase-based (Koehn et al.,
2003), but also syntax-based (Chiang, 2005; Liu
et al., 2006; Huang et al., 2006), derive translation
knowledge from large amount bilingual text anno-
tated with word alignment. Therefore, the quality
of the word alignment has big impact on the qual-
ity of translation output.
Word alignments are usually automatically ob-
tained from a large amount of bilingual training
corpus. The most widely used toolkit for word
alignment in SMT community is GIZA++ (Och
and Ney, 2004), which implements the well known
IBM models (Brown et al., 1993) and the HM-
M model (Vogel and Ney, 1996). Koehn et al.
(2003) proposed some heuristic methods (e.g. the
?grow-diag-final? method) to refine word align-
ments trained by GIZA++. Another group of word
alignment methods (Liu et al., 2005; Moore et
al., 2006; Riesa and Marcu, 2010) define feature
functions to describe word alignment. They need
manually aligned bilingual texts to train the mod-
el. However, the manually annotated data is too
expensive to be available for all languages. Al-
though these models reported high accuracy, the
GIZA++ and ?grow-diag-final? method are domi-
nant in practice.
However, automatic word alignments are usu-
ally very noisy. The example in Figure 1 shows
a Chinese and English sentence pair, with word
alignment automatically trained by GIZA++ and
the ?grow-diag-final? method. We find many er-
rors (dashed links) are caused by discontinuous
alignment (formal definition is described in Sec-
tion 2), a source (or target) word linking to sev-
eral discontinuous target (or source) words. This
kind of errors will result in the loss of many use-
ful phrase pairs that are learned based on bilingual
word alignment. Actually, according to the defini-
tion of phrases in a standard phrase-based model,
we cannot extract phrases from the discontinuous
alignment. The reason is that this kind of align-
ment break the alignment consistency constrain-
t (Koehn et al., 2003). For example, the Chi-
147
1{I
meiguo
2
?
shi
3
?
shaoshu
4
A?
jige
5
?
tou
6
e
xia
7
??
fandui
8
?
piao
9

de
10
I[
guojia
11
??
zhiyi
The
1
United
2
States
3
was
4
among
5
the
6
handful
7
of
8
nations
9
that
10
cast
11
a
12
nay
13
note
14
Figure 1: An example of word alignment between a Chinese and English sentence pair. The dashed links
are incorrect alignments.
nese word ?shi
2
?
1
is aligned to the English words
?was
4
? and ?that
10
?. However, these two English
words are discontinuous, and we cannot extract the
phrase pair ?(shi, was)?.
In this paper, we propose a simple weighed vote
method to deal with the discontinuous word align-
ment. Firstly, we split the discontinuous align-
ment into several continuous alignment group-
s, and consider each continuous alignment group
as a bucket. Secondly, we vote for each buck-
et with alignment score measured by word trans-
lation probabilities. Finally, we select the buck-
et with the highest score as the final alignment.
The strength of our method is that we refine word
alignment without using any external knowledge,
as the word translation probabilities can be esti-
mated from the bilingual corpus with the original
word alignment.
We notice that the discontinuous alignment is
helpful for hierarchical phrase-based model, as the
model allows discontinuous phrases. Thus, for
the hierarchical phrase-based model, our method
may lost some discontinuous phrases. To solve
the problem, we keep the original discontinuous
alignment in the training corpus.
We carry out experiment with the state-of-the-
art phrase-based and hierarchical phrase-based
(Chiang, 2005) SMT systems implemented in
Moses (Koehn et al., 2007). Experiments on large
scale Chinese-to-English and German-to-English
translation tasks demonstrate significant improve-
ments in both cases over the baseline systems.
2 The Weighted Vote Method
To refine the discontinuous alignment, we propose
a weighted vote method to transform discontinu-
ous alignment to continuous alignment by discard-
ing noisy links. We split discontinuous alignment
1
The subscript denotes the word position.
into several continuous groups, and select the best
group with the highest score computed by word
translation probabilities as the final alignment.
For further understanding, we first describe
some definitions. Given a word-aligned sentence
pair (F
I
1
, E
J
1
, A), an alignment set A
set
(i) is the
set of target word positions that aligned to the
source word F
i
i
:
A
set
(i) = {j|(i, j) ? A} (1)
For example, in Figure 1, the alignment set
for the Chinese word ?shaoshu
3
? is A
set
(3) =
{5, 7, 8, 10}. We define an alignment s-
pan A
span
(i) as [min(A
set
(i)),max(A
set
(i))].
Thus, the alignment span for the Chinese word
?shaoshu
3
? is A
span
(3) = [5, 10].
The alignment for F
i
i
is discontinuous if there
exist some target words in A
span
(i) linking to an-
other source word, i.e. ?(i
?
, j
?
) ? A, where i
?
6= i,
j
?
? A
span
(i). Otherwise, the alignment is contin-
uous. According to the definition, the alignment
for ?shaoshu
3
? is discontinuous. Because the tar-
get words ?the
6
? and ?nations
9
? in the alignmen-
t span link to another Chinese words ?de
9
? and
?guojia
10
?, respectively. For a target word E
j
j
, the
definition is similar.
If the alignment for F
i
i
is discontinuous, we
can split the alignment span A
span
(i) = [j
1
, j
2
]
into m continuous spans {[j
k
p
, j
k
q
]}, where k =
1, 2, ...,m, and j
k
p
, j
k
q
? [j
1
, j
2
]. Our goal is to se-
lect the best continuous span for the word F
i
i
. To
do this, we score each continuous span with word
translation probabilities:
S([j
k
p
, j
k
q
]) =
q
?
t=p
(Pr(E
j
k
t
|F
i
) + Pr(F
i
|E
j
k
t
))
(2)
where,
Pr(f |e) =
count(f, e)
?
f
?
count(f
?
, e)
(3)
148
am
o
n
g
t
h
e
h
a
n
d
f
u
l
o
f
n
a
t
i
o
n
s
t
h
a
t
?? shaoshu 0.1 0.5 0.2 0.1
Figure 2: An example of weighted voted method
for selecting the best continuous alignment from
the discontinuous alignment. The heavy shading
area is selected as the final alignment.
Pr(e|f) =
count(e, f)
?
e
?
count(f, e
?
)
(4)
The word translation probabilities can be comput-
ed from the bilingual corpus with the initial word
alignment. Finally, we select the span with the
highest score as the final alignment, and discard
all other alignments.
We illustrate our method in Figure 2, which
shows the source word ?shaoshu? and its align-
ment in Figure 1. We split the alignments into
three continuous alignment spans and compute s-
core for each span. Finally, the span with highest
score (heavy shading area) is selected as the final
alignment.
We conduct the procedure for each source and
target word, the improved alignment (solid links)
is shown in Figure 1.
3 Experiment
To demonstrate the effect of the proposed method,
we use the state-of-the-art phrase-based system
and hierarchical phrase-based system implement-
ed in Moses (Koehn et al., 2007). The phrase-
based system uses continuous phrase pair as the
main translation knowledge. While the hierarchi-
cal phrase-based system uses both continuous and
discontinuous phrase pairs, which has an ability to
capture long distance phrase reordering.
we carried out experiments on two translation
tasks: the Chinese-to-English task comes from the
NIST Open MT Evaluation, and the German-to-
English task comes from the Workshop on Ma-
chine Translation (WMT) shared task.
3.1 Training
The training data we used are listed in Table 1. For
the Chinese-English task, the bilingual data are s-
elected from LDC. We used NIST MT03 as the
development set and tested our system on NIST
MT evaluation sets from 2004 to 2008. For the
German-English task, the bilingual data are from
Task Src. Words Tgt. Words
Chinese-to-English 75M 78M
German-to- English 107M 113M
Table 1: Bilingual data for our experiments.
System N04 N05 N06 N08
Baseline 34.53 33.02 30.43 23.29
Refined 36.21 33.99 31.59 24.36
Table 2: Chinese-to-English translation quality of
the phrase-based system.
System W10 W11 W12 W13
Baseline 20.71 20.26 20.52 23.26
Refined 21.46 20.95 21.11 23.77
Table 3: German-to-English translation quality of
the phrase-based system.
the shared translation task 2013. We used WMT08
as the development set and tested our system on
WMT test sets from 2010 to 2013.
The baseline systems are trained on the training
corpus with initial word alignment, which was ob-
tained via GIZA++ and ?grow-diag-final? method.
Based on the initial word alignment, we comput-
ed word translation probabilities and used the pro-
posed method to obtain a refined word alignment.
Then we used the refined word alignment to train
our SMT systems.
The translation results are evaluated by case-
insensitive BLEU-4 (Papineni et al., 2002).
The feature weights of the translation system
are tuned with the standard minimum-error-rate-
training (Och, 2003) to maximize the systems
BLEU score on the development set.
3.2 Results
3.2.1 Phrase-based System
Table 2 shows Chinese-to-English translation
quality of the phrase-based system. We ob-
served that our refined method significantly out-
performed the baseline word alignment on all test
sets. The improvements are ranged from 0.97 to
1.68 BLEU%.
Table 3 shows German-to-English translation
quality of the phrase-based system. The improve-
ments are ranged from 0.51 to 0.75 BLEU%.
These results demonstrate that the proposed
method improves the translation quality for
149
System N04 N05 N06 N08
Baseline 37.33 34.81 32.20 25.33
Refined 37.91 35.36 32.75 25.40
Combined 38.13 35.63 33.48 25.66
Table 4: Chinese-to-English translation quality of
the hierarchical phrase-based system.
System W10 W11 W12 W13
Baseline 21.22 19.77 20.53 23.51
Refined 21.34 20.64 20.88 23.82
Combined 21.65 20.87 21.16 24.04
Table 5: German-to-English translation quality of
the hierarchical phrase-based system.
phrase-based system. The reason is that by dis-
carding noisy word alignments from the discon-
tinuous alignments, the phrase pairs constrained
by the noisy alignments can be extracted. Thus the
system utilized more phrase pairs than the baseline
did.
3.2.2 Hierarchical Phrase-based System
The hierarchical phrase-based system utilizes dis-
continuous phrase pairs for long distance phrase
reordering. Some of the discontinuous phrase
pairs are extracted from the discontinuous align-
ments. By transforming the discontinuous align-
ments to continuous alignments, on the one hand,
we may lost some discontinuous phrase pairs. On
the other hand, we may extract additional contin-
uous and discontinuous phrase pairs as the align-
ment restriction is loose.
See Figure 3 for illustration. From the initial
alignment, we can extract a hierarchical phrase
pair ?(dang X
1
shi, when X
1
)? from the discon-
tinuous alignment of the English word ?when?.
However, the hierarchical phrase pair cannot be
extracted from our refined alignment, because our
method discards the link between the Chinese
word ?dang? and the English word ?when?. In-
stead, we can extract another hierarchical phrase
pair ?(X
1
shi, when X
1
)?.
Does our method still obtain improvements on
the hierarchical phrase-based system? Table 4 and
Table 5 shows Chinese-to-English and German-
to-English translation quality of the hierarchical
phrase-based system, respectively. For Chinese-
to-English translation, the refined alignment ob-
tained improvements ranged from 0.07 to 0.58

dang
?
shigu
u)
fasheng
?
shi
when the accident
happend
Figure 3: Example of word alignment between a
Chinese and English sentence pair. The dashed
initial link is discarded by our method.
BLEU% on the test set ( the row ?Refined?).
While for German-to-English translation, the im-
provements ranged from 0.12 to 0.59 BLEU% on
the test set (the row ?Refined?).
We find that the improvements are less than
that of the phrase-based system. As discussed
above, our method may lost some hierarchical
phrase pairs that extracted from the discontinuous
alignments. To solve the problem, we combine
2
the initial alignments and the refined alignments
to train the SMT system. The results are shown
in the row ?Combined? in Table 4 and Table 5.
For Chinese-to-English translation, we obtained
an improvements of 1.28 BLEU% on NIST06 over
the baseline. While for German-to-English trans-
lation, the greatest improvements is 1.10 BLEU%
on WMT11.
4 Analyses
In order to further study the performance of the
proposed method, we analyze the word alignment
and the phrase table for Chinese-to-English trans-
lation. We find that our method improves the qual-
ity of word alignment. And as a result, more useful
phrase pairs are extracted from the refined word
alignment.
4.1 Word Alignment
The Chinese-to-English training corpus contains
4.5M sentence pairs. By applying GIZA++ and
the ?grow-diag-final? method, we obtained initial
alignments. We find that 4.0M (accounting for
89%) sentence pairs contain discontinuous align-
ments. We then used the proposed method to dis-
card noisy links. By doing this, the total links
between words in the training corpus are reduced
from 99.6M to 78.9M, indicating that 21% links
are discarded.
2
We do not perform combination for phrase-based sys-
tem, because the phrase table extracted from the initial align-
ment is a subset of that extracted from the refined alignment.
150
Alignment Precision Recall AER
Initial 62.94 89.55 26.07
Refined 73.43 87.82 20.01
Table 6: Precision, Recall and AER on Chinese-
to-English alignment.
Alignment StandPhr HierPhr
Initial 29M 86M
Refined 104M 436M
Table 7: The phrase number extracted from the
initial and refined alignment for the hierarchical
phrase-based system on Chinese-to-English trans-
lation. StandPhr is standard phrase, HierPhr is hi-
erarchical phrase.
We evaluated the alignment quality on 200 sen-
tence pairs. Results are shown in Table 6. It is
observed that our method improves the precision
and decreases the AER, while keeping a high re-
call. This means that our method effectively dis-
cards noisy links in the initial word alignments.
4.2 Phrase Table
According to the standard definition of phrase in
SMT, phrase pairs cannot be extracted from the
discontinuous alignments. By transforming dis-
continuous alignments into continuous alignmen-
t, we can extract more phrase pairs. Table 7
shows the number of standard phrases and hier-
archical phrases extracted from the initial and re-
fined word alignments. We find that the number of
both phrases and hierarchical phrases grows heav-
ily. This is because that the word alignment con-
straint for phrase extraction is loosed by removing
noisy links. Although the phrase table becomes
larger, fortunately, there are some methods (John-
son et al., 2007; He et al., 2009) to prune phrase
table without hurting translation quality.
For further illustration, we compare the phrase
pairs extracted from the initial alignment and re-
fined alignment in Figure 1. From the initial align-
ments, we extracted only 3 standard phrase pairs
and no hierarchical phrase pairs (Table 8). After
discarding noisy alignments (dashed links) by us-
ing the proposed method, we extracted 21 standard
phrase pairs and 36 hierarchical phrases. Table 9
and Table 10 show selected phrase pairs and hier-
archical phrase pairs, respectively.
Chinese English
meiguo The United States
guojia nations
piao note
Table 8: Phrase pairs extracted from the initial
alignment of Figure 1.
Chinese English
shi was
fandui piao a nay note
shaoshu jige the handful of
Table 9: Selected phrase pairs extracted from the
refined alignment of Figure 1.
Chinese English
X
1
zhiyi among X
1
X
1
de guojia nations that X
1
X
1
fandui piao X
2
X
2
X
1
a nay note
Table 10: Selected hierarchical phrase pairs ex-
tracted from the refined alignment of Figure 1.
5 Conclusion and Future Work
In this paper, we proposed a novel method to im-
prove word alignment for SMT. The method re-
fines initial word alignments by transforming dis-
continuous alignment to continuous alignment. As
a result, more useful phrase pairs are extracted
from the refined word alignment. Our method is
simple and efficient, since it uses only the word
translation probabilities obtained from the initial
alignments to discard noisy links. Our method
is independent of languages and can be applied
to most SMT models. Experimental results show
significantly improvements for the state-of-the-art
phrase-based and hierarchical phrase-based sys-
tems on all Chinese-to-English and German-to-
English translation tasks.
In the future, we will refine the method by con-
sidering neighbor words and alignments when dis-
carding noisy links.
Acknowlegement
This paper is supported by the 973 program No.
2014CB340505. We would like to thank Xuan Liu
and the anonymous reviewers for their insightful
comments.
151
References
Peter F. Brown, Stephen A. Della Pietra, Vincen-
t J. Della Pietra, and Robert L. Mercer. 1993.
The mathematics of statistical machine translation:
Parameter estimation. Computational Linguistics,
19(2):263?311.
David Chiang. 2005. A hierarchical phrase-based
model for statistical machine translation. In Pro-
ceedings of the 43rd Annual Meeting of the Associa-
tion for Computational Linguistics, pages 263?270.
Zhongjun He, Yao Meng, and Hao Yu. 2009. Dis-
carding monotone composed rule for hierarchical
phrase-based statistical machine translation. In Pro-
ceedings of the 3rd International Universal Commu-
nication Symposium, pages 25?29.
Liang Huang, Kevin Knight, and Aravind Joshi. 2006.
Statistical syntax-directed translation with extended
domain of locality. In Proceedings of the 7th Bienni-
al Conference of the Association for Machine Trans-
lation in the Americas.
Howard Johnson, Joel Martin, George Foster, and
Roland Kuhn. 2007. Improving translation quali-
ty by discarding most of the phrasetable. In Pro-
ceedings of the 2007 Joint Conference on Empirical
Methods in Natural Language Processing and Com-
putational Natural Language Learning (EMNLP-
CoNLL), pages 967?975, Prague, Czech Republic,
June.
Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003.
Statistical phrase-based translation. In Proceedings
of HLT-NAACL 2003, pages 127?133.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertol-
di, Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
source toolkit for statistical machine translation. In
ACL 2007 demonstration session.
Yang Liu, Qun Liu, and Shouxun Lin. 2005. Loglin-
ear models for word alignment. In Proceedings of
of ACL 2005, pages 459?466, Ann Arbor,Michigan,
June.
Yang Liu, Qun Liu, and Shouxun Lin. 2006. Tree-
to-string alignment template for statistical machine
translation. In Proceedings of the 44th Annual Meet-
ing of the Association for Computational Linguistic-
s, pages 609?616.
Robert C. Moore, Wen tau Yih, and Andreas Bode.
2006. Improved discriminative bilingual word
alignment. In In Proceedings of COLING/ACL
2006, pages 513?520, Sydney, Australia, July.
Franz Josef Och and Hermann Ney. 2004. The align-
ment template approach to statistical machine trans-
lation. 30:417?449.
Franz Josef Och. 2003. Minimum error rate training
in statistical machine translation. In Proceedings of
the 41st Annual Meeting of the Association for Com-
putational Linguistics, pages 160?167.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a method for automatic eval-
uation of machine translation. In Proceedings of the
40th Annual Meeting of the Association for Compu-
tational Linguistics, pages 311?318.
Jason Riesa and Daniel Marcu. 2010. Hierarchical
search forword alignment. In In Proceedings of the
48th Annual Meeting of the Association for Compu-
tational Linguistics, pages 157?166, Uppsala, Swe-
den, July.
Stephan Vogel and Hermann Ney. 1996. Hmm-based
word alignment in statistical translation. In Pro-
ceedings of COLING 1996, pages 836?841, Copen-
hagen, Danmark, August.
152
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1665?1675,
October 25-29, 2014, Doha, Qatar. c?2014 Association for Computational Linguistics
Improving Pivot-Based Statistical Machine Translation by Pivoting 
the Co-occurrence Count of Phrase Pairs 
 
Xiaoning Zhu1*, Zhongjun He2, Hua Wu2, Conghui Zhu1,  
Haifeng Wang2, and Tiejun Zhao1 
Harbin Institute of Technology, Harbin, China1 
{xnzhu,chzhu,tjzhao}@mtlab.hit.edu.cn 
Baidu Inc., Beijing, China2 
{hezhongjun,wu_hua,wanghaifeng}@baidu.com 
 
 
                                                 
* This work was done when the first author was visiting Baidu. 
Abstract 
To overcome the scarceness of bilingual 
corpora for some language pairs in ma-
chine translation, pivot-based SMT uses 
pivot language as a "bridge" to generate 
source-target translation from source-
pivot and pivot-target translation. One of 
the key issues is to estimate the probabili-
ties for the generated phrase pairs. In this 
paper, we present a novel approach to 
calculate the translation probability by 
pivoting the co-occurrence count of 
source-pivot and pivot-target phrase pairs. 
Experimental results on Europarl data 
and web data show that our method leads 
to significant improvements over the 
baseline systems. 
1 Introduction 
Statistical Machine Translation (SMT) relies on 
large bilingual parallel data to produce high qual-
ity translation results. Unfortunately, for some 
language pairs, large bilingual corpora are not 
readily available. To alleviate the parallel data 
scarceness, a conventional solution is to intro-
duce a ?bridge? language (named pivot language) 
to connect the source and target language (de 
Gispert and Marino, 2006; Utiyama and Isahara, 
2007; Wu and Wang, 2007; Bertoldi et al., 2008; 
Paul et al., 2011; El Kholy et al., 2013; Zahabi et 
al., 2013), where there are large amounts of 
source-pivot and pivot-target parallel corpora. 
Among various pivot-based approaches, the 
triangulation method (Cohn and Lapata, 2007; 
Wu and Wang, 2007) is a representative work in 
pivot-based machine translation. The approach 
proposes to build a source-target phrase table by 
merging the source-pivot and pivot-target phrase 
table. One of the key issues in this method is to 
estimate the translation probabilities for the gen-
erated source-target phrase pairs. Conventionally, 
the probabilities are estimated by multiplying the 
posterior probabilities of source-pivot and pivot-
target phrase pairs. However, it has been shown 
that the generated probabilities are not accurate 
enough (Cui et al., 2013). One possible reason 
may lie in the non-uniformity of the probability 
space. Through Figure 1. (a), we can see that the 
probability distributions of source-pivot and piv-
ot-target language are calculated separately, and 
the source-target probability distributions are 
induced from the source-pivot and pivot-target 
probability distributions. Because of the absence 
of the pivot language (e.g., p2 is in source-pivot 
probability space but not in pivot-target one), the 
induced source-target probability distribution is 
not complete, which will result in inaccurate 
probabilities.  
To solve this problem, we propose a novel ap-
proach that utilizes the co-occurrence count of 
source-target phrase pairs to estimate phrase 
translation probabilities more precisely. Different 
from the triangulation method, which merges the 
source-pivot and pivot-target phrase pairs after 
training the translation model, we propose to 
merge the source-pivot and pivot-target phrase 
pairs immediately after the phrase extraction step, 
and estimate the co-occurrence count of the 
source-pivot-target phrase pairs. Finally, we 
compute the translation probabilities according 
to the estimated co-occurrence counts, using the 
standard training method in phrase-based SMT 
(Koehn et al., 2003). As Figure 1. (b) shows, the 
1665
source-target probability distributions are calcu-
lated in a complete probability space. Thus, it 
will be more accurate than the traditional trian-
gulation method. Figure 2. (a) and (b) show the 
difference between the triangulation method and 
our co-occurrence count method. 
Furthermore, it is common that a small stand-
ard bilingual corpus can be available between the 
source and target language. The direct translation 
model trained with the standard bilingual corpus 
exceeds in translation performance, but its weak-
ness lies in low phrase coverage. However, the 
pivot model has characteristics characters. Thus, 
it is important to combine the direct and pivot 
translation model to compensate mutually and 
further improve the translation performance. To 
deal with this problem, we propose a mixed 
model by merging the phrase pairs extracted by 
pivot-based method and the phrase pairs extract-
ed from the standard bilingual corpus. Note that, 
this is different from the conventional interpola-
tion method, which interpolates the direct and 
pivot translation model. See Figure 2. (b) and (c) 
for further illustration. 
(a) the triangulation method                         (b) the co-occurrence count method 
 
Figure 1: An example of probability space evolution in pivot translation. 
 
 
Large SP 
corpus
Large PT 
corpus
SP phrase 
pairs
PT phrase 
pairs
SP model PT model
ST pivot 
model
Phrase Extraction Phrase Extraction
Train Train
Merge
Standard 
ST corpus
ST phrase 
pairs
ST direct 
model
Phrase Extraction
Train
Interpolate
ST interpolated 
model
Large SP 
corpus
Large PT 
corpus
SP phrase 
pairs
ST pivot 
model
ST phrase 
pairs
Phrase Extraction Phrase Extraction
Train
PT phrase 
pairs
Merge
Standard 
ST corpus
ST phrase 
pairs
ST direct 
model
Phrase Extraction
Train
Interpolate
ST interpolated 
model
Large SP 
corpus
Large PT 
corpus
SP phrase 
pairs
PT phrase 
pairs
ST mixed 
pairs
ST phrase 
pairs
Phrase Extraction Phrase Extraction
Merge
Standard 
ST corpus
ST phrase 
pairs
Phrase Extraction
Train
ST mixed 
model
Mix
        (a) the triangulation method        (b) the co-occurrence count method            (c) the mixed model 
 
Figure 2: Framework of the triangulation method, the co-occurrence count method and the mixed 
model. The shaded box in (b) denotes difference between the co-occurrence count method and the 
triangulation method. The shaded box in (c) denotes the difference between the interpolation model 
and the mixed model. 
1666
The remainder of this paper is organized as 
follows. In Section 2, we describe the related 
work. We introduce the co-occurrence count 
method in Section 3, and the mixed model in 
Section 4. In Section 5 and Section 6, we de-
scribe and analyze the experiments. Section 7 
gives a conclusion of the paper. 
2 Related Work 
Several methods have been proposed for pivot-
based translation. Typically, they can be classi-
fied into 3 kinds as follows: 
Transfer Method: The transfer method 
(Utiyama and Isahara, 2007; Wang et al., 2008; 
Costa-juss? et al., 2011) connects two translation 
systems: a source-pivot MT system and a pivot-
target MT system. Given a source sentence, (1) 
the source-pivot MT system translates it into the 
pivot language, (2) and the pivot-target MT sys-
tem translates the pivot sentence into the target 
sentence. During each step (source to pivot and 
pivot to target), multiple translation outputs will 
be generated, thus a minimum Bayes-risk system 
combination method is often used to select the 
optimal sentence (Gonz?lez-Rubio et al., 2011; 
Duh et al., 2011). The problem with the transfer 
method is that it needs to decode twice. On one 
hand, the time cost is doubled; on the other hand, 
the translation error of the source-pivot transla-
tion system will be transferred to the pivot-target 
translation. 
Synthetic Method: It aims to create a synthet-
ic source-target corpus by: (1) translate the pivot 
part in source-pivot corpus into target language 
with a pivot-target model; (2) translate the pivot 
part in pivot-target corpus into source language 
with a pivot-source model; (3) combine the 
source sentences with translated target sentences 
or/and combine the target sentences with trans-
lated source sentences (Utiyama et al., 2008; Wu 
and Wang, 2009). However, it is difficult to 
build a high quality translation system with a 
corpus created by a machine translation system. 
Triangulation Method: The triangulation 
method obtains source-target phrase table by 
merging source-pivot and pivot-target phrase 
table entries with identical pivot language 
phrases and multiplying corresponding posterior 
probabilities (Wu and Wang, 2007; Cohn and 
Lapata, 2007), which has been shown to work 
better than the other pivot approaches (Utiyama 
and Isahara, 2007). A problem of this approach is 
that the probability space of the source-target 
phrase pairs is non-uniformity due to the mis-
matching of the pivot phrase.  
3 Our Approach 
In this section, we will introduce our method for 
learning a source-target phrase translation model 
with a pivot language as a bridge. We extract the 
co-occurrence count of phrase pairs for each lan-
guage pair with a source-pivot and a pivot-target 
corpus. Then we generate the source-target 
phrase pairs with induced co-occurrence infor-
mation. Finally, we compute translation proba-
bilities using the standard phrase-based SMT 
training method. 
3.1 Phrase Translation Probabilities 
Following the standard phrase extraction method 
(Koehn et al., 2003), we can extract phrase pairs 
???, ???  and ???, ???  from the corresponding word-
aligned source-pivot and pivot-target training 
corpus, where ?? , ??  and ??  denotes the phrase in 
source, pivot and target language respectively. 
Formally, given the co-occurrence count 
????, ??? and ????, ???, we can estimate  ????, ???  by 
Equation 1: 
????, ??? ? ???????, ???, ????, ????
??
 (1) 
where ????  is a function to merge the co-
occurrences count ????, ???  and ????, ??? . We pro-
pose four calculation methods for function ????. 
Given the co-occurrence count ????, ???  and 
????, ???, we first need to induce the co-occurrence 
count ????, ?,? ??? . The ????, ?,? ???  is counted when 
the source phrase, pivot phrase and target phrase 
occurred together, thus we can infer that 
????, ?,? ???  is smaller than ????, ???  and ????, ??? . In 
this circumstance, we consider that ????, ?,? ???  is 
approximately equal to the minimum value of 
????, ??? and ????, ???, as shown in Equation 2. 
????, ??, ??? ? ?min?????, ???, ????, ????
??
 (2) 
Because the co-occurrence count of source-
target phrase pairs needs the existence of pivot 
phrase ?? , we intuitively believe that the co-
occurrence count ????, ???  is equal to the co-
occurrence count ????, ?,? ???. Under this assump-
tion, we can obtain the co-occurrence count 
????, ??? as shown in Equation 3. Furthermore, to 
testify our assumption, we also try the maximum 
value (Equation 4) to infer the co-occurrence 
count of ???, ???  phrase pair. 
1667
????, ??? ? ?min?????, ???, ????, ????
??
 (3) 
????, ??? ? ?max?????, ???, ????, ????
??
 (4) 
In addition, if source-pivot and pivot-target 
parallel corpus greatly differ in quantities, then 
the minimum function would likely just take the 
counts from the smaller corpus. To deal with the 
problem of the imbalance of the parallel corpora, 
we also try the arithmetic mean (Equation 5) and 
geometric mean (Equation 6) function to infer 
the co-occurrence count of source-target phrase 
pairs. 
????, ??? ? ??????, ??? ? ????, ????/2
??
 (5) 
????, ??? ? ??????, ??? ? ????, ???
??
 (6) 
When the co-occurrence count of source-target 
language is calculated, we can estimate the 
phrase translation probabilities with the follow-
ing Equation 7 and Equation 8. 
?????|?? ? ????, ???? ????, ?????  (7) 
????|??? ? ????, ???? ????, ?????  (8) 
3.2 Lexical Weight 
Given a phrase pair ???, ??? and a word alignment 
a between the source word positions ? ? 1,? , ? 
and the target word positions ? ? 0,? ,? , the 
lexical weight of phrase pair ???, ??? can be calcu-
lated by the following Equation 9 (Koehn et al., 
2003). 
??????|?, ?? ??
1
|??|??, ?? ? ??| ? ????|??????,????
?
???
(9) 
The lexical translation probability distribution 
???|?? between source word s and target word t 
can be estimated with Equation 10. 
???|?? ? ???, ??? ????, ????  (10)
To compute the lexical weight for a phrase 
pair ???, ??? generated by ???, ??? and ???, ???, we need 
the alignment information ?, which can be ob-
tained as Equation 11 shows. 
? ? ???, ??|??: ??, ?? ? ??&??, ?? ? ??? (11)
where ??  and ??  indicate the word alignment 
information in the phrase pair ???, ???  and ???, ??? 
respectively. 
4 Integrate with Direct Translation 
If a standard source-target bilingual corpus is 
available, we can train a direct translation model. 
Thus we can integrate the direct model and the 
pivot model to obtain further improvements. We 
propose a mixed model by merging the co-
occurrence count in direct translation and pivot 
translation. Besides, we also employ an interpo-
lated model (Wu and Wang, 2007) by merging 
the direct translation model and pivot translation 
model using a linear interpolation. 
4.1 Mixed Model 
Given ?  pivot languages, the co-occurrence 
count can be estimated using the method de-
scribed in Section 3.1. Then the co-occurrence 
count and the lexical weight of the mixed model 
can be estimated with the following Equation 12 
and 13. 
???, ?? ??????, ??
?
???
 (12)
??????|?, ?? ????
?
???
??,?????|?, ?? (13)
where ????, ??  and ??,?????|?, ??  are the co-
occurrence count and lexical weight in the direct 
translation model respectively. ????, ??  and 
??,?????|?, ?? denote the co-occurrence count and 
lexical weight in the pivot translation model. ?? 
is the interpolation coefficient, requiring 
? ?????? ? 1. 
4.2 Interpolated Model 
Following Wu and Wang (2007), the interpolated 
model can be modelled with Equation 14. 
?????|?? ? ?????????|??
?
???
 (14)
where ??????|?? is the phrase translation probabil-
ity in direct translation model; ??????|??  is the 
phrase translation probability in pivot translation 
model. The lexical weight is obtained with Equa-
tion 13. ?? is the interpolation coefficient, requir-
ing ? ?? ? 1???? . 
1668
5 Experiments on Europarl Corpus 
Our first experiment is carried out on Europarl1 
corpus, which is a multi-lingual corpus including 
21 European languages (Koehn, 2005). In our 
work, we perform translations among French (fr), 
German (de) and Spanish (es). Due to the rich-
ness of available language resources, we choose 
English (en) as the pivot language. Table 1 
summarized the statistics of training data. For the 
language model, the same monolingual data ex-
tracted from the Europarl are used. 
The word alignment is obtained by GIZA++ 
(Och and Ney, 2000) and the heuristics ?grow-
diag-final? refinement rule (Koehn et al., 2003). 
Our translation system is an in-house phrase-
based system analogous to Moses (Koehn et al., 
2007). The baseline system is the triangulation 
method (Wu and Wang, 2007), including an in-
terpolated model which linearly interpolate the 
direct and pivot translation model. 
                                                 
1 http://www.statmt.org/europarl 
We use WMT082  as our test data, which con-
tains 2000 in-domain sentences and 2051 out-of-
domain sentences with single reference. The 
translation results are evaluated by case-
insensitive BLEU-4 metric (Papineni et al., 
2002). The statistical significance tests using 
95% confidence interval are measured with 
paired bootstrap resampling (Koehn, 2004). 
5.1 Results 
We compare 4 merging methods with the base-
line system. The results are shown in Table 2 and 
Table 3. We find that the minimum method out-
performs the others, achieving significant im-
provements over the baseline on all translation 
directions. The absolute improvements range 
from 0.61 (fr-de) to 1.54 (es-fr) in BLEU% score 
on in-domain test data, and range from 0.36 (fr-
de) to 2.05 (fr-es) in BLEU% score on out-of-
domain test data. This indicates that our method 
is effective and robust in general. 
                                                 
2 http://www.statmt.org/wmt08/shared-task.html 
Language 
Pairs 
Sentence 
Pairs 
Source 
Words
Target 
Words
de-en 1.9M 48.5M 50.9M
es-en 1.9M 54M 51.7M
fr-en 2M 58.1M 52.4M
 
Table 1: Training data of Europarl corpus 
 
System 
BLEU% 
de-es de-fr es-de es-fr fr-de fr-es 
Baseline 27.04 23.01 20.65 33.84 20.87 38.31 
Minimum 27.93* 23.94* 21.52* 35.38* 21.48* 39.62* 
Maximum 25.70 21.59 20.26 32.58 20.50 37.30 
Arithmetic mean 26.01 22.24 20.13 33.38 20.37 37.37 
Geometric mean 27.31 23.49* 21.10* 34.76* 21.15* 39.19* 
 
Table 2: Comparison of different merging methods on in-domain test set. * indicates the results are 
significantly better than the baseline (p<0.05). 
 
System 
BLEU% 
de-es de-fr es-de es-fr fr-de fr-es 
Baseline 15.34 13.52 11.47 21.99 12.19 25.00 
Minimum 15.77* 14.08* 11.99* 23.90* 12.55* 27.05* 
Maximum 13.41 11.83 10.17 20.48 10.83 22.75 
Arithmetic mean 13.96 12.10 10.57 21.07 11.30 23.70 
Geometric mean 15.09 13.30 11.52 23.32* 12.46* 26.22* 
 
Table 3: Comparison of different merging methods on out-of-domain test set. 
 
1669
The geometric mean method also achieves im-
provement, but not as significant as the minimum 
method. However, the maximum and the arith-
metic mean methods show a decrement in BLEU 
scores. This reminds us that how to choose a 
proper merging function for the co-occurrence 
count is a key problem.  In the future, we will 
explore more sophisticated method to merge co-
occurrence count. 
5.2 Analysis 
The pivot-based translation is suitable for the 
scenario that there exists large amount of source-
pivot and pivot-target bilingual corpora and only 
a little source-target bilingual data. Thus, we 
randomly select 10K, 50K, 100K, 200K, 500K, 
1M, 1.5M sentence pairs from the source-target 
bilingual corpora to simulate the lack of source-
target data. With these corpora, we train several 
direct translation models with different scales of 
bilingual data. We interpolate each direct transla-
tion model with the pivot model (both triangula-
tion method and co-occurrence count method) to 
obtain the interpolated model respectively. We 
also mix the direct model and pivot model using 
the method described in Section 4.1.  Following 
 
(a) German-English-Spanish                                        (b) German-English-French 
 
 
(c) Spanish-English-German                                        (d) Spanish-English-French 
 
 
(e) French-English-German                                         (f) French-English-Spanish 
 
Figure 3: Comparisons of pivot-based methods on different scales of source-target standard corpora. 
(direct: direct model; tri: triangulation model; co: co-occurrence count model; tri+inter: triangulation 
model interpolated with direct model ; co+inter: co-occurrence count model interpolated with direct 
model; co+mix: mixed model). X-axis represents the scale of the standard training data. 
22.5
23
23.5
24
24.5
25
25.5
BL
EU
%
direct
tri
co
tri+inter
co+inter
co+mix
26.5
27
27.5
28
28.5
29
29.5
BL
EU
%
direct
tri
co
tri+inter
co+inter
co+mix
33.5
34
34.5
35
35.5
36
36.5
37
BL
EU
%
direct
tri
co
tri+inter
co+inter
co+mix
19.5
20
20.5
21
21.5
22
22.5
BL
EU
%
direct
tri
co
tri+inter
co+inter
co+mix
37.5
38
38.5
39
39.5
40
40.5
41
BL
EU
%
direct
tri
co
tri+inter
co+inter
co+mix
19.5
20
20.5
21
21.5
22
22.5
BL
EU
%
direct
tri
co
tri+inter
co+inter
co+mix
1670
Wu and Wang (2007), we set ?? ? 0.9, ?? ? 0.1, 
?? ? 0.9  and ?? ? 0.1  empirically. The experi-
ments are carried out on 6 translation directions: 
German-Spanish, German-French, Spanish-
German, Spanish-French, French-German and 
French-Spanish. The results are shown in Figure 
3. We only list the results on in-domain test sets. 
The trend of the results on out-of domain test 
sets is similar with in-domain test sets. 
The results are explained as follows: 
(1) Comparison of Pivot Translation and Di-
rect Translation 
The pivot translation models are better than 
the direct translation models trained on a small 
source-target bilingual corpus. With the incre-
ment of source-target corpus, the direct model 
first outperforms the triangulation model and 
then outperforms the co-occurrence count model 
consecutively. 
Taking Spanish-English-French translation as 
an example, the co-occurrence count model 
achieves BLEU% scores of 35.38, which is close 
to the direct translation model trained with 200K 
source-target bilingual data. Compared with the 
co-occurrence count model, the triangulation 
model only achieves BLEU% scores of 33.84, 
which is close to the direct translation model 
trained with 50K source-target bilingual data. 
(2) Comparison of Different Interpolated 
Models 
For the pivot model trained by triangulation 
method and co-occurrence count method, we 
interpolate them with the direct translation model 
trained with different scales of bilingual data. 
Figure 3 shows the translation results of the dif-
ferent interpolated models. For all the translation 
directions, our co-occurrence count method in-
terpolated with the direct model is better than the 
triangulation model interpolated with the direct 
model.  
The two interpolated model are all better than 
the direct translation model. With the increment 
of the source-target training corpus, the gap be-
comes smaller. This indicates that the pivot mod-
el and its affiliated interpolated model are suita-
ble for language pairs with small bilingual data. 
Even if the scale of source-pivot and pivot-target 
corpora is close to the scale of source-target bi-
lingual corpora, the pivot translation model can 
help the direct translation model to improve the 
translation performance. Take Spanish-English-
French translation as an issue, when the scale of 
Spanish-French parallel data is 1.5M sentences 
pairs, which is close to the Spanish-English and 
English-French parallel data, the performance of 
co+mix model is still outperforms the direct 
translation model. 
(3) Comparison of Interpolated Model and 
Mixed Model 
When only a small source-target bilingual 
corpus is available, the mix model outperforms 
the interpolated model. With the increasing of 
source-target corpus, the mix model is close to 
the interpolated model or worse than the interpo-
lated model. This indicates that the mix model 
has a better performance when the source-target 
corpus is small which is close to the realistic sce-
nario. 
5.3 Integrate the Co-occurrence Count 
Model and Triangulation Model 
Experimental results in the previous section 
show that, our co-occurrence count models gen-
erally outperform the baseline system. In this 
section, we carry out experiments that integrates 
co-occurrence count model into the triangulation 
model. 
For French-English-German translation, we 
apply a linear interpolation method to integrate 
the co-occurrence count model into triangulation 
model following the method described in Section 
4.2.  We set ? as the interpolation coefficient of 
triangulation model and 1 ? ? as the interpola-
tion coefficient of co-occurrence count model 
respectively. The experiments take 9 values for 
interpolation coefficient, from 0.1 to 0.9. The 
results are shown in Figure 4. 
 
 
Figure 4: Results of integrating the co-
occurrence count model and the triangulation 
model. 
 
When using interpolation coefficient ranging 
from 0.2 to 0.7, the integrated models outperform 
the triangulation and the co-occurrence count 
model. However, for the other intervals, the inte-
20.4
20.6
20.8
21
21.2
21.4
21.6
21.8
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
BL
EU
%
Interpolation Coefficient 
integrated triangulation
co-occurrence
1671
grated models perform slightly lower than the 
co-occurrence count model, but still show better 
results than the triangulation model. The trend of 
the curve infers that the integrated model synthe-
sizes the contributions of co-occurrence count 
model and triangulation model. Additionally, it 
also indicates that, the choice of the interpolation 
coefficient affects the translation performances. 
6 Experiments on Web Data 
The experimental on Europarl is artificial, as the 
training data for directly translating between 
source and target language actually exists in the 
original data sets. Thus, we conducted several 
experiments on a more realistic scenario: trans-
lating Chinese (zh) to Japanese (jp) via English 
(en) with web crawled data. 
As mentioned in Section 3.1, the source-pivot 
and pivot-target parallel corpora can be imbal-
anced in quantities. If one parallel corpus was 
much larger than another, then minimum heuris-
tic function would likely just take the counts 
from the smaller corpus.  
In order to analyze this issue, we manually set 
up imbalanced corpora. For source-pivot parallel 
corpora, we randomly select 1M, 2M, 3M, 4M 
and 5M Chinese-English sentence pairs. On the 
other hand, we randomly select 1M English-
Japanese sentence pairs as pivot-target parallel 
corpora. The training data of Chinese-English 
and English-Japanese language pairs are summa-
rized in Table 4. For the Chinese-Japanese direct 
corpus, we randomly select 5K, 10K, 20K, 30K, 
40K, 50K, 60K, 70K, 80K, 90K and 100K sen-
tence pairs to simulate the lack of bilingual data. 
We built a 1K in-house test set with four refer-
ences. For Japanese language model training, we 
used the monolingual part of English-Japanese 
corpus. 
Table 5 shows the results of different co-
occurrence count merging methods. First, the 
minimum method and the geometric mean meth-
od outperform the other two merging methods 
and the baseline system with different training 
corpus. When the scale of source-pivot and piv-
ot-target corpus is roughly balanced (zh-en-jp-1), 
the minimum method achieves an absolute im-
provement of 2.06 percentages points on BLEU 
over the baseline, which is also better than the 
other merging methods. While, with the growth 
of source-pivot corpus, the gap between source-
pivot corpus and pivot-target corpus becomes 
bigger. In this circumstance, the geometric mean 
method becomes better than the minimum meth-
od. Compared to the minimum method, the geo-
metric mean method considers both the source-
pivot and the pivot-target corpus, which may 
lead to a better result in the case of imbalanced 
training corpus. 
Language 
Pairs 
Sentence 
Pairs 
Source 
Words
Target 
Words
zh-en-1 1M 18.1M 17.7M
zh-en-2 2M 36.2M 35.5M
zh-en-3 3M 54.2M 53.2M
zh-en-4 4M 72.3M 70.9M
zh-en-5 5M 90.4M 88.6M
en-jp 1M 9.2M 11.1M
 
Table 4: Training data of web corpus 
 
System 
BLEU% 
zh-en-jp-1* zh-en-jp-2 zh-en-jp-3 zh-en-jp-4 zh-en-jp-5
Baseline 29.07 29.39 29.44 29.67 29.80 
Minimum 31.13* 31.28* 31.43* 31.62* 32.02* 
Maximum 28.88 29.01 29.12 29.37 29.59 
Arithmetic mean 29.08 29.36 29.51 29.79 30.01 
Geometric mean 30.77* 31.30* 31.75* 32.07* 32.34* 
 
Table 5: Comparison of different merging methods on the imbalanced web data. ( zh-en-jp-1 means 
the translation system is trained with zh-en-1 as source-pivot corpus and en-jp as pivot-target corpus, 
and so on. ) 
1672
Furthermore, with the imbalanced corpus zh-
en-jp-5, we compared the translation perfor-
mance of our co-occurrence count model (with 
geometric mean merging method), triangulation 
model, interpolated model, mixed model and the 
direct translation models. Figure 5 summarized 
the results. 
The co-occurrence count model can achieve an 
absolute improvement of 2.54 percentages points 
on BLEU over the baseline. The triangulation 
method outperforms the direct translation when 
only 5K sentence pairs are available. Meanwhile, 
the number is 10K when using the co-occurrence 
count method. The co-occurrence count models 
interpolated with the direct model significantly 
outperform the other models. 
 
 
Figure 5: Results on Chinese-Japanese Web Data. 
X-axis represents the scale of the standard train-
ing data. 
 
In this experiment, the training data contains 
parallel sentences on various domains. And the 
training corpora (Chinese-English and English-
Japanese) are typically very different, since they 
are obtained on the web. It indicates that our co-
occurrence count method is robust in the realistic 
scenario. 
7 Conclusion 
This paper proposed a novel approach for pivot-
based SMT by pivoting the co-occurrence count 
of phrase pairs. Different from the triangulation 
method merging the source-pivot and pivot-
target language after training the translation 
model, our method merges the source-pivot and 
pivot-target language after extracting the phrase 
pairs, thus the computing for phrase translation 
probabilities is under the uniform probability 
space. The experimental results on Europarl data 
and web data show significant improvements 
over the baseline systems. We also proposed a 
mixed model to combine the direct translation 
and pivot translation, and the experimental re-
sults show that the mixed model has a better per-
formance when the source-target corpus is small 
which is close to the realistic scenario. 
A key problem in the approach is how to learn 
the co-occurrence count. In this paper, we use the 
minimum function on balanced corpora and the 
geometric mean function on imbalanced corpora 
to estimate the co-occurrence count intuitively. 
In the future, we plan to explore more effective 
approaches. 
Acknowledgments 
We would like to thank Yiming Cui for insight-
ful discussions, and three anonymous reviewers 
for many invaluable comments and suggestions 
to improve our paper. This work is supported by 
National Natural Science Foundation of China 
(61100093), and the State Key Development 
Program for Basic Research of China (973 Pro-
gram, 2014CB340505). 
Reference 
Nicola Bertoldi, Madalina Barbaiani, Marcello 
Federico, and Roldano Cattoni. 2008. Phrase-
Based statistical machine translation with Piv-
ot Languages. In Proceedings of the 5th Inter-
national Workshop on Spoken Language 
Translation (IWSLT), pages 143-149. 
Trevor Cohn and Mirella Lapata. 2007. Machine 
Translation by Triangulation: Make Effective 
Use of Multi-Parallel Corpora. In Proceedings 
of 45th Annual Meeting of the Association for 
Computational Linguistics, pages 828-735. 
Marta R. Costa-juss?, Carlos Henr?quez, and Ra-
fael E. Banchs. 2011. Enhancing Scarce-
Resource Language Translation through Pivot 
Combinations. In Proceedings of the 5th In-
ternational Joint Conference on Natural Lan-
guage Processing, pages 1361-1365. 
Yiming Cui, Conghui Zhu, Xiaoning Zhu, Tiejun 
Zhao and Dequan Zheng. 2013. Phrase Table 
Combination Deficiency Analyses in Pivot-
based SMT. In Proceedings of 18th Interna-
tional Conference on Application of Natural 
Language to Information Systems, pages 355-
358. 
Adria de Gispert and Jose B. Marino. 2006. 
Catalan-English statistical machine translation 
without parallel corpus: bridging through 
Spanish. In Proceedings of 5th International 
Conference on Language Resources and Eval-
uation (LREC), pages 65-68. 
29
31
33
35
37
39
5K 20K 40K 60K 80K 100K
BL
EU
%
direct
tri
co-occur
tri+inter
co+inter
co+mix
1673
Kevin Duh, Katsuhito Sudoh, Xianchao Wu, 
Hajime Tsukada and Masaaki Nagata. 2011. 
Generalized Minimum Bayes Risk System 
Combination. In Proceedings of the 5th Inter-
national Joint Conference on Natural Lan-
guage Processing, pages 1356-1360. 
Ahmed El Kholy, Nizar Habash, Gregor Leusch, 
Evgeny Matusov and Hassan Sawaf. 2013. 
Language Independent Connectivity Strength 
Features for Phrase Pivot Statistical Machine 
Translation. In Proceedings of the 51st Annual 
Meeting of the Association for Computational 
Linguistics, pages 412-418. 
Ahmed El Kholy, Nizar Habash, Gregor Leusch, 
Evgeny Matusov and Hassan Sawaf. 2013. Se-
lective Combination of Pivot and Direct Sta-
tistical Machine Translation Models. In Pro-
ceedings of the 6th International Joint Confer-
ence on Natural Language Processing, pages 
1174-1180. 
Jes?s Gonz?lez-Rubio, Alfons Juan and Francis-
co Casacuberta. 2011. Minimum Bayes-risk 
System Combination. In Proceedings of the 
49th Annual Meeting of the Association for 
Computational Linguistics, pages 1268-1277. 
Philipp Koehn, Franz J. Och, and Daniel Marcu. 
2003. Statistical Phrase-Based Translation. In 
HLT-NAACL: Human Language Technology 
Conference of the North American Chapter of 
the Association for Computational Linguistics, 
pages 127-133. 
Philipp Koehn. 2004. Statistical significance 
tests for machine translation evaluation. In 
Proceedings of the 2004 Conference on Em-
pirical Methods in Natural Language Pro-
cessing (EMNLP), pages 388-395. 
Philipp Koehn. 2005. Europarl: A Parallel Cor-
pus for Statistical Machine Translation. In 
Proceedings of MT Summit X, pages 79-86. 
Philipp Koehn, Hieu Hoang, Alexanda Birch, 
Chris Callison-Burch, Marcello Federico, Ni-
cola Bertoldi, Brooke Cowan, Wade Shen, 
Christine Moran, Richard Zens, Chris Dyer, 
Ondrej Bojar, Alexandra Constantin, and Evan 
Herbst. 2007. Moses: Open Source Toolkit for 
Statistical Machine Translation. In Proceed-
ings of the 45th Annual Meeting of the Associ-
ation for Computational Linguistics, demon-
stration session, pages 177-180. 
Philipp Koehn, Alexandra Birch, and Ralf Stein-
berger. 2009. 462 Machine Translation Sys-
tems for Europe. In Proceedings of the MT 
Summit XII. 
Gregor Leusch, Aur?lien Max, Josep Maria 
Crego and Hermann Ney. 2010. Multi-Pivot 
Translation by System Combination. In Pro-
ceedings of the 7th International Workshop on 
Spoken Language Translation, pages 299-306. 
Franz Josef Och and Hermann Ney. 2000. A 
comparison of alignment models for statistical 
machine translation. In Proceedings of the 
18th International Conference on Computa-
tional Linguistics, pages 1086-1090. 
Michael Paul, Andrew Finch, Paul R. Dixon and 
Eiichiro Sumita. 2011. Dialect Translation: In-
tegrating Bayesian Co-segmentation Models 
with Pivot-based SMT. In Proceedings of the 
2011 Conference on Empirical Methods in 
Natural Language Processing, pages 1-9. 
Michael Paul and Eiichiro Sumita. 2011. Trans-
lation Quality Indicators for Pivot-based Sta-
tistical MT. In Proceedings of the 5th Interna-
tional Joint Conference on Natural Language 
Processing, pages 811-818. 
Kishore Papineni, Salim Roukos, Todd Ward and 
Wei-Jing Zhu. 2002. BLEU: a Method for Au-
tomatic Evaluation of Machine Translation. In 
Proceedings of the 40th Annual Meeting of the 
Association for Computation Linguistics, pag-
es 311-319. 
Rie Tanaka, Yohei Murakami and Toru Ishida. 
2009. Context-Based Approach for Pivot 
Translation Services. In the Twenty-first In-
ternational Conference on Artificial Intelli-
gence, pages 1555-1561. 
J?rg Tiedemann. 2012. Character-Based Pivot 
Translation for Under-Resourced Languages 
and Domains. In Proceedings of the 13th Con-
ference of the European Chapter of the Asso-
ciation for Computational Linguistics, pages 
141-151. 
Masatoshi Tsuchiya, Ayu Purwarianti, Toshiyu-
kiWakita and Seiichi Nakagawa. 2007. Ex-
panding Indonesian-Japanese Small Transla-
tion Dictionary Using a Pivot Language. In 
Proceedings of the ACL 2007 Demo and Post-
er Sessions, pages 197-200. 
Takashi Tsunakawa, Naoaki Okazaki and 
Jun'ichi Tsujii. 2010. Building a Bilingual 
Lexicon Using Phrase-based Statistical Ma-
chine Translation via a Pivot Language. In 
1674
Proceedings of the 22th International Confer-
ence on Computational Linguistics (Coling), 
pages 127-130. 
Masao Utiyama and Hitoshi Isahara. 2007. A 
Comparison of Pivot Methods for Phrase-
Based Statistical Machine Translation. In Pro-
ceedings of Human Language Technology: the 
Conference of the North American Chapter of 
the Association for Computational Linguistics, 
pages 484-491. 
Masao Utiyama, Andrew Finch, Hideo Okuma, 
Michael Paul, Hailong Cao, Hirofumi Yama-
moto, Keiji Yasuda,and Eiichiro Sumita. 2008. 
The NICT/ATR speech Translation System for 
IWSLT 2008. In Proceedings of the Interna-
tional Workshop on Spoken Language Trans-
lation, pages 77-84. 
Haifeng Wang, Hua Wu, Xiaoguang Hu, Zhanyi 
Liu, Jianfeng Li, Dengjun Ren, and Zhengyu 
Niu. 2008. The TCH Machine Translation 
System for IWSLT 2008. In Proceedings of 
the International Workshop on Spoken Lan-
guage Translation, pages 124-131. 
Hua Wu and Haifeng Wang. 2007. Pivot Lan-
guage Approach for Phrase-Based Statistical 
Machine Translation. In Proceedings of 45th 
Annual Meeting of the Association for Compu-
tational Linguistics, pages 856-863. 
Hua Wu and Haifeng Wang. 2009. Revisiting 
Pivot Language Approach for Machine Trans-
lation. In Proceedings of the 47th Annual 
Meeting of the Association for Computational 
Linguistics and the 4th IJCNLP of the AFNLP, 
pages 154-162. 
Samira Tofighi Zahabi, Somayeh Bakhshaei and 
Shahram Khadivi. Using Context Vectors in 
Improving a Machine Translation System with 
Bridge Language. In Proceedings of the 51st 
Annual Meeting of the Association for Compu-
tational Linguistics, pages 318-322. 
 
 
1675
