Event Detection and Summarization in Weblogs with Temporal Collocations 
Chun-Yuan Teng and Hsin-Hsi Chen 
Department of Computer Science and Information Engineering 
National Taiwan University 
Taipei, Taiwan 
{r93019, hhchen}@csie.ntu.edu.tw 
Abstract 
 
This paper deals with the relationship between weblog content and time. With the proposed temporal mutual information, we analyze 
the collocations in time dimension, and the interesting collocations related to special events. The temporal mutual information is 
employed to observe the strength of term-to-term associations over time. An event detection algorithm identifies the collocations that 
may cause an event in a specific timestamp. An event summarization algorithm retrieves a set of collocations which describe an event. 
We compare our approach with the approach without considering the time interval. The experimental results demonstrate that the 
temporal collocations capture the real world semantics and real world events over time. 
 
1. 
2. 
Introduction 
Compared with traditional media such as online news 
and enterprise websites, weblogs have several unique 
characteristics, e.g., containing abundant life experiences 
and public opinions toward different topics, highly 
sensitive to the events occurring in the real world, and 
associated with the personal information of bloggers. 
Some works have been proposed to leverage these 
characteristics, e.g., the study of the relationship between 
the content and bloggers? profiles (Adamic & Glance, 
2005; Burger & Henderson, 2006; Teng & Chen, 2006), 
and content and real events (Glance, Hurst & Tornkiyo, 
2004; Kim, 2005; Thelwall, 2006; Thompson, 2003). 
In this paper, we will use temporal collocation to 
model the term-to-term association over time.  In the past, 
some useful collocation models (Manning & Sch?tze, 
1999) have been proposed such as mean and variance, 
hypothesis test, mutual information, etc. Some works 
analyze the weblogs from the aspect of time like the 
dynamics of weblogs in time and location (Mei, et al, 
2006), the weblog posting behavior (Doran, Griffith & 
Henderson, 2006; Hurst, 2006), the topic extraction (Oka, 
Abe & Kato, 2006), etc. The impacts of events on social 
media are also discussed, e.g., the change of weblogs after 
London attack (Thelwall, 2006), the relationship between 
the warblog and weblogs (Kim, 2005; Thompson, 2003), 
etc. 
This paper is organized as follows. Section 2 defines 
temporal collocation to model the strength of term-to-term 
associations over time.  Section 3 introduces an event 
detection algorithm to detect the events in weblogs, and 
an event summarization algorithm to extract the 
description of an event in a specific time with temporal 
collocations. Section 4 shows and discusses the 
experimental results.  Section 5 concludes the remarks. 
Temporal Collocations 
We derive the temporal collocations from Shannon?s 
mutual information (Manning & Sch?tze, 1999) which is 
defined as follows (Definition 1). 
Definition 1 (Mutual Information) The mutual 
information of two terms x and y is defined as: 
)()(
),(log),(),(
yPxP
yxPyxPyxI =  
where P(x,y) is the co-occurrence probability of x and y, 
and P(x) and P(y) denote the occurrence probability of x 
and y, respectively. 
Following the definition of mutual information, we 
derive the temporal mutual information modeling the 
term-to-term association over time, and the definition is 
given as follows.  
 Definition 2 (Temporal Mutual Information) Given 
a timestamp t and a pair of terms x and y, the temporal 
mutual information of x and y in t is defined as: 
)|()|(
)|,(log)|,()|,(
tyPtxP
tyxPtyxPtyxI =
where P(x,y|t) is the probability of co-occurrence of terms 
x and y in timestamp t, P(x|t) and P(y|t) denote the 
probability of occurrences of x and y in timestamp t, 
respectively. 
To measure the change of mutual information in time 
dimension, we define the change of temporal mutual 
information as follows. 
Definition 3 (Change of Temporal Mutual 
Information) Given time interval [t1, t2], the change of 
temporal mutual information is defined as: 
12
12
21
)|,()|,(),,,(
tt
tyxItyxIttyxC ?
?=  
where C(x,y,t1,t2) is the change of temporal mutual 
information of terms x and y in time interval [t1, t2], I(x,y| 
t1) and I(x,y| t2) are the temporal mutual information in 
time t1 and t2, respectively. 
3. Event Detection 
Event detection aims to identify the collocations 
resulting in events and then retrieve the description of 
events. Figure 1 sketches an example of event detection. 
The weblog is parsed into a set of collocations. All 
collocations are processed and monitored to identify the 
plausible events.  Here, a regular event ?Mother?s day? 
and an irregular event ?Typhoon Chanchu? are detected.  
The event ?Typhoon Chanchu? is described by the words  
 
 
 
 
 
 
 
 
 
 
 
 
Figure 1: An Example of Event Detection
?Typhoon?, ?Chanchu?, ?2k?, ?Eye?, ?Path? and 
?chinaphillippine?.  
The architecture of an event detection system includes 
a preprocessing phase for parsing the weblogs and 
retrieving the collocations; an event detection phase 
detecting the unusual peak of the change of temporal 
mutual information and identifying the set of collocations 
which may result in an event in a specific time duration; 
and an event summarization phase extracting the 
collocations related to the seed collocations found in a 
specific time duration. 
The most important part in the preprocessing phase is 
collocation extraction. We retrieve the collocations from 
the sentences in blog posts. The candidates are two terms 
within a window size. Due to the size of candidates, we 
have to identify the set of tracking terms for further 
analysis. In this paper, those candidates containing 
stopwords or with low change of temporal mutual 
information are removed. 
In the event detection phase, we detect events by 
using the peak of temporal mutual information in time 
dimension.  However, the regular pattern of temporal 
mutual information may cause problems to our detection. 
Therefore, we remove the regular pattern by seasonal 
index, and then detect the plausible events by measuring 
the unusual peak of temporal mutual information. 
If a topic is suddenly discussed, the relationship 
between the related terms will become higher. Two 
alternatives including change of temporal mutual 
information and relative change of temporal mutual 
information are employed to detect unusual events. Given 
timestamps t1 and t2 with temporal mutual information 
MI1 and MI2, the change of temporal mutual information 
is calculated by (MI2-MI1). The relative change of 
temporal mutual information is calculated by (MI2-
MI1)/MI1. 
For each plausible event, there is a seed collocation, 
e.g., ?Typhoon Chanchu?. In the event description 
retrieval phase, we try to select the collocations with the 
highest mutual information with the word w in a seed 
collocation. They will form a collocation network for the 
event.  Initially, the seed collocation is placed into the 
network.  When a new collocation is added, we compute 
the mutual information of the multiword collocations by 
the following formula, where n is the number of 
collocations in the network up to now. 
?= n iMInInformatioMutualMultiwo  
If the multiword mutual information is lower than a 
threshold, the algorithm stops and returns the words in the 
collocation network as a description of the event.  Figure 
2 sketches an example.  The collocations ?Chanchu?s 
path?, ?Typhoon eye?, and ?Chanchu affects? are added 
into the network in sequence based on their MI. 
We have two alternatives to add the collocations to 
the event description. The first method adds the 
collocations which have the highest mutual information 
as discussed above. In contrast, the second method adds 
the collocations which have the highest product of mutual 
information and change of temporal mutual information. 
 
 
 
 
 
 
Figure 2: An Example of Collocation network 
4. 
4.1. 
Experiments and Discussions 
Temporal Mutual Information versus 
Mutual Information 
In the experiments, we adopt the ICWSM weblog data 
set (Teng & Chen, 2007; ICWSM, 2007). This data set 
collected from May 1, 2006 through May 20, 2006 is 
about 20 GB. Without loss of generality, we use the 
English weblog of 2,734,518 articles for analysis. 
To evaluate the effectiveness of time information, we 
made the experiments based on mutual information 
(Definition 1) and temporal mutual information 
(Definition 2). The former called the incremental 
approach measures the mutual information at each time 
point based on all available temporal information at that 
time. The latter called the interval-based approach 
considers the temporal mutual information in different 
time stamps.  Figures 3 and 4 show the comparisons 
between interval-based approach and incremental 
approach, respectively, in the event of Da Vinci Code.   
We find that ?Tom Hanks? has higher change of 
temporal mutual information compared to ?Da Vinci 
Code?. Compared to the incremental approach in Figure 4, 
the interval-based approach can reflect the exact release 
date of ?Da Vinci Code.? 
 rd
=i 1 4.2. Evaluation of Event Detection 
We consider the events of May 2006 listed in 
wikipedia1 as gold standard. On the one hand, the events 
posted in wikipedia are not always complete, so that we 
adopt recall rate as our evaluation metric.  On the other 
hand, the events specified in wikipedia are not always 
discussed in weblogs.  Thus, we search the contents of 
blog post to verify if the events were touched on in our 
blog corpus. Before evaluation, we remove the events 
listed in wikipedia, but not referenced in the weblogs. 
 
 
 
 
 
 
 
 
 
 
 
Figure 3: Interval-based Approach in Da Vinci Code  
 
 
 
 
 
 
 
 
Figure 4: Incremental Approach in Da Vinci Code 
gure 5 sketches the idea of evaluation.  The left side 
of t s figure shows the collocations detected by our event 
dete tion system, and the right side shows the events 
liste  in wikipedia.  After matching these two lists, we 
can find that the first three listed events were correctly 
identified by our system.  Only the event ?Nepal Civil 
War? was listed, but not found. Thus, the recall rate is 
75% in this case. 
 
 
 
 
 
 
 
Figure 5: Evaluation of Event Detection Phase 
As discussed in Section 3, we adopt change of 
temporal mutual information, and relative change of 
temporal mutual information to detect the peak. In Figure 
6, we compare the two methods to detect the events in 
weblogs. The relative change of temporal mutual 
information achieves better performance than the change 
of temporal mutual information. 
                                                     
1 http://en.wikipedia.org/wiki/May_2006 
Table 1 and Table 2 list the top 20 collocations based 
on these two approaches, respectively. The results of the 
first approach show that some collocations are related to 
the feelings such as ?fell left? and time such as ?Saturday 
night?. In contrast, the results of the second approach 
show more interesting collocations related to the news 
events at that time, such as terrorists ?zacarias 
moussaoui? and ?paramod mahajan.? These two persons 
were killed in May 3. Besides, ?Geena Davis? got the 
golden award in May 3. That explains why the 
collocations detected by relative change of temporal 
mutual information are better than those detected by 
change of temporal mutual information. 
-20
-15
-10
-5
0
5
10
1 3 5 7 9 11 13 15 17 19
Time (day)
M
ut
ua
l i
nf
or
m
at
io
n
Da-Vinci Tom Hanks
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 6: Performance of Event Detection Phase 
-15
-10
-5
0
5
10
1 3 5 7 9 11 13 15 17 19
Time (day)
M
ut
ua
l i
nf
or
m
at
io
n
Da-Vinci Tom Hanks
Collocations CMI Collocations CMI 
May 03 9276.08 Current music 1842.67
Illegal immigrants 5833.17 Hate studying 1722.32
Feel left 5411.57 Stephen Colbert 1709.59
Saturday night 4155.29 Thursday night 1678.78
Past weekend 2405.32 Can?t believe 1533.33
White house 2208.89 Feel asleep 1428.18
Red sox 2208.43 Ice cream 1373.23
Album tool 2120.30 Oh god 1369.52
Sunday morning 2006.78 Illegalimmigration 1368.12
16.56
f 
CMI
32.50
31.63
29.09
28.45
28.34
28.13Sunday night 1992.37 Pretty cool 13
Table 1: Top 20 collocations with highest change o
temporal mutual information 
Collocations CMI Collocations 
casinos online 618.36 Diet sodas 
zacarias moussaoui 154.68 Ving rhames 
Tsunami warning 107.93 Stock picks 
Conspirator zacarias 71.62 Happy hump 
Artist formerly 57.04 Wong kan 
Federal  
Jury 
41.78 Sixapartcom 
movabletype Wed 3 39.20 Aaron echolls 27.48
Pramod mahajan 35.41 Phnom penh 25.78
BBC  
Version 
35.21 Livejournal 
sixapartcom 
23.83  Fi
hi
c
dGeena davis 33.64 George yeo 20.34
Table 2: Top 20 collocations with highest relative change 
of mutual information 
4.3. Evaluation of Event Summarization 
As discussed in Section 3, we have two methods to 
include collocations to the event description. Method 1 
employs the highest mutual information, and Method 2 
utilizes the highest product of mutual information and 
change of temporal mutual information. Figure 7 shows 
the performance of Method 1 and Method 2. We can see 
that the performance of Method 2 is better than that of 
Method 1 in most cases. 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 7: Overall Performance of Event Summarization 
The results of event summarization by Method 2 are 
shown in Figure 8. Typhoon Chanchu appeared in the 
Pacific Ocean on May 10, 2006, passed through 
Philippine and China and resulted in disasters in these 
areas on May 13 and 18, 2006.  The appearance of the 
typhoon Chanchu cannot be found from the events listed 
in wikipedia on May 10.  However, we can identify the 
appearance of typhoon Chanchu from the description of 
the typhoon appearance such as ?typhoon named? and 
?Typhoon eye.  In addition, the typhoon Chanchu?s path 
can also be inferred from the retrieved collocations such 
as ?Philippine China? and ?near China?. The response of 
bloggers such as ?unexpected typhoon? and ?8 typhoons? 
is also extracted.   
 
 
 
 
 
 
 
 
 
 
Figure 8: Event Summarization for Typhoon Chanchu 
5. Concluding Remarks 
This paper introduces temporal mutual information to 
capture term-term association over time in weblogs. The 
extracted collocation with unusual peak which is in terms 
of relative change of temporal mutual information is 
selected to represent an event.  We collect those 
collocations with the highest product of mutual 
information and change of temporal mutual information 
to summarize the specific event.  The experiments on 
ICWSM weblog data set and evaluation with wikipedia 
event lists at the same period as weblogs demonstrate the 
feasibility of the proposed temporal collocation model 
and event detection algorithms. 
Currently, we do not consider user groups and 
locations. This methodology will be extended to model 
the collocations over time and location, and the 
relationship between the user-preferred usage of 
collocations and the profile of users. 
Acknowledgments 
Research of this paper was partially supported by 
National Science Council, Taiwan (NSC96-2628-E-002-
240-MY3) and Excellent Research Projects of National 
Taiwan University (96R0062-AE00-02). 
References 
Adamic, L.A., Glance, N. (2005). The Political 
Blogosphere and the 2004 U.S. Election: Divided 
They Blog. In: Proceedings of the 3rd International 
Workshop on Link Discovery, pp. 36--43. 
Burger, J.D., Henderson J.C. (2006). An Exploration of 
Observable Features Related to Blogger Age. In: 
Proceedings of AAAI 2006 Spring Symposium on 
Computational Approaches to Analysing Weblogs, pp. 
15--20. 
Doran, C., Griffith, J., Henderson, J. (2006). Highlights 
from 12 Months of Blogs. In: Proceedings of AAAI 
2006 Spring Symposium on Computational 
Approaches to Analysing Weblogs, pp. 30--33. 
Glance, N., Hurst, M., Tornkiyo, T. (2004). Blogpulse: 
Automated Trend Discovery for Weblogs. In: 
Proceedings of WWW 2004 Workshop on the 
Weblogging Ecosystem: Aggregation, Analysis, and 
Dynamics. 
Hurst, M. (2006). 24 Hours in the Blogosphere. In: 
Proceedings of AAAI 2006 Spring Symposium on 
Computational Approaches to Analysing Weblogs, pp. 
73--77. 
ICWSM (2007). http://www.icwsm.org/data.html 
Kim, J.H. (2005). Blog as an Oppositional Medium? A 
Semantic Network Analysis on the Iraq War Blogs. In: 
Internet Research 6.0: Internet Generations. 
 
Manning, C.D., Sch?tze, H. (1999). Foundations of 
Statistical Natural Language Processing, The MIT 
Press, London England. 
Mei, Q., Liu, C., Su, H., Zhai, C. (2006). A Probabilistic 
Approach to Spatiotemporal Theme Pattern Mining on 
Weblogs. In: Proceedings of the 15th International 
Conference on World Wide Web, Edinburgh, Scotland, 
pp. 533--542. 
Oka, M., Abe, H., Kato, K. (2006). Extracting Topics 
from Weblogs Through Frequency Segments. In: 
Proceedings of WWW 2006 Annual Workshop on the 
Weblogging Ecosystem: Aggregation, Analysis, and 
Dynamics. 
Teng, C.Y., Chen, H.H. (2006). Detection of Bloggers? 
Interest: Using Textual, Temporal, and Interactive 
Features. In: Proceeding of IEEE/WIC/ACM 
International Conference on Web Intelligence, pp. 
366--369. 
Teng, C.Y., Chen, H.H. (2007). Analyzing Temporal 
Collocations in Weblogs. In: Proceeding of 
International Conference on Weblogs and Social 
Media, 303--304. 
Thelwall, M. (2006). Blogs During the London Attacks: 
Top Information Sources and Topics. In: Proceedings 
of 3rd Annual Workshop on the Weblogging 
Ecosystem: Aggregation, Analysis and Dynamics. 
Thompson, G. (2003). Weblogs, Warblogs, the Public 
Sphere, and Bubbles. Transformations, 7(2). 
Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 247?254,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Coreference handling in XMG
Claire Gardent
CNRS/LORIA
615, rue du jardin botanique, B.P. 101
54602 Villers le`s Nancy CEDEX
France
Claire.Gardent@loria.fr
Yannick Parmentier
INRIA Lorraine
615, rue du jardin botanique, B.P. 101
54602 Villers le`s Nancy CEDEX
France
Yannick.Parmentier@loria.fr
Abstract
We claim that existing specification lan-
guages for tree based grammars fail to
adequately support identifier managment.
We then show that XMG (eXtensible Meta-
Grammar) provides a sophisticated treat-
ment of identifiers which is effective in
supporting a linguist-friendly grammar de-
sign.
1 Specifying tree-based grammars
Whilst the development of standard unification-
based grammars is well supported by the design of
formalisms such as PATR-II, Ale or TDL (Krieger
and Schafer, 1994), the situation is less well es-
tablished for Tree-Based Grammars such as Tree
Adjoining Grammars (Joshi and Schabes, 1997),
Tree Description Grammars (Kallmeyer, 1996) or
Interaction Grammars (Perrier, 2003).
Roughly, two main types of specification for-
malism for Tree-Based Grammars can be distin-
guished: formalisms based on tree fragments and
non monotonic inheritance and formalisms based
on tree descriptions and monotonic inheritance.
The tree fragment approach is advocated in
(Evans et al, 1995) which proposes to encode lex-
icalised TAGs using the DATR representation lan-
guage1. In this approach, tree fragments are com-
bined within a non monotonic inheritance hierar-
chy. Furthermore, new fragments can be derived
from existing ones by means of lexical rules. This
first approach suffers from the procedural char-
acter of non-monotonic inheritance. In specify-
ing the grammar, the grammar writer must keep
1A tree based approach is also used in(Becker, 2000) but
this time in combination with metarules. In that particular
approach, procedural aspects also come into play as the order
in which metarules apply affect the results.
in mind the order in which non-monotonic state-
ments have been made so as to be able to pre-
dict how explicit statements interact with defaults
and non-monotonic inheritance in determining the
final output. When developing a large coverage
grammar, this rapidly become extremely cumber-
some. Moreover, as (Candito, 1996) remarks, non-
monotonicity may result in an information loss
which makes it impossible to express the relation
existing for instance between an active object and
the corresponding passive subject.
The approach based on tree descriptions (of-
ten called, the metagrammar approach) obviates
the procedural character of the non-monotonic
approach by taking tree descriptions rather than
trees to be the basic units (Candito, 1996; Xia et
al., 1999; Vijay-Shanker and Schabes, 1992). In
essence, tree fragments are described using tree
descriptions and tree descriptions are combined
through conjunction or inheritance. The idea is
that the minimal models satisfying the resulting
descriptions are TAG elementary trees. In some
cases, lexical rules are also used to derive new
trees from existing ones.
One main drawback with this second type of
approach concerns the management of node iden-
tifiers. Either nodes are represented by name-
less variables and node identification is forced by
well-formedness constraints e.g., wff-constraints
on trees and wff-constraints given by the input
tree description (cf. e.g., (Duchier and Gardent,
1999)) or nodes are named and nodes with iden-
tical names are forced to denote the same entity.
The first option is unrealistic when developing a
large core grammar as it is easy to omit a neces-
sary constraint and thereby permit overgeneration
(the description will be satisfied by more trees than
intended). The second option greatly degrades
247
modularity as the grammar writer must remem-
ber which names were used where and with which
interpretation. As we shall see below, it also has
the undesirable effect that the same tree fragment
cannot be used twice in a given tree description.
Nevertheless, this is the option that is adopted in
most grammar formalisms and grammar compil-
ers (Candito, 1996; Xia et al, 1999; Gaiffe et al,
2002).
In this paper, we present an approach which
remedies these shortcomings by combining mono-
tonic inheritance of tree descriptions with an ex-
plicit management of identifier scope and identi-
fiers equality2 . The proposed approach thus es-
chews both the inconvenients induced by a non
monotonic framework (by using tree descriptions
rather than trees) and those resulting from a global
treatment of identifiers (by providing greater ex-
pressivity wrt identifiers).
Specifically, we show that the proposed ap-
proach supports several ways of identifying (node
or feature) values, we motivate this multiplicity
and we identify the linguistic and/or technical cri-
teria for choosing among the various possibilities.
The paper starts in section 2 by introducing the
syntax of the XMG formalism. In section 3, we
show that XMG provides four different ways of
identifying two (node or variable) identifiers. In
section 4, we motivate each of these four differ-
ent ways and indicate when each of them can and
should be used.
2 The XMG formalism
We start by briefly introducing XMG (eXtended
MetaGrammar). First, we show that it supports the
description and the combination of blocks consist-
ing of tree fragments and/or semantic representa-
tions. Then, we show that it supports a sophisti-
cated treatment of identifiers.
2.1 Defining blocks
At the syntactic level, the basic units are tree de-
scriptions which are specified using the following
tree logic:
2Recently, (Villemonte de la Clergerie, 2005) has pro-
posed a highly compact representation formalism for tree-
based grammars which also features explicit identifier man-
agement. His approach differs from ours in that it includes
neither a colouring mechanism (cf. section 3.4) nor interfaces
(cf. section 3.3).
Description ::= x ? y | x ?+ y | x ?? y |
x ? y | x ?+ y | x ?? y |
x[f :E] | x = y |
Description ? Description
(1)
where x, y represent node variables, ? immediate
dominance (x is directly above y), ?+ strict dom-
inance (x is above y), and ?? large dominance3
(x is above or equal to y). Similarly ? denotes
immediate precedence, ?+ strict precedence, and
?? large precedence. Finally x[f :E] constrains
feature f with associated expression E on node
x, and x = y indicates node identification.
The XMG formalism also supports the associa-
tion of semantic representations with elementary
trees. The semantic representation language is a
flat semantic representation language (Bos, 1995)
with the following syntax:
Description ::= `:p(E1, ..., En) |
?`:p(E1, ..., En) | Ei ? Ej
Description ? Description
(2)
where ` is a label, p is a predicate and E1, .., En
are parameters. Further, ? denotes negation and
Ei ? Ej expresses a scope constraint between Ei
and Ej (Ej is in the scope of Ei).
2.2 Combining blocks
As in other existing tree-based formalisms, in
XMG, blocks can be combined using inheritance.
However, XMG additionally supports block con-
junction and block disjunction.
Specifically, a Class associates a name with a
content:
Class ::= Name ? {Content } (3)
A Content is either a Description (i.e., a tree
description, a semantic formula or both), a class
name, a conjunction or a disjunction of class
name:
Content ::= Description | Name |
Name ? Name | Name ? Name (4)
Further, XMG allows multiple inheritance: a given
class can import or inherit one or more classes
(written Ci here):
3By large, we mean the transitive reflexive closure of
dominance.
248
Class ::= Name 6 C1 ? . . . ? Cn ? {Content } (5)
The semantic of the import instruction is to in-
clude the description of the imported class within
the current one. This makes it possible to refine a
class e.g., by adding information to a node or by
adding new nodes4 .
2.3 Managing identifiers
We now introduce the treatment of identifiers sup-
ported by XMG. We show in particular, that it in-
tegrates:
? a convenient way of managing identifier
scope based on import/export declarations
inspired from standard Object Oriented Pro-
gramming techniques (section 2.3.1);
? an alternative means of identifying feature
values based on the use of unification
? polarity- (here called colour-) based node
identification as first proposed in (Muskens
and Krahmer, 1998) and later used in
(Duchier and Thater, 1999; Perrier, 2000).
The next sections will detail the linguistic and
technical motivations behind this variety of identi-
fier handling techniques.
2.3.1 Import/Export declaration
In XMG, the default scope of an identifier is the
class in which it is declared. However, export
specifications can be used to extend the scope of
a given identifier outside its declaration class. The
export of identifier ?X ouside class A is written :5
A?X ? { . . . ?X . . . }
Export declarations interact with inheritance,
conjunction and disjunction specifications as fol-
lows (where A,B,C are classes):
Inheritance: if the class A is imported either di-
rectly or indirectly by a class B, then ?X is
visible in B. In case of multiple inheritance
4Note that disjunctive inheritance is not supported which
would allow a block to be defined as importing one or more
classes from a given set of imported classes
5Similarly, import declaration can be used to restrict the
set of accessible identifiers to a subset of it.
e.g., if B 6 C1 ? . . . ? Cn , then all identi-
fiers exported by C1 ? . . . ? Cn are visible
from B provided they have distinct names.
In other words, if two (or more) classes in
C1 ? . . . ? Cn export the same identifier ?X,
then ?X is not directly visible from B. It can
be accessed though using the dot operator.
First A is identified with a local identifier
(e.g., ?T = A), then ?T.?X can be used to
refer to the identifier ?X exported by A.
Conjunction: if classes A and B are conjoined in-
side a class C, then all the identifiers exported
by A or B are visible within C using the dot
operator.
Disjunction: if classes A and B are disjoined in-
side a class C, then all the identifiers exported
by A or B are visible within C using the dot
operator. However in this case, both A and
B have to be associated with the same local
identifier.
In sum, export/import declarations permit ex-
tending/restricting the scope of an identifier within
a branch of the inheritance hierarchy whilst the
dot operator allows explicit access to an inherited
identifier in case the inheriting class either dis-
plays multiple inheritance or is combined by con-
junction or disjunction with other classes. More
specifically, inheritance allows implicit corefer-
ence (the use of an imported name ensures coref-
erence with the object referred to when declaring
this name) and the dot operator explicit corefer-
ence (through an explicit equality statement e.g.,
?A.?X = ?B.?Y).
2.3.2 Class interface
In XMG, a class can be associated with a class
interface i.e., with a feature structure. Further-
more, when two classes are related either by in-
heritance or by combination (conjunction or dis-
junction), their interfaces are unified. Hence class
interfaces can be used to ensure the unification of
identifiers across classes.
Here is an illustrating example:
A ? { . . . ?X . . . }? = [n1 = ?X]
B ? { . . . ?Y . . . }? = [n1 = ?Y]
In A (resp. B), the local identifier ?X (resp. ?Y) is
associated with an interface feature named n1. If
249
these two classes are combined either by conjunc-
tion or by inheritance, their interfaces are unified
and as a result, the local identifiers ?X and ?Y are
unified. In the case of a disjunction, the interface
of the current class (C here) is non deterministi-
cally unified with that of A or B.
In practice, interface-based identification of val-
ues is particularly useful when two distinct fea-
tures need to be assigned the same value. In (Gar-
dent, 2006) for instance, it is used to identify the
semantic index associated with e.g., the subject
node of a verbal tree and the corresponding seman-
tic index in the semantic representation associated
with that tree.
2.3.3 Colouring nodes
Finally, XMG provides a very economical way
of identifying node variables based on the use of
colours (also called polarities in the literature).
The idea is that node variables are associated with
a specific colour and that this colouring will either
prevent or trigger node identifications based on the
following identification rules:
?B ?R ?W ?
?B ? ? ?B ?
?R ? ? ? ?
?W ?B ? ?W ?
? ? ? ? ?
and on the requirement that valid trees only
have red or black nodes. In effect, node colour-
ing enforces the following constraints : (i) a white
node must be identified with a black node, (ii) a
red node cannot be identified with any other node
and (iii) a black node may be identified with one
or more white nodes.
Contrary to other means of value identification,
colours are restricted to node identifiers. Hence
they are best used to induce node identification in
those contexts where neither inheritance nor ex-
plicit identification are appropriate (see section 4).
3 XMG at work
Recall (section 1) that one main problem when de-
veloping a factorised specification of tree based
grammars is to ensure a consistent treatment of
identifiers and in particular, of identifier unifica-
tion. That is, when combining two units of infor-
mation, the grammar writer must ensure that her
specification correctly states which objects are the
same and which are distinct.
In what follows, we show that XMG supports
four different ways of identifying objects. We il-
lustrate this by demonstrating that the following
tree can be obtained in four different ways:
s
n v
Figure 1: A tree that can be derived in four ways
In section 4, we will show that these four ways
of identifying nodes and/or features values support
both explicitness and economy thereby reducing
the risks of specification errors.
3.1 Using explicit identification
The most basic way to identify two identifiers is to
explicitly state their identity. Thus the above tree
can be produced by combining the following two
classes6 :
A?X,?Y ? { ?X [cat : s] ? ?Y [cat : n] }
B1 ? { ?U [cat : s] ? ?Z [cat : v]
? A ? ?U = A.?X ? A.?Y ? ?Z }
To improve readability, we use from now on a
graphical representation. For instance, the classes
above are represented as follows (exported identi-
fiers are underlined and boxed letters indicate class
names):


 
A s ?X




B1 s ?U
n ?Y v ?Z
? A ? ?U = A.?X
? A.?Y ? ?Z
Thus, the class A describes the left branch of the
tree in Figure 1 and the class B1 its right branch.
The root of A and B are named ?X and ?U re-
spectively. Since ?X is exported, ?X is visible in
B1. The explicit identification ?U=A.?X then en-
forces that the two roots are identified thus con-
straining the solution to be the tree given in Fig-
ure 1.
3.2 Using inheritance
Using inheritance instead of conjunction, the same
nodes identification can be obtained in a more eco-
nomical way. We reuse the same class A as before,
but we now define a class B 2 as a sub-class of A:


 
A s ?X




B2 6 A s ?X
n ?Y v ?Z
? ?Y ? ?Z
6Here and in what follows, we abbreviate the conjunction
of a class identification ?T = A and a dot notation T.?X to
A.?X. That is,
?T = A ? T.?X?abbrev A.?X
250
Since the identifiers ?X and ?Y are exported by A,
they are visible in B2. Thus, in the latter we only
have to indicate the precedence relation between
?Y and ?Z.
In sum, the main difference between explicit
identification and identification through simple ex-
ports, is that whilst inheritance of exported identi-
fiers gives direct access to these identifiers, class
combination requires the use of a prefix and dot
statement. Note nevertheless that with the latter,
identifiers conflicts are a lot less likely to appear.
3.3 Using interfaces
A third possibility is to use interfaces to force node
identifications as illustrated in figure 2.


 
A s ?X




B3 s ?U
n ?Y n ?W ? v ?V
? A
[root = ?X, [root = ?U,
nNode = ?Y] nNode = ?W]
Figure 2: Structure sharing using interfaces
Class A is the same as before except that the
identifiers ?X and ?Y are no longer exported. In-
stead they are associated with the interface fea-
tures root and nNode respectively. Similarly,
class B3 associates the identifiers (?U and ?V) with
the interface features root and nNode. As the tree
fragment of class B3 is conjoined with A, the inter-
face features of A and B3 are unified so that ?X is
identified with ?U and ?Y with ?V.
3.4 Using node colours
Finally, colours can be used as illustrated in the
Figure below:


 
A s ?




B4 s ?
n ? n ? ? v ?
? A
Now, class B4 contains three nodes: two white
ones whose categories are s and n and which must
be identified with compatible black nodes in A;
and a black node that may but need not be identi-
fied with a white one. To satisfy these constraints,
the black s node in A must be identified with the
white s node in B and similarly for the n nodes.
The result is again the tree given in Figure 1.
Note that in this case, none of the identifiers
need to be exported. Importantly, the use of
colours supports a very economical way of forcing
nodes identification. Indeed, nodes that are identi-
fied through colouration need neither be exported
nor even be named.
4 Which choice when?
As shown in the previous section, XMG allows
four ways of identifying values (i.e., nodes or fea-
ture values): through simple exports, through ex-
plicit identification, through colour constraints and
through the interface. We now identify when each
of these four possibilities is best used.
4.1 Exports
As shown in section 2.3, an identifier ?X can be
explicitly exported by a class Cwith the effect that,
within all classes that inherit from C, all occur-
rences of ?X denote the same object.
In essence, exports supports variable naming
that is global to a branch of the inheritance hier-
archy. It is possible to name an identifier within
a given class C and to reuse it within any other
class that inherits from C. Thus the empirical dif-
ficulty associated with the use of exported iden-
tifiers is that associated with global names. That
is, the grammar writer must remember the names
used and their intended interpretation. When de-
veloping a large size grammar, this rapidly makes
grammar writing, maintenance and debugging an
extremely difficult task. Hence global identifiers
should be use sparingly.
But although non trivial (this was in fact one
of the main motivations for developing XMG), this
empirical limitation is not the only one. There are
two additional formal restrictions which prevent a
general use of exported identifiers.
First, as remarked upon in (Crabbe and Duchier,
2004), global names do not support multiple use
of the same class within a class. For instance, con-
sider the case illustrated in Figure 3.
s s s
v pp ? v pp pp
p n p n p n
Figure 3: Case of double prepositional phrase.
In this case, the aim is to produce the elemen-
tary tree for a verb taking two prepositional argu-
ments such as parler a` quelqu?un de quelque chose
(to tell someone about something). Ideally, this is
done by combining the verbal fragment on the left
251
with two occurrences of the PP class in the mid-
dle to yield the tree on the right. However if, as is
likely in a large size metagrammar, any of the pp,
the p or the n node bears an exported identifier,
then the two occurrences of this node will be iden-
tified so that the resulting tree will be that given in
(4).
s
v pp
p n
Figure 4: Double prepositional phrase with ex-
ported identifiers.
We will see below how colours permit a natural
account of such cases.
Second, exported modifiers do not support iden-
tifier unification in cases of conjunction, disjunc-
tion and multiple inheritance. That is, in each of
the three cases below, the various occurrences of
?X are not identified.
C1 ?X ? C2 ?X
C1 ?X ? C2 ?X
C3 ?X 6 C1 ?X ? C2 ?X
In such cases, the multiple occurrences of ?X
need to be explicitly identified (see below).
In practice then, the safest use of simple exports
(ie without explicit identifier equalities) consists in
using them
? in combination with inheritance only and
? within a linguistically motivated subpart of
the inheritance hierarchy
4.2 Colours
As discussed in section 2.3, node identifications
can be based on colours. In particular, if a node is
white, it must be identified with a black node.
The main advantage of this particular identifica-
tion mechanism is that it is extremely economical.
Not only is there no longer any need to remember
names, there is in fact no need to chose a name.
When developing a metagrammar containing sev-
eral hundreds of nodes, this is a welcome feature.
This ?no-name? aspect of the colour mecha-
nism is in particular very useful when a given class
needs to be combined with many other classes.
For instance, in SEMFRAG (Gardent, 2006), the
semantic index of a semantic functor (i.e., a verb,
an adjective, a preposition or a predicative noun)
needs to be projected from the anchor to the root
node as illustrated in Figure 5. This can be done,
as shown in the figure by conjoining CSem with CV
or CA and letting the colour unify the appropriate
nodes.
s ? s ? ?i2
np ? vp ? np ? np ? ap ? np ? ?i2i1
v ? cop ? adj ? ?
i1
v | adj




CV




CA




CSem
Figure 5: Case of semantic projections.
Colouring also solves the problem raised by the
multiple reuse of the same class in the definition
of a given class. The colouring will be as shown
in Figure 6. Since the pp, p and n nodes are black,
their two occurrences cannot be identified. The
two white s nodes however will both be unified
with the black one thus yielding the expected tree.
s ? s ? s ?
v ? pp ? ? v ? pp ? pp ?
p ? n ? p ? n ? p ? n ?
Figure 6: Case of double prepositional phrase with
coloured descriptions.
As for exports however, colours cannot always
be used to force identifications.
First, colours can only be used in combination
with conjunction or inheritance of non exported
identifiers. Indeed, inheritance does not allow the
identification of two different objects. Hence if a
class C containing a white node named ?X inherits
from another class C? exporting a black node also
named ?X, compilation will fail as a given identi-
fier can only have one colour7 . In contrast, when
solving a description containing the conjunction of
a black and a white node (where these two nodes
have either no names or distinct names), the well
formedness constraint on coloured tree will ensure
that these two nodes are in fact the same (since a
tree containing a white node is ill formed).
Second, colour based identification is non de-
terministic. For instance, in Figure 5, if the lowest
7However, different occurrences of the same unnamed
node can have distinct colours.
252
node b of CSem was not labelled cat = v | adj,
CA? CSem would yield not one but two trees: one
where b is identified with the cop node and the
other where it is identified with the adj one. In
other words, colour based unification is only pos-
sible in cases where node decorations (or explicit
node identifications) are sufficiently rich to con-
strain the possible unifications.
To sum up, colours are useful in situations
where:
? a given class needs to be combined with
many other classes ? in this case it is unlikely
that the names used in all classes to be com-
bined are consistent (ie that they are the same
for information that must be unified and that
they are different for information that must
not) and
? the nodes to be identified are unambigu-
ous (the white and the black nodes contain
enough information so that it is clear which
white node must be identified with which
black one)
4.3 Interfaces
Interfaces provide another mechanism for global
naming. They are particularly useful in cases
where two fundamentally different objects contain
non-node identifiers that must be unified.
Recall (cf. section 4.2) that exported identifiers
are best used within restricted, linguistically well
defined hierarchies. In a case where the objects
containing the two identifiers to be identified are
different, these will belong to distinct part of the
inheritance hierarchy hence identifier export is not
a good option.
Node colouring is another possibility but as the
name indicates, it only works for nodes, not for
feature values.
In such a situation then, interfaces come in
handy. This is the case for instance, when com-
bining a semantic representation with a tree. The
semantic formula and the tree are distinct objects
but in the approach to semantic construction de-
scribed in (Gardent and Kallmeyer, 2003), they
share some semantic indices. For instance, the
subject node in the tree is labelled with an index
feature whose value must be (in an active form
tree) that of the first argument occurring in the
semantic representation. The encoding of the re-
quired coreference can be sketched as follows:
Subj ?{ . . . ?X . . .}? = [subjectIdx = ?X]
Sem ?{ . . . ?Y . . .}? = [arg1 = ?Y]
Tree ?Subj? = [subjectIdx = ?Z]?
Sem? = [arg1 = ?Z]
The first two lines show the naming of the iden-
tifiers ?X and ?Y through the interface, the third
illustrates how unification can be used to identify
the values named by the interface: since the same
variable ?Z is the value of the two features arg1
and subjectIdx, the corresponding values in the
Subj and Sem classes are identified.
4.4 Explicit identification of exported
identifiers
The explicit identification of exported identifiers is
the last resort solution. It is not subject to any of
the restrictions listed above and can be combined
with conjunction, disjunction and inheritance. It
is however uneconomical and complexifies gram-
mar writing (since every node identification must
be explicitly declared). Hence it should be used as
little as possible.
In practice, explicit identification of exported
identifiers is useful :
? to further constrain colour based identifica-
tion (when the feature information present in
the nodes does not suffice to force identifica-
tion of the appropriate nodes)
? to model general principles that apply to sev-
eral subtrees in a given hierarchy
The second point is illustrated by Subject/Verb
agreement. Suppose that in the metagrammar,
we want to have a separate class to enforce this
agreement. This class consists of a subject node
?SubjAgr bearing agreement feature ?X and of
a verb node ?VerbAgr bearing the same agree-
ment feature. It must then be combined with all
verbal elementary trees described by the meta-
grammar whereby in each such combination the
nodes ?SubjAgr, ?VerbAgr must be identi-
fied with the subject and the verb node respec-
tively. This is a typical case of multiple inheri-
tance because both the subject and the verb nodes
are specified by inheritance and ?SubjAgr,
?VerbAgr must be further inherited. Since
nodes must be identified and multiple inheritance
occur, simple identifier exports cannot be used (cf.
section 2.3.1). If colours cannot be sufficiently
253
Pros Cons Practice
Export Economy Name management Use in linguistically motivated
Not with multiple inheritance sub-hierarchy
Not with conjunction
Not with disjunction
Not with multiple reuse
Colours Economy ++ Non deterministic
Multiple reuse OK Not with inheritance Use when a given class
and identically named identifiers combines with many classes
Interface Global Name management Use for Syntax/Semantic interface
Explicit identification Usable in all cases Uneconomical Last Resort solution
Figure 7: Summary of the pros and cons of sharing mechanisms.
constrained by features, then the only solution left
is explicit node identification.
Figure 7 summarises the pros and the cons of
each approach.
5 Conclusion
In this paper, we have introduced a specification
formalism for Tree-Based Grammars and shown
that its expressivity helps solving specification
problems which might be encountered when de-
velopping a large scale tree-based grammar.
This formalism has been implemented within
the XMG system and successfully used to encode
both a core TAG for French (Crabbe, 2005; Gar-
dent, 2006) and a core Interaction Grammar (Per-
rier, 2003). We are currently exploring ways
in which the XMG formalism could be extended
to automatically enforce linguistically-based well-
formedness principles such as for instance, a kind
of Head Feature Principle for TAG.
References
T. Becker. 2000. Patterns in metarules. In A. Abeille and
O. Rambow, editors, Tree Adjoining Grammars: formal,
computational and linguistic aspects. CSLI publications,
Stanford.
J. Bos. 1995. Predicate Logic Unplugged. In Proceedings of
the 10th Amsterdam Colloquium, Amsterdam.
M.H. Candito. 1996. A principle-based hierarchical rep-
resentation of LTAGs. In Proceedings of COLING?96,
Kopenhagen.
B. Crabbe and D. Duchier. 2004. Metagrammar Redux. In
Proceedings of CSLP 2004, Copenhagen.
B. Crabbe. 2005. Repre?sentation informatique de gram-
maires fortement lexicalise?es : Application a` la gram-
maire d?arbres adjoints. Ph.D. thesis, Universite? Nancy
2.
D. Duchier and C. Gardent. 1999. A constraint based treat-
ment of descriptions. In Proceedings of the 3rd IWCS,
Tilburg.
Denys Duchier and Stefan Thater. 1999. Parsing with tree
descriptions: a constraint-based approach. In NLULP,
pages 17?32, Las Cruces, New Mexico.
R. Evans, G. Gazdar, and D. Weir. 1995. Encoding lexi-
calized tree adjoining grammars with a nonmonotonic in-
heritance hierarchy. In Proceedings of the 33rd Annual
Meeting of the ACL, 77-84.
B. Gaiffe, B. Crabbe, and A. Roussanaly. 2002. A new meta-
grammar compiler. In Proceedings of TAG+6, Venice.
C. Gardent and L. Kallmeyer. 2003. Semantic construction
in FTAG. In Proceedings of EACL?03, Budapest.
C. Gardent. 2006. Inte?gration d?une dimension se?mantique
dans les grammaires d?arbres adjoints. In Actes de La
13e`me e?dition de la confe?rence sur le TALN (TALN 2006).
A. Joshi and Y. Schabes. 1997. Tree-adjoining grammars.
In G. Rozenberg and A. Salomaa, editors, Handbook of
Formal Languages, volume 3, pages 69 ? 124. Springer,
Berlin, New York.
L. Kallmeyer. 1996. Tree description grammars. In Results
of the 3rd KONVENS Conference, pages 330 ? 341. Mou-
ton de Gruyter ed., Hawthorne, NY, USA.
H.-U. Krieger and U. Schafer. 1994. TDL ? a type descrip-
tion language for constraint-based grammars. In Proceed-
ings of COLING-94, pp. 893?899.
R. Muskens and E. Krahmer. 1998. Description theory, ltags
and underspecified semantics. In TAG?4.
G. Perrier. 2000. Interaction grammars. In Proceedings of
18th International Conference on Computational Linguis-
tics (CoLing 2000), Sarrebrcken.
G. Perrier. 2003. Les grammaires d?interaction. HDR en
informatique, Universite? Nancy 2.
K. Vijay-Shanker and Y. Schabes. 1992. Structure sharing
in lexicalized tree adjoining grammars. In Proceedings of
COLING?92, Nantes, pp. 205 - 212.
E. Villemonte de la Clergerie. 2005. DyALog: a tabular
logic programming based environment for NLP. In Pro-
ceedings of CSLP?05, Barcelona.
F. Xia, M. Palmer, and K. Vijay-Shanker. 1999. To-
ward semi-automating grammar development. In Proc. of
NLPRS-99, Beijing, China.
254
Proceedings of the ACL 2007 Demo and Poster Sessions, pages 13?16,
Prague, June 2007. c?2007 Association for Computational Linguistics
SemTAG: a platform for specifying Tree Adjoining Grammars and
performing TAG-based Semantic Construction
Claire Gardent
CNRS / LORIA
Campus scientifique - BP 259
54 506 Vand?uvre-Le`s-Nancy CEDEX
France
Claire.Gardent@loria.fr
Yannick Parmentier
INRIA / LORIA - Nancy Universite?
Campus scientifique - BP 259
54 506 Vand?uvre-Le`s-Nancy CEDEX
France
Yannick.Parmentier@loria.fr
Abstract
In this paper, we introduce SEMTAG, a free
and open software architecture for the de-
velopment of Tree Adjoining Grammars in-
tegrating a compositional semantics. SEM-
TAG differs from XTAG in two main ways.
First, it provides an expressive grammar
formalism and compiler for factorising and
specifying TAGs. Second, it supports se-
mantic construction.
1 Introduction
Over the last decade, many of the main grammatical
frameworks used in computational linguistics were
extended to support semantic construction (i.e., the
computation of a meaning representation from syn-
tax and word meanings). Thus, the HPSG ERG
grammar for English was extended to output mini-
mal recursive structures as semantic representations
for sentences (Copestake and Flickinger, 2000); the
LFG (Lexical Functional Grammar) grammars to
output lambda terms (Dalrymple, 1999); and Clark
and Curran?s CCG (Combinatory Categorial Gram-
mar) based statistical parser was linked to a seman-
tic construction module allowing for the derivation
of Discourse Representation Structures (Bos et al,
2004).
For Tree Adjoining Grammar (TAG) on the other
hand, there exists to date no computational frame-
work which supports semantic construction. In this
demo, we present SEMTAG, a free and open soft-
ware architecture that supports TAG based semantic
construction.
The structure of the paper is as follows. First,
we briefly introduce the syntactic and semantic for-
malisms that are being handled (section 2). Second,
we situate our approach with respect to other possi-
ble ways of doing TAG based semantic construction
(section 3). Third, we show how XMG, the linguistic
formalism used to specify the grammar (section 4)
differs from existing computational frameworks for
specifying a TAG and in particular, how it supports
the integration of semantic information. Finally, sec-
tion 5 focuses on the semantic construction module
and reports on the coverage of SEMFRAG, a core
TAG for French including both syntactic and seman-
tic information.
2 Linguistic formalisms
We start by briefly introducing the syntactic and se-
mantic formalisms assumed by SEMTAG namely,
Feature-Based Lexicalised Tree Adjoining Gram-
mar and LU .
Tree Adjoining Grammars (TAG) TAG is a tree
rewriting system (Joshi and Schabes, 1997). A TAG
is composed of (i) two tree sets (a set of initial trees
and a set of auxiliary trees) and (ii) two rewriting op-
erations (substitution and adjunction). Furthermore,
in a Lexicalised TAG, each tree has at least one leaf
which is a terminal.
Initial trees are trees where leaf-nodes are labelled
either by a terminal symbol or by a non-terminal
symbol marked for substitution (?). Auxiliary trees
are trees where a leaf-node has the same label as the
root node and is marked for adjunction (?). This
leaf-node is called a foot node.
13
Further, substitution corresponds to the insertion
of an elementary tree t1 into a tree t2 at a frontier
node having the same label as the root node of t1.
Adjunction corresponds to the insertion of an auxil-
iary tree t1 into a tree t2 at an inner node having the
same label as the root and foot nodes of t1.
In a Feature-Based TAG, the nodes of the trees are
labelled with two feature structures called top and
bot. Derivation leads to unification on these nodes as
follows. Given a substitution, the top feature struc-
tures of the merged nodes are unified. Given an
adjunction, (i) the top feature structure of the inner
node receiving the adjunction and of the root node of
the inserted tree are unified, and (ii) the bot feature
structures of the inner node receiving the adjunction
and of the foot node of the inserted tree are unified.
At the end of a derivation, the top and bot feature
structures of each node in a derived tree are unified.
Semantics (LU ). The semantic representation lan-
guage we use is a unification-based extension of the
PLU language (Bos, 1995). LU is defined as fol-
lows. Let H be a set of hole constants, Lc the set
of label constants, and Lv the set of label variables.
Let Ic (resp. Iv) be the set of individual constants
(resp. variables), let R be a set of n-ary relations
over Ic? Iv?H , and let ? be a relation over H ?Lc
called the scope-over relation. Given l ? Lc ? Lv,
h ? H , i1, . . . , in ? Iv ? Ic ?H , and Rn ? R, we
have:
1. l : Rn(i1, . . . , in) is a LU formula.
2. h ? l is a LU formula.
3. ?,? is LU formula iff both ? and ? are LU
formulas.
4. Nothing else is a LU formula.
In short, LU is a flat (i.e., non recursive) version
of first-order predicate logic in which scope may be
underspecified and variables can be unification vari-
ables1.
3 TAG based semantic construction
Semantic construction can be performed either dur-
ing or after derivation of a sentence syntactic struc-
ture. In the first approach, syntactic structure and
semantic representations are built simultaneously.
This is the approach sketched by Montague and
1For mode details on LU , see (Gardent and Kallmeyer,
2003).
adopted e.g., in the HPSG ERG and in synchronous
TAG (Nesson and Shieber, 2006). In the second
approach, semantic construction proceeds from the
syntactic structure of a complete sentence, from a
lexicon associating each word with a semantic rep-
resentation and from a set of semantic rules speci-
fying how syntactic combinations relate to seman-
tic composition. This is the approach adopted for
instance, in the LFG glue semantic framework, in
the CCG approach and in the approaches to TAG-
based semantic construction that are based on the
TAG derivation tree.
SEMTAG implements a hybrid approach to se-
mantic construction where (i) semantic construction
proceeds after derivation and (ii) the semantic lexi-
con is extracted from a TAG which simultaneously
specifies syntax and semantics. In this approach
(Gardent and Kallmeyer, 2003), the TAG used in-
tegrates syntactic and semantic information as fol-
lows. Each elementary tree is associated with a for-
mula of LU representing its meaning. Importantly,
the meaning representations of semantic functors in-
clude unification variables that are shared with spe-
cific feature values occurring in the associated ele-
mentary trees. For instance in figure 1, the variables
x and y appear both in the semantic representation
associated with the tree for aime (love) and in the
tree itself.
Given such a TAG, the semantics of a tree
t derived from combining the elementary trees
t1, . . . , tn is the union of the semantics of t1, . . . , tn
modulo the unifications that results from deriving
that tree. For instance, given the sentence Jean aime
vraiment Marie (John really loves Mary) whose
TAG derivation is given in figure 1, the union of the
semantics of the elementary trees used to derived the
sentence tree is:
l0 : jean(j), l1 : aime(x, y), l2 : vraiment(h0),
ls ? h0, l3 : marie(m)
The unifications imposed by the derivations are:
{x? j, y ? m, ls ? l1}
Hence the final semantics of the sentence Jean aime
vraiment Marie is:
l0 : jean(j), l1 : aime(j,m), l2 : vraiment(h0),
l1 ? h0, l3 : marie(m)
14
S[lab:l1]
NP[idx:j] NP[idx:x,lab:l1] V[lab:l1] NP
[idx:y,lab:l1] V[lab:l2] NP[idx:m]
Jean aime V[lab:ls]? Adv Marie
vraiment
l0 : jean(j) l1 : aimer(x, y) l2 : vraiment(h0), l3 : marie(m)
ls ? h0
Figure 1: Derivation of ?Jean aime vraiment Marie?
As shown in (Gardent and Parmentier, 2005), se-
mantic construction can be performed either dur-
ing or after derivation. However, performing se-
mantic construction after derivation preserves mod-
ularity (changes to the semantics do not affect syn-
tactic parsing) and allows the grammar used to re-
main within TAG (the grammar need contain nei-
ther an infinite set of variables nor recursive feature
structures). Moreover, it means that standard TAG
parsers can be used (if semantic construction was
done during derivation, the parser would have to be
adapted to handle the association of each elemen-
tary tree with a semantic representation). Hence in
SEMTAG, semantic construction is performed after
derivation. Section 5 gives more detail about this
process.
4 The XMG formalism and compiler
SEMTAG makes available to the linguist a formalism
(XMG) designed to facilitate the specification of tree
based grammars integrating a semantic dimension.
XMG differs from similar proposals (Xia et al, 1998)
in three main ways (Duchier et al, 2004). First it
supports the description of both syntax and seman-
tics. Specifically, it permits associating each ele-
mentary tree with an LU formula. Second, XMG pro-
vides an expressive formalism in which to factorise
and combine the recurring tree fragments shared by
several TAG elementary trees. Third, XMG pro-
vides a sophisticated treatment of variables which
inter alia, supports variable sharing between seman-
tic representation and syntactic tree. This sharing is
implemented by means of so-called interfaces i.e.,
feature structures that are associated with a given
(syntactic or semantic) fragment and whose scope
is global to several fragments of the grammar speci-
fication.
To specify the syntax / semantics interface
sketched in section 5, XMG is used as follows :
1. The elementary tree of a semantic functor is
defined as the conjunction of its spine (the projec-
tion of its syntactic head) with the tree fragments
describing each of its arguments. For instance, in
figure 2, the tree for an intransitive verb is defined
as the conjunction of the tree fragment for its spine
(Active) with the tree fragment for (a canonical re-
alisation of) its subject argument (Subject).
2. In the tree fragments representing the different
syntactic realizations (canonical, extracted, etc.) of
a given grammatical function, the node representing
the argument (e.g., the subject) is labelled with an
idx feature whose value is shared with a GFidx fea-
ture in the interface (where GF is the grammatical
function).
3. Semantic representations are encapsulated as
fragments where the semantic arguments are vari-
ables shared with the interface. For instance, the ith
argument of a semantic relation is associated with
the argI interface feature.
4. Finally, the mapping between grammatical
functions and thematic roles is specified when con-
joining an elementary tree fragment with a semantic
representation. For instance, in figure 22, the inter-
face unifies the value of arg1 (the thematic role) with
that of subjIdx (a grammatical function) thereby
specifying that the subject argument provides the
value of the first semantic argument.
5 Semantic construction
As mentioned above, SEMTAG performs semantic
construction after derivation. More specifically, se-
mantic construction is supported by the following 3-
step process:
2The interfaces are represented using gray boxes.
15
Intransitive: Subject: Active: 1-ary relation:
S
NP?[idx=X] VP
l0:Rel(X)
arg0=X
subjIdx=X
?
S
NP?[idx=I] VP
subjIdx=I
?
S
VP ? l0:Rel(A)
arg0=A
Figure 2: Syntax / semantics interface within the metagrammar.
1. First, we extract from the TAG generated by
XMG (i) a purely syntactic TAG G?, and (ii) a purely
semantic TAG G?? 3 A purely syntactic (resp. seman-
tic) Tag is a TAG whose features are purely syntactic
(resp. semantic) ? in other words, G?? is a TAG with
no semantic features whilst G?? is a TAG with only
semantic features. Entries of G? and G?? are indexed
using the same key.
2. We generate a tabular syntactic parser for G?
using the DyALog system of (de la Clergerie, 2005).
This parser is then used to compute the derivation
forest for the input sentence.
3. A semantic construction algorithm is applied to
the derivation forest. In essence, this algorithm re-
trieves from the semantic TAG G?? the semantic trees
involved in the derivation(s) and performs on these
the unifications prescribed by the derivation.
SEMTAG has been used to specify a core TAG for
French, called SemFRag. This grammar is currently
under evaluation on the Test Suite for Natural Lan-
guage Processing in terms of syntactic coverage, se-
mantic coverage and semantic ambiguity. For a test-
suite containing 1495 sentences, 62.88 % of the sen-
tences are syntactically parsed, 61.27 % of the sen-
tences are semantically parsed (i.e., at least one se-
mantic representation is computed), and the average
semantic ambiguity (number of semantic represen-
tation per sentence) is 2.46.
SEMTAG is freely available at http://trac.
loria.fr/?semtag.
3As (Nesson and Shieber, 2006) indicates, this extraction in
fact makes the resulting system a special case of synchronous
TAG where the semantic trees are isomorphic to the syntactic
trees and unification variables across the syntactic and semantic
components are interpreted as synchronous links.
References
J. Bos, S. Clark, M. Steedman, J. R. Curran, and J. Hock-
enmaier. 2004. Wide-coverage semantic representa-
tions from a ccg parser. In Proceedings of the 20th
COLING, Geneva, Switzerland.
J. Bos. 1995. Predicate Logic Unplugged. In Proceed-
ings of the tenth Amsterdam Colloquium, Amsterdam.
A. Copestake and D. Flickinger. 2000. An open-
source grammar development environment and broad-
coverage english grammar using hpsg. In Proceedings
of LREC, Athens, Greece.
Mary Dalrymple, editor. 1999. Semantics and Syntax in
Lexical Functional Grammar. MIT Press.
E. de la Clergerie. 2005. DyALog: a tabular logic pro-
gramming based environment for NLP. In Proceed-
ings of CSLP?05, Barcelona.
D. Duchier, J. Le Roux, and Y. Parmentier. 2004. The
Metagrammar Compiler: An NLP Application with
a Multi-paradigm Architecture. In Proceedings of
MOZ?2004, Charleroi.
C. Gardent and L. Kallmeyer. 2003. Semantic construc-
tion in FTAG. In Proceedings of EACL?03, Budapest.
C. Gardent and Y. Parmentier. 2005. Large scale se-
mantic construction for tree adjoining grammars. In
Proceedings of LACL05, Bordeaux, France.
A. Joshi and Y. Schabes. 1997. Tree-adjoining gram-
mars. In G. Rozenberg and A. Salomaa, editors,
Handbook of Formal Languages, volume 3, pages 69
? 124. Springer, Berlin, New York.
Rebecca Nesson and Stuart M. Shieber. 2006. Sim-
pler TAG semantics through synchronization. In Pro-
ceedings of the 11th Conference on Formal Grammar,
Malaga, Spain, 29?30 July.
F. Xia, M. Palmer, K. Vijay-Shanker, and J. Rosenzweig.
1998. Consistent grammar development using partial-
tree descriptions for lexicalized tree adjoining gram-
mar. Proceedings of TAG+4.
16
Proceedings of the 8th International Workshop on Tree Adjoining Grammar and Related Formalisms, pages 9?16,
Sydney, July 2006. c?2006 Association for Computational Linguistics
A constraint driven metagrammar
Joseph Le Roux
LORIA
Institut National
Polytechnique de Lorraine
615, Rue du Jardin Botanique
54 600 Villers-Le`s-Nancy
France
leroux@loria.fr
Beno??t Crabbe?
HCRC / ICCS
University of Edinburgh
2 Buccleuch Place
EH8 9LW,
Edinburgh, Scotland
bcrabbe@inf.ed.ac.uk
Yannick Parmentier
INRIA / LORIA
Universite? Henri Poincare?
615, Rue du Jardin Botanique
54 600 Villers-Le`s-Nancy
France
parmenti@loria.fr
Abstract
We present an operational framework al-
lowing to express a large scale Tree Ad-
joining Grammar (TAG) by using higher
level operational constraints on tree de-
scriptions. These constraints first meant
to guarantee the well formedness of the
grammatical units may also be viewed as
a way to put model theoretic syntax at
work through an efficient offline grammat-
ical compilation process. Our strategy pre-
serves TAG formal properties, hence en-
sures a reasonable processing efficiency.
1 Introduction
This paper is concerned with the semi-automatic
grammar development of real-scale grammars.
For natural language syntax, lexicalised TAGs are
made of thousands of trees, carrying an extreme
structural redundancy. Their development and
their maintenance is known to be cumbersome as
the size of the grammar raises significantly.
To counter the lack of generalisations inher-
ent to strong lexicalisation, various proposals for
semi-automatic grammar development have been
carried out: lexical rules or meta-rules (Becker,
2000) and metagrammars: (Candito, 1999; Gaiffe
et al, 2002; Xia, 2001). The aim of these frame-
works is twofold: expressing general facts about
the grammar of a language and factorising the in-
formation to avoid redundancy.
The metagrammar path adopts a different per-
spective from the lexical rule based grammar de-
velopment: instead of describing how a derived
tree is different from a canonical one, grammati-
cal description mainly consists of combining frag-
mentary tree descriptions or building blocks.
The paper is structured as follows. We start
in section 2 by providing motivations and back-
ground information on the framework we are us-
ing. Section 3 shows that the metagrammar frame-
work may be viewed as an offline system allowing
to express high level well-formedness constraints
on elementary grammatical structures while pre-
serving TAG computational and formal proper-
ties. Section 4 shows how to implement effi-
ciently this constraint-based approach with logic
programming techniques and finally section 5 pro-
vides an idea of the performance of the imple-
mented system.
2 eXtensible MetaGrammar (XMG)
By opposition to other metagrammatical frame-
works, XMG (Duchier et al, 2004) uses an expres-
sive though simple language, enabling a mono-
tonic description of a real scale grammar. Mono-
tonicity is important because it means that the or-
der of application of the different operations does
not matter. This is the major drawback of lexical-
rule systems. Moreover, (Crabb e?, 2005b) shows
that it is sufficiently expressive to implement con-
veniently a core TAG for French.
XMG allows the grammar writer to manipulate
tree descriptions through a control language. The
intuition behind is that a metagrammatical lan-
guage needs to provide means to describe syn-
tactic information along two methodological axis
(Crabb e?, 2005b): structure sharing and alterna-
tives. Structure sharing is the axis dedicated to
express factorisation in the grammar, whereas al-
ternatives allow to express regular alternation re-
lationships such as alternatives between the rep-
resentation of a canonical nominal subject and its
interrogative representation, or between an active
9
and a passive verb form1.
Building on this intuition the XMG language al-
lows the user to name partial tree descriptions
within classes. The name of the class can be ma-
nipulated afterwards. For instance the following
tree descriptions on the right of the arrow are as-
sociated with the names stated on the left of the
arrow2:
(1) a. CanonicalSubject ?
S
N? V
b. RelativisedSubject ?
N
N* S
N? V
c. VerbalForm ?
S
V
Naming is the main device that allows the gram-
mar writer to express and to take advantage of the
structure sharing axis mentioned above. Indeed
class names can be reused in other descriptions.
Thus names can also be used to describe alterna-
tives. To express, in our simplified example, that a
Subject is an abstract way to name a Relativised-
Subject or a CanonicalSubject, we use a choice op-
erator (?) as illustrated below:
(2) Subject ? CanonicalSubject
? RelativisedSubject
Disjunction (non-deterministic choice) is the de-
vice provided by the language to express the
methodological axis of alternatives.
Finally, names can be given to class combina-
tions. To express the composition of two tree de-
scriptions in the language, we use the ? operator.
1The passive is a semi-regular alternation, many transi-
tive verbs do not passivise. Our system presupposes a classi-
cal architecture for the computational representation of Tree
Adjoining Grammars such as XTAG, where means to ex-
press such exceptions during the anchoring process are well-
known. In what follows, we therefore consider only tree tem-
plates (or tree schematas) as our working units. Finally the
trees depicted in this paper take their inspiration from the
grammar described by (Abeill e?, 2002).
2To represent the tree descriptions mentioned in this pa-
per, we use a graphical notation. Immediate dominance is de-
picted with a straight line and precedence follows the graphi-
cal order. Note that nodes are decorated with their labels only,
ignoring the names of the variables denoting them. Note also
that we use only the reflexive transitive closure of precedence
between sibling nodes and it is explicitly stated with the sym-
bol ??.
Thus we can say that an IntransitiveVerb is made
by the composition of a Subject and a VerbalForm
as follows:
(3) IntransitiveVerb ? Subject ? VerbalForm
Given these 3 primitives, the control language
is naturally interpreted as a context free grammar
whose terminals are tree descriptions and where
our composition plays the role of concatenation.
This abstract grammar or metagrammar is further
restricted to be non recursive in order to ensure
that the generated TAG is finite.
Provided the axiom IntransitiveVerb, an inter-
preter for this language generates non determinis-
tically all the sentences of the grammar3 underly-
ing a grammatical description. Thus in our current
example the two sentences generated are those de-
picted on the left hand side of the arrows in Figure
1. On the right hand side of the arrow is depicted
the result of the composition of the tree descrip-
tions.
It remains to make clear what is actually this
composition. The grammatical classes may con-
tain information on tree descriptions and/or ex-
press composition of descriptions stated in other
classes. Tree descriptions take their inspiration
from the logic described in (Rogers and Vijay-
Shanker, 1994). Its syntax is the following:
Description ::= x ? y | x ?? y |
x ? y | x ?? y |
x[f :E]
where x, y are node variables, ? the dominance
relation, ? the precedence relation, ? denoting the
reflexive transitive closure of a relation. The last
line associates x with a feature f whose value is
the result of evaluating expression E.
Tree descriptions are interpreted as finite linear
ordered trees being the minimal models of the de-
scription.
Using tree descriptions, the above mentioned
operation of tree ?composition? breaks down to a
conjunction of formulas where variables of each
conjunct are in first approximation renamed to
avoid name collisions. Renaming is a crucial dif-
ference with previous approaches to metagrammar
(Candito, 1999; Xia, 2001) where the user had to
manage explicitly a ?global namespace?. Here a
specific attention is given to namespace manage-
ment, because this was a bottleneck for real scale
3Understood as compositions of tree fragments.
10
SN? V
Le garc?on. . .
The boy. . .
?
S
V
dort
sleeps
?
S
N? V
Le garc?on dort
The boy who sleeps
N
N* S
N? V
(Le garc?on) qui. . .
(The boy) who. . .
?
S
V
dort
sleeps
?
N
N* S
N? V
Le garc?on qui dort
The boy who sleeps
Figure 1: Interpretation of a grammatical description
grammar design. More precisely each class has
its own namespace of identifiers and namespace
merging can be triggered when a class combina-
tion occurs. This merging relies on a fine-grained
import/export mechanism.
In addition to conjunction and disjunction, XMG
is augmented with syntactic sugar to offer some
of the features other metagrammatical formalisms
propose. For instance, inheritance of classes is not
built-in in the core language but is realised through
conjunction and namespace import. Of course,
this restricts users to monotonic inheritance (spe-
cialisation) but it seems to be sufficient for most
linguists.
3 Constraining admissible structures
XMG has been tested against the development of a
large scale French Grammar (Crabb e?, 2005a). To
ease practical grammatical development we have
added several augmentations to the common tree
description language presented so far in order to
further restrict the class of admissible structures
generated by the metagrammar.
Further constraining the structures generated by
a grammar is a common practice in computational
linguistics. For instance a Lexical Functional
Grammar (Bresnan and Kaplan, 1982) further re-
stricts the structures generated by the grammar by
means of a functional uniqueness and a functional
completeness principles. These constraints further
restricts the class of admissible structures gener-
ated by an LFG grammar to verify valency condi-
tions.
For TAG and in a theoretical context, (Frank,
2002) states a set of such well formedness prin-
ciples that contribute to formulate a TAG theory
within a minimalist framework. In what remains
we describe operational constraints of this kind
that further restrict the admissibility of the struc-
ture generated by the metagrammar. By contrast
with the principles stated by (Frank, 2002), we
do not make any theoretical claim, instead we
are stating operational constraints that have been
found useful in practical grammar development.
However as already noted by (Frank, 2002) and
by opposition to an LFG framework where con-
straints apply to the syntactic structure of a sen-
tence as a whole, we formulate here constraints on
the well-formedness of TAG elementary trees. In
other words these constraints apply to units that
define themselves their own global domain of lo-
cality. In this case, it means that we can safely
ignore locality issues while formulating our con-
straints. This is theoretically weaker than formu-
lating constraints on the whole sentential structure
but this framework allows us to generate common
TAG units, preserving the formal and computa-
tional properties of TAG.
We formulate this constraint driven framework
by specifying conditions on model admissibility.
Methodologically the constraints used in the de-
velopment of the French TAG can be classified
in four categories: formal constraints, operational
constraints, language dependent constraints and
theoretical principles.
First the formal constraints are those constrain-
ing the trees generated by the model builder to
be regular TAG trees. These constraints require
the trees to be linear ordered trees with appropri-
ate decorations : each node has a category label,
leaf nodes are either terminal, foot or substitution,
there is at most one foot node, the category of the
foot note is identical to that of the root node, each
tree has at least one leaf node which is an anchor.
11
It is worth noting here that using a different set
of formal constraints may change the target for-
malism. Indeed XMG provides a different set of
formal constraints (not detailed here) that allow to
generate elementary units for another formalism,
namely Interaction Grammars.
The second kind of constraint is a single op-
erational constraint dubbed the colouration con-
straint. We found it convenient in the course
of grammar development. It consists of associ-
ating colour-based polarities to the nodes to en-
sure a proper combination of the fragmentary
tree descriptions stated within classes. Since in
our framework descriptions stated in two different
classes are renamed before being conjoined, given
a formula being the conjunction of the two follow-
ing tree descriptions :
(4)
X
W Z
X
Z Y
both the following trees are valid models of that
formula:
(5) (a)
X
W Z Y (b)
X
W Z Z Y
In the context of grammar development, however,
only (a) is regarded as a desired model. To rule out
(b) (Candito, 1999; Xia, 2001) use a naming con-
vention that can be viewed as follows4: they assign
a name to every node of the tree description. Both
further constrain model admissibility by enforcing
the identity of the interpretation of two variables
associated to the same name. Thus the description
stated in their systems can be exemplified as fol-
lows:
(6)
Xa
Wb Zc
Xa
Zc Yd
Though solving the initial formal problem, this de-
sign choice creates two additional complications:
(1) it constrains the grammar writer to manually
manage a global naming, entailing obvious prob-
lems as the size of the grammatical description
grows and (2) it prevents the user to reuse sev-
eral times the same class in a composition. This
case is a real issue in the context of grammati-
cal development since a grammar writer willing
to describe a ditransitive context with two prepo-
sitional phrases cannot reuse two times a fragment
4They actually use a different formal representation that
does not affect the present discussion.
describing such a PP since the naming constraint
will identify them.
To solve these problems we use a colouration
constraint. This constraint associates unary prop-
erties, colours, to every node of the descriptions.
A colour is taken among the set red(?R), black(?B ),
white (?W). A valid model is a model in which ev-
ery node is coloured either in red or black. Two
variables in the description interpreted by the same
node have their colours merged following the table
given in Figure 2.
?B ?R ?W ?
?B ? ? ?B ?
?R ? ? ? ?
?W ?B ? ?W ?
? ? ? ? ?
Figure 2: Colour identification rules.
The table indicates the resulting colour after
a merge. The ? symbol indicates that this two
colours cannot be merged and hence two nodes la-
belled with these colours cannot be merged. Note
that the table is designed to ensure that merging is
not a procedural operation.
The idea behind colouration is that of saturat-
ing the tree description. The colour white repre-
sents the non saturation or the need of a node to
be combined with a resource, represented by the
colour black. Black nodes need not necessarily
be combined with other nodes. Red is the colour
used to label nodes that cannot be merged with
any other node. A sample tree description with
coloured node is as follows:
(7)
X?B
W?R Z?B
X?W
Z?W Y?R
Colours contribute to rule out the (b) case and re-
move the grammar writer the burden of managing
manually a ?global namespace?.
The third category of constraints are language
dependent constraints. In the case of French, such
constraints are clitic ordering, islands constraints,
etc. We illustrate these constraints with clitic or-
dering in French. In French clitics are non tonic
particles with two specific properties already iden-
tified by (Perlmutter, 1970): first they appear in
front of the verb in a fixed order according to their
rank (8a-8b) and second two different clitics in
front of the verb cannot have the same rank (8c).
For instance the clitics le, la have the rank 3 and
lui the rank 4.
12
SN? V??+ ?
V?
Cl?3 V?+ ?
V?
Cl?4 V?+ ?
S
V?
V ?
S
N? V?
Cl?3 Cl?4 V
S
N? V?
Cl?4 Cl?3 V
Figure 3: Clitic ordering
(8) a. Jean le3 lui4 donne
John gives it to him
b. *Jean lui4 le3 donne
*John gives to him it
c. *Jean le3 la3 donne
*John gives it it
In the French grammar of (Crabb e?, 2005a) trees
with clitics are generated with the fragments illus-
trated on the left of the arrow in Figure 35. As
illustrated on the right of the arrow, the composi-
tion may generate ill-formed trees. To rule them
out we formulate a clitic ordering constraint. Each
variable labelled with a clitic category is also la-
belled with a property, an integer representing its
rank. The constraint stipulates that sibling nodes
labelled with a rank have to be linearly ordered ac-
cording to the order defined over integers.
Overall language dependent constraints handle
cases where the information independently spec-
ified in different fragments may interact. These
interactions are a counterpart in a metagrammar to
the interactions between independently described
lexical rules in a lexical rule based system. As-
suming independent lexical rules moving canoni-
cal arguments (NP or PP) to their clitic position,
lexical rules fall short for capturing the relative or-
dering among clitics6 .
A fourth category of constraints, not imple-
mented in our system so far are obviously the lan-
guage independent principles defining the theory
underlying the grammar. Such constraints could
involve for instance a Principle of Predicate Argu-
ment Coocurrency (PPAC) or even the set of min-
imalist principles described by (Frank, 2002).
4 Efficient implementation
We describe now the implementation of our meta-
grammatical framework. In particular, we will fo-
5Colours are omitted.
6This observation was already made by (Perlmutter, 1970)
in a generative grammar framework where clitics where as-
sumed to be moved by transformations.
cus on the implementation of the constraints dis-
cussed above within XMG.
As mentioned above, a metagrammar corre-
sponds to a reduced description of the grammar.
In our case, this description consists of tree frag-
ments combined either conjunctively or disjunc-
tively. These combinations are expressed using
a language close to the Definite Clause Grammar
formalism (Pereira and Warren, 1980), except that
partial tree descriptions are used as terminal sym-
bols. In this context, a metagrammar can be re-
duced to a logic program whose execution will
lead to the computation of the trees of the gram-
mar.
To perform this execution, a compiler for our
metagrammatical language has been implemented.
This compilation is a 3-step process as shown in
Figure 4.
First, the metagrammar is compiled into in-
structions for a specific virtual machine inspired
by the Warren?s Abstract Machine (Ait-Kaci,
1991). These instructions correspond to the un-
folding of the relations7 contained in the tree de-
scriptions of the metagrammar.
Then, the virtual machine performs unifications
of structures meant to refer to corresponding in-
formation within fragments (e.g. two nodes, two
feature structures ...). Note that the XMG?s virtual
machine uses the structure sharing technique for
memory management, i.e. data are represented by
a pair pattern ? environment in which to interpret
it. The consequences are that (a) we save mem-
ory when compiling the metagrammar, and (b) we
have to perform pointer dereferencing during uni-
fication. Even if the latter is time-consuming, it
remains more efficient than structure copying as
we have to possibly deal with a certain amount of
tree descriptions.
Eventually, as a result of this instruction pro-
cessing by the virtual machine, we obtain poten-
7These relations are either dominance or precedence be-
tween node variables, or their reflexive transitive closure, or
the labelling of node variable with feature structures.
13
STEP1
(translation of concrete syntax)
INTO INSTRUCTIONS
CONCRETE SYNTAX
METAGRAMMATICAL
COMPILATION OF 
TREE DESCRIPTION SOLVING
STEP3
(unification of data structures)
STEP2
A SPECIFIC VIRTUAL MACHINE
INSTRUCTIONS BY
EXECUTION OF THE 
INPUT: MetaGrammar
Total tree descriptions OUTPUT: TAGCompiled partial tree descriptions
Figure 4: Metagrammar compilation.
tially total tree descriptions, that have to be solved
in order to produce the expected TAG.
Now, we will introduce XMG?s tree description
solver and show that it is naturally designed to pro-
cess efficiently the higher level constraints men-
tioned above. In particular, we will see that the
description solver has been designed to be easily
extended with additional parametric admissibility
constraints.
4.1 Tree descriptions solving
To find the minimal models corresponding to the
total tree descriptions obtained by accumulating
fragmentary tree descriptions, we use a tree de-
scription solver. This solver has been developed in
the Constraint Programming paradigm using the
constraint satisfaction approach of (Duchier and
Niehren, 2000). The idea is to translate relations
between node variables into constraints over sets
of integers.
Basically, we refer to a node of the input de-
scription in terms of the nodes being equals,
above, below, or on its side (see Figure 5). More
precisely, we associate each node of the descrip-
tion with an integer, then our reference to a node
corresponds to a tuple containing sets of nodes (i.e.
sets of integers).
As a first approximation, let us imagine that we
refer to a node x in a model by means of a 5-tuple
N ix = (Eq, Up, Down, Left, Right) where i is an in-
teger associated with x and Eq (respectively Up,
Down, Left, Right) denotes the set of nodes8 in the
description which are equal, (respectively above,
below, left, and right) of x.
Then we can convert the relations between
nodes of our description language into constraints
on sets of integer.
8I.e. integers.
Eq
Up
Down
Left
Right
Figure 5: Node representation.
For instance, if we consider 2 nodes x and y of
the description. Assuming we associate x with the
integer i and y with j, we can translate the domi-
nance relation x ? y the following way9:
N ix? N jy?
[N ix.EqUp ? N jy.Up?N ix.Down ? N jy.EqDown
?N ix.Left ? N jy.Left?N ix.Right ? N
j
y.Right]
This means that if the node10 x strictly dominates
y in the input description, then (i) the set of nodes
that are above or equal x in a valid model is in-
cluded in the set of those that are strictly above y
and (ii) the dual holds for the nodes that are above
and (iii) the set of nodes that are on the left of y is
included in the set of those that are on the left of x
and (iv) similarly for the right part.
Once the constraints framework is settled, we
can search for the solutions to our problem, i.e.
the variable assignments for each of the sets of in-
tegers used to refer to the nodes of the input de-
scription. This search is performed by associating
with each pair of nodes (x, y) of the input descrip-
tion a choice variable denoting the mutually ex-
clusive relations11 between these two nodes. Then
9N ix.EqUp corresponds to the disjoint union of N ix.Eq and
N ix.Up, similarly for N jx.EqDown with N
i
x.Eq and N ix.Down.
10One should read the node denoted by the variable x.
11Either x equals y, x dominates y, y dominates x, x pre-
cedes y or y precedes x.
14
we use a search strategy to explore the consistent
assignments to these choices variables (and the as-
sociated assignments for sets of integers referring
to nodes)12 . Note that the strategy used in XMG
is a first-fail strategy which leads to very good re-
sults (see section 5 below). The implementation
of this solver has been done using the constraint
programming support of the Mozart Programming
System (The Oz-Mozart Board, 2005).
4.2 Extension to higher-level constraints
solving
An important feature of our approach is that this
system of constraints over integer sets can be
extended so that we not only ensure tree well-
formedness of the outputted trees, but also the re-
spect of linguistic properties such as the unique-
ness of clitics in French, etc.
The idea is that if we extend adequately our
node representation, we can find additional con-
straints that reflects the syntactic constraints we
want to express.
Clitic uniqueness For instance, let us consider
the clitic uniqueness constraint introduced above.
We want to express the fact that in a valid model
?, there is only one node having a given property
p (i.e. a parameter of the constraint, here the cat-
egory clitic13). This can be done by introducing,
for each node x of the description, a boolean vari-
able px indicating whether the node denoting x in
the model has this property or not. Then, if we call
V?p the set of integers referring to nodes having the
property p in a model, we have:
px ? (N ix.Eq ? V?p ) 6= ?
Finally, if we represent the true value with the in-
teger 1 and false with 0, we can sum the px for
each x in the model. When this sum gets greater
than 1, we can consider that we are not building a
valid model.
Colouration constraint Another example of the
constraints introduced in section 3 is coloura-
tion. Colouration represents operational con-
straints whose effect is to control tree fragment
combination. The idea is to label nodes with a
colour between red, black and white. Then, during
12More information about the use of such choice variables
is given in (Duchier, 1999)
13In fact, the uniqueness concerns the rank of the clitics,
see (Crabb e?, 2005b), ?9.6.3.
description solving, nodes are identified according
to the rules given previously (see Figure 2).
That is, red nodes are not identified with any
other node, white nodes can be identified with a
black one. Black nodes are not identified with
each other. A valid model in this context is a satu-
rated tree, i.e. where nodes are either black (possi-
bly resulting from identifications) or red. In other
words, for every node in the model, there is at most
one red or black node with which it has been iden-
tified. The implementation of such a constraint
is done the following way. First, the tuples rep-
resenting nodes are extended by adding a integer
field RB referring to the red or black node with
which the node has been identified. Then, con-
sidering the following sets of integers: VR, VB,
VW respectively containing the integers referring
to red, black and white nodes in the input descrip-
tion, the following constraints hold:
x ? VR ? N ix.RB = i ? N ix.Eq = {i} (a)
x ? VB ? N ix.RB = i (b)
x ? VW ? N ix.RB ? V?B (c)
where V?B represents the black nodes in a model,
i.e. V?B = V? ? VB. (a) expresses the fact that for
red nodes, N ix.RB is the integer i associated with
x itself, and N ix.Eq is a set only containing i. (b)
means that for black nodes, we have that N ix.RB is
also the integer i denoting x itself, but we cannot
say anything about N ix.Eq. Eventually (c) means
that whites nodes have to be identified with a black
one.
Thus, we have seen that Constraint Program-
ming offers an efficient and relatively natural way
of representing syntactic constraints, as ?all? that
has to be done is to find an adequate node repre-
sentation in terms of sets of nodes, then declare the
constraints associated with these sets, and finally
use a search strategy to compute the solutions.
5 Some features
There are two points worth considering here: (i)
the usability of the formalism to describe a real
scale grammar with a high factorisation, and (ii)
the efficiency of the implementation in terms of
time and memory use.
Concerning the first point, XMG has been used
successfully to compute a TAG having more than
6,000 trees from a description containing 293
15
classes14 . Moreover, this description has been de-
signed relatively quickly as the description lan-
guage is intuitive as advocated in (Crabb e?, 2005a).
Concerning the efficiency of the system, the
compilation of this TAG with more than 6,000 trees
takes about 15 min with a P4 processor 2.6 GHz
and 1 GB RAM. Note that compared with the
compilation time of previous approaches (Candito,
1999; Gaiffe et al, 2002) (with the latter, a TAG of
3,000 trees was compiled in about an hour), these
results are quite encouraging.
Eventually, XMG is released under the terms of
the GPL-like CeCILL license15 and can be freely
downloaded at http://sourcesup.cru.fr/xmg.
6 Conclusion
Unlike previous approaches, the description lan-
guage implemented by XMG is fully declara-
tive, hence allowing to reuse efficient techniques
borrowed to Logic Programming. The system
has been used successfully to produce core TAG
(Crabb e?, 2005b) and Interaction Grammar (Per-
rier, 2003) for French along with a core French
TAG augmented with semantics (Gardent, 2006).
This paper shows that the metagrammar can be
used to put model theoretic syntax at work while
preserving reasonably efficient processing proper-
ties. The strategy used here builds on constraining
offline a TAG whose units are elementary trees The
other option is to formulate constraints applied
on-line, in the course of parsing, applying on the
whole syntactic structure. In a dependency frame-
work, XDG followed this path (Debusmann et al,
2004), however it remains unknown to us whether
this approach remains computationally tractable
for parsing with real scale grammars.
References
A. Abeill e?. 2002. Une grammaire e?lectronique du franais.
CNRS Editions, Paris.
H. Ait-Kaci. 1991. Warren?s abstract machine: A tuto-
rial reconstruction. In K. Furukawa, editor, Proc. of the
Eighth International Conference of Logic Programming.
MIT Press, Cambridge, MA.
T. Becker. 2000. Patterns in metarules. In A. Abeille and
O. Rambow, editors, Tree Adjoining Grammars: formal,
computational and linguistic aspects. CSLI publications,
Stanford.
14I.e. tree fragments or conjunction / disjunction of frag-
ments
15More information about this license at http://www.
cecill.info/index.en.html.
Joan Bresnan and Ronal M. Kaplan. 1982. The Mental Rep-
resentation of Grammatical Relations. The MIT Press,
Cambridge MA.
M.H. Candito. 1999. Repre?sentation modulaire et
parame?trable de grammaires e?lectroniques lexicalise?es :
application au franc? ais et a` l?italien. Ph.D. thesis, Uni-
versit e? Paris 7.
B. Crabb e?. 2005a. Grammatical development with XMG.
Proceedings of the Fifth International Conference on Log-
ical Aspects of Computational Linguistics (LACL05).
B. Crabb e?. 2005b. Repre?sentation informatique de gram-
maires fortement lexicalise?es : Application a` la gram-
maire d?arbres adjoints. Ph.D. thesis, Universit e? Nancy
2.
R. Debusmann, D. Duchier, and G.-J. M. Kruijff. 2004. Ex-
tensible dependency grammar: A new methodology. In
Proceedings of the COLING 2004 Workshop on Recent
Advances in Dependency Grammar, Geneva/SUI.
D. Duchier and J. Niehren. 2000. Dominance constraints
with set operators. In Proceedings of CL2000, volume
1861 of Lecture Notes in Computer Science, pages 326?
341. Springer.
D. Duchier, J. Le Roux, and Y. Parmentier. 2004. The Meta-
grammar Compiler: An NLP Application with a Multi-
paradigm Architecture. In 2nd International Mozart/Oz
Conference (MOZ?2004), Charleroi.
D. Duchier. 1999. Set constraints in computational linguis-
tics - solving tree descriptions. In Workshop on Declara-
tive Programming with Sets (DPS?99), Paris, pp. 91 - 98.
Robert Frank. 2002. Phrase Structure Composition and Syn-
tactic Dependencies. MIT Press, Boston.
B. Gaiffe, B. Crabb e?, and A. Roussanaly. 2002. A new meta-
grammar compiler. In Proceedings of TAG+6, Venice.
C. Gardent. 2006. Int e?gration d?une dimension s e?mantique
dans les grammaires d?arbres adjoints. In Actes de La
13e`me e?dition de la confe?rence sur le TALN (TALN 2006).
F. Pereira and D. Warren. 1980. Definite clause grammars
for language analysis ?a survey of the formalism and a
comparison to augmented transition networks. Artificial
Intelligence, 13:231?278.
David Perlmutter. 1970. Surface structure constraints in syn-
tax. Linguistic Inquiry, 1:187?255.
Guy Perrier. 2003. Les grammaires d?interaction. HDR en
informatique, Universit e? Nancy 2.
J. Rogers and K. Vijay-Shanker. 1994. Obtaining trees from
their descriptions: An application to tree-adjoining gram-
mars. Computational Intelligence, 10:401?421.
The Oz-Mozart Board. 2005. The Oz-Mozart Programming
System. http://www.mozart-oz.org.
Fei Xia. 2001. Automatic Grammar Generation from two
Different Perspectives. Ph.D. thesis, University of Penn-
sylvania.
16
Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 9?12,
Suntec, Singapore, 4 August 2009.
c
?2009 ACL and AFNLP
An Earley Parsing Algorithm for Range Concatenation Grammars
Laura Kallmeyer
SFB 441
Universit?at T?ubingen
72074 T?ubingen, Germany
lk@sfs.uni-tuebingen.de
Wolfgang Maier
SFB 441
Universit?at T?ubingen
72074 T?ubingen, Germany
wo.maier@uni-tuebingen.de
Yannick Parmentier
CNRS - LORIA
Nancy Universit?e
54506 Vand?uvre, France
parmenti@loria.fr
Abstract
We present a CYK and an Earley-style
algorithm for parsing Range Concatena-
tion Grammar (RCG), using the deduc-
tive parsing framework. The characteris-
tic property of the Earley parser is that we
use a technique of range boundary con-
straint propagation to compute the yields
of non-terminals as late as possible. Ex-
periments show that, compared to previ-
ous approaches, the constraint propagation
helps to considerably decrease the number
of items in the chart.
1 Introduction
RCGs (Boullier, 2000) have recently received a
growing interest in natural language processing
(S?gaard, 2008; Sagot, 2005; Kallmeyer et al,
2008; Maier and S?gaard, 2008). RCGs gener-
ate exactly the class of languages parsable in de-
terministic polynomial time (Bertsch and Neder-
hof, 2001). They are in particular more pow-
erful than linear context-free rewriting systems
(LCFRS) (Vijay-Shanker et al, 1987). LCFRS is
unable to describe certain natural language phe-
nomena that RCGs actually can deal with. One
example are long-distance scrambling phenom-
ena (Becker et al, 1991; Becker et al, 1992).
Other examples are non-semilinear constructions
such as case stacking in Old Georgian (Michaelis
and Kracht, 1996) and Chinese number names
(Radzinski, 1991). Boullier (1999) shows that
RCGs can describe the permutations occurring
with scrambling and the construction of Chinese
number names.
Parsing algorithms for RCG have been intro-
duced by Boullier (2000), who presents a di-
rectional top-down parsing algorithm using pseu-
docode, and Barth?elemy et al (2001), who add an
oracle to Boullier?s algorithm. The more restricted
class of LCFRS has received more attention con-
cerning parsing (Villemonte de la Clergerie, 2002;
Burden and Ljungl?of, 2005). This article proposes
new CYK and Earley parsers for RCG, formulat-
ing them in the framework of parsing as deduction
(Shieber et al, 1995). The second section intro-
duces necessary definitions. Section 3 presents a
CYK-style algorithm and Section 4 extends this
with an Earley-style prediction.
2 Preliminaries
The rules (clauses) of RCGs
1
rewrite predicates
ranging over parts of the input by other predicates.
E.g., a clause S(aXb)? S(X) signifies that S is
true for a part of the input if this part starts with an
a, ends with a b, and if, furthermore, S is also true
for the part between a and b.
Definition 1. A RCG G = ?N,T, V, P, S? con-
sists of a) a finite set of predicates N with an arity
function dim: N ? N \ {0} where S ? N is
the start predicate with dim(S) = 1, b) disjoint fi-
nite sets of terminals T and variables V , c) a finite
set P of clauses ?
0
? ?
1
. . . ?
m
, where m ? 0
and each of the ?
i
, 0 ? i ? m, is a predicate of
the form A
i
(?
1
, . . . , ?
dim(A
i
)
) with A
i
? N and
?
j
? (T ? V )
?
for 1 ? j ? dim(A
i
).
Central to RCGs is the notion of ranges on
strings.
Definition 2. For every w = w
1
. . . w
n
with
w
i
? T (1 ? i ? n), we define a) Pos(w) =
{0, . . . , n}. b) ?l, r? ? Pos(w) ? Pos(w) with
l ? r is a range in w. Its yield ?l, r?(w) is the
substring w
l+1
. . . w
r
. c) For two ranges ?
1
=
?l
1
, r
1
?, ?
2
= ?l
2
, r
2
?: if r
1
= l
2
, then ?
1
? ?
2
=
?l
1
, r
2
?; otherwise ?
1
? ?
2
is undefined. d) A vec-
tor ? = (?x
1
, y
1
?, . . . , ?x
k
, y
k
?) is a range vector
of dimension k in w if ?x
i
, y
i
? is a range in w for
1 ? i ? k. ?(i).l (resp. ?(i).r) denotes then the
1
In this paper, by RCG, we always mean positive RCG,
see Boullier (2000) for details.
9
first (resp. second) component of the ith element
of ?, that is x
i
(resp. y
i
).
In order to instantiate a clause of the grammar,
we need to find ranges for all variables in the
clause and for all occurrences of terminals. For
convenience, we assume the variables in a clause
and the occurrences of terminals to be equipped
with distinct subscript indices, starting with 1 and
ordered from left to right (where for variables,
only the first occurrence is relevant for this order).
We introduce a function ? : P ? N that gives the
maximal index in a clause, and we define ?(c, x)
for a given clause c and x a variable or an occur-
rence of a terminal as the index of x in c.
Definition 3. An instantiation of a c ? P with
?(c) = j w.r.t. to some string w is given by a
range vector ? of dimension j. Applying ? to
a predicate A(~?) in c maps all occurrences of
x ? (T ? V ) with ?(c, x) = i in ~? to ?(i). If
the result is defined (i.e., the images of adjacent
variables can be concatenated), it is called an in-
stantiated predicate and the result of applying ? to
all predicates in c, if defined, is called an instanti-
ated clause.
We also introduce range constraint vectors, vec-
tors of pairs of range boundary variables together
with a set of constraints on these variables.
Definition 4. Let V
r
= {r
1
, r
2
, . . . } be a set
of range boundary variables. A range constraint
vector of dimension k is a pair ?~?, C? where a)
~? ? (V
2
r
)
k
; we define V
r
(~?) as the set of range
boundary variables occurring in ~?. b) C is a set
of constraints c
r
that have one of the following
forms: r
1
= r
2
, k = r
1
, r
1
+ k = r
2
,
k ? r
1
, r
1
? k, r
1
? r
2
or r
1
+ k ? r
2
for r
1
, r
2
? V
r
(~?) and k ? N.
We say that a range vector ? satisfies a range
constraint vector ??, C? iff ? and ? are of the same
dimension k and there is a function f : V
r
? N
that maps ?(i).l to ?(i).l and ?(i).r to ?(i).r for
all 1 ? i ? k such that all constraints in C are sat-
isfied. Furthermore, we say that a range constraint
vector ??, C? is satisfiable iff there exists a range
vector ? that satisfies it.
Definition 5. For every clause c, we define its
range constraint vector ??, C? w.r.t. aw with |w| =
n as follows: a) ? has dimension ?(c) and all
range boundary variables in ? are pairwise differ-
ent. b) For all ?r
1
, r
2
? ? ?: 0 ? r
1
, r
1
? r
2
,
r
2
? n ? C. For all occurrences x of terminals
in cwith i = ?(c, x): ?(i).l+1 = ?(i).r ? C. For
all x, y that are variables or occurrences of termi-
nals in c such that xy is a substring of one of the
arguments in c: ?(?(c, x)).r = ?(?(c, y)).l ? C.
These are all constraints in C.
The range constraint vector of a clause c cap-
tures all information about boundaries forming a
range, ranges containing only a single terminal,
and adjacent variables/terminal occurrences in c.
An RCG derivation consists of rewriting in-
stantiated predicates applying instantiated clauses,
i.e. in every derivation step ?
1
?
w
?
2
, we re-
place the lefthand side of an instantiated clause
with its righthand side (w.r.t. a word w). The lan-
guage of an RCG G is the set of strings that can
be reduced to the empty word: L(G) = {w |
S(?0, |w|?)
+
?
G,w
?}.
The expressive power of RCG lies beyond mild
context-sensitivity. As an example, consider the
RCG from Fig. 3 that generates a language that is
not semilinear.
For simplicity, we assume in the following with-
out loss of generality that empty arguments (?)
occur only in clauses whose righthand sides are
empty.
2
3 Directional Bottom-Up Chart Parsing
In our directional CYK algorithm, we move a dot
through the righthand side of a clause. We there-
fore have passive items [A, ?] where A is a pred-
icate and ? a range vector of dimension dim(A)
and active items. In the latter, while traversing
the righthand side of the clause, we keep a record
of the left and right boundaries already found
for variables and terminal occurrences. This is
achieved by subsequently enriching the range con-
straint vector of the clause. Active items have the
form [A(~x)? ? ??, ??, C?] with A(~x)? ?? a
clause, ?? 6= ?, ?(A(~x ? ??)) = j and ??, C?
a range constraint vector of dimension j. We re-
quire that ??, C? be satisfiable.
3
2
Any RCG can be easily transformed into an RCG satis-
fying this condition: Introduce a new unary predicate Eps
with a clause Eps(?) ? ?. Then, for every clause c with
righthand side not ?, replace every argument ? that occurs in
c with a new variable X (each time a distinct one) and add
the predicate Eps(X) to the righthand side of c.
3
Items that are distinguished from each other only by a bi-
jection of the range variables are considered equivalent. I.e.,
if the application of a rule yields a new item such that an
equivalent one has already been generated, this new one is
not added to the set of partial results.
10
Scan:
[A, ?]
A(~x)? ? ? P with instantiation ?
such that ?(A(~x)) = A(?)
Initialize:
[A(~x)? ??, ??,C?]
A(~x)? ? ? P with
range constraint vector
??,C?,? 6= ?
Complete:
[B,?
B
],
[A(~x)? ? ?B(x
1
...y
1
, ..., x
k
...y
k
)?, ??,C?]
[A(~x)? ?B(x
1
...y
1
, ..., x
k
...y
k
) ??, ??,C
?
?]
where C
?
= C ? {?
B
(j).l = ?(?(x
j
)).l, ?
B
(j).r =
?(?(y
j
)).r | 1 ? j ? k}.
Convert:
[A(~x)? ??, ??,C?]
[A, ?]
A(~x)? ? ? P with
an instantiation ? that
satisfies ??,C?,
?(A(~x)) = A(?)
Goal: [S, (?0, n?)]
Figure 1: CYK deduction rules
The deduction rules are shown in Fig. 1. The
first rule scans the yields of terminating clauses.
Initialize introduces clauses with the dot on the
left of the righthand side. Complete moves the dot
over a predicate provided a corresponding passive
item has been found. Convert turns an active item
with the dot at the end into a passive item.
4 The Earley Algorithm
We now add top-down prediction to our algorithm.
Active items are as above. Passive items have
an additional flag p or c depending on whether
the item is predicted or completed, i.e., they ei-
ther have the form [A, ??, C?, p] where ??, C? is a
range constraint vector of dimension dim(A), or
the form [A, ?, c] where ? is a range vector of di-
mension dim(A).
Initialize:
[S, ?(?r
1
, r
2
?), {0 = r
1
, n = r
2
}?, p]
Predict-rule:
[A, ??,C?, p]
[A(x
1
. . . y
1
, . . . , x
k
. . . y
k
)? ??, ??
?
, C
?
?]
where ??
?
, C
?
? is obtained from the range constraint vector
of the clause A(x
1
. . . y
1
, . . . , x
k
. . . y
k
) ? ? by taking all
constraints from C, mapping all ?(i).l to ?
?
(?(x
i
)).l and
all ?(i).r to ?
?
(?(y
i
)).r, and then adding the resulting con-
straints to the range constraint vector of the clause.
Predict-pred:
[A(...)? ? ?B(x
1
...y
1
, ..., x
k
...y
k
)?, ??,C?]
[B, ??
?
, C
?
?, p]
where ?
?
(i).l = ?(?(x
i
)).l, ?
?
(i).r = ?(?(y
i
)).r for all
1 ? i ? k and C
?
= {c | c ? C, c contains only range
variables from ?
?
}.
Scan:
[A, ??,C?, p]
[A, ?, c]
A(~x)? ? ? P with an
instantiation ? satisfying ??,C?
such that ?(A(~x)) = A(?)
Figure 2: Earley deduction rules
The deduction rules are listed in Fig. 2. The
axiom is the prediction of an S ranging over the
entire input (initialize). We have two predict op-
erations: Predict-rule predicts active items with
the dot on the left of the righthand side, for a
given predicted passive item. Predict-pred pre-
dicts a passive item for the predicate following the
dot in an active item. Scan is applied whenever a
predicted predicate can be derived by an ?-clause.
The rules complete and convert are the ones from
the CYK algorithm except that we add flags c to
the passive items occurring in these rules. The
goal is again [S, (?0, n?), c].
To understand how this algorithm works, con-
sider the example in Fig. 3. The crucial property of
this algorithm, in contrast to previous approaches,
is the dynamic updating of a set of constraints on
range boundaries. We can leave range boundaries
unspecified and compute their values in a more in-
cremental fashion instead of guessing all ranges of
a clause at once at prediction.
4
For evaluation, we have implemented a direc-
tional top-down algorithm where range bound-
aries are guessed at prediction (this is essentially
the algorithm described in Boullier (2000)), and
the new Earley-style algorithm. The algorithms
were tested on different words of the language
L = {a
2
n
|n ? 0}. Table 1 shows the number
of generated items.
Word Earley TD
a
2
15 21
a
4
30 55
a
8
55 164
a
9
59 199
Word Earley TD
a
16
100 539
a
30
155 1666
a
32
185 1894
a
64
350 6969
Table 1: Items generated by both algorithms
Clearly, range boundary constraint propagation
increases the amount of information transported
in single items and thereby decreases considerably
the number of generated items.
5 Conclusion and future work
We have presented a new CYK and Earley pars-
ing algorithms for the full class of RCG. The cru-
cial difference between previously proposed top-
down RCG parsers and the new Earley-style algo-
rithm is that while the former compute all clause
instantiations during predict operations, the latter
4
Of course, the use of constraints makes comparisons be-
tween items more complex and more expensive which means
that for an efficient implementation, an integer-based repre-
sentation of the constraints and adequate techniques for con-
straint solving are required.
11
Grammar for {a
2
n
|n > 0}: S(XY )? S(X)eq(X,Y ), S(a
1
)? ?, eq(a
1
X, a
2
Y )? eq(X,Y ), eq(a
1
, a
2
)? ?
Parsing trace for w = aa:
Item Rule
1 [S, ?(?r
1
, r
2
?), {0 = r
1
, r
1
? r
2
, 2 = r
2
}?, p] initialize
2 [S(XY )? ?S(X)eq(X,Y ), {X.l ? X.r,X.r = Y.l, Y.l ? Y.r, 0 = X.l, 2 = Y.r}] predict-rule from 1
3 [S, ?(?r
1
, r
2
?), {0 = r
1
, r
1
? r
2
}?, p] predict-pred from 2
4 [S, (?0, 1?), c] scan from 3
5 [S(XY )? ?S(X)eq(X,Y ), {X.l ? X.r,X.r = Y.l, Y.l ? Y.r, 0 = X.l, }] predict-rule from 3
6 [S(XY )? S(X) ? eq(X,Y ), {. . . , 0 = X.l, 2 = Y.r, 1 = X.r}] complete 2 with 4
7 [S(XY )? S(X) ? eq(X,Y ), {X.l ? X.r,X.r = Y.l, Y.l ? Y.r, 0 = X.l, 1 = X.r}] complete 5 with 4
8 [eq, ?(?r
1
, r
2
?, ?r
3
, r
4
?), {r
1
? r
2
, r
2
= r
3
, r
3
? r
4
, 0 = r
1
, 2 = r
4
, 1 = r
2
}?] predict-pred from 6
9 [eq(a
1
X, a
2
Y )? ?eq(X,Y ), {a
1
.l + 1 = a
1
.r, a
1
.r = X.l,X.l ? X.r,
a
2
.l + 1 = a
2
.r, a
2
.r = Y.l, Y.l ? Y.r,X.r = a
2
.l, 0 = a
1
.l, 1 = X.r, 2 = Y.r}] predict-rule from 8
. . .
10 [eq, (?0, 1?, ?1, 2?), c] scan 8
11 [S(XY )? S(X)eq(X,Y )?, {. . . , 0 = X.l, 2 = Y.r, 1 = X.r, 1 = Y.l}] complete 6 with 10
12 [S, (?0, 2?), c] convert 11
Figure 3: Trace of a sample Earley parse
avoids this using a technique of dynamic updating
of a set of constraints on range boundaries. Exper-
iments show that this significantly decreases the
number of generated items, which confirms that
range boundary constraint propagation is a viable
method for a lazy computation of ranges.
The Earley parser could be improved by allow-
ing to process the predicates of the righthand sides
of clauses in any order, not necessarily from left
to right. This way, one could process predicates
whose range boundaries are better known first. We
plan to include this strategy in future work.
References
Franc?ois Barth?elemy, Pierre Boullier, Philippe De-
schamp, and
?
Eric de la Clergerie. 2001. Guided
parsing of Range Concatenation Languages. In Pro-
ceedings of ACL, pages 42?49.
Tilman Becker, Aravind K. Joshi, and Owen Rambow.
1991. Long-distance scrambling and tree adjoining
grammars. In Proceedings of EACL.
Tilman Becker, Owen Rambow, and Michael Niv.
1992. The Derivationel Generative Power of Formal
Systems or Scrambling is Beyond LCFRS. Tech-
nical Report IRCS-92-38, Institute for Research in
Cognitive Science, University of Pennsylvania.
E. Bertsch and M.-J. Nederhof. 2001. On the complex-
ity of some extensions of RCG parsing. In Proceed-
ings of IWPT 2001, pages 66?77, Beijing, China.
Pierre Boullier. 1999. Chinese numbers, mix, scram-
bling, and range concatenation grammars. In Pro-
ceedings of EACL, pages 53?60, Bergen, Norway.
Pierre Boullier. 2000. Range concatenation grammars.
In Proceedings of IWPT 2000, pages 53?64, Trento.
H?akan Burden and Peter Ljungl?of. 2005. Parsing lin-
ear context-free rewriting systems. In Proceedings
of IWPT 2005, pages 11?17, Vancouver.
Laura Kallmeyer, Timm Lichte, Wolfgang Maier, Yan-
nick Parmentier, and Johannes Dellert. 2008. De-
veloping an MCTAG for German with an RCG-
based parser. In Proceedings of LREC-2008, Mar-
rakech, Morocco.
Wolfgang Maier and Anders S?gaard. 2008. Tree-
banks and mild context-sensitivity. In Proceedings
of the 13th Conference on Formal Grammar 2008,
Hamburg, Germany.
Jens Michaelis and Marcus Kracht. 1996. Semilinear-
ity as a Syntactic Invariant. In Logical Aspects of
Computational Linguistics, Nancy.
Daniel Radzinski. 1991. Chinese number-names, tree
adjoining languages, and mild context-sensitivity.
Computational Linguistics, 17:277?299.
Beno??t Sagot. 2005. Linguistic facts as predicates over
ranges of the sentence. In Proceedings of LACL 05,
number 3492 in Lecture Notes in Computer Science,
pages 271?286, Bordeaux, France. Springer.
Stuart M. Shieber, Yves Schabes, and Fernando C. N.
Pereira. 1995. Principles and implementation of
deductive parsing. Journal of Logic Programming,
24(1& 2):3?36.
Anders S?gaard. 2008. Range concatenation gram-
mars for translation. In Proceedings of COLING,
Manchester, England.
K. Vijay-Shanker, David Weir, and Aravind Joshi.
1987. Characterising structural descriptions used by
various formalisms. In Proceedings of ACL.
Eric Villemonte de la Clergerie. 2002. Parsing mildly
context-sensitive languages with thread automata.
In Proceedings of COLING, Taipei, Taiwan.
12
XMG - An expressive formalism for describing tree-based grammars
Yannick Parmentier
INRIA / LORIA
Universite? Henri Poincare?
615, Rue du Jardin Botanique
54 600 Villers-Les-Nancy
France
parmenti@loria.fr
Joseph Le Roux
LORIA
Institut National
Polytechnique de Lorraine
615, Rue du Jardin Botanique
54 600 Villers-Les-Nancy
France
leroux@loria.fr
Beno??t Crabbe?
HCRC / ICCS
University of Edinburgh
2 Buccleuch Place
EH8 9LW,
Edinburgh, Scotland
bcrabbe@inf.ed.ac.uk
Abstract
In this paper1 we introduce eXtensible
MetaGrammar, a system that facilitates
the development of tree based grammars.
This system includes both (1) a formal lan-
guage adapted to the description of lin-
guistic information and (2) a compiler for
this language. It applies techniques of
logic programming (e.g. Warren?s Ab-
stract Machine), thus providing an effi-
cient and theoretically motivated frame-
work for the processing of linguistic meta-
descriptions.
1 Introduction
It is well known that grammar engineering is a
complex task and that factorizing grammar in-
formation is crucial for the rapid development,
the maintenance and the debugging of large scale
grammars. While much work has been deployed
into producing such factorizing environments for
standard unification grammars, less attention has
been paid to the issue of developing such environ-
ments for ?tree based grammars? that is, grammars
like Tree Adjoining Grammars (TAG) or Tree De-
scription Grammars where the basic unit of infor-
mation is a tree rather than a category encoded in
a feature structure.
For these grammars, two trends have emerged
to automatize tree-based grammar production:
systems based on lexical rules (see (Becker,
2000)) and systems based on combination of
classes (also called metagrammar systems, see
(Candito, 1999), (Gaiffe et al, 2002)).
1We are grateful to Claire Gardent for useful comments
on this work. This work is partially supported by an INRIA
grant.
In this paper, we present a metagrammar system
for tree-based grammars which differs from com-
parable existing approaches both linguistically and
computationally.
Linguistically, the formalism we introduce is
both expressive and extensible. In particularly, we
show that it supports the description and factor-
ization both of trees and of tree descriptions; that
it allows the synchronized description of several
linguistic dimensions (e.g., syntax and semantics)
and that it includes a sophisticated treatment of
the interaction between inheritance and identifier
naming.
Computationally, the production of a grammar
from a metagrammar is handled using power-
ful and well-understood logic programming tech-
niques. A metagrammar is viewed as an extended
definite clause grammar and compiled using a vir-
tual machine closely resembling the Warren?s Ab-
stract Machine. The generation of the trees satisfy-
ing a given tree description is furthermore handled
using a tree description solver.
The paper is structured as follows. We begin
(section 2) by introducing the linguistic formal-
ism used for describing and factorizing tree based
grammars. We then sketch the logic program-
ming techniques used by the metagrammar com-
piler (section 3). Section 4 presents some evalu-
ation results concerning the use of the system for
implementing different types of tree based gram-
mars. Section 5 concludes with pointers for fur-
ther research and improvements.
2 Linguistic formalism
As mentioned above, the XMG system produces a
grammar from a linguistic meta-description called
a metagrammar. This description is specified us-
ing the XMG metagrammar formalism which sup-
103
ports three main features:
1. the reuse of tree fragments
2. the specialization of fragments via in-
heritance
3. the combination of fragments by
means of conjunctions and disjunctions
These features reflect the idea that a metagrammar
should allow the description of two main axes: (i)
the specification of elementary pieces of informa-
tion (fragments), and (ii) the combination of these
to represent alternative syntactic structures.
Describing syntax In a tree-based metagram-
mar, the basic informational units to be handled
are tree fragments. In the XMG formalism, these
units are put into classes. A class associates a
name with a content. At the syntactic level, a con-
tent is a tree description2 . The tree descriptions
supported by the XMG formalism are defined by
the following tree description language:
Description ::= x ? y | x ?+ y | x ?? y |
x ? y | x ?+ y | x ?? y |
x[f :E] (1)
where x, y represent node variables, ? immediate
dominance (x is directly above y),?+ strict dom-
inance (x is above y), ?? large dominance (x is
above or equal to y), ? is immediate precedence,
?+ strict precedence, and ?? large precedence3 .
x[f :E] constrains feature f with associated ex-
pression E on node x (a feature can for instance
refer to the syntactic category of the node)4.
Tree fragments can furthermore be combined
using conjunction and/or disjunction. These
two operators allow the metagrammar designer to
achieve a high degree of factorization. Moreover
the XMG system also supports inheritance be-
tween classes, thus offering more flexibility and
structure sharing by allowing one to reuse and
specialize classes.
Identifiers? scope When describing a broad-
coverage grammar, dealing with identifiers scope
is a non-trivial issue.
In previous approaches to metagrammar com-
pilation ((Candito, 1999), (Gaiffe et al, 2002)),
2As we shall later see, a content can in fact be multi-
dimensional and integrate for instance both semantic and syn-
tax/semantics interface information.
3We call strict the transitive closure of a relation and large
the reflexive and transitive one.
4E is an expression, so it can be a feature structure: that?s
how top and bottom are encoded in TAG.
node identifiers had global scope. When design-
ing broad-coverage metagrammars however, such
a strategy quickly reduces modularity and com-
plexifies grammar maintenance. To start with, the
grammar writer must remember each node name
and its interpretation and in a large coverage gram-
mar the number of these node names amounts to
several hundreds. Further it is easy to use twice
the same name erroneously or on the contrary, to
mistype a name identifier, in both cases introduc-
ing errors in the metagrammar
In XMG, identifiers are local to a class and can
thus be reused freely. Global and semi-global (i.e.,
global to a subbranch in the inheritance hierar-
chy) naming is also supported however through a
system of import / export inspired from Object
Oriented Programming. When defining a class as
being a sub-class of another one, the XMG user
can specify which are the viewable identifiers (i.e.
which identifiers have been exported in the super-
class).
Extension to semantics The XMG formalism
further supports the integration in the grammar of
semantic information. More generally, the lan-
guage manages dimensions of descriptions so that
the content of a class can consists of several ele-
ments belonging to different dimensions. Each di-
mension is then processed differently according to
the output that is expected (trees, set of predicates,
etc).
Currently, XMG includes a semantic represen-
tation language based on Flat Semantics (see (Gar-
dent and Kallmeyer, 2003)):
Description ::= `:p(E1, ..., En) |
?`:p(E1, ..., En) | Ei  Ej (2)
where `:p(E1, ..., En) represents the predicate p
with parameters E1, .., En, and labeled `. ? is the
logical negation, and Ei  Ej is the scope be-
tween Ei and Ej (used to deal with quantifiers).
Thus, one can write classes whose content con-
sists of tree description and/or of semantic formu-
las. The XMG formalism furthermore supports the
sharing of identifiers across dimension hence al-
lowing for a straightforward encoding of the syn-
tax/semantics interface (see figure 1).
3 Compiling a MetaGrammar into a
Grammar
We now focus on the compilation process and on
the constraint logic programming techniques we
104
Figure 1: Tree with syntax/semantics interface
draw upon.
As we have seen, an XMG metagrammar con-
sists of classes that are combined. Provided these
classes can be referred to by means of names, we
can view a class as a Clause associating a name
with a content or Goal to borrow vocabulary from
Logic Programming. In XMG, this Goal will be
either a tree Description, a semantic Description,
a Name (class call) or a combination of classes
(conjunction or disjunction). Finally, the valua-
tion of a specific class can be seen as being trig-
gered by a query.
Clause ::= Name ? Goal (3)
Goal ::= Description | Name
| Goal ? Goal | Goal ?Goal (4)
Query ::= Name (5)
In other words, we view our metagrammar lan-
guage as a specific kind of Logic Program namely,
a Definite Clause Grammar (or DCG). In this
DCG, the terminal symbols are descriptions.
To extend the approach to the representation of
semantic information as introduced in 2, clause (4)
is modified as follows:
Goal ::= Dimension+=Description |
Name |
Goal ? Goal | Goal ? Goal
Note that, with this modification, the XMG lan-
guage no longer correspond to a Definite Clause
Grammar but to an Extended Definite Clause
Grammar (see (Van Roy, 1990)) where the sym-
bol += represents the accumulation of information
for each dimension.
Virtual Machine The evaluation of a query is
done by a specific Virtual Machine inspired by
the Warren?s Abstract Machine (see (Ait-Kaci,
1991)). First, it computes the derivations con-
tained in the description, i.e. in the Extended Def-
inite Clause Grammar, and secondly it performs
unification of non standard data-types (nodes,
node features for TAG). Eventually it produces
as an output a description, more precisely one de-
scription per dimension (syntax, semantics).
In the case of TAG, the virtual machine produces
a tree description. We still need to solve this de-
scription in order to obtain trees (i.e. the items of
the resulting grammar).
Constraint-based tree description solver The
tree description solver we use is inspired by
(Duchier and Niehren, 2000). The idea is to:
1. associate to each node x in the description an
integer,
2. then refer to x by means of the tuple
(Eqx,Upx,Downx,Leftx,Rightx) where Eqx
(respectively Upx, Downx, Leftx, Rightx) de-
notes the set of nodes in the description which
are equal, (respectively above, below, left, and
right) of x (see picture 2). Note that these sets
are set of integers.
Eq
Up
Down
Left
Right
Figure 2: node regions
The operations supported by the XMG language
(i.e. dominance, precedence, etc) are then con-
verted into constraints on these sets. For instance,
let us consider 2 nodes x and y of the description.
Assuming we associate x with the integer i and
y with j, we can translate the dominance relation
x ? y the following way5:
N i ? N j ? [N iEqUp ? N
j
Up ?
N iDown ? N
j
EqDown ?
N iLeft ? N
j
Left ?
N iRight ? N
j
Right]
This means that if x dominates y, then in a model,
(1) the set of integers representing nodes that are
equal or above x is included in the set of inte-
gers representing nodes that are strictly above y,
5N iEqUp corresponds to the disjoint union of N iEq and
N iUp, similarly for N jEqDown with N
i
Eq and N iDown.
105
(2) the dual holds, i.e. the set of integers repre-
senting nodes that are below x contains the set of
integers representing nodes that are equal or be-
low y, (3) the set of integers representing nodes
that are on the left of x is included in the set of
integers representing those on the left of y, and (4)
symmetrically for the nodes on the right6.
Parameterized constraint solver To recap 3
from a grammar-designer?s point of view, a
queried class needs not define complete trees but
rather a set of tree descriptions. The solver is then
called to generate all the matching valid minimal
trees from those descriptions. This feature pro-
vides the users with a way to concentrate on what
is relevant in the grammar, thus taking advantage
of underspecification, and to delegate the tiresome
work to the solver.
Actually, the solver can be parameterized to per-
form various checks or constraints on the tree de-
scriptions besides tree-shaping them. These pa-
rameters are called principles in the XMG termi-
nology. Some are specific to a target formalism
(e.g. TAG trees must have at most one foot node)
while others are independent. The most interesting
one is a resources/needs mechanism for node uni-
fication called color principle, see (Crabb?e and
Duchier, 2004).
At the end of this tree description solving pro-
cess we obtain the trees of the grammar. Note that
the use of constraint programming techniques to
solve tree descriptions allows us to compute gram-
mars faster than the previous approaches (see sec-
tion 4).
4 Evaluation
The XMG system has been successfully used by
linguists to develop a core TAG for French contain-
ing more than 6.000 trees. This grammar has been
evaluated on the TSNLP test-suite, with a cover-
age rate of 75 % (see (Crabb?e, 2005)). The meta-
grammar used to produce that grammar consists of
290 classes and is compiled by the XMG system
in about 16 minutes with a Pentium 4, 2.6 GHz
and 1 GB of RAM.7
XMG has also been used to produce a core
size Interaction Grammar for French (see (Perrier,
2003)).
6See (Duchier and Niehren, 2000) for details .
7Because this metagrammar is highly unspecifi ed, con-
straint solving takes about 12 min. Of course, subsets of the
grammar may be rebuilt separately.
Finally, XMG is currently used to develop a
TAG that includes a semantic dimension along the
line described in (Gardent and Kallmeyer, 2003).
5 Conclusion and Future Work
We have presented a system, XMG8, for produc-
ing broad-coverage grammars, system that offers
an expressive description language along with an
efficient compiler taking advantages from logic
and constraint programming techniques.
Besides, we aim at extending XMG to a generic
tool. That is to say, we now would like to obtain
a compiler which would propose a library of lan-
guages (each associated with a specific process-
ing) that the user would load dynamically accord-
ing to his/her target formalism (not only tree-based
formalisms, but others such as HPSG or LFG).
References
H. Ait-Kaci. 1991. Warren?s abstract machine: A tu-
torial reconstruction. In Proc. of the Eighth Interna-
tional Conference of Logic Programming.
T. Becker. 2000. Patterns in metarules. In A. Abeille
and O. Rambow, editors, Tree Adjoining Grammars:
formal, computational and linguistic aspects. CSLI
publications, Stanford.
M.H. Candito. 1999. Repre?sentation modulaire
et parame?trable de grammaires e?lectroniques lex-
icalise?es : application au franc?ais et a` l?italien.
Ph.D. thesis, Universit?e Paris 7.
B. Crabb?e and D. Duchier. 2004. Metagrammar redux.
In CSLP 2004, Copenhagen.
B. Crabb?e. 2005. Repr?esentation informatique de
grammaires fortement lexicalise?es : Application a`
la grammaire d?arbres adjoints. Ph.D. thesis, Uni-
versit?e Nancy 2.
D. Duchier and J. Niehren. 2000. Dominance
constraints with set operators. In Proceedings of
CL2000.
B. Gaiffe, B. Crabb?e, and A. Roussanaly. 2002. A new
metagrammar compiler. In Proceedings of TAG+6.
C. Gardent and L. Kallmeyer. 2003. Semantic con-
struction in ftag. In Proceedings of EACL?03.
Guy Perrier. 2003. Les grammaires d?interaction.
HDR en informatique, Universit?e Nancy 2.
P. Van Roy. 1990. Extended dcg notation: A tool for
applicative programming in prolog. Technical re-
port, Technical Report UCB/CSD 90/583, Computer
Science Division, UC Berkeley.
8XMG is freely available at http://sourcesup.
cru.fr/xmg .
106
Proceedings of the 8th International Workshop on Tree Adjoining Grammar and Related Formalisms, pages 115?120,
Sydney, July 2006. c?2006 Association for Computational Linguistics
SemTAG, the LORIA toolbox for TAG-based Parsing and Generation
Eric Kow
INRIA / LORIA
Universite? Henri Poincare?
615, rue du Jardin Botanique
F-54 600 Villers-Le`s-Nancy
kow@loria.fr
Yannick Parmentier
INRIA / LORIA
Universite? Henri Poincare?
615, rue du Jardin Botanique
F-54 600 Villers-Le`s-Nancy
parmenti@loria.fr
Claire Gardent
CNRS / LORIA
615, rue du Jardin Botanique
F-54 600 Villers-Le`s-Nancy
gardent@loria.fr
Abstract
In this paper, we introduce SEMTAG, a
toolbox for TAG-based parsing and gen-
eration. This environment supports the
development of wide-coverage grammars
and differs from existing environments
for TAG such as XTAG, (XTAG-Research-
Group, 2001) in that it includes a semantic
dimension. SEMTAG is open-source and
freely available.
1 Introduction
In this paper we introduce a toolbox that allows for
both parsing and generation with TAG. This tool-
box combines existing software and aims at facili-
tating grammar development, More precisely, this
toolbox includes1:
? XMG: a grammar compiler which supports the
generation of a TAG from a factorised TAG
(Crabbe? and Duchier, 2004),
? LLP2 and DyALog: two chart parsers, one
with a friendly user interface (Lopez, 2000)
and the other optimised for efficient parsing
(Villemonte de la Clergerie, 2005)2
? GenI: a chart generator which has been
tested on a middle size grammar for French
(Gardent and Kow, 2005)
1All these tools are freely available, more information and
links at http://trac.loria.fr/?semtag.
2Note that DyALog refers in fact to a logic program-
ming language, and a tabular compiler for this language. The
DyALog system is well-adapted to the compilation of effi-
cient tabular parsers.
2 XMG, a grammar writing environment
for Tree Based Grammars
XMG provides a grammar writing environment for
tree based grammars3 with three distinctive fea-
tures. First, XMG supports a highly factorised and
fully declarative description of tree based gram-
mars. Second, XMG permits the integration in a
TAG of a semantic dimension. Third, XMG is based
on well understood and efficient logic program-
ming techniques. Moreover, it offers a graphical
interface for exploring the resulting grammar (see
Figure 1).
Factorising information. In the XMG frame-
work, a TAG is defined by a set of classes organised
in an inheritance hierarchy where classes define
tree fragments (using a tree logic) and tree frag-
ment combinations (by conjunction or disjunc-
tion). XMG furthermore integrates a sophisticated
treatment of names whereby variables scope can
be local, global or user defined (i.e., local to part
of the hierarchy).
In practice, the resulting framework supports a
very high degree of factorisation. For instance, a
first core grammar (FRAG) for French comprising
4 200 trees was produced from roughly 300 XMG
classes.
Integrating semantic information. In XMG,
classes can be multi-dimensional. That is, they
can be used to describe several levels of linguis-
tic knowledge such as for instance, syntax, seman-
tics or prosody. At present, XMG supports classes
including both a syntactic and a semantic dimen-
sion. As mentioned above, the syntactic dimen-
3Although in this paper we only mention TAG, the XMG
framework is also used to develop so called Interaction Gram-
mars i.e., grammars whose basic units are tree descriptions
rather than trees (Parmentier and Le Roux, 2005).
115
Figure 1: XMG?s graphical interface
sion is based on a tree logic and can be used to
describe (partial) tree fragments. The semantic di-
mension on the other hand, can be used to asso-
ciate with each tree a flat semantic formula. Such a
formula can furthermore include identifiers which
corefer with identifiers occurring in the associated
syntactic tree. In other words, XMG also provides
support for the interface between semantic formu-
lae and tree decorations. Note that the inclusion of
semantic information remains optional. That is, it
is possible to use XMG to define a purely syntactic
TAG.
XMG was used to develop a core grammar for
French (FRAG) which was evaluated to have 75%
coverage4 on the Test Suite for Natural Language
Processing (TSNLP, (Lehmann et al, 1996)). The
FRAG grammar was furthermore enriched with
semantic information using another 50 classes de-
scribing the semantic dimension (Gardent, 2006).
The resulting grammar (SEMFRAG) describes
both the syntax and the semantics of the French
core constructions.
Compiling an XMG specification. By build-
ing on efficient techniques from logic program-
ming and in particular, on the Warren?s Abstract
4This means that for 75 % of the sentences, a TAG parser
can build at least one derivation.
Figure 2: The LLP2 parser.
Machine idea (Ait-Kaci, 1991), the XMG com-
piler allows for very reasonable compilation times
(Duchier et al, 2004). For instance, the compila-
tion of a TAG containing 6 000 trees takes about 15
minutes with a Pentium 4 processor 2.6 GHz and
1 GB of RAM.
3 Two TAG parsers
The toolbox includes two parsing systems: the
LLP2 parser and the DyALog system. Both of
them can be used in conjunction with XMG. First
we will briefly introduce both of them, and then
show that they can be used with a semantic gram-
mar (e.g., SEMFRAG) to perform not only syntac-
tic parsing but also semantic construction.
LLP2 The LLP2 parser is based on a bottom-
up algorithm described in (Lopez, 1999). It has
relatively high parsing times but provides a user
friendly graphical parsing environment with much
statistical information (see Figure 2). It is well
suited for teaching or for small scale projects.
DyALog The DyALog system on the other
hand, is a highly optimised parsing system based
on tabulation and automata techniques (Ville-
monte de la Clergerie, 2005). It is implemented
using the DyALog programming language (i.e.,
it is bootstrapped) and is also used to compile
parsers for other types of grammars such as Tree
Insertion Grammars.
The DyALog system is coupled with a seman-
tic construction module whose aim is to associate
with each parsed string a semantic representation5.
This module assumes a TAG of the type described
in (Gardent and Kallmeyer, 2003; Gardent, 2006)
5The corresponding system is called SemConst (cf section
6).
116
Figure 3: The SemConst system
where initial trees are associated with semantic in-
formation and unification is used to combine se-
mantic representations. In such a grammar, the se-
mantic representation of a derived tree is the union
of the semantic representations of the trees enter-
ing in the derivation of that derived tree modulo
the unifications entailed by analysis. As detailed
in (Gardent and Parmentier, 2005), such grammars
support two strategies for semantic construction.
The first possible strategy is to use the full
grammar and to perform semantic construction
during derivation. In this case the parser must ma-
nipulate both syntactic trees and semantic repre-
sentations. The advantage is that the approach is
simple (the semantic representations can simply
be an added feature on the anchor node of each
tree). The drawback is that the presence of seman-
tic information might reduce chart sharing.
The second possibility involves extracting the
semantic information contained in the grammar
and storing it into a semantic lexicon. Parsing then
proceeds with a purely syntactic grammar and se-
mantic construction is done after parsing on the
basis of the parser output and of the extracted se-
mantic lexicon. This latter technique is more suit-
able for large scale semantic construction as it sup-
ports better sharing in the derivation forests. It
is implemented in the LORIA toolbox where a
module permits both extracting a semantic lexi-
con from a semantic TAG and constructing a se-
mantic representation based on this lexicon and on
the derivation forests output by DyALog (see Fig-
ure 3).
The integration of the DyALog system into the
toolbox is relatively new so that parsing evaluation
Figure 4: The GenI debugger
is still under progress. So far, evaluation has been
restricted to parsing the TSNLP with DyALog
with the following preliminary results. On sen-
tences ranging from 1 to 18 words, with an aver-
age of 7 words per sentence, and with a grammar
containing 5 069 trees, DyALog average parsing
time is of 0.38 sec with a P4 processor 2.6 GHz
and 1 GB of RAM6.
4 A TAG-based surface realiser
The surface realiser GenI takes a TAG and a flat
semantic logical form as input, and produces all
the sentences that are associated with that logi-
cal form by the grammar. It implements two bot-
tom up algorithms, one which manipulates derived
trees as items and one which is based on Earley for
TAG. Both of these algorithms integrate a number
of optimisations such as delayed adjunction and
polarity filtering (Kow, 2005; Gardent and Kow,
2005).
GenI is written in Haskell and includes a
graphical debugger to inspect the state of the gen-
erator at any point in the surface realisation pro-
cess (see Figure 4). It also integrates a test harness
for automated regression testing and benchmark-
ing of the surface realiser and the grammar. The
harness gtester is written in Python. It runs the
surface realiser on a test suite, outputting a single
document with a table of passes and failures and
various performance charts (see Figures 5 and 6).
Test suite and performance The test suite is
built with an emphasis on testing the surface re-
6These features only concern classic syntactic parsing as
the semantic construction module has not been tested on real
grammars yet.
117
test expected simple earley
t1 il le accepter pass pass
t32 il nous accepter pass pass
t83 le ingnieur le lui apprendre pass DIED
t114 le ingnieur nous le prsenter pass pass
t145 le ingnieur vous le apprendre pass pass
t180 vous venir pass pass
Figure 5: Fragment of test harness output - The
Earley algorithm timed out.
 0
 1000
 2000
 3000
 4000
 5000
 6000
 0  20  40  60  80  100  120  140  160  180  200
ch
art
_s
ize
lex_foot_nodes
chart_size for lex_foot_nodes
simpleearley
Figure 6: Automatically generated graph of per-
formance data by the test harness.
aliser?s performance in the face of increasing para-
phrastic power i.e., ambiguity. The suite consists
of semantic inputs that select for and combines
verbs with different valencies. For example, given
a hypothetical English grammar, a valency (2,1)
semantics might be realised in as Martin thinks
Faye drinks (thinks takes 2 arguments and drinks
takes 1), whereas a valency (2,3,2) one would be
Dora says that Martin tells Bob that Faye likes
music. The suite also adds a varying number of
intersective modifiers into the mix, giving us for
instance, The girl likes music, The pretty scary girl
likes indie music.
The sentences in the suite range from 2 to 15
words (8 average). Realisation times for the core
suite range from 0.7 to 2.84 seconds CPU time
(average 1.6 seconds).
We estimate the ambiguity for each test case
in two ways. The first is to count the number of
paraphrases. Given our current grammar, the test
cases in our suite have up to 669 paraphrases (av-
erage 41). The second estimate for ambiguity is
the number of combinations of lexical items cov-
ering the input semantics.
This second measure is based on optimisation
known as polarity filtering (Gardent and Kow,
2005). This optimisation detects and eliminates
combinations of lexical items that cannot be used
to build a result. It associates the syntactic re-
sources (root nodes) and requirements (substitu-
tion nodes) of the lexical items to polarities, which
are then used to build ?polarity automata?. The
automata are minimised to eliminate lexical com-
binations where the polarities do not cancel out,
that is those for which the number of root and sub-
stitution nodes for any given category do not equal
each other.
Once built, the polarity automata can also serve
to estimate ambiguity. The number of paths in the
automaton represent the number of possible com-
binations of lexical items. To determine how ef-
fective polarity filtering with respect to ambiguity,
we compare the combinations before and after po-
larity filtering. Before filtering, we start with an
initial polarity automaton in which all items are
associated with a zero polarity. This gives us the
lexical ambiguity before filtering. The polarity fil-
ter then builds upon this to form a final automaton
where all polarities are taken into account. Count-
ing the paths on this automaton gives us the am-
biguity after filtering, and comparing this number
with the lexical initial ambiguity provides an es-
timate on the usefulness of the polarity filter. In
our suite, the initial automata for each case have
1 to 800 000 paths (76 000 average). The fi-
nal automata have 1 to 6000 paths (192 average).
This can represent quite a large reduction in search
space, 4000 times in the case of the largest au-
tomaton. The effect of this search space reduc-
tion is most pronounced on the larger sentences or
those with the most modifiers. Indeed, realisation
times with and without filtering are comparable for
most of the test suite, but for the most complicated
sentence in the core suite, polarity filtering makes
surface realisation 94% faster, producing a result
in 2.35 seconds instead of 37.38.
5 Benefits of an integrated toolset
As described above, the LORIA toolbox for TAG
based semantic processing includes a lexicon, a
grammar, a parser, a semantic construction mod-
ule and a surface realiser. Integrating these into
a single platform provides some accrued benefits
which we now discuss in more details.
Simplified resource management The first ad-
vantage of an integrated toolkit is that it facilitates
118
the management of the linguistic resources used
namely the grammar and the lexicon. Indeed it is
common that each NLP tool (parser or generator)
has its own representation format. Thus, manag-
ing the resources gets tiresome as one has to deal
with several versions of a single resource. When
one version is updated, the others have to be re-
computed. Using an integrated toolset avoid such
a drawback as the intermediate formats are hidden
and the user can focus on linguistic description.
Better support for grammar development
When developing parsers or surface realisers, it is
useful to test them out by running them on large,
realistic grammars. Such grammars can explore
nooks and crannies in our implementations that
would otherwise have been overlooked by a toy
grammar. For example, it was only when we ran
GenI on our French grammar that we realised our
implementation did not account for auxiliary trees
with substitution nodes (this has been rectified).
In this respect, one could argue that XMG could al-
most be seen as a parser/realiser debugging utility
because it helps us to build and extend the large
grammars that are crucial for testing.
This perspective can also be inverted; parsers
and surface realiser make for excellent grammar-
debugging devices. For example, one possible
regression test is to run the parser on a suite of
known sentences to make sure that the modified
grammar still parses them correctly. The exact
reverse is useful as well; we could also run the
surface realiser over a suite of known semantic
inputs and make sure that sentences are gener-
ated for each one. This is useful for two reasons.
First, reading surface realiser output (sentences)
is arguably easier for human beings than reading
parser output (semantic formulas). Second, the
surface realiser can tell us if the grammar overgen-
erates because it would output nonsense sentences.
Parsers, on the other hand, are much better adapted
for testing for undergeneration because it is easier
to write sentences than semantic formulas, which
makes it easier to test phenomena which might not
already be in the suite.
Towards a reversible grammar Another ad-
vantage of using such a toolset relies on the fact
that we can manage a common resource for both
parsing and generation, and thus avoid inconsis-
tency, redundancy and offer a better flexibility as
advocated in (Neumann, 1994).
On top of these practical questions, having a
unique reversible resource can lead us further.
For instance, (Neumann, 1994) proposes an inter-
leaved parsing/realisation architecture where the
parser is used to choose among a set of para-
phrases proposed by the generator; paraphrases
which are ambiguous (that have multiple parses)
are discarded in favour of those whose meaning is
most explicit. Concretely, we could do this with a
simple pipeline using GenI to produce the para-
phrases, DyALog to parse them, and a small shell
script to pick the best result. This would only be
a simulation, of course. (Neumann, 1994) goes
as far as to interleave the processes, keeping the
shared chart and using the parser to iteratively
prune the search space as it is being explored by
the generator. The version we propose would not
have such niceties as a shared chart, but the point
is that having all the tools at our disposable makes
such experimentation possible in the first place.
Moreover, there are several other interest-
ing applications of the combined toolbox. We
could use the surface realiser to build artifi-
cial corpora. These can in turn be parsed to
semi-automatically create rich treebanks contain-
ing syntactico-semantic analyses a` la Redwoods
(Oepen et al, 2002).
Eventually, another use for the toolbox might be
in components of standard NLP applications such
as machine translation, questioning answering, or
interactive dialogue systems.
6 Availability
The toolbox presented here is open-source and
freely available under the terms of the GPL7. More
information about the requirements and installa-
tion procedure is available at http://trac.
loria.fr/?semtag. Note that this toolbox is
made of two main components: the GenI8 sys-
tem and the SemConst9 system, which respec-
tively performs generation and parsing from com-
mon linguistic resources. The first is written in
Haskell (except the XMG part written in Oz) and is
multi-platform (Linux, Windows, Mac OS). The
latter is written in Oz (except the DyALog part
which is bootstrapped and contains some Intel as-
sembler code) and is available on Unix-like plat-
7Note that XMG is released under the terms of the
CeCILL license (http://www.cecill.info/index.
en.html), which is compatible with the GPL.
8http://trac.loria.fr/?geni
9http://trac.loria.fr/?semconst
119
forms only.
7 Conclusion
The LORIA toolbox provides an integrated envi-
ronment for TAG based semantic processing: ei-
ther to construct the semantic representation of a
given sentence (parsing) or to generate a sentence
verbalising a given semantic content (generation).
Importantly, both the generator and the parsers
use the same grammar (SEMFRAG) so that both
tools can be used jointly to improve grammar pre-
cision. All the sentences outputted by the surface
realiser should be parsed to have at least the se-
mantic representation given by the test suite, and
all parses of a sentence should be realised into at
least the same sentence.
Current and future work concentrates on de-
veloping an automated error mining environment
for both parsing and generation; on extending the
grammar coverage; on integrating further optimi-
sations both in the parser (through parsing with
factorised trees) and in the generator (through
packing and accessibility filtering cf. (Carroll and
Oepen, 2005); and on experimenting with differ-
ent semantic construction strategies (Gardent and
Parmentier, 2005).
References
H. Ait-Kaci. 1991. Warren?s Abstract Machine: A Tu-
torial Reconstruction. In K. Furukawa, editor, Proc.
of the Eighth International Conference of Logic Pro-
gramming. MIT Press, Cambridge, MA.
J. Carroll and S. Oepen. 2005. High efficiency re-
alization for a wide-coverage unification grammar.
In R. Dale and K-F. Wong, editors, Proceedings of
the Second International Joint Conference on Natu-
ral Language Processing, volume 3651 of Springer
Lecture Notes in Artificial Intelligence, pages 165?
176.
B. Crabbe? and D. Duchier. 2004. Metagrammar Re-
dux. In Proceedings of CSLP 2004, Copenhagen.
D. Duchier, J. Le Roux, and Y. Parmentier. 2004. The
Metagrammar Compiler: An NLP Application with
a Multi-paradigm Architecture. In 2nd International
Mozart/Oz Conference (MOZ?2004), Charleroi.
C. Gardent and L. Kallmeyer. 2003. Semantic con-
struction in FTAG. In Proceedings of EACL?03, Bu-
dapest.
C. Gardent and E. Kow. 2005. Generating and select-
ing grammatical paraphrases. ENLG, Aberdeen.
C. Gardent and Y. Parmentier. 2005. Large scale
semantic construction for tree adjoining grammars.
In Proceedings of The Fifth International Confer-
ence on Logical Aspects of Computational Linguis-
tics (LACL05).
C. Gardent. 2006. Inte?gration d?une dimension
se?mantique dans les grammaires d?arbres adjoints.
In Actes de la confe?rence TALN?2006 Leuven.
E. Kow. 2005. Adapting polarised disambiguation
to surface realisation. In 17th European Summer
School in Logic, Language and Information - ESS-
LLI?05, Edinburgh, UK, Aug.
S. Lehmann, S. Oepen, S. Regnier-Prost, K. Netter,
V. Lux, J. Klein, K. Falkedal, F. Fouvry, D. Estival,
E. Dauphin, H. Compagnion, J. Baur, L. Balkan, and
D. Arnold. 1996. TSNLP ? Test Suites for Natural
Language Processing. In Proceedings of COLING
1996, Kopenhagen.
P. Lopez. 1999. Analyse d?e?nonce?s oraux pour le dia-
logue homme-machine a` l?aide de grammaires lex-
icalise?es d?arbres. Ph.D. thesis, Universite? Henri
Poincare? ? Nancy 1.
P. Lopez. 2000. Extended Partial Parsing for
Lexicalized Tree Grammars. In Proceedings of
the International Workshop on Parsing Technology
(IWPT2000), Trento, Italy.
G. Neumann. 1994. A Uniform Computational
Model for Natural Language Parsing and Gener-
ation. Ph.D. thesis, University of the Saarland,
Saarbru?cken.
S. Oepen, E. Callahan, C. Manning, and K. Toutanova.
2002. Lingo redwoods?a rich and dynamic tree-
bank for hpsg.
Y. Parmentier and J. Le Roux. 2005. XMG: an Exten-
sible Metagrammatical Framework. In Proceedings
of the Student Session of the 17th European Summer
School in Logic, Language and Information, Edin-
burg, Great Britain, Aug.
E. Villemonte de la Clergerie. 2005. DyALog: a tabu-
lar logic programming based environment for NLP.
In Proceedings of CSLP?05, Barcelona.
XTAG-Research-Group. 2001. A lexical-
ized tree adjoining grammar for english.
Technical Report IRCS-01-03, IRCS, Uni-
versity of Pennsylvania. Available at
http://www.cis.upenn.edu/?xtag/gramrelease.html.
120
XMG: eXtensible MetaGrammar
Beno??t Crabbe??
INRIA - Universite? Paris 7
Denys Duchier??
LIFO - Universite? d?Orle?ans
Claire Gardent?
CNRS - LORIA, Nancy
Joseph Le Roux?
LIPN - Universite? Paris Nord
Yannick Parmentier?
LIFO - Universite? d?Orle?ans
In this article, we introduce eXtensible MetaGrammar (XMG), a framework for specifying
tree-based grammars such as Feature-Based Lexicalized Tree-Adjoining Grammars (FB-LTAG)
and Interaction Grammars (IG). We argue that XMG displays three features that facilitate
both grammar writing and a fast prototyping of tree-based grammars. Firstly, XMG is fully
declarative. For instance, it permits a declarative treatment of diathesis that markedly departs
from the procedural lexical rules often used to specify tree-based grammars. Secondly, the XMG
language has a high notational expressivity in that it supports multiple linguistic dimensions,
inheritance, and a sophisticated treatment of identifiers. Thirdly, XMG is extensible in that its
computational architecture facilitates the extension to other linguistic formalisms. We explain
how this architecture naturally supports the design of three linguistic formalisms, namely,
FB-LTAG, IG, and Multi-Component Tree-Adjoining Grammar (MC-TAG). We further show
how it permits a straightforward integration of additional mechanisms such as linguistic and
formal principles. To further illustrate the declarativity, notational expressivity, and extensibility
of XMG, we describe the methodology used to specify an FB-LTAG for French augmented with a
? UFR de Linguistique, Universite? Paris Diderot-Paris 7, Case 7003, 2, F-75205 Paris Cedex 13, France.
E-mail: bcrabbe@linguist.jussieu.fr.
?? Laboratoire d?Informatique Fondamentale d?Orle?ans, Ba?timent IIIA, Rue Le?onard de Vinci, B.P. 6759,
F-45067 Orle?ans Cedex 2, France. E-mail: denys.duchier@univ-orleans.fr.
? Laboratoire LORIA - CNRS, Projet Synalp, Ba?timent B, BP 239, Campus Scientifique, F-54506
Vand?uvre-Le`s-Nancy Cedex, France. E-mail: gardent@loria.fr.
? Laboratoire d?Informatique de Paris Nord, UMR CNRS 7030, Institut Galile?e - Universite? Paris-Nord, 99,
avenue Jean-Baptiste Cle?ment, F-93430 Villetaneuse, E-mail: leroux@univ-paris13.fr.
? Laboratoire d?Informatique Fondamentale d?Orle?ans, Ba?timent IIIA, Rue Le?onard de Vinci, B.P. 6759,
F-45067 Orle?ans Cedex 2, France. E-mail: yannick.parmentier@univ-orleans.fr.
Submission received: 27 March 2009; revised version received: 2 July 2012; accepted for publication:
11 August 2012.
doi:10.1162/COLI a 00144
? 2013 Association for Computational Linguistics
Computational Linguistics Volume 39, Number 3
unification-based compositional semantics. This illustrates both how XMG facilitates the
modeling of the tree fragment hierarchies required to specify tree-based grammars and of a
syntax/semantics interface between semantic representations and syntactic trees. Finally, we
briefly report on several grammars for French, English, and German that were implemented
using XMG and compare XMG with other existing grammar specification frameworks for
tree-based grammars.
1. Introduction
In the late 1980s and early 1990s, many grammar engineering environments were
developed to support the specification of large computational grammars for natural
language. One may, for instance, cite XLE (Kaplan and Newman 1997) for specifying
Lexical-Functional Grammars (LFG), LKB (Copestake and Flickinger 2000) for speci-
fying Head-driven Phrase Structure Grammars (HPSG), and DOTCCG (Baldridge
et al 2007) for specifying Combinatory Categorial Grammars (CCG). Concretely, such
environments usually rely on (i) a formal language used to describe a target com-
putational grammar, and (ii) a processor for this language, which aims at generating
the actual described grammar (and potentially at checking it, e.g., by feeding it to
a parser).
Although these environments were tailored for specific grammar formalisms, they
share a number of features. Firstly, they are expressive enough to characterize subsets
of natural language. Following Shieber (1984), we call this feature weak completeness.
Secondly, they are notationally expressive enough to relatively easily formalize important
theoretical notions. Thirdly, they are rigorous, that is, the semantics of their underlying
language is well defined and understood. Additionally, for an environment to be useful
in practice, it should be simple to use (by a linguist), and make it possible to detect errors
in the described target grammar.
If we consider a particular type of computational grammar, namely, tree-based
grammars?that is, grammars where the basic units are trees (or tree descriptions) of
arbitrary depth, such as Tree-Adjoining Grammar (TAG; Joshi, Levy, and Takahashi
1975), D-Tree Grammar (DTG; Rambow, Vijay-Shanker, and Weir 1995), Tree Description
Grammars (TDG; Kallmeyer 1999) or Interaction Grammars (IG; Perrier 2000)?
environments sharing all of the listed features are lacking. As we shall see in Section 7
of this article, there have been some proposals for grammar engineering environments
for tree-based grammar (e.g., Candito 1996; Xia, Palmer, and Vijay-Shanker 1999,
but these lack notational expressivity. This is partly due to the fact that tree-based
formalisms offer an extended domain of locality where one can encode constraints
between remote syntactic constituents. If one wants to define such constraints while
giving a modular and incremental specification of the grammar, one needs a high level
of notational expressivity, as we shall see throughout the article (and especially in
Section 4).
In this article, we present XMG (eXtensible MetaGrammar), a framework for
specifying tree-based grammars. Focusing mostly on Feature-Based Lexicalized Tree-
Adjoining Grammars (FB-LTAG) (but using Interaction Grammars [IG] and Multi-
Component Tree-Adjoining Grammars [MC-TAG] to illustrate flexibility), we argue that
XMG departs from other existing computational frameworks for designing tree-based
grammars in three main ways:
 First, XMG is a declarative language. In other words, grammaticality is
defined in an order-independent fashion by a set of well-formedness
592
Crabbe? et al XMG: eXtensible MetaGrammar
constraints rather than by procedures. In particular, XMG permits a
fully declarative treatment of diathesis that markedly departs from the
procedural rules (called meta-rules or lexical rules) previously used to
specify tree-based grammars.
 Second, XMG is notationally expressive. The XMG language supports full
disjunction and conjunction of grammatical units, a modular treatment
of multiple linguistic dimensions, multiple inheritance of units, and a
sophisticated treatment of identifiers. We illustrate XMG?s notational
expressivity by showing (i) how it facilitates the modeling of the tree
fragment hierarchies required to specify tree-based grammars and (ii) how
it permits a natural modeling of the syntax/semantics interface between
semantic representations and syntactic trees as can be used in FB-LTAG.
 Third, XMG is extensible in that its computational architecture facilitates
(i) the integration of an arbitrary number of linguistic dimensions (syntax,
semantics, etc.), (ii) the modeling of different grammar formalisms
(FB-LTAG, MC-TAG, IG), and (iii) the specification of general linguistic
principles (e.g., clitic ordering in French).
The article is structured as follows. Section 2 starts by giving a brief introduction
to FB-LTAG, the grammar formalism we used to illustrate most of XMG?s features. The
next three sections then go on to discuss and illustrate XMG?s three main features?
namely, declarativity, notational expressivity, and flexibility. In Section 3, we focus
on declarativity and show how XMG?s generalized disjunction permits a declarative
encoding of diathesis. We then contrast the XMG approach with the procedural methods
previously resorted to for specifying FB-LTAG. Section 4 addresses notational expressiv-
ity. We present the syntax of XMG and show how the sophisticated identifier handling
it supports or permits a natural treatment (i) of identifiers in tree based hierarchies
and (ii) of the unification-based syntax/semantics interface often used in FB-LTAG. In
Section 5, we concentrate on extensibility. We first describe the operational semantics
of XMG and the architecture of the XMG compiler. We then show how these facilitate
the adaptation of the basic XMG language to (i) different grammar formalisms (IG,
MC-TAG, FB-LTAG), (ii) the integration of specific linguistic principles such as clitic
ordering constraints, and (iii) the specification of an arbitrary number of linguistic
dimensions. In Section 6, we illustrate the usage of XMG by presenting an XMG
specification for the verbal fragment of a large scale FB-LTAG for French augmented
with a unification-based semantics. We also briefly describe the various other tree-
based grammars implemented using XMG. Section 7 discusses the limitations of other
approaches to the formal specification of tree-based grammars, and Section 8 concludes
with pointers for further research.
2. Tree-Adjoining Grammar
A Tree-Adjoining Grammar (TAG) consists of a set of auxiliary or initial elementary
trees and of two tree composition operations, namely, substitution and adjunction.
Initial trees are trees whose leaves are either substitution nodes (marked with ?) or
terminal symbols (words). Auxiliary trees are distinguished by a foot node (marked
with ) whose category must be the same as that of the root node. Substitution inserts a
tree onto a substitution node of some other tree and adjunction inserts an auxiliary tree
593
Computational Linguistics Volume 39, Number 3
N
Marie
Mary
V
V
a
has
V
S
N? V
vu
seen
N?
N
Jean
John
??
S
N
Marie
Mary
V
V
a
has
V
vu
seen
N
Jean
John
Figure 1
Sample derivation of Marie a vu Jean ?Mary has seen John? in a TAG.
into a tree. Figure 1 shows a toy TAG generating the sentence Marie a vu Jean ?Mary has
seen John? and sketches its derivation.1
Among existing variants of TAG, one commonly used in practice is Lexical-
ized FB-LTAG (Vijay-Shanker and Joshi 1988). A lexicalized TAG is such that each
elementary tree has at least one leaf labeled with a lexical item (word), whereas in
an FB-LTAG, tree nodes are additionally decorated with two feature structures (called
top and bottom). These feature structures are unified during derivation as follows. On
substitution, the top features of the substitution node are unified with the top features of
the root node of the tree being substituted in. On adjunction, the top features of the root
of the auxiliary tree are unified with the top features of the node where adjunction takes
place; and the bottom features of the foot node of the auxiliary tree are unified with the
bottom features of the node where adjunction takes place. At the end of a derivation,
the top and bottom feature structures of all nodes in the derived tree are unified.
Implementation of Tree-Adjoining Grammars. Most existing implementations of TAGs fol-
low the three-layer architecture adopted for the XTAG grammar (XTAG Research Group
2001), a feature-based lexicalized TAG for English. Thus the grammar consists of (i) a
set of so-called tree schemas (i.e., elementary trees having a leaf node labeled with a
 referring to where to anchor lexical items2), (ii) a morphological lexicon associating
words with lemmas, and (iii) a syntactic lexicon associating lemmas with tree schemas
(these are gathered into families according to syntactic properties, such as the sub-
categorization frame for verbs). Figure 2 shows some of the tree schemas associated
with transitive verbs in the XTAG grammar. The tree corresponds (a) to a declarative
sentence, (b) to a WH-question on the subject, (c) to a passive clause with a BY-agent,
and (d) to a passive clause with a WH-object. As can be seen, each tree schema contains
an anchor node (marked with ). During parsing this anchor node can be replaced by
any word morphologically related to a lemma listed in the syntactic lexicon as anchor-
ing the transitive tree family.
This concept of tree family allows us to share structural information (tree schemas)
between words having common syntactic properties (e.g., sub-categorization frames).
There still remains a large redundancy within the grammar because many elementary
tree schemas share common subtrees (large coverage TAGs usually consist of hun-
dreds, sometimes thousands, of tree schemas). An important issue when specifying
1 The elementary trees displayed in this article conform to Abeille? (2002), that is, we reject the use of a VP
constituent in French.
2 As mentioned earlier, we describe lexicalized TAG, thus every tree schema has to contain at least one
anchor (node labeled ).
594
Crabbe? et al XMG: eXtensible MetaGrammar
(a) (b)
Sr
NP0 ? VP
V NP1 ?
Sq
NP0 ?
[
wh +
]
[]
Sr
NPNA

VP
V NP1 ?
(c) (d)
Sr [][
mode 3
]
NP1 ? VP
[
mode 3
]
?
?
passive 1
mode 2
?
?
V
?
?
passive 1 +
mode 2 ppart
?
?
[]
PP
P
by
NP0 ?
Sq
NP1 ?
[
wh +
]
[]
Sr [][
mode 3
]
NPNA

VP
[
mode 3
]
?
?
passive 1
mode 2
?
?
V
?
?
passive 1 +
mode 2 ppart
?
?
[]
PP
P
by
NP0 ?
Figure 2
Some tree schemas for English transitive verbs.
such grammars is thus structure sharing. Being able to share structural information is
necessary not only for a faster grammar development, but also for an easier grammar
maintenance (modifications to be applied to the tree schemas would be restricted to
shared structures). In the next section, we will see how XMG declarativity can be
efficiently used to factorize TAGs. In addition, Section 4 will show how XMG notational
expressivity facilitates the specification of another commonly used tree sharing device,
namely, inheritance hierarchies of tree fragments.
Extending TAG with a Unification-Based Semantics. To extend FB-LTAG with a compo-
sitional semantics, Gardent and Kallmeyer (2003) propose to associate each elementary
tree with a flat semantic representation. For instance, in Figure 3, the trees3 for John, runs,
and often are associated with the semantics l0:name(j,john), l1:run(e,s), and l2:often(x),
respectively. Importantly, the arguments of semantic functors are represented by uni-
fication variables which occur both in the semantic representation of this functor and
on some nodes of the associated syntactic tree. Thus in Figure 3, the semantic index s
occurring in the semantic representation of runs also occurs on the subject substitution
node of the associated elementary tree. The value of semantic arguments is then deter-
mined by the unifications resulting from adjunction and substitution. For instance, the
semantic index s in the tree for runs is unified during substitution with the semantic
index j labeling the root node of the tree for John. As a result, the semantics of John often
runs is {l0:name(j,john), l1:run(e,j), l2:often(e)}.
Gardent and Kallmeyer?s (2003) proposal was applied to various semantic phe-
nomena (Kallmeyer and Romero 2004a, 2004b, 2008). Its implementation, however,
3 Cx/Cx abbreviate a node with category C and a top/bottom feature structure including the feature-value
pair { index : x}.
595
Computational Linguistics Volume 39, Number 3
NPj
John
l0:name(j,john)
Sg
NP?s VPgf
Vfe
runs
l1:run(e,s)
VPx
often VP*x
l2:often(x)
? l0:name(j,john), l1:run(e,j), l2:often(e)
Figure 3
A toy lexicalized FTAG with unification-based semantics (l0, l1, l2, e, and j are constants and
s, f, g, x are unification variables).
relies on having a computational framework that associates syntactic trees with flat
semantic formulae while allowing for shared variables between trees and formulae. In
the following sections, we will show how XMG notational expressivity makes it pos-
sible to specify an FB-LTAG equipped with a unification-based semantics.
3. Declarativity
In this section, we show how a phenomenon which is often handled in a procedural
way by existing approaches can be provided with a declarative specification in XMG.
Concretely, we show how XMG supports a declarative account of diathesis that avoids
the drawbacks of lexical rules (e.g., information erasing). We start by presenting the
lexical rule approach. We then contrast it with the XMG account.
3.1 Capturing Diathesis Using Lexical Rules
Following Flickinger (1987), redundancy among grammatical descriptions is often han-
dled using two devices: an inheritance hierarchy and a set of lexical rules. Whereas
the inheritance hierarchy permits us to encode the sharing of common substructures,
lexical rules (sometimes called meta-rules) permit us to capture relationships between
trees by deriving new trees from already specified ones. For instance, passive trees will
be derived from active ones.
Although Flickinger?s (1987) approach was developed for HPSGs, several similar
approaches have been put forward for FB-LTAG (Vijay-Shanker and Schabes 1992;
Becker 1993; Evans, Gazdar, and Weir 1995; XTAG Research Group 2001). One important
drawback of these approaches, however, is that they are procedural in that the order in
which lexical rules apply matters. For instance, consider again the set of trees given
in Figure 2. In the meta-rule representation scheme adopted by Becker (1993), the base
tree (a) would be specified in the inheritance hierarchy grouping all base trees, and
the derived trees (b, c, d) would be generated by applying one or more meta-rules on
this base tree. Figure 4 sketches these meta-rules. The left-hand side of the meta-rule
is a matching pattern replaced with the right-hand side of the meta-rule in the newly
generated tree. Symbol ??? denotes a meta-variable whose matching subtree in the input
is substituted in place of the variable in the output tree. Given these, the tree family in
Figure 2 is generated as follows: (b) and (c) are generated by application to the base
tree (a) of the Wh-Subject and Passive meta-rules, respectively. Further, (d) is generated
by applying first, the Wh-Subject meta-rule and second, the Passive meta-rule to the
base tree.
596
Crabbe? et al XMG: eXtensible MetaGrammar
Passive meta-rule Wh-Subject meta-rule
Sr
?1 NP? VP
V ?2 NP?
? Sr [][
mode 3
]
?2 NP? VP
[
mode 3
]
?
?
mode 2
passive 1
?
?
V
?
?
passive 1 +
mode 2 ppart
?
?
[]
PP
P
by
?1 NP?
Sr
?2NP? ? ?1
? Sq
?2NP? ?
[
wh +
]
[]
Sr
NP?NA

?1
Figure 4
Simplified meta-rules for passive and wh-subject extraction.
More generally a meta-rule is a procedural device that, given a tree instance,
generates a new tree instance by adding, suppressing (hence possibly substituting)
information in grammatical units. Prolo (2002) defines a set of meta-rules that can
be used to specify a large FB-LTAG for English. Given an ordered set of meta-rules,
however, there is no guarantee that the trees they derive are linguistically appropriate
and that the derivation process terminates. Thus, to ensure termination and consistency,
Prolo needs to additionally provide rule ordering schemes (expressed as automata).
3.2 XMG: Capturing Diathesis Using Disjunction
XMG provides an alternative account for describing tree sets such as that of Figure 2
without lexical rules and without the related ordering constraints. In essence, the
approach consists of enumerating trees by combining tree fragments using conjunction
and disjunction.
More specifically, the tree set given in Figure 2 can be generated by combining
some of the tree fragments sketched in Figure 5 using the following conjunctions and
disjunctions:4
Subject ? CanonicalSubject ? Wh-NP-Subject (1)
ActiveTransitiveVerb ? Subject ? ActiveVerb ? CanonicalObject (2)
PassiveTransitiveVerb ? Subject ? PassiveVerb ? CanonicalByObject (3)
TransitiveVerb ? ActiveTransitiveVerb ? PassiveTransitiveVerb (4)
The first clause (Subject) groups together two subtrees representing the possi-
ble realizations of a subject (canonical and wh). The next two clauses define a tree
set for active and passive transitive verbs, respectively. The last clause defines the
TransitiveVerb family as a disjunction of the two verb forms (passive or active). In sum,
the TransitiveVerb clause defines the tree set sketched in Figure 2 as a disjunction of
conjunctions of tree fragments.
One of the issues of meta-rules reported by Prolo (2002) is the handling of feature
equations. For a number of cases (including subject relativization in passive trees),
4 For now, let us consider that the tree fragments are combined in order to produce minimal trees by
merging nodes whose categories (and features) unify. In the next section, we will see how to precisely
control node identification using either node variables or node constraints.
597
Computational Linguistics Volume 39, Number 3
Canonical Subject ? Wh-NP-Subject ? Canonical Object ? Wh-NP-Object ?
Sr
NP? VP
Sq
NP?
[
wh +
]
[]
Sr
NPNA

VP
VP
V NP?
Sq
NP?
[
wh +
]
[]
Sr
VP NPNA

Canonical By Object ? Wh By Object ? Active Verb ? Passive Verb ?
VP
V PP
P
by
NP?
VP
PP
P
by
NP?
V
Sr
VP
V
Sr[]
[
mode 3
]
VP
[
mode 3
]
?
?
passive 1
mode 2
?
?
V
?
?
passive 1 +
mode 2 ppart
?
?
[]
Figure 5
Tree fragments.
ad hoc meta-rules are needed, for a unified tree transformation cannot be defined. In
a declarative approach such as the one here, dealing with feature equations can be
done relatively easily. Let us imagine that we now want to extend the trees of Figure 2
with feature equations for subject?number agreement. We can for instance do so by
defining the following tree fragment (the dashed line indicates that the VP node can be
a descendant, not only a daughter, of the S node):5
SubjAgreement ? S
NP?
[
num 1
]
[
num 1
]
VP
[
num 1
]
[
num 1
]
Then we extend the definition of Subject as follows:
Subject ? SubjAgreement ? ( CanonicalSubject ? Wh-NP-Subject ) (5)
If we want to get further with the description of transitive verbs, for instance by
taking into account wh-objects and by-objects, this can be done as follows. We first
define the elementary fragments Wh-NP-Object and Wh-By-Object (see Figure 5), and
then define the following additional combinations:6
ActiveTransitiveVerb ? CanonicalSubject ? ActiveVerb ? Wh-Np-Object (6)
PassiveTransitiveVerb ? CanonicalSubject ? PassiveVerb ? Wh-By-Object (7)
5 Note that in XMG, it is not mandatory to define any tree structure inside SubjAgreement. We could define
independent NP and VP nodes, and associate them with variables, say n1 and n2. n1 and n2 would then
be exported and reused directly in the classes CanonicalSubject and Wh-NP-Subject, respectively.
6 Note that these clauses only consider canonical subjects to avoid having both a Wh-subject and a
Wh-object. This is not entirely satisfactory, as we would prefer to define a single abstraction over objects
(as was done for subjects) and use it wherever possible. There would then be another mechanism to
capture this exception and cause the invalid combination to fail (that is, the resulting tree description not
to have any model). Such a mechanism exists in XMG, and is called linguistic principle (see Section 5).
598
Crabbe? et al XMG: eXtensible MetaGrammar
Evans, Gazdar, and Weir (1995) argue for the necessity of using lexical rules for
grammatical description based on two arguments: (i) morphology is irregular and has
to be handled by a non-monotonic device and (ii) erasing rules such as the agentless
passive (John eats an apple / An apple is eaten ) are needed to erase an argument from
the canonical base tree. Neither of these arguments holds here, however: The first
argument because we describe tree schema hence lexical and morphological issues are
ruled out; the second because agentless passive and, more generally, argument erasing
constructions can simply be defined by an additional clause such as:
AgentlessPassiveTransitiveVerb ? Subject ? PassiveVerb (8)
To summarize, using a declarative language to specify a tree-based grammar offers
an adequate level of control on the structures being described while avoiding having
to deal with ordering and termination issues. It facilitates grammar design and mainte-
nance, by providing an abstract view on grammar trees, uniquely made of monotonic
(no information removal) combinations of tree fragments.
4. Notational Expressivity
We now focus on notational expressivity and show how XMG supports a direct
encoding of (i) distinct linguistic dimensions (here syntax, semantics and the syntax/
semantics interface) and (ii) the various types of coreferences7 that arise in the devel-
opment of tree-based grammars.
The syntax of the XMG language can be formally defined as follows.
Class ::= NameC1,...,Ckx1,...,xn ? Content (9)
Content ::= ?SYN, SEM, DYN? | Name | Content ? Content | Content ? Content
(10)
SYN ::=
n1 ? n2 | n1 ?+ n2 | n1 ?? n2 | n1 ? n2 | n1 ?+ n2 | n1 ?? n2 |
n1[f1 : v1,..., fk : vk] | n1(c1 : cv1,..., cl : cvl) | n1 = n2 | x = Ci.y |
n1 (c1 : cv1,..., cl : cvl) [f1 : v1,..., fk : vk] | SYN ? SYN
(11)
SEM ::= li : p(E1,...,En) | li ? hj | SEM ? SEM (12)
DYN ::= ? f1 : v1,...,fn : vn ? (13)
Here and in what follows, we use the following notational conventions. Ci denote
variables over class names; xi, x, and y are variables ranging over tree nodes or feature
values; ni refer to node variables; f, fi are features and v, vi and feature values (constants
or variables); li, hj, p, and Ei are variables over semantic labels, semantic holes, predi-
cates, and predicate arguments in flat semantic formulae, respectively.8 [ ] are used to
associate a node variable with some feature constraint. ( ) are used to associate a node
variable with some property constraint (e.g., node colors, see Section 5). ci and cvi denote
7 By coreference, we mean the sharing of information between distinct elementary fragments of the
grammar specification.
8 See Gardent and Kallmeyer (2003) for a detailed introduction to flat semantics.
599
Computational Linguistics Volume 39, Number 3
a property constraint and a property constraint value, respectively. Ci.y denotes the y
variable declared in class Ci and = is unification; ? and ? denote linear precedence and
immediate dominance relations between nodes. Finally, +, ? represent the transitive and
transitive-reflexive closure of a relation, respectively.
The first two clauses of the formal definition here specify XMG classes and how they
combine. The next three clauses define the languages supported for describing three lin-
guistic dimensions, namely, syntax (SYN), semantics (SEM), and the syntax/semantics
interface (called DYN for dynamic interface). We now discuss each of these in more
detail starting bottom?up with the three linguistic dimensions and ending with the
control language that permits us to combine basic linguistic units into bigger ones.
SYN. The XMG formalism for syntax (copied here for convenience) is a tree description
logic similar to that proposed by Vijay-Shanker and Schabes (1992) and Rogers and
Vijay-Shanker (1994) to describe tree-based grammars.
SYN ::= n1 ? n2 | n1 ?+ n2 | n1 ?? n2 | n1 ? n2 | n1 ?+ n2 | n1 ?? n2 |
n1[f1 : v1,..., fk : vk] | n1(c1 : cv1,..., cl : cvl) | n1 = n2 | x = Ci.y |
n1 (c1 : cv1,..., cl : cvl) [f1 : v1,..., fk : vk] | SYN ? SYN
It includes tree node variables, feature names, feature values, and feature variables.
Tree node variables can be related by equality (node identification), precedence (imme-
diate or non-immediate), and dominance (immediate or non-immediate). Tree nodes
can also be labeled with feature structures of depth 2, that is, sets of feature/value
pairs where feature values are either variables, constants (e.g., syntactic category), or
non-recursive feature structure (e.g., top and bottom feature structures).
Here is a graphical illustration of how tree logic formulae can be used to describe
tree fragments: The depicted tree fragment is a model satisfying the given formula.
n1 ? n2 ? n1 ? n3 ? n2 ? n3
? n1[cat : S] ? n2(mark : subst) [cat : NP] ? n3[cat : VP]
S
NP? VP
One distinguishing feature of the XMG tree language is the introduction of node
constraints (n1(c : cv)) that generalize Muskens and Krahmer?s (1998) use of positive
and negative node markings. Concretely, node constraints are attribute-value matri-
ces, which contain information to be used when solving tree descriptions to produce
grammar trees. In other words, node constraints are used to further restrict the set
of models satisfying a tree description. As an example of node constraint, consider
node annotations in FB-LTAG (foot node, substitution node, null-adjunction, etc.). Such
annotations can be used as node constraints to allow the description solver to apply
well-formedness constraints (e.g., there is at most one foot node).
Another interesting feature of XMG concerns the inclusion of the dot operator,
which permits us to identify variables across classes in cases where name sharing cannot
be resorted to. When a variable y is declared in a class C, the latter being instantiated
within a class D, y can be accessed from D by C.y (the identifier y still being available
in D?s namespace).
600
Crabbe? et al XMG: eXtensible MetaGrammar
SEM. The semantic dimension supports a direct encoding of the flat semantic formulae
used by Gardent and Kallmeyer (2003):
SEM ::= li : p(E1,...,En) | li ? hj | SEM ? SEM
where li : p(E1,..., En) represents a predicate p with label li and arguments E1,..., En and
li ? hj is a scope constraint between label li and scope hj. Expressions (predicate argu-
ments Ei) can refer to semantic holes, constants (atomic values), or unification variables
(written x, y hereafter).
For instance, the following flat semantic formula can be used to underspecify the
meaning of the sentence ?Every dog chases a cat?:
l0 : ?(x, h1, h2) ? l1 ? h1 ? l1 : Dog(x) ? l2 ? h2 ? l2 : Chase(x, y)
? l3 : ?(y, h3, h4) ? l4 ? h3 ? l4 : Cat(y) ? l2 ? h4
(14)
This formula denotes the following two first-order logic formulae, thereby describing
the two possibles readings of this sentence.9
l0 : ?(x, l1, l3) ? l1 : Dog(x) ? l2 : Chase(x, y) ? l3 : ?(y, l4, l2) ? l4 : Cat(y) (15)
l0 : ?(x, l1, l2) ? l1 : Dog(x) ? l2 : Chase(x, y) ? l3 : ?(y, l4, l0) ? l4 : Cat(y) (16)
DYN. The DYN dimension generalizes Kinyon?s hypertag (Kinyon 2000) which is
unified whenever two tree fragments are combined. Similarly, in XMG the DYN
dimension is a feature structure that is unified whenever two XMG classes are com-
bined through inheritance or through conjunction (see the discussion on XMG control
language, subsequently).
For instance, the following constraints ensure a coreference between the index I
occurring in the syntactic dimension and the argument X occurring in the semantic
dimension (indexsubject and arg1 are feature names, and E, I, X, and V local unification
variables).
C1 ? Node [idx : I] ? ?indexsubject : I? (17)
C2 ? L : P(E) ? L : Theta1(E, X) ? ?arg1 : X? (18)
SubjectArg1 ? C1 ? C2 ? ?indexsubject : V, arg1 : V? (19)
More generally, the DYN dimension permits us to unify nodes and feature values
that belong to distinct classes and dimensions, and are thus often not related within
the inheritance hierarchy. As we shall see in Section 6, the DYN dimension permits
a modular account of the syntax/semantics interface in which linking constraints can
be stipulated separately and reused to specify the various diatheses.
In other words, the DYN feature structure allows us to extend the scope of some
specific variables so that they can be unified with variables (or values) introduced
in some other classes of the metagrammar. This concept of scope extension can be
compared with that of hook in Copestake, Lascarides, and Flickinger (2001).
9 For more details on the interpretation of flat semantics and on its association with a grammar of natural
language, see Gardent (2008).
601
Computational Linguistics Volume 39, Number 3
Control language. The linguistic units (named Content here) defined by the linguist can
be abstracted and combined as follows:
Class ::= NameC1,...,Ckx1,...,xn ? Content
Content ::= ?SYN, SEM, DYN? | Name | Content ? Content | Content ? Content
The first clause states that the linguistic information encoded in Content is abstracted in
a class named Name and that this class inherits classes C1,..., Ck and exports variables
x1,..., xn. That is, XMG allows for abstraction, inheritance, and variable exports. By
default, variables (referring to nodes and feature values) are local to a class. Export
statements extend the scope of a variable to all sub-classes, however. An exported
variable can also be accessed from outside its class in case of class instantiation (using
the dot operator introduced earlier in this section). The second clause states that an
XMG class consists of a syntactic, a semantic, and a dynamic description (each of them
possibly empty), and that XMG classes can be combined by conjunction and disjunc-
tion and reused through class instantiation. The notation ?SYN, SEM, DYN? represents
simultaneous contributions (possibly empty) to all three dimensions.10
The XMG control language differs from other frameworks used to specify tree-
based grammars (Vijay-Shanker and Schabes 1992; Xia et al 1998; Candito 1999)
in two main ways. First, it supports generalized conjunctions and disjunctions of
classes. As shown in Section 3, this permits us, inter alia, a declarative treatment of
diathesis.
Second, it allows for both local and exported variables. As mentioned in Section 3, a
common way to share structure within a tree-based grammar is to define an inheritance
hierarchy of either tree fragments (Evans, Gazdar, and Weir 1995) or tree descriptions
(Vijay-Shanker and Schabes 1992; Candito 1996; Xia 2001). When considering an FB-
LTAG augmented with unification semantics, the hierarchy will additionally contain
semantic representations and/or tuples made of tree fragments and semantic represen-
tations. In all cases, the question arises of how to handle identifiers across classes and,
more specifically, how to share them.
In Candito?s (1996) approach, tree nodes are referred to using constants so that
multiple occurrences of the same node constant refer to the same node. As pointed out
in Gardent and Parmentier (2006), global names have several non-trivial shortcomings.
First, they complicate grammar writing in that the grammar writer must remember the
names used and their intended interpretation. Second, they fail to support multiple uses
of the same class within one class. For instance, in French, some verbs sub-categorize
for two prepositional phrases (PP). A natural way of deriving the tree for such verbs
would be to combine a verbal tree fragment with two instances of a PP fragment. If,
however, the nodes in the PP fragment are labeled with global names, then the two
occurrences of these nodes will be identified thereby blocking the production of the
appropriate tree.11
A less restrictive treatment of identifiers is proposed by Vijay-Shanker and Schabes
(1992), where each tree description can be associated with a set of declared node
variables and subsets of these node variables can be referred to by descriptions in the
10 Although formally precise, this notation can be cumbersome. In the interest of legibility we adopt
throughout the convention that SYN stands for ?SYN, , ?, SEM for ? , SEM, ?, and DYN for ? , , DYN?.
11 An analogous situation may arise in English with ditransitive verbs requiring two direct objects.
602
Crabbe? et al XMG: eXtensible MetaGrammar
hierarchy that inherit from the description in which these node variables were declared.
For instance, if entity A in the hierarchy declares such a special node variable X and B
inherits from A, then X can be referred to in B using the notation A.X.12
XMG generalizes Vijay-Shanker and Schabes?s (1992) approach by integrating an
export mechanism that can be used to extend the scope of a given identifier (node
or feature value variable) to classes that inherit from the exporting class. Thus if
class B inherits from class A and class A exports variable X, then X is visible in B
and its reuse forces identity. If B inherits from several classes and two (or more) of
these inherited classes export the same variable name X, then X is not directly visible
from B. It can be accessed though using the dot operator. First A is identified with a
local variable (e.g., T = A), then T.X can be used to refer to the variable X exported
by A.
To summarize, XMG allows for local variables to be exported to sub-classes as well
as for prefixed variables?that is, variables that are prefixed (using the dot operator)
with a reference to the class in which they are declared. In this way, the pitfalls in-
troduced by global names are avoided while providing enough expressivity to handle
variable coreference (via the definition of variable namespaces). Section 6 will further
illustrate the use of the various coreference devices made available by XMG showing
how they concretely facilitate grammar writing.
Let us finally illustrate variable handling with XMG in the example of Figure 2.
Recall that we define the trees of Figure 2 as the conjunctions and disjunctions of some
tree fragments of Figure 5, such as:
Subject ? SubjAgreement ? ( CanonicalSubject ? Wh-NP-Subject ) (20)
CanonicalSubject can be defined as a tree description formula as follows (only variables
n2 and n3 are exported):
CanonicalSubjectn2,n3 ?
n1 ? n2 ? n1[cat : S] ? n2(mark : subst) [cat : NP]?
n1 ? n3 ? n3[cat : VP] ? n2 ? n3
(21)
The class Wh-NP-Subject is defined accordingly (i.e., by means of a slightly more
complex tree description formula using the n2 and n3 variable identifiers to refer to
the nodes involved in subject agreement). The class SubjAgreement is defined slightly
differently (we do not impose any tree relation between the node concerned with
number agreement):
SubjAgreementn1,n2 ?
n1 [[top : [num : x]] [bot : [num : x]]]?
n2 [[top : [num : x]] [bot : [num : x]]]
(22)
12 In fact, the notation used by Vijay-Shanker and Schabes (1992) is attr:X with attr an attribute variable
ranging over a finite set of attributes, to indicate special node variables that scope outside their class; and
attr(A) to refer to such variables from outside the entity in which they were declared. We use a different
notation here to enforce consistency with the XMG notation.
603
Computational Linguistics Volume 39, Number 3
We can then explicitly control the way the fragments combine as follows:
Subject ?
C1 = SubjAgreementn1,n2 ?
C2 = ( CanonicalSubjectn2,n3 ? Wh-NP-Subjectn2,n3 ) ?
C1.n1 = C2.n2 ? C1.n2 = C2.n3
(23)
In this example, we see how to constrain, via variable export and unification, some
given syntactic nodes to be labeled with feature structures defined somewhere else in
the metagrammar. We use XMG?s flexible management of variable scope to deal with
node coreference. Compared with previous approaches on metagrammars such as those
of Candito (1996), Xia (2001), having the possibility of handling neither only global nor
only local variables, offers a high level of expressivity along with a precise control on
the structures being described.
5. Extensibility
A third distinguishing feature of XMG is extensibility. XMG is extensible in that
(i) dimensions can be added and (ii) each dimension can be associated with its own
interpreter. In order to support an arbitrary number of dimensions, XMG relies on a
device permitting the accumulation of an arbitrary number of types of literals, namely,
Extensible Definite Clause Grammar (EDCG) (Van Roy 1990). Once literals are accumu-
lated according to their type (i.e., each type of literals is accumulated separately), they
can be fed to dedicated interpreters. Because each of these sets of literals represents
formulas of a description language, these interpreters are solvers whose role is to
compute models satisfying the accumulated formulas.
Via this concept of separated dimensions, XMG allows us (i) to describe different
levels of language (not only syntax, but also semantics and potentially morphology,13
etc.), and (ii) to define linguistic principles (well-formedness constraints to be applied on
the structures being described). These principles depend either on the dimension (e.g.,
scope constraints in flat semantics), the target formalism (e.g. cooccurrence predicate-
arguments in FB-LTAG), or the natural language (e.g., clitic ordering in Romance lan-
guages) being described.
In what follows, we start by showing how XMG handles dimensions independently
from each other introducing EDCG (Section 5.1). We then summarize the architecture
of the XMG system (Section 5.2). We finally show how different solvers can be used
to implement various constraints on each of these dimensions (Section 5.3). In partic-
ular, we discuss three kinds of extensions implemented in XMG: extension to several
grammar formalisms, integration of explicit linguistic generalizations, and inclusion of
color-based node marking to facilitate grammar writing.
5.1 XMG: Accumulating and Interpreting an Arbitrary Number of Descriptions
Accumulating (tree) descriptions. First, let us notice that XMG is nothing other than a logic
language a` la Prolog (Duchier, Parmentier, and Petitjean 2012). More precisely, an XMG
13 Recently, XMG has been used to describe the morphology of verbs in Ikota, a Bantu language spoken in
Gabon (Duchier, Parmentier, and Petitjean 2012).
604
Crabbe? et al XMG: eXtensible MetaGrammar
specification is a collection of Horn clauses, which contribute a declarative description
of what a computational tree grammar is.
Logic Program XMG Metagrammar
Clause ::= Head ? Body
Body ::= Fact | Head |
Body ? Body |
Body ? Body
Query ::= Head
Class ::= Name ? Content
Content ::= Description | Name |
Content ? Content |
Content ? Content
Axiom ::= Name
Recall that the descriptions handled by XMG are in fact tuples of the form
?SYN, SEM, DYN?. An XMG class can thus describe, in a non-exclusive way, any of these
three levels of description. If one wants to add another level of description (i.e., another
dimension), one needs to extend the arity of this tuple. Before discussing this, let us first
see how such tuples are processed by XMG.
As mentioned earlier, XMG?s control language is comparable to Horn clauses.
A common way to represent Horn clauses is by using Definite Clause Grammar
(DCG) (Pereira and Warren 1980). Concretely, a DCG is a rewriting system (namely, a
context-free grammar), where the symbols of the rewriting rules are equipped with
pairs of unification variables (these are usually called difference list or accumulator)
(Blackburn, Bos, and Striegnitz 2006, page 100). As an illustration, consider the follow-
ing toy example.
s --> np,vp. np --> det,n.
vp --> v,np. vp --> v.
det --> [the]. det --> [a].
n --> [cat]. n --> [mouse].
v --> [eats].
The string language described by this DCG can be obtained by submitting the query
s(X,[]) where X is a unification variable to be bound with lists of facts (these being the
sentences belonging to the string language). As we can easily see, this language contains
the sentences ?a cat eats,? ?the cat eats,? ?a mouse eats,? ?the mouse eats,? ?a cat eats a
mouse,? ?a mouse eats a cat,? and so on.
Similarly, we can represent XMG classes as DCG clauses. For instance, the combina-
tions of syntactic fragments given in relations (1)?(4) can be rewritten as DCG clauses
as follows:
subject --> canonicalSubject.
subject --> whNpSubject.
activeTransitiveVerb --> subject, activeVerb, canonicalObject.
passiveTransitiveVerb --> subject, passiveVerb, canonicalByObject.
transitiveVerb --> activeTransitiveVerb.
transitiveVerb --> passiveTransitiveVerb.
Disjunctions (e.g., the subject specification) translate to multiple clauses with iden-
tical heads and conjunctions (e.g., activeTransitiveVerb) to a clause body.
In our case, the terminal symbols of the underlying DCG are not just facts, but
tuples of descriptions. In other words, the DCG clause whose head is canonicalSubject
is associated with a tuple of the following form (the dots have to be replaced with
605
Computational Linguistics Volume 39, Number 3
adequate descriptions, these can contain unification variables, whose scope is by default
local to the clause):
canonicalSubject --> [desc(syn(...),sem(...),dyn(...))].
In order to allow for an extension of XMG to an arbitrary number of dimensions,
instead of compiling XMG classes into a DCG whose accumulator stores tuples with
a fixed arity, these classes are compiled into an EDCG (Van Roy 1990). EDCG are DCG
with multiple accumulators. In XMG, each dimension is thus allocated a dedicated
accumulator in the underlying EDCG.
Note that although the content of the various dimensions is accumulated separately,
dimensions may nevertheless share information either via local unification variables
(if the XMG class defines several dimensions locally), via exported unification vari-
ables (in case of class instantiation or inheritance), or via the shared unification variables
supported by the DYN dimension.
At the end of the EDCG execution, we obtain, for each axiom of the metagrammar
(i.e., for each class name to be valuated), a list of description formulas per accumulator.
These lists are grouped together into a tuple of lists of the following form (N is the
number of dimensions, and consequently of accumulators):
desc(accu1(L1),accu2(L2), ... ,accuN(LN))
Each element (i.e., list Li) of such a tuple is a complete description of a given dimension,
where shared variables have been unified (via unification with backtracking).
Solving (tree) descriptions. As illustrated earlier, interpreting XMG?s control language in
terms of an EDCG yields tuples whose arity is the number of dimensions defined by
the linguist, that is, triples of the form ?SYN, SEM, DYN? if syntax, semantics, and the
dynamic interface are described.
For each dimension D, XMG includes a constraint solver SD that computes the set of
minimal models MD = SD(dD) satisfying the description (dD) of that dimension. In other
words, each dimension is interpreted separately by a specific solver. For instance, the
syntactic dimension is handled by a tree description solver that produces, for a given
tree description, the set of trees satisfying that description, whereas the solver for the
semantic dimension simply outputs the flat semantic representation (list of semantic
literals) built by the EDCG through accumulation.
Note that, although solvers are distinct, the models computed in each dimension
may nonetheless be coupled through shared variables. In that case, these variables can
constrain the models computed by the respective solvers. For instance, shared variables
can be used for the syntactic tree description solver to be parametrized by some value
coming from the semantic input description. Note that the output of the solving process
is a Cartesian product of the sets of minimal models of each solver. As a consequence,
the worst case complexity of metagrammar compilation is that of the various solvers
associated with relevant dimensions.
In addition to having separate solvers for each dimension, the constraint-solving
approach used in XMG permits us to modularize a given solver by combining different
principles. Each such principle enforces specific constraints on the models satisfying
the description of a given dimension. For instance, for the syntactic dimension of an
FB-LTAG, a set of principles is used to enforce that the structures produced by the
compiler are trees, and that these conform to the FB-LTAG formalism (e.g., there is no
tree having two foot nodes).
606
Crabbe? et al XMG: eXtensible MetaGrammar
5.2 Architecture
The XMG compiler14 consists of the following three modules:
 A compiler that parses XMG?s concrete syntax and compiles XMG classes
into clauses of an EDCG.
 A virtual machine (VM), which interprets EDCG. This VM performs
the accumulation of dimensions along with scope management and
identifiers resolution. This VM is basically a unification engine equipped
with backtracking, and which is extended to support EDCG. Although its
architecture is inspired by the Warren Abstract Machine (A??t-Kaci 1991),
it uses structure-sharing to represent and unify prolog terms, and, given
a query on a class, processes the conjunctions, disjunctions, inheritance,
and export statements related to that class to produce its full definition,
namely, a tree description for the SYN dimension, a flat semantic formula
for the SEM dimension, and a feature structure for the DYN dimension.
 A constraint-solving phase that produces for each dimension the minimal
models satisfying the input description as unfolded by the preceding
two steps.
As already mentioned, the first part is extensible in that new linguistic dimensions
can be added by specifying additional dedicated accumulators to the underlying EDCG.
The second part is a unification engine that interprets EDCG while performing both term
unification and polarized unification (i.e., unification of polarized feature structures, as
defined by Perrier [2000], and discussed in Section 5.3.1). This extended unification is
the reason why XMG does not merely recourse to an existing Prolog engine to process
EDCG, but relies on a specific VM instead.
The third part is completely modular in that various constraint solvers can be
plugged in depending on the requirements set by the dimensions used, and the chosen
grammatical framework. For instance, the SYN dimension is solved in terms of tree
models, and the SEM dimension is solved in terms of underspecified flat semantic
formulae (i.e., the input semantics remains untouched modulo the unification of its
shared variables).
Importantly, these additional solvers can be ?turned on/off? (via a primitive of the
XMG language) so that, for instance, the same processor can be used to compile an
XMG specification for an FB-LTAG using linguistic principles such as those defined in
the next section (i.e., clitic ordering principle) or not.
5.3 Three Extensions of XMG
We now show (i) how the modular architecture of the XMG compiler permits us
to specify grammars for several tree-based linguistic formalisms; (ii) how it can be
extended to enforce language specific constraints on the syntactic trees; and (iii) how
additional formal constraints (namely node marking) can be integrated to simplify node
identifications (and consequently grammar writing).
14 The XMG compiler is open source software released under the terms of the CeCILL GPL-compliant
licence. See http://sourcesup.renater.fr/xmg.
607
Computational Linguistics Volume 39, Number 3
Eq
Up
Down
Left
Right
Figure 6
Partition of the nodes of tree models.
5.3.1 TAG, MC-TAG, and IG: Producing Trees, Tree Sets, or Tree Descriptions. XMG in-
tegrates a generic tree solver that computes minimal tree models from tree descrip-
tion logic formulae built on the language SYN introduced in Section 4. This solver
integrates the dominance solving technique proposed by Duchier and Niehren (2000)
and can be summarized as follows. A minimal tree model is described in terms of
the relative positions of its nodes. For each node n in a minimal tree model T, the
set of all the nodes of T can be partitioned in five subsets, depending on their po-
sition relative to n. Hence, for each node variable n appearing in a tree description,
it is first associated with an integer (called node id). We then define the five sets
of node ids (i.e., sets of integers) Downn, Upn, Leftn, Rightn, and Eqn referring to the
ids of the nodes located below, above, on the left, on the right, or identified with n,
respectively (see Figure 6). Note that we require that these sets are a partition of all
node ids.
Using this set-based representation of a model, we translate each node relation
from the input formula (built on the tree description language introduced in Section 4)
into constraints on the sets of node ids that must hold in a valid model. For instance,
the sub-formula n1 ?+ n2, which states that node n1 strictly precedes node n2, is
translated into:
n1 ?+ n2 ? EqDownn1 ? Leftn2 ? EqDownn2 ? Rightn1?
Rightn2 ? Rightn1 ? Leftn1 ? Leftn2
(24)
where15 EqDownx = Eqx unionmulti Downx for x ? {n1, n2}. In other words, in a valid minimal
tree model, the set of nodes below or equal to n1 is included in the set of nodes (strictly)
on the left of n2, the set of nodes below or equal to n2 is included in the set of nodes
(strictly) on the right of n1, the set of nodes on the right of n2 is included in the set of
nodes on the right of n1, and finally the set of nodes on the left of n1 is included in the
set of nodes on the left of n2.
Once all input relations are translated into set constraints, the solver uses standard
Constraint Satisfaction techniques (e.g., a first-fail exploration of the search tree) to find a
set of consistent partitions. Finally, the nodes of the models are obtained by considering
nodes with distinct Eqn.
15 unionmulti represents disjoint union.
608
Crabbe? et al XMG: eXtensible MetaGrammar
FB-LTAG trees. To support the specification of FB-LTAG trees, the XMG compiler extends
the generic tree solver described here with a set of constraints ensuring that the trees are
well-formed TAG trees. In effect, these constraints require the trees to be linear ordered
trees with appropriate decorations. Each node must be labeled with a syntactic category.
Leaf nodes are either terminal, foot, or substitution nodes. There is at most one foot
node per tree and the category of the foot node must be identical to that of the root
node. Finally, each tree must have at least one leaf node that is an anchor.
MCTAG tree sets. Where FB-LTAG consists of trees, MC-TAG (Weir 1988) consists of sets
of trees. To support the specification of MC-TAG, the sole extension needed concerns
node variables that are not dominated by any other node variable in the tree description.
Whereas for FB-LTAG, these are taken to denote either the same root node or nodes that
are connected to some other node (i.e., uniqueness of the root), for MC-TAG they can
be treated as distinct nodes, thereby allowing for models that are sets of trees rather
than trees (Parmentier et al 2007). In other words, the only modification brought to the
tree description solver is that, in MC-TAG mode, it does not enforce the uniqueness of
a root node in a model.
IG polarized tree descriptions. IG (Perrier 2000) consist of tree descriptions whose node
variables are labeled with polarized feature structures. A polarized feature structure is
a set of polarized feature triples (f, p, v) where f and v are standard features and feature
values, respectively, and p is a polarity value in {?,?,=,?}. Polarities are used to
guide parsing in that a valid derivation structure must neutralize polarities.
To support an XMG encoding of IG, two extensions are introduced, namely, (i) the
ability to output tree descriptions rather than trees, and (ii) the ability to write polarized
feature structures. The first extension is trivially realized by specifying a description
solver that ensures that any output description has at least one tree model. For the
second point, the SYN language is extended to define polarized feature structures and
the unification engine to support unification of polarized features (for instance, a ?
feature will unify with a neutral (=) feature to yield a ? polarized feature value triple).
5.3.2 Adding Specific Linguistic Constraints: The Case of Clitics. XMG can be extended
to support specific constraints on tree descriptions (e.g., constraints on node linear
order), which make it possible to describe linguistic-dependent phenomena, such as,
for instance, clitic ordering in French, at a meta-level (i.e., within the metagrammar).
According to Perlmutter (1970), clitics are subject to two hard constraints. First,
they appear in front of the verb in a fixed order according to their rank (Exam-
ples 25a and 25b).16 Second, two different clitics in front of the verb cannot have the
same rank (Example 25c).
(25) a. Jean le3 lui4 donne.
?John gives it to him.?
b. *Jean lui4 le3 donne.
*?John gives to him it.?
c. *Jean le3 la3 donne.
*?John gives it it.?
16 In (Examples 25a?c), the numbers on the clitics indicate their rank.
609
Computational Linguistics Volume 39, Number 3
S
N? ?+ V?
?
V?
Cl?3 ?+ V
?
V?
Cl?4 ?+ V
?
S
V?
V
?
S
N? V?
Cl?3 Cl?4 V
S
N? V?
Cl?4 Cl?3 V
Figure 7
Clitic ordering in French.
To support a direct encoding of Perlmutter?s observation, XMG includes both a
node uniqueness principle and a node ordering principle. The latter allows us to label
nodes with some property (let us call it rank) whose value is an integer (for instance,
one can define a node as n1(rank : 2)[cat : Cl]). When solving tree descriptions, XMG
further requires that in a valid tree model, (i) there are no two nodes with the same
rank and (ii) sibling nodes labeled with a rank are linearly ordered according to their
rank.
Accordingly, in the French grammar of Crabbe? (2005), each node labeled with a clitic
category is also labeled with a numerical node property representing its rank.17 XMG
ordering principle then ensures that the ill-formed tree crossed out in Figure 7 is not
produced. Note that in Figure 7, every type of clitic is defined locally (i.e., in a separate
class), and that the interactions between these local definitions are handled by XMG
using this rank principle, to produce only one valid description (pictured to the right of
the arrow).
That is, XMG ordering constraints permit a simple, declarative encoding of the
interaction between clitics. This again contrasts with systems based on lexical rules. As
noted by Perlmutter (1970), if clitics are assumed to be moved by transformations, then
the order in which lexical rules apply this movement must be specified.
To implement the uniqueness principle, one needs to express the fact that in a valid
model ?, there is only one node having a given property p (i.e., a parameter of the
constraint, here the value of the rank node property). This can be done by introducing,
for each node n of the description, a Boolean variable pn indicating whether the node
denoting n in the model has this property or not (i.e., are there two nodes of identical
rank?). Then, if we call V?p the set of integers referring to nodes having the property p in
a model, we have: pn ? (Eqn ? V
?
p ) = ?. Finally, if we represent pn being true with 1 and
pn being false with 0,18 and we sum pn for each n in the model, we have that in a valid
model this sum is strictly lower than 2:
?
n?? pn < 2.
To implement the ordering principle, one needs to express the fact that in a valid
model ?, two sibling nodes n1 and n2 having a given property p of type integer and
of values p1 and p2, respectively, are such that the linear precedence between these
nodes conform to the natural order between p1 and p2. This can be done by first
introducing, for each pair of nodes n, m of the description, a Boolean variable bn,m
indicating whether they have the same ancestors: bn,m ? (Upn ? Upm) = (Upn ? Upm).
For each pair of nodes that do so, we check whether they both have the property p,
17 Recall that node properties are features whose values are used by the tree description solver in order to
restrict the set of valid models. These properties may not appear in the trees produced from the input
metagrammar. For instance, the rank property is not part of the FB-LTAG formalism, and thus does not
appear in the FB-LTAG elementary trees produced by XMG.
18 These integer representations are usually called reified constraints.
610
Crabbe? et al XMG: eXtensible MetaGrammar
and if this is the case, we add to the input description a strict precedence constraint on
these nodes according to their respective values of the property p:19
bn,m ? (pn < pm) ? n ?+ m (26)
bn,m ? (pm < pn) ? m ?+ n (27)
5.3.3 Adding Color Constraints to Facilitate Grammar Writing. To further ease grammar
development, XMG supports a node coloring mechanism that permits nameless node
identification (Crabbe? and Duchier 2004), reminiscent of the polarity-based node iden-
tification first proposed by Muskens and Krahmer (1998) and later used by Duchier
and Thater (1999) and Perrier (2000). Such a mechanism offers an alternative to explicit
node identification using equations between node variables. The idea is to label node
variables with a color property, whose value (either red, black, or white) can trigger
node identifications.
This mechanism is another parameter of the tree solver. When in use, the valid
tree models must satisfy some color constraints, namely, they must only have red or
black nodes (no remaining white nodes; these have to be identified with some black
nodes). As shown in the following table, node identification must observe the following
constraints: A white node must be identified with a black node; a red node cannot be
identified with any other node; and a black node may be identified with one or more
white nodes.20
?B ?R ?W ?
?B ? ? ?B ?
?R ? ? ? ?
?W ?B ? ?W ?
? ? ? ? ?
We now briefly describe how the constraint solver sketched in Section 5.3.1 was
extended to support colors. As mentioned previously, in valid models all white nodes
are identified with a black node (at most one black node per white node). Consequently,
there is a bijection from the red and black nodes of the tree description to the nodes of
the model. In order to take this bijection into account, we add a node variable RBn to
the five sets already associated with a node variable n from Section 5.1. RBn denotes
either n if n is a black or red node, or the black node identified with n if n is a white
node. Note that all the node variables must be colored: the set of node variables in a
tree description can then be partitioned into three sets: Red, Black, and White. Basically,
we know that, for all nodes n, RBn ? Eqn (this is what the bijection is about). Again
we translate color information into constraints on node sets (these constraints help the
generic tree solver by reducing the ambiguity for the Eqn sets):
n ? Red ? (n = RBn) ? (Eqn = {n}) (28)
n ? Black ? (n = RBn) ? (Eqn\{n} ? White) (29)
n ? White ? (RBn ? Black) ? (Eqn ? Black = {RBn}) (30)
19 In fact, rather than adding strict precedence constraints to the tree description, we directly add to the
solver their equivalent set constraints on Eq, Up, Left, Right, Down, introduced earlier.
20 In other words, node colors can be seen as information on node saturation.
611
Computational Linguistics Volume 39, Number 3
Node coloring offers an alternative to complex namespace management. The main
advantage of this particular identification mechanism is its economy: Not only is there
no longer any need to remember node identifiers, there is in fact no need to choose a
name for node variables.
It is worth stressing that the XMG node identification process is reduced to a
constraint-solving problem and so it is not a sequential process. Thus the criticisms
leveled by Cohen-Sygal and Wintner (2007, 2009) against non-associative constraints
on node unification do not apply.
Briefly, in their work, Cohen-Sygal and Wintner (2007, 2009) showed that any
polarity-based tree description formalism is not associative. In other words, when
describing trees in terms of combinations of polarized structures, the order in which
the structures are combined matters (i.e., the output structures depend on the combi-
nation order). This feature makes such formalisms not appropriate for a modular and
collaborative grammar engineering, such as that of Cohen-Sygal and Wintner (2011) for
Unification Grammar.
In the XMG case, when using node colors, the tree description solver does not
rely on any specific fragment combination order. It computes all possible combination
orders. In this context, the grammar designer cannot think in terms of sequences of node
identifications. This would lead to tree overgeneration.
Again, it is important to remember that tree solving computes any valid tree model,
independently of any specific sequence of node identifications (all valid node identifica-
tions are computed). In this context, non-associativity of color-based node identification
is not an issue, but rather a feature, as it allows for a compact description of a large
number of node identifications (and thus of tree structures).
6. Writing Grammars with XMG
In this section, we first provide a detailed example showing how XMG can be used to
specify the verbal trees of a large FB-LTAG for French extended with unification-based
semantics. We then give a brief description of several large- and middle-scale grammars
that were implemented using XMG.
6.1 SEMTAG: A large FB-LTAG for French Covering Syntax and Semantics
We now outline the XMG specification for the verbal trees of SEMTAG, a large FB-LTAG
for French. This specification further illustrates how the various features of XMG (e.g.,
combined use of disjunction and conjunction, node colors) permit us to specify compact
and declarative grammar descriptions. We first discuss the syntactic dimension (SYN).
We then go on to show how the semantic dimension (SEM) and the syntax/semantic
interface (DYN) are specified.
6.1.1 The Syntactic Dimension. The methodology used to implement the verbal fragment
of SEMTAG can be summarized as follows. First, tree fragments are defined that rep-
resent either a possible realization of a verb argument or a possible realization of the
verb. The verbal elementary TAG trees of SEMTAG are then defined by appropriately
combining these tree fragments.
To maximize structure sharing, we work with four levels of abstraction. First, basic
tree fragments describing verb or verb argument realizations are defined. Second, gram-
matical functions are defined as disjunctions of argument realizations. Third, verbal
diathesis alternatives are defined as conjunctions of verb realizations and grammatical
612
Crabbe? et al XMG: eXtensible MetaGrammar
CanonSubj ?
S?W
N??R V?W CanonObj ?
S?W
V?W N??R
CanonIndirObj ?
S?W
V?W PP?R
P?R
a`?R
N??R
CanonByObj ?
S?W
V?W PP?R
P?R
par?R
N??R
RelatSubj ?
N?R
N?R S?W
N??R V?W WhObj ?
S?R
N??R S?W
V?W
WhByObj ?
S?R
PP?R
P?R
par?R
N??R
S?W
WhIndirObj ?
S?R
PP?R
P?R
a`?R
N??R
S?W
ActiveVerbForm?
S?B
V?B PassiveVerbForm?
S?B
V?B
V??B V?B
Figure 8
Elementary tree fragments used as building blocks of the grammar (nodes are colored to control
their identification when blocks are combined).
functions. Fourth, diathesis alternatives are gathered into tree families. In the next
paragraphs, we explain each of these levels in more detail.
Tree fragments. Tree fragments are the basic building blocks used to define SEMTAG.
These are the units that are shared and reused in the definition of many elementary
trees. For instance, the fragment for a canonical subject will be used by all FB-LTAG
elementary trees involving a canonical subject.
As mentioned earlier, to specify the verbal elementary trees of SEMTAG, we begin
by defining tree fragments which describe the possible syntactic realizations of the verb
arguments and of the verb itself. Figure 8 provides some illustrative examples of these
fragments. Here and in the following, we omit the feature structures decorating the trees
to facilitate reading.21
To further factorize information and facilitate grammar maintenance, the basic tree
fragments are organized in an inheritance hierarchy.22 Figure 9 shows a partial view of
21 See Crabbe? (2005) for a complete description of SEMTAG tree fragments, including feature structures.
22 Recall from Section 4 that inheritance is used to share namespaces. Thus, (node or feature) variables
introduced in a given class C can be directly reused in the sub-classes of C.
613
Computational Linguistics Volume 39, Number 3
VerbalArgument
CanonSubj CanonCompl
CanonObj CanPP
CanonIndirObj CanonByObj
Wh
WhObj WhPP
WhIndirObj WhByObj
RelatSubj
Figure 9
Organization of elementary fragments in an inheritance hierarchy.
this hierarchy illustrating how the tree fragments for argument realization depicted in
Figure 8 are organized to maximize the sharing of common information. The hierarchy
classifies the verbal arguments depicted in Figure 8 into four categories:
1. The canonical subject is a noun realized in front of the verb.
2. Canonical complements occur after the verb. The canonical object is a
noun phrase whereas prepositional complements are introduced by
specific prepositions, namely, a` for the canonical indirect object and
par for the canonical by object.
3. Wh-arguments (or questioned arguments) occur in front of a sentence
headed by a verb. A Wh-object is an extracted noun whereas questioned
prepositional objects are extracted prepositional phrases that are
introduced by a specific preposition.
4. Finally, the relativized subject is a relative pronoun realized in front
of the sentence. Extracted subjects in French cannot be realized at an
unbounded distance from the predicate.
Syntactic functions. The second level of abstraction uses syntactic function names such
as Subject and Object to group together alternative ways in which a given syntactic
function can be realized. For instance, if we make the simplifying assumption that the
possible argument realizations are limited to those given in Figure 8, the Subject, Object,
ByObject, and IndirectObject classes would be defined as follows.23
Subject ? CanonSubj ? RelatSubj (31)
Object ? CanonObj ? WhObj (32)
ByObject ? CanonByObj ? WhByObj (33)
IndirectObject ? CanonIndirObj ? WhIndirObj (34)
That is, we define the Subject class as an abstraction for talking about the set of tree
fragments that represent the possible realizations of a subject argument?namely, in
23 Note that, when these abstractions will be combined to describe for instance transitive verbs, the
combination of WhObj with WhByObj will be ruled out by using a uniqueness principle such as
introduced in Section 5.
614
Crabbe? et al XMG: eXtensible MetaGrammar
our restricted example, canonical and relativized subject. Thus, the simplified Subject
class defined in Equation (31) characterizes contexts such as the following:
(35) a. Jean mange. (canonical subject)
?John eats.?
b. Le garc?on qui mange (relativized subject)
?The boy who eats?
Similarly, the IndirectObject class abstracts over the realization of an argument intro-
duced by the preposition a` to the right of the verb (CanonIndirObj) or realized in
extracted position (possibly realized at an unbounded distance from the predicate) as
illustrated by the following examples:
(36) a. Jean parle a` Marie. (canonical indirect object)
?John talks to Mary.?
b. A` qui Jean parle-t-il ? (wh indirect object)
?To whom is John talking ??
c. A` qui Pierre croit-il que Jean parle ? (wh indirect object)
?To whom Peter thinks that John talks ??
This way of grouping tree fragments is reminiscent of the informal classification of
French syntactic functions presented by Iordanskaja and Mel?c?uk (2009) whereby each
syntactic function is associated with a set of possible syntactic constructions.
Diathesis alternations. In this third level, we take advantage of the abstractions defined
in the previous level to represent diathesis alternations. Again, we are interested here
in describing alternatives. Diathesis alternations are those alternations of mapping
between arguments and syntactic functions such as for instance the active/passive
alternation. In a diathesis alternation, the actual form of the verb constrains the way
predicate arguments are realized in syntax. Thus, in the following example, it is con-
sidered that both Examples (37a) and (37b) are alternative realizations of a predicate
argument structure such as send(John, a letter).
(37) a. Jean envoie une lettre.
?John sends a letter.?
b. Une lettre est envoye?e par Jean.
?A letter is sent by John.?
The active/passive diathesis alternation captures the fact that if the verb is in the
active form, its two arguments are realized by a subject and an object whereas if the
verb is in the passive form, then the arguments consist of a subject and a by-object.
TransitiveDiathesis ? (Subject ? ActiveVerbForm ? Object)
? (Subject ? PassiveVerbForm ? ByObject)
(38)
Finally a traditional case of ?erasing,?24 such as the agentless passive (or passive
without agent) can be expressed in our language by adding an additional alternative
24 It is often argued that a language of grammatical representation must be equipped with an ?erasing
device? like lexical rules because of phenomena such as the passive without agent. In this framework it
turns out that this kind of device is not needed because we do not grant any special status to base trees.
615
Computational Linguistics Volume 39, Number 3
where the by-object or agentive complement is not expressed. Thus Equation (39) is an
augmentation of (38) where we have added the agentless passive alternative (indicated
in boldface).
TransitiveDiathesis ? (Subject ? ActiveVerbForm ? Object)
? (Subject ? PassiveVerbForm ? ByObject)
? (Subject ? PassiveVerbForm)
(39)
This methodology can be further augmented to implement an actual linking in the
manner of Bresnan and Zaenen (1990). For the so-called erasing cases, one can map the
?erased? predicative argument to an empty realization in syntax. We refer the reader to
Crabbe? (2005) for further details.
Tree families. Finally, tree families are defined?that is, sets of trees capturing alternative
realizations of a given verb type (i.e., sub-categorization frame). Continuing with the
simplified example presented so far, we can for instance define the tree family for
verbs taking a nominal subject, a nominal object, and an indirect nominal object (i.e.,
ditransitive verbs) as follows:
DitransitiveFamily ? TransitiveDiathesis ? IndirectObject (40)
The trees generated for such a family will, among others, handle the following
contexts:25
(41) a. Jean offre des fleurs a` Marie.
?John offers flowers to Mary.?
b. A` quelle fille Jean offre-t-il des fleurs ?
?To which girl does John offer flowers ??
c. Le garc?on qui offre des fleurs a` Marie.
?The boy who offers flowers to Mary.?
d. Quelles fleurs le garc?on offre-t-il a` Marie ?
?Which flowers does the boy offer to Mary ??
e. Les fleurs sont offertes par Jean a` Marie.
?The flowers are offered by John to Mary.?
f. Par quel garc?on les fleurs sont-elles offertes a` Marie ?
?By which boy are the flowers offered to Mary ??
It is straightforward to extend the grammar with new families. Thus, for instance,
Equation (42) shows how to define the transitive family (for verbs taking a nominal
subject and a nominal object) and Equation (43), the intransitive one (alternatives of a
verb sub-categorizing for a nominal subject).
TransitiveFamily ? TransitiveDiathesis (42)
IntransitiveFamily ? Subject ? ActiveVerbForm (43)
25 Note that number and gender agreements are dealt with using coreferences between features labeling
syntactic nodes, see Crabbe? (2005).
616
Crabbe? et al XMG: eXtensible MetaGrammar
Similarly, tree families for non-verbal predicates (adjectives, nouns) can be defined
using the abstraction over grammatical functions defined for verbs. For instance, the ex-
amples in (44a?44b) can be captured using the adjectival trees defined in Equations (46)
and (47), respectively, where Subject extends the definition of subject given above with a
Wh-subject, PredAdj combines a subject tree fragment with a tree fragment describing a
predicative adjective, and PredAdjAObj extends a PredAdj tree fragment with a canonical
a`-object.
(44) a. Jean est attentif. Qui est attentif ? L?homme qui est attentif
?John is mindful. Who is mindful ? The man who is mindful?
b. Jean est attentif a` Marie. Qui est attentif a` Marie ? L?homme qui est attentif a`
Marie
?John is mindful of Mary. Who is mindful of Mary ? The man who is mindful
of Mary?
Subject ? CanonSubj ? RelatSubj ? WhSubj (45)
PredAdj ? Subject ? AdjectivalForm (46)
PredAdjAObj ? PredAdj ? CanonAObj (47)
6.1.2 The Semantic Dimension and the Syntax/Semantic Interface. We now show how to
extend the XMG specification presented in the previous section to integrate a
unification-based compositional semantics. Three main changes need to be carried out:
1. Each elementary tree must be associated with a semantic formula. This is
done using the SEM dimension.
2. The nodes of elementary trees must be labeled with the appropriate
semantic indices. This involves introducing the correct attribute-value pair
in the correct feature structure (top or bottom) on the appropriate node.
3. Syntax and semantics need to be synchronized?that is, variable sharing
between semantic formulae and tree indices need to be enforced. To this
end we use the DYN dimension.
Informing the semantic dimension. To associate each elementary tree with a formula rep-
resenting the meaning of the words potentially anchoring that tree, we use the SEM
dimension to specify a semantic schema. For instance, the TransitiveFamily class defined
in Equation (42) for verbs taking two nominal arguments is extended as follows:
TransitiveFamily ? TransitiveDiathesis ? BinaryRel (48)
where TransitiveDiathesis is the XMG class defined in Equation (39) to describe the set of
trees associated with transitive verbs and BinaryRel the class describing the following
semantic schema:
L : P(E) ? L : Theta1(E, X) ? L : Theta2(E, Y) (49)
In this semantic schema, P, Theta1, and Theta2 are unification variables that become
ground when the tree is anchored with a specific word. For instance, P, Theta1, and
Theta2 are instantiated to eat, agent, and patient, respectively, when the anchor is ate (these
617
Computational Linguistics Volume 39, Number 3
pieces of information?predicate, thematic roles?are associated with lemmas, located
in the syntactic lexicon, and unified with adequate semantic variables via anchoring
equations). Further, X, Y, E, L are unification variables representing semantic arguments.
As illustrated in Figure 3, these become ground during (or after) derivation as a side
effect of the substitutions and adjunctions taking place when trees are combined. It
is worth noting that by combining semantic schemas with diathesis classes, one such
specification assigns the specified semantic schema to many trees, namely, all the trees
described by the corresponding diathesis class. In this way, the assignment of semantic
formulae to trees is relatively economical. Indeed in SEMTAG, roughly 6,000 trees are
assigned a semantic schema using a total of 75 schema calls.
Co-indexing trees and formulae indices. Assuming that tree nodes are appropriately deco-
rated with semantic indices by the specification scheme described in the next paragraph,
we now show how to enforce the correct mapping between syntactic and semantic
arguments. This is done in two steps.
First, we define a set of interface constraints of the form ?indexF : V, argi : V? which
are used to enforce the identification of the semantic index (indexF) labeling a given tree
node with grammatical function F (e.g., F := subject) with the index (argi) representing
the i-th argument in a semantic schema. For instance, the following constraints ensure
a subject/arg1 mapping, that is, a coreference between the index labeling a subject node
and the index representing the first argument of a semantic schema:
C1 ? Node [idx : I] ? ?indexsubject : I?
C2 ? L : P(E) ? L : Theta1(E, X) ? ?arg1 : X?
SubjectArg1 ? C1 ? C2 ? ?indexsubject : V, arg1 : V?
(50)
Given such interface constraints, we refine the diathesis definitions so as to ensure the
correct bindings. For instance, the specification in Equation (38) is modified to:
TransitiveDiathesis ? TransitiveActive ? TransitivePassive
TransitiveActive ? (SubjectArg1 ? ObjectArg2?
Subject ? ActiveVerbForm ? Object)
(51)
and the passive diathesis is specified as:
TransitivePassive ? (SubjectArg2 ? ByObjectArg1?
Subject ? PassiveVerbForm ? ByObject)
(52)
Labeling tree nodes with semantic indices. This scheme relies on the assumption that tree
nodes are appropriately labeled with semantic indices (e.g., the subject node must be
labeled with a semantic index) and that these indices are appropriately named (arg1
must denote the parameter representing the first argument of a binary relation and
indexsubject the value of the index feature on a subject node). As suggested by Gardent
(2007), a complete semantic labeling of a TAG with the semantic features necessary
618
Crabbe? et al XMG: eXtensible MetaGrammar
to enrich this TAG with the unification-based compositional semantics sketched in the
previous section can be obtained by applying the following labeling principles:26
Argument labeling: In trees associated with semantic functors, each argument node
is labeled with a semantic index27 named after the grammatical function of the
argument node (e.g., indexsubject for a subject node).
Controller/Controllee: In trees associated with control verbs, the semantic index of the
controller is identified with the value of the controlled index occurring on the
sentential argument node.
Anchor projection: The anchor node projects its index up to its maximal projection.
Foot projection: A foot node projects its index up to the root.28
As we shall now see, XMG permits a fairly direct encoding of these principles.
The Argument Labeling principle states that, in the tree associated with a syntactic
functor (e.g., a verb), each node representing a syntactic argument (e.g., the subject
node) should be labeled with a semantic index named after the grammatical function of
that node (e.g., indexsubject).29
To specify this labeling, we define for each grammatical function Function ?
{Subject, Object, ByObject, IndirectObject, . . . }, a semantic class FunctionSem which as-
sociates with an (exported) node variable called FunctionNode the feature value pair
[index : I] and a DYN constraint of the form ?indexFunction : I?. For instance, the class
SubjectSem associates the node SubjectNode with the feature value pair [index : I] and
the DYN constraint ?indexsubject : I?.
SubjectSem ? SubjectNode [index : I] ? ?indexsubject : I? (53)
Additionally, in the tree fragments describing the possible realizations of the grammat-
ical functions, the (exported) variable denoting the argument node is systematically
named ArgNode.
Finally, we modify the specification of the realizations of the grammatical functions
to import the appropriate semantic class and identify ArgNode and FunctionNode. For
instance, the Subject specification given above is changed to:
Subject ? SubjectSem ? ArgNode = SubjectNode ?
(CanonSubj ? RelatSubj ? WhSubj)
(54)
26 The principles required to handle quantification are omitted. We refer the reader to Gardent (2007) for a
more extensive presentation of how semantics is implemented using XMG.
27 For simplicity, we only mention indices. To be complete, however, labels should also be used.
28 The foot projection principle only applies to foot nodes that are not argument nodes (i.e., to modifiee
nodes).
29 In other words, this argument labeling principle defines an explicit and normalized reference to any
realization of a semantic argument. Following FB-LTAG predicate?argument co-occurrence principle
(Abeille?, Candito, and Kinyon 1999), we know that any elementary tree includes a leaf node for each
realized semantic argument of its anchor. This principle thus holds in any FB-LTAG. Its implementation,
however, is closely related to the architecture of the metagrammar; here we benefit from the fact that
verbal arguments are described in dedicated classes to reach a high degree of factorization.
619
Computational Linguistics Volume 39, Number 3
E3
E2
E2
E1
E2
E1
E1
E
E1
E
E1
E
? E? ? E? ? E?
Depth 3 Depth 2 Depth 1
SE2E1
VPE1E
?VE?
ActiveVerbForm
Figure 10
Anchor/Foot projection.
As a result, all ArgNode nodes in the tree descriptions associated with a subject realiza-
tion are labeled with an index feature I whose global name is indexsubject.
Value sharing between the semantic index of the controller (e.g., the subject of
the control verb) and that of the controllee (e.g., the empty subject of the infinitival
complement) is enforced using linking constraints between the semantic index labeling
the controller node and that labeling the sentential argument node of the control verb.
Control verb definitions then import the appropriate (object or subject control) linking
constraint.
The anchor (respectively, foot) projection principle stipulates the projection of
semantic indices from the anchor (respectively, foot) node up to the maximal projection
(respectively, root). Concretely, this means that the top and bottom features of the nodes
located on this path between the anchor (respectively, foot) and the maximal projection
(respectively, root) all include an index feature whose value is shared between adjacent
nodes (see variables Ei in Figure 10).30 Once the top and bottom structures are unified,
so are the semantic indices along this path (modulo expected adjunctions realized on
the projection).
To implement these principles, we define a set of anchor projection classes
{Depth1, Depth2, Depth3} as illustrated in Figure 10. We then ?glue? these projection
skeletons onto the relevant syntactic trees by importing the skeletons in the syntactic
tree description and explicitly identifying the anchor node of the semantic projection
classes with the anchor or foot node of these syntactic tree descriptions. Because the
models must be trees, the nodes dominating the anchor node of the projection class
will deterministically be identified with those dominating the anchor or foot node of
the trees being combined with. For instance, for verbs, the class specifying the verbal
spine (e.g., ActiveVerbForm, see Figure 10) equates the anchor node of the verbal spine
with that of the projection skeleton. As a result, the verb projects its index up to
the root.
6.1.3 Some Figures About SEMTAG. As mentioned previously, SEMTAG is a large FB-LTAG
for French equipped with semantics (Gardent 2008); it extends the purely syntactic
FTAG of Crabbe? (2005) with a unification based compositional semantics as described
by Gardent and Kallmeyer (2003).31 The syntactic FTAG in essence implements Abeille??s
(2002) proposal for an FB-LTAG-based modeling of French syntax. FTAG contains
around 6,000 elementary trees built from 293 XMG classes and covers some 40 basic
30 For sake of brevity, we write E2E1 for [bot : [index : E1] top : [index : E2]]. ? ? refers to the anchor / foot.31 FTAG and SEMTAG are freely available under the terms of the GPL-compliant CeCILL license, the former
at https://sourcesup.renater.fr/scm/viewvc.php/trunk/METAGRAMMARS/FrenchTAG/?root=xmg, and
the latter on request.
620
Crabbe? et al XMG: eXtensible MetaGrammar
verbal sub-categorization frames. For each of these frames, FTAG defines a set of
argument alternations (active, passive, middle, neuter, reflexivization, impersonal,
passive impersonal) and of argument realizations (cliticization, extraction, omission,
permutations, etc.) possible for this frame. Predicative (adjectival, nominal, and
prepositional) and light verb constructions are also covered as well as some common
sub-categorizing noun and adjective constructions. Basic descriptions are provided for
the remaining constructions namely, adverbs, determiners, and prepositions.
FTAG and SEMTAG were both evaluated on the Test Suite for Natural Language Pro-
cessing (TSNLP) (Lehmann et al 1996), using a lexicon designed specifically on the test
suite, hence reducing lexical ambiguity (Crabbe? 2005; Parmentier 2007). This test suite
focuses on difficult syntactical phenomena, providing grammatical and ungrammatical
sentences. These competence grammars accept 76% of the grammatical items, reject 83%
of the ungrammatical items, and have an average ambiguity of 1.64 parses per sentence.
To give an idea of the compilation time, under architectures made of a 2-Ghz processor
with 1 Gb of RAM, it takes XMG 10 minutes to compile the whole SEMTAG (recall that
there is no semantic description solving, hence the compilation times between FTAG
and SEMTAG do not differ).32
Note that SEMTAG can be used for assigning semantic representations to sentences
when combined with an FB-LTAG parser and a semantic construction module as de-
scribed by Gardent and Parmentier (2005, 2007).33 Conversely, it can be used to verbalize
the meaning denoted by a given semantic representation when coupled with the GenI
surface realizer described by Gardent and Kow (2007).
6.2 Other Grammars Designed with XMG
XMG has been used mainly to design FB-LTAG and IG for French or English. More
recently, it has also been used to design a FB-LTAG for Vietnamese and a TreeTuple
MC-TAG for German. We now briefly describe each of these resources.
SemXTAG. The English grammar, SEMXTAG (Alahverdzhieva 2008), reimplements the
FB-LTAG developed for English at the University of Pennsylvania (XTAG Research
Group 2001) and extends it with a unification-based semantics. It contains 1,017 trees
and covers the syntactic fragment of XTAG, namely, auxiliaries, copula, raising and
small clause constructions, topicalization, relative clauses, infinitives, gerunds, pas-
sives, adjuncts, ditransitives (and datives), ergatives, it-clefts, wh-clefts, PRO con-
structions, noun?noun modification, extraposition, determiner sequences, genitives,
negation, noun?verb contractions, sentential adjuncts, imperatives, and resultatives.
The grammar was tested on a handbuilt test-suite of 998 sentences illustrating the
various syntactic constructions meant to be covered by the grammar. All sentences in
the test suite can be parsed using the grammar.
FrenchIG. The extended XMG framework was used to design a core IG for French
consisting of 2,059 tree descriptions compiled out of 448 classes (Perrier 2007). The
resulting grammar is lexicalized, and its coverage was evaluated using the previously
mentioned TSNLP. The French IG accepts 88% of the grammatical sentences and rejects
32 As a comparison, about one hour was needed by Candito?s (1999) compiler to produce a French FB-LTAG
containing about 1,000 tree schemas.
33 As an alternative way to parse FB-LTAG grammars equipped with flat semantics such as those produced
by XMG, one can use the Tu?bingen Linguistic Parsing Architecture (TuLiPA) (Kallmeyer et al 2010).
621
Computational Linguistics Volume 39, Number 3
85% of the ungrammatical sentences, although the current version of the French IG
does not yet cover all the syntactic phenomena presented in the test suite (for example,
causative and superlative constructions).
Vietnamese TAG. The XMG language was used by Le Hong, N?Guyen, and Roussanaly
(2008) to produce a core FB-LTAG for Vietnamese. Their work is rather a proof of con-
cept than a large-scale implementation. They focused on Vietnamese?s categorization
frames, and were able to produce a TAG covering the following frames: intransitive
(tree family N0V), transitive with a nominal complement (N0VN1), transitive with a
clausal complement (N0VS1), transitive with modal complement (N0V0V1), ditransi-
tive (N0VN1N2), ditransitive with a preposition (N0VN1ON2), ditransitive with a ver-
bal complement (N0V0N1V1), ditransitive with an adjectival complement (N0VN1A),
movement verbs with a nominal complement (N0V0V1N1), movement verbs with an
adjectival complement (N0V0AV1), and movement ditransitive (N0V0N1V1N2).
GerTT. Another XMG-based grammar corresponds to the German MC-TAG of
Kallmeyer et al (2008). This grammar, called GerTT, is in fact an MC-TAG with
Tree Tuples (Lichte 2007). This variant of MCTAG has been designed to model free
word order phenomena. This is done by imposing node sharing constraints on MCTAG
derivations (Kallmeyer 2005). GerTT covers phenomena such as scrambling, coherent
constructions, relative clauses, embedded questions, copula verbs, complementized
sentences, verbs with various sub-categorization frames, nouns, prepositions, determin-
ers, adjectives, and partly includes semantics. It is made of 103 tree tuples, compiled
from 109 classes.
7. Related Work
We now compare XMG with existing environments for designing tree-based grammars
and briefly report on the grammars designed with these systems.
7.1 Environments for Designing Tree-Based Grammars
Candito?s Metagrammar Compiler. The concept of metagrammar was introduced by
Candito (1996). In her paper, Candito presented a compiler for abstract specifications
of FB-LTAG trees (the so-called metagrammars). Such specifications are based on three
dimensions, each of them being encoded in a separate inheritance hierarchy of linguistic
descriptions. Dimension 1 describes canonical sub-categorization frames (e.g., transitive),
the Dimension 2 describes redistributions of syntactic functions (e.g., active to passive),
and Dimension 3 the tree descriptions corresponding to the realizations of the syntactic
functions defined in Dimension 2. This three-dimensional metagrammatical description
is then processed by a compiler to compute FB-LTAG tree schemas. In essence, these
tree schemas are produced by associating a canonical sub-categorization frame (Dimen-
sion 1) with a compatible redistribution schema (Dimension 2), and with exactly one
function realization (Dimension 3) for each function required by the sub-categorization
frame.
Candito?s (1996, 1999) approach improves on previous proposals by Vijay-Shanker
and Schabes (1992) and Evans, Gazdar, and Weir (1995) in that it provides a linguistically
principled basis for structuring the inheritance hierarchy. As shown in Section 6.1,
622
Crabbe? et al XMG: eXtensible MetaGrammar
the XMG definition of SEMTAG uses similar principles. Candito?s approach differs,
however, from the XMG account in several important ways:
 Much of the linguistic knowledge used to determine which classes to
combine is hard-coded in the compiler (unlike in XMG, there is no explicit
control on class combinations). In other words, there is no clear separation
between the linguistic knowledge needed to specify a high-level FB-LTAG
description and the algorithm used to compile an actual FB-LTAG from
this description. This makes grammar extension and maintenance by
linguists extremely difficult.
 As in Vijay-Shanker and Schabes (1992) Evans, Gazdar, and Weir (1995),
the linguistic description is non-monotonic in that some erasing classes
are used to remove information introduced by other dimensions
(e.g., agentless passive).
 The approach fails to provide an easy means to state exceptions. These
are usually encoded in the compiling algorithm.
 The tree description language used to specify classes in Dimension 3
relies on global node variables. Thus, two variables with identical names
introduced in different classes are expected to refer to the same tree node.
As argued in Section 4, this makes it hard to design large-scale
metagrammars.
The LexOrg system. An approach similar to Candito?s was presented by Xia et al
(1998), Xia (2001), and Xia, Palmer, and Vijay-Shanker (2005, 2010). As in Candito?s
approach, a TAG abstract specification relies on a three-dimensional description made
of, namely, sub-categorization frames, blocks, and lexical redistribution rules. To com-
pile this specification into a TAG, the system selects a canonical sub-categorization
frame, and applies some lexical redistribution rules to derive new frames and finally
select blocks corresponding to the resulting frames. These blocks contain tree descrip-
tions using the logic of Rogers and Vijay-Shanker (1994).
LexOrg suffers from similar limitations as Candito?s compiler. Much of the lin-
guistic knowledge is embedded in the compiling algorithm, making it difficult for
linguists to extend the grammar description and to handle exceptions. Unlike in Can-
dito?s framework, the tree description language uses local node variables and lets the
tree description solver determine node identifications. Although this avoids having to
memorize node names, this requires that the descriptions be constrained enough to
impose the required node identifications and prevent the unwanted ones. In practice,
this again complicates grammar writing. In contrast, XMG provides an intermediate
solution which, by combining local variables with export declarations, avoids having to
memorize too many node variable names (only those local to the relevant sub-hierarchy
need memorizing) while allowing for explicit node identification.
The Metagrammar Compiler of Gaiffe, Crabbe?, and Roussanaly. Gaiffe, Crabbe?, and
Roussanaly (2002) proposed a compiler for FB-LTAG that aims to remedy both the lack
of a clear separation between linguistic information and compilation algorithm, and
the lack of explicit control on the class combinations prevalent in Candito (1996), Xia
et al (1998), and Xia (2001). In their approach, the linguistic specification consists of
a single inheritance hierarchy of classes, each class containing a tree description. The
623
Computational Linguistics Volume 39, Number 3
description logic used is similar to Candito?s. That is, global node names are used. To
trigger class combinations, classes are labeled with two types of information: needs and
resources. The compiler selects all final classes of the hierarchy, performs all possible
combinations, and only keeps those combinations that neutralize the stated needs
and resources. The tree descriptions contained in these neutral combinations are then
solved to produce the expected trees.
Although this approach implements a clear separation between linguistic informa-
tion and compilation algorithm, the fully automatic derivation of FB-LTAG trees from
the inheritance hierarchy makes it difficult in practice to control overgeneration. In
contrast, XMG?s explicit definitions of class combinations by conjunction, disjunction,
and inheritance makes it easier to control the tree set that will be generated by the
compiler from the grammar specification. Additionally, the issues raised by global
variables remain (no way to instantiate twice a given class, and cumbersome definition
of variables in large metagrammars).
The MGCOMP System. More recently, Villemonte de la Clergerie (2005, 2010) proposed a
compiler for FB-LTAG that aims at preserving a high degree of factorization in both the
abstract grammar specification and the grammar which is compiled from it. Thus, the
MGCOMP system does not compute FB-LTAG elementary trees, but factorized trees.
In MGCOMP, like in Gaiffe, Crabbe?, and Roussanaly?s (2002) approach, a meta-
grammar consists of a single hierarchy of classes. The classes are labeled with needs and
resources, and final classes of the hierarchy are combined to compute tree descriptions.
The main differences with Gaiffe, Crabbe?, and Roussanaly (2002), lies in the fact that
(i) a description can include new factorizing operators, such as repetition (Kleene-star
operator), shuffling (interleaving of nodes), optionality, and disjunctions; and (ii) it offers
namespaces to specify the scope of variables. MGCOMP?s extended tree descriptions
are not completely solved by the compiler. Rather, it compiles underspecified trees (also
called factorized trees). With this approach, a large grammar is much smaller in terms of
number of grammatical structures than a classical FB-LTAG. As a result, the grammars it
compiles are only compatible with the DyALog parsing environment (Villemonte de La
Clergerie 2005). And, because the linguist designs factorized trees and not actual TAG
trees, debugging the metagrammar becomes harder.
7.2 Resources Built Using Candito, Xia, and De La Clergerie?s Systems
Candito?s system has been used by Candito (1999) herself to design a core FB-LTAG
for French and Italian, and later by Barrier (2006) to design a FB-LTAG for adjectives
in French. Xia?s system (LexOrg) has been used to semi-automatically generate XTAG
(Xia 2001). De La Clergerie?s system (MGCOMP) has been used to design a grammar
for French named FRMG (FRench MetaGrammar) (Villemonte de la Clergerie 2010).
FRMG makes use of MGCOMP?s factorizing operators (e.g., shuffling operator), thus
producing not sensu stricto a FB-LTAG, but a factorized FB-LTAG. FRMG is freely
available, contains 207 factorized trees (having optional branches, etc.) built from 279
metagrammatical classes, and covers 95% of the TSNLP.
8. Conclusion
In this article, we presented the eXtensible MetaGrammar framework and argued that,
contrary to other existing grammar writing environments for tree-based grammar,
624
Crabbe? et al XMG: eXtensible MetaGrammar
XMG is declarative, extensible, and notationally expressive. We believe that these fea-
tures make XMG particularly appropriate for a fast prototyping of the kind of deep
tree-based grammars that are used in applications requiring high precision in gram-
mar modeling (e.g., language teaching, man/machine dialogue systems, data-to-text
generation).
The XMG language is documented on-line, and its compiler is open source soft-
ware, freely available under the terms of the GPL-compliant CeCILL license.34 Many
grammars designed with XMG (FB-LTAG and IG for French and English, TT-MCTAG
for German) are also open-source and available on-line.35
Future research will focus on extensibility. So far, XMG has been used to design tree-
based grammars for different languages. We plan to extend XMG to handle other types
of formalisms36 such as dependency grammars, and to support dimensions other than
syntax and semantics such as for instance, phonology or morphology. As mentioned
here, XMG offers a modular architecture, making it possible to extend it relatively easily.
Nonetheless, in its current state, such extensions imply modifying XMG?s code. We are
exploring new extensions of the formalism, which would allow the linguist to dynam-
ically define her/his metagrammar formalism (e.g., which principles or descriptions to
use) depending on the target formalism.
Another interesting question concerns cross-language grammar engineering. So far,
the metagrammar allows for dealing with structural redundancy. As pointed out by
Kinyon et al (2006), a metagrammar can be used to capture generalizations across
languages and is surely worth further investigating.
Finally, we plan to extend XMG with features borrowed from Integrated De-
velopment Environments (IDE) for programming languages. Designing a grammar
is, in some respect, similar to programming an application. Grammar environments
should benefit from the same tools as those used for the development of applications
(incremental compilation, debugger, etc.).
Acknowledgments
We are grateful to the three anonymous
reviewers for their valuable comments.
Any remaining errors are ours.
References
Abeille?, A. 2002. Une grammaire e?lectronique
du franc?ais. CNRS Editions.
Abeille?, A., M. Candito, and A. Kinyon. 1999.
Ftag: current status and parsing scheme.
In Proceedings of Vextal ?99, pages 283?292,
Venice.
A??t-Kaci, Hassan. 1991. Warren?s Abstract
Machine: A Tutorial Reconstruction. MIT
Press, Cambridge, MA.
Alahverdzhieva, Katya. 2008. XTAG using
XMG. Masters thesis, Nancy Universite?.
Baldridge, Jason, Sudipta Chatterjee,
Alexis Palmer, and Ben Wing. 2007.
DotCCG and VisCCG: Wiki and
programming paradigms for improved
grammar engineering with OpenCCG.
In Tracy Holloway King and Emily M.
Bender, editors, Proceedings of the Grammar
Engineering Across Framework Workshop
(GEAF 07). CSLI, Stanford, CA, pages 5?25.
Barrier, Se?bastien. 2006. Une me?tagrammaire
pour les noms pre?dicatifs du franc?ais :
de?veloppement et expe?rimentations pour les
grammaires TAG. Ph.D. thesis, Universite?
Paris 7.
Becker, Tilman. 1993. HyTAG: A New Type
of Tree Adjoining Grammars for Hybrid
Syntactic Representation of Free Word Order
Language. Ph.D. thesis, Universita?t des
Saarlandes.
34 See https://sourcesup.renater.fr/xmg.
35 The French TAG and French and English IG are available on XMG?s website, and the German TreeTuple
MC-TAG is available at http://www.sfs.uni-tuebingen.de/emmy/res.html.
36 Preliminary work on cross-framework grammar engineering has been realized by Cle?ment and Kinyon
(2003), who used Gaiffe et al?s compiler to produce both a TAG and a LFG from a given metagrammar.
625
Computational Linguistics Volume 39, Number 3
Blackburn, Patrick, Johan Bos, and Kristina
Striegnitz. 2006. Learn Prolog Now!,
volume 7 of Texts in Computing. College
Publications, London.
Bresnan, Joan and Annie Zaenen. 1990. Deep
unaccusitivity in LFG. In K. Dziwirek,
P. Farell, and E. Mejias-Bikandi, editors,
Grammatical Relations: A Cross-Theoretical
Perspective. CSLI publications, Stanford,
CA, pages 45?57.
Candito, Marie. 1996. A principle-based
hierarchical representation of LTAGs.
In Proceedings of the 16th International
Conference on Computational Linguistics
(COLING?96), pages 194?199, Copenhagen.
Candito, Marie. 1999. Repre?sentation modulaire
et parame?trable de grammaires e?lectroniques
lexicalise?es : application au franc?ais et a`
l?italien. Ph.D. thesis, Universite? Paris 7.
Cle?ment, Lionel and Alexandra Kinyon.
2003. Generating parallel multilingual
lfg-tag grammars from a metagrammar.
In Proceedings of the 41st Annual Meeting of
the Association for Computational Linguistics,
pages 184?191, Sapporo.
Cohen-Sygal, Yael and Shuly Wintner. 2007.
The Non-Associativity of Polarized
Tree-Based Grammars. In Proceedings of the
Eighth International Conference on Intelligent
Text Processing and Computational Linguistics
(CICLing-2007), pages 208?217, Mexico City.
Cohen-Sygal, Yael and Shuly Wintner. 2009.
Associative grammar combination operators
for tree-based grammars. Journal of Logic,
Language and Information, 18(3):293?316.
Cohen-Sygal, Yael and Shuly Wintner. 2011.
Towards modular development of typed
unification grammars. Computational
Linguistics, 37(1):29?74.
Copestake, Ann and Dan Flickinger. 2000.
An open-source grammar development
environment and broad-coverage English
grammar using HPSG. In Proceedings of the
Second Conference on Language Resources and
Evaluation (LREC-2000), Athens.
Copestake, Ann, Alex Lascarides, and Dan
Flickinger. 2001. An algebra for semantic
construction in constraint-based
grammars. In Proceedings of 39th Annual
Meeting of the Association for Computational
Linguistics, pages 140?147, Toulouse.
Crabbe?, Benoit. 2005. Repre?sentation
informatique de grammaires fortement
lexicalise?es : Application a` la grammaire
d?arbres adjoints. Ph.D. thesis, Universite?
Nancy 2.
Crabbe?, Beno??t and Denys Duchier. 2004.
Metagrammar redux. In Proceedings of the
Workshop on Constraint Solving for Language
Processing (CSLP 2004), pages 32?47,
Copenhagen.
Duchier, Denys, Brunelle Magnana Ekoukou,
Yannick Parmentier, Simon Petitjean, and
Emmanuel Schang. 2012. Describing
morphologically-rich languages using
metagrammars: A look at verbs in Ikota.
In Workshop on ?Language Technology for
Normalisation of Less-resourced Languages,?
8th SALTMIL Workshop on Minority
Languages and 4th Workshop on African
Language Technology, International
Conference on Language Resources and
Evaluation, LREC 2012, pages 55?60,
Istanbul.
Duchier, Denys and Joachim Niehren. 2000.
Dominance constraints with set operators.
In John W. Lloyd, Vero?nica Dahl, Ulrich
Furbach, Manfred Kerber, Kung-Kiu Lau,
Catuscia Palamidessi, Lu??s Moniz Pereira,
Yehoshua Sagiv, and Peter J. Stuckey,
editors, Proceedings of the First International
Conference on Computational Logic,
volume 1861 of Lecture Notes in Computer
Science. Springer, Berlin, pages 326?341.
Duchier, Denys, Yannick Parmentier, and
Simon Petitjean. 2012. Metagrammars as
logic programs. In International Conference
on Logical Aspects of Computational
Linguistics (LACL 2012). Proceedings of
the Demo Session, pages 1?4, Nantes.
Duchier, Denys and Stefan Thater. 1999.
Parsing with tree descriptions: A
constraint-based approach. In Proceedings
of the Sixth International Workshop on
Natural Language Understanding and Logic
Programming (NLULP?99), pages 17?32,
Las Cruces, NM.
Evans, Roger, Gerald Gazdar, and David
Weir. 1995. Encoding lexicalized tree
adjoining grammars with a nonmonotonic
inheritance hierarchy. In Proceedings of the
33rd Annual Meeting of the Association for
Computational Linguistics, pages 77?84,
Cambridge, MA.
Flickinger, Daniel. 1987. Lexical Rules in the
Hierarchical Lexicon. Ph.D. thesis, Stanford
University.
Gaiffe, Bertrand, Beno??t Crabbe?, and Azim
Roussanaly. 2002. A new metagrammar
compiler. In Proceedings of the Sixth
International Workshop on Tree Adjoining
Grammars and Related Frameworks (TAG+6),
pages 101?108, Venice.
Gardent, Claire. 2007. Tree adjoining
grammar, semantic calculi and labelling
invariants. In Proceedings of the International
Workshop on Computational Semantics
(IWCS), Tilburg.
626
Crabbe? et al XMG: eXtensible MetaGrammar
Gardent, Claire. 2008. Integrating a
unification-based semantics in a large
scale lexicalised tree adjoininig grammar
for French. In Proceedings of the 22nd
International Conference on Computational
Linguistics (COLING?08), pages 249?256,
Manchester.
Gardent, Claire and Laura Kallmeyer. 2003.
Semantic construction in feature-based
tree adjoining grammar. In Proceedings of
the 10th Conference of the European Chapter of
the Association for Computational Linguistics,
pages 123?130, Budapest.
Gardent, Claire and Eric Kow. 2007. A
symbolic approach to near-deterministic
surface realisation using tree adjoining
grammar. In 45th Annual Meeting of the
Association for Computational Linguistics,
pages 328?335, Prague.
Gardent, Claire and Yannick Parmentier.
2005. Large scale semantic construction for
tree adjoining grammars. In Proceedings
of the Fifth International Conference
on Logical Aspects of Computational
Linguistics (LACL?05), pages 131?146,
Bordeaux.
Gardent, Claire and Yannick Parmentier.
2006. Coreference Handling in XMG.
In Proceedings of the 21st International
Conference on Computational Linguistics and
44th Annual Meeting of the Association for
Computational Linguistics (COLING/ACL
2006) Main Conference Poster Sessions,
pages 247?254, Sydney.
Gardent, Claire and Yannick Parmentier.
2007. SemTAG: A platform for specifying
tree adjoining grammars and performing
TAG-based semantic construction. In
Proceedings of the 45th Annual Meeting
of the Association for Computational
Linguistics Companion Volume Proceedings
of the Demo and Poster Sessions,
pages 13?16, Prague.
Iordanskaja, Lidija and Igor Mel?c?uk, 2009.
Establishing an inventory of surface?
syntactic relations: valence-controlled
surface-dependents of the verb in French.
In A. Polgue`re and I. A. Mel?duk, editors,
Dependency in Linguistic Description.
John Benjamins, Amsterdam,
pages 151?234.
Joshi, Aravind K., Leon S. Levy, and Masako
Takahashi. 1975. Tree adjunct grammars.
Journal of Computer and System Sciences,
10(1):136?163.
Kallmeyer, Laura. 1999. Tree Description
Grammars and Underspecified
Representations. Ph.D. thesis,
Universita?t Tu?bingen.
Kallmeyer, Laura. 2005. Tree-local
multicomponent tree-adjoining grammars
with shared nodes. Computational
Linguistics, 31(2):187?226.
Kallmeyer, Laura, Timm Lichte, Wolfgang
Maier, Yannick Parmentier, and Johannes
Dellert. 2008. Developing a TT-MCTAG for
German with an RCG-based parser. In
Proceedings of the Sixth Language Resources
and Evaluation Conference (LREC),
pages 782?789, Marrakech.
Kallmeyer, Laura, Wolfgang Maier, Yannick
Parmentier, and Johannes Dellert. 2010.
TuLiPA?Parsing extensions of TAG with
range concatenation grammars. Bulletin of
the Polish Academy of Sciences: Technical
Sciences, 58(3):377?392.
Kallmeyer, Laura and Maribel Romero.
2004a. LTAG semantics for questions.
In Proceedings of 7th International Workshop
on Tree-Adjoining Grammar and Related
Formalisms (TAG+7), pages 186?193,
Vancouver.
Kallmeyer, Laura and Maribel Romero.
2004b. LTAG semantics with semantic
unification. In Proceedings of 7th
International Workshop on Tree-Adjoining
Grammar and Related Formalisms (TAG+7),
page 155?162, Vancouver.
Kallmeyer, Laura and Maribel Romero.
2008. Scope and situation binding in
LTAG using semantic unification.
Research on Language and Computation,
6(1):3?52.
Kaplan, Ronald and Paula Newman. 1997.
Lexical resource reconciliation in the Xerox
linguistic environment. In Proceedings
of the ACL Workshop on Computational
Environments for Grammar Development
and Linguistic Engineering, pages 54?61,
Madrid.
Kinyon, Alexandra. 2000. Hypertags.
In Proceedings of the 18th International
Conference on Computational Linguistics
(COLING?00), pages 446?452, Saarbru?cken.
Kinyon, Alexandra, Owen Rambow, Tatjana
Scheffler, SinWon Yoon, and Aravind K.
Joshi. 2006. The metagrammar goes
multilingual: A cross-linguistic look at
the v2-phenomenon. In Proceedings of
the Eighth International Workshop on Tree
Adjoining Grammar and Related Formalisms,
pages 17?24, Sydney.
Le Hong, Phuong, Thi-Min-Huyen
N?Guyen, and Azim Roussanaly. 2008.
A metagrammar for Vietnamese. In
Proceedings of the 9th International Workshop
on Tree-Adjoining Grammar and Related
Formalisms (TAG+9), Tu?bingen.
627
Computational Linguistics Volume 39, Number 3
Lehmann, Sabine, Stephan Oepen, Sylvie
Regnier-Prost, Klaus Netter, Veronika Lux,
Judith Klein, Kirsten Falkedal, Frederik
Fouvry, Dominique Estival, Eva Dauphin,
Herve? Compagnion, Judith Baur, Lorna
Balkan, and Doug Arnold. 1996. TSNLP?
Test suites for natural language processing.
In Proceedings of the 16th International
Conference on Computational Linguistics
(COLING?96), pages 711?716, Copenhagen.
Lichte, Timm. 2007. An MCTAG with tuples
for coherent constructions in German.
In Proceedings of the 12th Conference on
Formal Grammar (FG 2007), 12 pages,
Dublin.
Muskens, Reinhard and Emiel Krahmer.
1998. Description theory, LTAGs and
Underspecified Semantics. In Fourth
International Workshop on Tree Adjoining
Grammars and Related Frameworks,
pages 112?115, Philadelphia, PA.
Parmentier, Yannick. 2007. SemTAG: une
plate-forme pour le calcul se?mantique a` partir
de Grammaires d?Arbres Adjoints. Ph.D.
thesis, Universite? Henri Poincare? - Nancy.
Parmentier, Yannick, Laura Kallmeyer, Timm
Lichte, and Wolfgang Maier. 2007. XMG:
eXtending MetaGrammars to MCTAG. In
Proceedings of the Workshop on High-Level
Syntactic Formalisms, 14th Conference on
Natural Language Processing (TALN?2007),
pages 473?482, Toulouse.
Pereira, Fernando and David Warren. 1980.
Definite clause grammars for language
analysis?A survey of the formalism
and a comparison to augmented
transition networks. Artificial
Intelligence, 13:231?278.
Perlmutter, David. 1970. Surface structure
constraints in syntax. Linguistic Inquiry,
1:187?255.
Perrier, Guy. 2000. Interaction grammars.
In Proceedings of the 18th International
Conference on Computational Linguistics
(COLING 2000), pages 600?606,
Saarbru?cken.
Perrier, Guy. 2007. A French interaction
grammar. In Proceedings of the 6th
Conference on Recent Advances in Natural
Language Processing (RANLP 2007),
pages 463?467, Borovets.
Prolo, Carlos A. 2002. Generating the
XTAG English grammar using metarules.
In Proceedings of the 19th International
Conference on Computational Linguistics
(COLING?2002), pages 814?820, Taipei.
Rambow, Owen, K. Vijay-Shanker, and
David Weir. 1995. D-tree grammars.
In Proceedings of the 33th Meeting of the
Association for Computational Linguistics,
pages 151?158, Cambridge, MA.
Rogers, James and K. Vijay-Shanker. 1994.
Obtaining trees from their descriptions:
An application to tree-adjoining
grammars. Computational Intelligence,
10:401?421.
Shieber, Stuart M. 1984. The design of a
computer language for linguistic
information. In Proceedings of the Tenth
International Conference on Computational
Linguistics, pages 362?366, Stanford, CA.
Van Roy, Peter. 1990. Extended DCG
notation: A tool for applicative
programming in prolog. Technical
Report UCB/CSD 90/583, University
of California, Berkeley.
Vijay-Shanker, K. and Aravind K. Joshi.
1988. Feature structures based tree
adjoining grammars. In Proceedings
of the 12th Conference on Computational
Linguistics (COLING?88), pages 714?719,
Budapest.
Vijay-Shanker, K. and Yves Schabes. 1992.
Structure sharing in lexicalized tree
adjoining grammars. In Proceedings
of the 14th International Conference on
Computational Linguistics (COLING?92),
pages 205?212, Nantes.
Villemonte de La Clergerie, E?ric. 2005.
DyALog: a tabular logic programming
based environment for NLP. In Proceedings
of 2nd International Workshop on Constraint
Solving and Language Processing (CSLP?05),
pages 18?33, Barcelona.
Villemonte de la Clergerie, E?ric. 2010.
Building factorized TAGs with
meta-grammars. In Proceedings of
the 10th International Workshop on
Tree-Adjoining Grammar and Related
Formalisms (TAG+10), pages 111?118,
New Haven, CT.
Weir, David J. 1988. Characterizing Mildly
Context-Sensitive Grammar Formalisms.
Ph.D. thesis, University of Pennsylvania.
Xia, Fei. 2001. Automatic Grammar Generation
from Two Different Perspectives. Ph.D. thesis,
University of Pennsylvania.
Xia, Fei, Martha Palmer, and K. Vijay-
Shanker. 1999. Toward semi-automating
grammar development. In Proceedings of
the 5th Natural Language Processing Pacific
Rim Symposium (NLPRS-99), pages 96?101,
Beijing.
Xia, Fei, Martha Palmer, and K. Vijay-
Shanker. 2005. Automatically generating
tree adjoining grammars from abstract
specifications. Journal of Computational
Intelligence, 21(3):246?287.
628
Crabbe? et al XMG: eXtensible MetaGrammar
Xia, Fei, Martha Palmer, and
K. Vijay-Shanker. 2010. Developing
tree-adjoining grammars with lexical
descriptions. In Srinivas Bangalore and
Aravind Joshi, editors, Supertagging:
Using Complex Lexical Descriptions in
Natural Language Processing. MIT Press,
Cambridge, MA, pages 73?110.
Xia, Fei, Martha Palmer, K. Vijay-Shanker,
and Joseph Rosenzweig. 1998. Consistent
grammar development using partial-tree
descriptions for LTAGs. In Proceedings
of the 4th International Workshop on
Tree Adjoining Grammar and Related
Formalisms (TAG+ 1998), pages 180?183,
Philadelphia, PA.
XTAG Research Group. 2001. A lexicalized
tree adjoining grammar for English.
Technical Report IRCS-01-03, IRCS,
University of Pennsylvania.
629

Coling 2008: Proceedings of the workshop on Grammar Engineering Across Frameworks, pages 1?8
Manchester, August 2008
TuLiPA: Towards a Multi-Formalism Parsing Environment for
Grammar Engineering
Laura Kallmeyer
SFB 441
Universita?t Tu?bingen
D-72074, Tu?bingen, Germany
lk@sfs.uni-tuebingen.de
Yannick Parmentier
CNRS - LORIA
Nancy Universite?
F-54506, Vand?uvre, France
parmenti@loria.fr
Timm Lichte
SFB 441
Universita?t Tu?bingen
D-72074, Tu?bingen, Germany
timm.lichte@uni-tuebingen.de
Johannes Dellert
SFB 441 - SfS
Universita?t Tu?bingen
D-72074, Tu?bingen, Germany
{jdellert,kevang}@sfs.uni-tuebingen.de
Wolfgang Maier
SFB 441
Universita?t Tu?bingen
D-72074, Tu?bingen, Germany
wo.maier@uni-tuebingen.de
Kilian Evang
SFB 441 - SfS
Universita?t Tu?bingen
D-72074, Tu?bingen, Germany
Abstract
In this paper, we present an open-source
parsing environment (Tu?bingen Linguistic
Parsing Architecture, TuLiPA) which uses
Range Concatenation Grammar (RCG)
as a pivot formalism, thus opening the
way to the parsing of several mildly
context-sensitive formalisms. This en-
vironment currently supports tree-based
grammars (namely Tree-Adjoining Gram-
mars (TAG) and Multi-Component Tree-
Adjoining Grammars with Tree Tuples
(TT-MCTAG)) and allows computation not
only of syntactic structures, but also of the
corresponding semantic representations. It
is used for the development of a tree-based
grammar for German.
1 Introduction
Grammars and lexicons represent important lin-
guistic resources for many NLP applications,
among which one may cite dialog systems, auto-
matic summarization or machine translation. De-
veloping such resources is known to be a complex
task that needs useful tools such as parsers and
generators (Erbach, 1992).
Furthermore, there is a lack of a common frame-
work allowing for multi-formalism grammar engi-
neering. Thus, many formalisms have been pro-
posed to model natural language, each coming
with specific implementations. Having a com-
mon framework would facilitate the comparison
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
between formalisms (e.g., in terms of parsing com-
plexity in practice), and would allow for a better
sharing of resources (e.g., having a common lex-
icon, from which different features would be ex-
tracted depending on the target formalism).
In this context, we present a parsing environ-
ment relying on a general architecture that can
be used for parsing with mildly context-sensitive
(MCS) formalisms1 (Joshi, 1987). Its underly-
ing idea is to use Range Concatenation Grammar
(RCG) as a pivot formalism, for RCG has been
shown to strictly include MCS languages while be-
ing parsable in polynomial time (Boullier, 2000).
Currently, this architecture supports tree-based
grammars (Tree-Adjoining Grammars and Multi-
Component Tree-Adjoining Grammars with Tree
Tuples (Lichte, 2007)). More precisely, tree-
based grammars are first converted into equivalent
RCGs, which are then used for parsing. The result
of RCG parsing is finally interpreted to extract a
derivation structure for the input grammar, as well
as to perform additional processings (e.g., seman-
tic calculus, extraction of dependency views).
The paper is structured as follows. In section 2,
we present the architecture of the TuLiPA parsing
environment and show how the use of RCG as a
pivot formalism makes it easier to design a modu-
lar system that can be extended to support several
dimensions (syntax, semantics) and/or formalisms.
In section 3, we give some desiderata for gram-
mar engineering and present TuLiPA?s current state
1A formalism is said to be mildly context sensitive (MCS)
iff (i) it generates limited cross-serial dependencies, (ii) it is
polynomially parsable, and (iii) the string languages gener-
ated by the formalism have the constant growth property (e.g.,
{a
2
n
|n ? 0} does not have this property). Examples of MCS
formalisms include Tree-Adjoining Grammars, Combinatory
Categorial Grammars and Linear Indexed Grammars.
1
with respect to these. In section 4, we compare
this system with existing approaches for parsing
and more generally for grammar engineering. Fi-
nally, in section 5, we conclude by presenting fu-
ture work.
2 Range Concatenation Grammar as a
pivot formalism
The main idea underlying TuLiPA is to use RCG
as a pivot formalism for RCG has appealing for-
mal properties (e.g., a generative capacity lying be-
yond Linear Context Free Rewriting Systems and
a polynomial parsing complexity) and there ex-
ist efficient algorithms, for RCG parsing (Boullier,
2000) and for grammar transformation into RCG
(Boullier, 1998; Boullier, 1999).
Parsing with TuLiPA is thus a 3-step process:
1. The input tree-based grammar is converted
into an RCG (using the algorithm of
Kallmeyer and Parmentier (2008) when deal-
ing with TT-MCTAG).
2. The resulting RCG is used for parsing the in-
put string using an extension of the parsing
algorithm of Boullier (2000).
3. The RCG derivation structure is interpreted to
extract the derivation and derived trees with
respect to the input grammar.
The use of RCG as a pivot formalism, and thus
of an RCG parser as a core component of the sys-
tem, leads to a modular architecture. In turns, this
makes TuLiPA more easily extensible, either in
terms of functionalities, or in terms of formalisms.
2.1 Adding functionalities to the parsing
environment
As an illustration of TuLiPA?s extensibility, one
may consider two extensions applied to the system
recently.
First, a semantic calculus using the syn-
tax/semantics interface for TAG proposed by Gar-
dent and Kallmeyer (2003) has been added. This
interface associates each tree with flat semantic
formulas. The arguments of these formulas are
unification variables, which are co-indexed with
features labelling the nodes of the syntactic tree.
During classical TAG derivation, trees are com-
bined, triggering unifications of the feature struc-
tures labelling nodes. As a result of these unifica-
tions, the arguments of the semantic formulas are
unified (see Fig. 1).
S
NP?x VP
NP
j
V NP?y NP
m
John loves Mary
name(j,john) love(x,y) name(m,mary)
; love(j,m),name(j,john),name(m,mary)
Figure 1: Semantic calculus in Feature-Based
TAG.
In our system, the semantic support has been in-
tegrated by (i) extending the internal tree objects to
include semantic formulas (the RCG-conversion is
kept unchanged), and (ii) extending the construc-
tion of the derived tree (step 3) so that during the
interpretation of the RCG derivation in terms of
tree combinations, the semantic formulas are car-
ried and updated with respect to the feature unifi-
cations performed.
Secondly, let us consider lexical disambigua-
tion. Because of the high redundancy lying within
lexicalized formalisms such as lexicalized TAG,
it is common to consider tree schemata having a
frontier node marked for anchoring (i.e., lexical-
ization). At parsing time, the tree schemata are
anchored according to the input string. This an-
choring selects a subgrammar supposed to cover
the input string. Unfortunately, this subgrammar
may contain many trees that either do not lead to
a parse or for which we know a priori that they
cannot be combined within the same derivation
(so we should not predict a derivation from one
of these trees to another during parsing). As a re-
sult, the parser could have poor performance be-
cause of the many derivation paths that have to
be explored. Bonfante et al (2004) proposed to
polarize the structures of the grammar, and to ap-
ply an automaton-based filtering of the compatible
structures. The idea is the following. One compute
polarities representing the needs/resources brought
by a given tree (or tree tuple for TT-MCTAG).
A substitution or foot node with category NP re-
flects a need for an NP (written NP-). In the same
way, an NP root node reflects a resource of type
NP (written NP+). Then you build an automaton
whose edges correspond to trees, and states to po-
larities brought by trees along the path. The au-
tomaton is then traversed to extract all paths lead-
ing to a final state with a neutral polarity for each
category and +1 for the axiom (see Fig. 2, the state
2
7 is the only valid state and {proper., trans., det.,
noun.} the only compatible set of trees).
0
John
1 1
eats
2 2
a
3 3
cake
4
0 1
NP+
2
S+
3
S+ NP-
4
S+
5
S+ NP-
6
S+ NP+
7
S+
proper.
intrans.
trans.
det.
det.
noun.
noun.
Figure 2: Polarity-based lexical disambiguation.
In our context, this polarity filtering has been
added before step 1, leaving untouched the core
RCG conversion and parsing steps. The idea is
to compute the sets of compatible trees (or tree
tuples for TT-MCTAG) and to convert these sets
separately. Indeed the RCG has to encode only
valid adjunctions/substitutions. Thanks to this
automaton-based ?clustering? of the compatible
tree (or tree tuples), we avoid predicting incompat-
ible derivations. Note that the time saved by using
a polarity-based filter is not negligible, especially
when parsing long sentences.2
2.2 Adding formalisms to the parsing
environment
Of course, the two extensions introduced in the
previous section may have been added to other
modular architectures as well. The main gain
brought by RCG is the possibility to parse not
only tree-based grammars, but other formalisms
provided they can be encoded into RCG. In our
system, only TAG and TT-MCTAG have been
considered so far. Nonetheless, Boullier (1998)
and S?gaard (2007) have defined transformations
into RCG for other mildly context-sensitive for-
malisms.3
To sum up, the idea would be to keep the core
RCG parser, and to extend TuLiPA with a specific
conversion module for each targeted formalism.
On top of these conversion modules, one should
also provide interpretation modules allowing to de-
code the RCG derivation forest in terms of the in-
put formalism (see Fig. 3).
2An evaluation of the gain brought by this technique when
using Interaction Grammar is given by Bonfante et al (2004).
3These include Multi-Component Tree-Adjoining Gram-
mar, Linear Indexed Grammar, Head Grammar, Coupled
Context Free Grammar, Right Linear Unification Grammar
and Synchronous Unification Grammar.
Figure 3: Towards a multi-formalism parsing envi-
ronment.
An important point remains to be discussed. It
concerns the role of lexicalization with respect to
the formalism used. Indeed, the tree-based gram-
mar formalisms currently supported (TAG and TT-
MCTAG) both share the same lexicalization pro-
cess (i.e., tree anchoring). Thus the lexicon format
is common to these formalisms. As we will see
below, it corresponds to a 2-layer lexicon made of
inflected forms and lemma respectively, the latter
selecting specific grammatical structures. When
parsing other formalisms, it is still unclear whether
one can use the same lexicon format, and if not
what kind of general lexicon management module
should be added to the parser (in particular to deal
with morphology).
3 Towards a complete grammar
engineering environment
So far, we have seen how to use a generic parsing
architecture relying on RCG to parse different for-
malisms. In this section, we adopt a broader view
and enumerate some requirements for a linguistic
resource development environment. We also see
to what extent these requirements are fulfilled (or
partially fulfilled) within the TuLiPA system.
3.1 Grammar engineering with TuLiPA
As advocated by Erbach (1992), grammar en-
gineering needs ?tools for testing the grammar
with respect to consistency, coverage, overgener-
ation and accuracy?. These characteristics may
be taken into account by different interacting soft-
ware. Thus, consistency can be checked by a semi-
automatic grammar production device, such as the
XMG system of Duchier et al (2004). Overgen-
eration is mainly checked by a generator (or by
a parser with adequate test suites), and coverage
and accuracy by a parser. In our case, the TuLiPA
system provides an entry point for using a gram-
mar production system (and a lexicon conversion
3
tool introduced below), while including a parser.
Note that TuLiPA does not include any generator,
nonetheless it uses the same lexicon format as the
GenI surface realizer for TAG4.
TuLiPA?s input grammar is designed using
XMG, which is a metagrammar compiler for tree-
based formalisms. In other terms, the linguist de-
fines a factorized description of the grammar (the
so-called metagrammar) in the XMG language.
Briefly, an XMG metagrammar consists of (i) ele-
mentary tree fragments represented as tree descrip-
tion logic formulas, and (ii) conjunctive and dis-
junctive combinations of these tree fragments to
describe actual TAG tree schemata.5 This meta-
grammar is then compiled by the XMG system to
produce a tree grammar in an XML format. Note
that the resulting grammar contains tree schemata
(i.e., unlexicalized trees). To lexicalize these, the
linguist defines a lexicon mapping words with cor-
responding sets of trees. Following XTAG (2001),
this lexicon is a 2-layer lexicon made of morpho-
logical and lemma specifications. The motivation
of this 2-layer format is (i) to express linguistic
generalizations at the lexicon level, and (ii) to al-
low the parser to only select a subgrammar accord-
ing to a given sentence, thus reducing parsing com-
plexity. TuLiPA comes with a lexicon conversion
tool (namely lexConverter) allowing to write a lex-
icon in a user-friendly text format and to convert it
into XML. An example of an entry of such a lexi-
con is given in Fig. 4.
The morphological specification consists of a
word, the corresponding lemma and morphologi-
cal features. The main pieces of information con-
tained in the lemma specification are the ?ENTRY
field, which refers to the lemma, the ?CAT field
referring to the syntactic category of the anchor
node, the ?SEM field containing some semantic in-
formation allowing for semantic instantiation, the
?FAM field, which contains the name of the tree
family to be anchored, the ?FILTERS field which
consists of a feature structure constraining by uni-
fication the trees of a given family that can be
anchored by the given lemma (used for instance
for non-passivable verbs), the ?EQUATIONS field
allowing for the definition of equations targeting
named nodes of the trees, and the ?COANCHORS
field, which allows for the specification of co-
anchors (such as by in the verb to come by).
4http://trac.loria.fr/?geni
5See (Crabbe?, 2005) for a presentation on how to use the
XMG formalism for describing a core TAG for French.
Morphological specification:
vergisst vergessen [pos=v,num=sg,per=3]
Lemma specification:
?ENTRY: vergessen
?CAT: v
?SEM: BinaryRel[pred=vergessen]
?ACC: 1
?FAM: Vnp2
?FILTERS: []
?EX:
?EQUATIONS:
NParg1 ? cas = nom
NParg2 ? cas = acc
?COANCHORS:
Figure 4: Morphological and lemma specification
of vergisst.
From these XML resources, TuLiPA parses a
string, corresponding either to a sentence or a con-
stituent (noun phrase, prepositional phrase, etc.),
and computes several output pieces of informa-
tion, namely (for TAG and TT-MCTAG): deriva-
tion/derived trees, semantic representations (com-
puted from underspecified representations using
the utool software6, or dependency views of the
derivation trees (using the DTool software7).
3.2 Grammar debugging
The engineering process introduced in the preced-
ing section belongs to a development cycle, where
one first designs a grammar and corresponding
lexicons using XMG, then checks these with the
parser, fixes them, parses again, and so on.
To facilitate grammar debugging, TuLiPA in-
cludes both a verbose and a robust mode allow-
ing respectively to (i) produce a log of the RCG-
conversion, RCG-parsing and RCG-derivation in-
terpretation, and (ii) display mismatching features
leading to incomplete derivations. More precisely,
in robust mode, the parser displays derivations step
by step, highlighting feature unification failures.
TuLiPA?s options can be activated via an intu-
itive Graphical User Interface (see Fig. 5).
6See http://www.coli.uni-saarland.de/
projects/chorus/utool/, with courtesy of Alexander
Koller.
7With courtesy of Marco Kuhlmann.
4
Figure 5: TuLiPA?s Graphical User Interface.
3.3 Towards a functional common interface
Unfortunately, as mentioned above, the linguist
has to move back-and-forth from the gram-
mar/lexicon descriptions to the parser, i.e., each
time the parser reports grammar errors, the linguist
fixes these and then recomputes the XML files and
then parses again. To avoid this tedious task of re-
sources re-compilation, we started developing an
Eclipse8 plug-in for the TuLiPA system. Thus, the
linguist will be able to manage all these resources,
and to call the parser, the metagrammar compiler,
and the lexConverter from a common interface (see
Fig. 6).
Figure 6: TuLiPA?s eclipse plug-in.
The motivation for this plug-in comes from
the observation that designing electronic gram-
mars is a task comparable to designing source
8See http://www.eclipse.org
code. A powerful grammar engineering environ-
ment should thus come with development facili-
ties such as precise debugging information, syntax
highlighting, etc. Using the Eclipse open-source
development platform allows for reusing several
components inherited from the software develop-
ment community, such as plug-ins for version con-
trol, editors coupled with explorers, etc.
Eventually, one point worth considering in the
context of grammar development concerns data en-
coding. To our knowledge, only few environments
provide support for UTF-8 encoding, thus guaran-
tying the coverage of a wide set of charsets and
languages. In TuLiPA, we added an UTF-8 sup-
port (in the lexConverter), thus allowing to design
a TAG for Korean (work in progress).
3.4 Usability of the TuLiPA system
As mentioned above, the TuLiPA system is made
of several interacting components, that one cur-
rently has to install separately. Nonetheless, much
attention has been paid to make this installation
process as easy as possible and compatible with
all major platforms.9
XMG and lexConverter can be installed by com-
piling their sources (using a make command).
TuLiPA is developed in Java and released as an ex-
ecutable jar. No compilation is needed for it, the
only requirement is the Gecode/GecodeJ library10
(available as a binary package for many platforms).
Finally, the TuLiPA eclipse plug-in can be installed
easily from eclipse itself. All these tools are re-
leased under Free software licenses (either GNU
GPL or Eclipse Public License).
This environment is being used (i) at the Univer-
sity of Tu?bingen, in the context of the development
of a TT-MCTAG for German describing both syn-
tax and semantics, and (ii) at LORIA Nancy, in the
development of an XTAG-based metagrammar for
English. The German grammar, called GerTT (for
German Tree Tuples), is released under a LGPL li-
cense for Linguistic Resources11 and is presented
in (Kallmeyer et al, 2008). The test-suite cur-
rently used to check the grammar is hand-crafted.
A more systematic evaluation of the grammar is in
preparation, using the Test Suite for Natural Lan-
guage Processing (Lehmann et al, 1996).
9See http://sourcesup.cru.fr/tulipa.
10See http://www.gecode.org/gecodej.
11See http://infolingu.univ-mlv.
fr/DonneesLinguistiques/
Lexiques-Grammaires/lgpllr.html
5
4 Comparison with existing approaches
4.1 Engineering environments for tree-based
grammar formalisms
To our knowledge, there is currently no available
parsing environment for multi-component TAG.
Existing grammar engineering environments for
TAG include the DyALog system12 described in
Villemonte de la Clergerie (2005). DyALog is a
compiler for a logic programming language using
tabulation and dynamic programming techniques.
This compiler has been used to implement efficient
parsing algorithms for several formalisms, includ-
ing TAG and RCG. Unfortunately, it does not in-
clude any built-in GUI and requires a good know-
ledge of the GNU build tools to compile parsers.
This makes it relatively difficult to use. DyALog?s
main quality lies in its efficiency in terms of pars-
ing time and its capacity to handle very large re-
sources. Unlike TuLiPA, it does not compute se-
mantic representations.
The closest approach to TuLiPA corresponds to
the SemTAG system13, which extends TAG parsers
compiled with DyALog with a semantic calculus
module (Gardent and Parmentier, 2007). Unlike
TuLiPA, this system only supports TAG, and does
not provide any graphical output allowing to easily
check the result of parsing.
Note that, for grammar designers mainly inter-
ested in TAG, SemTAG and TuLiPA can be seen
as complementary tools. Indeed, one may use
TuLiPA to develop the grammar and check spe-
cific syntactic structures thanks to its intuitive pars-
ing environment. Once the grammar is stable, one
may use SemTAG in batch processing to parse
corpuses and build semantic representations using
large grammars. This combination of these 2 sys-
tems is made easier by the fact that both use the
same input formats (a metagrammar in the XMG
language and a text-based lexicon). This approach
is the one being adopted for the development of a
French TAG equipped with semantics.
For Interaction Grammar (Perrier, 2000), there
exists an engineering environment gathering the
XMG metagrammar compiler and an eLEtrOstatic
PARser (LEOPAR).14 This environment is be-
ing used to develop an Interaction Grammar for
French. TuLiPA?s lexical disambiguation module
12See http://dyalog.gforge.inria.fr
13See http://trac.loria.fr/?semconst
14See http://www.loria.fr/equipes/
calligramme/leopar/
reuses techniques introduced by LEOPAR. Unlike
TuLiPA, LEOPAR does not currently support se-
mantic information.
4.2 Engineering environments for other
grammar formalisms
For other formalisms, there exist state-of-the-art
grammar engineering environments that have been
used for many years to design large deep grammars
for several languages.
For Lexical Functional Grammar, one may cite
the Xerox Linguistic Environment (XLE).15 For
Head-driven Phrase Structure Grammar, the main
available systems are the Linguistic Knowledge
Base (LKB)16 and the TRALE system.17 For
Combinatory Categorial Grammar, one may cite
the OpenCCG library18 and the C&C parser.19
These environments have been used to develop
broad-coverage resources equipped with semantics
and include both a generator and a parser. Un-
like TuLiPA, they represent advanced projects, that
have been used for dialog and machine translation
applications. They are mainly tailored for a spe-
cific formalism.20
5 Future work
In this section, we give some prospective views
concerning engineering environments in general,
and TuLiPA in particular. We first distinguish be-
tween 2 main usages of grammar engineering en-
vironments, namely a pedagogical usage and an
application-oriented usage, and finally give some
comments about multi-formalism.
5.1 Pedagogical usage
Developing grammars in a pedagogical context
needs facilities allowing for inspection of the struc-
tures of the grammar, step-by-step parsing (or gen-
eration), along with an intuitive interface. The idea
is to abstract away from technical aspects related to
implementation (intermediate data structures, opti-
mizations, etc.).
15See http://www2.parc.com/isl/groups/
nltt/xle/
16See http://wiki.delph-in.net/moin
17See http://milca.sfs.uni-tuebingen.de/
A4/Course/trale/
18See http://openccg.sourceforge.net/
19See http://svn.ask.it.usyd.edu.au/trac/
candc/wiki
20Nonetheless, Beavers (2002) encoded a CCG in the
LKB?s Type Description Language.
6
The question whether to provide graphical or
text-based editors can be discussed. As advo-
cated by Baldridge et al (2007), a low-level text-
based specification can offer more flexibility and
bring less frustration to the grammar designer, es-
pecially when such a specification can be graph-
ically interpreted. This is the approach chosen
by XMG, where the grammar is defined via an
(advanced or not) editor such as gedit or emacs.
Within TuLiPA, we chose to go further by using
the Eclipse platform. Currently, it allows for dis-
playing a summary of the content of a metagram-
mar or lexicon on a side panel, while editing these
on a middle panel. These two panels are linked
via a jump functionality. The next steps concern
(i) the plugging of a graphical viewer to display
the (meta)grammar structures independently from
a given parse, and (ii) the extension of the eclipse
plug-in so that one can easily consistently modify
entries of the metagrammar or lexicon (especially
when these are split over several files).
5.2 Application-oriented usage
When dealing with applications, one may demand
more from the grammar engineering environment,
especially in terms of efficiency and robustness
(support for larger resources, partial parsing, etc.).
Efficiency needs optimizations in the parsing
engine making it possible to support grammars
containing several thousands of structures. One
interesting question concerns the compilation of a
grammar either off-line or on-line. In DyALog?s
approach, the grammar is compiled off-line into
a logical automaton encoding all possible deriva-
tions. This off-line compilation can take some
minutes with a TAG having 6000 trees, but the re-
sulting parser can parse sentences within a second.
In TuLiPA?s approach, the grammar is compiled
into an RCG on-line. While giving satisfactory re-
sults on reduced resources21 , it may lead to trou-
bles when scaling up. This is especially true for
TAG (the TT-MCTAG formalism is by definition a
factorized formalism compared with TAG). In the
future, it would be useful to look for a way to pre-
compile a TAG into an RCG off-line, thus saving
the conversion time.
Another important feature of grammar engineer-
ing environments consists of its debugging func-
21For a TT-MCTAG counting about 300 sets of trees and an
and-crafted lexicon made of about 300 of words, a 10-word
sentence is parsed (and a semantic representation computed)
within seconds.
tionalities. Among these, one may cite unit and
integration testing. It would be useful to extend
the TuLiPA system to provide a module for gen-
erating test-suites for a given grammar. The idea
would be to record the coverage and analyses of
a grammar at a given time. Once the grammar is
further developed, these snapshots would allow for
regression testing.
5.3 About multi-formalism
We already mentioned that TuLiPA was opening
a way towards multi-formalism by relying on an
RCG core. It is worth noticing that the XMG
system was also designed to be further extensi-
ble. Indeed, a metagrammar in XMG corresponds
to the combination of elementary structures. One
may think of designing a library of such structures,
these would be dependent on the target gram-
mar formalism. The combinations may represent
general linguistic concepts and would be shared
by different grammar implementations, following
ideas presented by Bender et al (2005).
6 Conclusion
In this paper, we have presented a multi-formalism
parsing architecture using RCG as a pivot formal-
ism to parse mildly context-sensitive formalisms
(currently TAG and TT-MCTAG). This system has
been designed to facilitate grammar development
by providing user-friendly interfaces, along with
several functionalities (e.g., dependency extrac-
tion, derivation/derived tree display and semantic
calculus). It is currently used for developing a core
grammar for German.
At the moment, we are working on the extension
of this architecture to include a fully functional
Eclipse plug-in. Other current tasks concern op-
timizations to support large scale parsing and the
extension of the syntactic and semantic coverage
of the German grammar under development.
In a near future, we plan to evaluate the parser
and the German grammar (parsing time, correction
of syntactic and semantic outputs) with respect to
a standard test-suite such as the TSNLP (Lehmann
et al, 1996).
Acknowledgments
This work has been supported by the Deutsche
Forschungsgemeinschaft (DFG) and the Deutscher
Akademischer Austausch Dienst (DAAD, grant
7
A/06/71039). We are grateful to three anonymous
reviewers for valuable comments on this work.
References
Baldridge, Jason, Sudipta Chatterjee, Alexis Palmer,
and Ben Wing. 2007. DotCCG and VisCCG: Wiki
and programming paradigms for improved grammar
engineering with OpenCCG. In King, Tracy Hol-
loway and Emily M. Bender, editors, Proceedings of
the GEAF07 workshop, pages 5?25, Stanford, CA.
CSLI.
Beavers, John. 2002. Documentation: A CCG Imple-
mentation for the LKB. LinGO Working Paper No.
2002-08, CSLI, Stanford University, Stanford, CA.
Bender, Emily, Dan Flickinger, Frederik Fouvry, and
Melanie Siegel. 2005. Shared representation in mul-
tilingual grammar engineering. Research on Lan-
guage & Computation, 3(2):131?138.
Bonfante, Guillaume, Bruno Guillaume, and Guy Per-
rier. 2004. Polarization and abstraction of grammat-
ical formalisms as methods for lexical disambigua-
tion. In Proceedings of the International Conference
on Computational Linguistics (CoLing 2004), pages
303?309, Geneva, Switzerland.
Boullier, Pierre. 1998. Proposal for a natural lan-
guage processing syntactic backbone. Rapport de
Recherche 3342, INRIA.
Boullier, Pierre. 1999. On TAG and Multicomponent
TAG Parsing. Rapport de Recherche 3668, INRIA.
Boullier, Pierre. 2000. Range concatenation gram-
mars. In Proceedings of the International Workshop
on Parsing Technologies (IWPT 2000), pages 53?64,
Trento, Italy.
Crabbe?, Benoit. 2005. Grammatical development with
XMG. In Proceedings of the conference on Logical
Aspects of Computational Linguistics 2005 (LACL
05), pages 84?100, Bordeaux, France.
Duchier, Denys, Joseph Le Roux, and Yannick Parmen-
tier. 2004. The Metagrammar Compiler: An NLP
Application with a Multi-paradigm Architecture. In
Proceedings of the 2nd International Mozart/Oz
Conference (MOZ?2004), pages 175?187, Charleroi,
Belgium.
Erbach, Gregor. 1992. Tools for grammar engineer-
ing. In 3rd Conference on Applied Natural Lan-
guage Processing, pages 243?244, Trento, Italy.
Gardent, Claire and Laura Kallmeyer. 2003. Semantic
Construction in FTAG. In Proceedings of the Con-
ference of the European chapter of the Association
for Computational Linguistics (EACL 2003), pages
123?130, Budapest, Hungary.
Gardent, Claire and Yannick Parmentier. 2007. Sem-
tag: a platform for specifying tree adjoining gram-
mars and performing tag-based semantic construc-
tion. In Proceedings of the International Confer-
ence of the Association for Computational Linguis-
tics (ACL 2007), Companion Volume Proceedings of
the Demo and Poster Sessions, pages 13?16, Prague,
Czech Republic.
Joshi, Aravind K. 1987. An introduction to Tree Ad-
joining Grammars. In Manaster-Ramer, A., editor,
Mathematics of Language, pages 87?114. John Ben-
jamins, Amsterdam.
Kallmeyer, Laura and Yannick Parmentier. 2008. On
the relation between Multicomponent Tree Adjoin-
ing Grammars with Tree Tuples (TT-MCTAG) and
Range Concatenation Grammars (RCG). In Pro-
ceedings of the 2nd International Conference on
Language and Automata Theories and Applications
(LATA 2008), pages 277?288, Tarragona, Spain.
Kallmeyer, Laura, Timm Lichte, Wolfgang Maier, Yan-
nick Parmentier, and Johannes Dellert. 2008. De-
velopping an MCTAG for German with an RCG-
based Parser. In Proceedings of the Language, Re-
source and Evaluation Conference (LREC 2008),
Marrakech, Morocco.
Lehmann, Sabine, Stephan Oepen, Sylvie Regnier-
Prost, Klaus Netter, Veronika Lux, Judith Klein,
Kirsten Falkedal, Frederik Fouvry, Dominique Esti-
val, Eva Dauphin, Herve? Compagnion, Judith Baur,
Lorna Balkan, and Doug Arnold. 1996. TSNLP ?
Test Suites for Natural Language Processing. In Pro-
ceedings of the International Conference on Compu-
tational Linguistics (Coling 1996), volume 2, pages
711?716, Copenhagen, Denmark.
Lichte, Timm. 2007. An MCTAG with tuples for co-
herent constructions in German. In Proceedings of
the 12th Conference on Formal Grammar, Dublin,
Ireland.
Perrier, Guy. 2000. Interaction grammars. In Pro-
ceedings of the International Conference on Compu-
tational Linguistics (CoLing 2000), pages 600?606,
Saarbruecken, Germany.
S?gaard, Anders. 2007. Complexity, expressivity and
logic of linguistic theories. Ph.D. thesis, University
of Copenhagen, Copenhagen, Denmark.
Villemonte de la Clergerie, ?Eric. 2005. DyALog: a
tabular logic programming based environment for
NLP. In Proceedings of the workshop on Constraint
Satisfaction for Language Processing (CSLP 2005),
pages 18?33, Barcelona, Spain.
XTAG-Research-Group. 2001. A lexicalized tree
adjoining grammar for english. Technical Re-
port IRCS-01-03, IRCS, University of Pennsylva-
nia. Available at http://www.cis.upenn.
edu/?xtag/gramrelease.html.
8
