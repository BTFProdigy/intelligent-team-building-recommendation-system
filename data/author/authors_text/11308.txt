Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 89?92,
Columbus, Ohio, USA, June 2008. c?2008 Association for Computational Linguistics
A Novel Feature-based Approach to Chinese Entity Relation Extraction
 
Wenjie Li1, Peng Zhang1,2, Furu Wei1, Yuexian Hou2 and Qin Lu1
1Department of Computing 2School of Computer Science and Technology
The Hong Kong Polytechnic University, Hong Kong Tianjin University, China 
{cswjli,csfwei,csluqin}@comp.polyu.edu.hk {pzhang,yxhou}@tju.edu.cn 
 
 
Abstract 
Relation extraction is the task of finding 
semantic relations between two entities from 
text. In this paper, we propose a novel 
feature-based Chinese relation extraction 
approach that explicitly defines and explores 
nine positional structures between two entities. 
We also suggest some correction and inference 
mechanisms based on relation hierarchy and 
co-reference information etc. The approach is 
effective when evaluated on the ACE 2005 
Chinese data set. 
1 Introduction 
Relation extraction is promoted by the ACE program. 
It is the task of finding predefined semantic relations 
between two entities from text. For example, the 
sentence ?Bill Gates is the chairman and chief 
software architect of Microsoft Corporation? conveys 
the ACE-style relation ?ORG-AFFILIATION? 
between the two entities ?Bill Gates (PER)? and 
?Microsoft Corporation (ORG)?.  
The task of relation extraction has been extensively 
studied in English over the past years. It is typically 
cast as a classification problem. Existing approaches 
include feature-based and kernel-based classification. 
Feature-based approaches transform the context of 
two entities into a liner vector of carefully selected 
linguistic features, varying from entity semantic 
information to lexical and syntactic features of the 
context. Kernel-based approaches, on the other hand, 
explore structured representation such as parse tree 
and dependency tree and directly compute the 
similarity between trees. Comparably, feature-based 
approaches are easier to implement and achieve much 
success. 
In contrast to the significant achievements 
concerning English and other Western languages, 
research progress in Chinese relation extraction is 
quite limited. This may be attributed to the different 
characteristic of Chinese language, e.g. no word 
boundaries and lack of morphologic variations, etc. In 
this paper, we propose a character-based Chinese 
entity relation extraction approach that complements 
entity context (both internal and external) character 
N-grams with four word lists extracted from a 
published Chinese dictionary. In addition to entity 
semantic information, we define and examine nine 
positional structures between two entities. To cope 
with the data sparseness problem, we also suggest 
some correction and inference mechanisms according 
to the given ACE relation hierarchy and co-reference 
information. Experiments on the ACE 2005 data set 
show that the positional structure feature can provide 
stronger support for Chinese relation extraction. 
Meanwhile, it can be captured with less effort than 
applying deep natural language processing. But 
unfortunately, entity co-reference does not help as 
much as we have expected. The lack of necessary 
co-referenced mentions might be the main reason. 
2 Related Work 
Many approaches have been proposed in the literature 
of relation extraction. Among them, feature-based and 
kernel-based approaches are most popular. 
Kernel-based approaches exploit the structure of 
the tree that connects two entities. Zelenko et al(2003) 
proposed a kernel over two parse trees, which 
recursively matched nodes from roots to leaves in a 
top-down manner. Culotta and Sorensen (2004) 
extended this work to estimate similarity between 
augmented dependency trees. The above two work 
was further advanced by Bunescu and Mooney (2005) 
who argued that the information to extract a relation 
between two entities can be typically captured by the 
shortest path between them in the dependency graph. 
Later, Zhang et al(2006) developed a composite 
kernel that combined parse tree kernel with entity 
kernel and Zhou et al(2007) experimented with a 
context-sensitive kernel by automatically determining 
context-sensitive tree spans.  
In the feature-based framework, Kambhatla (2004) 
employed ME models to combine diverse lexical, 
syntactic and semantic features derived from word, 
entity type, mention level, overlap, dependency and 
parse tree. Based on his work, Zhou et al(2005) 
89
further incorporated the base phrase chunking 
information and semi-automatically collected country 
name list and personal relative trigger word list. Jiang 
and Zhai (2007) then systematically explored a large 
space of features and evaluated the effectiveness of 
different feature subspaces corresponding to sequence, 
syntactic parse tree and dependency parse tree. Their 
experiments showed that using only the basic unit 
features within each feature subspace can already 
achieve state-of-art performance, while over-inclusion 
of complex features might hurt the performance. 
Previous approaches mainly focused on English 
relations. Most of them were evaluated on the ACE 
2004 data set (or a sub set of it) which defined 7 
relation types and 23 subtypes. Although Chinese 
processing is of the same importance as English and 
other Western language processing, unfortunately few 
work has been published on Chinese relation 
extraction. Che et al(2005) defined an improved edit 
distance kernel over the original Chinese string 
representation around particular entities. The only 
relation they studied is PERSON-AFFLIATION. The 
insufficient study in Chinese relation extraction drives 
us to investigate how to find an approach that is 
particularly appropriate for Chinese. 
3 A Chinese Relation Extraction Model 
Due to the aforementioned reasons, entity relation 
extraction in Chinese is more challenging than in 
English. The system segmented words are already not 
error free, saying nothing of the quality of the 
generated parse trees. All these errors will 
undoubtedly propagate to the subsequent processing, 
such as relation extraction. It is therefore reasonable to 
conclude that kernel-based especially tree-kernel 
approaches are not suitable for Chinese, at least at 
current stage. In this paper, we study a feature-based 
approach that basically integrates entity related 
information with context information. 
3.1 Classification Features  
The classification is based on the following four types 
of features. 
z Entity Positional Structure Features  
We define and examine nine finer positional 
structures between two entities (see Appendix). They 
can be merged into three coarser structures. 
z Entity Features 
Entity types and subtypes are concerned.  
z Entity Context Features 
These are character-based features. We consider 
both internal and external context. Internal context 
includes the characters inside two entities and the 
characters inside the heads of two entities. External 
context involves the characters around two entities 
within a given window size (it is set to 4 in this study). 
All the internal and external context characters are 
transformed to Uni-grams and Bi-grams. 
z Word List Features 
Although Uni-grams and Bi-grams should be able 
to cover most of Chinese words given sufficient 
training data, many discriminative words might not be 
discovered by classifiers due to the severe sparseness 
problem of Bi-grams. We complement character- 
based context features with four word lists which are 
extracted from a published Chinese dictionary. The 
word lists include 165 prepositions, 105 orientations, 
20 auxiliaries and 25 conjunctions. 
3.2 Correction with Relation/Argument 
Constraints and Type/Subtype Consistency Check 
An identified relation is said to be correct only when 
its type/subtype (R) is correct and at the same time its 
two arguments (ARG-1 and ARG-2) must be of the 
correct entity types/subtypes and of the correct order. 
One way to improve the previous feature-based 
classification approach is to make use of the prior 
knowledge of the task to find and rectify the incorrect 
results. Table 1 illustrates the examples of possible 
relations between PER and ORG. We regard possible 
relations between two particular types of entity 
arguments as constraints. Some relations are 
symmetrical for two arguments, such as PER_ 
SOCIAL.FAMILY, but others not, such as ORG_AFF. 
EMPLOYMENT. Argument orders are important for 
asymmetrical relations.  
 PER ORG 
PER PER_SOCIAL.BUS, PER_SOCIAL.FAMILY, ? 
ORG_AFF.EMPLOYMENT, 
 ORG_AFF.OWNERSHIP, ? 
ORG  PART_WHOLE.SUBSIDIARY, ORG_AFF.INVESTOR/SHARE, ?
Table 1 Possible Relations between ARG-1 and ARG-2 
Since our classifiers are trained on relations instead 
of arguments, we simply select the first (as in adjacent 
and separate structures) and outer (as in nested 
structures) as the first argument. This setting works at 
most of cases, but still fails sometimes. The correction 
works in this way. Given two entities, if the identified 
type/subtype is an impossible one, it is revised to 
NONE (it means no relation at all). If the identified 
type/subtype is possible, but the order of arguments 
does not consist with the given relation definition, the 
order of arguments is adjusted.  
Another source of incorrect results is the 
inconsistency between the identified types and 
subtypes, since they are typically classified separately. 
90
This type of errors can be checked against the 
provided hierarchy of relations, such as the subtypes 
OWNERSHIP and EMPLOYMENT must belong to 
the ORG_AFF type. There are existing strategies to 
deal with this problem, such as strictly bottom-up (i.e. 
use the identified subtype to choose the type it belongs 
to), guiding top-down (i.e. to classify types first and 
then subtypes under a certain type). However, these 
two strategies lack of interaction between the two 
classification levels. To insure consistency in an 
interactive manner, we rank the first n numbers of the 
most likely classified types and then check them 
against the classified subtype one by one until the 
subtype conforms to a type. The matched type is 
selected as the result. If the last type still fails, both 
type and subtype are revised to NONE. We call this 
strategy type selection. Alternatively, we can choose 
the most likely classified subtypes, and check them 
with the classified type (i.e. subtype selection 
strategy). Currently, n is 2. 
3.2 Inference with Co-reference Information and 
Linguistic Patterns 
Each entity can be mentioned in different places in 
text. Two mentions are said to be co-referenced to one 
entity if they refers to the same entity in the world 
though they may have different surface expressions. 
For example, both ?he? and ?Gates? may refer to ?Bill 
Gates of Microsoft?. If a relation ?ORG- 
AFFILIATION? is held between ?Bill Gates? and 
?Microsoft?, it must be also held between ?he? and 
?Microsoft?. Formally, given two entities E1={EM11, 
EM12, ?, EM1n} and E2={EM21, EM22, ?, EM2m} (Ei 
is an entity, EMij is a mention of Ei), it is true that 
R(EM11, EM21)? R(EM1l, EM2k). This nature allows 
us to infer more relations which may not be identified 
by classifiers.  
Our previous experiments show that the 
performance of the nested and the adjacent relations is 
much better than the performance of other structured 
relations which suffer from unbearable low recall due 
to insufficient training data. Intuitively we can follow 
the path of ?Nested ? Adjacent ? Separated ? 
Others? (Nested, Adjacent and Separated structures 
are majority in the corpus) to perform the inference. 
But soon we have an interesting finding. If two related 
entities are nested, almost all the mentions of them are 
nested. So basically inference works on ?Adjacent ? 
Separated??. 
When considering the co-reference information, we 
may find another type of inconsistency, i.e. the one 
raised from co-referenced entity mentions. It is 
possible that R(EM11, EM21) ? R(EM12, EM22) when R 
is identified based on the context of EM. Co-reference 
not only helps for inference but also provides the 
second chance to check the consistency among entity 
mention pairs so that we can revise accordingly. As the 
classification results of SVM can be transformed to 
probabilities with a sigmoid function, the relations of 
lower probability mention pairs are revised according 
to the relation of highest probability mention pairs. 
The above inference strategy is called coreference- 
based inference. Besides, we find that pattern-based 
inference is also necessary. The relations of adjacent 
structure can infer the relations of separated structure 
if there are certain linguistic indicators in the local 
context. For example, given a local context ?EM1 and 
EM2 located EM3?, if the relation of EM2 and EM3 has 
been identified, EM1 and EM3 will take the relation 
type/subtype that EM2 and EM3 holds. Currently, the 
only indicators under consideration are ?and? and ?or?. 
However, more patterns can be included in the future. 
4 Experimental Results 
The experiments are conducted on the ACE 2005 
Chinese RDC training data (with true entities) where 6 
types and 18 subtypes of relations are annotated. We 
use 75% of it to train SVM classifiers and the 
remaining to evaluate results.  
The aim of the first set of experiments is to examine 
the role of structure features. In these experiments, a 
?NONE? class is added to indicate a null type/subtype. 
With entity features and entity context features and 
word list features, we consider three different 
classification contexts: (1), only three coarser 
structures 1 , i.e. nested, adjacent and separated, are 
used as feature, and a classifier is trained for each 
relation type and subtype; (2) similar to (1) but all nine 
structures are concerned; and (3) similar to (2) but the 
training data is divided into 9 parts according to 
structure, i.e. type and subtype classifiers are trained 
on the data with the same structures. The results 
presented in Table 2 show that 9-structure is much 
more discriminative than 3-structure. Also, the 
performance can be improved significantly by 
dividing training data based on nine structures. 
Type / Subtype Precision Recall F-measure 
3-Structure 0.7918/0.7356 0.3123/0.2923 0.4479/0.4183
9-Structure 0.7533/0.7502 0.4389/0.3773 0.5546/0.5021
9-Structure_Divide 0.7733/0.7485 0.5506/0.5301 0.6432/0.6209
Table 2 Evaluation on Structure Features 
Structure Positive Class Negative Class Ratio 
Nested 6332 4612 1 : 0.7283
Adjacent 2028 27100 1 : 13.3629
                                                     
1 Nine structures are combined to three by merging (b) and (c) to (a), (e) 
and (f) to (d), (h) and (i) to (g). 
91
Separated 939 79989 1 : 85.1853
Total 9299 111701 1 : 12.01 
Table 3 Imbalance Training Class Problem 
In the experiments, we find that the training class 
imbalance problem is quite serious, especially for the 
separated structure (see Table 3 above where 
?Positive? and ?Negative? mean there exists a relation 
between two entities and otherwise). A possible 
solution to alleviate this problem is to detect whether 
the given two entities have some relation first and if 
they do then to classify the relation types and subtypes 
instead of combining detection and classification in 
one process. The second set of experiment is to 
examine the difference between these two 
implementations. Against our expectation, the 
sequence implementation does better than the 
combination implementation, but not significantly, as 
shown in Table 4 below.  
Type / Subtype Precision Recall F-measure 
Combination 0.7733/0.7485 0.5506/0.5301 0.6432/0.6206
Sequence 0.7374/0.7151 0.5860/0.5683 0.6530/0.6333
Table 4 Evaluation of Two Detection and Classification Modes 
Based on the sequence implementation, we set up 
the third set of experiments to examine the correction 
and inference mechanisms. The results are illustrated 
in Table 5. The correction with constraints and 
consistency check is clearly contributing. It improves 
F-measure 7.40% and 6.47% in type and subtype 
classification respectively. We further compare four 
possible consistency check strategies in Table 6 and 
find that the strategies using subtypes to determine or 
select types perform better than top down strategies. 
This can be attributed to the fact that correction with 
relation/argument constraints in subtype is tighter than 
the ones in type.  
Type / Subtype Precision Recall F-measure 
Seq. + Cor. 0.8198/0.7872 0.6127/0.5883 0.7013/0.6734
Seq. + Cor. + Inf. 0.8167/0.7832 0.6170/0.5917 0.7029/0.6741
Table 5 Evaluation of Correction and Inference Mechanisms 
Type / Subtype Precision Recall F-measure 
Guiding Top-Down 0.7644/0.7853 0.6074/0.5783 0.6770/0.6661
Subtype Selection 0.8069/0.7738 0.6065/0.5817 0.6925/0.6641
Strictly Bottom-Up 0.8120/0.7798 0.6146/0.5903 0.6996/0.6719
Type Selection 0.8198/0.7872 0.6127/0.5883 0.7013/0.6734
Table 6 Comparison of Different Consistency Check Strategies 
Finally, we provide our findings from the fourth set 
of experiments which looks at the detailed 
contributions from four feature types. Entity type 
features themselves do not work. We incrementally 
add the structures, the external contexts and internal 
contexts, Uni-grams and Bi-grams, and at last the 
word lists on them. The observations are: Uni-grams 
provide more discriminative information than 
Bi-grams; external context seems more useful than 
internal context; positional structure provides stronger 
support than other individual recognized features such 
as entity type and context; but word list feature can not 
further boost the performance.  
Type / Subtype Precision Recall F-measure 
Entity Type + Structure 0.7288/0.6902 0.4876/0.4618 0.5843/0.5534
+ External (Uni-) 0.7935/0.7492 0.5817/0.5478 0.6713/0.6321
+ Internal (Uni-) 0.8137/0.7769 0.6113/0.5836 0.6981/0.6665
+ Bi- (Internal & External) 0.8144/0.7828 0.6141/0.5902 0.7002/0.6730
+ Wordlist 0.8167/0.7832 0.6170/0.5917 0.7029/0.6741
Table 6 Evaluation of Feature and Their Combinations 
5 Conclusion 
In this paper, we study feature-based Chinese relation 
extraction. The proposed approach is effective on the 
ACE 2005 data set. Unfortunately, there is no result 
reported on the same data so that we can compare. 
6 Appendix: Nine Positional Structures  
 
Acknowledgments 
This work was supported by HK RGC (CERG PolyU5211/05E) 
and China NSF (60603027). 
References 
Razvan Bunescu and Raymond Mooney. 2005. A Shortest Path 
Dependency Tree Kernel for Relation Extraction, In Proceedings of 
HLT/EMNLP, pages 724-731.  
Aron Culotta and Jeffrey Sorensen. 2004. Dependency Tree Kernels for 
Relation Extraction, in Proceedings of ACL, pages 423-429. 
Jing Jiang, Chengxiang Zhai. 2007. A Systematic Exploration of the 
Feature Space for Relation Extraction. In proceedings of 
NAACL/HLT, pages 113-120. 
Nanda Kambhatla. 2004. Combining Lexical, Syntactic, and Semantic 
Features with Maximum Entropy Models for Extracting Relations. 
In Proceedings of ACL, pages 178-181.  
Dmitry Zelenko, Chinatsu Aone and Anthony Richardella. 2003. 
Kernel Methods for Relation Extraction. Journal of Machine 
Learning Research 3:1083-1106 
Min Zhang, Jie Zhang, Jian Su and Guodong Zhou. 2006. A Composite 
Kernel to Extract Relations between Entities with both Flat and 
Structured Features, in Proceedings of COLING/ACL, pages 
825-832. 
GuoDong Zhou, Jian Su, Jie Zhang, and Min Zhang. 2005. Exploring 
Various Knowledge in Relation Extraction. In Proceedings of ACL, 
pages 427-434. 
GuoDong Zhou, Min Zhang, Donghong Ji and Qiaoming Zhu. 2007. 
Tree Kernel-based Relation Extraction with Context-Sensitive 
Structured Parse Tree Information. In Proceedings of EMNLP, 
pages 728-736. 
Wanxiang Che et al 2005. Improved-Edit-Distance Kernel for Chinese 
Relation Extraction. In Proceedings of IJCNLP, pages 132-137. 
92
Proceedings of the ACL 2010 Conference Short Papers, pages 120?125,
Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational Linguistics
Event-based Hyperspace Analogue to Language for Query Expansion
Tingxu Yan
Tianjin University
Tianjin, China
sunriser2008@gmail.com
Tamsin Maxwell
University of Edinburgh
Edinburgh, United Kingdom
t.maxwell@ed.ac.uk
Dawei Song
Robert Gordon University
Aberdeen, United Kingdom
d.song@rgu.ac.uk
Yuexian Hou
Tianjin University
Tianjin, China
yxhou@tju.edu.cn
Peng Zhang
Robert Gordon University
Aberdeen, United Kingdom.
p.zhang1@rgu.ac.uk
Abstract
Bag-of-words approaches to information
retrieval (IR) are effective but assume in-
dependence between words. The Hy-
perspace Analogue to Language (HAL)
is a cognitively motivated and validated
semantic space model that captures sta-
tistical dependencies between words by
considering their co-occurrences in a sur-
rounding window of text. HAL has been
successfully applied to query expansion in
IR, but has several limitations, including
high processing cost and use of distribu-
tional statistics that do not exploit syn-
tax. In this paper, we pursue two methods
for incorporating syntactic-semantic infor-
mation from textual ?events? into HAL.
We build the HAL space directly from
events to investigate whether processing
costs can be reduced through more careful
definition of word co-occurrence, and im-
prove the quality of the pseudo-relevance
feedback by applying event information
as a constraint during HAL construction.
Both methods significantly improve per-
formance results in comparison with orig-
inal HAL, and interpolation of HAL and
relevance model expansion outperforms
either method alone.
1 Introduction
Despite its intuitive appeal, the incorporation of
linguistic and semantic word dependencies in IR
has not been shown to significantly improve over
a bigram language modeling approach (Song and
Croft, 1999) that encodes word dependencies as-
sumed from mere syntactic adjacency. Both the
dependence language model for IR (Gao et al,
2004), which incorporates linguistic relations be-
tween non-adjacent words while limiting the gen-
eration of meaningless phrases, and the Markov
Random Field (MRF) model, which captures short
and long range term dependencies (Metzler and
Croft, 2005; Metzler and Croft, 2007), con-
sistently outperform a unigram language mod-
elling approach but are closely approximated by
a bigram language model that uses no linguis-
tic knowledge. Improving retrieval performance
through application of semantic and syntactic in-
formation beyond proximity and co-occurrence
features is a difficult task but remains a tantalising
prospect.
Our approach is like that of Gao et al (2004)
in that it considers semantic-syntactically deter-
mined relationships between words at the sentence
level, but allows words to have more than one
role, such as predicate and argument for differ-
ent events, while link grammar (Sleator and Tem-
perley, 1991) dictates that a word can only sat-
isfy one connector in a disjunctive set. Compared
to the MRF model, our approach is unsupervised
where MRFs require the training of parameters us-
ing relevance judgments that are often unavailable
in practical conditions.
Other work incorporating syntactic and linguis-
tic information into IR includes early research by
(Smeaton, O?Donnell and Kelledy, 1995), who
employed tree structured analytics (TSAs) resem-
bling dependency trees, the use of syntax to de-
tect paraphrases for question answering (QA) (Lin
and Pantel, 2001), and semantic role labelling in
QA (Shen and Lapata, 2007).
Independent from IR, Pado and Lapata (2007)
proposed a general framework for the construc-
tion of a semantic space endowed with syntactic
120
information. This was represented by an undi-
rected graph, where nodes stood for words, de-
pendency edges stood for syntactical relations, and
sequences of dependency edges formed paths that
were weighted for each target word. Our work is
in line with Pado and Lapata (2007) in construct-
ing a semantic space with syntactic information,
but builds our space from events, states and attri-
butions as defined linguistically by Bach (1986).
We call these simply events, and extract them auto-
matically from predicate-argument structures and
a dependency parse. We will use this space to per-
form query expansion in IR, a task that aims to find
additional words related to original query terms,
such that an expanded query including these words
better expresses the information need. To our
knowledge, the notion of events has not been ap-
plied to query expansion before.
This paper will outline the original HAL al-
gorithm which serves as our baseline, and the
event extraction process. We then propose two
methods to arm HAL with event information: di-
rect construction of HAL from events (eHAL-1),
and treating events as constraints on HAL con-
struction from the corpus (eHAL-2). Evaluation
will compare results using original HAL, eHAL-
1 and eHAL-2 with a widely used unigram lan-
guage model (LM) for IR and a state of the art
query expansion method, namely the Relevance
Model (RM) (Lavrenko and Croft, 2001). We also
explore whether a complementary effect can be
achieved by combining HAL-based dependency
modelling with the unigram-based RM.
2 HAL Construction
Semantic space models aim to capture the mean-
ings of words using co-occurrence information
in a text corpus. Two examples are the Hyper-
space Analogue to Language (HAL) (Lund and
Burgess, 1996), in which a word is represented
by a vector of other words co-occurring with it
in a sliding window, and Latent Semantic Anal-
ysis (LSA) (Deerwester, Dumais, Furnas, Lan-
dauer and Harshman, 1990; Landauer, Foltz and
Laham, 1998), in which a word is expressed as
a vector of documents (or any other syntacti-
cal units such as sentences) containing the word.
In these semantic spaces, vector-based represen-
tations facilitate measurement of similarities be-
tween words. Semantic space models have been
validated through various studies and demonstrate
compatibility with human information processing.
Recently, they have also been applied in IR, such
as LSA for latent semantic indexing, and HAL for
query expansion. For the purpose of this paper, we
focus on HAL, which encodes word co-occurrence
information explicitly and thus can be applied to
query expansion in a straightforward way.
HAL is premised on context surrounding a word
providing important information about its mean-
ing (Harris, 1968). To be specific, an L-size
sliding window moves across a large text corpus
word-by-word. Any two words in the same win-
dow are treated as co-occurring with each other
with a weight that is inversely proportional to their
separation distance in the text. By accumulating
co-occurrence information over a corpus, a word-
by-word matrix is constructed, a simple illustra-
tion of which is given in Table 1. A single word is
represented by a row vector and a column vector
that capture the information before and after the
word, respectively. In some applications, direc-
tion sensitivity is ignored to obtain a single vector
representation of a word by adding corresponding
row and column vectors (Bai et al, 2005).
w1 w2 w3 w4 w5 w6
w1
w2 5
w3 4 5
w4 3 4 5
w5 2 3 4 5
w6 2 3 4 5
Table 1: A HAL space for the text ?w1 w2 w3 w4
w5 w6? using a 5-word sliding window (L = 5).
HAL has been successfully applied to query ex-
pansion and can be incorporated into this task di-
rectly (Bai et al, 2005) or indirectly, as with the
Information Flow method based on HAL (Bruza
and Song, 2002). However, to date it has used
only statistical information from co-occurrence
patterns. We extend HAL to incorporate syntactic-
semantic information.
3 Event Extraction
Prior to event extraction, predicates, arguments,
part of speech (POS) information and syntac-
tic dependencies are annotated using the best-
performing joint syntactic-semantic parser from
the CoNNL 2008 Shared Task (Johansson and
121
Nugues, 2008), trained on PropBank and Nom-
Bank data. The event extraction algorithm then
instantiates the template REL [modREL] Arg0
[modArg0] ...ArgN [modArgN], where REL is the
predicate relation (or root verb if no predicates
are identified), and Arg0...ArgN are its arguments.
Modifiers (mod) are identified by tracing from
predicate and argument heads along the depen-
dency tree. All predicates are associated with at
least one event unless both Arg0 and Arg1 are not
identified, or the only argument is not a noun.
The algorithm checks for modifiers based on
POS tag1, tracing up and down the dependency
tree, skipping over prepositions, coordinating con-
junctions and words indicating apportionment,
such as ?sample (of)?. However, to constrain out-
put the search is limited to a depth of one (with
the exception of skipping). For example, given
the phrase ?apples from the store nearby? and an
argument head apples, the first dependent, store,
will be extracted but not nearby, which is the de-
pendent of store. This can be detrimental when
encountering compound nouns but does focus on
core information. For verbs, modal dependents are
not included in output.
Available paths up and down the dependency
tree are followed until all branches are exhausted,
given the rules outlined above. Tracing can re-
sult in multiple extracted events for one predicate
and predicates may also appear as arguments in
a different event, or be part of argument phrases.
For this reason, events are constrained to cover
only detail appearing above subsequent predicates
in the tree, which simplifies the event structure.
For example, the sentence ?Baghdad already has
the facilities to continue producing massive quan-
tities of its own biological and chemical weapons?
results in the event output: (1) has Baghdad al-
ready facilities continue producing; (2) continue
quantities producing massive; (3) producing quan-
tities massive weapons biological; (4) quantities
weapons biological massive.
4 HAL With Events
4.1 eHAL-1: Construction From Events
Since events are extracted from documents, they
form a reduced text corpus from which HAL can
1To be specific, the modifiers include negation, as well as
adverbs or particles for verbal heads, adjectives and nominal
modifiers for nominal heads, and verbal or nominal depen-
dents of modifiers, provided modifiers are not also identified
as arguments elsewhere in the event.
be built in a similar manner to the original HAL.
We ignore the parameter of window length (L)
and treat every event as a single window of length
equal to the number of words in the event. Every
pair of words in an event is considered to be co-
occurrent with each other. The weight assigned to
the association between each pair is simply set to
one. With this scheme, all the events are traversed
and the event-based HAL is constructed.
The advantage of this method is that it sub-
stantially reduces the processing time during HAL
construction because only events are involved and
there is no need to calculate weights per occur-
rence. Additional processing time is incurred in
semantic role labelling (SRL) during event iden-
tification. However, the naive approach to extrac-
tion might be simulated with a combination of less
costly chunking and dependency parsing, given
that the word ordering information available with
SRL is not utilised.
eHAL-1 combines syntactical and statistical in-
formation, but has a potential drawback in that
only events are used during construction so some
information existing in the co-occurrence patterns
of the original text may be lost. This motivates the
second method.
4.2 eHAL-2: Event-Based Filtering
This method attempts to include more statistical
information in eHAL construction. The key idea
is to decide whether a text segment in a corpus
should be used for the HAL construction, based
on how much event information it covers. Given a
corpus of text and the events extracted from it, the
eHAL-2 method runs as follows:
1. Select the events of length M or more and
discard the others for efficiency;
2. Set an ?inclusion criterion?, which decides if
a text segment, defined as a word sequence
within an L-size sliding window, contains an
event. For example, if 80% of the words in an
event are contained in a text segment, it could
be considered to ?include? the event;
3. Move across the whole corpus word-by-word
with an L-size sliding window. For each win-
dow, complete Steps 4-7;
4. For the current L-size text segment, check
whether it includes an event according to the
?inclusion criterion? (Step 2);
122
5. If an event is included in the current text
segment, check the following segments for
a consecutive sequence of segments that also
include this event. If the current segment in-
cludes more than one event, find the longest
sequence of related text segments. An illus-
tration is given in Figure 1 in which dark
nodes stand for the words in a specific event
and an 80% inclusion criterion is used.
TextSegment KSegment K+1Segment K+2Segment K+3
Figure 1: Consecutive segments for an event
6. Extract the full span of consecutive segments
just identified and go to the next available text
segment. Repeat Step 3;
7. When the scanning is done, construct HAL
using the original HAL method over all ex-
tracted sequences.
With the guidance of event information, the pro-
cedure above keeps only those segments of text
that include at least one event and discards the rest.
It makes use of more statistical co-occurrence in-
formation than eHAL-1 by applying weights that
are proportional to word separation distance. It
also alleviates the identified drawback of eHAL-1
by using the full text surrounding events. A trade-
off is that not all the events are included by the
selected text segments, and thus some syntactical
information may be lost. In addition, the paramet-
ric complexity and computational complexity are
also higher than eHAL-1.
5 Evaluation
We empirically test whether our event-based
HALs perform better than the original HAL, and
standard LM and RM, using three TREC2 col-
lections: AP89 with Topics 1-50 (title field),
AP8889 with Topics 101-150 (title field) and
WSJ9092 with Topics 201-250 (description field).
All the collections are stemmed, and stop words
are removed, prior to retrieval using the Lemur
Toolkit Version 4.113. Initial retrieval is iden-
tical for all models evaluated: KL-divergence
2TREC stands for the Text REtrieval Conference series
run by NIST. Please refer to http://trec.nist.gov/ for details.
3Available at http://www.lemurproject.org/
based LM smoothed using Dirichlet prior with ?
set to 1000 as appropriate for TREC style title
queries (Lavrenko, 2004). The top 50 returned
documents form the basis for all pseudo-relevance
feedback, with other parameters tuned separately
for the RM and HAL methods.
For each dataset, the number of feedback terms
for each method is selected optimally among 20,
40, 60, 804 and the interpolation and smoothing
coefficient is set to be optimal in [0,1] with in-
terval 0.1. For RM, we choose the first relevance
model in Lavrenko and Croft (2001) with the doc-
ument model smoothing parameter optimally set
at 0.8. The number of feedback terms is fixed at
60 (for AP89 and WSJ9092) and 80 (for AP8889),
and interpolation between the query and relevance
models is set at 0.7 (for WSJ9092) and 0.9 (for
AP89 and AP8889). The HAL-based query ex-
pansion methods add the top 80 expansion terms
to the query with interpolation coefficient 0.9 for
WSJ9092 and 1 (that is, no interpolation) for AP89
and AP8889. The other HAL-based parameters
are set as follows: shortest event length M = 5,
for eHAL-2 the ?inclusion criterion? is 75% of
words in an event, and for HAL and eHAL-2, win-
dow size L = 8. Top expansion terms are selected
according to the formula:
PHAL(tj | ? t) = HAL(tj | ? q)?
ti
HAL(ti| ? q)
where HAL(tj |?q) is the weight of tj in the com-
bined HAL vector ?q (Bruza and Song, 2002)
of original query terms. Mean Average Precision
(MAP) is the performance indicator, and t-test (at
the level of 0.05) is performed to measure the sta-
tistical significance of results.
Table 2 lists the experimental results5. It can
be observed that all the three HAL-based query
expansion methods improve performance over the
LM and both eHALs achieve better performance
than original HAL, indicating that the incorpora-
tion of event information is beneficial. In addition,
eHAL-2 leads to better performance than eHAL-
1, suggesting that use of linguistic information as
a constraint on statistical processing, rather than
the focus of extraction, is a more effective strat-
egy. The results are still short of those achieved
4For RM, feedback terms were also tested on larger num-
bers up to 1000 but only comparable result was observed.
5In Table 2, brackets show percent improvement of
eHALs / RM over HAL / eHAL-2 respectively and * and #
indicate the corresponding statistical significance.
123
Method AP89 AP8889 WSJ9092
LM 0.2015 0.2290 0.2242
HAL 0.2299 0.2738 0.2346
eHAL-1 0.2364 0.2829 0.2409
(+2.83%) (+3.32%*) (+2.69%)
eHAL-2 0.2427 0.2850 0.2460
(+5.57%*) (+4.09%*) (+4.86%*)
RM 0.2611 0.3178 0.2676
(+7.58%#) (+11.5%#) (+8.78%#)
Table 2: Performance (MAP) comparison of query
expansion using different HALs
with RM, but the gap is significantly reduced by
incorporating event information here, suggesting
this is a promising line of work. In addition, as
shown in (Bai et al, 2005), the Information Flow
method built upon the original HAL largely out-
performed RM. We expect that eHAL would pro-
vide an even better basis for Information Flow, but
this possibility is yet to be explored.
As is known, RM is a pure unigram model while
HAL methods are dependency-based. They cap-
ture different information, hence it is natural to
consider if their strengths might complement each
other in a combined model. For this purpose, we
design the following two schemes:
1. Apply RM to the feedback documents (orig-
inal RM), the events extracted from these
documents (eRM-1), and the text segments
around each event (eRM-2), where the three
sources are the same as used to produce HAL,
eHAL-1 and eHAL-2 respectively;
2. Interpolate the expanded query model by
RM with the ones generated by each HAL,
represented by HAL+RM, eHAL-1+RM and
eHAL-2+RM. The interpolation coefficient is
again selected to achieve the optimal MAP.
The MAP comparison between the original RM
and these new models are demonstrated in Ta-
ble 36. From the first three lines (Scheme 1), we
can observe that in most cases the performance
generally deteriorates when RM is directly run
over the events and the text segments. The event
information is more effective to express the infor-
mation about the term dependencies while the un-
igram RM ignores this information and only takes
6For rows in Table 3, brackets show percent difference
from original RM.
Method AP89 AP8889 WSJ9092
RM 0.2611 0.3178 0.2676
eRM-1 0.2554 0.3150 0.2555
(-2.18%) (-0.88%) (-4.52%)
eRM-2 0.2605 0.3167 0.2626
(-0.23%) (-0.35%) (-1.87%)
HAL 0.2640 0.3186 0.2727
+RM (+1.11%) (+0.25%) (+1.19%)
eHAL-1 0.2600 0.3210 0.2734
+RM (-0.42%) (+1.01%) (+2.17%)
eHAL-2 0.2636 0.3191 0.2735
+RM (+0.96%) (+0.41%) (+2.20%)
Table 3: Performance (MAP) comparison of query
expansion using the combination of RM and term
dependencies
the occurrence frequencies of individual words
into account, which is not well-captured by the
events. In contrast, the performance of Scheme 2
is more promising. The three methods outperform
the original RM in most cases, but the improve-
ment is not significant and it is also observed that
there is little difference shown between RM with
HAL and eHALs. The phenomenon implies more
effective methods may be invented to complement
the unigram models with the syntactical and sta-
tistical dependency information.
6 Conclusions
The application of original HAL to query expan-
sion attempted to incorporate statistical word as-
sociation information, but did not take into ac-
count the syntactical dependencies and had a
high processing cost. By utilising syntactic-
semantic knowledge from event modelling of
pseudo-relevance feedback documents prior to
computing the HAL space, we showed that pro-
cessing costs might be reduced through more care-
ful selection of word co-occurrences and that per-
formance may be enhanced by effectively improv-
ing the quality of pseudo-relevance feedback doc-
uments. Both methods improved over original
HAL query expansion. In addition, interpolation
of HAL and RM expansion improved results over
those achieved by either method alone.
Acknowledgments
This research is funded in part by the UK?s Engi-
neering and Physical Sciences Research Council,
grant number: EP/F014708/2.
124
References
Bach E. The Algebra of Events. 1986. Linguistics and
Philosophy, 9(1): pp. 5?16.
Bai J. and Song D. and Bruza P. and Nie J.-Y. and Cao
G. Query Expansion using Term Relationships in
Language Models for Information Retrieval 2005.
In: Proceedings of the 14th International ACM Con-
ference on Information and Knowledge Manage-
ment, pp. 688?695.
Bruza P. and Song D. Inferring Query Models by Com-
puting Information Flow. 2002. In: Proceedings of
the 11th International ACM Conference on Informa-
tion and Knowledge Management, pp. 206?269.
Deerwester S., Dumais S., Furnas G., Landauer T. and
Harshman R. Indexing by latent semantic analysis.
1990. Journal of the American Sociaty for Informa-
tion Science, 41(6): pp. 391?407.
Gao J. and Nie J. and Wu G. and Cao G. Dependence
Language Model for Information Retrieval. 2004.
In: Proceedings of the 27th Annual International
ACM SIGIR Conference on Research and Develop-
ment in Information Retrieval, pp. 170?177.
Harris Z. 1968. Mathematical Structures of Lan-
guage.. Wiley, New York.
Johansson R. and Nugues P. Dependency-based
Syntactic-semantic Analysis with PropBank and
NomBank. 2008. In: CoNLL ?08: Proceedings of
the Twelfth Conference on Computational Natural
Language Learning, pp. 183?187.
Landauer T., Foltz P. and Laham D. Introduction to La-
tent Semantic Analysis. 1998. Discourse Processes,
25: pp. 259?284.
Lavrenko V. 2004. A Generative Theory of Relevance,
PhD thesis, University of Massachusetts, Amherst.
Lavrenko V. and Croft W. B. Relevance Based Lan-
guage Models. 2001. In: SIGIR ?01: Proceedings
of the 24th Annual International ACM SIGIR Con-
ference on Research and Development in Informa-
tion Retrieval, pp. 120?127, New York, NY, USA,
2001. ACM.
Lin D. and Pantel P. DIRT - Discovery of Inference
Rules from Text. 2001. In: KDD ?01: Proceedings
of the Seventh ACM SIGKDD International Confer-
ence on Knowledge Discovery and Data Mining, pp.
323?328, New York, NY, USA.
Lund K. and Burgess C. Producing High-dimensional
Semantic Spaces from Lexical Co-occurrence.
1996. Behavior Research Methods, Instruments &
Computers, 28: pp. 203?208. Prentice-Hall, Engle-
wood Cliffs, NJ.
Metzler D. and Bruce W. B. A Markov Random Field
Model for Term Dependencies 2005. In: SIGIR ?05:
Proceedings of the 28th annual international ACM
SIGIR conference on Research and development in
information retrieval, pp. 472?479, New York, NY,
USA. ACM.
Metzler D. and Bruce W. B. Latent Concept Expan-
sion using Markov Random Fields 2007. In: SIGIR
?07: Proceedings of the 30th Annual International
ACM SIGIR Conference on Research and Develop-
ment in Information Retrieval, pp. 311?318, ACM,
New York, NY, USA.
Pado S. and Lapata M. Dependency-Based Construc-
tion of Semantic Space Models. 2007. Computa-
tional Linguistics, 33: pp. 161?199.
Shen D. and Lapata M. Using Semantic Roles to Im-
prove Question Answering. 2007. In: Proceedings
of the 2007 Joint Conference on Empirical Methods
in Natural Language Processing and Computational
Natural Language Learning, pp. 12?21.
Sleator D. D. and Temperley D. Parsing English with
a Link Grammar 1991. Technical Report CMU-CS-
91-196, Department of Computer Science, Carnegie
Mellon University.
Smeaton A. F., O?Donnell R. and Kelledy F. Indexing
Structures Derived from Syntax in TREC-3: System
Description. 1995. In: The Third Text REtrieval
Conference (TREC-3), pp. 55?67.
Song F. and Croft W. B. A General Language Model
for Information Retrieval. 1999. In: CIKM ?99:
Proceedings of the Eighth International Confer-
ence on Information and Knowledge Management,
pp. 316?321, New York, NY, USA, ACM.
125
