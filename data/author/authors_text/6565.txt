Multilingual and cross-lingual news topic tracking 
Bruno Pouliquen, Ralf Steinberger, Camelia Ignat, Emilia K?sper & Irina Temnikova
Joint Research Centre, European Commission 
T.P. 267, Via E. Fermi 1 
21020 Ispra (VA), Italy 
http://www.jrc.it/langtech 
Firstname.Lastname@jrc.it 
 
 
Abstract 
We are presenting a working system for automated 
news analysis that ingests an average total of 7600 
news articles per day in five languages. For each 
language, the system detects the major news stories 
of the day using a group-average unsupervised ag-
glomerative clustering process. It also tracks, for 
each cluster, related groups of articles published 
over the previous seven days, using a cosine of 
weighted terms. The system furthermore tracks re-
lated news across languages, in all language pairs 
involved. The cross-lingual news cluster similarity 
is based on a linear combination of three types of 
input: (a) cognates, (b) automatically detected ref-
erences to geographical place names and (c) the re-
sults of a mapping process onto a multilingual clas-
sification system. A manual evaluation showed that 
the system produces good results.  
1 Introduction 
Most large organisations, companies and politi-
cal parties have a department analysing the news 
on a daily basis. Motivations differ, but often these 
organisations want to know how they and their 
leading members are represented in the news, or 
they need to know whether there has been any 
event they ought to know about. Examples of ex-
isting news gathering and analysis systems are In-
formedia1 and the Europe Media Monitor (Best et 
al. 2002). DARPA has taken an interest in the do-
main and launched, in 1996, the Topic Detection 
and Tracking task2 (TDT) under the TIDES pro-
gram. It distinguishes three major tasks: (a) seg-
mentation of a continuous information flow (e.g. 
spoken news) into individual news items, (b) de-
tection of breaking news, i.e. of a new subject that 
has not previously been discussed, and (c) topic 
tracking, i.e. the identification of related news over 
time. Our task is the analysis of a multilingual col-
lection of written news articles, which means that 
segmentation (task a) is of no relevance. Neither 
do we present here work on the detection of new 
                                                     
1 http://www.informedia.cs.cmu.edu/ 
2 http://www.nist.gov/speech/tests/tdt/ 
topics (task b). Instead, we focus on the topic 
tracking task (c), and especially on the novel as-
pect of cross-lingual tracking.  
The aim of our work is to provide an automati-
cally generated overview over the major news of 
each day (midnight to midnight) in the languages 
English, German, French, Spanish and Italian. The 
corpus consists of news items gathered from a 
large number of internet news sites world-wide, 
and of various subscription news wires (Best et al 
2002). The texts are thus from hundreds of differ-
ent sources (feeds) which often discuss the same 
events. Newspapers often publish the news they 
receive from press agencies with no or few 
amendments. The corpus of news articles thus con-
tains not only summaries of the same events writ-
ten by different journalists, but also many dupli-
cates and near duplicates of the same original text 
which need to be eliminated from the collection.  
In order to identify the major news, we identify 
clusters of similar news items, i.e. news items that 
deal with the same subject. All subjects that trigger 
a large number of news articles from various feeds 
are of interest. The related news thus do not neces-
sarily have to discuss events, i.e. things that happen 
at a particular time and place (e.g. the 11/03 Ma-
drid bombing), but they can also be a thread of dis-
cussions on the same subject, such as the campaign 
for the US presidential elections.  
In section 2, we summarise other work on topic 
tracking, on cross-lingual news linking and on fea-
ture extraction methods. Section 3 describes the 
multilingual news corpus and the text feature ex-
traction used for the document representation. In 
section 4, we present the process and evaluation of 
major news identification. Section 5 is dedicated to 
the multi-monolingual topic tracking process and 
its evaluation. Section 6 describes the cross-lingual 
linking of related clusters of major news, plus 
evaluation results. Section 7 points to future work.  
2 Related work 
Allan et al (1998) identify new events and then 
track the topic like in an information filtering task 
by querying new documents against the profile of 
the newly detected topic. Topics are represented as 
a vector of stemmed words and their TF.IDF val-
ues, only considering nouns, verbs, adjectives and 
numbers. In their experiments, using between 10 
and 20 features produced optimal results. Schultz 
(1999) took the alternative approach of clustering 
texts with a single-linkage unsupervised agglom-
erative clustering method, using cosine similarity 
and TF.IDF for term weighting. He concludes that 
?a successful clustering algorithm must incorporate 
a representation for a cluster itself as group aver-
age clustering does?. We followed Schultz? advice. 
Unlike Schultz, however, we use the log-likelihood 
test for term weighting as this measure seems to be 
better when dealing with varying text sizes (Kil-
garriff 1996). We do not consider parts-of-speech, 
lemmatisation or stemming, as we do not have ac-
cess to linguistic resources for all the languages we 
need to work with, but we use an extensive list of 
stop words.  
Approaches to cross-lingual topic tracking are 
rather limited. Possible solutions for this task are to 
either translate documents or words from one lan-
guage into the other, or to map the documents in 
both languages onto some multilingual reference 
system such as a thesaurus. Wactlar (1999) used 
bilingual dictionaries to translate Serbo-Croatian 
words and phrases into English and using the trans-
lations as a query on the English texts to find simi-
lar texts. In TDT-3, only four systems tried to es-
tablish links between documents written in differ-
ent languages. All of them tried to link English and 
Chinese-Mandarin news articles by using Machine 
Translation (e.g. Leek et al 1999). Using a ma-
chine translation tool before carrying out the topic 
tracking resulted in a 50% performance loss, com-
pared to monolingual topic tracking.  
Friburger & Maurel (2002) showed that the iden-
tification and usage of proper names, and espe-
cially of geographical references, significantly im-
proves document similarity calculation and cluster-
ing. Hyland et al (1999) clustered news and de-
tected topics exploiting the unique combinations of 
various named entities to link related documents. 
However, according to Friburger & Maurel (2002), 
the usage of named entities alone is not sufficient.  
Our own approach to cross-lingual topic track-
ing, presented in section 6, is therefore based on 
three kinds of information. Two of them exploit 
the co-occurrence of named entities in related news 
stories: (a) cognates (i.e. words that are the same 
across languages, including names) and (b) geo-
graphical references. The third component, (c) a 
process mapping texts onto a multilingual classifi-
cation scheme, provides an additional, more con-
tent-oriented similarity measure. Pouliquen et al 
(2003) showed that mapping texts onto a multilin-
gual classification system can be very successful 
for the task of identifying document translations. 
This approach should thus also be an appropriate 
measure to identify similar documents in other 
languages, such as news discussing the same topic. 
3 Feature extraction for document represen-
tation 
The similarity measure for monolingual news 
item clustering, discussed in section 4, is a cosine 
of weighted terms (see 3.1) enriched with informa-
tion about references to geographical place names 
(see 3.2).  Related news are tracked over time by 
calculating the cosine of their cluster representa-
tions, while setting certain thresholds (section 5). 
The cross-lingual linking of related clusters, as de-
scribed in section 6, additionally uses the results of 
a mapping process onto a multilingual classifica-
tion scheme (see 3.3).  
The news corpus consists of a daily average of 
3350 English news items, 2100 German, 870 Ital-
ian, 800 French and 530 Spanish articles, coming 
from over three hundred different internet sources.  
3.1 Keyword identification 
For monolingual applications, we represent 
documents by a weighted list of their terms. For 
the weighting, we use the log-likelihood test, 
which is said to perform better than the alternatives 
TF.IDF or chi-square when comparing documents 
of different sizes (Kilgarriff 1996). The reference 
corpus was produced with documents of the same 
type, i.e. news articles. It is planned to update the 
reference word frequency list daily or weekly so as 
to take account of the temporary news bias towards 
specific subjects (e.g. the Iraq war). We set the p-
value to 0.01 in order to limit the size of the vector 
to the most important words. Furthermore, we use 
a large list of stop words that includes not only 
function words, but also many other words that are 
not useful to represent the contents of a document. 
We do not consider part-of-speech information and 
do not carry out stemming or lemmatisation, in 
order to increase the speed of the process and to be 
able to include new languages quickly even if we 
do not have linguistic resources for them. Cluster-
ing results do not seem to suffer from this lack of 
linguistic normalisation, but when we extend the 
system to more highly inflected languages, we will 
have to see whether lemmatisation will be neces-
sary. The result of the keyword identification proc-
ess is thus a representation of each incoming news 
article in a vector space.  
3.2 Geographical Place Name Recognition 
For place name recognition, we use a system that 
has been developed by Pouliquen et al (2004). 
Compared to other named entity recognition sys-
tems, this tool has the advantage that it recognises 
exonyms (foreign language equivalences, e.g. Ven-
ice vs. Venezia) and that it disambiguates between 
places with the same name (e.g. Paris in France vs. 
the other 13 places called Paris in the world). 
However, instead of using the city and region 
names as they are mentioned in the article, each 
place name simply adds to the country score of 
each article. The idea behind this is that the place 
names themselves are already contained in the list 
of keywords. By adding the country score sepa-
rately, we heighten the impact of the geographical 
information on the clustering process.  
The country scores are calculated as follows: for 
each geographical place name identified for a 
given country, we add one to the country counter. 
We then normalise this value using the log-
likelihood value, using the average country counter 
in a large number of other news articles as a refer-
ence base. As with keywords, we plan to update 
the country counter reference frequency list on a 
daily or weekly basis. The resulting normalised 
country score has the same format as the keyword 
list so that it can simply be added to the document 
vector space representation.  
3.3 Mapping documents onto a multilingual 
classification scheme 
For the semantic mapping of news articles, we 
use an existing system developed by Pouliquen et 
al. (2003), which maps documents onto a multilin-
gual thesaurus called Eurovoc. Eurovoc is a wide-
coverage classification scheme with approximately 
6000 hierarchically organised classes. Each of the 
classes has exactly one translation in the currently 
22 languages for which it exists. The system car-
ries out category-ranking classification using Ma-
chine Learning methods. In an inductive process, it 
builds a profile-based classifier by observing the 
manual classification on a training set of docu-
ments with only positive examples. The outcome 
of the mapping process is a ranked list of the 100 
most pertinent Eurovoc classes. Due to the multi-
lingual nature of Eurovoc, this representation is 
independent of the text language so that it is very 
suitable for cross-lingual document similarity cal-
culation, as was shown by Pouliquen et al (2003).  
4 Clustering of news articles 
In this process, larger groups of similar articles 
are grouped into clusters. Unlike in document clas-
sification, clustering is a bottom-up, unsupervised 
process, because the document classes are not 
known beforehand. 
4.1 Building a dendrogram 
In the process, we build a hierarchical clustering 
tree (dendrogram), using an agglomerative algo-
rithm (Jain et al 1999). In a first step, (1) we cal-
culate the similarity between each document pair 
in the collection (i.e. one full day of news in one 
language), applying the cosine formula to the 
document vector pairs. The vector for each single 
document consists of its keywords and their log-
likelihood values, enhanced with the country pro-
file as described in sections 3.1 and 3.2. (2) When 
two or more documents have a cosine similarity of 
90% or more, we eliminate all but one of them as 
we assume that they are duplicates or near-
duplicates, i.e. they are exact copies or slightly 
amended versions of the same news wire. (3) We 
then combine the two most similar documents into 
a cluster, for which we calculate a new representa-
tion by merging the two vectors into one. For the 
node combining the two documents, we also have 
an intra-cluster similarity value showing the degree 
to which the two documents are similar. For the 
rest of the clustering process, this node will be 
treated like a single document, with the exception 
that it will have twice the weight of a single docu-
ment when being merged with another document 
or cluster of documents. We iteratively repeat steps 
(1) and (3) so as to include more and more docu-
ments into the binary dendrogram until all docu-
ments are included. The resulting dendrogram will 
have clusters of articles that are similar, and a list 
of keywords and their weight for each cluster. The 
degree of similarity for each cluster is shown by its 
intra-cluster similarity value.  
4.2 Cluster extraction to identify main events 
In a next step, we search the dendrogram for the 
major news clusters of the day, by identifying all 
sub-clusters of documents that fulfil the following 
conditions: (a) the intra-cluster similarity (cluster 
cohesiveness) is above the threshold of 50%; (b) 
the number X of articles in the cluster is at least 
0.6% of the total number of articles of that lan-
guage per day; (c) the number Y of different feeds 
is at least half the minimum number of articles per 
cluster (Y = X/2).  
The threshold of 50% in (a) was chosen because 
it guarantees that most related articles are included 
in the cluster, while unrelated ones are mostly ex-
cluded (see section 4.3). The minimum number of 
articles per cluster in (b) was chosen to limit the 
number of major news clusters per day. We re-
quested a minimum number of different news 
feeds (c) so as to be sure that the news items are of 
general interest and that we are not dealing with 
some newspaper-specific or local issues.  
With the current settings, the system produces an 
average of 9 English major news clusters per day, 
11 Italian, 16 German, 20 French and 21 Spanish. 
The varying numbers indicate that the settings 
should probably be changed so as to produce a 
similar number of major news clusters per day in 
the various languages. Most likely, the minimum 
number of feeds should have an upper maximum 
value for languages like English with thousands of 
news articles per day.  
For each cluster, we have the following informa-
tion: number of articles, number of sources (feeds), 
intra-cluster similarity measure and keywords. Us-
ing our group-average approach we also have the 
centroid of the cluster (i.e. the vector of features 
that represents the cluster). For each cluster, we 
compute the article that is most similar to the cen-
troid (short: the centroid article). We use the title 
of this centroid article as the title for the cluster 
and we present this article to the users as a first 
document to read about the contents of the whole 
cluster.  
The collection of clusters is mainly presented to 
the users as a flat and independent list of clusters. 
However, as we realised that some of the clusters 
are more related than others (e.g. with the recent 
interest in Iraq, there are often various clusters 
covering different aspects of the political situation 
of the country), we position clusters with an inter-
cluster similarity of over 30% closer to each other 
when presenting them to the users.  
4.3 Evaluation of the monolingual clustering 
The evaluation of clustering results is rather 
tricky. According to Joachims (2003), clustering 
results can be evaluated using a variety of different 
ways: (a) let the market decide (select the winner); 
(b) ask end users; (c) measure the ?tightness? or 
?purity? of clusters; (d) use human-identified clus-
ters to evaluate system-generated ones. The last 
solution (d) is out of our reach because it is very 
resource-consuming; several evaluators would be 
needed for cross-checking the human judgement. 
The ?market? (a) and user groups (b) will use and 
evaluate our system in the near future, but we need 
to evaluate the system prior to showing it to a large 
number of customers. We therefore focus on 
method (c) by letting a person judge how consis-
tently the articles of each cluster treat the same 
story.  
We evaluated the major clusters of English news 
articles (using the 50% intra-cluster similarity 
threshold) produced for the seven-day period start-
ing 9 March 2004. During this period, 71 clusters 
containing 1072 news articles were produced. The 
evaluator was asked to decide, for each cluster and 
on a four-grade scale, to what extent the clustered 
articles were related to the centroid article. Com-
paring the clustered articles to the centroid article 
was chosen over evaluating the homogeneity of the 
cluster because it is both easier and closer to the 
real-life situation of the users: users will enter the 
cluster via the centroid article and will judge the 
other articles according to whether or not they con-
tain the information they expect. The evaluation 
scale distinguishes the following ratings:  
 
(0) wrong link, e.g. Madrid football results vs. 
Madrid elections; this is a hypothetical exam-
ple as no such link was found.  
(1) loosely connected story, e.g. Welsh documen-
tary on drinking vs. alcohol policy in Britain; 
(2) interlinked news stories, e.g. 11/03 Madrid 
bombing vs. elections of the Spanish Prime 
Minister Zapatero vs. Spanish decision to pull 
troops out of Iraq; 
(3) same news story. 
 
In the evaluation, 91.5% of the articles were 
rated as good (3), 7.7% were rated as interlinked 
(2) and 0.8% were rated as loosely connected. No 
wrong links were found. 47 of the 71 clusters only 
contained good articles (3). Loosely connected ar-
ticles (1) were distributed evenly. No more than 
two  articles of this rating were found in a single 
cluster. They never amounted to more than 17% of 
all articles in a cluster (2 out of 12 articles).  
An evaluation of the clusters produced on one 
day?s data with 30% and 40% intra-cluster similar-
ity thresholds showed that the performance de-
creased drastically. In 30%-clusters, we found sev-
eral wrong links (category 0), while no such wrong 
links were found in the 50%-clusters. The total 
number of wrong (0) or loosely connected (1) arti-
cles went up from one (in the 50%-cluster for that 
day) to 37. Furthermore, the worst clusters con-
tained over 50% of such unrelated articles. The 
40%-clusters were of a slightly better quality, but 
they still were clearly less good than the 50%-
clusters: The percentage of wrong (0) and loosely 
connected (1) articles only went up from 0.8% (in 
the 50%-clusters) to 4%, but some of the 40%-
clusters still had more bad (category 0 or 1) than 
good (category 2 or 3) articles. These numbers 
confirm that our choice of the 50% intra-cluster 
similarity threshold is most useful. 
We have not produced a quantitative evaluation 
of the miss rate of the clustering process (i.e. the 
number of related articles not included in the clus-
ter, showing the recall). However, a full-text 
search of the relevant proper names in the rest of 
the news collection showed that the clustering 
process missed very few related articles. In any 
case, from our users? point of view, it is much 
more important to know the major news stories of 
a specific day than being able to access all articles 
on the subject.  
Statistical evaluation showed no correlation be-
tween cluster size and accuracy. However, cate-
gory (2) results were more frequently found in 
clusters pertaining to news stories that go on for a 
long time, such as the US presidential elections. 
These stories get wide coverage without being 
?breaking news?, and many of the articles involved 
are commentaries. Some of the category (2) results 
were also found in stories around the Madrid 
bombing and its consequences: some articles dis-
cussed the bombing itself on 11 March (number of 
dead, investigation, mourning); others discussed 
the fact that, in the 14 March elections, the Spanish 
people elected the socialists as they felt that former 
Prime Minister Aznar?s politics were partially re-
sponsible for this tragedy; yet other articles dis-
cussed the post-election consequences such as the 
decision of the new Socialist government to pull 
out the Spanish troops from Iraq, etc. Many of the 
articles touched upon several of these issues. Arti-
cles were rated as good (3) if they had at least one 
core topic in common with the centroid article.  
5 Monolingual linking of news over time 
Establishing automatic links between the major 
clusters of news published in one language in the 
last 24 hours and the news published in previous 
days can help users in their analysis of events. Es-
tablishing historical links between related news 
stories is the third of the TDT tasks (see the intro-
duction in section 1).  
We track topics by calculating the cosine simi-
larity between all major news clusters of one day 
with all major news clusters of the previous days, 
currently up to a maximum distance of seven days. 
The input for the similarity calculation is the clus-
ter vector produced by the monolingual clustering 
process (see section 4.2). The output for each pair-
wise similarity calculation is a similarity value be-
tween 0 and 1. Whether we decide that two clusters 
are related or not depends on the similarity thresh-
old we set. We found that related clusters over time 
have an extremely high similarity, often around 
90%, which shows that the vocabulary used in 
news stories over time changes very little. For test-
ing purposes, we set the threshold very low, at 
15%, so that we could determine a useful threshold 
during the evaluation process.  
5.1 Evaluation of historical linking 
We evaluated the historical links for the 136 
English clusters of major news produced for the 
two-week period starting on 9 March 2004, look-
ing at the seven-day window preceding the day for 
which each major news cluster was identified. The 
total number of historical links found for this pe-
riod is 228, i.e. on average 1.68 historical links per 
major news cluster. However, for 42 of the 136 
major news clusters, the system did not find any 
related news clusters with a similarity of 15% or 
more.  
We made a binary distinction between ?closely 
related articles? (+) and ?unrelated, or not so re-
lated articles? (?).The evaluation results at varying 
cosine similarity thresholds, displayed in Table 1, 
show that there is no threshold which includes all 
good clusters and excludes all bad ones. Setting the 
threshold at 40% would mean that 173 (135+24+ 
14) of the 203 good clusters (86%) would be found 
while three bad ones would also be shown to the 
user. Setting the threshold at the more inclusive 
level of 20% would mean that 199 of the 203 good 
clusters (98%) would be found, but the number of 
unrelated ones would increase to 17.  
 
Similarity + Related  ? Unrelated 
15 ? 19% 4 8 
20 ? 39% 26 14 
40 ? 59% 14 2 
60 ? 79% 24 0 
80 ? 100% 135 1 
Total 203 25 
Table 1: Evaluation, for varying similarity thresh-
olds, of the automatically detected links between 
major news of the day and the major news pub-
lished in the seven days before. The distinction 
was binary: Related (+) or Not (so) related (?). 
6 Cross-lingual linking of news clusters 
News analysts and employees in press rooms 
and public relations departments often want to see 
how the same news is discussed in different coun-
tries. To allow easy access to related news in other 
languages, we establish cross-lingual links between 
the clusters of major news stories. As major news 
in one country sometimes is only minor news in 
another, we calculate a second, alternative group of 
news clusters for each language and each day, con-
taining a larger number of smaller clusters. To get 
this alternative group of clusters, we set the intra-
cluster similarity to 25% and require that the news 
of the cluster come from at least two different 
news sources. These conditions are much weaker 
than the requirements described in section 4.2. For 
each major news cluster (50% intra-cluster similar-
ity) per day and per language, we thus try to find 
related news in the other languages among any of 
the smaller clusters produced with the 25% intra-
cluster similarity requirement.  
We use three types of input for the calculation of 
cross-lingual cluster similarity: (a) the vector of 
keywords, as described in section 3.1, not en-
hanced with geographical information, (b) the 
country score vector, as described in section 3.2, 
and (c) the vector of Eurovoc descriptors, as de-
scribed in section 3.3. The impact of the three 
components is currently set to 20%, 30% and 50% 
respectively. Using the Eurovoc vector alone 
would give very high similarity values for, say, 
news about elections in France and in the United 
States. By adding the country score, a considerable 
weight in the cross-lingual similarity calculation is 
given to the countries that are mentioned in each 
news cluster. The overlap between the keyword 
vectors of documents in two different languages 
will, of course, be extremely little, but it increases 
with the number of named entities that the docu-
ments have in common. According to Gey (2000), 
30% of content-bearing words in journalistic text 
are proper names.  
The system ignores individual articles, but calcu-
lates the similarity between whole clusters of the 
different languages. The country score and the 
Eurovoc descriptor vector are thus assigned to the 
cluster as a whole, treating all articles of each clus-
ter like one big bag of words. 
6.1 Evaluation of cross-lingual cluster links 
The evaluation for the cross-lingual linking was 
carried out on the same corpus as the evaluation of 
the historical links, i.e. taking the 136 English ma-
jor news clusters as a starting point. Cross-lingual 
cluster links were evaluated for two languages, 
English to French and English to Italian. The 
evaluation was again binary, i.e. clusters were ei-
ther judged as being ?closely related? (+) or ?unre-
lated, or not so related? (?). For 31 English clus-
ters, no French cluster was found. Similarly, for 32 
English clusters, no Italian cluster was found. This 
means that for almost 25% of the English-speaking 
major news stories (31/136), there was no equiva-
lent news cluster in the other languages.  
For the remaining English clusters, a total of 131 
French and 133 Italian clusters were detected by 
the system, i.e. on average more than one for each 
English cluster. However, when several related 
news clusters were found, only the one with the 
highest score was considered in the evaluation.  
Table 2 not only shows that the English-Italian 
links are less reliable than the English-French ones 
(the Italian document representation is inferior to 
the French one because we spent less effort on op-
timising the Italian keyword assignment), but also 
that the quality of cross-lingual links is generally 
lower than the historical links presented in sec-
tion 5.1. If we set the threshold for identifying re-
lated news across languages to 30%, the system 
catches 74 of the 75 good French clusters (99%) 
and 67 of the 69 Italian clusters (97%). However, 
the system then also proposes 13 bad French and 
12 bad Italian clusters to the users. Setting the 
threshold higher would decrease the number of 
wrong hits. However, we decided to use the 
threshold of 30% because we consider it important 
for users to be able to find related news in other 
languages. Furthermore, unrelated clusters are usu-
ally very easy to detect just by looking at the title 
of the cluster.  
 
Similarity FR +  FR ? IT + IT ? 
15 ? 19% 0 7 0 1 
20 ? 29% 1 6 2 11 
30 ? 39% 5 6 7 8 
40 ? 49% 16 4 13 5 
50 ? 59% 19 1 18 6 
60 ? 100% 34 1 29 1 
Total 75 25 69 32 
Table 2: Evaluation, for varying similarity thresh-
olds, of the automatically detected cross-lingual 
links between English major news and French (FR) 
or Italian (IT) news of the same day. The distinc-
tion was binary: Related (+) or Not (so) related (?). 
7 Conclusion and future work 
We have shown that our system can rather accu-
rately identify clusters of major news per day in 
five languages and that it can link these clusters to 
related news over time (topic tracking). The most 
interesting and novel feature of the system is, how-
ever, that it can also identify related news across 
languages, without translating articles or using bi-
lingual dictionaries. This cross-lingual cluster simi-
larity is achieved by a combination of three feature 
sets, which currently have an impact of 50%, 30% 
and 20%, respectively: the main feature set is the 
mapping onto the multilingual classification 
scheme Eurovoc; the others are the countries re-
ferred to in the articles (direct mention of the coun-
try, or of a smaller place name of that country) and 
the cognates (same strings used in the articles 
across languages, i.e. mainly named entities). The 
evaluation has shown that the results are good, but 
that the cross-lingual linking performs less well 
than the monolingual historical linking of related 
news clusters. Users felt that the system performs 
well enough for it to go online soon, for usage by a 
large user community of several thousand people. 
Improvements to the system will nevertheless be 
sought.  
Future work will include testing different set-
tings concerning the relative impact of the three 
components, as well as detecting and using more 
named entities such as absolute and relative date 
expressions, proper names, etc. A further aim is to 
extend the system to another six languages. 
The usage of cognate similarity could be im-
proved. Currently it will not work with Greek, for 
instance, except for a few proper names. We would 
therefore like to experiment with multi-lingual 
stemming methods to exploit the existence of simi-
lar words across languages such as English ele-
phant, French ?l?phant, Spanish and Italian ele-
fante and German Elefant.  
Several customer groups requested an advanced 
news analysis that distinguishes between articles 
about concrete events and articles commenting 
about these events. We will explore this issue, but 
it is very likely that this distinction will require a 
syntactic analysis of the news and cannot be made 
with our bag-of-words approach. 
Finally, we intend to work on breaking news de-
tection, i.e. detecting new events, as opposed to 
detecting major news. This work will require 
working on smaller time windows than the current 
24-hour window.  
8 Acknowledgements 
We would like to thank the Web Technology group 
of the Joint Research Centre for their collaboration 
and for giving us access to their valuable multilin-
gual news collection. Our special thanks goes to 
Clive Best, Erik van der Goot, Ken Blackler and 
Teofilo Garcia. We would also like to thank our 
former colleague Johan Hagman for introducing us 
to the methods and usefulness of cluster analysis.  
References  
Allan James, Ron Papka & Victor Lavrenko 
(1998). On-line New Event Detection and Track-
ing. Proceedings of the 21st Annual International 
ACM SIGIR Conference on Research and De-
velopment in Information Retrieval, pages 37-
45. Melbourne, Australia 
Best Clive, Erik van der Goot, Monica de Paola, 
Teofilo Garcia & David Horby (2002). Europe 
Media Monitor ? EMM. JRC Technical Note No. 
I.02.88. Ispra, Italy.  
Friburger N. & D. Maurel (2002). Textual Similar-
ity Based on Proper Names. Proceedings of the 
workshop Mathematical/Formal Methods in In-
formation Retrieval (MFIR?2002) at the 25th 
ACM SIGIR Conference, pp. 155-167. Tampere, 
Finland. 
Gey Frederic (2000). Research to Improve Cross-
Language Retrieval ? Position Paper for CLEF. 
In C. Peters (ed.): Cross-Language Information 
Retrieval and Evaluation, Workshop of Cross-
Language Evaluation Forum (CLEF?2000), Lis-
bon, Portugal. Lecture Notes in Computer Sci-
ence 2069, Springer. 
Hyland R., C. Clifton & R. Holland (1999). Geo-
NODE: Visualizing News in Geospatial Context. 
In Afca99. 
Jain A., M. Murty & P. Flynn (1999). Data cluster-
ing: a review. Pages 264 
Joachims Thorsten (2003). Representing and Ac-
cessing Digital Information. Available at http:// 
www.cs.cornell.edu/Courses/cs630/2003fa/lectur
es/tclust.pdf 
Kilgarriff A. (1996) Which words are particularly 
characteristic of a text? A survey of statistical 
approaches. Proceedings of the AISB Workshop 
on Language Engineering for Document Analy-
sis and Recognition. Sussex, 04/1996, pp. 33-40.  
Leek Tim, Hubert Jin, Sreenivasa Sista & Richard 
Schwartz (1999). The BBN Crosslingual Topic 
Detection and Tracking System. In 1999 TDT 
Evaluation System Summary Papers. 
http://www.nist.gov/speech/tests/tdt/tdt99/papers 
Pouliquen Bruno, Ralf Steinberger & Camelia Ig-
nat (2003). Automatic identification of document 
translations in large multilingual document col-
lections. Proceedings of the International Con-
ference Recent Advances in Natural Language 
Processing (RANLP'2003), pp. 401-408. Borov-
ets, Bulgaria, 10 - 12 September 2003. 
Pouliquen Bruno, Ralf Steinberger, Camelia Ignat 
& Tom de Groeve (2004). Geographical Infor-
mation Recognition and Visualisation in Texts 
Written in Various Languages. Proceedings of 
the 2004 ACM Symposium on Applied Comput-
ing, Session on Information Access and Retrieval 
(Nicosia, Cyprus), Volume 2 of 2, pages 1051-
1058. New York.  
Schultz J. Michael & Mark Liberman (1999). 
Topic detection and Tracking using idf-weighted 
Cosine Coefficient. DARPA Broadcast News 
Workshop Proceedings.  
Wactlar H.D. (1999). New Directions in Video In-
formation Extraction and Summarization. In 
Proceedings of the 10th DELOS Workshop, Sa-
norini, Greece, 24-25 June 1999. 
Coling 2008: Companion volume ? Posters and Demonstrations, pages 145?148
Manchester, August 2008
Online-Monitoring of Security-Related Events
Martin Atkinson, Jakub Piskorski, Bruno Pouliquen
Ralf Steinberger, Hristo Tanev, Vanni Zavarella
Joint Research Centre of the European Commission
Institute for the Protection and Security of the Citizen
Via Fermi 2749, 21027 Ispra (VA), Italy
firstname.lastname@jrc.it
Abstract
This paper presents a fully operational
real-time event extraction system which is
capable of accurately and efficiently ex-
tracting violent and natural disaster events
from vast amount of online news articles
per day in different languages. Due to the
requirement that the system must be mul-
tilingual and easily extendable, it is based
on a shallow linguistic analysis. The event
extraction results can be viewed on a pub-
licly accessible website.
1 Introduction
Gathering information about violent and natural
disaster events from online news is of paramount
importance to better understand conflicts and to
develop global monitoring systems for the auto-
matic detection of precursors for threats in the
fields of conflict and health. This paper reports
on a fully operational live event extraction system
to detect information on violent events and natural
disasters in large multilingual collections of online
news articles collected by the news aggregation
system Europe Media Monitor (Best et al, 2005),
http://press.jrc.it/overview.html.
Although a considerable amount of work on the
automatic extraction of events has been reported,
it still appears to be a lesser studied area in com-
parison to the somewhat easier tasks of named-
entity and relation extraction. Two comprehensive
examples of the current functionality and capabil-
ities of event extraction technology dealing with
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
the identification of disease outbreaks and con-
flict incidents are given in (Grishman et al, 2002)
and (King and Lowe, 2003) respectively. The most
recent trends and developments in this area are re-
ported in (Ashish et al, 2006)
In order to be capable of processing vast
amounts of textual data in real time (as in the case
of EMM)we follow a linguistically lightweight ap-
proach and exploit clustered news at various pro-
cessing stages (pattern learning, information fu-
sion, geo-tagging, etc.). Consequently, only a tiny
fraction of each text is analysed. In a nutshell, our
system deploys simple 1 and 2-slot extraction pat-
terns to identify event-relevant entities. These pat-
terns are semi-automatically acquired in a boot-
strapping manner by using clustered news data.
Next, information about events scattered over dif-
ferent documents is integrated by applying voting
heuristics. The results of the core event extraction
system are integrated into a real-world global mon-
itoring system. Although we mainly cover the se-
curity domain, the techniques deployed in our sys-
tem can be applied to other domains, such as for
instance tracking business-related events for risk
assessment.
In the remaining part of this paper we give a
brief overview of the real-time event extraction
processing chain and describe the particularities of
selected subcomponents. Finally, the online appli-
cation is presented.
2 Real-time Event Extraction Process
The real-time event extraction processing chain is
depicted in Figure 1. First, news articles are gath-
ered by dedicated software for electronic media
monitoring, namely the EMM system (Best et al,
2005). EMM receives an average of 50,000 news
articles per day from about 1,500 news sources in
145
over 40 languages, and regularly checks for up-
dates of news. Secondly, the input data is grouped
into news clusters ideally including documents
on one topic or event. Then, clusters describing
security-related events are selected using keyword-
based heuristics. For each such cluster, the system
tries to detect and extract only the main event by
analysing all documents in the cluster.
EMM
News
Clustering / 
Geo Tag
Text Pre-
Processing 
Pattern 
Matching
Information 
Aggregation 
Events
NEXUS
Figure 1: Real-time processing chain.
Next, each cluster is processed by our core event
extraction engine. For each detected violent event,
it produces a frame, whose main slots are: date and
location, number of killed, injured or kidnapped
people, actors, type of event, weapons used, etc.
In an initial step, each document in the cluster
is linguistically pre-processed in order to produce
a more abstract representation of the texts. This
encompasses: fine-grained tokenisation, sentence
splitting, matching of known named entities, la-
belling of key terms and phrases like action words
(e.g. kill, shoot) and person groups.
Once texts are grouped into clusters and lin-
guistically pre-processed, the pattern engine ap-
plies a cascade of extraction grammars (consisting
of 1 and 2-slot extraction patterns) on each docu-
ment within a cluster. For creating extraction pat-
terns, we apply a blend of machine learning and
knowledge-based techniques. The extraction pat-
terns are matched against the first sentence and the
title of each article from the cluster. By processing
only the top sentence and the title, the system is
more likely to capture facts about the most impor-
tant event in the cluster. Even if we fail to detect
a single piece of information in one document in a
cluster, the same information is likely to be found
in another document of the cluster, where it may
be expressed in a different way.
Finally, since information about events is scat-
tered over different articles, the last step con-
sists of cross-document cluster-level information
fusion, i.e., we aggregate and validate information
extracted locally from each single article in the
same cluster. For this purpose, simple voting-like
heuristics are deployed.
Every ten minutes, EMM clusters the articles
found during the last four hours. The event extrac-
tion engine analyses each of these clusters. The
event information is thus always up-to-date. The
output of the event extraction engine constitutes
the input for a global monitoring system.
3 Geo-tagging Clusters
Challenges for geo-tagging clusters are that place
names can be homographic with person names and
with other place names. We solve the former am-
biguity by first identifying person names found
in our automatically populated database of known
people and organisations. For the latter ambiguity,
we adopted a cluster-centric approach by weight-
ing all place names found in a cluster and by select-
ing the one with the highest score. For each cluster,
we thus first establish all possible candidate loca-
tions by looking up in the texts all place, province,
region and country names found in a multilingual
gazetteer (including name variants). The weights
of the locations are then based on the place name
significance (e.g., a capital city scores higher than
a village) and on the place name hierarchy (i.e. if
the province or region to which the place belongs
are also mentioned in the text, it scores higher).
4 Pattern Acquisition
For pattern acquisition, we deploy a weakly super-
vised bootstrapping algorithm (Tanev and Oezden-
Wennerberg, 2008) similar in spirit to the one de-
scribed in (Yangarber, 2003), which involves some
manual validation. Contrary to other approaches,
the learning phase exploits the knowledge to which
cluster the news items belong. Intuitively, this
guarantees better precision of the learned patterns.
In particular, for each event-specific semantic role
(e.g. killed), a separate cycle of learning iterations
is executed (usually up to three) in order to learn
1-slot extraction patterns. Each cluster includes ar-
ticles from different sources about the same news
story. Therefore, we assume that each entity ap-
pears in the same semantic role (actor, victim, in-
jured) in the context of one cluster. An auto-
matic procedure for syntactic expansion comple-
ments the learning. This procedure accepts a man-
ually provided list of words which have identical
(or similar) syntactic usage patterns (e.g. killed,
assassinated, murdered, etc.). It then generates
new patterns from the old ones by substituting for
each other the words in the list. After 1-slot pat-
terns are acquired, some of them are used to man-
ually create 2-slot patterns like X shot Y.
146
5 Pattern matching engine
In order to guarantee that massive amounts of tex-
tual data can be processed in real time, we have
developed ExPRESS (Piskorski, 2007), an effi-
cient extraction pattern engine, which is capable of
matching thousands of patterns against MB-sized
texts within seconds. The pattern specification lan-
guage is a blend of two previously introduced IE-
oriented grammar formalisms, namely JAPE used
in GATE (Cunningham et al, 2000) and XTDL,
used in SPROUT (Dro?zd?zy?nski et al, 2004).
A single pattern is a regular expression over flat
feature structures (FS), i.e., non-recursive typed
feature structures without structure sharing, where
features are string-valued and ? unlike in XTDL
types ? are not organised in a hierarchy. Each such
regular expression is associated with a list of FSs
which constitute the output specification. Like in
XTDL, we deploy variables and functional oper-
ators for forming slot values and for establishing
contact with the ?outer world?. Further, we adapted
JAPEs feature of associating patterns with mul-
tiple actions, i.e., producing multiple annotations
(possibly nested). An empirical comparison of the
run-time behaviour of the new formalism against
the other 2 revealed that significant speed-ups can
be achieved (at least 30 times faster). ExPRESS
comes with a pool of highly efficient core linguis-
tic processing resources (Piskorski, 2008).
6 Information Aggregation
Once single pieces of information are extracted by
the pattern engine, they are merged into event de-
scriptions by applying an information aggregation
algorithm. This algorithm assumes that each clus-
ter reports at most one main event of interest. It
takes as input the text entities extracted from one
news cluster with their semantic roles and consid-
ers the sentences from which these entities are ex-
tracted. If one and the same entity has two roles as-
signed, a preference is given to the role assigned by
the most reliable group of patterns (e.g., 2-slot pat-
terns are more reliable). Another ambiguity which
has to be resolved arises from the contradictory in-
formation which news sources give about the num-
ber of victims. We use an ad-hoc heuristic for
computing the most probable estimation for these
numbers, i.e., firstly the largest group of numbers
which are close to each other is selected and sec-
ondly the number closest to the average in that
group is chosen. After this estimation is com-
puted, the system discards from each news clus-
ter all the articles whose reported victim numbers
significantly differ from the estimated numbers for
the whole cluster. Additionally, some victim arith-
metic is applied, i.e., a small taxonomy of person
classes is used to sum victim numbers (e.g., gun-
men and terrorists belong to the same class ofNon-
GovernmentalArmedGroup).
7 Event Classification
After the single pieces of information are assem-
bled into the event description, an event classifica-
tion is performed. Some of the most used event
classes are Terrorist Attack, Bombing, Shooting,
Air Attack, etc. The classification algorithm uses
a blend of keyword matching and domain spe-
cific rules. As an example, consider the following
domain-specific rule: if the event description in-
cludes named entities, which are assigned the se-
mantic role kidnapped, as well as entities which
are assigned the semantic role released, then the
type of the event is Hostage Release, rather than
Kidnapping. If the event refers to kidnapped peo-
ple and at the same time the news articles contain
words like video or videotape, then the event type
is Hostage Video Release. The second rule has a
higher priority, therefore it impedes the Hostage
Release rule to fire erroneously, when the release
of a hostage video is reported.
8 Monitoring Events
The core event extraction engine for English is
fully operational since December 2007. There are
two online applications running on top of it which
allow monitoring events. The first one is a dedi-
cated webpage using the Google Maps JavaScript
API (see Figure 2). It is publicly accessible at:
http://press.jrc.it/geo?type=event
&format=html&language=en and provides
an instant overview of what is occurring where in
the world. A small problem with this application
is that it overlays and hides events that are close to
each other.
The second application shows the same events
using the Google Earth client application. The
geo-located data is transmitted via the Keyhole
Markup Language (KML) format
1
supported di-
rectly by Google Earth.
2
The application is re-
1
http://code.google.com/apis/kml/documentation/
2
In order to run it, start Google Earth with KML:
http://press.jrc.it/geo?type=event&format=kml&language=en
147
Figure 2: Event visualisation with Google Maps
stricted to displaying at most half the globe, but
it allows expanding overlaid events.
Since it is important for stakeholders to be
quickly and efficiently informed about the type and
gravity of the event, various icons are used to rep-
resent the type or group of events visually (see Fig-
ure 3). We use general forms of icons for violent
events and specific forms of icons for natural and
man-made disasters. For violent events, the gen-
eral form represents the major consequence of the
event, except for kidnappings, where specific icons
are used. Independently of the type of event, all
icons are sized according to the damage caused,
i.e. it is dependent on the number of victims in-
volved in the event. Also, to highlight the events
with a more significant damage, a border is drawn
around the icon to indicate that a threshold of peo-
ple involved has been passed.
The online demo is available for English, Italian
and French. We are currently working on adapt-
ing the event extraction engine to other languages,
including Russian, Spanish, Polish, German and
Arabic. A more thorough description of the sys-
tem can be found in (Tanev et al, 2008; Piskorski
et al, 2008).
References
Ashish, N., D. Appelt, D. Freitag, and D. Zelenko. 2006.
Proceedings of the workshop on Event Extraction and Syn-
thesis, held in conjunction with the AAAI 2006 conference.
Menlo Park, California, USA.
Best, C., E. van der Goot, K. Blackler, T. Garcia, and
D. Horby. 2005. Europe Media Monitor. Technical Re-
port EUR 22173 EN, European Commission.
Cunningham, H., D. Maynard, and V. Tablan. 2000. JAPE: a
Java Annotation Patterns Engine (Second Edition). Tech-
nical Report, CS?00?10, University of Sheffield, Depart-
ment of Computer Science.
?
Kidnap
K
A
Arrest
R
Release
V
Video
V
Man
Made
?Violent EventUndefined Violent EventKilled Violent EventInjured Violent EventKindnapped Violent EventArrest Hostage Release VideoRelease Violent EventNo Consequneces
Man Made
Disaster
Man Made 
Fire
Man Made
Explosion
ND
!
Natural
Dister
Volcanic 
Eruption
Tsunami Earthquake Landslide
?
Avalanche Tropical
Storm
Lightning
Strike
Storm
Snow
Storm
Flood Wild Fire
Heatwave
Key to Symbols
Consequence Significance (number of people involved)
No Circle  = up to 10 Red Circle = More than 100Yellow Circle= between 10 and 100
Humanitarian
Crisis
Trial
Unclassified
Figure 3: Key to event type icons and magnitude
indicators
Dro?zd?zy?nski, W., H.-U. Krieger, J. Piskorski, U. Sch?afer,
and F. Xu. 2004. Shallow Processing with Unification
and Typed Feature Structures ? Foundations and Appli-
cations. K?unstliche Intelligenz, 2004(1):17?23.
Grishman, R., S. Huttunen, and R. Yangarber. 2002. Real-
time Event Extraction for Infectious Disease Outbreaks.
Proceedings of the Human Language Technology Confer-
ence (HLT) 2002.
King, G. and W. Lowe. 2003. An Automated Information
Extraction Tool for International Conflict Data with Per-
formance as Good as Human Coders: A Rare Events Eval-
uation Design. International Organization, 57:617?642.
Piskorski, J., H. Tanev, M. Atkinson, and E. Van der Goot.
2008. Cluster-centric Approach to News Event Extraction.
In Proceedings of MISSI 2008, Wroclaw, Poland.
Piskorski, J. 2007. ExPRESS Extraction Pattern Recogni-
tion Engine and Specification Suite. In Proceedings of the
International Workshop Finite-State Methods and Natu-
ral language Processing 2007 (FSMNLP?2007), Potsdam,
Germany.
Piskorski, J. 2008. CORLEONE ? Core Linguistic Entity
Online Extraction. Technical report 23393 EN, Joint Re-
search Centre of the European Commission, Ispra, Italy.
Tanev, H. and P. Oezden-Wennerberg. 2008. Learning to
Populate an Ontology of Violent Events (in print). In
Fogelman-Soulie, F. and Perrotta, D. and Piskorski, J. and
Steinberger, R., editor, NATO Security through Science Se-
ries: Information and Communication Security. IOS Press.
Tanev, H., J. Piskorski, and M. Atkinson. 2008. Real-
Time News Event Extraction for Global Crisis Monitor-
ing. In Proceedings of the 13
th
International Conference
on Applications of Natural Language to Information Sys-
tems (NLDB 2008, Lecture Notes in Computer Science Vol.
5039), pages 207?218. Springer-Verlag Berlin Heidelberg.
Yangarber, R. 2003. Counter-Training in Discovery of Se-
mantic Patterns. In Proceedings of the 41
st
Annual Meet-
ing of the ACL.
148
Coling 2008: Proceedings of the workshop on Multi-source Multilingual Information Extraction and Summarization, pages 49?56
Manchester, August 2008
Story tracking: linking similar news over time and across languages 
Bruno Pouliquen & Ralf Steinberger 
European Commission 
Joint Research Centre 
Via E. Fermi 2749, 21027 Ispra, Italy 
Firstname.Lastname@jrc.it 
Olivier Deguernel 
Temis S.A. 
Tour Gamma B, 193-197 rue de Bercy 
75582 Paris Cedex, France 
Olivier.Deguernel@temis.com
Abstract 
The Europe Media Monitor system 
(EMM) gathers and aggregates an aver-
age of 50,000 newspaper articles per day 
in over 40 languages. To manage the in-
formation overflow, it was decided to 
group similar articles per day and per 
language into clusters and to link daily 
clusters over time into stories. A story 
automatically comes into existence when 
related groups of articles occur within a 
7-day window. While cross-lingual links 
across 19 languages for individual news 
clusters have been displayed since 2004 
as part of a freely accessible online appli-
cation (http://press.jrc.it/NewsExplorer), 
the newest development is work on link-
ing entire stories across languages. The 
evaluation of the monolingual aggrega-
tion of historical clusters into stories and 
of the linking of stories across languages 
yielded mostly satisfying results. 
1 Introduction 
Large amounts of information are published 
daily on news web portals around the world. Pre-
senting the most important news on simple, 
newspaper-like pages is enough when the user 
wants to be informed about the latest news. 
However, such websites do not provide a long-
term view on how any given story or event de-
veloped over time. Our objective is to provide 
users with a fully automatic tool that groups in-
dividual news articles every day into clusters of 
related news and to aggregate the daily clusters 
into stories, by linking them to the related ones 
                                                 
? 2008. Licensed under the Creative Commons Attribution-
Noncommercial-Share Alike 3.0 Unported license 
(http://creativecommons.org/licenses/by-nc-sa/3.0/). Some 
rights reserved. 
identified in the previous weeks and months. In 
our jargon, stories are thus groups of articles 
talking about a similar event or theme over time. 
We work with the daily clusters computed by the 
NewsExplorer application (Pouliquen et al 
2004). For each daily cluster in currently nine-
teen languages, the similarity to all clusters pro-
duced during the previous seven days is com-
puted and a link is established if the similarity is 
above a certain threshold. It is on the basis of 
these individual links that stories are built, i.e. 
longer chains of news clusters related over time. 
The current NewsExplorer application addition-
ally identifies for all news clusters, whether there 
are related clusters in the other languages. These 
daily cross-lingual links are used to link the 
longer-lasting stories across languages. 
After a review of related work (Section  1 2), 
we will present the Europe Media Monitor 
(EMM) system and its NewsExplorer application 
(section  3). We will then provide details on the 
process to build the multi-monolingual stories 
(Section  4) and on the more recent work on link-
ing stories across languages (Section  5). Sec-
tion  6 presents evaluation results both for the 
monolingual story compilation and for the estab-
lishment of cross-lingual links. Section  7 con-
cludes and points to future work.  
2 Related work 
The presented work falls into the two fields of 
Topic Detection and Tracking and cross-lingual 
document similarity calculation.  
2.1 Topic detection and tracking (TDT) 
TDT was promoted and meticulously defined by 
the US-American DARPA programme (see 
Wayne 2000). An example explaining the TDT 
concept was that of the Oklahoma City bombing 
in 1995, where not only the bombing, but also 
the related memorial services, investigations, 
prosecution etc. were supposed to be captured. 
49
Human evaluators will often differ in their opin-
ion whether a given document belongs to a topic 
or not, especially as ?topic? can be defined 
broadly (e.g. the Iraq war and the following pe-
riod of insurgence) or more specifically. For in-
stance, the capture and prosecution of Saddam 
Hussein, individual roadside bombings and air 
strikes, or the killing of Al Qaeda leader Abu 
Musab al-Zarqawi could either be seen as indi-
vidual topics or as part of the Iraq war. This 
fuzziness regarding what is a ?topic? makes a 
formal evaluation rather difficult. Our system is 
more inclusive and will thus include all the men-
tioned sub-events into one topic (story). A sepa-
rate clustering system was developed as part of 
the EMM-NewsBrief (http://press.jrc.it/NewsBrief/), 
which produces more short-lived and thus more 
specific historical cluster links. 
2.2 Cross-lingual linking of documents 
Since 2000, the TDT task was part of the TIDES 
programme (Translingual Information Detection, 
Extraction and Summarisation), which focused 
on cross-lingual information access. The goal of 
TIDES was to enable English-speaking users to 
access, correlate and interpret multilingual 
sources of real-time information and to share the 
essence of this information with collaborators. 
The purpose of our own work includes the topic 
detection and tracking as well as the cross-
lingual aspect. Main differences between our 
own work and TIDES are that we need to moni-
tor more languages, that we are interested in all 
cross-lingual links (as opposed to targeting only 
English), and that we use different methods to 
establish cross-lingual links (see Section 5). 
All TDT and TIDES participants used either 
Machine Translation (MT; e.g. Leek et al 1999) 
or bilingual dictionaries (e.g. Wactlar 1999) for 
the cross-lingual tasks. Performance was always 
lower for cross-lingual topic tracking (Wayne 
2000). An interesting insight was formulated in 
the ?native language hypothesis? by Larkey et al
(2004), which states that topic tracking works 
better in the original language than in (ma-
chine-)translated collections. Various partici-
pants stated that the usage of named entities 
helped (Wayne 2000). Taking these insights into 
account, we always work in the source language 
and make intensive use of named entities. 
Outside TDT, an additional two approaches 
for linking related documents across languages 
have been proposed, both of which use bilingual 
vector space models: Landauer & Littman (1991) 
used bilingual Lexical Semantic Analysis and Vi-
nokourov et al (2002) used Kernel Canonical 
Correlation Analysis. These and the approaches 
using MT or bilingual dictionaries have in com-
mon that they require bilingual resources and are 
thus not easily scalable for many language pairs. 
For N languages, there are N*(N-1)/2 language 
pairs (e.g. for 20 languages, there are 190 lan-
guage pairs and 380 language pair directions). 
Due to the multilinguality requirement in the 
European Union (EU) context (there are 23 offi-
cial EU languages as of 2007), Steinberger et al 
(2004) proposed to produce an interlingual docu-
ment (or document cluster) representation based 
on named entities (persons, organisations, disam-
biguated locations), units of measurement, multi-
lingual specialist taxonomies (e.g. medicine), 
thesauri and other similar resources that may help 
produce a language-independent document repre-
sentation. Similarly to Steinberger et al (2004), 
the work described in the following sections 
equally goes beyond the language pair-specific 
approach, but it does not make use of the whole 
range of information types.  
In Pouliquen et al (2004), we showed how 
NewsExplorer links individual news clusters 
over time and across languages, but without ag-
gregating the clusters into the more compact and 
high-level representations (which we call sto-
ries). This new level of abstraction was achieved 
by exploiting the monolingual and cross-lingual 
cluster links and by adding additional filtering 
heuristics to eliminate wrong story candidate 
clusters. As a result, long-term developments can 
now be visualised in timelines and users can ex-
plore the development of events over long time 
periods (see Section  4.2). Additionally, meta-
information for each story can be compiled 
automatically, including article and cluster statis-
tics as well as lists of named entities associated 
to a given story.  
2.3 Commercial applications 
Compared to commercial or other publicly accessi-
ble news analysis and navigation applications, the 
one presented here is unique in that it is the only 
one offering automatic linking of news items re-
lated either historically or across languages. The 
news aggregators Google News 
(http://news.google.com) and Yahoo! News 
(http://news.yahoo.com/), for instance, deliver daily 
news in multiple languages, but do not link the 
found articles over time or across languages. The 
monolingual English language applications Day-
Life (http://www.daylife.com/), SiloBreaker 
(http://www.silobreaker.com/), and NewsVine 
50
Figure 1. Example of historical links between 
clusters: The graph shows the cosine similarity 
between today?s English language cluster (Final 
hole being drilled ?) and seven clusters identi-
fied during five previous days. Only clusters with 
a similarity above 0.5 will be retained. 
(http://www.newsvine.com/) do not link related news 
over time either. NewsTin (http://www.newstin.com) 
is the only one to offer more languages (ten) and to 
categorise news into a number of broad categories, 
but  they, again, do not link related news over time 
or across languages.  
3 Europe Media Monitor (EMM) & 
NewsExplorer 
EMM has been gathering multilingual news arti-
cles from many different web portals since 2002. 
It?s NewsBrief application has since displayed 
the world?s most recent news items on its public 
web servers (http://emm.jrc.it/overview.html). 
Every day, and for each of 19 languages sepa-
rately, EMM?s NewsExplorer application groups 
related articles into clusters. Clusters are com-
puted using a group average agglomerative bot-
tom-up clustering algorithm (similar to Schultz 
& Liberman 1999). Each article is represented as 
a vector of keywords with the keywords being 
the words of the text (except stop words) and 
their weight being the log-likelihood value com-
puted using word frequency lists based on sev-
eral years of news. We additionally enrich the 
vector space representation of each cluster with 
country information (see Pouliquen et al, 2004), 
based on log-likelihood-weighted, automatically 
recognised and disambiguated location and coun-
try names (see Pouliquen et al 2006).  
Each computed daily cluster consists of its 
keywords (i.e. the average log-likelihood weight 
for each word) and the title of the cluster?s me-
doid (i.e. the article closest to the centroid of the 
cluster). In addition we enrich the cluster with 
features that will be used in further processes. 
These include the cluster size, lists of persons, 
organisations, geo-locations and subject domain 
codes (see Section  5). 
When comparing two clusters in the same lan-
guage, the keywords offer a good representation 
(especially when the keywords are enriched with 
the country information). Section  5 will show 
that the additional ingredients are useful to com-
pare two clusters in different languages. 
4 Building stories enriched with meta-
information 
For each language separately and for each individ-
ual cluster of the day, we compute the cosine simi-
larity with all clusters of the past 7 days (see Fig-
ure 1). Similarity is based on the keywords associ-
ated with each cluster. If the similarity between the 
keyword vectors of two clusters is above the em-
pirically derived threshold of 0.5, clusters are 
linked. This optimised threshold was established by 
evaluating cluster linking in several languages (see 
Pouliquen et al 2004). A cluster can be linked to 
several previous clusters, and it can even be linked 
to two different clusters of the same day. 
4.1 Building stories by linking clusters over 
time 
Stories are composed of several clusters. If a new 
cluster is similar to clusters that are part of a 
story, it is likely that this new cluster is a con-
tinuation of the existing story. For the purpose of 
building stories, individual and yet unlinked clus-
ters of the previous seven days are treated like 
(single cluster) stories. If clusters have not been 
linked to within seven days, they remain individ-
ual clusters that are not part of a story. Building 
stories out of clusters is done using the following 
incremental algorithm (for a given day): 
for each cluster c  
 for each story s  
  score[s]=0; 
 for each cluster cp (linked to c) 
  if (s: story containing cp) then 
  score[s] += (1-score[s])*sim(cp,s); 
  endif 
 endfor 
 endfor 
 if (s: story having the maximum score) 
 then 
  add c to story s (with sim score[s]) 
 else // not similar to any story 
  create new story containing only c 
 endif 
endfor 
51
Lang Biggest title Keywords 
En US Airways won't pursue Delta 
forever 
United states / Doug Parker, Delta Airlines / airways, offer, emerge, 
grinstein, bid, regulatory, creditors, bankruptcy, atlanta, increased 
It Stop al massacro di balene. Il 
mondo contro il Giappone 
Australia, N. Zealand, Japan/ Greenpeace International, John Ho-
ward/ caccia, megattere, balene, sydney, acqua, mesi, antartico, salti 
Es Mayor operaci?n contra la por-
nograf?a infantil en Internet en la 
historia de Espa?a 
Guardia Civil, Fernando Herrero Tejedor / pornograf?a, imputa-
dos, mayor, cinco, delito, internet, registros, siete, inform?tica, sci 
De Australian Open: "Tommynator" 
mit Gala-Vorstellung 
Russia, Australia, United states / Australian Open, Mischa Zverev 
/ satz, tennis, deutschen, bozoljac, erstrunden, melbourne, kohl-
schreiber, Donnerstag 
Fr Il faut aider l'Afrique ? se mon-
dialiser, dit Jacques Chirac 
Jacques Chirac, African Union / afrique, sommet, continent, pr?si-
dent, cannes, darfour, ?tat, pays, conf?rence, chefs, omar 
Table 1. Examples of stories, their biggest titles and their corresponding keywords. Countries are dis-
played in italic, person and organisation names in boldface. 
with sim(cp,s) being the similarity of the cluster 
to the story (the first cluster of a story gets a sim 
of 1, the following depend on the score com-
puted by the algorithm). 
When deciding whether a new cluster should 
be part of an existing story, the challenge is to 
combine the similarities of the new cluster with 
each of the clusters in the story. As stories 
change over time and the purpose is to link the 
newest events to existing stories, the new cluster 
is only compared to the story?s clusters of the last 
7 days. A seven-day window is intuitive and 
automatically takes care of fluctuations regarding 
the number of articles during the week (week-
ends are quieter). In the algorithm to determine 
whether the new cluster is linked to the story, the 
similarity score is computed incrementally: The 
score is the similarity of the new cluster with the 
latest cluster of the story (typically yesterday?s) 
plus the similarity of the new cluster with the 
story?s cluster of the day before multiplied with a 
reducing factor (1-scorei-1), plus the similarity of 
the new cluster with the story?s cluster of yet an-
other day before multiplied with a reducing fac-
tor (1-scorei-2), etc. The reducing factor helps to 
keep the similarity score between the theoretical 
values 0 (unrelated) and 1 (highly related): 
??
?
<<??
==
? )70(),()1(
)0(0
1 iscsimscore
i
score
ii
i
 
If the final score is above the threshold of 0.5, 
the cluster gets linked to the existing story. 
Otherwise it remains unlinked. The story building 
algorithm is language-independent and could thus 
be applied to all of the 19 NewsExplorer lan-
guages. Currently, it is run every day (in 
sequential order) in the following nine languages: 
Dutch, English, French, German, Italian, 
Portuguese, Slovene, Spanish and Swedish. 
Out of the daily average of 970 new clusters 
(average computed for all nine languages over a 
period of one month), only 281 get linked to an 
existing story (29%) and 90 contribute to a new 
story (9%). The remaining 599 clusters (62%) 
remain unlinked singleton clusters. A small num-
ber of stories are very big and go on over a long 
time. This reflects big media issues such as the 
Iraq insurgence, the Iran-nuclear negotiations 
and the Israel-Palestine conflict. The latter is the 
currently longest story ever (see 
http://press.jrc.it/NewsExplorer/storyedition/en/RTERadio-
5f47a76fe35215964cbab22dcbc88d7b.html).  
4.2 Aggregating and displaying information 
about each story 
For each story, daily updated information gets 
stored in the NewsExplorer knowledge base. 
This includes (a) the title of the first cluster of 
the story (i.e. the title of the medoid article of 
that first cluster); (b) the title of the biggest clus-
ter of the story (i.e. the cluster with most arti-
cles); (c) the most frequently mentioned person 
names in the story (related people); (d) the per-
son names most highly associated to the story 
(associated people, see below); (e) the most fre-
quently mentioned other names in the story 
(mostly organisations, but also events such as 
Olympics, World War II, etc.); (f) the countries 
most frequently referred to in the story (either 
directly with the country name or indirectly, e.g. 
by referring to a city in that country); (g) a list of 
keywords describing the story (see below). This 
meta-information is exported every day into 
XML files for display on NewsExplorer. The 
public web pages display up to 13 keywords, in-
cluding up to three country names and up to two 
person or organisation names (see Table 1). To 
52
see examples of all meta-information types for 
each story, see the NewsExplorer pages.  
Stories are currently accessible through three 
different indexes (see Figure 2): the stories of the 
week, the stories of the month and the biggest 
stories (all displayed on the main page of 
NewsExplorer). The biggest stories are ordered 
by the number of clusters they contain without 
any consideration of the beginning date or the 
end date. The stories of the month present stories 
that started within the last 30 days, stories of the 
week those that started within the last seven 
days. 
For each story, a time line graph (a flash ap-
plication taking an XML export as input) is pro-
duced automatically, allowing users to see trends 
and to navigate and explore the story (Figure 3). 
While a story can have more than one cluster on 
a given day, the graph only displays the largest 
cluster for that day. 
The story?s keyword signature is computed us-
ing the keywords appearing in most of the con-
stituent clusters. If any of the keywords repre-
sents a country, it will be displayed first. A filter-
ing function eliminates keywords that are part of 
one of the selected entities. For instance, if a se-
lected entity is George W. Bush and a selected 
country is Iraq, the keywords Bush, George, 
Iraqi, etc. will not be displayed. 
 
Figure 2. Examples of English language stories, as on the NewsExplorer main page (2.04. 2008). 
As mentioned in the previous paragraph, a 
story?s related entities are those that have been 
mentioned most frequently. This typically in-
cludes many media VIPs. Associated entities are 
names that appear in this particular story, but are 
not so frequently mentioned in news clusters out-
side this story, according to the following, 
TF.IDF-like formula:  
?
?
=
Sc
i
i
ecfreSrelated ),(),(  
)),(log(1(
)1)),(min(log(
),(
),( eSC
efr
ecfr
eSass Sc
i
i +?=
?
?
with fr(e) being the number of clusters the entity 
appears in (in a collection of three years of news) 
and C(S,e) being the number of clusters in the 
story S mentioning the entity. Inversely, the 
NewsExplorer person and organisation pages 
also display, for each entity, the biggest stories 
they are involved in.  
Figure 3. Sample of a short story timeline. When
mousing over the graph, title, date and cluster
size for that day are displayed. A simple click al-
lows to jump to the relevant cluster, enabling us-
ers to explore the story. Available on page
http://press.jrc.it/NewsExplorer/storyedition/en/guardi
an-ee9f870100be631c0147646d29222de9.html.
5 Cross-lingual cluster and story linking 
For each daily cluster in nine NewsExplorer lan-
guages, the similarity to clusters in the other 18 
languages is computed. To achieve this, we pro-
duce three different language-independent vector 
representations for each cluster (for details, see 
Pouliquen et al 2004): a weighted list of Euro-
voc subject domain descriptors (eurov, available 
only for EU languages), a frequency list of per-
son and organisation names (ent), and a weighted 
list of direct or indirect references to countries 
(geo). As a fourth ingredient, we also make use 
of language-dependent keyword lists because 
even monolingual keywords sometimes match 
53
across languages due to cognate words (cog), etc. 
(e.g. tsunami, airlines, Tibet etc.). The overall 
similarity clsim for two clusters c? and c?? in dif-
ferent languages is calculated using a linear 
combination of the four cosine similarities, using 
the values for ???? &,, as 0.4, 0.3, 0.2 and 
0.1, respectively (see Figure 4): 
),(.),(.
),(.),(),(
cccogccent
ccgeocceurovccclsim
???+???+
???+????=???
??
??
 
5.1 Filtering and refining cross-lingual clus-
ter links 
The process described in the previous paragraphs 
produces some unwanted cross-lingual links. We 
also observed that not all cross-lingual links are 
transitive although they should be. We thus de-
veloped an additional filtering and link weighting 
algorithm to improve matters, whose basic idea 
is the following: When clusters are linked in 
more than two languages, our assumption is: If 
cluster A is linked to cluster B and cluster C, 
then cluster B should also be linked to cluster C. 
We furthermore assume that if cluster B is not 
linked to cluster C, then cluster B is less likely to 
be linked to cluster A. The new algorithm thus 
checks these ?inter-links? and calculates a new 
similarity value which combines the standard 
similarity (described in 5.0) with the number of 
inter-links. The formula punishes links to an iso-
lated cluster (i.e. links to a target language clus-
ter which itself is not linked to other linked lan-
guages) and raises the score for inter-linked clus-
ters (i.e. links to a target language cluster which 
itself is linked to other linked languages). The 
new similarity score uses the formula: 
)(
)(
).,(),(
CEl
CCl
CCclsimCCmclsi ?
????=????    
with Cl(C) being the number of computed cross-
lingual links and El(C) being the number of ex-
pected cross-links (i.e. all cross-language links 
observed when looking at all languages). For in-
stance, if a cluster is linked to three languages 
and these are linked to a further three, then 
Cl(C?)=3 and El(C?)=6.  
Figure 4. Example of the similarity calculation 
for an English and a French cluster. The overall 
similarity for these two clusters, based on the lin-
ear combination of four  different vectors, is 0.46.  
5.2 Linking whole stories across languages  
The stories contain clusters which are themselves 
linked to clusters in other languages (see 5.1). 
This information can be used to compute the 
similarity between two whole stories in different 
languages. The formula is quite simple: 
     ?
????????
????=???
ScSc
ji
ji
ccmclsiSSSclsim
,
),(),(  
with S' and S'' being two stories in different lan-
guages, and c' and c'' being constituent clusters. 
Cross-lingual cluster similarity values are only 
added if they are above the threshold of 0.15. 
Table 2 shows an English story and its links in 
seven languages. 
As the evaluation results in Section 6 show, this 
formula produces reasonable results, but it has 
some limitations. Firstly, it relies exclusively on 
Lang. 
  
Biggest title 
 
Nb. of 
clusters
Nb. of  
articles 
Common 
clusters 
Simi-
larity 
En Rescuers injured at mine collapse 17 200 --- --- 
Pt EUA: mineiros presos numa mina continuam incontact?veis 12 63 7 2.1363 
Es Colapsa mina en EE.UU. 5 24 3 0.9138 
De USA: Sechs Bergleute eingeschlossen 3 28 2 0.7672 
Nl Mijnwerkers vast na aardbeving in Utah 2 7 2 0.6082 
Fr Le sauvetage de mineurs dans l'Utah tourne au drame 3 16 2 0.5541 
Nl Reddingswerkers omgekomen in mijn Utah 2 12 2 0.4644 
Sv Mystisk "ub?t" unders?ks i New York 4 16 2 0.3681 
Table 2. Example of cross-lingual links between the English language US mine collapse story and stories 
in seven other languages. The Swedish story, which has the lowest similarity score, is actually unrelated. 
54
daily cross-lingual links, whereas stories are not 
necessarily reported on the same day across lan-
guages. Secondly, we might be able to produce 
better results by making use of the available 
meta-information at story level described in Sec-
tion 4.2. We are thus planning to refine this for-
mula in future work.  
Type of story  
N
um
be
r o
f 
st
or
ie
s 
N
b 
of
 c
or
re
ct
 
cr
os
s-
lin
gu
al
 
lin
ks
 
N
um
be
r o
f 
cr
os
s-
lin
gu
al
 
lin
ks
 
Pr
ec
is
io
n 
All stories 112 275 465 0.59 
Stories containing at 
least 5 clusters 
39 145 232 0.62 
Stories containing at 
least 10 clusters 
11 75 100 0.75 
10 top stories in 4 
languages 
40 235 270 0.87 
Table 4. Evaluation of cross-lingual story linking. 
6 Evaluation 
Evaluating such a system is not straightforward 
as there is a lot of room for  interpretation re-
garding the relatedness of clusters and stories. 
Cluster consistency evaluation and the monolin-
gual and cross-lingual linking of individual clus-
ters using a very similar approach has already 
been evaluated in Pouliquen et al (2004).  
In order to evaluate the precision for the story 
building in four languages, we have evaluated 
the relatedness of the individual components (the 
clusters) with the story itself. We compiled a list 
of 330 randomly selected stories (in the 4 lan-
guages English, German, Italian and Spanish) 
and asked an expert to judge if each of the clus-
ters is linked to the main story. For each story, 
we thus have a ratio of 'correctly linked' clusters 
(see Table 3). The average ratio corresponds to 
the precision of the story tracking system. There 
clearly is room for improvement, but we found the 
results good enough to display the automatically 
identified stories as part of the live application.  
We did make an attempt at evaluating also the 
recall for story building, but soon found out that 
the results would not make sense. The idea was 
to carry out a usage-oriented evaluation for the 
situation in which users are looking for any story 
of their choice using their own search words (e.g. 
Oscar and nomination, Pavarotti and death, 
etc.). It was found that relevant stories did indeed 
exist for almost every query. However, the re-
sults would entirely depend on the type of story 
the evaluator is looking for and on the evalua-
tor?s capacity to identify significant search 
words. We can thus not present results for the re-
call evaluation of the story tracking system. 
The purpose of a second test was to evaluate 
the accuracy of the cross-lingual story linking. 
For that purpose, we evaluated those 112 multi-
lingual stories out of the 330 stories in the previ-
ous experiment that had cross-lingual links to 
any of the languages Dutch, English, French, 
German, Italian, Portuguese, Spanish or Swedish. 
Table 4 shows that only 59% of the automati-
cally established cross-lingual story links were 
accurate, but that the situation improves when 
looking at stories consisting of more clusters, i.e. 
5 or 10. This trend was confirmed by a separate 
study evaluating only the cross-lingual links for 
the 10 largest stories in the same four languages, 
into the same eight other languages: 87% of the 
cross-lingual links were correct. Note that ? for 
these large stories ? the cross-lingual links were 
96.5% complete (270 out of 280 possible links 
were present). Further insights from this evalua-
tion are that there are only two out of the 40 top 
stories that should be merged (there are two Eng-
lish top stories on Israel) and that there is one 
cluster in each of the four languages which 
should be split (all China-related news merges 
into one story). It is clear that more experiments 
are needed to improve the cross-lingual links for 
smaller stories. We have not evaluated the recall 
of the cross-lingual story linking as recall evalua-
tion is very time-consuming and we first want to 
optimise the algorithm.  
7 Conclusion and Future Work 
Lan-
guage 
Number 
of stories 
Correct com-
ponents 
All com-
ponents 
Preci
sion 
German 93 249 265 0.94
English 113 490 570 0.86
Spanish 33 78 91 0.86
Italian 91 239 299 0.80
All  330 1056 1225 0.86
Table 3. Evaluation of the monolingual linking 
of clusters into stories for four languages. 
The story tracking system has been running for 
two years. There is definitely space for improve-
ment as unrelated clusters are sometimes part of 
a story, but informal positive user feedback 
makes us believe that users already find the cur-
rent results useful. An analysis of the web logs 
shows that more than 400 separate visitors per 
day look at story-related information, split quite 
evenly across the different languages (Table 5).  
55
 The story tracking algorithm is rather sensi-
tive to the starting date for the process: Different 
starting dates may result in different stories and 
certain starting dates may result in having two 
separate parallel stories talking about very 
closely related subjects. Another issue is the 
seven-day window: We may want to extend the 
window as it happens occasionally that a story 
?dies? because no related articles are published 
on the subject for a week, and that another story 
talking about the same subject starts 8 days later. 
Finally, our algorithm should try to cope with the 
fact that stories can split or merge (an issue not 
currently dealt with), but this is a non-trivial issue. 
Regarding the cross-lingual linking, the current 
results are encouraging, but not sufficient. The ac-
curacy needs to be improved before the results can 
go online. The most promising idea here is to 
make use of each story?s meta-information (lists 
of related persons, organisations, countries and 
keywords at story level) and to allow a time de-
lay in the publication of stories across languages. 
However, the application has high potential, as it 
will provide users with (graphically visualisable) 
information on how the media report events 
across languages and countries.  
In a separate effort, a ?live? news clustering 
system has been developed within EMM, which 
groups the news as they come in during the day 
(see http://press.jrc.it/NewsBrief/). This process 
needs to be integrated with the daily and more 
long-term story tracking process so that users can 
explore the history and the background for cur-
rent events.  
Acknowledgements 
We thank the Web Mining and Intelligence team 
and our team leader Erik van der Goot for the valu-
able news data and the robust web sites. A special 
thanks to Jenya Belyaeva for her evaluation. 
References 
Landauer Thomas & Michael Littman (1991). A Sta-
tistical Method for Language-Independent Repre-
sentation of the Topical Content of Text Segments. 
Proceedings of the 11th International Conference 
?Expert Systems and Their Applications?, vol. 8: 
pp. 77-85.  
Larkey Leah, Fangfang Feng, Margaret Connell, Vic-
tor Lavrenko (2004). Language-specific Models in 
Multilingual Topic Tracking. Proceedings of the 
27th annual international ACM SIGIR conference 
on Research and development in information re-
trieval, pp. 402-409. 
Leek Tim, Hubert Jin, Sreenivasa Sista & Richard 
Schwartz (1999). The BBN Crosslingual Topic De-
tection and Tracking System. In 1999 TDT Evalua-
tion System Summary Papers.  
Pouliquen Bruno, Ralf Steinberger, Camelia Ignat, 
Emilia K?sper & Irina Temnikova (2004). Multi-
lingual and cross-lingual news topic tracking. In: 
Proceedings of the 20th International Conference on 
Computational Linguistics, Vol. II, pp. 959-965.   
Pouliquen Bruno, Marco Kimler, Ralf Steinber-
ger,  Camelia Ignat, Tamara Oellinger, Ken Black-
ler, Flavio Fuart, Wajdi Zaghouani, Anna Widiger, 
Ann-Charlotte Forslund & Clive Best (2006). Geo-
coding multilingual texts: Recognition, Disam-
biguation and Visualisation. Proceedings of the 5th 
International Conference on Language Resources 
and Evaluation (LREC'2006), pp. 53-58.  
Schultz J. Michael & Mark Liberman (1999). Topic 
detection and Tracking using idf-weighted Cosine 
Coefficient. DARPA Broadcast News Workshop 
Proceedings. 
Steinberger Ralf, Bruno Pouliquen & Camelia Ignat 
(2004). Providing cross-lingual information access 
with knowledge-poor methods. In: Andrej Brodnik, 
Matja? Gams & Ian Munro (eds.): Informatica. An 
international Journal of Computing and Informat-
ics. Vol. 28-4, pp. 415-423. Special Issue 'Informa-
tion Society in 2004'.  
Lang Hits Pct 
Hits/
day Visits 
Visits 
/day Pct 
De  59993 14% 2143 1611 58 13% 
En  164557 38% 5877 2273 81 19% 
Es  49360 11% 1763 1431 51 12% 
Fr  56023 13% 2001 1514 54 12% 
It  29445 7% 1052 1425 51 12% 
Nl  25175 6% 899 1242 44 10% 
Pt  42933 10% 1533 2170 78 18% 
Sv  7284 2% 260 575 21 5% 
Total: 434770  15527 12241 437  
Table 5. Number of connections to story-related 
NewsExplorer web pages only, and distribution 
per language (period 1-28/06/2008). Only visits 
from different IP addresses were counted. 
Vinokourov Alexei, John Shawe-Taylor, Nello Cristi-
anini (2002). Inferring a semantic representation of 
text via cross-language correlation analysis. Ad-
vances of Neural Information Processing Systems 15. 
Wactlar Howard (1999). New Directions in Video In-
formation Extraction and Summarization. Proceed-
ings of the 10th DELOS Workshop.  
Wayne Charles (2000). Multilingual topic detection 
and tracking: Successful research enabled by cor-
pora and evaluation. Proceedings of 2nd Interna-
tional Conference on Language Resources and 
Evaluation. 
56
