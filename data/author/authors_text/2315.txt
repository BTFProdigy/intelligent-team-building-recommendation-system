Accelerating Corporate Research in the Development, Application 
and Deployment of Human Language Technologies 
 
David Ferrucci  
IBM T.J. Watson Research Center 
Yorktown Heights,  NY 10598 
ferrucci@us.ibm.com 
Adam Lally 
IBM T.J. Watson Research Center 
Yorktown Heights,  NY 10598 
alally@us.ibm.com 
 
 
Abstract 
IBM Research has over 200 people working 
on Unstructured Information Management 
(UIM) technologies with a strong focus on 
HLT. Spread out over the globe they are en-
gaged in activities ranging from natural lan-
guage dialog to machine translation to 
bioinformatics to open-domain question an-
swering. An analysis of these activities 
strongly suggested that improving the organi-
zation?s ability to quickly discover each 
other's results and rapidly combine different 
technologies and approaches would accelerate 
scientific advance. Furthermore, the ability to 
reuse and combine results through a common 
architecture and a robust software framework 
would accelerate the transfer of research re-
sults in HLT into IBM?s product platforms.  
Market analyses indicating a growing need to 
process unstructured information, specifically 
multi-lingual, natural language text, coupled 
with IBM Research?s investment in HLT, led 
to the development of middleware architecture 
for processing unstructured information 
dubbed UIMA. At the heart of UIMA are 
powerful search capabilities and a data-driven 
framework for the development, composition 
and distributed deployment of analysis en-
gines. In this paper we give a general intro-
duction to UIMA focusing on the design 
points of its analysis engine architecture and 
we discuss how UIMA is helping to accelerate 
research and technology transfer. 
1 Architecture Goals 
In six major labs spread out over the globe, IBM Re-
search has over 200 people working on Unstructured 
Information Management (UIM) technologies with a 
significant focus on Human Language Technologies 
(HLT). These researchers are engaged in activities rang-
ing from natural language dialog to machine translation 
to bioinformatics to open-domain question answering.  
Each group is developing different technical and engi-
neering approaches to process unstructured information 
(e.g., natural language text, voice, audio and video) in 
pursuit of specific research objectives and their applica-
tions. 
The high-level objectives of IBM?s Unstructured In-
formation Management Architecture (UIMA) are two 
fold: 
1) Accelerate scientific advances by enabling the 
rapid combination UIM technologies (e.g., natu-
ral language processing, video analysis, infor-
mation retrieval, etc.). 
 
2) Accelerate transfer of UIM technologies to 
product by providing a robust software frame-
work that promotes reuse and supports flexible 
deployment options. 
 
UIMA is a software architecture for developing ap-
plications which integrate search and analytics over a 
combination of structured and unstructured information. 
We define structured information as information whose 
intended meaning is unambiguous and explicitly repre-
sented in the structure or format of the data. The ca-
nonical example is a database table. We define 
unstructured information as information whose intended 
meaning is only implied by its form. The canonical ex-
ample is a natural language document.  
The UIMA high-level architecture, illustrated in 
Figure 1, defines the roles, interfaces and communica-
tions of large-grained components essential for UIM 
applications. These include components capable of ana-
lyzing unstructured artifacts, integrating and accessing 
structured sources and storing, indexing and searching 
for artifacts based on discovered semantic content. 
As part of the UIMA project, IBM is developing dif-
ferent implementations of the architecture suitable for 
different classes of deployment. These range from light-
weight and embeddable implementations to highly 
scaleable implementations that are meant to exploit 
clusters of machines and provide high throughput and 
high availability. 
While the architecture extends to a variety of un-
structured artifacts including voice, audio and video, a 
primary analytic focus of current UIMA implementa-
tions is squarely on human language technologies.  
In this paper we will refer to elements of unstruc-
tured information processing as documents admitting, 
however, that an element may represent for the applica-
tion, a whole text document, a text document fragment 
or even multiple documents. 
2 Generalized Application Scenario and 
the High-Level Architecture 
In this section we provide a high-level overview of the 
UIMA architecture by describing its component roles in 
a generalized application scenario.  
The generalized scenario includes both analysis and 
access functions. Analysis functions are divided into 
two classes, namely document-level and collection-level 
analysis.  Access functions are divided into semantic 
search and structured knowledge access. 
We refer to the software program that employs 
UIMA components to implement some end-user capa-
bility as the application or application program. 
2.1 Document-Level Analysis 
Document-level analysis is performed by component 
processing elements named Text Analysis Engines 
(TAEs). These are extensions of the generic analysis 
engine, specialized for text. They are analogous, for 
example, to Processing Resources in the GATE archi-
tecture (Cunningham et al, 2000). In UIMA, a TAE is a 
recursive structure which may be composed of sub or 
component engines each performing a different stage of 
the application?s analysis. 
Application
Logic 
Semantic Search Engine
Document, Collection
& Meta-data Store
(Text) Analysis Engines (TAEs)
Structured Knowledge Access
Query key words and concepts
Token and concept Indexing
Knowledge Source Adapters (KSAs)  
integrate and deliver content from 
many structured knowledge sources 
according  to central ontologies
Collection
Processing
Manager
(CPM)
Structured
Information
Unstructured 
Information
Analysis engines employing a variety 
of analytical techniques and 
strategies for detecting semantic 
contentRelevant
Knowledge
Collection
Analysis
Engine(s)
Figure 1: UIMA High-Level Architecture 
Examples of Text Analysis Engines include lan-
guage translators, document summarizers, document 
classifiers, and named-entity detectors. Each TAE spe-
cializes in discovering specific concepts (or "semantic 
entities") otherwise unidentified or implicit in the 
document text. 
A TAE takes in a document and produces an analy-
sis. The original document and its analysis are repre-
sented in a common structure called the Common 
Analysis System or CAS. The CAS is conceptually 
analogous to the annotations in other architectures, be-
ginning with TIPSTER (Grishman, 1996). 
In general, annotations associate some meta-data 
with a region in the original artifact. Where the artifact 
is a text document, for example, the annotation associ-
ates meta-data (e.g., a label) with a span of text in the 
document by giving the span?s start and end positions.  
Annotations in the CAS are stand-off, meaning that the 
annotations are maintained separately from the docu-
ment itself; this is more flexible than inline markup 
(Mardis and Burger, 2002). In UIMA, annotations are 
not the only type of information stored in the CAS.  The 
CAS may be used to represent any class of meta-data 
element associated with analysis of a document regard-
less of whether it is explicitly linked to some sub com-
ponent of the original document.  The CAS also allows 
for multiple definitions of this linkage, as is necessary 
for the analysis of images, video or other modalities. 
The analysis represented in the CAS may be thought 
of as a collection of meta-data that is enriched as it 
passes through successive stages of analysis. At a spe-
cific stage of analysis, for example, the CAS may in-
clude a deep parse. A named-entity detector receiving 
this CAS may consider the deep parse to identify named 
entities.  The named entities may be input to an analysis 
engine that produces summaries or classifications of the 
document. 
The UIMA CAS object provides general object-
based representation with a hierarchical type system 
supporting single inheritance. It includes data creation, 
access and serialization methods designed for the effi-
cient representation, access and transport of analysis 
results among TAEs and between TAEs and other 
UIMA components or applications. Elements in the 
CAS may be indexed for fast access (Goetz et al, 
2001).  The CAS has been implemented in C++ and 
Java with serialization methods for binary as well as 
XML formats for managing the tradeoff between effi-
ciency and interoperability. 
2.2 Collection-Level Analysis 
Documents are gathered by the application and organ-
ized into collections. The architecture defines a Collec-
tion Reader interface. Implementations of the Collection 
Reader provide access to collection elements, collection 
meta-data and element meta-data. UIMA implementa-
tions include a document, collection and meta-data store 
that implements the Collection Reader interface and 
manages multiple collections and their elements. How-
ever, applications that need to manage their own collec-
tions can provide an implementation of a Collection 
Reader to UIMA components that require access to col-
lection data. 
Collections are analyzed to produce collection level 
analysis results. These results represent aggregate infer-
ences computed over all or some subset of the docu-
ments in a collection. The component of an application 
that analyzes an entire collection is considered a Collec-
tion Analysis Engine. These engines typically apply 
element-level, or more specifically document-level 
analysis, to elements of a collection and then consider-
ing the element analyses in performing aggregate com-
putations. 
Examples of collection level analysis results include 
sub collections where elements contain certain features, 
glossaries of terms with their variants and frequencies, 
taxonomies, feature vectors for statistical categorizers, 
databases of extracted relations, and master indices of 
tokens and other detected entities. 
In support of Collection Analysis Engines, UIMA 
defines the Collection Processing Manager (CPM) 
component. The CPM?s primary responsibility is to 
manage the application of a designated TAE to each 
document accessible through a Collection Reader. A 
Collection Analysis Engine may provide, as input to the 
CPM, a TAE and a Collection Reader. The CPM applies 
the TAE and returns the analysis, represented by a CAS, 
for each element in the collection. To control the proc-
ess, the CPM provides administrative functions that 
include failure reporting, pausing and restarting.  
At the request of the application?s collection analy-
sis engine, the CPM may be optionally configured to 
perform functions typical of UIM application scenarios. 
Examples of these include:  
1) Filtering - ensures that only certain elements 
are processed based on meta-data constraints.  
2) Persistence - stores element-level analysis re-
sults in a provided Collection Writer. 
3) Indexing - indexes documents using a desig-
nated search engine indexing interface based 
on meta-data extracted from the analysis. 
4) Parallelization - manages the creation and exe-
cution of multiple instances of a TAE for proc-
essing multiple documents simultaneously 
utilizing available computing resources. 
2.3 Semantic Search 
To support the concept of ?semantic search? ? the capa-
bility to find documents based on semantic content dis-
covered by document or collection level analysis and 
represented as annotations ? UIMA specifies search 
engine indexing and query interfaces.  
A key feature of the indexing interface is that it sup-
ports the indexing of tokens as well as annotations and 
particularly cross-over annotations. Two or more anno-
tations cross-over one another if they are linked to inter-
secting regions of the document.  
The key feature of the query interface is that it sup-
ports queries that may be predicated on nested structures 
of annotations and tokens in addition to Boolean combi-
nations of tokens and annotations. 
2.4 Structured Knowledge Access 
As analysis engines do their job they may consult a 
wide variety of structured knowledge sources. To in-
crease reusability and facilitate integration, UIMA 
specifies the Knowledge Source Adapter (KSA) inter-
face. 
KSA objects provide a layer of uniform access to 
disparate knowledge sources. They manage the techni-
cal communication, representation language and ontol-
ogy mapping necessary to deliver knowledge encoded 
in databases, dictionaries, knowledge bases and other 
structured sources in a uniform way. The primary inter-
face to a KSA presents structured knowledge as instan-
tiated predicates using the Knowledge Interchange 
Format (KIF) encoded in XML. 
A key aspect of the KSA architecture is the KSA 
meta-data and related services supporting KSA registra-
tion and search. These services include the description 
and registration of named ontologies. Ontologies are 
described by the concepts and predicates they include. 
The KSA is self-descriptive and among other meta-data 
includes the predicate signatures belonging to registered 
ontologies that the KSA can instantiate and the knowl-
edge sources it consults. 
Application or analysis engine developers can con-
sult human browseable KSA directory services to search 
for and find KSAs that instantiate predicates of a regis-
tered ontology. The service will deliver a handle to a 
web service or an embeddable KSA component.  
3 Analysis Engine Framework 
This section takes a closer look at the analysis engine 
framework. 
UIMA specifies an interface for an analysis engine; 
roughly speaking it is ?CAS in? and ?CAS out?. There 
are other operations used for filtering, administrative 
and self-descriptive functions, but the main interface 
takes a CAS as input and delivers a CAS as output.  
Any program that implements this interface may be 
plugged in as an analysis engine component in an im-
plementation of UIMA.  However, as part of UIMA 
tooling we have developed an analysis engine frame-
work to support the creation, composition and flexible 
deployment of primitive and aggregate analysis engines 
on a variety of different system middleware platforms. 
The underlying design philosophy for the Analysis 
Engine framework was driven by three primary princi-
ples: 
1) Encourage and enable component reuse. 
2) Support distinct development roles insulating 
the algorithm developer from system and 
deployment details. 
3) Support a flexible variety of deployment op-
tions by insulating lower-level system middle-
ware APIs. 
3.1 Encourage and Enable Component Reuse 
With many HLT components being developed through-
out IBM Research by independent groups, encouraging 
and enabling reuse is a critical design objective to 
achieve expected efficiencies and cross-group collabo-
rations. Three characteristics of the analysis engine 
framework address this objective: 
1) Recursive Structure 
2) Data-Driven 
3) Self-Descriptive 
 
Annotator
(Annotator Developer 
Implements)
CAS 
(part of framework)
Controller
(part of framework)
process(Result Spec.)
Primitive Analysis Engine
process(Result Spec.)
process(Result Spec.)
getCAS()
getCAS()
reads/writes 
analysis data
 
Figure 2: Primitive Analysis Engine 
Recursive Structure. A primitive analysis engine, illus-
trated in Figure 2, is composed of an Annotator and a 
CAS. The annotator is the object that implements the 
analysis logic (e.g. tokenization, grammatical parsing, 
entity detection). It reads the original document content 
and meta-data from the CAS. It then computes and 
writes new meta-data to the CAS.  An aggregate analy-
sis engine, illustrated in Figure 3, is composed of two or 
more component analysis engines, but implements ex-
actly the same external interface as the primitive engine. 
At run-time an aggregate analysis engine is given a se-
quence in which to execute its component engines. A 
component called the Analysis Structure Broker ensures 
that each component engine has access to the CAS ac-
cording to the specified sequence. Like any nested pro-
gramming model, this recursive structure ensures that 
components may be easily reused in combination with 
one another while insulating their internal structure. 
Data-Driven. An analysis engine?s processing 
model is strictly data-driven.  This means that an anno-
tator?s analysis logic may be predicated only on the con-
tent of its input and not on the specific analysis engines 
it may be combined with or the control sequence in 
which it may be embedded. This restriction ensures that 
an analysis engine may be successfully reused in differ-
ent aggregate structures and different control environ-
ments as long as its input requirements are met.  
The Analysis Sequencer is a component in the 
framework responsible for dynamically determining the 
next analysis engine to receive access to the CAS.  The 
Analysis Sequencer is distinct from the Analysis Struc-
ture Broker, whose responsibility is to deliver the CAS 
to the next analysis engine whichever it is wherever it 
may be located.  The Analysis Sequencer?s control logic 
is separate from the analysis logic embedded in an An-
notator and separate from the Analysis Structure Bro-
ker?s concerns related to ensuring and/or optimizing the 
CAS transport. This separation of concerns allows for 
the plug-n-play of different Analysis Sequencers. The 
Analysis Sequencer is a pluggable range from provide 
simple iteration over a declaratively specified static 
flow to complex planning algorithms. Current imple-
mentations have been limited to simple linear flows 
between analysis engines; however more advanced ap-
plications are generating requirements for dynamic and 
adaptive sequencing. How much of the control specifi-
cation ends up in a declarative representation and how 
much is implemented in the sequencer for these ad-
vanced requirements is currently being explored. 
Self-Descriptive. Ensuring that analysis engines 
may be easily composed to form aggregates and may be 
reused in different control sequences is necessary for 
technical reusability but not sufficient for enabling and 
validating reuse within a broad community of develop-
ers.   To promote reuse, analysis engine developers must 
be able to discover which analysis engines are available 
in terms of what they do ? their capabilities. 
Each analysis engine's data model is declared in 
XML and then dynamically realized in the CAS at run-
time, an approach similar to MAIA (Laprun et al, 
2002).  In UIMA, however, analysis engines publish 
their input requirements and output specifications rela-
tive to this declared data model, and this information is 
used to register the analysis engine in an analysis engine 
directory service. This service includes a human-
oriented interface that allows application developers to 
browse and/or search for analysis engines that meet 
their needs. 
While self-description and related directory services 
will promote reuse, their value is still dependent on es-
tablishing common data models (or fragments thereof) 
to which analysis engine capability descriptions sub-
scribe.  
3.2 Support Distinct Development Roles 
Language technology researchers that specialize in, for 
example, multi-lingual machine translation, may not be 
Analysis
Engine 1
CAS
Analysis Structure Broker
Aggregate Analysis Engine
process(RS)
Analysis
Engine 2
process(RS) process(RS)
Analysis Sequencer
Process(Result Spec.)
init (Result Spec.)
read/write analysis data
Controller
process(Result Spec.)
Analysis
Engine 3
getCAS()
next()
Figure 3: Aggregate Analysis Engine 
 
highly trained software engineers nor be skilled in the 
system technologies required for flexible and scaleable 
deployments. Yet one of the primary objectives of the 
UIMA project is to ensure that their work can be effi-
ciently deployed in robust and scaleable system archi-
tecture.   
Along the same lines, researchers with ideas about 
how to combine and orchestrate different components 
may not themselves be algorithm developers or systems 
engineers, yet we need to enable them to rapidly create  
and validate ideas through combining existing compo-
nents.  
Finally, deploying analysis engines as distributed, 
highly available services or as collocated objects in an 
aggregate system requires yet another skill.  
As a result we have identified the following devel-
opment roles and have designed the architecture with 
independent sets of interfaces in support of each of 
these different skill sets.  Our separation of development 
roles is analogous to the separation of roles in Sun's 
J2EE platform (Sun Microsystems, 2001).  
Annotator Developer. The annotator developer role 
is focused on developing core algorithms ranging from 
statistical language recognizers to rule-based named-
entity detectors to document classifiers.  
The framework design ensures that the annotator 
developer need NOT develop code to address aggregate 
system behavior or systems issues like interoperability, 
recovery, remote communications, distributed deploy-
ment, etc., but instead allow them to focus squarely on 
the algorithmic logic and the logical representation of 
their results. 
This was achieved through the analysis engine 
framework by requiring the annotator developer to un-
derstand only three interfaces, namely the Annotator, 
AnnotatorContext, and CAS interfaces.  The annotator 
developer performs the following steps: 
1) Implement Annotator interface 
2) Encode analysis algorithm using the CAS inter-
face to read input and write results and the An-
notatorContext interface to access resources 
3) Write Analysis Engine Descriptor 
4) Call Analysis Engine Factory 
To embed an analysis algorithm in the framework, 
the annotator developer implements the Annotator inter-
face. This interface is simple and requires the imple-
mentation of only two methods: one for initialization 
and one to analyze a document.  
It is only through the CAS that the annotator devel-
oper accesses input data and registers analysis results. 
The CAS contains the original document (the subject of 
analysis) plus the meta-data contributed by any analysis 
engines that have run previously. This meta-data may 
include annotations over elements of the original docu-
ment. The CAS input to an analysis engine may reside 
in memory, be managed remotely, or shared by other 
components. These issues are of concern to the analysis 
engine deployer role, but the annotator developer is in-
sulated from these issues.  
All external resources, such as dictionaries, that an 
annotator needs to consult are accessed through the An-
notator Context interface.  The exact physical manifes-
tation of the data can therefore be determined by the 
deployer, as can decisions about whether and how to 
cache the resource data. 
The annotator developer completes an XML descrip-
tor that identifies the input requirements, output specifi-
cations, and external resource dependencies. Given the 
annotator object and the descriptor, the framework?s 
Analysis Engine Factory returns a complete analysis 
engine. 
Analysis Engine Assembler. The analysis engine 
assembler creates aggregate analysis engines through 
the declarative coordination of component engines. The 
design objective is to allow the assembler to build an 
aggregate engine without writing any code. 
The analysis engine assembler considers available 
engines in terms of their capabilities and declaratively 
describes flow constraints. These constraints are cap-
tured in the aggregate engine?s XML descriptor along 
with the identities of selected component engines.   The 
assembler inputs this descriptor in the framework?s 
analysis engine factory object and an aggregate analysis 
engine is created and returned. 
Analysis Engine Deployer. The analysis engine de-
ployer decides how analysis engines and the resources 
they require are deployed on particular hardware and 
system middleware.  UIMA does not provide its own 
specification for how components are deployed, nor 
does it mandate the use of a particular type of middle-
ware or middleware product.  Instead, UIMA aims to 
give deployers the flexibility to choose the middleware 
that meets their needs. 
3.3 Insulate Lower-Level System Middleware 
HLT applications can share many requirements with 
other types of applications ? for example, they may 
need scalability, security, and transactions.   Existing 
middleware such as application servers can meet many 
of these needs.  On the other hand, HLT applications 
may need to have a small footprint so they can be de-
ployed on a desktop computer or PDA or they may need 
to be embeddable within other applications that use their 
own middleware.   
One design goal of UIMA is to support deployment 
of analysis engines on any type of middleware, and to 
insulate the annotator developer and analysis engine 
assembler from these concerns.  This is done through 
the use of Service Wrappers and the Analysis Structure 
Broker.  The analysis engine interface specifies that 
input and output are done via a CAS, but it does not 
specify how that CAS is transported between compo-
nent analysis engines.  A service wrapper implements 
the CAS serialization and deserialization necessary for a 
particular deployment.  Within an aggregate Analysis 
Engine, components may be deployed using different 
service wrappers. The Analysis Structure Broker is the 
component that transports the CAS between these com-
ponents regardless of how they are deployed.   
To support a new type of middleware, a new service 
wrapper and an extension to the Analysis Structure Bro-
ker must be developed and plugged into the framework.  
The Analysis Engine itself does not need to be modified 
in any way.  
For example, we have implemented Service Wrap-
pers and Analysis Structure Broker on top of both a 
web-services and a message queuing infrastructure.  
Each implementation has different pros and cons for 
deployment scenarios. 
4 Measuring Success 
We have considered four ways to evaluate UIMA in 
meeting its intended objectives:  
1) Combination Experiments 
2) Compliant Components and their Reuse 
3) System Performance Improvements 
4) Product Integration 
4.1 Combination Experiments 
Our UIMA implementations and associated tooling have 
led to the design of several combination experiments 
that were previously unimagined or considered too 
cumbersome to implement. This work has only just be-
gun but includes collaborative efforts combining rule-
based parsers with statistical machine translation en-
gines, statistical named-entity detectors in rule-based 
question answering systems (Chu-Carroll et al, 2003), 
and a host of independently developed analysis capabili-
ties in bioinformatics applications.  
4.2 Compliant Components and their Reuse 
Another way to measure the impact of UIMA is to look 
at its adoption by the target community. This may be 
measured by the number of compliant components and 
the frequency of their reuse by different projects/groups. 
We have developed a registry and an integration test 
bed where contributed components are tested, certified, 
registered and made available to the community for 
demonstration and download.  
The integration test bed includes a web-based facil-
ity where users can select from a collection of corpora, a 
collection of certified analysis engines and run the 
analysis engine on the corpus. Performance statistics 
breaking down the time spent in analysis, communica-
tions between components, and framework overhead are 
computed and presented. The system generates analysis 
results and stores them. Analysis results may be viewed 
using any of a variety of CAS viewers. The results may 
also be indexed by a search engine, which may then be 
used to process queries. 
While we are still instrumenting this site and gather-
ing reuse data, within six months of an internal distribu-
tion we will have over 15 UIMA-compliant analysis 
engines, many of which are based on code developed as 
part of multi-year HLT research efforts. Engines were 
contributed from six independent and geographically 
dispersed groups. They include several named-entity 
detectors of both rule-based and statistical varieties, 
several classifiers, a summarizer, deep and shallow 
parsers, a semantic class detector, an Arabic to English 
translator, an Arabic person detector, and several bio-
logical entity and relationship detectors. Several of these 
engines have been assembled using component engines 
that were previously inaccessible for reuse due to engi-
neering incompatibilities.   
4.3 System Performance Improvements 
We expect the architecture?s support for modularization 
and for the insulation of system deployment issues from 
algorithm development to result in opportunities to 
quickly deploy more robust and scaleable solutions. 
For example, IBM's Question Answering system, 
now under development for over three years, includes a 
home-grown answer type detector to analyze large cor-
pora of millions of documents (Prager et al, 2002). 
With a half day of training, an algorithm developer cast 
the answer type detector as a UIMA Annotator and em-
bedded it in the UIMA Analysis Engine framework. The 
framework provided the infrastructure necessary for 
configuring an aggregate analysis engine with the an-
swer type detector down-stream of a tokenizer and 
named-entity detector without additional programming. 
Within a day, the framework was used to build the ag-
gregate analysis engine and to deploy multiple instances 
of it on a host of machines. The result was a dramatic 
improvement in overall throughput.  
4.4 Product Integration 
IBM develops a variety of information management, 
information integration, data mining, knowledge man-
agement and search-related products and services. Un-
structured information processing and language 
technologies in particular represent an increasingly im-
portant capability that can enhance all of these products. 
UIMA will be a business success for IBM if it plays 
an important role in technology transfers. IBM Research 
has engaged a number of product groups which are real-
izing the benefits of adopting a standard architectural 
approach for integrating HLT that does not constrain 
algorithm invention and that allows for easy extension 
and integration and support for a wide variety of system 
deployment options. 
5 Conclusion 
The UIMA project at IBM has encouraged many groups 
in six of the Research division?s labs to understand and 
adopt the UIMA architecture as a common conceptual 
foundation for classifying, describing, developing and 
combining HLT components in aggregate applications 
that integrate search and analytical functions. 
While our measurements are only just beginning, the 
adoption of UIMA has clearly improved knowledge 
transfer throughout the organization. Implementations 
of the architecture are advancing and are beginning to 
demonstrate that HLT components developed within 
Research can be quickly combined to explore hybrid 
approaches as well as to rapidly transfer results into 
IBM product and service offerings.  
IBM product groups are encouraged by Research?s 
effort and are committed to leverage UIMA as a vehicle 
to embed HLT components. They are realizing the 
benefits of having Research adopt a standard architec-
tural approach that does not constrain algorithm inven-
tion while allowing for a wide variety of system 
deployment options. Product and service groups are 
seeing an easier path to combine, integrate and deliver 
these technologies into information integration, data 
mining, knowledge management and search-related 
products and services. 
Acknowledgements 
We acknowledge the contributions of Dan Gruhl and the 
WF project to the development of UIMA. In addition 
we acknowledge David Johnson, Thomas Hampp, Thilo 
Goetz and Oliver Suhre in the development of IBM?s 
Text Analysis Framework and the work of Roy Byrd 
and Mary Neff in the design of the Talent system. Their 
work continues to influence the UIMA CAS and analy-
sis engine framework. 
This work was supported in part by the Advanced 
Research and Development Activity (ARDA)?s Ad-
vanced Question Answering for Intelligence 
(AQUAINT) Program under contract number MDA904-
01-C-0988. 
References 
Kaling Bontcheva, Hamish Cunningham, Valentin Tab-
lan, Diana Maynard, Horacio Saggion. 2002. ?De-
veloping Reusable and Robust Language Processing 
Components for Information Systems using GATE.? 
3rd International Workshop on Natural Language and 
Information Systems (NLIS'2002), IEEE Computer 
Society Press. 
Jennifer Chu-Carroll, David Ferrucci, John Prager, and 
Christopher Welty. 2003. "Hybridization in Question 
Answering Systems." Working Notes of the AAAI 
Spring Symposium on New Directions in Question 
Answering, to appear. 
Hamish Cunningham, Kaling Bontcheva, Valentin Tab-
lan and Yorick Wilks. 2000. ?Software Infrastructure 
for Language Resources: a Taxonomy of Previous 
Work and a Requirements Analysis.? Proceedings of 
the Second Conference on Language Resources 
Evaluation. 
Ralph Grishman. 1996. ?Tipster architecture design 
document version 2.2.? Technical report, DARPA 
TIPSTER. 
Thilo Goetz, Robin Lougee-Heimer and Nicolas 
Nicolov.  2001. ?Efficient Indexing for Typed Fea-
ture Structures.? Proceedings of Recent Advances in 
Natural Language Processing, Tzigov Chark, Bul-
garia. 
Christophe Laprun, Johnathan Fiscus, John Garofolo,  
and Sylvain Pajot. 2002.  ?A Practical Introduction to 
ATLAS.? Proceedings of the Third International 
Conference on Language Resources and Evaluation 
(LREC). 
John Prager, Jennifer Chu-Carroll, Eric Brown, and 
Krzysztof Czuba. 2003. "Question Answering Using 
Predictive Annotation." Advances in Open-Domain 
Question Answering, T. Strzalkowski & S. Hara-
bagiu (eds.), Kluwer Academic Publishers, to appear. 
John Prager, Eric Brown, Anni Coden and Dragomir 
Radev. 2000.  ?Question-answering by Predictive 
Annotation.? Proceedings of ACMSIGIR. 
Scott Mardis and John Burger. 2002. ?Qanda and the 
Catalyst Architecture.? AAAI Spring Symposium on 
Mining Answers from Text and Knowledge Bases. 
Sun Microsystems, Inc.  2001. ?Java? 2 Platform 
Enterprise Edition Specification, v1.3.? 
http://java.sun.com/j2ee/1.3/docs/. 
Proceedings of the NAACL HLT 2010 First International Workshop on Formalisms and Methodology for Learning by Reading, pages 122?127,
Los Angeles, California, June 2010. c?2010 Association for Computational Linguistics
PRISMATIC: Inducing Knowledge from a Large Scale Lexicalized Relation
Resource?
James Fan and David Ferrucci and David Gondek and Aditya Kalyanpur
IBM Watson Research Lab
19 Skyline Dr
Hawthorne, NY 10532
{fanj, ferrucci, gondek, adityakal}@us.ibm.com
Abstract
One of the main bottlenecks in natural lan-
guage processing is the lack of a comprehen-
sive lexicalized relation resource that contains
fine grained knowledge on predicates. In this
paper, we present PRISMATIC, a large scale
lexicalized relation resource that is automati-
cally created over 30 gb of text. Specifically,
we describe what kind of information is col-
lected in PRISMATIC and how it compares
with existing lexical resources. Our main fo-
cus has been on building the infrastructure and
gathering the data. Although we are still in
the early stages of applying PRISMATIC to
a wide variety of applications, we believe the
resource will be of tremendous value for AI
researchers, and we discuss some of potential
applications in this paper.
1 Introduction
Many natural language processing and understand-
ing applications benefit from the interpretation of
lexical relations in text (e.g. selectional preferences
for verbs and nouns). For example, if one knows that
things being annexed are typically geopolitical enti-
ties, then given the phrase Napoleon?s annexation of
Piedmont, we can infer Piedmont is a geopolitical
entity. Existing linguistic resources such as VerbNet
and FrameNet provide some argument type infor-
mation for verbs and frames. However, since they
are manually built, they tend to specify type con-
straints at a very high level (e.g, Solid, Animate),
?Research supported in part by Air Force Contract FA8750-
09-C-0172 under the DARPA Machine Reading Program
consequently they do not suffice for cases such as
the previous example.
We would like to infer more fine grained knowl-
edge for predicates automatically from a large
amount of data. In addition, we do not want to re-
strict ourselves to only verbs, binary relations, or to
a specific type hierarchy.
In this paper, we present PRISMATIC, a large
scale lexicalized relation resource mined from over
30 gb of text. PRISMATIC is built using a suite of
NLP tools that includes a dependency parser, a rule
based named entity recognizer and a coreference
resolution component. PRISMATIC is composed
of frames which are the basic semantic representa-
tion of lexicalized relation and surrounding context.
There are approximately 1 billion frames in our cur-
rent version of PRISMATIC. To induce knowledge
from PRISMATIC, we define the notion of frame-
cuts, which basically specify a cut or slice operation
on a frame. In the case of the previous Napoleon
annexation example, we would use a noun-phrase
? object type cut to learn the most frequent type
of things being annexed. We believe there are many
potential applications that can utilize PRISMATIC,
such as type inference, relation extraction textual en-
tailment, etc. We discuss some of these applications
in details in section 8.
2 Related Work
2.1 Manually Created Resources
Several lexical resources have been built man-
ually, most notably WordNet (Fellbaum, 1998),
FrameNet(Baker et al, 1998) and VerbNet(Baker et
122
al., 1998). WordNet is a lexical resource that con-
tains individual word synset information, such as
definition, synonyms, antonyms, etc. However, the
amount of predicate knowledge in WordNet is lim-
ited.
FrameNet is a lexical database that describes the
frame structure of selected words. Each frame rep-
resents a predicate (e.g. eat, remove) with a list of
frame elements that constitutes the semantic argu-
ments of the predicate. Different words may map to
the same frame, and one word may map to multiple
frames based on different word senses. Frame ele-
ments are often specific to a particular frame, and
even if two frame elements with the same name,
such as ?Agent?, may have subtle semantic mean-
ings in different frames.
VerbNet is a lexical database that maps verbs to
their corresponding Levin (Levin, 1993) classes, and
it includes syntactic and semantic information of the
verbs, such as the syntactic sequences of a frame
(e.g. NP V NP PP) and the selectional restriction
of a frame argument value must be ANIMATE,
Compared to these resources, in addition to being
an automatic process, PRISMATIC has three major
differences. First, unlike the descriptive knowledge
in WordNet, VerbNet or FrameNet, PRISMATIC of-
fers only numeric knowledge of the frequencies of
how different predicates and their argument values
through out a corpus. The statistical profiles are eas-
ily to produce automatically, and they allow addi-
tional knowledge, such as type restriction (see 8.1),
to be inferred from PRISMATIC easily.
Second, the frames are defined differently. The
frames in PRISMATIC are not abstract concepts
generalized over a set of words. They are defined
by the words in a sentence and the relations between
them. Two frames with different slot values are con-
sidered different even though they may be semanti-
cally similar. For example, the two sentences ?John
loves Mary? and ?John adores Mary? result in two
different frame even though semantically they are
very close. By choosing not to use frame concepts
generalized over words, we avoid the problem of
determining which frame a word belongs to when
processing text automatically. We believe there will
be enough redundancy in a large corpus to produce
valid values for different synonyms and variations.
Third, PRISMATIC only uses a very small set of
slots (see table 1) defined by parser and relation an-
notators to link a frame and its arguments. By using
these slots directly, we avoid the problem of map-
ping parser relations to frame elements.
2.2 Automatically Created Resources
TextRunner (Banko et al, 2007) is an information
extraction system which automatically extracts re-
lation tuples over massive web data in an unsuper-
vised manner. TextRunner contains over 800 mil-
lion extractions (Lin et al, 2009) and has proven
to be a useful resource in a number of important
tasks in machine reading such as hypernym discov-
ery (Alan Ritter and Etzioni, 2009), and scoring in-
teresting assertions (Lin et al, 2009). TextRunner
works by automatically identifying and extracting
relationships using a conditional random field (CRF)
model over natural language text. As this is a rela-
tively inexpensive technique, it allows rapid applica-
tion to web-scale data.
DIRT (Discovering Inference Rules from Text)
(Lin and Pantel, 2001) automatically identifies in-
ference rules over dependency paths which tend to
link the same arguments. The technique consists of
applying a dependency parser over 1 gb of text, col-
lecting the paths between arguments and then cal-
culating a path similarity between paths. DIRT has
been used extensively in recognizing textual entail-
ment (RTE).
PRISMATIC is similar to TextRunner and DIRT
in that it may be applied automatically over mas-
sive corpora. At a representational level it differs
from both TextRunner and DIRT by storing full
frames from which n-ary relations may be indexed
and queried. PRISMATIC differs from TextRun-
ner as it applies a full dependency parser in order
to identify dependency relationships between terms.
In contrast to DIRT and TextRunner, PRISMATIC
also performs co-reference resolution in order to in-
crease coverage for sparsely-occurring entities and
employs a named entity recognizer (NER) and rela-
tion extractor on all of its extractions to better repre-
sent intensional information.
3 System Overview
The PRISMATIC pipeline consists of three phases:
1. Corpus Processing Documents are annotated
123
Figure 1: System Overview
by a suite of components which perform depen-
dency parsing, co-reference resolution, named
entity recognition and relation detection.
2. Frame Extraction Frames are extracted based
on the dependency parses and associated anno-
tations.
3. Frame-Cut Extraction Frame-cuts of interest
(e.g. S-V-O cuts) are identified over all frames
and frequency information for each cut is tabu-
lated.
4 Corpus Processing
The key step in the Corpus Processing stage is the
application of a dependency parser which is used
to identify the frame slots (as listed in Table 1) for
the Frame Extraction stage. We use ESG (McCord,
1990), a slot-grammar based parser in order to fill
in the frame slots. Sentences frequently require co-
reference in order to precisely identify the participat-
ing entity, and so in order to not lose that informa-
tion, we apply a simple rule based co-reference reso-
lution component in this phase. The co-reference in-
formation helps enhance the coverage of the frame-
cuts, which is especially valuable in cases of sparse
data and for use with complex frame-cuts.
A rule based Named Entity Recognizer (NER) is
used to identify the types of arguments in all frame
slot values. This type information is then registered
in the Frame Extraction stage to construct inten-
tional frames.
5 Frame Extraction
Relation Description/Example
subj subject
obj direct object
iobj indirect object
comp complement
pred predicate complement
objprep object of the preposition
mod nprep Bat Cave in Toronto is a tourist attraction.
mod vprep He made it to Broadway.
mod nobj the object of a nominalized verb
mod ndet City?s budget was passed.
mod ncomp Tweet is a word for microblogging.
mod nsubj A poem by Byron
mod aobj John is similar to Steve.
isa subsumption relation
subtypeOf subsumption relation
Table 1: Relations used in a frame and their descriptions
The next step of PRISMATIC is to extract a set of
frames from the parsed corpus. A frame is the basic
semantic unit representing a set of entities and their
relations in a text snippet. A frame is made of a set
of slot value pairs where the slots are dependency
relations extracted from the parse and the values are
the terms from the sentences or annotated types. Ta-
ble 2 shows the extracted frame based on the parse
tree in figure 2.
In order to capture the relationship we are inter-
ested in, frame elements are limited to those that
represent the participant information of a predicate.
Slots consist of the ones listed in table 1. Further-
more, each frame is restricted to be two levels deep
at the most, therefore, a large parse tree may re-
sult in multiple frames. Table 2 shows how two
frames are extracted from the complex parse tree
in figure 2. The depth restriction is needed for two
reasons. First, despite the best efforts from parser
researchers, no parser is perfect, and big complex
parse trees tend to have more wrong parses. By lim-
iting a frame to be only a small subset of a complex
parse tree, we reduce the chance of error parse in
each frame. Second, by isolating a subtree, each
frame focuses on the immediate participants of a
predicate.
Non-parser information may also be included in a
frame. For example, the type annotations of a word
from a named entity recognizer are included, and
such type information is useful for the various ap-
124
Figure 2: The parse tree of the sentence In 1921, Einstein received the Nobel Prize for his original work on the
photoelectric effect.
Frame01
verb receive
subj Einstein
type PERSON / SCIENTIST
obj Nobel prize
mod vprep in
objprep 1921
type YEAR
mod vprep for
objprep Frame02
Frame02
noun work
mod ndet his / Einstein
mod nobj on
objprep effect
Table 2: Frames extracted from Dependency Parse in Fig-
ure 2
plications described in section 8. We also include
a flag to indicate whether a word is proper noun.
These two kinds of information allow us to easily
separate the intensional and the extensional parts of
PRISMATIC.
6 Frame Cut
One of the main reasons for extracting a large
amount of frame data from a corpus is to induce
interesting knowledge patterns by exploiting redun-
dancy in the data. For example, we would like to
learn that things that are annexed are typically re-
gions, i.e., a predominant object-type for the noun-
phrase ?annexation of? is ?Region? where ?Region?
is annotated by a NER. To do this kind of knowledge
induction, we first need to abstract out specific por-
tions of the frame - in this particular case, we need
to isolate and analyze the noun-phrase ? object-
type relationship. Then, given a lot of data, and
frames containing only the above relationship, we
hope to see the frame [noun=?annexation?, prepo-
sition=?of?, object-type=?Region?] occur very fre-
quently.
To enable this induction analysis, we define
frame-cuts, which basically specify a cut or slice op-
eration on a frame. For example, we define an N-P-
OT frame cut, which when applied to a frame only
keeps the noun (N), preposition (P) and object-type
(OT) slots, and discards the rest. Similarly, we de-
fine frame-cuts such as S-V-O, S-V-O-IO, S-V-P-O
etc. (where S - subject, V - verb, O - object, IO -
indirect object) which all dissect frames along dif-
125
ferent dimensions. Continuing with the annexation
example, we can use the V-OT frame cut to learn
that a predominant object-type for the verb ?annex?
is also ?Region?, by seeing lots of frames of the form
[verb=?annex?, object-type=?Region?] in our data.
To make frame-cuts more flexible, we allow them
to specify optional value constraints for slots. For
example, we can define an S-V-O frame cut, where
both the subject (S) and object (O) slot values are
constrained to be proper nouns, thereby creating
strictly extensional frames, i.e. frames containing
data about instances, e.g., [subject=?United States?
verb=?annex? object=?Texas?]. The opposite ef-
fect is achieved by constraining S and O slot val-
ues to common nouns, creating intensional frames
such as [subject=?Political-Entity? verb=?annex?
object=?Region?]. The separation of extensional
from intensional frame information is desirable,
both from a knowledge understanding and an appli-
cations perspective, e.g. the former can be used to
provide factual evidence in tasks such as question
answering, while the latter can be used to learn en-
tailment rules as seen in the annexation case.
7 Data
The corpora we used to produce the initial PRIS-
MATIC are based on a selected set of sources, such
as the complete Wikipedia, New York Times archive
and web page snippets that are on the topics listed in
wikipedia. After cleaning and html detagging, there
are a total of 30 GB of text. From these sources, we
extracted approximately 1 billion frames, and from
these frames, we produce the most commonly used
cuts such as S-V-O, S-V-P-O and S-V-O-IO.
8 Potential Applications
8.1 Type Inference and Its Related Uses
As noted in Section 6, we use frame-cuts to dis-
sect frames along different slot dimensions, and then
aggregate statistics for the resultant frames across
the entire dataset, in order to induce relationships
among the various frame slots, e.g., learn the pre-
dominant types for subject/object slots in verb and
noun phrases. Given a new piece of text, we can
apply this knowledge to infer types for named en-
tities. For example, since the aggregate statistics
shows the most common type for the object of
the verb ?annex? is Region, we can infer from the
sentence ?Napoleon annexed Piedmont in 1859?,
that ?Piedmont? is most likely to be a Region.
Similarly, consider the sentence: ?He ordered a
Napoleon at the restaurant?. A dictionary based
NER is very likely to label ?Napoleon? as a Per-
son. However, we can learn from a large amount
of data, that in the frame: [subject type=?Person?
verb=?order? object type=[?] verb prep=?at? ob-
ject prep=?restaurant?], the object type typically
denotes a Dish, and thus correctly infer the type for
?Napoleon? in this context. Learning this kind of
fine-grained type information for a particular con-
text is not possible using traditional hand-crafted re-
sources like VerbNet or FrameNet. Unlike previ-
ous work in selectional restriction (Carroll and Mc-
Carthy, 2000; Resnik, 1993), PRISMATIC based
type inference does not dependent on a particular
taxonomy or previously annotated training data: it
works with any NER and its type system.
The automatically induced-type information can
also be used for co-reference resolution. For ex-
ample, given the sentence: ?Netherlands was ruled
by the UTP party before Napolean annexed it?, we
can use the inferred type constraint on ?it? (Region)
to resolve it to ?Netherlands? (instead of the ?UTP
Party?).
Finally, typing knowledge can be used for word
sense disambiguation. In the sentence, ?Tom Cruise
is one of the biggest stars in American Cinema?, we
can infer using our frame induced type knowledge
base, that the word ?stars? in this context refers to a
Person/Actor type, and not the sense of ?star? as an
astronomical object.
8.2 Factual Evidence
Frame data, especially extensional data involving
named entities, captured over a large corpus can be
used as factual evidence in tasks such as question
answering.
8.3 Relation Extraction
Traditional relation extraction approach (Zelenko et
al., 2003; Bunescu and Mooney, 2005) relies on the
correct identification of the types of the argument.
For example, to identify ?employs? relation between
?John Doe? and ?XYZ Corporation?, a relation ex-
tractor heavily relies on ?John Doe? being annotated
126
as a ?PERSON? and ?XYZ Corporation? an ?OR-
GANIZATION? since the ?employs? relation is de-
fined between a ?PERSON? and an ?ORGANIZA-
TION?.
We envision PRISMATIC to be applied to rela-
tion extraction in two ways. First, as described in
section 8.1, PRISMATIC can complement a named
entity recognizer (NER) for type annotation. This
is especially useful for the cases when NER fails.
Second, since PRISMATIC has broad coverage of
named entities, it can be used as a database to
check to see if the given argument exist in related
frame. For example, in order to determine if ?em-
ploys? relation exists between ?Jack Welch? and
?GE? in a sentence, we can look up the SVO cut
of PRISMATIC to see if we have any frame that has
?Jack Welch? as the subject, ?GE? as the object and
?work? as the verb, or frame that has ?Jack Welch?
as the object, ?GE? as the subject and ?employs? as
the verb. This information can be passed on as an
feature along with other syntactic and semantic fea-
tures to th relation extractor.
9 Conclusion and Future Work
In this paper, we presented PRISMATIC, a large
scale lexicalized relation resource that is built au-
tomatically over massive amount of text. It provides
users with knowledge about predicates and their ar-
guments. We have focused on building the infras-
tructure and gathering the data. Although we are
still in the early stages of applying PRISMATIC, we
believe it will be useful for a wide variety of AI ap-
plications as discussed in section 8, and will pursue
them in the near future.
References
Stephen Soderland Alan Ritter and Oren Etzioni. 2009.
What is this, anyway: Automatic hypernym discovery.
In Proceedings of the 2009 AAAI Spring Symposium
on Learning by Reading and Learning to Read.
Collin F. Baker, Charles J. Fillmore, and John B. Lowe.
1998. The berkeley framenet project. In Proceedings
of the 17th international conference on Computational
linguistics, pages 86?90, Morristown, NJ, USA. Asso-
ciation for Computational Linguistics.
Michele Banko, Michael J Cafarella, Stephen Soderl,
Matt Broadhead, and Oren Etzioni. 2007. Open
information extraction from the web. In In Inter-
national Joint Conference on Artificial Intelligence,
pages 2670?2676.
Razvan C. Bunescu and Raymond J. Mooney. 2005. A
shortest path dependency kernel for relation extrac-
tion. In HLT ?05: Proceedings of the conference on
Human Language Technology and Empirical Meth-
ods in Natural Language Processing, pages 724?731,
Morristown, NJ, USA. Association for Computational
Linguistics.
John Carroll and Diana McCarthy. 2000. Word sense
disambiguation using automatically acquired verbal
preferences. Computers and the Humanities Senseval
Special Issue, 34.
Christiane Fellbaum, 1998. WordNet: An Electronic Lex-
ical Database.
Beth Levin, 1993. English Verb Classes and Alterna-
tions: A Preliminary Investigation.
Dekang Lin and Patrick Pantel. 2001. Dirt - discovery
of inference rules from text. In In Proceedings of the
ACM SIGKDD Conference on Knowledge Discovery
and Data Mining, pages 323?328.
Thomas Lin, Oren Etzioni, and James Fogarty. 2009.
Identifying interesting assertions from the web. In
CIKM ?09: Proceeding of the 18th ACM conference on
Information and knowledge management, pages 1787?
1790, New York, NY, USA. ACM.
Michael C. McCord. 1990. Slot grammar: A system
for simpler construction of practical natural language
grammars. In Proceedings of the International Sympo-
sium on Natural Language and Logic, pages 118?145,
London, UK. Springer-Verlag.
Philip Resnik. 1993. Selection and Information:
A Class-Based Approach to Lexical Relationships.
Ph.D. thesis, University of Pennsylvania.
Dmitry Zelenko, Chinatsu Aone, and Anthony
Richardella. 2003. Kernel methods for relation
extraction. J. Mach. Learn. Res., 3:1083?1106.
127
