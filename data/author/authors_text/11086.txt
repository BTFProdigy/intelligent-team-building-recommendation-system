Proceedings of the Third Workshop on Statistical Machine Translation, pages 171?174,
Columbus, Ohio, USA, June 2008. c?2008 Association for Computational Linguistics
MATREX: the DCU MT System for WMT 2008
John Tinsley, Yanjun Ma, Sylwia Ozdowska, Andy Way
National Centre for Language Technology
Dublin City University
Dublin 9, Ireland
{jtinsley, yma, sozdowska, away}@computing.dcu.ie
Abstract
In this paper, we give a description of the ma-
chine translation system developed at DCU
that was used for our participation in the eval-
uation campaign of the Third Workshop on
Statistical Machine Translation at ACL 2008.
We describe the modular design of our data-
driven MT system with particular focus on
the components used in this participation. We
also describe some of the significant modules
which were unused in this task.
We participated in the EuroParl task for the
following translation directions: Spanish?
English and French?English, in which we em-
ployed our hybrid EBMT-SMT architecture to
translate. We also participated in the Czech?
English News and News Commentary tasks
which represented a previously untested lan-
guage pair for our system. We report results
on the provided development and test sets.
1 Introduction
In this paper, we present the Data-Driven MT sys-
tems developed at DCU, MATREX (Machine Trans-
lation using Examples). This system is a hybrid sys-
tem which exploits EBMT and SMT techniques to
build a combined translation model.
We participated in both the French?English and
Spanish?English EuroParl tasks. In these two tasks,
we monolingually chunk both source and target
sides of the dataset using a marker-based chunker
(Gough and Way, 2004). We then align these chunks
using a dynamic programming, edit-distance-style
algorithm and combine them with phrase-based
SMT-style chunks into a single translation model.
We also participated in the Czech?English News
Commentary and News tasks. This language pair
represents a new challenge for our system and pro-
vides a good test of its flexibility.
The remainder of this paper is organised as fol-
lows: Section 2 details the various components of
our system, in particular the chunking and chunk
alignment strategies used for the shared task. In Sec-
tion 3, we outline the complete system setup for the
shared task, and in Section 4 we give some results
and discussion thereof.
2 The MATREX System
The MATREX system is a modular hybrid data-
driven MT system, built following established De-
sign Patterns, which exploits aspects of both the
EBMT and SMT paradigms. It consists of a num-
ber of extendible and re-implementable modules, the
most significant of which are:
? Word Alignment Module: outputs a set of word
alignments given a parallel corpus,
? Chunking Module: outputs a set of chunks
given an input corpus,
? Chunk Alignment Module: outputs aligned
chunk pairs given source and target chunks ex-
tracted from comparable corpora,
? Decoder: returns optimal translation given a
set of aligned sentence, chunk/phrase and word
pairs.
In some cases, these modules may comprise
wrappers around pre-existing software. For exam-
ple, our system configuration for the shared task
incorporates a wrapper around GIZA++ (Och and
Ney, 2003) for word alignment and a wrapper
around Moses (Koehn et al, 2007) for decoding. It
171
should be noted, however, that the complete system
is not limited to using only these specific module
choices. The following subsections describe those
modules unique to our system.
2.1 Marker-Based Chunking
The chunking module used for the shared task is
based on the Marker Hypothesis, a psycholinguistic
constraint which posits that all languages are marked
for surface syntax by a specific closed set of lex-
emes or morphemes which signify context. Using a
set of closed-class (or ?marker?) words for a particu-
lar language, such as determiners, prepositions, con-
junctions and pronouns, sentences are segmented
into chunks. A chunk is created at each new occur-
rence of a marker word with the restriction that each
chunk must contain at least one content (or non-
marker) word. An example of this chunking strategy
for English and Spanish is given in Figure 1.
2.2 Chunk Alignment
In order to align the chunks obtained by the chunk-
ing procedures described in Section 2.1, we make
use of an ?edit-distance-style? dynamic program-
ming alignment algorithm.
In the following, a denotes an alignment between
a target sequence e consisting of I chunks and a
source sequence f consisting of J chunks. Given
these sequences of chunks, we are looking for the
most likely alignment a?:
a? = argmax
a
P(a|e, f) = argmax
a
P(a, e|f).
We first consider alignments such as those ob-
tained by an edit-distance algorithm, i.e.
a = (t1, s1)(t2, s2) . . . (tn, sn),
with ?k ? J1, nK, tk ? J0, IK and sk ? J0, JK, and
?k < k?:
tk ? tk? or tk? = 0,
sk ? sk? or sk? = 0,
where tk = 0 (resp. sk = 0) denotes a non-aligned
target (resp. source) chunk.
We then assume the following model:
P(a, e|f) = ?kP(tk, sk, e|f) = ?kP(etk |fsk),
where P(e0|fj) (resp. P(ei|f0)) denotes an ?inser-
tion? (resp. ?deletion?) probability.
Assuming that the parameters P(etk |fsk) are
known, the most likely alignment is computed by
a simple dynamic-programming algorithm.1
Instead of using an Expectation-Maximization al-
gorithm to estimate these parameters, as commonly
done when performing word alignment (Brown
et al, 1993; Och and Ney, 2003), we directly com-
pute these parameters by relying on the information
contained within the chunks. The conditional prob-
ability P(etk |fsk) can be computed in several ways.
In our experiments, we have considered three main
sources of knowledge: (i) word-to-word translation
probabilities, (ii) word-to-word cognates, and (iii)
chunk labels. These sources of knowledge are com-
bined in a log-linear framework. The weights of
the log-linear model are not optimised; we experi-
mented with different sets of parameters and did not
find any significant difference as long as the weights
stay in the interval [0.5 ? 1.5]. Outside this inter-
val, the quality of the model decreases. More details
about the combination of knowledge sources can be
found in (Stroppa and Way, 2006).
2.3 Unused Modules
There are numerous other features available in our
system which, due to time constraints, were not ex-
ploited for the purposes of the shared task. They
include:
? Word packing (Ma et al, 2007): a bilingually
motivated packing of words that changes the
basic unit of the alignment process in order to
simplify word alignment.
? Supertagging (Hassan et al, 2007b): incorpo-
rating lexical syntactic descriptions, in the form
of supertags, to the language model and target
side of the translation model in order to better
inform decoding.
? Source-context features (Stroppa et al, 2007):
use memory-based classification to incorporate
context-informed features on the source side of
the translation model.
? Treebank-based phrase extraction (Tinsley
et al, 2007): extract word and phrase align-
ments based on linguistically informed sub-
sentential alignment of the parallel data.
1This algorithm is actually a classical edit-distance al-
gorithm in which distances are replaced by opposite-log-
conditional probabilities.
172
English: [I voted] [in favour] [of the strategy presented] [by the council] [concerning relations] [with
Mediterranean countries]
Spanish: [He votado] [a favor] [de la estrategia presentada] [por el consejo] [relativa las relaciones]
[con los pa??ses mediterrane?os]
Figure 1: English and Spanish Marker-Based chunking
Filter criteria es?en fr?en cz?en
Initial Total 1258778 1288074 1096941
Blank Lines 5632 4200 2
Length 6794 8361 2922
Fertility 120 82 1672
Final Total 1246234 1275432 1092345
Table 1: Summary of pre-processing on training data.
3 Shared Task Setup
The following section describes the system setup
using the Spanish?English and French?English Eu-
roParl, and Czech?English CzEng training data.
3.1 Pre-processing
For all tasks we initially tokenised the data (Czech
data was already tokenised) and removed blank
lines. We then filtered out sentence pairs based on
length (>100 words) and fertility (9:1 word ratio).
Finally we lowercased the data. Details of this pre-
processing are given in Table 1.
3.2 System Configuration
As mentioned in Section 2, our word alignment
module employs a wrapper around GIZA++.
We built a 5-gram language model based the tar-
get side of the training data. This was done using
the SRI Language Modelling toolkit (Stolcke, 2002)
employing linear interpolation and modified Kneser-
Ney discounting (Chen and Goodman, 1996).
Our phrase-table comprised a combination of
marker-based chunk pairs2, extracted as described
in Sections 2.1 and 2.2, and word-alignment-based
phrase pairs extracted using the ?grow-diag-final?
method of Koehn et al (2003), with a maximum
phrase length of 7 words. Phrase translation proba-
bilities were estimated by relative frequency over all
phrase pairs and were combined with other features,
2This module was omitted from the Czech?English system
as we have yet to verify whether marker-based chunking is ap-
propriate for Czech.
System BLEU (-EBMT) BLEU (+EBMT)
es?en 0.3283 0.3287
fr?en 0.2768 0.2770
cz?en 0.2235 -
Table 2: Summary of results on developments sets de-
vtest2006 for EuroParl tasks and nc-test2007 for cz?en
tasks.
System BLEU (-EBMT) BLEU (+EBMT)
es?en 0.3274 0.3285
fr?en 0.3163 0.3174
cz?en (news) 0.1458 -
cz?en (nc) 0.2217 -
Table 3: Summary of results on 2008 test data.
such as a reordering model, in a log-linear combina-
tion of functions.
We tuned our system on the development set de-
vtest2006 for the EuroParl tasks and on nc-test2007
for Czech?English, using minimum error-rate train-
ing (Och, 2003) to optimise BLEU score.
Finally, we carried out decoding using a wrapper
around the Moses decoder.
3.3 Post-processing
Case restoration was carried out by training the sys-
tem outlined above - without the EBMT chunk ex-
traction - to translate from the lowercased version
of the applicable target language training data to the
truecased version. We have previously shown this
approach to be very effective for both case and punc-
tuation restoration (Hassan et al, 2007a). The trans-
lations were then detokenised.
4 Results
The system output is evaluated with respect to
BLEU score. Results on the development sets and
test sets for each task are given in Tables 2 and 3
respectively, where ?-EBMT? indicates that EBMT
chunk modules were not used, and ?+EBMT? indi-
cates that they were used.
173
4.1 Discussion
Those configurations which incorporated the EBMT
chunks improved slightly over those which did not.
Groves (2007) has shown previously that combin-
ing EBMT and SMT translation models can lead to
considerable improvement over the baseline systems
from which they are derived. The results achieved
here lead us to believe that on such a large scale
there may be a more effective way to incorporate the
EBMT chunks.
Previous work has shown the EBMT chunks to
have higher precision than their SMT counterparts,
but they lack sufficient recall when used in isola-
tion (Groves, 2007). We believe that increasing their
influence in the translation model may lead to im-
proved translation accuracy. One experiment to this
effect would be to add the EBMT chunks as a sep-
arate phrase table in the log-linear model and allow
the decoder to chose when to use them.
Finally, we intend to exploit the unused modules
of the system in future experiments to investigate
their effects on the tasks presented here.
Acknowledgments
This work is supported by Science Foundation Ireland
(grant nos. 05/RF/CMS064 and OS/IN/1732). Thanks
also to the reviewers for their insightful comments and
suggestions.
References
Brown, P. F., Pietra, S. A. D., Pietra, V. J. D., and Mercer,
R. L. (1993). The mathematics of statistical machine
translation: Parameter estimation. Computational Lin-
guistics, 19(2):263?311.
Chen, S. F. and Goodman, J. (1996). An Empirical Study
of Smoothing Techniques for Language Modeling. In
Proceedings of the Thirty-Fourth Annual Meeting of
the Association for Computational Linguistics, pages
310?318, San Francisco, CA.
Gough, N. and Way, A. (2004). Robust Large-Scale
EBMT with Marker-Based Segmentation. In Proceed-
ings of the 10th International Conference on Theoreti-
cal and Methodological Issues in Machine Translation
(TMI-04), pages 95?104, Baltimore, MD.
Groves, D. (2007). Hybrid Data-Driven Models of Ma-
chine Translation. PhD thesis, Dublin City University,
Dublin, Ireland.
Hassan, H., Ma, Y., and Way, A. (2007a). MATREX: the
DCU Machine Translation System for IWSLT 2007. In
Proceedings of the International Workshop on Spoken
Language Translation, pages 69?75, Trento, Italy.
Hassan, H., Sima?an, K., and Way, A. (2007b). Su-
pertagged Phrase-based Statistical Machine Transla-
tion. In Proceedings of the 45th Annual Meeting of the
Association for Computational Linguistics (ACL?07),
pages 288?295, Prague, Czech Republic.
Koehn, P., Hoang, H., Birch, A., Callison-Burch, C., Fed-
erico, M., Bertoldi, N., Cowan, B., Shen, W., Moran,
C., Zens, R., Dyer, C., Bojar, O., Constantin, A., and
Herbst, E. (2007). Moses: Open Source Toolkit for
Statistical Machine Translation. In Annual Meeting of
the Association for Computational Linguistics (ACL),
demonstration session, pages 177?180, Prague, Czech
Republic.
Koehn, P., Och, F. J., and Marcu, D. (2003). Statisti-
cal Phrase-Based Translation. In Proceedings of the
2003 Conference of the North American Chapter of the
Association for Computational Linguistics on Human
Language Technology (NAACL ?03), pages 48?54, Ed-
monton, Canada.
Ma, Y., Stroppa, N., and Way, A. (2007). Boostrap-
ping Word Alignment via Word Packing. In Proceed-
ings of the 45th Annual Meeting of the Association for
Computational Linguistics (ACL?07), pages 304?311,
Prague, Czech Republic.
Och, F. (2003). Minimum error rate training in statistical
machine translation. In Proceedings of the 41st Annual
Meeting of the Association for Computational Linguis-
tics (ACL), pages 160?167, Sapporo, Japan., Sapporo,
Japan.
Och, F. J. and Ney, H. (2003). A Systematic Comparison
of Various Statistical Alignment Models. Computa-
tional Linguistics, 29(1):19?51.
Stolcke, A. (2002). SRILM - An Extensible Language
Modeling Toolkit. In Proceedings of the Interna-
tional Conference Spoken Language Processing, Den-
ver, CO.
Stroppa, N., van den Bosch, A., and Way, A. (2007).
Exploiting Source Similarity for SMT using Context-
Informed Features. In Proceedings of the 11th Interna-
tional Conference on Theoretical and Methodological
Issues in Machine Translation (TMI-07), pages 231?
240, Sko?vde, Sweden.
Stroppa, N. and Way, A. (2006). MaTrEx: the DCU ma-
chine translation system for IWSLT 2006. In Proceed-
ings of the International Workshop on Spoken Lan-
guage Translation, pages 31?36, Kyoto, Japan.
Tinsley, J., Hearne, M., and Way, A. (2007). Exploiting
Parallel Treebanks to Improve Phrase-Based Statisti-
cal Machine Translation. In Proceedings of the Sixth
International Workshop on Treebanks and Linguistic
Theories (TLT-07), pages 175?187, Bergen, Norway.
174
Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 69?71,
Avignon, France, April 23 - 27 2012. c?2012 Association for Computational Linguistics
PLUTO: Automated Solutions for Patent Translation
i
 
John Tinsley, Alexandru Ceausu, Jian Zhang 
 
Centre for Next Generation Localisation 
School of Computing 
Dublin City University, Ireland 
{jtinsley;aceausu;jzhang}@computing.dcu.ie 
  
1 Introduction 
PLUTO is a commercial development project 
supported by the European Commission as part 
of the FP7 programme which aims to eliminate 
the language barriers that exist worldwide in the 
provision of multilingual access to patent infor-
mation. The project consortium comprises four 
partners: the Centre for Next Generation Locali-
sation at Dublin City University,1 ESTeam AB,2 
CrossLang, 3  and the Dutch Patent Information 
User Group (WON).4 Research and development 
is carried out in close collaboration with user 
groups and intellectual property (IP) profession-
als to ensure solutions and software are delivered 
that meet actual user needs. 
1.1 The need for patent translation 
The number of patent applications filed 
worldwide is continually increasing, with over 
1.8 million new filings in 2010 alone. Yet De-
spite the fact that patents are filed in dozens of 
different languages, language barriers are no ex-
cuse in the case of infringement. When carrying 
our prior-art and other searches IP professionals 
must ensure they include collections which en-
compass all potential relevant patents. Such 
searches will typically return results ? a set of 
patent documents ? 30% of which will be in a 
foreign language. 
As professional translation for patents is such 
a specialist task, translators command a premium 
fee for this service, often up to ?0.50 per word 
for Asian languages. This often results in high or 
unworkable translation costs for innovators. 
While free machine translation (MT) tools such 
as Google translate have unquestionably been 
beneficial in helping to reduce the need to resort 
                                                     
1 www.cngl.ie 
2 www.esteam.se 
3 www.crosslang.com 
4 www.won-nl.com 
to expensive human translation, the quality is 
still often inadequate as the models are too gen-
eral to cope with the intricacies of patent text. 
In what follows, we will provide an overview 
of some of the technologies being developed in 
PLUTO to address the need for higher quality 
MT solutions for patents and how these are de-
ployed for the benefit of IP professionals. 
2 Language Technology for Patents 
Patent translation is a unique task given the 
style of language used in patent documents. This 
language, so-called ?patentese?, typically com-
prises a mixture of highly-specific technical ter-
minology and legal jargon and is often written 
with the express purpose of obfuscating the in-
tended meaning. For example, in 2001 an inno-
vation was granted in Australia for a ?Circular 
Transportation Facilitation Device?, i.e. a wheel.5 
Patents are also characterised by a prolifera-
tion of extremely long sentences, complex chem-
ical formula, and other constructs which make 
the task for MT more difficult. 
2.1 Domain-specfic machine translation 
The patent translation systems used in 
PLUTO have been built using the MaTrEx MT 
framework (Armstrong et al, 2006). The systems 
are domain specific in that they have been 
trained exclusively using parallel patent corpora. 
A number of experiments related to domain ad-
aptation of the language and translation models 
have been carried out in the context of these sys-
tems. The principal findings from this work were 
that systems combining all available patent data 
for a given language were preferable (Ceausu et 
al. 2011). 
                                                     
5  
http://pericles.ipaustralia.gov.au/aub/pdf/nps/2002/0808/200
1100012A4/2001100012.pdf 
69
Significant pre-processing techniques are also 
applied to the input text to account for specific 
features of patent language. For instance, sen-
tence splitting based on the marker hypothesis 
(Green, 1979) is used to reduce long sentences to 
more manageable lengths, while named-entity 
recognition is applied to isolate certain struc-
tures, such as chemical compounds and refer-
ences to figures, in order to treat them in a 
specific manner. 
Additionally, various language-specific tech-
niques are used for relevant MT systems. For 
example, a technique called word packing (Ma et 
al., 2007), is exploited for Chinese?English. 
This is a bilingually motivated task which im-
proves the precision of word alignment by ?pack-
ing? several consecutive words together which 
correspond to a single word in the corresponding 
language.  
Japanese?English is a particularly challeng-
ing pair due to the divergent word ordering be-
tween the two languages. To overcome this, we 
employ preordering of the input text (Talbot et 
al. 2011) in order to harmonise the word ordering 
between the two languages and reduce the likeli-
hood of ordering errors. This is done using a 
rule-based technique called head-finalisation 
(Isozaki et al, 2010) which moves the English 
syntactic head towards the end of the phrase to 
emulate the Japanese word order. 
Finally, we use compound splitting and true 
casing modules for our English?German MT 
systems in order to reduce the occurrence of out-
of-vocabulary words. 
2.2 Translation memory integration 
In order to further improve the translation 
quality, we are developing an engine to automat-
ically combine the outputs of the MT system and 
a translation memory (TM). 
The engine works by taking a patent docu-
ment as input and searching for full matches on 
paragraph, sentence, and segment (sub-
sentential) level in the TM. If no full matches are 
found, fuzzy matches are sought above a prede-
termined threshold and combined with the output 
of the MT system using phrase- and word-level 
alignment information. 
For patents, most leverage from the TM is 
seen at segment level, particularly as the patent 
claims are often written using quite a rigid struc-
ture. This is due to that fact that, as patents typi-
cally describe something novel which may never 
have been written about previously, there is often 
little repetition of full sentences. 
2.3 Evaluation 
The performance of the patent MT systems in 
PLUTO is evaluated using a range of methods 
aimed not only at gauging general quality, but 
also identifying areas for improvement and rela-
tive performance against similar systems. 
In addition to assessing the MT systems using 
automatic evaluation metrics such as BLEU 
(Papineni et al, 2002) and METEOR (Banerjee 
et al 2005), large-scale human evaluations are 
also carried out. MT system output is ranked 
from 1?5 based on the overall quality of transla-
tion, and individual translation errors are identi-
fied and classified in an error categorisation task. 
On top of this standalone evaluation, the 
PLUTO MT systems are also benchmarked 
against leading commercial systems across two 
MT paradigms: Google Translate for statistical 
MT and Systran (Enterprise) for rule-based MT. 
A comparative analysis is carried out using both 
the automatic and human evaluation techniques 
described above. This comparison is also applied 
to the output of the PLUTO MT systems and the 
output of the integrated TM/MT system in order 
to quantify the improvements achieved using the 
translation memories. 
The main findings from the first round of 
evaluations for our French?English and Portu-
guese?English systems showed that our MT 
systems score relatively high based on human 
judgments -- 3.8 out of 5 on average -- while be-
ing ranked higher than the commercial systems 
approximately 75% of the time. More details on 
these experiments can be found in Ceausu et al 
(2011). 
3 Patent Translation Web Service 
The PLUTO MT systems are deployed as a 
web service (Tinsley et al, 2010). The main en-
try point for end users is through a web browser 
plugin which allows them to access translations 
on-the-fly regardless of the search engine being 
used to find relevant patents. In addition to the 
browser plugin, users also have the option to in-
put text directly or upload patent documents in a 
number of formats including PDF and MS Word. 
A number of further natural language pro-
cessing techniques are exploited to improve the 
user experience. N-gram based language identifi-
cation is used to send input to the correct MT 
system; while frequency based keyword extrac-
70
tion provides users with potentially important 
terms with which to carry out subsequent search-
es. 
Corresponding source and target segments are 
highlighted on both word and phrase level, while 
users have the option of post-editing translations 
which are stored in a personal terminology data-
base and applied to future translations. 
The entire framework has been designed to 
facilitate the patent professional in their daily 
workflow. It provides them with a consistency of 
translation quality and features regardless of the 
search tools being used to locate relevant patents. 
This has been validated through extensive us-
er experience testing which included a usability 
evaluation of the translation output.  
4 Looking Forward 
The PLUTO project has been running for just 
over two years and is scheduled to end in March 
2013. Our goal by that time is to have established 
a viable commercial offering to capitalize on the 
state-of-the-art research and development into 
automated patent translation. 
In the meantime, we will continue to build 
upon our existing work by building MT systems 
for additional language pairs and iteratively im-
proving upon our baseline translation perfor-
mance. Significant effort will also be spent on 
optimising the integration of translation memo-
ries with MT using techniques such as those de-
scribed in He et al (2011). 
Acknowledgements 
 
The PLuTO project (ICT-PSP-250416) is 
funded under the European Union's ICT Policy 
Support Programme as part of the Competitive-
ness and Innovation Framework Programme 
References 
Armstrong, S., M. Flanagan, Y. Graham, D. 
Groves, B. Mellebeek, S. Morrissey, N. 
Stroppa and A. Way. 2006. MaTrEx: Ma-
chine Translation Using Examples. TC-STAR 
OpenLab on Speech Translation. Trento, Ita-
ly. 
Banerjee, S. and Lavie, A. (2005). METEOR: An 
Automatic Metric for MT Evaluation with Im-
proved Correlation with Human Judgments. 
In Proceedings of Workshop on Intrinsic and 
Extrinsic Evaluation Measures for MT and/or 
Summarization at the 43th Annual Meeting of 
the Association of Computational Linguistics 
(ACL-05), Ann Arbor, MI. 
Ceausu, Alexandru, John Tinsley, Andrew Way, 
Jian Zhang, Paraic Sheridan, Experiments on 
Domain Adaptation for Patent Machine 
Translation in the PLuTO project, The 15th 
Annual Conference of the European Associa-
tion for Machine Translation, EAMT-2011, 
Leuven, Belgium 
Green, T., The necessity of syntax markers. two 
experiments with artificial languages. Journal 
of Verbal Learning and Behavior, 
18:481{496}, 1979. 
Isozaki, H., Sudoh, K., Tsukada, H., and Duh, K. 
Head finalization: A simple reordering rule 
for SOV languages. In Proceedings of the 5th 
Workshop on Machine Translation (WMT), 
Upsala, Sweden. 
Ma, Yanjun, Nicolas Stroppa, and Andy Way. 
2007. Boostrapping Word Alignment via 
Word Packing. In Proceedings of the 45th An-
nual Meeting of the Association for Computa-
tional Linguistics (ACL 2007), Prague, Czech 
Republic, pp.304?311 
Papineni, K., Roukos, S.,Ward, T., and Zhu,W.-
J. (2002). BLEU: a Method for Automatic 
Evaluationof Machine Translation. In Pro-
ceedings of the 40th Annual Meeting of the 
Association for Computational Linguistics 
(ACL-02), pages 311?318, Philadelphia, PA. 
Talbot, David, Hideto Kazawa, Hiroshi Ichikwa, 
Jason Katz-Brown, Masakazu Seno, Franz 
Och A Lightweight Evaluation Framework for 
Machine Translation Reordering, In Proceed-
ings of the Sixth Workshop on Statistical Ma-
chine Translation (July 2011), Edinburgh, 
Scotland.pp. 12-21 
Tinsley, J., A. Way and P. Sheridan 
2010. PLuTO: MT for Online Patent Transla-
tion In Proceedings of the 9th Conferences of 
the Association for Machine Translation in the 
Americas. Denver, CO, USA. 
 
                                                     
i This paper is an extended abstract intended to accom-
pany an oral presentation. It is not intended to be a 
standalone scientific article. 
71
