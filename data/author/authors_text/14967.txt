On the Means for Clarication in Dialogue
Matthew Purver and Jonathan Ginzburg
Department of Computer Science
King's College London
Strand, London WC2R 2LS, UK
fmatthew.purver, jonathan.ginzburgg@kcl.ac.uk
Patrick Healey
Department of Computer Science
Queen Mary, University of London
Mile End Road, London E1 4NS, UK
ph@dcs.qmw.ac.uk
Abstract
The ability to request clarication
of utterances is a vital part of the
communicative process. In this pa-
per we discuss the range of possi-
ble forms for clarication requests,
together with the range of read-
ings they can convey. We present
the results of corpus analysis which
show a correlation between certain
forms and possible readings, to-
gether with some indication of maxi-
mum likely distance between request
and the utterance being claried.
We then explain the implications of
these results for a possible HPSG
analysis of clarication requests and
for an ongoing implementation of
a clarication-capable dialogue sys-
tem.
1
1 Introduction
Clarication requests (CRs) are common in
human conversation. They can take various
forms and can be intended by the speaker
making the request (the CR initiator) to re-
quest various types of clarication informa-
tion (i.e. they can have various readings),
but have in common the fact that they are
in a sense meta-dialogue acts { they concern
the content or form of a previous utterance
that has failed to be fully comprehended by
the initiator.
1
This research is funded by grant number
GR/R04942/01 from the Engineering and Physical
Research Council of the United Kingdom.
It is not usual for computer dialogue sys-
tems do be able to process CRs produced by
the user. One can see how important this
might be in a negotiative dialogue by consid-
ering the following imagined exchange, which
gives some possible alternative responses to a
CR initiated by the caller:
(1)
System: Would you like to travel via
Paris or Amsterdam?
Caller: Paris?
System: (a) Yes, Paris.
(b) Paris, France.
(c) Paris is the quickest
route, although Amster-
dam is the cheapest.
(d) OK. Your ticket via
Paris will be posted to you.
Goodbye.
Any of responses (a){(c), which correctly
interpret the caller's move as a CR, might be
regarded as useful to the caller: response (d),
which incorrectly interprets it as an answer
to the system's question, would not be ac-
ceptable under any circumstances. Which of
(a){(c) is preferred will depend on the reading
intended. As a rst step towards a full theory
of CR interpretation, we therefore believe it
is important to have information about which
readings are available via which forms.
Previous studies have examined some indi-
vidual CR forms and given possible analyses
for these forms. In this paper we describe an
attempt to exhaustively categorise CR forms
and readings based on corpus work, and dis-
cuss the implications of our results for further
analysis.
The analyses so far proposed require all in-
formation from a previous utterance to be re-
tained in memory (not only propositional con-
tent but syntax and phonology). The reten-
tion of such a large amount of information in-
denitely poses obvious problems for any im-
plementation with nite resources, and seems
at odds with some results from work in psy-
cholinguistics: studies such as (Sachs, 1967;
van Dijk and Kintsch, 1983) have argued that
surface information such as syntax is retained
only in the short term (see (Fletcher, 1994)
for an overview). Our corpus work has there-
fore had the additional aim of identication
of the maximum distance between a CR and
the utterance being claried (the source ut-
terance).
In this section we give a brief overview
of CR forms identied in previous work, to-
gether with the analyses proposed and the
readings that these analyses give rise to. In
sections 2 and 3 we list the possible CR forms
and readings that we have identied from
corpus analysis. In section 4 we describe
this analysis and give detailed results, includ-
ing a discussion of apparent correlations be-
tween certain forms and readings and of max-
imum observed CR-source separation (CSS)
distance. Finally, in section 5 we discuss the
implications of our ndings for an intended
dialogue system implementation.
1.1 Previous Work
(Ginzburg and Sag, 2000) (hereafter G&S)
discuss reprise interrogatives, which they fur-
ther classify into echo questions (those \re-
sulting from mishearing a previous speech
act" { see B's question in example (2)) and
reference questions (those which \ask for clar-
ication of the reference of some element in
the immediately prior utterance" { see exam-
ple (3)).
(2)
A: Did Jill phone?
B: Did Jill phone?
(3)
A: Did Jill phone?
B: Did who phone?
They argue that the content of both read-
ings \contains as a constituent the illocu-
tionary force of the (previous) utterance" be-
ing reprised. In other words, B's utterances
in the examples above both involve query-
ing some feature of A's query. They might
be paraphrased \Are you asking whether Jill
phoned?" and \For which person are you
asking whether that person phoned?", respec-
tively.
They therefore oer a syntactic and seman-
tic analysis which covers both readings: the
reprise is analysed syntactically as an in-situ
interrogative, and semantically as a question
which takes as its propositional content the
perceived content of the previous utterance
being claried. As conversational move type
(CMT) is integrated into utterance content
by their HPSG grammar (see (Ginzburg et
al., 2001b)) this straightforwardly gives rise
to a reading along the lines of \For which
X are you asking/asserting/(etc.) Y about
X?". They give a full derivation for this read-
ing based on the kos dialogue context frame-
work (Ginzburg, 1996; Bohlin (Ljunglof) et
al., 1999).
This analysis is then extended to two el-
liptical forms: reprise sluices and elliptical
literal reprises. Sluices are elliptical wh-
constructions (see (Ross, 1969)) { short wh-
questions which receive a \sentential" inter-
pretation, in this case an interpretation as a
reprise question, as shown in example (4):
(4)
A: Did Jill phone?
B: Who?
(non-elliptical equivalent:
Did who phone?)
Elliptical literal reprises are short polar
questions { bare fragments which receive an
interpretation as a polar reprise question:
(5)
A: Did Jill phone?
B: Jill?
(non-elliptical equivalent:
Did Jill phone?)
Resolution of these elliptical forms is
achieved by allowing a conversational partici-
pant to coerce a clarication question onto the
list of questions under discussion (QUD) in
the current dialogue context. This allows el-
lipsis resolution in the manner of of (Ginzburg
et al, 2001a) to give essentially the same
reading as reprise questions.
(Ginzburg and Cooper, 2001) (hereafter
G&C) give more detailed analysis for the bare
fragment form (therein described as clari-
cation ellipsis) and also give a further read-
ing for this form. They call this reading the
constituent reading to distinguish it from the
clausal reading described above. This con-
stituent reading involves querying the con-
tent of a constituent which the CR initiator
has been unable to ground in context (see
(Traum, 1994; Clark, 1996)), and is along the
lines of \What/who/(etc.) is the reference of
your utterance X?".
A possible lexical identication reading is
also discussed, but no analysis given. They
also raise the issue of whether these specic
readings really exist or could be subsumed
by a single vague reading, but give evidence
that this is not the case: they cite examples
of CR misunderstanding leading to repeated
attempts to elicit the desired claricational
information, showing that a specic reading
was intended; they also point out that some
readings involve dierent parallelism condi-
tions. As will be discussed in detail below,
the results of the work described here also in-
dicate that particular forms may be restricted
to particular sets of specic readings.
2 Clarication Forms
The following forms have been identied as
possible means for CRs. While we cannot
claim that this list is exhaustive, a markup
scheme based on these forms has been shown
to cover the CRs encountered in a corpus of
dialogue, as detailed in section 4 below. In
this section we list the forms identied, and
illustrate them with examples. All examples
have been taken from the British National
Corpus (BNC).
2.1 Non-Reprise Clarications
Unsurprisingly, speakers have recourse to a
non-reprise
2
form of clarication. In this
2
Note that a non-reprise sentence need not be non-
elliptical.
form, the nature of the information being re-
quested by the CR initiator is spelt out for the
addressee. Utterances of this type thus often
contain phrases such as \do you mean. . . ",
\did you say. . . ", as can be seen in exam-
ples (6) and (7).
(6)
3
Cassie: You did get o with him?
Catherine: Twice, but it was totally
non-existent kissing so
Cassie: What do you mean?
Catherine: I was sort of falling asleep.
(7)
4
Leon: Erm, your orgy is a food
orgy.
Unknown: What did you say?
Leon: Your type of orgy is a food
orgy.
2.2 Reprise Sentences
Speakers can form a CR by echoing or repeat-
ing
5
a previous utterance in full, as shown in
example (8). This form corresponds to G&S's
reprise interrogative.
(8)
6
Orgady: I spoke to him on Wednes-
day, I phoned him.
Obina: You phoned him?
Orgady: Phoned him.
This form appears to be divisible into
two sub-categories, literal (as in example (8)
above) and wh-substituted reprise sentences,
as illustrated by example (9).
(9)
7
Unknown: He's anal retentive, that's
what it is.
Kath: He's what?
Unknown: Anal retentive.
2.3 Reprise Sluices
This form is an elliptical wh-construction as
already discussed above and described by
3
BNC le KP4, sentences 521{524
4
BNC le KPL, sentences 524{526
5
Repeats need not be verbatim, due to the possi-
ble presence of phenomena such as anaphora and VP
ellipsis, as well as changes in indexicals as shown in
example (8).
6
BNC le KPW, sentences 463{465
7
BNC le KPH, sentences 412{414
G&S.
(10)
8
Sarah: Leon, Leon, sorry she's
taken.
Leon: Who?
Sarah: Cath Long, she's spoken
for.
There may be a continuum of forms be-
tween wh-substituted reprise sentences and
reprise sluices. Consider the following ex-
change (11):
(11)
9
Richard: I'm opening my own busi-
ness so I need a lot of
money
Anon 5: Opening what?
This form seems to fall between the full wh-
substituted reprise sentence \You're opening
(your own) what?" and the simple reprise
sluice \(Your own) what?". The actual form
employed in this case appears closer to the
sluice and was classied as such.
10
2.4 Reprise Fragments
This elliptical bare fragment form corre-
sponds to that described as elliptical literal
reprise by G&S and clarication ellipsis by
G&C.
(12)
11
Lara: There's only two people in
the class.
Matthew: Two people?
Unknown: For cookery, yeah.
A similar form was also identied in which
the bare fragment is preceded by a wh-
question word:
(13)
12
Ben: No, ever, everything we say
she laughs at.
Frances: Who Emma?
Ben: Oh yeah.
8
BNC le KPL, sentences 347{349
9
BNC le KSV, sentences 363{364
10
While the current exercise has not highlighted it
as an issue, we note that a similar continuum might be
present between literal reprises and reprise fragments.
One approach in the face of this indeterminacy might
be to conate these forms { further analysis of the
results given in this paper may indicate whether this
is desirable.
11
BNC le KPP, sentences 352{354
12
BNC le KSW, sentences 698{700
As these examples appeared to be inter-
changeable with the plain fragment alterna-
tive (in example (13), \Emma?"), they were
not distinguished from fragments in our clas-
sication scheme.
2.5 Gaps
The gap form diers from the reprise forms
described above in that it does not involve a
reprise component corresponding to the com-
ponent being claried. Instead, it consists of
a reprise of (a part of) the utterance imme-
diately preceding this component { see exam-
ple (14).
(14)
13
Laura: Can I have some toast
please?
Jan: Some?
Laura: Toast
Our intuition is that this form is intonation-
ally distinct from the reprise fragment form
that it might be taken to resemble. This ap-
pears to be backed up by the fact that no
misunderstandings of gap-CRs were discov-
ered during our corpus analysis.
2.6 Gap Fillers
The ller form is used by a speaker to ll
a gap left by a previous incomplete utter-
ance. Its use therefore appears to be re-
stricted to such contexts, either because a pre-
vious speaker has left an utterance \hanging"
(as in example (15)) or because the CR ini-
tiator interrupts.
(15)
14
Sandy: if, if you try and do enchi-
ladas or
Katriane: Mhm.
Sandy: erm
Katriane: Tacos?
Sandy: tacos.
2.7 Conventional
A conventional form is available which ap-
pears to indicate a complete breakdown in
13
BNC le KD7, sentences 392{394
14
BNC le KPJ, sentences 555{559
communication. This takes a number of
seemingly conventionalised forms such as
\What?", \Pardon?", \Sorry?", \Eh?":
(16)
15
Anon 2: Gone to the cinema tonight
or summat.
Kitty: Eh?
Anon 2: Gone to the cinema
3 Clarication Readings
This section presents the readings that
have been identied, together with ex-
amples. We follow G&C's proposed
clausal/constituent/lexical split, with an
added reading for corrections.
3.1 Clausal
The clausal reading takes as the basis for
its content the content of the conversational
move made by the utterance being claried.
This reading corresponds roughly to \Are
you asking/asserting that X?", or \For which
X are you asking/asserting that X?". It fol-
lows that the source utterance must have been
partially grounded by the CR initiator, at
least to the extent of understanding the move
being made.
An attribute-value matrix (AVM) skeleton
for the semantic content of an HPSG sign
corresponding to this reading (according to
G&C's analysis) is shown below as AVM [1].
It represents a question
16
, the propositional
content of which is the conversational move
made by the source utterance (shown here as
being of type illoc(utionary)-rel(ation) { pos-
sible subtypes include assert, ask) together
with the message associated with that move
(e.g. the proposition being asserted). The pa-
rameter set being queried can be either a con-
stituent of that message (as would be the case
in a sluice or wh-substituted form, where the
CR question is the wh-question \For which X
are you asserting . . . ") or empty (as would be
15
BNC le KPK, sentences 580{582
16
We adopt here the version of HPSG developed in
G&S, wherein questions are represented as semantic
objects comprising a set of parameters (empty for a
polar question) and a proposition. This is the feature-
structure counterpart of a -abstract wherein the pa-
rameters are abstracted over the proposition.
the case in a fragment or literal reprise form,
where the CR question is the polar question
\Are you asserting . . . ").
[1]
2
6
6
6
6
4
question
params f
2
g or f g
prop j soa
2
4
illoc-rel
uttr
1
msg-arg

. . .
2
. . .

3
5
3
7
7
7
7
5
3.2 Constituent
Another possible reading is a constituent
reading whereby the content of a constituent
of the previous utterance is being claried.
This reading corresponds roughly to
\What/who is X?" or \What/who do you
mean by X?", as shown in AVM [2], a descrip-
tion of the content that would be given by
G&C's analysis. This shows a question whose
propositional content is the relation between
a sign (a constituent of the source utterance),
its speaker, and the intended semantic con-
tent. The abstracted parameter is the con-
tent.
[2]
2
6
6
6
6
6
6
4
question
params f
3
g
prop j soa
2
6
6
4
spkr-meaning-rel
agent
1
sign
2
cont
3
3
7
7
5
3
7
7
7
7
7
7
5
3.3 Lexical
Another possibility appears to be a lexical
reading. This is closely related to the clausal
reading, but is distinguished from it in that
the surface form of the utterance is being clar-
ied, rather than the content of the conversa-
tional move.
This reading therefore takes the form \Did
you utter X?" or \What did you utter?". The
CR initiator is attempting to identify or con-
rm a word in the source utterance, rather
than a part of the semantic content of the
utterance. This poses some interesting ques-
tions if a full analysis for this reading is to
be integrated into the HPSG framework de-
scribed above.
3.4 Corrections
The correction reading appears be along the
lines of \Did you intend to utter X (instead
of Y)?". We do not as yet have a full analysis
for this reading.
17
4 Corpus Analysis
4.1 Aims and Procedure
Our intention was to investigate the forms
and readings for CRs that are present in a cor-
pus of dialogue. For this purpose we used the
BNC, which contains a 10 million word sub-
corpus of English dialogue transcripts. For
this experiment, a sub-portion of the dialogue
transcripts was used consisting of c. 150,000
words. To maintain a spread across dialogue
domain, region, speaker age etc., this sub-
portion was created by taking a 200-speaker-
turn section from 59 transcripts.
All CRs within this sub-corpus were iden-
tied and tagged, using the markup scheme
and decision process described in 4.2 and 4.3
below. At time of writing this process has
been performed by only one (expert) user {
our intention is to conrm results by compar-
ing with those obtained by naive users, using
e.g. the kappa statistic (Carletta, 1996) to
assess reliability.
Initial identication of CRs was performed
using SCoRE (Purver, 2001), a search engine
developed specically for this purpose (in par-
ticular, to allow searches for repeated words
between speaker turns, and to display dia-
logue in an intuitive manner). However, in
order to ensure that all claricational phe-
nomena were captured, the nal search and
markup were performed manually.
4.2 Markup Scheme
The markup scheme used evolved during the
markup process as new CR mechanisms were
identied, and the nal scheme was as de-
scribed here. A multi-layered approach was
17
We suspect that corrections can in fact have
clausal, constituent or lexical sub-type, so this may in
fact not be a separate reading but a particular usage
of those already established. In this case corrections
may be covered by the analyses given for other read-
ings above, with a modied QUD coercion operation
{ see (Ginzburg and Cooper, forthcoming).
taken, along the lines of the DAMSL dialogue
act markup scheme (Allen and Core, 1997) {
this allowed sentences to be marked indepen-
dently for three attributes: form, reading and
source.
The form and reading attributes had -
nite sets of possible values. The possible val-
ues were as described in sections 2 and 3,
plus an extra catch-all category other to deal
with any otherwise uncategorisable phenom-
ena. The source attribute could take any in-
teger value and was set to the number of the
sentence that was being claried (according
to the BNC sentence-numbering scheme).
4.3 Decision Process
Following the methods described in (Allen
and Core, 1997), binary decision trees were
designed to guide the classication process.
The trees are designed so that a naive user can
follow them, but have yet to be tested in this
way. Trees were produced for initial identi-
cation of a CR, for classication of CR form
and for determination of CR source. Due to
space restrictions, the trees are not given here.
In the (common) case of ambiguity of read-
ing, the response(s) of other dialogue par-
ticipants were examined to determine which
reading was chosen by them. The ensuing re-
action of the CR initiator was then used to
judge whether this interpretation was accept-
able. If the CR initiator gave no reaction,
the reading was assumed to have been accept-
able. The following example (17) shows a case
where the other participant's initial (clausal)
reading was incorrect (the initiator is not sat-
ised), as a constituent reading was required.
In such cases, both CRs were marked as con-
stituent.
(17)
18
George: you always had er er say
every foot he had with a
piece of spunyarn in the
wire
Anon 1: Spunyarn?
George: Spunyarn, yes
Anon 1: What's spunyarn?
George: Well that's like er tarred
rope
18
BNC le H5G, sentences 193{196
In example (18), however, the other par-
ticipant's clausal interpretation provokes no
further reaction from the CR initiator, and is
taken to be correct:
(18)
19
Anon 1: you see the behind of Taz
Selassie: Tazmania?
Anon 1: Yeah.
Selassie: Oh this is so rubbish man.
In order to facilitate this process in the case
of CRs near the beginning or end of the 200-
turn section being marked, an additional 10
turns of backward and forward context were
shown (but not themselves marked up).
In the case of ambiguity as to which sen-
tence was being claried, the most recent one
was taken as the source.
4.4 Results
The BNC's SGML markup scheme (see
(Burnard, 2000) for details) allows sub-
corpora to be easily identied according to do-
main. This allowed us to collate results both
over all dialogue domains
20
, and restricted
to dialogue identied as demographic (non-
context-governed).
The distribution of CRs by form and read-
ing are shown in full in table 1 (all dialogue
domains) and table 2 (demographic only).
The distributions are presented as percent-
ages of all CRs found. This allows us to
see the proportion made up by each form
and each reading, together with any correla-
tions between form and reading, as discussed
in full below. Distributions are similar over
both sets, indicating that corpus size is large
enough to give repeatable results.
Separation between CR and source sen-
tence is shown in table 3 and gure 1, and
is discussed below.
4.4.1 Form/Reading Distribution
CRs were found to make up just under 4%
of sentences when calculated over the demo-
19
BNC le KNV, sentences 548{551
20
Domains identied by the BNC as context-
governing for dialogue include educational (school
classes, lectures) and business (meetings, training ses-
sions) { see (Burnard, 2000) for a full list.
graphic portion, or just under 3% when cal-
culated over all domains. This is a signicant
proportion, giving support to our claim that
processing of CRs is important for a dialogue
system.
The most common forms of CR can be seen
to be the conventional and reprise fragment
forms, with each making up over 25% of CRs.
Non-reprise CRs and reprise sluices are also
common, each contributing over 10% of CRs.
Other forms are all around 5% or less.
Nearly 50% of CRs can be successfully
interpreted as having a clausal reading, al-
though both the lexical (about 35%) and con-
stituent (about 15%) readings also make up a
signicant proportion.
This initially suggests that an automated
dialogue system which can deal with frag-
ments, sluices and reprise sentences (the anal-
yses described in section 1), together with
conventional and non-reprise CRs, could give
reasonable coverage of expected dialogue.
Fillers and especially gaps make up only a
small proportion.
However, the high proportion of lexical
readings suggests that a detailed analysis of
this phenomenon will be required.
4.4.2 Coverage
The coverage of the corpus by the forms
and readings listed in this paper is good, with
only 0.5% of CR readings (2 sentences) and
about 1.5% of CR forms (6 sentences) being
classied as other.
The readings not covered were all express-
ing surprise, amusement or outrage at a pre-
vious utterance (rather than requesting clar-
ication directly), and were all of the reprise
fragment or conventional form. Our intuition
is that these readings can be treated as clausal
readings with a further level of illocutionary
force given by use in context.
Of the 2 sentences left unclassied for form,
one appears to be an unusual conventional
reading, and one an interesting example of a
literal reprise of an unuttered but implied sen-
tence.
4.4.3 Form/Reading Correlation
It appears that of the non-conventional
reprise forms, only the reprise fragment re-
quires an analysis that gives a constituent
reading. Even then, this reading is much
less common than the clausal reading, and
we intend further investigation into this fact.
Sluices and reprise sentences appear always to
be satisfactorily interpretable by a clausal or
lexical reading.
21
As few examples of the rarer forms were
observed, it would be dangerous to attempt to
draw any rm conclusions about the readings
they can carry. We can, however, tentatively
suggest that the gap and ller forms might
only be used with a lexical reading.
22
One conclusion that can be safely drawn
is that many readings are available for some
forms (for example, the reprise fragment form
which appears to allow all readings). This
implies that disambiguation between readings
will be important for a dialogue system, and
this is an area we are currently examining.
Possibilities for sources of information that
could be used for disambiguation include di-
alogue context and intonation.
4.4.4 CR-Source Separation
The maximum CSS distance observed was
15 sentences. Only one example of this dis-
tance was observed, and one example of dis-
tance 13 { otherwise all CSS distances were
below 10 sentences. It should be noted that
the two long-distance cases were both seen
in one dialogue which had more than one
speaker present (the dialogue was in a class-
room situation with many people talking and
one speaker attempting to clarify an utter-
ance by the teacher), so may not be entirely
representative of the situation expected with
an automated dialogue system.
The vast majority of CRs had a CSS dis-
tance of one (i.e. were clarifying the immedi-
21
Whether this is desirable is less certain. G&S note
that echo and reference reprise sentences are intona-
tionally distinct, and this seems also true for sluices.
It may be that although the content of both can al-
ways be expressed as clausal, there is good reason not
to do so.
22
This runs contrary to our intuition which is that
the gap form might have a constituent reading.
ately preceding sentence { see gure 1), and
over 96% had a distance of 4 or less.
5 Conclusions
The taxonomy of readings and forms given
in this paper has been shown to cover nearly
99% of CRs within a corpus of dialogue. A
full HPSG analysis has been given elsewhere
for two of the four readings and four of the
eight forms.
Of the remaining readings, we believe that
the lexical reading can be treated by an ex-
tension of the existing analysis. Corrections
will need further research but make up only a
small proportion of CRs.
Of the remaining forms, we believe that two
(non-reprise and conventional) can be accom-
modated relatively smoothly within our cur-
rent HPSG framework. Gaps and llers, how-
ever, present a signicant challenge and will
be the subject of future research.
The measurements of CSS distance show
that an utterance record with length of the
order of ten sentences would be su?cient to
allow a dialogue system to process the vast
majority of CRs.
We are in the process of implement-
ing our existing analyses for the CR
forms and readings described above within
a HPSG/TrindiKit-based dialogue system
which incorporates the ellipsis resolution ca-
pability of SHARDS (Ginzburg et al, 2001a)
and the dialogue move engine of GoDiS (Lars-
son et al, 2000). At time of writing, the sys-
tem can successfully produce both clausal and
constituent readings. As a result of the re-
search outlined in this paper, a lexical reading
is currently being implemented.
Our results also suggest that investigation
into disambiguation of reading, possibly on
the basis of dialogue information state and/or
intonation, will be required.
References
James Allen and Mark Core. 1997. Draft of
DAMSL: Dialog act markup in several layers.
Peter Bohlin (Ljunglof), Robin Cooper, Elisabet
Engdahl, and Staan Larsson. 1999. Informa-
tion states and dialogue move engines. In Jan
Alexandersson, editor, IJCAI-99 Workshop on
Knowledge and Reasoning in Practical Dialogue
Systems.
Lou Burnard. 2000. Reference Guide for the
British National Corpus (World Edition). Ox-
ford University Computing Services.
Jean Carletta. 1996. Assessing agreement on clas-
sication tasks: the kappa statistic. Computa-
tional Linguistics, 22(2):249{255.
Herbert H. Clark. 1996. Using Language. Cam-
bridge University Press.
Charles Fletcher. 1994. Levels of representation
in memory for discourse. In Morton Ann Gerns-
bacher, editor, Handbook of Psycholinguistics.
Academic Press.
Jonathan Ginzburg and Robin Cooper.
2001. Resolving ellipsis in clarication.
In ACL/EACL01 Conference Proceedings.
Association for Computational Linguistics,
July.
Jonathan Ginzburg and Robin Cooper. forthcom-
ing. Clarication, ellipsis and utterance repre-
sentation.
Jonathan Ginzburg and Ivan Sag. 2000. Inter-
rogative Investigations: the Form, Meaning and
Use of English Interrogatives. Number 123 in
CSLI Lecture Notes. CSLI Publications.
Jonathan Ginzburg, Howard Gregory, and Shalom
Lappin. 2001a. SHARDS: Fragment resolu-
tion in dialogue. In Harry Bunt, Ielka van der
Sluis, and Elias Thijsse, editors, Proceedings of
the Fourth International Workshop on Compu-
tational Semantics (IWCS-4), pages 156{172.
ITK, Tilburg University, Tilburg.
Jonathan Ginzburg, Ivan A. Sag, and Matthew
Purver. 2001b. Integrating conversational
move types in the grammar of conversation.
In P. Kuhnlein, H. Rieser, and H. Zeevat, edi-
tors, Proceedings of the Fifth Workshop on For-
mal Semantics and Pragmatics of Dialogue. BI-
DIALOG.
Jonathan Ginzburg. 1996. Interrogatives: Ques-
tions, facts and dialogue. In Shalom Lappin,
editor, The Handbook of Contemporary Seman-
tic Theory, pages 385{422. Blackwell.
Staan Larsson, Peter Ljunglof, Robin Cooper,
Elisabet Engdahl, and Stina Ericsson. 2000.
GoDiS - an accommodating dialogue system. In
Proceedings of ANLP/NAACL-2000 Workshop
on Conversational Systems.
Matthew Purver. 2001. SCoRE: A tool for search-
ing the BNC. Technical report, Department of
Computer Science, King's College London.
John R. Ross. 1969. Guess who? In R. I. Bin-
nick, A. Davison, G. Green, and J. Morgan, ed-
itors, Papers from the Fifth Regional Meeting of
the Chicago Linguistic Society, pages 252{286.
CLS, University of Chicago.
Jacqueline D. Sachs. 1967. Recognition mem-
ory for syntactic and semantic aspects of
connected discourse. Perception and Psy-
chophysics, 2:437{442.
David Traum. 1994. A Computational Theory of
Grounding in Natural Language Conversation.
Ph.D. thesis, University of Rochester.
Teun A. van Dijk and Walter Kintsch. 1983.
Strategies of Discourse Comprehension. Aca-
demic Press.
Non- Literal Wh-sub Reprise Reprise Gap Gap Conve- Other Total
Reprise Reprise Reprise Sluice Fragmt Filler ntional
Clausal 4.3 4.8 1.0 10.7 25.2 0 0 0 0.5 46.5
Constituent 7.6 0 0 0 1.7 0 0 5.3 0 14.5
Lexical 0.7 0 2.6 2.1 0.2 0.5 3.8 25.0 0 35.0
Correction 1.0 0.5 0 0 1.0 0 0 0 0 2.4
Other 0 0 0 0 1.0 0 0 0.5 0 1.4
Total 13.6 5.3 3.6 12.8 29.1 0.5 3.8 30.7 0.5 100.0
Table 1: CR form and type as percentage of CRs { all domains
Non- Literal Wh-sub Reprise Reprise Gap Gap Conve- Other Total
Reprise Reprise Reprise Sluice Fragmt Filler ntional
Clausal 4.1 4.7 1.0 11.3 24.8 0 0 0 0.5 46.5
Constituent 6.2 0 0 0 1.8 0 0 5.7 0 13.6
Lexical 0.8 0 2.6 2.3 0.3 0.5 3.1 26.3 0 35.9
Correction 1.0 0.5 0 0 1.0 0 0 0 0 2.6
Other 0 0 0 0 0.8 0 0 0.5 0 1.3
Total 12.1 5.2 3.6 13.6 28.6 0.5 3.1 32.5 0.5 100.0
Table 2: CR form and type as percentage of CRs { demographic portion
Distance 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
All domains 8 291 36 16 10 3 4 0 2 2 0 0 0 1 0 1
Demographic 7 264 34 16 9 3 4 0 2 2 0 0 0 1 0 1
Table 3: Number of CRs vs. CR-Source Separation Distance
Figure 1: Percentage of CRs vs. CR-Source Separation Distance
Answering Clarification Questions
Matthew Purver1, Patrick G.T. Healey2, James King2, Jonathan Ginzburg1 and Greg J. Mills2
1Department of Computer Science
King?s College, London
London WC2R 2LS, UK
2Department of Computer Science
Queen Mary, University of London
London E1 4NS, UK
Abstract
This paper describes the results of cor-
pus and experimental investigation into
the factors that affect the way clarifica-
tion questions in dialogue are interpreted,
and the way they are responded to. We
present some results from an investigation
using the BNC which show some general
correlations between clarification request
type, likelihood of answering, answer type
and distance between question and an-
swer. We then describe a new experi-
mental technique for integrating manip-
ulations into text-based synchronous dia-
logue, and give more specific results con-
cerning the effect of word category and
level of grounding on interpretation and
response type.
1 Introduction
Requesting clarification is a vital part of the com-
municative process and has received attention from
both the formal semantic (Ginzburg and Cooper,
2001; Ginzburg and Cooper, forthcoming) and con-
versation analytic traditions (Schegloff, 1987), but
little in the computational dialogue system commu-
nity. In theory, a perfect dialogue system should be
able to interpret and deal with clarification requests
(CRs) made by the user in order to elicit clarifica-
tion of some part of a system utterance, and be able
to request clarification itelf of some part of a user ut-
terance. This is no easy task ? CRs may take many
different forms (often highly elliptical), and can be
intended to be interpreted with many different read-
ings which query different aspects of the original ut-
terance. As a result, dialogue system design has tra-
ditionally attempted to avoid the necessity for CR
interpretation by making system utterances as clear
and precise as possible, and avoid having to generate
all but the most simple CRs by using robust shallow
methods of interpretation or by relying on highly
domain-dependent lexicons and grammars. How-
ever, as systems become more human-like, it seems
likely that we will have to cope with user CRs at
some stage; and the ability to generate system CRs
can be useful in order to repair misunderstanding,
disambiguate other utterances, and learn new words
? see (Knight, 1996; Dusan and Flanagan, 2002;
Purver, 2002).
The investigations presented here had two main
aims: to examine (a) how CRs are interpreted, and
(b) how they are responded to. The two are clearly
dependent ? the response must depend on the inter-
pretation ? but there are many other influencing fac-
tors such as CR form, context and level of ground-
ing. Answers to (a) should help us with the follow-
ing questions:
? What factors can help us disambiguate and cor-
rectly interpret user CRs?
? What factors should govern generation of sys-
tem CRs such that they are correctly interpreted
by the user?
Answers to (b) should help with the following re-
lated questions:
? How (and when) should we answer user CRs?
? How (and when) should we expect users to re-
spond to system CRs?
The paper is organised as follows. The next sec-
tion gives a brief overview of CRs in general and
some previous corpus work. Section 3 describes fur-
ther corpus work which gives some general results
concerning response type. Section 4 then describes
a text-based dialogue experiment examining the de-
tailed effects on interpretation and response of part-
of-speech (PoS) type and level of grounding for one
particular CR form, and section 5 then draws some
general conclusions.
2 Clarification Requests
Purver et al (2001; 2002) presented a taxonomy
of CR forms and readings derived from a corpus
study using the British National Corpus (BNC) ?
see (Burnard, 2000). This showed that some forms
showed a high correlation with certain readings, but
that some were highly ambiguous.
Purver et al (2002)?s taxonomy of CR forms is
given in table 1 and CR readings in table 21. Some
CRs (the non-reprise class) explicitly identify the
clarification required, e.g. ?What did you say?? or
?What do you mean??, and some forms (e.g. literal
reprises) appear to favour a particular reading almost
exclusively, but most are more ambiguous. Indeed,
they found that the two most common forms (the
conventional and reprise fragment form) could take
any reading.
Although this corpus study provided informa-
tion about the distribution of different CR forms
and readings, it did not provide any information
about the specific conditions which prompt partic-
ular readings and affect how the CR is answered.
In this paper we concentrate mostly on the reprise
fragment (RF) form, where only a single part of
the problem utterance, possibly a single word, is
reprised2 as in example (1). This form is not only
1They also give a correction reading, which we have ex-
cluded here: such CRs are almost exclusively self-corrections
and as such do not fit well with our discussion here. They are
also very rare compared with the other classes, making up only
about 2% of CRs.
2Such reprises need not be verbatim repeats: users may use
anaphoric terms or use a clearer expression in order to clarify
the fragment in question.
common (approximately 30% of CRs in the previ-
ous study) and can appear with many readings (al-
though biased towards a clausal reading ? 87% of
occurrences), but specifies the problematic element
that it clarifies quite precisely, and therefore should
give us scope for examining the effect of features of
that element.
(1)3
Gary: Aye, but <pause> you
know <pause> like you
se- she mentioned one in
particular, like
Jake: What?
Gary: the word skeilth
Jake: Skeilth?
Lilias: Mm.
Gary: Aha.
Jake: Aye, yeah, yeah, take skeilth.
Intuitively, at least two such features would be
expected to affect the type of reading assigned to
a RF: PoS category and level of grounding.4 The
PoS category of the reprised word should influence
expectations about what is being clarified. For ex-
ample, reprise of a content word (e.g. noun or verb)
should be more likely to signal a constituent problem
than a reprise of a function word (e.g. preposition or
determiner). Dialogue participants would normally
assume that the meaning of function words is well
known in a particular linguistic community and that,
as a result, a reprise of a function word is more likely
to signal clausal or lexical problems. RF interpreta-
tion should also depend on whether a reprised frag-
ment is already considered to have been grounded
by the participants in a conversation. For example,
a reprise of a proper noun would be more likely to
be read as signalling a constituent problem if it oc-
curs on the first mention than on second mention.
All things being equal, the content of a constituent
is already considered to have been established by the
time a second mention occurs.
3 Corpus Investigation
Accordingly we have re-examined the corpus from
the above study in order to add information about
3BNC file KPD, sentences 578?584
4Another is intonation. However, there is no intonational
information in the BNC. In the future we hope to investigate
this using other corpora and experimental methods.
Class Description Example
non Non-Reprise ?What did you say??
wot Conventional ?Pardon??
frg Reprise Fragment ?Paris??
slu Reprise Sluice ?Where??
lit Literal Reprise ?You want to go to Paris??
sub Wh-Subsituted Reprise ?You want to go where??
gap Gap ?You want to go to . . . ??
fil Gap Filler ?. . . Paris??
oth Other Other
Table 1: CR forms
Class Description Paraphrase
cla Clausal ?Are you asking/telling me that . . . X . . . ??
con Constituent ?What/who do you mean by ?X???
lex Lexical ?Did you utter ?X???
oth Other Other
Table 2: CR readings
category, grounding and method of answering.
3.1 Method
The same corpus was re-marked for four attributes:
response type and CR-answer distance, and the PoS
and last mention of the original source element.
The markup scheme used for response type
evolved during the study and is shown in table 3:
it includes classification of apparently unanswered
CRs into those that may have been answered, but
the sentence possibly containing an answer was tran-
scribed in the BNC as <unclear>; those that ap-
pear to have remained unanswered because the CR
initiator continued their turn without pause; and
those that are not answered at all (or at least where
we have no indication of an answer ? eye contact,
head movement etc. are not recorded in the BNC but
could function as answers). In cases where the ini-
tial response was followed by further information,
both were recorded, but the results here are pre-
sented only for the initial response. Further work
later may take both into account, along the lines of
(Hockey et al, 1997) who showed this to be impor-
tant for questions in general.
CR-answer distance was marked in terms of the
sentence numbering scheme in the BNC ? in these
cases it corresponds very closely to distance in
speaker turns, although the correspondence is not
exact.
PoS category and time of last mention of the
source element were marked, but have not currently
been used due to lack of useful data (see below).
Reliability of the markup has not yet been exam-
ined. However, the method is close to that of (Purver
et al, 2002) (and the corpus is identical), where re-
liability was examined and found to be acceptable.
We then examined the correlation between CR type
and response type, between reading and response
type, and the spread of CR-answer distance.
3.2 Results
3.2.1 Response Type
Results for response type are shown in table 4 as
raw numbers, and also in table 5 as percentages for
each CR type, with the none, cont, uncl and qury
classes conflated as one ?unanswered? class, and
only the most common 4 CR forms shown.
The most striking result is perhaps the high over-
all number of CRs that do not receive an answer:
39% of all CRs do not appear to be answered overall,
although this reduces to 17% when taking account
of those marked uncl (possible answers transcribed
none No answer
cont CR initiator continues immediately
uncl Possible answer but transcribed as <unclear>
qury CR explicitly queried
frg Answered with parallel fragment
sent Answered with full sentence
yn Answered with polar particle
Table 3: CR response types
as <unclear>) and cont (the CR-raiser continues
without waiting). The most common forms (conven-
tional and RF) appear to be answered least ? around
45% go unanswered for both. The form which ap-
pears to be most likely to be answered overall is the
explicit non-conventional form.
Some forms appear to have high correlations
with particular response types. As might be ex-
pected, sluices (which are wh-questions) are gen-
erally answered with fragments, and never with a
polar yes/no answer. Yes/no answers also seem to
be unsuitable for the conventional CR form, which
is generally answered with a full sentence. RFs,
conversely, are not often answered with full sen-
tences, but can be responded to either by fragments
or yes/no answers.
Similarly, from tables 6 and 7 (again, percentages
given for each CR reading, with ?unanswered? re-
sponse types conflated and only the most common 3
readings shown) we can see that there is a correla-
tion between reading and response type, but that this
correlation is also not as simple as a direct reading-
answer correspondence. Clausal CRs are unlikely to
be answered with full sentences, but can get either
fragment or yes/no responses. Constituent CRs are
less likely to get yes/no responses but could get ei-
ther other type. Interestingly, constituent CRs seem
to be roughly twice as likely to get a response as
clausal or lexical CRs (even though there are fewer
examples of constituent CRs than the others, this
difference is statistically significant, with a ?2(1) test
showing <0.5% probability of independence).
3.2.2 Answer Distance
Results for CR-answer distance are shown in ta-
ble 8. It is clear that the vast majority (94%) of CRs
that are answered are answered in the immediately
unans frg sent yn
wot 45.6 8.7 44.8 0.8 (100)
frg 43.2 21.1 3.4 32.2 (100)
slu 37.0 50.0 12.9 0 (100)
non 13.4 26.9 26.9 32.6 (100)
Table 5: BNC results: Response type as percentages
for each CR form
unans frg sent yn
cla 39.8 22.2 7.8 30.0 (100)
con 20.0 35.0 33.3 11.6 (100)
lex 42.7 17.2 36.5 3.4 (100)
Table 7: BNC results: Response type as percentages
for each CR reading
1 2 3 >3 Total
Distance 273 14 2 0 289
Table 8: CR-answer distance (sentences)
following sentence, and that none are left longer
than 3 sentences. While we do not yet have concrete
equivalent figures for non-clarificational questions,
a study is in progress and initial indications are that
in general, answers are less immediate: only about
70% have distance 1, with some up to distance 6.5
We therefore expect that (a) answering user CRs
must be done immediately, and that any dialogue
management scheme must take this into account,
and (b) we should expect answers to any system
CRs to come immediately ? interpretation routines
(we are thinking especially of any ellipsis resolution
routines here) should not assume that later turns are
5Thanks to Raquel Ferna?ndez for providing us with these
preliminary figures.
none cont uncl qury frg sent yn Total
wot 21 13 24 0 11 57 1 127
frg 23 22 6 0 25 4 38 118
slu 8 6 5 1 27 7 0 54
non 4 2 1 0 14 14 17 52
lit 5 2 1 0 1 1 10 20
fil 3 0 1 0 7 1 4 16
sub 4 0 3 0 4 4 0 15
gap 1 0 0 0 1 0 0 2
oth 0 0 0 1 0 1 0 2
Total 69 45 41 2 90 89 70 406
Table 4: BNC results: Response type vs. CR form
none cont uncl qury frg sent yn Total
cla 33 31 11 2 43 15 58 193
con 9 3 0 0 21 20 7 60
lex 21 11 30 0 25 53 5 145
oth 5 0 0 0 0 1 0 6
Total 69 45 41 2 90 89 70 406
Table 6: BNC results: Response type vs. CR reading
relevant to the CR.
3.2.3 Further Details
While interesting, we would like to know more
detail than the general trends described above: in
particular we would like to know the effect of
the factors we have mentioned (word category and
grounding) for particular forms. As stated above,
we concentrate here on the reprise fragment form.
Examination of original CR source fragment PoS
category, in order to test the effect of the con-
tent/function distinction, showed that almost all RFs
were of content words or whole phrases: only 6 of
118 RFs were of function words, all of which were
determiners (mostly numbers). This is interesting in
itself: perhaps RFs are unlikely to be used to clarify
uses of e.g. prepositions. However, the effect may
be due to lack of data, and does not provide us with
any way of testing the distinction between clausal
and constituent reading that we expect.
Markup of last mention of the original source
fragment has also not given results in which we can
be confident. For RFs, we have seen that all con-
stituent readings occur on the first mention of the
fragment (as expected) ? but there are too few of
these examples to draw any firm conclusions. It is
also impossible to know whether first mention in the
transcription is really the first mention between the
participants: we do not know what happened before
the tape was turned on, what their shared history is,
or what is said during the frequent portions marked
as <unclear>.
So we need more information than our current
corpus can provide. In order to examine these ef-
fects properly we have therefore designed an exper-
imental technique to allow dialogues to be manipu-
lated directly, with reprises with the desired proper-
ties automatically introduced into the conversation.
The next section describes this technique and the ex-
periment performed.
4 Experimental Work
Empirical analyses of dialogue phenomena have
typically focused either on detailed descriptive anal-
yses of corpora of conversations (Schegloff, 1987)
or on the experimental manipulation of relatively
global parameters of interaction such as task type or
communicative modality (Clark and Wilkes-Gibbs,
1986), (Garrod and Doherty, 1994). These stud-
ies have been used to to motivate a variety of pro-
posals about turn-level mechanisms and procedures
that sustain dialogue co-ordination. Further devel-
opment and testing of these proposals has, how-
ever, been limited by the indirect nature of the avail-
able evidence. Corpus studies provide, retrospec-
tive, correlational data which is susceptible to chal-
lenge and re-interpretation. Current psycholinguis-
tic techniques do not provide ways of integrating ex-
perimental manipulations into interactions in a man-
ner that is sensitive to the linguistic and conversa-
tional context. This section introduces a technique
for carrying out experiments in which text-based in-
teractions can be directly manipulated at the turn
level, and gives the results of an experiment which
uses this approach to investigate the effects of the
factors mentioned above on interpretation and re-
ponse to RFs. We also briefly discuss the range of
potential applications and some of the practical lim-
itations of the approach in the context of the experi-
mental results.
4.1 Manipulating ?Chat? Interactions
The experimental technique presented here draws on
two general developments. Firstly, the increasing
use of text-based forms of synchronous conversa-
tional interaction, for example: chat rooms (MUD?s,
MOO?s etc.), instant messaging, and some online
conferencing tools. Secondly, advances in natural
language processing technology which make some
forms of text processing and transformation fast
enough to be performed on a time scale consistent
with exchanges of turns in synchronous text chat.
The basic paradigm involves pairs of subjects,
seated in different rooms, communicating using a
synchronous text chat tool (see figure 1 for an ex-
ample). However, instead of passing each completed
turn directly to the appropriate chat clients, each turn
is routed via a server. Depending on the specific
goals of the experiment, the server can be used to
systematically modify turns in a variety of ways. For
example, some simple forms of mis-communication
can be introduced into an interaction by transform-
ing the order of characters in some of the input
words or by substituting words with plausible non-
words. Importantly, the server controls which mod-
ifications are broadcast to which participant. So, if
participant A types the word ?table? the sever can
echo back A: table to participant A and a trans-
formed version, say, ?blate? to participant B who
sees A: blate. The ability to set up controlled
asymmetries of this kind between the participants in
a interaction creates a powerful range of experimen-
tal possibilities. Here, we describe an application of
this technique to the investigation of reprise clarifi-
cation requests (CR?s).
A chat-tool experiment was designed to test the
following hypotheses:
1. RFs for function words will normally receive
clausal readings, whereas both clausal and con-
stituent readings will be available for content
words.
2. RFs for content words will receive more con-
stituent readings on first mention than on sec-
ond mention.
3. No difference is predicted for RFs for function
words on first vs. second mention.
4.2 Method
Two tasks were used to elicit dialogue, a balloon
debate and a story-telling task. In the balloon de-
bate subjects are presented with a fictional scenario
in which a balloon is losing altitude and about to
crash. The only way for any of three passengers to
survive is for one of them to jump to a certain death.
The three passengers are; Dr. Nick Riviera, a can-
cer scientist, Mrs. Susie Derkins, a pregnant primary
school teacher, and Mr. Tom Derkins, the balloon
pilot and Susie?s husband. Subjects are asked to de-
cide who should jump. The advantages of this task
are that it is effective at generating debates between
subjects and involves repeated references to particu-
lar individuals.
Following (Bavelas et al, 1992), the second di-
alogue task used was the story-telling task. In this
case subjects are asked to relate a ?near-miss? story
about some experience in which something bad al-
most happened but in the end everything was okay.
This was chosen because, unlike the balloon task,
the topic of the exchange is unrestricted, in effect
a random factor, and the interaction relates to real
events.
4.2.1 Subjects
Twenty-eight subjects were recruited, 20 male
and 8 female, average age 19 years, from computer
science and IT undergraduate students. They were
recruited in pairs to ensure that the members of a
pair were familiar with one another and only sub-
jects who had experience with some form of text
chat such as chat rooms, IRC, ICQ or other mes-
saging systems were used. Each subject was paid
at a rate of ?7.50 per hour for participating in the
experiment.
4.2.2 Materials
A custom experimental chat tool, written in Java
and Perl, was used for the experiment. The user in-
terface is similar to instant messaging applications:
a lower window is used to enter text, and the con-
versation is displayed in the main upper window as
it emerges (see figure 1). The chat clients were run
on two Fujitsu LCD tablet computers with text in-
put via standard external keyboards, with the server
running on a standard PC in a separate room.
User Interface The Chattool client user interface
is written in Java and is designed to be familiar
to subjects experienced with instant messaging/chat
applications. The application window is split into
two panes: a lower pane for text entry and an up-
per pane in which the conversation is displayed (see
figure 1). A status display between the two panes
shows whether the other participant is active (typ-
ing) at any time. This can be artificially controlled
during the generation of artificial turns to make it
appear as if they are generated by the other partici-
pant. The client also has the ability to display an er-
ror message and prevent text entry: this can be used
to delay one participant while the other is engaged
in an artificially-generated turn sequence.
Server Each turn is submitted to a server (also
written in Java) on a separate machine when a ?Send?
button or the ?Return? key is pressed. This server
passes the text to a NLP component for processing
and possible transformation, and then displays the
original version to the originator client, and the pro-
cessed (or artificially generated) version to the other
client. The server records all turns, together with
each key press from both clients, for later analysis.
This data is also used on the fly to control the speed
and capitalisation of artificially generated turns, to
be as realistic a simulation of the relevant subject as
possible.
NLP Component The NLP component consists
of a Perl text-processing module which commu-
nicates with various external NLP modules as re-
quired: PoS tagging can be performed using LT-
POS (Mikheev, 1997), word rarity/frequency tag-
ging using a custom tagger based on the BNC (Kil-
garriff, 1997), and synonym generation using Word-
Net (Fellbaum, 1998).
Experimental parameters are specified as a set of
rules which are applied to each word in turn. Pre-
conditions for the application of the rule can be spec-
ified in terms of PoS, word frequency and the word
itself, together with contextual factors such as the
time since the last artificial turn was generated, and
a probability threshold to prevent behaviour appear-
ing too regular. The effect of the rule can be to
transform the word in question (by substitution with
another word, a synonym or a randomly generated
non-word, or by letter order scrambling) or to trigger
an artificially generated turn sequence (currently a
reprise fragment, followed by an acknowledgement,
although other turn types are possible).
The current experimental setup consists of rules
which generate pairs of RFs and subsequent
acknowledgements6, for proper nouns, common
nouns, verbs, determiners and prepositions, with
probabilities determined during a pilot experiment
to give reasonable numbers of RFs per subject. No
use is made of word rarity or synonyms.
The turn sequences are carried out by (a) present-
ing the artificially-generated RF to the relevant client
only; (b) waiting for a response from that client, pre-
venting the other client from getting too far ahead
by locking the interface if necessary; (c) presenting
an acknowledgement to that response; and (d) pre-
senting any text typed by the other client during the
sequence.
4.2.3 Procedure
Prior to taking part subjects were informed that
the experimenters were carrying out a study of the
effects of a network-based chat tool on the way peo-
6Acknowledgements are randomly chosen amongst: ?ah?,
?oh?, ?oh ok?, ?right?, ?oh right?, ?uh huh?, ?i see?, ?sure?.
ple interact with one another. They were told that
their interaction would be logged, anonymously, and
kept for subsequent analysis. Subjects were advised
that they could also request the log to be deleted af-
ter completion of the interaction. They were not in-
formed of the artificial interventions until afterwards
(see below).
At the start of the experiment subjects were given
a brief demonstration of the operation of the chat
tool.
To prevent concurrent verbal or gestural interac-
tion subjects were seated in separate rooms. Each
pair performed both dialogue tasks and were given
written instructions in each case. The balloon task
was carried out once and the story-telling task twice;
one story for each participant. To control for or-
der effects the order of presentation of the two tasks
was counterbalanced across pairs. A 10-minute time
limit was imposed on both tasks. At the end of
the experiment subjects were fully debriefed and the
intervention using ?artificial? clarifications was ex-
plained to them.
This resulted in a within-subjects design with two
factors; category of reprise fragment and level of
grounding (first vs. second mention).
After the experiment, the logs were manually cor-
rected for the PoS category of the RF and for the
first/second mention clarification. PoS required cor-
rection as the tagger produced incorrect word cate-
gories in approximately 30% of cases. In some in-
stances this was due to typing errors or text-specific
conventions, such as ?k? for ?okay?, that were not
recognised. Detection and classification of proper
nouns was also sensitive to capitalisation. Subjects
were not consistent or conventional in their capitali-
sation of words and this caused some misclassifica-
tions. In addition a small proportion of erroneous
tags were found. Each system-generated CR was
checked and, where appropriate, corrected. Because
pairs completed both tasks together CRs classified
as ?first mentions? were checked to ensure that they
hadn?t already occured in a previous dialogue.
4.3 Results
The readings attributed to each RF were classified
in the same way as the original BNC-based cor-
pus, with the addition of one further category: non-
clarificational, referring to situations in which the
fragment is treated as something other than a CR
(this did not apply when building the original cor-
pus, as only utterances treated as CRs were con-
sidered). In the experimental results, gap, lexical
and non-clarificational readings were low frequency
events (4, 1 and 8 instances respectively) and no in-
stances of correction readings were noted. These fig-
ures are comparable with (Purver et al, 2002)?s ob-
servations for the BNC. For statistical analysis these
three categories of reading were grouped together as
?Other?.
Across the corpus as a whole a total of 215
system-generated RFs were produced. In 50% of
cases the system-generated clarification received no
response from the target participant. This may be
due in part to the medium: unlike verbal exchanges,
participants in text-chat can produce their turns si-
multaneously. This can result in turns getting out
of sequence since users may still be responding to a
prior turn when a new turn arrives. Users must then
trade off the cost of undoing their turn in progress
to respond to the new one, against going ahead any-
way and responding to the new turn later if it seems
necessary. Thus in some cases we observed that the
response to a clarification was displaced to the end
of the turn in progress or to a subsequent turn. How-
ever, comparison with the BNC results from sec-
tion 3 above show similar figures: only 56% of the
frg class received a clear answer. Although the
true figure will be higher (of the 56%, 5% may have
been answered, but the next turn was transcribed as
<unclear>, and we cannot know in how many
cases the reprise may have been answered using
non-verbal signals), it seems likely that a significant
proportion may simply be ignored.
Response Category
Category None Con Cla Other
Cont (1st) 29 14 23 4
Cont (2nd) 43 7 16 9
Func (1st) 6 0 0 6
Func (2nd) 20 0 1 9
Table 9: Frequency of Reading Types By RF Cate-
gory and Mention
The distribution of reading types according to
word category was tested firstly by comparing the
frequency of Clausal, Constituent, and Other read-
ings for content words and function words. This
proved to be reliably different (?2(2) = 35.3, p =
0.00).7 As table 9 shows, RFs of Function words
were almost exclusively interpreted as Other, i.e. ei-
ther Gap, Lexical or Non-clarificational. By contrast
Content word reprises were interpreted as Clausal
CRs 53% of the time, as Constituent CRs 29% of
the time and as Other 18% of the time.
Content word and Function word clarifications
were also compared for the the frequency with
which they received a response. This showed no
reliable difference (?2(1) = 1.95, p = 0.16) indicat-
ing that although the pattern of interpretation for
Content and Function reprises is different they are
equally likely to receive some kind of response.
The influence of grounding on reading type was
assessed firstly by comparing the relative frequency
of Constituent, Clausal and Other readings on first
and second mention. This was reliably different
(?2(2) = 6.28, p = 0.04) indicating that level of
grounding affects the reading assigned. A focussed
comparison of Constituent and Clausal readings on
first and second mention shows no reliable differ-
ence (?2(1) = 0.0, p = 0.92). Together these findings
indicate that, across all word categories, Constituent
and Clausal readings are more likely for RF?s of a
first mention than a second mention and, conversely,
Other readings are less likely for RF?s to a first men-
tion than a second mention.
The effect of grounding on the relative frequency
with which a clarification received a response was
also tested. This indicated a strong effect of mention
(?2(1) = 12.01, p = 0.00); 58% of reprise clarifications
of first mentions recieved a response whereas only
33% of second mention clarifications did.
4.4 Discussion
The experimental results support two basic conclu-
sions. Firstly, people?s interpretation of the type of
CR a reprise fragment is intended to make is influ-
enced both by the category of the reprise fragment
and its level of grounding. Secondly, reprise frag-
ment CRs to first mentions are much more likely to
be responded to than reprise fragment CRs for sec-
7A criterion level of p < 0.05 was adopted for all statistical
tests.
ond mentions.
Text-based and verbal interaction have different
properties as communicative media. Amongst other
things, in text-chat turns take longer to produce,
are normally produced in overlap, and they persist
for longer. However, even given these differences,
the general pattern of clarifications observed in the
experimental task is similar to that noted in ver-
bal dialogue. In particular, Lexical, Gap and Non-
clarificational readings are infrequent and reprise
fragment clarifications are ignored with surprising
frequency. In the present data, the clearest contrast
between text-based and verbal interaction is in the
relative frequency of Constituent and Clausal read-
ings. In the BNC reprise fragments receive Clausal
readings in 87% of cases, and constituent readings in
6% of cases. In the experimental corpus they receive
Clausal readings in 48% of cases and Constituent
readings in 34% of cases.
These findings demonstrate the viability, and
some limitations, of investigating dialogue co-
ordination through the manipulation of chat-tool
based interactions. The chat tool was successful
in producing plausible clarification sequences. Al-
though in some cases participants had difficulty
making sense of the artificial clarifications this did
not make them distinguishable from other, real, but
equally problematic turns from other participants.
The clarifications were mostly successful in creat-
ing realistic exchanges such as those illustrated in
figures 2 and 3. When questioned during debriefing,
no participants reported any suspicions about the ex-
perimental manipulation.
The main practical difficulty encountered in the
present study related to text-chat conventions such
as novel spellings, abbreviations, and use of ?smi-
leys?. This created specific problems for the PoS
tagger which assumes a more standard form of En-
glish. These problems were also compounded by the
noise introduced by typing errors and inconsistency
in spelling and capitalisation.
The experiment presented here exploits only one
possibility for the use of this technique. Other
prossible manipulations include; manipulation of
distance, in turns or time, between target and probe,
substitution of synonyms, hyponyms and hyper-
nyms, introduction of artifical turns, blocking of
certain forms of response. The important potential
it carries, particularly in comparison with corpus-
based techniques, is in the investigation of dialogue
phenomena which for various reasons are infrequent
in existing corpora.
5 Conclusions
The main conclusions we draw from the results pre-
sented here are as follows:
? Reprise CRs appear to go without response far
more often than might be expected, both in the
BNC and in our experimental corpus. Both
may be effects of the media (transcription in
one case, turn sequencing overlap in the other),
but the figures are large enough and similar
enough to warrant further investigation.
? Corpus investigation shows some strong corre-
lations between CR form and expected answer
type. It also shows that responses to CRs, when
they come, come immediately.
? Both word PoS category and first/second men-
tion appear to be reliable indicators of RF read-
ing. This can help us in disambiguating user
CRs, and in choosing forms when generating
system CRs.
? RFs generated on the first mention of a word
have a higher likelihood of receiving a response
than on second mention.
? We have presented a new experimental tech-
nique for manipulating dialogue, which we be-
lieve has many potential uses in dialogue re-
search.
6 Acknowledgments
This work was supported by the EPSRC under the
project ?ROSSINI: Role of Surface Structural Infor-
mation in Dialogue? (GR/R04942/01).
References
J.B. Bavelas, N. Chovil, D. Lawrie, and L. Wade. 1992.
Interactive gestures. Discourse Processes, 15:469?
489.
Lou Burnard. 2000. Reference Guide for the British
National Corpus (World Edition). Oxford University
Computing Services.
Herbert H. Clark and Deanna Wilkes-Gibbs. 1986. Re-
ferring as a collaborative process. Cognition, 22:1?39.
Sorin Dusan and James Flanagan. 2002. Adaptive dialog
based upon multimodal language acquisition. In Pro-
ceedings of the Fourth IEEE International Conference
on Multimodal Interfaces, Pittsburgh, October.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. MIT Press.
Simon Garrod and Gwyneth Doherty. 1994. Conversa-
tion, co-ordination and convention: an empirical in-
vestigation of how groups establish linguistic conven-
tions. Cognition, 53:181?215.
Jonathan Ginzburg and Robin Cooper. 2001. Resolv-
ing ellipsis in clarification. In Proceedings of the 39th
Meeting of the ACL, pages 236?243. Association for
Computational Linguistics, July.
Jonathan Ginzburg and Robin Cooper. forthcoming.
Clarification, ellipsis, and the nature of contextual up-
dates. Linguistics and Philosophy.
Beth Ann Hockey, Deborah Rossen-Knill, Beverly Spe-
jewski, Matthew Stone, and Stephen Isard. 1997. Can
you predict answers to Yes/No questions? Yes, No and
Stuff. In Proceedings of Eurospeech ?97.
Adam Kilgarriff. 1997. Putting frequencies in the
dictionary. International Journal of Lexicography,
10(2):135?155.
Kevin Knight. 1996. Learning word meanings by in-
struction. In Proceedings of the Thirteenth National
Conference on Artifical Intelligence, pages 447?454.
AAAI/IAAI.
A. Mikheev. 1997. Automatic rule induction for un-
known word guessing. Computational Linguistics,
23(3):405?423.
Matthew Purver, Jonathan Ginzburg, and Patrick Healey.
2001. On the means for clarification in dialogue. In
Proceedings of the 2nd ACL SIGdial Workshop on Dis-
course and Dialogue, pages 116?125. Association for
Computational Linguistics, September.
Matthew Purver, Jonathan Ginzburg, and Patrick Healey.
2002. On the means for clarification in dialogue.
In R. Smith and J. van Kuppevelt, editors, Current
and New Directions in Discourse & Dialogue. Kluwer
Academic Publishers.
Matthew Purver. 2002. Processing unknown words in a
dialogue system. In Proceedings of the 3rd ACL SIG-
dial Workshop on Discourse and Dialogue, pages 174?
183. Association for Computational Linguistics, July.
E. Schegloff. 1987. Some sources of misunderstanding
in talk-in-interaction. Linguistics, 25:201?218.
Figure 1: Chattool Client Interface
Subject A?s View Subject B?s View
A: Obviously the relatives
were coming around like
they do to see me
B: Obviously the relatives
were coming around like
they do to see me
Probe ? A: relatives?
Block B: Yeah just unts and uncles
Ack ? A: ah
A: yeah B: yeah
Figure 2: Story Telling Task Excerpt, Noun Clarification, Subjects 1 & 2
Subject A?s View Subject B?s View
A: so we agree B: so we agree
B: agree? ? Probe
A: yeah to chuck out Susie
derkins
Block
B: uh huh ? Ack
A: yes B: yes
Figure 3: Balloon Task Excerpt, Verb Clarification, Subjects 3 & 4
Proceedings of the 9th SIGdial Workshop on Discourse and Dialogue, pages 46?53,
Columbus, June 2008. c?2008 Association for Computational Linguistics
Semantic negotiation in dialogue: the mechanisms of alignment
Gregory J. Mills
Interaction, Media and Communication
 Research Group
Department of Computer Science
Queen Mary, University of London
London E1 4NS
gj@dcs.qmul.ac.uk
Patrick G.T. Healey
Interaction, Media and Communication
 Research Group
Department of Computer Science
Queen Mary, University of London
London E1 4NS
ph@dcs.qmul.ac.uk
Abstract
A key problem for models of  dialogue  is  to 
explain  how  semantic  co-ordination  in  dia-
logue  is  achieved  and  sustained.  This  paper 
presents findings from a series of Maze Task 
experiments  which are  not  readily explained 
by the primary co-ordination mechanisms of 
existing  models.  It  demonstrates  that  align-
ment in dialogue is not simply an outcome of 
successful  interaction,  but  a  communicative 
resource  exploited  by  interlocutors  in  con-
verging on a semantic model. We argue this 
suggests mechanisms of co-ordination in dia-
logue which are of relevance for a general ac-
count  of  how  semantic  co-ordination  is 
achieved.
1 Introduction
One of the first things apparent to European trav-
ellers on arriving at an American hotel is that the 
ground floor is also the first floor. Any confusion 
can  be  quickly  corrected  by  an  observant 
concierge,  whether  by explicitly  stating  the  con-
vention,  or  by  implicitly  bypassing  the  problem 
with  a  different  description,  such  as  ?go  up  5 
flights of stairs?. Assuming this description is suf-
ficient to guide the hapless traveller to the correct 
room, when the same traveller asks for assistance 
to find another part of the hotel, the concierge is 
faced with a choice of whether to give a descrip-
tion involving floor numbers or in terms of flights 
of stairs.
   The immediate  question that  emerges  is  what 
motivates  this  choice  between different  semantic 
models of a domain, how they are deployed when 
interlocutors  are  faced  with  problematic  under-
standing, and which semantic model is subsequent-
ly used once the problem is resolved. Although ex-
isting approaches to dialogue agree that answering 
this question necessarily involves focusing on the 
interactional  devices  available  to  interlocutors, 
their  primary emphasis  is  on the information-ex-
change  aspects  of  language  use.  Larsson  (2007) 
provides a useful distinction between the co-ordi-
nation  of  information,  i.e.  establishing  common 
ground (Clark, 1996) and the co-ordination of lin-
guistic resources which are adapted to suit particu-
lar communicative situations in order to make such 
information-exchange possible. Part of this frame-
work involves interlocutors negotiating which par-
ticular semantic model  to use, and adapting their 
own interpretations on the basis of successful/un-
succesful use.  However, although this framework 
sketches out a formal account of the mechanisms 
involved in this process, it is not concerned with 
predicting which particular semantic model will be 
adopted by interlocutors.
    A model of dialogue which attempts to address 
this  issue  is  the  interactive  alignment  model  of 
Pickering and Garrod (2004). In this model conver-
gence on a semantic model is arrived at via tacit 
priming  occurring  at  all  levels  of  representation 
(phonetic, phonological, lexical, syntactic, seman-
tic and situational): interlocutors are more likely to 
re-use  the  representations  used  by  their  partner, 
giving  rise  to  a  ?winner-takes-all?  dynamic  (cf. 
Steels  & Belpaeme,  2005)  which leads  to  align-
46
ment of interlocutors' representations. This is fur-
ther  re-inforced  by  ?percolation?  occurring  be-
tween levels, thus lexemes associated with particu-
lar semantic models will reinforce the use of these 
models.
     The claims associated with the interactive align-
ment model (henceforth IM) are drawn from a se-
ries of maze task experiments (Garrod & Doherty 
1994; Garrod and Anderson, 1987; Anderson and 
Garrod,  1987).  This paper discusses some of the 
original findings of these experiments and a further 
set of maze task experiments conducted by Healey 
and Mills (2006), Mills and Healey (2006).  These 
papers argued that the primary mechanisms provid-
ed  by the  IM are  insufficient  for  explaining  ob-
served patterns in maze task dialogue; in particular 
how  semantic  co-ordination  is  achieved.  The 
present paper argues that interlocutors in the Maze 
task exploit variation in usage in the service of se-
mantic  co-ordination.  Furthermore  we  argue  this 
suggests  mechanisms which are relevant for a gen-
eral  account  of  how  semantic   co-ordination  is 
achieved in dialogue. As the claims developed here 
are based on the maze task, we first  explain the 
task in more detail.  We then discuss a series of ex-
amples drawn from this task that raise basic issues 
for models of semantic co-ordination.
Figure 1: Example maze configuration. The solid 
black circle shows the player's current position, the 
cross represents the goal point that the player must 
reach,  solid  bars  the  gates  and  shaded  areas  the 
switch points. 
2 The maze task
The maze task developed by Garrod et alinvolves 
pairs  of  participants  seated  in  separate  rooms  in 
front of a computer which displays a simple maze 
consisting  of  interconnected   nodes  (see  Fig  1). 
Participants  must  move  their  respective  position 
markers  through  the  maze  in  order  to  reach  a 
?goal?  node.  Some  of  the  paths  are  blocked  by 
gates,  which  are  opened  by  participants  guiding 
each  other  onto  ?switch?  nodes  (shaded  areas). 
This  provides  participants  with  the  recurrent  co 
-ordination problem of collaboratively individuat-
ing  and  referring  to  maze  locations  in  order  to 
solve the maze. The descriptions used by partici-
pants to refer to maze locations are classified by 
Garrod et al into four distinct types:
Figural: Picks out salient features of the maze:
?The l-shape sticking out at the top?
?The uppermost box?
Path: Traces  a  route  along  the  connections 
between nodes:
?Go 2 up, 1 down, 3 along, 5 up?
?up, right, down, up ?
Line: Treats the maze as consisting of hori-
zontal or vertical vectors:
?3rd row, 5th box?
?4th column, second square?
Matrix: Cartesian co-ordinate system:
?4,2?
?A1?
It is assumed that these different description types 
correspond  to  different  semantic  models  of  the 
maze. 
3 Conservatism
The first question, also raised by Healey and Mills 
(2006),  concerns the tension between the interac-
tive alignment model's inherently conservative pri-
mary co-ordination mechanism and the migration 
in  description  types  commonly  observed  in  the 
Maze task.  To the extent that it relies on priming 
as its basic mechanism the IM cannot provide an 
account  of  how once a convention is  established 
and used successfully,  it  might  be supplanted by 
47
another.. However, it is consistently observed that 
the description types used most frequently initially 
fall into disuse and are not converged on in later 
games. Across trials there is a general shift from 
more ?concrete? (Figural and Path) descriptions to-
wards more ?abstract? (Line and Matrix) descrip-
tions, which runs counter to precedence. A typical 
pattern of the shift is given in table 1, below:
0 mins: The piece of the maze sticking out
2 mins: The left hand corner of the maze
5 mins: The northenmost box
10 mins: Leftmost square of the row on top 
15 mins: 3rd column middle square
20 mins: 3rd column 1st square
25 mins: 6th row longest column
30 mins: 6th row 1st column
40 mins: 6 r, 1 c
45 mins: 6,1
Table  1:  Semantic  shift  from  ?Figural?  and 
?Path? descriptions to ?Line? and ?Matrix? ob-
served in maze task dialogues.
Garrod (1999) discusses this process as an ?explo-
ration? process. However, this, in itself, doesn't ex-
plain the systematic patterns of change observed in 
the experiments.
4  Variation
The  early  explanations  of  co-ordination  in  the 
Maze  Task  also  emphasized  the  importance  of 
variation in the description types  participants are 
exposed to.  Garrod and Doherty (1994) assigned 
participants  to  one  of  three  different  groups:  (1) 
isolated pairs who always interacted with the same 
partner in subsequent games, (2) a sub-community 
group whose  members  changed partners  in  each 
game,  only  interacting  with  members  from  the 
same  sub-community,  and  (3)  a  non-community 
group  whose  members  always  interacted  with  a 
new partner  who  was  not  drawn  from the  same 
community.  Although  initially  pairs  in  the  sub-
community group were less co-ordinated than the 
isolated pairs, using a wider variety of referring ex-
pressions,  by the later  trials,  this  pattern was re-
versed:  participants  in  the  sub-community  group 
had converged on a single Matrix scheme and con-
sistently matched each other's descriptions.
   These findings present a problem for accounts of 
co-ordination which rely on priming, as they make 
the emphasis of the priority of alignment of repre-
sentations at all levels problematic.  The metaphor 
of two tightly-coupled production and comprehen-
sion systems is the paradigm case of successful co-
ordination, as it allows rapid priming between in-
terlocutors' representations.  However, these exper-
iments show weaker semantic co-ordination in the 
isolated dyads  than within the  group.  As  Garrod 
and Doherty (1994) concur, this implies that varia-
tion,  i.e.   differences  in interlocutors'  representa-
tions  is  important  for  establishing and sustaining 
semantic co-ordination.
5 Granularity of analysis
If variation of description types is intrinsic to the 
development  of  semantic  co-ordination,  this 
strongly  suggests  the  importance  of  mechanisms 
involved in dealing with problematic understand-
ing (Healey, forthcoming). All things being equal, 
variation increases the likelihood that interlocutors 
will encounter others whose use of language will 
differ more from their own. Further, any account of 
misunderstandings must also be able to address  se-
mantic  differences  between  descriptions:  partici-
pants in the maze task do not treat these four de-
scription types  equally, and consequently are not 
appropriately modelled as co-ordination equilibria 
of  the  kind  described  by  Lewis  (1968)  (Healey, 
2004;  forthcoming).  Existing  experimental  data 
shows that participants systematically favour Figu-
ral and Path descriptions when encountering prob-
lematic dialogue (Mills and Healey, 2006; Healey, 
1997) not the prior most frequently used semantic 
model as predicted by the IM.
 Looking more closely at the dialogues, it is not 
clear  that  the  co-ordination  mechanisms  actually 
operate directly at the level of the four basic se-
mantic models. Consider the following excerpt in 
which a participant  encounters difficulties with a 
Line description type  and its  associated counting 
conventions.   The  dialogue  continues  with  more 
Figural descriptions,  before resuming at turn (35) 
with a Line description:
48
(1) A: go to the 1st row 2nd on the right
(2) B: 2nd?
(3) A: on the right
(4) B: OK, I can only get to the left  of the 
maze
(5) A: go to the highest square on the left
(6) B: yes. And then?
......
(35) B: I'm on the top row 2nd square
Excerpt 1: Deletion of elements from problem-
atic turn.
While superficially, A's turn at (3) appears sim-
ply as a repeat  of  (1),  with ?on the right? being 
omitted, the subsequent turns continue with Figural 
descriptions. On this basis, it is unclear whether (1) 
and (3) invoke the same Line model or whether (3) 
invokes a Figural description. There is a large class 
of  similar  clarification  sub-dialogues  which  in-
volve deletion of a problematic element and result 
in the continuation of the dialogue with more Figu-
ral descriptions.
This issue is of  importance for any theory of 
semantic co-ordination as it raises the question of 
the granularity of the mechanisms involved in how 
interlocutors collaboratively change semantic mod-
el.  Further,  it  strongly suggests that  alignment  is 
not simply an outcome of successful communica-
tion, but can provide the background against which 
other  co-ordination  mechanisms  operate.  Turns 
(1)-(6) demonstrate high levels of between-speaker 
alignment, while at the same time involving a shift 
in semantic model. Before returning to this below, 
we demonstrate further differences between the in-
formational  view  of  language  and  an  account 
which focuses on semantic co-ordination.
6 Information vs. semantic co-ordination
From an informational perspective, if an utterance 
fails  to  secure  reference,  there  is  the  general  as-
sumption that more information will be provided to 
allow resolution of the problem. However, in (3), 
no  new information  is  provided by A.  This  is  a 
counter-example to  Clark  and  Marshall's  (1981) 
model of definite reference repair, which states that 
to be effective ?repair  must  add or alter  descrip-
tors, but not delete them?. Importantly,  these CR 
responses that simply delete elements from the tar-
get turn are not treated by participants as repeats 
and queried again, but appear to promote resolu-
tion of the problematic understanding by engender-
ing  the  use  of  more  Figural  descriptions.  The 
words which are omitted do not appear, as with the 
level of description types, to be dictated by prior 
frequency of  use  (Mills,  2007).  Instead,  the  data 
suggest  that  this  pattern is  motivated by a relax-
ation of the constraints of successful interpretation 
(Healey and Mills, 2006).
The  example  above  raises  a  further  question 
concerning the relationship between semantic co-
ordination and the exchange of information. In ex-
isting ?ladder models? of communication such as 
the collaborative model  of Clark (1996) and All-
wood (1995), there  is the general expectation that 
on encountering and signalling problematic under-
standing, interlocutors enter a sub-dialogue to re-
solve the problem, which on completion proceeds 
at  the  same  ?level?.  From  this  perspective,  B's 
turn-initial  acknowledgment at (4) should demar-
cate the end of the sub-dialogue dealing with the 
problematic  understanding.  Focusing  on  the  de-
scription types,  however, shows that it  is only at 
turn (35) that the interlocutors return to using the 
original problematic line description; the semantic 
effects persist beyond the immediate sub-dialogue. 
This highlights the inadequacy of a strict informa-
tional view of language as the response provides 
no additional information, yet still has the effect of 
resolving the misunderstanding.
7 Exploitation  of  alignment:  patterns  of 
deletion, modification and addition
In addition to deletion of elements contained in re-
ferring expressions, the maze task dialogues exhib-
it  a  multiplicity  of  ways  in  which  interlocutors 
modify descriptions when dealing with problemat-
ic understanding, through the addition, substitution 
and (as described above) deletion of elements of 
semantic models. We argue that alignment is key 
to these patterns of modification, as it provides a 
backdrop  against  which  changes  can  be  made. 
The canonical example of this is embedded correc-
tion (Jefferson, 1983; Saxton, 2007) which exploits 
the structure provided by alignment to make a fig-
ure / ground distinction that allows the corrected 
element to be identified:
49
(1) A: You need to go to the top of the 5th 
row
(2) B: I can't get to the top of the 5th line
Excerpt 2: Substitution of problematic ele-
ments .
Embedded corrections in the maze task exhibit 
very high levels of between-speaker alignment, yet 
occur at points in the dialogue where there is prob-
lematic  understanding.  This  indicates  that  align-
ment can not simply be reduced to an index of suc-
cessful communication. While this particular con-
versational device which spans  2 turns (and possi-
bly a third) has received much attention, closer in-
spection of  the  maze  task  dialogues  reveal  a  far 
larger space of possible means of exploiting align-
ment. Excerpt 1 above showed deletions, Excerpt 2 
substitutions,  however  a  similar  pattern  also  ap-
pears with the addition of Figural elements.
(1) A: I'm in the 4th row 5th square
(2) B: where's that ?
(3) A: The end bit
(4) B: cheers, I'm on the end bit right at the 
top
(5) A: can you get to my switch?
....
(23) B: am on the top row 3rd square 
Excerpt 3: Addition of ?Figural? elements.
At  a  first  glance,  this  excerpt  looks  like  a 
straightforward  clarification  request  followed  by 
the provision of more details,  specifying that  the 
?5th  square?  is  also  ?the  end  bit?.  B's  use  of 
?cheers?  in  (4)  and  subsequent  provision  of  her 
own maze location would appear to demarcate the 
end of the clarification sequence, as they  provide 
an acknowledgment and a ?next relevant contribu-
tion? (Clark, 1996).  However, focusing on the en-
suing turns yields a pattern that parallels the first 
example. The semantic effects stretch beyond the 
immediate  clarification  sub-dialogue:  both  inter-
locutors  continue  with  more  Figural  descriptions 
until turn (23) where the original, problematic Line 
description is attempted again.
   A further issue  emerges when interlocutors fi-
nally re-use the original description, as in turn (23) 
of Excerpt 1, and (35) above: although the surface 
form of the descriptions are similar, this does not 
necessarily entail that they individuate the same lo-
cations. For example, the counting conventions as-
sociated with squares may change, such as count-
ing from the left  instead of the right or counting 
from 0 as opposed to 1, similar to the concierge ex-
ample  above.  The  axes  may  also  change,  with 
?rows? referring to vertical vectors (i.e. columns). 
   This raises important questions of the relation-
ship  between  the  problematic  utterance,  the  sig-
nalling of the problem,  the response, the ensuing 
figural sub-dialogue and the subsequent return to 
the superficially similar but potentially altered de-
scription type. It appears that alignment is not sim-
ply  an outcome but an interactional resource that 
is exploited to facilitate the continuation with more 
Figural descriptions (cf. Saxton, 2007).
     In the first excerpt, turns (1) and (3) only differ 
minimally from each other, while in the second ex-
ample, turn (3) can be seen to be operating ellipti-
cally on turn (1). However, both engender similar 
semantic  shifts  towards  Figural  descriptions  and 
result in a return to the originally problematic Line 
description.
    This leads to the immediate question of what 
motivates interlocutors'  patterns of alignment and 
modification,  and how they reflect differences of 
understanding and diagnosis of  the problem.  The 
tacit and fine-grained nature of these modifications 
exacerbates the problem of arriving at a prelimi-
nary  taxonomy,  as  these  dialogue  sequences  are 
not readily categorizable as either ?elaborations? or 
?reformulations?  (cf.  Purver  et  al.,  2004, 
Schlangen 2004).
8 Boundary of (mis)communication
During the course of maze task dialogues, partici-
pants shift seamlessly and tacitly from one descrip-
tion type to another. This occurs both within prob-
lematic and unproblematic dialogue.  From an in-
formational  perspective,  miscommunication  is 
readily  describable  as  a  form  of  mismatch,  yet 
from  a  semantic  perspective,  participants  match 
each  other  more  when  encountering  difficulties. 
50
Thus alignment  cannot  be taken as a straightfor-
ward index of successful interaction. 
   This also raises a methodological point.  Mea-
sures  of  matching  of  representations,  whether  at 
the level of description type or its constituent ele-
ments are only an approximate index of semantic 
co-ordination. The excerpts above demonstrate the 
importance  of  the  interplay  between  what  is  re-
tained and what is modified. What is required is a 
measure that is sensitive to the kind of model being 
used and the kind of repair being performed. 
In addition, more frequent repair does not nec-
essarily entail that a dialogue is unsuccessful.  It is 
not the case that interlocutors introduce their utter-
ances carefully, and once they are sufficiently co-
ordinated,  move  on.  The  general  pattern  is  that 
when participants introduce abstract (Line and Ma-
trix) descriptions, they do so opportunistically. At 
the start of the games they frequently attempt both 
Line and Matrix descriptions, which are associated 
with higher co-ordination. However,  there is evi-
dence that it is only where they can go through the 
process of detecting and responding to differences 
in  usage,  i.e.  repair,  that  co-ordination  develops 
(Healey and Mills, 2006). 
   If the boundary between description types and 
also the boundary between successful and unsuc-
cessful use can be as porous as demonstrated in the 
excerpts above, this also suggests a more complex 
picture  of  referential  contraction  (Krauss  and 
Weinheimer, 1966) than provided by current mod-
els of dialogue. In current models this is primarily 
associated with successful use: in the collaborative 
model, interlocutors follow the principle of ?least 
collaborative  effort?  (Clark  and  Wilkes-Gibbs, 
1986), whereby successful use sets a precedent for 
an expression; co-ordination on precedence allows 
interlocutors to delete elements of the description 
on successive mention. It is assumed that the infor-
mation associated with these deleted elements that 
are no longer on the conversational surface can be 
re-accessed in the common ground and mentioned 
explicitly, e.g. to assist disambiguation.
    By contrast, the phenomena from the maze task 
show how similar  processes are operative during 
problematic  dialogue,  raising  further  questions 
concerning  the  difference  between  elements  that 
are removed in successful, as opposed to problem-
atic dialogue and where this boundary lies.
    Larsson's  model  of  semantic  co-ordination 
places a strong emphasis on the role of feedback in 
negotiating this boundary in terms of appropriate-
ness gleamed from feedback (e.g. repair, acknowl-
edgements etc..), and provides a schema which an-
alyzes the effects of novel uses of a word  and the 
subsequent update of interlocutors' representations. 
    Findings from the maze task experiments aug-
ment this approach as they suggest that  evidence 
of appropriateness is also derived in the absence of 
overt repair from semantic change alone. The ex-
cerpts  indicate  that  interlocutors  are  sensitive  to 
which particular tacit shift in model leads to a re-
laxation of the constraints on successful communi-
cation, and consequently can be exploited to indi-
cate problematic understanding (Mills, 2007). For 
example, consider the following two excerpts:
(1) A: It's on the 5th row 4th square
(2) B: Huh?
(3) A: The last square
(1) A: It's on the 5th row 4th square
(2) A: The last square
Excerpts 4, 5: Provision of feedback
If the dialogue continues successfully in both these 
instances, it is unclear how to adequately capture 
the  differences  between them,  in  particular,  how 
both patterns affect subsequent use of the descrip-
tion types,
     One of the main challenges facing an account of 
semantic co-ordination is teasing apart how inter-
locutors'  models  are  affected  by  both  semantic 
change exploited as a resource using the mecha-
nisms of alignment outlined above, and feedback 
concerning that change, as both aspects inhabit the 
boundary between successful and unsuccessful use.
   Evidence  from  the  maze  task  suggests  this 
boundary is one of the important locii in the devel-
opment of semantic co-ordination.
9 Semantic plasticity 
To describe  how interlocutors  dynamically adapt 
the meanings of the words they use to the commu-
nicative  situation  and  how  they  are  shaped 
throughout  the  course  of  the  dialogue,  Larsson 
(2006) introduces the notion of ?semantic plastici-
51
ty?. This model is sensitive to the fact that descrip-
tions  can involve a plethora  of  different  ?ad-hoc 
registers?,  which resonates strongly with the em-
pirical  phenomena  described  here.  However,  the 
data from all the maze task experiments presents a 
further problem for attempts to model  these phe-
nomena,  as successful  co-ordination on the more 
specific  abstract  levels  appears  to  be  predicated 
upon prior successful use of less specific Figural 
descriptions:  the  Figural  descriptions  are  highly 
specific to individual mazes and allow participants 
to co-ordinate on their salient features, whereas the 
Line and Matrix descriptions abstract  away from 
each individual instance to form dyad-specific con-
ceptualizations  of  vectors  and  their  associated 
counting conventions.
   While  Larsson's  account  highlights  the  sheer 
flexibility of ways in which linguistic resources are 
mobilized and adapted to particular interaction set-
tings, the data from the maze task suggest an addi-
tional level of complexity. Namely that the seman-
tic resources can not  be treated as separate, essen-
tially equal encyclopaedias that interlocutors draw 
on.  One way in which the cumulative shift  toward 
Matrix descriptions is achieved is by the combina-
tion of different ?registers? (Larsson 2007) to form 
a super-ordinate one.  Here the question concerns 
which specific features of each semantic model are 
included in the final one, in particular when there 
are problems of commensurability. For example, as 
table 1 shows, a common pattern in maze task dia-
logues is that approximately half-way through the 
dialogues  participants  use  ?Line?  descriptions.  It 
can  occur  that  they alternate  between describing 
the maze  as consisting of vertical  and horizontal 
vectors,  say with  one  participant  favouring  hori-
zontal  and  the  other  favouring  vertical  vectors 
(space considerations preclude a throrough exami-
nation of this process, described in Mills, 2007).  It 
frequently occurs that Matrix descriptions emerge 
when  these  two  different  Line  models  are  com-
bined to form a Matrix description. This process, 
however, is not as a rule simply a matter of com-
bining the two. Frequently, the two types of Line 
description employ different counting conventions, 
as in the example of the concierge above, giving 
rise to the problem of whether to retain different 
counting conventions for the different axes, or em-
ploy the same one.  The question then emerges as 
to how this super-ordinate, more abstract semantic 
model affects the original models.
  Results  from  the  maze  task  suggest  this  is 
achieved tacitly by interlocutors, employing simi-
lar patterns of modification to those described in 
the excerpts above (Mills, 2007).
10 Conclusion
The  phenomena  described  here  demonstrate  the 
need for an account of semantic co-ordination that 
explains how interlocutors converge on a semantic 
representation. Dialogues from the maze task pro-
vide  compelling  evidence  that  such  an  account 
must necessarily be able to account for how varia-
tion, and hence differences in semantic models are 
resolved. This approach necessarily involves shift-
ing the focus from an informational view of lan-
guage towards a focus on how interlocutors actual-
ly address these differences. 
      In a sense, this presents a reversal of the priori-
ties of existing models.  For the interactive align-
ment  model,  as  well  as  the  collaborative  model, 
misunderstanding is seen as a secondary problem 
that emerges as a complication of communication 
which  is  ordinarily  successful  (Healey,  2004; 
forthcoming).  The  collaborative  model  explicitly 
states that in order for communication to be suc-
cessful,  positive  evidence  of  understanding  must 
be demonstrated.  
    By contrast,  the view presented  here brings 
problematic understanding into the foreground,  as 
it  is  in  such  instances,  when  conventions  don't 
work as expected, that interlocutors gain a sense of 
their applicability. The phenomena presented here 
suggest that the processes operating in instances of 
misunderstanding are as much progenitors  of  se-
mantic co-ordination, as their  traditional counter-
part  of  displays  of  positive  understanding.  Inter-
locutors' separate interaction histories inescapably 
give rise to problems concerning the development 
and sustenance of mutual-intelligibility, intrinsical-
ly requiring interlocutors to resolve differences of 
semantic model  in interaction. The data from the 
maze task experiments  demonstrate how this can 
be achieved  through  tacitly modifying the  con-
stituents of  semantic models. This modification in-
volves the exploitation of alignment,  and has the 
effect of relaxing the constraints on successful un-
derstanding.
Any theory  of  dialogue  must,  in  the  first  in-
stance be concerned with what interlocutors actual-
ly do. The phenomena presented here demonstrate 
52
mechanisms  of  semantic  co-ordination  that  have 
previously fallen  under  the  category of  informa-
tion-exchange,  and  the  questions  raised  present 
rich  opportunities for further experimental investi-
gation.
References
Allwood, J. (1995).  An activity based approach to prag-
matics. Technical Report (GPTL) 75, Gothenburg Pa-
pers in Theoretical Linguistics, University of  G?te-
borg.
Clark,  H.  H.  Using  Language.  Cambridge  University 
Press, Cambridge.
Garrod, S. and Doherty, G. 1994. Conversation, co-ordi-
nation and convention: an empirical investigation of 
how groups establish linguistic conventions. Cogni-
tion, 53:181-215.
Healey,  P.G.T.  1997.  ?Expertise  or  expert-ese:  The 
emergence  of  task-oriented  sub-languages.?  Pro-
ceedings of the Ninteenth Annual Conference of The 
Cognitive Science Society. M.G. Shafto and Langley, 
P. (Ed.s) August 7th-10th, Stanford University, CA. 
pp. 301-306.
Healey,  P.G.T.  2004.  ?Dialogue  in  the  degenerate 
case?? Peer  Commentary on Pickering and Garrod: 
?The Interactive Alignment Model?.  Behavioral and 
Brain Sciences 27(2) p. 201.
Healey P.G.T. (forthcoming) ?Interactive Misalignment: 
The Role of  Repair in the Development  of Group 
Sub-languages? in Cooper R. and and Kempson R. 
(eds) Language Change. 
Healey,  P.G.T.  and  Mills,  G.J.  2006.  ?Participation, 
Precedence and Co-ordination in Dialogue? in Sun R. 
and Miyake, N. (eds.) Proceedings of Cogsci06: The 
28th Annual Conference of the Cognitive Science So-
ciety.  Vancouver,  BC,  Canada.  26-29th  July.  pp. 
1470-1475.
Je erson, G. (1983). On exposed and embedded correcff -
tion in conversation.  Studium Linguistik, 14, 58?68. 
Krauss,  R.  M.  and  Weinheimer,  S.  1966.  Concurrent 
feedback, confirmation and the encoding of referents 
in verbal communication. Journal of Personality and 
Social Psychology, 4:343-346.
Larsson,  S.  2007.  A  general  framework  for  semantic 
plasticity and negotiation. In  Bunt,  H. C., and Thi-
jsse, E. C. G. (eds):  Prceedings of the 7th Interna-
tional  Workshop  on  Computational  Semantics 
(IWCS-7).
Larsson, S. 2006. Semantic plasticity.  Paper presented 
at  LCM 2006. (Language,  Culture and Mind),  July 
2006, Paris, France.
Lewis,  D.  1969.  Convention:  A  philosophical  study. 
Harvard University Press.
Mills, G.J. and Healey, P.G.T. (2006) Clarifying Spatial 
Descriptions: Local and Global Effects on Semantic 
Co-ordination.  In  Schlangen,  D. and Fernandez,  R. 
(eds.) Proceedings of Brandial06 The 10th Workshop  
on the Semantics and Pragmatics of Dialogue. Uni-
versity of Potsdam, Germany; September 11th-13th. 
pp.122-129.
Mills, G. J. 2007. The development  of semantic co-or-
dination  in  dialogue:  the  role  of  direct  interaction. 
Unpublished PhD. Thesis.
Purver,  M.,  Healey,  P.  G. T.,  King,  J.,  and Mills,  G. 
2003. Answering clarification questions. In Proceed-
ings of  the 5th Workshop of  the ACL SIG on Dis-
course and Sialogue (SIGdial03), Sapporo, Japan.
Saxton, M. 1997. The contrast theory of negative input. 
Journal of Child Language, 24, 139-161.
Schlangen, D. 2004. Causes and strategies for request-
ing clarification in dialogue.  In  Proceedings of  the 
5th SIGdial Workshop on Discourse and Dialogue.
Steels, L. and Belpaeme T. 2005. Coordinating percep-
tually grounded categories through language: A case 
study  for  colour.  Behavioral  and  Brain  Sciences, 
28(4):469-89
53
Proceedings of the 9th SIGdial Workshop on Discourse and Dialogue, pages 96?99,
Columbus, June 2008. c?2008 Association for Computational Linguistics
Quantifying Ellipsis in Dialogue:  an index of mutual understanding   Marcus Colman, Arash Eshghi and Patrick G. T. Healey Interaction, Media and Communication Research Group Queen Mary, University of London E1 4NS UK {marcus, arash, ph}@dcs.qmul.ac.uk        Abstract 
This paper presents a coding protocol that al-lows na?ve users to annotate dialogue tran-scripts for anaphora and ellipsis. Cohen's kappa statistic demonstrates that the protocol is sufficiently robust in terms of reliability. It is proposed that quantitative ellipsis data may be used as an index of mutual-engagement. Current and potential uses of ellipsis coding are described. 
1. Introduction Spontaneously generated dialogue, whether natu-rally occurring or task-oriented, rarely sticks to accepted rules of grammar or even politeness. In-terruptions, ungrammatical utterances and grunts or other noises are found in the majority of contri-butions in dialogue corpora. One reason for this is the ubiquitous use of ellipsis; the omission of words or phrases from a contribution which can be inferred or extracted from previous contributions. Ellipsis is optional; the full constituent could serve communication as well as the elliptical version. Where ellipsis occurs across speakers i.e., one par-ticipant makes (elliptical) use of another?s contri-bution, it provides a direct index of the mutual-accessibility of the current conversational context (cf. Healey et. al. 2007; Eshghi and Healey, 2007).      In some cases elliptical contributions are obvi-ous, as in the polar response 'yeah', signifying that a question has been heard, understood and consid-
ered; however, there are degrees of complexity that would seem to require a close understanding of what another participant is referring to. It is this issue of mutual-accessibility or 'grounding' that we propose can be investigated through the quantifica-tion of elliptical phenomena. These phenomena are, we propose, also related to the way referring expressions can contract over repeated use.  (e.g.  Schober and Clark, 1989; Wilkes-Gibbs and Clark, 1992). The approach taken in Clark et al's 'col-laborative theory' is that as mutual understanding increases, dialogue contributions become shorter as referring terms become part of the common ground. Clark and Krych (2004) note that various elliptical phrases can be used to establish common ground, from continuers ('uh-huh', 'yeah') or as-sessments ('gosh') to establishing shared attention through deictic expressions such as 'this', 'that', 'here' and 'there'.    Healey et al (2007) demonstrated the basic con-cept and viability of quantifying ellipsis phenom-ena as a quantitative index of mutual-accessibility of context. They showed that the frequency of use of cross-speaker elliptical expressions in online chat varies systematically depending on whether communication is ?local? i.e. within a single chat room or ?remote?.  However, the coding of ellipsis in this study did not follow an explicit protocol. It relied mainly on the distinctions made by Fernan-dez et al (2004)  but specific measures of reliabil-ity and validity were not calculated.    
96
 Figure 1. ?Anaphora? decision chart   In this paper we present an ellipsis coding protocol that provides a set of coding categories and we re-port the inter-rater reliability scores that have been obtained with it. In order to simplify coding and increase reliability, categories suggested by Fer-nandez et al have been collapsed into broader ones. It should be pointed out that we are not, in general, trying to produce an accurate or definitive analysis of ellipsis. The protocol is rather the prod-uct of contending with the compromise between robust coding categories and linguistic elegance. The categories presented here are generally or-dered in terms of occurrence in order to assist the coder. A contribution to dialogue may contain more than one type of elliptical utterance; contri-butions are not assigned to one mutually exclusive category. Rather, coders are able to use the proto-col to label any part of a dialogue that is elliptical. 2. The Ellipsis Protocol  The protocol is designed as a tool for coding one aspect of dialogue, developed with the intention    
 Figure 2. ?Answers? decision chart  that users with no specific knowledge of linguistics can use it. As can be seen from Figures 1-4, it con-sists of four binary branching decision trees that are applied to each contribution in an interaction. Full instructions for use of the protocol have also been written and are available from the authors. 3. Inter-rater reliability In order to demonstrate reliability between coders, two coders (one computer scientist, one psycholo-gist) applied the ellipsis protocol to a sample of task oriented dialogue. This was taken from the HCRC Map Task corpus (Anderson et al 1991); a series of dialogues in which one participant at-tempts to describe a route on a fictional map to another. The longest of these dialogues was chosen to be coded (transcript Q1NC1) which consisted of 446 turns and 5533 words. Cohen's kappa was cal-culated using the procedure outlined in Howell (1994); see Carletta (1996) for a discussion of the use of kappa in dialogue coding. Kappa in this in-stance was .81, which shows very high reliability, even by conservative standards (Krippendorff,  
97
 Figure 3. ?Questions? decision chart  1980). Table 1 below presents a breakdown of the instances of categories that were agreed upon. Table 1 shows the total number and approximate percentage of agreements. Also given, '1.dis' and '2.dis' are the number of observed instances by coders one and two respectively identified but dis-puted for that particular category. The total number of elliptical or non-elliptical instances coded, from single words or phrases to entire turns was 624; of these, 100 (16%) were disagreed upon and 78 in-stances (12.5%) were agreed to contain no ellipti-cal phenomena (no ellipsis disagreements = 50). Some categories have very low frequencies; how-ever, previous work suggests that these categories are necessary. To some extent this table shows the limitations of the kappa statistic; coder agreement varies considerably across these categories.  
 Figure 4. ?Statements? decision chart     Endophor Cataphor Exaphor Vague Anaphor Total 119 2 8 33 % 19 .03 1.3 5.3 1.dis 12 1 1 20 2.dis 10 3 17 6  Polar Answer Acknowledge Prompted NSU Ans. Un-prompted NSU Ans. Total 113 78 1 7 % 18.1 12.5 0.2 1.1 1.dis 7 15 0 1 2.dis 5 9 1 5  Sluice Clarification Ellipsis Check NSU Query Total 2 7 20 27 % .03 1.1 3.2 4.3 1.dis 0 0 2 5 2.dis 2 2 0 2  Rejection Modification Continua-tion Sentential Ellipsis Total 2 1 13 13 % .03 .002 2.1 2.1 1.dis 1 0 3 10 2.dis 4 0 3 3 Table 1. Total agreements by category  
98
4. Discussion  Although mutual-accessibility of context is funda-mental to communication, there has not been a re-liable method for observing or measuring it. The ellipsis protocol presented here thus provides a useful step in this direction. It gives a standardised coding scheme that can quantify the extent to which speakers can directly access the constituents of each other?s turns.     In previous work there have been several differ-ent attempts to define taxonomies of elliptical or context dependent utterances. For example, non-sentential utterances (NSUs), e.g. Schlangen and Lascarides (2003); Fernandez and Ginzburg (2002); Fernandez, Ginzburg and Lappin (2007). One issue with these previous approaches is the lack of reliability data; a statistic such as Cohen?s kappa is needed in order to demonstrate that a tax-onomy or coding scheme can be reliably applied between independent coders. Carletta et al (1997) presented a reliable coding scheme for the classifi-cation of dialogue moves; although there are over-laps between their categories and ours, the questions used in the scheme are intended to estab-lish solely the function of an utterance and impor-tantly, not whether the utterance is elliptical. The protocol presented here achieves a high level of reliability for some of these context dependent phenomena without requiring specific prior knowl-edge of the relevant linguistic theory.    Further work will code a sample from the BNC (Burnard, 2000) in order to allow comparisons with previous taxonomies. The HCRC map task corpus has previously been examined in terms of various features of dialogue, e.g. Dialogue Games Analysis (Kowtko et al 1991) and disfluencies (Lickley and Bard, 1998). Ongoing work will de-velop this through coding the entire HCRC map task corpus; providing data on how ellipsis varies over different conditions such as medium, familiar-ity and task role. Acknowledgments Thanks go to the HCRC group for providing the map task data. Thanks also to Jackie Folkes and Greg Mills for help and advice.  
References  Anderson, A., Bader. M., Bard, E., Boyle, E., Doherty, G. M., Garrod, S., Isard, S., Kowtko, J., McAllister, J., Miller, J., Sotillo, C., Thompson, H. S. and Wein-ert, R. (1991). The HCRC Map Task Corpus. Lan-guage and Speech, 34, 351-366. Burnard, L. (2000). Reference Guide for the British Na-tional Corpus (World Edition). Oxford University Computing Services. Carletta, J. (1996). Assessing agreement on classifica-tion tasks: the kappa statistic. Computational Lin-guistics, 22(2): 249-254. Clark, H. H. and Krych, M. A. (2004). Speaking while monitoring addressees for understanding. Journal of Memory and Language, 50, 62-81. Eshghi, A. and Healey, P. G. T. (2007). Collective states of understanding. Proceedings of the 8th SIGdial workshop on discourse and dialogue. pp 2-9. Fernandez, R. and Ginzburg, J. (2002). Non-sentential utterances: a corpus study. Traitement automatique des languages: dialogue, 43(2), 13-42. Fernandez, R., Ginzburg J and Lappin, S, (2004). Clas-sifying ellipsis in dialogue: a machine learning ap-proach. Proceedings of the 20th international conference on computational linguistics. pp 240-246. Fernandez, R. , Ginzburg J and Lappin, S. (2007). Clas-sifying non-sentential utterances in dialogue: a ma-chine learning approach. Computational Linguistics 33(3), 397-427. Healey, P. G. T., White, G., Eshghi, A. and Light, A. (2007). Communication Spaces. Computer Supported Co-operative Work, 2007. Howell, D. C. (1997). Statistical Methods for Psychol-ogy. Duxbury Press. Kowtko, J. C., Isard, S. D. and Doherty, G. M. (1991). Conversational games within dialogue. Proceedings of the espirit workshop on discourse coherence, 1991. Krippendorff, K. (1980). Content Analysis: an introduc-tion to its methodology. Beverly Hills: Sage Publica-tions. Lickley, R. and Bard, E. (1998). When can listeners detect disfluency in spontaneous speech? Language and Speech, 41. Schlangen, D. and Lascarides, A. (2003). The interpre-tation of non-sentential utterances in dialogue. Pro-ceedings of the 4th SIGdial workshop on discourse and dialogue, 2003. Schober, M. F. and Clark, H. H. (1989). Understanding by addressees and overhearers. Cognitive Psychol-ogy, 21, 211-232. Wilkes-Gibbs, D. and Clark, H. H. (1992). Coordinating beliefs in conversation. Journal of Memory and Lan-guage, 31, 183-194. 
99
Proceedings of SIGDIAL 2009: the 10th Annual Meeting of the Special Interest Group in Discourse and Dialogue, pages 79?86,
Queen Mary University of London, September 2009. c?2009 Association for Computational Linguistics
A: An Experimental Investigation into. . .
B: . . . Split Utterances
Christine Howes, Patrick G.T. Healey and Gregory J. Mills
Queen Mary University of London
Interaction, Media and Communication Research Group, London, E1 4NS
{chrizba, ph, gj}@dcs.qmul.ac.uk
Abstract
A distinguishing feature of dialogue is that
more that one person can contribute to the
production of an utterance. However, un-
til recently these ?split? utterances have re-
ceived relatively little attention in mod-
els of dialogue processing or of dialogue
structure. Here we report an experiment
that tests the effects of artificially intro-
duced speaker switches on groups of peo-
ple engaged in a task-oriented dialogue.
The results show that splits have reliable
effects on response time and on the num-
ber of edits involved in formulating sub-
sequent turns. In particular we show that
if the second half of an utterance is ?mis-
attributed? people take longer to respond
to it. We also show that responses to ut-
terances that are split across speakers in-
volve fewer deletes. We argue that these
effects provide evidence that: a) speaker
switches affect processing where they in-
terfere with expectations about who will
speak next and b) that the pragmatic effect
of a split is to suggest to other participants
the formation of a coalition or sub-?party?.
1 Introduction
Split utterances, defined simply as utterances
which are split between speakers1, are known
to occur in dialogue, as evidenced by Conversa-
1What we call split utterances have been variously re-
ferred to as collaborative turn sequences (Lerner, 1996;
Lerner, 2004), collaborative completions (Clark, 1996) co-
constructions (Helasvuo, 2004), co-participant completions
(Hayashi, 1999; Lerner and Takagi, 1999) collaborative pro-
ductions (Szczepek, 2000) and anticipatory completions (Fox
and others, 2007) amongst others.
tional Analysis (CA) studies, based on the anal-
ysis of naturally occuring dialogues. In addi-
tion to numerous analyses of split utterances in
generic English dialogues, there are cross lin-
guistic studies, and observations of conversations
with aphasics. In Finnish, split utterances within
a single clause conform to the strict syntactic
constraints of the language (which has a rich
inflectional morphology), despite the change in
speaker (Helasvuo, 2004). Similarly, in Japanese,
a verb-final language, speakers also engage in ?co-
participant completions? (Hayashi, 1999; Lerner
and Takagi, 1999). There is also evidence of
split utterances in conversations with aphasics
(Oelschlaeger and Damico, 1998), demonstrat-
ing that the phenomenon is pervasive in dia-
logue. However, with the possible exception of
Szczepek (2000) who analysed some 200 splits
from 40 hours of recorded English conversation,
these studies tend to be unconcerned with frequen-
cies of occurrence; that split utterances occur at all
renders them worthy of study.
Split utterances are a clear and canonical exam-
ple of coordination in dialogue. In order for one
person to continue an utterance which has been be-
gun by another person requires the hearer to have
coordinated with the initial speaker up to the point
at which they take over the role of producer2.
Analysis of split utterances, when they can or
cannot occur and what effects they have on the co-
ordination of agents in dialogue, is therefore an
area of interest not only for conversational an-
alysts wishing to characterise sytematic interac-
tions in dialogue, but also linguists trying to for-
mulate grammars of dialogue, and psychologists
interested in alignment mechanisms in dialogue.
2Note that this says nothing about whether such a continu-
ation is the same as the initial speakers intended continuation.
79
In this regard, studies of split utterances, in both
spontaneous dialogues and experimentally, as be-
low, provide a complementary way of studying
structural alignment to the traditional experimen-
tal set up exemplified by Branigan and colleagues
(Branigan et al, 2000; Branigan et al, 2003;
Branigan et al, 2006). Indeed, Poesio and Rieser
(In preparation) claim that ?[c]ollaborative com-
pletions . . . are among the strongest evidence yet
for the argument that dialogue requires coordina-
tion even at the sub-sentential level? (italics origi-
nal).
Broadly speaking, there have been two types,
or levels, of explanations of split utterances of-
fered; pragmatic accounts and processing ac-
counts. Pragmatic accounts are favoured by Con-
versational Analysts, with various aspects of split
utterances analysed. However, in line with CA as-
sumptions, these analyses are almost exclusively
concerned with the conditions under which split
utterances can occur. Lerner (1991), for ex-
ample, identifies a number of ?compound? turn-
constructional units, such as the IF-THEN con-
struction (whereby the second participant is in
some sense licensed to provide the THEN part of
the structure). However, Lerner?s insistence on
identifying the circumstances in which split utter-
ances usually occur misses the important general-
isation that, syntactically, they can be anywhere in
a string (his opportunistic completions). His claim
that an anticipatory completion is ordinarily ?de-
signed as a syntactic continuation of the utterance
part it follows at the point of onset?, seems to hold
for all split utterances.
The occurrence of split utterances also has im-
plications for the organisation of turn-taking, as
outlined in Sacks et al (1974). According to Sche-
gloff (1995), turn-taking operates, not on individ-
ual conversational participants, but on ?parties?.
For example, if a couple are talking to a third per-
son, they may organise their turns as if they are
one ?party?, rather than two separate individuals.
Lerner (1991) suggests that split utterances can
clarify the formation of such parties; ?collabora-
tively produced sentences reveal a relationship be-
tween syntax and social organisation. It provides
evidence of how syntax can be mobilised to organ-
ise participants into ?groups?.?
The processing approach towards split utter-
ances is exemplified by the interactive alignment
model of Pickering and Garrod (2004). They
claim that;
. . . it should be more-or-less as easy
to complete someone else?s sentence as
one?s own, and this does appear to be the
case.
(Pickering and Garrod, 2004, p186)
According to this model, speaker and listener
ought to be interchangeable at any point, and this
is also the stance taken by the grammatical frame-
work of Dynamic Syntax (Cann et al, 2005). In
Dynamic Syntax (DS), parsing and production are
taken to use exactly the same mechanisms, lead-
ing to a prediction that split utterances ought to be
strikingly natural (Purver et al, 2006). Addition-
ally, for a third person to process an utterance that
appears to come from two separate speakers ought
not be more difficult than processing the same ut-
terance from a single speaker, regardless of where
in a string the changeover occurs.
According to Poesio and Rieser (In prepara-
tion), ?the study of sentence completions can shed
light on a number of central issues. . . this type of
data may be used to compare competing claims
about coordination ? i.e. whether it is best ex-
plained with an intentional model like Clark?s. . . or
with a model based on simpler alignment models
like Pickering and Garrod?s.? As they see inten-
tions as crucial to dialogue management, they con-
clude that a model which accounts for intentions
(such as their PTT account) better captures their
task specific split utterance data (See Poncin and
Rieser (2006) for details of the German data they
are modelling).
If this is the case, it ought to be more difficult
to process an utterance that appears to be split
between speakers, as opposed to one that comes
from one source, because the intentions of the two
different agents have to be considered in arriving
at an interpretation, and they may appear to have
formed a ?party? with respect to the subject of the
utterance. Additionally it ought to be more dis-
ruptive to the conversation if the utterance is at-
tributed to someone other than the person who
genuinely contributed it, because the hearer would
falsely attribute intentions to the wrong interlocu-
tor. This ought to be especially clear in cases
where the ?conversational momentum? appears to
be with the ?wrong? interlocutor. Contrarily, if a
processing model such as the interactive alignment
model is correct, then no such differences should
80
be observed3.
To test these predictions, an experiment was set
up to alter genuine single-turn utterances into split
utterances at an arbitrary point in the string. Dif-
ferent types of intervention were introduced, in a 2
x 2 factorial design, in order to separate out the ef-
fects of an utterance appearing to come from two
different participants from effects caused by an ap-
parent change of floor.
2 Method
The effects of seeing an utterance split between
speakers or not were tested using the Dialogue
Experimentation Toolkit (DiET) chat tool, as de-
scribed in Healey et al (2003), which enables dia-
logues to be experimentally manipulated.
The DiET chat tool allows interventions to be
introduced into a dialogue in real time, thus caus-
ing a minimum of disruption to the natural ?flow?
of the conversation. In this case, a number of gen-
uine turns in a three way conversation were artifi-
cially split into two sections, with both parts either
appearing to originate from the genuine source, or
one or both parts being falsely attributed to another
participant.
2.1 Materials
2.1.1 The Balloon Task
The balloon task is an ethical dilemma re-
quiring agreement on which of three passengers
should be thrown out of a hot air balloon that will
crash, killing all the passengers, if one is not sac-
rificed. The choice is between a scientist, who be-
lieves he is on the brink of discovering a cure for
cancer, a 7 months pregnant woman, and her hus-
band, the pilot. This task was chosen on the basis
that it should stimulate discussion, leading to dia-
logues of a sufficient length to enable an adequate
number of interventions.
2.1.2 The DiET Chat Tool
The DiET chat tool itself is a custom built java
application consisting of two main components,
which will be outlined in turn; the user interface,
and the server console.
3This is, of course, an oversimplification, and note that in
contrast to pragmatic accounts, no claims are made regard-
ing higher level discourse effects of the split utterance, as the
focus is on the mechanisms which allow split utterances to
occur. Additional mechanisms could of course be posited in
processing models to account for any such differences.
2.1.3 User interface
The user interface is designed to look and feel
like instant messaging applications e.g. Microsoft
Messenger. It consists of a display split into two
windows, with a status bar, indicating whether any
other participant(s) are actively typing, between
them (see figure 1). The ongoing dialogue, con-
sisting of both the nickname of the contributor and
their transmitted text, is shown in the upper win-
dow. In the lower window, participants type and
revise their contributions, before sending them to
their co-participants. All key presses are time-
stamped and stored by the server.
Figure 1: The user interface chat window (as
viewed by participant ?sam?)
2.1.4 Server Console
All text entered is passed to the server, from
where it is relayed to the other participants, not
relayed directly between participants. Prior to be-
ing relayed, some turns are altered by the server to
create fake split utterances.
This is carried out automatically such that a
genuine single-person turn is split around a space
character near the centre of the string. The part
of the turn before the space is relayed first, fol-
lowed by a short delay during which no other turns
may be sent. This is followed by the part of the
turn after the space, as if they were in fact two
quite separate, consecutive turns. In every case,
the server produces two variants of the split utter-
ance, relaying different information to both recip-
ients. Each time an intervention is triggered, one
of the two recipients receives both parts from the
actual source of the utterance (henceforth referred
to as an AA-split). The other recipient receives
one of three, more substantial, manipulations; the
first half could appear to be from the actual ori-
gin with the second part of the split appearing to
originate from the other recipient (an AB-split), or
81
the inverse could be the case (a BA-split), or both
parts could be wrongly attributed to the other par-
ticipant (a BB-split). This design was in order to
separate the effects of a change in conversational
momentum (floor change) from the effects of split-
ting per se, hence the inclusion of the BB condi-
tion where who apparently has the floor is altered
without the utterance being attributable to differ-
ent participants. This contrast is shown in table 1.
Table 1: Comparison of split types
A types:
Should we start now
B sees (AA intervention):
A: Should we
A: start now
C sees (one of):
AB intervention: BA intervention: BB intervention:
A: Should we B: Should we B: Should we
B: start now A: start now B: start now
The intervention is triggered every 10 turns, and
restricted such that the participant who receives
the non AA-split is rotated (to ensure that each
participant only sees any of the more substantially
manipulated interventions every 30 turns). Which
of the three non AA-splits they see (AB, BA or
BB) is, however, generated randomly.
2.2 Subjects
41 male and 19 female native English speaking un-
dergraduate students were recruited for the exper-
iment, in groups of three to ensure that they were
familiar with each other. All had previous expe-
rience of internet chat software such as Microsoft
Messenger and each was paid ?7.00 for their par-
ticipation.
2.3 Procedure
Each of the triad of subjects was sat in front of a
desktop computer in separate rooms, so that they
were unable to see or hear each other. Subjects
were asked to follow the on screen instructions,
and input their e-mail address and their username
(the nickname that would identify their contribu-
tions in the chat window). When they had en-
tered these, a blank chat window appeared, and
they were given a sheet of paper with the task de-
scription on. Participants were instructed to read
this carefully, and begin discussing the task with
their colleagues via the chat window once they
had done so. They were told that the experi-
ment was investigating the differences in commu-
nication when conducted using a text only inter-
face as opposed to face-to-face. Additionally, sub-
jects were informed that the experiment would last
approximately 20-30 minutes, and that all turns
would be recorded anonymously for later analy-
sis. Once all three participants had been logged
on, the experimenter went to sit at the server ma-
chine, a fourth desktop PC out of sight of all three
subjects, and made no further contact with them
until at least 20 minutes of dialogue had been car-
ried out.
3 Results
A post experimental questionnaire and debrief-
ing showed that participants felt the conversations
went as smoothly as face-to-face dialogue. With
the exception of one subject, who had taken part
in a previous chat tool experiment and was there-
fore aware that interventions may occur, none of
the participants reported awareness of any inter-
ventions.
As production and receipt of turns sometimes
occurs in overlap in text chat, it is not possible
to say definitively when one turn is made in di-
rect response to another4. We therefore chose two
separate measures; next turn ? the first turn, by
the first recipient to start and complete a response,
after receipt of the intervention, and global ? all
the turns produced by both recipients between the
most recent intervention and the next intervention,
averaged to produce one data point per recipient
per intervention. This means that in the next turn
condition, only one datapoint is analysed for each
intervention, despite two different people seeing
an intervention (and both usually producing a re-
sponse). This was to try and isolate the initial re-
sponse to an intervention; for the other person who
saw a split but did not respond first, it is not clear
if they are responding to the split utterance, or to
4In online chat, participants can compose their next turns
simultaneously, and turns under construction when another is
received can be subsequently revised, prior to transmission.
This means that a genuine response to a split utterance might
have a negative start time. However, the inclusion of cases
where the whole turn was constructed after receiving the split
(an arbitrary cut-off point, which would catch some turns that
were responses to earlier turns in the dialogue, and miss some
which were begun before the intervention was received and
subsequently revised) should impose the same level of noise
in all cases.
82
the person who already responded to the split ut-
terance. In the global condition, in contrast, there
are two datapoints for each intervention (one for
each of the participants who saw a split utterance).
Of the 253 interventions to which at least one
recipient responded, 89 were AA/AB splits, 99
were AA/BA splits and 65 AA/BB splits. Table 2
shows the n values in each case.
Both next turn and global measures were anal-
ysed according to two factors in a 2 x 2 factorial
design; split ? whether both parts of the utterance
had appeared to come from the same person, or
from different sources ([AA and BB] vs [AB and
BA]), and floor change ? who appeared to have
produced the second part of the split, the genuine
source, or the other participant ([AA and BA] vs
[AB and BB]).
Measures selected for analysis were typing time
of turn (The time, in milliseconds, between the
first key press in a turn and sending the turn to
the other participants by hitting the return key) and
length of turn in characters as measures of produc-
tion; deletes per character (The number of keyed
deletes plus one (to prevent null values) divided
by the total number of characters) as a measure
of revisions; and typing time per character as a
measure of speed. Data in tables are displayed in
the original scale of measurement. However, as
inspection of the data showed that they were not
normally distributed, logarithmic transformations
(using loge) were applied to the data prior to all
formal analyses.
2 x 2 ANOVAs show a main effect of floor
change on the typing time of turn (see table 2).
This holds for next turns (F(3,249) = 7.13, p <
0.05) and globally (F(3,486) = 3.78, p < 0.05),
with participants taking longer over their turns in
the AB and BB conditions. There was no main
effect of split, and no effect of interaction. This
effect is greater locally than globally, with partici-
pants who respond first after seeing a floor change
condition taking more than 40% longer over their
turns than those who saw a non-floor change con-
dition. Globally the difference is in the order of
10%.
There was a main effect of split on the number
of deletes per character , which also held both in
the next turn condition (F(3,249) = 6.26, p < 0.05)
and globally (F(3,486) = 9.23, p < 0.05), with
subjects seeing a split condition (AB or BA) us-
ing fewer deletes per character than those seeing
a non-split condition (see table 3). There was no
main effect of floor change or interaction effect.
This effect is also stronger in the next turn con-
dition, with those not seeing a cross-person split
using over 50% more deletes. In the global condi-
tion, this difference is still 40%, though the overall
proportion of deletes is approximately 25% lower,
from 0.334 per character in the next turn condition
to 0.244 globally.
Table 2: Typing time of turn by type of interven-
tion
Condition Mean (s.d.) N (poss N)
Next Turn
AA 9475.54 (12258.5) 136 (253)
AB 14560.70 (18863.9) 37 (89)
BA 6968.24 (6437.0) 51 (99)
BB 14812.59 (20367.8) 29 (65)
Global
AA 11122.27 (14413.5) 246 (253)
AB 12500.98 (10944.6) 89 (89)
BA 9800.77 (8810.3) 92 (99)
BB 11561.67 (10138.4) 63 (65)
Table 3: Deletes per character by type of interven-
tion
Condition Mean (s.d.)
Next Turn
AA 0.435 (1.63)
AB 0.152 (0.30)
BA 0.202 (0.25)
BB 0.324 (0.61)
Global
AA 0.288 (0.83)
AB 0.192 (0.28)
BA 0.145 (0.18)
BB 0.287 (0.37)
Additional analyses showed an effect of floor
change on length of turn in characters (table 4)
in the next turn condition (F(3,249) = 5.57, p <
0.05) such that turns are longer in the AB and BB
conditions (note that though this might be thought
to be confounded by the typing time of turn, as you
would expect longer turns to take longer to type,
there are no significant effects when ANOVAs are
performed on typing time per character). There is
no main effect of split, or interaction effect. In the
global condition, however, there is a main effect
of split (F(3,486) = 4.08, p < 0.05) such that turns
are longer after seeing an utterance that appears
to be split between two different people (AB and
BA conditions). There is no main effect of floor
change, and no effect of interaction.
83
As the experiment was looking for generic ef-
fects of splitting on coordination, the location of
the splits was random. A post-hoc analysis was
therefore carried out to ascertain whether the stan-
dalone coherence (as judged by the authors) of the
two separate parts of the utterance was a possible
confounding factor. Examples of coherence judge-
ments are shown in table 5.
Table 4: Length of turn in characters by type of
intervention
Condition Mean (s.d.)
Next Turn
AA 23.95 (22.0)
AB 37.76 (34.9)
BA 23.92 (18.4)
BB 26.52 (21.5)
Global
AA 26.41 (20.4)
AB 32.12 (23.9)
BA 28.27 (18.4)
BB 25.78 (13.6)
Table 5: Examples of standalone coherence judge-
ment examples
Part of Split Coherent
First Second 1st 2nd
what the hell is that Y N
the woman is pregnant she should stay Y Y
these people said you did something N Y
I think this is also the wish of the doctor N N
2 x 2 ANOVAs showed that in the next turn con-
dition, there are no main effects of first or sec-
ond part coherence, but there was an interaction
effect of first part coherence by second part co-
herence on deletes (F(3,249) = 4.05, p < 0.05),
such that if both parts are independently coherent,
or if neither part is independently coherent, there
are fewer deletes used in the turn immediately fol-
lowing the intervention (see table 6). There are no
significant global effects.
Table 6: Deletes per character by first and second
part standalone coherence (next turn condition)
Coherence Mean (s.d.)1st 2nd
Y Y 0.198 (0.38)N 0.651 (2.26)
N Y 0.304 (0.66)N 0.206 (0.30)
Running a 2 x 2 x 2 x 2 ANOVA with these ad-
ditional factors does not alter the main effects ob-
served for floor change or split, as detailed above.
There are no additional interaction effects on any
of the measures.
4 Discussion
As this is the first experimental study into split ut-
terances using the DiET chat tool, what follows is
necessarily exploratory. This discussion presents
our current hypotheses as to how best to interpret
the data, as summarised in table 7, below.
Table 7: Summary of significant effects
Effect of Condition on and direction
Floor Next Turn Typing Time
Change and Global (AB ?BB) > (AA ?BA)
Floor Next Turn Number of Chars
Change (AB ?BB) > (AA ?BA)
Split Next Turn Deletes
and Global (AA ?BB) > (AB ?BA)
Split Global Number of Chars
(AB ?BA) > (AA ?BB)
Taking longer over the production of a turn (in-
dependently of typing speed) indicates a lack of
confidence in the conversation (misattributing the
second part of the utterance thus reducing confi-
dence), and is also indicative of local organisation
of turn-taking. If a participant who has seen a floor
change intervention (Participant C) responds first,
then they may be taking longer over their turns be-
cause there is less pressure on them to take a turn.
This is because of the C?s expectations. They will
falsely believe that the fake source (Participant B)
has just completed a turn, and will therefore not
expect them to take the floor, and the genuine
source (Participant A) will not be taking the floor
because they have just completed a turn (though C
does not know this). It is probable that in the turn
immediately following a floor change intervention
both these factors are at play, whereas globally it
is the weaker effect of generic confidence loss that
is observed. This compounding of effects in the
next turn condition would also help explain the di-
vergent effects on the length of turn in characters
in next turn and global conditions.
Regardless of the precise reasons for it, this ef-
fect of floor change on typing time clearly demon-
strates that changing the apparent speaker is dis-
ruptive, perhaps because it alters the forward mo-
84
mentum of the conversation.
More interestingly, independently of a change
of floor, seeing an utterance that appears to be split
between speakers also has an impact on the con-
versation, seen in the amount of revision under-
taken in formulating a response (deletes). One rea-
son why participants might worry less about pre-
cisely formulating their turns following a cross-
person split is that the production of a cross-person
split could have the effect on the recipient of sug-
gesting that the two other participants have formed
a ?party? (Schegloff, 1995) with respect to the de-
cision of who to throw out of the balloon. This
might be understood as signalling the formation
of a strong coalition between the other two partic-
ipants, therefore making the recipient behave as
though they are resigned to the decision of this
coalition. This is not the same as the effect on the
typing time of turn, whereby participants are less
rushed when seeing a change of floor. Deletes, on
the other hand, demonstrate how carefully partici-
pants are constructing their turns. Excerpt 1, taken
from the transcripts shows an example where this
appears to be the case.
Excerpt 1 AB-Split showing apparent coalition
between ?Bhups? and ?Dan? (?fake? part of split
shown in bold)
Bhups: and he can tell his formula
Dan: to tom and susie
If we take split utterances as an indicator of co-
ordination then it is likely that if we believe our
two conversational partners to be in coordination,
we will worry less about precisely formulating our
own contributions. This also backs up the idea that
people are not interchangeable.
The interaction of first and second part coher-
ence also underlines the effect of split on revi-
sions as outlined above. In the case were both
parts of the split could potentially stand as inde-
pendent utterances, they are treated as such and
the number of deletes per character is in line with
the global average (i.e. they are treated as nor-
mal dialogue). In the other non ambiguous case,
where neither part could be interpreted as an ut-
terance on its own, there are also fewer deletes,
in line with the result that there are fewer deletes
in strong split cases. Interestingly, the most dis-
ruptive case is that where the first part could have
been a standalone utterance, but the second part
could not. This could be seen as analogous to a
garden path effect, and provides some indication
that that the building up of interpretations is incre-
mental, and not concerned with who supplies the
input.
These results do not, of course, prejudice the
claim that, at a purely mechanistic level, people
could anticipate the structures needed to complete
a turn, as the interactive alignment model sug-
gests, because they are not concerned with the ac-
tual production of a split utterance, rather on the
effect it has on the conversation. They do indicate
that in terms of the effects of seeing split utter-
ances, the pragmatic approach offers a more fea-
sible level of analysis. For example, if we wish
to treat a jointly produced split utterance as sig-
nalling especially strong alignment, then we need
to account for more than simply syntax.
There is an issue with the design of the exper-
iment which means that the floor change effects
might be caused by a confounding variable; in
essence, because one of the recipients always re-
ceived an AA-split, in the cases which have been
labelled as cases of floor change, the two recipi-
ents will have been left with the impression that a
different person made the final contribution. This
means that there may well be a an effect of con-
founded listener expectation (though see Schober
and Brennan (2003) for discussion), although it
should be noted that this does not have any bear-
ing on the observed differences after an utterance
split between speakers. It is also possible that
split utterances might be particularly marked in a
chat environment, though preliminary results of a
corpus study show that, perhaps surprisingly, split
utterances also occur naturally and as frequently
in text-based chat (Eshghi, in prep) as they do in
face-to-face dialogue (Purver et al, 2009). Be-
cause of these issues, and the already noted po-
tential problems of linearity in text-based chat,
a follow-up study using a character-by-character
chat tool interface is underway. This more directly
enforces turn-taking, as it does not allow partici-
pants to formulate their turn before communicat-
ing it; each character is transmitted as and when it
is entered.
5 Conclusions
The experiment reported here offers clues towards
an understanding of split utterances as an exam-
ple of dialogue phenomena, and provides evidence
85
that speaker switches affect processing where they
interfere with expectations about who will speak
next and that the pragmatic effect of a split is to
suggest to other participants the formation of a
coalition or sub-?party?. It also clearly demon-
strates that this type of experiment provides a fruit-
ful line of future research in the ongoing attempt to
adequately characterise dialogue, though further
developments are needed.
References
H. Branigan, M. Pickering, and A. Cleland. 2000.
Syntactic co-ordination in dialogue. Cognition,
75(2):13?25.
H. Branigan, M. Pickering, J. Pearson, J. McLean, and
C. Nass. 2003. Syntactic alignment between com-
puters and people: The role of belief about mental
states. In Proceedings of the Twenty-fifth Annual
Conference of the Cognitive Science Society.
H. Branigan, M. Pickering, J. McLean, and A. Stewart.
2006. The role of local and global syntactic struc-
ture in language production: Evidence from syn-
tactic priming. Language and cognitive processes,
21(7-8):974?1010.
R. Cann, R. Kempson, and L. Marten. 2005. The Dy-
namics of Language. Elsevier, Oxford.
H. Clark. 1996. Using Language. Cambridge Univer-
sity Press.
A. Eshghi. in prep. Uncommon ground: the distri-
bution of dialogue contexts. Ph.D. thesis, Depart-
ment of Computer Science, Queen Mary University
of London.
A. Fox et al 2007. Principles shaping grammati-
cal practices: an exploration. Discourse Studies,
9(3):299.
M. Hayashi. 1999. Where Grammar and Interac-
tion Meet: A Study of Co-Participant Completion in
Japanese Conversation. Human Studies, 22(2):475?
499.
P. G. T. Healey, M. Purver, J. King, J. Ginzburg, and
G. J. Mills. 2003. Experimenting with clarifica-
tion in dialogue. In Proceedings of the 25th Annual
Meeting of the Cognitive Science Society.
M. Helasvuo. 2004. Shared syntax: the gram-
mar of co-constructions. Journal of Pragmatics,
36(8):1315?1336.
G. Lerner and T. Takagi. 1999. On the place
of linguistic resources in the organization of talk-
in-interaction: A co-investigation of English and
Japanese grammatical practices. Journal of Prag-
matics, 31(1):49?75.
G. Lerner. 1991. On the syntax of sentences-in-
progress. Language in Society, pages 441?458.
G. Lerner. 1996. On the semi-permeable character
of grammatical units in conversation: Conditional
entry into the turn space of another speaker. In
E. Ochs, E. A. Schegloff, and S. A. Thompson,
editors, Interaction and grammar, pages 238?276.
Cambridge University Press.
G. Lerner. 2004. Collaborative turn sequences. In
Conversation analysis: Studies from the first gener-
ation, pages 225?256. John Benjamins.
M. Oelschlaeger and J. Damico. 1998. Joint produc-
tions as a conversational strategy in aphasia. Clini-
cal linguistics & phonetics, 12(6):459?480.
M. Pickering and S. Garrod. 2004. Toward a mech-
anistic psychology of dialogue. Behavioral and
Brain Sciences, 27:169?226.
M. Poesio and H. Rieser. In preparation. Completions,
coordination, and alignment in dialogue. to appear.
K. Poncin and H. Rieser. 2006. Multi-speaker utter-
ances and co-ordination in task-oriented dialogue.
Journal of Pragmatics, 38(5):718?744.
M. Purver, R. Cann, and R. Kempson. 2006.
Grammars as parsers: Meeting the dialogue chal-
lenge. Research on Language and Computation,
4(2-3):289?326.
M. Purver, C. Howes, P. G. Healey, and E. Gre-
goromichelaki. 2009. Split utterances in dialogue:
a corpus study. In SigDial 2009 workshop proceed-
ings.
H. Sacks, E. Schegloff, and G. Jefferson. 1974. A sim-
plest systematics for the organization of turn-taking
for conversation. Language, pages 696?735.
E. Schegloff. 1995. Parties and talking together: Two
ways in which numbers are significant for talk-in-
interaction. Situated order: Studies in the social
organization of talk and embodied activities, pages
31?42.
M. Schober and S. Brennan. 2003. Processes of in-
teractive spoken discourse: The role of the partner.
Handbook of discourse processes, pages 123?64.
B. Szczepek. 2000. Formal Aspects of Col-
laborative Productions in English Conversa-
tion. Interaction and Linguistic Structures
(InLiSt), http://www.uni-potsdam.de/u/
inlist/issues/17/index.htm.
86
Proceedings of SIGDIAL 2009: the 10th Annual Meeting of the Special Interest Group in Discourse and Dialogue, pages 262?271,
Queen Mary University of London, September 2009. c?2009 Association for Computational Linguistics
Split Utterances in Dialogue: a Corpus Study
Matthew Purver, Christine Howes,
and Patrick G. T. Healey
Department of Computer Science
Queen Mary University of London
Mile End Road, London E1 4NS, UK
{mpurver,chrizba,ph}@dcs.qmul.ac.uk
Eleni Gregoromichelaki
Department of Philosophy
King?s College London
Strand, London WC2R 2LS, UK
eleni.gregor@kcl.ac.uk
Abstract
This paper presents a preliminary English
corpus study of split utterances (SUs), sin-
gle utterances split between two or more
dialogue turns or speakers. It has been
suggested that SUs are a key phenomenon
of dialogue, which this study confirms: al-
most 20% of utterances were found to fit
this general definition, with nearly 3% be-
ing the between-speaker case most often
studied. Other claims/assumptions in the
literature about SUs? form and distribu-
tion are investigated, with preliminary re-
sults showing: splits can occur within syn-
tactic constituents, apparently at any point
in the string; it is unusual for the sepa-
rate parts to be complete units in their own
right; explicit repair of the antecedent does
not occur very often. The theoretical con-
sequences of these results for claims in
the literature are pointed out. The prac-
tical implications for dialogue systems are
mentioned too.
1 Introduction
Split utterances (SUs) ? single utterances split be-
tween two or more dialogue turns/speakers ? have
been claimed to occur regularly in dialogue, espe-
cially according to the observations reported in the
Conversational Analysis (CA) literature, which is
based on the analysis of naturally occurring di-
alogues. SUs are of interest to dialogue theo-
rists as they are a clear sign of how turns cohere
with each other at all levels ? syntactic, seman-
tic and pragmatic. They also indicate the radi-
cal context-dependency of conversational contri-
butions. Turns can, in general, be highly ellip-
tical and nevertheless not disrupt the flow of the
dialogue. SUs are the most dramatic illustration
of this: contributions spread across turns/speakers
rely crucially on the dynamics of the unfolding
context, linguistic and extra-linguistic, in order to
guarantee successful processing and production.
Utterances that are split across speakers also
present a canonical example of participant coor-
dination in dialogue. The ability of one partic-
ipant to continue another interlocutor?s utterance
coherently, both at the syntactic and the seman-
tic level, suggests that both speaker and hearer are
highly coordinated in terms of processing and pro-
duction. The initial speaker must be able to switch
to the role of hearer, processing and integrating the
continuation of their utterance, whereas the ini-
tial hearer must be closely monitoring the gram-
mar and content of what they are being offered
so that they can take over and continue in a way
that respects the constraints set up by the first part
of the utterance. In fact there is (anecdotal) ev-
idence that such constraints are fully respected
across speaker and hearer in such utterances (see
e.g. Gregoromichelaki et al (2009)). A large pro-
portion of the CA literature on SUs tries to iden-
tify the conditions under which SUs usually oc-
cur (see section 2). However, this emphasis seems
to miss the important generalisation, confirmed
by the present study, that, syntactically, a speaker
switch may be able to occur anywhere in a string.
From a theoretical point of view, the implica-
tions of the above are that, if such observations
have an empirical foundation, the grammar em-
ployed by the interlocutors must be able to license
and the semantics interpret chunks much smaller
than the usual sentence/proposition units. More-
over, these observations have implications for the
nature of the grammar itself: dynamic, incremen-
tal formalisms seem more amenable to the mod-
262
elling of this phenomenon as the switch of roles
while syntactic/semantic dependencies are pend-
ing can be taken as evidence for direct involve-
ment of the grammar in the successful process-
ing/production of such utterances. Indeed, Poesio
and Rieser (to appear) claim that ?[c]ollaborative
completions . . . are among the strongest evidence
yet for the argument that dialogue requires coor-
dination even at the sub-sentential level? (italics
original).
From a psycholinguistic point of view, the phe-
nomenon of SUs is compatible with mechanis-
tic approaches as exemplified by the Interactive
Alignment model of Pickering and Garrod (2004)
where it is claimed that it should be as easy to
complete someone else?s sentence as one?s own
(Pickering and Garrod, 2004, p186). According
to this model, speaker and listener ought to be in-
terchangeable at any point. This is also the stance
taken by the grammatical framework of Dynamic
Syntax (DS) (Kempson et al, 2001; Cann et al,
2005). In DS, parsing and production are taken
to employ the same mechanisms, leading to a pre-
diction that split utterances ought to be strikingly
natural (Purver et al, 2006). However, from a
pragmatic point of view, utterance continuation
by another speaker might involve some kind of
guessing1 or preempting the other interlocutor?s
intended content. It has therefore been claimed
that a full account of this phenomenon requires
a complete model of pragmatics that can handle
intention recognition and formation. Indeed, Poe-
sio and Rieser (to appear) claim that ?the study
of sentence completions . . . may be used to com-
pare competing claims about coordination ? i.e.
whether it is best explained with an intentional
model like Clark (1996)?s . . . or with a model
based on simpler alignment models like Pickering
and Garrod (2004)?s.? They conclude that a model
which includes modelling of intentions better cap-
tures the data.
For computational models of dialogue, how-
ever, SUs pose a challenge. While Poesio and
Rieser (to appear) and Purver et al (2006) pro-
vide general foundational models for various parts
of the phenomenon, there are many questions that
remain if we are to begin automatic processing.
A computational dialogue system must be able
to identify SUs, match up their two (or more)
1Note that this says nothing about whether such a contin-
uation is the same as the initial speaker?s intended continua-
tion.
parts (which may not necessarily be adjacent), in-
tegrate them into some suitable syntactic and/or
semantic representation, and determine the over-
all pragmatic contribution to the dialogue context.
SUs also have implications for the organisation of
turn-taking in such models (see e.g. Sacks et al
(1974)), as regards what conditions (if any) allow
or prevent successful turn transfer. Additionally,
from a socio-linguistic point of view, turn-taking
operates (according to Schegloff (1995)) not on
individual conversational participants, but on ?par-
ties?. Lerner (1991) suggests that split utterances
can clarify the formation of such parties in that
they reveal evidence of how syntax can be em-
ployed to organise participants into ?groups?.
Analysis of SUs, when they can or cannot oc-
cur, and what effects they have on the coordina-
tion of agents in dialogue, is therefore an area of
interest not only for conversational analysts wish-
ing to characterise systematic interactions in di-
alogue, but also for linguists trying to formulate
grammars of dialogue, psychologists and sociolin-
guists interested in alignment mechanisms and so-
cial interaction, and those interested in building
automatic dialogue processing systems. In this pa-
per we present and examine empirical corpus data
in order to shed light on some of the questions and
controversies around this phenomenon.
2 Related Work
Most previous work on what we call SUs has ex-
amined specific sub-cases, generally of the cross-
speaker type, and have referred to these vari-
ously as collaborative turn sequences (Lerner,
1996; Lerner, 2004), collaborative completions
(Clark, 1996; Poesio and Rieser, to appear),
co-constructions (Sacks, 1992), joint produc-
tions (Helasvuo, 2004), co-participant comple-
tions (Hayashi, 1999; Lerner and Takagi, 1999),
collaborative productions (Szczepek, 2000) and
anticipatory completions (Fox and others, 2007)
(amongst others). Here we discuss some of these
views.
Conversation Analysis Lerner (1991) identifies
various structures typical of SUs which contain
characteristic split points. Firstly he gives a
number of ?compound? turn-constructional units
(TCUs), i.e., structures that include an initial con-
stituent that hearers can identify as introducing
some later final component. Examples include the
IF X-THEN Y, WHEN X-THEN Y and INSTEAD
263
OF X-Y constructions:
(1) A: Before that then if they were ill
G: They get nothing. [BNC H5H 110-111]
Other cues for potential anticipatory completions
include quotation markers (e.g. SHE SAID), paren-
thetical inserts and lists, as well as non-syntactic
cues such as contrast stress or prefaced disagree-
ments. Ru?hlemann (2007) uses corpus analysis to
examine sentence relatives as typical expansions
of another interlocutor?s turn (see also (16)):
(2) A: profit for the group is a hundred and
ninety thousand pounds.
B: Which is superb. [BNC FUK 2460-2461 ]
Opportunistic Cases Although Lerner focuses
on these projectable turn completions, he also
mentions that splits can occur at other points such
as ?intra-turn silence?, hesitations etc. which he
terms opportunistic completions:
(3) A: Well I do know last week thet=uh Al was
certainly very ? pause 0.5?
B: pissed off [(Lerner, 1996, p260)]
As he makes no claims regarding the frequency
of such devices for SUs, it would be interesting to
know how common these are (insomuch as they
occur at all and can be accordingly classified), es-
pecially as studies on SUs in Japanese (Hayashi,
1999) show that although SUs do occur, they do
not rely on compound TCUs.
Expansions vs. Completions Other classifica-
tions of SUs often distinguish between expansions
and completions (Ono and Thompson, 1993). Ex-
pansions are continuations which add, e.g., an ad-
junct, to an already complete syntactic element:
(4) T: It?ll be an E sharp.
G: Which will of course just be played as an
F. [BNC G3V 262-263]
whilst completions involve the addition of syntac-
tic material which is required to make the whole
utterance complete:
(5) A: . . . and then we looked along one deck, we
were high up, and down below there were
rows of, rows of lifeboats in case you see
B: There was an accident.
A: of an accident [BNC HDK 63-65]
In terms of frequency, the only estimate we
know of is Szczepek (2000), where there are ap-
parently 200 cross-person SUs in 40 hours of En-
glish conversation (there is no mention of the num-
ber of sentences or turns this equates to), of which
75% are completions.2 As briefly outlined above,
CA analyses of SUs tend to be broadly descriptive
of what they reveal for conversational practices.
Because such analyses present real examples they
establish that the phenomenon is a genuine one;
however, there is no discussion of its scale (with
the exception of Szczepek (2000), which offers ex-
tremely limited figures). Even though as a gen-
uine phenomenon it is of theoretical interest, the
lack of frequency statistics prevents generalisabil-
ity. Therefore, any claims that SUs are pervasive
in dialogue need empirical backing.
Linguistic Models Purver et al (2006) present
a grammatical model for split utterances, using an
inherently incremental grammar formalism, Dy-
namic Syntax (Kempson et al, 2001; Cann et al,
2005). This model shows how syntactic and se-
mantic processing can be accounted for no mat-
ter where the split occurs in a sentence; how-
ever, as their interest is in grammatical process-
ing, they give no account of any higher-level in-
ferences which may be required. Poesio and
Rieser (to appear) present a general model for col-
laborative completions based in the PTT frame-
work, using an incremental LTAG-based gram-
mar and an information-state-based approach to
context modelling. While many parts of their
model are compatible with a simple alignment-
based communication model like Pickering and
Garrod (2004)?s, they see intention recognition as
crucial to dialogue management. They conclude
that an intention-based model, more like Clark
(1996)?s, is more suitable. Their primary concern
is to show how such a model can account for the
hearer?s ability to infer a suitable continuation, but
their use of an incremental interpretation method
also allows an explanation of the low-level utter-
ance processing required. Nevertheless, the use
of an essentially head-driven grammar formalism
suggests that some syntactic splits that appear in
our corpus might be more problematic than oth-
ers.
Corpus Studies Skuplik (1999), as reported by
Poesio and Rieser (to appear), collected data from
German two-party task-oriented dialogue, and an-
notated for split utterance phenomena. She found
that expansions (cases where the part before the
split can be considered already complete) were
2However, this could be affected by her decision not to
include what she calls appendor questions in her data which
could also be argued to be expansion SUs.
264
more common than completions (where the first
part is incomplete as it stands). Given that this
study focuses on task-oriented dialogue, it needs
to be shown that its results can be replicated in nat-
urally occurring dialogue. In addition, de Ruiter
and van Dienst (in preparation) are also in the pro-
cess of studying other-initiated completions, in the
above sense, and their effect on the progressivity
of dialogue turns; however no results are available
to us at this point in time.
Dialogue Models We are not aware of any
system/model which treats other-person splits,
but same-person ones are now being looked at.
Skantze and Schlangen (2009) present an incre-
mental system design (for a limited domain) which
can react to user feedback, e.g., backchannels, and
resume with utterance completion if interrupted.
Some related empirical work regarding the issue
of turn-switch addressed here is also presented in
Schlangen (2006) but the emphasis there centered
mostly on prosodic rather than grammar/theory-
based factors.
3 Method
3.1 Terminology
In this paper, as our interest is general, we use the
term split utterances (SUs) to cover all instances
where an utterance is spread across more than one
dialogue contribution ? whether the contributions
are by the same or different speakers. We there-
fore use the term split point to refer to the point at
which the utterance is split (rather than e.g. tran-
sition point which is associated with a speaker
change). Cases where speaker does change across
the split will be called other-person splits; oth-
erwise same-person splits. One of the reasons
for including same-person splits is that there are
claims in the literature that the initial speaker may
strategically continue completing their own utter-
ance, after another person?s intervention, as an al-
ternative to acceptance or rejection of this inter-
vention (delayed completion, (Lerner, 1996)). In
addition, both grammatical formalisms (Purver et
al., 2006) and psycholinguistic models (Picker-
ing and Garrod, 2004) predict that SUs should be
equally natural in both the same- and other- person
conditions.
As not all cases will lead to complete contri-
butions, and not all will be split over exactly two
contributions, we also avoid terms like first-half,
second-half and completion: instead the contri-
butions on either side of a split point will be re-
ferred to as the antecedent and the continuation.
In cases where an utterance has more than one split
point, some portions may therefore act as the con-
tinuation for one split point, and the antecedent for
the next.
3.2 Questions
General Our first interest is in the general statis-
tics regarding SUs: how often do they occur, and
what is the balance between same- and other-
person splits? Do they usually fall into the specific
categories (with specific preferred split points) ex-
amined by e.g. Lerner (1991), or can the split
point be anywhere?
Completeness For a grammatical treatment
of SUs, as well as for implementing pars-
ing/production mechanisms for their processing,
we need to know about the likely completeness
of antecedent and continuation (if they are al-
ways complete in their own right, a standard head-
driven grammar may be suitable; if not, some-
thing more fundamentally incremental may be re-
quired). In addition, CA and other strategic anal-
yses of dialogue phenomena predict that split ut-
terances should occur at turn-transfer points that
are foreseeable by the participants. Complete syn-
tactic units serve this purpose from this point of
view and lack of such completeness will seem
to weaken this general claim. We therefore ask
how often antecedents and continuations are them-
selves complete,3 and look at the syntactic and lex-
ical categories which occur either side of the split.
Repair and Overlap Thirdly, we look at how
often splits involve explicit repair of antecedent
material, and how this depends on antecedent
completeness. Although, sometimes, repair might
be attributed to overlap or speaker uncertainty, it
also might indicate issues regarding preemptive
tactics on the part of the current speaker who needs
to reformulate the original contribution in order
to accommodate their novel offering or take into
account feedback offered while constructing their
utterance. Amount of repair also indicates the de-
gree of attempt the current speaker is making to
3For antecedents, we are more interested in whether they
end in a way that seems complete (they may have started ir-
regularly due to overlap or another split); for continuations,
whether they start in such a way (they may not get finished
for some other reason, but we want to know if they would be
complete if they do get finished).
265
Tag Value Explanation
end-complete y/n For all sentences: does this sentence end in such a way as to
yield a complete proposition or speech act?
continues sentence ID For all sentences: does this sentence continue the proposition
or speech act of a previous sentence? If so, which one?
repairs number of words For continuations: does this continuation explicitly repair
words in the antecedent? If so, how many?
start-complete y/n For continuations: does this continuation start in such a way as
to be able to stand alone as a complete proposition or speech
act?
Table 1: Annotation Tags
integrate syntactically their contribution with the
antecedent. However, we also examine how often
continuations involve overlap, which also has im-
plications for turn-taking management, and how
this depends on antecedent completeness.
3.3 Corpus
For this exercise we used the portion of the
BNC (Burnard, 2000) annotated by Ferna?ndez and
Ginzburg (2002), chosen to maintain a balance be-
tween context-governed dialogue (tutorials, meet-
ings, doctor?s appointments etc.) and general con-
versation. This portion comprises 11,469 sen-
tences taken from 200-turn sections of 53 separate
dialogues.
The BNC transcripts are already annotated for
overlapping speech, for non-verbal noises (laugh-
ter, coughing etc.) and for significant pauses.
Punctuation is included, based on the original au-
dio and the transcribers? judgements; as the au-
dio is not available, we allowed annotators to use
punctuation where it aided interpretation. The
BNC transcription protocol provides a sentence-
level annotation as well as an utterance (turn)-level
one, where turns may be made of several sentences
by the same speaker. We annotated at a sentence-
level, to allow self-continuations within a turn to
be examined. The BNC also forces turns to be
presented in linear order, which is vital if we are
to accurately assess whether turns are continua-
tions of one another; however, this has a side-
effect of forcing long turns to appear split into sev-
eral shorter turns when interrupted by intervening
backchannels. We will discuss this further below.
Annotation Scheme The initial stage of manual
annotation involved 4 tags: start-complete,
end-complete, continues and repairs ?
these are explained in Table 1 above. Sentences
which somehow require continuation (whether
they receive it or not) are therefore those marked
end-complete=n; sentences which act as
continuations are those marked with non-empty
continues tags; and their antecedents are the
values of those continues tags. Further specific
information about the syntactic or lexical nature of
antecedent or continuation components could then
be extracted (semi-)automatically, using the BNC
transcript and part-of-speech annotations.
Inter-Annotator Agreement Three annotators
were used, all linguistically knowledgeable. First,
all three annotators annotated one dialogue inde-
pendently, then compared results and discussed
differences. They then annotated 3 further di-
alogues independently to assess inter-annotator
agreement; kappa statistics (Carletta, 1996) are
shown in Table 2 below.
Tag KND KBG KB0
end-complete .86-.92 .80-1.0 .73-.90
continues (y/n) .89-.81 .76-.85 .77-.89
continues (ant) .90-.82 .74-.85 .76-.86
repairs 1.0-1.0 .55-.81 1.0-1.0
Table 2: Inter-Annotator ? statistic (min-max)
With the exception of the repairs tag for one
annotator pair for one dialogue, all are above 0.7;
the low figure results from a few disagreements
in a dialogue with only a very small number of
repairs instances. The remaining dialogues
were divided evenly between the three annotators.
4 Results and Discussion
The 11,469 sentences annotated yielded 2,228
SUs, of which 1,902 were same-person and 326
other-person splits; 111 examples involved an ex-
plicit repair by the continuation of some part of the
antecedent.
266
person: same other
overlapping 0 17
adjacent 840 260
sep. by overlap 320 10
sep. by backchnl 460 17
sep. by 1 sent 239 16
sep. by 2 sents 31 4
sep. by 3 sents 5 1
sep. by 4 sents 4 0
sep. by 5 sents 1 0
sep. by 6 sents 2 1
Total 1902 326
Table 3: Antecedent/continuation separation
General Same-person splits are much more
common than other-person; however, this is partly
an artefact of the BNC transcription protocol
(which forces contributions to be linearly ordered)
and our choice to annotate at the sentence level.
Around 44% of same-person cases are splits be-
tween sentences within the same-speaker turn;
and a further 17% are separated only by other-
speaker material which entirely overlaps with the
antecedent and therefore does not necessarily ac-
tually interrupt the turn. Both of these might be
considered as single utterances under some views.
However, we believe that splits between same-
turn sentences must be investigated in that the
transcription into separate sentences does indicate
some pause or other separating prosody and, from
a processing/psycholinguistic point of view, it
should be determined whether other-person splits
occur in the same places as same-person split
boundaries. Even in cases of overlap, one can-
not exclude the fact that the shape of the current
speaker?s utterance is influenced by receipt of the
feedback. Nevertheless, we will examine these
issues in further research and hence we exclude
within-turn splits of this type from here on.
Many splits are non-adjacent (see Table 3), with
the antecedent and continuation separated by at
least one intervening sentence. In same-person
cases, once we have excluded the within-turn
splits described above, this must in fact always
be the case; the intervening material is usually a
backchannel (62% of remaning cases) or a sin-
gle other sentence (32%, often e.g. a clarification
question), but two intervening sentences are possi-
ble (4%) with up to six being seen. In other-person
cases, 88% are adjacent or separated only by over-
lapping material, but again up to six intervening
person: same other
and/but/or 748 116
so/whereas 257 39
because 77 3
(pause) 56 5
which/who/etc 26 4
instead of 4 1
said/thought/etc 14 0
if then 1 0
when then 1 1
(other) 783 161
Table 4: Continuation categories
sentences were seen, with a single sentence most
common (10%, in half of which the intervening
sentence was a backchannel).
Many utterances have more than one split. In
same-person cases, a single utterance can be split
over as many as thirteen individual sentence con-
tributions; although such extreme cases occur gen-
erally within one-sided dialogues such as tutori-
als, many multi-split cases are also seen in general
conversation. Only 63% of cases consisted of only
two contributions. Antecedents can also receive
more than one competing continuation, although
this is rare: two continuations are seen in 2% of
cases.
CA Categories We searched for examples
which match CA categories (Lerner, 1991;
Ru?hlemann, 2007) by looking for particular lex-
ical items on either side of the split. Matching was
done loosely, to allow for the ungrammatical na-
ture of dialogue ? for example, an instance was
taken to match the IF X-THEN Y pattern if the con-
tinuation began with ?then? (modulo filled pauses
and non-verbal material) and the antecedent con-
tained ?if? at any point) ? so the counts may be
over-estimates. For Lerner (1996)?s opportunistic
cases, we looked for filled pauses (?er/erm? etc.)
or pauses explicitly annotated in the transcript, so
counts in this case may be underestimates.4 We
also chose some other broad categories based on
our observations of the most common cases. Re-
sults are shown in Table 4.5
The most common of the CA categories can be
4In further research we will examine other features as spe-
cialised laugh tokens, repetitions etc. as well as their particu-
lar positioning
5Note that the categories in Table 4 are not all mutually
exclusive (e.g. an example may have both an ?and?-initial
continuation and an antecedent ending in a pause), so column
sums will not match Table 3.
267
seen to be Lerner (1996)?s hesitation-related op-
portunistic cases, which make up at least 2-3% of
both same- and other-person splits. Ru?hlemann
(2007)?s sentence relative clause cases are next,
with over 1%; the others make up only small pro-
portions.
In contrast, by far the most common pattern (for
both same- and other-) is the addition of an ex-
tending clause, either a conjunction introduced by
?and/but/or/nor? (35-40%), or other clause types
with ?so/whereas/nevertheless/because?. Other
less obviously categorisable cases make up 40-
50% of continuations, with the most common first
words being ?you?, ?it?, ?I?, ?the?, ?in? and ?that?.
Completeness and repair Examination of the
end-complete annotations shows that about
8% of sentences in general are incomplete, but
that (perhaps surprisingly) only 63% of these get
continued. For both same- and other-person con-
tinuations, the vast majority (72% and 74%) con-
tinue an already complete antecedent, with only
26-28% therefore being completions in the sense
of e.g. de Ruiter and van Dienst (in preparation).
This does, however, mean that continuations are
significantly more likely than other sentences to
follow an incomplete antecedent (p < 0.001 us-
ing ?2(1)). Interestingly, though, continuations are
no more likely than other sentences to be complete
themselves.
The frequent clausal categories from Table 4 are
all more likely to continue complete antecedents
than incomplete ones, with the exception of the
(other) category; this suggests that split points
often occur at random points in a sentence, without
regard to particular clausal constructions (see also
A.1 for more examples and context):
(6) D: you know what the actual variations
U: entails
D: entails. you know what the actual quality
of the variations are.
[BNC G4V 114-117]
For the less frequent (e.g. ?if/then?, ?instead of?)
categories, the counts are too low to be sure.
Excluding all the clausal constructions (i.e.
looking only at the general (other) category),
and looking only at other-person cases, we see that
antecedents often end in a complete way (53%) but
that continuations do not often start in a complete
way (24%). Continuations are more than twice
as likely to start in a non-complete as opposed
to complete way, even after complete antecedents.
Explicit repair of some portion of the antecedent
is not common, only occurring in just under 5%
of splits. As might be expected, incomplete an-
tecedents are more likely to be repaired (13% vs.
2%, p < 0.001 using ?2(1)). Other-continuations
are also significantly more likely to repair their an-
tecedents than same-person cases (10% vs. 4%,
p < 0.001 using ?2(1)).
Problematic cases Examination of the data
shows that SUs is not necessarily an autonomous
well-defined category independent of other frag-
ment classifications in the literature. Besides cases
where it is not easy to identify whether a fragment
is a continuation or not or what the antecedent
is (see A.2), there are also cases where, as has
already been pointed out in the literature (Gre-
goromichelaki et al, 2009; Bunt, 2009), fragments
exhibit multifunctionality. This can be illustrated
by the following where the continuation could be
taken also as request for confirmation/question (7)
or a reply to a clarification request (8):
(7) M: It?s generated with a handle and
J: Wound round?
M: Yes [BNC K69 109-112]
(8) S: Quite a good word processor.
J: A word processor?
S: Which is vag- it?s basically a subset of
Word. [BNC H61 37-39]
In this respect, an interesting category is Lerner?s
delayed completions where often the continuation
also serves as some kind of repair or reformulation
(see e.g. (6) and A.3 (26)).
5 Conclusions
Although most of Lerner (1991)?s categories ap-
pear, they are not necessarily the most frequent.
On the other hand, the general results seem to in-
dicate that splits can occur anywhere in a string,
both in the same- or other- conditions. Both these
are consistent with models that advocate highly
coordinated resources between interlocutors and,
moreover, the need for highly incremental means
of processing (Purver et al, 2006; Skantze and
Schlangen, 2009). From a computational mod-
elling point of view, the results also indicate that
start-completeness of continuations is rare, which
means that a dialogue system has a chance of spot-
ting continuations from surface characteristics of
268
the input. This is hampered though by the fact
that the split can occur within any type of syn-
tactic constituent, hence no reliable grammatical
features can be employed securely. On the other
hand, end-incompleteness of antecedents is not as
common as would be expected and long distances
between antecedent and continuation are possible.
In this respect, locating the antecedent is not a
straightforward task for automated systems, espe-
cially again as this can be any type of constituent.
References
H. Bunt. 2009. Multifunctionality and multidimen-
sional dialogue semantics. In Proceedings of Dia-
Holmia, 13th SEMDIAL Workshop.
L. Burnard. 2000. Reference Guide for the British Na-
tional Corpus (World Edition). Oxford University
Computing Services http://www.natcorp.
ox.ac.uk/docs/userManual/.
R. Cann, R. Kempson, and L. Marten. 2005. The Dy-
namics of Language. Elsevier, Oxford.
J. Carletta. 1996. Assessing agreement on classifica-
tion tasks: The kappa statistic. Computational Lin-
guistics, 22(2):249?255.
H. Clark. 1996. Using Language. Cambridge Univer-
sity Press.
J. de Ruiter and M. van Dienst. in preparation. Com-
pleting other people?s utterances: evidence for for-
ward modeling in conversation. ms.
R. Ferna?ndez and J. Ginzburg. 2002. Non-sentential
utterances: A corpus-based study. Traitement Au-
tomatique des Langues, 43(2).
A. Fox et al 2007. Principles shaping grammati-
cal practices: an exploration. Discourse Studies,
9(3):299.
E. Gregoromichelaki, Y. Sato, R. Kempson, A. Gargett,
and C. Howes. 2009. Dialogue modelling and the
remit of core grammar. In Proceedings of IWCS.
M. Hayashi. 1999. Where Grammar and Interac-
tion Meet: A Study of Co-Participant Completion in
Japanese Conversation. Human Studies, 22(2):475?
499.
M. Helasvuo. 2004. Shared syntax: the gram-
mar of co-constructions. Journal of Pragmatics,
36(8):1315?1336.
R. Kempson, W. Meyer-Viol, and D. Gabbay. 2001.
Dynamic Syntax: The Flow of Language Under-
standing. Blackwell.
G. Lerner and T. Takagi. 1999. On the place
of linguistic resources in the organization of talk-
in-interaction: A co-investigation of English and
Japanese grammatical practices. Journal of Prag-
matics, 31(1):49?75.
G. Lerner. 1991. On the syntax of sentences-in-
progress. Language in Society, pages 441?458.
G. Lerner. 1996. On the semi-permeable character
of grammatical units in conversation: Conditional
entry into the turn space of another speaker. In
E. Ochs, E. A. Schegloff, and S. A. Thompson,
editors, Interaction and grammar, pages 238?276.
Cambridge University Press.
G. Lerner. 2004. Collaborative turn sequences. In
Conversation analysis: Studies from the first gener-
ation, pages 225?256. John Benjamins.
T. Ono and S. Thompson. 1993. What can conversa-
tion tell us about syntax. In P. Davis, editor, Alterna-
tive Linguistics: Descriptive and Theoretical Modes.
Benjamin.
M. Pickering and S. Garrod. 2004. Toward a mech-
anistic psychology of dialogue. Behavioral and
Brain Sciences, 27:169?226.
M. Poesio and H. Rieser. to appear. Completions, co-
ordination, and alignment in dialogue. Ms.
M. Purver, R. Cann, and R. Kempson. 2006.
Grammars as parsers: Meeting the dialogue chal-
lenge. Research on Language and Computation,
4(2-3):289?326.
C. Ru?hlemann. 2007. Conversation in context: a
corpus-driven approach. Continuum.
H. Sacks, E. A. Schegloff, and G. Jefferson. 1974.
A simplest systematics for the organization of turn-
taking for conversation. Language, 50(4):696?735.
H. Sacks. 1992. Lectures on Conversation. Blackwell.
E. Schegloff. 1995. Parties and talking together: Two
ways in which numbers are significant for talk-in-
interaction. Situated order: Studies in the social
organization of talk and embodied activities, pages
31?42.
D. Schlangen. 2006. From reaction to prediction: Ex-
periments with computational models of turn-taking.
In Proceedings of the 9th International Conference
on Spoken Language Processing (INTERSPEECH -
ICSLP).
G. Skantze and D. Schlangen. 2009. Incremental dia-
logue processing in a micro-domain. In Proceedings
of the 12th Conference of the European Chapter of
the ACL (EACL 2009).
K. Skuplik. 1999. Satzkooperationen. definition und
empirische untersuchung. SFB 360 1999/03, Biele-
feld University.
B. Szczepek. 2000. Formal Aspects of Collaborative
Productions in English Conversation. Interaction
and Linguistic Structures (InLiSt), http://www.
uni-potsdam.de/u/inlist/issues/17/.
269
A Examples
A.1 Split points
(6) D: Yeah I mean if you?re looking at quan-
titative things it?s really you know how
much actual- How much variation hap-
pens whereas qualitative is ?pause? you
know what the actual variations
U: entails
D: entails. you know what the actual quality
of the variations are.
[BNC G4V 114-117]
(9) A: All the machinery was
G: [[All steam.]]6
A: [[operated]] by steam
[BNC H5G 177-179]
(10) K: I?ve got a scribble behind it, oh annual re-
port I?d get that from.
S: Right.
K: And the total number of [[sixth form stu-
dents in a division.]]
S: [[Sixth form stu-
dents in a division.]] Right.
[BNC H5D 123-127]
(11) M: 292 And another sixteen percent is the
other Ne- Nestle coffee ?pause? erm
Blend Thirty Seven which I used to drink
a long time ago and others ?laugh? and
twenty two percent is er ?pause?
U: Maxwell.
M: Maxwell House, which has become the
other local brand now seeing as how
Maxwell House is owned by Kraft, and
Kraft now own Terry?s.
[BNC G3U 292-294]
(12) A: Erm because as Moira said that Kraft is
erm ?pause? now what was she saying,
what was she saying Kraft is the same as
?pause?
M: Craft? [BNC G3U 412-413]
(13) J: And I couldn?t remember whether she
said at the end of the three months or
A: End of the month. [BNC H4P 17-18]
6Overlapping material is shown in double square brackets,
aligned with the material with which it co-occurs.
(14) G: Had their own men
A: unload the boats?
G: unload the boats, yes. [BNC H5H 91-93]
(15) G: That?s right they had to go on a rota.
A: Run by the Dock Commission?
G: Run by the Dock Commission.
[BNC H5H 100-102]
(16) A: So I thought, oh, I think I?ll put lace over
it, it?ll tone the lilac [[down.]]
B: [[down.]] Yes.
Which it is has done
[BNC KBC 3195-3198]
A.2 Uncertain antecedents
(17) C: Look you?re cleaning this ?pause?
[[with erm]]
G: [[That box.]]
C: [[This.]]
G: [[With]] this. [[And this.]]
C: [[And this.]] [[And this.]]
G: [[And this.]]
Whoops! [BNC KSR 9-17]
(18) S: You?re trying to be everything ?pause?
and they?re pushing it away cos it?s not
what they really want ?pause? and they, I
mean, all, all you can get from him is how
marvellous, you?re right, how marvellous
his brothers are ?pause? and yet, what I?ve
heard of the brothers they?re not
C: Not much, [[yeah.]]
S: [[they?re]] not all that marvel-
lous, they?re not really that much to look
[[up]]
C: [[Ah]].
S: to.
C: No [BNC KBG 76-81]
(19) S: Well this is why I think he?d be better
off, hi- his needs ?pause? are not met by a
class teacher. And I don?t think they have
been for this last
C: Mm, we need a support teacher [[to go
there.]]
S: [[for the
last]] year. But yo-, you need somebody
who?s gonna work with him every day
?pause? and ?pause? with an individual
programme and you just can?t offer that
?pause? in a class. [BNC KBG 56-60]
270
(20) M: I might be a bit biased, I think they still
do that but I think erm ?pause?
J: The television has ?pause?
M: the television has made a difference. I
think not only just at fire stations, I think
in the whole of life, hasn?t it?
[BNC K69 51-54]
(21)A5: I?ll definitely use that
U: ?reading?:[ Get a headache ]?
A5: [[in getting to know ]]
A2: [[Year seven ]]
A5: new [[year seven]]
A2: [[Oh yeah]] for year seven
[BNC J8D 190-195]
(22) G: Well a chain locker is where all the spare
chain used to like coil up
A: So it ?unclear? came in and it went round
G: round the barrel about three times round
the barrel then right down into the chain
locker but if you kept, let it ride what we
used to call let it ride well ?unclear? well
now it get so big then you have to run it
all off cos you had one lever, that?s what
you had and the steam valve could have
all steamed. [BNC H5G 174:176]
A.3 Multifunctionality of fragments
(7) Completion and confirmation request:
J: How does it generate?
M: It?s generated with a handle and
J: Wound round?
M: Yes, wind them round and this should,
should generate a charge which rang bells
and sounded bells and then er you lift up a
telephone and plug in a jack and, and take
a message in that way.
[BNC K69 109-112]
(23) Completion and confirmation request:
G: Had their own men
A: unload the boats?
G: unload the boats, yes. [BNC H5H 91-93]
(24) Late completion and (repetitive) confir-
mation:
N: Alistair [last or full name] erm he?s, he?s
made himself er he has made himself co-
ordinator.
U: And section engineer.
N: And section engineer.
N: I didn?t sign it as coordinator.
[BNC H48 141-144]
(25) Completion and clarification reply:
John: If you press N
Sarah: N?
John: N for name, it?ll let you type in the docu
document name. [BNC G4K 84-86]
(26) Expansion and reformulation/repair:
S: Secondly er
J: We guarantee P five.
S: We we are we?re guaranteeing P five plus
a noise level.
J: Yeah. [BNC JP3 167-170]
(27) Expansion and question:
I: I can?t remember exactly who lived on
the right hand side, I?ve forgotten but th
I know the Chief Clerk lived just a little
way down [address], you see, er
A: In one of those little red brick cottages?
[BNC HDK 124-125]
(28) Answer and expansion:
A: We could hear it from outside ?unclear?.
R: Oh you could hear it?
A: Occasionally yeah. [BNC J8D 13-15]
(29) Answer/reformulation and expansion:
G: [address], that was in the middle, more or
less in the middle of the town.
A: And you called that the manual?
G: The manual school, yes.
[BNC H5G 96-98]
271
Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pages 79?83,
Seoul, South Korea, 5-6 July 2012. c?2012 Association for Computational Linguistics
Predicting Adherence to Treatment for Schizophrenia from Dialogue
Transcripts
Christine Howes, Matthew Purver, Rose McCabe, Patrick G. T. Healey, Mary Lavelle
Queen Mary University of London
Mile End Road, London E1 4NS
c.howes@qmul.ac.uk
Abstract
Recent work on consultations between out-
patients with schizophrenia and psychiatrists
has shown that adherence to treatment can
be predicted by patterns of repair ? specifi-
cally, the pro-activity of the patient in check-
ing their understanding, i.e. patient clarifi-
cation. Using machine learning techniques,
we investigate whether this tendency can be
predicted from high-level dialogue features,
such as backchannels, overlap and each partic-
ipant?s proportion of talk. The results indicate
that these features are not predictive of a pa-
tient?s adherence to treatment or satisfaction
with the communication, although they do
have some association with symptoms. How-
ever, all these can be predicted if we allow
features at the word level. These preliminary
experiments indicate that patient adherence is
predictable from dialogue transcripts, but fur-
ther work is necessary to develop a meaning-
ful, general and reliable feature set.
1 Introduction
How conversational partners achieve and maintain
shared understanding is of crucial importance in
the understanding of dialogue. One such mecha-
nism, other initiated repair (Schegloff, 1992), where
one conversational participant queries or corrects
the talk of another, has been well documented in
both general and task-based dialogues (Colman and
Healey, 2011). However, how such shared under-
standing impacts beyond the level of the conversa-
tion has not typically been examined. Exceptions to
this have highlighted the role of shared understand-
ing in schizophrenia (McCabe et al, 2002; Themis-
tocleous et al, 2009) and the association between
psychiatrist-patient communication and adherence.
McCabe et al (in preparation) found that more pa-
tient clarification (i.e. other initiated repair) of the
psychiatrist?s talk was associated with better treat-
ment adherence six months later. Clarification con-
sists mainly of asking questions to clarify the mean-
ing of the psychiatrist?s utterance (checking under-
standing) and correcting something that the psychi-
atrist has said (getting the facts straight). Example 1,
taken from a consultation, shows the patient request-
ing clarification of something the psychiatrist has
just said about a possible side effect.
(1) Dr: Yep, well that is a possible side effect
Pat: Side effect?
Dr: Of the er haloperidol
The patient?s request leads to additional explana-
tion by the psychiatrist about the medication which
can cause the possible side effect. More patient clar-
ification reflects greater effort to reach a shared un-
derstanding. McCabe et al (in preparation) found
that for each unit increase in the patient clarification
factor,1 the odds of good (versus poor) adherence
were increased by 5.8 (95% CI 1.3 to 25.8, p=0.02).
Explaining the link between communicative pat-
terns of patients and adherence may create the pos-
sibility for new interventions to improve adherence,
and has both clinical and theoretical implications.
1A regression factor weighted heavily towards patient clar-
ifcations (as in e.g. 1).
79
However, there is no evidence regarding what fac-
tors influence patient clarification and may explain
the link with adherence. If patient clarification is
a measure of greater communicational effort, or en-
gagement, then wemight expect other dialogue mea-
sures, such as the amount of acknowledgements or
other grounding cues (Traum and Allen, 1992), or
the proportion of talk per person, to be correlated
with other initiated repair and therefore similarly
predictive of subsequent adherence behaviour. This
is of particular importance if we wish to build a sys-
tem to automatically predict possible (lack of) ad-
herence from dialogue transcripts, especially given
that the types of patient clarification which carry
the highest weight in the patient clarification factor
(next-turn repair initiators, Schegloff, 1992) are rare,
occurring on average only 1.2 times per dialogue.
Further, although certain types of repair were
shown to affect how patients reported they felt the
conversation went, self-reports of symptoms and
communicational factors are not predictive of adher-
ence. Although micro-communicational behaviour
(in the form of other initiated repair) does have a
bearing on subsequent adherence behaviour, patients
are unaware of this. Additional questions therefore
concern whether we can predict patient?s symptom
levels and subjective analyses of the communication
based only on overview dialogue factors.
2 Hypotheses
Factors which we would expect to index patient en-
gagement, and thus be predictive of adherence to
treatment are the amount of backchannel responses
patients make, and the proportion of questions pa-
tients ask, both of which ought to be higher for the
more engaged patients. We might also expect that
such patients have a greater proportion of the talk
overall, and/or longer turns on average, though note
that this conversational pattern might also be one in
which the patient is not engaged, as they might not
be responding to the feedback from their consultant.
For the symptom scores (see below for details),
we should expect that patients with high levels
of negative symptoms (which includes loss of af-
fect and poverty of speech) would produce less
talk overall, and in general produce shorter turns.
There should also be more noticeable gaps in the
dialogues (defined as greater than approximately
200ms, (Heldner and Edlund, 2010)). Contrarily,
for positive symptoms, (including hallucinations and
delusions) patients ought to produce longer turns
and have a greater proportion of the talk.
We also expect to see effects on how patients felt
the conversation went from the amount of overlap,
though as overlap can be both intended and inter-
preted as either interruptive or collaborative (as with
e.g. overlapping backchannels) it is unclear which
direction such a prediction should take.
3 Method
131 dialogues from outpatient consultations be-
tween patients and psychiatrists were analysed ac-
cording to a number of factors. Each of these fac-
tors, detailed in table 1, below, is calculated for each
dialogue participant (with the exception of pauses).
Each patient featured in only one of the dialogues
however, there were only 29 doctors in the study,
so the same clinician may have featured in several
of the dialogues with different patients. The con-
sultations varied in length, with the shortest con-
sisting of 61 turns (438 words) and the longest
881 turns (13178 words), with an average of 320.5
turns (2706.4 words). In addition, a third party was
present in 47 of the consultations.
Following the consultation, each patient was
asked questions from standard questionnaires to as-
certain their level of symptoms, and their evalua-
tion of aspects of the consultation. The positive
and negative syndrome scale (PANSS) (Kay et al,
1987) assesses positive, negative and general symp-
toms on a 7-point scale of severity (1=absent ? 7=ex-
treme). Positive symptoms represent a change in
the patients? behaviour or thoughts and include sen-
sory hallucinations and delusional beliefs. Negative
symptoms represent a withdrawal or reduction in
functioning, including blunted affect, and emotional
withdrawal and alogia (poverty of speech). Positive
and negative subscale scores ranged from 7 (absent)
? 49 (extreme), general symptoms (such as anxiety)
scores ranged from 16 (absent) ? 112 (extreme).
Patient satisfaction with the communication was
assessed using the Patient Experience Questionnaire
(PEQ) (Steine et al, 2001). Three of the five sub-
scales (12 questions) were used as the others were
80
not relevant, having been developed for primary
care. The three subscales were ?communication ex-
periences?, ?communication barriers? and ?emotions
immediately after the visit?. For the communication
subscales, items were measured on a 5-point Lik-
ert scale, with 1=disagree completely and 5=agree
completely. The four items for the emotion scale
were measured on a 7-point visual analogue scale,
with opposing emotions were at either end. A higher
score indicates a better experience.
Adherence to treatment was rated by the clini-
cians as good (> 75%), average (25  75%) or poor
(< 25%) six months after the consultation. Due to
the low incidence of poor ratings (only 8 dialogues),
this was converted to a binary score of 1 for good ad-
herence (91 patients), and 0 otherwise (37). Ratings
were not available for the remaining dialogues.
Measure Description
Turns Total number of turns
Words Total number of words spoken
Proportion Proportion of total talk in words
(by each participant)
WordsPerTurn Average length of turn in words
WhPerWord Proportion of wh-words (e.g.
what? who?) per word
OCRPerWord Proportion of open class repair ini-
tiators (e.g. pardon? huh?) per
word
BackchannelPerWord Proportion of backchannels (e.g.
uh-huh, yeah) per word
RepeatPerWord Proportion of words repeated from
preceding turn by other person
OverlapAny Proportion of turns containing any
overlapping talk
OverlapAll Proportion of turns entirely over-
lapping another turn
QMark Proportion of turns containing a
question mark
TimedPause Pause of more than approx 200ms,
as marked on the transcripts
Table 1: Measures from outpatient consultations
3.1 Classification Experiments
We performed a series of classification experiments
using the Weka machine learning toolkit (Hall et
al., 2009) to predict each of the outcome mea-
sures outlined above (symptom measures, satisfac-
tion measures, and adherence to treatment). In each
case, outcome measures were converted to binary
high/low scores on an equal frequency basis (i.e.
providing approximately equal numbers of high and
low instances). Features used were the high-level
measures given in Table 1, and/or all unigrams ex-
tracted from the transcript; in both cases, features
from doctor and patient were treated separately. Un-
igrams were produced by tokenising the lower-cased
transcripts on white space; no stemming or stop-
word removal was performed, and feature values
were binary i.e. indicating only presence or ab-
sence of the word spoken by the given speaker in
the given dialogue.2 Given the small size of our
dataset (131 instances) and the large feature space
resulting (> 6500 features), we selected features
based on their predictive ability across the entire
dataset (using Weka?s CfsSubsetEval selector), re-
ducing the number of features to 50-100. In order
to avoid biasing towards doctor-specific features, we
used only words spoken by patients in these exper-
iments ? each patient only features in one dialogue,
so patient-specific vocabulary cannot help perfor-
mance across dialogues. All unigram features thus
selected were used in at least 3 dialogues.3
4 Results
Experiments including unigram features used Lib-
SVM?s support vector machine implementation
(Chang and Lin, 2001) with a radial basis func-
tion kernel; experiments with only high-level fea-
tures used J48 decision trees. In each case, experi-
ments used 5-fold cross-validation.4 In experiments
predicting adherence, the distribution between pos-
itive and negative (i.e. good and bad adherence)
made it impossible to balance the dataset - as this
can be problematic for decision tree classifiers, we
also present results for a downsampled dataset with
only 71 instances but which provides balance. Per-
formance is shown in Table 2 as overall percentage
accuracy, and is compared to a majority-class base-
line throughout; results which are significantly dif-
ferent at the 5% level according to a  2 test from a
2Experiments with frequency counts did not affect the re-
sults as reported.
3Bi- and tri-gram features were not extracted from this data
because of the small amount of data available which we felt
would result in models that suffered from overfitting (note that
the same concern holds for the unigram features).
4Classifiers were trained on 80% and tested on 20% of the
sample, with this was repeated 5 times over each possible 80/20
combination so as to test the whole dataset.
81
random distribution and the majority class distribu-
tion are shown marked with *.
Baseline Words High-level
PANSS positive 51.1 87.0* 56.5*
PANSS negative 49.6 87.8* 56.5*
PANSS general 48.4 91.1* 54.0
PEQ emotions 51.9 89.1* 53.5
PEQ communication 50.8 79.8* 52.4
PEQ comm. barriers 51.6 90.6* 51.6
PEQ overall 50.8 90.6* 53.9
Adherence 73.2 91.1* 63.4
Adherence (balanced) 53.5 93.0* 52.1
Table 2: Percentage accuracies vs feature set
Results show good performance for all experi-
ments when including lexical features, with all fac-
tors being predictable with around 90% accuracy
with the exception of PEQ communication at just be-
low 80%. However, using high-level features alone
gives negligible performance, except for a small
benefit on the PANSS negative and positive symp-
tom measures, though contrary to our hypotheses
the most important high-level features were OCR-
PerWord by the doctor (negative) and WhWords by
an other participant (positive).
Examination of the most predictive unigrams
shows that sets selected for different outcome mea-
sures are different: for example, the 54 fea-
tures selected for adherence and the 73 selected
for PEQ overall have only 1 word in com-
mon (?mates?). Adherence-related words in-
clude words related to conditions, treatment and
medication (?schizophrenic?, ?sickness?, ?symp-
toms?, ?worse?, ?pains?, ?flashbacks?, ?sodium?,
?chemical?, ?monthly?); PEQ-related words in-
clude those related to personal life (?sundays?,
?thursdays?, ?television?, ?sofa?, ?wine?, ?per-
sonally?, ?played?), and filled pauses (?eerrmm?,
?uhhm?) ? although more investigation is required
to draw any firm conclusions from these. Table 3
shows the full lists for adherence and PEQ overall.
5 Discussion and Conclusions
The results show that although we can weakly pre-
dict symptoms at levels above chance using only
high-level dialogue factors, we cannot do so for ad-
herence, or satisfaction measures. Despite the link
between patient other initiated repair and adherence,
this is also not an effective predictor for our machine
learning approach because of the scarcity of the phe-
nomenon, and the fact that many of the consulta-
tions for which the patients subsequently exhibited
good adherence behaviour do not feature a single
patient clarification, which may be linked to psychi-
atrist clarity rather than lack of effort or engagement
on the patient?s part.
The high accuracies with lexical features show
that some aspects of the consultations do enable ac-
curate prediction of adherence, PEQ measures and
symptoms. However, as the features which allow us
to achieve such good results rely on specific words
used, it is unclear how generalisable or interpretable
such results are. The lexical features chosen do gen-
eralise over our dataset (in which individual patients
appear only once), and exclude doctor talk, so can-
not be simply picking out unique unigram signatures
relating to individual patients or doctors; however,
given the small size of the dataset used for this ini-
tial investigation with its constrained domain, genre
and topics, and the use of the whole dataset to select
predictive words, it is unclear whether these results
will scale up to a larger dataset.
We therefore suspect that more general, higher-
level dialogue features such as specific interac-
tion phenomena (repair, question-answering) and/or
more general models of topic may be required.
While unigrams are too low-level to be explanatory
and may not generalise, the dialogue features dis-
cussed are too high-level to be useful; we are there-
fore examining mid-level phenomena and models
to capture the predictability while remaining gen-
eral and providing more interpretable features and
results. Although the word lists offer clues as to
the relevance of specific words for the overall pre-
dictability, we would not like to leave it at that.
Further experiments are therefore underway to in-
vestigate whether we can find a level of appropri-
ate explanatory power and maximal predictivity us-
ing an interim level of analysis, for example with n-
gram and part-of-speech-based models, topic mod-
els based on word distributions, and turn-taking phe-
nomena. Additional experiments also look at the
turn-level data to see if the patient led clarification
factor can be directly extracted from the transcripts.
82
Adherence PEQ overall
air grass schizophrenic 20th electric onto sometime
anyone grave sensation ages energy overweight son
balanced guitar sickness angry environment oxygen standing
bleach h simply anxiety experiencing packed stomach
build hahaha sodium background facilities percent suddenly
building lager stable bladder friendly personally sundays
busy laying stock booked helps picture suppose
challenge lifting symptoms boy ignore played table
chemical lucky talks broken immediately programs team
complaining mates teach bus increased progress television
cup monthly terminology certificate irritated provide thursdays
dates mouse throat dead kick public troubles
en nowhere virtually deep later quid uhhm
fill pains was drunk lee radio upsetting
finished possibly wave earn loose realised walks
fish pr weve eeerrrr low reply watchers
flashbacks recent worse eerrmm march sat wine
removed writing eerrrmm mates shaky
ri moments sofa
Table 3: Most predictive unigram features
References
Chih-Chung Chang and Chih-Jen Lin, 2001. LIB-
SVM: a library for Support Vector Machines. Soft-
ware available at http://www.csie.ntu.edu.
tw/?cjlin/libsvm.
M. Colman and P. G. T. Healey. 2011. The distribution of
repair in dialogue. In Proceedings of the 33rd Annual
Meeting of the Cognitive Science Society, pages 1563?
1568, Boston, MA.
Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard
Pfahringer, Peter Reutemann, and Ian H. Witten.
2009. The WEKA data mining software: An update.
SIGDKDD Explorations, 11(1):10?18.
M. Heldner and J. Edlund. 2010. Pauses, gaps and
overlaps in conversations. Journal of Phonetics,
38(4):555?568.
S.R. Kay, A. Fiszbein, and L.A. Opfer. 1987. The
positive and negative syndrome scale (PANSS) for
schizophrenia. Schizophrenia bulletin, 13(2):261.
R. McCabe, C. Heath, T. Burns, S. Priebe, and J. Skel-
ton. 2002. Engagement of patients with psychosis in
the consultation: conversation analytic study. British
Medical Journal, 325(7373):1148?1151.
R. McCabe, M. Lavelle, S. Bremner, D. Dodwell, P. G. T.
Healey, R. Laugharne, S. Priebe, and A. Snell. in
preparation. Shared understanding in psychiatrist-
patient communication: Association with treatment
adherence in schizophrenia.
E.A. Schegloff. 1992. Repair after next turn: The last
structurally provided defense of intersubjectivity in
conversation. American Journal of Sociology, pages
1295?1345.
S. Steine, A. Finset, and E. Laerum. 2001. A new,
brief questionnaire (PEQ) developed in primary health
care for measuring patients? experience of interaction,
emotion and consultation outcome. Family practice,
18(4):410?418.
M. Themistocleous, R. McCabe, N. Rees, I. Hassan,
P. G. T. Healey, and S. Priebe. 2009. Establishing mu-
tual understanding in interaction: An analysis of con-
versational repair in psychiatric consultations. Com-
munication & Medicine, 6(2):165?176.
D.R. Traum and J.F. Allen. 1992. A speech acts ap-
proach to grounding in conversation. In Second Inter-
national Conference on Spoken Language Processing.
83
