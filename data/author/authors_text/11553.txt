Proceedings of the EACL 2009 Workshop on Language Technologies for African Languages ? AfLaT 2009, pages 1?8,
Athens, Greece, 31 March 2009. c?2009 Association for Computational Linguistics
Collecting and evaluating speech recognition corpora
for nine Southern Bantu languages
Jaco Badenhorst, Charl van Heerden, Marelie Davel and Etienne Barnard
HLT Research Group, Meraka Institute, CSIR, South Africa
jbadenhorst@csir.co.za, mdavel@csir.co.za
cvheerden@csir.co.za, ebarnard@csir.co.za
Abstract
We describe the Lwazi corpus for auto-
matic speech recognition (ASR), a new
telephone speech corpus which includes
data from nine Southern Bantu lan-
guages. Because of practical constraints,
the amount of speech per language is
relatively small compared to major cor-
pora in world languages, and we report
on our investigation of the stability of
the ASR models derived from the corpus.
We also report on phoneme distance mea-
sures across languages, and describe initial
phone recognisers that were developed us-
ing this data.
1 Introduction
There is a widespread belief that spoken dialog
systems (SDSs) will have a significant impact in
the developing countries of Africa (Tucker and
Shalonova, 2004), where the availability of alter-
native information sources is often low. Tradi-
tional computer infrastructure is scarce in Africa,
but telephone networks (especially cellular net-
works) are spreading rapidly. In addition, speech-
based access to information may empower illiter-
ate or semi-literate people, 98% of whom live in
the developing world.
Spoken dialog systems can play a useful role
in a wide range of applications. Of particular im-
portance in Africa are applications such as ed-
ucation, using speech-enabled learning software
or kiosks and information dissemination through
media such as telephone-based information sys-
tems. Significant benefits can be envisioned if
information is provided in domains such as agri-
culture (Nasfors, 2007), health care (Sherwani et
al., ; Sharma et al, 2009) and government ser-
vices (Barnard et al, 2003). In order to make
SDSs a reality in Africa, technology components
such as text-to-speech (TTS) systems and auto-
matic speech recognition (ASR) systems are re-
quired. The latter category of technologies is the
focus of the current contribution.
Speech recognition systems exist for only a
handful of African languages (Roux et al, ; Seid
and Gambck, 2005; Abdillahi et al, 2006), and
to our knowledge no service available to the gen-
eral public currently uses ASR in an indigenous
African language. A significant reason for this
state of affairs is the lack of sufficient linguistic
resources in the African languages. Most impor-
tantly, modern speech recognition systems use sta-
tistical models which are trained on corpora of
relevant speech (i.e. appropriate for the recogni-
tion task in terms of the language used, the pro-
file of the speakers, speaking style, etc.) This
speech generally needs to be curated and tran-
scribed prior to the development of ASR systems,
and for most applications speech from a large
number of speakers is required in order to achieve
acceptable system performance. On the African
continent, where infrastructure such as computer
networks is less developed than in countries such
as America, Japan and the European countries, the
development of such speech corpora is a signifi-
cant hurdle to the development of ASR systems.
The complexity of speech corpus development
is strongly correlated with the amount of data that
is required, since the number of speakers that need
to be canvassed and the amount of speech that
must be curated and transcribed are major fac-
tors in determining the feasibility of such devel-
opment. In order to minimise this complexity, it
is important to have tools and guidelines that can
be used to assist in designing the smallest cor-
pora that will be sufficient for typical applications
of ASR systems. As minimal corpora can be ex-
tended by sharing data across languages, tools are
also required to indicate when data sharing will be
beneficial and when detrimental.
1
In this paper we describe and evaluate a new
speech corpus of South African languages cur-
rently under development (the Lwazi corpus) and
evaluate the extent in which computational anal-
ysis tools can provide further guidelines for ASR
corpus design in resource-scarce languages.
2 Project Lwazi
The goal of Project Lwazi is to provide South
African citizens with information and informa-
tion services in their home language, over the
telephone, in an efficient and affordable manner.
Commissioned by the South African Department
of Arts and Culture, the activities of this three year
project (2006-2009) include the development of
core language technology resources and compo-
nents for all the official languages of South Africa,
where, for the majority of these, no prior language
technology components were available.
The core linguistic resources being developed
include phoneme sets, electronic pronunciation
dictionaries and the speech and text corpora re-
quired to develop automated speech recognition
(ASR) and text-to-speech (TTS) systems for all
eleven official languages of South Africa. The
usability of these resources will be demonstrated
during a national pilot planned for the third quar-
ter of 2009. All outputs from the project are be-
ing released as open source software and open
content(Meraka-Institute, 2009).
Resources are being developed for all nine
Southern Bantu languages that are recognised as
official languages in South Africa (SA). These lan-
guages are: (1) isiZulu (zul1) and isiXhosa (xho),
the two Nguni languages most widely spoken in
SA. Together these form the home language of
41% of the SA population. (2) The three Sotho
languages: Sepedi (nso), Setswana (tsn), Sesotho
(sot), together the home language of 26% of the
SA population. (3) The two Nguni languages less
widely spoken in SA: siSwati (ssw) and isiNde-
bele (nbl), together the home language of 4% of
the SA population. (4) Xitsonga (tso) and Tshiv-
enda (ven), the home languages of 4% and 2% of
the SA population, respectively (Lehohla, 2003).
(The other two official languages of South Africa
are Germanic languages, namely English (eng)
and Afrikaans (afr).)
For all these languages, new pronunciation dic-
1After each language name, the ISO 639-3:2007 language
code is provided in brackets.
tionaries, text and speech corpora are being de-
veloped. ASR speech corpora consist of ap-
proximately 200 speakers per language, produc-
ing read and elicited speech, recorded over a tele-
phone channel. Each speaker produced approxi-
mately 30 utterances, 16 of these were randomly
selected from a phonetically balanced corpus and
the remainder consist of short words and phrases:
answers to open questions, answers to yes/no
questions, spelt words, dates and numbers. The
speaker population was selected to provide a bal-
anced profile with regard to age, gender and type
of telephone (cellphone or landline).
3 Related work
Below, we review earlier work relevant to the de-
velopment of speech recognisers for languages
with limited resources. This includes both ASR
system design (Sec. 3.1) and ASR corpus design
(Sec. 3.2). In Sec. 3.3, we also review the ana-
lytical tools that we utilise in order to investigate
corpus design systematically.
3.1 ASR for resource-scarce languages
The main linguistic resources required when de-
veloping ASR systems for telephone based sys-
tems are electronic pronunciation dictionaries, an-
notated audio corpora (used to construct acous-
tic models) and recognition grammars. An ASR
audio corpus consists of recordings from multi-
ple speakers, with each utterance carefully tran-
scribed orthographically and markers used to indi-
cate non-speech and other events important from
an ASR perspective. Both the collection of ap-
propriate speech from multiple speakers and the
accurate annotation of this speech are resource-
intensive processes, and therefore corpora for
resource-scarce languages tend to be very small
(1 to 10 hours of audio) when compared to the
speech corpora used to build commercial systems
for world languages (hundreds to thousands of
hours per language).
Different approaches have been used to best
utilise limited audio resources when developing
ASR systems. Bootstrapping has been shown to
be a very efficient technique for the rapid devel-
opment of pronunciation dictionaries, even when
utilising linguistic assistants with limited phonetic
training (Davel and Barnard, 2004).
Small audio corpora can be used efficiently by
utilising techniques that share data across lan-
2
guages, either by developing multilingual ASR
systems (a single system that simultaneously
recognises different languages), or by using addi-
tional source data to supplement the training data
that exists in the target language. Various data
sharing techniques for language-dependant acous-
tic modelling have been studied, including cross-
language transfer, data pooling, language adap-
tation and bootstrapping (Wheatley et al, 1994;
Schultz and Waibel, 2001; Byrne et al, 2000).
Both (Wheatley et al, 1994) and (Schultz and
Waibel, 2001) found that useful gains could be
obtained by sharing data across languages with
the size of the benefit dependent on the similar-
ity of the sound systems of the languages com-
bined. In the only cross-lingual adaptation study
using African languages (Niesler, 2007), similar
gains have not yet been observed.
3.2 ASR corpus design
Corpus design techniques for ASR are generally
aimed at specifying or selecting the most appro-
priate subset of data from a larger domain in order
to optimise recognition accuracy, often while ex-
plicitly minimising the size of the selected corpus.
This is achieved through various techniques that
aim to include as much variability in the data as
possible, while simultaneously ensuring that the
corpus matches the intended operating environ-
ment as accurately as possible.
Three directions are primarily employed: (1)
explicit specification of phonotactic, speaker and
channel variability during corpus development, (2)
automated selection of informative subsets of data
from larger corpora, with the smaller subset yield-
ing comparable results, and (3) the use of active
learning to optimise existing speech recognition
systems. All three techniques provide a perspec-
tive on the sources of variation inherent in a speech
corpus, and the effect of this variation on speech
recognition accuracy.
In (Nagroski et al, 2003), Principle Component
Analysis (PCA) is used to cluster data acousti-
cally. These clusters then serve as a starting point
for selecting the optimal utterances from a train-
ing database. As a consequence of the clustering
technique, it is possible to characterise some of the
acoustic properties of the data being analysed, and
to obtain an understanding of the major sources of
variation, such as different speakers and genders
(Riccardi and Hakkani-Tur, 2003).
Active and unsupervised learning methods can
be combined to circumvent the need for tran-
scribing massive amounts of data (Riccardi and
Hakkani-Tur, 2003). The most informative untran-
scribed data is selected for a human to label, based
on acoustic evidence of a partially and iteratively
trained ASR system. From such work, it soon be-
comes evident that the optimisation of the amount
of variation inherent to training data is needed,
since randomly selected additional data does not
necessarily improve recognition accuracy. By fo-
cusing on the selection (based on existing tran-
scriptions) of a uniform distribution across differ-
ent speech units such as words and phonemes, im-
provements are obtained (Wu et al, 2007).
In our focus on resource-scarce languages, the
main aim is to understand the amount of data that
needs to be collected in order to achieve accept-
able accuracy. This is achieved through the use
of analytic measures of data variability, which we
describe next.
3.3 Evaluating phoneme stability
In (Badenhorst and Davel, 2008) a technique is
developed that estimates how stable a specific
phoneme is, given a specific set of training data.
This statistical measure provides an indication of
the effect that additional training data will have on
recognition accuracy: the higher the stability, the
less the benefit of additional speech data.
The model stability measure utilises the Bhat-
tacharyya bound (Fukunaga, 1990), a widely-used
upper bound of the Bayes error. If Pi and pi(X)
denote the prior probability and class-conditional
density function for class i, respectively, the Bhat-
tacharyya bound ? is calculated as:
? =
?
P1P2
? ?
p1(X)p2(X)dX (1)
When both density functions are Gaussian with
mean ?i and covariance matrix ?i, integration of
? leads to a closed-form expression for ?:
? =
?
P1P2e??(1/2) (2)
where
?(1/2) = 18(?2 ? ?1)
T
[?1 +?2
2
]?1(?2 ? ?1)
+ 12 ln
|?1+?22 |?|?1||?2|
(3)
is referred to as the Bhattacharyya distance.
3
In order to estimate the stability of an acous-
tic model, the training data for that model is sep-
arated into a number of disjoint subsets. All sub-
sets are selected to be mutually exclusive with re-
spect to the speakers they contain. For each sub-
set, a separate acoustic model is trained, and the
Bhattacharyya bound between each pair of mod-
els calculated. By calculating both the mean of
this bound and the standard deviation of this mea-
sure across the various model pairs, a statistically
sound measure of model estimation stability is ob-
tained.
4 Computational analysis of the Lwazi
corpus
We now report on our analysis of the Lwazi
speech corpus, using the stability measure de-
scribed above. Here, we focus on four languages
(isiNdebele, siSwati, isiZulu and Tshivenda) for
reasons of space; later, we shall see that the other
languages behave quite similarly.
4.1 Experimental design
For each phoneme in each of our target lan-
guages, we extract all the phoneme occurrences
from the 150 speakers with the most utterances per
phoneme. We utilise the technique described in
Sec. 3.3 to estimate the Bhattacharyya bound both
when evaluating phoneme variability and model
distance. In both cases we separate the data for
each phoneme into 5 disjoint subsets. We calcu-
late the mean of the 10 distances obtained between
the various intra-phoneme model pairs when mea-
suring phoneme stability, and the mean of the
25 distances obtained between the various inter-
phoneme model pairs when measuring phoneme
distance.
In order to be able to control the number of
phoneme observations used to train our acoustic
models, we first train a speech recognition system
and then use forced alignment to label all of the
utterances using the systems described in Sec. 5.
Mel-frequency cepstral coefficients (MFCCs) with
cepstral mean and variance normalisation are used
as features, as described in Sec. 5.
4.2 Analysis of phoneme variability
In an earlier analysis of phoneme variability of
an English corpus (Badenhorst and Davel, 2008),
it was observed that similar trends are observed
when utilising different numbers of mixtures in
a Gaussian mixture model. For both context de-
pendent and context independent models similar
trends are also observed. (Asymptotes occur later,
but trends remain similar.) Because of the limited
size of the Lwazi corpus, we therefore only report
on single-mixture context-independent models in
the current section.
As we also observe similar trends for phonemes
within the same broad categories, we report on
one or two examples from several broad categories
which occur in most of our target languages. Us-
ing SAMPA notation, the following phonemes are
selected: /a/ (vowels), /m/ (nasals), /b/ and /g/
(voiced plosives) and /s/ (unvoiced fricatives), af-
ter verifying that these phonemes are indeed rep-
resentative of the larger groups.
Figures 1 and 2 demonstrate the effects of vari-
able numbers of phonemes and speakers, respec-
tively, on the value of the mean Bhattacharyya
bound. This value should approach 0.5 for a model
fully trained on a sufficiently representative set of
data. In Fig. 1 we see that the various broad cate-
gories of sounds approach the asymptotic bound in
different ways. The vowels and nasals require the
largest number of phoneme occurrences to reach
a given level, whereas the fricatives and plosives
converge quite rapidly (With 10 observations per
speaker, both the fricatives and plosives achieve
values of 0.48 or better for all languages, in con-
trast to the vowels and nasals which require 30 ob-
servations to reach similar stability). Note that we
employed 30 speakers per phoneme group, since
that is the largest number achievable with our pro-
tocol.
For the results in Fig. 2, we keep the number
of phoneme occurrences per speaker fixed at 20
(this ensures that we have sufficient data for all
phonemes, and corresponds with reasonable con-
vergence in Fig. 1). It is clear that additional
speakers would still improve the modelling ac-
curacy for especially the vowels and nasals. We
observe that the voiced plosives and fricatives
quickly achieve high values for the bound (close
to the ideal 0.5).
Figures 1 and 2 ? as well as similar figures for
the other phoneme classes and languages we have
studied ? suggest that all phoneme categories re-
quire at least 20 training speakers to achieve rea-
sonable levels of convergence (bound levels of
0.48 or better). The number of phoneme observa-
tions required per speaker is more variable, rang-
4
Figure 1: Effect of number of phoneme utterances per speaker on mean of Bhattacharyya bound for
different phoneme groups using data from 30 speakers
ing from less than 10 for the voiceless fricatives
to 30 or more for vowels, liquids and nasals. We
return to these observations below.
4.3 Distances between languages
In Sec. 3.1 it was pointed out that the simi-
larities between the same phonemes in different
languages are important predictors of the bene-
fit achievable from pooling the data from those
languages. Armed with the knowledge that sta-
ble models can be estimated with 30 speakers per
phoneme and between 10 and 30 phonemes oc-
currences per speaker, we now turn to the task of
measuring distances between phonemes in various
languages.
We again use the mean Bhattacharyya bound
to compare phonemes, and obtain values between
all possible combinations of phonemes. Results
are shown for the isiNdebele phonemes /n/ and /a/
in Fig. 3. As expected, similar phonemes from
the different languages are closer to one another
than different phonemes of the same language.
However, the details of the distances are quite re-
vealing: for /a/, siSwati is closest to the isiN-
debele model, as would be expected given their
close linguistic relationship, but for /n/, the Tshiv-
enda model is found to be closer than either of
the other Nguni languages. For comparative pur-
poses, we have included one non-Bantu language
(Afrikaans), and we see that its models are indeed
significantly more dissimilar from the isiNdebele
model than any of the Bantu languages. In fact,
the Afrikaans /n/ is about as distant from isiNde-
bele /n/ as isiNdebele and isiZulu /l/ are!
5 Initial ASR results
In order to verify the usability of the Lwazi cor-
pus for speech recognition, we develop initial
ASR systems for all 11 official South African
languages. A summary of the data statistics for
the Bantu languages investigated is shown in Tab.
1, and recognition accuracies achieved are sum-
marised in Tab. 2. For these tests, data from 30
speakers per language were used as test data, with
the remaining data being used for training.
Although the Southern Bantu languages are
tone languages, our systems do not encode tonal
5
Figure 2: Effect of number of speakers on mean of Bhattacharyya bound for different phoneme groups
using 20 utterances per speaker
Language total # # speech # distinct
minutes minutes phonemes
isiNdebele 564 465 46
isiXhosa 470 370 52
isiZulu 525 407 46
Tshivenda 354 286 38
Sepedi 394 301 45
Sesotho 387 313 44
Setswana 379 295 34
siSwati 603 479 39
Xitsonga 378 316 54
N-TIMIT 315 - 39
Table 1: A summary of the Lwazi ASR corpus:
Bantu languages.
information, since tone is unlikely to be impor-
tant for small-to-medium vocabulary applications
(Zerbian and Barnard, 2008).
As the initial pronunciation dictionaries were
developed to provide good coverage of the lan-
guage in general, these dictionaries did not cover
the entire ASR corpus. Grapheme-to-phoneme
rules are therefore extracted from the general
dictionaries using the Default&Refine algorithm
(Davel and Barnard, 2008) and used to generate
missing pronunciations.
We use HTK 3.4 to build a context-dependent
cross-word HMM-based phoneme recogniser with
triphone models. Each model had 3 emitting
states with 7 mixtures per state. 39 features are
used: 13 MFCCs together with their first and sec-
ond order derivatives. Cepstral Mean Normali-
sation (CMN) as well as Cepstral Variance Nor-
malisation (CMV) are used to perform speaker-
independent normalisation. A diagonal covariance
matrix is used; to partially compensate for this in-
correct assumption of feature independence semi-
tied transforms are applied. A flat phone-based
language model is employed throughout.
As a rough benchmark of acceptable phoneme-
recognition accuracy, recently reported results ob-
tained by (Morales et al, 2008) on a similar-sized
telephone corpus in American English (N-TIMIT)
are also shown in Tab. 2. We see that the Lwazi
results compare very well with this benchmark.
An important issue in ASR corpus design is
6
Figure 3: Effective distances in terms of the mean of the Bhattacharyya bound between a single phoneme
(/n/-nbl top and /a/-nbl bottom) and each of its closest matches within the set of phonemes investigated.
Language % corr % acc avg # total #
phons speakers
isiNdebele 74.21 65.41 28.66 200
isiXhosa 69.25 57.24 17.79 210
isiZulu 71.18 60.95 23.42 201
Tshivenda 76.37 66.78 19.53 201
Sepedi 66.44 55.19 16.45 199
Sesotho 68.17 54.79 18.57 200
Setswana 69.00 56.19 20.85 207
siSwati 74.19 64.46 30.66 208
Xitsonga 70.32 59.41 14.35 199
N-TIMIT 64.07 55.73 - -
Table 2: Initial results for South African ASR sys-
tems. The column labelled ?avg # phonemes? lists
the average number of phoneme occurrences for
each phoneme for each speaker.
the trade-off between the number of speakers and
the amount of data per speaker (Wheatley et al,
1994). The figures in Sec. 4.2 are not conclusive
on this trade-off, so we have also investigated the
effect of reducing either the number of speakers
or the amount of data per speaker when training
the isiZulu and Tshivenda recognisers. As shown
in Fig. 4, the impact of both forms of reduction
is comparable across languages and different de-
grees of reduction, in agreement with the results
of Sec. 4.2.
These results indicate that we now have a firm
Figure 4: The influence of a reduction in training
corpus size on phone recognition accuracy.
baseline to investigate data-efficient training meth-
ods such as those described in Sec. 3.1.
6 Conclusion
In this paper we have introduced a new tele-
phone speech corpus which contains data from
nine Southern Bantu languages. Our stability anal-
ysis shows that the speaker variety as well as
the amount of speech per speaker is sufficient to
achieve acceptable model stability, and this con-
clusion is confirmed by the successful training of
phone recognisers in all the languages. We con-
firm the observation in (Badenhorst and Davel,
2008) that different phone classes have different
7
data requirements, but even for the more demand-
ing classes (vowels, nasals, liquids) our amount of
data seems sufficient. Our results suggest that sim-
ilar accuracies may be achievable by using more
speech from fewer speakers ? a finding that may
be useful for the further development of speech
corpora in resource-scarce languages.
Based on the proven stability of our models, we
have performed some preliminary measurements
of the distances between the phones in the dif-
ferent languages; such distance measurements are
likely to be important for the sharing of data across
languages in order to further improve ASR accu-
racy. The development of real-world applications
using this data is currently an active topic of re-
search; for that purpose, we are continuing to in-
vestigate additional methods to improve recogni-
tion accuracy with such relatively small corpora,
including cross-language data sharing and effi-
cient adaptation methods.
References
Nimaan Abdillahi, Pascal Nocera, and Jean-Franois
Bonastre. 2006. Automatic transcription of Somali
language. In Interspeech, pages 289?292, Pitts-
burgh, PA.
J.A.C. Badenhorst and M.H. Davel. 2008. Data re-
quirements for speaker independent acoustic mod-
els. In PRASA, pages 147?152.
E. Barnard, L. Cloete, and H. Patel. 2003. Language
and technology literacy barriers to accessing govern-
ment services. Lecture Notes in Computer Science,
2739:37?42.
W. Byrne, P. Beyerlein, J. M. Huerta, S. Khudanpur,
B. Marthi, J. Morgan, N. Peterek, J. Picone, D. Ver-
gyri1, and W. Wang. 2000. Towards language inde-
pendent acoustic modeling. In ICASSP, volume 2,
pages 1029?1032, Istanbul, Turkey.
M. Davel and E. Barnard. 2004. The efficient cre-
ation of pronunication dictionaries: human factors
in bootstrapping. In Interspeech, pages 2797?2800,
Jeju, Korea, Oct.
M. Davel and E. Barnard. 2008. Pronunciation predi-
cation with Default&Refine. Computer Speech and
Language, 22:374?393, Oct.
K. Fukunaga. 1990. Introduction to Statistical Pattern
Recognition. Academic Press, Inc., 2nd edition.
Pali Lehohla. 2003. Census 2001: Census in brief.
Statistics South Africa.
Meraka-Institute. 2009. Lwazi ASR corpus. Online:
http://www.meraka.org.za/lwazi.
N. Morales, J. Tejedor, J. Garrido, J. Colas, and D.T.
Toledano. 2008. STC-TIMIT: Generation of a
single-channel telephone corpus. In LREC, pages
391?395, Marrakech, Morocco.
A. Nagroski, L. Boves, and H. Steeneken. 2003. In
search of optimal data selection for training of auto-
matic speech recognition systems. ASRU workshop,
pages 67?72, Nov.
P. Nasfors. 2007. Efficient voice information services
for developing countries. Master?s thesis, Depart-
ment of Information Technology, Uppsala Univer-
sity.
T. Niesler. 2007. Language-dependent state clustering
for multilingual acoustic modeling. Speech Commu-
nication, 49:453?463.
G. Riccardi and D. Hakkani-Tur. 2003. Active and
unsupervised learning for automatic speech recog-
nition. In Eurospeech, pages 1825?1828, Geneva,
Switzerland.
J.C. Roux, E.C. Botha, and J.A. du Preez. Develop-
ing a multilingual telephone based information sys-
tem in african languages. In LREC, pages 975?980,
Athens, Greece.
T. Schultz and A. Waibel. 2001. Language-
independent and language-adaptive acoustic model-
ing for speech recognition. Speech Communication,
35:31?51, Aug.
Hussien Seid and Bjrn Gambck. 2005. A speaker inde-
pendent continuous speech recognizer for Amharic.
In Interspeech, pages 3349?3352, Lisboa, Portugal,
Oct.
A. Sharma, M. Plauche, C. Kuun, and E. Barnard.
2009. HIV health information access using spoken
dialogue systems: Touchtone vs. speech. Accepted
at IEEE Int. Conf. on ICTD.
J. Sherwani, N. Ali, S. Mirza, A. Fatma, Y. Memon,
M. Karim, R. Tongia, and R. Rosenfeld. Healthline:
Speech-based access to health information by low-
literate users. In IEEE Int. Conf. on ICTD, pages
131?139.
R. Tucker and K. Shalonova. 2004. The Local Lan-
guage Speech Technology Initiative. In SCALLA
Conf., Nepal.
B. Wheatley, K. Kondo, W. Anderson, and
Y. Muthusumy. 1994. An evaluation of cross-
language adaptation for rapid HMM development
in a new language. In ICASSP, pages 237?240,
Adelaide.
Y. Wu, R. Zhang, and A. Rudnicky. 2007. Data selec-
tion for speech recognition. ASRU workshop, pages
562?565, Dec.
S. Zerbian and E. Barnard. 2008. Phonetics of into-
nation in South African Bantu languages. Southern
African Linguistics and Applied Language Studies,
26(2):235?254.
8
Proceedings of the NAACL HLT Workshop on Extracting and Using Constructions in Computational Linguistics, pages 39?46,
Los Angeles, California, June 2010. c?2010 Association for Computational Linguistics
Learning Rules and Categorization Networks for Language  
Standardization 


Gerhard B van Huyssteen Marelie H Davel 
Human Language Technology Group Human Language Technology Group 
Council for Scientific and Industrial Research Council for Scientific and Industrial Research 
Pretoria, South Africa Pretoria, South Africa 
gvhuyssteen@csir.co.za  mdavel@csir.co.za 
 
 
 
 
 
 
Abstract 
In this research, we use machine learning 
techniques to provide solutions for descriptive 
linguists in the domain of language standardi-
zation. With regard to the personal name con-
struction in Afrikaans, we perform function 
learning from word pairs using the De-
fault&Refine algorithm. We demonstrate how 
the extracted rules can be used to identify ir-
regularities in previously standardized con-
structions and to predict new forms of unseen 
words. In addition, we define a generic, auto-
mated process that allows us to extract con-
structional schemas and present these visually 
as categorization networks, similar to what is 
often being used in Cognitive Grammar. We 
conclude that computational modeling of con-
structions can contribute to new descriptive 
linguistic insights, and to practical language 
solutions. 
1 Introduction 
In the main, constructionist approaches to grammar 
focus on discovering generalizations in language 
by analyzing clusters of usage-based instances of 
linguistic phenomena. Similarly, computational 
linguistic approaches to grammar learning aim to 
discover these very same patterns, using automated 
techniques such as machine learning (ML).  
In this research, we use techniques from ML to 
analyze and predict irregular phenomena with li-
mited data available, and then represent these phe-
nomena visually in a way that is compatible with 
the Cognitive Grammar descriptive framework (as 
a constructionist approach to grammar; henceforth 
CG). Our grand goal is to develop language tech-
nology tools that could be used in descriptive lin-
guistics. Specifically, we aim to (1) develop a 
predictor that could suggest derivational forms for 
novel base-forms; and (2) automatically extract 
categorization networks (i.e. constructional sche-
mas and the relationships between them) from a 
dataset, which could serve as a heuristic input to 
descriptive linguistics. 
2 Contextualization  
This research originates from a practical problem 
related to language standardization. Similar to 
standardization bodies for languages like Dutch, 
and German, the ?Afrikaanse Taalkommisie? (TK) 
is the official body responsible for the description 
and regulation of Afrikaans spelling. The TK regu-
larly publishes the official orthography of Afri-
kaans in the form of the Afrikaanse Woordelys en 
Spelre?ls (?Afrikaans Wordlist and Spelling 
Rules?; AWS (Taalkommissie, 2009)).  
One of the challenges faced by the TK is to 
standardize the spelling of foreign place names 
(including names of countries, cities, regions, 
provinces, etc.), and their derived forms (i.e. adjec-
tives, such as Amerika?ans ?American?; and per-
sonal names, such as Amerika?ner ?person from 
America?). In the absence of sufficient usage-based 
39
evidence, many variant forms are often being ac-
cepted, either related to spelling or derivation; 
compare for instance the variant spelling forms 
Maskat or Masqat or Muskat ?Muscat?, or the va-
riant derivational forms Turkmenistan?i or Turkme-
nistan?ner ?person from Turkmenistan?. The TK is 
therefore challenged with the task to give guide-
lines regarding spelling and derivation, while faced 
with highly irregular and sparse data containing 
many variants.  
We contribute to address this challenge by dis-
covering the constructions in seemingly unsyste-
matic and irregular data. Based on our tools and 
outputs, the TK could then revise existing irregu-
larities and variants, or use these tools to guide 
future decisions.  
3 Related Work 
3.1 Constructional Schemas 
Morphological constructions can be defined as 
composite symbolic assemblies (i.e. complex 
form-meaning pairings) smaller than phrases, con-
sisting of component structures between which 
valence relations hold (Van Huyssteen, 2010; see 
also Tuggy, 2005). One of the main component 
structures in morphological constructions is the 
morpheme, which is simply defined as a simplex 
symbolic unit in the language system (i.e. it does 
not contain smaller symbolic units as subparts). 
More schematic symbolic assemblies (i.e. less spe-
cified in their characterization) are referred to as 
constructional schemas.  
Constructional schemas can be represented as a 
network with relationships of categorization hold-
ing between different constructional schemas; 
these categorization networks provide the structur-
al description of a construction (Langacker, 2008: 
222). In the representations used in CG, categori-
zation relationships of elaboration (i.e. full instan-
tiations of a schema), extension (i.e. partial 
instantiations), and correspondence are specified. 
Entrenchment and ease of activation is indicated 
by the thickness of boxes: the thicker the line of a 
box, the more prototypical that unit is (Langacker, 
2008: 226; see also Figure 5).  
 The aim of descriptive linguistics is to postulate 
categorization networks that describe a construc-
tion in a language, based on usage data. Our re-
search contributes to this aim by automatically 
creating visual representations of such language 
models. For our current research, we are specifical-
ly interested in the personal name construction in 
Afrikaans. 
3.2 Afrikaans Personal Name Construction 
Formation of personal names by means of a per-
sonal name creating derivational suffix (NRPERS) is 
a productive process in many languages. The spe-
cific category that we are investigating in this re-
search is personal names derived from place 
names, such as Trinidad?ees ?person from Trini-
dad?.  
In one of the standard works on derivation in 
Afrikaans, Kempen (1969) identifies a number of 
NRPERS suffixes that are used in derivations from 
place names. He finds that there is no obvious sys-
tematicity in their distribution (based on a dataset 
of 132 instances), but concludes that, in derivations 
of foreign place names, the -ees and -s morphemes 
are most frequently used, with some distribution 
also over -i, -n (especially -aan) and -r. In addition 
to some of the morphemes mentioned by Kempen 
(1969), Combrink (1990) also mentions a few, 
while excluding others. In as far as we know, no 
other description of this construction in Afrikaans 
has been done, and based on the difference be-
tween Combrink (1990) and Kempen (1969), we 
can also deduct that there is no comprehensive un-
derstanding of this construction.  
Personal names from place names can be formed 
in four basic ways in Afrikaans: (1) suffixation 
(Aruba?an ?Arubian?); (2) zero derivation (Aber-
deen ?person from Aberdeen?); (3) clipping and 
back-formation (Turk<Turkye ?person from Tur-
key?; Armeen<Armeni? ?person from Armenia?); 
and (4) lexicalization (Cornwallis>Korni?r ?person 
from Cornwallis?). In a rather large number of cas-
es (119 in our dataset of 1,034; see 5.1) none of the 
above strategies can be applied, and then paraph-
rasing is being used (e.g. ? persoon van Akkra ?a 
person from Accra?).  
Variants of morphemes (i.e. allomorphs) exist 
for phonological reasons, of which a linking ele-
ment is the most prominent (Combrink, 1990). 
Compare for example -aar in Brussel?aar ?person 
from Brussels? (where the base-form is polysyllab-
ic) vs. -enaar in Delft?enaar ?person from Delft? 
(where the base-form is monosyllabic; Delftenaar 
could therefore also be analyzed as Delft?en?aar). 
40
For our purposes, we consider -enaar as an allo-
morph (i.e. elaboration) of ?aar, and is identified 
as such in our categorization network (see Figure 
5). Similarly, we classify morphemes as allo-
morphs in cases where an allomorph exists due to 
identical vowel deletion (e.g. -an as a variant of -
aan when it combines with a base-form ending on 
an -a, as in Afrika?an ?person from Africa?), as well 
as consonant doubling after a short, stressed sylla-
ble in the auslaut (e.g. -mer as a variant of -er, as 
in Amsterdam?mer ?person from Amsterdam?).  
3.3 Automatic Extraction of Constructional 
Schemas 
Computational modeling of morphology is a vast 
subfield in computational linguistics, gaining 
popularity since the 1980s. Pioneering work in the 
field has been done within the two-level morphol-
ogy framework, and elaborations on this frame-
work can be considered the basis of state-of-the-art 
morphological analyzers today. However, since 
constructing such analyzers manually is hugely 
expensive in terms of time and human effort, the 
approach does not scale well for new languages.  
To overcome this obstacle, many computational 
linguists have developed techniques towards the 
automatic learning of morphology (e.g. Goldsmith, 
2001). A key goal is to be able to produce a mor-
phological analysis of the words of a corpus when 
only provided with the unannotated corpus.   
We are interested in the related goal of function 
learning: given a base-form of a word, learn other 
forms of the word. Most typically, function learn-
ing takes pairs of words (base-forms plus in-
flected/derived forms) as input to discover patterns 
in the data. This is also the paradigm used in the 
current paper. 
Several ML techniques have been used to solve 
specific function learning tasks (such as learning 
the past tense form of the English verb). Ap-
proaches include the use of decision trees, neural 
networks, inductive logic programming, and statis-
tical approaches (Shalonova & Flach, 2007). 
We are not aware of any work related to the au-
tomated learning of categorization networks spe-
cifically. 
4 Approach 
Our research has two complementary goals, dealt 
with separately: (1) to develop a predictor that can 
suggest potential derivational forms for novel base-
forms (and alternative forms for existing base-
forms with irregular forms); and (2) to automati-
cally extract categorization networks that are easily 
interpretable by linguists.  
4.1 Prediction of Derivational Forms 
In order to analyze existing and predict new deri-
vational forms, we use the Default&Refine (D&R) 
algorithm (Davel & Barnard, 2004). This algorithm 
extracts context-sensitive rules from discrete data, 
and is particularly effective when learning from 
small training sets. It has the additional advantage 
that rules generated are interpretable by humans. 
When applied to the grapheme-to-phoneme predic-
tion task, it has been shown to outperform compar-
ative algorithms (Davel & Barnard, 2008). 
The D&R algorithm defines a set of templates 
and then uses a greedy search to find the most gen-
eral rule (matching the templates) that describes 
the training data in question. Examples that are 
successfully explained by this rule are removed 
from the data set and the process repeated. When-
ever a new rule contradicts examples previously 
dealt with successfully, these are again added to 
the training data to be ?re-explained? by a later 
rule. The rule set therefore captures hierarchical 
default behavior: the last rule defines the default 
behavior for a specific pattern, and acts as a back-
off rule to the second-last (more refined) rule, 
which would capture deviations from default beha-
vior. The second-last rule would then act as back-
off to the third-last rule, and so forth. Rules are 
therefore explicitly ordered according to the re-
verse rule extraction order. (The rule extracted first 
is matched last.)  
Once a set of rules have been generated, these 
describe the training data completely. In addition, 
by tracing each of the possible rules that may apply 
to a new pattern (in order), various alternative de-
rivational forms are identified, along with the evi-
dence supporting each option (as in Table 2). 
4.2 Extraction of Categorization Networks 
While the D&R rules extracted in Section Error! 
Reference source not found. provide a perspec-
tive on the phenomena that occur, these rule sets 
could become extremely large and, accordingly, 
more difficult to interpret. We therefore attempt to 
extract categorization networks (a la CG) as visual 
41
representations in a fully automated fashion. These 
networks are more easily interpretable, especially 
to humans.  
An iterative string matching process is used to 
structure ?potential morphemes? within a directed 
tree. Our main assumptions are that: 
? the only input to the process consists of a 
set of unannotated word pairs: base-form + 
derivational form; 
? a morpheme is added as a suffix; 
? allomorphs are either shorter than the main 
morpheme (i.e. characters removed) or 
longer (i.e. characters added); and 
? preference is given to larger strings that 
occur systematically in the training data. 
The following steps are followed: 
1. Generate a list of initial transformation classes  
based on the word pairs provided.  These are 
derived through a comparison based on the 
longest common substring of the derivational 
form and its respective base-form (see Table 
1).  The classes specify the character string to 
be removed from the base-form (if any), and 
the replacement string; note that ellipses indi-
cates the base-form (or part of it), and curly 
brackets indicate deletions (i.e. in China, de-
lete the -a, and then add -ees). If a place name 
and its personal name are identical, the class 
will be ?0?. 
 
Table 1: Examples of transformation classes 
Place 
name  
Personal 
name 
Class (constructional 
schema) 
Aberdeen Aberdeen [[x] [0]] 
Amerika Amerikaner [[?] [ner]] 
China Chinees [[?{a}] [ees]] 
 
2. Create a list of all transformation classes and, 
per transformation class, a set of all deriva-
tional forms (referred to as the transformation 
derivations set). 
3. For each transformation derivations set, find 
the largest end-of-word string common to all 
members of that set (the set best string). The 
set of all ?set best strings? are referred to as the 
best string list and can be interpreted as a set 
of candidate morphemes. 
4. For each transformation derivations set, con-
sider the elements in the best string list, and 
determine if any subsets of the current set exist 
that match a larger string currently in the best 
string list. If so, partition the set into subsets 
accordingly. (Each subset is therefore identi-
fied by both a transformation class and a best 
string. For example, three different sets, each 
with a different best string may be related to a 
single transformation class. This makes it poss-
ible to identify situations where an allomorph 
is created in other ways than simply adding the 
morpheme as a suffix.) 
5. For each subset, update the set best string 
based on the latest partition; update the best 
string list to reflect new best strings created. 
6. Repeat steps (4) and (5) until no further 
changes are made. The set of morphemes are 
considered stable, and it now remains to struc-
ture these elements into a visual categorization 
network. 
7. In order to create the categorization network, 
we start with an empty directed graph. For 
each set best string, create a list of all the trans-
formation classes that are applicable (as calcu-
lated above) and add these transformation 
classes from largest to smallest to a single 
branch of the tree. (One branch is created for 
each string in the best string list, and is a first 
attempt at capturing a morpheme along with its 
different variations.)   
8. Consider the nodes at each level (all nodes that 
have the same node as parent) and wherever 
one node fully contains another, move the con-
tained node to become the parent of the other 
(cutting the link between the original parent 
node and the contained node). This process en-
sures that morpheme candidates that are ac-
tually variations of other morphemes are 
suppressed at each level of the tree.  
9. Now combine any nodes that occur in different 
places in the tree but have identical transfor-
mation classes, by merging the lower node 
with the higher node. Only identical transfor-
mation classes are merged. 
10. For each node in the final tree, consider 
whether the left hand side of the transforma-
tion class can be refined, specifically by add-
ing additional matching characters based on 
the final transformation derivations set. 
The result of this process is a set of final transfor-
mation classes, each describing a constructional 
schema, and the relationships among these con-
structional schemas, displayed as a categorization 
network. 
42
Figure 1: Number of words, rules and initial trans-
formations for the various person-x data sets 
5 Experimental Setup and Results 
5.1 Data 
The dataset that we use is the list of foreign place 
names and their corresponding personal names 
from the AWS (Taalkommissie, 2009). For pur-
poses of brevity, we only report on suffixation and 
back-formation, and exclude cases with variant 
morphemes, zero derivation and clipping, as well 
as all cases of paraphrasing. 732 instances are re-
tained (from the original dataset of 1,034 in-
stances).  
A supplementary dataset consisting of adjectival 
derivations of place names was also taken from the 
AWS and treated in the same manner as the per-
sonal names; this dataset is used in Section 6.3 to 
verify certain of the findings. This set contains 786 
instances. 
5.2 Development of Predictor 
The full dataset is highly irregular, containing 
many transformation classes that occur only once. 
We are interested in these irregularities (in order to 
identify words that may need further review), as 
well as in more systematic phenomena that occur 
in the data. We therefore create different data sets; 
in each set (referred to as person-x) we only retain 
those instances that occur x or more times in the 
transformations. (The person-1 set therefore con-
tains all training data, including all exceptions, 
while the person-6 set only contains transforma-
tions supported by 6 or more instances.) In Figure 
 
 Figure 2: Cross-validated rule accuracy for the per-
son-x and adjective-x data sets. 
 
1 the number of words and number of unique 
transformation classes are displayed for each per-
son-x data set.  
In order to verify the accuracy of our extracted 
rules, we use 10-fold cross-validation to obtain a 
mean accuracy per data set, as depicted in Figure 2 
(labeled ?person?). We also generate a rule set 
from the training and test data combined: this larg-
er set is used to extract categorization networks.  
When the rule set is structured as a graph (called 
a rule network), the data can be interpreted as fol-
lows: the root node indicates the default transfor-
mation, which applies unless any child node is 
matched by the base-form, which again only ap-
plies unless a child of the child node matches the 
base-form (and so forth), which indicates that a 
more refined rule should be applied. A small part 
of a rule network is displayed in Figure 3, with 
each node listing the end-of-word string of the 
base-form that will trigger the rule, the transforma-
tion rule that will be applied, and the number of 
instances of the rule in the training data. The com-
plete rule network is very large: 266 nodes for the 
person-1 data set, as indicated in Figure 1.  
As was expected, a large number of exceptional 
rules are generated, indicating much inconsistency 
in how derivations are formed. For the person-1 
data set, 217 exceptions are identified. For each of 
these exceptions, alternatives are suggested in or-
der of prototypicality by tracing the rule network, 
as illustrated for the base-form Smirna in Table 2. 
Automatically generated tables like these provide a 
practical tool for language standardization. 
43
 
Figure 3: A small subsection of a rule network 
 
 
Table 2: Alternative suggestions for the exception: 
Smirna -> Smirnioot 
Alternative Instances Examples 
Smirna 1 Smirna>Smirnioot 
Smirnees 1 Navarra>Navarrees 
Smirnaan 58 Sparta>Spartaan 
Astana>Astanaan 
Smirnaer 155 Hiroshima>Hiroshimaer 
Breda>Bredaer 
 
5.3 Development of Categorization Networks 
The categorization network in Figure 5 was com-
piled automatically, as described in 4.2. Note that 
this specific categorization network is based on 
construction schemas with three or more support-
ing examples per node; for the sake of brevity, we 
do not include the full categorization network 
(based on all the examples) in this paper. 
The relative prototypicality of constructional 
schemas (indicated by the thickness of lines in 
Figure 5) is determined post hoc by observing dis-
tribution frequencies. We obtain four natural clus-
ters in this way: highly prototypical (hundred or 
more instantiations), prototypical (forty or more 
instantiations), less prototypical (three or more in-
stantiations), and unprototypical (less than three 
instantiations, therefore also including exceptions); 
the latter category is not included in Figure 5.  
Full instantiations of a schema (i.e. relationships 
of elaboration) is indicated with solid arrows; the 
highest node in our network represents the seman-
tic pole, and is here simply indicated as [[PLACE X] 
[NRPERS]]. For each node in the network, we also 
indicate the class frequency, and provide three ex-
amples of the base-form.  
6 Discussion 
6.1 Predictor 
The extracted rules immediately provide us with: 
? An indication of the predictability of the 
data (rule accuracy); 
? A set of all exceptions (single instances 
that require an individual rule to describe 
that instance); and 
? A predictor of new forms (applying the 
rules to unseen words).  
From the accuracies depicted in Figure 2, it is clear 
that the full data set, including all phenomena that 
only occur once, describes a difficult learning task, 
with an overall accuracy of only 63.2% achieved. 
When more systematic phenomena are investigated 
(i.e. transformations with six or more instances), 
our classification accuracy quickly increases above 
80%, indicating that the predictor is in fact usable. 
An error analysis reveals that improvements may 
be possible by taking pronunciation information 
into account (stress patterns, syllable information, 
consonant categories, etc.).  
A standardization body such as the TK could 
use the automatically generated list of exceptions 
(similar to Table 2) to review prior standardization 
decisions.  In addition, the predictor can be used to 
suggest derivational forms for novel base-forms, 
which could then be verified with usage data. 
6.2 Categorization Networks 
From Figure 5, observe that we have identified 
seven basic morphemes (i.e. nodes on the highest 
level), viz. -aan, -aar, -ees, -er, -i, -iet and -?r; 
with the exception of the latter, all these corres-
pond to the morphemes identified by Kempen 
(1969) and Combrink (1990). Linguistically speak-
ing, -?r is actually an extension of the [[?] [er]] 
construction, since the e-trema is used in Afrikaans 
orthography as a variant of the letter ?e? to signify 
a syllable with a null onset, preceded by a syllable 
without a coda. However, our algorithm treated -er 
and -?r as two separate morphemes.  
We can also observe that the [[?] [er]] con-
structional schema can be considered the most pro-
totypical schema (based on frequency). Other 
prototypical constructional schemas include [[?a] 
[an]], [[?] [ner]] and [[?] [?r]] (with the latter 
two actually instantiations of [[?] [er]]). Within a 
44
CG framework, it is assumed that these prototypi-
cal constructional schemas are more likely to be 
activated for the categorization of novel examples. 
This observation contradicts Kempen?s (1969) 
finding that there is no obvious systematicity in the 
distribution of personal name forming suffixes, as 
well as his finding that the -ees and -s morphemes 
are most frequently used. Conversely, we did not 
find in our data significant evidence for the promi-
nence that Kempen (1969) and Combrink (1990) 
give to morphemes/allomorphs such as -der, -lees, 
-naar, -aner, -een, -ein/-yn or -ioot; that does not 
mean that these do not exist ? they are just not as 
prominent as these previous descriptions might 
have made us believe.  
Furthermore, if we look at allomorphs due to 
linking elements, we identified six, viz. -nees,        
-enaar, -iaan, -ner, -ter and -i?r. With the excep-
tion of -nees, all these have also been identified by 
Kempen (1969) and Combrink (1990). If we look 
closely at the instantiations of [[?] [nees]], we see 
that all base-form examples end on the stressed 
syllables [an] or [on], with the exception of Bali 
and Mali. A standardization body could therefore 
investigate whether these two examples could not 
be classified better under the [[?] [?r]] construc-
tional schema, resulting in, for example, Bali??r, as 
we also find in Dutch. If this could be the case, 
then it would make sense why -nees has not been 
identified by other morphologists, since it would 
then be a case of an allomorph due to consonant 
doubling, and not due to a linking element.  
A similar closer look at -ees vs. -nees shows that 
all instantiations of the base-forms of [[?] [nees]] 
end on a stressed syllable, while those for [[?] 
[ees]] are unstressed. In the data, there is only one 
exception to the latter schema, viz.  Gaboen?ees 
?person from Gabon?. Since Gaboen ends on a 
stressed syllable, it would actually fit better under 
the [[?] [nees]] constructional schema. Support 
for this hypothesis comes from Donaldson (1993), 
where he indicates that it should be spelled Ga-
boen?nees. In the absence of usage data, and based 
on this categorization network, the TK could there-
fore reconsider the spelling of Gaboen?ees.   
Several similar observations can be made re-
garding inconsistencies in the data (e.g. inconsis-
tencies regarding base-forms ending on [stan]). In 
this sense, categorization networks like these could 
be a helpful descriptive tool for a standardization 
body in finding systematicity in data and rules. 
6.3 Supplementary Data: Adjectival Deriva-
tions 
In order to validate the generic process, the full 
process (as described in 4.1 and 4.2) is repeated 
using the supplementary data set of adjectival 
forms described in 5.1. Results are positive: a simi-
larly efficient learning curve is obtained (see Fig-
ure 2) and the categorization network, although 
quite different, is similarly interpretable (Figure 4). 
 
Figure 4: Categorization network for the adjective-4 
data set 
7 Conclusion and Future Work 
In this paper, we presented a methodology to au-
tomatically discover constructional schemas from 
highly irregular data, and to represent these in a 
way that is both interpretable by computers (pre-
dictive rule sets) and humans (categorization net-
works). The graphical representation is by and 
large compatible with one of the major Construc-
tion Grammar theories, viz. CG: we show proto-
typical examples (based on frequency), and also 
indicate relationships of elaboration. In future 
work, these representations could be further re-
fined, to also indicate relationships of extensions 
and correspondences. We have illustrated how 
these representations could provide insight in our 
knowledge of the morphology of Afrikaans, as 
well as providing practical language solutions for 
language standardization (such as the predictor and 
the tables with alternative suggestions).  
Other future work will continue in two direc-
tions: (1) refining the current tool for predicting 
derivational forms by taking additional features 
45
into account, incorporating data that was left out in 
our current experiments (such as zero derivations), 
and benchmarking our results with regard to alter-
native approaches; and (2) applying our algorithm 
to describe other morphological constructions.  
Acknowledgments 
Van Huyssteen is jointly affiliated with North-
West University. Support by NWU is hereby ac-
knowledged.  
Part of this research was made possible through 
a research grant by the South African National Re-
search Foundation (FA207041600015).  
We would like to extend our gratitude to Handr? 
Groenewald and Martin Puttkammer for their help. 
References  
Combrink, J.G.H. 1990. Afrikaanse morfologie [Afri-
kaans morphology]. Pretoria: Academica. 
Davel, M. & Barnard, E. 2004. A default-and-
refinement approach to pronunciation prediction. 
Proceedings of the 15th Annual Symposium of the 
Pattern Recognition Association of South Africa. 
Grabouw, November 2004. pp 119-123.  
Davel, M. & Barnard, E. 2008. Pronunciation Prediction 
with Default & Refine. Computer Speech and Lan-
guage. 22: 374-393.  
Donaldson, B.C. 1993. A Grammar of Afrikaans. Berlin: 
Mouton de Gruyter. 
Goldsmith, J. 2001. Unsupervised Learning of the Mor-
phology of a Natural Language. Computational Lin-
guistics 27, pp. 153-198. 
Kempen, W. 1969. Samestelling, afleiding en woord-
soortelike meerfunksionaliteit in Afrikaans [Com-
pounding, derivation and change of part-of-speech 
category in Afrikaans]. Kaapstad: Nasou. 
Langacker, R.W. 2008. Cognitive Grammar: A Basic 
Introduction. Oxford: Oxford University Press. 
Shalonova, K. & Flach, P. 2007. Morphology learning 
using tree of aligned suffix rules. ICML Workshop: 
Challenges and Applications of Grammar Induction. 
Taalkommissie. (comp.). 2009. Afrikaanse Woordelys 
en Spelre?ls [Afrikaans Wordlist and Spelling Rules]. 
Tenth edition. Kaapstad: Pharos Dictionaries. 
Tuggy, D. 2005. Cognitive Approach to Word-
Formation. In: ?tekauer, P. & Lieber, R. (eds.). 
Handbook of Word-Formation. Dordrecht: Springer. 
pp. 233-265. 
Van Huyssteen, GB. 2010. (Re)defining Component 
Structures in Morphological Constructions: A Cogni-
tive Grammar Perspective. In: Michel, S & Onysko, 
A (eds.). Cognitive Approaches to Word-Formation. 
Berlin: Mouton de Gruyter. pp. 97-126. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 5: Categorization network for the person-4 
data set 
46
