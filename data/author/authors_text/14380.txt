Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 1020?1028,
Beijing, August 2010
Ukwabelana - An open-source morphological Zulu corpus
Sebastian Spiegler
Intelligent Systems Group
University of Bristol
spiegler@cs.bris.ac.uk
Andrew van der Spuy
Linguistics Department
University of the Witwatersrand
andrew.vanderspuy@wits.ac.za
Peter A. Flach
Intelligent Systems Group
University of Bristol
peter.flach@bris.ac.uk
Abstract
Zulu is an indigenous language of South
Africa, and one of the eleven official
languages of that country. It is spoken
by about 11 million speakers. Although
it is similar in size to some Western
languages, e.g. Swedish, it is consid-
erably under-resourced. This paper
presents a new open-source morphologi-
cal corpus for Zulu named Ukwabelana
corpus. We describe the agglutinating
morphology of Zulu with its multiple
prefixation and suffixation, and also
introduce our labeling scheme. Further,
the annotation process is described and
all single resources are explained. These
comprise a list of 10,000 labeled and
100,000 unlabeled word types, 3,000
part-of-speech (POS) tagged and 30,000
raw sentences as well as a morphological
Zulu grammar, and a parsing algorithm
which hypothesizes possible word roots
and enumerates parses that conform to the
Zulu grammar. We also provide a POS
tagger which assigns the grammatical
category to a morphologically analyzed
word type. As it is hoped that the corpus
and all resources will be of benefit to
any person doing research on Zulu or on
computer-aided analysis of languages,
they will be made available in the public
domain from http://www.cs.bris.
ac.uk/Research/MachineLearning/
Morphology/Resources/.
1 Introduction
Zulu (also known as isiZulu) is a Bantu language
of South Africa, classified as S.30 in Guthrie?s
classification scheme (Guthrie, 1971). Since
1994, it has been recognized as one of the eleven
official languages of South Africa. It has a written
history of about 150 years: the first grammar was
published by Grout (1859), and the first dictionary
by Colenso (1905). There are about 11 million
mother-tongue speakers, who constitute approxi-
mately 23% of South Africa?s population, making
Zulu the country?s largest language.
Zulu is highly mutually intelligible with the
Xhosa, Swati and Southern Ndebele languages,
and with Ndebele of Zimbabwe (Lanham, 1960),
to the extent that all of these can be consid-
ered dialects or varieties of a single language,
Nguni. Despite its size, Zulu is considerably
under-resourced, compared to Western languages
with similar numbers of speakers, e.g. Swedish.
There are only about four regular publications in
Zulu, there are few published books, and the lan-
guage is not used as a medium of instruction.
This of course is partly due to the short time-
span of its written history, but the main reason, of
course, is the apartheid history of South Africa:
for most of the twentieth century resources were
allocated to Afrikaans and English, the two former
official languages, and relatively few resources
to the indigenous Bantu languages. Since 1994,
Zulu has had a much larger presence in the media,
with several television programs being broadcast
in Zulu every day. Yet much needs to be done in
order to improve the resources available to Zulu
speakers and students of Zulu.
The aim of the project reported in this paper
was to establish a Zulu corpus, named the Uk-
wabelana corpus1, consisting of morphologically
labeled words (that is, word types) and part-of-
speech (POS) tagged sentences. Along with the
labeled corpus, unlabeled words and sentences, a
morphological grammar, a semi-automatic mor-
1Ukwabelana means ?to share? in Zulu where the ?k? is
pronounced voiced like a [g].
1020
phological analyzer and a POS tagger for morpho-
logically analyzed words will be provided.
The sources used for the corpus were limited to
fictional works and the Zulu Bible. This means
that there is not a wide variety of registers, and
perhaps even of vocabulary items. This defect will
have to be corrected in future work.
The Ukwabelana corpus can be used to de-
velop and train automatic morphological analyz-
ers, which in turn tag a large corpus of writ-
ten Zulu, similar to the Brown corpus or the
British National Corpus. Moreover, the list of
POS tagged sentences is an essential step towards
building an automatic syntactic tagger, which still
does not exist for Zulu, and a tagged corpus of
Zulu. Such a corpus would be beneficial to lan-
guage researchers as it provides them with ex-
amples of actual usage, as opposed to elicited
or invented examples, which may be artificial or
unlikely to occur in real discourse. This would
greatly improve the quality of Zulu dictionaries
and grammars, most of which rely heavily on
the work of Doke (1927) and Doke, Malcom and
Sikakana (1958), with little in the way of inno-
vation. Morphological tagging is also useful for
practical computational applications like predic-
tive text, spell-checking, grammar checking and
machine translation; in the case of Zulu, where
a large percentage of grammatical information is
conveyed by prefixes and suffixes rather than by
separate words, it is essential. For example, in
English, the negative is expressed by means of a
separate word ?not?, but in Zulu the negative is
constructed using a prefix-and-suffix combination
on the verb, and this combination differs accord-
ing to the mood of the verb (indicative, participial
or subjunctive). The practical computational ap-
plications mentioned could have a very great im-
pact on the use of Zulu as a written language, as
spell-checking and grammar checking would ben-
efit proofreaders, editors and writers. Machine
translation could aid in increasing the number of
texts available in Zulu, thus making it more of a
literary language, and allowing it to become es-
tablished as a language of education. The use
of Zulu in public life could also increase. Cur-
rently, the tendency is to use English, as this is
the language that reaches the widest audience. If
high-quality automatic translation becomes avail-
able, this would no longer be necessary. As it is
hoped that the Ukwabelana corpus will be of ben-
efit to any person doing research on Zulu or on
computer-aided analysis of languages, it will be
made available as the first morphologically anal-
ysed corpus of Zulu in the public domain.
2 Related work
In this section, we will give an overview of lin-
guistic research on Nguni languages, following
the discussions in van der Spuy (2001), and there-
after a summary of computational approaches to
the analysis of Zulu.
2.1 Linguistic research on Nguni languages
The five Nguni languages Zulu, Xhosa, South
African Ndebele, Swati, and Zimbabwean Nde-
bele are highly mutually intelligible, and for this
reason, works on any of the other Nguni languages
are directly relevant to an analysis of Zulu.
There have been numerous studies of Nguni
grammar, especially its morphology; in fact,
the Nguni languages probably rival Swahili and
Chewa for the title of most-studied Bantu lan-
guage. The generative approach to morphologi-
cal description (as developed by Aronoff (1976),
Selkirk (1982), Lieber (1980), Lieber (1992)) has
had very little influence on most of the work that
has been done on Nguni morphology.
Usually, the descriptions have been atheoreti-
cal or structuralist. Doke?s paradigmatic descrip-
tion of the morphology (Doke, 1927; Doke, 1935)
has remained the basis for linguistic work in the
Southern Bantu languages. Doke (1935) criticized
previous writers on Bantu grammars for basing
their classification, treatment and terminology on
their own mother tongue or Latin. His intention
was to create a grammatical structure for Bantu
which did not conform to European or classical
standards. Nevertheless, Doke himself could not
shake off the European mindset: he treated the
languages as if they had inflectional paradigms,
with characteristics like subjunctive or indicative
belonging to the whole word, rather than to identi-
fiable affixes; in fact, he claimed (1950) that Bantu
languages are ?inflectional with [just] a tendency
to agglutination?, and assumed that the morphol-
1021
ogy was linear not hierarchical. Most subsequent
linguistic studies and reference grammars of the
Southern Bantu languages have been directed at
refining or redefining Doke?s categories from a
paradigmatic perspective.
Important Nguni examples are Van Eeden
(1956), Van Wyk (1958), Beuchat (1966), Wilkes
(1971), Nkabinde (1975), Cope (1984), Davey
(1984), Louw (1984), Ziervogel et al (1985),
Gauton (1990), Gauton (1994), Khumalo (1992),
Poulos and Msimang (1998), Posthumus (1987),
Posthumus (1988), Posthumus (1988) and Posthu-
mus (2000). Among the very few generative
morphological descriptions of Nguni are Lanham
(1971), Mbadi (1988) and Du Plessis (1993). Lan-
ham (1971) gives a transformational analysis of
Zulu adjectival and relative forms. This analy-
sis can be viewed as diachronic rather than syn-
chronic. Mbadi (1988) applies Lieber (1980)
and Selkirk?s percolation theory (Selkirk, 1982)
to a few Xhosa morphological forms. Du Plessis
(1993) gives a hierarchical description of the mor-
phology of the verb, but he assumes that deriva-
tion is syntactical rather than lexical.
In short, there has been no thorough-going
generative analysis of the morphology which
has treated the Nguni languages as agglutinative
rather than inflectional.
2.2 Computational approaches to analyzing
Zulu
In the last decade, various computational ap-
proaches for Zulu have been reported. Based on
the Xerox finite-state toolbox by Beesley and Kart-
tunen (2003), Pretorius and Bosch (2003) devel-
oped a prototype of a computational morpholog-
ical analyzer for Zulu. Using a semi-automated
process, a morphological lexicon and a rule-base
were built incrementally. Later work (Pretorius
and Bosch, 2007) dealt with overgeneration of
the Zulu finite-state tool concerning locative for-
mation from nouns and verbal extensions to verb
roots. Pretorius and Bosch (2009) also used cross-
linguistic similarities and dissimilarities of Zulu
to bootstrap a morphological analyser for Xhosa.
Joubert et al (2004) followed a bootstrapping
approach to morphological analysis. A simple
framework uses morpheme lists, morphophono-
logical and morphosyntactic rules which are learnt
by consulting an oracle, in their case a linguis-
tic expert who corrects analyses. The frame-
work then revises its grammar so that the updated
morpheme lists and rules do not contradict previ-
ously found analyses. Botha and Barnard (2005)
compared two approaches for gathering Zulu text
corpora from the World Wide Web. They drew
the conclusion that using commercial search en-
gines for finding Zulu websites outperforms web-
crawlers even with a carefully selected starting
point. They saw the reason for that in the fact that
most documents on the internet are in one of the
world?s dominant languages. Bosch and Eiselen
(2005) presented a spell checker for Zulu based on
morphological analysis and regular expressions.
It was shown that after a certain threshold for
the lexicon size performance could only be im-
proved by incrementally extending morphological
rules. Experiments were performed for basic and
complex Zulu verbs and nouns, and large num-
bers of words still were not recognized. Spiegler
et al (2008) performed experiments where they
tested four machine learning algorithms for mor-
phological analysis with different degrees of su-
pervision. An unsupervised algorithm analyzed
a raw word list, two semi-supervised algorithms
were provided with word stems and subsequently
segmented prefix and suffix sequences, and the
supervised algorithm used a language model of
analysed words which was applied to new words.
They experimentally showed that there is a cer-
tain trade-off between the usage of labeled data
and performance. They also reckoned that com-
putational analysis improves if words of different
grammatical categories are analysed separately
since there exist homographic morphemes across
different word categories.
3 Zulu morphology
Zulu is an agglutinative language, with a complex
morphology. It presents an especial problem for
computational analysis, because words usually in-
corporate both prefixes and suffixes, and there can
be several of each. This makes it hard to identify
the root by mechanical means, as the root could
be the first, second, third, or even a later mor-
pheme in a word. The complexities involved are
1022
exacerbated by the fact that a considerable num-
ber of affixes, especially prefixes, have allomor-
phic forms. This is largely brought about by the
fact that Zulu has a prohibition against sequences
of vowels, so that a prefix whose canonical form is
nga- will have an allomorph ng- before roots that
begin with vowels. Given a sequence nga-, then, it
is possible that it constitutes an entire morpheme,
or the beginning of a morpheme like the verb root
ngabaz- ?to be uncertain?, or a morpheme ng- fol-
lowed by a vowel-commencing root like and- ?to
increase?. Furthermore, many morphemes are ho-
mographs, so that the prefix nga- could represent
either the potential mood morpheme or a form of
the negative that occurs in subordinate clauses;
and the sequence ng- could be the allomorph of ei-
ther of these, or of a number of homographic mor-
phemes ngi-, which represent the first person sin-
gular in various moods. Besides these phonologi-
cally conditioned allomorphs, there are also mor-
phologically conditioned ones, for example the
locative prefix e- has an allomorph o- that occurs
in certain morphological circumstances. Certain
morpheme sequences also exhibit syncretism, so
that while most nouns take a sequence of prefixes
known as the initial vowel and the noun prefix, as
in i-mi-zi ?villages?, nouns of certain classes, like
class 5, syncretise these two prefixes, as in i-gama
?name?, where the prefix i- represents both the ini-
tial vowel and the noun prefix.
Like all other Bantu languages, Zulu divides its
nouns into a number of classes. The class is often
identifiable from the noun prefix that is attached
to the noun, and it governs the agreement of all
words that modify the noun, as well as of predi-
cates of which the noun is a subject. Object agree-
ment may also be marked on the predicate. Two
examples of this agreement are given below.
Example 1.
Leso si-tshudeni e-si-hle e-ngi-si-fundis-ile si-phas-e kahle.
that student who-AGR-good who-I-him-teach-PAST AGR-
pass-PAST well.
?That good student whom I taught passed well.?
Example 2.
Lowo m-fundi o-mu-hle e-ngi-m-fundis-ile u-phas-e kahle.
that learner who-AGR-good who-I-him-teach-PAST AGR-
pass-PAST well.
?That good learner whom I taught passed well.?
The differences in agreement morphology in the
two sentences is brought about because the nouns
sitshudeni and mfundi belong to different classes.
Canonici (1996) argues that a noun should be as-
signed to a class by virtue of the agreement that it
takes. In terms of this criterion, there are twelve
noun classes in Zulu. These classes are numbered
1?7, 9, 10, 11, 14, 15. The numbering system
was devised by Meinhof (1906), and reflects the
historical affinities between Zulu and other Bantu
languages: Zulu lacks classes 8, 12 and 13, which
are found in other Bantu languages. In the labels
used on the database, morphemes that command
or show agreement have been labeled as <xn>,
where x is a letter or sequence of letters, and n is
a number: thus the morpheme m- in mfundi is la-
beled <n1>, as it marks the noun as belonging to
noun class 1. The morpheme si- in engisifundis-
ile is marked <o7>, as it shows object agreement
with a noun of class 7.
Zulu predicatives may be either verbal or non-
verbal ? the latter are referred to in the literature as
copulatives. Copulatives usually consist of a pred-
icative prefix and a base, which may be a noun,
an adjective, or a prepositional, locative or adver-
bial form. There may also be various tense, aspect
and polarity markers. They translate the English
verb ?be?, plus its complement ? Zulu has no di-
rect equivalent of ?be?; the verb -ba, which has
the closest meaning, is probably better translated
as ?become?. Examples of copulative forms are
ubenguthisha ?he was a teacher?, zimandla ?they
are strong?, basekhaya ?they are at home?. Pred-
icatives may occur in a variety of moods, tenses,
aspects and polarities; these are usually distin-
guished by the affixes attached to the base form.
Thus in engasesendlini ?(s)he no longer being in
the house?, the initial prefix e- indicates third per-
son singular, class 1, participial mood; the prefix
nga- denotes negative; the first prefix se- denotes
continuative aspect; the second prefix se- is the
locative prefix; n- shows that the noun belongs to
class 9; dl- is the noun root meaning ?house?, an
allomorph of the canonical form -dlu; and -ini is
the locative suffix. Thus in typical agglutinative
manner, each affix contributes a distinctive part of
1023
the meaning of the word as a whole. This charac-
teristic of the language was exploited in the label-
ing system used for the morphological corpus: la-
bels were designed so as to indicate the grammati-
cal function of the morpheme. A person searching
for past tense negative verbs, for example, could
simply search for the combination of <past >,
<neg> and <vr>. A complete list of morphemes,
allomorphs and their labels is provided along with
the corpus and other resources.
According to the Dokean grammatical tradition
(Doke, 1927), Zulu has a large number of parts
of speech. This is because what would be sepa-
rate words in other languages are often prefixes in
Zulu, and also because various subtypes of deter-
miner are given individual names. The parts of
speech recognised in the corpus are: noun, verb,
adjective, pronoun, adverb, conjunction, prepo-
sitional, possessive, locative, demonstrative, pre-
sentative, quantitative, copulative and relative.
Adjective includes the traditional Dokean ad-
jective (a closed class of roots which take noun
prefixes as their agreement prefixes) and the pred-
icative form of the Dokean relative, which is
seen as an open class of adjectives (cf. van der
Spuy (2006)). Pronouns are the personal pro-
nouns, which may also (sometimes in allomor-
phic form) be used as agreement morphemes in
quantifiers. Adverbs may be forms derived from
adjectives by prefixing ka- to the root, or mor-
phologically unanalysable forms like phansi ?in
front, forward?. Ideophones have been included
as adverbs. Prepositionals are words that incor-
porate the Dokean ?adverbials? na- ?with?, nga-
?by means of?, njenga- ?like?, kuna- ?more than?,
etc., which are better analysed as prepositions.
The presentative is Doke?s ?locative demonstra-
tive copulative? - the briefer name was suggested
by van der Spuy (2001). Copulatives are all
Doke?s copulatives, excluding the adjectives men-
tioned above. Relatives are all predicative forms
incorporating a relative prefix.
4 The labeling scheme
The labeling scheme has been based on the idea
that each morpheme in a word should be la-
beled, even when words belong to a very re-
stricted class. For example, the demonstratives
could have been labeled as composite forms, but
instead it is assumed that demonstratives con-
tain between one and three morphemes, e.g.
le<d>si<d7>ya<po3> ?a demonstrative of the
third position referring to class 7? - i.e.. ?that one
yonder, class 7?. It should be possible from this
detailed labeling to build up an amalgam of the
morphological structure of the word. The labels
have been chosen to be both as brief as possi-
ble and as transparent as possible, though trans-
parency was often sacrificed for brevity. Thus in-
dicative subject prefixes are labeled <i1-15>, rel-
ative prefixes are labeled <r>, and noun prefixes
are labeled <n1-15>; but negative subject pre-
fixes are labeled <g1-15> and possessive agree-
ment prefixes are labeled <z1-15>. Sometimes a
single label was used for several different forms,
when these are orthographically distinct, so for
example <asp> (aspect) is used as a label for
the following, among others: the continuative pre-
fix sa- and its allomorph se-, the exclusive pre-
fix se-, and the potential prefix nga- and its allo-
morph ng-. A person searching for forms contain-
ing the potential aspect would have to search for
?nga<asp> + ng<asp>?. However, there should
be no ambiguity, as the orthographic form would
eliminate this. The detailed description of the
scheme is provided by Spiegler et al (2010).
5 Annotation process
The goal of this project was to build a reason-
ably sized corpus of morphologically annotated
words of high quality which could be later used
for developing and training automatic morpholog-
ical analyzers. For this reason, we had gathered a
list of the commonest Zulu word types, defined
a partial grammar and parsed Zulu words with a
logic algorithm which proposes possible parses
based on the partial grammar. Compared to a
completely manual approach, this framework pro-
vided possible annotations to choose from or the
option to type in an annotation if none of the sug-
gestions was the correct one. This semi-automatic
process speeded up the labeling by an estimated
factor of 3-4, compared to a purely manual ap-
proach. In Figure 1 we illustrate the annotation
process and in the following subsections each step
is detailed.
1024
	 ?Hypothesis	 ?
generation	 ?
Hypothesis	 ?
evaluation	 ?
Best	 ?
hypothesis	 ?
Parsing	 ?
algorithm	 ?
Grammar	 ?update	 ?
Web	 ?interface	 ?
Annotation	 ?framework	 ?
Curation	 ? Ukwabelana	 ?
corpus	 ?Annotated	 ?word	 ?list	 ?
Unannotated	 ?
word	 ?list	 ?
Partial	 ?
grammar	 ?
Figure 1: Process view of the annotation.
5.1 Unannotated word list
A list of unannotated Zulu words has been com-
piled from fictional works and the Zulu Bible. The
original list comprises around 100,000 of the com-
monest Zulu word types. No information, mor-
phological or syntactic, was given along with the
words. We selected an initial subset of 10,000
words although our long-term goal is the complete
analysis of the entire word list.
5.2 Partial grammar
Our choice for representing the morphological
Zulu grammar was the formalism of Definite
Clause Grammars (DCGs) used in the logic pro-
gramming language Prolog. Although we de-
fined our grammar as a simple context-free gram-
mar, DCGs can also express context-sensitive
grammars by associating variables as arguments
to non-terminal symbols (Gazdar and Mellish,
1989). When defining our morphological gram-
mar, we assumed that a linguistic expert could
enumerate all or at least the most important mor-
phological rules and morphemes of ?closed? mor-
pheme categories, e.g. prefixes and suffixes of
nouns and verbs. Morphemes of ?open? categories
like noun and verb roots, however, would need to
be hypothesized during the semi-automatic anal-
ysis and confirmed by the linguistic expert. Our
final grammar comprised around 240 morpholog-
ical rules and almost 300 entries in the morpheme
dictionary. Since we did not only want to recog-
nize admissible Zulu words but also obtain their
morphological structure, we needed to extend our
DCG by adding parse construction arguments as
shown in the example below.
Example 3.
w((X)) --> n(X).
n((X,Y,Z)) --> iv(X),n2(Y),nr(Z).
iv(iv(a)) --> [a].
n2(n2(ba))--> [ba].
A possible parse for the word abantu ?people?
could be iv(a),n2(ba),*nr(ntu) where
?*? marks the hypothesized noun root.
With our partial grammar we could not directly
use the inbuilt Prolog parser since we had to ac-
count for missing dictionary entries: Zulu verb
and noun roots. We therefore implemented an
algorithm which would generate hypotheses for
possible parses according to our grammar. The al-
gorithm will be described in the next subsection.
5.3 Hypothesis generation
For the hypothesis generation we reverted to logic
programming and abductive reasoning. Abduc-
tion is a method of reasoning which is used with
incomplete information. It generates possible hy-
potheses (parses) for an observation (word) and a
given theory (grammar). Depending on the im-
plementation, abduction finds the best hypothe-
sis by evaluating all possible explanations. Our
abductive algorithm is an extension of the meta-
interpreter designed by Flach (1994) which only
enumerates possible parses based on the grammar.
A linguistic expert would then choose the best hy-
pothesis. The algorithm invokes rules top-down
starting with the most general until it reaches the
last level of syntactic variables. These variables
1025
are then matched against their dictionary entries
from the left to the right of the word. A possi-
ble parse is found if either all syntactic variables
can be matched to existing dictionary entries or
if an unmatched variable is listed as abducible.
Abducibles are predefined non-terminal symbols
whose dictionary entry can be hypothesized. In
our case, abducibles were noun and verb roots.
5.4 Evaluation and best hypothesis
Our annotation framework only enumerated al-
lowable parses for a given word, therefore a lin-
guistic expert needed to evaluate hypotheses. We
provided a web-interface to the annotation frame-
work, so that multiple users could participate in
the annotation process. They would choose either
a single or multiple correct parses. If none of the
hypotheses were correct, the user would provide
the correct analysis. Although our grammar was
incomplete it still generated a substantial number
of hypotheses per word. These were in no par-
ticular order and a result of the inherent ambi-
guity of Zulu morphology. We therefore experi-
mented with different ways of improving the pre-
sentation of parses. The most promising approach
was structural sorting. Parses were alphabetically
re-ordered according to their morphemes and la-
bels such that similar results were presented next
to each other.
5.5 Grammar update
The grammar was defined in an iterative process
and extended if the linguistic expert found mor-
phemes of closed categories which had not been
listed yet or certain patterns of incomplete or in-
correct parses caused by either missing or inaccu-
rate rules. The updated rules and dictionary were
considered for newly parsed words.
5.6 Annotated word list and curation process
Although there had been great effort in improv-
ing the hypothesis generation of the parsing al-
gorithm, a reasonable number of morphological
analyses still had to be provided manually. Dur-
ing the curation process, we therefore had to deal
with removing typos and standardizing morpheme
labels provided by different experts. In order to
guarantee a high quality of the morphological cor-
Category # Analyses #Word types
Verb 6965 4825
Noun 1437 1420
Relative 1042 988
Prepositional 969 951
Possessive 711 647
Copulative 558 545
Locative 380 379
Adverb 156 155
Modal 113 113
Demonstrative 63 61
Pronoun 38 31
Interjection 24 24
Presentative 15 15
Adjective 14 14
Conjunction 3 3
Total# 12488 10171
Table 1: Categories of labeled words.
pus, we also inspected single labels and analyses
for their correctness. This was done by examin-
ing frequencies of labels and label combinations
assuming that infrequent labels and combinations
were likely to be incorrect and needed to be man-
ually examined again. The finally curated corpus
has an estimated error of 0.4 ? 0.5 incorrect sin-
gle labels and 2.8? 2.1 incorrect complete analy-
ses per 100 parses. Along with each word?s anal-
ysis we wanted to provide part-of-speech (POS)
tags. This was done by using a set of rules which
determine the POS tag based on the morphologi-
cal structure. We developed a prototype of a POS
tagger which would assign the part-of-speech to a
given morphological analysis based on a set of 34
rules. A summary of morphological analyses and
words is given in Table 1. The rules are provided
in Spiegler et al (2010).
5.7 POS tagging of sentences
In addition to the list of morphologically labeled
words, we assigned parts-of-speech to a subset of
30,000 Zulu sentences. This task is straightfor-
ward if each word of a sentence only belongs to a
single grammatical category. This was the case for
2595 sentences. For 431 sentences, however, we
needed to disambiguate POS tags. We achieved
this by analysing the left and right context of a
word form and selecting the most probable part-
of-speech from a given list of possible tags.
The overall error is estimated at 3.1?0.3 incor-
rect POS tags per 100 words for the 3,000 sen-
1026
Dataset # Sentences #Word tokens #Word types #Words per sentence Word length
Raw 29,424 288,106 87,154 9.79?6.74 7.49?2.91
Tagged 3,026 21,416 7,858 7.08?3.75 6.81?2.68
Table 2: Statistics of raw and POS-tagged sentences.
tences we tagged. The summary statistics for raw
and tagged sentences are shown in Table 2.
6 The Ukwabelana corpus - a resource
description
The Ukwabelana corpus is three-fold:
1. It contains 10,000 morphologically labeled
words and 3,000 POS-tagged sentences.
2. The corpus also comprises around 100,000
common Zulu word types and 30,000 Zulu sen-
tences compiled from fictional works and the
Zulu Bible, from which the labeled words and
sentences have been sampled.
3. Furthermore, all software and additional data
used during the annotation process is provided:
the partial grammar in DCG format, the ab-
ductive algorithm for parsing with incomplete
information and a prototype for a POS tagger
which assigns word categories to morphologi-
cally analyzed words.
We are making these resources publicly available
from http://www.cs.bris.ac.uk/Research/
MachineLearning/Morphology/Resources/ so
that they will be of benefit to any person doing
research on Zulu or on computer-aided analysis
of languages.
7 Conclusions and future work
In this paper, we have given an overview of the
morphology of the language Zulu, which is spo-
ken by 23% and understood by more than half of
the South African population. As an indigenous
language with a written history of 150 years which
was only recognised as an official languages in
1994, it is considerably under-resourced. We have
spent considerable effort to compile the first open-
source corpus of labeled and unlabeled words as
well as POS-tagged and untagged sentences to
promote research on this Bantu language. We
have described the annotation process and the
tools for compiling this corpus. We see this work
as a first step in an ongoing effort to ultimately
label the entire word and sentence corpus.
Our future work includes further automation of
the annotation process by extending the described
abductive algorithm with a more sophisticated hy-
pothesis evaluation and by combining syntactical
and morphological information during the deci-
sion process. Our research interest also lies in the
field of automatic grammar induction which will
help to refine our partial grammar. Another aspect
is interactive labeling where a linguistic expert di-
rects the search of an online parsing algorithm by
providing additional information. Apart from the
benefits to language researchers, we foresee an ap-
plication of the corpus by machine learners which
can develop and train their algorithms for morpho-
logical analysis.
Acknowledgements
We would like to thank Etienne Barnard and the
Human Language Technologies Research Group
from the Meraka Institute for their support during
this project. Furthermore, we want to acknowl-
edge Johannes Magwaza, Bruno Gole?nia, Ksenia
Shalonova and Roger Tucker. The research work
was sponsored by EPSRC grant EP/E010857/1
Learning the morphology of complex synthetic
languages and a grant from the NRF (S. Africa).
References
Aronoff. 1976. Word Formation in Generative Grammar.
The MIT Press.
Beesley and Karttunen. 2003. Finite State Morphology.
University of Chicago Press.
Beuchat. 1966. The Verb in Zulu. African Studies, 22:137?
169.
Bosch and Eiselen. 2005. The Effectiveness of Morpho-
logical Rules for an isiZulu Spelling Checker. S. African
Journal of African Lang., 25:25?36.
Botha and Barnard. 2005. Two Approaches to Gathering
Text Corpora from the World Wide Web. 16th Ann. Symp.
of the Pattern Recog. Ass. of S. Africa.
1027
Canonici. 1996. Zulu Grammatical Structure. Zulu Lang.
and Literature, University of Natal, Durban.
Colenso. 1905. Zulu-English Dictionary. Natal, Vause,
Slatter & Co.
Cope. 1984. An Outline of Zulu Grammars. African Stud-
ies, 43(2):83?102.
Davey. 1984. Adjectives and Relatives in Zulu. S. African
Journal of African Lang., 4:125?138.
Doke. 1927. Text Book of Zulu Grammar. Witwatersrand
University Press.
Doke. 1935. Bantu Linguistic Terminology. Longman,
Green and Co, London.
Doke. 1954. Handbook of African Lang., chapter The S.ern
Bantu Lang. Oxford University Press.
Doke, Malcom and Sikakana. 1958. Zulu-English vocabu-
lary. Witwatersrand Uni. Press.
Du Plessis. 1993. Linguistica: Festschrift EB van Wyk,
chapter Inflection in Syntax, pp. 61?66. Van Schaik, Pre-
toria.
Flach. 1994. Simply Logical. John Wiley.
Gauton. 1990. Adjektiewe en Relatiewe in Zulu. Master?s
thesis, University of Pretoria.
Gauton. 1994. Towards the Recognition of a Word Class
?adjective? for Zulu. S. African Journal of African Lang.,
14:62?71.
Gazdar and Mellish. 1989. Natural Language Processing in
Prolog. Addison-Wesley.
Grout. 1859. The Isizulu: A Grammar Of The Zulu Lang.
Kessinger Publishing.
Guthrie. 1971. Comparative Bantu: An Introduction to
the Comparative Linguistics and Prehistory of the Bantu
Lang. Farnborough, Gregg International Publishers.
Joubert, Zimu, Davel, and Barnard. 2004. A Framework
for Bootstrapping Morphological Decomposition. Tech.
report, CSIR/University of Pretoria, S. Africa.
Khumalo. 1992. African Linguistic Contributions, chapter
The morphology of the direct relative in Zulu. Via Afrika.
Lanham. 1960. The Comparative Phonology of Nguni.
Ph.D. thesis, Witwatersrand Uni., Jo?burg, S. Africa.
Lanham. 1971. The Noun as Deep-Structure Source for
Nguni Adjectives and Relatives. African Studies, 30:294?
311.
Lieber. 1980. On the Organization of the Lexicon. Ph.D.
thesis, Massachusetts Institute of Technology.
Lieber. 1992. Deconstructing Morphology. The University
of Chicago Press.
Louw. 1984. Word Categories in Southern Bantu. African
Studies, 43(2):231?239.
Mbadi. 1988. Anthology of Articles on African Linguistics
and Literature, chapter The Percolation Theory in Xhosa
Morphology. Lexicon, Jo?burg.
Meinhof. 1906. Grundzu?ge einer Vergleichenden Gram-
matik der Bantusprachen. Reimer, Berlin.
Nkabinde. 1975. A Revision of the Word Categories in Zulu.
Ph.D. thesis, University of S. Africa.
Posthumus. 1987. Relevancy and Applicability of Terminol-
ogy Concerning the Essential Verb Categories in African
Lang. Logos, 7:185?212.
Posthumus. 1988. Identifying Copulatives in Zulu and S.ern
Sotho. S. African Journal of African Lang., 8:61?64.
Posthumus. 2000. The So-Called Adjective in Zulu. S.
African Journal of African Lang., 20:148?158.
Poulos and Msimang. 1998. A Linguistic Analysis of Zulu.
Via Afrika.
Pretorius and Bosch. 2003. Finite-State Computational
Morphology: An Analyzer Prototype For Zulu. Machine
Translation, 18:195?216.
Pretorius and Bosch. 2007. Containing Overgeneration in
Zulu Computational Morphology. Proceedings of 3rd
Lang. and Technology Conference, pp. 54 ? 58, Poznan.
Pretorius and Bosch. 2009. Exploiting Cross-Linguistic
Similarities in Zulu and Xhosa Computational Morphol-
ogy. Workshop on Lang. Technologies for African Lang.
(AfLaT), pp. 96?103.
Selkirk. 1982. The Syntax of Words. MIT Press.
Spiegler, Golenia, Shalonova, Flach, and Tucker. 2008.
Learning the Morphology of Zulu with Different Degrees
of Supervision. IEEE Workshop on Spoken Lang. Tech.
Spiegler, van der Spuy, Flach. 2010. Additional material for
the Ukwabelana Zulu corpus. Tech. report, University of
Bristol, U.K.
van der Spuy. 2001. Grammatical Structure and Zulu Mor-
phology. Ph.D. thesis, University of the Witwatersrand,
Jo?burg, S. Africa.
van der Spuy. 2006. Wordhood in Zulu. S.ern African Lin-
guistics and Applied Lang. Studies, 24(3):311?329.
Van Eeden. 1956. Zoeloe-Grammatika. Pro Ecclesia, Stel-
lenbosch.
Van Wyk. 1958. Woordverdeling in Noord-Sotho en Zulu:
?n bydrae tot die vraagstuk van word-identifikasie in die
Bantoetale. Ph.D. thesis, University of Pretoria.
Wilkes. 1971. Agtervoegsels van die werkwoord in Zulu.
Ph.D. thesis, Rand Afrikaans University.
Ziervogel, Louw, and Taljaard. 1985. A Handbook of the
Zulu Lang. Van Schaik, Pretoria.
1028
Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 1029?1037,
Beijing, August 2010
EMMA: A Novel Evaluation Metric for Morphological Analysis
Sebastian Spiegler
Intelligent Systems Group
University of Bristol
spiegler@cs.bris.ac.uk
Christian Monson
Center for Spoken Language Understanding
Oregon Health & Science University
monsonc@csee.ogi.edu
Abstract
We present a novel Evaluation Metric
for Morphological Analysis (EMMA)
that is both linguistically appealing and
empirically sound. EMMA uses a graph-
based assignment algorithm, optimized
via integer linear programming, to match
morphemes of predicted word analyses
to the analyses of a morphologically rich
answer key. This is necessary especially
for unsupervised morphology analysis
systems which do not have access to
linguistically motivated morpheme labels.
Across 3 languages, EMMA scores of
14 systems have a substantially greater
positive correlation with mean average
precision in an information retrieval
(IR) task than do scores from the metric
currently used by the Morpho Challenge
(MC) competition series. We compute
EMMA and MC metric scores for 93
separate system-language pairs from
the 2007, 2008, and 2009 MC compe-
titions, demonstrating that EMMA is
not susceptible to two types of gaming
that have plagued recent MC competi-
tions: Ambiguity Hijacking and Shared
Morpheme Padding. The EMMA eval-
uation script is publicly available from
http://www.cs.bris.ac.uk/
Research/MachineLearning/
Morphology/Resources/.
1 Introduction
Words in natural language are constructed from
smaller building blocks called morphemes. For
example, the word wives breaks down into an un-
derlying stem, wife, together with a plural suffix.
Analyzing the morphological structure of words
is known to benefit a variety of downstream nat-
ural language (NL) tasks such as speech recogni-
tion (Creutz, 2006; Ar?soy et al, 2009), machine
translation (Oflazer et al, 2007), and information
retrieval (McNamee et al, 2008).
A variety of automatic systems can morpholog-
ically analyze words that have been removed from
their surrounding context. These systems range
from hand-built finite state approaches (Beesley
and Karttunen, 2003) to recently proposed algo-
rithms which learn morphological structure in an
unsupervised fashion (Kurimo et al, 2007). Since
unsupervised systems do not have access to lin-
guistically motivated morpheme labels, they typ-
ically produce morphological analyses that are
closely related to the written form. Such a system
might decompose wives as wiv -es. Meanwhile,
a hand-built system might propose wife_N +Plu-
ral, or even parse wives as a hierarchical feature
structure. As morphological analysis systems pro-
duce such varied outputs, comparing decomposi-
tions from disparate systems is a challenge.
This paper describes EMMA, an Evaluation
Metric for Morphological Analysis that quantita-
tively measures the quality of a set of morpholog-
ical analyses in a linguistically adequate, empir-
ically useful, and novel fashion. EMMA evalu-
ates analyses that can be represented as a flat set
of symbolic features, including hierarchical repre-
sentations, which can be projected down to a lin-
earized form (Roark and Sproat, 2007).
An automatic metric that discriminates be-
tween proposed morphological analyses should
1029
fulfill certain computational and linguistic crite-
ria. Computationally, the metric should:
1. Correlate with the performance of real-world
NL processing tasks which embed the morpho-
logical analyses.
2. Be Readily Computable: The metric will only
be useful if it is less time consuming and easier
to compute than the larger NL task.
3. Be Robust: The metric should be difficult to
game and should accurately reflect the distri-
bution of predicted and true morphemes.
4. Be Readily Interpretable: When possible, the
final numeric score should directly identify the
strengths and weaknesses of the underlying
morphological analysis system.
While accounting for these computational re-
quirements, a morphology metric should still re-
ward accurate models of linguistic structure. In
particular, the metric should account for:
1. Morphophonology: Applying a morphological
rule may alter the surface form of stem or af-
fix. In the word wives, /waivz/, a rule of mor-
phophonology voices the stem-final /f/ of wife,
/waif/, when the plural suffix is added. A met-
ric should penalize for not placing wives and
wife as forms of the same lexeme.
2. Allomorphy: A metric should capture the suc-
cessful grouping of allomorphs. The German
plural has several surface allomorphs includ-
ing -en in Zeiten (times), -e in Hunde (dogs),
and -s in Autos (cars). A metric should reward
a morphological analysis system that analyzes
the different surface forms of the German plu-
ral as underlyingly identical.
3. Syncretism: In mirror fashion, a metric
should reward analyses that distinguish be-
tween surface-identical syncretic morphemes:
although derives and derivations both contain
an -s morpheme, one marks 3rd person singular
and the other plural.
4. Ambiguity: Finally, a metric should account
for legitimate morphological ambiguity. In He-
brew, the written word MHGR has three vi-
able morphological segmentations: M- H- GR,
?from the foreigner?, M- HGR, ?from Hagar?,
and the unsegmented form MHGR, meaning
?immigrant? (Lavie et al, 2004). Absent dis-
ambiguating context, a morphological system
should be rewarded for calling out all three
analyses for MHGR.
Morphophonology, allomorphy, syncretism,
and ambiguity are all common phenomena in the
world?s languages. The first three have all re-
ceived much discussion in theoretical linguistics
(Spencer and Zwicky, 2001), while morpholog-
ical ambiguity has significant practical implica-
tions in NL processing, e.g. in machine translation
of morphologically complex languages (Lavie et
al., 2004; Oflazer et al, 2007).
In Section 2 we propose the metric EMMA,
which has been specifically designed to evalu-
ate morphological analyses according to our com-
putational and linguistic criteria. Section 3 then
describes and qualitatively critiques several well-
used alternative metrics. Section 4 empirically
compares EMMA against the qualitatively-strong
metric used in the Morpho Challenge competition
series (Kurimo et al, 2009). And we conclude in
Section 5.
2 EMMA: An Evaluation Metric for
Morphological Analysis
EMMA, the metric we propose for the evalua-
tion of morphological analyses, like all the met-
rics that we consider in this paper, compares pro-
posed morphological analyses against an answer
key of definitively-analyzed words from a vocab-
ulary. Since a set of proposed analyses is likely
to use a different labeling scheme than the answer
key, especially true of the output from unsuper-
vised systems, EMMA does not perform a direct
comparison among proposed and answer analy-
ses. Instead, EMMA seeks a one-to-one relabel-
ing of the proposed morphemes that renders them
as similar as possible to the answer key. EMMA,
then, measures the degree to which proposed anal-
yses approximate an isomorphism of the answer
key analyses. For exposition, we initially assume
that, for each word, a single proposed analysis
is scored against a single unambiguous answer
analysis. We relax this restriction in Section 2.3,
where EMMA scores multiple proposed analyses
1030
against a set of legitimately ambiguous morpho-
logical analyses.
To find the most appropriate one-to-one mor-
pheme relabeling, EMMA turns to a standard al-
gorithm from graph theory: optimal maximum
matching in a bipartite graph. A bipartite graph,
G = {X,Y ;E}, consists of two disjoint sets
of vertices, X = {x1, x2, . . . , xn} and Y = {y1,
y2, . . . , ym}, and a set of edges e(xi, yj) ? E
such that each edge has one end in X and the other
end in Y . In EMMA, the set, A, of all unique mor-
phemes in the answer key and the set, P , of all
unique morphemes in the proposed analyses serve
as the disjoint vertex sets of a bipartite graph.
A matching M ? E in a bipartite graph is de-
fined as a set of edges e(xi, yj) such that no xi
or yj is repeated. A maximum matching is a
matching where no M ? with |M ?| > |M | exists.
Furthermore, a weight w(xi, yj) ? < may be as-
signed to each edge e(xi, yj) of a bipartite graph.
An optimal assignment is a maximum matching
which also maximizes the sum of the weights of
the edges of the matching
?
e(xi,yj)?M
w(xi, yj) .
EMMA weights the edge between a particular
answer morpheme a ? A and a proposed mor-
pheme p ? P as the number of words, w, in the
vocabulary, V , where the answer analysis of w in-
cludes morpheme a while the proposed analysis
includes p. EMMA constructs an optimal assign-
ment maximum matching in this weighted bipar-
tite morpheme graph. The edge weights ensure
that the optimal matching will link the answer and
proposed morphemes which globally occur in the
analyses of the same words most often ? restrict-
ing each answer morpheme to be represented by at
most one proposed morpheme, and each proposed
morpheme to represent at most one morpheme in
the answer key. On the one hand, the restrictions
thus imposed by bipartite matching penalize sets
of proposed analyses that do not differentiate be-
tween surface-identical syncretic morphemes. On
the other hand, the same one-to-one matching re-
strictions penalize proposed analyses that do not
conflate allomorphs of the same underlying mor-
pheme, whether those allomorphs are phonologi-
cally induced or not. Thus, EMMA meets our lin-
guistic criteria from Section 1 of modeling syn-
cretism, allomorphy, and morphophonology.
2.1 Maximum Matching by Integer Linear
Programming
To construct the maximum matching optimal as-
signment of answer and proposed morphemes,
EMMA uses standard integer linear programming
techniques as implemented in lpsolve (Berkelaar
et al, 2004). For the purpose of our integer pro-
gram, we represent the weight of each potential
edge of the optimal bipartite morpheme assign-
ment in a count matrix C = {cij} where cij is as-
signed the number of words w ? V which share
morpheme ai in the answer key and pj in the pre-
diction. We then define a binary matrix B = {bij}
of the same dimensions as C. Each bij will be set
to 1 if an edge exists from ai to pj in the optimal
maximum matching, with bij = 0 otherwise. The
integer linear program can then be defined as fol-
lows:
argmax
B
?
i,j
(C ?B)ij (1)
s.t.
?
i
bij ? 1 ,
?
j
bij ? 1 , bij ? 0 ,
where (C ? B)ij = cij ? bij is the element-wise
Hadamard product.
2.2 Performance Measures
Having settled on a maximum matching optimal
assignment of proposed and answer morphemes,
EMMA derives a final numeric score. Let wk
be the kth word of V ; and let Ak and Pk de-
note, respectively, the sets of morphemes in the
answer key analysis of wk and predicted analysis
of wk. Furthermore, let P ?k denote the predicted
morphemes for wk where a morpheme pj is re-
placed by ai if bij = 1. Now that Ak and P ?k
contain morpheme labels that are directly compa-
rable, we can define precision and recall scores
for the proposed analysis of the word wk. Preci-
sion is the fraction of correctly relabeled proposed
morphemes from among all proposed morphemes
of wk; while recall is the number of correctly rela-
beled morphemes as a fraction of the answer key
1031
analysis of wk. Precision and recall of the full vo-
cabulary are the average word-level precision and
recall:
precision = 1|V |
|V |?
k
|Ak
?
P ?k |
|P ?k |
, (2)
recall = 1|V |
|V |?
k
|Ak
?
P ?k |
|Ak|
. (3)
Finally, f-measure is the harmonic mean of pre-
cision and recall:
f -measure = 2 ? precision ? recallprecision+ recall . (4)
2.3 Morphological Ambiguity in EMMA
Thus far we have presented EMMA for the sce-
nario where each word has a single morphological
analysis. But, as we saw in Section 1 with the He-
brew word MHGR, natural language permits sur-
face forms to have multiple legitimate morpho-
logical analyses. When a word is truly ambigu-
ous, EMMA expects an answer key to contain a
set of analyses for that word. Similarly, we per-
mit sets of proposed alternative analyses. To ex-
tend EMMA with the ability to evaluate alterna-
tive analyses we first generalize the optimal max-
imum matching of morphemes from Section 2.1.
We then define a new integer linear program to
match answer and proposed alternative analyses.
Finally, we adjust the performance measures of
Section 2.2 to account for alternatives.
2.3.1 Ambiguity and Morpheme Matching
Let Ak,r denote the rth alternative answer anal-
ysis of the kth word with 1 ? r ? mk, and let
Pk,s denote the sth alternative prediction with
1 ? s ? nk, where mk is the number of alterna-
tive analyses in the answer key and nk the num-
ber of alternative predictions for wk. We redefine
Ak =
?mk
r Ak,r and Pk =
?nk
s Pk,s as the set of
all answer or, respectively, predicted morphemes
of wk across all analysis alternatives. Instead of
incrementing each cij entry in the count matrix
C by a full count, we now add 1mk?nk to cij forall pairs (ai, pj) ? Ak ? Pk. This corresponds to
counting each combination of an answer key and
predicted morpheme normalized by the number of
possible pairings between proposed and answer
analysis alternatives. When both the answer and
proposed analyses consist of just a single alter-
native, cij remains unchanged. Generalized mor-
pheme matching still employs the linear program
defined in Equation 1.
2.3.2 Matching of Alternative Analyses
After performing a one-to-one morpheme rela-
belling that accounts for ambiguity, we need to
extend EMMA with the ability to evaluate alterna-
tive analyses. We again turn to optimal maximum
matching in a bipartite graph: Where earlier we
matched proposed and answer morphemes, now
we match full proposed and answer analysis alter-
natives, maximizing the total number of correctly
predicted morphemes across all alternatives. Gen-
eralizing on the notation of the unambiguous case,
let P ?k,s denote the sth alternative predicted analy-
sis of the kth word where predicted morphemes
have been replaced by their assigned answer key
morphemes. We introduce a new count matrix
C ? = {c?r,s}, where c?r,s is the count of common
morphemes of the rth answer key alternative and
sth predicted alternative. Based on Equation 1,
we calculate the binary matrix B? = {b?r,s} which
contains the optimal assignment of the alternative
answer key and predicted analyses for wk.
2.3.3 Ambiguity and Performance Scores
We now adjust EMMA?s numeric performance
measures to account for sets of ambiguous anal-
ysis alternatives. Precision becomes
1
|V |
|V |?
k
1
nk
mk?
r
nk?
s
b?r,s
|Ak,r
?
P ?k,s|
|P ?k,s|
, (5)
the ratio of correctly predicted morphemes across
all predicted alternatives normalised by the num-
ber of predicted alternatives, nk, and the vocab-
ulary size, |V |. The factor b?r,s guarantees that
scores are only averaged over pairs of proposed
and answer analysis alternatives that have been as-
signed, that is, where b?r,s = 1. Recall is measured
similarly with
1
|V |
|V |?
k
1
mk
mk?
r
nk?
s
b?r,s
|Ak,r
?
P ?k,s|
|Ak,r|
. (6)
1032
Here, we normalize by mk, the number of alterna-
tive analyses for the kth word that are listed in the
answer key. The normalisation factors 1mk and 1nkensure that predicting too few or many alternative
analyses is penalised.
3 Other Morphology Metrics
Having presented the EMMA metric for evaluat-
ing the quality of a set of morphological analyses,
we take a step back and examine other metrics that
have been proposed. Morphology analysis metrics
can be categorized as either: 1. Directly compar-
ing proposed analyses against an answer key, or 2.
Indirectly comparing proposed and answer analy-
ses by measuring the strength of an isomorphic-
like relationship between the proposed and answer
morphemes. The proposed EMMA metric belongs
to the second category of isomorphism-based met-
rics.
3.1 Metrics of Direct Inspection
By Segmentation Point. Perhaps the most read-
ily accessible automatic evaluation metric is a di-
rect comparison of the morpheme boundary posi-
tions in proposed and answer analyses. As early
as 1974, Hafer and Weiss used the direct boundary
metric. Although intuitively simple, the segmen-
tation point method implicitly assumes that it is
possible to arrive at a valid morphological anal-
ysis by merely dividing the characters of a word
into letter sequences that can be reconcatenated to
form the original word. But, by definition, con-
catenation cannot describe non-contanative pro-
cesses like morphophonology and allomorphy.
Nor does simple segmentation adequately differ-
entiate between surface-identical syncretic mor-
phemes. Despite these drawbacks, precision and
recall of segmentation points is still used in cur-
rent morphological analysis research (Poon et al
(2009), Snyder and Barzilay (2008), Kurimo et al
(2006)).
Against Full Analyses. To confront the reality
of non-concatenative morphological processes, an
answer key can hold full morphological analyses
(as opposed to merely segmented surface forms).
But while a hand-built (Beesley and Karttunen,
2003) or supervised (Wicentowski , 2002) mor-
phology analysis system can directly model the
annotation standards of a particular morphologi-
cal answer key, the label given to specific mor-
phemes is ultimately an arbitrary choice that an
unsupervised morphology induction system has
no way to discover.
By Hand. On the surface, scoring proposed
analyses by hand appears to provide a way to eval-
uate the output of an unsupervised morphology
analysis system. Hand evaluation, however, does
not meet our criteria from Section 1 for a robust
and readily computable metric. It is time consum-
ing and, as Goldsmith (2001) explains, leaves dif-
ficult decisions of what constitutes a morpheme to
on-the-fly subjective opinion.
3.2 Metrics of Isomorphic Analysis
Recognizing the drawbacks of direct evaluation,
Schone and Jurafsky (2001), Snover et al (2002),
and Kurimo et al (2007) propose related measures
of morphological analysis quality that are based
on the idea of an isomorphism. For reasons that
will be clear momentarily, we refer to the Schone
and Jurafsky, Snover et al, and Kurimo et al met-
rics as soft isomorphic measures. As discussed
in Section 2, metrics of isomorphism measure
similarities between the distribution of proposed
morphemes and the distribution of answer mor-
phemes, where proposed and answer morphemes
may be disjoint symbol sets.
Unlike the EMMA metric proposed in Section
2, the soft metrics of isomorphism do not seek
to explicitly link proposed morphemes to answer
morphemes. Instead, their metrics group sets or
pairs of words which share, in either the pro-
posed analyses or in the answer analyses, a stem
(Schone and Jurafsky, 2001; Snover, 2002), a suf-
fix (Snover et al, 2002), or any arbitrary mor-
pheme (Kurimo et al, 2007). The soft met-
rics subsequently note whether these same sets or
pairs of words share any morpheme in the answer
key or, respectively, in the proposed analyses. By
foregoing a hard morpheme assignment, the soft
metrics do not adequately punish sets of proposed
and answer morphemes which fail to model syn-
cretism and/or allomorphy. For example, pro-
posed analyses that annotate 3rd person singular
and plural with a single undifferentiated +s mor-
pheme will receive recall credit for both nouns and
1033
verbs.
3.3 The Morpho Challenge Metric
The Morpho Challenge (MC) competition series
for unsupervised morphology analysis algorithms
(Kurimo et al, 2009) has used a soft metric of iso-
morphism in its most recent three years of compe-
tition: 2007, 2008, and 2009. According to Ku-
rimo et al (2009) the Morpho Challenge (MC)
measure samples random word pairs which share
at least one common morpheme. Precision is cal-
culated by generating random word pairs from
the set of proposed analyses and then compar-
ing the analyses of the word pairs in the answer
key. The fraction of found and expected common
morphemes is normalised by the number of words
which are evaluated. Recall is defined in mirror
fashion. The MC metric also normalizes preci-
sion and recall scores across sets of alternative
analyses for each word in the proposal and answer
key. To our knowledge the MC metric is the first
isomorphism-based metric to attempt to account
for morphological ambiguity. As we show in Sec-
tion 4, however, MC?s handling of ambiguity is
easily gamed.
The MC metric does meet our criterion of being
readily computable and, as we will show in the ex-
perimental section, the metric also correlates to a
certain extent with performance on a higher-level
natural language processing task. The downside
of the MC metric, however, is robustness. In addi-
tion to MC?s crude handling of ambiguity and its
over-counting of allomorphs and syncretic mor-
phemes, the random pair sampling method that
MC uses is not independent of the set of analyses
being evaluated. If two algorithms predict differ-
ent morpheme distributions, the sampling method
will find different numbers of word pairs. We sub-
stantiate our claim that the MC metric lacks ro-
bustness in Section 4 where we empirically com-
pare it to the EMMA metric.
4 Experimental Evaluation
To experimentally evaluate our newly proposed
EMMA metric, and to quantitatively compare the
EMMA and MC metrics, we have evaluated re-
sults of 93 system-language pairs from Morpho
Challenge 2007, 2008, and 2009.1 The evaluation
comprised three algorithms by Bernhard (2007)
and Bernhard (2009), one algorithm by Can and
Manandhar (2009), the MC baseline algorithm
Morfessor by Creutz (2006), UNGRADE by Gole-
nia et al (2009), two algorithms by Lavallee and
Langlais (2009), one algorithm by Lignos et al
(2009), five ParaMor versions by Monson et al
(2008) and Monson et al (2009), three Promodes
versions by Spiegler et al (2009) and one al-
gorithm by Tchoukalov et al (2009). We ran
these algorithms over six data sets available from
the MC competition: Arabic (vowelized and non-
vowelized), English, Finnish, German, and Turk-
ish. We then scored the system outputs using both
EMMA and the MC metric against an answer key
provided by MC. In Sections 2 and 3.3 we have al-
ready commented on the linguistic characteristics
of both metrics. In this section, we concentrate on
their computational performance.
Both the EMMA and MC metrics are readily
computable: Both are freely available2 and they
each take less than two minutes to run on the av-
erage desktop machines we have used. In terms
of interpretability, EMMA not only returns the
performance as precision, recall and f-measure
as MC does, but also provides predicted analy-
ses where mapped morphemes are replaced by an-
swer key morphemes. This information is help-
ful when judging results qualitatively since it ex-
poses tangible algorithmic characteristics. In Ta-
ble 1 we present the algorithms with the highest
MC and EMMA scores for each language. For
all languages, the EMMA and MC metrics place
different algorithms highest. One reason for the
significantly different rankings that the two met-
rics provide may be the sampling of random pairs
that MC uses. Depending on the distribution of
predicted morphemes across words, the number
of random pairs, which is used for calculating the
precision, may vary. For instance, on vowelized
Arabic, Promodes 1 is evaluated over a sample
of 100 pairs where MC selected just 47 pairs for
ParaMor Mimic.
1Detailed results can be found in Spiegler (2010).
2EMMA may be downloaded from http://www.
cs.bris.ac.uk/Research/MachineLearning/
Morphology/Resources/
1034
Language Algorithm and year of MC evaluation metric EMMA evaluation metric
participation in MC Pr. Re. F1 Pr. Re. F1
Arabic (nv) Promodes 2 2009 0.7789 0.3980 0.5268 0.5356 0.2444 0.3356
Ungrade 2009 0.7971 0.1603 0.2670 0.7017 0.2490 0.3675
Arabic (vw) Promodes 2 2009 0.5946 0.6017 0.5982 0.4051 0.3199 0.3575
Promodes 1 2009 0.7381 0.3477 0.4727 0.5588 0.3281 0.4135
English Bernhard 1 2007 0.7850 0.5763 0.6647 0.8029 0.7460 0.7734
Lignos 2009 0.7446 0.4716 0.5775 0.9146 0.6747 0.7766
Finnish ParaMorPlusMorfessor 2008 0.5928 0.5675 0.5798 0.2271 0.3428 0.2732
Lavallee rali-cof 2009 0.6731 0.3563 0.4659 0.5061 0.4065 0.4509
German ParaMorPlusMorfessor 2008 0.5562 0.6077 0.5808 0.3633 0.4948 0.4190
Morfessor 2009 0.6528 0.3818 0.4818 0.7311 0.5556 0.6314
Turkish ParaMorPlusMorfessor 2008 0.6779 0.5732 0.6212 0.3476 0.4315 0.3851
Morfessor 2009 0.7894 0.3330 0.4684 0.5901 0.3703 0.4550
Table 1: Best performing algorithms with MC and EMMA evaluation metric.
Algorithm and year of MC evaluation metric EMMA evaluation metric
participation in MC Pr. Re. F1 Pr. Re. F1
Morfessor 2009 0.8143 0.2788 0.4154 0.4751 0.3472 0.4012
ParaMor 2008 0.4111 0.4337 0.4221 0.4322 0.3770 0.4027
ParaMorPlusMorfessor 2008 0.5928 0.5675 0.5798 0.2271 0.3428 0.2732
Paramor Morfessor Union 2009 0.4374 0.5676 0.4941 0.3878 0.4530 0.4178
Table 3: Gaming MC with ambiguity hijacking on Finnish.
Looking at any particular algorithm-language
pair, the EMMA and MC scores differ consider-
ably and respective raw scores are not directly
comparable. More interesting is the extent to
which both metrics correlate with real NL tasks.
Table 2 lists the Spearman rank correlation co-
efficient for algorithms from MC 2009 on En-
glish, Finnish and German comparing rankings of
f-measure results returned by either MC or EMMA
against rankings using the mean average preci-
sion (MAP) of an information retrieval (IR) task.3
All MAP scores are taken from Kurimo et al
(2009). Although both metrics positively correlate
with the IR results; EMMA?s correlation is clearly
stronger across all three languages.
To test the robustness of the EMMA and MC
metrics, we performed two experiments where we
intentionally attempt to game the metrics ? ambi-
guity hijacking and shared morpheme padding. In
both experiments, the MC metric showed vulnera-
bility. Ambiguity hijacking results for Finnish ap-
3Detailed results can be found in Spiegler (2010).
pear in Table 3, other languages perform similarly.
Using both metrics, we scored the Finnish analy-
ses that were proposed by a) the Morfessor algo-
rithm alone, b) ParaMor alone, and c) two ways
of combining ParaMor and Morfessor: ParaMor-
PlusMorfessor simply lists the ParaMor and Mor-
fessor analyses as alternatives ? as if each word
were ambiguous between a ParaMor and a Mor-
fessor analysis; ParaMorMorfessorUnion, on the
other hand, combines the morpheme boundary
predictions of ParaMor and Morfessor into a sin-
gle analysis. The ParaMorPlusMorfessor system
games the ambiguity mechanism of the MC met-
ric, achieving an f-measure higher than that of any
of the three other algorithms. EMMA, however,
correctly discovers that the analyses proposed by
ParaMorPlusMorfessor lie farther from an iso-
morphism to the the answer key than do the uni-
fied analyses of ParaMorMorfessorUnion.
In Table 4 we show a second way of gaming
the MC metric ? shared morpheme padding. We
add the same unique bogus morpheme to each
proposed analysis of every word for all systems.
1035
Language MC evaluation EMMA evaluationPrecision Recall F-measure Precision Recall F-measure
Arabic (nv) 0.91?0.02 10.83? 8.33 7.20?5.10 0.91?0.05 1.30?0.07 1.20?0.05
Arabic (vw) 0.85?0.04 11.17?8.81 7.13?5.23 0.89?0.07 1.21?0.06 1.12?0.05
English 0.36?0.08 2.02?0.66 0.63?0.10 0.73?0.15 1.05?0.08 0.86?0.12
Finnish 0.57?0.08 3.07?2.47 1.19?0.68 0.87?0.19 1.12?0.10 0.99?0.14
German 0.43?0.08 2.90?1.45 0.84?0.16 0.80?0.17 1.09?0.08 0.94?0.11
Turkish 0.58?0.09 2.95?1.65 1.19?0.37 0.85?0.08 1.07?0.04 0.97?0.05
Table 4: Gaming MC with shared morpheme padding: Average and standard deviations of the ratio of
padded to original scores.
Padding analyses with a shared morpheme signif-
icantly increases the recall scores of the MC met-
ric. We summarize our experimental results by
calculating, for each language-algorithm pair, the
ratio of the score for the padded analyses as com-
pared to that of the original, unpadded analyses.
Table 4 reports average and standard deviation of
the ratios across all systems for each language. In
Arabic (nv. and vw.), the recall increases by 10.83
and 11.17 times, which leads to an inflation of f-
measure by 7.20 and 7.13 times ? this is a direct
result of the soft nature of the MC isomorphism.
In contrast, EMMA?s recall scores increase much
less than MC?s do, and EMMA?s precision scores
decrease proportionately. A small change to the
set of proposed analyses does not lead to a huge
difference in f-measure ? characteristic of a more
robust metric.
5 Conclusion
This paper has proposed, EMMA, a novel evalua-
tion metric for the assessment of the quality of a
set of morphological analyses. EMMA?s:
1. Coverage of the major morphological phenom-
ena,
Correlation with IR
IR vs. MC IR vs. EMMA
English 0.466 0.608
Finnish 0.681 0.759
German 0.379 0.637
Table 2: Spearman rank correlation coefficient of
metrics vs. Information Retrieval (IR).
2. Correlation with performance on natural lan-
guage processing tasks, and
3. Computational robustness
all recommend the the metric as a strong and use-
ful measure ? particularly when evaluating un-
supervised morphology analysis systems which,
lacking access to labeled training data, are unin-
formed of the labeling standard used in the answer
key.
Acknowledgements
We would like to acknowledge various fruitful
discussions with Aram Harrow, Alex Popa, Tilo
Burghardt and Peter Flach. The work was par-
tially sponsored by EPSRC grant EP/E010857/1
Learning the morphology of complex synthetic
languages, as well as by NSF Grant #IIS-0811745
and DOD/NGIA grant #HM1582-08-1-0038.
References
Ar?soy, Ebru, Dog?an Can, S?dd?ka Parlak, Has?im Sak,
and Murat Sara?lar. 2009. Turkish Broadcast News
Transcription and Retrieval. IEEE Trans. on Audio,
Speech and Lang. Proc.
Beesley, Kenneth R. and Lauri Karttunen. 2003.
Finite State Morphology. University of Chicago
Press.
Berkelaar, Michel, Kjell Eikland, and Peter Note-
baert. 2004. Open source (mixed-integer) lin-
ear programming system, version 5.1.0.0. http:
//lpsolve. sourceforge.net/.
Bernhard, Delphine. 2007. Simple morpheme la-
belling in unsupervised morpheme analysis. Work-
ing Notes, CLEF 2007 Workshop.
1036
Bernhard, Delphine. 2009. Morphonet: Exploring the
use of community structure for unsupervised mor-
pheme analysis. Working Notes, CLEF 2009 Work-
shop.
Can, Burcu and Suresh Manandhar. 2009. Unsuper-
vised learning of morphology by using syntactic cat-
egories. Working Notes, CLEF 2009 Workshop.
Creutz, Mathias. 2006. Induction of the Morphol-
ogy of Natural Language: Unsupervised Morpheme
Segmentation with Application to Automatic Speech
Recognition. Ph.D. thesis, Helsinki University of
Technology, Espoo, Finland.
Goldsmith, John. 2001. Unsupervised learning of the
morphology of a natural language. Comp. Ling., 27.
Gol?nia, Bruno, Sebastian Spiegler, and Peter Flach.
2009. Ungrade: unsupervised graph decomposi-
tion. Working Notes, CLEF 2009 Workshop.
Hafer, M. A. and S. F. Weiss. 1974. Word segmenta-
tion by letter successor varieties. Inf. Storage and
Retrieval, 10.
Kurimo, Mikko, Mathias Creutz, Matti Varjokallio,
Ebru Arisoy, Murat Saraclar. 2006. Unsupervised
segmentation of words into morphemes - Morpho
Challenge 2005. Interspeech.
Kurimo, Mikko, Mathias Creutz, and Ville Turunen.
2007. Overview of morpho challenge in CLEF
2007. Working Notes, CLEF 2007 Workshop.
Kurimo, Mikko and Ville Turunen. 2008. Unsuper-
vised Morpheme Analysis Evaluation by IR exper-
iments ? Morpho Challenge 2008. Working Notes,
CLEF 2008 Workshop.
Kurimo, Mikko, Sami Virpioja, and Ville T. Turunen.
2009. Overview and results of morpho challenge
2009. Working Notes, CLEF 2009 Workshop.
Lavallee, Jean-Francois and Philippe Langlais. 2009.
Morphological Acquisition by Formal Analogy.
Working Notes, CLEF 2009 Workshop.
Lavie, Alon, Erik Peterson, Katharina Probst, Shuly
Wintner, Yaniv Eytani. 2004. Rapid Prototyp-
ing of a Transfer-based Hebrew-to-English Machine
Translation System. Proc. of TMI-2004.
Lignos, Constantine, Erwin Chan, Mitchell P. Mar-
cus, and Charles Yang. 2009. A rule-based unsu-
pervised morphology learning framework. Working
Notes, CLEF 2009 Workshop.
McNamee, Paul, Charles Nicholas, and James May-
field. 2008. Don?t Have a Stemmer? Be Un+con-
cern+ed Proc. of the 31st Anual International ACM
SIGIR Conference 20-24 July 2008.
Monson, Christian, Jaime Carbonell, Alon Lavie, and
Lori Levin. 2008. Paramor and morpho challenge
2008. Working Notes, CLEF 2008 Workshop.
Monson, Christian, Kristy Hollingshead, and Brian
Roark. 2009. Probabilistic paramor. Working
Notes, CLEF 2009 Workshop.
Oflazer, Kemal, and I?lknur Durgar El-Kahlout. 2007.
Different Representational Units in English-to-
Turkish Statistical Machine Translation. Proc. of
Statistical Machine Translation Workshop at ACL
2007.
Poon, Hoifung, Colin Cherry and Kristina Toutanova
2009. Unsupervised Morphological Segmentation
with Log-Linear Models. Proc. of ACL.
Roark, Brian and Richard Sproat. 2007. Computa-
tional Approaches to Morphology and Syntax. Ox-
ford Univ. Press.
Schone, Patrick and Daniel Jurafsky. 2001. Know-
lege-free induction of inflectional morphologies.
Proc. of NAACL-2001.
Snover, Matthew G., Gaja E. Jarosz and Michael R.
Brent. 2002. Unsupervised Learning of Morphol-
ogy Using a Novel Directed Search Algorithm: Tak-
ing the First Step. Proc. of the ACL-02 SIGPHON
Workshop.
Snyder, Benjamin and Regina Barzilay. 2008. Unsu-
pervised Multilingual Learning for Morphological
Segmentation. Proc. of ACL-08: HLT.
Spencer, Andrew and Arnold M. Zwicky, editors.
2001. The Handbook of Morphology. Wiley-Black-
well.
Spiegler, Sebastian, Bruno Gol?nia, and Peter A.
Flach. 2009. Promodes: A probabilistic genera-
tive model for word decomposition. Working Notes,
CLEF 2009 Workshop.
Spiegler, Sebastian. 2010. EMMA: A Novel Metric for
Morphological Analysis - Experimental Results in
Detail. Computer Science Department, University
of Bristol, U.K.
Tchoukalov, Tzvetan, Christian Monson, and Brian
Roark. 2009. Multiple sequence alignment for
morphology induction. Working Notes, CLEF 2009
Workshop.
Wicentowski, Richard 2002. Modeling and Learn-
ing Multilingual Inflectional Morphology in a Min-
imally Supervised Framework. Ph.D. thesis, The
Johns Hopkins University, Baltimore, Maryland,
U.S.A.
1037
Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 375?383,
Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational Linguistics
Enhanced word decomposition by calibrating the decision threshold of
probabilistic models and using a model ensemble
Sebastian Spiegler
Intelligent Systems Laboratory,
University of Bristol, U.K.
spiegler@cs.bris.ac.uk
Peter A. Flach
Intelligent Systems Laboratory,
University of Bristol, U.K.
peter.flach@bristol.ac.uk
Abstract
This paper demonstrates that the use of
ensemble methods and carefully calibrat-
ing the decision threshold can signifi-
cantly improve the performance of ma-
chine learning methods for morphologi-
cal word decomposition. We employ two
algorithms which come from a family of
generative probabilistic models. The mod-
els consider segment boundaries as hidden
variables and include probabilities for let-
ter transitions within segments. The ad-
vantage of this model family is that it can
learn from small datasets and easily gen-
eralises to larger datasets. The first algo-
rithm PROMODES, which participated in
the Morpho Challenge 2009 (an interna-
tional competition for unsupervised mor-
phological analysis) employs a lower or-
der model whereas the second algorithm
PROMODES-H is a novel development of
the first using a higher order model. We
present the mathematical description for
both algorithms, conduct experiments on
the morphologically rich language Zulu
and compare characteristics of both algo-
rithms based on the experimental results.
1 Introduction
Words are often considered as the smallest unit
of a language when examining the grammatical
structure or the meaning of sentences, referred to
as syntax and semantics, however, words them-
selves possess an internal structure denominated
by the term word morphology. It is worthwhile
studying this internal structure since a language
description using its morphological formation is
more compact and complete than listing all pos-
sible words. This study is called morpholog-
ical analysis. According to Goldsmith (2009)
four tasks are assigned to morphological analy-
sis: word decomposition into morphemes, build-
ing morpheme dictionaries, defining morphosyn-
tactical rules which state how morphemes can
be combined to valid words and defining mor-
phophonological rules that specify phonological
changes morphemes undergo when they are com-
bined to words. Results of morphological analy-
sis are applied in speech synthesis (Sproat, 1996)
and recognition (Hirsimaki et al, 2006), machine
translation (Amtrup, 2003) and information re-
trieval (Kettunen, 2009).
1.1 Background
In the past years, there has been a lot of inter-
est and activity in the development of algorithms
for morphological analysis. All these approaches
have in common that they build a morphologi-
cal model which is then applied to analyse words.
Models are constructed using rule-based meth-
ods (Mooney and Califf, 1996; Muggleton and
Bain, 1999), connectionist methods (Rumelhart
and McClelland, 1986; Gasser, 1994) or statisti-
cal or probabilistic methods (Harris, 1955; Hafer
and Weiss, 1974). Another way of classifying ap-
proaches is based on the learning aspect during
the construction of the morphological model. If
the data for training the model has the same struc-
ture as the desired output of the morphological
analysis, in other words, if a morphological model
is learnt from labelled data, the algorithm is clas-
sified under supervised learning. An example for
a supervised algorithm is given by Oflazer et al
(2001). If the input data has no information to-
wards the desired output of the analysis, the algo-
rithm uses unsupervised learning. Unsupervised
algorithms for morphological analysis are Lin-
guistica (Goldsmith, 2001), Morfessor (Creutz,
2006) and Paramor (Monson, 2008). Minimally or
semi-supervised algorithms are provided with par-
tial information during the learning process. This
375
has been done, for instance, by Shalonova et al
(2009) who provided stems in addition to a word
list in order to find multiple pre- and suffixes. A
comparison of different levels of supervision for
morphology learning on Zulu has been carried out
by Spiegler et al (2008).
Our two algorithms, PROMODES and
PROMODES-H, perform word decomposi-
tion and are based on probabilistic methods
by incorporating a probabilistic generative
model.1 Their parameters can be estimated
from either labelled data, using maximum like-
lihood estimates, or from unlabelled data by
expectation maximization2 which makes them
either supervised or unsupervised algorithms.
The purpose of this paper is an analysis of the
underlying probabilistic models and the types of
errors committed by each one. Furthermore, it is
investigated how the decision threshold can be cal-
ibrated and a model ensemble is tested.
The remainder is structured as follows. In Sec-
tion 2 we introduce the probabilistic generative
process and show in Sections 2.1 and 2.2 how
we incorporate this process in PROMODES and
PROMODES-H. We start our experiments with ex-
amining the learning behaviour of the algorithms
in 3.1. Subsequently, we perform a position-wise
comparison of predictions in 3.2, show how we
find a better decision threshold for placing mor-
pheme boundaries in 3.3 and combine both algo-
rithms using a model ensemble to leverage indi-
vidual strengths in 3.4. In 3.5 we examine how
the single algorithms contribute to the result of the
ensemble. In Section 4 we will compare our ap-
proaches to related work and in Section 5 we will
draw our conclusions.
2 Probabilistic generative model
Intuitively, we could say that our models describe
the process of word generation from the left to the
right by alternately using two dice, the first for de-
ciding whether to place a morpheme boundary in
the current word position and the second to get a
corresponding letter transition. We are trying to
reverse this process in order to find the underlying
sequence of tosses which determine the morpheme
boundaries. We are applying the notion of a prob-
1PROMODES stands for PRObabilistic MOdel for different
DEgrees of Supervision. The H of PROMODES-H refers to
Higher order.
2In (Spiegler et al, 2009; Spiegler et al, 2010a) we have
presented an unsupervised version of PROMODES.
abilistic generative process consisting of words as
observed variables X and their hidden segmenta-
tion as latent variables Y . If a generative model is
fully parameterised it can be reversed to find the
underlying word decomposition by forming the
conditional probability distribution Pr(Y |X).
Let us first define the model-independent com-
ponents. A given word w j ?W with 1? j ? |W |
consists of n letters and has m = n?1 positions
for inserting boundaries. A word?s segmentation is
depicted as a boundary vector b j = (b j1, . . . ,b jm)
consisting of boundary values b ji ? {0,1} with
1? i? m which disclose whether or not a bound-
ary is placed in position i. A letter l j,i-1 precedes
the position i in w j and a letter l ji follows it. Both
letters l j,i-1 and l ji are part of an alphabet. Fur-
thermore, we introduce a letter transition t ji which
goes from l j,i-1 to l ji.
2.1 PROMODES
PROMODES is based on a zero-order model for
boundaries b ji and on a first-order model for letter
transitions t ji. It describes a word?s segmentation
by its morpheme boundaries and resulting letter
transitions within morphemes. A boundary vector
b j is found by evaluating each position i with
argmax
b ji
Pr(b ji|t ji) = (1)
argmax
b ji
Pr(b ji)Pr(t ji|b ji) .
The first component of the equation above is
the probability distribution over non-/boundaries
Pr(b ji). We assume that a boundary in i is in-
serted independently from other boundaries (zero-
order) and the graphemic representation of the
word, however, is conditioned on the length of
the word m j which means that the probability
distribution is in fact Pr(b ji|m j). We guarantee
?1r=0 Pr(b ji=r|m j) = 1. To simplify the notation
in later explanations, we will refer to Pr(b ji|m j)
as Pr(b ji).
The second component is the letter transition
probability distribution Pr(t ji|b ji). We suppose a
first-order Markov chain consisting of transitions
t ji from letter l j,i-1 ? AB to letter l ji ? A where A
is a regular letter alphabet and AB=A?{B} in-
cludes B as an abstract morpheme start symbol
which can occur in l j,i-1. For instance, the suf-
fix ?s? of the verb form gets, marking 3rd person
singular, would be modelled as B? s whereas a
morpheme internal transition could be g? e. We
376
guarantee ?l ji?A Pr(t ji|b ji)=1 with t ji being a tran-
sition from a certain l j,i?1 ? AB to l ji. The ad-
vantage of the model is that instead of evaluating
an exponential number of possible segmentations
(2m), the best segmentation b?j=(b
?
j1, . . . ,b
?
jm) is
found with 2m position-wise evaluations using
b?ji = argmax
b ji
Pr(b ji|t ji) (2)
=
?
?????
?????
1, if Pr(b ji=1)Pr(t ji|b ji=1)
> Pr(b ji=0)Pr(t ji|b ji=0)
0, otherwise .
The simplifying assumptions made, however,
reduce the expressive power of the model by not
allowing any dependencies on preceding bound-
aries or letters. This can lead to over-segmentation
and therefore influences the performance of PRO-
MODES. For this reason, we have extended the
model which led to PROMODES-H, a higher-order
probabilistic model.
2.2 PROMODES-H
In contrast to the original PROMODES model, we
also consider the boundary value b j,i-1 and mod-
ify our transition assumptions for PROMODES-
H in such a way that the new algorithm applies
a first-order boundary model and a second-order
transition model. A transition t ji is now defined
as a transition from an abstract symbol in l j,i-1 ?
{N ,B} to a letter in l ji ? A. The abstract sym-
bol is N or B depending on whether b ji is 0 or 1.
This holds equivalently for letter transitions t j,i-1.
The suffix of our previous example gets would be
modelled N ? t?B? s.
Our boundary vector b j is then constructed from
argmax
b ji
Pr(b ji|t ji, t j,i-1,b j,i-1) = (3)
argmax
b ji
Pr(b ji|b j,i-1)Pr(t ji|b ji, t j,i-1,b j,i-1) .
The first component, the probability distribution
over non-/boundaries Pr(b ji|b j,i-1), satisfies
?1r=0 Pr(b ji=r|b j,i-1)=1 with b j,i-1,b ji ? {0,1}.
As for PROMODES, Pr(b ji|b j,i-1) is short-
hand for Pr(b ji|b j,i-1,m j). The second
component, the letter transition proba-
bility distribution Pr(t ji|b ji,b j,i-1), fulfils
?l ji?A Pr(t ji|b ji, t j,i-1,b j,i-1)=1 with t ji being
a transition from a certain l j,i?1 ? AB to l ji. Once
again, we find the word?s best segmentation b?j in
2m evaluations with
b?ji = argmax
b ji
Pr(b ji|t ji, t j,i-1,b j,i-1) = (4)
?
??
??
1, if Pr(b ji=1|b j,i-1)Pr(t ji|b ji=1, t j,i-1,b j,i-1)
> Pr(b ji=0|b j,i-1)Pr(t ji|b ji=0, t j,i-1,b j,i-1)
0, otherwise .
We will show in the experimental results that in-
creasing the memory of the algorithm by looking
at b j,i?1 leads to a better performance.
3 Experiments and Results
In the Morpho Challenge 2009, PROMODES
achieved competitive results on Finnish, Turkish,
English and German ? and scored highest on non-
vowelized and vowelized Arabic compared to 9
other algorithms (Kurimo et al, 2009). For the
experiments described below, we chose the South
African language Zulu since our research work
mainly aims at creating morphological resources
for under-resourced indigenous languages. Zulu
is an agglutinative language with a complex mor-
phology where multiple prefixes and suffixes con-
tribute to a word?s meaning. Nevertheless, it
seems that segment boundaries are more likely in
certain word positions. The PROMODES family
harnesses this characteristic in combination with
describing morphemes by letter transitions. From
the Ukwabelana corpus (Spiegler et al, 2010b) we
sampled 2500 Zulu words with a single segmenta-
tion each.
3.1 Learning with increasing experience
In our first experiment we applied 10-fold cross-
validation on datasets ranging from 500 to 2500
words with the goal of measuring how the learning
improves with increasing experience in terms of
training set size. We want to remind the reader that
our two algorithms are aimed at small datasets.
We randomly split each dataset into 10 subsets
where each subset was a test set and the corre-
sponding 9 remaining sets were merged to a train-
ing set. We kept the labels of the training set
to determine model parameters through maximum
likelihood estimates and applied each model to
the test set from which we had removed the an-
swer keys. We compared results on the test set
against the ground truth by counting true positive
(TP), false positive (FP), true negative (TN) and
377
false negative (FN) morpheme boundary predic-
tions. Counts were summarised using precision3,
recall4 and f-measure5, as shown in Table 1.
Data Precision Recall F-measure
500 0.7127?0.0418 0.3500?0.0272 0.4687?0.0284
1000 0.7435?0.0556 0.3350?0.0197 0.4614?0.0250
1500 0.7460?0.0529 0.3160?0.0150 0.4435?0.0206
2000 0.7504?0.0235 0.3068?0.0141 0.4354?0.0168
2500 0.7557?0.0356 0.3045?0.0138 0.4337?0.0163
(a) PROMODES
Data Precision Recall F-measure
500 0.6983?0.0511 0.4938?0.0404 0.5776?0.0395
1000 0.6865?0.0298 0.5177?0.0177 0.5901?0.0205
1500 0.6952?0.0308 0.5376?0.0197 0.6058?0.0173
2000 0.7008?0.0140 0.5316?0.0146 0.6044?0.0110
2500 0.6941?0.0184 0.5396?0.0218 0.6068?0.0151
(b) PROMODES-H
Table 1: 10-fold cross-validation on Zulu.
For PROMODES we can see in Table 1a that
the precision increases slightly from 0.7127 to
0.7557 whereas the recall decreases from 0.3500
to 0.3045 going from dataset size 500 to 2500.
This suggests that to some extent fewer morpheme
boundaries are discovered but the ones which are
found are more likely to be correct. We believe
that this effect is caused by the limited memory
of the model which uses order zero for the occur-
rence of a boundary and order one for letter tran-
sitions. It seems that the model gets quickly sat-
urated in terms of incorporating new information
and therefore precision and recall do not drasti-
cally change for increasing dataset sizes. In Ta-
ble 1b we show results for PROMODES-H. Across
the datasets precision stays comparatively con-
stant around a mean of 0.6949 whereas the recall
increases from 0.4938 to 0.5396. Compared to
PROMODES we observe an increase in recall be-
tween 0.1438 and 0.2351 at a cost of a decrease in
precision between 0.0144 and 0.0616.
Since both algorithms show different behaviour
with increasing experience and PROMODES-H
yields a higher f-measure across all datasets, we
will investigate in the next experiments how these
differences manifest themselves at the boundary
level.
3 precision = T PT P+FP .
4recall = T PT P+FN .
5 f -measure = 2?precision?recallprecision+recall .
TNPH	 ?=	 ?0.8726	 ?
TNP	 ?	 ?	 ?=	 ?0.9472	 ?
	 ?
TPPH=	 ?0.5394	 ?
TPP	 ?	 ?	 ?=	 ?0.3045	 ?
	 ?
FPPH=	 ?0.1274	 ?
FPP	 ?	 ?	 ?=	 ?0.0528	 ?
	 ?
	 ?FNPH	 ?=	 ?0.4606	 ?
	 ?FNP	 ?	 ?	 ?	 ?=	 ?0.6955	 ?
	 ?
0.3109	 ? 0.7889	 ?
0.2111	 ?0.6891	 ?
+	 ?0.0819	 ?
(net)	 ?
+	 ?0.0486	 ?
(net)	 ?
0.5698	 ?0.8828	 ?
0.4302	 ?0.1172	 ?
	 ?
Figure 1: Contingency table for PROMODES [grey
with subscript P] and PROMODES-H [black with
subscript PH] results including gross and net
changes of PROMODES-H.
3.2 Position-wise comparison of algorithmic
predictions
In the second experiment, we investigated which
aspects of PROMODES-H in comparison to PRO-
MODES led to the above described differences in
performance. For this reason we broke down
the summary measures of precision and recall
into their original components: true/false positive
(TP/FP) and negative (TN/FN) counts presented in
the 2? 2 contingency table of Figure 1. For gen-
eral evidence, we averaged across all experiments
using relative frequencies. Note that the relative
frequencies of positives (TP + FN) and negatives
(TN + FP) each sum to one.
The goal was to find out how predictions
in each word position changed when applying
PROMODES-H instead of PROMODES. This
would show where the algorithms agree and
where they disagree. PROMODES classifies non-
boundaries in 0.9472 of the times correctly as TN
and in 0.0528 of the times falsely as boundaries
(FP). The algorithm correctly labels 0.3045 of the
positions as boundaries (TP) and 0.6955 falsely as
non-boundaries (FN). We can see that PROMODES
follows a rather conservative approach.
When applying PROMODES-H, the majority of
the FP?s are turned into non-boundaries, how-
ever, a slightly higher number of previously cor-
rectly labelled non-boundaries are turned into
false boundaries. The net change is a 0.0486 in-
crease in FP?s which is the reason for the decrease
in precision. On the other side, more false non-
378
boundaries (FN) are turned into boundaries than
in the opposite direction with a net increase of
0.0819 of correct boundaries which led to the in-
creased recall. Since the deduction of precision
is less than the increase of recall, a better over-all
performance of PROMODES-H is achieved.
In summary, PROMODES predicts more accu-
rately non-boundaries whereas PROMODES-H is
better at finding morpheme boundaries. So far we
have based our decision for placing a boundary in
a certain word position on Equation 2 and 4 as-
suming that P(b ji=1| . . .)> P(b ji=0| . . .)6 gives the
best result. However, if the underlying distribu-
tion for boundaries given the evidence is skewed,
it might be possible to improve results by introduc-
ing a certain decision threshold for inserting mor-
pheme boundaries. We will put this idea to the test
in the following section.
3.3 Calibration of the decision threshold
For the third experiment we slightly changed our
experimental setup. Instead of dividing datasets
during 10-fold cross-validation into training and
test subsets with the ratio of 9:1 we randomly split
the data into training, validation and test sets with
the ratio of 8:1:1. We then run our experiments
and measured contingency table counts.
Rather than placing a boundary if
P(b ji=1| . . .) > P(b ji=0| . . .) which corresponds
to P(b ji=1| . . .) > 0.50 we introduced a decision
threshold P(b ji=1| . . .) > h with 0? h? 1. This
is based on the assumption that the underlying
distribution P(b ji| . . .) might be skewed and an
optimal decision can be achieved at a different
threshold. The optimal threshold was sought on
the validation set and evaluated on the test set.
An overview over the validation and test results
is given in Table 2. We want to point out that the
threshold which yields the best f-measure result
on the validation set returns almost the same
result on the separate test set for both algorithms
which suggests the existence of a general optimal
threshold.
Since this experiment provided us with a set of
data points where the recall varied monotonically
with the threshold and the precision changed ac-
cordingly, we reverted to precision-recall curves
(PR curves) from machine learning. Following
Davis and Goadrich (2006) the algorithmic perfor-
6Based on Equation 2 and 4 we use the notation P(b ji| . . .)
if we do not want to specify the algorithm.
mance can be analysed more informatively using
these kinds of curves. The PR curve is plotted with
recall on the x-axis and precision on the y-axis for
increasing thresholds h. The PR curves for PRO-
MODES and PROMODES-H are shown in Figure
2 on the validation set from which we learnt our
optimal thresholds h?. Points were connected for
readability only ? points on the PR curve cannot
be interpolated linearly.
In addition to the PR curves, we plotted isomet-
rics for corresponding f-measure values which are
defined as precision= f -measure?recall2recall? f -measure and are hy-
perboles. For increasing f-measure values the iso-
metrics are moving further to the top-right corner
of the plot. For a threshold of h = 0.50 (marked
by ?3?) PROMODES-H has a better performance
than PROMODES. Nevertheless, across the entire
PR curve none of the algorithms dominates. One
curve would dominate another if all data points
of the dominated curve were beneath or equal
to the dominating one. PROMODES has its opti-
mal threshold at h? = 0.36 and PROMODES-H at
h? = 0.37 where PROMODES has a slightly higher
f-measure than PROMODES-H. The points of op-
timal f-measure performance are marked with ?4?
on the PR curve.
Prec. Recall F-meas.
PROMODES validation (h=0.50) 0.7522 0.3087 0.4378
PROMODES test (h=0.50) 0.7540 0.3084 0.4378
PROMODES validation (h?=0.36) 0.5857 0.7824 0.6699
PROMODES test (h?=0.36) 0.5869 0.7803 0.6699
PROMODES-H validation (h=0.50) 0.6983 0.5333 0.6047
PROMODES-H test (h=0.50) 0.6960 0.5319 0.6030
PROMODES-H validation (h?=0.37) 0.5848 0.7491 0.6568
PROMODES-H test (h?=0.37) 0.5857 0.7491 0.6574
Table 2: PROMODES and PROMODES-H on vali-
dation and test set.
Summarizing, we have shown that both algo-
rithms commit different errors at the word posi-
tion level whereas PROMODES is better in pre-
dicting non-boundaries and PROMODES-H gives
better results for morpheme boundaries at the de-
fault threshold of h = 0.50. In this section, we
demonstrated that across different decision thresh-
olds h for P(b ji=1| . . .) > h none of algorithms
dominates the other one, and at the optimal thresh-
old PROMODES achieves a slightly higher perfor-
mance than PROMODES-H. The question which
arises is whether we can combine PROMODES and
PROMODES-H in an ensemble that leverages indi-
vidual strengths of both.
379
0.4 0.5 0.6 0.7 0.8 0.9 1
0.4
0.5
0.6
0.7
0.8
0.9
1
Recall
Pre
cis
ion
 
 
Promodes
Promodes?H
Promodes?E
F?measure isometrics
Default result
Optimal result (h*)
Figure 2: Precision-recall curves for algorithms on validation set.
3.4 A model ensemble to leverage individual
strengths
A model ensemble is a set of individually trained
classifiers whose predictions are combined when
classifying new instances (Opitz and Maclin,
1999). The idea is that by combining PROMODES
and PROMODES-H, we would be able to avoid cer-
tain errors each model commits by consulting the
other model as well. We introduce PROMODES-E
as the ensemble of PROMODES and PROMODES-
H. PROMODES-E accesses the individual proba-
bilities Pr(b ji=1| . . .) and simply averages them:
Pr(b ji=1|t ji)+Pr(b ji=1|t ji,b j,i-1, t j,i-1)
2
> h .
As before, we used the default threshold
h = 0.50 and found the calibrated threshold
h? = 0.38, marked with ?3? and ?4? in Figure 2
and shown in Table 3. The calibrated threshold
improves the f-measure over both PROMODES and
PROMODES-H.
Prec. Recall F-meas.
PROMODES-E validation (h=0.50) 0.8445 0.4328 0.5723
PROMODES-E test (h=0.50) 0.8438 0.4352 0.5742
PROMODES-E validation (h?=0.38) 0.6354 0.7625 0.6931
PROMODES-E test (h?=0.38) 0.6350 0.7620 0.6927
Table 3: PROMODES-E on validation and test set.
The optimal solution applying h? = 0.38 is
more balanced between precision and recall and
boosted the original result by 0.1185 on the test
set. Compared to its components PROMODES and
PROMODES-H the f-measure increased by 0.0228
and 0.0353 on the test set.
In short, we have shown that by combining
PROMODES and PROMODES-H and finding the
optimal threshold, the ensemble PROMODES-E
gives better results than the individual models
themselves and therefore manages to leverage the
individual strengths of both to a certain extend.
However, can we pinpoint the exact contribution
of each individual algorithm to the improved re-
sult? We try to find an answer to this question in
the analysis of the subsequent section.
3.5 Analysis of calibrated algorithms and
their model ensemble
For the entire dataset of 2500 words, we have
examined boundary predictions dependent on the
relative word position. In Figure 3 and 4 we have
plotted the absolute counts of correct boundaries
(TP) and non-boundaries (TN) which PROMODES
predicted but not PROMODES-H, and vice versa,
as continuous lines. We furthermore provided the
number of individual predictions which were ulti-
mately adopted by PROMODES-E in the ensemble
as dashed lines.
In Figure 3a we can see for the default thresh-
old that PROMODES performs better in predicting
non-boundaries in the middle and the end of the
word in comparison to PROMODES-H. Figure 3b
380
shows the statistics for correctly predicted bound-
aries. Here, PROMODES-H outperforms PRO-
MODES in predicting correct boundaries across the
entire word length. After the calibration, shown
in Figure 4a, PROMODES-H improves the correct
prediction of non-boundaries at the beginning of
the word whereas PROMODES performs better at
the end. For the boundary prediction in Figure 4b
the signal disappears after calibration.
Concluding, it appears that our test language
Zulu has certain features which are modelled best
with either a lower or higher-order model. There-
fore, the ensemble leveraged strengths of both al-
gorithms which led to a better overall performance
with a calibrated threshold.
4 Related work
We have presented two probabilistic genera-
tive models for word decomposition, PROMODES
and PROMODES-H. Another generative model
for morphological analysis has been described
by Snover and Brent (2001) and Snover et al
(2002), however, they were interested in finding
paradigms as sets of mutual exclusive operations
on a word form whereas we are describing a gener-
ative process using morpheme boundaries and re-
sulting letter transitions.
Moreover, our probabilistic models seem to re-
semble Hidden Markov Models (HMMs) by hav-
ing certain states and transitions. The main differ-
ence is that we have dependencies between states
as well as between emissions whereas in HMMs
emissions only depend on the underlying state.
Combining different morphological analysers
has been performed, for example, by Atwell and
Roberts (2006) and Spiegler et al (2009). Their
approaches, though, used majority vote to decide
whether a morpheme boundary is inserted in a cer-
tain word position or not. The algorithms them-
selves were treated as black-boxes.
Monson et al (2009) described an indirect
approach to probabilistically combine ParaMor
(Monson, 2008) and Morfessor (Creutz, 2006).
They used a natural language tagger which was
trained on the output of ParaMor and Morfes-
sor. The goal was to mimic each algorithm since
ParaMor is rule-based and there is no access to
Morfessor?s internally used probabilities. The tag-
ger would then return a probability for starting a
new morpheme in a certain position based on the
original algorithm. These probabilities in com-
bination with a threshold, learnt on a different
dataset, were used to merge word analyses. In
contrast, our ensemble algorithm PROMODES-E
directly accesses the probabilistic framework of
each algorithm and combines them based on an
optimal threshold learnt on a validation set.
5 Conclusions
We have presented a method to learn a cali-
brated decision threshold from a validation set and
demonstrated that ensemble methods in connec-
tion with calibrated decision thresholds can give
better results than the individual models them-
selves. We introduced two algorithms for word de-
composition which are based on generative prob-
abilistic models. The models consider segment
boundaries as hidden variables and include prob-
abilities for letter transitions within segments.
PROMODES contains a lower order model whereas
PROMODES-H is a novel development of PRO-
MODES with a higher order model. For both
algorithms, we defined the mathematical model
and performed experiments on language data of
the morphologically complex language Zulu. We
compared the performance on increasing train-
ing set sizes and analysed for each word position
whether their boundary prediction agreed or dis-
agreed. We found out that PROMODES was bet-
ter in predicting non-boundaries and PROMODES-
H gave better results for morpheme boundaries at
a default decision threshold. At an optimal de-
cision threshold, however, both yielded a simi-
lar f-measure result. We then performed a fur-
ther analysis based on relative word positions and
found out that the calibrated PROMODES-H pre-
dicted non-boundaries better for initial word posi-
tions whereas the calibrated PROMODES for mid-
and final word positions. For boundaries, the cali-
brated algorithms had a similar behaviour. Subse-
quently, we showed that a model ensemble of both
algorithms in conjunction with finding an optimal
threshold exceeded the performance of the single
algorithms at their individually optimal threshold.
Acknowledgements
We would like to thank Narayanan Edakunni and
Bruno Gole?nia for discussions concerning this pa-
per as well as the anonymous reviewers for their
comments. The research described was sponsored
by EPSRC grant EP/E010857/1 Learning the mor-
phology of complex synthetic languages.
381
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 10
100
200
300
400
500
600
700
800
Relative word position
Abs
olut
e tru
e ne
gati
ves
 (TN
)
Performance on non?boundaries, default threshold
 
 Promodes (unique TN)Promodes?H (unique TN)Promodes and Promodes?E (unique TN)Promodes?H and Promodes?E (unique TN)
(a) True negatives, default
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 10
100
200
300
400
500
600
700
800
Relative word position
Abs
olut
e tru
e po
sitiv
es (
TP)
Performance on boundaries, default threshold
 
 Promodes (unique TP)Promodes?H (unique TP)Promodes and Promodes?E (unique TP)Promodes?H and Promodes?E (unique TP)
(b) True positives, default
Figure 3: Analysis of results using default threshold.
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 10
100
200
300
400
500
600
700
800
Relative word position
Abs
olut
e tru
e ne
gati
ves
 (TN
)
Performance on non?boundaries, calibrated threshold
 
 Promodes (unique TN)Promodes?H (unique TN)Promodes and Promodes?E (unique TN)Promodes?H and Promodes?E (unique TN)
(a) True negatives, calibrated
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 10
100
200
300
400
500
600
700
800
Relative word position
Abs
olut
e tru
e po
sitiv
es (
TP)
Performance on boundaries, calibrated threshold
 
 Promodes (unique TP)Promodes?H (unique TP)Promodes and Promodes?E (unique TP)Promodes?H and Promodes?E (unique TP)
(b) True positives, calibrated
Figure 4: Analysis of results using calibrated threshold.
382
References
J. W. Amtrup. 2003. Morphology in machine trans-
lation systems: Efficient integration of finite state
transducers and feature structure descriptions. Ma-
chine Translation, 18(3):217?238.
E. Atwell and A. Roberts. 2006. Combinatory hy-
brid elementary analysis of text (CHEAT). Proceed-
ings of the PASCAL Challenges Workshop on Un-
supervised Segmentation of Words into Morphemes,
Venice, Italy.
M. Creutz. 2006. Induction of the Morphology of Nat-
ural Language: Unsupervised Morpheme Segmen-
tation with Application to Automatic Speech Recog-
nition. Ph.D. thesis, Helsinki University of Technol-
ogy, Espoo, Finland.
J. Davis and M. Goadrich. 2006. The relationship
between precision-recall and ROC curves. Interna-
tional Conference on Machine Learning, Pittsburgh,
PA, 233?240.
M. Gasser. 1994. Modularity in a connectionist
model of morphology acquisition. Proceedings of
the 15th conference on Computational linguistics,
1:214?220.
J. Goldsmith. 2001. Unsupervised learning of the mor-
phology of a natural language. Computational Lin-
guistics, 27:153?198.
J. Goldsmith. 2009. The Handbook of Computational
Linguistics, chapter Segmentation and morphology.
Blackwell.
M. A. Hafer and S. F. Weiss. 1974. Word segmenta-
tion by letter successor varieties. Information Stor-
age and Retrieval, 10:371?385.
Z. S. Harris. 1955. From phoneme to morpheme. Lan-
guage, 31(2):190?222.
T. Hirsimaki, M. Creutz, V. Siivola, M. Kurimo, S. Vir-
pioja, and J. Pylkkonen. 2006. Unlimited vocabu-
lary speech recognition with morph language mod-
els applied to Finnish. Computer Speech And Lan-
guage, 20(4):515?541.
K. Kettunen. 2009. Reductive and generative ap-
proaches to management of morphological variation
of keywords in monolingual information retrieval:
An overview. Journal of Documentation, 65:267 ?
290.
M. Kurimo, S. Virpioja, and V. T. Turunen. 2009.
Overview and results of Morpho Challenge 2009.
Working notes for the CLEF 2009 Workshop, Corfu,
Greece.
C. Monson, K. Hollingshead, and B. Roark. 2009.
Probabilistic ParaMor. Working notes for the CLEF
2009 Workshop, Corfu, Greece.
C. Monson. 2008. ParaMor: From Paradigm
Structure To Natural Language Morphology Induc-
tion. Ph.D. thesis, Language Technologies Institute,
School of Computer Science, Carnegie Mellon Uni-
versity, Pittsburgh, PA, USA.
R. J. Mooney and M. E. Califf. 1996. Learning the
past tense of English verbs using inductive logic pro-
gramming. Symbolic, Connectionist, and Statistical
Approaches to Learning for Natural Language Pro-
cessing, 370?384.
S. Muggleton and M. Bain. 1999. Analogical predic-
tion. Inductive Logic Programming: 9th Interna-
tional Workshop, ILP-99, Bled, Slovenia, 234.
K. Oflazer, S. Nirenburg, and M. McShane. 2001.
Bootstrapping morphological analyzers by combin-
ing human elicitation and machine learning. Com-
putational. Linguistics, 27(1):59?85.
D. Opitz and R. Maclin. 1999. Popular ensemble
methods: An empirical study. Journal of Artificial
Intelligence Research, 11:169?198.
D. E. Rumelhart and J. L. McClelland. 1986. On
learning the past tenses of English verbs. MIT
Press, Cambridge, MA, USA.
K. Shalonova, B. Gole?nia, and P. A. Flach. 2009. To-
wards learning morphology for under-resourced fu-
sional and agglutinating languages. IEEE Transac-
tions on Audio, Speech, and Language Processing,
17(5):956965.
M. G. Snover and M. R. Brent. 2001. A Bayesian
model for morpheme and paradigm identification.
Proceedings of the 39th Annual Meeting on Asso-
ciation for Computational Linguistics, 490 ? 498.
M. G. Snover, G. E. Jarosz, and M. R. Brent. 2002.
Unsupervised learning of morphology using a novel
directed search algorithm: Taking the first step. Pro-
ceedings of the ACL-02 workshop on Morphological
and phonological learning, 6:11?20.
S. Spiegler, B. Gole?nia, K. Shalonova, P. A. Flach, and
R. Tucker. 2008. Learning the morphology of Zulu
with different degrees of supervision. IEEE Work-
shop on Spoken Language Technology.
S. Spiegler, B. Gole?nia, and P. A. Flach. 2009. Pro-
modes: A probabilistic generative model for word
decomposition. Working Notes for the CLEF 2009
Workshop, Corfu, Greece.
S. Spiegler, B. Gole?nia, and P. A. Flach. 2010a. Un-
supervised word decomposition with the Promodes
algorithm. In Multilingual Information Access Eval-
uation Vol. I, CLEF 2009, Corfu, Greece, Lecture
Notes in Computer Science, Springer.
S. Spiegler, A. v. d. Spuy, and P. A. Flach. 2010b. Uk-
wabelana - An open-source morphological Zulu cor-
pus. in review.
R. Sproat. 1996. Multilingual text analysis for text-to-
speech synthesis. Nat. Lang. Eng., 2(4):369?380.
383
