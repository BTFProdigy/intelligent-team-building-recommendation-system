Proceedings of the NAACL-HLT 2007 Doctoral Consortium, pages 17?20,
Rochester, April 2007. c?2007 Association for Computational Linguistics
Analysis of Summarization Evaluation Experiments
Marie-Jos?e Goulet
CIRAL, Department of Linguistics
Laval University, Quebec City
G1K 7P4, Canada
marie-josee.goulet.1@ulaval.ca
Abstract
The goals of my dissertation are: 1) to pro-
pose a French terminology for the presen-
tation of evaluation results of automatic
summaries, 2) to identify and describe
experimental variables in evaluations of
automatic summaries, 3) to highlight the
most common tendencies, inconsistencies
and methodological problems in summa-
rization evaluation experiments, and 4)
to make recommendations for the presen-
tation of evaluation results of automatic
summaries. In this paper, I focus on the
second objective, i.e. identifying and de-
scribing variables in summarization eval-
uation experiments.
1 Introduction
The general subject of my dissertation is summa-
rization evaluation. As stated in my thesis proposal,
my work aims at four goals: 1) proposing a French
terminology for the presentation of evaluation re-
sults of automatic summaries, 2) identifying and de-
scribing experimental variables in evaluations of au-
tomatic summaries, 3) highlighting the most com-
mon tendencies, inconsistencies and methodological
problems in summarization evaluations, and 4) mak-
ing recommendations for the presentation of evalua-
tion results of automatic summaries. In this paper, I
will focus on the second objective.
My ultimate goal is to provide the francophone
scientific community with guidelines for the evalua-
tion of automatic summaries of French texts. Evalu-
ation campaigns for NLP applications already exist
in France, the EVALDA project1. However, no cam-
paign has yet been launched for French automatic
summaries, like Document Understanding Confer-
ences for English texts or Text Summarization Chal-
lenge for Japanese texts. I hope that such a campaign
will begin in the near future and that my thesis work
may then serve as a guide for its design.
2 Completed Work
I collected 22 scientific papers about summarization
evaluation, published between 1961 and 2005. Each
paper has been the subject of an in-depth analysis,
where every detail regarding the evaluation has been
carefully noted, yielding a quasi-monstrous amount
of experimental variables. These variables have
been classified into four categories: 1) information
about source texts, 2) information about automatic
summaries being evaluated, 3) information about
other summaries used in the evaluation process, and
4) information about evaluation methods and crite-
ria. At the current stage of my research work, the
first three types of variables have been analyzed and
will be presented here.
2.1 Variables about source texts
Four types of information about source texts
emerged from the analysis: 1) the number of source
texts, 2) the length, 3) the type of text, and 4) the lan-
guage. First, the number of source texts is an indica-
tor of the significance of the evaluation. In my study,
1http://www.elda.org/rubrique25.html
17
all the evaluations used less than 100 source texts,
except for Mani and Bloedorn (1999) (300 source
texts), Brandow et al (1995) (250 source texts), Ku-
piec et al (1995) (188 source texts) and Teufel and
Moens (1999) (123 source texts).
Secondly, regarding source text length, it is ex-
pressed in different ways from one evaluation to an-
other. For example, Edmundson (1969) gives the
number of words, Klavans et al (1998) give the
number of sentences and Minel et al (1997) give
the number of pages. In some papers, the length
of the shortest and of the longest text is provided
(Marcu, 1999) while in others it is the average num-
ber of words, sentences or pages that is given (Teufel
and Moens, 1999). Obviously, it would be wise to
standardize the way source texts length is given in
evaluation experiments.
In my corpora, there are three main types of
source texts: 1) scientific papers, 2) technical re-
ports, and 3) newspapers. Also, Minel et al (1997)
used book extracts and memos, and Farzindar and
Lapalme (2005) used judgments of the Canadian
federal court. All evaluations used only one type of
source texts, except for Kupiec et al (1995) and for
Minel et al (1997).
Finally, the majority of the evaluations used Eng-
lish texts. Some authors used French texts (Minel et
al., 1997; Ch?ar et al, 2004), Korean texts (Myaeng
and Jang, 1999) or Japanese texts (Nanba and Oku-
mura, 2000).
2.2 Variables about automatic summaries
being evaluated
In this section, I describe variables about automatic
summaries being evaluated. The variables have been
classified into six categories: 1) the total number
of automatic summaries evaluated, 2) the number
of automatic summaries produced per source text,
3) if they are multiple document summaries, 4) the
length, 5) if they are extracts or abstracts, and 6)
their purpose.
First, concerning the total number of automatic
summaries, Brandow et al (1995), Mani and Bloe-
dorn (1999), Kupiec et al (1995), Salton et al
(1997) and Teufel and Moens (1999) evaluated re-
spectively 750, 300, 188, 150 and 123 automatic
summaries. All the other studies for which this in-
formation is given evaluated less than 100 automatic
summaries. It may appear redundant to give the
number of source texts and the number of automatic
summaries in an evaluation, but sometimes more
than one automatic summary per source text may
have been produced. This is the case in Brandow
et al (1995) and Barzilay and Elhadad (1999) where
automatic summaries of different lengths have been
evaluated.
Automatic summaries can either be produced
from one text or more than one text. In my cor-
pora, only Mani and Bloedorn (1999) and Ch?ar et
al. (2004) evaluated multiple document summaries.
As for source texts, automatic summary length is
expressed in different ways from one evaluation to
another. Moreover, it is not always expressed in the
same way than source text length, which is inconsis-
tent.
On a different note, most experiments evaluated
extracts, except for Maybury (1999) and Saggion
and Lapalme (2002) who evaluated abstracts, re-
flecting the predominance of systems producing ex-
tracts in the domain of summarization. Extracts are
summaries produced by extracting the most impor-
tant segments from texts while abstracts are the re-
sult of a comprehension process and text generation.
Most extracts evaluated are composed of sentences,
except for Salton et al (1997) and Ch?ar et al (2004)
where they are respectively composed of paragraphs
and passages. The type of automatic summaries is
crucial information because it normally influences
the choice of the evaluation method and criteria. In-
deed, we do not evaluate extracts and abstracts in the
same way since they are not produced in the same
way. Also, their purposes generally differ, which can
also influence the choice of the evaluation method
and criteria.
Last, some papers contain the specific purpose of
automatic summaries, not only if they are indica-
tive or informative, which is interesting because it
can sometimes explain the choice of the evaluation
method. Only 9 experiments out of 22 give this in-
formation in my corpora.
2.3 Variables about other summaries used in
the evaluation process
One of the most common evaluation methods con-
sists of comparing automatic summaries with other
summaries. During my analysis, I identified seven
18
types of information about these other summaries:
1) the total number of other summaries, 2) the type
of summaries, 3) the length, 4) the total number of
human summarizers, 5) the number of human sum-
marizers per source text, 6) the instructions given to
the human summarizers, and 7) the human summa-
rizers? profile.
The number of other summaries does not neces-
sarily correspond to the number of automatic sum-
maries evaluated, depending on many factors: the
use of other summaries of different types or different
lengths, the number of persons producing the other
summaries, the number of other systems producing
the other summaries, and so on.
There are two general types of summaries used
for comparison with the automatic summaries be-
ing evaluated. First, gold standard summaries (or
target summaries) can be author summaries, pro-
fessional summaries or summaries produced specif-
ically for the evaluation. Second, baseline sum-
maries are generally produced by extracting random
sentences from source texts or produced by another
system.
In my corpora, gold standard summaries are of-
ten produced specifically for the evaluation. In most
cases, they are produced by manually extracting the
most important passages, sentences or paragraphs,
allowing automatic comparison between automatic
summaries and gold standard summaries.
On the other hand, many evaluations used base-
line summaries. For example, Barzilay and Elhadad
(1999) used summaries produced by Word AutoSum-
marize, Hovy and Lin (1999) used summaries pro-
duced by automatically extracting random sentences
from source texts. In Brandow et al (1995), Kupiec
et al (1995) and Teufel and Moens (1999), baseline
summaries were produced by automatically extract-
ing sentences at the beginning of the texts, and in
Myaeng and Jang (1999) by extracting the first five
sentences of the conclusion.
Logically, the length of the summaries used for
the comparison should be equivalent to the length of
the automatic summaries being evaluated. If auto-
matic summaries of different lengths are evaluated,
there should be corresponding baselines and/or gold
standard summaries for each length, unless the goal
of the evaluation is to determine if the length plays a
role in the quality of automatic summaries.
Many of the evaluations analyzed do not indicate
the number of human summarizers participating in
the production of gold standard summaries. A few of
them specify the total number of persons involved,
but not the number for each source text. This is an
important variable because summarizing, either by
extracting or abstracting, is a subjective task. The
more people involved in the summarization of one
text, the more we can consider the final summary
to be reliable. From the pieces of information I was
able to gather, the number of summarizers per source
text ranges from 1 to 13 in my corpora.
In analyzing the evaluations of my corpora, I re-
alized that some authors gave clear instructions to
the human summarizers, for example Edmundson
(1969). In other cases, authors asked the summariz-
ers to extract the most ?important? sentences. The
term ?important? includes other terms like represen-
tative, informative, relevant, and eligible. It is rarely
mentioned however if those words were explained to
the summarizers.
I also noticed that some evaluations used people
coming from different backgrounds, for example in
Salton et al (1997), while others used more homo-
geneous groups, for example in Barzilay and El-
hadad (1999) and Kupiec et al (1995).
3 Future Directions
In the next couple of months, I plan to analyze evalu-
ation methods identified in my corpora, for example
comparing automatic summaries with gold standard
or baseline summaries, and asking judges to give
their opinion on the quality of automatic summaries.
I will also describe evaluation criteria used to as-
sess the quality of the automatic summaries, for ex-
ample informativeness and readability. Next, I will
make recommendations for the presentation of sum-
marization evaluation results, based on the knowl-
edge acquired from my analysis of 22 scientific pa-
pers, and from previous evaluation campaigns.
4 Conclusion
In this paper, I described variables about source
texts, about automatic summaries being evaluated
and about other summaries used in summarization
evaluation experiments. These variables provide
important information for the understanding of the
19
evaluation results presented in a scientific paper. My
analysis is based on 22 scientific papers on summa-
rization evaluation, which is to my knowledge the
largest study on the variables found in evaluation ex-
periments. This constitutes a notable contribution in
the domain of summarization. In another paper (in
French) to appear, I propose a French terminology
for the presentation of evaluation results in the do-
main of summarization, which is also a major con-
tribution.
To conclude, the analysis presented in this pa-
per gave an overview of summarization evaluation
habits since 1961. Also, it showed that there is
no common agreement as to how evaluation results
should be presented in a scientific paper about auto-
matic summaries.
Acknowledgements
I would like to thank the SSHRC and the FQRSC
for granting me doctoral scholarships. I would also
like to thank Jo?l Bourgeoys, Neil Cruickshank,
Lorraine Couture and the anonymous reviewer for
their useful comments.
References
R. Barzilay and M. Elhadad. 1999. Using lexical chains
for text summarization. In I. Mani and M. T. May-
bury, editors, Advances in Automatic Text Summariza-
tion, pages 111?121, Cambridge, Massachusetts. MIT
Press.
R. Brandow, K. Mitze, and L. Rau. 1995. Auto-
matic condensation of electronic publications by sen-
tence selection. Information Processing Management,
31(5):675?685.
S. L. Ch?ar, O. Ferret, and C. Fluhr. 2004. Filtrage pour
la construction de r?sum?s multidocuments guid?e
par un profil. Traitement automatique des langues,
45(1):65?93.
H. P. Edmundson. 1969. New methods in automatic ab-
stracting. Journal of the Association for Computing
Machinery, 16(2):264?285.
A. Farzindar and G. Lapalme. 2005. Production automa-
tique de r?sum? de textes juridiques : ?valuation de
qualit? et d?acceptabilit?. In TALN, pages 183?192,
Dourdan.
E. Hovy and C.-Y. Lin. 1999. Automated text sum-
marization in SUMMARIST. In I. Mani and M. T.
Maybury, editors, Advances in Automatic Text Sum-
marization, pages 81?94, Cambridge, Massachusetts.
MIT Press.
J. L. Klavans, K. R. McKeown, M.-Y. Kan, and S. Lee.
1998. Resources for the evaluation of summarization
techniques. In Antonio Zampolli, editor, LREC, pages
899?902, Granada, Spain.
J. Kupiec, J. Pedersen, and F. Chen. 1995. A trainable
document summarizer. In SIGIR, pages 68?73, Seat-
tle.
I. Mani and E. Bloedorn. 1999. Summarizing simi-
larities and differences among related documents. In
I. Mani and M. T. Maybury, editors, Advances in Au-
tomatic Text Summarization, pages 357?379, Cam-
bridge, Massachusetts. MIT Press.
D. Marcu. 1999. Discourse trees are good indicators
of importance in text. In I. Mani and M. T. May-
bury, editors, Advances in Automatic Text Summariza-
tion, pages 123?136, Cambridge, Massachusetts. MIT
Press.
M. Maybury. 1999. Generating summaries from event
data. In I. Mani and M. T. Maybury, editors, Ad-
vances in Automatic Text Summarization, pages 265?
281, Cambridge, Massachusetts. MIT Press.
J.-L. Minel, S. Nugier, and G. Piat. 1997. How to ap-
preciate the quality of automatic text summarization?
Examples of FAN and MLUCE protocols and their re-
sults on SERAPHIN. In EACL, pages 25?31, Madrid.
S. H. Myaeng and D.-H. Jang. 1999. Development
and evaluation of a statistically-based document sum-
marization system. In I. Mani and M. T. Maybury,
editors, Advances in Automatic Text Summarization,
pages 61?70, Cambridge, Massachusetts. MIT Press.
H. Nanba and M. Okumura. 2000. Producing more
readable extracts by revising them. In 18th Inter-
national Conference on Computational Linguistics,
pages 1071?1075, Saarbrucker.
H. Saggion and G. Lapalme. 2002. Generat-
ing indicative-informative summaries with SumUM.
Computational Linguistics, 28(4):497?526.
G. Salton, A. Singhal, M. Mitra, and C. Buckley. 1997.
Automatic text structuring and summarization. Infor-
mation Processing and Management, 33(2):193?207.
S. Teufel and M. Moens. 1999. Argumentative clas-
sification of extracted sentences as a first step to-
wards flexible abstracting. In I. Mani and M. T. May-
bury, editors, Advances in Automatic Text Summariza-
tion, pages 155?171, Cambridge, Massachusetts. MIT
Press.
20
Proceedings of the EACL 2012 Workshop on Computational Linguistics and Writing, pages 39?47,
Avignon, France, April 23, 2012. c?2012 Association for Computational Linguistics
Focus Group on Computer Tools Used for Professional Writing and 
Preliminary Evaluation of LinguisTech 
 
 
 
Marie-Jos?e Goulet Annie Duplessis 
University of Quebec in Outaouais 
Gatineau, Quebec 
J8X 3X7, Canada 
University of Quebec in Outaouais 
Gatineau, Quebec  
J8X 3X7, Canada 
marie-josee.goulet@uqo.ca dupa08@uqo.ca 
 
 
 
 
 
 
Abstract 
This paper focuses on computer writing tools 
used during the production of documents in a 
professional setting. Computer writing tools 
include language technologies, for example 
electronic dictionaries and text correction 
software, as well as information and 
communication technologies, for example 
collaborative platforms and search engines. As 
we will see, professional writing has become 
an entirely computerised activity. First, we 
report on a focus group with professional 
writers, during which they discussed their 
experience using computer tools to write 
documents. We will describe their practices, 
point out the most important problems they 
encounter, and analyse their needs. Second, we 
describe LinguisTech, a reference web site for 
language professionals (translators, writers, 
language instructors, etc.) that was launched in 
Canada in September, 2011. We comment on a 
preliminary evaluation that we conducted to 
determine if this new platform meets 
professional writers? needs.    
1 Introduction 
This paper focuses on computer writing tools 
used during the production of documents, be they 
letters, newsletters, policies, guidelines, releases 
or annual reports, in a professional setting, what 
we call professional writing (Beaudet, 1998). 
The importance of professional writing in private 
and public organisations is undeniable as written 
documents serve as communication between 
employees, support in decision making and 
organisational memory.  
Computer tools can be used in a variety of 
writing situations, such as learning how to write 
in schools (Kuhn et al, 2009), learning a second 
language (Milton and Cheng, 2010), and helping 
people with cognitive, visual or motor disabilities 
(Majaranta and Kari-Jouko, 2002). However, our 
knowledge and understanding of computer tools 
used by professional writers are somewhat 
limited. Which tools are used by professional 
writers? Are these tools meeting their needs? Do 
writers know what these tools can do? Kavanagh 
(1999) is one of the few authors who investigated 
such questions. In his detailed analysis of 
Microsoft Word, he demonstrated that the text 
processor mostly meets formatting and editing 
needs, and that it cannot, by far, support every 
step of the professional writing process. 
Kavanagh?s research was quite a revelation at the 
time. However, many years have passed, and we 
have seen few studies on that subject since then.  
Writers have seen their profession evolve 
over the last 20 years. First, the massive use of 
personal computers has transformed writing 
practices as writers now have to cope with 
machines (computers, printers, scanners) and 
computer tools (text processors, search engines, 
electronic messaging systems, electronic 
dictionaries, spelling checkers, and collaborative 
platforms), whose number increases each year. 
Surely, this computer revolution has simplified 
professional writers? work as computer tools can 
help render more efficient document formatting, 
proofreading, collaborative writing, and content 
reusing, to name just a few examples. In that 
perspective, computer tools should help 
professional writers produce more documents. 
However, the number of documents that need to 
be produced in today?s society, especially in the 
service sector (Nakbi, 2002), is such that 
productivity?s expectations towards writers are 
39
great. And, as we will discuss in this paper, 
computer tools are not always well-adapted to 
professional writing.  
Also, the webification of human knowledge is 
creating new expectations in professional 
writers? skills. While only a few years ago, 
documents written according to printing 
standards were scanned and published on the 
web as images, an increasing number of 
documents are now produced according to 
hypertext standards. Therefore, professional 
writers have to master new specialised skills, for 
example in hypertext information organisation, 
document design, and computer science 
(Kavanagh, 2006).  
The goal of this paper is twofold. First, it 
reports on an exploratory study on computer 
tools used for the production of written 
documents in the workplace (see Section 2). This 
research consisted in asking questions to 
professional writers during a focus group. We 
will present a summary of those discussions and 
analyse professional writers? needs in terms of 
computer writing tools. Second, the paper 
describes and analyses LinguisTech, a reference 
web site for language professionals that was 
launched in Canada in September, 2011 (see 
Section 3). This preliminary evaluation will 
allow us to determine if this new platform 
actually meets professional writers? needs.    
2 Exploratory Study on Computer 
Tools Used by Professional Writers 
2.1  Focus Group 
A focus group was conducted with volunteers. 
This method is well suited for exploring subjects, 
gathering opinions on a specific topic, and asking 
questions to participants when more details are 
needed. Participants were met together and could 
interact with each other. Eight francophone 
professional writers working in Canada?s capital 
region (Gatineau-Ottawa) participated in our 
study1. Our principal selection criteria was that 
the candidates? main task consisted in writing 
practical texts or, at least, that this be the most 
important part of their job. The participants had 
between 3 and 12 years of experience in 
professional writing and came from different 
sectors: government and parapublic, enterprise, 
                                                          
1 As Geoffrion (1998) explains, the focus group calls for a 
small number of participants, preferably between six and 
twelve. 
non-profit organisation, professional association 
and print media.  
Prior to the focus group, it was assumed that 
professional writing had become an entirely 
computerised activity. The main objective of the 
study reported in this paper was to gather 
information on professional writers? experience 
with computer tools. We also wanted to explore 
their thoughts on how these tools could better 
support professional writing in general. Here is a 
sample of the questions that we asked them. 
Those questions were addressed to the group, not 
to individuals.  
? In your every day job as a professional 
writer, what computer tools do you use? 
? For what specific task of the writing 
process do you use those tools?  
? Do you exclusively use computer tools or 
also printed material? 
? Do you think that using computer tools 
improve your productivity? 
? Do you have any problems using those 
computer tools? 
? How, in your opinion, could computer 
tools better help professional writers?  
? What other computer tools would you 
like to use?  
 
We organised two meetings of one and a half 
hour each, for a total of three hours. The 
meetings were recorded and transcribed, 
rendering a 27,000-word text. This text was 
analysed by identifying all relevant information 
on professional writers? experience with 
computer tools, a step we repeated until we could 
not find any new information.  
During the focus group, we used the general 
expression computer tool to refer to any tool 
used to accomplish a task related to professional 
writing. But as we will see later, this concept 
includes two types of computer tools: language 
technologies, for example electronic dictionaries 
and text correction software, and information and 
communication technologies, for example 
collaborative platforms and search engines.  
2.2 Analytical Framework 
In order to present results from the focus group, 
we need a standard procedural model of the 
writing process. We will use Clerc?s model 
(1998, 2000), which is based on the actual 
professional writers? practice. This model 
includes five steps: assignment analysis, 
information research, information structuring, 
40
writing and revising. Table 1 gives an overview 
of the tasks accomplished at every step of the 
writing process. 
 
Step 1: 
Assignment 
analysis 
? Meet supervisor or client 
? Define mandate 
? Establish writing strategy 
and calendar 
? Write a proposal, if 
necessary 
Step 2: 
Information 
research 
? Establish a research 
strategy 
? Collect information 
Step 3: 
Information 
structuring 
? Select information 
? Group information 
? Determine information 
ordering 
? Find the main thread 
Step 4: 
Writing 
? Put plan into words 
? Write headings 
Step 5: 
Revising 
? Evaluate information 
? Evaluate structure 
? Evaluate writing 
 
Table 1. Tasks done at different steps of the writing 
process in a professional setting (Clerc, 2000) 
 
Although this model is in general suited for 
the purpose of our research, we needed to make 
some adjustments. First, since none of the 
participants seem to be using computer tools 
during the assignment analysis (in fact, no one 
brought this step up during the discussion), we 
excluded this step from our analysis. Second, 
?Information research? was renamed 
?Information research and processing?, which 
better represents the fact that writers have to 
process (even summarily) the information during 
the research in order to evaluate information 
relevance. Third, we added the document 
transmission task but, instead of creating a new 
distinct step, we included it in the last one of the 
model. This step is thus renamed ?Revising and 
document transmission?.  Table 2 shows a 
summary of the modified analytical framework.  
 
Step 1: Information research and processing 
Step 2: Information structuring 
Step 3: Writing 
Step 4: Revising and document transmission 
 
Table 2. Modified analytical framework (adapted 
from Clerc, 2000)  
 
2.3 Results 
Results will be presented according to the four 
steps of our analytical framework. 
Information Research and Processing 
Morizio (2006) defines information research as 
an operation consisting of matching an 
information need and a document. In the context 
of our study, the professional writer formulates 
an information need after receiving an 
assignment from his superior or customer. As 
expected, most of the documents consulted by 
our professional writers are in electronic format: 
files either saved on a drive or available on a 
network (intranet or internet). Professional 
writers seem to take advantage of what the web 
has to offer, consulting newspapers, annual 
reports, web pages and social networks. 
Although the content of some of these web 
documents may be questioned (the content of a 
blog for example), they are still considered as 
?interesting? sources, which indicates the 
professional writers? interest and adaptability 
towards new forms of electronic information. 
However, the participants criticised the 
immensity of the web, which keeps growing day 
after day. If we add the fact that many documents 
found on the web are duplicated, and that the 
same document can be found in different format 
(HTML, PDF), this can really slow down the 
information gathering because the writer has to 
verify if it is in fact the same document. They do 
not blame the web for offering too much 
information, but they wish that this information 
be better organised and easier to find.  
As we said earlier, professional writers 
summarily analyse documents during the 
information gathering, and they save relevant 
documents in personal folders. We identified two 
strategies used by writers to process the 
information at this stage of the writing project2. 
One of these strategies consists in searching for 
information within documents using the search 
engine available in conventional operating 
systems. Professional writers experience 
considerable difficulties with this method: 
? They have to try many synonyms and 
lexical variants as search terms, in order 
to retrieve all relevant documents.  
? Having copied many versions of a same 
document in different folders, processing 
the results can be a lot of work because 
                                                          
2 Not all participants necessarily use both strategies. 
41
the operating system considers copies of 
the same document as distinct 
documents.      
? Still according to the participants of our 
study, search engines from conventional 
operating systems produce a lot of noise.  
 
Those remarks are not original, but they 
suggest that professional writers know which 
computer tools, or which aspects of a particular 
tool, can slow down their productivity. 
Conventional operating systems are ubiquitous in 
organisations and are relatively user-friendly, so 
we can easily understand why our participants 
use them to track documents, but it appears that 
they are not optimal for professional writers, for 
whom information research and processing can 
be impressive in terms of workload. Of course, 
all writers may not classify their documents in 
folders astutely, a step that would allow for more 
specific searches afterwards in individual folders. 
Second, some writers may not use the advanced 
functions of the search engine correctly. It would 
be interesting in further research to study writers? 
behaviour in-vivo, allowing for more specific 
recommendations for document and information 
management. Also, other information 
management solutions should be tested in regard 
to professional writers? needs. Could more 
specialised tools improve their effectiveness, or 
at least their satisfaction?  
The participants described a second strategy 
for processing information, which consists in 
copying and pasting parts of a source document 
(web page, email, PDF document, etc.) in a text 
file. More specifically, they create a thematic file 
in which they paste relevant parts of web 
documents, making sure that they note the 
source. As we know from other computational 
linguistics related research such as automatic 
summarisation by sentence extraction, this 
operation causes considerable information loss, 
making it difficult to interpret the information 
correctly when writing. In fact, the participants 
admitted that they often have to go back to the 
original document in order to understand the 
parts they had copied. In other words, 
professional writers need a better strategy to 
process textual electronic information. 
The copy-and-paste method is also 
problematic for at least one other aspect: the 
manipulation of the target document. 
Professional writers of our study explained 
having problems organising the parts they copy 
in the target document, especially when those 
files contain a considerable amount of pages. 
Therefore, we understand why some writers 
chose to create a home-made database (using 
Excel or Access) in which they record the name 
of the documents they consulted and the topic(s) 
associated to those documents. This information 
can then be automatically sorted, for example, by 
location, topic, or name. 
Information Structuring 
The last task before the writing step is 
information structuring. This is where the writer 
groups chunks of information and plan the 
ordering. This plan is generally written using a 
word processor, and is sometimes created 
directly in the document used to write the text. 
Surprisingly, none of the interviewed writers use 
tools such as mind mapping at this stage of the 
writing process.  
Writing 
When it comes to actually writing, participants 
use the traditional language technologies 
associated with the production of professional 
writing, such as text correction software (Word, 
Antidote 3 ), electronic dictionaries (Le Petit 
Robert, Le Grand Robert et Collins, Word 
Reference) and terminology data banks 
(Termium Plus, Le Grand dictionnaire 
terminologique). Professional writers use more 
than one language technology at once. Overall, 
they find these tools useful, an assessment that 
should reassure the language industry, which has 
put its focus on developing and promoting this 
type of tools in the past years. 
Revising and Document Transmission 
During the revising step, professional writers use 
Word?s advanced functions (track changes and 
add comments) and the other language 
technologies that we already mentioned in the 
previous section. Regarding document 
transmission (or sharing), professional writers 
favour web-based file hosting services, even 
though some of them still prefer emails. We also 
include groupware like Google Documents in 
this category. As showed in Adler et al (2006), 
group writing is a growing practice in 
professional settings, and writers in our study 
corroborate this evolution.  
                                                          
3 As our participants write French documents, most 
language-specific tools that they use are for French textual 
data. 
42
2.4 General Conclusions 
Table 3 presents a summary of computer tools 
used for professional writing by the participants 
of the focus group. 
 
Steps of the 
writing process 
Computer tools 
used by writers 
Information 
research 
and processing 
? Web search engine 
? Email 
? Operating system 
? Office tools (text 
processor, database) 
Information 
structuring 
? Text processor 
Writing 
? Text processor 
? Text correction 
software 
? Dictionaries 
? Terminology data 
banks 
Revising and 
document 
transmission 
? Text processor 
(including advanced 
functionalities) 
? Text correction 
software 
? Dictionaries 
? Terminology data 
banks 
? File hosting service 
? Collaborative 
platform 
? Email 
 
Table 3. Summary of computer tools used by 
professional writers of the focus group 
 
Our study allows us to draw general 
conclusions on the actual practices of Canadian 
professional writers, or even those to come, 
regarding their use of computer tools. First, it 
confirms that professional writing has become an 
entirely computerised activity. In fact, except for 
the assignment analysis, step that our participants 
did not address, all tasks related to writing are 
accomplished using computer tools. While some 
tasks could still be done by hand, for example 
reading a document selected during information 
research or editing a colleague?s document 
working in the same physical environment, this 
is not what professional writers choose to do. 
Only one participant (out of eight) mentioned 
using printed dictionaries, but never exclusively. 
We also know, from this study, that 
professional writers, at least those we 
interviewed, would welcome the integration of 
additional computer tools to their workstation. In 
particular, they expressed the need for better 
information and document management 
software. This assessment is quite surprising 
considering the fact that, as Clerc (2000) notes, 
the information research can represent more than 
half of the total time dedicated to one writing 
project. However, although professional writers 
would like to use other computer tools in their 
work, they are afraid that they would not know 
how to use them. 
Professional writers also wish to see other 
specialised tools developed. For example, the 
participants would use a writing memory system 
in contexts where they reuse content such as 
producing an annual report. This idea is certainly 
not out of reach. As a matter of fact, Allen 
(1999) suggested that the concept of translation 
memory be adapted to writing technical 
documents in a controlled language. A 
preliminary inventory confirms that such tools 
still exist (for example, Author-it, Congree), but 
we will have to verify to which extent they could 
be adapted to writing practical texts in general-
purpose language.  
Professional writers have developed specific 
computerised strategies for each task related to 
written document production, using the computer 
tools that were available to them. Considering all 
the problems mentioned by the participants, it 
seems that this piece-by-piece process came to 
saturation. From information research to 
document transmission, the steps leading to the 
production of professional documents overlap, 
which results in the simultaneous presence of 
many computer tools on the writers? workstation. 
At the least, the workstation presents a word 
processor (text that is being written, writing plan 
and other documents that need to be consulted), a 
web navigator (with many open windows or 
tabs), a messaging system, and language 
technologies.  This clutter of the workstation is 
not without consequences. Professional writers 
admitted that the numerous computer 
manipulations that are necessary to navigate 
from one tool to the other slow down their work, 
which goes against basic ergonomics.  In 
addition, some writers suggested that the 
multiplication of computer tools was interfering 
with their creativity. Table 4 summarises the 
most important problems reported by 
43
professional writers who use computer tools to 
produce documents. 
 
1. Conventional operating systems are not 
effective to retrieve information or documents 
on personal computers. 
2. Access to more specialised tools such as 
writing memory systems is difficult. 
3. Desktop is cluttered up with too many 
computer tools and windows. 
4. Training on computer tools is needed. 
 
Table 4. Most important problems reported by 
professional writers who use computer tools to 
produce documents  
 
In the next section, we will describe 
LinguisTech, a new web site dedicated to 
language professionals (translators, writers, 
language instructors, etc.), the first of its kind in 
Canada.  We conducted a preliminary evaluation 
in order to determine how useful LinguisTech 
could be especially for professional writers. 
3 Preliminary Evaluation of 
LinguisTech 
3.1 Description of LinguisTech 
LinguisTech4 was launched in September, 2011. 
It is developed by the Language Technologies 
Research Centre (LTRC) and is funded by the 
Government of Canada?s Canadian Language 
Sector Enhancement Program. LTRC describes 
LinguisTech as a toolbox for language 
professionals offering language technologies in 
both Canadian official languages (French and 
English), but also as a documentation and 
training centre, as well as a virtual community. 
We will comment more specifically on the 
Language Technologies Toolbox and on the 
Training Center, the two most developed features 
as of today. 
LinguisTech?s toolbox offers a broad 
selection of computer tools intended for language 
professionals (41 in total). The toolbox includes 
an inventory of free online tools useful for 
language-related tasks, as well as a ?virtual? 
desktop with other information and language 
technologies. Computer tools included on this 
virtual desktop can be very expensive, but at the 
moment, they are available for free to Canadians 
who register and further obtain a password. 
Users can connect from any computer (Mac or 
                                                          
4 www.linguistech.ca 
PC), anywhere in the world, and access their own 
virtual computer. LinguisTech is also a 
documentation and training centre where 
language professionals can find, among other 
resources, tutorials and exercises on how to use 
computer tools (29 in total) 5.  
Table 5 presents a complete list of computer 
tools, tutorials and exercises presently available 
in LinguisTech. Tool names in italics indicate 
free online tools. Tools names in grey lines 
indicate that a tutorial or an exercise is available, 
but not the tool itself.   
 
Tutorial or exercise available? 
Office tools 
Adobe Reader X yes  
Microsoft Office yes  
Open Office no  
PDF Creator no  
Windows yes  
Search engines 
Google yes  
Library databases (uOttawa) yes  
ORBIS (uOttawa) yes  
Text correction software 
Antidote yes  
PerfectIT no 
WhiteSmoke no  
Text analysis software 
KwicKwic no  
Concept mapping tools 
CmapTools yes 
Microsoft Office Concept Mapping yes  
Text aligners 
YouAlign yes  
Concordancers 
Le Migou yes  
TextSTAT yes  
TradooIT  no  
TransSearch yes  
WeBiText  yes  
WordSmith Tools yes  
Dictionaries and terminology tools  
Diatopix yes  
DiCoInfo yes  
FranceTerme no  
Health Multi-Terminology Portal no  
Inspiration no  
InterActive Terminology for Europe yes 
                                                          
5 Tutorials and exercises are developed by the Collection of 
Electronic Resources in Translation Technologies (CERTT) 
team at the University of Ottawa (see Bowker and 
Marshman, 2011). 
44
Le grand dictionnaire terminologique yes 
lexicool.com no 
SDL MultiTerm 2009 no 
SDL International (Trados 2007) no 
SynchroTerm yes  
Terminaute no  
TerminoWeb no  
TERMIUM Plus yes  
TermoStat Web yes  
UNTerm  no  
Wiktionary yes  
WordNet yes  
Translation and localization tools 
CatsCradle yes  
Fusion Translate  no  
Linguee no  
LogiTerm  yes  
MultiTrans yes  
Online machine translation yes  
Reverso Promt yes  
SDL Passolo 2009 no  
SDL Trados Studio 2009 no  
Wordfast no  
Other resources   
Language Portal of Canada no  
Pidgin no  
 
Table 5. Computer tools, tutorials and exercises 
available in LinguisTech 
3.2 Analysis 
We address two research questions: How does 
LinguisTech respond to professional writers? 
needs in terms of computer tools and training 
material? Can LinguisTech solve any of the 
problems mentioned by our participants? This 
preliminary evaluation of LinguisTech will be 
presented according to the four steps of our 
analytical framework. The analysis is based on 
the information obtained from the focus group 
discussions (see Subsection 2.3). It is important 
to note that LinguisTech did not exist at the time 
of the focus group, which was in March, 2011, so 
the participants could not have used it prior to the 
focus group or mentioned it during the 
discussions.  
Information Research and Processing 
During information research and processing, 
professional writers use many computer tools: 
web search engines, email services, operating 
systems, text processors, and databases. As we 
can see in Table 5, LinguisTech offers many 
useful tools in regard to this stage of the writing 
process, for example Microsoft Office and 
Windows, many of which are accompanied by a 
tutorial or an exercise. Training material is also 
available for other tools required at this stage, for 
example Google search engine. 
However, LinguisTech does not offer any 
tool, tutorial or exercise related to email, a 
service largely used by our participants to gather 
information from colleagues in the workplace. A 
forum where language professionals can share 
ideas on their profession has been recently 
created in LinguisTech. This forum will probably 
help develop a virtual community, but training 
material on how to effectively use this computer 
tool will be helpful. 
Also, our participants stated that conventional 
operating systems are not effective to retrieve 
information or documents on personal 
computers, and that more effective information 
retrieval systems are needed. At the moment, 
LinguisTech does not provide any solution to this 
problem. 
 
Information Structuring 
During information structuring, our participants 
use a text processor, which is covered in 
LinguisTech, both in terms of availability and 
training.  
Writing 
While putting ideas into words, professional 
writers use a text processor, text correction 
software, some dictionaries and terminology data 
banks. LinguisTech offers many computer tools 
related to those tasks, with tutorials and 
exercises. 
One of the problems mentioned by our 
participants was the difficulty to have access to 
specialised tools such as writing memory 
systems.  As of today, LinguisTech does not 
include any specialised tools of that kind, or 
training material on such tools. 
Revising and Document Transmission 
During the last steps of the writing process, 
professional writers use two additional tools: file 
hosting services (for example Dropbox) and 
collaborative platforms (Google Documents). 
While those computer tools seem to grow in 
popularity among professional writers, 
LinguisTech does not cover them. They are 
neither included in the toolbox, nor is there any 
training material related to them.  
45
As we reported in Subsection 2.4, the 
professional writers? workstation is cluttered up, 
meaning that the desktop is busy with many open 
windows. LinguisTech offers many useful 
computer tools, but no interface (or environment) 
to integrate them in an ergonomic way.  
 
3.3 General Conclusions 
In conclusion, this preliminary evaluation shows 
the usefulness of LinguisTech for Canadian 
professional writers, at least those who 
participated in the focus group. Most of the 
computer tools they use during the production of 
written documents are available in LinguisTech. 
Where LinguisTech falls short is in the 
integration of more effective information and 
document management systems and specialised 
writing tools (for example authoring memory 
systems). We do not know how many 
professional writers use LinguisTech 6 , but we 
can imagine that they would expect a ?reference 
web site for language professionals? to offer 
some specialised computer tools for tasks related 
to writing in a professional setting7. 
On the other hand, we have to admit that 
LinguisTech?s focus on tutorials and exercises 
addresses concerns expressed in our exploratory 
study, since the absence of training on 
information and language technologies was one 
of the major problems mentioned by our 
participants. 
Also, we think that LinguisTech could serve 
as an introduction to new tools, since our 
participants mentioned that they would welcome 
the integration of additional computer tools to 
their writing process. For example, LinguisTech 
includes concept mapping tools, which could be 
tested for information structuring, and 
concordancers, which could be tested for 
checking the correct usage of an expression 
during writing or revising. Those two categories 
of computer tools are accompanied by training 
material in LinguisTech. 
4 Conclusion 
In this paper, we presented results from a focus 
group with professional writers, in which they 
                                                          
6 As a survey on LinguisTech users? satisfaction will be 
launched in March, 2012, we hope to have more 
information soon on that subject. 
7 Many resources are available for translation specialised 
tasks (see the list of translation and localization tools in 
Table 5).  
 
discussed their experience with computer tools 
used to produce documents in the workplace. As 
we have seen, although they would not be able to 
work without those tools, they reported a number 
of problems, namely that they do not have access 
to specialised writing tools, such as authoring 
memory systems, and that they need training on 
computer tools.  
In the second part of the paper, we briefly 
described LinguisTech, a new platform for 
language professionals launched last September 
in Canada. We concluded that LinguisTech is 
useful for professional writers since it gives 
access to many computer tools intended for 
writing purposes, and many of those tools are 
accompanied by tutorials or exercises. However, 
according to our preliminary evaluation, 
LinguisTech would be even more adapted to 
today?s professional writing if it offered more 
effective information and document management 
systems, specialised writing tools, and training 
material on collaborative platforms.  
Acknowledgments 
We would like to thank the anonymous reviewers 
for their useful comments and suggestions in 
revising this paper, and Jo?l Bourgeoys for his 
considerable help.  
References 
Andy Adler, John C. Nash, and Sylvie No?l. 2006. 
Evaluating and Implementing a Collaborative 
Office Document System. In Interacting with 
Computers, 18(4):665-682. 
Jeffrey Allen. 1999. Adapting the Concept of 
?Translation Memory? to ?Authoring Memory? for 
a Controlled Language Writing Environment. In 
Proceedings of the Twenty-First International 
Conference on Translating and the Computer, 
London. 
C?line Beaudet. 1998. Litt?racie et r?daction: vers la 
d?finition d?une pratique professionnelle. In G.  A. 
Legault, editor, L?intervention : usages et 
m?thodes. ?ditions GGC, Sherbrooke, Canada, 
pages 68-88. 
Lynne Bowker, and Elizabeth Marshman. 2011. 
Towards a Model of Active and Situated Learning 
in the Teaching of Computer-Aided Translation: 
Introducing the CERTT Project. In Journal of 
Translation Studies, 13-14. To appear. 
Isabelle Clerc. 1998. L?enseignement de la r?daction 
professionnelle en milieu universitaire. In C. 
Pr?fontaine, L. Godard and G. Fortier, editors, 
Pour mieux comprendre la lecture et l??criture : 
enseignement et apprentissage. ?ditions Logiques, 
Montreal, pages 345-370. 
46
Isabelle Clerc, et al 2000. La d?marche de r?daction. 
?ditions Nota bene, Quebec, Canada. 
Paul Geoffrion. 1998. Le groupe de discussion. In B. 
Gauthier, editor, Recherche sociale: de la 
probl?matique ? la collecte des donn?es. Presses de 
l?Universit? du Qu?bec, Qu?bec, Canada, pages 
303-328. 
?ric Kavanagh. 1999. Analyse des fonctions d?un 
traitement de texte en regard des besoins du 
r?dacteur professionnel. In Z. Gu?vel and I. Clerc, 
editors, Les professions langagi?res ? l?aube de 
l?an 2000. CIRAL, Quebec, Canada, pages 161-
182. 
?ric Kavanagh. 2006. La r?daction web : anatomie 
d?une ? nouvelle ? expertise. In A. Piolat, editor, 
Lire, ?crire, communiquer et apprendre avec 
internet. Solal, Marseille, pages 175-201. 
Alex Kuhn, Chris Quintana, and Elliot Soloway. 
2009. Story Time : A New Way for Children to 
Write. In Proceedings of the 8th International 
Conference on Interaction Design and Children, 
pages 218-221, New York. 
P?ivi Majaranta, and R?ih? Kari-Jouko. 2002. Twenty 
Years of Eye Typing: Systems and Design Issues. 
In Proceedings of the 2002 Symposium on Eye 
Tracking Research and Applications, pages 15-22, 
New York.  
John Milton, and Vivying S. Y. Cheng. 2010. A 
Toolkit to Assist L2 Learners Become Independent 
Writers. In Proceedings of the NAACL HLT 2010 
Workshop on Computational Linguistics and 
Writing: Writing Processes and Authoring Aids, 
pages 33-41, Stroudsburg, Pennsylvania. 
Claude Morizio. 2006. La recherche d?information. 
Armand Colin, Paris. 
Kh?dija Nakbi. 2002. La r?dactologie : domaine, 
m?thode et comp?tences. ASp, 37-38, pages 15-26. 
Retrieved December 7, 2011 from 
http://asp.revues.org/1428. 
47
