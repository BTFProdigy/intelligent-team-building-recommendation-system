147
148
149
150
151
152
153
154
187
188
189
190
Proceedings of the ACL Interactive Poster and Demonstration Sessions,
pages 85?88, Ann Arbor, June 2005. c?2005 Association for Computational Linguistics
Two diverse systems built using
generic components for spoken dialogue
(Recent Progress on TRIPS)
James Allen, George Ferguson, Mary Swift, Amanda Stent, Scott Stoness, 
Lucian Galescu, Nathan Chambers, Ellen Campana, and Gregory Aist
University of Rochester
Computer Science Department
UR Comp Sci RC 270226
Rochester NY 14627 USA
{james, ferguson, swift, stoness,
campana, gaist}
@cs.rochester.edu
Institute for
Human and Machine Cognition
40 South Alcaniz St.
Pensacola FL 32502
{lgalescu,nchambers}@ihmc.us
State University of New York at
Stony Brook
1418 Computer Science
Stony Brook University
Stony Brook NY 11794 USA
stent@cs.sunysb.edu
Abstract
This  paper  describes  recent  progress  on  the
TRIPS architecture for developing spoken-lan-
guage dialogue systems.  The interactive poster
session will include demonstrations of two sys-
tems built using TRIPS: a computer purchas-
ing assistant, and an object placement (and ma-
nipulation) task.
1 Introduction
Building a robust spoken dialogue system for a new
task currently requires considerable effort,  includ-
ing  extensive  data  collection,  grammar  develop-
ment, and building a dialogue manager that drives
the  system using its  "back-end" application (e.g.
database query, planning and scheduling). We de-
scribe progress in an effort to build a generic dia-
logue system that  can be rapidly customized to a
wide range of different types of applications, pri-
marily  by  defining a  domain-specific  task  model
and the interfaces to the back-end systems. This is
achieved by  using generic  components  (i.e.,  ones
that apply in any practical domain) for all stages of
understanding  and developing techniques for rapid-
ly customizing the generic components to new do-
mains  (e.g.  Aist,  Allen,  and  Galescu  2004).  To
achieve this goal we have made several innovations,
including (1) developing domain independent mod-
els of  semantic and  contextual  interpretation,  (2)
developing generic  dialogue  management  compo-
nents based on an abstract  model of collaborative
problem solving, and (3) extensively using an ontol-
ogy-mapping system that connects the domain inde-
pendent representations to the representations/query
languages used by the back-end applications,  and
which is used to automatically optimize the perfor-
mance of the system in the specific domain.
2 Theoretical  Underpinnings:  The Prob-
lem-Solving Model of Dialogue
While many have observed that communication
is a specialized form of joint action that happens to
involve language and that dialogue can be viewed
as collaborative problem solving, very few imple-
mented systems have been explicitly based on these
ideas. Theories of speech act interpretation as inten-
tion recognition have been developed  (including ex-
tensive  prior  work  in  TRIPS'  predecessor,  the
TRAINS project), but have been generally consid-
ered impractical for actual systems.  Planning mod-
els  have been more successful  on the  generation
side, and some systems have used the notion of exe-
cuting explicit task models to track and drive the in-
teractions  (e.g.,  Sidner  and  Rich's  COLLAGEN
framework). But collaborative problem solving, and
dialogue in general, is much more general than exe-
cuting tasks. In our applications, in addition to exe-
cuting tasks, we see dialogue that is used to define
the task (i.e., collaborative planning), evaluate the
task (e.g., estimating how long it will take,  com-
paring options,  or  likely effects),    debug a  task
(e.g., identifying and discussing problems and how
to remedy them), learn new tasks (e.g., by demon-
stration and instruction).
85
In the remainder of the paper, we'll first discuss
the methods we've developed for building dialogue
systems using generic components.  We'll then de-
scribe two systems implemented using the TRIPS
architecture that we will demonstrate at the interac-
tive poster session.
3 Generic Methods:  Ontology Mappings
and Collaborative Problem Solving
The goal of our work is to develop generic spoken
dialogue technology that can be rapidly customized
to new applications, tasks and domains. To do this,
we have developed generic domain independent rep-
resentations not only of sentence meaning but also
of the collaborative actions that are performed by
the speech acts as one engages in dialogue. Further-
more, we need to be able to easily connect these
generic representations to a wide range of different
domain specific task models and applications, rang-
ing from data base query systems to state-of-the-art
planning and scheduling systems.  This  paper  de-
scribes  the  approach  we  have  developed  in  the
TRIPS system. TRIPS is now being used in a wide
range of diverse applications, from interactive plan-
ning (e.g., developing evacuation plans), advice giv-
ing  (e.g.,  a  medication  advisor  (Ferguson  et  al.
2002)),  controlling teams of robots,   collaborative
assistance (e.g., an assistant that can help you pur-
chase a computer, as described in this paper), sup-
porting human learning, and most recently having
the computer  learn (or  be  taught)  tasks,  such as
learning to perform tasks on the web.  Even though
the tasks and domains differ dramatically, these ap-
plications use the same set of core understanding
components. 
The key to supporting such a range of tasks and ap-
plications is the use of a general ontology-mapping
system. This allows the developer to express a set
of mapping rules that translate the generic knowl-
edge representation into the specific representations
used by the back-end applications (called the KR
representation).   In  order  to  support  generic dis-
course processing, we represent these mappings as
a chain of simpler transformations. These represen-
tations are thus transformed in several stages. The
first,  using the ontology mapping rules,  maps the
LF representation into an intermediary representa-
tion (AKRL - the abstract KR language) that has a
generic syntax  but  whose content is  expressed in
terms of the KR ontology. The second stage is a
syntactic transformation that occurs at the time that
calls to the back-end applications actually occur so
that  interactions  occur  in  the  representations  the
back-end expects.   In  addition to  using ontology
mapping to  deal  with the representational  issues,
TRIPS is unique in that it uses a generic model of
collaborative problem solving to drive the dialogue
itself  (e.g.  Allen,  Blaylock,  and  Ferguson 2002).
This model forms the basis of a generic component
(the collaboration manager) that supports both in-
tention recognition to identify the intended speech
acts and their content, planning the system's actions
to respond to the user (or that take initiative), and
providing utterance realization goals to the genera-
tion system. To develop this, we have been develop-
ing  a  generic  ontology  of  collaborative  problem
solving acts, which provide the framework for man-
aging  the  dialogue.  The  collaboration  manager
queries a domain-specific task component in order
to  make  decisions  about  interpretations  and  re-
sponses.
4 TRIPS  Spoken  Dialogue  Interface  to
the CALO Purchasing Assistant 
The CALO project is a large multisite effort which
aims  at  building  a  computerized  assistant  that
learns how to help you with day-to-day tasks. The
overarching goal of the CALO project is to 
... create cognitive software systems, that is,
systems that can reason, learn from experi-
ence, be told what to do, explain what they
are doing, reflect on their experience, and re-
spond robustly to surprise (Mark and Per-
rault 2004). 
Within this broad mandate, one of our current areas
of focus is user-system dialogue regarding the task
of purchasing - including eliciting user needs, de-
scribing possibilities, and reviewing & finalizing a
purchase  decision.  (Not  necessarily  as  discrete
stages; these elements may be interleaved as appro-
priate for the specific item(s) and setting.)  Within
the purchasing domain,  we began with computer
purchasing and have branched out to other equip-
ment such as projectors.
How to help with purchasing? The family of tasks
involving purchasing items online, regardless of the
type of item, have a  number of elements in com-
mon. The process of purchasing has some common
86
dialogue elements - reporting on the range of fea-
tures  available,  allowing the user  to specify con-
straints, and so forth.  Also, regarding the goal that
must be reached at the end of the task, the eventual
item must:
Meet requirements.  The item needs to meet some
sort of user expectations. This could be as arbitrary
as a specific part number, or as compositional - and
amenable to machine understanding -  as  a  set  of
physical  dimensions (length,  width,  height,  mass,
etc.) 
Be approved. Either the system will have the au-
thority to approve it (cf. Amazon's one-click order-
ing system), or more commonly the user will review
and confirm the purchase. In an office environment
the approval process may extend to include review
by a supervisor, such as might happen with an item
costing over (say) $1000. 
Be available. (At  one time a  certain  electronics
store in California had the habit of leaving out floor
models of laptops beyond the point where any were
actually available for sale.  (Perhaps to entice the
unwitting customer into an ?upsale?, that is, buying
a  similar  but  more  expensive  computer.))  On  a
more serious note, computer specifications change
rapidly, and so access to online information about
available  computers  (provided  by  other  research
within CALO) would be important in order to en-
sure that the user can actually order the machine he
or she has indicated a preference for.  
At  the interactive poster  session,  we will demon-
strate some of the current spoken dialogue capabili-
ty related to the CALO task of purchasing equip-
ment.  We will demonstrate a number of the aspects
of the system such as initiating a conversation, dis-
cussing specific requirements,  presenting possible
equipment to purchase,  system-initiated reminders
to ask for supervisor approval for large purchases,
and finalizing a decision to purchase. 
Figure 1. Fruit carts display.
87
5 TRIPS  Spoken  Dialogue  Interface  to
choosing,  placing,  painting,  rotating,
and filling (virtual) fruit carts
TRIPS is versatile in its applications, as we've said
previously.  We hope to also demonstrate an inter-
face to  a  system for  using spoken commands to
modifying, manipulating, and placing objects on a
computer-displayed map.  This  system (aka  ?fruit
carts?)  extends  the  TRIPS  architecture  into  the
realm of continuous understanding.  That is, when
state-of-the-art  dialogue systems listen,  they typi-
cally wait for the end of the utterance before decid-
ing what to do.  People on the other hand do not
wait in this way ? they can act on partial informa-
tion as  it  becomes available.   A classic example
comes  from  M.  Tanenhaus  and  colleagues  at
Rochester: when presented with several objects of
various colors and told to ?click on the yel-?, people
will already tend to be looking relatively more at the
yellow object(s) even before the word ?yellow? has
been completed.  To achieve this type of interactivi-
ty with a dialogue system ? at least at the level of
two or three words at a time, if not parts of words ?
imposes some interesting challenges. For example:
1. Information must flow asynchronously between
dialogue components, so that actions can be trig-
gered based on partial utterances even while the
understanding continues
2. There must be reasonable representations of in-
complete information ? not just ?incomplete sen-
tence?,  but  specifying what  is  present  already
and perhaps what may potentially follow
3. Speech  recognition,  utterance  segmentation,
parsing, interpretation, discourse reasoning, and
actions must all be able to happen in real time
The fruit carts system consists of two main compo-
nents:  first,  a  graphical  interface implemented on
Windows  2000  using  the  .NET  framework,  and
connected to  a  high-quality  eyetracker;  second,  a
TRIPS-driven spoken dialogue interface implement-
ed primarily in LISP.   The actions in this domain
are as follows:
1. Select an object (?take the large plain square?)
2. Move it (?move it to central park?)
3. Rotate  it  (?and then turn  it  left  a  bit  ?  that's
good?)
4. Paint it (?and that one needs to be purple?)
5. Fill it (?and there's a grapefruit inside it?)
Figure 1 shows an example screenshot from the
fruit carts visual display. The natural language in-
teraction  is  designed to  handle  various  ways  of
speaking,  including conventional  definite  descrip-
tions (?move the large square to central park?) and
more interactive language such as (?up towards the
flag pole ? right a bit ? more ? um- stop there.?)
6 Conclusion
In this brief paper,  we have described some of
the recent progress on the TRIPS platform.  In par-
ticular we have focused on two systems developed
in TRIPS: a spoken dialogue interface to a mixed-
initiative purchasing assistant, and a spoken inter-
face for exploring continuous understanding in an
object-placement task.  In  both  cases  the  systems
make use of reusable components ? for input and
output  such as  parsing and speech synthesis,  and
also for dialogue functionality such as mapping be-
tween language,  abstract  semantics,  and  specific
representations for each domain.
References 
Aist,  G.  2004.  Speech,  gaze,  and  mouse  data  from
choosing,  placing,  painting,  rotating,  and  filling
(virtual) vending carts. International Committee for
Co-ordination  and  Standardisation  of  Speech
Databases  (COCOSDA)  2004  Workshop,  Jeju  Is-
land, Korea, October 4, 2004. 
Aist, G.S., Allen, J., and Galescu, L. 2004. Expanding
the linguistic coverage of a spoken dialogue system
by mining human-human dialogue for new sentences
with familiar meanings. Member Abstract, 26th An-
nual  Meeting  of  the  Cognitive  Science  Society,
Chicago, August 5-7, 2004. 
James Allen, Nate Blaylock, and George Ferguson. A
problem-solving model for collaborative agents.  In
First International Joint Conference on Autonomous
Agents and Multiagent Systems, Bologna, Italy, July
15-19 2002. 
George  Ferguson,  James  F.  Allen,  Nate  J.  Blaylock,
Donna K. Byron, Nate W. Chambers, Myrsolava O.
Dzikovska, Lucian Galescu, Xipeng Shen, Robert S.
Swier, and Mary D. Swift.  The Medication Advisor
Project: Preliminary Report, Technical Report 776,
Computer  Science  Dept.,  University  of  Rochester,
May 2002. 
Mark,  B.,  and  Perrault,  R.  (principal  investigators).
2004.  Website for Cognitive Assistant  that  Learns
and Organizes. http://www.ai.sri.com/project/CALO
88
Squibs
Fruit Carts: A Domain and Corpus for Research in
Dialogue Systems and Psycholinguistics
Gregory Aist?
Iowa State University
Ellen Campana??
Arizona State University
James Allen?
University of Rochester
Mary Swift?
University of Rochester
Michael K. Tanenhaus?
University of Rochester
We describe a novel domain, Fruit Carts, aimed at eliciting human language production for the
twin purposes of (a) dialogue system research and development and (b) psycholinguistic research.
Fruit Carts contains five tasks: choosing a cart, placing it on a map, painting the cart, rotating
the cart, and filling the cart with fruit. Fruit Carts has been used for research in psycholinguistics
and in dialogue systems. Based on these experiences, we discuss how well the Fruit Carts
domain meets four desired features: unscripted, context-constrained, controllable difficulty, and
separability into semi-independent subdialogues. We describe the domain in sufficient detail to
allow others to replicate it; researchers interested in using the corpora themselves are encouraged
to contact the authors directly.
1. Introduction and Relation to Prior Work
Dialogue system research, like much else in computational linguistics, has greatly
benefited from corpora of natural speech. With notable exceptions (e.g. the Edinburgh
Maptask, Anderson et al [1991]), these corpora consist of samples annotated with
linguistic properties (e.g. POS, syntax, discourse status) setting aside the visual and
? 206 Ross Hall, Iowa State University, Ames, Iowa 50011. E-mail: gregory.aist@alumni.cmu.edu.
?? 240c Matthews Center, Arizona State University, Tempe, Arizona 85287. E-mail: ellen.campana@asu.edu.
? 721 CSB, University of Rochester, Rochester, New York 14627. Email: james@cs.rochester.edu.
? 732 CSB, University of Rochester, Rochester, New York 14627. E-mail: swift@cs.rochester.edu.
? 420 Meliora, University of Rochester, Rochester, New York 14627. E-mail: mtan@bcs.rochester.edu.
Submission received: 24 August 2009; revised submission received: 6 May 2010; accepted for publication:
20 September 2010.
? 2012 Association for Computational Linguistics
Computational Linguistics Volume 38, Number 3
pragmatic aspects of the context in which they occurred. In recent years natural lan-
guage processing (NLP) researchers have been working to incorporate visual and other
context into their models and systems (DeVault and Stone 2004; Gabsdil and Lemon
2004; Schuler, Wu, and Schwartz 2009). This is consistent with the growing evidence in
psycholinguistics that human language production crucially depends on such aspects of
context. To take this NLP research further, there is a need for more corpora that include
both variation in, and annotation of, visual and pragmatic context.
There are still many open questions that span computational linguistics and
psycholinguistics concerning how natural language and context are related. One core
question at the intersection of these areas is how the inherent difficulty of describing an
end-goal (i.e., its codability) will affect the structure and content of referring expressions
and the referential strategy speakers adopt. Referential strategies are a topic of grow-
ing interest in natural language generation. In recent work, Viethen and Dale (2006)
demonstrated that even when describing simple grid layouts, people adopt different
referential strategies, due perhaps to proximity to landmarks (and hence codability):
the orange drawer below the two yellow drawers, in contrast to the yellow drawer in the third
column from the left second from the top. For systems to produce humanlike references in
these situations, existing methods of reference generation will need to be modified or
extended to include better models of the choice of referential strategies (Viethen and
Dale 2006). Such models can also be expected to improve reference resolution: If better
predictions can be made about what people will say in a given situation, automatic
speech recognition language models can be tighter, NLP grammars can be smaller, and
unlikely parses can be avoided, improving both speed and accuracy.
Recent psycholinguistic research suggests that codability does play a role in human
reference production (e.g., Cook, Jaeger, and Tanenhaus 2009). This work has largely
focused on timing, signals of production difficulty (e.g., disfluency, gesture), and the
content of referring expressions (e.g., adjectives, pronouns). There has been much
less consideration of how entire referential strategies might systematically vary with
codability. A corpus with the correct design and structure will allow for investigation
of the more well-studied aspects as well as higher-level factors such as strategy choice,
and possible interactions between them.
With these considerations in mind, we designed a domain, Fruit Carts, and a set
of corresponding tasks in order to elicit human language production for two pur-
poses: 1) the testing of psycholinguistic hypotheses, specifically that object complexity
modulates referential strategy, and more generally the exploration of the relationship
between visual context and human?human dialogue, and 2) research and development
of dialogue systems that understand language as it unfolds, taking pragmatic factors
into account early in the recognition process. By designing with both fields in mind
we hope to strengthen the long tradition of cross-fertilization between the disciplines
(e.g., Brennan 1991), particularly for task- or game-oriented systems and domains, with
a visual component.
We identified four important features to build into the domain. First, the language
produced should be completely unscripted: Participants should be able to perform the
task with a general description of what to do (e.g., Give instructions on how to make the
map on the screen look like the map in your hand) and zero prior examples of what to
say. For psycholinguistics, this makes the language natural speech rather than speech
that is restricted by the instructions or by prior examples. For dialogue systems, this
makes the language ?untrained? rather than the result of careful training, meaning that
systems will be processing language that is representative of what speakers are likely
to produce when they use the system, especially without extensive training. Second,
470
Aist et al Fruit Carts Domain and Corpus
the language should be fairly well constrained by context. For psycholinguistics, this
makes the language more straightforward to analyze and also more directly tied to the
visual context and thus amenable to ?visual world? studies that use eye movements to
examine real-time production (Griffin and Bock 2000) and comprehension (Tanenhaus
et al 1995). For dialogue systems, this makes the language more amenable to automatic
processing and also facilitates the integration of different types of knowledge into the
recognition process. Third, it should be possible to vary the difficulty of the tasks. For
psycholinguistics, this makes hypotheses about the effect of task difficulty on language
production amenable to study. For dialogue systems, this allows the resulting corpora
to have a combination of relatively easy tasks (?low-hanging fruit?) and more difficult
NLP challenges. Fourth, the domain should support the collection of dialogues that are
separable into partially or semi-independent subdialogues, with limited need for ref-
erence to previous subdialogues. For psycholinguistics, this makes each subdialogue a
separate trial, allowing for analyses where trials are treated as random effects in mixed-
effect regression models or repeated measures in ANOVAs. For dialogue systems, this
limits the likelihood that errors in processing one subdialogue will spill over and
affect processing of subsequent subdialogues. For both research areas, this separability
constraint enables within-subject experiments with each subdialogue as a trial.
In purpose and approach, Fruit Carts is most similar to the Map Task (Anderson
et al 1991); both are simultaneously a set of experiments on language and a corpus
used for developing language processing systems. Map Task dialogues ?are unscripted
[but] the corpus as a whole comprises a large, carefully controlled elicitation exercise?
(Anderson et al 1991, page 352) that has been used inmany computational endeavors as
well. Fruit Carts was guided by our twin goals of furthering the development of spoken
language systems, and providing a psycholinguistic test bed in which to test specific
hypotheses about human language production. Fruit Carts differs from Map Task in
terms of dynamic object properties and in terms of the information available to the
speaker and hearer. In the Map Task, objects have fixed properties that differ between
giver and follower, yet remain constant while the path is constructed. In Fruit Carts,
objects have properties that can be changed: position, angle, and color. This allows for
a wide variety of linguistic behavior which in turn supports detailed exploration of
continuous understanding by humans and machines. In the Map Task, the participants?
screens differ, whereas in Fruit Carts the speaker and hearer share the same visual
context, which simplifies the analysis and interpretation of results (Figure 1).
2. Fruit Carts Domain and Tasks
The Fruit Carts domain has three screen areas: amap, an object bin, and a controls panel.
Each area was designed in part to elicit the types of expressions that require continuous
understanding to approximate human behavior such as progressive restriction of a
reference set throughout the utterance.
The map contains named regions divided by solid lines, with three flags as land-
marks. The region names did not appear on the screen, to preclude use of spelling in
referring expressions (the C in Central Park). Names were chosen to be phonetically
distinct. To support progressive restriction of potential regions, regions whose initial
portions overlap are adjacent (Morn identifies Morningside and Morningside Heights)
and some regions have flags and others not (put the square on the flag in... identifies
the regions with flags.) No compass is displayed, in an attempt to limit the directions
elicited to up, down, left, and right and not north, south, and so on.
471
Computational Linguistics Volume 38, Number 3
Figure 1
Example initial and final configurations for Fruit Carts domain and corpus. The region names
were available to both director and actor (on paper) but were not shown on screen. The final
configuration shown is the actual screen after the five dialogues from the participant whose
third, fourth, and fifth dialogues are shown in Appendix A.
The object bin contains fruits and carts, by analogy with food vendor carts (e.g., hot
dog stands). The fruits are avocados, bananas, cucumbers, grapefruits, and tomatoes,
all botanically fruits. We chose fruits because they were nameable, especially with a
label, and visually different from the carts. The carts are either squares or triangles,
in two sizes, with an optional tag that for squares is either a diamond or a heart and
for triangles is either a star or a circle. Adjectives (e.g., large, small) are commonly
used in natural language descriptions and there is a growing body of psycholinguistic
research, mostly with scripted utterances, that has used adjectives to investigate real-
time language processing (Sedivy et al 1999; Brown-Schmidt, Campana, and Tanenhaus
2005). Here, to support progressive restriction of potential carts, each component is easy
to name but the entire shape requires a complex description rather than a prenominal
modifier?or at least strongly prefers one, as no examples to the contrary were observed
in the Fruit Carts corpus described later in this article. That is, whereas a square with
stripes could be either the square with stripes or the striped square, a square with a diamond
on the corner is the square with a diamond on the corner but not *the corner-diamonded square.
The controls panel contains left and right rotation arrows and six paint colors (black,
brown, orange, blue, pink, and purple) chosen to be distinct from the colors of the fruit.
Five tasks are included in Fruit Carts, all performed by using a mouse. To CHOOSE
a cart, the user clicks on it. To PLACE it on the map, the user drags it there. To PAINT
the cart, the user clicks on the desired color. Painting is a uniformly easy control task.
To ROTATE the cart, the user presses and holds down the left or right rotation button.
472
Aist et al Fruit Carts Domain and Corpus
The goal of the rotation tool was to allow arbitrary rotations and to elicit utterances
that were in response to visual feedback, such as rotate it a little to the right, more, stop.
Finally, to FILL the cart, the user drags fruit to it.
3. Fruit Carts Corpus
For the dual goals of gathering a corpus of utterances for dialogue system research, and
testing the hypothesis that object complexity modulates referential strategy in human
language production, we designed a set of goal maps that systematically manipulated:
POSITION. Each cart was in a high-codability ?easy? position, such as centered on a flag
or in a region; or a low-codability ?hard? position, such as off-center.
HEADING. Each cart was at an ?easy? angle, an integer multiple of 45 degrees from its
original orientation; or a ?hard? angle, a non-multiple of 45 degrees.
CONTENTS. Each cart contained an ?easy? set of objects, fruit of the same type, such as
three tomatoes; or a ?hard? set of objects, such as two bananas and a grapefruit.
COLOR. Each cart was painted a uniformly ?easy? color to provide a control condition.
One person (the director) gave directions to the other (the actor) on how to carry
out the task. The director wore a headset microphone that collected speech data; the
actor in this set-up wore a head-mounted eye-tracker that collected eye movements.
The director (a subject) sat just behind the actor (a confederate); both viewed the same
screen. Twelve subjects participated, each of whom specified twenty objects to place on
the map; thus, a total of 240 dialogues were collected. The recordings were transcribed
word-for-word by a professional transcription service that also provided sentence
boundaries. The corpus has been labeled for referential strategy at the utterance level
(Aist et al 2005) and subsequently with referring expressions, spatial relations, and
actions in order to support word-by-word incremental interpretation (Gallo et al 2007);
see Appendix A.
4. Analysis with Respect to Desired Features
How well does the Fruit Carts domain meet the desired features described earlier?
1. Unscripted. Subjects were generally able to complete the task with only the instruc-
tions to make the screen match their paper map, and no prior examples of what to say,
although one subject systematically did not issue instructions to paint the shapes.
2. Constrained. Generally speaking, subjects used the language we expected, such as
square, triangle, and so forth, or high-frequency synonyms such as box for a square cart
(from the first dialogue of the participant in Appendix A, omitted for space) or dot for
a circle tag (Appendix A, [D3]). There were examples of participants using unexpected
expressions, such as calling an avocado a lime, despite the on-screen label. Yet overall
the language was well constrained by the context.
3. Support for varying of task difficulty. As the Fruit Carts corpus showed, location,
heading, and contents of carts can be systematically varied; later corpora, outside
the scope of this article, have varied the number of carts placed together in order to
construct simple or compound objects, in order to test the hypothesis that higher-level
473
Computational Linguistics Volume 38, Number 3
task and goal knowledge (e.g. a tower is being built from several blocks) modulates
language production, and to support further dialogue system research.
4. Support for collection of semi-independent subdialogues. Here the Fruit Carts
domain excels. Due to the presence of multiple separate objects and regions, different
subdialogues can make use of different objects, regions, properties, and so forth. By
contrast, a domain revolving around construction of a single complex target, such as a
landscaping plan, would have licensed substantial amounts of reference to previously
placed objects including objects not in place at the time the dialogue began?making
subdialogues dependent on each other in terms of accuracy, correctness, and so forth.
As Appendix A illustrates, these Fruit Carts data contain relatively few such references.
This is analogous to the difference between a math exercise set that contains several
independent exercises, and a set where each exercise builds on previous answers.
5. Use in Research
For dialogue systems research, the Fruit Carts domain has already been useful in de-
veloping dialogue systems that understand language continuously while taking prag-
matics into account. For example, using Fruit Carts, incorporating pragmatic feedback
about the visual world early in the parsing process was shown to substantially improve
parsing efficiency as well as allowing parsing decisions to accurately reflect the visual
world (Aist et al 2006). Also using Fruit Carts, a dialogue system using continuous
understanding was shown to be faster than, and preferred to, a counterpart that used a
traditional pipeline architecture but was otherwise identical (Aist et al 2007).
For psycholinguistic research, Fruit Carts has also been used for studying the
relationship between bi-clausal structure and theme complexity (Gallo et al 2008) and
testing hypotheses regarding the relationship of information in a message, resource
limitations, and sentence production (Gallo, Jaeger, and Smyth 2008).
6. Discussion and Conclusions
Fruit Carts also has a number of other advantages as well as some limitations.
First, Fruit Carts provides ample temporary or local ambiguity in its utterances, a
central challenge for continuous understanding systems and a classic target of research
in psycholinguistics (for a review see Altmann [1998]). In a typical sequence such as okay
take a ... small triangle with a dot on the corner (Appendix A, [D3]), most of the content
words and some of the function words serve to resolve local ambiguity:
okay take... ? uniquely identifies an action
...a ... small... ? restricts (partially disambiguates) referential domain to half of the shapes
...triangle... ? further restricts the referential domain to the triangles
...with... ? further restricts the referential domain to carts with tags
...a dot... ? further restricts the referential domain to carts with circles
...on the corner ? uniquely identifes one of the twenty carts
Likewise, flag in right ... um ... side of the uh ... flag in pine tree mountain [D5] restricts
regions to flagged regions.
474
Aist et al Fruit Carts Domain and Corpus
Second, Fruit Carts also elicits substantial variation in referential strategy. Some
utterances could be grounded independent of context, up to pronominal reference. For
example, the hypothetical utterance Move a large plain square to the flag in Central Park
has a fully specified action, object, and goal, as do rotate it about 45 degrees (Appendix A,
[D4]), and and um make that orange [D5]. We labeled this category ?all-at-once.? For
other utterances, grounding relied on the surrounding context?dialogue and/or task.
For example, um a little to the left [D4] contains a direction (left) but might rely on the
last action to identify the intended action as rotation or movement, and on the selected
shape on the screen to identify the object. We labeled this category ?continuous.?
Some utterances exhibited ?both? all-at-once and continuous properties, or properties
of ?neither? category. The continuous utterances contained 21% fewer words (mean,
8.72 vs. 6.85) than the all-at-once and contained shorter words, too (mean, 3.95 letters
vs. 3.74). About one-third of the utterances were labeled as ?continuous?; speakers
produced more continuous utterances as task experience increased (Aist et al 2005).
Finally, Fruit Carts is relatively abstract: The carts are basic shapes such as squares
and triangles, and the fruit are chosen for language research purposes. On the one hand,
this is desirable because it reduces the possibility of confounding effects from prior
knowledge. On the other hand, it would be interesting for future work to extend Fruit
Carts-style domains to more realistic object construction and placement tasks.
Appendix A: Example Dialogues
Referential strategy. These dialogues [D3]?[D5] are the third, fourth, and fifth dia-
logues from one subject, screen one. For conciseness, ?...? concatenates some adjacent
utterances. All-at-once sections are marked in bold and continuous sections in italics.
[D3] okay take a ... small triangle with a dot on the corner
and ... um ... put it ... it should be in um ... kinda the uh ... center right side of morningside
heights
uh morningside heights ... oh ... um a little further in ... uh ... towards the um oh wait a little back
sorry ... uh that?s good
and then rotate it to the right until the l- hypotenuse is str- fa- yeah like that <laughter>
and then make that blue
and put a uh grapefruit in it so that
it ... it?s touching the left side but sticking out of the top
oh it should be inside the triangle and touching
um a little ... over ... or down and over a little bit ... uh yeah that?s good
um <breath> ... now ... uh
[D4] take a square ... and put it in um ... oceanview terrace
and pretty much in the center
um i don?t know which one it i- i guess the s- try the smaller one
um and then uh
rotate it about 45 degrees
um ... oh ... like one more turn ... yeah
um and make that ... pink
475
Computational Linguistics Volume 38, Number 3
and then put a uh tomato ... in the ... um a little to the left ...okay
good ... um ... it ... i?m not sure if it should be a bigger one that triangle or not
um you can try the bigger triangle ... i mean not the bigger triangle the bigger square ... i think
maybe it should be the ... yeah i think it should be the bigger square
<mumble> ... put the yeah right there
[D5] and then um ... and put ... um <breath> ... <mumble> ... then put uh get a uh ...
<mumble>
take the uh large triangle with the star
and um ... put that ... um to the ... right ... um ... side of the uh ... flag in pine tree mountain
er the right side
and ... <laughter> um down a little
um ... then rotate it so that ... the ... the hypotenuse is ... almost ... horizontal but ... tilted a
little sli- like one more rotat- yeah
and um make that orange
um maybe a little closer to the flag
and down ... yeah that should be good
kay um and then put a uh tomato in the right ... er in the left corner and then a cucumber in
the right corner of it
um ... the tomato should be a l- er um ... not ... quite ... in the corner th- yeah that?s good and the
cucumber should be a little down
a little more yeah um oh wait that?s a little too much ... uh that sh- um that?s good
okay ... that?s it <laughter> ... <laughter>
oh you wanna see this ... <laughter>
i think that?s good ... okay <laughter>
Incremental disambiguation. This example, adapted fromGallo et al (2007), shows
annotation to support disambiguation, here, in the small box in Morningside. These
are word-level annotations in the smallest possible semantic units, marked at the
point of disambiguation with no lookahead, and following the speaker?s intentions
(Gallo et al 2007).
the
anchor(A1)
definite(A1)
small
size(A1, small)
box
objectType(A1, square)
in
anchor(A2)
spatialRelation(A2, inside)
location(A1, A2)
476
Aist et al Fruit Carts Domain and Corpus
Morningside
anchor(A3)
name(A3)
objectReferent(A3, MorningsideRegion3)
ground(A2, A3)
Message structure. The following example, adapted from Gallo et al (2008), shows
annotation for the purpose of exploring the link between message structure and
complexity of the theme.
original: take a square with a ... square with a heart on the corner
clean: take a square with a heart on the corner
action: SELECT
verb: take
theme: a square with a heart on the corner
theme disfluency: Yes
theme pause: Yes
Acknowledgments
This material is based upon work supported
by the National Science Foundation under
grant 0328810. Any opinions, findings, and
conclusions or recommendations expressed
in this material are those of the author(s)
and do not necessarily reflect the views
of the National Science Foundation. This
publication was partially supported by
grant HD 27206 from the NIH. The contents
of this report are solely the responsibility
of the authors and do not necessarily
represent the official views of the NIH.
References
Aist, G. S., J. Allen, E. Campana,
L. Galescu, C. Go?mez Gallo, S. Stoness,
M. Swift, and M. K. Tanenhaus. 2006.
Software architectures for incremental
understanding of human speech.
In Proceedings of the 9th International
Conference on Spoken Language Processing,
pages 1922?1925, Pittsburgh, PA.
Aist, G. S., J. Allen, E. Campana,
C. Go?mez Gallo, S. Stoness, M. Swift,
and M. K. Tanenhaus. 2007. Incremental
dialogue system faster than and preferred
to its nonincremental counterpart.
In Proceedings of the 29th Annual
Meeting of the Cognitive Science Society,
pages 761?766, Nashville, TN.
Aist, G. S., E. Campana, J. Allen, M. Rotondo,
M. Swift, and M. K. Tanenhaus. 2005.
Variations along the contextual continuum
in task-oriented speech. In Proceedings of
the 27th Annual Meeting of the Cognitive
Science Society, pages 79?84, Stresa.
Altmann, G. T. M. 1998. Ambiguity in
sentence processing. Trends in Cognitive
Sciences, 2(4):146?152.
Anderson, A., M. Bader, E. Bard, E. Boyle,
G. M. Doherty, G. M. Garrod, S. Isard,
J. Kowtko, J. McAllister, J. Miller, C. Sotillo,
H. S. Thompson, and R. Weinert. 1991.
The HCRC map task corpus. Language
and Speech, 34:351?366.
Brennan, S. E. 1991. Conversation with and
through computers. User Modeling and
User-Adapted Interaction, 1:67?86.
Brown-Schmidt, S., E. Campana, and
M. K. Tanenhaus. 2005. Real-time
reference resolution in a referential
communication task. In J. C. Trueswell
and M. K. Tanenhaus, editors, Processing
World-situated Language: Bridging the
Language-as-action and Language-as-product
Traditions. MIT Press, Cambridge, MA,
pages 153?171.
Cook, S. W., T. F. Jaeger, andM. K. Tanenhaus.
2009. Producing less preferred structures:
More gestures, less fluency. In Proceedings
of the 31st Annual Meeting of the Cognitive
Science Society, pages 62?67, Amsterdam.
DeVault, D. and M. Stone. 2004. Interpreting
vague utterances in context. In Proceedings
of COLING, pages 1247?1253, Geneva.
Gabsdil, M. and O. Lemon. 2004. Combining
acoustic and pragmatic features to predict
477
Computational Linguistics Volume 38, Number 3
recognition performance in spoken
dialogue systems. In Proceedings of the
42nd Annual Meeting of the Association of
Computational Linguistics, pages 79?84,
Barcelona.
Gallo, C. Go?mez, G. Aist, J. Allen,
W. de Beaumont, S. Coria,
W. Gegg-Harrison, J. Paulo Pardal, and
M. Swift. 2007. Annotating continuous
understanding in a multimodal dialogue
corpus. In Proceedings of the 2007 Workshop
on the Semantics and Pragmatics of Dialogue,
pages 75?82, Rovereto.
Gallo, C. Go?mez, T. F. Jaeger, J. Allen, and
M. Swift. 2008. Production in a multimodal
corpus: How speakers communicate
complex actions. In Proceedings of the
Language Resources and Evaluation
Conference, pages 2917?2920, Marrakech.
Gallo, C. Go?mez, T. F. Jaeger, and R. Smyth.
2008. Incremental syntactic planning
across clauses. In Proceedings of the 30th
Annual Meeting of the Cognitive Science
Society, pages 845?850, Washington, DC.
Griffin, Z. M. and K. Bock. 2000. What the
eyes say about speaking. Psychological
Science, 11:274?279.
Schuler, W., S. Wu, and Lane Schwartz.
2009. A framework for fast incremental
interpretation during speech decoding.
Computational Linguistics, 35(3):313?343.
Sedivy, J. E., M. K. Tanenhaus, C. G.
Chambers, and G. N. Carlson. 1999.
Achieving incremental interpretation
through contextual representation:
Evidence from the processing of
adjectives. Cognition, 71:109?147.
Tanenhaus, M. K., M. J. Spivey-Knowlton,
K. M. Eberhard, and J. E. Sedivy. 1995.
Integration of visual and linguistic
information in spoken language
comprehension. Science, 268:1632?1634.
Viethen, J. and R. Dale. 2006. Algorithms
for generating referring expressions:
Do they do what people do? In Proceedings
of the 4th International Conference on
Natural Language Generation, pages 63?70,
Sydney.
478
