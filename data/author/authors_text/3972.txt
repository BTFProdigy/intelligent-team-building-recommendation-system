Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 41?44,
Suntec, Singapore, 4 August 2009.
c?2009 ACL and AFNLP
Incremental Parsing with Monotonic Adjoining Operation
Yoshihide Kato and Shigeki Matsubara
Information Technology Center, Nagoya University
Furo-cho, Chikusa-ku, Nagoya, 464-8601 Japan
{yosihide,matubara}@el.itc.nagoya-u.ac.jp
Abstract
This paper describes an incremental parser
based on an adjoining operation. By using
the operation, we can avoid the problem
of infinite local ambiguity in incremental
parsing. This paper further proposes a re-
stricted version of the adjoining operation,
which preserves lexical dependencies of
partial parse trees. Our experimental re-
sults showed that the restriction enhances
the accuracy of the incremental parsing.
1 Introduction
Incremental parser reads a sentence from left to
right, and produces partial parse trees which span
all words in each initial fragment of the sentence.
Incremental parsing is useful to realize real-time
spoken language processing systems, such as a si-
multaneous machine interpretation system, an au-
tomatic captioning system, or a spoken dialogue
system (Allen et al, 2001).
Several incremental parsing methods have been
proposed so far (Collins and Roark, 2004; Roark,
2001; Roark, 2004). In these methods, the parsers
can produce the candidates of partial parse trees
on a word-by-word basis. However, they suffer
from the problem of infinite local ambiguity, i.e.,
they may produce an infinite number of candidates
of partial parse trees. This problem is caused by
the fact that partial parse trees can have arbitrar-
ily nested left-recursive structures and there is no
information to predict the depth of nesting.
To solve the problem, this paper proposes an in-
cremental parsing method based on an adjoining
operation. By using the operation, we can avoid
the problem of infinite local ambiguity. This ap-
proach has been adopted by Lombardo and Sturt
(1997) and Kato et al (2004). However, this
raises another problem that their adjoining opera-
tions cannot preserve lexical dependencies of par-
tial parse trees. This paper proposes a restricted
version of the adjoining operation which preserves
lexical dependencies. Our experimental results
showed that the restriction enhances the accuracy
of the incremental parsing.
2 Incremental Parsing
This section gives a description of Collins and
Roark?s incremental parser (Collins and Roark,
2004) and discusses its problem.
Collins and Roark?s parser uses a grammar de-
fined by a 6-tuple G = (V, T, S,#, C,B). V is
a set of nonterminal symbols. T is a set of ter-
minal symbols. S is called a start symbol and
S ? V . # is a special symbol to mark the end
of a constituent. The rightmost child of every par-
ent is labeled with this symbol. This is necessary
to build a proper probabilistic parsing model. C
is a set of allowable chains. An allowable chain
is a sequence of nonterminal symbols followed by
a terminal symbol. Each chain corresponds to a
label sequence on a path from a node to its left-
most descendant leaf. B is a set of allowable
triples. An allowable triple is a tuple ?X,Y, Z?
where X,Y, Z ? V . The triple specifies which
nonterminal symbol Z is allowed to follow a non-
terminal symbol Y under a parent X .
For each initial fragment of a sentence, Collins
and Roark?s incremental parser produces partial
parse trees which span all words in the fragment.
Let us consider the parsing process as shown
in Figure 1. For the first word ?we?, the parser
produces the partial parse tree (a), if the allowable
chain ?S ? NP ? PRP ? we? exists in C. For
other chains which start with S and end with ?we?,
the parser produces partial parse trees by using the
chains. For the next word, the parser attaches the
chain ?VP?VBP? describe? to the partial parse
tree (a)
1
. The attachment is possible when the al-
lowable triple ?S, NP, VP? exists in B.
1
More precisely, the chain is attached after attaching end-
of-constituent# under the NP node.
41
WePRP
NP S(a)
WePRP
NP S(b)
describeVBP
VP
WePRP
NP S(c)
describeVBP
VP NPDTa
WePRP
NP S(d)
describeVBP
VP NP
DTa
WePRP
NP S(e)
describeVBP
VP NP
DTa
NP
NPNP
Figure 1: A process in incremental parsing
2.1 Infinite Local Ambiguity
Incremental parsing suffers from the problem of
infinite local ambiguity. The ambiguity is caused
by left-recursion. An infinite number of partial
parse trees are produced, because we cannot pre-
dict the depth of left-recursive nesting.
Let us consider the fragment ?We describe a.?
For this fragment, there exist several candidates of
partial parse trees. Figure 1 shows candidates of
partial parse trees. The partial parse tree (c) rep-
resents that the noun phrase which starts with ?a?
has no adjunct. The tree (d) represents that the
noun phrase has an adjunct or is a conjunct of a
coordinated noun phrase. The tree (e) represents
that the noun phrase has an adjunct and the noun
phrase with an adjunct is a conjunct of a coordi-
nated noun phrase. The partial parse trees (d) and
(e) are the instances of partial parse trees which
have left-recursive structures. The major problem
is that there is no information to determine the
depth of left-recursive nesting at this point.
3 Incremental Parsing Method Based on
Adjoining Operation
In order to avoid the problem of infinite local am-
biguity, the previous works have adopted the fol-
lowing approaches: (1) a beam search strategy
(Collins and Roark, 2004; Roark, 2001; Roark,
2004), (2) limiting the allowable chains to those
actually observed in the treebank (Collins and
Roark, 2004), and (3) transforming the parse trees
with a selective left-corner transformation (John-
son and Roark, 2000) before inducing the al-
lowable chains and allowable triples (Collins and
Roark, 2004). The first and second approaches can
prevent the parser from infinitely producing partial
parse trees, but the parser has to produce partial
parse trees as shown in Figure 1. The local ambi-
guity still remains. In the third approach, no left
recursive structure exists in the transformed gram-
mar, but the parse trees defined by the grammar are
different from those defined by the original gram-
mar. It is not clear if partial parse trees defined by
the transformed grammar represent syntactic rela-
tions correctly.
As an approach to solve these problems, we
introduce an adjoining operation to incremental
parsing. Lombardo and Sturt (1997) and Kato
et al (2004) have already adopted this approach.
However, their methods have another problem that
their adjoining operations cannot preserve lexical
dependencies of partial parse trees. To solve this
problem, this section proposes a restricted version
of the adjoining operation.
3.1 Adjoining Operation
An adjoining operation is used in Tree-Adjoining
Grammar (Joshi, 1985). The operation inserts a
tree into another tree. The inserted tree is called an
auxiliary tree. Each auxiliary tree has a leaf called
a foot which has the same nonterminal symbol as
its root. An adjoining operation is defined as fol-
lows:
adjoining An adjoining operation splits a parse
tree ? at a nonterminal node ? and inserts an
auxiliary tree ? having the same nonterminal
symbol as ?, i.e., combines the upper tree of
? with the root of ? and the lower tree of ?
with the foot of ?.
We write a
?,?
(?) for the partial parse tree obtained
by adjoining ? to ? at ?.
We use simplest auxiliary trees, which consist
of a root and a foot.
As we have seen in Figure 1, Collins and
Roark?s parser produces partial parse trees such as
(c), (d) and (e). On the other hand, by using the
adjoining operation, our parser produces only the
partial parse tree (c). When a left-recursive struc-
ture is required to parse the sentence, our parser
adjoins it. In the example above, the parser adjoins
the auxiliary tree ?NP ? NP? to the partial parse
tree (c) when the word ?for? is read. This enables
42
WePRP*
NP S
describeVBP*
VP* NPa  method WePRP*
NP S
describeVBP*
VP* NP
a  method
adjoining
NP* WePRP*
NP S
describeVBP*
VP* NP
a  methodNP* PPforIN*
Figure 2: Adjoining operation
WePRP*
NP S
describeVBP*
VP* NPJohn  's WePRP*
NP S
describeVBP*
VP* NPadjoining NPJohn  's
We  describe  John  's We  describe  John  's
(a) (b)
WePRP*
NP S
describeVBP*
VP* NPNPJohn  's
We  describe  John  's  method
(c)
NN*method
Figure 3: Non-monotonic adjoining operation
the parser to attach the allowable chain ?PP ? IN
? for?. The parsing process is shown in Figure 2.
3.2 Adjoining Operation and Monotonicity
By using the adjoining operation, we avoid the
problem of infinite local ambiguity. However, the
adjoining operation cannot preserve lexical depen-
dencies of partial parse trees. Lexical dependency
is a kind of relation between words, which repre-
sents head-modifier relation. We can map parse
trees to sets of lexical dependencies by identifying
the head-child of each constituent in the parse tree
(Collins, 1999).
Let us consider the parsing process as shown
in Figure 3. The partial parse tree (a) is a can-
didate for the initial fragment ?We describe John
?s?. We mark each head-child with a special sym-
bol ?. We obtain three lexical dependencies ?We
? describe?, ?John ? ?s? and ??s ? describe?
from (a). When the parser reads the next word
?method?, it produces the partial parse tree (b) by
adjoining the auxiliary tree ?NP ? NP?. The par-
tial parse tree (b) does not have ??s ? describe?.
The dependency ??s ? describe? is removed when
the parser adjoins the auxiliary tree ?NP ? NP? to
(a). This example demonstrates that the adjoining
operation cannot preserve lexical dependencies of
partial parse trees.
Now, we define the monotonicity of the adjoin-
ing operation. We say that adjoining an auxiliary
tree ? to a partial parse tree ? at a node ? is mono-
tonic when dep(?) ? dep(a
?,?
(?)) where dep is
the mapping from a parse tree to a set of dependen-
cies. An auxiliary tree ? is monotonic if adjoining
? to any partial parse tree is monotonic.
We want to exclude any non-monotonic auxil-
iary tree from the grammar. For this purpose, we
restrict the form of auxiliary trees. In our frame-
work, all auxiliary trees satisfy the following con-
straint:
? The foot of each auxiliary tree must be the
head-child of its parent.
The auxiliary tree ?NP ? NP
?
? satisfies the con-
straint, while ?NP ? NP? does not.
3.3 Our Incremental Parser
Our incremental parser is based on a probabilistic
parsing model which assigns a probability to each
operation. The probability of a partial parse tree is
defined by the product of the probabilities of the
operations used in its construction. The probabil-
ity of attaching an allowable chain c to a partial
parse tree ? is approximated as follows:
P (c | ?) = P
root
(R | P,L,H, t
H
, w
H
,D)
?P
template
(c
?
| R,P,L,H)
?P
word
(w | c
?
, t
h
, w
h
)
where R is the root label of c, c
?
is the sequence
which is obtained by omitting the last element
from c and w is the last element of c. The proba-
bility is conditioned on a limited context of ?. P
is a set of the ancestor labels of R. L is a set of the
left-sibling labels of R. H is the head label in L.
w
H
and t
H
are the head word and head tag of H ,
respectively. D is a set of distance features. w
h
and t
h
are the word and POS tag modified by w,
respectively. The adjoining probability is approxi-
mated as follows:
P (? | ?) = P
adjoining
(? | P,L,H,D)
where ? is an auxiliary tree or a special symbol
nil, the nil means that no auxiliary tree is ad-
joined. The limited contexts used in this model
are similar to the previous methods (Collins and
Roark, 2004; Roark, 2001; Roark, 2004).
To achieve efficient parsing, we use a beam
search strategy like the previous methods (Collins
and Roark, 2004; Roark, 2001; Roark, 2004). For
each word position i, our parser has a priority
queue H
i
. Each queue H
i
stores the only N -best
43
Table 1: Parsing results
LR(%) LP(%) F(%)
Roark (2004) 86.4 86.8 86.6
Collins and Roark (2004) 86.5 86.8 86.7
No adjoining 86.3 86.8 86.6
Non-monotonic adjoining 86.1 87.1 86.6
Monotonic adjoining 87.2 87.7 87.4
partial parse trees. In addition, the parser discards
the partial parse tree ? whose probability P (?) is
less than the P
?
? where P
?
is the highest proba-
bility on the queue H
i
and ? is a beam factor.
4 Experimental Evaluation
To evaluate the performance of our incremental
parser, we conducted a parsing experiment. We
implemented the following three types of incre-
mental parsers to assess the influence of the ad-
joining operation and its monotonicity: (1) with-
out adjoining operation, (2) with non-monotonic
adjoining operation, and (3) with monotonic ad-
joining operation. The grammars were extracted
from the parse trees in sections 02-21 of the Wall
Street Journal in Penn Treebank. We identified the
head-child in each constituent by using the head
rule of Collins (Collins, 1999). The probabilistic
models were built by using the maximum entropy
method. We set the beam-width N to 300 and the
beam factor ? to 10
?11
.
We evaluated the parsing accuracy by using sec-
tion 23. We measured labeled recall and labeled
precision. Table 1 shows the results
2
. Our in-
cremental parser is competitive with the previous
ones. The incremental parser with the monotonic
adjoining operation outperforms the others. The
result means that our proposed constraint of auxil-
iary trees improves parsing accuracy.
5 Conclusion
This paper has proposed an incremental parser
based on an adjoining operation to solve the prob-
lem of infinite local ambiguity. The adjoining
operation causes another problem that the parser
cannot preserve lexical dependencies of partial
parse trees. To tackle this problem, we defined
2
The best results of Collins and Roark (2004)
(LR=88.4%, LP=89.1% and F=88.8%) are achieved when
the parser utilizes the information about the final punctuation
and the look-ahead. However, the parsing process is not
on a word-by-word basis. The results shown in Table 1 are
achieved when the parser does not utilize such informations.
the monotonicity of adjoining operation and re-
stricted the form of auxiliary trees to satisfy the
constraint of the monotonicity. Our experimental
result showed that the restriction improved the ac-
curacy of our incremental parser.
In future work, we will investigate the incre-
mental parser for head-final language such as
Japanese. Head-final language includes many in-
direct left-recursive structures. In this paper, we
dealt with direct left-recursive structures only. To
process indirect left-recursive structures, we need
to extend our method.
References
James Allen, George Ferguson, and Amanda Stent.
2001. An architecture for more realistic conver-
sational systems. In Proceedings of International
Conference of Intelligent User Interfaces, pages 1?
8.
Michael Collins and Brian Roark. 2004. Incremen-
tal parsing with the perceptron algorithm. In Pro-
ceedings of the 42nd Meeting of the Association for
Computational Linguistics (ACL?04), Main Volume,
pages 111?118, Barcelona, Spain, July.
Michael Collins. 1999. Head-Driven Statistical Mod-
els for Natural Language Parsing. Ph.D. thesis,
University of Pennsylvania.
Mark Johnson and Brian Roark. 2000. Compact
non-left-recursive grammars using the selective left-
corner transform and factoring. In Proceedings of
the 18th International Conference on Computational
Linguistics, pages 355?361, July.
Aravind K. Joshi. 1985. Tree adjoining grammars:
How much context sensitivity is required to provide
a reasonable structural description? In David R.
Dowty, Lauri Karttunen, and Arnold M. Zwicky, ed-
itors, Natural Language Parsing, pages 206?250.
Cambridge University Press.
Yoshihide Kato, Shigeki Matsubara, and Yasuyoshi In-
agaki. 2004. Stochastically evaluating the valid-
ity of partial parse trees in incremental parsing. In
Proceedings of the ACLWorkshop Incremental Pars-
ing: Bringing Engineering and Cognition Together,
pages 9?15, July.
Vincenzo Lombardo and Patrick Sturt. 1997. Incre-
mental processing and infinite local ambiguity. In
Proceedings of the 19th Annual Conference of the
Cognitive Science Society, pages 448?453.
Brian Roark. 2001. Probabilistic top-down parsing
and language modeling. Computational Linguistics,
27(2):249?276, June.
Brian Roark. 2004. Robust garden path parsing. Nat-
ural language engineering, 10(1):1?24.
44
Stochastically Evaluating the Validity of Partial Parse Trees in
Incremental Parsing
Yoshihide Kato1, Shigeki Matsubara2 and Yasuyoshi Inagaki3
Graduate School of International Development, Nagoya University 1
Information Technology Center, Nagoya University 2
Furo-cho, Chikusa-ku, Nagoya, 464-8601 Japan
Faculty of Information Science and Technology, Aichi Prefectural University 3
1522-3 Ibaragabasama, Kumabari, Nagakute-cho, Aichi-gun, 480-1198 Japan
yosihide@gsid.nagoya-u.ac.jp
Abstract
This paper proposes a method for evaluating the
validity of partial parse trees constructed in incre-
mental parsing. Our method is based on stochastic
incremental parsing, and it incrementally evaluates
the validity for each partial parse tree on a word-
by-word basis. In our method, incremental parser
returns partial parse trees at the point where the va-
lidity for the partial parse tree becomes greater than
a threshold. Our technique is effective for improv-
ing the accuracy of incremental parsing.
1 Introduction
Real-time spoken language processing systems,
such as simultaneous machine interpretation sys-
tems, are required to quickly respond to users? utter-
ances. To fulfill the requirement, the system needs
to understand spoken language at least incremen-
tally (Allen et al, 2001; Inagaki and Matsubara,
1995; Milward and Cooper, 1994), that is, to ana-
lyze each input sentence from left to right and ac-
quire the content.
Several incremental parsing methods have been
proposed to date (Costa et al, 2001; Haddock,
1987; Matsubara et al, 1997; Milward, 1995;
Roark, 2001). These methods construct candidate
partial parse trees for initial fragments of the input
sentence on a word-by-word basis. However, these
methods contain local ambiguity problems that par-
tial parse trees representing valid syntactic relations
can not be determined without using information
from the rest of the input sentence.
On the other hand, Marcus proposed a method
of deterministically constructing valid partial parse
trees by looking ahead several words (Marcus,
1980), while Kato et al proposed an incremental
parsing which delays the decision of valid partial
parse trees (Kato et al, 2000). However, it is hard to
say that these methods realize broad-coverage incre-
mental parsing. The method in the literature (Mar-
cus, 1980) uses lookahead rules, which are con-
structed by hand, but it is not clear whether broad
coverage lookahead rules can be obtained. The
incremental parsing in the literature (Kato et al,
2000), which is based on context free grammar, is
infeasible to deal with large scale grammar, because
the parser exhaustively searches all candidate partial
parse trees in top-down fashion.
This paper proposes a probabilistic incremental
parser which evaluates the validity of partial parse
trees. Our method extracts a grammar from a tree-
bank, and the incremental parsing uses a beam-
search strategy so that it realizes broad-coverage
parsing. To resolve local ambiguity, the parser in-
crementally evaluates the validity of partial parse
trees on a word-by-word basis, and delays the deci-
sion of which partial parse trees should be returned,
until the validity for the partial parse tree becomes
greater than a threshold. Our technique is effective
for improving the accuracy of incremental parsing.
This paper is organized as follows: The next
section proposes a probabilistic incremental parser.
Section 3 discusses the validity of partial parse tree
constructed in incremental parsing. Section 4 pro-
poses a method of incrementally evaluating the va-
lidity of partial parse tree. In section 5, we report an
experimental evaluation of our method.
2 TAG-based Incremental Parsing
Our incremental parsing is based on tree adjoining
grammar (TAG) (Joshi, 1985). This section pro-
poses a TAG-based incremental parsing method.
2.1 TAG for Incremental Parsing
Firstly, we propose incremental-parsing-oriented
TAG (ITAG). An ITAG comprises two sets of ele-
mentary trees just like TAG: initial trees and auxil-
iary trees. The difference between ITAG and TAG
is the form of elementary trees. Every ITAG ini-
tial tree is leftmost-expanded. A tree is leftmost-
expanded if it is of the following forms:
1. [t]X , where t is a terminal symbol and X is a
nonterminal symbol.
SNP VPPRPI
VPVB NPfound
NPDT NN
a
NNdime NPDT NNthe
NN
wood
Initial trees:1 2
5 7 8
10
VPVB NPfound
3 ADJP
PPIN NPin
NPNP* PPIN NPin
VPVP*
Auxiliary trees:1 2
NPDT NN
a
6 JJ NPDT NNthe
9 JJ
VPVBfound
4
Figure 1: Examples of ITAG elementary trees
2. [?X1 ? ? ?Xk]X , where ? is a leftmost expanded
tree, X1, . . . , Xk, X are nonterminal symbols.
On the other hand, every ITAG auxiliary tree is of
the following form:
[X??X1 ? ? ?Xk]X
where ? is a leftmost expanded tree and X ,
X1, . . . , Xk are nonterminal symbols. X? is called
a foot node. Figure 1 shows examples of ITAG ele-
mentary trees.
These elemental trees can be combined by using
two operations: substitution and adjunction.
substitution The substitution operation replaces a
leftmost nonterminal leaf of a partial parse tree
? with an initial tree ? having the same nonter-
minal symbol at its root. We write s? for the
operation of substituting ? and s?(?) for the
result of applying s? to ?.
adjunction The adjunction operation splits a par-
tial parse tree ? at a nonterminal node having
no nonterminal leaf, and inserts an auxiliary
tree ? having the same nonterminal symbol at
its root. We write a? for the operation of ad-
joining ? and a?(?) for the result of applying
a? to ?.
The substitution operation is similar to rule expan-
sion of top-down incremental parsing such as (Mat-
subara et al, 1997; Roark, 2001). Furthermore,
by introducing the adjunction operation to incre-
mental parsing, we can expect that local ambiguity
of left-recursive structures is decreased (Lombardo
and Sturt, 1997).
Our proposed incremental parsing is based on
ITAG. When i-th word wi is scanned, the parser
combines elementary trees for wi with partial parse
trees for w1 ? ? ?wi?1 to construct the partial parse
trees for w1 ? ? ?wi?1wi.
As an example, let us consider incremental pars-
ing of the following sentence by using ITAG shown
in Figure 1:
I found a dime in the wood. (1)
Table 1 shows the process of tree construction
for the sentence (1). When the word ?found? is
scanned, partial parse trees #3, #4 and #5 are con-
structed by applying substitution operations to par-
tial parse tree #2 for the initial fragment ?I?. When
the word ?in? is scanned, partial parse trees #12 and
#13 are constructed by applying adjunction opera-
tions to partial parse tree #10 for the initial frag-
ment ?I found a dime?. This example shows that
the ITAG based incremental parsing is capable of
constructing partial parse trees of initial fragments
for every word input.
2.2 ITAG Extraction from Treebank
Here, we propose a method for extracting an ITAG
from a treebank to realize broad-coverage incre-
mental parsing. Our method decomposes parse trees
in treebank to obtain ITAG elementary trees. The
decomposition is as follows:
? for each node ?1 having no left-sibling, if the
parent ?p has the same nonterminal symbol as
?1, split the parse tree at ?1 and ?p, and com-
bine the upper tree and the lower tree. ?1 of
intermediate tree is a foot node.
? for each node ?2 having only one left-sibling,
if the parent ?p does not have the same nonter-
minal symbol as the left-sibling ?1 of ?2, split
the parse tree at ?2.
? for the other node ? in the parse tree, split the
parse tree at ?.
For example, The initial trees ?1, ?2, ?5, ?7 ?8 and
?10 and the auxiliary tree ?2 are extracted from the
parse tree #18 in Table 1.
Our proposed tree extraction is similar to the TAG
extractions proposed in the literatures (Chen and
Vijay-Shanker, 2000; Chiang, 2003; Xia, 1999).
The main difference between these methods is the
position of nodes at which parse trees are split.
While the methods in the literatures (Chen and
Vijay-Shanker, 2000; Chiang, 2003; Xia, 1999) uti-
lize a head percolation rule to split the parse trees at
complement nodes, our method splits the parse trees
Table 1: Incremental parsing process of ?I found a dime in the wood.?
word # partial parse tree
1 s
I 2 [[[I]prp]npvp]s
found 3 [[[I]prp]np[[found]vbnp]vp]s
4 [[[I]prp]np[[found]vbnp adjp]vp]s
5 [[[I]prp]np[[found]vb]vp]s
a 6 [[[I]prp]np[[found]vb[[a]dtnn]np]vp]s
7 [[[I]prp]np[[found]vb[[a]dtjj nn]np]vp]s
8 [[[I]prp]np[[found]vb[[a]dtnn]npadjp]vp]s
9 [[[I]prp]np[[found]vb[[a]dtjj nn]npadjp]vp]s
dime 10 [[[I]prp]np[[found]vb[[a]dt[dime]nn]np]vp]s
11 [[[I]prp]np[[found]vb[[a]dt[dime]nn]npadjp]vp]s
in 12 [[[I]prp]np[[[found]vb[[a]dt[dime]nn]np]vp[[in]innp]pp]vp]s
13 [[[I]prp]np[[found]vb[[[a]dt[dime]nn]np[[in]innp]pp]np]vp]s
the 14 [[[I]prp]np[[[found]vb[[a]dt[dime]nn]np]vp[[in]in[[the]dtnn]np]pp]vp]s
15 [[[I]prp]np[[[found]vb[[a]dt[dime]nn]np]vp[[in]in[[the]dtjj nn]np]pp]vp]s
16 [[[I]prp]np[[found]vb[[[a]dt[dime]nn]np[[in]in[[the]dtnn]np]pp]np]vp]s
17 [[[I]prp]np[[found]vb[[[a]dt[dime]nn]np[[in]in[[the]dtjj nn]np]pp]np]vp]s
wood 18 [[[I]prp]np[[[found]vb[[a]dt[dime]nn]np]vp[[in]in[[the]dt[wood]nn]np]pp]vp]s
19 [[[I]prp]np[[found]vb[[[a]dt[dime]nn]np[[in]in[[the]dt[wood]nn]np]pp]np]vp]s
at left recursive nodes and nodes having left-sibling.
The elementary trees extracted by our method are of
the forms described in section 2.1, and can be com-
bined from left to right on a word-by-word basis.
The property is suitable for incremental parsing. On
the other hand, the elementary trees obtained by the
method based on head information does not neces-
sarily have this property 1.
2.3 Probabilistic ITAG
This section describes probabilistic ITAG (PITAG)
which is utilized by evaluating partial parse trees in
incremental parsing. PITAG assigns a probability
to the event that an elementary tree is combined by
substitution or adjunction with another tree.
We induce the probability by maximum likeli-
hood estimation. Let ? be an initial tree and X be
the root symbol of ?. The probability that ? is sub-
stituted is calculated as follows:
P (s?) = C(s?)?
???I(X) C(s??)
(2)
where C(s?) is the count of the number of times of
applying substitution s? in the treebank, and I(X)
is the set of initial trees whose root is labeled with
X .
1For example, the tree extraction based on head informa-
tion splits the parse tree #18 at the node labeled with dt to ob-
tain the elementary tree [a]dt for ?a?. However, the tree [a]dt
cannot be combined with the partial parse tree for ?I found?,
since substitution node labeled with dt exists in the initial tree
[dt[dime]nn]np for ?dime? and not the partial parse trees for ?I
found?.
Let ? be a auxiliary tree and X be the root symbol
of ?. The probability that ? is adjoined is calculated
as follows:
P (a?) = C(a?)C(X) (3)
where C(X) is the count of the number of occur-
rences of symbol X . The probability that adjunction
is not applied is calculated as follows:
P (nilX) = 1?
?
??A(X)
P (a?) (4)
where nilX means that the adjunction is not applied
to a node labeled with X , and A(X) is the set of all
auxiliary trees whose root is labeled X .
In this PITAG formalism, the probability that el-
ementary trees are combined at each node depends
only on the nonterminal symbol of that node 2.
The probability of a parse tree is calculated by the
product of the probability of the operations which
are used in construction of the parse tree. For ex-
ample, the probability of each operation is given as
shown in Table 2. The probability of the partial
parse tree #12, which is constructed by using s?1 ,
s?2 , s?5 , s?7 , nilNP and a?2 , is 1 ? 0.7 ? 0.3 ?
0.5? 0.7? 0.7 = 0.05145.
We write P (?) for the probability of a partial
parse tree ?.
2The PITAG formalism corresponds to SLG(1) in the liter-
ature (Carroll and Weir, 2003).
Table 2: Probability of operations
operation probability
s?1 1.0
s?2 0.7
s?7 , s?10 0.5
s?5 , s?8 0.3
s?4 , s?6 , s?9 0.2
s?3 0.1
a?1 0.3
a?2 0.7
nilNP 0.7
nilV P 0.3
2.4 Parsing Strategies
In order to improve the efficiency of the parsing, we
adapt two parsing strategies as follows:
? If two partial parse trees have the same se-
quence of nodes to which ITAG operations are
applicable, then the lower probability tree can
be safely discarded.
? The parser only keeps n-best partial parse trees.
3 Validity of Partial Parse Trees
This section gives some definitions about the valid-
ity of a partial parse tree. Before describing the va-
lidity of a partial parse tree, we define the subsump-
tion relation between partial parse trees.
Definition 1 (subsumption relation) Let ? and ?
be partial parse trees. Then we write ? ? ? , if
s?(?) = ? , for some initial tree ? or a?(?) = ? ,
for some auxiliary tree ?. Let ?? be the reflexive
transitive closure of ?. We say that ? subsumes ? ,
if ? ?? ? . 2
That ? subsumes ? means that ? is the result of ap-
plying a substitution or an adjunction to ?. Figure 2
shows the subsumption relation between the partial
parse trees constructed for the sentence (1).
If a partial parse tree for an initial fragment repre-
sents a syntactic relation correctly, the partial parse
tree subsumes the correct parse tree for the input
sentence. We say that such a partial parse tree is
valid. The validity of a partial parse tree is defined
as follows:
Definition 2 (valid partial parse tree) Let ? be a
partial parse tree and w1 ? ? ?wn be an input sen-
tence. We say that ? is valid for w1 ? ? ?wn if ? sub-
sumes the correct parse tree for w1 ? ? ?wn. 2
#1 I #2 #3 #6
#7
found a dime #10 #12 #14 #18
#19#16#13
in the wood
subsumption relation
#4 #8
#9
#11
#15
#17
#5
Figure 2: Subsumption relation between partial
parse trees
#1 I #2 #3 #6
#7
found a dime #10 #12 #14 #18
#19#16#13
in the wood
subsumption relation
#4 #8
#9
#11
#15
#17
valid partial parse tree#5
Figure 3: Valid partial parse trees
For example, assume that the #18 is correct parse
tree for the sentence (1). Then partial parse tree #3
is valid for the sentence (1), because #3 ?? #18. On
the other hand, partial parse tree #4 and #5 are not
valid for (1). Figure 3 shows the valid partial parse
trees for the sentence (1).
4 Evaluating the Validity of Partial Parse
Tree
The validity of a partial parse tree for an initial frag-
ment depends on the rest of the sentence. For ex-
ample, the validity of the partial parse trees #3, #4
and #5 depends on the remaining input that follows
the word ?found.? This means that the validity dy-
namically varies for every word input. We define a
conditional validity of partial parse tree:
V (? | w1 ? ? ?wj) =
?
??Sub(?,w1???wj) P (?)?
??T (w1???wj) P (?)
(5)
where ? is a partial parse tree for an initial frag-
ment w1 ? ? ?wi(i ? j), T (w1 ? ? ?wj) is the set of
constructed partial parse trees for the initial frag-
ment w1 ? ? ?wj and Sub(?,w1 ? ? ?wj) is the subset
of T (w1 ? ? ?wj) whose elements are subsumed by ?.
The equation (5) represents the validity of ? on the
condition w1 ? ? ?wj . ? is valid for input sentence
if and only if some partial parse tree for w1 ? ? ?wj
subsumed by ? is valid. The equation 5 is the ratio
of such partial parse trees to the constructed partial
parse trees.
4.1 Output Partial Parse Trees
Kato et al proposed a method of delaying the deci-
sion of which partial parse trees should be returned
as the output, until the validity of partial parse trees
are guaranteed (Kato et al, 2000). The idea of
delaying the decision of the output is interesting.
However, delaying the decision until the validity are
guaranteed may cause the loss of incrementality of
the parsing.
To solve the problem, in our method, the in-
cremental parser returns high validity partial parse
trees rather than validity guaranteed partial parse
trees.
When the j-th word wj is scanned, our incremen-
tal parser returns the following partial parse:
argmax{?:V (?,w1???wj)??}l(?) (6)
where ? is a threshold between [0, 1] and l(?) is
the length of the initial fragment which is yielded
by ?. The output partial parse tree is the one for
the longest initial fragment in the partial parse trees
whose validity are greater than a threshold ?.
4.2 An Example
Let us consider a parsing example for the sentence
(1). We assume that the threshold ? = 0.8.
Let us consider when the partial parse tree
#3, which is valid for (1), is returned as output.
When the word ?found? is scanned, partial parse
trees #3, #4 and #5 are constructed. That is,
T (I found) = {#3,#4,#5}. As shown in Figure
2, Sub(#3, I found) = {#3}. Furthermore,
P (#3) = 0.7, P (#4) = 0.1 and P (#5) = 0.2.
Therefore, V alidity(#3, I found) =
0.7/(0.7 + 0.1 + 0.2) = 0.7. Because
V alidity(#3, I found) < ?, partial parse tree
#3 is not returned as the output at this point. The
parser only keeps #3 as a candidate partial parse
tree.
When the next word ?a? is scanned, partial parse
trees #6, #7, #8 and #9 are constructed, where
P (#6) = 0.21, P (#7) = 0.14, P (#8) = 0.03 and
P (#9) = 0.02. Sub(#3, I found a) = {#6,#7}.
Therefore, V alidity(#3, I found a) = (0.21 +
0.14)/(0.21+0.14+0.03+0.02) = 0.875. Because
V alidity(#3, I found a) ? ?, partial parse tree #3
is returned as the output.
Table 3 shows the output partial parse tree for ev-
ery word input.
Our incremental parser delays the decision of the
output as shown in this example.
Table 3: Output partial parse trees
input word output partial parse tree
I #2
found
a #3
dime #10
in #12
the
wood #18
5 Experimental Results
To evaluate the performance of our proposed
method, we performed a parsing experiment. The
parser was implemented in GNU Common Lisp on a
Linux PC. In the experiment, the inputs of the incre-
mental parser are POS sequences rather than word
sequences. We used 47247 initial trees and 2931
auxiliary trees for the experiment. The elementary
trees were extracted from the parse trees in sec-
tions 02-21 of the Wall Street Journal in Penn Tree-
bank (Marcus et al, 1993), which is transformed
by using parent-child annotation and left factoring
(Roark and Johnson, 1999). We set the beam-width
at 500.
The labeled precision and recall of the parsing
are 80.8% and 78.5%, respectively for the section
23 in Penn Treebank. We used the set of sentences
for which the outputs of the incremental parser are
identical to the correct parse trees in the Penn Tree-
bank. The number of these sentences is 451. The
average length of these sentences is 13.5 words.
We measured the delays and the precisions for va-
lidity thresholds 0.5, 0.6, 0.7, 0.8, 0.9 and 1.0.
We define the degree of delay as follows: Let
s = w1 ? ? ?wn be an input sentence and oj(s) be
the partial parse tree that is the output when the j-th
word wj is scanned. We define the degree of delay
when j-th word is scanned as follows:
D(j, s) = j ? l(oj(s)) (7)
We define maximum delay Dmax(s) and average
delay Dave(s) as follows:
Dmax(s) = max1?j?nD(j, s) (8)
Dave(s) = 1n
n?
j=1
D(j, s) (9)
The precision is defined as the percentage of valid
partial parse trees in the output.
Moreover, we measured the precision of the pars-
ing whose delay is always 0 and which returns the
Table 4: Precisions and delays
precision(%) Dmax Dave
? = 1.0 100.0 11.9 6.4
? = 0.9 97.3 7.5 2.9
? = 0.8 95.4 6.4 2.2
? = 0.7 92.5 5.5 1.8
? = 0.6 88.4 4.5 1.3
? = 0.5 83.0 3.4 0.9
baseline 73.6 0.0 0.0
0
2
4
6
8
10
12
14
70 75 80 85 90 95 100
delay(number of words)
precision(%)
Dmax
3
33333
3
Dave
?
?????
?
baseline
2
2
Figure 4: Relation between precision and delay
partial parse tree having highest probability. We call
it the parsing baseline.
Table 4 shows the precisions and delays. Figure
4 illustrates the relation between the precisions and
delays.
The experimental result demonstrates that there
is a precision/delay trade-off. Our proposed method
increases the precision in comparison with the base-
line, while returning the output is delayed. When
? = 1, it is guaranteed that the output partial parse
trees are valid, that is, our method is similar to the
method in the literature (Kato et al, 2000). In com-
parison with this case, our method when ? < 1 dra-
matically decreases the delay.
Although the result does not necessarily demon-
strates that our method is the best one, it achieves
both high-accuracy and short-delay to a certain ex-
tent.
6 Concluding Remarks
In this paper, we have proposed a method of evalu-
ating the validity that a partial parse tree constructed
in incremental parsing becomes valid. The method
is based on probabilistic incremental parsing. When
a word is scanned, the method incrementally calcu-
lates the validity for each partial parse tree and re-
turns the partial parse tree whose validity is greater
than a threshold. Our method delays the decision of
which partial parse tree should be returned.
To evaluate the performance of our method, we
conducted a parsing experiment using the Penn
Treebank. The experimental result shows that our
method improves the accuracy of incremental pars-
ing.
The experiment demonstrated a precision/delay
trade-off. To evaluate overall performance of in-
cremental parsing, we would like to investigate a
single measure into which delay and precision are
combined.
Acknowledgement
This work is partially supported by the Grant-in-Aid
for Scientific Research of the Ministry of Education,
Science, Sports and Culture, Japan (No. 15300044),
and The Tatematsu Foundation.
References
J. Allen, G. Ferguson, and A. Stent. 2001. An Ar-
chitecture for More Realistic Conversational Sys-
tems. In Proceedings of International Confer-
ence of Intelligent User Interfaces, pages 1?8.
J. Carroll and D. Weir. 2003. Encoding Frequency
Information in Stochastic Parsing Models. In
R. Bod, R. Scha, and K. Sima?an, editors, Data-
Oriented Parsing, pages 43?60. CSLI Publica-
tions, Stanford.
J. Chen and K. Vijay-Shanker. 2000. Automated
Extraction of TAGs from the Penn Treebank. In
Proceedings of the 6th International Workshop on
Parsing Technologies, pages 65?76.
D. Chiang. 2003. Statistical Parsing with an Auto-
matically Extracted Tree Adjoining Grammar. In
R. Bod, R. Scha, and K. Sima?an, editors, Data-
Oriented Parsing, pages 299?316. CSLI Publica-
tions, Stanford.
F. Costa, V. Lombardo, P. Frasconi, and Soda G.
2001. Wide Coverage Incremental Parsing by
Learning Attachment Preferences. In Proceed-
ings of the 7th Congress of the Italian Association
for Artificial Intelligence, pages 297?307.
N. J. Haddock. 1987. Incremental Interpretation
and Combinatory Categorial Grammar. In Pro-
ceedings of the 10th International Joint Confer-
ence on Artificial Intelligence, pages 661?663.
Y. Inagaki and S. Matsubara. 1995. Models for In-
cremental Interpretation of Natural Language. In
Proceedings of the 2nd Symposium on Natural
Language Processing, pages 51?60.
A. K. Joshi. 1985. Tree Adjoining Grammar: How
Much Context-Sensitivity is required to provide
reasonable structural descriptions? In D. R.
Dowty, L. Karttunen, and A. Zwicky, editors,
Natural Language Parsing, pages 206?250. Cam-
bridge University Press, Cambridge.
Y. Kato, S. Matsubara, K. Toyama, and Y. Ina-
gaki. 2000. Spoken Language Parsing based on
Incremental Disambiguation. In Proceedings of
the 6th International Conference on Spoken Lan-
guage Processing, volume 2, pages 999?1002.
V. Lombardo and P. Sturt. 1997. Incremental Pro-
cessing and Infinite Local Ambiguity. In Pro-
ceedings of the 19th Annual Conference of the
Cognitive Science Siciety, pages 448?453.
M. P. Marcus, B. Santorini, and M. A.
Marcinkiewicz. 1993. Building a Large Anno-
tated Corpus of English: the Penn Treebank.
Computational Linguistics, 19(2):310?330.
M Marcus. 1980. A Theory of Syntactic Recog-
nition for Natural Language. MIT Press, Cam-
brige, MA.
S. Matsubara, S. Asai, K. Toyama, and Y. Inagaki.
1997. Chart-based Parsing and Transfer in In-
cremental Spoken Language Translation. In Pro-
ceedings of the 4th Natural Language Processing
Pacific Rim Symposium, pages 521?524.
D. Milward and R. Cooper. 1994. Incremental In-
terpretation: Applications, Theory, and Relation-
ship to Dynamic Semantics. In Proceedings of
the 15th International Conference on Computa-
tional Linguistics, pages 748?754.
D. Milward. 1995. Incremental Interpretation of
Categorial Grammar. In Proceedings of the 7th
Conference of European Chapter of the Associ-
ation for Computational Linguistics, pages 119?
126.
B. Roark and M. Johnson. 1999. Efficient Prob-
abilistic Top-down and Left-corner Parsing. In
Proceedings of the 37th Annual Meeting of the
Association for Computational Linguistics, pages
421?428.
B. Roark. 2001. Probabilistic Top-Down Parsing
and Language Modeling. Computational Lin-
guistics, 27(2):249?276.
F. Xia. 1999. Extracting Tree Adjoining Gram-
mars from Bracketed corpora. In Proceedings of
the 5th Natural Language Processing Pacific Rim
Symposium, pages 398?403.
Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,
pages 1186?1196, Dublin, Ireland, August 23-29 2014.
Japanese Word Reordering Integrated with Dependency Parsing
Kazushi Yoshida
1,a)
Tomohiro Ohno
2,b)
Yoshihide Kato
3,c)
Shigeki Matsubara
1,d)
1
Graduate School of Information Science, Nagoya University, Japan
2
Information Technology Center, Nagoya University, Japan
3
Information & Communications, Nagoya University, Japan
a)
yoshida@db.ss.is.nagoya-u.ac.jp
b)
ohno@nagoya-u.jp
c)
yoshihide@icts.nagoya-u.ac.jp
d)
matubara@nagoya-u.jp
Abstract
Although Japanese has relatively free word order, Japanese word order is not completely arbitrary
and has some sort of preference. Since such preference is incompletely understood, even native
Japanese writers often write Japanese sentences which are grammatically well-formed but not
easy to read. This paper proposes a method for reordering words in a Japanese sentence so
that the sentence becomes more readable. Our method can identify more suitable word order
than conventional word reordering methods by concurrently performing dependency parsing and
word reordering instead of sequentially performing the two processing steps. As the result of an
experiment on word reordering using newspaper articles, we confirmed the effectiveness of our
method.
1 Introduction
Japanese has relatively free word order, and thus Japanese sentences which make sense can be written
without having a strong awareness of word order. However, Japanese word order is not completely
arbitrary and has some sort of preference. Since such preference is incompletely understood, even native
Japanese writers often write Japanese sentences which are grammatically well-formed but not easy to
read. The word reordering of such sentences enables the readability to be improved.
There have been proposed some methods for reordering words in a Japanese sentence so that the
sentence becomes easier to read (Uchimoto et al., 2000; Yokobayashi et al., 2004). In addition, there
exist a lot of researches for estimating appropriate word order in various languages (Filippova and Strube,
2007; Harbusch et al., 2006; Kruijff et al., 2001; Ringger et al., 2004; Shaw and Hatzivassiloglou, 1999).
Although most of these previous researches used syntactic information, the sentences they used there
were what had been previously parsed. It is a problem that word reordering suffers the influence of
parsing errors. Furthermore, as the related works, there are various researches on word reordering for
improving the performance of statistical machine translation (Goto et al., 2012; Elming, 2008; Ge, 2010;
Christoph and Hermann, 2003; Nizar, 2007). These researches consider information as to both a source
language and a target language to handle word order differences between them. Therefore, their problem
setting is different from that for improving the readability of a single language.
This paper proposes a method for reordering words in a Japanese sentence so that the sentence becomes
easier to read for revision support. Our proposed method concurrently performs dependency parsing
and word reordering for an input sentence of which the dependency structure is still unknown. Our
method can identify more suitable word order than conventional word reordering methods because it
can concurrently consider the preference of both word order and dependency. An experiment using
newspaper articles showed the effectiveness of our method.
2 Word Order and Dependency in Japanese Sentences
There have been a lot of researches on Japanese word order in linguistics (for example, Nihongo Kijutsu
Bunpo Kenkyukai, 2009; Saeki, 1998), which have marshalled fundamental contributing factors which
This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer
are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/
1186
naganen(for years)
sekaiju-no(all over the world)
hitobito-ga(people)
torikun-de-ki-ta(have tackled)
kare-ga(He)
mondai-wo(theproblem)
tsuini(finally)
S1 (inappropriate word order)
kaiketsu-shi-ta(resolved)
?He finally resolved the problem that people all over the world have tackled for years.?
S2 (appropriate word order)
naganen(for years)
sekaiju-no(all over the world)
hitobito-ga(people)
torikun-de-ki-ta(have tackled)
kare-ga(He)
mondai-wo(theproblem)
tsuini(finally) kaiketsu-shi-ta(resolved)
Figure 1: Example of inappropriate/appropriate word order
decide the appropriate word order in detail. In a Japanese sentence, a predicate of the main clause is
fundamentally placed in last position, and thus, case elements, adverbial elements, or subordinate clauses
are located before it. In addition, case elements are basically placed in the order of a nominative, a dative
and an accusative. However, the basic order of case elements is often changed by being influenced from
grammatical and discourse factors. For example, it is pointed out that a long case element has strong
preference to be located at the beginning of a sentence even if the element is not nominative, as shown
in Figure 1.
In Figure 1, a box and an arrow express a bunsetsu
1
and a dependency relation respectively. Both the
sentences S1 and S2 have the same meaning which is translated as ?He finally resolved the problem that
people all over the world have tackled for years? in English. The difference between S1 and S2 is just in
their word orders in Japanese.
The word order of S1 is more difficult to read than that of S2 because the distance between the bun-
setsu ?kare-ga (He)? and its modified bunsetsu ?kaiketsu-shi-ta (resolved)? is large and thus the loads on
working memory become large. This example suggests that if the dependency structure of S1 is iden-
tified, that information is useful to reorder the word order of S1 to that of S2 so that it becomes easier
to read. In fact, most of the conventional word reordering methods have reordered words using the pre-
viously parsed dependency structure. However, the word order of S1 is thought to be more difficult to
parse than that of S2 because dependency parsers are usually trained on syntactically annotated corpora
in which sentences have the appropriate word order such as that in S2. This is why it is highly possible
that dependency parsing can achieve a higher accuracy by changing the word order of S1 to that of S2 in
advance.
The above observations indicate that word reordering and dependency parsing depend on each other.
Therefore, we consider it is more desirable to concurrently perform the two processings than to sequen-
tially perform them.
3 Word Reordering Method
In our method, a sentence, on which morphological analysis and bunsetsu segmentation have been per-
formed, is considered as the input
2
. We assume that the input sentence might have unsuitable word order,
1
Bunsetsu is a linguistic unit in Japanese that roughly corresponds to a basic phrase in English. A bunsetsu consists of one
independent word and zero or more ancillary words. A dependency relation in Japanese is a modification relation in which a
modifier bunsetsu depends on a modified bunsetsu. That is, the modifier bunsetsu and the modified bunsetsu work as modifier
and modifyee, respectively.
2
In order to focus attention on the comparison between our method and the conventional method, we assumed the input on
which the lower layer processings than dependency parsing have been performed. Even if morphological analysis and bunsetsu
segmentation are automatically performed on input sentences which have unsuitable word order, we can expect the accuracies
1187
which is not easy to read but grammatically well-formed. Our method identifies the suitable word order
which is easy to read by concurrently performing dependency parsing.
The simultaneous performing of dependency parsing and word reordering is realized by searching for
the maximum-likelihood pattern of word order and dependency structure for the input sentence. Note our
method reorders bunsetsus in a sentence without paraphrasing and does not reorder morphemes within a
bunsetsu.
3.1 Probabilistic Model for Word Reordering
When a sequence of bunsetsus in an input sentence B = b
1
? ? ?b
n
is provided, our method identifies the
structure S which maximizes P (S|B). The structure S is defined as a tuple S = ?O,D? where O =
{o
1,2
, o
1,3
, ? ? ? , o
1,n
, ? ? ? , o
i,j
, ? ? ? , o
n?2,n?1
, o
n?2,n
, o
n?1,n
} is the word order pattern after reordering
and D = {d
1
, ? ? ? , d
n?1
} is dependency structure. Here, o
i,j
(1 ? i < j ? n) expresses the order
between b
i
and b
j
after reordering. o
i,j
is 1 if b
i
is located before b
j
, and is 0 otherwise. In addition, d
i
expresses the dependency relation whose modifier bunsetsu is b
i
.
P (S|B) for a S = ?O,D? is calculated as follows.
P (S|B) = P (O,D|B)
=
?
P (O|B) ? P (D|O,B) ? P (D|B) ? P (O|D,B) (1)
Formula (1) is obtained for the product of the following two formulas. According to the probability
theory, the calculated result of Formula (1) is equal to those of Formulas (2) and (3). However, in practice,
since each factor in the formulas is estimated based on the corpus used for training, the calculated results
of these formulas are different from each other. We use Formula (1) to estimate P (S|B) by using both
values of P (D|O,B) and P (O|D,B). In fact, we pre-experimentally confirmed that the calculated
result of Formula (1) was better than those of the others.
P (O,D|B) = P (O|B) ? P (D|O,B) (2)
P (O,D|B) = P (D|B) ? P (O|D,B) (3)
Assuming that order o
i,j
between two bunsetsus is independent of that between other two bunsetsus
and that each dependency relation d
i
is independent of the others, each factor in Formula (1) can be
approximated as follows:
P (O|B)
?
=
n?1
?
i=1
n
?
j=i+1
P (o
i,j
|B) (4)
P (D|O,B)
?
=
n?1
?
i=1
P (d
i
|O,B) (5)
P (D|B)
?
=
n?1
?
i=1
P (d
i
|B) (6)
P (O|D,B)
?
=
n?1
?
i=1
n
?
j=i+1
P (o
i,j
|D,B) (7)
where P (o
i,j
|B) is the probability that the order between b
i
and b
j
is o
i,j
whenB is provided, P (d
i
|O,B)
is the probability that the dependency relation whose modifier bunsetsu is b
i
is d
i
when the sentence
generated by reordering B according to O is provided, P (d
i
|B) is the probability that the dependency
relation whose modifier bunsetsu is b
i
is d
i
when B is provided, and P (o
i,j
|D,B) is the probability
that the order between b
i
and b
j
is o
i,j
when B where the dependency relation is D is provided. These
probabilities are estimated by the maximum entropy method.
remain comparatively high. This is because their processings use mainly local information.
1188
To estimate P (d
i
|O,B), we used the features used in Uchimoto et al. (1999) except when eliminating
features about Japanese commas (called toten, which is a kind of punctuation) and quotation marks.
To estimate P (d
i
|B), we used the features which can be obtained without information about the order
of input bunsetsus among the features used in estimating P (d
i
|O,B). To estimate P (o
i,j
|D,B), if b
i
and b
j
modifies the same bunsetsu, we used the features used in Uchimoto et al. (2000), except when
eliminating features about parallel relations and semantic features. Otherwise, we used the features left
after eliminating features about modified bunsetsus from those used in the above-mentioned case. To
estimate P (o
i,j
|B), we used the features which can be obtained without dependency information among
the features used to estimate P (O
i,j
|D,B).
3.2 Search Algorithm
Since there are a huge number of the structures S = ?O,D? which are theoretically possible for an input
sentence B, an efficient algorithm is desired. However, since O and D are dependent on each other,
it is difficult to find the optimal structure efficiently. In our research, we extend CYK algorithm used
in conventional dependency parsing to efficiently find the suboptimal S = ?O,D? which maximizes
P (S|B) efficiently.
Our research assumes that an input sentence, which is grammatically well-formed, is reordered without
changing the meaning so that the sentence becomes much easier to read. From this assumption, we can
use following conditions for efficient search:
1. The dependency structure of an input sentence should satisfy the following Japanese syntactic con-
straints under the input word order:
? No dependency is directed from right to left.
? Dependencies don?t cross each other.
? Each bunsetsu, except the last one, depends on only one bunsetsu.
2. Even after the words are reordered, the dependency structure should satisfy the above-mentioned
Japanese syntactic constraints under the changed word order.
3. The dependency structures of a sentence before and after reordering should be identical.
Using the condition 1 and the condition 3, we can narrow down the search space of D to dependency
structures that satisfy Japanese syntactic constraints under the input word order. Furthermore, the search
space of O can be narrowed down to the word order patterns derived from the above narrowed depen-
dency structures based on the conditions 2 and 3. That is, after dependency structures possible for an
input sentence are narrowed down, we just have to find the word order patterns after reordering so that
each of the dependency structures is maintained and satisfies the Japanese syntactic constraints even
under the changed word order.
On the other hand, it is well known that CYK algorithm can efficiently find the optimal dependency
structure which satisfies Japanese syntactic constraints. Therefore, in our research, we have extended the
CYK algorithm for the conventional dependency parsing so that it can find the suboptimal D and O from
among the dependency structures and word order patterns which satisfy the conditions 1, 2 and 3.
3.2.1 Word Reordering Algorithm
Algorithm 1 shows our word reordering algorithm. In our algorithm, the n?n triangular matrixM
i,j
(1 ?
i ? j ? n) such as the left-side figure in Figure 2 is prepared for an input sentence consisting of n
numbers of bunsetsus. M
i,j
, the element of the triangular matrix M in the i-th row and j-th column, is
filled by argmax
S
i,j
P (S
i,j
|B
i,j
), which is the maximum-likelihood structure for an input subsequence
B
i,j
= b
i
? ? ? b
j
. In this section, for convenience of explanation, we represent S
i,j
as a sequence of
dependency relations d
x
(i ? x ? j). For example, S
i,j
= d
i
d
i+1
? ? ? d
0
j
means that the first bunsetsu
is b
i
, the second is b
i+1
, ? ? ? , the last is b
j
, and the dependency structure is {d
i
, d
i+1
, ? ? ? , d
j?1
}. Here,
if we need to clearly specify the modified bunsetsu, we represent the dependency relation that bunsetsu
1189
Algorithm 1 word reordering algorithm
1: input B
1,n
= b
1
? ? ? b
n
// input sentence
2: set M
i,j
(1 ? i ? j ? n) // triangular matrix
3: set C
i,j
(1 ? i ? j ? n) // set of structure candidates
4: for i = 1 to n do
5: M
i,i
= d
0
i
6: end for
7: for d = 1 to n? 1 do
8: for i = 1 to n? d do
9: j = i+ d
10: for k = i to j ? 1 do
11: C
i,j
= C
i,j
? ConcatReorder(M
i,k
,M
k+1,j
)
12: end for
13: M
i,j
= argmax
S
i,j
?C
i,j
P (S
i,j
|B
i,j
)
14: end for
15: end for
16: return M
1,n
Candidates generated by 
?By the concatenating process
?By the reordering process
M1,1= M1,2= M1,3= M1,4
M2,2= M2,3= M2,4
M3,3= M3,4=
M4,4=
2 2 3
3 4
4
Candidates generated by 
?By the concatenating process
2 3 4
23 4
? By the reordering process
2 3 4
is filled by the structure which maximizes among the following candidates.
Candidate 1:
Candidate 3:
Candidate 2:
? means that is located  before and depends on . For example, i j
?is filled by the maximum-likelihood 
structure for a subsequence from to .
3
1 1 2 2 31
No candidate is generated because has no child in .2 31 means .
by moving after , which is the first child of in 
Figure 2: Execution example of our search algorithm
b
x
modifies b
y
as d
y
x
. In addition, d
0
j
means that the last bunsetsu of the subsequence don?t modify any
bunsetsu.
First, the statements of the lines 4 to 6 fill each of diagonal elements M
i,i
(1 ? i ? n) with d
0
i
. Next,
the statements of the lines 7 to 15 fill M
i,j
in turn toward the upper right M
1,n
along the diagonal line,
starting from the diagonal elements M
i,i
. The maximum-likelihood structure which should fill an M
i,j
is found as follows:
The statements of the lines 10 to 12 repeat the process of generating candidates of the maximum-
likelihood structure from M
i,k
and M
k+1,j
by the function ConcatReorder, and adding them to the set
of structure candidates C
i,j
. The function ConcatReorder takes two arguments ofM
i,k
andM
k+1,j
and
returns the set of candidates of the maximum-likelihood structure which should fill M
i,j
. The function
ConcatReorder is composed of two processes: concatenating process and reordering process. First,
the concatenating process generates a candidate by simply concatenating M
i,k
and M
k+1,j
in turn about
the word order and connecting M
i,k
and M
k+1,j
by the dependency relation between the last bunsetsus
of them about the dependency structure, without changing the internal structure of each of them. For
example, whenM
i,k
= d
i
d
i+1
? ? ? d
k?1
d
0
k
andM
k+1,j
= d
k+1
d
k+2
? ? ? d
j?1
d
0
j
are given as the argument,
the concatenating process generates ?d
i
d
i+1
? ? ? d
k?1
d
j
k
d
k+1
d
k+2
? ? ? d
j?1
d
0
j
.?
1190
Second, the reordering process generates candidates by reordering words in the candidate generated
by the concatenating process. The reordering is executed on the following conditions. The first condition
is that the dependency structure is maintained and satisfies the Japanese syntactic constraints even under
the changed word order. The second condition is that the order of any two words within each of M
i,k
and M
k+1,j
is maintained. Concretely, the first reordered candidate is generated by moving M
i,k
after
the first (leftmost) child
3
of the last bunsetsu of M
k+1,j
among the children in M
k+1,j
. Then, the sec-
ond reordered candidate is generated by moving M
i,k
after the second child. The reordering process is
continued until the last reordered candidate is generated by moving M
i,k
after the last child. That is, the
number of candidates generated by the reordering process is equal to the number of children of the last
bunsetsu in M
k+1,j
. For example, when M
i,k
= d
i
d
i+1
? ? ? d
k?1
d
0
k
and M
k+1,j
= d
j
k+1
d
j
k+2
? ? ? d
j
j?1
d
0
j
,
which means all bunsetsus except the last one depend on the last one, are given, the reordering
process generates the following j ? k? 1 candidates: ?d
j
k+1
d
i
d
i+1
? ? ? d
k?1
d
j
k
d
j
k+2
d
j
k+3
? ? ? d
j
j?1
d
0
j
,?
?d
j
k+1
d
j
k+2
d
i
d
i+1
? ? ? d
k?1
d
j
k
d
j
k+3
d
j
k+4
? ? ? d
j
j?1
d
0
j
,? . . ., and ?d
j
k+1
d
j
k+2
? ? ? d
j
j?1
d
i
d
i+1
? ? ? d
k?1
d
j
k
d
0
j
.?
Therefore, in this case, the function ConcatReorder finally returns the set of candidates of which size
is j?k, which includes the candidates generated by the reordering process and a candidate generated by
the concatenating process. Next, in the line 13, our algorithm fills in argmax
S
i,j
?C
i,j
P (S
i,j
|B
i,j
) which
is the maximum-likelihood structure for a subsequence B
i,j
on M
i,j
.
Finally, our algorithm outputs M
1,n
as the maximum-likelihood structure of word order and depen-
dency structure for the input sentence.
Note that if the function ConcatReorder is changed to the function Concat in the line 11, our algorithm
becomes the same as CYK algorithm used in the conventional dependency parsing. The functionConcat
takes two arguments of M
i,k
and M
k+1,j
and generates a candidate of the maximum-likelihood structure
which should fill M
i,j
by the same way as the concatenating process in the function ConcatReorder.
Then, the function Concat returns the set which has the generated candidate as a element, of which size
is 1.
3.2.2 Execution Example of Word Reordering Algorithm
Figure 2 represents an example of execution of our word reordering algorithm in n = 4. The left side
of Figure 2 represents the triangle diagram which has 4 ? 4 dimensions. The elements of the triangle
diagram M
1,1
,M
2,2
,M
3,3
,M
4,4
,M
1,2
,M
2,3
,M
3,4
, and M
1,3
have already been filled in turn, and M
2,4
is being filled. The right side of Figure 2 shows the process of calculating the maximum-likelihood
structure which should fill M
2,4
. First, in the loop from the line 10 to the line 12 in Algorithm 1,
two structure candidates are generated by ConcatReorder(M
2,2
,M
3,4
). The candidate 1 is generated
by the concatenating process, that is, by simply concatenating M
2,2
and M
3,4
and connecting the last
bunsetsu of M
2,2
and that of M
3,4
. The candidate 2 is generated by the reordering process, that is, by
moving M
2,2
after b
3
, which is the first child of b
4
in M
3,4
. Second, the candidate 3 is generated by
the concatenating process in ConcatReorder(M
2,3
,M
4,4
). On the other hand, the reordering process in
ConcatReorder(M
2,3
,M
4,4
) generates no candidates because b
4
has no child inM
4,4
. Among the three
structures generated in the above way, the structure which maximizes P (S
2,4
|B) = P (O
2,4
, D
2,4
|B
2,4
)
fills M
2,4
.
4 Experiment
To evaluate the effectiveness of our method, we conducted an experiment on word reordering by using
Japanese newspaper articles.
4.1 Outline of Experiment
In the experiment, as the test data, we used sentences generated by only changing the word order of
newspaper article sentences in Kyoto Text Corpus (Kurohashi and Nagao, 1998), maintaining the depen-
dency structure. That is, we artificially generated sentences which made sense but were not easy to read,
3
When b
i
depends on b
j
, we call b
i
as a child of b
j
. Furthermore, if b
j
has more than or equal to one child, the children are
numbered from left to right based on their positions.
1191
kokkai-wo(the Diet)
toot-ta
(passed)
ato-demo(Even after)
seron-chosa-de-wa(according to opinion polls)
shohi-ze-zoze-ga(the consumption tax hike bill)
zoze-hantai-ga(opposing views to the bill)
Original sentence in newspaper articles (correct word order)
taise-da(are in majority)
?Even after the Diet passed the consumption tax hike bill,according to opinion polls opposing views to the bill are in majority.?
Test data (input sentence)
test data generation
kokkai-wo(the Diet)
toot-ta
(passed)
ato-demo(Even after)
seron-chosa-de-wa(according to opinion polls)
shohi-ze-zoze-ga(the consumption tax hike bill)
zoze-hantai-ga(opposing views to the bill)
taise-da(are in majority)
Figure 3: Example of test data generation
in order to focus solely on problems caused by unsuitable word order. Figure 3 shows an example of the
test data generation. The generation procedure is as follows:
1. Find a bunsetsu modified by multiple bunsetsus from the sentence end.
2. Change randomly the order of the sub-trees which modify such bunsetsu.
3. Iterate 1 and 2 until reaching the beginning of the sentence.
In Figure 3, the bunsetsus ?taise-da (are in the majority)? and ?toot-ta (passed)? are found as bunsetsus
modified by multiple bunsetsus. For example, when ?toot-ta (passed)? is found, the order of ?shohi-
ze-zoze-ga (the consumption tax hike bill)? and ?kokkai-wo (the Diet)? is randomly changed. In this
experiment, all Japanese commas (toten) in a sentence, and sentences which have quotation marks were
removed.
In this way, we artificially generated 865 sentences (7,620 bunsetsus) from newspaper articles of Jan.
9 in Kyoto Text Corpus and used them as the test data. As the training data, we used 7,976 sentences in 7
days? newspaper articles (Jan. 1, 3-8). Here, we used the maximum entropy method tool (Zhang, 2008)
with the default options except ?-i 1000.?
In the evaluation of word reordering, we obtained the following two measurements, which are defined
by Uchimoto et al. (2000):
? complete agreement: the percentage of the sentences in which all words? order completely agrees
with that of the original sentence.
? pair agreement: the percentage of the pairs of bunsetsus whose word order agrees with that in the
original sentence. (For example, in Figure 3, if the word order of the input sentence is not changed
after reordering, the pair agreement is 52.4% (= 11/
7
C
2
) because the 11 pairs out of the
7
C
2
pairs
are the same as those in the original sentence.)
In the evaluation of dependency parsing, we obtained the dependency accuracy (the percentage of
correctly analyzed dependencies out of all dependencies) and sentence accuracy (the percentage of
the sentences in which all the dependencies are analyzed correctly), which are defined by Sekine et al.
(2000).
For comparison, we established two baselines. Both of the baselines execute the dependency pars-
ing primarily, and then, perform the word reordering by using the conventional word reordering method
1192
Table 1: Experimental results (word reordering)
pair agreement complete agreement
our method 77.3% (30,190/38,838) 25.7% (222/865)
baseline 1 75.4% (29,279/38,838)
*
23.8% (206/865)
baseline 2 74.8% (29,067/38,838)
*
23.5% (203/865)
no reordering 61.5% (23,886/38,838)
*
8.0% (69/865)
*
Note that the agreements followed by * differ signifi-
cantly from those of our method (p < 0.05).
Table 2: Experimental results (dependency parsing)
dependency accuracy sentence accuracy
our method 78.4% (5,293/6,755) 35.3% (305/865)
baseline 1 79.2% (5,350/6,755) 31.6% (273/865)
*
baseline 2 81.2% (5,487/6,755)
*
32.1% (278/865)
*
Note that the accuracies followed by * differ sig-
nificantly from those of our method (p < 0.05).
(Uchimoto et al., 1999). The difference between the two is the method of dependency parsing. The
baselines 1 and 2 use the dependency parsing method proposed by Uchimoto et al. (2000) and the de-
pendency parsing tool CaboCha (Kudo and Matsumoto, 2002), respectively. The features used for the
word reordering in both the baselines are the same as those used to estimate P (o
i,j
|D,B) in our method.
Additionally, the features used for the dependency parsing in the baseline 1 are the same as those used to
estimate P (d
i
|O,B) in our method.
4.2 Experimental Results
Table 1 shows the experimental results on word reordering of our method and the baselines. Here, the
last row shows the agreements measured by comparing the input word order with the correct word order.
The agreements mean the values which can be achieved with no reordering
4
. The pair and complete
agreements of our method were highest among all. The pair agreement of our method is significantly
different from those of both the baselines (p < 0.05) although there is no significant difference between
the complete agreements of them.
Next, Table 2 shows the experimental results on dependency parsing. The sentence accuracy of our
method is significantly higher than those of both the baselines (p < 0.05). On the other hand, the
dependency accuracy of our method is significantly lower than that of the baseline 2 although there is no
significant difference between the dependency accuracies of our method and the baseline 1 (p > 0.05).
Here, if the input sentences had the correct word order, the dependency accuracies of the baselines 1 and
2 were 86.4% (5,835/6,755) and 88.1% (5,950/6,755), respectively. We can see that the unsuitable word
order caused a large decrease of the accuracies of the conventional dependency parsing methods. This is
why the word order agreements of the baselines were decreased.
Figure 4 shows an example of sentences of which all bunsetsus were correctly reordered and the de-
pendency structure was correctly parsed only by our method. We can see that our method can achieve
the complicated word reordering. On the other hand, Figure 5 shows an example of sentences incorrectly
reordered and parsed by our method. In this example, our method could not identify the correct modified
bunsetsu and the appropriate position of the bunsetsu ?arikata-wo (whole concept).? This is because the
dependency probability between the bunsetsu ?arikata-wo (whole concept)? and the bunsetsu ?fukume
4
Some input sentences were in complete agreement with the original ordering. There were some cases that the randomly
reordered sentences accidentally have the same word order as the original ones. In addition, there were some sentences in
which all bunsetsus except the last one depend on the next bunsetsu. The word order of such sentences is not changed by the
test data generation procedure because the procedure is executed on condition of maintaining the dependency structure.
1193
Input sentence(inappropriate word order) 
?Although I myself do not have an experience with a war, I think any generation should not glorify war.?
Output sentence(correct word order and dependency structure) itsu-no(any) sedai-mo(generation) bika-su-beki-de-nai-to(should not glorify)
senso-wo(with a war)
senso-wo(war)
taiken-shi-ta(have an  experience)
koto-wa(?)
watashi-jishin(I myself)
omou
(think)
itsu-no(any)
sedai-mo
(generation)
bika-su-beki-de-nai-to(should not glorify)
senso-wo(with a war)
senso-wo(war)
taiken-shi-ta(have an  experience)
koto-wa(?)
watashi-jishin(I myself)
nai-ga
(although do not)
omou
(think)
nai-ga
(although do not)
:  shows an alignment of a bunsetsu before and after reordering.:  shows a correct dependency relation.?  :  means there is no English word corresponding to the Japanese word.
Figure 4: Example of sentences correctly reordered and parsed by our method
?Whole concept of the examination of rice should be fundamentally revised including the transfer of control to a private sector or prefectural and city governments.?
Input sentence(inappropriate word order) 
Output sentence(incorrect word order and dependency structure)
kensa-no(of the exami-nation)
arikata-wo(whole concept)
todofuken-ya(or prefectural and city governments)
minkan-e-no(to a private sector)
kome-no(of rice)
ikan-mo(the transferof control)
fukume
(including)
konpon-teki-ni(fundamen-tally)
minaosu-beki-daro(should be revised)
Original sentence(correct word order and dependency structure)
kensa-no(of the exami-nation)
arikata-wo(whole concept)
todofuken-ya(or prefectural and city governments)
minkan-e-no(to a private sector)
kome-no(of rice)
ikan-mo(the transferof control)
fukume
(including)
konpon-teki-ni(fundamen-tally)
minaosu-beki-daro(should be revised)
kensa-no(of the exami-nation)
arikata-wo(whole concept)
todofuken-ya(or prefectural and city governments)
minkan-e-no(to a private sector)
kome-no(of rice)
ikan-mo(the transferof control)
fukume
(including)
konpon-teki-ni(fundamen-tally)
minaosu-beki-daro(should be revised)
: shows an alignment of a bunsetsu before and after reordering.:  shows a correct dependency relation.:  shows an incorrect dependency relation.
Figure 5: Example of sentences incorrectly reordered and parsed by our method
(including)? is higher than the one between the bunsetsu ?arikata-wo (whole concept)? and the bunsetsu
?minaosu-beki-daro (should be revised)?, and the probability that the bunsetsu ?arikata-wo (whole con-
cept)? is located at the left side of ?fukume (including)? is higher than that of the right side. Since the
word order of the output sentence has a strong probability of causing a wrong interpretation like ?The
transfer of control to a private sector or prefectural and city governments should be fundamentally re-
vised including whole concept of the examination of rice.?, this reordering has a harmful influence on
the comprehension. We need to study techniques for avoiding the word order which causes the change
of meanings in an input sentence.
From the above, we confirmed the effectiveness of our method on word reordering and dependency
parsing of a sentence of which the word order is not easy to read.
5 Conclusion
This paper proposed the method for reordering bunsetsus in a Japanese sentence. Our method can identify
suitable word order by concurrently performing word reordering and dependency parsing. Based on the
1194
idea of limiting the search space using the Japanese syntactic constraints, we made the search algorithm
by extending the CYK algorithm used in the conventional dependency parsing, and found the optimal
structure efficiently. The result of the experiment using newspaper articles showed the effectiveness of
our method.
In our future works, we would like to collect sentences written by Japanese subjects who do not have
much writing skills, to conduct an experiment using those sentences. In addition, we would like to
conduct a subjective evaluation to investigate whether the output sentences are indeed more readable
than the input ones.
Acknowledgments
This research was partially supported by the Grant-in-Aid for Young Scientists (B) (No.25730134) and
Challenging Exploratory Research (No.24650066) of JSPS.
References
Tillmann Christoph and Ney Hermann. 2003. Word reordering and a dynamic programming beam search
algorithm for statistical machine translation. Computational Linguistics, 29(1):97?133.
Jakob Elming. 2008. Syntactic reordering integrated with phrase-based SMT. In Proceedings of the
22nd International Conference on Computational Linguistics (COLING2008), pages 209?216.
Katja Filippova and Michael Strube. 2007. Generating constituent order in German clauses. In Proceed-
ings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL2007), pages
320?327.
Niyu Ge. 2010. A direct syntax-driven reordering model for phrase-based machine translation. In
Proceedings of Human Language Technologies: The 11th Annual Conference of the North American
Chapter of the Association for Computational Linguistics (NAACL-HLT2010), pages 849?857.
Geert-Jan M. Kruijff, Ivana Kruijff-Korbayov?a, John Bateman, and Elke Teich. 2001. Linear order as
higher-level decision: Information structure in strategic and tactical generation. In Proceedings of the
8th European Workshop on Natural Language Generation (ENLG2001), pages 74?83.
Isao Goto, Masao Utiyama, and Eiichiro Sumita. 2012. Post-ordering by parsing for Japanese-English
statistical machine translation. In Proceedings of the 50th Annual Meeting of the Association for
Computational Linguistics (ACL2012), pages 311?316.
Karin Harbusch, Gerard Kempen, Camiel van Breugel, and Ulrich Koch. 2006. A generation-oriented
workbench for performance grammar: Capturing linear order variability in German and Dutch. In
Proceedings of the 4th International Natural Language Generation Conference (INLG2006), pages
9?11.
Nihongo Kijutsu Bunpo Kenkyukai, editor. 2009. Gendai nihongo bunpo 7 (Contemporary Japanese
Grammar 7), pages 165?182. Kuroshio Shuppan. (In Japanese).
Taku Kudo and Yuji Matsumoto. 2002. Japanese dependency analysis using cascaded chunking. In Pro-
ceedings of the 6th Conference on Computational Natural Language Learning (CoNLL2002), pages
63?69.
Sadao Kurohashi and Makoto Nagao. 1998. Building a Japanese parsed corpus while improving the
parsing system. In Proceedings of the 1st International Conference on Language Resources and
Evaluation (LREC ?98), pages 719?724.
Habash Nizar. 2007. Syntactic preprocessing for statistical machine translation. In Proceedings of the
11th Machine Translation Summit (MT SUMMIT XI), pages 215?222.
Eric Ringger, Michael Gamon, Robert C. Moore, David Rojas, Martine Smets, and Simon Corston-
Oliver. 2004. Linguistically informed statistical models of constituent structure for ordering in sen-
tence realization. In Proceedings of the 20th International Conference on Computational Linguis-
tics (COLING2004), pages 673?679.
1195
Tetsuo Saeki. 1998. Yosetsu nihonbun no gojun (Survey: Word Order in Japanese Sentences). Kuroshio
Shuppan. (In Japanese).
Satoshi Sekine, Kiyotaka Uchimoto, and Hitoshi Isahara. 2000. Backward beam search algorithm for de-
pendency analysis of Japanese. In Proceedings of the 18th International Conference on Computational
Linguistics (COLING2000), volume 2, pages 754?760.
James Shaw and Vasileios Hatzivassiloglou. 1999. Ordering among premodifiers. In Proceedings of the
37th Annual Meeting of the Association for Computational Linguistics (ACL ?99), pages 135?143.
Kiyotaka Uchimoto, Satoshi Sekine, and Hitoshi Isahara. 1999. Japanese dependency structure analysis
based on maximum entropy models. In Proceedings of the 9th Conference of the European Chapter
of the Association for Computational Linguistics (EACL ?99), pages 196?203.
Kiyotaka Uchimoto, Masaki Murata, Qing Ma, Satoshi Sekine, and Hitoshi Isahara. 2000. Word order
acquisition from corpora. In Proceedings of the 18th International Conference on Computational
Linguistics (COLING2000), volume 2, pages 871?877.
Hiroshi Yokobayashi, Akira Suganuma, and Rin-ichiro Taniguchi. 2004. Generating candidates for
rewriting based on an indicator of complex dependency and it?s application to a writing tool. Journal
of Information Processing Society of Japan, 45(5):1451?1459. (In Japanese).
Le Zhang. 2008. Maximum entropy modeling toolkit for Python and C++. http://homepages.
inf.ed.ac.uk/s0450736/maxent_toolkit.html. [Online; accessed 1-March-2008].
1196
Proceedings of the ACL 2010 Conference Short Papers, pages 74?79,
Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational Linguistics
Correcting Errors in a Treebank Based on
Synchronous Tree Substitution Grammar
Yoshihide Kato1 and Shigeki Matsubara2
1Information Technology Center, Nagoya University
2Graduate School of Information Science, Nagoya University
Furo-cho, Chikusa-ku, Nagoya, 464-8601 Japan
yosihide@el.itc.nagoya-u.ac.jp
Abstract
This paper proposes a method of correct-
ing annotation errors in a treebank. By us-
ing a synchronous grammar, the method
transforms parse trees containing annota-
tion errors into the ones whose errors are
corrected. The synchronous grammar is
automatically induced from the treebank.
We report an experimental result of apply-
ing our method to the Penn Treebank. The
result demonstrates that our method cor-
rects syntactic annotation errors with high
precision.
1 Introduction
Annotated corpora play an important role in the
fields such as theoretical linguistic researches or
the development of NLP systems. However, they
often contain annotation errors which are caused
by a manual or semi-manual mark-up process.
These errors are problematic for corpus-based re-
searches.
To solve this problem, several error detection
and correction methods have been proposed so far
(Eskin, 2000; Nakagawa and Matsumoto, 2002;
Dickinson and Meurers, 2003a; Dickinson and
Meurers, 2003b; Ule and Simov, 2004; Murata
et al, 2005; Dickinson and Meurers, 2005; Boyd
et al, 2008). These methods detect corpus posi-
tions which are marked up incorrectly, and find
the correct labels (e.g. pos-tags) for those posi-
tions. However, the methods cannot correct errors
in structural annotation. This means that they are
insufficient to correct annotation errors in a tree-
bank.
This paper proposes a method of correcting er-
rors in structural annotation. Our method is based
on a synchronous grammar formalism, called syn-
chronous tree substitution grammar (STSG) (Eis-
ner, 2003), which defines a tree-to-tree transfor-
mation. By using an STSG, our method trans-
forms parse trees containing errors into the ones
whose errors are corrected. The grammar is au-
tomatically induced from the treebank. To select
STSG rules which are useful for error correction,
we define a score function based on the occurrence
frequencies of the rules. An experimental result
shows that the selected rules archive high preci-
sion.
This paper is organized as follows: Section 2
gives an overview of previous work. Section 3 ex-
plains our method of correcting errors in a tree-
bank. Section 4 reports an experimental result us-
ing the Penn Treebank.
2 Previous Work
This section summarizes previous methods for
correcting errors in corpus annotation and dis-
cusses their problem.
Some research addresses the detection of er-
rors in pos-annotation (Nakagawa andMatsumoto,
2002; Dickinson and Meurers, 2003a), syntactic
annotation (Dickinson and Meurers, 2003b; Ule
and Simov, 2004; Dickinson and Meurers, 2005),
and dependency annotation (Boyd et al, 2008).
These methods only detect corpus positions where
errors occur. It is unclear how we can correct the
errors.
Several methods can correct annotation errors
(Eskin, 2000; Murata et al, 2005). These meth-
ods are to correct tag-annotation errors, that is,
they simply suggest a candidate tag for each po-
sition where an error is detected. The methods
cannot correct syntactic annotation errors, because
syntactic annotation is structural. There is no ap-
proach to correct structural annotation errors.
To clarify the problem, let us consider an exam-
ple. Figure 1 depicts two parse trees annotated ac-
cording to the Penn Treebank annotation 1. The
10 and *T* are null elements.
74
SNP VP .DTThat PRNS, NP VPPRPthey VBPsay SBAR-NONE- S-NONE-0 *T*
, ,,
MDwill VPVBbe ADJPJJgood PPINfor NPNNSbonds
.
SNP VP .DTThat PRNS, NP VPPRPthey VBPsay SBAR-NONE- S-NONE-0 *T*
, ,, MDwill VPVBbe ADJPJJgood PPINfor NPNNSbonds
.
(a) incorrect parse tree
(b) correct parse tree
Figure 1: An example of a treebank error
parse tree (a) contains errors and the parse tree
(b) is the corrected version. In the parse tree (a),
the positions of the two subtrees (, ,) are erro-
neous. To correct the errors, we need to move the
subtrees to the positions which are directly dom-
inated by the node PRN. This example demon-
strates that we need a framework of transforming
tree structures to correct structural annotation er-
rors.
3 Correcting Errors by Using
Synchronous Grammar
To solve the problem described in Section 2, this
section proposes a method of correcting structural
annotation errors by using a synchronous tree sub-
stitution grammar (STSG) (Eisner, 2003). An
STSG defines a tree-to-tree transformation. Our
method induces an STSG which transforms parse
trees containing errors into the ones whose errors
are corrected.
3.1 Synchronous Tree Substitution Grammar
First of all, we describe the STSG formalism. An
STSG defines a set of tree pairs. An STSG can be
treated as a tree transducer which takes a tree as
input and produces a tree as output. Each grammar
rule consists of the following elements:
? a pair of trees called elementary trees
PRNS,1 NP2 VP3 ,4
PRNS,1 NP2 VP3 ,4
source target
Figure 2: An example of an STSG rule
? a one-to-one alignment between nodes in the
elementary trees
For a tree pair ?t, t??, the tree t and t? are
called source and target, respectively. The non-
terminal leaves of elementary trees are called fron-
tier nodes. There exists a one-to-one alignment
between the frontier nodes in t and t?. The rule
means that the structure which matches the source
elementary tree is transformed into the structure
which is represented by the target elementary tree.
Figure 2 shows an example of an STSG rule. The
subscripts indicate the alignment. This rule can
correct the errors in the parse tree (a) depicted in
Figure 1.
An STSG derives tree pairs. Any derivation
process starts with the pair of nodes labeled with
special symbols called start symbols. A derivation
proceeds in the following steps:
1. Choose a pair of frontier nodes ??, ??? for
which there exists an alignment.
2. Choose a rule ?t, t?? s.t. label(?) = root(t)
and label(??) = root(t?) where label(?) is
the label of ? and root(t) is the root label of
t.
3. Substitute t and t? into ? and ??, respectively.
Figure 3 shows a derivation process in an STSG.
In the rest of the paper, we focus on the rules
in which the source elementary tree is not identi-
cal to its target, since such identical rules cannot
contribute to error correction.
3.2 Inducing an STSG for Error Correction
This section describes a method of inducing an
STSG for error correction. The basic idea of
our method is similar to the method presented by
Dickinson andMeurers (2003b). Their method de-
tects errors by seeking word sequences satisfying
the following conditions:
? The word sequence occurs more than once in
the corpus.
75
S SSNP VPPRN . SNP VPPRN .DT DTThat ThatSNP VPPRN . SNP VPPRN .DT DTThat ThatS, NP VP , S, NP VP ,SNP VPPRN . SNP VPPRN .DT DTThat ThatS, NP VP , S, NP VP ,, ,PRPthey PRPthey
(a)(b)
(c)
(d)
Figure 3: A derivation process of tree pairs in an
STSG
? Different syntactic labels are assigned to the
occurrences of the word sequence.
Unlike their method, our method seeks word se-
quences whose occurrences have different partial
parse trees. We call a collection of these word
sequences with partial parse trees pseudo paral-
lel corpus. Moreover, our method extracts STSG
rules which transform the one partial tree into the
other.
3.2.1 Constructing a Pseudo Parallel Corpus
Our method firstly constructs a pseudo parallel
corpus which represents a correspondence be-
tween parse trees containing errors and the ones
whose errors are corrected. The procedure is as
follows: Let T be the set of the parse trees oc-
curring in the corpus. We write Sub(?) for the
set which consists of the partial parse trees in-
cluded in the parse tree ?. A pseudo parallel cor-
pus Para(T ) is constructed as follows:
Para(T ) = {??, ? ?? | ?, ? ? ?
?
??T
Sub(?)
? ? ?= ? ?
? yield(?) = yield(? ?)
? root(?) = root(? ?)}
PRNS,1 NP2 VP4PRP3they VBP5say SBAR6-NONE-7 S8-NONE-90 *T*
, ,10,
PRNS,1 NP2 VP4PRP3they VBP5say SBAR6-NONE-7 S8-NONE-90 *T*
, ,10,
Figure 4: An example of a partial parse tree pair
in a pseudo parallel corpusSNP VP .DTThat PRNS, NP VPPRPthey VBPsay SBAR-NONE- S-NONE-0 *T*
, ,, VBDwill ADJP PPINof NPPRP$his NNSabilities
.JJproud
Figure 5: Another example of a parse tree contain-
ing a word sequence ?, they say ,?
where yield(?) is the word sequence dominated
by ? .
Let us consider an example. If the parse trees
depicted in Figure 1 exist in the treebank T , the
pair of partial parse trees depicted in Figure 4 is
an element of Para(T ). We also obtain this pair
in the case where there exists not the parse tree
(b) depicted in Figure 1 but the parse tree depicted
in Figure 5, which contains the word sequence ?,
they say ,?.
3.2.2 Inducing a Grammar from a Pseudo
Parallel Corpus
Our method induces an STSG from the pseudo
parallel corpus according to the method proposed
by Cohn and Lapata (2009). Cohn and Lapata?s
method can induce an STSG which represents a
correspondence in a parallel corpus. Their method
firstly determine an alignment of nodes between
pairs of trees in the parallel corpus and extracts
STSG rules according to the alignments.
For partial parse trees ? and ? ?, we define a node
alignment C(?, ? ?) as follows:
C(?, ? ?) = {??, ??? | ? ? Node(?)
? ?? ? Node(? ?)
? ? is not the root of ?
76
? ?? is not the root of ? ?
? label(?) = label(??)
? yield(?) = yield(??)}
where Node(?) is the set of the nodes in ? , and
yield(?) is the word sequence dominated by ?.
Figure 4 shows an example of a node alignment.
The subscripts indicate the alignment.
An STSG rule is extracted by deleting nodes in
a partial parse tree pair ??, ? ?? ? Para(T ). The
procedure is as follows:
? For each ??, ??? ? C(?, ? ?), delete the de-
scendants of ? and ??.
For example, the rule shown in Figure 2 is ex-
tracted from the pair shown in Figure 4.
3.3 Rule Selection
Some rules extracted by the procedure in Section
3.2 are not useful for error correction, since the
pseudo parallel corpus contains tree pairs whose
source tree is correct or whose target tree is incor-
rect. The rules which are extracted from such pairs
can be harmful. To select rules which are use-
ful for error correction, we define a score function
which is based on the occurrence frequencies of
elementary trees in the treebank. The score func-
tion is defined as follows:
Score(?t, t??) = f(t
?)
f(t) + f(t?)
where f(?) is the occurrence frequency in the tree-
bank. The score function ranges from 0 to 1. We
assume that the occurrence frequency of an ele-
mentary tree matching incorrect parse trees is very
low. According to this assumption, the score func-
tion Score(?t, t??) is high when the source ele-
mentary tree t matches incorrect parse trees and
the target elementary tree t? matches correct parse
trees. Therefore, STSG rules with high scores are
regarded to be useful for error correction.
4 An Experiment
To evaluate the effectiveness of our method, we
conducted an experiment using the Penn Treebank
(Marcus et al, 1993).
We used 49208 sentences in Wall Street Journal
sections. We induced STSG rules by applying our
method to the corpus. We obtained 8776 rules. We
PRN, SNP ,
PRN SNPNP VP
SNP VP
NPNP NPIN NP
NPNP PPIN NP
(1) (2)
(4)
source target
VP , S ,NP VP(3) PPIN NNSDT PPIN NPDT NNS
Figure 6: Examples of error correction rules in-
duced from the Penn Treebank
measured the precision of the rules. The precision
is defined as follows:
precision = # of the positions where an error is corrected
# of the positions to which some rule is applied
We manually checked whether each rule appli-
cation corrected an error, because the corrected
treebank does not exist2. Furthermore, we only
evaluated the first 100 rules which are ordered by
the score function described in Section 3.3, since
it is time-consuming and expensive to evaluate all
of the rules. These 100 rules were applied at 331
positions. The precision of the rules is 71.9%. For
each rule, we measured the precision of it. 70 rules
achieved 100% precision. These results demon-
strate that our method can correct syntactic anno-
tation errors with high precision. Moreover, 30
rules of the 70 rules transformed bracketed struc-
tures. This fact shows that the treebank contains
structural errors which cannot be dealt with by the
previous methods.
Figure 6 depicts examples of error correction
rules which achieved 100% precision. Rule (1),
(2) and (3) are rules which transform bracketed
structures. Rule (4) simply replaces a node la-
bel. Rule (1) corrects an erroneous position of a
comma (see Figure 7 (a)). Rule (2) deletes a use-
less node NP in a subject position (see Figure 7
(b)). Rule (3) inserts a node NP (see Figure 7 (c)).
Rule (4) replaces a node label NP with the cor-
rect label PP (see Figure 7 (d)). These examples
demonstrate that our method can correct syntactic
annotation errors.
Figure 8 depicts an example where our method
detected an annotation error but could not correct
it. To correct the error, we need to attach the node
2This also means that we cannot measure the recall of the
rules.
77
PRN, SNP ,VPI think
PRN, SNP ,VPI think NP
NP S VPis  one  good  oneall  you  need
NP S VPis  one  good  oneall  you  need
IN PP NNSof DTthe respondents IN
PP
NNSof DTthe respondents
NP
NP NP NP
the  U.S.only  two  or  three  other  major  banks
IN NPin
NP NP PP
the  U.S.only  two  or  three  other  major  banks
IN NPin
(a) (b)
(c)
(d)
Figure 7: Examples of correcting syntactic annotation errors
SPP SBAR,INAt NPNPCD10:33
, SPP SBAR,INAt NPCD10:33 ,when ... when ...
Figure 8: An example where our method detected
an annotation error but could not correct it
SBAR under the node NP. We found that 22 of the
rule applications were of this type.
Figure 9 depicts a false positive example
where our method mistakenly transformed a cor-
rect syntactic structure. The score of the rule
is very high, since the source elementary tree
(TOP (NP NP VP .)) is less frequent. This
example shows that our method has a risk of
changing correct annotations of less frequent syn-
tactic structures.
5 Conclusion
This paper proposes a method of correcting er-
rors in a treebank by using a synchronous tree
substitution grammar. Our method constructs a
pseudo parallel corpus from the treebank and ex-
tracts STSG rules from the parallel corpus. The
experimental result demonstrates that we can ob-
tain error correction rules with high precision.
TOP
NP .VP
based on quotations atfive major banksThe average of interbank offered rates
NP
TOP
NP .VP
based on quotations atfive major banksThe average of interbank offered rates
S
Figure 9: A false positive example where a correct
syntactic structure was mistakenly transformed
In future work, we will explore a method of in-
creasing the recall of error correction by construct-
ing a wide-coverage STSG.
Acknowledgements
This research is partially supported by the Grant-
in-Aid for Scientific Research (B) (No. 22300051)
of JSPS and by the Kayamori Foundation of Infor-
mational Science Advancement.
78
References
Adriane Boyd, Markus Dickinson, and Detmar Meur-
ers. 2008. On detecting errors in dependency tree-
banks. Research on Language and Computation,
6(2):113?137.
Trevor Cohn and Mirella Lapata. 2009. Sentence com-
pression as tree transduction. Journal of Artificial
Intelligence Research, 34(1):637?674.
Markus Dickinson and Detmar Meurers. 2003a. De-
tecting errors in part-of-speech annotation. In Pro-
ceedings of the 10th Conference of the European
Chapter of the Association for Computational Lin-
guistics, pages 107?114.
Markus Dickinson and Detmar Meurers. 2003b. De-
tecting inconsistencies in treebanks. In Proceedings
of the SecondWorkshop on Treebanks and Linguistic
Theories.
Markus Dickinson and W. Detmar Meurers. 2005.
Prune diseased branches to get healthy trees! how
to find erroneous local trees in a treebank and why
it matters. In Proceedings of the 4th Workshop on
Treebanks and Linguistic Theories.
Jason Eisner. 2003. Learning non-isomorphic tree
mappings for machine translation. In Proceedings of
the 41st Annual Meeting of the Association for Com-
putational Linguistics, Companion Volume, pages
205?208.
Eleazar Eskin. 2000. Detecting errors within a corpus
using anomaly detection. In Proceedings of the 1st
North American chapter of the Association for Com-
putational Linguistics Conference, pages 148?153.
Mitchell P. Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1993. Building a large annotated
corpus of English: the Penn Treebank. Computa-
tional Linguistics, 19(2):310?330.
Masaki Murata, Masao Utiyama, Kiyotaka Uchimoto,
Hitoshi Isahara, and Qing Ma. 2005. Correction of
errors in a verb modality corpus for machine transla-
tion with a machine-learning method. ACM Trans-
actions on Asian Language Information Processing,
4(1):18?37.
Tetsuji Nakagawa and Yuji Matsumoto. 2002. Detect-
ing errors in corpora using support vector machines.
In Proceedings of the 19th Internatinal Conference
on Computatinal Linguistics, pages 709?715.
Tylman Ule and Kiril Simov. 2004. Unexpected pro-
ductions may well be errors. In Proceedings of 4th
International Conference on Language Resources
and Evaluation, pages 1795?1798.
79
