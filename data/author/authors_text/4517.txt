  
Intelligent patent analysis through the use of a neural network: 
experiment of multi-viewpoint analysis with the MultiSOM model
 
Jean-Charles Lamirel 
LORIA 
Campus scientifique, BP 239 
54506 Vandoeuvre CEDEX 
France 
lamirel@loria.fr 
 
Shadi Al Shehabi 
LORIA 
Campus scientifique, BP 239 
54506 Vandoeuvre CEDEX 
France 
alshehab@loria.fr 
  
 
Martial Hoffmann 
INIST-CNRS   
2, All?e du Parc de Brabois 
54514 Vandoeuvre CEDEX 
France 
Martial.Hoffmann@inist.fr 
 
 
Claire Fran?ois 
INIST-CNRS   
2, All?e du Parc de Brabois 
54514 Vandoeuvre CEDEX 
France 
Claire.Francois@inist.fr
Abstract 
 
The main area of this paper concerns the neural 
methods for mapping scientific and technical 
information (articles, patents) and for assisting a 
user in carrying out the complex process of 
analysing large quantities of such information. 
In the procedure of information analysis, like in 
the domain of patent analysis, the complexity of the 
studied topics and the accuracy of the question to 
be answered may often lead the analyst to partition 
his reasoning into viewpoints. Most of the classical 
information analysis tools can only manage an 
analysis of the studied domain in a global way. The 
information analysis tool that will be considered in 
our study is the MultiSOM tool whose core model 
represents a significant extension of the classical 
Kohonen SOM neural model. The MultiSOM 
neural-based tool introduces the concepts of 
viewpoints and dynamics into the information 
analysis with its multi-maps displays and its inter-
map communication process. The dynamic 
information exchange between maps can be 
exploited by an analyst in order to perform 
cooperative deduction between several different 
analyzes that have been performed on the same 
data.  
The paper demonstrates the efficiency of a 
viewpoint-oriented-analysis as compared to a global 
analysis in the domain of patents. Both objective 
and subjective quality criteria are taken into 
account for quality evaluation. 
The experimental context of the paper is 
constituted by a patent database of 1000 patents 
related to oil engineering. The patents structure and 
the patents field semantics are firstly exploited in 
order to generate different viewpoints corresponding 
to different areas of interest for the analysts. In the 
experiment the selected viewpoints correspond to 
uses, advantages, patentees, and titles subfields of 
the patents. The indexing vocabulary of each 
viewpoint is automatically extracted of its related 
textual contents in the patents through a full text 
analysis. The resulting vocabulary is then used to 
rebuild patents descriptions regarding each 
viewpoint. These descriptions are finally classified 
through the unsupervised MultiSOM algorithm 
resulting in as much different maps as viewpoints. 
A fifth ?global viewpoint? which represent the 
combination of all the specific ones is also 
considered in order to perform our comparison 
between a global classification mechanism and a 
pure viewpoint-oriented classification mechanism. 
 
1. Introduction    
The digital maps are not only tools of 
visualization. They also represent an analysis tool. 
Appropriate display of class points can give the 
analyst an insight that it is impossible to get from 
reading tables of output or simple summary 
statistics. For some tasks, appropriate visualization 
is the only tool needed to solve a problem or 
confirm a hypothesis, even though we do not 
usually think of maps as a kind of analysis, as for 
patent analysis. There is many ways to create 
digital maps. The one we consider here is based on 
Artificial Neural Networks (ANNs). ANNs are a 
useful class of models consisting of layers of nodes. 
The power of ANNs is derived from their learning 
capability defined as a change in the weight matrix 
 (W), which represents the strength of the links 
among nodes. Moreover, both their relationships 
with multivariate data analysis and their non-linear 
capabilities represent added-values for classing and 
mapping. The Kohonen self-organizing map (SOM) 
model is a specific kind of ANN which implements 
in only one step the tasks of classing and mapping a 
data set. In the SOM case, the learning is 
competitive and unsupervised and the approach 
gives central attention to spatial order in the 
classing of data. The purpose is to compress 
information by forming reduced representations of 
the most relevant features, without loss of 
information about their interrelationships. The main 
advantages of the SOM model are its robustness 
and its very good illustrative power. Conversely, the 
fact that original model he his only able to deal with 
one classification of the data at a time might be 
considered as a serious bottleneck for exploiting it 
for fine mining tasks.  
In this article we shall be dealing with an 
innovation that was firstly introduced for the 
information retrieval purposes [13]. It has also been 
successfully tested for multimedia mining and 
browsing tasks, exploiting both the multi-map 
concept and the synergy between images and text on 
the same maps [14]. It is the multi-map extension of 
the Kohonen SOM algorithm. This will be from 
now signified by the name of MultiSOM. As we 
shall notice, the MultiSOM introduces the concepts 
of viewpoints and dynamics into the information 
analysis concept with its multi-map displays and its 
inter-map communication process. The dynamic 
information exchange between maps can be 
exploited by an analyst in order to perform 
cooperative deduction between several different 
analyzes that have been performed on the same 
data. The principal intent of this article is to 
propose the MultiSOM model as an ANN 
implementation of the information analysis concept. 
We will mainly focuses on the study of the 
contribution of the viewpoint's oriented data 
analysis proposed by the MultiSOM model as 
compared to the global analysis proposed by the 
other models. An attempt will be made to define a 
protocol and to design a platform for this 
comparison. As soon as the MultiSOM model can 
be used either in a global way or in a viewpoint-
oriented way, it will be used as the reference model 
for our comparison. The section 2 of the article 
presents the Kohonen self-organizing maps (SOM) 
and their main applications in mapping of science 
and technology. Sections 3 deals with MultiSOM, 
the multi-map innovation of the SOM algorithm. 
The context of the experiment on the oil engineering 
patents and the preprocessing of these latter will be 
described in the section 4. The Section 5 describes 
the protocol of comparison which has been set up 
along with its results. The conclusions are finally 
exposed. 
 
2. The self-organizing  map (SOM) 
 
The basic principle of the SOM is that our 
knowledge organization at higher levels is created 
during learning by algorithms that promote self-
organization in an spatial order (see 
[5],[6],[7],[8],[9],[10],[11],[12],[28]). Thus, the 
architecture form of the SOM network is based on 
the understanding that the representation of data 
features might assume the form of a self-organizing 
feature map that is geometrically organized as a 
grid or lattice. In the pure form, the SOM defines 
an "elastic net" of points (parameter, reference, or 
codebook vectors) that are fitted to the input data 
space to approximate its density function in an 
ordered way. The algorithm takes thus a set of N-
dimensional objects as input and maps them onto 
nodes of a two-dimensional grid, resulting in an 
orderly feature map [9]. A layer of two-dimensional 
array of competitive output nodes is used to form 
the feature map. The lattice type of array can be 
defined to be square, rectangular, hexagonal, or 
even irregular. Every input is connected to every 
output node via a variable connection weight. It is 
the self-organizing property. The SOM belongs to 
the category of the unsupervised competitive 
learning networks [4],[11],[13]. It is called 
competitive learning because there is a set of nodes 
that compete with one another to become active. To 
this category belongs also the adaptive resonance 
theory (ART) model of Grossberg and Carpenter, 
as well as the self-organizing maps discussed in this 
paper. In the SOM, the competitive learning means 
also that a number of nodes is comparing the same 
input data with their internal parameters, and the 
node with the best match (say, "winner") is then 
 tuning itself to that input, in addition the best 
matching node activates its topographical neighbors 
in the network to take part in tuning to the same 
input. More a node is distant from the winning node 
the learning is weaker. It is also called unsupervised 
learning because no information concerning the 
correct classes is provided to the network during its 
training. Like any unsupervised clustering method, 
the SOM can be used to find classes in the input 
data, and to identify an unknown data vector with 
one of the classes. Moreover, the SOM represents 
the results of its classing process in an ordered two-
dimensional space (R2). A mapping from a high-
dimensional data space Rn onto a two dimensional 
lattice of nodes is thus defined. Such a mapping can 
effectively be used to visualize metric ordering 
relations of input data. As Kohonen [9] says: "The 
main applications of the SOM are in the 
visualization of complex data in a two dimensional 
display, and creation of abstractions like in many 
classing techniques." 
The SOM algorithm is presented in details in 
([2],[9],[12],[13],[19]). It consists of two basic 
procedures: (1) selecting a winning node and (2) 
updating weights of the winning node and its 
neighboring nodes. This preliminary learning phase 
is not straightforward process [9]. It necessitates 
several different learning steps, single map 
evaluations, and comparisons between a lot of 
generated maps in order to find at least a reliable 
map, at most an optimal one [13],[32]. 
Let x(t) = {x1(t), x2(t),?, xN(t)} be the input 
vector selected at time t, and Wk(t) = {Wk1(t), 
Wk2(t),?, WkN(t)} the weights for node k at time t. 
The smallest of the Euclidean distances ||x(t) ? 
Wk(t)|| can be made to define the winning node s: 
||x(t) ? Ws(t)|| = min ||x(t) ? Wk(t)|| 
After the winning node s thus selected, the 
weights of s and the weights of the nodes in a 
defined neighborhood (for example all nodes within 
a square or a cycle around the winning node) are 
adjusted so that similar input patterns are more 
likely to select this node again. This is achieved 
through the following computation: 
Wki(t+1) = Wki(t) + ?(t) ? h(t) ? [Xi(t) ? Wki (t)], 
for 1 ? i ? N  
where ?(t) is a gain term (0 ? ?(t) ? 1) that 
decreases in time and converges to 0, and h(t) is the 
neighborhood function.  
 
Once the SOM algorithm is achieved, the data 
can be set to the nodes of the map. For each input 
data vector, the winning node is selected according 
to the algorithm first step presented above, and the 
data are affected to this selected node.  
In the quantitative studies of science, the 
Kohonen self-organizing maps have been 
successfully used for mapping scientific journal 
networks [2], and also author co-citation data [33]. 
Maps have been also successfully used for several 
other applications in the general area of data 
analysis like for classifying meeting output [30], for 
classing socio-economic data [32] and for 
documentary database contents mapping and 
browsing [13],14]. Kaski et al have implemented a 
specific adaptation of SOM, named WEBSOM, for 
the analysis of important document collections [6]. 
WEBSOM main characteristic is to include 
strategies for reducing the dimension of the entry 
data descriptions by using random projection 
techniques applied on word histograms extracted 
from the document contents. WEBSOM method has 
been tested for patents abstract analysis [7]. 
Nevertheless, as this method only manages such an 
analysis in a global way, it can only provide the 
analyst with general overview of the topics covered 
by the patents along with their interactions. A more 
exhaustive description of all the SOM applications 
might be found in [32].  
After the map building, the main characteristics 
of the classes resulting from the topographical 
classification process have to be highlighted to the 
analyst in order to provide him an overview (i.e. a 
global summary) of the analysis results. This task is 
difficult because the profiles of the obtained classes 
are mostly complex weighted combination of 
indexes extracted from the data. We have 
previously observed that single extraction strategy 
like the one proposed by [17] could cause 
shortcomings or mistakes in the interpretation of the 
database contents. The first set of solutions we 
proposed for solving this problem, like class 
labeling and zoning strategies or generalization 
mechanisms, are presented in [14]. Figure 3 of 
 section 4 presents a map resulting from these 
processes. 
In all the following sections, we will consider 
that the classification process deals with electronic 
documents associated with their description in the 
form of index vectors. Classes will be represented 
by node vectors or class profile; each component of 
the vectors being the coordinate of a document 
index element (keyword). The list of the input data, 
which are the documents affected to the node, will 
represent the ?class members? profile. The 
conceptual mean of the classes will be below called 
a topic. This semantic information is supplied by 
the classified keywords and documents. 
 
3. The MultiSOM model 
 
The communication between self-organizing 
maps that has been first introduced in the context of 
an information retrieval model [10], represents a 
major amelioration of the basic Kohonen SOM 
model. From a practical point of view, the multi-
map display introduces in the information analysis 
the use of viewpoints. Each different viewpoint is 
achieved in the form of map. Each map is a spatial 
order in which the information is represented into 
nodes (classes) and spatial areas (group of classes). 
The multi-map enables a user to highlight semantic 
relationships between different topics belonging to 
different viewpoints. Each map represents a 
particular viewpoint. Figure 4 of section 4 
illustrates it.  
 
3.1 The viewpoint paradigm 
The viewpoint building principle consists in 
separating the description space of the documents 
into different subspaces corresponding to different 
keyword subsets. The set of V all possible 
viewpoints issued from the description space D of a 
document set can be defined as: 
V = {v1, v2, ?, vn}, vi ? P(D), with  Dv
n
1i
i =
=
U  
where each vi represents a viewpoint and P(D) 
represents the set of the parts of the description 
space of the documents D; the union of the different 
viewpoints constitutes the description space of the 
documents.  
 
The viewpoint subsets issued from V may be 
overlapping ones. Moreover, they may also fit into 
the structure of the document when they 
correspond to different vocabulary subsets 
associated to different documents subfields, if any. 
Other viewpoints may be also manually extracted 
from an overall document description space. At 
last, the viewpoint model is flexible enough to 
tolerate document descriptions belonging to 
different media, as soon as these descriptions can 
be implemented by description vectors (for ex. an 
image can be simultaneously described both by a 
keyword vector and by color histogram vector). 
The inter-map communication mechanism, 
which is described hereafter, takes directly benefit 
of the above described viewpoint model in order to 
overcome the low quality problem inherent to a 
global classification approach while conserving a 
overall view on the interaction between the data. 
 
3.2 Inter-map communication mechanism 
In MultiSOM, this inter-map communication is 
based on the use of the data that have been 
projected onto the maps as intermediary nodes or 
activity transmitters between maps. The 
intercommunication process between maps operates 
in three successive steps. Figure 1 shows 
graphically the three steps of this 
intercommunication mechanism. 
At the step 1, the original activity is directly set up 
by the user on the node or on the logical areas of a 
source map through decisions represented by 
different scalable modalities (full acceptance, 
moderated acceptance, moderated rejection, full 
rejection) directly associated to nodes activity 
levels. This procedure can be interpreted as the 
user?s choices to highlight (positively or negatively) 
different topics representing his centers of interest 
relatively to the viewpoint associated to the source 
map. The original activity could also be indirectly 
set up by the projection of a user?s query on the 
nodes of a source map. The effect of this process 
will then be to highlight the topics that are more or 
less related to that query. The activity transmission 
protocol, which corresponds to the steps 2 and 3 of 
the inter-map communication mechanism, is 
extensively described in [24]. 
 To perform in the best conditions, the inter-map 
communication process obviously necessitates that 
a significant part of the data should play that roles 
between the maps. This last condition could be 
easily verified if each vector used for the map 
generation indexes a significant part of the 
bibliographic database. 
 
 
 
 
Source signal: direct user activation
or query matching activation
Source Map
[1]
[2]
[3]
 
Figure 1:  Inter-map communication mechanism. This figure represents the main steps of the inter-map 
communication mechanism. [1] The activity is set up directly by the user or by a query formulation on one or several 
nodes of one or several source map. [2] The activity is transmitted to the data nodes associated to the activated class 
nodes of the source map. [3] The activity is transmitted through the data nodes to other maps to which these data are 
associated. Positive as well as negative activity could be managed in the same process. Note that the data are in this 
case indexed document. 
 
4. Application 
 
In the two preceding sections we have introduced 
MultiSOM after having previously presented the 
SOM algorithm. In this section, we shall then use a 
real example, to make some of the notions more 
concrete. We argue that visualization into form of a 
set of maps represents an important added-value for 
analysis in the technology watching tasks, as well 
as in science watch, and in knowledge discovery in 
databases. Our example is a set of 1000 patents 
about oil engineering technology recorded during 
the year 1999. 
  
4.1 The analysis phase 
The role of the MultiSOM application has been 
firstly planed by the domain expert in order to get 
answers to such various kinds of questions on the 
patents that:  
1: ?Which are the relationships between the 
patentees?? 
2: ?Which are the advantages of the different oils??,  
3: ?Does a patentee works on a specific engineering 
technology, for which advantage and for which 
use??,  
4: ?Which is the technology that is used by a given 
patentee without being used by another one??, 
5: ?Which are the main advantages of a specific oil 
component and do this advantages have been 
mentioned in all the patents using this component??.  
 
An analysis carried out on all the possible types of 
question led the expert to define different 
viewpoints on the patents that could be associated 
to different closed semantic domains appearing in 
these questions. One of the main aim of the expert 
was to be able to use each viewpoints separately in 
order to get answers to domain closed questions 
(like questions 1,2) while maintaining the possibility 
of a multi-viewpoint communication in order to get 
answers to multi-domain questions (like questions 
3,4,5) that might also contain negation (like 
question 4). The specific viewpoints which have 
 been highlighted by the expert from the set of 
possible questions are: 
1: Patentees, 
2: Title (often contains information on the specific 
components used in the patent), 
3: Use, 
4: Advantages. 
A fifth ?global viewpoint? which represent the 
combination of all the specific ones is also 
considered in order to perform our comparison 
between a global classification mechanism, of the 
WEBSOM type, and a pure viewpoint-oriented 
classification mechanism, of the MultiSOM type.  
 
 
4.2 The technical realization 
The role of this phase consists in mapping the 
four specific viewpoints highlighted by the domain 
expert in the preceding phase in four different 
maps. A preliminary task consists in obtaining the 
index set (i.e. the vocabulary set) associated to each 
viewpoint from the full text of the patents. This task 
has been itself divided into three elementary steps. 
At the step 1, the structure of the patent abstracts is 
parsed in order to extract the subfields 
corresponding to the Use and to the Advantages 
viewpoints1. At the step 2, the rough index set of 
each subfield is constructed by the use of a basic 
computer-based indexing tool [4]. This tool extracts 
terms and noun phrases from the subfield content 
according to a normalized terminology and its 
syntactical variations. It eliminates as well usual 
language templates. At the step 3, the normalization 
of the rough index set associated to each viewpoint 
is performed by the domain expert in order to 
obtain the final index sets. The normalization of the 
Title, Use and Advantages subfields consists in 
choosing a single representative among the terms or 
noun phrases which represent the same concept (for 
ex., ?oil fabrication? and ?oil engineering? noun 
phrases will be both assimilated to the single ?oil 
engineering? noun phrase). The normalization of the 
Patentees viewpoint is operated in the same way 
considering that the same firm can appear with 
different names in the set of published patents. 
                                                             
1 The Patentees and Title subfields are directly represented in the original 
patent structure and therefore do not necessitate any extraction. 
After the construction of the final index sets, the 
patents are re-indexed separately for each viewpoint 
thanks to these sets. Figure 2 presents a patent 
abstract including its generated multi-index.  
The following task consists in building the maps 
representing the different viewpoints, using the map 
algorithm described in section 2. Before these step, 
a classical IDF-Normalization step [27] is applied 
to the index vectors associated to the patents in 
order to reduce the influence of the most 
widespread terms of the indexes. For each specific 
viewpoint a map of 10x10 nodes (classes) is finally 
generated. Two global maps representing global 
unsupervised classifications, of the WEBSOM type 
[7], of the patents are also constructed. The index 
sets of these maps represent the union of the index 
sets of all the specific viewpoints. They only differ 
one to another by the number of their classes. The 
first one (GlobMin) is constrained to have the same 
number of classes as the viewpoint maps (i.e. 100 
classes). The second one (GlobMax) is constrained 
to have to sum of the number of classes of all the 
viewpoint maps (i.e. it becomes a 20x20 map 
comprising 400 classes). The table 1 summarizes 
the results of the patent indexation and the map 
building. A single viewpoint map resulting from the 
map building process is presented at the figure 4. 
Some remarks must be made concerning the results 
shown in table 1. (1) The index count of the Title 
field is significantly higher than the other ones. An 
analysis of the indexes shows that the information 
contained in the patent titles is both sparser, of 
higher diversity, and more precise than the ones 
contained in the Use and Advantages fields. 
Thanks to the expert opinion, the high level of 
generality of the Use and Advantages fields, which 
consequently led to poorer generated indexes, could 
be explained as an obvious strategy of the Patentees 
for indirectly protecting their patents. (2) The 
number of final patentees (i.e. 32) has been 
significantly reduced by the expert as compared to 
the one initially generated by the computer-based 
indexing tool.  The main part of this reduction is not 
due to variations in patentee names. It is related to 
the fact that the prior goal of the study was to 
consider the main companies and their 
relationships. Thus, the patentees corresponding to 
small companies have been grouped into a same 
 general index: ?Divers?. (3) On the Patentees map, 
the number of classes is close to the final number of 
retained patentees. Most of these patentees will then 
be associated to separate classes on the Patentees 
map. (4) Only 62% of the patents have an 
Advantages field and 75% a Use field. 
Consequently, some of the patents will not be 
indexed for the all the expected viewpoints. The role 
of the mechanism of communication between 
viewpoints (see next section) will then be to 
generate indirect evaluation of the contents of these 
patents on their missing viewpoints through their 
associations with other patents. 
 
 
 
Figure 2: Example of a patent abstract with its generated multi-index. The multi-index that has been generated 
for the above patent abstract corresponds to the ?Final indexation? field. The terms of the generated multi-index are 
prefixed by the name of the viewpoint to which they are associated: ?adv.? for the Advantages viewpoint, ?titre.? for 
the Title viewpoint, ?use.? for the Use viewpoint, ?soc.? for the Patentees viewpoint. 
 
 
 
Figure 3: Example of a generated map. Partial view of a topographic map of 10 x 10 nodes. The map is initially 
organized as a square 2D grid of nodes. The viewpoint chosen for the showed map is the "Advantages" viewpoint. 
The names of the classes illustrate the topics (considering the chosen viewpoint) that have been highlighted by the 
 learning. After the learning, the nodes related to the same topics have been grouped into coherent areas thanks to the 
topographic properties of the map. The number of nodes of each area can then be considered as a good indicator of 
the topic weight in the database. Topics or areas near one to another represent related notions. For example, the 
?extending oil live? area shares some of its borders with the ?black sludge control? area on the map. The proximity 
of these two areas illustrates the fact that oil duration strongly depends of maintaining a low level of sludge in it. The 
surrounding circles represent the centers of gravity of the areas. 
 
 
 Patentees Title Use  Advantages GlobMin 
(WEBSOM) 
GlobMax 
(WEBSOM) 
Number of indexed documents  
(NID) 1000 1000 745 624 1000 1000
Number of rough indexes generated 
(NRI) 73 605 252 231 1395 1395
Number of final indexes  
(NFI) 32 589 234 207 1075 1075
Numbers of map classes with members 
(/100) 28 55 57 61 89 238
Table 1: Summary of the results of patent indexation and map building. Note that the NRI (resp. NFI) of the 
?global viewpoint? are less than the sum of the NRIs (resp. NFIs) of all the specific viewpoints (i.e. 1089) because 
there are similar indexes occurring in different viewpoints.  
 
 
Figure 4: Example of exploitation of the inter-map communication mechanism. The analyst decision to activate 
the area corresponding to the TONEN CORP. company on the Patentees map and to propagate the activity to the 
thematic maps associated to the Use, Advantages and Title viewpoints corresponds to a "viewpoints crossing query" 
whose explicit formulation might look like: "I want to know which are the specific areas of competence (concerning 
oil use, oil composition and expected advantages) of the TONEN CORP. company, if there are. The MultiSOM 
application let him interactively find that TONEN CORP. company is a specialist of the lubrication of the automatic 
transmissions [arrow n?2 on the map] and that it adopted for this kind of lubrication sulfur-containing 
organo-molybdenum compound [arrow n?1] whose main advantages are to provide oil with a friction coefficient that 
is stable on a wide range of temperature [arrow n?3]. In this case, an inverted propagation from the target topics 
should be also used to verify that these topics only belong to TONEN CORP. areas of competence. The whiter is the 
color of a node representing a map class (topic), the higher is its resulting activity. 
1 2
3
Patentees 
Title 
Advantages 
Use 
  
 
4.3 Inter-map communication for analysis  
In comparison with the standard mapping 
methods, as such as principal component analysis, 
multidimensional scaling or WEBSOM global 
SOM analysis, the advantage of the multi-map 
displays is the inter-map communication 
mechanism that MultiSOM environment provides to 
user. Each map is representing a viewpoint. Each 
viewpoint is representing a subject category. The 
inter-map communication mechanism assisted the 
user to cross information between the different 
viewpoints. In both cases, the responses of the 
system are given both through activity profiles on 
the maps and through patents examples associated 
to the most active class representatives of these 
maps. The estimation of the quality of thematic 
deduction is achieved through an evaluation of the 
activity focalization on the target maps (see [13]). 
The figure 4 illustrates a thematic deduction 
between the four different viewpoints of the study.  
 
5. Evaluation 
The advantages of the MultiSOM method seem 
obvious to the expert of the domain: the original 
multiple viewpoints classification approach of 
MultiSOM tends to reduce the noise which is 
inevitably generated in an overall classification 
approach while increasing the flexibility and the 
granularity of the analyses. Moreover, with a global 
classification method, like WEBSOM, important 
relationships between some subtopics are hidden in 
the class profiles and therefore very difficult to 
precisely characterize. The expert found more than 
35 of such important relationships by the use of the 
MultiSOM method. A simple example is given by 
the comparison of the figure 3 and the figure 5. 
Other examples of more elaborated topic 
relationships that can be only obtained by the 
MultiSOM inter-map communication mechanism 
are given in the annex of the paper. Finally, the 
expert argued that the possibility of interactively 
activating, positively or negatively, the classes on 
the maps represents a great help for tuning very 
precisely an analysis process. Nevertheless, expert 
empirical evaluation remains insufficient to 
objectively compare global approach to viewpoint-
oriented approach. For this last purpose, we 
propose new objective classification quality 
estimators for both evaluating and optimising the 
results of the classification and of the mapping 
methods, especially when they are applied in the 
domain of documentary databases. These estimators 
are described in the next section. 
 
 
    
Figure 5: Results of a WEBSOM-like global mapping of 10x10 nodes (GlobMin). The left part of the figure 
represents the WEBSOM-like mapping (i.e. without viewpoint management) of the content of the patent abstracts. 
The right part of the map represents the description (i.e. profile) of the ?extending oil life? WEBSOM global topic. 
Even if a strong relationship between ?extending oil life? and ?black sludge control? topics has been highlighted by 
Profile of topic: Extending oil life 
 the MultiSOM viewpoint-oriented classification (see map of figure 3), this relationship has been lost by the 
WEBSOM-like classification due to the noise of the global classification (this relationship do not appear, neither in 
the above map, nor in the ?extending oil life? topic profile). 
 
5.1 Evaluation procedure 
When anyone aims at comparing classification 
methods, he will be faced with the problem of 
choice of reliable classification quality measures. 
The classical evaluation measures for the quality of 
a classification are based on the intra-class inertia 
and the inter-class inertia [16][17][25]. Thanks to 
these two measures, a classification is considered as 
good if it possesses low intra-class inertia as 
compared to its inter-class inertia. However, in the 
case of a Kohonen classification, as well as for 
many other numerical classification methods, these 
measures are often strongly biased, mainly because 
the intrinsic dimensions of the classes profiles 
(number of non-zero components in the profiles) are 
not of the same order of magnitude than the 
intrinsic dimensions of the data profiles2. It is 
especially true in the documentary domain where 
the number of indexes in the documents is 
extremely low as compared to the dimension of 
their overall description space. 
A promising way we have found in order to more 
precisely highlight the main characteristics of the 
classes of the map and to validate the thematic 
deductions between the maps consists in coupling 
the MultiSOM model with a symbolic model using 
Galois lattice conceptual classification of the 
patents regarding the same viewpoints as the one 
used for the map building. This approach is 
extensively described in [31]. A Galois lattice 
model could also be considered as a pure natural 
elementary classifier. Indeed, it groups the data by 
directly considering their intrinsic properties (i.e. 
without any preliminary construction of class 
profiles). Hence, one might derive from its behavior 
news class quality evaluation factors which can be 
substituted to the measures of inertia for validating 
the intrinsic properties of the numerical classes. For 
the sake of user-orientation, our measures will be 
based in a parallel way on the recall and precision 
criteria which are extensively used from evaluating 
                                                             
2 In the SOM method, a second bias is generated by the class construction 
process that tends to maintain the topographic properties of the map by 
enhancing the similarities between neighboring classes. 
the result quality of information retrieval (IR) 
systems. In IR [29], the Recall R represents the 
ratio between the number of relevant documents 
which have been returned by an IR system for a 
given query and the total number of relevant 
documents which should have been found in the 
documentary database. The Precision P represents 
the ratio between the number of relevant documents 
which have been returned by an IR system for a 
given query and the total number of documents 
returned for the said query. Recall and Precision 
generally behave in an antagonist way: as Recall 
increases, Precision decreases, and conversely. The 
F function has thus been proposed in order to 
highlight the best compromise between these two 
values [35]. It is given by: 
( )
PR
PR
F
+
=
*2
 (Eq. 1) 
Based on the same principles, the Recall and 
Precision measures which we introduce hereafter 
evaluate the quality of a classification method by 
measuring the relevance of its resulting class 
content3 in terms of shared properties. In our further 
descriptions, the class content is supposed to be 
represented by documents and the indexes (i.e. the 
properties) of the documents are supposed to be 
weighted by values within the range [ ]1,0 . 
Let us consider a set of classes C resulting from a 
classification method applied on a set of documents 
D, the Recall measure is expressed as: 
??
??
=
cSp p
p
Cc c C
c
SC
R
*
*
11
, ??
??
=
cSp
p
Cc c c
c
SC
P
*
11
 
where Sc is the set of properties which are 
peculiar to the class c that is described as: 
( )??
??
?
??
??
?
=??=
?Cc
pp
cc WMaxWcddpS c
'
',  
where C represents the peculiar set of classes 
                                                           
3 The content of a class is represented by the subset of original data that 
have been associated to it by the classification process. 
 extracted from the classes of C, which verifies: 
{ }???= cSCcC  
and: 
??
?
? ?
?
=
Cc cd
p
d
cd
p
d
p
c
W
W
W
' '
 
where pxW  represents the weight of the property 
p for element x. 
 
Similarly to IR, the F-measure (described by 
Eq. 1) could be used to combine Recall and 
Precision results. Moreover, we have demonstrated 
in [16] that if both values of Recall and Precision 
reach the unity value, the peculiar set of class 
C represents a Galois lattice. Therefore, the 
combination of this two measures enables to 
evaluate to what extent a numerical classification 
model can be assimilated to a Galois lattice natural 
classifier. The stability of our Quality criteria has 
also been demonstrated in [16]. 
 
5.2 Evaluation results 
 
 Patentees Title Use Advantages Average F 
(MSOM) 
GlobMin 
(WEBSOM) 
GlobMax 
(WEBSOM) 
R 0,94 0,89 0,78 0,77 0,87 0,84 
P 0,92 0,40 0,63 0,60 0,48 0,65 
F 0,93 0,55 0,70 0,67 0,71 0,61 0,68 
 
Table 2: Summary of the results of Quality, Recall and Precision evaluation: The nearer the different values are 
from 1, the better are the classification results. The F value provides a synthesis of the results of R and P. 
 
 
The examination of the Quality measures of the 
table 2 gives more reliable and stable results 
because these measures are both independent of the 
classification method and of the size of the 
description space. It highlights the overall 
superiority of the viewpoint-oriented approach as 
compared with a global approach with the same 
number of class (GlobMin). As the number of 
classes is strongly increased in the global approach 
(GlobMax), its quality is simultaneously increased, 
but the advantage of the viewpoint-oriented 
approach remains obvious in the average (higher 
Average F-value on all viewpoints than F-value of 
GlobMax), with a more reasonable number of 
classes per maps from a user point of view. The 
specific case of the Title classification should be 
discussed here. The bad quality of this classification 
is both due to the index sparseness of this field4 and 
to an inappropriate number of classes, relatively to 
                                                           
4 This can be ?a posteriori? confirmed by the inertia results for this 
viewpoint. 
the size of its associated description space. An 
interesting strategy would then be to make use of 
the quality factor Q in order to find the optimal 
number of classes for this classification. An 
unbalance between Recall and Precision (in the 
favour of Recall) can be observed in the case of the 
worse classifications (GlobMin and Titles). Such 
an unbalance means that documents with different 
properties sets are grouped in the same classes, 
leading conjointly to the risk of confusion in the 
interpretation of the content of the classes by the 
user. 
The quality analysis clearly shows that the 
viewpoint-oriented approach enhance the quality of 
interpretation of a classification by both reducing 
the number of class to be consulted by the user on 
each viewpoint and providing him with more 
coherent and exhaustive classes in terms of content. 
 
5.3 Optimisation of classification results 
The quality criteria that have been presented in 
 the latter section can also be used for optimizing the 
number of classes for each viewpoint map. The goal 
of this process is to provide the analyst with an 
optimal quality of interpretation for each individual 
map associated to a specific viewpoint. For that 
purpose, different maps are generated from 6x6 to 
24*24 nodes (classes) for each viewpoint. The 
principle of our algorithm of classification 
optimisation, which is described in [16], is to search 
for a break-even point (i.e. intersection point) 
between Recall and Precision. The map whose 
quality criteria stand the nearest from the break-
even point is considered as the optimal one. The 
figure subjectively illustrates the difference of 
accuracy that can be obtained in the analysis by 
optimizing the map size for a given viewpoint. As it 
is shown in the figure 6, high quality maps are 
usually characterized by more precise topic labels 
and smaller average size of their logical areas. 
 
     
 
Figure 6: Comparison between a 11x11 ?Use viewpoint? thematic map and a 16x16 ?Use viewpoint? thematic 
map through map extracts: the 11x11 map extract is presented at the left, the 16x16 map extract is presented at the 
right. On the figure, the focus is given ?machine oil? topic. The comparison highlights, as an example, that the logical 
surrounding of this topic is more precisely defined in the 16x16 map (optimal quality) than in the 11x11 map (lower 
quality). Moreover, in the 11x11 map, the topic ?machine oil? has been derived in a more fuzzy scope topic named 
?machine and vehicles?. 
 
6. Conclusion 
 
We have presented a new self-organizing multi-
map system. We proposed it as a visualization-
based system for scientific and technical 
information analysis, like patents analysis. The 
model that this multi-map environment provides is 
certainly not the map but in its original extended 
version of intercommunication between multiples 
maps. Each map representing a particular viewpoint 
extracted from the data. These viewpoints are 
related either by the problem to be solved, or by the 
intercommunication mechanism between the maps. 
We have exposed both the map generation and their 
intercommunication mechanism. We finally showed 
how one can evaluate such a viewpoint-oriented 
approach by comparing it to a global classification 
approach. 
The advantages of the MultiSOM method seem 
obvious both in terms of objective evaluation, like 
the one we proposed, and for the domain experts: 
the original multiple viewpoints classification 
approach of MultiSOM tends to reduce the noise 
which is inevitably generated in an overall 
classification approach while increasing the 
flexibility and the granularity of the analyses. 
Moreover, with a global classification method, even 
if this latter manages overlapping classes, important 
 relationships between some subtopics are hidden in 
the class profiles and therefore very difficult to 
precisely characterize.  
Our experiment has also highlighted that our 
quality evaluation factors that we have proposed 
can be benefitely used for optimizing the 
classifications in terms of number of classes, either 
these classifications are global or they are 
viewpoint-oriented. This optimization seems to be 
mandatory when one want to classify documents 
issued from the Web, where sparseness could 
usually be a blocking factor. 
 
  
7. References 
[1] IST-1999-20350. 
[2] J. M. Campanario, ?Using Neural Networks To 
Study Networks of Scientific Journals,? 
Scientometrics, 33 (1995) No. 1, p. 23-40.  
[3] J-F. Jodouin, Les r?seaux neuromim?tiques, 
HERMES, Paris, 1994. 
[4] O. Jouve, ?Les nouvelles technologie de la 
recherche d?information?, S?minaire 
Documentation, Paris, Otobre, 1999 
[5] G. E. Hinton, ?Connectionist Learning 
Procedures,? Artificial Intelligence, 40 (1989) p. 
185-234. 
[6] S. Kaski, T. Honkela, K. Lagus and T. 
Kohonen, ?WEBSOM-self organizing maps of 
document collections ?, Neurocomputing, vol. 21, 
pp. 101-117, 1998. 
[7] T. Kohonen, S. Kaski, K. Lagus, J. Salojrvi, J. 
Honkela, V. Paatero and A. Saarela, Self 
organization of a massive document collection",  
IEEE Transactions on Neural Networks, 2000. 
[8] T. Kohonen, Self-Organisation and Associative 
Memory, Springer Verlag, Third edition, Berlin, 
1984. 
[9] T. Kohonen ?The Self-Organizing Map,? 
Proceedings of the IEEE, 78 (1990) No 9, p. 1464-
1480. 
[10] T. Kohonen, ?Self-Organizing Maps: 
Optimization Approaches,? in Artificial Neural 
Networks, T. Kohonen, K. M?kisara, O. Simula, J. 
Kanges, Editors, Elsevier Science Publishers B.V, 
North Holland, Amsterdam, 1991, p. 981?990. 
[11] T. Kohonen, ?Things You Haven't Heard 
about the Self-Organizing Map,? IEEE 
International Conference on Neural Networks, San 
Francisco, Calif., March 28 ? April 1, (1993) p. 
1147-1156. 
[12] T. Kohonen, Self-Organizing Maps. Springer 
Verlag, Berlin, 1997. 
[13] J-C. Lamirel, Application d?une approche 
symbolico-connexionniste pour la conception d?un 
syst?me documentaire hautement interactif, Th?se 
de l?Universit? de Nancy 1 Henri Poincar?, 1995. 
[14] J-C. Lamirel, J. Ducloy, G. Oster, ?Adaptative 
browsing for information discovery in an 
iconographic context,? In Conference Proceedings 
RIAO, Paris, Volume 2, 2000, p. 1657-1672. 
[15] J.C. Lamirel, Y. Toussaint, ? Combining 
Symbolic and Numeric Techniques for Digital 
Libraries Contents Classification and Analysis ?. 
Proceedings of First DELOS Network of 
Excellence Worshop, Zurich, December 2000. 
[16] J.C. Lamirel, S. Al Shehabi, C. Francois, M. 
Hoffmann, ? New classification quality estimators 
for analysis of documentary information: 
application to web mapping ?. Proceedings of  
ISSI, Bejing, 2003 (to be published). 
[17] L. Lebart, A. Morineau and J. P. F?nelon, ? 
Traitement des donn?es statistiques ?, Dunod, 
Paris, France, 1982. 
[18] A. Lelu et A. Georgel, ? Neural Models for 
Orthogonal and Oblique Factor Analysis: Towards 
Dynamic Data Analysis of Large Sets of Highly 
Multidimensional Objects ?, Proceedings of 
IJCNN, pp. 829?832, Paris, France, 1990. 
[19] X. Lin, D. Soergel, G. Marchionini, ?A Self-
Organizing Semantic Map for Information 
Retrieval,? in Proceedings of the 4th International 
SIGIR Conference on R&D in Information 
Retrieval, 13-16 October, Chicago, 1991, p. 262-
269. 
[20] X. Lin., ? Map Displays for Information 
Retrieval, ? JASIS, 48 (1) : 40-54, 1997. 
[21] R. P Lippmann., ?An Introduction to 
Computing with Neural Nets,? IEEE ASSP 
Magazine, April, p. 4-22 (1987) p. 4-22. 
[22] R. E. Orwig, H. Chen and J. F. Nunamaker 
Jr., ? A graphical, Self Organizing Approach to 
Classifying Electronic Meeting Output, ? JASIS, 
48 (1) : 157-170, 1997. 
[23] M. A. Ould Mahamed Yahya, ? Comparaison 
de m?hodes neuronales avec des m?thodes 
d?analyse des donn?es dans le cadre d?ing?nierie 
de l?information ?, M?moire de stage de D.E.S.S. 
en ?Ing?nierie math?matique et outils 
 informatiques?, Centre Elie Cartan, Universit? de 
Nancy I, France, 1997. 
[24] X. Polanco, J.C. Lamirel and C. Francois, 
? Using Artificial Neural Networks for Mapping of 
Science and technology: A Multi self-organizing 
maps Approach ?, Scientometrics, Vol. 51, N? 1 
(2001), pp. 267-292. 
[25] X. Polanco, C. Fran?ois, ?Data Classing and 
Class Mapping or Visualization in Text Processing 
and Mining,? Dynamism and Stability in 
Knowledge Organization. Proceedings of the Sixth 
international ISKO Conference, 10-13 July 2000, 
Toronto, Canada. Edited by C. Beghtol, C. L. 
Howarth, N. J. Williamson. Advances in 
Knowledge Organization, 7 (2000a), p. 359-365. 
[26] C. Rham (De), ?La classing hi?rarchique 
ascendante selon la m?thode des voisins 
r?ciproques,? Les cahiers de l?analyse de donn?es, 
5 (1980) No. 2, p. 135-144. 
[27] S. E. Robertson and K. Sparck Jones, 
? Relevance Weighting of Search Terms ?, Journal 
of the American Society for Information Science, 
27:129?146, 1976. 
[28] H. Ritter, T. Kohonen, ?Self-Organizing 
Semantic Maps,? Biological Cybernetics, 61 
(1989) p. 241-254. 
[29] G. Salton, The SMART Retrieval System: 
Experiments in Automatic Document Processing, 
Prentice Hall Inc., Englewood Cliffs, New Jersey, 
1971. 
[30] SOM papers, http://www.cis.hut.fi/nnrc/refs/ 
[31] Y. Toussaint, J.C. Lamirel, M. d?Aquin, 
? Combining Symbolic and Numeric Techniques 
for Database Content Analysis, ? Proceedings of 
IEA01, Budapest, Hungary, 2001. 
[32] Varsis and C. Versino ? Clustering of Socio-
Economic Data with Kohonen Maps, ? In 
Proceedings of third International Workshop on 
Parallel Applications in Statistics and Economics, 
Pragues, Czechoslovakia, december 1992. 
[33] H. D. White, X. Lin, K.W. McCain, ?Two 
Modes of Automated Domain Analysis: 
Multidimensional Scaling vs Kohonen Feature 
Mapping of Information Science Authors,? in 
Structures and Relations in Knowledge 
Organization. Proceeding of the Fifth 
International ISKO Conference, Lille, 25-29 
August 2000. Edited by W. Mustafa el Hadi, J. 
Maniez, S.. A. Politt. Advances in Knowledge 
Organization, 6 (1998) p. 57-63. 
[34] P. H. Winston, Artificial Intelligence. 
Addison-Wesley Publishing Company, Reading, 
Mass., 1977. 
[35] C. J. Van Rijsbergen,  ? Information 
Retrieval?,  Butterworths, London, England, 1975. 
 
 
  
 
ANNEX: EXAMPLE OF DYNAMIC ANALYSIS 
 
Dynamic analysis takes place mainly by using 
the inter-map communication mechanism which 
makes it possible to bring to successful conclusion 
sets of topics deductions between different 
viewpoints chosen like investigation subfields. This 
analysis is based on the generation of an initial 
activity corresponding to the premises of the 
deductions to check. According to the stage of 
analysis, this activity can itself be generated 
several manners by the analyst on one or more 
source maps. If the activity generation is directly 
operated by analyst on a map, it corresponds then 
to a broad set of topics questions. If the activity 
generation is operated indirectly by projection of a 
query on a map or by activation of documents 
group stored beforehand in a document collector, 
it corresponds then to more targeted questions, 
which can intervene in one advanced stage of the 
analysis. 
The analyst interest is to highlight the specific 
areas of competence of the Exxon company. On 
the simulation of analysis we develop on figure 7, 
we will consider two different viewpoints, the 
Patentees viewpoint which will represent the 
source of the analysis and the Title viewpoint 
which will represent its destination. 
The analyst starts the process of deduction by 
generating an initial activity on the main Exxon 
topic (i.e. Exxon area gravity center) of the 
Patentees viewpoint map. To obtain a broad set of 
potential deductions, he selects the Possibilistic 
mode of deduction [14]. The activity generated by 
the inter-map communication mechanism on the 
Title viewpoint map is focused in two different 
zones of this map, corresponding to two potential 
results. 
In the first active zone (1), the analyst makes 
use of  two different naming strategies to facilitate 
its interpretation, namely, a naming strategy 
based on the profile of the topics (more generic) 
and a naming strategy based on  the profile of 
the best members (i.e. patents) of the topics (more 
specific). These operations enable him to highlight 
that the Exxon company is specialized in a 
correlative way on topics: ?marine diesel 
engine?, ?surfactant system? and ?basic 
calcium compound?. The expert checks the 
correlation between these topics by consulting the 
patents associated to the topic ?surfactant 
system? (2). The title of the patents already 
confirm him the problematic detected by the 
application. A thorough examination of the 
contents of the documents will show him than the 
purpose of use of surfactant containing calcium in 
addition with the normal formula of oils is to 
protect the combustion chambers of the marine 
diesel engines against corrosion due to the 
absorption of air charged out of salt during their 
operation. The problem of protection of the marine 
engines against corrosion is sufficiently important 
to represent a field of investigation for an oil 
manufacturer like Exxon. 
The construction of a query containing the single 
descriptor ?surfactant system? (3) on the Title 
viewpoint will allow the analyst: 
1. To validate the correlation between 
?surfactant system? and ?marine diesel engine? 
topics which will be interpreted by the fact that 
?surfactant system? is only associated with 
?marine diesel engine?. 
2. To check the inverse deduction 
?surfactant system ? Exxon? which will insure 
him that Exxon is the only company whose 
interest in the conception of ?surfactant system?. 
The result of the projection of the query on the 
Title viewpoint map (4) shows that the generated 
activity is peculiar to the logical topic area 
?marine diesel engine?, which confirms the first 
assumption. Simultaneously with projection, the 
documents that are relevant for the query are 
presented in a Collector (5). The global activation 
of these documents allows analyst to initiate a new 
deduction.  Then, the result of this latter can be 
examined on the Patentees map. Like only the 
main Exxon topic has been activated (6), the 
second assumption of the analyst is confirmed. 
The second active zone (7) generated by the 
initial process of deduction will allow the analyst 
 to observe that the second major field of activity of 
Exxon is the ?biodegradable? oils. He will be 
able to also note that these oils are more 
specifically used for the lubrication of the two-
stroke engines (?two cycle engine?) that  reject 
generally much unburned oil. Probabilistic mode 
of deduction will allow him to check if the inverse 
deduction, namely, that Exxon is the only 
company to be worked on biodegradable oils, can 
be validated (8). This process will lead the analyst 
to conclude that ?biodegradable? oil 
manufacturing is shared between Exxon and 
Mobil companies (9), which are the most 
important oil manufacturers.  
A complementary use of negative activity setting 
on the ?two cycle engine? topic (10) will show 
more precisely to the analyst that that Mobil 
company mainly focuses on manufacturing of 
biodegradable oils for ?two stroke engines? and, 
in a complementary way, that Mobil company only 
focuses on manufacturing of biodegradable oils 
for ?four stroke engines? (11). 
The simulation of analysis presented here above 
shows clearly how the analyst can make use of the 
MultiSOM functionalities in order to highlight all 
the privileged activity fields of the Exxon 
company starting from a patents database related 
to engineering of oils. Main functionality is inter-
map communication. Multiple naming strategies, 
generation of queries and collection of 
intermediate results that have been implemented 
complementary to inter-map communication also 
play an important role in the analysis process. 
  
 
 
 
 
Activated area 
Inverse validation 
Activity resulting 
from the inverse 
validation 
Analysis of 
deduction 
Focali-
zation 
Inverse validation 
Activity resulting from 
the inverse validation
Projection resulting from the 
inverse validation 
  Legend : 
 Viewpoint  ?Patentees? 
Viewpoint ?Title?
1 
 2
3 
7 
6 Figure 7: Diagram of the analysis simulation 
4 
5 
8
9
=
Result = 28,6% and 23% 
Result = 100%
Activated area 
Categorical 
choice 
Result = 28,6% and 17% 
Categorical
rejection 
11
10 
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 854?863,
Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational Linguistics
Classifying French Verbs Using French and English Lexical Resources
Ingrid Falk
Universite? de Lorraine/LORIA,
Nancy, France
ingrid.falk@loria.fr
Claire Gardent
CNRS/LORIA,
Nancy, France
claire.gardent@loria.fr
Jean-Charles Lamirel
Universite? de Strasbourg/LORIA,
Nancy, France
jean-charles.lamirel@loria.fr
Abstract
We present a novel approach to the automatic
acquisition of a Verbnet like classification of
French verbs which involves the use (i) of
a neural clustering method which associates
clusters with features, (ii) of several super-
vised and unsupervised evaluation metrics and
(iii) of various existing syntactic and semantic
lexical resources. We evaluate our approach
on an established test set and show that it
outperforms previous related work with an F-
measure of 0.70.
1 Introduction
Verb classifications have been shown to be useful
both from a theoretical and from a practical perspec-
tive. From the theoretical viewpoint, they permit
capturing syntactic and/or semantic generalisations
about verbs (Levin, 1993; Kipper Schuler, 2006).
From a practical perspective, they support factorisa-
tion and have been shown to be effective in various
NLP (Natural language Processing) tasks such as se-
mantic role labelling (Swier and Stevenson, 2005) or
word sense disambiguation (Dang, 2004).
While there has been much work on automatically
acquiring verb classes for English (Sun et al, 2010)
and to a lesser extent for German (Brew and Schulte
im Walde, 2002; Schulte im Walde, 2003; Schulte
im Walde, 2006), Japanese (Oishi and Matsumoto,
1997) and Italian (Merlo et al, 2002), few studies
have been conducted on the automatic classification
of French verbs. Recently however, two proposals
have been put forward.
On the one hand, (Sun et al, 2010) applied
a clustering approach developed for English to
French. They exploit features extracted from a large
scale subcategorisation lexicon (LexSchem (Mes-
siant, 2008)) acquired fully automatically from Le
Monde newspaper corpus and show that, as for En-
glish, syntactic frames and verb selectional prefer-
ences perform better than lexical cooccurence fea-
tures. Their approach achieves a F-measure of
55.1 on 116 verbs occurring at least 150 times in
Lexschem. The best performance is achieved when
restricting the approach to verbs occurring at least
4000 times (43 verbs) with an F-measure of 65.4.
On the other hand, Falk and Gardent (2011)
present a classification approach for French verbs
based on the use of Formal Concept Analysis (FCA).
FCA (Barbut and Monjardet, 1970) is a sym-
bolic classification technique which permits creating
classes associating sets of objects (eg. French verbs)
with sets of features (eg. syntactic frames). Falk
and Gardent (2011) provide no evaluation for their
results however, only a qualitative analysis.
In this paper, we describe a novel approach to the
clustering of French verbs which (i) gives good re-
sults on the established benchmark used in (Sun et
al., 2010) and (ii) associates verbs with a feature
profile describing their syntactic and semantic prop-
erties. The approach exploits a clustering method
called IGNGF (Incremental Growing Neural Gas
with Feature Maximisation, (Lamirel et al, 2011b))
which uses the features characterising each cluster
both to guide the clustering process and to label the
output clusters. We apply this method to the data
contained in various verb lexicons and we evalu-
854
ate the resulting classification on a slightly modified
version of the gold standard provided by (Sun et al,
2010). We show that the approach yields promising
results (F-measure of 70%) and that the clustering
produced systematically associates verbs with syn-
tactic frames and thematic grids thereby providing
an interesting basis for the creation and evaluation
of a Verbnet-like classification.
Section 2 describes the lexical resources used for
feature extraction and Section 3 the experimental
setup. Sections 4 and 5 present the data used for
and the results obtained. Section 6 concludes.
2 Lexical Resources Used
Our aim is to accquire a classification which covers
the core verbs of French, could be used to support
semantic role labelling and is similar in spirit to the
English Verbnet. In this first experiment, we there-
fore favoured extracting the features used for clus-
tering, not from a large corpus parsed automatically,
but from manually validated resources1. These lexi-
cal resources are (i) a syntactic lexicon produced by
merging three existing lexicons for French and (ii)
the English Verbnet.
Among the many syntactic lexicons available for
French (Nicolas et al, 2008; Messiant, 2008; Kups?c?
and Abeille?, 2008; van den Eynde and Mertens,
2003; Gross, 1975), we selected and merged three
lexicons built or validated manually namely, Dico-
valence, TreeLex and the LADL tables. The result-
ing lexicon contains 5918 verbs, 20433 lexical en-
tries (i.e., verb/frame pairs) and 345 subcategorisa-
tion frames. It also contains more detailed syntac-
tic and semantic features such as lexical preferences
(e.g., locative argument, concrete object) or thematic
role information (e.g., symmetric arguments, asset
role) which we make use of for clustering.
We use the English Verbnet as a resource for asso-
ciating French verbs with thematic grids as follows.
We translate the verbs in the English Verbnet classes
to French using English-French dictionaries2. To
1Of course, the same approach could be applied to corpus
based data (as done e.g., in (Sun et al, 2010)) thus making the
approach fully unsupervised and directly applicable to any lan-
guage for which a parser is available.
2For the translation we use the following resources: Sci-
Fran-Euradic, a French-English bilingual dictionary, built and
improved by linguists (http://catalog.elra.info/
deal with polysemy, we train a supervised classifier
as follows. We first map French verbs with English
Verbnet classes: A French verb is associated with
an English Verbnet class if, according to our dictio-
naries, it is a translation of an English verb in this
class. The task of the classifier is then to produce
a probability estimate for the correctness of this as-
sociation, given the training data. The training set
is built by stating for 1740 ?French verb, English
Verbnet class? pairs whether the verb has the the-
matic grid given by the pair?s Verbnet class3. This
set is used to train an SVM (support vector machine)
classifier4. The features we use are similar to those
used in (Mouton, 2010): they are numeric and are
derived for example from the number of translations
an English or French verb had, the size of the Verb-
net classes, the number of classes a verb is a member
of etc. The resulting classifier gives for each ?French
verb, English VN class? pair the estimated probabil-
ity of the pair?s verb being a member of the pair?s
class5. We select 6000 pairs with highest proba-
bility estimates and obtain the translated classes by
assigning each verb in a selected pair to the pair?s
class. This way French verbs are effectively asso-
ciated with one or more English Verbnet thematic
grids.
3 Clustering Methods, Evaluation Metrics
and Experimental Setup
3.1 Clustering Methods
The IGNGF clustering method is an incremental
neural ?winner-take-most? clustering method be-
longing to the family of the free topology neu-
ral clustering methods. Like other neural free
topology methods such as Neural Gas (NG) (Mar-
tinetz and Schulten, 1991), Growing Neural Gas
(GNG) (Fritzke, 1995), or Incremental Growing
Neural Gas (IGNG) (Prudent and Ennaji, 2005),
the IGNGF method makes use of Hebbian learning
product_info.php?products_id=666), Google dic-
tionary (http://www.google.com/dictionary) and
Dicovalence (van den Eynde and Mertens, 2003).
3The training data consists of the verbs and Verbnet classes
used in the gold standard presented in (Sun et al, 2010).
4We used the libsvm (Chang and Lin, 2011) implementation
of the classifier for this step.
5The accuracy of the classifier on the held out random test
set of 100 pairs was of 90%.
855
(Hebb, 1949) for dynamically structuring the learn-
ing space. However, contrary to these methods, the
use of a standard distance measure for determining a
winner is replaced in IGNGF by feature maximisa-
tion. Feature maximisation is a cluster quality metric
which associates each cluster with maximal features
i.e., features whose Feature F-measure is maximal.
Feature F-measure is the harmonic mean of Feature
Recall and Feature Precision which in turn are de-
fined as:
FRc(f) =
?
v?c
W fv
?
c??C
?
v?c?
W fv
, FPc(f) =
?
v?c
W fv
?
f ??Fc,v?c
W f
?
v
where W fx represents the weight of the feature f for
element x and Fc designates the set of features as-
sociated with the verbs occuring in the cluster c. A
feature is then said to be maximal for a given clus-
ter iff its Feature F-measure is higher for that cluster
than for any other cluster.
The IGNGF method was shown to outperform
other usual neural and non neural methods for clus-
tering tasks on relatively clean data (Lamirel et al,
2011b). Since we use features extracted from man-
ually validated sources, this clustering technique
seems a good fit for our application. In addition,
the feature maximisation and cluster labeling per-
formed by the IGNGF method has proved promising
both for visualising clustering results (Lamirel et al,
2008) and for validating or optimising a clustering
method (Attik et al, 2006). We make use of these
processes in all our experiments and systematically
compute cluster labelling and feature maximisation
on the output clusterings. As we shall see, this per-
mits distinguishing between clusterings with simi-
lar F-measure but lower ?linguistic plausibility? (cf.
Section 5). This facilitates clustering interpretation
in that cluster labeling clearly indicates the associa-
tion between clusters (verbs) and their prevalent fea-
tures. And this supports the creation of a Verbnet
style classification in that cluster labeling directly
provides classes grouping together verbs, thematic
grids and subcategorisation frames.
3.2 Evaluation metrics
We use several evaluation metrics which bear on dif-
ferent properties of the clustering.
Modified Purity and Accuracy. Following (Sun
et al, 2010), we use modified purity (mPUR);
weighted class accuracy (ACC) and F-measure to
evaluate the clusterings produced. These are com-
puted as follows. Each induced cluster is assigned
the gold class (its prevalent class, prev(C)) to which
most of its member verbs belong. A verb is then said
to be correct if the gold associates it with the preva-
lent class of the cluster it is in. Given this, purity is
the ratio between the number of correct gold verbs
in the clustering and the total number of gold verbs
in the clustering6:
mPUR =
?
C?Clustering,|prev(C)|>1 |prev(C) ? C|
VerbsGold?Clustering
,
where VerbsGold?Clustering is the total number of gold
verbs in the clustering.
Accuracy represents the proportion of gold verbs
in those clusters which are associated with a gold
class, compared to all the gold verbs in the clus-
tering. To compute accuracy we associate to each
gold class CGold a dominant cluster, ie. the cluster
dom(CGold) which has most verbs in common with
the gold class. Then accuracy is given by the follow-
ing formula:
ACC =
?
C?Gold |dom(C) ? C|
VerbsGold?Clustering
Finally, F-measure is the harmonic mean of mPUR
and ACC.
Coverage. To assess the extent to which a cluster-
ing matches the gold classification, we additionally
compute the coverage of each clustering that is, the
proportion of gold classes that are prevalent classes
in the clustering.
Cumulative Micro Precision (CMP). As pointed
out in (Lamirel et al, 2008; Attik et al, 2006), un-
supervised evaluation metrics based on cluster la-
belling and feature maximisation can prove very
useful for identifying the best clustering strategy.
Following (Lamirel et al, 2011a), we use CMP to
identify the best clustering. Computed on the clus-
tering results, this metrics evaluates the quality of a
clustering w.r.t. the cluster features rather than w.r.t.
6Clusters for which the prevalent class has only one element
are ignored
856
to a gold standard. It was shown in (Ghribi et al,
2010) to be effective in detecting degenerated clus-
tering results including a small number of large het-
erogeneous, ?garbage? clusters and a big number of
small size ?chunk? clusters.
First, the local Recall (Rfc ) and the local Preci-
sion (P fc ) of a feature f in a cluster c are defined as
follows:
Rfc =
|vfc |
|V f |
P fc =
|vfc |
|Vc|
where vfc is the set of verbs having feature f in c, Vc
the set of verbs in c and V f , the set of verbs with
feature f .
Cumulative Micro-Precision (CMP) is then de-
fined as follows:
CMP =
?
i=|Cinf |,|Csup|
1
|Ci+|2
?
c?Ci+,f?Fc P
f
c
?
i=|Cinf |,|Csup|
1
Ci+
where Ci+ represents the subset of clusters of C
for which the number of associated verbs is greater
than i, and: Cinf = argminci?C |ci|, Csup =
argmaxci?C |ci|
3.3 Cluster display, feature f-Measure and
confidence score
To facilitate interpretation, clusters are displayed as
illustrated in Table 1. Features are displayed in
decreasing order of Feature F-measure (cf. Sec-
tion 3.1) and features whose Feature F-measure is
under the average Feature F-measure of the over-
all clustering are clearly delineated from others. In
addition, for each verb in a cluster, a confidence
score is displayed which is the ratio between the sum
of the F-measures of its cluster maximised features
over the sum of the F-measures of the overall cluster
maximised features. Verbs whose confidence score
is 0 are considered as orphan data.
3.4 Experimental setup
We applied an IDF-Norm weighting scheme
(Robertson and Jones, 1976) to decrease the influ-
ence of the most frequent features (IDF component)
and to compensate for discrepancies in feature num-
ber (normalisation).
C6- 14(14) [197(197)]
???-
Prevalent Label ? = AgExp-Cause
0.341100 G-AgExp-Cause
0.274864 C-SUJ:Ssub,OBJ:NP
0.061313 C-SUJ:Ssub
0.042544 C-SUJ:NP,DEOBJ:Ssub
**********
**********
0.017787 C-SUJ:NP,DEOBJ:VPinf
0.008108 C-SUJ:VPinf,AOBJ:PP
. . .
[**de?primer 0.934345 4(0)] [affliger 0.879122 3(0)]
[e?blouir 0.879122 3(0)] [choquer 0.879122 3(0)]
[de?cevoir 0.879122 3(0)] [de?contenancer 0.879122
3(0)] [de?contracter 0.879122 3(0)] [de?sillusionner
0.879122 3(0)] [**ennuyer 0.879122 3(0)] [fasciner
0.879122 3(0)] [**heurter 0.879122 3(0)] . . .
Table 1: Sample output for a cluster produced with
the grid-scf-sem feature set and the IGNGF clustering
method.
We use K-Means as a baseline. For each cluster-
ing method (K-Means and IGNGF), we let the num-
ber of clusters vary between 1 and 30 to obtain a
partition that reaches an optimum F-measure and a
number of clusters that is in the same order of mag-
nitude as the initial number of Gold classes (i.e. 11
classes).
4 Features and Data
Features In the simplest case the features are
the subcategorisation frames (scf) associated to the
verbs by our lexicon. We also experiment with dif-
ferent combinations of additional, syntactic (synt)
and semantic features (sem) extracted from the lex-
icon and with the thematic grids (grid) extracted
from the English Verbnet.
The thematic grid information is derived from the
English Verbnet as explained in Section 2. The syn-
tactic features extracted from the lexicon are listed
in Table 1(a). They indicate whether a verb accepts
symmetric arguments (e.g., John met Mary/John and
Mary met); has four or more arguments; combines
with a predicative phrase (e.g., John named Mary
president); takes a sentential complement or an op-
tional object; or accepts the passive in se (similar to
the English middle voice Les habits se vendent bien /
The clothes sell well). As shown in Table 1(a), these
857
(a) Additional syntactic features.
Feature related VN class
Symmetric arguments amalgamate-22.2, correspond-36.1
4 or more arguments get-13.5.1, send-11.1
Predicate characterize-29.2
Sentential argument correspond-36.1, characterize-29.2
Optional object implicit theme (Randall, 2010), p. 95
Passive built with se theme role (Randall, 2010), p. 120
(b) Additional semantic features.
Feature related VN class
Location role put-9.1, remove-10.1, . . .
Concrete object hit-18.1 (eg. INSTRUMENT)
(non human role) other cos-45.4 . . .
Asset role get-13.5.1
Plural role amalgamate-22.2, correspond-36.1
Table 2: Additional syntactic (a) and semantic (b) fea-
tures extracted from the LADL and Dicovalence re-
sources and the alternations/roles they are possibly re-
lated to.
features are meant to help identify specific Verbnet
classes and thematic roles. Finally, we extract four
semantic features from the lexicon. These indicate
whether a verb takes a locative or an asset argument
and whether it requires a concrete object (non hu-
man role) or a plural role. The potential correlation
between these features and Verbnet classes is given
in Table 1(b).
French Gold Standard To evaluate our approach,
we use the gold standard proposed by Sun et al
(2010). This resource consists of 16 fine grained
Levin classes with 12 verbs each whose predomi-
nant sense in English belong to that class. Since
our goal is to build a Verbnet like classification
for French, we mapped the 16 Levin classes of the
Sun et al (2010)?s Gold Standard to 11 Verbnet
classes thereby associating each class with a the-
matic grid. In addition we group Verbnet semantic
roles as shown in Table 4. Table 3 shows the refer-
ence we use for evaluation.
Verbs For our clustering experiments we use the
2183 French verbs occurring in the translations of
the 11 classes in the gold standard (cf. Section 4).
Since we ignore verbs with only one feature the
number of verbs and ?verb, feature? pairs considered
may vary slightly across experiments.
AgExp Agent, Experiencer
AgentSym Actor, Actor1, Actor2
Theme Theme, Topic, Stimulus, Proposition
PredAtt Predicate, Attribute
ThemeSym Theme, Theme1, Theme2
Patient Patient
PatientSym Patient, Patient1, Patient2
Start Material (transformation), Source (motion,
transfer)
End Product (transformation), Destination (mo-
tion), Recipient (transfer)
Location
Instrument
Cause
Beneficiary
Table 4: Verbnet role groups.
5 Results
5.1 Quantitative Analysis
Table 4(a) includes the evaluation results for all the
feature sets when using IGNGF clustering.
In terms of F-measure, the results range from 0.61
to 0.70. This generally outperforms (Sun et al,
2010) whose best F-measures vary between 0.55 for
verbs occurring at least 150 times in the training data
and 0.65 for verbs occurring at least 4000 times in
this training data. The results are not directly com-
parable however since the gold data is slightly dif-
ferent due to the grouping of Verbnet classes through
their thematic grids.
In terms of features, the best results are ob-
tained using the grid-scf-sem feature set with an F-
measure of 0.70. Moreover, for this data set, the un-
supervised evaluation metrics (cf. Section 3) high-
light strong cluster cohesion with a number of clus-
ters close to the number of gold classes (13 clusters
for 11 gold classes); a low number of orphan verbs
(i.e., verbs whose confidence score is zero); and a
high Cumulated Micro Precision (CMP = 0.3) indi-
cating homogeneous clusters in terms of maximis-
ing features. The coverage of 0.72 indicates that ap-
proximately 8 out of the 11 gold classes could be
matched to a prevalent label. That is, 8 clusters were
labelled with a prevalent label corresponding to 8
distinct gold classes.
In contrast, the classification obtained using the
scf-synt-sem feature set has a higher CMP for the
clustering with optimal mPUR (0.57); but a lower
F-measure (0.61), a larger number of classes (16)
858
AgExp, PatientSym
amalgamate-22.2: incorporer, associer, re?unir, me?langer, me?ler, unir, assembler, combiner, lier, fusionner
Cause, AgExp
amuse-31.1: abattre, accabler, briser, de?primer, consterner, ane?antir, e?puiser, exte?nuer, e?craser, ennuyer, e?reinter, inonder
AgExp, PredAtt, Theme
characterize-29.2: appre?hender, concevoir, conside?rer, de?crire, de?finir, de?peindre, de?signer, envisager, identifier, montrer, percevoir, repre?senter, ressen-
tir
AgentSym, Theme
correspond-36.1: coope?rer, participer, collaborer, concourir, contribuer, associer
AgExp, Beneficiary, Extent, Start, Theme
get-13.5.1: acheter, prendre, saisir, re?server, conserver, garder, pre?server, maintenir, retenir, louer, affre?ter
AgExp, Instrument, Patient
hit-18.1: cogner, heurter, battre, frapper, fouetter, taper, rosser, brutaliser, e?reinter, maltraiter, corriger
other cos-45.4: me?langer, fusionner, consolider, renforcer, fortifier, adoucir, polir, atte?nuer, tempe?rer, pe?trir, fac?onner, former
AgExp, Location, Theme
light emission-43.1 briller, e?tinceler, flamboyer, luire, resplendir, pe?tiller, rutiler, rayonner, scintiller
modes of being with motion-47.3: trembler, fre?mir, osciller, vaciller, vibrer, tressaillir, frissonner, palpiter, gre?siller, trembloter, palpiter
run-51.3.2: voyager, aller, errer, circuler, courir, bouger, naviguer, passer, promener, de?placer
AgExp, End, Theme
manner speaking-37.3: ra?ler, gronder, crier, ronchonner, grogner, bougonner, maugre?er, rouspe?ter, grommeler, larmoyer, ge?mir, geindre, hurler,
gueuler, brailler, chuchoter
put-9.1: accrocher, de?poser, mettre, placer, re?partir, re?inte?grer, empiler, emporter, enfermer, inse?rer, installer
say-37.7: dire, re?ve?ler, de?clarer, signaler, indiquer, montrer, annoncer, re?pondre, affirmer, certifier, re?pliquer
AgExp, Theme
peer-30.3: regarder, e?couter, examiner, conside?rer, voir, scruter, de?visager
AgExp, Start, Theme
remove-10.1: o?ter, enlever, retirer, supprimer, retrancher, de?barasser, soustraire, de?compter, e?liminer
AgExp, End, Start, Theme
send-11.1: envoyer, lancer, transmettre, adresser, porter, expe?dier, transporter, jeter, renvoyer, livrer
Table 3: French gold classes and their member verbs presented in (Sun et al, 2010).
and a higher number of orphans (156). That is, this
clustering has many clusters with strong feature co-
hesion but a class structure that markedly differs
from the gold. Since there might be differences in
structure between the English Verbnet and the the-
matic classification for French we are building, this
is not necessarily incorrect however. Further inves-
tigation on a larger data set would be required to as-
sess which clustering is in fact better given the data
used and the classification searched for.
In general, data sets whose description includes
semantic features (sem or grid) tend to produce bet-
ter results than those that do not (scf or synt). This
is in line with results from (Sun et al, 2010) which
shows that semantic features help verb classifica-
tion. It differs from it however in that the seman-
tic features used by Sun et al (2010) are selectional
preferences while ours are thematic grids and a re-
stricted set of manually encoded selectional prefer-
ences.
Noticeably, the synt feature degrades perfor-
mance throughout: grid,scf,synt has lower F-
measure than grid,scf; scf,synt,sem than scf,sem;
and scf,synt than scf. We have no clear explanation
for this.
The best results are obtained with IGNGF method
on most of the data sets. Table 4(b) illustrates
the differences between the results obtained with
IGNGF and those obtained with K-means on the
grid-scf-sem data set (best data set). Although K-
means and IGNGF optimal model reach similar F-
measure and display a similar number of clusters,
the very low CMP (0.10) of the K-means model
shows that, despite a good Gold class coverage
(0.81), K-means tend to produce more heteroge-
neous clusters in terms of features.
Table 4(b) also shows the impact of IDF feature
weighting and feature vector normalisation on clus-
tering. The benefit of preprocessing the data appears
clearly. When neither IDF weighting nor vector nor-
malisation are used, F-measure decreases from 0.70
to 0.68 and cumulative micro-precision from 0.30
to 0.21. When either normalisation or IDF weight-
ing is left out, the cumulative micro-precision drops
by up to 15 points (from 0.30 to 0.15 and 0.18) and
the number of orphans increases from 67 up to 180.
859
(a) The impact of the feature set.
Feat. set Nbr. feat. Nbr. verbs mPUR ACC F (Gold) Nbr. classes Cov. Nbr. orphans CMP at opt (13cl.)
scf 220 2085 0.93 0.48 0.64 17 0.55 129 0.28 (0.27)
grid, scf 231 2085 0.94 0.54 0.68 14 0.64 183 0.12 (0.12)
grid, scf, sem 237 2183 0.86 0.59 0.70 13 0.72 67 0.30 (0.30)
grid, scf, synt 236 2150 0.87 0.50 0.63 14 0.72 66 0.13 (0.14)
grid, scf, synt, sem 242 2201 0.99 0.52 0.69 16 0.82 100 0.50 (0.22)
scf, sem 226 2183 0.83 0.55 0.66 23 0.64 146 0.40 (0.26)
scf, synt 225 2150 0.91 0.45 0.61 15 0.45 83 0.17 (0.22)
scf, synt, sem 231 2101 0.89 0.47 0.61 16 0.64 156 0.57 (0.11)
(b) Metrics for best performing clustering method (IGNGF) compared to K-means. Feature set is grid, scf, sem.
Method mPUR ACC F (Gold) Nbr. classes Cov. Nbr. orphans CMP at opt (13cl.)
IGNGF with IDF and norm. 0.86 0.59 0.70 13 0.72 67 0.30 (0.30)
K-means with IDF and norm. 0.88 0.57 0.70 13 0.81 67 0.10 (0.10)
IGNGF, no IDF 0.86 0.59 0.70 17 0.81 126 0.18 (0.14)
IGNGF, no norm. 0.78 0.62 0.70 18 0.72 180 0.15 (0.11)
IGNGF, no IDF, no norm. 0.87 0.55 0.68 14 0.81 103 0.21 (0.21)
Table 5: Results. Cumulative micro precision (CMP) is given for the clustering at the mPUR optimum and in paran-
theses for 13 classes clustering.
That is, clusters are less coherent in terms of fea-
tures.
5.2 Qualitative Analysis
We carried out a manual analysis of the clusters ex-
amining both the semantic coherence of each cluster
(do the verbs in that cluster share a semantic com-
ponent?) and the association between the thematic
grids, the verbs and the syntactic frames provided
by clustering.
Semantic homogeneity: To assess semantic ho-
mogeneity, we examined each cluster and sought
to identify one or more Verbnet labels character-
ising the verbs contained in that cluster. From
the 13 clusters produced by clustering, 11 clus-
ters could be labelled. Table 6 shows these eleven
clusters, the associated labels (abbreviated Verbnet
class names), some example verbs, a sample sub-
categorisation frame drawn from the cluster max-
imising features and an illustrating sentence. As
can be seen, some clusters group together several
subclasses and conversely, some Verbnet classes are
spread over several clusters. This is not necessar-
ily incorrect though. To start with, recall that we
are aiming for a classification which groups together
verbs with the same thematic grid. Given this, clus-
ter C2 correctly groups together two Verbnet classes
(other cos-45.4 and hit-18.1) which share the same
thematic grid (cf. Table 3). In addition, the features
associated with this cluster indicate that verbs in
these two classes are transitive, select a concrete ob-
ject, and can be pronominalised which again is cor-
rect for most verbs in that cluster. Similarly, cluster
C11 groups together verbs from two Verbnet classes
with identical theta grid (light emission-43.1 and
modes of being with motion-47.3) while its associ-
ated features correctly indicate that verbs from both
classes accept both the intransitive form without ob-
ject (la jeune fille rayonne / the young girl glows, un
cheval galope / a horse gallops) and with a prepo-
sitional object (la jeune fille rayonne de bonheur /
the young girl glows with happiness, un cheval ga-
lope vers l?infini / a horse gallops to infinity). The
third cluster grouping together verbs from two Verb-
net classes is C7 which contains mainly judgement
verbs (to applaud, bless, compliment, punish) but
also some verbs from the (very large) other cos-45.4
class. In this case, a prevalent shared feature is
that both types of verbs accept a de-object that is,
a prepositional object introduced by ?de? (Jean ap-
plaudit Marie d?avoir danse? / Jean applaudit Marie
for having danced; Jean de?gage le sable de la route /
Jean clears the sand of the road). The semantic fea-
tures necessary to provide a finer grained analysis of
their differences are lacking.
Interestingly, clustering also highlights classes
which are semantically homogeneous but syntac-
tically distinct. While clusters C6 and C10 both
860
contain mostly verbs from the amuse-31.1 class
(amuser,agacer,e?nerver,de?primer), their features in-
dicate that verbs in C10 accept the pronominal form
(e.g., Jean s?amuse) while verbs in C6 do not (e.g.,
*Jean se de?prime). In this case, clustering highlights
a syntactic distinction which is present in French but
not in English. In contrast, the dispersion of verbs
from the other cos-45.4 class over clusters C2 and
C7 has no obvious explanation. One reason might
be that this class is rather large (361 verbs) and thus
might contain French verbs that do not necessarily
share properties with the original Verbnet class.
Syntax and Semantics. We examined whether the
prevalent syntactic features labelling each cluster
were compatible with the verbs and with the seman-
tic class(es) manually assigned to the clusters. Ta-
ble 6 sketches the relation between cluster, syntac-
tic frames and Verbnet like classes. It shows for in-
stance that the prevalent frame of the C0 class (man-
ner speaking-37.3) correctly indicates that verbs in
that cluster subcategorise for a sentential argument
and an AOBJ (prepositional object in ?a`?) (e.g., Jean
bafouille a` Marie qu?il est amoureux / Jean stam-
mers to Mary that he is in love); and that verbs
in the C9 class (characterize-29.2) subcategorise for
an object NP and an attribute (Jean nomme Marie
pre?sidente / Jean appoints Marie president). In gen-
eral, we found that the prevalent frames associated
with each cluster adequately characterise the syntax
of that verb class.
6 Conclusion
We presented an approach to the automatic classi-
fication of french verbs which showed good results
on an established testset and associates verb clusters
with syntactic and semantic features.
Whether the features associated by the IGNGF
clustering with the verb clusters appropriately car-
acterise these clusters remains an open question. We
carried out a first evaluation using these features
to label the syntactic arguments of verbs in a cor-
pus with thematic roles and found that precision is
high but recall low mainly because of polysemy: the
frames and grids made available by the classification
for a given verb are correct for that verb but not for
the verb sense occurring in the corpus. This sug-
gests that overlapping clustering techniques need to
C0 speaking: babiller, bafouiller, balbutier
SUJ:NP,OBJ:Ssub,AOBJ:PP
Jean bafouille a` Marie qu?il l?aime / Jean stammers to Mary that he is
in love
C1 put: entasser, re?pandre, essaimer
SUJ:NP,POBJ:PP,DUMMY:REFL
Loc, Plural
Les de?chets s?entassent dans la cour / Waste piles in the yard
C2 hit: broyer, de?molir, fouetter
SUJ:NP,OBJ:NP
T-Nhum
Ces pierres broient les graines / These stones grind the seeds.
other cos: agrandir, alle?ger, amincir
SUJ:NP,DUMMY:REFL
les ae?roports s?agrandissent sans arre?t / airports grow constantly
C4 dedicate: s?engager a`, s?obliger a`,
SUJ:NP,AOBJ:VPinf,DUMMY:REFL
Cette promesse t?engage a` nous suivre / This promise commits you to
following us
C5 conjecture: penser, attester, agre?er
SUJ:NP,OBJ:Ssub
Le me?decin atteste que l?employe? n?est pas en e?tat de travailler / The
physician certifies that the employee is not able to work
C6 amuse: de?primer, de?contenancer, de?cevoir
SUJ:Ssub,OBJ:NP
SUJ:NP,DEOBJ:Ssub
Travailler de?prime Marie / Working depresses Marie
Marie de?prime de ce que Jean parte / Marie depresses because of Jean?s
leaving
C7 other cos: de?gager, vider, drainer, sevrer
judgement
SUJ:NP,OBJ:NP,DEOBJ:PP
vider le re?cipient de son contenu / empty the container of its contents
applaudir, be?nir, bla?mer,
SUJ:NP,OBJ:NP,DEOBJ:Ssub
Jean blame Marie d?avoir couru / Jean blames Mary for runnig
C9 characterise: promouvoir, adouber, nommer
SUJ:NP,OBJ:NP,ATB:XP
Jean nomme Marie pre?sidente / Jean appoints Marie president
C10 amuse: agacer, amuser, enorgueillir
SUJ:NP,DEOBJ:XP,DUMMY:REFL
Jean s?enorgueillit d?e?tre roi/ Jean is proud to be king
C11 light: rayonner,clignoter,cliqueter
SUJ:NP,POBJ:PP
Jean clignote des yeux / Jean twinkles his eyes
motion: aller, passer, fuir, glisser
SUJ:NP,POBJ:PP
glisser sur le trottoir verglace? / slip on the icy sidewalk
C12 transfer msg: enseigner, permettre, interdire
SUJ:NP,OBJ:NP,AOBJ:PP
Jean enseigne l?anglais a` Marie / Jean teaches Marie English.
Table 6: Relations between clusters, syntactic frames and
Verbnet like classes.
be applied.
We are also investigating how the approach scales
up to the full set of verbs present in the lexicon. Both
Dicovalence and the LADL tables contain rich de-
tailed information about the syntactic and semantic
properties of French verbs. We intend to tap on that
potential and explore how well the various semantic
features that can be extracted from these resources
support automatic verb classification for the full set
of verbs present in our lexicon.
861
References
M. Attik, S. Al Shehabi, and J.-C. Lamirel. 2006. Clus-
tering Quality Measures for Data Samples with Mul-
tiple Labels. In Databases and Applications, pages
58?65.
M. Barbut and B. Monjardet. 1970. Ordre et Classifica-
tion. Hachette Universite?.
C. Brew and S. Schulte im Walde. 2002. Spectral Clus-
tering for German Verbs. In Proceedings of the Con-
ference on Empirical Methods in Natural Language
Processing, pages 117?124, Philadelphia, PA.
C. Chang and C. Lin. 2011. LIBSVM: A library for
support vector machines. ACM Transactions on Intel-
ligent Systems and Technology, 2:27:1?27:27. Soft-
ware available at http://www.csie.ntu.edu.
tw/?cjlin/libsvm.
H. T. Dang. 2004. Investigations into the role of lexical
semantics in word sense disambiguation. Ph.D. thesis,
U. Pennsylvannia, US.
I. Falk and C. Gardent. 2011. Combining Formal Con-
cept Analysis and Translation to Assign Frames and
Thematic Role Sets to French Verbs. In Amedeo
Napoli and Vilem Vychodil, editors, Concept Lattices
and Their Applications, Nancy, France, October.
B. Fritzke. 1995. A growing neural gas network learns
topologies. Advances in Neural Information Process-
ing Systems 7, 7:625?632.
M. Ghribi, P. Cuxac, J.-C. Lamirel, and A. Lelu. 2010.
Mesures de qualite? de clustering de documents : prise
en compte de la distribution des mots cle?s. In Nicolas
Be?chet, editor, E?valuation des me?thodes d?Extraction
de Connaissances dans les Donne?es- EvalECD?2010,
pages 15?28, Hammamet, Tunisie, January. Fatiha
Sa??s.
M. Gross. 1975. Me?thodes en syntaxe. Hermann, Paris.
D. O. Hebb. 1949. The organization of behavior: a
neuropsychological theory. John Wiley & Sons, New
York.
K. Kipper Schuler. 2006. VerbNet: A Broad-Coverage,
Comprehensive Verb Lexicon. Ph.D. thesis, University
of Pennsylvania.
A. Kups?c? and A. Abeille?. 2008. Growing treelex. In
Alexander Gelbkuh, editor, Computational Linguis-
tics and Intelligent Text Processing, volume 4919 of
Lecture Notes in Computer Science, pages 28?39.
Springer Berlin / Heidelberg.
J.-C. Lamirel, A. Phuong Ta, and M. Attik. 2008. Novel
Labeling Strategies for Hierarchical Representation of
Multidimensional Data Analysis Results. In AIA -
IASTED, Innbruck, Autriche.
J. C. Lamirel, P. Cuxac, and R. Mall. 2011a. A new
efficient and unbiased approach for clustering quality
evaluation. In QIMIE?11, PaKDD, Shenzen, China.
J.-C. Lamirel, R. Mall, P. Cuxac, and G. Safi. 2011b.
Variations to incremental growing neural gas algo-
rithm based on label maximization. In Neural Net-
works (IJCNN), The 2011 International Joint Confer-
ence on, pages 956 ?965.
B. Levin. 1993. English Verb Classes and Alternations:
a preliminary investigation. University of Chicago
Press, Chicago and London.
T. Martinetz and K. Schulten. 1991. A ?Neural-Gas?
Network Learns Topologies. Artificial Neural Net-
works, I:397?402.
P. Merlo, S. Stevenson, V. Tsang, and G. Allaria. 2002.
A multilingual paradigm for automatic verb classifica-
tion. In ACL, pages 207?214.
C. Messiant. 2008. A subcategorization acquisition sys-
tem for French verbs. In Proceedings of the ACL-
08: HLT Student Research Workshop, pages 55?60,
Columbus, Ohio, June. Association for Computational
Linguistics.
C. Mouton. 2010. Ressources et me?thodes semi-
supervise?es pour l?analyse se?mantique de textes en
fran cais. Ph.D. thesis, Universite? Paris 11 - Paris Sud
UFR d?informatique.
L. Nicolas, B. Sagot, E?. de La Clergerie, and J. Farre?.
2008. Computer aided correction and extension of a
syntactic wide-coverage lexicon. In Proc. of CoLing
2008, Manchester, UK, August.
A. Oishi and Y. Matsumoto. 1997. Detecting the orga-
nization of semantic subclasses of Japanese verbs. In-
ternational Journal of Corpus Linguistics, 2(1):65?89,
october.
Y. Prudent and A. Ennaji. 2005. An incremental grow-
ing neural gas learns topologies. In Neural Networks,
2005. IJCNN ?05. Proceedings. 2005 IEEE Interna-
tional Joint Conference on, volume 2, pages 1211?
1216.
J. H. Randall. 2010. Linking. Studies in Natural Lan-
guage and Linguistic Theory. Springer, Dordrecht.
S. E. Robertson and K. S. Jones. 1976. Relevance
weighting of search terms. Journal of the American
Society for Information Science, 27(3):129?146.
S. Schulte im Walde. 2003. Experiments on the Auto-
matic Induction of German Semantic Verb Classes.
Ph.D. thesis, Institut fu?r Maschinelle Sprachverar-
beitung, Universita?t Stuttgart. Published as AIMS Re-
port 9(2).
S. Schulte im Walde. 2006. Experiments on the au-
tomatic induction of german semantic verb classes.
Computational Linguistics, 32(2):159?194.
L. Sun, A. Korhonen, T. Poibeau, and C. Messiant. 2010.
Investigating the cross-linguistic potential of verbnet:
style classification. In Proceedings of the 23rd In-
ternational Conference on Computational Linguistics,
862
COLING ?10, pages 1056?1064, Stroudsburg, PA,
USA. Association for Computational Linguistics.
R. S. Swier and S. Stevenson. 2005. Exploiting
a verb lexicon in automatic semantic role labelling.
In HLT/EMNLP. The Association for Computational
Linguistics.
K. van den Eynde and P. Mertens. 2003. La valence :
l?approche pronominale et son application au lexique
verbal. Journal of French Language Studies, 13:63?
104.
863
