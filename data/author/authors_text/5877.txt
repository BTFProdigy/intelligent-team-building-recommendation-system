Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 105?108,
New York, June 2006. c?2006 Association for Computational Linguistics
Using Semantic Authoring for Blissymbols Communication Boards
Yael Netzer
Dept. of Computer Science
Ben Gurion University
Beer Sheva, Israel
yaeln@cs.bgu.ac.il
Michael Elhadad
Dept. of Computer Science
Ben Gurion University
Beer Sheva, Israel
elhadad@cs.bgu.ac.il
Abstract
Natural language generation (NLG) refers
to the process of producing text in a spo-
ken language, starting from an internal
knowledge representation structure. Aug-
mentative and Alternative Communica-
tion (AAC) deals with the development
of devices and tools to enable basic con-
versation for language-impaired people.
We present an applied prototype of an
AAC-NLG system generating written out-
put in English and Hebrew from a se-
quence of Bliss symbols. The system does
not ?translate? the symbols sequence, but
instead, it dynamically changes the com-
munication board as the choice of sym-
bols proceeds according to the syntactic
and semantic content of selected symbols,
generating utterances in natural language
through a process of semantic authoring.
1 Introduction
People who suffer from severe language impair-
ments lack the ability to express themselves through
natural usage of language and cannot achieve var-
ious forms of communication. The field of Aug-
mentative and Alternative Communication (AAC) is
concerned with methods that can be added to the
natural communication. In the most common form,
iconic symbols are presented on a display (or a com-
munication board). Communication is conducted by
the sequential selection of symbols on the display
(with vocal output when available), which are then
interpreted by the partner in the interaction.
AAC devices are characterized by three aspects:
(i) Selection method i.e., the physical choice of sym-
bols on the communication board; (ii) input lan-
guage and (iii) output medium. In a computerized
system, as (McCoy and Hershberger, 1999) mention,
a processing method aspect is added to this list. This
method refers to the process which creates the out-
put once symbols are inserted.
We specifically study the set of symbols (as an in-
put language) called Blissymbolics (Bliss in short).
Bliss is a graphic meaning-referenced language, cre-
ated by Charles Bliss to be used as a written univer-
sal language (Bliss, 1965); since 1971, Blissymbols
are used for communication with severely language-
impaired children. Bliss is designed to be a written-
only language, with non-arbitrary symbols. Sym-
bols are constructed from a composition of atomic
icons. Because words are structured from seman-
tic components, the graphic representation by itself
provides information on words? connectivity 1.
In the last decade, several systems that integrate
NLG techniques for AAC systems have been devel-
oped ((McCoy, 1997), (Vaillant, 1997) for example).
These systems share a common architecture: a tele-
graphic input sequence (words or symbols) is first
parsed, and then a grammatical sentence that repre-
sents the message is generated.
This paper presents an NLG-AAC system that
generates messages through a controlled process of
authoring, where each step in the selection of sym-
bols is controlled by the input specification defined
1See http://www.bci.org for reference on the language
105
for the linguistic realizer.
2 Generating Messages via Translation
A major difficulty when parsing a telegraphic se-
quence of words or symbols, is that many of the
hints that are used to capture the structure of the
text and, accordingly, the meaning of the utterance,
are missing. Moreover, as an AAC device is usu-
ally used for real-time conversation, the interpreta-
tion of utterances relies heavily on pragmatics ? time
of mentioned events, reference to the immediate en-
vironment.
Previous works dealing with translating tele-
graphic text, such as (Grishman and Sterling, 1989),
(Lee et al, 1997) requires to identify dependency
relations among the tokens of the telegraphic input.
Rich lexical knowledge is needed to identify possi-
ble dependencies in a given utterance, i.e., to find
the predicate and to apply constraints, such as selec-
tional restrictions to recognize its arguments.
Similar methods were used for AAC applica-
tions, COMPANSION (McCoy, 1997) for example
? where the telegraphic text is expanded to full sen-
tences, using a word order parser, and a semantic
parser to build the case frame structure of the verb
in the utterance, filling the slots with the rest of the
content words given. The system uses the semantic
representation to re-generate fluent text, relying on
lexical resources and NLG techniques.
The main questions at stake in this approach are
how good can a semantic parser be, in order to re-
construct the full structure of the sentence from tele-
graphic input and are pragmatic gaps in the given
telegraphic utterances recoverable in general.
3 Generating Messages via Semantic
Authoring
Our approach differs from previous NLG-AAC sys-
tems in that, with the model of semantic authoring
(Biller et al, 2005), we intervene during the process
of composing the input sequence, and thus can pro-
vide early feedback (in the form of display composi-
tion and partial text feedback), while preventing the
need for parsing a telegraphic sequence.
Semantic parsing is avoided by constructing a se-
mantic structure explicitly while the user inputs the
sequence incrementally. It combines three aspects
into an integrated approach for the design of an AAC
system:
? Semantic authoring drives a natural language
realization system and provides rich semantic
input.
? A display is updated on the fly as the authoring
system requires the user to select options.
? Ready-made inputs, corresponding to prede-
fined pragmatic contexts are made available to
the user as semantic templates.
In this method, each step of input insertion is con-
trolled by a set of constraints and rules, which are
drawn from an ontology. The system offers, at each
step, only possible complements to a small set of
concepts. For example, if the previous symbol de-
notes a verb which requires an instrumental theme,
only symbols that can function as instruments are
presented on the current display. Other symbols are
accessible through navigation operations, which are
interpreted in the context of the current partial se-
mantic specification. The general context of each
utterance or conversation can be determined by the
user, therefore narrowing the number of symbols
displayed in the board.
The underlying process of message generation is
based on layered lexical knowledge bases (LKB)
and an ontology. The ontology serves as a basis
for the semantic authoring process; it includes a hi-
erarchy of concepts and relations, and the informa-
tion it encodes interacts with the conceptual graphs
processing performed as part of content determina-
tion and lexical choice. The ontology was acquired
with a semi-automatic tool, which relies on WordNet
(Miller, 1995) and VerbNet (Kipper et al, 2000).
We designed and implemented the Bliss lexicon
for both Hebrew and English. The lexicon can be
used either as a stand-alone lexicon or as part of an
application through an API. The design of the lexi-
con takes advantage of the unique properties of the
language. The Bliss lexicon provides the list of sym-
bols accessible to the user, along with their graphic
representation, semantic information, and the map-
ping of symbols to English and Hebrew words. The
lexicon can be searched by keyword (learn), or by
semantic/graphic component: searching all words in
the lexicon that contain both food and meat returns
the symbols hamburger, hot-dog, meatball etc. (see
106
Fig. 1). The lexicon currently includes 2,200 en-
tries.
Figure 1: A snapshot of the Bliss Lexicon Web Ap-
plication
The core of the processing machinery of the
AAC message generation system is based on SAUT
(Biller et al, 2005) ? an authoring system for logical
forms encoded as conceptual graphs (CG). The sys-
tem belongs to the family of WYSIWYM (What You
See Is What You Mean) (Power and Scott, 1998) text
generation systems: logical forms are entered inter-
actively and the corresponding linguistic realization
of the expressions is generated in several languages.
The system maintains a model of the discourse con-
text corresponding to the authored documents to en-
able reference planning in the generation process.
Generating language from pictorial inputs, and
specifically from Bliss symbols using semantic au-
thoring in the WYSIWYM approach is not only a
pictorial application of the textual version, but it also
addresses specific needs of augmentative communi-
cation.
As was mentioned above, generating text from a
telegraphic message for AAC usage must take the
context of the conversation into account. We address
this problem in two manners: (1) adding pre-defined
inputs into the system (yet alowing accurate text
generation that considers syntactic variations), and
(2) enabling the assignment of default values to each
conversation (such as participants, tense, mood). We
also take advantage of the unique properties of the
Bliss symbols; the set of symbols that are offered
in each display can be filtered using their seman-
tic/graphical connectivity; the reduction of the num-
ber of possible choices that are to be made by the
user in each step of the message generation affects
the cognitive load and can affect the rate of commu-
nication.
4 Evaluation
We evaluate our system as an AAC application for
message generation from communication boards.
From an NLG evaluation perspective, this corre-
sponds to an intrinsic evaluation, i.e. judging quality
criteria of the generated text and its adequacy rela-
tive to the input (Bangalore et al, 1998). Since the
prototype of our system is not yet adjusted to inter-
act with alternative pointing devices, we could not
test it on actual Bliss users, and could not perform a
full extrinsic (task-based) evaluation.
However, as argued in (Higginbotham, 1995),
evaluations of AAC systems with nondisabled sub-
jects, when appropriately used, is easier to per-
form, and in some cases provide superior results.
Higginbotham?s claims rely on the observation that
the methods of message production are not unique
to AAC users and analogous communication situa-
tions exist both for disabled and nondisabled users.
Nondisabled subjects can contribute to the under-
standing of the cognitive processes underlying the
acquisition of symbol and device performance com-
petencies. We believe that the evaluation of effi-
ciency for non-AAC users should be served as base-
line.
The approach we offer for message generation re-
quires users to plan their sentences abstractly. (Mc-
Coy and Hershberger, 1999) points that novel sys-
tems may be found to slow communication but to in-
crease literacy skills. We therefore tested both speed
of message generation and semantic coverage (the
capability to generate a given message correctly).
The usage of semantic authoring was evaluated on
nondisabled subjects through a user study of 10 sub-
jects. This provides a reliable approximation of the
learning curve and usability of the system in general
(Biller et al, 2005).
In order to evaluate the keystroke savings of the
system we have collected a set of 19 sentences writ-
ten in Bliss and their full English correspondents.
We compared the number of the words in the Eng-
lish sentences with the number of choices needed
to generate the sentence with our system. The total
number of choice steps is 133, while the total num-
107
ber of words in the sentences is 122. This simple ra-
tio shows no improvement of keystrokes saving us-
ing our system. Savings, therefore, must be calcu-
lated in terms of narrowing the choice possibilities
in each step of the process.
However, counting the number of words does not
include morphology which in Bliss symbols requires
additional choices. We have counted the words
in the sentences considering morphology markers
of inflections as additional words, all summing to
138, as was suggested in (McCoy and Hershberger,
1999).
Assuming a display with 50 symbols (and addi-
tional keys for functions) ? a vocabulary of requires
50 different screens. Assuming symbols are orga-
nized by frequencies (first screens present the most
frequently used words) or by semantic domain.
The overall number of selections is reduced using
our communication board since the selectional re-
strictions narrow the number of possible choices that
can be made at each step. The extent to which selec-
tion time can be reduced at each step depends on the
application domain and the ontology structure. We
cannot evaluate it in general, but expect that a well-
structured ontology could support efficient selection
mechanisms, by grouping semantically related sym-
bols in dedicated displays.
In addition, the semantic authoring approach can
generate fluent output in other languages (English
and Hebrew, beyond the Bliss sequence ? without re-
quiring noisy translation). We also hypothesize that
ontologically motivated grouping of symbols could
speed up each selection step ? but this claim must be
assessed empirically in a task-based extrinsic evalu-
ation, which remains to be done in the future.
We are now building the environment for AAC
users with cooperation with ISAAC-ISRAEL 2, in
order to make the system fully accessible and to be
tested by AAC-users. However, this work is still in
progress. Once this will be achieved, full evaluation
of the system will be plausible.
5 Conclusions and Future Work
This work offers a new approach for message gen-
eration in the context of AAC displays using seman-
2Israeli chapter of the International Society for Augmenta-
tive and Alternative Communication
tic authoring and preventing the need to parse and
re-generate. We have designed and implemented a
Bliss lexicon for both Hebrew and English, which
can either be used a stand-alone lexicon for refer-
ence usage or as a part of an application.
Future work includes an implementation of a sys-
tem with full access for alternative devices, expan-
sion of the underlying lexicon for Hebrew genera-
tion, and adding voice output.
References
Srinivas Bangalore, Anoop Sarkar, Christy Doran, and Beth-
Ann Hockey. 1998. Grammar and parser evaluation in the
XTAG project. In Proc. of Workshop on Evaluation of Pars-
ing Systems, Granada, Spain, May.
Ofer Biller, Michael Elhadad, and Yael Netzer. 2005. Interac-
tive authoring of logical forms for multilingual generation.
In Proc. of the 10th workshop of ENLG, Aberdeen, Scotland.
Charles K. Bliss. 1965. Semantography (Blissymbolics). Se-
mantography Press, Sidney.
Ralph Grishman and John Sterling. 1989. Analyzing tele-
graphic messages. In Proc. of DARPA Speech and Natural
Language Workshop, pages 204?208, Philadelphia, Febru-
ary.
D. Jeffery Higginbotham. 1995. Use of nondisabled subjects
in AAC research: Confessions of a research infidel. AAC
Augmentative and Alternative Communication, 11, March.
AAC Research forum.
K. Kipper, H. Trang Dang, and M. Palmer. 2000. Class-based
construction of a verb lexicon. In Proceeding of AAAI-2000.
Young-Suk Lee, Clifford Weinstein, Stephanie Seneff, and Di-
nesh Tummala. 1997. Ambiguity resolution for machine
translation of telegraphic messages. In Proc. of the 8th con-
ference on EACL, pages 120?127.
Kathleen F. McCoy and Dave Hershberger. 1999. The role
of evaluation in bringing NLP to AAC: A case to consider.
In Filip T. Loncke, John Clibbens, Helen H. Arvidson, and
Lyle L. Lloyd, editors, AAC: New Directions in Research and
Practice, pages 105?122. Whurr Publishers, London.
Kathleen F. McCoy. 1997. Simple NLP techiques for expand-
ing telegraphic sentences. In Proc. of workshop on NLP for
Communication Aids, Madrid, July. ACL/EACL.
George A. Miller. 1995. WORDNET: a lexical database for
English. Commun. ACM, 38(11):39?41.
Roger Power and Donia Scott. 1998. Multilingual authoring
using feedback texts. In Proc. of COLING-ACL 98, Mon-
treal, Canada.
Pascal Vaillant. 1997. A semantic-based communication sys-
tem for dysphasic subjects. In Proc. of the 6th conference
on AI in Medicine Europe (AIME?97), Grenoble, France,
March.
108
Integrating a Large-scale, Reusable Lexicon with a Natural 
Language Generator 
Hongyan 3 ing  
Department of Computer  Science 
Columbia University 
New York, NY 10027, USA 
hjing@cs.columbia.edu 
Yael Dahan Netzer 
Department of Computer  Science 
Ben-Gurion University 
Be'er-Sheva, 84105, Israel 
yaeln@cs.bgu.ac.il 
Michael Elhadad 
Department  of Computer  Science 
Ben-Gurion University 
Be'er-Sheva, 84105, Israel 
elhadad@cs.bgu.ac.i l  
Kathleen R. McKeown 
Department of Computer  Science 
Columbia University 
New York, NY 10027, USA 
kathy@cs.columbia.edu 
Abst rac t  
This paper presents the integration of a large- 
scale, reusable lexicon for generation with the 
FUF/SURGE unification-based syntactic realizer. 
The lexicon was combined from multiple xisting re- 
sources in a semi-automatic process. The integra- 
tion is a multi-step unification process. This inte- 
gration allows the reuse of lexical, syntactic, and 
semantic knowledge ncoded in the lexicon in the 
development of lexical chooser module in a genera- 
tion system. The lexicon also brings other benefits 
to a generation system: for example, the ability to 
generate many lexical and syntactic paraphrases and 
the ability to avoid non-grammatical output. 
1 In t roduct ion  
Natural language generation requires lexical, syn- 
tactic, and semantic knowledge in order to produce 
meaningful and fluent output. Such knowledge is 
often hand-coded anew when a different application 
is developed. We present in this paper the integra- 
tion of a large-scale, reusable lexicon with a natural 
language generator, FUF/SURGE (Elhadad, 1992; 
Robin, 1994); we show that by integrating the lexi- 
con with FUF/SURGE as a tactical component, we 
can reuse the knowledge ncoded in the lexicon and 
automate to some extent he development of the lex- 
ical realization component in a generation applica- 
tion. 
The integration of the lexicon with FUF/SURGE 
also brings other benefits to generation, including 
the possibility to accept a semantic input at the 
level of WordNet synsets, the production of lexical 
and syntactic paraphrases, the prevention of non- 
grammatical output, reuse across applications, and 
wide coverage. 
We present he process of integrating the lexicon 
with FUF/SUR(;E. including how to represenl the 
lexicon in FUF format, how to unify input with the 
lexicon incrementally to generate more sophisticated 
and informative representations, and how to design 
an appropriate semantic input format so that the 
integration of the lexicon and FUF/SURGE can be 
done easily. 
This paper is organized as follows. In Section 2, 
we explain why a reusable lexical chooser for gen- 
eration needs to be developed. In Section 3, we 
present he large-scale, reusable lexicon which we 
combined from multiple resources, and illustrate its 
benefits to generation by examples. In Section 4, we 
describe the process of integrating the lexicon with 
FUF/SURGE, which includes four unification steps, 
with each step adding additional lexical or syntac- 
tic information. Other applications and comparison 
with related work are presented inSection 5. Finally, 
we conclude by discussing future work. 
2 Bu i ld ing  a reusab le  lex ica l  chooser  
for generat ion  
While reusable components have been widely used in 
generation applications, the concept of a "reusable 
lexical chooser" for generation remains novel. 
There are two main reasons why such a lexical 
chooser has not been developed in the past: 
1. In the overall architecture of a generator, the 
lexical chooser is an internal component that 
depends on the semantic representation a d for- 
.:malism and onthe syntactic realizer used by the 
application. 
2. The lexical chooser links conceptual e ements to 
lexical items. Conceptual elements are by defi- 
nition domain and application dependent ( hey 
are the primitive concepts used in an applica- 
tion knowledge base). These primitives are not 
easily ported from application to application. 
209 
The emergence of standard architectures for gen- 
erators (RAGS, (Reiter, 1994))and the possibility 
to use a standard syntactic realizer answer the first 
issue. 
To address the second issue, one must realize that 
if the whole lexical chooser can not be made domain- 
independent, major parts can be made reusable. 
The main argument is that lexical knowledge is mod- 
ular. Therefore, while choice of words is constrained 
by domain-specific conceptual knowledge (what in- 
formation the sentences are to represent) on the one 
hand, it is also affected by several other dimensions: 
* inter-lexical constraints: collocations among 
words 
o pragmatic onstraints: connotations of words 
o stylistic constraints: familiarity of words 
* syntactic constraints: government patterns of 
words, e.g., thematic structure of verbs. 
We show in this paper how the separation of the 
syntactic and conceptual interfaces of lexical item 
definitions allows us to reuse a large amount of lex- 
ical knowledge across appli.cations. 
3 The  lex icon  and  i t s  benef i t s  to  
generat ion  
3.1  A large-scale,  reusab le  lexicon for 
generat ion  
Natural Language generation starts from semantic 
concepts and then finds words to realize such seman- 
tic concepts. Most existing lexical resources, how- 
ever, are indexed by words rather than by semantic 
concepts. Such resources, therefore, can not be used 
for generation directly. Moreover, generation eeds 
different ypes of knowledge, which typically are en- 
coded in different resources. However, the different 
representation formats used by these resources make 
it impossible to use them simultaneously in a single 
system. 
To overcome these limitations, we built a large- 
scale, reusable lexicon for generation by combining 
multiple existing resources. The resources that are 
combined include: 
o Tile WordNet Lexical Database (Miller et al, 
1990). WordNet is the largest lexical database 
to date, consisting of over 120,000 unique words 
(version 1.6). It also encodes many types of 
lexical relations between words, including syn- 
onytny, antonymy, and many more. 
o English Verb Classes and Alternations 
(EVCA) (Levin, 1993). It categorized 3.104 
verbs into classes based on their syntactic 
properties and studied verb alternations. An 
alternation is a variation in the realization of 
verb arguments. For example, the alternation 
"there-insertion" transforms A ship appeared 
~-on..the horizon_to There,appeared a ship..o~....the 
horizon. A total of 80 alternations for 3,104 
verbs were studied. 
The COMLEX syntax dictionary (Grishman et 
al., 1994). COMLEX contains syntactic infor- 
mation for over 38,000 English words. 
The Brown Corpus tagged with WordNet senses 
(Miller et al, 1993). We use this corpus for 
frequency measurement. . 
In combining these resources, we focused on verbs, 
since they play a more important role in deciding 
sentence structures. The combined lexicon includes 
rich lexical and syntactic knowledge for 5,676 verbs. 
It is indexed by WordNet synsets(which are at the 
semantic oncept level) as required by the generation 
task. The knowledge in the lexicon includes: 
Q A complete list of subcategorizations for each 
sense of a verb. 
o A large variety of alternations for each sense of 
a verb. 
o Frequency of lexical items and verb subcatego- 
rizations in the tagged Brown corpus 
Rich lexicat relations between words 
The sample entry for the verb "appear" is shown 
in Figure 1. It shows that the verb appear has eight 
senses (the sense distinctions come from WordNet). 
For each sense, the lexicon lists all the applicable 
subcategorization for that particular sense of the 
verb. The subcategorizations are represented using 
the same format as in COMLEX. For each sense, 
the lexicon also lists applicable alternations, which 
we encoded based on the information in EVCA. In 
addition, for each subcategorization a d alternation, 
the lexicon lists the semantic ategory constraints on 
verb arguments. In the figure, we omitted the fre- 
quency information derived from Brown Corpus and 
lexical relations (the lexical relations are encoded in 
WordNet). 
The construction of the lexicon is semi-automatic. 
First, COMLEX and EVCA were merged, produc- 
ing a list of syntactic subcategorizations and alter- 
nations for each verb. Distinctions in these syntac- 
tic restrictions according to each sense of a verb 
are achieved in the second stage, where WordNet 
is merged with the result of the first step. Finally, 
the corpus information is added, complementing the 
static resources with actual usage counts for each 
syntactic pattern. For a detailed description of the 
combination process, refer to (Jing and Mchieown, 
1998). 
210 
appear: 
sense  1 give an impress ion  
((PP-TO-INF-gS :PVAL ("to") :SO ((sb,  - ) ) )  
(TO-INF-RS :S0 ((sb, --))) 
(NP-PRED-RS :S0 ((sb,  --))) 
(ADJP-PRED-RS :SO ((sb,  - )  (sth, - - ) ) ) ) )  
sense 2 become v is ib le  
((PP-T0-INF-KS :PVAL ("to") 
:S0 ((sb, -) (sth, -))) 
(INTRANS TIIERE-V-SUB J 
. . . . . . . . .  . . _  
: ALT there-insertion 
:S0 ((sb, --) (sth, --)))) 
sense 8 have an outward express ion 
((NP-PRED-RS :SO ((sth, --))) 
(ADJP-PRED-RS :S0 ((sb, --) (sth, --)))) 
Figure I: Lexicon entry for the verb appear 
3.2 The  benefits of  the  lex icon  
There are a number of benefits that this combined 
lexicon can bring to language generation. 
First, the use of synsets as semantic tags can 
help map an application conceptual model to lexi- 
cal items. Whenever application concepts are repre- 
sented at the abstraction level of a WordNet synset, 
they can be directly accepted as input to the lexi- 
con. By this way, the lexicon can actually lead to 
the generation of many lexical paraphrases. For ex- 
ample, (look, seem, appear} is a WordNet synset; it 
includes a list of words that can convey the seman- 
tic concept ' 'g ive  an impression o f '  '. We can 
use synsets to find words that can lexicalize the se- 
mantic concepts in the semantic input. By choosing 
different words in a synset, we can therefore gen- 
erate lexical paraphrases. For instance, using the 
above synset, the system can generate the following 
paraphrases: 
"He seems happy. "
"He looks happy. "
"He appears happy.'" 
Secondly, the subcategorization information i  the 
lexicon prevents generating a non-grammatical out- 
put. As shown in Figure 1, the lexicon lists appli- 
cable subcategorizations for each sense of a verb. It 
will not allow the generation of sentences like 
"*He convinced me in his innocence" 
(wrong preposition) 
"*He convinced to go to the party" 
(missing object) 
"*Th.e bread cuts" 
(missing adverb (e.g., "'easily" )) 
"*The book consists three parts" 
( m issing t)reposit.ion) 
In addition, alternation information can help gen- 
erate .syntactic paraphrases. For instance, using 
the "simple reciprocal intransitive" alternation, the 
system can generate the following syntactic para- 
phrases: ? , 
"Brenda agreed with Molly." 
"Brenda and Molly agreed?" 
"Brenda and Molly agreed with each other." 
Finally, the corpus frequency information can help 
............... _the.lexicat.. -~ice.proeesa~.,When:multiple .words can 
be used to realize a semantic oncept, the system 
can use corpus frequency information in addition 
to other constraints to choose the most appropriate 
word. 
The knowledge ncoded in the lexicon is general, 
thus it can be used in different applications. The 
lexicon has wide coverage: the final lexicon consists 
of 5,676 verbs in total, over 14,100 senses (on average 
2.5 senses/verb), and over 11,000 semantic oncepts 
(synsets). It uses 147 patterns to represent the sub- 
categorizations and includes 80 alternations. 
To exploit the lexicon's many benefits, its format 
must be made compatible with the architecture of a 
generator. We have integrated the lexicon with the 
FUF/SURGE syntactic realizer to form a combined 
lexico-grammar. 
4 Integration Process 
In this section, we first explain how lexical choosers 
are interfaced with FUF/SURGE. We then describe 
step by step how the lexicon is integrated with 
FUF/SURGE and show that this integration pro- 
cess helps to automate the development of a lexical 
realization component. 
4.1 FUF /SURGE and the lexical chooser 
FUF (Elhadad, 1992) uses a functional unification 
formalism for generation. It unifies the input that a 
user provides with a grammar to generate sentences. 
SURGE (Elhadad and Robin, 1996) is a comprehen- 
sive English Grammar written in FUF. Tile role of 
a lexical realization component is to map a semantic 
representation drawn from the application domain 
to an input format acceptable by SURGE, adding 
necessary lexical and syntactic information during 
this process. 
Figure 2 shows a sample semantic input (a), the 
lexicalization module that is used to map this se- 
mantic input to SURGE input (b), and 'thefinal 
SURGE input (c) - -  taken from a real application 
system(Passoneau et al, 1996). The functions of the 
lexicalization module include selecting words that 
can be used to realize the semalltic oncepts in the 
input, adding syntactic features, and mapping tile 
arguments in tile semantic input to the thematic 
roles in SURGE. 
211 
Sentence :  / t  has 24 activities, including 20 tasks and four decisions. 
concept 
args 
total-node-count 
theme concept 
ref 
concept 
rheme args 
pronounPr?cess-fl?wgraph \] 
elaboration 
concept 
theme args 
expansion concept 
args 
cardinality \] 
\[ theme \[1\] \] / 
t value \[21 l -I. s.ubset-node-countJ 
concept flownode \] 
\[1\] = ref full 
concept 
proc 
partic 
cat  
proc 
partic 
\[2\] = 
concept cardinal \] 
cardinal 24 
ref full 
(a) The semantic input (i.e., input of lexicalization module) 
#(under  total-node-count) 
type possessive \] 
possessor cat pronoun / 
i 
cat common 
cardinal \[ value 
definite no 
head 
possessed 
qualifier 
\[,l\] 
lex "activity" \] 
cat clause 
mood present-participle 
type locative 
proc lex "include" 
partic location \[ cat 
k 
(b) Tile lexicalization module 
\] 
clause 
type possessive \] 
possessor cat pronoun / 
I 
cat  COn l l l l on  
cardinal \[ value 24 \] 
definite no 
head lex "activhy" \] 
possessed cat clause 
mood present-participle 
type locative \] 
qualifier proc lex "include" 
(c) Tile SURGE input (ie., output of lexicalization module) 
1 
I 
I 
I 
I 
I 
Figure 2: A samph~ lexicalization component 
212 
The development of the lexicalizer component was 
done by hand in the past. Furthermore, for. each 
new application, a new lexicatizer component had 
to be written despite the fact that some lexical and 
syntactic information is repeatedly used in different 
applications. The integration process we describe, 
however, partially automates this process. 
4.2 The  in tegrat ion  s teps  
The integration of the lexicon with FUF/SURGE 
is done through incremental unification, using four 
unification steps as shown in Figure 3. Each  step 
adds information to the semantic input, and at the 
end of the four unification steps, the semantic input 
has been mapped to the SURGE input format. 
(1) The semantic input 
Different generation systems usually use different 
representation formats for semantic input. Some 
systems use case roles ; some systems use flat 
attribute-value r presentation (Kukich et al, 1994). 
For the integrated lexicon and FUF/SURGE pack- 
age to be easily pluggable in applications, we need to 
define a standard semantic input format. It should 
be designed in such a way that applications can eas- 
ily adapt their particular semantic inputs to this 
standard format. It should also be easily mapped 
to the SURGE input format. 
In this paper, we only consider the issue of seman- 
tic input format for the expression of the predicate- 
argument relation. Two questions need to be an- 
swered in the design of the standard semantic input 
format: one, how to represent semantic oncepts; 
and two, how to represent he predicate-argument 
relation. 
We use WordNet synsets to represent semantic 
concepts. The input can refer to synsets in several 
ways: either using a globally unique synset num- 
ber I or by specifying a word and its sense number 
in WordNet. 
The representation of verb arguments is a more 
complicated issue. Case roles are frequently used in 
generation systems to represent verb arguments in 
semantic inputs. For example, (Dorr et al, 1998) 
used 20 case roles in their lexical conceptual struc- 
ture corresponding to underlying positions in a com- 
positional lexical structure. (Langkilde and Knight. 
1998) use a list of case roles in their interlingua rep- 
resentations. 
We decided to use numbered arguments (similar to 
the DSyntR in MTT (Mel'cuk and Perstov, 1987)) 
instead of case roles. The difference between the two 
1Since there are a huge number of synsets in WordNet, we 
will provide a searchable database of synsets o that users can 
look up a synset and its index number easily. For a part icular 
appl ication, users can adapt  the synsets to their specific do- 
main, such as removing non-relevant synsets, merging synsets. 
and relabel ing the synsets for convenience, as discussed in 
(,ling, 1998). 
is not critical but the numbered argument approach 
? avoids the need? to commit: the: lexicon to a specific 
ontology and seems to be easier to learn 2. 
Figure 4 shows a sample semantic input. For easy 
understanding, we refer to  the semantic concepts 
using their definitions rather than numerical index 
numbers. There are two arguments in the input. 
The intended output sentence for this semantic in- 
put is "A boat appeared on the horizon" or its para- 
phrases. 
(2) Lexical unification 
In this step, we map the semantic oncepts in the " 
semantic input to concrete words. To do this, we use 
the synsets in WordNet. All the words in the same 
synset can be used to convey the same semantic on- 
cept. For the above example, the semantic oncepts 
"become visible" and "a small vessel for travel on 
water" can be realized by the the verb appear and 
the noun boat respectively. This is the step that can 
produce lexical paraphrases. Note that when the 
system chooses a word, it also determines the par- 
ticular sense number of the word, since a word as 
it belongs to a synset has a unique sense number in 
WordNet. 
We represented all the synsets in Wordnet in FUF 
format. Each synset includes its numerical index 
number and the list of word senses included in the 
synsets. This lexical unification, works for both 
nouns and verbs. 
(3) Structural unification 
After the system has chosen a verb (actually a 
particular sense of a verb), it uses that information 
as an index to unify with the subcategorization a d 
alternations the particular verb sense has. This step 
adds additional syntactic information to the origi- 
nal input and has the capacity to produce syntactic 
paraphrases using alternation information. 
(4) Constraints on the number of arguments 
Next, we use the constraints that a subcategoriza- 
tion has on the number of arguments it requires to 
restrict unification with subcategorization patterns. 
\~k~ use 147 possible patterns. For example, the in- 
put in Figure 4 has two arguments. Although IN- 
TRANS (meaning intransitive) is listed as a possi- 
ble subcategorization pattern for "appear" (see sense 
2 in Figure 1), the input will fail to unify with it 
since INTRANS requires a single argument only. 
This prevents the generation of non-grammatic'A 
sentences. This step adds a feature which specifies 
the transitivity of the verb to FUF/SURGE input, 
selecting one from the lexicon when there is more 
than one possibility for the given verb. 
2The difference between numbered arguments and labeled 
roles is s imi lar  to that between amed semantic primit ives and 
synsets in \.VordNet. Verb classes share the same definition 
of which argument is denoted by l, 2 etc. if they share some 
syntact ic properties as far as argument aking properties are  
concerned. 
213 
Semantic input Synsets verbs lexicon si~ucts Input for SURGE 
Figure 3: The integration process 
\[rel-- i--ept --evisible J 1\] 
1 \[ concept  "a  smal l  vesse l  fo r  t rave l  on  water ' '  \] 
args 2 \[ concept ' ' the  l i ne  at  which the sky and Earth appear to  meet' '  \] 
Figure 4: The semantic input using numbered arguments 
(5) Mapping structures to SURGE input 
In the last step, the subcategorization a d alter- 
nations are mapped to SURGE input format. The 
mapping from subcategorizations to SURGE input 
was manually encoded in the lexicon for each one 
of the 147 patterns. This mapping information can 
be reused for all applications, which is more effi- 
cient than composing SURGE input in the lexical- 
ization component of each different application. Fig- 
ure 5 shows how the subcategorization NP-WITH- 
NP (e.g., The clown amused the children with his 
antics) is mapped to the SURGE input format. This 
mapping mainly involves matching the numbered ar- 
guments in the semantic input to appropriate l xical 
roles and syntactic ategories so that FIJF/SURGE 
can generate them in the correct order. 
The final SURGE input for the sentence ",4 boat 
appeared on the horizon" is shown in Figure 6. Us- 
ing the "THERE-INSERTION" alternation that the 
verb "appear" (sense 2) authorizes, the system can 
also generate the syntactic paraphrase "There ap- 
peared a boat on the hor izon".  The SURGE input 
the system generates for "There appeared a boat on 
the horizon" is very different .from that for "A boat 
appeared on the horizon".  
It is possible that for a given application some 
generated paraphrases are not appropriate. In this 
case, users can edit the synsets and the alternations 
to filter out tile paraphrases tile) do not want. 
Tile four unification steps are completely auto- 
matic. Tile system can send feedback upon failure 
struct 
relation 
args 
proc 
lex-roles 
np-with-np 
1 \[21<...> 
2 \[al<...> 
3 \[41<...> 
type lexical 
lex Ill 
t 
1 
2 
subcat 2 
3 
\ [1  \[all 2 \[3\] 
3 \[41 
cat np \] 
121 
\[rat .p \] 
\[al 
cat ip  
prep lex 
np \[41 
"with" \] 1 
Figure 5: Mapping subcategorization "NP-\VITH- 
NP" to SURGE input 
of unification. 
5 Re la ted  Work  
The lexicon, after it is integrated with 
FUF/SURGE, can also be used for other tasks in 
language generation. For example, revision (Robin, 
1994) is a technique for building semantic inputs 
incrementally. The revision process decides whether 
it is appropriate to attach a new constituent to the 
current semantic input, for example, by adding an 
214 
relation 
args 
struct 
argl 
cat 
lexical-roles 
concept 
word 
1 concept 
word 
concept 
2 word 
ppb 
2 ~ given 
c lause c 
d 
c 'become ~is ib le '  ' \] 
\] "appear"a 
'a small  vessel  for travel on water'' \] 
J "boa~"a 
'Cthe l ine  at  which the sky and Earth appear to meet \] 
"hor,izon ''a \] 
"Enriched in first step 
bEnriched in second step 
CEnriched in third step 
dEnriched in fourth step 
Figure 6: SURGE input for "A boat appeared on the horizon" 
object or an adverb. Such decisions are constrained 
by syntactic properties of verbs. The integrated 
lexicon is useful to verify these properties. 
Nitrogen (Langkilde and Knight, 1998), a natural 
language generation system developed at ISI, also 
includes a large-scale l xicon to support the genera- 
tion process. Given that Nitrogen and FUF/SURGE 
use very different methods for generation, the way 
that we integrate the lexicon with the generation sys- 
tem is also very different. Nitrogen combines ym- 
bolic rules with statistics learned from text corpora, 
while FUF/SURGE is based on Functional Unifica- 
tion Grammar. Other related work includes (Stede, 
1998), which suggests a lexicon structure for multi- 
lingual generation in a knowledge-based generation 
system. The main idea is to handle multilingual gen- 
eration in the same way as paraphrasing of the same 
language. Stede's work concerns mostly the lexical 
semantics of the transitivity alternations. 
6 Conc lus ion  
We have presented in this paper the integration of 
a large-scale, reusable lexicon for generation with 
FUF/SURGE, a unification-based natural language 
generator. This integration makes it possible to 
reuse major parts of a lexical chooser, which is tile 
component in a generation system that is responsi- 
ble for mapping semantic inputs to surface genera- 
tor inputs. We show that although the whole lexical " 
chooser can not be made domain-independent, it is 
possible to reuse a large amount of lexical, syntactic, 
and semantic knowledge across applications. 
In addition, tile lexicon other benefits to a genera- 
tion system, inchiding the abilities to generate nlany 
lexical paraphrases automatically, generate syntac -  
tic paraphrases, av(fid n(m-grammatical output, and 
choose the most frequently used word when there is 
more than one candidate words. Since the lexical, 
syntactic, and semantic knowledge ncoded in the  
lexicon is general and the lexicon has a wide cover- 
age, it can be reused for different applications. 
In the future, we plan to validate the paraphrases 
the lexicon can generate by asking human subjects to 
read the generated paraphrases and judge whether 
they are acceptable. We would like to investigate 
ways that can systematically filter out paraphrases 
that are considered unacceptable. We are also inter- 
ested in exploring the usage of this system in multi- 
lingual generation. 
Re ferences  
B. J. Doff, N. Habash, 
A thematic hierarchy 
from lexical-conceptual. 
and D. Traum. 1998. 
for efficient generation 
Technical Report CS- 
TR-3934, Institute for Advanced Computer Stud- 
ies, Department of Computer Science, University 
of Maryland, October. 
M. Elhadad and J. Robin. 1996. An overview of 
SURGE: a re-usable comprehensive syntactic re- 
alization component. In INLG'96, Brighton, UK. 
(demonstration session). 
M. Elhadad. 1992. Using Argumentation to Control 
Lezical Choice: A Functional Unification-Based 
Approach. Ph.D. thesis, Department of Computer 
Science, Columbia University. 
R. Grishman, C. Macleod, and A. Meyers. 1994. 
COMLEX syntax: Building a computational 
lexicon. In Proceedings of COLING'94, Kyoto, 
,Japan. 
H.. l ing and K. McKeown. 1998. Combining mul- 
tiple, large-scale resources in a reusable lexicon 
for natural language generation. In Proceedings 
215 
of the 36th Annual Meeting of the Association for 
Computational Linguistics and the .17th Interna- 
tional Conference on Computational Linguistics, 
volume 1, pages 607-613, Universit(~ de MontrEal, 
Quebec, Canada, August. 
H. Jing. 1998. Applying wordnet o natural an- 
guage generation. In Proceedings of COLING- 
ACL'98 workshop on the Usage of WordNet in 
Natural Language Processing Systems, University 
of Montreal, Montreal, Canada, August. 
K. Kukich, K. McKeown, J. Shaw, J. Robin, N. Mor- 
gan, and J. Phillips. "1994. User-needs analysis 
and design methodology for an automated oc- 
ument generator. In A. Zampolli, N. Calzolari, 
and M. Palmer, editors, Current Issues in Com- 
putational Linguistics: In Honour of Don Walker. 
Kluwer Academic Press, Boston. 
I. Langkilde and K. Knight. 1998. The practical 
value of n-grams in generation. In INLG'98, pages 
248-255, Niagara-on-the-Lake, Canada, August. 
B. Levin. 1993. English Verb Classes and Alterna- 
tions: A Preliminary Investigation. University of 
Chicago Press, Chicago, Illinois. 
I.A. Mel'cuk and N.V. Perstov. 1987. Surface- 
syntax of English, a formal model in the 
Meaning Text Theory. Benjamins, Amster- 
dam/Philadelphia. 
G. Miller, R. Beckwith C. Fellbaum, and D. Gross K. 
Miller. 1990. Introduction to WordNet: An on- 
line lexical database. International Journal of 
Lexicography (special issue), 3 (4) :235-312. 
G.A. Miller, C. Leacock, R. Tengi, and R.T. Bunker. 
1993. A semantic oncordance. Cognitive Science 
Laboratory, Princeton University. 
R. Passoneau, K. Kukich, J. Robin, V. Hatzivas- 
siloglou, L. Lefkowitz, and H. Jing. 1996. Gen- 
erating summaries of workflow diagrams. In Pro- 
ceedings of the International Conference on Nat- 
ural Language Processing and Industrial Appli- 
cations (NLP-IA'96), Moncton, New Brunswick, 
Canada. 
E. Reiter. 1994. Has a consensus nl generation ar- 
chitecture appeared, and is it psyeholinguistically 
plausible? In Proceedings of the Seventh Interna- 
tional Workshop on Natural Language Generation 
(INLGW-1994), pages 163-170, Kennebunkport, 
Maine, USA. available from the cmp-lg archive as 
paper cmp-lg/9411032. 
J. Robin. 1994. Revision-Based Generation of Nat- 
.ural Language Summaries Providing Historical 
Background: Corpus-Based Analysis, Design, Im- 
plementation, and Evaluation. Ph.D. thesis, De- 
partment of Computer Science, Cohnnbia Univer- 
sity. Also Technical Report CU-CS-034-94. 
M. Stede. 1998. A generative l)ersl}ective on vert} al- 
ternations. Computational Lin.quistics. 24(3):4{}1- 
_430-,September" 
216 
Interactive Authoring of Logical Forms for Multilingual Generation?
Ofer Biller, Michael Elhadad, Yael Netzer
Department of Computer Science
Ben Gurion University
Be?er-Sheva, 84105, Israel
{billero, elhadad, yaeln}@cs.bgu.ac.il
Abstract
We present an authoring system for logical forms
encoded as conceptual graphs (CG). The system
belongs to the family of WYSIWYM (What You
See Is What You Mean) text generation systems:
logical forms are entered interactively and the cor-
responding linguistic realization of the expressions
is generated in several languages. The system
maintains a model of the discourse context corre-
sponding to the authored documents.
The system helps users author documents formu-
lated in the CG format. In a first stage, a domain-
specific ontology is acquired by learning from ex-
ample texts in the domain. The ontology acquisi-
tion module builds a typed hierarchy of concepts
and relations derived from the WordNet and Verb-
net.
The user can then edit a specific document, by en-
tering utterances in sequence, and maintaining a
representation of the context. While the user en-
ters data, the system performs the standard steps
of text generation on the basis of the authored log-
ical forms: reference planning, aggregation, lexi-
cal choice and syntactic realization ? in several lan-
guages (we have implemented English and Hebrew
- and are exploring an implementation using the
Bliss graphical language). The feedback in natural
language is produced in real-time for every single
modification performed by the author.
We perform a cost-benefit analysis of the applica-
tion of NLG techniques in the context of authoring
cooking recipes in English and Hebrew. By com-
bining existing large-scale knowledge resources
(WordNet, Verbnet, the SURGE and HUGG real-
ization grammars) and techniques from modern in-
tegrated software development environment (such
as the Eclipse IDE), we obtain an efficient tool for
the generation of logical forms, in domains where
content is not available in the form of databases.
?Research supported by the Israel Ministry of Science - Knowl-
edge Center for Hebrew Computational Linguistics and by the
Frankel Fund
1 Introduction
Natural language generation techniques can be applied to
practical systems when the ?input? data to be rendered in text
can be obtained in a cost-effective manner, and when the ?out-
put? requires such variability (multiple styles or languages,
or customization to specific users or classes) that producing
documents manually becomes prohibitively expensive.
The input data can be either derived from an existing appli-
cation database or it can be authored specifically to produce
documents. Applications where the data is available in a data-
base include report generators (e.g., ANA [Kukich, 1983],
PlanDoc [Shaw et al, 1994], Multimeteo [Coch, 1998], FOG
[Goldberg et al, 1994]). In other cases, researchers identi-
fied application domains where some of the data is available,
but not in sufficient detail to produce full documents. The
?WYSIWYM? approach was proposed ([Power and Scott,
1998], [Paris and Vander Linden, 1996]) as a system design
methodology where users author and manipulate an underly-
ing logical form through a user interface that provides feed-
back in natural language text.
The effort invested in authoring logical forms ? either from
scratch or from a partial application ontology ? is justified
when the logical form can be reused. This is the case when
documents must be generated in several languages. The field
of multilingual generation (MLG) has addressed this need
([Bateman, 1997], [Stede, 1996]). When documents must be
produced in several versions, adapted to various contexts or
users, the flexibility resulting from generation from logical
forms is also valuable. Another motivation for authoring logi-
cal forms (as opposed to textual documents) is that the logical
form can be used for other applicative requirements: search,
summarization of multiple documents, inference. This con-
cern underlies the research programme of the Semantic Web,
which promotes the encoding in standardized forms of on-
tological knowledge such as KIF [Berners-Lee et al, 2001],
[Genesereth and Fikes, 1992].
In this paper, we analyze an application of the WYSIWYM
method to author logical forms encoded in Sowa?s Concep-
tual Graphs (CG) format [Sowa, 1987]. In a first stage, users
submit sample texts in a domain to the system. The system
learns from the samples a hierarchy of concepts and relations.
Given this ontology, the author then enters expressions using
a simple variant of the CG Interchange Format (CGIF) which
we have designed to speed editing operations. The system
provides realtime feedback to the author in English and He-
brew.
We evaluate the specific features of such a system which
make it cost-effective as a tool to author logical forms. We
select the CG formalism as one of the representatives of
the family of knowledge encoding formalisms, which bene-
fits from well-established inference and quantification mech-
anisms and standard syntax encodings in graphical and linear
formats.
The editing system we developed can be seen as CG ed-
itor motivated and expanded by natural language generation
(NLG) techniques. The mixing of a practical ontology edit-
ing perspective with NLG techniques yielded the following
benefits:
? Generation tasks such as aggregation and reference plan-
ning are easily expressed as operations upon CGs.
? The construction and maintenance of context according
to models of text planning [Reiter and Dale, 1992], allow
the author to break a complex CG into a manageable
collection of small utterances. Each utterance links to a
global context in a natural manner.
? We designed a compact form to edit a textual encoding
of CGs taking into account defaults, knowledge of types
of concepts, sets and individual instances and context.
This format syntactically looks like a simple object-
oriented programming language with objects, methods
and attributes. We use an editing environment similar to
a modern programming language development environ-
ment ? with a browser of types and instances, intelligent
typing completion based on type analysis, and context-
specific tooltip assistance.
? The simultaneous generation of text in two languages
(Hebrew and English) is important to distinguish be-
tween un-analyzed terms in the ontology and their lin-
guistic counterpart.
We evaluate the overall effectiveness of the authoring en-
vironment in the specific domain of cooking recipes (inspired
by [Dale, 1990]). We perform various usability studies to
evaluate the overall cost of authoring cooking recipes as log-
ical forms and evaluate the relative contribution of each com-
ponent of the system: ontology, natural language feedback,
user interface. We conclude that the combination of these
three factors results in an effective environment for authoring
logical forms.
In the paper, we first review the starting points upon which
this study builds in generation and knowledge editing. We
then present the tool we have implemented ? its architecture,
the knowledge acquisition module and the editor, we finally
present the evaluation experiments and their results, and con-
clude with their analysis.
2 Related Work
Our work starts from several related research traditions: mul-
tilingual generation systems; WYSIWYM systems; knowl-
edge and ontology editors. We review these in this section in
turn.
2.1 Multilingual Generation
Multilingual texts generation (MLG) is a well motivated
method for the automatic production of technical documents
in multiple languages. The benefits of MLG over translation
from single language source were documented in the past and
include the high cost of human translation and the inaccu-
racy of automatic machine translation [Stede, 1996], [Coch,
1998], [Bateman, 1997]. In an MLG system, users enter data
in an interlingua, from which the target languages are gener-
ated.
MLG Systems aim to be as domain independent as pos-
sible (since development is expensive) but usually refer to a
narrow domain, since the design of the interlingua refers to
domain information. MLG systems share a common archi-
tecture consisting of the following modules:
? A language-independent underlying knowledge repre-
sentation: knowledge represented as AI plans [Ro?sner
and Stede, 1994] [Delin et al, 1994], [Paris and Van-
der Linden, 1996], knowledge bases (or ontologies)
such as LOOM, the Penman Upper-model and other
(domain-specific) concepts and instances [Ro?sner and
Stede, 1994].
? Micro-structure planning (rhetorical structure) - lan-
guage independent - this is usually done by the human
writers using the MLG application GUI.
? Sentence planning - different languages can express the
same content in various rhetorical structures, and plan-
ning must take it into consideration: either by avoiding
the tailoring of structure to a specific language [Ro?sner
and Stede, 1994] or by taking advantage of knowledge
on different realizations of rhetorical structures in differ-
ent languages at the underlying representation [Delin et
al., 1994].
? Lexical and syntactic realization resources (e.g., Eng-
lish PENMAN/German NIGEL in [Ro?sner and Stede,
1994])
As an MLG system, our system also includes similar mod-
ules. We have chosen to use Conceptual Graphs as an inter-
lingua for encoding document data [Sowa, 1987]. We use ex-
isting generation resources for English ? SURGE [Elhadad,
1992] for syntactic realization and the lexical chooser de-
scribed in [Jing et al, 2000] and the HUGG grammar for
syntactic realization in Hebrew [Netzer, 1997]. For micro-
planning, we have implemented the algorithm for reference
planning described in [Reiter and Dale, 1992] and the ag-
gregation algorithm described in [Shaw, 1995]. The NLG
components rely on the C-FUF implementation of the FUF
language [Kharitonov, 1999] [Elhadad, 1991] ? which is fast
enough to be used interactively in realtime for every single
editing modification of the semantic input.
2.2 WYSIWYM
In an influential series of papers [Power and Scott, 1998],
WYSIWYM (What You See Is What You Mean) was pro-
posed as a method for the authoring of semantic information
through direct manipulation of structures rendered in natural
language text. A WYSIWYM editor enables the user to edit
information at the semantic level. The semantic level is a di-
rect controlled feature, and all lower levels which are derived
from it, are considered as presentational features. While edit-
ing content, the user gets a feedback text and a graphical rep-
resentation of the semantic network. These representations
can be interactively edited, as the visible data is linked back
to the underlying knowledge representation.
Using this method, a domain expert produces data by edit-
ing the data itself in a formal way, using a tool that requires
only knowledge of the writer?s natural language. Knowledge
editing requires less training, and the natural language feed-
back strengthens the confidence of users in the validity of the
documents they prepare.
The system we have developed belongs to the WYSIWYM
family. The key aspects of the WYSIWYM method we in-
vestigate are the editing of the semantic information. Text
is generated as a feedback for every single editing operation.
Specifically, we evaluate how ontological information helps
speed up semantic data editing.
2.3 Controlled Languages
A way to ensure that natural language text is unambiguous
and ?easy to process? is to constrain its linguistic form. Re-
searchers have designed ?controlled languages? to ensure that
words in a limited vocabulary and simple syntactic struc-
tures are used (see for example [Pulman, 1996]). This notion
is related to that of sublanguage [Kittredge and Lehrberger,
1982], which has been used to analyze and generate text in
specific domains such as weather reports.
With advances in robust methods for text analysis, it is be-
coming possible to parse text with high accuracy and recover
partial semantic information. For example, the DIRT system
[Lin and Pantel, 2001] recovers thematic structures from free
text in specific domains. Combined with lexical resources
(WordNet [Miller, 1995] and Verbnet [Kipper et al, 2000]),
it is now possible to confirm the thesis that controlled lan-
guages are easy to process automatically.
Complete semantic interpretation of text remains however
too difficult for current systems. In our system, we rely on
automatic interpretation of text samples in a specific sublan-
guage to assist in the acquisition of a domain-specific ontol-
ogy, as described below.
2.4 Graphical Editors for Logical Forms
Since many semantic encodings are described as graphs,
knowledge editing tools have traditionally been proposed as
graphical editors ? where concepts are represented as nodes
and relations as edges. Such a ?generic graphical editor? is
presented for example in [Paley et al, 1997].
Conceptual graphs have also been traditionally represented
graphically, and there is a standard graphical encoding for
CGs. Graphical editors for CGs are available (e.g., [Delu-
gach, 2001]).
While graphical editors are attractive, they suffer from
known problems of visual languages: they do not scale well
(large networks are particularly difficult to edit and under-
stand). Editing graphical representations is often slower than
editing textual representations. Finally, graphical representa-
tions convey too much information, as non-meaningful data
may be inferred from graphical features such as layout of
font, which is not constrained by the underlying visual lan-
guage.
2.5 Generation from CG
CGs have been used as an input to text generation in a variety
of systems in the past [Cote and Moulin, 1990], [Bontcheva,
1995] and others.
In our work, we do not view the CG level as a direct in-
put to a generation system. Instead, we view the CG level
as an ontological representation, lacking communicative in-
tention levels, and not linked directly to linguistic considera-
tions. The CG level is justified by its inferencing and query
retrieval capabilities, while taking into account sets, quantifi-
cation and nested contexts.
Processing is required to link the CG representation level
(see Fig. 1) to linguistically motivated rhetorical structures,
sentence planning and lexical choice. In our work, CGs are
formally converted to an input to a generation system by a
text planner and a lexical chooser, as described below. Ex-
isting generation components for lexical choice and syntac-
tic realization based on functional unification are used on the
output of the text planner.
Figure 1: Conceptual Graph in a linear representation.
3 Method and Architecture
We now present the system we have implemented, which we
have called SAUT (Semantic AUthoring Tool). Our objective
is to perform usability studies to evaluate:
? How ontological knowledge in the form of concept and
relation hierarchies is useful for semantic authoring;
? How natural language feedback improves the authoring
? and how feedback in two languages modifies the au-
thoring process;
? How user interface functionality improves the speed and
accuracy of the authoring.
The architecture of the system is depicted in Fig. 2.
The two key components of the system are the knowledge
acquisition system and the editing component. The knowl-
edge acquisition system is used to derive an ontology from
sample texts in a specific domain. In the editing component,
users enter logical expressions on the basis of the ontology.
3.1 Knowledge Acquisition
For the acquisition of the concepts/relations database, we use
two main sources: Verbnet [Kipper et al, 2000] and WordNet
[Miller, 1995].
We use the information for bootstrapping concept and rela-
tion hierarchies. Given sample texts in the target domain, we
Figure 2: Architecture of the SAUT system
perform shallow syntactic analysis and extract nouns, verbs
and adjectives from the text. Dependency structures for verbs
and nouns are also extracted. We currently perform manually
anaphora resolution and word sense disambiguation, since
automatic methods do not produce accurate enough results.
Given the set of nouns and adjectives, we induce the hyper-
nym hierarchy from WordNet, resulting in a tree of concepts
? one for each synset appearing in the list of words in the
sample texts.1
In addition to the concept hierarchy, we derive relations
among the concepts and predicates by using the Verbnet lexi-
cal database [Kipper et al, 2000]. Verbnet supplies informa-
tion on the conceptual level, in the form of selectional restric-
tions for the thematic roles.
These relations allow us to connect the concepts and rela-
tions in the derived ontology to nouns, verbs and adjectives.
The selectional restrictions in Verbnet refer to the WordNet
conceptual hierarchy. In Verbnet, verbs are classified fol-
lowing Levin?s classes [Levin, 1993] and thus its represen-
tation is easily adjustable with our verb lexicon [Jing et al,
2000], which combined information on argument structure of
verbs from Levin, Comlex [Macleod and Grishman, 1995]
and WordNet. The rich information on argument structure
and selectional restrictions can be automatically adopted to
the domain concepts database. Thus, by connecting a con-
cept to a verb, given all the concepts that stand in relation to
it in a specific CG (the verb?s arguments and circumstantials)
? our lexical chooser finds the suitable structure (alternation)
to map the CG to a syntactic structure.
The outcome of this process is useful in the lexical and syn-
tactic module of the system due to the flexibility it offers to
the lexical chooser (a general word can be used instead of a
1Although hypernym relations in WordNet define a forest of
trees, we connect all trees with a general node.
specific word i.e. vehicles instead of cars, and for the gener-
ality of selectional restrictions on verb/adjective arguments.
Since there are no Hebrew parallels to WordNet/verbnet,
we use a ?naive? scheme of translating the English LC to He-
brew, with manual corrections of specific structures when er-
rors are found.
Once the knowledge is acquired, we automatically updated
a lexical chooser adopted to the domain. The lexical chooser
maps the ontological concepts and relations to nouns, verbs
and adjectives in the domain.
3.2 The SAUT Editor
To describe the SAUT editor, we detail the process of author-
ing a document using the tool. When the authoring tool is
initiated, the next windows are presented (see Fig. 3):
? Input window
? Global context viewer
? Local context viewer
? CG feedback viewer
? Feedback text viewer
? Generated document viewer.
The user operates in the input window. This window in-
cludes three panels:
? Defaults: rules that are enforced by default on the rest of
the document. The defaults can be changed while edit-
ing. Defaults specify attribute values which are auto-
matically copied to the authored CGs according to their
type.
? Participants: a list of objects to which the document
refers. Each participant is described by an instance (or a
generic) CG, and is given an alias. The system provides
Figure 3: Snapshot of editing state in the SAUT system
an automatic identifier for participants, but these can be
changed by the user to a meaningful identifier.
? Utterances: editing information proposition by proposi-
tion.
The system provides suggestions to complete expressions
according to the context in the form of popup windows. In
these suggestion windows, the user can either scroll or choose
with the mouse or by entering the first letters of the desired
word, when the right word is marked by the system, the user
can continue, and the word will be automatically completed
by the system. For example, when creating a new participant,
the editor presents a selection window with all concepts in
the ontology that can be instantiated. If the user chooses the
concept type ?Dog? the system creates a new object of type
dog, with the given identifier. The user can further enrich this
object with different properties. This is performed using the
?.? notation to modify a concept with an attribute. While the
user enters the instance specification and its initial properties,
a feedback text and a conceptual graph in linear form are gen-
erated simultaneously. When the user moves to the next line,
the new object is updated on the global context view. Each
object is placed in a folder corresponding to its concept type,
and will include its instance name and its description in CG
linear form.
In the Utterances panel, the author enters propositions in-
volving the objects he declared in the participants section. To
create an utterance, the user first specifies the object which is
the topic of the utterance. The user can choose one of the par-
ticipants declared earlier from an identifiers list, or by choos-
ing a concept type from a list. Choosing a concept type will
result in creating a new instance of this concept type. Every
instance created in the system will be viewed in the context
viewer. After choosing an initial object, the user can add ex-
pressions in order to add information concerning this object.
After entering the initial object in an utterance, the user can
press the dot key which indicates that he wants to enrich this
object with information. The system will show the user list
of expressions that can add information on this object. In CG
terms, the system will fill the list with items which fall in one
of the following three categories:
? Relations that can be created by the system and their se-
lectional restrictions are such that they allow the modi-
fied object as a source for the relation.
? Properties that can be added to the concept object such
as name and quantity.
? Concept types that expect relations, the first of whom
can connect to the new concept. For example the con-
cept type ?Eat? expects a relation ?Agent? and a relation
?Patient.? The selectional restriction on the destination
of ?Agent? will be for example ?Animate?. Therefore
the concept ?Eat? will appear on the list of an object of
type ?Dog?.
The author can modify and add information to the active
object by pressing the dot key. An object which itself mod-
ifies an object previously entered, can be modified with new
relations, properties and concepts in the same manner. The
global context is updated whenever a new instance is created
in the utterances. When the author has finished composing
the utterance, the system will update the local context and
will add this information to the generated natural language
document.
The comma operator (?,?) is used to define sets in exten-
sion. For example, in Fig.3, the set ?salt and pepper? is
created by entering the expression #sa,#pe. The set itself be-
comes an object in the context and is assigned its own identi-
fier.
The dot notation combined with named variables allows
for easy and intuitive editing of the CG data. In addition,
the organization of the document as defaults, participants and
context (local and global) ? provides an intuitive manner to
organize documents.
Propositions, after they are entered as utterances, can also
be named, and therefore can become arguments for further
propositions. This provides a natural way to cluster large con-
ceptual graphs into smaller chunks.
The text generation component proceeds from this infor-
mation, according to the following steps:
? Pronouns are generated when possible using the local
and global context information.
? Referring expression are planned using the competing
expressions from the context information, excluding and
including information and features of the object in the
generated text, so the object identity can be resolved by
the reader, but without adding unnecessary information.
? Aggregation of utterances which share certain features
using the aggregation algorithm described in [Shaw,
1995].
Consider the example cooking recipe in Fig.3. The author
uses the participants section in order to introduce the ingre-
dients needed for this recipe. One of the ingredients is ?six
large eggs?. The author first chooses an identifier name for
the eggs, for example ?eg?. From the initial list of concepts
types proposed by the system, we choose the concept type
?egg?. Pressing the dot key will indicate we want to pro-
vide the system with further information about the newly cre-
ated object. We choose ?quantity? from a given list by typ-
ing ?qu?. seeing that the word ?quantity? was automatically
marked in the list. Pressing the space key will automatically
open brackets, which indicates we have to provide the system
with an argument. A tool tip text will pop to explain the user
what is the function of the required argument. After entering
number, we will hit the space bar to indicate we have no more
information to supply about the ?quantity?; the brackets will
be automatically closed. After the system has been told no
more modification will be made on the quantity, the ?egg?
object is back to be the active one. The system marks the ac-
tive object in any given time by underline the related word in
the input text.
Pressing the dot will pop the list box with the possible mod-
ifications for the object. We will now choose ?attribute?.
Again the system will open brackets, and a list of possible
concepts will appear. The current active node in the graph is
?attribute?. Among the possible concepts we will choose the
?big? concept, and continue by clicking the enter key (the
lexical chooser will map the ?big? concept to the collocation
?large? appropriate for ?eggs?). A new folder in the global
context view will be added with the title of ?egg? and will
contain the new instance with its identifier and description as
a CG in linear form.
Each time a dot or an identifier is entered, the system con-
verts the current expression to a CG, maps the CG to a FUF
Functional Description which serves as input to the lexical
chooser; lexical choice and syntactic realization is performed,
and feedback is provided in both English and Hebrew.
The same generated sentence is shown without context (in
the left part of the screen), and in context (after reference
planning and aggregation).
When generating utterances, the author can refer to an ob-
ject from the context by clicking on the context view. This
enters the corresponding identifier in the utterance graph.
4 Evaluation
The objectives of the SAUT authoring system are to pro-
vide the user with a fast, intuitive and accurate way to com-
pose semantic structures that represent meaning s/he wants to
convey, then presenting the meaning in various natural lan-
guages. Therefore, an evaluation of these aspects (speed, in-
tuitiveness, accuracy and coverage) is required, and we have
conducted an experiment with human subjects to measure
them. The experiment measures a snapshot of these parame-
ters at a given state of the implementation. In the error analy-
sis we have isolated parameters which depend on specifics
of the implementation and those which require essential revi-
sions to the approach followed by SAUT.
4.1 User Experiment
We have conducted a user experiment, in which ten subjects
were given three to four recipes in English (all taken from
the Internet) from a total pool of ten. The subjects had to
compose semantic documents for these recipes using SAUT
2
. The ontology and lexicon for the specific domain of cook-
ing recipes were prepared in advance, and we have tested the
tool by composing these recipes with the system. The docu-
ments the authors prepared are later used as a ?gold standard?
(we refer to them as ?reference documents?). The experi-
ment was managed as follows: first, a short presentation of
the tool (20 minutes) was given. Then, each subject recieved
a written interactive tutorial which took approximately half
an hour to process. Finally, each subject composed a set of 3
to 4 documents. The overall time taken for each subject was
2.5 hours.
4.2 Evaluation
We have measured the following aspects of the system during
the experiment.
Coverage - answers the questions ?can I say everything I
mean? and ?how much of the possible meanings that can be
expressed in natural language can be expressed using the in-
put language?. In order to check the coverage of the tool,
we examined the reference documents. We compared the
text generated from the reference documents with the orig-
inal recipes and checked which parts of the information were
2All subjects were computer science students.
included, excluded or expressed in a partial way with respect
to the original. We counted each of these in number of words
in the original text, and expressed these 3 counts as a per-
centage of the words in the original recipe. We summed up
the result as a coverage index which combined the 3 counts
(correct, missing, partial) with a factor of 70% for the partial
count.
The results were checked by two authors independently
and we report here the average of these two verifications. On
a total of 10 recipes, containing 1024 words overall, the cov-
erage of the system is 91%. Coverage was uniform across
recipes and judges. We performed error analysis for the re-
maining 9% of the un-covered material below.
Intuitiveness - to assess the ease of use of the tool,
we measured the ?learning curve? for users first using the
system, and measuring the time it takes to author a recipe for
each successive document (1st, 2nd, 3rd, 4th). For 10 users
first facing the tool, the time it took to author the documents
is as follows:
Document # Average Time to author
1st 36 mn
2nd 28 mn
3rd 22 mn
4th 14 mn
The time distribution among 10 users was extremely uni-
form. We did not find variation in the quality of the authored
documents across users and across number of document.
The tool is mastered quickly, by users with no prior train-
ing in knowledge representation or natural language process-
ing. Composing the reference documents (approximately
100-words recipes) by the authors took an average of 12
minutes.
Speed - we measured the time required to compose a docu-
ment as a semantic representation, and compare it to the time
taken to translate the same document in a different language.
We compare the average time for trained users to author a
recipe (14 minutes) with that taken by 2 trained translators to
translate 4 recipes (from English to Hebrew).
Semantic Authoring Time Translation Time
14 (minutes) 6 (minutes)
The comparison is encouraging - it indicates that a tool for
semantic authoring could become cost-effective if it is used
to generate in 2 or 3 languages.
Accuracy - We analyzed the errors in the documents pre-
pared by the 10 users according to the following breakup:
? Words in the source document not present in the seman-
tic form
? Words in the source document presented inaccurately in
the semantic form
? Users? errors in semantic form that are not included in
the former two parameters.
We calculated the accuracy for each document produced
by the subjects during the experiment. Then we compared
each document with the corresponding reference document
(used here as a gold standard). Relative accuracy of this
form estimates a form of confidence ? ?how sure can the
user be that s/he wrote what s/he meant?? This measurement
depends on the preliminary assumption that for a given
recipe, any two readers (in the experiment environment ?
including the authors), will extract similar information. This
assumption is warranted for cooking recipes. This measure
takes into account the limitations of the tool and reflects the
success of users to express all that the tool can express:
Document # Accuracy
1st 93%
2nd 92%
3rd 95%
4th 90%
Accuracy is quite consistent during the experiment ses-
sions, i.e., it does not change as practice increases. The aver-
age 92.5% accuracy is quite high.
We have categorized the errors found in subjects? docu-
ments in the following manner:
? Content can be accurately expressed with SAUT (user
error)
? Content will be accurately expressed with changes in the
SAUT?s lexicon and ontology (ontology deficit)
? Content cannot be expressed in the current implemen-
tation, and requires further investigation of the concept
(implementation and conceptual limitations)
Document # Accuracy
User error 44%
Ontology deficit 23%
Tool limitations 33%
This breakdown indicates that the tool can be improved by
investing more time in the GUI and feedback quality and by
extending the ontology. The difficult conceptual issues (those
which will require major design modifications, or put in ques-
tion our choice of formalism for knowledge encoding) repre-
sent 33% of the errors ? overall accounting for 2.5% of the
words in the word count of the generated text.
5 Analysis
The current prototype of SAUT proves the feasibility of se-
mantic authoring combined with natural language generation.
The system includes a lexical chooser of several hundred
verbs and nouns derived from WordNet in a specific domain.
The system is easy to use and requires training of less than
one hour. User interface features make it very fast to enter
CGs of the type required for a recipe. If the documents are
generated in more than 2 languages, the tool can even become
cost effective at its current level of ergonomy.
The current prototype indicates that combining techniques
from NLG with User Interfaces techniques from program-
ming languages editors results in an efficient knowledge edi-
tor. In future work, we intend to evaluate how to use semantic
forms for summarization and inferencing. We also will evalu-
ate how rhetorical information can be managed in the system,
by applying the tool to different domains.
References
[Bateman, 1997] John Bateman. Enabling technology for
multilingual natural language generation: the KPML de-
velopment. Natural Language Engineering, 1(1):1 ? 42,
1997.
[Berners-Lee et al, 2001] Tim Berners-Lee, James Hendler,
and Ora Lassila. Semantic web. Scientific American, 2001.
[Bontcheva, 1995] Kalina Bontcheva. Generation of multi-
lingual eplanations from conceptual graphs. In Proc. of
RANLP?97, Batak, Bulgaria, 1995.
[Coch, 1998] J. Coch. Interactive generation and knowledge
administration in multimeteo. In Proc. of the 9th Workshop
INLG, pages 300?303, Canada, 1998.
[Cote and Moulin, 1990] D. Cote and B. Moulin. Refin-
ing sowa?s con-ceptual graph theory for text genera-
tion. In Proc. of IEA/AIE90, volume 1, pages 528?537,
Charleston, SC, 1990.
[Dale, 1990] Robert Dale. Generating recipes: An overview
of epicure. In Michael Zock Robert Dale, Chris Mellish,
editor, Current Research in Natural Language Generation,
pages 229?255. Academic Press, New York, 1990.
[Delin et al, 1994] Judy Delin, Anthony Hartley, Ce?cile L.
Paris, Donia Scott, and Keith Vander Linden. Expressing
Procedural Relationships in Multilingual Instructions. In
Proc. of the 7th. Int. Workshop on NLG, pages 61 ? 70,
1994.
[Delugach, 2001] Harry Delugach. Charger: A graphical
conceptual graph editor. In Proc. of ICCS 2001 CGTools
Workshop, 2001.
[Elhadad, 1991] Michael Elhadad. FUF user manual - ver-
sion 5.0. Technical Report CUCS-038-91, University of
Columbia, 1991.
[Elhadad, 1992] Michael Elhadad. Using Argumentation to
Control Lexical Choice: A Functional Unification Imple-
mentation. PhD thesis, Columbia University, 1992.
[Genesereth and Fikes, 1992] M.R. Genesereth and R.E.
Fikes. Knowledge interchange format, version 3.0 ref-
erence manual. Technical Report Logic-92-1, Computer
Science Department, Stanford University, 1992.
[Goldberg et al, 1994] E. Goldberg, N. Driedger, and
R. Kittredge. Using natural-language processing to pro-
duce weather forecasts. IEEE Expert, 9(2):45?53, 1994.
[Jing et al, 2000] Hongyan Jing, Yael Dahan Netzer,
Michael Elhadad, and Kathleen McKeown. Integrating
a large-scale, reusable lexicon with a natural language
generator. In Proceedings of the 1st INLG, pages 209?216,
Mitzpe Ramon, Israel, 2000.
[Kharitonov, 1999] Mark Kharitonov. Cfuf: A fast inter-
preter for the functional unification formalism. Master?s
thesis, BGU, Israel, 1999.
[Kipper et al, 2000] K. Kipper, H. Trang Dang, and
M. Palmer. Class-based construction of a verb lexicon.
In Proceeding of AAAI-2000, 2000.
[Kittredge and Lehrberger, 1982] R. Kittredge and
J. Lehrberger. Sublanguage: Studies of Language in
Restricted Semantic Domains. De Gruyter, Berlin, 1982.
[Kukich, 1983] Karen Kukich. Knowledge-based report gen-
eration: A technique for automatically generating natural
language reports from databases. In Proc. of the 6th Inter-
national ACM SIGIR Conference, 1983.
[Levin, 1993] Beth Levin. English Verb Classes and Verb
Alternations: A Preliminary Investigation. University of
Chicago Press, 1993.
[Lin and Pantel, 2001] Dekang Lin and Patrick Pantel. DIRT
@SBT@discovery of inference rules from text. In Knowl-
edge Discovery and Data Mining, pages 323?328, 2001.
[Macleod and Grishman, 1995] C. Macleod and R. Grish-
man. COMLEX Syntax Reference Manual. Proteus
Project, NYU, 1995.
[Miller, 1995] George A. Miller. Wordnet: a lexical database
for english. Commun. ACM, 38(11):39?41, 1995.
[Netzer, 1997] Yael Netzer. Design and evaluation of a func-
tional input specification language for the generation of
bilingual nominal expressions (hebrew/english). Master?s
thesis, BGU, Israel, 1997.
[Paley et al, 1997] S.M. Paley, Lowrance, J.D., and P.D.
Karp. A generic knowledge-base browser and editor. In
Proc. of the 1997 National Conference on AI, 1997.
[Paris and Vander Linden, 1996] Ce?cile Paris and Keith Van-
der Linden. DRAFTER: An interactive support tool
for writing multilingual instructions. IEEE Computer,
29(7):49?56, 1996.
[Power and Scott, 1998] Roger Power and Donia Scott. Mul-
tilingual authoring using feedback texts. In Proc. of
COLING-ACL 98, Montreal, Canada, 1998.
[Pulman, 1996] Stephen Pulman. Controlled language for
knowledge representation. In Proc. of the 1st Int. Work-
shop on Controlled Language Applications, pages 233 ?
242, 1996.
[Reiter and Dale, 1992] Ehud Reiter and Robert Dale. A
fast algorithm for the generation of referring expressions.
In Proc. of the 14th COLING, pages 232?238, Nantes,
France, 1992.
[Ro?sner and Stede, 1994] D. Ro?sner and M. Stede. Generat-
ing multilingual documents from a knowledge base: The
techdoc project. In Proc. of COLING?94, pages 339?346,
Kyoto, 1994.
[Shaw et al, 1994] J. Shaw, K. Kukich, and K. Mckeown.
Practical issues in automatic documentation generation. In
Proceeding of the 4th ANLP, pages 7?14, 1994.
[Shaw, 1995] James Shaw. Conciseness through aggregation
in text generation. In Proc. of the 33rd conference on ACL,
pages 329 ? 331, Morristown, NJ, USA, 1995.
[Sowa, 1987] J. F. Sowa. Semantic networks. In S. C.
Shapiro, editor, Encyclopedia of Artificial Intelligence 2.
John Wiley & Sons, New York, 1987.
[Stede, 1996] Manfred Stede. Lexical semantics and knowl-
edge representation in multilingual sentence generation.
PhD thesis, University of Toronto, 1996.
Proceedings of the 5th Workshop on Important Unresolved Matters, pages 57?64,
Prague, Czech Republic, June 2007. c?2007 Association for Computational Linguistics
Can You Tag the Modal? You Should.
Yael Netzer and Meni Adler and David Gabay and Michael Elhadad
Ben Gurion University of the Negev
Department of Computer Science
POB 653 Be?er Sheva, 84105, Israel
{yaeln,adlerm,gabayd,elhadad}@cs.bgu.ac.il
Abstract
Computational linguistics methods are typ-
ically first developed and tested in English.
When applied to other languages, assump-
tions from English data are often applied
to the target language. One of the most
common such assumptions is that a ?stan-
dard? part-of-speech (POS) tagset can be
used across languages with only slight vari-
ations. We discuss in this paper a specific is-
sue related to the definition of a POS tagset
for Modern Hebrew, as an example to clar-
ify the method through which such varia-
tions can be defined. It is widely assumed
that Hebrew has no syntactic category of
modals. There is, however, an identified
class of words which are modal-like in their
semantics, and can be characterized through
distinct syntactic and morphologic criteria.
We have found wide disagreement among
traditional dictionaries on the POS tag at-
tributed to such words. We describe three
main approaches when deciding how to tag
such words in Hebrew. We illustrate the im-
pact of selecting each of these approaches
on agreement among human taggers, and on
the accuracy of automatic POS taggers in-
duced for each method. We finally recom-
mend the use of a ?modal? tag in Hebrew
and provide detailed guidelines for this tag.
Our overall conclusion is that tagset defini-
tion is a complex task which deserves appro-
priate methodology.
1 Introduction
In this paper we address one linguistic issue that was
raised while tagging a Hebrew corpus for part of
speech (POS) and morphological information. Our
corpus is comprised of short news stories. It in-
cludes roughly 1,000,000 tokens, in articles of typ-
ical length between 200 to 1000 tokens. The arti-
cles are written in a relatively simple style, with a
high token/word ratio. Of the full corpus, a sam-
ple of articles comprising altogether 100,000 tokens
was assembled at random and manually tagged for
part of speech. We employed four students as tag-
gers. An initial set of guidelines was first composed,
relying on the categories found in several dictionar-
ies and on the Penn treebank POS guidelines (San-
torini, 1995). Tagging was done using an automatic
tool1. We relied on existing computational lexicons
(Segal, 2000; Yona, 2004) to generate candidate tags
for each word. As many words from the corpus were
either missing or tagged in a non uniform manner in
the lexicons, we recommended looking up missing
words in traditional dictionaries. Disagreement was
also found among copyrighted dictionaries, both for
open and closed set categories. Given the lack of
a reliable lexicon, the taggers were not given a list
of options to choose from, but were free to tag with
whatever tag they found suitable. The process, al-
though slower and bound to produce unintentional
mistakes, was used for building a lexicon, and to
refine the guidelines and on occasion modify the
POS tagset. When constructing and then amending
the guidelines we sought the best trade-off between
1http://wordfreak.sourceforge.net
57
accuracy and meaningfulness of the categorization,
and simplicity of the guidelines, which is important
for consistent tagging.
Initially, each text was tagged by four different
people, and the guidelines were revised according
to questions or disagreements that were raised. As
the guidelines became more stable, the disagreement
rate decreased, each text was tagged by three peo-
ple only and eventually two taggers and a referee
that reviewed disagreements between the two. The
disagreement rate between any two taggers was ini-
tially as high as 20%, and dropped to 3% after a few
rounds of tagging and revising the guidelines.
Major sources of disagreements that were identi-
fied, include:
Prepositional phrases vs. prepositions In Hebrew,
formative letters ?      b,c,l,m2 ? can be attached
to a noun to create a short prepositional phrase. In
some cases, such phrases function as a preposition
and the original meaning of the noun is not clearly
felt. Some taggers would tag the word as a prepo-
sitional prefix + noun, while others tagged it as a
preposition, e.g., 
	 
 b?iqbot (following), that
can be tagged as 	 
 b-iqbot (in the footsteps
of).
Adverbial phrases vs. Adverbs the problem is simi-
lar to the one above, e.g.,  	  bdiyuq (exactly), can
be tagged as b-diyuq (with accuracy).
Participles vs. Adjectives as both categories can
modify nouns, it is hard to distinguish between
them, e.g,   Proceedings of the NAACL HLT Workshop on Computational Approaches to Linguistic Creativity, pages 32?39,
Boulder, Colorado, June 2009. c?2009 Association for Computational Linguistics
Gaiku : Generating Haiku with Word Associations Norms
Yael Netzer? and David Gabay and Yoav Goldberg? and Michael Elhadad
Ben Gurion University of the Negev
Department of Computer Science
POB 653 Be?er Sheva, 84105, Israel
{yaeln,gabayd,yoavg,elhadad}@cs.bgu.ac.il
Abstract
creativeness / a pleasing field / of bloom
Word associations are an important element
of linguistic creativity. Traditional lexical
knowledge bases such as WordNet formalize
a limited set of systematic relations among
words, such as synonymy, polysemy and hy-
pernymy. Such relations maintain their sys-
tematicity when composed into lexical chains.
We claim that such relations cannot explain
the type of lexical associations common in
poetic text. We explore in this paper the
usage of Word Association Norms (WANs)
as an alternative lexical knowledge source
to analyze linguistic computational creativity.
We specifically investigate the Haiku poetic
genre, which is characterized by heavy re-
liance on lexical associations. We first com-
pare the density of WAN-based word asso-
ciations in a corpus of English Haiku po-
ems to that of WordNet-based associations as
well as in other non-poetic genres. These
experiments confirm our hypothesis that the
non-systematic lexical associations captured
in WANs play an important role in poetic text.
We then present Gaiku, a system to automat-
ically generate Haikus from a seed word and
using WAN-associations. Human evaluation
indicate that generated Haikus are of lesser
quality than human Haikus, but a high propor-
tion of generated Haikus can confuse human
readers, and a few of them trigger intriguing
reactions.
? Supported by Deutsche Telekom Laboratories at Ben-
Gurion University of the Negev.
? Supported by the Lynn and William Frankel Center for
Computer Sciences.
1 Introduction
Traditional lexical knowledge bases such as Word-
Net formalize a limited set of systematic relations
that exist between words, such as synonymy, pol-
ysemy, hypernymy. When such relations are com-
posed, they maintain their systematicity, and do not
create surprising, unexpected word associations.
The human mind is not limited to such system-
atic relations, and people tend to associate words to
each other with a rich set of relations, such as non
systematic paradigmatic (doctor-nurse) and syntag-
matic relations (mash-potato) as identified by Saus-
sure (1949). Such associations rely on cultural
(mash-television), emotional (math - yuck) and per-
sonal experience (autumn - Canada).
In linguistic creativity, such as prose or poetry
writing, word associations play an important role
and the ability to connect words into new, unex-
pected relations is one of the key mechanisms that
triggers the reader involvement.
We explore in this paper the usage of Word As-
sociation Norms (WANs) as an alternative lexical
knowledge source to analyze linguistic computa-
tional creativity. WANs have been developed in psy-
chological research in the past 40 years. They record
typical word associations evoked by people when
they are submitted a trigger word. Such associations
(e.g., table to chair or cloth) are non-systematic, yet
highly stable across people, time (over a period of 30
years) and languages. WANs have been compiled in
various languages, and provide an interesting source
to analyze word associations in creative writing.
We specifically investigate the Haiku poetic
32
genre, which is characterized by heavy reliance on
lexical associations. The hypothesis we investigate
is that WANs play a role in computational creativ-
ity, and better explain the type of word associations
observed in creative writing than the systematic re-
lations found in thesauri such as WordNet.
In the rest of the paper, we refine our hypothe-
sis and present observations on a dataset of English
Haikus we collected. We find that the density of
WAN-based word associations in Haikus is much
higher than in other genres, and also much higher
than the density of WordNet-based associations. We
then present Gaiku, a system we developed to auto-
matically generate Haikus from a seed word using
word association norms. Evaluation we performed
with a group of 60 human readers indicates that the
generated Haikus exhibit interesting creative charac-
teristics and sometimes receive intriguing acclaim.
2 Background and Previous Work
2.1 Computational Creativity
Computational creativity in general and linguistic in
particular, is a fascinating task. On the one hand, lin-
guistic creativity goes beyond the general NLP tasks
and requires understanding and modelling knowl-
edge which, almost by definition, cannot be formal-
ized (i.e., terms like beautiful, touching, funny or in-
triguing). On the other hand, this vagueness itself
may enable a less restrictive formalization and allow
a variety of quality judgments. Such vague formal-
izations are naturally more useful when a computa-
tional creativity system does not attempt to model
the creativity process itself, but instead focuses on
?creative products? such as poetry (see Section 2.3),
prose and narrative (Montfort, 2006), cryptic cross-
word clues (Hardcastle, 2007) and many others.
Some research focus on the creative process itself
(see (Ritchie, 2006) for a comprehensive review of
the field). We discuss in this paper what Boden
(1998) calls P-Creativity (Psychological Creativity)
which is defined relative to the initial state of knowl-
edge, and H-Creativity (Historical Creativity) which
is relative to a specific reference culture. Boden
claims that, while hard to reproduce, exploratory
creativity is most successful in computer models of
creativity. This is because the other kinds of creativ-
ity are even more elusive due to the difficulty of ap-
proaching the richness of human associative mem-
ory, and the difficulty of identifying our values and
of expressing them in computational form.
We investigate in our work one way of addressing
this difficulty: we propose to use associative data as
a knowledge source as a first approximation of hu-
man associative capabilities. While we do not ex-
plain such associations, we attempt to use them in
a constructive manner as part of a simple combina-
tional model of creativity in poetry.
2.2 Word Associations and Creativity
Associations and creativity are long known to be
strongly connected. Mendick (Mendick, 1969) de-
fines creative thinking as ?the forming of associative
elements into new combinations which either meet
specified requirements or are in some way useful.?
The usefulness criterion distinguishes original think-
ing from creative thinking. A creative solution is
reached through three main paths: serendipity (ran-
dom stimuli evoke associative elements), similar-
ity (stimuli and solution are found similar through
an association) and mediation (both ?problem? and
?solution? can be associated to similar elements).
In our work, we hypothesize that interesting Haiku
poems exhibit creative word associations. We rely
on this hypothesis to first generate candidate word
associations starting from a seed word and follow-
ing random walks through WANs, but also to rank
candidate Haiku poems by measuring the density of
WAN-based associations they exhibit.
2.3 Poetry Generation
Although several automatic and semi-automatic po-
etry generation systems were developed over the
years, most of them did not rise above the level of
?party tricks? (Manurung et al, 2000). In his the-
sis, (Manurung, 2003), defined a poem to be a text
that meets three properties: meaningfulness, gram-
maticality and poeticness. Two of the few systems
that attempt to explicitly represent all three prop-
erties are reported in (Gervas, 2001) and (D??az-
Agudo et al, 2002). Both systems take as input a
prose message provided by the user, and translate it
into formal Spanish poetry. The system proposed
in (Manurung et al, 2000) is similar in that it fo-
cuses on the syntactic and phonetic patterns of the
poem, putting less stress on the semantics. The sys-
33
tem starts with a simple seed and gradually devel-
ops a poem, by making small syntactic and semantic
changes at every step.
Specifically in the subfield of Haiku generation,
the Haiku generator presented in (Wong and Chun,
2008) produces candidate poems by combining lines
taken from blogs. The system then ranks the can-
didates according to semantic similarity, which is
computed using the results returned by a search en-
gine when querying for words in each line. Hitch-
Haiku (Tosa et al, 2008), another Haiku generation
system, starts from two seed words given by the user.
It retrieves two phrases containing these words from
a corpus, and then adds a third phrase that connects
both input words, using lexical resources.
In our work, we induce a statistical language
model of the structure of Haikus from an analysis
of a corpus of English Haikus, and explore ways to
combine chains of lexical associations into the ex-
pected Haiku syntactic structure. The key issues we
investigate are the importance of WAN-based asso-
ciations in the Haiku generation process, and how a
chain of words, linked through WAN-based associa-
tions, can be composed into a Haiku-like structure.
2.4 Haiku
Haiku is a form of poetry originated in Japan in
the sixteenth century. The genre was adopted in
Western languages in the 20th Century. The origi-
nal form of a poem is of three lines of five, seven
and five syllables (although this constraint is loos-
ened in non-Japanese versions of Haiku (Gilbert and
Yoneoka, 2000)). Haiku, by its nature, aims to re-
flect or evoke emotion using an extremely economi-
cal linguistic form; most Haiku use present tense and
use no judgmental words; in addition, functional or
syntactic words may be dropped. Traditional Haiku
involve reference to nature and seasons, but modern
and western Haiku are not restricted to this theme1.
We adopt the less ?constraining? definition of the
author Jack Kerouac (2004) for a Haiku ?I propose
that the ?Western Haiku? simply say a lot in three
short lines in any Western language. Above all, a
Haiku must be very simple and free of all poetic
1Senryu poetry, similar in form to Haiku, is the Japanese
genre of poems that relate to human and relationships, and may
be humorous. Hereafter, we use Haiku for both the original
definition and the Senryu as well.
trickery and make a little picture and yet be as airy
and graceful as a Vivaldi Pastorella.? (pp. x-xi). In
addition, we are guided by the saying ? The best
haiku should leave the reader wondering ? (Quoted
in (Blasko and Merski, 1998))
2.5 Word Association Norms
The interest in word associations is common to
many fields. Idiosyncrasy of associations was used
as a diagnostic tool at the beginning of the 20th cen-
tury, but nowadays the majority of approaches deal
less with particular associations and more with gen-
eral patterns in order to study the structure of the
mental lexicon and of semantic memory (Rubinsten
et al, 2005).
Word Association Norms (WAN) are a collection
of cue words and the set of free associations that
were given as responses to the cue, accompanied
with quantitative and statistical measures. Subjects
are given a word and asked to respond immediately
with the first word that comes to their mind. The
largest WAN we know for English is the University
of South Florida Free Association Norms (Nelson et
al., 1998).
Word Association Norms and Thesauri in NLP
Sinopalnikova and Smrz (2004) have shown that
when building and extending semantic networks,
WANs have advantages over corpus-based meth-
ods. They found that WANs cover semantic rela-
tions that are difficult to acquire from a corpus: 42%
of the non-idiosyncratic cue-target pairs in an En-
glish WAN never co-appeared in a 10 words win-
dow in a large balanced text corpus. From the point
of view of computational creativity, this is encourag-
ing, since it suggests that association-based content
generation can lead to texts that are both sensible
and novel. (Duch and Pilichowski, 2007)?s work,
from a neuro-cognitive perspective, generates neol-
ogisms based, among other data, on word associa-
tion. (Duch and Pilichowski, 2007) sums ?creativity
requires prior knowledge, imagination and filtering
of the results.?
3 WordNet vs. Associations
Word association norms add an insight on language
that is not found in WordNet or are hard to acquire
from corpora, and therefore can be used as an ad-
ditional tool in NLP applications and computational
34
creativity.
We choose the Haiku generation task using word
associations, since this genre of poetry encapsulates
meaning in a special way. Haiku tend to use words
which are connected through associative or phono-
logical connections (very often ambiguous).
We hypothesize that word-associations are good
catalyzers for creativity, and use them as a building
block in the creative process of Haiku generation.
We first test this hypothesis by analyzing a corpus of
existing Haiku poems.
3.1 Analyzing existing text
Can the creativity of text as reflected in word as-
sociations be quantified? Are Haiku poems indeed
more associative than newswire text or prose? If
this is the case, we expect Haiku to have more asso-
ciative relations, which cannot be easily recovered
by WordNet than other type of text. We view the
WAN as an undirected graph in which the nodes
are stemmed words, and two nodes are connected
iff one of them is a cue for the other. We take the
associative distance between two words to be the
number of edges in the shortest path between the
words in the associations-graph. Interestingly, al-
most any word pair in the association graph is con-
nected with a path of at most 3 edges. Thus, we
take two words to be associatively related if their
associative distance is 1 or 2. Similarly, we define
the WordNet distance between two stemmed words
to be the number of edges in the shortest path be-
tween any synset of one word to any synset of the
other word2. Two words are WordNet-related if their
WordNet distance is less than 4 (this is consistent
with works on lexical-cohesion, (Morris and Hirst,
1991)).
We take the associativity of a piece of text to be
the number of associated word pairs in the text, nor-
malized by the number of word pairs in the text of
which both words are in the WAN.3 We take the
WordNet-relations level of a piece of text to be the
number of WordNet-related word pairs in the text.
2This is the inverse of the path-similarity measure of (Ped-
ersen et al, 2004).
3This normalization is performed to account for the limited
lexical coverage of the WAN. We don?t want words that appear
in a text, but are not covered by the WAN, to affect the associa-
tivity level of the text.
SOURCE AVG. ASSOC AVG. WORDNETRELATIONS (<3) RELATIONS (<4)
News 0.26 2.02
Prose 0.22 1.4
Haiku 0.32 1.38
Table 1: Associative and WordNet relations in various
text genres
We measure the average associativity and Word-
Net levels of 200 of the Haiku in our Haiku Cor-
pus (Section 4.1), as well as of random 12-word
sequences from Project Gutenberg and from the
NANC newswire corpus.
The results are presented in Table 1.
Perhaps surprisingly, the numbers for the Guten-
berg texts are lower on all measures. This is at-
tributed to the fact that Gutenberg texts have many
more pronouns and non-content words than the
Haiku and newswire text. Haiku text appears to
be more associative than newswire text. Moreover,
newswire documents have many more WordNet-
relations than the Haiku poems ? whenever words
are related in Haiku, this relatedness tends to be cap-
tured via the association network rather than via the
WordNet relations. The same trend is apparent also
when considering the Gutenberg numbers: they have
about 15% less associations than newswire text, but
about 30% less WordNet-relations. This supports
the claim that associative information which is not
readily available in WordNet is a good indicator of
creative content.
3.2 Generating creative content
We now investigate how word-associations can help
in the process of generating Haikus. We define
a 5 stage generative process: theme selection in
which the general theme of the Haiku is decided,
syntactic planning, which sets the Haiku form and
syntactic constraints, content selection / semantic
planning which combines syntactic and aesthetic
constraints with the theme selected in the previous
stages to form good building blocks, filtered over-
generation of many Haiku based on these selected
building blocks, and finally re-ranking of the gen-
erated Haiku based on external criteria.
The details of the generation algorithm are pre-
sented in Section 4.2. Here we focus on the creative
aspect of this process ? theme selection. Our main
claim is that WANs are a good source for interest-
35
ing themes. Specifically, interesting themes can be
obtained by performing a short random walk on the
association graph induced by the WAN network.
Table 2 presents the results of several random
walks of 3 steps starting from the seed words ?Dog?,
?Winter?, ?Nature? and ?Obsession?. For compar-
ison, we also present the results of random walks
over WordNet glosses for the same seeds.
We observe that the association network is bet-
ter for our needs than WordNet. Random walks in
WordNet are more likely to stay too close to the seed
word, limiting the poetic options, or to get too far
and produce almost random connections.
4 Algorithm for generating Haiku
4.1 Dataset
We used the Word Association Norms (WAN) of the
University of South Florida 4 (Nelson et al, 1998)
for discovering associations of words. The dataset
(Appendix A, there) includes 5,019 cue words and
10,469 additional target that were collected with
more than 6,000 participants since 1973.
We have compiled a Haiku Corpus, which in-
cludes approximately 3,577 Haiku in English of var-
ious sources (amateurish sites, children?s writings,
translations of classic Japanese Haiku of Bashu and
others, and ?official? sites of Haiku Associations
(e.g., Haiku Path - Haiku Society of America).
For the content selection part of the algorithms,
we experimented with two data sources: a corpus of
1TB web-based N-grams supplied by Google, and
the complete text of Project Gutenberg. The Guten-
berg data has the advantage of being easier to POS-
tag and contains less restricted-content, while the
Google Web data is somewhat more diverse.
4.2 Algorithm Details
Our Haiku generation algorithm includes 5 stages:
theme selection, syntactic planning, content selec-
tion, filtered over generation, and ranking.
The Theme Selection stage is in charge of dictat-
ing the overall theme of our Haiku. We start with
a user-supplied seed word (e.g. WINTER). We then
consult the Association database in order to enrich
the seed word with various associations. Ideally, we
would like these associations to be close enough to
4http://w3.usf.edu/FreeAssociation/
the seed word to be understandable, yet far enough
away from it as to be interesting. After some ex-
perimenting, we came up with the following heuris-
tic, which we found to provide adequate results. We
start with the seed word, and conduct a short random
walk on the associations graph. Each random step
is comprised of choosing a random direction (either
?Cue? or ?Target?) using a uniform distribution, and
then a random neighbor according to its relative fre-
quency. We conduct several (8) such walks, each
with 3 steps, and keep all the resulting words. This
gives us mostly close, probable associations, as well
as some less probable, further away from the seed.
The syntactic planning stage determines the
form of the generated Haiku, setting syntactic and
aesthetic constraints for the generative process. This
is done in a data-driven way by considering common
line patterns from our Haiku corpus. In a training
stage, we POS-tagged each of the Haiku, and then
extracted a pattern from each of the Haiku lines. A
line-pattern is a sequence of POS-tags, in which the
most common words are lexicalized to include the
word-form in addition to the POS-tag. An example
for such a line pattern might be DT the JJ NN.
We kept the top-40 frequent patterns for each of the
Haiku lines, overall 120 patterns. When generating a
new Haiku, we choose a random pattern for the first
line, then choose the second line pattern conditioned
on the first, and the third line pattern conditioned
on the second. The line patterns are chosen with a
probability proportional to their relative frequencies
in the training corpus. For the second and third lines
we use the conditional probabilities of a pattern ap-
pearing after the previous line pattern. The result
of this stage is a 3-line Haiku skeleton, dictating the
number of words on each line, their POS-tags, and
the placement of specific function words.
In the Content Selection stage, we look for pos-
sible Haiku lines, based on our selected theme and
syntactic structure. We go over our candidate lines5,
and extract lines which match the syntactic patterns
and contain a stemmed appearance of one of the
stemmed theme words. In our current implemen-
tation, we require the first line to contain the seed
word, and the second and third line to contain any of
5These are POS-tagged n-grams extracted from a large text
corpora: the Google T1 dataset or Project Gutenberg
36
SEED WAN WORDNET
Dog puppy adorable cute heel villain villainess
Dog cat curious george hound scoundrel villainess
Winter summer heat microwave wintertime solstice equinox
Winter chill cold alergy midwinter wintertime season
Nature animals instinct animals world body crotch
Nature natural environment surrounding complexion archaism octoroon
Obsession cologne perfume smell fixation preoccupation thought
Obsession compulsion feeling symptom compulsion onomatomania compulsion
Table 2: Some random walks on the WordNet and WAN induced graphs
the theme words. Other variations, such as choos-
ing a different word set for each line, are of course
possible.
The over generation stage involves creating
many possible Haiku candidates by randomly
matching lines collected in the content selection
stage. We filter away Haiku candidates which have
an undesired properties, such as repeating the same
content-word in two different lines.
All of the generated Haiku obey the syntactic and
semantic constraints, but not all of them are interest-
ing. Thus, we rank the Haiku in order to weed out
the better ones. The top-ranking Haiku is the output
of our system. Our current heuristic prefers highly
associative Haikus. This is done by counting the
number of 1st and 2nd degree associations in each
Haiku, while giving more weight to 2nd degree as-
sociations in order to encourage ?surprises?. While
all the candidate Haiku were generated based on a
common theme of intended associative connections,
the content selection and adherence to syntactic con-
straints introduce additional content words and with
them some new, unintended associative connections.
Our re-ranking approach tries to maximize the num-
ber of such connections.6
5 Evaluation
The ultimate goal of a poetry generation system is to
produce poems that will be considered good if writ-
ten by a human poet. It is difficult to evaluate to what
extent a poetry generation system can meet this goal
(Ritchie, 2001; Manurung et al, 2000). Difficulties
arise from two major sources: first, since a creative
6While this heuristic works well, it leaves a lot to be desired.
It considers only the quantity of the associations, and not their
quality. Indeed, when looking at the Haiku candidates produced
in the generation stage, one can find many interesting pieces,
where some of the lower ranking ones are far better than the top
ranking.
work should be novel, it cannot be directly evaluated
by comparison to some gold standard. Second, it is
hard for people to objectively evaluate the quality of
poetry. Even determining whether a text is a poem
or not is not an easy task, as readers expect poetry
to require creative reading, and tolerate, to some ex-
tent, ungrammatical structures or cryptic meaning.
5.1 ?Turing Test? Experiment
To evaluate the quality of Gaiku, we asked a group
of volunteers to read a set of Haiku, indicate how
much they liked each one (on a scale of 1-5), and
classify each Haiku as written by a human or by a
computer.
We compiled two sets of Haiku. The first set
(AUTO) contained 25 Haiku. 10 Haiku chosen at
random from our Haiku corpus, and 15 computer
generated ones. The computer generated Haiku
were created by identifying the main word in the first
line of each human-written Haiku, and passing it as
a seed word to the Haiku generation algorithm (in
case a first line in human-written Haiku contained
two main words, two Haiku were generated). We in-
cluded the top-ranking Haiku returning from a single
run of the system for each seed word. The only hu-
man judgement in compiling this set was in the iden-
tification of the main words of the human Haiku.
The second set (SEL) was compiled of 9 haiku po-
ems that won awards7, and 17 computer Haiku that
were selected by us, after several runs of the auto-
matic process. (Again, each poem in the automatic
poems set shared at least one word with some poem
in the human Haiku set).
The subjects were not given any information
about the number of computer-generated poems in
the sets.
7Gerald Brady Memorial Award Collection http://www.hsa-
haiku.org/bradyawards/brady.htm 2006-2007
37
The AUTO questionnaire was answered by 40
subjects and the SEL one by 22. (Altogether, 52 dif-
ferent people took part in the experiment, as some
subjects answered both versions). The subjects were
all adults (age 18 to 74), some were native English
speakers and others were fully fluent in English. Ex-
cept a few, they did not have academic background
in literature.
5.2 Results and Discussion
Results are presented in Table 3 and Figure 1.
Overall, subjects were correct in 66.7% of their
judgements in AUTO and 61.4% in SEL. The aver-
age grade that a poem - human or machine-made -
received correlates with the percentage of subjects
who classified it as human. The average grade and
rate of acceptance as written by human were signifi-
cantly higher for the Haiku written by people. How-
ever, some computer Haiku rivaled the average hu-
man poem in both measures. This is true even for
AUTO, in which both the generation and the selec-
tion processes were completely automatic. The best
computer Haiku of SEL scored better than most hu-
man Haiku in both measures.
The best computer poem in SEL was:
early dew / the water contains / teaspoons of honey
which got an average grade of 3.09 and was classi-
fied as human by 77.2% of the subjects.
At the other extreme, the computer poem (SEL):
space journey / musical instruments mythology /
of similar drugs
was classified as human by only 9% of the subjects,
and got an average grade of 2.04.
The best Haiku in the AUTO set was:
cherry tree / poisonous flowers lie / blooming
which was classified as human by 72.2% of the sub-
jects and got an average grade of 2.75.
The second human-like computer generated
Haiku in each set were:
spring bloom / showing / the sun?s pyre
(AUTO, 63.8% human) and:
blind snakes / on the wet grass / tombstoned terror
(SEL, 77.2% human).
There were, expectedly, lots of disagreements.
Poetry reading and evaluation is subjective and by
Human Poems Gaiku
AUTO avg. % classified as Human 72.5% 37.2%
avg. grade 2.86 2.11
SEL avg. % classified as Human 71.7% 44.1%
avg. grade 2.84 2.32
Table 3: Turing-test experiment results
itself (in particular for Haiku) a creative task. In ad-
dition, people have very different ideas in mind as to
a computer?s ability to do things. (One subject said,
for example, that the computer generated
holy cow / a carton of milk / seeking a church
is too stupid to be written by a computer; how-
ever, content is very strongly connected and does
not seem random). On the other end, subjects often
remarked that some of the human-authored Haiku
contained metaphors which were too obvious to be
written by a human.
Every subject was wrong at least 3 times (at least
once in every direction); every poem was wrongly-
classified at least once. Some really bad auto-poems
got a good grade here and there, while even the most
popular human poems got a low grade sometimes.
6 Discussion and Future Work
Word association norms were shown to be a useful
tool for a computational creativity task, aiding in the
creation of an automatic Haiku-generation software,
which is able to produce ?human-like? Haiku. How-
ever, associations can be used for many other tasks.
In the last decade, lexical chains are often used in
various NLP tasks such as text summarization or text
categorization; WordNet is the main resource for
detecting the cohesive relationships between words
and their relevance to a given chain (Morris and
Hirst, 1991). We believe that using word association
norms can enrich the information found in WordNet
and enable the detection of more relevant words.
Another possible application is for assisting
word-finding problem of children with specific lan-
guage impairments (SLI). A useful tactic practiced
as an assistance to retrieve a forgotten word is by
saying all words that come to mind. The NLP task,
therefore, is for a set of a given associations, recon-
struct the targeted word.
38
0 20 40 60 80 100
1.5
2
2.5
3
3.5
4
% of subjects who classified the poem as written by a human
Av
ar
eg
e 
gr
ad
e
 
 
Gaiku poems
Human poems
0 20 40 60 80 100
1.5
2
2.5
3
3.5
4
% of subjects who classified the poem as written by a human
Av
ar
eg
e 
gr
ad
e
 
 
Gaiku poems
Human poems
Figure 1: Average grades and percentages of subjects who classified poems as written by humans, for AUTO (left)
and SEL. Circles represent Haiku written by people, and stars represent machine-made Haiku
References
D.G. Blasko and D.W. Merski. 1998. Haiku poetry
and metaphorical thought: An invention to interdisci-
plinary study. Creativity Research Journal, 11.
M.A. Boden. 1998. Creativity and artificial intelligence.
Artificial Intelligence, 103(1?2).
F. de Saussure, C. Bally, A. Riedlinger, and
A. Sechehaye. 1949. Cours de linguistique gen-
erale. Payot, Paris.
B. D??az-Agudo, P. Gerva?s, and P. A. Gonza?lez-Calero.
2002. Poetry generation in COLIBRI. In Proc. of EC-
CBR.
W. Duch and M. Pilichowski. 2007. Experiments with
computational creativity. Neural Information Process-
ing, Letters and Reviews, 11(3).
P. Gervas. 2001. An expert system for the composition of
formal Spanish poetry. Journal of Knowledge-Based
Systems, 14.
R. Gilbert and J. Yoneoka. 2000. From 5-7-5 to 8-8-8:
An investigation of Japanese Haiku metrics and impli-
cations for English Haiku. Language Issues: Journal
of the Foreign Language Education Center.
D. Hardcastle. 2007. Cryptic crossword clues: Generat-
ing text with a hidden meaning BBKCS-07-04. Tech-
nical report, Birkbeck College, London.
J. Kerouac. 2004. Book of Haikus. Enitharmon Press.
H.M. Manurung, G. Ritchie, and H. Thompson. 2000.
Towards a computational model of poetry generation.
In Proc. of the AISB?00.
H.M. Manurung. 2003. An evolutionary algorithm ap-
proach to poetry generation. Ph.D. thesis, University
of Edinburgh.
S.A. Mendick. 1969. The associative basis of the cre-
ative process. Psychological Review.
N. Montfort. 2006. Natural language generation and nar-
rative variation in interactive fiction. In Proc. of Com-
putational Aesthetics Workshop at AAAI 2006, Boston.
J. Morris and G. Hirst. 1991. Lexical cohesion computed
by thesaural relations as an indicator of the structure of
text. Computational Linguistics, 17.
D.L. Nelson, C.L. Mcevoy, and T.A. Schreiber.
1998. The University of South Florida Word
Association, Rhyme, and Word Fragment Norms.
http://www.usf.edu/FreeAssociation/.
T. Pedersen, S. Patwardhan, and J. Michelizzi. 2004.
Wordnet::similarity - measuring the relatedness of
concepts. In HLT-NAACL 2004: Demonstrations.
G. Ritchie. 2001. Assessing creativity. In Proc. of
AISB?01 Symposium.
G. Ritchie. 2006. The transformational creativity hy-
pothesis. New Generation Computing, 24.
O. Rubinsten, D. Anaki, A. Henik, S. Drori, and Y. Faran.
2005. Free association norms in the Hebrew language.
Word Norms in Hebrew. (In Hebrew).
A. Sinopalnikova and P. Smrz. 2004. Word association
thesaurus as a resource for extending semantic net-
works. In Communications in Computing.
N. Tosa, H. Obara, and M. Minoh. 2008. Hitch haiku:
An interactive supporting system for composing haiku
poem. In Proc. of the 7th International Conference on
Entertainment Computing.
M. Tsan Wong and A. Hon Wai Chun. 2008. Automatic
Haiku generation using vsm. In Proc. of ACACOS?08,
April.
39
