Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 26?37,
Edinburgh, Scotland, UK, July 27?31, 2011. c?2011 Association for Computational Linguistics
Exact Decoding of Phrase-Based Translation Models
through Lagrangian Relaxation
Yin-Wen Chang
MIT CSAIL
Cambridge, MA 02139, USA
yinwen@csail.mit.edu
Michael Collins
Department of Computer Science,
Columbia University,
New York, NY 10027, USA
mcollins@cs.columbia.edu
Abstract
This paper describes an algorithm for exact
decoding of phrase-based translation models,
based on Lagrangian relaxation. The method
recovers exact solutions, with certificates of
optimality, on over 99% of test examples.
The method is much more efficient than ap-
proaches based on linear programming (LP)
or integer linear programming (ILP) solvers:
these methods are not feasible for anything
other than short sentences. We compare our
method to MOSES (Koehn et al, 2007), and
give precise estimates of the number and mag-
nitude of search errors that MOSES makes.
1 Introduction
Phrase-based models (Och et al, 1999; Koehn et
al., 2003; Koehn et al, 2007) are a widely-used
approach for statistical machine translation. The
decoding problem for phrase-based models is NP-
hard1; because of this, previous work has generally
focused on approximate search methods, for exam-
ple variants of beam search, for decoding.
This paper describes an algorithm for exact
decoding of phrase-based models, based on La-
grangian relaxation (Lemare?chal, 2001). The core
of the algorithm is a dynamic program for phrase-
based translation which is efficient, but which allows
some ill-formed translations. More specifically, the
dynamic program searches over the space of transla-
tions where exactly N words are translated (N is
the number of words in the source-language sen-
tence), but where some source-language words may
be translated zero times, or some source-language
words may be translated more than once. La-
grangian relaxation is used to enforce the constraint
1We refer here to the phrase-based models of (Koehn et al,
2003; Koehn et al, 2007), considered in this paper. Other vari-
ants of phrase-based models, which allow polynomial time de-
coding, have been proposed, see the related work section.
that each source-language word should be translated
exactly once. A subgradient algorithm is used to op-
timize the dual problem arising from the relaxation.
The first technical contribution of this paper is the
basic Lagrangian relaxation algorithm. By the usual
guarantees for Lagrangian relaxation, if this algo-
rithm converges to a solution where all constraints
are satisfied (i.e., where each word is translated ex-
actly once), then the solution is guaranteed to be
optimal. For some source-language sentences how-
ever, the underlying relaxation is loose, and the algo-
rithm will not converge. The second technical con-
tribution of this paper is a method that incrementally
adds constraints to the underlying dynamic program,
thereby tightening the relaxation until an exact solu-
tion is recovered.
We describe experiments on translation from Ger-
man to English, using phrase-based models trained
by MOSES (Koehn et al, 2007). The method
recovers exact solutions, with certificates of opti-
mality, on over 99% of test examples. On over
78% of examples, the method converges with zero
added constraints (i.e., using the basic algorithm);
99.67% of all examples converge with 9 or fewer
constraints. We compare to a linear programming
(LP)/integer linear programming (ILP) based de-
coder. Our method is much more efficient: LP or
ILP decoding is not feasible for anything other than
short sentences,2 whereas the average decoding time
for our method (for sentences of length 1-50 words)
is 121 seconds per sentence. We also compare our
method to MOSES, and give precise estimates of the
number and magnitude of search errors that MOSES
makes. Even with large beam sizes, MOSES makes
a significant number of search errors. As far as we
are aware, previous work has not successfully re-
2For example ILP decoding for sentences of lengths 11-15
words takes on average 2707.8 seconds.
26
covered exact solutions for the type of phrase-based
models used in MOSES.
2 Related Work
Lagrangian relaxation is a classical technique for
solving combinatorial optimization problems (Korte
and Vygen, 2008; Lemare?chal, 2001). Dual decom-
position, a special case of Lagrangian relaxation, has
been applied to inference problems in NLP (Koo et
al., 2010; Rush et al, 2010), and also to Markov ran-
dom fields (Wainwright et al, 2005; Komodakis et
al., 2007; Sontag et al, 2008). Earlier work on be-
lief propagation (Smith and Eisner, 2008) is closely
related to dual decomposition. Recently, Rush and
Collins (2011) describe a Lagrangian relaxation al-
gorithm for decoding for syntactic translation; the
algorithmic construction described in the current pa-
per is, however, very different in nature to this work.
Beam search stack decoders (Koehn et al, 2003)
are the most commonly used decoding algorithm
for phrase-based models. Dynamic-programming-
based beam search algorithms are discussed for both
word-based and phrase-based models by Tillmann
and Ney (2003) and Tillmann (2006).
Several works attempt exact decoding, but effi-
ciency remains an issue. Exact decoding via integer
linear programming (ILP) for IBM model 4 (Brown
et al, 1993) has been studied by Germann et al
(2001), with experiments using a bigram language
model for sentences up to eight words in length.
Riedel and Clarke (2009) have improved the effi-
ciency of this work by using a cutting-plane algo-
rithm, and experimented with sentence lengths up
to 30 words (again with a bigram LM). Zaslavskiy
et al (2009) formulate the phrase-based decoding
problem as a traveling salesman problem (TSP), and
take advantage of existing exact and approximate
approaches designed for TSP. Their translation ex-
periment uses a bigram language model and applies
an approximate algorithm for TSP. Och et al (2001)
propose an A* search algorithm for IBM model 4,
and test on sentence lengths up to 14 words. Other
work (Kumar and Byrne, 2005; Blackwood et al,
2009) has considered variants of phrase-based mod-
els with restrictions on reordering that allow exact,
polynomial time decoding, using finite-state trans-
ducers.
The idea of incrementally adding constraints to
tighten a relaxation until it is exact is a core idea in
combinatorial optimization. Previous work on this
topic in NLP or machine learning includes work on
inference in Markov random fields (Sontag et al,
2008); work that encodes constraints using finite-
state machines (Tromble and Eisner, 2006); and
work on non-projective dependency parsing (Riedel
and Clarke, 2006).
3 The Phrase-based Translation Model
This section establishes notation for phrase-based
translation models, and gives a definition of the de-
coding problem. The phrase-based model we use is
the same as that described by Koehn et al (2003), as
implemented in MOSES (Koehn et al, 2007).
The input to a phrase-based translation sys-
tem is a source-language sentence with N words,
x1x2 . . . xN . A phrase table is used to define the
set of possible phrases for the sentence: each phrase
is a tuple p = (s, t, e), where (s, t) are indices rep-
resenting a contiguous span in the source-language
sentence (we have s ? t), and e is a target-language
string consisting of a sequence of target-language
words. For example, the phrase p = (2, 5, the dog)
would specify that words x2 . . . x5 have a translation
in the phrase table as ?the dog?. Each phrase p has
a score g(p) = g(s, t, e): this score will typically
be calculated as a log-linear combination of features
(e.g., see Koehn et al (2003)).
We use s(p), t(p) and e(p) to refer to the three
components (s, t, e) of a phrase p.
The output from a phrase-based model is a
sequence of phrases y = ?p1p2 . . . pL?. We
will often refer to an output y as a derivation.
The derivation y defines a target-language transla-
tion e(y), which is formed by concatenating the
strings e(p1), e(p2), . . . , e(pL). For two consecutive
phrases pk = (s, t, e) and pk+1 = (s?, t?, e?), the dis-
tortion distance is defined as ?(t, s?) = |t+ 1? s?|.
The score for a translation is then defined as
f(y) = h(e(y))+
L?
k=1
g(pk)+
L?1?
k=1
???(t(pk), s(pk+1))
where ? ? R is often referred to as the distortion
penalty, and typically takes a negative value. The
function h(e(y)) is the score of the string e(y) under
27
a language model.3
The decoding problem is to find
argmax
y?Y
f(y)
where Y is the set of valid derivations. The set Y can
be defined as follows. First, for any derivation y =
?p1p2 . . . pL?, define y(i) to be the number of times
that the source-language word xi has been translated
in y: that is, y(i) = ?Lk=1[[s(pk) ? i ? t(pk)]],
where [[pi]] = 1 if pi is true, and 0 otherwise. Then
Y is defined as the set of finite length sequences
?p1p2 . . . pL? such that:
1. Each word in the input is translated exactly
once: that is, y(i) = 1 for i = 1 . . . N .
2. For each pair of consecutive phrases
pk, pk+1 for k = 1 . . . L ? 1, we have
?(t(pk), s(pk+1)) ? d, where d is the
distortion limit.
An exact dynamic programming algorithm for
this problem uses states (w1, w2, b, r), where
(w1, w2) is a target-language bigram that the par-
tial translation ended with, b is a bit-string denoting
which source-language words have been translated,
and r is the end position of the previous phrase (e.g.,
see Koehn et al (2003)). The bigram (w1, w2) is
needed for calculation of trigram language model
scores; r is needed to enforce the distortion limit,
and to calculate distortion costs. The bit-string b
is needed to ensure that each word is translated ex-
actly once. Since the number of possible bit-strings
is exponential in the length of sentence, exhaustive
dynamic programming is in general intractable. In-
stead, people commonly use heuristic search meth-
ods such as beam search for decoding. However,
these methods have no guarantee of returning the
highest scoring translation.
4 A Decoding Algorithm based on
Lagrangian Relaxation
We now describe a decoding algorithm for phrase-
based translation, based on Lagrangian relaxation.
3The language model score usually includes a word inser-
tion score that controls the length of translations. The relative
weights of the g(p) and h(e(y)) terms, and the value for ?, are
typically chosen using MERT training (Och, 2003).
We first describe a dynamic program for decoding
which is efficient, but which relaxes the y(i) = 1
constraints described in the previous section. We
then describe the Lagrangian relaxation algorithm,
which introduces Lagrange multipliers for each con-
straint of the form y(i) = 1, and uses a subgradient
algorithm to minimize the dual arising from the re-
laxation. We conclude with theorems describing for-
mal properties of the algorithm, and with an example
run of the algorithm.
4.1 An Efficient Dynamic Program
As described in the previous section, our goal is to
find the optimal translation y? = argmaxy?Y f(y).
We will approach this problem by defining a set Y ?
such that Y ? Y ?, and such that
argmax
y?Y ?
f(y)
can be found efficiently using dynamic program-
ming. The set Y ? omits some constraints?
specifically, the constraints that each source-
language word is translated once, i.e., that y(i) = 1
for i = 1 . . . N?that are enforced for members
of Y . In the next section we describe how to re-
introduce these constraints using Lagrangian relax-
ation. The set Y ? does, however, include a looser
constraint, namely that ?Ni=1 y(i) = N , which re-
quires that exactly N words are translated.
We now give the dynamic program that defines
Y ?. The main idea will be to replace bit-strings (as
described in the previous section) by a much smaller
number of dynamic programming states. Specifi-
cally, the states of the new dynamic program will
be tuples (w1, w2, n, l,m, r). The pair (w1, w2) is
again a target-language bigram corresponding to the
last two words in the partial translation, and the inte-
ger r is again the end position of the previous phrase.
The integer n is the number of words that have been
translated thus far in the dynamic programming al-
gorithm. The integers l and m specify a contiguous
span xl . . . xm in the source-language sentence; this
span is the last contiguous span of words that have
been translated thus far.
The dynamic program can be viewed as a
shortest-path problem in a directed graph, with
nodes in the graph corresponding to states
(w1, w2, n, l,m, r). The transitions in the
28
graph are defined as follows. For each state
(w1, w2, n, l,m, r), we consider any phrase
p = (s, t, e) with e = (e0 . . . eM?1eM ) such that:
1) ?(r, s) ? d; and 2) t < l or s > m. The former
condition states that the phrase should satisfy the
distortion limit. The latter condition requires that
there is no overlap of the new phrase?s span (s, t)
with the span (l,m). For any such phrase, we create
a transition
(w1, w2, n, l,m, r)
p=(s,t,e)?????? (w?1, w?2, n?, l?,m?, r?)
where
? (w?1, w?2) =
{
(eM?1, eM ) if M ? 2
(w2, e1) if M = 1
? n? = n+ t? s+ 1
? (l?,m?) =
?
?
?
(l, t ) if s = m+ 1
(s,m) if t = l ? 1
(s, t ) otherwise
? r? = t
The new target-language bigram (w?1, w?2) is the last
two words of the partial translation after including
phrase p. It comes from either the last two words
of e, or, if e consists of a single word, the last word
of the previous bigram, w2, and the first and only
word, e1, in e. (l?,m?) is expanded from (l,m) if
the spans (l,m) and (s, t) are adjacent. Otherwise,
(l?,m?) will be the same as (s, t).
The score of the transition is given by a sum
of the phrase translation score g(p), the language
model score, and the distortion cost ?? ?(r, s). The
trigram language model score is h(e1|w1, w2) +
h(e2|w2, e1) +
?M?2
i=1 h(ei+2|ei, ei+1), where
h(w3|w1, w2) is a trigram score (typically a log
probability plus a word insertion score).
We also include start and end states in the directed
graph. The start state is (<s>,<s>, 0, 0, 0, 0) where
<s> is the start symbol in the language model. For
each state (w1, w2, n, l,m, r), such that n = N , we
create a transition to the end state. This transition
takes the form
(w1, w2, N, l,m, r)
(N,N+1,</s>)???????????? END
For this transition, we define the score as score =
h(</s>|w1, w2); thus this transition incorporates
the end symbol </s> in the language model.
The states and transitions we have described form
a directed graph, where each path from the start state
to the end state corresponds to a sequence of phrases
p1p2 . . . pL. We define Y ? to be the full set of such
sequences. We can use the Viterbi algorithm to solve
argmaxy?Y ? f(y) by simply searching for the high-
est scoring path from the start state to the end state.
The set Y ? clearly includes derivations that are ill-
formed, in that they may include words that have
been translated 0 times, or more than 1 time. The
first line of Figure 2 shows one such derivation (cor-
responding to the translation the quality and also the
and the quality and also .). For each phrase we show
the English string (e.g., the quality) together with the
span of the phrase (e.g., 3, 6). The values for y(i) are
also shown. It can be verified that this derivation is a
valid member of Y ?. However, y(i) 6= 1 for several
values of i: for example, words 1 and 2 are trans-
lated 0 times, while word 3 is translated twice.
Other dynamic programs, and definitions of Y ?,
are possible: for example an alternative would be
to use a dynamic program with states (w1, w2, n, r).
However, including the previous contiguous span
(l,m) makes the set Y ? a closer approximation to
Y . In experiments we have found that including the
previous span (l,m) in the dynamic program leads
to faster convergence of the subgradient algorithm
described in the next section, and in general to more
stable results. This is in spite of the dynamic pro-
gram being larger; it is no doubt due to Y ? being a
better approximation of Y .
4.2 The Lagrangian Relaxation Algorithm
We now describe the Lagrangian relaxation decod-
ing algorithm for the phrase-based model. Recall
that in the previous section, we defined a set Y ? that
allowed efficient dynamic programming, and such
that Y ? Y ?. It is easy to see that Y = {y : y ?
Y ?, and ?i, y(i) = 1}. The original decoding
problem can therefore be stated as:
argmax
y?Y ?
f(y) such that ?i, y(i) = 1
We use Lagrangian relaxation (Korte and Vygen,
2008) to deal with the y(i) = 1 constraints. We
introduce Lagrange multipliers u(i) for each such
constraint. The Lagrange multipliers u(i) can take
any positive or negative value. The Lagrangian is
L(u, y) = f(y) +
?
i
u(i)(y(i)? 1)
29
Initialization: u0(i)? 0 for i = 1 . . . N
for t = 1 . . . T
yt = argmaxy?Y? L(ut?1, y)
if yt(i) = 1 for i = 1 . . . N
return yt
else
for i = 1 . . . N
ut(i) = ut?1(i)? ?t (yt(i)? 1)
Figure 1: The decoding algorithm. ?t > 0 is the step size
at the t?th iteration.
The dual objective is then
L(u) = max
y?Y ?
L(u, y).
and the dual problem is to solve
min
u
L(u).
The next section gives a number of formal results de-
scribing how solving the dual problem will be useful
in solving the original optimization problem.
We now describe an algorithm that solves the dual
problem. By standard results for Lagrangian re-
laxation (Korte and Vygen, 2008), L(u) is a con-
vex function; it can be minimized by a subgradient
method. If we define
yu = argmaxy?Y ? L(u, y)
and ?u(i) = yu(i) ? 1 for i = 1 . . . N , then ?u is
a subgradient of L(u) at u. A subgradient method
is an iterative method for minimizing L(u), which
perfoms updates ut ? ut?1??t?ut?1 where ?t > 0
is the step size for the t?th subgradient step.
Figure 1 depicts the resulting algorithm. At each
iteration, we solve
argmax
y?Y ?
(
f(y) +
?
i
u(i)(y(i)? 1)
)
=argmax
y?Y ?
(
f(y) +
?
i
u(i)y(i)
)
by the dynamic program described in the previous
section. Incorporating the ?i u(i)y(i) terms in the
dynamic program is straightforward: we simply re-
define the phrase scores as
g?(s, t, e) = g(s, t, e) +
t?
i=s
u(i)
Intuitively, each Lagrange multiplier u(i) penal-
izes or rewards phrases that translate word i; the al-
gorithm attempts to adjust the Lagrange multipliers
in such a way that each word is translated exactly
once. The updates ut(i) = ut?1(i) ? ?t(yt(i) ? 1)
will decrease the value for u(i) if yt(i) > 1, in-
crease the value for u(i) if yt(i) = 0, and leave u(i)
unchanged if yt(i) = 1.
4.3 Properties
We now give some theorems stating formal proper-
ties of the Lagrangian relaxation algorithm. These
results for Lagrangian relaxation are well known:
for completeness, we state them here. First, define
y? to be the optimal solution for our original prob-
lem:
Definition 1. y? = argmaxy?Y f(y)
Our first theorem states that the dual function pro-
vides an upper bound on the score for the optimal
translation, f(y?):
Theorem 1. For any value of u ? RN , L(u) ?
f(y?).
Proof.
L(u) = max
y?Y ?
f(y) +
?
i
u(i)(y(i)? 1)
? max
y?Y
f(y) +
?
i
u(i)(y(i)? 1)
= max
y?Y
f(y)
The first inequality follows because Y ? Y ?. The
final equality is true since any y ? Y has y(i) =
1 for all i, implying that?i u(i)(y(i)?1) = 0.
The second theorem states that under an appropri-
ate choice of the step sizes ?t, the method converges
to the minimum ofL(u). Hence we will successfully
find the tightest possible upper bound defined by the
dual L(u).
Theorem 2. For any sequence ?1, ?2, . . . If 1)
limt?? ?t ? 0; 2) ??t=1 ?t = ?, then
limt?? L(ut) = minu L(u)
Proof. See Korte and Vygen (2008).
30
Input German: dadurch ko?nnen die qualita?t und die regelma??ige postzustellung auch weiterhin sichergestellt werden .
t L(ut?1) yt(i) derivation yt
1 -10.0988 0 0 2 2 3 3 0 0 2 0 0 0 1
?
?
?
?
3, 6
the quality and
?
?
?
?
9, 9
also
?
?
?
?
6, 6
the
?
?
?
?
5, 5
and
?
?
?
?
3, 3
the
?
?
?
?
4, 6
quality and
?
?
?
?
9, 9
also
?
?
?
?
13, 13
.
?
?
?
?
2 -11.1597 0 0 1 0 0 0 1 0 0 4 1 5 1
?
?
?
?
3, 3
the
?
?
?
?
7, 7
regular
?
?
?
?
12, 12
will
?
?
?
?
10, 10
continue to
?
?
?
?
12, 12
be
?
?
?
?
10, 10
continue to
?
?
?
?
12, 12
be
?
?
?
?
10, 10
continue to
?
?
?
?
12, 12
be
?
?
?
?
10, 10
continue to
?
?
?
?
11, 13
be guaranteed .
?
?
?
?
3 -12.3742 3 3 1 2 2 0 0 0 1 0 0 0 1
?
?
?
?
1, 2
in that way ,
?
?
?
?
5, 5
and
?
?
?
?
2, 2
can
?
?
?
?
1, 1
thus
?
?
?
?
4, 4
quality
?
?
?
?
1, 2
in that way ,
?
?
?
?
3, 5
the quality and
?
?
?
?
9, 9
also
?
?
?
?
13, 13
.
?
?
?
?
4 -11.8623 0 1 0 0 0 1 1 3 3 0 3 0 1
?
?
?
?
2, 2
can
?
?
?
?
6, 7
the regular
?
?
?
?
8, 8
distribution should
?
?
?
?
9, 9
also
?
?
?
?
11, 11
ensure
?
?
?
?
8, 8
distribution should
?
?
?
?
9, 9
also
?
?
?
?
11, 11
ensure
?
?
?
?
8, 8
distribution should
?
?
?
?
9, 9
also
?
?
?
?
11, 11
ensure
?
?
?
?
13, 13
.
?
?
?
?
5 -13.9916 0 0 1 1 3 2 4 0 0 0 1 0 1
?
?
?
?
3, 3
the
?
?
?
?
7, 7
regular
?
?
?
?
5, 5
and
?
?
?
?
7, 7
regular
?
?
?
?
5, 5
and
?
?
?
?
7, 7
regular
?
?
?
?
6, 6
the
?
?
?
?
4, 4
quality
?
?
?
?
5, 7
and the regular
?
?
?
?
11, 11
ensured
?
?
?
?
13, 13
.
?
?
?
?
6 -15.6558 1 1 1 2 0 2 0 1 1 1 1 1 1
?
?
?
?
1, 2
in that way ,
?
?
?
?
3, 4
the quality of
?
?
?
?
6, 6
the
?
?
?
?
4, 4
quality of
?
?
?
?
6, 6
the
?
?
?
?
8, 8
distribution should
?
?
?
?
9, 10
continue to
?
?
?
?
11, 13
be guaranteed .
?
?
?
?
7 -16.1022 1 1 1 1 1 1 1 1 1 1 1 1 1
?
?
?
?
1, 2
in that way ,
?
?
?
?
3, 4
the quality
?
?
?
?
5, 7
and the regular
?
?
?
?
8, 8
distribution should
?
?
?
?
9, 10
continue to
?
?
?
?
11, 13
be guaranteed .
?
?
?
?
Figure 2: An example run of the algorithm in Figure 1. For each value of t we show the dual value L(ut?1), the
derivation yt, and the number of times each word is translated, yt(i) for i = 1 . . . N . For each phrase in a derivation
we show the English string e, together with the span (s, t): for example, the first phrase in the first derivation has
English string the quality and, and span (3, 6). At iteration 7 we have yt(i) = 1 for i = 1 . . . N , and the translation is
returned, with a guarantee that it is optimal.
Our final theorem states that if at any iteration the
algorithm finds a solution yt such that yt(i) = 1 for
i = 1 . . . N , then this is guaranteed to be the optimal
solution to our original problem. First, define
Definition 2. yu = argmaxy?Y ? L(u, y).
We then have the theorem
Theorem 3. If ? u, s.t. yu(i) = 1 for i = 1 . . . N ,
then f(yu) = f(y?), i.e. yu is optimal.
Proof. We have
L(u) = max
y?Y ?
f(y) +
?
i
u(i)(y(i)? 1)
= f(yu) +
?
i
u(i)(yu(i)? 1)
= f(yu)
The second equality is true because of the defini-
tion of yu. The third equality follows because by
assumption yu(i) = 1 for i = 1 . . . N . Because
L(u) = f(yu) and L(u) ? f(y?) for all u, we have
f(yu) ? f(y?). But y? = argmaxy?Y f(y), and
yu ? Y , hence we must also have f(yu) ? f(y?). It
follows that f(yu) = f(y?).
In some cases, however, the algorithm in Figure 1
may not return a solution yt such that yt(i) = 1
for all i. There could be two reasons for this. In
the first case, we may not have run the algorithm
for enough iterations T to see convergence. In the
second case, the underlying relaxation may not be
tight, in that there may not be any settings u for the
Lagrange multipliers such that yu(i) = 1 for all i.
Section 5 describes a method for tightening
the underlying relaxation by introducing hard con-
straints (of the form y(i) = 1 for selected values of
i). We will see that this method is highly effective
in tightening the relaxation until the algorithm con-
verges to an optimal solution.
4.4 An Example of the Algorithm
Figure 2 shows an example of how the algorithm
works when translating a German sentence into an
English sentence. After the first iteration, there are
words that have been translated two or three times,
and words that have not been translated. At each
iteration, the Lagrangian multipliers are updated to
encourage each word to be translated once. On
this example, the algorithm converges to a solution
where all words are translated exactly once, and the
solution is guaranteed to be optimal.
5 Tightening the Relaxation
In some cases the algorithm in Figure 1 will not
converge to y(i) = 1 for i = 1 . . . N because
the underlying relaxation is not tight. We now de-
scribe a method that incrementally tightens the La-
grangian relaxation algorithm until it provides an ex-
act answer. In cases that do not converge, we in-
troduce hard constraints to force certain words to be
translated exactly once in the dynamic programming
solver. In experiments we show that typically only a
31
Optimize(C, u)
while (dual value still improving)
y? = argmaxy?Y?C L(u, y)if y?(i) = 1 for i = 1 . . . N return y?
else for i = 1 . . . N
u(i) = u(i)? ? (y?(i)? 1)
count(i) = 0 for i = 1 . . . N
for k = 1 . . .K
y? = argmaxy?Y?C L(u, y)if y?(i) = 1 for i = 1 . . . N return y?
else for i = 1 . . . N
u(i) = u(i)? ? (y?(i)? 1)
count(i) = count(i) + [[y?(i) 6= 1]]
Let C? = set of G i?s that have the largest value for
count(i), that are not in C, and that are not adjacent to
each other
return Optimize(C ? C?, u)
Figure 3: A decoding algorithm with incremental addi-
tion of constraints. The function Optimize(C, u) is a re-
cursive function, which takes as input a set of constraints
C, and a vector of Lagrange multipliers, u. The initial
call to the algorithm is with C = ?, and u = 0. ? > 0 is
the step size. In our experiments, the step size decreases
each time the dual value increases from one iteration to
the next; see Appendix A.
few constraints are necessary.
Given a set C ? {1, 2, . . . , N}, we define
Y ?C = {y : y ? Y ?, and ? i ? C, y(i) = 1}
Thus Y ?C is a subset of Y ?, formed by adding hard
constraints of the form y(i) = 1 to Y ?. Note that Y ?C
remains as a superset of Y , which enforces y(i) =
1 for all i. Finding argmaxy?Y ?C f(y) can againbe achieved using dynamic programming, with the
number of dynamic programming states increased
by a factor of 2|C|: dynamic programming states of
the form (w1, w2, n, l,m, r) are replaced by states
(w1, w2, n, l,m, r, bC) where bC is a bit-string of
length |C|, which records which words in the set C
have or haven?t been translated in a hypothesis (par-
tial derivation). Note that if C = {1 . . . N}, we have
Y ?C = Y , and the dynamic program will correspond
to exhaustive dynamic programming.
We can again run a Lagrangian relaxation algo-
rithm, using the set Y ?C in place of Y ?. We will use
Lagrange multipliers u(i) to enforce the constraints
y(i) = 1 for i /? C. Our goal will be to find a
small set of constraints C, such that Lagrangian re-
laxation will successfully recover an optimal solu-
tion. We will do this by incrementally adding el-
ements to C; that is, by incrementally adding con-
straints that tighten the relaxation.
The intuition behind our approach is as follows.
Say we run the original algorithm, with the set Y ?,
for several iterations, so that L(u) is close to con-
vergence (i.e., L(u) is close to its minimal value).
However, assume that we have not yet generated a
solution yt such that yt(i) = 1 for all i. In this case
we have some evidence that the relaxation may not
be tight, and that we need to add some constraints.
The question is, which constraints to add? To an-
swer this question, we run the subgradient algorithm
for K more iterations (e.g., K = 10), and at each it-
eration track which constraints of the form y(i) = 1
are violated. We then choose C to be the G con-
straints (e.g., G = 3) that are violated most often
during the K additional iterations, and are not ad-
jacent to each other. We recursively call the algo-
rithm, replacing Y ? by Y ?C ; the recursive call may
then return an exact solution, or alternatively again
add more constraints and make a recursive call.4
Figure 3 depicts the resulting algorithm. We ini-
tially make a call to the algorithm Optimize(C, u)
with C equal to the empty set (i.e., no hard con-
straints), and with u(i) = 0 for all i. In an initial
phase the algorithm runs subgradient steps, while
the dual is still improving. In a second step, if a so-
lution has not been found, the algorithm runs for K
more iterations, thereby choosing G additional con-
straints, then recursing.
If at any stage the algorithm finds a solution y?
such that y?(i) = 1 for all i, then this is the so-
lution to our original problem, argmaxy?Y f(y).
This follows because for any C ? {1 . . . N} we
have Y ? Y ?C ; hence the theorems in section 4.3 go
through for Y ?C in place of Y ?, with trivial modifica-
tions. Note also that the algorithm is guaranteed to
eventually find the optimal solution, because even-
tually C = {1 . . . N}, and Y = Y ?C .
4Formal justification for the method comes from the rela-
tionship between Lagrangian relaxation and linear program-
ming relaxations. In cases where the relaxation is not tight,
the subgradient method will essentially move between solu-
tions whose convex combination form a fractional solution to
an underlying LP relaxation (Nedic? and Ozdaglar, 2009). Our
method eliminates the fractional solution through the introduc-
tion of hard constraints.
32
# iter. 1-10 words 11-20 words 21-30 words 31-40 words 41-50 words All sentences
0-7 166 (89.7 %) 219 (39.2 %) 34 ( 6.0 %) 2 ( 0.6 %) 0 ( 0.0 %) 421 (23.1 %) 23.1 %
8-15 17 ( 9.2 %) 187 (33.5 %) 161 (28.4 %) 30 ( 8.6 %) 3 ( 1.8 %) 398 (21.8 %) 44.9 %
16-30 1 ( 0.5 %) 93 (16.7 %) 208 (36.7 %) 112 (32.3 %) 22 ( 13.1 %) 436 (23.9 %) 68.8 %
31-60 1 ( 0.5 %) 52 ( 9.3 %) 105 (18.6 %) 99 (28.5 %) 62 ( 36.9 %) 319 (17.5 %) 86.3 %
61-120 0 ( 0.0 %) 7 ( 1.3 %) 54 ( 9.5 %) 89 (25.6 %) 45 ( 26.8 %) 195 (10.7 %) 97.0 %
121-250 0 ( 0.0 %) 0 ( 0.0 %) 4 ( 0.7 %) 14 ( 4.0 %) 31 ( 18.5 %) 49 ( 2.7 %) 99.7 %
x 0 ( 0.0 %) 0 ( 0.0 %) 0 ( 0.0 %) 1 ( 0.3 %) 5 ( 3.0 %) 6 ( 0.3 %) 100.0 %
Table 1: Table showing the number of iterations taken for the algorithm to converge. x indicates sentences that fail to
converge after 250 iterations. 97% of the examples converge within 120 iterations.
# cons. 1-10 words 11-20 words 21-30 words 31-40 words 41-50 words All sentences
0-0 183 (98.9 %) 511 (91.6 %) 438 (77.4 %) 222 (64.0 %) 82 ( 48.8 %) 1,436 (78.7 %) 78.7 %
1-3 2 ( 1.1 %) 45 ( 8.1 %) 94 (16.6 %) 87 (25.1 %) 50 ( 29.8 %) 278 (15.2 %) 94.0 %
4-6 0 ( 0.0 %) 2 ( 0.4 %) 27 ( 4.8 %) 24 ( 6.9 %) 19 ( 11.3 %) 72 ( 3.9 %) 97.9 %
7-9 0 ( 0.0 %) 0 ( 0.0 %) 7 ( 1.2 %) 13 ( 3.7 %) 12 ( 7.1 %) 32 ( 1.8 %) 99.7 %
x 0 ( 0.0 %) 0 ( 0.0 %) 0 ( 0.0 %) 1 ( 0.3 %) 5 ( 3.0 %) 6 ( 0.3 %) 100.0 %
Table 2: Table showing the number of constraints added before convergence of the algorithm in Figure 3, broken down by sentence
length. Note that a maximum of 3 constraints are added at each recursive call, but that fewer than 3 constraints are added in cases
where fewer than 3 constraints have count(i) > 0. x indicates the sentences that fail to converge after 250 iterations. 78.7% of the
examples converge without adding any constraints.
The remaining question concerns the ?dual still
improving? condition; i.e., how to determine that the
first phase of the algorithm should terminate. We do
this by recording the first and second best dual val-
ues L(u?) and L(u??) in the sequence of Lagrange
multipliers u1, u2, . . . generated by the algorithm.
Suppose that L(u??) first occurs at iteration t??. If
L(u?)?L(u??)
t?t?? < , we say that the dual value does notdecrease enough. The value for  is a parameter of
the approach: in experiments we used  = 0.002.
See the supplementary material for this submis-
sion for an example run of the algorithm.
When C 6= ?, A* search can be used for de-
coding, with the dynamic program for Y ? provid-
ing admissible estimates for the dynamic program
for Y ?C . Experiments show that A* gives significant
improvements in efficiency. The supplementary ma-
terial contains a full description of the A* algorithm.
6 Experiments
In this section, we present experimental results to
demonstrate the efficiency of the decoding algo-
rithm. We compare to MOSES (Koehn et al, 2007),
a phrase-based decoder using beam search, and to
a general purpose integer linear programming (ILP)
solver, which solves the problem exactly.
The experiments focus on translation from Ger-
man to English, using the Europarl data (Koehn,
2005). We tested on 1,824 sentences of length at
most 50 words. The experiments use the algorithm
shown in Figure 3. We limit the algorithm to a max-
imum of 250 iterations and a maximum of 9 hard
constraints. The distortion limit d is set to be four,
and we prune the phrase translation table to have 10
English phrases per German phrase.
Our method finds exact solutions on 1,818 out
of 1,824 sentences (99.67%). (6 examples do not
converge within 250 iterations.) Table 1 shows the
number of iterations required for convergence, and
Table 2 shows the number of constraints required
for convergence, broken down by sentence length.
In 1,436/1,818 (78.7%) sentences, the method con-
verges without adding hard constraints to tighten the
relaxation. For sentences with 1-10 words, the vast
majority (183 out of 185 examples) converge with
0 constraints added. As sentences get longer, more
constraints are often required. However most exam-
ples converge with 9 or fewer constraints.
Table 3 shows the average times for decoding,
broken down by sentence length, and by the number
of constraints that are added. As expected, decod-
ing times increase as the length of sentences, and
the number of constraints required, increase. The
average run time across all sentences is 120.9 sec-
onds. Table 3 also shows the run time of the method
without the A* algorithm for decoding. The A* al-
gorithm gives significant reductions in runtime.
33
# cons. 1-10 words 11-20 words 21-30 words 31-40 words 41-50 words All sentencesA* w/o A* w/o A* w/o A* w/o A* w/o A* w/o
0-0 0.8 0.8 9.7 10.7 47.0 53.7 153.6 178.6 402.6 492.4 64.6 76.1
1-3 2.4 2.9 23.2 28.0 80.9 102.3 277.4 360.8 686.0 877.7 241.3 309.7
4-6 0.0 0.0 28.2 38.8 111.7 163.7 309.5 575.2 1,552.8 1,709.2 555.6 699.5
7-9 0.0 0.0 0.0 0.0 166.1 500.4 361.0 1,467.6 1,167.2 3,222.4 620.7 1,914.1
mean 0.8 0.9 10.9 12.3 57.2 72.6 203.4 299.2 679.9 953.4 120.9 168.9
median 0.7 0.7 8.9 9.9 48.3 54.6 169.7 202.6 484.0 606.5 35.2 40.0
Table 3: The average time (in seconds) for decoding using the algorithm in Figure 3, with and without A* algorithm, broken down
by sentence length and the number of constraints that are added. A* indicates speeding up using A* search; w/o denotes without
using A*.
method ILP LP
set length mean median mean median % frac.
Y ?? 1-10 275.2 132.9 10.9 4.4 12.4 %11-15 2,707.8 1,138.5 177.4 66.1 40.8 %
16-20 20,583.1 3,692.6 1,374.6 637.0 59.7 %
Y ? 1-10 257.2 157.7 18.4 8.9 1.1 %
11-15 3607.3 1838.7 476.8 161.1 3.0 %
Table 4: Average and median time of the LP/ILP solver (in
seconds). % frac. indicates how often the LP gives a fractional
answer. Y ? indicates the dynamic program using set Y ? as de-
fined in Section 4.1, and Y ?? indicates the dynamic program us-
ing states (w1, w2, n, r). The statistics for ILP for length 16-20
are based on 50 sentences.
6.1 Comparison to an LP/ILP solver
To compare to a linear programming (LP) or inte-
ger linear programming (ILP) solver, we can im-
plement the dynamic program (search over the set
Y ?) through linear constraints, with a linear ob-
jective. The y(i) = 1 constraints are also lin-
ear. Hence we can encode our relaxation within an
LP or ILP. Having done this, we tested the result-
ing LP or ILP using Gurobi, a high-performance
commercial grade solver. We also compare to
an LP or ILP where the dynamic program makes
use of states (w1, w2, n, r)?i.e., the span (l,m) is
dropped, making the dynamic program smaller. Ta-
ble 4 shows the average time taken by the LP/ILP
solver. Both the LP and the ILP require very long
running times on these shorter sentences, and run-
ning times on longer sentences are prohibitive. Our
algorithm is more efficient because it leverages the
structure of the problem, by directly using a combi-
natorial algorithm (dynamic programming).
6.2 Comparison to MOSES
We now describe comparisons to the phrase-based
decoder implemented in MOSES. MOSES uses
beam search to find approximate solutions.
The distortion limit described in section 3 is the
same as that in Koehn et al (2003), and is the same
as that described in the user manual for MOSES
(Koehn et al, 2007). However, a complicating fac-
tor for our comparisons is that MOSES uses an ad-
ditional distortion constraint, not documented in the
manual, which we describe here.5 We call this con-
straint the gap constraint. We will show in experi-
ments that without the gap constraint, MOSES fails
to produce translations on many examples. In our
experiments we will compare to MOSES both with
and without the gap constraint (in the latter case, we
discard examples where MOSES fails).
We now describe the gap constraint. For a se-
quence of phrases p1, . . . , pk define ?(p1 . . . pk) to
be the index of the left-most source-language word
not translated in this sequence. For example, if
the bit-string for p1 . . . pk is 111001101000, then
?(p1 . . . pk) = 4. A sequence of phrases p1 . . . pL
satisfies the gap constraint if and only if for k =
2 . . . L, |t(pk) + 1 ? ?(p1 . . . pk)| ? d, where d is
the distortion limit. We will call MOSES without
this restriction MOSES-nogc, and MOSES with this
restriction MOSES-gc.
Results for MOSES-nogc Table 5 shows the
number of examples where MOSES-nogc fails to
give a translation, and the number of search errors
for those cases where it does give a translation, for
a range of beam sizes. A search error is defined as a
case where our algorithm produces an exact solution
that has higher score than the output from MOSES-
nogc. The number of search errors is significant,
even for large beam sizes.
5Personal communication from Philipp Koehn; see also the
software for MOSES.
34
Beam size Fails # search errors percentage
100 650/1,818 214/1,168 18.32 %
200 531/1,818 207/1,287 16.08 %
1000 342/1,818 115/1,476 7.79 %
10000 169/1,818 68/1,649 4.12 %
Table 5: Table showing the number of examples where
MOSES-nogc fails to give a translation, and the num-
ber/percentage of search errors for cases where it does give a
translation.
Diff. MOSES-gc MOSES-gc MOSES-nogcs =100 s =200 s=1000
0.000 ? 0.125 66 (24.26%) 65 (24.07%) 32 ( 27.83%)
0.125 ? 0.250 59 (21.69%) 58 (21.48%) 25 ( 21.74%)
0.250 ? 0.500 65 (23.90%) 65 (24.07%) 25 ( 21.74%)
0.500 ? 1.000 49 (18.01%) 49 (18.15%) 23 ( 20.00%)
1.000 ? 2.000 31 (11.40%) 31 (11.48%) 5 ( 4.35%)
2.000 ? 4.000 2 ( 0.74%) 2 ( 0.74%) 3 ( 2.61%)
4.000 ?13.000 0 ( 0.00%) 0 ( 0.00%) 2 ( 1.74%)
Table 6: Table showing statistics for the difference between the
translation score from MOSES, and from the optimal deriva-
tion, for those sentences where a search error is made. For
MOSES-gc we include cases where the translation produced by
our system is not reachable by MOSES-gc. The average score
of the optimal derivations is -23.4.
Results for MOSES-gc MOSES-gc uses the gap
constraint, and thus in some cases our decoder will
produce derivations which MOSES-gc cannot reach.
Among the 1,818 sentences where we produce a so-
lution, there are 270 such derivations. For the re-
maining 1,548 sentences, MOSES-gc makes search
errors on 2 sentences (0.13%) when the beam size is
100, and no search errors when the beam size is 200,
1,000, or 10,000.
Table 6 shows statistics for the magnitude of
the search errors that MOSES-gc and MOSES-nogc
make.
BLEU Scores Finally, table 7 gives BLEU scores
(Papineni et al, 2002) for decoding using MOSES
and our method. The BLEU scores under the two
decoders are almost identical; hence while MOSES
makes a significant proportion of search errors, these
search errors appear to be benign in terms of their
impact on BLEU scores, at least for this particular
translation model. Future work should investigate
why this is the case, and whether this applies to other
models and language pairs.
7 Conclusions
We have described an exact decoding algorithm for
phrase-based translation models, using Lagrangian
type of Moses beam size # sents Moses our method
MOSES-gc
100 1,818 24.4773 24.5395
200 1,818 24.4765 24.5395
1,000 1,818 24.4765 24.5395
10,000 1,818 24.4765 24.5395
MOSES-nogc
100 1,168 27.3546 27.3249
200 1,287 27.0591 26.9907
1,000 1,476 26.5734 26.6128
10,000 1,649 25.6531 25.6620
Table 7: BLEU score comparisons. We consider only
those sentences where both decoders produce a transla-
tion.
relaxation. The algorithmic construction we have
described may also be useful in other areas of NLP,
for example natural language generation. Possi-
ble extensions to the approach include methods that
incorporate the Lagrangian relaxation formulation
within learning algorithms for statistical MT: we see
this as an interesting avenue for future research.
A Step Size
Similar to Koo et al (2010), we set the step size at
the t?th iteration to be ?t = 1/(1 + ?t), where ?t is
the number of times that L(u(t?)) > L(u(t??1)) for
all t? ? t. Thus the step size decreases each time the
dual value increases from one iteration to the next.
Acknowledgments Yin-Wen Chang and Michael
Collins were supported under the GALE program
of the Defense Advanced Research Projects Agency,
Contract No. HR0011-06-C-0022. Michael Collins
was also supported by NSF grant IIS-0915176.
References
Graeme Blackwood, Adria` de Gispert, Jamie Brunning,
and William Byrne. 2009. Large-scale statistical
machine translation with weighted finite state trans-
ducers. In Proceeding of the 2009 conference on
Finite-State Methods and Natural Language Process-
ing: Post-proceedings of the 7th International Work-
shop FSMNLP 2008, pages 39?49, Amsterdam, The
Netherlands, The Netherlands. IOS Press.
Peter F. Brown, Vincent J. Della Pietra, Stephen A. Della
Pietra, and Robert L. Mercer. 1993. The mathematics
of statistical machine translation: Parameter estima-
tion. Computational Linguistics, 19:263?311, June.
Ulrich Germann, Michael Jahr, Kevin Knight, Daniel
Marcu, and Kenji Yamada. 2001. Fast decoding and
optimal decoding for machine translation. In Proceed-
35
ings of the 39th Annual Meeting on Association for
Computational Linguistics, ACL ?01, pages 228?235.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Proceed-
ings of the 2003 Conference of the North American
Chapter of the Association for Computational Linguis-
tics on Human Language Technology, NAACL ?03,
pages 48?54.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondr?ej Bojar, Alexandra Con-
stantin, and Evan Herbst. 2007. Moses: Open source
toolkit for statistical machine translation. In Proceed-
ings of the 45th Annual Meeting of the ACL on Inter-
active Poster and Demonstration Sessions, ACL ?07,
pages 177?180.
Philipp Koehn. 2005. Europarl: A parallel corpus for
statistical machine translation. In Proceedings of the
MT Summit.
Nikos Komodakis, Nikos Paragios, and Georgios Tziri-
tas. 2007. MRF optimization via dual decomposition:
Message-passing revisited. In Proceedings of the 11th
International Conference on Computer Vision.
Terry Koo, Alexander M. Rush, Michael Collins, Tommi
Jaakkola, and David Sontag. 2010. Dual decompo-
sition for parsing with non-projective head automata.
In Proceedings of the 2010 Conference on Empiri-
cal Methods in Natural Language Processing, pages
1288?1298, Cambridge, MA, October. Association for
Computational Linguistics.
Bernhard Korte and Jens Vygen. 2008. Combinatorial
Optimization: Theory and Application. Springer Ver-
lag.
Shankar Kumar and William Byrne. 2005. Local phrase
reordering models for statistical machine translation.
In Proceedings of the conference on Human Language
Technology and Empirical Methods in Natural Lan-
guage Processing, HLT ?05, pages 161?168.
Claude Lemare?chal. 2001. Lagrangian Relaxation.
In Computational Combinatorial Optimization, Op-
timal or Provably Near-Optimal Solutions [based
on a Spring School], pages 112?156, London, UK.
Springer-Verlag.
Angelia Nedic? and Asuman Ozdaglar. 2009. Approxi-
mate primal solutions and rate analysis for dual sub-
gradient methods. SIAM Journal on Optimization,
19(4):1757?1780.
Franz Josef Och, Christoph Tillmann, Hermann Ney, and
Lehrstuhl Fiir Informatik. 1999. Improved alignment
models for statistical machine translation. In Pro-
ceedings of the Joint SIGDAT Conference on Empiri-
cal Methods in Natural Language Processing and Very
Large Corpora, pages 20?28.
Franz Josef Och, Nicola Ueffing, and Hermann Ney.
2001. An efficient A* search algorithm for statisti-
cal machine translation. In Proceedings of the work-
shop on Data-driven methods in machine translation -
Volume 14, DMMT ?01, pages 1?8, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Franz Josef Och. 2003. Minimum error rate training
in statistical machine translation. In Proceedings of
the 41st Annual Meeting on Association for Computa-
tional Linguistics, ACL ?03, pages 160?167.
Kishore Papineni, Salim Roukos, Todd Ward, and
Wei Jing Zhu. 2002. Bleu: a method for automatic
evaluation of machine translation. In Proceedings of
ACL 2002.
Sebastian Riedel and James Clarke. 2006. Incremental
integer linear programming for non-projective depen-
dency parsing. In Proceedings of the 2006 Conference
on Empirical Methods in Natural Language Process-
ing, EMNLP ?06, pages 129?137, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Sebastian Riedel and James Clarke. 2009. Revisiting
optimal decoding for machine translation IBM model
4. In Proceedings of Human Language Technologies:
The 2009 Annual Conference of the North American
Chapter of the Association for Computational Lin-
guistics, Companion Volume: Short Papers, NAACL-
Short ?09, pages 5?8, Stroudsburg, PA, USA. Associ-
ation for Computational Linguistics.
Alexander M. Rush and Michael Collins. 2011. Exact
decoding of syntactic translation models through La-
grangian relaxation. In Proceedings of ACL.
Alexander M Rush, David Sontag, Michael Collins, and
Tommi Jaakkola. 2010. On dual decomposition and
linear programming relaxations for natural language
processing. In Proceedings of the 2010 Conference on
Empirical Methods in Natural Language Processing,
pages 1?11, Cambridge, MA, October. Association for
Computational Linguistics.
David A. Smith and Jason Eisner. 2008. Dependency
parsing by belief propagation. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing, EMNLP ?08, pages 145?156.
David Sontag, Talya Meltzer, Amir Globerson, Tommi
Jaakkola, and Yair Weiss. 2008. Tightening LP relax-
ations for MAP using message passing. In Proceed-
ings of the 24th Conference on Uncertainty in Artifi-
cial Intelligence, pages 503?510.
Christoph Tillmann and Hermann Ney. 2003. Word re-
ordering and a dynamic programming beam search al-
gorithm for statistical machine translation. Computa-
tional Linguistics, 29:97?133, March.
Christoph Tillmann. 2006. Efficient dynamic pro-
gramming search algorithms for phrase-based SMT.
36
In Proceedings of the Workshop on Computationally
Hard Problems and Joint Inference in Speech and Lan-
guage Processing, CHSLP ?06, pages 9?16.
Roy W. Tromble and Jason Eisner. 2006. A fast
finite-state relaxation method for enforcing global con-
straints on sequence decoding. In Proceedings of
the main conference on Human Language Technology
Conference of the North American Chapter of the As-
sociation of Computational Linguistics, HLT-NAACL
?06, pages 423?430, Stroudsburg, PA, USA. Associa-
tion for Computational Linguistics.
Martin Wainwright, Tommi Jaakkola, and Alan Will-
sky. 2005. MAP estimation via agreement on
trees: Message-passing and linear programming. In
IEEE Transactions on Information Theory, volume 51,
pages 3697?3717.
Mikhail Zaslavskiy, Marc Dymetman, and Nicola Can-
cedda. 2009. Phrase-based statistical machine transla-
tion as a traveling salesman problem. In Proceedings
of the Joint Conference of the 47th Annual Meeting of
the ACL and the 4th International Joint Conference on
Natural Language Processing of the AFNLP: Volume
1 - Volume 1, ACL ?09, pages 333?341, Stroudsburg,
PA, USA. Association for Computational Linguistics.
37
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 210?221,
Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational Linguistics
Optimal Beam Search for Machine Translation
Alexander M. Rush Yin-Wen Chang
MIT CSAIL,
Cambridge, MA 02139, USA
{srush, yinwen}@csail.mit.edu
Michael Collins
Department of Computer Science,
Columbia University,
New York, NY 10027, USA
mcollins@cs.columbia.edu
Abstract
Beam search is a fast and empirically effective
method for translation decoding, but it lacks
formal guarantees about search error. We de-
velop a new decoding algorithm that combines
the speed of beam search with the optimal cer-
tificate property of Lagrangian relaxation, and
apply it to phrase- and syntax-based transla-
tion decoding. The new method is efficient,
utilizes standard MT algorithms, and returns
an exact solution on the majority of transla-
tion examples in our test data. The algorithm
is 3.5 times faster than an optimized incremen-
tal constraint-based decoder for phrase-based
translation and 4 times faster for syntax-based
translation.
1 Introduction
Beam search (Koehn et al, 2003) and cube prun-
ing (Chiang, 2007) have become the de facto decod-
ing algorithms for phrase- and syntax-based trans-
lation. The algorithms are central to large-scale
machine translation systems due to their efficiency
and tendency to produce high-quality translations
(Koehn, 2004; Koehn et al, 2007; Dyer et al, 2010).
However despite practical effectiveness, neither al-
gorithm provides any bound on possible decoding
error.
In this work we present a variant of beam search
decoding for phrase- and syntax-based translation.
The motivation is to exploit the effectiveness and ef-
ficiency of beam search, but still maintain formal
guarantees. The algorithm has the following bene-
fits:
? In theory, it can provide a certificate of optimal-
ity; in practice, we show that it produces opti-
mal hypotheses, with certificates of optimality,
on the vast majority of examples.
? It utilizes well-studied algorithms and extends
off-the-shelf beam search decoders.
? Empirically it is very fast, results show that it is
3.5 times faster than an optimized incremental
constraint-based solver.
While our focus is on fast decoding for machine
translation, the algorithm we present can be applied
to a variety of dynamic programming-based decod-
ing problems. The method only relies on having a
constrained beam search algorithm and a fast uncon-
strained search algorithm. Similar algorithms exist
for many NLP tasks.
We begin in Section 2 by describing constrained
hypergraph search and showing how it generalizes
translation decoding. Section 3 introduces a variant
of beam search that is, in theory, able to produce
a certificate of optimality. Section 4 shows how to
improve the effectiveness of beam search by using
weights derived from Lagrangian relaxation. Sec-
tion 5 puts everything together to derive a fast beam
search algorithm that is often optimal in practice.
Experiments compare the new algorithm with
several variants of beam search, cube pruning, A?
search, and relaxation-based decoders on two trans-
lation tasks. The optimal beam search algorithm is
able to find exact solutions with certificates of opti-
mality on 99% of translation examples, significantly
more than other baselines. Additionally the optimal
210
beam search algorithm is much faster than other ex-
act methods.
2 Background
The focus of this work is decoding for statistical ma-
chine translation. Given a source sentence, the goal
is to find the target sentence that maximizes a com-
bination of translation model and language model
scores. In order to analyze this decoding problem,
we first abstract away from the specifics of transla-
tion into a general form, known as a hypergraph. In
this section, we describe the hypergraph formalism
and its relation to machine translation.
2.1 Notation
Throughout the paper, scalars and vectors are writ-
ten in lowercase, matrices are written in uppercase,
and sets are written in script-case, e.g. X . All vec-
tors are assumed to be column vectors. The function
?(j) yields an indicator vector with ?(j)j = 1 and
?(j)i = 0 for all i 6= j.
2.2 Hypergraphs and Search
A directed hypergraph is a pair (V, E) where V =
{1 . . . |V|} is a set of vertices, and E is a set of di-
rected hyperedges. Each hyperedge e ? E is a tuple?
?v2, . . . , v|v|?, v1
?
where vi ? V for i ? {1 . . . |v|}.
The head of the hyperedge is h(e) = v1. The tail
of the hyperedge is the ordered sequence t(e) =
?v2, . . . , v|v|?. The size of the tail |t(e)| may vary
across different hyperedges, but |t(e)| ? 1 for all
edges and is bounded by a constant. A directed
graph is a directed hypergraph with |t(e)| = 1 for
all edges e ? E .
Each vertex v ? V is either a non-terminal or a
terminal in the hypergraph. The set of non-terminals
is N = {v ? V : h(e) = v for some e ? E}. Con-
versely, the set of terminals is defined as T = V\N .
All directed hypergraphs used in this work are
acyclic: informally this implies that no hyperpath (as
defined below) contains the same vertex more than
once (see Martin et al (1990) for a full definition).
Acyclicity implies a partial topological ordering of
the vertices. We also assume there is a distinguished
root vertex 1 where for all e ? E , 1 6? t(e).
Next we define a hyperpath as x ? {0, 1}|E| where
x(e) = 1 if hyperedge e is used in the hyperpath,
procedure BESTPATHSCORE(?, ? )
pi[v]? 0 for all v ? T
for e ? E in topological order do
??v2, . . . , v|v|?, v1? ? e
s? ?(e) +
|v|?
i=2
pi[vi]
if s > pi[v1] then pi[v1]? s
return pi[1] + ?
Figure 1: Dynamic programming algorithm for uncon-
strained hypergraph search. Note that this version only
returns the highest score: maxx?X ?>x+ ? . The optimal
hyperpath can be found by including back-pointers.
x(e) = 0 otherwise. The set of valid hyperpaths is
defined as
X =
?
?????
?????
x :
?
e?E:h(e)=1
x(e) = 1,
?
e:h(e)=v
x(e) =
?
e:v?t(e)
x(e) ? v ? N \ {1}
?
?????
?????
The first problem we consider is unconstrained hy-
pergraph search. Let ? ? R|E| be the weight vector
for the hypergraph and let ? ? R be a weight offset.1
The unconstrained search problem is to find
max
x?X
?
e?E
?(e)x(e) + ? = max
x?X
?>x+ ?
This maximization can be computed for any
weights and directed acyclic hypergraph in time
O(|E|) using dynamic programming. Figure 1
shows this algorithm which is simply a version of
the CKY algorithm.
Next consider a variant of this problem: con-
strained hypergraph search. Constraints will be nec-
essary for both phrase- and syntax-based decoding.
In phrase-based models, the constraints will ensure
that each source word is translated exactly once. In
syntax-based models, the constraints will be used to
intersect a translation forest with a language model.
In the constrained hypergraph problem, hyper-
paths must fulfill additional linear hyperedge con-
straints. Define the set of constrained hyperpaths as
X ? = {x ? X : Ax = b}
1The purpose of the offset will be clear in later sections. For
this section, the value of ? can be taken as 0.
211
where we have a constraint matrix A ? R|b|?|E|
and vector b ? R|b| encoding |b| constraints.
The optimal constrained hyperpath is x? =
arg maxx?X ? ?>x+ ? .
Note that the constrained hypergraph search prob-
lem may be NP-Hard. Crucially this is true even
when the corresponding unconstrained search prob-
lem is solvable in polynomial time. For instance,
phrase-based decoding is known to be NP-Hard
(Knight, 1999), but we will see that it can be ex-
pressed as a polynomial-sized hypergraph with con-
straints.
Example: Phrase-Based Machine Translation
Consider translating a source sentencew1 . . . w|w| to
a target sentence in a language with vocabulary ?. A
simple phrase-based translation model consists of a
tuple (P, ?, ?) with
? P; a set of pairs (q, r) where q1 . . . q|q| is a se-
quence of source-language words and r1 . . . r|r|
is a sequence of target-language words drawn
from the target vocabulary ?.
? ? : R|P|; parameters for the translation model
mapping each pair in P to a real-valued score.
? ? : R|???|; parameters of the language model
mapping a bigram of target-language words to
a real-valued score.
The translation decoding problem is to find the
best derivation for a given source sentence. A
derivation consists of a sequence of phrases p =
p1 . . . pn. Define a phrase as a tuple (q, r, j, k)
consisting of a span in the source sentence q =
wj . . . wk and a sequence of target words r1 . . . r|r|,
with (q, r) ? P . We say the source words wj . . . wk
are translated to r.
The score of a derivation, f(p), is the sum of the
translation score of each phrase plus the language
model score of the target sentence
f(p) =
n?
i=1
?(q(pi), r(pi)) +
|u|+1?
i=0
?(ui?1, ui)
where u is the sequence of words in ? formed
by concatenating the phrases r(p1) . . . r(pn), with
boundary cases u0 = <s> and u|u|+1 = </s>.
Crucially for a derivation to be valid it must sat-
isfy an additional condition: it must translate every
source word exactly once. The decoding problem
for phrase-based translation is to find the highest-
scoring derivation satisfying this property.
We can represent this decoding problem as a con-
strained hypergraph using the construction of Chang
and Collins (2011). The hypergraph weights en-
code the translation and language model scores, and
its structure ensures that the count of source words
translated is |w|, i.e. the length of the source sen-
tence. Each vertex will remember the preceding
target-language word and the count of source words
translated so far.
The hypergraph, which for this problem is also a
directed graph, takes the following form.
? Vertices v ? V are labeled (c, u) where c ?
{1 . . . |w|} is the count of source words trans-
lated and u ? ? is the last target-language word
produced by a partial hypothesis at this vertex.
Additionally there is an initial terminal vertex
labeled (0,<s>).
? There is a hyperedge e ? E with head (c?, u?)
and tail ?(c, u)? if there is a valid corresponding
phrase (q, r, j, k) such that c? = c + |q| and
u? = r|r|, i.e. c
? is the count of words translated
and u? is the last word of target phrase r. We
call this phrase p(e).
The weight of this hyperedge, ?(e), is the trans-
lation model score of the pair plus its language
model score
?(e) = ?(q, r)+
?
?
|r|?
i=2
?(ri?1, ri)
?
?+?(u, r1)
? To handle the end boundary, there are hyper-
edges with head 1 and tail ?(|w|, u)? for all
u ? ?. The weight of these edges is the cost of
the stop bigram following u, i.e. ?(u,</s>).
While any valid derivation corresponds to a hy-
perpath in this graph, a hyperpath may not corre-
spond to a valid derivation. For instance, a hyper-
path may translate some source words more than
once or not at all.
212
Figure 2: Hypergraph for translating the sentence w = les1 pauvres2 sont3 demunis4 with set of pairs P =
{(les, the), (pauvres, poor), (sont demunis, don?t have any money)}. Hyperedges are color-coded
by source words translated: orange for les1, green for pauvres2, and red for sont3 demunis4. The dotted lines
show an invalid hyperpath x that has signature Ax = ?0, 0, 2, 2? 6= ?1, 1, 1, 1? .
We handle this problem by adding additional con-
straints. For all source words i ? {1 . . . |w|}, define
? as the set of hyperedges that translate wi
?(i) = {e ? E : j(p(e)) ? i ? k(p(e))}
Next define |w| constraints enforcing that each word
in the source sentence is translated exactly once
?
e??(i)
x(e) = 1 ? i ? {1 . . . |w|}
These linear constraints can be represented with
a matrix A ? {0, 1}|w|?|E| where the rows corre-
spond to source indices and the columns correspond
to edges. We call the product Ax the signature,
where in this case (Ax)i is the number of times word
i has been translated. The full set of constrained hy-
perpaths is X ? = {x ? X : Ax = 1 }, and the best
derivation under this phrase-based translation model
has score maxx?X ? ?>x+ ? .
Figure 2.2 shows an example hypergraph
with constraints for translating the sentence les
pauvres sont demunis into English using
a simple set of phrases. Even in this small exam-
ple, many of the possible hyperpaths violate the
constraints and correspond to invalid derivations.
Example: Syntax-Based Machine Translation
Syntax-based machine translation with a language
model can also be expressed as a constrained hyper-
graph problem. For the sake of space, we omit the
definition. See Rush and Collins (2011) for an in-
depth description of the constraint matrix used for
syntax-based translation.
3 A Variant of Beam Search
This section describes a variant of the beam
search algorithm for finding the highest-scoring con-
strained hyperpath. The algorithm uses three main
techniques: (1) dynamic programming with ad-
ditional signature information to satisfy the con-
straints, (2) beam pruning where some, possibly op-
timal, hypotheses are discarded, and (3) branch-and-
bound-style application of upper and lower bounds
to discard provably non-optimal hypotheses.
Any solution returned by the algorithm will be a
valid constrained hyperpath and a member of X ?.
Additionally the algorithm returns a certificate flag
opt that, if true, indicates that no beam pruning
was used, implying the solution returned is opti-
mal. Generally it will be hard to produce a certificate
even by reducing the amount of beam pruning; how-
ever in the next section we will introduce a method
based on Lagrangian relaxation to tighten the upper
bounds. These bounds will help eliminate most so-
lutions before they trigger pruning.
3.1 Algorithm
Figure 3 shows the complete beam search algorithm.
At its core it is a dynamic programming algorithm
filling in the chart pi. The beam search chart indexes
hypotheses by vertex v ? V as well as a signature
sig ? R|b| where |b| is the number of constraints. A
new hypothesis is constructed from each hyperedge
and all possible signatures of tail nodes. We define
the function SIGS to take the tail of an edge and re-
213
turn the set of possible signature combinations
SIGS(v2, . . . v|v|) =
|v|?
i=2
{sig : pi[vi, sig] 6= ??}
where the product is the Cartesian product over sets.
Line 8 loops over this entire set.2 For hypothesis x,
the algorithm ensures that its signature sig is equal
to Ax. This property is updated on line 9.
The signature provides proof that a hypothesis is
still valid. Let the function CHECK(sig) return true
if the hypothesis can still fulfill the constraints. For
example, in phrase-based decoding, we will define
CHECK(sig) = (sig ? 1); this ensures that each
word has been translated 0 or 1 times. This check is
applied on line 11.
Unfortunately maintaining all signatures is inef-
ficient. For example we will see that in phrase-
based decoding the signature is a bit-string recording
which source words have been translated; the num-
ber of possible bit-strings is exponential in the length
of the sentence. The algorithm includes two meth-
ods for removing hypotheses, bounding and prun-
ing.
Bounding allows us to discard provably non-
optimal solutions. The algorithm takes as arguments
a lower bound on the optimal score lb ? ?>x? + ? ,
and computes upper bounds on the outside score
for all vertices v: ubs[v], i.e. an overestimate of
the score for completing the hyperpath from v. If
a hypothesis has score s, it can only be optimal if
s+ ubs[v] ? lb. This bound check is performed on
line 11.
Pruning removes weak partial solutions based on
problem-specific checks. The algorithm invokes the
black-box function, PRUNE, on line 13, passing it
a pruning parameter ? and a vertex-signature pair.
The parameter ? controls a threshold for pruning.
For instance for phrase-based translation, it specifies
a hard-limit on the number of hypotheses to retain.
The function returns true if it prunes from the chart.
Note that pruning may remove optimal hypotheses,
so we set the certificate flag opt to false if the chart
is modified.
2For simplicity we write this loop over the entire set. In
practice it is important to use data structures to optimize look-
up. See Tillmann (2006) and Huang and Chiang (2005).
1: procedure BEAMSEARCH(?, ?, lb, ?)
2: ubs? OUTSIDE(?, ?)
3: opt? true
4: pi[v, sig]? ?? for all v ? V, sig ? R|b|
5: pi[v, 0]? 0 for all v ? T
6: for e ? E in topological order do
7: ??v2, . . . , v|v|?, v1? ? e
8: for sig(2) . . . sig(|v|) ? SIGS(v2, . . . , v|v|) do
9: sig ? A?(e) +
|v|?
i=2
sig(i)
10: s? ?(e) +
|v|?
i=2
pi[vi, sig
(i)]
11: if
?
?
s > pi[v1, sig] ?
CHECK(sig) ?
s+ ubs[v1] ? lb
?
? then
12: pi[v1, sig]? s
13: if PRUNE(pi, v1, sig, ?) then opt? false
14: lb? ? pi[1, c] + ?
15: return lb?, opt
Input:
?
?
?
?
(V, E , ?, ?) hypergraph with weights
(A, b) matrix and vector for constraints
lb ? R lower bound
? a pruning parameter
Output:
[
lb? resulting lower bound score
opt certificate of optimality
Figure 3: A variant of the beam search algorithm. Uses
dynamic programming to produce a lower bound on the
optimal constrained solution and, possibly, a certificate of
optimality. Function OUTSIDE computes upper bounds
on outside scores. Function SIGS enumerates all possi-
ble tail signatures. Function CHECK identifies signatures
that do not violate constraints. Bounds lb and ubs are
used to remove provably non-optimal solutions. Func-
tion PRUNE, taking parameter ?, returns true if it prunes
hypotheses from pi that could be optimal.
This variant on beam search satisfies the follow-
ing two properties (recall x? is the optimal con-
strained solution)
Property 3.1 (Primal Feasibility). The returned
score lb? lower bounds the optimal constrained
score, that is lb? ? ?>x? + ? .
Property 3.2 (Dual Certificate). If beam search re-
turns with opt = true, then the returned score is
optimal, i.e. lb? = ?>x? + ? .
An immediate consequence of Property 3.1 is that
the output of beam search, lb?, can be used as the in-
put lb for future runs of the algorithm. Furthermore,
214
procedure PRUNE(pi, v, sig, ?)
C ? {(v?, sig?) : ||sig?||1 = ||sig||1,
pi[v?, sig?] 6= ??}
D ? C \mBEST(?, C, pi)
pi[v?, sig?]? ?? for all v?, sig? ? D
if D = ? then return true
else return false
Input:
[
(v, sig) the last hypothesis added to the chart
? ? Z # of hypotheses to retain
Output: true, if pi is modified
Figure 4: Pruning function for phrase-based translation.
Set C contains all hypotheses with ||sig||1 source words
translated. The function prunes all but the top-? scoring
hypotheses in this set.
if we loosen the amount of beam pruning by adjust-
ing the pruning parameter ? we can produce tighter
lower bounds and discard more hypotheses. We can
then iteratively apply this idea with a sequence of
parameters ?1 . . . ?K producing lower bounds lb(1)
through lb(K). We return to this idea in Section 5.
Example: Phrase-based Beam Search. Recall
that the constraints for phrase-based translation con-
sist of a binary matrix A ? {0, 1}|w|?|E| and vec-
tor b = 1. The value sigi is therefore the num-
ber of times source word i has been translated in
the hypothesis. We define the predicate CHECK as
CHECK(sig) = (sig ? 1) in order to remove hy-
potheses that already translate a source word more
than once, and are therefore invalid. For this reason,
phrase-based signatures are called bit-strings.
A common beam pruning strategy is to group
together items into a set C and retain a (possibly
complete) subset. An example phrase-based beam
pruner is given in Figure 4. It groups together
hypotheses based on ||sigi||1, i.e. the number of
source words translated, and applies a hard pruning
filter that retains only the ? highest-scoring items
(v, sig) ? C based on pi[v, sig].
3.2 Computing Upper Bounds
Define the setO(v, x) to contain all outside edges of
vertex v in hyperpath x (informally, hyperedges that
do not have v as an ancestor). For all v ? V , we set
the upper bounds, ubs, to be the best unconstrained
outside score
ubs[v] = max
x?X :v?x
?
e?O(v,x)
?(e) + ?
This upper bound can be efficiently computed for
all vertices using the standard outside dynamic pro-
gramming algorithm. We will refer to this algorithm
as OUTSIDE(?, ? ).
Unfortunately, as we will see, these upper bounds
are often quite loose. The issue is that unconstrained
outside paths are able to violate the constraints with-
out being penalized, and therefore greatly overesti-
mate the score.
4 Finding Tighter Bounds with
Lagrangian Relaxation
Beam search produces a certificate only if beam
pruning is never used. In the case of phrase-based
translation, the certificate is dependent on all groups
C having ? or less hypotheses. The only way to en-
sure this is to bound out enough hypotheses to avoid
pruning. The effectiveness of the bounding inequal-
ity, s + ubs[v] < lb, in removing hypotheses is di-
rectly dependent on the tightness of the bounds.
In this section we propose using Lagrangian re-
laxation to improve these bounds. We first give a
brief overview of the method and then apply it to
computing bounds. Our experiments show that this
approach is very effective at finding certificates.
4.1 Algorithm
In Lagrangian relaxation, instead of solving the con-
strained search problem, we relax the constraints
and solve an unconstrained hypergraph problem
with modified weights. Recall the constrained hy-
pergraph problem: max
x?X :Ax=b
?>x + ? . The La-
grangian dual of this optimization problem is
L(?) = max
x?X
?>x+ ? ? ?>(Ax? b)
=
(
max
x?X
(? ?A>?)>x
)
+ ? + ?>b
= max
x?X
??>x+ ? ?
where ? ? R|b| is a vector of dual variables and
define ?? = ? ? A>? and ? ? = ? + ?>b. This
maximization is over X , so for any value of ?, L(?)
can be calculated as BestPathScore(??, ? ?).
Note that for all valid constrained hyperpaths x ?
X ? the termAx?b equals 0, which implies that these
hyperpaths have the same score under the modified
weights as under the original weights, ?>x + ? =
??>x+? ?. This leads to the following two properties,
215
procedure LRROUND(?k, ?)
x? arg max
x?X
?>x+ ? ? ?>(Ax? b)
?? ? ?? ?k(Ax? b)
opt? Ax = b
ub? ?>x+ ?
return ??,ub, opt
procedure LAGRANGIANRELAXATION(?)
?(0) ? 0
for k in 1 . . .K do
?(k),ub, opt? LRROUND(?k, ?(k?1))
if opt then return ?(k),ub, opt
return ?(K),ub, opt
Input: ?1 . . . ?K sequence of subgradient rates
Output:
?
?
? final dual vector
ub upper bound on optimal constrained solution
opt certificate of optimality
Figure 5: Lagrangian relaxation algorithm. The algo-
rithm repeatedly calls LRROUND to compute the subgra-
dient, update the dual vector, and check for a certificate.
where x ? X is the hyperpath computed within the
max,
Property 4.1 (Dual Feasibility). The valueL(?) up-
per bounds the optimal solution, that is L(?) ?
?>x? + ?
Property 4.2 (Primal Certificate). If the hyperpath
x is a member of X ?, i.e. Ax = b, then L(?) =
?>x? + ? .
Property 4.1 states that L(?) always produces
some upper bound; however, to help beam search,
we want as tight a bound as possible: min? L(?).
The Lagrangian relaxation algorithm, shown in
Figure 5, uses subgradient descent to find this min-
imum. The subgradient of L(?) is Ax ? b where
x is the argmax of the modified objective x =
arg maxx?X ??>x + ? ?. Subgradient descent itera-
tively solves unconstrained hypergraph search prob-
lems to compute these subgradients and updates ?.
See Rush and Collins (2012) for an extensive discus-
sion of this style of optimization in natural language
processing.
Example: Phrase-based Relaxation. For phrase-
based translation, we expand out the Lagrangian to
L(?) = max
x?X
?>x+ ? ? ?>(Ax? b) =
max
x?X
?
e?E
?
??(e)?
k(p(e))?
i=j(p(e))
?i
?
?x(e) + ? +
|s|?
i=1
?i
The weight of each edge ?(e) is modified by the
dual variables ?i for each source word translated by
the edge, i.e. if (q, r, j, k) = p(e), then the score
is modified by
?k
i=j ?i. A solution under these
weights may use source words multiple times or not
at all. However if the solution uses each source word
exactly once (Ax = 1), then we have a certificate
and the solution is optimal.
4.2 Utilizing Upper Bounds in Beam Search
For many problems, it may not be possible to satisfy
Property 4.2 by running the subgradient algorithm
alone. Yet even for these problems, applying sub-
gradient descent will produce an improved estimate
of the upper bound, min? L(?).
To utilize these improved bounds, we simply re-
place the weights in beam search and the outside al-
gorithm with the modified weights from Lagrangian
relaxation, ?? and ? ?. Since the result of beam search
must be a valid constrained hyperpath x ? X ?, and
for all x ? X ?, ?>x + ? = ??>x + ? ?, this sub-
stitution does not alter the necessary properties of
the algorithm; i.e. if the algorithm returns with opt
equal to true, then the solution is optimal.
Additionally the computation of upper bounds
now becomes
ubs[v] = max
x?X :v?x
?
e?O(v,x)
??(e) + ? ?
These outside paths may still violate constraints, but
the modified weights now include penalty terms to
discourage common violations.
5 Optimal Beam Search
The optimality of the beam search algorithm is de-
pendent on the tightness of the upper and lower
bounds. We can produce better lower bounds by
varying the pruning parameter ?; we can produce
better upper bounds by running Lagrangian relax-
ation. In this section we combine these two ideas
and present a complete optimal beam search algo-
rithm.
Our general strategy will be to use Lagrangian
relaxation to compute modified weights and to use
beam search over these modified weights to attempt
to find an optimal solution. One simple method for
doing this, shown at the top of Figure 6, is to run
216
in stages. The algorithm first runs Lagrangian relax-
ation to compute the best ? vector. The algorithm
then iteratively runs beam search using the parame-
ter sequence ?k. These parameters allow the algo-
rithm to loosen the amount of beam pruning. For
example in phrase based pruning, we would raise
the number of hypotheses stored per group until no
beam pruning occurs.
A clear disadvantage of the staged approach is
that it needs to wait until Lagrangian relaxation is
completed before even running beam search. Of-
ten beam search will be able to quickly find an opti-
mal solution even with good but non-optimal ?. In
other cases, beam search may still improve the lower
bound lb.
This motivates the alternating algorithm OPT-
BEAM shown Figure 6. In each round, the algo-
rithm alternates between computing subgradients to
tighten ubs and running beam search to maximize
lb. In early rounds we set ? for aggressive beam
pruning, and as the upper bounds get tighter, we
loosen pruning to try to get a certificate. If at any
point either a primal or dual certificate is found, the
algorithm returns the optimal solution.
6 Related Work
Approximate methods based on beam search and
cube-pruning have been widely studied for phrase-
based (Koehn et al, 2003; Tillmann and Ney, 2003;
Tillmann, 2006) and syntax-based translation mod-
els (Chiang, 2007; Huang and Chiang, 2007; Watan-
abe et al, 2006; Huang and Mi, 2010).
There is a line of work proposing exact algorithms
for machine translation decoding. Exact decoders
are often slow in practice, but help quantify the er-
rors made by other methods. Exact algorithms pro-
posed for IBM model 4 include ILP (Germann et al,
2001), cutting plane (Riedel and Clarke, 2009), and
multi-pass A* search (Och et al, 2001). Zaslavskiy
et al (2009) formulate phrase-based decoding as a
traveling salesman problem (TSP) and use a TSP
decoder. Exact decoding algorithms based on finite
state transducers (FST) (Iglesias et al, 2009) have
been studied on phrase-based models with limited
reordering (Kumar and Byrne, 2005). Exact decod-
ing based on FST is also feasible for certain hier-
archical grammars (de Gispert et al, 2010). Chang
procedure OPTBEAMSTAGED(?, ?)
?,ub, opt?LAGRANGIANRELAXATION(?)
if opt then return ub
?? ? ? ?A>?
? ? ? ? + ?>b
lb(0) ? ??
for k in 1 . . .K do
lb(k), opt? BEAMSEARCH(??, ? ?, lb(k?1), ?k)
if opt then return lb(k)
return maxk?{1...K} lb
(k)
procedure OPTBEAM(?, ?)
?(0) ? 0
lb(0) ? ??
for k in 1 . . .K do
?(k),ub(k), opt? LRROUND(?k, ?(k?1))
if opt then return ub(k)
?? ? ? ?A>?(k)
? ? ? ? + ?(k)>b
lb(k), opt? BEAMSEARCH(??, ? ?, lb(k?1), ?k)
if opt then return lb(k)
return maxk?{1...K} lb
(k)
Input:
[
?1 . . . ?K sequence of subgradient rates
?1 . . . ?K sequence of pruning parameters
Output: optimal constrained score or lower bound
Figure 6: Two versions of optimal beam search: staged
and alternating. Staged runs Lagrangian relaxation to
find the optimal ?, uses ? to compute upper bounds, and
then repeatedly runs beam search with pruning sequence
?1 . . . ?k. Alternating switches between running a round
of Lagrangian relaxation and a round of beam search with
the updated ?. If either produces a certificate it returns the
result.
and Collins (2011) and Rush and Collins (2011) de-
velop Lagrangian relaxation-based approaches for
exact machine translation.
Apart from translation decoding, this paper is
closely related to work on column generation for
NLP. Riedel et al (2012) and Belanger et al (2012)
relate column generation to beam search and pro-
duce exact solutions for parsing and tagging prob-
lems. The latter work also gives conditions for when
beam search-style decoding is optimal.
7 Results
To evaluate the effectiveness of optimal beam search
for translation decoding, we implemented decoders
for phrase- and syntax-based models. In this sec-
tion we compare the speed and optimality of these
217
decoders to several baseline methods.
7.1 Setup and Implementation
For phrase-based translation we used a German-to-
English data set taken from Europarl (Koehn, 2005).
We tested on 1,824 sentences of length at most 50
words. For experiments the phrase-based systems
uses a trigram language model and includes standard
distortion penalties. Additionally the unconstrained
hypergraph includes further derivation information
similar to the graph described in Chang and Collins
(2011).
For syntax-based translation we used a Chinese-
to-English data set. The model and hypergraphs
come from the work of Huang and Mi (2010). We
tested on 691 sentences from the newswire portion
of the 2008 NIST MT evaluation test set. For ex-
periments, the syntax-based model uses a trigram
language model. The translation model is tree-to-
string syntax-based model with a standard context-
free translation forest. The constraint matrix A
is based on the constraints described by Rush and
Collins (2011).
Our decoders use a two-pass architecture. The
first pass sets up the hypergraph in memory, and the
second pass runs search. When possible the base-
lines share optimized construction and search code.
The performance of optimal beam search is de-
pendent on the sequences ? and ?. For the step-
size ? we used a variant of Polyak?s rule (Polyak,
1987; Boyd and Mutapcic, 2007), substituting the
unknown optimal score for the last computed lower
bound: ?k ? ub
(k)?lb(k)
||Ax(k)?b||22
. We adjust the order of
the pruning parameter ? based on a function ? of
the current gap: ?k ? 10?(ub
(k)?lb(k)).
Previous work on these data sets has shown that
exact algorithms do not result in a significant in-
crease in translation accuracy. We focus on the effi-
ciency and model score of the algorithms.
7.2 Baseline Methods
The experiments compare optimal beam search
(OPTBEAM) to several different decoding meth-
ods. For both systems we compare to: BEAM, the
beam search decoder from Figure 3 using the orig-
inal weights ? and ? , and ? ? {100, 1000}; LR-
TIGHT, Lagrangian relaxation followed by incre-
Figure 7: Two graphs from phrase-based decoding.
Graph (a) shows the duality gap distribution for 1,824
sentences after 0, 5, and 10 rounds of LR. Graph (b)
shows the % of certificates found for sentences with dif-
fering gap sizes and beam search parameters ?. Duality
gap is defined as, ub - (?>x? + ? ).
mental tightening constraints, which is a reimple-
mentation of Chang and Collins (2011) and Rush
and Collins (2011).
For phrase-based translation we compare with:
MOSES-GC, the standard Moses beam search de-
coder with ? ? {100, 1000} (Koehn et al, 2007);
MOSES, a version of Moses without gap constraints
more similar to BEAM (see Chang and Collins
(2011)); ASTAR, an implementation of A? search
using original outside scores, i.e. OUTSIDE(?, ?),
and capped at 20,000,000 queue pops.
For syntax-based translation we compare with:
ILP, a general-purpose integer linear program-
ming solver (Gurobi Optimization, 2013) and
CUBEPRUNING, an approximate decoding method
similar to beam search (Chiang, 2007), tested with
? ? {100, 1000}.
7.3 Experiments
Table 1 shows the main results. For phrase-based
translation, OPTBEAM decodes the optimal trans-
lation with certificate in 99% of sentences with an
average time of 17.27 seconds per sentence. This
218
11-20 (558) 21-30 (566) 31-40 (347) 41-50 (168) all (1824)
Phrase-Based time cert exact time cert exact time cert exact time cert exact time cert exact
BEAM (100) 2.33 19.5 38.0 8.37 1.6 7.2 24.12 0.3 1.4 71.35 0.0 0.0 14.50 15.3 23.2
BEAM (1000) 2.33 37.8 66.3 8.42 3.4 18.9 21.60 0.6 3.2 53.99 0.6 1.2 12.44 22.6 36.9
BEAM (100000) 3.34 83.9 96.2 18.53 22.4 60.4 46.65 2.0 18.1 83.53 1.2 6.5 23.39 43.2 62.4
MOSES (100) 0.18 0.0 81.0 0.36 0.0 45.6 0.53 0.0 14.1 0.74 0.0 6.0 0.34 0.0 52.3
MOSES (1000) 2.29 0.0 97.8 4.39 0.0 78.8 6.52 0.0 43.5 9.00 0.0 19.6 4.20 0.0 74.6
ASTAR (cap) 11.11 99.3 99.3 91.39 53.9 53.9 122.67 7.8 7.8 139.61 1.2 1.2 67.99 58.8 58.8
LR-TIGHT 4.20 100.0 100.0 23.25 100.0 100.0 88.16 99.7 99.7 377.9 97.0 97.0 60.11 99.7 99.7
OPTBEAM 2.85 100.0 100.0 10.33 100.0 100.0 28.29 100.0 100.0 84.34 97.0 97.0 17.27 99.7 99.7
ChangCollins 10.90 100.0 100.0 57.20 100.0 100.0 203.4 99.7 99.7 679.9 97.0 97.0 120.9 99.7 99.7
MOSES-GC (100) 0.14 0.0 89.4 0.27 0.0 84.1 0.41 0.0 75.8 0.58 0.0 78.6 0.26 0.0 84.9
MOSES-GC (1000) 1.33 0.0 89.4 2.62 0.0 84.3 4.15 0.0 75.8 6.19 0.0 79.2 2.61 0.0 85.0
11-20 (192) 21-30 (159) 31-40 (136) 41-100 (123) all (691)
Syntax-Based time cert exact time cert exact time cert exact time cert exact time cert exact
BEAM (100) 0.40 4.7 75.9 0.40 0.0 66.0 0.75 0.0 43.4 1.66 0.0 25.8 0.68 5.72 58.7
BEAM (1000) 0.78 16.9 79.4 2.65 0.6 67.1 6.20 0.0 47.5 15.5 0.0 36.4 4.16 12.5 65.5
CUBE (100) 0.08 0.0 77.6 0.16 0.0 66.7 0.23 0.0 43.9 0.41 0.0 26.3 0.19 0.0 59.0
CUBE (1000) 1.76 0.0 91.7 4.06 0.0 95.0 5.71 0.0 82.9 10.69 0.0 60.9 4.66 0.0 85.0
LR-TIGHT 0.37 100.0 100.0 1.76 100.0 100.0 4.79 100.0 100.0 30.85 94.5 94.5 7.25 99.0 99.0
OPTBEAM 0.23 100.0 100.0 0.50 100.0 100.0 1.42 100.0 100.0 7.14 93.6 93.6 1.75 98.8 98.8
ILP 9.15 100.0 100.0 32.35 100.0 100.0 49.6 100.0 100.0 108.6 100.0 100.0 40.1 100.0 100.0
Table 1: Experimental results for translation experiments. Column time is the mean time per sentence in seconds,
cert is the percentage of sentences solved with a certificate of optimality, exact is the percentage of sentences solved
exactly, i.e. ?>x+ ? = ?>x? + ? . Results are grouped by sentence length (group 1-10 is omitted for space).
is seven times faster than the decoder of Chang and
Collins (2011) and 3.5 times faster then our reim-
plementation, LR-TIGHT. ASTAR performs poorly,
taking lots of time on difficult sentences. BEAM runs
quickly, but rarely finds an exact solution. MOSES
without gap constraints is also fast, but less exact
than OPTBEAM and unable to produce certificates.
For syntax-based translation. OPTBEAM finds a
certificate on 98.8% of solutions with an average
time of 1.75 seconds per sentence, and is four times
faster than LR-TIGHT. CUBE (100) is an order
of magnitude faster, but is rarely exact on longer
sentences. CUBE (1000) finds more exact solu-
tions, but is comparable in speed to optimal beam
search. BEAM performs better than in the phrase-
based model, but is not much faster than OPTBEAM.
Figure 7.2 shows the relationship between beam
search optimality and duality gap. Graph (a) shows
how a handful of LR rounds can significantly tighten
the upper bound score of many sentences. Graph (b)
shows how beam search is more likely to find opti-
mal solutions with tighter bounds. BEAM effectively
uses 0 rounds of LR, which may explain why it finds
so few optimal solutions compared to OPTBEAM.
Table 2 breaks down the time spent in each part
of the algorithm. For both methods, beam search has
the most time variance and uses more time on longer
sentences. For phrase-based sentences, Lagrangian
relaxation is fast, and hypergraph construction dom-
? 30 all
mean median mean median
Hypergraph 56.6% 69.8% 59.6% 69.6%
PB Lag. Relaxation 10.0% 5.5% 9.4% 7.6%
Beam Search 33.4% 24.6% 30.9% 22.8%
Hypergraph 0.5% 1.6% 0.8% 2.4%
SB Lag. Relaxation 15.0% 35.2% 17.3% 41.4%
Beam Search 84.4% 63.1% 81.9 % 56.1%
Table 2: Distribution of time within optimal beam search,
including: hypergraph construction, Lagrangian relax-
ation, and beam search. Mean is the percentage of total
time. Median is the distribution over the median values
for each row.
inates. If not for this cost, OPTBEAM might be com-
parable in speed to MOSES (1000).
8 Conclusion
In this work we develop an optimal variant of beam
search and apply it to machine translation decod-
ing. The algorithm uses beam search to produce
constrained solutions and bounds from Lagrangian
relaxation to eliminate non-optimal solutions. Re-
sults show that this method can efficiently find exact
solutions for two important styles of machine trans-
lation.
Acknowledgments Alexander Rush, Yin-Wen
Chang and Michael Collins were all supported by
NSF grant IIS-1161814. Alexander Rush was partially
supported by an NSF Graduate Research Fellowship.
219
References
David Belanger, Alexandre Passos, Sebastian Riedel, and
Andrew McCallum. 2012. Map inference in chains
using column generation. In NIPS, pages 1853?1861.
Stephen Boyd and Almir Mutapcic. 2007. Subgradient
methods.
Yin-Wen Chang and Michael Collins. 2011. Exact de-
coding of phrase-based translation models through la-
grangian relaxation. In Proceedings of the Conference
on Empirical Methods in Natural Language Process-
ing, pages 26?37. Association for Computational Lin-
guistics.
David Chiang. 2007. Hierarchical phrase-based transla-
tion. computational linguistics, 33(2):201?228.
Adria de Gispert, Gonzalo Iglesias, Graeme Blackwood,
Eduardo R. Banga, and William Byrne. 2010. Hierar-
chical Phrase-Based Translation with Weighted Finite-
State Transducers and Shallow-n Grammars. In Com-
putational linguistics, volume 36, pages 505?533.
Chris Dyer, Adam Lopez, Juri Ganitkevitch, Jonathen
Weese, Ferhan Ture, Phil Blunsom, Hendra Setiawan,
Vlad Eidelman, and Philip Resnik. 2010. cdec: A
decoder, alignment, and learning framework for finite-
state and context-free translation models.
Ulrich Germann, Michael Jahr, Kevin Knight, Daniel
Marcu, and Kenji Yamada. 2001. Fast decoding and
optimal decoding for machine translation. In Proceed-
ings of the 39th Annual Meeting on Association for
Computational Linguistics, ACL ?01, pages 228?235.
Inc. Gurobi Optimization. 2013. Gurobi optimizer refer-
ence manual.
Liang Huang and David Chiang. 2005. Better k-best
parsing. In Proceedings of the Ninth International
Workshop on Parsing Technology, pages 53?64. As-
sociation for Computational Linguistics.
Liang Huang and David Chiang. 2007. Forest rescoring:
Faster decoding with integrated language models. In
Proceedings of the 45th Annual Meeting of the Asso-
ciation of Computational Linguistics, pages 144?151,
Prague, Czech Republic, June. Association for Com-
putational Linguistics.
Liang Huang and Haitao Mi. 2010. Efficient incremental
decoding for tree-to-string translation. In Proceedings
of the 2010 Conference on Empirical Methods in Natu-
ral Language Processing, pages 273?283, Cambridge,
MA, October. Association for Computational Linguis-
tics.
Gonzalo Iglesias, Adria` de Gispert, Eduardo R. Banga,
and William Byrne. 2009. Rule filtering by pattern
for efficient hierarchical translation. In Proceedings of
the 12th Conference of the European Chapter of the
ACL (EACL 2009), pages 380?388, Athens, Greece,
March. Association for Computational Linguistics.
Kevin Knight. 1999. Decoding complexity in word-
replacement translation models. Computational Lin-
guistics, 25(4):607?615.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Proceed-
ings of the 2003 Conference of the North American
Chapter of the Association for Computational Linguis-
tics on Human Language Technology, NAACL ?03,
pages 48?54.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondr?ej Bojar, Alexandra Con-
stantin, and Evan Herbst. 2007. Moses: Open source
toolkit for statistical machine translation. In Proceed-
ings of the 45th Annual Meeting of the ACL on Inter-
active Poster and Demonstration Sessions, ACL ?07,
pages 177?180.
Philipp Koehn. 2004. Pharaoh: a beam search decoder
for phrase-based statistical machine translation mod-
els. Machine translation: From real users to research,
pages 115?124.
Shankar Kumar and William Byrne. 2005. Local phrase
reordering models for statistical machine translation.
In Proceedings of Human Language Technology Con-
ference and Conference on Empirical Methods in Nat-
ural Language Processing, pages 161?168, Vancou-
ver, British Columbia, Canada, October. Association
for Computational Linguistics.
R. Kipp Martin, Rardin L. Rardin, and Brian A. Camp-
bell. 1990. Polyhedral characterization of dis-
crete dynamic programming. Operations research,
38(1):127?138.
Franz Josef Och, Nicola Ueffing, and Hermann Ney.
2001. An efficient A* search algorithm for statisti-
cal machine translation. In Proceedings of the work-
shop on Data-driven methods in machine translation -
Volume 14, DMMT ?01, pages 1?8, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Boris Polyak. 1987. Introduction to Optimization. Opti-
mization Software, Inc.
Sebastian Riedel and James Clarke. 2009. Revisiting
optimal decoding for machine translation IBM model
4. In Proceedings of Human Language Technologies:
The 2009 Annual Conference of the North American
Chapter of the Association for Computational Linguis-
tics, Companion Volume: Short Papers, pages 5?8. As-
sociation for Computational Linguistics.
Sebastian Riedel, David Smith, and Andrew McCallum.
2012. Parse, price and cut: delayed column and row
generation for graph based parsers. In Proceedings
of the 2012 Joint Conference on Empirical Methods
in Natural Language Processing and Computational
220
Natural Language Learning, pages 732?743. Associa-
tion for Computational Linguistics.
Alexander M Rush and Michael Collins. 2011. Exact
decoding of syntactic translation models through la-
grangian relaxation. In Proceedings of the 49th An-
nual Meeting of the Association for Computational
Linguistics: Human Language Technologies, vol-
ume 1, pages 72?82.
Alexander M Rush and Michael Collins. 2012. A tutorial
on dual decomposition and lagrangian relaxation for
inference in natural language processing. Journal of
Artificial Intelligence Research, 45:305?362.
Christoph Tillmann and Hermann Ney. 2003. Word re-
ordering and a dynamic programming beam search al-
gorithm for statistical machine translation. Computa-
tional Linguistics, 29(1):97?133.
Christoph Tillmann. 2006. Efficient dynamic pro-
gramming search algorithms for phrase-based SMT.
In Proceedings of the Workshop on Computationally
Hard Problems and Joint Inference in Speech and Lan-
guage Processing, CHSLP ?06, pages 9?16.
Taro Watanabe, Hajime Tsukada, and Hideki Isozaki.
2006. Left-to-right target generation for hierarchical
phrase-based translation. In Proceedings of the 21st
International Conference on Computational Linguis-
tics and the 44th annual meeting of the Association for
Computational Linguistics, ACL-44, pages 777?784,
Morristown, NJ, USA. Association for Computational
Linguistics.
Mikhail Zaslavskiy, Marc Dymetman, and Nicola Can-
cedda. 2009. Phrase-based statistical machine transla-
tion as a traveling salesman problem. In Proceedings
of the Joint Conference of the 47th Annual Meeting of
the ACL and the 4th International Joint Conference on
Natural Language Processing of the AFNLP: Volume
1 - Volume 1, ACL ?09, pages 333?341, Stroudsburg,
PA, USA. Association for Computational Linguistics.
221
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1481?1490,
Baltimore, Maryland, USA, June 23-25 2014.
c
?2014 Association for Computational Linguistics
A Constrained Viterbi Relaxation for Bidirectional Word Alignment
Yin-Wen Chang Alexander M. Rush
MIT CSAIL,
Cambridge, MA 02139
{yinwen,srush}@
csail.mit.edu
John DeNero
UC Berkeley,
Berkeley, CA 94720
denero@
cs.berkeley.edu
Michael Collins
Columbia University,
New York, NY 10027
mcollins@
cs.columbia.edu
Abstract
Bidirectional models of word alignment
are an appealing alternative to post-hoc
combinations of directional word align-
ers. Unfortunately, most bidirectional
formulations are NP-Hard to solve, and
a previous attempt to use a relaxation-
based decoder yielded few exact solu-
tions (6%). We present a novel relax-
ation for decoding the bidirectional model
of DeNero and Macherey (2011). The
relaxation can be solved with a mod-
ified version of the Viterbi algorithm.
To find optimal solutions on difficult
instances, we alternate between incre-
mentally adding constraints and applying
optimality-preserving coarse-to-fine prun-
ing. The algorithm finds provably ex-
act solutions on 86% of sentence pairs
and shows improvements over directional
models.
1 Introduction
Word alignment is a critical first step for build-
ing statistical machine translation systems. In or-
der to ensure accurate word alignments, most sys-
tems employ a post-hoc symmetrization step to
combine directional word aligners, such as IBM
Model 4 (Brown et al, 1993) or hidden Markov
model (HMM) based aligners (Vogel et al, 1996).
Several authors have proposed bidirectional mod-
els that incorporate this step directly, but decoding
under many bidirectional models is NP-Hard and
finding exact solutions has proven difficult.
In this paper, we describe a novel Lagrangian-
relaxation based decoder for the bidirectional
model proposed by DeNero and Macherey (2011),
with the goal of improving search accuracy.
In that work, the authors implement a dual
decomposition-based decoder for the problem, but
are only able to find exact solutions for around 6%
of instances.
Our decoder uses a simple variant of the Viterbi
algorithm for solving a relaxed version of this
model. The algorithm makes it easy to re-
introduce constraints for difficult instances, at the
cost of increasing run-time complexity. To offset
this cost, we employ optimality-preserving coarse-
to-fine pruning to reduce the search space. The
pruning method utilizes lower bounds on the cost
of valid bidirectional alignments, which we obtain
from a fast, greedy decoder.
The method has the following properties:
? It is based on a novel relaxation for the model
of DeNero and Macherey (2011), solvable
with a variant of the Viterbi algorithm.
? To find optimal solutions, it employs an effi-
cient strategy that alternates between adding
constraints and applying pruning.
? Empirically, it is able to find exact solutions
on 86% of sentence pairs and is significantly
faster than general-purpose solvers.
We begin in Section 2 by formally describing
the directional word alignment problem. Section 3
describes a preliminary bidirectional model us-
ing full agreement constraints and a Lagrangian
relaxation-based solver. Section 4 modifies this
model to include adjacency constraints. Section 5
describes an extension to the relaxed algorithm to
explicitly enforce constraints, and Section 6 gives
a pruning method for improving the efficiency of
the algorithm.
Experiments compare the search error and accu-
racy of the new bidirectional algorithm to several
directional combiners and other bidirectional al-
gorithms. Results show that the new relaxation is
much more effective at finding exact solutions and
is able to produce comparable alignment accuracy.
1481
 m
o
n
t
r
e
z
- n
o
u
s
l
e
s
d
o
c
u
m
e
n
t
s

let
us
see
the
documents
Figure 1: An example e?f directional alignment for the sen-
tences let us see the documents and montrez -
nous les documents, with I = 5 and J = 5. The in-
dices i ? [I]
0
are rows, and the indices j ? [J ]
0
are columns.
The HMM alignment shown has transitions x(0, 1, 1) =
x(1, 2, 3) = x(3, 3, 1) = x(1, 4, 4) = x(4, 5, 5) = 1.
Notation We use lower- and upper-case letters
for scalars and vectors, and script-case for sets
e.g. X . For vectors, such as v ? {0, 1}
(I?J )?J
,
where I and J are finite sets, we use the notation
v(i, j) and v(j) to represent elements of the vec-
tor. Define d = ?(i) to be the indicator vector with
d(i) = 1 and d(i
?
) = 0 for all i
?
6= i. Finally de-
fine the notation [J ] to refer to {1 . . . J} and [J ]
0
to refer to {0 . . . J}.
2 Background
The focus of this work is on the word alignment
decoding problem. Given a sentence e of length
|e| = I and a sentence f of length |f | = J , our
goal is to find the best bidirectional alignment be-
tween the two sentences under a given objective
function. Before turning to the model of interest,
we first introduce directional word alignment.
2.1 Word Alignment
In the e?f word alignment problem, each word
in e is aligned to a word in f or to the null word .
This alignment is a mapping from each index i ?
[I] to an index j ? [J ]
0
(where j = 0 represents
alignment to ). We refer to a single word align-
ment as a link.
A first-order HMM alignment model (Vogel et
al., 1996) is an HMM of length I + 1 where the
hidden state at position i ? [I]
0
is the aligned in-
dex j ? [J ]
0
, and the transition score takes into
account the previously aligned index j
?
? [J ]
0
.
1
Formally, define the set of possible HMM align-
ments as X ? {0, 1}
([I]
0
?[J ]
0
)?([I]?[J ]
0
?[J ]
0
)
with
1
Our definition differs slightly from other HMM-based
aligners in that it does not track the last  alignment.
X =
?
?
?
?
?
?
?
?
?
x : x(0, 0) = 1,
x(i, j) =
J?
j
?
=0
x(j
?
, i, j) ?i ? [I], j ? [J ]
0
,
x(i, j) =
J?
j
?
=0
x(j, i+ 1, j
?
) ?i ? [I ? 1]
0
, j ? [J ]
0
where x(i, j) = 1 indicates that there is a link
between index i and index j, and x(j
?
, i, j) = 1
indicates that index i ? 1 aligns to index j
?
and
index i aligns to j. Figure 1 shows an example
member of X .
The constraints of X enforce backward and for-
ward consistency respectively. If x(i, j) = 1,
backward consistency enforces that there is a tran-
sition from (i? 1, j
?
) to (i, j) for some j
?
? [J ]
0
,
whereas forward consistency enforces a transition
from (i, j) to (i+ 1, j
?
) for some j
?
? [J ]
0
. Infor-
mally the constraints ?chain? together the links.
The HMM objective function f : X ? R can
be written as a linear function of x
f(x; ?) =
I
?
i=1
J
?
j=0
J
?
j
?
=0
?(j
?
, i, j)x(j
?
, i, j)
where the vector ? ? R
[I]?[J ]
0
?[J ]
0
includes the
transition and alignment scores. For a generative
model of alignment, we might define ?(j
?
, i, j) =
log(p(e
i
|f
j
)p(j|j
?
)). For a discriminative model
of alignment, we might define ?(j
?
, i, j) = w ?
?(i, j
?
, j, f , e) for a feature function ? and weights
w (Moore, 2005; Lacoste-Julien et al, 2006).
Now reverse the direction of the model and
consider the f?e alignment problem. An f?e
alignment is a binary vector y ? Y where for
each j ? [J ], y(i, j) = 1 for exactly one i ?
[I]
0
. Define the set of HMM alignments Y ?
{0, 1}
([I]
0
?[J ]
0
)?([I]
0
?[I]
0
?[J ])
as
Y =
?
?
?
?
?
?
?
?
?
y : y(0, 0) = 1,
y(i, j) =
I?
i
?
=0
y(i
?
, i, j) ?i ? [I]
0
, j ? [J ],
y(i, j) =
I?
i
?
=0
y(i, i
?
, j + 1) ?i ? [I]
0
, j ? [J ? 1]
0
Similarly define the objective function
g(y;?) =
J
?
j=1
I
?
i=0
I
?
i
?
=0
?(i
?
, i, j)y(i
?
, i, j)
with vector ? ? R
[I]
0
?[I]
0
?[J ]
.
1482
 m
o
n
t
r
e
z
- n
o
u
s
l
e
s
d
o
c
u
m
e
n
t
s

let
us
see
the
documents
(a)
 m
o
n
t
r
e
z
- n
o
u
s
l
e
s
d
o
c
u
m
e
n
t
s

let
us
see
the
documents
(b)
Figure 2: (a) An example alignment pair (x, y) satisfying the
full agreement conditions. The x alignment is represented
with circles and the y alignment with triangles. (b) An exam-
ple f?e alignment y ? Y
?
with relaxed forward constraints.
Note that unlike an alignment from Y multiple words may
be aligned in a column and words may transition from non-
aligned positions.
Note that for both of these models we can solve
the optimization problem exactly using the stan-
dard Viterbi algorithm for HMM decoding. The
first can be solved in O(IJ
2
) time and the second
in O(I
2
J) time.
3 Bidirectional Alignment
The directional bias of the e?f and f?e align-
ment models may cause them to produce differing
alignments. To obtain the best single alignment,
it is common practice to use a post-hoc algorithm
to merge these directional alignments (Och et al,
1999). First, a directional alignment is found from
each word in e to a word f . Next an alignment is
produced in the reverse direction from f to e. Fi-
nally, these alignments are merged, either through
intersection, union, or with an interpolation algo-
rithm such as grow-diag-final (Koehn et al, 2003).
In this work, we instead consider a bidirectional
alignment model that jointly considers both direc-
tional models. We begin in this section by in-
troducing a simple bidirectional model that en-
forces full agreement between directional models
and giving a relaxation for decoding. Section 4
loosens this model to adjacent agreement.
3.1 Enforcing Full Agreement
Perhaps the simplest post-hoc merging strategy is
to retain the intersection of the two directional
models. The analogous bidirectional model en-
forces full agreement to ensure the two alignments
select the same non-null links i.e.
x
?
, y
?
= argmax
x?X ,y?Y
f(x) + g(y) s.t.
x(i, j) = y(i, j) ?i ? [I], j ? [J ]
We refer to the optimal alignments for this prob-
lem as x
?
and y
?
.
Unfortunately this bidirectional decoding
model is NP-Hard (a proof is given in Ap-
pendix A). As it is common for alignment pairs to
have |f | or |e| over 40, exact decoding algorithms
are intractable in the worst-case.
Instead we will use Lagrangian relaxation for
this model. At a high level, we will remove a
subset of the constraints from the original problem
and replace them with Lagrange multipliers. If we
can solve this new problem efficiently, we may be
able to get optimal solutions to the original prob-
lem. (See the tutorial by Rush and Collins (2012)
describing the method.)
There are many possible subsets of constraints
to consider relaxing. The relaxation we use pre-
serves the agreement constraints while relaxing
the Markov structure of the f?e alignment. This
relaxation will make it simple to later re-introduce
constraints in Section 5.
We relax the forward constraints of set Y . With-
out these constraints the y links are no longer
chained together. This has two consequences: (1)
for index j there may be any number of indices i,
such that y(i, j) = 1, (2) if y(i
?
, i, j) = 1 it is no
longer required that y(i
?
, j ? 1) = 1. This gives a
set Y
?
which is a superset of Y
Y
?
=
{
y : y(0, 0) = 1,
y(i, j) =
?
I
i
?
=0
y(i
?
, i, j) ?i ? [I]
0
, j ? [J ]
Figure 2(b) shows a possible y ? Y
?
and a valid
unchained structure.
To form the Lagrangian dual with relaxed for-
ward constraints, we introduce a vector of La-
grange multipliers, ? ? R
[I?1]
0
?[J ]
0
, with one
multiplier for each original constraint. The La-
grangian dual L(?) is defined as
max
x?X ,y?Y
?
,
x(i,j)=y(i,j)
f(x) +
I?
i=1
J?
j=0
I?
i
?
=0
y(i
?
, i, j)?(i
?
, i, j) (1)
?
I?
i=0
J?1?
j=0
?(i, j)
(
y(i, j)?
I?
i
?
=0
y(i, i
?
, j + 1)
)
= max
x?X ,y?Y
?
,
x(i,j)=y(i,j)
f(x) +
I?
i=1
J?
j=0
I?
i
?
=0
y(i
?
, i, j)?
?
(i
?
, i, j)(2)
= max
x?X ,y?Y
?
,
x(i,j)=y(i,j)
f(x) +
I?
i=1
J?
j=0
y(i, j) max
i
?
?[I]
0
?
?
(i
?
, i, j)(3)
= max
x?X ,y?Y
?
,
x(i,j)=y(i,j)
f(x) + g
?
(y;?, ?) (4)
1483
Line 2 distributes the ??s and introduces a modi-
fied potential vector ?
?
defined as
?
?
(i
?
, i, j) = ?(i
?
, i, j)? ?(i, j) + ?(i
?
, j ? 1)
for all i
?
? [I]
0
, i ? [I]
0
, j ? [J ]. Line 3 uti-
lizes the relaxed set Y
?
which allows each y(i, j)
to select the best possible previous link (i
?
, j ? 1).
Line 4 introduces the modified directional objec-
tive
g
?
(y;?, ?) =
I
?
i=1
J
?
j=0
y(i, j) max
i
?
?[I]
0
?
?
(i
?
, i, j)
The Lagrangian dual is guaranteed to be an up-
per bound on the optimal solution, i.e. for all ?,
L(?) ? f(x
?
) + g(y
?
). Lagrangian relaxation
attempts to find the tighest possible upper bound
by minimizing the Lagrangian dual, min
?
L(?),
using subgradient descent. Briefly, subgradient
descent is an iterative algorithm, with two steps.
Starting with ? = 0, we iteratively
1. Set (x, y) to the argmax of L(?).
2. Update ?(i, j) for all i ? [I ? 1]
0
, j ? [J ]
0
,
?(i, j)? ?(i, j)? ?
t
(
y(i, j)?
I?
i
?
=0
y(i, i
?
, j + 1)
)
.
where ?
t
> 0 is a step size for the t?th update. If
at any iteration of the algorithm the forward con-
straints are satisfied for (x, y), then f(x)+g(y) =
f(x
?
) + g(x
?
) and we say this gives a certificate
of optimality for the underlying problem.
To run this algorithm, we need to be able to effi-
ciently compute the (x, y) pair that is the argmax
of L(?) for any value of ?. Fortunately, since the y
alignments are no longer constrained to valid tran-
sitions, we can compute these alignments by first
picking the best f?e transitions for each possible
link, and then running an e?f Viterbi-style algo-
rithm to find the bidirectional alignment.
The max version of this algorithm is shown in
Figure 3. It consists of two steps. We first compute
the score for each y(i, j) variable. We then use the
standard Viterbi update for computing the x vari-
ables, adding in the score of the y(i, j) necessary
to satisfy the constraints.
procedure VITERBIFULL(?, ?
?
)
Let pi, ? be dynamic programming charts.
?[i, j]? max
i
?
?[I]
0
?
?
(i
?
, i, j) ? i ? [I], j ? [J ]
0
pi[0, 0]?
?
J
j=1
max{0, ?[0, j]}
for i ? [I], j ? [J ]
0
in order do
pi[i, j]? max
j
?
?[J]
0
?(j
?
, i, j) + pi[i? 1, j
?
]
if j 6= 0 then pi[i, j]? pi[i, j] + ?[i, j]
return max
j?[J]
0
pi[I, j]
Figure 3: Viterbi-style algorithm for computing L(?). For
simplicity the algorithm shows the max version of the algo-
rithm, argmax can be computed with back-pointers.
4 Adjacent Agreement
Enforcing full agreement can be too strict an align-
ment criteria. DeNero and Macherey (2011) in-
stead propose a model that allows near matches,
which we call adjacent agreement. Adjacent
agreement allows links from one direction to agree
with adjacent links from the reverse alignment for
a small penalty. Figure 4(a) shows an example
of a valid bidirectional alignment under adjacent
agreement.
In this section we formally introduce adjacent
agreement, and propose a relaxation algorithm for
this model. The key algorithmic idea is to extend
the Viterbi algorithm in order to consider possible
adjacent links in the reverse direction.
4.1 Enforcing Adjacency
Define the adjacency set K = {?1, 0, 1}. A bidi-
rectional alignment satisfies adjacency if for all
i ? [I], j ? [J ],
? If x(i, j) = 1, it is required that y(i+k, j) =
1 for exactly one k ? K (i.e. either above,
center, or below). We indicate which position
with variables z
l
i,j
? {0, 1}
K
? If x(i, j) = 1, it is allowed that y(i, j + k) =
1 for any k ? K (i.e. either left, center, or
right) and all other y(i, j
?
) = 0. We indicate
which positions with variables z
?
i,j
? {0, 1}
K
Formally for x ? X and y ? Y , the pair (x, y) is
feasible if there exists a z from the set Z(x, y) ?
{0, 1}
K
2
?[I]?[J ]
defined as
Z(x, y) =
?
?
?
?
?
?
?
?
?
z : ?i ? [I], j ? [J ]
z
l
i,j
? {0, 1}
K
, z
?
i,j
? {0, 1}
K
x(i, j) =
?
k?K
z
l
i,j
(k),
?
k?K
z
?
i,j
(k) = y(i, j),
z
l
i,j
(k) ? y(i+ k, j) ?k ? K : i+ k > 0,
x(i, j) ? z
?
i,j?k
(k) ?k ? K : j + k > 0
1484
 m
o
n
t
r
e
z
- n
o
u
s
l
e
s
d
o
c
u
m
e
n
t
s

let
us
see
the
documents
(a)
 m
o
n
t
r
e
z
- n
o
u
s
l
e
s
d
o
c
u
m
e
n
t
s

let
us
see
the
documents
(b)
Figure 4: (a) An alignment satisfying the adjacency con-
straints. Note that x(2, 1) = 1 is allowed because of
y(1, 1) = 1, x(4, 3) = 1 because of y(3, 3), and y(3, 1)
because of x(3, 2). (b) An adjacent bidirectional alignment
in progress. Currently x(2, 2) = 1 with z
l
(?1) = 1 and
z
?
(?1) = 1. The last transition was from x(1, 3) with
z
??
(?1) = 1, z
??
(0) = 1, z
l?
(0) = 1.
Additionally adjacent, non-overlapping
matches are assessed a penalty ? calculated as
h(z) =
I
?
i=1
J
?
j=1
?
k?K
?|k|(z
l
i,j
(k) + z
?
i,j
(k))
where ? ? 0 is a parameter of the model. The
example in Figure 4(a) includes a 3? penalty.
Adding these penalties gives the complete adja-
cent agreement problem
argmax
z?Z(x,y)
x?X ,y?Y
f(x) + g(y) + h(z)
Next, apply the same relaxation from Sec-
tion 3.1, i.e. we relax the forward constraints of
the f?e set. This yields the following Lagrangian
dual
L(?) = max
z?Z(x,y)
x?X ,y?Y
?
f(x) + g
?
(y;?, ?) + h(z)
Despite the new constraints, we can still com-
pute L(?) in O(IJ(I + J)) time using a variant
of the Viterbi algorithm. The main idea will be to
consider possible adjacent settings for each link.
Since each z
l
i,j
and z
?
i,j
only have a constant num-
ber of settings, this does not increase the asymp-
totic complexity of the algorithm.
Figure 5 shows the algorithm for computing
L(?). The main loop of the algorithm is similar to
Figure 3. It proceeds row-by-row, picking the best
alignment x(i, j) = 1. The major change is that
the chart pi also stores a value z ? {0, 1}
K?K
rep-
resenting a possible z
l
i,j
, z
?
i,j
pair. Since we have
procedure VITERBIADJ(?, ?
?
)
?[i, j]? max
i
?
?[I]
0
?
?
(i
?
, i, j) ? i ? [I], j ? [J ]
0
pi[0, 0]?
?
J
j=1
max{0, ?[0, j]}
for i ? [I], j ? [J ]
0
, z
l
, z
?
? {0, 1}
|K|
do
pi[i, j, z]?
max
j
?
?[J]
0
,
z
?
?N (z,j?j
?
)
?(j
?
, i, j) + pi[i? 1, j
?
, z
?
]
+
?
k?K
z
?
(k)(?[i, j + k] + ?|k|)
+z
l
(k)?|k|
return max
j?[J]
0
,z?{0,1}
|K?K|
pi[I, j, z]
Figure 5: Modified Viterbi algorithm for computing the adja-
cent agreement L(?).
the proposed z
i,j
in the inner loop, we can include
the scores of the adjacent y alignments that are
in neighboring columns, as well as the possible
penalty for matching x(i, j) to a y(i + k, j) in a
different row. Figure 4(b) gives an example set-
ting of z.
In the dynamic program, we need to ensure that
the transitions between the z?s are consistent. The
vector z
?
indicates the y links adjacent to x(i ?
1, j
?
). If j
?
is near to j, z
?
may overlap with z
and vice-versa. The transition setN ensures these
indicators match up
N (z, k
?
) =
?
?
?
z
?
: (z
l
(?1) ? k
?
? K)? z
??
(k
?
),
(z
l?
(1) ? k
?
? K)? z
?
(?k
?
),
?
k?K
z
l
(k) = 1
5 Adding Back Constraints
In general, it can be shown that Lagrangian relax-
ation is only guaranteed to solve a linear program-
ming relaxation of the underlying combinatorial
problem. For difficult instances, we will see that
this relaxation often does not yield provably exact
solutions. However, it is possible to ?tighten? the
relaxation by re-introducing constraints from the
original problem.
In this section, we extend the algorithm to al-
low incrementally re-introducing constraints. In
particular we track which constraints are most of-
ten violated in order to explicitly enforce them in
the algorithm.
Define a binary vector p ? {0, 1}
[I?1]
0
?[J ]
0
where p(i, j) = 1 indicates a previously re-
laxed constraint on link y(i, j) that should be re-
introduced into the problem. Let the new partially
1485
constrained Lagrangian dual be defined as
L(?; p) = max
z?Z(x,y)
x?X ,y?Y
?
f(x) + g
?
(y;?, ?) + h(z)
y(i, j) =
?
i
?
y(i, i
?
, j + 1) ?i, j : p(i, j) = 1
If p =
~
1, the problem includes all of the original
constraints, whereas p =
~
0 gives our original La-
grangian dual. In between we have progressively
more constrained variants.
In order to compute the argmax of this op-
timization problem, we need to satisfy the con-
straints within the Viterbi algorithm. We augment
the Viterbi chart with a count vector d ? D where
D ? Z
||p||
1
and d(i, j) is a count for the (i, j)?th
constraint, i.e. d(i, j) = y(i, j) ?
?
i
?
y(i
?
, i, j).
Only solutions with count 0 at the final position
satisfy the active constraints. Additionally de-
fine a helper function [?]
D
as the projection from
Z
[I?1]
0
?[J ]
? D, which truncates dimensions
without constraints.
Figure 6 shows this constrained Viterbi relax-
ation approach. It takes p as an argument and en-
forces the active constraints. For simplicity, we
show the full agreement version, but the adjacent
agreement version is similar. The main new addi-
tion is that the inner loop of the algorithm ensures
that the count vector d is the sum of the counts of
its children d
?
and d? d
?
.
Since each additional constraint adds a dimen-
sion to d, adding constraints has a multiplicative
impact on running time. Asymptotically the new
algorithm requires O(2
||p||
1
IJ(I + J)) time. This
is a problem in practice as even adding a few con-
straints can make the problem intractable. We ad-
dress this issue in the next section.
6 Pruning
Re-introducing constraints can lead to an expo-
nential blow-up in the search space of the Viterbi
algorithm. In practice though, many alignments
in this space are far from optimal, e.g. align-
ing a common word like the to nous instead
of les. Since Lagrangian relaxation re-computes
the alignment many times, it would be preferable
to skip these links in later rounds, particularly after
re-introducing constraints.
In this section we describe an optimality pre-
serving coarse-to-fine algorithm for pruning. Ap-
proximate coarse-to-fine pruning algorithms are
procedure CONSVITERBIFULL(?, ?
?
, p)
for i ? [I], j ? [J ]
0
, i
?
? [I] do
d? |?(i, j)? ?(i
?
, j ? 1)|
D
?[i, j, d]? ?
?
(i
?
, i, j)
for j ? [J ], d ? D do
pi[0, 0, d]? max
d
?
?D
pi[0, 0, d
?
] + ?[0, j, d? d
?
]
for i ? [I], j ? [J ]
0
, d ? D do
if j = 0 then
pi[i, j, d]? max
j
?
?[J]
0
?(j
?
, i, j) + pi[i? 1, j
?
, d]
else
pi[i, j, d]?
max
j
?
?[J]
0
,d
?
?D
?(j
?
, i, j) + pi[i? 1, j
?
, d
?
]
+?[i, j, d? d
?
]
return max
j?[J]
0
pi[I, j,0]
Figure 6: Constrained Viterbi algorithm for finding partially-
constrained, full-agreement alignments. The argument p in-
dicates which constraints to enforce.
widely used within NLP, but exact pruning is
less common. Our method differs in that it
only eliminates non-optimal transitions based on
a lower-bound score. After introducing the prun-
ing method, we present an algorithm to make this
method effective in practice by producing high-
scoring lower bounds for adjacent agreement.
6.1 Thresholding Max-Marginals
Our pruning method is based on removing transi-
tions with low max-marginal values. Define the
max-marginal value of an e?f transition in our
Lagrangian dual as
M(j
?
, i, j;?) = max
z?Z(x,y),
x?X ,y?Y
?
f(x) + g
?
(y;?) + h(z)
s.t. x(j
?
, i, j) = 1
where M gives the value of the best dual align-
ment that transitions from (i ? 1, j
?
) to (i, j).
These max-marginals can be computed by running
a forward-backward variant of any of the algo-
rithms described thus far.
We make the following claim about max-
marginal values and any lower-bound score
Lemma 1 (Safe Pruning). For any valid con-
strained alignment x ? X , y ? Y, z ? Z(x, y)
and for any dual vector ? ? R
[I?1]
0
?[J ]
0
, if there
exists a transition j
?
, i, j with max-marginal value
M(j
?
, i, j;?) < f(x)+g(y)+h(z) then the tran-
sition will not be in the optimal alignment, i.e.
x
?
(j
?
, i, j) = 0.
This lemma tells us that we can prune transi-
tions whose dual max-marginal value falls below
1486
a threshold without pruning possibly optimal tran-
sitions. Pruning these transitions can speed up La-
grangian relaxation without altering its properties.
Furthermore, the threshold is determined by any
feasible lower bound on the optimal score, which
means that better bounds can lead to more pruning.
6.2 Finding Lower Bounds
Since the effectiveness of pruning is dependent on
the lower bound, it is crucial to be able to produce
high-scoring alignments that satisfy the agreement
constraints. Unfortunately, this problem is non-
trivial. For instance, taking the union of direc-
tional alignments does not guarantee a feasible so-
lution; whereas taking the intersection is trivially
feasible but often not high-scoring.
To produce higher-scoring feasible bidirectional
alignments we introduce a greedy heuristic al-
gorithm. The algorithm starts with any feasible
alignment (x, y, z). It runs the following greedy
loop:
1. Repeat until there exists no x(i, 0) = 1 or
y(0, j) = 1, or there is no score increase.
(a) For each i ? [I], j ? [J ]
0
, k ? K :
x(i, 0) = 1, check if x(i, j) ? 1 and
y(i, j + k) ? 1 is feasible, remember
score.
(b) For each i ? [I]
0
, j ? [J ], k ? K :
y(0, j) = 1, check if y(i, j) ? 1 and
x(i + k, j) ? 1 is feasible, remember
score.
(c) Let (x, y, z) be the highest-scoring fea-
sible solution produced.
This algorithm produces feasible alignments with
monotonically increasing score, starting from the
intersection of the alignments. It has run-time of
O(IJ(I + J)) since each inner loop enumerates
IJ possible updates and assigns at least one index
a non-zero value, limiting the outer loop to I + J
iterations.
In practice we initialize the heuristic based on
the intersection of x and y at the current round
of Lagrangian relaxation. Experiments show that
running this algorithm significantly improves the
lower bound compared to just taking the intersec-
tion, and consequently helps pruning significantly.
7 Related Work
The most common techniques for bidirectional
alignment are post-hoc combinations, such as
union or intersection, of directional models, (Och
et al, 1999), or more complex heuristic combiners
such as grow-diag-final (Koehn et al, 2003).
Several authors have explored explicit bidirec-
tional models in the literature. Cromieres and
Kurohashi (2009) use belief propagation on a fac-
tor graph to train and decode a one-to-one word
alignment problem. Qualitatively this method is
similar to ours, although the model and decoding
algorithm are different, and their method is not
able to provide certificates of optimality.
A series of papers by Ganchev et al (2010),
Graca et al (2008), and Ganchev et al (2008) use
posterior regularization to constrain the posterior
probability of the word alignment problem to be
symmetric and bijective. This work acheives state-
of-the-art performance for alignment. Instead of
utilizing posteriors our model tries to decode a sin-
gle best one-to-one word alignment.
A different approach is to use constraints at
training time to obtain models that favor bidi-
rectional properties. Liang et al (2006) propose
agreement-based learning, which jointly learns
probabilities by maximizing a combination of
likelihood and agreement between two directional
models.
General linear programming approaches have
also been applied to word alignment problems.
Lacoste-Julien et al (2006) formulate the word
alignment problem as quadratic assignment prob-
lem and solve it using an integer linear program-
ming solver.
Our work is most similar to DeNero and
Macherey (2011), which uses dual decomposition
to encourage agreement between two directional
HMM aligners during decoding time.
8 Experiments
Our experimental results compare the accuracy
and optimality of our decoding algorithm to direc-
tional alignment models and previous work on this
bidirectional model.
Data and Setup The experimental setup is iden-
tical to DeNero and Macherey (2011). Evalu-
ation is performed on a hand-aligned subset of
the NIST 2002 Chinese-English dataset (Ayan and
Dorr, 2006). Following past work, the first 150
sentence pairs of the training section are used for
evaluation. The potential parameters ? and ? are
set based on unsupervised HMM models trained
on the LDC FBIS corpus (6.2 million words).
1487
1-20 (28%) 21-40 (45%) 41-60 (27%) all
time cert exact time cert exact time cert exact time cert exact
ILP 15.12 100.0 100.0 364.94 100.0 100.0 2,829.64 100.0 100.0 924.24 100.0 100.0
LR 0.55 97.6 97.6 4.76 55.9 55.9 15.06 7.5 7.5 6.33 54.7 54.7
CONS 0.43 100.0 100.0 9.86 95.6 95.6 61.86 55.0 62.5 21.08 86.0 88.0
D&M - 6.2 - - 0.0 - - 0.0 - - 6.2 -
Table 1: Experimental results for model accuracy of bilingual alignment. Column time is the mean time per sentence pair in
seconds; cert is the percentage of sentence pairs solved with a certificate of optimality; exact is the percentage of sentence pairs
solved exactly. Results are grouped by sentence length. The percentage of sentence pairs in each group is shown in parentheses.
Training is performed using the agreement-based
learning method which encourages the directional
models to overlap (Liang et al, 2006). This direc-
tional model has been shown produce state-of-the-
art results with this setup (Haghighi et al, 2009).
Baselines We compare the algorithm described
in this paper with several baseline methods. DIR
includes post-hoc combinations of the e?f and
f?e HMM-based aligners. Variants include
union, intersection, and grow-diag-final. D&M is
the dual decomposition algorithm for bidirectional
alignment as presented by DeNero and Macherey
(2011) with different final combinations. LR is the
Lagrangian relaxation algorithm applied to the ad-
jacent agreement problem without the additional
constraints described in Section 5. CONS is our
full Lagrangian relaxation algorithm including in-
cremental constraint addition. ILP uses a highly-
optimized general-purpose integer linear program-
ming solver to solve the lattice with the constraints
described (Gurobi Optimization, 2013).
Implementation The main task of the decoder
is to repeatedly compute the argmax of L(?).
To speed up decoding, our implementation fully
instantiates the Viterbi lattice for a problem in-
stance. This approach has several benefits: each
iteration can reuse the same lattice structure; max-
marginals can be easily computed with a gen-
eral forward-backward algorithm; pruning corre-
sponds to removing lattice edges; and adding con-
straints can be done through lattice intersection.
For consistency, we implement each baseline (ex-
cept for D&M) through the same lattice.
Parameter Settings We run 400 iterations of
the subgradient algorithm using the rate schedule
?
t
= 0.95
t
?
where t
?
is the count of updates for
which the dual value did not improve. Every 10
iterations we run the greedy decoder to compute
a lower bound. If the gap between our current
dual value L(?) and the lower bound improves
significantly we run coarse-to-fine pruning as de-
scribed in Section 6 with the best lower bound. For
Model Combiner
alignment phrase pair
Prec Rec AER Prec Rec F1
DIR
union 57.6 80.0 33.4 75.1 33.5 46.3
intersection 86.2 62.9 27.0 64.3 43.5 51.9
grow-diag 59.7 79.5 32.1 70.1 36.9 48.4
D&M
union 63.3 81.5 29.1 63.2 44.9 52.5
intersection 77.5 75.1 23.6 57.1 53.6 55.3
grow-diag 65.6 80.6 28.0 60.2 47.4 53.0
CONS 72.5 74.9 26.4 53.0 52.4 52.7
Table 2: Alignment accuracy and phrase pair extraction ac-
curacy for directional and bidirectional models. Prec is the
precision. Rec is the recall. AER is alignment error rate and
F1 is the phrase pair extraction F1 score.
CONS, if the algorithm does not find an optimal
solution we run 400 more iterations and incremen-
tally add the 5 most violated constraints every 25
iterations.
Results Our first set of experiments looks at the
model accuracy and the decoding time of various
methods that can produce optimal solutions. Re-
sults are shown in Table 1. D&M is only able to
find the optimal solution with certificate on 6% of
instances. The relaxation algorithm used in this
work is able to increase that number to 54.7%.
With incremental constraints and pruning, we are
able to solve over 86% of sentence pairs includ-
ing many longer and more difficult pairs. Addi-
tionally the method finds these solutions with only
a small increase in running time over Lagrangian
relaxation, and is significantly faster than using an
ILP solver.
Next we compare the models in terms of align-
ment accuracy. Table 2 shows the precision, recall
and alignment error rate (AER) for word align-
ment. We consider union, intersection and grow-
diag-final as combination procedures. The com-
bination procedures are applied to D&M in the
case when the algorithm does not converge. For
CONS, we use the optimal solution for the 86%
of instances that converge and the highest-scoring
greedy solution for those that do not. The pro-
posed method has an AER of 26.4, which outper-
forms each of the directional models. However,
although CONS achieves a higher model score
than D&M, it performs worse in accuracy. Ta-
1488
1-20 21-40 41-60 all
# cons. 20.0 32.1 39.5 35.9
Table 3: The average number of constraints added for sen-
tence pairs where Lagrangian relaxation is not able to find an
exact solution.
ble 2 also compares the models in terms of phrase-
extraction accuracy (Ayan and Dorr, 2006). We
use the phrase extraction algorithm described by
DeNero and Klein (2010), accounting for possi-
ble links and  alignments. CONS performs bet-
ter than each of the directional models, but worse
than the best D&M model.
Finally we consider the impact of constraint ad-
dition, pruning, and use of a lower bound. Table 3
gives the average number of constraints added for
sentence pairs for which Lagrangian relaxation
alone does not produce a certificate. Figure 7(a)
shows the average over all sentence pairs of the
best dual and best primal scores. The graph com-
pares the use of the greedy algorithm from Sec-
tion 6.2 with the simple intersection of x and y.
The difference between these curves illustrates the
benefit of the greedy algorithm. This is reflected
in Figure 7(b) which shows the effectiveness of
coarse-to-fine pruning over time. On average, the
pruning reduces the search space of each sentence
pair to 20% of the initial search space after 200
iterations.
9 Conclusion
We have introduced a novel Lagrangian relaxation
algorithm for a bidirectional alignment model that
uses incremental constraint addition and coarse-
to-fine pruning to find exact solutions. The algo-
rithm increases the number of exact solution found
on the model of DeNero and Macherey (2011)
from 6% to 86%.
Unfortunately despite achieving higher model
score, this approach does not produce more accu-
rate alignments than the previous algorithm. This
suggests that the adjacent agreement model may
still be too constrained for this underlying task.
Implicitly, an approach with fewer exact solu-
tions may allow for useful violations of these con-
straints. In future work, we hope to explore bidi-
rectional models with soft-penalties to explicitly
permit these violations.
A Proof of NP-Hardness
We can show that the bidirectional alignment
problem is NP-hard by reduction from the trav-
0 50 100 150 200 250 300 350 400iteration
100
50
0
50
100
sco
re 
rel
ati
ve 
to 
opt
ima
l best dualbest primal
intersection
(a) The best dual and the best primal score, relative to the
optimal score, averaged over all sentence pairs. The best
primal curve uses a feasible greedy algorithm, whereas the
intersection curve is calculated by taking the intersec-
tion of x and y.
0 50 100 150 200 250 300 350 400number of iterations
0.0
0.2
0.4
0.6
0.8
1.0
rel
ati
ve 
sea
rch
 sp
ace
 siz
e
(b) A graph showing the effectiveness of coarse-to-fine prun-
ing. Relative search space size is the size of the pruned lattice
compared to the initial size. The plot shows an average over
all sentence pairs.
Figure 7
eling salesman problem (TSP). A TSP instance
with N cities has distance c(i
?
, i) for each (i
?
, i) ?
[N ]
2
. We can construct a sentence pair in which
I = J = N and -alignments have infinite cost.
?(i
?
, i, j) = ?c(i
?
, i) ?i
?
? [N ]
0
, i ? [N ], j ? [N ]
?(j
?
, i, j) = 0 ?j
?
? [N ]
0
, i ? [N ], j ? [N ]
?(i
?
, 0, j) = ?? ?i
?
? [N ]
0
, j ? [N ]
?(j
?
, i, 0) = ?? ?j
?
? [N ]
0
, i ? [N ]
Every bidirectional alignment with finite objec-
tive score must align exactly one word in e to each
word in f, encoding a permutation a. Moreover,
each possible permutation has a finite score: the
negation of the total distance to traverse the N
cities in order a under distance c. Therefore, solv-
ing such a bidirectional alignment problem would
find a minimal Hamiltonian path of the TSP en-
coded in this way, concluding the reduction.
Acknowledgments Alexander Rush, Yin-Wen
Chang and Michael Collins were all supported
by NSF grant IIS-1161814. Alexander Rush was
partially supported by an NSF Graduate Research
Fellowship.
1489
References
Necip Fazil Ayan and Bonnie J Dorr. 2006. Going
beyond aer: An extensive analysis of word align-
ments and their impact on mt. In Proceedings of
the 21st International Conference on Computational
Linguistics and the 44th annual meeting of the Asso-
ciation for Computational Linguistics, pages 9?16.
Association for Computational Linguistics.
Peter F Brown, Vincent J Della Pietra, Stephen A Della
Pietra, and Robert L Mercer. 1993. The mathemat-
ics of statistical machine translation: Parameter esti-
mation. Computational linguistics, 19(2):263?311.
Fabien Cromieres and Sadao Kurohashi. 2009. An
alignment algorithm using belief propagation and a
structure-based distortion model. In Proceedings
of the 12th Conference of the European Chapter
of the Association for Computational Linguistics,
pages 166?174. Association for Computational Lin-
guistics.
John DeNero and Dan Klein. 2010. Discriminative
modeling of extraction sets for machine translation.
In Proceedings of the 48th Annual Meeting of the
Association for Computational Linguistics, pages
1453?1463. Association for Computational Linguis-
tics.
John DeNero and Klaus Macherey. 2011. Model-
based aligner combination using dual decomposi-
tion. In ACL, pages 420?429.
Kuzman Ganchev, Jo?ao V. Grac?a, and Ben Taskar.
2008. Better alignments = better translations?
In Proceedings of ACL-08: HLT, pages 986?993,
Columbus, Ohio, June. Association for Computa-
tional Linguistics.
K. Ganchev, J. Grac?a, J. Gillenwater, and B. Taskar.
2010. Posterior Regularization for Structured La-
tent Variable Models. Journal of Machine Learning
Research, 11:2001?2049.
Joao Graca, Kuzman Ganchev, and Ben Taskar. 2008.
Expectation maximization and posterior constraints.
In J.C. Platt, D. Koller, Y. Singer, and S. Roweis,
editors, Advances in Neural Information Processing
Systems 20, pages 569?576. MIT Press, Cambridge,
MA.
Inc. Gurobi Optimization. 2013. Gurobi optimizer ref-
erence manual.
Aria Haghighi, John Blitzer, John DeNero, and Dan
Klein. 2009. Better word alignments with su-
pervised itg models. In Proceedings of the Joint
Conference of the 47th Annual Meeting of the ACL
and the 4th International Joint Conference on Natu-
ral Language Processing of the AFNLP: Volume 2-
Volume 2, pages 923?931. Association for Compu-
tational Linguistics.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In
Proceedings of the 2003 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics on Human Language Technology-
Volume 1, pages 48?54. Association for Computa-
tional Linguistics.
Simon Lacoste-Julien, Ben Taskar, Dan Klein, and
Michael I Jordan. 2006. Word alignment via
quadratic assignment. In Proceedings of the main
conference on Human Language Technology Con-
ference of the North American Chapter of the As-
sociation of Computational Linguistics, pages 112?
119. Association for Computational Linguistics.
Percy Liang, Ben Taskar, and Dan Klein. 2006. Align-
ment by agreement. In Proceedings of the main
conference on Human Language Technology Con-
ference of the North American Chapter of the As-
sociation of Computational Linguistics, pages 104?
111. Association for Computational Linguistics.
Robert C Moore. 2005. A discriminative framework
for bilingual word alignment. In Proceedings of
the conference on Human Language Technology and
Empirical Methods in Natural Language Process-
ing, pages 81?88. Association for Computational
Linguistics.
Franz Josef Och, Christoph Tillmann, Hermann Ney,
et al 1999. Improved alignment models for statis-
tical machine translation. In Proc. of the Joint SIG-
DAT Conf. on Empirical Methods in Natural Lan-
guage Processing and Very Large Corpora, pages
20?28.
Alexander M Rush and Michael Collins. 2012. A tuto-
rial on dual decomposition and lagrangian relaxation
for inference in natural language processing. Jour-
nal of Artificial Intelligence Research, 45:305?362.
Stephan Vogel, Hermann Ney, and Christoph Tillmann.
1996. Hmm-based word alignment in statistical
translation. In Proceedings of the 16th conference
on Computational linguistics-Volume 2, pages 836?
841. Association for Computational Linguistics.
1490
