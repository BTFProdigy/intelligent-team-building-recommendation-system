A Transformational-based Learner for Dependency Grammars in 
Discharge Summaries 
David A. Campbell M. Phil., Stephen B. Johnson Ph.D. 
Department of Medical Informatics, Columbia University 
 
Abstract 
NLP systems will be  more portable 
among medical domains if acquisition 
of semantic lexicons can be 
facilitated.  We are pursuing lexical 
acquisition through the syntactic 
relationships of words in medical 
corpora.  Therefore we require a 
syntactic parser which is flexible, 
portable, captures head-modifier pairs 
and does not require a large training 
set.  We have designed a dependency 
grammar parser that learns through a 
transformational-based algorithm.  
We propose a novel design for 
templates and transformations which 
capitalize on the dependency structure 
directly and produces human-readable 
rules.  Our parser achieved a 77% 
accurate parse training on only 830 
sentences.  Further work will evaluate 
the usefulness of this parse for lexical 
acquisition. 
1 Introduction 
Natural Language is a vital medium in 
medicine.  Health care providers rely on medical 
narratives for recording, representing and 
sharing complex medical information such as 
the description of images, explanation of test 
results, or the summary of a patient?s hospital 
visit.  Natural Language Processing (NLP) tools 
have been applied to medical narrative for a 
variety of applications, such as triggering 
clinical alerts (Friedman, 1997) and document 
classification (Wilcox, 2000). 
The effort required to create and maintain 
NLP systems in the medical setting can be 
prohibitive.  Most language processors require a 
domain-specific semantic lexicon to function 
and, so far, these lexica have been created 
manually.  The time and cost involved in 
creating these knowledge structures put limits 
on the extensibility and portability of NLP 
systems (Hripcsak, 1998). One solution to this 
bottleneck is to use machine learning to assist in 
categorizing lexemes into semantic classes.  
Such a tool could reduce the difficulty in porting 
NLP systems from one domain to another. 
2 Dependency Grammars 
One approach to semantic categorization is 
the use of syntactic features (Kokkinakis, 2001).  
This is based on the assumption that lexemes 
that share similar syntactic relations to other 
lexemes in the corpus will be semantically 
similar (Dorr, 2000).  The idea of clustering 
words based on syntactic features has been well 
investigated in general language (Pereira, 1993; 
Li, 1998)  However, (Harris, 1991) states that 
the syntactic relationships are more well-defined 
and have less variation in scientific languages  
(sublanguages), such as the ones used in medical 
texts.  Identifying word classes using syntactic 
relationships should be simpler and potentially 
more useful in these types of languages.   
Dependency grammars (Hudson, 1991) 
generate parses where words in a sentence are 
related directly to the word which is its syntactic 
head.  Each word, except for the root has exactly 
one head, and the structure is a tree.  The 
analysis does not generate any intermediate 
syntactic structures.  Figure 1 shows an example 
of a sentence with a dependency grammar parse.  
There has been interest in learning dependency 
grammars from corpora.  Collins (Collins, 1996) 
used dependencies as the backbone for his 
probabilistic parser and there has been work on 
learning both probabilistic (Carroll, 1992; Lee, 
1999; Paskin, 2001) and transformation based 
dependency grammars (Hajic, 1997).   
There are a number of attributes of 
dependency grammars which make them ideal 
for our goal of investigating medical 
sublanguage.  First, the semantics of a word are 
often defined by a feature space of related 
words.  The head-dependent relationships 
generated by a dependency parse can be used as 
the relationship for acquisition.  Second, 
dependency grammars may be a better fit for 
parsing medical text.  Medical text is frequently 
                                            Association for Computational Linguistics.
                            the Biomedical Domain, Philadelphia, July 2002, pp. 37-44.
                         Proceedings of the Workshop on Natural Language Processing in
include telegraphic omissions, run-on structures, 
improper use of conjunctions, left attaching 
noun modifiers etc (Sager, 1981). In many 
cases, many traditional phrase structures are 
absent or altered, making a phrase structure 
parse using traditional production rules difficult.  
A dependency grammar may still capture useful 
syntactic relationships when an accurate phrase 
grammar parse is not possible.  In this way, a 
dependency parse may be compared to a 
shallow parse, in that it can return a partial 
analysis.  However, even with a shallow parser, 
we would still interested in the dependency 
relationships inside the chunks.  Third, the 
syntactic grammar of medical English, 
specifically regarding discharge summaries, is 
simpler overall (Campbell, 2001).  We are not 
interested so much in the labeling of 
intermediate syntactic structures, such as noun 
phrases and prepositional phrases.  Dependency 
grammars may allow us to capitalize on the 
relative syntactic simplicity of medical language 
without the overhead of generating and 
identifying structures which will not be used. 
 
 
 
 
 
 
 
Figure 1.  Dependency grammar parse of the 
sentence ?In general she was sleeping quietly.? 
 
The dependency grammar used in this 
experiment did not allow crossing dependencies 
(projectivity).  Crossing dependencies are ones 
where the parent and child of a relationship are 
on opposite sides of a common ancestor.   
3 Transformational Based 
Learning 
Transformational Based Learning (TBL) has 
been applied to numerous language learning 
problems, including part-of-speech tagging 
(Brill, 1994) , and parsing (Florian, 1998).  It 
also has been used for learning dependency 
grammars (Hajic, 1997).  In general, TBL 
algorithms generate smaller rule sets and require 
less training material than probabilistic 
approaches.  Brill produced a part-of-speech 
tagger which was comparable in accuracy to 
other tagging methods.   
In language, the general paradigm for TBL is 
to generate logical rules which apply 
transformations to the text.  The training text  is 
first annotated with the goal state.  In this case, 
the sentences would be assigned a dependency 
parse.  An initial state annotator is then applied 
to an unannotated copy of the text.  For 
example, a right branching dependency tree was 
used in our experiment as the initial state 
(compare figure 1 and figure 2).  The goal of 
TBL is to then generate rules which transform 
the na?ve training state into the goal state.  In 
order to do so, the TBL algorithm will have 
templates which describe the environment in the 
training corpus where a transformation can 
occur.  The algorithm also has a scoring 
function which allows the comparison of the 
training state to the goal state.  After iterating 
through the training corpus and testing all 
combinations of templates and transformations, 
the paired template and transformation which 
has the highest score  becomes a rule.  In other 
words, the best rule is the one which results in a 
corpus closest to the goal state after applying the 
transformation at the locations indicated by the 
template.  This best rule is applied to the 
training corpus to produce a refined corpus.  The 
process is then repeated, using the refined 
corpus as the training corpus, until no more 
positively scoring rules are produced.  The final 
product is an ordered set of rules which can be 
applied to any unannotated corpus. 
 
 
 
 
 
 
 
 
 
Figure 2.  The initial dependency parse of the 
sentence ?In general she was sleeping quietly.? 
 
TBL is a good choice for learning a 
dependency grammar of medical language.  
Assigning dependency heads is a task that is 
similar to part-of-speech tagging; each word in 
the text has exactly one dependency head, 
represented by the index of the head word.  
Transformations to this representation consist of 
. 
was/VBD 
general/JJ 
she/PN sleeping/VBG 
quietly/RB 
In/IN 
. 
was/VBD 
general/JJ 
she/PN 
quietly/RB 
sleeping/VBG 
In/IN 
changing a word?s dependency head from one 
word to another. 
4     The Learning Algorithm 
4.1 Template Design 
In TBL, transformations occur when a 
specific environment in the text is found.  These 
environments, or triggers, are defined by the 
proximal relationship of two or more parts of 
speech within a sentence.  For example, in 
Brill?s early work with POS tagging, one trigger 
was the existence of another specific POS tag 
immediately preceding the one to be 
transformed.  The triggers, therefore, compose 
the ?if? component of the ?if-then? 
transformational rules.    
When considering what triggers would be 
appropriate for dependency grammars, it was 
noted that many arcs in the grammar span a 
number of words.  For example, the arc between 
a verb and the head of a noun phrase may span 
many words, especially in medical narratives 
where noun phrases can be especially lengthy.  
In previous attempts to parse language using 
TBL templates, the triggers have been tokens in 
the vicinity of the token to be transformed.  
While this has been successful for POS tagging, 
where the context necessary to correctly 
transform the tag may be found within two or 
three surrounding tokens, the distance of some 
dependency relationships can be much greater.  
In order to capture long distance relationships 
explicitly in a trigger, it would be necessary to 
expand the vicinity to be searched.   
In the case of a dependency grammar parse, 
words are related to each other not only through 
their left-to-right arrangement, but also through 
the dependency tree.  We sought to design  
triggers that take advantage of the dependency 
tree itself.  Using the dependency relationships 
directly in the trigger is in the spirit of TBL 
where learning must change the triggering 
environments in the corpus from one iteration to 
the next.  For example, in the case of POS tag 
learning, newly learned POS tags are used in 
subsequent iterations of the algorithm as 
triggers.  Similarly, by using the dependency 
relationship directly in the trigger, we would 
expect the learner to capitalize on parse 
improvements through the learning process. 
Each trigger used in this experiment had six 
parameters, which defined the vicinity around a 
target token, summarized in figure 3.  Triggers 
can search using solely word distance, tree 
distance, or a combination of both.  Any 
template can have multiple triggers, requiring 
multiple criteria to be met before considered 
true. 
Figure 3.  Trigger design and examples 
 
The parameters of direction and distance are 
self-explanatory.  Scope defines whether or not 
the triggering token must be exactly at the 
location defined by the distance, or within that 
distance.  The third setting for scope is a special 
case.  If the scope is set to all the template will 
search all tokens in the direction set, regardless 
of distance (e.g. if the tree direction is set to left 
and the scope is set to all, the trigger will match 
all tokens to the left, regardless of distance).  
 
Trigger parameters 
 
1.  Word distance 
2.  Word direction (left, right, either) 
3.  Word scope (exactly at, within, all) 
4.  Tree distance 
5.  Tree direction (parent, child, either) 
6.  Tree scope (exactly at, within, all) 
 
Example 1. 
 
 
 
 
 
 
 
Trigger: 
W-dist = 2  W-dir = right  W-scp = within 
T-dist  = 1   T-dir  = child  T-scp = within  
 
Example 2 
 
 
 
 
 
 
 
Trigger: 
W-dist = 2  W-dir = right  W-scp = ex. at. 
T-dist  = 2   T-dir  = par   T-scp  =  ex. at 
x 
1 
2 
x 
2 
2 
Two examples of triggers are given in figure 3.  
In both cases the triggers are searching for 
elements near token x which meet the correct 
criteria.  In the first example, the trigger criteria 
will be met by any token within the shaded area 
of the tree, those tokens which are either one or 
two tokens to the right of x and are descendents 
of x with a tree distance of one.  The second 
trigger will match a single token, shown as a 
black circle, that is exactly two tokens to the 
right of x and is also an ancestor of tree distance 
two.   
4.2 Transformations 
The second principal component of a TBL 
rule is the transformation, which defines a 
change to the structure of the sentence.  For 
example, in the case of POS tagging, the 
transformation would be to change POS tag x to 
POS tag y.  When TBL has been applied to 
parsing, the transformations have been on 
bracketed parse trees and have added or deleted 
brackets in a balanced method.  Where the 
transformations seem intuitive for POS tagging, 
they are not as transparent for parsing.  A rule 
for POS tagging may read, ?If tag x is DT and 
tag y immediately to the right is VB, change  tag 
y to NN.? (see figure 4)  This makes sense, for 
we do not expect verbs to immediately trail 
determiners, and transforming the verb to a noun 
would likely correct an error.  A rule for parsing 
may read ?If a bracket is immediately left of 
NN, delete a bracket to the left of the NN.?  This 
rule will combine a phrase which has a noun as 
the left-most component with the phrase which 
covers it.  While this makes some sense, as 
many phrases do not have nouns as their left-
most component, there are also many phrases 
which do.    The linguistic motivation behind the  
transformation is not immediately obvious. 
 
We wanted to give our transformations 
the intuitive readability of the rules seen in the 
POS tagging rules.  In the case of our 
dependency grammar, we wanted our 
transformations to describe changes made 
directly to the tree.  We considered four ways in 
which one token in the tree could be moved in 
relation to another outlined in figure 5.  All four 
of the transformations decompose to the first 
transform. These transformations make intuitive 
sense for dependency grammars.  We want to 
identify tokens in the text which are in the 
incorrect tree configuration and transform the 
tree by changing the dependency relationships.  
For example, the transformations ?Make a noun 
the child of a verb? or ?Make adjectives siblings 
of each other? are both readable in English and 
are linguistically reasonable. 
 
Figure 4. Examples of applying 
transformations in POS tagging and parsing 
 
Some transformations are disallowed in the 
special case that the root node is involved.  The 
root node has no parent and can have no siblings 
and therefore transformations which would 
create these circumstances are not allowed.  The 
shape of the dependency tree is restricted in 
other ways as described above, in that the trees 
have no crossing dependencies.  These 
restrictions are not enforced by the 
transformations and it is possible that they could 
generate trees that violate these restrictions. 
4.3 Rule Scoring 
At every iteration, it is necessary to evaluate the 
goodness of the parse that results from the 
application of all tested rules.  The rule which 
produces the best parse for that iteration is the 
one that is chosen and applied before continuing 
on to the next iteration.  A number of measures 
for measuring parsing accuracy have been 
established, including bracketing sensitivity and 
specificity.  Parsing accuracy for dependency 
Part-of-speech rule application 
 
Before:  The/DT fly/VB on/IN the/DT wall/NN 
 
Apply Rule: If VB right of DT change VB to NN 
 
After:    The/DT fly/NN on/IN the/DT wall/NN 
 
Bracketed-tree rule application 
 
Before: 
 
 
(((The/DT (fly/NN on/IN)) the/DT) wall/NN) 
 
Apply Rule:  If ?(? left of NN delete ?(? on left 
 
After 
 
(((The/DT fly/NN on/IN) the/DT) wall/NN) 
grammars is often measured as a function of the 
number of tokens which have the correct 
ancestors, or dependency accuracy.  Keeping 
our goal of generating word-modifier pairs for 
subsequent machine learning, we chose an 
aggressive scoring function, counting only 
correct parent-child relationships.  This also 
keeps the scoring function as simple as possible. 
 
 
 
 
Dependency grammar transformations 
 
1.  Make x the child of y 
 
 
 
 
 
2.  Make x the parent of y 
 
 
 
 
3.  Make x the sibling of y keeping x?s 
parent 
 
 
 
 
 
 
4. Make x the sibling of y keeping y?s 
parent 
 
 
 
 
 
 
Figure 5.  The four basic transformations 
4.4 The Algorithm 
The general design of TBL algorithms has 
been well described (Brill, 1994).  The essential 
components, outlined above, include the 
template design, the transformations used, and 
the scoring system.  The initial state of the 
dependency tree is the right branching tree 
shown in figure 2.  To improve efficiency, we 
use the indexed TBL method  outlined by 
Ramshaw and Marcus (Ramshaw, 1994).  Rules 
have pointers to the sentences to which they 
apply, and similarly each sentence has pointers 
to the rules which have applied to it in the past.  
Rules are held on a heap based on their score, 
allowing the best rule to be found immediately 
after each iteration.  The rule is applied to the 
list of sentences to which it points, and this list 
is used in the next iteration so no sentences 
which have not been modified need be seen. 
5 Methods 
A corpus of 1000 sentences (16,949 words) 
of text from medical discharge summaries was 
split into a training set of 830 sentences (13,954 
words) and a test set of 170 sentences (2,995 
words).  The entire corpus was first POS tagged 
using a tagger trained specifically for discharge 
summaries (Campbell, 2001).  The corpus was 
then hand parsed with a dependency grammar, 
and the TBL learner was allowed to learn rules 
on the training set.  The sentences in the corpus 
were not restricted by length.  Three sets of 
increasingly complex templates were used to 
learn rules, summarized in figure 6. 
 
Figure 6. Three template sets used 
Corpus score =  # correct dependencies 
 
Template Set #1 
1.  Word distance: 
2.  Word direction: 
3.  Word scope:  
4.  Tree distance:  
5. Tree direction:  
6. Tree scope:  
 
1, 2, or 3 
left, right, or either 
exactly at, within, or all 
not used 
not used 
not used 
Template Set #2  
1.  Word distance:  
2.  Word direction:  
3.  Word scope:  
4.  Tree distance: 
5. Tree direction:  
6. Tree scope:  
all of set 1, and . . . 
not used 
not used 
not used 
1, 2, or 3 
child, parent or either 
exactly at, within, or all 
Template Set #3  
1.  Word distance:  
2.  Word direction:  
3.  Word scope: 
4.  Tree distance:  
5. Tree direction:  
6. Tree scope:  
all of set 1, 2, and. . .  
1,2 or 3 
left, right, or either 
exactly at, within, or all 
1, 2, or 3 
child, parent or either 
exactly at, within, or all 
x y y 
x 
x y 
y 
x 
x 
y z 
x 
z 
y 
x w 
x 
w 
y y 
# of dependencies in corpus 
6 Results 
The three template sets generated three rule 
sets, each of which was evaluated on the 170 
sentence test set.  Each template set was trained 
with increasing amounts of the training corpus 
to measure the effect of the training set size on 
the learner?s accuracy.  Chart 1 shows the 
improvement in accuracy gained through larger 
training sets.  The best dependency accuracy and 
number of rules generated for each template set 
is reported in table 1.  
 
 
Table 1.  Results for three template sets used 
 
Table 2.  Effect of sentence length on accuracy 
 
 
To measure the effect of sentence length on 
parsing accuracy, the best parser rules were re-
tested on two subsets of the test sets.  The first 
subset contained sentences with a length less 
than ten words and the second contained 
sentences of length less than twenty.  The 
resulting accuracy of the parser on these 
sentences is summarized in table 2.  The top ten 
rules acquired with the third template set are 
reported in table 3. 
7 Discussion and Further Work 
For all sets of templates, the learner produced a 
rule-based parser with dependency accuracy 
exceeding 75% when sentence length was not 
restricted.  For the best parser generated, 
limiting the sentence length to 20 and 10 words 
improved the parsing accuracy to 80.1% and 
87.6%.  Little difference among the template 
sets was found, although the use of tree-based 
templates gave slightly better performance.  
Although we expected the inclusion of tree 
based templates to improve the performance of 
the parser by a greater extent than observed, it is 
significant that the learner was reasonably 
successful with only word-order information.  
The strongest syntactic dependencies in medical 
language may be local and the addition of the 
tree-oriented templates is not very significant.  
However, when the tree information is available, 
the learner does use it, as can be seen by the 
number of rules using tree information in the 
three sets shows (table 1).  For the third template 
set, 46% of the rules learned incorporated tree 
information. 
 
 
Base POS {POS of current token} 
Trig. POS      {POS to be found by trigger} 
W/T Dis {# of tokens trigger is from base} 
W Dir  {1 = right, -1 = left, 0 = either } 
T Dir  {1 = par, -1 = child, 0 = either } 
W/T Scp {1 = at, 2 = within, 3 = all} 
Xf   {1 = make child, 2 = make par} 
 
Table 3. First 5 rules learned by template set 3 
  
The rules generated are easily translated into 
English and make good linguistic sense.  The 
first rule in Table 2 reads ?If this is a singular 
noun (Base POS = NN) and there is a 
preposition (Trg POS = IN) within (W. scp = 2) 
three tokens (W. dis = 3) to the left (W. dir =-1) 
then make the preposition the parent of the 
noun.?  This is the type of rule we would expect 
to see, as it begins forming prepositional  
phrases attaching to prepositions on the left.  
The third rule uses information in the 
dependency tree, reading ?If this is a simple past 
verb and there is a singular noun that is the 
grandparent, make that noun the child of the 
verb.? 
Template 
Set 
Rules 
tested 
Parser  
Rules 
Tree 
Rules 
Parse 
acc. 
Set 1 48K+ 424 0 76.5% 
Set 2 93K+ 498 127 77.0% 
Set 3 187K+ 541 249 77.0% 
Test set Sentence 
length 
Total 
Sents. 
Avg.  
Length 
Parse 
acc. 
1 n <= 10 61 7.1 87.6% 
2 n <= 20 127 11.4 80.1% 
Full all n 200 17.9 77.0% 
 
 
Base 
POS 
Trg. 
POS 
W 
Dis 
W 
Dir 
W 
Scp 
T  
Dis 
T  
Dir 
T  
Scp 
Xf 
 
1 NN IN 3 -1 2 0 0 0 2 
2 IN NN -1 1 2 0 0 0 2 
3 VBD NN 0 0 0 2 1 1 1 
4 JJ NN 2 1 2 0 0 0 2 
5 VBD VBN 3 1 2 0 0 0 1 
0.65
0.7
0.75
0.8
0 100 200 300 400 500 600 700 800 900
Training set size (sentences)
D
ep
en
de
nc
y 
ac
cu
ra
cy
Template Set 1
Template Set 2
Template Set 3
 
Chart 1. Effect of training set size on dependency accuracy for three template sets 
 
The greatest drawback to this approach is 
the computing requirements.  The consequence 
of the complex template design used is a large 
number of rules which need to be kept in 
memory.  The third template set generated over 
187,000 rules which need to be stored in 
memory.  Of these, only 240 rules were kept in 
the rule set.   Because each rule needs to store a 
list of pointers back to the sentences to which it 
applied, the size of a rule grows with the size of 
the training set.  It will be crucial to incorporate 
rule pruning in the future to allow larger training 
sets and more complex templates. 
Although the results shown here are for 
training on a specific corpus of discharge 
summaries, the learning algorithm itself is 
domain independent.  We foresee generating 
parsers on a number of medical corpora, 
including radiology reports, pathology reports 
and progress notes.  Therefore, we require a 
flexible solution that would not demand 
reengineering the parser for every new domain.  
The learning algorithm described here could be 
used on any general corpus where the sentences 
can be given a dependency parse.  We intend to 
evaluate the algorithm on more general corpora 
in the future. 
Overall, the results are very encouraging.  
Keeping in mind our goal of gathering head-
modifier pairs for machine learning, a 77% 
accurate parse is approaching an acceptable 
parse (Sekine, 1992).  The results also show that 
limiting the sentence length can improve the 
accuracy of the parser.   If our sole desire is the 
generation of head-modifier pairs, using a large 
number of shorter sentences may be equivalent 
to using fewer longer ones.  We also believe that 
the parser may be improved through 
lexicalization, but that remains future work. 
The ability to generate a good parser from 
such a small training set is important in the 
medical domain.  Previous work has shown that 
different medical domains have to be treated as 
separate languages for successful NLP 
(Friedman, 1995).  Therefore, it is likely that 
any medical domain we wish to parse will 
require its own training set for the parser.  If 
extensive training set preparation was required, 
then we are simply trading one difficult task for 
another: the task of manually creating and 
maintaining a semantic lexicon with the task of 
hand dependency-parsing large amounts of text.  
Although the task of hand-parsing 1,000 
sentences of discharge summaries is not trivial, 
it is reasonable and manageable and does not 
require extensive medical  knowledge.  The 
shift-reduce parser  described by (Hermjakob, 
1997) also requires relatively few  training 
examples but requires semantic features that 
may require  medical knowledge to construct 
and assign.  Although we do not propose here a 
specific application for a dependency grammar 
in a medical domain, we believe it will be 
valuable for future clustering, disambiguation  
and indexing applications.   
8 Conclusions 
Natural language processors in the medical 
domain will be more flexible and portable with 
assisted lexicon design.  The syntactic 
dependencies in a dependency grammar may be 
useful for the lexical acquisition necessary to 
make this possible.  We have investigated using 
transformational-based learning as a technique 
for learning a dependency grammar in a medical 
corpus.  To better learn dependency grammars 
we used a template design which uses the 
structure of the parse tree explicitly and 
transformations that operated directly on the 
trees.  Training on a set of 830 sentences of 
parsed medical discharge summaries gave a best 
parser with 77% accuracy.  The inclusion of tree 
information in the template design slightly 
improved the parser.  The rules produced were 
intuitive and understandable, and the limited 
amount of training material will allow the 
technique to be used on other medical domains 
without extensive manual parsing. Further work 
will test the utility of head-dependency 
relationships for machine learning semantic 
classes. 
References 
Brill, E. (1994). A report of recent progress in 
transformation-based error-driven learning. In 
Proceedings of the Twelfth National 
Conference on Artificial Intelligence, 
Princeton, NJ. 
Campbell, D.A., Johnson, S.B. (2001). 
Comparing Syntactic Complexity in Medical 
and non-Medical Corpora. In Proc AMIA 
Annu Fall Symp. 90-94. 
Carroll, G., Charniak, E. (1992). Two 
experiments on learning probabilistic 
dependency grammars from corpora. In 
Workshop Notes for Statistically-Based NLP 
Techniques, AAAI. 1-13. 
Collins, M. (1996.). A new statistical parser 
based on bigram lexical dependencies. In 
Proceedings of the 34th Annual Meeting of 
ACL. 184-191. 
Dorr, B. J.,  Jones, D. (2000). Acquisition of 
Semantic Lexicons: Using Word Sense 
Disambiguation to Improve Precision, in 
Evelyn Viegas (Ed), Breadth and Depth of 
Semantic Lexicons, Kluwer Academic 
Publishers: Norwell, MA, 79-98. 
Florian, R., Brill, E. (1998). Transformation 
Based Parsing. Ph.D. Qualifier Project, 
Computer Science Department, Johns Hopkins 
University. 
Friedman, C. (1997).  Towards a comprehensive 
medical language processing system: methods 
and issues. In Proc AMIA Annu Fall Symp. 
595-9. 
Friedman C, et. al (1995). Architectural 
requirements for a multipurpose natural 
language processor in the clinical 
environment.  In Proc 19th  Annu SCAMC. 
347-51. 
Hajic, J. and K. Ribarov (1997). Rule-Based 
Dependencies. Workshop on Empirical 
Learning of Natural Language Processing 
Tasks, Prague, Czech Republic. 
Harris, Z. (1991).  A Theory of Language and 
Information.  Oxford University Press:  
Oxford.   
Hermjakob U. & Mooney R.J. (1997) Learning 
Parse and Translation Decisions From 
Examples With Rich Context, Proc. of ACL-
EACL Conf. 482-489. 
Hripcsak, G., G. Kuperman, et al (1998). 
Extracting Findings from Narrative Reports:  
Software Transferability and Sources of 
Physician Disagreement. Methods Inf Med 37. 
1-7. 
Hudson, Richard. (1991). English Word 
Grammar. Blackwell:  Cambridge, Mass. 
Kokkinakis D. (2001),  Syntactic Parsing as a 
Step for Automatically Augmenting Semantic 
Lexicons, In Proceedings of the 39th ACL and 
the 10th EACL, Toulouse, France.  Student 
Workshop. 13-18. 
Lee, S. and K.-S. Choi (1999). A Reestimation 
Algorithm for Probabilistic Dependency 
Grammars. Natural Language Engineering  
5(3). 251-270. 
Li H. and Abe N.(1998). Word clustering and 
disambiguation based on co-occurrence data. 
In Proceedings of COLING - ACL'98. 749-
755 
Paskin, M. (2001). Grammatical Bigrams. In T. 
Dietterich, S. Becker, and Z. Gharahmani eds., 
Advances in Neural Information Processing 
Systems 14. MIT Press: Cambridge, MA.  
Pereira F., Tishby, N., Lee, L (1993). 
Distributional clustering of English words. In 
30th Annual Meeting of the ACL, 183-190. 
Ramshaw, L. A., Marcus, M. P. (1994).  
Exploring the statistical derivation of 
transformational rule sequences for part-of-
speech tagging. In Proceedings of the 
Balancing Act Workshop on Combining 
Symbolic and Statistical Approaches to 
Language, Association for Computational 
Linguistics. 86-95. 
Sager N. (1981). Natural Language Information 
Processing: A Computer Grammar of English 
and its Applications. Addison-Wesley: 
Reading, Massachusetts.  
Sekine, S. et. al (1992)  Automatic Learning for 
Semantic Collocation. In 3rd Conf. on Applied 
Natural Language Processing  :Trent - Italy. 
Wilcox, A, Hripcsak G. (2000).  Medical Text 
Representations for Inductive Learning. Proc 
AMIA Symp. 923-7.  
 
Analyzing the Semantics of Patient Data to Rank Records of 
Literature Retrieval 
Eneida A. Mendon?a
Department of Medical 
Informatics 
Columbia University 
em264@columbia.edu 
Stephen B. Johnson
Department of Medical 
Informatics 
Columbia University 
sbj2@columbia.edu 
Yoon-Ho Seol 
Department of Medical 
Informatics 
Columbia University 
seol@dmi.columbia.edu 
James J. Cimino 
Department of Medical 
Informatics 
Columbia University 
jjc7@columbia.edu 
 
Abstract 
We describe the use of clinical data 
present in the medical record to 
determine the relevance of research 
evidence from literature databases. 
We studied the effect of using 
automated knowledge approaches as 
compared to physician?s selection of 
articles, when using a traditional 
information retrieval system. Three 
methods were evaluated. The first 
method identified terms and their 
semantics and relationships in the 
patient?s record to build a map of the 
record, which was represented in 
conceptual graph notation. This 
approach was applied to data in an 
individual?s medical record and used 
to score citations retrieved using a 
graph matching algorithm. The 
second method identified associations 
between terms in the medical record, 
assigning them semantic types and 
weights based on the co-occurrence of 
these associations in citations of 
biomedical literature. The method was 
applied to data in an individual?s  
medical record and used to score 
citations. The last method combined 
the first two. The results showed that 
physicians agreed better with each 
other than with the automated 
methods. However, we found a 
significant positive relation between 
physicians? selection of abstracts and 
two of the methods. We believe the 
results encourage the use of clinical 
data to determine the relevance of 
medical literature to the care of 
individual patients.  
1 Introduction 
The practice of evidence-based medicine, which 
gained popularity in the last decade, has 
encouraged clinicians to understand and utilize 
critically appraised published research evidence. 
The tremendous increase of biomedical 
knowledge resources in electronic form, 
particularly on the World Wide Web, has 
generated a great deal of interest.  The increased 
availability of information does not make it easy 
for clinicians to filter large amounts of 
information and incorporate evidence to clinical 
practice. Although the number of clinicians and 
medical students who routinely perform their 
own searches has increased, they still have 
difficulty keeping-up-to-date with advances in 
medical science. (Gorman and Helfand, 1995) 
 Decision support tools designed to provide 
relevant and current evidence to clinicians 
promise to substantially improve health care 
quality (Haynes, Hayward, and Lomas, 1995 
;Rodrigues, 2000 ;Sim, et al, 2001) and 
potentially reduce medical errors.(Bates, et al, 
2001) Such tools include those that facilitate the 
access to, extraction of, and summarization of 
evidence. The Evidence and Decision Support 
track of the 2000 AMIA Spring Symposium 
examined the challenges in the development and 
adoption of clinical decision support systems for 
evidence-based practice.(Sim, et al, 2001) The 
speakers for the Evidence and Decision Support 
track described five central areas of activity as 
essential for the adoption of those systems. Two 
of the areas were a) the capture of both 
literature-based and practice based research 
evidence into machine-interpretable form, and 
b) the establishment of a technical and 
methodological foundation for applying research 
evidence to individual patients at the point of 
care.  
                                            Association for Computational Linguistics.
                            the Biomedical Domain, Philadelphia, July 2002, pp. 69-76.
                         Proceedings of the Workshop on Natural Language Processing in
Our goal is to improve the way retrieved 
medical literature is presented by identifying 
critical information in the individual medical 
record that is useful for determining the 
relevance of literature data, also called research 
evidence. We describe an automated knowledge 
based approach that uses case-specific evidence 
present in patient?s medical record to rank 
research evidence from literature databases. 
2 
2.1 
Background 
The integration of information with clinical 
applications may facilitate the access to 
scientific evidence, clinical guidelines, and other 
decision tools, in a way that information 
retrieved from these sources is personalized 
based on the context of individual 
needs.(Cimino, 1996) One of many challenges 
in building such systems is to understand what 
information in the individual medical record is 
important to the user and therefore potentially 
useful in search, retrieval, summarization, and 
presentation processes. Identifying the important 
terms, their semantic types, and common 
relationships maybe an interesting solution to 
the problem. The approach we describe here is 
based on previous research on automated 
methods to extract information from medical 
literature, and the use of natural language 
processing techniques to analyze free text 
clinical reports. Natural language processing 
techniques have been used to analyze free text 
reports in order to provide data for applications, 
such as automated encoding, decision support, 
patient management, quality assurance, 
outcomes analysis, and clinical research.(Baud, 
et al, 1995 ;Fiszman, et al, 2000 ;Friedman, et 
al., 1994 ;Friedman, et al, 1999 ;Gundersen, et 
al., 1996 ;Sager, et al, 1995) Data mining and 
knowledge discovery techniques have been used 
to interpret data from natural language 
processing output of narrative reports.(Wilcox 
and Hripcsak, 2000) 
Automated extraction from medical 
literature 
Research studies have introduced approaches to 
facilitate knowledge extraction from MEDLINE 
(Cimino and Barnett, 1993 ;Mendon?a and 
Cimino, 2000) and the Unified Medical 
Language System (UMLS).(Zeng and Cimino, 
1998) MEDLINE is the National Library of 
Medicine (NLM) premier bibliographic database 
covering the fields of medicine, nursing, 
dentistry, veterinarian medicine, the health care 
system, and the preclinial sciences. MEDLINE 
contains bibliographic citations and author 
abstracts from more than 4,600 biomedical 
journals published in the United States and 70 
other countries. MEDLINE citations are indexed 
with Medical Subject Headings (MeSH) terms. 
MeSH (1999) is the NLM?s controlled 
vocabulary used specifically for medical 
bibliographic indexing. Terms from MeSH are 
manually assigned to each document. The 
UMLS project was initiated in the mid-1980s by 
the National Library of Medicine.(Humphreys 
and Lindberg, 1993) The main goal was to 
provide a mechanism for linking diverse 
medical vocabularies as well as sources of 
information. There are currently three 
components of the UMLS Knowledge Sources: 
the Metathesaurus, Semantic Network, and 
SPECIALIST Lexicon. 
We based our method on the approach described 
by Mendon?a and Cimino. The researchers 
described an automated knowledge extraction 
method from MEDLINE citations, based on the 
ideas introduced by Zeng and Cimino (Zeng and 
Cimino, 1998), using the search strategies by 
Haynes and colleagues.(Haynes, et al, 1994) 
The approach involved the use of hierarchical 
and semantic links in the Medical Entities 
Dictionary (MED)(Cimino, et al, 1994) to 
identify additional terms which could be used to 
build specific patient-oriented queries. The 
MED uses a frame-based semantic network that 
includes a classification hierarchy to represent 
medical concepts and the relationship among 
them. The authors identified semantic 
associations in literature citations of four basic 
clinical tasks: etiology, prognosis, diagnosis, 
and therapy. These associations were based on 
the co-occurrence of MeSH terms in 4,000 
MEDLINE citations.   
The results of the study showed that only 7 to 
8% of the semantic pairs generated in each task 
group differ significantly from random chance. 
A pilot study to assess the clinical validity of the 
associations showed a relative good specificity 
and sensitivity for their intended purpose, 
information retrieval, except in one 
group(prognosis). Performance was especially 
good in the therapy group.  
 
Figure 1. Conceptual representation of a culture and sensitivity test 
 
3 
4 
4.1 
Research Question 
The work we describe here focused on the 
clinical data present in patients' medical records, 
and the use of these data to determine the 
relevance of research evidence. The main 
research question was ?What is the effect of 
using the automated knowledge based approach 
compared to a physician?s selection of articles 
when using a traditional information retrieval 
system?? 
Methods 
We evaluated the application of semantic 
algorithms to data in an electronic medical 
record for sorting abstracts of articles (citations) 
retrieved from medical literature databases. 
Semantic Approaches 
Data from an individual?s medical record was 
retrieved from the clinical repository using the 
latest entry of each laboratory test and narrative 
reports, if within one month from the retrieval 
data, to create a ?map? or summary of the 
medical record. Discharge summaries were an 
exception to this rule. The latest discharge 
summary was always retrieved independently of 
the time constraints.  
The selected narrative reports were parsed by 
AQUA - A QUery Analyzer,(Johnson, et al, 
1993) a natural language parser that translates 
text into a standard notation: conceptual graphs. 
(Sowa, 1984) AQUA?s lexicon is based on the 
UMLS Metathesaurus. The UMLS Semantic 
Net recommends which concepts and relations 
can be sensibly combined.  
Coded data (e.g., laboratory tests) were also 
represented as conceptual graphs. We used the 
MED to infer knowledge when appropriate. For 
instance, when a glucose measure of 150 mg/dl 
was retrieved, the information in the MED 
allowed us to infer that the result could also be 
interpreted as hyperglycemia. The MED was 
also used to map concepts in the electronic 
medical record to UMLS concepts in order to 
obtain their semantic types. Figure 1 shows an 
example of a test result extracted from the 
medical record and its conceptual graph 
representation.  
Three semantic algorithms are used. The first 
algorithm is based on graph matching 
techniques. The second method identifies 
associations between terms in the medical 
record, assigning them semantic types and 
weights based on the co-occurrence of these 
associations in citations of biomedical literature. 
The method is applied to data in an individual?s 
medical record, and scored citations according 
to this information. The last method combines 
the first two. 
The graph matching algorithm is based on 
assumption that the similarity of two 
representations is a function of the amount of 
information they share. (Maher, 1993 ;Poole and 
Campbell, 1995) It worked as follows:  
1. graphs on both sides (clinical data and 
citations) are broken into subgraphs; 
2. subgraphs of clinical data are then 
compared to subgraphs of the citations; 
3. if a perfect match is found (semantic 
type and relationship) a score of 1 is 
given. If not, points are reduced for each 
type of relation that did not match. 
Points are reduced based on the UMLS 
semantic types and relationship 
hierarchy (UMLS Semantic Net);  
4. indirect matches are searched; 
5. the score is then normalized based on 
the number of subgraphs generated by 
each graph, and the number of graphs in 
the document. 
Figure 2 shows how the similarity between 
two graphs is computed. 
 
 
Figure 2. Simplified graph matching 
representation 
 
The second method studied is based on the 
semantic associations between concepts in the 
medical record. A knowledge base containing 
the statistically significant semantic type 
associations found in MEDLINE by Mendon?a 
and Cimino was built. In addition to the 
semantic types, the knowledge base also stores 
the number of times the association occurred in 
the citations, the MeSH terms that originated the 
association, and the P values generated by the 
significance test. The knowledge base contains 
three groups of associations: therapy, etiology 
and diagnosis. The associations are grouped 
based on the type of questions the citations were 
retrieved to answer.  In this method, we identify 
all possible associations between semantic types 
in the medical record. Semantic relationships are 
not taken in consideration. If the same 
associations are found in the citations retrieved, 
we consider it a match. Only the associations 
present in the knowledge base are weighted. The 
weights for each citation depend on the type of 
question that originated the citation. 
The algorithm may be best understood 
through an example. Assume a clinician sees 
Mr. Ocean, and has a question about how to 
treat Mr. Ocean?s migraine. The clinician 
searches the literature and finds two citations, 
one published in the Annals of Internal 
Medicine and the second, in the New England 
Journal of Medicine.  In the semantic approach 
described, if a pair of semantic types is found in 
Mr. Ocean?s medical record (e.g., Disease or 
Syndrome ? Pharmaceutical Substance) and also 
in the citations retrieved, and the association is 
present in the knowledge base for questions on 
therapy, then that association receives a certain 
weight. The association weights are based on the 
co-occurrence of these associations in citations 
of biomedical literature. Two values are used in 
the scoring process:  a) number of associations 
that are present in the medical record and 
citation, b) the logarithm of the sum of the 
inverse of P values of each association found.  
The third semantic algorithm combines 
features from the previous two. For each 
association that matches the medical record, 0.1 
point is added to the graph matching score for 
that citation.   
4.2 Evaluation studies 
We performed a study in order to assess the 
effect of using the automated knowledge 
approach compared to a physicians? selection of 
articles when using traditional information 
retrieval systems. 
Three patients consented to the use of 
anonymized versions of the data stored in their 
electronic medical records. We randomly 
selected one admission of each patient to build 
the clinical cases. Data from these individuals? 
medical records were retrieved from the clinical 
repository as previously described. Narrative 
reports were parsed differently depending on the 
algorithm in evaluation. The ?maps? of the three 
medical records were created. For each case, 
four clinical questions were selected from a 
database of generic questions based on the work 
of Ely and collaborators.(Ely, et al, 2000) 
Nonclinical questions (e.g., What are the 
administrative rules/considerations in <situation 
y?>) were eliminated from the database before 
the selection. Each question selected was also 
eliminated before the next random selection, so 
that we had a total of 12 unique questions. A 
health science librarian generated the search 
strategy for each question based on the case 
description. Two information retrieval systems 
were searched: PubMED (clinical queries using 
research methodology filters based largely on 
the work of Haynes and colleagues) (Haynes, et 
al., 1994) and OVID (Evidence-Based Medicine 
Reviews)1. All search strategies were keyword 
based with Boolean connectors. The search was 
time limited (last 3 years). In the cases where no 
citation was retrieved, the time limit was 
removed. The time limit was imposed because 
the time required by an expert to analyze all 
citations retrieved without this limitation would 
have been a disincentive to their participation in 
the study. 
Subjects were recruited as follows. Three 
board-certified internists, one board-certified 
family physician, and one research physician 
were selected as experts. Four of the five 
physicians actively practice medicine in their 
fields. Participants were given instructions and 
received the following materials: a) cases? 
description, b) clinical questions selected for 
each case, and c) citations retrieved to answer 
each question. Case descriptions were based on 
the admission note (chief complaint, history of 
present illness, past medical and surgery history, 
and current medications), and the results of 
laboratory tests performed during the admission. 
Subjects were asked to score each citation 
according to the relevance of the article 
(citation) to the question asked and to the patient 
the case referred to. We asked each to define a 
relevant citation as providing information that 
could be used in the care of that particular 
patient.  
                                                     
5 
1 EBM Reviews includes the following 
databases : ACP Journal Club (ACP), Cochrane 
Database of Systematic Reviews (COCH), and 
Database of Abstracts of Reviews of Effectiveness 
(DARE) 
The score used by the physicians was: 
1 ? completely nonrelevant 
2 ? almost entirely nonrelevant 
3 ? somewhat relevant 
4 ? very relevant  
5 ? completely relevant 
Each participant analyzed all questions. 
The automated methods also scored each 
citation. The scores were based on how well the 
abstract and title in the citation matched the 
case?s summary. The computer scores are 
described in the previous section. We used the 
inverse chronological order in which the 
citations were provided by their respective 
programs as an additional method for 
comparison (control). 
The main outcome measure in my study was 
the distance of averaged correlation coefficients 
between subjects and the average of the raters.  
For each physician, we calculated the average 
distance from the average of the other 4 
physicians, and for each automated method, we 
calculated the average distance from the average 
of all 5 physicians.  The null hypotheses were:  
a) that each subject was no more distant from 
the average of the physicians than the physicians 
were from each other and b) that there was no 
correlation between the average of the 
physicians? scores and the average of the 
subjects? scores. We used bootstrapping to 
estimate variance directly from the data. 
We used Pearson?s product-moment 
correlation to calculate the strength of the 
association between subjects and the average of 
the raters. In order to accommodate the fact that 
questions had a different number of citations 
associated with them, we calculated a weighted 
average r_ of correlation coefficients ri given 
weights wi as follows: 
r_ = ri * (wi / ?(wi)) 
 wi = (ni - 1) ? 
where n is the number of citations retrieved 
in question i. 
Results 
The 3 clinical cases and 12 questions generated 
a set of 219 citations: 111 from PubMED and 
108 from EBM reviews. The number of citations 
per question varied from 1 to 28. The four 
questions that retrieved only one citation were 
removed from the statistical analysis. Thus, the 
total number of citations analyzed was 215. 
 The correlation coefficient between subjects 
and the average of raters varied from -0.07 to 
0.52. The weighted correlation coefficient for 
each subject is listed in Table 1. A significant 
positive correlation was found between the 
average of physicians? scores and the scores 
given by the graph matching and the combined 
algorithms. 
The main outcome measure, the difference 
between subject correlations minus average 
physician correlations, is shown in Table 2.  
Positive numbers imply worse performance 
(more unlike the average physician). No 
physicians differed significantly from other 
physicians. The automated methods did differ 
from physicians with significant P values. 
 
 
Table 1. Correlation coefficients and significance of 
the correlation 
Subject Correlation P Value 
Physician 1 0.46 < 0.0001 
Physician 2 0.44 < 0.0001 
Physician 3 0.52 < 0.0001 
Physician 4 0.52 < 0.0001 
Physician 5 0.48 < 0.0001 
Graph matching 0.19 0.0098 
Graph matching + 
associations 
0.15 0.046 
Number of associations -0.07 > 0.05 
Associations value -0.03 > 0.05 
Inverse chronological 
order 
0.04 > 0.05 
 
 
Table 2. Average subject correlations minus average 
physician correlations 
Subject Difference (95% CI) P Value 
Physician 1 -0.03 (-0.08 to 0.14) 0.60 
Physician 2 -0.05 (-.08 to 0.18) 0.43 
Physician 3 0.04 (-0.06 to 0.14) 0.41 
Physician 4 0.05 (-0.07 to 0.17) 0.40 
Physician 5 -0.01 (-0.11 to 0.13) 0.86 
Graph matching 0.29 (0.24 to 0.54)  0.0002 
Graph matching 
+ associations 
0.33 (0.29 to 0.58) < 0.0002 
Inverse 
chronological 
order 
0.44 (0.32 to 0.56) < 0.0002 
6 Discussion 
Our main goal in this project was to assess the 
effect of the use of clinical data to improve 
presentation of medical literature. We evaluated 
three semantic methods.  
The level of association between pairs of 
subjects ranged from -0.07 to 0.52. The level of 
association associations among physicians 
seemed to be similar to levels of agreement 
between 2 independent raters reported in the 
literature.(Wilczynski, McKibbon, and Haynes, 
2001) No single physician stood out as 
significantly different from the others.  
The graph matching algorithm highly 
correlated with physicians? average, although it 
did not perform as well as individual physicians. 
This finding encourages the use of clinical data 
to determine the relevance of medical literature 
to the care of individual patients. In an 
integrated system (medical record with 
information resources) this positive correlation 
suggests that our method can facilitate 
presentation of online biomedical literature. For 
instance, if the electronic medical record is 
integrated to an existent information retrieval, 
findings from an individual medical record can 
be used to rearrange the way retrieved 
information is presented; in a way that literature 
matching that individual?s medical record will 
be presented first, rather than the usual 
presentation in reverse chronological order. 
The combined method also correlated 
significantly with physicians? average, although 
its performance was not as good as of the simple 
graph matching. This result may be due to a 
negative effect of the associations in the 
knowledge over the matching. There was no 
correlation between the methods that use the co-
occurrence of semantic types in medical 
literature citations and the average of physicians.   
The automated method based on the 
chronological order of articles did not correlate 
with physicians? average.  
The poor results of the method which used 
the knowledge base of semantic co-occurrences 
in Medline citations may be due to several 
aspects. The terms used for indexing medical 
citations may not correspond well to data 
usually found in medical records.  Approaches 
using the UMLS Semantic Net may be also 
somewhat limited by the fact approximately one 
fourth of the Metathesaurus concepts are 
assigned several semantic types, which makes it 
difficult to get a precise understanding of the co-
occurrences.(Burgun and Bodenreider, 2001) 
We believe enhancements can still be made. 
The graph matching algorithm is highly 
dependent on the output of the natural language 
processor. The general language processor used 
to parse both clinical data and citations was 
never validated for this use. AQUA was 
designed to translate user?s natural language 
queries into a conceptual graph representation. It 
was developed on a corpus of clinical queries. 
Prior to this study, the parser was trained with 
only a few sentences from the medical literature. 
The complexity of the clinical data and medical 
literature involved in the study generated a 
significant number of ?broken? graphs. The 
similarity found between the graphs was usually 
at the level of single nodes. It was also observed 
that the parser had difficult with very long 
sentences and sentences in the results section of 
the abstract. An example of a sentence partially 
parsed is ?Furthermore, patients treated with 
aprotinin had significantly less total 
postoperative blood loss (718 +/- 340 ml vs 920 
+/- 387 ml, p =0.04)?. With enhancements to the 
natural language processor, we believe we could 
obtain a better representation of the data, and 
consequently more accurate results. 
The use of UMLS Semantic Net may have 
also contributed to the elevated incidence of 
?broken? graphs. Mendon?a and Cimino 
(Mendon?a and Cimino, 2001) found that only 
22.99% of the associations of semantic types 
based on MeSH terms retrieved from the 
medical literature had a direct semantic 
relationship in the UMLS Semantic Net. A 
careful appreciation of the missing relationships 
may help us to understand whether the addition 
of new semantic relationships can contribute to a 
better representation of clinical and literature 
data.   
Whether improvements in the parser to allow 
it to handle medical literature and complex 
clinical data would improve the performance of 
the automated methods is unclear; further 
studies are needed. The use of this method in 
association with other information retrieval 
techniques is being investigated by the authors.  
 
 
 
7   Conclusion 
The goal of the study is to support the use of 
clinical data to facilitate the information 
retrieval of biomedical literature. The results of 
this study support this goal. The use of 
conceptual graph representation and graph 
matching techniques correlated significantly 
with the average of physicians when judging the 
relevance of citations to the care of an individual 
patient. Additional studies are needed in order to 
understand if this performance is acceptable in a 
clinical environment. A careful evaluation of the 
parsed reports and careful appreciation of the 
missing relationships may help us to understand 
the results and enhance the performance of the 
algorithms.   
 
References 
Medical Subject Headings - Annotated 
Alphabetical List. Bethesda, MD:  1999. 
(National Library of Medicine). 
Bates DW, Cohen M, Leape LL, Overhage 
JM, Shabot MM, Sheridan T. Reducing the 
frequency of errors in medicine using 
information technology. Journal of the 
American Medical Informatics Association 
2001; 8(4):299-308. 
Baud RH, Rassinoux AM, Wagner JC et al 
Representing clinical narratives using 
conceptual graphs. Methods of Information in 
Medicine 1995; 34(1-2):176-86. 
Burgun A, Bodenreider O. Methods for 
Exploring the Semantics of the Relationships 
between Co- occurring UMLS Concepts. 
Medinfo 2001; 10(Pt 1):171-5. 
Cimino JJ. Linking patient information 
systems to bibliographic resources. Methods of 
Information in Medicine 1996; 35(2):122-6. 
Cimino JJ, Barnett GO. Automatic 
knowledge acquisition from MEDLINE. 
Methods of Information in Medicine 1993; 
32(2):120-30. 
Cimino JJ, Clayton PD, Hripcsak G, Johnson 
SB. Knowledge-based approaches to the 
maintenance of a large controlled medical 
terminology. Journal of the American Medical 
Informatics Association 1994; 1(1):35-50. 
Ely JW, Osheroff JA, Gorman PN et al A 
taxonomy of generic clinical questions: 
classification study. British Medical Journal 
2000; 321(7258):429-32. 
Fiszman M, Chapman WW, Aronsky D, 
Evans RS, Haug PJ. Automatic detection of 
acute bacterial pneumonia from chest X-ray 
reports. Journal of the American Medical 
Informatics Association 2000; 7(6):593-604. 
Friedman C, Alderson PO, Austin JH, 
Cimino JJ, Johnson SB. A general natural-
language text processor for clinical radiology. 
Journal of the American Medical Informatics 
Association 1994; 1(2):161-74. 
Friedman C, Knirsch C, Shagina L, Hripcsak 
G. Automating a severity score guideline for 
community-acquired pneumonia employing 
medical language processing of discharge 
summaries. Proceedings of the AMIA Fall 
Symposium 1999; 256-60. 
Gorman PN, Helfand M. Information seeking 
in primary care: how physicians choose which 
clinical questions to pursue and which to leave 
unanswered.  Medical Decision Making 1995; 
15(2):113-9. 
Gundersen ML, Haug PJ, Pryor  TA et al 
Development and evaluation of a computerized 
admission diagnoses encoding system. 
Computers and Biomedical Research 1996; 
29(5):351-72. 
Haynes RB, Hayward RS, Lomas J. Bridges 
between health care research evidence and 
clinical practice. Journal of the American 
Medical Informatics Association 1995; 
2(6):342-50. 
Haynes RB, Wilczynski N, McKibbon KA, 
Walker CJ, Sinclair JC. Developing optimal 
search strategies for detecting clinically sound 
studies in MEDLINE. Journal of the American 
Medical Association 1994; 1(6):447-58. 
Humphreys BL, Lindberg DAB. The UMLS 
project: making the conceptual connection 
between users and the information they need. 
Bulletin of the Medical Library Association 
1993; 81(2):170-7. 
Johnson SB, Aguirre A, Peng P, Cimino J. 
Interpreting natural language queries using the 
UMLS. Proceedings of the Annual Symposium 
on Computer Applications in Medical Care 
1993; 294-8. 
Maher PE. A similarity measure for 
conceptual graphs. International Journal of 
Intelligent Systems 1993; 8:819-37. 
Mendon?a EA, Cimino JJ. Automated 
knowledge extraction from MEDLINE citations. 
Proceedings of the AMIA Fall Symposium 
2000; (20 Suppl):575-9. 
Mendon?a EA, Cimino JJ. Content 
evaluation of a knowledge base. 2001; 974. 
 Poole J, Campbell JA. A novel algorithm for 
matching conceptual graphs and related graphs. 
Ellis G, Levinson R , Rich W, Sowa JF, edts. 
Conceptual Structures: Applications, 
Implementation and Theory, Third International 
Conference on Conceptual Structures, ICCS'95. 
Springer, 1995: 293-307. 
Rodrigues RJ. Information systems: the key 
to evidence-based health practice. Bulletin of the 
World Health Organization 2000; 78(11):1344-
51. 
Sager N, Lyman M, Nhan NT, Tick LJ. 
Medical language processing: applications to 
patient data representation and automatic 
encoding. Methods of Information in Medicine 
1995; 34(1-2):140-6. 
Sim I, Gorman P, Greenes RA et al Clinical 
decision support systems for the practice of 
evidence-based medicine. Journal of the 
American Medical Informatics Association 
2001; 8(6):527-34. 
Sowa JF. Conceptual structures: information 
processing in mind and machine. Reading, MA: 
Addison-Wesley, 1984.  
Wilcox A, Hripcsak G. Medical text 
representations for inductive learning. 
Proceedings of the AMIA Fall Symposium 
2000; 923-7. 
Wilczynski NL, McKibbon KA, Haynes RB. 
Enhancing retrieval of best evidence for health 
care from bibliographic databases: calibration of 
the hand search of the literature. Medinfo 2001; 
10(Pt 1):390-3. 
 Zeng Q, Cimino JJ. Automated knowledge 
extraction from the UMLS. Chute CG. 
Proceedings of the AMIA Fall Symposium. 
Philadelphia: Hanley & Belfus Inc., 1998: 568-
72. 
