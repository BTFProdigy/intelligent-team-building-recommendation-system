Proceedings of the 14th European Workshop on Natural Language Generation, pages 206?207,
Sofia, Bulgaria, August 8-9 2013. c?2013 Association for Computational Linguistics
Team UDEL KBGen 2013 Challenge  
Keith Butler, Priscilla Moraes, Ian Tabolt, Kathleen F. McCoy 
Computer and Information Science Department 
University of Delaware 
Newark, DE 19716 
keithb@udel.edu, pmoraes@udel.edu, itabolt@udel.edu, mccoy@cis.udel.edu 
  
 
Abstract 
This document describes the University of Dela-
ware?s entry into KBGen 2013 Challenge which 
provided teams with input data representation from 
the AURA knowledge base (KB), developed in the 
context of the HALO Project at SRI International, 
along with a lexicon mapping for concepts present 
on those input files. Training sentences were also 
provided. The task was to accurately generate an 
English sentence depicting the information from a 
set of triples from the knowledge base. 
1 Approach 
Our approach to the problem was to develop a 
set of rules for translating KB structures into 
English structures and to use an existing genera-
tor, such as SimpleNLG (Gatt & Reiter, 2009) or 
FUF-SURGE (Elhadad, 1993) to generate the 
sentences. 
Our analysis of pre-release data provided by 
the KBGen organization (triple-files, training 
sentences, tree graphs, lexicon) was facilitated by 
writing a mashup program (KBGenMashup) that 
enabled viewing/searching the data. The program 
initially loads all the training sentences into a 
clickable list box.  When a sentence is clicked, 
all data relating to that sentence is displayed: cor-
responding triples, tree-graph, and Stanford parse 
of the sentence.  The displayed triples are given 
?hot spots? so clicking on them will present a list 
of other sentences containing (or NOT contain-
ing) that same relation or instance type.  Finally, 
KBGenMashup enables a search for other sen-
tences that contain a given word or phrase.  Us-
ing this tool allowed us to discover common real-
ization patterns for certain KB triples. 
2 Major sentence types 
Our initial generator implementation utilized 
SimpleNLG in a java wrapper. Our tack was to 
focus on the realization of major sentence types, 
generally identified by the presence of a particu-
lar function in the KB triples, e.g. has-function, 
subevent, plays. These functions provided the 
main verb and sentence structures, and other KB 
relations were fit into this structure (in sub-
ject/object position or as adjuncts) in a rule-
based way. 
For instance, Figure 1 shows a triples file from 
the testing data that was identified under the 
cluster has-function, along with the sentence 
generated by our system and the rule used to re-
alize the cluster for this relation type. 
  
 
Figure 1: A triples file from the testing data. 
 
Sentence generated: The function of the peptide 
bond is to hold together hydrogen and nitrogen 
using a single bond. 
The identified rule for this input is the has-
function rule. The main entity is the entity that is 
related to the event of the instance by the has-
function relation type. The rule states that the 
subject of the sentence is the ?the function of 
[main entity]?. For this template the verb to be is 
identified as the main verb and the object of the 
sentence is a verb phrase (VP) composed of the 
events present in the triples file in the infinitive 
form, and the existing secondary entities. Each 
secondary entity is related to an event by a se-
mantic relation type. The nature of this relation 
defines which role the secondary entity plays in 
the sentence (e.g. the ?object? relation, when 
present, usually links the event to the head(s) of 
the noun phrase (NP) within the VP). Although 
the majority of the input files have secondary 
206
entities that are related to the main event by the 
object relation, some other cases do not present 
them. The head of the noun phrases can be repre-
sented, in those cases, by secondary relations 
connected to the main event by one of agent, 
base, result, raw-material, relation types. Heuris-
tics are applied in order to define the head of the 
noun phrase since the relation that will define 
which entity is the head of the NP is based on the 
combination of the existing relations. The rela-
tions in the set of triples that are not already real-
ized as one of the previous roles in the sentence 
are then realized recursively for each event, 
complementing the VP. Those relations are rep-
resented by prepositional phrases (PP) and the 
preposition chosen for each PP represents the 
semantic role of the relation type (e.g. instrument 
relations often use the prepositions with or us-
ing, while donor and origin relations often use 
from). 
3 No-Events and other sentence types 
The simple strategy described above worked well 
for some sentence types, but others required 
more sophisticated triple traversal. In particular, 
realizing triple sets not containing an event was 
problematic.  With time running short, we im-
plemented a second realizer to handle these 
types. It used its own heuristics, plus stored the 
sets of triples in a database that allowed for flex-
ible traversing. Consider its heuristics to handle 
no-event triple sets (events generally provide the 
verb and sentence structure). No-event sentences 
would use a form of ?be? as the main verb, but 
we still needed to identify the sentence?s main 
subject.  To do this, the software looks for the 
Entity that is on the left side of the most triples. 
Why?  There is more information about this Enti-
ty than about any other. Consider ex29b.4 (Fig-
ure 2).  The tree graph shows that ?Restriction-
Site? is on the left side of five triples.  It should 
be the subject of the sentence, which could be 
realized as ?A restriction site is a short DNA se-
quence which consists of 2 deoxyribose and a 
deoxyribonucleoside monophosphate.?  Note the 
order of the Entities in the sentence.  The subject 
is mentioned first, then its adjective (?short?), 
then class (?DNA sequence?), then remaining 
entities.  In realizing the remaining Entities, a 
common routine is used to check for cardinality 
and perform any rewording as appropriate. 
 
Figure 2: ex29b.4 
In many cases, there was a tie among the times 
Entities were on the left.  In one type of ?tie? 
(ex05a2.265, Figure 3), there is a cycle in the 
graph (see ?Fibronectin, ?Carbohydrate-Side-
Chain?, ?Surface?.)  In these cases, the heuristic 
chooses the ?middle? Entity in the cycle (Carbo-
hydrate in this case) as the subject.  Then in 
choosing mention-order, the software (usually) 
starts the sentence by putting the adjective before 
the subject (i.e. ?branched? & ?carbohydrate side 
chain?), then visits each Entity around the cycle, 
then traverses up to the ?Top? Entity.   This sen-
tence is realized as ?There are branched carbo-
hydrate side chains at the surface of the fibron-
ectin of an animal plasma membrane.? 
 
Figure 3: ex05a2.265 
4 Conclusions 
We have described a template-based generation 
entry based on two different paradigms. In one, 
sentences are formed on the basis of a major re-
lation that generally selects the main verb and 
fits the realization of the other pieces according 
to the structures specific for that sentence type. 
The second piece that we needed is based on 
flexibly traversing the knowledge base and real-
izing based on patterns found in the triples. 
References  
Albert Gatt and Ehud Reiter. 2009. SimpleNLG: A 
realization engine for practical applications, Pro-
ceedings of the 12th European Workshop on Natu-
ral Language Generation, pages 90?93, Athens, 
Greece, 30 ? 31 March 2009.  
Michael Elhadad. 1993. FUF: the Universal Unifier 
User Manual Version 5.2. 
207
Proceedings of the 8th International Natural Language Generation Conference, pages 64?73,
Philadelphia, Pennsylvania, 19-21 June 2014. c?2014 Association for Computational Linguistics
 
 
Adapting Graph Summaries to the Users? Reading Levels 
 
 
Priscilla Moraes, Kathleen McCoy and Sandra Carberry 
Department of Computer and Information Sciences 
University of Delaware, Newark, Delaware, USA 
[pmoraes | mccoy | carberry]@udel.edu 
 
  
 
Abstract 
Deciding on the complexity of a generated text 
in NLG systems is a contentious task. Some 
systems propose the generation of simple text 
for low-skilled readers; some choose what 
they anticipate to be a ?good measure? of 
complexity by balancing sentence length and 
number of sentences (using scales such as the 
D-level sentence complexity) for the text; 
while others target high-skilled readers. In this 
work, we discuss an approach that aims to lev-
erage the experience of the reader when read-
ing generated text by matching the syntactic 
complexity of the generated text to the reading 
level of the surrounding text. We propose an 
approach for sentence aggregation and lexical 
choice that allows generated summaries of line 
graphs in multimodal articles available online 
to match the reading level of the text of the ar-
ticle in which the graphs appear. The tech-
nique is developed in the context of the 
SIGHT (Summarizing Information Graphics 
Textually) system. This paper tackles the mi-
cro planning phase of sentence generation dis-
cussing additionally the steps of lexical 
choice, and pronominalization.  
1 Introduction 
Multimodal documents from online popular me-
dia often contain information graphics that aug-
ment the information found in the text. These 
graphics, however, are inaccessible to blind us-
ers.  The SIGHT system is an ongoing project 
that proposes methods of making this infor-
mation accessible to visually impaired users by 
generating a textual summary capturing the high-
level message of the graphic along with visually 
distinctive features. Figure 1 shows an example 
of an information graphic found in popular me-
dia. This graphic ostensibly conveys that there 
was a change in the trend of ocean levels, which 
is first stable until about 1940 and then rising 
through 2003. Earlier work on the system (Wu, 
Carberry, Elzer, & Chester, 2010) is able to infer 
this high-level message given a representation of 
the graphic. 
Nevertheless, a generated summary should 
convey more than just the intended message. It 
should provide important visual features that 
jump out at a person who views the graphic 
(such as the fluctuation in the data values as seen 
in the graph in Figure 1). The set of remarkable 
features is different for different graphics. Previ-
ous work of ours (Moraes, Carberry, & McCoy, 
2013) presents methods that capture these most 
important features and allow the composition of 
customized summaries for each graph. Thus, 
given a graphic, our previous work has resulted 
in a system that can produce a set of propositions 
to include in its summary. In this paper, we turn 
to the subsequent phases of generation: given a 
set of propositions, how these propositions 
should be realized such that the resultant text is 
adapted to the user?s reading level and thus is 
coherent and understandable. 
Therefore, this work presents novel strategies 
that have been deployed in the text generation 
phase of the SIGHT system applied to line 
graphs. It describes the micro planning phase, 
emphasizing sentence aggregation, lexical choice 
and pronominalization. The contribution of this 
work is the provision of coherent and concise 
textual summaries that narrate line graphs? high-
level content to visually impaired users through 
approaches that rely on 1) making the right 
wording choices and 2) making appropriate syn-
tactical decisions in order to achieve a desired 
reading level for the generated text. 
Previous work in generation assumes a partic-
ular level of complexity for all texts created. Our 
hypothesis is that the graph?s summary should 
vary depending on the user?s reading level.  Alt-
hough one could explicitly inquire about the us-
er?s reading level, this would be intrusive and 
64
  
would detract from the overall experience.  Thus 
we hypothesize that the level of complexity of 
the article in which the graph appears roughly 
equates with the user?s reading level --- that is, 
users generally choose articles that are at their 
own reading comfort level.  Therefore, our ap-
proach is to generate summaries that reflect the 
reading level of the accompanying article.  Not 
only will such summaries be coherent and under-
standable to the user, but also the summary 
should fit seamlessly into the user?s reading of 
the article. 
The decision to match the text complexity of 
the generated text to that of the article?s text was 
inspired by results of an experiment performed 
with college students aiming to evaluate the con-
tent determination output. In the experiment, sen-
tences were generated for each proposition se-
lected by the system. Comments made by the 
subjects revealed that the simplest possible text 
was not easier to understand. Rather, it caused 
them confusion and discomfort when reading it. 
Based on these results, we decided to tackle the 
problem of deciding on the text complexity of 
automatically generated text by following the 
same syntactical complexity of the surrounding 
text, by reading level. In addition, we use word 
frequencies to select more common lexical items 
to compose summaries of lower reading levels.  
The next section presents the background and 
motivation for our work. Section 3 discusses 
some related work concerned with text genera-
tion and simplification. Section 4 presents our 
proposed approach to text generation that adapts 
the output to the reading level of the surrounding 
text. Section 5 shows some examples of text 
generated in different grade level groups. Section 
6 shows our preliminary evaluation and it is fol-
lowed by some conclusions and ideas for future 
work in Section 7 and 8, respectively. 
2 Background 
The approaches presented in this work are de-
ployed in the context of the SIGHT system. The 
system is concerned with providing access to 
information graphics present in multimodal doc-
uments from popular media such as the graphic 
in Figure 1. For this graphic, the content selec-
tion module1 (Moraes et al., 2013) chooses the 
following propositions for inclusion in the initial 
summary: 
? graph type (line graph); 
                                                 
1 The content selection module has been presented in a pre-
vious paper and is outside the scope of this paper. 
? entity being measured (annual difference 
from Seattle's 1899 sea level, in inches); 
? the intended message of the graphic 
(changing trend: stable then rising); 
? the high fluctuation of the data values; 
? the description of the individual seg-
ments of the graphic; 
? the initial value (annotated end point); 
? the ending value (annotated end point). 
 Figure 1: Example of a graphic that has a Chang-
ing Trend as its intended message and presents 
out-standing visual features (volatility and anno-
tations on end points). 
These propositions are not necessarily selected 
in this listed order, nor in the order they will be 
mentioned in the summary. They are selected 
based on their overall importance in the context 
of the graphic since the content selection frame-
work is based on an adapted version of a cen-
trality-based algorithm. Once these propositions 
are selected, an overarching organizational strat-
egy must be chosen to decide on the most appro-
priate ordering. Our system gives most im-
portance to the overall intended message of the 
graphic and thus this will be mentioned first. 
Next, a description of the features of the individ-
ual trend(s) will be provided. Finally, summary 
information about the whole graph will be given. 
The system must make further decisions when 
the graph conveys more than one trend (such as 
the graph in Figure 1). For such cases, the system 
must further decide whether to organize the de-
scription of the trends (1) by the trends them-
selves ? e.g. either in left to right order - when no 
trend is considered more important than the oth-
ers; or (2) by importance ? when a trend has a 
65
  
greater set of features selected for the discourse 
or it composes a candidate intended message, 
which augments the intended message (Moraes 
et al., 2013). In the latter case, if a piece of the 
graphic (trend) has significantly more features 
selected, meaning that it possesses a higher num-
ber of visually outstanding features, it will be 
described first, then followed by the other trends. 
The organization of the sentences is a separate 
step that happens prior to the realization phase, 
which is the focus here, and will not be discussed 
further in this paper. 
Having the set of ordered propositions select-
ed, the question that arises is how to realize this 
information to the user. The most straightforward 
way of realizing the summary would be to realize 
each proposition as a single sentence. This strat-
egy was applied in an evaluation experiment 
(briefly described next) that aimed to test the 
preciseness of the content selection framework. 
The experiment presented the subjects with line 
graphs and their correspondent generated initial 
summaries (the propositions were properly or-
dered for this experiment). Subjects were asked 
whether or not the most important information 
about the graphic was part of the summary and 
whether the summary presented unnecessary or 
redundant information. They were also offered 
the opportunity to provide additional comments. 
For the experiment, the initial summary for the 
graphic in Figure 1 was the following: 
The image shows a line 
graph. The line graph is 
highly volatile. The line 
graph presents the number of 
annual difference from Seat-
tle's 1899 sea level, in 
inches. The line graph shows 
a trend that changes. The 
changing trend consists of a 
stable trend from 1900 to 
1928 followed by a rising 
trend through 2003. The 
first segment is the stable 
trend. The stable trend has 
a starting value of 1.97 
inches. The second segment 
is the rising trend. The 
rising trend has an ending 
value of 8.9 inches. 
Although the experiment was intended to evalu-
ate the content present in the summaries, various 
comments addressed the syntactical construction 
of the text. These comments highlighted the lack 
of aggregation and pronominalization. For in-
stance, a common theme of the comments was 
that some of the information could be ?com-
bined? and presented more succinctly. 
All the participants of the experiment were 
graduate students. These results showed that 
more sophisticated readers prefer text that is 
more sophisticated. This finding pointed to the 
necessity of an aggregation step before the deliv-
ery of the summaries. However, questions arose 
concerning how much aggregation to do, how to 
measure aggregation to choose one strategy over 
another, or to decide on a desired level of aggre-
gation. 
To answer the above questions, we decided to 
examine the text complexity of the text surround-
ing the graphic --- that is, the text from the article 
in which the graph appears. We presume that this 
text complexity equates with the user?s reading 
level and thus summaries at this level of com-
plexity will be understandable and coherent to 
the users.  This approach seemed to be the best 
way of customizing the text complexity of the 
summaries in order to tailor summaries to indi-
vidual users. 
3 Related Work 
Research on generating text concerned with low-
skilled users has been conducted by (Williams & 
Reiter, 2004, 2005a, 2005b, 2008; Williams, 
Reiter, & Osman, 2003). As stated by (Williams 
& Reiter, 2005b), most NLG systems generate 
text for readers with good reading ability. Thus, 
they developed a system called SkillSum which 
adapts its output for readers with poor literacy 
after assessing their reading and numeracy skills. 
Their results show that, for these target readers, 
the micro planning choices made by SkillSum 
enhanced readability. (Siddharthan, 2003) pro-
poses a regeneration phase for syntactical text 
simplification in order to preserve discourse 
structure ?aiming to make the text easier to read 
for some target group (like aphasics and people 
with low reading ages) or easier to process by 
some program (like a parser or machine transla-
tion system). (J. Carroll et al., 1999) presents a 
text simplification methodology to help lan-
guage-impaired users. (Rello & Baeza-Yates, 
2012) investigates dyslexic errors on the Web 
and (Rello, Baeza-Yates, Bott, & Saggion, 2013) 
propose a system that uses lexical simplification 
to enhance readability and understandability of 
text for people with dyslexia. They help users to 
understand the text by offering as options the 
replacement of more complicated lexical items 
66
  
by simpler vocabulary. They performed experi-
ments with people with no visual impairments 
and with people with dyslexia and concluded that 
the system improved readability for the users 
with dyslexia and improved comprehensibility 
for users with no visual impairments. Experi-
ments performed with blind users and the usabil-
ity of a system that provides access to charts and 
graphs is presented by (Ferres, Lindgaard, 
Sumegi, & Tsuji, 2013). 
Other NLG systems make decisions on text 
complexity based on available scales such as the 
D-level sentence complexity (Covington, He, 
Brown, Naci, & Brown, 2006). One example is 
presented in (Demir et al., 2010) where tree 
structures are built representing all the possible 
ways sentences can be aggregated and the choice 
of the tree tries to balance the number of sen-
tences, their D-level complexity, and the types of 
relative clauses. 
Although text simplification is crucial to target 
low-skilled readers and users with language dis-
abilities, our experiment with college students 
showed that the simplest text was rather unpleas-
ant to read for them. We therefore propose a 
technique that focuses on adjusting the generated 
text to the reading level of the surrounding text. 
Thus, our system should satisfy both high-level 
and low-level readers. 
4 Aggregation and Text Complexity 
The initial summaries generated by the system 
are composed of individual sentences that were 
realized from atomic concept units. Since we use 
a bottom-up approach when selecting content, in 
order to achieve different text complexity levels, 
a sentence aggregation step is needed. The ag-
gregation module is in charge of merging propo-
sitions that describe an entity, creating a more 
complex sentence that will encompass the infor-
mation selected that describes the referring ex-
pression. 
The approach proposed by (Wilkinson, 1995) 
presents the aggregation process divided in two 
major steps: semantic grouping and sentence 
structuring. Although they are interdependent, 
both are needed in order to achieve aggregation 
in a text. Initiatives on automatic aggregation (or 
only semantic grouping) of text using learning 
techniques also exist. (Barzilay, 2006), 
(Bayyarapu, 2011), (Walker, Rambow, & Rogati, 
2001) are some examples of learning aggregation 
rules and grouping constrains in order to aggre-
gate text. (Demir, 2010) presents a mechanism in 
which each proposition is a single node tree 
which can be realized as a sentence and attempts 
to form more complex trees by combining trees 
in such a way so that the more complex tree 
(containing multiple propositions) can still be 
realized as a single sentence. In order to decide 
which tree is the best one to be realized, Demir?s 
work applies the revised D-level sentence com-
plexity scale, which measures the syntactic com-
plexity of a sentence according to its syntactic 
structure. 
Although learning methodologies are innova-
tive, they strive to train the algorithms in order to 
choose the best text plan based in a specific task 
or environment (defined by the training data and 
the decision of which plan is the ?best? given the 
human subjects? judgments). Our contention is 
that a given sentence plan can be perfectly suita-
ble in one context and, at the same time, be inef-
fective in another one, making the choice of the 
best text plan a variable. For this reason, we de-
cided to take into consideration the article read-
ing level when choosing the text plan that will be 
used to design the aggregation of summaries 
generated by our system. This approach allows 
the summary of the line graph to fit coherently 
within the article?s text. Text plans, in the con-
text of this work, refer to the different set of rules 
that are followed in order to aggregate proposi-
tions before the realization phase. Each text plan 
decides how propositions related to a given enti-
ty should be combined in order to produce sen-
tences. 
4.1 Reading Level Assessment 
Much effort has been devoted to developing au-
tomated approaches for assessing text complexi-
ty. Some examples are the use of support vector 
machines (Schwarm & Ostendorf, 2005) in order 
to find topical texts at a given reading level. An-
other approach is the use of statistical language 
models (Collins-Thompson & Callan, 2005; 
Collins-Thompson & Callan, 2004) for predict-
ing reading difficulty. The combination of vo-
cabulary and grammatical features in order to 
predict reading difficulty for first and second 
language texts is the object of study in (Heilman, 
Collins-Thompson, Callan, & Eskenazi, 2007).  
(Sheehan, Kostin, Futagi, & Flor, 2010) de-
veloped a system called SourceRater (now 
named TextEvaluator), which considers features 
of text that go beyond syntactical features. The 
authors list a set of dimensions of text that influ-
ences in a text reading complexity. These dimen-
sions are: Spoken vs. Written Language, Aca-
67
  
demic Orientation, Syntactic Complexity, Narra-
tive Style, Overt Expression of Persuasion, Vo-
cabulary Difficulty, and Negation. They divide 
texts into literary and informational in order to 
assess these features and their impact in reading 
difficulty after finding that these styles have sub-
stantial differences. They evaluate their tech-
nique by comparing their results with assess-
ments done using Flesh-Kincaid reading level 
assessment (Kincaid, Fishburne, Rogers, & 
Chissom, 1975) applied to text categorized into 
grade levels by the Common Core Standards 
("Common Core State Standards Initiative," 
2014). 
Another tool, Coh-Metrix (Graesser et al., 
2004), was designed to analyze text on measures 
of cohesion, language and readability. This eval-
uator also categorizes the input text into one of 
Scientific, Narrative or Informational and it con-
siders features such as cohesion relations, user 
world knowledge, language, and discourse char-
acteristics besides syntactical features such as 
word and sentence length when assessing the text 
complexity. 
To generate text that complies with a given 
reading level, we consider that a common, well-
know, widely-used metric such as Flesch-
Kincaid or SMOG (Laughlin, 1969) will suffice 
for providing input to the text planning phase of 
our system. To assure the usefulness of this met-
ric in our context, we evaluated the similarity 
between assessments done by Flesch-Kincaid 
and SMOG and assessments made by TextEvalu-
ator. For this comparison, we used 55 articles 
from our corpus2. The results showed that for 
only 20 percent of the articles was the reading 
level assessment provided by Flesch-Kincaid and 
SMOG different from the text complexity classi-
fication done by TextEvaluator. From these re-
sults, we concluded that simple reading assess-
ments such as Flesch-Kincaid and SMOG would 
suffice for guiding the choice of syntactical text 
complexity in our generated summaries. 
4.2 Generating Summaries for Different 
Reading Levels 
When generating the initial summaries of line 
graphs, our system creates different text plans for 
each group of grade levels (each group compris-
es two or more grade levels starting at the 5th 
grade) and applies the appropriate one depending 
                                                 
2 Our Digital Library contains multimodal articles collected 
from popular media. It is available at 
http://ir.cis.udel.edu/~moraes/udgraphs 
upon the assessed reading level of the text in the 
article containing the graphic. 
Because the summary is not long enough to be 
exact when determining its reading level (since 
longer texts result in more accurate assessment 
of their reading level), we decided not to create 
one text plan for each grade level. Instead, we 
have created five grade level groups and each 
one comprises two or more grades. For each 
group of grade levels, we define a text plan that 
increases a sentence syntactic structure complex-
ity as the grade gets higher. We define a text plan 
for summaries that can range between grades 5 
(inclusive) and 7 (exclusive), another text plan 
for grades between 7 (inclusive) and 9 (excusive). 
A third text plan is defined for grades 9 inclusive 
and 11 (exclusive), one for 11 (inclusive) and 13 
(exclusive) and, finally, another one for grades 
greater than or equal to 13 (college level). 
The content selection framework, as men-
tioned earlier, defines the content of a given 
summary dynamically. Due to this fact, the 
amount of information (or the number of propo-
sitions) selected for inclusion in a summary var-
ies per graphic. Our intention is to make sure that 
the reading level of the summaries generated by 
our system do not exceed the reading level of 
their respective article?s text. It is admissible, 
however, for the summary to have a slightly 
lower reading level than the one from the text. 
The organization phase, which is a previous 
step, divides the set of propositions produced by 
the content selection module into three groups: 1) 
propositions that comprise an introduction con-
taining the high-level message of the graphic, 2) 
propositions that detail the individual trends of 
the graph, and 3) propositions that convey com-
putational information about the overall graph. 
Thus, from the set of selected propositions, the 
text plan of a given group defines rules on Noun 
Phrase (NP) density and lexical choice. When 
describing an entity, attributes of this entity can 
be added to the NP as modifiers using either ad-
jectives e.g. ?a steep rising trend?, conjunctions 
e.g., ?the rising trend is steep and volatile? or 
relative clauses e.g. ?a rising trend, which is 
steep?. When the modifier of an NP is a Verb 
Phrase (VP), it is combined using a relative 
clause e.g., ?the line graph, which presents the 
number of jackets sold in 2013...? VPs can be 
modified by adverbs e.g., ?the falling trend is 
very steep?. The text plans applies rules within 
sets of propositions that are grouped hierarchical-
ly. Within these major groups, propositions can 
only be aggregated if they belong to the same 
68
  
entity. The decision of using one syntactic struc-
ture over the other is currently based on dis-
course strategies. The complexity added by a 
relative clause over the one added by an adjec-
tive, for example, is the focus of current investi-
gation (more details in Section 8) and will be 
considered when choosing one construction over 
another.  
4.3 Lexical Choice 
Most of the work on text simplification and read-
ability assessment considers lexicalization a cru-
cial aspect for readability and comprehensibility. 
(Rello, Baeza-Yates, Bott, & Saggion, 2013) pre-
sents a system that increases the understandabil-
ity and readability of text by helping users under-
stand the text by replacing complex words with 
more common ones in the lexicon.  (Laughlin, 
1969) states that longer and more precise words 
are usually harder to understand.  
This led us to use more common words at 
lower grade levels to increase the chance of the 
text being easily understood by the reader. For 
this, we use the Word Frequency Data from the 
Corpus of Contemporary American English 
(Davies, 2008). Precise and specific words 
(which are less frequently used) that describe 
visual features of line graphs such as volatility 
and steepness are replaced by other words or ex-
pressions that are more commonly used but still 
carry the same meaning, such as ?peaks and val-
leys? or ?ups and downs?. The experiment pre-
sented in Section 6 corroborates this claim, 
showing that college level students were com-
fortable with the use of such lexical items where-
as fifth graders complained about them and as-
serted they did not know their meanings. Future 
work concerns the use of lexical items catego-
rized by reading levels (details in Section 8).  
4.4 Pronominalization 
Another important feature is the pronominaliza-
tion of referring expressions. This technique 
avoids reintroduction of entities every time they 
are mentioned. The experiment mentioned in 
Section 2 showed that the reintroduction of enti-
ties or the repetition of referring expressions 
(when a pronoun could be used) in fact jeopard-
ized the understanding of some passages in the 
summaries. The participants would usually com-
plain that a given summary was confusing be-
cause it could be ?better presented? and they 
would additionally provide us with comments 
regarding the reintroduction of the referring ex-
pressions. From these results, we concluded that 
it would be valuable to include a pronominaliza-
tion step in the aggregation phase so that even 
the summaries that are at a lower grade level 
would not repeat the referring expression when 
using multiple non aggregated sentences. 
The propositions chosen by the content selec-
tion framework contain the information about 
their memberships (features such as volatility 
and steepness point to the segment of the graphic 
they belong to). This membership information is 
the clue used to define discourse focus. Our work 
follows the approach applied in the TEXT sys-
tem (McKeown, 1992), in which pronouns are 
used in order to refer to the entity being focused 
in subsequent sentences. Also inspired by the 
work presented by (McCoy & Strube, 1999) our 
system makes use of other anaphoric expressions 
besides pronouns, such as ?the trend? or ?the 
graph?. These alternative anaphoric expressions 
are used to reintroduce entities when the dis-
course focus changes. The following example 
shows the use of pronouns and the reintroduction 
of the entity in the last set of propositions. The 
entities that are in focus in each sentence are un-
derlined and the referring expressions are bolded. 
The image shows a line 
graph. The line graph pre-
sents the number of cumula-
tive, global unredeemed fre-
quent-flier miles. It con-
veys a rising trend from 
1999 to 2005. It has a 
starting value of 5.5. It 
has an ending value of 14.2. 
The graph shows an overall 
increase of 8.7. 
The last sentence changes the focus back to 
the overall graph. Even though the entity line 
graph was already mentioned, the focus had 
changed to the entity rising trend, so when the 
focus returns to the entity line graph, the system 
makes use of a definite reference to reintroduce 
it. 
5 Examples of Summaries Generated 
for Different Reading Levels 
Below are examples of some of the summaries 
that our system generates for the graph in Figure 
1 at different reading levels. Their assessed read-
ing levels provided by SMOG are also shown3. 
The summaries in these examples are also pro-
                                                 
3 These results were obtained from using a tool available in 
the GNU project Style and Diction (FSF, 2005). 
69
  
nominalized. The pronominalization phase is 
described in Section 4.4. 
Summary for Grades > 5 and <= 7 
The image shows a line 
graph. The line graph has 
ups and downs. It presents 
the number of annual differ-
ence from Seattle's 1899 sea 
level, in inches. It conveys 
a changing trend. It con-
sists of a stable trend from 
1900 to 1928 followed by a 
rising trend through 2003. 
The first segment is the 
stable trend. It has a 
starting value of 1.97 inch-
es. The second segment is 
the rising trend. It has an 
ending value of 8.9 inches. 
(SMOG 4.8) 
 
Summary for Grades > 11 and <= 13 
The image shows a highly 
volatile line graph, which 
presents the number of annu-
al difference from Seattle's 
1899 sea level, in inches, 
in addition to conveying a 
changing trend that consists 
of a stable trend from 1900 
to 1928 followed by a rising 
trend through 2003. The 
first segment is the stable 
trend that has starting val-
ue of 1.97 inches. The sec-
ond segment is the rising 
trend that has ending value 
of 8.9 inches.  
(SMOG 10.0) 
The assessed reading level of these passages 
are below the maximum threshold due to the lim-
ited number of propositions selected by the con-
tent determination algorithm. 
6 Evaluation 
This work on aggregation was motivated by the 
evaluation described in Section 2, which was 
intended to evaluate the content selection phase 
of the system. Much to our surprise, many of the 
comments indicated that the summaries were 
difficult to read because they lacked aggregation! 
This result caused us to implement the work pre-
sented here. Our first evaluation therefore repli-
cated our first experiment where, instead of using 
a simple sentence for each proposition, sentences 
were aggregated to reflect a 7th ? 9th grade read-
ing level (the level slightly lower than the medi-
an of the articles collected for our corpus).  
Table 1 compares the results of these two ini-
tial experiments. The results4  show a dramatic 
drop in the comments related to issues with ag-
gregation. From this preliminary experiment re-
sults, we felt encouraged to pursue the generation 
of summaries suited to grade levels. 
 Number 
of  
Subjects 
Number 
of 
Responses 
Number 
of 
complaints 
Experiment 
1 16 201 22 
Experiment 
2 29 331 4 
Table 1. Comparison of results from preliminary 
experiment. 
Our second experiment targeted our genera-
tion of grade-level appropriate text. In this exper-
iment, we wished to judge whether readers at 
different reading levels would prefer texts gener-
ated by our system aimed at their reading level. 
We therefore recruited two groups of partici-
pants: (1) students from a fifth grade elementary 
school in the area and (2) undergraduate students 
in an introductory CS course at a university. 
Participants were presented with 2 summaries 
from each of 5 different graphs. One of the 
summaries was generated to be at a 5th ? 7th 
grade reading level and the other at a 11th ? 13th 
grade reading level. The participants were asked 
to select the summary they liked the best and to 
provide comments on what they did not like in 
either summary. 
Table 2 shows the results of this experiment. 
Five students from 5th grade and thirty-four 
freshmen college students were recruited to par-
ticipate. From these results we can see that, in 
fact, the majority in both groups preferred the 
grade-level appropriate summary. For the fresh-
men college students, the fact that the subjects 
were almost evenly split on their choices, even 
though they are at the same grade level, was ex-
pected. This shows that reading preferences may 
vary even among people from same age/grade 
level. Since there were subjects who preferred 
simple to complex text, we can assume that read-
ing skills can vary even within a grade level 
group. Our contention is that readers who prefer 
simple text would read venues that use simple 
text structure and syntax. That is where our ap-
                                                 
4 The number of complaints presented in Table 1 are con-
cerned only with syntactical issues. 
70
  
proach plays an even better role when looking 
into the surrounding text the user is reading. Fol-
lowing this approach, instead of assessing or ask-
ing the user which level they are in, gives us 
more chances of being successful at producing 
text that will be more appropriate to each user. 
Analyzing the results on the choices of the op-
posite summary to their target group, we noticed 
that there was an agreement amongst subjects 
regarding the type of the graph. Kids who 
showed a preference for the complex text, for 
example, did so only for graphics describing a 
simple trend, therefore having a small amount of 
information an making it easy for them to follow. 
Some college students who chose the simpler 
summary provided comments that showed to be 
independent of the reading level decisions of the 
system. Some subjects pointed that a default 
connective applied by the realizer (?in addition 
to?) was making the summary complicated to 
read. That can actually be the cause of the choice 
for the simple summary, and not necessarily the 
amount of aggregation. To address this, we con-
sider that changing the connective to a more 
common one (e.g. ?and?) would make the text 
more fluid.  
From these results, we conclude that, indeed, 
adapting the generated text to the complexity of 
text commonly read by a user is a promising path 
to follow. An experiment where we provide the 
subjects with the article accompanying the graph 
and ask them to choose the summary that they 
believe fits the text complexity of the summary is 
intended and planned as future work. We have 
initiated investigation in some automated ways 
of generating text within these different grade 
level groups and we discuss it further in Section 
8. 
 
 
Chose Sum-
maries for 5th ? 
7th Grades (%) 
Chose Summar-
ies for 11th - 13th 
Grades (%) 
5th grade 80 20 
Freshmen 
students 47 53 
Table 2. Results from experiment measuring 
choices of summaries in different reading levels. 
7 Conclusion 
Most NLG systems available today generate 
text that focus on specific target readers. Some of 
them focus on text generation for low-skilled 
readers, while others generate text for high-
skilled readers. In this work, we presented an 
approach that offers a solution that attends to the 
needs of readers at different grade levels. 
Our system generates initial summaries of line 
graphs available in popular media, so visually 
impaired users can have access to the high-level 
message these resources carry. Our contention is 
that users read articles from venues that they feel 
comfortable with reading. Therefore, we assert 
that generating summaries that fit the text com-
plexity of the overall article leverages the quality 
of the generated text. We showed an approach 
that uses Flesch-Kincaid and SMOG reading as-
sessments in order to determine the syntactical 
complexity of the generated text. From the ex-
periments performed, we conclude that pursuing 
the generation of natural language text that fits 
the reading level of the surrounding text is prom-
ising. 
8 Path Forward 
Investigation on more automated ways of decid-
ing on how to aggregate propositions is the next 
step to take. Our current aggregation method re-
lies on templates for each group. We anticipate 
some techniques to learn how different text con-
structions can affect reading measures and then 
using them when choosing an adjective over a 
relative clause for increasing the NP density and 
use of passive voice, for example. This would 
allow the aggregation phase to be easily applied 
to NLG systems in different contexts.  
Another important point is the choice of lexi-
cal items by reading level or age. We plan on 
investigating how the usage of word frequency 
by age/grade level (Carroll, 1972) might help 
achieving a more appropriate summary for a giv-
en grade level. Then, the lexical items that are 
listed as common to the target grade reading lev-
el would be applied in their respective context. 
Some comments provided on the second ex-
periment described in Section 6 were that it was 
not so easy to understand long sentences on 
which values and dates were also present. This 
aspect deserves investigation on acquiring nu-
meracy skills along with reading skills as clues to 
assess the best text complexity to present. Re-
search that assess numeracy and literacy skills of 
users is presented by (Williams & Reiter, 2008). 
From the accessibility prospective, an experi-
ment with blind users is anticipated. We intend 
to evaluate the effect of generating text in differ-
ent reading levels for people with visual and/or 
reading impairments. 
71
  
References  
Barzilay, R. (2006). Aggregation via set partitioning 
for natural language generation. Paper 
presented at the In HLT-NAACL. 
Bayyarapu, H. S. (2011). Efficient algorithm for 
Context Sensitive Aggregation in Natural 
Language generation. Paper presented at the 
RANLP. 
Carroll, J. B. (1972). A New Word Frequency Book. 
Elementary English, 49(7), pp. 1070-1074.  
Collins-Thompson, K., & Callan, J. (2005). Predicting 
Reading Difficulty with Statistical Language 
Models. J. Am. Soc. Inf. Sci. Technol., 
56(13), 1448-1462.  
Collins-Thompson, K., & Callan, J. P. (2004). A 
Language Modeling Approach to Predicting 
Reading Difficulty. Paper presented at the 
HLT-NAACL. 
Common Core State Standards Initiative. (2014).   
Retrieved 2014-01-09, from 
http://www.corestandards.org/ 
Covington, M., He, C., Brown, C., Naci, L., & 
Brown, J. (2006). How Complex is that 
Sentence? A Proposed Revision of the 
Rosenberg and Abbeduto D-Level Scale. 
Paper presented at the Research Report, 
Artificial Intelligence Center, University of 
Georgia. 
Davies, M. (2008). Word frequency data: Corpus of 
Contemporary American English. 
Demir, S. (2010). Sight for visually impaired users: 
Summarizing information graphics textually. 
University of Delaware.    
Demir, S., Oliver, D., Schwartz, E., Elzer, S., 
Carberry, S., McCoy, K. F., & Chester, D. 
(2010). Interactive SIGHT: textual access to 
simple bar charts. New Rev. Hypermedia 
Multimedia, 16, 245-279.  
Ferres, L., Lindgaard, G., Sumegi, L., & Tsuji, B. 
(2013). Evaluating a Tool for Improving 
Accessibility to Charts and Graphs. ACM 
Trans. Comput.-Hum. Interact., 20(5), 28:21-
28:32.  
FSF. (2005). Style and Diction GNU project. from 
www.gnu.org/software/diction 
Graesser, A. C., McNamara, D. S., Louwerse, M. M., 
Cai, Z., Dempsey, K., Floyd, Y., . . . 
Correspondence, F. Y. (2004). Coh-Metrix: 
Analysis of text on cohesion and language. 
Paper presented at the M. Louwerse Topics 
in Cognitive Science. 
Heilman, M., Collins-Thompson, K., Callan, J., & 
Eskenazi, M. (2007). Combining Lexical and 
Grammatical Features to Improve 
Readability Measures for First and Second 
Language Texts. Paper presented at the HLT-
NAACL. 
Kincaid, J. P., Fishburne, R. P., Rogers, R. L., & 
Chissom, B. S. (1975). Derivation of New 
Readability Formulas (Automated 
Readability Index, Fog Count and Flesch 
Reading Ease Formula) for Navy Enlisted 
Personnel. 
Laughlin, G. H. M. (1969). SMOG Grading-a New 
Readability Formula. Journal of Reading, 
12(8), pp. 639-646.  
McCoy, K., & Strube, M. (1999). Generating 
Anaphoric Expressions: Pronoun or Definite 
Description? Paper presented at the ACL 
WORKSHOP ON DISCOURSE AND 
REFERENCE STRUCTURE. 
McKeown, K. (1992). Text Generation: Cambridge 
University Press. 
Moraes, P. S., Carberry, S., & McCoy, K. (2013). 
Providing access to the high-level content of 
line graphs from online popular media. 
Paper presented at the Proceedings of the 
10th International Cross-Disciplinary 
Conference on Web Accessibility, Rio de 
Janeiro, Brazil. 
Rello, L., Baeza-Yates, R., Bott, S., & Saggion, H. 
(2013). Simplify or Help?: Text 
Simplification Strategies for People with 
Dyslexia. Paper presented at the Proceedings 
of the 10th International Cross-Disciplinary 
Conference on Web Accessibility, New 
York, NY, USA. 
Rello, L., & Baeza-Yates, R. A. (2012). The presence 
of English and Spanish dyslexia in the Web. 
The New Review of Hypermedia and 
Multimedia, 18(3), 131-158.  
Schwarm, S. E., & Ostendorf, M. (2005). Reading 
Level Assessment Using Support Vector 
Machines and Statistical Language Models. 
Paper presented at the Proceedings of the 
43rd Annual Meeting on Association for 
Computational Linguistics, Stroudsburg, PA, 
USA. 
Sheehan, K. M., Kostin, I., Futagi, Y., & Flor, M. 
(2010). Generating automated text 
complexity classifications that are aligned 
with targeted text complexity standards. 
Walker, M. A., Rambow, O., & Rogati, M. (2001). 
SPoT: a trainable sentence planner. Paper 
presented at the Proceedings of the second 
meeting of the North American Chapter of 
the Association for Computational 
Linguistics on Language technologies, 
Stroudsburg, PA, USA. 
Wilkinson, J. (1995). Aggregation in Natural 
Language Generation: Another Look. 
Williams, S., & Reiter, E. (2008). Generating basic 
skills reports for low-skilled readers*. 
Natural Language Engineering, 14(4), 495-
525.  
Wu, P., Carberry, S., Elzer, S., & Chester, D. (2010). 
Recognizing the intended message of line 
graphs. Paper presented at the Proceedings 
of the 6th international conference on 
72
  
Diagrammatic representation and inference, 
Berlin, Heidelberg. 
 
73
Proceedings of the 8th International Natural Language Generation Conference, pages 95?98,
Philadelphia, Pennsylvania, 19-21 June 2014. c?2014 Association for Computational Linguistics
Generating Summaries of Line Graphs 
 
Priscilla Moraes, Gabriel Sina, Kathleen McCoy and Sandra Carberry 
Department of Computer and Information Sciences 
University of Delaware, Newark, Delaware, USA 
 [pmoraes | gsina | mccoy | carberry]@udel.edu 
 
Abstract 
This demo presents a Natural Language Gener-
ation (NLG) system that generates summaries 
of informational graphics, specifically simple 
line graphs, present in popular media. The sys-
tem is intended to capture the high-level 
knowledge conveyed by the graphic and its out-
standing visual features. It comprises a content 
selection phase that extracts the most important 
content of the graphic, an organization phase, 
which orders the propositions in a coherent 
manner, and a realization phase that uses the 
text surrounding the article to make decisions 
on the choice of lexical items and amount of ag-
gregation applied to the propositions to gener-
ate the summary of the graphic. 
1 Introduction 
Multimodal documents from online popular me-
dia often contain information graphics that aug-
ment the information found in the text. These 
graphics, however, are inaccessible for visually 
impaired users or in environments where the im-
age cannot be processed/displayed. Our system 
captures the high-level content of the graphic and 
produces a textual summary that conveys it. Fig-
ure 1 shows the system architecture.  
The first step is the identification of the pres-
ence of a graphical image in the web page by a 
Browser Helper Object (BHO) (Elzer et al., 2007). 
If a graphic is present on the web page, the Graph-
ical Information Extraction Module (VEM) 
(Chester & Elzer, 2005) is triggered by the BHO  
in order to extract the data from the image. The 
VEM then produces an XML representation of the 
graphic that is used by the Intention Recognition 
Module (IRM) for simple bar charts (Elzer, 
Green, Carberry, & Hoffman, 2006), simple line 
graphs (Wu, Carberry, Elzer, & Chester, 2010) 
and grouped bar charts (R. Burns, Carberry, & 
Elzer, 2010; R. Burns, Carberry, & Schwartz, 
2013; R. J. Burns, 2013). The XML representation 
1 http://ir.cis.udel.edu/~moraes/udgraphs 
of the graphic, along with the intended message 
identified by the IRM, is sent to the Generation 
Module (GM), which produces a textual summary 
of the most important content presented in the 
graphic. The system produces an initial summary 
and follow-up responses for simple bar charts 
(Demir, Carberry, & Elzer, 2009; Demir, 
Carberry, & McCoy, 2008) and this demo pre-
sents the GM for simple line graphs. 
This demo focuses on presenting the generation 
phase of the system. For that, we will demonstrate 
the generation of summaries in the context of a 
digital library that is available online 1 and that 
contains information graphics collected from 
online popular media, along with the articles con-
taining the graphics. In addition, we have included 
hand-generated XML representations for the 
graphics (the current VEM is not fully robust). For 
each article that contains a graph, the user can 
choose to have access to the generated summary 
by clicking on the ?Generate summary? button 
(highlighted in Figure 2). Figure 2 shows a screen-
shot on which the graph shown in Figure 3 has its 
article featured. 
For accessibility projects that may use our sys-
tem (applications developed for visually impaired 
users, for example), the application might use a 
combination of key strokes to allow user interac-
tion. The module of the system that is the focus of 
this demo is the Generation Module. 
 
 
Figure 1: System Architecture
                                                
95
 
Figure 2: Digital library screenshot where we have added summary generation functionality. 
2 Generation Module 
For generating summaries of line graphs, the first 
step is the selection of content. In order to select 
the most important features of the line graph that 
should be conveyed in the summary, the system 
represents the intended message and the visual 
features identified by a human subject experiment 
(Greenbacker, Carberry, & McCoy, 2011) using a 
graph. A centrality-based algorithm, which is an 
adapted version of PageRank (Page, Brin, 
Motwani, & Winograd, 1999), is then imple-
mented to select the most important information 
(represented as nodes in the graph). This imple-
mentation allows semantic relationships between 
propositions to be represented on the edges of the 
graph. The core of the content selection frame-
work is to detect present outstanding visual fea-
tures in the graphic, along with its intended mes-
sage, in order to select nodes. Details in the con-
tent selection phase are available in the work pre-
sented at (P. S. Moraes, Carberry, & McCoy, 
2013). 
The next phase is the organization of the se-
lected content. The organization phase works by 
ordering the selected propositions such that the 
delivered summary is fluent and coherent. The 
summaries are organized having an introduction 
section, a detailed section and a conclusion. The 
introduction consists of overall information about 
the line graph (the type of the graph, the entity be-
ing measured, the volatility of the graph and its 
intended message). The identified trends are de-
scribed in the detail section. For this part of the 
summary, pieces of the graphic that outstand due 
to its visual features may be described first, being 
followed by other trends. Finally, the conclusion 
section of the summary presents computational 
information about the graphic (overall value and 
rate change, time span of the graphic, maximum 
and minimum points and dates when they occur). 
The strategies on organizing the summaries are 
described in (P. Moraes, McCoy, & Carberry, 
2014). 
The last step of the Generation Module is the 
aggregation of propositions into more complex 
sentences. This decision is usually left to the de-
signer?s choice on how much aggregation to per-
form when generating text. Some systems are de-
signed to generate simple text for people with low 
reading abilities (Williams & Reiter, 2005a). As 
stated by (Williams & Reiter, 2005b), most NLG 
systems available generate text for high-skilled 
users. Our system generates line graph summaries 
that fit the reading level of the article in which the 
line graph appears. We contend that users gener-
ally read articles from venues they feel comforta-
ble with reading. In this manner, we intrinsically 
assess the user?s reading level without needing to 
actively survey it. 
 
Figure 3: A line graph present in popular media. 
96
The first step of the aggregation phase is to as-
sess the reading level of the article?s text. There is 
a myriad of techniques to measure the reading 
level of text. Much of them use machine learning 
techniques in order to learn text constructions and 
lexicalization used in different grade levels. As 
presented in (P. Moraes et al., 2014), simpler and 
well established reading level measurement tech-
niques suffice for our scenario. The work shows 
that Flesh-Kincaid (Kincaid, Fishburne, Rogers, 
& Chissom, 1975) and SMOG (Laughlin, 1969) 
provide the set of information needed by the sys-
tem in order to make decisions of syntactical text 
complexity. 
After assessing the reading level of the article, 
the system then uses the text plan that applies to 
the identified reading level. Text plans define 
rules on Noun Phrase (NP) density and lexical 
choice. When describing an entity, attributes of 
this entity can be added to the NP as modifiers us-
ing either adjectives e.g. ?a highly volatile rising 
trend?, conjunctions e.g., ?the rising trend is vol-
atile and steep? or relative clauses e.g. ?a rising 
trend, which is highly volatile?. When the modi-
fier of an NP is a Verb Phrase (VP), it is combined 
using a relative clause e.g., ?the line graph, which 
presents the number of jackets sold in 2013...? 
VPs can be modified by adverbs e.g., ?the falling 
trend is very steep?. The text plans apply rules 
within sets of propositions that are grouped hier-
archically. The system then uses the appropriate 
lexical items (highly volatile vs ups and downs; 
conveys vs shows) and applies the appropriate 
amount of aggregation in order to realize sen-
tences. 
 
Figure 4: Pop up window with the resulting sum-
mary generated by the system. 
Figure 4 and Figure 5 display the summaries 
generated for a user whose reading level is 11th-
13th grade and 5th-7th grade respectively. From 
these one can see the different aggregation and 
lexical choice decisions made for the different 
reading levels. The system also includes appropri-
ate pronominalization in order to avoid repetition 
of the referring expressions (P. Moraes et al., 
2014). 
 
Figure 5: Example of a summary adapted to the 
reading level of grades 5 to 7. 
For the surface realization phase we use 
FUF/SURGE (Elhadad & Robin, 1999) to create 
the templates for realization. The template are cre-
ated based on the text plans defined for a given 
reading level, as described above. 
3 Conclusion 
This paper presents the demonstration of the gen-
eration module of SIGHT. For the demo, the gen-
eration module works on a digital library that ar-
chives informational graphics collected from pop-
ular media available online. The aggregation 
phase of the generation module tailors the syntac-
tical complexity of the generated text to that of the 
article?s text in which the graphic appears.  
An evaluation of the text summaries generated 
at different reading level is presented at (P. 
Moraes et al., 2014). It shows that, indeed, differ-
ent users have different preferences regarding dif-
ferent text designs. 
4 Future Work 
A more automated way of defining a text plan for 
a given reading level is under investigation. We 
will explore techniques for learning how different 
text constructions can affect reading measures and 
then using these learned models when choosing an 
97
adjective over a relative clause for increasing the 
NP density and use of passive voice, for example.  
Choosing lexical items that are classified by 
age is another possibility. We plan on investigat-
ing how the usage of word frequency by age/grade 
level (Carroll, 1972) might influence the overall 
generated summaries. 
5 Acknowledgement 
Gabriel Sina was supported by the Coor-
dena??o de Aperfei?oamento de Pessoal de N?vel 
Superior from Brazil CAPES ? in Portuguese. 
References  
Burns, R., Carberry, S., & Elzer, S. (2010). Visual and 
spatial factors in a bayesian reasoning 
framework for the recognition of intended 
messages in grouped bar charts. Paper 
presented at the Proceedings of the AAAI 
Workshop on Visual Representations and 
Reasoning. 
Burns, R., Carberry, S., & Schwartz, S. E. (2013). 
Modeling a Graph Viewer's Effort in 
Recognizing Messages Conveyed by Grouped 
Bar Charts. Paper presented at the UMAP. 
Burns, R. J. (2013). Automated intention recognition of 
grouped bar charts in multimodal documents. 
University of Delaware, Ann Arbor. 
Retrieved from 
http://search.proquest.com/docview/1318643
227?accountid=10457   
Carroll, J. B. (1972). A New Word Frequency Book. 
Elementary English, 49(7), pp. 1070-1074.  
Chester, D., & Elzer, S. (2005). Getting computers to 
see information graphics so users do not have 
to. Paper presented at the the Proceedings of 
the 15th International Symposium on 
Methodologies for Intelligent Systems. 
Demir, S., Carberry, S., & Elzer, S. (2009). Issues in 
Realizing the Overall Message of a Bar Chart. 
In N. Nicolov, G. Angelova & R. Mitkov 
(Eds.), Recent Advances in Natural Language 
Processing V (pp. 311-320): John Benjamins. 
Demir, S., Carberry, S., & McCoy, K. F. (2008). 
Generating textual summaries of bar charts. 
Paper presented at the Proceedings of the 
Fifth International Natural Language 
Generation Conference, Stroudsburg, PA, 
USA. 
Elhadad, M., & Robin, J. (1999). SURGE: a 
comprehensive plug-in syntactic realization 
component for text generation. 
Computational Linguistics.  
Elzer, S., Green, N., Carberry, S., & Hoffman, J. 
(2006). A Model of Perceptual Task Effort for 
Bar Charts and its Role in Recognizing 
Intention. International Journal on User 
Modeling and User-Adapted Interaction, 
16(1), 1-30.  
Elzer, S., Schwartz, E., Carberry, S., Chester, D., 
Demir, S., & Wu, P. (2007). A Browser 
Extension For Providing Visually Impaired 
Users Access To The Content Of Bar Charts 
On The Web. Paper presented at the the 
Proceedings of the International Conference 
on Web Information Systems and 
Technologies. 
Greenbacker, C., Carberry, S., & McCoy, K. (2011, 
July). A Corpus of Human-written Summaries 
of Line Graphs. Paper presented at the 
Proceedings of the UCNLG+Eval: Language 
Generation and Evaluation Workshop, 
Edinburgh, Scotland. 
Kincaid, J. P., Fishburne, R. P., Rogers, R. L., & 
Chissom, B. S. (1975). Derivation of New 
Readability Formulas (Automated 
Readability Index, Fog Count and Flesch 
Reading Ease Formula) for Navy Enlisted 
Personnel. 
Laughlin, G. H. M. (1969). SMOG Grading-a New 
Readability Formula. Journal of Reading, 
12(8), pp. 639-646.  
Moraes, P., McCoy, K., & Carberry, S. (2014). 
Adapting Graph Summaries to the Users? 
Reading Levels. Paper presented at the 
Proceedings of the 8th International Natural 
Language Generation Conference. 
Moraes, P. S., Carberry, S., & McCoy, K. (2013). 
Providing access to the high-level content of 
line graphs from online popular media. Paper 
presented at the Proceedings of the 10th 
International Cross-Disciplinary Conference 
on Web Accessibility, Rio de Janeiro, Brazil. 
Page, L., Brin, S., Motwani, R., & Winograd, T. 
(1999). The PageRank Citation Ranking: 
Bringing Order to the Web: Stanford InfoLab. 
Williams, S., & Reiter, E. (2005a). Appropriate 
Microplanning Choices for Low-Skilled 
Readers. Paper presented at the IJCAI. 
Williams, S., & Reiter, E. (2005b). Generating 
readable texts for readers with low basic 
skills. Paper presented at the Proceedings of 
the 10th European Workshop on Natural 
Language Generation (EWNLG 2005). 
Wu, P., Carberry, S., Elzer, S., & Chester, D. (2010). 
Recognizing the intended message of line 
graphs. Paper presented at the Proceedings of 
the 6th international conference on 
Diagrammatic representation and inference, 
Berlin, Heidelberg. 
 
98
