Proceedings of the NAACL HLT 2010: Demonstration Session, pages 29?32,
Los Angeles, California, June 2010. c?2010 Association for Computational Linguistics
Serious Game Environments for Language and Culture Education 


Alicia Sagae, W. Lewis Johnson, and Rebecca Row 
Alelo, Inc. 
12910 Culver Boulevard, Suite J 
Los Angeles, CA 90066, USA 
{asagae, ljhonson, rrow}@alelo.com 
 
 
 
 
 
 
Abstract 
In this demonstration we will present technol-
ogies that enable learners to engage in spoken 
conversations in foreign languages, integrat-
ing intelligent tutoring and serious game ca-
pabilities into a package that helps learners 
quickly acquire communication skills.  Con-
versational AI technologies based on the 
SAIBA framework for dialog modeling are 
realized in this 3-D game environment.  Par-
ticipants will be introduced to tools for author-
ing dialogs in this framework, and will have 
an opportunity to experience learning with 
Alelo products, including the Operational 
Language and Culture Training System 
(OLCTS). 
1 Introduction 
Alelo's language and culture education environ-
ments, including The Tactical Language and Cul-
ture Training System (TLCTS) and the Operational 
Language and Culture Training System (OLCTS), 
are AI-enhanced learning platforms that help 
learners quickly acquire communication skills in 
foreign languages and cultures.  They have been 
developed by Alelo, Inc. based on a prototype de-
veloped at the University of Southern California 
(USC).   
These environments utilize an integrated combi-
nation of intelligent tutoring system and serious 
game technologies.  Trainees work through a series 
of interactive lessons and exercises, called the Skill 
Builder, focusing on mission-oriented communica-
tion skills.  The lessons make extensive use of au-
tomated speech recognition focused on learner 
language, and provide learners with feedback on 
their performance.  Cultural notes describing cus-
toms and nonverbal gestures are integrated into the 
Skill Builder lessons.  Trainees apply their skills in 
an interactive Arcade Game, where they use spo-
ken commands in the target language to navigate a 
town grid, and in a Mission Game, where they par-
ticipate in real-time dialog with simulated local 
people in order to accomplish their mission. 
2 Systems that Impact Learners  
Five TLCTS/OLCTS training courses have been 
developed so far: Tactical IraqiTM, focusing on Ira-
qi Arabic, Tactical PashtoTM and Tactical DariTM 
focusing on the predominant dialects spoken in 
Afghanistan, Tactical FrenchTM for Sahel Africa, 
and Operational IndonesianTM.  TLCTS courses are 
complete training courses, providing all of the 
training materials needed to conduct basic training 
in foreign language and culture.  For example, Tac-
tical IraqiTM includes eighteen Mission Game 
scenes, ten Arcade Game levels, and sixty-three 
Skill Builder scenes comprising over 2000 lesson 
pages.  Additional scenes and lessons are under 
development.   
While the platform imposes no limit on content 
size, the material developed so far or these systems 
typically covers 80-120 hours of training.  In-game  
reference materials, including glossaries, summa-
ries of lesson content, and grammar notes, are 
29
available both as part of the training package and 
as is a support Web site.  Manuals, comprising tu-
torials and training guidelines, help with initial 
orientation, training management, and trouble-
shooting.  The OLCTS versions of these courses 
include supplementary exercises delivered on 
handheld devices and on the web, giving trainees a 
range of platforms for "train-anywhere" access. 
TLCTS rapidly transitioned into widespread use.  
Computer labs for training with TLCTS courses 
have been established in numerous locations in the 
USA and around the world.  An estimated twenty-
five thousand US military users have trained with 
the system, and consistently rate it highly.  It has 
also been made available to service members in 
allied military forces. 
Although the Tactical Language and Culture 
concept was originally developed under military 
funding, the approach can be applied quite general-
ly to language and culture learning.  The key is that 
the courses are task-oriented: the learner has a task 
to carry out, the Skill Builder helps the learner to 
acquire the skills necessary to carry out the task, 
and the Mission Game gives the learner an oppor-
tunity to practice the task in compelling simulated 
settings. 
 
 
3 Conversational Agent Technologies 
Simulated dialogs are executed by the virtual hu-
man architecture described in (Johnson & Valente, 
2008).  The architecture adopts a variant of the 
SAIBA framework (Vilhjalmsson & Marsella, 
2005), which separates intent planning (the choice 
of what to communicate) from production of be-
lievable behavior (how to realize the communica-
tion).  An overview of the social simulation 
process is given in Figure 1.   
3.1 Rule-Driven Behavior 
Virtual human behavior is generated by a series of 
components that include explicit models of speech 
and language (for natural language understanding 
and generation) as well as behavior-mapping rules 
that implicitly reflect the subject-matter expertise 
of the rule authors.  These rules generally occur at 
the level of communicative acts (Traum & Hin-
kelman, 1992).  A simple example of such a rule, 
expressed in natural language, is shown below: 
 
IF the learner says that your home is beautiful,  
THEN reply that it is quite plain 
(1) 
Utterance
Automated
Speech
Recognizer
Interpretation
Rules
Environmental
Context
Cultural
Context
Dialog 
Context
Intent Planning
Agent
Behavior 
Interpretation
Communicative 
Act <FML>
Behavior
Generation
Translation 
Rules
Behavior 
Specification
<BML>
Behavior
Realization
Communicative 
Act <FML>
Input Processing
Conversation
Cache
Personality Model
Language Model
Culture Model
World Model
(physical/social)
Agent Models 
Input
Processing
Social Simulation
Module
Game
Engine
Simulation 
Management
AgentAgent
Social Simulation Manager (API)
Player
Player Speech 
+- Gesture
Figure 1.  Dialog simulation architecture in Alelo language and culture training systems 
30
 3.2 Collaborative Authoring 
Rules like (1) are created by a content development 
team with expertise in linguistics and cultural anth-
ropology.  This work is supported by a set of web-
based collaborative authoring tools, called Kona 
and TIDE.  Kona is used to create lesson content 
for the Skill Builder, while TIDE is a graphical 
editor used to encode dialog rules as transitions in 
a Finite State Machine.   
Kona gives authors access to a database of les-
son content, specified in XML format.  The authors 
can selectively lock and edit lessons in the data-
base, and view and edit different fields in the spe-
cification of each page in the lesson.  The author 
can edit the written descriptions of the image on 
the page, the cultural notes, and the enabling learn-
ing objectives (ELOs) covered in the page.  In oth-
er views, authors can link in images and sound 
recordings, and make notes and comments for oth-
er authors to review.  The lesson specifications are 
then automatically translated into the internal data 
format used in OLCTS, so that authors can review 
the lessons as they appear in the training applica-
tion.  
4 The Demonstration 
The demonstration will give participants an oppor-
tunity to use OLCTS, and other Alelo interactive 
language and culture training products, and learn 
about their supporting authoring tools.  It is in-
tended for people who are interested in gaining an 
in-depth understanding of AIED (artificial intelli-
gence in education) technology for serious games, 
and the development tools used to create them.  
The demo will be conducted by a presenter, who 
will give live demonstrations of the software, and 
an assistant presenter who will coach the partici-
pants in the use of the game and supporting author-
ing tools. 
 
4.1 Overview 
First, the participants will get a hands-on intro-
duction to one of the Operational Language and 
Culture courses.  Under supervision of a presenter, 
 
Figure 2.  Screen shot of a Mission Game dialog in Operational DariTM 
31
the participants will learn to say a few phrases in 
the Skill Builder and use the phrases that they have 
learned in the Mission Game.  This portion can be 
tailored on the fly to the interests of participants, 
and can take from 5 to 30 minutes to complete. 
Depending on time and interest, participants 
may also have an opportunity to work with an 
OLCTS course in more depth.  They can be called 
upon to learn some basic communication skills in 
Dari and apply them in the Mission Game.  This 
will give participants a firsthand understanding of 
how each component of OLCTS supports learning, 
how the components support each other, and how 
artificial intelligence technology is applied in the 
learning experience.   
Finally, the presenter will demo some of the au-
thoring tools used to create OLCTS content.  The 
participants will propose modifications or exten-
sions to an existing OLCTS course.  The presenter 
will use the authoring tools in real time to make the 
modifications, following the recommendations of 
the participants. 
4.2 Example: Engaging in a Dialog in Opera-
tional DariTM 
For a video summary of the demonstration, please 
visit http://www.alelo.com/movie_tlt-6min.html. 
The user experience in the Mission Game is one 
engaging component of this demonstration.  An 
example script for a Mission Game interaction in 
Alelo's Operational DariTM course is given in the 
following sections. 
A sample of a Mission Game screen is shown in 
Figure 2.  The player controls the figure in the cen-
ter-left.  At this point in the demonstration, the 
player has received a briefing that describes a 
communication task that he or she should accom-
plish in this exercise.  To complete the task, the 
player must engage the virtual human, or non-
player character (NPC) shown on the right.   
Organizing rebuilding operations is one example 
of such a task.  The NPC is a host-national charac-
ter in Afghanistan.  The player should check on the 
status of their shared plan for rebuilding and give 
constructive feedback.  This type of communica-
tion task can require finesse and delicacy on the 
part of the player in order to be culturally appro-
priate.  It draws on the learner's understanding and 
skill with face-saving, a prominent feature of many 
cultures worldwide. 
The learner must initiate the conversation by 
speaking into a headset-mounted microphone.  He 
or she clicks on the microphone icon, shown in 
Figure 3, speaks, then clicks on the icon again to 
indicate the end of the turn. 
 
 
 
Figure 2.  Push the microphone button to speak during a 
dialog, push again to stop. 
 
Recognized player speech is posted to a dialog his-
tory window that appears near the top of the virtual 
scene, as shown in Figure 1.  The NPC responds 
using spoken output, creating a realistic and engag-
ing practice environment.  During the dialog, the 
player may view hints that display key phrases in 
Dari.  Once the player has discussed all of the host 
national's training mistakes, the dialog ends in suc-
cess. 
 
References  
H. Vilhjalmsson and S. Marsella. "Social Performance 
Framework", in Proceedings of the AAAI Workshop 
on Modular Construction of Human-Like Intelli-
gence. 2005. 
W. L. Johnson and A. Valente. ?Tactical Language and 
Culture Training Systems: Using Artificial Intelli-
gence to Teach Foreign Languages and Cultures?, in 
Proceedings of IAAI 2008. March 2008. 
David R. Traum and Elizabeth A. Hinkelman. "Conver-
sation Acts in Task-Oriented Spoken Dialogue", in 
Computational Intelligence, 8(3):575--599, 1992. 
 
32
Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 241?244,
The University of Tokyo, September 24-25, 2010. c?2010 Association for Computational Linguistics
Validation of a Dialog System for Language Learners 
 
 
Alicia Sagae, W. Lewis Johnson, Stephen Bodnar 
Alelo, Inc. 
Los Angeles, CA 
{asagae,ljohnson,sbodnar}@alelo.com 
 
  
 
Abstract 
 
In this paper we present experiments related to 
the validation of spoken language understand-
ing capabilities in a language and culture train-
ing system.  In this application, word-level 
recognition rates are insufficient to character-
ize how well the system serves its users.  We 
present the results of an annotation exercise 
that distinguishes instances of non-recognition 
due to learner error from instances due to poor 
system coverage.  These statistics give a more 
accurate and interesting description of system 
performance, showing how the system could 
be improved without sacrificing the instruc-
tional value of rejecting learner utterances 
when they are poorly formed. 
1 Introduction 
Conversational practice in real-time dialogs with 
virtual humans is a compelling element of train-
ing systems for communicative competency, 
helping learners acquire procedural skills in addi-
tion to declarative knowledge (Johnson, Rickel et 
al. 2000).  Alelo's language and culture training 
systems allow language learners to engage in 
such dialogs in a serious game environment, 
where they practice task-based missions in new 
linguistic and cultural settings (Barrett and 
Johnson 2010).  To support this capability, Alelo 
products apply a variety of spoken dialog tech-
nologies, including automatic speech recognition 
(ASR) and agent-based models of dialog that 
capture theories of politeness (Wang and 
Johnson 2008), and cultural expectations (John-
son, 2010; (Sagae, Wetzel et al 2009).  
To properly assess these dialog systems, we 
must take several issues into account.  First, us-
ers who interact with these systems are language 
learners, who can be expected occasionally to 
produce invalid speech, and who may benefit 
from the corrective signal of recognizer rejec-
tion.  Second, word recognition is one step in a 
social simulation pipeline that allows virtual hu-
mans to respond to learner input (Samtani, 
Valente et al 2008).  Consequently, the system 
goals extend beyond word-level decoding into 
meaning interpretation and response planning. 
As a result, Word Error Rate (WER) and re-
lated metrics, such as those described by Hunt 
(1990) for evaluating ASR performance, are in-
sufficient to characterize how well the speech 
understanding component of the dialog system 
performs. We need a meaningful way to account 
for the performance of the dialog system as a 
whole, which can distinguish acceptable interpre-
tation failures from unacceptable ones. 
We present a validation process for assessing 
speech understanding in dialog systems for lan-
guage training applications.  The process in-
volves annotation of historical user data acquired 
from learner interaction with the Tactical Lan-
guage and Culture Training System (Johnson and 
Valente 2009).   The results indicate that learner 
mistakes make up the majority of non-
recognitions, confirming the hypothesis that 
?recognition failures? are a complex category of 
events that are only partly explained by lack of 
coverage in speech understanding components 
such as ASR. 
2 Metrics for Dialog System Assessment  
Speech recognition errors in the dialog system 
result in at least two sub-types of error: non-
understandings, where the system cannot find an 
interpretation for user input, and misunderstand-
ings, where the system finds an interpretation 
that does not match the learner?s intent (McRoy 
and Hirst 1995). 
These classes generalize beyond speech rec-
ognition to speech understanding.  This is shown 
in Figure 1, where "act" refers to a message 
241
modeled along the lines of Traum & Hinkleman 
(1992).  In the context of speech-enabled dialog 
systems, the understanding task is more critical, 
since it more closely models the overall success 
of the communication between the human user 
and the virtual human interlocutor. 
 
 
 
Figure 1.  Speech understanding pipeline. 
 
As a result, a variety of metrics have been sug-
gested that assess performance at the level of 
intent recognition, rather than word recognition.  
Examples include PARADISE (Walker, Litman 
et al 1998) and the work of Suendermann, Lis-
combe, et al(2009). 
We propose an assessment procedure that uses 
expert annotation to compare speaker-intended 
acts to the acts recognized by the speech-
understanding component of the dialog system.  
Like the metrics mentioned above, it evaluates 
the system's ability to recognize intent as well as 
words.  However we focus our attention on adap-
tations that characterize interactions with lan-
guage learners, who are a special type of user.  
As a result, we can distinguish system non-
understandings and mis-understandings that are 
due to system error from those that are caused by 
learner mistakes. 
Our goal is to use this information to reduce 
mis-understandings due to system errors; such 
mis-understandings can yield confusing dialog 
behavior, causing learners to lose confidence in 
the accuracy of the speech recognizer. Non-
understandings may be less serious, since they 
occur in real life between learners and native 
speakers. Non-understandings due to learner er-
ror may be beneficial if the additional practice 
that results from non-understandings leads to an 
increase in language accuracy. 
3 Procedure 
To assess performance, we recruited two annota-
tors to provide judgments on historical log data 
regarding the accuracy of the system interpreta-
tions at multiple levels, including word-level 
recognition and act recognition.   
3.1 Annotation team and data collection 
The annotators are Alelo team members with 
expertise in General Linguistics, French and 
Spanish Linguistics, Translation, and Teaching 
English as a Foreign Language (TEFL).  Their 
combined experience in content authoring for 
Alelo courses covers more than 10 languages. 
The data was collected in the fall of 2009 as 
part of a field test for Alelo courses teaching Ira-
qi Arabic and Sub-Saharan French.  Naval per-
sonnel at several sites around the United States 
volunteered to complete the courses in self-
study.  The training systems generated user logs, 
capturing recordings of learner turns and system 
recognition results for each turn.  From these 
logs, samples of beginner-level and intermediate-
level dialogs were selected and anonymized for 
annotation. 
3.2 Speech understanding accuracy 
The point of this exercise is to explore how of-
ten the system fails to understand what a learner 
is trying to say during spoken dialog.  
Annotation was performed on a total of 345 
learner turns.  To determine the act-level accura-
cy of the speech understanding system, annota-
tors listened to the recording of each turn and 
selected the act they heard from a drop-down list.  
The results were compared with the system-
perceived act result recovered from the log.  
Speech understanding rejections, where the sys-
tem determined that no meaningful act could be 
perceived from the learner turn, were labeled 
with the act name "garbage".  Human annotators 
could also select the garbage act for recordings 
where no meaningful interpretation could be 
made.   
4 Results 
To analyze the results, we measure system ac-
curacy at two levels.  First, we determine accura-
cy on distinguishing meaningful utterances (ut-
terances that annotators labeled with an act) from 
non-meaningful speech attempts (labeled as gar-
bage by annotators).  The results are shown in 
Table 1.  Inter-annotator agreement as measured 
by Cohen's Kappa on the first task is 0.8, indicat-
ing good agreement between our two experts.  
Next, we examine the utterances classified as 
meaningful by both the system and the annota-
242
tors, to assess correctness at a finer level of gra-
nularity: given that the system identified the ut-
terance as meaningful, did the meaning that it 
assigned match our annotators? judgments?  If 
not, mis-understandings occur.  These results are 
shown in Table 2.  System mis-understandings 
over all meaningful utterances.  Inter-annotator 
agreement on the non-understanding classifica-
tion task was 0.73, suggesting that there is sub-
stantial agreement between our raters. 
4.1 Correct interpretations 
Numbers in the bottom-right cells of Table 1 
and the first row of Table 2 represent correct sys-
tem interpretations, according to an annotator.  In 
these instances, the annotator assigned an act to 
the turn that matched the system interpretation 
for that turn (in Table 2), or both the annotator 
and the system assigned the label "garbage" (in 
Table 1).  On average these examples account for 
62% of the total turns. 
An important result from this procedure is that 
it reveals the class of appropriate rejections by 
the speech understanding component.  These 
"garbage-in, garbage-out" instances are instruc-
tive cases where the system indicates to the 
learner that he or she should re-try the utterance.  
4.2 Mis-understandings 
In Table 2, the row labeled "Incorrect" con-
tains mis-understandings, where the system made 
an interpretation but failed to match the expert 
annotation. Mis-understandings account for 
around 3.5% of the turns in our data set, on aver-
age.   The low rate of mis-understandings is an 
encouraging result for the overall quality of the 
understanding component. Prior to the introduc-
tion of the garbage model into the speech recog-
nizer the mis-understanding rate had been rela-
tively high, and these results indicate a signifi-
cant improvement. 
  Annotator 1 
  Act Garbage 
System Act 175 3 
Garbage 94 73 
   
  Annotator 2 
  Act Garbage 
System Act 176 2 
Garbage 134 33 
Table 1. Distinguishing meaningful utterances 
(corresponding to an Act) from non-meaningful 
attempts (Garbage). 
System Annotator 1 Annotator 2 
Correct 167 160 
Incorrect 8 16 
Table 2.  System mis-understandings over all mea-
ningful utterances. 
4.3 Non-understandings 
Instances from the data set where the annota-
tor was able to interpret an act, but the system 
returned "garbage," are shown in the lower-left 
cells of Table 1. These are system non-
understandings, since the speech understanding 
component was not able to map the learner input 
to a meaningful act, even though the annotators 
were.   Non-understandings account for 33% of 
turns in our data set, on average.   
To understand the impact of these non-
understandings on dialog system quality, we 
must consider the specialized case of language 
learners.  Several components of the speech un-
derstanding pipeline are tuned with language 
learners in mind.  For example, acoustic models 
used in the automatic speech recognizer are 
trained on a mixture of native and non-native 
data.  The goal is for the system to be as tolerant 
as possible of pronunciation variability, while 
still catching learner mistakes.   
  We expect learner speech attempts to occur 
on a continuum, ranging from fully correct to 
minor mistakes to unrecoverable errors.  In the 
first procedure, the annotators were instructed to 
label a recording with a meaningful act in all 
cases where they could do so, using garbage only 
for unintelligible attempts.  As a result, we con-
sciously placed the annotator tolerance at the far 
end of this spectrum.   
Since the system is less forgiving, we hypo-
thesize that the non-understandings we found 
mask two different sub-classes: instances where 
the system truly failed to interpret a well-formed 
utterance, and instances where the system was 
(perhaps appropriately) rejecting a learner mis-
take: an intelligible but malformed utterance.  
In a follow-up procedure, the annotators revi-
sited instances labeled as non-understandings.  In 
this second round, they distinguished instances 
where the learner successfully performed an act 
that was simply outside the coverage of the 
speech understanding system from instances 
where they perceived a learner error, either in 
pronunciation or grammar.  The results are sum-
marized in Table 3.  
We found that most of the cases of non-
recognition were actually due to learner error, 
rather than system error.  
243
Annotator 1  
Error Type Count  
Learner Grammar 0  
Learner Pronunciation 58 (62%)  
System Error 36  
Total 94  
  
Annotator 2  
Error Type Count ? 
Learner Grammar 2 0 
Learner Pronunciation 85 (63%) 0.65 
System Error 47 0.65 
Total 134 0.73 
Table 3.  Classification of non-understandings.  
Inter-annotator agreement (?) is substantial 
over all classes. 
 
5 Conclusions and Future Work 
By applying a method for assessment that goes 
beyond word recognition rate, we have produced 
an analysis of the speech understanding compo-
nents in a dialog system for language learners.  
Expert annotators found that most system-
understood speech attempts were interpreted cor-
rectly, with mis-understandings occurring only 
3% of the time.  While non-understandings oc-
curred much more frequently, a follow-up exer-
cise showed that learner pronunciation error was 
the most frequent cause; these cases are legiti-
mate candidates for system rejection, leaving 
12% of all instances as non-understandings 
where the system was at fault.   These instances 
represent the most beneficial errors to correct 
when making refinements to the speech under-
standing module.  
In this exercise, one could interpret the hu-
man-assigned acts as a model of recognition by 
an extremely sympathetic hearer.  Although this 
model may be too lenient to provide learners 
with realistic communication practice, it could be 
useful for the dialog engine to recognize some 
poorly-formed utterances, for the purpose of 
providing feedback.  For example, a learner who 
repeatedly attempts the same utterance with un-
acceptable but intelligible pronunciation could 
trigger a tutoring-style intervention (?Are you 
trying to say bonjour?  Try it more like this...?).   
The assessment methods and analysis pre-
sented in this paper are a first step toward this 
type of system improvement, one that meets the 
needs of language learners as a unique type of 
dialog-system user. 
 
 
Acknowledgments 
The authors thank Rebecca Row and Mickey 
Rosenberg for their contributions to the experi-
ments described here, and three anonymous re-
viewers for comments that improved the clarity 
of the paper. This work was sponsored by PM 
TRASYS, Voice of America, the Office of Naval 
Research, and DARPA. Opinions expressed here 
are those of the author and not of the sponsors or 
the US Government. 
References  
Barrett, K. A. and W. L. Johnson (2010). Developing 
serious games for learning language-in-culture. Inter-
disciplinary Models and Tools for Serious Games: 
Emerging Concepts and Future Directions. R. V. Eck. 
Hershey, PA, IGI Global. 
  
Hunt, M. J. (1990). "Figures of Merit for Assessing 
Connected Word Recognisers." Speech Communica-
tion 9: 239-336. 
  
Johnson, W. L., J. Rickel, et al (2000). "Animated 
Pedagogical Agents: Face-to-Face Interaction in In-
teractive Learning Environments." Journal of Artifi-
cial Intelligence in Education 11: 47--78. 
  
Johnson, W. L. and A. Valente (2009). "Tactical Lan-
guage and Culture Training Systems: Using AI to 
Teach Foreign Languages and Cultures." AI Maga-
zine 30(2). 
  
McRoy, S. W. and G. Hirst (1995). "The repair of 
speech act misunderstandings by abductive infe-
rence." Computational Linguistics 21(4): 435--478. 
  
Sagae, A., B. Wetzel, et al (2009). Culture-Driven 
Response Strategies for Virtual Human Behavior in 
Training Systems. SLaTE-2009, Warwickshire, Eng-
land. 
  
Samtani, P., A. Valente, et al (2008). Applying the 
SAIBA framework to the Tactical Language and Cul-
ture Training System. AAMAS 2008 Workshop on 
Functional Markup Language (FML). 
  
Suendermann, D., J. Liscombe, et al (2009). A hand-
some set of metrics to measure utterance classification 
performance in spoken dialog systems. SigDial 2009. 
  
Walker, M. A., D. J. Litman, et al (1998). "Evaluat-
ing spoken dialogue agents with PARADISE: Two 
case studies." Computer Speech & Language 12(4): 
317-347. 
  
Wang, N. and W. L. Johnson (2008). The Politeness 
Effect in an Intelligent Foreign Language Tutoring 
System. ITS 2008. 
244
