Proceedings of the 2010 Workshop on Biomedical Natural Language Processing, ACL 2010, pages 117?125,
Uppsala, Sweden, 15 July 2010. c?2010 Association for Computational Linguistics
Towards Internet-Age Pharmacovigilance: Extracting Adverse Drug
Reactions from User Posts to Health-Related Social Networks
Robert Leaman1, Laura Wojtulewicz2, Ryan Sullivan2
Annie Skariah2, Jian Yang1, Graciela Gonzalez2
1School of Computing, Informatics and Decision Systems Engineering
2Department of Biomedical Informatics
Arizona State University, Tempe, Arizona, USA
{robert.leaman, whitz, rpsulli, annie.skariah,
jian.yang, graciela.gonzalez}@asu.edu
Abstract
Adverse reactions to drugs are among the
most common causes of death in industri-
alized nations. Expensive clinical trials are
not sufficient to uncover all of the adverse
reactions a drug may cause, necessitating
systems for post-marketing surveillance,
or pharmacovigilance. These systems
have typically relied on voluntary report-
ing by health care professionals. However,
self-reported patient data has become an
increasingly important resource, with ef-
forts such as MedWatch from the FDA al-
lowing reports directly from the consumer.
In this paper, we propose mining the re-
lationships between drugs and adverse re-
actions as reported by the patients them-
selves in user comments to health-related
websites. We evaluate our system on a
manually annotated set of user comments,
with promising performance. We also re-
port encouraging correlations between the
frequency of adverse drug reactions found
by our system in unlabeled data and the
frequency of documented adverse drug re-
actions. We conclude that user comments
pose a significant natural language pro-
cessing challenge, but do contain useful
extractable information which merits fur-
ther exploration.
1 Introduction
It is estimated that approximately 2 million pa-
tients in the United States are affected each year by
severe adverse drug reactions, resulting in roughly
100,000 fatalities. This makes adverse drug re-
actions the fourth leading cause of death in the
U.S, following cancer and heart diseases (Giaco-
mini et al, 2007). It is estimated that $136 bil-
lion is spent annually on treating adverse drug re-
actions in the U.S., and other nations face simi-
lar difficulties (van Der Hooft et al, 2006; Leone
et al, 2008). Unfortunately, the frequency of ad-
verse drug reactions is often under-estimated due
to a reliance on voluntary reporting (Bates et al,
2003; van Der Hooft et al, 2006).
While severe adverse reactions have received
significant attention, less attention has been di-
rected to the indirect costs of more common
adverse reactions such as nausea and dizziness,
which may still be severe enough to motivate the
patient to stop taking the drug. The literature
shows, however, that non-compliance is a major
cause of the apparent failure of drug treatments,
and the resulting economic costs are estimated to
be quite significant (Urquhart, 1999; Hughes et al,
2001). Thus, detecting and characterizing adverse
drug reactions of all levels of severity is critically
important, particularly in an era where the demand
for personalized health care is high.
1.1 Definitions
An adverse drug reaction is generally defined as
an unintended, harmful reaction suspected to be
caused by a drug taken under normal conditions
(World Health Organization, 1966; Lee, 2006).
This definition is sufficiently broad to include such
conditions as allergic reactions, drug tolerance,
addiction or aggravation of the original condition.
A reaction is considered severe if it ?results in
death, requires hospital admission or prolonga-
tion..., results in persistent or significant disabil-
ity/incapacity, or is life-threatening,? or if it causes
a congenital abnormality (Lee, 2006).
117
1.2 Pharmacovigilance
The main sources of adverse drug reaction in-
formation are clinical trials and post-marketing
surveillance instruments made available by the
Food and Drug Administration (FDA), Centers
for Disease Control and Prevention (CDC) in the
United States, and similar governmental agencies
worldwide. The purpose of a clinical trial, how-
ever, is only to determine whether a product is
effective and to detect common serious adverse
events. Clinical trials, by their nature and pur-
pose, are focused on a limited number of par-
ticipants selected by inclusion/exclusion criteria
reflecting specific subject characteristics (demo-
graphic, medical condition and diagnosis, age).
Thus, major uncertainties about the safety of the
drug remain when the drug is made available to
a wider population over longer periods of time,
in patients with co-morbidities and in conjunction
with other medications or when taken for off-label
uses not previously evaluated.
Recently, the regulatory bodies of both the U.S.
and the U.K. have begun programs for patient re-
porting of adverse drug reactions. Studies have
shown that patient reporting is of similar qual-
ity to that of health professionals, and there is
some evidence that patients are more likely to
self-report adverse drug reactions when they be-
lieve the health professionals caring for them have
not paid sufficient attention to an adverse reaction
(Blenkinsopp et al, 2007). In general, however,
the FDA advocates reporting only serious events
through MedWatch.
Self-reported patient information captures a
valuable perspective that might not be captured in
a doctor?s office, clinical trial, or even in the most
sophisticated surveillance software. For this rea-
son, the International Society of Drug Bulletins
asserted in 2005 that ?patient reporting systems
should periodically sample the scattered drug ex-
periences patients reported on the internet.?
1.3 Social Networks
Social networks focusing on health related topics
have seen rapid growth in recent years. Users in
an online community often share a wide variety
of personal medical experiences. These interac-
tions can take many forms, including blogs, mi-
croblogs and question/answer discussion forums.
For many reasons, patients often share health ex-
periences with each other rather than in a clini-
cal research study or with their physician (Davi-
son et al, 2000). Such social networks bridge
the geographical gap between people, allowing
them to connect with patients who share similar
conditions?something that might not be possible
in the real world.
In this paper we propose and evaluate automat-
ically extracting relationships between drugs and
adverse reactions in user posts to health-related
social network websites. We anticipate this tech-
nique will provide valuable additional confirma-
tion of suspected associations between drugs and
adverse reactions. Moreover, it is possible this
technique may eventually provide the ability to
detect novel associations earlier than with current
methods.
2 Related Work
In the work closest in purpose to this study, two
reviewers manually analyzed 1,374 emails to the
BBC and 862 messages on a discussion forum re-
garding a link between the drug paroxetine and
several adverse reactions including withdrawal
symptoms and suicide (Medawara et al, 2002).
The authors concluded that the user reports con-
tained clear evidence of linkages that the voluntary
reporting system then in place had not detected.
Not much work has been done to automatically
extract adverse reactions from text, other than the
SIDER side effect resource, which was created by
mining drug insert literature (Kuhn et al, 2010).
There is, however, significant literature support for
mining more general concepts, such as diseases.
MetaMap is a primarily lexical system for map-
ping concepts in biomedical text to concepts in
the UMLS Metathesaurus (Aronson, 2001). The
ConText system categorizes findings in clinical
records as being negated, hypothetical, or histor-
ical (Harkema et al, 2009).
Most of the work on finding diseases concerns
either biomedical text or clinical records. A no-
table exception is the BioCaster system, which de-
tects infectious disease outbreaks by mining news
reports posted to the web (Collier et al, 2008).
Health social networks have become a popular
way for patients to share their health related expe-
riences. A considerable amount of research has
been devoted to this area (Moturu et al, 2008),
but most of this work has focused on the study of
social interactions and quality evaluation instead
of text mining. Automated information extrac-
118
tion from health social network websites remains
largely unexplored.
3 Data Preparation
We used the DailyStrength1 health-related social
network as the source of user comments in this
study. DailyStrength allows users to create pro-
files, maintain friends and join various disease-
related support groups. It serves as a resource for
patients to connect with others who have similar
conditions, many of whom are friends solely on-
line. As of 2007, DailyStrength had an average
of 14,000 daily visitors, each spending 82 minutes
on the site and viewing approximately 145 pages
(comScore Media Metrix Canada, 2007).
3.1 Data Acquisition
To efficiently gather user comments about spe-
cific drugs from the DailyStrength site, we im-
plemented a highly parallelized automatic web
crawler. All data was scraped from the raw
HTML using regular expressions since the site has
no open API. Users indicate a specific treatment
when posting comments to DailyStrength, how-
ever we filter treatments which are not drugs. For
each user comment we extracted the user ID, dis-
ease name, drug name, and comment text. While
more information about each user is available at
the site (gender, age, self-declared location, and
length of membership at the site), we limited our
data usage to just the comment data. The Dai-
lyStrength Privacy Policy states that comments
made by users will be publicly available. All
data was gathered in accordance with the Dai-
lyStrength Terms of Service, and to respect fair
use the data will not be made publicly available
without permission from the site.
3.2 Preparing the Lexicon
To enable finding adverse reactions in the user
comments, we created a lexicon by combining
terms and concepts from four resources.
The UMLS Metathesaurus is a resource con-
taining many individual biomedical vocabularies
(National Library of Medicine, 2008). We utilized
a subset limited to the COSTART vocabulary cre-
ated by the U.S. Food and Drug Administration for
post-marketing surveillance of adverse drug reac-
tions, which contains 3,787 concepts.
1http://www.dailystrength.org
The SIDER side effect resource contains 888
drugs linked with 1,450 adverse reaction terms
extracted from pharmaceutical insert literature
(Kuhn et al, 2010). We used the raw term found
in the literature and the associated UMLS concept
identifier (CUI).
The Canada Drug Adverse Reaction Database,
or MedEffect2, contains associations between
10,192 drugs and 3,279 adverse reactions, which
we used to create a list of adverse reaction terms.
We found many adverse reaction terms with very
similar meanings, for example ?appetite exagger-
ated,? and ?appetite increased,? which we grouped
together manually.
We also included a small set of colloquial
phrases we located manually in a subset of the
DailyStrength comments and mapped to UMLS
CUIs. This list is available3, and includes the
terms ?throw up,? meaning vomit, ?gain pounds,?
meaning weight gain, and ?zonked out,? meaning
somnolence.
We considered all terms which are associated
with the same UMLS concept identifier (CUI) as
synonymous and grouped them into a single con-
cept. We also merged all concepts containing a
term in common into a single unified concept. Our
lexicon contains 4,201 unified concepts, each con-
taining between one and about 200 terms.
4 Annotation
We annotated comments relating to the following
4 drugs: carbamazepine, olanzapine, trazodone,
and ziprasidone. These drugs were chosen be-
cause they are known to cause adverse reactions
and we could verify our results with close collabo-
rators. We retained but did not annotate comments
for the drugs aspirin and ciprofloxacin; these com-
ments are used during evaluation. Our data con-
tains a total of 6,890 comment records. User com-
ments were selected for annotation randomly and
were independently annotated by two annotators.
Annotator 1 has a BS in biology, 10 years nurs-
ing experience in the behavioral unit of a long term
care facility, and has dispensed all of the drugs an-
notated. Annotator 2 has a BS and an MS in neuro-
science, and has work experience in data manage-
ment for pharmaceutical-related clinical research
and post-marketing drug surveillance.
2http://www.hc-sc.gc.ca/dhp-mps/medeff/index-eng.php
3http://diego.asu.edu/downloads/adrs
119
Concept Definition
Adverse
effect
A reaction to the drug experienced by the
patient, which the user considered nega-
tive
Beneficial
effect
A reaction to the drug experienced by the
patient, which the user considered posi-
tive
Indication The condition for which the patient is tak-
ing the drug
Other A disease or reaction related term not
characterizable as one of the above
Table 1: The concepts annotated in this study and
their definitions.
4.1 Concepts Annotated
Each comment was annotated for mentions of ad-
verse effects, beneficial effects, indications and
other terms, as defined in table 1. Each annota-
tion included the span of the mention and the name
of the concept found, using entries from the lexi-
con described in section 3.2. Each annotation also
indicates whether it refers to an adverse effect, a
beneficial effect, an indication or an other term,
which we shall call its characterization.
4.2 Annotation Practices
There are four aspects which require careful con-
sideration when characterizing mentions. First,
the stated concept may or may not be actually
experienced by the patient; mentions of concepts
not experienced by the patient were categorized as
other. Second, the user may state that the con-
cept is the reason for taking the drug. If so, the
mention was categorized as an indication. Third,
the concept may be an effect caused by the drug.
In this case, the mention is categorized as either
an adverse effect or a beneficial effect based on
whether the user considers the effect a positive
one. This requires some judgment regarding what
people normally view as positive ? while sleepi-
ness is normally an adverse effect, someone suf-
fering from insomnia would consider it a benefi-
cial effect, regardless of whether insomnia is the
primary reason for taking the drug. Mentions of
concepts which were experienced by the patient
but neither an effect of the drug nor the reason for
taking it were also categorized as other. Concepts
were characterized as an adverse effect unless the
context indicated otherwise.
Comments not containing a mention or that only
indicated the presence of an adverse effect (?Gave
me weird side effects?) were discarded. If more
than one mention occurred in a comment, then
each mention was annotated separately.
Some comments clearly mentioned an adverse
reaction, but the reaction itself was ambiguous.
For example, in the comment ?It did the job when
I was really low. However, I BALLOONED on
it,? the annotator could infer ?BALLOONED? to
mean either weight gain or edema. A frequent ex-
ample is colloquial terms such as ?zombie,? which
could be interpreted as a physiological effect (e.g.
fatigue) or a cognitive effect (e.g. mental dull-
ness). In such cases, each mention was annotated
by using both the context of the mention and an-
notator?s knowledge of the effects of the drug.
Spans were annotated by choosing the mini-
mum span of characters from the comment that
would maintain the meaning of the term. Lo-
cating the mention boundaries was straightfor-
ward in many cases, even when descriptive words
were in the middle of the term (?It works bet-
ter than the other meds ive taken but I am
gaining some weight?). However some com-
ments were not as simple (?it works but the
pounds are packing on?).
4.3 Corpus Description
A total of 3,600 comments were annotated, a sam-
ple of which can be seen in table 2. We reserved
450 comments for system development. The an-
notators found 1,260 adverse effects, 391 indica-
tions, 157 beneficial effects and 78 other, for a to-
tal of 1,886 annotations.
We measured the agreement between annotators
by calculating both kappa (?) (Cohen, 1960) and
inter-annotator agreement (IAA). For ?, we con-
sidered agreement to mean that the concept terms
were in the same unified concept from the lexicon
and the characterization of the mentions matched,
since there is no standard method for calculating
? which includes the span. For IAA, we added
the constraint that the annotation spans must over-
lap, since discussions of IAA typically include the
span. Using these definitions, ? was calculated to
be 85.6% and IAA to be 85.3%4.
5 Text Mining
Since the drug name is specified by the user when
the comment is submitted to DailyStrength, no ex-
4?>IAA here due to the different definitions of agree-
ment.
120
Sample Comments Annotations
hallucinations and weight gain ?hallucinations? - hallucinations: adverse effect; ?weight gain?
- weight gain: adverse effect
This has helped take the edge off of my constant sorrow.
It has also perked up my appetite. I had lost a lot of
weight and my doctor was concerned.
?constant sorrow? - depression: indication; ?perked up my ap-
petite? - appetite increased: beneficial effect; ?lost a lot of
weight? - weight loss: other
It worked well, but doctor didn?t asked for the treatment
to continue once my husband was doing well again.
none
ARGH! Got me nicely hypomanic for two weeks, then
pooped out on me and just made me gain a half pound
a day so I had to stop.
?hypomanic? - hypomania: beneficial effect; ?pooped out? -
tolerance: adverse effect; ?gain a half a pound a day? - weight
gain: adverse effect
Works to calm mania or depression but zonks me and
scares me about the diabetes issues reported.
?mania? - mania: indication; ?depression? - depression: indi-
cation; ?zonks me? - somnolence: adverse effect; ?diabetes? -
diabetes: other
Works for my trigeminal neuralgia. Increasing to see if
it helps stabalize mood. Fatigue!
?trigeminal neuralgia? - trigeminal neuralgia: indication; ?sta-
balize mood? - emotional instability: indication; ?Fatigue? -
fatigue: adverse effect
Take for seizures and bipolar works well ?seizures? - seizures: indication; ?bipolar? - bipolar disorder:
indication
fatty patti! ?fatty? - weight gain: adverse effect
Table 2: An illustrative selection of uncorrected comments submitted to the DailyStrength health-related
social networking website, and their associated annotations.
traction was necessary for drug names. To ex-
tract the adverse drug reactions from the user
comments, we implemented a primarily lexical
method, utilizing the lexicon discussed in section
3.2.
5.1 Methods Used
Each user comment was split into sentences using
the Java sentence breaker, tokenized by splitting at
whitespace and punctuation, and tagged for part-
of-speech using the Hepple tagger (Hepple, 2000).
Stop-words were removed from both user com-
ments and lexical terms5. Tokens were stemmed
using the Snowball implementation of the Porter2
stemmer6.
Terms from the lexicon were found in the user
comments by comparing a sliding window of to-
kens from the comment to each token in the lexical
term. The size of the window is configurable and
set to 5 for this study since that is the number of
tokens in the longest term found by the annotators.
Using a sliding window allows the tokens to be in
different orders and for there to be irrelevant to-
kens between the relevant ones, as in weight gain
and ?gained a lot of weight.?
Since user comments contain many spelling er-
rors, we used the Jaro-Winkler measurement of
string similarity to compare the individual tokens
5http://ir.dcs.gla.ac.uk/resources/linguistic utils/stop words
6http://snowball.tartarus.org
(Winkler, 1999). We scored the similarity between
the window of tokens in the user comment and the
tokens in the lexical term by pairing them as an
assignment problem (Burkard et al, 2009). We
then summed the similarities of the individual to-
kens and normalized the result by the number of
tokens in the lexical term. This score is calculated
for both the original tokens and the stemmed to-
kens in the window, and the final score is taken to
be the higher of the two scores. The lexical term is
considered to be present in a user comment if the
final score is greater than a configurable threshold.
We noted that most mentions could be cate-
gorized by using the closest verb to the left of
the mention, as in ?taking for seizures.? As this
study focuses on adverse effects, we implemented
a filtering method to remove indications, benefi-
cial effects, and other mentions on a short list of
verbs we found to indicate them. Verbs on this
list include ?helps,? ?works,? and ?prescribe? all
of which generally denote indications. The com-
plete list is available7.
5.2 Text Mining Results
We first evaluated the system against the 3,150 an-
notated comments not reserved for system devel-
opment. Because our purpose is to find adverse
drug reactions, we limited our evaluation to ad-
7http://diego.asu.edu/downloads/adrs
121
verse effects. We used a strict definition of true
positive, requiring the system to label the mention
with a term from the same unified concept as the
annotators. The results of this study are 78.3%
precision and 69.9% recall, for an f-measure of
73.9%.
Since the purpose of this study is to determine
if mining user comments is a valid way to find ad-
verse reactions, we ran our system on all avail-
able comments and compared the frequencies of
adverse reactions found against their documented
incidence. We calculated the frequency that each
adverse effect was found in the user comments
for each of the drugs studied in this experiment.
We then determined the most commonly found ad-
verse reactions for each drug and compared them
against the most common documented adverse re-
actions for the drug. Since the four drugs we chose
for annotation all act primarily on the central ner-
vous system, we added aspirin and ciprofloxacin
for this study. The results of this evaluation con-
tain encouraging correlations that are summarized
in table 3.
6 Discussion
6.1 Error Analysis
We performed an analysis to determine the pri-
mary sources of error for our extraction system.
We randomly selected 100 comments and deter-
mined the reason for the 24 false positives (FPs)
and 29 false negatives (FNs) found.
The largest source of error (17% of FPs and
55% of FNs) was the use of novel adverse re-
action phrases (?liver problem?) and descriptions
(?burn like a lobster?). This problem is due in part
to idiomatic expressions, which may be handled
by creating and using a specialist lexicon. This
problem might also be partially relieved by the ap-
propriate use of semantic analysis. However, this
source of error is also caused by the users delib-
erately employing a high degree of linguistic cre-
ativity (?TURNED ME INTO THE SPAWN OF
SATAN!!!?) which may require deep background
knowledge to correctly recognize.
The next largest source of error was poor ap-
proximate string matching (46% of FPs and 17%
of FNs). While users frequently misspelled words,
making lexical analysis difficult, the approximate
string matching technique used also introduced
many FPs. We note that spelling unfamiliar med-
ical terminology is particularly difficult for users.
Correcting this important source of error will re-
quire improved modeling of the spelling errors
made by users.
Ambiguous terms accounted for 8% of the FPs
and 7% of the FNs. While this is frequently
a problem with colloquial phrases (?brain fog?
could refer to mental dullness or somnolence),
there are some terms which are ambiguous on their
own (?numb? may refer to loss of sensation or
emotional indifference). These errors can be cor-
rected by improving the analysis of the context
surrounding each mention.
Surprisingly, miscategorizations only ac-
counted for 4% of the FPs. This small percentage
seems to indicate that the simple filtering tech-
nique employed is reasonably effective. However
this source of error can be seen more prominently
in the frequency analysis, as seen in table 3. For
example, one of the most frequent effects found in
comments about trazodone was insomnia, which
is one of its most common off-label uses. Other
examples included depression with olanzapine,
mania with ziprasidone, and stroke with aspirin.
We note that since conditions not being experi-
enced by the patient are always categorized as
other, our techniques should profit somewhat
from an extension to handle negation.
6.2 Analysis of Documented vs. Found
Adverse Reactions
The experiment comparing the documented inci-
dence of adverse reactions to the frequency they
are found contained some interesting correlations
and differences. We begin by noting that the ad-
verse reaction found most frequently for all 6 of
the drugs corresponded to a documented adverse
reaction. There were also similarities in the less
common reactions, such as diabetes with olanzap-
ine and bleeding with aspirin. In addition, many of
the adverse reactions found corresponded to docu-
mented, but less common, reactions to the drug.
Examples of this included edema with olanzap-
ine, nightmares with trazodone, weight gain with
ziprasidone, tinnitus with aspirin, and yeast infec-
tion with ciprofloxacin.
One interesting difference is the relative fre-
quency of ?hangover? in the comments for ziprasi-
done. Since the users were not likely referring to
a literal hangover, they were probably referring
to the fatigue, headache, dry mouth and nausea
that accompany a hangover, all of which are doc-
122
Drug name
(Brand name)
Primary Indi-
cations
Documented Adverse Effects
(Frequency)
Adverse Effects Found in User Comments (Fre-
quency)
carbamazepine
(Tegretol)
epilepsy,
trigeminal
neuralgia
dizziness, somnolence or fa-
tigue, unsteadiness, nausea,
vomiting
somnolence or fatigue (12.3%), allergy (5.2%),
weight gain (4.1%), rash (3.5%), depression (3.2%),
dizziness (2.4%), tremor/spasm (1.7%), headache
(1.7%), appetite increased (1.5%), nausea (1.5%)
olanzapine
(Zyprexa)
schizophrenia,
bipolar
disorder
weight gain (65%), alteration
in lipids (40%), somnolence
or fatigue (26%), increased
cholesterol (22%), diabetes
(2%)
weight gain (30.0%), somnolence or fatigue
(15.9%), appetite increased (4.9%), depression
(3.1%), tremor (2.7%), diabetes (2.6%), mania
(2.3%), anxiety (1.4%), hallucination (0.7%), edema
(0.6%)
trazodone
(Oleptro)
depression somnolence or fatigue (46%),
headache (33%), dry mouth
(25%), dizziness (25%), nausea
(21%)
somnolence or fatigue (48.2%), nightmares (4.6%),
insomnia (2.7%), addiction (1.7%), headache
(1.6%), depression (1.3%), hangover (1.2%), anxi-
ety attack (1.2%), panic reaction (1.1%), dizziness
(0.9%)
ziprasidone
(Geodon)
schizophrenia somnolence or fatigue (14%),
dyskinesia (14%), nausea
(10%), constipation (9%),
dizziness (8%)
somnolence or fatigue (20.3%), dyskinesia (6.0%),
mania (3.7%), anxiety attack (3.5%), weight gain
(3.2%), depression (2.4%), allergic reaction (1.9%),
dizziness (1.2%), panic reaction (1.2%)
aspirin pain, fever,
reduce blood
clotting
nausea, vomiting, ulcers,
bleeding, stomach pain or
upset
ulcers (4.5%), sensitivity (3.8%), stroke (3.1%),
bleeding time increased (2.8%), somnolence or fa-
tigue (2.7%), malaise (2.1%), weakness (1.4%),
numbness (1.4%), bleeding (1.0%), tinnitus (0.7%)
ciprofloxacin
(Cipro)
bacterial infec-
tion
diarrhea (2.3%), vomiting
(2.0%), abdominal pain
(1.7%), headache (1.2%),
restlessness (1.1%)
abdominal pain (8.8%), malaise (4.4%), nau-
sea (3.8%), allergy (3.1%), somnolence or fatigue
(2.5%), dizziness (1.9%), weakness (1.6%), tolerance
(1.5%), rash (1.3%), yeast infection (1.1%)
Table 3: List of drugs included in the subset for analysis, with their indications and 5 most common
adverse effects together with their frequency of incidence in adults taking the drug over the course of
one year, as listed in the FDA online drug library, http://www.accessdata.fda.gov/scripts/cder/drugsatfda
(some frequency data is not available). Also the 10 most frequent adverse effects found in the the
DailyStrength data using our automated system. Correlations are highlighted in bold.
umented adverse reactions to the drug.
Users frequently commented on weight gain
and fatigue while ignoring other reactions such as
increased cholesterol. While this may be because
users are more conscious of issues they can di-
rectly observe, this hypothesis would not explain
why other directly observable reactions such as
nausea and constipation are not always reported.
Determining the general trends in the differences
between clinical and user reports is an important
area for future work.
6.3 Limitations
The present study has some limitations. We
did not analyze the demographics of the users
whose comments we mined, though it is likely
that they are predominantly from North America
and English-speaking. In future work we intend
to expand the range of users and compare their
demographics against clinical studies of adverse
reactions. Also, the drugs we annotated oper-
ate primarily on the central nervous system and
therefore have different adverse reaction profiles
than would other drugs with substantially different
mechanisms. While the inclusion of aspirin and
ciprofloxacin does provide some evidence these
techniques are more generally applicable, we also
intend to expand the range of drugs studied in fu-
ture work.
6.4 Opportunities for Further Study
In addition to our current classification for ad-
verse reactions, there are additional dimensions
along which each user comment could be studied.
For example, many comments describe the degree
of the adverse reaction, which can be straight-
forward (?extremely?) or more creative (?like a
pig?). Also, many users explicitly state whether
they are still taking the drug, typically indicating
whether their physician took them off or whether
they took themselves off (non-compliance), and
whether adverse reactions were the reason. User
123
comments can also be categorized as medically
non-descriptive (?I took one tablet and could?nt
get out of bed for days and felt like I got hit
by a truck?), somewhat medically descriptive
(?My kidneys were not functioning properly?),
or medically sound (?I ended up with severe leg
swelling?). Comments also typically indicate
whether the user is the patient or a caretaker by be-
ing phrased in either the first person or third person
narrative. Finally, users also frequently describe
whether they thought the benefits of the drug out-
weighed the adverse effects. We believe these ad-
ditional dimensions represent a fertile area for fur-
ther research.
7 Conclusion
In summary, we have shown that user comments
to health related social networks do contain ex-
tractable information relevant to pharmacovigi-
lance. We believe this approach should be eval-
uated for the ability to detect novel relationships
between drugs and adverse reactions.
In addition to the improvements discussed in
section 6, we plan in future work to increase the
scale of the study (additional drugs, additional
data sources, more user comments), improve the
characterization of reactions using rule-based pat-
terns, and evaluate the improved system with re-
spect to all characterizations.
Acknowledgments
The authors would like to thank Dr. Diana Pe-
titti for her early support and suggestions, Tasnia
Tahsin for reviewing an earlier version, Skatje My-
ers for locating mergeable reaction concepts, and
the anonymous reviewers for many useful sugges-
tions. The authors are grateful for support from
Science Foundation Arizona grant CAA 0277-
08, the Arizona Alzheimers Disease Data Man-
agement Core under NIH Grant NIA P30 AG-
19610, and the Arizona Alzheimers Consortium
pilot grant.
References
Alan R. Aronson. 2001. Effective mapping of biomed-
ical text to the UMLS Metathesaurus: the MetaMap
program. In Proceedings of the AMIA Symposium,
page 17. American Medical Informatics Associa-
tion.
D.W. Bates, R.S. Evans, H. Murff, P.D. Stetson,
L. Pizziferri, and G. Hripcsak. 2003. Detecting ad-
verse events using information technology. Journal
of the American Medical Informatics Association,
10(2):115?128.
A. Blenkinsopp, M. Wang, P. Wilkie, and P. A. Rout-
ledge. 2007. Patient reporting of suspected adverse
drug reactions: a review of published literature and
international experience. British Journal of Clinical
Pharmacology, 63(2):148?156.
Rainer Burkard, Mauro Dell?Amico, and Silvano
Martello. 2009. Assignment Problems. Society for
Industrial and Applied Mathematics.
Jacob Cohen. 1960. A Coefficient of Agreement for
Nominal Scales. Educational and Psychological
Measurement, 20(1):37?46.
Nigel Collier, Son Doan, Ai Kawazoe, Reiko Matsuda
Goodwin, Mike Conway, Yoshio Tateno, Quoc-
Hung Ngo, Dinh Dien, Asanee Kawtrakul, Koichi
Takeuchi, Mika Shigematsu, and Kiyosu Taniguchi.
2008. BioCaster: detecting public health rumors
with a Web-based text mining system. Bioinformat-
ics, 24(24):2940?2941.
comScore Media Metrix Canada. 2007. Key Measures
Report - Health.
K. P. Davison, J. W. Pennebaker, and S. S. Dickerson.
2000. Who talks? The social psychology of ill-
ness support groups. The American Psychologist,
55(2):205?217.
K.M. Giacomini, R.M. Krauss, D.M. Roden,
M. Eichelbaum, M.R. Hayden, and Y. Naka-
mura. 2007. When good drugs go bad. Nature,
446(7139):975?977.
Henk Harkema, John N. Dowling, Tyler Thornblade,
and Wendy W. Chapman. 2009. ConText: An al-
gorithm for determining negation, experiencer, and
temporal status from clinical reports. Journal of
Biomedical Informatics, 42(5):839851.
Mark Hepple. 2000. Independence and commit-
ment: Assumptions for rapid training and execution
of rule-based POS taggers. In Proceedings of the
38th Annual Meeting of the Association for Compu-
tational Linguistics, pages 277?278.
Dyfrig A. Hughes, Adrian Bagust, Alan Haycox,
and Tom Walley. 2001. The impact of non-
compliance on the cost-effectiveness of pharmaceu-
ticals: a review of the literature. Health Economics,
10(7):601?615.
International Society Of Drug Bulletins. 2005. Berlin
Declaration on Pharmacovigilance.
Michael Kuhn, Monica Campillos, Ivica Letunic,
Lars Juhl Jensen, and Peer Bork. 2010. A side ef-
fect resource to capture phenotypic effects of drugs.
Molecular Systems Biology, 6:343?348.
Anne Lee, editor. 2006. Adverse Drug Reactions.
Pharmaceutical Press, second edition.
124
Roberto Leone, Laura Sottosanti, Maria Luisa Iorio,
Carmela Santuccio, Anita Conforti, Vilma Sabatini,
Ugo Moretti, and Mauro Venegoni. 2008. Drug-
Related Deaths: An Analysis of the Italian Sponta-
neous Reporting Database. Drug Safety, 31(8):703?
713.
Charles Medawara, Andrew Herxheimer, Andrew Bell,
and Shelley Jofre. 2002. Paroxetine, Panorama
and user reporting of ADRs: Consumer intelligence
matters in clinical practice and post-marketing drug
surveillance. The International Journal of Risk and
Safety in Medicine, 15(3):161169.
S. T. Moturu, H. Liu, and W. G. Johnson. 2008. Trust
evaluation in health information on the World Wide
Web. In 30th Annual International Conference of
the IEEE Engineering in Medicine and Biology So-
ciety, pages 1525?1528.
National Library of Medicine. 2008. UMLS Knowl-
edge Sources.
John Urquhart. 1999. Pharmacoeconomic conse-
quences of variable patient compliance with pre-
scribed drug regimens. PharmacoEconomics,
15(3):217?228.
Cornelis S. van Der Hooft, Miriam C. J. M. Sturken-
boom, Kees van Grootheest, Herre J. Kingma, and
Bruno H. Ch. Stricker. 2006. Adverse drug
reaction-related hospitalisations: a nationwide study
in The Netherlands. Drug Safety, 29(2):161?168.
William E. Winkler. 1999. The state of record linkage
and current research problems.
World Health Organization. 1966. International Drug
Monitoring: The Role of the Hospital.
125
Proceedings of the 2012 Workshop on Biomedical Natural Language Processing (BioNLP 2012), pages 214?222,
Montre?al, Canada, June 8, 2012. c?2012 Association for Computational Linguistics
Automatic Approaches for Gene-Drug Interaction Extraction  
from Biomedical Text: Corpus and Comparative Evaluation 
 
 
Nate Sutton, Laura Wojtulewicz, Neel Mehta, Graciela Gonzalez 
Department of Biomedical Informatics 
Arizona State University, Tempe, Arizona, USA 
{nate.sutton, whitz, nbmehta2, graciela.gonzalez}@asu.edu  
 
  
Abstract 
Publications that report genotype-drug inte-
raction findings, as well as manually curated 
databases such as DrugBank and PharmGKB 
are essential to advancing pharmacogenomics, 
a relatively new area merging pharmacology 
and genomic research. Natural language 
processing (NLP) methods can be very useful 
for automatically extracting knowledge such 
as gene-drug interactions, offering researchers 
immediate access to published findings, and 
allowing curators a shortcut for their work.   
We present a corpus of gene-drug interac-
tions for evaluating and training systems to 
extract those interactions.  The corpus in-
cludes 551 sentences that have a mention of a 
drug and a gene from about 600 journals 
found to be relevant to pharmacogenomics 
through an analysis of gene-drug relationships 
in the PharmGKB knowledgebase.  
We evaluated basic approaches to auto-
matic extraction, including gene and drug co-
occurrence, co-occurrence plus interaction 
terms, and a linguistic pattern-based method.  
The linguistic pattern method had the highest 
precision (96.61%) but lowest recall (7.30%), 
for an f-score of 13.57%. Basic co-occurrence 
yields 68.99% precision, with the addition of 
an interaction term precision increases slightly 
(69.60%), though not as much as could be ex-
pected. Co-occurrence is a reasonable base-
line method, with pattern-based being a prom-
ising approach if enough patterns can be gen-
erated to address recall. The corpus is availa-
ble at http://diego.asu.edu/index.php/projects 
1 Introduction 
Pharmacogenomics is a relatively new area of 
biomedical research that merges pharmacology and 
molecular genomics, among other disciplines, and 
focuses on studying the effects of genetic variabili-
ty on drug toxicity and efficacy, on the discovery 
of novel genomic targets for drug development, 
and on the identification and functional characteri-
zation of polymorphisms relevant to drug action.  
Thus, publications that report genotype-drug find-
ings and manually curated databases that collect 
such findings, like PharmGKB and DrugBank 
(Hewett et al, 2002; Wishart, 2006) are of para-
mount importance to the field.  However, manual 
curation is expensive and time consuming, and 
cannot keep up with the ever increasing number of 
publications.  Natural language processing (NLP) 
methods can be very useful for automatically ex-
tracting such gene-drug interactions, offering re-
searchers immediate access to published findings, 
and allowing curators a shortcut for their work. 
 Consider for example a sentence contain-
ing an interaction NLP can help extract:  ?Only the 
epsilon4 allele of APOE was found to make a sig-
nificant (P = 0.002) but small contribution to war-
farin dose requirement.? (PMID: 16847429).  We 
can easily see that in the sentence, an APOE allele 
interacts with the drug warfarin in its dose re-
quirement.   Furthermore, at a higher level of ab-
straction, the sentence can help researchers infer 
that APOE affects the metabolic processes targeted 
by the drug warfarin. 
 NLP researchers attacking an interaction 
extraction project such as this one, will usually 
start by identifying the entities involved in the ex-
tractions and the terms that indicate such interac-
tions.  Assuming named entity recognition (NER) 
systems exist for the entities in question (or a dic-
tionary is available for direct match), the main 
concern becomes extracting true interactions.  A 
gold standard corpus would then need to be identi-
fied or created in order to evaluate and develop 
interaction extraction approaches, starting with the 
214
simplest ones.  We aim to support advancement in 
the area of gene-drug interaction extraction 
through the construction of a corpus for that task 
that offers advantages not available in another sim-
ilar corpus.  Also for that support we report on a 
study of the capabilities of different methods for 
that form of extraction. 
To achieve our aim, we describe a new 
corpus of gene-drug interactions, and compare the 
performance of two basic approaches plus the re-
implementation of a more advanced pattern-based 
approach measured against this corpus.  We do not 
seek in this publication to advance the extraction 
methods themselves, but allow a side-to-side com-
parison of approaches on a single corpus. 
 The sentences in the corpus (a total of 551) 
were randomly selected from sentences that in-
clude both a gene and a drug mention from the ab-
stracts published on a selection of journals that 
have articles relevant to pharmacogenomics. In 
general, annotations include interactions evident 
from the sentence, if any, also noting when men-
tioned genes or drugs are not involved in interac-
tions.  All sentences were annotated by the main 
author, with a second and third annotator verifying 
26% of the corpus.  The corpus is publicly availa-
ble online along with other supplementary mate-
rials including the annotation guide1.  
 The extraction methods evaluated include 
co-occurrence of a gene and a drug, co-occurrence 
of a gene and a drug plus a recognized interaction 
term, and one that uses specific linguistic patterns 
for classification based on (Coulet, Shah, Garten, 
Musen, & Altman, 2010).  The linguistic pattern 
method had the highest precision (96.61%) but 
lowest recall (7.30%), for an f-score of 13.57%. 
Basic co-occurrence yields 68.99% precision, with 
the addition of an interaction term increasing pre-
cision slightly (69.60%), though not as much as 
could be expected.  Analysis of our results show 
that performance could be immediately improved 
by improving the fundamental entity-recognition 
of drugs and genes.  
2 Related Work 
A good portion of the work presented here follows 
prior approaches to high quality protein-protein 
interaction (PPI) corpora development and extrac-
                                                          
1 http://diego.asu.edu/index.php/projects 
tion.  Given that our corpus contains genes and 
proteins as entities, procedures used to create PPI 
corpora were a useful resource.  A variety of anno-
tation decisions made were informed by the work 
of Pyysalo et. al. on their BioInfer corpus (Pyysalo 
et al, 2007).  A detailed annotation guide used in 
their work was referenced in annotation rules in 
this work.  Other corpora, such as the ones used in 
Biocreative challenges, have also made valuable 
contributions to PPI extraction progress (Haken-
berg et al, 2010; Krallinger, Leitner, Rodriguez-
Penagos, & Valencia, 2008). 
 Unlike for PPI interaction extraction, there 
are very limited currently available corpora that 
can be used for automatic gene-drug interaction 
extraction system development and evaluation.  
One corpus that contains those interactions is a 300 
sentence corpus by Ahlers et al (Ahlers, Fiszman, 
Demner-Fushman, Lang, & Rindflesch, 2007).  
The Ahlers et. al. corpus include the biological 
interaction categories of inhibit, and stimulate in 
addition to interaction annotations for genes and 
drugs.  Our corpus does not contain those addition-
al categories directly, but the interaction words that 
are annotated in our corpus can indicate such cate-
gories as well as others.  All in all, our focus was 
on creating a corpus that could be used for evalua-
tion of basic as well as complex approaches, and 
allow machine-learning based systems to be 
trained on it. 
Current systems for extracting gene-drug 
interactions are based on entity co-occurrence and 
some include matching of relationship terms.  
Those systems commonly use statistical formulas 
for ranking the relevance of results.  Polysearch, 
Pharmspresso, and others are examples of such 
systems (Cheng et al, 2008; Garten & Altman, 
2009).  Some systems integrate linguistic patterns 
into their methods, such as those by Coulet et. al. 
and Tari et. al. (Luis Tari, J?rg Hakenberg, Gracie-
la Gonzalez, & Baral, 2009).  The system by Cou-
let et al explores the value of dependency graph 
information for relationship extraction.  Another 
result of Coulet et. al.'s work was the Phare ontol-
ogy that includes concepts relevant to those rela-
tionships, which we utilize in this work. The value 
of such collections of interaction-indicating terms 
has been highlighted before in the biomedical rela-
tionship extraction context (Bui, Nuall?in, Bouch-
er, & Sloot, 2010; Chowdhary, Zhang, & Liu, 
2009). 
215
3 Materials and Methods  
3.1  Corpus design. 
The purpose for the creation of the new corpus was 
to create a resource that NLP developers can use to 
train and test gene-drug interaction extraction sys-
tems.  The corpus was based on articles from jour-
nals that are known to contain pharmacogenomic 
relationships.  Genes and drugs were automatically 
tagged and then 551 sentences that contain both a 
gene and drug were randomly selected for annota-
tion.  The corpus and sentence selection process is 
described in the following subsections.  
 
Journal Selection.  A list of journals relevant to 
pharmacogenomics was generated by extracting 
the journal names from articles that have been cu-
rated in PharmGKB as containing evidence of 
gene-drug relationships. This list was generated 
from their downloadable ?relationships? file, 
which contains the abstract IDs of articles with 
manually curated gene-drug relationships.  591 
journal names were obtained this way.  The goal of 
using only those journals is to make the corpus 
representative of typical sentences containing a 
gene and drug from literature known to report 
pharmacogenomic findings. 
 
Sentence processing. All abstracts in PubMed from 
the relevant journal names were downloaded. A 
sentence splitter program from OpenNLP was used 
to extract sentences from the abstracts (?The 
OpenNLP Homepage,? n.d.).  A total of 
22,601,402 sentences were processed.  
 
Identification of entites.  Previous work in pharma-
cogenomics relationship extraction has shown ef-
fective results by classifying relationships after 
identifying sentences with entities of interest 
through dictionary matching techniques (Garten & 
Altman, 2009; Rebholz-Schuhmann et al, 2007).  
Our work takes a similar approach, but utilizes a 
machine-learning based method, BANNER, for 
gene recognition, as it was shown to have better 
performance than a dictionary-based method 
(Leaman & Gonzalez, 2008). Drugs were recog-
nized through the use of dictionary matching.  The 
dictionaries used for drugs were based on drug 
names available at DrugBank.  Exact full token 
matching of drug terms was used to identify them 
in sentences. Although incorrectly tagged (false 
entity) genes and drugs were corrected by annota-
tors, they did not add entities missed by NER rec-
ognition. A second round of annotation will correct 
this when we shift focus to NER. 
 Terms indicative of an interaction for add-
ing to basic co-occurrence relationship extraction 
were extracted from the Phare ontology.  The 
terms acquired were from rdfs labeled text in the 
?object properties? in the ontology.  Object proper-
ties are elements of the ontology that describe rela-
tionships between classes such as gene and drugs, 
yielding 168 unique terms after stemming. 
 
Sentence selection.  The initial annotation effort 
that is the focus of this paper was aimed at com-
pleting around 500 sentences as a proof of concept, 
with a total of 1,500 to be completed in the second 
phase of this project.  Random selection of sen-
tences that include a gene and a drug, in contrast to 
balanced positive and negative selection, was used 
to make the corpus reflect typical sentences poten-
tially containing an interaction that can be easily 
extracted from the source articles after simple 
(drug and gene) concept tagging, which is the most 
basic approach to interaction extraction.  The ran-
domized ratio of positive and negative interactions 
in the corpus is useful for training classification 
systems that operate on similarly pre-processed 
sentences to account for that naturally occurring 
ratio. 
 
3.2  Annotation. 
An annotation tool named STAV was used to 
create annotations (?stav,? n.d.).  Customization of 
the tool was performed to match the types of anno-
tations needed for the corpus.  The identified enti-
ties were formatted for use with the tool.  Annota-
tions created with the tool were stored in the Bi-
oNLP shared task file format. That format is com-
patible with a variety of existing systems for rela-
tionship extraction.  
 
Annotation guidelines. Based on a review of litera-
ture on related annotation guidelines for relation-
ships such as PPIs, an initial annotation guideline 
was created based on a small sample of sentences.  
The guide was iteratively refined through annota-
tion of additional sentences, until considered suffi-
ciently stable for release to additional annotators.   
The guideline was refined to achieve a bal-
ance of complexity and clarity to assist annotators.  
216
Only a few (5-10) example sentences per annotator 
have been discussed in person.  The explicit writ-
ten instructions in the guide were relied on more 
than in-person example sentence discussions to 
train annotators to handle the complicated content 
of the corpus and avoid over-influencing the anno-
tators, as noted that is possible with the overuse of 
those examples (Hovy & Lavid, 2008). 
 The first annotator, a student with a Bache-
lor of Science (BS) in Biology, was the main anno-
tator and author of the guidelines. The second and 
third annotators are PhD students in Biomedical 
Informatics, the second with a BS in Biology and 
10 years nursing experience, and the other with a 
Bachelor of Technology in Bioinformatics.  Week-
ly annotation meetings were done on individual 
bases.  A short checklist of things to look for in 
annotations was distributed in addition to the 
guidelines. 
 
Annotations.  The following describes major anno-
tation categories and subcategories in the corpus:  
 
? Interaction  Genes and drugs are annotated 
simply as ?having an interaction? broadly un-
derstood as having an ?action, effect, or influ-
ence? on each other.  All gene-drug interac-
tions annotated must have at least one interac-
tion term that helps explain the interaction.  
Additional properties that were annotated and 
a brief explanation of their purpose include: 
o Direct/Indirect:  Describes the complexi-
ty in the interaction statements. An ?indi-
rect? interaction is one where the presence 
of an intermediary entity is needed for se-
mantic understanding of the interaction. 
o Explicit/Inferred:  Records if an infe-
rence had to be made on whether the inte-
raction was present because an interaction 
was not explicitly stated. 
? Non-interaction 
o Shared Entity:  An entity connected to 
both a gene and a drug that don't interact 
with each other.  In contrast to an interme-
diary entity. 
? Interaction Term  Terms that are descriptive 
of the interaction (as defined earlier).  These 
terms are helpful for capturing more specifical-
ly the type of interaction present.  
? Intermediary Entity  These are non-gene, 
non-drug entities that are closely connected to 
the interaction.  They are entities that are 
needed for understanding of the full semantic 
meaning of gene-drug interactions.  These enti-
ties are not annotated themselves but they are 
used to determine the indirectness property. 
 
Examples of these categories can be seen in the 
sentence: ?Using standard steady-state kinetic 
analysis, it was demonstrated that paclitaxel was a 
possible uncompetitive inhibitor to NAT activity in 
cytosols based on the decrease in apparent values 
of K(m) and V(max).? (PMID: 11955677).  This 
sentence includes an interaction between the drug 
paclitaxel and gene NAT.  An interaction term that 
helps establish that the interaction is present is ?in-
hibitor?.  ?Cytosols? is where the NAT inhibition 
activity can occur and represents an intermediary 
entity that is needed in the semantic meaning of the 
interaction. 
 The broad definition of interaction was 
used to make progress toward annotations includ-
ing, and in turn being representative of, the most 
general form of gene-drug interaction that is de-
scribed in the source abstracts.  We chose to first 
concentrate on getting good inter-annotator agree-
ment using the general definition before consider-
ing additionally annotating specific biological inte-
raction types.  Annotated interactions are required 
to have at least one annotated interaction term (al-
though terms do not have to be from the predefined 
list) to ensure that specific and identifiable lan-
guage is present that justifies the annotation.   
 The subcategories included were added to 
record the linguistic complexity in which the inte-
ractions and non-interactions are described.  Re-
cording that complexity can help system develop-
ers handle its presence when trying to automatical-
ly recognize interaction statements.  Additionally, 
the annotation properties of speculation, negation, 
and nesting were allowed but not separately anno-
tated in interaction annotations.  
 Each annotator reported annotation time 
estimates.  Total time spent on annotations includ-
ing meetings but not other work (e.g. guideline 
development) was approximately 80 hours for the 
primary annotator and 20 hours combined for other 
annotators.  Hard sentences to annotate required 
research into source articles and entities described.   
 
217
Evaluation of the Corpus. Around 26% of the cor-
pus was annotated by a second and third annotator.  
A program was created for IAA scoring, account-
ing for nested entities and equivalent entities in-
cluding abbreviations.  Manual review was used to 
verify the program?s scores.   Example sentences 
from the corpus discussed with annotators were not 
used for IAA scoring. 
 
3.3  Relationship Extraction methods. 
Three basic methods for extracting interactions 
were implemented for evaluation. The basic me-
thod, co-occurrence, is inherent to the corpus as all 
sentences are selected based on both entities being 
present in them. Thus, in co-occurrence, any men-
tion of a gene and a drug together in a sentence 
represents an interaction between those entities. 
Co-occurrence plus interaction terms, the 
second method tried, identifies that interactions are 
present only when sentences contain an interaction 
word from a predefined list.  The list of interaction 
terms obtained from the Phare ontology was fil-
tered by removing common stop words. Also, a 
filter was applied to only use terms greater than 
two letters in size.  Those filters were used to avoid 
unneeded matches from common words. 
 The linguistic pattern based extraction me-
thod developed for this evaluation was based on 
the work by Coulet et. al.  Specific linguistic pat-
terns described in that work were used to classify 
the presence of interactions between genes and 
drugs.  A program named Graph Spider was used 
to match the specified patterns within sentences 
(Shepherd & Clegg, 2008).  The Stanford Parser 
was used to generate dependency graphs for use 
with the pattern recognition in Graph Spider.   
 The dependency rules designed by Coulet. 
et. al. were entered into Graph Spider using the 
metapattern language (MPL) designed by the 
Graph Spider authors.  MPL is a pattern formalism 
that can be used to match dependency subgraph 
patterns in dependency parsed text.  After depen-
dency graphs were generated for processing in 
Graph Spider, text representing genes and drugs in 
the graphs were converted to general tags for those 
entity types.  Those conversions were made to al-
low the patterns in MPL to be generalizable.  
 Java programs were created to reformat 
and score the subgraph pattern match results made 
by Graph Spider.  Scoring used text character posi-
tions (spans) of entities included in annotations.  
True positives were recorded when pairs of entity 
spans in Graph Spider subgraph results matched 
annotated pairs of entity spans labeled as having 
interactions.  False positives and false negatives 
were similarly assessed using entity spans.  A ma-
nual evaluation of pattern matched output com-
pared to annotations was performed to ensure ac-
curacy. 
 A condition applied in the pattern based 
system was that the patterns can match up to four 
modifier words for each individual gene and drug 
in interaction pattern matches.  Those words are 
additional words that modify the meaning of the 
gene or drug in the interaction.  The limit was in-
cluded for practical reasons, as hand coding of pat-
terns in MPL is complex.  The rules described by 
Coulet et. al. did not specify any limit on modifier 
words but the difference in results by including a 
realistic limit is predicted to be negligible. 
4 Results  
A total of 551 sentences are annotated, with 781 
interactions present in them. There are 351 in-
stances of non-interactive entities in the same set.   
The average length of sentences is 28.1 words.  
Table 1 describes further properties of the corpus.   
 
Annotation Analysis. The inter-annotator agree-
ment scores are reported as accuracy and Cohen?s 
kappa.  Kappa was chosen due to its widespread 
use and therefore comparability with other work in 
corpus creation.  Accuracy is found by the number 
of instances agreed on divided by the total in-
stances annotated.  A total of 144 sentences were 
used for the scoring.  Annotators 1 and 2, 1 and 3, 
and 2 and 3 were compared using 92, 52, and 61 
sentences respectively.  IAA results with the main 
categories of interaction vs. non-interaction are 
shown in Table 2. 
 
 
Sentences Tokens (with 
punctuation) 
Words (tokens with 
no punctuation) 
551 18,585 15,464 
Table 1.  Statistics describing corpus properties. 
 1 & 2 1 & 3 2 & 3 
Accuracy 81.1% 74.2% 73.0% 
Kappa 45.7% 30.5% 11.4% 
Table 2.  Inter-annotator agreement results. 
218
 IAA scores were found for all annotated 
subcategories.  Those subcategories are DirectEx-
plicit, IndirectExplicit, IndirectInferred for interac-
tions and SharedEntity for non-interactions.  Their 
ranges of scores with all annotator pair groups us-
ing accuracy scores are 72-79%, 40-69%, 62-82%, 
50-60% and kappa scores are 31-58%, 1-27%, -4-
31%, 0-4% respectively.  Those scores are created 
by selecting main category inter-annotator matches 
(e.g. interaction) and calculating the IAA between 
the annotated subcategories. 
In some sentences, annotators missed 
doing annotations for gene-drug instances that the 
other annotator added. IAA scores did not include 
annotations made by only one annotator.  Confir-
mation with annotators was made that annotations 
not made were not intended to represent non-
interactions.  The percentage of missed inter-
annotator instances was approximately 20%.  Fu-
ture work will be to improve the inter-annotator 
annotation process so that those instances are not 
missed for IAA scoring.  While some annotations 
were missed in IAA scoring, annotations by the 
primary annotator that are included in the corpus 
contain all instances (none missed) from the source 
text to our knowledge.
 
I
D 
Contents Agree
ment 
Sentence text 
A One direct expli-
cit interaction 
Y This suggests that galantamine (GAL), a cholinesterase inhibitor, could be 
effective when seeking to prolong abstinence in recently detoxified alcohol-
ics. (PMID: 16328375) 
B One indirect ex-
plicit and four 
shared entity 
non-interactions  
Y They are widely distributed and mediate all of the known biologic effects of 
angiotensin II (AngII) through a variety of signal transduction systems, in-
cluding activation of phospholipases C and A2, inhibition of adenylate cyc-
lase, opening of calcium channels, and activation of tyrosine kinases. (PM-
ID: 9892138) 
C One indirect ex-
plicit interaction 
N The results of studies of perfused rat hearts with completely inhibited crea-
tine kinase show significantly decreased work capacity and respectively, 
energy fluxes, in these hearts in spite of significant activation of adenylate 
kinase system (Dzeja et al this volume). (PMID: 9746326) 
Table 3.  Example sentences from the corpus.
 
Table 4.  Extraction system performances.    
Note that sentences were selected based on co-
occurrence of a gene and a drug, thus recall is 
100% for that method, as it essentially defines 
the corpus. 
 
 
The scoring methods used were instance 
level scoring instead of sentence level scoring.  In 
the instance level scoring each gene-drug instance 
counted in performance scores.   
 A caveat about the pattern-based system 
scoring should be noted.  That caveat was that the 
Graph Spider software used was unable to process 
approximately 10% (around 50) of the sentences in 
the corpus due to errors.  The pattern-based system 
is likely to have scored slightly higher if it could 
have processed those sentences. 
5 Discussion 
5.1  Analyses of interaction extraction methods 
performance. 
Interaction  
Extractor Type 
Precision 
(TP/TP+FP) 
Recall 
(TP/TP+
FN) 
F1-Score 
(2*((P*R)/(
P+R))) 
Co-occurrence 68.99%  
(781/1132) 
100.00% 
(781/781) 
 
81.65% 
Co-occurrence 
plus int. terms 
69.60% 
(664/954) 
85.02% 
(664/781) 
76.54% 
Pattern-based 96.61% 
(57/59)  
7.30% 
(57/781) 
13.57% 
 
219
The f-score of co-occurrence with and without in-
teraction terms showed better performance than the 
pattern-based interaction extractions, which was 
expected. Pattern based methods, particularly those 
where the patterns were manually created, are typi-
cally very high in precision and very low in recall, 
as they are highly dependant on the specific pat-
terns included for recognition. Although recall was 
low, users who want very high confidence interac-
tion predictions or interactions of a very specific 
type can benefit from the pattern-based system?s 
demonstrated high precision. Co-occurrence can 
suit users who want to focus on recall. 
Coulet et al reported their system scored a 
precision of 70% for exact match and 87.7% for 
exact or incomplete match but true classification.  
Our results are similar to their 87.7% results in 
both percentage and scoring method.  The method 
that allows incompleteness accepts matches that 
accurately identify core pharmacogenomic rela-
tionships but don?t need to correctly match modifi-
er words.  Our scoring is similar in not needing to 
match modifier words.  The similarity in results 
indicates that we correctly implemented the system 
that Coulet et al designed.  That indication does 
have the limitation that the 10% of sentences una-
ble to be processed may have affected the results. 
An example of a more complex interaction 
that was matched by co-occurrence with an inte-
raction term but not the pattern-based method was 
?Moreover, S-nitrosylation of thioredoxin was also 
significantly augmented after atorvastatin treat-
ment.? (PMID: 15289372).  In that sentence, an 
interaction occurred where thioredoxin's (gene) S-
nitrosylation was augmented by atorvastatin 
(drug).  Analysis of the dependency graphs used by 
the pattern-based system revealed some reasons 
why it was unable to identify the interaction.  
 The pattern-based system uses a rule that 
applies to that sentence: a potential pattern se-
quence match can be ?interrupted? by a dependen-
cy that does not fit accepted patterns.  In the non-
classified sentence, the entities ?was? and ?aug-
mented? were terms that caused the pattern match-
ing to be interrupted.  Both ?was? and ?aug-
mented? are not nouns or prepositions.  They both 
also are needed in the dependency subgraph that 
connects the gene and drug together.  Those parts 
of speech are not allowed to be chained together in 
the pattern-based system's patterns.  That deviation 
from the allowed patterns caused the system to 
miss that interaction. 
Adding patterns with more diversity in al-
lowed parts of speech in series of interaction terms 
that connect genes and drugs in interactions can 
improve recall performance.  A review of parts of 
speech (POS) in missed matches showed that some 
misses were due to no verb POS tags being present 
in interaction descriptions.  That can occur when 
verbs are in their nominalized form or other situa-
tions.  Mining the corpus for both part of speech 
and dependency graph patterns can identify pat-
terns that are able to correct those misses.  Also, 
the POS tagger included with the parser mis-
tagged a variety of words.  Using a higher perfor-
mance tagger or one trained on biomedical text 
may help with pattern matches.  
Ahlers et. al. also reported relationship ex-
traction performance from a new system with their 
gene-drug corpus.  That system achieved a preci-
sion of 73% and recall of 50% extracting an anno-
tation category including gene-drug relationships.  
The system is built upon an earlier system and an 
important part of its capabilities comes from spe-
cialized linguistic rules it uses.  The corpus in-
cluded in this work can be useful for further devel-
opment of systems that integrate such rules with 
other methods to improve extraction performances. 
Some characteristics were notable about 
the results of the methods using co-occurrence 
with and without interaction terms.  The perfor-
mances found of those methods may be specific to 
an increased amount of gene-drug interactions 
found in the journals used compared to other jour-
nals.  Also, the use of interaction terms from the 
Phare ontology was expected to increase precision 
because they were found from predicted pharma-
cogenomic relationships.  The co-occurrence with 
interaction terms method resulted in only approx-
imately equaling the precision of basic co-
occurrence.  One possible reason for that is the 
terms were originally found partly with disease 
relationships.  They therefore can be less relevant 
to gene-drug interactions.   
 
5.2  Analyses of annotations 
Table 2 includes that the general interaction anno-
tations had the kappa values 46%, 30%, 11% 
which are considered only moderate to low scores 
by common rating methods.  Some IAA scores, 
such as kappa, include a correction for chance 
220
agreement probability.  An intentional design 
choice was made in the corpus to allow an unba-
lanced but natural ratio of interactions to non-
interactions.  That imbalance increased kappa?s 
correction.  Although our reasonably high IAA 
scores with accuracy helped increase the kappa 
score, they were not enough to offset the correction 
and bring kappa above the moderate score.   
 An article by Strijbos et. al. states that 
kappa can have a strict chance agreement correc-
tion in the case of few categories (Strijbos, Mar-
tens, Prins, & Jochems, 2006).  Given that general 
interaction scores were only based on the catego-
ries of present or absent, kappa may have been 
overly strict with the correction.  If that correction 
in our data is not strict, but justified, than that indi-
cates how further improving our annotation 
process can be valuable.  Further investigation will 
go into understanding what statistics may be useful 
for scoring given the corpus properties.  Explora-
tion will also continue with talking to annotator s 
about what may be causing disagreement.  That 
exploration will help reveal ways to improve IAA. 
 Subcategories showed mixed results in 
their IAA performances.  The subcategories with 
the highest IAA scores may indicate that those 
subcategories are more clearly defined than others 
in the annotation guide. 
 Reviewing some annotated sentences can 
help clarify how the IAA results occurred.  All an-
notators agreed the drug galantamine has a direct 
explicit interaction with cholinesterase in sentence 
A in Table 3.  Such an interaction description is 
simply described and an annotator has reported 
that type of interaction being the easiest to identify.   
 Agreement was found with all annotators 
for annotations in sentence B in Table 3.  It was 
readily understandable to annotators that calcium 
and other signal transduction systems do not have 
an interaction simply for all being a part of those 
types of systems. 
 An example of a sentence with annotator 
disagreement was sentence C in table 3. Although 
endogenously produced in this case, the nested 
entity creatine was considered a drug due to being 
relevant to creatine in its exogenous drug form. 
 The occurrence of multiple properties, 
such as inhibition and effects on hearts can make it 
difficult to follow the logic of the interaction be-
tween creatine and adenylate kinase (enzyme).  
The interaction annotation can be hard for annota-
tors to find due to that complexity and the subtle-
ness of the ?in spite of? phrase describing the ne-
gated effect between the drug and gene.  The inte-
raction is negated but that still is considered an 
interaction by the annotation rules used. 
   
5.3  Future Work 
As mentioned before, the corpus will grow from 
around 500 sentences that it has right now to 
around 1,500.  The larger the corpus expands to be, 
the more representative it will become of gene-
drug interactions.  Other future work includes work 
with more advanced interaction extraction systems. 
Along with this publication, a version of 
the corpus with high confidence in annotations will 
be released.  Given that this is an initial work, a 
relatively modest amount of annotation revisions 
may occur with a few periodic later version releas-
es of the corpus to improve its quality. 
 Unfortunately no tagger is perfect so as 
annotations proceed, drugs or genes that were 
missed by the tagger can be investigated to further 
understand why that occurred.  An example of a 
commonly missed drug was acetylcholine.  Ace-
tylcholine was picked up as a drug if it was spelled 
out, but not if it was abbreviated as ACh and it is 
commonly abbreviated.   
6 Conclusion 
The extraction results indicated that the systems 
tested can be utilized and built upon according to 
user preferences in precision, recall, or specific 
interaction terms.  The corpus presented here offers 
valuable utility to system developers working to-
ward achieving favorable balances of precision and 
recall in gene-drug interaction extractions.  The 
growth of that corpus will also increasingly benefit 
the developers working on those extractions.  That 
type of extraction is important to advancing work 
in pharmacogenomics by retrieving knowledge for 
individuals working in the field.  
Acknowledgements 
The authors wish to thank Ehsan Emadzadeh for 
his help with the annotation tool and Robert Lea-
man for his help with annotation methods. 
 
 
 
221
References  
Ahlers, C., Fiszman, M., Demner-Fushman, D., 
Lang, F.-M., & Rindflesch, T. (2007). Extracting 
semantic predications from Medline citations for 
pharmacogenomics. Pacific Symposium on Bio-
computing. Pacific Symposium on Biocomputing, 
209?220. 
Bui, Q.-C., Nuall?in, B. O., Boucher, C. A., & 
Sloot, P. M. A. (2010). Extracting causal relations 
on HIV drug resistance from literature. BMC Bio-
informatics, 11, 101. doi:10.1186/1471-2105-11-
101 
Cheng, D., Knox, C., Young, N., Stothard, P., Da-
maraju, S., & Wishart, D. S. (2008). PolySearch: a 
web-based text mining system for extracting rela-
tionships between human diseases, genes, muta-
tions, drugs and metabolites. Nucleic Acids Re-
search, 36(Web Server issue), W399?405. 
doi:10.1093/nar/gkn296 
Chowdhary, R., Zhang, J., & Liu, J. S. (2009). 
Bayesian inference of protein-protein interactions 
from biological literature. Bioinformatics (Oxford, 
England), 25(12), 1536?1542. 
doi:10.1093/bioinformatics/btp245 
Coulet, A., Shah, N. H., Garten, Y., Musen, M., & 
Altman, R. B. (2010). Using text to build semantic 
networks for pharmacogenomics. Journal of Bio-
medical Informatics, 43(6), 1009?1019. 
doi:10.1016/j.jbi.2010.08.005 
Garten, Y., & Altman, R. B. (2009). Pharmspresso: 
a text mining tool for extraction of pharmacoge-
nomic concepts and relationships from full text. 
BMC Bioinformatics, 10 Suppl 2, S6. 
doi:10.1186/1471-2105-10-S2-S6 
Hakenberg, J., Leaman, R., Vo, N. H., Jonnalagad-
da, S., Sullivan, R., Miller, C., Tari, L., et al 
(2010). Efficient extraction of protein-protein inte-
ractions from full-text articles. IEEE/ACM Trans-
actions on Computational Biology and Bioinfor-
matics / IEEE, ACM, 7(3), 481?494. 
doi:10.1109/TCBB.2010.51 
Hewett, M., Oliver, D. E., Rubin, D. L., Easton, K. 
L., Stuart, J. M., Altman, R. B., & Klein, T. E. 
(2002). PharmGKB: The Pharmacogenetics Know-
ledge Base. Nucleic Acids Research, 30(1), 163?
165. doi:10.1093/nar/30.1.163 
Krallinger, M., Leitner, F., Rodriguez-Penagos, C., 
& Valencia, A. (2008). Overview of the protein-
protein interaction annotation extraction task of 
BioCreative II. Genome Biology, 9 Suppl 2, S4. 
doi:10.1186/gb-2008-9-s2-s4 
Leaman, R., & Gonzalez, G. (2008). BANNER: an 
executable survey of advances in biomedical 
named entity recognition. Pacific Symposium on 
Biocomputing. Pacific Symposium on Biocomput-
ing, 652?663. 
Luis Tari, J?rg Hakenberg, Graciela Gonzalez, & 
Baral, C. (2009). Querying parse tree database of 
medline text to synthesize user-specific biomolecu-
lar networks. CiteSeerX. Retrieved from 
http://citeseerx.ist.psu.edu/viewdoc/summary?doi=
10.1.1.140.8574 
Pyysalo, S., Ginter, F., Heimonen, J., Bj?rne, J., 
Boberg, J., J?rvinen, J., & Salakoski, T. (2007). 
BioInfer: a corpus for information extraction in the 
biomedical domain. BMC Bioinformatics, 8, 50. 
doi:10.1186/1471-2105-8-50 
Rebholz-Schuhmann, D., Kirsch, H., Arregui, M., 
Gaudan, S., Riethoven, M., & Stoehr, P. (2007). 
EBIMed?text Crunching to Gather Facts for Pro-
teins from Medline. Bioinformatics, 23(2), e237?
e244. doi:10.1093/bioinformatics/btl302 
Sconce, E. A., Daly, A. K., Khan, T. I., Wynne, H. 
A., & Kamali, F. (2006). APOE genotype makes a 
small contribution to warfarin dose requirements. 
Pharmacogenetics and Genomics, 16(8), 609?611. 
doi:10.1097/01.fpc.0000220567.98089.b5 
Shepherd, A. J., & Clegg, A. B. (2008). Syntactic 
pattern matching with GraphSpider and MPL. Pro-
ceedings of the Third International Symposium on 
Semantic Mining in Biomedicine SMBM 2008 Tur-
ku Finland, 129?132. 
stav. (n.d.).GitHub. Retrieved March 26, 2012, 
from https://github.com/TsujiiLaboratory/stav 
Strijbos, J.-W., Martens, R. L., Prins, F. J., & Jo-
chems, W. M. G. (2006). Content analysis: What 
are they talking about? Computers & Education, 
46(1), 29?48. doi:10.1016/j.compedu.2005.04.002 
T1.pdf. (n.d.). Retrieved from http://www.lrec-
conf.org/proceedings/lrec2008/workshops/T1.pdf 
The OpenNLP Homepage. (n.d.). Retrieved March 
26, 2012, from 
http://opennlp.sourceforge.net/projects.html 
Wishart, D. S. (2006). DrugBank: a comprehensive 
resource for in silico drug discovery and explora-
tion. Nucleic Acids Research, 34(90001), D668?
D672. doi:10.1093/nar/gkj067 
 
222
