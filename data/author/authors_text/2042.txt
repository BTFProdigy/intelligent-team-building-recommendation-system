Context Sensing using Speech and Common Sense 
 
 
Nathan Eagle 
20 Ames St., Cambridge, MA 02139 
nathan@media.mit.edu 
Push Singh 
20 Ames St., Cambridge, MA 02139 
push@media.mit.edu 
 
 
 
 
 
Abstract 
We present a method of inferring aspects of a 
person?s context by capturing conversation 
topics and using prior knowledge of human 
behavior. This paper claims that topic-spotting 
performance can be improved by using a large 
database of common sense knowledge. We 
describe two systems we built to infer context 
from noisy transcriptions of spoken conversa-
tions using common sense, and detail some 
preliminary results. The GISTER system uses 
OMCSNet, a commonsense semantic net-
work, to infer the most likely topics under dis-
cussion in a conversation stream. The 
OVERHEAR system is built on top of 
GISTER, and distinguishes between aspects 
of the conversation that refer to past, present, 
and future events by using LifeNet, a prob-
abilistic graphical model of human behavior, 
to help infer the events that occurred in each 
of those three time periods. We conclude by 
discussing some of the future directions we 
may take this work. 
1 
2 
2.1 
Introduction 
Can we build computers that infer a speaker's context by 
summarizing the conversation's gist? Once computers 
are able to capture the gist of a conversation, an enor-
mous number of potential applications become possible. 
However, current topic-spotting methods have met with 
little success in characterizing spontaneous conversa-
tions involving hundreds of potential topics (Jebara et 
al., 2000). This paper claims that performance can be 
greatly improved by making use of not only the text of a 
speech transcription, but also perceptual and common-
sensical information from the dialogue.  
We have enabled a suite of wearable computers with 
the ability to provide the perceptual information neces-
sary for a human to infer a conversation's gist and pre-
dict subsequent events. To take the human fully out of 
the loop we have infused the system with two common-
sense knowledge bases that enable the computer to 
make educated inferences about the user's context.  
Implementation 
Our system incorporated a Zaurus Linux handheld com-
puter, with an 802.11b CF card and a wireless Bluetooth 
headset microphone. Applications were written to en-
able the Zaurus to stream high quality audio (22 kHz, 
16-bit) to an available 802.11b network, or to store the 
audio locally when no network is detected. Besides 
streaming audio, packets in this wireless network could 
be ?sniffed? by the PDAs interested in determining who 
else is in the local proximity. Information regarding 
access point signal strength information was correlated 
with location using a static table look-up procedure. The 
system is typically kept in a participant's pocket, or for 
those with Bluetooth headsets, stored in a briefcase, 
purse, or backpack. 
Audio Processing and Transcription 
ViaVoice, a commercial speech recognition engine, is 
used to transcribe the audio streams, however typically 
word recognition rates fall below 35% for spontaneous 
speech recognition (Eagle & Pentland, 2002). This inac-
curacy poses a serious problem for determining the gist 
of an interaction. However, a human can read through a 
noisy transcript and with adequate perceptual cues, still 
have an impression of the underlying conversation 
topic. 
 
Speaker 1: you do as good each key in and tell 
on that this this printers? rarely broken key fixed 
on and off-fixes and the new nine-month London 
deal on and then now take paper out and keep 
looking cartridges and then see if we confine 
something of saw someone to fix it but see Sad-
dam out of the system think even do about it had 
tools on is there a persona for the minister what 
will come paper response to use the paper is not 
really going to stay in the printer for very much 
longer high is Chinese college and shredded 
where inks that inks is really know where the 
sounds like a Swiss have to have played by ear 
than 
Speaker 2: a can what can do that now I think 
this this seems to work on which side is working 
are in 
Speaker 1: an hour riderless I E fix the current 
trend the Stratton practice page of the test cas-
ings to of printed nicely I think jacking years ago 
that is paid toes like a printed Neisse 
 
Additional context, such as information that the con-
versation is occurring in an office, or more precisely, by 
a printer, may help many people understand that the 
conversation is about fixing a printer jam. Prior knowl-
edge about the conversation participants and the time of 
day may also significantly augment a person?s ability to 
infer the gist of the interaction, for example, one of the 
speakers could be a printer repairman. Our work sug-
gests that the additional contextual and commonsensical 
information a human can employ for inference on the 
transcript above is equally helpful to a probabilistic 
model. 
As will be shown, this additional contextual and 
commonsense information can be used to form prob-
abilistic models relating observed keywords to conver-
sation topic. Thus by combining audio and information 
from a mobile device with a commonsense knowledge 
network, we can determine the gist of noisy, face-to-
face conversations. In the above example, for instance, 
our system correctly labeled the conversation as ?print-
ing on printer?. 
3 
3.1 
GISTER 
GISTER is a system that infers the most likely topics 
under discussion in a conversation stream by using a 
commonsense semantic network called OMCSNet. 
More details about the GISTER system are available in 
(Eagle et al, 2003) but we summarize its operation in 
this section. 
OMCSNet 
We built the OMCSNet commonsense semantic net-
work (Liu & Singh, 2004) by aggregating and normaliz-
ing the contributions from nearly 14,000 people from 
across the web (Singh et al, 2002). Its semantic net-
work structure resembles that of WordNet (Fellbaum, 
1998) but its content is motivated by the range of 
knowledge in commonsense knowledge bases such as 
Cyc (Lenat, 1995). As in WordNet, the nodes of 
OMCSNet are natural language terms and the links are 
drawn from a fixed ontology of semantic relationships. 
But as in Cyc, the nodes include not just single words, 
but also compound expressions such as ?at the zoo?, ?eat 
a sandwich? or ?fix a printer?, and the links are drawn 
from a broader range of semantic relationships than are 
available in WordNet; OMCSNet goes beyond simple 
?is-a? and ?part-of? relations to include spatial, temporal, 
causal, affect, and other types of relations. At present 
OMCSNet employs the 20 binary semantic relations 
shown below in Table 1. 
 
Relation Type Semantic Relation 
Things KindOf, HasProperty, PartOf, 
MadeOf 
Events SubEventOf, FirstSubeventOf, 
LastSubeventOf, HappensAfter 
Actions Requires, HasEffect, ResultsIn-
Want, HasAbility 
Spatial OftenNear, LocationOf  
Goals DoesWant, DoesNotWant, 
MotivatedBy 
Functions UsedInLocation, HasFunction 
Generic ConceptuallyRelatedTo 
 
Table 1. Semantic relations currently in OMCSNet 
 
Prior research in text summarization has recognized the 
need for general world knowledge?in SUMMARIST 
(1997), Hovy & Lin describe how the words ?gun?, 
?mask?, ?money?, ?caught?, and ?stole? together would 
indicate the topic of ?robbery?, but they note that that 
WordNet and other dictionary-like resources did not 
contain enough such knowledge. However, OMCSNet 
contains precisely this type of knowledge. It contains a 
wide variety of knowledge about many aspects of eve-
ryday life: typical objects and their properties, the ef-
fects of ordinary actions, the kinds of things people like 
and dislike, the structure of typical activities and events, 
and many other things. A small excerpt of OMCSNet is 
show in Figure 1 below. 
 
HAS USE
printer
print on printer
load in
paperprinter will jam
HAS LOCATION
HAS MOTIVATION HAS REQUIREMENT
HAS CONSEQUENCE
hard copy of 
document
configure printer
HAS FIRST STEP
putting ink on paper
HAS EFFECT
type of 
computer
hardware
IS A
paper
HAS WANT
office
 
 
Figure 1. A selection of OMCSNet?s 250,000 relations 
 
OMCSNet has been used in a variety of applications to 
date (Lieberman et al, 2004). 
3.2 GISTER infers fine-grained topics 
The purpose of the GISTER system is to infer the ?fine 
grained topic?, or gist, of a conversation. A gist is the 
class of event that most accurately summarizes the cur-
rent subject of the conversation. For example: 
? Buying a ticket to a baseball game 
? Looking for a restaurant 
? Scheduling a meeting 
? Canceling a meeting 
These gists are represented within OMCSNet as the 
nodes of the semantic network containing simple verb 
phrases. For our set of target gists, we use the 700 most 
richly defined verb phrase nodes within OMCSNet 
(those for which at least 10 facts are asserted.) 
GISTER infers gists using a two step process. First, 
the transcriptions are preprocessed to reduce the noise 
of the speech recognition engine. To do this the tran-
scriptions are lemmatized and filtered for stop words 
(such as ?like?, ?the?, ?a?, etc.), and a filtering process is 
performed using a clustering metric to reduce the num-
ber of weakly connected words. These outliers, words 
with very sparse links to the rest of the transcription, are 
removed from the data set. 
Second, the OMCSNet network is flattened into a 
bipartite network that incorporates all ties from words in 
the OMCSNet lexicon to gists. The probability of a spe-
cific gist can be modeled as proportional to the gist?s 
links to the selected words: 
1
( )
i
i G
i
i
i
k
P g k
k
GistScore k
=
=
=
?  
where  is the number of links between a gist, ik ig , and 
the observed transcript, and G is the number of potential 
gists (approximately 700). This simple method is often 
capable of identifying a small group of potential gists, 
frequently with one dominating the others. 
Once the probable topics of conversation have been 
identified and ranked, contextual information about the 
conversation is incorporated into the model. In many 
instances, information such as location or participant 
identity can identify the gist from the small subsection 
of topics. In our initial tests we incremented a gist?s 
score for each of its links to a keyword related to the 
given context. 
3.3 Experiments 
We ran a series of experiments on a testing set of 20 
speech segments ranging from 50 to 150 words and 
taken from a single individual on a wide range of topics. 
No prior knowledge about the participant was assumed, 
but the 802.11b networks were used to give general 
locations such as office and cafeteria when appropriate. 
In one test we captured conversations from the student 
center cafeteria ? streaming data to an access point 
mapped as ?restaurant?. Using this contextual informa-
tion to condition the model, our results significantly 
improved: 
 
Transcription: 
Store going to stop and listen to type of its cellu-
lar and fries he backed a bill in the one everyone 
get a guess but that some of the past like a salad 
bar and some offense militias cambers the site 
fast food them and the styrofoam large chicken 
nuggets son is a pretty pleased even guess I as 
long as can?t you don?t have to wait too long its 
complicity sunrise against NAFTA pact if for 
lunch  
 
Selected Keywords: 
wait type store stop salad past lunch long long 
listen large fry food fast chicken cellular bill big 
bar back 
 
Top Ten Scores: 
 
Without Location Context With Location Context 
5 talk with someone 
far away 
27 eat in fast food res-
taurant 
5 buy beer 21 eat in restaurant 
5 Eat in restaurant 18 wait on table 
5 eat in fast food 
restaurant 
16 you would go to 
restaurant because 
you 
5 buy hamburger 16 wait table 
4 go to hairdresser 16 go to restaurant 
4 wait in line 
 
15 know how much you 
owe restaurant 
4 howl with laughter 12 store food for people 
to purchase 
4 eat healthily 
 
11 sitting down while 
place order at bar 
4 play harp 11 cook food 
Table 2. Results of using Context for Gist Differentia-
tion 
 
Actual Situation: 
Deciding what to get for lunch while standing in 
line at the cafeteria. 
 
4 OVERHEAR 
The OVERHEAR system is a newer system, built on 
top of GISTER, and distinguishes between aspects of 
the conversation that refer to past, present, and future 
events. The system relies on LifeNet, a probabilistic 
graphical model of human behavior, to infer the events 
occurring in each of those three time periods. 
We have two reasons for trying to distinguish be-
tween past, present, and future events. First, using addi-
tional sensory context (such as addition information 
about the speakers? location) to bias the results of gist 
sensing only works when the conversation is referring to 
the present context. Often, people?s conversations re-
ferred to things that happened in the past, or things they 
were planning to do in the future, and in those cases 
sensory context only hurt GISTER?s performance. 
However, one could imagine making use of recorded, 
time-stamped sensory data to bias the gisting of conver-
sations that were talking about events that happened 
earlier. 
The structure of LifeNet is represented by a Markov 
network whose structure resembles a Dynamic Bayesian 
Network (DBN). Although lacking the 'explaining away' 
power of true Bayesian inference, the model is not con-
strained to directed acyclic graphs. LifeNet is designed 
to support the same kinds of temporal inferences as a 
DBN, including predicting future states and guessing 
prior states from the current state.  
LifeNet was built as a probabilistic graphical model 
because stochastic methods can be more tolerant than 
traditional logical reasoning methods to the uncertainty 
in our knowledge of the situation, as well as to the un-
certainty in the reliability of the rules themselves. Addi-
tionally these methods have efficient and well-known 
inference procedures for generating approximate solu-
tions. 
Second, our long term goal is to use context sensing 
from speech to build new types of context-aware appli-
cations for wearable computers and other mobile de-
vices. An application that knew that the speaker was 
referring to past events could perform tasks like retrieve 
documents and e-mails that referred to those past 
events. However, if the speaker was referring to the 
current situation, the application could know to make 
use of sensory information to improve its understanding 
of the current context. And if the speaker was referring 
to potential future events, like ?going to a movie this 
weekend?, the application could assist the user by mak-
ing plans to help make those events happen (or not hap-
pen, as the case may be), for instance by offering to 
purchase movie tickets on-line. 
Our early experiments reasoning with LifeNet treat 
it as Markov network, an undirected graphical model 
where the nodes represent random variables and the 
edges joint probability constraints relating those vari-
ables. We convert LifeNet into a series of joint prob-
abilities (the details of this process are described later 
this paper), and we reason with the resulting network 
using local belief updating techniques. We engage in 
?loopy? belief propagation as described by Pearl (Pearl, 
1988). Belief propagation in a Markov network is 
straightforward. We use the following belief updating 
rules, as described in (Yedidia et al, 2000): 
( )\
( ) ( , ) ( ) ( )ij i ij i j i i ki i
x k N ii
m x x x x m x? ? ?
?
? ? ?
j
 (1) 4.1 LifeNet 
LifeNet is a probabilistic graphical model that captures 
a first-person model of human experience. It relates 
80,000 ?egocentric? propositions with 415,000 temporal 
and atemporal links between these propositions, as 
shown in Figure 2. More details about how the LifeNet 
model is generated are given in (Singh & Williams, 
2003). 
  (2) 
( )
( ) ( ) ( )i i i i ki i
k N i
b x x m x??
?
? ?
In these rules ix represents the random variable at 
node i . The current belief in node i is denoted by ib , the 
local evidence for node i by i? and the joint probability 
of a pair of linked nodes andi j by ij? . The message 
sent from node i to j is denoted by m . ij ( )N i  is the set 
of all neighbors of node , and i ( ) \N i j represents the 
set of all neighbors of node i except for node j . is a 
normalization constant. 
?
 
I switch TV on
I watch television
I watch evening news
I put child to bed
I turn out the light
An armchair is here
A television is here
I flip a switch
A television stand is here
Before After
 
These simple updating rules run fairly quickly even 
on a knowledge base as large as LifeNet. In our opti-
mized Common Lisp implementation, on a 1.8 GHz 
Pentium 4 with 512 MB ram, a single iteration of belief 
updating runs in 15 seconds. Inference is further sped up 
by restricting the belief updating to run only on nodes 
within a fixed distance from the evidence nodes. Given 
a single evidence node and using only those nodes 
within a depth of three edges away, a single iteration of 
belief updating runs in as little as 0.5 seconds for some 
nodes; on average it takes about 3 seconds. 
4.2 Model Integration and Implementation  
Figure 2. A sample of LifeNet GISTER leverages the commonsense facts within 
OMCSNet to generate discrete conceptual topics from a  
given transcript segmented into twenty-word-long 
observations, with each twenty-word observation 
independent from the others. We extended GISTER to 
infer the average tense of the text within the observation 
by detecting verb tenses, auxiliary verbs like did and 
will, and also specific temporal expressions like 
yesterday and tomorrow. LifeNet then allows us to 
calculate the transition probabilites to a given specific 
propositional representation based on previous states. 
By using the independent output of GISTER as input 
into LifeNet, we are able to improve the inferences of a 
user's context which subsequently can be used to 
training data for improved models of human behavior. 
As shown in Figure 3, by using the output of GISTER 
for inference in LifeNet, additional insight can be 
gained about the user's situation. If the output from 
GISTER is 'eating sushi' and was assigned a past tense, 
while 'going to the doctor' was assigned a future tense, 
LifeNet can make educated inferences about what 
happened to the user. This inference can be fed back 
into the lower level of the model by weighting words 
like 'sick, full, tired', and rerunning the semantic 
filtering technique. By incorporating this feedback into 
the system, the filtering technique would be much less 
likely to exclude words related to being sick despite 
them being initally filtered from the transcript. If the 
gister's output changes, the process continues until the 
two systems converge on a solution. 
We propose a variation to the Markov network 
implementation of LifeNet described in section 4.1. 
Noisy transcript and signal data is still used as initial 
input into the system; GISTER then processes this data, 
semantically filters the speech, and calculates the likely 
subjects of conversation and their tenses. Highly ranked 
output from GISTER is then used as temporal 
observations for inference on the LifeNet model, as 
shown in Figure 3. These observations are linked to 
specific nodes within LifeNet that correspond to the 
given tense (past, present, future). We used multiple 
root nodes with weights proportional to the rank 
generated from the gister. This belief weighting system 
accounts for the uncertainty of the gister's output while 
starting with multiple roots enables much richer 
inference. 
4.3 Preliminary Results 
The system was initially tested on an office worker's 
conversation regarding how she had eaten too much the 
day before and that she will have to go to the doctor's 
office during the next day. The following transcripts 
were input into GISTER: 
 
PAST: had sushi for lunch could then have 
thought so he and then so yesterday's the sushi I 
its while I was at the Senate Committee lunch it 
tasted good sign yet was expenses over a cost me 
$7 to buy six roles and they lead to much of its in 
the rules were not a very good and I ate too 
many roles half so after words about six hours 
later I wasn't feeling very well of this so more 
Matsushita I never bought some sugar before 
usually advised chicken sandwich usual and 
normal food there I thought that this issue would 
be a good deal I also bought some seltzer water 
was so worked well and silence 
  
OMCSNet
Past Present Future
Gister
LifeNet
uggg.. ate a ton of sushi last night...
think i'm going to have to see a doctor tomorrow...
I eat sushi.
I go to the doctor's office.
I feel sick.
I
 
 
FUTURE: of debt reduction appointment tomor-
row they can see mental tomorrow to clock will 
meet Dr. Smith and he's going to put my stomach 
because of what I a yesterday bomb I'm hoping 
that when I'll feel better so looking forward to 
going 
 
In this experience an overall tense was assigned to each 
passage. GISTER correctly inferred that the first 
passage referred to past events and the second to future 
events, and output potential topics of the conversation 
for each of those time periods: 
 
 
 
 
  
Figure 3. The OVERHEAR System  
 
Past Present Future 
eat lunch 
eat 
have lunch 
get in shape 
get job 
get fit 
eat breakfast 
cook dinner 
taste something 
sweet 
lose weight 
 
 
 
 
 
 
 
 
 
 
 
 
 
fall 
have examination  
eat cookie 
go for run  
have physical exam 
eat lunch 
go on vacation 
give assistance 
take walk 
walk 
 
 
Table 3. Potential Topics Separated by Tense 
 
The topics generated by GISTER in Table 3 were 
subsquently used as observational inputs to the next 
section of the model. These topics were mapped to the 
past and future nodes within LifeNet, marked as 'true', 
and then we ran the loopy belief propogation algorithm 
described earlier. The solution converged on nodes 
representing the present state, in-between the first tier 
(past) and the third tier (future). The nodes deemed most 
likely by the system are listed in Table 4 below. 
 
Inferences on Present Situation  
0.999 I stop being hungry 
0.999 I warm feeling 
0.982 I satisfy hunger 
0.964 I make appointment  
0.962 I have energy  
0.957 I schedule appointment with doctor 
0.956 I feel worry 
 
Table 4. Inferences about Present Situation given Past 
and Future 
4.4 
5 
Training Future Models of Human Behavior 
When this system is deployed on many users over an 
extended period of time, information about people's 
behavior can begin to influence the initial priors from 
LifeNet. Although it has not been determined how addi-
tional links could be made, this represents an alternative 
method for increasing the common sense knowledge 
stored within LifeNet. Additionally, extensive observa-
tions on the same people could augment the original 
commonsense model by better reflecting an individual?s 
behavior.  
Conclusions 
Combining common sense with speech and other types 
of sensory context presents abundant opportunities 
within a wide range of fields, from artificial intelligence 
and ubiquitous computing to traditional social science. 
By integrating two common sense knowledge bases, we 
have developed a method for inferring human behavior 
from noisy transcripts and sensor data. As mobile 
phones and PDAs become ever more embedded in soci-
ety, the additional contextual information they provide 
will become invaluable for a variety of applications. 
This paper has shown the potential for these devices to 
leverage this additional information to begin under-
standing informal face-to-face conversations and infer-
ring a user's context. 
Acknowledgements 
The authors would like to thank to Hugo Liu for his 
work developing OMCSNet and Sandy Pentland. 
References 
Nathan Eagle and Alex Pentland. 2002. Information 
Explication from Computer-Transcribed Conversa-
tions. MIT Media Lab Vision and Modeling Techni-
cal Report. 
Nathan Eagle, Push Singh, and Alex Pentland. 2003. 
Common sense conversations: understanding casual 
conversation using a common sense database. Pro-
ceedings of the Artificial Intelligence, Information 
Access, and Mobile Computing Workshop (IJCAI 
2003). Acapulco, Mexico. 
Christiane Fellbaum (Ed.) 1998. WordNet: An elec-
tronic lexical database. MIT Press. 
Eduard Hovy and Chin-Yew Lin. 1997. Automated text 
summarization in SUMMARIST. In ACL/EACL-97 
Workshop on Intelligent Scalable Text Summariza-
tion. Madrid, Spain. 
Douglas Lenat. 1995. CYC: A large-scale investment in 
knowledge infrastructure. Communications of the 
ACM, 38(11). 
Henry Lieberman, Hugo Liu, Push Singh, and Barbara 
Barry. 2004. Beating Some Common Sense into In-
teractive Applications. In submission. Draft available 
at 
http://web.media.mit.edu/~lieber/Publications/Beatin
g-Common-Sense.pdf. 
Hugo Liu and Push Singh (2004). OMCSNet: A com-
monsense inference toolkit. MIT Media Lab Techni-
cal Report SOM03-01. Available at: http:// 
web.media.mit.edu/~push/OMCSNet.pdf 
Tony Jebara, Yuri Ivanov, Ali Rahimi, and Alex Pent-
land. 2000. Tracking Conversational Context for Ma-
chine Mediation of Human Discourse. Proceedings 
of AAAI Fall Symposium on Socially Intelligent 
Agents. North Falmouth, MA.  
Judea Pearl. 1988. Probabilistic reasoning in intelligent 
systems: networks of plausible inference. San Mateo, 
CA: Morgan Kaufman. 
Push Singh, Thomas Lin,  Erik T. Mueller, Grace 
Lim, Travell Perkins and Wan Li Zhu. 2002. Open 
Mind Common Sense: Knowledge acquisition from 
the general public. Proceedings of ODBASE?02. Ir-
vine, CA.  
Push Singh and William Williams. 2003. LifeNet: a 
propositional model of ordinary human activity. Pro-
ceedings of the Workshop on Distributed and Col-
laborative Knowledge Capture (DC-KCAP) at K-
CAP 2003. Sanibel Island, Florida. 
Jonathan Yedidia, William Freeman, and Yair Weiss. 
2000. Generalized belief propagation. Advances in 
Neural Information Processing Systems (NIPS), 13, 
689-695. 
 
 
Assigning Domains to Speech Recognition Hypotheses
Klaus Ru?ggenmann and Iryna Gurevych
EML Research gGmbH
Schloss-Wolfsbrunnenweg 33
69118 Heidelberg, Germany
{rueggenmann,gurevych}@eml-r.villa-bosch.de
Abstract
We present the results of experiments
aimed at assigning domains to speech
recognition hypotheses (SRH). The meth-
ods rely on high-level linguistic repre-
sentations of SRHs as sets of ontolog-
ical concepts. We experimented with
two domain models and evaluated their
performance against a statistical, word-
based model. Our hand-annotated and
tf*idf-based models yielded a precision
of 88,39% and 82,59% respectively, com-
pared to 93,14% for the word-based base-
line model. These results are explained in
terms of our experimental setup.
1 Motivation
High-level linguistic knowledge has been shown to
have the potential of improving the state of the art
in automatic speech recognition (ASR). Such know-
ledge can be integrated in the ASR component (Gao,
2003; Gao et al, 2003; Stolcke et al, 2000; Sarikaya
et al, 2003; Taylor et al, 2000). Alternatively,
it may be included in the processing pipeline at a
later stage, namely at the interface between the au-
tomatic speech recognizer and the spoken language
understanding component (Gurevych et al, 2003a;
Gurevych and Porzel, 2003).
In any of these cases, it is necessary to provide a
systematic account of domain and world knowledge.
These types of knowledge have largely been ignored
so far in ASR research. The reason for this state of
affairs lies in the fact that the manual construction of
appropriate knowledge sources for broad domains is
extremely costly. Also, easy domain portability is
an important requirement for any ASR system. The
emergence of wide coverage linguistic knowledge
bases for multiple languages, such as WordNet (Fell-
baum, 1998), FrameNet (Baker et al, 1998; Baker et
al., 2003), PropBank (Palmer et al, 2003; Xue et al,
2004) is likely to change this situation.
Domain recognition, which is the central topic of
this paper, can be thought of as high-level seman-
tic tagging of utterances. We expect significant im-
provements in the performance of the ASR compo-
nent of the system if information about the current
domain of discourse is available. An obvious intu-
ition behind this expectation is that knowing the cur-
rent domain of discourse narrows down the search
space of the speech recognizer. It also allows to
rule out incoherent speech recognition hypotheses as
well as those which do not fit in a given domain.
Apart from that, there are additional important
reasons for the inclusion of information about the
current domain in any spoken language process-
ing (SLP) system. Current SLP systems deal
not only with a single, but with multiple do-
mains, e.g., Levin et al (2000), Itou et al (2001),
Wahlster et al (2001). In fact, the development of
multi-domain systems is one of the new research di-
rections in SLP, which makes the issue of automati-
cally assigning domains to utterances especially im-
portant. This type of knowledge can be effectively
utilized at different stages of the spoken language
and multi-domain input processing in the following
ways:
? optimizing the performance of the speech rec-
ognizer;
? improving the performance of the dialogue
manager, e.g., if a domain change occurred in
the discourse;
? dynamic loading of resources, e.g. speech rec-
ognizer lexicons or dialogue plans, especially
in mobile environments.
Here, we present the results of research directed
at automatic assigning of domains to speech recog-
nition hypotheses. In Section 2, we briefly introduce
the knowledge sources in our experiments, such as
the ontology, the lexicon and domain models. The
data and annotation experiments will be presented in
Section 3, followed by the detailed description of the
domain classification algorithms in Section 4. Sec-
tion 5 will give the evaluation results for the linguis-
tically motivated conceptual as well as purely statis-
tical models. Conclusions and some future research
directions can be found in Section 6.
2 High-Level Knowledge Sources
2.1 Ontology and lexicon
Current SLP systems often employ multi-
domain ontologies representing the relevant
world and discourse knowledge. The know-
ledge encoded in such an ontology can be
applied to a variety of natural language pro-
cessing tasks, e.g. Mahesh and Nirenburg (1995),
Flycht-Eriksson (2003).
Our ontology models the domains Electronic Pro-
gram Guide, Interaction Management, Cinema In-
formation, Personal Assistance, Route Planning,
Sights, Home Appliances Control and Off Talk.
The hierarchically structured ontology consists of
ca. 720 concepts and 230 properties specifying rela-
tions between concepts. For example every instance
of the concept Process features the relations
hasBeginTime, hasEndTime and hasState.
A detailed description of the ontology employed in
our experiments is given in Gurevych et al (2003b).
Ontological concepts are high-level units. They
allow to reduce the amount of information needed to
represent relations existing between individual lex-
emes and to effectively incorporate this knowledge
into automatic language processing. E.g., there may
exist a large number of movies in a cinema reser-
vation system. All of them will be represented by
the concept Movie, thus allowing to map a variety
of lexical items (instances) to a single unit (concept)
describing their meaning and the relations to other
concepts in a generic way.
We did not use the structure of the ontology in
an explicit way in the reported experiments. The
knowledge was used implicitly to come up with a
set of ontological concepts needed to represent the
user?s utterance.
The high-level domain knowledge represented in
the ontology is linked with the language-specific
knowledge through a lexicon. The lexicon con-
tains ca. 3600 entries of lexical items and their
senses (0 or more), encoded as concepts in the
ontology. E.g., the word am is mapped to the onto-
logical concepts StaticSpatialProcess
as in the utterance I am in New York,
SelfIdentificationProcess as in the
utterance I am Peter Smith, and NONE, if the lexeme
has a grammatical function only, e.g., I am going to
read a book.
2.2 Domain models
For scoring high-level linguistic representations of
utterances we use a domain model. A domain model
is a two-dimensional matrix DM with the dimen-
sions (#d ? #c), where #d and #c denote the
overall number of domain categories and ontologi-
cal concepts, respectively. This can be formalized
as: DM = (Sdc)d=1,...,#d,c=1,...,#c, where the ma-
trix elements Sdc are domain specificity scores of
individual concepts.
We experimented with two different domain mod-
els. The first model DManno was obtained through
direct annotation of concepts with respect to do-
mains as reported in Section 3.2. The second domain
model DMtf?idf resulted from statistical analysis of
Dataset 1 (described in Section 3.1). In this case,
we computed the term frequency - inverse document
frequency (tf*idf) score (Salton and Buckley, 1988)
of each concept for individual domains. In the case
of human annotations, we deal with binary values,
whereas tf*idf scores range over the interval [0,1].
3 Data and Annotation Experiments
We performed a number of annotation experiments.
The purpose of these experiments was to:
? investigate the reliability of the annotations;
? create a domain model based on human anno-
tations;
? produce a training dataset for statistical classi-
fiers;
? set a Gold Standard as a test dataset for the
evaluation.
All annotation experiments were conducted on
data collected in hidden-operator tests following
the paradigm described in Rapp and Strube (2002).
Subjects were asked to verbalize a predefined inten-
tion in each of their turns, the system?s reaction was
simulated by a human operator. We collected ut-
terances from 29 subjects in 8 dialogues with the
system each. All user turns were recorded in sep-
arate audio files. These audio files were processed
by two versions of our dialogue system with differ-
ent speech recognition modules. Data describing our
corpora is given in Table 1. The first and the sec-
ond system?s runs are referred to as Dataset 1 and
Dataset 2 respectively.
Dataset 1 Dataset 2
Number of dialogues 232 95
Number of utterances 1479 552
Number of SRHs 2.239 1.375
Number of coherent SRHs 1511 867
Number of incoherent SRHs 728 508
Table 1: Descriptive corpus statistics.
The corpora obtained from these experiments
were further transformed into a set of annotation
files, which can be read into GUI-based annotation
tools, e.g., MMAX (Mu?ller and Strube, 2003). This
tool can be adopted for annotating different levels of
information, e.g., semantic coherence and domains
of utterances, the best speech recognition hypothe-
sis in the N-best list, as well as domains of individual
concepts. The two annotators were trained with the
help of an annotation manual. A reconciled version
of both annotations resulted in the Gold Standard.
In the following, we present the results of our anno-
tation experiments.
3.1 Coherence, domains of SRHs in Dataset 1
The first experiment was aimed at annotating the
speech recognition hypotheses (SRH) from Dataset
1 w.r.t. their domains. This process was two-staged.
In the first stage, the annotators labeled randomly
mixed SRHs, i.e. SRHs without discourse context,
for their semantic coherence as coherent or incoher-
ent. In the second stage, coherent SRHs were la-
beled for their domains, resulting in a corpus of 1511
hypotheses labeled for at least one domain category.
The numbers for ambiguous domain attributions can
be found in Table 2. The class distribution is given
in Table 3.
Number of domains Annotator 1 Annotator 2
1 90.06% 87.11%
2 6.94% 11.27%
3 3.01% 1.28%
4 0% 0.35%
Table 2: Multiple domain assignments in Dataset 1.
Annotator 1 Annotator 2
Electr. Program Guide 14.43% 14.86%
Interaction Management 15.56% 15.17%
Cinema Information 5.32% 8.7%
Personal Assistance 0.31% 0.3%
Route Planning 37.05% 36%
Sights 12.49% 12.74%
Home Appliances Control 14.12% 11.22%
Off Talk 0.72% 1.01%
Table 3: Class distribution for domain assignments.
P(A) P(E) Kappa
Electr. Program Guide 0.9743 0.7246 0.9066
Interaction Management 0.9836 0.7107 0.9434
Cinema Information 0.9661 0.8506 0.7229
Personal Assistance 0.9953 0.9930 0.3310
Route Planning 0.9777 0.5119 0.9544
Sights 0.9731 0.7629 0.8865
Home Appliances Control 0.9626 0.7504 0.8501
Off Talk 0.9871 0.9780 0.4145
Table 4: Kappa coefficient for separate domains.
Table 4 presents the Kappa coefficient values
computed for individual categories. P(A) is the per-
centage of agreement between annotators. P(E) is
the percentage we expect them to agree by chance.
The annotations are generally considered to be reli-
able if K > 0.8. This is true for all classes except
those which occur very rarely on our data.
3.2 Domains of ontological concepts
In the second experiment, ontological concepts were
annotated with zero or more domain categories.1 We
1Top-level concepts like Event are typically not domain-
specific. Therefore, they will not be assigned any domains.
extracted 231 concepts from the lexicon, which is a
subset of ontological concepts relevant for our cor-
pus of SRHs. The annotators were given the tex-
tual descriptions of all concepts. These definitions
are supplied with the ontology. We computed two
kinds of inter-annotator agreement. In the first case,
we calculated the percentage of concepts, for which
the annotators agreed on all domain categories, re-
sulting in ca. 47.62% (CONCabs, see Figure 1). In
the second case, the agreement on individual domain
decisions (1848 overall) was computed, ca. 86.85%
(CONCindiv, see Figure 1).
3.3 Best conceptual representation and
domains of SRHs in Dataset 2
As will be evident from Section 4.1, each SRH can
be mapped to a set of possible interpretations, which
are called conceptual representations (CR). In this
experiment, the best conceptual representation and
the domains of coherent SRHs from Dataset 2 were
annotated. As our system operates on the basis of
CR, it is necessary to disambiguate them in a pre-
processing step.
867 SRHs used in this experiment are mapped to
2853 CR, i.e. on average each SRH is mapped to
3.29 CR. The annotators? agreement on the task of
determining the best CR reached ca. 88.93%.
For the task of domain annotation, again, we com-
puted the absolute agreement, when the annotators
agreed on all domains for a given SRH. This resulted
in ca. 92.5% (SRHabs, see Figure 1). The agree-
ment on individual domain decisions (6936 over-
all) yielded ca. 98.92% (SRHindiv, see Figure 1).
As the Figure 1 suggests, annotating utterances with
domains is an easier task for humans than annotat-
ing ontological concepts with the same information.
One possible reason for this is that even for an iso-
lated SRH of an utterance there is at least some lo-
cal context available, which clarifies its high-level
meaning to some extent. An isolated concept has no
defining context whatsoever.
4 Domain Classification
In this section, we present the algorithms employed
for assigning domains to speech recognition hy-
potheses. The system called DOMSCORE performs
several processing steps, each of which will be de-
Figure 1: Agreement in % on domain annotations
for concepts and SRHs. Absolute agreement (CON-
Cabs, SRHabs) means that annotators agreed on
all domains. Individual agreement (CONCindiv,
SRHindiv) refers to identical individual domain de-
cisions.
scribed separately in the respective subsections.
4.1 From SRHs to conceptual representations
SRH is a set of words W = {w1, ..., wn}. DOM-
SCORE operates on high-level representations of
SRHs as conceptual representations (CR). CR is
a set of ontological concepts CR = {c1, ..., cn}.
Conceptual representations are obtained from W
through the process called word-to-concept map-
ping. In this process, all possible ontological senses
corresponding to individual words in the lexicon are
permutated resulting in a set I of possible interpre-
tations I = {CR1, ..., CRn} for each speech recog-
nition hypothesis.
For example, in our data a user formulated the
query concerning the TV program, as:2
(1) Und
And
was fu?r
which
Spielfilme
movies
kommen
come
heute abend
tonight
This utterance resulted in the following SRHs:
2All examples are displayed with the German original and a
glossed translation.
SRH1 Was fu?r
Which
Spielfilme
movies
kommen
come
heute abend
tonight
SRH2 Was fu?r
Which
kommen
come
heute abend
tonight
The two hypotheses have two conceptual represen-
tations each. This is due to the lexical ambiguity
of the word come as either MotionProcess or
WatchProcess in German. Movie in SRH1 is
mapped to Broadcast. As a consequence, the
permutation yields CR1a,1b for SRH1 and CR2a,2b
for SRH2:
CR1a: {Broadcast, MotionProcess}
CR1b: {Broadcast, WatchProcess}
CR2a: {MotionProcess}
CR2b: {WatchProcess}
In Tables 5 and 6, the domain specificity scores
Sdc for all concepts of Example 1 are given.
Broadcast Motion Watch
Electr. Program Guide 1 0 1
Interaction Management 0 0 0
Cinema Information 0 0 1
Personal Assistance 0 0 0
Route Planning 0 1 1
Sights 0 0 1
Home Appliances Control 1 0 0
Off Talk 0 0 0
Table 5: Matrix DManno derived from human anno-
tations.
Broadcast Motion Watch
Electr. Program Guide 1 0.496 0.744
Interaction Management 0 0 0
Cinema Information 0.283 0.178 0.043
Personal Assistance 0 0 0
Route Planning 0 0.689 0.044
Sights 0 0.020 0.079
Home Appliances Control 0.494 0.027 0.147
Off Talk 0 0.238 0.374
Table 6: Matrix DMtf?idf derived from the anno-
tated corpus.
4.2 Domain classification of CR
The domain specificity score S of the conceptual
representation CR for the domain d is, then, defined
as the average score of all concepts in CR for this
domain. For a given domain model DM , this for-
mally means:
SCR(d) =
1
n
n
?
i=1
Sd,i
where n is the number of concepts in the respective
CR. As each CR is scored for all domains d, the
output of DOMSCORE is a set of domain scores:
SCR = {Sd1 , ..., S#d}
where #d is the number of domain categories.
Tables 7 and 8 display the results of the domain
scoring algorithm for the conceptual representations
of Example 1.
SRH1 SRH2
CR1a CR1b CR2a CR2b
Electr. Program Guide 0.5 1.0 0 1.0
Interaction Management 0 0 0 0
Cinema Information 0 0.5 0 1.0
Personal Assistance 0 0 0 0
Route Planning 0.5 0.5 1.0 1.0
Sights 0 0.5 0 1.0
Home Appliances Control 0.5 0.5 0 0
Off Talk 0 0 0 0
Table 7: Domain scores on the basis of DManno.
SRH1 SRH2
CR1a CR1b CR2a CR2b
Electr. Program Guide 0.748 0.872 0.496 0.744
Interaction Management 0 0 0 0
Cinema Information 0.231 0.163 0.178 0.043
Personal Asssitance 0 0 0 0
Route Planning 0.344 0.022 0.689 0.044
Sights 0.01 0.04 0.02 0.079
Home Appliances Control 0.26 0.32 0.027 0.147
Off Talk 0.119 0.187 0.238 0.374
Table 8: Domain scores on the basis of DMtf?idf .
In the Gold Standard evaluation data, SRH1 was
annotated as the best SRH and attributed the do-
main Electronic Program Guide, CR1b was selected
as its best conceptual representation. As can be seen
in the above tables, this CR1b gets the highest do-
main score for Electronic Program Guide on the ba-
sis of both DManno and DMtf?idf . Consequently,
both domain models attribute this domain to SRH1.
SRH2 was not labeled with any domains in the
Gold Standard, as this hypothesis is an incoherent
one and hence cannot be considered to belong to
any domain at all. According to DManno, its rep-
resentation CR2a gets a single score 1 for the do-
main Route Planning and CR2b gets multiple equal
scores. DOMSCORE interprets a single score as a
more reliable indicator for a specific domain than
multiple equal scores and assigns the domain Route
Planning to SRH2. On the basis of DMtf?idf the
highest overall score for CR2a,2b is the one for do-
main Electronic Program Guide. Therefore, the
model will assign this domain to SRH2.
4.3 Word2Concept ratio
In previous experiments (Gurevych et al, 2003a),
we found that when operating on sets of concepts
as representations of speech recognition hypotheses,
the ratio of the number of ontological concepts n in
a given CR and the total number of words w in the
respective SRH must be accounted for. This relation
is defined by the ratio R = n/w.
The idea is to prevent an incoherent SRH contain-
ing many function words with zero concept map-
pings, represented by a single concept in the ex-
treme, from being classified as coherent. Exper-
imental results indicate that the optimal threshold
R should be set to 0.33. This means that if there
are more than three words corresponding to a single
concept on average, the SRH is likely to be incoher-
ent and should be excluded from processing.
DOMSCORE implements this as a post-processing
technique. For both conceptual representations of
SRH1 the ratio is R = 1/3, whereas for those of
SRH2, we find R = 1/5. This value is under the
threshold, which means that SRH2 is considered in-
coherent and its domain scores are dropped. Finally,
this results in both models assigning the single do-
main Electronic Program Guide as the best one to
the utterance in Example 1.
5 Evaluation
5.1 Evaluation metrics
The evaluation of the algorithms and domain mod-
els presented herein poses a methodological prob-
lem. As stated in Section 3.3, the annotators were
allowed to assign 1 or more domains to an SRH, so
the number of domain categories varies in the Gold
Standard data. The output of DOMSCORE, however,
is a set with confidence values for all domains rang-
ing from 0 to 1. To the best of our knowledge, there
exists no evaluation method that allows the straight-
forward evaluation of these confidence sets against
the varying number of binary domain decisions.
As a consequence, we restricted the evaluation to
the subset of 758 SRHs unambiguously annotated
for a single domain in Dataset 2. For each SRH
we compared the recognized domain of its best CR
with the annotated domain. This recognized domain
is the one that was scored the highest confidence by
DOMSCORE. In this way we measured the precision
on recognizing the best domain of an SRH. The best
conceptual representation of an SRH had been previ-
ously disambiguated by humans as reported in Sec-
tion 3.3. Alternatively, this kind of disambiguation
can be performed automatically, e.g., with the help
of the system presented in Gurevych et al (2003a).
The system scores semantic coherence of SRHs,
where the best CR is the one with the highest se-
mantic coherence.
5.2 Results
We included two baselines in this evaluation. As as-
signing domains to speech recognition hypotheses
is a classification task, the majority class frequency
can serve as a first baseline. For a second base-
line, we trained a statistical classifier employing the
k-nearest neighbour method using Dataset 1. This
dataset had also been employed to create the tf*idf
model. The statistical classifier treated each SRH as
a bag of words or bag of concepts labeled with do-
main categories.
Figure 2: Precision on domain assignments.
The results of DOMSCORE employing the hand-
annotated and tf*idf domain models as well as
the baseline systems? performances are displayed
in Figure 2. The diagram shows that all sys-
tems clearly outperform the majority class base-
line. The hand-annotated domain model (precision
88.39%) outperforms the tf*idf domain model (pre-
cision 82.59%). The model created by humans turns
out to be of higher quality than the automatically
computed one. However, the k-nearest neighbour
baseline with words as features performs better (pre-
cision 93.14%) than the other methods employing
ontological concepts as representations.
5.3 Discussion
We believe that this finding can be explained in
terms of our experimental setup which favours the
statistical model. Table 9 gives the absolute fre-
quency for all domain categories in the evaluation
data. As the data implies, three of the possible cate-
gories are missing in the data.
Number of instances
Electr. Program Guide 74
Interaction Management 85
Cinema Information 0
Personal Assistance 0
Route Planning 385
Sights 150
Home Appliances Control 64
Off Talk 0
Table 9: Class distribution in the evaluation dataset.
The main reason for our results, however, lies in
the controlled experimental setup of the data col-
lection. Subjects had to verbalize pre-defined in-
tentions in 8 scenarios, e.g. record a specific pro-
gram on TV or ask for information regarding a given
historical sight. Naturally, this leads to restricted
man-machine interactions using controlled vocabu-
lary. As a result, there is rather limited lexical vari-
ation in the data. This is unfortunate for illustrat-
ing the strengths of high-level ontological represen-
tations.
In our opinion, the power of ontological represen-
tations is just their ability to reduce multiple lexi-
cal surface realizations of the same concept to a sin-
gle unit, thus representing the meaning of multiple
words in a compact way. This effect could not be
exploited in a due way given the test corpora in these
experiments. We expect a better performance of
concept-based methods as compared to word-based
ones in broader domains.
An additional important point to consider is the
portability of the domain recognition approach. Sta-
tistical models, e.g., tf*idf and k-nearest neighbour
rely on substantial amounts of annotated data when
moving to new domains. Such data is difficult to
obtain and requires expensive human efforts for an-
notation. When the manually created domain model
is employed for the domain classification task, the
extension of knowledge sources to a new domain
boils down to extending the list of concepts with
some additional ones and annotating them for do-
mains. These new concepts are part of the extension
of the system?s general ontology, which is not cre-
ated specifically for domain classification, but em-
ployed for many purposes in the system.
6 Conclusions
In this paper, we presented a system which de-
termines domains of speech recognition hypothe-
ses. Our approach incorporates high-level semantic
knowledge encoded in a domain model of ontologi-
cal concepts. We believe that this type of semantic
information has the potential to improve the perfor-
mance of the automatic speech recognizer, as well
as other components of spoken language processing
systems.
Basically, information about the current domain
of discourse is a type of contextual knowledge. One
of the future challenges will be to find ways of
including this high-level semantic knowledge into
SLP systems in the most beneficial way. It remains
to be studied how to integrate semantic processing
into the architecture, including speech recognition
and discourse processing.
An important aspect of the scalability of our
methods is their dependence on concept-based do-
main models. A natural extension would be to re-
place hand-crafted ontological concepts with, e.g.,
WordNet concepts. The structure of WordNet can
then be used to determine high-level domain con-
cepts that can replace human domain annotations.
One of the evident problems with this approach is,
however, the high level of lexical ambiguity of the
WordNet concepts. Apparently, the problem of am-
biguity scales up together with the coverage of the
respective knowledge source.
Another remaining challenge is to define the
methodology for the evaluation of methods such as
proposed herein. We have to think about appropri-
ate evaluation metrics as well as reference corpora.
Following the practices in other NLP fields, such as
semantic text analysis (SENSEVAL), message and
document understanding conferences (MUC/DUC),
it is desirable to conduct rigourous large-scale eval-
uations. This should facilitate the progress in study-
ing the effects of individual methods and cross-
system comparisons.
References
Collin F. Baker, Charles J. Fillmore, and John B. Lowe.
1998. The Berkeley FrameNet Project. In Proceed-
ings of COLING-ACL, Montreal, Canada.
Collin F. Baker, Charles J. Fillmore, and Beau Cronin.
2003. The structure of the FrameNet database. Inter-
national Journal of Lexicography, 16.3:281?296.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. MIT Press, Cambridge,
Mass.
Annika Flycht-Eriksson. 2003. Representing knowledge
of dialogue, domain, task and user in dialogue systems
- how and why? Electronic Transactions on Artificial
Intelligence, 3:5?32.
Yuqing Gao, Bowen Zhou, Zijian Diao, Jeffrey Sorensen,
and Michael Picheny. 2003. MARS: A statistical
semantic parsing and generation-based multilingual
automatic translation system. Machine Translation,
17(3):185 ? 212.
Yuqing Gao. 2003. Coupling vs. unifying: Modeling
techniques for speech-to-speech translation. In Pro-
ceedings of Eurospeech, pages 365 ? 368, Geneva,
Switzerland, 1-4 September.
Iryna Gurevych and Robert Porzel. 2003. Using
knowledge-based scores for identifying best speech
recognition hypotheses. In Proceedings of ISCA Tu-
torial and Research Workshop on Error Handling in
Spoken Dialogue Systems, pages 77 ? 81, Chateau-
d?Oex-Vaud, Switzerland, 28-31 August.
Iryna Gurevych, Rainer Malaka, Robert Porzel, and
Hans-Peter Zorn. 2003a. Semantic coherence scoring
using an ontology. In Proceedings of the HLT-NAACL
Conference, pages 88?95, 27 May - 1 June.
Iryna Gurevych, Robert Porzel, Elena Slinko, Nor-
bert Pfleger, Jan Alexandersson, and Stefan Merten.
2003b. Less is more: Using a single knowledge rep-
resentation in dialogue systems. In Proceedings of
the HLT-NAACL?03 Workshop on Text Meaning, pages
14?21, Edmonton, Canada, 31 May.
Katunobu Itou, Atsushi Fujii, and Tetsuya Ishikawa.
2001. Language modeling for multi-domain speech-
driven text retrieval. In Proceedings of IEEE Auto-
matic Speech Recognition and Understanding Work-
shop, December.
Lori Levin, Alon Lavie, Monika Woszczyna, Donna
Gates, Marsal Gavalda, Detlef Koll, and Alex Waibel.
2000. The JANUS-III translation system: Speech-
to-speech translation in multiple domains. Machine
Translation, 15(1-2):3 ? 25.
K. Mahesh and S. Nirenburg. 1995. A Situated Ontol-
ogy for Practical NLP. In Workshop on Basic On-
tological Issues in Knowledge Sharing, International
Joint Conference on Artificial Intelligence (IJCAI-95),
Montreal, Canada, 19-20 August.
Christoph Mu?ller and Michael Strube. 2003. Multi-level
annotation in MMAX. In Proceedings of the 4th SIG-
dial Workshop on Discourse and Dialogue, pages 198?
207, Sapporo, Japan, 4-5 July.
Martha Palmer, Daniel Gildea, and Paul Kingsbury.
2003. The Proposition Bank: An annotated corpus of
semantic roles. Submitted to Computational Linguis-
tics, December.
Stefan Rapp and Michael Strube. 2002. An iterative data
collection approach for multimodal dialogue systems.
In Proceedings of the 3rd International Conference on
Language Resources and Evaluation, pages 661?665,
Las Palmas, Canary Island, Spain, 29-31 May.
Gerard Salton and Christopher Buckley. 1988. Term-
weighting approaches in automatic text retrieval. In-
formation Processing and Management, 24(5):513?
523.
Ruhi Sarikaya, Yuqing Gao, and Michael Picheny. 2003.
Word level confidence measurement using semantic
features. In Proceedings of ICASSP, Hong Kong,
April.
Andreas Stolcke, Klaus Ries, Noah Coccaro, Eliza-
beth Shriberg, Rebecca Bates, Daniel Jurafsky, Paul
Taylor, Rachel Martin, Carol Van Ess-Dykema, and
Marie Meteer. 2000. Dialogue act modeling for
automatic tagging and recognition of conversational
speech. Computational Linguistics, 26(3):339?373.
Paul Taylor, Simon King, Steve Isard, and Helen Wright.
2000. Intonation and dialogue context as constraints
for speech recognition. Language and Speech, 41(3-
4):493?512.
Wolfgang Wahlster, Norbert Reithinger, and Anselm
Blocher. 2001. SmartKom: Multimodal communi-
cation with a life-like character. In Proceedings of the
7th European Conference on Speech Communication
and Technology, pages 1547?1550.
Nianwen Xue, Fei Xia, Fu-dong Chiou, and Martha
Palmer. 2004. The Penn Chinese Treebank: Phrase
Structure Annotation of a Large Corpus. Natural Lan-
guage Engineering, 10(4):1?30, June.
