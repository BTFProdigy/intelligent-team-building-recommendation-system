The interpretation of non-sentential utterances in dialogue
David Schlangen Alex Lascarides
School of Informatics, University of Edinburgh
{das|alex}@cogsci.ed.ac.uk
Abstract
We present an overview of a compre-
hensive formal theory of the interpreta-
tion of sentential fragments, which has
as components an empirically validated
taxonomy, an analysis of the syntax and
compositional semantics of fragments,
and a formalisation of their contextual
interpretation. We also briefly describe
an implementation of this theory, and
quantify the potential practical use of
handling fragments in dialogue systems.
1 Introduction
In dialogue settings, people frequently produce ut-
terances which, despite being non-sentential, con-
vey propositions, questions or requests. For in-
stance, B?s utterance in (1) of the NP ?John? con-
veys in this context the proposition ?John came to
the party.?
(1) A: Who came to the party?
B: John.
Clearly, the interpretation of such non-sentential
utterances or fragments, as they are traditionally
called (eg. (Morgan, 1973)) is highly context de-
pendent. In this paper we present an overview of
a comprehensive formal theory of the interpretation
of fragments.1
The theory has as components an empirically val-
idated taxonomy, an analysis of the syntax and com-
positional semantics of fragments, and a formal-
isation of their contextual interpretation. We also
briefly describe an implementation of this theory,
1More details can be found in (Schlangen, 2003).
and quantify the potential practical use of handling
utterances of this kind in dialogue systems.
The main thesis of our approach is that the res-
olution of the intended content of fragments can be
modelled as a by-product of the establishment of
coherence in dialogue, which (following much of
the work on discourse) we define as the establish-
ment of a meaningful connection of the content of
the current utterance to its discourse context. We
will show that the constraints on the form and con-
tent of fragments follow from such connections.
There has recently been some renewed interest
in fragments. For example, (Carberry, 1990) of-
fers an approach where computationally expens-
ive plan-recognition techniques are employed for
their interpretation. As we will show, this fails
to predict certain empirical facts and further, we
will show that the complex reasoning with cognit-
ive states that she employs can often be replaced
with much simpler inferences based on linguistic
information. (Ginzburg and Sag, 2001) on the other
hand uses grammar-based methods which, as we
will show, are too weak to explain the interpreta-
tion of certain kinds of fragments where their miss-
ing content is linguistically implicit and has to be
inferred. Moreover, we will show that the non-
compositionality of that approach has certain dis-
advantages.
The remainder of the paper is organised as fol-
lows. We first describe our empirically validated,
two-dimensional taxonomy of fragment-types and
say something about the distribution of these types
in corpora. In our theory, the type instantiated by
a given fragment determines how it is resolved, but
before we formalise this in Section 5, we present in
Sections 3 and 4 respectively an analysis of the se-
mantics and syntax of such utterances in isolation.
This separation of grammar and resolution has cer-
tain advantages, as we discuss in comparison to pre-
vious work.
2 A Taxonomy of Fragments
2.1 The Taxonomy
We classify fragments according to two dimen-
sions. In the first dimension, the criterion for clas-
sification is the source of the material that is needed
for resolution. In examples like (1), all informa-
tion that is required to resolve the meaning of the
fragment (we will soon say something about what
kind of information we assume this to be, syntactic
or semantic) is present in the context: the resolu-
tion ?John came to the party? can be computed by
identifying the ?missing? content in ?John? with ele-
ments from the utterance it is related to, ie. the ques-
tion. We call this type of resolution resolution-via-
identity. However, there are also examples where
required information is linguistically implicit, as in
(2).
(2) A: Why did John leave?
B: Exams.
If John is a student and this fact is mutually known
by the dialogue participants, then B?s utterance is
presumably resolved to something like ?John left
because he has to take an exam soon?. This res-
olution contains elements that are not linguistically
explicit in the utterance to which the fragment is a
reply; the resolution has to be inferred, from both
linguistic sources (the content of the fragment and
the content of its discourse context) and also extra-
linguistic sources (knowledge about preparing for
exams, for example). Hence we call this type of
resolution resolution-via-inference. We will show
below that there are different constraints on frag-
ments of these types.
In the second dimension fragments are categor-
ised by their discourse-function or rhetorical role
with respect to elements of the context. For ex-
ample, in both (1) and (2), the fragment provides
an answer to a question, and so we call the type
these fragments instantiate Question-Answer Pair
(QAP).2 As this name suggests, strictly speaking
this dimension does not classify fragments as such,
but rather the relation a given fragment has to ele-
ments of its context. To make this explicit, our types
are defined as relations, that is, the element of the
2That both (1) and (2) instantiate this type shows
that the dimensions are indeed independent, since as dis-
cussed above in the first dimension they belong to differ-
ent classes.
context the fragment connects to is explicitly part
of what individuates the type.3
As a theoretical backbone for the taxonomy, we
used the rhetorical relations defined by a theory
of discourse structure called SDRT (Asher, 1993;
Asher and Lascarides, 2003), which is also the
framework in which we formalised the resolution
of fragments. However, we also used corpora
to motivate the set of fragment-types in our tax-
onomy. We manually identified all instances of
non-sentential utterances in a number of transcripts
of dialogues and classified their relation to the con-
text.4 The resulting list of relations is given in
Tables 1 and 2, together with informal definitions
of the semantics of each relation (where ? is the
fragment and ? the utterance it is related to) and
an example instance. We will not go into more de-
tails of the types here; in Section 5 we will return
to a select few and give a formal definition of their
semantics. Note that we do not claim that this set
of fragment-types is exhaustive; we discuss in the
next section the coverage that can be achieve with
it on test data.5 As a final point, note that we sub-
sume what is often called ?clarification question?
(eg. (Ginzburg and Cooper, 2001)) under Elabora-
tion to stress the similarity with ?normal? elabora-
tions. The subscripts
p
and
q
indicate the message
type of ? and ?; e.g. Elab
pq
is an elaboration of a
proposition, performed with a question.
2.2 Corpus Study
To test the coverage that can be achieved with
our taxonomy, we analysed 5087 items of general
free conversation from the BNC (dialogues KSU
and KSV), and 4037 items of task-oriented dia-
logue from the VM/redwoods corpus (the 125 dia-
logues on the VM-CD-ROM 6).6 We proceeded
3All taxonomies of fragment-types that are known
to us use classes that are at least partially determined
by the rhetorical function of the fragment (eg., that of
(Carberry, 1990) as well as that of (Ferna?ndez and Gin-
zburg, 2002)); nevertheless, to our knowledge ours is the
only one to make this inherent relationality explicit in the
formal definition of the classes.
4For this we used two dialogue transcripts from the
BNC (Aston and Burnard, 1998) and five dialogues from
the Verbmobil corpus (Wahlster, 2000).
5A systematic omission are relations that connect re-
quests. In the dialogues we looked at (which were nego-
tiations and free conversation) these did not occur; how-
ever, in more task-oriented dialogues they will presum-
ably be quite frequent. Note that there is no principled
reason for not including them, and our approach could
easily be extended accordingly.
6We held out this data in the compilation stage, and
so ?training? and ?test-data? are disjoint.
Relation Definition, Example
QAP  provides a direct answer to .
?A: Who came to the party? ? B:
Peter.?
QAP
q
Positive answers to y/n-question 
provide a direct answer to , negative
answers a partial answer.
?A: Who was this? Peter??
Elab
pp
 elaborates on some aspect of the in-
dicative .
?A: I talked to Peter. Peter Miller.?
?A: I talked to Peter. Yesterday.?
Elab
qp
 elaborates on the content of .
?A: Who did you talk to? Yesterday.?
( = ?Who did you talk to yesterday??)
Elab
pq
Any answer to  elaborates on some as-
pect of the indicative .
?A: I talked to Peter. ? B: When??
?A: I talked to Peter. ? B: Peter
Miller??
Elab
qq
Any answer to  elaborates on the con-
tent of .
?A: Did you talk to Peter? ? B: Peter
Miller??
Contr  and  have a contrasting theme.
?(A: Are they in the cupboard?) ? B:
( : ) No, ( :) in the fridge.?
Cont  continues a topic of .
?A: I am free on Monday. And on Wed-
nesday.?
Q-Cont The question  continues a topic of the
question .
?A: What?s his name? ? B: . . . ? A:
His address??
Q-Alt Answers to  answer an alternative
question combined out of  and the
fragment-phrase ? .
?A: Can you come on Tuesday? Or
Wednesday??
(= ?When can you come, Tuesday or
Wednesday??)
Expl  explains e
?
.
?A: Peter left early. Exams.?
Expl
q
All answers to  explain e
?
.
?A: Peter left early. ? B: Exams??
Expl?
q
All answers to  explain why  has
been uttered.
?A: Are you married? ? B: Why??
Res  explains e
?
.
?A: He had a stroke. And died.?
Res
q
Answers to  are explained by .
?A: He had a stroke. ? B: And died??
Table 1: Speech act types that can be realized with
NSUs
Relation Definition, Example
Plan-Elab  details a step in a plan to reach a goal
behind .
?A: Let?s meet on Monday. At two
o?clock.?
Q-Elab Answers to  detail a step in a plan to
reach a goal behind .
?A: Let?s meet on Monday. ? B: At two
o?clock??
Ack  entails that Agent() has accepted or
achieved Agent()?s goal behind utter-
ing .
?A: Let?s meet on Monday. ? B: OK.?
Plan-Corr  indicates that Agent() doesn?t ac-
cept or is unable to help achieve
Agent()?s goal behind .
?A: Let?s meet on Monday. ? B: No.?
Ack
q
positive answers ? to  entails
Ack(; ?), negative Plan-Corr(; ?).
?A: Let?s meet on Monday. OK??
Comnt  indicates a propositional attitude of
Agent() towards the content of .
?A: I talked to Peter. ? B: Awesome!?
Comnt
q
Answers to  indicate a propositional
attitude of Agent() towards the con-
tent of .
?A: I talked to Peter. ? B: Really??
Narr e
?
occurs after e
?
, . . .
?A: He went to Italy. And (then) to
Spain.?
Narr
q
Answers ? to  entail Narr(; ?).
?A: He went to Italy. ? B: And then??
Table 2: Speech act types that can be realized with
NSUs (contd)
in two stages, first semi-automatically identifying
non-sentential utterances (using the wide-coverage
grammar described below as a filter for sentential-
ity) which we then classified according to the tax-
onomy, or with other if no decision could be
made.7
Results Numbers about the frequency of frag-
ments in our corpus and about the achieved cover-
age overall are presented in Table 3. For reasons of
space, we cannot show the detailed distribution of
the classes here; what is noteworthy about it is that
the majority of fragment instances is concentrated
in a few classes, with the rest of the classes only
represented by a few examples each. The most fre-
quent type is QAP, followed by Elab
pq
and Elab
pp
,
7For this study we only used one annotator, so we can-
not present inter-annotator agreement measures. Further
studies are underway at the moment that will give us such
data.
whereas types like Expl?
q
, Q-Alt and Contr were
found only a few times.
SUMMARY
items analysed 9142
Fragments 931 (= 10.2%)
classfd. 865 (= 93% of fragments)
other 66 (= 7% of fragments)
Table 3: Results of Annotation
Discussion The overall percentage of fragments
we have found seems to confirm the results of
earlier studies (Thompson, 1980; Ferna?ndez and
Ginzburg, 2002), which also classified as frag-
ments around 10% of the utterances in the dialogues
they looked at. (Ferna?ndez and Ginzburg, 2002)
also offers a taxonomy of fragment types; the au-
thors claim to have reached a coverage which is
much higher than what we achieved (99% com-
pared to our 93%). We think this can partially be
explained by the fact that the classes they use are
more surface-oriented. For example, they have a
class ?sluice?, which is defined as ?bare question-
denoting wh-phrases? (Ferna?ndez and Ginzburg,
2002, p.16). We make a finer distinction, split-
ting this class further according to the rhetorical
function played by the fragmental question (eg.,
Expl
q
, Expl?
q
, Narr
q
, Elab
q
). Hence, to classify a
given fragment we need more information about its
rhetorical function; information which sometimes
is difficult to recover from a transcript. While a
surface-oriented approach to defining classes is an
advantage for annotation, it is a hindrance for form-
ally defining their semantics, as we will argue be-
low.
In conclusion, we think that this corpus study has
shown that our taxonomy has satisfactory empirical
motivation. In the next two sections we look at frag-
ments in isolation. We return to the taxonomy when
we give an example of the formal semantics of re-
lations and show how they determine the resolution
of the fragments.
3 A Compositional Semantics for
Fragments
For compositional semantic analysis we use Min-
imal Recursion Semantics (MRS, (Copestake et al,
1999)), a language in which partial descriptions of
formulae of a logical language (the base language)
can be expressed. This allows one to leave cer-
tain semantic distinctions unresolved, reflecting the
idea that syntax supplies only partial information
about meaning. Technically this is achieved via a
strategy that has become standard in computational
semantics (e.g., (Reyle, 1993)): one assigns labels
to bits of base language formulae so that state-
ments about their combination can remain ?under-
specified?. The (first-order) models of formulae of
this latter language then can be seen as standing in
a direct relation to formulae of the base language;
M |= ? then means that the (unique) base-language
formula corresponding to M is described by the
MRS ?.8 By way of example, (3) shows an MRS-
representation of ?Everyone loves someone?, where
so-called elementary predications (EPs) are labelled
with handles (h
n
), with h being the top handle that
outscopes all others; ?h
1
=
q
h
2
? stands for an ?out-
scopes? relation between EPs where only quantifiers
can be scoped in between h
1
and h
2
; prpstn rel sig-
nals that the MRS describes a proposition.
(3) ?h; e; {h : prpstn rel(h
1
); h
2
: love v rel(e; x
1
; x
2
);
h
6
: every rel(x
1
; h
8
; h
9
);
h
10
: person rel(x
1
);
h
11
: some rel(x
2
; h
12
; h
13
);
h
14
: person rel(x
2
)};
{ h
1
=
q
h
2
; h
8
=
q
h
10
; h
12
=
q
h
14
}?
The compositional semantics of fragments leaves
more information unresolved than just semantic
scope, however. All we know about the meaning of
fragments like those in (1) and (2) independent from
their context is: (a) they will resolve to a proposi-
tion,9 of which (b) the main predicate is unknown,
but (c) one participant in the main event is specified
although its exact role isn?t. We represent this with
an anaphoric relation unknown rel, and so the NP-
fragment ?John.? (regardless of the context it stands
in) is represented as:
(4) ?h; e; {h : prpstn rel(h
1
);
h
2
: unknown rel(e; x);
h
6
: def np rel(x; h
8
; h
9
);
h
10
: named(x; John)};
{ h
1
=
q
h
2
; h
8
=
q
h
10
} ?
The unknown rel acts as a ?place-holder? for a po-
tentially complex sub-formula; more precisely it is
a constraint on the form of the described (base-
8Such a semantics if given to MRS in (Copestake et
al., 2001); we follow the similar formalisation in (Asher
and Lascarides, 2003). Note that we do not make any
assumptions about the base language and its logic here;
the descriptions are compatible with it being static first
order predicate logic, or a dynamic logic like DRT (Kamp
and Reyle, 1993).
9We make the simplifying assumption that there is
an unambiguous intonation pattern indicating whether a
fragment is intended to convey a proposition, a question
or a request.
language) formulae, that they contain at this place
a subformula, which in the case of (4) must have e
and x amongst its variables. Clearly, such a descrip-
tion then describes an infinite number of formulae;
however, all of these are potential resolutions of the
fragment. For instance, (4) (partially) describes the
intended resolution of the fragment in context (1)?
?John came to the party.??, but it also describes for
example ?Carl loves John.? or ?Sandy thinks that
Kim relies on John.?, which can be resolutions in
other contexts.
It is important to note that unknown rel is not a
second order variable (as it would be in an approach
in the vein of (Dalrymple et al, 1991)), and it is not
something that simply gets replaced by a predicate
symbol of the same arity. Rather, unknown rel is a
constraint more like the =
q
-constraints, constrain-
ing the ?shape? of the described formulae. It is ana-
phoric, because the sub-formula that is to be inser-
ted at this point in the described formula is not de-
termined by the grammar, but must be provided by
the context.
4 A Grammar of Fragments
4.1 The Analysis
Our grammatical analysis of fragments is relatively
straightforward: we make the assumption that frag-
ments are phrases,10 possibly modified by adverbs.
As (5) shows, only scopally modifying adverbs are
allowed.11
(5) A: Who sang this song?
B: Maybe Sandy. / *Badly Sandy.
In a pseudo phrase-structure notation, the rules
simply are of the form ?S-frag ? (ADV) XP?. We
formalise this in a version of HPSG that allows con-
structions (Sag, 1997) (ie. phrase-types that make
a semantic contribution) and that uses MRSs as se-
mantic representations. HPSG-representations of
these semantic structures consist of a feature IN-
DEX whose value represents the semantic index of
the sign; a feature LTOP that holds the handle of the
sign, ie. a label for the bits of logical form intro-
duced by it; LZT, which is a bag of labelled EPs;
and H-CONS, which collects the constraints on the
10This goes back to (Morgan, 1973); explicit rules
can be found in (Barton, 1990). We ignore for now
more complicated examples like ?A: Does John devour
or nibble at his food? ? B: Oh, John devours.?
11Note that the latter is licensed as an answer to a mul-
tiple wh-question like ?Who sang, and how??, in which
case we analyse it as a sequence of two fragments.
order of sub-formulae.
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
headed-phrase & np-nm-decl-frag
SS.LOC
?
?
?
?
?
?
?
?
?
?
?
?
CAT
?
?
?
HD verb
VAL
[
SUBJ ??
SPEC ??
COMPS ??
]
?
?
?
CONT
?
?
?
?
mrs
INDEX 1 event
LTOP 2 handle
LZT A ? B
H-CONS C ? D
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
C-CONT
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
mrs
INDEX 1
LTOP 2
LZT A
?
[
prpstn rel
HNDL 2
SOA 3
]
?
?
?
unknown rel
HNDL 4
EVENT 1
ARG 5
?
?
?
?
H-CONS C
?[
qeq
SC-ARG 3
OUTSCPD 4
]?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
|
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
SS.LOC
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
CAT np-cat
CONT
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
INDEX 5
LZT B
?
?
?
?
?
def np rel
HNDL hndl
BV 5
RSTR 7
SCP hndl
?
?
?
?
?
?
?
named rel
HNDL 8
INST 5
NMD ?John?
?
?
?
?
H-CONS D
?[
qeq
SC-ARG 7
OUTSCPD 8
]?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
John
Figure 1: ?John? as a declarative fragment.
The formalisation is best explained with an ex-
ample. Figure 1 shows, in a tree representation, the
sign for the NP-fragment ?John.? It demonstrates
how the NP is lifted to the level of sentences, and
how the semantics of that sentence is composed.
Let?s work ?top-down? to describe this Figure in
detail. The root-sign in this tree has all the syn-
tactic features of a sentence: the value of its SYN-
SEM.LOCAL.CAT is of type verb, and all valence re-
quirements are satisfied. It is also semantically like
a sentence, in that its top-EP (with the handle 2 ) is
of type message (more precisely, a prpstn). This
EP is contributed by the fragment-rule, via the fea-
ture C-CONT (construction content). In the same
way the unknown rel-constraint that was intro-
duced in the previous section is added. The con-
nection of this constraint to the semantics of the
phrase is made via co-indexation of the argument-
slot of unknown rel with the INDEX of the argu-
ment phrase (in Figure 1 this is 5 ).
As the type-declaration in Figure 1 shows, this
sign is the combination of two types, namely
headed-phrase, which is a general type that defines
the features and co-indexations in headed phrases;
and np-nm-decl-frag, which collects the specifica-
tions particular to fragments. This type in turn in-
herits from three further types: np-frag, which spe-
cifies the particularities of fragments consisting of
NPs; nm-frag, which specifies non-modified frag-
ments (ie., a phrase that is not modified by an ad-
verb); and decl-frag, which indicates that the frag-
ments resolves to a proposition. These three types
encapsulate properties of fragments that can vary
independently; see the hierarchy in Figure 2.
We assume a generalised head-feature principle
(ghfp) as in (Ginzburg and Sag, 2001) according
to which all values for SYNSEM-features on the
mother are by default token-identical to those of the
daughter, and hence we have to make sure that the
fragment-types override this default where appro-
priate. For example, the value for SYNSEM.LOCAL
of fragments must be specified on the types for the
fragments, since it will always be different from
that of the head daughter?raising different XPs to
sentences is the whole point of the rule, and so the
default of the ghfp to copy these specifications must
be overridden. The value of SYNSEM.LOCAL.CAT
will be the same for all types of fragments, namely
that of a sentence. In fact, the only elements of the
type instantiated in Figure 1 that are specific to NP-
fragments are the co-indexation of the INDEX of the
head (the NP) with the ARG of the unknown rel,
and the restriction that the phrase be an NP. So the
constraint unique to NP-fragments (ie., the specific-
ation of the type np-frag) is that shown in (6).
(6) np-frg:
[
C-CONT.LZT
?
[ ]
,
[
ARG 1
]
?
]
?
H
?
?
?
?
SYNSEM.LOCAL
?
?
?
CAT
[
HEAD nominal
VAL
[
COMPS ??
SPR ??
]
]
CONT.INDEX 1
?
?
?
?
?
?
?
Figure 1 represents a non-modified fragment. In
fragments that are modified by an adverb, we
find an additional non-head-daughter, whose EP is
scoped in as sister to the unknown rel, as shown in
(7).
(7)?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
mod-frg
C-CONT
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
mrs
LZT
?
[
prpstn rel
HNDL 2
SOA 3
]
,
[
unknown rel
HNDL 4
]
?
H-CONS
?
[
qeq
SC-ARG 3
OUTSCPD 4
]
,
[
qeq
SC-ARG 3
OUTSCPD 5
]
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
NON-HEAD-DTRS
?
[
SYNSEM
[
scopal vp adv
LOCAL.CONT.TOP 5
]]
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
Finally, the last dimension organises the differences
in the type of message to which the fragment will
resolve. The example we have seen in Figure 1
was one of a propositional-fragment; fragmental
questions or requests only differ in the type of this
message-relation. To give an example, (8) shows
the type int(errogative)-frag(ment).
(8) [int-frag
C-CONT.LZT ?
[
int
]
, . . . ?
]
The rules in this dimension also make sure that wh-
phrases must be int-frags.
4.2 Implementation
We have implemented our analysis in a wide-
coverage HPSG, the English Resource Grammar
(ERG, see for example (Copestake and Flickinger,
2000));12 the implementation was evaluated us-
ing the grammar-profiling tool [incr tsdb()]
(Oepen and Flickinger, 1998). First, to test for
possible adverse effects on the analyses of full-
sentences, we ran a batch-parse of a test-suite of
full sentences, the CSLI-test-suite which is distrib-
uted with [incr tsdb()]. It consists of 1348
sentences, of which 961 are marked as syntactically
well-formed and 387 as ill-formed. Table 4 shows
a comparison of the original ERG with our extended
version containing the fragment rules, with respect
to the average number of parses per sentence.
12The implementation differs slightly from the analysis
described in the previous section: the ERG doesn?t make
use of defaults, and so we had to explicitly state what is
identical between mother and daughter and what isn?t.
msg-type frg-type frg-arg-type
imp-frag int-frag decl-frag mod-frag n-mod-frg nom-frag vp-frag s-comp-frg
np-frag pp-frag
pp-f-frag pp-l-frag
... np-m-decl-frg np-nm-decl-frg ...
Figure 2: An extract of the construction hierarchy for fragments
Version of Grammar Average # parses
LinGO ERG, 20/11/02 2.86
ERG+frag 3.69
Table 4: Competence comparison of the original
ERG with the fragment-ERG
As these data show, the fragment rules introduce
some new ambiguity, but on average less than one
more parse per item. We conclude from this that
adding the fragment-rules doesn?t lead to an ex-
plosion of readings that would render the grammar
practically unusable. What this evaluation doesn?t
tell us, however, is whether the additional readings
(of what is meant to be full sentences) are erroneous
or not. The problem is that ?fragmenthood? is not a
syntactic criterion, and so some strings that can be
analysed as sentences can also be analysed as frag-
ments. E.g., ?leave? can be both an imperative sen-
tence and a VP-fragment (e.g. in the context of the
question ?What did John make Sandy do??).
To test the coverage of our extended grammar,
we used parts of the annotated corpus described
in Section 2.2. In 4037 items we identified 369
fragments, of which our grammar correctly parsed
242 (= 65.5%). A detailed study of the frag-
ments that were not recognised showed that a use-
ful extension would be rules for handling fragments
of the form ?CONJ XP?, eg. ?and on Saturday.?;
including those would bring our coverage up to
82.6% of the corpus. This result is in the same
order of magnitude as what the original grammar
achieves on full sentences, and is in the range of
what the best wide-coverage grammars that provide
semantic representations at present can achieve.
However, although extending the grammar in this
way is straightforward it would lead to a dramatic
rise in the number of average parses, and so for
practical purposes we did not carry out such an ex-
tension here.
5 Computing the Intended Meaning of
Fragments
5.1 Theory
The final problem we have to address is how the
underspecified semantic representations that our
grammar produces for fragments are resolved con-
textually. For this, we use a theory of discourse
interpretation called SDRT (Asher and Lascarides,
2003). This theory attempts to enrich dynamic se-
mantics with techniques for encoding the contribu-
tion of pragmatics. One central notion of dynamic
semantics (eg. (Kamp and Reyle, 1993)) is the up-
date of a representation of the context with that of
new information; in SDRT, this update is depend-
ent on non-monotonic inferences over linguistic
and non-linguistic information. SDRT?s update-
operation is defined on descriptions like MRSs;
it simply adds constraints on the form of logical
forms. The inferred information that is most im-
portant for us is the speech act type (e.g. QAP,
Elab
pp
) that connects the new information to the
context; this is what we used to classify fragments
in Section 2.
These speech acts are computed via default rules;
to give an example, the rule for IQAP is shown be-
low. In this rules, ??, ?, ?? means ? is to be attached
to ? with a rhetorical relation (? and ? label bits of
content) where ? is part of the discourse context ? ;
? :? means that ? is an interrogative, and A > B
means If A then normally B:13
(9) IQAP: (?; ; ? ?  :?) > IQAP(; )
This rule stipulates that the default contribution of a
response to a question is to supply information from
which the questioner can infer an answer. Thus in-
ferences about speech acts, and hence about impli-
cit content and goals, can sometime be triggered (by
default) purely on the basis of sentence moods. For
13(Asher and Lascarides, 1998) shows that some rules
like this can be derived from a precise model of rational-
ity and cooperativity.
other speech acts, information about speaker-goals
might be required; however, the general principle is
to always minimise the need for such information.
We now address resolving the underspecification
indicated by unknown rel. In particular, we argue
that there are certain constraints on the form of
resolution-via-identity fragments which do not ap-
ply to resolution-via-inference fragments. We de-
rive these different constraints from a general dis-
course coherence principle, but before we come to
this, we have to show what these constraints are.
We begin with questions and answers like (1).
Intuitively, one can say that there is a ?hole? in
questions like (1) or (10), marked syntactically by
the wh-phrase and semantically by a variable (be
that bound by a ?-operator, as in (Groenendijk and
Stokhof, 1984) or by a quantifier, as in the ERG).
(10) A: Who came to the party?
B: Not Sandy.
This initially suggests that to resolve the content of
the fragment, one could attempt to do syntactic re-
construction, ?plugging? the syntactic structure of
the fragment into the (syntactic) ?hole? in the ques-
tion (cf. (Morgan, 1973)). Unfortunately, as (Gin-
zburg and Sag, 2001) (henceforth G&S) attest, such
a strategy fails for some cases; eg. for (10) above:
?*Not Sandy came to the party.?
On the other hand, G&S also attest that a purely
semantic reconstruction, where the semantic rep-
resentation of the fragment is ?plugged into? the
(semantic) ?hole? in the question, is also unsatis-
factory. Certain grammatical idiosyncrasies seem
to persist beyond sentence boundaries. This can
be shown with example (11) (from G&S, p.300).
Here the fragmental answers must be of the syn-
tactic category required by the verb in the question
(VP[bse] and VP[inf ], respectively), even though
the semantic objects denoted by these VPs presum-
ably are of the same type.14
(11) a. A: What did he make you do? ? B: Sing
b. A: What did he force you to do? ? B: To
sing.
G&S model this constraint by restricting short an-
swers to be syntactically parallel to the question
they answer. This however is too strict, as ex-
amples like (2) show, which is a short answer as
well but does not exhibit such ?parallelism?. We
explain the observation in a less direct but more
14For a further discussion of the exact extent of this
parallelism see (Schlangen, 2002).
general way. First of all, our theory is declarat-
ive: it describes the form of the preferred resolu-
tion (it?s the one that satisfies the coherence con-
straints of the rhetorical relations), but not neces-
sarily how it is generated. We assume as a gen-
eral discourse principle that resolutions which are
(semantic-)structurally very close must satisfy a
certain syntactic constraint which says that sub-
categorization requirements must be satisfied, too.
Hence our principle can rule out resolutions even if
they satisfy the semantic constraints (eg., it would
rule out the ?wrong? combination of questions and
answers in (11) above), in case they violate that syn-
tactic constraint. The difference between (1) and
(2) now is explained by different contextual require-
ments. In (2) there is another relation present be-
sides QAP, namely Explanation. The semantics of
this former relation (namely that ? explains the pro-
positional content of ?) puts additional semantic
constraints on the answer; the structural closeness
is not required, and hence the fragment is exempt
from the syntactic constraint.
For reasons of space, we simply sketch the the-
ory here, but we should stress that, following G&S,
we also assume that certain syntactic information
persists beyond sentence boundaries.
5.2 Implementation
We have partially implemented the theory described
here in a computer program (see also (Schlangen
and Lascarides, 2002)). The resolution of res-via-
id fragments is very straightforward to implement,
since for them all possibilities can be generated via
simple abstraction and functional application oper-
ations over the semantic representations. That of
res-via-inf fragments is more problematic, and we
have only implemented it for a very limited domain,
namely that of scheduling dialogues. In this do-
main, the discourse-plans are particularly simple,
and so we can specify the required axioms for reas-
oning with extra-linguistic information. Again we
can?t go into details here and only note that even
though we minimise the amount of extra-linguistic
information that is needed, resolution of res-via-inf
fragments is a demanding task and can be auto-
mated only for very restricted domains.
6 Related Work
The idea that content is determined by coherence
relations is of course not new, and has been imple-
mented for example in (Hobbs et al, 1993), which
also mentions in passing the problem of resolving
fragments in context. However, this ?Interpreta-
tion as Abduction?-theory (IAT) differs from our ap-
proach in a number of important aspects. First, un-
like IAT?s weighted abduction where conflict among
the clues to interpretation is handled by the ex-
traneous logical machinery of weights, in our the-
ory conflict is resolved automatically by the logical
consequence relation itself. Secondly, Hobbs et al
don?t consider the syntactic constraints on the resol-
ution of fragments that we discussed above. In fact,
they seem to regard fragments as ?syntactically-ill
formed utterances?, and so do not make a difference
between well-formed and ill-formed fragments. In
principle, further constraints could be added to the
ITA framework, but at the cost of having to re-assign
weights so that the results of inference are always as
intended, and no princples or regulations are given
in (Hobbs et al, 1993) about how to do this.
As mentioned in the introduction, (Ginzburg
and Sag, 2001) (henceforth G&S) also offer a
non-modular approach to the resolution of short-
answers (and some other fragmental speech acts).
(12) shows a very schematic representation of their
approach.
(12) S: Peter walks
|
QUD ? NP: Peter
Who walks? |
|
Peter
A grammar rule specific to the use made of the frag-
ment (in (12) as an answer) directly projects NPs as
sentences, with parts of the sentential content com-
ing from a contextual feature QUD (question under
discussion). This grammar rule in one go checks
the syntactic constraints and constructs the intended
content of the fragment in its discourse context.
In our opinion, our compositional approach has
certain advantages. First, the grammatical analysis
of fragments is uniform; contextual variation in
their meaning is accounted for in the same way as
it is for other anaphoric phenomena, via inferences
underlying discourse update. This yields the second
advantage: resolving fragments is fully integrated
with resolving other kinds of underspecification (al-
though we have not shown this here; cf. (Schlan-
gen and Lascarides, 2002)). Third, the interac-
tion between grammar and pragmatics is straight-
forward: pragmatics enriches information coming
from the grammar. In G&S?s approach the grammar
has to ?decide? on the speech act that has been per-
formed (the grammar-rules are specific for eg. an-
swering, clarification); something that is normally
seen to be a defeasible process. Hence, even in
G&S?s approach a pragmatic module is required,
which then has the task of filtering out unwanted
parses. Fourth, we have available a strong theory
of contextual interpretation which can explain the
reasoning behind the resolution of examples like (2)
(although we have not shown here in detail how);
the functional application used by G&S seems too
weak to do this. Fifth, our compositional approach
allowed us to straightforwardly extend an existing
wide-coverage grammar. This contrasts with the
non-compositional approach which through its de-
mands for making contextual information available
entails that standard parsers cannot be used without
modifications. Lastly, the separation of the gram-
mar and resolution components means that in the-
ory our grammar can be used with different resolu-
tion strategies; however, we have not systematically
explored that.
As mentioned in the introduction, (Carberry,
1990) offers an approach that uses plan-recognition
techniques to resolve fragments. While such an
approach can perhaps model res-via-inf cases, it
seems to us needlessy powerful for fragment-types
like (1), where purely linguistic information is suf-
ficient. Moreover, Carberry does not deal with the
syntactic constraints and so overgenerates possible
fragments.
7 Conclusions
We draw the following conclusions from the work
presented in this paper: fragments occur frequently
in dialogues, namely relatively consistently around
10% across dialogue types (but possibly more fre-
quently in question/answer-based informative dia-
logues). This means that a principled approach to
their resolution is important for natural sounding
dialogue systems, besides being of theoretical in-
terest. We have offered such an approach, begin-
ning with a comprehensive taxonomy of fragment-
types, through to a semantic and syntactic analysis,
which we also implemented. In that implementa-
tion we identified for future work the sub-type of
fragments of the form ?CONJ XP? (eg. ?and on
Monday.?).
Acknowledgements
We would like to thank the anonymous reviewers
for their helpful comments.
References
Nicholas Asher and Alex Lascarides. 1998. Ques-
tions in dialogue. Linguistics and Philosophy,
23(2):237?309.
Nicholas Asher and Alex Lascarides. 2003. Logics
of Conversation. Cambridge University Press.
Nicholas Asher. 1993. Reference to Abstract
Objects in Discourse. Studies in Linguistics
and Philosophy. Kluwer Academic Publisher,
Dordrecht.
Guy Aston and Lou Burnard. 1998. The BNC
Handbook. Edinburgh University Press, Edin-
burgh, UK.
Ellen L. Barton. 1990. Nonsentential Constituents.
John Benjamins, Amsterdam / Philadelphia.
Sandra Carberry. 1990. Plan Recognition in Nat-
ural Language Dialogue. MIT Press, Cam-
bridge, Massachusetts.
Ann Copestake and Dan Flickinger. 2000. An open
source grammar development environment and
broad-coverage english grammar using HPSG.
In Proceedings of the 2nd Linguistic Resources
and Evaluation Conference, pages 591?600,
Athens, Greece.
Ann Copestake, Dan Flickinger, Ivan Sag, and Carl
Pollard. 1999. Minimal recursion semantics: An
introduction. Stanford University, Stanford, CA.
Ann Copestake, Alex Lascarides, and Dan
Flickinger. 2001. An algebra for semantic
construction in constraint-based grammars. In
Proceedings of the 39th Annual Meeting of
the Association for Computational Linguistics
(ACL/EACL 2001), pages 132?139, Tolouse,
France.
Mary Dalrymple, Stuart Shieber, and Fernando
Pereira. 1991. Ellipsis and higher order unifica-
tion. Linguistics and Philosophy, 14:399?452.
Raquel Ferna?ndez and Jonathan Ginzburg. 2002.
Non-sentential utterances in dialogue: A corpus-
based study. In Kristiina Jokinen and Susan
McRoy, editors, Proceedings of the Third SIG-
dial Workshop on Discourse and Dialogue, pages
15?26, Philadelphia, USA. ACL Special Interest
Group on Dialog.
Jonathan Ginzburg and Robin Cooper. 2001.
Resolving ellipsis in clarification. In Proceed-
ings of the 39th Meeting of the ACL, Tolouse,
France.
Jonathan Ginzburg and Ivan A. Sag. 2001. In-
terrogative Investigations: The Form, Meaning,
and Use of English Interrogatives. Number 123
in CSLI Lecture Notes. CSLI Publications, Stan-
ford.
Jeroen Groenendijk and Martin Stokhof. 1984.
Studies on the Semantics of Questions and the
Pragmatics of Answers. Ph.D. thesis, University
of Amsterdam, Amsterdam.
J. R. Hobbs, M. Stickel, D. Appelt, and P. Martin.
1993. Interpretation as abduction. Artificial In-
telligence, 63:69?142.
Hans Kamp and Uwe Reyle. 1993. From Discourse
to Logic. Kluwer, Dordrecht.
Jerry L. Morgan. 1973. Sentence fragments and the
notion ?sentence?. In Issues in Linguistics: Es-
says in honour of Henry and Rene Kahane. UIP,
Urbana.
Stephan Oepen and Daniel P. Flickinger. 1998. To-
wards systematic grammar profiling: Test suite
technology ten years after. Journal of Computer
Speech and Language: Special Issue on Evalu-
ation, 12(4):411?437.
Uwe Reyle. 1993. Dealing with ambiguities by un-
derspecification. Journal of Semantics, 10:123?
179.
Ivan A. Sag. 1997. English relative clause con-
structions. Journal of Linguistics, 33(2):431?
484.
David Schlangen and Alex Lascarides. 2002.
Resolving fragments using discourse informa-
tion. In Johan Bos, Mary Ellen Foster, and Colin
Matheson, editors, Proceedings of the 6th In-
ternational Workshop on Formal Semantics and
Pragmatics of Dialogue (EDILOG 2002), pages
161?168, Edinburgh, September.
David Schlangen. 2002. A compositional approach
to short answers in dialogue. In Gideon Mann
and Alexander Koller, editors, Proceedings of
the Student Research Workshop at the 40th ACL,
Philadelphia, USA, July.
David Schlangen. 2003. A Coherence-Based Ap-
proach to the Interpretation of Non-Sentential
Utterances in Dialogue. Ph.D. thesis, School
of Informatics, University of Edinburgh, Edin-
burgh, UK.
Bozena H. Thompson. 1980. Linguistic analysis
of natural language communication with com-
puters. In Proceedings of the Eighth Interna-
tional Conference on Computational Linguistics,
pages 190?201, Tokyo.
Wolfgang Wahlster, editor. 2000. Verbmobil:
Foundations of Speech-to-Speech Translation.
Springer, Berlin.
Coling 2008: Companion volume ? Posters and Demonstrations, pages 11?14
Manchester, August 2008
Towards Incremental End-of-Utterance Detection in Dialogue Systems
Michaela Atterer, Timo Baumann, David Schlangen
Institute of Linguistics
University of Potsdam, Germany
{atterer,timo,das}@ling
?
.uni-potsdam.de
Abstract
We define the task of incremental or 0-
lag utterance segmentation, that is, the task
of segmenting an ongoing speech recog-
nition stream into utterance units, and
present first results. We use a combination
of hidden event language model, features
from an incremental parser, and acous-
tic / prosodic features to train classifiers on
real-world conversational data (from the
Switchboard corpus). The best classifiers
reach an F-score of around 56%, improv-
ing over baseline and related work.
1 Introduction
Unlike written language, speech?and hence, au-
tomatic speech transcription?does not come seg-
mented into units. Current spoken dialogue sys-
tems simply wait for the speaker to turn silent to
segment their input. This necessarily reduces their
responsiveness, as further processing can only
even commence a certain duration after the turn
has ended (Ward et al, 2005). Moreover, given
the typically simple domains, such work mostly
does not deal with the problem of segmenting the
turn into utterances, i.e. does not distinguish be-
tween utterance and turn segmentation. However,
as our corpus shows (see below), multi-utterance
turns are the norm in natural dialogues. The work
that does treat intra-turn utterance segmentation
does so in an offline context, namely the post-
processing of automatic transcripts of recorded
speech such as meeting protocols (Fung et al,
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
2007), and relies heavily on right-context pause in-
formation.
In this paper, we define the task of incremental
or 0-lag utterance segmentation, that is, the task of
segmenting an ongoing speech recognition stream
into utterance units using only left-context infor-
mation.1 This work is done in the context of devel-
oping an incremental dialogue system architecture
(as proposed among others by (Aist et al, 2007)),
where, ideally, a considerable part of the analy-
sis has already been done while the speaker still
speaks. The incremental parser and other compo-
nents of such a system need to be reset at turn-
internal utterance-boundaries with as little delay as
possible. Hence it is of vital importance to predict
the end-of-utterance while the last word of a sen-
tence is processed (or even earlier). We investigate
typical features an incremental system can access,
such as partial parse trees and parser internal in-
formation. These experiments are a first important
step towards online endpointing in an incremental
system.
2 Data
We used section 2 of the Switchboard corpus
(Godfrey et al, 1992) for our experiments. Section
3 was used for training the language models and
the parser that we used. Some of the Switchboard
dialogues are of a very low quality. We excluded
those where transcription notes indicated high rate
of problems due to static noise, echo from the other
speaker or background noise. As our parser be-
came very slow for long sentences, we excluded
sentences that were longer than 25 words from the
10-lag here refers to the time where feature extraction
starts. As the modules on which feature extraction is based
require processing time themselves, a complete absence of
prediction delay is of course not possible.
11
analysis (4% of the sentences). We also excluded
back-channel utterances (typically one-word turns)
from the corpus.
Of the remaining corpus we only used the first
100,000 instances to reduce the computational
load for training the classifiers. 80 % of those were
used as a training corpus, and 20 % as a test corpus.
For follow-up experiments that investigated turn-
initial or turn-internal utterance boundaries only
(see below), we used the relevant subsets of the
first 200,000 instances.
3 Feature Extraction
Our features comprise prosodic features, and syn-
tactic features.
Prosodic features are pitch, logarithmized sig-
nal energy and derived features, extracted from the
audio every 10 ms. In order to track changes over
time, we derive features by windowing over past
values of pitch, energy, and energy in voiced re-
gions only, with window sizes ranging from 50 ms
to 5000 ms. We calculate the arithmetic mean and
the range of the values, the mean difference be-
tween values within the window and the relative
position of the minimum and maximum. We also
perform a linear regression and use its slope, the
MSE of the regression and the error of the regres-
sion for the last value in the window.
As classification was done word-wise (final vs.
non-final word), each word was attributed the
prosodic features of the last corresponding 10-ms-
frame.
For the extraction of syntactic features we used
both n-gram models and a parser. The parser
was a modified version of Amit Dubey?s sleepy
parser,2 which can produce syntactic structure in-
crementally online. The n-gram model was a
hidden event model as typically used in the sen-
tence unit detection literature (see e.g. (Fung et
al., 2007)). For the time being, all features based
on word identities are computed on gold stan-
dard transcriptions. We trained n-gram models
both based on words and on words plus POS-
information that was incrementally obtained from
the parser.3 We calculated the log-probability of
trigrams with the last token in the n-gram being
a place-holder for end-of-utterance (i.e. the prob-
2http://homepages.inf.ed.ac.uk/adubey/
software/
3The models were trained using the SRILM-tools (Stol-
cke, 2002) for n = 3 using Chen and Goodman?s modified
Kneser-Ney discounting (Chen and Goodman, 1998).
ability of (I,would,end-of-utterance) or (Thank,you,end-
of-utterance). We also calculated log probabili-
ties for trigrams such as (I, end-of-utterance-1,end-
of-utterance). Thirdly, the log probability was also
computed for a string consisting of 4 word/POS-
pairs followed by an end marker.
Further syntactic features can be roughly di-
vided into two classes: parser-based features,
which are related to internal states of the parser,
and structure-based features which refer to prop-
erties of the syntactic tree. The former try to cap-
ture the expectation of there being more incom-
plete edges towards the beginning of a sentence
than towards the end. We also might expect a rel-
ative decrease in the overall number of edges to-
wards the end of a sentence. Therefore we track a
selection of numbers referring to the various kinds
of edges stored in the chart. Moreover, we utilize
some of the parser?s information about the best in-
termediate edge, and use the category after the dot
of this edge as an estimate for the most probable
category to come next. Furthermore, we use the
forward probability of the best tree as a rounded
log probability.
The structure-based features are simple features
such as the part-of-speech category of the current
word and the number of the word in the current
utterance, and more complex features that try to
(roughly) approximate semantic notions of com-
pleteness by counting the number of verbs or num-
ber of nominal phrases encountered, as we would
usually expect a sentence to be incomplete if we
haven?t heard a verb or nominal phrase yet. For
example, in sentences of the structure (NP) (VP (V
NP)) or (NP) (VP (V NP (N PP))), humans would
typically be aware that the last phrase has probably
been reached during the last noun phrase or prepo-
sitional phrase (cf. (Grosjean, 1983)). However,
the length and internal structure of these phrases
can vary a great deal. We try to capture some of
this variation by features referring to the last non-
terminal seen, the second-to-last non-terminal seen
and the number of words seen since the last non-
terminal. A number of features (the count fea-
tures) are simple features that record the number
of words since the turn or utterance started and the
time elapsed since the utterance started. They are
also subsumed under syntactic features.
We also used dialogue act features like the pre-
vious dialogue act, and the previous dialogue act
of the last speaker. Those currently come from
12
the gold standard. We assume that in a dialogue
system the system would at least have information
about its own dialogue acts.
4 Experimental Settings
We tested a number of classifiers as implemented
in the Weka toolkit (Witten and Frank, 2005),
and found that the JRip-classifier, an implementa-
tion of the RIPPER-algorithm (Cohen, 1995), per-
formed best. A number of attribute selection algo-
rithms also did not result in a significant change of
performance. Therefore, we only report the plain
results by JRip. We also tested the impact each of
our information sources had on the results. The
aim was to find out how important parser, part-of-
speech information and pitch and energy features
are, respectively.
As turn-internal utterance-ends might be more
difficult to detect than those that coincide with
turn-ends, we repeat the experiment with turn-
internal utterances only. Deleting turn-final utter-
ances from our initial 200,000-instance corpus re-
sulted in 128,686 remaining word instances, 80 %
of which were used for training. For a third ex-
periment, where we look at turn-initial utterances,
we use again a subset of those 200,000 word-
instances.
For clarity, we simply use precision/recall for
evaluation; see (Liu and Shriberg, 2007) for a dis-
cussion of other metrics. As a baseline we assume
non-existent utterance segmentation, which results
in a recall of 0 and a precision of 100 %.
5 Results
Precision Recall F
baseline 100 0 0
all features 73.8 45.0 55.9
all syntactic features 74.8 44.0 55.4
word/POS n-gram features 73.4 45.8 56.4
word n-gram features 66.9 34.7 45.7
only count features 59.3 7.7 13.6
prosodic features only 49.5 8.3 14.2
pitch features 100 0 0
energy features 48.2 7.4 12.8
Table 1: Results for end-of-utterance classification
for all utterances.
Tables 1 and 2 show the results for the experi-
mental settings described above. Dialogue act fea-
tures were included in the syntactic features, but
JRip did not use them in its rules eventually. Ta-
ble 1 shows that the overall F-score is best when
n-grams with POS information are used. Adding
a parser, however, increases precision. Prosody
features in general do not seem to have much of
an influence on end-of-utterance prediction in our
data, with energy features contributing more than
pitch features. Table 2 indicates, as expected, that
Precision Recall F
baseline 100 0 0
all features 71.2 40.3 51.4
all syntactic features 72.7 38.2 50.0
word/POS n-gram features 70.5 41.1 51.9
word n-gram features 70.9 26.4 38.5
only count features 60.4 1.0 2.0
prosodic features only 41.7 1.7 3.3
pitch features 100 0 0
energy features 31.6 1.2 2.3
Table 2: Results for end-of-utterance classification
for utterances which are not turn-final.
the end of an utterance is harder to predict when
it is not turn-final. Performance drops compared
to the results shown in Table 1. Note that some
of the performance drop must be attributed to the
use of a different data set. However, the perfor-
mance drop is much more dramatic for the exper-
iments where only prosody is used than for those
where syntax is used. We speculate that the count
features also loose their impact because one-word
utterances like ?Okay? are usually turn-initial.
The results shown in Tables 1 and 2 can be re-
garded as an upper bound for a dialogue system,
because our experiments so far work with gold
standard sentence boundaries for creating syntac-
tic features (e.g., for resetting our parser). Strictly
speaking, they are only realistic for turn-initial ut-
terances. For the remaining 14,737 of our 26,401
utterances, we therefore report a lower bound,
where we use only features that do not have knowl-
edge about the beginning of the sentence (Table 3).
No count and parser-based features were used for
this experiment, only n-gram (word-based without
POS information) and pitch features. The Table
also shows the results for the 11,664 turn-initial
utterances, where we use all features.4 We then
derive the overall performance from the fractions
of initial and non-initial utterances.
Future work aims at putting together a sys-
tem where the parser is restarted using predictions
based on its own output.
4Note that turn-initial utterances can at the same time be
turn-final.
13
Precision Recall F
non-initial 65.0 28.6 39.7
initial 74.5 55.1 63.3
overall 70.4 40.3 51.3
Table 3: Results for end-of-utterance classification
for utterances which are not turn-initial (reduced
feature set), and utterances that are turn-initial (full
feature set) and the derived overall performance.
6 Related Work
(Fuentes et al, 2007) report F-measures of 84%
using prosodic features only, but they use left?
right-windows for feature calculation, where our
processing is truly incremental and more suitable
for real-time usage in a dialogue system. More-
over, they only seem to use one-utterance turns,
which makes the task easier when prosodic fea-
tures are used. In our dialogue corpus (Switch-
board, section 2), however, each turn contains
on average 2.5 utterances, and turn-internal ut-
terances also need to be recognized. (Fung et
al., 2007) reach an F-score of 75.3% , but report
that the best feature was pause-duration?a fea-
ture we don?t use because we want to find out
how well we can predict the end of a sentence
before a pause makes this clear. Similarly, (Fer-
rer et al, 2002) rely largely on pause features.
(Schlangen, 2006) investigates incremental predic-
tion of end-of-utterance and end-of-turn for var-
ious pause-lengths, and achieves an F-score of
35.5% for pause length 0, on which we can im-
prove here.
7 Discussion and Conclusion
We investigated 0-lag end-of-utterance detection
for incremental dialogue systems. In our setup,
we aim to recognise the end of an utterance as
soon as possible, while the potentially last word is
processed, without the help of information about
subsequent silence. We investigate a number of
features an incremental system would be able to
access, such as information from an incremen-
tal parser. We find that remaining (non-pause)
prosodic information is not as helpful as in non-
incremental studies, especially for non-turn-final
utterances. Syntactic information, on the other
hand, increases performance. Future work aims at
more sophisticated prosodic modelling and at test-
ing the impact of using real or simulated speech
recognition output. We also intend to implement
end-of-utterance prediction in the context of a real
incremental system we are building.
8 Acknowledgement
This work was funded by DFG ENP
SCHL845/3-1.
References
Aist, Gregory, James Allen, Ellen Campana, Carlos Gomez-
Gallo, Scott Stoness, Mary Swift, and Michael Tanenhaus.
2007. Incremental understanding in human-computer dia-
logue and experimental evidence for advantages over non-
incremental methods. In Proc. of the 2007 Workshop on
the Semantics and Pragmatics of Dialogue (DECALOG).
Chen, S.F. and J. Goodman. 1998. An empirical study
of smoothing techniques for language modeling. Techni-
cal report, Center for Research in Computing Technology
(Harvard University).
Cohen, William W. 1995. Fast effective rule induction. In
Machine Learning: Proceedings of the Twelfth Interna-
tional Conference.
Ferrer, L., E. Shriberg, and A. Stolcke. 2002. Is the speaker
done yet? Faster and more accurate end-of-utterance de-
tection using prosody in human-computer dialog. In Proc.
Intl. Conf. on Spoken Language Processing, Denver.
Fuentes, Olac, David Vera, and Thamar Solorio. 2007.
A filter-based approach to detect end-of-utterances from
prosody in dialog systems. In Proc. Human Language
Technologies 2007, Rochester, New York.
Fung, J., D. Hakkani-Tur, M. Magimai-Doss, E. Shriberg,
S. Cuendet, and N. Mirghafori. 2007. Prosodic features
and feature selection for multi-lingual sentence segmenta-
tion. In Proc. Interspeech, pages 2585?2588, Antwerp.
Godfrey, John J., E. C. Holliman, and J. McDaniel. 1992.
SWITCHBOARD: Telephone speech corpus for research
and development. In Proc. of ICASSP-1992, pages 517?
520, San Francisco, USA, March.
Grosjean, Franc?ois. 1983. How long is the sentence? Pre-
diction and prosody in the on-line processing of language.
Linguistics, 21:501?529.
Liu, Y. and E. Shriberg. 2007. Comparing evaluation metrics
for sentence boundary detection. In Proc. IEEE ICASSP,
Honolulu,USA.
Schlangen, David. 2006. From reaction to prediction: Exper-
iments with computational models of turn-taking. In Proc.
Interspeech 2006, Panel on Prosody of Dialogue Ac ts and
Turn-Taking, Pittsburgh, USA.
Stolcke, Andreas. 2002. SRILM ? an extensible language
modeling toolkit. In Proc. ICSLP 2002.
Ward, Nigel G., Anais G. Rivera, Karen Ward, and David G.
Novick. 2005. Root causes of lost time and user stress in
a simple dialog system. In Proc. of Interspeech, El Paso,
USA.
Witten, Ian H. and Eibe Frank. 2005. Data Mining: Practical
Machine Learning Tools and Techniques. Morgan Kauf-
mann.
14
Proceedings of the 12th Conference of the European Chapter of the ACL, pages 710?718,
Athens, Greece, 30 March ? 3 April 2009. c?2009 Association for Computational Linguistics
A General, Abstract Model of Incremental Dialogue Processing
David Schlangen
Department of Linguistics
University of Potsdam, Germany
das@ling.uni-potsdam.de
Gabriel Skantze?
Dept. of Speech, Music and Hearing
KTH, Stockholm, Sweden
gabriel@speech.kth.se
Abstract
We present a general model and concep-
tual framework for specifying architec-
tures for incremental processing in dia-
logue systems, in particular with respect
to the topology of the network of modules
that make up the system, the way informa-
tion flows through this network, how in-
formation increments are ?packaged?, and
how these increments are processed by the
modules. This model enables the precise
specification of incremental systems and
hence facilitates detailed comparisons be-
tween systems, as well as giving guidance
on designing new systems.
1 Introduction
Dialogue processing is, by its very nature, incre-
mental. No dialogue agent (artificial or natural)
processes whole dialogues, if only for the simple
reason that dialogues are created incrementally, by
participants taking turns. At this level, most cur-
rent implemented dialogue systems are incremen-
tal: they process user utterances as a whole and
produce their response utterances as a whole.
Incremental processing, as the term is com-
monly used, means more than this, however,
namely that processing starts before the input is
complete (e.g., (Kilger and Finkler, 1995)). Incre-
mental systems hence are those where ?Each pro-
cessing component will be triggered into activity
by a minimal amount of its characteristic input?
(Levelt, 1989). If we assume that the character-
istic input of a dialogue system is the utterance
(see (Traum and Heeman, 1997) for an attempt to
define this unit), we would expect an incremental
system to work on units smaller than utterances.
Our aim in the work presented here is to de-
scribe and give names to the options available to
?The work reported here was done while the second au-
thor was at the University of Potsdam.
designers of incremental systems. We define some
abstract data types, some abstract methods that
are applicable to them, and a range of possible
constraints on processing modules. The notions
introduced here allow the (abstract) specification
of a wide range of different systems, from non-
incremental pipelines to fully incremental, asyn-
chronous, parallel, predictive systems, thus mak-
ing it possible to be explicit about similarities and
differences between systems. We believe that this
will be of great use in the future development of
such systems, in that it makes clear the choices
and trade-offs one can make. While we sketch our
work on one such system, our main focus here
is on the conceptual framework. What we are
not doing here is to argue for one particular ?best
architecture??what this is depends on the particu-
lar aims of an implementation/model and on more
low-level technical considerations (e.g., availabil-
ity of processing modules).1
In the next section, we give some examples of
differences in system architectures that we want to
capture, with respect to the topology of the net-
work of modules that make up the system, the
way information flows through this network and
how the modules process information, in partic-
ular how they deal with incrementality. In Sec-
tion 3, we present the abstract model that under-
lies the system specifications, of which we give an
example in Section 4. We close with a brief dis-
cussion of related work.
2 Motivating Examples
Figure 1 shows three examples of module net-
works, representations of systems in terms of their
component modules and the connections between
them. Modules are represented by boxes, and con-
nections by arrows indicating the path and the di-
1As we are also not trying to prove properties of the spec-
ified systems here, the formalisations we give are not sup-
ported by a formal semantics here.
710
rection of information flow. Arrows not coming
from or going to modules represent the global in-
put(s) and output(s) to and from the system.
Figure 1: Module Network Topologies
One of our aims here is to facilitate exact and
concise description of the differences between
module networks such as in the example. Infor-
mally, the network on the left can be described as
a simple pipeline with no parallel paths, the one in
the middle as a pipeline enhanced with a parallel
path, and the one on the right as a star-architecture;
we want to be able to describe exactly the con-
straints that define each type of network.
A second desideratum is to be able to specify
how information flows in the system and between
the modules, again in an abstract way, without
saying much about the information itself (as the
nature of the information depends on details of
the actual modules). The directed edges in Fig-
ure 1 indicate the direction of information flow
(i.e., whose output is whose input); as an addi-
tional element, we can visualise parallel informa-
tion streams between modules as in Figure 2 (left),
where multiple hypotheses about the same input
increments are passed on. (This isn?t meant to
imply that there are three actual communications
channels active. As described below, we will en-
code the parallelism directly on the increments.)
One way such parallelism may occur in an in-
cremental dialogue system is illustrated in Fig-
ure 2 (right), where for some stretches of an input
signal (a sound wave), alternative hypotheses are
entertained (note that the boxes here do not repre-
sent modules, but rather bits of incremental infor-
mation). We can view these alternative hypothe-
Figure 2: Parallel Information Streams (left) and
Alternative Hypotheses (right)
Figure 3: Incremental Input mapped to (less) in-
cremental output
Figure 4: Example of Hypothesis Revision
ses about the same original signal as being paral-
lel to each other (with respect to the input they are
grounded in).
We also want to be able to specify the ways in-
cremental bits of input (?minimal amounts of char-
acteristic input?) can relate to incremental bits of
output. Figure 3 shows one possible configuration,
where over time incremental bits of input (shown
in the left column) accumulate before one bit of
output (in the right column) is produced. (As for
example in a parser that waits until it can com-
pute a major phrase out of the words that are its
input.) Describing the range of possible module
behaviours with respect to such input/output rela-
tions is another important element of the abstract
model presented here.
It is in the nature of incremental processing,
where output is generated on the basis of incom-
plete input, that such output may have to be re-
vised once more information becomes available.
Figure 4 illustrates such a case. At time-step t1,
the available frames of acoustic features lead the
processor, an automatic speech recogniser, to hy-
pothesize that the word ?four? has been spoken.
This hypothesis is passed on as output. However,
at time-point t2, as additional acoustic frames have
come in, it becomes clear that ?forty? is a bet-
ter hypothesis about the previous frames together
with the new ones. It is now not enough to just
output the new hypothesis: it is possible that later
modules have already started to work with the hy-
pothesis ?four?, so the changed status of this hy-
pothesis has to be communicated as well. This is
shown at time-step t3. Defining such operations
and the conditions under which they are necessary
711
is the final aim of our model.
3 The Model
3.1 Overview
We model a dialogue processing system in an ab-
stract way as a collection of connected processing
modules, where information is passed between the
modules along these connections. The third com-
ponent beside the modules and their connections is
the basic unit of information that is communicated
between the modules, which we call the incremen-
tal unit (IU). We will only characterise those prop-
erties of IUs that are needed for our purpose of
specifying different system types and basic oper-
ations needed for incremental processing; we will
not say anything about the actual, module specific
payload of these units.
The processing module itself is modelled as
consisting of a Left Buffer (LB), the Processor
proper, and a Right Buffer (RB). When talking
about operations of the Processor, we will some-
times use Left Buffer-Incremental Unit (LB-IU)
for units in LB and Right Buffer-Incremental Unit
(RB-IU) for units in RB.
This setup is illustrated in Figure 4 above. IUs
in LB (here, acoustic frames as input to an ASR)
are consumed by the processor (i.e., is processed),
which creates an internal result, in the case shown
here, this internal result is posted as an RB-IU only
after a series of LB-IUs have accumulated. In our
descriptions below, we will abstract away from the
time processing takes and describe Processors as
relations between (sets of) LBs and RBs.
We begin our description of the model with the
specification of network topologies.
3.2 Network Topology
Connections between modules are expressed
through connectedness axioms which simply state
that IUs in one module?s right buffer are also in
another buffer?s left buffer. (Again, in an imple-
mented system communication between modules
will take time, but we abstract away from this
here.) This connection can also be partial or fil-
tered. For example, ?x(x ? RB1 ? NP (x) ?
x ? LB2) expresses that all and only NPs in mod-
ule one?s right buffer appear in module two?s left
buffer. If desired, a given RB can be connected to
more than one LB, and more than one RB can feed
into the same LB (see the middle example in Fig-
ure 1). Together, the set of these axioms define the
network topology of a concrete system. Different
topology types can then be defined through con-
straints on module sets and their connections. I.e.,
a pipeline system is one in which it cannot hap-
pen that an IU is in more than one right buffer and
more than one left buffer.
Note that we are assuming token identity here,
and not for example copying of data struc-
tures. That is, we assume that it indeed is the
same IU that is in the left and right buffers
of connected modules. This allows a spe-
cial form of bi-directionality to be implemented,
namely one where processors are allowed to make
changes to IUs in their buffers, and where these
changes automatically percolate through the net-
work. This is different to and independent of
the bi-directionality that can be expressed through
connectedness axioms.
3.3 Incremental Units
So far, all we have said about IUs is that they are
holding a ?minimal amount of characteristic input?
(or, of course, a minimal amount of characteris-
tic output, which is to be some other module?s in-
put). Communicating just these minimal informa-
tion bits is enough only for the simplest kind of
system that we consider, a pipeline with only a
single stream of information and no revision. If
more advanced features are desired, there needs to
be more structure to the IUs. In this section we de-
fine what we see as the most complete version of
IUs, which makes possible operations like hypoth-
esis revision, prediction, and parallel hypothesis
processing. (These operations will be explained in
the next section.) If in a particular system some of
these operations aren?t required, some of the struc-
ture on IUs can be simplified.
Informally, the representational desiderata are
as follows. First, we want to be able to repre-
sent relations between IUs produced by the same
processor. For example, in the output of an ASR,
two word-hypothesis IUs may stand in a succes-
sor relation, meaning that word 2 is what the ASR
takes to be the continuation of the utterance be-
gun with word 1. In a different situation, word 2
may be an alternative hypothesis about the same
stretch of signal as word 1, and here a different re-
lation would hold. The incremental outputs of a
parser may be related in yet another way, through
dominance: For example, a newly built IU3, rep-
resenting a VP, may want to express that it links
712
via a dominance relation to IU1, a V, and IU2, an
NP, which were both posted earlier. What is com-
mon to all relations of this type is that they relate
IUs coming from the same processor(s); we will
in this case say that the IUs are on the same level.
Information about these same level links will be
useful for the consumers of IUs. For example, a
parsing module consuming ASR-output IUs will
need to do different things depending on whether
an incoming IU continues an utterance or forms an
alternative hypothesis to a string that was already
parsed.
The second relation between IUs that we want
to capture cuts across levels, by linking RB-IUs to
those LB-IUs that were used by the processor to
produce them. For this we will say that the RB-IU
is grounded in LB-IU(s). This relation then tracks
the flow of information through the modules; fol-
lowing its transitive closure one can go back from
the highest level IU, which is output by the sys-
tem, to the input IU or set of input IUs on which it
is ultimately grounded. The network spanned by
this relation will be useful in implementing the re-
vision process mentioned above when discussing
Figure 4, where the doubt about a hypothesis must
spread to all hypotheses grounded in it.
Apart from these relations, we want IUs to carry
three other types of information: a confidence
score representing the confidence its producer had
in it being accurate; a field recording whether revi-
sions of the IU are still to be expected or not; and
another field recording whether the IU has already
been processed by consumers, and if so, by whom.
Formally, we define IUs as tuples IU =
?I,L,G,T , C,S,P?, where
? I is an identifier, which has to be unique for
each IU over the lifetime of a system. (That
is, at no point in the system?s life can there be
two or more IUs with the same ID.)
? L is the same level link, holding a statement
about how, if at all, the given IU relates to
other IUs at the same level, that is, to IUs pro-
duced by the same processor. If an IU is not
linked to any other IU, this slot holds the spe-
cial value ?.
The definition demands that the same level
links of all IUs belonging to the same larger
unit form a graph; the type of the graph will
depend on the purposes of the sending and
consuming module(s). For a one-best output
of an ASR it might be enough for the graph
to be a chain, whereas an n-best output might
be better represented as a tree (with all first
words linked to ?) or even a lattice (as in
Figure 2 (right)); the output of a parser might
require trees (possibly underspecified).
? G is the grounded in field, holding an ordered
list of IDs pointing to those IUs out of which
the current IU was built. For example, an IU
holding a (partial) parse might be grounded
in a set of word hypothesis IUs, and these in
turn might be grounded in sets of IUs holding
acoustic features. While the same level link
always points to IUs on the same level, the
grounded in link always points to IUs from
a previous level.2 The transitive closure of
this relation hence links system output IUs to
a set of system input IUs. For convenience,
we may define a predicate supports(x,y) for
cases where y is grounded in x; and hence
the closure of this relation links input-IUs to
the output that is (eventually) built on them.
This is also the hook for the mechanism that
realises the revision process described above
with Figure 4: if a module decides to re-
voke one of its hypotheses, it sets its confi-
dence value (see below) to 0; on noticing this
event, all consuming modules can then check
whether they have produced RB-IUs that link
to this LB-IU, and do the same for them. In
this way, information about revision will au-
tomatically percolate through the module net-
work.
Finally, an empty grounded in field can also
be used to trigger prediction: if an RB-IU has
an empty grounded in field, this can be under-
stood as a directive to the processor to find
evidence for this IU (i.e., to prove it), using
the information in its left buffer.
? T is the confidence (or trust) slot, through
which the generating processor can pass on
its confidence in its hypothesis. This then can
have an influence on decisions of the con-
suming processor. For example, if there are
parallel hypotheses of different quality (con-
fidence), a processor may decide to process
2The link to the previous level may be indirect. E.g.,
for an IU holding a phrase that is built out of previously
built phrases (and not words), this link may be expressed by
pointing to the same level link, meaning something like ?I?m
grounded in whatever the IUs are grounded in that I link to
on the same level link, and also in the act of combination that
is expressed in that same level link?.
713
(and produce output for) the best first.
A special value (e.g., 0, or -1) can be defined
to flag hypotheses that are being revoked by
a processor, as described above.
? C is the committed field, holding a Boolean
value that indicates whether the producing
module has committed to the IU or not, that
is, whether it guarantees that it will never re-
voke the IU. See below for a discussion of
how such a decision may be made, and how
it travels through the module network.
? S is the seen field. In this field consum-
ing processors can record whether they have
?looked at??that is, attempted to process?
the IU. In the simplest case, the positive fact
can be represented simply by adding the pro-
cessor ID to the list; in more complicated
setups one may want to offer status infor-
mation like ?is being processed by module
ID? or ?no use has been found for IU by
module ID?. This allows processors both to
keep track of which LB-IUs they have al-
ready looked at (and hence, to more easily
identify new material that may have entered
their LB) and to recognise which of its RB-
IUs have been of use to later modules, infor-
mation which can then be used for example
to make decisions on which hypothesis to ex-
pand next.
? P finally is the actual payload, the module-
specific unit of ?characteristic input?, which
is what is processed by the processor in order
to produce RB-IUs.
It will also be useful later to talk about the com-
pleteness of an IU (or of sets of IUs). This we de-
fine informally as its relation to (the type of) what
would count as a maximal input or output of the
module. For example, for an ASR module, such
maximally complete input may be the recording of
the whole utterance, for the parser maximal out-
put may be a parse of type sentence (as opposed
to one of type NP, for example).3 This allows us
to see non-incremental systems as a special case
of incremental systems, namely those with only
maximally complete IUs, which are always com-
mitted.
3This definition will only be used for abstractly classify-
ing modules. Practically, it is of course rarely possible to
know how complete or incomplete the already seen part of
an ongoing input is. Investigating how a dialogue system can
better predict completion of an utterance is in fact one of the
aims of the project in which this framework was developed.
3.4 Modules
3.4.1 Operations
We describe in this section operations that the pro-
cessors may perform on IUs. We leave open how
processors are triggered into action, we simply as-
sume that on receiving new LB-IUs or noticing
changes to LB or RB-IUs, they will eventually per-
form these operations. Again, we describe here the
complete set of operations; systems may differ in
which subset of the functions they implement.
purge LB-IUs that are revoked by their producer
(by having their confidence score set to the special
value) must be purged from the internal state of the
processor (so that they will not be used in future
updates) and all RB-IUs grounded in them must
be revoked as well.
Some reasons for revoking hypotheses have al-
ready been mentioned. For example, a speech
recogniser might decide that a previously output
word hypothesis is not valid anymore (i.e., is not
anymore among the n-best that are passed on). Or,
a parser might decide in the light of new evidence
that a certain structure it has built is a dead end,
and withdraw support for it. In all these cases, all
?later? hypotheses that build on this IU (i.e., all hy-
potheses that are in the transitive closure of this
IU?s support relation) must be purged. If all mod-
ules implement the purge operation, this revision
information will be guaranteed to travel through
the network.
update New LB-IUs are integrated into the in-
ternal state, and eventually new RB-IUs are built
based on them (not necessarily in the same fre-
quency as new LB-IUs are received; see Figure 3
above, and discussion below). The fields of the
new RB-IUs (e.g., the same level links and the
grounded in pointers) are filled appropriately. This
is in some sense the basic operation of a processor,
and must be implemented in all useful systems.
We can distinguish two implementation strate-
gies for dealing with updates: a) all state is thrown
away and results are computed again for the whole
input set. The result must then be compared with
the previous result to determine what the new out-
put increment is. b) The new information is in-
tegrated into internal state, and only the new out-
put increment is produced. For our purposes here,
we can abstract away from these differences and
assume that only actual increments are commu-
nicated. (Practically, it might be an advantage to
keep using an existing processor and just wrap it
714
into a module that computes increments by differ-
ences.)
We can also distinguish between modules along
another dimension, namely based on which types
of updates are allowed. To do so, we must first
define the notion of a ?right edge? of a set of
IUs. This is easiest to explain for strings, where
the right edge simply is the end of the string, or
for a lattice, where it is the (set of) smallest ele-
ment(s). A similar notion may be defined for trees
as well (compare the ?right frontier constraint?
of Polanyi (1988)). If now a processor only ex-
pects IUs that extend the right frontier, we can
follow Wire?n (1992) in saying that it is only left-
to-right incremental. Within what Wire?n (1992)
calls fully incremental, we can make more dis-
tinctions, namely according to whether revisions
(as described above) and/or insertions are allowed.
The latter can easily be integrated into our frame-
work, by allowing same-level links to be changed
to fit new IUs into existing graphs.
Processors can take supports information into
account when deciding on their update order. A
processor might for example decide to first try to
use the new information (in its LB) to extend struc-
tures that have already proven useful to later mod-
ules (that is, that support new IUs). For example,
a parser might decide to follow an interpretation
path that is deemed more likely by a contextual
processing module (which has grounded hypothe-
ses in the partial path). This may result in better
use of resources?the downside of such a strategy
of course is that modules can be garden-pathed.4
Update may also work towards a goal. As men-
tioned above, putting ungrounded IUs in a mod-
ule?s RB can be understood as a request to the
module to try to find evidence for it. For exam-
ple, the dialogue manager might decide based on
the dialogue context that a certain type of dialogue
act is likely to follow. By requesting the dialogue
act recognition module to find evidence for this
hypothesis, it can direct processing resources to-
wards this task. (The dialogue recognition mod-
ule then can in turn decide on which evidence it
would like to see, and ask lower modules to prove
this. Ideally, this could filter down to the interface
module, the ASR, and guide its hypothesis form-
ing. Technically, something like this is probably
easier to realise by other means.)
4It depends on the goals behind building the model
whether this is considered a downside or desired behaviour.
We finally note that in certain setups it may be
necessary to consume different types of IUs in one
module. As explained above, we allow more than
one module to feed into another modules LB. An
example where something like this could be useful
is in the processing of multi-modal information,
where information about both words spoken and
gestures performed may be needed to compute an
interpretation.
commit There are three ways in which a proces-
sor may have to deal with commits. First, it can
decide for itself to commit RB-IUs. For example,
a parser may decide to commit to a previously built
structure if it failed to integrate into it a certain
number of new words, thus assuming that the pre-
vious structure is complete. Second, a processor
may notice that a previous module has committed
to IUs in its LB. This might be used by the proces-
sor to remove internal state kept for potential re-
visions. Eventually, this commitment of previous
modules might lead the processor to also commit
to its output, thus triggering a chain of commit-
ments.
Interestingly, it can also make sense to let com-
mits flow from right to left. For example, if the
system has committed to a certain interpretation
by making a publicly observable action (e.g., an
utterance, or a multi-modal action), this can be
represented as a commit on IUs. This information
would then travel down the processing network;
leading to the potential for a clash between a re-
voke message coming from the left and the com-
mit directive from the right. In such a case, where
the justification for an action is revoked when the
action has already been performed, self-correction
behaviours can be executed.5
3.4.2 Characterising Module Behaviour
It is also useful to be able to abstractly describe the
relation between LB-IUs and RB-IUs in a module
or a collection of modules. We do this here along
the dimensions update frequency, connectedness
and completeness.
Update Frequency The first dimension we con-
sider here is that of how the update frequency of
LB-IUs relates to that of (connected) RB-IUs.
We write f:in=out for modules that guarantee
that every new LB-IU will lead to a new RB-IU
5In future work, we will explore in more detail if and
how through the implementation of a self-monitoring cycle
and commits and revokes the various types of dysfluencies
described for example by Levelt (1989) can be modelled.
715
(that is grounded in the LB-IU). In such a setup,
the consuming module lags behind the sending
module only for exactly the time it needs to pro-
cess the input. Following Nivre (2004), we can
call this strict incrementality.
f:in?out describes modules that potentially col-
lect a certain amount of LB-IUs before producing
an RB-IU based on them. This situation has been
depicted in Figure 3 above.
f:in?out characterises modules that update RB
more often than their LB is updated. This could
happen in modules that produce endogenic infor-
mation like clock signals, or that produce contin-
uously improving hypotheses over the same input
(see below), or modules that ?expand? their input,
like a TTS that produces audio frames.
Connectedness We may also want to distin-
guish between modules that produce ?island? hy-
potheses that are, at least when initially posted, not
connected via same level links to previously out-
put IUs, and those that guarantee that this is not
the case. For example, to achieve an f:in=out be-
haviour, a parser may output hypotheses that are
not connected to previous hypotheses, in which
case we may call the hypotheses ?unconnected?.
Conversely, to guarantee connectedness, a parsing
module might need to accumulate input, resulting
in an f:in?out behaviour.6
Completeness Building on the notion of com-
pleteness of (sets of) IUs introduced above, we
can also characterise modules according to how
the completeness of LB and RB relates.
In a c:in=out-type module, the most complete
RB-IU (or set of RB-IUs) is only as complete as
the most complete (set of) LB-IU(s). That is, the
module does not speculate about completions, nor
does it lag behind. (This may technically be diffi-
cult to realise, and practically not very relevant.)
More interesting is the difference between the
following types: In a c:in?out-type module, the
most complete RB-IU potentially lags behind the
most complete LB-IU. This will typically be the
case in f:in?out modules. c:in?out-type mod-
ules finally potentially produce output that is more
complete than their input, i.e., they predict contin-
uations. An extreme case would be a module that
always predicts complete output, given partial in-
put. Such a module may be useful in cases where
6The notion of connectedness is adapted from Sturt and
Lombardo (2005), who provide evidence that the human
parser strives for connectedness.
modules have to be used later in the processing
chain that can only handle complete input (that is,
are non-incremental); we may call such a system
prefix-based predictive, semi-incremental.
With these categories in hand, we can make
further distinctions within what Dean and Boddy
(1988) call anytime algorithms. Such algorithms
are defined as a) producing output at any time,
which however b) improves in quality as the al-
gorithm is given more time. Incremental mod-
ules by definition implement a reduced form of
a): they may not produce an output at any
time, but they do produce output at more times
than non-incremental modules. This output then
also improves over time, fulfilling condition b),
since more input becomes available and either
the guesses the module made (if it is a c:out?in
module) will improve or the completeness in
general increases (as more complete RB-IUs are
produced). Processing modules, however, can
also be anytime algorithms in a more restricted
sense, namely if they continuously produce new
and improved output even for a constant set of
LB-IUs, i.e. without changes on the input side.
(Which would bring them towards the f:out?in be-
haviour.)
3.5 System Specification
Combining all these elements, we can finally de-
fine a system specification as the following:
? A list of modules that are part of the system.
? For each of those a description in terms
of which operations from Section 3.4.1 the
module implements, and a characterisation of
its behaviour in the terms of Section 3.4.2.
? A set of axioms describing the connections
between module buffers (and hence the net-
work topology), as explained in Section 3.2.
? Specifications of the format of the IUs that
are produced by each module, in terms of the
definition of slots in Section 3.3.
4 Example Specification
We have built a fully incremental dialogue system,
called NUMBERS (for more details see Skantze
and Schlangen (2009)), that can engage in dia-
logues in a simple domain, number dictation. The
system can not only be described in the terms ex-
plained here, but it also directly instantiates some
of the data types described here.
716
Figure 5: The NUMBERS System Architecture
(CA = communicative act)
The module network topology of the system is
shown in Figure 5. This is pretty much a stan-
dard dialogue system layout, with the exception
that prosodic analysis is done in the ASR and that
dialogue management is divided into a discourse
modelling module and an action manager. As can
be seen in the figure, there is also a self-monitoring
feedback loop?the system?s actions are sent from
the TTS to the discourse modeller. The system
has two modules that interface with the environ-
ment (i.e., are system boundaries): the ASR and
the TTS.
A single hypothesis chain connects the mod-
ules (that is, no two same level links point to the
same IU). Modules pass messages between them
that can be seen as XML-encodings of IU-tokens.
Information strictly flows from LB to RB. All IU
slots except seen (S) are realised. The purge and
commit operations are fully implemented. In the
ASR, revision occurs as already described above
with Figure 4, and word-hypothesis IUs are com-
mitted (and the speech recognition search space is
cleared) after 2 seconds of silence are detected.
(Note that later modules work with all IUs from
the moment that they are sent, and do not have
to wait for them being committed.) The parser
may revoke its hypotheses if the ASR revokes the
words it produces, but also if it recovers from a
?garden path?, having built and closed off a larger
structure too early. As a heuristic, the parser
waits until a syntactic construct is followed by
three words that are not part of it until it com-
mits. For each new discourse model increment,
the action manager may produce new communica-
tive acts (CAs), and possibly revoke previous ones
that have become obsolete. When the system has
spoken a CA, this CA becomes committed, which
is recorded by the discourse modeller.
No hypothesis testing is done (that is, no un-
grounded information is put on RBs). All modules
have a f:in?out; c:in?out characteristic.
The system achieves a very high degree of
responsiveness?by using incremental ASR and
prosodic analysis for turn-taking decisions, it can
react in around 200ms when suitable places for
backchannels are detected, which should be com-
pared to a typical minimum latency of 750ms
in common systems where only a simple silence
threshold is used.
5 Related Work, Future Work
The model described here is inspired partially by
Young et al (1989)?s token passing architecture;
our model can be seen as a (substantial) general-
isation of the idea of passing smaller information
bits around, out of the domain of ASR and into the
system as a whole. Some of the characterisations
of the behaviour of incremental modules were in-
spired by Kilger and Finkler (1995), but again we
generalised the definitions to fit all kinds of incre-
mental modules, not just generation.
While there recently have been a number of
papers about incremental systems (e.g., (DeVault
and Stone, 2003; Aist et al, 2006; Brick and
Scheutz, 2007)), none of those offer general con-
siderations about architectures. (Despite its title,
(Aist et al, 2006) also only describes one particu-
lar setup.)
In future work, we will give descriptions of
these systems in the terms developed here. We
are also currently exploring how more cognitively
motivated models such as that of generation by
Levelt (1989) can be specified in our model. A
further direction for extension is the implementa-
tion of modality fusion as IU-processing. Lastly,
we are now starting to work on connecting the
model for incremental processing and ground-
ing of interpretations in previous processing re-
sults described here with models of dialogue-level
grounding in the information-state update tradi-
tion (Larsson and Traum, 2000). The first point
of contact here will be the investigation of self-
corrections, as a phenomenon that connects sub-
utterance processing and discourse-level process-
ing (Ginzburg et al, 2007).
Acknowledgments This work was funded by a grant in the
DFG Emmy Noether Programme. Thanks to Timo Baumann
and Michaela Atterer for discussion of the ideas reported
here, and to the anonymous reviewers for their very detailed
and helpful comments.
717
References
G.S. Aist, J. Allen, E. Campana, L. Galescu, C.A.
Gomez Gallo, S. Stoness, M. Swift, and M Tanen-
haus. 2006. Software architectures for incremental
understanding of human speech. In Proceedings of
the International Conference on Spoken Language
Processing (ICSLP), Pittsburgh, PA, USA, Septem-
ber.
Timothy Brick and Matthias Scheutz. 2007. Incremen-
tal natural language processing for HRI. In Proceed-
ings of the Second ACM IEEE International Confer-
ence on Human-Robot Interaction, pages 263?270,
Washington, DC, USA.
Thomas Dean and Mark Boddy. 1988. An analysis of
time-dependent planning. In Proceedings of AAAI-
88, pages 49?54. AAAI.
David DeVault and Matthew Stone. 2003. Domain
inference in incremental interpretation. In Proceed-
ings of ICOS 4: Workshop on Inference in Computa-
tional Semantics, Nancy, France, September. INRIA
Lorraine.
Jonathan Ginzburg, Raquel Ferna?ndez, and David
Schlangen. 2007. Unifying self- and other-repair.
In Proceeding of DECALOG, the 11th International
Workshop on the Semantics and Pragmatics of Dia-
logue (SemDial07), Trento, Italy, June.
Anne Kilger and Wolfgang Finkler. 1995. Incremen-
tal generation for real-time applications. Technical
Report RR-95-11, DFKI, Saarbru?cken, Germany.
Staffan Larsson and David Traum. 2000. Information
state and dialogue management in the TRINDI dia-
logue move engine toolkit. Natural Language Engi-
neering, pages 323?340.
Willem J.M. Levelt. 1989. Speaking. MIT Press,
Cambridge, USA.
Joakim Nivre. 2004. Incrementality in determinis-
tic dependency parsing. pages 50?57, Barcelona,
Spain, July.
Livia Polanyi. 1988. A formal model of the structure
of discourse. Journal of Pragmatics, 12:601?638.
Gabriel Skantze and David Schlangen. 2009. Incre-
mental dialogue processing in a micro-domain. In
Proceedings of the 12th Conference of the European
Chapter of the Association for Computational Lin-
guistics (EACL 2009), Athens, Greece, April.
Patrick Sturt and Vincenzo Lombardo. 2005. Process-
ing coordinated structures: Incrementality and con-
nectedness. Cognitive Science, 29:291?305.
D. Traum and P. Heeman. 1997. Utterance units in
spoken dialogue. In E. Maier, M. Mast, and S. Lu-
perFoy, editors, Dialogue Processing in Spoken Lan-
guage Systems, Lecture Notes in Artificial Intelli-
gence. Springer-Verlag.
Mats Wire?n. 1992. Studies in Incremental Natural
Language Analysis. Ph.D. thesis, Linko?ping Uni-
versity, Linko?ping, Sweden.
S.J. Young, N.H. Russell, and J.H.S. Thornton. 1989.
Token passing: a conceptual model for con-
nected speech recognition systems. Technical re-
port CUED/FINFENG/TR 38, Cambridge Univer-
sity Engineering Department.
718
Proceedings of the 12th Conference of the European Chapter of the ACL, pages 745?753,
Athens, Greece, 30 March ? 3 April 2009. c?2009 Association for Computational Linguistics
Incremental Dialogue Processing in a Micro-Domain 
 
 
 Gabriel Skantze1 
 Dept. of Speech, Music and Hearing 
KTH, Stockholm, Sweden 
gabriel@speech.kth.se 
 David Schlangen 
Department of Linguistics 
University of Potsdam, Germany  
das@ling.uni-potsdam.de  
  
  
 
Abstract 
This paper describes a fully incremental dia-
logue system that can engage in dialogues 
in a simple domain, number dictation. Be-
cause it uses incremental speech recognition 
and prosodic analysis, the system can give 
rapid feedback as the user is speaking, with 
a very short latency of around 200ms.  Be-
cause it uses incremental speech synthesis 
and self-monitoring, the system can react to 
feedback from the user as the system is 
speaking. A comparative evaluation shows 
that na?ve users preferred this system over a 
non-incremental version, and that it was 
perceived as more human-like. 1 
1 Introduction 
A traditional simplifying assumption for spoken 
dialogue systems is that the dialogue proceeds 
with strict turn-taking between user and system. 
The minimal unit of processing in such systems 
is the utterance, which is processed in whole by 
each module of the system before it is handed on 
to the next. When the system is speaking an ut-
terance, it assumes that the user will wait for it to 
end before responding. (Some systems accept 
barge-ins, but then treat the interrupted utterance 
as basically unsaid.) 
Obviously, this is not how natural human-
human dialogue proceeds. Humans understand 
and produce language incrementally ? they use 
multiple knowledge sources to determine when it 
is appropriate to speak, they give and receive 
backchannels in the middle of utterances, they 
start to speak before knowing exactly what to 
say, and they incrementally monitor the listener?s 
reactions to what they say (Clark, 1996).  
                                                          
1
 The work reported in this paper was done while the first 
author was at the University of Potsdam. 
This paper presents a dialogue system, called 
NUMBERS, in which all components operate in-
crementally. We had two aims: First, to explore 
technical questions such as how the components 
of a modularized dialogue system should be ar-
ranged and made to interoperate to support in-
cremental processing, and which requirements 
incremental processing puts on dialogue system 
components (e.g., speech recognition, prosodic 
analysis, parsing, discourse modelling, action 
selection and speech synthesis).  Second, to in-
vestigate whether incremental processing can 
help us to better model certain aspects of human 
behaviour in dialogue systems ? especially turn-
taking and feedback ? and whether this improves 
the user?s experience of using such a system.   
2 Incremental dialogue processing  
All dialogue systems are ?incremental?, in some 
sense ? they proceed in steps through the ex-
change of ?utterances?. However, incremental 
processing typically means more than this; a 
common requirement is that processing starts 
before the input is complete and that the first 
output increments are produced as soon as possi-
ble (e.g., Kilger & Finkler, 1995). Incremental 
modules hence are those where ?Each processing 
component will be triggered into activity by a 
minimal amount of its characteristic input? 
(Levelt, 1989). If we assume that the ?character-
istic input? of a dialogue system is the utterance, 
this principle demands that ?minimal amounts? of 
an utterance already trigger activity. It should be 
noted though, that there is a trade-off between 
responsiveness and output quality, and that an 
incremental process therefore should produce 
output only as soon as it is possible to reach a 
desired output quality criterion.  
2.1 Motivations & related work 
The claim that humans do not understand and 
produce speech in utterance-sized chunks, but 
745
rather incrementally, can be supported by an 
impressive amount of psycholinguistic literature 
on the subject (e.g., Tanenhaus & Brown-
Schmidt, 2008; Levelt, 1989). However, when it 
comes to spoken dialogue systems, the dominant 
minimal unit of processing has been the utter-
ance. Moreover, traditional systems follow a 
very strict sequential processing order of utter-
ances ? interpretation, dialogue management, 
generation ? and there is most often no monitor-
ing of whether (parts of) the generated message 
is successfully delivered.  
Allen et al (2001) discuss some of the short-
comings of these assumptions when modelling 
more conversational human-like dialogue. First, 
they fail to account for the frequently found mid-
utterance reactions and feedback (in the form of 
acknowledgements, repetition of fragments or 
clarification requests). Second, people often 
seem to start to speak before knowing exactly 
what to say next (possibly to grab the turn), thus 
producing the utterance incrementally. Third, 
when a speaker is interrupted or receives feed-
back in the middle of an utterance, he is able to 
continue the utterance from the point where he 
was interrupted.  
Since a non-incremental system needs to proc-
ess the whole user utterance using one module at 
a time, it cannot utilise any higher level informa-
tion for deciding when the user?s turn or utter-
ance is finished, and typically has to rely only on 
silence detection and a time-out. Silence, how-
ever, is not a good indicator: sometimes there is 
silence but no turn-change is intended (e.g., hesi-
tations), sometimes there isn?t silence, but the 
turn changes (Sacks et al, 1974). Speakers ap-
pear to use other knowledge sources, such as 
prosody, syntax and semantics to detect or even 
project the end of the utterance. Attempts have 
been made to incorporate such knowledge 
sources for turn-taking decisions in spoken dia-
logue systems (e.g., Ferrer et al, 2002; Raux & 
Eskenazi, 2008). To do so, incremental dialogue 
processing is clearly needed. 
Incremental processing can also lead to better 
use of resources, since later modules can start to 
work on partial results and do not have to wait 
until earlier modules have completed processing 
the whole utterance. For example, while the 
speech recogniser starts to identify words, the 
parser can already add these to the chart. Later 
modules can also assist in the processing and for 
example resolve ambiguities as they come up. 
Stoness et al (2004) shows how a reference reso-
lution module can help an incremental parser 
with NP suitability judgements. Similarly, Aist et 
al. (2006) shows how a VP advisor could help an 
incremental parser.  
On the output side, an incremental dialogue 
system could monitor what is actually happening 
to the utterance it produces. As discussed by 
Raux & Eskenazi (2007), most dialogue manag-
ers operate asynchronously from the output com-
ponents, which may lead to problems if the 
dialogue manager produces several actions and 
the user responds to one of them. If the input 
components do not have any information about 
the timing of the system output, they cannot re-
late them to the user?s response. This is even 
more problematic if the user reacts (for example 
with a backchannel) in the middle of system 
utterances. The system must then relate the 
user?s response to the parts of its planned output 
it has managed to realise, but also be able to stop 
speaking and possibly continue the interrupted 
utterance appropriately. A solution for handling 
mid-utterance responses from the user is pro-
posed by Dohsaka & Shimazu (1997). For in-
cremental generation and synthesis, the output 
components must also cope with the problem of 
revision (discussed in more detail below), which 
may for example lead to the need for the genera-
tion of speech repairs, as discussed by Kilger & 
Finkler (1995). 
As the survey above shows, a number of stud-
ies have been done on incrementality in different 
areas of language processing. There are, how-
ever, to our knowledge no studies on how the 
various components could or should be inte-
grated into a complete, fully incremental dia-
logue system, and how such a system might be 
perceived by na?ve users, compared to a non-
incremental system. This we provide here. 
2.2 A general, abstract model 
The NUMBERS system presented in this paper can 
be seen as a specific instance (with some simpli-
fying assumptions) of a more general, abstract 
model that we have developed (Schlangen & 
Skantze, 2009). We will here only briefly de-
scribe the parts of the general model that are 
relevant for the exposition of our system. 
We model the dialogue processing system as a 
collection of connected processing modules. The 
smallest unit of information that is communi-
cated along the connections is called the incre-
mental unit (IU), the unit of the ?minimal 
amount of characteristic input?. Depending on 
what the module does, IUs may be audio frames, 
words, syntactic phrases, communicative acts, 
746
etc. The processing module itself is modelled as 
consisting of a Left Buffer (LB), the Processor 
proper, and a Right Buffer (RB). An example of 
two connected modules is shown in Figure 1. As 
IU1 enters the LB of module A, it may be con-
sumed by the processor. The processor may then 
produce new IUs, which are posted on the RB 
(IU2 in the example). As the example shows, the 
modules in the system are connected so that an 
IU posted on the RB in one module may be con-
sumed in the LB of another module. One RB 
may of course be connected to many other LB?s, 
and vice versa, allowing a range of different 
network topologies.    
 
 
Figure 1: Two connected modules. 
 
In the NUMBERS system, information is only 
allowed to flow from left to right, which means 
that the LB may be regarded as the input buffer 
and the RB as the output buffer. However, in the 
general model, information may flow in both 
directions.  
A more concrete example is shown in Figure 
2, which illustrates a module that does incre-
mental speech recognition. The IUs consumed 
from the LB are audio frames, and the IUs posted 
in the RB are the words that are recognised.  
 
 
Figure 2: Speech recognition as an example of incre-
mental processing. 
 
We identify three different generic module 
operations on IUs: update, purge and commit. 
First, as an IU is added to the LB, the processor 
needs to update its internal state. In the example 
above, the speech recogniser has to continuously 
add incoming audio frames to its internal state, 
and as soon as the recogniser receives enough 
audio frames to decide that the word ?four? is a 
good-enough candidate, the IU holding this word 
will be put on the RB (time-point t1). If a proces-
sor only expects IUs that extend the rightmost IU 
currently produced, we can follow Wir?n (1992) 
in saying that it is only left-to-right incremental.  
A fully incremental system (which we aim at 
here), on the other hand, also allows insertions 
and/or revisions.  
An example of revision is illustrated at time-
point t2 in Figure 2.  As more audio frames are 
consumed by the recogniser, the word ?four? is 
no longer the best candidate for this stretch of 
audio. Thus, the module must now revoke the IU 
holding the word ?four? (marked with a dotted 
outline) and add a new IU for the word ?forty?. 
All other modules consuming these IUs must 
now purge them from their own states and pos-
sibly revoke other IUs. By allowing revision, a 
module may produce tentative results and thus 
make the system more responsive. 
As more audio frames are consumed in the ex-
ample above, a new word ?five? is identified and 
added to the RB (time-point t3). At time-point t4, 
no more words are identified, and the module 
may decide to commit to the IUs that it has pro-
duced (marked with a darker shade). A commit-
ted IU is guaranteed to not being revoked later, 
and can hence potentially be removed from the 
processing window of later modules, freeing up 
resources. 
3 Number dictation: a micro-domain 
Building a fully incremental system with a be-
haviour more closely resembling that of human 
dialogue participants raises a series of new chal-
lenges. Therefore, in order to make the task more 
feasible, we have chosen a very limited domain ? 
what might be called a micro-domain (cf. Edlund 
et al, 2008): the dictation of number sequences. 
In this scenario, the user dictates a sequence of 
numbers (such as a telephone number or a credit 
card number) to the dialogue system. This is a 
very common situation in commercial telephone-
based dialogue systems, which however operate 
in a non-incremental manner: The user is first 
asked to read out the whole number sequence, 
which the system then confirms. Should the rec-
ognition be incorrect, the user has to repeat the 
whole sequence again. In an incremental version 
of this scenario, the system might give continu-
ous feedback (such as acknowledgements and 
clarification requests) as the user is reading the 
forty five 
forty five 
four t1
forty
 
four
 
forty 
forty five 
forty five 
t2
t3
t4
time left buffer processor right buffer 
four
 
IU2 
left buffer 
processor right buffer 
right buffer processor 
left buffer 
IU1 IU1 IU2 
IU3 IU2 
IU3 
module A 
module B
747
sequence. When the system repeats the sequence, 
the user is also given the opportunity to give 
feedback and make corrections at any time. Ob-
viously, such a dialogue will result in many more 
speaker-shifts, which in turn increases the need 
for the rapid turn-taking. Thus, while the number 
dictation task might appear simple at a first 
glance (very limited vocabulary, simple syntax 
and semantics), there are several issues ? not 
typically considered in most dialogue systems ? 
which an incremental and more human-like dia-
logue system must address. 
To explore dialogue phenomena in this do-
main, we gave 8 pairs of subjects the task of 
dictating number sequences to each other. The 
subjects were sitting in different rooms and used 
headsets to communicate. To induce more feed-
back behaviour, noise was randomly inserted in 
the utterances from the information giver (as in 
the setting used by Schlangen & Fern?ndez 
(2007)). The subjects were all speaking German 
(their native tongue). The recorded dialogues 
were then transcribed and annotated. The ob-
served dialogue strategies directly influenced the 
design of our system (see below). Table 1 shows 
an example of a dialogue between a user and the 
system and illustrates some of the phenomena we 
intended to model. 
 
U.01 two five three - 
S.02 okay 
U.03 one forty, five - 
S.04 sorry, do you mean one and then forty and 
then five? 
U.05 no, one forty five 
S.06 okay, one forty five 
U.07 yeah, and six eight four - 
S.08 okay 
U.09 seven twelve nine. 
S.10 so, from the start, two five three - 
U.11 yeah 
S.12 one forty five - 
S.13 six six four - 
U.14 no, six eight four 
S.15 okay, six eight four - 
S.16 and then seven twelve nine. 
U.17 that?s right 
Table 1: An example dialogue between a user and 
the NUMBERS system. 
 
Just like in this example, a common strategy 
for the subjects was to first let the information 
giver read the number sequence and then switch 
roles and let the information follower repeat it. 
Instead of reading out the whole number se-
quence at once, subjects tended to package 
pieces of information into what Clark (1996) 
refers to as installments (in this case small 
groups of numbers). After each installment, the 
other speaker may react by giving an acknowl-
edgement (as in S.02) a clarification request (as 
in S.04), a correction (as in U.14), or do nothing 
(as after S.12).  
As there are a lot of speaker shifts, there needs 
to be a mechanism for rapid turn taking. In the 
example above, the system must recognize that 
the last digit in U.01, U.03, U.05 and U.07 ends 
an installment and calls for a reaction, while the 
last digit in U.09 ends the whole sequence. One 
information source that has been observed to be 
useful for this is prosody (Koiso et al, 1998). 
When analysing the recorded dialogues, it 
seemed like mid-sequence installments most 
often ended with a prolonged duration and a 
rising pitch, while end-sequence installments 
most often ended with a shorter duration and a 
falling pitch. How prosody is used by the 
NUMBERS system for this classification is de-
scribed in section 4.2.  
4 The NUMBERS system components 
The NUMBERS system has been implemented 
using the HIGGINS spoken dialogue system 
framework (Skantze, 2007). All modules have 
been adapted and extended to allow incremental 
processing. It took us roughly 6 months to im-
plement the changes described here to a fully 
working baseline system. Figure 3 shows the 
architecture of the system2.  
 
  
Figure 3: The system architecture.  
CA = communicative act. 
 
This is pretty much a standard dialogue system 
layout, with some exceptions that will be dis-
cussed below. Most notably perhaps is that dia-
logue management is divided into a discourse 
modelling module and an action manager. As can 
                                                          
2
 A video showing an example run of the system has been 
uploaded to 
http://www.youtube.com/watch?v=_rDkb1K1si8 
Action  
Manager 
Discourse 
modeller 
ASR 
Semantic 
parser 
TTS Audio 
CAs 
Audio 
CAs + 
Words 
 
Words + 
Prosody
CAs + 
Entities 
CAs + 
Words 
748
be seen in the figure, the discourse modeller also 
receives information about what the system itself 
says. The modules run asynchronously in sepa-
rate processes and communicate by sending 
XML messages containing the IUs over sockets.  
We will now characterize each system module 
by what kind of IUs they consume and produce, 
as well as the criteria for committing to an IU.  
4.1 Speech recognition  
The automatic speech recognition module (ASR) 
is based on the Sphinx 4 system (Lamere et al, 
2003). The Sphinx system is capable of incre-
mental processing, but we have added support 
for producing incremental results that are com-
patible with the HIGGINS framework. We have 
also added prosodic analysis to the system, as 
described in 4.2. For the NUMBERS domain, we 
use a very limited context-free grammar accept-
ing number words as well as some expressions 
for feedback and meta-communication.  
An illustration of the module buffers is shown 
in Figure 2 above. The module consumes audio 
frames (each 100 msec) from the LB and pro-
duces words with prosodic features in the RB. 
The RB is updated every time the sequence of 
top word hypotheses in the processing windows 
changes. After 2 seconds of silence has been 
detected, the words produced so far are commit-
ted and the speech recognition search space is 
cleared. Note that this does not mean that other 
components have to wait for this amount of si-
lence to pass before starting to process or that the 
system cannot respond until then ? incremental 
results are produced as soon as the ASR deter-
mines that a word has ended.  
4.2 Prosodic analysis 
We implemented a simple form of prosodic 
analysis as a data processor in the Sphinx fron-
tend. Incremental F0-extraction is done by first 
finding pitch candidates (on the semitone scale) 
for each audio frame using the SMDSF algo-
rithm (Liu et al, 2005). An optimal path between 
the candidates is searched for, using dynamic 
programming (maximising candidate confidence 
scores and minimising F0 shifts). After this, me-
dian smoothing is applied, using a window of 5 
audio frames.  
In order for this sequence of F0 values to be 
useful, it needs to be parameterized. To find out 
whether pitch and duration could be used for the 
distinction between mid-sequence installments 
and end-sequence installments, we did a machine 
learning experiment on the installment-ending 
digits in our collected data. There were roughly 
an equal amount of both types, giving a majority 
class baseline of 50.9%. 
As features we calculated a delta pitch pa-
rameter for each word by computing the sum of 
all F0 shifts (negative or positive) in the pitch 
sequence. (Shifts larger than a certain threshold 
(100 cents) were excluded from the summariza-
tion, in order to sort out artefacts.) A duration 
parameter was derived by calculating the sum of 
the phoneme lengths in the word, divided by the 
sum of the average lengths of these phonemes in 
the whole data set. Both of these parameters 
were tested as predictors separately and in com-
bination, using the Weka Data Mining Software 
(Witten & Frank, 2005). The best results were 
obtained with a J.48 decision tree, and are shown 
in Table 2. 
 
Baseline 50.9% 
Pitch 81.2% 
Duration 62.4% 
Duration + Pitch 80.8% 
Table 2: The results of the installment classifica-
tion (accuracy). 
 
 As the table shows, the best predictor was 
simply to compare the delta pitch parameter 
against an optimal threshold. While the perform-
ance of 80.8% is significantly above baseline, it 
could certainly be better. We do not know yet 
whether the sub-optimal performance is due to 
the fact that the speakers did not always use 
these prosodic cues, or whether there is room for 
improvement in the pitch extraction and parame-
terization. 
Every time the RB of the ASR is updated, the 
delta pitch parameter is computed for each word 
and the derived threshold is used to determine a 
pitch slope class (rising/falling) for the word. 
(Note that there is no class for a flat pitch. This 
class is not really needed here, since the digits 
within installments are followed by no or only 
very short pauses.) The strategy followed by the 
system then is this: when a digit with a rising 
pitch is detected, the system plans to immedi-
ately give a mid-sequence reaction utterance, and 
does so if indeed no more words are received. If 
a digit with a falling pitch is detected, the system 
plans an end-of-sequence utterance, but waits a 
little bit longer before producing it, to see if there 
really are no more words coming in. In other 
words, the system bases its turn-taking decisions 
on a combination of ASR, prosody and silence-
thresholds, where the length of the threshold 
749
differs for different prosodic signals, and where 
reactions are planned already during the silence. 
(This is in contrast to Raux & Eskenazi (2008), 
where context-dependent thresholds are used as 
well, but only simple end-pointing is performed.) 
The use of prosodic analysis in combination 
with incremental processing allows the 
NUMBERS system to give feedback after mid-
sequence installments in about 200 ms. This 
should be compared with most dialogue systems 
which first use a silence threshold of about 750-
1500 msec, after which each module must proc-
ess the utterance. 
4.3 Semantic parsing 
For semantic parsing, the incremental processing 
in the HIGGINS module PICKERING (Skantze & 
Edlund, 2004) has been extended. PICKERING is 
based on a modified chart parser which adds 
automatic relaxations to the CFG rules for ro-
bustness, and produces semantic interpretations 
in the form of concept trees. It can also use fea-
tures that are attached to incoming words, such 
as prosody and timestamps. For example, the 
number groups in U.03 and U.05 in Table 1 ren-
der different parses due to the pause lengths be-
tween the words. 
The task of PICKERING in the NUMBERS do-
main is very limited. Essentially, it identifies 
communicative acts (CAs), such as number in-
stallments. The only slightly more complex pars-
ing is that of larger numbers such as ?twenty 
four?. There are also cases of ?syntactic ambigu-
ity?, as illustrated in U.03 in the dialogue exam-
ple above ("forty five" as "45" or "40 5"). In the 
NUMBERS system, only 1-best hypotheses are 
communicated between the modules, but 
PICKERING can still assign a lower parsing confi-
dence score to an ambiguous interpretation, 
which triggers a clarification request in S.04. 
Figure 4 show a very simple example of the 
incremental processing in PICKERING. The LB 
contains words with prosodic features produced 
by the ASR (compare with Figure 2 above). The 
RB consists of the CAs that are identified. Each 
time a word is added to the chart, PICKERING 
continues to build the chart and then searches for 
an optimal sequence of CAs in the chart, allow-
ing non-matching words in between. To handle 
revision, a copy of the chart is saved after each 
word has been added. 
 
 
Figure 4: Incremental parsing. There is a jump in time 
between t4 and t5. 
 
As can be seen at time-point t4, even if all 
words that a CA is based on are committed, the 
parser does not automatically commit the CA. 
This is because later words may still cause a 
revision of the complex output IU that has been 
built. As a heuristic, PICKERING instead waits 
until a CA is followed by three words that are not 
part of it until it commits, as shown at time-point 
t5. After a CA has been committed, the words 
involved may be cleared from the chart. This 
way, PICKERING parses a ?moving window? of 
words.  
4.4 Discourse modelling 
For discourse modelling, the HIGGINS module 
GALATEA (Skantze, 2008) has been extended to 
operate incrementally. The task of GALATEA is 
to interpret utterances in their context by trans-
forming ellipses into full propositions, indentify 
discourse entities, resolve anaphora and keep 
track of the grounding status of concepts (their 
confidence score and when they have been 
grounded in the discourse). As can be seen in 
Figure 3, GALATEA models both utterances from 
the user as well as the system. This makes it 
possible for the system to monitor its own utter-
ances and relate them to the user?s utterances, by 
using timestamps produced by the ASR and the 
speech synthesiser. 
In the LB GALATEA consumes CAs from both 
the user (partially committed, as seen in Figure 
4) and the system (always committed, see 4.6). 
In the RB GALATEA produces an incremental 
discourse model. This model contains a list of 
resolved communicative acts and list of resolved 
discourse entities. This model is then consulted 
by an action manager which decides what the 
system should do next. The discourse model is 
40 
forty 
forty five 
forty five 
forty 
forty five 
forty five 
40 
45 
45 
40 
45 
45 
three 62 3 45 
forty five sixty two three 
62 3 45 
t1
t2
t3
t4
time
four
 
four
 
4
 
4
 
t5
left buffer processor right buffer 
4
 
four
 
750
committed up to the point of the earliest non-
committed incoming CA. In the NUMBERS do-
main, the discourse entities are the number in-
stallments.  
4.5 Action management  
Based on the discourse model (from the LB), the 
action manager (AM) generates system actions 
(CAs) in semantic form (for GALATEA) with an 
attached surface form (for the TTS), and puts 
them on the RB. (In future extensions of the sys-
tem, we will add an additional generation module 
that generates the surface form from the semantic 
form.) In the NUMBERS system, possible system 
actions are acknowledgements, clarification re-
quests and repetitions of the number sequence. 
The choice of actions to perform is based on the 
grounding status of the concepts (which is repre-
sented in the discourse model). For example, if 
the system has already clarified the first part of 
the number sequence due to an ambiguity, it does 
not need to repeat this part of the sequence again. 
The AM also attaches a desired timing to the 
produced CA, relative to the end time of last user 
utterance. For example, if a number group with a 
final rising pitch is detected, the AM may tell the 
TTS to execute the CA immediately after the 
user has stopped speaking. If there is a falling 
pitch, it may tell the TTS to wait until 500 msec 
of silence has been detected from the user before 
executing the action. If the discourse model gets 
updated during this time, the AM may revoke 
previous CAs and replace them with new ones.  
4.6 Speech synthesis 
A diphone MBROLA text-to-speech synthesiser 
(TTS) is used in the system (Dutoit et al, 1996), 
and a wrapper for handling incremental process-
ing has been implemented. The TTS consumes 
words linked to CAs from the LB, as produced 
by the AM. As described above, each CA has a 
timestamp. The TTS places them on a queue, and 
prepares to synthesise and start sending the audio 
to the speakers. When the system utterance has 
been played, the corresponding semantic con-
cepts for the CA are sent to GALATEA. If the 
TTS is interrupted, the semantic fragments of the 
CA that corresponds to the words that were spo-
ken are sent. This way, GALATEA can monitor 
what the system actually says and provide the 
AM with this information. Since the TTS only 
sends (parts of) the CAs that have actually been 
spoken, these are always marked as committed.  
There is a direct link from the ASR to the TTS 
as well (not shown in Figure 3), informing the 
TTS of start-of-speech and end-of-speech events. 
As soon as a start-of-speech event is detected, 
the TTS stops speaking. If the TTS does not re-
ceive any new CAs from the AM as a conse-
quence of what the user said, it automatically 
resumes from the point of interruption. (This 
implements a "reactive behaviour" in the sense of 
(Brooks, 1991), which is outside of the control of 
the AM.)   
An example of this is shown in Table 1. After 
U.09, the AM decides to repeat the whole num-
ber sequence and sends a series of CAs to the 
TTS for doing this. After S.10, the user gives 
feedback in the form of an acknowledgement 
(U.11). This causes the TTS to make a pause. 
When GALATEA receives the user feedback, it 
uses the time-stamps to find out that the feedback 
is related to the number group in S.10 and the 
grounding status for this group is boosted. When 
the AM receives the updated discourse model, it 
decides that this does not call for any revision to 
the already planned series of actions. Since the 
TTS does not receive any revisions, it resumes 
the repetition of the number sequence in S.12. 
The TTS module is fully incremental in that it 
can stop and resume speaking in the middle of an 
utterance, revise planned output, and can inform 
other components of what (parts of utterances) 
has been spoken. However, the actual text-to-
speech processing is done before the utterance 
starts and not yet incrementally as the utterance 
is spoken, which could further improve the effi-
ciency of the system. This is a topic for future 
research, together with the generation of hidden 
and overt repair as discussed by Kilger & Finkler 
(1995).  
5 Evaluation  
It is difficult to evaluate complete dialogue sys-
tems such as the one presented here, since there 
are so many different components involved (but 
see M?ller et al (2007) for methods used). In our 
case, we?re interested in the benefits of a specific 
aspect, though, namely incrementality. No 
evaluation is needed to confirm that an incre-
mental system such as this allows more flexible 
turn-taking and that it can potentially respond 
faster ? this is so by design. However, we also 
want this behaviour to result in an improved user 
experience. To test whether we have achieved 
this, we implemented for comparison a non-
incremental version of the system, very much 
like a standard number dictation dialogue in a 
commercial application. In this version, the user 
751
is asked to read out the whole number sequence 
in one go. After a certain amount of silence, the 
system confirms the whole sequence and asks a 
yes/no question whether it was correct. If not, the 
user has to repeat the whole sequence.  
Eight subjects were given the task of using the 
two versions of the system to dictate number 
sequences (in English) to the system. (The sub-
jects were native speakers of German with a 
good command of English.) Half of the subjects 
used the incremental version first and the other 
half started with the non-incremental version. 
They were asked to dictate eight number se-
quences to each version, resulting in 128 dia-
logues. For each sequence, they were given a 
time limit of 1 minute. After each sequence, they 
were asked whether they had succeeded in dictat-
ing the sequence or not, as well as to mark their 
agreement (on a scale from 0-6) with statements 
concerning how well they had been understood 
by the system, how responsive the system was, if 
the system behaved as expected, and how hu-
man-like the conversational partner was. After 
using both versions of the system, they were also 
asked whether they preferred one of the versions 
and to what extent (1 or 2 points, which gives a 
maximum score of 16 to any version, when total-
ling all subjects).  
There was no significant difference between 
the two versions with regard to how many of the 
tasks were completed successfully. However, the 
incremental version was clearly preferred in the 
overall judgement (9 points versus 1). Only one 
of the more specific questions yielded any sig-
nificant difference between the versions: the 
incremental version was judged to be more hu-
man-like for the successful dialogues (5,2 on 
average vs. 4,5; Wilcoxon signed rank test; 
p<0.05).  
The results from the evaluation are in line with 
what could be expected. A non-incremental sys-
tem can be very efficient if the system under-
stands the number sequence the first time, and 
the ASR vocabulary is in this case very limited, 
which explains why the success-rate was the 
same for both systems. However, the incremental 
version was experienced as more pleasant and 
human-like. One explanation for the better rating 
of the incremental version is that the acknowl-
edgements encouraged the subjects to package 
the digits into installments, which helped the 
system to better read back the sequence using the 
same installments. 
6 Conclusions and future work 
To sum up, we have presented a dialogue system 
that through the use of novel techniques (incre-
mental prosodic analysis, reactive connection 
between ASR and TTS, fully incremental archi-
tecture) achieves an unprecedented level of reac-
tiveness (from a minimum latency of 750ms, as 
typically used in dialogue systems, down to one 
of 200ms), and is consequently evaluated as 
more natural than more typical setups by human 
users. While the domain we've used is relatively 
simple, there are no principled reasons why the 
techniques introduced here should not scale up. 
In future user studies, we will explore which 
factors contribute to the improved experience of 
using an incremental system. Such factors may 
include improved responsiveness, better install-
ment packaging, and more elaborate feedback. It 
would also be interesting to find out when rapid 
responses are more important (e.g. acknowl-
edgements), and when they may be less impor-
tant (e.g., answers to task-related questions). 
We are currently investigating the transfer of 
the prosodic analysis to utterances in a larger 
domain, where similarly instructions by the user 
can be given in installments. But even within the 
currently used micro-domain, there are interest-
ing issues still to be explored. In future versions 
of the system, we will let the modules pass paral-
lel hypotheses and also improve the incremental 
generation and synthesis. Since the vocabulary is 
very limited, it would also be possible to use a 
limited domain synthesis (Black & Lenzo, 2000), 
and explore how the nuances of different back-
channels might affect the dialogue. Another chal-
lenge that can be researched within this micro-
domain is how to use the prosodic analysis for 
other tasks, such as distinguishing correction 
from dictation (for example if U.14 in Table 1 
would not begin with a ?no?). In general, we 
think that this paper shows that narrowing down 
the domain while shifting the focus to the model-
ling of more low-level, conversational dialogue 
phenomena is a fruitful path. 
Acknowledgements 
This work was funded by a DFG grant in the 
Emmy Noether programme. We would also like 
to thank Timo Baumann and Michaela Atterer 
for their contributions to the project, as well as 
Anna Iwanow and Angelika Adam for collecting 
and transcribing the data used in this paper. 
752
References  
Aist, G., Allen, J. F., Campana, E., Galescu, L., 
G?mez Gallo, C. A., Stoness, S. C., Swift, M., & 
Tanenhaus, M. (2006). Software Architectures for 
Incremental Understanding of Human Speech. In 
Proceedings of Interspeech (pp. 1922-1925). Pitts-
burgh PA, USA. 
Allen, J. F., Ferguson, G., & Stent, A. (2001). An 
architecture for more realistic conversational sys-
tems. In Proceedings of the 6th international con-
ference on Intelligent user interfaces (pp. 1-8).  
Black, A., & Lenzo, K. (2000). Limited domain syn-
thesis. In Proceedings of ICSLP (pp. 410-415). 
Beijing, China. 
Brooks, R. A. (1991). Intelligence without representa-
tion. Artificial Intelligence, 47, 139-159. 
Clark, H. H. (1996). Using language. Cambridge, 
UK: Cambridge University Press. 
Dohsaka, K., & Shimazu, A. (1997). System architec-
ture for spoken utterance production in collabora-
tive dialogue. In Working Notes of IJCAI 1997 
Workshop on Collaboration, Cooperation and 
Conflict in Dialogue Systems.  
Dutoit, T., Pagel, V., Pierret, N., Bataille, F., & Vre-
ken, O. v. d. (1996). The MBROLA project: To-
wards a set of high-quality speech synthesizers free 
of use for non-commercial purposes. In Proceed-
ings of ICSLIP '96 (pp. 1393-1396).  
Edlund, J., Gustafson, J., Heldner, M., & Hjalmars-
son, A. (2008). Towards human-like spoken dialo-
gue systems. Speech Communication, 50(8-9), 630-
645. 
Ferrer, L., Shriberg, E., & Stolcke, A. (2002). Is the 
speaker done yet? Faster and more accurate end-of 
utterance detection using prosody. In Proceedings 
of ICSLP (pp. 2061-2064).  
Kilger, A., & Finkler, W. (1995). Incremental Gener-
ation for Real-Time Applications. Technical Report 
RR-95-11, German Research Center for Artificial 
Intelligence. 
Koiso, H., Horiuchi, Y., Tutiya, S., Ichikawa, A., & 
Den, Y. (1998). An analysis of turn-taking and 
backchannels based on prosodic and syntactic fea-
tures in Japanese Map Task dialogs. Language and 
Speech, 41, 295-321. 
Lamere, P., Kwok, P., Gouvea, E., Raj, B., Singh, R., 
Walker, W., Warmuth, M., & Wolf, P. (2003). The 
CMU SPHINX-4 speech recognition system.. In 
Proceedings of the IEEE Intl. Conf. on Acoustics, 
Speech and Signal Processing. Hong Kong. 
Levelt, W. J. M. (1989). Speaking: From Intention to 
Articulation. Cambridge, Mass., USA: MIT Press. 
Liu, J., Zheng, T. F., Deng, J., & Wu, W. (2005). 
Real-time pitch tracking based on combined 
SMDSF. In Proceedings of Interspeech (pp. 301-
304). Lisbon, Portugal. 
M?ller, S., Smeele, P., Boland, H., & Krebber, J. 
(2007). Evaluating spoken dialogue systems ac-
cording to de-facto standards: A case study. Com-
puter Speech & Language, 21(1), 26-53. 
Raux, A., & Eskenazi, M. (2007). A multi-Layer 
architecture for semi-synchronous event-driven di-
alogue Management. In ASRU 2007. Kyoto, Ja-
pan.. 
Raux, A., & Eskenazi, M. (2008). Optimizing end-
pointing thresholds using dialogue features in a 
spoken dialogue system. In Proceedings of SIGdial 
2008. Columbus, OH, USA. 
Sacks, H., Schwegloff, E., & Jefferson, G. (1974). A 
simplest systematics for the organization of turn-
taking for conversation. Language, 50, 696-735. 
Schlangen, D., & Fern?ndez, R. (2007). Speaking 
through a noisy channel: experiments on inducing 
clarification behaviour in human-human dialogue. 
In Proceedings of Interspeech 2007. Antwerp, Bel-
gium. 
Schlangen, D., & Skantze, G. (2009). A general, ab-
stract model of incremental dialogue processing. In 
Proceedings of the 12th Conference of the Euro-
pean Chapter of the Association for Computational 
Linguistics (EACL-09). Athens, Greece. 
Skantze, G., & Edlund, J. (2004). Robust interpreta-
tion in the Higgins spoken dialogue system. In 
Proceedings of ISCA Tutorial and Research Work-
shop (ITRW) on Robustness Issues in Conversa-
tional Interaction. Norwich, UK. 
Skantze, G. (2007). Error Handling in Spoken Dialo-
gue Systems - Managing Uncertainty, Grounding 
and Miscommunication. Doctoral dissertation, 
KTH, Department of Speech, Music and Hearing. 
Skantze, G. (2008). Galatea: A discourse modeller 
supporting concept-level error handling in spoken 
dialogue systems. In Dybkj?r, L., & Minker, W. 
(Eds.), Recent Trends in Discourse and Dialogue. 
Springer. 
Stoness, S. C., Tetreault, J., & Allen, J. (2004). In-
cremental parsing with reference interaction. In 
Proceedings of the ACL Workshop on Incremental 
Parsing (pp. 18-25).  
Tanenhaus, M. K., & Brown-Schmidt, S. (2008). 
Language processing in the natural world. In 
Moore, B. C. M., Tyler, L. K., & Marslen-Wilson, 
W. D. (Eds.), The perception of speech: from 
sound to meaning (pp. 1105-1122).  
Wir?n, M. (1992). Studies in Incremental Natural 
Language Analysis. Doctoral dissertation, 
Link?ping University, Link?ping, Sweden. 
Witten, I. H., & Frank, E. (2005). Data Mining: Prac-
tical machine learning tools and techniques. San 
Francisco: Morgan Kaufmann. 
 
753
Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 380?388,
Boulder, Colorado, June 2009. c?2009 Association for Computational Linguistics
Assessing and Improving the Performance of
Speech Recognition for Incremental Systems
Timo Baumann, Michaela Atterer, David Schlangen
Institut fu?r Linguistik
Universita?t Potsdam
Potsdam, Germany
{timo,atterer,das}@ling.uni-potsdam.de
Abstract
In incremental spoken dialogue systems, par-
tial hypotheses about what was said are re-
quired even while the utterance is still ongo-
ing. We define measures for evaluating the
quality of incremental ASR components with
respect to the relative correctness of the par-
tial hypotheses compared to hypotheses that
can optimize over the complete input, the tim-
ing of hypothesis formation relative to the por-
tion of the input they are about, and hypothesis
stability, defined as the number of times they
are revised. We show that simple incremen-
tal post-processing can improve stability dra-
matically, at the cost of timeliness (from 90%
of edits of hypotheses being spurious down to
10% at a lag of 320ms). The measures are
not independent, and we show how system de-
signers can find a desired operating point for
their ASR. To our knowledge, we are the first
to suggest and examine a variety of measures
for assessing incremental ASR and improve
performance on this basis.
1 Introduction
Incrementality, that is, the property of beginning to
process input before it is complete, is often seen as a
desirable property of dialogue systems (e.g., Allen
et al (2001)), as it allows the system to (a) fold
processing time (of modules such as parsers, or di-
alogue managers) into the time taken by the utter-
ance, and (b) react to partial results, for example by
generating back-channel utterances or speculatively
initiating potentially relevant database queries.
Input to a spoken dialogue system normally
passes an automatic speech recognizer (ASR) as a
first processing module, thus the module?s incre-
mentality determines the level of incrementality that
can be reached by the system as a whole. Using
an ASR system incrementally poses interesting chal-
lenges, however. Typically, ASRs use dynamic pro-
gramming and the maximum likelihood hypothesis
to find the word sequence with the lowest expected
likelihood of the sequence containing errors (sen-
tence error). Due to the dynamic programming ap-
proach, what is considered the best hypothesis about
a given stretch of the input signal can change during
the recognition process, as more right context which
can be used as evidence becomes available.
In this paper, we argue that normally used met-
rics for ASR evaluation such as word error rate must
be complemented with metrics specifically designed
for measuring incremental performance, and offer
some such metrics. We show that there are various
subproperties that are not independent of each other,
and that trade-offs are involved if either of those is
to be optimized. Finally, we propose ways to im-
prove incremental performance (as measured by our
metrics) through the use of smoothing techniques.
To our knowledge, incremental evaluation met-
rics of ASR for incremental systems have not yet
been covered in the literature. Most closely related,
Wachsmuth et al (1998) show results for an ASR
which fixes its results after a given time ? and re-
port the corresponding word error rate (WER). This
unfortunately confounds the incremental and non-
incremental properties of their ASR?s performance.
The remainder of this paper is structured as fol-
lows: In section 2, we give an overview of increme-
nality with respect to ASR, and develop our evalua-
380
tion metrics. Section 3 describes the setup and data
that we used in our experiments, and reports and dis-
cusses some basic measures for different variants of
the setup. In section 4 we propose and discuss two
orthogonal methods that improve incremental per-
formance: using right context and using message
smoothing, which show different properties with re-
gard to our measures. Finally, in section 5 we sum
up and point to future directions.
2 Incrementality and Evaluation Measures
for Incremental ASR
In a modular system, an incremental module is one
that generates (partial) responses while input is still
ongoing and makes these available to other mod-
ules (Kilger and Finkler, 1995). ASR modules that
use token passing (Young et al, 1989) can easily
be adapted to output a new, live hypothesis after
processing of every input frame (often that is ev-
ery 10ms). In an incremental system we are able
to get partial results from these hypotheses as soon
as they become available ? or rather as soon as they
can be trusted. As mentioned above, hypotheses are
only tentative, and may be revised when more right
context becomes available. Modules consuming the
output of an incremental ASR hence must be able
to deal with such revisions. There is a first trade-off
here: Depending on how costly revision is for later
modules (which after all may need to revise any hy-
potheses which they themselves based on the now-
revised input), it may be better to reduce the incre-
mentality a bit ? in the sense that partial informa-
tion is produced less often, and hence new words for
example are recognised later ? if that buys stability
(fewer revisions). Also, ignoring some incremen-
tal results that are likely to be wrong may increase
system performance. Defining these notions more
precisely is the aim of this section.
2.1 Relative Correctness
We define a hypothesis at time t (hypt) as consist-
ing of a sequence whypt of words predicted by the
ASR at time t.1 As an example figure 1 shows
1In this paper, we only deal with one-best ASR. We believe
that there are no principled differences when generalising to n-
best hypotheses, but will explore this in detail in future work.
We also abstract away from changes in the hypothesised start
and end times of the words in the sequence. It often happens that
Figure 1: Live ASR hypotheses during incremental
recognition. Edit messages (see section 2.2) are shown
on the right when words are added (?) or revoked (?).
For the word ?zwei? WFC and WFF (see section 2.3) are
shown at the bottom.
a sequence of incrementally produced hypotheses.
(Note that this is an artificial example, showing only
a few illustratory and interesting hypotheses. In a
real recognition system, the hypothesis frequency is
of course much higher, with much repetition of sim-
ilar hypotheses at consecutive frames.)
The question now is how we can evaluate the
quality of a hypothesis at the time t it is produced.
It is reasonable to only expect this hypothesis to say
something (correct or not) about the input up to time
t ? unless we want the ASR to predict, in which case
we want it to make assumptions about times beyond
t (see section 4.1). There are two candidates for the
yardstick against which the partial hypotheses could
be compared: First, one could take the actually spo-
ken words, computing measures such as word error
rate. The other option, which is the one taken here,
is to take as the gold standard the final hypothesis
produced by the ASR when it has all evidence avail-
the ASR?s assumptions about the position of the word bound-
aries change, even if the word sequence stays constant. If, as we
assume here, later modules do not use this timing information,
we can consider two hypotheses that only differ in boundary
placement as identical.
381
able (i.e., when the utterance is complete). This is
more meaningful for our purpose, as it relates the in-
formativity of the partial hypothesis to what can be
expected if the ASR can do all its internal optimisa-
tions, and not to the factually correct sequence that
the ASR might not be able to recognise even with
all information present. This latter problem is al-
ready captured in the conventional non-incremental
performance measures.
In our metrics in this paper, we hence take as gold
standard (wgold) the final, non-incremental hypothe-
sis of the ASR (which, to reiterate this point, might
be factually incorrect, that is, might contain word
errors). We define a module?s incremental response
at time t (whypt) as relatively correct (r-correct), iff
it is equal to the non-incremental hypothesis up to
time t: whypt t = wgoldt. Hence, in figure 1 above,
hypotheses 1, 2, 6, 7, 9 and 12 are r-correct.2 We
call the normalised rate of r-correct responses of a
module its (average) r-correctness.
As defined above, the criterion for r-correctness
is still pretty strict, as it demands of the ASR that
words on the right edge are recognised even from
the first frame on. For example, whyp10 in figure 1
is not r-correct, because wgold10 (that part of wgold
that ends where whyp10 ends) already spans parts of
the word ?drei? which has not yet been picked up
by the incremental recognition. A relaxed notion
of correctness hence is prefix-correctness, which re-
quires only that whypt be a prefix of wgoldt. (Hy-
potheses 3 and 10 in figure 1 are p-correct, as are all
r-correct hypotheses.) It should be noted though that
p-correctness is too forgiving to be used directly as
an optimization target: in the example in figure 1,
a module that only ever produces empty hypotheses
would trivally achieve perfect p-correctness (as this
is always a prefix of wgold).
2.2 Edit Overhead
The measures defined so far capture only static as-
pects of the incremental performance of a module
and do not say anything about the dynamics of the
recognition process. To capture this, we look at
the changes between subsequent partial hypotheses.
There are three ways in which an hypothesis hypt+1
2The timing in hypothesis 7 is not correct ? but this does not
matter to our notion of correctness (see footnote 1).
can be different from hypt: there can be an extension
of the word sequence, a revokation, or a revision of
the last words in the sequence.3 These differences
can be expressed as edit messages, where extending
a sequence by one word would require an add mes-
sage (?), deleting the last word in the sequence a
revoke message (?), and exchange of the last word
would require two messages, one to revoke the old
and one to add the new word.4
Now, an incrementally perfect ASR would only
generate extensions, adding new words at the right
edge; thus, there would be exactly as many edit mes-
sages as there are words in wgold. In reality, there
are typically many more changes, and hence many
spurious edits (see below for characteristic rates in
our data). We call the rate of spurious edits the edit
overhead (EO). For figure 1 above, this is 811 : There
are 11 edits (as shown in the figure), while we?d ex-
pect only 3 (one ? for each word in the final result).
Hence, 8 edits are spurious.
This measure corresponds directly to the amount
of unnecessary activity a consumer of the ASR?s
output performs when it reacts swiftly to words that
may be revoked later on. If the consumer is able to
robustly cope with parallel hypotheses (for example
by building a lattice-like structure), a high EO may
not be problematic, but if revisions are costly for
later modules (or even impossible because action has
already been taken), we would like EO to be as low
as possible. This can be achieved by not sending edit
messages unconditionally as soon as words change
in the ASR?s current hypothesis, using strategies as
outlined in section 4. Obviously, deferring or sup-
pressing messages results in delays, a topic to which
we turn in the following section, where we define
measures for the response time of ASR.
2.3 Timing Measures
So far, our measures capture characteristics about
the complete recognition process. We now turn to
the timing of the recognition of individual words.
For this, we again take the output of the ASR when
all signal is present (i.e., wgold) as the basis. There
3As fourth and most frequent alternative, consecutive hy-
potheses do not change at all.
4Revision could also be seen as a third atomic operation,
as in standard ASR evaluation (then called ?substitution?). To
keep things simple, we only regard two atomic operations.
382
are two things we may be interested in. First, we
may want to know when is the first time that a certain
word appears in the correct position in the sequence
(or equivalently, when its first correct add edit mes-
sage is sent), expressed in relation to its boundaries
in wgold. We measure this event, the first time that
the ASR was right about a word, relative to its gold
beginning. We call the measure word first correct
response (WFC). As a concrete example take hyp7
in figure 1. At this point, the word ?zwei? is first hy-
pothesised. Compared to the beginning of the word
in wgold, this point (t7) has a delay of 1 frame (the
frames are illustrated by the dashed lines).
As explained above, it may very well be the
case that for a brief while another hypothesis, not
r-correct w.r.t. wgold, may be favoured (cf. the word
?zwar? in the example in the figure). Another mea-
sure we hence might also be interested in is when our
word hypothesis starts remaining stable or, in other
words, becomes final. We measure this event rela-
tive to the end of the word in the gold standard. We
call it word first final response (WFF). In our exam-
ple, again for ?zwei?, this is t9, which has a distance
of 0 to the right boundary of the word in wgold.
In principle, we could use both anchor points (the
left vs. the right edge of a word) for either measure
or use a word-relative scale, but for simplicity?s sake
we restrict ourselves to one anchor point each.
Under normal conditions, we expect WFC to be
positive. The better the incremental ASR, the closer
to 0 it will be. WFC is not a measure we can eas-
ily optimize. We would either have to enumerate
the whole language model or use external non-ASR
knowledge to predict continuations of the word se-
quence before the word in question has started. This
would increase EO. In principle, we are rather in-
terested in accepting an increase in WFC, when we
delay messages in order to decrease EO.
WFF however, can reach values below 0. It
converges towards the negative average of word
length as an incremental ASR improves. For non-
incremental ASR it would be positive: the average
distance beween the sentence end and word end.
WFF is a measure we can strive to reduce by sending
fewer (especially fewer wrong) messages.
Another property we might be interested in opti-
mizing is the time it takes from the first correct hy-
pothesis to stabilize to a final hypothesis. We com-
pute this correction time as the difference in time
between WFF and WFC.5 A correction time of 0 in-
dicates that there was no correction, i.e. the ASRwas
immediately correct about a word, something which
we would like to happen as often as possible.
Note that these are measures for each word in
each processed utterance, and we will use distribu-
tional parameters of these timing measures (means
and standard deviations) as metrics for the perfor-
mance of the incremental setups described later.
2.4 Summary of Measures
In this section, we first described measures that eval-
uate the overall correctness of incrementally pro-
duced ASR hypotheses, not taking into account their
sequential nature. We then turned to the dynamics of
how the current hypothesis evolves in a way which
we consider important for a consumer of incremen-
tal ASR, namely the overhead that results from edits
to the hypothesis. Finally, we looked at the timing
of individual messages with regard to first correct
(potentially unstable) occurrence (WFC) and stabil-
ity (WFF). In the next section, we use the measures
defined here to characterize the incremental perfor-
mance of our ASR, before we discuss ways to im-
prove incremental performance in section 4.
3 Setup, Corpora and Base Measurements
We use the large-vocabulary continuous-speech
recognition framework Sphinx-4 (Walker et al,
2004) for our experiments, using the built-in Lex-
Tree decoder, extended by us to provide incremen-
tal results. We built acoustic models for German,
based on a small corpus of spontaneous instructions
in a puzzle building domain,6 and the Kiel corpus
of read speech (IPDS, 1994). We use a trigram lan-
guage model that is based on the puzzle domain tran-
scriptions. As test data we use 85 recordings of two
speakers (unknown to the acoustic model) that speak
sentences similar to those in the puzzle domain.
We do not yet use recognition rescoring to opti-
mize for word error rate, but just the ASR?s best
hypotheses which optimize for low sentence error.
Incremental rescoring mechanisms such as that of
5In figure 1, the correction time for ?zwei? is 9? 7 = 2.
6Available from http://www.voxforge.org/
home/downloads/speech/
383
SER (non-incremental) 68.2%
WER (non-incremental) 18.8%
r-correct (cropped) 30.9%
p-correct (cropped) 53.1%
edit overhead 90.5%
mean word duration 0.378 s
WFC: mean, stddev, median 0.276 s, 0.186 s, 0.230 s
WFF: mean, stddev, median 0.004 s, 0.268 s, ?0.06 s
immediately correct 58.6%
Table 1: Base measurements on our data
Razik et al (2008) to optimize ASR performance are
orthogonal to the approaches presented in section 4
and could well be incorporated to further improve
incremental performance.
The individual recordings in our corpus are fairly
short (5.5 seconds on average) and include a bit of si-
lence at the beginning and end. Obviously, recogniz-
ing silence is much easier than recognizing words.
To make our results more meaningful for continuous
speech, we crop away all ASR hypotheses from be-
fore and after the active recognition process.7 While
this reduces our performance in terms of correctness
(we crop away areas with nearly 100% correctness),
it has no impact on the edit overhead, as the number
of changes in wcurr remains unchanged, and also no
impact on the timing measures as all word bound-
aries remain the same.
3.1 Base Measurements
Table 1 characterises our ASR module (on our data)
in terms of the metrics defined in section 2. Addi-
tionally we state sentence error rate, as the rate of
sentences that contain at least one error, and word
error rate computed in the usual way, as well as
the mean duration of words in our corpus (as non-
incrementally measured for our ASR).
We see that correctness is quite low. This is
mostly due to the jitter that the evolving current hy-
pothesis shows in its last few frames, jumping back
and forth between highly-ranked alternatives. Also,
our ASR only predicts words once there is acoustic
evidence for several phonemes and every phoneme
(being modelled by 3 HMM states) must have a du-
ration of at least 3 frames. Thus, some errors rela-
tive to the final hypothesis occur because the ASR
7In figure 1, hypotheses 1, 2 and 3 would be cropped away.
 40
 50
 60
 70
 80
 90
 100
 0  0.2  0.4  0.6  0.8  1  1.2
pe
rc
en
ta
ge
 o
f w
or
ds
 th
at
 a
re
 fi
na
l
correction time in s
Figure 2: Distribution of correction times (WFF?WFC).
only hypothesizes about words once they already
have a certain duration (and hence preceding hy-
potheses are not r-correct). The difference between
r-correctness and p-correctness (20% in our case)
may be largely attributed to this fact.
The edit overhead of 90.5% means that for ev-
ery neccessary add message, there are nine superflu-
ous (add or revoke) messages. Thus, a consumer of
the ASR output would have to recompute its results
ten times on average. In an incremental system, this
consumer might itself output messages and further
revise decisions as information from other modules
becomes available, leading to a tremendous amount
of changes in the system state. As ASR is the first
module in an incremental spoken dialogue system,
reducing the edit overhead is essential for overall
system performance.
On average, the correct hypothesis about a word
becomes available 276ms after the word has started
(WFC). With a mean word duration of 378ms
this means that information becomes available af-
ter roughly 34 of the word have been spoken. No-
tice though that the median is somewhat lower than
the mean, implying that this time is lower for most
words and much higher for some words. In fact, the
maximum for WFC in our data is 1.38 s.
On average, a word becomes final (i.e. is
not changed anymore) when it has ended
(mean(WFF) = 0.004). Again, the median is
lower, indicating the unnormal distribution of WFF
(more often lower, sometimes much higher).
Of all words, 58.6% were immediately correctly
384
 0
 20
 40
 60
 80
 100
2 5 8 11
LM weight
R-Correctness
P-Correctness
Edit Overhead
WER
Figure 3: Correctness, Edit Overhead and Word Error
Rate (WER) with varied language model weight and un-
altered audio.
hypothesized by the ASR. Figure 2 plots the per-
centage of words with correction times equal to or
lower than the time on the x-axis. While this starts
at the initial 58.6% of words that were immediately
correct, it rises above 90% for a correction time of
320ms and above 95% for 550ms. Inversely this
means that we can be certain to 90% (or 95%) that
a current correct hypothesis about a word will not
change anymore once it has not been revoked for
320ms (or 550ms respectively).
Knowing (or assuming with some certainty) that
a hypothesis is final allows us, to commit ourselves
to this hypothesis. This allows for reduced compu-
tational overhead (as alternative hypotheses can be
abandoned) and is crucial if action is to be taken that
cannot be revoked later on (as for example, initiat-
ing a response from the dialogue system). Figure 2
allows us to choose an operating point for commit-
ment with respect to hypothesis age and certainty.
3.2 Variations of the Setup
In setting up our system we did not yet strive for best
(non-incremental) performance; this would have re-
quired much more training material and parameter
tweaking. We were more interested here in explor-
ing general questions related to incremental ASR,
and in developing approaches to improve incremen-
tal performance (see section 4), which we see as a
problem that is independent from that of improving
performance measures like (overall) accuracy.
To test how independent our measures are on de-
 0
 20
 40
 60
 80
 100
orig -20 -15 -10 -5 0
signal to noise ratio in dB
R-Correctness
P-Correctness
Edit Overhead
WER
Figure 4: Correctness, Edit Overhead and Word Error
Rate (WER) with additive noise (LM weight set to 8).
tails of the specific setting, such as quality of the
audio material and of the language model, we var-
ied these factors systematically, by adding white
noise to the audio and changing the language model
weight relative to the acoustic model. We varied the
noise to produce signal to noise ratios ranging from
hardly audible (?20 dB), through annoying noise
(?10 dB) to barely understandable audio (0 dB).
Figure 3 gives an overview of the ASR-
performance with different LM weights and figure 4
with degraded audio signals. Overall, we see that
r-correctness and EO change little with different
LM and AM performance and correspondigly de-
graded WER. A tendency can be seen that larger LM
weights result in higher correctness and lower EO. A
larger LM weight leads to less influence of acoustic
events which dynamically change hypotheses, while
the static knowledge from the LM becomes more
important. Surprisingly, WER improved with the
addition of slight noise, which we assume is due to
differences in recording conditions between our test
data and the training data of the acoustic model.
In the following experiments as well as in the data
in table 1 above, we use a language model weight of
8 and unaltered audio.
4 Improving Incremental Performance
In the previous section we have shown how a stan-
dard ASR that incrementally outputs partial hy-
potheses after each frame processed performs with
regard to our measures and showed that they remain
385
stable in different acoustic conditions and with dif-
fering LM weights. We now discuss ways of incre-
mentally post-processing ASR hypotheses in order
to improve selected measures.
We particularly look for ways to improve EO;
that is, we want to reduce the amount of wrong hy-
potheses and resulting spurious edits that deterio-
rate later modules? performance, while still being as
quick as possible with passing on relevant hypothe-
ses. We are less concerned with correctness mea-
sures, as they do not capture well the dynamic evo-
lution, which is important for further processing of
the incremental hypothesis. We also discuss trade-
offs that are involved in the optimization decisions.
4.1 Right Context
Allowing the use of some right context is a com-
mon strategy to cope with incremental data. For
example, our ASR already uses this strategy (with
very short right contexts) internally at word bound-
aries to restrict the language model hypotheses to
an acoustically plausible subset (Ortmanns and Ney,
2000). In the experiment described here, we allow
the ASR a larger right context of size ? by taking
into account at time t the output of the ASR up to
time t ? ? only. That is, what the ASR hypothe-
sizes about the interval ]t ? ?, t] is considered to
be too immature and is discarded, and the hypothe-
ses about the input up to t?? have the benefit of a
lookahead up to t. This reduces jitter, which is found
mostly to the very right of the incremental hypothe-
ses. Thus, we expect to reduce the edit overhead in
proportion with ?. On the other hand, allowing the
use of a right context leads to the current hypothe-
sis lagging behind the gold standard. Correspond-
ingly, WFC increases by ?. Obviously, using only
information up to t ? ? has averse effects on cor-
rectness as well, as this measure evaluates the word
sequences up to wgoldt which may already contain
more words (those recognised in ]t ? ?, t]). Thus,
to be more fair and to account for the lag when mea-
suring the module?s correctness, we additionally de-
fine fair r-correctness which restricts the evaluation
up to time t??: whyptt?? = wgoldt??.
Figure 5 details the results for our data with right
context between 1.5 s and ?0.2 s. (The x-axis plots
? as negative values, with 0 being ?now?. Results
for a right context (?) of 1.2 can thus be found 1.2 to
 0
 20
 40
 60
 80
 100
-1.6 -1.4 -1.2 -1 -0.8 -0.6 -0.4 -0.2  0  0.2
right context in s (scale shows larger right contexts towards the left)
(strict) R-Correctness
fair R-Correctness
P-Correctness
Edit Overhead
WER
Figure 5: Correctness (see text), Edit Overhead and
fixed-WER for varying right contexts ?.
the left of 0, at ?1.2.) We see that at least in the fair
measure, fixed lag performs quite well at improving
both the module?s correctness and EO. This is due
to the fact that ASR hypotheses become more and
more stable when given more right context. Still,
even for fairly long lags, many late edits still occur.
To illustrate the effects of a system that does not
support edits of hypotheses, but instead commits
right away, we plot WER that would be reached by a
system that always commits after a right context of
?. As can be seen in the figure, the WER remains
higher than the non-incremental WER (18.8%) even
for fairly large right contexts. Also, the WER plot by
Wachsmuth et al (1998) looks very similar to ours
and likewise shows a sweet spot suitable as an oper-
ating point with a right context of about 800ms.
As expected, the analysis of timing measures
shows an increase with larger right contexts with
their mean values quickly approaching ? (or
??meanword duration for WFF), which are the
lower bounds when using right context. Correspond-
ingly, the percentage of immediately correct hy-
potheses increases with right context reaching 90%
for ? = 580ms and 98% for ? = 1060ms.
Finally, we can extend the concept of right con-
text into negative values, predicting the future, as it
were. By choosing a negative right context, in which
we extrapolate the last hypothesis state by ? into the
future, we can measure the correctness of our hy-
potheses correctly predicting the close future, which
is always the case when the current word is still be-
386
ing spoken. The graph shows that 15% of our hy-
potheses will still be correct 100ms in the future and
10% will still be correct for 170ms. Unfortunately,
there is little way to tell apart hypotheses that will
survive and those which will soon be revised.
4.2 Message Smoothing
In the previous section we reduced wrong edit mes-
sages by avoiding most of the recognition jitter by
allowing the ASR a right context of size ?, which
directly hurt timing measures by roughly the same
amount. In this section, we look at the sequence of
partial hypotheses from the incremental ASR, using
the dynamic properties as cues. We accomplish this
by looking at the edit messages relative to the cur-
rently output word sequence. But instead of sending
them to a consumer directly (updating the external
word sequence), we require that an edit message be
the result of N consecutive hypotheses. To illustrate
the process with N = 2 we return to figure 1. None
of the words ?an?, ?ein? or ?zwar? would ever be
output, because they are only present for one time-
interval each. Edit messages would be sent at the
following times: ?(eins) at t7, ?(zwei) at t10 (only
then is ?zwei? the result of two consecutive hypothe-
ses) and ?(drei) at t13. While no words are revoked
in the example, this still occurs when a revocation is
consecutively hypothesized for N frames.
We get controversial results for this strategy, as
can be seen in figure 6: The edit overhead falls
rapidly, reaching 50% (for each message necessary,
there is one superfluous message) with only 110ms
(and correspondingly increasing WFC by the same
time) and 10% with 320ms. The same thresh-
olds are reached through the use of right context at
530ms and 1150ms respectively as shown in fig-
ure 5. Likewise, the prefix correctness improve-
ments are better than with using right context, but
the r-correctness is poor, even under the ?fair? mea-
sure. We believe this is due to correct hypotheses
being held back too long due to the hypothesis se-
quence being interspersed with wrong hypotheses
(which only last for few consecutive hypotheses)
which reset the counter until the add message (for
the prevalent and potentially correct word) is sent.8
8This could be resolved by using some kind of majority
smoothing instead of requiring a message to be the result of all
consecutive hypotheses. We will investigate this in future work.
 0
 20
 40
 60
 80
 100
-1 -0.8 -0.6 -0.4 -0.2  0
smoothing in s (scale shows larger smoothings towards the left)
(strict) R-Correctness
fair R-Correctness
P-Correctness
Edit Overhead
Figure 6: Correctness and Edit Overhead for varying
smoothing lengths.
5 Conclusions and Further Directions
We have presented the problem of speech recogni-
tion for incremental systems, outlined requirements
for incremental speech recognition and showed mea-
sures that capture how well an incremental ASR per-
forms with regard to these measures. We discussed
the measures and their implications in detail with
our baseline system and showed that the incremen-
tal measures remain stable regardless of the specific
ASR setting used.
Finally, we presented ways for the online post-
processing of incremental results, looking for ways
to improve some of the measures defined, while
hurting the other measures as little as possible.
Specifically, we were interested in generating less
wrong hypotheses at the cost of possible short de-
lays. While using right context shows improvements
with larger delays, using message smoothing seems
especially useful for fast processing. We think these
two approaches could be combined to good effect.
Together with more elaborate confidence handling a
system could quickly generate hypotheses and then
refine the associated confidences over time. We will
explore this in future work.
Acknowledgments
This work was funded by a DFG grant in the Emmy
Noether programme. We wish to thank the anony-
mous reviewers for helpful comments.
387
References
James Allen, George Ferguson, and Amanda Stent. 2001.
An architecture for more realistic conversational sys-
tems. In Proceedings of the Conference on Intelligent
User Interfaces, Santa Fe, USA.
IPDS. 1994. The Kiel Corpus of Read Speech. CD-
ROM.
Anne Kilger and Wolfgang Finkler. 1995. Incremental
generation for real-time applications. Technical Re-
port RR-95-11, DFKI, Saarbru?cken, Germany.
Stefan Ortmanns and Hermann Ney. 2000. Look-ahead
techniques for fast beam search. Computer Speech &
Language, 14:15?32.
Joseph Razik, Odile Mella, Dominique Fohr, and Jean-
Paul Haton. 2008. Frame-Synchronous and Local
ConfidenceMeasures for on-the-fly Automatic Speech
Recognition. In Proceedings of Interspeech 2008.
Sven Wachsmuth, Gernot A. Fink, and Gerhard Sagerer.
1998. Integration of parsing and incremental speech
recognition. In Proceedings of the European Sig-
nal Processing Conference, volume 1, pages 371?375,
Rhodes, Greece.
Willi Walker, Paul Lamere, Philip Kwok, Bhiksha Raj,
Rita Singh, Evandro Gouvea, Peter Wolf, and Joe
Woelfel. 2004. Sphinx-4: A flexible open source
framework for speech recognition. Technical Report
SMLI TR2004-0811, Sun Microsystems Inc.
Steve Young, NH Russell, and JHS Thornton. 1989. To-
ken passing: a simple conceptual model for connected
speech recognition systems. Cambridge University
Engineering Department Technical Report CUED/F-
INFENG/TR, 38.
388
Proceedings of the 43rd Annual Meeting of the ACL, pages 247?254,
Ann Arbor, June 2005. c?2005 Association for Computational Linguistics
Towards Finding and Fixing Fragments: Using ML to Identify
Non-Sentential Utterances and their Antecedents in Multi-Party Dialogue
David Schlangen
Department of Linguistics
University of Potsdam
P.O. Box 601553
D-14415 Potsdam ? Germany
das@ling.uni-potsdam.de
Abstract
Non-sentential utterances (e.g., short-
answers as in ?Who came to the party???
?Peter.?) are pervasive in dialogue. As
with other forms of ellipsis, the elided ma-
terial is typically present in the context
(e.g., the question that a short answer an-
swers). We present a machine learning
approach to the novel task of identifying
fragments and their antecedents in multi-
party dialogue. We compare the perfor-
mance of several learning algorithms, us-
ing a mixture of structural and lexical fea-
tures, and show that the task of identifying
antecedents given a fragment can be learnt
successfully (f(0.5) = .76); we discuss
why the task of identifying fragments is
harder (f(0.5) = .41) and finally report
on a combined task (f(0.5) = .38).
1 Introduction
Non-sentential utterances (NSUs) as in (1) are per-
vasive in dialogue: recent studies put the proportion
of such utterances at around 10% across different
types of dialogue (Ferna?ndez and Ginzburg, 2002;
Schlangen and Lascarides, 2003).
(1) a. A: Who came to the party?
B: Peter. (= Peter came to the party.)
b. A: I talked to Peter.
B: Peter Miller? (= Was it Peter Miller
you talked to?)
c. A: Who was this? Peter Miller? (= Was
this Peter Miller?
Such utterances pose an obvious problem for natural
language processing applications, namely that the
intended information (in (1-a)-B a proposition) has
to be recovered from the uttered information (here,
an NP meaning) with the help of information from
the context.
While some systems that automatically resolve
such fragments have recently been developed
(Schlangen and Lascarides, 2002; Ferna?ndez et al,
2004a), they have the drawback that they require
?deep? linguistic processing (full parses, and also in-
formation about discourse structure) and hence are
not very robust. We have defined a well-defined
subtask of this problem, namely identifying frag-
ments (certain kinds of NSUs, see below) and their
antecedents (in multi-party dialogue, in our case),
and present a novel machine learning approach to it,
which we hypothesise will be useful for tasks such
as automatic meeting summarisation.1
The remainder of this paper is structured as fol-
lows. In the next section we further specify the task
and different possible approaches to it. We then de-
scribe the corpus we used, some of its characteris-
tics with respect to fragments, and the features we
extracted from it for machine learning. Section 4
describes our experimental settings and reports the
results. After a comparison to related work in Sec-
tion 5, we close with a conclusion and some further
1(Zechner and Lavie, 2001) describe a related task, linking
questions and answers, and evaluate its usefulness in the context
of automatic summarisation; see Section 5.
247
work that is planned.
2 The Tasks
As we said in the introduction, the main task we
want to tackle is to align (certain kinds of) NSUs
and their antecedents. Now, what characterises this
kind of NSU, and what are their antecedents?
In the examples from the introduction, the NSUs
can be resolved simply by looking at the previous
utterance, which provides the material that is elided
in them. In reality, however, the situation is not that
simple, for three reasons: First, it is of course not
always the previous utterance that provides this ma-
terial (as illustrated by (2), where utterance 7 is re-
solved by utterance 1); in our data the average dis-
tance in fact is 2.5 utterances (see below).
(2) 1 B: [. . . ] What else should be done ?
2 C: More intelligence .
3 More good intelligence .
4 Right .
5 D: Intelligent intelligence .
6 B: Better application of face and voice
recognition .
7 C: More [. . . ] intermingling of the
agencies , you know .
[ from NSI 20011115 ]
Second, it?s not even necessarily a single utter-
ance that does this?it might very well be a span
of utterances, or something that has to be inferred
from such spans (parallel to the situation with pro-
nouns, as discussed empirically e.g. in (Strube and
Mu?ller, 2003)). (3) shows an example where a new
topic is broached by using an NSU. It is possible to
analyse this as an answer to the question under dis-
cussion ?what shall we organise for the party??, as
(Ferna?ndez et al, 2004a) would do; a question, how-
ever, which is only implicitly posed by the previous
discourse, and hence this is an example of an NSU
that does not have an overt antecedent.
(3) [after discussing a number of different topics]
1 D: So, equipment.
2 I can bring [. . . ]
[ from NSI 20011211 ]
Lastly, not all NSUs should be analysed as being the
result of ellipsis: backchannels for example (like the
?Right? in utterance 4 in (2) above) seem to directly
fulfil their discourse function without any need for
reconstruction.2
To keep matters simple, we concentrate in this pa-
per on NSUs of a certain kind, namely those that a)
do not predominantly have a discourse-management
function (like for example backchannels), but rather
convey messages (i.e., propositions, questions or
requests)?this is what distinguishes fragments from
other NSUs?and b) have individual utterances as
antecedents. In the terminology of (Schlangen and
Lascarides, 2003), fragments of the latter type are
resolution-via-identity-fragments, where the elided
information can be identified in the context and
need not be inferred (as opposed to resolution-via-
inference-fragments). Choosing only this special
kind of NSUs poses the question whether this sub-
group is distinguished from the general group of
fragments by criteria that can be learnt; we will re-
turn to this below when we analyse the errors made
by the classifier.
We have defined two approaches to this task. One
is to split the task into two sub-tasks: identifying
fragments in a corpus, and identifying antecedents
for fragments. These steps are naturally performed
sequentially to handle our main task, but they also
allow the fragment classification decision to come
from another source?a language-model used in an
automatic speech recognition system, for example?
and to use only the antecedent-classifier. The other
approach is to do both at the same time, i.e. to clas-
sify pairs of utterances into those that combine a
fragment and its antecedent and those that don?t. We
report the results of our experiments with these tasks
below, after describing the data we used.
3 Corpus, Features, and Data Creation
3.1 Corpus
As material we have used six transcripts from the
?NIST Meeting Room Pilot Corpus? (Garofolo et al,
2004), a corpus of recordings and transcriptions of
multi-party meetings.3 Those six transcripts con-
2The boundaries are fuzzy here, however, as backchan-
nels can also be fragmental repetitions of previous material,
and sometimes it is not clear how to classify a given utter-
ance. A similar problem of classifying fragments is discussed
in (Schlangen, 2003) and we will not go further into this here.
3We have chosen a multi-party setting because we are ulti-
mately interested in automatic summarisation of meetings. In
this paper here, however, we view our task as a ?stand-alone
task?. Some of the problems resulting in the presence of many
248
average distance ? ? ?
(utterances): 2.5
? declarative 159 (52%)
? interrogative 140 (46%)
? unclassfd. 8 (2%)
? declarative 235 (76%)
? interrogative (23%)
? unclassfd. 2 (0.7%)
? being last in their turn 142 (46%)
? being first in their turn 159 (52%)
Table 1: Some distributional characteristics. (? de-
notes antecedent, ? fragment.)
sist of 5,999 utterances, among which we identified
307 fragment?antecedent pairs.4,5 With 5.1% this is
a lower rate than that reported for NSUs in other cor-
pora (see above); but note that as explained above,
we are actually only looking at a sub-class of all
NSUs here.
For these pairs we also annotated some more at-
tributes, which are summarised in Table 1. Note
that the average distance is slightly higher than that
reported in (Schlangen and Lascarides, 2003) for
(2-party) dialogue (1.8); this is presumably due to
the presence of more speakers who are able to re-
ply to an utterance. Finally, we automatically an-
notated all utterances with part-of-speech tags, us-
ing TreeTagger (Schmid, 1994), which we?ve
trained on the switchboard corpus of spoken lan-
guage (Godfrey et al, 1992), because it contains,
just like our corpus, speech disfluencies.6
We now describe the creation of the data we used
for training. We first describe the data-sets for the
different tasks, and then the features used to repre-
sent the events that are to be classified.
3.2 Data Sets
Data creation for the fragment-identification task
(henceforth simply fragment-task) was straightfor-
speakers are discussed below.
4We have used the MMAX tool (Mu?ller and Strube, 2001))
for the annotation.
5To test the reliability of the annotation scheme, we had a
subset of the data annotated by two annotators and found a sat-
isfactory ?-agreement (Carletta, 1996) of ? = 0.81.
6The tagger is available free for academic research from
http://www.ims.uni-stuttgart.de/projekte/
corplex/TreeTagger/DecisionTreeTagger.html.
ward: for each utterance, a number of features was
derived automatically (see next section) and the cor-
rect class (fragment / other) was added. (Note
that none of the manually annotated attributes were
used.) This resulted in a file with 5,999 data points
for classification. Given that there were 307 frag-
ments, this means that in this data-set there is a ratio
positives (fragments) vs. negatives (non-fragments)
for the classifier of 1:20. To address this imbalance,
we also ran the experiments with balanced data-sets
with a ratio of 1:5.
The other tasks, antecedent-identification
(antecedent-task) and antecedent-fragment-
identification (combined-task) required the creation
of data-sets containing pairs. For this we created
an ?accessibility window? going back from each
utterance. Specifically, we included for each
utterance a) all previous utterances of the same
speaker from the same turn; and b) the three last
utterances of every speaker, but only until one
speaker took the turn again and up to a maximum
of 6 previous utterances. To illustrate this method,
given example (2) it would form pairs with utterance
7 as fragment-candidate and all of utterances 6?2,
but not 1, because that violates condition b) (it is the
second turn of speaker B).
In the case of (2), this exclusion would be a wrong
decision, since 1 is in fact the antecedent for 7. In
general, however, this dynamic method proved good
at capturing as many antecedents as possible while
keeping the number of data points manageable. It
captured 269 antecedent-fragment pairs, which had
an average distance of 1.84 utterances. The remain-
ing 38 pairs which it missed had an average distance
of 7.27 utterances, which means that to capture those
we would have had to widen the window consid-
erably. E.g., considering all previous 8 utterances
would capture an additional 25 pairs, but at the cost
of doubling the number of data points. We hence
chose the approach described here, being aware of
the introduction of a certain bias.
As we have said, we are trying to link utterances,
one a fragment, the other its antecedent. The no-
tion of utterance is however less well-defined than
one might expect, and the segmentation of contin-
uous speech into utterances is a veritable research
problem on its own (see e.g. (Traum and Heeman,
1997)). Often it is arguable whether a prepositional
249
Structural features
dis distance ? ? ?, in utterances
sspk same speaker yes/no
nspk number speaker changes (= # turns)
iqu number of intervening questions
alt ? last utterance in its turn?
bft ? first utterance in its turn?
Lexical / Utterance-based features
bvb (tensed) verb present in ??
bds disfluency present in ??
aqm ? contains question mark
awh ? contains wh word
bpr ratio of polar particles (yes, no, maybe, etc..)
/ other in ?
apr ratio of polar particles in ?
lal length of ?
lbe length of ?
nra ratio nouns / non-nouns in ?
nra ratio nouns / non-nouns in ?
rab ratio nouns in ? that also occur in ?
rap ratio words in ? that also occur in ?
god google similarity (see text)
Table 2: The Features
phrase for example should be analysed as an adjunct
(and hence as not being an utterance on its own) or
as a fragment. In our experiments, we have followed
the decision made by the transcribers of the origi-
nal corpus, since they had information (e.g. about
pauses) which was not available to us.
For the antecedent-task, we include only pairs
where ? (the second utterance in the pair) is a
fragment?since the task is to identify an antecedent
for already identified fragments. This results in a
data-set with 1318 data points (i.e., we created on
average 4 pairs per fragment). This data-set is suf-
ficiently balanced between positives and negatives,
and so we did not create another version of it. The
data for the combined-task, however, is much big-
ger, as it contains pairs for all utterances. It consists
of 26,340 pairs, i.e. a ratio of roughly 1:90. For this
reason we also used balanced data-sets for training,
where the ratio was adjusted to 1:25.
3.3 Features
Table 2 lists the features we have used to represent
the utterances. (In this table, and in this section, we
denote the candidate for being a fragment with ? and
the candidate for being ??s antecedent with ?.)
We have defined a number of structural fea-
tures, which give information about the (discourse-
)structural relation between ? and ?. The rationale
behind choosing them should be clear; iqu for ex-
ample indicates in a weak way whether there might
have been a topic change, and high nspk should
presumably make an antecedent relation between ?
and ? less likely.
We have also used some lexical or utterance-
based features, which describe lexical properties of
the individual utterances and lexical relations be-
tween them which could be relevant for the tasks.
For example, the presence of a verb in ? is presum-
ably predictive for its being a fragment or not, as
is the length. To capture a possible semantic rela-
tionship between the utterances, we defined two fea-
tures. The more direct one, rab, looks at verbatim
re-occurrences of nouns from ? in ?, which occur
for example in check-questions as in (4) below.
(4) A: I saw Peter.
B: Peter? (= Who is this Peter you saw?)
Less direct semantic relations are intended to be
captured by god, the second semantic feature we
use.7 It is computed as follows: for each pair (x, y)
of nouns from ? and ?, Google is called (via the
Google API) with a query for x, for y, and for x and
y together. The similarity then is the average ratio of
pair vs. individual term:
Google Similarity(x, y) = (hits(x, y)hits(x) +
hits(x, y)
hits(y) )?
1
2
We now describe the experiments we performed
and their results.
4 Experiments and Results
4.1 Experimental Setup
For the learning experiments, we used three classi-
fiers on all data-sets for the the three tasks:
? SLIPPER (Simple Learner with Iterative Prun-
ing to Produce Error Reduction), (Cohen and Singer,
1999), which is a rule learner which combines
the separate-and-conquer approach with confidence-
rated boosting. It is unique among the classifiers that
7The name is short for google distance, which indicates its
relatedness to the feature used by (Poesio et al, 2004); it is how-
ever a measure of similarity, not distance, as described above.
250
we have used in that it can make use of ?set-valued?
features, e.g. strings; we have run this learner both
with only the features listed above and with the ut-
terances (and POS-tags) as an additional feature.
? TIMBL (Tilburg Memory-Based Learner),
(Daelemans et al, 2003), which implements a
memory-based learning algorithm (IB1) which pre-
dicts the class of a test data point by looking at its
distance to all examples from the training data, us-
ing some distance metric. In our experiments, we
have used the weighted-overlap method, which as-
signs weights to all features.
? MAXENT, Zhang Le?s C++ implementation8 of
maximum entropy modelling (Berger et al, 1996).
In our experiments, we used L-BFGS parameter es-
timation.
We also implemented a na??ve bayes classifier and
ran it on the fragment-task, with a data-set consisting
only of the strings and POS-tags.
To determine the contribution of all features, we
used an iterative process similar to the one described
in (Kohavi and John, 1997; Strube and Mu?ller,
2003): we start with training a model using a base-
line set of features, and then add each remaining
feature individually, recording the gain (w.r.t. the f-
measure (f(0.5), to be precise)), and choosing the
best-performing feature, incrementally until no fur-
ther gain is recorded. All individual training- and
evaluation-steps are performed using 8-fold cross-
validation (given the small number of positive in-
stances, more folds would have made the number of
instances in the test set set too small).
The baselines were as follows: for the fragment-
task, we used bvb and lbe as baseline, i.e. we let
the classifier know the length of the candidate and
whether the candidate contains a verb or not. For
the antecedent-task we tested a very simple baseline,
containing only of one feature, the distance between
? and ? (dis). The baseline for the combined-
task, finally, was a combination of those two base-
lines, i.e. bvb+lbe+dis. The full feature-set for
the fragment-task was lbe, bvb, bpr, nrb,
bft, bds (since for this task there was no ? to
compute features of), for the two other tasks it was
the complete set shown in Table 2.
8Available from http://homepages.inf.ed.ac.uk/
s0450736/maxent toolkit.html.
4.2 Results
The Tables 3?5 show the results of the experiments.
The entries are roughly sorted by performance of the
classifier used; for most of the classifiers and data-
sets for each task we show the performance for base-
line, intermediate feature set(s), and full feature-set,
for the rest we only show the best-performing set-
ting. We also indicate whether a balanced or unbal-
anced data set was used. I.e., the first three lines
in Table 3 report on MaxEnt on a balanced data set
for the fragment-task, giving results for the baseline,
baseline+nrb+bft, and the full feature-set.
We begin with discussing the fragment task. As
Table 3 shows, the three main classifiers perform
roughly equivalently. Re-balancing the data, as ex-
pected, boosts recall at the cost of precision. For all
settings (i.e., combinations of data-sets, feature-sets
and classifier), except re-balanced maxent, the base-
line (verb in ? yes/no, and length of ?) already has
some success in identifying fragments, but adding
the remaining features still boosts the performance.
Having available the string (condition s.s; slipper
with set valued features) interestingly does not help
SLIPPER much.
Overall the performance on this task is not great.
Why is that? An analysis of the errors made shows
two problems. Among the false negatives, there is a
high number of fragments like ?yeah? and ?mhm?,
which in their particular context were answers to
questions, but that however occur much more of-
ten as backchannels (true negatives). The classifier,
without having information about the context, can of
course not distinguish between these cases, and goes
for the majority decision. Among the false positives,
we find utterances that are indeed non-sentential,
but for which no antecedent was marked (as in (3)
above), i.e., which are not fragments in our narrow
sense. It seems, thus, that the required distinctions
are not ones that can be reliably learnt from looking
at the fragments alone.
The antecedent-task was handled more satisfac-
torily, as Table 4 shows. For this task, a na??ve base-
line (?always take previous utterance?) preforms rel-
atively well already; however, all classifiers were
able to improve on this, with a slight advantage for
the maxent model (f(0.5) = 0.76). As the entry
for MaxEnt shows, adding to the baseline-features
251
Data Set Cl. Recall Precision f(0.5) f(1.0) f(2.0)
B; bl m 0.00 0.00 0.00 0.00 0.00
B; bl+nrb+bft m 36.39 31.16 0.31 0.33 0.35
B; all m 40.61 44.10 0.43 0.42 0.41
UB; all m 22.13 65.06 0.47 0.33 0.25
B; bl t 31.77 21.20 0.22 0.24 0.28
B; bl+nrb+bpr+bds t 42.18 41.26 0.41 0.42 0.42
B; all t 44.54 32.74 0.34 0.37 0.41
UB; bl+nrb t 26.22 59.05 0.47 0.36 0.29
B; bl s 21.07 16.95 0.17 0.18 0.20
B; bl+nrb+bft+bds s 36.37 49.28 0.46 0.41 0.38
B; all s 36.67 43.31 0.42 0.40 0.38
UB; bl+nrb s 28.28 57.88 0.48 0.38 0.31
B s.s 32.57 42.96 0.40 0.36 0.34
B b 55.62 19.75 0.23 0.29 0.41
UB b 66.50 20.00 0.23 0.31 0.45
Table 3: Results for the fragment task. (Cl. = classifier used, where s = slipper, s.s = slipper + set-valued
features, t = timbl, m = maxent, b = naive bayes; UB/B = (un)balanced training data.)
Data Set Cl. Recall Precision f(0.5) f(1.0) f(2.0)
dis=1 - 44.95 44.81 0.45 0.45 0.45
UB; bl m 0 0 0.0 0.0 0.0
UB; bl+awh m 43.21 52.90 0.50 0.47 0.45
UB; bl+awh+god m 36.98 75.31 0.62 0.50 0.41
UB; bl+awh+god+lbe+lal+iqu+nra+buh m 64.26 80.39 0.76 0.71 0.67
UB; all m 58.16 73.57 0.69 0.64 0.60
UB; bl s 0.00 0.00 0.00 0.00 0.00
UB; bl+aqm s 36.65 78.44 0.63 0.49 0.41
UB; bl+aqm+rab+iqu+lal s 49.72 79.75 0.71 0.61 0.54
UB; all s 49.43 72.57 0.66 0.58 0.52
UB; bl t 0 0 0.0 0.0 0.0
UB; bl+aqm t 36.98 73.58 0.61 0.49 0.41
UB; bl+aqm+awh+rab+iqu t 46.41 77.65 0.68 0.58 0.50
UB; all t 60.57 58.74 0.59 0.60 0.60
Table 4: Results for the antecedent task.
Data Set Cl. Recall Precision f(0.5) f(1.0) f(2.0)
B; bl m 0.00 0.00 0.00 0.00 0.00
B; bl+rap m 5.83 40.91 0.18 0.10 0.07
B; bl+rap+god m 7.95 55.83 0.25 0.14 0.10
B; bl+rap+god+nspk m 11.70 49.15 0.30 0.19 0.14
B; bl+rap+god+nspk+alt+awh+nra+lal m 20.27 50.02 0.38 0.28 0.23
B; all m 23.29 43.79 0.36 0.30 0.25
UB; bl+rap+god+nspk+iqu+nra+bds+rab+awh m 13.01 54.87 0.33 0.21 0.15
B; bl s 0.00 0.00 0.00 0.00 0.00
B; bl+god s 11.80 35.60 0.25 0.17 0.13
B; bl+god+bds s 14.44 46.98 0.32 0.22 0.17
B; all s 17.78 41.96 0.32 0.24 0.20
UB; bl+alt+bds+god+sspk+rap s 11.37 56.34 0.31 0.19 0.13
B; bl t 0.00 0.00 0.00 0.00 0.00
B; bl+god t 17.20 29.09 0.25 0.21 0.19
B; all t 17.87 19.97 0.19 0.19 0.18
UB; bl+god+iqu+rab t 14.24 41.63 0.29 0.21 0.16
B; bl+rab+buh s.s 8.63 54.20 0.26 0.15 0.10
Table 5: Results for the combined task.
252
information about whether ? is a question or not al-
ready boost the performance considerably. An anal-
ysis of the predictions of this model then indeed
shows that it already captures cases of question and
answer pairs quite well. Adding the similarity fea-
ture god then gives the model information about
semantic relatedness, which, as hypothesised, cap-
tures elaboration-type relations (as in (1-b) and (1-c)
above). Structural information (iqu) further im-
proves the model; however, the remaining features
only seem to add interfering information, for perfor-
mance using the full feature-set is worse.
If one of the problems of the fragment-task was
that information about the context is required to dis-
tinguish fragments and backchannels, then the hope
could be that in the combined-task the classifier
would able to capture these cases. However, the per-
formance of all classifiers on this task is not satis-
factory, as Table 5 shows; in fact, it is even slightly
worse than the performance on the fragment task
alone. We speculate that instead of of cancelling out
mistakes in the other part of the task, the two goals
(let ? be a fragment, and ? a typical antecedent) in-
terfere during optimisation of the rules.
To summarise, we have shown that the task of
identifying the antecedent of a given fragment is
learnable, using a feature-set that combines struc-
tural and lexical features; in particular, the inclusion
of a measure of semantic relatedness, which was
computed via queries to an internet search engine,
proved helpful. The task of identifying (resolution-
via-identity) fragments, however, is hindered by the
high number of non-sentential utterances which can
be confused with the kinds of fragments we are in-
terested in. Here it could be helpful to have a method
that identifies and filters out backchannels, presum-
ably using a much more local mechanism (as for ex-
ample proposed in (Traum, 1994)). Similarly, the
performance on the combined task is low, also due
to a high number of confusions of backchannels and
fragments. We discuss an alternative set-up below.
5 Related Work
To our knowledge, the tasks presented here have so
far not been studied with a machine learning ap-
proach. The closest to our problem is (Ferna?ndez et
al., 2004b), which discusses classifying certain types
of fragments, namely questions of the type ?Who??,
?When??, etc. (sluices). However, that paper does
not address the task of identifying those in a cor-
pus (which in any case should be easier than our
fragment-task, since those fragments cannot be con-
fused with backchannels).
Overlapping from another direction is the work
presented in (Zechner and Lavie, 2001), where the
task of aligning questions and answers is tackled.
This subsumes the task of identifying question-
antecedents for short-answers, but again is presum-
ably somewhat simpler than our general task, be-
cause questions are easier to identify. The authors
also evaluate the use of the alignment of questions
and answers in a summarisation system, and report
an increase in summary fluency, without a compro-
mise in informativeness. This is something we hope
to be able to show for our tasks as well.
There are also similarities, especially of the an-
tecedent task, to the pronoun resolution task (see
e.g. (Strube and Mu?ller, 2003; Poesio et al, 2004)).
Interestingly, our results for the antecedent task are
close to those reported for that task. The problem of
identifying the units in need of an antecedent, how-
ever, is harder for us, due to the problem of there
being a large number of non-sentential utterances
that cannot be linked to a single utterance as an-
tecedent. In general, this seems to be the main differ-
ence between our task and the ones mentioned here,
which concentrate on more easily identified mark-
ables (questions, sluices, and pronouns).
6 Conclusions and Further Work
We have presented a machine learning approach
to the task of identifying fragments and their an-
tecedents in multi-party dialogue. This represents a
well-defined subtask of computing discourse struc-
ture, which to our knowledge has not been studied so
far. We have shown that the task of identifying the
antecedent of a given fragment is learnable, using
features that provide information about the structure
of the discourse between antecedent and fragment,
and about semantic closeness.
The other tasks, identifying fragments and the
combined tasks, however, did not perform as well,
mainly because of a high rate of confusions be-
tween general non-sentential utterances and frag-
253
ments (in our sense). In future work, we will try
a modified approach, where the detection of frag-
ments is integrated with a classification of utterances
as backchannels, fragments, or full sentences, and
where the antecedent task only ranks pairs, leaving
open the possibility of excluding a supposed frag-
ment by using contextual information. Lastly, we
are planning to integrate our classifier into a pro-
cessing pipeline after the pronoun resolution step,
to see whether this would improve both our perfor-
mance and the quality of automatic meeting sum-
marisations.9
References
Adam L. Berger, Stephen Della Pietra, and Vincent J. Della
Pietra. 1996. A maximum entropy approach to natural lan-
guage processing. Computational Linguistics, 22(1):39?71.
Jean Carletta. 1996. Assessing agreement on classifica-
tion tasks: the kappa statistic. Computational Linguistics,
22(2):249?254.
William Cohen and Yoram Singer. 1999. A simple, fast, and
effective rule learner. In Proceedings of the Sixteenth Na-
tional Conference on Artificial Intelligence (AAAI-99), Or-
lando, Florida, July. AAAI.
Walter Daelemans, Jakub Zavrel, Ko van der Sloot,
and Antal van den Bosch. 2003. TiMBL: Tilburg
memory based learner, version 5.0, reference guide.
ILC Technical Report 03-10, Induction of Linguis-
tic Knowledge; Tilburg University. Available from
http://ilk.uvt.nl/downloads/pub/...
papers/ilk0310.pdf.
Raquel Ferna?ndez and Jonathan Ginzburg. 2002. Non-
sentential utterances in dialogue: A corpus-based study. In
Kristiina Jokinen and Susan McRoy, editors, Proceedings
of the Third SIGdial Workshop on Discourse and Dialogue,
pages 15?26, Philadelphia, USA, July. ACL Special Interest
Group on Dialog.
Raquel Ferna?ndez, Jonathan Ginzburg, Howard Gregory, and
Shalom Lappin. 2004a. Shards: Fragment resolution in
dialogue. In H. Bunt and R. Muskens, editors, Computing
Meaning, volume 3. Kluwer.
Raquel Ferna?ndez, Jonathan Ginzburg, and Shalom Lappin.
2004b. Classifying ellipsis in dialogue: A machine learn-
ing approach. In Proceedings of COLING 2004, Geneva,
Switzerland, August.
John S. Garofolo, Christophe D. Laprun, Martial Michel, Vin-
cent M. Stanford, and Elham Tabassi. 2004. The NITS
9Acknowledgements: We would like to acknowledge help-
ful discussions with Jason Baldridge and Michael Strube during
the early stages of the project, and helpful comments from the
anonymous reviewers.
meeting room pilot corpus. In Proceedings of the Interna-
tional Language Resources Conference (LREC04), Lisbon,
Portugal, May.
J.J. Godfrey, E. C. Holliman, and J. McDaniel. 1992. SWITCH-
BOARD: Telephone speech corpus for research and devlop-
ment. In Proceedings of the IEEE Conference on Acoustics,
Speech, and Signal Processing, pages 517?520, San Fran-
cisco, USA, March.
Ron Kohavi and George H. John. 1997. Wrappers for feature
selection. Artificial Intelligence Journal, 97(1?2):273?324.
Christoph Mu?ller and Michael Strube. 2001. MMAX: A Tool
for the Annotation of Multi-modal Corpora. In Proceedings
of the 2nd IJCAI Workshop on Knowledge and Reasoning
in Practical Dialogue Systems, pages 45?50, Seattle, USA,
August.
Massimo Poesio, Rahul Mehta, Axel Maroudas, and Janet
Hitzeman. 2004. Learning to resolve bridging refer-
ences. In Proceedings of the 42nd annual meeting of the
Association for Computational Linguistics, pages 144?151,
Barcelona, Spain, July.
David Schlangen and Alex Lascarides. 2002. Resolving
fragments using discourse information. In Johan Bos,
Mary Ellen Foster, and Colin Matheson, editors, Proceed-
ings of the 6th International Workshop on Formal Semantics
and Pragmatics of Dialogue (EDILOG 2002), pages 161?
168, Edinburgh, September.
David Schlangen and Alex Lascarides. 2003. The interpreta-
tion of non-sentential utterances in dialogue. In Alexander
Rudnicky, editor, Proceedings of the 4th SIGdial workshop
on Discourse and Dialogue, Sapporo, Japan, July.
David Schlangen. 2003. A Coherence-Based Approach to
the Interpretation of Non-Sentential Utterances in Dialogue.
Ph.D. thesis, School of Informatics, University of Edin-
burgh, Edinburgh, UK.
Helmut Schmid. 1994. Probabilistic part-of-speech tagging us-
ing decision trees. In Proceedings of the International Con-
ference on New Methods in Language Processing, Manch-
ester, UK.
Michael Strube and Christoph Mu?ller. 2003. A machine learn-
ing approach to pronoun resolution in spoken dialogue. In
Proceedings of the 41st Annual Meeting of the Association
for Computational Lingustics, Sapporo, Japan.
D. Traum and P. Heeman. 1997. Utterance units in spoken
dialogue. In E. Maier, M. Mast, and S. LuperFoy, editors,
Dialogue Processing in Spoken Language Systems, Lecture
Notes in Artificial Intelligence. Springer-Verlag.
David R. Traum. 1994. A Computational Theory of Grounding
in Natural Language Conversation. Ph.D. thesis, Computer
Science, University of Rochester, Rochester, USA, Decem-
ber.
Klaus Zechner and Anton Lavie. 2001. Increasing the coher-
ence of spoken dialogue summaries by cross-speaker infor-
mation linking. In Proceedings of the NAAACL Workshop
on Automatic Summarisation, Pittsburgh, USA, June.
254
Feeding OWL: Extracting and Representing
the Content of Pathology Reports
David Schlangen and Manfred Stede
Department of Linguistics
University of Potsdam
P.O. Box 601553
D-14415 Potsdam, Germany
{das|stede}@ling.uni-potsdam.de
Elena Paslaru Bontas
Institute for Computer Science
Freie Universita?t Berlin
Takustr.9
D-14195 Berlin, Germany
paslaru@inf.fu-berlin.de
Abstract
This paper reports on an ongoing project that com-
bines NLP with semantic web technologies to sup-
port a content-based storage and retrieval of medical
pathology reports. We describe the NLP component
of the project (a robust parser) and the background
knowledge component (a domain ontology repre-
sented in OWL), and how they work together during
extraction of domain specific information from nat-
ural language reports. The system provides a good
example of how NLP techniques can be used to pop-
ulate the Semantic Web.
1 Introduction
Clinical pathologists work with and produce vast
amounts of data: images of biological samples and
written reports of their findings. Digital Pathology
is the cover term for a number of efforts to intro-
duce digital processing into the work-flow of the
pathologist. While previous projects have focussed
on storage and distribution of images and reports
(e.g. in Tele-Pathology-projects, (Slodowksa et al,
2002; Demichellis et al, 2002)), the work reported
here explores the use of Natural Language Process-
ing (NLP) and Semantic Web technologies to sup-
port a content-based storage and retrieval of case
reports. The system that we are building, LUPUS
(Lung Pathology System), consists of an NLP com-
ponent (a robust parser) and a Semantic Web com-
ponent (a domain ontology represented in OWL, and
a Description Logic reasoner), which work closely
together, with the domain ontology guiding the in-
formation extraction process.
The remainder of the paper is organised as fol-
lows. In the next section we describe the context
and intended application of the system, we discuss
linguistic properties of the input material we are
working with, and we give some details of the back-
ground ontology we are using. In Section 3 we go
into the technical details of the process of extracting
information from natural language reports and rep-
resenting it in an OWL representation, after which
we describe a preliminary evaluation. We close with
discussing related work, and planned future work.
2 Digital Pathology
2.1 The Application
LUPUS is intended to support the pathologist in two
ways. First, it is used to semantically annotate a
large archive of case reports, turning them into a
valuable resource for diagnosis and teaching. The
system uses the case reports produced by experts
(the pathologists) to extract information about the
accompanying images (of the tissue samples), and
thus produces semantic annotation both for the re-
port and for those images.
This corpus of cases can then be searched in a
fast, content-based manner to retrieve case reports
(the textual reports together with the images of tis-
sue samples) that might be relevant for a case the
pathologist is working on. The search is content-
based in that it can make use of semantic relation-
ships between search concepts and those occuring
in the text. We also encode in rules knowledge
about certain diagnostics tasks, so that for example
queries asking for ?differential diagnosis? (?show
me cases of diagnoses which are known to be easily
confusable with the diagnosis I am thinking of for
the present case?) can be processed?tasks which
normally require consultation of textbooks. These
search capabilities are useful both during diagnosis
and for teaching, where it makes interesting exam-
ples immediately available to students.
Another use case is quality control during input
of new reports. Using our system, such reports can
be entered in a purpose-built editor (which com-
bines digital microscopy facilities (Saeger et al,
2003) with our semantic annotator / search engine),
where they are analysed on-the-fly, and potential
inconsistencies with respect to the background do-
main ontology are spotted.1 During the develop-
ment phase of the system, we are using this feature
1Naturally, to gain acceptance by working pathologists, this
process has to be ?minimally invasive?.
to detect where the coverage of the system must be
extended.
The present paper focuses on the process of ex-
tracting the relevant information from natural lan-
guage reports and representing it in a semantic
web-ready format as a precondition for performing
searches; we leave the description of the search and
retrieval functions to another paper. To give an idea
of the kind of data we are dealing with, and of the in-
tended target representation, Figure 1 shows an ex-
ample report (at the top of the figure) and the repre-
sentation of its content computed by our system (at
the bottom).2 We discuss the input format in the fol-
lowing subsection, and the target representation to-
gether with the domain knowledge available to us in
Subsection 2.3; discussion of the intermediate for-
mat that is also shown in the figure is deferred until
Section 3.
2.2 Pathology Reports
During the development phase of the system, we
are using a corpus of 90 randomly selected case re-
ports (ca. 13,000 words; i.e. the average length of
the reports is ca. 140 words, with a standard devia-
tion of 12 words) for testing and grammar develop-
ment. Linguistically, these reports are quite distin-
guished: they are written in a ?telegram?-style, with
verbs largely being absent (a rough examination of
the corpus showed that only about every 43rd token
is a verb, compared to every 11th in a comparable
corpus of German newspaper). Also, the vocabulary
is rather controlled, with very little variation?this
of course is good news for automatically process-
ing such input. On the discourse level we also find
a strict structure, with a fixed number of semanti-
cally grouped sections. E.g., information about the
diagnosis made will normally be found in the sec-
tion ?Kritischer Bericht? (critical report), and the in-
formation in the ?Makroskopie? and ?Mikroskopie?
sections (macroscopy and microscopy, respectively)
will be about the same parts of the sample, but on
different levels of granularity.
The last peculiarity we note is the relatively high
frequency of compound nouns. These are especially
important for our task, since technical concepts in
German tend to be expressed by such compound
nouns (rather than by noun groups). While some
2What is shown in the figure is actually already the result
of a preprocessing step; the cases as stored in the database con-
tain patient data as well, and are formatted to comply with the
HL7 standard for medical data (The HL7 Consortium, 2003).
Moreover, the italicisation in the input representation and the
numbers in square brackets are added here for ease of refer-
ence and are not part of the actual representations maintained
by the system.
of those will denote individual concepts and hence
will be recorded in the domain lexicon, others must
be analysed and their semantics must be composed
out of that of their parts (see below).
2.3 Lung Pathology Knowledge in OWL
The result of processing such reports with LUPUS
is a representation of (relevant aspects of) their con-
tent. This representation has the form of instances
of concepts and assertions of properties that are de-
fined in an ontology, which constitutes the domain
knowledge of the system (at the moment focussed
on pathologies of the lung). This ontology is spec-
ified in OWL DL (W3C WebOnt WG, 2004), a ver-
sion of OWL with a formal semantics and a complete
and decidable calculus. Consequently, the content
of the texts is represented in OWD DL as well, and
so the knowledge base of the system consists of the
ontology and the instances.
The ontology we use is compiled out of sev-
eral medical sources (such as UMLS (The UMLS
Consortium, 2003) and SNOMED (SNOMED Inter-
national, 2004)), but since these sources often were
not intended for machine reasoning (i.e., are not
necessarily consistent, and use rather loosely de-
fined relations), considerable effort has been spent
(and is being spent) on cleaning them up.3 At the
moment, about 1,000 domain-level concepts and
ca. 160 upper-level concepts have been identified,
which are connected by about 50 core relation types.
To our knowledge, this makes it one of the biggest
OWL-ontologies currently in use.
Besides representing concepts relevant to our do-
main, the ontology also lists properties that in-
stances of these concepts can have. These proper-
ties are represented as two-place relations; to give
an example, the property ?green? attributed to an
entity x will in our system not be represented as
?green(x)?, but rather as something like ?colour(x,
green)?. This allows us to enforce consistency
checks, by demanding that for each second-order
predicate (colour, malignity, consistency, etc.) ap-
propriate for a given concept only one value is
chosen.4 This choice of representation has conse-
quences for the way the semantics of adjectives is
represented in the lexicon, as we will see presently.
3There are several current research projects with a similar
aim of extracting stricter ontologies from sources like those
mentioned above (see e.g. (Schulz and Hahn, 2001; Burgun and
Bodenreider, 2001)), and this is by no means a trivial task. The
present paper, however, focuses on a different (but of course in-
terdependent) problem, namely that of extracting information
such that it can be represented in the way described here.
4Technically, these constraints are realised by functional
data-properties relating entities to enumerated data types.
An example report (with translation):
<befund>
<makroskopie>
Stanzzylinder von 15 mm La?nge und 1 mm Durchmesser. [1]
</makroskopie>
<mikroskopie>
Stanzbiopsat [2] eingenommen durch Infiltrate einer soliden malignen epithelialen Neoplasie. [3]
Die Tumorzellen mit distinkten Zellgrenzen [4], zum Teil interzellula?r Spaltra?ume [5], zwischen
denen stellenweise kleine Bru?cken [6] nachweisbar sind. Das Zytoplasma leicht basophil,
z.T. auch breit und eosinphil, [7] die Zellkerne hochgradig polymorph mit zum Teil
multiplen basophilen Nukleolen. [8] Deutliche desmoplastische Stromareaktion. [9]
</mikroskopie>
<kritischer bericht>
Stanzbiopsat aus einer Manifestation eines soliden Karzinoms [10]
(klinisch rechte Lunge apikal).
</kritischer bericht>
<kommentar>
...
</kommentar>
</befund>
( Biopsy cylinder of 15 mm length and 1 mm diameter. | Biobsy infiltrated by a solid
malignant epithelial neoplasia. The tumor cells with distinct cell borders, partially intercel-
lular spatia, between which sporadically small bridges are verifiable. The cytoplasm lightly
basophil, in part also broad and eosinphile, the nuclei highly polymorphic, partially with
multiple basophile nucleoli. Distinct desmoplastic stroma reaction. | Biopsy cylinder from
a manifestation of a solid carcinoma (clinical right lung apical). )
?
Intermediate Representation (excerpt):
[2] unspec det(x2) ? punch biopsat(x2) [3] unspec plur det(x3) ? infiltrate(x3, x4) ?
indef det(x4) ? solid(x4) ?malign(x4) ? epithelial(x4) ? neoplasia(x4)
[4] def plur det(x5)?tumorcell(x5)?with rel(x5, x6)?unspec plur det(x6)?distinctive(x6)?
cell borders(x6) [7] spec det(x9) ? low degree(d1) ? basophile(x9, d1) ? partially(d2) ?
broad(x9, d2) ? eosinphile(x9, d2) ? cytoplasm(x9)
[8] def plur det(x10) ? high degree(d3) ? polymorpheous(x10, d3) ? nucleus(x10) ?
with rel(x10, x11)?unspec plur det(x11)?partially(d4)?multiple(x11, d4)?basophile(x11)?
nucleoli(x11)
?
Target Representation (excerpt):
<Malignant Epithelial Neoplasm C0432650 rdf:ID=?neoplasia x4?>
<solidity rdf:datatype=?http://www.w3.org/2001/XMLSchema#float?>1.0</solidity>
</Malignant Epithelial Neoplasm>
<Cell Border C0032743 rdf:ID=?cell border x61?/>
<Tumor cells C0431085 rdf:ID=?tumor cell x52?>
<hasBoundary rdf:resource=?file:...#cell boundary x61?/>
</Tumor cells C0431085>
<cytoplasm C0326583 rdf:ID=?cytoplasm1?>
<broad rdf:datatype=?http://www.w3.org/2001/XMLSchema#float?>1.0</broad>
<eosinphil rdf:datatype=?http://www.w3.org/2001/XMLSchema#float?>1.0</eosinphil>
<basophil rdf:datatype=?http://www.w3.org/2001/XMLSchema#float?>0.5</basophil>
</cytoplasm>
Figure 1: Input, Intermediate and Target Representation
Figure 2: Flowchart
Using OWL DL as a representation format for
natural language content means certain limitations
have to be accepted. Being a fragment of FOL, it
is not expressive enough to represent certain finer
semantic details, as will be discussed below. How-
ever, the advantage of using an emerging standard
for delivering and sharing information outweighs
these drawbacks.
3 Implementation
3.1 Overview
As mentioned above, most of the sentences in our
corpus do not contain a finite verb; i.e., according to
standard rules of grammar they are elliptical. While
a theoretically motivated approach should strive to
resolve this ellipsis contextually (for example as de-
scribed in (Schlangen, 2003)), in view of the in-
tended application and for reasons of robustness we
have decided to focus only on extracting informa-
tion about the entities introduced in the reports?
that is, on recognising nominal phrases, leaving
aside the question of how verbal meanings are to
be resolved.
Our strategy is to combine a ?shallow? prepro-
cessing stage (based on finite-state methods and sta-
tistical approaches) with a symbolic phase, in which
the semantics of the NPs is assembled.5 A require-
ment for the processing is that it must be robust, in
two ways: it must be able to deal with unknown
tokens (i.e., ?out of vocabulary? items) and with un-
known structure (i.e., ?out of grammar? construc-
tions), degrading gracefully and not just failing.
Figure 2 shows a flow chart of the system; the
individual modules are described in the following
sections.
5This strategy sits somewhere between Information Extrac-
tion, where also only certain phrases are extracted, for which,
however, normally no compositional semantics is computed,
and ?full? parsing, where such a semantics is computed only if
the whole input can be parsed.
3.2 Preprocessing
The first step, tokenising and sentence splitting, is
fairly standard, and so we skip over it here. The
second step, morpho-syntactic analysis, is more in-
teresting. It is performed by an independently de-
veloped module called TAGH, a huge finite-state
machine that makes use of a German word-stem
lexicon (containing about 90,000 entries for nouns,
17,000 for verbs, 20,000 adjectives and adverbs,
and about 1,500 closed class word forms). The
transducer is implemented in C++ and has a very
high throughput (about 20,000 words per second
on modern machines). The coverage achieved on
a balanced corpus of German is around 96% (Ju-
rish, 2003), for our domain the lexicon had to be
extended with some domain specific vocabulary.
To give an example of the results of the analysis,
Figure 3 shows (excerpts of) the output for Sentence
2 of the example report. Note that this is already the
POS-disambiguated output, and we only show one
analysis for each token. In most cases, we will get
several analyses for each token at this stage, differ-
ing with respect to their part of speech tag or other
morphological features (e.g., case) that are not fully
determined by their form. (The average is 5.7 anal-
yses per token.) Note also that the actual output of
the module is in an XML format (as indeed are all
intermediate representations); only for readability is
it presented here as a table.
Another useful feature of TAGH is that it pro-
vides derivational information about compound
nouns. To give an example, (1) shows one analysis
of the noun ?Untersuchungsergebnis? (examination
result).
(1) Untersuchungsergebnis
untersuch(V)?ung(n)/s#Ergebnis
As this shows, the analysis gives us information
about the stems of the compounds; this can be used
to guide the computation of the meaning of the com-
plex noun. However, this meaning is not fully com-
Token Type Analysis
Stanzbiopsat Stanzbiopsat [NN Gender=neut Number=sg Case=nom]
eingenommen ein|nehm?en [VVPP2]
durch durch [APPR]
Infiltrate Infiltrat [NN Gender=neut Number=pl Case=acc]
einer eine [ARTINDEF Number=sg Case=gen Gender=fem]
soliden solid [ADJA Degree=pos Number=sg Case=gen Gender=* ADecl=mixed]
malignen maligne [ADJA Degree=pos Number=sg Case=gen Gender=* ADecl=mixed]
epithelialen epithelial [ADJA Degree=pos Number=sg Case=gen Gender=* ADecl=mixed]
Neoplasie Neoplasie [NN Gender=fem Number=sg Case=*]
Figure 3: Result of Morphological Analysis / POS-tag disambiguation for Sentence 2
positional, as the nature of the relation between the
compounds is underspecified. We represent this by
use of an underspecified relation rel that holds be-
tween the compounds, and which has to be specified
later on in the processing chain.
The output of this module is then fed into a statis-
tically trained POS-disambiguator, which finds the
most likely path through the lattice of morpholog-
ical analyses (Jurish, 2003) (with an accuracy of
96%). In cases where morphology failed to provide
an analysis, the syntagmatically most likely POS tag
is chosen. At the end of this stage all analyses for
a given token agree on its part of speech; however,
other features (number, person, case, etc.) might
still not be disambiguated.
At the next stage, certain sequences of tokens
are grouped together, namely multi-word expres-
sion that denote a single concept in our ontology
(e.g., ?anthrakotische Lymphknoten? denotes a sin-
gle concept, and hence is marked as one token of
type NN at this step), and certain other phrases (e.g.
specifications of spatial dimensions) which can be
recognised easily but would require very specialised
grammar rules later on.6
Then, the domain-specific lexicon is accessed,
which maps ?concept names? (nouns, or phrases as
recognised in the previous step) to the concept IDs
used in the ontology.7 Tokens for which there is no
entry in that lexicon, and which are hence deemed
?irrelevant? for the domain, are assigned a ?dummy?
semantics appropriate for their part of speech, so
that they do not confuse the later parsing stage.
(More details about this kind of robustness will be
given shortly.)
6See for example (Grover et al, 2002) for a discussion of
the utility of a named entitiy recognition preprocessing stage
for robust symbolic parsing.
7Note that this lexicon is one single resource out of which
also the domain specfic additions to the morphology-lexicon
and the list of multi-word expressions are compiled.
3.3 Chunk Parsing
Next, the analyses of the tokens are transformed
into a feature structure format, and are passed to
the parsing component.8 The output of this stage
is an intermediate semantic representation of (as-
pects of) the content (of which the notation shown
in 1 is a variant). This format is akin to traditional
logical forms and still has to be mapped into OWL;
we decided on this strategy because such a format
is closer to surface structure and hence easier to
build compositionally (see discussion below in Sec-
tion 3.5). Also note that the semantics is ?flat?, and
does not represent scope of quantifiers (which only
very rarely occur in our data, and cannot be repre-
sented OWL in any case).
To get an idea of the feature geometry used by the
grammar see Figure 4; this figure also shows the se-
mantic representations generated at this stage (in a
different notation than in Figure fig:reps). Note the
?simulation? of typing of feature structures, and the
representation of properties via second order prop-
erties as discussed above. Chunk parsing is per-
formed by a chart parser running a grammar that is
loosely inspired by HPSG (Pollard and Sag, 1994).9
The grammar contains context-free rules for fairly
complex NPs (allowing arguments of Ns, modifi-
cation by PPs, and coordination). When extracting
chunks, the strategy followed by the system is to al-
ways extract the largest non-overlapping chunks.10
An example might help to illustrate the robust-
8Up until here, all steps are performed in one go for the
whole document. The subsequent steps, on the other hand, are
performed incrementally for each sentence. This allows the
system to remove ambiguity when it occurs, rather than having
to maintain and later filter out different analyses.
9The parser is implemented in PROLOG, and based on the
simple algorithm given in (Gazdar and Mellish, 1989). It also
uses code by Michael Covington for dealing with feature struc-
tures in PROLOG, which is described in (Covington, 1994).
10That strategy will prefer lenght of individual chunks over
coverage of input, for example when there is one big chunk and
two overlapping smaller chunks at each side of that chunk, that
however together span more input.
??
?
?
?
?
?
?
?
?
?
?
?
?
SYN
?
?
?
?
?
CAT np
HEAD
?
?
CASE nom
AGR
[
NUM sg
PER dr
GEN neu
]
?
?
COMP nil
?
?
?
?
?
SEM
?
?
?
RESTR
?
[
RELTYPE det
TYPE unspec
ARG x3
][
RELTYPE ent
TYPE stanzbiopsat
INST x3
]
?
INDEX x3
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
SYN
?
?
?
?
?
CAT np
HEAD
?
?
CASE acc
AGR
[
NUM pl
PER dr
GEN fem
]
?
?
COMP nil
?
?
?
?
?
SEM
?
?
?
?
?
?
?
?
?
RESTR
?
[
RELTYPE det
TYPE unspec plur
ARG x1
]
[
RELTYPE ent
TYPE infiltrat
ARG x2
INST x1
]
[
RELTYPE det
TYPE indef
ARG x2
]
[
RELTYPE prop
TYPE consistency
ARG x2
VALUE solid
]
[
RELTYPE prop
TYPE malignity
ARG x2
VALUE malign
][
RELTYPE prop
TYPE position
ARG x2
VALUE epithelial
]
[
RELTYPE ent
TYPE neoplasia
INST x2
]
?
INDEX x1
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
Figure 4: The chunks extracted from Sentence 2
ness of the system. (2) shows a full syntactic analy-
sis of our example sentence. Our system only recog-
nises the chunks indicated by the brackets printed
in bold typeface: since it can?t recognise the pred-
icative use of the verb here, it is satisfied with just
building parses for the NPs it does recognise. (The
round brackets around the analysis of the first word
indicate that this parse is strictly speaking not cor-
rect if the full structure is respected.)
(2) [NP ([NP) [NOM Stanzbiopsat] (]), [ADJP [VVPP2
eingenommen] [PP [P durch] [NP Infiltrate einer
soliden malignen epithelialen Neoplasie.]]]]?
This is an example of the system?s tolerance to un-
known structure; (3) shows a (constructed) exam-
ple of an NP where the structure is covered by the
grammar, but there are ?unknown? (or rather, irrele-
vant) lexical items. As described above, we assign
a ?dummy semantics? (here, a property that is true
of all entities) to words that are irrelevant to the do-
main, and so parsing can proceed.
(3) Solid, hardly detectable tumor cells. ?
solid(x) ? true(x) ? tumor cell(x)
A few last remarks about the grammar. First, as
shown in Figure 4, NPs without determiner intro-
duce an underspecified relation unspec det, and in-
formation about definiteness and number of deter-
miners is represented. This means that all infor-
mation to do discourse processing (bridging of def-
inites to antecedents) is there; we plan to exploit
such information in later incarnations of the sys-
tem. Secondly, it can of course occur that there is
more than one analysis spanning the same input;
i.e., we can have syntactic ambiguity. This will be
dealt with in the transformation component, where
domain knowledge is used to only let through ?plau-
sible? analyses.
Lastly, prepositions are another source for under-
specification. For instance, given as input the string
(4), the parser will compute a semantics where an
underspecified with rel connects the two entities
tumor and alveolar; this relation will be specified
in the next step, using domain knowledge, to a rela-
tion contains.
(4) Ein Tumor mit freien Alveolaren.
A tumor with free alveolars.
3.4 Resolution of Underspecification using
Ontologies
As described in the previous sections, the output of
the parser (and of the morphological analysis) might
still contain underspecified relations. These are re-
solved in the module described in this section. This
module sends a query to a reasoning component that
can perform inference over the ontology, asking for
possible relations that can hold between (instances
of) entities. For example (4) above, this will return
the answer contains, since the ontology specifies
that ?alveolars? are parts of tumours (via a chain of
is-a-relations linking tumours with cells, and cells
with alveolars). In a similar way the underspecifi-
cation of compound nouns is resolved. This process
proceeds recursively, ?inside-out?, since compound
nouns can of course be embedded in NPs that are
parts of PPs, and so on.
3.5 Mapping LF to OWL
In the final step, the logical forms produced by the
parser and specified by the previous module are
transformed into OWL-compliant representations.
This process is fairly straightforward, as should be
clear from comparing the intermediate representa-
tion in Figure 1 with the target representation: a)
unique identifiers for the instances of concepts are
generated; b) in cases of plural entities (?three sam-
ples? ? card(x, 3) ? sample(x)), several separate
instances are created; and c) appropriateness condi-
tions for properties are applied: if a property is not
defined for a certain type of entity, the analysis is
rejected.
This translation step also handles potential syn-
tactic ambiguity, since it can filter out analyses
if they specify inconsistent information. Note
also that certain information, e.g. about second
order properties, might be lost, due to the re-
stricted expressivity of OWL. E.g., an expres-
sion like ?highly polymorpheous? in Figure 1 ei-
ther has to be converted into a representation like
polymorphism : high, or the modification is lost
(polymorpheous(x)).
This ends our brief description of the system. We
now discuss a preliminary evaluation of the mod-
ules, related work, and further extensions of the sys-
tem we are currently working on or which we are
planning.
4 Evaluation
At the moment, we have only evaluated the mod-
ules individually, and?since the system is still un-
der developement?this evaluation only provides a
snapshot of the current state of developement. A
full-scale evaluation of the whole system in its ap-
plication context is planned as soon as the modules
are finalised; plans for this are discussed below.
The coverage of the morphology module and the
POS-tagger have already been reported above, so we
concentrate here on the chunk-parser. To evaluate
this module, we have manually annotated the NPs
in a randomly selected test set of 20 reports (ca.
2,800 words; we found about 500 NPs). The re-
ports were then morphologically analysed and POS-
filtered, and the results were manually checked and
corrected, to ensure that the input was optimal and
really only the performance of the chunker was eval-
uated. We then computed precision and recall based
on two different matching criteria: for exact match-
ing, where only exact congruence of chunks counts,
a precision of 48% and a recall of 63% was com-
puted; the numbers improve when partial matches,
i.e. smaller chunks within the target chunk, receive
partial credit (by a factor of .25), resulting in a (re-
laxed) precision of 61% and a (relaxed) recall of
80%. This difference can be explained by the fact
that some of the more complex NP-constructions
(with quite complex modifications) in our data are
not yet covered by the grammar, and only their con-
stituent NPs are recognised.
Note that this evaluation just takes into account
the boundaries of the chunks and not the correct-
ness of the computed semantic representations. For
a full-scale evaluation, we will manually annotate
these NPs with semantic representations, and we
will use this to compute precision and recall also
with respect to semantics, and ultimately with re-
spect to sample search queries. This annotation,
however, is very resource-intensive, and so will only
be done once the modules have been finalised.
5 Related Work
Acquisition of information from texts especially
from the medical domain is a lively research area.
Among the many projects in that field, we share
some of our central concerns with the medSyn-
diKAte system (Hahn et al, 2002): robust text anal-
ysis of medical reports; a background knowledge
base for guiding the analysis and storing the text?s
content; emphasis on handling co-reference phe-
nomena. What distinguishes LUPUS from medSyn-
diKAte, though, is foremost the parsing scheme: the
language used in the reports analysed by Hahn et al
is much closer to ?natural? language in that it con-
tains sentences with tensed verbs. Accordingly, they
use a variant of dependency parsing which is driven
by verb information. As described in Section 2.2
above, this is not an option for us, given the style of
our input texts, and hence our data renders a bottom-
up chart parsing approach much more promising.
Besides this difference, the work in medSynDiKAte
predates the emergence of XML/web ontology stan-
dards and thus uses an earlier description logic
knowledge representation language; we are hoping
that by using a standard we will be able to allow
even future semantic web technologies to work with
our data.
As for the robust analysis side, (Grover et al,
2002), also use a similar preprocessing pipeline
in combination with parsing. However, they also
focus on more ?natural? input texts (Medline ab-
stracts), and they use statistical rather than sym-
bolic/ontology based methods for computing the
meaning of compound nouns.
6 Summary and Further Work
We have described LUPUS, an NLP system that
makes use of a domain ontology to guide extraction
of information about entities from medical texts,
and represents this information as instances of con-
cepts from that ontology. Besides its direct use for
content-based search on these texts, the fact that the
system relies entirely on emerging semantic web
standards will make the resulting annotated infor-
mation usable for all kinds of agents working with
such data.
As a next step, we plan to add discourse process-
ing to the pipeline (see e.g. (Hahn et al, 1998) for
a discussion why such a step is required even for
such relatively simple texts). As mentioned above,
the prerequisite information (about definite articles,
for example) is already there; we plan to use the
available domain knowledge to guide the search for
antecedents for bridging. As a more technical im-
provement we are investigating ways of making the
architecture less pipeline-y, and to integrate domain
reasoning in computing edges in the chart. Lastly,
we are also working on a large-scale evaluation of
the system, by manually annotating reports to com-
pute precision and recall.
Acknowledgements
We thank the anonymous reviewers for their helpful
comments. Thanks are also due to Thomas Hanneforth
and Bryan Jurish for their help with integrating their
modules, and to our student assistant Sebastian Maar for
doing much of the actual coding.
References
Anita Burgun and Oliver Bodenreider. 2001. Mapping
the UMLS semantic network into general ontologies.
In Proceedings of the AMIA Symposium.
Michael A. Covington. 1994. GULP 3.1: An extension
of prolog for unification-based grammar. Technical
Report AI-1994-06, University of Georgia.
F. Demichellis, V. Della Mea, S. Forti, P. Dalla Palma,
and C.A. Beltrami. 2002. Digital storage of glass
slide for quality assurance in histopathology and cy-
topathology. Telemedicine and Telecare, 8(3):138?
142.
Gerald Gazdar and Chris Mellish. 1989. Natural Lan-
guage Processing in PROLOG. Addison-Wesley,
Wokingham, England.
Claire Grover, Ewan Klein, Mirella Lapata, and
Alex Lascarides. 2002. XML-based NLP tools for
analysing and annotating medical language. In Pro-
ceedings of the 2nd Workshop on NLP and XML,
Taipei, Taiwan, September.
Udo Hahn, Martin Romacker, and Stefan Schulz. 1998.
Why discourse structures in medical reports matter
for the validity of automatically generated text knowl-
edge bases. In MedInfo ?98 ? Proceedings of the 9th
World Congress on Medical Informatics, pages 633?
638, Seoul, Korea, August.
Udo Hahn, Martin Romacker, and Stefan Schulz. 2002.
Creating knowledge repositories from biomedical re-
ports: The medsyndikate text mining system. In Pa-
cific Symposium on Biocomputing, pages 338?349,
Hawai, USA, January.
Bryan Jurish. 2003. Part-of-speech tagging with finite
state morphology. In Proceedings of the Workshop on
Collocations and Idioms: Linguistic, Computational
and Psycholinguistic Perspectives, Berlin, Germany,
September.
Carl Pollard and Ivan Sag. 1994. Head-Driven Phrase
Structure Grammar. CSLI / The University of
Chicago Press, Chicago and London.
Kai Saeger, Karsten Schlu?ns, Thomas Schrader, and Pe-
ter Hufnagl. 2003. The virtual microscope for routine
pathology based on a pacs system for 6 gb images.
In Proceedings of the 17th International Congress on
Computer Assisted Radiology and Surgery (CARS),
pages 299?304, London, UK, June.
David Schlangen. 2003. A Coherence-Based Approach
to the Interpretation of Non-Sentential Utterances in
Dialogue. Ph.D. thesis, School of Informatics, Uni-
versity of Edinburgh, Edinburgh, UK.
Stefan Schulz and Udo Hahn. 2001. Medical knowledge
engineering?converting major portions of the umls
into a terminological knowledge base. International
Journal of Medical Informatics.
J. Slodowksa, K. Kayser, and P. Hasleton. 2002. Tele-
consultation in the chest disorders. European Journal
for Medical Research, 7(Suppl.I):80.
SNOMED International. 2004. SNOMED clinical terms.
http://www.snomed.org/index.html.
The HL7 Consortium. 2003. HL7 version 2.5 ANSI
standard, June. http://www.hl7.org.
The UMLS Consortium. 2003. UMLS release 2003AC.
http://www.nlm.nih.gov/research/umls/.
W3C WebOnt WG. 2004. OWL web ontology language
overview. W3C recommendation, W3C, Febru-
ary. http://www.w3.org/TR/2004/REC-owl-features-
20040210/.
Causes and Strategies for Requesting Clarification in Dialogue
David Schlangen
Universita?t Potsdam
das@ling.uni-potsdam.de
Abstract
We do two things in this paper. First, we
present a model of possible causes for request-
ing clarifications in dialogue, i.e., we classify
types of non-understandings that lead to clar-
ifications. For this we make more precise the
models of communication of (Clark, 1996) and
(Allwood, 1995), relating them to an indepen-
dently motivated theory of discourse seman-
tics, SDRT (Asher and Lascarides, 2003). As
we show, the lack of such a model is a prob-
lem for extant analyses of clarification moves.
Second, we combine this model with an ex-
tended notion of ?confidence score? that com-
bines speech recognition confidence with dif-
ferent kinds of semantic and pragmatic confi-
dence, and argue that the resulting processing
model can produce a more natural clarification
and confirmation behaviour than that of current
dialogue systems. We close with a descrip-
tion of an experimental implementation of the
model.
1 Introduction
It is widely accepted that it would be desirable for dia-
logue systems to be able to produce and understand the
whole range of Clarification Requests (CRs) that can be
found in human-human dialogue, as exemplified in the
following:
(1) a. A: I talked to Mary-Ann Parker-Tomlison.
B: Parker-WHO?
b. A: Well, I?ve seen him.
B: Sorry, you have or you haven?t?
c. A: Did you talk to Peter?
B: Peter Miller?
d. A: Did you bring a 3-5 torx?
B: What?s that?
A precondition for fulfilling this desideratum is a de-
tailed analysis of the communication problems that lead
to the need for clarification. As we show in this paper,
extant approaches to CR do not satisfy this precondi-
tion. We propose that a good starting-point for devel-
oping a more general analysis is a multi-levelled model
of communication along the lines of (Clark, 1996) and
(Allwood, 1995), distinguishing (among other things) be-
tween acoustic understanding and semantic understand-
ing.1 We explore such a model from the perspective
of generating and interpreting CRs, making the central
concepts of the model precise by relating it to an inde-
pendently motivated model of discourse semantics called
SDRT (Asher and Lascarides, 2003).
Deciding on whether to produce CRs is part of the
Confirmation Strategy (CS) of a dialogue system (cf.
(San-Segundo et al, 2001), inter alia). An explicit con-
firmation of an understanding can be sought via a CR,
whereas implicit confirmation can be sought by display-
ing the system?s understanding:
(2) a. Explicit confirmation: ?Did you say you
want to leave from Potsdam??
b. Implicit confirmation: ?From Potsdam. To
where??
Current dialogue systems base their decision on the CS
to follow only on their confidence in the speech recogni-
tion results. It would be desirable, however, if they could
clarify or confirm other hypotheses as well, for example
about reference resolution, depending on their confidence
1Several recent papers (Gabsdil, 2003; Larsson, 2003) have
followed a similar approach, but with a somewhat narrower fo-
cus. (Gabsdil, 2003) is mostly concerned with CRs reacting to
speech recognition, while (Larsson, 2003) offers a similar, but
less fine-grained classification and deals more with integrating
CRs into a specific kind of dialogue management strategy.
in that resolution:
(3) User: Send the file to Peter.
System a: Do you mean Peter Miller?
System b: Will send the file to Peter Miller. Any-
thing else?
Moreover, confidences on different levels of processing
should be allowed to interact. In a situation where the
speech recogniser cannot decide between the hypotheses
?Sandy? and ?Andy? for a certain input, but where the
former proper name can be resolved to a more salient dis-
course referent than the latter, a dialogue system should
ideally prefer the former hypothesis and choose implicit
confirmation (variant A below), rather than explicitly
clarifying which alternative to choose (variant B):
(4) User: Send the file to {Sandy | Andy}.
Sys a: To Sandy, OK.
Sys b: Did you say Sandy or Andy?
The remainder of the paper is organised as follows. Af-
ter presenting an initial classification of CRs and dis-
cussing extant approaches in the next section, we propose
in Section 3 a model of causes for requesting clarification.
Building on this theoretical model we turn in Section 4 to
extending the concept of confidence in a hypothesis in or-
der to produce the CS behaviour sketched above. We also
discuss initial findings from an experimental implemen-
tation of this idea.
2 Clarification Requests
2.1 A First Classification
The examples in (1) above together with (5) below il-
lustrate the wide range of CRs that can occur in dia-
logues, varying with respect to their form (from con-
ventional forms (5-a) to full sentences ((1-d),(5-c-i) and
(5-c-ii)), to sentential fragments ((1-a),(1-b),(1-c),(5-b-i)
and (5-b-ii))) and with respect to their function (clarify-
ing acoustic understanding ((5-a) and possibly those in
(1)); reference ((1-c),(1-d),(5-b-ii) and possibly (1-a) and
(5-b-i)); or pragmatic impact (the examples in (5-c))).
(5) a. A: Did you talk to Peter?
B: Sorry? / Pardon? / You what?
b. (i) A: Did you bring a 3-5 torx?
B: A what?
(ii) A: George Bush is in hospital.
B: Junior or senior?
[from (Gabsdil, 2003)]
c. (i) A: What time is it?
B: Do you want to leave?
(ii) A: Can you pass me the salt?
B: Is that a question or a request?
What the questions in these examples have in common
is that, unlike ?normal? questions, they are not about the
state of the world in general, but rather about aspects of
previous utterances: they indicate a problem with under-
standing that utterance, and they request repair of that
problem. We take this to be the defining features of CRs.
Note that this definition includes correctional uses of CRs
as illustrated in (6); in this case the problem is taken to
originate on the side of the speaker of the original utter-
ance rather than on the side of the CR initiator.
(6) a. A: Dear police men....
B: Police men?
A: Alright then, police people.
b. Student: 3 + 4 = 8
Teacher: 3 + 4 = 8?
We will focus on the possible functions of CRs in this pa-
per, leaving the question of how to map CR form to that
function to further work.2 We simply observe at this point
that some CRs indicate the kind of understanding prob-
lem that occurred; e.g., in (1-c) and (5-b-ii) this seems
to be a problem with identifying the intended referent;
in (1-d) and (5-b-i) a lexical problem; in (5-c) a problem
with recognising the intention behind the utterance. This
observation will form the basis of the classification devel-
oped below in Section 3, where we further develop extant
models to make the pre-theoretic notion of understanding
precise.
Contrasting (1-c) and (5-b-ii) with (7) below illustrates
another dimension for classification. Where the former
two CRs ask for a confirmation of a hypothesis, the latter
asks for a repetition (or reformulation) of the problematic
element.
(7) A: I talked to Shanti.
B: WHO?
We call this dimension severity; this represents the intu-
ition that a problem that leads to a request for repetition
is more severe than one that leads to a request for con-
firmation; we will make this notion of severity precise in
Section 4. Note that a confirmation request can be re-
alised as an alternative question, as in (5-b-ii) and (4) b,
or as a y/n-question, as in (1-c).
Lastly, we also distinguish between CRs that point out
a problematic element in the original utterance, and those
that don?t. The former category is illustrated by the CRs
in (1) and (5-b), the latter by those in (5-a) and (5-c). We
call this dimension extent.3
2(Purver et al, 2001) investigates such a mapping, based on
the classification discussed below in Section 2.2.
3The dimensions for classification introduced here are re-
lated to, but different in some aspects from those used in (Lars-
son, 2003). Our term ?CR? covers what Larsson calls negative
feedback as well as what he calls checking feedback, whereas
Before we finally come to the description of the di-
mension level of understanding in the next Section, we
will briefly look at an earlier analysis of CR that does not
make these distinctions.
2.2 Previous Analyses
In a number of papers (Ginzburg and Cooper, 2001;
Purver et al, 2001), Jonathan Ginzburg and colleagues
have developed an influential analysis of CR. The authors
define two readings that can be ascribed to CRs, which
they name the constituent reading and the clausal read-
ing.4 (8-b) shows paraphrases of these readings for the
CR in (8-a).5
(8) a. A: Did Bo leave? ? B: Bo?
b. clausal: Are you asking whether Bo left?
constituent: Who?s Bo?
These readings are defined informally by (Ginzburg and
Cooper, 2001) (henceforth G&C) as follows: the clausal
reading ?takes as the basis for its content the content of
the conversational move [? speech act, D.S.] made by
the utterance being clarified. [It] corresponds roughly to
?Are you asking / asserting that X??, or ?For which X are
you asking / asserting that X??.?; the constituent reading
is a reading ?whereby the content of a constituent of the
previous utterance is being clarified.?
Let?s look at the conditions under which a dialogue
participant (be that a dialogue system or a human) might
intend one or the other reading. We begin with the situa-
tion shown in (9-a), taken from G&C.
(9) a. A: Did Bo leave? ? B: Who?
b. clausal: For which x are you asking
whether x left?
constituent: Who?s Bo?
severity gives a finer classification of what he calls ?eliciting
feedback?. Larsson gives a classification comparable to our ex-
tent dimension only indirectly, via a classification of the forms
used to express CR as syntactically fragmental or complete;
however, since syntactically complete utterances can neverthe-
less target individual elements (?Which Peter are you talking
about??), these categorisations are not congruent.
4They also mention that a third reading might be needed,
namely a lexical reading in which ?the surface form of the ut-
terance is being clarified, rather than the content of the conver-
sational move. This reading therefore takes the form ?Did you
utter X??.? (Purver et al, 2001). However, the authors do not
offer a formalisation of this reading, so we will concentrate on
the two readings for which they do.
5These readings are realised technically by a straightforward
formalisation of these paraphrases in an HPSG framework, us-
ing an illocutionary-act relation for the clausal reading and a
relation content for the clausal readings, where both relations
take signs as arguments. Since the formalisation is so close to
the paraphrases (and is in any case not backed up by a formal
semantics of the predicates used), we can use in the following
arguments just the paraphrases without missing crucial details.
It seems that the clausal reading is appropriate both in
situations where A failed to recognise the name acous-
tically as well as when she failed to resolve the refer-
ence. An answer to this question will always resolve both
kinds of problems; i.e., this reading does not make a dif-
ference between these kinds of understanding problems.
The constituent reading, on the other hand, does, and is
only appropriate for repetition requests targeting the se-
mantic/pragmatic problem ?reference resolution.?
The next example, also from G&C, shows a CR that
has the form of a reformulation of the original con-
tent. In this case a constituent reading is not available
in G&C?s analysis, since they postulate a phonological-
identity condition for constituent readings which is vio-
lated here.
(10) a. A: Did Bo leave? ? B: My cousin?
b. clausal: Are you asking whether my cousin
left?
constituent (not allowed by G&C): Is the
denotation of ?my cousin? the denotation of
?Bo??
However, in this example the intended distinction be-
tween the readings seems to break down, since the func-
tion of the clausal reading here is to clarify a hypothesis
about the denotation of a referring expression, which in
other cases is the function of constituent readings.
To summarise, G&C?s analysis does not explicitly
record the problem that leads to the need for clarification.
This leads to a loss of information; information which
however will be present on the side of the CR producer
(who knows where the understanding problem occurred)
and presumably should be present on the side of the re-
cipient, who might want to react differently depending
on the assumed problem. It seems that the construct ?Are
you X-ing whether p?? is too general to make these fine-
grained distinctions.6
6There is also a technical problem with this analysis, which
can be illustrated with the following example.
(i) A: Can you pass me the salt? ? B: The salt?
A?s utterance is of course an example of an indirect speech
act. Since G&C assume that the illocutionary force of the
previous utterance is represented in the CR-reading (?Are you
asking/asserting/etc.-ing whether...?) generated by the grammar,
they have to find a way to capture this indirectness. There are
only two, equally unattractive, options to do this: either the au-
thors have to assume that the grammar directly assigns A?s utter-
ance the force request (rather than question), so that the clausal
reading of B?s utterance can be paraphrased as ?Did you request
that I pass the salt??. But interpreting indirect speech acts is a
highly context-dependent task and not something that can be
decided on syntactical grounds alone. The other option is to
stick with the speech act type that is normally associated with
interrogatives, and arrive at a reading that can be paraphrased as
?Are you asking whether I can pass you the SALT??. This, how-
ever, is presumably in most cases not the right interpretation of
Level Clark Allwood Ginzburg et al
4 proposal &
consideration
reaction to
main evocative
function
3 meaning & un-
derstanding
understanding clausal reading;
constituent
reading
2 presentation &
identification
perception lexical reading
1 execution & at-
tention
contact
Figure 1: The four basic levels of communication
We now turn to exploring a model that does make these
distinctions.
3 A Model of Causes for Clarification
3.1 The Fundamental Distinctions
Herb Clark (Clark, 1996) and Jens Allwood (Allwood,
1995) independently developed a model of the (hierar-
chically ordered) tasks involved in communication, as
shown schematically in Figure 1.7 (We have also as-
signed the readings defined by G&C to the appropriate
levels in the last column.) This model can serve as a ba-
sis for classifying the function of CRs. For example, the
CRs shown in (11) can be classified as each targeting a
different level according to the model.
(11) a. [You are sitting in a subway train when A
sits down on the seat next to you, talking.
You might say:] Are you talking to me?
b. A: I saw Peter.
B: What did you say? (I didn?t hear you.)
c. A: I saw Peter.
B: Which Peter?
d. A: My mother is a lawyer.
B: Are you trying to threaten me?
The distinctions made by this model, however, are
still fairly coarse-grained. It seems desirable to further
analyse the levels?and especially the third one, that of
?meaning and understanding??so as to capture for ex-
ample the difference between the CRs in (12) below. We
will do this in the next section.
(12) a. A: I ate a Pizza with chopsticks the
other day.
B: A Pizza with chopsticks on it?
the CR.
7There are significant differences between these two mod-
els; however, for our purposes the similarities dominate and so
we treat the models as terminological variants; keeping in mind
that we simplify both models considerably.
b. A: Please give me the double torx.
B: What?s a torx?
c. A: Please give me the double torx.
B: Which one?
d. A: Every wire has to be connected to
a power source.
B: Each to a different one, or can it be
the same for every wire?
3.2 A More Fine-Grained Model
How shall we further carve up the level ?meaning & un-
derstanding?? One well-known additional distinction that
seems useful is that between literal meaning and speaker
meaning.8 For instance, this distinction is evoked in the
following categorisation given by (Larsson, 2003):
? Semantic Meaning: discourse-independent mean-
ing. E.g. word meanings.
? Pragmatic Meaning: domain-dependent and
discourse-dependent meaning, further split into:
? referential meaning, e.g. referents of pronouns,
temporal expressions;
? pragmatic meaning proper: the relevance of u
in the current context.
This points in the right direction, but still needs to
be made more precise: for instance, what is ?relevance?
here? Where do the examples in (12) fit in that schema?
To make these terms precise, and to add fur-
ther distinctions, we have devised a model that is
closely inspired by how the discourse semantics the-
ory SDRT (Asher and Lascarides, 2003) sets up the syn-
tax/semantics/pragmatics interface. In particular, we use
the idea of using semantic underspecification to allow for
?pragmatic intrusion? into the determination of the truth
value of an utterance; where roughly the underspecified
logical form generated by the grammar corresponds to the
(set of) literal meaning(s) of an utterance, and the prag-
matically resolved LF to the speaker meaning. We also
use SDRT?s idea of spelling out contextual relevance as
the need for determining a rhetorical relation with which
to connect a new utterance to the context, and the con-
cept of speech act related goals (SARGs), i.e. goals that
are conventionally connected to certain types of speech
acts.9 (These ideas will be illustrated with examples be-
low in Section 4 when we discuss the implementation.)
This move allows us to say precisely what constitutes an
understanding problem in this model?namely, a failure
to tackle one (or more) of the precisely defined tasks.
8Which goes back at least to Grice?s studies from the 1960s
reprinted in (Grice, 1989).
9In this paper we concentrate on outlining how this theory
could be used to model clarification and leave further formali-
sation for future work.
Level Description
1 establishing contact
2 speech recognition
3a parsing:
3aa recognising all words
3ab determining syntactic structure
3ac determining a unique syntactic structure
3b resolving underspecification:
3ba reference
3bb tense, scope, presuppositions, lexical
ambiguities, etc.
3c contextual relevance, computing the rhetori-
cal connection
4 recognising speaker?s intentions; evaluating
resulting discourse structure
Figure 2: The fine-grained model
The resulting fine-grained model is shown in Figure 2;
the additional levels are further motivated by the exam-
ples of CRs shown in (13), which indicate problems on
each of these levels (the labels refer to the labels of the
(sub-)levels in the figure).10,11
(13) a. 3aa: see e.g. (1-d) or (5-b-i) above, or:
A: Peter kowtowed again.
B: What does ?kowtow? mean?
b. 3ab:
A: The cat that the mouse that the flee
bit saw slept.
B: Who did what? Again, please.
c. 3ac:
A: I saw a man with a telescope.
B: What do you mean? Did you see a
man who was holding a telescope,
or did you use a telescope to watch
him?
d. 3ba: see e.g. (1-c), (12-c) above.
e. 3bb: see (12-d) above, or:
A: I went to the bank yesterday.
B: As in ?monetary institute?, or in
?going fishing??
f. 3c:
10Note that despite the rather technical names for the levels
this is still a theoretical model of the process of understanding?
one, however, that could be implemented in a dialogue system
(see (Schlangen et al, 2001) or Section 4 below). Note also
that we do not want to make any claims about the psychological
status of these postulated levels. All we claim here is that these
levels (which are independently motivated in SDRT) are useful
for distinguishing types of CRs.
11These CRs are not necessarily very natural sounding; the
point is just that one can construct CRs that target exactly those
postulated levels. The examples are presented here to theo-
retically motivate those levels. We are currently conducting a
detailed corpus analysis to determine the coverage that can be
achieved with this model.
[At court, A being a witness and B the
judge.]
A: Max fell. John pushed him.
B: Witness, do you mean that he fell
because he was pushed by the de-
fendant?
g. 4:
(i) A: My mother is a lawyer.
B: Are you trying to threaten me?
B?: Why are you telling me that?
B??: What do you want to say with that?
(ii) A: Let?s meet next week.
B: My parents in law are visiting
on Tuesday.
A: So are you saying that Tues-
day is good or bad?
To summarise what we have done so far, we have
shown a model that can distinguish in a fine-grained
manner possible problems during the processing (?under-
standing?) of an utterance which can lead to the need for
clarification.12 This models one of the dimensions for
classification which we described in Section 2. What re-
mains to be done is to explain how the problems at each
level can be of different severity, leading to either repeti-
tion or confirmation requests. This we will do in the next
section, where also a general strategy for dealing with
processing hypotheses will be discussed.
4 Clarification Strategies
4.1 Extending the Concept of Confidence Scores
In current spoken dialogue systems there is a very domi-
nant source for understanding problems: speech recogni-
tion (SR). Many existing dialogue systems (cf. e.g. (San-
Segundo et al, 2001)) make use of the confidence scores
returned by SR systems together with each recognition
hypothesis. Based on this value the system can decide
whether to reject the hypothesis (which will lead to a
repetition request, e.g. ?Can you repeat??, ?Pardon??),
whether to confirm it (explicitly with a confirmation re-
quest or implicitly), or whether to accept it without gen-
erating explicit feedback. This strategy is represented
schematically in Figure 3, where the different CSs are
distributed over the space of possible confidence values.
The idea we want to explore here is very straightfor-
ward: this concept of confidence score should be ex-
tended to all levels of processing. At all processing
stages where the system has to rely on ?guesses? (non-
monotonic inferences, heuristics, etc.), it should assign
a confidence value to its hypothesis. These confidence
12This model is backed up by an independently-motivated
formal semantic theory, which however for reasons of space we
cannot present here in any detail; cf. (Asher and Lascarides,
2003) for this.
Reject Confirm Accept
(= Rpt. Request)
expl. impl.
(= Cnfrm. Req.)
Figure 3: Confirmation Strategies
values should then be combined in some principled way
(for example by taking a weighted average), to determine
the Confirmation Strategy (repetition or confirmation re-
quest, implicit confirmation, acceptance) and the level of
processing that is to be indicated as the primary source of
the problem.13
In the simplest case, a system should be able to delay
its decision on a CS until processing of (a certain num-
ber of) the hypotheses is completed. For example, imag-
ine the case of a travel information system based in the
UK. This system might be able to offer flights to Boston
(and so should be able to recognise the input ?Boston?),
but it also knows that there are no trains from the UK to
Boston. So in this case it should be able to make a deci-
sion for one of the hypotheses in the following example.
(14) Sys: Hello. This is TravelUK. How may I help?
User: I want to go to {Brighton | Boston} by train.
The strategy to make use of combined confidence scores
could be implemented in many different systems; for ex-
ample even the rather simple technique of reference res-
olution via salience lists has an inherent quantitative ele-
ment that could be used. However, to make the idea more
precise, we will in the next section describe an experi-
mental implementation of it in a dialogue system that fol-
lows the approach to discourse interpretation described in
the previous section. Such a system should ultimately be
able to produce the whole range of CRs according to the
dimension level of processing as discussed in Section 3.2
as well as along the dimension severity.
4.2 An Experimental Implementation
So far we have said very little about how the theory of
discourse semantics alluded to in Section 3.2 tackles its
various tasks. In a nutshell, the theory SDRT can be seen
as a combination of dynamic semantics (e.g., DRT, (Kamp
and Reyle, 1993)) plus (AI-based) pragmatics. In con-
trast to traditional dynamic semantics, SDRT attempts to
represent the pragmatically preferred interpretation of a
discourse. The central notion of Discourse Update is for-
13This is a generalisation of the approach taken for example
by (Walker et al, 2000), who use the output of the semantic and
pragmatic modules of their dialogue system to dramatically im-
prove the classifier that judges whether a SR hypothesis is cor-
rect or not, compared to a classifier that just uses SR-features.
mulated in SDRT within a precise nonmonotonic logic,
in which one computes the rhetorical relation (or equiv-
alently, the speech act type) which connects the new in-
formation to some antecedent utterance. This speech act
places constraints on content and the speech act related
goals or SARGs; these in turn serve to resolve semantic
underspecification. Note that those SARGs are goals that
are either conventionally associated with a particular type
of utterance or are recoverable by the interpreter from the
discourse context; this distinguishes the goals that inter-
act with linguistic knowledge from goals in general.
The implementation of the theory which we extended
for this paper, RUDI (Schlangen et al, 2001; Schlangen,
2003), works in the domain of appointment scheduling
(we will refer to the extended version as RUDIclar). It
focuses on resolving one particular kind of underspeci-
fication, namely that arising from the need to ?bridge?
definites to their context. To give an example, for (15)
the system computes that the ?Wednesday afternoon? is
?bridged? via the relation ?next? to the time of utterance:
(15) A: What is a good time for you in the next
couple of weeks?
B: Wednesday afternoon would be good.
It does this by non-monotonically inferring the rhetori-
cal relation connecting the second to the first utterance
(Question-Answer Pair), and using constraints on this re-
lation (roughly, times mentioned in the answer must over-
lap with that from the question) to resolve underspeci-
fication. Before we further describe how the algorithm
works, however, we give a couple of examples illustrat-
ing the clarification behaviour of the system.14
Example (16) shows an input where the SR compo-
nent offers two hypotheses that both have to be consid-
ered.15 Let?s assume that there is no salient Monday
the 13th given the dialogue context. In such a situation
we want the system to dramatically lower its confidence
in the Monday hypothesis, leading to a situation where
only the Sunday hypothesis will have to be confirmed,
and only implicitly, rather than having to clarify both hy-
potheses.
14We should stress that RUDIclar is a proof-of-concept im-
plementation of the model presented here and not a proper di-
alogue system. Neither is the system actually connected to a
speech recogniser?we simulate this by annotating the input
with confidence scores?nor does it generate the clarification
forms shown in the examples?rather it produces abstract in-
structions of the form ?confirm element x?, ?request repetition
of element y? etc. which could be used in such a generation.
Moreover, RUDI models an overhearer of a conversation, not an
actual participant. In RUDIclar this is an overhearer that barges
in if it feels the need to clarify something.
15At present the system can only handle two alternative hy-
potheses, where only one constituent may differ.
? mrs2di ? avail
attach
? choose ? avail
antec
? speech
acts
? sa cnstr ? sarg ? resolve ? clarify ? update ?
Figure 4: Schematic Overview of RUDIclar
(16) A: I?m free on {Sunday ?55?| Monday ?45?} the
13th.
Example (17) brings in combined confidence values in
a more subtle way.
(17) A: Let?s meet this weekend.
B: How about {Sunday ?57?| Monday ?43?}?
Here it is not the case that one hypothesis is ruled out
completely; the difference between the hypotheses here is
that one is ?costlier? to maintain. In our approach the dia-
logue ?Let?s meet next weekend. ? How about Monday??
is just about coherent, under a reading where the second
utterance indirectly corrects the plan (a more explicit ver-
sion of this would be ?How about Monday instead??).
This speech act (Plan-Correction), however, is inferred
in RUDIclar with a much lower confidence than the more
direct speech act Plan-Elaboration that is computed for
the Sunday-variant of B?s utterance. Hence, the system
prefers that latter variant and proceeds accordingly.
The previous examples combined an ambiguity intro-
duced by the SR module with confidence scores from fur-
ther levels. However, new ambiguity can also arise dur-
ing these latter processing stages. In (18) the temporal
expression in B?s utterance cannot be uniquely resolved
(and in this sense the utterance is actually slightly inco-
herent, since it violates the uniqueness presupposition of
definites), and so the system has to clarify the intended
reference.
(18) A: Let?s meet this weekend.
B: How about at 3pm?
RUDI: 3pm on Saturday or 3pm on Sunday?
The last example, (19), shows another source for quan-
tified hypotheses: resolving any temporal expression
other than ?tomorrow? to the next day is dispreferred in
the system, and so its confidence in this resolution is low-
ered and it has to be clarified.
(19) A [on a Friday]: Let?s meet this weekend.
B: How about Saturday?
RUDI: You mean tomorrow?
We now sketch how the system works. Reflecting the
modularity of the underlying theory, RUDI(clar) divides
the update process into several stages (shown schemati-
cally in Figure 4). The initial module mrs2di postpro-
cesses the semantic representation provided by the gram-
mar, for example by including underspecified bridging re-
lations for definites. RUDIclar allows logical forms to be
annotated with confidence values (following an approach
similar to that of (Gabsdil and Bos, 2003), associating the
confidence values with labels in an underspecified LF),
and it allows alternative hypotheses as input (only two at
present). In this way we can represent in the system a
situation where the speech recogniser cannot make a de-
cision, as in (16) or (17) above.
At the next stage, an utterance in the context is chosen
to which the current one can be attached via a rhetorical
relation, and this in turn determines which antecedents
for bridging are available. (Should this choice turn out
to lead to failure in successive modules, the system can
backtrack and choose another attachment site.) The
speech act(s) of the current utterance is (are) then inferred
non-monotonically (if there is more than one hypothe-
sis coming from the previous step, this is done for each
of them) from information about the antecedent and the
current utterance and axioms for each relation. The next
module, sa cnstr, tests whether certain constraints on
the meaning of the speech acts are satisfied by the ut-
terances that are being connected. After this, the SARGs
are computed and any remaining underspecification is re-
solved.
Finally, a new module clarify compares (if there is
more than one) and scores the hypotheses, assigning
scores for the bridging decisions and for the speech-act
inferences. Some of the rules used here are shown in
Figure 5. A weighted average is computed, and, based
on the resulting score, the module decides on whether to
launch into a clarification sub-dialogue, and if so, which
clarification strategy to follow. (We set the thresholds for
this and the weights for the average manually to achieve
the behaviour described here; see discussion below.) The
level at which RUDIclar targets the clarification is always
the lowest one where there was a problem; i.e., where al-
ternative hypotheses were introduced, or where no result
could be computed. For instance, in (17) this would be
the SR level rather than the speech act level.
This system is capable of producing flexible CRs that
adapt to the dialogue context, and this shows the value
of the idea of modelling in a fine-grained way sources of
CRs and of extending the concept of confidence scores.
However, the system is only a first proof-of-concept, and
we discuss possible improvements in the next section.
5 Conclusions and Further Work
We have presented a model of causes for requesting clar-
ifications in dialogues. We classified these causes?
BR1 If two (or more) hypotheses are bridged via
?next? to same antecedent, closer is better.
BR3 Tomorrow should be referred to as ?tomor-
row?.
RR1 If there are hypotheses where Plan-Corr has
been inferred (non-monotonically) and some
where other relations have been inferred, pre-
fer these other hypotheses.
Figure 5: Some of the scoring rules
understanding problems in the widest sense?according
to the level of processing on which they arise, and ac-
cording to the severity of the problem. To make this pre-
cise, we related the multi-level models of communication
of (Clark, 1996) and (Allwood, 1995) to the discourse se-
mantics theory SDRT (Asher and Lascarides, 2003), and
arrived at a fine-grained model of different understand-
ing tasks which was motivated by analysing examples of
CRs. We then proposed to extend the notion of confi-
dence score from speech recognition to other kinds of
processing (semantic and pragmatic), and sketched an
implementation of this idea. We think that the resulting,
relatively natural clarification behaviour shows that this
idea of using ?pragmatic confidences? is promising.
However, the initial results also suggest that there is
a lot of further work to be done. Firstly, it turned out
during development of the system that setting the thresh-
olds in the system manually in such a way that the de-
sired behaviour was produced was rather hard (besides
being ad hoc). We are currently exploring techniques to
automatically learn the best settings from a corpus (this
could perhaps be done along the lines of (Walker et al,
2000)). Secondly, the system we extended, RUDI, makes
rather high demands on the quality of the data, being a
system that relies on ?deep processing? at all stages. We
are currently exploring ways of implementing the idea
of using confidence values throughout in ?simpler?, more
realistic dialogue systems. This is a precondition for a
thorough evaluation of the proposed clarification strategy,
using ?real-world? criteria like user satisfaction and dia-
logue duration until task-completion.
With regard to the theoretical analysis of CRs, we are
currently testing the coverage and accuracy of the model
in a corpus study, and we are also working on a proper
formalisation of the different classes of CR we proposed,
in the framework of SDRT.
Acknowledgements
Parts of the work reported here are based on work done in col-
laboration with Alex Lascarides when the author was at the Uni-
versity of Edinburgh. Thanks are also due to Manfred Stede and
Malte Gabsdil, who commented on drafts of the paper, and to
the SIGdial reviewers for their helpful comments.
References
Jens Allwood. 1995. An activity based approach to prag-
matics. Gothenburg Papers in Theoretical Linguis-
tics 76, Go?teborg University, Go?teborg, Sweden.
Nicholas Asher and Alex Lascarides. 2003. Logics of
Conversation. Cambridge University Press.
Herbert H. Clark. 1996. Using Language. Cambridge
University Press, Cambridge.
Malte Gabsdil and Johan Bos. 2003. Combining acoustic
confidence scores with deep semantic analysis for clar-
ification dialogues. In Proceedings of the 5th interna-
tional workshop on computational semantics (IWCS-
5), Tilburg.
Malte Gabsdil. 2003. Clarification in spoken dialogue
systems. In Proceedings of the 2003 AAAI Spring Sym-
posium. Workshop on Natural Language Generation in
Spoken and Written Dialogue, Stanford, USA.
Jonathan Ginzburg and Robin Cooper. 2001. Resolv-
ing ellipsis in clarification. In Proceedings of the 39th
Meeting of the ACL, Tolouse, France.
Herbert Paul Grice. 1989. Studies in the Way of Words.
Harvard University Press, Cambridge, Massachusets.
Hans Kamp and Uwe Reyle. 1993. From Discourse to
Logic. Kluwer, Dordrecht.
Staffan Larsson. 2003. Interactive communication man-
agement in an issue-based dialogue system. In Pro-
ceedings of SemDial-7 (DiaBruck), Saarbru?cken.
Matthew Purver, Jonathan Ginzburg, and Patrick Healey.
2001. On the means for clarification in dialogue.
In Proceedings of the 2nd SIGdial Workshop on Dis-
course and Dialogue, Aalborg, Denmark.
R. San-Segundo, J.M. Montero, J. Ferreiros, R. Co?rdoba,
and J.M. Pardo. 2001. Designing confirmation mecha-
nisms and error recovery techniques in a railway infor-
mation system for spanish. In Proceedings of the 2nd
SIGdial Workshop on Discourse and Dialogue, Aal-
borg, Denmark.
David Schlangen, Alex Lascarides, and Ann Copestake.
2001. Resolving underspecification using discourse
information. In Proceedings of SemDial-5 (BiDialog),
pages 79?93, Bielefeld.
David Schlangen. 2003. A Coherence-Based Approach
to the Interpretation of Non-Sentential Utterances in
Dialogue. Ph.D. thesis, School of Informatics, Uni-
versity of Edinburgh, Edinburgh, UK.
Marilyn Walker, Jerry Wright, and Irene Langkilde.
2000. Using natural language processing and dis-
course features to identify understanding errors in a
spoken dialogue system. In Proceedings of the 17th
international conference on machine learning.
Proceedings of the 9th SIGdial Workshop on Discourse and Dialogue, pages 84?87,
Columbus, June 2008. c?2008 Association for Computational Linguistics
A Simple Method for Resolution of Definite Reference
in a Shared Visual Context
Alexander Siebert
Berlin-Brandenburgische
Akademie der Wissenschaften
siebert@bbaw.de
David Schlangen
Department of Linguistics
University of Potsdam, Germany
das@ling.uni-potsdam.de
Abstract
We present a method for resolving definite ex-
ophoric reference to visually shared objects
that is based on a) an automatically learned,
simple mapping of words to visual features
(?visual word semantics?), b) an automat-
ically learned, semantically-motivated utter-
ance segmentation (?visual grammar?), and c)
a procedure that, given an utterance, uses b)
to combine a) to yield a resolution. We evalu-
ated the method both on a pre-recorded corpus
and in an online setting, where it performed
with 81% (chance: 14%) and 66% accuracy,
respectively. This is comparable to results re-
ported in related work on simpler settings.
1 The Task
The method described in this paper is a module of
a dialogue system that acts as a collaborator of a
human player in the task of manipulating visually
present puzzle objects. An example scene is shown
in Figure 1 (the indices a and b are added here for
illustrative purposes). Given utterances like those in
(1), the task of the module is to identify the likely
referents (here, a and b, respectively).1
(1) a.Take the piece in the middle on the left side.
b.Take the piece in the middle.
More formally, the task can be characterised as fol-
lows: possibly starting with an a priori assump-
tion about likely referents (e.g., from knowledge of
1Our system is implemented for German input; for ease of
description we use examples from our corpus translated into
English here.
Figure 1: Example Scene
discourse salience), the module uses the evidence
present in the utterance (words, syntax) and in the
visual scene (visual features) to derive at a new as-
sumption about likely referents. If we call such an
assumption a confidence function c that assigns to
each object in the domain O, a number between 0
and 1; i.e., c : O ? R, then reference resolution is a
function r that takes a triple of an initial confidence
function c, an utterance u, and a visual scene repre-
sentation v to yield an updated confidence function
c?. Formally: r : C ? U ? V ? C.
In the following, we describe the resources
needed to set up the module, its subcomponents, and
the evaluation we performed. We close by relating
the proposed method to prior work and discussing
future extensions.
2 Resources
2.1 Corpus
As our method is based on automatically learned
models, a corpus is required. Our intended use case
is similar to the setting described in (Schlangen and
Ferna?ndez, 2007), but with the addition of a shared
visual context. We collected 300 scene descriptions
84
(of scenes containing between 1 and 12 distinct,
monochrome shapes, randomly placed and rotated
on a rectangular area) using the two-part methodol-
ogy of (Siebert et al, 2007) that yields recordings
and quality assessments (here: attempts to follow
other subjects? instructions). We also later recorded
an additional 300 scene descriptions by a single
speaker, to further increase our data base.
After transcription of the recordings (239 min-
utes of audio material), we discarded roughly 6%
of the instructions because they could not be fol-
lowed by the evaluators, and a further 4% because
the complexity of the descriptions was outside the
scope of what we wanted to model. The remaining
instructions were then automatically cleaned from
dysfluencies, morphologically lemmatised and POS
tagged, and annotated as described below.
2.2 Computer Vision
The other required resource is a visual perception
algorithm. We use it to compute a feature repre-
sentation of every visual scene as presented in the
data collection:2 First, each object is represented by
a number of object features such as size / length /
height of the bounding box, center of gravity, num-
ber of edges. Second, topological features note for
each object the distance to certain points on the
board (edges, center, etc.) and to other objects.
(For details on the computation of such features see
for example (Regier and Carlson, 2001).) Lastly,
we also compute groupings of objects by clustering
along columns and rows or both (see Figure 2 for an
illustration). For each group, we compute two sets
of topological features, one for the objects within
the group (e.g., distance to the center of the group),
and one for the configuration of groups (distance of
group to other objects). This set of features was se-
lected to be representative of typical basic visual fea-
tures.
3 Components
3.1 Visual Grammar
The ?visual grammar? segments utterances accord-
ing to functional aspects on two levels. The first
2At the moment, the input to the algorithm is a symbolic
representation of the scene (which object is where); the features
are designed to also be derivable from digital images instead,
using standard computer vision techniques (Shapiro and Stock-
man, 2001); this is future work, however.
Figure 2: Scene with Horizontal Group Detection
describes the macro-structure of a spatial expres-
sion, i.e., the division into target (the denoted ob-
ject; T) and optional landmarks (other objects; LM)
and their relation to the target (R; see example in Ta-
ble 2). The second level annotates the spatial-lexical
function of each word, e.g., whether the word de-
notes a piece or a configuration of pieces (Table 1).
A fully ?parsed? example is shown in Table 2.
Name Description Examples
l lexical reference T,piece,cross
d r topological direction top left Corner
d s topological distance outer left
d n numeric second column
p g group (perceptually active) from the left column
g s synthetic group the three pieces on the left
f landmark field N in the Middle
r prepositional relation in the middle
grad grading function exactly right
Table 1: Visual Lexical Functions of Words
the cross from the second column from left at the top
l r d n p g r d r d r
(a) - Annotation of spatial lexical functions
T R LM LM LM LM T
(b) - Segmentation of visual spatial parts
Table 2: Example Annotation / ?Parse?
Given the requirement for robustness, we decided
against a hand-written grammar for deriving such
annotations; the moderate size of our corpus on
the other hand made for example Markov model-
based approaches difficult to apply. We hence chose
transformation-based learning to create this (shal-
low) segmentation grammar, converting the seg-
mentation task into a tagging task (as is done in
85
(Ramshaw and Marcus, 1995), inter alia). In our ap-
proach, each token that is to be tagged is itself repre-
sented in three different forms or layers: lemmatised
word, as POS-tag, and by its spatial-functional tag
(as in Table 1; added by simple look-up). All these
layers can be accessed in the learned rules. Apart
from this, the module is a straightforward imple-
mentation of (Ramshaw and Marcus, 1995), which
in turn adapts (Brill, 1993) for syntactic chunking.
3.2 Visual Word Semantics
To learn the visual semantics of words we imple-
mented a simple technique for grounding words in
perceptions. Roughly, the idea is to extract from
all instances in which a word was used in the train-
ing corpus and all associated scenes a prototypical
visual meaning representation by identifying those
features whose values best predict the appropriate-
ness of the word given a scene. (This is similar in
spirit to the approach used in (Roy, 2002).)
As material for learning, we only used the sim-
ple expressions (target only, no landmark) in the
corpus, to ensure that all words used were in some
way ?about? the target. The algorithm iterates over
all pairs of utterance and scene and saves for each
lemma all visual information. This creates for each
lemma a matrix of feature values with as many rows
as there were occurrences of the lemma. The values
in each column (that is, for each feature) are then
normalised to the interval [-1, 1] and the standard
deviation is recorded.
The next tasks then are a) to compute one sin-
gle representative value for each feature, but only
b) for those features that carry semantic weight for
the given word (i.e., to compute a dimensionality re-
duction). E.g., for the lemma ?left?, we want the fea-
ture x distance to center to be part of the semantic
model, but not y distance to center.
One option for a) is to simply take the average
value as representative for a feature (for a given
word). While this works for some words, it causes
problems for others which imply a maximisation
and not a prototypisation. E.g., the lemma left is
best represented by maximal values of the feature
x distance to center, not by the average of all val-
ues for all occurrences of left (this will yield some-
thing like leftish). Perhaps surprisingly, representa-
tion through the majority value, i.e., choosing the
most frequent value as representative for a feature
(for a given word), performed better, and is hence
the method we chose.
For b), dimensionality reduction, we again chose
a very simple approach (much simpler than for ex-
ample (Roy, 2002)): features are filtered out as ir-
relevant for a given lemma features if their variance
is above a certain threshold. To give an example,
for the lemma left the distribution of values of the
feature x distance to center varies with a ? of 0.05,
that of y distance to center with a ? of 0.41. We
empirically determined the setting of the threshold
such that it excluded the latter.3
3.3 Combination
Figure 3: Steps of the Algorithm for Example Utterance
The combination algorithm works through the
segmented utterance and combines visual word se-
mantics to yield a reference hypothesis. Figure 3
illustrates this process for the example from Table 2.
On detecting a landmark segment (Step 1), the res-
olution algorithm ?activates? the appropriate group;
which one this is is determined by the p g item in
the landmark segment. (Here: column). The group
is then treated as a single object, and (Step 2) the
semantics of topological terms (d r or d s) in the
landmark segment is applied to it (more on this in
a second). For our example, this yields a ranking
of all columns with respect to their ?left-ness?. The
ordinal ?second? finally simply picks out the second
element on this list?the second group w.r.t. the prop-
erty of leftness (Step 3). The expressions in the tar-
get segment are now only applied to the members
of the group that was selected in this way; i.e., the
semantic models of ?top? and ?cross? are now only
applied to the objects in that column (Steps 4 to 6).
3With more data and hence the possibility to set aside a de-
velopment set, one could and should of course set such a thresh-
old automatically.
86
Semantic word models are applied through a sim-
ple calculation of distance between values (of se-
mantic model and actual scene): the closer, the bet-
ter the match of word to scene. (Modulo selectivity
of a feature; for a feature that occurred for all lem-
mata with a high specificity (small ?), good matches
are expected to be closer to the prototype value than
for features with a high variability.)
This method encodes parts of the utterance se-
mantics procedurally, namely the way how certain
phrases (here grouped under the label landmark) se-
mantically modify other phrases (here grouped un-
der the label target). This encoding makes the al-
gorithm perhaps harder to understand than seman-
tic composition rules tied to syntactic rules, but it
also affords a level of abstraction over specific syn-
tactic rules: our very general concepts of landmark
and target cover various ways of modification (e.g.
through PPs or relative clauses), adding to the ro-
bustness of the approach.
4 Evaluation
With an f-score of 0.985 (10-fold cross validation),
the transformation-based learning of the segmen-
tation performs quite well, roughly at the level
of state-of-the-art POS-taggers (albeit with a much
smaller tag inventory). Also evaluated via cross-
validation on the corpus, the resolution component
as a whole performs with an accuracy of 80.67%
(using frequency-based word-semantic features; it
drops to 66.95% for average-based). There were on
average 7 objects in each scene in the corpus; i.e.
the baseline of getting the reference right by chance
is 14%. Our system significantly improves over this
baseline.
We also evaluated the system in a more realis-
tic application situation. We asked subjects to refer
to certain pieces in presented scenes (via typed ut-
terances); here, the system reached a success-rate
of 66% (7 subjects, 100 scene / utterance pairs).
While this is considerably lower than the corpus-
based evaluation, it is still on a par with related
systems using more complicated resolution methods
(Roy, 2002; Gorniak and Roy, 2004). We also think
these results represent the lower end of the perfor-
mance range that can be expected in practical use,
as in an interactive dialogue system users have time
to adapt to the capabilities of the system.
5 Conclusions
We have presented a method for resolving defi-
nite, exophoric reference to objects that are visu-
ally co-present to user and system. The method
combines automatically acquired models (a ?visual
word semantics?, a simple, but effective mapping be-
tween visual features and words; and a ?visual gram-
mar?, a semantically motivated segmentation of ut-
terances) and hard-coded knowledge (combination
procedure). To us, this combines the strengths of
two approaches: statistical, where robustness and
wide coverage is required, hard-coding, where few,
but complex patterns are concerned.
We are currently integrating the module into a
working dialogue system; in future work we will in-
vestigate the use of digital images as input format.
Acknowledgements
This work was supported by DFG through an Emmy
Noether Programm Grant to the second author.
References
Eric Brill. 1993. A Corpus-Based Approach to Language
Learning. Ph.D. thesis, University of Pennsylvania.
Peter Gorniak and Deb Roy. 2004. Grounded semantic
composition for visual scenes. In Journal of Artifical
Intelligence Research.
Lance A. Ramshaw and Mitchell P. Marcus. 1995. Text
chunking using transformation-based learning. In Pro-
ceedings of the Third Workshop on Very Large Cor-
pora, pages 82?94.
Terry Regier and Laura A. Carlson. 2001. Grounding
spatial language in perception: An empirical and com-
putational investigation. In Journal of Experimental
Psychology, volume 130, pages 273?298.
Deb Roy. 2002. Learning words and syntax for a visual
description task. Computer Speech and Language,
16(3).
David Schlangen and Raquel Ferna?ndez. 2007. Beyond
repair: Testing the limits of the conversational repair
system. In Proceedings of SIGdial 2007, pages 51?
54, Antwerp, Belgium, September.
Linda G. Shapiro and George C. Stockman. 2001. Com-
puter Vision. Prentice Hall, New Jersey, USA.
Alexander Siebert, David Schlangen, and Raquel
Ferna?ndez. 2007. An implemented method for dis-
tributed collection and assessment of speech data. In
Proceedings of SIGdial 2007, Antwerp, Belgium.
87
Proceedings of EACL 2009 Workshop on Semantic Representation of Spoken Language - SRSL 2009, pages 66?73,
Athens, Greece, 30 March 2009. c?2009 Association for Computational Linguistics
RUBISC - a Robust Unification-Based Incremental Semantic Chunker
Michaela Atterer
Department for Linguistics
University of Potsdam
atterer@ling?uni-potsdam.de
David Schlangen
Department for Linguistics
University of Potsdam
das@ling?uni-potsdam.de
Abstract
We present RUBISC, a new incremen-
tal chunker that can perform incremental
slot filling and revising as it receives a
stream of words. Slot values can influ-
ence each other via a unification mecha-
nism. Chunks correspond to sense units,
and end-of-sentence detection is done in-
crementally based on a notion of seman-
tic/pragmatic completeness. One of RU-
BISC?s main fields of application is in
dialogue systems where it can contribute
to responsiveness and hence naturalness,
because it can provide a partial or com-
plete semantics of an utterance while the
speaker is still speaking. The chunker is
evaluated on a German transcribed speech
corpus and achieves a concept error rate of
43.3% and an F-Score of 81.5.
1 Introduction
Real-time NLP applications such as dialogue sys-
tems can profit considerably from incremental
processing of language. When syntactic and se-
mantic structure is built on-line while the speech
recognition (ASR) is still working on the speech
stream, unnatural silences can be avoided and
the system can react in a faster and more user-
friendly way. As (Aist et al, 2007) and (Skantze
and Schlangen, 2009) show, such incremental sys-
tems are typically preferred by users over non-
incremental systems.
To achieve incrementality, most dialogue sys-
tems employ an incremental chart parser (cf.
(Stoness et al, 2004; Seginer, 2007) etc.). How-
ever, most existing dialogue systems operate in
very limited domains, e.g. moving objects, peo-
ple, trains etc. from one place to another (cf.
(Aist et al, 2007), (Skantze, 2007), (Traum et al,
1996)). The complexity of the semantic repre-
sentations needed is thus limited. Moreover, user
behaviour (ungrammatical sentences, hesitations,
false starts) and error-prone ASR require the pars-
ing process to be robust.1 We argue that obtaining
relatively flat semantics in a limited domain while
needing exigent robustness calls for investigating
shallower incremental chunking approaches as al-
ternatives to CFG or dependency parsing. Previ-
ous work that uses a combination of shallow and
deep parsing in dialogue systems also indicates
that shallow methods can be superior to deep pars-
ing (Lewin et al, 1999).
The question addressed in this paper is how to
construct a chunker that works incrementally and
robustly and builds the semantics required in a
dialogue system. In our framework chunks are
built according to the semantic information they
contain while syntactic structure itself is less im-
portant. This approach is inspired by Selkirk?s
sense units (Selkirk, 1984). She claims such
units to be relevant for prosodic structure and dif-
ferent to syntactic structure. Similarly, (Abney,
1991) describes some characteristics of chunks as
follows?properties which also make them seem
to be useful units to be considered in spoken dia-
logue systems:
?when I read a sentence, I read it a chunk at
a time. [...] These chunks correspond in some
way to prosodic patterns. Chunks also represent a
grammatical watershed of sorts. The typical chunk
consists of a single content word surrounded by a
constellation of function words, matching a fixed
template. By contrast, the relationships between
chunks are mediated more by lexical selection
1cf. The incremental parser in (Skantze, 2007) can jump
over a configurable number of words in the input.
66
than by rigid templates. [...] and the order in
which chunks occur is much more flexible than the
order of words within chunks.?
In our approach chunks are built incrementally
(one at a time) and are defined semantically (a
sense unit is complete when a slot in our template
or frame semantics can be filled). Ideally, in a full
system, the definition of their boundaries will also
be aided by prosodic information. The current im-
plementation builds the chunks or sense units by
identifying a more or less fixed sequence of con-
tent and function words, similar to what Abney
describes as a fixed template. The relationships
between the units are mediated by a unification
mechanism which prevents selectional restrictions
from being violated. This allows the order of the
sense units to be flexible, even as flexible as they
appear in ungrammatical utterances. This unifi-
cation mechanism and the incremental method of
operation are also the main difference to Abney?s
work and other chunkers.
In this paper, we first present our approach of
chunking, show our grammar formalism, the main
features of the chunker (unification mechanism,
incrementality, robustness), and explain how the
chunker can cope with certain tasks that are an is-
sue in dialogue systems, such as online utterance
endpointing and revising hypotheses. In Section 3,
we evaluate the chunker on a German corpus (of
transcribed spontaneous speech) in terms of con-
cept error rate and slot filling accuracy. Then we
discuss related work, followed by a general dis-
cussion and the conclusion.
2 Incremental Chunking
Figure 1 shows a simple example where the chun-
ker segments the input stream incrementally into
semantically relevant chunks. The figure also dis-
plays how the frame is being filled incrementally.
The chunk grammar developed for this work and
the dialogue corpus used were German, but we
give some examples in English for better readabil-
ity.
As time passes the chunker receives more and
more words from the ASR. It puts the words in a
queue and waits until the semantic content of the
accumulated words is enough for filling a slot in
the frame semantics. When this is the case the
chunk is completed and a new chunk is started.
At the same time the frame semantics is updated if
slot unification (see below) is possible and a check
time
turn
erm
the
piece
erm
the
second
in
the
upper
row
to
erm
clockwise
chunk:
[turn]
erm
erm the
erm the piece
erm the piece erm
erm the piece erm the 
in
in the
in the upper
[in the upper row]
to
to erm
[to erm clockwise]
action:turning
end:?
grammar:
action:turning ?>turn
end:right?>to the right|clockwise
...
action:turning
[erm the piece erm the second]
R
U
B
I
S
C
semantics:input:
object:xpos:2?>the second
object:ypos:?1?>the upper row
object: name:?
end:?
object: name:?
action:turning
end:?
object: name:?
action:turning
end:right
object: name:?
         xpos:2
          ypos:?
         xpos:2
          ypos:?1
         xpos:2
          ypos:?1
          ypos:?
         xpos:?
Figure 1: Incremental robust sense unit construc-
tion by RUBISC.
Figure 2: Puzzle-task of the corpus used for gram-
mar building and testing.
whether the utterance is complete is made, so that
the chunker can be restarted for the next utterance
if necessary.
2.1 A Regular Grammar for Semantics
The grammar we are using for the experiments in
this paper was developed using a small corpus of
German dialogue (Siebert and Schlangen, 2008),
(Siebert, 2007). Figure 2 shows a picture of the
task that the subjects completed for this corpus.2 A
number of pentomino pieces were presented. The
pieces had to be moved into an animal-shaped fig-
ure. The subjects were shown partly completed
puzzles and had to give concise and detailed ver-
bal instructions of the next move that had to be
done. The locations inside this figure were usually
referred to in terms of body parts (move the x into
2For the corpus used here the difference was that the but-
ton labels were German and that the pentomino pieces were
not ordered in two rows. For better readability, we show the
picture with the English labels.
67
the head of the elephant).
For such restricted tasks, a simple frame se-
mantics seems sufficient, representing the action
(grasping, movement, flipping or turning of an ob-
ject), the object that is involved, and where or
in which position the object will end up. In our
current grammar implementation the object can
be described with three attributes: name is the
name of the object. In our domain, the objects are
pentomino-pieces (i.e., geometrical forms that can
be built out of five squares) which have traditional
letter names such as x or w; the grammar maps
other descriptions such as cross or plus to such
canonical names. A piece can also be described
by its current position, as in the lower piece in
the third column. This is covered by the attributes
xpos and ypos demarking the x-position and y-
position of a piece. The x- or y-position can
be a positive or negative number, depending on
whether the description counts from left or right,
respectively.
The possible slots must be defined in the gram-
mar file in the following format:
@:action
@:entity:name
@:entity:xpos
@:entity:ypos
@:end
(That is: definition marker @:level
1: (optional) level 2.)
The position where or in which the piece ends
up could also be coded as a complex entry, but for
simplicity?s sake (in the data used for evaluation,
we have a very limited set of end positions that
would each be described by just one attribute re-
spectively), we restrict ourselves to a simple entry
called end which takes the value of a body part
(head, back, leg1 etc.) in the case of movement,
and the value of a direction or end position hor-
izontal, vertical, right, left in the case of a turn-
ing or flipping action. It will be (according to
our current grammar) set to empty in the case of a
grasping action, because grasping does not specify
an end position. This will also become important
later, when unification comes into play. Figure 3
shows a part of the German grammar used with
approximate translations (in curly brackets) of the
right-hand side into English. The English parts in
curly brackets is meta-notation and not part of the
grammar file. Note that one surface string can de-
termine the value of more than one semantic slot.
The grammar used in the experiments in this paper
action:grasping,end:empty -> nimm|nehme
{take}
action:turning -> drehe? {turn}
action:flipping -> spieg(le|el) {flip}
action:movement -> bewegt {moved}
action:turning -> gedreht {turned}
entity:name:x -> kreuz|plus|((das|ein) x)
{cross|pluss|((the|an) x)}
entity:name:w -> treppe|((das|ein) w$)
{staircase|(the|a) w}
entity:name:w -> (das|ein) m$
{(the|an) m}
entity:name:z -> (das|ein) z$
{(the|a) z}
end:head -> (in|an) den kopf
{(on|in) the head}
end:leg2 -> ins? das (hinterbein|hintere
bein|rechte bein|zweites bein) {in the hindleg|
back leg|right leg| second leg}
entity:ypos:lower -> der (unteren|zweiten)
reihe {(lower|second) row}
entity:xpos:1 -> das erste {the first}
entity:ypos:-1 -> das letzte {the last}
end:horizontal,action:flipping -> horizontal
{horizontally}
Figure 3: Fragment of the grammar file used in
the experiments (with English translations of the
patterns for illustration only).
had 97 rules.
2.2 Unification
Unification is an important feature of RUBISC
for handling aspects of long-distance dependen-
cies and preventing wrong semantic representa-
tions. Unification enables a form of ?semantic
specification? of verb arguments, avoiding that the
wrong arguments are combined with a given verb.
It also makes possible that rules can check for the
value of other slots and hence possibly become
inapplicable. The verb move, for instance, en-
sures that action is set to movement. For the ut-
terance schieb das a?h das horizontal a?h liegt ins
Vorderbein (move that uh which is horizontal into
the front leg). The action-slot will be filled
with movement but the end-slot remains empty
because horizontal as an end fits only with a flip-
ping action, and so is ignored here. Figure 4 illus-
trates how the slot unification mechanism works.
2.3 Robustness
The chunker meets various robustness require-
ments to a high degree. First, pronunciation vari-
ants can be taken account of in the grammar in
a very flexible way, because the surface string or
terminal symbols can be expressed through regu-
68
action:?
end:?
...
unify frame with
Input: unification component:time: Frame:
[schieb]
[action:movement]
?>unification success: action:movement
end:?
...
das
das mh
[das mh horizontal] unify frame with
action:flipping
end:horizontal
?>unification failed: action:movement
end:?
liegt
liegt ins
[liegt ins Vorderbein]
unify frame with
[end:leg1] action:movement
end:leg1
...
...
Figure 4: Example of slot unification and failure
of unification.
lar expression patterns. move in German for in-
stance can be pronounced with or without a final
-e as bewege or beweg. flip (spiegle can be pro-
nounced with or without -el-inversion at the end.
Note, that this is due to the performance of speak-
ers in our corpus and does not necessarily reflect
German grammar rules. A system, however, needs
to be able to cope with performance-based varia-
tions.
Disfluencies are handled through how the chun-
ker constructs chunks as sense units. First, the
chunker only searches for relevant information in
a chunk. Irrelevant information such as an initial
uh in uh second row is put in the queue, but ig-
nored as the chunker picks only second row as the
semantically relevant part. Furthermore the chun-
ker provides a mechanism that allows it to jump
over words, so that second row will be found in
the second uh row and the cross will be found in
the strange cross, where strange is an unknown
word.
2.4 Incrementality
One of the main features of RUBISC is its incre-
mentality. It can receive one word at a time and
extract semantic structure from it. Incrementality
is not strict here in the sense of (Nivre, 2004), be-
cause sometimes more than one word is needed
before parts of the frame are constructed and out-
put: into the right, for instance, needs to wait for a
word like leg that completes the chunk. We don?t
necessarily consider this a disadvantage, though,
as our chunks closely correlate to the minimal bits
of information that can usefully be reacted to. In
our corpus the first slot gets on average filled after
3.5 words (disregarding examples where no slots
are filled). The average utterance is 12.4 words
long.
2.5 End-of-Sentence Detection
An incremental parser in a dialogue system needs
to know when to stop processing a sentence and
when to start the next one. This can be done by
using prosodic and syntactic information (Atterer
et al, 2008) or by checking whether a syntactic
S-node is complete. Since RUBISC builds sense
units, the completeness of an utterance can be de-
fined as semantic-pragmatic completeness, i.e. by
a certain number of slots that must be filled. In our
domain, for instance, it makes sense to restart the
chunker when the action and end slot and either
the name slot or the two position slots are filled.
2.6 History
The chunker keeps a history of the states of the
frames. It is able to go back to a previous state
when the incremental speech recognition revokes
a word hypothesis. As an example consider the
current word hypothesis to be the L. The slot en-
tity name will be filled with l. Then the speech
recognition decides to change the hypothesis into
the elephant. This results in clearing the slot for
entity name again.
3 Evaluation
The sense unit chunker was evaluated in terms of
how well it performed in slot filling on an unseen
part of our corpus. This corpus comes annotated
with utterance boundaries. 500 of these utterances
were manually labelled in terms of the semantic
slots defined in the grammar. The annotators were
not involved in the construction of the chunker or
grammar. The annotation guidelines detailed the
possible values for each slot. The entity names
had to be filled in with the letter names of the
pieces, the end slot with body parts or right, left,
horizontal etc., and the position slots with posi-
tive and negative numbers.3 The chunker was then
run on 400 of these utterances and the slot values
were compared with the annotated frames. 100
of the labelled utterances and 50 additional utter-
3In a small fraction (21) of the 500 cases an utterance
actually contained 2 statements that were combined with
und/and. In these cases the second statement was neglected.
69
ances were used by the author for developing the
grammar.
We examined the following evaluation mea-
sures:
? the concept error (concept err) rate (percentage
of wrong frames)
? the percentage of complete frames that were
correct (frames corr)
? the percentage of slots that were correct
? the percentage of action slots correct
? the percentage of end slots correct
? the percentage of object:name slots correct
? the percentage of object:xpos slots correct
? the percentage of object:ypos slots correct
The results are shown in Table 1. We used
a very simple baseline: a system that does not
fill any slots. This strategy still gets 17% of
the frames right, because some utterances do
not contain any real content. For the sentence
Also das ist recht schwer (Trans: That?s quite
difficult.), for instance, the gold standard seman-
tic representation would be: {action:None,
end:None, object:{xpos:None, name:None,
ypos:None}}. As the baseline ?system? always
returns the empty frame, it scores perfectly for
this example sentence. We are aware that this
appears to be a very easy baseline. However, for
some slots, such as the xpos and ypos slots it still
turned out to be quite hard to beat this baseline,
as wrong entries were common for those slots.
The chunker achieves a frame accuracy of 54.5%
and an overall slot filling accuracy of 86.80%
(compared to 17% and 64.3% baseline). Of the
individual slots the action slot was the one that
improved the most. The position slots were the
only ones to deteriorate. As 17% of our utterances
did not contain any relevant content, i.e. the frame
was completely empty, we repeated the evaluation
without these irrelevant data. The results are
shown in brackets in the table.
To check the impact of the unification mecha-
nism, we performed another evaluation with this
mechanism turned off, i.e. slots are always filled
when they are empty without regarding other slots.
In the second step in Figure 4, the end slot would
hence be filled. This resulted in a decline in per-
formance as can also be seen in Table 1. We also
turned off robustness features to test for their im-
pact. Surprisingly, turning off the skipping of one
word within a string specified by a grammar rule
(as in to erm clockwise), did not have an effect on
the results on our corpus. When we also turn off
allowing initial material (erm the piece), however,
performance drops considerably.
We also tested a variant of the system RUBISC-
o (for RUBISC-overlap) which considers overlap-
ping chunks: Take the third piece will result in
xpos:3 for the original chunker, even if the utter-
ance is continued with from the right. RUBISC-o
also considers the previous chunk the third piece
for the search of a surface representation. In this
case, it overwrites 3 with -3. In general, this be-
haviour improves the results.4
To allow a comparison with other work that re-
ports recall and precision as measures, we also
computed those values for RUBISC: for our test
corpus recall was 83.47% and precision was
79.69% (F-score 81.54). A direct comparison with
other systems is of course not possible, because
the tasks and data are different. Nevertheless, the
numbers allow an approximate feel of how well
the system performs.
To get an even better idea of the performance,
we let a second annotator label the data we tested
on; inter-annotator agreement is given in Table 1.
The accuracy for most slots is around 90% agree-
ment beween annotators. The concept error rate
is 32.25%. We also examined 50 utterances of the
test corpus for an error analysis. The largest part of
the errors was due to vocabulary restrictions or re-
strictions in the regular expressions: subjects used
names for pieces or body parts or even verbs which
had not been seen or considered during grammar
development. As our rules for end positions con-
tained pronouns like (into the back), they were
too restricted for some description variants (such
that it touches the back). Another problem that
appears is that descriptions of starting positions
can be confounded with descriptions of end po-
sitions. Sometimes subjects refer to end positions
not with body parts but with at the right side etc.
In some cases this leads to wrong entries in the
object-position slots. In some cases a full parser
might be helpful, but not always, because some
expressions are syntactically ambiguous: fu?ge das
Teil ganz rechts in das Rechteck ein. (put the piece
on the right into the square/put the piece into the
square on the right.) A minority of errors was also
4Testing significance, there is a significant difference be-
tween RUBISC and the baseline, and RUBISC and RIBISC
w/o rob (for all measures except xpos and ypos). The other
variants show no significance compared with RUBISC but
clear tendencies in the directions described above.
70
baseline RUBISC w/o unif w/o rob RUBISC-o i-annotator
concept err 83.0 (100) 45.5 (44.6) 49.5 (49.7) 73.3 (85.5) 43.3 (42.8) 32.3 (35.5)
frames corr 17.0 (0) 54.5 (55.4) 50.3 (50.3) 26.8 (14.5) 56.8 (57.2) 67.8 (64.5)
slots corr 64.3 (57.0) 86.8 (87.2) 84.6 (84.5) 78.8 (74.9) 87.6 (87.6) 92.1 (91.5)
action corr 27.8 (13.0) 90.3 (92.2) 85.8 (86.7) 64.3 (57.5) 89.8 (90.7) 89.0 (88.6)
end corr 68.0 (61.4) 85.8 (87.3) 81.0 (81.6) 73.8 (69.0) 85.5 (87.0) 95.8 (95.1)
name corr 48.8 (38.3) 86.3 (88.3) 84.5 (86.1) 79.0 (76.2) 86.5 (88.0) 86.8 (85.8)
xpos corr 87.5 (84.9) 83.0 (80.7) 83.0 (80.7) 86.5 (83.7) 85.5 (83.4) 94.5 (94.0)
ypos corr 89.5 (87.3) 88.8 (87.3) 88.8 (87.3) 90.3 (88.3) 90.5 (88.9) 94.5 (94.0)
Table 1: Evaluation results (in %) for RUBISC in comparison with the baseline, RUBISC without uni-
fication mechanism (w/o unif), without robustness (w/o rob), RUBISC with overlap (RUBISC-o), and
inter-annotator aggreement (i-annotator). See the text for more information.
due to complex descriptions (the damaged t where
the right part has dropped downwards ? referring
to the f), transcription errors (recht statt rechts) etc.
4 Related Work
Slot filling is used in dialogue systems such as
the Ravenclaw-Olympus system5, but the slots are
filled by using output from a chart parser (Ward,
2008). The idea is similar in that word strings are
mapped onto semantic frames. A filled slot, how-
ever, does not influence other slots via unification
as in our framework, nor can the system deal with
incrementality. This is also the main difference
to systems such as Regulus (Rayner et al, 2006).
Our unification is carried out on filled slots and in
an incremental fashion. It is not directly specified
in our grammar formalism. The chunker rather
checks whether slot entries suggested by various
independent grammar rules are unifiable.
Even though not incremental either, the ap-
proach by (Milward, 2000) is similar in that it can
pick information from various parts of an utter-
ance; for example, it can extract the arrival time
from sentences like I?d like to arrive at York now
let?s see yes at 3pm. It builds a semantic chart us-
ing a Categorial grammar. The entries of this chart
are then mapped into slots. A number of settings
are compared and evaluated using recall and preci-
sion measures. The setting with the highest recall
(52%) achieves a precision of 79%. The setting
with the highest precision (96%) a recall of 22%.
These are F-scores of 62.7 and 35.8 respectively.
(Aist, 2006) incrementally identifies what they
call ?pragmatic fragments?, which resemble the
sense units produced in this paper. However, their
5http://www.ravenclaw-olympus.org/
system is provided with syntactic labels and the
idea is to pass those on to a parser (this part ap-
pears to not be implemented yet). No evaluation is
given.
(Zechner, 1998) also builds frame representa-
tions. Contrary to our approach, semantic infor-
mation is extracted in a second step after syntac-
tic chunks have been defined. The approach does
not address the issue of end of sentence-detection,
and also differs in that it was designed for use with
unrestricted domains and hence requires resources
such as WordNet (Miller et al, 1993). Depend-
ing on the WordNet output, usually more than one
frame representation is built. In an evaluation, in
21.4% of the cases one of the frames found is cor-
rect. Other approaches like (Rose, 2000) also need
lexicons or similar resources.
(Helbig and Hartrumpf, 1997) developed an in-
cremental word-oriented parser for German that
uses the notion of semantic kernels. This idea
is similar in that increments correspond to con-
stituents that have already been understood se-
mantically. The parser was later on mainly used
for question answering systems and, even though
strongly semantically oriented, places more em-
phasis on syntactic and morphological analysis
and less on robustness than our approach. It
uses quite complex representations in the form of
multi-layered extended semantic networks.
Finally, speech grammars such as JSFG6 are
similar in that recognition patterns for slots like
?action? are defined via regular patterns. The main
differences are non-incrementality and that the re-
sult of employing the grammar is a legal sequential
string for each individual slot, while our grammar
6java.sun.com/products/java-media/
speech/forDevelopers/JSGF/
71
also encodes, what is a legal (distributed) combi-
nation of slot entries.
5 Discussion and Future Work
The RUBISC chunker presented here is
not the first NLU component that is robust
against unknown words or structures, or non-
grammaticalities and disfluencies in the input, nor
the first that works incrementally, or chunk-based,
or focusses predominantly on semantic content
instead of syntactic structure. But we believe that
it is the first that is all of this combined, and that
the combination of these features provides an
advantage?at least for the domains that we are
working on. The novel combination of unification
and incrementality has the potential to handle
more phenomena than simple key word spotting.
Consider the sentence: Do not take the piece that
looks like an s, rather the one that looks like a w.
The idea is to introduce a negation slot or flag,
that will be set when a negation occurs. nicht das
s (not the s) will trigger the flag to be set while at
the same time the name slot is filled with s. This
negation slot could then trigger a switch of the
mode of integration of new semantic information
from unification to overwriting. We will test this
in future work.
One of the main restrictions of our approach is
that the grammar is strongly word-oriented and
does not abstract over syntactic categories. Its
expressive power is thus limited and some extra
coding work might be necessary due to the lack
of generalization. However, we feel that this is
mediated by the simplicity of the grammar for-
malism. A grammar for a restricted domain (and
the approach is mainly aiming at such domains)
like ours can be developed within a short time
and its limited size also restricts the extra cod-
ing work. Another possible objection to our ap-
proach is that handcrafting grammars like ours is
costly and to some extent arbitrary. However, for
a small specialized vocabulary as is typical for
many dialogue systems, we believe that our ap-
proach can lead to a good fast-running system in a
short developing time due to the simplicity of the
grammar formalism and algorithm, which makes
it easier to handle than systems that use large lexi-
cal resources for complexer domains (e.g. tutoring
systems). Other future directions are to expand
the unification mechanism and grammar formal-
ism such that alternatives for slots are possible.
This feature would allow the grammar writer to
specify that end:right requires a turning action or
a flipping action.
6 Conclusion
We presented a novel framework for chunking.
The main new ideas are that of incremental chunk-
ing and chunking by sense units, where the rela-
tionship between chunks is established via a uni-
fication mechanism instead of syntactic bounds,
as in a full parsing approach. This mechanism
is shown to have advantages over simple keyword
spotting. The approach is suitable for online end-
of-sentence detection and can handle revised word
hypotheses. It is thus suitable for use in a spoken
dialogue system which aims at incrementality and
responsiveness. Nevertheless it can also be used
for other NLP applications. It can be used in an
incremental setting, but also for non-incremental
tasks. The grammar format is easy to grasp, and
the user can specify the slots he wants to be filled.
In an evaluation it achieved a concept error rate of
43.25% compared to a simple baseline of 83%.
7 Acknowledgement
This work was funded by the DFG Emmy-Noether
grant SCHL845/3-1. Many thanks to Ewan Klein
for valuable comments. All errors are of course
ours.
References
Steven Abney. 1991. Parsing by chunks. In Principle-
based Parsing: Computation and Psycholinguistics,
volume 44 of Studies in Linguistics and Philosophy.
Kluwer.
Gregory Aist, James Allen, Ellen Campana, Car-
los Gomez Gallo, Scott Stoness, Mary Swift, and
Michael K. Tanenhaus. 2007. Incremental under-
standing in human-computer dialogue and experi-
mental evidence for advantages over nonincremental
methods. In Decalog 2007, Trento, Italy.
Gregory S. Aist. 2006. Incrementally segment-
ing incoming speech into pragmatic fragments. In
The Third Midwest Computational Linguistics Col-
loquium (MCLC-2006), Urbana, USA.
Michaela Atterer, Timo Baumann, and David
Schlangen. 2008. Towards incremental end-
of-utterance detection in dialogue systems. In
Proceedings of Coling 2008, Manchester, UK.
Hermann Helbig and Sven Hartrumpf. 1997. Word
class functions for syntactic-semantic analysis. In
72
Proceedings of the 2nd International Conference on
Recent Advances in Natural Language Processing
(RANLP?97).
I. Lewin, R. Becket, J. Boye, D. Carter, M. Rayner, and
M. Wiren. 1999. Language processing for spoken
dialogue systems: is shallow parsing enough? In
Accessing Information in Spoken Audio: Proceed-
ings of ESCA ETRW Workshop, Cambridge, USA.
George A. Miller, Richard Beckwith, Christiane Fell-
baum, Derek Gross, and Katherine Miller. 1993.
Five papers on wordnet. Technical report, Princeton
University.
David Milward. 2000. Distributing representation for
robust interpretation of dialogue utterances. In Pro-
ceedings of ACL 2000, pages 133?141.
Joakim Nivre. 2004. Incrementality in determinis-
tic dependency parsing. In Frank Keller, Stephen
Clark, Matthew Crocker, and Mark Steedman, edi-
tors, Proceedings of the ACL Workshop Incremental
Parsing: Bringing Engineering and Cognition To-
gether, pages 50?57, Barcelona, Spain, July. Asso-
ciation for Computational Linguistics.
M. Rayner, B.A. Hockey, and P. Bouillon. 2006.
Putting Linguistics into Speech Recognition: The
Regulus Grammar Compiler. CSLI Press, Chicago.
Carolyn P. Rose. 2000. A framework for robust se-
mantic interpretation. In Procs of NACL.
Yoav Seginer. 2007. Fast unsupervised incremental
parsing. In Proceedings of ACL, Prague, Czech Re-
public.
E. Selkirk. 1984. Phonology and Syntax. The rela-
tion between sound and structure. MIT Press, Cam-
bridge, USA.
Alexander Siebert and David Schlangen. 2008. A sim-
ple method for resolution of definite reference in a
shared visual context. In Procs of SIGdial, Colum-
bus, Ohio.
Alexander Siebert. 2007. Maschinelles Lernen
der Bedeutung referenzierender und relationaler
Ausdru?cke in einem Brettspieldialog. Diploma The-
sis, University of Potsdam.
Gabriel Skantze and David Schlangen. 2009. Incre-
mental dialogue processing in a micro-domain. In
Proceedings of EACL 2009, Athens, Greece, April.
Gabriel Skantze. 2007. Error Handling in Spoken Di-
alogue Systems. Ph.D. thesis, KTH, Stockholm.
Scott C. Stoness, Joel Tetreault, and James Allen.
2004. Incremental parsing with reference inter-
action. In Frank Keller, Stephen Clark, Matthew
Crocker, and Mark Steedman, editors, Proceedings
of the ACL Workshop Incremental Parsing: Bring-
ing Engineering and Cognition Together, Barcelona,
Spain, July.
David R. Traum, Lenhart K. Schubert, Massimo Poe-
sio, Nathaniel G. Martin, Marc Light, Chung Hee
Hwang, P. Heeman, George Ferguson, and James
Allen. 1996. Knowledge representation in the
trains-93 conversation system. International Jour-
nal of Expert Systems, 9(1):173?223.
Wayne H. Ward. 2008. The phoenix parser user man-
ual. http://cslr.colorado.edu/ whw/phoenix/phoenix-
manual.htm.
Klaus Zechner. 1998. Automatic construction of
frame representations for spontaneous speech in un-
restricted domains. In Proceedings of COLING-
ACL 1998, Montreal, Canada.
73
Proceedings of SIGDIAL 2009: the 10th Annual Meeting of the Special Interest Group in Discourse and Dialogue, pages 30?37,
Queen Mary University of London, September 2009. c?2009 Association for Computational Linguistics
Incremental Reference Resolution: The Task, Metrics for Evaluation, and
a Bayesian Filtering Model that is Sensitive to Disfluencies
David Schlangen, Timo Baumann, Michaela Atterer
Department of Linguistics
University of Potsdam, Germany
{das|timo|atterer}@ling.uni-potsdam.de
Abstract
In this paper we do two things: a) we dis-
cuss in general terms the task of incre-
mental reference resolution (IRR), in par-
ticular resolution of exophoric reference,
and specify metrics for measuring the per-
formance of dialogue system components
tackling this task, and b) we present a sim-
ple Bayesian filtering model of IRR that
performs reasonably well just using words
directly (no structure information and no
hand-coded semantics): it picks the right
referent out of 12 for around 50% of real-
world dialogue utterances in our test cor-
pus. It is also able to learn to interpret not
only words but also hesitations, just as hu-
mans have shown to do in similar situa-
tions, namely as markers of references to
hard-to-describe entities.
1 Introduction
Like other tasks involved in language comprehen-
sion, reference resolution?that is, the linking of
natural language expressions to contextually given
entities?is performed incrementally by human
listeners. This was shown for example by Tanen-
haus et al (1995) in a famous experiment where
addressees of utterances containing referring ex-
pressions made eye movements towards target ob-
jects very shortly after the end of the first word
that unambiguously specified the referent, even if
that wasn?t the final word of the phrase. In fact, as
has been shown in later experiments (Brennan and
Schober, 2001; Bailey and Ferreira, 2007; Arnold
et al, 2007), such disambiguating material doesn?t
even have to be lexical: under certain circum-
stances, a speaker?s hesitating already seems to be
understood as increasing the likelihood of subse-
quent reference to hard-to-describe entities.
Recently, efforts have begun to build dialogue
systems that make use of incremental processing
as well (Aist et al, 2006; Skantze and Schlangen,
2009). These efforts have so far focused on as-
pects other than resolution of references ((Stoness
et al, 2004) deals with the interaction of reference
and parsing). In this paper, we discuss in gen-
eral terms the task of incremental reference res-
olution (IRR) and specify metrics for evaluating
incremental components for this task. To make
the discussion more concrete, we also describe a
simple Bayesian filtering model of IRR in a do-
main with a small number of possible referents,
and show that it performs better wrt. our metrics
if given information about hesitations?thus pro-
viding computational support for the rationality of
including observables other than words into mod-
els of dialogue meaning.
The remainder of the paper is structured as fol-
lows: We discuss the IRR task in Section 2, and
suitable evaluation metrics in Section 3. In Sec-
tion 4 we describe and analyse the data for which
we present results with our Bayesian model for
IRR in Section 5.
2 Incremental Reference Resolution
To a first approximation, IRR can be modeled as
the ?inverse? as it were of the task of generating re-
ferring expressions (GRE; which is well-studied in
computational linguistics, see e. g. (Dale and Re-
iter, 1995)). Where in GRE words are added that
express features which reduce the size of the set
of possible distractors (with which the object that
the expression is intended to pick out can be con-
fused), in IRR words are encountered that express
features that reduce the size of the set of possible
30
referents. To give a concrete example, for the ex-
pression in (1-a), we could imagine that the logical
representation in (1-b) is built on a word-by-word
basis, and at each step the expression is checked
against the world model to see whether the refer-
ence has become unique.
(1) a. the red cross
b. ?x(red(x) ? cross(x))
To give an example, in a situation where there
are available for reference only one red cross, one
green circle, and two blue squares, we can say
that after ?the red? the referent should have been
found; in a world with two red crosses, we would
need to wait for further restricting information
(e. g. ?. . . on the left?).
This is one way to describe the task, then: a
component for incremental reference resolution
takes expressions as input in a word-by-word fash-
ion and delivers for each new input a set (possibly
a singleton set) as output which collects those dis-
course entities that are compatible with the expres-
sion up to that point. (This description is meant
to be neutral as to whether reference is exophoric,
i. e. directly to entities in the world, or anaphoric,
via previous mentions; we will mainly discuss the
former case, though.)
As we will see below, this does however
not translate directly into a usable metric for
evaluation. While it is easy to identify the
contributions of individual words in simple,
constructed expressions like (1-a), reference in
real conversations is often much more complex,
and is a collaborative process that isn?t confined
to single expressions (Clark and Schaefer, 1987):
referring is a pragmatic action that is not reducible
to denotation. In our corpus (see below), we often
find descriptions as in (2), where the speaker
continuously adds (rather vague) material, typi-
cally until the addressee signals that she identified
the item, or proposes a different way to describe it.
(2) Also das S Teil sieht so aus dass es ein
einzelnes . Teilchen hat . dann . vier am Stu?ck
im rechten Winkel .. dazu nee . nee warte ..
dann noch ein einzelnes das guckt auf der an-
deren Seite raus.
well, the S piece looks so that it has a single . piece .
and then . four together in a 90 degree angle .. and also
. no .. wait .. and then a single piece that sticks out on
the other side.
While it?s difficult to say in the individual case
what the appropriate moment is to settle on a hy-
pothesis about the intended referent, and what the
?correct? time-course of the development of hy-
potheses is, it?s easy to say what we want to be true
in general: we want a referent to be found as early
as possible, with as little change of opinion as pos-
sible during the utterance.1 Hence a model that
finds the correct referent earlier and makes fewer
wrong decisions than a competing one will be con-
sidered better. The metrics we develop in the next
section spell out this idea.
3 Evaluation Metrics for IRR
In previous work, we have discussed metrics for
evaluating the performance of incremental speech
recognition (Baumann et al, 2009). There, our
metrics could rely on time-aligned gold-standard
information against which the incremental results
could be measured. For the reasons discussed
in the previous section, we do not assume that
we have such temporally-aligned information for
evaluating IRR. Our measures described here sim-
ply assume that there is one intention behind the
referring utterances (namely to identify a certain
entity), and that this intention is there from the be-
ginning of the utterance and stays constant.2 This
is not to be understood as the claim that it is rea-
sonable to expect an IRR component to pick out a
referent even if the only part of the utterance that
has already been processed for example is ?now
take the??it just facilitates the ?earlier is better?
ranking discussed above.
We use two kinds of metrics for IRR: posi-
tional metrics, which measure when (which per-
centage into the utterance) a certain event happens,
and edit metrics which capture the ?jumpiness?
of the decision process (how often the component
changes its mind during an utterance).
Figure 1 shows a constructed example that il-
1We leave open here what ?as early as possible? means?
a well-trained model might be able to resolve a reference
before the speaker even deems that possible, and hence ap-
pear to do unnatural (or supernatural?) ?mind reading?. Con-
versely, frequent changes of opinion might be something that
human listeners would exhibit as well (e. g. in their gaze di-
rection). We abstract away from these finer details in our
heuristic.
2Note that our metrics would also work for corpora where
the correct point-of-identification is annotated; this would
simply move the reference point from the beginning of the
utterance to that point. Gallo et al (2007) describe an anno-
tation effort in a simpler domain where entities can easily be
described which would make such information available.
31
X F W F Fsil?model
no?sil?model X ? ?X F
first final
first correct
edit phase
take the
time
gold reference F
words (sil)
F F F
(sil)
F
f
Figure 1: Simple constructed example that illus-
trates the evaluation measures
lustrates these ideas. We assume that reference is
to an object that is internally represented by the
letter F. The example shows two models, no-sil
and sil (what exactly they are doesn?t matter for
now). The former model guesses that reference is
to object X already after the first word, and stays
with this opinion until it encounters the final word,
when it chooses F as most likely referent. (Why
the decision for the items sil is ?-? will be ex-
plained below; here this can be read as ?repetition
of previous decision?.) The other model changes
its mind more often, but also is correct for the first
time earlier and stays correct earlier. Our metrics
make this observation more precise:
? average fc (first correct): how deep into the ut-
terance do we make the first correct guess? (If the
decision component delivers n-best lists instead of
single guesses, ?correct? means here and below ?is
member of n-best list?.)
E. g., if the referent is recognised only after the
final word of the expression, the score for this met-
ric would be 1. In our example it is 2/5 for the
sil-model and 1 for the non-sil model.
? fc applicable: since the previous measure can
only be specified for cases where the correct refer-
ent has been found, we also specify for how many
utterances this is the case.
? average ff (first final): how deep into the utter-
ance do we make the correct guess and don?t sub-
sequently change our mind? This would be 4/5 for
the sil-model in our example and 1 for the no-sil-
model.
? ff applicable: again, the previous measure can
only be given where the final guess of the compo-
nent is correct, so we also need to specify how of-
ten this is the case. Note that whenever ff is appli-
cable, fc is applicable as well, so ff applicable?fc
applicable.
? ed-utt (mean edits per utterance): an IRR mod-
ule may still change its mind even after it has al-
ready made a correct guess. This metric measures
how often the module changes its mind before it
comes back to the right guess (if at all). Since such
decision-revisions (edits) may be costly for later
modules, which possibly need to retract their own
hypotheses that they?ve built based on the output
of this module, ideally this number should be low.
In our example the number of edits between fc
and ff is 2 for the sil-model and 0 for the non-sil
model (because here fc and ff are at the same po-
sition).
? eo (edit overhead): ratio unnecessary edits / nec-
essary edits. (In the ideal case, there is exactly one
edit, from ?no decision? to the correct guess.)
? correctness: how often the model guesses cor-
rectly. This is 3/5 for the sil-model in the example
and 1/5 for the non-sil-model.
? sil-correctness: how often the model guesses
correctly during hesitations. The correctness mea-
sure applied only to certain data-points; we use
this to investigate whether informing the model
about hesitations is helpful.
? adjusted error: some of our IRR models can re-
turn ?undecided? as reply. The correctness mea-
sures defined above would punish this in the same
way as a wrong guess. The adjusted error measure
implements the idea that undecidedness is better
than a wrong guess, at least early in the utterance.
More precisely, it?s defined to be 0 if the guess is
correct, pos / posmax if the reply is ?undecided?
(with pos denoting the position in the utterance),
and 1 if the guess is incorrect. That way uncer-
tainty is not punished in the beginning of the utter-
ance and counted like an error towards its end.
Note that these metrics characterise different as-
pects of the performance of a model. In practi-
cal cases, they may not be independent from each
other, and a system designer will have to decide
which one to optimize. If it is helpful to be in-
formed about a likely referent early, for example
to prepare a reaction, and is not terribly costly to
later have to revise hypotheses, then a low first cor-
rect may be the target. If hypothesis revisions are
costly, then a low edit overhead may be preferred
over a low first correct. (first final and ff applicable,
however, are parameters that are useful for global
optimisation.)
32
Figure 2: The Twelve Pentomino Pieces with their
canonical names (which were not known to the di-
alogue participants). The pieces used in the dia-
logues all had the same colour.
In the remaining sections, we describe a prob-
abilistic model of IRR that we have implemented,
and evaluate it in terms of these metrics. We begin
with describing the data from which we learnt our
model.
4 Data
4.1 Our Corpora
As the basis for training and testing of our model
we used data from three corpora of task-oriented
dialogue that differ in some details of the set-up,
but use the same task: an Instruction Giver (IG) in-
structs an Instruction Follower (IF) on which puz-
zle pieces (from the ?Pentomino? game, see Fig-
ure 2) to pick up. In detail, the corpora were:
? The Pento Naming corpus described in (Siebert
and Schlangen, 2008). In this variant of the task,
IG records instructions for an absent IF; so these
aren?t fully interactive dialogues. The corpus con-
tained 270 utterances out of which we selected
those 143 that contained descriptions of puzzle
pieces (and not of their position on the game-
board).
? Selections from the FTT/PTT corpus described
in (Ferna?ndez et al, 2007), where IF and IG are
connected through an audio-only connection, and
in some dialogues a simplex / push-to-talk one.
We selected all utterances from IG that contained
references to puzzle pieces (286 altogether).
? The third part of our corpus was constructed
specifically for the experiments described here.
We set-up a Wizard of Oz experiment where users
were given the task to describe puzzle pieces for
the ?dialogue system? to pick up. The system
(i. e. the wizard) had available a limited number
of utterances and hence could conduct only a lim-
ited form of dialogue. We collected 255 utter-
ances containing descriptions of puzzle pieces in
this way.
0.
0
0.
1
0.
2
0.
3
0.
4
tile
sl
rt
F I L N P T U V W X Y Z
Figure 3: Silence rate per referent and corpus
(WOz:black, PentoNaming:red, FTT:green)
All utterances were hand-transcribed and the
transcriptions were automatically aligned with the
speech data using the MAUS system (Schiel,
2004); this way, we could automatically identify
pauses during utterances and measure their length.
For some experiments (see below), pauses were
?re-ified? through the addition of silence pseudo-
words (one for each 333ms of silence).
The resulting corpus is not fully balanced in
terms of available material for the various pieces
or contributions by sub-corpora.
4.2 Descriptive Statistics
We were interested to see whether intra-utterance
silences (hesitations) could potentially be used as
an information source in our (more or less) real-
world data in the same way as was shown in
the much more controlled situations described in
the psycholinguistics literature mentioned above
in the introduction (Arnold et al, 2007). Fig-
ure 3 shows the mean ratio of within-utterance si-
lences per word for the different corpora and dif-
ferent referents. We can see that there are clear
differences between the pieces. For example, ref-
erences to the piece whose canonical name is X
contain very few or short hesitations, whereas ref-
erences to Y tend to contain many. We can also
see that the tendencies seem to be remarkably sim-
ilar between corpora, but with relatively stable off-
sets between them, PentoDescr having the longest,
PTT/FTT the shortest silences. We speculate that
this is the result of the differing degrees of inter-
activity (none in PentoDescr, restricted in WOz,
less restricted in PTT, free in FTT) which puts dif-
ferent pressures on speakers to avoid silences. To
balance our data with respect to this difference, we
performed some experiments with adjusted data
33
where silence lengths in PentoDescr were adjusted
by 0.7 and in PTT/FTT by 1.3. This brings the si-
lence rates in the corpora, if plotted in the style of
Figure 3, almost in congruence.
To test whether the differences in silence rate
between utterances referring to different pieces
are significant, we performed an ANOVA and
found a main effect of silence rate, F (11, 672) =
6.2102, p < 8.714?10. A post-hoc t-test reveals
that there are roughly two groups whose members
are not significantly different within-group, but are
across groups: I, L, U, W and X form one group
with relatively low silence rate, F, N, P, T, V, Y, and
Z another with relatively high silence rate. We will
see in the next section whether our model picked
up on these differences.
5 A Bayesian Filtering Model of IRR
To explore incremental reference resolution, and
as part of a larger incremental dialogue system we
are building, we implemented a probabilistic refer-
ence resolver that works in the pentomino domain.
At its base, the resolver has a Bayesian Filtering
model (see e. g. (Thrun et al, 2005)) that with each
new observation (word) computes a belief distri-
bution over the available objects (the twelve puz-
zle pieces); in a second step, a decision for a piece
(or a collection of pieces in the n-best case) is de-
rived from this distribution. This model is incre-
mental in a very natural and direct way: new input
increments are simply treated as new observations
that update the current belief state. Note that this
model does not start with any assumptions about
semantic word classes: whether an observed word
carries information about what is being referred to
will be learnt from data.
5.1 The Belief-Update Model
We use a Bayesian model which treats the in-
tended referent as a latent variable generating a
sequence of observations (w1:n is the sequence of
words w1, w2, . . . , wn):
P (r|w1:n) = ? ? P (wn|r, w1:n?1) ? P (r|w1:n?1)
where
? P (wn|r, w1:n?1) is the likelihood of the new
observation (see below for how we approximate
that); and
? the prior P (r|w1:n?1) at step n is the posterior
of the previous step. Before the first observation is
made (i. e., the first word is seen), the prior is sim-
ply a distribution over the possible referents, P (r).
F I L N P T U V W X Y Z
intended referent:  N
 nimm <sil?0> <sil?1> <sil?2> das teil <sil?0> <sil?1> <sil?2> <sil?3> das aus einer
0.
0
0.
1
0.
2
0.
3
0.
4
Figure 4: Example of Belief Distribution after Ob-
servation
In our experiment, we set this to a uniform distri-
bution, but if there is prior information from other
sources (e. g., because the dialogue state makes
certain pieces more salient), this can be reflected.
? ? is a normalising constant, ensuring that the re-
sult is indeed a probability distribution.
The output of the model is a distribution of be-
lief over the 12 available entities, as shown in Fig-
ure 4. Figure 5 shows in a 3D plot the devel-
opment of the belief state (pieces from front to
back, strength of belief as height of the peaks) over
the course of a whole utterance (with observations
from left to right).
5.2 The Decision Step
We implemented several ways to derive a decision
for a referent from such a distribution:
i) In the arg max approach, at each state the ref-
erent with the highest posterior probability is cho-
sen. For Figure 4, that would be F (and hence,
a wrong decision). As Figure 5 shows (and the
example is quite representative for the model be-
haviour), there often are various local maxima
over the course of an utterance, and hence a model
that takes as its decision always the maximum can
be expected to perform many edits.
ii) In the adaptive threshold approach, we start
with a default decision for a special 13th class,
?undecided?, and a new decision is only made if
the maximal value at the current step is above a
certain threshold, where this threshold is reset ev-
ery time this condition is met. In other words, this
draws a plane into the belief space and only makes
a new decision when a peak rises above this plane
and hence above the previous peak. In effect, this
approach favours strong convictions and reduces
34
utterance #: 230 intended referent:  N
 hast eine lange ule mit drei teilen <sil?0> <sil?1> und eine kurze mit zwei
Z, Y, X, W, V, U, T, P, N, L, I, F
as.matrix(norm.vect[, 1:12])
0.0
0.2
0.4
0.6
0.8
1.0
Figure 5: Belief Update over Course of Utterance
the ?jitter? in the decision making.
In our example from Figure 4, this would mean
that the maximum, F, would only be the decision
if its value was higher than the threshold and there
was no previous guess that was even higher.
iii) The final model implements a threshold n-
best approach, where not just a single piece is se-
lected but all pieces that are above a certain thresh-
old. Assuming that the threshold is 0.1 for exam-
ple this would select F, I, N, Y, and Z?and hence
would include the correct reference in Figure 4.
5.3 Implementation
To learn and query the observation likelihoods
P (wn|r, w1:n?1), we used referent-specific lan-
guage models. More precisely, we computed the
likelihood as P (r, w1:n)/P (r, w1:n?1) (definition
conditional probability), and approximated the
joint probabilities of referent and word sequence
via n-grams with specialised words. E. g., an ut-
terance like ?take the long, narrow piece? refer-
ring to piece I (or tested for reference to this piece)
would be rewritten as ?take I the I long I narrow I
piece I? and presented to the n-gram learner / in-
ference component. (Both taken from the SRI LM
package, (Stolcke, 2002).)
During evaluation of the models, the test utter-
ances are fed word-by-word to the model and the
decision is evaluated against the known intended
referent. Since we were interested in testing
whether disfluencies contained information that
would be learned, for one variant of the system
we also fed pseudo-words for silences and hesi-
tation markers like uhm, numbered by their posi-
tion (i. e., ?take the ..? becomes ?take the sil-1 sil-
2?), to both learning and inference for the silence-
sensitive variant; the silence-ignorant variant sim-
ply repeats the previous decision at such points
and does not update its belief state; this way, it
is guaranteed that both variants generate the same
number of decisions and can be compared directly.
(Cf. the dashes in the ?no-sil-model? in Figure 1
above: those are points where no real computation
is made in the no-sil case.)
5.4 Experiments
All experiments were performed with 10-fold
cross-validation. We always ran both versions, the
one that showed silences to the model and the one
that didn?t. We tested various combinations of lan-
guage model parameters and deciders, of which
the best-performing ones are discussed in the next
section.
5.5 Results
Table 1 shows the results for the different deci-
sion methods and for models where silences are
included as observations and where they aren?t,
and, as a baseline, the result for a resolver that
makes a random decision after each observation.
As we can see, the different decision methods
have different characteristics wrt. individual mea-
sures. The threshold n-best approach performs
best across the board?but of course has a slightly
easier job since it does not need to make unam-
biguous decisions. We will look into the develop-
ment of the n-best lists in a second, but for now
we note that this model is for almost all utterances
correct at least once (97% fc applicable) and if
so, typically very early (after 30% of the utter-
ance). In over half of the cases (54.68%), the fi-
nal decision is correct (i. e. is an n-best list that
contains the correct referent), and similarly for a
good third of all silence observations. Interest-
ingly, silence-correctness is decidedly higher for
the silence model (which does actually make new
decisions during silences and hence based on the
information that the speaker is hesitating) than for
the non-sil model (which at these places only re-
peats the previously made decision). The model
performs significantly bettern than a baseline that
randomly selects n-best lists of the same size (see
rnd-nb in Table 1).
As can be expected, the adaptive threshold ap-
proach is more stable with its decisions, as wit-
nessed by the low edit overhead. The fact that it
changes its decision not as often has an impact on
the other measures, though: in more cases, the
model is correct not even once (fc applicable is
35
n-best rnd-nb adapt max random
Measure / Model w/ h w/o h w/ h w/ h w/o h w/ h w/o h w/ h
fc applicable 97.22% 95.03% 85.38% 63.15% 66.67% 86.55% 82.89% 59.94%
average fc 30.43% 33.73% 29.61% 53.87% 55.25% 46.55% 49.31% 42.60%
ff applicable 54.68% 54.24% 17.54% 48.68% 53.07% 39.77% 40.64% 9.65%
average ff 87.74% 85.01% 97.08% 71.24% 70.89% 96.08% 94.28% 98.44%
edit overhead 93.49% 90.65% 96.65% 69.61% 67.66% 92.57% 89.44% 93.16%
correctness 37.81% 36.81% 23.37% 23.01% 26.61% 17.83% 20.23% 7.83%
sil-correctness 36.60% 31.09% 26.39% 18.71% 22.58% 13.67% 19.34% 8.63%
adjusted error 60.07% 56.96% 76.63% 76.29% 70.90% 82.17% 79.42% 92.16%
Table 1: Results for different decision methods (n-best, adaptive, max arg and random) and for models
with and without silence-observations (w/ h and w/o h, respectively)
lower than for the other two models). But it is
still correct with almost half of its final decisions,
and these come even earlier than for the n-best
model. Silence information does not seem to help
this model; this suggests that the information pro-
vided by knowledge about the fact that the speaker
hesitates is too subtle to push through the thresh-
old in order to change decisions.
The arg max approach fares worst. Since nei-
ther the relative strength of the strongest belief (as
compared to that in the competing pieces) nor the
global strength (have I been more convinced be-
fore?) is taken into account, the model changes
its mind too often, as evidenced by the edit over-
head, and does not settle on the correct referent of-
ten (and if, then late). Again, silence information
does not seem to be helpful for this model.
As a more detailed look at what happens dur-
ing silence sequences, Figure 6 plots the average
change in probability from onset of silence to a
point at 1333ms of silence. (Recall that the un-
derlying Bayesian model is the same for all mod-
els evaluated above, they differ only in how they
derive a decision.) We can see that the gains and
losses are roughly as expected from the analysis of
the corpora: pieces like L and P become more ex-
pected after a silence of that length, pieces like X
less. So the model does indeed seem to learn that
hesitations systematically occur together with cer-
tain pieces. (The reader can convince herself with
the help of Figure 2 that these shapes are indeed
comparatively hard-to-describe; but the interesting
point here is that this categorisation does not have
to be brought to the model but rather is discovered
by it.)
Finally, a look at the distribution and the sizes of
the n-best groupings: the most frequent decision is
F I L N P T U V W X Y Z
?
0.
05
0.
00
0.
05
Figure 6: Average change in probability from on-
set of silence to 1333ms into silence
?undecided? (474 times), followed by the group-
ings F N, N Y, and N Y P (343, 342 and 196, re-
spectively). Here again we find groupings that re-
flect the differences w.r.t. hesitation rate. The av-
erage size of the n-best lists is 2.58 (sd = 1.4).
6 Conclusions and Further Work
We discussed the task of incremental reference
resolution (IRR), in particular with respect to ex-
ophoric reference. From a theoretical perspective,
it might seem easy to specify what the ideal be-
haviour of an IRR component should be, namely
to always produce the set of entities (the exten-
sion) that is compatible with the part of the ex-
pression seen so far. In practice, however, this is
difficult to annotate, for both practical reasons as
well as theoretical (referring is a pragmatic activ-
ity that is not reducible to denotation). The met-
rics we defined for evaluation of IRR components
account for this in that they do not require a gold
36
standard annotation that fixes the dynamics of the
resolution process; they simply make it possible
to quantify the assumption that ?early and with
strong convictions? is best.
We then presented our probabilistic model of
IRR that works directly on word observations
without any further processing (POS tagging,
parsing). It achieves a reasonable success (as mea-
sured with our metrics); for example, in over half
of the cases, the final guess of the model is correct,
and comes before the utterance is over. As an ad-
ditional interesting feature, the model is able to in-
terpret hesitations (silences lifted to pseudo-word
status) in a way shown before only in controlled
psycholinguistic experiments, namely as making
reference to hard-to-describe pieces more likely.3
In future work, we want to explore the model?s
performance on ASR output. It is not clear a
priori that this would degrade performance much,
as it can be expected that the learning components
are quite robust against noise. Connected to
this, we want to explore more complex statis-
tical models, e. g. a hierarchical model where
one level generates parts of the utterance (e. g.
non-referential parts and referential parts) and the
second the actual words. We also want to test how
this approach scales up to worlds with a larger
number of possible referents, where consequently
approximation methods like particle filtering have
to be used. Finally, we will test how the module
contributes to a working dialogue system, where
further decisions (e. g. for clarification requests)
can be built on its output.
Acknowledgments This work was funded by
a grant from DFG in the Emmy Noether Pro-
gramme. We would like to thank the anonymous
reviewers for their detailed comments.
References
G.S. Aist, J. Allen, E. Campana, L. Galescu, C.A.
Gomez Gallo, S. Stoness, M. Swift, and M Tanenhaus.
2006. Software architectures for incremental understand-
ing of human speech. In Proceedings of the Interna-
tional Conference on Spoken Language Processing (IC-
SLP), Pittsburgh, PA, USA, September.
Jennifer E. Arnold, Carla L. Hudson Kam, and Michael K.
Tanenhaus. 2007. If you say thee uh you are describ-
ing something hard: The on-line attribution of disfluency
3It is interesting to speculate whether this could have im-
plications for generation of referring expressions as well. It
might be a good strategy to make your planning problems
observable or even to fake planning problems that are under-
standable to humans.
during reference comprehension. Journal of Experimental
Psychology.
Karl Bailey and F. Ferreira. 2007. The processing of filled
pause disfluencies in the visual world. In R. P. G. von
Gompel, M H. Fischer, W. S. Murray, and R. L. Hill,
editors, Eye Movements: A Window on Mind and Brain,
chapter 22. Elsevier.
Timo Baumann, Michaela Atterer, and David Schlangen.
2009. Assessing and Improving the Performance of
Speech Recognition for Incremental Systems. In Proceed-
ings of NAACL-HLT 2009, Boulder, USA.
Susan E. Brennan and Michael F. Schober. 2001. How lis-
teners compensate for disfluencies in spontaneous speech.
Journal of Memory and Language, 44:274?296.
Herbert H. Clark and Edward F. Schaefer. 1987. Collabo-
rating on contributions to conversations. Language and
Cognitive Processes, 2(1):19?41.
Robert Dale and Ehud Reiter. 1995. Computational interpre-
tations of the gricean maxims in the generation of referring
expressions. Cognitive Science, 19:233?263.
Raquel Ferna?ndez, David Schlangen, and Tatjana Lucht.
2007. Push-to-talk ain?t always bad! comparing differ-
ent interactivity settings in task-oriented dialogue. In Pro-
ceeding of DECALOG (SemDial?07), Trento, Italy, June.
Carlos Go?mez Gallo, Gregory Aist, James Allen, William
de Beaumont, Sergio Coria, Whitney Gegg-Harrison,
Joana Paulo Pardal, and Mary Swift. 2007. Annotating
continuous understanding in a multimodal dialogue cor-
pus. In Proceeding of DECALOG (SemDial07), Trento,
Italy, June.
Florian Schiel. 2004. Maus goes iterative. In Proc. of the
IV. International Conference on Language Resources and
Evaluation, Lisbon, Portugal.
Alexander Siebert and David Schlangen. 2008. A simple
method for resolution of definite reference in a shared vi-
sual context. In Procs of SIGdial, Columbus, Ohio.
Gabriel Skantze and David Schlangen. 2009. Incremental
dialogue processing in a micro-domain. In Proceedings of
EACL 2009, Athens, Greece, April.
Andreas Stolcke. 2002. SRILM - an extensible language
modeling toolkit. In Proceedings Intl. Conf. Spoken Lan-
guage Processing (ICSLP?02), Denver, Colorado, USA,
September.
Scott C. Stoness, Joel Tetreault, and James Allen. 2004. In-
cremental parsing with reference interaction. In Proceed-
ings of the Workshop on Incremental Parsing at the ACL
2004, pages 18?25, Barcelona, Spain, July.
Michael K. Tanenhaus, Michael J. Spivey-Knowlton, Kath-
llen M. Eberhard, and Julie C. Sedivy. 1995. Intergration
of visual and linguistic information in spoken language
comprehension. Science, 268.
Sebastian Thrun, Wolfram Burgard, and Dieter Fox. 2005.
Probabilistic Robotics. MIT Press, Cambridge, Mas-
sachusetts, USA.
37
Proceedings of SIGDIAL 2009: the 10th Annual Meeting of the Special Interest Group in Discourse and Dialogue, pages 302?305,
Queen Mary University of London, September 2009. c?2009 Association for Computational Linguistics
TELIDA: A Package for Manipulation and Visualization of
Timed Linguistic Data
Titus von der Malsburg, Timo Baumann, David Schlangen
Department of Linguistics
University of Potsdam, Germany
{malsburg|timo|das}@ling.uni-potsdam.de
Abstract
We present a toolkit for manipulating and
visualising time-aligned linguistic data
such as dialogue transcripts or language
processing data. The package comple-
ments existing editing tools by allowing
for conversion between their formats, in-
formation extraction from the raw files,
and by adding sophisticated, and easily ex-
tended methods for visualising the dynam-
ics of dialogue processing. To illustrate
the versatility of the package, we describe
its use in three different projects at our site.
1 Introduction
Manual inspection and visualization of raw data is
often an important first step in the analysis of lin-
guistic data, be that transcripts of conversations or
records of the performance of processing modules.
Dialogue data or speech processing data in gen-
eral are typically temporally aligned, which poses
additional challenges for handling and visualiza-
tion. A number of tools are available for work-
ing with timed data, each with different focus:
as a small selection, Praat (Boersma, 2001) and
Wavesurfer (Sjo?lander and Beskow, 2000) excel at
acoustic analysis and are helpful for transcription
work, Anvil (Kipp, 2001) helps with the analysis
of video material, Exmaralda (Schmidt, 2004) of-
fers a suite of specialized tools for discourse anal-
ysis.
We developed TELIDA (TimEd LInguistic
DAta) to complement the strengths of these tools.
TELIDA comprises (a) a suite of Perl mod-
ules that offer flexible data structures for stor-
ing timed data; tools for converting data in other
formats to and from this format; a command-
line based interface for querying such data, en-
abling for example statistical analysis outside of
the original creators of transcriptions or annota-
tions; and (b) a lightweight but powerful visual-
ization tool, TEDview, that has certain unique fea-
tures, as will be described in Section 2.3. TEL-
IDA is available for download from http://www.
ling.uni-potsdam.de/~timo/code/telida/.
2 Overview of TELIDA
2.1 Data Structures
Like the tools mentioned above, we handle timed
data as discrete labels which span a certain time
and contain some data. To give an example, in a
word-aligned transcription of a recording, a single
word would correspond to one label. Sequences
of (non-overlapping) labels are collected into what
we call alignments. In our example of the word-
aligned transcription, all words from one speaker
might be collected in one alignment.
This so far is a conceptualization that is com-
mon to many tools. In Praat for example, our
alignments would be called a tier. TELIDA adds a
further, novel, abstraction, by treating alignments
as belief states that can have a time (namely that
of their formation) as well. Concretely, an incre-
mental ASR may hypothesize a certain way of an-
alyzing a stretch of sound at one point, but at a
later point might slighlty adapt this analysis; in our
conceptualization, this would be two alignments
that model the same original data, each with a time
stamp. For other applications, timed belief states
may contain other information, e.g. new states of
parse constructions or dialogue manager informa-
tion states. We also allow to store several of such
alignment sequences (= successive belief states) in
parallel, to represent n-best lists.
302
Figure 1: TEDview Showing Annotated Dialogue Data
A document finally can consist of collections
of such alignments that reference the same time-
line, but model different aspects of the base-data.
For example, we may want to store information
about turns, how they decompose into words, and
into phonemes; or, for dual-channel dialogue, have
separate alignments for the different speakers.
2.2 Data Manipulation Tools
In order to process timed linguistic data, we im-
plemented a Perl library and command-line tools,
TGtool and INtool for non-incremental and incre-
mental data respectively. They facilitate handling
(showing, merging, editing, . . . ) and processing
(search-and-replace, hypothesis filtering, . . . ) of
data and interface to TEDview for interactive vi-
sualization.
2.3 TEDview
TEDview is the visualization component of TEL-
IDA. It organizes the different sources of informa-
tion (i.e., alignments or alignment sequences) in
horizontal tracks. Similar as in many of the above-
mentioned tools, time progresses from left to right
in those tracks. The content of tracks consists of
events that are displayed as bars if they have a tem-
poral extent or as diamonds otherwise. TEDview
uses a player metaphor and therefore has a cursor
that marks the current time and a play-mode that
can be used to replay recorded sequences of events
(in real-time or sped-up / slowed-down). Unlike in
other tools, TEDview has a steady cursor (the red
line in the Figures) across which events flow, and
this cursor can be moved, e.g. to give a configura-
tion where no future events are shown.
Information encapsulated by events is displayed
in two different ways:
a) Labels are represented as bars, with the la-
bel information shown as text. (Figure 1 shows a
configuration with only labels.)
b) Events without duration are displayed as di-
amonds at the appropriate time (all other Figures).
Such events can carry a ?payload?; depending on
its type, different display methods are chosen:
? If the payload is an alignment, it is displayed
on the same track, as a sequence of labels.
? In all other cases TEDview determines the
data type of the information and selects an appro-
priate plug-in for displaying it in a separate inspec-
tor window. These data types can be syntax trees,
probability distributions, etc.
To avoid visual clutter, only the information
contained in the diamonds that most recently
passed the cursor are displayed. In this way, TED-
view can elegantly visualize the dynamics of in-
formation state development.
Events can be fed to TEDview either from a file,
in a use case where pre-recorded material is re-
played for analysis, or online, via a network con-
nection, in use cases where processing compo-
nents are monitored or profiled in real-time. The
format used to encode events and their encapsu-
303
Figure 2: TEDview showing different filtering
strategies for incremental ASR: Diamonds corre-
spond to edits of the hypothesis.
lated information is a simple and generic XML
format (which the data manipulation tools can cre-
ate out of other formats, if necessary), i.e. the for-
mat does not make any assumptions as to what the
events represent. For this reason TEDview can be
used to visualize almost any type of discrete tem-
poral data. Intervals can be adorned with display
information, for example to encode further infor-
mation via colouring. Plug-ins for special data-
types can be written in the programming language
Python with its powerful library of extension mod-
ules; this enabled us to implement an inspector for
syntax trees in only 20 lines of code.
3 Use Cases
To illustrate the versatility of the tool, we now de-
scribe how we use it in several projects at our site.
(Technical manuals can be downloaded from the
page listed above.)
3.1 Analysis of Dialogue Data
In the DEAWU project (see e.g. (Schlangen and
Ferna?ndez, 2007)), we used the package to main-
tain transcriptions made in Praat and annotations
made in MMAX2 (Mu?ller and Strube, 2006), and
to visualize these together in a time-aligned view.
As Figure 1 shows, we made heavy use of the
possibility of encoding information via colour. In
the example, there is one track (mac, for mouse
activity) where a numerical value (how much the
mouse travels in a certain time frame) is visual-
ized through the colouring of the interval. In other
tracks other information is encoded through colour
as well. We found this to be of much use in the
?getting to know the data? phase of the analysis of
our experiment. We have also used the tool and
the data in teaching about dialogue structure.
Figure 3: TEDview showing 5-best incremental
ASR hypotheses.
3.2 Analysis of SDS Performance
In another project, we use TELIDA to analyze and
visualize the incremental output of several mod-
ules of a spoken dialogue system we are currently
developing.
In incremental speech recognition, what is con-
sidered the best hypothesis frequently changes as
more speech comes in. We used TEDview to an-
alyze these changes and to develop filtering meth-
ods to reduce the jitter and to reduce edits of the
ASR?s incremental hypothesis (Baumann et al,
2009a). Figure 2 shows incremental hypotheses
and different settings of two filtering strategies.
When evaluating the utility of using n-best ASR
hypotheses, we used TEDview to visualize the
best hypotheses (Baumann et al, 2009b). An in-
teresting result we got from this analysis is that
typically the best hypothesis seems to be more sta-
ble than lower-ranked hypotheses, as can be seen
in Figure 3.
We also evaluated the behaviour of our in-
cremental reference resolution module, which
outputs distributions over possible referents
(Schlangen et al, 2009). We implemented a TED-
view plug-in to show distributions in bar-charts, as
can be seen in Figure 4.
3.3 Analysis of Cognitive Models
In another project, we use TEDview to visualize
the output of an ACT-R (Anderson et al, 2004)
simulation of human sentence parsing developed
by (Patil et al, 2009). This model produces
predictions of parsing costs based on working-
memory load which in turn are used to predict
eye tracking measures in reading. Figure 5 shows
an example where the German sentence ?Den Ton
gab der Ku?nstler seinem Gehilfen? (the artist gives
the clay to his assistant) is being parsed, taking
304
Figure 4: TEDview showing the output of our in-
cremental reference resolution module. Distribu-
tions are shown with a bar-chart plug-in.
about 3 seconds of simulated time. The items in
the channel labeled ?Memory? indicate retrievals
of items from memory, the items in the channel la-
beled ?Parse? indicate that the parser produced a
new hypothesis, and the inspector window on the
right shows the latest of these hypotheses accord-
ing to cursor time. The grey bars finally in the
remaining channels show the activity of the pro-
duction rules. Such visualizations help to quickly
grasp the behaviour of a model, and so greatly aid
development and debugging.
4 Conclusions
We presented TELIDA, a package for the manip-
ulation and visualization of temporally aligned
(linguistic) data. The package enables convenient
handling of dynamic data, especially from incre-
mental processing, but more generally from all
kinds of belief update. We believe that it can be
of use to anyone who is interested in exploring
complex state changes over time, be that in
dialogue annotations or in system performance
profiles.
Acknowledgments This work was funded by
a grant from DFG in the Emmy Noether Pro-
gramme.
References
J.R. Anderson, D. Bothell, M.D. Byrne, S. Douglass,
C. Lebiere, and Y. Qin. 2004. An integrated theory of
the mind. Psychological Review, 111(4):1036?1060.
Timo Baumann, Michaela Atterer, and David Schlangen.
2009a. Assessing and Improving the Performance of
Speech Recognition for Incremental Systems. In Proceed-
ings of NAACL-HLT 2009, Boulder, USA.
Figure 5: TEDview visualizing the dynamics of
an ACT-R simulation, including the current parse-
tree.
Timo Baumann, Okko Bu?, Michaela Atterer, and David
Schlangen. 2009b. Evaluating the Potential Utility of
ASR N-Best Lists for Incremental Spoken Dialogue Sys-
tems. In Proceedings of Interspeech 2009, Brighton, UK.
Paul Boersma. 2001. Praat, a system for doing phonetics by
computer. Glot International, 5(9?10):341?345.
Michael Kipp. 2001. Anvil - a generic annotation tool for
multimodal dialogue. In Proceedings of the 7th Euro-
pean Conference on Speech Communication and Technol-
ogy (Eurospeech), pages 1367?1370, Aalborg, Denmark.
Christoph Mu?ller and Michael Strube. 2006. Multi-level an-
notation of linguistic data with MMAX2. In Corpus Tech-
nology and Language Pedagogy: New Resources, New
Tools, New Methods, pages 197?214. Peter Lang.
Umesh Patil, Marisa Ferrara Boston, John T. Hale, Shravan
Vasishth, and Reinhold Kliegl. 2009. The interaction of
surprisal and working memory cost during reading. In
Proc. of the CUNY sentence processing conference, Davis,
USA.
David Schlangen and Raquel Ferna?ndez. 2007. Speaking
through a noisy channel - experiments on inducing clarifi-
cation behaviour in human-human dialogue. In Proceed-
ings of Interspeech 2007, Antwerp, Belgium.
David Schlangen, Timo Baumann, and Michaela Atterer.
2009. Incremental Reference Resolution: The Task, Met-
rics for Evaluation, and a Bayesian Filtering Model that is
Sensitive to Disfluencies. In Proc. of SigDial 2009, Lon-
don, UK.
Thomas Schmidt. 2004. Transcribing and annotating spoken
language with exmaralda. In Proceedings of the LREC-
Workshop on XML based richly annotated corpora, Lis-
bon 2004, Paris. ELRA. EN.
K. Sjo?lander and J. Beskow. 2000. Wavesurfer?an open
source speech tool. In Sixth International Conference on
Spoken Language Processing, Beijing, China. ISCA.
305
Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,
pages 1803?1812, Dublin, Ireland, August 23-29 2014.
Situated Incremental Natural Language Understanding using a
Multimodal, Linguistically-driven Update Model
Casey Kennington
CITEC, Bielefeld University
ckennington
1
Spyros Kousidis
Bielefeld University
spyros.kousidis
2
1
@cit-ec.uni-bielefeld.de
2
@uni-bielefeld.de
David Schlangen
Bielefeld University
david.schlangen
2
Abstract
A common site of language use is interactive dialogue between two people situated together in
shared time and space. In this paper, we present a statistical model for understanding natural
human language that works incrementally (i.e., does not wait until the end of an utterance to
begin processing), and is grounded by linking semantic entities with objects in a shared space.
We describe our model, show how a semantic meaning representation is grounded with properties
of real-world objects, and further show that it can ground with embodied, interactive cues such
as pointing gestures or eye gaze.
1 Introduction
Dialogue between co-located participants is possibly the most common form of language use (Clark,
1996). It is highly interactive (time is shared between two participants), interlocutors can refer to ob-
jects in their visual field (space is also shared), and visual cues such as gaze or pointing gestures often
play a role (shared time and space). Most computational dialogue research focuses only one of these
constraints.
In this paper, we present a model that processes incrementally (i.e., can potentially work interactively),
can make use of the visual world by symbolically representing objects in a scene, and incorporate gaze
and gestures. The model can learn from conversational data and can potentially be used in an application
for a situated dialogue system, such as an autonomous robot.
In the following section we will provide background and present related work. That will be followed
by a description of the task and the model. In Section 4 we will show how our model performs in two
experiments, the first uses speech and a visual scene, the second incorporates visual cues.
2 Background and Related Work
2.1 Background: Incremental Dialogue Processing
Dialogue systems that process incrementally produce behavior that is perceived by human users to be
more natural than systems that use a turn-based approach (Aist et al., 2006; Skantze and Schlangen, 2009;
Skantze and Hjalmarsson, 2010). Incremental dialogue has seen improvements in speech recognition
(Baumann et al., 2009), speech synthesis (Buschmeier et al., 2012), and dialogue management (Bu? et
al., 2010; Selfridge et al., 2012). Futhermore, architectures for incremental dialogue systems have been
proposed (Schlangen and Skantze, 2009; Schlangen and Skantze, 2011) and incremental toolkits are also
available (Baumann and Schlangen, 2012).
In this paper, we approach natural language understanding (NLU), which aims to map an utterance to
an intention, as a component in the incremental model of dialogue processing as described in (Schlangen
and Skantze, 2011; Schlangen and Skantze, 2009), where incremental systems consist of a network of
processing modules. Each module has a left buffer and a right buffer, where a typical module takes input
This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer
are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/
1803
Figure 1: Example of an IU network composed of words, parts of speech (POS), a semtic representation
(Robust Minimal Recursion Semantics; RMRS), and NLU modules. Solid arrows represent GRIN links
and the dotted lines represent SLLs. The utterance take the red cross is represented as word IUs, which
are GRIN by the part of speech tags, phrase-structure parse, semantic representation, and the intention.
Note that red and cross are GRIN by the same syntactic IU, which in turn is GRIN by two semantic IUs.
Succeeding levels of IUs are shifted slightly to the right, representing a processing delay. The X14 slot
in the bolded NLU frame refers to the cross-shaped object in the game board on the right.
from its left buffer, performs some kind of processing on that data, and places the processed result onto
its right buffer. The data are packaged as the payload of incremental units (IU) which are passed between
modules. The IUs themselves are also interconnected via so-called same level links (SLL) and grounded-
in links (GRIN), the former allowing the linking of IUs as a growing sequence, the latter allowing that
sequence to convey what IUs directly affect them. See Figure 1 for an example; each layer represents a
module in the IU-module network and each node is an IU in the IU network. The focus of this paper is
the top layer (module), but how it is produced depends on the layers below it.
2.2 Related Work
The work presented in this paper connects and extends recent work in grounded semantics (Roy, 2005;
Hsiao et al., 2008; Liu et al., 2012; Chai et al., 2014), which aims to connect language with the world,
but typically does not work incrementally; semantic parsing / statistical natural language understanding
via logical forms (Zettlemoyer and Collins, 2007; Zettlemoyer and Collins, 2009), dependency-based
compositional semantics (Liang et al., 2011), neural networks (Huang and Er, 2010), Markov Logic
Networks (Meurs et al., 2008; Meza-Ruiz et al., 2008), and Dynamic Bayesian Networks (Meurs et al.,
2009); see also overviews of NLU in (De Mori et al., 2008; Tur and De Mori, 2011), but typically neither
provide situated interpretations nor incremental specifications of the representations; incremental NLU
(DeVault et al., 2009; DeVault et al., 2011; Aist et al., 2007; Schlangen and Skantze, 2009), which
focuses on incrementality, but not on situational grounding; as well as integration of gaze into language
understanding (Prasov and Chai, 2010).
We move beyond this work in that we present a model that is incremental, uses a form of grounded se-
mantics, can easily incorporate multi-modal information sources, and which inference can be performed
quickly, satisfying the demands of real-time dialogue.
3 Task and Model
3.1 Task
The task for our model is as follows: to compute at any moment a distribution over possible intentions
which the speaker wanted to convey in the utterance, expressed as semantic frames, given the unfolding
utterance and information about the state of the world in which the utterance is happening. The slots of
these frames are to be filled with semantic constants, that is, they are uniquely resolved, if appropriate,
to objects in the shared environment. This is illustrated in Figure 1 where the words of the utterance give
1804
rise to the part-of-speech tags, the incrementally growing syntax, semantic representation, and, finally,
the intention. Note how x14 in the bolded NLU frame resolves to an object identifier for a real object in
the shared scene (red cross in the bottom-left of the game board shown on the right in the figure).
3.2 Model
Kennington et al., (2013) presented a simple, incremental model of NLU, which is an update model
(i.e., increments build on previous ones) and which can potentially work in real time and in situated
environments. The goal of the model is to recover I , the intention of the speaker behind the utterance,
word by word. We observe U , the current word (or in this paper, a semantic meaning representation,
see below) and an unobserved mediating variable R which represents visual or abstract properties of the
object of the intention. Formally, we are interested in P (I|U), the probability of a certain intention I
underlying utterance U . We assume a latent variable R (pRoperties of entities in the world), and build
a generative model (that is, model the joint P (I,R, U)). Going from P (I,R|U) and making certain
independence assumptions, we arrive at
P (I|U) =
P (I)
P (U)
?
r?R
P (U |R = r)P (R = r|I) (1)
That is, we assume that R is only conditional on I , and U is only conditional on R, and we can move
P (I) and P (U) out of the summation, as they do not depend on R. This is an update model in the usual
sense that the posterior (P (I|U)) at one step becomes the prior (P (I)) at the next. P (R|I) provides the
link between the intentions and the properties.
Another variant of the model which we will use in this paper is as follows: we rewrite P (U |R) using
Bayes? rule, which cancels P (U) and introduces P (R) into the summation, but P (R) can be dropped
since (in this work) it can be approximated with a uniform distribution, yielding:
P (I|U) = P (I)
?
r?R
P (R = r|U)P (R = r|I) (2)
There are, however, three important differences between the realisation of our model and the one
presented in Kennington et al., (2013), all of which are a direct result of replacing, as we do here, the n-
gram model represented by P (U |R) with output from a parser that produces a Robust Minimal Recursion
Semantics (RMRS) semantic representation (Copestake, 2007). Such a representation provides our model
with a structured way to abstract over the surface forms. We will first give a brief explanation of the
RMRS framework, then describe each of the three differences between our model and that of Kennington
et al., (2013), namely (1) how the language grounds with the world, (2) how the frame is built, and (3)
when to consider evidence for the slots in the frame.
RMRS RMRS is a framework for representing semantics that factors a logical form into elementary
predicates (EP). For example in Table 1, the first row represents the first word of an utterance, take, and
the corresponding RMRS representation; the EPs take and addressee are produced. The EPs in this exam-
ple have anchor variables and in most cases, an EP has an argument entity. Relations between EPs can be
expressed via argument relations, e.g., for take in the table, there is an ARG1 relation, denoting addressee
as the first argument of the predicate take. Other relations include ARG2 and BV (relating determiners to
the words they modify). A full example of an utterance and corresponding RMRS representation can be
found in Table 1, where each row in the word column makes up the words of the example utterance.
In this paper we are interested in processing utterances incrementally. As argued in Peldzsus et al.,
(2012), RMRS is amenable to incremental processing by allowing for underspecification in how relations
are represented (RMRS can also underspecify scope, but we don?t consider that here). Table 1 has an
example of an underspecified relation: when the second word the is uttered, the RMRS segment predicts
that the entity represented by x14 will be the ARG2 relation of the EP for take, but the actual word that
1805
word RMRS segment
take a7 : addressee(x8), a1 : take(e2), ARG1(a1, x8)
the a13 : def(), ARG2(a1, x14), BV (a13, x14)
red a33 : red(e34), ARG1(a33, x14)
cross a19 : cross(x14)
next to a49 : next(e50), ARG1(a49, x14), ARG2(a49, x53)
the a52 : def(), BV (a52, x53)
blue a72 : blue(e73), ARG1(a72, x53)
piece a58 : piece(x53)
Table 1: Example RMRS representation for the utterance take the red cross next to the blue piece. Each
row represents an increment of the utterance.
produces the EP that has x14 as an argument has not yet been uttered. Each row in the table represents
what we would want an RMRS parser to produce for our model at each word increment.
A more detailed explanation of RMRS can be found in Copestake (2007). We will now discuss the
three key differences of our model with that of previous work.
(1) Grounding Semantics with the Visual World In Kennington et al., (2013), the utterance was
represented via n-grams, which was used to ground with the world. Here, we ground RMRS structures
with the world. For example, Figure 1 shows which words produced which RMRS increments; our model
learns the co-occurances between those increments and properties of objects (real properties such as
colors, shapes, and spatial placements, or abstract properties; e.g., take is a property of the action take).
(2) Building the Frame In this paper, intentions are represented as frames. However, unlike Kenning-
ton et al., (2013), we don?t assume beforehand that we know the slots of the frame. To determine the
slots, we turn again to RMRS and build a slot for each entity that is produced (more on this below). This
kind of frame, coupled with the RMRS representation, shows not just a meaning representation, but also
interpretation of the representation in the current model (the real situation / visual domain of discourse),
outputted incrementally making our model fully incremental in the sense of Heintze et al., (2010). The
final, bolded NLU frame in Figure 1 shows the addressee (in this case, the dialogue system) as the recip-
ient of the request, the request itself is a take request, where the object to be taken is obj5, as indexed
by the real world, and that object happens to be red (i.e., e12 represents the notion of redness).
(3) Driven by Sematics Another important difference is when to consider the semantic evidence and
when to ignore it, in terms of when to apply the model for interpretation of the slots. In Kennington et
al., (2013), each slot in the frame was processed at each increment in the entire utterance, regardless of
whether n-grams in that segment contributed to the interpretation of that slot. In our approach, again,
we turn to RMRS. At each word increment, RMRS produces a corresponding, underspecified semantic
meaning represenation which is added to at the next increment. Our model takes the new information
and only attempts to process the interpretation for those ?active? entities. For example, by the time red is
uttered in Figure 1, the processing for entities x8, e2, and e12 is complete, but the processing for x14
is under way, and active as long as x14 is referenced as an entity in the RMRS increment.
With these important extensions, our model of NLU is highly driven by the semantic meaning repre-
sentation that is being built incrementally for the utterance. We will now show through two experiments
how our approach improves upon previous work.
4 Experiments
Similar to Kennington et al., (2013), we use the model represented formally in Equation 2, where
P (R|U) is realised using a maximum entropy classifier (ME) that predicts properties from RMRS evi-
dence.
1
We use the German RMRS parser described in Peldszus et al (2012), Peldszus and Schlangen
(2012) which is a top-down PCFG parser that builds RMRS structure incrementally with the parse.
We train an individual model for each RMRS entity type (e.g., e and x), where the features are the
entity type, relations, and predicates of an RMRS increment and the class label are the visual properties.
1
http://opennlp.apache.org/
1806
The RMRS representations are not checked for accuracy (i.e., they do not represent ground truth); we use
the top-predicted output of the RMRS parser explained in Peldszus et al (2012).
4.1 Pento Puzzle with Speech
Figure 2: Example Pen-
tomino Board
?
?
?
ACTION rotate
OBJECT obj4
RESULT clockwise
?
?
?
Figure 3: Pento gold frame ex-
ample
?
?
?
?
X8 addr
E2 rotate
X14 obj4
E21 clockwise
?
?
?
?
Figure 4: Pento frame example
from our model
Data and Task The Pentomino domain (Fern?andez et al., 2007) contains task-oriented conversational
data which has been used in several situated dialogue studies (Heintze et al., 2010; Peldszus et al., 2012;
Kennington and Schlangen, 2012; Kennington et al., 2013). This corpus was collected in a Wizard-of-Oz
study, where the user goal was to instruct the computer to pick up, delete, rotate or mirror puzzle tiles on
a rectangular board (as in Figure 2), and place them onto another board. For each utterance, the corpus
records the state of the game board before the utterance, the immediately preceding system action, and
the intended interpretation of the utterance (as understood by the Wizard) in the form of a semantic frame
specifying action-type and arguments, where those arguments are objects occurring in the description of
the state of the board. The language of the corpus is German. See Figure 2 for a sample source board,
and Figure 3 for an annotated frame.
The task that we want our model to perform is as follows: given information about the state of the
world (i.e., game board), previous system action, and the ongoing utterance, incrementally build the
frame by providing the interpretation of each RMRS entity, represented as a distribution over all possible
interpretations for that entity (i.e., domain of discourse).
Procedure To make our work comparable to previous work, results were obtained by averaging the
results of a 10-fold validation on 1489 Pento boards (i.e., utterances+context, as in (Kennington and
Schlangen, 2012)). We used a separate set of 168 boards for small-scale, held-out experiments. For
incremental processing, we used INPROTK.
2
We calculate accuracies by comparing against a gold frame,
with assumptions. We check to see if the slot values (3 slots in total) exist in the frame our model
produces. If a gold slot value exists in any slot produced by our model, it is counted as correct (it is
difficult to tell which slot from our model?s frame maps to which slot in the gold frame, we leave this for
future work). A fully correct frame would contain all three values. For example, each of the values for the
gold slots in Figure 3 exist in the example frame our model would produce in Figure 4, marking each gold
slot as correct, and the entire frame as correct since all three were correct together. To directly compare
with previous work, we will use the gold slot names action, object, and result in the Results
section. We perform training and evaluation on hand-transcribed data and on automatically transcribed
data, using the incremental speech recogniser (Sphinx4) in InproTK. We report results on sentence-level
and incremental evaluations.
On the incremental level, we followed previously used metrics for evaluation:
first correct: how deep into the utterance do we make the first correct guess?
first final: how deep into the utterance do we make the correct guess, without subsequent changes?
edit overhead: what is the ratio of unnecessary edits / sentence length, where the only necessary edit is
the first prediction for an entity?
Results Figure 5 shows the results of our evaluation in graph and table form. As expected, our model
dramatically improved the result value, which generally is verbally represented towards the end of
2
https://bitbucket.org/inpro/inprotk
1807
ME+RMRS ME+NGRAMS MLN P
frame 78.75 74.08 74.76
(63.0) (67.2) (61.2)
action 92.11 93.62 92.62
object 90.44 90.79 84.71 64.3
result 94.0 82.34 86.65
Figure 5: Comparison of accuracies in Pento using the model presented here ME+RMRS, (Kennington
et al., 2013) ME+NGRAMS, (Kennington and Schlangen, 2012) MLN, (Peldszus et al., 2012) P; paren-
theses denote results from automatically transcribed speech. Bolded values represent the highest values
for that row. Note that the column chart begins at 60%. The chart and table show the same information.
an utterance. This resulted in a dramatic increase in frame accuracy (a somewhat strict metric). Our
model fares better than previous work using speech (in parentheses in the figure), but is outperformed by
the n-gram approach. These results are encouraging, however we leave improvements on automatically
transcribed speech to future work.
Incremental Table 2 shows the incremental results of Kennington et al.,(2013), and Table 3 shows
our results. Utterances are binned into short, normal, and long utterance lengths (1-6, 7-8, 9-17 words,
respectively; 7-8 word utterances were the most represented). Previous work processed all three slots
throughout the ongoing utterance, whereas the model presented here only processed entities (that could
give rise to these slots) as dictated by the RMRS. This causes a later overall first correct, but an overall
earlier first final, with a much narrower window between them. This represents an ideal system that waits
for processing a slot until it needs to, but comes to a final decision quickly, without changing its mind
later. This is further evidenced by the edit overhead which is lower here than previous work. This has
implications in real-time systems that need to define operating points; i.e., a dialogue system would need
to wait for specific information before making a decision.
action 1-6 7-8 9-14
first correct (% into utt.) 5.78 2.56 3.64
first final (% into utt.) 38.26 36.10 30.84
edit overhead 2.37
object 1-6 7-8 9-14
first correct (% into utt.) 7.39 7.5 10.11
first final (% into utt.) 44.7 44.18 35.55
edit overhead 4.6
result 1-6 7-8 9-14
first correct (% into utt.) 15.16 23.23 20.88
first final (% into utt.) 42.55 40.57 35.21
edit overhead 10.19
Table 2: Incremental Results for Pento slots with
varying sentence lengths, Kennington et al.,(2013),
Edit overhead represents all lengths of utterances.
action 1-6 7-8 9-14
first correct (% into utt.) 12.03 7.8 12.59
first final (% into utt.) 37.84 26.02 24.11
edit overhead 1.57
object 1-6 7-8 9-14
first correct (% into utt.) 30.64 17.66 14.46
first final (% into utt.) 32.27 19.20 15.79
edit overhead 3.1
result 1-6 7-8 9-14
first correct (% into utt.) 59.72 54.50 48.94
first final (% into utt.) 62.80 64.13 60.72
edit overhead 7.71
Table 3: Incremental Results for Pento slots with
varying sentence lengths, current work. Edit over-
head represents all lengths of utterances.
4.2 Pento Puzzle with Speech, Gaze, and Deixis
Data and Task The second experiment uses data also from the Pentomino domain, as described in
(Kousidis et al., 2013; Kennington et al., 2013), also a Wizard-of-Oz study consisting of 7 participants,
example in Figure 1. The user was to select a puzzle tile (out of a possible 15) on a game board shown
on a large monitor, and then describe this piece to the ?system? (wizard). Speech, eye gaze (tracked by
Seeingmachines FaceLab) and pointing gestures (tracked by Microsoft Kinect) were recorded. After the
participant uttered a confirmation, the wizard began a new episode, generating a new random board and
1808
the process repeated.
The task for the NLU in this experiment was reference resolution. The information available to our
model for these data included the utterance (hand-transcribed) the visual context (game board), gaze
information, and deixis (pointing) information, where a rule-based classifier predicted from the motion
capture data the quadrant of the screen at which the participant was pointing. These data were very noisy
(and hence, realistic) despite the constrained conditions of the task; the participants were not required to
say things a certain way (as long as it was understood by the wizard), their hand movements potentially
covered their faces which interfered with the eye tracker, and each participant had a different way of
pointing (e.g., different gesture space, handedness, distance of hand from body when pointing, alignment
of hand with face, etc.).
Procedure Removing the utterances which were flagged by the wizard (i.e., when the wizard mis-
understood the participant) and the utterances of one of the participants (who had misunderstood the
task) left a total of 1051 utterances. We used 951 for development and training the model, and 100 for
evaluation. We give results as resolution accuracy. All models were trained on hand-transcribed data,
but two evaluations were performed: one with hand-transcribed data, and one with speech automatically
transcribed by the Google Web Speech API.
3
Gaze and deixis are incorporated by incrementally com-
puting properties to be provided to our NLU model; i.e., a tile has a property in R of being gazed at
if it is gazed at for some interval of time, or tiles in a quadrant of the screen have the property of being
pointed at. Figure 6 shows an example utterance, gaze, and gesture activity over time and how they
are reflected in the model. Our baseline model is the NLU without using gaze or deixis information;
random accuracy is 7%. We will compare our model with that of an NGRAM (up to trigram) model in the
evaluations, for each of the conditions (baseline, deixis, gaze, deixis and gaze).
We also include the percentage of the time the gold tile is in the top 2 and top 4 rankings (out of 15);
situations in which a dialogue system could at least provide alternatives in a clarification request (if it
could detect that it should have low confidence in the best prediction; which we didn?t investigate here).
For gaze, we also make the naive assumption that over the utterance the participant (who in this case is
the speaker) will gaze at his chosen intended tile most of the time.
Figure 6: Human activity (top) aligned with how modalities are reflected in the model for Gaze and Point
(bottom) over time for example utterance: take the yellow t from this group here. The intervals of the
properties are denoted by square brackets.
Results Table 4 shows the results of our evaluation. Overall, the model that uses RMRS outperforms
the model that uses NGRAMS under all conditions using hand-transcribed data. The results for speech tell
a different story; speech with NGRAMS is generally better ? an effect of the model here relying on parser
output. Overall, both model types increase performance when using hand-transcribed or automatically-
transcribed speech when incorporating other modalities, particularly pointing. Furthermore, the Top 2
and Top 4 columns show that this model has an overall good distribution, especially in the case of RMRS
and pointing, where the target object is in the top four ranks 90% of the time. This would allow a real-
time system to ask a specific clarification request to the human, with a high confidence that the object is
among the top four ranking objects.
Incremental For further incremental results, Figure 7 shows the rank of each object on an example
board using our baseline model for the utterance nimm das rote untere kreuz (take the red below cross /
3
The Web Speech API Specificiation: https://dvcs.w3.org/hg/speech-api/raw-file/tip/
speechapi.html
1809
NLU Acc Top 2 Top 4
NGRAMS 68% 83% 87%
(speech) NGRAMS 44% 57% 69%
RMRS 73% 82% 88%
(speech) RMRS 36% 54% 66%
NLU + Pointing Acc Top 2 Top 4
NGRAMS 70% 83% 88%
(speech) NGRAMS 46% 60% 72%
RMRS 78% 85% 90%
(speech) RMRS 40% 56% 73%
NLU + Gaze Acc Top 2 Top 4
NGRAMS 68% 84% 88%
(speech) NGRAMS 43% 59% 71%
RMRS 74% 81% 88%
(speech) RMRS 39% 54% 67%
NLU + Gaze + Point Acc Top Top
NGRAMS 70% 84% 87%
(speech) NGRAMS 45% 61% 65%
RMRS 77% 85% 89%
(speech) RMRS 41% 56% 74%
Table 4: Results for Experiment 2. The highest scores for each column are in bold. Four evaluations are
compared under four different settings; Acc denotes accuracy (referent in top position), Top 2 and Top
4 respectively show the percentage of time the referent was between those ranks and the top.
take the red cross below). Once das (the) is uttered, RMRS makes an X entity and the model begins to
interpret. The initial distribution appears to be quite random as das does not have high co-occurence with
any particular object property. Once rote (red) is uttered, all non-red objects fall to the lowest ranks in
the distribution. Once untere (under / below) is uttered, all of the red pieces in the bottom two quadrants
increase overall in rank. Finally, as kreuz (cross) is uttered, the two crosses receive the highest ranks,
the bottom one being the highest rank and intended object. Note the rank of the cross in the top left
quadrant over time; it began with a fairly high rank, which moved lower once untere was uttered, then
moved into second rank once kreuz was uttered. As the utterance progresses the rank of the intended
object decreases, showing that our model predicted the correct piece at the appropriate word.
... das rote untere kreuz
Figure 7: Example of reference resolution for the utterance: nimm das rote untere kreuz / take the red
below cross; objects are annotated with their rank in the distribution as outputed by the NLU model at
each increment. The board size has been adjusted for formatting purposes.
5 Discussion and Conclusions
We have presented a model of NLU that uses a semantic representation to recover the intention of a
speaker utterance. Our model is general in that it doesn?t fit a template or ontology like other NLU ap-
proaches (though we would need to determine how a dialogue manager would make use of such a frame),
and grounds the semantic representation with a symbolic representation of the visual world. It works in-
crementally and can incorporate other modalities incrementally. It improves overall upon previous work
that used a similar model, but relied on n-grams. Our model implicitely handles complex utterances that
use spatial language. However, we leave important aspects, such as negation in an utterance, to future
work (they were not very common in our data).
The experiments in this paper were done off-line, but we have a real-time system currently working.
Our model incorporates in real-time the gesture and gaze information as it is picked up by the sensors,
as well as the speech of the user. We leave a full evaluation using this interactive setup with human
participants for future work.
Acknowledgements Thanks to the anonymous reviewers for their useful comments.
1810
References
Gregory Aist, James Allen, Ellen Campana, Lucian Galescu, Carlos A Gomez Gallo, Scott Stoness, Mary Swift,
and Michael Tanenhaus. 2006. Software architectures for incremental understanding of human speech. In
Proceedings of InterspeechICSLP.
Gregory Aist, James Allen, Ellen Campana, Carlos Gomez Gallo, Scott Stoness, Mary Swift, and Michael K
Tanenhaus. 2007. Incremental understanding in human-computer dialogue and experimental evidence for
advantages over nonincremental methods. In Proceedings of Decalog (Semdial 2007), Trento, Italy.
Timo Baumann and David Schlangen. 2012. The InproTK 2012 Release. In NAACL.
Timo Baumann, Michaela Atterer, and David Schlangen. 2009. Assessing and Improving the Performance of
Speech Recognition for Incremental Systems. In Proceedings of NAACL-HLT 2009, Boulder, USA, June.
Hendrik Buschmeier, Timo Baumann, Benjamin Dosch, Stefan Kopp, and David Schlangen. 2012. Combining
Incremental Language Generation and Incremental Speech Synthesis for Adaptive Information Presentation.
In Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages
295?303, Seoul, South Korea, July. Association for Computational Linguistics.
Okko Bu? Timo Baumann, and David Schlangen. 2010. Collaborating on Utterances with a Spoken Dialogue
System Using an ISU-based Approach to Incremental Dialogue Management. In Proceedings of the SIGdial
2010 Conference, pages 233?236, Tokyo, Japan, September.
Joyce Y Chai, Lanbo She, Rui Fang, Spencer Ottarson, Cody Littley, Changsong Liu, and Kenneth Hanson. 2014.
Collaborative Effort towards Common Ground in Situated Human-Robot Dialogue. In HRI?14, pages 33?40,
Bielefeld, Germany.
Herbert H Clark. 1996. Using Language. Cambridge University Press.
Ann Copestake. 2007. Semantic composition with (robust) minimal recursion semantics. In Proceedings of
the Workshop on Deep Linguistic Processing - DeepLP ?07, page 73, Morristown, NJ, USA. Association for
Computational Linguistics.
Renato De Mori, Frederic B?echet, Dilek Hakkani-t?ur, Michael Mctear, Giuseppe Riccardi, and Gokhan Tur. 2008.
Spoken Language Understanding. IEEE Signal Processing Magazine, (May):50?58, May.
David DeVault, Kenji Sagae, and David Traum. 2009. Can I finish?: learning when to respond to incremental
interpretation results in interactive dialogue. In Proceedings of the 10th SIGdial, number September, pages
11?20. Association for Computational Linguistics.
David DeVault, Kenji Sagae, and David Traum. 2011. Incremental Interpretation and Prediction of Utterance
Meaning for Interactive Dialogue. Dialogue & Discourse, 2(1):143?170.
Raquel Fern?andez, Tatjana Lucht, and David Schlangen. 2007. Referring under restricted interactivity conditions.
In Proceedings of the 8th SIGdial Workshop on Discourse and Dialogue, pages 136?139.
Silvan Heintze, Timo Baumann, and David Schlangen. 2010. Comparing local and sequential models for statistical
incremental natural language understanding. In Proceedings of the 11th Annual Meeting of the Special Interest
Group on Discourse and Dialogue, pages 9?16. Association for Computational Linguistics.
Kai-yuh Hsiao, Soroush Vosoughi, Stefanie Tellex, Rony Kubat, and Deb Roy. 2008. Object schemas for ground-
ing language in a responsive robot. Connection Science2, 20(4):253?276.
Guangpu Huang and Meng Joo Er. 2010. A Hybrid Computational Model for Spoken Language Understanding.
In 11th International Conference on Control, Automation, Robotics, and Vision, number December, pages 7?10,
Singapore. IEEE.
Casey Kennington and David Schlangen. 2012. Markov Logic Networks for Situated Incremental Natural Lan-
guage Understanding. In Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse
and Dialogue, pages 314?322, Seoul, South Korea. Association for Computational Linguistics.
Casey Kennington, Spyros Kousidis, and David Schlangen. 2013. Interpreting Situated Dialogue Utterances: an
Update Model that Uses Speech, Gaze, and Gesture Information. In SIGdial 2013.
Spyros Kousidis, Casey Kennington, and David Schlangen. 2013. Investigating speaker gaze and pointing be-
haviour in human-computer interaction with the mint.tools collection. In SIGdial 2013.
1811
Percy Liang, Michael Jordan, and Dan Klein. 2011. Learning Dependency-Based Compositional Semantics. In
Proceedings of the 49th ACLHLT, pages 590?599, Portland, Oregon. Association for Computational Linguistics.
Changsong Liu, Rui Fang, and Joyce Chai. 2012. Towards Mediating Shared Perceptual Basis in Situated Dia-
logue. In Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue,
pages 140?149, Seoul, South Korea, July. Association for Computational Linguistics.
Marie-Jean Meurs, Frederic Duvert, Fabrice Lefevre, and Renato De Mori. 2008. Markov Logic Networks for
Spoken Language Interpretation. Information Systems Journal, (1978):535?544.
Marie-Jean Meurs, Fabrice Lef`evre, and Renato De Mori. 2009. Spoken Language Interpretation: On the Use
of Dynamic Bayesian Networks for Semantic Composition. In IEEE International Conference on Acoustics,
Speech, and Signal Processing, pages 4773?4776.
Ivan Meza-Ruiz, Sebastian Riedel, and Oliver Lemon. 2008. Accurate Statistical Spoken Language Understanding
from Limited Development Resources. In IEEE International Conference on Acoustics, Speech, and Signal
Processing, pages 5021?5024. IEEE.
Andreas Peldszus and David Schlangen. 2012. Incremental Construction of Robust but Deep Semantic Represen-
tations for Use in Responsive Dialogue Systems. In Proceedings of the Workshop on Advances in Discourse
Analysis and its Computational Aspects, pages 59?76, Mumbai, India, December. The COLING 2012 Organiz-
ing Committee.
Andreas Peldszus, Okko Bu?, Timo Baumann, and David Schlangen. 2012. Joint Satisfaction of Syntactic and
Pragmatic Constraints Improves Incremental Spoken Language Understanding. In Proceedings of the 13th
EACL, pages 514?523, Avignon, France, April. Association for Computational Linguistics.
Zahar Prasov and Joyce Y Chai. 2010. Fusing Eye Gaze with Speech Recognition Hypotheses to Resolve Ex-
ophoric References in Situated Dialogue. In EMNLP 2010, number October, pages 471?481.
Deb Roy. 2005. Grounding words in perception and action: computational insights. Trends in Cognitive Sciences,
9(8):389?396, August.
David Schlangen and Gabriel Skantze. 2009. A General, Abstract Model of Incremental Dialogue Processing. In
Proceedings of the 10th EACL, number April, pages 710?718, Athens, Greece. Association for Computational
Linguistics.
David Schlangen and Gabriel Skantze. 2011. A General, Abstract Model of Incremental Dialogue Processing.
Dialoge & Discourse, 2(1):83?111.
Ethan O Selfridge, Iker Arizmendi, Peter A Heeman, and Jason D Williams. 2012. Integrating Incremental
Speech Recognition and POMDP-Based Dialogue Systems. In Proceedings of the 13th Annual Meeting of the
Special Interest Group on Discourse and Dialogue, pages 275?279, Seoul, South Korea, July. Association for
Computational Linguistics.
Gabriel Skantze and Anna Hjalmarsson. 2010. Towards Incremental Speech Generation in Dialogue Systems. In
Proceedings of SigDial 2010, pages 1?8, Tokyo, Japan, September.
Gabriel Skantze and David Schlangen. 2009. Incremental dialogue processing in a micro-domain. Proceedings
of the 12th Conference of the European Chapter of the Association for Computational Linguistics on EACL 09,
(April):745?753.
Gokhan Tur and Renato De Mori. 2011. Spoken Language Understanding: Systems for Extracting Semantic
Information from Speech. Wiley.
Luke S Zettlemoyer and Michael Collins. 2007. Online Learning of Relaxed CCG Grammars for Parsing to
Logical Form. Computational Linguistics, (June):678?687.
Luke S Zettlemoyer and Michael Collins. 2009. Learning context-dependent mappings from sentences to logical
form. Proceedings of the Joint Conference of the 47th ACL and the 4th AFNLP: Volume 2 - ACL-IJCNLP ?09,
2:976.
1812
Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 514?523,
Avignon, France, April 23 - 27 2012. c?2012 Association for Computational Linguistics
Joint Satisfaction of Syntactic and Pragmatic Constraints
Improves Incremental Spoken Language Understanding
Andreas Peldszus
University of Potsdam
Department for Linguistics
peldszus@uni-potsdam.de
Okko Bu?
University of Potsdam
Department for Linguistics
okko@ling.uni-potsdam.de
Timo Baumann
University of Hamburg
Department for Informatics
baumann@informatik.uni-hamburg.de
David Schlangen
University of Bielefeld
Department for Linguistics
david.schlangen@uni-bielefeld.de
Abstract
We present a model of semantic processing
of spoken language that (a) is robust against
ill-formed input, such as can be expected
from automatic speech recognisers, (b) re-
spects both syntactic and pragmatic con-
straints in the computation of most likely
interpretations, (c) uses a principled, ex-
pressive semantic representation formalism
(RMRS) with a well-defined model the-
ory, and (d) works continuously (produc-
ing meaning representations on a word-
by-word basis, rather than only for full
utterances) and incrementally (computing
only the additional contribution by the new
word, rather than re-computing for the
whole utterance-so-far).
We show that the joint satisfaction of syn-
tactic and pragmatic constraints improves
the performance of the NLU component
(around 10% absolute, over a syntax-only
baseline).
1 Introduction
Incremental processing for spoken dialogue sys-
tems (i. e., the processing of user input even while
it still may be extended) has received renewed at-
tention recently (Aist et al 2007; Baumann et
al., 2009; Bu? and Schlangen, 2010; Skantze and
Hjalmarsson, 2010; DeVault et al 2011; Purver
et al 2011). Most of the practical work, how-
ever, has so far focussed on realising the poten-
tial for generating more responsive system be-
haviour through making available processing re-
sults earlier (e. g. (Skantze and Schlangen, 2009)),
but has otherwise followed a typical pipeline ar-
chitecture where processing results are passed
only in one direction towards the next module.
In this paper, we investigate whether the other
potential advantage of incremental processing?
providing ?higher-level?-feedback to lower-level
modules, in order to improve subsequent process-
ing of the lower-level module?can be realised as
well. Specifically, we experimented with giving a
syntactic parser feedback about whether semantic
readings of nominal phrases it is in the process of
constructing have a denotation in the given con-
text or not. Based on the assumption that speak-
ers do plan their referring expressions so that they
can successfully refer, we use this information to
re-rank derivations; this in turn has an influence
on how the derivations are expanded, given con-
tinued input. As we show in our experiments, for
a corpus of realistic dialogue utterances collected
in a Wizard-of-Oz setting, this strategy led to an
absolute improvement in computing the intended
denotation of around 10% over a baseline (even
more using a more permissive metric), both for
manually transcribed test data as well as for the
output of automatic speech recognition.
The remainder of this paper is structured as fol-
lows: We discuss related work in the next section,
and then describe in general terms our model and
its components. In Section 4 we then describe the
data resources we used for the experiments and
the actual implementation of the model, the base-
lines for comparison, and the results of our exper-
iments. We close with a discussion and an outlook
on future work.
2 Related Work
The idea of using real-world reference to inform
syntactic structure building has been previously
explored by a number of authors. Stoness et al
(2004, 2005) describe a proof-of-concept imple-
514
mentation of a ?continuous understanding? mod-
ule that uses reference information in guiding a
bottom-up chart-parser, which is evaluated on a
single dialogue transcript. In contrast, our model
uses a probabilistic top-down parser with beam
search (following Roark (2001)) and is evalu-
ated on a large number of real-world utterances
as processed by an automatic speech recogniser.
Similarly, DeVault and Stone (2003) describe a
system that implements interaction between a
parser and higher-level modules (in this case, even
more principled, trying to prove presuppositions),
which however is also only tested on a small, con-
structed data-set.
Schuler (2003) and Schuler et al(2009) present
a model where information about reference is
used directly within the speech recogniser, and
hence informs not only syntactic processing but
also word recognition. To this end, the processing
is folded into the decoding step of the ASR, and
is realised as a hierarchical HMM. While techni-
cally interesting, this approach is by design non-
modular and restricted in its syntactic expressiv-
ity.
The work presented here also has connections
to work in psycholinguistics. Pado? et al(2009)
present a model that combines syntactic and se-
mantic models into one plausibility judgement
that is computed incrementally. However, that
work is evaluated for its ability to predict reading
time data and not for its accuracy in computing
meaning.
3 The Model
3.1 Overview
Described abstractly, the model computes the
probability of a syntactic derivation (and its ac-
companying logical form) as a combination of a
syntactic probability (as in a typical PCFG) and
a semantic or pragmatic plausibility.1 The prag-
matic plausibility here comes from the presuppo-
sition that the speaker intended her utterance to
successfully refer, i. e. to have a denotation in the
current situation (a unique one, in the case of def-
inite reference). Hence, readings that do have a
denotation are preferred over those that do not.
1Note that, as described below, in the actual implemen-
tation the weights given to particular derivations are not real
probabilities anymore, as derivations fall out of the beam and
normalisation is not performed after re-weighting.
The components of our model are described in
the following sections: first the parser which com-
putes the syntactic probability in an incremental,
top-down manner; the semantic construction al-
gorithm which associates (underspecified) logi-
cal forms to derivations; the reference resolution
component that computes the pragmatic plausi-
bility; and the combination that incorporates the
feedback from this pragmatic signal.
3.2 Parser
Roark (2001) introduces a strategy for incremen-
tal probabilistic top-down parsing and shows that
it can compete with high-coverage bottom-up
parsers. One of the reasons he gives for choosing
a top-down approach is that it enables fully left-
connected derivations, where at every process-
ing step new increments directly find their place
in the existing structure. This monotonically en-
riched structure can then serve as a context for in-
cremental language understanding, as the author
claims, although this part is not further developed
by Roark (2001). He discusses a battery of dif-
ferent techniques for refining his results, mostly
based on grammar transformations and on con-
ditioning functions that manipulate a derivation
probability on the basis of local linguistic and lex-
ical information.
We implemented a basic version of his parser
without considering additional conditioning or
lexicalizations. However, we applied left-facto-
rization to parts of the grammar to delay cer-
tain structural decisions as long as possible. The
search-space is reduced by using beam search. To
match the next token, the parser tries to expand
the existing derivations. These derivations are
stored in a priorized queue, which means that the
most probable derivation will always be served
first. Derivations resulting from rule expansions
are kept in the current queue, derivations result-
ing from a successful lexical match are pushed in
a new queue. The parser proceeds with the next
most probable derivation until the current queue
is empty or until a threshhold is reached at which
remaining analyses are pruned. This threshhold
is determined dynamically: If the probability of
the current derivation is lower than the product of
the best derivation?s probability on the new queue,
the number of derivations in the new queue, and a
base beam factor (an initial parameter for the size
of the search beam), then all further old deriva-
515
FormulaIU
CandidateAnalysisIU
TagIU
TextualWordIU
FormulaIU[ [l0:a1:i2]{ [l0:a1:i2] } ] FormulaIU[ [l0:a1:e2]{ [l0:a1:e2] }ARG1(a1,x8),l6:a7:addressee(x8),l0:a1:_nehmen(e2)]
CandidateAnalysisIULD=[s*/s, s/vp, vp/vvimp-v1, m(vvimp)]P=0.49S=[V1, S!]
CandidateAnalysisIULD=[]P=1.00S=[S*,S!]
TagIUvvimp
FormulaIU...
CandidateAnalysisIULD=[s*/s,kon,s*, s/vp, vp/vvimp-v1, m(vvimp)]P=0.14S=[V1, kon, S*, S!]
FormulaIU[ [l0:a1:e2]{ [l18:a19:x14] [l0:a1:e2] }ARG1(a1,x8),l6:a7:addressee(x8),l0:a1:_nehmen(e2),ARG2(a1,x14),BV(a13,x14),RSTR(a13,h21),BODY(a13,h22),l12:a13:_def(),qeq(h21,l18)]
CandidateAnalysisIULD=[v1/np-vz, np/det-n1, m(det)]P=0.2205S=[N1, VZ, S!]
TagIUdet
FormulaIU...
CandidateAnalysisIULD=[v1/np-vz, np/pper, i(det)]P=0.00441S=[pper, VZ, S!]
FormulaIU[ [l0:a1:e2]{ [l29:a30:x14] [l0:a1:e2] }ARG1(a1,x8),l6:a7:addressee(x8),l0:a1:_nehmen(e2),ARG2(a1,x14),BV(a13,x14),RSTR(a13,h21),BODY(a13,h22),l12:a13:_def(),l18:a19:_winkel(x14),qeq(h21,l18)]
CandidateAnalysisIULD=[n1/nn-nz, m(nn)]P=0.06615S=[NZ, VZ, S!]
TagIUnn
FormulaIU...
CandidateAnalysisIULD=[n1/adjp-n1, adjp/adja, i(nn)]P=0.002646S=[adja, N1, VZ, S!]
FormulaIU...
CandidateAnalysisIULD=[n1/nadj-nz, nadj/adja, i(nn)]P=0.000441S=[adja, NZ, VZ, S!]
FormulaIU[ [l0:a1:e2]{ [l42:a43:x44] [l29:a30:x14] [l0:a1:e2] }ARG1(a1,x8),l6:a7:addressee(x8),l0:a1:_nehmen(e2),ARG2(a1,x14),BV(a13,x14),RSTR(a13,h21),BODY(a13,h22),l12:a13:_def(),l18:a19:_winkel(x14),ARG1(a40,x14),ARG2(a40,x44),l39:a40:_in(e41),qeq(h21,l18)]
CandidateAnalysisIULD=[nz/pp-nz, pp/appr-np, m(appr)]P=0.0178605S=[NP, NZ, VZ, S!]
TagIUappr
FormulaIU...
CandidateAnalysisIULD=[nz/advp-nz, advp/adv, i(appr)]P=0.0003969S=[adv, NZ, VZ, S!]
FormulaIU...
CandidateAnalysisIULD=[nz/eps, vz/advp-vz, advp/adv, i(appr)]P=0.00007938S=[adv, VZ, S!]
TagIU$TopOfTags
TextualWordIUnimm TextualWordIUden TextualWordIUwinkel TextualWordIUinTextualWordIU$TopOfWords
Figure 1: An example network of incremental units, including the levels of words, POS-tags, syntactic derivations
and logical forms. See section 3 for a more detailed description.
tions are pruned. Due to probabilistic weighing
and the left factorization of the rules, left recur-
sion poses no direct threat in such an approach.
Additionally, we implemented three robust lex-
ical operations: insertions consume the current
token without matching it to the top stack item;
deletions can ?consume? a requested but actu-
ally non-existent token; repairs adjust unknown
tokens to the requested token. These robust op-
erations have strong penalties on the probability
to make sure they will survive in the derivation
only in critical situations. Additionally, only a
single one of them is allowed to occur between
the recognition of two adjacent input tokens.
Figure 1 illustrates this process for the first few
words of the example sentence ?nimm den winkel
in der dritten reihe? (take the bracket in the third
row), using the incremental unit (IU) model to
represent increments and how they are linked; see
(Schlangen and Skantze, 2009).2 Here, syntactic
2Very briefly: rounded boxes in the Figures represent
IUs, and dashed arrows link an IU to its predecessor on the
same level, where the levels correspond to processing stages.
The Figure shows the levels of input words, POS-tags, syn-
tactic derivations and logical forms. Multiple IUs sharing
derivations (?CandidateAnalysisIUs?) are repre-
sented by three features: a list of the last parser ac-
tions of the derivation (LD), with rule expansions
or (robust) lexical matches; the derivation proba-
bility (P); and the remaining stack (S), where S*
is the grammar?s start symbol and S! an explicit
end-of-input marker. (To keep the Figure small,
we artificially reduced the beam size and cut off
alternatives paths, shown in grey.)
3.3 Semantic Construction Using RMRS
As a novel feature, we use for the representation
of meaning increments (that is, the contributions
of new words and syntactic constructions) as well
as for the resulting logical forms the formalism
Robust Minimal Recursion Semantics (Copestake,
2006). This is a representation formalism that was
originally constructed for semantic underspecifi-
cation (of scope and other phenomena) and then
adapted to serve the purposes of semantics repre-
the same predecessor can be regarded as alternatives. Solid
arrows indicate which information from a previous level an
IU is grounded in (based on); here, every semantic IU is
grounded in a syntactic IU, every syntactic IU in a POS-tag-
IU, and so on.
516
sentations in heterogeneous situations where in-
formation from deep and shallow parsers must be
combined. In RMRS, meaning representations of
a first order logic are underspecified in two ways:
First, the scope relationships can be underspeci-
fied by splitting the formula into a list of elemen-
tary predications (EP) which receive a label ` and
are explicitly related by stating scope constraints
to hold between them (e.g. qeq-constraints). This
way, all scope readings can be compactly repre-
sented. Second, RMRS allows underspecification
of the predicate-argument-structure of EPs. Ar-
guments are bound to a predicate by anchor vari-
ables a, expressed in the form of an argument re-
lation ARGREL(a,x). This way, predicates can
be introduced without fixed arity and arguments
can be introduced without knowing which predi-
cates they are arguments of. We will make use of
this second form of underspecification and enrich
lexical predicates with arguments incrementally.
Combining two RMRS structures involves at
least joining their list of EPs and ARGRELs and
of scope constraints. Additionally, equations be-
tween the variables can connect two structures,
which is an essential requirement for semantic
construction. A semantic algebra for the combi-
nation of RMRSs in a non-lexicalist setting is de-
fined in (Copestake, 2007). Unsaturated semantic
increments have open slots that need to be filled
by what is called the hook of another structure.
Hook and slot are triples [`:a:x] consisting of a
label, an anchor and an index variable. Every vari-
able of the hook is equated with the corresponding
one in the slot. This way the semantic representa-
tion can grow monotonically at each combinatory
step by simply adding predicates, constraints and
equations.
Our approach differs from (Copestake, 2007)
only in the organisation of the slots: In an incre-
mental setting, a proper semantic representation
is desired for every single state of growth of the
syntactic tree. Typically, RMRS composition as-
sumes that the order of semantic combination is
parallel to a bottom-up traversal of the syntactic
tree. Yet, this would require for every incremental
step first to calculate an adequate underspecified
semantic representation for the projected nodes
on the lower right border of the tree and then to
proceed with the combination not only of the new
semantic increments but of the complete tree. For
our purposes, it is more elegant to proceed with
semantic combination in synchronisation with the
syntactic expansion of the tree, i.e. in a top-down
left-to-right fashion. This way, no underspecifica-
tion of projected nodes and no re-interpretation of
already existing parts of the tree is required. This,
however, requires adjustments to the slot structure
of RMRS. Left-recursive rules can introduce mul-
tiple slots of the same sort before they are filled,
which is not allowed in the classic (R)MRS se-
mantic algebra, where only one named slot of
each sort can be open at a time. We thus organize
the slots as a stack of unnamed slots, where mul-
tiple slots of the same sort can be stored, but only
the one on top can be accessed. We then define
a basic combination operation equivalent to for-
ward function composition (as in standard lambda
calculus, or in CCG (Steedman, 2000)) and com-
bine substructures in a principled way across mul-
tiple syntactic rules without the need to represent
slot names.
Each lexical items receives a generic represen-
tation derived from its lemma and the basic se-
mantic type (individual, event, or underspecified
denotations), determined by its POS tag. This
makes the grammar independent of knowledge
about what later (semantic) components will ac-
tually be able to process (?understand?).3 Parallel
to the production of syntactic derivations, as the
tree is expanded top-down left-to-right, seman-
tic macros are activated for each syntactic rule,
composing the contribution of the new increment.
This allows for a monotonic semantics construc-
tion process that proceeds in lockstep with the
syntactic analysis.
Figure 1 (in the ?FormulaIU? box) illustrates
the results of this process for our example deriva-
tion. Again, alternatives paths have been cut to
keep the size of the illustration small. Notice that,
apart from the end-of-input marker, the stack of
semantic slots (in curly brackets) is always syn-
chronized with the parser?s stack.
3.4 Computing Noun Phrase Denotations
Formally, the task of this module is, given a model
M of the current context, to compute the set of
all variable assignments such that M satisfies ?:
G = {g | M |=g ?}. If |G| > 1, we say that ?
refers ambiguously; if |G| = 1, it refers uniquely;
3This feature is not used in the work presented here, but
it could be used for enabling the system to learn the meaning
of unknown words.
517
and if |G| = 0, it fails to refer. This process does
not work directly on RMRS formulae, but on ex-
tracted and unscoped first-order representations of
their nominal content.
3.5 Parse Pruning Using Reference
Information
After all possible syntactic hypotheses at an in-
crement have been derived by the parser and
the corresponding semantic representations have
been constructed, reference resolution informa-
tion can be used to re-rank the derivations. If
pragmatic feedback is enabled, the probability of
every reprentation that does not resolve in the cur-
rent context is degraded by a constant factor (we
used 0.001 in our experiments described below,
determined by experimentation). The degradation
thus changes the derivation order in the parsing
queue for the next input item and increases the
chances of degraded derivations to be pruned in
the following parsing step.
4 Experiments and Results
4.1 Data
We use data from the Pentomino puzzle piece do-
main (which has been used before for example
by (Ferna?ndez and Schlangen, 2007; Schlangen et
al., 2009)), collected in a Wizard-of-Oz study. In
this specific setting, users gave instructions to the
system (the wizard) in order to manipulate (select,
rotate, mirror, delete) puzzle pieces on an upper
board and to put them onto a lower board, reach-
ing a pre-specified goal state. Figure 2 shows an
example configuration. Each participant took part
in several rounds in which the distinguishing char-
acteristics for puzzle pieces (color, shape, pro-
posed name, position on the board) varied widely.
In total, 20 participants played 284 games.
We extracted the semantics of an utterance
from the wizard?s response action. In some cases,
such a mapping was not possible to do (e. g. be-
cause the wizard did not perform a next action,
mimicking a non-understanding by the system),
or potentially unreliable (if the wizard performed
several actions at or around the end of the utter-
ance). We discarded utterances without a clear se-
mantics alignment, leaving 1687 semantically an-
notated user utterances. The wizard of course was
able to use her model of the previous discourse for
resolving references, including anaphoric ones; as
Figure 2: The game board used in the study, as pre-
sented to the player: (a) the current state of the game
on the left, (b) the goal state to be reached on the right.
our study does not focus on these, we have dis-
regarded another 661 utterances in which pieces
are referred to by pronouns, leaving us with 1026
utterances for evaluation. These utterances con-
tained on average 5.2 words (median 5 words;
std dev 2 words).
In order to test the robustness of our method,
we generated speech recognition output using an
acoustic model trained for spontaneous (German)
speech. We used leave-one-out language model
training, i. e. we trained a language model for ev-
ery utterance to be recognized which was based
on all the other utterances in the corpus. Unfor-
tunately, the audio recordings of the first record-
ing day were too quiet for successful recognition
(with a deletion rate of 14%). We thus decided
to limit the analysis for speech recognition out-
put to the remaining 633 utterances from the other
recording days. On this part of the corpus word
error rate (WER) was at 18%.
The subset of the full corpus that we used for
evaluation, with the utterances selected according
to the criteria described above, nevertheless still
only consists of natural, spontaneous utterances
(with all the syntactic complexity that brings) that
are representative for interactions in this type of
domain.
4.2 Grammar and Resolution Model
The grammar used in our experiments was hand-
constructed, inspired by a cursory inspection of
the corpus and aiming to reach good coverage
518
Words Predicates Status
nimm nimm(e) -1
nimm den nimm(e,x) def(x) 0
nimm den Winkel nimm(e,x) def(x) winkel(x) 0
nimm den Winkel in nimm(e,x) def(x) winkel(x) in(x,y) 0
nimm den Winkel in der nimm(e,x) def(x) winkel(x) in(x,y) def(y) 0
nimm den Winkel in der dritten nimm(e,x) def(x) winkel(x) in(x,y) def(y) third(y) 1
nimm den Winkel in der dritten Reihe nimm(e,x) def(x) winkel(x) in(x,y) def(y) third(y) row(y) 1
Table 1: Example of logical forms (flattened into first-order base-language formulae) and reference resolution
results for incrementally parsing and resolving ?nimm den winkel in der dritten reihe?
for a core fragment. We created 30 rules, whose
weights were also set by hand (as discussed be-
low, this is an obvious area for future improve-
ment), sparingly and according to standard intu-
itions. When parsing, the first step is the assign-
ment of a POS tag to each word. This is done by
a simple lookup tagger that stores the most fre-
quent tag for each word (as determined on a small
subset of our corpus).4
The situation model used in reference resolu-
tion is automatically derived from the internal
representation of the current game state. (This
was recorded in an XML-format for each utter-
ance in our corpus.) Variable assignments were
then derived from the relevant nominal predicate
structures,5 consisting of extracted simple pred-
ications, e. g. red(x) and cross(x) for the NP in
a phrase such as ?take the red cross?. For each
unique predicate argument X in these EP struc-
tures (such as as x above), the set of domain ob-
jects that satisfied all predicates of which X was
an argument were determined. For example for
the phrase above, X mapped to all elements that
were red and crosses.
Finally, the size of these sets was determined:
no elements, one element, or multiple elements,
as described above. Emptiness of at least one set
denoted that no resolution was possible (for in-
stance, if no red crosses were available, x?s set
was empty), uniqueness of all sets denoted that
an exact resolution was possible while multiple
elements in at least some sets denoted ambiguity.
This status was then leveraged for parse pruning,
as per Section 3.5.
A more complex example using the scene de-
picted in Figure 2 and the sentence ?nimm den
4A more sophisticated approach has recently been pro-
posed by Beuck et al(2011); this could be used in our setup.
5The domain model did not allow making a plausibility
judgement based on verbal resolution.
winkel in der dritten reihe? (take the bracket in the
third row) is shown in Table 1. The first column
shows the incremental word hypothesis string, the
second the set of predicates derived from the most
recent RMRS representation and the third the res-
olution status (-1 for no resolution, 0 for some res-
olution and 1 for a unique resolution).
4.3 Baselines and Evaluation Metric
4.3.1 Variants / Baselines
To be able to accurately quantify and assess the
effect of our reference-feedback strategy, we im-
plemented different variants / baselines. These all
differ in how, at each step, the reading is deter-
mined that is evaluated against the gold standard,
and are described in the following:
In the Just Syntax (JS) variant, we simply take
single-best derivation, as determined by syntax
alone and evaluate this.
The External Filtering (EF) variant adds in-
formation from reference resolution, but keeps
it separate from the parsing process. Here, we
look at the 5 highest ranking derivations (as de-
termined by syntax alone), and go through them
beginning at the highest ranked, picking the first
derivation where reference resolution can be per-
formed uniquely; this reading is then put up for
evaluation. If there is no such reading, the highest
ranking one will be put forward for evaluation (as
in JS).
Syntax/Pragmatics Interaction (SPI) is the
variant described in the previous section. Here,
all active derivations are sent to the reference res-
olution module, and are re-weighted as described
above; after this has been done, the highest-
ranking reading is evaluated.
Finally, the Combined Interaction and Fil-
tering (CIF) variant combines the previous two
strategies, by using reference-feedback in com-
puting the ranking for the derivations, and then
519
again using reference-information to identify the
most promising reading within the set of 5 highest
ranking ones.
4.3.2 Metric
When a reading has been identified according
to one of these methods, a score s is computed as
follows: s = 1, if the correct referent (according
to the gold standard) is computed as the denota-
tion for this reading; s = 0 if no unique referent
can be computed, but the correct one is part of the
set of possible referents; s = ?1 if no referent
can be computed at all, or the correct one is not
part of the set of those that are computed.
As this is done incrementally for each word
(adding the new word to the parser chart), for an
utterance of length m we get a sequence of m
such numbers. (In our experiments we treat the
?end of utterance? signal as a pseudo-word, since
knowing that an utterance has concluded allows
the parser to close off derivations and remove
those that are still requiring elements. Hence, we
in fact have sequences ofm+1 numbers.) A com-
bined score for the whole utterance is computed
according to the following formula:
su =
m?
n=1
(sn ? n/m)
(where sn is the score at position n). The fac-
tor n/m causes ?later? decisions to count more
towards the final score, reflecting the idea that
it is more to be expected (and less harmful) to
be wrong early on in the utterance, whereas the
longer the utterance goes on, the more pressing
it becomes to get a correct result (and the more
damaging if mistakes are made).6
Note that this score is not normalised by utter-
ance length m; the maximally achievable score
being (m + 1)/2. This has the additional ef-
fect of increasing the weight of long utterances
when averaging over the score of all utterances;
we see this as desirable, as the analysis task be-
comes harder the longer the utterance is.
We use success in resolving reference to eval-
uate the performance of our parsing and semantic
construction component, where more tradition-
ally, metrics like parse bracketing accuracy might
6This metric compresses into a single number some of
the concerns of the incremental metrics developed in (Bau-
mann et al 2011), which can express more fine-grainedly
the temporal development of hypotheses.
be used. But as we are building this module for an
interactive system, ultimately, accuracy in recov-
ering meaning is what we are interested in, and so
we see this not just as a proxy, but actually as a
more valuable metric. Moreover, this metric can
be applied at each incremental step, which is not
clear how to do with more traditional metrics.
4.4 Experiments
Our parser, semantic construction and reference
resolution modules are implemented within the
InproTK toolkit for incremental spoken dialogue
systems development (Schlangen et al 2010). In
this toolkit, incremental hypotheses are modified
as more information becomes available over time.
Our modules support all such modifications (i. e.
also allow to revert their states and output if word
input is revoked).
As explained in Section 4.1, we used offline
recognition results in our evaluation. However,
the results would be identical if we were to use
the incremental speech recognition output of In-
proTK directly.
The system performs several times faster than
real-time on a standard workstation computer. We
thus consider it ready to improve practical end-to-
end incremental systems which perform within-
turn actions such as those outlined in (Bu? and
Schlangen, 2010).
The parser was run with a base-beam factor of
0.01; this parameter may need to be adjusted if a
larger grammar was used.
4.5 Results
Table 2 shows an overview of the experiment re-
sults. The table lists, separately for the manual
transcriptions and the ASR transcripts, first the
number of times that the final reading did not re-
solve at all, or to a wrong entitiy; did not uniquely
resolve, but included the correct entity in its de-
notiation; or did uniquely resolve to the correct
entity (-1, 0, and 1, respectively). The next lines
show ?strict accuracy? (proportion of ?1? among
all results) at the end of utterance, and ?relaxed
accuracy? (which allows ambiguity, i.e., is the set
{0, 1}). incr.scr is the incremental score as de-
scribed above, which includes in the evaluation
the development of references and not just the fi-
nal state. (And in that sense, is the most appro-
priate metric here, as it captures the incremental
behaviour.) This score is shown both as absolute
520
JS EF SPI CIF
tr
an
sc
ri
pt
?1 563 518 364 363
0 197 198 267 268
1 264 308 392 392
str.acc. 25.7% 30.0% 38.2% 38.2%
rel.acc. 44.9% 49.3% 64.2% 64.3%
incr.scr ?1568 ?1248 ?536 ?504
avg.incr.scr ?1.52 ?1.22 ?0.52 ?0.49
re
co
gn
ti
on
?1 362 348 254 255
0 122 121 173 173
1 143 158 196 195
str.acc. 22.6% 25.0% 31.0% 30.8%
rel.acc. 41.2% 44.1% 58.3% 58.1%
incr.scr ?1906 ?1730 ?1105 ?1076
avg.incr.scr ?1.86 ?1.69 ?1.01 ?1.05
Table 2: Results of the Experiments. See text for explanation of metrics.
number as well as averaged for each utterance.
As these results show, the strategy of provid-
ing the parser with feedback about the real-world
utility of constructed phrases (in the form of refer-
ence decisions) improves the parser, in the sense
that it helps the parser to successfully retrieve the
intended meaning more often compared to an ap-
proach that only uses syntactic information (JS)
or that uses pragmatic information only outside
of the main programme: 38.2% strict or 64.2%
relaxed for SPI over 25.7% / 44.9% for JS, an
absolute improvement of 12.5% for strict or even
more, 19.3%, for the relaxed metric; the incre-
mental metric shows that this advantage holds not
only at the final word, but also consistently within
the utterance, the average incremental score for
an utterance being ?0.49 for SPI and ?1.52
for JS. The improvement is somewhat smaller
against the variant that uses some reference infor-
mation, but does not integrate this into the parsing
process (EF), but it is still consistently present.
Adding such n-best-list processing to the output
of the parser+reference-combination (as variant
CIF does) finally does not further improve the
performance noticeably. When processing par-
tially defective material (the output of the speech
recogniser), the difference between the variants
is maintained, showing a clear advantage of SPI,
although performance of all variants is degraded
somewhat.
Clearly, accuracy is rather low for the base-
line condition (JS); this is due to the large num-
ber of non-standard constructions in our sponta-
neous material (e.g., utterances like ?lo?schen, un-
ten? (delete, bottom) which we did not try to cover
with syntactic rules, and which may not even con-
tain NPs. The SPI condition can promote deriva-
tions resulting from robust rules (here, deletion)
which then can refer. In general though state-of-
the art grammar engineering may narrow the gap
between JS and SPI ? this remains to be tested ?
but we see as an advantage of our approach that
it can improve over the (easy-to-engineer) set of
core grammar rules.
5 Conclusions
We have described a model of semantic process-
ing of natural, spontaneous speech that strives
to jointly satisfy syntactic and pragmatic con-
straints (the latter being approximated by the as-
sumption that referring expressions are intended
to indeed successfully refer in the given context).
The model is robust, accepting also input of the
kind that can be expected from automatic speech
recognisers, and incremental, that is, can be fed
input on a word-by-word basis, computing at each
increment only exactly the contribution of the new
word. Lastly, as another novel contribution, the
model makes use of a principled formalism for se-
mantic representation, RMRS (Copestake, 2006).
While the results show that our approach of
combining syntactic and pragmatic information
can work in a real-world setting on realistic
data?previous work in this direction has so far
521
only been at the proof-of-concept stage?there is
much room for improvement. First, we are now
exploring ways of bootstrapping a grammar and
derivation weights from hand-corrected parses.
Secondly, we are looking at making the variable
assignment / model checking function probabilis-
tic, assigning probabilities (degree of strength of
belief) to candidate resolutions (as for example
the model of Schlangen et al(2009) does). An-
other next step?which will be very easy to take,
given the modular nature of the implementation
framework that we have used?will be to integrate
this component into an interactive end-to-end sys-
tem, and testing other domains in the process.
Acknowledgements We thank the anonymous
reviewers for their helpful comments. The work
reported here was supported by a DFG grant in
the Emmy Noether programme to the last author
and a stipend from DFG-CRC (SFB) 632 to the
first author.
References
Gregory Aist, James Allen, Ellen Campana, Car-
los Gomez Gallo, Scott Stoness, Mary Swift, and
Michael K. Tanenhaus. 2007. Incremental under-
standing in human-computer dialogue and experi-
mental evidence for advantages over nonincremen-
tal methods. In Proceedings of Decalog 2007, the
11th International Workshop on the Semantics and
Pragmatics of Dialogue, Trento, Italy.
Timo Baumann, Michaela Atterer, and David
Schlangen. 2009. Assessing and improving the per-
formance of speech recognition for incremental sys-
tems. In Proceedings of the North American Chap-
ter of the Association for Computational Linguis-
tics - Human Language Technologies (NAACL HLT)
2009 Conference, Boulder, Colorado, USA, May.
Timo Baumann, Okko Bu?, and David Schlangen.
2011. Evaluation and optimization of incremen-
tal processors. Dialogue and Discourse, 2(1):113?
141.
Niels Beuck, Arne Ko?hn, and Wolfgang Menzel.
2011. Decision strategies for incremental pos tag-
ging. In Proceedings of the 18th Nordic Con-
ference of Computational Linguistics, NODALIDA-
2011, Riga, Latvia.
Okko Bu? and David Schlangen. 2010. Modelling
sub-utterance phenomena in spoken dialogue sys-
tems. In Proceedings of the 14th International
Workshop on the Semantics and Pragmatics of Dia-
logue (Pozdial 2010), pages 33?41, Poznan, Poland,
June.
Ann Copestake. 2006. Robust minimal recursion se-
mantics. Technical report, Cambridge Computer
Lab. Unpublished draft.
Ann Copestake. 2007. Semantic composition with
(robust) minimal recursion semantics. In Proceed-
ings of the Workshop on Deep Linguistic Process-
ing, DeepLP ?07, pages 73?80, Stroudsburg, PA,
USA. Association for Computational Linguistics.
David DeVault and Matthew Stone. 2003. Domain
inference in incremental interpretation. In Proceed-
ings of ICOS 4: Workshop on Inference in Compu-
tational Semantics, Nancy, France, September. IN-
RIA Lorraine.
David DeVault, Kenji Sagae, and David Traum. 2011.
Incremental Interpretation and Prediction of Utter-
ance Meaning for Interactive Dialogue. Dialogue
and Discourse, 2(1):143?170.
Raquel Ferna?ndez and David Schlangen. 2007. Re-
ferring under restricted interactivity conditions. In
Simon Keizer, Harry Bunt, and Tim Paek, editors,
Proceedings of the 8th SIGdial Workshop on Dis-
course and Dialogue, pages 136?139, Antwerp,
Belgium, September.
Ulrike Pado?, Matthew W Crocker, and Frank Keller.
2009. A probabilistic model of semantic plausi-
bility in sentence processing. Cognitive Science,
33(5):794?838.
Matthew Purver, Arash Eshghi, and Julian Hough.
2011. Incremental semantic construction in a di-
alogue system. In J. Bos and S. Pulman, editors,
Proceedings of the 9th International Conference on
Computational Semantics (IWCS), pages 365?369,
Oxford, UK, January.
Brian Roark. 2001. Robust Probabilistic Predictive
Syntactic Processing: Motivations, Models, and
Applications. Ph.D. thesis, Department of Cogni-
tive and Linguistic Sciences, Brown University.
David Schlangen and Gabriel Skantze. 2009. A gen-
eral, abstract model of incremental dialogue pro-
cessing. In EACL ?09: Proceedings of the 12th
Conference of the European Chapter of the Associa-
tion for Computational Linguistics, pages 710?718.
Association for Computational Linguistics, mar.
David Schlangen, Timo Baumann, and Michaela At-
terer. 2009. Incremental reference resolution: The
task, metrics for evaluation, and a bayesian filtering
model that is sensitive to disfluencies. In Proceed-
ings of SIGdial 2009, the 10th Annual SIGDIAL
Meeting on Discourse and Dialogue, London, UK,
September.
David Schlangen, Timo Baumann, Hendrik
Buschmeier, Okko Bu?, Stefan Kopp, Gabriel
Skantze, and Ramin Yaghoubzadeh. 2010. Middle-
ware for Incremental Processing in Conversational
Agents. In Proceedings of SigDial 2010, Tokyo,
Japan, September.
522
William Schuler, Stephen Wu, and Lane Schwartz.
2009. A framework for fast incremental interpre-
tation during speech decoding. Computational Lin-
guistics, 35(3).
William Schuler. 2003. Using model-theoretic se-
mantic interpretation to guide statistical parsing and
word recognition in a spoken language interface. In
Proceedings of the 41st Meeting of the Association
for Computational Linguistics (ACL 2003), Sap-
poro, Japan. Association for Computational Lin-
guistics.
Gabriel Skantze and Anna Hjalmarsson. 2010. To-
wards incremental speech generation in dialogue
systems. In Proceedings of the SIGdial 2010 Con-
ference, pages 1?8, Tokyo, Japan, September.
Gabriel Skantze and David Schlangen. 2009. Incre-
mental dialogue processing in a micro-domain. In
Proceedings of the 12th Conference of the Euro-
pean Chapter of the Association for Computational
Linguistics (EACL 2009), pages 745?753, Athens,
Greece, March.
Mark Steedman. 2000. The Syntactic Process. MIT
Press, Cambridge, Massachusetts.
Scott C. Stoness, Joel Tetreault, and James Allen.
2004. Incremental parsing with reference inter-
action. In Proceedings of the Workshop on In-
cremental Parsing at the ACL 2004, pages 18?25,
Barcelona, Spain, July.
Scott C. Stoness, James Allen, Greg Aist, and Mary
Swift. 2005. Using real-world reference to improve
spoken language understanding. In AAAI Workshop
on Spoken Language Understanding, pages 38?45.
523
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 103?108,
Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational Linguistics
INPRO_iSS: A Component for Just-In-Time Incremental Speech Synthesis
Timo Baumann
University of Hamburg
Department for Informatics
Germany
baumann@informatik.uni-hamburg.de
David Schlangen
University of Bielefeld
Faculty of Linguistics and Literary Studies
Germany
david.schlangen@uni-bielefeld.de
Abstract
We present a component for incremental
speech synthesis (iSS) and a set of applications
that demonstrate its capabilities. This compo-
nent can be used to increase the responsivity
and naturalness of spoken interactive systems.
While iSS can show its full strength in systems
that generate output incrementally, we also dis-
cuss how even otherwise unchanged systems
may profit from its capabilities.
1 Introduction
Current state of the art in speech synthesis for spoken
dialogue systems (SDSs) is for the synthesis com-
ponent to expect full utterances (in textual form) as
input and to deliver an audio stream verbalising this
full utterance. At best, timing information is returned
as well so that a control component can determine in
case of an interruption / barge-in by the user where
in the utterance this happened (Edlund, 2008; Mat-
suyama et al, 2010).
We want to argue here that providing capabilities
to speech synthesis components for dealing with units
smaller than full utterances can be beneficial for a
whole range of interactive speech-based systems. In
the easiest case, incremental synthesis simply reduces
the utterance-initial delay before speech output starts,
as output already starts when its beginning has been
produced. In an otherwise conventional dialogue sys-
tem, the synthesis module could make it possible
to interrupt the output speech stream (e. g., when a
noise event is detected that makes it likely that the
user will not be able to hear what is being said), and
continue production when the interruption is over. If
other SDS components are adapted more to take ad-
vantage of incremental speech synthesis, even more
flexible behaviours can be realised, such as providing
utterances in installments (Clark, 1996) that prompt
for backchannel signals, which in turn can prompt
different utterance continuations, or starting an utter-
ance before all information required in the utterance
is available (?so, uhm, there are flights to Seoul on uh
. . . ?), signaling that the turn is being held. Another,
less conventional type of speech-based system that
could profit from iSS is ?babelfish-like? simultaneous
speech-to-speech translation.
Research on architectures, higher-level process-
ing modules and lower-level processing modules that
would enable such behaviour is currently underway
(Skantze and Schlangen, 2009; Skantze and Hjal-
marsson, 2010; Baumann and Schlangen, 2011), but
a synthesis component that would unlock the full
potential of such strategies is so far missing. In this
paper, we present such a component, which is capa-
ble of
(a) starting to speak before utterance processing has
finished;
(b) handling edits made to (as-yet unspoken) parts of
the utterance even while a prefix is already being
spoken;
(c) enabling adaptations of delivery parameters such
as speaking rate or pitch;
(d) autonomously making appropriate delivery-
related decisions;
(e) providing information about progress in delivery;
and, last but not least,
(f) running in real time.
Our iSS component is built on top of an exist-
ing non-incremental synthesis component, MaryTTS
(Schr?der and Trouvain, 2003), and on an existing
architecture for incremental processing, INPROTK
(Baumann and Schlangen, 2012).
103
After a discussion of related work (Section 2), we
describe the basic elements of our iSS component
(Section 3) and some demonstrator applications that
we created which showcase certain abilities.1
2 Related Work
Typically, in current SDSs utterances are gener-
ated (either by lookup/template-based generation, or,
less commonly, by concept-to-utterance natural lan-
guage generation (NLG)) and then synthesised in full
(McTear, 2002). There is very little work on incre-
mental synthesis (i.e., one that would work with units
smaller than full utterances). Edlund (2008) outlines
some requirements for incremental speech synthe-
sis: to give constant feedback to the dialogue system
about what has been delivered, to be interruptible
(and possibly continue from that position), and to run
in real time. Edlund (2008) also presents a prototype
that meets these requirements, but is limited to di-
phone synthesis that is performed non-incrementally
before utterance delivery starts. We go beyond this
in processing just-in-time, and also enabling changes
during delivery.
Skantze and Hjalmarsson (2010) describe a sys-
tem that generates utterances incrementally (albeit
in a WOz-enviroment), allowing earlier components
to incrementally produce and revise their hypothesis
about the user?s utterance. The system can automati-
cally play hesitations if by the time it has the turn it
does not know what to produce yet. They show that
users prefer such a system over a non-incremental
one, even though it produced longer dialogues. Our
approach is complementary to this work, as it tar-
gets a lower layer, the realisation or synthesis layer.
Where their system relies on ?regular? speech syn-
thesis which is called on relatively short utterance
fragments (and thus pays for the increase in respon-
siveness with a reduction in synthesis quality, esp.
regarding prosody), we aim to incrementalize the
speech synthesis component itself.
Dutoit et al (2011) have presented an incremental
formulation for HMM-based speech synthesis. How-
ever, their system works offline and is fed by non-
incrementally produced phoneme target sequences.
1The code of the toolkit and its iSS component and the demo
applications discussed below have been released as open-source
at http://inprotk.sourceforge.net.
We aim for a fully incremental speech synthesis com-
ponent that can be integrated into dialogue systems.
There is some work on incremental NLG (Kilger
and Finkler, 1995; Finkler, 1997; Guhe, 2007); how-
ever, that work does not concern itself with the actual
synthesis of speech and hence describes only what
would generate the input to our component.
3 Incremental Speech Synthesis
3.1 Background on Speech Synthesis
Text-to-speech (TTS) synthesis normally proceeds in
a top-down fashion, starting on the utterance level
(for stress patterns and sentence-level intonation) and
descending to words and phonemes (for pronunci-
ation details), in order to make globally optimised
decisions (Taylor, 2009). In that way, target phoneme
sequences annotated with durations and pitch con-
tours are generated, in what is called the linguistic
pre-processing step.
The then following synthesis step proper can be
executed in one of several ways, with HMM-based
and unit-selection synthesis currently being seen as
producing the perceptually best results (Taylor, 2009).
The former works by first turning the target sequence
into a sequence of HMM states; a global optimiza-
tion then computes a stream of vocoding features
that optimize both HMM emission probabilities and
continuity constraints (Tokuda et al, 2000). Finally,
the parameter frames are fed to a vocoder which gen-
erates the speech audio signal. Unit-selection, in
contrast, searches for the best sequence of (variably
sized) units of speech in a large, annotated corpus
of recordings, aiming to find a sequence that closely
matches the target sequence.
As mentioned above, Dutoit et al (2011) have pre-
sented an online formulation of the optimization step
in HMM-based synthesis. Beyond this, two other fac-
tors influenced our decision to follow the HMM-based
approach: (a) HMM-based synthesis nicely separates
the production of vocoding parameter frames from
the production of the speech audio signal, which
allows for more fine-grained concurrent processing
(see next subsection); (b) parameters are partially
independent in the vocoding frames, which makes
it possible to manipulate e. g. pitch independently
(and outside of the HMM framework) without altering
other parameters or deteriorating speech quality.
104
Figure 1: Hierarchic structure of incremental units describ-
ing an example utterance as it is being produced during
utterance delivery.
3.2 System Architecture
Our component works by reducing the aforemen-
tioned top-down requirements. We found that it is
not necessary to work out all details at one level
of processing before starting to process at the next
lower level. For example, not all words of the utter-
ance need to be known to produce the sentence-level
intonation (which itself however is necessary to de-
termine pitch contours) as long as a structural outline
of the utterance is available. Likewise, post-lexical
phonological processes can be computed as long
as a local context of one word is available; vocod-
ing parameter computation (which must model co-
articulation effects) in turn can be satisfied with just
one phoneme of context; vocoding itself does not
need any lookahead at all (aside from audio buffering
considerations).
Thus, our component generates its data structures
incrementally in a top-down-and-left-to-right fashion
with different amounts of pre-planning, using sev-
eral processing modules that work concurrently. This
results in a ?triangular? structure (illustrated in Fig-
ure 1) where only the absolutely required minimum
has to be specified at each level, allowing for later
adaptations with few or no recomputations required.
As an aside, we observe that our component?s ar-
chitecture happens to correspond rather closely to
Levelt?s (1989) model of human speech production.
Levelt distinguishes several, partially independent
processing modules (conceptualization, formulation,
articulation, see Figure 1) that function incrementally
and ?in a highly automatic, reflex-like way? (Levelt,
1989, p. 2).
3.3 Technical Overview of Our System
As a basis, we use MaryTTS (Schr?der and Trou-
vain, 2003), but we replace Mary?s internal data struc-
tures with structures that support incremental spec-
ifications; these we take from an extant incremen-
tal spoken dialogue system architecture and toolkit,
INPROTK (Schlangen et al, 2010; Baumann and
Schlangen, 2012). In this architecture, incremental
processing as the processing of incremental units
(IUs), which are the smallest ?chunks? of information
at a specific level (such as words, or phonemes, as
can be seen in Figure 1). IUs are interconnected to
form a network (e. g. words keep links to their asso-
ciated phonemes, and vice-versa) which stores the
system?s complete information state.
The iSS component takes an IU sequence of
chunks of words as input (from an NLG component).
Crucially, this sequence can then still be modified,
through: (a) continuations, which simply link further
words to the end of the sequence; or (b) replacements,
where elements in the sequence are ?unlinked? and
other elements are spliced in. Additionally, a chunk
can be marked as open; this has the effect of linking
to a special hesitation word, which is produced only
if it is not replaced (by the NLG) in time with other
material.
Technically, the representation levels below the
chunk level are generated in our component by
MaryTTS?s linguistic preprocessing and converting
the output to IU structures. Our component provides
for two modes of operation: Either using MaryTTS?
HMM optimization routines which non-incrementally
solve a large matrix operation and subsequently iter-
atively optimize the global variance constraint (Toda
and Tokuda, 2007). Or, using the incremental algo-
rithm as proposed by Dutoit et al (2011). In our
implementation of this algorithm, HMM emissions
are computed with one phoneme of context in both
directions; Dutoit et al (2011) have found this set-
ting to only slightly degrade synthesis quality. While
the former mode incurs some utterance-initial delay,
switching between alternatives and prosodic alter-
ation can be performed at virtually no lookahead,
while requiring just little lookahead for the truly
incremental mode. The resulting vocoding frames
then are attached to their corresponding phoneme
units. Phoneme units then contain all the information
105
Figure 2: Example application that showcases just-in-time
manipulation of prosodic aspects (tempo and pitch) of the
ongoing utterance.
needed for the final vocoding step, in an accessible
form, which makes possible various manipulations
before the final synthesis step.
The lowest level module of our component is what
may be called a crawling vocoder, which actively
moves along the phoneme IU layer, querying each
phoneme for its parameter frames one-by-one and
producing the corresponding audio via vocoding. The
vocoding algorithm is entirely incremental, making
it possible to vocode ?just-in-time?: only when audio
is needed to keep the sound card buffer full does the
vocoder query for a next parameter frame. This is
what gives the higher levels the maximal amount of
time for re-planning, i. e., to be incremental.
3.4 Quality of Results
As these descriptions should have made clear, there
are some elements in the processing steps in our iSS
component that aren?t yet fully incremental, such as
assigning a sentence-level prosody. The best results
are thus achieved if a full utterance is presented to the
component initially, which is used for computation of
prosody, and of which then elements may be changed
(e. g., adjectives are replaced by different ones) on the
fly. It is unavoidable, though, that there can be some
?breaks? at the seams where elements are replaced.
Moreover, the way feature frames can be modified
(as described below) and the incremental HMM op-
timization method may lead to deviations from the
global optimum. Finally, our system still relies on
Mary?s non-incremental HMM state selection tech-
nique which uses decision trees with non-incremental
features.
However, preliminary evaluation of the compo-
nent?s prosody given varying amounts of lookahead
indicate that degradations are reasonably small. Also,
the benefits in naturalness of behaviour enabled by
iSS may outweigh the drawback in prosodic quality.
4 Interface Demonstrations
We will describe the features of iSS, their implemen-
tation, their programming interface, and correspond-
ing demo applications in the following subsections.
4.1 Low-Latency Changes to Prosody
Pitch and tempo can be adapted on the phoneme
IU layer (see Figure 1). Figure 2 shows a demo in-
terface to this functionality. Pitch is determined by
a single parameter in the vocoding frames and can
be adapted independently of other parameters in the
HMM approach. We have implemented capabilities of
adjusting all pitch values in a phoneme by an offset,
or to change the values gradually for all frames in
the phoneme. (The first feature is show-cased in the
application in Figure 2, the latter is used to cancel
utterance-final pitch changes when a continuation is
appended to an ongoing utterance.) Tempo can be
adapted by changing the phoneme units? durations
which will then repeat (or skip) parameter frames
(for lengthened or shortened phonemes, respectively)
when passing them to the crawling vocoder. Adapta-
tions are conducted with virtually no lookahead, that
is, they can be executed even on a phoneme that is
currently being output.
4.2 Feedback on Delivery
We implemented a fine-grained, hierarchical mech-
anism to give detailed feedback on delivery. A new
progress field on IUs marks whether the IU?s produc-
tion is upcoming, ongoing, or completed. Listeners
may subscribe to be notified about such progress
changes using an update interface on IUs. The appli-
cations in Figures 2 and 4 make use of this interface
to mark the words of the utterance in bold for com-
pleted, and in italic for ongoing words (incidentally,
the screenshot in Figure 4 was taken exactly at the
boundary between ?delete? and ?the?).
4.3 Low-Latency Switching of Alternatives
A major goal of iSS is to change what is being said
while the utterance is ongoing. Forward-pointing
same-level links (SLLs, (Schlangen and Skantze,
2009; Baumann and Schlangen, 2012)) as shown
in Figure 3 allow to construct alternative utterance
paths beforehand. Deciding on the actual utterance
continuation is a simple re-ranking of the forward
106
Figure 3: Incremental units chained together via forward-
pointing same-level links to form an utterance tree.
Figure 4: Example application to showcase just-in-time
selection between different paths in a complex utterance.
SLLs which can be changed until immediately before
the word (or phoneme) in question is being uttered.
The demo application shown in Figure 4 allows the
user to select the path through a fairly complex utter-
ance tree. The user has already decided on the color,
but not on the type of piece to be deleted and hence
the currently selected plan is to play a hesitation (see
below).
4.4 Extension of the Ongoing Utterance
In the previous subsection we have shown how alter-
natives in utterances can be selected with very low
latency. Adding continuations (or alternatives) to
an ongoing utterance incurs some delay (some hun-
dred milliseconds), as we ensure that an appropriate
sentence-level prosody for the alternative (or con-
tinuation) is produced by re-running the linguistic
pre-processing on the complete utterance; we then
integrate only the new, changed parts into the IU
structure (or, if there still is time, parts just before the
change, to account for co-articulation).
Thus, practical applications which use incremen-
tal NLG must generate their next steps with some
lookahead to avoid stalling the output. However, ut-
terances can be marked as non-final, which results in
a special hesitation word being inserted, as explained
below.
4.5 Autonomously Performing Disfluencies
In a multi-threaded, real-time system, the crawling
vocoder may reach the end of synthesis before the
NLG component (in its own thread) has been able
to add a continuation to the ongoing utterance. To
avoid this case, special hesitation words can be in-
serted at the end of a yet unfinished utterance. If the
crawling vocoder nears such a word, a hesitation will
be played, unless a continuation is available. In that
case, the hesitation is skipped (or aborted if currently
ongoing).2
4.6 Type-to-Speech
A final demo application show-cases truly incremen-
tal HMM synthesis taken to its most extreme: A text
input window is presented, and each word that is
typed is treated as a single-word chunk which is im-
mediately sent to the incremental synthesizer. (For
this demonstration, synthesis is slowed to half the
regular speed, to account for slow typing speeds and
to highlight the prosodic improvements when more
right context becomes available to iSS.) A use case
with a similar (but probably lower) level of incre-
mentality could be simultaneous speech-to-speech
translation, or type-to-speech for people with speech
disabilities.
5 Conclusions
We have presented a component for incremental
speech synthesis (iSS) and demonstrated its capa-
bilities with a number of example applications. This
component can be used to increase the responsivity
and naturalness of spoken interactive systems. While
iSS can show its full strengths in systems that also
generate output incrementally (a strategy which is
currently seeing some renewed attention), we dis-
cussed how even otherwise unchanged systems may
profit from its capabilities, e. g., in the presence of
intermittent noise. We provide this component in the
hope that it will help spur research on incremental
natural language generation and more interactive spo-
ken dialogue systems, which so far had to made do
with inadequate ways of realising its output.
2Thus, in contrast to (Skantze and Hjalmarsson, 2010), hesi-
tations do not take up any additional time.
107
References
Timo Baumann and David Schlangen. 2011. Predicting
the Micro-Timing of User Input for an Incremental Spo-
ken Dialogue System that Completes a User?s Ongoing
Turn. In Proceedings of SigDial 2011, pages 120?129,
Portland, USA, June.
Timo Baumann and David Schlangen. 2012. The
INPROTK 2012 release. In Proceedings of SDCTD.
to appear.
Herbert H. Clark. 1996. Using Language. Cambridge
University Press.
Thierry Dutoit, Maria Astrinaki, Onur Babacan, Nico-
las d?Alessandro, and Benjamin Picart. 2011. pHTS
for Max/MSP: A Streaming Architecture for Statistical
Parametric Speech Synthesis. Technical Report 1, nu-
mediart Research Program on Digital Art Technologies,
March.
Jens Edlund. 2008. Incremental speech synthesis. In
Second Swedish Language Technology Conference,
pages 53?54, Stockholm, Sweden, November. System
Demonstration.
Wolfgang Finkler. 1997. Automatische Selbstkorrek-
tur bei der inkrementellen Generierung gesprochener
Sprache unter Realzeitbedingungen. Dissertationen zur
K?nstlichen Intelligenz. infix Verlag.
Markus Guhe. 2007. Incremental Conceptualization for
Language Production. Lawrence Erlbaum Asso., Inc.,
Mahwah, USA.
Anne Kilger and Wolfgang Finkler. 1995. Incremen-
tal Generation for Real-time Applications. Technical
Report RR-95-11, DFKI, Saarbr?cken, Germany.
William J.M. Levelt. 1989. Speaking: From Intention to
Articulation. MIT Press.
Kyoko Matsuyama, Kazunori Komatani, Ryu Takeda,
Toru Takahashi, Tetsuya Ogata, and Hiroshi G. Okuno.
2010. Analyzing User Utterances in Barge-in-able Spo-
ken Dialogue System for Improving Identification Ac-
curacy. In Proceedings of Interspeech, pages 3050?
3053, Makuhari, Japan, September.
Michael McTear. 2002. Spoken Dialogue Technology.
Toward the Conversational User-Interface. Springer,
London, UK.
David Schlangen and Gabriel Skantze. 2009. A General,
Abstract Model of Incremental Dialogue Processing.
In Proceedings of the EACL, Athens, Greece.
David Schlangen, Timo Baumann, Hendrik Buschmeier,
Okko Bu?, Stefan Kopp, Gabriel Skantze, and Ramin
Yaghoubzadeh. 2010. Middleware for Incremental
Processing in Conversational Agents. In Proceedings of
SigDial 2010, pages 51?54, Tokyo, Japan, September.
Marc Schr?der and J?rgen Trouvain. 2003. The German
Text-to-Speech Synthesis System MARY: A Tool for
Research, Development and Teaching. International
Journal of Speech Technology, 6(3):365?377, October.
Gabriel Skantze and Anna Hjalmarsson. 2010. Towards
incremental speech generation in dialogue systems. In
Proceedings of SigDial 2010, pages 1?8, Tokyo, Japan,
September.
Gabriel Skantze and David Schlangen. 2009. Incremental
dialogue processing in a micro-domain. In Proceedings
of EACL 2009, Athens, Greece, April.
Paul Taylor. 2009. Text-to-Speech Synthesis. Cambridge
Univ Press, Cambridge, UK.
Tomoki Toda and Keiichi Tokuda. 2007. A Speech Pa-
rameter Generation Algorithm Considering Global Vari-
ance for HMM-based Speech Synthesis. IEICE Trans-
actions on Information and Systems, 90(5):816?824.
Keiichi Tokuda, Takayoshi Yoshimura, Takashi Ma-
suko, Takao Kobayashi, and Tadashi Kitamura. 2000.
Speech Parameter Generation Algorithms for HMM-
based Speech Synthesis. In Proceedings of ICASSP
2000, pages 1315?1318, Istanbul, Turkey.
108
Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 9?16,
The University of Tokyo, September 24-25, 2010. c?2010 Association for Computational Linguistics
Comparing Local and Sequential Models for
Statistical Incremental Natural Language Understanding
Silvan Heintze, Timo Baumann, David Schlangen
Department of Linguistics
University of Potsdam, Germany
firstname.lastname@uni-potsdam.de
Abstract
Incremental natural language understand-
ing is the task of assigning semantic rep-
resentations to successively larger prefixes
of utterances. We compare two types of
statistical models for this task: a) local
models, which predict a single class for
an input; and b), sequential models, which
align a sequence of classes to a sequence
of input tokens. We show that, with some
modifications, the first type of model can
be improved and made to approximate the
output of the second, even though the lat-
ter is more informative. We show on two
different data sets that both types of model
achieve comparable performance (signifi-
cantly better than a baseline), with the first
type requiring simpler training data. Re-
sults for the first type of model have been
reported in the literature; we show that for
our kind of data our more sophisticated
variant of the model performs better.
1 Introduction
Imagine being at a dinner, when your friend Bert
says ?My friend, can you pass me the salt over
there, please??. It is quite likely that you get the
idea that something is wanted of you fairly early
into the utterance, and understand what exactly it
is that is wanted even before the utterance is over.
This is possible only because you form an un-
derstanding of the meaning of the utterance even
before it is complete; an understanding which
you refine?and possibly revise?as the utterance
goes on. You understand the utterance incremen-
tally. This is something that is out of reach for
most current dialogue systems, which process ut-
terances non-incrementally, en bloc (cf. (Skantze
and Schlangen, 2009), inter alia).
Enabling incremental processing in dialogue
systems poses many challenges (Allen et al,
2001; Schlangen and Skantze, 2009); we focus
here on the sub-problem of modelling incremental
understanding?a precondition for enabling truly
interactive behaviour. More specifically, we look
at statistical methods for learning mappings be-
tween (possibly partial) utterances and meaning
representations. We distinguish between two types
of understanding, which were sketched in the first
paragraph above: a) forming a partial understand-
ing, and b) predicting a complete understanding.
Recently, some results have been published on
b), predicting utterance meanings, (Sagae et al,
2009; Schlangen et al, 2009). We investigate
here how well this predictive approach works in
two other domains, and how a simple extension of
techniques (ensembles of slot-specific classifiers
vs. one frame-specific one) can improve perfor-
mance. To our knowledge, task a), computing par-
tial meanings, has so far only been tackled with
symbolic methods (e.g., (Milward and Cooper,
1994; Aist et al, 2006; Atterer and Schlangen,
2009));1 we present here some first results on ap-
proaching it with statistical models.
Plan of the paper: First, we discuss relevant pre-
vious work. We then define the task of incremental
natural language understanding and its two vari-
ants in more detail, also looking at how models
can be evaluated. Finally, we present and discuss
the results of our experiments, and close with a
conclusion and some discussion of future work.
2 Related Work
Statistical natural language understanding is an ac-
tive research area, and many sophisticated mod-
els for this task have recently been published, be
that generative models (e.g., in (He and Young,
2005)), which learn a joint distribution over in-
1We explicitly refer to computation of incremental inter-
pretations here; there is of course a large body of work on
statistical incremental parsing (e.g., (Stolcke, 1995; Roark,
2001)).
9
(Mairesse et al, 2009) 94.50
(He and Young, 2005) 90.3
(Zettlemoyer and Collins, 2007) 95.9
(Meza et al, 2008) 91.56
Table 1: Recent published f-scores for non-
incremental statistical NLU, on the ATIS corpus
put, output and possibly hidden variables; or, more
recently, discriminative models (e.g., (Mairesse et
al., 2009)) that directly learn a mapping between
input and output. Much of this work uses the ATIS
corpus (Dahl et al, 1994) as data and hence is di-
rectly comparable. In Table 1, we list the results
achieved by this work; we will later situate our re-
sults relative to this.
That work, however, only looks at mappings be-
tween complete utterances and semantic represen-
tations, whereas we are interested in the process of
mapping semantic representations to successively
larger utterance fragments. More closely related
then is (Sagae et al, 2009; DeVault et al, 2009),
where a maximum entropy model is trained for
mapping utterance fragments to semantic frames.
(Sagae et al, 2009) make the observation that of-
ten the quality of the prediction does not increase
anymore towards the end of the utterance; that is,
the meaning of the utterance can be predicted be-
fore it is complete.
In (Schlangen et al, 2009), we presented a
model that predicts incrementally a specific as-
pect of the meaning of a certain type of utterance,
namely the intended referent of a referring expres-
sion; the similarity here is that the output is of the
same type regardless of whether the input utter-
ance is complete or not.
(DeVault et al, 2009) discuss how such ?mind
reading? can be used interactionally in a dialogue
system, e.g. for completing the user?s utterance
as an indication of the system?s grounding state.
While these are interesting uses, the approach is
somewhat limited by the fact that it is incremental
only on the input side, while the output does not
reflect how ?complete? (or not) the input is. We
will compare this kind of incremental processing
in the next section with one where the output is
incremental as well, and we will then present re-
sults from our own experiments with both kinds of
incrementality in statistical NLU.
3 Task, Evaluation, and Data Sets
3.1 The Task
We have said that the task of incremental natural
language understanding consists in the assignment
of semantic representations to progressively more
complete prefixes of utterances. This description
can be specified along several aspects, and this
yields different versions of the task, appropriate
for different uses. One question is what the as-
signed representations are, the other is what ex-
actly they are assigned to. We investigate these
questions here abstractly, before we discuss the in-
stantiations in the next sections.
Let?s start by looking at the types of representa-
tions that are typically assigned to full utterances.
A type often used in dialogue systems is the frame,
an attribute value matrix. (The attributes are here
typically called slots.) These frames are normally
typed, that is, there are restrictions on which slots
can (and must) occur together in one frame. The
frames are normally assigned to the utterance as a
whole and not to individual words.
In an incremental setting, where the input
potentially consists of an incomplete utterance,
choosing this type of representation and style of
assignment turns the task into one of prediction of
the utterance meaning. What we want our model
to deliver is a guess of what the meaning of the ut-
terance is going to be, even if we have only seen
a prefix of the utterance so far; we will call this
?whole-frame output? below.2
Another popular representation of semantics in
applied systems uses semantic tags, i.e., markers
of semantic role that are attached to individual
parts of the utterance. Such a style of assignment
is inherently ?more incremental?, as it provides a
way to assign meanings that represent only what
has indeed been said so far, and does not make as-
sumptions about what will be said. The semantic
representation of the prefix simply contains all and
only the tags assigned to the words in the prefix;
this will be called ?aligned output? below. To our
knowledge, the potential of this type of represen-
tation (and the models that create them) for incre-
mental processing has not yet been explored; we
present our first results below.
Finally, there is a hybrid form of representation
and assignment. If we allow the output frames to
?grow? as more input comes in (hence possibly vi-
olating the typing of the frames as they are ex-
pected for full utterances), we get a form of rep-
resentation with a notion of ?partial semantics? (as
2In (Schlangen and Skantze, 2009), this type of incremen-
tal processing is called ?input incremental?, as only the input
is incrementally enriched, while the output is always of the
same type (but may increase in quality).
10
only that is represented for which there is evidence
in what has already been seen), but without direct
association of parts of the representation and parts
of the utterance or utterance prefix.
3.2 Evaluation
Whole-Frame Output A straightforward met-
ric is Correctness, which can take the values 1
(output is exactly as expected) or 0 (output is not
exactly as expected). Processing a test corpus in
this way, we get one number for each utterance
prefix, and, averaging this number, one measure-
ment for the whole corpus.
This can give us a first indication of the gen-
eral quality of the model, but because it weighs
the results for prefixes of all lengths equally, it
cannot tell us much about how well the incremen-
tal processing worked. In actual applications, we
presumably do not expect the model to be correct
from the very first word on, but do expect it to get
better the longer the available utterance prefix be-
comes. To capture this, we define two more met-
rics: first occurrence (FO), as the position (relative
to the eventual length of the full utterance) where
the response was correct first; and final decision
(FD) as the position from which on the response
stayed correct (which consequently can only be
measured if indeed the response stays correct).3
The difference between FO and FD then tells us
something about the stability of hypotheses of the
model.
In some applications, we may indeed only be
able to do further processing with fully correct?
or at least correctly typed?frames; in which case
correctness and FO/FD on frames are appropriate
metrics. However, sometimes even frames that are
only partially correct can be of use, for example if
specific system reactions can be tied to individual
slots. To give us more insight about the quality of a
model in such cases, we need a metric that is finer-
grained than binary correctness. Following (Sagae
et al, 2009), we can conceptualise our task as one
of retrieval of slot/value pairs, and use precision
and recall (and, as their combination, f-score) as
metrics. As we will see, it will be informative to
plot the development of this score over the course
of processing the utterance.
For these kinds of evaluations, we need as a
gold standard only one annotation per utterance,
3These metrics of course can only be computed post-hoc,
as during processing we do not know how long the utterance
is going to be.
namely the final frame.
Aligned Output As sequence alignments have
more structure?there is a linear order between the
tags, and there is exactly one tag per input token?
correctness is a more fine-grained, and hence more
informative, metric here; we define it as the pro-
portion of tags that are correct in a sequence. We
can also use precision and recall here, looking at
each position in the sequence individually: Has
the tag been recalled (true positive), or has some-
thing else been predicted instead (false negative,
and false positive)? Lastly, we can also recon-
struct frames from the tag sequences, where se-
quences of the same tag are interpreted as seg-
menting off the slot value. (And hence, what was
several points for being right or wrong, one for
each tag, becomes one, being either the correct
slot value or not. We will discuss these differences
when we show evaluations of aligned output.)
For this type of evaluation, we need gold-
standard information of the same kind, that is, we
need aligned tag sequences. This information is
potentially more costly to create than the one fi-
nal semantic representation needed for the whole-
frame setting.
Hybrid Output As we will see below, the hy-
brid form of output (?growing? frames) is pro-
duced by ensembles of local classifiers, with one
classifier for each possible slot. How this output
can be evaluated depends on what type of informa-
tion is available. If we only have the final frame,
we can calculate f-score (in the hope that preci-
sion will be better than for the whole-frame clas-
sifier, as such a classifier ensemble can focus on
predicting slots/value pairs for which there is di-
rect evidence); if we do have sequence informa-
tion, we can convert it to growing frames and eval-
uate against that.
3.3 The Data Sets
ATIS As our first dataset, we use the ATIS air
travel information data (Dahl et al, 1994), as pre-
processed by (Meza et al, 2008) and (He and
Young, 2005). That is, we have available for each
utterance a semantic frame as in (1), and also a
tag sequence that aligns semantic concepts (same
as the slot names) and words. One feature to note
here about the ATIS representations is that the slot
values / semantic atoms are just the words in the
utterance. That is, the word itself is its own se-
mantic representation, and no additional abstrac-
11
tion is performed. In this domain, this is likely un-
problematic, as there aren?t many different ways
(that are to be expected in this domain) to refer to
a given city or a day of the week, for example.
(1) ?What flights are there arriving in Chicago after
11pm??
?
?
?
?
GOAL = FLIGHT
TOLOC.CITY NAME = Chicago
ARRIVE TIME.TIME RELATIVE = after
ARRIVE TIME.TIME = 11pm
?
?
?
?
In our experiments, we use the ATIS training
set which contains 4481 utterances, between 1
and 46 words in length (average 11.46; sd 4.34).
The vocabulary consists of 897 distinct words.
There are 3159 distinct frames, 2594 (or 58% of
all frames) of which occur only once. Which of
the 96 possible slots occur in a given frame is
distributed very unevenly; there are some very
frequent slots (like FROMLOC.CITYNAME
or DEPART DATE.DAY NAME) and
some very rare or even unique ones (e.g.,
ARRIVE DATE.TODAY RELATIVE, or
TIME ZONE).
Pentomino The second corpus we use is of ut-
terances in a domain that we have used in much
previous work (e.g., (Schlangen et al, 2009;
Atterer and Schlangen, 2009; Ferna?ndez and
Schlangen, 2007)), namely, instructions for ma-
nipulating puzzle pieces to form shapes. The par-
ticular version we use here was collected in a
Wizard-of-Oz study, where the goal was to instruct
the computer to pick up, delete, rotate or mirror
puzzle tiles on a rectangular board, and drop them
on another one. The user utterances were anno-
tated with semantic frames and also aligned with
tag sequences. We use here a frame representation
where the slot value is a part of the utterance (as
in ATIS), an example is shown in (2). (The cor-
pus is in German; the example is translated here
for presentation.) We show the full frame here,
with all possible slots; unused slots are filled with
?empty?. Note that this representation is some-
what less directly usable in this domain than for
ATIS; in a practical system, we?d need some fur-
ther module (rule-based or statistical) that maps
such partial strings to their denotations, as this
mapping is less obvious here than in the travel do-
main.
(2) ?Pick up the W-shaped piece in the upper right cor-
ner?
?
?
?
?
?
?
?
action = ?pick up?
tile = ?the W-shaped piece
in the upper right corner?
field = empty
rotpar = empty
mirpar = empty
?
?
?
?
?
?
?
The corpus contains 1563 utterances, average
length 5.42 words (sd 2.35), with a vocabulary of
222 distinct words. There are 964 distinct frames,
with 775 unique frames.
In both datasets we use transcribed utterances
and not ASR output, and hence our results present
an upper bound on real-world performance.
4 Local Models: Support Vector Machines
In this section we report the results of our exper-
iments with local classifiers, i.e. models which,
given an input, predict one out of a set of classes as
an answer. Such models are very naturally suited
to the prediction task, where the semantics of the
full utterance is treated as its class, which is to be
predicted on the basis of what possibly is only a
prefix of that utterance. We will also look at a
simple modification, however, which enables such
models to do something that is closer to the task of
computing partial meanings.
4.1 Experimental Setup
For our experiments with local models, we used
the implementations of support vector machines
provided by the WEKA toolkit (Witten and Frank,
2005); as baseline we use a simple majority class
predictor.4
We used the standard WEKA tools to convert
the utterance strings into word vectors. Training
was always done with the full utterance, but test-
ing was done on prefixes of utterances; i.e., a sen-
tence with 5 words would be one instance in train-
ing, but in a testing fold it would contribute 5 in-
stances, one with one word, one with two words,
and so on.5 Because of this special way of testing
the classifiers, and also because of the modifica-
4We tried other classifiers (C4.5, logistic regression, naive
Bayes) as well, and found comparable performance on a de-
velopment set. However, because of the high time costs
(some models needed > 40 hours for training and testing on
modern multi-CPU servers) we do not systematically com-
pare performance and instead focus on SVMs. In any case,
our interest here is not in comparing classification algorithms,
but rather in exploring approaches to the novel problem of
statistical incremental NLU.
5On a development set, we tried training on utterance pre-
fixes, but that degraded performance, presumably due to in-
crease in ambiguous training instances (same beginnings of
what ultimately are very different utterances).
12
tions described below, we had to provide our own
methods for cross-validation and evaluation. For
the larger ATIS data set, we used 10 folds in cross
validation, and for the Pentomino dataset 20 folds.
4.2 Results
To situate our results, we begin by looking at
the performance of the models that predict a full
frame, when given a full utterance; this is the
normal, ?non-incremental? statistical NLU task.6
(3)
classf. metric ATIS Pento
maj correctness 1.07 1.79
maj f-score 35.98 16.15
SVM correctness 16.21 38.77
SVM f-score 68.17 63.23
We see that the results for ATIS are considerably
lower than the state of the art in statistical NLU
(Table 1). This need not concern us too much
here, as we are mostly interested in the dynam-
ics of the incremental process, but it indicates that
there is room for improvement with more sophisti-
cated models and feature design. (We will discuss
an example of an improved model shortly.) We
also see a difference between the corpora reflected
in these results: being exactly right (good correct-
ness) seems to be harder on the ATIS corpus, while
being somewhat right (good f-score) seems to be
harder on the pento corpus; this is probably due to
the different sizes of the search space of possible
frame types (large for ATIS, small for pento).
What we are really interested in, however, is the
performance when given only a prefix of an ut-
terance, and how this develops over the course of
processing successively larger prefixes. We can
investigate this with Figure 1. First, look at the
solid lines. The black line shows the average f-
score at various prefix lengths (in 10% steps) for
the ATIS data, the grey line for the pento corpus.
We see that both lines show a relatively steady in-
cline, meaning that the f-score continues to im-
prove when more of the utterance is seen. This is
interesting to note, as both (DeVault et al, 2009)
and (Atterer et al, 2009) found that in their data,
all that is to be known can often be found some-
what before the end of the utterance. That this
does not work so well here is most likely due to
the difference in domain and the resulting utter-
ances. Utterances giving details about travel plans
6The results for ATIS are based on half of the overall
ATIS data, as cross-validating the model on all data took pro-
hibitively long, presumably due to the large number of unique
frames / classes.
2 4 6 8 10
0.0
0.2
0.4
0.6
0.8
percentiles into utterance
f?sc
ore
l l
l
l
l
l
l
l
l l
l all utterancesshort utterancesnormal utteranceslong utterances
l
l
l
l
l
l
l
l
l l
Figure 1: F-Score by Length of Prefix
are likely to present many important details, and
some of them late into the utterance; cf. (1) above.
The data from (DeVault et al, 2009) seems to be
more conversational in nature, and, more impor-
tantly, presumable the expressible goals are less
closely related to each other and hence can be read
off of shorter prefixes.
As presented so far, the results are not very
helpful for practical applications of incremental
NLU. One thing one would like to know in a prac-
tical situation is how much the prediction of the
model can be trusted for a given partial utterance.
We would like to read this off graphs like those
in the Figure?but of course, normally we cannot
know what percentage of an utterance we have al-
ready seen! Can we trust this averaged curve if we
do not know what length the incoming utterance
will have?
To investigate this question, we have binned the
test utterances into three classes, according to their
length: ?normal?, for utterances that are of aver-
age length? half a standard deviation, and ?short?
for all that are shorter, and ?long? for all that are
longer. The f-score curves for these classes are
shown with the non-solid lines in Figure 1. We
see that for ATIS there is not much variation com-
pared to averaging over all utterances, and more-
over, that the ?normal? class very closely follows
the general curve. On the pento data, the model
seems to be comparably better for short utterances.
In a practical application, one could go with
the assumption that the incoming utterance is go-
ing to be of normal length, and use the ?normal?
13
curve for guidance; or one could devise an ad-
ditional classifier that predicts the length-class of
the incoming utterance, or more generally predicts
whether a frame can already be trusted (DeVault et
al., 2009). We leave this for future work.
As we have seen, the models that treat the se-
mantic frame simply as a class label do not fare
particularly well. This is perhaps not that surpris-
ing; as discussed above, in our corpora there aren?t
that many utterances with exact the same frame.
Perhaps it would help to break up the task, and
train individual classifiers for each slot?7 This
idea can be illustrated with (2) above. There we al-
ready included ?unused? slots in the frame; if we
now train classifiers for each slot, allowing them
to predict ?empty? in cases where a slot is unused,
we can in theory reconstruct any frame from the
ensemble of classifiers. To cover the pento data,
the ensemble is small (there are 5 frames); it is
considerably larger for ATIS, where there are so
many distinct slots.
Again we begin by looking at the performance
for full utterances (i.e., at 100% utterance length),
but this time for constructing the frame from the
reply of the classifier ensemble:
(4)
classf. metric ATIS Pento
maj correctness 0.16 0
maj f-score 33.18 20.24
SVM correctness 52.69 50.48
SVM f-score 86.79 73.15
We see that this approach leads to an impressive
improvement on the ATIS data (83.64 f-score in-
stead of 68.17), whereas the improvement on the
pento data is more modest (73.15 / 63.23).
Figure 2 shows the incremental development of
the f-scores for the reconstructed frame. We see
a similar shape in the curves; again a relatively
steady incline for ATIS and a more dramatic shape
for pento, and again some differences in behaviour
for the different length classes of utterances. How-
ever, by just looking at the reconstructed frame,
we are ignoring valuable information that the slot-
classifier approach gives us. In some applications,
we may already be able to do something useful
with partial information; e.g., in the ATIS domain,
we could look up an airport as soon as a FROM-
LOC becomes known. Hence, we?d want more
fine-grained information, not just about when we
can trust the whole frame, but rather about when
7A comparable approach is used for the non-incremental
case for example by (Mairesse et al, 2009).
2 4 6 8 10
0.0
0.2
0.4
0.6
0.8
percentiles into utterance
f?sc
ore
l l
l
l
l
l
l
l
l
l
l all utterancesshort utterancesnormal utteranceslong utterancesl
l
l
l l
l
l
l
l l
Figure 2: F-Score by Length of Prefix; Slot Clas-
sifiers
we can trust individual predicted slot values. (And
so we move from the prediction task to the partial
representations task.)
To explore this, we look at First Occurrence and
Final Decision for some selected slots in Table 2.
For some slots, the first occurrence (FO) of the
correct value comes fairly early into the utterance
(e.g., for the name of the airline it?s at ca. 60%,
for the departure city at ca. 63%, both with rela-
tively high standard deviation, though) while oth-
ers are found the first time rather late (goal city
at 81%). This conforms well with intuitions about
how such information would be presented in an ut-
terance (?I?d like to fly on Lufthansa from Berlin
to Tokyo?).
We also see that the predictions are fairly stable:
the number of cases where the slot value stays cor-
rect until the end is almost the same as that where
it is correct at least once (FD applicable vs. FO
apl), and the average position is almost the same.
In other words, the classifiers seem to go fairly
reliably from ?empty? (no value) to the correct
value, and then seem to stay there. The overhead
of unnecessary edits (EO) is fairly low for all slots
shown in the table. (Ideally, EO is 0, meaning that
there is no change except the one from ?empty? to
correct value.) All this is good news, as it means
that a later module in a dialogue system can often
begin to work with the partial results as soon as
a slot-classifier makes a non-empty prediction. In
an actual application, how trustworthy the individ-
ual classifiers are would then be read off statistics
14
slot name avg FO stdDev apl avg FD stdDev apl avg EO stdDev apl
AIRLINE NAME 0.5914 0.2690 506 0.5909 0.2698 501 0.5180 0.5843 527
DEPART TIME.PERIOD OF DAY 0.7878 0.2506 530 0.7992 0.2476 507 0.2055 0.5558 579
FLIGHT DAYS 0.4279 0.2660 37 0.4279 0.2660 37 0.0000 0.0000 37
FROMLOC.CITY NAME 0.6345 0.1692 3633 0.6368 0.1692 3554 0.1044 0.4526 3718
ROUND TRIP 0.5366 0.2140 287 0.5366 0.2140 287 0.0104 0.1015 289
TOLOC.CITY NAME 0.8149 0.1860 3462 0.8162 0.1856 3441 0.2348 0.5723 3628
frames 0.9745 0.0811 2382 0.9765 0.0773 2361 0.7963 1.1936 4481
Table 2: FO/FD/EO for some selected slots; averaged over utterances of all lengths
like these, given a corpus from the domain.
To conclude this section, we have shown that
classifiers that predict a complete frame based on
utterance prefixes have a somewhat hard task here
(harder, it seems, than in the corpus used in (Sagae
et al, 2009), where they achieve an f-score of 87
on transcribed utterances), and the prediction re-
sults improve steadily throughout the whole utter-
ance, rather than reaching their best value before
its end. When the task is ?spread? over several
classifiers, with each one responsible for only one
slot, performance improves drastically, and also,
the results become much more ?incremental?. We
now turn to models that by design are more incre-
mental in this sense.
5 Sequential Models: Conditional
Random Fields
5.1 Experimental Setup
We use Conditional Random Fields (Lafferty et
al., 2001) as our representative of the class of se-
quential models, as implemented in CRF++.8 We
use a simple template file that creates features
based on a left context of three words.
Even though sequential models have the poten-
tial to be truly incremental (in the sense that they
could produce a new output when fed a new in-
crement, rather than needing to process the whole
prefix again), CRF++ is targeted at tagging appli-
cations, and expects full sequences. We hence test
in the same way as the SVMs from the previous
section, by computing a new tag sequence for each
prefix. Training again is done only on full utter-
ances / tag sequences.
We compare the CRF results against two base-
lines. The simplest consists of just always choos-
ing the most frequent tag, which is ?O? (for other,
marking material that does not contribute directly
to the relevant meaning of the utterance, such
as ?please? in ?I?d like to return on Monday,
please.?). The other baseline tags each word with
8http://crfpp.sourceforge.net/
2 4 6 8 10
0.5
0.6
0.7
0.8
0.9
1.0
percentiles into utterance
f?sc
ore
l l l l l l l l l l
l all utterancesshort utterancesnormal utteranceslong utterances
l l l l l l l l l
Figure 3: F-Score by Length of Prefix
ATIS Corr. Tag F-Score Frame F-Score
CRF 93.38 82.56 76.10
Maj 85.14 60.86 48.08
O 63.43 00.31 00.31
Pento Corr. Tag F-Score Frame F-Score
CRF 89.19 88.95 76.94
Maj 80.20 80.13 65.94
O 5.90 0.19 0.19
Table 3: Results of CRF models
its most frequent training data tag.
5.2 Results
We again begin by looking at the limiting case, the
results for full utterances (i.e., at the 100%mark).
Table 3 show three sets of results for each cor-
pus. Correctness looks at the proportion of tags
in a sequence that were correct. This measure is
driven up by correct recognition of the dummy
tag ?o?; as we can see, this is quite frequently
correct in ATIS, which drives up the ?always use
O?-baseline. Tag F-Score values the important
tags higher; we see here, though, that the majority
baseline (each word tagged with its most frequent
tag) is surprisingly good. It is solidly beaten for
the ATIS data, though. On the pento data, with
its much smaller tagset (5 as opposed to 95), this
baseline comes very high, but still the learner is
able to get some improvement. The last metric
evaluates reconstructed frames. It is stricter, be-
cause it offers less potential to be right (a sequence
of the same tag will be translated into one slot
value, turning several opportunities to be right into
15
only one).
The incremental dynamics looks quite different
here. Since the task is not one of prediction, we
do not expect to get better with more information;
rather, we start at an optimal point (when nothing
is said, nothing can be wrong), and hope that we
do not amass too many errors along the way. Fig-
ure 3 confirms this, showing that the classifier is
better able to keep the quality for the pento data
than for the ATIS data. Also, there is not much
variation depending on the length of the utterance.
6 Conclusions
We have shown how sequential and local statistical
models can be used for two variants of the incre-
mental NLU task: prediction, based on incomplete
information, and assignment of partial representa-
tions to partial input. We have shown that break-
ing up the prediction task by using an ensemble
of classifiers improves performance, and creates a
hybrid task that sits between prediction and incre-
mental interpretation.
While the objective quality as measured by our
metrics is quite good, what remains to be shown is
how such models can be integrated into a dialogue
system, and how what they offer can be turned into
improvements on interactivity. This is what we are
turning to next.
Acknowledgements Funded by ENP grant from DFG.
References
G.S. Aist, J. Allen, E. Campana, L. Galescu, C.A.
Gomez Gallo, S. Stoness, M. Swift, and M Tanenhaus.
2006. Software architectures for incremental understand-
ing of human speech. In Proceedings of the Interna-
tional Conference on Spoken Language Processing (IC-
SLP), Pittsburgh, PA, USA, September.
James Allen, George Ferguson, and Amanda Stent. 2001.
An architecture for more realistic conversational systems.
In Proceedings of the conference on intelligent user inter-
faces, Santa Fe, USA, June.
Michaela Atterer and David Schlangen. 2009. RUBISC ?
a robust unification-based incremental semantic chunker.
In Proceedings of the 2nd International Workshop on Se-
mantic Representation of Spoken Language (SRSL 2009),
Athens, Greece, March.
Michaela Atterer, Timo Baumann, and David Schlangen.
2009. No sooner said than done? testing incrementality of
semantic interpretations of spontaneous speech. In Pro-
ceedings of Interspeech 2009, Brighton, UK, September.
Deborah A. Dahl, Madeleine Bates, Michael Brown, William
Fisher, Kate Hunicke-Smith, David Pallett, Christine Pao,
Alexander Rudnicky, and Elizabeth Shriberg. 1994. Ex-
panding the scope of the atis task: the atis-3 corpus. In
Proceedings of the workshop on Human Language Tech-
nology, pages 43?48, Plainsboro, NJ, USA.
David DeVault, Kenji Sagae, and David Traum. 2009. Can
i finish? learning when to respond to incremental inter-
pretation results in interactive dialogue. In Proceedings
of the 10th Annual SIGDIAL Meeting on Discourse and
Dialogue (SIGDIAL?09), London, UK, September.
Raquel Ferna?ndez and David Schlangen. 2007. Referring
under restricted interactivity conditions. In Simon Keizer,
Harry Bunt, and Tim Paek, editors, Proceedings of the
8th SIGdial Workshop on Discourse and Dialogue, pages
136?139, Antwerp, Belgium, September.
Yulan He and Steve Young. 2005. Semantic processing us-
ing the hidden vector state model. Computer Speech and
Language, 19(1):85?106.
J. Lafferty, A. McCallum, and F. Pereira. 2001. Conditional
random fields: Probabilistic models for segmenting and
labeling sequence data. In Proc. of ICML, pages 282?289.
F. Mairesse, M. Gasic, F. Jurcicek, S. Keizer, B. Thomson,
K. Yu, and S. Young. 2009. Spoken language understand-
ing from unaligned data using discriminative classification
models. In Proceedings of the 2009 IEEE International
Conference on Acoustics, Speech and Signal Processing,
Taipei, Taiwan, April.
Ivan Meza, Sebastian Riedel, and Oliver Lemon. 2008. Ac-
curate statistical spoken language understanding from lim-
ited development resources. In In Proceedings of ICASSP.
David Milward and Robin Cooper. 1994. Incremental in-
terpretation: Applications, theory, and relationships to dy-
namic semantics. In Proceedings of COLING 1994, pages
748?754, Kyoto, Japan, August.
Brian Roark. 2001. Robust Probabilistic Predictive Syntac-
tic Processing: Motivations, Models, and Applications.
Ph.D. thesis, Department of Cognitive and Linguistic Sci-
ences, Brown University.
Kenji Sagae, Gwen Christian, David DeVault, and David
Traum. 2009. Towards natural language understand-
ing of partial speech recognition results in dialogue sys-
tems. In Short paper proceedings of the North Ameri-
can chapter of the Association for Computational Linguis-
tics - Human Language Technologies conference (NAACL-
HLT?09), Boulder, Colorado, USA, June.
David Schlangen and Gabriel Skantze. 2009. A general, ab-
stract model of incremental dialogue processing. In Pro-
ceedings of the 12th Conference of the European Chapter
of the Association for Computational Linguistics (EACL
2009), pages 710?718, Athens, Greece, March.
David Schlangen, Timo Baumann, and Michaela Atterer.
2009. Incremental reference resolution: The task, met-
rics for evaluation, and a bayesian filtering model that is
sensitive to disfluencies. In Proceedings of SIGdial 2009,
the 10th Annual SIGDIAL Meeting on Discourse and Di-
alogue, London, UK, September.
Gabriel Skantze and David Schlangen. 2009. Incremental
dialogue processing in a micro-domain. In Proceedings
of the 12th Conference of the European Chapter of the
Association for Computational Linguistics (EACL 2009),
pages 745?753, Athens, Greece, March.
Andreas Stolcke. 1995. An efficient probabilistic context-
free parsing algorithm that computes prefix probabilities.
Computational Linguistics, 21(2):165?201.
Ian H. Witten and Eibe Frank. 2005. Data Mining: Practi-
cal machine learning tools and techniques. Morgan Kauf-
mann, San Francisco, USA, 2nd edition.
Luke S. Zettlemoyer and Michael Collins. 2007. Online
learning of relaxed ccg grammars for parsing to logical
form. In Proceedings of EMNLP-CoNLL.
16
Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 51?54,
The University of Tokyo, September 24-25, 2010. c?2010 Association for Computational Linguistics
Middleware for Incremental Processing in Conversational Agents
David Schlangen?, Timo Baumann?, Hendrik Buschmeier?, Okko Bu??
Stefan Kopp?, Gabriel Skantze?, Ramin Yaghoubzadeh?
?University of Potsdam ?Bielefeld University ?KTH, Stockholm
Germany Germany Sweden
david.schlangen@uni-potsdam.de
Abstract
We describe work done at three sites on
designing conversational agents capable of
incremental processing. We focus on the
?middleware? layer in these systems, which
takes care of passing around and maintain-
ing incremental information between the
modules of such agents. All implementa-
tions are based on the abstract model of
incremental dialogue processing proposed
by Schlangen and Skantze (2009), and the
paper shows what different instantiations
of the model can look like given specific
requirements and application areas.
1 Introduction
Schlangen and Skantze (2009) recently proposed
an abstract model of incremental dialogue process-
ing. While this model introduces useful concepts
(briefly reviewed in the next section), it does not
talk about how to actually implement such sys-
tems. We report here work done at three different
sites on setting up conversational agents capable
of incremental processing, inspired by the abstract
model. More specifically, we discuss what may
be called the ?middleware? layer in such systems,
which takes care of passing around and maintaining
incremental information between the modules of
such agents. The three approaches illustrate a range
of choices available in the implementation of such
a middle layer. We will make our software avail-
able as development kits in the hope of fostering
further research on incremental systems.1
In the next section, we briefly review the abstract
model. We then describe the implementations cre-
ated at Uni Bielefeld (BF), KTH Stockholm (KTH)
and Uni Potsdam (UP). We close with a brief dis-
cussion of similarities and differences, and an out-
look on further work.
1Links to the three packages described here can be found
at http://purl.org/net/Middlewares-SIGdial2010.
2 The IU-Model of Incremental Processing
Schlangen and Skantze (2009) model incremental
systems as consisting of a network of processing
modules. Each module has a left buffer, a proces-
sor, and a right buffer, where the normal mode of
processing is to take input from the left buffer, pro-
cess it, and provide output in the right buffer, from
where it goes to the next module?s left buffer. (Top-
down, expectation-based processing would work
in the opposite direction.) Modules exchange incre-
mental units (IUs), which are the smallest ?chunks?
of information that can trigger connected modules
into action. IUs typically are part of larger units;
e.g., individual words as parts of an utterance, or
frame elements as part of the representation of an
utterance meaning. This relation of being part of
the same larger unit is recorded through same level
links; the information that was used in creating a
given IU is linked to it via grounded in links. Mod-
ules have to be able to react to three basic situa-
tions: that IUs are added to a buffer, which triggers
processing; that IUs that were erroneously hypothe-
sised by an earlier module are revoked, which may
trigger a revision of a module?s own output; and
that modules signal that they commit to an IU, that
is, won?t revoke it anymore (or, respectively, expect
it to not be revoked anymore).
Implementations of this model then have to re-
alise the actual details of this information flow, and
must make available the basic module operations.
3 Sociable Agents Architecture
BF?s implementation is based on the ?D-Bus? mes-
sage bus system (Pennington et al, 2007), which
is used for remote procedure calls and the bi-
directional synchronisation of IUs, either locally
between processes or over the network. The bus sys-
tem provides proxies, which make the interface of
a local object accessible remotely without copying
data, thus ensuring that any access is guaranteed to
yield up-to-date information. D-Bus bindings exist
for most major programming languages, allowing
51
for interoperability across various systems.
IUs exist as objects implementing a D-Bus in-
terface, and are made available to other modules
by publishing them on the bus. Modules are ob-
jects comprising a main thread and right and left
buffers for holding own IUs and foreign IU proxies,
respectively. Modules can co-exist in one process
as threads or occupy one process each?even dis-
tributed across a network.
A dedicated Relay D-Bus object on the network
is responsible for module administration and up-
date notifications. At connection time, modules
register with the relay, providing a list of IU cat-
egories and/or module names they are interested
in. Category interests create loose functional links
while module interests produce more static ones.
Whenever a module chooses to publish informa-
tion, it places a new IU in its right buffer, while
removal of an IU from the right buffer corresponds
to retraction. The relay is notified of such changes
and in turn invokes a notification callback in all
interested modules synchronising their left buffers
by immediately and transparently creating or re-
moving proxies of those IUs.
IUs consist of the fields described in the abstract
model, and an additional category field which the
relay can use to identify the set of interested mod-
ules to notify. They furthermore feature an optional
custom lifetime, on the expiration of which they
are automatically retracted.
Incremental changes to IUs are simply realised
by changing their attributes: regardless of their lo-
cation in either a right or left buffer, the same setter
functions apply (e.g., set payload). These generate
relay-transported update messages which commu-
nicate the ID of the changed IU. Received update
messages concerning self-owned and remotely-
owned objects are discerned automatically to allow
for special treatment of own IUs. The complete
process is illustrated in Figure 1.
Current state and discussion. Our support for
bi-directional IU editing is an extension to the con-
cepts of the general model. It allows higher-level
modules with a better knowledge of context to re-
vise uncertain information offered by lower levels.
Information can flow both ways, bottom-up and
top-down, thus allowing for diagnostic and causal
networks linked through category interests.
Coming from the field of embodied conversa-
tional agents, and being especially interested in
modelling human-like communication, for exam-
A B
C
IU
IU proxy
Write access
Relay
Data access
Update notification
RBuf LBuf
Interest sets
Figure 1: Data access on the IU proxies is transparently dele-
gated over the D-Bus; module A has published an IU. B and C
are registered in the corresponding interest set, thus receiving
a proxy of this IU in their left buffer. When B changes the IU,
A and C receive update notifications.
ple for on-line production of listener backchannel
feedback, we constantly have to take incremen-
tally changing uncertain input into account. Using
the presented framework consistently as a network
communication layer, we are currently modelling
an entire cognitive architecture for virtual agents,
based on the principle of incremental processing.
The decision for D-Bus as the transportation
layer has enabled us to quickly develop ver-
sions for Python, C++ and Java, and produced
straightforward-to-use libraries for the creation of
IU-exchanging modules: the simplest fully-fledged
module might only consist of a periodically in-
voked main loop callback function and any subset
of the four handlers for IU events (added, removed,
updated, committed).
4 Inpro Toolkit
The InproTK developed at UP offers flexibility on
how tightly or loosely modules are coupled in a
system. It provides mechanisms for sending IU up-
dates between processes via a messaging protocol
(we have used OAA [Cheyer and Martin, 2001], but
other communication layers could also be used) as
well as for using shared memory within one (Java)
process. InproTK follows an event-based model,
where modules create events, for which other mod-
ules can register as Listeners. Module networks are
configured via a system configuration file which
specifies which modules listen to which.
Modules push information to their right, hence
the interface for inter-module communication is
called PushBuffer. (At the moment, InproTK only
implements left-to-right IU flow.) The PushBuffer
interface defines a hypothesis-change method
which a module will call for all its listening mod-
ules. A hypothesis change is (redundantly) charac-
terised by passing both the complete current buffer
state (a list of IUs) as well as the delta between
52
the previous and the current state, leaving listen-
ing modules a choice of how to implement their
internal update.
Modules can be fully event-driven, only trig-
gered into action by being notified of a hypothesis
change, or they can run persistently, in order to cre-
ate endogenous events like time-outs. Event-driven
modules can run concurrently in separate threads or
can be called sequentially by a push buffer (which
may seem to run counter the spirit of incremental
processing, but can be advantageous for very quick
computations for which the overhead of creating
threads should be avoided).
IUs are typed objects, where the base class IU
specifies the links (same-level, grounded-in) that
allow to create the IU network and handles the
assignment of unique IDs. The payload and addi-
tional properties of an IU are specified for the IU?s
type. A design principle here is to make all relevant
information available, while avoiding replication.
For instance, an IU holding a bit of semantic rep-
resentation can query which interval of input data
it is based on, where this information is retrieved
from the appropriate IUs by automatically follow-
ing the grounded-in links. IU networks ground out
in BaseData, which contains user-side input such
as speech from the microphone, derived ASR fea-
ture vectors, camera feeds from a webcam, derived
gaze information, etc., in several streams that can
be accessed based on their timing information.
Besides IU communication as described in the
abstract model, the toolkit also provides a separate
communication track along which signals, which
are any kind of information that is not seen as incre-
mental hypotheses about a larger whole but as infor-
mation about a single current event, can be passed
between modules. This communication track also
follows the observer/listener model, where proces-
sors define interfaces that listeners can implement.
Finally, InproTK also comes with an extensive
set of monitoring and profiling modules which can
be linked into the module network at any point and
allow to stream data to disk or to visualise it online
through a viewing tool (ANON 2009), as well as
different ways to simulate input (e.g., typed or read
from a file) for bulk testing.
Current state and discussion. InproTK is cur-
rently used in our development of an incremental
multimodal conversational system. It is usable in its
current state, but still evolves. We have built and in-
tegrated modules for various tasks (post-processing
of ASR output, symbolic and statistical natural lan-
guage understanding [ANON 2009a,b,c]). The con-
figuration system and the availability of monitoring
and visualisation tools enables us to quickly test
different setups and compare different implementa-
tions of the same tasks.
5 Jindigo
Jindigo is a Java-based framework for implement-
ing and experimenting with incremental dialogue
systems currently being developed at KTH. In
Jindigo, all modules run as separate threads within
a single Java process (although the modules them-
selves may of course communicate with external
processes). Similarly to InproTK, IUs are mod-
elled as typed objects. The modules in the system
are also typed objects, but buffers are not. Instead,
a buffer can be regarded as a set of IUs that are
connected by (typed) same-level links. Since all
modules have access to the same memory space,
they can follow the same-level links to examine
(and possibly alter) the buffer. Update messages
between modules are relayed based on a system
specification that defines which types of update
messages from a specific module go where. Since
the modules run asynchronously, update messages
do not directly invoke methods in other modules,
but are put on the input queues of the receiving
modules. The update messages are then processed
by each module in their own thread.
Jindigo implements a model for updating buffers
that is slightly different than the two previous ap-
proaches. In this approach, IUs are connected by
predecessor links, which gives each IU (words,
widest spanning phrases from the parser, commu-
nicative acts, etc), a position in a (chronologically)
ordered stream. Positional information is reified by
super-imposing a network of position nodes over
the IU network, with the IUs being associated with
edges in that network. These positional nodes then
give us names for certain update stages, and so
revisions can be efficiently encoded by reference
to these nodes. An example can make this clearer.
Figure 2 shows five update steps in the right buffer
of an incremental ASR module. By reference to po-
sitional nodes, we can communicate easily (a) what
the newest committed IU is (indicated in the figure
as a shaded node) and (b) what the newest non-
revoked or active IU is (i.e., the ?right edge? (RE);
indicated in the figure as a node with a dashed line).
So, the change between the state at time t1 and t2
is signalled by RE taking on a different value. This
53
Figure 2: The right buffer of an ASR module, and update
messages at different time-steps.
value (w3) has not been seen before, and so the
consuming module can infer that the network has
been extended; it can find out which IUs have been
added by going back from the new RE to the last
previously seen position (in this case, w2). At t3, a
retraction of a hypothesis is signalled by a return to
a previous state, w2. All consuming modules have
to do now is to return to an internal state linked
to this previous input state. Commitment is repre-
sented similarly through a pointer to the rightmost
committed node; in the figure, that is for example
w5 at t5.
Since information about whether an IU has been
revoked or committed is not stored in the IU it-
self, all IUs can (if desirable) be defined as im-
mutable objects. This way, the pitfalls of having
asynchronous processes altering and accessing the
state of the IUs may be avoided (while, however,
more new IUs have to be created, as compared to
altering old ones). Note also that this model sup-
ports parallel hypotheses as well, in which case the
positional network would turn into a lattice.
The framework supports different types of up-
date messages and buffers. For example, a parser
may incrementally send NPs to a reference reso-
lution (RR) module that has access to a domain
model, in order to prune the chart. Thus, informa-
tion may go both left-to-right and right-to-left. In
the buffer between these modules, the order be-
tween the NPs that are to be annotated is not im-
portant and there is no point in revoking such IUs
(since they do not affect the RR module?s state).
Current state and discussion. Jindigo uses con-
cepts from (Skantze, 2007), but has been rebuilt
from ground up to support incrementality. A range
of modules for ASR, semantic interpretation, TTS,
monitoring, etc., have been implemented within
the framework, allowing us to do experiments
with complete systems interacting with users. We
are currently using the framework to implement a
model of incremental speech production.
6 Discussion
The three implementations of the abstract IU model
presented above show that concrete requirements
and application areas result in different design de-
cisions and focal points.
While BF?s approach is loosely coupled and han-
dles exchange of IUs via shared objects and a me-
diating module, KTH?s implementation is rather
closely coupled and publishes IUs through a single
buffer that lies in shared memory. UP?s approach
is somewhat in between: it abstracts away from the
transportation layer and enables message passing-
based communication as well as shared memory
transparently through one interface.
The differences in the underlying module com-
munication infrastructure affect the way incremen-
tal IU updates are handled in the systems. In BF?s
framework modules holding an IU in one of their
buffers just get notified when one of the IU?s fields
changed. Conversely, KTH?s IUs are immutable
and new information always results in new IUs
being published and a change to the graph repre-
sentation of the buffer?but this allows an efficient
coupling of module states and cheap revoke op-
erations. Again, UP?s implementation lies in the
middle. Here both the whole new state and the delta
between the old and new buffer is communicated,
which leads to flexibility in how consumers can be
implemented, but also potentially to some commu-
nication overhead.
In future work, we will explore if further gener-
alisations can be extracted from the different im-
plementations presented here. For now, we hope
that the reference architectures presented here can
already be an inspiration for further work on incre-
mental conversational systems.
References
Adam Cheyer and David Martin. 2001. The open
agent architecture. Journal of Autonomous Agents
and Multi-Agent Systems, 4(1):143?148, March.
H. Pennington, A. Carlsson, and A. Larsson. 2007.
D-Bus Specification Version 0.12. http://dbus.free-
desktop.org/doc/dbus-specification.html.
David Schlangen and Gabriel Skantze. 2009. A Gen-
eral, Abstract Model of Incremental Dialogue Pro-
cessing. In Proceedings of EACL 2009, Athens,
Greece.
Gabriel Skantze. 2007. Error Handling in Spoken Dia-
logue Systems. Ph.D. thesis, KTH, Stockholm, Swe-
den, November.
54
Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 233?236,
The University of Tokyo, September 24-25, 2010. c?2010 Association for Computational Linguistics
Collaborating on Utterances with a Spoken Dialogue System
Using an ISU-based Approach to Incremental Dialogue Management
Okko Bu?, Timo Baumann, David Schlangen
Department of Linguistics
University of Potsdam, Germany
{okko|timo|das}@ling.uni-potsdam.de
Abstract
When dialogue systems, through the
use of incremental processing, are
not bounded anymore by strict, non-
overlapping turn-taking, a whole range of
additional interactional devices becomes
available. We explore the use of one such
device, trial intonation. We elaborate
our approach to dialogue management
in incremental systems, based on the
Information-State-Update approach, and
discuss an implementation in a micro-
domain that lends itself to the use of
immediate feedback, trial intonations and
expansions. In an overhearer evaluation,
the incremental system was judged as sig-
nificantly more human-like and reactive
than a non-incremental version.
1 Introduction
In human?human dialogue, most utterances have
only one speaker.1 However, the shape that an
utterance ultimately takes on is often determined
not just by the one speaker, but also by her ad-
dressees. A speaker intending to refer to some-
thing may start with a description, monitor while
they go on whether the description appears to be
understood sufficiently well, and if not, possibly
extend it, rather than finishing the utterance in the
form that was initially planned. This monitoring
within the utterance is sometimes even made very
explicit, as in the following example from (Clark,
1996):
(1) A: A man called Annegra? -
B: yeah, Allegra
A: Allegra, uh, replied and, uh, . . .
In this example, A makes use of what Sacks and
Schegloff (1979) called a try marker, a ?question-
ing upward intonational contour, followed by a
1Though by far not all; see (Clark, 1996; Purver et al,
2009; Poesio and Rieser, 2010).
brief pause?. As discussed by Clark (1996), this
device is an efficient solution to the problem posed
by uncertainty on the side of the speaker whether
a reference is going to be understood, as it checks
for understanding in situ, and lets the conversation
partners collaborate on the utterance that is in pro-
duction.
Spoken dialogue systems (SDS) typically can-
not achieve the close coupling between produc-
tion and interpretation that is needed for this to
work, as normally the smallest unit on which they
operate is the full utterance (or, more precisely,
the turn). (For a discussion see e.g. (Skantze and
Schlangen, 2009).) We present here an approach
to managing dialogue in an incremental SDS that
can handle this phenomenon, explaining how it is
implemented in system (Section 4) that works in
a micro-domain (which is described in Section 3).
As we will discuss in the next section, this goes be-
yond earlier work on incremental SDS, combining
the production of multimodal feedback (as in (Aist
et al, 2007)) with fast interaction in a semantically
more complex domain (compared to (Skantze and
Schlangen, 2009)).
2 Related Work
Collaboration on utterances has not often been
modelled in SDS, as it presupposes fully incre-
mental processing, which itself is still something
of a rarity in such systems. (There is work on
collaborative reference (DeVault et al, 2005; Hee-
man and Hirst, 1995), but that focuses on written
input, and on collaboration over several utterances
and not within utterances.) There are two systems
that are directly relevant here.
The system described in (Aist et al, 2007) is
able to produce some of the phenomena that we
are interested in here. The set-up is a simple
reference game (as we will see, the domain we
have chosen is very similar), where users can re-
fer to objects shown on the screen, and the SDS
gives continuous feedback about its understand-
233
ing by performing on-screen actions. While we
do produce similar non-linguistic behaviour in our
system, we also go beyond this by producing
verbal feedback that responds to the certainty of
the speaker (expressed by the use of trial intona-
tion). Unfortunately, very little technical details
are given in that paper, so that we cannot compare
the approaches more fully.
Even more closely related is some of our own
previous work, (Skantze and Schlangen, 2009),
where we modeled fast system reactions to deliv-
ery of information in installments in a number se-
quence dictation domain. In a small corpus study,
we found a very pronounced use of trial or in-
stallment intonations, with the first installments of
numbers being bounded by rising intonation, and
the final installment of a sequence by falling into-
nation. We made use of this fact by letting the sys-
tem distinguish these situations based on prosody,
and giving it different reaction possibilities (back-
channel feedback vs. explicit confirmation).
The work reported here is a direct scaling up of
that work. For number sequences, the notion of
utterance is somewhat vague, as there are no syn-
tactic constraints that help demarcate its bound-
aries. Moreover, there is no semantics (beyond
the individual number) that could pose problems
? the main problem for the speaker in that do-
main is ensuring that the signal is correctly identi-
fied (as in, the string could be written down), and
the trial intonation is meant to provide opportuni-
ties for grounding whether that is the fact. Here,
we want to go beyond that and look at utterances
where it is the intended meaning whose recogni-
tion the speaker is unsure about (grounding at level
3 rather than (just) at level 2 in terms of (Clark,
1996).) This difference leads to differences in the
follow up potential: where in the numbers domain,
typical repair follow-ups were repetitions, in se-
mantically more complex domains we can expect
expansions or reformulations.
3 The Puzzle Micro-Domain
To investigate these issues in a controlled set-
ting, we chose a domain that makes complex and
possibly underspecified references likely, and that
also allows a combination of linguistic and non-
linguistic feedback. In this domain, the user?s goal
is to instruct the system to pick up and manipu-
late Tetris-like puzzle pieces, which are shown on
the screen. We recorded human?human as well
as human?(simulated) machine interactions in this
domain, and indeed found frequent use of ?pack-
aging? of instructions, and immediate feedback, as
in (2) (arrow indicating intonation).
(2) IG-1: The cross in the corner? ...
IF-2: erm
IG-3: the red one .. yeah
IF-4: [moves cursor]
IG-5: take that.
We chose these as our target phenomena for the
implementation: intra-utterance hesitations, possi-
bly with trial intonation (as in line 2);2 immediate
execution of actions (line 4), and their grounding
role as display of understanding (?yeah? in line 3).
The system controls the mouse cursor, e.g. moving
it over pieces once it has a good hypothesis about
a reference; other actions are visualised similarly.
4 Implementation
4.1 Overview
Our system is realised as a collection of incre-
mental processing modules in the InproToolKit
(Schlangen et al, 2010), a middle-ware pack-
age that implements some of the features of the
model of incremental processing of (Schlangen
and Skantze, 2009). The modules used in the im-
plementation will be described briefly below.
4.2 ASR, Prosody, Floor Tracker & NLU
For speech recognition, we use Sphinx-4 (Walker
et al, 2004), with our own extensions for incre-
mental speech recognition (Baumann et al, 2009),
and our own domain-specific acoustic model. For
the experiments described here, we used a recog-
nition grammar.
Another module performs online prosodic anal-
ysis, based on pitch change, which is measured in
semi-tone per second over the turn-final word, us-
ing a modified YIN (de Cheveigne? and Kawahara,
2002). Based on the slope of the f0 curve, we clas-
sify pitch as rising or falling.
This information is used by the floor track-
ing module, which notifies the dialogue manager
(DM) about changes in floor status. These sta-
tus changes are classified by simple rules: silence
following rising pitch leads to a timeout signal
2Although we chose to label this ?intra-utterance? here,
it doesn?t matter much for our approach whether one consid-
ers this example to consist of one or several utterances; what
matters is that differences in intonation and pragmatic com-
pleteness have an effect.
234
{< a ( 1 action=A=take; 2 prepare(A) ; 3 U),
( 4 tile=T ; 5 highlight(T) ; 6 U),
( 7 ; 8 execute(A,T) ; 9 U) >
< b (10 action=A=del ;11 prepare(A) ;12 U),
(13 tile=T ;14 highlight(T) ;15 U),
(16 ;17 execute(A,T) ;18 U) >}
Figure 1: Example iQUD
sent to the DM faster (200ms) than silence after
falling pitch (500ms). (Comparable to the rules in
(Skantze and Schlangen, 2009).)
Natural language understanding finally is per-
formed by a unification-based semantic composer,
which builds simple semantic representations out
of the lexical entries for the recognised words; and
a resolver, which matches these representations
against knowledge of the objects in the domain.
4.3 Dialogue Manager and Action Manager
The DM reacts to input from three sides: semantic
material coming from the NLU, floor state signals
from the floor tracker, and notifications about exe-
cution of actions from the action manager.
The central element of the information state
used in the dialogue manager is what we call the
iQUD (for incremental Question under Discus-
sion, as it?s a variant of the QUD of (Ginzburg,
1996)). Figure 1 gives an example. The iQUD
collects all relevant sub-questions into one struc-
ture, which also records what the relevant non-
linguistic actions are (RNLAs; more on this in a
second, but see also (Bu? and Schlangen, 2010),
where we?ve sketched this approach before), and
what the grounding status is of that sub-question.
Let?s go through example (2). The iQUD in
Figure 1 represents the state after the system has
asked ?what shall I do now??. The system an-
ticipates two alternative replies, a take request, or
a delete request; this is what the specification of
the slot value in 1 and 10 in the iQUD indicates.
Now the user starts to speak and produces what is
shown in line 1 in the example. The floor tracker
reacts to the rising pitch and to the silence of ap-
propriate length, and notifies the dialogue man-
ager. In the meantime, the DM has received up-
dates from the NLU module, has checked for each
update whether it is relevant to a sub-question on
the iQUD, and if so, whether it resolves it. In this
situation, the material was relevant to both 4 and
13, but did not resolve it. This is a precondition for
the continuer-questioning rule, which is triggered
by the signal from the floor tracker. The system
then back-channels as in the example, indicating
acoustic understanding (Clark?s level 2), but fail-
ure to operate on the understanding (level 3). (As
an aside, we found that it is far from trivial to find
the right wording for this prompt. We settled on
an ?erm? with level pitch.)
The user then indeed produces more material,
which together with the previously given informa-
tion resolves the question. This is where the RN-
LAs come in: when a sub-question is resolved, the
DM looks into the field for RNLAs, and if there
are any, puts them up for execution to the action
manager. In our case, slots 4 and 13 are both
applicable, but as they have compatible RNLAs,
this does not cause a conflict. When the action
has been performed, a new question is accommo-
dated (not shown here), which can be paraphrased
as ?was the understanding displayed through this
action correct??. This is what allows the user reply
in line 3 to be integrated, which otherwise would
need to be ignored, or even worse, would confuse
a dialogue system. A relevant continuation, on the
other hand, would also have resolved the question.
We consider this modelling of grounding effects
of actions an important feature of our approach.
Similar rules handle other floor tracker events;
not elaborated here for reasons of space. In
our current prototype the rules are hard-coded,
but we are preparing a version where rules and
information-states can be specified externally and
are read in by a rule-engine.
4.4 Overhearer Evaluation
Evaluating the contribution of one of the many
modules in an SDS is notoriously difficult (Walker
et al, 1998). To be able to focus on evaluation of
the incremental dialogue strategies and avoid in-
terference from ASR problems (and more techni-
cal problems; our system is still somewhat frag-
ile), we opted for an overhearer evaluation. (Such
a setting was also used for the test of the incremen-
tal system of (Aist et al, 2007).)
We implemented a non-incremental version of
the system that does not give non-linguistic feed-
back during user utterances and has only one,
fixed, timeout of 800ms (comparable to typical
settings in commercial dialogue systems). Two
of the authors then recorded 30 minutes of inter-
actions with the two versions of the system.We
then identified and discarded ?outlier? interac-
tions, i.e. those with technical problems, or where
235
recognition problems were so severe that a non-
understanding state was entered repeatedly. These
criteria were meant to be fair to both versions
of the system, and indeed we excluded similar
numbers of failed interactions from both versions
(around 10% of interactions in total).
We measured the length of interactions in the
two sets, and found that the interactions in the in-
cremental setting were significantly shorter (t-test,
p< 0.005). This was to be expected, of course,
as the incremental strategies allow faster reactions
(execution time can be folded into the user utter-
ance); other outcomes would have been possible,
though, if the incremental version had systemati-
cally more understanding problems.
We then had 8 subjects (university students,
not involved in the research) watch and directly
judge (questionnaire, Likert-scale replies to ques-
tions about human-likeness, helpfulness, and re-
activity) 34 randomly selected interactions from
either condition. Human-likeness and reactivity
were judged significantly higher for the incremen-
tal version (Wilcoxon rank-sum test; p< 0.05 and
p< 0.005, respectively), while there was no effect
for helpfulness (p= 0.06).
5 Conclusions
We described our incremental micro-domain dia-
logue system, which is capable of reacting to sub-
tle signals from the user about expected feedback,
and is able to produce overlapping non-linguistic
actions, modelling their effect as displays of un-
derstanding. Interactions with the system were
judged by overhearers to be more human-like and
reactive than with a non-incremental variant. We
are currently working on extending and generalis-
ing our approach to incremental dialogue manage-
ment, porting it to other domains.
Acknowledgments Funded by an ENP grant from DFG.
References
Gregory Aist, James Allen, Ellen Campana, Car-
los Gomez Gallo, Scott Stoness, Mary Swift, and
Michael K. Tanenhaus. 2007. Incremental under-
standing in human-computer dialogue and experi-
mental evidence for advantages over nonincremen-
tal methods. In Proceedings of Decalog (Semdial
2007), Trento, Italy.
Timo Baumann, Michaela Atterer, and David
Schlangen. 2009. Assessing and Improving the
Performance of Speech Recognition for Incremental
Systems. In Proceedings of NAACL-HLT 2009,
Boulder, USA.
Okko Bu? and David Schlangen. 2010. Modelling
sub-utterance phenomena in spoken dialogue sys-
tems. In Proceedings of Semdial 2010 (?Pozdial?),
pages 33?41, Poznan, Poland, June.
Herbert H. Clark. 1996. Using Language. Cambridge
University Press, Cambridge.
Alain de Cheveigne? and Hideki Kawahara. 2002. YIN,
a fundamental frequency estimator for speech and
music. Journal of the Acoustical Society of America,
111(4):1917?1930.
David DeVault, Natalia Kariaeva, Anubha Kothari, Iris
Oved, and Matthew Stone. 2005. An information-
state approach to collaborative reference. In Short
Papers, ACL 2005, Michigan, USA, June.
Jonathan Ginzburg. 1996. Interrogatives: Ques-
tions, facts and dialogue. In Shalom Lappin, editor,
The Handbook of Contemporary Semantic Theory.
Blackwell, Oxford.
Peter A. Heeman and Graeme Hirst. 1995. Collabo-
rating on referring expressions. Computational Lin-
guistics, 21(3):351?382.
Massimo Poesio and Hannes Rieser. 2010. Comple-
tions, coordination, and alignment in dialogue. Dia-
logue and Discourse, 1(1):1?89.
Matthew Purver, Christine Howes, Eleni Gre-
goromichelaki, and Patrick Healey. 2009. Split
utterances in dialogue: a corpus study. In Proceed-
ings of the SIGDIAL 2009, pages 262?271, London,
UK, September.
Harvey Sacks and Emanuel A. Schegloff. 1979. Two
preferences in the organization of reference to per-
sons in conversation and their interaction. In George
Psathas, editor, Everyday Language: Studies in Eth-
nomethodology, pages 15?21. Irvington Publishers,
Inc., New York, NY, USA.
David Schlangen and Gabriel Skantze. 2009. A gen-
eral, abstract model of incremental dialogue pro-
cessing. In Proceedings of EACL 2009, pages 710?
718, Athens, Greece, March.
David Schlangen, Timo Baumann, Hendrik
Buschmeier, Okko Bu?, Stefan Kopp, Gabriel
Skantze, and Ramin Yaghoubzadeh. 2010. Middle-
ware for incremental processing in conversational
agents. In Proceedings of SIGDIAL 2010, Tokyo,
Japan.
Gabriel Skantze and David Schlangen. 2009. Incre-
mental dialogue processing in a micro-domain. In
Proceedings of EACL 2009, pages 745?753, Athens,
Greece, March.
Marilyn A. Walker, Diane J. Litman, Candace A.
Kamm, and Alicia Abella. 1998. Evaluating spoken
dialogue agents with PARADISE: Two case studies.
Computer Speech and Language, 12(3).
Willie Walker, Paul Lamere, Philip Kwok, Bhiksha
Raj, Rita Singh, Evandro Gouvea, Peter Wolf, and
Joe Woelfel. 2004. Sphinx-4: A flexible open
source framework for speech recognition. Techni-
cal report, Sun Microsystems Inc.
236
Proceedings of the SIGDIAL 2011: the 12th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 120?129,
Portland, Oregon, June 17-18, 2011. c?2011 Association for Computational Linguistics
Predicting the Micro-Timing of User Input for an Incremental
Spoken Dialogue System that Completes a User?s Ongoing Turn
Timo Baumann
Department of Linguistics
Potsdam University
Germany
timo@ling.uni-potsdam.de
David Schlangen
Faculty of Linguistics and Literature
Bielefeld University
Germany
david.schlangen@uni-bielefeld.de
Abstract
We present the novel task of predicting tem-
poral features of continuations of user input,
while that input is still ongoing. We show that
the remaining duration of an ongoing word, as
well as the duration of the next can be predicted
reasonably well, and we put this information to
use in a system that synchronously completes
a user?s speech. While we focus on collabo-
rative completions, the techniques presented
here may also be useful for the alignment of
back-channels and immediate turn-taking in an
incremental SDS, or to synchronously monitor
the user?s speech fluency for other reasons.
1 Introduction
Turn completion, that is, finishing a user?s ongoing ut-
terance, can be considered an ideal test-case of incre-
mental spoken language processing, as it requires that
all levels of language understanding and production
are carried out in real time, without any noticeable
lags and with proper timing and even with the ability
to predict what will come. Spoken dialogue systems,
especially incremental ones, have come a long way
towards reducing lags at turn changes (e. g. (Raux and
Eskenazi, 2009; Skantze and Schlangen, 2009)), or
even predicting upcoming turn changes (Schlangen,
2006; Baumann, 2008; Ward et al, 2010). Com-
pared to regular turn changes, where short pauses or
overlaps occur frequently (Weilhammer and Rabold,
2003), turn completions in natural dialogues are typ-
ically precisely aligned and prosodically highly in-
tegrated with the turn that is being completed (Lo-
cal, 2007). With ever more incremental (and hence
quicker) spoken dialogue systems, the phenomenon
of completion comes into reach for SDSs, and hence
questions of micro-timing become important.
While completing someone else?s turn ? especially
for a computer ? may be considered impolite or even
annoying, being able to do so can be a useful capa-
bility. Some tasks where it might be helpful are
? negotiation training to induce stress in a human
trainee as presented by DeVault et al (2009), or
? pronunciation aids for language learners, in
which hard to pronounce words could be spoken
simultaneously by the system.
A system should certainly not try to complete all
or even many user turns, but having the capability
to do so means that the system has a very efficient
interactional device at its disposal.
Furthermore, monitoring the user?s timing, as is
required for the temporal prediction of turn continua-
tions, can also be used for other conversational tasks
such as producing back-channels that are precisely
aligned to the user?s back-channel inviting cues, to
enable micro-alignment of turn-onsets, or to quickly
react to deviations in the user?s fluency.
In this paper, we concentrate on the temporal as-
pects of turn completion, that is, the prediction of
the precise temporal alignment of a turn continuation
and the technical realization of this timing. We as-
sume the task of predicting the completion itself to
be handled by some other system component. Such
components are indeed under development (see Sec-
tion 2). However, previous work has left out the
question of how the precise timing of turn comple-
tions can be accomplished, which is what we try to
answer here.
The remainder of this paper is structured as fol-
lows: In Section 2 we review literature on turn com-
pletion and related work in spoken dialogue systems,
120
before we explain what exactly our task is in Sec-
tion 3. In Section 4 we present our system?s overall
architecture and the duration modelling technique
that we use, before describing the corpus that we use
in Section 5. In Section 6 we first analyse whether
enough time to output a completion is available suffi-
ciently often, before turning to the question for the
actual sub-tasks of when and how to complete. We
wrap up with concluding remarks and ideas for future
work.
2 Related Work
The general phenomenon of turn completion can
be broken down into cases where the completion
is spoken simultaneously with the original speaker
(turn sharing, (Lerner, 2002)) and where the floor
changes in mid-utterance (collaborative turn se-
quences (Lerner, 2004) or split utterances (Purver
et al, 2009)). In this paper, a differentiation be-
tween the two cases is not important, as we only
deal with the question of when to start speaking
(for the previously non-speaking system) and not the
question of whether the current turn owner will stop
speaking. Moreover, whether the other speaker will
stop is beyond the system?s control. Lerner (2004)
distinguishes turn co-optation, in which a listener
joins in to come first and win the floor, and turn co-
completion, in which the completion is produced in
chorus. Both of these phenomena relate to the cur-
rent speaker?s speech: either to match it, or to beat
it. While we focus on matching in this work, the
methods described similarly apply to co-optation.
As Lerner (2002) notes, attributing this view to
Sacks et al (1974), simultaneous speech in conver-
sation is often treated exclusively as a turn taking
problem in need of repair. This is exactly the point
of view taken by current spoken dialogue systems,
which avoid overlap and interpret al simultaneous
speech as barge-in, regardless of content. However,
Lerner (2002) also notes that simultaneous speech
systematically occurs without being perceived as a
problem, e. g. in greetings, or when saying good bye,
which are relevant sub-tasks in deployed SDSs.
Two corpus studies are available which investi-
gate split utterances and their frequency: Skuplik
(1999) looked at sentence cooperations in a corpus
of task-oriented German (Poesio and Rieser, 2010)
and found 3.4 % of such utterances. Purver et al
(2009) find 2.8 % of utterance boundaries in the BNC
(as annotated by Ferna?ndez and Ginzburg (2002))
to meet their definition of utterances split between
speakers. Thus, while the absolute frequency may
seem low, the phenomenon does seem to occur con-
sistently across different languages and corpora.
Local (2007) describes phonetic characteristics at
utterance splits (he calls the phenomenon turn co-
construction) which distinguish them from regular
turn handovers, namely temporal alignment and close
prosodic integration with the previous speaker?s utter-
ance. In this paper, we focus on the temporal aspects
(both alignment and speech rate) when realizing turn
completions, leaving pitch integration to future work.
Cummins (2009) analyses speech read aloud by
two subjects at the same time (which he calls syn-
chronous speech): Synchrony is slightly better in a
live setting than with a subject synchronizing to a
recording of speech which was itself spoken in syn-
chrony and this is easier than to a recording of uncon-
strained speech. Cummins (2009) also experiments
with reduced stimuli: eliminating f0-contour had no
significant impact on synchrony, while a carrier with-
out segmental information (but including f0-contour)
fared significantly better than speaking to an uninfor-
mative hiss. (The first sentence of each recording was
always left unmodified, allowing subjects to estimate
speech rate even in the HISS condition.) Thus, pitch
information does not seem necessary for the task but
may help in the absence of segmental information.
On a more technical level and as mentioned above,
much work has been put into speeding up end-of-
turn detection and reducing processing lags at turn
changes (Raux and Eskenazi, 2009) and more re-
cently into end-of-turn prediction: Ward et al (2010)
present a model of turn-taking which estimates the
remaining duration of a currently ongoing turn. We
extend the task to predicting the remaining duration
of any currently ongoing word in the turn. Of course,
for this to be possible, words must be recognized
while they are still being uttered. We have previ-
ously shown (Baumann et al, 2009) that this can be
achieved with incremental ASR for the vast major-
ity of words and with an average of 102 ms between
when a word is first recognized and the word?s end.
As mentioned above, our work relies on other in-
cremental components to form a meaningful, turn
121
completing application and such components are be-
ing developed: Incremental understanding is well un-
derway (Sagae et al, 2009; Heintze et al, 2010), as is
decision making on whether full understanding of an
utterance has been reached (DeVault et al, 2009), and
Purver et al (2011) present an incremental semantics
component aimed explicitly at split utterances. In
fact, DeVault et al (2009) provide exactly the coun-
terpart to our work, describing a method that, given
the words of an ongoing utterance, decides when the
point of maximum understanding has been reached
and with what words this utterance is likely to end.
However, in their system demonstration, Sagae et al
(2010) use short silence time-outs to trigger system
responses. Our work eliminates the need for such
time-outs.
Hirasawa et al (1999) present a study where im-
mediate, overlapping back-channel feedback from
the system was found to be inferior to acknowledg-
ing information only after the user?s turn. However,
they disregarded the back-channels? micro-temporal
alignment as explored in this study (presumably pro-
ducing back-channels as early as possible), so their
negative results cannot be taken as demonstrating a
general shortcoming of the interactional strategy.
3 The Task
The general task that our timing component tackles
is illustrated in Figure 1. The component is triggered
into action when an understanding module signals
that (and with what words) a turn should be com-
pleted. At this decision point, our component must
estimate (a) when the current word ends and (b) how
the user will speak the predicted continuation. Ide-
ally, the system will start speaking the continuation
precisely when the next word starts and match the
user?s speech as best as possible. Thus, our compo-
nent must estimate the time between decision point
and ideal onset (which we call holding time) and the
user?s speech rate during the following words.
In order for the system to be able to produce a
continuation (?five six seven? in Figure 1) in time,
of course the decision point must come sufficiently
early (i. e. during ?four?) to allow for a completion
to be output in due time. This important precondition
must be met by-and-large by the employed ASR.
However, it is not a strict requirement: If ASR results
Figure 1: The task: When notified that the ongoing utter-
ance should be completed with ?five six seven? after the
word ?four?, the first three words are used to (a) estimate
the remaining duration of ?four? and to (b) estimate the
speech rate for the completion.
are lagging behind, the timing component?s estimated
holding time should turn negative. Depending on the
estimated lag, a completion can be suppressed or,
if it is small, fairly good completions can still be
realized by shortening the first (few) phonemes of
the completion to be synthesized.
We will now present our overall system before
describing two strategies we developed for solving
the task just described, and further on present the
experiments we conducted with the system and their
results in Sections 5 and 6.
4 System Description
Our system is based on the InproTK toolkit for in-
cremental spoken dialogue systems (Schlangen et
al., 2010) which uses Sphinx-4 (Walker et al, 2004)
and MaryTTS (Schro?der and Trouvain, 2003) as un-
derlying ASR and TTS engines, respectively. The
core of our system is a component that incrementally
receives rich speech recognition input (words, their
durations and a pitch track) from an incremental ASR
and computes the timing of completions.
When receiving a new word from ASR, our com-
ponent queries an understanding component whether
a completion can be predicted, and if so, whether
such a completion should be performed. In order to
not duplicate the work of DeVault et al (2009), we
use a mock implementation of an understanding mod-
ule, which actually knows what words are going to be
spoken (from a transcript file) and aims to complete
after every word spoken.
We have implemented two strategies for the timing
module, which we will describe in turn, after first
discussing a simple baseline approach.
122
Baseline: Speak Immediately A first, very simple
approach for our timing component is to never wait
between the decision point and outputting a comple-
tion right away. We believe that this was the strategy
taken by Hirasawa et al (1999) and we will show in
our evaluation in Section 6.2 that it is not very good.
Strategy 1: Estimating ASR Lookahead In our
ASR-based strategy (illustrated in Figure 2, top) the
system estimates what we call its lookahead rate,
i. e. the average time between when a word is first
recognized by ASR and the word?s end in the signal.
This lookahead is known for the words that have been
recognized so far and the average lookahead can then
be used as an estimate of the remaining duration
of the word that is currently being detected (i. e. its
holding time). Once the currently spoken word is
expected to end, the system should start to speak.
The strategy just described, as well as the baseline
strategy, only solve half of the task, namely, when the
continuation should be started, but not the question
of how to speak, which we will turn to now. Both
sub-tasks can be solved simultaneously by estimating
the speech rate of the current speaker, based on what
she already said so far, and considering this speech
rate when synthesizing a completion. Speech rate
estimation using some kind of duration model thus
forms the second strategy?s main component. For the
purpose of this work, we focus on duration models
in the context of TTS, where they are used to assign
durations to the phones to be uttered. Rule-based
approaches (Klatt, 1979) as well as methods using
machine learning have been used (primarily CART
(Breiman et al, 1984)); for HMM-based speech syn-
thesis, durations can be generated from Gaussian
probability density functions (PDFs) (Yoshimura et
al., 1998). We are not aware of any work that uses
duration models to predict the remaining time of an
ongoing word or utterance.
In our task, we need the duration model to make
estimations based on limited input (instead of pro-
viding plausibility ratings as in most ASR-related
applications). As it turns out, a TTS system in itself
is an excellent duration model because it potentially
ponders all kinds of syntactic, lexical, post-lexical,
phonological and prosodical context when assigning
durations to words and their phones. Also, our task
already involves a TTS system to synthesize the turn
Figure 2: Our strategies to estimate holding time (when to
speak), and speech rate (how to speak; only Strategy 2).
completion ? in our case MaryTTS (Schro?der and
Trouvain, 2003). The durations can be accessed in
symbolic form in MaryTTS, and the system allows
to manipulate this information prior to acoustic syn-
thesis. Depending on which voice is used, MaryTTS
uses machine-learned duration models (CART or
PDFs) or an optimized version of Klatt?s (1979) rules
which have been shown to perform only marginally
worse than the CART-based approach (Brinckmann
and Trouvain, 2003).
Strategy 2: Analysis-by-Synthesis As just de-
scribed, we hence employ the TTS? duration model
in an analysis-by-synthesis approach in this second
strategy, as illustrated in Figure 2 (bottom): When
triggered to complete an ongoing utterance, we query
the TTS for the durations it would assign to a produc-
tion of the predicted full utterance, i. e. the prefix that
was heard plus the predicted continuation of the turn.
In that way, the TTS can take the full utterance into
account when assigning prosodic patterns which may
influence durations. We then compute the factor that
is needed to scale the TTS?s duration of the words
already finished by the user (in the example: ?one
two three?) to the duration of the actual utterance
and apply this scaling factor to the remaining words
in the synthesized completion. We can then read off
the expected duration of the currently spoken word
from the scaled TTS output and, by subtracting the
time that this word is already going on, find out the
holding time. Similarly, the completion of the turn
which is now scaled to match the user?s speech rate
can be fed back to the synthesis system in order to
generate the acoustic waveform which is to be output
to the speakers once the system should start to speak.
123
5 Corpus and Experiment Setup
In order to evaluate the accuracy of the individual
components involved in the specific subtasks, we
conducted a controlled offline experiment. We have
not yet evaluated how actual users of our system
would judge its performance at outputting collabora-
tive completions.
As evaluation corpus we use recordings of the
German version of the story The North Wind and
the Sun (IPA, 1999) from the Kiel Corpus of Read
Speech (IPDS, 1994). The story (including title)
consists of 111 words and is read by 16 speakers,
giving a total of 1776 words in 255 inter-pausal-units
(IPUs), altogether resulting in about 12 minutes of
speech. (In the following, we will equate ?turns? with
IPUs, as our corpus of read speech does not contain
true turns.) Words and phones in our corpus have
a mean/median/std dev duration of 319/290/171 ms
and 78/69/40 ms, respectively.
We assume that every word can be a possible com-
pletion point in a real system, hence we evaluate the
performance of our timing component for all words
in the corpus. (This generalization may have an in-
fluence on our results: real collaborative completions
are sometimes invited by the speaker, probably by
giving cues that might simplify co-completion; if that
is true, the version tackled here is actually harder than
the real task.)
Good turn completions (and good timings) can
probably only be expected in the light of high ASR
performance. We trained a domain-specific language
model (based on the test corpus) and used an acous-
tic model trained for conversational speech which
was not specifically tuned for the task. The resulting
WER is 4.2 %. While our results could hence be con-
sidered too optimistic, Baumann et al (2009) showed
that incremental metrics remained stable in the light
of varying ASR performance. We expect that lower
ASR performance would not radically change pre-
diction quality itself; rather, it would have an impact
on how often continuations could be predicted, since
that is based on correct understanding of the prefix
of the utterance, limiting the amount of data points
for our statistics.
Even though we simulated the understanding and
prediction module, we built in some constraints that
are meant to be representative of real implementa-
tions of such a module: it can only find the right
completion if the previous two words are recognized
correctly and the overall WER is lower than 10 %.
(Coming back to Figure 1, if the system had falsely
recognized ?on two three?, no completion would
take place: Even though the last two words ?two
three? were recognized correctly, the WER between
?on two three? and ?one two three? is too high.) Un-
der this constraint, the timing component generated
data for 1100 IPU-internal and 223 IPU-final words
in our corpus.
The main focus of this paper is turn completion and
completions can only take place if there is something
left to complete (i. e. after turn-internal words). It
is still useful to be able to predict the duration of
turn-final words, though, as this is a prerequisite for
the related task of timing speaker changes. For this
reason, we include both turn-internal and turn-final
words in the analyses in Section 6.2.
In the evaluation, we use the ASR?s word align-
ments from recognition as gold standard (instead of
e. g. hand-labelled timings), which are essentially
equal to output from forced alignment. However,
when evaluating how well our timing component pre-
dicts the following word?s duration, we need that
word to also be correctly recognized by ASR. This
holds for 1045 words in our corpus, for which we
report results in Section 6.3.
6 Results
We evaluate the timing of our system with regards to
whether completions are possible in general, when a
completion should be produced, and what the speech
rate of the completion should be in the subsections
below.
6.1 Availability of Time to Make a Decision
While it is strictly speaking not part of the timing
component, a precondition to being able to speak
just-in-time is to ponder this decision sufficiently
early as outlined above.
Figure 3 shows a statistic of when our ASR first
hypothesizes a correct word relative to the word?s
end (which can be determined post-hoc from the
final recognition result) on the corpus. Most words
are hypothesized before their actual endings, with a
mean of 134 ms (median: 110 ms) ahead. This leaves
124
 0
 5
 10
 15
 20
?
 
-0.48
-0.40
-0.32
-0.24
-0.16
-0.08
 0 ?
 0.08
%
decision point relative to end of word (in seconds)
binned histogram
median (-0.11)
Figure 3: Statistics of when decisions can be first taken
relative to the word?s end (determined post-hoc).
enough lookahead to synthesize a completion and
for some delays that must be taken into account for
input and output buffering in the sound card, which
together take around 50 ms in our system.
Interestingly, lookahead differs widely for the
speakers in our corpus with means between 97 and
237 ms. As can be seen in Figure 3, some words are
only hypothesized after the fact, or at least too late
to account for the inevitable lags, which renders im-
possible successful turn-completions following these
words. However, the timing component should know
when it is too late ? the holding time should be nega-
tive ? and could either not output the completion at
this point or e. g. back off to setting in one or more
phones or syllables later (actually, back off until the
holding time turns positive).
6.2 When to Start Speaking
We evaluate the strategies from Section 4 by com-
paring the predicted holding times with the ideal
holding time, i. e. the time necessary to match the
ASR?s lookahead.
Figure 3 can also be taken as depicting the error
distribution of our baseline strategy to find out when
to start a completion: on average, the completion
will be early by 134 ms if it is uttered immediately
and the distribution is somewhat skewed. An unbi-
ased baseline strategy is obtained by subtracting the
global mean from the holding times. This however re-
quires the mean to be known in advance and is hence
inflexible: the global mean may very well be differ-
ent for other data sets as it already differs between
model
error distribution metrics (in ms)
mean median std dev MAE
baseline: all -134 -110 107 110
baseline ?? 0 23 107 63
ASR-based : all -2 19 105 60
IPU-internal 26 33 82 51
IPU-final -148 -143 87 142
TTS-based : all -3 4 85 45
IPU-internal 12 11 77 41
IPU-final -78 -76 83 79
Table 1: Descriptive statistics of the error distributions
over estimated onset times for different duration models.
speakers in our corpus. The two other strategies? er-
ror distributions are less skewed, so we just report
the distributions? mean, median, and standard devi-
ation,1 as well as the median absolute error (MAE)
for the ASR-based, the TTS-based and the baseline
strategies in Table 1.
As can be seen in Table 1, both strategies are
similarly effective in predicting the average remain-
ing time of a currently uttered word, reducing the
mean error close to zero, a significant improvement
over starting a completion or next turn immediately.
(ANOVA with post-hoc Tukey?s honest significance
differences test.) While our two approaches perform
similarly when comparing the performance for all
words, there actually are differences when looking
separately at IPU-internal and IPU-final words. In
both cases the TTS-based approach has a significantly
lower bias (paired Student?s t-tests, p < 0.01).
The bias of both strategies differs depending on
whether the current word is IPU-internal or -final.
We believe this to be due to final lengthening: phones
are about 40 % longer in IPU-final words. This is not
captured by the ASR-based strategy and the length-
ening may be stronger than what is predicted by the
pronunciation model of the TTS we use.
A low standard deviation of the error distribution
is probably even more important than a low mean
error, as it is variability, or jitter, that makes a system
unpredictable to the user. While there is no signifi-
cant improvement of the ASR-based approach over
the baseline, the TTS-based approach significantly
outperforms the other approaches with a 20 % re-
1We prefer to report mean and std dev for bias and jitter
separately; notice that RMSE=
?
?2 + ?2.
125
task
error distribution metric (in ms)
mean median std dev MAE
TTS-based : duration -5 4 75 45
+ ASR-based : onset 26 33 82 51
= end of word 25 30 100 81
+ TTS-based : onset 12 11 77 41
= end of word 7 10 94 74
Table 2: Descriptive statistics of the error distributions for
the first spoken word of a completion.
duction of jitter down to about the average phone?s
length (Browne-Forsythe?s modified Levene?s test,
p < 0.001).
Regarding human performance in synchronous
speech, Cummins (2002) reports an MAE of 30 ms for
the synchronous condition. However, MAE increased
to 56 ms when synchronizing to an (unsynchronously
read) recording, a value which is in the range of our
results (and with our system relying on similar input).
6.3 How to Speak
As explained in the task description, knowing when
to speak is only one side of the medal, as a turn
completion itself must be integrated with the previ-
ous speech in terms of duration, prosodic shape and
loudness.
Only our TTS-based strategy is capable of out-
putting predictions for a future word; our ASR-based
approach does not provide this information. How-
ever, both duration and onset estimation (the next
onset is identical to the end of the current word as
estimated in Section 6.2) together determine the error
at the word?s end. Hence, we report the error at the
next word?s end for the TTS strategy?s duration esti-
mate combined with both strategies? onset estimates
in Table 2.
Duration prediction for the next word with the
TTS-based strategy works similarly well as for on-
going words (as in Section 6.2), with an MAE of
45 ms (which is again in the range of human perfor-
mance). However, for the next word?s end to occur
when the speaker?s word ends, correct onset estima-
tion is just as important. When we combine onset
estimation with duration prediction, errors add up
and hence the error for the next word?s end is some-
what higher than for either of the tasks alone, with a
standard deviation of 94 ms and an MAE of 74 ms for
the TTS-based model, which again outperforms the
ASR-based model.
So far, we have not evaluated the matching of
prosodic characteristics such as loudness and intona-
tion (nor implemented their prediction). We believe
that simple matching (as we implemented for onset
and speech rate) is not as good a starting point for
these as they are more complex. Instead, we believe
these phenomena to mostly depend on communica-
tive function, e. g. a co-optation having a wide pitch-
range and relatively high loudness regardless of the
current speaker?s speech. Additionally, pitch-range
would have to be incrementally speaker-normalized
which results in some implementation difficulties.2
7 Demo Application: Shadowing
To get a feeling for the complete system and to
demonstrate that our timing component works on
live input, we implemented a shadowing application
which completes ? or rather shadows ? a user utter-
ance word-by-word. Given the prediction for the next
word?s onset time and duration it prepares the output
of that next word while the user is still speaking the
preceding word. As the application expects to know
what the user is going to speak, the user is currently
limited to telling the story of North Wind and the
Sun.
Two examples of shadowings are shown in Ap-
pendix A.3 As can be seen in the screenshots, the
decision points for all words are sufficiently early
before the next word, allowing for the next word?s
output generation to take place. Overall, shadowing
quality is good, with the exception of the second ?die?
in the second example. However, there is an ASR
error directly following (?aus? instead of ?luft?) and
the ASR?s alignment quality for ?sonne die? is al-
ready sub-optimal. Also, notice that the two words
following the ASR error are not shadowed as per our
error recovery strategy outlined in Section 5.
2Edlund and Heldner (2007) report that for a reliable pitch-
range estimation 10 to 20 seconds of voiced speech and hence ?
in our view ? twice the amount of audio is necessary. This would
have reduced our corpus size by too much.
3Audio files of the examples are available at http://www.
ling.uni-potsdam.de/?timo/pub/shadowing/.
126
8 Discussion and Future Work
We described the task of micro-timing, or micro-
aligning a system response (in our case a turn com-
pletion and shadowing a speaker) to the user?s speech
based on incremental ASR output and with both ASR
and symbolic TTS output as duration models to pre-
dict when and how a completion should be uttered.
We have shown first of all, that a completion is pos-
sible after most words, as an incremental ASR in a
small-enough domain can have a sufficient lookahead.
Additionally, we have shown that the TTS-based du-
ration model is better than both the baseline and the
ASR-based model. Both the next word?s onset and
duration can be predicted relatively well (? = 77 ms
and ? = 75 ms, respectively), and within the mar-
gin of human performance in synchronously reading
speech. It is interesting to note here that synchronous
speech is simplified in prosodic characteristics (Cum-
mins, 2002), which presumably facilitates the task.
Errors in speech rate estimation add up, so that the
deviation at the next word?s end is somewhat higher
(? = 94 ms). Deviation will likely increase for longer
completions, underlining the need for an incremen-
tal speech synthesis system which should allow to
instantly adapt output to changes in speech rate, con-
tent, and possibly sentiment of the other speaker.
Clearly, our duration modelling is rather simplistic
and could likely be improved by combining ASR and
TTS knowledge, more advanced (than a purely lin-
ear) mapping when calculating relative speech rate,
integration of phonetic and prosodic features from
the ASR, and possibly more. As currently imple-
mented, improvements to the underlying TTS sys-
tem (e. g. more ?conversational? synthesis) should
automatically improve our model. The TTS-based
approach integrates additional, non-ASR knowledge,
and hence it should be possible to single out those
decision points after which a completion would be es-
pecially error-prone, trading coverage against quality
of results. Initial experiments support this idea and
we would like to extend it to a full error estimation
capability.
We have focused the analysis of incrementally
comparing expected to actual speech rate to the task
of micro-aligning a turn-completion and shadowing a
speaker. However, we believe that this capability can
be used in a broad range of tasks, e. g. in combination
with word-based end-of-turn detection (Atterer et al,
2008) to allow for swift turn taking.4 In fact, precise
micro-alignment of turn handovers could be used for
controlled testing of linguistic/prosodic theory such
as the oscillator model of the timing of turn-taking
(Wilson and Wilson, 2005).
Finally, duration modelling can be used to quickly
detect deviations in speech rate (which may indicate
hesitations or planning problems of the user) as they
happen (rather than post-hoc), allowing to take the
speaker?s fluency into account in understanding and
turn-taking coordination as outlined by Clark (2002).
Acknowledgments
This work was funded by a DFG grant in the Emmy
Noether programme. We wish to thank the anony-
mous reviewers for their very helpful comments.
References
Michaela Atterer, Timo Baumann, and David Schlangen.
2008. Towards incremental end-of-utterance detection
in dialogue systems. In Proceedings of Coling, Manch-
ester, UK.
Timo Baumann, Michaela Atterer, and David Schlangen.
2009. Assessing and improving the performance of
speech recognition for incremental systems. In Pro-
ceedings of NAACL, Boulder, USA.
Timo Baumann. 2008. Simulating spoken dialogue with
a focus on realistic turn-taking. In Proceedings of the
13th ESSLLI Student Session, Hamburg, Germany.
Leo Breiman, Jerome H. Friedman, Richard A. Olshen,
and Charles J. Stone. 1984. Classification and regres-
sion trees. Wadsworth, Monterey.
Caren Brinckmann and Ju?rgen Trouvain. 2003. The role
of duration models and symbolic representation for
timing in synthetic speech. International Journal of
Speech Technology, 6(1):21?31.
Herbert H. Clark. 2002. Speaking in time. Speech Com-
munication, 36(1):5?13.
Fred Cummins. 2002. On synchronous speech. Acoustic
Research Letters Online, 3(1):7?11.
Fred Cummins. 2009. Rhythm as entrainment: The case
of synchronous speech. Journal of Phonetics, 37(1):16?
28.
4Additionally, both our models consistently under-estimate
the duration of IPU-final words. It should be possible to turn this
into a feature by monitoring whether a word actually has ended
when it was predicted to end. If it is still ongoing, this may be
an additional indicator that the word is turn-final.
127
David DeVault, Kenji Sagae, and David Traum. 2009.
Can I finish? Learning when to respond to incremental
interpretation results in interactive dialogue. In Pro-
ceedings of SIGDIAL, London, UK.
Jens Edlund and Mattias Heldner. 2007. Underpinning
/nailon/: Automatic Estimation of Pitch Range and
Speaker Relative Pitch. In Speaker Classification II,
volume 4441 of LNCS, pages 229?242. Springer.
Raquel Ferna?ndez and Jonathan Ginzburg. 2002. Non-
sentential utterances: A corpus-based study. Traitement
automatique des languages, 43(2):13?42.
Silvan Heintze, Timo Baumann, and David Schlangen.
2010. Comparing local and sequential models for sta-
tistical incremental natural language understanding. In
Proceedings of SIGDIAL, Tokyo, Japan.
Jun-ichi Hirasawa, Mikio Nakano, Takeshi Kawabata, and
Kiyoaki Aikawa. 1999. Effects of system barge-in
responses on user impressions. In Proceedings of Eu-
rospeech, Budapest, Hungary.
International Phonetic Association, IPA. 1999. Handbook
of the International Phonetic Association. Cambridge
University Press.
Institut fu?r Phonetik und digitale Sprachverarbeitung,
IPDS. 1994. The Kiel corpus of read speech. CD-
ROM.
Dennis H. Klatt. 1979. Synthesis by rule of segmental
durations in English sentences. Frontiers of Speech
Communication Research, pages 287?299.
Gene H. Lerner. 2002. Turn sharing: The choral co-
production of talk in interaction. In C. Ford, B. Fox,
and S. Thompson, editors, The Language of Turn and
Sequence, chapter 9. Oxford University Press.
Gene H. Lerner. 2004. Collaborative turn sequences. In
Gene H. Lerner, editor, Conversation Analysis: Studies
from the First Generation, Pragmatics & Beyond, pages
225?256. John Benjamins, Amsterdam.
John Local. 2007. Phonetic detail and the organisation of
talk-in-interaction. In Proceedings of the 16th ICPhS,
Saarbru?cken, Germany.
Massimo Poesio and Hannes Rieser. 2010. Completions,
coordination, and alignment in dialogue. Dialogue and
Discourse, 1(1):1?89.
Matthew Purver, Christine Howes, Patrick G. T. Healey,
and Eleni Gregoromichelaki. 2009. Split utterances in
dialogue: a corpus study. In Proceedings of SIGDIAL,
London, UK.
Matthew Purver, Arash Eshghi, and Julian Hough. 2011.
Incremental semantic construction in a dialogue system.
In Proceedings of the 9th IWCS, Oxford, UK.
Antoine Raux and Maxine Eskenazi. 2009. A finite-
state turn-taking model for spoken dialog systems. In
Proceedings of NAACL, Boulder, USA.
Harvey Sacks, Emanuel A. Schegloff, and Gail A. Jeffer-
son. 1974. A simplest systematic for the organization
of turn-taking in conversation. Language, 50:735?996.
Kenji Sagae, Gwen Christian, David DeVault, and David
Traum. 2009. Towards natural language understanding
of partial speech recognition results in dialogue systems.
In Proceedings of NAACL, Boulder, USA.
Kenji Sagae, David DeVault, and David Traum. 2010.
Interpretation of partial utterances in virtual human
dialogue systems. In Proceedings of NAACL.
David Schlangen, Timo Baumann, Hendrik Buschmeier,
Okko Bu?, Stefan Kopp, Gabriel Skantze, and Ramin
Yaghoubzadeh. 2010. Middleware for incremental
processing in conversational agents. In Proceedings of
SIGDIAL, Tokyo, Japan.
David Schlangen. 2006. From reaction to prediction:
Experiments with computational models of turn-taking.
In Proceedings of Interspeech, Pittsburgh, USA.
Marc Schro?der and Ju?rgen Trouvain. 2003. The Ger-
man text-to-speech synthesis system MARY: A tool
for research, development and teaching. International
Journal of Speech Technology, 6(3):365?377.
Gabriel Skantze and David Schlangen. 2009. Incremental
dialogue processing in a micro-domain. In Proceedings
of EACL, Athens, Greece.
Kristina Skuplik. 1999. Satzkooperationen. Defini-
tion und empirische Untersuchung. Technical Report
1999/03, SFB 360, Universita?t Bielefeld.
Willie Walker, Paul Lamere, Philip Kwok, Bhiksha Raj,
Rita Singh, Evandro Gouvea, Peter Wolf, and Joe
Woelfel. 2004. Sphinx-4: A flexible open source
framework for speech recognition. Technical Report
SMLI TR2004-0811, Sun Microsystems Inc.
Nigel Ward, Olac Fuentes, and Alejandro Vega. 2010.
Dialog prediction for a general model of turn-taking.
In Proceedings of Interspeech, Tokyo, Japan.
Karl Weilhammer and Susen Rabold. 2003. Durational as-
pects in turn taking. In Proceedings of the 15th ICPhS,
Barcelona, Spain.
Margaret Wilson and Thomas P. Wilson. 2005. An oscil-
lator model of the timing of turn-taking. Psychonomic
Bulletin & Review, 12(6):957?968.
Takayoshi Yoshimura, Keiichi Tokuda, Takashi Masuko,
Takao Kobayashi, and Tadashi Kitamura. 1998. Du-
ration modeling for HMM-based speech synthesis. In
Proceedings of the 5th ICSLP, Sydney, Australia.
128
Appendix A Examples of Shadowing
Figure 4: Example of shadowing for a file in our corpus (k73nord2). The first line of labels shows the final ASR output,
the second line shows the decision points for each word and the third and fourth lines show the system?s output (planned
output may overlap, hence two lines; in the system, an overlapped portion of a word is replaced by the following word?s
audio).
Figure 5: Example of shadowing with live input (verena2nord2). Notice that ?Luft? is predicted and synthesized
although it is (later) misunderstood by ASR as ?aus?, resulting in a missing shadowing of ?mit? and ?ihren?. In order
to not disturb the speaker, the system?s audio output was muted.
129
Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pages 295?303,
Seoul, South Korea, 5-6 July 2012. c?2012 Association for Computational Linguistics
Combining Incremental Language Generation and
Incremental Speech Synthesis for Adaptive Information Presentation
Hendrik Buschmeier1, Timo Baumann3, Benjamin Dosch, Stefan Kopp1, David Schlangen2
1Sociable Agents Group, CITEC and Faculty of Technology, Bielefeld University
2Dialogue Systems Group, Faculty of Linguistics and Literary Studies, Bielefeld University
{hbuschme,bdosch,skopp,david.schlangen}@uni-bielefeld.de
3Natural Language Systems Division, Department of Informatics, University of Hamburg
baumann@informatik.uni-hamburg.de
Abstract
Participants in a conversation are normally re-
ceptive to their surroundings and their inter-
locutors, even while they are speaking and can,
if necessary, adapt their ongoing utterance. Typ-
ical dialogue systems are not receptive and can-
not adapt while uttering. We present combin-
able components for incremental natural lan-
guage generation and incremental speech syn-
thesis and demonstrate the flexibility they can
achieve with an example system that adapts to
a listener?s acoustic understanding problems
by pausing, repeating and possibly rephrasing
problematic parts of an utterance. In an eval-
uation, this system was rated as significantly
more natural than two systems representing the
current state of the art that either ignore the
interrupting event or just pause; it also has a
lower response time.
1 Introduction
Current spoken dialogue systems often produce pre-
scripted system utterances or use templates with vari-
able substitution during language generation. If a
dialogue system uses grammar-based generation at
all, it produces complete utterances that are then syn-
thesised and realised in one big chunk. As systems
become increasingly more conversational, however,
the need arises to make output generation1 more flex-
ible. In particular, capabilities for incrementally gen-
erating output become desirable, for two kinds of
reasons.
(a) In situations where fast system responses are
important, production of output can begin before the
1We will use the term ?output generation? here to cover both
natural language generation and speech synthesis.
content that is to be presented is fully specified ? even
if what is being produced is just a turn-taking signal
(Skantze and Hjalmarsson, 2010).
(b) A system that produces its output incrementally
can react to events happening while it is realising an
utterance. This can be beneficial in domains where
the state of the world that the system relays informa-
tion about can change mid-utterance, so that a need
may arise to adapt while speaking. It should also
improve naturalness by allowing the system to react
to dialogue phenomena such as concurrent feedback
signals from the user (Buschmeier and Kopp, 2011).
We present work towards enabling such capabil-
ities. We have implemented and connected a com-
ponent for incremental natural language genera-
tion (iNLG) that works with specifications of sub-
utterance-sized communicative intentions and a com-
ponent for incremental speech synthesis (iSS) that can
handle sub-utterance-sized input and modifications
to not-yet-spoken parts of the utterance with very low
latencies. To explore whether such an output genera-
tion capability can indeed be advantageous, we have
created a test system that can react to random noise
events that occur during a system utterance by repeat-
ing and modifying the last sub-utterance chunk. In
an evaluation, we found that this system is in general
more reactive than a non-incremental variant and that
humans rate its behaviour to be more natural than
two non-incremental and non-responsive systems.
2 Related Work
Psycholinguistic research has identified incremen-
tality as an important property of human language
production early on and it has been incorporated into
several models (e. g., Kempen and Hoenkamp, 1987;
295
Levelt, 1989). Guhe (2007) presents a computational
model of incremental conceptualisation. However,
work on iNLG itself is rare, partly because NLG re-
search focusses on text (instead of spoken language).
Notable exceptions are the in-depth analysis of
requirements for and properties of incremental gen-
eration by Kilger and Finkler (1995), who describe
the LTAG-based incremental syntactic generator VM-
GEN. It takes incremental input, processes it and pro-
duces output as soon as at least a prefix of the final
sentence is syntactically complete. If VM-GEN no-
tices that it committed itself to a prefix too early, it
can initiate an overt repair. More recently, Skantze
and Hjalmarsson (2010) presented a system that per-
forms incremental generation in the context of a spo-
ken dialogue system. It can already start to produce
output when the user has not yet finished speaking
and only a preliminary interpretation exists. By flexi-
bly changing what to say and by being able to make
self-repairs the system can recover from situations
where it selected and committed on an inadequate
speech plan. Both systems, however, are not able
to flexibly adapt the language that they generate to
changing requirements due to changes in the situation
or changing needs on the side of the user.
Real-time on-the-fly control of speech synthesis
is rare, especially the full integration into a dialogue
system. Matsuyama et al (2010) describe a system
that feeds back to the dialogue system the word at
which it has been interrupted by a barge-in. Edlund
(2008) additionally enables a system to continue at
the point where it was interrupted. He also outlines
some requirements for incremental speech synthe-
sis: to give constant feedback about what has been
delivered, to be interruptible (and possibly continue
from that position), and to run in real time. Edlund?s
system, which uses diphone synthesis, performed
non-incrementally before delivery starts. We go be-
yond this in also enabling changes during delivery
and conducting synthesis steps just-in-time.
Dutoit et al (2011) present an incremental HMM
optimiser which allows to change pitch and tempo
of upcoming phonemes. However, as that system is
fed from a (non-incrementally produced) label file, it
cannot easily be used in an incremental system.
A predecessor of our iSS component (which was
not yet fully incremental on the HMM level) is de-
scribed in detail in (Baumann and Schlangen, 2012a).
3 Incremental and Adaptive NLG
3.1 The SPUD microplanning framework
The NLG component presented here is based on
the SPUD microplanning framework (Stone et al,
2003) and realised in DeVault?s (2008) implemen-
tation ?Java SPUD?. SPUD frames microplannig as
a constraint satisfaction problem, solving the tasks
that are involved in generating a sentence (lexical
and syntactic choice, referring expression generation
and aggregation) in an integrated manner. Genera-
tion starts from a communicative goal that specifies
constraints for the final utterance. The generation pro-
cess is further shaped by (a) general constraints that
model pragmatic properties of language use such as
the Gricean maxims (a principle called ?textual econ-
omy?); (b) specific constraints imposed through the
communicative status of the propositions to be com-
municated (i. e., what knowledge can be presupposed
and what needs to be communicated explicitly); and
(c) linguistic resources (a context-free tree rewriting
formalism based on LTAG; Stone, 2002).
To deal efficiently with the infinite search space
spanned by the linguistic resources, SPUD uses a
heuristic search algorithm to find an utterance that
satisfies the imposed constraints (Stone et al, [2003]
describe the heuristic function). In each search step,
the algorithm expands the ?provisional? utterance by
adding the linguistic resource that maximally reduces
the estimated distance to the final utterance.
If the generation process runs into a dead-end state,
it could in principle deal with the situation by track-
ing back and expanding a different branch. This,
however, is impractical, as it becomes impossible
to project when ? if at all ? generation will finish.
Hence, in that case, SPUD stops without providing a
result, delegating the problem back to the preceding
component in the generation pipeline.
3.2 Partially incremental generation
SPUD generates utterances incrementally in the sense
that the completeness of the provisional utterance
increases monotonically with every step. This, how-
ever, does not mean that the surface structure of pro-
visional utterances is constructed incrementally (i. e.,
from left to right) as well, which would only be pos-
sible, if (a) the search strategy would always expand
the leftmost non-lexicalised node in the provisional
296
Utterance IC
1
IC
2
IC
n
 ?
Utterance
outline
IMPT
1
IMPT
2
IMPT
n
 ?
  MCP
? {U
1
, ?}
? KB
1
? {U
i
, ?}
? KB
2
? {U
k
, ?}
? KB
n
  MPP
 ?state
t
Figure 1: Incremental microplanning consists of two pro-
cesses, micro content planning (MCP) and microplanning-
proper (MPP). The former provides incremental microplan-
ning tasks from an utterance outline to the latter, which
incrementally transforms them into communicative intent
and intonation unit-sized chunks of natural language.
utterance first and if (b) the linguistic resources are
specified (and ordered) in a way that allows left-to-
right expansion of the trees in all possible situations.
In practice, both requirements are difficult to meet
and full word-by-word incrementality in natural lan-
guage microplanning is not within reach in the SPUD
framework. Because of this, we take a slightly more
coarse grained approach to incremental microplan-
ning and choose chunks of the size of intonation
phrases instead of words as our incremental units.
We say that our microplanner does ?partially incre-
mental generation?.
Our incremental microplanner comprises two inter-
acting processes, micro content planning and micro-
planning-proper (MCP and MPP; schematised in Fig-
ure 1), each of which fulfils a distinct task and oper-
ates on different structures.
MCP takes as input utterance outlines that describe
the communicative goal (a set of desired updates Ux)
intended to be communicated in an utterance and the
presuppositions and private knowledge needed to do
so. Importantly, utterance outlines specify how the
communicative goal can be decomposed into an or-
dered list of incremental microplanning-tasks IMPTx.
Each such task comprises (a) a subset of the commu-
nicative goal?s desired updates that belong together
and fit into one intonation unit sized chunk of speech
and (b) knowledge KBx used in generation.
MPP takes one incremental microplanning-task at
a time and uses SPUD to generate the IMPT?s commu-
nicative intent as well as its linguistic surface form
ICx. The communiciative intent is added to a repre-
sentation (?state? in Figure 1) that is shared between
the two processes. While processing the IMPTs of
an utterance outline, MCP can access this representa-
tion, which holds information about all the desired
updates that were achieved before, and thus knows
that a desired update that is shared between subse-
quent IMPTs has already been communicated. MPP
can also take this information into account during
generation. This makes it possible that an utterance
is coherent and adheres to pragmatic principles even
though generation can only take local decisions.
3.3 Adaptive generation
Being able to generate language in sub-utterance
chunks makes it possible to dynamically adapt later
increments of an utterance to changes in the situa-
tion that occur while the utterance is being realised.
Decisions about these adaptations need not be taken
almost until the preceding increment finishes, mak-
ing the generation process very responsive. This is
important to be able to deal with interactive dialogue
phenomena, such as communicative feedback of the
interlocutor (Allwood et al, 1992) or compound con-
tributions (Howes et al, 2011), in a timely manner.
Adaptation may happen in both parts of incremen-
tal microplanning. In MCP, adaptation takes the form
of dynamically changing the choice of which IMPT to
generate next or changing the internal structure of an
IMPT; adaptation in MPP changes the choices the gen-
eration process makes while transforming IMPTs into
communicative intent and surface form. Adaptation
in MCP is triggered top-down, by higher-level pro-
cesses such as dialogue management. Adaptation in
MPP on the other hand depends on the task given and
on the status of the knowledge used during generation.
The details are then governed by global parameter
settings MPP uses during generation.
If there is, for example, reason for the system to
believe that the current increment was not commu-
nicated clearly because of noise in the transmission
channel, the MCP process might delay future IMPTs
and initiate a repair of the current one by re-inserting
it at the beginning of the list of upcoming IMPTs of
this utterance outline. The MPP process? next task
is then to re-generate the same IMPT again. Due to
297
Table 1: Surface forms generated from the same IMPT (de-
sired updates = {hasSubject(event6, ?Vorlesung
Linguistik?)}; KB = {event6}) but with different
levels of verbosity.
Verbosity Generated sub-utterance chunk
0 ?Vorlesung Linguistik?
(lecture Linguistcs)
1 ?Betreff: Vorlesung Linguistik?
(subject: lecture Linguistics)
2 ?mit dem Betreff Vorlesung Linguistik?
(with the subject: lecture Linguistics)
changes in the state information and situation that
influence microplanning, the resulting communica-
tive intent and surface form might then differ from
its previous result.
3.4 Adaptation mechanisms
As a proof of concept, we integrated several adapta-
tion mechanism into our NLG-microplanning system.
The goal of these mechanisms is to respond to a dia-
logue partner?s changing abilities to perceive and/or
understand the information the system wants to con-
vey. Some of the mechanisms operate on the level of
MCP, others on the level of MPP. The mechanisms are
implemented either with the knowledge and its con-
versational status used in generation or by altering
the decision structure of SPUD?s search algorithm?s
heuristic function. Similar to the approach of flexi-
ble NLG described by Walker et al (2007), most of
the mechanism are conditioned upon individual flags,
that in our case depend on a numeric value that repre-
sents the level of understanding the system attributes
to the user. Here we describe the two most relevant
mechanisms used to adapt verbosity and redundancy.
Verbosity The first mechanism aims at influenc-
ing the length of a sub-utterance chunk by making
it either more or less verbose. The idea is that actual
language use of human speakers seldom adheres to
the idealised principle of textual economy. This is
not only the case for reasons of cognitive constraints
during speech production, but also because words
and phrases that do not contribute much to an utter-
ance?s semantics can serve a function, for example by
drawing attention to specific aspects of an utterance
or by giving the listener time to process.
To be able to vary utterance verbosity, we anno-
tated the linguistic resources in our system with val-
ues of their verbosity (these are hand-crafted similar
to the rule?s annotation with production costs). Dur-
ing generation in MPP the values of all linguistic re-
sources used in a (provisional) utterance are added up
and used as one factor in SPUD?s heuristic function.
When comparing two provisional utterances that only
deviate in their verbosity value, the one that is nearer
to a requested verbosity level is chosen. Depend-
ing on this level, more or less verbose constructions
are chosen and it is decided whether sub-utterance
chunks are enriched with additional words. Table 1
shows the sub-utterance chunk ?Betreff: Vorlesung
Linguistik? (subject: lecture Linguistics) generated
with different levels of verbosity.
Redundancy The second adaptation mechanism is
redundancy. Again, redundancy is something that an
ideal utterance does not contain and by design SPUD
penalises the use of redundancy in its heuristic func-
tion. Two provisional utterances being equal, the one
exhibiting less redundancy is normally preferred. But
similar to verbosity, redundancy serves communica-
tive functions in actual language use. It can highlight
important information, it can increase the probability
of the message being understood (Reiter and Sripada,
2002) and it is often used to repair misunderstanding
(Baker et al, 2008).
In incremental microplanning, redundant informa-
tion can be present both within one sub-utterance
chunk (e. g., ?tomorrow, March 26, . . . ? vs. ?tomorrow
. . . ?) or across IMPTs. For the former case, we modi-
fied SPUD?s search heuristic in order to conditionally
either prefer an utterance that contains redundant in-
formation or an utterance that only contains what is
absolutely necessary. In the latter case, redundancy
only becomes an option when later IMPTs enable the
choice of repeating information previously conveyed
and therefore already established as shared knowl-
edge. This is controlled via the internal structure of
an IMPT and thus decided on the level of MCP.
4 Incremental Speech Synthesis
In this section we describe our component for incre-
mental speech synthesis. We extend Edlund?s (2008)
requirements specification cited in Section 2, requir-
ing additionally that an iSS supports changes to as-yet
298
unspoken parts of an ongoing utterance.
We believe that the iSS?s requirements of inter-
ruptability, changeability, responsiveness, and feed-
back are best resolved by a processing paradigm in
which processing takes place just-in-time, i. e., tak-
ing processing steps as late as possible such as to
avoid re-processing if assumptions change. Before
we describe these ideas in detail, we give a short
background on speech synthesis in general.
4.1 Background on speech synthesis
Text-to-speech (TTS) synthesis functions in a top-
down processing approach, starting on the utterance
level and descending onto words and phonemes, in
order to make good decisions (Taylor, 2009). For
example, top-down modelling is necessary to assign
stress patterns and sentence-level intonation which
ultimately lead to pitch and duration contours, and to
model co-articulation effects.
TTS systems start out assigning intonation patterns
to the utterance?s words and then generate a target
phoneme sequence which is annotated with the tar-
gets? durations and pitch contour; all of this is called
the linguistic pre-processing step. The synthesis step
proper can be executed in one of several ways with
HMM-based and unit-selection synthesis currently
producing the perceptually best results.
In HMM-based synthesis, the target sequence is
first turned into a sequence of HMM states. A global
optimisation then determines a stream of vocoding
features that optimise both HMM emission probabili-
ties and continuity constraints (Tokuda et al, 2000).
The stream may also be enhanced to consider global
variance of features (Toda and Tokuda, 2007). The
parameter frames are then fed to a vocoder which
generates the final speech audio signal.
Unit-selection, in contrast, searches for the best
sequence of (variably sized) units of speech in a
large, annotated corpus, aiming to find a sequence
that closely matches the target sequence while having
few and if possible smooth joints between units.
We follow the HMM-based approach for our com-
ponent for the following reasons: (a) even though
only global optimisation is optimal for both tech-
niques, the influence of look-ahead on the continuity
constraints of HMM-based synthesis is linear leading
to a linear loss in optimality with smaller look-aheads
(whereas unit-selection with limited look-ahead may
Figure 2: Hierarchical structure of incremental units de-
scribing an example utterance as it is being produced
during delivery.
jump erratically between completely different unit se-
quences). (b) HMM-based synthesis nicely separates
the production of vocoding parameter frames from
the production of the speech audio signal which al-
lows for fine-grained concurrent processing (see next
subsection). (c) Parameters in the vocoding frames
are partially independent. This allows us to indepen-
dently manipulate, e. g., pitch without altering other
parameters or deteriorating speech quality (in unit-
selection, a completely different unit sequence might
become optimal even for slight changes of pitch).
4.2 Incrementalising speech synthesis
As explained in the previous subsection, speech syn-
thesis is performed top-down, starting at the utterance
and progressing down to the word, target and finally,
in the HMM approach, vocoding parameter and signal
processing levels. It is, however, not necessary that
all details at one level of processing are worked out
before starting to process at the next lower level. To
be precise, some syntactic structure is sufficient to
produce sentence-level intonation, but all words need
not be known. Likewise, post-lexical phonological
processes can be computed as long as a local context
of one word is available and vocoding parameter com-
putation (which must model co-articulation effects)
should in turn be satisfied with about one phoneme of
context. Vocoding itself does not need any lookahead
at all (aside from audio buffering considerations).
Thus, we generate our data structures incremen-
tally in a top-down and left-to-right fashion with dif-
ferent amounts of pre-planning and we do this using
several processing modules that work concurrently.
This results in a ?triangular? structure as shown in
299
Figure 2. At the top stands a pragmatic plan for the
full utterance from which a syntactic plan can be de-
vised. This plan is filled with words, as they become
available. On the vocoding parameter level, only a
few frames into the future have been computed so
far ? even though much more context is already avail-
able. That is, we generate structure just-in-time, only
shortly before it is needed by the next processor. This
holds very similarly for the vocoding step that pro-
duces the speech signal just-in-time.
The just-in-time processing approach, combined
with the increasing temporal granularity of units to-
wards the lower levels has several advantages: (a) lit-
tle utterance-initial processing (only what is neces-
sary to produce the beginning of the signal) allows for
very responsive systems; and (b) changes to the ini-
tial plan result only in a modest processing overhead
because little structure has to be re-computed.
4.3 Technical overview
As a basis, we use MaryTTS (Schr?der and Trouvain,
2003), but replace Mary?s internal data structures
and processing strategies with structures from our
incremental SDS architecture, the INPROTK toolkit
(Schlangen et al, 2010; Baumann and Schlangen,
2012b), which implements the IU model for incre-
mental dialogue processing (Schlangen and Skantze,
2009). The model conceptualises ? and the toolkit
implements ? incremental processing as the process-
ing of incremental units (IUs), which are the smallest
?chunks? of information at a specific level (the boxes
in Figure 2). IUs are interconnected to form a network
(e. g., words keep links to their associated phonemes
and neighbouring words and vice-versa) which repre-
sents the system?s information state.
The component is fed with chunk IUs which con-
tain some words to be synthesised (on their own or
appended to an ongoing utterance). For simplicity,
all units below the chunk level are currently gener-
ated using Mary?s (non-incremental) linguistic pre-
processing capabilities to obtain the target phoneme
sequence. For continuations, the preceding parts of
the utterance are taken into account when generating
prosodic characteristics for the new chunk. Also, our
component is able to revoke and exchange chunks
(or unspoken parts thereof) to change what is to be
spoken; this capability however is not used in the
example system presented in Section 5.
The lowest level module of our component is what
may be called a crawling vocoder, which actively
moves along the phoneme IU layer and executes two
processing steps: (a) for each phoneme it generates
the sequence of HMM parameter frames using a local
optimisation technique (using up to four neighbour-
ing phonemes as context) similar to the one described
by Dutoit et al (2011); and (b) vocoding the HMM
parameters into an audio stream which contains the
actual speech signal.
IUs have a ?progress? field which is set by the
crawling vocoder to one of ?upcoming?, ?ongoing?,
or ?completed?, as applicable. IUs provide a generic
update mechanism to support notification about
progress changes in delivery. The next section de-
scribes how this is used to drive the system.
5 Integrating iNLG and iSS for Adaptive
Information Presentation
Integrating incremental microplanning with incre-
mental speech synthesis in one incremental output
generation architecture allows us to test and explore
how their capabilities act in a coordinated way. As a
first example, we implemented a system that presents
information about events in an appointment database
(e. g., new, conflicting or rescheduled appointments)
and is able to cope with external noise burst events,
as they might for example occur on a bad telephone
line or when using a dialogue system next to a busy
street. The focus is on the incremental capabilities of
the system which enable its adaptive behaviour.
5.1 Component interplay
iNLG and iSS are implemented as IU modules in the
INPROTK architecture. The control flow of the sys-
tem (Figure 3) is managed without special coupling
between the modules, relying only on the left-to-right
processing capabilities of INPROTK combined with
its generic IU update mechanism for transporting
feedback from iSS to iNLG. Both modules can be
(and have been) combined with other IU modules.
To communicate an appointment event, the iNLG
module starts by generating two initial chunk IUs,
the first to be expressed immediately, the second as
additional prosodic context (chunk lengths differ with
an average of about 4 words). The iNLG registers as a
?progress listener? on each chunkIU, which registers
300
Figure 3: Information flow (dashed lines) between iNLG
and iSS components (rounded boxes) and incremental
units (rectangular boxes). The vocoder crawls along with
time and triggers the updates.
as a progress listener on a phonemeIUnear its end.
Shortly before iSS finishes speaking the chunk, iNLG
is thus informed and can generate and send the next
chunk to iSS just-in-time.
If adaptation to noise is needed, iNLG re-generates
and re-sends the previous chunk, taking altered pa-
rameters into account. Again, a subsequent chunk
is immediately pre-generated for additional prosodic
context. This way of generating sub-utterance chunks
ensures that there is always one chunk lookahead to
allow the iSS module to compute an adequate in-
tonation for the current chunk, while maintaining
the single chunk as increment size for the system
and minimising redundant work on the side of iNLG
(this lookahead is not required for iSS; but if it is un-
available, sub-utterance chunks may be inadequately
connected prosodically).
5.2 Responding to a noise event
A third module, the noise detector connects to both
iSS and iNLG. On noise onset, it informs iSS to inter-
rupt the ongoing utterance after the current word (this
works by breaking the links between words so that
the crawling vocoder finishes after the currently ongo-
ing word). Once a noise burst ends, iNLG is informed,
re-generates the interrupted sub-utterance chunk with
the verbosity level decreased by one and the assumed
understanding value increased by one (this degree
of adaptation results in a noticeable difference, it is,
however, not based on empirical study). The values
are then reset, the following chunk is generated and
both chunks are sent to iSS.
It should be noted, that we have not implemented
a real noise source and noise detector. Instead, our
random noise simulator generates bursts of noise of
1000 ms after a random time interval (between 2 and
Table 2: Processing time per processing step before deliv-
ery can begin (in ms; averaged over nine stimuli taking the
median of three runs for each stimulus; calculated from
log messages; code paths preheated for optimisation).
non-incr. incr.
NLG-microplanning 361 52
Synthesis (ling. pre-processing) 217 4472
Synthesis (HMM and vocoding) 1004 21
total response time 1582 519
5 seconds) and directly informs the system 300 ms
after noise starts and ends. We think it is reasonable
to assume that a real noise detector should be able to
give accurate information with a similar delay.
6 Evaluation
6.1 Quantitative evaluation
One important argument in favour of incremental
processing is the possibility of speeding up system
response time, which for non-incremental systems
is the sum of the times taken by all processors to
do their work. An incremental system, in contrast,
can fold large amounts of its processing time into the
ongoing speech output; what matters is the sum of
the onset times of each processor, i. e., the time until
a first output becomes available to the next processor.
Table 2 summarises the runtime for the three major
steps in output production of our system using nine
utterances from our domain. Both NLG and speech
synthesis? onset times are greatly reduced in the in-
cremental system.2 Combined, they reduce system
response time by more than a second. This is mostly
due to the almost complete folding of HMM opti-
misation and vocoding times into the spoken utter-
ance. NLG profits from the fact that at the beginning
of an utterance only two chunks have to be gener-
ated (instead of an average of 6.5 chunks in the non-
incremental system) and that the first chunk is often
very simple.
6.2 Subjective evaluation
To further test whether the system?s behaviour in
noisy situations resembles that of a human speaker
2The iSS component by mistake takes the symbolic pre-
processing step twice. Unfortunately, we found this bug only
after creating the stimuli used in the subjective evaluation.
301
in a similar situation, we let humans rate utterances
produced by the fully incremental, adaptive system
and utterances produced by two non-incremental
and less responsive variants (we have not used non-
incremental TTS in combination with iNLG as another
possible base-line as pretests showed this to sound
very unnatural due to the missing prosodic linkage be-
tween phrases). The participants were to rate whether
they agree to the statement ?I found the behaviour of
the system in this situation as I would expect it from
a human speaker? on a 7-point Likert-scale.
In condition A, full utterances were generated non-
incrementally, synthesised non-incrementally and
played without responding to noise-interruptions in
the channel (as if the system did not notice them).
Utterances in condition B were generated and synthe-
sised as in condition A, but playback responded to the
noisy channel, stopping when the noise was noticed
and continuing when noise ended. For condition C,
utterances were generated with the fully incremental
and adaptive system described in Section 5. Upon
noise detection, speech synthesis is interrupted and,
when the noise ends, iNLG will re-generate the in-
terrupted sub-utterance chunk ? using the adaptation
strategy outlined in Section 5.2. This then triggers
iSS into action and shortly after, the system contin-
ues speaking. Nine system runs, each producing a
different utterance from the calendar domain, were
recorded in each of the three conditions, resulting in
a total of 27 stimuli.
Before the actual stimuli were presented, partici-
pants listened to two example stimuli without noise
interruptions to get an impression of how an aver-
age utterance produced by the system sounds. After
the presentation of these two examples, the 27 stim-
uli were presented in the same random order. Par-
ticipants listened once to each stimulus and rated it
immediately after every presentation.
Twelve PhD-students (3 female, 9 male; mean age
30.5 years; 11 with German as one of their first lan-
guages; none with uncorrected hearing impairment)
from Bielefeld University participated in our study
and listened to and rated the 27 stimuli.
A Friedman rank sum test revealed a highly sig-
nificant difference between the perceived human-
likeness of the three systems (?2 = 151, p < .0001).
Median values of stimulus ratings in the conditions
A, B and C were 2, 2 and 6 respectively, indicat-
ing that the fully incremental system was rated con-
siderably more human-like. This was also shown
through a post-hoc analysis with Wilcoxon signed
rank tests which found no significant difference be-
tween condition A and B (V = 1191.5, p = .91)3.
Conditions A and C, however, differed highly signifi-
cantly (V = 82, p < .0001), as did conditions B and
C (V = 22.5, p < .0001) ? even after applying a Bon-
ferroni correction to correct for a possible cumulation
of ?-errors.
7 Conclusion
We have presented what is ? to the best of our knowl-
edge ? the first integrated component for incremental
NLG and speech synthesis and demonstrated the flex-
ibility that an incremental approach to output gener-
ation for speech systems offers by implementing a
system that can repair understanding problems.
From the evaluation we can conclude that incre-
mental output generation (both iNLG and iSS in iso-
lation or combined) is able to greatly speed up sys-
tem response time and can be used as a means to
speed up system response even in an otherwise non-
incremental system. Furthermore, we showed that the
behaviour of our fully incremental and adaptive sys-
tem was perceived as significantly more human-like
than the non-incremental and the non-incremental
but responsive baseline systems.
The understanding problem that our demonstra-
tor system tackled was of the simplest kind, namely
acoustic non-understanding, objectively detectable
as the presence of noise. In principle, however, the
same mechanisms of stopping and rephrasing can be
used to tackle more subjective understanding prob-
lems as can be signalled by linguistic feedback. Our
incremental output generation component gives us an
ideal basis to explore such problems in future work.
Acknowledgements This research is partially sup-
ported by the Deutsche Forschungsgemeinschaft
(DFG) in the Center of Excellence in ?Cognitive Inter-
action Technology? (CITEC) and through an Emmy
Noether Fellowship to the last author.
3This suggests that it does not matter whether a system re-
sponds to problems in the communication channel by waiting or
totally ignores these problems. Notice, however, that we did not
test recall of the calendar events. In that case, condition B should
outperform A, as some information was clearly inaudible in A.
302
References
Jens Allwood, Joakim Nivre, and Elisabeth Ahls?n. 1992.
On the semantics and pragmatics of linguistic feedback.
Journal of Semantics, 9:1?26.
Rachel Baker, Alastair Gill, and Justine Cassell. 2008.
Reactive redundancy and listener comprehension in
direction-giving. In Proceedings of the 9th SIGdial
Workshop on Discourse and Dialogue, pages 37?45,
Columbus, OH.
Timo Baumann and David Schlangen. 2012a. INPRO_iSS:
A component for just-in-time incremental speech syn-
thesis. In Proceedings of ACL System Demonstrations,
Jeju, South Korea.
Timo Baumann and David Schlangen. 2012b. The
INPROTK 2012 release. In Proceedings of the NAACL-
HLT Workshop on Future directions and needs in the
Spoken Dialog Community: Tools and Data, pages 29?
32, Montr?al, Canada.
Hendrik Buschmeier and Stefan Kopp. 2011. Towards
conversational agents that attend to and adapt to com-
municative user feedback. In Proceedings of the 11th
International Conference on Intelligent Virtual Agents,
pages 169?182, Reykjavik, Iceland.
David DeVault. 2008. Contribution Tracking: Partici-
pating in Task-oriented Dialogue Under Uncertainty.
Ph.D. thesis, Rutgers, The State University of New Jer-
sey, New Brunswick, NJ.
Thierry Dutoit, Maria Astrinaki, Onur Babacan, Nicolas
d?Alessandro, and Benjamin Picart. 2011. pHTS for
Max/MSP: A streaming architecture for statistical para-
metric speech synthesis. Technical Report 1, numediart
Research Program on Digital Art Technologies, Mons,
Belgium.
Jens Edlund. 2008. Incremental speech synthesis. In
Second Swedish Language Technology Conference,
pages 53?54, Stockholm, Sweden, November. System
Demonstration.
Markus Guhe. 2007. Incremental Conceptualization for
Language Production. Lawrence Erlbaum, Mahwah,
NJ.
Christine Howes, Matthew Purver, Patrick G. T. Healey,
Gregory Mills, and Eleni Gregoromichelaki. 2011. On
incrementality in dialogue: Evidence from compound
contributions. Discourse & Dialogue, 2:279?311.
Gerard Kempen and Edward Hoenkamp. 1987. An incre-
mental procedural grammar for sentence formulation.
Cognitive Science, 11:201?258.
Anne Kilger and Wolfgang Finkler. 1995. Incremen-
tal generation for real-time applications. Technical
Report RR-95-11, Deutsches Forschungszentrum f?r
K?nstliche Intelligenz, Saarbr?cken, Germany.
Willem J. M. Levelt. 1989. Speaking: From Intention to
Articulation. The MIT Press, Cambridge, UK.
Kyoko Matsuyama, Kazunori Komatani, Ryu Takeda,
Toru Takahashi, Tetsuya Ogata, and Hiroshi G. Okuno.
2010. Analyzing user utterances in barge-in-able spo-
ken dialogue system for improving identification accu-
racy. In Proceedings of INTERSPEECH 2010, pages
3050?3053, Makuhari, Japan.
Ehud Reiter and Somayajulu Sripada. 2002. Human vari-
ation and lexical choice. Computational Linguistics,
28:545?553.
David Schlangen and Gabriel Skantze. 2009. A general,
abstract model of incremental dialogue processing. In
Proceedings of the 12th Conference of the European
Chapter of the Association for Computational Linguis-
tics, pages 710?718, Athens, Greece.
David Schlangen, Timo Baumann, Hendrik Buschmeier,
Okko Bu?, Stefan Kopp, Gabriel Skantze, and Ramin
Yaghoubzadeh. 2010. Middleware for incremental
processing in conversational agents. In Proceedings of
SIGdial 2010: the 11th Annual Meeting of the Special
Interest Group in Discourse and Dialogue, pages 51?
54, Tokyo, Japan.
Marc Schr?der and J?rgen Trouvain. 2003. The Ger-
man text-to-speech synthesis system MARY: A tool
for research, development and teaching. International
Journal of Speech Technology, 6:365?377.
Gabriel Skantze and Anna Hjalmarsson. 2010. Towards
incremental speech generation in dialogue systems. In
Proceedings of SIGDIAL 2010: the 11th Annual Meet-
ing of the Special Interest Group on Discourse and
Dialogue, pages 1?8, Tokyo, Japan.
Matthew Stone, Christine Doran, Bonnie Webber, Tonia
Bleam, and Martha Palmer. 2003. Microplanning with
communicative intentions: The SPUD system. Compu-
tational Intelligence, 19:311?381.
Matthew Stone. 2002. Lexicalized grammar 101. In
Proceedings of the ACL-02 Workshop on Effective Tools
and Methodologies for Teaching Natural Language
Processing and Computational Linguistics, pages 77?
84, Philadelphia, PA.
Paul Taylor. 2009. Text-to-Speech Synthesis. Cambridge
Univ Press, Cambridge, UK.
Tomoki Toda and Keiichi Tokuda. 2007. A speech param-
eter generation algorithm considering global variance
for HMM-based speech synthesis. IEICE TRANSAC-
TIONS on Information and Systems, 90:816?824.
Keiichi Tokuda, Takayoshi Yoshimura, Takashi Masuko,
Takao Kobayashi, and Tadashi Kitamura. 2000.
Speech parameter generation algorithms for HMM-
based speech synthesis. In Proceedings of ICASSP
2000, pages 1315?1318, Istanbul, Turkey.
Marylin Walker, Amanda Stent, Fran?ois Mairesse, and
Rashmi Prasad. 2007. Individual and domain adap-
tation in sentence planning for dialogue. Journal of
Artificial Intelligence Research, 30:413?456.
303
Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pages 314?323,
Seoul, South Korea, 5-6 July 2012. c?2012 Association for Computational Linguistics
Markov Logic Networks for
Situated Incremental Natural Language Understanding
Casey Kennington David Schlangen
CITEC Dialogue Systems Group and Faculty of Linguistics and Literary Studies
Universita?t Bielefeld, Bielefeld, Germany
ckennington@cit-ec.uni-bielefeld.de
david.schlangen@uni-bielefeld.de
Abstract
We present work on understanding natural lan-
guage in a situated domain, that is, language
that possibly refers to visually present enti-
ties, in an incremental, word-by-word fashion.
Such type of understanding is required in con-
versational systems that need to act immedi-
ately on language input, such as multi-modal
systems or dialogue systems for robots. We
explore a set of models specified as Markov
Logic Networks, and show that a model that
has access to information about the visual con-
text of an utterance, its discourse context, as
well as the linguistic structure of the utter-
ance performs best. We explore its incremen-
tal properties, and also its use in a joint pars-
ing and understanding module. We conclude
that MLNs offer a promising framework for
specifying such models in a general, possibly
domain-independent way.
1 Introduction
We speak situated in time and space. Speech by ne-
cessity unfolds sequentially in time; and in a conver-
sation, all speech but that of the opening utterance is
preceded by other speech belonging to the same con-
versation. In many, if not most, conversational situa-
tions speaker and addressee are co-located in space,
and their speech may refer to their shared situation.
Most current spoken dialogue systems attempt to
abstract from this fact, however. They work in do-
mains where physical co-location is not necessary,
such as information look-up, and they quantize time
into discrete turn units by endpointing utterances
(see discussion in (Aist et al, 2007; Schlangen and
Skantze, 2009)).
In this paper we present our current work on over-
coming these abstractions for the task of natural lan-
guage understanding (NLU). We have created a sta-
tistical model that can be trained on conversational
data and which can be used as an NLU module for
an incremental, situated dialogue system (such as
that described in (Bu? et al, 2010)). We show that
this model beats baseline approaches by a wide mar-
gin, and that making available the full set of infor-
mation comprising visual context, discourse context,
and linguistic structure gives significantly better re-
sults than any subset of these information sources on
their own.
The paper is structured as follows: we first dis-
cuss related work and introduce some background,
and then describe in detail our set of experiments,
and present and analyse our results. We close with a
general discussion of this work and possible future
extensions.
2 Related Work and Background
The work in this paper builds on, connects and ex-
tends several strands of research: grounded seman-
tics (Roy, 2005), which worries about the connec-
tion between language and the situation in which
it is used, but often does not go beyond the word
level to include linguistic structure information and
does not work incrementally;1 statistical NLU (see
e.g. (Zettlemoyer and Collins, 2009; Liang et al,
1But see (Spranger et al, 2010); for recent attempts that par-
tially overcome these limitations.
314
2011)), which tries to infer linguistic structures au-
tomatically, but normally stops at generating, not in-
terpreting semantic representations, and works with
(the text of) full utterances and not incrementally on
speech data; and incremental NLU, which is a less
intensely studied field, but where previous contri-
butions (such as (DeVault et al, 2009; Devault et
al., 2011; Aist et al, 2007; Schlangen and Skantze,
2009)) have not dealt with learned grounded seman-
tics.
We go beyond this earlier work in that we study
a model that is incremental, can use linguistic struc-
ture, and learns from conversational data a semantics
that connects the utterance to its visual and discourse
context. We have looked at individual components
of this before (grounded semantics in (Siebert and
Schlangen, 2008); incremental reference resolution
in (Schlangen et al, 2009); incremental general NLU
in (Heintze et al, 2010); interaction between incre-
mental parsing and reference resolution in (Peldszus
et al, 2012)), but use a more sophisticated model in
this work and show that tackling these tasks jointly
improves performance.
MLNSystem
Context/World
Language/RMRS
Context/Discourse
Prediction:actionobjectresult
Figure 1: NLU Data Flow
We apply Markov Logic Networks (MLNs,
(Richardson and Domingos, 2006)) as the machine
learning technique in our experiments. MLNs have
recently received attention in language processing
fields like co-reference resolution (Chen, 2009), se-
mantic role labeling (Meza-Ruiz and Riedel, 2009),
spoken (albeit neither situational nor incremental)
NLU (Meurs et al, 2008), and web information ex-
traction (Satpal et al, 2011). The framework of-
fers a convenient way of specifying factor functions
on sets of random variables for undirected graphical
models (Markov Random Fields, see (Kindermann
and Snell, 1980)), in such a way that the factors
correspond to weighted first order formulae and the
joint distribution of random variables corresponds to
probabilities of groundings of formulae. In this way,
MLNs offer a helpful bridge between symbolic rep-
resentation and stochastic inference. Weights of for-
mulae can be specified by hand or learned from data;
we used the latter capability.
Figure 1 shows data flow in our task. We use com-
binations of situated context, previous context, and
linguistic information as evidence to an MLN, and
infer what action is to be taken, what object is to be
acted upon, and specifications of the manner of exe-
cution.
3 Experiments
We will now describe our experiments with using
Markov Logic Networks for situated incremental
natural language understanding.
3.1 Data and Task
For our experiments, we used task-oriented con-
versational data from the Pentomino domain
(Ferna?ndez et al, 2007); more specifically, we
worked with the corpus also used recently in
(Heintze et al, 2010) and (Peldszus et al, 2012).
This corpus was collected in a Wizard-of-Oz study,
where the user goal was to instruct the computer to
pick up, delete, rotate or mirror puzzle tiles on a
rectangular board (as in Figure 2), and place them
onto another one. For each utterance, the corpus
records the state of the game board before the utter-
ance, the immediately preceding system action, and
the intended interpretation of the utterance (as un-
derstood by the Wizard) in the form of a semantic
frame specifying action-type and arguments, where
those arguments are objects occurring in the descrip-
tion of the state of the board. The language of the
corpus is German.
Figure 2: Example Pentomino Board
For this study, we were interested in the potential
contribution of linguistic structure to the NLU task.
315
To this end, we produced for each utterance an in-
cremental sequence of parses and corresponding se-
mantic representations (as RMRS structures (Copes-
take, 2007), i.e. underspecified semantic representa-
tions), using the parser described in (Peldszus et al,
2012). These representations were not further man-
ually checked for appropriateness, and hence do not
necessarily represent ground truth.
As in (Peldszus et al, 2012), we discarded ut-
terances without clear semantic alignments. One
major difference from them is that we do include
the 661 utterances that used pronouns to refer to
pieces, leaving us with 1687 utterances, 5.43 words
per utterance (sd 2.36), with a vocabulary of 237 dis-
tinct words. These were transcribed utterances and
not automatic speech recognition output, so our re-
sults represent an upper-bound on real world perfor-
mance.
The task that we wanted our model to tackle can
then be stated as follows: given information about
the current state of the world (i.e., the game board),
the previous system action, and about the (possibly
still not-yet completed) utterance, predict an inter-
pretation for the utterance, in the form of such a
frame. The elements of the frame may be speci-
fied separately; as argued in (Heintze et al, 2010),
this is the most appropriate format for incremental
processing since it provides a rough alignment be-
tween parts of the utterance and parts of its inter-
pretation. Figure 3 illustrates such a desired output
from the model. In more general terms, what we
want our model to learn then is how, in a given dis-
course context, language connects to the world. To
explore what information contributes to this, we will
systematically vary in our experiments what is avail-
able to the learner.
3.2 Representation
As mentioned above, Markov Logic allows the spec-
ification of knowledge bases through first order for-
mulae. A straightforward representation of the game
board would simply assert salient properties of the
individual objects such as their colour, shape, po-
sition, etc.; for the topmost object in Figure 2 this
could be colour(yellow) ? shape(g) ? pos(2, 1).
However, in pre-experiments on held-out data, we
found that a more parsimonious representation ac-
tually worked better, in which there is only one
n word interpretation
1 rotate action:rotate
2 the ...
3 yellow argument:yellow objects
4 piece argument:yellow pieces
5 next ...
6 to ...
7 the ...
8 yellow argument:yellow pieces
by yellow objects
9 plus argument:yellow piece
next to unique yellow plus
10 clockwise option:clockwise
Figure 3: Incremental interpretation of a 10-word utter-
ance. Only changes to the frame are shown, e.g. when
predictions about different frame elements are made. For
illustration, sets of objects are represented by descrip-
tions; in the system, these would be sets of object identi-
fiers.
abstract property that only implicitly does a typ-
ing into different features of the objects; again, for
the topmost piece from the figure this would be
piece(p)? property(p, yellow)? property(p, g)?
property(p, row0)?property(p, col1). This repre-
sentation follows a Davidsonian form of represent-
ing the relations between predicates.
The properties of the objects that we represented
in this way were colour, shape, its row and column,
horizontal percentage from the center and vertical
percentage from the center.
The utterance itself forms another source of in-
formation about the situation. In the simplest form,
it could be represented just through assertions of
the words which are part of it, e.g. word(rotate) ?
word(the) ? word(yellow) ? . . . . As mentioned
above, we were interested in whether a more de-
tailed linguistic analysis could provide more useful
information to a model of situated semantics; we
represented this information by extracting some of
the relations of the RMRS representation for each ut-
terance (-prefix) and converting them to a slightly
simpler form. Figure 4 shows the RMRS representa-
tion of an example utterance and the corresponding
simplified representation that we derive from it (la-
bels as defined by RMRS and quotes required by and
the MLN are removed for simplicity). We represent
words as RMRS EPs (elementary predicates); i.e., by
316
their lemma and with additional identifiers as argu-
ments, which can be used to relate the EP to other
RMRS structure. In the variants of the model that
only look at words, the other arguments can sim-
ply be ignored in the MLN template. The final ar-
gument for EP is the board identifier, which remains
unchanged during an utterance.
RMRS
a33:yellow(e34)
a19:NN(x14)
ARG1(a49,x14)
ARG2(a49,x53)
a49:nextto(e50)
BV(a52,x53)
RSTR(a52,h60)
BODY(a52,h61)
a52:def()
ARG1(a72,x53)
a72:yellow(e73)
a58:plus(x53)
MLN
EP(a33,yellow,e34,1)
EP(a19,NN,x14,1)
RMRS(ARG1,a49,x14,1)
RMRS(ARG2,a49,x53,1)
EP(a49,nextto,e50,1)
RMRS(BV,a52,x53,1)
EP(a52,def,,1)
RMRS(ARG1,a72,x53,1)
EP(a72,yellow,e73,1)
EP(a58,plus,x53,1)
Figure 4: RMRS and MLN for yellow piece next to the
yellow plus
Finally, the previous system action and, during
learning but not testing, the interpretation that is
to be predicted needs to be represented. This is
done through predicates action(), argument() and
option() for the interpretation of the current utter-
ances and corresponding predicates for that of the
previous one.
To summarise, each problem instance is hence
represented as a conjunction of predicates encoding
a) the (world) situational context (the state of the
game board), b) the discourse context (in the form
of the previous action), and c) the (possibly as-yet
partial) utterance, linguistically analysed.
3.3 Model and Decision Rule
The actual model is now formed by the MLN tem-
plates that specify the relations between the predi-
cates; in particular those between those representing
the available information (evidence) and the predi-
cates that represent the information that is to be pre-
dicted (or, in MLN terminology, whose most likely
values are to be inferred). Figure 5 illustrates graph-
ically how our model makes these connections, sep-
arately for each frame element that is to be predicted.
These graphs show that for action and
option, we assume an influence both of the words
Action
Argument
Option
PrevAction PrevOptionEP
RMRS
Property
EP
EP
Property
EP
Figure 5: MLN relations between predicates
present in the utterance (denoted by EP; see above)
and of the previous value of these slots on the cur-
rent one. The previous context that is used for train-
ing and evaluation is taken from the corpus anno-
tation files. The structure for argument is some-
what more complicated; this is where the linguis-
tic information coming from the RMRSs comes into
play, and also where the connection between lan-
guage and properties of the visual scene is made.
The actual template that defines our MLN is shown
in Figure 6.
1 EP (a1, a2,+w, a3, b) ? Action(+a, b)
2 PrevAction(+a, b) ? Action(+a, b)
3 EP (a1, a2,+w, a3, b)) ? Option(+o, b)
4 PrevOption(+o, b) ? Option(+o, b)
5 EP (a1, a2,+w, a3, b)) ? Property(p,+pr, b)
? Argument(p, b)
6 EP (a1, a2, w1, a3, b) ?RMRS(+t, a4, a3, b)
?RMRS(+t, a4, a5, b) ? EP (a5, a6, w2, a5, )
?Property(p,+pr, b) ? Argument(p, b)
Figure 6: The MLN template specifying our model
Our MLN system gives us probability distribu-
tions over all possible groundings of the frame pred-
icates, but as we are interested in single best candi-
dates (or the special value unknown, if no guess
can be made yet), we applied an additional deci-
sion rule to the output of the MLN component. If
the probability of the highest candidate is below a
threshold, unknown is returned, otherwise that can-
didate is returned. Ties are broken by random se-
lection. The thresholds for each frame element /
predicate were determined empirically on held-out
data so that a satisfactory trade-off between letting
through wrong predictions and changing correct re-
317
Type Class Acc.
Action majority put 33.55
Argument majority tile-3 20.98
Option majority na 27.08
Frame majority take, tile-3, na 3.67
Action Contextual 42.24
Table 1: Majority class and Action contextual baselines
sults to unknown was achieved.
3.4 Parameter Training Procedure, Baselines,
Metrics
All results reported below were obtained by aver-
aging results of a 10-fold validation on 1489 Pento
boards (i.e., utterances + context). We used a sep-
arate set of 168 boards for small-scale, held-out
experiments. For learning and inference we used
the Alchemy system (Domingos et al, 2006), us-
ing the discriminative training option (Singla and
Domingos, 2005).2 Inference was performed on the
Action, Argument, and Option predicates; a sin-
gle answer was derived from the distributions deliv-
ered by alchemy in the way described in the previous
section.
To be able to assess our results, we devised two
kinds of baselines for the full utterance. The sim-
plest is just the majority class. Table 1 shows ac-
curacy when choosing the majority class, both for
the frame elements individually (where this baseline
is quite high) and for the most frequent full frame
(which, unsurprisingly, only reaches a very low ac-
curacy). Action can be predicted with somewhat
more accuracy if not the overall most frequent value
is chosen but that given the previous action (i.e.,
when Action is conditioned on PreviousAction).
The accuracy for this method, where the conditional
distribution was determined on the 1489 boards and
tested on the remaining 168 boards, is shown in the
Table under ?action contextual?.
We give our results below as f-score, slot accuracy
and frame accuracy based on comparison to a gold
representation. To compute the f-score, we count a
prediction of unknown as a false negative (since for
our test utterance a value should always have been
predicted) and a wrong prediction as a false posi-
2http://alchemy.cs.washington.edu/
tive; i.e., a frame with one correct slot and the rest as
unknown has perfect precision, but only 1/3 recall.
Slot accuracy counts the number of slots that are
correct, and frame accuracy only counts fully cor-
rect frames. Hence, these metrics are successively
more strict. Which one most accurately predicts per-
formance of the model in the context of a dialogue
system depends on properties of the further compo-
nents: if they can act on partial frames, then an f-
score that start highs and continually improves as the
utterance goes on is desired; if not, then what?s rel-
evant is when in the utterance high frame accuracy
can be reached.
Using the best model variant, we further com-
pare two parsing/NLU feedback strategies, where the
feedback is to provide aid to the syntactic/RMRS
parser as to which parses to prune (as in (Peldszus
et al, 2012)). If a candidate parse does not resolve
to anything, then the parse score is degraded. (Peld-
szus et al, 2012) use a rule-based reference resolu-
tion component to provide this feedback signal. We
explore what the effects are of exchanging this for
a learned feedback strategy using our MLN model.
This model, however, does not provide discrete ref-
erent sets, but instead gives a probability distribution
over all possible pieces. We therefore simply mul-
tiplied each parse by the probability of the highest
probable piece, so that low probabilities effectively
result in pruning a parse.
On the incremental level, we followed Schlangen
et al (2009) by using a subset of their incremental
metrics, with a modification on the edit overhead:
first correct: how deep into the utterance do we
make the first correct guess?
first final: how deep into the utterance do we make
the correct guess, and don?t subsequently change our
minds?
edit overhead: ratio of unnecessary edits / sentence
length, where the only necessary edit is that going
from unknown to the final, correct result anywhere
in the sentence)
We also follow their assumption that as the sen-
tence progresses incrementally, the earlier the frame
prediction can be made, the better. This is an impor-
tant part of our threshold decision rule, because we
also assume that no decision is better than a bad de-
cision. A comparison between first correct and first
final would reveal how well this assumption is real-
318
W E R P FScore Slot Frame
5 5 5 5 92.18 88.88 74.76 1
{86.76} {81.61} {61.21}
5 5 5 81.06 72.59 34.36
{68.20} {58.61} {19.19}
5 5 5 91.63 88.03 72.68 2
{86.47} {80.69} {58.18}
5 5 75.44 65.72 22.55
5 5 5 72.29 61.61 24.56
5 5 18.15 12.10 0.0
5 5 72.34 61.67 24.63
5 18.32 12.21 0.0
5 5 5 90.68 85.68 63.75 4
5 5 68.94 56.26 0.0
5 5 90.67 85.68 63.89 3
5 69.10 56.39 0.0
5 5 72.29 61.61 24.56
5 18.15 12.10 0.0
5 72.30 61.63 24.69
18.15 12.10 0.0
Table 2: Comparison of combinations using World, EPs
(words), RMRS and Previous context. Number in brack-
ets are for tests on automatically transcribed speech.
ized. A good model would have the two numbers
fairly close together, and the prediction would be
best if both were lower, meaning good predictions
earlier in the sentence. The edit overhead further
sheds light on this distinction by showing what per-
centage of the time edits were made unnecessarily
throughout a sentence.
The procedure on the incremental level is simi-
lar to the full utterance procedure, except that for
incremental evaluation the f-score, slot accuracy,
and frame accuracies were calculated word for word
against the final gold representation.
3.5 Results
Since we were interested in the relative contributions
of our different kinds of information sources (visual
context, discourse context, words, linguistic struc-
ture), we trained and tested variant of the model de-
scribed above that had access to only parts of the full
information (by removing the appropriate predicates
from the MLN template). We report results in Table 2
for these different variants; here just as results after
the final word of the utterance, i.e., we?re not yet
Feedback Predictor FScore Slot Frame
HC HC 38.2
HC Full 92.26 88.94 74.69
none Full 92.18 88.88 74.76
Full Full 92.29 89.01 74.96
Table 3: Feedback strategies comparison for hard-coded
(HC), automatic (MLN) and no feedback (none)
looking at the incremental performance. For easier
reference, some lines are indexed with their rank ac-
cording to frame accuracy. The tope three lines also
contain a bracketed entry which represents automat-
ically transcribed utterances (also trained on manu-
ally transcribed data as in (Peldszus et al, 2012)).
First, it should be pointed out that the full model
(which has access to all information types) performs
rather well, giving a fully correct interpretation for
74% of all frames. As the somewhat higher f-score
indicates, some of the loss of frame accuracy is not
due to wrong predictions but rather to staying unde-
cided (choosing unknown)?a behaviour that could
be advantageous in some applications.
The next line shows that much of the informa-
tion required to reach this accuracy comes not from
the visual context or an analysis of the language but
from the discourse context; without access to it, ac-
curacy drops to 22%. However, the advantage of
having access to discourse context only really comes
out when access to the utterance is given as well
(rows indexed with 3 and 4, and 1 and 2). The model
that just goes by previous context can only achieve
an accuracy of 24%
Connecting discourse context to language alone
only brings accuracy to around 65% (rows 3 and 4);
only when the visual context is provided as well can
the best accuracy be reached. This is a pleasing re-
sult, as it shows that the model is indeed capable
of making the desired connection between language
and world; as none of it was not explicitly given,
which words and linguistic structure linked to which
properties was completely learned by the discrimi-
native training.
For the automatically transcribed results, all ver-
sions take a hit especially with regards to frame ac-
curacy. These also show that previous context and
linguistic structure contribute to increased perfor-
mance.
319
action 1-6 7-8 9-14
first correct (% into utt.) 4.43 9.17 6.80
first final (% into utt.) 29.47 31.57 28.47
edit overhead 4.28
argument 1-6 7-8 9-14
first correct (% into utt.) 12.12 11.14 8.08
first final (% into utt.) 38.26 36.10 30.84
edit overhead 5.72
option 1-6 7-8 9-14
first correct (% into utt.) 7.62 27.75 26.73
first final (% into utt.) 45.13 56.68 59.36
edit overhead 13.96
Table 4: Incremental Results for Action, Argument, and
Option with varying sentence lengths
3.5.1 Feedback Results
Table 3 shows the various feedback strategies. HC
refers to the hard-coded version of feedback as in
(Peldszus et al, 2012). None means no feedback
was used, which is the setting of the parser as it was
used for the RMRS structures used in Table 2. MLN
refers using our learned model to provide feedback.
The column ?Predictor? shows what model was used
to make the final prediction at the end of the utter-
ance. Overall, MLN performed much better on pre-
dicting the frame than the HC system (first row vs the
other rows); but one should keep in mind that much
of that improvement is presumably due to it having
access to discourse context.
The last three lines show that, as (Peldszus et
al., 2012) observed, providing feedback during pars-
ing does offer benefits; both HC-MLN and MLN-
MLN significantly improve over NONE-MLN (for f-
score: one-sided t(1489) = -3.313, p-value < 0.001,
and t(1489) = -3.67, p-value < 0.001, respectively;
significance-level Bonferroni corrected for multiple
comparisons; similar numbers for other metrics).
There was no significance when comparing HC with
MLN. This is an interesting result, indicating that
even though our model performs better at accurately
picking out referents, it provides a less useful feed-
back signal. This may be due to the way we com-
pute this signal; we leave further exploration to fu-
ture work.
3.5.2 Incremental Results
Table 4 shows the incremental results. Rows in-
volving first correct and first final represent aver-
age percentage into the utterance, where the utter-
ances were binned for lengths 1-6, 7-8, and 10-17
(?short?, ?normal?, ?long? utterances, respectively).
The boundaries of the bins were determined by look-
ing at the distribution of utterance lengths, which
looked like a normal distribution with 7 and 8-word
utterances having the highest representation. Our
model makes very early predictions (low first cor-
rect), but those predictions don?t always remain sta-
ble, and there is an edit overhead which leads to a
final correct decision only later in the sentence (first
final). For action and argument, the final deci-
sion is typically made within the first third of the ut-
terance. For option, it comes between the first and
second third of the sentence; this reflects typical ut-
terance structure, where the words that describe the
option (?spiegle es horizontal?; mirror it horizon-
tally) usually come later in the sentence.
A final way to show incremental progress is in
Figures 7 and 8 for sentences of ?normal? length
(7-8 words). These show how accurate the pre-
diction was for each incremental step into the sen-
tence, both for the model with and that without ac-
cess to discourse context. Where first correct and
first final help identify specific points in the process-
ing of an utterance, for this graph each incremental
step is compared with the gold result. Figure 8, for
the model variant without access to discourse con-
text, shows that there is little impact on prediction
of action or option, but a significant and con-
stant impact on the quality of predicting argument
(i.e., of doing reference resolution); this is due to
some extent to the presence of anaphoric references
which simply cannot be resolved without access to
context.
Taken together, the incremental statistics help de-
termine an ?operating point? for later modules that
consume NLU output. Under the assumption that the
ongoing utterance will be one of normal length (this
of course cannot be known in advance), the strength
with which a decision of the predictor can be be-
lieved at the current point into the utterance can be
read off the graphs.
Some discussion on speed efficiency: Using
320
lll
l l l l l l l
l l ll
0.0 0.2 0.4 0.6 0.8
0.0
0.2
0.4
0.6
0.8
1.0
% into sentence
acc
ura
cy
l action
argument
optionfscore
Figure 7: incremental accuracies
l
l
l l
l l l l l l
l l ll
0.0 0.2 0.4 0.6 0.8
0.0
0.2
0.4
0.6
0.8
1.0
% into sentence
acc
ura
cy
l action
argument
optionfscore
Figure 8: incremental accuracies, no discourse context
MLNs did not introduce any noticeable speed effi-
ciency reduction in non-feedback models. In feed-
back models which used Auto, many more calls
to MLN were used, which greatly slowed down the
model.
3.6 Model Analysis
Examining the utterances that were not correctly in-
terpreted, we found that words dealing with the ar-
gument occured most frequently, specifically words
involving spatial language where the argument was
described in relation to another piece. This is some-
what disappointing, as we were hoping that RMRS
structure might help learn such constructions.
However, basic spatial expressions were learned
successfully, as can be illustrated by Figure 9. It
shows shows the probability distributions for the ut-
terances left and bottom right, on a 5x5 board we
generated for analysis, where each field was filled
with the same kind of piece of the same colour
(thus making these properties non-distinguishing).
The darker the gradient in the Figure the higher the
probability. The Figure shows that model success-
fully marks the fields closer to the left (or bottom-
right, respectively) as having higher probability. In-
terestingly, ?left? seems to have some confusability
with ?right? for the model, indicating perhaps that
it picked up on the general type of description (?far
side?). Further investigation of model properties is
left to future work, however.
left bottom right
Figure 9: probability gradient for left and bottom right
4 Conclusions
Markov logic networks are effective in expressing
models for situated incremental natural language un-
derstanding in a domain like Pentomino. We have
shown that various aspects of situated language use,
like previous context and the current state of the
world, all play a role in NLU. We have also shown
that semantic representations like RMRS can im-
prove performance, and we further verified that in-
cremental feedback between parser and NLU can im-
prove performance (Peldszus et al, 2012). MLNs
also provide an easy-to-read trained model which
can be easily analyzed. However, there is a trade-off
in that MLNs take some time to design, which still is
an intellectual task. Furthermore, inference in MLNs
is still not as efficient as other methods, which can
cause a slowdown in applications where very many
inference steps are required, such as the feedback
model.
In future work, we will further explore how to best
integrate linguistic information from the RMRSs,
specifically in spatial language; as well as look into
improvements in speed performance. Future work
will focus on interaction with live ASR. We will also
investigate using this setup for automatically trained
natural language generation.
321
Acknowledgements: Thanks to Andreas Peld-
szus for help with data and to the reviewers.
References
Gregory Aist, James Allen, Ellen Campana, Car-
los Gomez Gallo, Scott Stoness, Mary Swift, and
Michael K. Tanenhaus. 2007. Incremental under-
standing in human-computer dialogue and experimen-
tal evidence for advantages over nonincremental meth-
ods. In Proceedings of Decalog 2007, the 11th Inter-
national Workshop on the Semantics and Pragmatics
of Dialogue, Trento, Italy.
Okko Bu?, Timo Baumann, and David Schlangen. 2010.
Collaborating on utterances with a spoken dialogue
system using an isu-based approach to incremental
dialogue management. In Proceedings of the SIG-
dial 2010 Conference, pages 233?236, Tokyo, Japan,
September.
Fei Chen. 2009. Coreference Resolution with Markov
Logic. Association for the Advancement of Artificial
Intelligence.
Ann Copestake. 2007. Semantic composition with (ro-
bust) minimal recursion semantics. In Proceedings of
the Workshop on Deep Linguistic Processing - DeepLP
?07, page 73, Morristown, NJ, USA. Association for
Computational Linguistics.
D. DeVault, Kenji Sagae, and David Traum. 2009. Can I
finish?: learning when to respond to incremental inter-
pretation results in interactive dialogue. In Proceed-
ings of the SIGDIAL 2009 Conference: The 10th An-
nual Meeting of the Special Interest Group on Dis-
course and Dialogue, number September, pages 11?
20. Association for Computational Linguistics.
David Devault, Kenji Sagae, and David Traum. 2011.
Incremental Interpretation and Prediction of Utterance
Meaning for Interactive Dialogue. Dialoge & Dis-
course, 2(1):143?170.
Pedro Domingos, Stanley Kok, Hoifung Poon, and
Matthew Richardson. 2006. Unifying logical and sta-
tistical AI. American Association of Artificial Intelli-
gence.
Raquel Ferna?ndez, Tatjana Lucht, and David Schlangen.
2007. Referring under restricted interactivity condi-
tions. In Proceedings of the 8th SIGdial Workshop on
Discourse and Dialogue, pages 136?139.
Silvan Heintze, Timo Baumann, and David Schlangen.
2010. Comparing local and sequential models for sta-
tistical incremental natural language understanding. In
Proceedings of the 11th Annual Meeting of the Special
Interest Group on Discourse and Dialogue, pages 9?
16. Association for Computational Linguistics.
Ross Kindermann and J. Laurie Snell. 1980. Markov
random fields and their applications. In In Practice,
volume 1 of Contemporary Mathematics, page 142.
American Mathematical Society.
Percy Liang, Michael Jordan, and Dan Klein. 2011.
Learning Dependency-Based Compositional Seman-
tics. In Proceedings of the 49th Annual Meeting of
the Association for Computational Linguistics: Hu-
man Language Technologies, pages 590?599, Port-
land, Oregon. Association for Computational Linguis-
tics.
Marie-jean Meurs, Frederic Duvert, Fabrice Lefevre, and
Renato De Mori. 2008. Markov Logic Networks for
Spoken Language Interpretation. Information Systems
Journal, (1978):535?544.
Ivan Meza-Ruiz and Sebastian Riedel. 2009. Jointly
identifying predicates, arguments and senses using
Markov logic. In Proceedings of Human Language
Technologies: The 2009 Annual Conference of the
North American Chapter of the Association for Com-
putational Linguistics on - NAACL ?09, number June,
page 155, Morristown, NJ, USA. Association for
Computational Linguistics.
Andreas Peldszus, Okko Bu?, Timo Baumann, and David
Schlangen. 2012. Joint Satisfaction of Syntactic
and Pragmatic Constraints Improves Incremental Spo-
ken Language Understanding. In Proceedings of the
13th Conference of the European Chapter of the As-
sociation for Computational Linguistics, pages 514?
523, Avignon, France, April. Association for Compu-
tational Linguistics.
Matthew Richardson and Pedro Domingos. 2006.
Markov logic networks. Machine Learning, 62(1-
2):107?136.
Deb Roy. 2005. Grounding words in perception and ac-
tion: computational insights. Trends in Cognitive Sci-
ences, 9(8):389?396, August.
Sandeepkumar Satpal, Sahely Bhadra, S Sundararajan
Rajeev, and Rastogi Prithviraj. 2011. Web Infor-
mation Extraction Using Markov Logic Networks.
Learning, pages 1406?1414.
David Schlangen and Gabriel Skantze. 2009. A General,
Abstract Model of Incremental Dialogue Processing.
In Proceedings of the 12th Conference of the Euro-
pean Chapter of the ACL (EACL 2009), number April,
pages 710?718, Athens, Greece. Association for Com-
putational Linguistics.
David Schlangen, Timo Baumann, and Michaela At-
terer. 2009. Incremental Reference Resolution: The
Task, Metrics for Evaluation, and a {B}ayesian Filter-
ing Model that is Sensitive to Disfluencies. In Pro-
ceedings of the SIGDIAL 2009 Conference, number
September, pages 30?37, London, UK. Association for
Computational Linguistics.
322
Alexander Siebert and David Schlangen. 2008. A Sim-
ple Method for Resolution of Definite Reference in a
Shared Visual Context. In Proceedings of the 9th SIG-
dial Workshop on Discourse and Dialogue, number
June, pages 84?87, Columbus, Ohio. Association for
Computational Linguistics.
Parag Singla and Pedro Domingos. 2005. Discrimina-
tive Training of Markov Logic Networks. Computing,
20(2):868?873.
Michael Spranger, Martin Loetzsch, and Simon Pauw.
2010. Open-ended Grounded Semantics. In Euro-
pean Conference on Artificial Intelligence 2010, Lis-
bon, Portugal. Volume 215 Frontiers in Artificial In-
telligence and Applications.
Luke S. Zettlemoyer and Michael Collins. 2009. Learn-
ing context-dependent mappings from sentences to
logical form. Proceedings of the Joint Conference of
the 47th Annual Meeting of the ACL and the 4th Inter-
national Joint Conference on Natural Language Pro-
cessing of the AFNLP: Volume 2 - ACL-IJCNLP ?09,
2:976.
323
NAACL-HLT 2012 Workshop on Future directions and needs in the Spoken Dialog Community: Tools and Data, pages 11?12,
Montre?al, Canada, June 7, 2012. c?2012 Association for Computational Linguistics
The Future of Spoken Dialogue Systems is in their Past:
Long-Term Adaptive, Conversational Assistants
David Schlangen
Faculty of Linguistics and Literary Studies
Bielefeld University, Germany
david.schlangen@uni-bielefeld.de
Abstract
A sketch of dialogue systems as long-term
adaptive, conversational agents.
1 Introduction
?Show me the lecture notes from last year?, you say
to your bow-tied virtual assistant. It does, but un-
fortunately, ?this will not do. Pull up all the new
articles I haven?t read yet?. Your assistant obliges,
pointing your attention to a ?new article from your
friend, Jill Gilbert?. A video call later, your lec-
ture preparation is done?Jill will actually give it,
via video link?and you go on with your day.
This of course describes the first scene from Ap-
ple?s ?Knowledge Navigator? concept video (Apple
Computer Inc., 1987; Colligan, 2011). Not much
of what that video showed was actually technically
possible at the time, but it captured the promise of
personalized natural language interfaces that many
people saw and hoped would be realised soon. Hav-
ing to deal with the constraints of reality, however,
research and development of spoken dialogue inter-
faces had to set itself the more modest aim of replac-
ing, in certain settings, mouse and keyboard, rather
than personal assistants.
Recent years have seen two developments that
bring that more ambitious goal back into focus.
First, the required basic technologies such as speech
recognition and speech synthesis have matured to a
state where they begin to allow the necessary flexi-
bility of spoken in- and output. Second, it has be-
come not only possible but completely unremark-
able for large portion of the population to carry with
them sensor-rich, networked computing devices?
their smartphones?during large parts of their day.
In this position paper, I?d like to sketch what
the opportunities are that this situation offers, for
the creation of dialogue systems that are long-term
adaptive and conversational, and act as assistants,
not interfaces.
2 Long-Term Adaptive ...
The fact that users carry with them the same device
(or class of devices; it only matters that access is
constant), provides the chance of repeated interac-
tions with what is understood to be the same system.
To make use of this, the system must
? learn from errors / miscommunications, by im-
proving internal models (acoustic model, language
model, semantic models: how are tasks structured
for particular user); and it must
? build up personal common ground:
? What has been refered to previously, and how?
Which tasks have been done together, and how?
? Which situations have been shared? (Where a
multi-sensor device can have detailed situational in-
formation.)
While the first point mostly describes current prac-
tice (user adaptation of speech resources), there is
much to be explored in the building up of common
ground with a technical device.
3 ... Conversational ...
Interaction with these systems must be less driven by
fixed system-intiative, and be more conversational:
? User and system must be able to mean more
than they say, by making use of context, both from
11
the ongoing conversation as well as from the com-
mon ground that was built up over previous interac-
tion.
? Systems should be responsive, incremental,
providing feedback where required; realising a tight
interaction loop, not strict turn-based exchanges.
? Things will go wrong, so error handling needs
to be graceful and natural, using the full range
of conversational repair devices (Schlangen, 2004;
Purver, 2004); including handing off tasks to other
modalities if expected success rate is low.
? Conversations express and project personality,
emotionality, sociality; systems need to model the
dynamics of this as part of their modelling of the
conversation.
Again, these are active areas of research (for re-
sponsive systems, see e.g. (Skantze and Schlangen,
2009; Bu? et al, 2010; Schlangen et al, 2010); for
error handling / acting under uncertainty, see e.g.
(Williams and Young, 2007); for social aspects of
dialogue, see e.g. (Kopp, 2010)); pulling them to-
gether in this kind of application will likely provide
new challenges and insights for all of them.
4 ... Assistants
Of course, the systems will need to provide actual
services, for it at all to come to repeated conversa-
tions. While providing the services lies outside the
domain of speech research, there are some unique
requirements that conversational access poses:
? To be usefully embeddable into conversational
systems, back-end applications are needed that are
interaction-ready; e.g., by providing confindence in-
formation about their results, and, building on this,
by suggesting ways to improve quality through ad-
ditional information.
? Not all back-end services are under the control
of the application developer or provide APIs, and the
semantic web is not going to happen. The reach of a
virtual assistant can be increased if it can be taught
to do tasks like use a website to book a train. Some
promising first work in this direction exists (Allen et
al., 2007).
5 Resources
Building dialogue systems is always hard, as many
different components need to be integrated. Systems
as sketched above bring the additional challenge of
requiring work on mobile platforms; a framework
that provides the required interfaces and infrastruc-
ture would be very helpful.
References
James F. Allen, Nathanael Chambers, George Ferguson,
Lucian Galescu, Hyuckchul Jung, Mary Swift, and
William Taysom. 2007. PLOW: A collaborative task
learning agent. In Proceedings of the National Confer-
ence on Artificial Intelligens (AAAI), Vancouver, BC,
Canada.
Apple Computer Inc. 1987. The knowledge navigator
concept video. http://youtu.be/HGYFEI6uLy0.
Okko Bu?, Timo Baumann, and David Schlangen. 2010.
Collaborating on utterances with a spoken dialogue
system using an isu-based approach to incremental
dialogue management. In Proceedings of the SIG-
dial 2010 Conference, pages 233?236, Tokyo, Japan,
September.
Bud Colligan. 2011. How the knowl-
edge navigator video came about, Nov.
http://www.dubberly.com/articles/how-the-
knowledge-navigator-video-came-about.html.
Stefan Kopp. 2010. Social resonance and embodied
coordination in face-to-face conversation with artifi-
cial interlocutors. Speech Communication, 52(6):587?
597.
Matthew Purver. 2004. The Theory and Use of Clar-
ification Requests in Dialogue. Ph.D. thesis, King?s
College, Unversity of London, London, UK, August.
David Schlangen, Timo Baumann, Hendrik Buschmeier,
Okko Bu?, Stefan Kopp, Gabriel Skantze, and Ramin
Yaghoubzadeh. 2010. Middleware for incremental
processing in conversational agents. In Proceedings
of the SIGdial 2010 Conference, pages 51?54, Tokyo,
Japan, September.
David Schlangen. 2004. Causes and strategies for re-
questing clarification in dialogue. In Proceedings of
the 5th Workshop of the ACL SIG on Discourse and
Dialogue, Boston, USA, April.
Gabriel Skantze and David Schlangen. 2009. Incre-
mental dialogue processing in a micro-domain. In
Proceedings of the 12th Conference of the European
Chapter of the Association for Computational Linguis-
tics (EACL 2009), pages 745?753, Athens, Greece,
March.
Jason Williams and Steve Young. 2007. Partially ob-
servable Markov decision processes for spoken dialog
systems. Computer Speech and Language, 21(2):231?
422.
12
NAACL-HLT 2012 Workshop on Future directions and needs in the Spoken Dialog Community: Tools and Data, pages 29?32,
Montre?al, Canada, June 7, 2012. c?2012 Association for Computational Linguistics
The INPROTK 2012 Release
Timo Baumann
Department for Informatics
University of Hamburg, Germany
baumann@informatik.uni-hamburg.de
David Schlangen
Faculty of Linguistics and Literary Studies
Bielefeld University, Germany
david.schlangen@uni-bielefeld.de
Abstract
We describe the 2012 release of our ?Incremen-
tal Processing Toolkit? (INPROTK)1, which
combines a powerful and extensible architec-
ture for incremental processing with compo-
nents for incremental speech recognition and,
new to this release, incremental speech syn-
thesis. These components work fairly domain-
independently; we also provide example imple-
mentations of higher-level components such as
natural language understanding and dialogue
management that are somewhat more tied to a
particular domain. We offer this release of the
toolkit to foster research in this new and excit-
ing area, which promises to help increase the
naturalness of behaviours that can be modelled
in such systems.
1 Introduction
As recent work has shown, incremental (or online)
processing of user input or generation of system
output enables spoken dialogue systems to produce
behaviour that is perceived as more natural than
and preferable to that produced by systems that are
bound by a turn-based processing mode (Aist et
al., 2006; Skantze and Schlangen, 2009; Bu? et al,
2010; Skantze and Hjalmarsson, 2010). There is still
much left to find out about the best ways of mod-
elling these behaviours in such systems, however.
To foster research in this area, we are releasing a
new version of our ?Incremental Processing Toolkit?
(INPROTK), which provides lower-level components
(such as speech recognition and speech synthesis,
1The code of the toolkit and some example applications
have been released as open-source at http://inprotk.
sourceforge.net.
but also a general modular processing architecture)
and allows researchers to concentrate on higher-level
modules (such as natural language understanding and
dialogue modelling; for which we provide example
implementations).2 We describe these components
in the following, pointing out the differences and
extensions to earlier releases (Baumann et al, 2010).
2 An Incremental Processing Architecture
INPROTK realises the IU-model of incremental pro-
cessing (Schlangen and Skantze, 2009; Schlangen
and Skantze, 2011), where incremental systems are
conceptualised as consisting of a network of pro-
cessing modules. Each module has a left buffer, a
processor, and a right buffer, where the normal mode
of processing is to take input from the left buffer, pro-
cess it, and provide output in the right buffer, from
where it goes to the next module?s left buffer. (Top-
down, expectation-based processing would work in
the opposite direction.) Modules exchange incremen-
tal units (IUs), which are the smallest ?chunks? of
information that can trigger connected modules into
action. IUs typically are part of larger units; e.g.,
individual words as parts of an utterance, or frame
elements as part of the representation of an utterance
meaning. This relation of being part of the same
larger unit is recorded through same level links; the
units that were used in creating a given IU are linked
to it via grounded in links. Modules have to be able
to react to three basic situations: that IUs are added
to a buffer, which triggers processing; that IUs that
were erroneously hypothesised by an earlier module
2An alternative to the toolkit described here is jindigo
(Skantze and Hjalmarsson, 2010), http://www.jindigo.
net.
29
are revoked, which may trigger a revision of a mod-
ule?s own output; and that modules signal that they
commit to an IU, that is, won?t revoke it anymore (or,
respectively, expect it to not be revoked anymore).
INPROTK offers flexibility on how tightly or
loosely modules are coupled in a system. It pro-
vides mechanisms for sending IU updates between
processes via a light-weight remote procedure call
protocol,3 as well as for using shared memory within
one (Java) process. INPROTK follows an event-based
model, where modules create events, for which other
modules can register as listeners. Module networks
are configured via a system configuration file which
specifies which modules listen to which.
As opposed to our previous release (Baumann et
al., 2010), INPROTK module communication is now
completely encapsulated in the IUModule class. An
implementing processor is called into action by a
method which gives access both to the edits to IUs
in the left buffer since the last call, and to the list of
IUs directly. The implementing processor must then
notify its right buffer, either about the edits to the
right buffer, or giving the content directly. Modules
can be fully event-driven, only triggered into action
by being notified of a hypothesis change, or they
can run persistently, in order to create endogenous
events like time-outs. Event-driven modules can run
concurrently in separate threads or can be called se-
quentially by another module (which may seem to
run counter the spirit of incremental processing, but
can be advantageous for very quick computations
for which the overhead of creating threads should be
avoided). In the case of separate threads, which run
at different update intervals, the left-buffer view will
automatically be updated to its most recent state.
INPROTK also comes with an extensive set of mon-
itoring and profiling modules which can be linked
into the module network at any point and allow to
stream data to disk or to visualise it online through a
viewing tool (von der Malsburg et al, 2009), as well
as different ways to simulate input (e.g., typed or
read from a file) for debugging. All IUmodules can
also output loggging messages to the viewing tool
directly (to ease graphic debugging of error cases in
multi-threaded applications).
3In an earlier release, we used OAA (Cheyer and Martin,
2001), which however turned out to be too slow.
3 Incremental Speech Recognition
Our speech recognition module is based on the
Sphinx-4 (Walker et al, 2004) toolkit and comes with
acoustic models for German.4 The module queries
the ASR?s current best hypothesis after each frame of
audio and changes its output accordingly, adding or
revoking WordIUs and notifying its listeners. Addi-
tionally, for each of the WordIUs, SyllableIUs and
SegmentIUs are created and bound to the word (and
to the syllable respectively) via the grounded-in hier-
archy. Later modules in the pipeline are thus able to
use this lower-level information (e.g. to disambiguate
meaning based on prosodic aspects of words). For
prosodic processing, we inject additional processors
into Sphinx? acoustic frontend which provide features
for further prosodic processing (pitch, loudness, and
spectral tilt). In this way, IUs are able to access the
precise acoustic data (in raw and processed forms).
An ASR?s current best hypothesis frequently
changes during the recognition process with the ma-
jority of the changes not improving the result. Every
such change triggers all listening modules (and pos-
sibly their listeners), resulting in a lot of unnecessary
processing. Furthermore, changes may actually dete-
riorate results, if a ?good? hypothesis is intermittently
changed for worse. Therefore, we developed hypoth-
esis smoothing approaches (Baumann et al, 2009)
which greatly reduce spurious edits in the output at
the cost of some timeliness: With a lag of 320ms we
reduced the amount of spurious edits to 10% from an
initial 90%. The current implementation of hypothe-
sis smoothing is taylored specifically towards ASR
output, but other input modules (like gesture or facial
expression recognition) could easily be smoothed
with similar methods.
4 Incremental NLU and DM
As mentioned above, the more ?higher-level? com-
ponents in our toolkit are more domain-specific than
the other components, and in any case are proba-
bly exactly those modules which users of the toolkit
may want to substitute with their own. Neverthe-
less, we provide example implementations of a sim-
ple keyword-spotting ?NLU?, as well as statistically
4Models for English, French and other languages
are available from the Sphinx? distribution and from
http://www.voxforge.org.
30
trained ones (Schlangen et al, 2009; Heintze et al,
2010).
We have recently built a somewhat more traditional
NLU component which could be more easily ported
to other domains (by adapting lexicon and grammar).
It consists of a probabilistic, beam-search top-down
parser (following (Roark, 2001)), which produces
a principled semantic representation in the formal-
ism robust minimal recursion semantics (Copestake,
2006). This component is described in more detail in
(Peldszus et al, 2012).
5 Incremental Speech Synthesis
Rounding out the toolkit is our new component for in-
cremental speech synthesis, which has the following
properties:
(a) It makes possible changes to the as-yet unspoken
part of the ongoing utterance,
(b) allows adaptations of delivery parameters such
as speaking rate or pitch with very low latency.
(c) It autonomously makes delivery-related deci-
sions (such as producing hesitations), and
(d) it provides information about delivery status (e. g.
useful in case of barge-ins).
(e) And, last but not least, it runs in real time.
Figure 1 provides a look into the internal data
structures of the component, showing a triangular
structure where on successive levels structure is built
just-in-time (e.g., turning target phoneme sequences
into vocoding parameters) and hence can be changed
with low cost, if necessary. We have evaluated the
component in an application scenario where it proved
to increase perceived naturalness, and have also stud-
ied the tradeoff between look-ahead and prosodic
quality. To this end, Figure 2 plots the deviation of
the prosodic parameters pitch and timing from that
of a non-incremental synthesis of the same utterance
versus the amount of look-ahead, that is, how far into
the current phrase the next phrase becomes known. It
shows that best results are achieved if the next phrase
that is to be synthesized becomes known no later than
one or two words into the current phrase (w0 or w1).
6 Evaluation of Incremental Processors
While not part of the toolkit proper, we think that it
can only be useful for the field to agree on common
evaluation metrics. Incremental processing brings
Figure 1: Hierarchic structure of incremental units describ-
ing an example utterance as it is being produced during
delivery, showing the event-based just-in-time processing
strategy.
0
10
20
30
l l l
l l l
w0 w1 w2 w3 wn?1 wn
l
l
pitch dev.
timing dev.
Figure 2: Deviation of pitch and timing plotted against
lookahead (right context available for incremental synthe-
sis). The more lookahead available, the better the results.
new considerations of dynamics into the assessment
of processing quality, and hence requires additional
metrics compared to non-incremental processing. In
(Baumann et al, 2011) we have proposed a family
of such metrics, and we provide an evaluation frame-
work for analysing incremental ASR performance as
part of our distribution.
7 Conclusions
We have sketched the major features of our ?Incre-
mental Processing Toolkit? INPROTK. While it is far
from offering ?plug-and-play? ease of constructing
incremental dialogue systems, we hope it will prove
useful for other researchers insofar as it offers solu-
tions to the more low-level problems that often are
not one?s main focus, but which need solving any-
ways before more interesting things can be done. We
look forward to what these interesting things may be
that others will build.
31
Acknowledgments
Most of the work decribed in this paper was funded
by a grant from DFG in the Emmy Noether Pro-
gramme.
References
G.S. Aist, J. Allen, E. Campana, L. Galescu, C.A.
Gomez Gallo, S. Stoness, M. Swift, and M Tanen-
haus. 2006. Software architectures for incremental
understanding of human speech. In Proceedings of the
International Conference on Spoken Language Process-
ing (ICSLP), Pittsburgh, PA, USA, September.
Timo Baumann, Michaela Atterer, and David Schlangen.
2009. Assessing and improving the performance of
speech recognition for incremental systems. In Pro-
ceedings of the North American Chapter of the Associa-
tion for Computational Linguistics - Human Language
Technologies (NAACL HLT) 2009 Conference, Boulder,
Colorado, USA, May.
Timo Baumann, Okko Bu?, and David Schlangen. 2010.
InproTK in action: Open-source software for building
german-speaking incremental spoken dialogue systems.
In Proceedings of ESSV 2010, Berlin, Germany.
Timo Baumann, Okko Bu?, and David Schlangen. 2011.
Evaluation and optimization of incremental processors.
Dialogue and Discourse, 2(1):113?141.
Okko Bu?, Timo Baumann, and David Schlangen. 2010.
Collaborating on utterances with a spoken dialogue
system using an isu-based approach to incremental dia-
logue management. In Proceedings of the SIGdial 2010
Conference, pages 233?236, Tokyo, Japan, September.
Adam Cheyer and David Martin. 2001. The open agent
architecture. Journal of Autonomous Agents and Multi-
Agent Systems, 4(1):143?148, March. OAA.
Ann Copestake. 2006. Robust minimal recursion se-
mantics. Technical report, Cambridge Computer Lab.
Unpublished draft.
Silvan Heintze, Timo Baumann, and David Schlangen.
2010. Comparing local and sequential models for sta-
tistical incremental natural language understanding. In
Proceedings of the SIGdial 2010 Conference, pages
9?16, Tokyo, Japan, September.
Andreas Peldszus, Okko Bu?, Timo Baumann, and David
Schlangen. 2012. Joint satisfaction of syntactic and
pragmatic constraints improves incremental spoken lan-
guage understanding. In Proceedings of the Confer-
ence of the European Association for Computational
Linguistics (EACL 2012), Avignon, France, April.
Brian Roark. 2001. Robust Probabilistic Predictive Syn-
tactic Processing: Motivations, Models, and Appli-
cations. Ph.D. thesis, Department of Cognitive and
Linguistic Sciences, Brown University.
David Schlangen and Gabriel Skantze. 2009. A general,
abstract model of incremental dialogue processing. In
Proceedings of the 12th Conference of the European
Chapter of the Association for Computational Linguis-
tics (EACL 2009), pages 710?718, Athens, Greece,
March.
David Schlangen and Gabriel Skantze. 2011. A gen-
eral, abstract model of incremental dialogue processing.
Dialogue and Discourse, 2(1):83?111.
David Schlangen, Timo Baumann, and Michaela Atterer.
2009. Incremental reference resolution: The task, met-
rics for evaluation, and a bayesian filtering model that
is sensitive to disfluencies. In Proceedings of SIGdial
2009, the 10th Annual SIGDIAL Meeting on Discourse
and Dialogue, London, UK, September.
Gabriel Skantze and Anna Hjalmarsson. 2010. Towards
incremental speech generation in dialogue systems. In
Proceedings of the SIGdial 2010 Conference, pages
1?8, Tokyo, Japan, September.
Gabriel Skantze and David Schlangen. 2009. Incremental
dialogue processing in a micro-domain. In Proceedings
of the 12th Conference of the European Chapter of
the Association for Computational Linguistics (EACL
2009), pages 745?753, Athens, Greece, March.
Titus von der Malsburg, Timo Baumann, and David
Schlangen. 2009. Telida: A package for manipulation
and visualisation of timed linguistic data. In Proceed-
ings of the Poster Session at SIGdial 2009, the 10th
Annual SIGDIAL Meeting on Discourse and Dialogue,
London, UK, September.
Willie Walker, Paul Lamere, Philip Kwok, Bhiksha Raj,
Rita Singh, Evandro Gouvea, Peter Wolf, and Joe
Woelfel. 2004. Sphinx-4: A flexible open source
framework for speech recognition. Technical Report
SMLI TR2004-0811, Sun Microsystems Inc.
32
Proceedings of the SIGDIAL 2013 Conference, pages 173?182,
Metz, France, 22-24 August 2013. c?2013 Association for Computational Linguistics
Interpreting Situated Dialogue Utterances:
an Update Model that Uses Speech, Gaze, and Gesture Information
Casey Kennington
CITEC, Bielefeld University
ckennington1
Spyros Kousidis
Bielefeld University
spyros.kousidis2
1@cit-ec.uni-bielefeld.de
2@uni-bielefeld.de
David Schlangen
Bielefeld University
david.schlangen2
Abstract
In situated dialogue, speakers share time
and space. We present a statistical model
for understanding natural language that
works incrementally (i.e., in real, shared
time) and is grounded (i.e., links to en-
tities in the shared space). We describe
our model with an example, then estab-
lish that our model works well on non-
situated, telephony application-type utter-
ances, show that it is effective in ground-
ing language in a situated environment,
and further show that it can make good use
of embodied cues such as gaze and point-
ing in a fully multi-modal setting.
1 Introduction
Speech by necessity unfolds over time, and in spo-
ken conversation, this time is shared between the
participants. Speakers are also by necessity lo-
cated, and in face-to-face conversation, they share
their (wider) location (that is, they are co-located).
The constraints that arise from this set of facts are
often ignored in computational research on spoken
dialogue, and where they are addressed, typically
only one of the two is addressed.
Here, we present a model that computes in an
incremental fashion an intention representation for
dialogue acts that may comprise both spoken lan-
guage and embodied cues such as gestures and
gaze, where these representations are grounded in
representations of the shared visual context. The
model is trained on conversational data and can be
used as an understanding module in an incremen-
tal, situated dialogue system.
Our paper begins with related work and back-
ground and then specifies in an abstract way the
task of the model. We describe our model formally
in Section 4, followed by three experiments with
the model, the first establishing it with a traditional
spoken language understanding (SLU) setting, the
second to show that our model works well under
situated conditions, and the third shows that our
model can make use of embodied cues. We fin-
ish the paper with a general discussion and future
work.
2 Related Work and Background
The work presented in this paper connects and ex-
tends several areas of research: grounded seman-
tics (Roy, 2005; Hsiao et al, 2008; Liu et al,
2012), which aims to connect language with the
world, but typically does not work incrementally;
semantic parsing / statistical natural language un-
derstanding (NLU), which aims to map an utter-
ance to its meaning representation (using vari-
ous routes and approaches, such as logical forms
(Zettlemoyer and Collins, 2007; Zettlemoyer and
Collins, 2009), dependency-based compositional
semantics (Liang et al, 2011), neural networks
(Huang and Er, 2010), Markov Logic Networks
(MLN) (Meurs et al, 2008; Meza-Ruiz et al,
2008), and dynamic Bayesian networks (Meurs
et al, 2009); see also overviews in (De Mori et
al., 2008; Wang et al, 2011)), but typically nei-
ther provides situated interpretations nor incre-
mental specifications of the representations; incre-
mental NLU (DeVault et al, 2009; DeVault et al,
2011; Aist et al, 2007; Schlangen and Skantze,
2009), which focuses on incrementality, but not
on situational grounding; integration of gaze into
language understanding (Prasov and Chai, 2010),
which was not incremental.
We move beyond this work in that we present a
model that is incremental, uses a form of grounded
semantics, can easily incorporate multi-modal in-
formation sources, and finally on which inference
can be performed quickly, satisfying the demands
of real-time dialogue. The model brings together
aspects we?ve previously looked into separately:
grounded semantics in (Siebert and Schlangen,
173
2008); incremental interpretation (reference res-
olution) in (Schlangen et al, 2009); incremental
general NLU in (Heintze et al, 2010); and a more
sophisticated approach that handled all of these us-
ing markov logic networks, but did not work in
real-time or with multi-modal input (Kennington
and Schlangen, 2012).
3 The Task
The task for our model is as follows: to compute at
any moment a distribution over possible intentions
(expressed as semantic frames), given the unfold-
ing utterance and possibly information about the
state of the world in which the utterance is hap-
pening. The slots of these frames are to be filled
with semantic constants, that is, they are uniquely
resolved; if appropriate, to objects in the shared
environment.
This is illustrated in Figure 1, where for
three successive incremental units (Schlangen and
Skantze, 2009) (that is, successively available bits
of information pertaining to the same act, such as
words of an utterance, or information about speech
accompanying gesture) three distributions over in-
tentions are shown.1
[   ]
fe: a
[   ]
fe: b
[   ]
fe: a
IU
1
IU
2
IU
3
Donnerstag, 2. Mai 2013
Figure 1: Schematic Illustration of Task
4 Our Model
More formally, the goal of the model is to recover
I , the intention of the speaker behind her utter-
ance, in an incremental fashion, that is, word by
word. We make the assumption that the set of
possible intentions is finite, and that they consist
of (combinations of) entities (where however even
actions like taking are considered ?entities?; more
on this below). We observe U , the current word
that the speaker uttered as part of their utterance
(and features derived from that). We also assume
that there is an unobserved mediating variable R,
1Here, no links between these intention representations
are shown. The model we present in the next section is
an update model, that is, it builds the representation at step
tn based on that at tn?1; other possibilities are explored in
(Heintze et al, 2010) and (Kennington and Schlangen, 2012).
which represents the (visual or abstract) proper-
ties of the (visually present, or abstract) object
of the intention. So, what we need to calculate
is P (I|U,R), even though ultimately we?re inter-
ested only in P (I|U). By definition of conditional
probability, P (I|U,R) = P (I, U,R)?P (U,R)?1.
We factorise P (I, U,R) as indicated in the follow-
ing:
P (I|R,U) = P (R|I)P (I)P (U |R)P (U,R) (1)
That is, we make the assumption that R is con-
ditional only on I , and U is conditional only on
R. Marginalizing over R gets us the model we?re
interested in (and it amounts to a not uncommon
tagging model with a hidden layer):
P (I|U) = P (I)
?
r?R
P (U |R = r)P (R = r|I)
P (U,R = r)
(2)
Where we can move P (I) out of the summation,
as it is not dependent on R. Hence, we need three
models, P (I), P (U |R) and P (R|I), to compute
P (I|U). Figure 2 shows how these three models
interact over time.
It?2
Rt?2
Ut?2
It?1
Rt?1
Ut?1
It
Rt
Ut
Figure 2: Our model represented as an unrolled
DBN over three words.
Each sub-model will now be explained.
P(I) At the beginning of the computation for an
incoming sentence, we set the prior P (I) to a uni-
form distribution (or, if there is reason to do so, a
different distribution to encode initial expectations
about intentions; i.e., prior gaze information). For
later words, it is set to the posteriori of the pre-
vious step, and so this constitutes a Bayesian up-
dating of belief (with a trivial, constant transition
model that equates P (It?1) and P (It)).2
2In that sense, our incremental understanding could be
called ?intra-sentential belief tracking,? in analogy to the cur-
rent effort to track system belief about user intentions across
turns (Ma et al, 2012; Williams, 2010).
174
The other models represent knowledge about
links between intentions and object properties,
P (R|I), and knowledge about language use,
P (U |R). We now explain how this knowledge is
acquired.
P(R|I) The model P (R|I) provides the link be-
tween objects (as occurring in the intentions) and
their properties. Here we follow, to our knowl-
edge, a novel approach, by deriving this distribu-
tion directly from the scene representation. This
is best explained by looking at the overall model
in a generative way. First, the intention is gener-
ated, P (I), then based on that a property, P (R|I).
We assume that with equal probability one of the
properties that the intended object actually has is
picked to be verbalised, leaving zero probability
for the ones that it does not have. This in a way is
a rationality assumption: a rational speaker will, if
at all, mention properties that are realised and not
others (at least in non-negative contexts).
P(U|R), learned directly The other model,
P (U |R), can be learned directly from data by
(smoothed) Maximum Likelihood estimation. For
training, we assume that the property R that is
picked out for verbalisation is actually observable.
In our data, we know which properties the refer-
ent actually has, and so we can simply count how
often a word (and its derived features) co-ocurred
with a given property, out of all cases where that
property was present.
P(U|R), via P(R|U) Instead of directly learn-
ing a model of the data, we can learn a discrimina-
tive model that connects words and properties.
In Equation 2, we can rewrite P (U |R) using
Bayes? Rule:
P (I|U) = P (I)
?
r?R
P (U)P (R = r|U)P (R = r|I)
P (R = r)P (U,R = r) (3)
P (U) is a constant when computing P (I|U) for
all possible values of I whose actual value does
not change the rank of each intention, and so can
be dropped. P (R) can be approximated with a
uniform distribution, and can also be dropped,
yielding:
P (I|U) = P (I)
?
r?R
P (R = r|U)P (R = r|I)
P (U,R = r)
(4)
Other models could also be learned here; we chose
a discriminative model to show that our model
works under varied circumstances.
word red round square green
the 0.03 0.02 0.02 0.02
red 0.82 0.009 0.09 0.01
ball 0.02 0.9 0.02 0.07
Table 1: P (U |R) for our toy domain for some
values of U and R; we assume that this model is
learned from data (columns are excerpted from a
distribution over a larger vocabulary).
int. red round square green
obj1 0.5 0.5 0 0
obj2 0.5 0 0.5 0
Table 2: P (R|I), for our example domain.
Properties An important part of our model is
the set of properties. Properties can be visual
properties such as color or shape or spatial prop-
erties (left-of, below, etc.). Though not the fo-
cus of this paper, they could also be concep-
tual properties (the verb run can have the proper-
ties of movement, use of legs, and quick).
Another example, New York has the property of
being New York. (That is generally sufficient
enough to denote New York, but note that descrip-
tive properties (e.g., ?location of the Empire State
Building?) could be used as well.) The purpose
of the properties is to ground intentions with lan-
guage in a more fine-grained way than the words
alone.
We will now give an example of the generative
approach as in Equation 2 (it is straight-forward to
do the same for the discriminative model).
4.1 Example
The task is reference resolution in a shared visual
context: there is an intention to refer to a visible
object. For this example, there are two objects
obj1 and obj2, and four properties to describe
those objects, red, round, square and green.
The utterance for which we want to track a dis-
tribution over possible referents, going word-by-
word, is the red ball. obj1 happens to be a red
ball, with properties red and round; obj2 is a
red cube, with the properties red and square.
We now need the models P (U |R) and P (R|I).
We assume the former is learned from data, and
for the four properties and three words gives us re-
sults as shown in Table 1 (that is, P (U = the|R =
red) = 0.03). The model P (R|I) can be read off
the representation of the scene: if you intend to
175
refer to object obj1 (I = obj1), you can either
pick the property red or the property round, so
both get a probability of 0.5 and all others 0; sim-
ilar for obj2 and red and square (Table 2).
Table 3 now shows an application of the full
model to our example utterance. The cells
in the columns labeled with properties show
P (U |R)P (R|I) for the appropriate properties and
intentions (objects), the column ? shows results
after marginalizing over R. The final column then
factors in P (I) with a uniform prior for the first
word, and the respectively previous distribution
for all others, and normalises.
I U red rnd. sq. ? P (I|U)
obj1 the .015 .01 0 .025 .5
obj2 .015 0 .01 .025 .5
obj1 red .41 .0045 0 .41 .47
obj2 .41 0 .045 .46 .53
obj1 ball .01 .45 0 .46 .96
obj2 .01 0 .01 .02 .04
Table 3: Application of utterance the red ball,
where obj1 is the referred object
As these numbers show, the model behaves as
expected: up until ball, the utterance does not
give enough information to decide for either ob-
ject probabilities are roughly equal, once ball is
uttered obj1 is the clear winner.
This illustrated how the model works in princi-
ple and showed that it yields the expected results
in a simple toy domain. In the next section we will
show that this works in more realistic domains.
5 Experiments
Our model?s task is to predict a semantic frame,
where the required slots of the frame are known
beforehand and each slot value is predicted us-
ing a separate model P (I|U). We realise P (U |R)
as a Naive Bayes classifier (NB) which counts co-
occurrences of utterance features (words, bigrams,
trigrams; so U is actually a tuple, not a single vari-
able) and properties (but naively treats features as
independent), and which is smoothed using add-
one smoothing. As explained earlier, P (I) repre-
sents a uniform distribution at the beginning of an
utterance, and the posteriori of the previous step,
for later words. We also train a discriminative
model, P (R|U), using a maximum entropy classi-
fier (ME) using the same features as NB to classify
properties.3
3http://opennlp.apache.org/
5.1 A Non-Situated Baseline using ATIS
We performed an initial test of our model using
a corpus in traditional NLU: the air travel infor-
mation system (ATIS) corpus (Dahl et al, 1994)
using the pre-processed corpus as in (Meza-Ruiz
et al, 2008). In ATIS, the main task is to predict
the slot attributes (the values were simply words
from the utterance); however, the GOAL slot (rep-
resenting the overall utterance intent) was was al-
ways present, the value of which required a predic-
tion. We tested our model?s ability to predict the
GOAL slot (using very simple properties; the prop-
erty of a GOAL intention is itself, i.e., the property
of flight is flight) and found encouraging re-
sults (the GOAL slot baseline is 71.6%, see (Tur et
al., 2010); our NB and ME models obtained scores
of 77% and 77.9% slot value prediction accura-
cies, respectively). How our model works under
more complicated settings will now be explained.
5.2 Puzzle Domain: Speech-Only
Figure 3: Example
Pentomino Board
?
??
ACTION rotate
OBJECT object-4
RESULT clockwise
?
??
Figure 4: Pento
frame example
Data and Task The Pentomino domain
(Ferna?ndez et al, 2007) contains task-oriented
conversational data; more specifically, we worked
with the corpus also used recently in (Heintze et
al., 2010; Peldszus et al, 2012; Kennington and
Schlangen, 2012). This corpus was collected in
a Wizard-of-Oz study, where the user goal was
to instruct the computer to pick up, delete, rotate
or mirror puzzle tiles on a rectangular board (as
in Figure 3), and place them onto another one.
For each utterance, the corpus records the state of
the game board before the utterance, the immedi-
ately preceding system action, and the intended
interpretation of the utterance (as understood
by the Wizard) in the form of a semantic frame
specifying action-type and arguments, where
those arguments are objects occurring in the
description of the state of the board. The language
of the corpus is German. An example frame is
given in Figure 4.
176
The task that we want our model to perform is
as follows: given information about the state of
the world (i.e., game board), previous system ac-
tion, and the ongoing utterance, predict the values
of the frame. To this end, three slot values need
to be predicted, one of which links to the visual
scene. Each slot value will be predicted by an in-
dividual instantiation of our model (i.e., each has
a different I to predict). Generally, we want our
model to learn how language connects to the world
(given discourse context, visual context, domain
context, etc.). We used a combination of visual
properties (color, shape, and board position), and
simple properties to ground the utterance with I .
Our model gives probability distributions over
all possible slot values, but as we are interested
in single best candidates (or the special value
unknown if no guess can be made yet), we ap-
plied an additional decision rule to the output of
our model. If the probability of the highest candi-
date is below a threshold, unknown is returned,
otherwise that candidate is returned. Ties are bro-
ken by random selection. The thresholds for each
slot value were determined empirically on held-
out data so that a satisfactory trade-off between
letting through wrong predictions and changing
correct results to unknown was achieved.
Procedure All results were obtained by aver-
aging the results of a 10-fold validation on 1489
Pento boards (i.e., utterances+context, as in (Ken-
nington and Schlangen, 2012)). We used a sep-
arate set of 168 boards for small-scale, held-out
experiments. As this data set has been used
in previous work, we use previous results as
baselines/comparisons. For incremental process-
ing, we used InproTK (Baumann and Schlangen,
2012).4
On the incremental level, we followed
(Schlangen et al, 2009) and (Kennington and
Schlangen, 2012) for evaluation, but use a subset
of their incremental metrics, with a modification
on the edit overhead:
first correct: how deep into the utterance do we
make the first correct guess?
first final: how deep into the utterance do we
make the correct guess, and don?t subsequently
change our minds?
edit overhead: what is the ratio of unnecessary
edits / sentence length, where the only necessary
edit is that going from unknown to the final,
4http://sourceforge.net/projects/inprotk/
correct result anywhere in the sentence)?
Results The results for full utterances are given
in Table 4. Both of our model types work better
than (Heintze et al, 2010) which used support vec-
tor machines and conditional random fields, and
(Peldszus et al, 2012) which was rule-based (but
did not include utterances with pronouns like we
do here). The NB version did not work well in
comparison to (Kennington and Schlangen, 2012)
which used MLN, but the ME version did in most
metrics. Overall these are nice results as they
are achieved using a more straightforward model
with rather simple features (with room for exten-
sions). Another welcome result is performance
from noisy data (trained and evaluated on automat-
ically transcribed speech; ASR); the ME version of
our model is robust and performs well in compar-
ison to previous work.
NB ME K H P
fscore 81.16 92.26 92.18 76.9
(74.5) (89.4) (86.8)
slot 73.62 88.91 88.88
(66.4) (85.1) (81.6)
frame 42.57 74.08 74.76
(34.2) (67.2) (61.2)
action 80.05 93.62 92.62
object 76.27 90.79 84.71 64.3
result 64.4 82.34 86.65
Table 4: Comparison of results from Pento: Naive
Bayes NB, Maximum Entropy ME, (Kennington
and Schlangen, 2012) K, (Heintze et al, 2010)
H, (Peldszus et al, 2012) P; values in parenthe-
ses denote results from automatically transcribed
speech.
A big difference between our current model
and MLN is the way incrementality is realised:
MLN was restart incremental in that at each incre-
ment, features from the full utterance prefix were
used, not just the latest word; the present model is
fully incremental in that a prior belief is updated
based only on the new information. This, how-
ever, seems to lead our model to perform with less
accuracy for the result slot, which usually oc-
curs at the end of the sentence.
Incremental Table 5 shows the incremental
results in the same way as (Kennington and
Schlangen, 2012). Utterances are binned into
short, normal, and long utterance lengths (1-6,
7-8, 9-17 words, respectively) as determined by
looking at the distribution of utterance lengths,
which appeared as a normal distribution with 7 and
177
das graue Teil in der ersten Reihe nehmen
Figure 5: Example of reference resolution for the utterance: das graue Teil in der ersten Reihe nehmen /
the gray piece in the first row take; lighter cell background means higher probability assigned to piece.
8-word utterances having highest representation.
In comparison with (Kennington and Schlangen,
2012), our model generally takes longer to come
to a first correct for action, but is earlier for the
other two slots. For first final, our model always
takes longer, albeit with lower edit overhead. This
tells us that our model is more careful than the
MLN one; it waits longer before making a final de-
cision and it doesn?t change its mind as much in
the process, which arguably is desired behaviour
for incremental systems.
action 1-6 7-8 9-14
first correct (% into utt.) 5.78 2.56 3.64
first final (% into utt.) 38.26 36.10 30.84
edit overhead 2.37
object 1-6 7-8 9-14
first correct (% into utt.) 7.39 7.5 10.11
first final (% into utt.) 44.7 44.18 35.55
edit overhead 4.6
result 1-6 7-8 9-14
first correct (% into utt.) 15.16 23.23 20.88
first final (% into utt.) 42.55 40.57 35.21
edit overhead 10.19
Table 5: Incremental Results for Pento slots with
varying sentence lengths.
Figure 5 illustrates incremental performance by
showing the distribution over the pieces (using the
ME model; lighter means higher probability) for
the utterance das graue Teil in der ersten Reihe
nehmen (the gray piece in the first row take / take
the gray piece in the first row) for each word in
the utterance. When the first word, das is uttered,
it already assigns probabilities to the pieces with
some degree of confidence (note that in German,
das (the) denotes the neuter gender, and the piece
on the right with the lowest probability is often re-
ferred to by a noun (Treppe) other than neuter).
Once graue (gray) is uttered, the distribution is
now more even upon the three gray pieces, which
remains largely the same when Teil (piece) is ut-
tered. The next two words, in der (in the) give
more probability to the left gray piece, but once er-
sten Reihe (first row) is uttered, the most probable
piece becomes the correct one, the second piece
from the left on the top.
5.3 Puzzle Domain: Speech, Gaze and Deixis
Data and Task Our final experiment uses newly
collected data (Kousidis et al, 2013), again from
the Pentomino domain. In this Wizard-of-Oz
study, the participant was confronted with a Pento
game board containing 15 pieces in random col-
ors, shapes, and positions, where the pieces were
grouped in the four corners of the screen (exam-
ple in Figure 6). The users were seated at a table
in front of the screen. Their gaze was then cali-
brated with an eye tracker (Seeingmachines Face-
Lab) placed above the screen and their arm move-
ments (captured by a Microsoft Kinect, also above
the screen) were calibrated by pointing to each
corner of the screen, then the middle of the screen.
They were then given task instructions: (silently)
choose a Pento tile on the screen and then instruct
the computer game system to select this piece by
describing and pointing to it. When a piece was se-
lected (by the wizard), the participant had to utter
a confirmation (or give negative feedback) and a
new board was generated and the process repeated
(each instance is denoted as an episode). The ut-
terances, board states, arm movements, and gaze
information were recorded, as in (Kousidis et al,
2012). The wizard was instructed to elicit point-
ing gestures by waiting to select the participant-
referred piece by several seconds, unless a point-
ing action by the participant had already occurred.
When the wizard misunderstood, or a technical
problem arose, the wizard had an option to flag
the episode. In total, 1214 episodes were recorded
from 8 participants (all university students). All
but one were native speakers; the non-native spoke
proficient German (see Appendix for a set of ran-
dom example utterances).
The task in this experiment was reference res-
olution (i.e., filling a single-slot frame). The in-
formation available to our model for these data
include the utterance (ASR-transcribed and repre-
sented as words, bigrams, and trigrams), the vi-
178
Figure 6: Example Pento board for gaze and deixis
experiment; yellow piece in the top-right quadrant
has been ?selected? by the wizard after the partic-
ipant utterance.
sual context (game board), gaze information, and
deixis (pointing) information, where a rule-based
classifier predicted from the motion capture data
the quadrant of the screen at which the participant
was pointing. These data were very noisy (and
hence, realistic) despite the constrained conditions
of the task: the participants were not required to
say things a certain way (as long as it was under-
stood by the wizard); their hand movements poten-
tially covered their faces which interfered with the
eye tracker; each participant had a different way of
pointing (each had their own gesture space, hand-
edness, distance of hand from body when point-
ing, alignment of hand with face, etc.). Also, the
episodes were not split into individual utterances,
but rather interpreted as one; this indicates that the
model can deal with belief tracking over whole in-
teractions (here, if the wizard did not respond, the
participant had to clarify her intent in some way,
producing a new utterance).
Procedure Removing the flagged utterances and
the utterances of one of the participants (who had
misunderstood the task) left us with a total of 1051
utterances. We used 951 for development (fine-
tuning of parameters, see below), and 100 for eval-
uation. Evaluation was leave-one-out (i.e., 100
fold cross validation) where the training data were
all other 1050 utterances. For this experiment, we
only used the ME model as it performed much bet-
ter in the previous experiment. We give results
as resolution accuracy. We incorporate gaze and
deixis information in two ways: (1) We computed
the distribution over tiles gazed at, and quadrant
of the screen pointed at during the interval before
and during an utterance. The distributions were
then combined at the end of the utterance with the
NLU distribution (denoted as Gaze and Point); that
is, Gaze and Point had their own P (I) which were
evenly interpolated with the INLU P (I|U), and (2)
we incrementally computed properties to be pro-
vided to our INLU model; i.e., a tile has a prop-
erty in R of being looked at if it is gazed at for
some interval of time, or tiles in a quadrant of the
screen have the property of being pointed at.
These models are denoted as Gaze-F and Point-F.
As an example, Figure 7 shows an example utter-
ance, gaze, and gesture activity over time and how
they are reflected in the model (the utterance is the
observed U , where the gaze and gesture become
properties in R for the tiles that they affect). Our
baseline model is the NLU without using gaze or
deixis information; random accuracy is 7%.
We also include the percentage of the time
the gold tile is in the top 2 and top 4 rankings
(out of 15); situations in which a dialogue sys-
tem could at least provide alternatives in a clar-
ification request (if it could detect that it should
have low confidence in the best prediction; which
we didn?t investigate here). Importantly, these re-
sults are achieved with automatically transcribed
utterances; hand transcriptions do not yet exist for
these data. For gaze, we also make the naive as-
sumption that over the utterance the participant
(who in this case is the speaker) will gaze at his
chosen intended tile most of the time.
Figure 7: Human activity (top) aligned with how
modalities are reflected in the model for Gaze-F
and Point-F (bottom) over time for example utter-
ance: take the yellow tile.
Results See Table 6 for results. The models that
have access to gaze and pointing gestures can re-
solve better than those that do not. Our findings
are consistent in that referential success with gaze
alone approaches 20% (a rate found by (Pfeiffer,
2010) in a different setting). Another interest-
ing result is that the Gaze-F and Point-F variants,
that continuously integrate multi-modal informa-
tion, perform the same as or better than their non-
incremental counterparts (where the distributions
are weighted once at the end of the utterance).
179
Version Acc Top 2 Top 4
Gaze 18%
(baseline) NLU 50% 59% 77%
NLU + Gaze 53% 62% 80%
NLU + Point 52% 65% 90%
NLU + Gaze + Point 53% 70% 91%
NLU + Gaze-F 53% 65% 78%
NLU + Point-F 57% 68% 88%
NLU+Gaze-F+Point-F 56% 69% 85%
Table 6: Accuracies for reference resolution task
when considering NLU, gaze and pointing infor-
mation before and during the utterance (Gaze and
Point), and gaze and pointing information when
considered as properties to the NLU model (Gaze-
F and Point-F).
Incremental We also include incremental re-
sults when using gaze and deixis. We binned the
sentences in the same way as in the previous ex-
periment (the distribution of sentence lengths was
similar). Figure 8 shows how the NLU model base-
line, the (NLU+) Gaze-F, Point-F, and Gaze-F +
Point-F models perform incrementally for utter-
ances of lengths 7-8. All models increase mono-
tonically, except for Point-F at one point in the ut-
terance and Gaze-F at the end. It would appear that
the gaze as an information source is a good early
indicator of speaker intent, but should be trusted
less as the utterance progresses. Deixis is more
trustworthy overall, and the two taken together of-
fer a more stable model. Table 7 shows the re-
sults using the previously explained incremental
metrics. All models have little edit overhead, but
don?t make the correct final decision until well into
the utterances. This was expected due to the noisy
data. A consumer of the output of these models
would need to wait longer to trust the results given
by the models (though the number of words of the
utterance can never be known beforehand).
6 Discussion and Conclusions
We presented a model for the interpretation of
utterances in situated dialogue that a) works in-
crementally and b) can ground meanings in the
shared context. Taken together, the three experi-
ments we?ve reported give good evidence that our
model has the potential to be used as a success-
ful NLU component of an interactive dialogue sys-
tem. Our model can process at a speed which is
faster than the ongoing utterance, which will al-
low it to be useful in real-time, interactive exper-
iments. And, crucially, our model is able to inte-
Figure 8: Incremental process for referential accu-
racy; comparing NLU, Gaze-F, Point-F, and Gaze-
F + Point-F for utterances of length 7-8.
NLU 1-6 7-8 9-14
first correct (% into utt.) 22.2 37.2 30
first final (% into utt.) 82.4 82.4 74.8
edit overhead 2.95
Gaze-F 1-6 7-8 9-14
first correct (% into utt.) 23 32 31.1
first final (% into utt.) 84.1 81.5 75.4
edit overhead 2.89
Point-F 1-6 7-8 9-14
first correct (% into utt.) 21.4 30 23.3
first final (% into utt.) 83.5 80 72.3
edit overhead 2.59
Gaze-F + Point-F 1-6 7-8 9-14
first correct (% into utt.) 16.7 31 28
first final (% into utt.) 81.5 81 73.9
edit overhead 2.67
Table 7: Incremental results for Pento slots with
varying sentence lengths.
grate information from various sources, including
gaze and deixis. We expect the model to scale to
larger domains; the number of computations that
are required grows with |I| ? |R|.
Our model makes use of properties which are
used to connect an utterance to an intention.
Knowing which properties to use requires empir-
ical testing to determine which ones are useful.
We are working on developing principled meth-
ods for selecting such properties and their con-
tribution (i.e., properties should not be uniform).
Future work also includes better use of linguistics
(instead of just n-grams), building a more sophis-
ticated DBN model that has fewer independence
assumptions, e.g. tracking properties as well by
making Rt depended on Rt?1. We are also in
the process of using the model interactively; as a
proof-of-concept, we were trivially able to plug it
into an existing dialogue manager for Pento do-
mains (see (Bu? et al, 2010)).
180
Acknowledgements: Thanks to the anony-
mous reviewers for their useful comments and
feedback. This work was partially funded through
a DFG Emmy Noether grant.
Appendix A: Example Utterances (Pento
Speech)
1. nimm die Bru?cke in der oberen Reihe
2. nimm das Teil in der mittleren Reihe das zweite
Teil in der mittleren Reihe
3. und setz ihn in die Mitte links
4. dreh das nach links
5. a?hm und setz ihn oben links in die Ecke
6. nimm bitte den gelben Winkel oben
7. bewege das Ka?stchen die Treppe unten links
8. lo?sche das Teil in der Mitte
9. nimm die gelbe Kru?cke aus der zweiten Reihe
oben
10. und verschiebe es in die erste Zeile dritte
Spalte
Appendix B: Example Utterances (Speech,
Gaze and Deixis)
(as recognised by the ASR)
1. dieses teil genau st es oben links t
2. das t mit vier rechts oben ist d es direkt hier
rechts
3. gru?ne von rechts uh fla?che
4. das obere gru?ne za?hl hm so es obersten hohles
e rechts oben ecke
5. a?hm das hintere kreuz unten links rechts rechts
6. a?h das einzige blaue symbol oben rechts
7. das einzige gru?n okay oben rechts
8. hm innerhalb diesem blauen striche vorne hm
so genau in die genau rechts
9. und das sind dann nehmen diese fu?nf zeichen
oben na?mlich genau das in der mitte so
10. oben links is die untere
References
Gregory Aist, James Allen, Ellen Campana, Car-
los Gomez Gallo, Scott Stoness, Mary Swift, and
Michael K Tanenhaus. 2007. Incremental under-
standing in human-computer dialogue and experi-
mental evidence for advantages over nonincremen-
tal methods. In Proceedings of Decalog (Semdial
2007), Trento, Italy.
Timo Baumann and David Schlangen. 2012. The In-
proTK 2012 Release. In NAACL.
Okko Bu? Timo Baumann, and David Schlangen.
2010. Collaborating on Utterances with a Spoken
Dialogue System Using an ISU-based Approach to
Incremental Dialogue Management. In Proceedings
of SIGdial, pages 233?236.
Deborah A Dahl, Madeleine Bates, Michael Brown,
William Fisher, Kate Hunicke-Smith, David Pallett,
Christine Pao, Alexander Rudnicky, and Elizabeth
Shriberg. 1994. Expanding the scope of the ATIS
task: the ATIS-3 corpus. In Proceedings of the
workshop on Human Language Technology, HLT
?94, pages 43?48, Stroudsburg, PA, USA. Associ-
ation for Computational Linguistics.
Renato De Mori, Frederic Be?chet, Dilek Hakkani-tu?r,
Michael Mctear, Giuseppe Riccardi, and Gokhan
Tur. 2008. Spoken Language Understanding. IEEE
Signal Processing Magazine, pages 50?58, May.
David DeVault, Kenji Sagae, and David Traum. 2009.
Can I finish?: learning when to respond to incremen-
tal interpretation results in interactive dialogue. In
Proceedings of the 10th SIGdial, pages 11?20. As-
sociation for Computational Linguistics.
David DeVault, Kenji Sagae, and David Traum. 2011.
Incremental Interpretation and Prediction of Utter-
ance Meaning for Interactive Dialogue. Dialogue &
Discourse, 2(1):143?170.
Raquel Ferna?ndez, Tatjana Lucht, and David
Schlangen. 2007. Referring under restricted
interactivity conditions. In Proceedings of the 8th
SIGdial, pages 136?139.
Silvan Heintze, Timo Baumann, and David Schlangen.
2010. Comparing local and sequential models for
statistical incremental natural language understand-
ing. In Proceedings of the 11th SIGdial, pages 9?16.
Association for Computational Linguistics.
Kai-yuh Hsiao, Soroush Vosoughi, Stefanie Tellex,
Rony Kubat, and Deb Roy. 2008. Object schemas
for grounding language in a responsive robot. Con-
nection Science2, 20(4):253?276.
Guangpu Huang and Meng Joo Er. 2010. A Hybrid
Computational Model for Spoken Language Under-
standing. In 11th International Conference on Con-
trol, Automation, Robotics, and Vision, pages 7?10,
Singapore. IEEE.
Casey Kennington and David Schlangen. 2012.
Markov Logic Networks for Situated Incremental
Natural Language Understanding. In Proceedings
of the 13th SIGdial, pages 314?323, Seoul, South
Korea, July. Association for Computational Linguis-
tics.
Spyros Kousidis, Thies Pfeiffer, Zofia Malisz, Petra
Wagner, and David Schlangen. 2012. Evaluat-
ing a minimally invasive laboratory architecture for
recording multimodal conversational data. In Proc.
of the Interdisciplinary Workshop on Feedback Be-
haviours in Dialogue.
181
Spyros Kousidis, Casey Kennington, and David
Schlangen. 2013. Investigating speaker gaze and
pointing behaviour in human-computer interaction
with the mint.tools collection. In Proceedings of the
14th SIGdial.
Percy Liang, Michael Jordan, and Dan Klein. 2011.
Learning Dependency-Based Compositional Se-
mantics. In Proceedings of the 49th ACLHLT, pages
590?599, Portland, Oregon. Association for Compu-
tational Linguistics.
Changsong Liu, Rui Fang, and Joyce Chai. 2012. To-
wards Mediating Shared Perceptual Basis in Situ-
ated Dialogue. In Proceedings of the 13th SIGdial,
pages 140?149, Seoul, South Korea, July. Associa-
tion for Computational Linguistics.
Yi Ma, Antoine Raux, Deepak Ramachandran, and
Rakesh Gupta. 2012. Landmark-Based Location
Belief Tracking in a Spoken Dialog System. In Pro-
ceedings of the 13th SIGdial, pages 169?178, Seoul,
South Korea, July. Association for Computational
Linguistics.
Marie-Jean Meurs, Frederic Duvert, Fabrice Lefevre,
and Renato De Mori. 2008. Markov Logic Net-
works for Spoken Language Interpretation. Infor-
mation Systems Journal, pages 535?544.
Marie-Jean Meurs, Fabrice Lefe`vre, and Renato De
Mori. 2009. Spoken Language Interpretation: On
the Use of Dynamic Bayesian Networks for Seman-
tic Composition. In IEEE International Conference
on Acoustics, Speech, and Signal Processing, pages
4773?4776.
Ivan Meza-Ruiz, Sebastian Riedel, and Oliver Lemon.
2008. Accurate Statistical Spoken Language Un-
derstanding from Limited Development Resources.
In IEEE International Conference on Acoustics,
Speech, and Signal Processing, pages 5021?5024.
IEEE.
Andreas Peldszus, Okko Bu?, Timo Baumann, and
David Schlangen. 2012. Joint Satisfaction of Syn-
tactic and Pragmatic Constraints Improves Incre-
mental Spoken Language Understanding. In Pro-
ceedings of the 13th EACL, pages 514?523, Avi-
gnon, France, April. Association for Computational
Linguistics.
Thies Pfeiffer. 2010. Understanding multimodal deixis
with gaze and gesture in conversational interfaces.
Ph.D. thesis, Bielefeld University.
Zahar Prasov and Joyce Y Chai. 2010. Fusing Eye
Gaze with Speech Recognition Hypotheses to Re-
solve Exophoric References in Situated Dialogue.
In EMNLP 2010, number October, pages 471?481.
Deb Roy. 2005. Grounding words in perception and
action: computational insights. Trends in Cognitive
Sciences, 9(8):389?396, August.
David Schlangen and Gabriel Skantze. 2009. A Gen-
eral, Abstract Model of Incremental Dialogue Pro-
cessing. In Proceedings of the 10th EACL, pages
710?718, Athens, Greece. Association for Compu-
tational Linguistics.
David Schlangen, Timo Baumann, and Michaela At-
terer. 2009. Incremental Reference Resolution: The
Task, Metrics for Evaluation, and a Bayesian Filter-
ing Model that is Sensitive to Disfluencies. In Pro-
ceedings of the 10th SIGdial, pages 30?37, London,
UK. Association for Computational Linguistics.
Alexander Siebert and David Schlangen. 2008. A Sim-
ple Method for Resolution of Definite Reference in
a Shared Visual Context. In Proceedings of the 9th
SIGdial, pages 84?87, Columbus, Ohio. Association
for Computational Linguistics.
Gokhan Tur, Dilek Hakkani-tu?r, and Larry Heck. 2010.
What Is Left to Be Understood by ATIS? In IEEE
Workshop on Spoken Language Technologies, pages
19?24, Berkeley, California. IEEE.
Ye-Yi Wang, Li Deng, and Alex Acero. 2011. Seman-
tic Frame-based Spoken Language Understanding.
Wiley.
Jason D Williams. 2010. Incremental partition re-
combination for efficient tracking of multiple dia-
log states. Acoustics Speech and Signal Processing
ICASSP 2010, pages 5382?5385.
Luke S Zettlemoyer and Michael Collins. 2007. On-
line Learning of Relaxed CCG Grammars for Pars-
ing to Logical Form. Computational Linguistics,
pages 678?687.
Luke S Zettlemoyer and Michael Collins. 2009.
Learning context-dependent mappings from sen-
tences to logical form. Proceedings of the Joint
Conference of the 47th ACL and the 4th AFNLP:
Volume 2 - ACL-IJCNLP ?09, 2:976.
182
Proceedings of the SIGDIAL 2013 Conference, pages 280?283,
Metz, France, 22-24 August 2013. c?2013 Association for Computational Linguistics
Open-ended, Extensible System Utterances Are Preferred,
Even If They Require Filled Pauses
Timo Baumann
Universit?t Hamburg
Department of Informatics
Germany
baumann@informatik.uni-hamburg.de
David Schlangen
University of Bielefeld
Faculty of Linguistics and Literary Studies
Germany
david.schlangen@uni-bielefeld.de
Abstract
In many environments (e. g. sports com-
mentary), situations incrementally unfold
over time and often the future appearance
of a relevant event can be predicted, but not
in all its details or precise timing. We have
built a simulation framework that uses our
incremental speech synthesis component
to assemble in a timely manner complex
commentary utterances. In our evaluation,
the resulting output is preferred over that
from a baseline system that uses a simpler
commenting strategy. Even in cases where
the incremental system overcommits tem-
porally and requires a filled pause to wait
for the upcoming event, the system is pre-
ferred over the baseline.
1 Introduction
In spontaneous speech, speakers often commit tem-
porally, e. g. by starting utterances that they do not
yet know how to complete (Clark, 1996), putting
time pressure on them for the generation of a com-
pletion. While this may be for planning and effi-
ciency reasons, it also enables them to start com-
menting on events for which the outcome is not yet
known. For example when a ball is flying towards
the goal, but it is uncertain yet whether it will hit,
in sports commentary.
To accommodate this incremental behaviour, hu-
man speakers plan their utterances just somewhat
ahead, typically in chunks of major phrases (Levelt,
1989), and remain flexible to change or abandon
the original plan, or to hesitate, e. g. to adapt their
timing. This flexibility is in contrast to speech
output in spoken dialogue systems (SDSs) which
typically generate, synthesize and deliver speech
in units of full utterances that cannot be changed
while ongoing, apart from being aborted or inter-
rupted (Edlund, 2008).
Recently, incremental speech synthesis (iSS) has
been presented (Dutoit et al, 2011; Baumann and
Schlangen, 2012b) which allows to start partial ut-
terances that are then smoothly extended during
verbalization. Incremental spoken output for di-
alogue systems has been shown to improve natu-
ralness (Buschmeier et al, 2012) and Skantze and
Hjalmarsson (2010) have used filled pauses to hold
a turn. Dethlefs et al (2012) present an incremental
NLG strategy to reduce the need for filled pauses
in interactions.
We investigate the impact of incremental spoken
output in a highly dynamic environment, that is,
where the rate of external events is high enough
to allow only few utterances to finish as planned.
As an example, we choose an otherwise simple
commentary domain, where incremental output en-
ables the system to combine multiple events into
one complex commenting utterance that takes into
account predictions about upcoming events. If the
system overcommits to the timing of future events,
it autonomously uses a filled pause until more ma-
terial becomes available.
2 Related Work
A paradigmatic example of a domain that uses
open-ended utterances is sports commentary,
which has received some attention in the NLG
community. For example, Chen and Mooney
(2008) present a system that learns from hand-
annotated data what to comment on. However,
attention seems to have been placed more on
truthfulness of the content, as, judging from videos
provided on their website,1 the formulations
that are produced are rather monotonic (?pink7
dribbles towards the goal. pink7 shoots for the
goal. pink7 passes to...?). More importantly,
the delivery of a produced utterance does not seem
to be temporally tied to the occurrence of the event.
1http://www.cs.utexas.edu/users/ml/clamp/sportscasting
280
Figure 1: The map shown in the CarChase domain,
including the car on one of its itineraries (red; an-
other in blue). At the depicted moment we can
assume that the car will take a turn, but do not
know whether left or right.
Repeatedly, utterances are synthesized long after
the fact that they describe which sometimes has
become obsolete at that point (for example, a goal
is scored while the system still talks about a pass).
Lohmann et al (2011) describe another domain
that can be called highly dynamic: a system that
adds spoken assistance to tactile maps for the vi-
sually impaired. In their settings, users can move
around on a computer representation of a map with
a hand-held haptic force-feedback device. Users
are given spoken advice about the currently tra-
versed streets? names, the relation of streets to each
other, and to other map objects in the user?s vicin-
ity. Such exploratory moves by users can become
rather quick, which in the system they describe
can lead to output that comes late, referring to a
position that has long been left.
3 A Highly Dynamic Commenting Domain
Our example domain combines properties of the
sports commentary and map exploration domains
mentioned above: the CarChase domain depicted
in Figure 1. In the domain, a car drives around
streets on the map and a commentator (supposed to
be observing the scene from above) comments on
where it is driving and what turns it is taking.
The car?s itinerary in our domain simulator is
scripted from a configuration file which assigns
target positions for the car at different points in time
and from which the motion and rotation of the car
is animated. The speed of the car is set so that the
event density is high enough that the setting cannot
be described by simply producing one utterance
per event ? in other words: the domain is highly
dynamic.
time event description ongoing utterance (already realized part in bold,
newly appended continuation in italic)
t1 car on Main Street The car drives along Main Street.
t2 car will likely turn . . .drives along Main Street and then turns ?hes?
t3 car turns right . . .drives along Main Street and then turns right.
Figure 2: Example of incremental utterance pro-
duction as a car drives along a street and turns. The
ongoing utterance is extended as events unfold.
4 A Strategy for Incremental
Commentary
We distinguish three types of events in the do-
main: identification (ID) events trigger the system
to name the street the car is on, turn events fire
when the car is taking a turn. Finally, turn-prep
events fire when it is obvious that the car will turn
but the direction of the turn remains open. These
three event types are shown in Figure 2 at time t1
(ID), t2 (turn-prep), and t3 (turn).
As can be seen in the example in Figure 2, the
turn-prep event enables a system that is able to
incrementally update its ongoing utterance to con-
tinue speaking about the anticipated future (?and
then turns?) without knowing the direction of the
turn. This allows an incremental system to output
efficient utterances that fluently combine multiple
events and avoid repetition. Furthermore, turn-prep
events enable the system to output the direction
of the turn (the most important information) very
shortly after the fact.
A non-incremental system, in contrast, must out-
put individual utterances for every event and utter-
ances can only start after the fact. Furthermore,
a non-incremental system cannot extend ongoing
utterances, rendering turn-prep events useless.
5 Implemented System
The system used for the experiment reported be-
low uses an early version of incremental speech
synthesis as implemented in INPROTK (Baumann
and Schlangen, 2012c), a toolkit for incremental
spoken dialogue processing based on the IU model
(Schlangen and Skantze, 2009). The system al-
lows to extend ongoing utterances, enabling the
281
incremental commenting strategy outlined above.
In addition, we implemented a capability to syn-
thesize a hesitation if no more content is specified,
and to continue as soon as content becomes avail-
able. (Thus, in contrast to (Skantze and Hjalmars-
son, 2010), hesitations do not consume additional
time.) By using hesitations, the system gracefully
accommodates temporal over-commitment (i. e. the
obligation to produce a continuation that is not ful-
filled in time) which may occur, e. g. when the car
drives slower than anticipated and a turn?s direction
is not yet known when the system needs it.
In the preliminary version of iSS used for the ex-
periments, no prosodic integration of continuations
takes place, resulting in prosodic discontinuities;
see (Baumann and Schlangen, 2012a) for a detailed
assessment of prosodic integration in iSS.
As we focus on the merit of iSS in this work, we
did not implement a scene analysis/event detection
nor a NLG component for the task.2 Instead, the
commentary is scripted from the same configura-
tion file that controls the car?s motion on the board.
iSS events lag behind slightly, ensuring that visual
analysis would be possible, and event/text corre-
spondence is close, matching NLG capabilities.
6 Experiment
To evaluate the incremental system, we compared
it to a non-incremental baseline system which is
unable to alter speech incrementally and hence can-
not smoothly extend ongoing partial utterances. In-
stead, the baseline system always produces full
utterances, one per event. To ensure the tempo-
ral proximity of delivery with the causing event
in the baseline system, utterances can be marked
as optional (in which case they are skipped if the
system is still outputting a previous utterance), or
non-optional (in which case an ongoing utterance
is aborted in favour of the new utterance). All ?turn?
events in the domain were marked as optional, all
street ID events as non-optional.
We devised 4 different configurations (including
the itineraries shown in Figure 1), and the timing of
events was varied (by having the car go at different
speeds, or by delaying some events), resulting in 9
scenarios; in 3 of these, the incremental system gen-
erated one or more hesitations. Both systems? out-
put for the 9 scenarios was recorded with a screen-
recorder, resulting in 18 videos that were played in
2However, Lohmann et al (2012) present an incremental
NLG strategy for a similar task.
random order to 9 participants (university students
not involved in the research). Participants were
told that various versions of commentary-generat-
ing systems generated the commentary based on
the running picture in the videos and were then
asked to rate each video on a five-point Likert scale
with regards to how natural (similar to a human)
the spoken commentary was (a) formulated, and
(b) pronounced. In total, this resulted in 81 paired
samples for each question.3
The assumption (and rationale for the second
question) was that the incremental system?s formu-
lations would result in higher formulation ratings,
while we hoped the acoustic and prosodic artefacts
resulting from the coarsely implemented incremen-
tal synthesis would not significantly hurt pronun-
ciation ratings. In order to not draw the subjects?
attention towards incremental aspects, no question
regarding the timeliness of the commentary was
asked for explicitly.
7 Results
The mean ratings for both formulation quality and
pronunciation quality for the incremental and base-
line systems is shown in Figure 3. The median
differences in the ratings of the two conditions is
2 points on the Likert scale for question (a) and
0 points for question (b) (means of 1.66 and 0.51,
respectively), favouring the incremental system.
The sign test shows that the advantage of the incre-
mental system is clearly significant for questions
(a) (68+/9=/4-; p < .0001) and (b) (38+/30=/13-;
p < .0007)4.
Thus, it is safe to say that the production strate-
gies enabled by incremental speech synthesis (i. e.
starting to speak before all evidence is known and
extending the utterance as information becomes
available) allows for formulations in the spoken
commentary that are favoured by human listeners.
Incremental behaviour in the 3 scenarios that
required hesitations was rated significantly worse
than in those scenarios without hesitations for both
questions (t-tests, p < .001 (a) and p < .01 (b)). This
3The experiment was conducted in one language (German)
only, but we believe our results to carry over to other lan-
guages. Specifically, we assume that most or all languages
cater for commenting, and believe that human commenters
universally use their ability to integrate events late in the utter-
ance. However, practices of commenting may work differently
(and differently well) among languages.
4We also conducted a non-paired t-test for question (b), as
the different formulations of the systems might have effects on
pronunciation quality; this test was also significant (p < .0012).
282
very
little
a little
neutral
a bit
very
much
a) formulation b) pronunciation
no hes
no hes 
incremental strategy
baseline strategy
hes
hes
Figure 3: Mean ratings of formulation and pronun-
ciation for the incremental and baseline systems;
the formulation rating differs for utterances with
and without hesitations in the incremental system.
is a clear indication that a system should try to
avoid over-commitment, as users do not accept hes-
itations as inevitable (given that there was simply
no evidence yet where the car would turn, for exam-
ple). However, even in those scenarios that require
filled pauses, the incremental commentary?s for-
mulation is rated as significantly better than the
baseline system?s (sign test, 18+/5=/4-; p < .005)
while there is no effect on pronunciation in these
cases.
8 Discussion & Outlook
The results indicate a clear user preference for open-
ended, extensible utterances that grow as events un-
fold. Furthermore, this preference is stronger than
the negative impact of filled pauses that are needed
to cover temporal over-commitment, and despite
the poor quality of filled pauses in the current sys-
tem, which we plan to improve in the future.
Similarly to spoken commentary in dynamic do-
mains, conversational speech requires revisions and
reactions to events such as listener feedback, or the
absence thereof (Clark, 1996). Thus, we believe
that our results, as well as iSS in general, also apply
to a broad range of conversational SDS tasks.
Finally, synthesis quality appears to be less im-
portant than interaction adequacy: we found no
difference in rating of perceptual quality (?pronun-
ciation?) between the variants, even though in isola-
tion iSS sounded noticeably worse in the prototype.
This result calls for interactive adequacy as an op-
timization target over (isolated) perception ratings
for speech synthesis, and also challenges the use of
canned speech in conversational SDSs, which does
not adapt to the interaction.
Acknowledgements The first author would like
to thank Wolfgang Menzel for fruitful discussions
on the topic, and permanent encouragement.
References
Timo Baumann and David Schlangen. 2012a. Eval-
uating prosodic processing for incremental speech
synthesis. In Procs. of Interspeech, Portland, USA.
Timo Baumann and David Schlangen. 2012b. IN-
PRO_iSS: A component for just-in-time incremen-
tal speech synthesis. In Proceedings of ACL System
Demonstrations, Jeju, Korea.
Timo Baumann and David Schlangen. 2012c. The
INPROTK 2012 release. In Proceedings of SDCTD,
Montr?al, Canada.
Hendrik Buschmeier, Timo Baumann, Benjamin
Dorsch, Stefan Kopp, and David Schlangen. 2012.
Combining incremental language generation and in-
cremental speech synthesis for adaptive information
presentation. In Procs. of SigDial, pages 295?303,
Seoul, Korea.
David L. Chen and Raymond J. Mooney. 2008. Learn-
ing to sportscast: A test of grounded language ac-
quisition. In Proceedings of 25th Int. Conference on
Machine Learning (ICML), Helsinki, Finland.
Herbert H. Clark. 1996. Using Language. Cambridge
University Press.
Nina Dethlefs, Helen Hastie, Verena Rieser, and Oliver
Lemon. 2012. Optimising incremental generation
for spoken dialogue systems: Reducing the need for
fillers. In Procs. of the Seventh Int. Natural Lan-
guage Generation Conf., pages 49?58, Utica, USA.
Thierry Dutoit, Maria Astrinaki, Onur Babacan, Nico-
las d?Alessandro, and Benjamin Picart. 2011. pHTS
for Max/MSP: A Streaming Architecture for Statis-
tical Parametric Speech Synthesis. Technical Re-
port 1, numediart Research Program on Digital Art
Technologies.
Jens Edlund. 2008. Incremental speech synthesis. In
Second Swedish Language Technology Conference,
pages 53?54, Stockholm, Sweden. System Demo.
William J.M. Levelt. 1989. Speaking: From Intention
to Articulation. MIT Press.
Kris Lohmann, Carola Eschenbach, and Christopher
Habel. 2011. Linking spatial haptic perception to
linguistic representations: assisting utterances for
tactile-map explorations. In Spatial information the-
ory, pages 328?349, Berlin, Heidelberg. Springer.
Kris Lohmann, Ole Eichhorn, and Timo Baumann.
2012. Generating situated assisting utterances to fa-
cilitate tactile-map understanding: A prototype sys-
tem. In Procs. of SLPAT 2012, Montr?al, Canada.
David Schlangen and Gabriel Skantze. 2009. A Gen-
eral, Abstract Model of Incremental Dialogue Pro-
cessing. In Procs. of the EACL, Athens, Greece.
Gabriel Skantze and Anna Hjalmarsson. 2010. To-
wards incremental speech generation in dialogue sys-
tems. In Procs. of SigDial, pages 1?8, Tokyo, Japan.
283
Proceedings of the SIGDIAL 2013 Conference, pages 319?323,
Metz, France, 22-24 August 2013. c?2013 Association for Computational Linguistics
Investigating speaker gaze and pointing behaviour
in human-computer interaction with the mint.tools collection
Spyros Kousidis Casey Kennington David Schlangen
Dialogue Systems Group / CITEC / SFB 673
Bielefeld University
spyros.kousidis@uni-bielefeld.de
Abstract
Can speaker gaze and speaker arm move-
ments be used as a practical informa-
tion source for naturalistic conversational
human?computer interfaces? To investi-
gate this question, we recorded (with eye
tracking and motion capture) a corpus of
interactions with a (wizarded) system. In
this paper, we describe the recording, anal-
ysis infrastructure that we built for such
studies, and analysis we performed on
these data. We find that with some initial
calibration, a ?minimally invasive?, sta-
tionary camera-based setting provides data
of sufficient quality to support interaction.
1 Introduction
The availability of sensors such as Microsoft
Kinect and (almost) affordable eye trackers bring
new methods of naturalistic human-computer in-
teraction within reach. Studying the possibilities
of such methods requires building infrastructure
for recording and analysing such data (Kousidis et
al., 2012a). We present such an infrastructure?
the mint.tools collection (see also (Kousidis et
al., 2012b))1?and present results of a study we
performed on whether speaker gaze and speaker
arm movements can be turned into an information
source for an interactive system.
2 The mint.tools Collection
The mint.tools collection comprises tools (and
adaptations to existing tools) for recording and
analysis of multimodal data. The recording archi-
tecture (Figure 1) is highly modular: each infor-
mation source (sensor) runs on its own dedicated
workstation and transmits its data via the local area
network. In the setup described in this paper, we
1Available at http://dsg-bielefeld.de/
mint/.
kinect.srv
faceLab.srv
MINT.tools
f
o
r
 
a
c
q
u
i
s
i
t
i
o
n
f
o
r
 
a
n
a
l
y
s
i
s
instantIO
instant
player
kinect.srv
faceLab.srv
.xio
mumodo.py /
IPython
ELAN.mod
MPI, ELAN
annotation
tool
fame.rc
fame.rp
Fraunhofer instant reality
Figure 1: Overview of components of mint.tools;
our contributions denoted by italics font. Top mid-
dle shows example lab setup; middle right shows
corresponding VR scene, visualising motion cap-
ture and tracking of head posture, eye and gaze
perform motion capture via Microsoft Kinect and
head, eye and gaze tracking via Seeingmachines
Facelab 5.2 We have developed specialised plug-
ins that connect these sensors to the central com-
ponent in our architecture, Instantreality.3 This
is a VR environment we use for monitoring the
recording process by visualising a reconstructed
3D scene in real-time. A logging component si-
multaneously streams the timestamped and inte-
grated sensor data to disk, ensuring that all data are
synchronised. The data format is a shallow XML
representation of timed, typed events.
The tracking equipment used in this setting is
camera-based, providing for a minimally invasive
setting, as subjects are not required to wear any
equipment or tracking markers. In addition to the
tracking sensors, video and audio are recorded us-
2http://www.microsoft.com/en-us/
kinectforwindows/, http://www.
seeingmachines.com/product/facelab/, re-
spectively
3Built by IGD Fraunhofer, http://www.
instantreality.org
319
ing one HD camera. The AV channel is synchro-
nised with the stream data from the sensors by
means of a timecode in view of the camera.
Representative of the high modularity and flexi-
bility of the mint.tools architecture is the ease with
which components can be added. For the setting
described here, a GUI was created which connects
to the VR environment as an additional sensor,
transmitting all of its state updates, which then
are synchronously logged together with all other
stream data from the trackers. This allows us to
recreate the full scene (subject behaviour and the
stimuli they received) in the virtual reality envi-
ronment, for later inspection (see below Figure 6).
The analysis part of the mint.tools collection
comprises a package for the Python programming
language (described below) and a version of the
ELAN annotation tool (Lausberg and Sloetjes,
2009), which we modified to control the replay of
the virtual reality scene; this makes it possible to
view video, annotations and the 3D reconstruction
at the same time and in synchronisation.
Sensors are represented as nodes in a node-tree
within the 3D environment. The values of data
fields in these nodes are continuously updated as
new data is received from the network. Using
more than one sensor of the same type means sim-
ply another instantiation of that node type within
the tree. In this way, our architecture facilitates
tracking many people or complex setups where
many sensors are required to cover an area.
3 Procedure / The TAKE Corpus
Our experiment is a Wizard-of-Oz scenario in
which subjects (7 in total) were situated in front of
a 40? screen displaying random Pentomino boards
(Ferna?ndez et al, 2007). Each board configura-
tion had exactly 15 Pentomino pieces of various
colours and shapes, divided in four grids located
near the four corners of the screen (see Figure 3
below). At the beginning of the session, a head and
gaze model were created for the subject within the
FaceLab software. Next, the subjects were asked
to point (with their arm stretched) at the four cor-
ners and the center of the screen (with each hand),
to calibrate to their pointing characteristics.
In the main task, subjects were asked to
(silently) choose a piece and instruct the ?system?
to select it, using speech and/or pointing gestures.
A wizard then selected the indicated piece, caus-
ing it to be highlighted. Upon approval by the
subject, the wizard registered the result and a new
board was created. We denote the time-span from
the creation of a board to the acknowledgement
by the subject that the correct piece was selected
an episode. The wizard had the option to not im-
mediately highlight the indicated piece, in order
to elicit a more detailed description of the piece
or a pointing gesture. What we were interested
in learning from these data was whether speaker
gaze and arm movements could be turned into sig-
nals that can support a model of situated language
understanding. We focus here on the signal pro-
cessing and analysis that was required; the model
is described in (Kennington et al, 2013).
4 Analysis and Results
We perform the analyses described in this sec-
tion using the analysis tools in the mint.tools col-
lection, mumodo.py. This is a python package
we have developed that interfaces our recorded
stream data with powerful, freely available, sci-
entific computing tools written in the Python pro-
gramming language.4 mumodo.py facilitates im-
porting streamed data into user-friendly, easily
manageable structures such as dataframes (tables
with extended database functionality), or compati-
ble formats such as Praat TextGrids (Boersma and
Weenink, 2013) and ELAN tiers. In addition, mu-
modo.py can remote-control playback in ELAN
and Instant Reality for the purpose of data view-
ing and annotation.
4.1 Gaze
Our post-processing and analysis of the gaze data
focuses primarily on the detection of eye fixations
in order to determine the pentomino pieces that the
subjects look at while speaking. This knowledge
is interesting from a reference resolution point of
view. Although Koller et al(2012) explored lis-
tener gaze in that context, it is known that gaze pat-
terns differ in interactions, depending on whether
one speaks or listens (Jokinen et al, 2009).
Facelab provides a mapping between a person?s
gaze vector and the screen, which yields an in-
tersection point in pixel coordinates. However,
due to limitations to the accuracy of the calibra-
tion procedure and noise in the data, it is pos-
4Especially IPython and Pandas, as collected for exam-
ple in https://www.enthought.com/products/
epd/. Example of finished analyses using this package
can be found at http://dsg-bielefeld.de/mint/
mintgaze.html
320
sible that the gaze vector does not intersect the
model of the screen when the subject is looking at
pieces near screen corners. For this reason, we first
perform offline linear interpolation, artificially ex-
tending the screen by 200 pixels in each direction,
by means of linear regression of the x, y compo-
nents of the gaze vector with the x, y pixel coordi-
nates, respectively (R2 > 0.95 in all cases). Fig-
ure 2 shows the probability density function of in-
tersection points before (left) and after this process
(right), for one of the subjects. We see on the right
plot that many intersection points fall outside the
viewable screen area, denoted by the shaded rect-
angle.
Figure 2: Probability density function of gaze in-
tersections on screen before (left) and after inter-
polating for points 200 pixels around screen edges
(right). Shaded rectangle shows screen size
In order to detect the eye fixations, we use two
common algorithms, namely the I-DT and ve-
locity algorithms, as described in (Nystro?m and
Holmqvist, 2010). The I-DT algorithm requires
the points to lie within a pre-defined ?dispersion?
area (see Figure 3), while the velocity algorithm
requires the velocity to remain below a thresh-
old. In both algorithms, a minimum fixation time
threshold is also used, while a fixation centroid is
calculated as the midpoint of all points in a fixa-
tion. Increasing the minimum fixation time thresh-
old and decreasing the dispersion area or velocity
(depending on the algorithm) results in fewer fix-
ations being detected.
Figure 3: Fixation detection using the I-DT algo-
rithm, circles show the dispersion radius threshold
Gaze fixations can be combined with informa-
tion on the pentomino board in order to determine
which piece is being looked at. To do this, we cal-
culate the euclidean distance between each piece
and the fixation centroid, and assign the piece a
probability of being gazed at, which is inversely
proportional to its distance from the centroid.
Figure 4 illustrates the gazing behaviour of the
subjects during 1051 episodes: After an initial
rapid scan of the whole screen (typically before
they start speaking), subjects fixate on the piece
they are going to describe (the ?gold piece?). This
is denoted by the rising number of fixations on the
gold piece between seconds 5?10. At the same
time, the average rank of the gold piece is higher
(i.e. closer to 1, hence lower in the plot). Subse-
quently, the average rank drops as subjects tend to
casually look around the screen for possible dis-
tractors (i.e. pieces that are identical or similar to
the gold piece).
We conclude from this analysis that, especially
around the onset of the utterance, gaze can provide
a useful signal about intended referents.
Figure 4: Average Rank and Counts over time (all
episodes)
4.2 Pointing Gestures
We detect pointing gestures during which the arm
is stretched from Kinect data (3D coordinates of
20 body joints) using two different methods. The
first is based on the distance of the hand joint from
the body (Sumi et al, 2010). We define the body
as a plane, using the coordinates of the two shoul-
ders, shoulder-center and head joints, and use a
threshold beyond which a movement is considered
a possible pointing gesture.
The second detection method uses the idea that,
while the arm is stretched, the vectors defined by
the hand and elbow, and hand and shoulder joints,
respectively, should be parallel, i.e. have a dot
product close to 1 (vectors are first normalised).
321
Figure 5: detection of pointing thresholds by dis-
tance of left(blue) or right(green) hand from body
In reality, the arm is never strictly a straight line,
hence a threshold (0.95-0.98) is set, depending on
the subject. The result of this process is an an-
notation tier of pointing gestures (for each hand),
similar to the one shown in Figure 5. To make
pointing gesture detection more robust, we only
consider gestures identified by both methods, i.e.
the intersection of the two annotation tiers.
Further, we want to map the pointing gestures to
locations on the screen. Following a methodology
similar to Pfeiffer (2010), we define two methods
of determing pointing direction: (a) the extension
of the arm, i.e. the shoulder-hand vector, and (b)
the hand-head vector, which represents the subjec-
tive point-of-view (looking through the tip of one?s
finger). Figure 6 shows both vectors: depending
on the subject and the target point, we have found
that both of these vectors perform equally well, by
considering the gaze intersection point (green dot
on screen) and assuming that subjects are looking
where they are pointing.
Figure 6: Hand-to-head and hand-to-shoulder
pointing vectors
In order to map the pointing gestures to ac-
tual locations on the screen, we use the calibra-
tion points acquired at the beginning of the ses-
sion, and plot their intersections to the screen
plane, which we compute analytically, as we al-
ready have a spatial model of both the vector in
question (Kinect data) and the screen location (In-
stantreality model).
Based on the pointing gestures we have de-
tected, we look at the pointing behaviour of par-
ticipants as a function of the presence of distrac-
tors. This knowledge can be used in designing
system responses in a multimodal interactive en-
viroment or in training models to expect pointing
gestures depending on the state of the scene. Fig-
ure 7 shows the result from 868 episodes (a subset
that satisfies minor technical constraints). Overall,
the subjects pointed in 60% of all episodes. Pieces
on the board may share any of three properties:
shape, colour, and location (being in the same cor-
ner on the screen). The left plot shows that sub-
jects do not point more than normal when only
one property is shared, regardless of how many
such distractors are present, while they point in-
creasingly more when pieces that share two or all
three properties exist. The plot on the right shows
that subjects point more when the number of same
colour pieces increases (regardless of position and
shape) and even more when identical pieces occur
anywhere on the board. Interestingly, shape by it-
self does not appear to be considered a distractor
by the subjects.
Figure 7: Frequency of pointing gestures as a
function of the presence of distractors. Dot size
denotes the confidence of each point, based on
sample size
5 Conclusions
We have presented a detailed account of analysis
procedures on multimodal data acquired from ex-
periments in situated human-computer interaction.
These analyses have been facilitated by mint.tools,
our collection of software components for mul-
timodal data acquisition, annotation and analysis
and put to use in (Kennington et al, 2013). We
will continue to further improve our approach for
manageable and easily reproducible analysis.
322
References
Paul Boersma and David Weenink. 2013. Praat: do-
ing phonetics by computer (version 5.3.48)[com-
puter program]. retrieved may 1, 2013.
Raquel Ferna?ndez, Andrea Corradini, David
Schlangen, and Manfred Stede. 2007. To-
wards Reducing and Managing Uncertainty in
Spoken Dialogue Systems. In Proceedings of the
7th International Workshop on Computational
Semantics (IWCS?07), pages 1?3.
Kristiina Jokinen, Masafumi Nishida, and Seiichi Ya-
mamoto. 2009. Eye-gaze experiments for conversa-
tion monitoring. In Proceedings of the 3rd Interna-
tional Universal Communication Symposium, pages
303?308. ACM.
Casey Kennington, Spyros Kousidis, and David
Schlangen. 2013. Interpreting situated dialogue ut-
terances: an update model that uses speech, gaze,
and gesture information. In Proceedings of SIGdial
2013.
Alexander Koller, Maria Staudte, Konstantina Garoufi,
and Matthew Crocker. 2012. Enhancing referen-
tial success by tracking hearer gaze. In Proceed-
ings of the 13th Annual Meeting of the Special Inter-
est Group on Discourse and Dialogue, pages 30?39.
Association for Computational Linguistics.
Spyros Kousidis, Thies Pfeiffer, Zofia Malisz, Petra
Wagner, and David Schlangen. 2012a. Evaluat-
ing a minimally invasive laboratory architecture for
recording multimodal conversational data. In Proc.
of the Interdisciplinary Workshop on Feedback Be-
haviours in Dialogue.
Spyros Kousidis, Thies Pfeiffer, and David Schlangen.
2012b. Mint.tools: Tools and adaptors supporting
acquisition, annotation and analysis of multimodal
corpora. In to appear in Proc. of Interspeech 2013.
Hedda Lausberg and Han Sloetjes. 2009. Coding ges-
tural behavior with the neuroges-elan system. Be-
havior research methods, 41(3):841?849.
Marcus Nystro?m and Kenneth Holmqvist. 2010. An
adaptive algorithm for fixation, saccade, and glis-
sade detection in eyetracking data. Behavior re-
search methods, 42(1):188?204.
Thies Pfeiffer. 2010. Understanding multimodal deixis
with gaze and gesture in conversational interfaces.
Ph.D. thesis, Bielefeld University, Technical Fac-
ulty.
Yasuyuki Sumi, Masaharu Yano, and Toyoaki Nishida.
2010. Analysis environment of conversational struc-
ture with nonverbal multimodal data. In Interna-
tional Conference on Multimodal Interfaces and the
Workshop on Machine Learning for Multimodal In-
teraction, page 44. ACM.
323
Proceedings of the of the EACL 2014 Workshop on Dialogue in Motion (DM), pages 68?72,
Gothenburg, Sweden, April 26-30 2014.
c?2014 Association for Computational Linguistics
Situationally Aware In-Car Information Presentation
Using Incremental Speech Generation: Safer, and More Effective
Spyros Kousidis
1
, Casey Kennington
1,2
, Timo Baumann
4
, Hendrik Buschmeier
2,3
,
Stefan Kopp
2,3
, and David Schlangen
1
1
Dialogue Systems Group,
2
CITEC,
3
Sociable Agents Group ? Bielefeld University
4
Department of Informatics, Natural Language Systems Division ? University of Hamburg
spyros.kousidis@uni-bielefeld.de
Abstract
Holding non-co-located conversations
while driving is dangerous (Horrey and
Wickens, 2006; Strayer et al., 2006),
much more so than conversations with
physically present, ?situated? interlocutors
(Drews et al., 2004). In-car dialogue
systems typically resemble non-co-located
conversations more, and share their
negative impact (Strayer et al., 2013). We
implemented and tested a simple strategy
for making in-car dialogue systems aware
of the driving situation, by giving them
the capability to interrupt themselves
when a dangerous situation is detected,
and resume when over. We show that this
improves both driving performance and
recall of system-presented information,
compared to a non-adaptive strategy.
1 Introduction
Imagine you are driving on a relatively free high-
way at a constant speed and you are talking with the
person next to you. Suddenly, you need to overtake
another car. This requires more attention from you;
you check the mirrors before you change lanes, and
again before you change back. Plausibly, an attent-
ive passenger would have noticed your attention
being focused more on the driving, and reacted to
this by interrupting their conversational contribu-
tion, resuming when back on the original lane.
Using a driving simulation setup, we implemen-
ted a dialogue system that realises this strategy. By
employing incremental output generation, the sys-
tem can interrupt and flexibly resume its output.
We tested the system using a variation of a stand-
ard driving task, and found that it improved both
driving performance and recall, as compared to a
non-adaptive baseline system.
Figure 1: Overview of our system setup: human
controls actions of a virtual car; events are sent to
DM, which controls the speech output.
2 The Setup
2.1 The Situated In-Car System
Figure 1 shows an overview of our system setup,
with its main components: a) the driving simulator
that presents via computer graphics the driving task
to the user; b) the dialogue system, that presents,
via voice output, information to the user (here, cal-
endar entries).
Driving Simulation For the driving simulator,
we used the OpenDS Toolkit,
1
connected to a steer-
ing wheel and a board with an acceleration and
brake pedal, using standard video game hardware.
We developed our own simple driving scenarios
(derived from the ?ReactionTest? task, which is dis-
tributed together with OpenDS) that specified the
driving task and timing of the concurrent speech,
as described below. We modified OpenDS to pass
real-time data (e.g. car position/velocity/events in
the simulation, such as a gate becoming visible
or a lane change) using the mint.tools architec-
ture (Kousidis et al., 2013). In addition, we have
bridged INPROTK (Baumann and Schlangen, 2012)
with mint.tools via the Robotics Service Bus (RSB,
Wienke and Wrede (2011)) framework.
1http://www.opends.eu/
68
Figure 2: Driver?s view during experiment. The
green signal on the signal-bridge indicates the tar-
get lane.
Dialogue System Using INPROTK, we imple-
mented a simple dialogue system. The notion of
?dialogue? is used with some liberty here: the user
did not interact directly with the system but rather
indirectly (and non-intentionally) via driving ac-
tions. Nevertheless, we used the same modularisa-
tion as in more typical dialogue systems by using a
dialoge management (DM) component that controls
the system actions based on the user actions. We
integrated OpenDial (Lison, 2012) as the DM into
INPROTK,
2
though we only used it to make simple,
deterministic decisions (there was no learned dia-
logue policy) based on the state of the simulator
(see below). We used the incremental output gen-
eration capabilities of INPROTK, as described in
(Buschmeier et al., 2012).
3 Experiment
We evaluated the adaptation strategy in a driving
simulation setup, where subjects performed a 30
minute, simulated drive along a straight, five-lane
road, during which they were occasionally faced
with two types of additional tasks: a lane-change
task and a memory task, which aim to measure the
driving performance and the driver?s ability to pay
attention to speech while driving, respectively. The
two tasks occured in isolation or simultaneoulsy.
The Lane-Change Task The driving task we
used is a variant of the well-known lane-change
task (LCT), which is standardised in (ISO, 2010):
It requires the driver to react to a green light posi-
tioned on a signal gate above the road (see Figure 2).
The driver (otherwise instructed to remain in the
middle lane) must move to the lane indicated by
2
OpenDial can be found at http://opendial.
googlecode.com/.
Table 1: Experiment conditions.
Lane Change Presentation mode Abbreviation
Yes CONTROL CONTROL_LANE
Yes ADAPTIVE ADAPTIVE_LANE
Yes NO_TALK NO_TALK_LANE
No CONTROL CONTROL_EMPTY
the green light, remain there until a tone is sounded,
and then return again to the middle lane. OpenDS
gives a success or fail result to this task depending
on whether the target lane was reached within 10
seconds (if at all) and the car was in the middle lane
when the signal became visible. We also added a
speed constraint: the car maintained 40 km/h when
the pedal was not pressed, with a top speed of 70
km/h when fully pressed. During a Lane-change,
the driver was to maintain a speed of 60 km/h, thus
adding to the cognitive load.
The Memory Task We tested the attention of
the drivers to the generated speech using a simple
true-false memory task. The DM generated utter-
ances such as ?am Samstag den siebzehnten Mai
12 Uhr 15 bis 14 Uhr 15 hast du ?gemeinsam Essen
im Westend mit Martin? ? (on Saturday the 17th
of May from 12:15?14:15 you are meeting Mar-
tin for Lunch). Each utterance had 5 information
tokens: day, time, activity, location and partner,
spoken by a female voice. After utterance comple-
tion, and while no driving distraction occurred, a
confirmation question was asked by a male voice,
e.g. ?Richtig oder Falsch? ? Freitag? (Right or
wrong? ? Friday). The subject was then required
to answer true or false by pressing one of two re-
spective buttons on the steering wheel. The token
of the confirmation question was chosen randomly,
although tokens near the beginning of the utterance
(day and time) were given a higher probability of
occurrence. The starting time of the utterance re-
lative to the gate was varied randomly between 3
and 6 seconds before visibility. Figure 3 gives a
schematic overview of the task and describes the
strategy we implemented for interrupting and re-
suming speech, triggered by the driving situation.
3.1 Conditions
Table 1 shows the 4 experiment conditions, de-
noting if a lane change was signalled, and what
presentation strategy was used. Each condition ap-
peared exactly 11 times in the scenario, for a total
of 44 episodes. The order of episodes was randomly
69
t1
t
2
suc
gate
lane t
3
0
1
2
3
4
am Samstag den siebzehn- den siebzehnten Mai ?
am Samstag den siebzehnten Mai um 12 Uhr hast du ?Besprechung mit Peter?
ADAPTIVE
CONTROL
Figure 3: Top view of driving task: as the car moves to the right over time, speech begins at t
1
, the gate with
the lane-change indicator becomes visible at t
2
, where in the adaptive version speech pauses. Successful
lane change is detected at suc; successful change back to the middle lane is detected at lane, and resumes.
(If no change back is detected, the interruption times out at t
3
). All red-dotted lines denote events sent
from OpenDS to the Dialogue Manager.
generated for each subject. With this design, sub-
jects perceive conditions to be entirely random.
3.2 Dependent Variables
The dependent variables for the Memory task
are (a) whether the subject?s answer was correct
(true/false), and (b) the response delay, which is
the time from the end of the clarification ques-
tion to the time the true or false button was
pressed. For the driving task, the dependent vari-
ables are the OpenDS performance measurements
success/failure (as defined above) and reaction time
(time to reach the target lane).
3.3 Procedure
After signing a consent form, subjects were led into
the experiment room, where seat position and audio
level were adjusted, and were given written instruc-
tions. Next, the OpenDS scenario was initiated. The
scenario started with 10 successive lane-change sig-
nal gates without speech, for driving training. An
experimenter provided feedback during training
while the subjects familiarized themselves with the
driving task. Following the training gates came a
clearly-marked ?START? gate, signifying the be-
ginning of the experiment to the subjects (at this
point, the experimenter left). There was a ?FINISH?
gate at the end of the scenario. The whole stretch of
road was 23 km and took approximately 30 minutes
to complete. After the driving task, the subjects
were given a questionnaire, which asked them to
identify the information presentation strategies and
assign a preference.
Table 2: Subjects?
judgement of task
difficulty.
Diff. Freq.
4 (easy) 8
3 7
2 1
1 (hard) 1
Table 3: Subjects? system
preference.
Preference Freq.
ADAPTIVE 3
CONTROL 9
Neither 5
4 Results
In total, 17 subjects (8 male, 9 female, aged 19-
36) participated in the study. All of the subjects
were native German speakers affiliated with AN-
ONYMIZED University. As reported in the post-test
questionnaire, all held a driving license, two had
previous experience with driving simulators and
only one had previous experience with spoken dia-
logue systems. Table 2 shows the subjects? assess-
ment of difficulty, while Table 3 shows their prefer-
ence between the different strategies. Most subjects
found the task relatively easy and either prefer the
speech not to adapt or have no preference.
Memory task The overall percentages of correct
answers to the system?s recall questions (across all
subjects) are shown in Table 4. We see that the sub-
jects? performance in this task is considerably bet-
ter when the system adapts to the driving situation
(ADAPTIVE_LANE condition) rather than speaking
through the lane change (CONTROL_LANE con-
dition). In fact, the performance in the ADAPT-
IVE_LANE condition is closer to the control upper
70
Table 4: Performance in memory task per condi-
tion.
Condition Percentage
CONTROL_EMPTY 169/180 (93.9%)
ADAPTIVE_LANE 156/172 (90.7%)
CONTROL_LANE 150/178 (84.3%)
Table 5: Success in driving task per condition (as
reported by OpenDS).
Condition Success
NOTALK_LANE 175/185 (94.6%)
ADAPTIVE_LANE 165/174 (94.8%)
CONTROL_LANE 165/180 (91.7%)
bound (CONTROL_EMPTY condition). We tested
significance of the results using a generalized lin-
ear mixed model with CONDITION and SUBJECT
as factors, which yields a p-value of 0.027 when
compared against a null model in which only SUB-
JECT is a factor. No significant effects of between-
subjects factors gender, difficulty or preference
were found. In addition, the within-subject variable
time did not have any significant effect (subjects do
not improve in the memory task with time).
The average response delay (from the end of
the recall question to the button press) per condi-
tion across all subjects is shown in Figure 4. Sub-
jects reply slower to the recall questions in the
CONTROL_LANE condition, while their perform-
ance in the ADAPTIVE_LANE condition is indis-
tinguishable from the CONTROL_EMPTY condi-
tion (in which there is no distraction). Addition-
ally, there is a general decreasing trend of response
delay with time, which means that users get ac-
quainted with the task (type of information, format
of question) over time. Both factors (condition
and time) are significant (repeated measures AN-
OVA, 2x2 factorial design, F
condition
= 3.858, p =
0.0359,F
time
= 4.672, p= 0.00662). No significant
effects were found for any of the between-subject
factors (gender, difficulty, preference).
Driving task The success rate in the lane-change
task per condition is shown in Table 5. Here too
we find that the performance is lower in the CON-
TROL_LANE condition, while ADAPTIVE_LANE
does not seem to affect driving performance, when
compared to the NOTALK_LANE condition. The
effect is significant (p = 0.01231) using the same
GLMM approach and factors as above.
ADAPTIVE_LANE CONTROL_EMPTY CONTROL_LANECondition0
500
1000
1500
2000
2500
3000
3500
4000
User
 Res
pons
e De
lay (
ms)
Figure 4: User answer response delay under three
conditions.
5 Discussion, Conclusions, Future Work
We have developed and tested a driving simula-
tion scenario where information is presented by a
spoken dialogue system. Our system has the unique
ability (compared to today?s commercial systems)
to adapt its speech to the driving situation: it in-
terrupts itself when a dangerous situation occurs
and later resumes with an appropriate continuation.
Using this strategy, information presentation had
no impact on driving, and dangerous situations no
impact on information recall. In contrast, a system
that blindly spoke while the driver was distracted
by the lane-change task resulted in worse perform-
ance in both tasks: subjects made more errors in
the memory task and also failed more of the lane-
change tasks, which could prove dangerous in a
real situation.
Interestingly, very few of the subjects preferred
the adaptive version of the system in the post-task
questionnaire. Among the reasons that they gave
for this was their inability to control the interrup-
tions/resumptions of the system. We plan to ad-
dress the issue of control by allowing future ver-
sions of our system to accept user signals, such as
speech or head gestures; it will be interesting to see
whether this will impact driving performance or not.
Further, more sophisticated presentation strategies
(e.g., controlling the complexity of the generated
language in accordance to the driving situation) can
be tested in this framework.
Acknowledgments This research was partly sup-
ported by the Deutsche Forschungsgemeinschaft
(DFG) in the CRC 673 ?Alignment in Communic-
71
ation? and the Center of Excellence in ?Cognit-
ive Interaction Technology? (CITEC). The authors
would like to thank Oliver Eckmeier and Michael
Bartholdt for helping implement the system setup,
as well as Gerdis Anderson and Fabian Wohlge-
muth for assisting as experimenters.
References
Timo Baumann and David Schlangen. 2012. The In-
proTK 2012 release. In NAACL-HLT Workshop on
Future directions and needs in the Spoken Dialog
Community: Tools and Data (SDCTD 2012), pages
29?32, Montr?al, Canada.
Hendrik Buschmeier, Timo Baumann, Benjamin
Dosch, Stefan Kopp, and David Schlangen. 2012.
Combining incremental language generation and in-
cremental speech synthesis for adaptive information
presentation. In Proceedings of the 13th Annual
Meeting of the Special Interest Group on Discourse
and Dialogue, pages 295?303, Seoul, South Korea.
Frank A. Drews, Monisha Pasupathi, and David L.
Strayer. 2004. Passenger and cell-phone conver-
sations in simulated driving. In Proceedings of the
48th Annual Meeting of the Human Factors and Er-
gonomics Society, pages 2210?2212, New Orleans,
USA.
William J. Horrey and Christopher D. Wickens. 2006.
Examining the impact of cell phone conversations
on driving using meta-analytic techniques. Human
Factors, 48:196?205.
ISO. 2010. Road vehicles ? Ergonomic aspects of
transport information and control systems ? Simu-
lated lane change test to assess in-vehicle second-
ary task demand. ISO 26022:2010, Geneva, Switzer-
land.
Spyros Kousidis, Thies Pfeiffer, and David Schlangen.
2013. MINT.tools: Tools and adaptors supporting
acquisition, annotation and analysis of multimodal
corpora. In Interspeech 2013, Lyon, France. ISCA.
Pierre Lison. 2012. Probabilistic dialogue models with
prior domain knowledge. In Proceedings of the 13th
Annual Meeting of the Special Interest Group on Dis-
course and Dialogue, pages 179?188, Seoul, South
Korea.
David L Strayer, Frank A Drews, and Dennis J Crouch.
2006. A comparison of the cell phone driver and the
drunk driver. Human Factors, 48:381?91.
David L Strayer, Joel M Cooper, Jonna Turrill, James
Coleman, and Nate Medeiros. 2013. Measuring
cognitive distraction in the automobile. Technical
report, AAA Foundation for Traffice Safety.
J Wienke and S Wrede. 2011. A middleware for col-
laborative research in experimental robotics. In Sys-
tem Integration (SII), 2011 IEEE/SICE International
Symposium on, pages 1183?1190.
72
Proceedings of the SIGDIAL 2014 Conference, pages 84?88,
Philadelphia, U.S.A., 18-20 June 2014.
c?2014 Association for Computational Linguistics
InproTK
S
: A Toolkit for Incremental Situated Processing
Casey Kennington
CITEC, Dialogue Systems
Group, Bielefeld University
ckennington
1
Spyros Kousidis
Dialogue Systems Group
Bielefeld University
spyros.kousidis
2
1
@cit-ec.uni-bielefeld.de
2
@uni-bielefeld.de
David Schlangen
Dialogue Systems Group
Bielefeld University
david.schlangen
2
Abstract
In order to process incremental situated
dialogue, it is necessary to accept infor-
mation from various sensors, each track-
ing, in real-time, different aspects of the
physical situation. We present extensions
of the incremental processing toolkit IN-
PROTK which make it possible to plug in
such multimodal sensors and to achieve
situated, real-time dialogue. We also de-
scribe a new module which enables the use
in INPROTK of the Google Web Speech
API, which offers speech recognition with
a very large vocabulary and a wide choice
of languages. We illustrate the use of these
extensions with a description of two sys-
tems handling different situated settings.
1 Introduction
Realising incremental processing of speech in-
and output ? a prerequisite to interpretation and
possibly production of speech concurrently with
the other dialogue participant ? requires some fun-
damental changes in the way that components
of dialogue systems operate and communicate
with each other (Schlangen and Skantze, 2011;
Schlangen and Skantze, 2009). Processing situ-
ated communication, that is, communication that
requires reference to the physical setting in which
it occurs, makes it necessary to accept (and fuse)
information from various different sensors, each
tracking different aspects of the physical situation,
making the system multimodal (Atrey et al., 2010;
Dumas et al., 2009; Waibel et al., 1996).
Incremental situated processing brings together
these requirements. In this paper, we present a col-
lection of extensions to the incremental process-
ing toolkit INPROTK (Baumann and Schlangen,
2012) that make it capable of processing situ-
ated communication in an incremental fashion:
we have developed a general architecture for
plugging in multimodal sensors whith we denote
INPROTK
S
, which includes instantiations for mo-
tion capture (via e.g. via Microsoft Kinect and
Leap Motion) and eye tracking (Seeingmachines
FaceLAB). We also describe a new module we
built that makes it possible to perform (large vo-
cabulary, open domain) speech recognition via the
Google Web Speech API. We describe these com-
ponents individually and give as use-cases in a
driving simulation setup, as well as real-time gaze
and gesture recognition.
In the next section, we will give some back-
ground on incremental processing, then describe
the new methods of plugging in multimodal sen-
sors, specifically using XML-RPC, the Robotics
Service Bus, and the InstantReality framework.
We then explain how we incorporated the Google
Web Speech API into InproTK, offer some use
cases for these new modules, and conclude.
2 Background: The IU model, INPROTK
As described in (Baumann and Schlangen, 2012),
INPROTK realizes the IU-model of incremen-
tal processing (Schlangen and Skantze, 2011;
Schlangen and Skantze, 2009), where incremental
systems consist of a network of processing mod-
ules. A typical module takes input from its left
buffer, performs some kind of processing on that
data, and places the processed result onto its right
buffer. The data are packaged as the payload of
incremental units (IUs) which are passed between
modules.
The IUs themselves are also interconnected via
so-called same level links (SLL) and grounded-in
links (GRIN), the former allowing the linking of
IUs as a growing sequence, the latter allowing that
sequence to convey what IUs directly affect it (see
Figure 1 for an example). A complication partic-
ular to incremental processing is that modules can
?change their mind? about what the best hypothe-
84
Figure 1: Example of IU network; part-of-speech
tags are grounded into words, tags and words have
same level links with left IU; four is revoked and
replaced with forty.
sis is, in light of later information, thus IUs can be
added, revoked, or committed to a network of IUs.
INPROTK determines how a module network is
?connected? via an XML-formatted configuration
file, which states module instantiations, includ-
ing the connections between left buffers and right
buffers of the various modules. Also part of the
toolkit is a selection of ?incremental processing-
ready? modules, and so makes it possible to realise
responsive speech-based systems.
3 InproTK and new I/O: InproTK
S
The new additions introduced here are realised as
INPROTK
S
modules. The new modules that input
information to an INPROTK
S
module network are
called listeners in that they ?listen? to their respec-
tive message passing systems, and modules that
output information from the network are called
informers. Listeners are specific to their method
of receiving information, explained in each sec-
tion below. Data received from listeners are pack-
aged into an IU and put onto the module?s right
buffer. Listener module left buffers are not used
in the standard way; left buffers receive data from
their respective message passing protocols. An in-
former takes all IUs from its left buffer, and sends
their payload via that module?s specific output
method, serving as a kind of right buffer. Figure
2 gives an example of how such listeners and in-
formers can be used. At the moment, only strings
can be read by listeners and sent by informers; fu-
ture extensions could allow for more complicated
data types.
Listener modules add new IUs to the network;
correspondingly, further modules have to be de-
signed in instatiated systems then can make use
of these information types. These IUs created by
the listeners are linked to each other via SLLs.
As with audio inputs in previous version of IN-
PROTK, these IUs are considered basedata and not
explictly linked via GRINs in the sensor data. The
modules defined so far also simply add IUs and do
not revoke.
We will now explain the three new methods of
getting data into and out of INPROTK
S
.
3.1 XML-RPC
XML-RPC is a remote procedure call protocol
which uses XML to encode its calls, and HTTP as a
transport mechanism. This requires a server/client
relationship where the listener is implemented as
the server on a specified port.
1
Remote sensors
(e.g., an eye tracker) are realised as clients and can
send data (encoded as a string) to the server using
a specific procedural call. The informer is also re-
alised as an XML-RPC client, which sends data to a
defined server. XML-RPC was introduced in 1998
and is widely implemented in many programming
languages.
Mic
Motion !Sensor
ASR
Listener
NLU
Speaker DMNLG
Informer
InproTKs
Logger
Gesture Classifier
Figure 2: Example architecture using new mod-
ules: motion is captured and processed externally
and class labels are sent to a listener, which adds
them to the IU network. Arrows denote connec-
tions from right buffers to left buffers. Information
from the DM is sent via an Informer to an external
logger. External gray modules denote input, white
modules denote output.
3.2 Robotics Service Bus
The Robotics Service Bus (RSB) is a middleware
environment originally designed for message-
passing in robotics systems (Wienke and Wrede,
2011).
2
As opposed to XML-RPC which requires
1
The specification can be found at http://xmlrpc.
scripting.com/spec.html
2
https://code.cor-lab.de/projects/rsb
85
point-to-point connections, RSB serves as a bus
across specified transport mechanisms. Simply,
a network of communication nodes can either in-
form by sending events (with a payload), or lis-
ten, i.e., receive events. Informers can send in-
formation on a specific scope which establishes
a visibility for listeners (e.g., a listener that re-
ceives events on scope /one/ will receive all events
that fall under the /one/ scope, whereas a listener
with added constants on the scope, e.g., /one/two/
will not receive events from different added con-
stants /one/three/, but the scope /one/ can listen
on all three of these scopes). A listener mod-
ule is realised in INPROTK
S
by setting the de-
sired scope in the configuration file, allowing IN-
PROTK
S
seamless interconnectivity with commu-
nication on RSB.
There is no theoretical limit to the number of in-
formers or listeners; events from a single informer
can be received by multiple listeners. Events are
typed and any new types can be added to the avail-
able set. RSB is under active development and is
becoming more widely used. Java, Python, and
C++ programming languages are currently sup-
ported. In our experience, RSB makes it particu-
larly convenient for setting distributed sensor pro-
cessing networks.
3.3 InstantReality
In (Kousidis et al., 2013), the InstantReality
framework, a virtual reality environment, was
used for monitoring and recording data in a real-
time multimodal interaction.
3
Each information
source (sensor) runs on its own dedicated work-
station and transmits the sensor data across a net-
work using the InstantIO interface. The data can
be received by different components such as In-
stantPlayer (3D visualization engine; invaluable
for monitoring of data integrity when recording
experimental sessions) or a logger that saves all
data to disk. Network communication is achieved
via multicast, which makes it possible to have any
number of listeners for a server and vice-versa.
The InstantIO API is currently available in C++
and Java. It comes with a non-extensible set of
types (primitives, 2D and 3D vectors, rotations,
images, sounds) which is however adequate for
most tracking applications. InstantIO listeners and
informers are easily configured in INPROTK
S
con-
figuration file.
3
http://www.instantreality.org/
3.4 Venice: Bridging the Interfaces
To make these different components/interfaces
compatible with each other, we have developed a
collection of bridging tools named Venice. Venice
serves two distinct functions. First, Venice.HUB,
which pushes data to/from any of the following
interfaces: disk (logger/replayer), InstantIO, and
RSB. This allows seamless setup of networks for
logging, playback, real-time processing (or com-
binations; e.g, for simulations), minimizing the
need for adaptations to handle different situations.
Second, Venice.IPC allows interprocess communi-
cation and mainly serves as a quick and efficient
way to create network components for new types
of sensors, regardless of the platform or language.
Venice.IPC acts as a server to which TCP clients
(a common interface for sensors) can connect. It
is highly configurable, readily accepting various
sensor data outputs, and sends data in real-time to
the InstantIO network.
Both Venice components operate on all three
major platforms (Linux, Windows, Mac OS X),
allowing great flexibility in software and sensors
that can be plugged in the architecture, regardless
of the vendor?s native API programming language
or supported platform. We discuss some use cases
in section 5.
4 Google Web Speech
One barrier to dialogue system development is
handling ASR. Open source toolkits are available,
each supporting a handful of languages, with each
language having a varying vocabulary size. A step
in overcoming this barrier is ?outsourcing? the
problem by making use of the Google Web Speech
API.
4
This interface supports many languages, in
most cases with a large, open domain of vocabu-
lary. We have been able to access the API directly
using INPROTK
S
, similar to (Henderson, 2014).
5
INPROTK
S
already supports an incremental vari-
ant of Sphinx4; a system designer can now choose
from these two alternatives.
At the moment, only the Google Chrome
browser implements the Web Speech API. When
the INPROTK
S
Web Speech module is invoked,
it creates a service which can be reached from
4
The Web Speech API Specificiation: https:
//dvcs.w3.org/hg/speech-api/raw-file/
tip/speechapi.html
5
Indeed, we used Matthew Henderson?s webdial project
as a basis: https://bitbucket.org/matthen/
webdialog
86
the Chrome browser via an URL (and hence, mi-
crophone client, dialogue processor and speech
recogniser can run on different machines). Navi-
gating to that URL shows a simple web page where
one can control the microphone. Figure 3 shows
how the components fit together.
While this setup improves recognition as com-
pared to the Sphinx4-based recognition previously
only available in INPROTK, there are some ar-
eas of concern. First, there is a delay caused by
the remote processing (on Google?s servers), re-
quiring alignment with data from other sensors.
Second, the returned transcription results are only
?semi-incremental?; sometimes chunks of words
are treated as single increments. Third, n-best lists
can only be obtained when the API detects the end
of the utterance (incrementally, only the top hy-
pothesis is returned). Fourth, the results have a
crude timestamp which signifies the end of the au-
dio segment. We use this timestamp in our con-
struction of word IUs, which in informal tests have
been found to be acceptable for our needs; we de-
fer more systematic testing to future work.
Figure 3: Data flow of Google Web Speech API:
Chrome browser controls the microphone, sends
audio to API and receives incremental hypotheses,
which are directly sent to InproTK
S
.
5 INPROTK
S
in Use
We exemplify the utility of INPROTK
S
in two ex-
periments recently performed in our lab.
In-car situated communication We have tested
a ?pause and resume? strategy for adaptive in-
formation presentation in a driving simulation
scenario (see Figure 4), using INPROTK
S
and
OpenDS (Math et al., 2013). Our dialogue man-
ager ? implemented using OpenDial (Lison, 2012)
? receives trigger events from OpenDS in order to
update its state, while it verbalises calendar events
and presents them via speech. This is achieved
by means of InstantIO servers we integrated into
OpenDS and respective listeners in INPROTK
S
. In
turn, InstantIO informers send data that is logged
Figure 4: Participant performing driving test while
listening to iNLG speech delivered by InProTK
S
.
by Venice.HUB. The results of this study are pub-
lished in (Kousidis et al., 2014). Having available
the modules described here made it surprisingly
straightforward to implement the interaction with
the driving simulator (treated as a kind of sensor).
Real-time gaze fixation and pointing gesture
detection Using the tools described here, we
have recently tested a real-time situated commu-
nication environment that uses speech, gaze, and
gesture simultaneously. Data from a Microsoft
Kinect and a Seeingmachines Facelab eye tracker
are logged in realtime to the InstantIO network.
A Venice.HUB component receives this data and
sends it over RSB to external components that
perform detection of gaze fixation and pointing
gestures, as described in (Kousidis et al., 2013).
These class labels are sent in turn over RSB to
INPROTK
S
listeners, aggregating these modalities
with the ASR in a language understanding module.
Again, this was only enabled by the framework de-
scribed here.
6 Conclusion
We have developed methods of providing mul-
timodal information to the incremental dialogue
middleware INPROTK. We have tested these
methods in real-time interaction and have found
them to work well, simplifying the process of
connecting external sensors necessary for multi-
modal, situated dialogue. We have further ex-
tended its options for ASR, connecting the Google
Web Speech API. We have also discussed Venice,
a tool for bridging RSB and InstantIO interfaces,
which can log real-time data in a time-aligned
manner, and replay that data. We also offered
some use-cases for our extensions.
INPROTK
S
is freely available and accessible.
6
6
https://bitbucket.org/inpro/inprotk
87
Acknowledgements Thank you to the anony-
mous reviewers for their useful comments and to
Oliver Eickmeyer for helping with InstantReality.
References
Pradeep K. Atrey, M. Anwar Hossain, Abdulmotaleb
El Saddik, and Mohan S. Kankanhalli. 2010. Multi-
modal fusion for multimedia analysis: a survey, vol-
ume 16. April.
Timo Baumann and David Schlangen. 2012. The In-
proTK 2012 Release. In NAACL.
Bruno Dumas, Denis Lalanne, and Sharon Oviatt.
2009. Multimodal Interfaces : A Survey of Princi-
ples , Models and Frameworks. In Human Machine
Interaction, pages 1?25.
Matthew Henderson. 2014. The webdialog Frame-
work for Spoken Dialog in the Browser. Technical
report, Cambridge Engineering Department.
Spyros Kousidis, Casey Kennington, and David
Schlangen. 2013. Investigating speaker gaze and
pointing behaviour in human-computer interaction
with the mint.tools collection. In SIGdial 2013.
Spyros Kousidis, Casey Kennington, Timo Baumann,
Hendrik Buschmeier, Stefan Kopp, and David
Schlangen. 2014. Situationally Aware In-Car Infor-
mation Presentation Using Incremental Speech Gen-
eration: Safer, and More Effective. In Workshop on
Dialog in Motion, EACL 2014.
Pierre Lison. 2012. Probabilistic Dialogue Mod-
els with Prior Domain Knowledge. In Proceedings
of the 13th Annual Meeting of the Special Interest
Group on Discourse and Dialogue, pages 179?188,
Seoul, South Korea, July. Association for Computa-
tional Linguistics.
Rafael Math, Angela Mahr, Mohammad M Moniri,
and Christian M?uller. 2013. OpenDS: A new
open-source driving simulator for research. GMM-
Fachbericht-AmE 2013.
David Schlangen and Gabriel Skantze. 2009. A Gen-
eral, Abstract Model of Incremental Dialogue Pro-
cessing. In Proceedings of the 10th EACL, number
April, pages 710?718, Athens, Greece. Association
for Computational Linguistics.
David Schlangen and Gabriel Skantze. 2011. A Gen-
eral, Abstract Model of Incremental Dialogue Pro-
cessing. Dialoge & Discourse, 2(1):83?111.
Alex Waibel, Minh Tue Vo, Paul Duchnowski, and Ste-
fan Manke. 1996. Multimodal interfaces. Artificial
Intelligence Review, 10(3-4):299?319.
Johannes Wienke and Sebastian Wrede. 2011. A
middleware for collaborative research in experimen-
tal robotics. In System Integration (SII), 2011
IEEE/SICE International Symposium on, pages
1183?1190.
88
