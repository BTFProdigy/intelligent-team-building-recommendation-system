A Framework for Unsupervised Natural Language Morphology Induction 
Christian Monson 
Language Technologies Institute 
Carnegie Mellon University  
5000 Forbes Ave. 
Pittsburgh, PA, USA 15213 
  cmonson@cs.cmu.edu 
 
Abstract 
This paper presents a framework for unsuper-
vised natural language morphology induction 
wherein candidate suffixes are grouped into 
candidate inflection classes, which are then ar-
ranged in a lattice structure.  With similar can-
didate inflection classes placed near one an-
other in the lattice, I propose this structure is 
an ideal search space in which to isolate the 
true inflection classes of a language.  This pa-
per discusses and motivates possible search 
strategies over the inflection class lattice struc-
ture. 
1 Introduction 
Many natural language processing tasks, includ-
ing parsing and machine translation, frequently 
require a morphological analysis of the language(s) 
at hand.  The task of a morphological analyzer is to 
identify the lexeme, citation form, or inflection 
class of surface word forms in a language.  Striv-
ing to bypass the time consuming, labor intensive 
task of constructing a morphological analyzer by 
hand, unsupervised morphology induction tech-
niques seek to automatically discover the morpho-
logical structure of a natural language through the 
analysis of corpora. 
This paper presents a framework for automatic 
natural language morphology induction inspired by 
the traditional and linguistic concept of inflection 
classes.  Monson et al (2004) uses the framework 
discussed in this paper and presents results using 
an intuitive baseline search strategy.  This paper 
presents a discussion of the candidate inflection 
class framework as a generalization of corpus tries 
used in early work (Harris, 1955; Harris, 1967; 
Hafer and Weiss, 1974) and discusses an as yet 
unimplemented statistically motivated search strat-
egy.   This paper employs English to illustrate its 
main conjectures and a Spanish newswire corpus 
of 40,011 tokens and 6,975 types for concrete ex-
amples. 
2 Previous Work 
It is possible to organize much of the recent 
work on unsupervised morphology induction by 
considering the bias each approach has toward dis-
covering morphologically related words that are 
also orthographically similar.  Yarowsky et al 
(2001), who acquire a morphological analyzer for 
a language by projecting the morphological analy-
sis of a second language onto the first through a 
clever application of statistical machine translation 
style word alignment probabilities, place no con-
straints on the orthographic shape of related word 
forms.  
Next along the spectrum of orthographic similar-
ity bias is the work of Schone and Jurafsky (2000; 
2001), who first acquire a list of potential morpho-
logical variants using an orthographic similarity 
technique due to Gaussier (1999) in which  pairs of 
words with the same initial string are identified.  
They then apply latent semantic analysis (LSA) to 
score the potential morphological variants with a 
semantic distance.  Word forms with small seman-
tic distance are proposed as morphological variants 
of one anther. 
Goldsmith (2001), by searching over a space of 
morphology models limited to substitution of suf-
fixes, ties morphology yet closer to orthography.  
Segmenting word forms in a corpus, Goldsmith 
creates an inventory of stems and suffixes.  Suf-
fixes which can interchangeably concatenate onto 
a set of stems form a signature.  After defining the 
space of signatures, Goldsmith searches for that 
choice of word segmentations resulting in a mini-
mum description length local optimum. 
Finally, the work of Harris (1955; 1967), and 
later Hafer and Weiss (1974), has direct bearing on 
the approach taken in this paper.  Couched in mod-
ern terms, their work involves first building tries 
over a corpus vocabulary and then selecting, as 
morpheme boundaries, those character boundaries 
with corresponding high branching count in the 
tries. 
The work in this paper also has a strong bias to-
ward discovering morphologically related words 
that share a similar orthography.  In particular, the 
morphology model I use is, akin to Goldsmith, 
limited to suffix substitution.  The novel proposal I 
bring to the table, however, is a formalization of 
the full search space of all candidate inflection 
classes.  With this framework in place, defining 
search strategies for morpheme discovery becomes 
a natural and straightforward activity. 
3 Inflection Classes as Motivation 
When learning the morphology of a foreign lan-
guage, it is common for a student to study tables of 
inflection classes.  Carstairs-McCarthy formalizes 
the concept of an inflection class in chapter 16 of 
The Handbook of Morphology (1998).  In his ter-
minology, a language with inflectional morphol-
ogy contains lexemes which occur in a variety of 
word forms.  Each word form carries two pieces of 
information: 
1) Lexical content and  
2) Morphosyntactic properties.   
For example, the English word form gave ex-
presses the lexeme GIVE plus the morphosyntactic 
property Past, while gives expresses GIVE plus the 
properties 3rd Person, Singular, and Non-Past. 
A set of morphosyntactic properties realized 
with a single word form is defined to be a cell, 
while a paradigm is a set of cells exactly filled by 
the word forms of some lexeme.  A particular natu-
ral language may have many paradigms.  In Eng-
lish, a language with very little inflectional mor-
phology, there are at least two paradigms, a noun 
paradigm consisting of two cells, Singular and 
Plural, and a paradigm for verbs, consisting of the 
five cells given (with one choice of naming con-
vention) as the first column of Table 1. 
Lexemes that belong to the same paradigm may 
still differ in their morphophonemic realizations of 
various cells in that paradigm?each paradigm 
may have several associated inflection classes 
which specify, for the lexemes belonging to that 
inflection class, the surface instantiation for each 
cell of the paradigm.  Three of the many inflection 
classes within the English verb paradigm are found 
in Table 1 under the columns labeled A through C.   
The task the morphology induction system pre-
sented in this paper engages is exactly the discov-
ery of the inflection classes of a natural language.  
Unlike the analysis in Table 1, however, the rest of 
this paper treats word forms as simply strings of 
characters as opposed to strings of phonemes. 
4 Empirical Inflection Classes 
There are two stages in the approach to unsuper-
vised morphology induction proposed in this pa-
per.  First, a search space over a set of candidate 
inflection classes is defined, and second, this space 
is searched for those candidates most likely to be 
part of a true inflection class in the language.  I 
have written a program to create the search space 
but the search strategies described in this paper 
have yet to be implemented. 
4.1 Candidate Inflection Class Search Space 
To define a search space wherein inflection 
classes of a natural language can be identified, my 
algorithm accepts as input a monolingual corpus 
for the language and proposes candidate mor-
pheme boundaries at every character boundary in 
every word form in the corpus vocabulary.  I call 
each string before a candidate morpheme boundary 
a candidate stem or c-stem, and each string after a 
boundary a c-suffix.  I define a candidate inflection 
class (CIC) to be a set of c-suffixes for which there 
exists at least one c-stem, t, such that each c-suffix 
in the CIC concatenated to t produces a word form 
in the vocabulary.  I let the set of c-stems which 
generate a CIC, C, be called the adherent c-stems 
of C; the size of the set of adherent c-stems of C be 
C?s adherent size; and the size of the set of c-
suffixes in C be the level of C. 
I then define a lattice of relations between CIC?s.  
In particular, two types of relations are defined: 
1) C-suffix set inclusion relations relate pairs 
of CIC?s when the c-suffixes of one CIC are 
a superset of the c-suffixes of the other, and 
2) Morpheme boundary relations occur be-
tween CIC?s which propose different mor-
Inflection Classes Verb 
Paradigm A B C 
Basic 
blame 
roam 
solve 
show 
sow 
saw 
sing 
ring 
3rd Person 
Singular     
Non-past 
-/z/ 
blames 
roams 
solves 
-/z/ 
shows 
sows 
saws 
-/z/ 
sings 
rings 
 
Past 
-/d/ 
blamed 
roamed 
solved 
-/d/ 
showed 
sowed 
sawed 
V? /eI/ 
sang 
rang 
 
Perfective       
or Passive 
-/d/ 
blamed 
roamed 
solved 
-/n/ 
shown 
sown 
sawn 
V? /?/ 
sung 
rung 
 
Progressive 
-/i?/ 
blaming 
roaming 
solving 
-/i?/ 
showing 
sowing 
sawing 
-/i?/ 
singing 
ringing 
 
 
Table 1: A few inflection classes of the Eng-
lish verb paradigm 
pheme boundaries within the same word 
forms. 
Figure 1 diagrams a portion of a CIC lattice over 
a toy vocabulary consisting of a subset of the word 
forms found under inflection class A from Table 1.  
The c-suffix set inclusion relations, represented 
vertically by solid lines, connect such CIC?s as 
e.es.ed and e.ed, both of which originate from the 
c-stem blam, since the first is a superset of the sec-
ond.  Morpheme boundary relations, drawn hori-
zontally with dashed lines, connect such CIC?s as 
me.mes.med and e.es.ed, each derived from ex-
actly the triple of word forms blame, blames, and 
blamed, but differing in the placement of the hy-
pothesized morpheme boundary 
Hierarchical links, connect any given CIC to of-
ten more than one parent and more than one child.  
The empty CIC (not pictured in Figure 1) can be 
considered the child of all level one CIC?s (includ-
ing the ? CIC), but there is no universal parent of 
all top level CIC?s.   
Horizontal morpheme boundary links, dashed 
lines, connect a CIC, C, with a neighbor to the 
right if each c-suffix in C begins with the same 
character.  This entails that there is at most one 
morpheme boundary link leading to the right of 
each CIC.  There may be, however, as many links 
leading to the left as there are characters in the or-
thography.  The only CIC with depicted multiple 
left links in Figure 1 is ?, which has left links to 
the CIC?s e, s, and d.  A number of left links ema-
nating from the CIC?s in Figure 1 are not shown; 
among others absent from the figure is the left link 
from the CIC e.es leading to the CIC ve.ves with 
the adherent sol.   
While many ridiculous CIC?s are found in Fig-
ure 1, such as ame.ames.amed from the vocabu-
lary items blame, blames, and blamed and the c-
stem bl, there are also CIC?s that seem very rea-
sonable, such as ?.s from the c-stems blame and 
tease.  The key task in automatic morphology in-
duction is to autonomously separate the nonsense 
CIC?s from the useful ones, thus identifying lin-
guistically plausible inflection classes. 
To better visualize what a CIC lattice looks like 
when derived from real data, Figure 2 contains a 
portion of a hierarchical lattice automatically gen-
erated from the Spanish newswire corpus.  Each 
entry in Figure 2 contains the c-suffixes compris-
ing the CIC, the adherent size of the CIC, and a 
sample of adherent c-stems.  The lattice in Figure 2 
covers: 
1) The productive Spanish inflection class for 
adjectives, a.as.o.os, covering the four cells 
feminine singular, feminine plural, masculine 
singular, and masculine plural, respectively; 
2) All possible CIC subsets of the adjective 
CIC, e.g. a.as.o, a.os, etc.; and 
3) The imposter CIC a.as.o.os.tro, together 
with its rogue descendents, a.tro and tro.   
Other CIC?s that are descendents of 
a.as.o.os.tro and that contain the c-suffix tro do 
not supply additional adherents and hence are not 
present either in Figure 2 or in my program?s rep-
resentation of the CIC lattice.  The CIC?s a.as.tro 
and os.tro, for example, both have only the one 
adherent, cas, already possessed by their common 
ancestor a.as.o.os.tro. 
4.2 Search 
With the space of candidate inflection classes 
defined, it seems natural to treat this lattice of 
CIC?s as a hypothesis space of valid inflection 
classes and to search this space for CIC?s most 
likely to be true inflection classes in a language.  
There are many possible search strategies applica-
ble to the CIC lattice.  Monson et al (2004) inves-
tigate a series of heuristic search algorithms.  Us-
ing the same Spanish newswire corpus as this pa-
per, the implemented algorithms have achieved F1 
measures above 0.5 when identifying CIC?s be-
longing to true inflection classes in Spanish.  In 
e.es 
blam 
solv 
e.ed 
blam 
es 
blam 
solv 
?.s.d 
blame 
?.s 
blame 
solve 
? 
blame 
blames 
blamed 
roams 
roamed 
roaming 
solve 
solves 
solving 
e.es.ed 
blam 
ed 
blam 
roam 
d 
blame 
roame 
?.d 
blame 
s.d 
blame 
s 
blame 
roam 
solve 
es.ed 
blam 
e 
blam 
solv 
me.mes 
bla 
me.med 
bla 
mes 
bla 
me.mes.med 
bla 
med 
bla 
roa 
mes.med 
bla 
me 
bla 
Figure 1: Portion of a CIC lattice from the 
toy vocabulary: blame, blames, blamed, roams, 
roamed, roaming, solve, solves, solving 
Hierarchical c-suffix set inclusion links 
Morpheme boundary links 
this paper I discuss some theoretical motivations 
underlying CIC lattice search. 
Since there are two types of relations in the CIC 
lattices I construct, search can be broken into two 
phases.  One phase searches the c-suffix set inclu-
sion relations, and the other phase searches the 
morpheme boundary relations.  The search algo-
rithms discussed in Monson et al (2004) focus on 
searching the c-suffix set inclusion relations and 
only utilize morpheme boundary links as a con-
straint.  
In previous related work, morpheme boundary 
relations and c-suffix set inclusion relations are 
implicitly present but not explicitly referred to.  
For example, Goldsmith (2001) does not separate 
these two types of search.  Goldsmith?s triage 
search strategies, which make small changes in the 
segmentation positions in words, primarily search 
the morpheme boundary relations, while the verti-
cal search is primarily performed by heuristics that 
suggest initial word segmentations.  To illustrate, 
if, using the Spanish newswire corpus from this 
paper, Goldsmith?s algorithm decided to segment 
the word form castro as cas-tro, then there is an 
implicit vote for the CIC a.as.o.os.tro in Figure 2.  
If, on the other hand, his algorithm decided not to 
segment castro then there is a vote for the lower 
level CIC a.as.o.os. 
The next two subsections motivate search over 
the morpheme boundary relations and the c-suffix 
set inclusion relations respectively. 
4.2.1 Searching Morpheme Boundary Relations 
Harris (1955; 1967) and Hafer and Weiss (1974) 
obtain intriguing results at segmenting word forms 
into morphemes by first placing the word forms 
from a vocabulary in a trie, such as the trie pic-
tured in the top half of Figure 3, and then propos-
ing morpheme boundaries after trie nodes that have 
a large branching factor.  The rationale behind 
their procedure is that the phoneme, or grapheme, 
sequence within a morpheme is completely re-
stricted, while at a morpheme boundary any num-
ber of new morphemes (many with different initial 
phonemes) could occur.  To assess the flavor of 
Harris? algorithms, the bottom branch of the trie in 
Figure 3 begins with roam and subsequently en-
counters a branching factor of three, leading to the 
trie nodes ?, i, and s.  Such a high branching factor 
suggests there may be a morpheme boundary after 
roam.   
One way to view the horizontal morpheme 
boundary links in a CIC lattice is as a character trie 
generalization where identical sub-tries within the 
full vocabulary trie are conflated.  Figure 3 illus-
trates the correspondences between a trie and a 
portion of a CIC lattice for a small vocabulary con-
sisting of the word forms: rest, rests, resting, re-
treat, retreats, retreating, retry, retries, retrying, 
roam, roams, and roaming.  Each circled sub-trie 
of the trie in the top portion of the figure corre-
sponds to one of the four CIC?s in the bottom por-
tion of the figure.  For example, the right-
branching children of the y node in retry form a 
sub-trie consisting of ? and ing, but this same sub-
trie is also found following the t node in rest, the t 
node in retreat, and the m node in roam.  The CIC 
lattice conflates all these sub-tries into the single 
CIC ?.ing with the four adherents rest, retreat, 
retry, and roam. 
Taking this congruency further, branching factor 
in the trie corresponds roughly to the level of a 
CIC.  A level 3 CIC such as ?.ing.s corresponds to 
sub-tries with initial branching factor of 3.  If sepa-
rate c-suffixes in a CIC happen to begin with the 
same character, then a lower branching factor may 
correspond to a higher level CIC.  Similarly, the 
number of sub-tries which conflate to form a CIC 
corresponds to the number of adherents belonging 
to the CIC. 
Figure 2: Hierarchical CIC lattice automati-
cally derived from Spanish 
a.as.o.os 
43 
african 
cas 
jur?dic 
l 
... 
a.as.o.os.tro 
1 
cas 
a.as.os 
50 
afectad 
cas 
jur?dic 
l 
... 
a.as.o 
59 
cas 
citad 
jur?dic 
l 
... 
a.o.os 
105 
impuest 
indonesi 
italian 
jur?dic 
... 
a.as 
199 
huelg 
incluid 
industri 
inundad 
... 
a.os 
134 
impedid 
impuest 
indonesi 
inundad 
... 
as.os 
68 
cas 
implicad 
inundad 
jur?dic 
... 
a.o 
214 
id 
indi 
indonesi 
inmediat 
... 
as.o 
85 
intern 
jur?dic 
just 
l 
... 
a.tro 
2 
cas 
cen 
a 
1237 
huelg 
ib 
id 
iglesi 
... 
as 
404 
huelg 
huelguist 
incluid 
industri 
... 
os 
534 
humor?stic 
human 
h?gad 
impedid 
... 
o 
1139 
hub 
hug 
human 
huyend 
... 
tro 
16 
catas 
ce 
cen 
cua 
... 
as.o.os 
54 
cas 
implicad 
jur?dic 
l 
... 
 
o.os 
268 
human 
implicad 
indici 
indocumentad 
... 
It is interesting to note that while Harris? style 
phoneme successor criteria do often correctly iden-
tify morpheme boundaries, they posses one inher-
ent class of errors.  Because Harris treats all word 
forms with the same initial string as identical, any 
morpheme boundary decision is global for all 
words that happen to begin with the same string.  
For example, Harris cannot differentiate between 
the forms casa and castro.  If a morpheme bound-
ary is (correctly) placed after the cas in casa, then 
a morpheme boundary must be placed (incorrectly) 
after the cas in castro.  Using a CIC lattice, how-
ever, allows an algorithm to first choose which 
branches of a trie are relevant and then select mor-
pheme boundaries given the relevant sub-trie.  Ex-
ploring the vertical CIC lattice in Figure 2, a 
search algorithm might hope to discover that the 
tro trie branch is irrelevant and search for a mor-
pheme boundary along the sub-tries ending in 
a.as.o.os.  Perhaps the morpheme boundary search 
would use the branching factor of this restricted 
trie as a discriminative criterion. 
4.2.2 Searching C-suffix Set Inclusion Relations 
Since trie branches correspond to CIC level, I 
turn now to outline a search method over the verti-
cal c-suffix set inclusion relations.  This search 
method makes particular use of CIC adherent 
counts through the application of statistical inde-
pendence tests.  The goal of a vertical search algo-
rithm is to avoid c-suffixes which occur not as true 
suffixes that are part of an inflection class, but in-
stead as random strings that happen to be able to 
attach to a given initial string. 
To formalize the idea of randomness I treat each 
c-suffix, F, as a Boolean random variable which is 
true when F attaches to a given c-stem and false 
when F does not attach to that c-stem.  I then make 
the simplifying assumption that c-stems are inde-
pendent identically distributed draws from the 
population of all possible c-stems.  Since my algo-
rithm identifies all possible initial substrings of a 
vocabulary as c-stems, the c-stems are clearly not 
truly independent?some c-stems are actually sub-
strings of other c-stems.   
Nevertheless, natural language inflection classes, 
in the model of this paper, consist of c-suffixes 
which interchangeably attach to the same c-stems.  
Hence, given the assumption of c-suffixes as ran-
dom variables, the true inflection classes of a lan-
guage are most likely those groups of c-suffixes 
which are positively correlated.  That is, if know-
ing that c-suffix F1 concatenates onto c-stem T in-
creases the probability that the suffix F2 also con-
catenates onto T, then F1 and F2 are likely from the 
same inflection class.  On the other hand, if F1 and 
F2 are statistically independent, or knowing that F1 
concatenates to T does not change the probability 
that F2 can attach to T, then it is likely that F1 or F2 
(or both) is a c-suffix that just randomly happens to 
be able to concatenate onto a T.  And finally, if F1 
and F2 are negatively correlated, i.e. they occur 
interchangeably on the same c-stem less frequently 
than random chance, then it may be that F1 and F2 
come from different inflection classes within the 
same paradigm or are even associated with com-
pletely separate paradigms. 
There are a number of statistical tests designed 
to assess the probability that two discrete random 
variables are independent. Here I will look at the ?2 
independence test, which computes the probability 
that two random variables are independent by cal-
culating a statistic Q distributed as ?2 by comparing 
the expected distributions of the two random vari-
ables, assuming their independence with their ac-
tual distribution.  The larger the values of Q, the 
lower the probability that the random variables are 
independent. 
Summing the results of each c-stem independent 
trial of the c-suffix Boolean random variables, re-
r 
e 
o 
s t 
t r 
a 
y 
i e s 
? 
i n g 
i n g 
s 
e a t i n g 
? 
? 
m 
? 
i n g 
s 
s 
t.ts.ting 
res 
retrea 
t.ting 
res 
retrea 
?.ing 
rest 
retreat 
retry 
roam 
?.s.ing 
rest 
retreat 
roam 
Figure 3: A trie (top) with some repeated sub-
tries circled.  These sub-tries are then conflated 
into the corresponding CIC lattice (bottom). 
sults in Bernoulli distributed random variables 
whose joint distributions can be described as two 
by two contingency tables.  Table 2 gives such 
contingency tables for the pairs of random variable 
c-suffixes (a, as) and (a, tro).  These tables can be 
calculated by examining specific CIC?s in the lat-
tices.  To fill the contingency table for (a, as) I 
proceed as follows: The number of times a occurs 
jointly with as is exactly the adherent size of the 
a.as CIC, 199.  The marginal number of occur-
rences of a, 1237, can be read from the CIC a, and 
similarly the marginal number of occurrences of 
as, 404, can be read from the CIC as.  The bottom 
right-hand cell in the tables in Table 2 is the total 
number of trials, or in this case, the number of 
unique c-stems.  This quantity is easily calculated 
by summing the adherent sizes of all level one 
CIC?s together.  In the Spanish newswire corpus 
there are 22950 unique c-stems.  The remaining 
cells in the contingency table can be calculated by 
assuring the rows and columns sum up to their 
marginals. Using these numbers we can calculate 
the Q statistic: Q(a, as) = 1552 and Q(a, tro) = 
1.587.  These values suggest that a and as are not 
independent while a and tro are. 
5  Future Work  
There is clearly considerable work left to do 
within the CIC framework presented in this paper.  
I intend to implement the search strategies outlined 
in this paper.  I also plan to apply these techniques 
to describe the morphologies of a variety of lan-
guages beyond English and Spanish. 
Acknowledgements 
The research presented in this paper was funded 
in part by NSF grant number IIS-0121631. 
References 
Andrew Carstairs-McCarthy. 1998. ?Paradigmatic 
Structure: Inflectional Paradigms and Morpho-
logical Classes.? The Handbook of Morphology. 
Eds. Andrew Spencer and Arnold M. Zwicky. 
Blackwell Publishers Inc., Massachusetts, USA, 
322-334. 
?ric Gaussier. 1999. Unsupervised learning of 
derivational morphology from inflectional lexi-
cons. In Proceedings of ACL ?99 Workshop: Un-
supervised Learning in Natural Language Proc-
essing. 
John Goldsmith. 2001. Unsupervised learning of 
the morphology of a natural language. Computa-
tional Linguistics, 27(2): 153-198. 
Margaret A. Hafer and Stephen F. Weiss. 1974. 
Word segmentation by letter successor varieties. 
Information Storage and Retrieval, 10:371-385. 
Zellig Harris. 1955. From phoneme to morpheme. 
Language, 31:190-222. Reprinted in Harris 
1970. 
Zellig Harris. 1967. Morpheme boundaries within 
words: Report on a computer test. Transforma-
tion and Discourse Analysis Papers 73, Depart-
ment of Linguistics, University of Pennsylvania. 
Reprinted in Harris 1970. 
Zellig Harris. 1970. Papers in Structural and 
Transformational Linguistics. D. Reidel, 
Dordrecht, Holland. 
Christian Monson, Alon Lavie, Jaime Carbonell, 
and Lori Levin. 2004. Unsupervised Induction of 
Natural Language Morphology Inflection 
Classes. In Proceedings of the Seventh Meeting 
of the ACL Special Interest Group in Computa-
tional Phonology (SIGPHON?04). 
Patrick Schone and Daniel Jurafsky. 2000. Knowl-
edge-free Induction of Morphology Using Latent 
Semantic Analysis. In Proceedings of the Fourth 
Conference on Computational Natural Language 
Learning and of the Second Learning Language 
in Logic Workshop, 67-72. 
Patrick Schone and Daniel Jurafsky. 2001. Knowl-
edge-free Induction of Inflectional Morpholo-
gies. In Proceedings of the North American 
Chapter of the Association of Computational 
Linguistics. 183-191. 
David Yarowsky, Grace Ngai, and Richard Wicen-
towski. 2001. Inducing multilingual text analysis 
tools via robust projection across aligned cor-
pora. In Proceedings of the Human Language 
Technology Conference, 161-168. 
 
Table 2: Contingency tables for a few c-suffixes 
 a ~a marginal 
as 199 205 404 
~as 1038 21508 22546 
marginal 1237 21713 22950 
 
 a ~a marginal 
tro 2 14 16 
~tro 1235 21699 22934 
marginal 1237 21713 22950 
 
 
Unsupervised Induction of Natural Language Morphology Inflection Classes 
Christian Monson, Alon Lavie, Jaime Carbonell, Lori Levin 
Language Technologies Institute 
Carnegie Mellon University  
5000 Forbes Ave. 
Pittsburgh, USA 15213 
{cmonson, alavie+, jgc+, lsl+}@cs.cmu.edu 
 
Abstract 
We propose a novel language-independent 
framework for inducing a collection of mor-
phological inflection classes from a monolin-
gual corpus of full form words.  Our approach 
involves two main stages.  In the first stage, 
we generate a large data structure of candidate 
inflection classes and their interrelationships.  
In the second stage, search and filtering tech-
niques are applied to this data structure, to 
identify a select collection of "true" inflection 
classes of the language.  We describe the basic 
methodology involved in both stages of our 
approach and present an evaluation of our 
baseline techniques applied to induction of 
major inflection classes of Spanish.  The pre-
liminary results on an initial training corpus 
already surpass an F1 of 0.5 against ideal 
Spanish inflectional morphology classes. 
1 Introduction 
Many natural language processing tasks, such as 
morphological analysis and parsing, have mature 
solutions when applied to resource-rich European 
and Asian languages.  Addressing these same tasks 
in less studied low-density languages, however, 
poses exciting challenges.   
These languages have limited available re-
sources: with perhaps a few million speakers there 
is likely no native speaker linguist and frequently 
there is little electronic text readily available.  To 
compound the difficulties, while low-density lan-
guages abound, comparatively little financial re-
sources are available to address their challenges.  
These considerations suggest developing systems 
to automatically induce solutions for NLP tasks in 
new languages. 
The AVENUE project (Lavie et al 2003; Car-
bonell et al, 2002; Probst et al, 2002) at Carnegie 
Mellon University seeks to apply automatic induc-
tion methods to develop rule-based machine trans-
lation systems between pairs of languages where 
one of the languages is low-density and the other is 
resource-rich.  We are currently pursuing MT sys-
tems with Mapudungun, an indigenous language 
spoken by 900,000 people in southern Chile and 
Argentina, and Aymara, spoken by 3 million peo-
ple in Bolivia, Peru, and northern Chile, as low-
density languages and Spanish the resource rich 
language. 
A vital first step in a rule-based machine transla-
tion system is morphological analysis.  This paper 
outlines a framework for automatic natural lan-
guage morphology induction inspired by the tradi-
tional and linguistic concept of inflection classes.  
Additional details concerning the candidate inflec-
tion class framework can be found in Monson 
(2004).  This paper then goes on to describe one 
implemented search strategy within this frame-
work, presenting both a simple summary of results 
and an in depth error analysis. 
While the intent of this research direction is to 
define techniques applicable to low-density lan-
guages, this paper employs English to illustrate the 
main conjectures and Spanish, a language with a 
reasonably complex morphological system, for 
quantitative analysis.  All experiments detailed in 
this paper are over a Spanish newswire corpus of 
40,011 tokens and 6,975 types. 
2 Previous Work 
It is possible to organize much of the recent 
work on unsupervised morphology induction by 
considering the bias each approach has toward dis-
covering morphologically related words that are 
also orthographically similar. 
At one end of the spectrum is the work of 
Yarowsky et al (2001), who derive a morphologi-
cal analyzer for a language, L, by projecting the 
morphological analysis of a resource-rich language 
onto L through a clever application of statistical 
machine translation style word alignment prob-
abilities.  The word alignments are trained over a 
sentence aligned parallel bilingual text for the lan-
guage pair.  While the probabilistic model they use 
to generalize their initial system contains a bias 
toward orthographic similarity, the unembellished 
algorithm contains no assumptions on the ortho-
graphic shape of related word forms. 
Next along the spectrum of orthographic similar-
                                                                  Barcelona, July 2004
                                              Association for Computations Linguistics
                       ACL Special Interest Group on Computational Phonology (SIGPHON)
                                                    Proceedings of the Workshop of the
ity bias is the work of Schone and Jurafsky (2000), 
who first acquire a list of pairs of potential mor-
phological variants (PPMV?s) using an ortho-
graphic similarity technique due to Gaussier 
(1999), in which pairs of words from a corpus vo-
cabulary with the same initial string are identified.  
They then apply latent semantic analysis (LSA) to 
score each PPMV with a semantic distance.  Pairs 
measuring a small distance, those whose potential 
variants tend to occur where a neighborhood of the 
nearest hundred words contains similar counts of 
individual high-frequency forms, are then pro-
posed as true morphological variants of one anther.  
In later work, Schone and Jurafsky (2001) extend 
their technique to identify not only suffixes but 
also prefixes and circumfixes by building both 
forward and backward tries over a corpus. 
Goldsmith (2001), by searching over a space of 
morphology models limited to substitution of suf-
fixes, ties morphology yet closer to orthography.  
Segmenting word forms in a corpus, Goldsmith 
creates an inventory of stems and suffixes.  Suf-
fixes which can interchangeably concatenate onto 
a set of stems form a signature.  After defining the 
space of signatures, Goldsmith searches for that 
choice of word segmentations resulting in a mini-
mum description length local optimum. 
Finally, the work of Harris (1955; 1967), and 
later Hafer and Weiss (1974), has direct bearing on 
the approach taken in this paper.  Couched in mod-
ern terms, their work involves first building tries 
over a corpus vocabulary, and then selecting, as 
morpheme boundaries, those character boundaries 
with high branching count in the tries. 
The work in this paper also has a strong bias to-
ward discovering morphologically related words 
that share a similar orthography.  In particular, the 
morphology model we use is, akin to Goldsmith, 
limited to suffix substitution.  The novel proposal 
we bring to the table, however, is a formalization 
of the full search space of all candidate inflection 
classes.  With this bulwark in place, defining 
search strategies for morpheme discovery becomes 
a natural and straightforward activity. 
3 Inflection Classes as Motivation 
When learning the morphology of a foreign lan-
guage, it is common for a student to study tables of 
inflection classes.  In Spanish, for example, a regu-
lar verb belongs to one of three inflection 
classes?verbs that take the -ar infinitive suffix 
inflect for various syntactic features with one set of 
suffixes, verbs that take the -er infinitive suffix 
realize the same set of syntactic features with a 
second set of suffixes, while -ir verbs take yet a 
third set. 
Carstairs-McCarthy formalizes the concept of an 
inflection class in chapter 16 of The Handbook of 
Morphology (1998).  In his terminology, a lan-
guage with inflectional morphology contains lex-
emes which occur in a variety of word forms.  
Each word form carries two pieces of information: 
1) Lexical content and 
2) Morphosyntactic properties. 
For example, the English word form gave ex-
presses the lexeme GIVE plus the morphosyntactic 
property Past, while gives expresses GIVE plus the 
properties 3rd Person, Singular, and Non-Past. 
A set of morphosyntactic properties realized 
with a single word form is defined to be a cell, 
while a paradigm is a set of cells exactly expressed 
by the word forms of some lexeme.   
A particular natural language may have many 
paradigms.  In English, a language with very little 
inflectional morphology, there are at least two 
paradigms, a noun paradigm consisting of two 
cells, Singular and Plural, and a paradigm for 
verbs, consisting of the five cells given (with one 
choice of naming convention) as the first column 
of Table 1. 
Lexemes that belong to the same paradigm may 
still differ in their morphophonemic realizations of 
various cells in that paradigm?each paradigm 
may have several associated inflection classes 
which specify, for the lexemes belonging to that 
inflection class, the surface instantiation for each 
cell of the paradigm.   
Three of the inflection classes within the English 
verb paradigm are found in Table 1 under the col-
umns labeled A through C.  Each inflection class 
Inflection Classes Verb 
Paradigm A B C 
Basic 
blame 
roam 
solve 
show 
sow 
saw 
sing 
ring 
3rd Person 
Singular     
Non-past 
-/z/ 
blames 
roams 
solves 
-/z/ 
shows 
sows 
saws 
-/z/ 
sings 
rings 
 
Past 
-/d/ 
blamed 
roamed 
solved 
-/d/ 
showed 
sowed 
sawed 
V? /eI/ 
sang 
rang 
 
Perfective       
or Passive 
-/d/ 
blamed 
roamed 
solved 
-/n/ 
shown 
sown 
sawn 
V? /?/ 
sung 
rung 
 
Progressive 
-/i?/ 
blaming 
roaming 
solving 
-/i?/ 
showing 
sowing 
sawing 
-/i?/ 
singing 
ringing 
 
 
Table 1: A few inflection classes of the Eng-
lish verb paradigm 
column consists of entries corresponding to the 
cells of the verb paradigm.  Each entry contains an 
informal notation for the morphophonemic process 
which the inflection class applies to the basic form 
of a lexeme and examples of word forms filling the 
corresponding paradigm cell. 
Inflection class A is one of the largest and most 
productive verb inflection classes in English, in-
flection class B contains the Perfective/Passive 
suffix -/n/, and C is a small ?irregular? inflection 
class of strong verbs. 
The task our morphology induction system en-
gages is exactly the discovery of the inflection 
classes of a natural language.  Unlike the analysis 
in Table 1, however, the rest of this paper treats 
word forms as simply strings of characters as op-
posed to strings of phonemes. 
4 Empirical Inflection Classes 
There are two stages in our approach to unsu-
pervised morphology induction.  First, we define a 
search space over a set of candidate inflection 
classes, and second, we search this space for those 
candidates most likely to be part of a true inflec-
tion class in the language.  In both stages of our 
approach we intentionally exploit the fact that suf-
fixes belonging to the same natural language in-
flection class frequently occur interchangeably on 
the same stems. 
4.1 Candidate Inflection Class Search Space 
To define a search space wherein we hope to 
identify inflection classes of a natural language, 
our algorithm accepts as input a monolingual cor-
pus for that language and proposes candidate mor-
pheme boundaries at every character boundary in 
every word form in the corpus vocabulary.  We 
call each string before a candidate morpheme 
boundary a candidate stem or c-stem, and each 
string after a boundary a c-suffix.  We define a 
candidate inflection class (CIC) to be a set of c-
suffixes for which there exists at least one c-stem, 
t, such that each c-suffix in the CIC concatenated 
to t produces a word form in the vocabulary.  For 
convenience, let the set of c-stems which generate 
a CIC, C, be called the adherent c-stems of C; let 
the number of adherent c-stems of C be C?s adher-
ent size; and let the size of the set of c-suffixes in 
C be the level of C.  We denote a CIC in this paper 
by a period delimited sequence of c-suffixes. 
While CIC?s effectively model suffix substitu-
tion on bound stems, we would also like to model 
suffix concatenation onto free stems.  To this end, 
the set of candidate morpheme boundaries our al-
gorithm proposes include those boundaries after 
the final character in each word form.  In this paper 
we assume a suffix, which we denote as ?, follows 
all word form final boundaries.  A CIC contains 
the ? c-suffix when each c-stem in the CIC can 
occur, not only bound to other c-suffixes in the 
CIC, but also as a free stem.  For generality, the 
boundary before the first character of each word 
form is also a candidate morpheme boundary. 
 Table 2 illustrates the type of CIC?s produced 
by our algorithm.  The CIC?s in this table, arranged 
in a systematic but arbitrary order, are each derived 
Vocabulary: blame
blames roams
blamed roamed
roaming
?.s.d
blame
?.s
blame.solve
?.d
blame
s.d s.ed.ing e.es.ing
blame roam solv
s.ed e.ing
roam solv
s s.ing es.ing
blame.roam.solve roam solv
d ed.ing ng
blame.roame roam roami.solvi
ing g
roam.solv roamin.solvin
lame
b
solves
solve
ame.ames.amed
bl
me.mes.med e.es.ed
solving
oams.oamed.oaming
bla blam r
me.mes e.es olve.olves.olvingame.ames
ame.amed
bla blam.solv sbl
me.med e.ed
...bla blam
bl
mes.med es.ed
bla blam
me e
bla blam.solv
amed
bl.ro
mes es
bla blam.solvbl
ames
med ed
bla.roa blam.roam
?
blame.blames.blamed.roams.roamed.roaming.solve.solves.solving
lame.lames.lamed
b
lame.lames
b
lame.lamed
b
lames.lamed
b
lames
b
lamed
b
bl
ames.amed
bl
ame
Table 2: Some of the CIC's, arranged in a systematic but arbitrary order, derived from a toy vo-
cabulary. Each entry is specified as a period delimited sequence of c-suffixes in bold above a   
period delimited sequence of adherent c-stems in italics 
from one or more forms in a small vocabulary con-
sisting of a subset of the word forms found under 
inflection class A from Table 1.  Proposing, as our 
procedure does, morpheme boundaries at every 
character boundary in every word form necessarily 
produces many ridiculous CIC?s, such as 
ame.ames.amed, from the forms blame, blames, 
and blamed and the c-stem bl.  Dispersed among 
the incorrect CIC?s generated by our algorithm, 
however, are also CIC?s that seem very reasonable, 
such as ?.s, from the c-stems blame and tease.   
Note that where Table 1 lists all the surface 
forms of the three lexemes BLAME, ROAM, and 
SOLVE, the vocabulary of Table 2 mimics the vo-
cabulary of a text corpus from a highly inflected 
language where we expect few, if any, lexemes to 
occur in the complete set of possible surface forms.  
Specifically, the vocabulary of Table 2 lacks the 
surface form blaming of the lexeme BLAME, solved 
of the lexeme SOLVE, and the root form roam of 
the lexeme ROAM.  Hence, while the reasonable 
CIC ?.s arises from the pairs of surface forms 
(blame, blames) and (solve, solves), there is no 
way for the form roams to contribute to the ?.s 
CIC because the surface form roam is missing 
from this vocabulary.  In other words, we lack evi-
dence for a ? suffix on the c-stem roam.  Also no-
tice that, as a result of English spelling rules, the 
CIC s.ed generated from the pair of surface forms 
(roams, roamed) is separate from each of the 
CIC?s s.d and es.ed generated from the pair of sur-
face forms (blames, blamed).   
Looking at Table 2, it is clear there is structure 
among the CIC?s.  In particular, at least two types 
of relations hold between CIC?s.  First, hierarchi-
cally, the c-suffixes of one CIC may be a superset 
of the c-suffixes of another CIC.  For example the 
c-suffixes in the CIC e.es.ed are a superset of the 
c-suffixes in the CIC e.ed.  Second, cutting across 
this hierarchical structure there is structure be-
tween CIC?s which propose different morpheme 
boundaries within the same word forms.  Compare 
the CIC?s me.mes.med and e.es.ed; each is de-
rived from exactly the triple of word forms blame, 
blames, and blamed, but differ in the placement of 
the hypothesized morpheme boundary.   
Taken together the hierarchical c-suffix set in-
clusion relations and the morpheme boundary rela-
tions impose a lattice structure on the space of 
CIC?s.  Figure 1 diagrams the CIC lattice over an 
interesting subset of the columns of Table 2.  Hier-
archical links, represented by solid lines, connect 
any given CIC often to more than one parent and 
more than one child.  The empty CIC (not pictured 
in Figure 1) can be considered the child of all level 
one CIC?s (including the ? CIC), but there is no 
universal parent of all top level CIC?s.  Moving up 
the lattice always results in a monotonic decrease 
in adherent size because a parent CIC requires 
each adherent c-stem to form a word with a super-
set of the c-suffixes of each child. 
Horizontal morpheme boundary links, dashed 
lines, connect a CIC, C, with a neighbor to the 
right if each c-suffix in C begins with the same 
character.  This entails that there is at most one 
morpheme boundary link leading to the right of 
each CIC.  There may, however, be as many links 
leading to the left as there are characters in the or-
thography.  The only CIC with depicted multiple 
left links in Figure 1 is ?, which has left links to 
the CIC?s e, s, and d.  A number of left links ema-
nating from the CIC?s in Figure 1 are not shown; 
among others absent from the figure is the left link 
from the CIC e.es leading to the CIC ve.ves with 
the adherent sol.  Since left links effectively divide 
a CIC into separate CIC?s, one for each character 
in the orthography, adherent count monotonically 
decreases as left links are followed. 
To better visualize what a CIC lattice looks like 
when derived from real data, Figure 2 contains a 
portion of a hierarchical lattice automatically gen-
erated from our Spanish newswire corpus.  Each 
entry in Figure 2 contains the c-suffixes compris-
ing the CIC, the adherent size of the CIC, and a 
sample of adherent c-stems.  The lattice in Figure 2 
covers: 
e.es 
blam 
solv 
e.ed 
blam 
es 
blam 
solv 
?.s.d 
blame 
?.s 
blame 
solve 
? 
blame 
blames 
blamed 
roams 
roamed 
roaming 
solve 
solves 
solving 
e.es.ed 
blam 
ed 
blam 
roam 
d 
blame 
roame 
?.d 
blame 
s.d 
blame 
s 
blame 
roam 
solve 
es.ed 
blam 
e 
blam 
solv 
me.mes 
bla 
me.med 
bla 
mes 
bla 
me.mes.med 
bla 
med 
bla 
roa 
mes.med 
bla 
me 
bla 
Figure 1: Portion of a CIC lattice from the 
toy vocabulary in Table 2 
c-suffix set inclusion links 
morpheme boundary links 
1) The productive Spanish inflection class for 
adjectives, a.as.o.os, covering the four adjec-
tive paradigm cells: feminine singular, femi-
nine plural, masculine singular, and mascu-
line plural, respectively, 
2) All possible CIC subsets of the adjective 
CIC, e.g. a.as.o, a.os, etc. and, 
3) The imposter CIC a.as.o.os.tro, together 
with its rogue descendents, a.tro, and tro.   
Other CIC?s that are descendents of a.as.o.os.tro 
and that contain the c-suffix tro do not supply ad-
ditional adherents and hence are not present either 
in Figure 2 or in our program?s representation of 
the CIC lattice.  The CIC?s a.as.tro and os.tro, for 
example, both have only the one adherent, cas, 
already possessed by their common ancestor 
a.as.o.os.tro.  Strictly speaking we have simplified 
for exposition, as the CIC a.as.o.os.tro is not actu-
ally present in the algorithm?s representation ei-
ther, because the c-stem cas occurred with a num-
ber of additional c-suffixes yielding the CIC: 
a.as.i.o.os.sandra.tanier.ter.tro.trol.  
4.2 Search 
Given the framework of CIC lattices, the key 
task for automatic morphology induction is to 
autonomously separate the nonsense CIC?s from 
the useful ones, thus identifying linguistically 
plausible inflection classes.  This section treats the 
CIC lattices as a hypothesis space of valid inflec-
tion classes and searches this space for CIC?s most 
likely to be true inflection classes in a language. 
There are many possible search strategies and 
heuristics applicable to the CIC lattice, and while 
for future work we intend to explore a variety of 
search techniques, this paper presents a reasonable 
and intuitive baseline search procedure.  We have 
investigated a series of algorithms which build 
upon each other.  Each algorithm employs a num-
ber of parameters which are tuned by hand.  These 
parameters are only interesting in so far as they 
help us find true CIC?s from among the many in 
the lattice.  The performance of each algorithm is 
described in section 6. 
4.2.1 Vertical Only 
 To motivate the general approach we have 
taken, compare the adherent sizes of the various 
CIC?s in Figure 2.  The target CIC a.as.o.os, corre-
sponding to the Spanish adjective inflection class, 
has 43 adherents.  Its various descendents must 
occur with monotonically increasing adherent 
sizes, but frequently a child will not more than 
double or triple its immediate parent?s adherent 
size, and never is there a difference greater than a 
factor of ten. Notice also the large adherent counts 
of the level one descendents of a.as.o.os, the 
smallest is as with 404 adherents.   
Contrast this behavior with that of CIC?s involv-
ing the spurious suffix tro.  The CIC a.as.o.os.tro 
occurs in the corpus with exactly one adherent, 
cas.  Additionally, the word forms cena, supper, 
and centro, center, occur yielding the CIC a.tro 
with two adherents.  In total tro is the final string 
of only 16 individual word forms. 
In general, we expect that true suffixes in a lan-
guage will both occur frequently and occur at-
tached to a large number of stems which also ac-
cept other suffixes from the same inflection class.  
These considerations led us to propose three pa-
rameters for our basic search strategy: 
L1 SIZE:  A level one adherent size cutoff 
TOP SIZE:  An absolute adherent size cutoff 
RATIO:  A parent-to-child adherent size      
ratio cutoff 
The L1 SIZE parameter requires a c-suffix to be 
frequent, while the TOP SIZE and RATIO parame-
ters require a suffix to be substitutable for other c-
suffixes in a reasonable number of c-stems. 
a.as.o.os 
43 
african 
cas 
jur?dic 
l 
... 
a.as.o.os.tro 
1 
cas 
a.as.os 
50 
afectad 
cas 
jur?dic 
l 
... 
a.as.o 
59 
cas 
citad 
jur?dic 
l 
... 
a.o.os 
105 
impuest 
indonesi 
italian 
jur?dic 
... 
a.as 
199 
huelg 
incluid 
industri 
inundad 
... 
a.os 
134 
impedid 
impuest 
indonesi 
inundad 
... 
as.os 
68 
cas 
implicad 
inundad 
jur?dic 
... 
a.o 
214 
id 
indi 
indonesi 
inmediat 
... 
as.o 
85 
intern 
jur?dic 
just 
l 
... 
a.tro 
2 
cas 
cen 
a 
1237 
huelg 
ib 
id 
iglesi 
... 
as 
404 
huelg 
huelguist 
incluid 
industri 
... 
os 
534 
humor?stic 
human 
h?gad 
impedid 
... 
o 
1139 
hub 
hug 
human 
huyend 
... 
tro 
16 
catas 
ce 
cen 
cua 
... 
as.o.os 
54 
cas 
implicad 
jur?dic 
l 
... 
 
Figure 2: Hierarchical CIC lattice automati-
cally derived from Spanish 
o.os 
268 
human 
implicad 
indici 
indocumentad 
... 
We apply these three parameters by beginning 
our search at the bottom of the lattice.  Each level 
one CIC with an adherent count larger than L1 
SIZE is placed in a list of path CIC?s.  Then for 
each path CIC, C, we remove C from the list of 
path CIC?s, and in turn consider each of C?s hier-
archical parents, Pi.  If Pi?s adherent size is at least 
TOP SIZE, and if the ratio of Pi?s adherent size to 
C?s adherent size is larger than RATIO, then Pi is 
placed in the list of path CIC?s.  If no parent of C 
can be placed in the list of path CIC?s, and if C?s 
level is greater than one, then C is placed in a list 
of selected CIC?s.  When there are no more CIC?s 
in the list of path CIC?s, the search ends and the 
CIC?s in the selected list are the CIC?s the algo-
rithm believes are true CIC?s of the language. 
As an illustration suppose we explored the lattice 
in Figure 2 with the following parameter settings: 
L1 SIZE:  100 
TOP SIZE:  2 
RATIO:  0.1 
Our search algorithm begins by comparing the 
adherent size of each level one CIC to L1 SIZE.  
The only level one CIC with an adherent count less 
than 100 is tro with 16 adherents, preventing tro 
from being placed in the list of path CIC?s.   
Each of the surviving level one CIC?s is then 
considered in turn.  The algorithm comes to the 
CIC a, where the ratios of adherent sizes between 
each of its parents a.tro, a.as, a.o, and a.os and 
itself are 0.002, 0.161, 0.173, and 0.108 respec-
tively.  Each of these ratios, except that between a 
and a.tro, at 0.002, is larger than 0.1.  And since 
the adherent sizes of a.as, a.o, and a.os are each 
larger than TOP SIZE, these three CIC?s are placed 
in the list of path CIC?s.   
From this point, every hierarchical link in Figure 
2 leading to the CIC a.as.o.os passes the TOP SIZE 
and RATIO cutoffs.  Thus the algorithm reaches a 
state where the only CIC in the list of path CIC?s is 
a.as.o.os.  When this good CIC is removed from 
the list of path CIC?s, the algorithm finds that its 
only parent is a.as.o.os.tro with its lone adherent.  
Since TOP SIZE requires a parent to have at least 
two adherents, a.as.o.os.tro cannot be placed in 
the list of path CIC?s.  As no parent can be placed 
in the list of path CIC?s, a.as.o.os is placed in the 
list of selected CIC?s?which is the desired out-
come.  The list of path CIC?s is now empty and the 
search ends. 
4.2.2 Horizontal Blocking 
 To improve performance over the Vertical Only 
algorithm we next incorporated knowledge from 
the horizontal morpheme boundary links.  Monson 
(2004) describes how morpheme boundary links in 
a CIC lattice can be thought of as branchings in a 
vocabulary trie where identical subtries are con-
flated.  Harris (1955) discusses how the branching 
count in a suffix trie can be exploited to identify 
morpheme boundaries.  We extend the spirit of 
Harris? work in our algorithm through the use of 
two search parameters: 
HORIZ RATIO: A cutoff over: 
sizeadherent 
character in  ending adherents of #
argmax cc  
HORIZ SIZE: An adherent size cutoff 
Left Blocking 
In the first variant of horizontal blocking we ap-
ply these two horizontal parameters when consid-
ering a CIC, C, removed from the list of path 
CIC?s.  If the adherent size of C is larger than 
HORIZ SIZE and the maximum percentage of ad-
herents of C that end in any one character is larger 
than HORIZ RATIO, then C is simply thrown out. 
For example, suppose we used the following 
horizontal parameter settings: 
HORIZ RATIO:  0.5 
HORIZ SIZE:  10 
 The CIC da.do in our Spanish corpus has 62 
adherents, 46, or a fraction of 0.742, of which end 
in the character a (ada and ado fill the feminine 
and masculine past participle cells for the -ar verb 
inflection class).  If our Left Blocking search algo-
rithm reached the CIC da.do, it would be dis-
carded because while its adherent size is larger 
than HORIZ SIZE more than half of its adherents 
end with the same character.  Notice that this algo-
rithm does not explicitly follow leftward mor-
pheme boundary links.  The rationale for this be-
havior is that ada.ado will likely be explored inde-
pendently by a separate vertical path.  In future 
experiments we intend to investigate the effect of 
ensuring that the CIC to the left is explored by 
overtly placing the leftward CIC in the list of path 
CIC?s. 
Right Blocking 
 So far we have only described an algorithm to 
block paths where the correct morpheme boundary 
is to the left of the current hypothesis.  There are 
also CIC?s where a morpheme boundary should be 
moved to the right. The CIC cada.cado with seven 
adherents is one such. 
Accordingly, whenever we encounter a CIC, C, 
all of whose c-suffixes begin with the same charac-
ter (e.g. c in cada.cado) our algorithm poses the 
question, if we were considering the CIC to the 
right (e.g. ada.ado) would we have triggered Left 
Blocking?  If Left Blocking would not have been 
triggered then we throw C out.  In other words, we 
prefer the rightmost possible morpheme boundary, 
unless there is some reason to believe the mor-
pheme boundary should be to the left. 
Taking a closer look at cada.cado, the CIC to its 
right, ada.ado, has 46 adherents of which the char-
acter c ends the most, 7 or a fraction of 0.152.  If 
we were using a HORIZ RATIO of 0.5 as in the pre-
vious section, Left Blocking would not be trig-
gered from ada.ado and so Right Blocking is trig-
gered, throwing out cada.cado.  On the other hand, 
if we were considering blocking ada.ado, where 
both c-suffixes begin with a, the HORIZ RATIO pa-
rameter would need to be larger than 0.742 before 
right blocking would throw out ada.ado.   
Right Blocking Recursive 
 In addition to standard Right Blocking we ex-
plored recursively looking at the next most right 
neighbor of a CIC if the immediate right neighbor 
falls below the HORIZ SIZE threshold.  The ration-
ale behind this variant stems from CIC?s such as 
icada.icado with 4 adherents, crit, publ, ratif, and 
ub.  Since icada.icado?s immediate right neighbor 
cada.cado has only 7 adherents itself we may not 
want to base our blocking decision on so little data.  
Instead we consider the CIC ada.ado, discussed in 
the previous section, which has a large enough ad-
herent size that we might feel confident in our 
judgment.   
Full Horizontal Blocking 
The final version of the search we tried was to 
combine Left Blocking and Right Blocking Recur-
sive while constraining both to use the same values 
for the HORIZ RATIO and HORIZ SIZE parameters. 
5 Evaluation 
To evaluate the performance of the various base-
line search strategies, we first decided on a stan-
dard set of six inflection classes for Spanish: two 
for nouns, ?.s and ?.es, one for adjectives, 
a.as.o.os, and three for verbs, corresponding to the 
traditional -ar, -er, and -ir verb inflection classes.  
We call these six inflection classes our set of stan-
dard IC?s.  We make no claim as to the truth or 
completeness of the set of standard inflection 
classes we used in this evaluation.  The standard 
IC?s we compiled were simply some of the most 
common suffixes filling some of the most common 
morphosyntactic properties marked in Spanish. 
We then defined measures of recall, precision, 
and fragmentation over these standard IC?s (Figure 
3).  As defined, recall measures the fraction of 
unique suffixes in the standard IC?s that are found 
within those selected CIC?s that are subsets of 
some inflection class in the standard; precision 
measures the fraction of unique suffixes among all 
the selected CIC?s that are found within those se-
lected CIC?s that are subsets of an inflection class 
in the standard; and fragmentation measures re-
dundancy, specifically calculating the ratio of the 
number of selected CIC?s that are subsets of stan-
dard IC?s to the number of inflection classes in the 
standard.  High values for recall and precision are 
desirable, while a fragmentation of exactly 1 im-
plies that the number of usefully selected CIC?s is 
the same as the number of inflection classes in the 
standard. 
6 Results and Error Analysis 
For each of the search variants described in sec-
tion 4.2 we executed a by-hand search over the 
relevant parameters for those settings that optimize 
the F1 measure (the harmonic mean of recall and 
precision).  The best performing parameter settings 
are presented in Table 3 while quantitative results 
using these settings are plotted in Figure 4.   
Examining the performance of each algorithm 
(Figure 4) reveals that the simple Vertical only 
search achieves a high precision at the expense of a 
low recall measure.  The simple Vertical search 
also gives the smallest fragmentation, which, when 
combined with the high precision score, indicates a 
conservative algorithm that selects few CIC?s.  The 
parameter settings which achieve the highest F1 for 
Left Block alone and Right Block alone each pro-
duce much higher recall than the simple Vertical 
search.  Right Block Recursive increases precision 
significantly over simple Right Block and achieves 
U
U
sIC' standard 
sIC' standard 
sCIC' selected 
 of elements
 if  of elements
Recall
?
?
?
?
=
I
I
C
I
ICC
U
U
sCIC' selected 
sIC' standard 
sCIC' selected 
 of elements
 if  of elements
Precision
?
?
?
?
=
C
I
C
C
ICC
 
 {
sIC' standard
ionFragmentat sIC' standard 
sCIC' selected 
 if 1 
 if 0 ?
?
?
?
?
=
I
C
IC
IC
 
Figure 3: Three performance measures to   
optimize 
the highest F1 measure of any search variant.  
While Full Horizontal Block also performs well, 
sharing the values of HORIZ RATIO and HORIZ 
SIZE forced a compromise between Left Block and 
Right Block Recursive that did not significantly 
outperform either algorithm alone. 
Of the 83 unique suffixes in the hand compiled 
standard inflection classes, 21 did not share a c-
stem with any other c-suffix in the Spanish news-
wire corpus used for this evaluation?placing an 
upper limit on recall of 0.75 for the search algo-
rithms presented in this paper. 
Examining the parameter settings that yielded 
the highest F1 measure for each search variant 
(Table 3) is also enlightening.  Early experiments 
with Vertical only search clearly demonstrated that 
a TOP SIZE of two, or restricting the CIC?s permit-
ted to be selected to those with at least two adher-
ents, always resulted in better performance than 
other possible settings.  A TOP SIZE of one places 
no restriction on the adherent size of a CIC, ram-
pantly selecting CIC?s, such as the level 10 CIC 
given at the end of section 4.1, that consist of 
many c-suffixes that happen to validly concatenate 
onto a single c-stem?obliterating reasonable pre-
cision.  Higher settings for TOP SIZE induce a 
graceful degradation in recall.  Thus all experi-
ments reported here used a TOP SIZE of two. 
Beyond TOP SIZE the only parameters available 
to the basic Vertical algorithm are L1 SIZE and 
RATIO, which provide only crude means to halt the 
search of bad paths.  In particular, if a level one 
CIC, C, has more than L1 SIZE adherents, and has 
some parent which passes the RATIO cutoff, then 
some ancestor of C will be selected by the algo-
rithm as a good CIC.  Hence, the Vertical only al-
gorithm ensures search gets off on the right foot by 
using the highest values for the L1 SIZE and RATIO 
parameters of any algorithm variant.  Performance 
falls off quickly above L1 SIZE settings of 192, 
indicating that this parameter in this algorithm is 
sensitive to the size of the training corpus. 
In contrast, the horizontal blocking search algo-
rithms have additional parameters available to cull 
out bad search paths, and can hence afford to use 
lower (and more stable) values for L1 SIZE and 
RATIO.  Recall that the Left Blocking algorithm 
discards paths determined to be using a morpheme 
boundary too far to the right, while the Right 
Blocking algorithm discards paths using mor-
pheme boundaries too far to the left.  Notice that 
since, as reasoned in section 4.1, adherent count 
monotonically decreases as morpheme boundary 
links are followed to the left, if the L1 SIZE cutoff 
blocks a particular CIC, C, all CIC?s to the left of 
C will also be blocked.  From these facts it follows 
that a large L1 SIZE will reject some paths result-
ing from morpheme boundaries chosen too far to 
the left, which would otherwise have been pursued 
in the Left Blocking algorithm.  The Right Block-
ing algorithm, however, receives no such benefit, 
and achieves its best performance by maximizing 
recall with a small L1 SIZE. 
Examining the best performing parameter values 
for the Right Blocking Recursive algorithm reveals 
a curious behavior in which low values for L1 SIZE 
and RATIO allow a permissive vertical search while 
stringent values of HORIZ RATIO and, particularly, 
HORIZ SIZE constrain the search.  One explanation 
for these facts might be that following the mono-
tonically increasing chain of CIC adherent sizes 
along right horizontal links allows the algorithm to 
Figure 4: Recall, Precision, F1 and Fragmen-
tation Results for each search algorithm:     
Vertical, Left Blocking, Right Blocking,   
Right Blocking Recursive, and                     
Full Horizontal Blocking 
0.
0
0.
1
0.
2
0.
3
0.
4
0.
5
0.
6
0.
7
0.
8
0.
9
1.
0
V
LB
RB
RBR
FHB
A
lg
o
ri
th
m
Recall/Precision/F-Measure
0 3 6 9 12 15 18 21 24 27 30
Fragmentation
Recall Precision
F-Measure Fragmentation
Table 3: Hand tuned optimal parameter set-
tings for each search algorithm:                       
Vertical, Left Blocking, Right Blocking,       
Right Blocking Recursive, and                      
Full Horizontal Blocking 
Algorithm TOP SIZE 
L1 
SIZE RATIO 
HORIZ 
RATIO 
HORIZ 
SIZE 
V 2 192 0.3   
LB 2 64 0.1 0.3 3 
RB 2 27 0.2 0.5 27 
RBR 2 27 0.05 0.5 243 
FHB 2 27 0.2 0.3 3 
 
make intelligent blocking decisions backed by suf-
ficient data. 
The best performing parameter values for the 
Full Horizontal Search are a compromise between 
the well performing values for the Left Blocking 
and those for the Right Blocking algorithms.  This 
parameter value compromise does not draw benefit 
from the recursion in the Right Block Recursive 
algorithm, but instead employs Right Block as a 
replacement for the relatively higher L1 SIZE pa-
rameter in the Left Blocking algorithm. 
It is also interesting to examine CIC?s selected 
by the search algorithms.  Table 4 lists all of the 
CIC?s selected by the conservative Vertical search 
algorithm together with a random sample of CIC?s 
selected by Right Blocking Recursive, the algo-
rithm which reached the highest F1 measure of any 
algorithm variant.   
Perhaps the most striking feature of Table 4 is 
the extent to which the CIC?s overlap.  Very few 
individual c-suffixes occur in only one CIC.  Of all 
the CIC?s in Table 4, only ?.s and a.as.o.os, both 
among the CIC?s selected by the Vertical algo-
rithm, represent complete inflection classes in the 
standard IC?s.  The remaining CIC?s are proper 
subsets of various verbal inflection classes.  The 
overlapping nature of the selected CIC?s suggests 
an additional step, which we do not investigate 
here, of conflating CIC?s into a fewer number of 
meta-CIC?s. 
The only verbal inflection class for which sub-
sets are able to pass the large L1 SIZE cutoff im-
posed by the Vertical search algorithm is -ar, the 
most frequent of the three major inflection classes 
in Spanish.  The Right Blocking Recursive algo-
rithm on the other hand identifies significant por-
tions of all three verbal inflection classes.  
The c-suffixes appearing in italics in Table 4 
correspond to no suffix found in any standard IC.  
These alien c-suffixes fall into two categories. 
1) The c-suffixes aciones, aci?n, and adores 
are noun forming derivational suffixes.   
2) The remaining c-suffixes were formed by 
choosing a morpheme boundary too far to 
the right.   
It is the second type of mistake that the Left 
Blocking search algorithm was specifically de-
signed to address.  Unfortunately na?vely combin-
ing the Right Blocking Recursive with the Left 
Blocking algorithm did not improve performance.  
We expect that by using separate horizontal pa-
Vertical
ar er ir 23 of 23 Selected CIC's
? ?.s
? a.aba.ada.adas.ado.ar.as
? a.aba.ada.ado.ando.ar
? a.aba.ada.ado.ar.ar?.en.?
a.aciones.aci?n .ada.adas.ar.aron
? a.ada.adas.ado.ar.ar?
? a.ada.adas.ar.aron.?
? a.ada.ado.ar.aron.ar?.?
? a.ada.ado.ar.ar?.ar?n.en.?
? a.ada.ado.ar.o.?
? a.ada.ados.ar.aron.?
? a.ado.ar.ara.aron.e.?
? a.ado.ar.aron.?
? a.an.ar.?
? a.as.o.os
? ? ? ? a.as
? aba.ado.ando.ar.aron.ar?
? aba.ado.ar.aron.ar?.en
? ada.ado.ados.ar.aron.?
? ada.ado.ando.ar.aron.?
? ada.ado.ar.ar?.o.?
? ada.ado.ar.en.o.?
? ado.ar.aron.ar?.ar?n.en
N A
dj Verbs
 
Table 4: All of the CIC?s selected by the conservative Vertical search algorithm (left), and a random 
sample of CIC?s selected by the algorithm with best F1 measure, Right Blocking Recursive (right).  For 
each CIC row, a dot is placed in the columns representing standard IC?s for which that CIC is a subset.  
The c-suffixes in italics are in no standard IC. 
Right Blocking Recursive
ar er ir 23 of 204 Selected CIC's
?.ba.n.ndo
? a.aba.ado.ados.ar.ar?.ar?n
a.aciones.aci?n .adas.ado.ar
? a.ada.adas.ado.ar.ar?
? a.adas.ado.an.ar
? a.ado.ados.ar.?
? a.ado.an.arse.?
? a.ado.aron.arse.?
? aba.ada.ado.ar.o.os
aciones.aci?n .ado.ados
aciones .ado.ados.ar?
aci?n .ado.an.e
? ada.adas.ado.ados.aron.?
? ada.ado.ados.ar.o
ado.adores .o
? ado.ados.arse.e
? ado.ar.aron.arse.ar?
do.dos.ndo.r.ron
? ? e.ida.ido
? emos.ido.?a.?an
? ida.ido.idos.ir.i?
? ido.iendo.ir
? ido.ir.ro
N A
dj Verbs
 
rameters for left blocking and for right blocking 
we could combine these two algorithms in a less 
constrained fashion that would result in better 
overall performance. 
7 Future Work  
We believe the heuristic search strategy de-
scribed in this paper can be significantly improved 
upon.  We plan to investigate search strategies for 
both the vertical and horizontal links in our CIC 
lattices.  We currently have plans to employ statis-
tical independence and correlation tests to adjacent 
CIC?s as a guide to search (Monson, 2004).  Other 
search criteria we are considering are information 
gain and minimum description length measures. 
There are also modifications to the search strat-
egy that may significantly improve performance.  
For example, it may be advantageous to actively 
follow horizontal morpheme boundary links, in-
stead of merely blocking paths, when a morpheme 
boundary error is discovered.  The next immediate 
step we will take is to scale our implementation to 
investigate performance changes as we increase 
the size of our Spanish corpus. 
The intention of this work is to produce a lan-
guage independent morphology induction algo-
rithm.  Hence, we plan to apply this work to a vari-
ety of languages, both well studied resource-rich 
languages as well as low-density languages of in-
terest to the AVENUE project. 
8 Acknowledgements 
The research reported in this paper was funded 
in part by NSF grant number IIS-0121631. 
References 
Jaime Carbonell, Katharina Probst, Erik Peterson, 
Christian Monson, Alon Lavie, Ralf Brown, and 
Lori Levin.  2002. Automatic Rule Learning for 
Resource-Limited MT. In Proceedings of the 5th 
Conference of the Association for Machine 
Translation in the Americas (AMTA-02). 
Andrew Carstairs-McCarthy. 1998. ?Paradigmatic 
Structure: Inflectional Paradigms and Morpho-
logical Classes.? The Handbook of Morphology. 
Eds. Andrew Spencer and Arnold M. Zwicky. 
Blackwell Publishers Inc., Massachusetts, USA, 
322-334. 
?ric Gaussier. 1999. Unsupervised learning of 
derivational morphology from inflectional lexi-
cons. In Proceedings of ACL ?99 Workshop: Un-
supervised Learning in Natural Language Proc-
essing. 
John Goldsmith. 2001. Unsupervised learning of 
the morphology of a natural language. Computa-
tional Linguistics, 27(2): 153-198. 
Margaret A. Hafer and Stephen F. Weiss. 1974. 
Word segmentation by letter successor varieties. 
Information Storage and Retrieval, 10:371-385. 
Zellig Harris. 1955. From phoneme to morpheme. 
Language, 31:190-222. Reprinted in Harris 
1970. 
Zellig Harris. 1967. Morpheme boundaries within 
words: Report on a computer test. Transforma-
tion and Discourse Analysis Papers 73, Depart-
ment of Linguistics, University of Pennsylvania. 
Reprinted in Harris 1970. 
Zellig Harris. 1970. Papers in Structural and 
Transformational Linguistics. D. Reidel, 
Dordrecht, Holland. 
Alon Lavie, Stephan Vogel, Lori Levin, Erik Pe-
terson, Katharina Probst, Ariadna Font Llitj?s, 
Rachel Reynolds, Jaime Carbonell, and Richard 
Cohen. 2003. Experiments with a Hindi-to-
English Transfer-based MT System under a Mis-
erly Data Scenario. ACM Transactions on Asian 
Language Information Processing (TALIP), to 
appear in 2(2). 
Christian Monson. 2004. A Framework for Unsu-
pervised Natural Language Morphology Induc-
tion.  In Proceedings of the Student Workshop at 
ACL-04. 
Katharina Probst, Lori Levin, Erik Peterson, Alon 
Lavie, and Jaime Carbonell. 2002. MT for Re-
source-Poor Languages using Elicitation-based 
Learning of Syntactic Transfer Rules. Machine 
Translation, Special Issue on Embedded MT, 
17(4): 245-270. 
Patrick Schone and Daniel Jurafsky. 2000. Knowl-
edge-free Induction of Morphology Using Latent 
Semantic Analysis. In Proceedings of the Fourth 
Conference on Computational Natural Language 
Learning and of the Second Learning Language 
in Logic Workshop, 67-72. 
Patrick Schone and Daniel Jurafsky. 2001. Knowl-
edge-free Induction of Inflectional Morpholo-
gies. In Proceedings of the North American 
Chapter of the Association of Computational 
Linguistics. 183-191. 
David Yarowsky, Grace Ngai, and Richard Wicen-
towski. 2001. Inducing multilingual text analysis 
tools via robust projection across aligned cor-
pora. In Proceedings of the Human Language 
Technology Conference, 161-168. 
 
Proceedings of Ninth Meeting of the ACL Special Interest Group in Computational Morphology and Phonology, pages 117?125,
Prague, June 2007. c?2007 Association for Computational Linguistics
ParaMor: Minimally Supervised Induction of Paradigm  
 Structure and Morphological Analysis 
 
Christian Monson, Jaime Carbonell, Alon Lavie, Lori Levin 
Language Technologies Institute 
Carnegie Mellon University 
5000 Forbes Ave. 
Pittsburgh, PA, USA 15213 
{cmonson, alavie+, jgc+, lsl+}@cs.cmu.edu 
Abstract 
Paradigms provide an inherent 
organizational structure to natural language 
morphology. ParaMor, our minimally 
supervised morphology induction 
algorithm, retrusses the word forms of raw 
text corpora back onto their paradigmatic 
skeletons; performing on par with state-of-
the-art minimally supervised morphology 
induction algorithms at morphological 
analysis of English and German. ParaMor 
consists of two phases. Our algorithm first 
constructs sets of affixes closely mimicking 
the paradigms of a language. And with 
these structures in hand, ParaMor then 
annotates word forms with morpheme 
boundaries. To set ParaMor?s few free 
parameters we analyze a training corpus of 
Spanish. Without adjusting parameters, we 
induce the morphological structure of 
English and German. Adopting the 
evaluation methodology of Morpho 
Challenge 2007 (Kurimo et al, 2007), we 
compare ParaMor?s morphological 
analyses with Morfessor (Creutz, 2006), a 
modern minimally supervised morphology 
induction system. ParaMor consistently 
achieves competitive F1 measures. 
1 Introduction 
Words in natural language (NL) have internal 
structure. Morphological processes derive new lex-
emes from old ones or inflect the surface form of 
lexemes to mark morphosyntactic features such as 
tense, number, person, etc. This paper address 
minimally supervised induction of productive natu-
ral language morphology from text. Minimally su-
pervised induction of morphology interests us both 
for practical and theoretical reasons. In linguistic 
theory, the morpheme is often defined as the 
smallest unit of language which conveys meaning. 
And yet, without annotating for meaning, recent 
work on minimally supervised morphology induc-
tion from written corpora has met with some suc-
cess (Creutz, 2006). We are curious how far this 
program can be pushed. From a practical perspec-
tive, minimally supervised morphology induction 
would help create morphological analysis systems 
for languages outside the traditional scope of NLP. 
However, to develop our method we induce the 
morphological structure of three well-understood 
languages, English, German, and Spanish. 
1.1 Inherent Structure in NL Morphology 
The approach we have taken to induce morpho-
logical structure has explicit roots in linguistic the-
ory. Cross-linguistically, natural language organ-
izes inflectional morphology into paradigms and 
inflection classes. A paradigm is a set of mutually 
exclusive operations that can be performed on a 
word form. Each mutually exclusive morphologi-
cal operation in a paradigm marks a lexeme for 
some set or cell of morphosyntactic features. An 
inflection class, meanwhile, specifies the proce-
dural details that a particular set of adherent lex-
emes follow to realize the surface form filling each 
paradigm cell. Each lexeme in a language adheres 
to a single inflection class for each paradigm the 
lexeme realizes. The lexemes belonging to an in-
flection class may have no relationship binding 
them together beyond an arbitrary morphological 
stipulation that they adhere to the same inflection 
class. But for this paper, an inflection class may 
117
also refer to a set of lexemes that inflect similarly 
for phonological or orthographic reasons. Working 
with text we intentionally blur phonology and or-
thography. 
A simple example will help illustrate paradigms, 
inflection classes, and the mutual exclusivity of 
cells. As shown in Table 1, all English verbs 
belong to a single common paradigm of five cells: 
One cell marks a verb for the morphosyntactic 
feature values present tense 3rd person, as in eats; 
another cell marks past tense, as in ate; a third cell 
holds a surface form typically used to mark 
progressive aspect, eating; a fourth produces a 
passive participle, eaten; and finally there is the 
unmarked cell, in this example eat.  
Aside from inflection classes each containing 
only a few irregular lexemes, such as that 
containing eat, there are no English verbal 
inflection classes that arbitrarily differentiate 
lexemes on purely morphological grounds. There 
are, however, several inflection classes that realize 
surface forms only for verbs with particular 
phonology or orthography. The ?silent-e? inflection 
class is one such. To adhere to the ?silent-e? 
inflection class a lexeme must fill the unmarked 
paradigm cell with a form that ends in an unspoken 
character e, as in dance. The other paradigm cells 
in the ?silent-e? inflection class are filled by 
applying orthographic rules such as:  
Progressive Aspect Cell ? replace the final e of 
the unmarked form with the string ing, 
dance  dancing  
Past Cell ? substitute ed, dance  danced  
Paradigm cells are mutually exclusive. In the Eng-
lish verbal paradigm, although English speakers 
can express progressive past actions with a 
grammatical construction, viz. was eating, there is 
no surface form of the lexeme eat that 
simultaneously fills both the progressive and the 
past cells of the verbal paradigm, *ateing. 
1.2 ParaMor 
Paradigms and inflection classes, the inherent 
structure of natural language morphology, form the 
basis of ParaMor, our minimally supervised 
morphological induction algorithm. In ParaMor?s 
first phase, we find sets of mutually exclusive 
strings which closely mirror the inflection classes 
of a language?although ParaMor does not 
differentiate between syncretic word forms of the 
same lexeme filling different paradigm cells, such 
as ed-suffixed forms which can fill either the past 
or the passive cells of English verbs. In ParaMor?s 
second phase we employ the structured knowledge 
contained within the discovered inflection classes 
to segment word forms into morpheme-like pieces.  
Languages employ a variety of morphological 
processes to arrive at grammatical word forms?
processes including suffix-, prefix-, and infixation, 
reduplication, and template filling. Furthermore, 
the application of word forming processes often 
triggers phonological (or orthographic) change, 
such a as the dropped final e of the ?silent-e? 
inflection class, see Table 1. Despite the wide 
range of morphological processes and their 
complicating concomitant phonology, a large caste 
of inflection classes, and hence paradigms, can be 
represented as mutually exclusive substring 
substitutions. In the ?silent-e? inflection class, for 
example, the word-final strings e.ed.es.ing can be 
substituted for one another to produce the surface 
forms that fill the paradigm cells of lexemes 
belonging to this inflection class. In this paper we 
focus on identifying word final suffix morphology. 
While we focus on suffixes, the methods we 
employ can be straightforwardly generalized to 
prefixes and ongoing work seeks to model 
sequences of concatenative morphemes. 
Inducing the morphology of a language from a 
naturally occurring text corpus is challenging. In 
languages with a rich morphological structure, sur-
face forms filling particular cells of an inflection 
class may be relatively rare. In the Spanish news-
wire text over which we developed ParaMor there 
are 50,000 unique types. Among these types, in-
Table 1: The English verbal paradigm, left col-
umn, and two inflection classes of the verbal 
paradigm. The verb eat fills the cells of its in-
flection class with the five surface forms 
shown in the second column. Verbs belonging 
to the ?silent-e? inflection class inflect follow-
ing the pattern of the third column. 
            Inflection Class Paradigm 
Cells ?eat? ?silent-e? 
Unmarked eat dance, erase, ? 
Present, 3rd eats dances, erases, ? 
Past Tense ate danced, erased, ? 
Progressive eating dancing, erasing, ? 
Passive eaten danced, erased, ? 
 
118
stances of first and second person verb forms are 
few. The suffix imos which fills the first person 
plural indicative present cell for the ir verbal in-
flection class of Spanish occurs on only 77 unique 
lexemes. And yet we aim to identify candidate in-
flection classes which closely model the true in-
flection classes of a language, covering as many 
inflectional paradigm cells as possible. 
Fortunately, we can leverage the paradigm struc-
ture of natural language morphology itself to retain 
many inflections which, because of data sparse-
ness, might be missed if considered in isolation. 
ParaMor begins with a recall-centric search for 
partial candidate inflection classes. Many of the 
candidates which result from this initial search are 
incorrect. But intermingled with the false positives 
are candidates which collectively model significant 
fractions of true inflection classes. Hence, Pa-
raMor?s next step is to cluster the initial partial 
candidate inflection classes into larger groups. This 
clustering effectively uses the larger correct initial 
candidates as nuclei to which smaller correct can-
didates accrete. With as many initial true candi-
dates as possible safely corralled with other candi-
dates covering the same inflection class, ParaMor 
completes the paradigm discovery phase by dis-
carding the large number of erroneous initially se-
lected candidate inflection classes. Finally, with a 
strong grasp on the paradigm structure, ParaMor 
straightforwardly segments the words of a corpus 
into morphemes. 
1.3 Related Work 
In this section we highlight previously proposed 
minimally supervised approaches to the induction 
of morphology that, like ParaMor, draw on the 
unique structure of natural language morphology. 
One facet of NL morphological structure com-
monly leveraged by morphology induction algo-
rithms is that morphemes are recurrent building 
blocks of words. Brent et al (1995), Goldsmith 
(2001), and Creutz (2006) emphasize the building 
block nature of morphemes when they each use 
recurring word segments to efficiently encode a 
corpus. These approaches then hypothesize that 
those recurring segments which most efficiently 
encode a corpus are likely morphemes. Another 
technique that exploits morphemes as repeating 
sub-word segments encodes the lexemes of a cor-
pus as a  character tree, i.e. trie, (Harris, 1955; 
Hafer and Weis, 1974), or as a finite state automa-
ton (FSA) over characters (Johnson, H. and Martin, 
2003; Altun and M. Johnson, 2001). A trie or FSA 
conflates multiple instances of a morpheme into a 
single sequence of states. Because the choice of 
possible succeeding characters is highly con-
strained within a morpheme, branch points in the 
trie or FSA are likely morpheme boundaries. Often 
trie similarities are used as a first step followed by 
further processing to identify morphemes (Schone 
and Jurafsky, 2001).  
The paradigm structure of NL morphology has 
also been previously leveraged. Goldsmith (2001) 
uses morphemes to efficiently encode a corpus, but 
he first groups morphemes into paradigm like 
structures he calls signatures. To date, the work 
that draws the most on paradigm structure is 
Snover (2002). Snover incorporates paradigm 
structure into a generative statistical model of 
morphology. Additionally, to discover paradigm 
like sets of suffixes, Snover designs and searches 
networks of partial paradigms. These networks are 
the direct inspiration for ParaMor?s morphology 
scheme networks described in section 2.1. 
2 ParaMor: Inflection Class Identification 
2.1 Search 
A Search Space: The first stage of ParaMor is a 
search procedure designed to identify partial in-
flection classes containing as many true productive 
suffixes of a language as possible. To search for 
these partial inflection classes we must first define 
a space to search over. In a naturally occurring 
corpus not all possible surface forms occur. In a 
corpus, each stem adhering to an inflection class 
will likely be observed in combination with only a 
subset of the suffixes in that inflection class. Each 
box in Figure 1 depicts a small portion of the em-
pirical co-occurrence of suffixes and stems from a 
Spanish newswire corpus of 50,000 types. Each 
box in this figure contains a list of suffixes at the 
top in bold, together with the total number, and a 
few examples (in italics), of stems that occurred in 
separate word forms with each suffix in that box. 
For example, the box containing the suffixes e, 
er?, ieron, and i? contains the stems deb and 
padec because the word forms debe, padece, de-
ber?, padecer?, etc. all occurred in the corpus. We 
call each possible pair of suffix and stem sets a 
scheme, and say that the e.er?.ieron.i? scheme 
covers the words debe, padece, etc. Note that a 
scheme contains both stems that occurred with ex-
actly the set of suffixes in that scheme, as well as 
119
stems that occurred with suffixes beyond just those 
in the scheme. For example, in addition to the four 
suffixes e, er?, ieron, and i?, the stem deb oc-
curred with the suffixes er and ido, as evident from 
the top left scheme e.er.er?.ido.ieron.i? which 
contains the stem deb. Intuitively, a scheme is a 
subset of the suffixes filling the paradigm cells of a 
true inflection class together with the stems that 
empirically occurred with that set of suffixes.  
The schemes in Figure 1 cover portions of the er 
and the ir Spanish verbal inflection classes. The 
top left scheme of the figure contains suffixes in 
the er inflection class, while the top center scheme 
contains suffixes in the ir inflection class. The six 
suffixes in the top left scheme and the six suffixes 
in the top center scheme are just a few of the 
suffixes in the full er and ir inflection classes. As 
is fairly common for inflection classes across 
languages, the sets of suffixes in the Spanish er 
and ir inflection classes overlap. That is, verbs that 
belong to the er inflection class can take as a suffix 
certain strings of characters that verbs belonging to 
the ir inflection class can also take. The suffixes 
that are unique to the er verb inflection class in the 
top left scheme are er and er?; while the unique 
suffixes for the ir class in the top center scheme are 
ir and ir?. In the third row of the figure, the 
scheme e.ido.ieron.i? contains only suffixes found 
in both the er and ir schemes. 
 While the example schemes in Figure 1 are cor-
rect and do occur in a real Spanish newswire cor-
pus, the schemes are atypically perfect. There is 
only one suffix appearing in Figure 1 that is not a 
true suffix of Spanish?azar in the upper right 
scheme. In unsupervised morphology induction we 
do not know a priori the correct suffixes of a lan-
guage. Hence, we form schemes by proposing can-
didate morpheme boundaries at every character 
boundary in every word, including the character 
boundary after the final character in each word 
form, to allow for empty suffixes. 
Schemes of suffixes and their exhaustively co-
occurring stems define a natural search space over 
partial inflection classes because schemes readily 
organize by the suffixes and stems they contain. 
We define a parent-child relationship between a 
parent scheme, P  and a child scheme C , when P  
contains all the suffixes that C  contains and when 
P  contains exactly one more suffix than C . In 
Figure 1, parent child relations are represented by 
solid lines connecting boxed schemes. The scheme 
e.er.er?.ido.ieron.i?, for example, is the parent of 
three depicted children in Figure 1, one of which is 
e.er.er?.ieron.i?.  
Our search strategy exploits a fundamental 
aspect of the relationship between parent and child 
schemes. Consider the number of stems in a parent 
scheme P  as compared to the number of stems in 
any one of its children C . Since P  contains all the 
suffixes which C  contains, and because P  only 
contains stems that occurred with every suffix in 
P , P  can at most contain exactly the stems C  
contains and typically will contain fewer. In the 
Spanish corpus from which the scheme network of 
Figure 1 was built, 32 stems occur in forms with 
each of the five suffixes e, er, er?, ieron, and i? 
attached. But only 28 of these 32 stems occur in 
yet another form involving ido?the stem deb did 
but the stems padec and romp did not, for example. 
A Search Strategy: To search for schemes 
which cover portions of the true inflection classes 
of a language, ParaMor?s search starts at the bot-
tom of the network. The lowest level in the scheme 
e.er.er?.ido.ieron.i? 
28: deb, escog, ofrec, roconoc, vend, ... 
e.ido.ieron.ir.ir?.i? 
28: asist, dirig, exig, ocurr, sufr, ... 
e.er?.ido.ieron.i? 
28: deb, escog, ... 
e.er.ido.ieron.i? 
46: deb, parec, recog... 
e.ido.ieron.ir?.i? 
28: asist, dirig, ... 
 
e.ido.ieron.ir.i? 
39: asist, bat, sal, ... 
e.er.er?.ieron.i? 
32: deb, padec, romp, ... 
e.ido.ieron.i? 
86: asist, deb, hund,... 
e.er?.ieron.i? 
32: deb, padec, ... 
er.ido.ieron.i? 
58: ascend, ejerc, recog, ... 
ido.ieron.ir.i? 
44: interrump, sal, ... 
Figure 1: A small portion of a morphology scheme network?our search space of partial empirical in-
flection classes. This network was built from a Spanish Newswire corpus of 50,000 types, 1.26 million 
tokens. Each box contains a scheme. The suffixes of each scheme appear in bold at the top of each box. 
The total number of adherent stems for each scheme, together with a few exemplar stems, is in italics. 
Stems are underlined if they do not appear in any parent shown in this figure. 
azar.e.ido.ieron.ir.i? 
1: sal 
120
network consists of schemes which contain exactly 
one suffix together with all the stems that occurred 
in the corpus with that suffix attached. ParaMor 
considers each one-suffix scheme in turn beginning 
with that scheme containing the most stems, work-
ing toward schemes containing fewer. From each 
bottom scheme, ParaMor follows a single greedy 
upward path from child to parent. As long as an 
upward path takes at least one step, making it to a 
scheme containing two or more alternating suf-
fixes, our search strategy accepts the terminal 
scheme of the path as likely modeling a portion of 
a true inflection class. 
Each greedily chosen upward step is based on 
two criteria. The first criterion considers the 
number of adherent stems in the current scheme as 
compared to its parents? adherent sizes. A variety 
of statistics could judge the stem-strength of parent 
schemes: ranging from simple ratios through 
(dis)similarity measures, such as the dice 
coefficient or mutual information, to full fledged 
statistical tests. After experimenting with a range 
of such statistics we found, somewhat surprisingly, 
that measuring the ratio of parent stem size to child 
stem size correctly identifies parent schemes which 
contain only true suffixes just as consistently as 
more sophisticated tests. While a full report of our 
experiments is beyond the scope of this paper, the 
short explanation of this behavior is data 
sparseness. Many upward search steps start from 
schemes containing few stems. And when little 
data is available no statistic is particularly reliable.  
Parent-child stem ratios have two additional 
computational advantages over other measures. 
First, they are quick to compute and second, the 
parent with the largest stem ratio is always that 
parent with the most stems. So, being greedy, each 
search step simply moves to that parent, P , with 
the most stems, as long as the parent-child stem 
ratio to P  is large. The threshold above which a 
stem ratio is considered large enough to warrant an 
upward step is a free parameter. As the goal of this 
initial search stage is to identify schemes contain-
ing as wide a variety of productive suffixes as pos-
sible, we want to set the parent-child stem ratio 
threshold as low as possible. But a ratio threshold 
that is too small will allow search paths to schemes 
containing unproductive and spurious suffixes. In 
practice, for Spanish, we have found that setting 
the parent-child stem ratio cutoff much below 0.25 
results in schemes that begin to include only mar-
ginally productive derivational suffixes. For this 
paper we leave the parent-child stem ratio cutoff 
parameter at 0.25.  
Alone, stem strength assessments of parent 
schemes, such as parent-child stem ratios, falter as 
a search path nears the top of the morphology 
scheme network. Monotonically decreasing adher-
ent stem size causes statistics that assess parents? 
stem-strength to become less and less reliable. 
Hence, the second criterion governing each search 
step helps to halt upward search paths before judg-
ing parents? worth becomes impossible. While 
there are certainly many possible stopping criteria, 
ParaMor?s policy stops each upward search path 
when there is no parent scheme with more stems 
than it has suffixes. We devised this halting condi-
tion for two reasons. First, requiring each path 
scheme to contain more stems than suffixes attains 
high suffix recall. High recall results from setting a 
low bar for upward movement at the bottom of the 
network. Search paths which begin from schemes 
whose single suffix is rare in the text corpus can 
often take one or two upward search steps and 
reach a scheme containing the necessary three or 
four stems. Second, this halting criterion requires 
the top scheme of search paths that climb high in 
the network to contain a comparatively large num-
ber of stems. Reigning in high-reaching search 
paths before the stem count falls too far, captures 
path-terminal schemes which cover a large number 
of word types. In the second stage of ParaMor?s 
inflection class identification phase these larger 
terminal schemes effectively vacuum up the useful 
smaller paths that result from the more rare suf-
fixes. Figure 2 contains examples of schemes se-
lected by ParaMor?s initial search. 
To evaluate ParaMor at paradigm identification, 
we hand compiled an answer key of the inflection 
classes of Spanish. This answer key contains nine 
productive inflection classes. Three contain the 
suffixes of the ar, er, and ir verbal inflection 
classes. There are two orthographically differenti-
ated inflection classes for nouns in the answer key: 
one for nouns that form the plural by adding s, and 
one for nouns that take es. Adjectives in Spanish 
inflect for gender and number. Arguably, gender 
and number each constitute separate paradigms, 
each with two cells. But here we conflated these 
into a single inflection class with four cells. Fi-
nally, there are three inflection classes in our an-
swer key covering Spanish clitics. Spanish verbal 
clitics behave orthographically as agglutinative 
sequences of suffixes.  
121
In a corpus of Spanish newswire text of 50,000 
types and 1.26 million tokens, the initial search 
identifies schemes containing 92% of all ideal in-
flectional suffixes of Spanish, or 98% of the ideal 
suffixes that occurred at least twice in the corpus. 
There are selected schemes which contain portions 
of each of the nine inflection classes in the answer 
key. The high recall of the initial search comes, of 
course, at the expense of precision. While there are 
nine inflection-classes and 87 unique suffixes in 
the hand-built answer key for Spanish, 8339 
schemes are selected containing 9889 unique can-
didate suffixes.  
2.2 Clustering Partial Inflection Classes 
While the third step of inflection class identifica-
tion, discussed in Section 2.3, directly improves 
the initial search?s low precision by filtering out 
bogus schemes, the second step, described here, 
conflates selected schemes which model portions 
of the same inflection class. Consider the fifth and 
twelfth schemes selected by ParaMor from our 
Spanish corpus, as shown in Figure 2. Both of 
these schemes contain a large number of suffixes 
from the Spanish ar verbal inflection class. And 
while each contains many overlapping suffixes, 
each possesses correct suffixes which the other 
does not. Meanwhile, the 1591st selected scheme 
contains four suffixes of the ir verbal inflection 
class, including the only instance of ir? that occurs 
in any selected scheme. Containing only six stems, 
the 1591st scheme could accidentally be filtered out 
during the third phase of inflection class identifica-
tion. Hence, the rationale for clustering initial se-
lected schemes is two fold. First, by consolidating 
schemes which cover portions of the same inflec-
tion class we produce sets of suffixes which more 
closely model the paradigm structure of natural 
language morphology. And, second, corralling cor-
rect schemes safeguards against losing unique suf-
fixes. 
The clustering of schemes presents two unique 
challenges. First, we must avoid over-clustering 
schemes which model distinct inflection classes. 
As noted in Section 2.1, it is common, cross-
linguistically, for the suffixes of inflection classes 
to overlap. Looking at Figure 2, we must be careful 
not to merge the 209th selected scheme, which 
models a portion of the er verbal inflection class, 
with the 1591st selected scheme, which models the 
ir class?despite these schemes sharing two suf-
fixes, ido and idos. As the second challenge, the 
many small schemes which the search strategy 
produces act as distractive noise during clustering. 
While small schemes containing correct suffixes 
do exist, e.g. the 1591st scheme, the vast majority 
of schemes containing few stems and suffixes are 
incorrect collections of word final strings that hap-
pen to occur in corpus word forms attached to a 
small number of shared initial strings. ParaMor?s 
clustering algorithm should, for example, avoid 
placing ?.s and ?.ipo, respectively the 1st and 
1590th selected schemes, in the same cluster. Al-
though ?.ipo shares the null suffix with the valid 
nominal scheme ?.s, the string ?ipo? is not a mor-
phological suffix of Spanish. 
To form clusters of related schemes while ad-
dressing both the challenge of observing a lan-
guage?s paradigm structure as well as the challenge 
of merging in the face of many small incorrectly 
selected schemes, ParaMor adapts greedy hierar-
chical agglomerative clustering. We modify vanilla 
bottom-up clustering by placing restrictions on 
which clusters are allowed to merge. The first re-
striction helps ensure that schemes modeling dis-
tinct but overlapping inflection classes remain 
separated. The restriction: do not place into the 
same cluster suffixes which share no stem in the 
corpus. This restriction retains separate clusters for 
separate inflection classes because a lexeme?s stem 
Figure 2: The suffixes of some schemes selected 
by the initial search over a Spanish corpus of 
50,000 types. While some selected schemes 
contain large numbers of correct suffixes, such 
as the 1st, 2nd, 5th, 12th, 209th, and 1591st selected 
schemes; many others are incorrect collections 
of word final strings. 
 1) ?.s 5501 stems 
 2) a.as.o.os 892 stems 
... 
 5) a.aba.aban.ada.adas.ado.ados.an.ando.   
ar.aron.arse.ar?.ar?n.? 25 stems 
... 
 12) a.aba.ada.adas.ado.ados.an.ando.ar.   
aron.ar?.ar?n.e.en.? 21 stems 
... 
 209) e.er.ida.idas.ido.idos.imiento.i? 9 stems 
... 
1590) ?.ipo 4 stems 
1591) ido.idos.ir.ir? 6 stems 
1592) ?.e.iu 4 stems 
1593) iza.izado.izan.izar.izaron.izar?n.iz? 
... 8 stems 
122
occurring with suffixes unique to that lexeme?s 
inflection class will not occur with suffixes unique 
to some other inflection class.  
Alone, requiring all pairs of suffixes in a cluster 
to occur in the corpus with some common stem 
will not prevent small bogus schemes, such as 
?.ipo from attaching to correct schemes, such as 
?.s?the ipo.s scheme contains two ?stems,? the 
word form initial strings ?ma? and ?t?. And so a 
second restriction is required. This second restric-
tion employs a heuristic specifically adapted to 
ParaMor?s initial search strategy. As discussed in 
Section 2.1, in addition to many schemes which 
contain only few suffixes, ParaMor?s initial net-
work search also identifies multiple overlapping 
schemes containing significant subsets of the suf-
fixes in an inflection class. The 5th, 12th, and 209th 
selected schemes of Figure 2 are three such larger 
schemes. ParaMor restricts cluster merges heuristi-
cally by requiring at least one large scheme for 
each small scheme the cluster contains, where we 
measure the size of a scheme as the number of 
unique word forms it covers. The threshold size 
above which schemes are considered large is the 
second of ParaMor?s two free parameters. The 
scheme size threshold is reused during ParaMor?s 
filtering stage. We discuss the unsupervised proce-
dure we use to set the size threshold when we pre-
sent the details of cluster filtering in Section 2.3. 
We have found that with these two cluster re-
strictions in place, the particular metric we use to 
measure the similarity of scheme-clusters does not 
significantly affect clustering. For the experiments 
we report here, we measure the similarity of 
scheme-clusters as the cosine between the sets of 
all possible stem-suffix pairs the clusters contain. 
A stem-suffix pair occurs in a cluster if some 
scheme belonging to that cluster contains both that 
stem and that suffix. With these adaptations, we 
allow agglomerative clustering to proceed until 
there are no more clusters that can legally be 
merged.  
2.3 Filtering of Inflection Classes 
With most valid schemes having found a safe ha-
ven in a cluster with other schemes modeling the 
same inflection class, we turn our attention to im-
proving scheme-cluster precision. ParaMor applies 
a series of filters, culling out unwanted scheme-
clusters. The first filter is closely related to the 
cluster restriction on scheme size discussed in Sec-
tion 2.2. ParaMor discards all unclustered schemes 
falling below the size threshold used during clus-
tering. Figure 3 graphs the number of Spanish clus-
ters which survive this size-based filtering step as 
the threshold size is varied. Figure 3 also contains 
a plot of the recall of unique Spanish suffixes as a 
function of this threshold. As the size threshold is 
increased the number of remaining clusters quickly 
drops. But suffix recall only slowly falls during the 
steep decline in cluster count, indicating ParaMor 
discards mostly bogus schemes containing illicit 
suffixes. Because recall is relatively stable, the ex-
act size threshold we use should have only a minor 
effect on ParaMor?s final morphological analyses. 
In fact, we have not fully explored the ramifica-
tions various threshold values have on the final 
morphological word segmentations, but have sim-
ply picked a reasonable setting, 37 covered word 
types. At this threshold, the number of scheme-
clusters is reduced by more than 98%, while the 
number of unique candidate suffixes in any cluster 
is reduced by more than 85%. Note that the initial 
number of selected schemes, 8339, falls outside the 
scale of Figure 3. 
Of the scheme-clusters which remain after size 
based filtering is complete, by far the largest cate-
gory of incorrect clusters contains schemes which, 
like the 1593rd selected scheme, shown in Figure 2, 
incorrectly hypothesize morpheme boundaries one 
or more characters to the left of the true boundary. 
To filter out these incorrectly segmented clusters 
we use a technique inspired by Harris (1955). For 
each initial string common to all suffixes in the 
cluster, for each scheme in the cluster, we examine 
the network scheme containing the suffixes formed 
by stripping the initial string from the scheme?s 
Figure 3: The # of clusters and their recall of 
unique Spanish suffixes as the scheme-cluster 
size cutoff is varied. The value of each function 
at the threshold we use in all experiments re-
ported in this paper is that of the larger symbol. 
0
200
400
600
800
1000
0 50 100 150
Scheme or Cluster Size
# 
o
f C
lu
st
er
s
0
0.2
0.4
0.6
0.8
1
R
ec
a
ll
# of Clusters
Recall
 
123
suffixes. We then measure the entropy of leftward 
trie characters of the stripped scheme. If the en-
tropy is large, then the character stripped scheme is 
likely at a morpheme boundary and the original 
scheme is likely modeling an incorrect morpheme 
boundary. This algorithm would throw out the 
1593rd selected scheme because the stems in the 
scheme a.ado.an.ar.aron.ar?n.? end in a wide 
variety of characters, yielding high trie entropy, 
and signaling a likely morpheme boundary. 
Because we apply morpheme boundary filtering 
after we have clustered, the redundancy of the 
many schemes in the cluster makes this filter quite 
robust, letting us set the cutoff parameter as low as 
we like avoiding another free parameter. 
2.4 Segmentation and Evaluation 
Word segmentation is our final step of morpholo-
gical analysis. ParaMor?s current segmentation 
algorithm is perhaps the most simple paradigm 
inspired segmentation algorithm possible. Essen-
tially, ParaMor strips off suffixes which likely par-
ticipate in a paradigm. To segment any word, w , 
ParaMor identifies all scheme-clusters that contain 
a non-empty suffix that matches a word final string 
of w . For each such matching suffix, Cf ? , 
where C is the cluster containing f , we strip f  
from w  obtaining a stem t . If there is some sec-
ond suffix Cf ??  such that ft ?.  is a word form 
found in either of the training or the test corpora, 
then ParaMor proposes a segmentation of w  be-
tween t  and f . ParaMor, here, identifies f  and 
f ?  as mutually exclusive suffixes from the same 
paradigm. If ParaMor finds no complex analysis, 
then we propose w  itself as the sole analysis of the 
word. Note that for each word form, ParaMor may 
propose multiple separate segmentation analyses 
each containing a single proposed stem and suffix. 
To evaluate ParaMor?s morphological segmenta-
tions we follow the methodology of Morpho Chal-
lenge 2007 (Kurimo et al, 2007), a minimally su-
pervised morphology induction competition. Word 
segmentations are evaluated in Morpho Challenge 
2007 by comparing against hand annotated mor-
phological analyses. The correctness of proposed 
morphological analyses is computed in Morpho 
Challenge 2007 by comparing pairs of word forms 
which share portions of their analyses. Recall is 
measured by first sampling pairs of words from the 
answer analyses which share a stem or morphosyn-
tactic feature and then noting if that pair of word 
forms shares a morpheme in any of their proposed 
analyses. Precision is measured analogously, sam-
pling morpheme-sharing pairs of words from the 
proposed analyses and noting if that pair of words 
shares a feature in any correct analysis of those 
words.  
We evaluate ParaMor on two languages not 
examined during the development of ParaMor?s 
induction algorithms: English and German. And 
we evaluate with each of these two languages at 
two tasks:  
1. Analyzing inflectional morphology alone 
2. Jointly analyzing inflectional and derivational 
morphology.  
We constructed Morpho Challenge 2007 style 
answer keys for each language and each task using 
the Celex database (Burnage, 1990). The English 
and German corpora we test over are the corpora 
available through Morpho Challenge 2007. The 
English corpus contains nearly 385,000 types, 
while the German corpus contains more than 1.26 
million types. ParaMor induced paradigmatic 
scheme-clusters over these larger corpora by 
reading just the top 50,000 most frequent types. 
But with the scheme-clusters in hand, ParaMor 
segmented all the types in each corpus. 
We compare ParaMor to Morfessor v0.9.2 
(Creutz, 2006), a state-of-the-art minimally super-
vised morphology induction algorithm. Morfessor 
has a single free parameter. To make for stiff com-
petition, we report results for Morfessor at that pa-
rameter setting which maximized F1 on each sepa-
rate test scenario. We did not vary the two free pa-
rameters of ParaMor, but hold each of ParaMor?s 
parameters at a setting which produced reasonable 
Spanish suffix sets, see sections 2.1-2.2. Table 2 
contains the evaluation results. To estimate the 
variance of our experimental results we measured 
Morpho Challenge 2007 style precision, recall, and 
F1 on multiple non-overlapping pairs of 1000 fea-
ture-sharing words.  
Neither ParaMor nor Morfessor arise in Table 2 
as clearly superior. Each algorithm outperforms the 
other at F1 in some scenario. Examining precision 
and recall is more illuminating. ParaMor attains 
particularly high recall of inflectional affixes for 
both English and German. We conjecture that Pa-
raMor?s strong performance at identifying inflec-
tional morphemes comes from closely modeling 
the natural paradigm structure of language. Con-
versely, Morfessor places its focus on precision 
and does not rely on any property exclusive to in-
flectional (or derivational) morphology. Hence, 
124
Morfessor attains high precision with reasonable 
recall when graded against an answer key contain-
ing both inflectional and derivational morphology. 
We are excited by ParaMor?s strong 
performance and are eager to extend our algorithm. 
We believe the precision of ParaMor?s simple 
segmentation algorithm can be improved by 
narrowing down the proposed analyses for each 
word to the most likely. Perhaps ParaMor and 
Morfessor?s vastly different strategies for 
morphology induction could be combined into a 
hybrid strategy more successful than either alone. 
And ambitiously, we hope to extend ParaMor to 
analyze languages with agglutinative sequences of 
affixes by generalizing the definition of a scheme.  
Acknowledgements 
The research reported in this paper was funded in 
part by NSF grant number IIS-0121631. 
References 
Altun, Yasemin, and Mark Johnson. "Inducing 
SFA with -Transitions Using Minimum 
Description Length." Finite State Methods in 
Natural Language Processing Workshop at 
ESSLLI Helsinki: 2001.  
Brent, Michael R., Sreerama K. Murthy, and 
Andrew Lundberg. "Discovering Morphemic 
Suffixes: A Case Study in MDL Induction." The 
Fifth International Workshop on Artificial Intel-
ligence and Statistics Fort Lauderdale, Florida, 
1995.  
Burnage, Gavin. Celex?A Guide for Users. 
Springer, Centre for Lexical information, 
Nijmegen, the Netherlands, 1990. 
Creutz, Mathias. ?Induction of the Morphology of 
Natural Language: Unsupervised Morpheme 
Segmentation with Application to Automatic 
Speech Recognition.? Ph.D. Thesis in Computer 
and Information Science, Report D13. Helsinki: 
University of Technology, Espoo, Finland, 2006. 
Goldsmith, John. "Unsupervised Learning of the 
Morphology of a Natural Language." Computa-
tional Linguistics 27.2 (2001): 153-198.  
Hafer, Margaret A., and Stephen F. Weiss. "Word 
Segmentation by Letter Successor Varieties." 
Information Storage and Retrieval 10.11/12 
(1974): 371-385. 
Harris, Zellig. "From Phoneme to Morpheme." 
Language 31.2 (1955): 190-222. Reprinted in 
Harris 1970. 
Harris, Zellig. Papers in Structural and 
Transformational Linguists. Ed. D. Reidel, 
Dordrecht 1970. 
Johnson, Howard, and Joel Martin. "Unsupervised 
Learning of Morphology for English and Inuk-
titut." Human Language Technology Conference 
/ North American Chapter of the Association for 
Computational Linguistics (HLT-NAACL). 
Edmonton, Canada: 2003. 
Kurimo, Mikko, Mathias Creutz, and Matti 
Varjokallio. ?Unsupervised Morpheme Analysis 
? Morpho Challenge 2007.? March 26, 2007. 
<http://www.cis.hut.fi/morphochallenge2007/> 
Schone, Patrick, and Daniel Jurafsky. "Know-
ledge-Free Induction of Inflectional Morpho-
logies." North American Chapter of the 
Association for Computational Linguistics 
(NAACL). Pittsburgh, Pennsylvania: 2001. 183-
191. 
Snover, Matthew G. "An Unsupervised Knowledge 
Free Algorithm for the Learning of Morphology 
in Natural Languages." Sever Institute of Tech-
nology, Computer Science Saint Louis, Mis-
souri: Washington University, M.S. Thesis, 
2002. 
Table 2: ParaMor segmentations compared to Morfessor?s (Creutz, 2006) evaluated for Precision, Recall, 
F1, and standard deviation of F1, , in four scenarios. Segmentations over English and German are each 
evaluated against correct morphological analyses consisting, on the left, of inflectional morphology 
only, and on the right, of both inflectional and derivational morphology. 
 Inflectional Morphology Only Inflectional & Derivational Morphology 
 English German English German 
 P R F1  P R F1  P R F1  P R F1  
Morfessor 53.3 47.0 49.9 1.3 38.7 44.2 41.2 0.8 73.6 34.0 46.5 1.1 66.9 37.1 47.7 0.7 
ParaMor 33.0 81.4 47.0 0.9 42.8 68.6 52.7 0.8 48.9 53.6 51.1 0.8 60.0 33.5 43.0 0.7 
 
125
Proceedings of the Tenth Meeting of the ACL Special Interest Group on Computational Morphology and Phonology, pages 49?58,
Columbus, Ohio, USA June 2008. c?2008 Association for Computational Linguistics
Evaluating an Agglutinative Segmentation Model for ParaMor 
Christian Monson, Alon Lavie, Jaime Carbonell, Lori Levin 
Language Technologies Institute 
Carnegie Mellon University 
Pittsburgh, PA 15217, USA 
 {cmonson, alavie, jgc, lsl}@cs.cmu.edu
Abstract 
This paper describes and evaluates a modifica-
tion to the segmentation model used in the un-
supervised morphology induction system, Pa-
raMor. Our improved segmentation model 
permits multiple morpheme boundaries in a 
single word. To prepare ParaMor to effectively 
apply the new agglutinative segmentation 
model, two heuristics improve ParaMor?s pre-
cision. These precision-enhancing heuristics 
are adaptations of those used in other unsuper-
vised morphology induction systems, including 
work by Hafer and Weiss (1974) and Gold-
smith (2006). By reformulating the segmenta-
tion model used in ParaMor, we significantly 
improve ParaMor?s performance in all lan-
guage tracks and in both the linguistic evalua-
tion as well as in the task based information re-
trieval (IR) evaluation of the peer operated 
competition Morpho Challenge 2007. Para-
Mor?s improved morpheme recall in the lin-
guistic evaluations of German, Finnish, and 
Turkish is higher than that of any system which 
competed in the Challenge. In the three lan-
guages of the IR evaluation, our enhanced Pa-
raMor significantly outperforms, at average 
precision over newswire queries, a morpho-
logically na?ve baseline; scoring just behind the 
leading system from Morpho Challenge 2007 
in English and ahead of the first place system 
in German.  
1 Unsupervised Morphology Induction 
Analyzing the morphological structure of words 
can benefit natural language processing (NLP) ap-
plications from grapheme-to-phoneme conversion 
(Demberg et al, 2007) to machine translation 
(Goldwater and McClosky, 2005). But many of the 
world?s languages currently lack morphological 
analysis systems. Unsupervised induction could fa-
cilitate, for these lesser-resourced languages, the 
quick development of morphological systems from 
raw text corpora. Unsupervised morphology induc-
tion has been shown to help NLP tasks including 
speech recognition (Creutz, 2006) and information 
retrieval (Kurimo et al, 2007b). In this paper we 
work with languages like Spanish, German, and 
Turkish for which morphological analysis systems 
already exist. 
The baseline ParaMor algorithm which we ex-
tend here competed in the English and German 
tracks of Morpho Challenge 2007 (Monson et al, 
2007b). The peer operated competitions of the 
Morpho Challenge series standardize the evalua-
tion of unsupervised morphology induction algo-
rithms (Kurimo et al, 2007a; 2007b). The ParaMor 
algorithm showed promise in the 2007 Challenge, 
placing first in the linguistic evaluation of German. 
Developed after the close of Morpho Challenge 
2007, our improvements to the ParaMor algorithm 
could not officially compete in this Challenge. 
However, the Morpho Challenge 2007 Organizing 
Committee (Kurimo et al, 2008) graciously over-
saw the quantitative evaluation of our agglutinative 
version of ParaMor.  
1.1 Related Work 
A variety of approaches to unsupervised morphol-
ogy induction have shown promise in past work: 
Here we highlight three techniques which have 
been used in a number of unsupervised morphol-
ogy induction algorithms. Since character se-
quences are less predictable at morpheme bounda-
ries than within any particular morpheme (see dis-
cussion in section 2.1), a first unsupervised mor-
49
phology induction technique measures the predict-
ability of word-internal character sequences. Harris 
(1955) was the first to propose the branching factor 
of the character tree of a corpus vocabulary as a 
measure of character predictability. Character trees 
have been incorporated into a number of more re-
cently proposed unsupervised morphology induc-
tion systems (Schone and Jurafsky, 2001; Wicen-
towski, 2002; Goldsmith, 2006; Bordag, 2007). 
Johnson and Martin (2003) generalize from charac-
ter trees and model morphological character se-
quences with minimized finite state automata. 
Bernhard (2007) measures character predictability 
by directly computing transitional probabilities be-
tween substrings of words. 
A second successful technique has used the 
minimum description length principle to capture 
the morpheme as a recurrent structure of morphol-
ogy. The Linguistica system of Goldsmith (2006), 
the Morfessor system of Creutz (2006), and the 
system described in Brent et al (1995) take this 
approach. 
A third technique leverages inflectional para-
digms as the organizational structure of morphol-
ogy. The ParaMor algorithm, which this paper ex-
tends, joins Snover (2002), Zeman (2007), and 
Goldsmith?s Linguistica in building morphology 
models around the paradigm.  
ParaMor tackles three challenges that face mor-
phology induction systems which Goldsmith's Lin-
guistica algorithm does not yet address. First, sec-
tion 2.2 of this paper introduces an agglutinative 
segmentation model. This agglutinative model seg-
ments words into as many morphemes as the data 
justify. Although Goldsmith (2001) and Goldsmith 
and Hu (2004) discuss ideas for segmenting indi-
vidual words into more than two morphemes, the 
implemented Linguistica algorithm, as presented in 
Goldsmith (2006), permits at most a single mor-
pheme boundary in each word. Second, ParaMor 
decouples the task of paradigm identification from 
that of word segmentation (Monson et al, 2007b). 
In contrast, morphology models in Linguistica in-
herently encode both a belief about paradigm 
structure on individual words as well as a segmen-
tation of those words. Without ParaMor?s decoup-
ling of paradigm structure from specific segmenta-
tion models, our algorithm for agglutinative seg-
mentation (section 2.2) would not have been possi-
ble. Third, the evaluation of ParaMor in this paper 
is over much larger corpora than any published 
evaluation of Linguistica. Goldsmith (2006) seg-
ments the Brown corpus of English, which, after 
discarding numbers and punctuation, has a vocabu-
lary size of 47,607 types. Using Linguistica, Creutz 
(2006) successfully segments a Finnish corpus of 
250,000 tokens (approximately 130,000 types), but 
Creutz notes that Linguistica is memory intensive 
and not runable for larger corpora. In the evalua-
tions of Morpho Challenge 2007, ParaMor seg-
mented the words from corpora with over 42 mil-
lion tokens and vocabularies as large as 2.2 million 
types.  
2 ParaMor 
This section briefly outlines the high level struc-
ture of ParaMor as described in detail in Monson et 
al. (2007a; 2007b). ParaMor takes the inflectional 
paradigm as the basic building block of morphol-
ogy. A paradigm is a mutually substitutable set of 
morphological operations. For example, most ad-
jectives in Spanish inflect for two paradigms. First, 
adjectives are marked for gender: an a suffix 
marks feminine, an o masculine. Then Spanish ad-
jectives mark number: an s suffix signals plural, 
while no marking, ? in this paper, indicates singu-
lar. The four surface forms of the cross-product of 
the gender and number paradigms on the Spanish 
word for ?beautiful? are then: bello, bella, bellos, 
and bellas.  
ParaMor is a two stage algorithm. In the first 
stage, ParaMor identifies candidate paradigms 
which likely model suffixes of morphological pa-
radigms and their cross-products. Since some 70% 
of the world?s languages are significantly suffixing 
(Dryer, 2005), ParaMor only attempts to identify 
suffix paradigms. ParaMor?s first stage consists of 
three pipelined steps. In the first step, ParaMor 
searches a space of candidate partial paradigms, 
called schemes, for those which possibly model 
suffixes of true paradigms. The second step merges 
selected schemes which appear to model the same 
paradigm. And in the third step, ParaMor discards 
scheme clusters which likely do not model true 
paradigms.  
The second stage of the ParaMor algorithm 
segments word forms using the candidate para-
digms identified in the first stage. Section 2.2 of 
this paper introduces a new segmentation model 
for ParaMor?s second stage that allows more than 
one morpheme boundary in a single word?as is 
50
needed to correctly segment Spanish plural adjec-
tives. As this agglutinative segmentation model re-
lies on the paradigms learned in ParaMor?s first 
stage, section 2.1 presents solutions to two types of 
paradigm model error that the baseline ParaMor 
system makes. The solutions to these two error 
types are similar in nature to ideas proposed in the 
unsupervised morphology induction work of Hafer 
and Weiss (1974) and Goldsmith (2006). 
2.1 Precision at Paradigm Identification 
Table 1 presents 14 of the more than 8000 schemes 
identified during one baseline run of ParaMor?s 
scheme search step. Each row of Table 1 lists a 
scheme that was selected while searching over a 
Spanish newswire corpus of 50,000 types. On the 
far left of Table 1, the Rank column states the or-
dinal rank at which that row?s scheme was selected 
during the search procedure: the first scheme Pa-
raMor selects is ?.s; a.as.o.os is the second; ido.-
idos.ir.ir? is the 1566th selected scheme, etc. The 
right four columns of Table 1, present raw data on 
the selected schemes, giving the number of can-
didate suffixes in that scheme, the proposed suf-
fixes themselves, the number of candidate stems in 
the scheme, and a sample of those candidate stems. 
Each candidate stem in a ParaMor scheme forms a 
word that occured in the input corpus with each 
candidate suffix belonging to that scheme; for 
example, from the first selected scheme, the candi-
date stem apoyada joins to the candidate suffix s to 
form the word apoyadas ?supported (adjective 
feminine plural)??a word which occured in the 
Spanish newswire corpus.  
Between the rank on the left and the scheme 
details on the right of Table 1, are columns which 
categorize the scheme on its success, or failure, to 
model a true paradigm of Spanish. A dot appears in 
the columns marked Noun, Adjective, or Verb if the 
majority of the candidate suffixes in a row?s 
scheme attempt to model suffixes in a paradigm of 
that part of speech. A dot appears in the Derivation 
column if one or more candidate suffixes of the 
scheme models a Spanish derivational suffix. The 
Good column is marked if the candidate suffixes of 
a scheme take the surface form of true paradig-
matic suffixes. Initially selected schemes in Table 
1 that correctly capture suffixes of real Spanish 
paradigms are the 1st, 2nd, 5th, 13th, 30th, and 1566th 
selected schemes. While some smaller paradigms 
of Spanish are perfectly identified (including ?.s, 
which marks singular and plural on many nouns 
and adjectives, and the adjectival cross-product 
paradigm of gender and number, a.as.o.os) many 
selected schemes do not satisfactorily model Span-
ish suffixes. Incorrect schemes in Table 1 are 
marked in the Error columns.  
The vast majority of unsatisfactory paradigm 
models fail for one of two reasons. First, many 
schemes contain candidate suffixes which system-
Model of Error 
Verb 
Ra
nk
 
No
un
 
Ad
jec
tiv
e 
ar er ir 
De
riv
ati
on
 
Go
od
 
St
em
 In
ter
na
l 
Su
ffi
x I
nt
er
na
l 
Ch
an
ce
 Candidate Suffixes Candidate Stems 
1 ?  ?      ?     2 ?.s 5513 apoyada, barata, hombro, oficina, reo, ? 
2  ?      ?     4 a.as.o.os 899 apoyad, captad, dirigid, junt, pr?xim, ? 
3   ?       ?   14 ?.ba.ban.da.das.do.dos.n.ndo.r.ron.rse.r?.r?n 25 apoya, disputa, lanza, lleva, toma, ? 
5   ?     ?     15 a.aba.aban.ada.adas.ado.ados.an.ando.ar.aron.arse.ar?.ar?n.? 24 apoy, desarroll, disput, lanz, llev, ? 
11  ?     ?   ?    5 ta.tamente.tas.to.tos 22 cier, direc, ins?li, modes, sangrien, ? 
12   ?    ?    ?   14 ?.ba.ci?n.da.das.do.dos.n.ndo.r.ron.r?.r?n.r?a 16 acepta, concentra, fija, provoca, ? 
13   ?     ?     15 a.aba.ada.adas.ado.ados.an.ando.ar.aron.ar?.ar?n.e.en.? 20 apoy, declar, enfrent, llev, tom, ? 
30    ?  ?   ?     11 a.e.en.ida.idas.ido.idos.iendo.ieron.i?.?a 15 cumpl, escond, recib, transmit, vend, ? 
1000          ?  3 ?.g.gs 4 h, k, on, s 
1566     ?   ?     4 ido.idos.ir.ir? 6 conclu, cumpl, distribu, exclu, reun, segu 
2000      ?   ?    2 lia.liana 5 austra, ita, ju, sici, zu 
3000          ?  3 ?.a.anar 4 all, am, g, s 
4000          ?  3 ?.e.ince 4 l, pr, qu, v 
8000   ?      ?    2 trada.trarnos 3 concen, demos, encon 
               
 
Table 1. Candidate partial paradigms, or schemes, that the baseline ParaMor algorithm selected during its first step, 
search, of its first stage, paradigm identification. This baseline ParaMor run was over a Spanish newswire corpus of 
50,000 types. While some selected schemes contain suffixes from true paradigms, other schemes contain incorrectly 
segmented candidate suffixes. 
  
51
atically misanalyze word forms. These schemes 
consistently hypothesize either stem-internal or 
suffix-internal morpheme boundaries. Schemes 
which hypothesize incorrect morpheme boundaries 
include the 3rd, 11th, 12th, 2000th, and 8000th se-
lected schemes of Table 1. Among these, the 3rd 
and 12th selected schemes place morpheme boun-
daries internal to true suffixes. For example, the 3rd 
selected scheme contains truncated forms of suf-
fixes that occur correctly in the 5th selected 
scheme. Symmetrically, the candidate suffixes in 
the 11th, 2000th, and 8000th selected schemes hy-
pothesize morpheme boundaries internal to true 
Spanish stems, inadvertently including portions of 
stems within their suffix lists. In a random sample 
of 100 schemes from the 8240 schemes that the 
baseline ParaMor algorithm selects over our Span-
ish corpus, 59 schemes hypothesized an incorrect 
morpheme boundary. 
The second most prevalent reason for model 
failure occurs when the candidate suffixes of a 
scheme are related not by belonging to the same 
paradigm, but rather by a chance co-occurrence on 
a few candidate stems of the text. Schemes which 
arise from chance string collisions in Table 1 in-
clude the 1000th, 3000th, and 4000th selected 
schemes. The string lengths of the candidate stems 
and candidate suffixes of these chance schemes are 
often quite short. The longest candidate stem in 
any of the three chance-error schemes of Table 1 is 
three characters long; and all three selected 
schemes propose the suffix ?, which has length 
zero. Short stems and short suffixes in selected 
schemes are easily explained combinatorially: The 
inventory of possible strings grows exponentially 
with the length of the string. Because there just 
aren?t very many length one, length two, or even 
length three strings, it should come as no surprise 
when a variety of candidate suffixes happen to oc-
cur attached to the same set of short stems. In our 
random sample of 100 initially selected schemes, 
35 were erroneously selected as a result of a 
chance collision of word types. 
The next two sub-sections present solutions to 
the two types of paradigm model failure in the 
baseline algorithm that are exemplified in Table 1. 
These first two extensions aim to improve preci-
sion by reducing the number of schemes ParaMor 
erroneously selects. 
 
Correcting Morpheme Boundary Errors 
Most of the baseline selected schemes which incor-
rectly hypothesize a morpheme boundary do so at 
stem-internal positions. Indeed, in our random 
sample of 100 schemes, 51 of the 59 schemes with 
morpheme boundary errors incorrectly hypothe-
sized a boundary stem-internally. For this reason, 
the baseline ParaMor algorithm already discarded 
schemes that likely misplace a boundary stem-
internally (Monson et al, 2007b). Although there 
are fewer schemes that misplace a morpheme 
boundary suffix-internally, suffix-internal error 
schemes contain short suffixes that can generalize 
to segment a large number of word forms. (See 
section 2.2 for a description of ParaMor?s morpho-
logical segmentation model). To measure the in-
fluence of suffix-internal error schemes on mor-
pheme segmentation, we examined ParaMor?s 
baseline segmentations of a random sample of 100 
word forms from the 50,000 words of our Spanish 
corpus. In these 100 words, 82 morpheme bounda-
ries were introduced that should not have been. 
And 40 of these 82 incorrectly proposed bounda-
ries were placed by schemes which hypothesized a 
morpheme boundary internal to true suffixes.  
To address the problem of suffix-internal mis-
placed boundaries we adapt an idea originally pro-
posed by Harris (1955) and extended by Hafer and 
Weiss (1974): Take any string t. Let F be the set of 
strings such that for each Ff ? , t.f is a word form 
of a particular natural language. Harris noted that 
when the boundaries between t and each f fall at 
morpheme boundaries, the strings in F typically 
begin in a wide variety of characters; but when the 
t-f boundaries are morpheme-internal, each legiti-
mate word final string must first complete the er-
roneously split morpheme, and so the strings in F 
will begin with one of a very few characters. This 
argument similarly holds when the roles of t and f 
are reversed. Hafer and Weiss (1974) describe a 
number of variations to Harris? letter variety algo-
rithm. Their most successful variation uses entropy 
to measure character variety.  
Goldsmith?s (2006) Linguistica algorithm pio-
neered the use of entropy in a paradigm-based un-
supervised morphology induction system. Linguis-
tica measures the entropy of stem-final characters 
in a set of initially selected paradigm models. 
When entropy falls below a threshold, Linguistica 
considers relocating the morpheme boundary of 
52
each word covered by that paradigm model. If, af-
ter boundary relocation, the resulting description 
length of Linguistica?s morphology model de-
creases, Linguistica accepts the relocated bounda-
ries.  
To identify suffix-internal morpheme boundary 
errors among ParaMor?s initially selected schemes, 
we follow Hafer and Weiss (1974) and Goldsmith 
(2006) in using entropy as a measure of the variety 
in boundary-adjacent character distributions. In a 
ParaMor style scheme, the candidate stems form a 
set of word-initial strings, and the candidate suf-
fixes a set of word-final strings. If a scheme?s 
stems end in a very few unique characters, the 
scheme has likely hypothesized an incorrect suffix-
internal morpheme boundary. Consider the 3rd se-
lected scheme in Table 1. All 25 of the 3rd 
scheme?s stems end in the character ?a?. Conse-
quently, we measure the entropy of the distribution 
of final characters in each scheme?s candidate 
stems. Where Linguistica modifies paradigm mod-
els which appear to incorrectly place morpheme 
boundaries, our extension to ParaMor permanently 
removes schemes. To avoid introducing a free pa-
rameter, our extension to ParaMor flags a scheme 
as a likely boundary error only when virtually all 
of that scheme?s candidate stems end in the same 
character. We flag a scheme if its entropy is below 
a threshold set close to zero, 0.5. The baseline Pa-
raMor algorithm discards schemes which it be-
lieves hypothesize an incorrect stem-internal mor-
pheme boundary only after the scheme clustering 
step of ParaMor?s paradigm identification stage. 
Our extension follows suit: If we flag more than 
half of the schemes in a cluster as likely proposing 
a suffix-internal boundary, then we discard that 
cluster. Referencing Table 1, this first extension to 
ParaMor successfully removes both the 3rd and the 
12th selected schemes.  
Correcting Chance String Collision Errors 
Scheme errors due to chance string collisions are 
the second most prevalent error type. As described 
above, the string lengths of the candidate stems 
and suffixes of chance schemes are typically short. 
When the stems and suffixes of a scheme are short, 
then the underlying types which support a scheme 
are also short. Where the baseline ParaMor algo-
rithm explicitly builds schemes over all types in a 
corpus, we modify ParaMor to exclude short types 
from the vocabulary during morphology induction. 
Goldsmith (2006) also uses string-length thresh-
olds to restrict what paradigm models the Linguis-
tica algorithm produces. 
Excluding short types during ParaMor?s mor-
phology induction stage does not preclude short 
types from being analyzed as containing multiple 
morphemes during ParaMor?s segmentation stage. 
As section 2.2 describes, ParaMor?s segmentation 
algorithm is independent of the set of types from 
which schemes and scheme clusters are built. 
The string length that types must meet to join 
the induction vocabulary is a free parameter. Pa-
raMor is designed to identify the productive inflec-
tional paradigms of a language. Unless a paradigm 
is restricted to occur only with short stems, a pos-
sible but unusual scenario (as with the English ad-
jectival comparative, c.f. faster but *exquisiter) we 
can expect a productive paradigm to occur with a 
reasonable number of longer stems in a corpus. 
Hence, ParaMor needn?t be overly concerned 
about discarding short types. A qualitative exam-
ination of Spanish data suggested discarding types 
five characters or less in length; we use this cutoff 
in all experiments described in this paper. 
Excluding short types from the paradigm induc-
tion vocabulary virtually eliminates the entire cate-
gory of chance scheme. In a random sample of 100 
schemes that ParaMor selected when short types 
were excluded, only one scheme contained types 
related only by chance string similarity, down from 
35 when short types were not excluded. Returning 
to Table 1, excluding types five characters or less 
in length bars ten of the twelve word types which 
support the erroneous 3000th selected scheme ?.a.-
anar. Among the excluded types are valid Spanish 
words such as ganar ?to gain?. But also eliminated 
are several meaningless acronyms such as the sin-
gle letters g and s. Without these short types, Pa-
raMor rightly cannot select the 3000th scheme. 
2.2 Segmentation 
An Agglutinative Model 
With the improvement in scheme precision that re-
sults from the two extensions discussed in section 
2.1, we are ready to propose a more realistic model 
of morphology. ParaMor?s baseline segmentation 
algorithm distrusts ParaMor?s induced scheme 
models. The baseline algorithm assumes each word 
form can contain at most a single morpheme 
boundary. If it detects more than one morpheme 
53
boundary, then the baseline algorithm proposes a 
separate morphological analysis for each possible 
boundary. In contrast, our extended model of seg-
mentation vests more trust in the induced schemes, 
assuming that scheme clusters which propose dif-
ferent morpheme boundaries are simply modeling 
different valid morpheme boundaries. And our ex-
tension proposes a single morphological analysis 
containing all hypothesized morpheme boundaries.  
To detect morpheme boundaries, ParaMor 
matches each word, w, in the full vocabulary of a 
corpus against the clusters of schemes which are 
the final output of ParaMor?s paradigm identifica-
tion stage. When a suffix, f, of some scheme-
cluster, C, matches a word-final string of w, i.e. 
fuw .= , ParaMor attempts to replace f in turn with 
each suffix f ?  of C. If the string fu ?.  occurs in 
the full corpus vocabulary, then, on the basis of 
this paradigmatic evidence, ParaMor identifies a 
morpheme boundary in w between u and f . 
For example, to detect morpheme boundaries in 
the Spanish word apoyados ?supports (adjective 
masculine plural)?, ParaMor matches all word-
final strings of apoyados against the candidate suf-
fixes of ParaMor?s induced scheme clusters. The 
word-final strings of apoyados are s, os, dos, ados, 
yados, ?. The scheme clusters that our extended 
version of ParaMor induces include clusters which 
contain schemes very similar to the 1st, 2nd, and 5th 
baseline selected schemes, see Table 1. In particu-
lar, our extended ParaMor identifies separate 
scheme clusters that contain the candidate suffixes: 
s and ?; os and o; and ados and ado. Substituting 
? for s, o for os, or ado for ados yields the Spanish 
string apoyado ?supports (adjective masculine sin-
gular)?. It so happens, that apoyado does occur in 
our Spanish corpus, and so ParaMor has found 
paradigmatic evidence for three morpheme boun-
daries. Crucially, our ParaMor extension from sec-
tion 2.1 that removes schemes which hypothesize 
suffix internal morpheme boundaries correctly dis-
cards all schemes which contained the candidate 
suffix dos. Consequently, no scheme cluster exists 
to incorrectly suggest the morpheme boundary 
*apoya + dos, as the 3rd baseline selected scheme 
would have. Where ParaMor?s baseline segmenta-
tion algorithm would propose three separate analy-
ses of apoyados, one for each detected morpheme 
boundary: apoy +ados, apoyad +os, and apoyado 
+s; our extended segmentation algorithm produces 
the single correct analysis: apoy +ad +o +s.  
It is interesting to note that although each of Pa-
raMor?s individual paradigm models proposes a 
single morpheme boundary, our agglutinative seg-
mentation model can recover multiple boundaries 
in a single word. Using this idea it may be possible 
to quickly adapt Linguistica for agglutinative lan-
guages. Instead of interpreting the sets of stems 
and affixes that Goldsmith?s Linguistica algorithm 
produces as immediate segmentations of words, 
these signatures can be thought of as models of 
paradigms that may generalize to new words. 
Augmenting ParaMor?s Segmentations 
With its focus on the paradigm, ParaMor special-
izes at analyzing inflectional morphology (Monson 
et al, 2007a). Morpho Challenge 2007 requires al-
gorithms to analyze both inflectional and deriva-
tional morphology (Kurimo et al, 2007a; 2007b). 
To compete in the challenge, we combine Pa-
raMor?s morphological segmentations with seg-
mentations from Morfessor (Creutz, 2006), an un-
supervised morphology induction algorithm which 
learns both inflectional and derivational morphol-
ogy. We incorporate the segmentations from Mor-
fessor into the segmentations that the ParaMor sys-
tem produces by straightforwardly adding the Mor-
fessor segmentation for each word as an additional 
separate analysis to those ParaMor produces (Mon-
son et al, 2007b). Morfessor has one free parame-
ter, which we optimize separately for each lan-
guage of Morpho Challenge 2007.  
ParaMor also has several free parameters, in-
cluding the type length parameter and the parame-
ter over stem-final character entropy described in 
section 2.1. We do not adjust any of ParaMor?s pa-
rameters from language to language, but fix them 
at values that produce reasonable Spanish para-
digms and segmentations. As in Monson et al 
(2007b), to avoid adjusting ParaMor?s parameters 
we limit ParaMor?s paradigm induction vocabulary 
to 50,000 frequent types for each language.  
3 Evaluation 
To evaluate our extensions to the ParaMor algo-
rithm, we follow the methodology of the peer op-
erated Morpho Challenge 2007. All segmentations 
produced by our extensions were sent to the Mor-
pho Challenge Organizing Committee (Kurimo et 
al., 2008). The Organizing Committee evaluated 
our segmentations and returned the automatically 
54
calculated quantitative results. Using the evalua-
tion methodology of Morpho Challenge 2007 per-
mits us to compare our algorithms against the un-
supervised morphology induction systems which 
competed in the 2007 Challenge. Of the many al-
gorithms for unsupervised morphology induction 
discussed with the related work in section 1.1, five 
participated in Morpho Challenge 2007. Unless an 
algorithm has been given an explicit name, mor-
phology induction algorithms will be denoted in 
this paper by the name of their lead author. The 
five algorithms which participated in the 2007 
Challenge are: Bernhard (2007), Bordag (2007), 
Zeman (2007), Creutz?s (2006) Morfessor, and Pa-
raMor (2007b). 
Morpho Challenge 2007 had participating algo-
rithms analyze words in four languages: English, 
German, Finnish, and Turkish. The Challenge 
evaluated each algorithm?s morphological analyses 
in two ways. First, a linguistic evaluation measured 
each algorithm?s precision, recall, and F1 at mor-
pheme identification against an answer key of mor-
phologically analyzed word forms. Scores were 
normalized when a system proposed multiple 
analyses of a single word, as our combined Pa-
raMor-Morfessor submissions do. For further de-
tails on the linguistic evaluation in Morpho Chal-
lenge 2007, see Kurimo et al (2007a). The second 
evaluation of Morpho Challenge 2007 was a task 
based evaluation. Each algorithm?s analyses were 
imbedded in an information retrieval (IR) system. 
The IR evaluation consisted of queries over a lan-
guage specific collection of newswire articles. All 
word forms in all queries and all documents were 
replaced with the morphological decompositions of 
each individual analysis algorithm. Separate IR 
tasks were run for English, German, and Finnish, 
but not Turkish. For additional details on the IR 
evaluation of Morpho Challenge 2007 please refer-
ence Kurimo et al (2007b). 
Tables 2 and 3 present, respectively, the lin-
guistic and IR evaluation results. In these two ta-
bles, the top two rows contain results for segmen-
tations produced by versions of ParaMor that in-
clude our extensions. The topmost row in each ta-
ble, labeled ?+P +Seg?, gives the results for our 
fully augmented version of ParaMor, which in-
cludes our two extensions designed to improve 
precision as well as our new segmentation model 
which can propose multiple morpheme boundaries 
in a single analysis of a word form. The second 
row of each table, labeled ?+P ?Seg?, augments Pa-
raMor only with the two enhancements designed to 
improve precision. The third row of each table 
gives the Challenge results for the ParaMor base-
line algorithm. Rows four through seven of each 
table give scores from Morpho Challenge 2007 for 
the best performing unsupervised systems. If mul-
tiple versions of a single algorithm competed in the 
Challenge, the scores reported here are the highest 
F1 or Average Precision score of any algorithm 
variant at a particular task. In all test scenarios but 
Finnish IR, we produced Morfessor segmentations 
to augment ParaMor that are independent of the 
Morfessor runs which competed in Morpho Chal-
lenge. If our Morfessor runs gave a higher F1 or 
Average Precision, then we report this higher 
score. Finally, scores reported on rows eight and 
beyond are from reference algorithms that are not 
unsupervised. Reference algorithms appear in ital-
ics. A double line bisects both Table 2 and Table 3 
horizontally. All results which appear above the 
double line were evaluated after the final deadline 
of Morpho Challenge 2007. In particular, ParaMor 
officially competed only in the English and Ger-
man tracks of the Challenge.  
The Linguistic Evaluation 
Table 2 contains the results from the linguistic 
evaluation of Morpho Challenge. The Morpho 
Challenge Organizing Committee did not provide 
us with data on the statistical significance of the 
results for the enhanced versions of ParaMor. But 
most score differences are statistically signifi-
cant?All F1 differences of more than 0.5 between 
systems which officially competed in Morpho 
Challenge 2007 were statistically significant (Ku-
rimo et al, 2007a).  
In German, Finnish, and Turkish our fully en-
hanced version of ParaMor achieves a higher F1 
than any system that competed in Morpho Chal-
lenge 2007. In English, ParaMor?s precision score 
drags F1 under that of the first place system, Bern-
hard; In Finnish, the Bernhard system?s F1 is likely 
not statistically different from that of our system. 
Our final segmentation algorithm demonstrates 
consistent performance across all four languages. 
In Turkish, where the morpheme recall of other 
unsupervised systems is anomalously low, our al-
gorithm achieves a recall in a range similar to its 
recall scores for the other languages. ParaMor?s ul-
timate recall is double that of any other unsuper-
55
vised Turkish system, leading to an improvement 
in F1 over the next best system, Morfessor alone, 
of 13.5% absolute or 22.0% relative.  
In all four languages, as expected, the combina-
tion of removing short types from the training data, 
and the additional filtering of scheme clusters, 
?+P?, significantly improves precision scores over 
the ParaMor baseline. Allowing multiple mor-
pheme boundaries in a single word, ?+Seg?, in-
creases the number of words ParaMor believes 
share a morpheme. Some of these new words do in 
fact share a morpheme, some, in reality do not. 
Hence, our extension of ParaMor to agglutinative 
sequences of morphemes increases recall but low-
ers precision across all four languages. The effect 
of agglutinative segmentations on F1, however, dif-
fers with language. For the two languages which 
make limited use of suffix sequences, English and 
German, a model which hypothesizes multiple 
morpheme boundaries can only moderately in-
crease recall and does not justify, by F1, the many 
incorrect segmentations which result. On the other 
hand, an agglutinative model significantly im-
proves recall for true agglutinative languages like 
Finnish and Turkish, more than compensating in F1 
for the drop in precision over these languages. But 
in all four languages, the agglutinative version of 
ParaMor outperforms the baseline unenhanced ver-
sion at F1. 
The final row of Table 2 is the evaluation of a 
reference algorithm submitted by Tepper (2007). 
While not an unsupervised algorithm, Tepper?s 
reference parallels ParaMor in augmenting seg-
mentations produced by Morfessor. Where Pa-
raMor augments Morfessor with special attention 
to inflectional morphology, Tepper augments Mor-
fessor with hand crafted morphophonology rules 
that conflate multiple surface forms of the same 
underlying suffix. Like ParaMor, Tepper?s algo-
rithm significantly improves on Morfessor?s recall. 
With two examples of successful system augmen-
tation, we suggest that future research take a closer 
look at building on existing unsupervised mor-
phology induction systems. 
The IR Evaluation 
Turn now to results from the IR evaluation in Ta-
ble 3. Although ParaMor does not fair as well in 
Finnish, in German, the fully enhanced version of 
ParaMor places above the best system from the 
2007 Challenge, Bernhard, while our score on 
English rivals this same best system. Morpho Chal-
lenge 2007 did not measure the statistical signifi-
cance of uninterpolated average precision scores in 
the IR evaluation. It is not clear what feature of Pa-
raMor?s Finnish analyses causes comparatively 
low average precision. Perhaps it is simply that Pa-
raMor attains a lower morpheme recall over Fin-
nish than over English or German. And unfortu-
nately, Morpho Challenge 2007 did not run IR ex-
periments over the other agglutinative language in 
the competition, Turkish. When ParaMor does not 
combine multiple morpheme boundaries into a sin-
gle analysis, as in the baseline and ?+P ?Seg? sce-
Table 2. Unsupervised morphology induction systems evaluated for precision (P), recall (R), and F1 at morpheme 
identification using the methodology of the linguistic competition of Morpho Challenge 2007. 
English German Finnish Turkish 
 P R F1 P R F1 P R F1 P R F1 
 +P +Seg 50.6 63.3 56.3 49.5 59.5 54.1 49.8 47.3 48.5 51.9 52.1 52.0 
 +P ?Seg 56.2 60.9 58.5 57.4 53.5 55.4 60.5 33.9 43.5 62.0 38.2 47.3 
ParaMor  
&        
Morfessor 
Baseline 41.6 65.1 50.7 51.5 55.6 53.4 55.0 35.6 43.2 53.2 41.6 46.7 
Bernhard 61.6 60.0 60.8 49.1 57.4 52.9 59.7 40.4 48.2 73.7 14.8 24.7 
Bordag 59.7 32.1 41.8 60.5 41.6 49.3 71.3 24.4 36.4 81.3 17.6 28.9 
Morfessor 82.2 33.1 47.2 67.6 36.9 47.8 76.8 27.5 40.6 73.9 26.1 38.5 
Zeman 53.0 42.1 46.9 52.8 28.5 37.0 58.8 20.9 30.9 65.8 18.8 29.2 
Tepper 69.2 52.6 59.8 - - - 62.0 46.2 53.0 70.3 43.0 53.3 
 
56
narios, average precision is comparatively poor. 
Where the linguistic evaluation did not always pe-
nalize a system for proposing multiple partial 
analyses, real NLP applications, such as IR, can. 
The reference algorithms for the IR evaluation 
are: Dummy, no morphological analysis; Oracle, 
where all words in the queries and documents for 
which the linguistic answer key contains an entry 
are replaced with that answer; Porter, the standard 
English Porter stemmer; and Tepper described 
above. While the hand built Porter stemmer still 
outperforms the best unsupervised systems on Eng-
lish, these same best unsupervised systems outper-
form both the Dummy and Oracle references for all 
three evaluated languages?strong evidence that 
unsupervised induction algorithms are not only 
better than no morphological analysis, but that they 
are better than incomplete analysis as well.  
4 Conclusions and Future Directions 
Augmenting ParaMor with an agglutinative model 
of segmentation produces an unsupervised mor-
phology induction system with consistent and 
strong performance at morpheme identification 
across all four languages of Morpho Challenge 
2007. By first cleaning up the paradigm models 
that ParaMor learns, we raise ParaMor?s segmenta-
tion precision and allow the agglutinative model to 
significantly improve ParaMor?s morpheme recall.  
Looking forward to future improvements, we 
examined by hand the final set of scheme clusters 
that the current version of ParaMor produces over 
our newswire corpus of 50,000 Spanish types. Pa-
raMor?s paradigm identification stage outputs 41 
separate clusters. Among these final scheme clus-
ters are those which model all major productive 
paradigms of Spanish. In fact, there are often mul-
tiple scheme clusters which model portions of the 
same true paradigm. As an extreme case, 12 sepa-
rate scheme clusters contain suffixes from the 
Spanish ar verbal paradigm. Relaxing restrictions 
on ParaMor?s clustering algorithm (Monson et al, 
2007a) may address this paradigm fragmentation.  
The second significant shortcoming which sur-
faces among ParaMor?s 41 final scheme clusters is 
that ParaMor currently does not address morpho-
phonology. Among the final scheme clusters, 12 
attempt to model morphophonological change by 
incorporating the phonological change either into 
the stems or into the suffixes of the scheme cluster. 
But ParaMor currently has no mechanism for de-
tecting when a cluster is modeling morphophonol-
ogy. Perhaps ideas on morphophonology from 
Goldsmith (2006) could be adapted to work with 
the ParaMor algorithm. Finally, we plan to look at 
scaling the size of the vocabulary used both during 
paradigm induction and during morpheme segmen-
tation. We are particularly interested in the possi-
bility that ParaMor may  be able to identify para-
digms from much less data than 50,000 types. 
Acknowledgements 
We kindly thank Mikko Kurimo, Ville Turunen, 
Matti Varjokallio, and the full Organizing Com-
mittee of Morpho Challenge 2007, for running the 
evaluations of ParaMor. These dedicated workers 
produced impressively fast turn around for evalua-
tions on sometimes rather short notice. 
The research described in this paper was sup-
ported by NSF grants IIS-0121631 (AVENUE) and 
IIS-0534217 (LETRAS), with supplemental fund-
ing from NSF?s Office of Polar Programs and Of-
fice of International Science and Education. 
Table 3. Unsupervised morphology induction sys-
tems evaluated for uninterpolated average precision 
using the methodology of the IR competition of 
Morpho Challenge 2007. These results use Okapi 
term weighting (Kurimo et al, 2008b). 
*Only a subset of the words which occurred in the 
IR evaluation of this language was analyzed by this 
system.  
 Eng. Ger. Finn. Tur. 
 +P +Seg 39.3 48.4 42.6 - 
 +P ?Seg 35.1 43.1 37.1 - 
ParaMor 
&        
Morfessor 
Baseline 34.4 40.1 35.9 - 
Bernhard 39.4 47.3 49.2 - 
Bordag 34.0 43.1 43.1 - 
Morfessor 38.8 46.0 44.1 - 
Zeman  26.7*  25.7*  28.1* - 
Dummy 31.2 32.3 32.7 - 
Oracle 37.7 34.7 43.1 - 
Porter 40.8 - - - 
Tepper  37.3* - - - 
 
57
References 
Bernhard, Delphine. Simple Morpheme Labeling in Un-
supervised Morpheme Analysis. Working Notes for 
the CLEF 2007 Workshop. Budapest, Hungary, 2007. 
Bordag, Stefan. Unsupervised and Knowledge-free 
Morpheme Segmentation and Analysis. Working 
Notes for the CLEF 2007 Workshop. Budapest, Hun-
gary, 2007. 
Brent, Michael R., Sreerama K. Murthy, and Andrew 
Lundberg. Discovering Morphemic Suffixes: A Case 
Study in MDL Induction. The Fifth International 
Workshop on Artificial Intelligence and Statistics. 
Fort Lauderdale, Florida, 1995.  
Creutz, Mathias. Induction of the Morphology of Natu-
ral Language: Unsupervised Morpheme Segmenta-
tion with Application to Automatic Speech Recogni-
tion. Ph.D. Thesis. Computer and Information Sci-
ence, Report D13. Helsinki: University of Technol-
ogy, Espoo, Finland, 2006. 
Demberg, Vera, Helmut Schmid, and Gregor M?hler. 
Phonological Constraints and Morphological Pre-
processing for Grapheme-to-Phoneme Conversion. 
Association for Computational Linguistics. Prague, 
Czech Republic, 2007. 
Dryer, Matthew S. Prefixing vs. Suffixing in Inflec-
tional Morphology.  In The World Atlas of Language 
Structures. Eds. Martin Haspelmath, Matthew S. 
Dryer, David Gil, and Bernard Comrie. 2005. 
Goldsmith, John. Unsupervised Learning of the Mor-
phology of a Natural Language. Computational Lin-
guistics. 27.2:153-198. 2001. 
Goldsmith, John. An Algorithm for the Unsupervised 
Learning of Morphology. Natural Language Engi-
neering. 12.4:335-351. 2006. 
Goldsmith, John, and Yu Hu. From Signatures to Finite 
State Automata. Paper presented at the Midwest 
Computational Linguistics Colloquium. Blooming-
ton, Indiana, 2004. 
Goldwater, Sharon, and David McClosky. Improving 
Statistic MT through Morphological Analysis. Em-
pirical Methods in Natural Language Processing. 
Vancouver, Canada, 2005. 
Hafer, Margaret A. and Stephen F. Weiss. Word Seg-
mentation by Letter Successor Varieties. Information 
Storage and Retrieval, 10:371-385. 1974. 
Harris, Zellig. From Phoneme to Morpheme. Language 
31.2:190-222. 1955. Reprinted in Harris (1970). 
Harris, Zellig. Papers in Structural and Transforma-
tional Linguists. Ed. D. Reidel, Dordrecht. 1970. 
Johnson, Howard, and Joel Martin. Unsupervised 
Learning of Morphology for English and Inuktitut. 
Human Language Technology Conference / North 
American Chapter of the Association for Computa-
tional Linguistics. Edmonton, Canada, 2003. 
Kurimo, Mikko, Mathias Creutz, and Matti Varjokallio. 
Unsupervised Morpheme Analysis Evaluation by a 
Comparison to a Linguistic Gold Standard ? Morpho 
Challenge 2007. Working Notes for the CLEF 2007 
Workshop. Budapest, Hungary, 2007a. 
Kurimo, Mikko, Mathias Creutz, and Ville Turunen. 
Unsupervised Morpheme Analysis Evaluation by IR 
Experiments ? Morpho Challenge 2007. Working 
Notes for the CLEF 2007 Workshop. Budapest, Hun-
gary, 2007b. 
Kurimo, Mikko, Mathias Creutz, and Matti Varjokallio. 
Unsupervised Morpheme Analysis -- Morpho Chal-
lenge 2007. January 10, 2008. <http://www.cis.hut.-
fi/morphochallenge2007/>. 2008. 
Monson, Christian, Jaime Carbonell, Alon Lavie, and 
Lori Levin. ParaMor: Minimally Supervised Induc-
tion of Paradigm Structure and Morphological 
Analysis. Computing and Historical Phonology: The 
Ninth Meeting of the ACL Special Interest Group in 
Computational Morphology and Phonology. Prague, 
Czech Republic, 2007a. 
Monson, Christian, Jaime Carbonell, Alon Lavie, and 
Lori Levin. ParaMor: Finding Paradigms across 
Morphology. Working Notes for the CLEF 2007 
Workshop. Budapest, Hungary, 2007b. 
Schone, Patrick, and Daniel Jurafsky. Knowledge-Free 
Induction of Inflectional Morphologies. North 
American Chapter of the Association for Computa-
tional Linguistics. Pittsburgh, Pennsylvania, 2001. 
Snover, Matthew G. An Unsupervised Knowledge Free 
Algorithm for the Learning of Morphology in Natural 
Languages. M.S. Thesis. Computer Science, Sever 
Institute of Technology, Washington University, 
Saint Louis, Missouri, 2002. 
Tepper, Michael A. Using Hand-Written Rewrite Rules 
to Induce Underlying Morphology. Working Notes 
for the CLEF 2007 Workshop. Budapest, Hungary, 
2007. 
Wicentowski, Richard. Modeling and Learning Multi-
lingual Inflectional Morphology in a Minimally Su-
pervised Framework. Ph.D. Thesis. Johns Hopkins 
University, Baltimore, Maryland, 2002. 
Zeman, Daniel. Unsupervised Acquiring of Morpho-
logical Paradigms from Tokenized Text. Working 
Notes for the CLEF 2007 Workshop. Budapest, Hun-
gary, 2007. 
 
 
58
Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 1029?1037,
Beijing, August 2010
EMMA: A Novel Evaluation Metric for Morphological Analysis
Sebastian Spiegler
Intelligent Systems Group
University of Bristol
spiegler@cs.bris.ac.uk
Christian Monson
Center for Spoken Language Understanding
Oregon Health & Science University
monsonc@csee.ogi.edu
Abstract
We present a novel Evaluation Metric
for Morphological Analysis (EMMA)
that is both linguistically appealing and
empirically sound. EMMA uses a graph-
based assignment algorithm, optimized
via integer linear programming, to match
morphemes of predicted word analyses
to the analyses of a morphologically rich
answer key. This is necessary especially
for unsupervised morphology analysis
systems which do not have access to
linguistically motivated morpheme labels.
Across 3 languages, EMMA scores of
14 systems have a substantially greater
positive correlation with mean average
precision in an information retrieval
(IR) task than do scores from the metric
currently used by the Morpho Challenge
(MC) competition series. We compute
EMMA and MC metric scores for 93
separate system-language pairs from
the 2007, 2008, and 2009 MC compe-
titions, demonstrating that EMMA is
not susceptible to two types of gaming
that have plagued recent MC competi-
tions: Ambiguity Hijacking and Shared
Morpheme Padding. The EMMA eval-
uation script is publicly available from
http://www.cs.bris.ac.uk/
Research/MachineLearning/
Morphology/Resources/.
1 Introduction
Words in natural language are constructed from
smaller building blocks called morphemes. For
example, the word wives breaks down into an un-
derlying stem, wife, together with a plural suffix.
Analyzing the morphological structure of words
is known to benefit a variety of downstream nat-
ural language (NL) tasks such as speech recogni-
tion (Creutz, 2006; Ar?soy et al, 2009), machine
translation (Oflazer et al, 2007), and information
retrieval (McNamee et al, 2008).
A variety of automatic systems can morpholog-
ically analyze words that have been removed from
their surrounding context. These systems range
from hand-built finite state approaches (Beesley
and Karttunen, 2003) to recently proposed algo-
rithms which learn morphological structure in an
unsupervised fashion (Kurimo et al, 2007). Since
unsupervised systems do not have access to lin-
guistically motivated morpheme labels, they typ-
ically produce morphological analyses that are
closely related to the written form. Such a system
might decompose wives as wiv -es. Meanwhile,
a hand-built system might propose wife_N +Plu-
ral, or even parse wives as a hierarchical feature
structure. As morphological analysis systems pro-
duce such varied outputs, comparing decomposi-
tions from disparate systems is a challenge.
This paper describes EMMA, an Evaluation
Metric for Morphological Analysis that quantita-
tively measures the quality of a set of morpholog-
ical analyses in a linguistically adequate, empir-
ically useful, and novel fashion. EMMA evalu-
ates analyses that can be represented as a flat set
of symbolic features, including hierarchical repre-
sentations, which can be projected down to a lin-
earized form (Roark and Sproat, 2007).
An automatic metric that discriminates be-
tween proposed morphological analyses should
1029
fulfill certain computational and linguistic crite-
ria. Computationally, the metric should:
1. Correlate with the performance of real-world
NL processing tasks which embed the morpho-
logical analyses.
2. Be Readily Computable: The metric will only
be useful if it is less time consuming and easier
to compute than the larger NL task.
3. Be Robust: The metric should be difficult to
game and should accurately reflect the distri-
bution of predicted and true morphemes.
4. Be Readily Interpretable: When possible, the
final numeric score should directly identify the
strengths and weaknesses of the underlying
morphological analysis system.
While accounting for these computational re-
quirements, a morphology metric should still re-
ward accurate models of linguistic structure. In
particular, the metric should account for:
1. Morphophonology: Applying a morphological
rule may alter the surface form of stem or af-
fix. In the word wives, /waivz/, a rule of mor-
phophonology voices the stem-final /f/ of wife,
/waif/, when the plural suffix is added. A met-
ric should penalize for not placing wives and
wife as forms of the same lexeme.
2. Allomorphy: A metric should capture the suc-
cessful grouping of allomorphs. The German
plural has several surface allomorphs includ-
ing -en in Zeiten (times), -e in Hunde (dogs),
and -s in Autos (cars). A metric should reward
a morphological analysis system that analyzes
the different surface forms of the German plu-
ral as underlyingly identical.
3. Syncretism: In mirror fashion, a metric
should reward analyses that distinguish be-
tween surface-identical syncretic morphemes:
although derives and derivations both contain
an -s morpheme, one marks 3rd person singular
and the other plural.
4. Ambiguity: Finally, a metric should account
for legitimate morphological ambiguity. In He-
brew, the written word MHGR has three vi-
able morphological segmentations: M- H- GR,
?from the foreigner?, M- HGR, ?from Hagar?,
and the unsegmented form MHGR, meaning
?immigrant? (Lavie et al, 2004). Absent dis-
ambiguating context, a morphological system
should be rewarded for calling out all three
analyses for MHGR.
Morphophonology, allomorphy, syncretism,
and ambiguity are all common phenomena in the
world?s languages. The first three have all re-
ceived much discussion in theoretical linguistics
(Spencer and Zwicky, 2001), while morpholog-
ical ambiguity has significant practical implica-
tions in NL processing, e.g. in machine translation
of morphologically complex languages (Lavie et
al., 2004; Oflazer et al, 2007).
In Section 2 we propose the metric EMMA,
which has been specifically designed to evalu-
ate morphological analyses according to our com-
putational and linguistic criteria. Section 3 then
describes and qualitatively critiques several well-
used alternative metrics. Section 4 empirically
compares EMMA against the qualitatively-strong
metric used in the Morpho Challenge competition
series (Kurimo et al, 2009). And we conclude in
Section 5.
2 EMMA: An Evaluation Metric for
Morphological Analysis
EMMA, the metric we propose for the evalua-
tion of morphological analyses, like all the met-
rics that we consider in this paper, compares pro-
posed morphological analyses against an answer
key of definitively-analyzed words from a vocab-
ulary. Since a set of proposed analyses is likely
to use a different labeling scheme than the answer
key, especially true of the output from unsuper-
vised systems, EMMA does not perform a direct
comparison among proposed and answer analy-
ses. Instead, EMMA seeks a one-to-one relabel-
ing of the proposed morphemes that renders them
as similar as possible to the answer key. EMMA,
then, measures the degree to which proposed anal-
yses approximate an isomorphism of the answer
key analyses. For exposition, we initially assume
that, for each word, a single proposed analysis
is scored against a single unambiguous answer
analysis. We relax this restriction in Section 2.3,
where EMMA scores multiple proposed analyses
1030
against a set of legitimately ambiguous morpho-
logical analyses.
To find the most appropriate one-to-one mor-
pheme relabeling, EMMA turns to a standard al-
gorithm from graph theory: optimal maximum
matching in a bipartite graph. A bipartite graph,
G = {X,Y ;E}, consists of two disjoint sets
of vertices, X = {x1, x2, . . . , xn} and Y = {y1,
y2, . . . , ym}, and a set of edges e(xi, yj) ? E
such that each edge has one end in X and the other
end in Y . In EMMA, the set, A, of all unique mor-
phemes in the answer key and the set, P , of all
unique morphemes in the proposed analyses serve
as the disjoint vertex sets of a bipartite graph.
A matching M ? E in a bipartite graph is de-
fined as a set of edges e(xi, yj) such that no xi
or yj is repeated. A maximum matching is a
matching where no M ? with |M ?| > |M | exists.
Furthermore, a weight w(xi, yj) ? < may be as-
signed to each edge e(xi, yj) of a bipartite graph.
An optimal assignment is a maximum matching
which also maximizes the sum of the weights of
the edges of the matching
?
e(xi,yj)?M
w(xi, yj) .
EMMA weights the edge between a particular
answer morpheme a ? A and a proposed mor-
pheme p ? P as the number of words, w, in the
vocabulary, V , where the answer analysis of w in-
cludes morpheme a while the proposed analysis
includes p. EMMA constructs an optimal assign-
ment maximum matching in this weighted bipar-
tite morpheme graph. The edge weights ensure
that the optimal matching will link the answer and
proposed morphemes which globally occur in the
analyses of the same words most often ? restrict-
ing each answer morpheme to be represented by at
most one proposed morpheme, and each proposed
morpheme to represent at most one morpheme in
the answer key. On the one hand, the restrictions
thus imposed by bipartite matching penalize sets
of proposed analyses that do not differentiate be-
tween surface-identical syncretic morphemes. On
the other hand, the same one-to-one matching re-
strictions penalize proposed analyses that do not
conflate allomorphs of the same underlying mor-
pheme, whether those allomorphs are phonologi-
cally induced or not. Thus, EMMA meets our lin-
guistic criteria from Section 1 of modeling syn-
cretism, allomorphy, and morphophonology.
2.1 Maximum Matching by Integer Linear
Programming
To construct the maximum matching optimal as-
signment of answer and proposed morphemes,
EMMA uses standard integer linear programming
techniques as implemented in lpsolve (Berkelaar
et al, 2004). For the purpose of our integer pro-
gram, we represent the weight of each potential
edge of the optimal bipartite morpheme assign-
ment in a count matrix C = {cij} where cij is as-
signed the number of words w ? V which share
morpheme ai in the answer key and pj in the pre-
diction. We then define a binary matrix B = {bij}
of the same dimensions as C. Each bij will be set
to 1 if an edge exists from ai to pj in the optimal
maximum matching, with bij = 0 otherwise. The
integer linear program can then be defined as fol-
lows:
argmax
B
?
i,j
(C ?B)ij (1)
s.t.
?
i
bij ? 1 ,
?
j
bij ? 1 , bij ? 0 ,
where (C ? B)ij = cij ? bij is the element-wise
Hadamard product.
2.2 Performance Measures
Having settled on a maximum matching optimal
assignment of proposed and answer morphemes,
EMMA derives a final numeric score. Let wk
be the kth word of V ; and let Ak and Pk de-
note, respectively, the sets of morphemes in the
answer key analysis of wk and predicted analysis
of wk. Furthermore, let P ?k denote the predicted
morphemes for wk where a morpheme pj is re-
placed by ai if bij = 1. Now that Ak and P ?k
contain morpheme labels that are directly compa-
rable, we can define precision and recall scores
for the proposed analysis of the word wk. Preci-
sion is the fraction of correctly relabeled proposed
morphemes from among all proposed morphemes
of wk; while recall is the number of correctly rela-
beled morphemes as a fraction of the answer key
1031
analysis of wk. Precision and recall of the full vo-
cabulary are the average word-level precision and
recall:
precision = 1|V |
|V |?
k
|Ak
?
P ?k |
|P ?k |
, (2)
recall = 1|V |
|V |?
k
|Ak
?
P ?k |
|Ak|
. (3)
Finally, f-measure is the harmonic mean of pre-
cision and recall:
f -measure = 2 ? precision ? recallprecision+ recall . (4)
2.3 Morphological Ambiguity in EMMA
Thus far we have presented EMMA for the sce-
nario where each word has a single morphological
analysis. But, as we saw in Section 1 with the He-
brew word MHGR, natural language permits sur-
face forms to have multiple legitimate morpho-
logical analyses. When a word is truly ambigu-
ous, EMMA expects an answer key to contain a
set of analyses for that word. Similarly, we per-
mit sets of proposed alternative analyses. To ex-
tend EMMA with the ability to evaluate alterna-
tive analyses we first generalize the optimal max-
imum matching of morphemes from Section 2.1.
We then define a new integer linear program to
match answer and proposed alternative analyses.
Finally, we adjust the performance measures of
Section 2.2 to account for alternatives.
2.3.1 Ambiguity and Morpheme Matching
Let Ak,r denote the rth alternative answer anal-
ysis of the kth word with 1 ? r ? mk, and let
Pk,s denote the sth alternative prediction with
1 ? s ? nk, where mk is the number of alterna-
tive analyses in the answer key and nk the num-
ber of alternative predictions for wk. We redefine
Ak =
?mk
r Ak,r and Pk =
?nk
s Pk,s as the set of
all answer or, respectively, predicted morphemes
of wk across all analysis alternatives. Instead of
incrementing each cij entry in the count matrix
C by a full count, we now add 1mk?nk to cij forall pairs (ai, pj) ? Ak ? Pk. This corresponds to
counting each combination of an answer key and
predicted morpheme normalized by the number of
possible pairings between proposed and answer
analysis alternatives. When both the answer and
proposed analyses consist of just a single alter-
native, cij remains unchanged. Generalized mor-
pheme matching still employs the linear program
defined in Equation 1.
2.3.2 Matching of Alternative Analyses
After performing a one-to-one morpheme rela-
belling that accounts for ambiguity, we need to
extend EMMA with the ability to evaluate alterna-
tive analyses. We again turn to optimal maximum
matching in a bipartite graph: Where earlier we
matched proposed and answer morphemes, now
we match full proposed and answer analysis alter-
natives, maximizing the total number of correctly
predicted morphemes across all alternatives. Gen-
eralizing on the notation of the unambiguous case,
let P ?k,s denote the sth alternative predicted analy-
sis of the kth word where predicted morphemes
have been replaced by their assigned answer key
morphemes. We introduce a new count matrix
C ? = {c?r,s}, where c?r,s is the count of common
morphemes of the rth answer key alternative and
sth predicted alternative. Based on Equation 1,
we calculate the binary matrix B? = {b?r,s} which
contains the optimal assignment of the alternative
answer key and predicted analyses for wk.
2.3.3 Ambiguity and Performance Scores
We now adjust EMMA?s numeric performance
measures to account for sets of ambiguous anal-
ysis alternatives. Precision becomes
1
|V |
|V |?
k
1
nk
mk?
r
nk?
s
b?r,s
|Ak,r
?
P ?k,s|
|P ?k,s|
, (5)
the ratio of correctly predicted morphemes across
all predicted alternatives normalised by the num-
ber of predicted alternatives, nk, and the vocab-
ulary size, |V |. The factor b?r,s guarantees that
scores are only averaged over pairs of proposed
and answer analysis alternatives that have been as-
signed, that is, where b?r,s = 1. Recall is measured
similarly with
1
|V |
|V |?
k
1
mk
mk?
r
nk?
s
b?r,s
|Ak,r
?
P ?k,s|
|Ak,r|
. (6)
1032
Here, we normalize by mk, the number of alterna-
tive analyses for the kth word that are listed in the
answer key. The normalisation factors 1mk and 1nkensure that predicting too few or many alternative
analyses is penalised.
3 Other Morphology Metrics
Having presented the EMMA metric for evaluat-
ing the quality of a set of morphological analyses,
we take a step back and examine other metrics that
have been proposed. Morphology analysis metrics
can be categorized as either: 1. Directly compar-
ing proposed analyses against an answer key, or 2.
Indirectly comparing proposed and answer analy-
ses by measuring the strength of an isomorphic-
like relationship between the proposed and answer
morphemes. The proposed EMMA metric belongs
to the second category of isomorphism-based met-
rics.
3.1 Metrics of Direct Inspection
By Segmentation Point. Perhaps the most read-
ily accessible automatic evaluation metric is a di-
rect comparison of the morpheme boundary posi-
tions in proposed and answer analyses. As early
as 1974, Hafer and Weiss used the direct boundary
metric. Although intuitively simple, the segmen-
tation point method implicitly assumes that it is
possible to arrive at a valid morphological anal-
ysis by merely dividing the characters of a word
into letter sequences that can be reconcatenated to
form the original word. But, by definition, con-
catenation cannot describe non-contanative pro-
cesses like morphophonology and allomorphy.
Nor does simple segmentation adequately differ-
entiate between surface-identical syncretic mor-
phemes. Despite these drawbacks, precision and
recall of segmentation points is still used in cur-
rent morphological analysis research (Poon et al
(2009), Snyder and Barzilay (2008), Kurimo et al
(2006)).
Against Full Analyses. To confront the reality
of non-concatenative morphological processes, an
answer key can hold full morphological analyses
(as opposed to merely segmented surface forms).
But while a hand-built (Beesley and Karttunen,
2003) or supervised (Wicentowski , 2002) mor-
phology analysis system can directly model the
annotation standards of a particular morphologi-
cal answer key, the label given to specific mor-
phemes is ultimately an arbitrary choice that an
unsupervised morphology induction system has
no way to discover.
By Hand. On the surface, scoring proposed
analyses by hand appears to provide a way to eval-
uate the output of an unsupervised morphology
analysis system. Hand evaluation, however, does
not meet our criteria from Section 1 for a robust
and readily computable metric. It is time consum-
ing and, as Goldsmith (2001) explains, leaves dif-
ficult decisions of what constitutes a morpheme to
on-the-fly subjective opinion.
3.2 Metrics of Isomorphic Analysis
Recognizing the drawbacks of direct evaluation,
Schone and Jurafsky (2001), Snover et al (2002),
and Kurimo et al (2007) propose related measures
of morphological analysis quality that are based
on the idea of an isomorphism. For reasons that
will be clear momentarily, we refer to the Schone
and Jurafsky, Snover et al, and Kurimo et al met-
rics as soft isomorphic measures. As discussed
in Section 2, metrics of isomorphism measure
similarities between the distribution of proposed
morphemes and the distribution of answer mor-
phemes, where proposed and answer morphemes
may be disjoint symbol sets.
Unlike the EMMA metric proposed in Section
2, the soft metrics of isomorphism do not seek
to explicitly link proposed morphemes to answer
morphemes. Instead, their metrics group sets or
pairs of words which share, in either the pro-
posed analyses or in the answer analyses, a stem
(Schone and Jurafsky, 2001; Snover, 2002), a suf-
fix (Snover et al, 2002), or any arbitrary mor-
pheme (Kurimo et al, 2007). The soft met-
rics subsequently note whether these same sets or
pairs of words share any morpheme in the answer
key or, respectively, in the proposed analyses. By
foregoing a hard morpheme assignment, the soft
metrics do not adequately punish sets of proposed
and answer morphemes which fail to model syn-
cretism and/or allomorphy. For example, pro-
posed analyses that annotate 3rd person singular
and plural with a single undifferentiated +s mor-
pheme will receive recall credit for both nouns and
1033
verbs.
3.3 The Morpho Challenge Metric
The Morpho Challenge (MC) competition series
for unsupervised morphology analysis algorithms
(Kurimo et al, 2009) has used a soft metric of iso-
morphism in its most recent three years of compe-
tition: 2007, 2008, and 2009. According to Ku-
rimo et al (2009) the Morpho Challenge (MC)
measure samples random word pairs which share
at least one common morpheme. Precision is cal-
culated by generating random word pairs from
the set of proposed analyses and then compar-
ing the analyses of the word pairs in the answer
key. The fraction of found and expected common
morphemes is normalised by the number of words
which are evaluated. Recall is defined in mirror
fashion. The MC metric also normalizes preci-
sion and recall scores across sets of alternative
analyses for each word in the proposal and answer
key. To our knowledge the MC metric is the first
isomorphism-based metric to attempt to account
for morphological ambiguity. As we show in Sec-
tion 4, however, MC?s handling of ambiguity is
easily gamed.
The MC metric does meet our criterion of being
readily computable and, as we will show in the ex-
perimental section, the metric also correlates to a
certain extent with performance on a higher-level
natural language processing task. The downside
of the MC metric, however, is robustness. In addi-
tion to MC?s crude handling of ambiguity and its
over-counting of allomorphs and syncretic mor-
phemes, the random pair sampling method that
MC uses is not independent of the set of analyses
being evaluated. If two algorithms predict differ-
ent morpheme distributions, the sampling method
will find different numbers of word pairs. We sub-
stantiate our claim that the MC metric lacks ro-
bustness in Section 4 where we empirically com-
pare it to the EMMA metric.
4 Experimental Evaluation
To experimentally evaluate our newly proposed
EMMA metric, and to quantitatively compare the
EMMA and MC metrics, we have evaluated re-
sults of 93 system-language pairs from Morpho
Challenge 2007, 2008, and 2009.1 The evaluation
comprised three algorithms by Bernhard (2007)
and Bernhard (2009), one algorithm by Can and
Manandhar (2009), the MC baseline algorithm
Morfessor by Creutz (2006), UNGRADE by Gole-
nia et al (2009), two algorithms by Lavallee and
Langlais (2009), one algorithm by Lignos et al
(2009), five ParaMor versions by Monson et al
(2008) and Monson et al (2009), three Promodes
versions by Spiegler et al (2009) and one al-
gorithm by Tchoukalov et al (2009). We ran
these algorithms over six data sets available from
the MC competition: Arabic (vowelized and non-
vowelized), English, Finnish, German, and Turk-
ish. We then scored the system outputs using both
EMMA and the MC metric against an answer key
provided by MC. In Sections 2 and 3.3 we have al-
ready commented on the linguistic characteristics
of both metrics. In this section, we concentrate on
their computational performance.
Both the EMMA and MC metrics are readily
computable: Both are freely available2 and they
each take less than two minutes to run on the av-
erage desktop machines we have used. In terms
of interpretability, EMMA not only returns the
performance as precision, recall and f-measure
as MC does, but also provides predicted analy-
ses where mapped morphemes are replaced by an-
swer key morphemes. This information is help-
ful when judging results qualitatively since it ex-
poses tangible algorithmic characteristics. In Ta-
ble 1 we present the algorithms with the highest
MC and EMMA scores for each language. For
all languages, the EMMA and MC metrics place
different algorithms highest. One reason for the
significantly different rankings that the two met-
rics provide may be the sampling of random pairs
that MC uses. Depending on the distribution of
predicted morphemes across words, the number
of random pairs, which is used for calculating the
precision, may vary. For instance, on vowelized
Arabic, Promodes 1 is evaluated over a sample
of 100 pairs where MC selected just 47 pairs for
ParaMor Mimic.
1Detailed results can be found in Spiegler (2010).
2EMMA may be downloaded from http://www.
cs.bris.ac.uk/Research/MachineLearning/
Morphology/Resources/
1034
Language Algorithm and year of MC evaluation metric EMMA evaluation metric
participation in MC Pr. Re. F1 Pr. Re. F1
Arabic (nv) Promodes 2 2009 0.7789 0.3980 0.5268 0.5356 0.2444 0.3356
Ungrade 2009 0.7971 0.1603 0.2670 0.7017 0.2490 0.3675
Arabic (vw) Promodes 2 2009 0.5946 0.6017 0.5982 0.4051 0.3199 0.3575
Promodes 1 2009 0.7381 0.3477 0.4727 0.5588 0.3281 0.4135
English Bernhard 1 2007 0.7850 0.5763 0.6647 0.8029 0.7460 0.7734
Lignos 2009 0.7446 0.4716 0.5775 0.9146 0.6747 0.7766
Finnish ParaMorPlusMorfessor 2008 0.5928 0.5675 0.5798 0.2271 0.3428 0.2732
Lavallee rali-cof 2009 0.6731 0.3563 0.4659 0.5061 0.4065 0.4509
German ParaMorPlusMorfessor 2008 0.5562 0.6077 0.5808 0.3633 0.4948 0.4190
Morfessor 2009 0.6528 0.3818 0.4818 0.7311 0.5556 0.6314
Turkish ParaMorPlusMorfessor 2008 0.6779 0.5732 0.6212 0.3476 0.4315 0.3851
Morfessor 2009 0.7894 0.3330 0.4684 0.5901 0.3703 0.4550
Table 1: Best performing algorithms with MC and EMMA evaluation metric.
Algorithm and year of MC evaluation metric EMMA evaluation metric
participation in MC Pr. Re. F1 Pr. Re. F1
Morfessor 2009 0.8143 0.2788 0.4154 0.4751 0.3472 0.4012
ParaMor 2008 0.4111 0.4337 0.4221 0.4322 0.3770 0.4027
ParaMorPlusMorfessor 2008 0.5928 0.5675 0.5798 0.2271 0.3428 0.2732
Paramor Morfessor Union 2009 0.4374 0.5676 0.4941 0.3878 0.4530 0.4178
Table 3: Gaming MC with ambiguity hijacking on Finnish.
Looking at any particular algorithm-language
pair, the EMMA and MC scores differ consider-
ably and respective raw scores are not directly
comparable. More interesting is the extent to
which both metrics correlate with real NL tasks.
Table 2 lists the Spearman rank correlation co-
efficient for algorithms from MC 2009 on En-
glish, Finnish and German comparing rankings of
f-measure results returned by either MC or EMMA
against rankings using the mean average preci-
sion (MAP) of an information retrieval (IR) task.3
All MAP scores are taken from Kurimo et al
(2009). Although both metrics positively correlate
with the IR results; EMMA?s correlation is clearly
stronger across all three languages.
To test the robustness of the EMMA and MC
metrics, we performed two experiments where we
intentionally attempt to game the metrics ? ambi-
guity hijacking and shared morpheme padding. In
both experiments, the MC metric showed vulnera-
bility. Ambiguity hijacking results for Finnish ap-
3Detailed results can be found in Spiegler (2010).
pear in Table 3, other languages perform similarly.
Using both metrics, we scored the Finnish analy-
ses that were proposed by a) the Morfessor algo-
rithm alone, b) ParaMor alone, and c) two ways
of combining ParaMor and Morfessor: ParaMor-
PlusMorfessor simply lists the ParaMor and Mor-
fessor analyses as alternatives ? as if each word
were ambiguous between a ParaMor and a Mor-
fessor analysis; ParaMorMorfessorUnion, on the
other hand, combines the morpheme boundary
predictions of ParaMor and Morfessor into a sin-
gle analysis. The ParaMorPlusMorfessor system
games the ambiguity mechanism of the MC met-
ric, achieving an f-measure higher than that of any
of the three other algorithms. EMMA, however,
correctly discovers that the analyses proposed by
ParaMorPlusMorfessor lie farther from an iso-
morphism to the the answer key than do the uni-
fied analyses of ParaMorMorfessorUnion.
In Table 4 we show a second way of gaming
the MC metric ? shared morpheme padding. We
add the same unique bogus morpheme to each
proposed analysis of every word for all systems.
1035
Language MC evaluation EMMA evaluationPrecision Recall F-measure Precision Recall F-measure
Arabic (nv) 0.91?0.02 10.83? 8.33 7.20?5.10 0.91?0.05 1.30?0.07 1.20?0.05
Arabic (vw) 0.85?0.04 11.17?8.81 7.13?5.23 0.89?0.07 1.21?0.06 1.12?0.05
English 0.36?0.08 2.02?0.66 0.63?0.10 0.73?0.15 1.05?0.08 0.86?0.12
Finnish 0.57?0.08 3.07?2.47 1.19?0.68 0.87?0.19 1.12?0.10 0.99?0.14
German 0.43?0.08 2.90?1.45 0.84?0.16 0.80?0.17 1.09?0.08 0.94?0.11
Turkish 0.58?0.09 2.95?1.65 1.19?0.37 0.85?0.08 1.07?0.04 0.97?0.05
Table 4: Gaming MC with shared morpheme padding: Average and standard deviations of the ratio of
padded to original scores.
Padding analyses with a shared morpheme signif-
icantly increases the recall scores of the MC met-
ric. We summarize our experimental results by
calculating, for each language-algorithm pair, the
ratio of the score for the padded analyses as com-
pared to that of the original, unpadded analyses.
Table 4 reports average and standard deviation of
the ratios across all systems for each language. In
Arabic (nv. and vw.), the recall increases by 10.83
and 11.17 times, which leads to an inflation of f-
measure by 7.20 and 7.13 times ? this is a direct
result of the soft nature of the MC isomorphism.
In contrast, EMMA?s recall scores increase much
less than MC?s do, and EMMA?s precision scores
decrease proportionately. A small change to the
set of proposed analyses does not lead to a huge
difference in f-measure ? characteristic of a more
robust metric.
5 Conclusion
This paper has proposed, EMMA, a novel evalua-
tion metric for the assessment of the quality of a
set of morphological analyses. EMMA?s:
1. Coverage of the major morphological phenom-
ena,
Correlation with IR
IR vs. MC IR vs. EMMA
English 0.466 0.608
Finnish 0.681 0.759
German 0.379 0.637
Table 2: Spearman rank correlation coefficient of
metrics vs. Information Retrieval (IR).
2. Correlation with performance on natural lan-
guage processing tasks, and
3. Computational robustness
all recommend the the metric as a strong and use-
ful measure ? particularly when evaluating un-
supervised morphology analysis systems which,
lacking access to labeled training data, are unin-
formed of the labeling standard used in the answer
key.
Acknowledgements
We would like to acknowledge various fruitful
discussions with Aram Harrow, Alex Popa, Tilo
Burghardt and Peter Flach. The work was par-
tially sponsored by EPSRC grant EP/E010857/1
Learning the morphology of complex synthetic
languages, as well as by NSF Grant #IIS-0811745
and DOD/NGIA grant #HM1582-08-1-0038.
References
Ar?soy, Ebru, Dog?an Can, S?dd?ka Parlak, Has?im Sak,
and Murat Sara?lar. 2009. Turkish Broadcast News
Transcription and Retrieval. IEEE Trans. on Audio,
Speech and Lang. Proc.
Beesley, Kenneth R. and Lauri Karttunen. 2003.
Finite State Morphology. University of Chicago
Press.
Berkelaar, Michel, Kjell Eikland, and Peter Note-
baert. 2004. Open source (mixed-integer) lin-
ear programming system, version 5.1.0.0. http:
//lpsolve. sourceforge.net/.
Bernhard, Delphine. 2007. Simple morpheme la-
belling in unsupervised morpheme analysis. Work-
ing Notes, CLEF 2007 Workshop.
1036
Bernhard, Delphine. 2009. Morphonet: Exploring the
use of community structure for unsupervised mor-
pheme analysis. Working Notes, CLEF 2009 Work-
shop.
Can, Burcu and Suresh Manandhar. 2009. Unsuper-
vised learning of morphology by using syntactic cat-
egories. Working Notes, CLEF 2009 Workshop.
Creutz, Mathias. 2006. Induction of the Morphol-
ogy of Natural Language: Unsupervised Morpheme
Segmentation with Application to Automatic Speech
Recognition. Ph.D. thesis, Helsinki University of
Technology, Espoo, Finland.
Goldsmith, John. 2001. Unsupervised learning of the
morphology of a natural language. Comp. Ling., 27.
Gol?nia, Bruno, Sebastian Spiegler, and Peter Flach.
2009. Ungrade: unsupervised graph decomposi-
tion. Working Notes, CLEF 2009 Workshop.
Hafer, M. A. and S. F. Weiss. 1974. Word segmenta-
tion by letter successor varieties. Inf. Storage and
Retrieval, 10.
Kurimo, Mikko, Mathias Creutz, Matti Varjokallio,
Ebru Arisoy, Murat Saraclar. 2006. Unsupervised
segmentation of words into morphemes - Morpho
Challenge 2005. Interspeech.
Kurimo, Mikko, Mathias Creutz, and Ville Turunen.
2007. Overview of morpho challenge in CLEF
2007. Working Notes, CLEF 2007 Workshop.
Kurimo, Mikko and Ville Turunen. 2008. Unsuper-
vised Morpheme Analysis Evaluation by IR exper-
iments ? Morpho Challenge 2008. Working Notes,
CLEF 2008 Workshop.
Kurimo, Mikko, Sami Virpioja, and Ville T. Turunen.
2009. Overview and results of morpho challenge
2009. Working Notes, CLEF 2009 Workshop.
Lavallee, Jean-Francois and Philippe Langlais. 2009.
Morphological Acquisition by Formal Analogy.
Working Notes, CLEF 2009 Workshop.
Lavie, Alon, Erik Peterson, Katharina Probst, Shuly
Wintner, Yaniv Eytani. 2004. Rapid Prototyp-
ing of a Transfer-based Hebrew-to-English Machine
Translation System. Proc. of TMI-2004.
Lignos, Constantine, Erwin Chan, Mitchell P. Mar-
cus, and Charles Yang. 2009. A rule-based unsu-
pervised morphology learning framework. Working
Notes, CLEF 2009 Workshop.
McNamee, Paul, Charles Nicholas, and James May-
field. 2008. Don?t Have a Stemmer? Be Un+con-
cern+ed Proc. of the 31st Anual International ACM
SIGIR Conference 20-24 July 2008.
Monson, Christian, Jaime Carbonell, Alon Lavie, and
Lori Levin. 2008. Paramor and morpho challenge
2008. Working Notes, CLEF 2008 Workshop.
Monson, Christian, Kristy Hollingshead, and Brian
Roark. 2009. Probabilistic paramor. Working
Notes, CLEF 2009 Workshop.
Oflazer, Kemal, and I?lknur Durgar El-Kahlout. 2007.
Different Representational Units in English-to-
Turkish Statistical Machine Translation. Proc. of
Statistical Machine Translation Workshop at ACL
2007.
Poon, Hoifung, Colin Cherry and Kristina Toutanova
2009. Unsupervised Morphological Segmentation
with Log-Linear Models. Proc. of ACL.
Roark, Brian and Richard Sproat. 2007. Computa-
tional Approaches to Morphology and Syntax. Ox-
ford Univ. Press.
Schone, Patrick and Daniel Jurafsky. 2001. Know-
lege-free induction of inflectional morphologies.
Proc. of NAACL-2001.
Snover, Matthew G., Gaja E. Jarosz and Michael R.
Brent. 2002. Unsupervised Learning of Morphol-
ogy Using a Novel Directed Search Algorithm: Tak-
ing the First Step. Proc. of the ACL-02 SIGPHON
Workshop.
Snyder, Benjamin and Regina Barzilay. 2008. Unsu-
pervised Multilingual Learning for Morphological
Segmentation. Proc. of ACL-08: HLT.
Spencer, Andrew and Arnold M. Zwicky, editors.
2001. The Handbook of Morphology. Wiley-Black-
well.
Spiegler, Sebastian, Bruno Gol?nia, and Peter A.
Flach. 2009. Promodes: A probabilistic genera-
tive model for word decomposition. Working Notes,
CLEF 2009 Workshop.
Spiegler, Sebastian. 2010. EMMA: A Novel Metric for
Morphological Analysis - Experimental Results in
Detail. Computer Science Department, University
of Bristol, U.K.
Tchoukalov, Tzvetan, Christian Monson, and Brian
Roark. 2009. Multiple sequence alignment for
morphology induction. Working Notes, CLEF 2009
Workshop.
Wicentowski, Richard 2002. Modeling and Learn-
ing Multilingual Inflectional Morphology in a Min-
imally Supervised Framework. Ph.D. thesis, The
Johns Hopkins University, Baltimore, Maryland,
U.S.A.
1037
