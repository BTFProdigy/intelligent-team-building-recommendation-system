Proceedings of the 5th Workshop on Important Unresolved Matters, pages 17?24,
Prague, Czech Republic, June 2007. c?2007 Association for Computational Linguistics
Person Name Entity Recognition for Arabic 
Khaled Shaalan 
Institute of Informatics 
The British University in Dubai 
P O Box 502216, Dubai, UAE 
Khaled.shaalan@buid.ac.ae 
Hafsa Raza 
Institute of Informatics 
The British University in Dubai 
P O Box 502216, Dubai, UAE 
hafsa.raza@gmail.com 
 
 
Abstract 
Named entity recognition (NER) is nowa-
days an important task, which is responsi-
ble for the identification of proper names in 
text and their classification as different 
types of named entity such as people, loca-
tions, and organizations. In this paper, we 
present our attempt at the recognition and 
extraction of the most important proper 
name entity, that is, the person name, for 
the Arabic language. We developed the 
system, Person Name Entity Recognition 
for Arabic (PERA), using a rule-based ap-
proach. The system consists of a lexicon, in 
the form of gazetteer name lists, and a 
grammar, in the form of regular expres-
sions, which are responsible for recogniz-
ing person name entities. The PERA sys-
tem is evaluated using a corpus that is 
tagged in a semi-automated way. The sys-
tem performance results achieved were sat-
isfactory and confirm to the targets set 
forth for the precision, recall, and f-
measure. 
1 Introduction 
The recognition and classification of proper names 
in text (e.g. persons, locations, and organizations) 
has recently become considered of major impor-
tance in Natural Language Processing (NLP) as it 
plays a significant role in various types of NLP 
applications, especially in Information Extraction, 
Information Retrieval, Machine Translation, Syn-
tactic Parsing/Chunking, Question-Answering, 
among others. The valuable information in text is 
usually located around proper names, to collect this 
information it should be found first (Abuleil, 2004; 
Chinchor, 1998). In our presentation, we will con-
centrate on the role of NER in Information Extrac-
tion (IE). IE is the NLP task that retrieves relevant 
information from unstructured texts and produces 
as a result a structured set of data. 
This paper describes work on recognizing and 
extracting the most important entities, that is, per-
son names for the Arabic language. We have 
adopted the rule-based approach using linguistic 
grammar-based techniques to develop PERA. This 
approach provides flexibility and adaptability fea-
tures in our system and it can be easily configured 
to work with different languages, NLP applications, 
and domains. In order to determine the best rules 
for recognition of person names, various Arabic 
text corpora were analyzed. Phrases containing 
person names were retrieved, the underlying pat-
tern was learned and person indicators such as ti-
tles were identified. Apart from this, person names 
were extracted from the available corpora and 
other resources to build up a lexicon, in the form of 
gazetteer name lists, or gazetteer for short. The 
various Arabic naming conventions and the person 
indicators identified helped in deriving fine rules 
that gave high-quality recognition of person names 
in Arabic text. The recognition was done in two 
cycles using first the gazetteer and then the gram-
mar rules. The PERA system is evaluated using a 
reference corpus that is tagged with person names 
in a semi-automated way. The achieved system 
performance results were satisfactory and confirm 
17
to the targets set forth for the precision, recall, and 
f-measure. 
The paper is structured as follows. Section 2 
presents the related work. Section 3 describes the 
naming conventions of person names used in Ara-
bic language. Section 4 presents methods of data 
collection used. Section 5 explains the system ar-
chitecture and implementation. Section 6 presents 
the experiment performed to evaluate the system 
and finally Section 7 concludes the paper,     
summarizes our achievements, and highlights our 
plans for future work.. 
    
Larkey et al (2003) have conducted a study that 
showed the importance of the proper names com-
ponent in cross language tasks involving searching, 
tracking, retrieving, or extracting information. In 
particular, they have concluded that a combination 
of static proper name (English-Arabic) translation 
plus transliteration provides a successful solution.  2 Related Work 
As in other NLP techniques, there are two main 
approaches to NER (Toral, 2005). One is based on 
linguistic knowledge, in particular grammar rules 
and hence called rule-based, while the other is 
based on machine learning techniques. The re-
quired resources for the knowledge approach are 
usually gazetteers and rules whereas the learning 
approach needs an annotated (tagged) corpus. The 
linguistic knowledge-based model achieve better 
results in specific domains, as the gazetteers can be 
adapted very precisely, and it is able to detect 
complex entities, as the rules can be tailored to 
meet nearly any requirement. However, if we deal 
with an unrestricted domain, it is better to choose 
the machine learning approach, as it would be inef-
ficient to acquire and/or derive rules and gazetteers 
in this case. 
Name identification has been worked on quite 
intensively for the past few years, and has been 
incorporated into several products. Many research-
ers have attacked this problem in a variety of lan-
guages but only a few limited researches have fo-
cused on NER for Arabic text. This is due to the 
lack of resources for Arabic NE and the limited 
amount of progress made in Arabic NLP in gen-
eral. 
Maloney and Niv (1998) developed TAGARAB 
an Arabic name recognizer that uses a pattern-
recognition engine integrated with morphological 
analysis. The role of the morphological analyzer is 
to decide where a name ends and the non-name 
context begins. The decision depends on the part-
of-speech of the Arabic word and/or its inflections. 
Abuleil (2004) presented a technique to extract 
proper names from text to build a database of 
names along with their classification that can be 
used in question-answering systems. This work 
was done in three main stages: 1) marking the 
phrases that might include names, 2) building up 
graphs to represent the words in these phrases and 
the relationships between them, and 3) applying 
rules to generate the names, classify each of them, 
and saves them in a database. 
Pouliquen et al (2005) developed a tool for mul-
tilingual person name recognition that focuses on 
the "Who" part of the analysis of large news text. 
As multilingual NER is concerned, the translitera-
tion of the NE has included alternative spelling 
variants where the origin language of the name is 
usually not known. Several variants could also be 
found in the same language. 
Samy et al (2005) has used parallel corpora in 
Spanish, and Arabic and an NE tagger in Spanish 
to tag the names in the Arabic corpus. For each 
sentence pair aligned together, they use a simple 
mapping scheme to transliterate all the words in 
the Arabic sentence and return those matching with 
NEs in the Spanish sentence as the NEs in Arabic. 
While they report high precision and recall, it 
should be noted that their approach is applicable 
only when a parallel corpus is available. 
Zitouni et al (2005) has adopted a statistical ap-
proach for the entity detection and recognition 
(EDR). In this work, a mention can be either 
named (e.g. John Mayor), nominal (the president) 
or pronominal (she, it). An entity is the aggregate 
of all the mentions (of any level) which refer to 
one conceptual entity. This extended definition of 
the entity has proved the suitability of the ap-
proach. 
3 Components of an Arabic Full Name 
Arabic has well-defined naming practices. The 
Arabic name elements may be divided into five 
main categories, Ibn Auda (2003): 
1. An ism (pronounced IZM, as the final syllable 
in the word dogmatism), a personal, proper 
name given shortly after birth, i.e. the given 
name. Examples of such names are Muham-
18
mad [Mohammed], Musa [Moses], Ibrahim 
[Abraham].  
2. A kunya (pronounced COON-yah), an honor-
ific name or surname, as the father or mother 
of someone; e.g., abu Da'ud [the father of 
David], umm Salim [the mother of Salim]. It is 
meant as a prefix of respect or reverence. Mar-
ried persons (especially married ladies) are, as 
a general rule, simply called by their kunya 
(abu or umm + the name of their first-born 
child). When using a person's full name, the 
kunya precedes the personal (given) name: Abu 
Yusuf Hasan [the father of Joseph, Hasan], 
Umm Ja?far Aminah [the mother of Ja?far, 
Aminah].  
3. By a nasab (pronounced NAH-sahb), a pedi-
gree, as the son or daughter of someone; e.g., 
ibn 'Umar [the son of Omar], bint 'Abbas [the 
daughter of Abbas]. The nasab follows the ism 
in usage: Hasan ibn Faraj [Hasan the son of 
Faraj], Sumayya bint Khubbat [Sumayya the 
daughter of Khubbat]. Many historical person-
ages are more familiar to us by their nasab 
than by their ism: e.g., the historian ibn 
Khaldun, the traveler ibn Battuta, and the phi-
losopher ibn Sina [Avicenna].  
 Nasabs may be extended for several genera-
tions, as may be noted in the example below 
containing two generations nasab: 
Abu al-Qasim Mansur ibn al-Zabriqan ibn 
Salamah al-Namari 
4. A laqab (pronounced LAH-kahb), a combina-
tion of words into a byname or epithet, usually 
religious, relating to nature, a descriptive, or of 
some admirable quality the person had (or 
would like to have); e.g., al-Rashid [the 
Rightly-guided], al-Fadl [the Prominent]. 
Laqabs follow the ism: Harun al-Rashid 
[Aaron the Rightly-guided]. 
5. A nisba (pronounced NISS-bah), a name de-
rived from a person's: trade or profession, 
place of residence or birth, religious affiliation, 
among others; e.g. al-Hallaj [the dresser of 
cotton], Al Msri [The Egyptian], Islami [Is-
lamic]. Nisbas follow the ism or, if the name 
contains a nasab (of however many genera-
tions), generally follow the nasab.  
4 Data Collection 
The development of the system PERA depends on 
collecting dictionaries of proper nouns and their 
related indicators. Techniques used for acquiring 
such data to build the dictionaries include: 
1. Automatic collection of person names from 
annotated corpus. The person entities in the 
ACE1 and Treebank corpus2 were recognized 
and extracted using regular expression patterns 
coded within Python scripts. Python is a strong 
string processing language and widely used in 
developing NLP applications and tools. 
2. Identification of person indicators. Apart from 
extracting the person names, these corpora 
were used also to extract noun phrases contain-
ing the person names. The surrounding se-
quence of words around person names was 
analyzed to identify indicators of person 
names. A dictionary of these indicators was 
formed which represented contextual cues of 
person names. 
3. Name Database provided by government or-
ganization. The person name dictionary was 
also build from names collected from some or-
ganizations including Immigration Depart-
ments, Educational bodies, and Brokerage 
companies.  
4. Internet Resources. Names were retrieved fur-
ther from various websites3 containing lists of 
Arabic names. Some of these names are Ro-
manized (written using the Latin alphabet) and 
had to be transliterated from English to Arabic. 
This was done using the online translation 
software ?Tarjim? provided by Sakhr Software 
Company. Notice that the variations in Roman-
ized Arabic due to the lack of one to one corre-
spondence between Arabic letters and Roman 
letters have also been reflected in the translit-
eration, in reverse, from Romanized Arabic to 
Arabic Script. 
The raw data received had to be further proc-
essed to make it suitable for building gazetteers to 
                                                 
1 ACE reference: http://projects.ldc.upenn.edu/ace/ 
2 Treebank Corpus reference: 
http://www.ircs.upenn.edu/arabic/ 
Both software are available to BUiD under license agreement. 
3 Web sites include: 
http://en.wikipedia.org/wiki/List_of_Arabic_names , 
http://www.islam4you.info/contents/names/fa.php,  and 
http://www.mybabynamessite.com/list.php?letter=a 
19
be incorporated within the system. Some of the 
automated preprocessing performed on these data 
includes: 
? Removing extra whitespaces between first 
and last names, or beginning and end of 
names for the efficient processing of the 
main gazetteer (dictionary) of complete 
person names. 
? Creating separate dictionaries (i.e. first, 
last and middle names) without redun-
dancy because the full names had to be 
parsed. The extraction of each of these in-
dividual components from full person 
names was based on Python code and 
common sense. 
4.1 Typographic Variants 
In order to be able to recognize variant Arabic 
name entities, we added extra expressions in rules 
and lexicon entries which lead to recognizing 
named entities and their typographic variants. Ex-
amples of typographic variants include: 
? The drop of hamza initially, medially, and 
finally (e.g. ?????  vs ????? - [Ehessan]) ?
????
 ????? ?? ???
? Two dots inserted on aleph maqsura, and 
two dots removed from yaa (e.g.  ????? vs 
-[Mousa]) 
? Dropping the madda from the aleph (e.g.  
  vs  ????? - [Al Khalifa]) 
? Hamza insertion below vs. above aleph 
(e.g. ????? vs ?????-[Essraa]) 
? Two dots inserted on final haa, and two 
dots removed from taa marbouta (e.g.  ?????? 
vs ?????-[Fatma]) 
? Diacritics: partial, full, or none. In the cur-
rent version we remove diacritics. 
? Typing hamza followed by aleph maqsura 
separately vs. together (e.g.  ?????? vs  ?????-
[Hani]). 
4.2 Dictionaries 
The following dictionaries (gazetteers) are derived 
using the aforementioned data collection tech-
niques. A total of 472617 entries were collected. 
? A dictionary of full person names (263598 
entries) 
? A dictionary of first names (78956 entries) 
? A dictionary of middle names (67595 en-
tries) 
? A dictionary of last names (33517 entries) 
? A dictionary of job titles (19245 entries) 
? A dictionary of honorifics used before 
names (173 entries) 
? A dictionary of country names including 
variations in spellings (923 entries) 
? A dictionary of nick names and laqabs  
(8169 entries) 
? A dictionary of  person titles (20 entries) 
? a dictionary of words and phrases that act 
as person indicators such as ? ????????
 ????????? (The sports supervisor) (421 en-
tries) 
5 System Architecture and Implementa-
tion 
Figure 1 shows the architecture of the PERA sys-
tem. Our system has two major components: the 
gazetteers and the Grammar. A filtration mecha-
nism is employed that enables revision capabilities 
in the system. 
 
 
Figure 1: Architecture of the System 
5.1 Gazetteers 
The main gazetteer (dictionary) of complete person 
names plays the role of a fixed static dictionary of 
full person names. It recognizes person name enti-
Dictionaries 
Acquisition from ACE 
& Treebank corpus 
Arabic 
script 
Internet Resources
Names Databases
Annotated 
Text 
Rule-based System 
    Whitelist   
     Dictionary 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
                   Blacklist  
                                  Dictionary 
Text 
(3) Filter 
(2) Grammar 
Configuration  
(1) Gazetteer 
Data Collection 
20
ties by being applied as a Whitelist mechanism that 
accepts matches which are reported as a result of 
an intersection between the dictionary and the in-
put text. A Whitelist is a list of strings that must be 
recognized independent of the rules. It contains 
entries in the following format: 
????????? ???? ????????|Abdulrahman Qasim 
Mohammed Alshirawi 
 
Since the system being developed can be incor-
porated in various applications independent of lan-
guage constraints, the English transliterations of 
the Arabic names are included in the dictionary as 
meta data. 
5.2 Grammar 
The grammar performs recognition and extraction 
of person entities from the input text based on 
combinations of regular expression patterns. This 
rule definition is particularly challenging for the 
Arabic language due to reasons such as: 
? Arabic writing systems do not exhibit dif-
ferences in orthographic case, such as ini-
tial capitalized letters to indicate the pres-
ence of a proper name. This lack of spe-
cific internal structure in the Arabic lan-
guage poses great challenge for recogniz-
ing person entities. 
? Arabic is a highly inflected language 
which entails a requirement of understand-
ing of its morphological nature. The in-
flected Arabic word maybe composed of 
prefixes such as prepositions and suffixes 
such as pronouns. These affixes need to be 
addressed to ensure recognition of person 
names alone. 
Due to the above complexities in the Arabic 
language a deep contextual analysis of various 
Arabic scripts was performed using Python scripts 
to build grammar rules based on keywords or trig-
ger words forming a window around a person 
name.  
 
An Example Rule: 
The following rule recognizes a person name com-
posed of a first name followed by optional middle 
and last names based on a preceding person indica-
tor pattern.  
 
 
 
Description: 
? The names should be verified against their 
respective dictionaries (i.e. first, middle, 
and last names). 
? The indicator pattern is composed of an 
honorific such as "?????" [The king] fol-
lowed by an optional Nisba derived from a 
location name such as "???????" [Jordanian]. 
These act as trigger words to recognize the 
person name and should be verified against 
their respective dictionaries of honorific 
and locations. 
? The rule also matches an optional ordinal 
number appearing at the end of some 
names such as "??????" [II]. 
? The Arabic suffix letters "??" and "?" used 
in the above pattern parses the inflections 
attached to Nisba derived from locations 
that are commonly found in Arabic text.  
 
Implementation: 
 
 
 
 
 
Writing conventions: 
(($honorific$ws*($location 
(\x{064A}|\x{0629})*$ws*)?)+ 
$firsts_v(($ws*$middle_vv)| 
($ws*$lasts_v))?$ws*($number)?) 
? $: reference to a slave schema. 
? Firsts_v: dictionary of first names. 
? Middle_vv: dictionary of middle names. 
? Lasts_v: dictionary of last names. 
? Ws: whitespace. 
? Honorific:  dictionary of honorifics ap-
pearing before names. 
? Location: dictionary of locations. 
? Number: Arabic ordinal numbers. 
 
Example: 
The following name would be recognized by the 
above rule: 
 ???  ???? ??????????????????   
[The Jordanian king Abdullah II] 
 
Apart from contextual cues, the typical Arabic 
naming elements were used to formulate rules such 
as nasab, kunya, etc. Thereby the rules resulted in a 
good control over critical instances by recognizing 
complex entities. ((honorfic+ws(location(?|??)+ws)?) 
+firsts_v((ws+middle_vv)| 
(ws+lasts_v))?ws+(number)?) 
21
5.3 Filter 
A filtration mechanism is used in the form of a 
Blacklist (rejecter) within the grammar configura-
tion to filter matches that appear after person titles 
but are invalid person names. In the following ex-
ample: 
 ? ?????? ????? ????? ??????????? ??? ? [The Iraqi Foreign 
Minister the Secretary-General] 
 
The sequence of words ????? ???????? ???????? [The 
Iraqi Foreign Minister] acts as a person indicator 
and the word immediately following it is usually a 
valid person name. However, in this example, the 
words following the person indicator that is, ? ??????
?????? (the Secretary-General) is not a valid person 
name. Hence the role of the blacklist comes into 
play by rejecting the incorrect matches recognized 
by certain rules. 
5.4 The Implementation Platform 
The PERA system was implemented through in-
corporation into the FAST ESP framework, 
(FAST,_). FAST ESP is an integrated software 
application that provides searching and filtering 
services. It is a distributed system that enables in-
formation retrieval from any type of information, 
combining real-time searching, advanced linguis-
tics, and a variety of content access options into a 
modular, scalable product suite. 
The document processing stage within FAST 
ESP system provides support for Entity Extraction. 
PERA is implemented through the customizable 
document processing pipelines within FAST ESP, 
which consists of multiple document processing 
stages. A new search pipeline was created and 
stages containing the grammar configuration and 
gazetteers were added to this pipeline. Figure 2 
indicates the functionality of the PERA system 
incorporated in the pipeline within FAST ESP for 
recognizing and tagging person entity in text. 
6 The Experiment 
In evaluating the PERA system we follow the 
standard practice in the IE field of comparing sys-
tem output against a reference corpus and measur-
ing the performance of the Arabic person named 
entity. 
 
 
Figure 2: PERA incorporated into FAST ESP pipe-
line to produce Tagged text 
 
6.1 Reference Corpus 
The text within the ACE and Treebank corpus was 
used for creating the entity tagged reference corpus 
for evaluating PERA. The text was chosen ran-
domly from files with ?sgm? extension (containing 
the Arabic script) within ACE & Treebank corpus. 
The tagging was automatically performed with a 
Python script and further a post manual check was 
performed to correct any invalid tags or identify 
the missing ones. The end product was an anno-
tated text corpus in the xml format with the UTF-8 
encoding. This was divided into a 46 test sets and 
each evaluated individually with hurricane. The 
total size of the reference corpus build is around 
4MB. The size and content of the corpus is such 
that it contains a representative amount of occur-
rences of the person entity. 
6.2 Evaluation Method 
We have adopted the evaluation measures that are 
standard in the IE community (De Sitter et al, 
2004), to evaluate and compare the results (preci-
sion, recall and F-measures): 
correct entities recognized 
Precision= total entities recognized 
PIPELINE
Politics of Ukraine 
In July 1994, Leonid Kuchma was elected as Ukraine's second president in 
free and fair elections. Kuchma was reelected in November 1999 to 
another five-year term, with 56 percent of the vote. International observers 
criticized aspects of the election, especially slanted media coverage; 
however, the outcome of the vote was not called into question. In March 
2002, Ukraine held its most recent parliamentary elections, which were 
characterized by the Organization for Security and Cooperation in Europe 
(OSCE) as flawed, but an improvement over the 1998 elections. The pro-
presidential For a United Ukraine bloc won the largest number of seats, 
followed by the reformist Our Ukraine bloc of former Prime Minister Viktor 
Yushchenko, and the Communist Party. There are 450 seats in parliament, 
with half chosen from party lists by proportional vote and half from individ-
ual constituencies 
Person Person 
Person 
22
correct entities recognized 
Recall= total correct entities 
2 x recall x precision 
F-measure= recall + precision 
Precision indicates how many of the extracted 
entities are correct. Recall indicates how many of 
the entities that should have been found, are effec-
tively extracted. Usually there is a trade off of re-
call against precision. Therefore, often an average 
accuracy is reported in the form of the F-measure, 
a harmonic mean which weights recall and preci-
sion equally. It was introduced to provide a single 
figure to compare different systems? performances. 
The PERA system implemented within the FAST 
ESP pipeline was evaluated using an Information 
Extraction testing tool called ?hurricane? that ap-
plies these standard measures. 
6.3 Results 
Figure 3 is a snapshot of the evaluation performed 
by hurricane in terms of the above mentioned 
measure. 
 
Figure 3: An Extraction from Hurricane Evaluation 
 
The extraction quality of the pipeline created for 
the person name extractor confirms to the initial 
target set. The required degree of precision (80%) 
and recall (70%), for the Person name extractor, 
has been achieved with the hurricane evaluation. 
Some of the entries within the gazetteers were ex-
tracted from the same corpus used also for creating 
the reference corpus for evaluation. However, the 
results achieved are accurate since they indicated 
recognition of person entities not included in the 
gazetteers but being recognized by the grammar 
rules.  
Table1 indicates the performance figures pro-
duced by 6 out of the 46 sets used for Hurricane 
evaluation.  
The average Precision and Recall for the total 46 
sets in recognizing person names is 85.5% and 
89%, respectively. And the average f-measure is 
87.5%. 
 
Test Set Precision Recall F-measure 
Treebank set 1 91.2 90.3 90.7 
Treebank set 2 94 96.3 95.1 
Treebank set  3  84.2 84.7 84.4 
ACE set 1 89.6 96.8 93.1 
ACE set 2 88.4 94.2 91.2 
ACE set 3  86.7 89 87.8 
Table 1: Evaluation result for 6 test sets. 
 
The missing accuracy can be overcome in the 
following ways: 
? Expanding the dictionary of person 
names further. 
? More Arabic text/corpus can be analyzed 
to identify strings that act as person indi-
cators. 
? Reducing negative effects on evaluation 
results (true positive being treated as 
false positives) caused due to incomplete 
annotation of the test corpus. The refer-
ence corpus can be further fine tuned to 
tag all person entities completely. 
? Enhancing quality of transliterated 
names used. 
? Using Arabic text with error free spell-
ing. 
? Including all possible spelling variations 
used for names in Arabic written text. 
7 Conclusion and Future Work 
The work done in this project is an attempt to 
broaden the coverage for entity extraction by in-
corporating the Arabic language, thereby paving 
the path towards enabling search solutions to the 
Arabian market.  
Various data collection techniques were used for 
acquiring gazetteer name lists. The rule-based ap-
proach employed with great linguistic expertise 
provided a successful implementation of the PERA 
system. Rules are capable of recognizing inflected 
23
forms by breaking them down into stems and af-
fixes. A filtration mechanism is employed in the 
form of a rejecter within the grammar configura-
tion that helps in deciding where a name ends and 
the non-name context begins. We have evaluated 
our system performance using a reference corpus 
that is tagged in a semi-automated way. The aver-
age Precision and Recall achieved for recognizing 
person names was 85.5% and 89%, respectively. 
Suggestions for improving the system performance 
were provided. 
This work is part of a new system for Arabic 
NER. It has several ongoing activities, all con-
cerned with extending our research to recognize 
and categorize other entity Arabic named entities 
such as locations, organization. 
Acknowledgement 
This work is funded by the "Named Entity Rec-
ognition for Arabic" joint project between The 
British Univ. in Duabi, Dubai, UAE and FAST 
search & Transfer Inc., Oslo, Norway. We thank 
the FAST team. In particular, we would like to 
thank Dr. Petra Maier and Dr. J?rgen Oesterle for 
their technical support. 
Any opinions, findings and conclusions or rec-
ommendations expressed in this material are the 
authors, and do not necessarily reflect those of the 
sponsor. 
References 
Saleem Abuleil 2004. Extracting Names from Arabic 
Text for Question-Answering Systems, In Proceed-
ings of Coupling approaches, coupling media and 
coupling languages for information retrieval (RIAO 
2004), Avignon, France. pp. 638- 647. 
Da'ud Ibn Auda. 2003. Period Arabic Names and Nam-
ing Practices, In Proceedings of the Known World 
Heraldic Symposium (SCA: KWHS Proceedings, 
2003), pp. 42-56, St. Louis, USA. 
FAST ESP   
http://www.fastsearch.com/thesolution.aspx?m=376 
Nancy Chinchor 1998. Overview of MUC-7. In Pro-
ceedings of the Seventh Message Understanding 
Conference (MUC-7). Available at: 
http://www.itl.nist.gov/iaui/894.02/related_projects/
muc/  
Leah S. Larkey, Nasreen Abdul Jaleel, Margaret Con-
nell. 2003. What's in a Name?: Proper Names in 
Arabic Cross Language Information Retrieval CIIR 
Technical Report IR-278. Available at 
http://ciir.cs.umass.edu/pubfiles/ir-278.pdf 
John Maloney and Michael Niv. 1998. TAGARAB: A 
Fast, Accurate Arabic Name Recogniser Using High 
Precision Morphological Analysis. In Proceedings of 
the Workshop on Computational Approaches to Se-
mitic Languages. Montreal, Canada. August, pp. 8-
15.   
Bruno Pouliquen, Ralf Steinberger, Camelia Ignat, Irina 
Temnikova, Anna Widiger, Wajdi Zaghouani, and 
Jan Zizka. 2005. Multilingual person name recogni-
tion and transliteration. Journal CORELA-Cognition, 
Repr?sentation, Langage, Vol. 2,  ISSN 1638-5748. 
Available at http://edel.univ-poitiers.fr/corela/ 
Doaa Samy, Antonio Moreno and Jose M. Guirao. 2005. 
A Proposal for an Arabic Named Entity Tagger Lev-
eraging a Parallel Corpus, International Conference 
RANLP, Borovets, Bulgaria, pp. 459-465. 
An De Sitter, Toon Calders, and Walter Daelemans. 
2004. A Formal Framework for Evaluation of Infor-
mation Extraction, University of Antwerp,  Dept. of 
Mathematics and Computer Science, Technical Re-
port, TR 2004-0. Available at 
http://www.cnts.ua.ac.be/Publications/2004/DCD04 
Antonio Toral. 2005. DRAMNERI: a free knowledge 
based tool to Named Entity Recognition. In Proceed-
ings of the 1st Free Software Technologies Confer-
ence. A Coru?a, Spain. pp. 27-32. 
Imed Zitouni, Jeffrey Sorensen, Xiaoqiang Luo and 
Radu Florian, 2005 The Impact of Morphological 
Stemming on Arabic Mention Detection and 
Coreference Resolution, In the Proceedings of the 
ACL workshop on Computational Approaches to Se-
mitic Languages, 43rd Annual Meeting of the Asso-
ciation of Computational Linguistics (ACL05). June, 
Ann Arbor, Michigan, USA, pp. 63-70. 
24
Proceedings of the EACL 2009 Workshop on Computational Approaches to Semitic Languages, pages 27?35,
Athens, Greece, 31 March, 2009. c?2009 Association for Computational Linguistics
A Hybrid Approach for Building Arabic Diacritizer  
 
 
Khaled Shaalan Hitham M. Abo Bakr Ibrahim Ziedan 
The Faculty of Informatics  Computer & System Dept Computer & System Dept. 
The British University in Dubai Zagazig University Zagazig University 
khaled.shaalan@buid.ac.ae hithamab@yahoo.com i.ziedan@yahoo.com 
 
  
 
Abstract 
 
Modern standard Arabic is usually written 
without diacritics. This makes it difficult for 
performing Arabic text processing. Diacritiza-
tion helps clarify the meaning of words and 
disambiguate any vague spellings or pronun-
ciations, as some Arabic words are spelled the 
same but differ in meaning. In this paper, we 
address the issue of adding diacritics to undia-
critized Arabic text using a hybrid approach. 
The approach requires an Arabic lexicon and 
large corpus of fully diacritized text for train-
ing purposes in order to detect diacritics. Case-
Ending is treated as a separate post processing 
task using syntactic information. The hybrid 
approach relies on lexicon retrieval, bigram, 
and SVM-statistical prioritized techniques.  
We present results of an evaluation of the pro-
posed diacritization approach and discuss var-
ious modifications for improving the perfor-
mance of this approach. 
1 Introduction 
Modern Arabic written texts usually include 
Arabic scripts without short vowels and other 
diacritic marks. This often leads to considerable 
ambiguity since several words that have differ-
ent diacritic patterns may appear identical in a 
diacritic-less setting. Educated modern Arabic 
speakers are able to accurately derive/restore 
diacritics in a document. This is based on the 
context and their linguistic knowledge of Arabic. 
However, a text without diacritics brings diffi-
culties for Arabic readers. It is also problematic 
for Arabic processing applications, such as text-
to-speech, speech-to-text, and text analysis, 
where the lack of diacritics adds another layer of 
ambiguity when processing the input data. As an 
example, full vocalization of Arabic text is re-
quired for text-to-speech applications, where the 
mapping from graphemes to phonemes is com-
plicated compared to languages such as English 
and French; where there is, in most cases, simple 
one-to-one relationship. Nevertheless, using 
Arabic text with diacritics has proven an im-
provement in the accuracy of speech-recognition 
applications (Zitouni et al, 2006).  
The problem of automatic restoration (i.e., deri-
vation) of the diacritic signs of Arabic text can 
be solved by two approaches. The first is a rule-
based approach that involves a complex integra-
tion of the Arabic morphological, syntactic, and 
semantic tools with significant efforts to acquire 
respective linguistic rules. A morphological ana-
lyzer gets the breakdowns of the undiacritized 
word according to known patterns or templates 
and recognizes its prefixes and suffixes. A syn-
tax analyzer applies specific syntactic rules to 
determine the case-ending diacritics, usually, by 
techniques such as finite-state automata. Seman-
tics handling helps to resolve ambiguous cases 
and to filter out hypothesis. Hence, rule-based 
diacritization approach is a complicated process 
and takes longer time to process an Arabic sen-
tence which is naturally long. The second ap-
proach is the statistical approach that requires 
linguistic resources such as a large tagged cor-
pus (in particular a TreeBank) to extract lan-
guage statistics for estimating the missing dia-
critical marks. The approach is fully automated 
and does not require efforts to acquire respective 
linguistic knowledge. Results are usually im-
proved by increasing the size of the corpus. 
It is worth noting that identifying some of the 
diacritic marks can be seen as a morphological 
problem and the relevant letters are called inter-
nal characters in this paper. Moreover, diacritic 
mark of the last character of the Arabic is called 
case ending (????? ???????). The identification of 
case-ending diacritics is determined at the syn-
27
tactic processing level (case ending depends on 
the position of the word within the sentence) 
whereas detecting the internal diacritics is de-
termined at the morphological processing level. 
In widespread cases, the case-ending come in-
ternally rather than with the last character such 
as "?????????" (by-her-pen). 
In this paper, an Arabic diacritizer is proposed. 
Internal diacritization was restored by a model 
based on the synergy of three different tech-
niques:  retrieval of unambiguous lexicon en-
tries, retrieval of two-word expression from a 
preprocessed diacritized bigram database, and a 
prediction using statistical approach based on 
SVM-learning technique, (Cristianini and Tay-
lor, 2000) and (Hearst, 1998). The later tech-
nique tokenizes a text and provides a Reduced 
Tag Set (RTS) of Part of Speech (POS)1 for each 
token. The tags are used to restore the diacritics. 
From the obtained diacritization results of these 
techniques, the most consistent one is selected. 
The Case-Ending diacritization is treated as a 
post-process of the internal diacritization task 
using the same machine learning approach that 
was trained on Base phrase (BP)-Chunk as well 
as POS features of individual tokens with correct 
case-ending tags. A utility has been designed to 
extract correct case-ending tags from the LDC?s 
Arabic Tree Bank (ATB).  
This paper presents a new simple but efficient 
approach that gets results comparable with the 
best performing systems, to our knowledge, 
(Habash and Rambow, 2007). The achieved re-
sults are: 11.795% Word Error Rate (WER) and 
about 3.245% Diacritics Error Rate (DER). The 
paper is structured as follows. Section 2 reviews 
closely related work. Section 3 introduces the 
proposed diacritization approach. Section 4 de-
scribes the training process. Section 5 presents 
the evaluation experiment. Section 6 concludes 
the article and gives direction for future re-
search. 
2 Related Work 
Diacritic restoration has been receiving increas-
ing attention and has been the focus of several 
studies. In El-Sadany and Hashish (1988), a rule-
                                                 
1 List of POS and RTS that are used here can be found at: 
http://www.ircs.upenn.edu/arabic/Jan03release/arabic-
POStags-collapse-to-PennPOStags.txt 
 
based approach that uses morphological analyzer 
for vowelization was proposed. Another, rule-
based grapheme to sound conversion approach 
appeared in 2003 by Y. El-Imam (2003). 
There are many related works dealing with the 
problem of Arabic diacritization in general (Zi-
touni et al, 2006), (Habash and Rambow, 2007), 
(Ananthakrishnan, 2005), (Kirchhoff, 2005).  and 
(Elshafei et al 2006); all trying to handle this 
problem using statistical approaches but they 
tend to handle the case ending diacritic mark in 
the same way they used to handle the internal 
(any letter but the last) diacritics. In our proposed 
approach we differentiate between them as the 
detection of case-ending diacritics is a syntactic-
based problem whereas detecting the internal 
diacritics is a morphological-based problem. Ha-
bash et al (2007) introduced a system called 
MADA-D that uses Buckwalter?s Arabic mor-
phological analyzer where they used 14 taggers 
and a lexeme-based language model. MADA is 
so far the best performing system to date. It has 
been reported that it achieved a WER of 14.9% 
and a DER of 4.8%. 
3 The Proposed Diacritization Ap-
proach  
The Arabic internal diacritization problem will 
be addressed from three different proposed tech-
niques, each of which has its own strengths and 
weaknesses. Such techniques are integrated to 
optimize the performance of the Arabic diacritiz-
er and to a large extent remove ambiguities. 
These proposed techniques are: 1) Lexicon Re-
trieval, 2) diacritized bigram, and 3) SVM-
statistical-based diacritizer. Then, the case end-
ing diacritization will be determined after the 
internal discrimination is performed. Figure 1 
shows the architecture of Arabic Diacritization 
System. 
 
28
Receive 
undiacritized 
statement
Tokenize 
statement
Get POS tagging
Get BP-Chunk
Get Case Ending
Search in Arabic 
Lexicon for Diac 
word by using 
the POS
Return Case 
Ending for 
each Token
Return 
Diac Word 
Word if 
exist
Split Eeach word 
with its POS
Search for single 
result in the 
Lexicon
Search In 
Diacritized 
Bigram Database
Return 
Diac Word 
if exist
Return 
Diac 
Words if 
exist
Receive 
selected internal 
Diacritized 
Words
Search for token 
in Internal 
diacritized word 
to decide the 
position of Case-
Ending
Fully 
Diacritized 
Statement
Add Case Ending 
in correct 
position
Get Correct Internal 
Diacritics using Decision 
Maker module 
Split Statement 
to words
Split Statement 
to Bigrams
Results From SVM 
Statistical Module
 
Figure 1: Arabic Diacritization System 
 
Lexicon Retrieval Technique (LR) 
Lexicon retrieval approach tries to find the result 
(diacritized word) returned from an Arabic lex-
icon for a specific input undiacritized word. If 
only one diacritization is returned, then there is 
no ambiguity. This solution is final and we do 
not need to look at the results form the other two 
techniques. However, this situation is usually 
rare but when it occurs the result is confirmed. 
 
Diacritized Bigram Technique (DB) 
When more than one solution is retrieved for an 
unvowelized input word, i.e., ambiguous diacrti-
cazation, the bigram technique comes into play. 
The idea behind this technique is to make use of 
the multiword expressions in Arabic texts.  When 
such expressions are analyzed as separate words, 
the possibility for ambiguity is increased.  In this 
work, we considered a two-word expression (bi-
gram) that usually occurs with high frequency in 
Arabic texts such that one word can determine 
the diacritization of the other. Once the expres-
sion is identified and diacritized correctly, it adds 
a sense of certitude to the diacritization which 
significantly reduces the ambiguity. Table 1 
shows an extraction of the diacritized bigram 
database. 
   
1st 
Word 
2nd 
Word 
Cat Diac. 1st 
Word 
Diac. 2nd 
Word 
??????? ??????? 3 ????? ???? 
???????????? ????????? 1 ??????? ???????? 
????????? ?????? 1 ??????? ???? 
???? ?????? 1 ??? ????? 
???????????? ???????? 1 ??????? ????? 
Table 1: Diacritized Bigram Database 
 
SVM-Statistical Technique (SVM) 
The previous two diacritization techniques can 
be viewed as a lookup process; either for a word 
in the lexicon or for a two-word expression in a 
large bigram database. However, statistical me-
thods can be viewed as general approaches be-
cause they are heavily dependent on the Arabic 
syntactic analysis that was manually performed 
by Arabic specialists. 
The main idea of this approach is to tokenize 
and automatically annotate tokens with the cor-
rect POS tags. Then, by searching the Arabic 
lexicon using a token and the corresponding 
POS, the correct diacritization result can reached, 
even though multiple ambiguous words are re-
trieved from the lexicon. 
 Buckwalter's morphological analyzer (Buck-
walter, 2002) takes an inflected Arabic word and 
returns fully diacritized ambiguous words. We 
claim in our approach that only internal diacritics 
should be handled morphologically whereas case 
ending should be handled syntactically. Hence, 
we have used the Buckwalter's morphological 
analyzer after removing all case ending diacritics 
from the suffixes table in order to prevent the 
generation of the case ending output. One advan-
tage of this modification is to considerably re-
duce the number of alternatives (i.e., overgenera-
tions) returned from the morphological analyzer. 
Another advantage is that some NLP tasks, such 
as Information Retrieval, require only diacritic 
restoration of internal (lexical) vowels which can 
benefit from such modification. For example, 
given the word ? ???? ? to this morphological 
analyzer, it returns 7 results that have the same 
internal diacritics with one having no case-
ending and 6 having different case-ending dia-
critics. Consequently, splitting the diacrization 
into two stages (internal and case ending) will 
avoid such morphological ambiguity and at the 
second stage the syntactic case ending is treated 
29
separately as a post processing which ultimately 
leads to a fully efficient diacritized Arabic word. 
A Hybrid of All Internal Techniques 
When we apply each of the three proposed 
techniques on an input undiacritized Arabic sen-
tence we may get different diacritization results 
for each word within this sentence. The selection 
criteria depend on the agreement among these 
techniques. Two or more matched results can 
determine the discrimination of a word. In case 
of disagreement, a priority is applied in the fol-
lowing, highest to lowest, order: lexicon retriev-
al, bigram and SVM-Statistical technique respec-
tively. If no solution is reached from all tech-
niques, the undiacritized input word is returned.  
 
Case Ending Model 
The main idea is to relate the case-ending for 
each token with its POS and chunk position as 
well as its position within the sentence (Abo 
Bakr et al, 2008). We made a training using 
Support Vector Machines (SVM) technique with 
undiacritized tokens. This technique involves an 
Arabic Treebank. 
An Arabic Treebank usually created on top of 
a corpus that has already been annotated with 
POS tags. We have used the Penn Arabic Tree-
bank (ATB) (Maamouri et al 2004). ATB has 
begun in the fall of 2001 and has now completed 
four full releases of morphologically and syntac-
tically annotated data: Version 1 of the ATB has 
three parts with different releases; some versions 
like Part 1 V3.0 and Part 2 V 2.0 are fully diacri-
tized trees. For example, consider the following 
undiacritized statement: 
 
 
 
 
 
The following tree representation is partially 
extracted from the tree fileU-
MAAH_UM.ARB_20020120-a.0007.tree that is part 
of  the ATB Part 2 V.2.  
 
 
 
 
 
 
Figure 2 shows a graphical representation of this 
tree2. Case-ending is indicated, ovals in Figure 2, 
by one of the following tags: NCE, 
CASE_DEF_GEN, CASE_INDEF_GEN, 
CASE_DEF_NOM, CASE_DEF_ACC, 
CASE_INDEF_NOM, CASE_DEF_ACCGEN, 
CASE_INDEF ACC, and 
CASE_INDEF_ACCGEN. 
Table 2 gives the complete description of these 
tags. 
 
Figure 2: A graphical representation of an Arabic sen-
tence extracted from the Penn Arabic Treebank 
 
Case Ending Tags Description 
NCE No Case Ending 
CASE_DEF_GEN  Kasra  ?? 
CASE_INDEF_GEN  kasratan ?? 
CASE_DEF_NOM Damma ?? 
CASE_DEF_ACC Fat-ha ?? 
CASE_DEF_ACCGEN  Maftouh bi Kasra ?? 
CASE_INDEF_NOM  Damatan  ?? 
CASE_INDEF_ACCGEN  Fathatan ?? or  ?? 
CASE_INDEF_ACC Fathatan ?? 
Table 2: Description of Case-Ending tags found in 
ATB 
 
A sequence of tokens with its POS, BP-chunk 
and Case-Ending is extracted from Treebank us-
ing YamCha File Creator (YFC utility3). The 
                                                 
2 This graphical representation of the Treebank files is ex-
tracted from our Treebank Viewer tool that is freely availa-
ble at: http://www.staff.zu.edu.eg/hmabobakr/ 
 
3 We developed YFC utility to extract information from 
Penn Arabic Treebank ATB and produce the Yamcha stan-
dard input format to be able to use this information in the 
training process. 
http://www.staff.zu.edu.eg/hmabobakr/page.asp?id=53 
"????? ?????? ??? ??????? ????? ???? ?????? ??? 
?????".... 
"llywm AlvAny ElY AltwAly tZAhr TlAb 
(S (S (S (PP-TMP (PREP li-) (NP (NP 
(DET+NOUN+CASE_DEF_GEN -Al+yawom+i) 
(DET+ADJ Al+vAniy)) (PP (PREP EalaY) (NP 
(DET+NOUN Al+tawAliy))))) (VP 
(VERB_PERFECT+PVSUFF_SUBJ:3MS N 
Al+musolim+iyona) ?.. 
30
basic approach used in YFC is inspired by the 
work of Sabine for Treebank-to-chuck conver-
sion script (Sang and Buchholz, 2000), which we 
have extended to be used with Arabic. This has 
required adding some features like Case-Ending. 
The output produced from YFC utility for case 
ending training process is shown in Table 3. 
 
Token POS Chunk Case Ending
L IN B-PP NCE 
Al DT B-NP NCE 
ywm NN I-NP CASE_DEF_GEN 
Al DT I-NP NCE 
vAny JJ I-NP NCE 
ElY IN B-PP NCE 
Al DT B-NP NCE 
twAly NN I-NP NCE 
tZAhr VBD B-VP NCE 
TlAb NN B-NP CASE_INDEF_NOM 
Yntmwn VBP B-VP NCE 
<lY IN B-PP NCE 
jmAEp NN B-NP CASE_DEF_GEN 
Table 3: Training file format for detecting Case-
Ending 
4 Training of the Arabic Diacritizer 
The diacritization system we present here is 
trained and evaluated on the LDC?s Arabic Tree-
bank of diacritized news articles ? Part 2 v2.0: 
catalog number LDC2004T02 and 1-58563-282-
1. The corpus includes complete vocalization 
(including case endings). We introduce here a 
clearly defined and replicable split of the corpus, 
so that the reproduction of the results or future 
investigations can accurately and correctly be 
established. This corpus includes 501 stories 
from the Ummah Arabic News Text. There are a 
total of 144,199 words (counting non-Arabic to-
kens such as numbers and punctuation) in the 
501 files - one story per file.   We split the cor-
pus into two sets: training data and development 
test (devtest) data. The devtest data are the files 
ended by character ?7? like 
?UMAAH_UM.ARB_20020120-a.0007.tree? 
and its count was 38 files. The remaining files 
are used for training. 
5 Evaluation 
For Arabic tokenizer, POS tagger, BP-chunk, 
and statistical Case-Ending, we used a standard 
SVM with a polynomial kernel of degree 2 and 
C=1.0. Evaluation of the system was done by 
calculating the performance using the standard 
evaluation measures: accuracy, precision, recall, 
and the f-measure4.We used YamCha (Kudo and 
Matsumoto, 2003) implementation of SVMs. 
Diacritization evaluation of our experiments is 
reported in terms of word error rate (WER), and 
diacritization error rate (DER)5. 
We conducted experiments to: 
1. Evaluate the impact of tokenization, part-of-
speech, chunking, and case-ending parame-
ters on the training models, see Section 5.1. 
2. Evaluate the impact of including and ex-
cluding the case-ending on the performance 
of the Arabic diacritizer, see Section 5.2. 
3. Compare our approach of Tokenization and 
POS tagger with the ArabicSVMTools tag-
ger using different parameters and fea-
ture(s), see Section 5.2. 
 
5.1 Results of Tokenization, Part-of-Speech, 
BP-chunking, and case-ending  
The results obtained for tokenization (TOK), 
part-of-speech (POS), and Chunking (BP-chunk) 
tasks are comparable with the results presented 
in the most notable literature (Diab et al 2007; 
Diab et al 2004). We did some modifications of 
the feature list to compromise between the speed 
and accuracy. The case ending task is novel, and 
did not get enough handling in other research. It 
achieved acceptable results. 
 
Evaluation of the impact of the tokenization 
parameter on the training process 
Two tokenization tasks was performed on 
window sizes of -2 /+2 and -4/+4, for illustration 
see TOK1 and TOK2 tasks in Figure 3. For each 
window size there are two columns. The first one 
contains a sequence of Buckwalter's translite-
rated Arabic letters shown from top to bottom 
that resembles the left-to-right Arabic writing 
system (e.g., ?.wyblg Eddhm ?.. are the trans-
literation of the Arabic words ...????? ?????... , re-
spectively). The second column contains the cor-
responding tokenization tags presented by In-
side-Outside-Beginning (I-O-B) of a chunk, i.e., 
                                                 
4 These results were computed using our developed evlua-
tion tool that was developed and tested against Evaluation 
Tools for CONLL 2000 
http://www.cnts.ua.ac.be/conll2000/chunking/conlleval.txt. 
 
5 These results were computed using our developed evalua-
tion tool that was developed based on information presented 
in (Habash and Rambow, 2007). 
 
31
prefix (PRE), word (WRD), and suffix (SUFF), 
respectively, (Kudo and Matsumoto, 2003). The 
tokenization tags are: B-PRE1, I-PRE1, B-PRE2, 
I-PRE2, B-PRE3, I-PRE3, B-WORD-1, I-
WORD-1, B-SUFF1, I-SUFF1 and O for outside 
word boundary. We made segmentation for the 
determiner "Al" ? "??". This segmentation is im-
portant for the case-ending detection for: the ad-
jective and the noun it modifies ?????? ?????????, 
1st and 2nd Particle of the construction Annexed 
and Annexed noun ??????? ? ?????? ?????, and Nu-
nation  ???????" ". The result of the evaluation of the 
two tokenization tasks is shown in Table 4. 
 
 
Figure 3: Tokenization evaluation with window sizes 
of -2/+2 and -4/+4 
 
Measurement TOK1 TOK2
Accuracy 98.59% 99.56% 
Precision 97.17% 98.95% 
Recall 97.29% 99.06% 
F-Measure 97.23% 99.00% 
Table 4: Tokenization results with window sizes of     
-2/+2 and -4/+4 
 
Evaluation of the impact of the part-of-speech 
parameter on the training process 
A POS tagging (POS1) task was performed on a 
sequence of tokens produced from the tokeniza-
tion task. A window size of +2/ -2 tokens centered 
at the focus token. We made another POS tag-
ging (POS2) task by adding the last two charac-
ters as an extra feature for enhancing the accura-
cy of some tags such as plural or dual noun 
(NNS) and singular noun (NN). For illustration 
see POS1 and POS2 tasks in Figure 4. The result 
of the evaluation of the two POS tagging tasks is 
shown in Table 5. 
 
 
Figure 4: POS evaluations with window size of -2/+2; 
with and without using the last two characters as an 
added feature 
Measurement POS1 POS2 
Accuracy 94.34% 95.97% 
Table 5: POS results for different window sizes 
 
Evaluation of the impact of chunking parame-
ters on the training process 
The chunking task was performed on tokens pro-
duced from the tokenization and POS tasks. The 
evaluation included 16 tag-set (features) of a 
window size of -2/+2 for both tokens and POS, 
and only the previous two chunk tags. For illu-
stration see Figure 5. The result of the evaluation 
of is shown in Table 6. 
 
Figure 5: Chunk evaluation with window size of -2/+2 
 
Measurement Results 
Accuracy 95.52% 
Precision 93.19% 
Recall 95.90% 
F-Measure 94.52% 
Table 6: Results for BP-chunk 
32
 
Evaluation of the impact case-ending parame-
ters on the training process 
Two case-ending tasks were performed. The 
first case-ending (CE1) task was discussed in a 
previous work (Abo Bakr et al, 2008). It was 
performed on window size of -3/+3 and 8 tag 
sets. For illustration see Figure 6. 
 
Figure 6: Case-ending evaluation with window size of 
-3/+3 
 
The evaluation has achieved 95.35% in accu-
racy. We noticed that in some cases the system 
can produce unacceptable case ending (e.g., 
Tanween on the sound plural masculine ? ???
?????? ???????) that we could improved by: 
1- Enhancing the POS tagging (POS2) task 
by adding last two characters (L2Ch) as 
a feature.  
2- Enhancing the case ending (CE2) task by 
adding the last character (LCh) and the 
last two characters (L2Ch) as features. 
 
 
Figure 7: Case-Ending evaluation with widow size of 
-3/3 and using the last two characters (L2Ch) and the 
last character (LCh) as added features 
 
The following modifications were done to 
conduct the second case-ending (CE2) task, for 
illustration see Figure 7:  
? Adding the last two characters (L2Ch) and 
the last character (LCh) as features.  
? Enhancing the case ending representation by 
adding an extra tagset for ?indeclension of 
the fatha? - ????? ??? ?????? that is presented in 
Treebank as ?PVSUFF_SUNJ:3MS?. 
 
Table 7 presents the results obtained for the two 
case ending (CE1 and CE2) tasks. As shown, the 
performance is improved.  
 
 Measurement CE1 CE2 
Accuracy 95.35% 96.57% 
Table 7: Results of Case Ending evaluation 
5.2 Diacritization Results 
In this section, we compare our approach of To-
kenization and POS tagger with Ara-
bicSVMTools tagger. We evaluate the impact of 
including and excluding different techniques of 
internal diacritization and case-ending on the 
overall performance of our Arabic diacritizer. In 
particular, we show the results from the follow-
ing techniques:  lexicon retrieval (LR), diacri-
tized bigram (DB), SVM, and case-ending (CE), 
techniques. Results for different combinations 
were reported and compared. All results were 
performed using TOK1, POS1, and CE1 tasks 
and shown in Table 8 through Table 10. 
 
Including CE Excluding CE6
Technique WER DER WER DER
LR 90.35% 40.85%? 31.38%? 36.67%
SVM 69.94% 23.36%? 16.28%? 11.36%
Table 8: WER and DER for Lexicon Retrieval and 
Statistical SVM techniques for including and exclud-
ing case ending 
 
Table 8 shows that excluding case ending (letter) 
from the evaluation gives better results in terms 
of WER and DER.  
As shown in Table 9, it is noted that including 
the case ending technique has enhanced dramati-
cally the results of diacritic restoration. Further 
enhancement was obtained by adopting a new 
method to restore internal diacritics, when all of 
the hybrid techniques fail to return any solution; 
the new method, we call it ?accepts any? (AA), 
                                                 
6 Results for ?Excluding CE? are calculated manually for a 
limited number of test files because Case-Ending diacritic is 
not always at the last character.  
33
is used for arbitrary accepting results from lex-
icon. 
 
Technique WER DER
LR+DB? 35.81%? 9.77%
LR+DB+SVM? 33.51%? 7.99%
LR+DB+SVM+CE 17.31% 4.41%
LR+DB+SVM+CE+AA 16.66%? 3.84%
Table 9: WER and DER for different combination of 
diacritization techniques 
 
To investigate the effect of enhancing POS tag-
ging on the internal SVM statistical technique, 
we adapted our modules to interact with Ara-
bicSVMTools, the up-to-date most famous free 
tagger7.  Some modification were made to our 
module to accept the article ?Al? as it may occur 
as radical letters inside the Noun (we handle ?Al? 
separately in our tokenizer). We evaluated our 
statistical diacritization approach using Ara-
bicSVMTools and our proposed tagger. The use 
of ArabicSVMTools has improved the perfor-
mance of our diacrtizer as shown in Table 10. 
ArabicSVMTools gave better results than our 
proposed tagger. However, our proposed tagger 
is about 4 times faster than ArabicSVMTools 
because we use less features. 
 
Tagger WER DER
ArabicSVMTools  12.79% 9.94% 
Proposed SVM  16.28% 11.36% 
Table 10: WER and DER for statistical approach us-
ing different taggers without considering case-ending 
diacritics. 
 
Table 11, shows the results after modifying both 
the statistical and the case ending approaches for 
TOK2, POS2, and CE2 tasks. The last row 
represent results after adding some simple heu-
ristic rules (SHR) to correctly add Tanween Ka-
sra instead of Tanween el Fatha in case of sound 
plural  feminine "??? ?????? ??????" . 
 
Technique WER DER
LR+DB+SVM 31.86% 7.92% 
LS+DB+SVM+CE 12.16% 3.78% 
LS+DB+SVM+CE+SHR 11.795% 3.245%
Table 11: WER and DER for different techniques 
                                                 
7 ArabicSVMTools: 
http://www.cs.columbia.edu/~mdiab/downloads/ArabicSV
MTools.tar.gz 
 
6 Conclusions and Future work 
In this paper, we proposed a diacritization model 
that distinguishes between internal and case end-
ing diacritization. The overall performance is 
comparable with the best diacritization model 
that was reported in the literature so far. 
Statistically based methods show great promise 
in addressing the ambiguity resolution problem 
in Arabic language diacritization.  
The proposed system yields good results in the 
DER and WER compared with MADA-D sys-
tem, the modifications for case ending algorithm 
have enhanced the performance. 
The proposed system has an advantage that we 
can use all internal diacritics approaches in paral-
lel because there is no such dependency between 
algorithms. Nevertheless, the case ending algo-
rithm can also be processed in parallel with the 
statistical approach. Such parallel processing ad-
vantage can improve the response time that could 
be critical for some diacritization-based real time 
systems. 
Maintaining the bigram database up-to-date will 
significantly enhance the performance of the sys-
tem. 
Our future work will include adding some heu-
ristic rules for the proposed model as a post 
processing. This  will enhance the performance 
for the system especially to restore correct dia-
critics of the possessive personal pronounce suf-
fixes ? ?????? ?. Moreover, adding extra POS tag 
sets to distinguish between dual noun and plural 
nouns will enhance the diacritization results. We 
plan also to enrich the system by increasing the 
training set by using latest fully diacritized Tree-
bank like Part1 V3.0 (Maamouri et al 2008) 
which is not available due to limitation of our 
budget. This has the effect of enhancing the sys-
tem performance and allow us to make a compar-
ison with other systems, such as (Habash and 
Rambow, 2007) and (Zitouni et al , 2006) . 
 
References 
Abo Bakr H. M. , Shaalan K., Ziedan I., 2008, "A 
Statistical Method for Adding Case Ending Diacrit-
ics for Arabic Text", The Eighth Conference on 
Language Engineering, ESOLEC?2008, Page 225-
234, Cairo, Egypt,Deceber 17-18 2008. 
Ananthakrishnan, Narayanan S., and Bangalore S., 
(2005), ?Automatic diacritization of arabic tran-
scripts for asr?. In Proceedings of ICON-05, Kan-
pur, India. 
Buckwalter T., (2002). Buckwalter Arabic morpho-
logical analyzer version 1.0. Technical report, Lin-
34
guistic Data Consortium, LDC2002L49 and ISBN 
1-58563- 257-0.  
Cristianini N. and Taylor J.S., (2000), ?An Introduc-
tion to Support Vector Machines and Other Kernel-
based Learning Methods?, The Press Syndicate of 
the University of Cambridge, Cambridge, United 
Kingdom. 
Diab M., Hacioglu K., and Jurafsky D., (2004), "Au-
tomatic Tagging of Arabic Text: From Raw Text to 
Base Phrase Chunks," In Proc. of HLT/NAACL 
2004, Boston. 
Diab M., Hacioglu K., and Jurafsky D.,(2007), ?Arab-
ic Computational Morphology Knowledge-based 
and Empirical Methods? - Chapter 7 ?Automatic 
Processing of Modern Standard Arabic 
Text?,ISBN: 978-1-4020-6046-5, SpringerLink. 
El-Imam Y., (2003). Phonetization of Arabic: rules 
and algorithms. Computer Speech and Language, 
18:339? 373. 
El-Sadany T. and Hashish M., (1988). Semi-
automatic vowelization of Arabic verbs.  In 10th 
NC Conference, Jeddah, Saudi Arabia. 
Elshafei M., Al-Muhtaseb H., and Alghamdi M., 
(2006), ?Statistical Methods for Automatic Diacri-
tization of Arabic Text?. The Saudi 18th National 
Computer Conference. Riyadh. 18: 301-306. 
Emam O. and Fisher V. (2004)., A hierarchical ap-
proach for the statistical vowelization of Arabic 
text. Technical report, IBM patent filed, DE9-2004-
0006, US patent application US2005/0192809 A1. 
Gal Y., (2002). An HMM approach to vowel restora-
tion in Arabic and Hebrew. In ACL-02 Workshop 
on Computational Approaches to Semitic Languag-
es. 
Habash N. and Rambow O., (2007), ?Arabic Diacriti-
zation through Full Morphological Tagging?, In 
Proceedings of the North American chapter of the 
Association for Computational Linguistics 
(NAACL), Rochester, New York. 
Hearst M. A., (1998), "Support Vector Machines," 
IEEE Intelligent Systems, vol. 13,  no. 4,  pp. 18-
28,  Jul/Aug,  1998. 
Kirchhoff K. and Vergyri D., (2005). Cross-dialectal 
data sharing for acoustic modeling in Arabic speech 
recognition. Speech Communication, 46(1):37?51, 
May.  
Kudo T. and Matsumoto Y., (2003), " Fast methods 
for kernel-based text analysis," In Proceedings of 
the 41st Annual Meeting on Association For Com-
putational Linguistics - Volume 1 (Sapporo, Japan, 
July 07 - 12, 2003). Annual Meeting of the ACL. 
Association for Computational Linguistics, Morris-
town. 
Maamouri, M., Bies, A. & Buckwalter, T. (2004). The 
Penn Arabic treebank: Building a largescale anno-
tated Arabic corpus. In NEMLAR Conference on 
Arabic Language Resources and Tools, Cairo, 
Egypt. 
Maamouri M., Bies A., Kulick S., (2008), "Enhanced 
Annotation and Parsing of the Arabic Treebank"; 
INFOS 2008, Cairo, Egypt, March 27-29, 2008. 
Sang E. and Buchholz S., (2000), ? Introduction to the 
CoNLL-2000 Shared Task: Chunking?, Proceeding 
of CoNLL-2000 and LLL-2000,Page 127-132, Lis-
bon,Portugal. 
Zitouni I., Sorensen J. S., and Sarikaya R., (2006), 
?Maximum entropy based restoration of Arabic di-
acritics?. In Proceedings of ACL?06. 
35
A Survey of Arabic Named Entity
Recognition and Classification
Khaled Shaalan?
School of Informatics, University of Edinburgh, UK
The British University in Dubai, UAE
As more and more Arabic textual information becomes available through the Web in homes
and businesses, via Internet and Intranet services, there is an urgent need for technologies and
tools to process the relevant information. Named Entity Recognition (NER) is an Information
Extraction task that has become an integral part of many other Natural Language Processing
(NLP) tasks, such as Machine Translation and Information Retrieval. Arabic NER has begun
to receive attention in recent years. The characteristics and peculiarities of Arabic, a member
of the Semitic languages family, make dealing with NER a challenge. The performance of
an Arabic NER component affects the overall performance of the NLP system in a positive
manner. This article attempts to describe and detail the recent increase in interest and progress
made in Arabic NER research. The importance of the NER task is demonstrated, the main
characteristics of the Arabic language are highlighted, and the aspects of standardization in
annotating named entities are illustrated. Moreover, the different Arabic linguistic resources
are presented and the approaches used in Arabic NER field are explained. The features of
common tools used in Arabic NER are described, and standard evaluation metrics are illustrated.
In addition, a review of the state of the art of Arabic NER research is discussed. Finally,
we present our conclusions. Throughout the presentation, illustrative examples are used for
clarification.
1. Introduction
In the 1990s, in particular at the Message Understanding Conferences, Named Entity
Recognition (NER) was first introduced as an information extraction task and deemed
important by the research community. In NER, the expression ?named entity? (NE)
covers not only proper names but also includes temporal expressions and some nu-
merical expressions such as monetary amounts and other types of units. Proper names
include three classic specializations (referred to as types or classes in the literature):
persons, locations, and organizations. For example, in the sentence Ahmed Khaled, CEO
of Arabisoft Company in Egypt, Ahmed Khaled, Arabisoft Company, and Egypt would be
identified as references to a person, an organization, and a location, respectively. A type
can in turn be divided into subtypes (Sekine, Sudo, and Nobata 2002), possibly forming
an entity type hierarchy (Pappu 2009). For example, locations might be divided into
? The British University in Dubai (BUiD), P.O. Box 345015, Dubai, UAE.
E-mail: khaled.shaalan@buid.ac.ae.
Submission received: 12 September 2012; revised submission received: 12 March 2013; accepted for
publication: 17 July 2013.
doi:10.1162/COLI a 00178
? 2014 Association for Computational Linguistics
Computational Linguistics Volume 40, Number 2
multiple fine-grained locations, such as city, state, and country. For specific needs other
types might be introduced, such as e-mail address, phone number, book ISBN, filename,
and so on.
A good portion of NER research is devoted to the study of English, due to its signif-
icance as a dominant language that is used internationally for communications, science,
information technology, business, seafaring, aviation, entertainment, and diplomacy.
This has limited the diversity of text genre and domain factors from other languages
that are usually considered when developing NER for these fields. For instance, as
most scientific studies are conducted in English in almost all Arabic-speaking countries,
there is no urgency to investigate Arabic NER for areas such as bioinformatics, drug, or
chemical named entities.
NER can be defined as the task that attempts to locate, extract, and automatically
classify named entities into predefined classes or types in open-domain and unstruc-
tured texts, such as newspaper articles (Nadeau and Sekine 2007). One obvious reason
for the importance of named entities is their pervasiveness, which is evidenced by the
high frequency, including occurrence and co-occurrence, of named entities in corpora
(cf. Saravanan et al. 2012). Arabic is a language of rich morphology and syntax. Its
characteristics and peculiarities make dealing with it a challenge (Farghaly and Shaalan
2009). The last decade has shown a growing interest in addressing challenges that
underlie the development of a productive and robust Arabic NER system (Al-Jumaily
et al. 2012; Oudah and Shaalan 2012).
This article investigates the progress in Arabic NER research. The survey byNadeau
and Sekine (2007) presents background on much of the work on NER for a variety of
languages and myriad machine learning (ML) techniques. To the best of our knowl-
edge, Arabic NER and classification have not yet been surveyed extensively, which has
motivated us to conduct this survey.
The survey is structured as follows. Section 2 provides background information
relevant for working with Arabic NER. Section 3 presents some aspects of the Arabic
language that will allow the reader to appreciate the difficulties associated with Arabic
NER. Section 4 briefly introduces the standard tag sets commonly used to annotate
named entities. Section 5 describes the Arabic NER language-specific resources that are
involved in the NER task. Section 6 gives a brief description of approaches used in
Arabic NER. Section 7 discusses feature selection, which is a critical factor for achieving
better performance for NER systems. Section 8 presents various tools that have been
used in building Arabic NER systems and Section 9 illustrates evaluation techniques
for NER systems. Section 10 presents the state-of-the-art in ArabicNER research. Finally,
the concluding remarks are presented in Section 11.
2. Background
2.1 Entity Tracking
The task of identifying named entities must be distinguished from entity tracking,
which involves identifying mentions, relations, and the co-references that may exist
between them. In this regard, a NE may contain only one mention such as a person
name (e.g., Mohammed Morsi), but when a pronoun is used to refer to the same person,
it is considered another mention of that entity. Moreover, a nominal (e.g., president) can
also be used as a mention to refer to the same NE (cf. Zitouni et al. 2005). It should be
noted that the richness of Arabic morphology allows two mentions to appear in one
470
Shaalan A Survey of Arabic Named Entity Recognition and Classification
word (e.g., A 	J?
KP our president, president-our), where a pronominal ( A 	K, our) can appear
as a suffix pronoun to a nominal (e.g., president ?
KP). A co-reference exists when a
group of mentions refers to the same entity. For example, in the sentence The [Egyptian
President], [Mohammad Morsi], as the [chair of the 15th Non-Aligned Movement summit]
declared opening of the 16th summit, there are three mentions that refer to the same person.
Mentions also include aliases such as Abu Ammar, which refers to the same entity as
Yasser Arafat.
An entity relation may be established between two or more NEs, such as a
person, an organization, a location, or a specific time. Relationships between NEs can be
binary, such as person-affiliation or organization-location, or may involve more entities;
for example, [a person] is in [a place] at [a specific time]. The entity relation is usually
expressed in a predicate form and is used to establish relations such as whether two
persons were working at the same organization at the same time (Ben Hamadou, Odile,
and He?la 2010a).
In summary, it is important to direct attention to the choice of the recognition
unit (i.e., real world NE, mention, co-reference, or relation), because mention detec-
tion, co-reference resolution, and relation extraction are considered more difficult than
the traditional NER task due to the complexity incurred by extracting non-named
mentions, grouping mentions into entities, and deriving semantic relations among
entities.
2.2 The Broader Role of NER
The implications of research in NER for NLP more generally are too obvious to
enumerate. Examples of applications for which NER is useful are shown in this
section.
Information Retrieval. This is the task of identifying and retrieving relevant
documents from a set of data according to an input query. A study by Guo et al.
(2009) has indicated that about 71% of the queries in search engines contain NEs.
Information Retrieval can benefit from NER in two phases (Benajiba, Diab, and Rosso
2009a): firstly, recognizing the NEs within the query; and secondly, recognizing the NEs
within the searched documents, and then extracting the relevant documents taking into
account their classified NEs and how they are related to the query. For example, the
word ?QK
 	Qm.?'@ (Aljazeera) can be recognized as an organization name or a noun corre-
sponding to the word island; the correct classification will facilitate extracting relevant
documents.
Question Answering. This is very similar to Information Retrieval but with more
sophisticated results. A Question Answering system takes questions as input and gives
in return concise and precise answers (Ezzeldin and Shaheen 2012). The NER task can
be utilized in the phase of analyzing the question so as to recognize the NEs within the
question that will help later in identifying the relevant documents and constructing the
answer from relevant passages (Molla?, van Zaanen, and Smith 2006; Badawy, Shaheen,
and Hamadene 2011; Lahsen, Bouzoubaa, and Rosso 2012). For instance, the NE
???

B@ ?Q??? @ (Middle East) may be classified as an organization name (e.g., a newspaper)
or as a location name according to the context. Hence, the correct classification for the
NE will help to target the relevant group of documents that answer the input query.
Moreover, Question Answering systems could benefit substantially from NER, because
the answer to many factoid questions involve NEs (Trigui et al. 2012) (e.g., answers
to who (?? 	??/?
 ?A?) questions usually involve persons or organizations, where (
	?K


@)
471
Computational Linguistics Volume 40, Number 2
questions involve locations, and when (?

??) questions involve temporal expressions)
(Brini et al. 2009).
Machine Translation. This is the task of automatically translating a text from
one natural language into another. NEs need special attention in order to decide
which parts of an NE should be meaning-translated and which parts should be
phoneme-transliterated (Al-Onaizan and Knight 2002b; Hassan and Sorensen 2005).
Usually this depends on the type of the NE (Chen, Yang, and Lin 2003). For example,
personal names tend to be transliterated.1 For a location name, the name part and the
category part (e.g., mountains) are usually transliterated and translated, respectively.
Organization names are completely different in that most of the constituents are
translated (e.g., United Nations). The quality of the NER system plays a significant
role in determining the overall quality of the machine translation system, and
hence, NE translation is critical for most multilingual application systems (Babych
and Hartley 2003; Ben Hamadou, Odile, and He?la 2010b; Steinberger 2012). In
addition, NE translation is very important for other applications such as cross-lingual
information retrieval for extracting newly introduced NEs from the Web and news
documents and regularly updating the list of NE translation pairs (Hassan, Fahmy, and
Hassan 2007).
Text Clustering. Search results clustering may exploit NER by ranking the re-
sulting clusters based on the ratio of entities each cluster contains (Benajiba, Diab,
and Rosso 2009a). This enhances the process of analyzing the nature of each cluster
and also improves the clustering approach in terms of selected features. For example,
time expressions along with location NEs can be utilized as factors that will give an
indication of when and where the events mentioned in a cluster of documents have
occurred.
Navigation Systems. These systems, which facilitate navigation using digital maps,
now play significant roles in our lives. They provide directions, information about
nearby places possibly linked with other on-line resources, and traffic conditions. In
these systems, points of interest (also known as waypoints) are NEs that are stored in
a database with their geographic coordinates (Kim, Kim, and Cho 2012). They refer to
areas of interest that are typically of significance to, among others, tourists, visitors,
and rescuers, allowing the location of places such as parking areas, shops, hospitals,
restaurants, universities, schools, landmarks, and so on.
3. Linguistic Issues and Challenges
Arabic is a highly inflected language, with a rich morphology and complex syn-
tax (Al-Sughaiyer and Al-Kharashi 2004; Ryding 2005). Current Arabic NLP research
efforts cannot cope with the massive growth of Arabic data on the Internet and
the heightened need for accurate and robust processing tools (Abdul-Mageed, Diab,
and Korayem 2011). NER is considered one of the building blocks of Arabic NLP
tools and applications. Though significant progress has been achieved in Arabic
NER research in the last decade, the task remains challenging due to the following
1 Transliteration is the task of replacing words in the source language with their approximate phonetic or
spelling equivalents in the target language. It unambiguously represents the graphemes, rather than the
phonemes, of the NE. Transliteration between languages that use similar alphabets and sound systems is
very simple. However, transliterating NEs between Arabic and English is a non-trivial task, mainly due
to the differences in their sound and writing systems (Al-Onaizan and Knight 2002a).
472
Shaalan A Survey of Arabic Named Entity Recognition and Classification
features of the Arabic language; opportunities for improved performance are still
available.
3.1 Arabic Script
The Arabic language relies on the Arabic script, which is also used in writing other
languages such as Persian, Urdu, Kurdish, and Pashto (Habash 2010). Some researchers
have developed Arabic computational tools and resources based on Romanized2
or transliterated3 Arabic text rather than genuine Arabic script (e.g., Buckwalter?s
Arabic Morphological Analyzer [Buckwalter 2002], the CJK lexical resources [Halpern
2009], and Arabic NER systems [Bidhend, Minaei-Bidgoli, and Jouzi 2012; Zayed
and El-Beltagy 2012]), either because these formats are more familiar to non-native
Arabic speakers or because of limitations in the Arabic script encoding imposed by
the development environment. This approach should disappear over time with the
rapidly growing quantity of Arabic script-based Web content and new technologies
that support multiple encodings.
3.2 Language in Use
With regard to language usage, Arabic can be classified into three types (Elgibali
2005): Classical Arabic (CA), Modern Standard Arabic (MSA), and Colloquial Arabic
Dialects (Abdel Monem et al. 2008; Habash 2010; Korayem, Crandall, and Abdul-
Mageed 2012). As far as Arabic NE is concerned, it is important to know the difference
between these various uses of the language. CA is the formal version that has been
used continuously for over 1,500 years as the language of Islam, used by Muslims
in their daily prayers. Most Arabic religious texts are written in CA. In this context,
person name recognition is of particular interest in order to identify and verify
the correctness of citations (Zaraket and Makhlouta 2012) (a sequence of hadith
narrators referencing each other who provide narrations related to the Prophet
Mohammed based on known truthful and untruthful relaters). The importance of
verification is that the authenticity of a hadith needs to be established before his
narration is used in jurisprudence, and this depends on the credibility of the narrators.
Furthermore, many historical Arabic manuscripts are handwritten in CA (or Arabic
calligraphy); when they are digitized and converted to text, Arabic NE will become
important.
MSA is the language of today?s Arabic newspapers, magazines, periodicals, letters,
modern writers, and education. MSA is one of the six official languages of the United
Nations used in meetings and official UN documents. Most Arabic NLP, including NER
research projects, is focused on MSA. The main difference between MSA and CA lies
in the vocabulary, including NEs, and the orthography of conventional written Arabic
(Farber et al. 2008): MSA does not require the inclusion of short vowels. Moreover, MSA
reflects the needs of contemporary expression, whereas CA reflects the needs of older
styles. For example, the Arabic NEs in rare documents and old manuscripts that refer
2 Transliteration from Arabic to languages using the Latin alphabet is called Romanization.
3 In a multilingual context, transliteration of NEs would differ depending on the target language
(Pouliquenet et al. 2005). For example, the Arabic name ?

	???? could be transliterated into English
as Mustafa or Moustapha, while a likely French transliteration would be Moustafa or Moustapha.
473
Computational Linguistics Volume 40, Number 2
to places, jobs, or organizations are different from the corresponding NEs in modern
documents.
Colloquial Arabic is the spoken Arabic used by Arabs in their informal daily com-
munication; it is not taught in schools due to its irregularity. Unlike the widespread
use of MSA across all Arab countries, colloquial Arabic is a regional variant that
differs not only among Arab countries, but also across regions in the same country.
Written Colloquial Arabic is presently used mainly in social media communication.
For comparison, a person name in either CA or MSA could be expressed in Arabic
dialect by more than one form; for example, PXA?? @ YJ.? (Abd Al-Kader) versus PXAm.?'@ YJ.?
(Abd Al-Gader) or PX

B@ YJ.? (Abd Al-Aader). Salloum and Habash (2012) presented a
universal machine translation pre-processing approach that has the ability to produce
MSA paraphrases of dialectal input. In this way, available MSA tools can also be used
to process Colloquial Arabic text, as most of the Arabic NER systems are developed to
support MSA.
3.3 Lack of Capitalization
Unlike languages like English that use the Latin script, where most NEs begin with
a capital letter, capitalization is not a distinguishing orthographic feature of Arabic
script for recognizing NEs such as proper names, acronyms, and abbreviations (Farber
et al. 2008). The ambiguity caused by the absence of this feature is further increased
by the fact that most Arabic proper nouns (NEs) are indistinguishable from forms
that are common nouns and adjectives (non-NEs). Thus, an approach relying only
on looking up entries in proper noun dictionaries would not be an appropriate way
to tackle this problem, as ambiguous tokens/words that fall in this category are
more likely to be used as non-proper nouns in text (Algahtani 2011). For example,
the Arabic proper name 	?Q??

@ (Ashraf ) can be used in a sentence as a given name,
an inflected verb (he-supervised), and a superlative (the-most-honorable) (Mesfar 2007).
An NE is usually found in a context, namely, with trigger and cue words to the left
and/or right of the NE. Therefore, it is common to resolve this type of ambiguity by
analyzing the context surrounding the NE. However, this might require deeper analysis
of the NE?s context. As an example, consider the nominal sentence ?Ym.Proceedings of the 10th International Workshop on Finite State Methods and Natural Language Processing, pages 20?24,
Donostia?San Sebastia?n, July 23?25, 2012. c?2012 Association for Computational Linguistics
Handling Unknown Words in Arabic FST Morphology 
  Khaled Shaalan and Mohammed Attia Faculty of Engineering & IT, The British University in Dubai khaled.shaalan@buid.ac.ae mohammed.attia@buid.ac.ae         Abstract 
A morphological analyser only recognizes words that it already knows in the lexical database. It needs, however, a way of sensing significant changes in the language in the form of newly borrowed or coined words with high frequency. We develop a finite-state morphological guesser in a pipelined methodology for extracting unknown words, lemmatizing them, and giving them a priority weight for inclusion in a lexicon. The processing is performed on a large contemporary corpus of 1,089,111,204 words and passed through a machine-learning-based annotation tool. Our method is tested on a manually-annotated gold standard of 1,310 forms and yields good results despite the complexity of the task. Our work shows the usability of a highly non-deterministic finite state guesser in a practical and complex application. 
1 Introduction Due to the complex and semi-algorithmic nature of the Arabic morphology, it has always been a challenge for computational processing and analysis (Kiraz, 2001; Beesley 2003; Shaalan et al, 2012). A lexicon is an indispensable part of a morphological analyser (Dichy and Farghaly, 2003; Attia, 2006; Buckwalter, 2004; Beesley, 2001), and the coverage of the lexical database is a key factor in the coverage of the morphological analyser. This is why an automatic method for updating a lexical database is crucially important. 
 We present the first attempt, to the best of our knowledge, to address lemmatization of Arabic unknown words. The specific problem with lemmatizing unknown words is that they cannot be matched against a morphological lexicon. We develop a rule-based finite-state morphological guesser and use a machine learning disambiguator, MADA (Roth et al, 2008), in a pipelined approach to lemmatization.   This paper is structured as follows. The remainder of the introduction reviews previous work on Arabic unknown word extraction and lemmatization, and explains the data used in our experiments. Section 2 presents the methodology followed in extracting and analysing unknown words. Section 3 provides details on the morphological guesser we have developed to help deal with the problem. Section 4 shows and discusses the testing and evaluation results, and finally Section 5 gives the conclusion. 1.1 Previous Work Lemmatization of Arabic words has been addressed in (Roth et al, 2008; Dichy, 2001). Lemmatization of unknown words has been addressed for Slovene in (Erjavec and D?erosk, 2004), for Hebrew in (Adler at al., 2008) and for English, Finnish, Swedish and Swahili in (Lind?n, 2008). Lemmatization means the normalization of text data by reducing surface forms to their canonical underlying representations, which, in Arabic, means verbs in their perfective, indicative, 3rd person, masculine, singular forms, such as  ?????? 
20
$akara ?to thank?; and nominals in their nominative, singular, masculine forms, such as ?????? TAlib ?student?; and nominative plural for pluralia tantum nouns (or nouns that appear only in the plural form and are not derived from a singular word), such as ???? nAs ?people?. To the best of our knowledge, the study presented here is the first to address lemmatization of Arabic unknown words. The specific problem with lemmatizing unknown words is that they cannot be matched against a lexicon. In our method, we use a machine learning disambiguator, develop a rule-based finite-state morphological guesser, and combine them in a pipelined process of lemmatization. We test our method against a manually created gold standard of 1,310 types (unique forms) and show a significant improvement over the baseline. Furthermore, we develop an algorithm for weighting and prioritizing new words for inclusion in a lexicon depending on three factors: number of form variations of the lemmas, cumulative frequency of the forms, and POS tags.  1.2 Data Used In our work we rely on a large-scale corpus of 1,089,111,204 words, consisting of 925,461,707 words from the Arabic Gigaword Fourth Edition (Parker et al, 2009), and 163,649,497 words from news articles collected from the Al-Jazeera web site.1 In this corpus, unknown words appear at a rate of between 2% of word tokens (when we ignore possible spelling variants) and 9% of word tokens (when possible spelling variants are included).  2 Methodology To deal with unknown words, or out-of-vocabulary words (OOVs), we use a pipelined approach, which predicts part-of-speech tags and morpho-syntactic features before lemmatization. First, a machine learning, context-sensitive tool is used. This tool, MADA (Roth et al, 2008), performs POS tagging and morpho-syntactic analysis and disambiguation of words in context. MADA internally uses the Standard Arabic Morphological Analyser (SAMA) (Maamouri et al, 2010), an updated version of Buckalter Arabic                                                             1 http://aljazeera.net/portal. Collected in January 2010. 
Morphological  Analyser (BAMA) (Buckwalter, 2004). Second, we develop a finite-state morphological guesser that gives all possible interpretations of a given word. The morphological guesser first takes an Arabic form as a whole and then strips off all possible affixes and clitics one by one until all potential analyses are exhausted. As the morphological guesser is highly non-deterministic, all the interpretations are matched against the morphological analysis of MADA that receives the highest probabilistic scores. The guesser?s analysis that bears the closest resemblance (in terms of morphological features) with the MADA analysis is selected.  These are the steps followed in extracting and lemmatizing Arabic unknown words: ? A corpus of 1,089,111,204 is analysed with MADA. The number of types for which MADA could not find an analysis in SAMA is 2,116,180.  ? These unknown types are spell checked by the Microsoft Arabic spell checker using MS Office 2010. Among the unknown types, the number of types accepted as correctly spelt is 208,188. ? We then select types with frequency of 10 or more. This leave us with 40,277 types. ? We randomly select 1,310 types and manually annotate them with the gold lemma, the gold POS and lexicographic preference for inclusion in a dictionary. ? We use the full POS tags and morpho-syntactic features produced by MADA. ? We use the finite-state morphological guesser to produce all possible morphological inter-pretations and corresponding lemmatizations. ? We compare the POS tags and morpho-syntactic features in MADA output with the output of the morphological guesser and choose the one with the highest matching score.  3 Morphological Guesser We develop a morphological guesser for Arabic that analyses unknown words with all possible clitics, morpho-syntactic affixes and all relevant alteration operations that include insertion, assimilation, and deletion. Beesley and Karttunen 
21
(2003) show how to create a basic guesser. The core idea of a guesser is to assume that a stem is composed of any arbitrary sequence of Arabic non-numeric characters, and this stem can be prefixed and/or suffixed with a predefined set of prefixes, suffixes or clitics. The guesser marks clitic boundaries and tries to return the stem to its underlying representation, the lemma. Due to the nondeterministic nature of the guesser, there will be a large number of possible lemmas for each form.   The XFST finite-state compiler (Beesley and Karttunen, 2003) uses the ?substitute defined? command for creating the guesser. The XFST commands in our guesser are stated as follows.   define PossNounStem [[Alphabet]^{2,24}] "+Guess":0; define PossVerbStem [[Alphabet]^{2,6}] "+Guess":0;  This rule states that a possible noun stem is defined as any sequence of Arabic non-numeric characters of length between 2 and 24 characters.  A possible verb stem is between 2 and 6 characters. The length is the only constraint applied to an Arabic word stem. This word stem is surrounded by prefixes, suffixes, proclitics and enclitics. Clitics are considered as independent tokens and are separated by the ?@? sign, while prefixes and suffixes are considered as morpho-syntactic features and are interpreted with tags preceded by the ?+? sign. Below we present the analysis of the unknown noun  ????? ???????????? wa-Al-musaw~iquwna ?and-the-marketers?.  MADA output: form:wAlmswqwn num:p gen:m per:na case:n asp:na mod:na vox:na pos:noun prc0:Al_det prc1:0 prc2:wa_conj prc3:0 enc0:0 stt:d  Finite-state guesser output: ???????????? +adj??????????+Guess+masc+pl+nom@ ???????????? +adj????????????+Guess+sg@ ???????????? +noun??????????+Guess+masc+pl+nom@ ???????????? +noun????????????+Guess+sg@ ?? ????????????+conj@????+defArt@+adj?????  +Guess+masc+pl+nom@ ?? ????????????+conj@????+defArt@+adj??????? 
 +Guess+sg@ ?? ????????????+conj@????+defArt@+noun?????  +Guess+masc+pl+nom@ ?? ????????????+conj@????+defArt@+noun???????  +Guess+sg@ ?? ????????????+conj@+adj????????+Guess+masc  +pl+nom@ ?? ????????????+conj@+adj??????????+Guess+sg@ ?? ????????????+conj@+noun????????+Guess+masc  +pl+nom@ ?? ????????????+conj@+noun??????????+Guess+sg@  For a list of 40,277 word types, the morphological guesser gives an average of 12.6 possible interpretations per word. This is highly non-deterministic when compared to AraComLex morphological analyser (Attia et al 2011) which has an average of 2.1 solutions per word. We also note that 97% of the gold lemmas are found among the finite-state guesser's choices.  4 Testing and Evaluation To evaluate our methodology we create a manually annotated gold standard test suite of randomly selected surface form types. For these surface forms, the gold lemma and part of speech are manually given. Besides, the human annotator gives a preference on whether or not to include the entry in a dictionary. This feature helps to evaluate our lemma weighting equation. The annotator tends to include nouns, verbs and adjectives, and only proper nouns that have a high frequency. The size of the test suite is 1,310.   4.1 Evaluating Lemmatization In the evaluation experiment we measure accuracy calculated as the number of correct tags divided by the count of all tags. The baseline is given by the assumption that new words appear in their base form, i.e., we do not need to lemmatize them. The baseline accuracy is 45% as shown in Table 1. The POS tagging baseline proposes the most frequent tag (proper name) for all unknown words. In our test data this stands at 45%. We notice that MADA POS tagging accuracy is unexpectedly low (60%). We use Voted POS Tagging, that is when a lemma gets a different POS tag with a higher frequency, the new tag replaces the old low frequency tag. 
22
This method has improved the tagging results significantly (69%).    Accuracy  POS tagging 1 POS Tagging baseline 45% 2 MADA POS tagging 60% 3 Voted POS Tagging 69% Table 1. Evaluation of POS tagging  As for the lemmatization process itself, we notice that our experiment in the pipelined lemmatization approach gains a higher (54%) score than the baseline (45%) as shown in Table 2. This score significantly rises to 63% when the difference in the definite article ?Al? is ignored. The testing results indicate significant improvements over the baseline.   Lemmatization 1 Lemmas found among corpus forms 64% 2 Lemmas found among FST guesser forms 97% 3 Lemma first-order baseline 45% 4 Pipelined lemmatization (first-order decision) with strict definite article matching 54% 5 Pipelined lemmatization  (first-order decision) ignoring definite article matching 63% Table 2. Evaluation of lemmatization  4.2 Evaluating Lemma Weighting In our data we have 40,277 unknown token types. After lemmatization they are reduced to 18,399 types (that is 54% reduction of the surface forms) which are presumably ready for manual validation before being included in a lexicon. This number is still too big for manual inspection. In order to facilitate human revision, we devise a weighting algorithm for ranking so that the top n number of words will include the most lexicographically relevant words. We call surface forms that share the same lemma ?sister forms?, and we call the lemma that they share the ?mother lemma?. This weighting algorithm is based on three criteria: frequency of the sister forms, number of sister forms, and a POS factor which penalizes proper nouns (due to their disproportionate high frequency). The parameters of the weighting 
algorithm has been tuned through several rounds of experimentation.  Word Weight = ((number of sister forms having the same mother lemma * 800) + cumulative sum of frequencies of sister forms having the same mother lemma) / 2 + POS factor  Good words In top 100 In bottom 100 relying on Frequency alone (baseline) 63 50 relying on number of sister forms * 800 87 28 relying on POS factor 58 30 using the combined criteria 78 15 Table 3. Evaluation of lemma weighting and ranking  Table 3 shows the evaluation of the weighting  criteria. We notice that the combined criteria gives the best balance between increasing the number of good words in the top 100 words and reducing the number of good words in the bottom 100 words.  5 Conclusion We develop a methodology for automatically extracting unknown words in Arabic and lemmatizing them in order to relate multiple surface forms to their base underlying representation using a finite-state guesser and a machine learning tool for disambiguation. We develop a weighting mechanism for simulating a human decision on whether or not to include the new words in a general-domain lexical database. We show the feasibility of a highly non-deterministic finite state guesser in an essential and practical application.  Out of a word list of 40,255 unknown words, we create a lexicon of 18,399 lemmatized, POS-tagged and weighted entries. We make our unknown word lexicon available as a free open-source resource2. Acknowledgments This research is funded by the UAE National Research Foundation (NRF) (Grant No. 0514/2011).                                                             2 http://arabic-unknowns.sourceforge.net/ 
23
References  Adler, M., Goldberg, Y., Gabay, D. and Elhadad, M. 2008. Unsupervised Lexicon-Based Resolution of Unknown Words for Full Morpholological Analysis. In: Proceedings of Association for Computational Linguistics (ACL), Columbus, Ohio. Attia, M. 2006. An Ambiguity-Controlled Morpho-logical Analyzer for Modern Standard Arabic Modelling Finite State Networks. In: Challenges of Arabic for NLP/MT Conference, The British Computer Society, London, UK. Attia, Mohammed, Pavel Pecina, Lamia Tounsi, Antonio Toral, Josef van Genabith. 2011. An Open-Source Finite State Morphological Transducer for Modern Standard Arabic. International Workshop on Finite State Methods and Natural Language Processing (FSMNLP). Blois, France. Beesley, K. R. 2001. Finite-State Morphological Analysis and Generation of Arabic at Xerox Research: Status and Plans in 2001. In: The ACL 2001 Workshop on Arabic Language Processing: Status and Prospects, Toulouse, France. Beesley, K. R., and Karttunen, L.. 2003. Finite State Morphology: CSLI studies in computational linguistics. Stanford, Calif.: Csli. Buckwalter, T. 2004. Buckwalter Arabic Morphological Analyzer (BAMA) Version 2.0. Linguistic Data Consortium (LDC) catalogue number LDC2004L02, ISBN1-58563-324-0 Dichy, J. 2001. On lemmatization in Arabic, A formal definition of the Arabic entries of multilingual lexical databases. ACL/EACL 2001 Workshop on Arabic Language Processing: Status and Prospects. Toulouse, France. Dichy, J., and Farghaly, A. 2003. Roots & Patterns vs. Stems plus Grammar-Lexis Specifications: on what basis should a multilingual lexical database centred on Arabic be built? In: The MT-Summit IX workshop on Machine Translation for Semitic Languages, New Orleans. Erjavec, T., and D?erosk, S. 2004. Machine Learning of Morphosyntactic Structure: Lemmatizing Unknown Slovene Words. Applied Artificial Intelligence, 18:17?41. Kiraz, G. A. 2001. Computational Nonlinear Morphology: With Emphasis on Semitic Languages. Cambridge University Press. Lind?n, K. 2008. A Probabilistic Model for Guessing Base Forms of New Words by Analogy. In CICling-2008, 9th International Conference on Intelligent 
Text Processing and Computational Linguistics, Haifa, Israel, pp. 106-116. Maamouri, M., Graff, D., Bouziri, B., Krouna, S., and Kulick, S. 2010. LDC Standard Arabic Morphological Analyzer (SAMA) v. 3.1. LDC Catalog No. LDC2010L01. ISBN: 1-58563-555-3. Parker, R., Graff, D., Chen, K., Kong, J., and Maeda, K. 2009. Arabic Gigaword Fourth Edition. LDC Catalog No. LDC2009T30. ISBN: 1-58563-532-4. Roth, R., Rambow, O., Habash, N., Diab, M., and Rudin, C. 2008. Arabic Morphological Tagging, Diacritization, and Lemmatization Using Lexeme Models and Feature Ranking. In: Proceedings of Association for Computational Linguistics (ACL), Columbus, Ohio. Shaalan, K., Magdy, M., Fahmy, A., Morphological Analysis of Il-formed Arabic Verbs for Second Language Learners, In Eds. McCarthy P., Boonthum, C., Applied Natural Language Processing: Identification, Investigation and Resolution, PP. 383-397, IGI Global, PA, USA, 2012.  
24
