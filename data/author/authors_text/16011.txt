2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 731?741,
Montre?al, Canada, June 3-8, 2012. c?2012 Association for Computational Linguistics
Exploring Semi-Supervised Coreference Resolution of Medical Concepts
using Semantic and Temporal Features
Preethi Raghavan?, Eric Fosler-Lussier?, and Albert M. Lai?
?Department of Computer Science and Engineering
?Department of Biomedical Informatics
The Ohio State University, Columbus, Ohio, USA
{raghavap, fosler}@cse.ohio-state.edu, albert.lai@osumc.edu
Abstract
We investigate the task of medical concept
coreference resolution in clinical text using
two semi-supervised methods, co-training and
multi-view learning with posterior regulariza-
tion. By extracting semantic and temporal
features of medical concepts found in clinical
text, we create conditionally independent data
views; co-training MaxEnt classifiers on this
data works almost as well as supervised learn-
ing for the task of pairwise coreference resolu-
tion of medical concepts. We also train Max-
Ent models with expectation constraints, using
posterior regularization, and find that poste-
rior regularization performs comparably to or
slightly better than co-training. We describe
the process of semantic and temporal feature
extraction and demonstrate our methods on a
corpus of case reports from the New England
Journal of Medicine and a corpus of patient
narratives obtained from The Ohio State Uni-
versity Wexner Medical Center.
1 Introduction
The clinical community creates and uses a variety
of semi-structured and unstructured electronic tex-
tual documents that include medical reports such
as admission notes, progress notes, pathology re-
ports, radiology reports and hospital discharge sum-
maries. The documents, collectively termed clini-
cal narratives, account for various medical condi-
tions, procedures, diagnoses and assessments in a
patient?s medical history. Researchers have inves-
tigated ways in which clinical text can be automati-
cally processed for enabling access to relevant infor-
mation for physicians and health researchers (Embi
and Payne, 2009). One application is to support pa-
tient recruitment into clinical trials (research studies
that try to answer scientific questions to find bet-
ter ways to prevent, diagnose, or treat a disease)
by matching patient characteristics against eligibil-
ity criteria (Raghavan and Lai, 2010). While there
has been significant efforts to move to structured
data collection, clinical narratives remain a critical
data source for these tasks.
Extracting structured information from unstruc-
tured clinical text using natural language processing
(NLP) is complicated by the distinct clinical report-
ing sub-language characterized by incomplete sen-
tences and domain specific abbreviations (Friedman
et al, 2002). The large number of clinical narra-
tives generated per patient, over the years, along
with redundant information within and across narra-
tives, further adds to the complexity of using infor-
mation structured using NLP. There is a tendency to
copy and edit parts of an old clinical narrative when-
ever a new one is created, thus leading to redundant
information in clinical narratives of a patient. Fur-
thermore, since different types of clinical narratives
are created for different purposes, certain narratives
may summarize information from various other, at
times older, clinical narratives. All of this makes the
task of automatically processing unstructured clin-
ical narratives significantly difficult. However, the
ability to resolve medical concept coreferences helps
deal with redundant information within and across
clinical narratives and thus produce a unique list of
medical concepts in the patient?s clinical history.
We investigate the task of resolving references to
731
the same medical concept in the clinical narratives
of a patient using supervised and semi-supervised
methods. Our main contributions are as follows:
1. Since manual coreference annotation of patient
narratives is a slow and expensive process and pub-
licly available datasets are difficult to acquire, we
study the application of semi-supervised methods,
co-training and using expectation constraints with
posterior regularization, to medical concept coref-
erence resolution (MCCR).
2. We work with the hypothesis that if two medical
concepts have the same meaning and have occurred
at the same time, there is a very high probability that
they corefer. Based on this hypothesis, we explain
extraction of semantic and temporal feature sets that
are effectively used for MCCR.
3. We propose a method to associate medical con-
cepts with time durations centered around admission
and discharge dates of the patient using CRFs.
4. With the help of corpora created from the New
England Journal of Medicine (NEJM) and actual pa-
tient narratives obtained from the medical center, we
demonstrate that the semi-supervised methods per-
form comparably with supervised learning for pair-
wise MCCR using a MaxEnt classifier.
2 Related Work
Free-text reports form a significant portion of the
information content in a patient?s medical record.
There is great need for tools that can structure the
information in clinical text for use in various stud-
ies studies such as clinical trials, quality assess-
ment of healthcare delivery in institutions, and pub-
lic health research. Researchers have been investi-
gating ways in which clinical free-text can be struc-
tured to transform the information content in a clin-
ical narrative into a representation suitable for com-
putational analysis (Ananiadou et al, 2004). Medi-
cal NLP systems like Mayo?s cTakes (Savova et al,
2010), IBM?s MedKAT,1 and MedLEE (Chiang et
al., 2010), have components specifically trained or
designed for the clinical domain, to support tasks
such as named entity recognition. Previous at-
tempts at learning temporal relations between med-
ical events in clinical text include work by Jung et
1https://cabig-kc.nci.nih.gov/Vocab/KC/
index.php/OHNLP
al. (2011) and Zhou et al (2006). Gaizauskas et
al. (2006) learn the temporal relations before, after,
is included between events from a corpus of clinical
text much like the event-event relation tlink learn-
ing in Timebank (Pustejovsky et al, 2003). A com-
prehensive survey of temporal reasoning in medi-
cal data is provided by Zhou and Hripcsak (2007).
Chapman et al (2011) discuss barriers to NLP de-
velopment in the clinical domain.
Coreference resolution is a well-studied prob-
lem in computational linguistics (Ng, 2010; Raghu-
nathan et al, 2010). Supervised machine learn-
ing algorithms have been previously used for noun
phrase coreference resolution with fairly good re-
sults (Soon et al, 2001; Raghunathan et al, 2010).
Recently, the i2b2 challenge2 on coreference reso-
lution examined coreference resolution in clinical
data. The problem addressed in our paper is simi-
lar to the task described in the i2b2 challenge.3 Be-
sides the i2b2 challenge, there has not been signifi-
cant work in MCCR. This may be due to various pri-
vacy concerns and the efforts required to anonymize
and annotate massive amounts of patient narratives.
Zheng et al (2011) review heuristic-based, super-
vised and unsupervised methods for coreference res-
olution in the context of the clinical domain. He
(2007) studied coreference resolution in discharge
summaries, treating coreference resolution as a bi-
nary classification problem and investigated critical
features for coreference resolution for entities that
fall into five medical semantic categories commonly
appearing in discharge summaries. However, we fo-
cus on feature extraction to determine the similarity
between medical concepts, both in terms of meaning
and time of occurrence, for resolving coreferences
within and across all types of clinical narratives.
A disadvantage of supervised machine learning
approaches is the need for an unknown amount of
annotated training data for optimal performance.
Researchers then began to experiment with weakly
supervised machine learning algorithms such as co-
training (Blum and Mitchell, 1998). Muller et al
(2002) investigate the practical applicability of co-
training for the task of building a classifier for coref-
erence resolution and observed that the results were
2https://www.i2b2.org/NLP/Coreference/
3https://www.i2b2.org/NLP/Coreference/assets/
CoreferenceGuidelines.pdf
732
mostly negative for their dataset.
Ganchev et al (2010) propose a posterior regular-
ization framework for weakly supervised learning to
derive a multi-view learning algorithm. Multi-view
methods typically begin by assuming that each view
alone can yield a good predictor. Under this as-
sumption, we can regularize the models from each
view by constraining the amount by which we per-
mit them to disagree on unlabeled instances. In the
proposed approach, they train a model for each view,
and use constraints that the models should agree on
the label distribution.
We investigate the applicability of these two weakly
supervised methods to the task of MCCR using se-
mantic and temporal views. Savova et al (2011) dis-
cuss the creation of a corpus for coreference resolu-
tion in the clinical narrative. We annotate a corpus of
clinical narratives to tag medical concepts, temporal
relations, and coreference information. We use this
corpus as a gold standard to evaluate the proposed
approach to resolving coreferences between medical
concepts in clinical text.
To summarize, we study the problem of intra and
cross-narrative coreference resolution on longitudi-
nal patient data using relatedness between medical
concepts in terms of semantics and time. Further,
we importantly demonstrate that this task gives us
reasonable results even when modeled as a semi-
supervised problem. Creating annotated clinical cor-
pora is tedious, time consuming, and costly, as it
requires experts with medical domain knowledge.
Thus, the ability to train semi-supervised models
with limited labeled data for MCCR would be of
tremendous value.
3 Problem Description
Coreference resolution in clinical text refers to the
problem of identifying all medical concepts that re-
fer to the same medical concept. Medical con-
cepts are medical entities, events or states associ-
ated with the patient?s medical condition and health-
care. These include medical conditions, drugs ad-
ministered, diseases, procedures and lab tests as well
as normal health situations like pregnancy affecting
the patient?s health. The task of MCCR is similar to
noun phrase coreference resolution. However, med-
ical concepts are not restricted to noun phrases. For
instance, the actions cauterize and cauterization are
both considered medical concepts.
To make the task of identifying medical concepts
from clinical text more deterministic, any contigu-
ous group of words that have a direct or close match
in the Unified Medical Language System (UMLS)
Metathesaurus4 is considered a medical concept.
The UMLS includes a large Metathesaurus of con-
cepts and terms from many biomedical vocabular-
ies and a lexicon which contains syntactic, morpho-
logical, and orthographic information for biomedi-
cal and common words in the English language.
Problem Formulation. Consider a corpus of clini-
cal narratives, where multiple clinical narratives are
associated with each patient. If Pi, i ? {1, 2, ..., n}
where n is the number of patients in corpus, then
for each Pi, we have a set of associated clinical nar-
ratives. Each clinical narrative in turn has a set of
medical concepts. Thus, each Pi has a set of associ-
ated medical concepts, M = {M1,M2,M3, ..} that
occur within each clinical narrative as well as across
clinical narratives for that Pi. We study the problem
of MCCR of all medical concepts in M for each Pi.
4 Semantic and Temporal Features
We extract features based on semantic and tempo-
ral relatedness for each pair of medical concepts.
Semantic relatedness measures closeness between
medical concepts in terms of their meaning. This is
quantified by measuring distance between medical
events in the UMLS Metathesaurus graph structure
(Xiang et al, 2011). Temporal relatedness measures
the closeness between medical concepts in terms of
when they occurred. This is achieved by first, learn-
ing to assign every medical concept to a time-bin,
and then using the time-bin as a feature for learn-
ing to resolve coreferences. Extracting semantic and
temporal features helps identify conditionally inde-
pendent views of the data for co-training classifiers.
As previously noted by Nigam and Ghani (2000), it
is hard to identify conditionally independent views
for real-data problems. However, we believe there
are no natural dependencies between the semantic
and temporal feature sets. While semantic features
help identify synonymous medical concepts, that
alone may not guarantee coreference. Medical con-
4https://uts.nlm.nih.gov/home.html
733
Clinical 
Text 
Semantic Feature 
Extraction 
Temporal Feature 
Extraction using 
CRFs 
Co-train 
Posterior 
Regularization 
Coreference 
decisions 
Section 4 Section 5 
Medical Concept 
Coreference Resolution 
(MCCR) 
OR 
Figure 1: MCCR pipeline: Extract semantic and tempo-
ral features from clinical text to train MaxEnt classifiers
for medical concept coreference resolution using 1) Co-
training or 2) Posterior Regularization
cepts that are similar in meaning, but dissimilar in
terms of their time of occurrence, most probably do
not corefer. Similarly, medical concepts that occur
during the same time duration but are dissimilar in
terms of meaning, most probably do not corefer.
Semantic Relatedness. We leverage the UMLS
to derive a semantic relatedness score between med-
ical concepts. The UMLS codifies concepts found
in various medical vocabularies (e.g., ICD5 and
SNOMED-CT6) and includes relationships between
various concepts. The medical concepts and their
relationships are modeled in a graph structure. We
use the k-Neighborhood decentralization method
(kDLS) (Xiang et al, 2011) to index and transi-
tively traverse associated relations between concept
unique identifiers (CUIs) in the UMLS graph. The
UMLS uses semantic relations to mark the avail-
able links between two concepts. Around 2,404,937
CUIs and 15,333,246 links between them are seen in
the full UMLS graph structure. The kDLS method
is shown to outperform both breadth-first and depth-
first search in terms of speed and various other
measures in finding important information, such as
reachability, distance, and a summary of paths, be-
tween two concepts in the UMLS graph structure.
The relation between two concepts Mj (denoted by
x) and Mk (denoted by y) is measured as follows.
R(x, y) =
?
p?D(x,y)
1
?length(p)?1
+
?
q?D(y,x)
1
?length(q)?1
where D(x, y) is the set of paths from x to y and
D(y, x) is the set of paths from y to x obtained us-
5http://www.cdc.gov/nchs/icd.htm
6http://www.ihtsdo.org/snomed-ct/
ing the kDLS method, excluding paths with length
equal to 1. In order to make the measurement be-
tween a medical concepts unbiased against the avail-
able links in the UMLS that directly connect them,
the paths with length being 1 between them are not
counted. Each path?s contribution to the relation
score R(x, y) is determined by its length and ?. ? is
varied between 1 to 50; if ? is set to 1, then all paths
contribute equally to R irrespective of their lengths.
When ? increases, more weight will be placed on
the short paths as opposed to the long paths. Xiang
et al (2011) observe several fold enrichment values
when ? is varied between 5 and 15.
Besides traversing the UMLS graph structure us-
ing the kDLS method to obtain a similarity score
between medical concepts, we also measure similar-
ity between medical concepts by taking into account
the surrounding context. We do so by measuring
the KL-divergence between the sentences to which
the medical concepts belong. In order to avoid the
possibility of an empty set when calculating the in-
tersection of the probability distributions, we use a
smoothing method that makes the probability distri-
butions sum to 1 (Brigitte, 2003).
Another important semantic feature is the type of
relation between the medical concepts. This feature
is calculated by first computing the stemmed word
overlap between the medical concepts and deriving
features based on exact and partial matches between
the word stems of the medical concepts. If there is
no exact or partial match between the concepts, we
query the UMLS to check if the stem of one of the
medical concepts occurs in the UMLS definition or
atoms of the other medical event. An atom is the
smallest unit of naming within the UMLS. A med-
ical concept in UMLS represents a single meaning
and contains all atoms in the UMLS that express that
meaning in any way, whether formal or casual, ver-
bose or abbreviated. All of the atoms within a con-
cept are synonymous.
Besides the described features, we also include
the UMLS semantic category of each medical con-
cept and the WordNet7 similarity score between sen-
tences containing the medical concept.
Temporal Relatedness. Clinical text is fre-
quently characterized by temporal expressions co-
7http://wordnet.princeton.edu/
734
occurring with medical concepts (Zhou and Hripc-
sak, 2007). For instance, two days ago, fever started
4 days before rash, July 10th, 2010 etc. The abil-
ity to associate medical concepts with temporal ex-
pressions helps order medical concepts and deter-
mine potential temporal overlap between them. This
in turn could be a powerful discriminatory feature
in MCCR. Consider the medical concept chest pain
that occurs multiple times in a clinical narrative. If
these mentions of chest pain have occurred at the
same time, there is a possibility that they all refer to
the same instance of the medical concept chest pain.
Instead of relying on implicit temporal references
that may or may be evident from the clinical nar-
rative, we focus on temporal expressions that are
found in most clinical narratives. We do so by lever-
aging structural properties of clinical narratives such
as section information and explicit temporal infor-
mation such as admission and discharge dates, to
learn to assign medical concepts to time periods we
refer to as time-bins.
We now proceed to explain the process of assign-
ing medical concepts to time-bins using CRFs. Clin-
ical narratives are usually formatted with a struc-
tured header with information that includes the pa-
tient admission and discharge date. Clinical narra-
tives are also typically divided into sections. Sec-
tions represent a logical, and at times, temporal
grouping of information in the narrative. Sections
such as ?history of present illness,? ?physical ex-
amination,? ?review of systems,? ?impression,? and
?assessment plan? tend to occur in a certain order
within each clinical narrative. Thus, section tran-
sitions may indicate a temporal pattern for medical
concepts across those sections. For example, ?past
medical history? (before admission), followed by
?findings on admission? (on admission), followed
by ?physical examination? (after admission). Sec-
tions of certain types may also exhibit certain tem-
poral patterns. A ?history of present illness? sec-
tion may start with diseases and diagnoses 30 years
ago and then proceed to talk about them in the con-
text of a medical condition that happened few years
ago and finally describe the patient?s condition on
admission. Given the temporal patterns within sec-
tions and at section transitions, it works well to treat
the list of medical concepts from each clinical nar-
rative as a sequence (considering them in narrative
order) and learning to label them with a correspond-
ing time-bin. We define the following sequence of
time-bins centered around admission and discharge,
{way before admission, before admission, on admis-
sion, after admission, after discharge}.
We model the problem of assigning medical con-
cepts to time-bins as a sequence labeling task using
a CRF where we predict labels from the set {way be-
fore admission, before admission, on admission, af-
ter admission, after discharge} as a sequence Y pre-
dicted from the detected medical concepts X . CRFs
use two types of features in classification, state fea-
tures and transition features. State features con-
sider relating the label y (time-bin) of a single ver-
tex (medical concept) to features corresponding to a
medical concept x, and are given by,
S(x, y, i) =
?
j ?jsj(y, x, i)
Transition features consider the mutual depen-
dence of labels yi?1 and yi (dependence between the
time-bins of the current and previous medical event
in the sequence) and are given by,
T (x, y, i) =
?
k ?ktk(yi?1, yi, x, i)
Above, sj is a state feature function, and ?j is its
associated weight and tk is a transition function, and
?k is its associated weight. In contrast to the state
function, the transition function takes as input the
current label as well as the previous label, in addition
to the data.
Example state features include indicator features
based on verbs patterns in the same sentence as that
of the medical concept, last verb before the medical
concept, and type of clinical narrative. We also in-
clude position of medical event in the narrative as
well as within each section, the temporal expres-
sions and dates co-occurring with the medical con-
cept as features and the difference between these
dates and the admission date on each clinical nar-
rative. Example transition features include section
transitions based on the sections under which the
medical concept occurs, UMLS relatedness score
between the previous and current medical concept,
difference in verb patterns between the previous and
current medical concept, difference in dates (if any)
between the dates co-occurring with the previous
and current medical concept.
In order to enable feature extraction for this learn-
ing task, we use the following heuristic-based al-
735
gorithm to automatically identify sections and asso-
ciate medical concepts with them.
1. Extract lines that are all upper-case, and longer
than a word, from all narratives in corpus. They
mostly correspond to section titles.
2. Derive the stem of each word in the title using a
Porter stemming algorithm8 and sort stemmed
titles by frequency. If two or more words in
the title overlap, they are considered the same.
This gives us a candidate set of section titles.
3. When parsing a clinical narrative, and encoun-
tering a stemmed ngram matching a section ti-
tle from the frequent list, all subsequent sen-
tences are associated with that section until a
new section title is encountered. If an exact
match is not found, we allow partially match-
ing ngrams to be considered as section titles.
Along with the time-bin that are learned using the
process described above, dates and temporal expres-
sions extracted from the annotations in our corpus
are also used as temporal features. The list of fea-
tures extracted for the task of MCCR include the
following:
1. Verb pattern in the sentence in which the med-
ical concept occurs.
2. Last verb before the medical concept in the
same sentence.
3. Type of clinical narrative.
4. Section under which the medical concept is
mentioned.
5. Position of the medical concept.
6. Dates that fall in the same sentence as the med-
ical concept.
7. Difference between admission date and the date
in the same sentence as the clinical narrative.
8. The learned time-bin of each medical concept.
We also derive features based on the overlap-
ping in time-bins for the medical concept pair
and the nature of time-bin (past, present, fu-
ture).
9. Difference in verb patterns in the sentences of
the medical concept pair.
10. Difference in dates between the medical con-
cept pair.
8http://tartarus.org/martin/PorterStemmer/
11. UMLS relatedness score between the medical
concept pair and all the UMLS related and
other features described previously in the se-
mantic relatedness section.
When applying CRFs to the problem of assigning
medical concepts to time-bins, an observation se-
quence is medical concepts in the order in which
they appear in a clinical narrative, and the state se-
quence is the corresponding label sequence of time
bins. Thus, given a sequence of concepts in narrative
order {M1,M2,M3, ..}, we learn a corresponding
label sequence of time-bins {way before admission,
before admission, on admission, after admission, af-
ter discharge}. The learned label sequence is now
used as part of the temporal feature set in co-training
and posterior regularization for MCCR.
5 Weakly Supervised Learning
5.1 Co-training
We co-train two MaxEnt classifiers, one each on the
semantic features fs and temporal features ft of the
data, to classify pairs of medical concepts as core-
fer or no-corefer in a semi-supervised fashion. We
use the co-training algorithm proposed by Blum and
Mitchell (1998).
The assumption here is that each feature set contains
sufficient information to train a model for classifica-
tion of medical concepts. Consider the concept pair,
{renal inflammation, posterior uveitis} that core-
fer. The semantic view for this concept pair may
not strongly indicate coreference. The ?UMLS rela-
tion type? feature indicates that the two concepts are
not similar in meaning. However, both concepts are
mapped to the same time-bin after admission. Thus,
the time-bin along with features extracted based on
explicit temporal expressions co-occurring with the
medical concepts indicate a coreference between the
pair of medical concepts. Similarly, the semantic
view is confident about confident about the corefer-
ence of certain medical concept pairs which do not
occur in the same time-bin. The classifiers trained
on each view complement each other in the learn-
ing process. Thus, we can leverage the predictions
made by each classifier on the unlabeled dataset to
augment the training data of both classifiers.
The co-training algorithm is shown in Table 1. We
set a threshold for an unlabeled sample to be added
736
Function coTrain
Repeat till all unlabeled data is labeled.
1. Train classifier c1 on tf s to obtain model m1
2. Train classifier c2 on tf t to obtain model m2
3. Use m1 to classify a subset of unlabeled data
and update the training data as,
tf s.subset = {usubset1, predicted label}
iff classifier confidence > 1/number of labels
4. Use m2 to classify a subset of unlabeled data
and update the training data as,
tf t.subset = {usubset2, predicted label}
iff classifier confidence > 1/number of labels
5. tf s = tf s + tf t.subset +
{usubset1, predicted label}
6. tf t = tf t + tf s.subset +
{usubset2, predicted label}
Table 1: Co-training algorithm for the binary pairwise
classification task of MCCR (Blum and Mitchell, 1998).
c = classifier, u = unlabeled data.
usubset1, usubset2 = subsets of unlabeled data.
usubset1 and usubset2 are mutually exclusive.
F = {fs, ft} is the features space divided into condition-
ally independent semantic and temporal feature sets.
tf s = {fs,l} training data consisting of semantic features
of a medical concept pair along with class label.
tf t = {ft,l} training data consisting of temporal features
of a medical concept pair along with class label.
into the labeled pool. An unlabeled sample is la-
beled in a particular iteration, if classifier confidence
> 1/number of labels. In the next iteration, ran-
domly pick a subset of unlabeled samples and label
all samples in this subset. This could include sam-
ples that have already been labeled in previous iter-
ations. A label is assigned in a subsequent iteration
if: the sample was previously labeled OR if classi-
fier confidence > threshold. The parameters in this
algorithm are the number of iterations, the pool size
of examples selected from the unlabeled set in each
iteration and the number of labeled examples added
at each iteration to the labeled data pool. Similar to
Blum and Mitchell (1998), we update the pool size
by 2p+ 2n in each iteration, where p is the number
of medical pairs that corefer and n is the number of
medical concept pairs that do not corefer.
5.2 MaxEnt with Posterior Regularization
The next semi-supervised learning method applied
to MCCR is MaxEnt with posterior regularization
using expectation constraints (Ganchev et al, 2010).
This method incorporates prior knowledge directly
on the output variables during learning. The prior
knowledge is expressed as inequalities on the ex-
pected value under the posterior distribution of user-
defined constraint features. Thus, posterior regular-
ization incorporates side-information into unsuper-
vised estimation in the form of constraints on the
model?s posteriors. It is similar to the EM algorithm
during learning, but it solves a problem similar to
Maximum Entropy inside the E-Step to enforce the
constraints.
Posterior regularization is used to derive a multi-
view learning algorithm while specifying constraints
that the models should agree on the label distri-
bution. We train MaxEnt models based on two
views of the data, semantic and temporal. This
method starts by considering the setting of complete
agreement where there is a common desired out-
put for the two models and each of the two views
is sufficiently rich to predict labels accurately. The
search is restricted to model pairs p1, p2 that sat-
isfy p1(y|x) ? p2(y|x), where p1 and p2 each de-
fine a distribution over labels. The product dis-
tribution p1(y1)p2(y2) is considered and constraint
features are defined such that the proposal distri-
bution q(y1, y2) will have the same marginal for
y1 and y2. There is one constraint feature defined
for each label y given by, ?y(y1, y2) = ?(y1 =
y)?(y2 = y), where ?(.) is the 0-1 indicator func-
tion. The constraint set Q = q : Eq[?] = 0 re-
quires that the marginals over the two output vari-
ables are identical q(y1) = q(y2). An agreement
between two models is defined as agree(p1, p2) =
argmin KL(q(y1, y2)||p1(y1)p2(y2)) | Eq [?] = 0.
In the semantic feature set, we convert the follow-
ing feature (described in Section 4) into expectation
constraints. The type of relation between the pair
of medical concepts, is derived from matching the
word stems and querying the UMLS definition and
atoms of the medical concepts. Based on the relation
between the medical concepts (i.e., partial match,
complete match, UMLS definition match, UMLS
atom match, and no match), we indicate the prob-
ability of label distribution coref and no-coref. If
the relation turns out to be no match, there is a high
probability that the medical concepts do not corefer.
In the temporal feature set, we convert the features
based on time-bins of the medical concepts in the
pair into expectation constraints.
737
Class(time-bin) Precision Recall
after discharge 96.05 62.53
before admission 94.02 92.44
on admission 33.25 75.16
way before admission 50.42 66.72
after admission 93.62 99.14
Table 2: Sequence tagging of medical concepts with
time-bins using CRFs.
6 Experimental Setup
6.1 Corpus Annotation
Annotation of clinical text is a time consuming and
costly process. Many annotation efforts have used
physicians to annotate the data. Instead, we use an-
notators that are students or recently graduated stu-
dents from diverse clinical backgrounds with vary-
ing levels of clinical experience. In spite of this di-
versity, the annotation agreement across our team of
annotators is high; all annotators agreed on 89.5% of
the events and our overall inter-annotator Cohen?s
kappa statistic (Conger, 1980) for medical events
was 0.865. The annotators mark medical concepts,
coereference chains and temporal expressions in the
clinical narratives and the NEJM case reports. They
also map each medical concept to a UMLS CUI.
6.2 Feature Extraction
The first step involves extraction of semantic and
temporal features for the annotated medical con-
cepts, as described in Section 4 from both corpora.
The semantic relatedness scores are computed us-
ing the kDLS (Xiang et al, 2011) method to calcu-
late the relationship between concepts in the UMLS
with value of ? set to 7. The type of relation be-
tween medical concepts is derived by matching word
stems in each medical concept using the Lucene9
implementation of the Porter stemming algorithm.
We query the latest release (UMLS 2011AB) of the
UMLS Metathesaurus for finding a match between
medical concept and the UMLS definition or UMLS
atoms. The WordNet similarity score is computed
using Java API for WordNet Searching (JAWS).10
Explicit temporal expressions annotated in the
corpora are included in our temporal feature set.
Medical concepts in the NEJM are mostly de-
scribed temporally relative to the patient?s admis-
9http://lucene.apache.org/
10http://lyle.smu.edu/?tspell/jaws/
Class NEJM Clinical Narratives
Precision Recall Precision Recall
coref 79.24 94.53 74.81 88.33
no-coref 86.71 90.62 83.92 94.86
Table 3: Supervised learning for MCCR.
sion. Temporal expressions like ?2 years before ad-
mission? and ?3 weeks before admission? are com-
mon. Hence, we use a heuristic-based algorithm
to associate medical concepts with explicit tempo-
ral expressions in the NEJM corpus. The algo-
rithm parses case reports and identifies the tempo-
ral expressions anchored to admission. All medi-
cal concepts following such a temporal expression
are anchored to it until a new temporal expression
is encountered. Over 88% of the medical concept-
temporal expression associations done with the al-
gorithm above is accurate when compared against
the NEJM gold standard.
As described in Section 4, we apply sequence tag-
ging using a CRF to assign medical concepts in clin-
ical narratives to time-bins. We use the implementa-
tion of CRF in Mallet,11 trained by Limited-Memory
BFGS for our experiments. We use the Stanford
POS tagger12 to identify verbs and derive verb pat-
terns. The dataset for the task of assigning medi-
cal concepts to time-bins consisted of 1613 medical
concepts. We used a 60-40 train-test split to train a
CRF using a sequence of medical concepts and ob-
served an overall accuracy of 92%. The precision
and recall values for each time-bin class is indicated
in Table 2. The percentage of medical concepts that
fall under ?way before admission? and ?on admis-
sion? are less than 5%, affecting the learning accu-
racy of those classes. When modeled as a multi-
class classification task using MaxEnt, we achieve
around 86% accuracy.
7 MCCR Results and Discussion
We perform the following experiments for pairwise
MCCR: 1) Supervised learning with a MaxEnt clas-
sifier, using the combined semantic and temporal
feature set, 2) Co-training two MaxEnt models, 3)
Training MaxEnt models with using posterior regu-
larization.
11http://mallet.cs.umass.edu/
12http://nlp.stanford.edu/software/tagger.
shtml
738
Class NEJM Clinical Narratives
Co-train Precision Recall Precision Recall
coref 70.32 82.54 69.26 87.31
no-coref 82.54 84.85 71.15 89.44
PR Precision Recall Precision Recall
coref 76.63 90.41 74.81 84.25
no-coref 80.35 89.21 78.93 87.46
Table 4: Co-training and posterior regularization (PR) for
MCCR using semantic and temporal feature sets.
We use the MaxEnt classifier available in Mallet
for 1) and 2) and the the Mallet implementation of
MaxEnt models with posterior regularization for 3).
The NEJM corpus has 722 medical concepts,
12576 candidate pairs of medical concepts includ-
ing 137 pairs that corefer. We include all 12576
pairs in our experiments. The clinical narrative cor-
pus has 1613 medical concepts. The candidate pairs
and coreference chains for each patient is as follows.
Patient 1 has 241001 candidate pairs, 29 corefer-
ence chains. Patient 2 has 149604 candidate pairs,
9 coreference chains. Patient 3 has 6,446,521 can-
didate pairs, 20 coreference chains. From all the
candidate pairs in the clinical narrative corpus, 1025
pairs corefer. We randomly sample the no-coref in-
stances to restrict the corpus size to 1 million candi-
date pairs of medical concepts.
The results for all 3 experiments for both corpora
is shown in Tables 3, 4. We also train-test a super-
vised MaxEnt classifier on a 60-40 split of the en-
tire corpus. This gives us a precision of 74.81% and
88.33% recall (coref) for the binary classification
task of pairwise MCCR in the clinical narratives cor-
pus. In the both the semi-supervised experiments,
we use an initial labeled pool size of 30 where 12
medical concept pairs that corefer (p) and 18 that do
not corefer (n). The growth size is each iteration of
co-training is 2p+2n. At each iteration, confidently
labeled examples are added to the training set from
the previous iteration. The co-training algorithm
is run until all unlabeled instances become labeled.
The parameters in the posterior regularization im-
plementation include the regularization penalty for
each step and the number of iterations. We use the
default values (maxIterations=100, pGaussianPrior-
Variance=0.1, qGaussianPriorVariance=1000) sug-
gested on the Mallet toolkit page (Bellare et al,
2009). Co-training two MaxEnt models based on
independent semantic and temporal views of the
data results in 69.26% precision and 87.31% recall
(coref), whereas training MaxEnt models with ex-
pectation constraints gives us 74.81% precision and
84.25% recall (coref), on the corpus of clinical nar-
ratives.
Posterior regularization does better than co-training
and the performance of both the semi-supervised
methods is comparable to if not as good as the super-
vised classifier trained on a 60-40 split of the corpus.
Thus, our results indicate that the use of semantic
and temporal features is effective for MCCR in clin-
ical text. It is clear from the co-training and poste-
rior regularization results that treating MCCR as a
semi-supervised problem works.
8 Conclusions
We investigated the task of MCCR in clinical text us-
ing supervised and semi-supervised learning meth-
ods. We create annotated corpora of clinical text
with case reports from the NEJM and narratives ob-
tained from The Ohio State University Wexner Med-
ical Center. We work with the hypothesis that de-
termining semantic and temporal similarity between
medical concepts helps resolve coreferences. In
order to test this hypothesis, we describe the pro-
cess of semantic and temporal feature extraction
from clinical text. We demonstrate the effective-
ness of the extracted features in a supervised binary
classification task for MCCR with MaxEnt classi-
fiers (using the combined feature set) as well as us-
ing semi-supervised methods of co-training MaxEnt
classifiers and training MaxEnt models using pos-
terior regularization (using two independent views
of the data - semantic view and temporal view).
Thus, we show that MCRR can be performed using
semi-supervised learning with semantic and tempo-
ral views of the data.
Acknowledgments
The project described was supported by the
National Center for Research Resources,
Grant UL1RR025755, KL2RR025754, and
TL1RR025753, and is now at the National
Center for Advancing Translational Sciences,
Grant 8KL2TR000112-05, 8UL1TR000090-05,
8TL1TR000091-05. The content is solely the re-
sponsibility of the authors and does not necessarily
represent the official views of the NIH.
739
References
Sophia Ananiadou, Carol Freidman, and Jun??chi Tsu-
jii. 2004. Introduction: named entity recognition in
biomedicine. J. of Biomedical Informatics, pages 393?
395.
Kedar Bellare, Gregory Druck, and Andrew McCallum.
2009. Alternating projections for learning with expec-
tation constraints. In Proceedings of the Twenty-Fifth
Conference on Uncertainty in Artificial Intelligence,
UAI ?09, pages 43?50.
Avrim Blum and Tom M. Mitchell. 1998. Combin-
ing labeled and unlabeled data with co-training. In
COLT?98, pages 92?100.
Bigi Brigitte. 2003. Using Kullback-Leibler distance for
text categorization. In Proceedings of the 25th Euro-
pean conference on IR research, ECIR?03, pages 305?
319.
Wendy W Chapman, Prakash M Nadkarni, Lynette
Hirschman, Guergana K Savova Leonard W D?Avolio,
and Ozlem Uzuner. 2011. Overcoming barriers to
NLP for clinical text: the role of shared tasks and the
need for additional creative solutions. In JAMIA.
Jung-Hsien Chiang, Jou-Wei Lin, and Chen-Wei Yang.
2010. Automated evaluation of electronic discharge
notes to assess quality of care for cardiovascular dis-
eases using Medical Language Extraction and Encod-
ing System (MedLEE). JAMIA, pages 245?252.
A.J. Conger. 1980. Integration and generalization of
kappas for multiple raters. In Psychological Bulletin
Vol 88(2), pages 322?328.
Peter J Embi and Philip Payne. 2009. Clinical research
informatics: challenges, opportunities and definition
for an emerging domain. Journal of the American
Medical Informatics Association, 16(3):316?327.
Carol Friedman, Pauline Kra, and Andrey Rzhetsky.
2002. Two biomedical sublanguages: a description
based on the theories of Zellig Harris. Journal of
Biomedical Informatics, 35(4):222?235.
Rob Gaizauskas, Henk Harkema, Mark Hepple, and An-
drea Setzer. 2006. Task-oriented extraction of tem-
poral information: The case of clinical narratives.
In Proceedings of the Thirteenth International Sym-
posium on Temporal Representation and Reasoning,
TIME ?06, pages 188?195.
Kuzman Ganchev, Joo Graa, Jennifer Gillenwater, and
Ben Taskar. 2010. Posterior regularization for struc-
tured latent variable models. Journal of Machine
Learning Research, pages 2001?2049.
Tian Ye He. 2007. Coreference Resolution on Entities
and Events for Hospital Discharge Summaries. EECS,
Cambridge, MA, MIT. M.Eng.
Hyuckchul Jung, James Allen, Nate Blaylock, Will
de Beaumont, Lucian Galescu, and Mary Swift. 2011.
Building timelines from narrative clinical records: ini-
tial results based-on deep natural language under-
standing. In Proceedings of BioNLP 2011 Workshop,
BioNLP ?11, pages 146?154.
Christoph Muller, Stefan Rapp, and Michael Strube.
2002. Applying co-training to reference resolution. In
ACL, pages 352?359.
Vincent Ng. 2010. Supervised noun phrase coreference
research: The first fifteen years. In Proceedings of the
ACL, pages 1396?1411.
Kamal Nigam and Rayid Ghani. 2000. Analyzing
the effectiveness and applicability of co-training. In
CIKM?00, pages 86?93.
James Pustejovsky, Jos M. Castao, Robert Ingria, Roser
Sauri, Robert J. Gaizauskas, Andrea Setzer, Graham
Katz, and Dragomir R. Radev. 2003. Timeml: Robust
specification of event and temporal expressions in text.
In New Directions in Question Answering?03, pages
28?34.
Preethi Raghavan and Albert M. Lai. 2010. Leveraging
natural language processing of clinical narratives for
phenotype modeling. In PIKM?10, pages 57?66.
Karthik Raghunathan, Heeyoung Lee, Sudarshan Ran-
garajan, Nathanael Chambers, Mihai Surdeanu, Dan
Jurafsky, and Christopher Manning. 2010. A multi-
pass sieve for coreference resolution. In Proceedings
of the 2010 Conference on Empirical Methods in Nat-
ural Language Processing, EMNLP ?10, pages 492?
501, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.
Guergana K. Savova, James J. Masanz, Philip V.
Ogren, Jiaping Zheng, Sunghwan Sohn, Karin Kip-
per Schuler, and Christopher G. Chute. 2010. Mayo
clinical text analysis and knowledge extraction sys-
tem (cTAKES): architecture, component evaluation
and applications. JAMIA, pages 507?513.
Guergana K. Savova, Wendy Webber Chapman, Jiaping
Zheng, and Rebecca S. Crowley. 2011. Anaphoric
relations in the clinical narrative: corpus creation.
JAMIA, 18(4):459?465.
Wee Meng Soon, Hwee Tou Ng, and Chung Yong Lim.
2001. A machine learning approach to coreference
resolution of noun phrases. Computational Linguis-
tics, pages 521?544.
Yang Xiang, Kewei Lu, Stephen L James, Tara B Bor-
lawsky, Kun Huang, and Philip R O Payne. 2011. k-
neighborhood decentralization: A comprehensive so-
lution to index the UMLS for scale knowledge discov-
ery. In Journal of Biomedical Informatics.
Jiaping Zheng, Wendy Webber Chapman, Rebecca S.
Crowley, and Guergana K. Savova. 2011. Coreference
resolution: A review of general methodologies and ap-
plications in the clinical domain. Journal of Biomedi-
cal Informatics, 44(6):1113?1122.
740
Li Zhou and George Hripcsak. 2007. Temporal rea-
soning with medical data - a review with emphasis
on medical natural language processing. Journal of
Biomedical Informatics, pages 183?202.
Li Zhou, Genevieve B. Melton, Simon Parsons, and
George Hripcsak. 2006. A temporal constraint struc-
ture for extracting temporal information from clinical
narrative. Journal of Biomedical Informatics, pages
424?439.
741
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 70?74,
Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational Linguistics
Learning to Temporally Order Medical Events in Clinical Text
Preethi Raghavan?, Eric Fosler-Lussier?, and Albert M. Lai?
?Department of Computer Science and Engineering
?Department of Biomedical Informatics
The Ohio State University, Columbus, Ohio, USA
{raghavap, fosler}@cse.ohio-state.edu, albert.lai@osumc.edu
Abstract
We investigate the problem of ordering med-
ical events in unstructured clinical narratives
by learning to rank them based on their time
of occurrence. We represent each medical
event as a time duration, with a correspond-
ing start and stop, and learn to rank the
starts/stops based on their proximity to the ad-
mission date. Such a representation allows us
to learn all of Allen?s temporal relations be-
tween medical events. Interestingly, we ob-
serve that this methodology performs better
than a classification-based approach for this
domain, but worse on the relationships found
in the Timebank corpus. This finding has im-
portant implications for styles of data repre-
sentation and resources used for temporal re-
lation learning: clinical narratives may have
different language attributes corresponding to
temporal ordering relative to Timebank, im-
plying that the field may need to look at a
wider range of domains to fully understand the
nature of temporal ordering.
1 Introduction
There has been considerable research on learning
temporal relations between events in natural lan-
guage. Most learning problems try to classify event
pairs as related by one of Allen?s temporal rela-
tions (Allen, 1981) i.e., before, simultaneous, in-
cludes/during, overlaps, begins/starts, ends/finishes
and their inverses (Mani et al, 2006). The Timebank
corpus, widely used for temporal relation learning,
consists of newswire text annotated for events, tem-
poral expressions, and temporal relations between
events using TimeML (Pustejovsky et al, 2003). In
Timebank, the notion of an ?event? primarily con-
sists of verbs or phrases that denote change in state.
However, there may be a need to rethink how we
learn temporal relations between events in different
domains. Timebank, its features, and established
learning techniques like classification, may not work
optimally in many real-world problems where tem-
poral relation learning is of great importance.
We study the problem of learning temporal rela-
tions between medical events in clinical text. The
idea of a medical ?event? in clinical text is very dif-
ferent from events in Timebank. Medical events
are temporally-associated concepts in clinical text
that describe a medical condition affecting the pa-
tient?s health, or procedures performed on a patient.
Learning to temporally order events in clinical text
is fundamental to understanding patient narratives
and key to applications such as longitudinal studies,
question answering, document summarization and
information retrieval with temporal constraints. We
propose learning temporal relations between medi-
cal events found in clinical narratives by learning to
rank them. This is achieved by representing medical
events as time durations with starts and stops and
ranking them based on their proximity to the admis-
sion date.1 This implicitly allows us to learn all of
Allen?s temporal relations between medical events.
In this paper, we establish the need to rethink
the methods and resources used in temporal re-
lation learning, as we demonstrate that the re-
sources widely used for learning temporal relations
in newswire text do not work on clinical text. When
we model the temporal ordering problem in clinical
text as a ranking problem, we empirically show that
it outperforms classification; we perform similar ex-
periments with Timebank and observe the opposite
conclusion (classification outperforms ranking).
1The admission date is the only explicit date always present
in each clinical narrative.
70
e1 before e2 e1 equals e2
e1.start e1.start; e2.start
e1.stop e1.stop; e2.stop
e2.start
e2.stop
e1 overlaps with e2 e1 starts e2
e1.start e1.start; e2.start
e2.start e1.stop
e1.stop e2.stop
e2.stop
e2 during e1 e2 finishes e1
e1.start e1.start
e2.start e2.start
e2.stop e1.stop; e2.stop
e1.stop
Table 1: Allen?s temporal relations between medical
events can be realized by ordering the starts and stops
2 Related Work
The Timebank corpus provides hand-tagged fea-
tures, including tense, aspect, modality, polarity and
event class. There have been significant efforts
in machine learning of temporal relations between
events using these features and a wide range of other
features extracted from the Timebank corpus (Mani
et al, 2006; Chambers et al, 2007; Lapata and Las-
carides, 2011). The SemEval/TempEval (Verhagen
et al, 2009) challenges have often focused on tem-
poral relation learning between different types of
events from Timebank. Zhou and Hripcsak (2007)
provide a comprehensive survey of temporal reason-
ing with clinical data. There has also been some
work in generating annotated corpora of clinical text
for temporal relation learning (Roberts et al, 2008;
Savova et al, 2009). However, none of these cor-
pora are freely available. Zhou et al (2006) propose
a Temporal Constraint Structure (TCS) for medical
events in discharge summaries. They use rule-based
methods to induce this structure.
We demonstrate the need to rethink resources,
features and methods of learning temporal relations
between events in different domains with the help of
experiments in learning temporal relations in clini-
cal text. Specifically, we observe that we get better
results in learning to rank chains of medical events
to derive temporal relations (and their inverses) than
learning a classifier for the same task.
The problem of learning to rank from examples
has gained significant interest in the machine learn-
ing community, with important similarities and dif-
ferences with the problems of regression and clas-
sification (Joachims et al, 2007). The joint cumu-
lative distribution of many variables arises in prob-
HISTORY PHYSICAL                                                                DATE: 09/01/2007  NAME: Smith Daniel T                                                          MR#: XXX-XX-XXXX  ATTENDING PHYSICIAN: John Payne MD                           DOB: 03/10/1940  HISTORY OF PRESENT ILLNESS  The patient is a 67-year-old Caucasian male with a history of paresis secondary to back  injury who is bedridden status post colostomy and PEG tube who was brought by EMS with  a history of fever. The patient gives a history of fever on and off associated with chills for the last 1 month. He does give a history of decubitus ulcer on the back but his main  complaint is fever associated with epigastric discomfort.  PAST MEDICAL HISTORY  Significant for polymicrobial infection in the blood as well as in the urine in July 2007 history  of back injury with paraparesis. He is status post PEG tube and colostomy tube.  REVIEW OF SYSTEMS  Positive for decubitus ulcer. No cough. There is fever. No shortness of breath.  PHYSICAL EXAMINATION  On physical exam the patient is a debilitated malnourished gentleman in mild distress.  Abdomen showed PEG tube with discharging pus and there are multiple scars one in the  midline. It had a healing wound. Bowel sounds were present. Extremities revealed pain and  atrophied muscles in the lower extremities with decubitus ulcer which had a transparent  bandage in the decubitus area which was stage 2-3. CNS - The patient is alert and awake x3.  There was good power in both upper extremities. Cranial nerves II-XII grossly intact.  
Figure 1: Excerpt from a sanitized clinical narrative (history &
physical report) with medical events underlined.
lems of learning to rank objects in information re-
trieval and various other domains. To the best of our
understanding, there have been no previous attempts
to learn temporal relations between events using a
ranking approach.
3 Representation of Medical Events (MEs)
Clinical narratives contain unstructured text describ-
ing various MEs including conditions, diagnoses
and tests in the history of a patient, along with
some information on when they occurred. Much of
the temporal information in clinical text is implicit
and embedded in relative temporal relations between
MEs. A sample excerpt from a note is shown in
Figure 1. MEs are temporally related both qualita-
tively (e.g., paresis before colostomy) and quantita-
tively (e.g. chills 1 month before admission). Rela-
tive time may be more prevalent than absolute time
(e.g., last 1 month, post colostomy rather than on
July 2007). Temporal expressions may also be fuzzy
where history may refer to an event 1 year ago or 3
months ago. The relationship between MEs and time
is complicated. MEs could be recurring or continu-
ous vs. discrete date or time, such as fever vs. blood
in urine. Some are long lasting vs. short-lived, such
as cancer, leukemia vs. palpitations.
We represent MEs of any type of in terms of their
time duration. The idea of time duration based rep-
resentation for MEs is in the same spirit as TCS
(Zhou et al, 2006). We break every ME me into
me.start and me.stop. Given the ranking of all starts
and stops, we can now compose every one of Allen?s
temporal relations (Allen, 1981). If it is clear from
context that only the start or stop of a ME can be de-
termined, then only that is considered. For instance,
?history of paresis secondary to back injury who is
bedridden status post colostomy? indicates the start
of paresis is in the past history of the patient prior
71
to colostomy. We only know about paresis.start rel-
ative to other MEs and may not be able determine
paresis.stop. For recurring and continuous events
like chills and fever, if the time period of recurrence
is continuous (last 1 month), we consider it to be
the time duration of the event. If not continuous, we
consider separate instances of the ME. For MEs that
are associated with a fixed date or time, the start and
stop are assumed to be the same (e.g., polymicrobial
infection in the blood as well as in the urine in July
2007). In case of negated events like no cough, we
consider cough as the ME with a negative polarity.
Its start and stop time are assumed to be the same.
Polarity allows us to identify events that actually oc-
curred in the patient?s history.
4 Ranking Model and Experiments
Given a patient with multiple clinical narratives, our
objective is to induce a partial temporal ordering of
all medical events in each clinical narrative based on
their proximity to a reference date (admission).
The training data consists of medical event (ME)
chains, where each chain consists of an instance of
the start or stop of a ME belonging to the same clin-
ical narrative along with a rank. The assumption is
that the MEs in the same narrative are more or less
semantically related by virtue of narrative discourse
structure and are hence considered part of the same
ME chain. The rank assigned to an instance indi-
cates the temporal order of the event instance in the
chain. Multiple MEs could occupy the same rank.
Based on the rank of the starts and stops of event
instances relative to other event instances, the tem-
poral relations between them can be derived as indi-
cated in Table 1. Our corpus for ranking consisted
of 47 clinical narratives obtained from the medical
center and annotated with MEs, temporal expres-
sions, relations and event chains. The annotation
agreement across our team of annotators is high; all
annotators agreed on 89.5% of the events and our
overall inter-annotator Cohen?s kappa statistic (Con-
ger, 1980) for MEs was 0.865. Thus, we extracted
47 ME chains across 4 patients. The distribution of
MEs across event chains and chains across patients
(p) is as as follows. p1 had 5 chains with 68 MEs,
p2 had 9 chains with 90 MEs, p3 had 20 chains with
119 MEs and p4 had 13 chains with 82 MEs. The
distribution of chains across different types of clin-
ical narratives is shown in Figure 2. We construct
a vector of features, from the manually annotated
corpus, for each medical event instance. Although
0 
2 
4 
6 
8  
10 
12 
14 
Radiology Discharge Summaries Pathology History & Physical  
p1 p2 p3 p4 
Figure 2: Distribution of the 47 medical event chains derived
from discharge summaries, history and physical reports, pathol-
ogy and radiology notes across the 4 patients.
there is no real query in our set up, the admission
date for each chain can be thought of as the query
?date? and the MEs are ordered based on how close
or far they are from each other and the admission
date. The features extracted for each ME include
the the type of clinical narrative, section informa-
tion, ME polarity, position of the medical concept
in the narrative and verb pattern. We extract tempo-
ral expressions linked to the ME like history, before
admission, past, during examination, on discharge,
after discharge, on admission. Temporal references
to specific times like next day, previously are re-
solved and included in the feature set. We also ex-
tract features from each temporal expression indicat-
ing its closeness to the admission date. Differences
between each explicit date in the narrative is also
extracted. The UMLS(Bodenreider, 2004) semantic
category of each medical concept is also included
based on the intuition that MEs of a certain semantic
group may occur closer to admission. We tried using
features like the tense of ME or the verb preceding
the ME (if any), POS tag in ranking. We found no
improvement in accuracy upon their inclusion.
In addition to the above features, we also anchor
each ME to a coarse time-bin and use that as a fea-
ture in ranking. We define the following sequence
of time-bins centered around admission, {way be-
fore admission, before admission, on admission, af-
ter admission, after discharge}. The time-bins are
learned using a linear-chain CRF,2 where the obser-
vation sequence is MEs in the order in which they
appear in a clinical narrative, and the state sequence
is the corresponding label sequence of time-bins.
We ran ranking experiments using SVM-rank
(Joachims, 2006), and based on the ranking score
assigned to each start/stop instance, we derive the
relative temporal order of MEs in a chain.3 This in
turn allows us to infer temporal relations between
2http://mallet.cs.umass.edu/sequences.php
3In evaluating simultaneous, ?0.05 difference in ranking
score of starts/stops of MEs is counted as a match.
72
Relation Clinical Text Timebank
Ranking Classifier Ranking Classifier
begins 81.21 73.34 52.63 58.82
ends 76.33 69.85 61.32 82.87
simulatenous 85.45 71.31 50.23 56.58
includes 83.67 74.20 59.56 60.65
before 88.3 77.14 61.34 70.38
Table 2: Per-class accuracy (%) for ranking, classification on
clinical text and Timebank. We merge class ibefore into before.
all MEs in a chain. The ranking error on the test set
is 28.2%. On introducing the time-bin feature, the
ranking error drops to 16.8%. The overall accuracy
of ranking MEs on including the time-bin feature
is 82.16%. Each learned relation is now compared
with the pairwise classification of temporal relations
between MEs. We train a SVM classifier (Joachims,
1999) with an RBF kernel for pairwise classification
of temporal relations. The average classification ac-
curacy for clinical text using the same feature set is
71.33%. We used Timebank (v1.1) for evaluation,
186 newswire documents with 3345 event pairs. We
traverse transitive relations between events in Time-
bank, increasing the number of event-event links
to 6750 and create chains of related events to be
ranked. Classification works better on Timebank, re-
sulting in an overall accuracy of 63.88%, but rank-
ing gives only 55.41% accuracy. All classification
and ranking results from 10-fold cross validation are
presented in Table 2.
5 Discussion
In ranking, the objective of learning is formalized
as minimizing the fraction of swapped pairs over all
rankings. This model is well suited to the features
that are available in clinical text. The assumption
that all MEs in a clinical narrative are temporally re-
lated allows us to totally order events within each
narrative. This works because a clinical narrative
usually has a single protagonist, the patient. This as-
sumption, along with the availability of a fixed refer-
ence date in each narrative, allows us to effectively
extract features that work in ranking MEs. How-
ever, this assumption does not hold in newswire text:
there tend to be multiple protagonists, and it may be
possible to totally order only events that are linked to
the same protagonist. Ranking implicitly allows us
to learn the transitive relations between MEs in the
chain. Ranking ME starts/ stops captures relations
like includes and begins much better than classifi-
cation, primarily because of the date difference and
time-bin difference features. However, the hand-
tagged features available in Timebank are not suited
for this kind of model. The features work well with
classification but are not sufficiently informative to
learn time durations using our proposed event repre-
sentation in a ranking model. Features like ?tense?
that are used for temporal relation learning in Time-
bank are not very useful in ME ordering. Tense
is a temporal linguistic quality expressing the time
at, or during which a state or action denoted by a
verb occurs. In most cases, MEs are not verbs (e.g.,
colostomy). Even if we consider verbs co-occurring
with MEs, they are not always accurately reflective
of the MEs? temporal nature. Moreover, in discharge
summaries, almost all MEs or co-occurring verbs
are in the past tense (before the discharge date). This
is complicated by the fact that the reference time/
ME with respect to which the tense of the verb is
expressed is not always clear. Based on the type of
clinical narrative, when it was generated, the refer-
ence date for the tense of the verb could be in the
patient?s history, admission, discharge, or an inter-
mediate date between admission and discharge. For
similar reasons, features like POS and aspect are not
very informative in ordering MEs. Moreover, fea-
tures like aspect require annotators with not only a
clinical background but also some expert knowledge
in linguistics, which is not feasible.
6 Conclusions
Representing and reasoning with temporal informa-
tion in unstructured text is crucial to the field of natu-
ral language processing and biomedical informatics.
We presented a study on learning to rank medical
events. Temporally ordering medical events allows
us to induce a partial order of medical events over
the patient?s history. We noted many differences be-
tween learning temporal relations in clinical text and
Timebank. The ranking experiments on clinical text
yield better performance than classification, whereas
the performance is the exact opposite in Timebank.
Based on experiments in two very different domains,
we demonstrate the need to rethink the resources and
methods for temporal relation learning.
Acknowledgments
The project was supported by the NCRR,
Grant UL1RR025755, KL2RR025754, and
TL1RR025753, is now at the NCATS, Grant
8KL2TR000112-05, 8UL1TR000090-05,
8TL1TR000091-05. The content is solely the
responsibility of the authors and does not necessar-
ily represent the official views of the NIH.
73
References
James F. Allen. 1981. An interval-based representation
of temporal knowledge. In IJCAI, pages 221?226.
Olivier Bodenreider. 2004. The unified medical lan-
guage system (umls): integrating biomedical termi-
nology. Nucleic Acids Research, 32(suppl 1):D267?
D270.
Nathanael Chambers, Shan Wang, and Daniel Jurafsky.
2007. Classifying temporal relations between events.
In ACL.
A.J. Conger. 1980. Integration and generalization of
kappas for multiple raters. In Psychological Bulletin
Vol 88(2), pages 322?328.
Thorsten Joachims, Hang Li, Tie-Yan Liu, and ChengX-
iang Zhai. 2007. Learning to rank for information
retrieval (lr4ir 2007). SIGIR Forum, 41(2):58?62.
Thorsten Joachims. 1999. Making large-scale SVM
learning practical. In Bernhard Scho?lkopf, Christo-
pher John C. Burges, and Alexander J. Smola, editors,
Advances in Kernel Methods - Support Vector Learn-
ing, pages 169?184. MIT Press.
Thorsten Joachims. 2006. Training linear SVMs in linear
time. In KDD, pages 217?226.
Mirella Lapata and Alex Lascarides. 2011. Learn-
ing sentence-internal temporal relations. CoRR,
abs/1110.1394.
Inderjeet Mani, Marc Verhagen, Ben Wellner, Chong Min
Lee, and James Pustejovsky. 2006. Machine learning
of temporal relations. In ACL.
James Pustejovsky, Jos M. Castao, Robert Ingria, Roser
Sauri, Robert J. Gaizauskas, Andrea Setzer, Graham
Katz, and Dragomir R. Radev. 2003. TimeML: Ro-
bust specification of event and temporal expressions
in text. In New Directions in Question Answering?03,
pages 28?34.
A. Roberts, R. Gaizauskas, M. Hepple, G. Demetriou,
Y. Guo, and A. Setzer. 2008. Semantic Annotation of
Clinical Text: The CLEF Corpus. In Proceedings of
the LREC 2008 Workshop on Building and Evaluating
Resources for Biomedical Text Mining, pages 19?26.
Guergana K. Savova, Steven Bethard, Will Styler, James
Martin, Martha Palmer, James Masanz, and Wayne
Ward. 2009. Towards temporal relation discovery
from the clinical narrative. AMIA.
Marc Verhagen, Robert J. Gaizauskas, Frank Schilder,
Mark Hepple, Jessica Moszkowicz, and James Puste-
jovsky. 2009. The tempeval challenge: identifying
temporal relations in text. Language Resources and
Evaluation, 43(2):161?179.
Li Zhou and George Hripcsak. 2007. Temporal rea-
soning with medical data - a review with emphasis
on medical natural language processing. Journal of
Biomedical Informatics, pages 183?202.
Li Zhou, Genevieve B. Melton, Simon Parsons, and
George Hripcsak. 2006. A temporal constraint struc-
ture for extracting temporal information from clinical
narrative. Journal of Biomedical Informatics, pages
424?439.
74
Proceedings of the 2012 Workshop on Biomedical Natural Language Processing (BioNLP 2012), pages 29?37,
Montre?al, Canada, June 8, 2012. c?2012 Association for Computational Linguistics
Temporal Classification of Medical Events
Preethi Raghavan?, Eric Fosler-Lussier?, and Albert M. Lai?
?Department of Computer Science and Engineering
?Department of Biomedical Informatics
The Ohio State University, Columbus, Ohio, USA
{raghavap, fosler}@cse.ohio-state.edu, albert.lai@osumc.edu
Abstract
We investigate the task of assigning medi-
cal events in clinical narratives to discrete
time-bins. The time-bins are defined to cap-
ture when a medical event occurs relative to
the hospital admission date in each clinical
narrative. We model the problem as a se-
quence tagging task using Conditional Ran-
dom Fields. We extract a combination of lexi-
cal, section-based and temporal features from
medical events in each clinical narrative. The
sequence tagging system outperforms a sys-
tem that does not utilize any sequence infor-
mation modeled using a Maximum Entropy
classifier. We present results with both hand-
tagged as well as automatically extracted fea-
tures. We observe over 8% improvement in
overall tagging accuracy with the inclusion of
sequence information.
1 Introduction
There has been a lot of interest in building timelines
of medical events from unstructured patient narra-
tives (Jung et al, 2011; Zhou and Hripcsak, 2007).
Creating a timeline from longitudinal clinical text
requires learning temporal relations such as before,
simultaneous, includes, overlaps, begins, ends and
their inverses between medical events found within
and across patient narratives (Allen, 1981). How-
ever, learning temporal relations for fine-grained
temporal ordering of medical events in clinical text
is challenging: the temporal cues typically found in
clinical text may not always be sufficient for this
task.
An important characteristic of a clinical narrative
is that the medical events in the same narrative are
more or less semantically related by narrative dis-
course structure. However, medical events in the
narrative are not ordered chronologically. Thus, the
clinical narrative structure is not always temporally
coherent.
Moreover, extracting precise temporal features
for highly accurate temporal ordering of medical
events is difficult as the temporal relationship be-
tween medical events is varied and complicated.
Zhou and Hripcsak (2007) identify six major cate-
gories of temporal expressions from a corpus of dis-
charge summaries: ?date and time,? ?relative date
and time,? ?duration,? ?event-dependent temporal
expression,? ?fuzzy time,? and ?recurring times.?
Their study of temporal expressions in clinical text
indicates that relative time (e.g., ever since the
episode 2 days ago) may be more prevalent than ab-
solute time (e.g., 06/03/2007). Further, temporal ex-
pressions may be fuzzy where ?history of cocaine
use? may imply that cocaine use started 2 years ago
or 10 years ago.
In this paper, we address a relatively simpler task
of assigning medical events to coarsely defined time-
bins. The time-bins, way before admission, before
admission, on admission, after admission, after dis-
charge, are defined based on the relative temporal
distance of the medical event from the admission
date, which is the only explicit date almost always
found in each clinical narrative. We extract fea-
tures based on narrative structure as well as tempo-
ral expressions to label a sequence of medical events
from each clinical narrative with a highly probable
29
HISTORY   PHYSICAL                                 DATE:  06/03/2007 
NAME:  Smith Jack                           MR#:  XXX-XX-XXXX 
ATTENDING PHYSICIAN:  Bill Payne  MD             DOB:  02/28/1960 
CHIEF COMPLAINT 
Chest pain and arm infection. 
HISTORY OF PRESENT ILLNESS 
Patient is a 48-year-old male with history of cocaine use hypertension who presents with chest pain  
which started 2 days ago . He did not having  chest pain yesterday but ever since the episode 2 days ago  
he has felt a little weaker.  He did have chest pain today and this is what prompted him to come to the  
ER.  He also  notices that he has had some infections under his arms.  He states that he had to have an  
abscess I and D 3 or 4 months ago under his arm and 2 to 3 weeks ago he noticed some more spots and  
these spots have now grown and now are under both arms. Currently he is chest pain free. His blood  
pressure upon presentation was 189/106. 
REVIEW OF SYSTEMS 
On exam initial blood pressure was 189/106 current blood pressure 148/83 with heart rate of 74  
respirations  16.  Heart regular rhythm.  No murmurs.   Arms:  He does have tender areas right greater  
than left under the arm. Difficult to tell if there is any erythema but  obvious cellulitis sludge abscess  
under the right arm which is tender. 
ASSESSMENT/PLAN 
1. Chest pain history of cocaine with T-wave inversions in the inferior leads.  Currently he is chest pain free.  We will check a 2-D echocardiogram.  Consult Cardiology for a stress test.   
2. Axillary abscesses.  Consult Surgery for I and D.  We will place on IV vancomycin pain control. 
3. Cocaine abuse.  Encouraged to quit. 
 
1  
 
 
2  
 
 
3  
 
 
4  
 
 
5  
 
 
6  
 
 
7  
 
 
8  
  
9  
 
Figure 1: Excerpt from a de-identified clinical narrative
(cn1) written for a patient in 2007. Medical events are
underlined. Enumerated events (in circles) are used as an
example later in Table 1.
sequence of time-bins using Conditional Random
Fields (CRFs). The learned time-bins can be used
as an informative temporal feature for tasks such
as fine-grained temporal ordering of medical events
and medical event coreference resolution.
2 Motivation
Clinical narratives are medical reports that contain
unstructured text documenting the medical history
of the patient. Medical events are temporally-related
concepts in clinical narratives that describe medical
conditions affecting the patient?s health, or tests and
procedures performed on a patient. Sample excerpts
from two different clinical notes (cn1 and cn2) of
the same patient, generated over time, are shown in
Figures 1 and 2. We can see from the examples that
narrative structure moves back and forth in time and
is not temporally coherent. We use cn1 and cn2 as
running examples throughout the paper.
The medical events assigned to time-bins in each
clinical narrative allow us to derive a coarse tempo-
ral order between medical events within and across
the longitudinal medical history of the patient. Since
we learn time-bins centered around admission in
each narrative and we also know the admission date
and perhaps the discharge dates in cn1 and cn2, we
can derive a coarse partial order across the medi-
HISTORY   PHYSICAL                                 DATE:  06/17/2007 
NAME:  Black Jack                           MR#:  XXX-XX-XXXX 
ATTENDING PHYSICIAN:  Jack Payne MD             DOB:  02/28/1960 
He is a 48-year-old African American gentleman with a history of cocaine use and hypertension. He  
has hidradenitis of both axilla resected. The patient is MRSA positive on IV antibiotics at the present  
time.  The patient's physical condition is excellent but he had MRSA in the axilla for hidradenitis that  
was devastating.  The wounds now are very large but he is wound vac and being changed to alginate.  
Both axilla show major wounds of 20-25 cm in diameter and 4 -5 cm deep in overall size and he has  
excoriations on his chest from the tape.  The plan is to change him from vac to alginate and see him  
in a week. 
Figure 2: Excerpt from another de-identified clinical nar-
rative (cn2) for the same patient written in later in 2007.
Medical events are underlined.
cal events in cn1 and cn2. This is shown in Fig-
ure 3. Even if the discharge dates are not known,
we still know that the admission date (A1) of cn1
is 6/03/2007 and A2 of cn2 is 06/17/2007. Thus,
A2 > A1, and all the time-bins in cn2 that are on or
after admission would have happened after A2. The
partially ordered time-bins can now be used for tasks
such as medical concept coreference resolution.
In cross narrative coreference resolution tasks,
we can prune the space of candidate pairs of med-
ical events by ruling out portions of clinical nar-
ratives that will not have any coreferring medical
events. For example, in the timeline shown in Fig-
ure 3, the medical events in time-bins admission, af-
ter admission and discharge of cn2 will not corefer
with any medical event in cn1. Further, when men-
tions of the same medical events occur in different
time-bins, it could mean that they are the same in-
stance of the medical event and they corefer. For
instance, cocaine abuse and cocaine use. Similarly,
MRSA positive is assigned to time-bin on admission
whereas MRSA is assigned to before admission and
both mentions of MRSA corefer.
3 Related Work
The Timebank (Pustejovsky et al, 2003) corpus of
annotated newswire text is widely used for tempo-
ral relation learning. The TempEval challenges have
often focused on extracting different types of tempo-
ral relations from Timebank (Verhagen et al, 2009).
In Timebank, events are typically verbs that denote
change in state. Since the notion of an event in Time-
bank is different from medical events in clinical text,
it is not possible to directly train models on Time-
bank and apply them to clinical text. The THYME
work (Savova et al, 2009) extends TimeML to the
30
    A1 D1 
   A2 D2 
cocaine use  hypertension 
 chest pain   abscess 
chest pain         arm  infection 
heart regular  rhythm 
cellulitis 
2-D echocardiogram 
stress test 
MRSA positive 
hidradenitis of axilla  resected   MRSA in the axilla for hidradenitis 
wounds 
wound vac 
IV antibiotics 
alginate cocaine use  hypertension 
way before before admission after discharge 
before admission after discharge way before 
p1-cn1 
p1-cn2 
Figure 3: Medical events in clinical narratives cn1 and cn2 for patient p1 assigned to time-bins. A1 is the admission
date in cn1 and D1 is the discharge date. Similarly A2 is the admission date in cn2 and D2 is the discharge date. Thus,
we have, A1 < D1, D1 < A2, A2 < D2
medical domain to create layered annotation to be
used for event linking. Boland et al (2012) identify
the temporal knowledge representation requirements
of clinical eligibility criteria and develop a frame-
based representation designed to support semantic
annotation for temporal expressions in eligibility cri-
teria. However, the nature of data found in eligibility
criteria is different from clinical narratives.
Previous attempts at learning temporal relations
between medical events in clinical text include Jung
et al (2011) and Zhou et al (2006). Gaizauskas et
al. (2006) learn the temporal relations before, after,
is included between events from a corpus of clinical
text much like the event-event relation TLINK learn-
ing in Timebank (Pustejovsky et al, 2003). How-
ever, the corpora used in these studies are not freely
available. A comprehensive survey of temporal rea-
soning in medical data is provided by Zhou and
Hripcsak (2007).
The task addressed in this paper is at a higher
level than the temporal relation learning or tempo-
ral ordering task. Without getting into fine-grained
temporal ordering, we define coarse time-bins and
classify medical events into one of the time-bins.
We work with a similar motivation of being able
to answer clinical trial eligibility criteria with tem-
poral constraints. However, while they model the
temporal information in eligibility criteria, we pro-
cess the temporal information and medical events
in the clinical narrative to assign events to time-
bins. The learned time-bins are a step towards fine-
grained temporal ordering of medical events in clin-
ical text. More importantly, we also demonstrate
how automatic feature extraction for this task gives
us promising results, though not as good as using
hand-tagged features.
4 Problem Description
A patient could have multiple clinical narratives,
generated over a period of time, representing the pa-
tient?s longitudinal medical history. Returning to the
examples in Figures 1 and 2, in this section we de-
scribe how such clinical narratives are translated into
a temporal-bin assignment problem.
4.1 Medical event representation
Medical events in clinical narratives often have a
time duration with a corresponding start and stop
time, for example, history of hypertension (Zhou et
al., 2006). In this example, hypertension started at
some point before admission and is present to the
current date. Time duration based representation is
essential to learning the exact fine-grained tempo-
ral order of medical events within and across clin-
ical narratives. In order to keep the task of classi-
fying medical events into coarse time-bins relatively
simple and easy to learn, we use a time-point nota-
tion for representing medical events. Each mention
of a medical event is assigned to a time-bin with-
out taking into consideration whether it denotes the
beginning or end of that event. We also do not dif-
ferentiate between coreferences of the same medical
event. Thus, if chest pain is mentioned in the past
medical history and the same chest pain continues
to persist in the after admission time-bin, the two
different mentions of chest pain get anchored to dif-
31
ferent time-bins. Similarly, cocaine use started in
the history of the patient and cocaine abuse still per-
sists. We assign the two different mentions of this
medical event into different time-bins.
4.2 Time-bins
As mentioned earlier, we learn to classify medical
events into one of the following time-bins: way be-
fore admission, before admission, on admission, af-
ter admission, after discharge. The intuition behind
each time-bin label is as follows. The time-bin way
before admission is intended to capture all medical
events that happened in the past medical history of
the patient but are not mentioned as being directly
related to the present illness. Before admission cap-
tures events that occurred before admission and are
related to the present illness. On admission captures
medical events that occur on the day of admission.
After admission captures medical events that occur
between admission and discharge (during the hospi-
tal stay or clinic visit). Finally, medical events that
are supposed to occur in the future after the patient
is discharged belong to the class after discharge.
Further, the time duration of each time-bin varies
based on the patient. For instance, the hospital stay
of a patient could be 4 days or 1 month or a year.
This makes it very difficult to define exact time-bins
based on the intuitions described above. In order
to make the problem more precise and consistent
across different patients, we restrict way before ad-
mission to events that happened more than a year
ago and before admission to events that occurred in
the same year before admission. If it is unclear as
to when in the past the medical event occurred, we
assume it happened way before admission.
5 Learning time-bin assignments
We model the problem of classifying medical events
to time-bins as a sequence tagging task using CRFs
(Lafferty et al, 2001). CRFs are a joint model of
label sequence conditioned on the observation.
For the task proposed in this paper, an observation
sequence is composed of medical events in the order
in which they appear in a clinical narrative, and the
state sequence is the corresponding label sequence
of time-bins. Each label in the label sequence could
be any one of the time-bins way before admission
(wa), before admission (ba), on admission (a), after
admission (aa), after discharge (ad). Thus, given
a sequence of medical events in narrative order we
learn a corresponding label sequence of time-bins
{wb, b, a, aa, ad}.
The probability of time-bin (label) sequence y,
given a medical event (input) sequence x, is given
by,
P (Y |X) = exp
?
i
(S(x, y, i) + T (x, y, i)) (1)
where i is the medical event index and S and T are
the state and transition features respectively. State
features S consider the label of a single medical
event and are defined as,
S(x, y, i) =
?
j
?jsj(y, x, i) (2)
Transition features consider the mutual dependence
of labels yi?1 and yi (dependence between the time-
bins of the current and previous medical event in the
sequence) and are given by,
T (x, y, i) =
?
k
?ktk(yi?1, yi, x, i) (3)
where sj and tk are the state and transition feature
functions. Above, sj is a state feature function, and
?j is its associated weight and tj is a transition func-
tion, and ?j is its associated weight. In contrast to
the state function, the transition function takes as in-
put the current label as well as the previous label,
in addition to the data. The mutual dependence be-
tween the time-bins of the current and previous med-
ical events is observed frequently in sections of the
text describing the history of the patient. Around
40% of the medical events in gold standard corpus
demonstrate such dependencies.
The Maximum Entropy (MaxEnt) model (Berger
et al, 1996) estimates the probability of a time-bin
given the observed medical event. In this case, we
are interested in finding the time-bin with the maxi-
mum estimated probability.
6 Feature Space
We extract features from medical event sequences
found in each clinical narrative. The extracted
feature-set captures narrative structure in terms of
the narrative type, sections, section transitions, and
32
position in document. The medical event and the
context in which it is mentioned is captured with
the help of lexical features. The temporal features
resolve temporal references and associate medical
events with temporal expressions wherever possible.
6.1 Section-based features
Determining the document-level structure of a clin-
ical narrative is useful in mapping medical events
to time-bins. This can be achieved by identifying
different sections in different types of clinical narra-
tives and relating them to different time-bins. The
section in which the medical event is mentioned
tells us something about when it occurred. Li et al
(2010) train a hidden Markov model (HMM) to map
a sequence of sections to 15 possible known section
types in free-text narratives with high accuracy.
Commonly found sections in discharge sum-
maries and history and physical reports include:
?past medical history,? ?history of present illness,?
?findings on admission,? ?physical examination,?
?review of systems,? ?impression,? and ?assess-
ment/plan.? On the other hand, radiology notes tend
to have sections describing ?indication,? ??com-
parison,? ?findings? and ?impression?. Similarly,
pathology notes may have sections including ?clini-
cal history,? ?specimen received,? ?laboratory data?
and ?interpretation.? While some sections talk about
patient history, some other sections describe the pa-
tient?s condition after admission, or plans after dis-
charge. However, some clinical notes like cn2 in
Figure 2 may not have any section information.
The combined feature representing the type of
clinical narrative along with the section can be infor-
mative. Section transitions may also indicate a tem-
poral pattern for medical events mentioned across
those sections. For instance, ?past medical history?
(way before admission), followed by ?history of
present illness? (way before admission), followed by
?findings on admission? (on admission), followed
by ?physical examination? (after admission), fol-
lowed by ?assessment/plan? (discharge). Medical
events in different types of sections may also exhibit
different temporal patterns. A ?history of present ill-
ness? section may start with diseases and diagnoses
30 years ago and then proceed to talk about them in
the context of a medical condition that happened few
years ago and finally describe the patient?s condition
on admission.
In addition to the section information, we also use
other features extracted from the clinical narrative
structure such as the position of the medical concept
in the section and in the narrative.
6.2 Lexical features
Bigrams are pairs of words that occur in close prox-
imity to each other, and in a particular order. The
bigrams preceding the medical event in the narra-
tive can be useful in determining when it occurred.
For instance, ?history of cocaine use and hyper-
tension,? ?presents with chest pain,? ?have chest
pain,? ?since the episode,? etc. If the preceding bi-
gram contains a verb, we also extract the tense of the
verb as a feature. However, tense is not always help-
ful in learning the time of occurrence of a medical
event. Consider the following line from cn2 in Fig-
ure 2, ?He has hidradenitis of both axilla resected.?
Though ?has? is in present tense, the medical event
has actually occurred in the history and is only being
observed and noted now. Additionally, we also ex-
plicitly include the preceding bigrams and the tense
of verb for the previous and next medical event as a
feature for the current medical event.
Every medical event that occurs above a certain
frequency threshold in all the clinical narratives of
a particular patient is also represented as a binary
feature. More frequent medical events tend to occur
in the history of the patient, for example, cocaine
use. We use a threshold of 3 in our experiments.
The medical event frequency in also calculated in
combination with other features such as the type of
clinical narrative and section type.
6.3 Dictionary features
The UMLS1 includes a large Metathesaurus of con-
cepts and terms from many biomedical vocabular-
ies and a lexicon that contains syntactic, morpho-
logical, and orthographic information for biomed-
ical and common words in the English language.
We map each medical event to the closest concept
in the UMLS Metathesaurus and extract its seman-
tic category. The semantic categories in UMLS in-
clude Finding, Disease or Syndrome, Therapeutic
or Preventative procedure, Congenital abnormality,
1https://uts.nlm.nih.gov/home.html
33
and Pathologic Function. The intuition behind this is
that medical events associated with certain semantic
categories may be more likely to occur within cer-
tain time-bins. For instance, a medical event classi-
fied as ?Congenital abnormality? may be more likely
to occur way before admission.
6.4 Temporal features
Temporal features are derived from any explicit
dates that fall in the same sentence as the medical
concept. The gold-standard corpus contains anno-
tations for temporal anchors for events. Although
there are no explicit dates in cn1 and cn2, there may
be narratives where there are mentions of dates such
as fever on June 7th, 2007. In some cases, there
may also be indirect references to dates, which tell
us when the medical event occurred. The reference
date with respect to which the indirect temporal ref-
erence is made depends on the type of note. In case
of history and physical notes, the reference date is
usually the admission date. For instance, chest pain
which started 2 days ago, this would mean chest
pain which started 2 days before admission. Since
the admission date is 06/03/2007, chest pain would
have started on 06/01/2007. Similarly, 3 to 4 months
ago resolves to February 2007 or March 2007 and 2
to 3 weeks ago resolves to first or second week of
May 2007. Whenever, the exact date is fuzzy, we as-
sume the date that is farthest from the reference date
as accurate. So in case of these examples, February
2007 and first week of May 2007 are assumed to be
correct. We also calculate the difference between ad-
mission date and these dates associated with medical
events. Another fuzzy temporal expression is ?his-
tory of,? where history could mean any time frame
before admission. We assume that any medical event
mentioned along with ?history of? has occurred way
before admission.
Other implicit temporal expressions can be found
in phrases such as upon presentation yesterday, to-
day, at the present time, and now. Upon presen-
tation, at the present time, today, and now resolve
to the admission date 06/03/2007 and yesterday
resolves to the day before admission 06/02/2007.
There are some other implicit temporal expressions
expressed relative to medical events, for example,
ever since the episode 2 days ago he has felt a little
weaker. Here, episode refers to chest pain and since
chest pain happened 2 days ago, ever since then up
to the present time would resolve to the time period
between 06/01/2007 and 06/03/2007. This time pe-
riod is associated with weaker.
7 Corpus
We use annotators that are students or recently grad-
uated students from diverse clinical backgrounds
with varying levels of clinical experience to anno-
tate a corpus of clinical narratives from the medical
center. The corpus consists of narratives specifically
from MRSA cases and consists of admission notes,
radiology and pathology reports, history and physi-
cal reports and discharge summaries. The features
marked by the annotators include medical events;
corresponding time-bin; corresponding UMLS con-
cept identifier; the UMLS semantic category; tem-
poral expressions; the link between temporal expres-
sions and medical events, if any; and the section un-
der which the medical event is mentioned, if any.
The annotators marked 1854 medical events across
5 patients and 51 clinical narratives. The annotation
agreement across our team of annotators is high; all
annotators agreed on 89.5% of the events and our
overall inter-annotator Cohen?s kappa statistic (Con-
ger, 1980) for medical events was 0.865.
While we found the inter-annotator agreement
for medical event UMLS concept identifiers to be
lower than for medical events and temporal expres-
sions, agreement was still very high. We discov-
ered that in many cases there was either a dis-
crepancy in the granularity to which the medical
events were coded or whether or not clinical judg-
ment was used in selecting the concept identifier.
For example, all of our annotators marked ?B-Cell
CLL? as an event. Three of them coded this term
as ?C0023434: Chronic Lymphocytic Leukemia.?
Two others coded this event as ?C0475774: B-cell
chronic lymphocytic leukemia variant.? While both
could be considered correct annotations for ?B-Cell
CLL,? C0475774 is the more specific term. In
another example, all of the annotators marked the
phrase ?white blood cell count of 10,000.? For this
situation, one of them selected ?C0750426: white
blood cell count increased,? while another selected
?C0023508: White Blood Cell count procedure.? In
contrast, the other three selected different concept
34
identifiers, applying clinical judgment to the medi-
cal events. One other annotator selected ?C0860797:
differential white blood cell count normal.?
We use this gold-standard corpus for our exper-
iments. We conduct two sets of experiments with
the clinical narratives in this corpus: 1) Medical
event, Time-bin experiments using hand-tagged fea-
tures from the corpus and 2) Medical event, Time-
bin experiments using automatically extracted fea-
tures from the corpus.
8 Experiments
We first conducted experiments using the hand-
tagged features in our corpus. Based on these
features, we generated the section-based, lexical,
dictionary and temporal features described in the
previous sections. We used 10-fold cross vali-
dation in all our experiments. We use the Mal-
let2 implementation of CRFs and MaxEnt. CRFs
are trained by Limited-Memory Broyden-Fletcher-
Goldfarb-Shanno (BFGS) for our experiments. The
per-class accuracy values of both sequence tagging
using CRFs and using a MaxEnt model are indicated
in Table 3.
When modeled as a multi-class classification task
using MaxEnt, we get an average precision of 81.2%
and average recall of 71.4% whereas using CRFs we
obtain an average precision of 89.4% and average
recall of 79.2%. In order to determine the utility
of temporal features, we do a feature ablation study
with the temporal features removed. In this case
the average precision of the CRF is 79.5% and av-
erage recall is 67.2%. Similarly, when we remove
the section-based features, the average precision of
the CRF is 82.7% and average recall is 72.3%. The
section-based features seems to impact the precision
of the on admission and after admission time-bins
the most.
We compare our approach for classifying medi-
cal events to time-bins with the following baseline
model. We assign medical events to time-bins based
on the type of narrative, any explicit dates and sec-
tion in which they occur. Each section is associated
with a pre-defined time-bin. In the case of the sec-
tions in cn1, any medical event under ?history of
present illness? is before admission, ?review of sys-
2http://mallet.cs.umass.edu/
Medical Event Baseline MaxEnt CRF Gold
1?cocaine use ba wa wa wa
2?hypertension ba wa wa wa
3?chest pain ba ba ba ba
4?episode ba ba ba ba
5?chest pain ba ba a a
6?infections ba wa ba ba
7?abscess ba ba ba ba
8?spots ba ba ba ba
9?chest pain free ba wa a a
Table 1: Time-bin predictions by the section baseline
method, MaxEnt model and CRF for a subset of medi-
cal events marked in cn1 in Figure 1.
Class(time-bin) Section baseline
P R
way before admission (wa) 56.3 61.4
before admission (ba) 60.2 57.5
on admission (a) 63.8 59.1
after admission (aa) 57.5 68.2
after discharge (ad) 52.3 55.1
Table 2: Per-class precision (P) and recall (R) for medical
events, time-bins using hand-tagged extracted features.
tems? is after admission and ?assessment/plan? is
discharge. If the narrative has a ?past medical his-
tory? or a similar section, the events mentioned un-
der it would be assigned to way before admission.
Partial results of (medical event, time-bin) assign-
ment in cn2 as per this baseline can be seen in Table
1. However, this baseline does not work for clinical
narratives like cn2 that do not have any section in-
formation. This model gives us an average precision
of 58.02% and average recall of 60.26% across the 5
time-bins. Per-class predictions for the baseline are
shown in Table 2.
The most common false positives for the before
admission class are medical events belonging to on
admission. This may be due to lack of temporal fea-
tures to indicate that the event happened on the same
day as admission. Frequently, medical events that
belong to the aa, ba and wa time-bin get classified
as after discharge. One of the reasons for this could
be misleading section information in case of histori-
cal medical events mentioned in the assessment/plan
section.
Next, we conduct experiments using automati-
cally extracted features. This is done as follows. The
medical events are extracted using MetaMap, which
recognizes medical concepts and codes them using
35
Class(time-bin) MaxEnt CRF
P R P R
way before admission (wa) 72.4 63.5 79.8 66.7
before admission (ba) 83.4 80.8 92.0 92.4
on admission (a) 76.6 72.1 87.5 75.2
after admission (aa) 88.6 82.1 93.6 99.1
after discharge (ad) 85.2 58.7 94.3 62.5
Table 3: Per-class precision (P) and recall (R) for medical
events, time-bins using hand-tagged extracted features.
UMLS (Aronson, 2001). Based on this UMLS code,
we can extract the semantic category associated with
the code. Compared to the 1854 medical events
marked by the annotators, MetaMap identifies 1257
medical events, which are a subset of the 1854. The
UMLS coding by the annotators is more contextu-
ally relevant and precise. We use a rule-based al-
gorithm to identify and extract document structure
based features such as sections from clinical narra-
tives. The rules are formulated based on commonly
occurring sections in our corpus. We extract lines
that are all upper-case, and longer than a word and
use their stemmed representation to sort them by fre-
quency of occurrence in the corpus. While parsing
the text in each clinical narrative, on encountering
a line that matches a section title from the frequent
list, all subsequent lines are associated with that title
until a new section title is encountered. In case of the
lexical features, we extract bigrams and calculate the
tense of the verb preceding the medical event using
the Stanford NLP software.3 The temporal features
are extracted with the help of TimeText developed
by Zhou and Hripcsak (2007) that automatically an-
notates temporal expressions in clinical text. How-
ever, it is not able to capture many of the implicit
temporal references. Following this, a temporal ex-
pression is linked to a medical event if it occurs in
the same sentence as the medical event.
The average precision and recall of the Max-
Ent model using automatically extracted features is
74.3% and 66.5% respectively. Sequence tagging
using CRFs gives us an average precision and recall
of 79.6% and 69.7% respectively. Although the re-
sults are not as good as using hand-tagged features,
they are certainly promising. One reason for the loss
in accuracy could be because the automatically cal-
culated temporal features are not as precise as the
3http://nlp.stanford.edu/software/
Gold-standard Features
P R
ME 81.2 71.4
CRF 89.4 79.2
CRF(no temp. feats) 79.5 67.2
CRF(no section feats) 82.7 72.3
Automatic Features
P R
ME 74.3 66.5
CRF 79.6 69.7
Baseline (P;R) 58.02 60.26
Table 4: Overall Result Summary: Average precision
(P) and recall (R) with manually annotated gold-standard
features, automatically extracted features and the base-
line.
hand-tagged ones. These results are summarized in
Table 4.
9 Conclusion
We investigate the task of classifying medical events
in clinical narratives to coarse time-bins. We de-
scribe document structure based, lexical and tempo-
ral features in clinical text and explain how these
feature are useful in time-binning medical events.
The extracted feature-set when used in a sequence
tagging framework with CRFs gives us high accu-
racy when compared with a section-based baseline
or a MaxEnt model. The learned time-bins can
be used as an informative feature for tasks such as
fine-grained ordering of medical events and medical
event coreference resolution. We also experiment
with hand-tagged vs. automatically extracted fea-
tures for this task and observe that while automati-
cally extracted features show promising results, they
are not as good as using hand-tagged features for this
task.
Acknowledgments
The project described was supported by the
National Center for Research Resources,
Grant UL1RR025755, KL2RR025754, and
TL1RR025753, and is now at the National
Center for Advancing Translational Sciences,
Grant 8KL2TR000112-05, 8UL1TR000090-05,
8TL1TR000091-05. The content is solely the re-
sponsibility of the authors and does not necessarily
represent the official views of the NIH.
36
References
James F. Allen. 1981. An interval-based representation
of temporal knowledge. In IJCAI, pages 221?226.
Alan R. Aronson. 2001. Effective mapping of biomed-
ical text to the UMLS Metathesaurus: the MetaMap
program. Proc of AMIA Symposium, pages 17?21.
Adam Berger, Stephen Della Pietra, and Vincent Della
Pietra. 1996. A maximum entropy approach to nat-
ural language processing. Computational Linguistics,
22:39?71.
Mary Regina Boland, Samson W. Tu, Simona Carini, Ida
Sim, and Chunhua Weng. 2012. EliXR: An Approach
to Eligibility Criteria Extraction and Representation.
Proc of AMIA Clinical Research Informatics Summit.
Anthony J. Conger. 1980. Integration and generalization
of kappas for multiple raters. In Psychological Bul-
letin Vol 88(2), pages 322?328.
Rob Gaizauskas, Henk Harkema, Mark Hepple, and An-
drea Setzer. 2006. Task-oriented extraction of tem-
poral information: The case of clinical narratives.
In Proceedings of the Thirteenth International Sym-
posium on Temporal Representation and Reasoning,
TIME ?06, pages 188?195.
Hyuckchul Jung, James Allen, Nate Blaylock, Will
de Beaumont, Lucian Galescu, and Mary Swift. 2011.
Building timelines from narrative clinical records: ini-
tial results based-on deep natural language under-
standing. In Proceedings of BioNLP 2011 Workshop,
BioNLP ?11, pages 146?154.
John D. Lafferty, Andrew McCallum, and Fernando C. N.
Pereira. 2001. Conditional random fields: Probabilis-
tic models for segmenting and labeling sequence data.
In Proceedings of the Eighteenth International Con-
ference on Machine Learning, ICML ?01, pages 282?
289.
Ying Li, Sharon Lipsky Gorman, and Noemie Elhadad.
2010. Section classification in clinical notes using su-
pervised hidden markov model. In IHI, pages 744?
750.
James Pustejovsky, Jose? M. Castan?o, Robert Ingria,
Roser Sauri, Robert J. Gaizauskas, Andrea Setzer,
Graham Katz, and Dragomir R. Radev. 2003.
TimeML: Robust specification of event and temporal
expressions in text. In New Directions in Question An-
swering ?03, pages 28?34.
Guergana Savova, Steven Bethard, Will Styler, James
Martin, Martha Palmer, James Masanz, and Wayne
Ward. 2009. Towards temporal relation discovery
from the clinical narrative. Proc of AMIA Symposium,
pages 568?572.
Marc Verhagen, Robert J. Gaizauskas, Frank Schilder,
Mark Hepple, Jessica Moszkowicz, and James Puste-
jovsky. 2009. The TempEval challenge: identifying
temporal relations in text. Language Resources and
Evaluation, 43(2):161?179.
Li Zhou and George Hripcsak. 2007. Temporal rea-
soning with medical data - a review with emphasis
on medical natural language processing. Journal of
Biomedical Informatics, pages 183?202.
Li Zhou, Genevieve B. Melton, Simon Parsons, and
George Hripcsak. 2006. A temporal constraint struc-
ture for extracting temporal information from clinical
narrative. Journal of Biomedical Informatics, pages
424?439.
37
