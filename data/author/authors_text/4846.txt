Proceedings of the ACL Interactive Poster and Demonstration Sessions,
pages 37?40, Ann Arbor, June 2005. c?2005 Association for Computational Linguistics
Learning Source-Target Surface Patterns for  
Web-based Terminology Translation 
 
Jian-Cheng Wu 
Department of Computer Science 
National Tsing Hua University 
101, Kuangfu Road,  
Hsinchu, 300, Taiwan 
D928322@oz.nthu.edu.tw 
Tracy Lin 
Dep. of Communication Eng. 
National Chiao Tung University 
1001, Ta Hsueh Road,  
Hsinchu, 300, Taiwan 
tracylin@cm.nctu.edu.tw 
Jason S. Chang 
Department of Computer Science 
National Tsing Hua University 
101, Kuangfu Road,  
Hsinchu, 300, Taiwan 
jschang@cs.nthu.edu.tw 
 
Abstract 
This paper introduces a method for learn-
ing to find translation of a given source 
term on the Web. In the approach, the 
source term is used as a query and part of 
patterns to retrieve and extract transla-
tions in Web pages. The method involves 
using a bilingual term list to learn source-
target surface patterns. At runtime, the 
given term is submitted to a search engine 
then the candidate translations are ex-
tracted from the returned summaries and 
subsequently ranked based on the surface 
patterns, occurrence counts, and translit-
eration knowledge. We present a proto-
type called TermMine that applies the 
method to translate terms. Evaluation on a 
set of encyclopedia terms shows that the 
method significantly outperforms the 
state-of-the-art online machine translation 
systems. 
1 Introduction 
Translation of terms has long been recognized as 
the bottleneck of translation by translators. By re-
using prior translations a significant time spent in 
translating terms can be saved. For many years 
now, Computer-Aided Translation (CAT) tools 
have been touted as very useful for productivity 
and quality gains for translators. CAT tools such as 
Trados typically require up-front investment to 
populate multilingual terminology and translation 
memory. However, such investment has proven 
prohibitive for many in-house translation depart-
ments and freelancer translators and the actual 
productivity gains realized have been insignificant 
except for a few, very repetitive types of content. 
Much more productivity gain could be achieved by 
providing translation service of terminology. 
Consider the job of translating a textbook such 
as ?Artificial Intelligence ? A Modern Approach.? 
The best practice is probably to start by translating 
the indexes (Figure 1). It is not uncommon for 
these repetitive terms to be translated once and 
applied consistently throughout the book. For ex-
ample, A good translation F = "????" for the 
given term E = "acoustic model," might be avail-
able on the Web due to the common practice of 
including the source terms (often in brackets,  see 
Figure 2)  when   using  a   translated term (e.g. 
"???????????Acoustic Model? ?
????  ?"). The surface patterns of co-
occurring source and target terms (e.g., "F?E") 
can be learned by using the Web as corpus. Intui-
tively, we can submit E and F to a search engine  
 
Figure 1. Some index entries in ?Artificial intelli-
gence ? A Modern Approach? page 1045. 
academy award, 458 
accessible, 41 
accusative case, 806 
Acero, A., 580, 1010 
Acharya, A., 131, 994 
achieves, 389 
Ackley, D. H., 133, 987 
acoustic model, 568 
 
Figure 2. Examples of web page summaries with 
relevant translations returned by Google for some 
source terms in Figure 1. 
1. ... ???? Academy Awards. ???? Berlin International 
Film Festival. ... 
2. ... ?????????(inherent Case)???????
(accusative Case)???? ... 
3. ... ??????????(Alfred H. Ackley) ??????
??????????????.. 
4. ..?????? ??????????????????
?????????Acoustic Model??????... 
37
and then extract the strings beginning with F and 
ending with E (or vice versa) to obtain recurring 
source-target patterns. At runtime, we can submit 
E as query, request specifically for target-language 
web-pages. With these surface patterns, we can 
then extract translation candidates Fs from the 
summaries returned by the search engine. Addi-
tional information of occurrence counts and trans-
literation patterns can be taken into consideration 
to rank Fs. 
 
Table 1. Translations by the machine translation 
system Google Translate and TermMine. 
Terms Google Translate TermMine
academy award *???? ???? 
accusative case *???? ?? 
Ackley - ??? 
acoustic model *???? ???? 
 
For instance, among many candidate translations, 
we will pick the translations "????" for "acous-
tic model" and "???" for "Ackley, " because 
they fit certain surface-target surface patterns and 
appears most often in the relevant webpage sum-
maries. Furthermore, the first morpheme "?" in "
???" is consistent with prior transliterations of 
"A-" in "Ackley" (See Table 1). 
We present a prototype system called TermMine, 
that automatically extracts translation on the Web 
(Section 3.3) based on surface patterns of target 
translation and source term in Web pages auto-
matically learned on bilingual terms (Section 3.1). 
Furthermore, we also draw on our previous work 
on machine transliteration (Section 3.2) to provide 
additional evidence. We evaluate TermMine on a 
set of encyclopedia terms and compare the quality 
of translation of TermMine (Section 4) with a 
online translation system. The results seem to indi-
cate the method produce significantly better results 
than previous work. 
2 Related Work 
There is a resurgent of interested in data-intensive 
approach to machine translation, a research area 
started from 1950s. Most work in the large body of 
research on machine translation (Hutchins and 
Somers, 1992), involves production of sentence-
by-sentence translation for a given source text. In 
our work, we consider a more restricted case where 
the given text is a short phrase of terminology or 
proper names (e.g., ?acoustic model? or ?George 
Bush?).  
A number of systems aim to translate words and 
phrases out of the sentence context. For example, 
Knight and Graehl (1998) describe and evaluate a 
multi-stage method for performing backwards 
transliteration of Japanese names and technical 
terms into English by the machine using a genera-
tive model. In addition, Koehn and Knight (2003) 
show that it is reasonable to define noun phrase 
translation without context as an independent MT 
subtask and build a noun phrase translation subsys-
tem that improves statistical machine translation 
methods. 
Nagata, Saito, and Suzuki (2001) present a sys-
tem for finding English translations for a given 
Japanese technical term by searching for mixed 
Japanese-English texts on the Web. The method 
involves locating English phrases near the given 
Japanese term and scoring them based on occur-
rence counts and geometric probabilistic function 
of byte distance between the source and target 
terms. Kwok also implemented a term translation 
system for CLIR along the same line. 
Cao and Li (2002) propose a new method to 
translate base noun phrases. The method involves 
first using Web-based method by Nagata et al, and 
if no translations are found on the Web, backing 
off to a hybrid method based on dictionary and 
Web-based statistics on words and context vectors. 
They experimented with noun-noun NP report that 
910 out of 1,000 NPs can be translated with an av-
erage precision rate of 63%.  
In contrast to the previous research, we present a 
system that automatically learns surface patterns 
for finding translations of a given term on the Web 
without using a dictionary. We exploit the conven-
tion of including the source term with the transla-
tion in the form of recurring patterns to extract 
translations. Additional evident of data redundancy 
and transliteration patterns is utilized to validate 
translations found on the Web. 
3 The TermMine System 
In this section we describe a strategy for searching 
the Web pages containing translations of a given 
term (e.g., ?Bill Clinton? or ?aircraft carrier?) and 
extracting translations therein. The proposed 
method involves learning the surface pattern 
38
knowledge (Section 3.1) necessary for locating 
translations. A transliteration model automatically 
trained on a list of proper name and transliterations 
(Section 3.2) is also utilized to evaluate and select 
transliterations for proper-name terms. These 
knowledge sources are used in concert to search, 
rank, and extract translations (Section 3.3). 
3.1 Source and Target Surface patterns 
With a set of terms and translations, we can learn 
the co-occurring patterns of a source term E and its 
translation F following the procedure below: 
(1) Submit a conjunctive query (i.e. E AND F) for 
each pair (E, F) in a bilingual term list to a 
search engine. 
(2) Tokenize the retrieved summaries into three 
types of tokens: I. A punctuation II. A source 
word, designated with the letter "w" III. A 
maximal block of target words (or characters in 
the case of language without word delimiters 
such as Mandarin or Japanese). 
(3) Replace the tokens for E?s instances with the 
symbol ?E? and the type-III token containing 
the translation F with the symbol ?F?. Note the 
token denoted as ?F? is a maximal string cover-
ing the given translation but containing no 
punctuations or words in the source language. 
(4) Calculate the distance between E and F by 
counting the number of tokens in between.  
(5) Extract the strings of tokens from E to F (or the 
other way around) within a maximum distance 
of d (d is set to 3) to produce ranked surface 
patterns P. 
 
For instance, with the source-target pair ("Califor-
nia," "??") and a retrieved summary of "...??
??. ??? Northern California. ...," the surface 
pattern "FwE" of distance 1 will be derived. 
3.2 Transliteration Model  
TermMine also relies on a machine transliteration 
model (Lin, Wu and Chang 2004) to confirm the 
transliteration of proper names. We use a list of 
names and transliterations to estimate the translit-
eration probability function P(? | ?), for any given 
transliteration unit (TU) ? and transliteration char-
acter (TC) ?. Based on the Expectation Maximiza-
tion (EM) algorithm. A TU for an English name 
can be a syllable or consonants which corresponds 
to a character in the target transliteration. Table 2 
shows some examples of sub-lexical alignment 
between proper names and transliterations. 
Table 2. Examples of aligned transliteration units. 
Name transliteration Viterbi alignment 
Spagna ???? s-? pag-? n-? a-?
Kohn ?? Koh-? n-? 
Nayyar ?? Nay-? yar-? 
Rivard ??? ri-? var-? d-? 
Hall ?? ha-? ll-? 
Kalam ?? ka-? lam-? 
Figure 3. Transliteration probability trained on 
1,800 bilingual names (? denotes an empty string). 
? ? P(?|?) ? ? P(?|?) ? ? P(?|?)
? .458 b ? .700 ye ? .667 
? .271  ? .133  ? .333 
? .059  ? .033 z ? .476 
a 
? .051  ? .033  ? .286 
? .923 an ? .923  ? .095 an 
? .077  ? .077  ? .048 
3.3 Finding and locating translations 
At runtime, TermMine follows the following steps 
to translate a given term E: 
(1) Webpage retrieval. The term E is submitted to 
a Web search engine with the language option 
set to the target language to obtain a set of 
summaries.  
(2) Matching patterns against summaries. The 
surface patterns P learned in the training phase 
are applied to match E in the tokenized summa-
ries, to extract a token that matches the F sym-
bol in the pattern. 
(3) Generating candidates. We take the distinct 
substrings C of all matched Fs as the candidates. 
(4) Ranking candidates. We evaluate and select 
translation candidates by using both data re-
dundancy and the transliteration model. Candi-
dates with a count or transliteration probability 
lower than empirically determined thresholds 
are discarded. 
I. Data redundancy. We rank translation candi-
dates by numbers of instances it appeared in the 
retrieved summaries. 
II. Transliteration Model. For upper-case E, we 
assume E is a proper name and evaluate each 
candidate translation C by the likelihood of C as 
the transliteration of E using the transliteration 
model described in (Lin, Wu and Chang 2004).  
39
Figure 4. The distribution of distances between 
source and target terms in Web pages. 
0
1000
2000
3000
4000
5000
Distance
Co
un
t
Count 63 111 369 2182 4961 2252 718 91 34
-4 -3 -2 -1 0 1 2 3 4
Figure 5. The distribution of distances between 
source and target terms in Web pages. 
Pattern Count Acc. Percent Example distance
FE 3036 28.1% ???? ATLAS 0 
EF 1925 45.9% Elton John???? 0 
E(F 1485 59.7% Austria(??? -1 
F?E 1251 71.2% ?????Atlas 1 
F(E 361 74.6% ????(Atlas 1 
F.E 203 76.5% Peter Pan. ??? 1 
EwF 197 78.3% ?? Northern California -1 
E,F 153 79.7% Mexico, ??? -1 
F??E 137 81.0% ??????Titanic 2 
F??E 119 82.1% ??????Atlas 2 
 
 
(5) Expanding the tentative translation. Based 
on a heuristics proposed by Smadja (1991) to 
expand bigrams to full collocations, we extend 
the top-ranking candidate with count n on both 
sides, while keeping the count greater than n/2 
(empirically determined). Note that the con-
stant n is set to 10 in the experiment described 
in Section 4. 
(6) Final ranking. Rank the expanded versions of 
candidates by occurrence count and output the 
ranked list. 
4 Experimental results 
We took the answers of the first 215 questions on a 
quiz Website (www.quiz-zone.co.uk) and hand-
translations as the training data to obtain a of sur-
face patterns. For all but 17 source terms, we are 
able to find at least 3 instances of co-occurring of 
source term and translation. Figure 4 shows distri-
bution of the distances between co-occurring 
source and target terms. The distances tend to con-
centrate between - 3 and + 3 (10,680 out of 12,398 
instances, or 86%). The 212 surface patterns ob-
tained from these 10,860 instances, have a very 
skew distribution with the ten most frequent sur-
face patterns accounting for 82% of the cases (see 
Figure 5). In addition to source-target surface pat-
terns, we also trained a transliteration model (see 
Figure 3) on 1,800 bilingual proper names appear-
ing in Taiwanese editions of Scientific American 
magazine.  
Test results on a set of 300 randomly selected 
proper names and technical terms from Encyclope-
dia Britannica indicate that TermMine produces 
300 top-ranking answers, of which 263 is the exact 
translations (86%) and 293 contain the answer key 
(98%). In comparison, the online machine transla-
tion service, Google translate produces only 156 
translations in full, with 103 (34%) matching the 
answer key exactly, and 145 (48%) containing the 
answer key. 
5 Conclusion 
We present a novel Web-based, data-intensive ap-
proach to terminology translation from English to 
Mandarin Chinese. Experimental results and con-
trastive evaluation indicate significant improve-
ment over previous work and a state-of-sate 
commercial MT system.  
References 
Y. Cao and H. Li. (2002). Base Noun Phrase Translation Us-
ing Web Data and the EM Algorithm, In Proc. of COLING 
2002, pp.127-133. 
W. Hutchins and H. Somers. (1992). An Introduction to Ma-
chine Translation. Academic Press. 
K. Knight, J. Graehl. (1998). Machine Transliteration. In 
Journal of Computational Linguistics 24(4), pp.599-612. 
P. Koehn, K. Knight. (2003). Feature-Rich Statistical Transla-
tion of Noun Phrases. In Proc. of ACL 2003, pp.311-318. 
K. L. Kwok, The Chinet system. (2004). (personal 
communication). 
T. Lin, J.C. Wu, J. S. Chang. (2004). Extraction of Name and 
Transliteration in Monolingual and Parallel Corpora. In 
Proc. of AMTA 2004, pp.177-186. 
M. Nagata, T. Saito, and K. Suzuki. (2001). Using the Web as 
a bilingual dictionary. In Proc. of ACL 2001 DD-MT 
Workshop, pp.95-102. 
F. A. Smadja. (1991). From N-Grams to Collocations: An 
Evaluation of Xtract. In Proc. of ACL 1991,  pp.279-284. 
40
Class Based Sense Definition Model for Word Sense Tagging and Disambiguation 
Tracy Lin 
Department of Communication Engineering 
National Chiao Tung University, 
1001, Ta Hsueh Road, Hsinchu, 300, Taiwan, ROC 
tracylin@cm.nctu.edu.tw  
 
Jason S. Chang 
Department of Computer Science 
National Tsing Hua University 
101, Kuangfu Road, Hsinchu, 300, Taiwan, ROC 
jschang@cs.nthu.edu.tw 
 
Abstract 
We present an unsupervised learning 
strategy for word sense disambiguation 
(WSD) that exploits multiple linguistic 
resources including a parallel corpus, a bi-
lingual machine readable dictionary, and a 
thesaurus. The approach is based on Class 
Based Sense Definition Model (CBSDM) 
that generates the glosses and translations 
for a class of word senses. The model can 
be applied to resolve sense ambiguity for 
words in a parallel corpus. That sense 
tagging procedure, in effect, produces a 
semantic bilingual concordance, which 
can be used to train WSD systems for the 
two languages involved. Experimental re-
sults show that CBSDM trained on 
Longman Dictionary of Contemporary 
English, English-Chinese Edition 
(LDOCE E-C) and Longman Lexicon of 
Contemporary English (LLOCE) is very 
effectively in turning a Chinese-English 
parallel corpus into sense tagged data for 
development of WSD systems. 
1. Introduction 
Word sense disambiguation has been an important 
research area for over 50 years. WSD is crucial for 
many applications, including machine translation, 
information retrieval, part of speech tagging, etc. 
Ide and Veronis (1998) pointed out the two major 
problems of WSD: sense tagging and data sparse-
ness. On one hand, tagged data are very difficult to 
come by, since sense tagging is considerably more 
difficult than other forms of linguistic annotation. 
On the other hand, although the data sparseness is 
a common problem, it is especially severe for 
WSD. The problems were attacked in various ways. 
Yarowsky (1992) showed a class-based approach 
under which a very large untagged corpus and the-
saurus can be used effectively for unsupervised 
training for noun homograph disambiguation. 
However, the method does not offer a method that 
explicitly produces sense tagged data for any given 
sense inventory. Li and Huang (1999) described a 
similar unsupervised approach for Chinese text 
based on a Chinese thesaurus. As noted in Meri-
aldo (1994), even minimal hand tagging improved 
on the results of unsupervised methods. Yarowsky 
(1995) showed that the learning strategy of boot-
strapping from small tagged data led to results ri-
valing supervised training methods. Li and Li 
(2002) extended the approach by using corpora in 
two languages to bootstrap the learning process. 
They showed bilingual bootstrapping is even more 
effective. The bootstrapping approach is limited by 
lack of a systematic procedure of preparing seed 
data for any word in a given sense inventory. The 
approach also suffers from errors propagating from 
one iteration into the next. Li and Huang  
 
Another alternative involves using a parallel 
corpus as a surrogate for tagged data. Gale, Church 
and Yarowsky (1992) exploited the so-called one 
sense per translation constraint for WSD. They 
reported high precision rates of a WSD system for 
two-way disambiguation of six English nouns 
based on their translations in an English-French 
Parallel corpus. However, when working with a 
particular sense inventory, there is no obvious way 
to know whether the one sense per translation con-
straint holds or how to determine the relevant 
translations automatically. 
 
Diab and Resnik (2002) extended the transla-
tion-based learning strategy with a weakened con-
straint that many instances of a word in a parallel 
corpus often correspond to lexically varied but se-
mantically consistent translations. They proposed 
to group those translations into a target set, which 
can be automatically tagged with correct senses 
based on the hypernym hierarchy of WordNet. 
Diab and Resnik?s work represents a departure 
from previous unsupervised approaches in that no 
seed data is needed and explicit tagged data are 
produced for a given sense inventory (WordNet in 
their case). The system trained on the tagged data 
was shown to be on a par with the best ?supervised 
training? systems in SENSEVAL-2 competition. 
However, Diab and Resnik?s method is only appli-
cable to nominal WordNet senses. Moreover, the 
method is seriously hampered by noise and seman-
tic inconsistency in a target set. Worse still, it is 
not always possible to rely on the hypernym hier-
archy for tagging a target set. For instance, the 
relevant senses of the target set of {serve, tee off} 
for the Chinese counterpart  [faqiu] do not 
have a common hypernym: 
 
Sense 15 
serve ? (put the ball into play; as in games like tennis) 
? move ? (have a turn; make one?s move in a game) 
Sense 1 
Tee off ? (strike a golf ball from a tee at the start of a game) 
? play ? (participating in game or sports) 
? compete ? (compete for something) 
 
This paper describes a new WSD approach to 
simultaneously attack the problems of tagging and 
data sparseness. The approach assumes the avail-
ability of a parallel corpus of text written in E (the 
first language, L1+) and C (the second language, 
L2), an L1 to L2 bilingual machine readable dic-
tionary M, and a L1 thesaurus T. A so-called Mu-
tually Assured Resolution of Sense Algorithm 
(MARS) and Class Based Sense Definition Model 
(CBSDM) are proposed to identify the word senses 
in I for each word in a semantic class of words L in 
T. Unlike Diab and Resnik, we do not apply the 
MARS algorithm directly to target sets to avoid 
the noisy words therein. The derived classes senses 
and their relevant glosses in L1 and L2 make it 
possible to build Class Based Sense Definition and 
Translation Models (CBSDM and CBSTM), which 
subsequently can be applied to assign sense tags to 
words in a parallel corpus. 
The main idea is to exploit the defining L1 and 
L2 words in the glosses to resolve the sense ambi-
                                                           
+
 This has nothing to do with the direction of translation and is 
not to be confused with the native and second language dis-
tinction made in the literature of Teaching English As a Sec-
ond Language (TESL) and Computer Assisted Language 
Learning. 
guity. For instance, for the class containing ?serve? 
and ?tee off,? the approach exploits common defin-
ing words, including ?ball? and ?game? in two 
relevant serve-15 and tee off-1 to assign the cor-
rect senses to ?serve? and ?tee off.? The character 
bigram  [faqiu] in an English-Chinese 
MRD: 
 
serve v 10 [I?; T1] to begin play by striking  (the 
ball) to the opponent  (LDOCE E-C p. 
1300), 
 
would make it possible to align and sense tag 
?serve? or ?tee off? in a parallel corpus such as the 
bilingual citations in Example 1:  
 
(1C)  
(1E) drink a capful before teeing off at each hole. 
(Source: Sinorama, 1999, Nov. Issue, p.15, Who 
Played the First Stroke?). 
 
That effectively attaches semantic information to 
bilingual citations and turns a parallel corpus into a 
Bilingual Semantic Concordance (BSC). The BSC 
enables us to simultaneously attack two critical 
WSD problems of sense tagging difficulties and 
data sparseness, thus provides an effective ap-
proach to WSD. BSC also embodies a projection 
of the sense inventory from L1 onto L2, thus cre-
ates a new sense inventory and semantic concor-
dance for L2. If I is based on WordNet for English, 
it is then possible to obtain an L2 WordNet. There 
are many additional applications of BSC, including 
bilingual lexicography, cross language information 
retrieval, and computer assisted language learning. 
 
The remainder of the paper is organized as fol-
lows: Sections 2 and 3 lay out the approach and 
describe the MARS and SWAT algorithms. Sec-
tion 4 describes experiments and evaluation. Sec-
tion 5 contains discussion and we conclude in 
Section 6. 
2. Class Based Sense Definition Model 
We will first illustrate our approach with an exam-
ple. A formal treatment of the approach will follow 
in Section 2.2. 
2.1 An example 
To make full use of existing machine readable dic-
tionaries and thesauri, some kind of linkage and 
integration is necessary (Knight and Luk, 1994). 
Therefore, we are interested in linking thesaurus 
classes and MRD senses: Given a thesaurus class S, 
it is important that the relevant senses for each 
word w in S is determined in a MRD-based sense 
inventory I. We will show such linkage is useful 
for WSD and is feasible, based solely on the words 
of the glosses in I. For instance, given the follow-
ing set of word (N060) in Longman Lexicon of 
Contemporary English  (McArthur 1992): 
L = {difficult, hard, stiff, tough, arduous, awkward}. 
Although those words are highly ambiguous, 
the juxtaposition immediately brings to mind the 
relevant senses. Specifically for the sense inven-
tory of LDOCE E-C, the relevant senses for L are 
as follows: 
 
Therefore, we have the intended senses, S 
S = {difficult-1, hard-2, stiff-6, tough-4, arduous-1, awk-
ward-2}.  
It is reasonable to assume each sense in I is ac-
companied by a sense definition written in the 
same language (L1). We use D(S) to denote the 
glosses of S. Therefore we have 
D(S) = ?not easy; hard to do, make, understand, etc.;  diffi-
cult to do or understand; difficult to do; difficult to do; not 
easy; demanding effort; needing much effort; difficult; not 
well made for use; difficult to use; causing difficulty;?  
The intuition of bringing out the intended 
senses of semantically related words can be for-
malized by Class Based Sense Definition Model 
(CBSDM), which is a micro language model gen-
erating D(S), the glosses of S in I. For simplicity, 
we assume an unigram language model P(d) that 
generates the content words d in the glosses of S. 
Therefore, we have 
D(S) = ?easy hard do make understand difficult do under-
stand difficult do difficult do easy demanding effort need-
ing much effort difficult well made use difficult use causing 
difficulty?  
 
If we have the relevant senses, it is a simple 
matter of counting to estimate P(d). Conversely, 
with P(d) available to us, we can pick the relevant 
sense of S in I which is most likely generated by 
P(d). The problem of learning the model P(d) lend 
itself nicely to an iterative relaxation method such 
as the Expectation and Maximization Algorithm 
(Dempster, Laird, Rubin, 1977). 
 
Initially, we assume all senses of S word in I is 
equally likely and use all the defining words 
therein to estimate P(d) regardless of whether they 
are relevant. For LDOCE senses, initial estimate of 
the relevant glosses is as follows: 
 
D(S) = ?easy hard do make understand people unfriendly 
quarrelling pleased ? firm stiff broken pressed bent diffi-
cult do understand forceful needing using force body 
mind ?bent painful moving moved ? strong weakened 
suffer uncomfortable conditions cut worn bro-
ken ?needing effort difficult lacking skill moving body 
parts body CLUMSY made use difficult use causing diffi-
culty?  
 
Table 1. The initial CBSDM for n-word list {difficult, 
hard, stiff, tough, arduous, awkward} based on the rele-
vant and irrelevant LDOCE senses, n = 6. 
Defining word d Count, k P(d) = k/n 
Difficult 5 0.83 
Effort 3 0.50 
Understand 2 0.33 
Bad 2 0.33 
Bent 2 0.33 
Body 2 0.33 
Broken 2 0.33 
Difficulty 2 0.33 
Easy 2 0.33 
Firm 2 0.33 
Hard 2 0.33 
Moving 2 0.33 
Needing 2 0.33 
Water 2 0.33 
 
As evident from Table 1, the initial estimates of 
P(d) are quite close to the true probability distribu-
tion (based on the relevant senses only). The three 
top ranking defining words ?difficult,? ?effort,? and 
?understand? appear in glosses of relevant senses, 
and not in irrelevant senses. Admittedly, there are 
still some noisy, irrelevant words such as ?bent? 
and ?broken.? But they do not figure prominently 
in the model from the start and will fade out gradu-
ately with successive iterations of re-estimation. 
We estimate the probability of a particular sense s 
being in S by P(D(s)), the probability of its gloss 
under P(d). For intance, we have 
 
P(hard-1) = P(D(hard-1)) = P(?firm and stiff; which ??), 
P(hard-2) = P(D(hard-2)) = P(?difficult to do or understand?).  
 
On the other hand, we re-estimate the probabil-
ity P(d) of a defining word d under CBSDM by 
how often d appears in a sense s and P(s). P(d) is 
positively prepositional to the frequency of d in 
D(s) and to the value of P(s). Under that re-
estimation scheme, the defining words in relevant 
senses will figure more prominently in CBSDM, 
leading to more accurate estimation for probability 
of s being in S. For instance, in the first round, 
?difficult? in the gloss of hard-2 will weigh twice 
more than ?firm? in the gloss of irrelevant hard-1, 
leading to relatively higher unigram probability for 
?difficult.? That in turn makes hard-2 even more 
probable than hard-1. See Table 2. 
 
Table 2. First round estimates for P(s), the probability of 
sense s in S. 
Sense* Definition P(s) 
hard-1 firm and stiff; which can-
not easily be broken 
0.2857 
hard-2 difficult to do or under-
stand 
0.7143 
stiff-1 not easily bent 0.2857 
stiff-6 difficult to do 0.7143 
* in LDOCE. 
** Assuming )(max)(
)(
dPsP
sDd?
?  
 
Often the senses in I are accompanied with 
glosses written in a second language (L2); exclu-
sively (as in a simple bilingual word list) or addi-
tionally (as in LDOCE E-C). Either way, the words 
in L2 glosses can be incorporated into D(s) and 
P(d). For instance, the character unigrams and/or 
overlapping bigrams in the Mandarin glosses of S 
in LDOCE E-C and their appearance counts and 
probability are shown in Table 3. 
 
Table 3. Classes Based Sense Translation Model for 
{difficult-1, hard-2, stiff-6, tough-4, arduous-1, awk-
ward-2} in LDOCE*. 
 
 
We call the part of CBSDM that are involved 
with words written in L2, Class Based Sense 
Translation Model.  CBSTM trained on a thesaurus 
and a bilingual MRD can be exploited to align 
words and translation counter part as well as to 
assign word sense in a parallel corpus. For instance, 
given a pair of aligned sentences in a parallel cor-
pus: 
 
 
(2E) A scholar close to Needham analyses the reasons 
that he was able to achieve this huge work as 
being due to a combination of factors that 
would be hard to find in any other person. 
(Source: 1990, Dec Issue Page 24, Giving Jus-
tice Back to China --Dr. Joseph Needham and 
the History of Science and Civilisation in China) 
It is possible to apply CBSTM to obtain the fol-
lowing pair of translation equivalent, (  [nan], 
?hard?) and, at the same time, determine the in-
tended sense. For instance, we can label the cita-
tion with hard-2LDOCE, leading to the following 
quadruple: 
(3) (hard,  [nan], hard-2
 LDOCE , (2C, 2E)) 
After we have done this for all pairs of word and 
translation counterpart, we would in effect estab-
lish a Bilingual Semantic Concordance (BSC).  
 
2.2 The Model 
We assume that there is a Class Based Sense Defi-
nition Model, which can be viewed as a language 
model that generates the glosses for a class of 
senses S. Assume that we are given L, the words of 
S but not explicitly the intended senses S. In addi-
tion, we are given a sense inventory I in the form 
of an MRD with the regular glosses, which are 
written in L1 and/or L2. We are concerned with 
two problems: (1) Unsupervised training of M, 
CBSDM for S; (2) Determining S by identifying a 
relevant sense in I, if existing, for each word in L. 
Those two problems can be solved based on 
Maximum Likelihood Principle: Finding M and S 
such that M generates the glosses of S with maxi-
mum probability. For that, we utilize the Expecta-
tion and Maximization Algorithm to derive M and 
S through Mutually Assured Resolution of Sense 
Algorithm (MARS) given below: 
Mutual Assured Resolution of Sense Algorithm  
Determine the intended sense for each of a set of seman-
tic related words. 
Input: (1) Class of words L = {w1 w2 ?wn}; 
(2) Sense inventory I. 
Output: (1) Senses S from I for words in L; 
(2) CBSTM M from L1 to L2. 
1. Initially, we assume that each of the senses wi,j, j = 
1, mi in I is equally probable to be in S with prob-
ability 
i
ji,
1),|(
m
LiwP = , j = 1, mi; where mi is 
the number of senses in I for the word wi. 
2. Estimate CBSDM P(d | L) for L , 
,
),(),|(
)|(
kj,i,ji,kj,max
n
ddEQLiwP
LdP i
?
=
where d is a unigram or overlapping bigram in L1 
or L2, di,j,k = the kth word in D(wi,j), and EQ(x, y) 
= 1, if x = y and 0 otherwise; 
3. Re-estimate P(wi,j | i,L) according to di,j,k , k = 1,n i,j : 
,)|P(15.0)|P(5.0),|(P kj,i,
ji,
kj,i,ji,1 max ?+=
k
k Ld
n
LdLiw
?
=
=
i,1
ji,1
ji,1
ji, ),|(P
),|(P),|P(
mj
Liw
Liw
Liw ; 
4. Repeat Steps 2 and 3 until the values of P(d | L) and 
P(wi,j | i, L) converge; 
5. For each i, find the most probable sense wi,j* ,  
j*=argmax
 j P(wi,j | i, L) ; 
6. Output S = { wi,j* | j*=argmax j P(wi,j | i, L)} ; 
7. Estimate and output CBSTM for L, 
n
tcI
LcP ni
?
=
?
=
,1
j*,i )(
)|( , 
where c is a unigram or overlapping bigram in L2 
and ti,j is the L2 gloss of wi,j. 
 
Note that the purpose of Step 2 is to estimate how likely 
a word will appear in the definition of S based on the 
definining word for the senses, wi,j  and relevant prob-
ability P(wi,j | i,L). This likelihood of the word d being 
used to define senses in questions is subsequently used 
to re-estimate P(wi,j | i,L), the likelihood of the jth sense, 
wi,j of wi being in the intended senses of L. 
3. Application to Word Sense Tagging 
Armed with the Class Based Sense Translation 
Model, we can attack the word alignment and 
sense tagging problems simultaneously. Each word 
in a pair of aligned sentences in a parallel corpus 
will be considered and assigned a counterpart 
translation and intended sense in the given context 
through the proposed algorithm below: 
 
Simutaneous Word Alignment and Tagging Algorithm (SWAT) 
Align and sense tag words in a give sentence and trans-
lation. 
Input: (1) Pair of sentences (E, C); 
(2) Word w, POS p in question; 
(3) Sense Inventory I; 
(4) CBSTM, P(c|L). 
Output:  (1) Translation c of w in C; 
(2) Intended sense s for w. 
1. Perform part of speech tagging on E; 
2. Proceed if w with part of speech p is found in the 
results of tagging E; 
3. For all classes L to which (w, p) belongs and all 
words c in C: 
,)|(maxmaxarg*
),(
??
???
?
= LcPL
cwLINKL
( )*)|(maxarg* LcPc
c
= , 
where LINK(x, y) means x and y are two word 
aligned based on Competitive Linking Align-
ment 
4. Output c* as the translation; 
5. Output the sense of w in L* as the intended sense. 
 
To make sense tagging more precise, it is advisable 
to place constraint on the translation counterpart c 
of w. SWAT considers only those translations c 
that has been linked with w based the Competitive 
Linking Algorithm (Melamed 1997) and logarith-
mic likelihood ratio (Dunning 1993). 
 
Table 4. The experimental results of assigning LDOCE 
senses to classes of LLOCE.  
 
 
4. Experiments and evaluation 
In order to assess the feasibility of the proposed 
approach, we carried out experiments and evalua-
tion on an implementation of MARS and SWAT 
based on LDOCE E-C, LLOCE, and Sinorama. 
 
First experiment was involved with the train-
ability of CBSDM and CBSTM via MARS. The 
second experiment was involved with the effec-
tiveness of using SWAT and CBSTM to annotate a 
parallel corpus with sense information. Evaluation 
was done on a set of 14 nouns, verbs, adjectives, 
and adverbs studies in previous work. The set in-
cludes the nouns ?bass,? ?bow,? ?cone,? ?duty,? 
?gallery,? ?mole,? ?sentence,? ?slug,? ?taste,? 
?star,? ?interest,? ?issue,? the adjective ?hard,? 
and the verb ?serve.? 
 
Table 5. Evaluation of the MARS Algorithm based on 
12 nouns, 1 verb, 1 adjective in LDOCE. 
Word Pos #Senses #Done #Correct Prec 
(LB*) 
Prec. 
Bass N 4 1 1 0.25 1.00 
Bow N 5 2 2 0.25 1.00 
Cone N 3 3 2 0.33 0.67 
Duty N 2 2 2 0.13 1.00 
Galley N 3 3 2 0.33 0.67 
Mole N 3 2 2 0.33 1.00 
Sentence N 2 2 2 1.00 1.00 
Slug N 2 2 2 0.20 1.00 
Taste N 6 1 1 0.17 1.00 
Star N 8 2 2 0.13 1.00 
Interest N 6 4 4 0.17 1.00 
Issue N 7 4 3 0.14 0.75 
Serve V 13 4 2 0.08 0.50 
Hard A 12 2 2 0.08 1.00 
Avg.  4.14 1.36 1.29 0.26 0.90 
* The lower bound of precision of picking one sense in random. 
 
Table 6. Experimental results of sense tagging the Sinorama 
parallel Corpus.
 
Word Instance #done #correct Precision 
Star 173 86 82 0.95 
Hard 325 37 33 0.89 
4.1 Experiment 1: Training CBSDM 
We applied MARS to assign LDOCE senses to 
word classes in LLOCE. Some results related to 
the test set are shown in Tables 4. The evaluation 
in Tables indicates that MARS assigns LDOCE 
senses to an LLOCE class with a high average pre-
cision rate of 90%.  
4.2 Experiment 2: Sense Tagging 
We applied SWAT to sense tag English words in 
some 50,000 reliably aligned sentence pairs in Si-
norama parallel Corpus based on LDOCE sense 
inventory. The results are shown in Tables 6. 
Evaluation indicates an average precision rate of 
around 90%.  
 
5. Discussion 
The proposed approach offers a new method for 
automatic learning for the task of word sense dis-
ambiguation. The class based approach attacks the 
problem of tagging and data sparseness in a way 
similar to the Yarowsky approach (1992) based on 
thesaurus categories. We differ from the 
Yarowsky?s approach, in the following ways: 
i. The WSD problem is solved for two languages in-
stead of one within a single sense inventory. Fur-
thermore, an explicit sense tagged corpus is 
produced in the process. 
ii. It is possible to work with any number of sense in-
ventories. 
iii. The method is applicable not only to nouns but 
also to adjectives and verbs, since it does not rely 
on topical context, which is effective only for 
nouns as pointed out by Towell and Voorhees 
(1998). 
The approach is very general and modular and 
can work in conjunction with a number of learning 
strategies for word sense disambiguation 
(Yarowsky, 1995; Li and Li, 2002). 
 
6. Conclusion 
In this paper, we present the Mutual Assured Reso-
lution of Sense (MARS) Algorithm for assigning 
relevant senses to word classes in a given sense 
inventory (i.e. LDOCE or WordNet). We also de-
scribe the SWAT Algorithm for automatic sense 
tagging of a parallel corpus. 
We carried out experiments on an implementa-
tion of the MARS and SWAT Algorithms for all 
the senses in LDOCE and LLOCE. Evaluation on a 
set of 14 highly ambiguous words showed that 
very high precision CBSDM and CBSTM can be 
constructed. High applicability and precision rates 
were achieved, when applying CBSTM to sense 
tagging of a Chinese-English parallel corpus. 
 
A number of interesting future directions pre-
sent themselves. First, it would be interesting to 
see how effectively we can broaden the coverage 
of CBSTM via backing off smoothing. Second, a 
CBSTM trained directly on a parallel corpus would 
be more effective in word alignment and sense 
tagging. The approach of training CBSTM on the 
L2 glosses in a bilingual MRD may lead to occa-
sional mismatch between MRD translations and in-
context translations. Third, there is a lack of re-
search for a more abstractive and modular repre-
sentation of sense differences and commonality. 
There is potential of developing Sense Definition 
Model to identify and represent semantic and sty-
listic differentiation reflected in the MRD glosses 
pointed out in DiMarco, Hirst and Stede (1993). 
Last but not the least, it would be interesting to 
apply MARS to both LDOCE E-C and WordNet 
and project WordNet?s sense inventory to a sen-
cond language via CBSDM and a parallel corpus, 
thus creating a Chinese WordNet and semantic 
concordance. 
Acknowledgement  
We acknowledge the support for this study through 
grants from National Science Council and Ministry 
of Education, Taiwan (NSC 90-2411-H-007-033-
MC and MOE EX-91-E-FA06-4-4). 
References 
Dagan, Ido; A. Itai, and U. Schwall (1991). Two lan-
guages are more informative than one. Proceedings 
of the 29th Annual Meeting of the Association for 
Computational Linguistics, 18-21 June 1991, Berke-
ley, California, 130-137. 
Dempster, A., N. Laird, and D. Rubin (1977). Maxi-
mum likelihood from incomplete data via the EM al-
gorithm. Journal of the Royal Statistical Society, 
Series B, 39(1):1?38. 
Diab, M. and  P. Resnik, (2002). An Unsupervised 
Method for Word Sense Tagging using Parallel Cor-
pora, Proceedings of ACL, 255-262. 
DiMarco, C., G. Hirst, M. Stede, (1993). "The semantic 
and stylistic differentiation of synonyms and near-
synonyms." In: Working notes of the AAAI Spring 
Symposium on Building Lexicons for Machine Trans-
lation. Stanford University. 
Dunning, T (1993) Accurate methods for the statistics 
of surprise and coincidence, Computational Linguis-
tics 19:1, 61-75. 
Gale, W., K. Church, and D. Yarowsky, (1992). Using 
Bilingual Materials to Develop Word Sense Disam-
biguation Methods. In Proceedings, Fourth Interna-
tional Conference on Theoretical and 
Methodological Issues in Machine Translation. 
Montreal, 101-112, 1992. 
Ide, N. and J. V?ronis (1998). Word sense disambigua-
tion: The state of the art. Computational Linguistics, 
24:1, 1-40. 
Knight, K, and A. Luk, (1994). Building a Large-Scale 
Knowledge Base for Machine Translation, Proc. of 
the National Conference on Artificial Intelligence 
(AAAI). 
Knight, K., I. Chander, M. Haines, V. Hatzivassiloglou, 
E. Hovy, M. Iida, S. Luk, A. Okumura, R. Whitney, 
K. Yamada, (1994). "Integrating Knowledge Bases 
and Statistics in MT, Proc. of the Conference of the 
Association for Machine Translation in the Americas 
(AMTA). 
Leacock, C., G. Towell, and E. Voorhees (1993). Cor-
pus-based statistical sense resolution. Proceedings of 
the ARPA Human Language Technology Worskshop, 
San Francisco, Morgan Kaufman. 
Li, C, and H. Li (2002). Word Translation Disambigua-
tion Using Bilingual Bootstrapping, Proceedings of 
the 40th Annual Meeting of the Association for Com-
putational Linguistics (ACL), Philadelphia, July 2002, 
343-351. 
Li, Juanzi and C. Huang (1999). A Model for Word 
Sense Disambiguation. In Computational Linguistics 
and Chinese Language Processing,4(2), August 1999, 
pp.1-20 
McArthur, T. (1992) Longman Lexicon of Contempo-
rary English, Longman Group (Far East) Ltd., Hong 
Kong. 
Mei, J. J., et al (1984) Tongyici Cilin, Shanghai, Com-
mercial Press. (in Chinese) 
Melamed, I.D. (1997). "A Word-to-Word Model of 
Translational Equivalence". In Procs. of the ACL97. 
pp 490-497. Madrid Spain.  
Merialdo, B, (1994). Tagging English Text with a 
Probabilistic Model, Computational Linguistics, 
20(2):155-171. 
Miller, G., A, R.. Beckwith, C. Fellbaum, D. Gross and 
K.J. Miller. (1990). WordNet: An on-line lexical da-
tabase. International Journal of Lexicography, 3(4), 
235- 244. 
Proctor, P. (1988) Longman English-Chinese Dictionary 
of Contemporary English, Longman Group (Far East) 
Ltd., Hong Kong. 
Towell, G. and E. Voorhees. (1998) Disambiguating 
Highly Ambiguous Words. Computational Linguis-
tics, vol. 24, no. 1, 125-146. 
Yarowsky, D. (1992). Word sense disambiguation using 
statistical models of Roget's categories trained on 
large corpora. Proceedings of the 14th International 
Conference on Computational Linguistics, 
COLING'92, 23-28 August, Nantes, France, 454-460. 
Yarowsky, D. (1995). Unsupervised word sense disam-
biguation rivaling supervised methods. Proceedings 
of the 33rd Annual Meeting of the Association for 
Computational Linguistics, 189-196 
 
