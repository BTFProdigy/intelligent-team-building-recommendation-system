Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 106?111,
Baltimore, Maryland, USA, June 23-25 2014.
c?2014 Association for Computational Linguistics
Automatically constructing Wordnet synsets
Khang Nhut Lam, Feras Al Tarouti and Jugal Kalita
Computer Science department
University of Colorado
1420 Austin Bluffs Pkwy, Colorado Springs, CO 80918, USA
{klam2,faltarou,jkalita}@uccs.edu
Abstract
Manually constructing a Wordnet is a dif-
ficult task, needing years of experts? time.
As a first step to automatically construct
full Wordnets, we propose approaches to
generate Wordnet synsets for languages
both resource-rich and resource-poor, us-
ing publicly available Wordnets, a ma-
chine translator and/or a single bilin-
gual dictionary. Our algorithms translate
synsets of existing Wordnets to a target
language T, then apply a ranking method
on the translation candidates to find best
translations in T. Our approaches are ap-
plicable to any language which has at least
one existing bilingual dictionary translat-
ing from English to it.
1 Introduction
Wordnets are intricate and substantive reposito-
ries of lexical knowledge and have become im-
portant resources for computational processing of
natural languages and for information retrieval.
Good quality Wordnets are available only for a
few "resource-rich" languages such as English and
Japanese. Published approaches to automatically
build new Wordnets are manual or semi-automatic
and can be used only for languages that already
possess some lexical resources.
The Princeton Wordnet (PWN) (Fellbaum,
1998) was painstakingly constructed manually
over many decades. Wordnets, except the PWN,
have been usually constructed by one of two ap-
proaches. The first approach translates the PWN
to T (Bilgin et al, 2004), (Barbu and Mititelu,
2005), (Kaji and Watanabe, 2006), (Sagot and
Fi?er, 2008), (Saveski and Trajkovsk, 2010) and
(Oliver and Climent, 2012); while the second ap-
proach builds a Wordnet in T, and then aligns
it with the PWN by generating translations (Gu-
nawan and Saputra, 2010). In terms of popular-
ity, the first approach dominates over the second
approach. Wordnets generated using the second
approach have different structures from the PWN;
however, the complex agglutinative morphology,
culture specific meanings and usages of words and
phrases of target languages can be maintained. In
contrast, Wordnets created using the first approach
have the same structure as the PWN.
One of our goals is to automatically gener-
ate high quality synsets, each of which is a set
of cognitive synonyms, for Wordnets having the
same structure as the PWN in several languages.
Therefore, we use the first approach to construct
Wordnets. This paper discusses the first step of a
project to automatically build core Wordnets for
languages with low amounts of resources (viz.,
Arabic and Vietnamese), resource-poor languages
(viz., Assamese) or endangered languages (viz.,
Dimasa and Karbi)
1
. The sizes and the qualities
of freely existing resources, if any, for these lan-
guages vary, but are not usually high. Hence, our
second goal is to use a limited number of freely
available resources in the target languages as in-
put to our algorithms to ensure that our methods
can be felicitously used with languages that lack
much resource. In addition, our approaches need
to have a capability to reduce noise coming from
the existing resources that we use. For transla-
tion, we use a free machine translator (MT) and
restrict ourselves to using it as the only "dictio-
nary" we can have. For research purposes, we have
obtained free access to the Microsoft Translator,
which supports translations among 44 languages.
In particular, given public Wordnets aligned to the
PWN ( such as the FinnWordNet (FWN) (Lind?n,
2010) and the JapaneseWordNet (JWN) (Isahara et
al., 2008) ) and the Microsoft Translator, we build
Wordnet synsets for arb, asm, dis, ajz and vie.
1
ISO 693-3 codes of Arabic, Assamese, Dimasa, Karbi
and Vietnamese are arb, asm, dis, ajz and vie, respectively.
106
2 Proposed approaches
In this section, we propose approaches to create
Wordnet synsets for a target languages T using ex-
isting Wordnets and the MT and/or a single bilin-
gual dictionary. We take advantage of the fact
that every synset in PWN has a unique offset-POS,
referring to the offset for a synset with a partic-
ular part-of-speech (POS) from the beginning of
its data file. Each synset may have one or more
words, each of which may be in one or more
synsets. Words in a synset have the same sense.
The basic idea is to extract corresponding synsets
for each offset-POS from existing Wordnets linked
to PWN, in several languages. Next, we translate
extracted synsets in each language to T to produce
so-called synset candidates using MT. Then, we
apply a ranking method on these candidates to find
the correct words for a specific offset-POS in T.
2.1 Generating synset candidates
We propose three approaches to generate synset
candidates for each offset-POS in T.
2.1.1 The direct translation (DR) approach
The first approach directly translates synsets in
PWN to T as in Figure 1.
Figure 1: The DR approach to construct Wordnet
synsets in a target language T.
For each offset-POS, we extract words in that
synset from the PWN and translate them to the tar-
get language to generate translation candidates.
2.1.2 Approach using intermediate Wordnets
(IW)
To handle ambiguities in synset translation, we
propose the IW approach as in Figure 2. Publicly
available Wordnets in various languages, which
we call intermediate Wordnets, are used as re-
sources to create synsets for Wordnets. For each
offset-POS, we extract its corresponding synsets
from intermediate Wordnets. Then, the extracted
synsets, which are in different languages, are
translated to T using MT to generate synset candi-
dates. Depending on which Wordnets are used and
the number of intermediate Wordnets, the num-
ber of candidates in each synset and the number
of synsets in the new Wordnets change.
Figure 2: The IW approach to construct Wordnet
synsets in a target language T
2.1.3 Approach using intermediate Wordnets
and a dictionary (IWND)
The IW approach for creating Wordnet synsets de-
creases ambiguities in translations. However, we
need more than one bilingual dictionary from each
intermediate languages to T. Such dictionaries are
not always available for many languages, espe-
cially the ones that are resource poor. The IWND
approach is like the IW approach, but instead of
translating immediately from the intermediate lan-
guages to the target language, we translate synsets
extracted from intermediate Wordnets to English
(eng), then translate them to the target language.
The IWND approach is presented in Figure 3.
Figure 3: The IWND approach to construct Word-
net synsets
107
2.2 Ranking method
For each of offset-POS, we have many translation
candidates. A translation candidate with a higher
rank is more likely to become a word belonging to
the corresponding offset-POS of the new Wordnet
in the target language. Candidates having the same
ranks are treated similarly. The rank value in the
range 0.00 to 1.00. The rank of a word w, the so-
called rank
w
, is computed as below.
rank
w
=
occur
w
numCandidates
?
numDstWordnets
numWordnets
where:
- numCandidates is the total number of trans-
lation candidates of an offset-POS
- occur
w
is the occurrence count of the word w
in the numCandidates
- numWordnets is the number of intermediate
Wordnets used, and
- numDstWordnets is the number of distinct in-
termediate Wordnets that have words trans-
lated to the word w in the target language.
Our motivation for this rank formula is the fol-
lowing. If a candidate has a higher occurrence
count, it has a greater chance to become a cor-
rect translation. Therefore, the occurrence count
of each candidate needs to be taken into account.
We normalize the occurrence count of a word by
dividing it by numCandidates. In addition, if a
candidate is translated from different words hav-
ing the same sense in different languages, this can-
didate is more likely to be a correct translation.
Hence, we multiply the first fraction by numDst-
Wordnets. To normalize, we divide results by the
number of intermediate Wordnet used.
For instance, in our experiments we use 4 in-
termediate Wordnets, viz., PWN, FWN, JWN and
WOLF Wordnet (WWN) (Sagot and Fi?er, 2008).
The words in the offset-POS "00006802-v" ob-
tained from all 4 Wordnets, their translations to
arb, the occurrence count and the rank of each
translation are presented in the second, the fourth
and the fifth columns, respectively, of Figure 4.
2.3 Selecting candidates based on ranks
We separate candidates based on three cases as be-
low.
Case 1: A candidate w has the highest chance
to become a correct word belonging to a specific
synset in the target language if its rank is 1.0. This
means that all intermediate Wordnets contain the
synset having a specific offset-POS and all words
belonging to these synsets are translated to the
Figure 4: Example of calculating the ranks of
candidates translated from words belonging to the
offset-POS "00006802-v" in 4 Wordnets: PWN,
FWN, JWN and WWN. The word
A
, word
B
and
word
C
are obtained from PWN, FWN and WWN,
respectively. The JWN does not contain this offset-
POS. TL presents transliterations of the words in
arb. The numWordnets is 4 and the numCandi-
dates is 7. The rank of each candidate is shown in
the last column of Figure 4.
same word w. The more the number of intermedi-
ate Wordnets used, the higher the chance the can-
didate with the rank of 1.0 has to become the cor-
rect translation. Therefore, we accept all transla-
tions that satisfy this criterion. An example of this
scenario is presented in Figure 5.
Figure 5: Example of Case 1: Using the IW ap-
proach with four intermediate Wordnets, PWN,
FWN, JWN and WWN. All words belonging to
the offSet-POS "00952615-n" in all 4 Wordnets are
translated to the same word "?i?n" in vie. The
word "?i?n" is accepted as the correct word be-
longing to the offSet-POS "00952615-n" in the
Vietnamese Wordnet we create.
Case 2: If an offSet-POS does not have candi-
dates having the rank of 1.0, we accept the candi-
dates having the greatest rank. Figure 6 shows the
example of the second scenario.
Case 3: If all candidates of an offSet-POS has
the same rank which is also the greatest rank, we
108
Figure 6: Example of Case 2: Using the IW ap-
proach with three intermediate Wordnets, PWN,
FWN and WWN. For the offSet-POS "01437254-
v", there is no candidate with the rank of 1.0.
The highest rank of the candidates in "vie" is 0.67
which is the word g?i. We accept "g?i" as the cor-
rect word in the offSet-POS "01437254-v" in the
Vietnamese Wordnet we create.
skip these candidates. Table 1 gives an example of
the last scenario.
Wordnet Words Cand. Rank
PWN act h?nh ??ng 0.33
PWN behave ho?t ??ng 0.33
FWN do l?m 0.33
Table 1: Example of Case 3: Using the DR ap-
proach. For the offSet-POS "00010435-v", there
is no candidate with the rank of 1.0. The highest
rank of the candidates in vie is 0.33. All of 3 can-
didates have the rank as same as the highest rank.
Therefore, we do not accept any candidate as the
correct word in the offSet-POS "00010435-v" in
the Vietnamese Wordnet we create.
3 Experiments
3.1 Publicly available Wordnets
The PWN is the oldest and the biggest available
Wordnet. It is also free. Wordnets in many
languages are being constructed and developed
2
.
However, only a few of these Wordnets are of high
quality and free for downloading. The EuroWord-
net (Vossen, 1998) is a multilingual database with
Wordnets in European languages (e.g., Dutch, Ital-
ian and Spanish). The AsianWordnet
3
provides
a platform for building and sharing Wordnets for
Asian languages (e.g., Mongolian, Thai and Viet-
namese). Unfortunately, the progress in building
most of these Wordnets is slow and they are far
from being finished.
2
http://www.globalWordnet.org/gwa/Wordnet_table.html
3
http://www.asianWordnet.org/progress
In our current experiments as mentioned ear-
lier, we use the PWN and other Wordnets linked
to the PWN 3.0 provided by the Open Multilingual
Wordnet
4
project (Bond and Foster, 2013): WWN,
FWN and JWN. Table 2 provides some details of
the Wordnets used.
Wordnet Synsets Core
JWN 57,179 95%
FWN 116,763 100%
PWN 117,659 100%
WWN 59,091 92%
Table 2: The number of synsets in the Wordnets
linked to the PWN 3.0 are obtained from the Open
Multilingual Wordnet, along with the percentage
of synsets covered from the semi-automatically
compiled list of 5,000 "core" word senses in PWN.
Note that synsets which are not linked to the PWN
are not taken into account.
For languages not supported by MT, we use
three additional bilingual dictionaries: two dictio-
naries Dict(eng,ajz) and Dict(eng,dis) provided by
Xobdo
5
; one Dict(eng,asm) created by integrat-
ing two dictionaries Dict(eng,asm) provided by
Xobdo and Panlex
6
. The dictionaries are of vary-
ing qualities and sizes. The total number of entries
in Dict(eng,ajz), Dict(eng,asm) and Dict(eng,dis)
are 4682, 76634 and 6628, respectively.
3.2 Experimental results and discussion
As previously mentioned, our primary goal is to
build high quality synsets for Wordnets in lan-
guages with low amount of resources: ajz, asm,
arb, dis and vie. The number of Wordnet synsets
we create for arb and vie using the DR approach
and the coverage percentage compared to the
PWN synsets are 4813 (4.10%) and 2983 (2.54%),
respectively. The number of synsets for each
Wordnet we create using the IW approach with
different numbers of intermediate Wordnets and
the coverage percentage compared to the PWN
synsets are presented in Table 3.
For the IWND approach, we use all 4 Wordnets
as intermediate resources. The number of Wordnet
synsets we create using the IWND approach are
presented in Table 4. We only construct Wordnet
synsets for ajz, asm and dis using the IWND ap-
4
http://compling.hss.ntu.edu.sg/omw/
5
http://www.xobdo.org/
6
http://panlex.org/
109
App. Lang. WNs Synsets % coverage
IW arb 2 48,245 41.00%
IW vie 2 42,938 36.49%
IW arb 3 61,354 52.15%
IW vie 3 57,439 48.82%
IW arb 4 75,234 63.94%
IW vie 4 72,010 61.20%
Table 3: The number of Wordnet synsets we create
using the IW approach. WNs is the number of in-
termediate Wordnets used: 2: PWN and FWN, 3:
PWN, FWN and JWN and 4: PWN, FWN, JWN
and WWN.
proach because these languages are not supported
by MT.
App. Lang. Synsets % coverage
IWND ajz 21,882 18.60%
IWND arb 70,536 59.95%
IWND asm 43,479 36.95%
IWND dis 24,131 20.51%
IWND vie 42,592 36.20%
Table 4: The number of Wordnets synsets we cre-
ate using the IWND approach.
Finally, we combine all of the Wordnet synsets
we create using different approaches to generate
the final Wordnet synsets. Table 5 presents the fi-
nal number of Wordnet synsets we create and their
coverage percentage.
Lang. Synsets % coverage
ajz 21,882 18.60%
arb 76,322 64.87%
asm 43,479 36.95%
dis 24,131 20.51%
vie 98,210 83.47%
Table 5: The number and the average score of
Wordnets synsets we create.
Evaluations were performed by volunteers who
use the language of the Wordnet as mother tongue.
To achieve reliable judgment, we use the same
set of 500 offSet-POSs, randomly chosen from the
synsets we create. Each volunteer was requested
to evaluate using a 5-point scale ? 5: excellent, 4:
good, 3: average, 2: fair and 1: bad. The aver-
age score of Wordnet synsets for arb, asm and vie
are 3.82, 3.78 and 3.75, respectively. We notice
that the Wordnet synsets generated using the IW
approach with all 4 intermediate Wordnets have
the highest average score: 4.16/5.00 for arb and
4.26/5.00 for vie. We are in the process of finding
volunteers to evaluate the Wordnet synsets for ajz
and dis.
It is difficult to compare Wordnets because the
languages involved in different papers are differ-
ent, the number and quality of input resources vary
and the evaluation methods are not standard. How-
ever, for the sake of completeness, we make an at-
tempt at comparing our results with published pa-
pers. Although our score is not in terms of percent-
age, we obtain the average score of 3.78/5.00 (or
informally and possibly incorrectly, 75.60% preci-
sion) which we believe it is better than 55.30% ob-
tained by (Bond et al, 2008) and 43.20% obtained
by (Charoenporn et al, 2008). In addition, the av-
erage coverage percentage of all Wordnet synsets
we create is 44.85% which is better than 12% in
(Charoenporn et al, 2008) and 33276 synsets ('
28.28%) in (Saveski and Trajkovsk, 2010) .
The previous studies need more than one dic-
tionary to translate between a target language
and intermediate-helper languages. For exam-
ple, to create the JWN, (Bond et al, 2008) needs
the Japanese-Multilingual dictionary, Japanese-
English lexicon and Japanese-English life sci-
ence dictionary. For asm, there are a number
of Dict(eng,asm); to the best of our knowledge
only two online dictionaries, both between eng
and asm, are available. The IWND approach re-
quires only one input dictionary between a pair of
languages. This is a strength of our method.
4 Conclusion and future work
We present approaches to create Wordnet synsets
for languages using available Wordnets, a public
MT and a single bilingual dictionary. We create
Wordnet synsets with good accuracy and high cov-
erage for languages with low resources (arb and
vie), resource-poor (asm) and endangered (ajz and
dis). We believe that our work has the potential
to construct full Wordnets for languages which do
not have many existing resources. We are in the
process of creating a Website where all Wordnet
synsets we create will be available, along with a
user friendly interface to give feedback on individ-
ual entries. We will solicit feedback from commu-
nities that use these languages as mother-tongue.
Our goal is to use this feedback to improve the
quality of the Wordnet synsets. Some of Word-
net synsets we created can be downloaded from
http://cs.uccs.edu/?linclab/projects.html.
110
References
Antoni Oliver and Salvador Climent. 2012. Parallel
corpora for Wordnet construction: Machine trans-
lation vs. automatic sense tagging. In Proceed-
ings of the 13th International Conference on Com-
putational Linguistics and Intelligent Text Process-
ing (CICLing), volume part II, pages 110-121, New
Delhi, India, March.
Beno?t Sagot and Darja Fi?er. 2008. Building a free
French Wordnet from multilingual resources. In
Proceedings of the Ontolex 2008 Workshop, Mar-
rakech, Morocco, May.
Fellbaum, Christiane. 1998. Wordnet: An electronic
lexical database. MIT Press, Cambridge, Mas-
sachusetts, USA.
Francis Bond and Ryan Foster. 2013. Linking and ex-
tending an open multilingual Wordnet. In Proceed-
ings of the 51st Annual Meeting of the Association
for Computational Linguistics (ACL), pages 1352?
1362, Sofia, Bulgaria, August.
Francis Bond, Hitoshi Isahara, Kyoko Kanzaki and
Kiyotaka Uchimoto. 2008. Boot-strapping a Word-
net using multiple existing Wordnets. In Proceed-
ings of the 6th International Conference on Lan-
guage Resources and Evaluation (LREC), pages
1619?1624, Genoa, Italy, May.
Eduard Barbu and Verginica Barbu Mititelu. 2005.
Automatic building of Wordnets. In Proceedings of
the International Conference on Recent Advances in
Natural Language Processing (RANLP), Borovets,
Bulgaria, September.
Gunawan and Andy Saputra. 2010. Building synsets
for Indonesian Wordnet with monolingual lexical re-
sources. In Proceedings of the International Confer-
ence on Asian Language Processing (IALP), pages
297?300, Harbin, China, December.
Hiroyuki Kaji and Mariko Watanabe. 2006. Auto-
matic construction of Japanese Wordnet. In Pro-
ceedings of the 5th International Conference on
Language Resources and Evaluation (LREC), pages
1262?1267, Genoa, Italy, May.
Hitoshi Isahara, Francis Bond, Kiyotaka Uchimoto,
Masao Utiyama and Kyoko Kanzaki. 2008. De-
velopment of Japanese Wordnet. In Proceedings of
the 6th International Conference on Language Re-
sources and Evaluation (LREC), pages 2420?2423,
Marrakech, Morocco, May.
Krister Lind?n and Laur Carlson. 2010. FinnWordnet -
WordNet p?finska via ?vers?ttning, LexicoNordica.
Nordic Journal of Lexicography, 17:119?140.
Martin Saveski and Igor Trajkovsk. 2010. Automatic
construction of Wordnets by using machine transla-
tion and language modeling. In Proceedings of the
13th Multiconference Information Society, Ljubl-
jana, Slovenia.
Orhan Bilgin, ?zlem ?entino?glu and Kemal Oflazer.
2004. Building a Wordnet for Turkish. Romanian
Journal of Information Science and Technology, 7(1-
2): 163?172.
Piek Vossen. 1998. A multilingual database with lex-
ical semantic networks. Kluwer Academic Publish-
ers, Dordrecht, Netherlands.
Thatsanee Charoenporn, Virach Sornlertlamvanich,
Chumpol Mokarat and Hitoshi Isahara. 2008. Semi-
automatic compilation of Asian Wordnet, In Pro-
ceedings of the 14th Annual Meeting of the Associa-
tion for Natural Language Processing, pages 1041?
1044, Tokyo, Japan.
111
Proceedings of the 2014 Workshop on the Use of Computational Methods in the Study of Endangered Languages, pages 54?62,
Baltimore, Maryland, USA, 26 June 2014.
c?2014 Association for Computational Linguistics
Creating Lexical Resources for Endangered Languages
Khang Nhut Lam, Feras Al Tarouti and Jugal Kalita
Computer Science department
University of Colorado
1420 Austin Bluffs Pkwy, Colorado Springs, CO 80918, USA
{klam2,faltarou,jkalita}@uccs.edu
Abstract
This paper examines approaches to gener-
ate lexical resources for endangered lan-
guages. Our algorithms construct bilin-
gual dictionaries and multilingual the-
sauruses using public Wordnets and a ma-
chine translator (MT). Since our work re-
lies on only one bilingual dictionary be-
tween an endangered language and an ?in-
termediate helper? language, it is applica-
ble to languages that lack many existing
resources.
1 Introduction
Languages around the world are becoming extinct
at a record rate. The Ethnologue organization
1
re-
ports 424 languages as nearly extinct and 203 lan-
guages as dormant, out a total of 7,106 recorded
languages. Many other languages are becoming
endangered, a state which is likely to lead to their
extinction, without determined intervention. Ac-
cording to UNESCO, ?a language is endangered
when its speakers cease to use it, use it in fewer
and fewer domains, use fewer of its registers and
speaking styles, and/or stop passing it on to the
next generation...?. In America, UNESCO reports
134 endangered languages, e.g., Arapaho, Chero-
kee, Cheyenne, Potawatomi and Ute.
One of the hallmarks of a living and thriving
language is the existence and continued produc-
tion of ?printed? (now extended to online pres-
ence) resources such as books, magazines and ed-
ucational materials in addition to oral traditions.
There is some effort afoot to document record and
archive endangered languages. Documentation
may involve creation of dictionaries, thesauruses,
text and speech corpora. One possible way to re-
suscitate these languages is to make them more
easily learnable for the younger generation. To
1
http://www.ethnologue.com/
learn languages and use them well, tools such as
dictionaries and thesauruses are essential. Dictio-
naries are resources that empower the users and
learners of a language. Dictionaries play a more
substantial role than usual for endangered lan-
guages and are ?an instrument of language main-
tenance? (Gippert et al., 2006). Thesauruses are
resources that group words according to similarity
(Kilgarriff, 2003). For speakers and students of an
endangered language, multilingual thesauruses are
also likely to be very helpful.
This study focuses on examining techniques
that leverage existing resources for ?resource-
rich? languages to build lexical resources for low-
resource languages, especially endangered lan-
guages. The only resource we need is a single
available bilingual dictionary translating the given
endangered language to English. First, we create a
reverse dictionary from the input dictionary using
the approach in (Lam and Kalita, 2013). Then, we
generate additional bilingual dictionaries translat-
ing from the given endangered language to sev-
eral additional languages. Finally, we discuss the
first steps to constructing multilingual thesauruses
encompassing endangered and resources-rich lan-
guages. To handle the word sense ambiguity prob-
lems, we exploit Wordnets in several languages.
We experiment with two endangered languages:
Cherokee and Cheyenne, and some resource-rich
languages such as English, Finnish, French and
Japanese
2
. Cherokee is the Iroquoian language
spoken by 16,000 Cherokee people in Oklahoma
and North Carolina. Cheyenne is a Native Ameri-
can language spoken by 2,100 Cheyenne people in
Montana and Oklahoma.
The remainder of this paper is organized as fol-
lows. Dictionaries and thesauruses are introduced
in Section 2. Section 3 discusses related work. In
2
ISO 693-3 codes for Cherokee, Cheyenne, English,
Finnish, French and Japanese are chr, chy, eng, fin, fra and
jpn, respectively.
54
Section 4 and Section 5, we present approaches
for creating new bilingual dictionaries and multi-
lingual thesauruses, respectively. Experiments are
described in Section 6. Section 7 concludes the
paper.
2 Dictionaries vs. Thesauruses
A dictionary or a lexicon is a book (now, in elec-
tronic database formats as well) that consists of a
list of entries sorted by the lexical unit. A lexical
unit is a word or phrase being defined, also called
definiendum. A dictionary entry or a lexical en-
try simply contains a lexical unit and a definition
(Landau, 1984). Given a lexical unit, the defini-
tion associated with it usually contains parts-of-
speech (POS), pronunciations, meanings, exam-
ple sentences showing the use of the source words
and possibly additional information. A monolin-
gual dictionary contains only one language such
as The Oxford English Dictionary
3
while a bilin-
gual dictionary consists of two languages such as
the English-Cheyenne dictionary
4
. A lexical entry
in the bilingual dictionary contains a lexical unit in
a source language and equivalent words or multi-
word expressions in the target language along with
optional additional information. A bilingual dic-
tionary may be unidirectional or bidirectional.
Thesauruses are specialized dictionaries that
store synonyms and antonyms of selected words
in a language. Thus, a thesaurus is a resource
that groups words according to similarity (Kilgar-
riff, 2003). However, a thesaurus is different from
a dictionary. (Roget, 1911) describes the orga-
nizes of words in a thesaurus as ?... not in alpha-
betical order as they are in a dictionary, but ac-
cording to the ideas which they express.... The
idea being given, to find the word, or words, by
which that idea may be most fitly and aptly ex-
pressed. For this purpose, the words and phrases
of the language are here classed, not according to
their sound or their orthography, but strictly ac-
cording to their signification?. Particularly, a the-
saurus contains a set of descriptors, an indexing
language, a classification scheme or a system vo-
cabulary (Soergel, 1974). A thesaurus also con-
sists of relationships among descriptors. Each de-
scriptor is a term, a notation or another string of
symbols used to designate the concept. Examples
3
http://www.oed.com/
4
http://cdkc.edu/cheyennedictionary/index-
english/index.htm
of thesauruses are Roget?s international Thesaurus
(Roget, 2008), the Open Thesaurus
5
or the one at
thesaurus.com.
We believe that the lexical resources we create
are likely to help endangered languages in sev-
eral ways. These can be educational tools for lan-
guage learning within and outside the community
of speakers of the language. The dictionaries and
thesauruses we create can be of help in developing
parsers for these languages, in addition to assisting
machine or human translators to translate rich oral
or possibly limited written traditions of these lan-
guages into other languages. We may be also able
to construct mini pocket dictionaries for travelers
and students.
3 Related work
Previous approaches to create new bilingual dic-
tionaries use intermediate dictionaries to find
chains of words with the same meaning. Then,
several approaches are used to mitigate the ef-
fect of ambiguity. These include consulting the
dictionary in the reverse direction (Tanaka and
Umemura, 1994) and computing ranking scores,
variously called a semantic score (Bond and
Ogura, 2008), an overlapping constraint score, a
similarity score (Paik et al., 2004) and a con-
verse mapping score (Shaw et al., 2013). Other
techniques to handle the ambiguity problem are
merging results from several approaches: merging
candidates from lexical triangulation (Gollins and
Sanderson, 2001), creating a link structure among
words (Ahn and Frampton, 2006) and building
graphs connecting translations of words in sev-
eral languages (Mausam et al., 2010). Researchers
also merge information from several sources such
as bilingual dictionaries and corpora (Otero and
Campos, 2010) or a Wordnet (Istv?n and Shoichi,
2009) and (Lam and Kalita, 2013). Some re-
searchers also extract bilingual dictionaries from
corpora (Ljube?i
?
c and Fi?er, 2011) and (Bouamor
et al., 2013). The primary similarity among these
methods is that either they work with languages
that already possess several lexical resources or
these approaches take advantage of related lan-
guages (that have some lexical resources) by using
such languages as intermediary. The accuracies of
bilingual dictionaries created from several avail-
able dictionaries and Wordnets are usually high.
However, it is expensive to create such original
5
http://www.openthesaurus.de/
55
lexical resources and they do not always exist for
many languages. For instance, we cannot find any
Wordnet for chr or chy. In addition, these exist-
ing approaches can only generate one or just a few
new bilingual dictionaries from at least two exist-
ing bilingual dictionaries.
(Crouch, 1990) clusters documents first using
a complete link clustering algorithm and gener-
ates thesaurus classes or synonym lists based on
user-supplied parameters such as a threshold sim-
ilarity value, number of documents in a cluster,
minimum document frequency and specification
of a class formation method. (Curran and Moens,
2002a) and (Curran and Moens, 2002b) evaluate
performance and efficiency of thesaurus extrac-
tion methods and also propose an approximation
method that provides for better time complexity
with little loss in performance accuracy. (Ram?rez
et al., 2013) develop a multilingual Japanese-
English-Spanish thesaurus using freely available
resources: Wikipedia and Wordnet. They extract
translation tuples from Wikipedia from articles in
these languages, disambiguate them by mapping
to Wordnet senses, and extract a multilingual the-
saurus with a total of 25,375 entries.
One thing to note about all these approaches is
that they are resource hungry. For example, (Lin,
1998) works with a 64-million word English cor-
pus to produce a high quality thesaurus with about
10,000 entries. (Ram?rez et al., 2013) has the en-
tire Wikipedia at their disposal with millions of
articles in three languages, although for experi-
ments they use only about 13,000 articles in total.
When we work with endangered or low-resource
languages, we do not have the luxury of collecting
such big corpora or accessing even a few thousand
articles from Wikipedia or the entire Web. Many
such languages have no or very limited Web pres-
ence. As a result, we have to work with whatever
limited resources are available.
4 Creating new bilingual dictionaries
A dictionary Dict(S,T) between a source language
S and a target language T has a list of entries. Each
entry contains a word s in the source language S,
part-of-speech (POS) and one or more translations
in the target language T. We call such a transla-
tion t. Thus, a dictionary entry is of the form
<s
i
,POS,t
i1
>, <s
i
,POS,t
i2
>, ....
This section examines approaches to create new
bilingual dictionaries for endangered languages
from just one dictionary Dict(S,I), where S is the
endangered source language and I is an ?inter-
mediate helper? language. We require that the
language I has an available Wordnet linked to
the Princeton Wordnet (PWN) (Fellbaum, 1998).
Many endangered languages have a bilingual dic-
tionary, usually to or from a resource-rich lan-
guage like French or English which is the inter-
mediate helper language in our experiments. We
make an assumption that we can find only one uni-
directional bilingual dictionary translating from a
given endangered language to English.
4.1 Generating a reverse bilingual dictionary
Given a unidirectional dictionary Dict(S,I) or
Dict(I,S), we reverse the direction of the entries
to produce Dict(I,S) or Dict(S,I), respectively. We
apply an approach called Direct Reversal with
Similarity (DRwS), proposed in (Lam and Kalita,
2013) to create a reverse bilingual dictionary from
an input dictionary.
The DRwS approach computes the distance be-
tween translations of entries by measuring their se-
mantic similarity, the so-called simValue. The sim-
Value between two phrases is calculated by com-
paring the similarity of the ExpansionSet for ev-
ery word in one phrase with ExpansionSet of ev-
ery word in the other phrase. An ExpansionSet of
a phrase is a union of the synset, synonym set, hy-
ponym set, and/or hypernym set of every word in
it. The synset, synonym, hyponym and hypernym
sets of a word are obtained from PWN. The greater
is the simValue between two phrases, the more se-
mantically similar are these phrases. According to
(Lam and Kalita, 2013), if the simValue is equal to
or greater than 0.9, the DRwS approach produces
the ?best? reverse dictionary.
For creating a reverse dictionary, we skip en-
tries with multiword expression in the translation.
Based on our experiments, we have found that ap-
proach is successful and hence, it may be an effec-
tive way to automatically create a new bilingual
dictionary from an existing one. Figure 1 presents
an example of generating entries for the reverse
dictionary.
4.2 Building bilingual dictionaries to/from
additional languages
We propose an approach using public Word-
nets and MT to create new bilingual dictionaries
Dict(S,T) from an input dictionary Dict(S,I). As
previously mentioned, I is English in our exper-
56
Figure 1: Example of creating entries for a reverse
dictionary Dict(eng,chr) from Dict(chr,eng). The
simValue between the words "ocean" and "sea" is
0.98, which is greater than the threshold of 0.90.
Therefore, the words "ocean" and "sea" in English
are hypothesized to have both meanings "ame-
quohi" and "ustalanali" in Cherokee. We add these
entries to Dict(eng, chr).
iments. Dict(S,T) translates a word in an endan-
gered language S to a word or multiword expres-
sion in a target language T. In particular, we create
bilingual dictionaries for an endangered language
S from a given dictionary Dict(S,eng). Figure 2
presents the approach to create new bilingual dic-
tionaries.
Figure 2: The approach for creating new bilin-
gual dictionaries from intermediate Wordnets and
a MT.
For each entry pair (s,e) in a given dictionary
Dict(S,eng), we find all synonym words of the
word e to create a list of synonym words in En-
glish: SY N
eng
. SY N
eng
of the word eng is
obtained from the PWN. Then, we find all syn-
onyms of words belonging to SY N
eng
in sev-
eral non-English languages to generate SY N
L
,
L ? {fin, fra, jpn}. SY N
L
in the language L is
extracted from the publicly available Wordnet in
language L linked to the PWN. Next, translation
candidates are generated by translating all words
in SY N
L
, L ? {eng, fin, fra, jpn} to the target
language T using an MT. A translation candidate is
considered a correct translation of the source word
in the target language if its rank is greater than a
threshold. For each word s, we may have many
candidates. A translation candidate with a higher
rank is more likely to become a correct translation
in the target language. The rank of a candidate is
computed by dividing its occurrence count by the
total number of candidates. Figure 3 shows an ex-
ample of creating entries for Dict(chr,vie), where
vie is Vietnamese, from Dict(chr,eng).
Figure 3: Example of generating new entries for
Dict(chr,vie) from Dict(chr,eng). The word "ayvt-
seni" in chr is translated to "throat" in eng. We
find all synonym words for "throat" in English to
generate SY N
eng
and all synonyms in fin, fra and
jpn for all words in SY N
eng
. Then, we translate
all words in all SY N
L
s to vie and rank them. Ac-
cording to rank calculations, the best translations
of "ayvtseni" in chr are the words "c? h?ng" and
"h?ng" in vie.
57
5 Constructing thesauruses
As previously mentioned, we want to generate a
multilingual thesaurus THS composed of endan-
gered and resource-rich languages. For example,
we build the thesaurus encompassing an endan-
gered language S and eng, fin, fra and jpn. Our
thesaurus contains a list of entries. Every entry has
a unique ID. Each entry is a 7-tuple: ID, SY N
S
,
SY N
eng
, SY N
fin
, SY N
fra
, SY N
jpn
and POS.
Each SY N
L
contains words that have the same
sense in language L. All SY N
L
, L ? {S, eng, fin,
fra, jpn} with the same ID have the same sense.
This section presents the initial steps in con-
structing multilingual thesauruses using Wordnets
and the bilingual dictionaries we create. The
approach to create a multilingual thesaurus en-
compassing an endangered language and several
resource-rich languages is presented in Figure 4
and Algorithm 1.
Figure 4: The approach to construct a multilingual
thesaurus encompassing an endangered language
S and resource-rich language.
First, we extract SY N
L
in resource-rich lan-
guages from Wordnets. To extract SY N
eng
,
SY N
fin
, SY N
fra
and SY N
jpn
, we use PWN
and Wordnets linked to the PWN provided by
the Open Multilingual Wordnet
6
project (Bond
and Foster, 2013): FinnWordnet (FWN) (Lind?n,
2010), WOLF (WWN) (Sagot and Fi?er, 2008)
and JapaneseWordnet (JWN) (Isahara et al.,
2008). For each Offset-POS, we extract its cor-
responding synsets from PWN, FWN, WWN and
6
http://compling.hss.ntu.edu.sg/omw/
JWN to generate SY N
eng
, SY N
fin
, SY N
fra
and
SY N
jpn
(lines 7-10). The POS of the entry is
the POS extracted from the Offset-POS (line 5).
Since these Wordnets are aligned, a specific offset-
POS retrieves synsets that are equivalent sense-
wise. Then, we translate all SY N
L
s to the given
endangered language S using bilingual dictionar-
ies we created in the previous section (lines 11-
14). Finally, we rank translation candidates and
add the correct translations to SY N
S
(lines 15-
19). The rank of a candidate is computed by di-
viding its occurrence count by the total number of
candidates. If a candidate has a rank value greater
than a threshold, we accept it as a correct transla-
tion and add it to SY N
S
.
Algorithm 1
Input: Endangered language S, PWN, FWN,
WWN, JWN, Dict(eng,S), Dict(fin,S), Dict(fra,S)
and Dict(jpn,S)
Output: thesaurus THS
1: ID:=0
2: for all offset-POSs in PWN do
3: ID++
4: candidates := ?
5: POS=extract(offset-POS)
6: SY N
S
:= ?
7: SY N
eng
=extract(offset-POS, PWN)
8: SY N
fin
=extract(offset-POS, FWN)
9: SY N
fra
=extract(offset-POS, WWN)
10: SY N
jpn
=extract(offset-POS, JWN)
11: candidates+=translate(SY N
eng
,S)
12: candidates+=translate(SY N
fin
,S)
13: candidates+=translate(SY N
fra
,S)
14: candidates+=translate(SY N
jpn
,S)
15: for all candidate in candidates do
16: if rank(candidate) > ? then
17: add(candidate,SY N
S
)
18: end if
19: end for
20: add ID, POS and all SY N
L
into THS
21: end for
Figure 5 presents an example of creating an en-
try for the thesaurus. We generate entries for the
multilingual thesaurus encompassing of Cherokee,
English, Finnish, French and Japanese.
We extract words belonging to offset-POS
"09426788-n" in PWN, FWN, WWN and JWN
and add them into corresponding SY N
L
. The
POS of this entry is "n", which is a "noun".
Next, we use the bilingual dictionaries we cre-
58
Figure 5: Example of generating an entry in the
multilingual thesaurus encompassing Cherokee,
English, Finnish, French and Japanese.
ated to translate all words in SY N
eng
, SY N
fin
,
SY N
fra
, SY N
jpn
to the given endangered lan-
guage, Cherokee, and rank them. According to the
rank calculations, the best Cherokee translation is
the word ?ustalanali?. The new entry added to the
multilingual thesaurus is presented in Figure 6.
Figure 6: An entry of the multilingual thesaurus
encompassing Cherokee, English, Finnish, French
and Japanese.
6 Experimental results
Ideally, evaluation should be performed by volun-
teers who are fluent in both source and destination
languages. However, for evaluating created dic-
tionaries and thesauruses, we could not recruit any
individuals who are experts in two corresponding
languages. We are in the process of finding vol-
unteers who are fluent in both languages for some
selected resources we create.
6.1 Datasets used
We start with two bilingual dictionaries:
Dict(chr,eng)
7
and Dict(chy,eng)
8
that we
obtain from Web pages. These are unidirectional
bilingual dictionaries. The numbers of entries
in Dict(chr,eng) and Dict(chy,eng) are 3,199
and 28,097, respectively. For entries in these
input dictionaries without POS information, our
algorithm chooses the best POS of the English
word, which may lead to wrong translations. The
Microsoft Translator Java API
9
is used as another
main resource. We were given free access to this
API. We could not obtain free access to the API
for the Google Translator.
The synonym lexicons are the synsets of PWN,
FWN, JWN and WWN. Table 1 provides some de-
tails of the Wordnets used.
Wordnet Synsets Core
JWN 57,179 95%
FWN 116,763 100%
PWN 117,659 100%
WWN 59,091 92%
Table 1: The number of synsets in the Wordnets
linked to PWN 3.0 are obtained from the Open
Multilingual Wordnet, along with the percentage
of synsets covered from the semi-automatically
compiled list of 5,000 "core" word senses in PWN.
Note that synsets which are not linked to the PWN
are not taken into account.
6.2 Creating reverse bilingual dictionaries
From Dict(chr,eng) and Dict(chy,eng), we create
two reverse bilingual dictionaries Dict(eng,chr)
with 3,538 entries and Dict(eng,chy) with 28,072
entries
Next, we reverse the reverse dictionaries we
produce to generate new reverse of the reverse
(RR) dictionaries, then integrate the RR dictio-
naries with the input dictionaries to improve the
sizes of dictionaries. During the process of gen-
erating new reverse dictionaries, we already com-
puted the semantic similarity values among words
to find words with the same meanings. We use a
simple approach called the Direct Reversal (DR)
approach in (Lam and Kalita, 2013) to create
7
http://www.manataka.org/page122.html
8
http://www.cdkc.edu/cheyennedictionary/index-
english/index.htm
9
https://datamarket.azure.com/dataset/bing/microsofttranslator
59
these RR dictionaries. To create a reverse dictio-
nary Dict(T,S), the DR approach takes each entry
<s,POS,t> in the input dictionary Dict(S,T) and
simply swaps the positions of s and t. The new
entry <t,POS,s> is added into Dict(T,S). Figure 7
presents an example.
Figure 7: Given a dictionary Dict(chy,eng), we
create a new Dict(eng,chy) using the DRwS ap-
proach of (Lam and Kalita, 2013). Then, we create
a new Dict(chy,eng) using the DR approach from
the created dictionary Dict(eng,chy). Finally, we
integrate the generated dictionary Dict(chy,eng)
with the input dictionary Dict(chy,eng) to create a
new dictionary Dict(chy,eng) with a greater num-
ber of entries
The number of entries in the integrated dictio-
naries Dict(chr,eng) and Dict(chy,eng) are 3,618
and 47,529, respectively. Thus, the number of en-
tries in the original dictionaries have "magically"
increased by 13.1% and 69.21%, respectively.
6.3 Creating additional bilingual dictionaries
We can create dictionaries from chr or chy to
any non-eng language supported by the Microsoft
Translator, e.g., Arabic (arb), Chinese (cht), Cata-
lan (cat), Danish (dan), German (deu), Hmong
Daw (mww), Indonesian (ind), Malay (zlm), Thai
(tha), Spanish (spa) and vie. Table 2 presents the
number of entries in the dictionaries we create.
These dictionaries contain translations only with
the highest ranks for each word.
Although we have not evaluated entries in the
particular dictionaries in Table 1, evaluation of
dictionaries with non-endangered languages, but
using the same approach, we have confidence that
these dictionaries are of acceptable, if not very
good quality.
Dictionary Entries Dictionary Entries
chr-arb 2,623 chr-cat 2,639
chr-cht 2,607 chr-dan 2,655
chr-deu 2,629 chr-mww 2,694
chr-ind 2,580 chr-zlm 2,633
chr-spa 2,607 chr-tha 2,645
chr-vie 2,618 chy-arb 10,604
chy-cat 10,748 chy-cht 10,538
chy-dan 10,654 chy-deu 10,708
chy-mww 10,790 chy-ind 10,434
chy-zlm 10,690 chy-spa 10,580
chy-tha 10,696 chy-vie 10,848
Table 2: The number of entries in some dictionar-
ies we create.
6.4 Creating multilingual thesauruses
We construct two multilingual thesauruses:
THS
1
(chr, eng, fin, fra, jpn) and THS
2
(chy, eng,
fin, fra, jpn). The number of entries in THS
1
and THS
2
are 5,073 and 10,046, respectively.
These thesauruses we construct contain words
with rank values above the average. A similar
approach used to create Wordnet synsets (Lam
et al., 2014) has produced excellent results. We
believe that our thesauruses reported in this paper
are of acceptable quality.
6.5 How to evaluate
Currently, we are not able to evaluate the dictio-
naries and thesauruses we create. In the future, we
expect to evaluate our work using two methods.
First, we will use the standard approach which is
human evaluation to evaluate resources as previ-
ously mentioned. Second, we will try to find an
additional bilingual dictionary translating from an
endangered language S (viz., chr or chy) to another
?resource-rich? non-English language (viz., fin or
fra), then, create a new dictionary translating from
S to English using the approaches we have intro-
duced. We plan to evaluate the new dictionary we
create, say Dict(chr,eng) against the existing dic-
tionary Dict(chr,eng).
7 Conclusion and future work
We examine approaches to create bilingual dictio-
naries and thesauruses for endangered languages
from only one input dictionary, publicly avail-
able Wordnets and an MT. Taking advantage of
available Wordnets linked to the PWN helps re-
duce ambiguities in dictionaries we create. We
60
run experiments with two endangered languages:
Cherokee and Cheyenne. We have also experi-
mented with two additional endangered languages
from Northeast India: Dimasa and Karbi, spo-
ken by about 115,000 and 492,000 people, respec-
tively. We believe that our research has the po-
tential to increase the number of lexical resources
for languages which do not have many existing re-
sources to begin with. We are in the process of
creating reverse dictionaries from bilingual dictio-
naries we have already created. We are also in
the process of creating a Website where all dic-
tionaries and thesauruses we create will be avail-
able, along with a user friendly interface to dis-
seminate these resources to the wider public as
well as to obtain feedback on individual entries.
We will solicit feedback from communities that
use the languages as mother-tongues. Our goal
will be to use this feedback to improve the qual-
ity of the dictionaries and thesauruses. Some of
resources we created can be downloaded from
http://cs.uccs.edu/?linclab/projects.html
References
Adam Kilgarriff. 2003. Thesauruses for natu-
ral language processing. In Proceedings of the
Joint Conference on Natural Language Processing
and Knowledge Engineering, pages 5?13, Beijing,
China, October.
Benoit Sagot and Darja Fi?er. 2008. Building a free
French Wordnet from multilingual resources. In
Proceedings of OntoLex, Marrakech, Morocco.
Carolyn J. Crouch 1990. An approach to the auto-
matic construction of global thesauri, Information
Processing & Management, 26(5): 629?640.
Christiane Fellbaum. 1998. Wordnet: An Electronic
Lexical Database. MIT Press, Cambridge, Mas-
sachusetts, USA.
Dagobert Soergel. 1974. Indexing languages and the-
sauri: construction and maintenance. Melville Pub-
lishing Company, Los Angeles, California.
Dhouha Bouamor, Nasredine Semmar and Pierre
Zweigenbaum. 2013 Using Wordnet and Semantic
Similarity for Bilingual Terminology Mining from
Comparable Corpora. In Proceedings of the 6th
Workshop on Building and Using Comparable Cor-
pora, pages 16?23, Sofia, Bulgaria, August. Associ-
ation for Computational Linguistics.
Dekang Lin. 1998. Automatic retrieval and cluster-
ing of similar words. In Proceedings of the 17th In-
ternational Conference on Computational Linguis-
tics (Volume 2), pages 768?774, Montreal, Quebec,
Canada.
Francis Bond and Kentaro Ogura. 2008 Combin-
ing linguistic resources to create a machine-tractable
Japanese-Malay dictionary. Language Resources
and Evaluation, 42(2): 127?136.
Francis Bond and Ryan Foster. 2013. Linking and
extending an open multilingual Wordnet. In Pro-
ceedings of 51st Annual Meeting of the Association
for Computational Linguistics (ACL 2013), pages
1352?1362, Sofia, Bulgaria, August.
Hitoshi Isahara, Francis Bond, Kiyotaka Uchimoto,
Masao Utiyama and Kyoko Kanzaki. 2008. De-
velopment of Japanese Wordnet. In Proceedings
of 6th International Conference on Language Re-
sources and Evaluation (LREC 2008), pages 2420?
2423, Marrakech, Moroco, May.
James R. Curran and Marc Moens. 2002a. Scaling
context space. In Proceedings of the 40th Annual
Meeting of Association for Computational Linguis-
tics (ACL 2002), pages 231?238, Philadelphia, USA,
July.
James R. Curran and Marc Moens. 2002b. Improve-
ments in automatic thesaurus extraction, In Pro-
ceedings of the Workshop on Unsupervised lexical
acquisition (Volume 9), pages 59?66, Philadelphia,
USA, July. Association for Computational Linguis-
tics.
Jessica Ram?rez, Masayuki Asahara and Yuji Mat-
sumoto. 2013. Japanese-Spanish thesaurus con-
struction using English as a pivot. arXiv preprint
arXiv:1303.1232.
Jost Gippert, Nikolaus Himmelmann and Ulrike Mosel,
eds. 2006. Essentials of Lnguage Documenta-
tion. Vol. 178, Walter de Gruyter GmbH & Co. KG,
Berlin, Germany.
Khang N. Lam and Jugal Kalita. 2013. Creating re-
verse bilingual dictionaries. In Proceedings of the
Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies (NAACL-HLT), pages 524?
528, Atlanta, USA, June.
Khang N. Lam, Feras A. Tarouti and Jugal Kalita.
2014. Automatically constructing Wordnet synsets.
To appear at the 52nd Annual Meeting of the Asso-
ciation for Computational Linguistics (ACL 2014),
Baltimore, USA, June.
Kisuh Ahn and Matthew Frampton. 2006. Automatic
generation of translation dictionaries using interme-
diary languages. In Proceedings of the Interna-
tional Workshop on Cross-Language Knowledge In-
duction, pages 41?44, Trento, Italy, April. European
Chapter of the Association for Computational Lin-
guistics.
Krister Lind?n and Lauri Carlson 2010. FinnWordnet -
WordNet p?finska via ?vers?ttning, LexicoNordica.
Nordic Journal of Lexicography (Volume 17), pages
119?140.
61
Kumiko Tanaka and Kyoji Umemura. 1994. Construc-
tion of bilingual dictionary intermediated by a third
language. In Proceedings of the 15th Conference on
Computational linguistics (COLING 1994), Volume
1, pages 297?303, Kyoto, Japan, August. Associa-
tion for Computational Linguistics.
Kyonghee Paik, Satoshi Shirai and Hiromi Nakaiwa.
2004. Automatic construction of a transfer dictio-
nary considering directionality. In Proceedings of
the Workshop on Multilingual Linguistic Resources,
pages 31?38, Geneva, Switzerland, August . Asso-
ciation for Computational Linguistics.
Mausam, Stephen Soderland, Oren Etzioni, Daniel S.
Weld, Kobi Reiter, Michael Skinner, Marcus Sam-
mer and Jeff Bilmes 2010. Panlingual lexical trans-
lation via probabilistic inference. Artificial Intelli-
gence, 174(2010): 619?637.
Nikola Ljube?i?c and Darja Fi?er. 2011. Bootstrap-
ping bilingual lexicons from comparable corpora for
closely related languages. In Proceedings of the
14th International Conference on Text, Speech and
Dialogue (TSD 2011), pages 91?98. Plze?n, Czech
Republic, September.
Pablo G. Otero and Jos? R.P. Campos. 2010. Auto-
matic generation of bilingual dictionaries using in-
termediate languages and comparable corpora. In
Proceedings of the 11th International Conference on
Computational Linguistic and Intelligent Text Pro-
cessing (CICLing?10 ), pages 473?483, Ias?i, Roma-
nia, March.
Peter M. Roget. 1911. Roget?s Thesaurus of English
Words and Phrases.... Thomas Y. Crowell Com-
pany, New York, USA.
Peter M. Roget. 2008. Roget?s International The-
saurus, 3rd Edition. Oxford & IBH Publishing
Company Pvt, New Delhi, India.
Ryan Shaw, Anindya Datta, Debra VanderMeer and
Kaushik Datta. 2013. Building a scalable database
- Driven Reverse Dictionary. IEEE Transactions on
Knowledge and Data Engineering, 25(3): 528?540.
Sidney I. Landau 1984. Dictionaries: the art and
craft of lexicography. Charles Scribner?s Sons, New
York, USA.
Tim Gollins and Mark Sanderson. 2001. Improving
cross language information retrieval with triangu-
lated translation. In Proceedings of the 24th Annual
International ACM SIGIR Conference on Research
and Development in Information Retrieval, pages
90?95, New Orleans, Louisiana, USA, September.
Varga Istv?n and Yokoyama Shoichi. 2009. Bilin-
gual dictionary generation for low-resourced lan-
guage pairs. In Proceedings of the 2009 Confer-
ence on Empirical Methods in Natural Language
Processing (Volume 2), pages 862?870, Singapore,
August. Association for Computational Linguistics.
62
