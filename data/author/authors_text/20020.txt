Proceedings of the 7th Workshop on Asian Language Resources, ACL-IJCNLP 2009, pages 123?130,
Suntec, Singapore, 6-7 August 2009. c?2009 ACL and AFNLP
CWN-LMF: Chinese WordNet in the Lexical Markup Framework 
 
Lung-Hao Lee1, Shu-Kai Hsieh2, Chu-Ren Huang1,3 
 
1Institute of Linguistics, Academia Sinica 
2Department of English, National Taiwan Normal University 
3Department of Chinese & Bilingual Studies, The Hong Kong Polytechnic University 
1128 Academia Road, Section 2, Taipei 115, Taiwan 
2162 He-ping East Road, Section 1, Taipei 106, Taiwan 
3Hung Hom, Kowloon, Hong Kong 
1{lunghao,churen}@gate.sinica.edu.tw 
2shukai@ntnu.edu.tw 
3churen.huang@inet.polyu.edu.hk 
 
Abstract 
Lexical Markup Framework (LMF, ISO-
24613) is the ISO standard which provides 
a common standardized framework for the 
construction of natural language 
processing lexicons. LMF facilitates data 
exchange among computational linguistic 
resources, and also promises a convenient 
uniformity for future application. This 
study describes the design and implemen-
tation of the WordNet-LMF used to 
represent lexical semantics in Chinese 
WordNet. The compiled CWN-LMF will 
be released to the community for linguis-
tic researches.  
1 Introduction 
Princeton WordNet1 is an English lexical data-
base that groups nouns, verbs, adjectives and 
adverbs into sets of cognitive synonyms, which 
are named as synsets (Fellbaum, 1998; Miller, 
1995).  The Global WordNet Association 
(GWA)2 built on the results of Princeton Word-
Net and Euro WordNet (Vossen, 2004) is a free 
and public association that provides a platform to 
share and connect all languages in the world. For 
Mandarin Chinese in Taiwan, Huang et al (2004) 
constructed the Academia Sinica Bilingual Onto-
logical Wordnet (Sinica BOW) which integrates 
WordNet, English-Chinese Translation Equiva-
                                                 
n
1 Wordnet, available online 
at http://wordnetweb.princeton.edu/perl/webw  
2 Global WordNet Association (GWA), available on-
line at http://www.globalwordnet.org/ 
lents Database (ECTED) and SUMO for cross-
language linguistic studies. As a follow-up, Chi-
nese WordNet (CWN) has been built as a robust 
lexical knowledge system which also embodies a 
precise expression of sense relations (Huang et 
al., 2008). In recent years, WordNet-like re-
sources have become one of the most reliable 
and essential resources for linguistic studies for 
all languages (Magnini and Cavaglia, 2000; So-
ria et al 2009; Strapparava and Valitutti, 2004).  
Lexical Markup Framework (LMF, ISO-
24613) is the ISO standard which provides a 
common standardized framework for the con-
struction of natural language processing lexicons 
(Francopoulo et al, 2009).  One important pur-
pose of LMF is to define a standard for lexicons 
which covers multilingual lexical information 
(Francopoulo et al, 2006b). In this study, we 
describe the design and implementation of the 
Wordnet-LMF (Soria et al 2009) to represent 
lexical semantics in Chinese WordNet. 
The rest of this paper is organized as follows: 
Section 2 introduces Chinese WordNet and Lexi-
cal Markup Framework. Section 3 describes how 
we represent Chinese WordNet in the Lexical 
Markup Framework (CWN-LMF). Section 4 
presents an example on Chinese word sense dis-
tinction using CWN-LMF format. Quantitative 
analysis of compiled CWN-LMF is presented in 
Section 5. We also describe the application sce-
nario using CWN-LMF for information interope-
rability of lexical semantics in Section 6. Section 
7 discusses the experience and difficulties of en-
coding CWN into Wordnet-LMF.  Finally, Sec-
tion 8 concludes this study with future research.  
 
 
123
2 Related Work  
2.1 Chinese WordNet 
Creating a semantic relation-based language re-
source is a time consuming and labor intensive 
task, especially for Chinese due to the unobvious 
definition and distinction among characters, 
morphemes and words. Chinese WordNet 3  
(CWN) has been built by Academia Sinica and is 
successively extended its scope so far. Lemmas 
included in CWN mainly fall on the medium fre-
quency words. Each lexical entry is analyzed 
according to the guidelines of Chinese word 
sense distinctions (CKIP, 2003; Huang et al 
2003) which contain information including Part-
of-Speech, sense definition, example sentences, 
corresponding English synset(s) from Princeton 
WordNet, lexical semantic relations and so on. 
Unlike Princeton WordNet, CWN has not been 
constructed mainly on the synsets and semantic 
relations. Rather it focuses to provide precise 
expression for the Chinese sense division and the 
semantic relations needs to be based on the lin-
guistic theories, especially lexical semantics 
(Huang et al, 2008). Moreover, Huang et al 
(2005) designed and implemented the Sinica 
Sense Management System (SSMS) to store and 
manage word sense data generated in the analy-
sis stage. SSMS is meaning-driven. Each sense 
of a lemma is identified specifically using a 
unique identifier and given a separate entry. 
There are 8,646 lemmas / 25,961 senses until 
December 2008 have been analyzed and stored 
in SSMS. Figure 1 shows the result of sense dis-
tinction for ?? zu-ji ?footprint? as an example 
in Chinese WordNet. 
Huang et al (2004) proposed Domain Lexico-
Taxonomy (DLT) as a domain taxonomy popu-
lated with lexical entries. By using DLT with 
Chinese WordNet and Domain Taxonomy, there 
were 15,160 Chinese senses that linked and dis-
tributed in 463 domain nodes. In addition, Huang 
et al (2005) further applied DLT approach to a 
Chinese thesaurus called as CiLin and showed 
with evaluation that DLT approach is robust 
since the size and number of domain lexica in-
creased effectively.  
 
Figure1: The result of sense distinction for ?zu2 
ji1 (footprint)?. 
2.2 Lexical Markup Framework  
Lexical Markup Framework (LMF, ISO-24613) 
is the ISO standard for natural language 
processing lexicons and machine readable dic-
tionaries. The goals of LMF are to provide a 
common model for the creation and use of lexi-
cal resources, and to manage the exchange of 
data between them. Francopoulo et al (2006a; 
2009) offered a snapshot of how LMF represents 
multilingual lexicons. LMF facilitates data ex-
change among computational linguistic resources 
and also promises a convenient uniformity for 
future application. More updated information can 
be found online 
at http://www.lexicalmarkupframework.org . 
                                                
Soria et al (2009) proposed a Wordnet-LMF 
developed in the framework of the KYOTO 4  
project as a standardized interoperability format 
for the interchange of lexico-semantic informa-
tion. Wordnet-LMF is an LMF dialect tailored to 
encode lexical resources adhering to the Word-
                                                 
/
 
3 Chinese WordNet, available online 
at http://cwn.ling.sinica.edu.tw
4 KYOTO, available online at http://www.kyoto-
project.eu/  
124
Net model of lexical knowledge representation. 
Wordnet-LMF was designed by adhering to LMF 
principles yet taking into account on the one 
hand, the peculiarities of the Wordnet model, and 
on the other by trying to maximize the efficiency 
of the format.  
If we take Princeton WordNet 3.0 synset 
{footprint_1} for example, a Wordnet-LMF re-
presentation can be found in Figure 2. The de-
tails will be explained in Section 3. 
 
<Synset id=?eng-30-06645039-n? baseConcept=?1?>
<Definition gloss=?mark of a foot or shoe on a surface?>
<Statement example=?the police made casts of the 
footprints in the soft earth outside the window?/>
</Definition>
<SynsetRelations>
<SynsetRelation target=?eng-30-06798750-n?
relType=?has_hyperonym?>
</SynsetRelation>
<SynsetRelation target=?eng-30-06645266-n?
relType=?has_hyponym?>
</SynsetRelation>
</SynsetRelations>
<MonolingualExternalRefs>
<MonolingualExternalRef externalSystem=?Wordnet1.6?
externalReference=?eng-16-01234567-n?>
<MonolingualExternalRef externalSystem=?SUMO?
externalReference=?superficialPart? relType=?at?>
</MonolingualExternalRefs>
<Synset>
 
Figure 2: An example of Wordnet-LMF format. 
 
3 CWN in the Lexical Markup Frame-
xical se-
ation 
lInformation is used 
label=?Compile Chinese 
work (CWN-LMF) 
Wordnet-LMF is used to represent le
mantics in Chinese WordNet. As LexicalRe-
source is the root element in Wordnet-LMF, it 
has three children: one GlobalInformation ele-
ment, one or more Lexicon elements, zero or one 
SenseAxes element. This means the object Lexi-
calResource is the container for possibly more 
than one lexicon; inter-lingual correspondences 
are grouped in SenseAxes section. The details are 
presented as follows. 
3.1 Global Inform
The element named as Globa
to describe general information about the lexical 
resource. The attribute ?label? is a free text field. 
Example as follows: 
<GlobalInformation 
Wordnet entries using Wordnet-LMF?> 
3.2  Lexicon 
In CWN-LMF, only one element Lexicon is used 
to contain a monolingual resource as a set of 
LexicalEntry instances followed by a set of Syn-
set elements. The following attributes are speci-
fied: 
 
z languageCoding: It has ?ISO 639-3? as a 
fixed value. 
z language: The standardized 3-letter lan-
guage coding, e.g. zho, is used to spe-
cify the language represented by the 
lexical resource. It is a required 
attribute. 
z owner: It is a required attribute to speci-
fy the copyright holder 
z version: It is a required attribute to speci-
fy the resource version. 
z label: It is used to record additional in-
formation that may be needed. This 
attribute is optional. 
 
Example as follows:  
<Lexicon languageCoding=?ISO 639-3? la-
bel=?Chinese WordNet 1.6? language=?zho?, 
owner=?Academia Sinica?, version=?1.6?>. 
3.2.1 Lexical Entry 
A LexicalEntry element can contain one lemma 
and one sense and has an optional attribute ?id? 
which means a unique identifier.  
The element, Lemma, represents a word form 
chosen by convention to designate the lexical 
entry. It contains the following attributes: 
 
z partOfSpeech: It is a required attribute. 
This attribute takes as its value the 
part-of ?speech value that according 
to WordNet conventions is usually 
specified for a synset. There are four 
part-of-speech notations that are used 
in CWN-LMF. The notation ?n? is 
represented as a noun; the notation 
?v? is represented as a verb; the nota-
tion ?a? is represented as an adjective; 
the notation ?r? is represented as an 
adverb; and the other POS tags are 
represented as ?s?. 
z writtenForm: It is added in case that ?id? 
of LexicalEntry is numerical and it 
takes Unicode strings as values. This 
attribute is optional. 
 
 
125
The Sense element represents one meaning of 
a lexical entry. For WordNet representation, it 
represents the variant of a synset. Required 
attributes are:  
 
z id: It must be specified according to the 
convention used in Chinese WordNet, 
i.e. word_sense#nr.. For example, ??
?_1? means that the first sense of 
lemma ?? huan-jing ?environment?. 
z synset:  It takes as its value the ID of the 
synset to which the particular sense of 
the variant belongs. The ID of the 
synset will be described in the next 
subsection.  
 
Take the first sense of lemma ?? huan-jing 
?environment? for example, it will be represented 
as follows: 
<LexicalEntry> 
  <Lemma writtenForm="??" partOfS-
peech="n"></Lemma> 
     <Sense id="??_1" synset=" zho-16-
06640901-n"></Sense> 
</LexicalEntry> 
3.2.2 Synset 
This element encodes information about a Chi-
nese WordNet synset. Synset elements can con-
tain one Definition, optional SynsetRelations and 
MonolingualExternalRefs elements. Required 
attributes for Synset element are the following: 
 
z id: It is a unique identifier. The agreed 
syntax is ?languageCode-version-id-
POS?.  For example, ?zho-16-
06640901-n? is unique identifier of 
the first sense of lemma ?? huan-
jing ?environment?. 
z baseConcept: Values for the baseCon-
cept attribute will be numerical (1,2,3), 
which correspond to the BaseConcept 
sets. If the sense belongs to the first-
class basic words of NEDO project 
(Tokunaga et al 2006), we encode it 
as 1.  Similarly, if the sense belongs to 
second-class basic words, we encode 
it as 2. The other senses will be en-
coded as 3 if they are not basic words. 
 
The element Definition allows the representa-
tion of the gloss associated with each synset in 
attribute ?gloss?. The required attribute ?exam-
ple? of the element Statement contains the exam-
ples of use associated with the synset . 
SynsetRelations is a bracketing element for 
grouping all SynsetRelation elements. Relations 
between synsets are codified by means of Synse-
tRelation elements, one per relation. Required 
attributes are: 
 
z target: It contains the ID value of the 
synset that is the target of the relation. 
z relType: It means the particular type. 
There are nine semantic relations in 
Chinese WordNet, including 
?has_synonym?, ?has_nearsynonym?, 
?has_hypernym?, ?has_hyponym?, 
?has_holonym?, ?has_meronym?, 
?has_paranym?, ?has_antonym? and 
?has_variant?. Among them, the se-
mantic relation paranymy is used to 
refer to relation between any two lexi-
cal items belonging to the same se-
mantic classification (Huang et al 
2008). For example, the set of 
?spring/summer/fall/winter?   has pa-
ranymy relation of main concept of 
?seasons in a year?. 
 
MonolingualExternalRefs is a bracketing ele-
ment to group all MonolingualExternalRef ele-
ments. MonolingualExternalRef elements must 
be used to represent links between a Sense or 
Synset and other resources, such as an ontology, 
a database or other lexical resources. Attributes 
are: 
 
z  externalSystem: It is a required attribute 
to describe the name of the external 
resource. For instance, possible values 
are ?domain? (Magnini and Cavaglia, 
2000), ?SUMO? (Niles and Pease, 
2001), and ?Wordnet 3.0? for record-
ing SenseKey values.   
z externalReference: It means the particu-
lar identifier or node. This attribute is 
required. 
z relType: It is optional attribute. If the 
?externalSystem? is ?SUMO?. ?rel-
Type? is the type of relations with 
SUMO ontology nodes. Possible val-
ues are ?at?, ?plus?, and ?equal?. 
 
 
 
 
 
126
We use the first sense of lemma ?? huan-
jing ?environment? to illustrate as follows: 
 
<Synset id="zho-16-06640901-n" baseCon-
cept="2"> 
<Definition gloss="?????????? 
????????"> 
<Statement example="???????? 
????????????????? 
???"/> 
</Definition> 
<SynsetRelations> 
<SynsetRelation target="zho-16- 
07029502-n" relType="has_synonym"> 
</SynsetRelation> 
</SynsetRelations> 
<MonolingualExternalRefs> 
<MonolingualExternalRef externalSys 
tem="SUMO" externalRefe 
rence="GeographicArea" rel 
Type="plus"/> 
</MonolingualExternalRefs> 
</Synset> 
 
3.3 SenseAxes 
SenseAxes is a bracketing element that groups 
together SenseAxis elements used for inter-
lingual correspondences. The SenseAxis element 
is a means to group synsets belonging to differ-
ent monolingual wordnets and sharing the same 
equivalent relation to Princeton WordNet 3.0. 
Required attributes are: 
 
z id: It is a unique identifier. 
z relType: It specifies the particular type 
of correspondence among synsets be-
longing to different resources. We use 
?eq_synonym? to represent equal 
synonym relation between Chinese 
Wordnet and Princeton WordNet. 
 
For instance, Chinese synset zho-16-06640901-n 
maps onto English synset eng-30-08567235-n by 
means of an eq_synonym relation. This will be 
represented as follows: 
 
<SenseAxes> 
<SenseAxis id="sa_zho16-eng30_5709" rel 
Type="eq_synonym"> 
<Target ID="zho-16-06640901-n"/> 
<Target ID="eng-30-08567235-n"/> 
</SenseAxis> 
</SenseAxes> 
4 An Example of CWN-LMF Format 
Take ?? zi-ran ?nature? as an example shown 
in Figure 3. ?? has six senses (some of them 
are abridged in the figure). Id attribute of the first 
sense is ??_1 and its synset is called ?zho-16-
03059301-n?. This encoding of synset stands for
??_1 with the unique ID 03059301 in Chinese 
WordNet version 1.6 and its part-of-speech is 
noun. Moreover, one can also learn that??_1 
has a synonym, ???_1 (zho-16-06653601-n). 
Meanwhile, this sense is also corresponded to 
IEEE SUMO. Finally, this compiled CWN-LMF 
version is pointed to Princeton WordNet 3.0, i.e. 
Chinese synset ?zho-16-03059301-n? maps onto 
English synset ?eng-30-11408559-n? by means 
of an eq_synonym relation. 
 
<?xml version=?1.0? encoding=?UTF-8??>
<!DOCTYPE LexicalResource SYSTEM ?kyoto_wn.dtd?>
<LexicalResource>
<GlobalInformation label=?CWN-LMF? />
<Lexicon languageCoding=?ISO 693-3? label=?Chinese  
Wordnet 1.6? language=?zho? owner=?Academia Sinica?
version=?1.6? >
<LexicalEntry>
<Lemma writtenForm=???? partOfSpeech=?n?>
</Lemma>
<Sense id=???_1? synset=?zho-16-03059301-n?>
</Sense>
</LexicalEntry>
?????
<Synset id=?zho-16-03059301-n? baseConcept=?3?>
<Definition gloss=??????????????????>        
<Statement example=???????????????
?????? />
</Definition>
<SynsetRelations>
<SynsetRelation target=?zho-16-06653061-n?
relType=?has_synonym?>
</SynsetRelation>
<MonolingualExternalRefs>
<MonolingualExternalRef externalSystem=?SUMO?
externalReference=?(ComplementFn)InternationalProcess?
relType=?plus? />
</MonolingualExternalRefs>
</Synset>
?????
</Lexion>
<SenseAxes>
<SenseAxis id=?sa_zho16-eng30_17638? relType=?eq_synonym?>
<Target ID=?zho-16-03059301-n?>
<Target ID=?eng-30-11408559-n?>
</SenseAxis>
?????
</SenseAxes>
</LexicalResource>
 
Figure 3: The lemma ?? in  CWN-LMF format. 
5 Quantitative Analysis of CWN-LMF 
There are 8,646 lemmas / 25,961 senses until 
December 2008 have been analyzed in CWN 1.6. 
So far the work on Chinese word distinction is 
still ongoing. It is expected that there are more 
analyzed results in the next released version.  
127
Among analyzed 25,961 senses, there are 268 
senses and 1,217 senses that belong to the first-
class and the second ?class basic words, respec-
tively. When part-of-speech is concerned, we can 
find most of these senses belong to nouns or 
verbs. There are 12,106 nouns, 10,454 nouns, 
806 adjectives and 1,605 adverbs in CWN 1.6 
We further distinguish semantic relations of 
CWN 1.6 and found that there are 3,328 syn-
onyms, 213 near synonyms, 246 hypernyms, 38 
hyponyms, 3 holonyms, 240 paranyms, 369 an-
tonyms and 432 variants, respectively.  
The IEEE SUMO is the only external system 
for monolingual references in CWN-LMF. There 
are 21,925 senses that were pointed to SUMO so 
far. In addition, there are 17,952 senses which 
shared the same equivalent relation to Princeton 
WordNet 3.0 in CWN-LMF. 
 
6 Application Scenarios 
The EU-7 project, KYOTO (Knowledge Yield-
ing Ontologies for Transition-based Organiza-
tion), wants to make knowledge sharable be-
tween communities of people, culture, language 
and computers, by assigning meaning to text and 
giving text to meaning (Vossen et al, 2008a; 
2008b). The goal of KYOTO is a system that 
allows people in communities to define the 
meaning of their words and terms in a shared 
Wiki platform so that it becomes anchored across 
languages and cultures but also so that a comput-
er can use this knowledge to detect knowledge 
and facts in text. 
KYOTO is a generic system offering know-
ledge transition and information across different 
target groups, transgressing linguistic, cultural 
and geographic boundaries. Initially developed 
for the environmental domain, KYOTO will be 
usable in any knowledge domain for mining, or-
ganizing, and distributing information on a glob-
al scale in both European and non-European lan-
guages.   
Whereas the current Wikipedia uses free text 
to share knowledge, KYOTO will represent this 
knowledge so that a computer can understand it. 
For example, the notion of environmental foot-
print will become defined in the same way in all 
these languages but also in such a way that the 
computer knows what information is necessary 
to calculate a footprint. With these definitions it 
will be possible to find information on footprints 
in documents, websites and reports so that users 
can directly ask the computer for actual informa-
tion in their environment, for instance, what is 
the footprint of their town, their region or their 
company. 
KYOTO?s principal components are an ontol-
ogy linked to WordNets in seven different lan-
guages (Basque, Chinese, Dutch, English, Italian, 
Japanese and Spanish). Due to different natures 
of languages, the different designed architectures 
were used to develop WordNets in theses lan-
guages. A unified framework is needed for in-
formation exchange. LMF is hence adopted as 
the framework at lexical semantic level in this 
project. The WordNet in these languages are 
compiled with designed WordNet-LMF format. 
CWN-LMF will also be involved and benefit for 
cross-language interpretabilities in semantic 
search field.  
7 Discussion 
Due to characters of Chinese language, there are 
some difficulties of encoding Chinese WordNet 
into Wordnet-LMF. A brief description is pre-
sented as follows.   
Chinese WordNet was designed for Chinese 
word sense distinction and its lexical semantic 
relationships. The designed architecture belongs 
to word-driven, not synset-driven.  So in CWN-
LMF, we encoded a sense as an individual synset 
and marked up the ?has_synonym? relation when 
senses belong to the same WordNet synset.  
In addition, how to define the basic concept of 
Chinese language is difficult. So far the basic 
word lists of the NEDO project were used as pre-
liminary basis. We need a further method to dis-
tinguish baseConcept attribute of word senses. 
8 Conclusions 
This study describes the design and implementa-
tion of how the Wordnet-LMF used to represent 
lexical semantics in Chinese WordNet. CWN-
LMF is benefit for data exchange among compu-
tational linguistic resources, and also promises a 
convenient uniformity for domain-specific appli-
cations such as KYOTO in cross-language se-
mantic search field.   
Future work is investigated with several direc-
tions. We are planning to release Chinese Word-
Net 1.6 using CWN-LMF format in an xml file, 
including a XML DTD in the following days. In 
addition, the use of this lingual resource for fur-
ther linguistic research is also under investigation. 
 
 
 
128
Acknowledgements  
The authors would like to thank Prof. Claudia 
Soria for her constructive comments. This work 
was funded by National Science Council, Taiwan 
under Grants NSC 97-2923-I-001-001-MY3., 
and also cooperated with EU-FP7 KYOTO 
project. 
References  
CKIP. 2003. Sense and Sensibility Vol. I. Technical 
Report 03-01. Taipei: Academia Sinica. 
Fellbaum, C.. 1998. WordNet: an Electronic Lexical 
Database. The MIT Press. 
Francopoulo, G., Bel, N., George, M., Calzolari, N., 
Monachini, M., Pet, M. and Soria, C.. 2006a. Lexi-
cal Markup Framework (LMF) for NLP Multilin-
gual Resources. Proceedings of COLING-ACL 
Workshop on Multilingual Language Resources 
and Interoperability.  
Francopoulo, G., Bel, N., George, M., Calzolari, N., 
Monachini, M., Pet, M. and Soria, C.. 2006b. LMF 
for Multilingual, Specialized Lexicons. Proceed-
ings of the LREC Workshop on Acquiring and 
Representing Multilingual, Specialized Lexicons: 
the Case of Biomedicine.  
Francopoulo, G., Bel, N., George, M., Calzolari, N., 
Monachini, M., Pet, M. and Soria, C.. 2009. Multi-
lingual Resources for NLP in the Lexical Markup 
Framework (LMF). Language Resource and Eval-
uation. 43:57-70. 
Huang, C.-R., Chang, R.-Y. and Lee, H.-P.. 2004. 
Sinica BOW (Bilingual Ontological Wordnet): In-
tegration of Bilingual WordNet and SUMO. Pro-
ceedings of the 4th International Conference on 
Language Resources and Evaluation. 
Huang, C.-R., Chen, C.-L., Weng, C.-X., Lee, H.-P., 
Chen, Y.-X. and Chen, K.-J.. 2005. The Sinica 
Sense Management System: Design and Implemen-
tation. Computational Linguistics and Chinese 
Language Processing. 10(4): 417-430. 
Huang, C.-R., Hsieh, S.-K., Hong, J.-F., Chen, Y.-Z., 
Su, I.-L., Chen, Y.-X. and Huang, S.-W.. 2008. 
Chinese Wordnet: Design, Implementation, and 
Application of an Infrastructure for Cross-lingual 
Knowledge Processing. Proceedings of the 9th Chi-
nese Lexical Semantics Workshop. 
Huang, C.-R., Lee, H.-P. and Hong, J.-F.. 2004. Do-
main Lexico-Taxonomy: an Approach Towards 
Multi-domain Language Processing. Proceedings 
of the Asian Symposium on Natural Language 
Processing to Overcome Language Barriers. 
Huang, C.-R., Lee, H.-P. and Hong, J.-F.. 2005. The 
Robustness of Domain Lexico-Taxonomy: Ex-
panding Domain Lexicon with Cilin. Proceedings 
of the 4th ACL SIGHAN Workshop on Chinese 
Language Processing. 
Huang, C.-R., Su, I.-L., Hsiao, P.-Y. and Ke, X.-L.. 
2008. Paranymy: Enriching Ontological Know-
ledge in Wordnets. Proceedings of the 4th Global 
WordNet Conference. 
Huang, C.-R., Tsai, D. B.-S., Weng, C.-X., Chu, N.-
X., Ho, W.-R., Huang, L.-H. and Tsai, I.-N.. 2003. 
Sense and Meaning Facet: Criteria and Operational 
Guidelines for Chinese Sense Distinction. Proceed-
ings of the 4th Chinese Lexical Semantics Work-
shop. 
LMF. 2009. Lexical Markup Framework. ISO-24613. 
Geneva:ISO. 
Magnini, B. and Cavaglia, G.. 2000. Integrating Sub-
ject Field Codes into WordNet.  Proceedings of the 
2nd International Conference on Language Re-
sources and Evaluation. 
Miller, G. A.. 1995. WordNet: a Lexical Database for 
English. Communications of the ACM. 38(11): 39-
41. 
Niles, I. and Pease, A.. 2001. Toward a Standard Up-
per Ontology. Proceedings of the 2nd International 
Conference on Formal Ontology in Information 
Systems.  
Soria, C., Monachini, M. and Vossen, P.. 2009. 
Wordnet-LMF: Fleshing out a Standardized For-
mat for Wordnet Interoperability. Proceedings of 
ACM Workshop on Intercultural Collaboration. 
Soria, C., Monachini, M., Bertagna, F., Calzolari, N., 
Huang, C.-R., Hsieh, S.-K., Marchetti, A. and Tes-
coni, M.. 2009. Exploring Interoperability of Lan-
guage Resources: the Case of Cross-lingual Semi-
automatic Enrichment of Wordnets. Language Re-
source and Evaluation. 43:87-96. 
Strapparava, C. and Valitutti, A.. 2004. WordNet-
Affect: an Affective Extension of WordNet. Pro-
ceedings of the 4th International Conference on 
Language Resources and Evaluation. 
Tokuaga, T., Sornlertlamvanich, V., Charoenporn, T., 
Calzolari, N., Monachini, M., Soria, C., Huang, C.-
R., Yu, Y., Yu, H. and Prevot, L.. 2006. Infrastruc-
ture for Standardization of Asian Language Re-
sources. Proceedings of the COLING/ACL Main 
Conference Poster Sessions. 
Vossen, P.. 2004. EuroWordNet: a Multilingual Data-
base of Autonomous and Language-specific Word-
nets Connected via an Inter-Lingual-Index. Interna-
tional Journal of Linguistics. 17(2): 1-23. 
Vossen, P., Agirre, E., Calzolari, N., Fellbaum, C., 
Hsieh, S.-K., Huang, C.-R., Isahara, H., Kanzaki, 
K., Marchetti, A., Monachini, M., Neri, F., Raffael-
li, R., Rigau, G., Tescon, M. and VanGent, J.. 
2008a.   KYOTO: A System for Mining, Structur-
129
ing, and Distributing Knowledge Across Languag-
es and Cultures. Proceedings of 6th International 
Conference on Language Resource and Evaluation.  
Vossen, P., Agirre, E., Calzolari, N., Fellbaum, C., 
Hsieh, S.-K., Huang, C.-R., Isahara, H., Kanzaki, 
K., Marchetti, A., Monachini, M., Neri, F., Raffael-
li, R., Rigau, G., Tescon, M. and VanGent, J.. 
2008b.   KYOTO: A System for Mining, Structur-
ing, and Distributing Knowledge Across Languag-
es and Cultures. Proceedings of the 4th Internation-
al Global WordNet Conference.  
 
 
130
Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: System Demonstrations,
pages 67?70, Dublin, Ireland, August 23-29 2014.
 A Sentence Judgment System for Grammatical Error Detection 
 
Lung-Hao Lee 1,2, Liang-Chih Yu3,4, Kuei-Ching Lee1,2,  
Yuen-Hsien Tseng1, Li-Ping Chang5, Hsin-Hsi Chen2 
1Information Technology Center, National Taiwan Normal University 
2Dept. of Computer Science and Information Engineering, National Taiwan University 
3Dept. of Information Management, Yuen Ze University 
4Innovation Center for Big Data and Digital Convergence, Yuen Ze University 
5Mandarin Training Center, National Taiwan Normal University 
lcyu@saturn.yzu.edu.tw, {lhlee, johnlee, lchang, 
samtseng}@ntnu.edu.tw, hhchen@ntu.edu.tw 
  
 
Abstract 
This study develops a sentence judgment system using both rule-based and n-gram statistical 
methods to detect grammatical errors in Chinese sentences. The rule-based method provides 
142 rules developed by linguistic experts to identify potential rule violations in input sentences. 
The n-gram statistical method relies on the n-gram scores of both correct and incorrect training 
sentences to determine the correctness of the input sentences, providing learners with im-
proved understanding of linguistic rules and n-gram frequencies. 
1 Introduction 
China?s growing global influence has prompted a surge of interest in learning Chinese as a foreign 
language (CFL), and this trend is expected to continue. This has driven an increase in demand for au-
tomated IT-based tools designed to assist CFL learners in mastering the language, including so-called 
MOOCs (Massive Open Online Courses) which allows huge numbers of learners to simultaneously 
access instructional opportunities and resources. This, in turn, has driven demand for automatic proof-
reading techniques to help instructors review and respond to the large volume of assignments and tests 
submitted by enrolled learners. 
However, whereas many computer-assisted learning tools have been developed for use by students 
of English as a Foreign Language (EFL), support for CFL learners is relatively sparse, especially in 
terms of tools designed to automatically detect and correct Chinese grammatical errors. For example, 
while Microsoft Word has integrated robust English spelling and grammar checking functions for 
years, such tools for Chinese are still quite primitive. In contrast to the plethora of research related to 
EFL learning, relatively few studies have focused on grammar checking for CFL learners. Wu et al. 
(2010) proposed relative position and parse template language models to detect Chinese errors written 
by US learner. Yu and Chen (2012) proposed a classifier to detect word-ordering errors in Chinese 
sentences from the HSK dynamic composition corpus. Chang et al. (2012) proposed a penalized prob-
abilistic First-Order Inductive Learning (pFOIL) algorithm for error diagnosis. In summary, although 
there are many approaches and tools to help EFL learners, the research problem described above for 
CFL learning is still under-explored. In addition, no common platform is available to compare differ-
ent approaches and to promote the study of this important issue. 
This study develops a sentence judgment system using both rule-based and n-gram statistical meth-
ods to detect grammatical errors in sentences written by CFL learners. Learners can input Chinese sen-
tences into the proposed system to check for possible grammatical errors. The rule-based method uses 
a set of rules developed by linguistic experts to identify potential rule violations in input sentences. 
 
This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer 
are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ 
67
The n-gr
tences to
proved u
can also 
assignme
2 A S
Figure 1
http://sjf
shown in
part-of-s
grammat
ods dete
informat
ence, as 
?
( I
The ru
(towards
frequenc
detail the
2.1 Pr
Chinese 
Languag
nese wo
usually s
corpus-b
Ma, 200
ed word
????
?POS:W
words, t
lexicon a
POS tag 
 
am statistica
 determine 
nderstandin
be incorpora
nts and test
entence Ju
 shows the
.itc.ntnu.edu
 the upper 
peech taggi
ical error de
ct grammatic
ion, the exp
shown in the
     ?     ??
      from   he
le-based me
)) cannot be
y of the big
 pre-process
e-processin
is written w
e Processing
rd segmente
uffers from 
ased learnin
2). This is fo
s with parts-
??? (Ob
ord? sequen
he translatio
nd therefore
?SHI? is a ta
l method re
the correctn
g of both lin
ted into onl
s. 
dgement S
 user interf
.tw/demo/. L
part of Fig. 
ng, and then
tection. Fina
al errors. O
lanation of t
 bottom par
    ?     ?
re    go   tow
thod shows
 used after a
ram ?? ?
ing, rule-ba
g 
ithout word 
 (NLP) task
rs are gener
the unknow
g method is 
llowed by a
of-speech (T
ama is the p
ce  shown 
n of a forei
 is extracted
g to represen
Figure 1.
lies on the n
ess of the in
guistic rules 
ine CFL MO
ystem 
ace of the 
earners can
1. Each inp
 passed to 
lly, an inpu
therwise, it w
he matched 
t of Fig. 1. F
         ? 
ads  north. )
a rule violat
 verb (e.g., ?
? (go toward
sed method, 
boundaries.
s, texts mus
ally trained 
n word (i.e.,
used to merg
 reliable and
sai and Che
resident of 
as follows: 
gn proper na
 by the unk
t the be-ver
Screenshot 
-gram scor
put sentence
and n-gram 
OC platform
sentence ju
 submit sing
ut sentence 
both the ru
t sentence w
ill be mark
rules and n-g
or instance, 
 
ion is detec
?? (go)). T
s) is relativ
and n-gram 
 As a result,
t undergo au
by an input 
 the out-of-v
e unknown
 cost-effecti
n, 2004). F
the USA). 
 Nb:???
me ????
nown word 
b ???. 
of the senten
es of both c
s. The syste
frequencies
s to help as
dgment sys
le or multip
is pre-proce
le-based an
ill be marke
ed as correc
ram frequen
the followin
ted and expl
he n-gram fr
e low. The f
statistical m
 prior to the
tomatic wo
lexicon and
ocabulary, o
 words to tac
ve POS-tagg
or example, 
It was segm
  SHI:?  N
? (Obama) 
detection me
ce judgemen
orrect and in
m helps lea
. In addition,
sess and/or 
tem, which 
le sentences
ssed for wo
d n-gram st
d as incorre
t ( ). In ad
cies are als
g sentence i
ains that a p
equencies al
ollowing su
ethod. 
 implementa
rd segmenta
 probability 
r OOV) pro
kle the OOV
ing method 
take the Ch
ented and ta
c:??  Na
is not likely
chanism. In
t system. 
correct train
rners develo
 the propose
score the nu
can be acc
 through th
rd segmenta
atistical met
ct ( ) if bo
dition to the
o presented 
s marked as 
reposition (e
so shows th
bsections de
tion of mos
tion. Autom
models. Ho
blem. In this
 problem (C
to label the 
inese senten
gged in the
:??. Amo
 to be inclu
 this case, th
ing sen-
p an im-
d system 
mbers of 
essed at 
e textbox 
tion and 
hods for 
th meth-
 decision 
for refer-
incorrect: 
.g., ??? 
at the the 
scribe in 
t Natural 
atic Chi-
wever, it 
 study, a 
hen and 
segment-
ce ???
 form of  
ng these 
ded in a 
e special 
 
68
2.2 Rule-based Linguistic Analysis 
Several symbols are used to represent the syntactic rules to facilitate the detection of errors embedded 
in Chinese sentences written by CFL learners: (1) ?*? is a wild card, with ?Nh*? denoting all subordi-
nate tags of ?Nh?, e.g., ?Nhaa,? ?Nhab,? ?Nhac,? ?Nhb,? and ?Nhc?. (2) ?-? means an exclusion from 
the previous representation, with ?N*-Nab-Nbc? indicating that the corresponding word should be any 
noun (N*) excluding countable entity nouns (Nab) and surnames (Nbc). (3) ?/? means an alternative 
(i.e., ?or?), where the expression ???/??/??? (some/these/those) indicates that one of these 
three words satisfies the rule. (4) The rule mx{W1 W2} denotes the mutual exclusivity of the two 
words W1 and W2. (5) ?<? denotes the follow-by condition, where the expression ?Nhb  <  Nep? 
means the POS-tag ?Nep? follows the tag ?Nhb? that can exist several words ahead of the ?Nep?. 
Using such rule symbols, we manually constructed syntactic rules to cover errors that frequently oc-
cur in sentences written by CFL learners. We adopted the ?Analysis of 900 Common Erroneous Sam-
ples of Chinese Sentences? (Cheng, 1997) as the development set to handcraft the linguistic rules with 
syntactic information. If an input sentence satisfies any syntactic rule, the system will report the input 
as suspected of containing grammatical errors, creating a useful tool for autonomous CFL learners.  
2.3 N-gram Statistical Analysis 
Language modeling approaches to grammatical error detection are usually based on a score (log prob-
ability) output by an n-gram model trained on a large corpus. A sentence with grammatical errors usu-
ally has a low n-gram score. However, choosing an appropriate threshold to determine whether a sen-
tence is correct is still a nontrivial task. Therefore, this study proposes the use of n-gram scores of cor-
rect and incorrect sentences to build the respective correct and incorrect statistical models for gram-
matical error detection. That is, a given sentence is denoted as incorrect (i.e., having grammatical er-
rors) if its probability score output by the statistical model of incorrect sentences (i.e., the incorrect 
model) is greater than that of correct sentences (i.e., the correct model).  
To build the incorrect and correct statistical models, a total of 19,080 sentences with grammatical 
errors were extracted from the HSK dynamic composition corpus. These sentences were then manual-
ly corrected. An n-gram (n= 2 and 3) language model was then built from the Sinica corpus released 
by the Association for Computational Linguistics and Chinese Language Processing (ACLCLP) using 
the SRILM toolkit (Stolcke, 2002). The trained language model was used to assign an n?gram score 
for each correct and incorrect sentence, which were then used to build the respective correct and incor-
rect models based on a normal probability density function (Manning and Sch?tze, 1999). Both mod-
els can then be used to evaluate each test sentence by transforming its n-gram score into a probability 
score to determine whether the sentence is correct or not. 
3 Performance Evaluation 
The test set included 880 sentences with grammatical errors generated by CSL learners in the NCKU 
Chinese Language Center, and the corresponding 880 manually corrected sentences. For the rule-
based approach, a total of 142 rules were developed to identify incorrect sentences. For the n-gram 
statistical approach, both bi-gram and tri-gram language models were used for the correct and incor-
rect statistical models. In addition to precision, recall, and F1, the false positive rate (FPR) was defined 
as the number of correct sentences incorrectly identified as incorrect sentences divided by the total 
number of correct sentences in the test set. 
Table 1 shows the comparative results of the rule-based and n-gram statistical approaches to gram-
matical error detection. The results show that the rule-based approach achieved high precision, low 
recall and low FPR. Conversely, the n-gram-based approach yielded low precision, high recall and 
high FPR. In addition, the tri-gram model outperformed the bi-gram model for all metrics. Given the 
different results yielded by the rule-based and n-gram statistical approaches, we present different com-
binations of these two methods for comparison. The ?OR? combination means that a given sentence is 
identified as incorrect by only one of the methods, while the ?AND? combination means that a given 
sentence is identified as incorrect by both methods. The results show that the ?OR? combination yield-
ed better recall than the individual methods, and the ?AND? combination yielded better precision and 
FPR than the individual methods. Thus, the choice of methods may depend on application require-
ments or preferences 
69
Method Precision Recall F1 False Positive Rate 
Rule 0.857 0.224 0.356 0.038 
2-gram 0.555 0.751 0.638 0.603 
3-gram 0.585 0.838 0.689 0.595 
Rule OR 2-gram 0.500 1.000 0.667 1.000 
Rule OR 3-gram 0.502 1.000 0.668 0.993 
Rule AND 2-gram 0.924 0.083 0.153 0.007 
Rule AND 3-gram 0.924 0.083 0.153 0.007 
Table 1. Comparative results of the rule-based and n-gram statistical approaches. 
 
Many learner corpora exist for EFL for use in machine learning, including the International Corpus 
of Learner English (ICLE) and Cambridge Learner Corpus (CLC). But collecting a representative 
sample of authentic errors from CFL learners poses a challenge. In addition, English and Chinese 
grammars are markedly different. In contrast to syntax-oriented English language, Chinese is dis-
course-oriented, with meaning often expressed in several clauses to make a complete sentence. These 
characteristics make syntactic parsing difficult, due to long dependency between words in a clause or 
across clauses in a sentence. These difficulties constrain system performance.  
4 Conclusions  
This study presents a sentence judgment system developed using both rule-based and n-gram statisti-
cal methods to detect grammatical errors in sentences written by CFL learners. The system not only 
alerts learners to potential grammatical errors in their input sentences, but also helps them learn about 
linguistic rules and n-gram frequencies. The major contributions of this work include: (a) demonstrat-
ingg the feasibility of detecting grammatical errors in sentences written by CFL learners, (b) develop-
ing a system to facilitate autonomous learning among CFL learners and (c) collecting real grammatical 
errors  from CFL learners for the construction of a Chinese learner corpus. 
Acknowledgments 
This research was partially supported by Ministry of Science and Technology, Taiwan under the grant 
NSC102-2221-E-155-029-MY3, NSC 102-2221-E-002-103-MY3, and the "Aim for the Top Universi-
ty Project" sponsored by the Ministry of Education, Taiwan.  
Reference 
Andreas Stolcke. 2002. SRILM ? An extensible language modeling toolkit. Proceedings of ICSLP?02, pages 
901-904. 
Chi-Hsin Yu and Hsin-Hsi Chen. 2012. Detecting word ordering errors in Chinese sentences for learning Chi-
nese as a foreign language. Proceedings of COLING?12, pages 3003-3018. 
Christopher D. Manning and Hinrich Sch?tze. 1999. Foundations of Statistical Natural Language Processing. 
MIT Press. Cambridge, MA.  
Chung-Hsien Wu, Chao-Hung Liu, Matthew Harris and Liang-Chih Yu. 2010. Sentence correction incorporating 
relative position and parse template language model. IEEE Transactions on Audio, Speech, and Language 
Processing, 18(6):1170-1181. 
Keh-Jiann Chen and Wei-Yun Ma. 2002. Unknown word extraction for Chinese documents. Proceedings of 
COLING?02, pages 169-175. 
M. Cheng. 1997. Analysis of 900 Common Erroneous Samples of Chinese Sentences - for Chinese Learners 
from English Speaking Countries (in Chinese). Beijing, CN: Sinolingua. 
Ru-Ying Chang, Chung-Hsien Wu, and Philips K. Prasetyo. 2012. Error diagnosis of Chinese sentences using 
inductive learning algorithm and decomposition-based testing mechanism. ACM Transactions on Asian Lan-
guage Information Processing, 11(1):Article 3. 
Yu-Fang Tsai and Keh-Jiann Chen. 2004. Reliable and cost-effective pos-tagging. International Journal of 
Computational Linguistics and Chinese Language Processing, 9(1):83-96. 
70
Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 12?16,
Gothenburg, Sweden, April 26-30 2014. c?2014 Association for Computational Linguistics
Chinese Open Relation Extraction for Knowledge Acquisition Yuen-Hsien Tseng1, Lung-Hao Lee1,2, Shu-Yen Lin1, Bo-Shun Liao1,  Mei-Jun Liu1, Hsin-Hsi Chen2, Oren Etzioni3, Anthony Fader4   1Information Technology Center, National Taiwan Normal University  2Dept. of Computer Science and Information Engineering, National Taiwan University 3Allen Institute for Artificial Intelligence, Seattle, WA 4Dept. of Computer Science and Engineering, University of Washington  {samtseng, lhlee, sylin, skylock, meijun}@ntnu.edu.tw, hhchen@ntu.edu.tw, OrenE@allenai.org, afader@cs.washington.edu  Abstract 
This study presents the Chinese Open Relation Extraction (CORE) system that is able to extract entity-relation triples from Chinese free texts based on a series of NLP techniques, i.e., word segmentation, POS tagging, syntactic parsing, and extraction rules. We employ the proposed CORE techniques to extract more than 13 million entity-relations for an open domain question answering application. To our best knowledge, CORE is the first Chinese Open IE system for knowledge acquisition.  1 Introduction  Traditional Information Extraction (IE) involves human intervention of handcrafted rules or tagged examples as the input for machine learning to recognize the assertion of a particular relationship between two entities in texts (Riloff, 1996; Soderland, 1999). Although machine learning helps enumerate potential relation patterns for extraction, this approach is often limited to extracting the relation sets that are predefined. In addition, traditional IE has focused on satisfying pre-specified requests from small homogeneous corpora, leaving the question open whether it can scale up to massive and heterogeneous corpora such as the Web (Banko and Etzioni, 2008; Etzioni et al., 2008, 2011). Open IE, a new domain-independent knowledge discovery paradigm that extracts a diverse set of relations without requiring any relation-specific human inputs and a pre-specified vocabulary, is especially suited to 
massive text corpora, where target relations are unknown in advance. Several Open IE systems, such as TextRunner (Banko et al., 2007), WOE (Wu and Weld, 2010), ReVerb (Fader et al., 2011), and OLLIE (Mausam et al., 2012) achieve promising performance in open relation extraction on English sentences. However, application of these systems poses challenges to those languages that are very different from English, such as Chinese, as grammatical functions in English and Chinese are realized in markedly different ways. It is not sure whether those techniques for English still work for Chinese. This issue motivates us to extend the state-of-the-art Open IE systems to extract relations from Chinese texts. The relatively rich morpho-syntactic marking system of English (e.g., verbal inflection, nominal case, clausal markers) makes the syntactic roles of many words detectable from their surface forms. A tensed verb in English, for example, generally indicates its main verb status of a clause. The pinning down of the main verb in a Chinese clause, on the other hand, must rely on other linguistic cues such as word context due to the lack of tense markers. In contrast to the syntax-oriented English language, Chinese is discourse-oriented and rich in ellipsis ? meaning is often construable in the absence of explicit linguistic devices such that many obligatory grammatical categories (e.g., pronouns and BE verbs) can be elided in Chinese.  For example, the three Chinese sentences ???????? (?Apples nutritious?), ????????? ? (?Apples are nutritious?), and ???????? 
12
(?Apples are rich in nutrition?) are semantically synonymous sentences, but the first one, which lacks an overt verb, is used far more often than the other two. Presumably, an adequate multilingual IE system must take into account those intrinsic differences between languages. This paper introduces the Chinese Open Relation Extraction (CORE) system, which utilizes a series of NLP techniques to extract relations embedded in Chinese sentences. Given a Chinese text as the input, CORE employs word segmentation, part-of-speech (POS) tagging, and syntactic parsing, to automatically annotate the Chinese sentences. Based on this rich information, the input sentences are chunked and the entity-relation triples are extracted. Our evaluation shows the effectiveness of CORE, and its deficiency as well. 2 Related Work TextRunner (Banko et al., 2007) was the first Open IE system, which trains a Na?ve Bayes classifier with POS and NP-chunk features to extract relationships between entities. The subsequent work showed that employing the classifiers capable of modeling the sequential information inherited in the texts, like linear-chain CRF (Banko and Etzioni, 2008) and Markov Logic Network (Zhu et al., 2009), can result in better extraction performance. The WOE system (Wu and Weld, 2010) adopted Wikipedia as the training source for their extractor. Experimental results indicated that parsed dependency features lead to further improvements over TextRunner.  ReVerb (Fader et al., 2011) introduced another approach by identifying first a verb-centered relational phrase that satisfies their pre-defined syntactic and lexical constraints, and then split the input sentence into an Argument-Verb-Argument triple. This approach involves only POS tagging for English and ?regular expression?-like matching. As such, it is suitable for large corpora, and likely to be applicable to Chinese.  
For multilingual open IE, Gamallo et al. (2012) adopts a rule-based dependency parser to extract relations represented in English, Spanish, Portuguese, and Galician. For each parsed sentence, they separate each verbal clause and then identify each one?s verb participants, including their functions: subject, direct object, attribute, and prepositional complements. A set of rules is then applied on the clause constituents to extract the target triples. For Chinese open IE, we adopt a similar general approach. The main differences are the processing steps specific to Chinese language. 3 Chinese Open Relation Extraction This section describes the components of CORE. Not requiring any predefined vocabulary, CORE?s sole input is a Chinese corpus and its output is an extracted set of relational tuples. The system consists of three key modules, i.e., word segmentation and POS tagging, syntactic parsing, and entity-relation triple extraction, which are introduced as follows: Chinese is generally written without word boundaries. As a result, prior to the implementation of most NLP tasks, texts must undergo automatic word segmentation. Automatic Chinese word segmenters are generally trained by an input lexicon and probability models. However, it usually suffers from the unknown word (i.e., the out-of-vocabulary, or OOV) problem. In CORE, a corpus-based learning method to merge the unknown words is adopted to tackle the OOV problem (Chen and Ma, 2002). This is followed by a reliable and cost-effective POS-tagging method to label the segmented words with part-of-speeches (Tsai and Chen, 2004). Take the Chinese sentence ?????????? (?Edison invented the light bulb?) for instance. It was segmented and tagged as follows: ???/Nb  ??/VC  ?/Di  ??/Na. Among these words, the translation of a foreign proper name ????? (?Edison?) is not likely to be included in a lexicon and therefore is extracted by the unknown word detection method. In this case, 
13
the special POS tag ?Di? is a tag to represent a verb?s tense when its character ??? follows immediately after its precedent verb. The complete set of part-of-speech tags is defined in the technical report (CKIP, 1993). In the above sentence, ?? ? could represent a complete different meaning if it is associate with other character, such as ???? meaning ?understand?. Therefore, ????????? ? (?Edison invented a cure?) would be segmented incorrectly once ?? ? is associated with its following character, instead of its precedent word. We adopt CKIP, the best-performing parser in the bakeoff of SIGHAN 2012 (Tseng et al., 2012), to do syntactic structure analysis. The CKIP solution re-estimates the context-dependent probability for Chinese parsing and improves the performance of probabilistic context-free grammar (Hsieh et al., 2012). For the example sentence above, ????/Nb? and ??? /Na? were annotated as two nominal phrases (i.e., ?NP?), and ???/VC  ?/Di? was annotated as a verbal phrase (i.e., ?VP?). CKIP parser also adopts dependency decision-making and example-based approaches to label the semantic role ?Head?, showing the status of a word or a phrase as the pivotal constituent of a sentence (You and Chen, 2004). CORE adopts the head-driven principle to identify the main relation in a given sentence (Huang et al., 2000). Firstly, a relation is defined by both the ?Head?-labeled verb and the other words in the syntactic chunk headed by the verb. Secondly, the noun phrases preceding/preceded by the relational chunk are regarded as the candidates of the head?s arguments. Finally, the entity-relation triple is identified in the form of (entity1, relation, entity2). Regarding the example sentence described above, the triple (???/Edison, ???/invented, ??/light bulb) is extracted by this approach. Figure 1 shows the parsed tree of a Chinese sentence for the relation extraction by CORE. The Chinese sentence ???????????
????????? (?Democrats on the House Budget Committee released a report on Monday?) is the manual translation of one of the English sentences evaluated by ReVerb (Fader et al., 2011). The first step of CORE involves word-segmentation and POS-tagging, thus returning eight word/POS pairs: ??/Nc, ??/Na, ???/Nc, ?/DE, ???/Nb, ???/Nd, ??/VE, ?? /Na. Next, ???? /Nd ?? /VE? is identified as the verbal phrase that heads the sentence. This verbal phrase is regarded as the center of a potential relation. The two noun phrases before and after the verbal phrase, i.e., the NP ??? ?? ??? ? ???? and NP ???? are regarded as the entities that complete the relation. A potential entity-relation-entity triple (i.e., ??????????? / ????? / ??, ?Democrats on the House Budget Committee / on Monday released / a report?) is extracted accordingly. This triple is chunked from its original sentence fully automatically. Finally, a filtering process, which retains ?Head?-labeled words only, can be applied to strain out from each component of this triple the most prominent word: ???? / ?? / ??? (?Democrats / released / report?). 
 Figure 1: The parsed tree of a Chinese sentence. 4 Experiments and Evaluation We adopted the same test set released by ReVerb for performance evaluation. The test set consists of 500 English sentences randomly sampled from the Web and were annotated using a pooling method. To obtain ?gold standard? relation triples in Chinese, the 500 test sentences were manually translated from English to Chinese by a 
14
trained native Chinese speaker and verified by another. Additionally, two other native Chinese speakers annotated the relation triples for each Chinese sentence. In total, 716 Chinese entity-relation triples with an agreement score of 0.79 between the two annotators were obtained and regarded as gold standard.  Performance evaluation of CORE was conducted based on: 1) exact match; and 2) relation-only match. For exact match, each component of the extracted triple must be identical with the gold standard. For relation-only match, the extracted triple is regarded as a correct case if an extracted relation agreed with the relation of the gold standard.  Without another Chinese Open IE system for performance comparison, we compared CORE with a modification of ReVerb system capable of handling Chinese sentences. The modification of ReVerb?s verb-driven regular expression matching was kept to a minimum to deal with language-specific processing. As such, ReVerb remains mostly the same as its English counterpart so that a bilingual (Chinese/English) Open IE system can be easily implemented. Table 1 shows the experimental results. Our CORE system obviously performs better than ReVerb when recall is considered for both exact and relation-only match. The results suggest that utilizing more sophisticated NLP techniques is effective to extract relations without any specific human intervention. In addition, there is a slight decrease in the precision of exact match for CORE. This reveals that ReVerb?s original syntactic and lexical constraints are also useful to identify the arguments and their relationship precisely. In summary, CORE achieved relatively promising F1 scores. These results imply that CORE method is more suitable for Chinese open relation extraction. 
Chinese Open IE Precision Recall F1 Exact Match ReVerb 0.5820 0.0987 0.1688 CORE 0.5579 0.3291 0.4140 Relation Only ReVerb 0.8361 0.1425 0.2435 CORE 0.8463 0.5000 0.6286 Table 1: Performance evaluation on Chinese Open IE. 
We also analyzed the errors made by the CORE model. Almost all the errors resulted from incorrect parsing. Enhancing the parsing effectiveness is most likely to improve the performance of CORE. The relatively low recall rate also indicates that CORE misses many types of relation expression. Ellipsis and flexibility in Chinese syntax are so difficult not only to fail the parser, but also the extraction attempts to bypass the parsing errors. To demonstrate the applicability of CORE, we implement a Chinese Question-Answering (QA) system based on two million news articles from 2002 to 2009 published by the United Daily News Group (udn.com/NEWS). CORE extracted more than 13 million unique entity-relation triples from this corpus. These extracted relations are useful for knowledge acquisition. Take the question ????????? ? (?What is originated from China??) as an example, the relation is automatically identified as ?? ? (?originate?) that heads the following entity ??? ? (?China?). Our open QA system then searched the triples and returned the first entity as the answers. In addition to the obvious answer ???? (?Chinese medicine?), which is usually considered as common-sense knowledge, we also obtained those that are less known, such as the traditional Japanese food ???? (?natto?) and the musical instrument ????? (?accordion?). 5 Conclusions This work demonstrates the feasibility of extracting relations from Chinese corpus without the input of any predefined vocabulary to IE systems. This work is the first to explore Chinese open relation extraction to our best knowledge.  Acknowledgments 
This research was partially supported by National Science Council, Taiwan under grant NSC102-2221-E-002-103-MY3, and the ?Aim for the Top University Project? of National Taiwan Normal University, sponsored by the Ministry of Education, Taiwan. 
15
References  Anthony Fader, Stephen Soderland, and Oren Etzioni. 2011. Identifying relations for open information extraction. Proceedings of EMNLP?11, pages 1535-1545. Chu-Ren Huang, Feng-Yi Chen, Keh-Jiann Chen, Zhao-Ming Gao, and Kuang-Yu Chen. 2000. Sinina Treebank: design criteria, annotation guidelines, and on-line interface. Proceedings of SIGHAN?00, pages 29-37. Chinese Knowledge Information Processing (CKIP) Group. 1993. Categorical analysis of Chinese. ACLCLP Technical Report # 93-05, Academia Sinica.  Fei Wu and Daniel S. Weld. 2010. Open information extraction using Wikipedia. Proceedings of ACL?10, pages 118-127. Jia-Ming You, and Keh-Jiann Chen. 2004. Automatic semantic role assignment for a tree structure.  In Proceedings of SIGHAN?04, pages 1-8. Jun Zhu, Zaiqing Nie, Xiaojiang Lium Bo Zhang, and Ji-Rong Wen. 2009. StatSnowball: a statistical approach to extracting entity relationships. In Proceedings of WWW?09, pages 101-110. Keh-Jiann Chen and Wei-Yun Ma. 2002. Unknown word extraction for Chinese documents. In Proceedings of COLING?02, pages 169-175. Michele Banko, Michael J. Cafarella, Stephen Soderland, Matt Broadhead, and Oren Etzioni. 2007. Open information extraction from the web. Proceedings of IJCAI?07, pages 2670-2676. 
Michele Banko, and Oren Etzioni. 2008. The tradeoffs between open and traditional relation extraction. Proceedings of ACL?08, pages 28-26.   Oren Etzioni, Anthony Fader, Janara Christensen, Stephen Soderland, and Mausam. 2011. Open information extraction: the second generation. In Proceedings of IJCAI?11, pages 3-10. Oren Etzioni, Michele Banko, Stephen Soderland, and Daniel S. Weld. 2008. Open information extraction from the web. Communications of the ACM, 51(12):68-74. Pablo Gamallo, Marcos Garcia, and Santiago Fern?ndez-Lanza. 2012. Dependency-based open information extraction. In Proceedings of ROBUS-UNSUP?12, pages 10-18.  Elleen Riloff. 1996. Automatically constructing extraction patterns from untagged text. In Proceedings of AAAI?96, pages 1044-1049.  Stephen Soderland. 1999. Learning information extraction rules for semi-structured and free text.  Machine Learning, 34(1-3):233-272. Yu-Ming Hsieh, Ming-Hong Bai, Jason S. Chang, and Keh-Jiann Chen. 2012. Improving PCFG Chinese Parsing with Context-Dependent Probability Re-estimation. Proceedings of CLP?12, pages 216-221. Yu-Fang Tsai, and Keh-Jiann Chen. 2004. Reliable and cost-effective pos-tagging. International Journal of Computational Linguistics and Chinese Language Processing, 9(1):83-96. Yuen-Hsien Tseng, Lung-Hao Lee, and Liang-Chih Yu 2012. Traditional Chinese parsing evaluation at SIGHAN Bake-offs 2012. Proceedings of CLP?12, pages 199-205.   
16
