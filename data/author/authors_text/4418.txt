Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 496?504,
Singapore, 6-7 August 2009.
c
?2009 ACL and AFNLP
Multi-Class Confidence Weighted Algorithms
Koby Crammer
?
?
Department of Computer
and Information Science
University of Pennsylvania
Philadelphia, PA 19104
{crammer,kulesza}@cis.upenn.edu
Mark Dredze
?
Alex Kulesza
?
?
Human Language Technology
Center of Excellence
Johns Hopkins University
Baltimore, MD 21211
mdredze@cs.jhu.edu
Abstract
The recently introduced online
confidence-weighted (CW) learning
algorithm for binary classification per-
forms well on many binary NLP tasks.
However, for multi-class problems CW
learning updates and inference cannot
be computed analytically or solved as
convex optimization problems as they are
in the binary case. We derive learning
algorithms for the multi-class CW setting
and provide extensive evaluation using
nine NLP datasets, including three derived
from the recently released New York
Times corpus. Our best algorithm out-
performs state-of-the-art online and batch
methods on eight of the nine tasks. We
also show that the confidence information
maintained during learning yields useful
probabilistic information at test time.
1 Introduction
Online learning algorithms such as the Perceptron
process one example at a time, yielding simple and
fast updates. They generally make few statisti-
cal assumptions about the data and are often used
for natural language problems, where high dimen-
sional feature representations, e.g., bags-of-words,
demand efficiency. Most online algorithms, how-
ever, do not take into account the unique properties
of such data, where many features are extremely
rare and a few are very frequent.
Dredze, Crammer and Pereira (Dredze et al,
2008; Crammer et al, 2008) recently introduced
confidence weighted (CW) online learning for bi-
nary prediction problems. CW learning explicitly
models classifier weight uncertainty using a multi-
variate Gaussian distribution over weight vectors.
The learner makes online updates based on its con-
fidence in the current parameters, making larger
changes in the weights of infrequently observed
features. Empirical evaluation has demonstrated
the advantages of this approach for a number of bi-
nary natural language processing (NLP) problems.
In this work, we develop and test multi-class
confidence weighted online learning algorithms.
For binary problems, the update rule is a sim-
ple convex optimization problem and inference
is analytically computable. However, neither is
true in the multi-class setting. We discuss sev-
eral efficient online learning updates. These up-
date rules can involve one, some, or all of the
competing (incorrect) labels. We then perform an
extensive evaluation of our algorithms using nine
multi-class NLP classification problems, includ-
ing three derived from the recently released New
York Times corpus (Sandhaus, 2008). To the best
of our knowledge, this is the first learning evalua-
tion on these data. Our best algorithm outperforms
state-of-the-art online algorithms and batch algo-
rithms on eight of the nine datasets.
Surprisingly, we find that a simple algorithm in
which updates consider only a single competing
label often performs as well as or better than multi-
constraint variants if it makes multiple passes over
the data. This is especially promising for large
datasets, where the efficiency of the update can
be important. In the true online setting, where
only one iteration is possible, multi-constraint al-
gorithms yield better performance.
Finally, we demonstrate that the label distribu-
tions induced by the Gaussian parameter distribu-
tions resulting from our methods have interesting
properties, such as higher entropy, compared to
those from maximum entropy models. Improved
label distributions may be useful in a variety of
learning settings.
2 Problem Setting
In the multi-class setting, instances from an input
space X take labels from a finite set Y , |Y| = K.
496
We use a standard approach (Collins, 2002) for
generalizing binary classification and assume a
feature function f(x, y) ? R
d
mapping instances
x ? X and labels y ? Y into a common space.
We work in the online framework, where learn-
ing is performed in rounds. On each round the
learner receives an input x
i
, makes a prediction y?
i
according to its current rule, and then learns the
true label y
i
. The learner uses the new example
(x
i
, y
i
) to modify its prediction rule. Its goal is to
minimize the total number of rounds with incor-
rect predictions, |{i : y
i
6= y?
i
}|.
In this work we focus on linear models parame-
terized by weightsw and utilizing prediction func-
tions of the form h
w
(x) = arg max
z
w ? f(x, z).
Note that since we can choose f(x, y) to be the
vectorized Cartesian product of an input feature
function g(x) and y, this setup generalizes the use
of unique weight vectors for each element of Y .
3 Confidence Weighted Learning
Dredze, Crammer, and Pereira (2008) introduced
online confidence weighted (CW) learning for bi-
nary classification, where X = R
d
and Y =
{?1}. Rather than using a single parameter vec-
tor w, CW maintains a distribution over param-
eters N (?,?), where N (?,?) the multivariate
normal distribution with mean ? ? R
d
and co-
variance matrix ? ? R
d?d
. Given an input in-
stance x, a Gibbs classifier draws a weight vector
w from the distribution and then makes a predic-
tion according to the sign of w ? x.
This prediction rule is robust if the example
is classified correctly with high-probability, that
is, for some confidence parameter .5 ? ? < 1,
Pr
w
[y (w ? x) ? 0] ? ?. To learn a binary CW
classifier in the online framework, the robustness
property is enforced at each iteration while mak-
ing a minimal update to the parameter distribution
in the KL sense:
(?
i+1
,?
i+1
) =
arg min
?,?
D
KL
(N (?,?) ?N (?
i
,?
i
))
s.t. Pr
w
[y
i
(w ? x
i
) ? 0] ? ? (1)
Dredze et al (2008) showed that this optimization
can be solved in closed form, yielding the updates
?
i+1
= ?
i
+ ?
i
?
i
x
i
(2)
?
i+1
=
(
?
?1
i
+ ?
i
x
i
x
T
i
)
?1
(3)
for appropriate ?
i
and ?
i
.
For prediction, they use the Bayesian rule
y? = arg max
z?{?1}
Pr
w?N (?,?)
[z (x ?w) ? 0] ,
which for binary labels is equivalent to using the
mean parameters directly, y? = sign (? ? x).
4 Multi-Class Confidence Weighted
Learning
As in the binary case, we maintain a distribution
over weight vectors w ? N (?,?). Given an in-
put instance x, a Gibbs classifier draws a weight
vector w ? N (?,?) and then predicts the label
with the maximal score, arg max
z
(w ? f(x, z)).
As in the binary case, we use this prediction rule
to define a robustness condition and corresponding
learning updates.
We generalize the robustness condition used in
Crammer et al (2008). Following the update on
round i, we require that the ith instance is correctly
labeled with probability at least ? < 1. Among the
distributions that satisfy this condition, we choose
the one that has the minimal KL distance from the
current distribution. This yields the update
(?
i+1
,?
i+1
) = (4)
arg min
?,?
D
KL
(N (?,?) ?N (?
i
,?
i
))
s.t. Pr [y
i
|x
i
,?,?] ? ? ,
where
Pr [y |x,?,?] =
Pr
w?N (?,?)
[
y = arg max
z?Y
(w ? f(x, z))
]
.
Due to the max operator in the constraint, this op-
timization is not convex when K > 2, and it does
not permit a closed form solution. We therefore
develop approximations that can be solved effi-
ciently. We define the following set of events for a
general input x:
A
r,s
(x)
def
= {w : w ? f(x, r) ? w ? f(x, s)}
B
r
(x)
def
= {w : w ? f(x, r) ? w ? f(x, s) ?s}
=
?
s 6=r
A
r,s
(x)
We assume the probability that w ? f(x, r) =
w ? f(x, s) for some s 6= r is zero, which
497
holds for non-trivial distribution parameters and
feature vectors. We rewrite the prediction y? =
arg max
r
Pr [B
r
(x)], and the constraint from
Eq. (4) becomes
Pr [B
y
i
(x)] ? ? . (5)
We focus now on approximating the event B
y
i
(x)
in terms of events A
y
i
,r
. We rely on the fact that
the level sets of Pr [A
y
i
,r
] are convex in ? and
?. This leads to convex constraints of the form
Pr [A
y
i
,r
] ? ?.
Outer Bound: Since B
r
(x) ? A
r,s
(x), it holds
trivially that Pr [B
y
i
(x)] ? ? ? Pr [A
y
i
,r
] ?
?,?r 6= y
i
. Thus we can replace the constraint
Pr [B
y
i
(x)] ? ? with Pr [A
y
i
,r
] ? ? to achieve an
outer bound. We can simultaneously apply all of
the pairwise constraints to achieve a tighter bound:
Pr [A
y
i
,r
] ? ? ?r 6= y
i
This yields a convex approximation to Eq. (4) that
may improve the objective value at the cost of
violating the constraint. In the context of learn-
ing, this means that the new parameter distribu-
tion will be close to the previous one, but may not
achieve the desired confidence on the current ex-
ample. This makes the updates more conservative.
Inner Bound: We can also consider an inner
bound. Note that B
y
i
(x)
c
= (?
r
A
y
i
,r
(x))
c
=
?
r
A
y
i
,r
(x)
c
, thus the constraint Pr [B
y
i
(x)] ? ?
is equivalent to
Pr [?
r
A
y
i
,r
(x)
c
] ? 1? ? ,
and by the union bound, this follows whenever
?
r
Pr [A
y
i
,r
(x)
c
] ? 1? ? .
We can achieve this by choosing non-negative
?
r
? 0,
?
r
?
r
= 1, and constraining
Pr [A
y
i
,r
(x)] ? 1? (1? ?) ?
r
for r 6= y
i
.
This formulation yields an inner bound on the
original constraint, guaranteeing its satisfaction
while possibly increasing the objective. In the
context of learning, this is a more aggressive up-
date, ensuring that the current example is robustly
classified even if doing so requires a larger change
to the parameter distribution.
Algorithm 1 Multi-Class CW Online Algorithm
Input: Confidence parameter ?
Feature function f(x, y) ? R
d
Initialize: ?
1
= 0 , ?
1
= I
for i = 1, 2 . . . do
Receive x
i
? X
Predict ranking of labels y?
1
, y?
2
, . . .
Receive y
i
? Y
Set ?
i+1
,?
i+1
by approximately solving
Eq. (4) using one of the following:
Single-constraint update (Sec. 5.1)
Exact many-constraint update (Sec. 5.2)
Seq. many-constraint approx. (Sec. 5.2)
Parallel many-constraint approx. (Sec. 5.2)
end for
Output: Final ? and ?
Discussion: The two approximations are quite
similar in form. Both replace the constraint
Pr [B
y
i
(x)] ? ? with one or more constraints of
the form
Pr [A
y
i
,r
(x)] ? ?
r
. (6)
To achieve an outer bound we choose ?
r
= ? for
any set of r 6= y
i
. To achieve an inner bound we
use all K ? 1 possible constraints, setting ?
r
=
1 ? (1? ?) ?
r
for suitable ?
r
. A simple choice is
?
r
= 1/(K ? 1).
In practice, ? is a learning parameter whose
value will be optimized for each task. In this case,
the outer bound (when all constraints are included)
and inner bound (when ?
r
= 1/(K ? 1)) can be
seen as equivalent, since for any fixed value of
?
(in)
for the inner bound we can choose
?
(out)
= 1?
1? ?
(in)
K ? 1
,
for the outer bound and the resulting ?
r
will be
equal. By optimizing ? we automatically tune the
approximation to achieve the best compromise be-
tween the inner and outer bounds. In the follow-
ing, we will therefore assume ?
r
= ?.
5 Online Updates
Our algorithms are online and process examples
one at a time. Pseudo-code for our approach is
given in algorithm 1. We approximate the pre-
diction step by ranking each label y according
to the score given by the mean weight vector,
? ? f(x
i
, y). Although this approach is Bayes op-
timal for binary problems (Dredze et al, 2008),
498
it is an approximation in general. We note that
more accurate inference can be performed in the
multi-class case by sampling weight vectors from
the distribution N (?,?) or selecting labels sen-
sitive to the variance of prediction; however, in
our experiments this did not improve performance
and required significantly more computation. We
therefore proceed with this simple and effective
approximation.
The update rule is given by an approximation
of the type described in Sec. 4. All that remains
is to choose the constraint set and solve the opti-
mization efficiently. We discuss several schemes
for minimizing KL divergence subject to one or
more constraints of the form Pr [A
y
i
,r
(x)] ? ?.
We start with a single constraint.
5.1 Single-Constraint Updates
The simplest approach is to select the single con-
straint Pr [A
y
i
,r
(x)] ? ? corresponding to the
highest-ranking label r 6= y
i
. This ensures that,
following the update, the true label is more likely
to be predicted than the label that was its closest
competitor. We refer to this as the k = 1 update.
Whenever we have only a single constraint, we
can reduce the optimization to one of the closed-
form CW updates used for binary classification.
Several have been proposed, based on linear ap-
proximations (Dredze et al, 2008) and exact for-
mulations (Crammer et al, 2008). For simplicity,
we use the Variance method from Dredze et al
(2008), which did well in our initial evaluations.
This method leads to the following update rules.
Note that in practice ? is projected to a diagonal
matrix as part of the update; this is necessary due
to the large number of features that we use.
?
i+1
= ?
i
+ ?
i
?
i
g
i,y
i
,r
(7)
?
i+1
=
(
?
?1
i
+ 2?
i
?g
i,y
i
,r
g
>
i,y
i
,r
)
?1
(8)
g
i,y
i
,r
= f(x
i
, y
i
)? f (x
i
, r) ? = ?
?1
(?)
The scale ?
i
is given by max(?
i
, 0), where ?
i
is
equal to
?(1 + 2?m
i
) +
?
(1 + 2?m
i
)
2
? 8?(m
i
? ?v
i
)
4?v
i
and
m
i
= ?
i
? g
i,y
i
,r
v
i
= g
>
i,y
i
,r
?
i
g
i,y
i
,r
.
These rules derive directly from Dredze et al
(2008) or Figure 1 in Crammer et al (2008); we
simply substitute y
i
= 1 and x
i
= g
i,y
i
,r
.
5.2 Many-Constraints Updates
A more accurate approximation can be obtained
by selecting multiple constraints. Analogously, we
choose the k ? K?1 constraints corresponding to
the labels r
1
, . . . , r
k
6= y
i
that achieve the highest
predicted ranks. The resulting optimization is con-
vex and can be solved by a standard Hildreth-like
algorithm (Censor & Zenios, 1997). We refer to
this update as Exact. However, Exact is expen-
sive to compute, and tends to over-fit in practice
(Sec. 6.2). We propose several approximate alter-
natives.
Sequential Update: The Hildreth algorithm it-
erates over the constraints, updating with respect
to each until convergence is reached. We approxi-
mate this solution by making only a single pass:
? Set ?
i,0
= ?
i
and ?
i,0
= ?
i
.
? For j = 1, . . . , k, set (?
i,j
,?
i,j
) to the solu-
tion of the following optimization:
min
?,?
D
KL
(
N (?,?) ?N
(
?
i,j?1
,?
i,j?1
))
s.t. Pr
[
A
y
i
,r
j
(x)
]
? ?
? Set ?
i+1
= ?
i,k
and ?
i+1
= ?
i,k
.
Parallel Update: As an alternative to the Hil-
dreth algorithm, we consider the simultaneous al-
gorithm of Iusem and Pierro (1987), which finds
an exact solution by iterating over the constraints
in parallel. As above, we approximate the exact
solution by performing only one iteration. The
process is as follows.
? For j = 1, . . . , k, set (?
i,j
,?
i,j
) to the solu-
tion of the following optimization:
min
?,?
D
KL
(N (?,?) ?N (?
i
,?
i
))
s.t. Pr
[
A
y
i
,r
j
(x)
]
? ?
? Let ? be a vector, ?
j
?0 ,
?
j
?
j
=1.
? Set ?
i+1
=
?
j
?
j
?
i,j
, ?
?1
i+1
=
?
j
?
j
?
?1
i,j
.
In practice we set ?
j
= 1/k for all j.
6 Experiments
6.1 Datasets
Following the approach of Dredze et al (2008),
we evaluate using five natural language classifica-
tion tasks over nine datasets that vary in difficulty,
size, and label/feature counts. See Table 1 for an
overview. Brief descriptions follow.
499
Task Instances Features Labels Bal.
20 News 18,828 252,115 20 Y
Amazon 7 13,580 686,724 7 Y
Amazon 3 7,000 494,481 3 Y
Enron A 3,000 13,559 10 N
Enron B 3,000 18,065 10 N
NYTD 10,000 108,671 26 N
NYTO 10,000 108,671 34 N
NYTS 10,000 114,316 20 N
Reuters 4,000 23,699 4 N
Table 1: A summary of the nine datasets, includ-
ing the number of instances, features, and labels,
and whether the numbers of examples in each class
are balanced.
Amazon Amazon product reviews. Using the
data of Dredze et al (2008), we created two do-
main classification datasets from seven product
types (apparel, books, dvds, electronics, kitchen,
music, video). Amazon 7 includes all seven prod-
uct types and Amazon 3 includes books, dvds, and
music. Feature extraction follows Blitzer et al
(2007) (bigram features and counts).
20 Newsgroups Approximately 20,000 news-
group messages, partitioned across 20 different
newsgroups.
1
This dataset is a popular choice for
binary and multi-class text classification as well as
unsupervised clustering. We represent each mes-
sage as a binary bag-of-words.
Enron Automatic sorting of emails into fold-
ers.
2
We selected two users with many email
folders and messages: farmer-d (Enron A) and
kaminski-v (Enron B). We used the ten largest
folders for each user, excluding non-archival email
folders such as ?inbox,? ?deleted items,? and ?dis-
cussion threads.? Emails were represented as bi-
nary bags-of-words with stop-words removed.
NY Times To the best of our knowledge we are
the first to evaluate machine learning methods on
the New York Times corpus. The corpus con-
tains 1.8 million articles that appeared from 1987
to 2007 (Sandhaus, 2008). In addition to being
one of the largest collections of raw news text,
it is possibly the largest collection of publicly re-
leased annotated news text, and therefore an ideal
corpus for large scale NLP tasks. Among other
annotations, each article is labeled with the desk
that produced the story (Financial, Sports, etc.)
(NYTD), the online section to which the article was
1
http://people.csail.mit.edu/jrennie/20Newsgroups/
2
http://www.cs.cmu.edu/?enron/
Task Sequential Parallel Exact
20 News 92.16 91.41 88.08
Amazon 7 77.98 78.35 77.92
Amazon 3 93.54 93.81 93.00
Enron A 82.40 81.30 77.07
Enron B 71.80 72.13 68.00
NYTD 83.43 81.43 80.92
NYTO 82.02 78.67 80.60
NYTS 52.96 54.78 51.62
Reuters 93.60 93.97 93.47
Table 2: A comparison of k = ? updates. While
the two approximations (sequential and parallel)
are roughly the same, the exact solution over-fits.
posted (NYTO), and the section in which the arti-
cle was printed (NYTS). Articles were represented
as bags-of-words with feature counts (stop-words
removed).
Reuters Over 800,000 manually categorized
newswire stories (RCV1-v2/ LYRL2004). Each
article contains one or more labels describing its
general topic, industry, and region. We performed
topic classification with the four general topics:
corporate, economic, government, and markets.
Details on document preparation and feature ex-
traction are given by Lewis et al (2004).
6.2 Evaluations
We first set out to compare the three update ap-
proaches proposed in Sec. 5.2: an exact solution
and two approximations (sequential and parallel).
Results (Table 2) show that the two approxima-
tions perform similarly. For every experiment the
CW parameter ? and the number of iterations (up
to 10) were optimized using a single randomized
iteration. However, sequential converges faster,
needing an average of 4.33 iterations compared to
7.56 for parallel across all datasets. Therefore, we
select sequential for our subsequent experiments.
The exact method performs poorly, displaying
the lowest performance on almost every dataset.
This is unsurprising given similar results for bi-
nary CW learning Dredze et al (2008), where ex-
act updates were shown to over-fit but converged
after a single iteration of training. Similarly, our
exact implementation converges after an average
of 1.25 iterations, much faster than either of the
approximations. However, this rapid convergence
appears to come at the expense of accuracy. Fig. 1
shows the accuracy on Amazon 7 test data after
each training iteration. While both sequential and
parallel improve with several iterations, exact de-
500
1 2 3 4 5Training Iterations
77.0
77.5
78.0
78.5
Tes
t Ac
cura
cy
K=1Sequential K=5Sequential K=AllParallel K=AllExact K=All
Figure 1: Accuracy on test data after each iteration
on the Amazon 7 dataset.
grades after the first iteration, suggesting that it
may over-fit to the training data. The approxima-
tions appear to smooth learning and produce better
performance in the long run.
6.3 Relaxing Many-Constraints
While enforcing many constraints may seem op-
timal, there are advantages to pruning the con-
straints as well. It may be time consuming to en-
force dozens or hundreds of constraints for tasks
with many labels. Structured prediction tasks of-
ten involve exponentially many constraints, mak-
ing pruning mandatory. Furthermore, many real
world datasets, especially in NLP, are noisy, and
enforcing too many constraints can lead to over-
fitting. Therefore, we consider the impact of re-
ducing the constraint set in terms of both reducing
run-time and improving accuracy.
We compared using all constraints (k = ?)
with using 5 constraints (k = 5) for the sequential
update method (Table 3). First, we observe that
k = 5 performs better than k =? on nearly every
dataset: fewer constraints help avoid over-fitting
and once again, simpler is better. Additionally,
k = 5 converges faster than k = ? in an average
of 2.22 iterations compared with 4.33 iterations.
Therefore, reducing the number of constraints im-
proves both speed and accuracy. In comparing
k = 5 with the further reduced k = 1 results, we
observe the latter improves on seven of the nine
methods. This surprising result suggests that CW
learning can perform well even without consid-
ering more than a single constraint per example.
However, k = 1 exceeds the performance of mul-
tiple constraints only through repeated training it-
erations. k = 5 CW learning converges faster ?
2.22 iterations compared with 6.67 for k = 1 ? a
desirable property in many resource restricted set-
tings. (In the true online setting, only a single it-
eration may be possible.) Fig. 1 plots the perfor-
mance of k = 1 and k = 5 CW on test data after
each training iteration. While k = 1 does better
in the long run, it lags behind k = 5 for several
iterations. In fact, after a single training iteration,
k = 5 outperforms k = 1 on eight out of nine
datasets. Thus, there is again a tradeoff between
faster convergence (k = 5) and increased accuracy
(k = 1). While the k = 5 update takes longer per
iteration, the time required for the approximate so-
lutions grows only linearly in the number of con-
straints. The evaluation in Fig. 1 required 3 sec-
onds for the first iteration of k = 1, 10 seconds
for k = 5 and 11 seconds for one iteration of all
7 constraints. These differences are insignificant
compared to the cost of performing multiple itera-
tions over a large dataset. We note that, while both
approximate methods took about the same amount
of time, the exact solution took over 4 minutes for
its first iteration.
Finally, we compare CW methods with sev-
eral baselines in Table 3. Online baselines in-
clude Top-1 Perceptron (Collins, 2002), Top-1
Passive-Aggressive (PA), and k-best PA (Cram-
mer & Singer, 2003; McDonald et al, 2004).
Batch algorithms include Maximum Entropy (de-
fault configuration in McCallum (2002)) and sup-
port vector machines (LibSVM (Chang & Lin,
2001) for one-against-one classification and multi-
class (MC) (Crammer & Singer, 2001)). Classifier
parameters (C for PA/SVM and maxent?s Gaus-
sian prior) and number of iterations (up to 10) for
the online methods were optimized using a sin-
gle randomized iteration. On eight of the nine
datasets, CW improves over all baselines. In gen-
eral, CW provides faster and more accurate multi-
class predictions.
7 Error and Probabilistic Output
Our focus so far has been on accuracy and speed.
However, there are other important considerations
for selecting learning algorithms. Maximum en-
tropy and other probabilistic classification algo-
rithms are sometimes favored for their probabil-
ity scores, which can be useful for integration
with other learning systems. However, practition-
501
PA CW SVM
Task Perceptron K=1 K=5 K=1 K=5 K=? 1 vs. 1 MC Maxent
20 News 81.07 88.59 88.60 ??92.90 ??92.78 ??92.16 85.18 90.33 88.94
Amazon 7 74.93 76.55 76.72 ??78.70 ??78.04 ??77.98 75.11 76.60 76.40
Amazon 3 92.26 92.47 93.29 ?94.01 ??94.29 93.54 92.83 93.60 93.60
Enron A 74.23 79.27 80.77 ??83.83 ?82.23 ?82.40 80.23 82.60 82.80
Enron B 66.30 69.93 68.90 ??73.57 ??72.27 ??71.80 65.97 71.87 69.47
NYTD 80.67 83.12 81.31 ??84.57 ?83.94 83.43 82.95 82.00 83.54
NYTO 78.47 81.93 81.22 ?82.72 ?82.55 82.02 82.13 81.01 82.53
NYTS 50.80 56.19 55.04 54.67 54.26 52.96 55.81 56.74 53.82
Reuters 92.10 93.12 93.30 93.60 93.67 93.60 92.97 93.32 93.40
Table 3: A comparison of CW learning (k = 1, 5,? with sequential updates) with several baseline
algorithms. CW learning achieves the best performance eight out of nine times. Statistical significance
(McNemar) is measured against all baselines (? indicates 0.05 and ?? 0.001) or against online baselines
(? indicates 0.05 and ?? 0.001).
0.35 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.7528
29
30
31
32
33
entropy
error
MC CWMaxEnt
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.90
200400
600800
10001200
Bin lower threshold
Number
 of exam
ples per
 bin
MaxEntMC CW
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.90
2
4
68
1012
Bin lower threshold
Test err
or in bin
MaxEntMC CW
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.90
0.10.2
0.30.4
0.50.6
0.70.8
Bin lower threshold
Test err
or given
 bin
MaxEntMC CW
Figure 2: First panel: Error versus prediction entropy on Enron B. As CW converges (right to left) error
and entropy are reduced. Second panel: Number of test examples per prediction probability bin. The
red bars correspond to maxent and the blue bars to CW, with increasing numbers of epochs from left
to right. Third panel: The contribution of each bin to the total test error. Fourth panel: Test error
conditioned on prediction probability.
ers have observed that maxent probabilities can
have low entropy and be unreliable for estimating
prediction confidence (Malkin & Bilmes, 2008).
Since CW also produces label probabilities ? and
does so in a conceptually distinct way ? we in-
vestigate in this section some empirical properties
of the label distributions induced by CW?s param-
eter distributions and compare them with those of
maxent.
We trained maxent and CW k = 1 classi-
fiers on the Enron B dataset, optimizing parame-
ters as before (maxent?s Gaussian prior and CW?s
?). We estimated the label distributions from our
CW classifiers after each iteration and on every
test example x by Gibbs sampling weight vec-
tors w ? N (?,?), and for each label y count-
ing the fraction of weight vectors for which y =
arg max
z
w ? f(x, z). Normalizing these counts
yields the label distributions Pr [y|x]. We denote
by y? the predicted label for a given x, and refer to
Pr [y?|x] as the prediction probability.
The leftmost panel of Fig. 2 plots each
method?s prediction error against the nor-
malized entropy of the label distribution
?
(
1
m
?
i
?
z
Pr [z|x
i
] log (Pr [z|x
i
])
)
/ log(K).
Each CW iteration (moving from right to left in
the plot) reduces both error and entropy. From our
maxent results we make the common observation
that maxent distributions have (ironically) low
entropy. In contrast, while CW accuracy exceeds
maxent after its second iteration, normalized
entropy remains high. Higher entropy suggests
a distribution over labels that is less peaked and
potentially more informative than those from
maxent. We found that the average probability
assigned to a correct prediction was 0.75 for
CW versus 0.83 for maxent and for an incorrect
prediction was 0.44 for CW versus 0.56 for
maxent.
Next, we investigate how these probabilities
relate to label accuracy. In the remaining pan-
els, we binned examples according to their pre-
diction probabilities Pr [y?|x] = max
y
Pr [y|x].
The second panel of Fig. 2 shows the numbers
of test examples with Pr [y?|x] ? [?, ? + 0.1) for
? = 0.1, 0.2 . . . 0.9. (Note that since there are 10
502
classes in this problem, we must have Pr [y?|x] ?
0.1.) The red (leftmost) bar corresponds to the
maximum entropy classifier, and the blue bars cor-
respond, from left to right, to CW after each suc-
cessive training epoch.
From the plot we observe that the maxent classi-
fier assigns prediction probability greater than 0.9
to more than 1,200 test examples out of 3,000.
Only 50 examples predicted by maxent fall in the
lowest bin, and the rest of examples are distributed
nearly uniformly across the remaining bins. The
large number of examples with very high predic-
tion probability explains the low entropy observed
for the maximum entropy classifier.
In contrast, the CW classifier shows the oppo-
site behavior after one epoch of training (the left-
most blue bar), assigning low prediction probabil-
ity (less than 0.3) to more than 1,200 examples
and prediction probability of at least 0.9 to only
100 examples. As CW makes additional passes
over the training data, its prediction confidence
increases and shifts toward more peaked distribu-
tions. After seven epochs fewer than 100 examples
have low prediction probability and almost 1,000
have high prediction probability. Nonetheless, we
note that this distribution is still less skewed than
that of the maximum entropy classifier.
Given the frequency of high probability maxent
predictions, it seems likely that many of the high
probability maxent labels will be wrong. This is
demonstrated in the third panel, which shows the
contribution of each bin to the total test error. Each
bar reflects the number of mistakes per bin divided
by the size of the complete test set (3,000). Thus,
the sum of the heights of the corresponding bars
in each bin is proportional to test error. Much of
the error of the maxent classifier comes not only
from the low-probability bins, due to their inac-
curacy, but also from the highest bin, due to its
very high population. In contrast, the CW clas-
sifiers see very little error contribution from the
high-probability bins. As training progresses, we
see again that the CW classifiers move in the direc-
tion of the maxent classifier but remain essentially
unimodal.
Finally, the rightmost panel shows the condi-
tional test error given bin identity, or the fraction
of test examples from each bin where the predic-
tion was incorrect. This is the pointwise ratio be-
tween corresponding values of the previous two
histograms. For both methods, there is a monoton-
ically decreasing trend in error as prediction prob-
ability increases; that is, the higher the value of
the prediction probability, the more likely that the
prediction it provides is correct. As CW is trained,
we see an increase in the conditional test error, yet
the overall error decreases (not shown). This sug-
gests that as CW is trained and its overall accuracy
improves, there are more examples with high pre-
diction probability, and the cost for this is a rela-
tive increase in the conditional test error per bin.
The maxent classifier produces an extremely large
number of test examples with very high prediction
probabilities, which yields relatively high condi-
tional test error. In nearly all cases, the conditional
error values for the CW classifiers are smaller than
the corresponding values for maximum entropy.
These observations suggest that CW assigns prob-
abilities more conservatively than maxent does,
and that the (fewer) high confidence predictions it
makes are of a higher quality. This is a potentially
valuable property, e.g., for system combination.
8 Conclusion
We have proposed a series of approximations for
multi-class confidence weighted learning, where
the simple analytical solutions of binary CW
learning do not apply. Our best CW method out-
performs online and batch baselines on eight of
nine NLP tasks, and is highly scalable due to the
use of a single optimization constraint. Alterna-
tively, our multi-constraint algorithms provide im-
proved performance for systems that can afford
only a single pass through the training data, as in
the true online setting. This result stands in con-
trast to previously observed behaviors in non-CW
settings (McDonald et al, 2004). Additionally, we
found improvements in both label entropy and ac-
curacy as compared to a maximum entropy clas-
sifier. We plan to extend these ideas to structured
problems with exponentially many labels and de-
velop methods that efficiently model label correla-
tions. An implementation of CW multi-class algo-
rithms is available upon request from the authors.
References
Blitzer, J., Dredze, M., & Pereira, F. (2007).
Biographies, bollywood, boom-boxes and
blenders: Domain adaptation for sentiment
classification. Association for Computational
Linguistics (ACL).
503
Censor, Y., & Zenios, S. (1997). Parallel opti-
mization: Theory, algorithms, and applications.
Oxford University Press, New York, NY, USA.
Chang, C.-C., & Lin, C.-J. (2001). LIBSVM: a
library for support vector machines. Software
available at http://www.csie.ntu.edu.
tw/
?
cjlin/libsvm.
Collins, M. (2002). Discriminative training meth-
ods for hidden markov models: Theory and ex-
periments with perceptron algorithms. Empir-
ical Methods in Natural Language Processing
(EMNLP).
Crammer, K., Dredze, M., & Pereira, F. (2008).
Exact confidence-weighted learning. Advances
in Neural Information Processing Systems 22.
Crammer, K., & Singer, Y. (2001). On the al-
gorithmic implementation of multiclass kernel-
based vector machines. Jornal of Machine
Learning Research, 2, 265?292.
Crammer, K., & Singer, Y. (2003). Ultraconserva-
tive online algorithms for multiclass problems.
Jornal of Machine Learning Research (JMLR),
3, 951?991.
Dredze, M., Crammer, K., & Pereira, F. (2008).
Confidence-weighted linear classification. In-
ternational Conference on Machine Learning
(ICML).
Iusem, A., & Pierro, A. D. (1987). A simultaneous
iterative method for computing projections on
polyhedra. SIAM J. Control and Optimization,
25.
Lewis, D. D., Yang, Y., Rose, T. G., & Li, F.
(2004). Rcv1: A new benchmark collection for
text categorization research. Journal of Machine
Learning Research (JMLR), 5, 361?397.
Malkin, J., & Bilmes, J. (2008). Ratio semi-
definite classifiers. IEEE Int. Conf. on Acous-
tics, Speech, and Signal Processing.
McCallum, A. (2002). MALLET: A machine
learning for language toolkit. http://
mallet.cs.umass.edu.
McDonald, R., Crammer, K., & Pereira, F. (2004).
Large margin online learning algorithms for
scalable structured classification. NIPS Work-
shop on Structured Outputs.
Sandhaus, E. (2008). The new york times an-
notated corpus. Linguistic Data Consortium,
Philadelphia.
504
 
		Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural
Language Learning, pages 710?720, Jeju Island, Korea, 12?14 July 2012. c?2012 Association for Computational Linguistics
Discovering Diverse and Salient Threads in Document Collections
Jennifer Gillenwater Alex Kulesza
Department of Computer and Information Science
University of Pennsylvania
Philadelphia, PA 19104
{jengi,kulesza,taskar}@cis.upenn.edu
Ben Taskar
Abstract
We propose a novel probabilistic technique
for modeling and extracting salient struc-
ture from large document collections. As
in clustering and topic modeling, our goal
is to provide an organizing perspective into
otherwise overwhelming amounts of infor-
mation. We are particularly interested in
revealing and exploiting relationships be-
tween documents. To this end, we focus on
extracting diverse sets of threads?singly-
linked, coherent chains of important doc-
uments. To illustrate, we extract research
threads from citation graphs and construct
timelines from news articles. Our method
is highly scalable, running on a corpus of
over 30 million words in about four minutes,
more than 75 times faster than a dynamic
topic model. Finally, the results from our
model more closely resemble human news
summaries according to several metrics and
are also preferred by human judges.
1 Introduction
The increasing availability of large document
collections has the potential to revolutionize
our ability to understand the world. However,
the scale and complexity of such collections fre-
quently make it difficult to quickly grasp the
important details and the relationships between
them. As a result, automatic interfaces for data
navigation, exploration, aggregation, and analy-
sis are becoming increasingly valuable.
In this work we propose a novel approach:
threading structured document collections. Con-
sider a large graph, with documents as nodes
and edges indicating relationships, as in Figure 1.
Our goal is to find a diverse set of paths (or
threads) through the collection that are indi-
vidually coherent and together cover the most
salient parts. For example, given a collection
of academic papers, we might want to identify
the most significant lines of research, threading
the citation graph to produce chains of impor-
tant papers. Or, given news articles connected
chronologically, we might want to extract threads
of articles to form timelines describing the ma-
jor events from the most significant news stories.
Top-tier news organizations like The New York
Times and The Guardian regularly publish such
timelines, but have so far been limited to creat-
ing them by hand. Other possibile applications
might include discovering trends on social media
sites, or perhaps mining blog entries for impor-
tant conversations through trackback links. We
show how these kinds of threading tasks can be
done efficiently, providing a simple, practical tool
for representing graph-based data that offers new
possibilities compared with existing models.
The Topic Detection and Tracking (TDT) pro-
gram (Wayne, 2000) has recently led to some
research in this direction. Several of TDT?s core
tasks, like link detection, topic detection, and
topic tracking, can be seen as subroutines for
the threading problem. Our work, however, ad-
dresses these tasks jointly, using a global prob-
abilistic model with a tractable inference algo-
rithm. To achieve this, we employ structured
determinantal point processes (SDPPs) (Kulesza
710
Figure 1: An illustration of document collection threading. We first build a graph from the collection, using
measures of importance and relatedness to weight nodes (documents) and build edges (relationships). Then,
from this graph, we extract a diverse, salient set of threads to represent the collection. The supplement
contains a version of this figure for our real-world news dataset.
and Taskar, 2010), which offer a natural prob-
abilistic model over sets of structures (such as
threads) where diversity is desired, and we incor-
porate k-DPP extensions to control the number
of threads (Kulesza and Taskar, 2011).
We apply our model to two real-world datasets,
extracting threads of research papers and time-
lines of news articles. An example of news
threads extracted using our model is shown in
Figure 2. Quantitative evaluation shows that our
model significantly outperforms multiple base-
lines, including dynamic topic models, in com-
parisons with human-produced news summaries.
It also outperforms baseline methods in a user
evaluation of thread coherence, and runs 75 times
faster than a dynamic topic model.
The primary contributions of this paper
are: (1) proposing a novel framework for finding
diverse and salient sets of document threads; (2)
combining SDPPs and k-DPPs to implement the
proposed model; (3) introducing random projec-
tions to improve efficiency with only bounded
deviation; and (4) demonstrating the model on
large-scale, real-world datasets.
2 Related Work
A variety of papers from the topic tracking liter-
ature are broadly related to our work (Mei and
Zhai, 2005; Blei and Lafferty, 2006; Leskovec et
al., 2009; Ahmed and Xing, 2010). Blei and Laf-
ferty (2006) recently introduced dynamic topic
models (DTMs). Assuming a division of doc-
uments into time slices, a DTM draws in each
slice a set of topics from a Gaussian distribution
whose mean is determined by the topics from
the previous slice. In this way, a DTM generates
topic threads. In this work we are interested in
the related but not identical task of generating
document threads. We engineer a baseline for
constructing document threads from DTM topic
threads (see Section 6.2.2), but the topic-centric
nature of DTMs means they are not ideal for
this task. Figure 2 illustrates some of the issues.
The work of Ahmed and Xing (2010) general-
izes DTMs to iDTMs (infinite DTMs) by allowing
topics to span only a subset of time slices, and
allowing an arbitrary number of topics. However,
iDTMs still require placing documents into dis-
crete epochs, and the issue of generating topic
rather than document threads remains. In Sec-
tion 6 we compare to DTMs but not iDTMs
because an implementation of iDTMs was not
readily available.
In the information retrieval community there
has also been work on extracting temporal in-
formation from document collections. Swan and
Jensen (2000) proposed a system for finding tem-
porally clustered named entities in news text and
presenting them on a timeline. Allan, Gupta,
and Khandelwal (2001) introduced the task of
temporal summarization, which takes a stream
of news articles on a particular topic and tries to
extract sentences describing important events as
they occur. Yan et al011) evaluated methods
for choosing sentences from temporally clustered
documents that are relevant to a query. Here, we
are interested not in extracting topically grouped
entities or sentences, but instead in organizing a
subset of the articles themselves into timelines,
with topic identification as a side effect.
There has also been some prior work focus-
ing more directly on threading. Shahaf and
711
Jan 08 Jan 28 Feb 17 Mar 09 Mar 29 Apr 18 May 08 May 28 Jun 17
pope vatican church parkinson 
israel palestinian iraqi israeli gaza abbas baghdad 
owen nominees senate democrats judicial filibusters 
social tax security democrats rove accounts 
iraq iraqi killed baghdad arab marines deaths forces 
Jan 08 Jan 28 Feb 17 Mar 09 Mar 29 Apr 18 May 08 May 28 Jun 17
cancer heart breast women disease aspirin risk study 
palestinian israel baghdad palestinians sunni korea gaza israeli 
social security accounts retirement benefits tax workers 401 payroll 
mets rangers dodgers delgado martinez astacio angels mientkiewicz 
hotel kitchen casa inches post shade monica closet 
Feb 24: Parkinson?s Disease Increases Risks to Pope
Feb 26: Pope?s Health Raises Questions About His Ability to Lead
Mar 13: Pope Returns Home After 18 Days at Hospital
Apr 01: Pope?s Condition Worsens as World Prepares for End of Pa-
pacy
Apr 02: Pope, Though Gravely Ill, Utters Thanks for Prayers
Apr 18: Europeans Fast Falling Away from Church
Apr 20: In Developing World, Choice [of Pope] Met with Skepticism
May 18: Pope Sends Message with Choice of Name
Jan 11: Study Backs Meat, Colon Tumor Link
Feb 07: Patients?and Many Doctors?Still Don?t Know How Often
Women Get Heart Disease
Mar 07: Aspirin Therapy Benefits Women, but Not in the Way It
Aids Men
Mar 16: Study Shows Radiation Therapy Doesn?t Increase Heart Dis-
ease Risk for Breast Cancer Patients
Apr 11: Personal Health: Women Struggle for Parity of the Heart
May 16: Black Women More Likely to Die from Breast Cancer
May 24: Studies Bolster Diet, Exercise for Breast Cancer Patients
Jun 21: Another Reason Fish is Good for You
Figure 2: A set of five news threads generated by our method (left) and a dynamic topic model (right) for
the first half of 2005. Above, the threads are shown on a timeline with the most salient words superimposed;
below, the dates and headlines from the threads appearing at the bottom are listed. Topic models are not
designed for threading and often link together topically similar documents that do not constitute a coherent
news story, as on the right.
Guestrin (2010) and Chieu and Lee (2004) pro-
posed selecting a single thread, whereas we seek
a set of threads, which is a more general task.
Shahaf, Guestrin, and Horvitz (2012) recently
proposed metro maps as alternative structured
representations of related news stories. Metro
maps are effectively sets of non-chronological
threads that are encouraged to intersect and thus
create a ?map? of events and topics. However,
these approaches assume some prior knowledge
about content. Shahaf and Guestrin (2010), for
example, assume the thread endpoints are spec-
ified, and Chieu and Lee (2004) require a set
of query words. These inputs make it possible
to quickly pare down the document graph. In
constrast, we work with very large graphs and
consider all possible threads. Furthermore, while
some prior work has relied on heuristics and ap-
proximate optimization, we can efficiently sample
a joint probabilistic model with approximation
guarantees.
In previous work on SDPPs (structured DPPs),
which we use here to model threads, Kulesza and
Taskar (2010) derived exact polynomial-time al-
gorithms for sampling and other inference. How-
ever, their experiments involved feature vectors
of only 32 dimensions. For text, natural features
like word occurrences typically yield dimension-
ality in the tens of thousands, making SDPP
inference prohibitively expensive. We solve this
problem by reducing the feature space using ran-
dom projections (see Section 5). We prove that
even a logarithmic number of projections is suffi-
cient to yield a close approximation to the origi-
nal SDPP distribution.
3 Framework
Before presenting our probabilistic model, we
describe a natural framework for representing
document collections. We assume that the collec-
tion has been transformed into a directed graph
G = (V,E) on n vertices, where each node cor-
responds to a document and each edge repre-
sents a relationship between documents whose
semantics depend on the task. We also as-
sume the existence of a weight function w on
nodes and edges, which measures the impor-
tance or salience of documents and the relative
strength of the relationships between them. For-
mally, we define the weight of a path (or thread)
y = (y(1), y(2), . . . , y(T )), (y(t), y(t+1)) ? E by:
w(y) =
T?
t=1
w
(
y(t)
)
+
T?1?
t=1
w
(
y(t), y(t+1)
)
. (1)
712
Lastly, we also assume the existence of node
features. Specifically, let ? represent a feature
mapping from nodes to RD (for example, tf-idf
word vectors). The feature map on a thread is
then just a sum over the nodes in the thread:
?(y) =
T?
t=1
?
(
y(t)
)
. (2)
(If it is convenient to have features on edges as
well as on nodes, it is possible to accommodate
them without affecting asymptotic performance.)
Given this framework, our goal is to develop
a probabilistic model over sets of k threads of
length T , favoring sets whose threads have large
weight but are also distinct from one another with
respect to ?. In other words, a high-probability
set under the model should include threads that
are both salient and diverse.
This is a daunting problem, given that the
number of possible sets of threads is O(nkT ).
For the datasets we use later, the actual number
is around 21000. However, we will show how to
construct the desired model in a way that allows
efficient inference, even for large datasets, using
determinantal point processes (DPPs). We begin
with some background.
4 Determinantal point processes
A DPP is a type of distribution over subsets.
Formally, a DPP P on a set of items Y =
{y1, . . . , yN} is a probability measure on 2Y , the
set of all subsets of Y . (In our setting, Y will be
the set of all possible threads.) For every Y ? Y
we have:
P(Y ) =
det(LY )
?
Y?Y
det(LY )
=
det(LY )
det(L+ I)
, (3)
where L is a positive semidefinite matrix and I
is the N ?N identity matrix. LY ? [Lij ]yiyj?Y
denotes the restriction of L to the entries indexed
by elements of Y , and det(L?) = 1. We can
define the entries of L as follows:
Lij = q(yi)?(yi)
>?(yj)q(yj) , (4)
where we can think of q(yi) ? R+ as the ?qual-
ity? of an item yi, and ?(yi) ? RD, ??(yi)?2 = 1
Figure 3: (a) The DPP probability of a set Y depends
on the volume spanned by vectors q(yi)?(yi) for i ? Y .
(b) As quality (length) increases, so does volume. (c)
As similarity increases, volume decreases.
as a normalized D-dimensional feature vector
such that ?(yi)>?(yj) ? [?1, 1] is a measure of
similarity between items yi and yj . This simple
definition gives rise to a distribution that places
most of its weight on sets that are both high qual-
ity and diverse. To understand why this is the
case, note that determinants are closely related
to volumes; in particular, det(LY ) is proportional
to the volume spanned by the vectors q(yi)?(yi)
for yi ? Y . Thus, sets with high-quality, diverse
items have the highest probability; see Figure 3
for an illustration.
4.1 Structured DPPs
Kulesza and Taskar (2010) introduced structured
DPPs (SDPPs) to efficiently handle Y containing
exponentially many structures. In our setting, Y
contains all threads of length T , so each yi ? Y is
a sequence (y(1)i , . . . , y
(T )
i ), where y
(t)
i is the docu-
ment included in the thread at position t. When
G is a complete graph, there are nT possible
sequences, so |Y| = N = nT .
In order to allow for efficient normalization
and sampling, SDPPs assume a factorization
of the quality score q(yi) and similarity score
?(yi)>?(yj) into parts, decomposing quality mul-
tiplicatively and similarity additively:
q(yi) =
T?
t=1
q
(
y(t)i
)
?(yi) =
T?
t=1
?
(
y(t)i
)
(5)
For threading, the definition of ? is just as given
in Equation (2). However, in order to convert the
weight function defined in Equation (1) to the
713
appropriate multiplicative form, we use a sim-
ple log-linear model, setting q(yi) = exp(?w(yi)),
where ? is a hyperparameter that effectively gov-
erns the balance between quality and diversity
by adjusting the dynamic range of the quality
function.
An efficient algorithm for sampling structures
(in this case, sets of threads) from an SDPP is
derived in Kulesza and Taskar (2010). While
the details are beyond the scope of this paper,
we note that the sampling algorithm requires
O(Tn2D2) time. If the node degrees are bounded
by r then the time is reduced to O(TrnD2). This
is not quite efficient enough when the number
of features, D, is large, as it often is for textual
tasks, but we will show in Section 5 how to
overcome this last hurdle.
Note that, in our later experiments, we fix T
to moderate values (T = 5, 8) for ease of analysis
and display. However, it is possible (and effi-
cient, due to the linear scaling) to allow longer
threads, as well as threads of variable length.
The latter effect can be achieved by adding a sin-
gle ?dummy? node to the document graph, with
incoming edges from all other documents and a
single outgoing self-loop edge. Shorter threads
will simply transition to this dummy node when
they are complete.
4.2 k-DPPs
SDPPs allow us to efficiently model all sets of
threads; however, for practical reasons we would
prefer to focus only on sets of exactly k threads.
To do so we exploit recently developed methods
for working with DPPs of fixed size (Kulesza
and Taskar, 2011). A k-DPP Pk is a DPP con-
ditioned on the event that the subset Y ? Y has
cardinality k; formally, whenever |Y | = k:
Pk(Y ) =
det(LY )
?
|Y ?|=k det(LY ?)
. (6)
In this work we combine k-DPPs with SDPPs,
referring to the result as a k-SDPP. We note that
using k-SDPPs instead of SDPPs does not affect
efficiency of sampling; it merely affords a mecha-
nism for controlling the number of threads.
5 Random projections
As described above, the time complexity for sam-
pling sets from SDPPs is O(TrnD2). Although
this is polynomial, for practical problems nD2
is prohibitively large. While previous work has
dealt only with small datasets, in our experi-
ments we typically have n,D > 30,000; storing
a single message for the message-passing routine
involved in SDPP sampling would require over
200 terabytes of memory. To make the model
practical, therefore, we turn to techniques for
dimensionality reduction.
Standard PCA requires O(D3) time and would
be much too slow. But a classic result of John-
son and Lindenstrauss (1984) shows that high-
dimensional points can be randomly projected
onto a logarithmic number of dimensions while
approximately preserving the distances between
them. More recently, Magen and Zouzias (2008)
extended this idea to the preservation of volumes
spanned by sets of points. Here, we use a rela-
tionship between determinants and volumes to
adapt the latter result. We will prove the follow-
ing bound on the variational distance between
the original k-SDPP and a randomly projected
version.
Theorem 1. Fix , ? < 1/2, and set d =
max
{
2k

,
24
2
(
log(3/?)
logN
+ 1
)
log 2N + k ? 1
}
.
(7)
Let Pk be the k-SDPP distribution in Equa-
tion (6), let G be a d ? D random matrix
whose entries are independently sampled from
N (0, 1/d), and let P?k(Y ) be the k-SDPP distri-
bution after projecting ? by G?that is, replacing
? with G?. Then with probability at least 1? ?,
?Pk?P?k?1 =
?
|Y |=k
|Pk(Y )?P?k(Y )| ? e6k?1 .
(8)
Note that e6k ? 1 ? 6k when k is small, and
d = O(max{k/, (log(1/?) + T log n)/2}).
Practically, Theorem 1 says that if we project
? down to dimension d logarithmic in the number
of documents and linear in thread length, the L1
variational distance between the true model and
the projected model is bounded.
714
To prove Theorem 1, we will first state a vari-
ant of Magen and Zouzias? result, which bounds
the ratio of volumes before and after projection
from D down to d dimensions.
Lemma 1. Let X be a D?N matrix. Fix k < N
and , ? < 1/2, and set d and G as in Theorem 1.
Then with probability at least 1? ? we have, for
all D ? k matrices Y formed by a subset of k
columns from X:
(1? )k ?
Vol(GY )
Vol(Y )
? (1 + )k ,
where Vol(Y ) is the k-dimensional volume
spanned by the columns of Y and the origin.
We can make use of the following fact to con-
vert this bound on volumes to a bound on deter-
minants:
Vol(Y ) =
1
k!
?
det(Y >Y ) . (9)
In order to handle the k-SDPP normalization
constant
?
|Y |=k
?
?
?
yi?Y
q2(yi)
?
?det(?(Y )>?(Y )) , (10)
we also must adapt Lemma 1 to sums of deter-
minants. The following lemma gives the details.
Lemma 2. Under the same conditions as
Lemma 1, with probability at least 1? ?,
(1+2)?2k ?
?
|Y |=k det((GY )
>(GY ))
?
|Y |=k det(Y
>Y )
? (1+)2k .
Proof.
?
|Y |=k
det((GY )>(GY ))
=
?
|Y |=k
(k!Vol(GY ))2
?
?
|Y |=k
(
k!Vol(Y )(1? )k
)2
? (1 + 2)?2k
?
|Y |=k
det(Y >Y ) ,
0 50 100 1500
0.2
0.4
0.6
0.8
1
1.2
L1 
var
iati
ona
l di
sta
nce
Projection dimension
0
1
2
3
4x 10
8
Me
mo
ry u
se 
(byt
es)
Figure 4: The effect of random projections. In black,
on the left, we estimate the L1 variational distance
between the true and projected models. In blue, on
the right, we plot the memory required for sampling.
Running time is proportional to memory use.
where the first inequality holds with probability
at least 1?? by Lemma 1, and the second follows
from the fact that (1? )(1 + 2) ? 1 (since  <
1/2), thus (1? )2k ? (1 + 2)?2k. A symmetric
argument gives the upper bound.
Proof (of Theorem 1). Let B be the matrix
whose columns are given by Bi = q(yi)?(yi).
We have
?Pk ? P?k?1 =
?
|Y |=k
|Pk(Y )? P?k(Y )|
=
?
|Y |=k
Pk(Y )
?
?
?
?
?
1?
P?k(Y )
Pk(Y )
?
?
?
?
?
=
?
|Y |=k
Pk(Y )
?
?
?
?1?
det([GB>Y ][GBY ])
det(B>Y BY )
?
?
|Y ?|=k det(B
>
Y ?BY ?)
?
|Y ?|=k det([GB
>
Y ? ][GBY ? ])
?
?
?
?
?
?
?
?
?1? (1 + )2k(1 + 2)2k
?
?
?
?
|Y |=k
Pk(Y )
? e6k ? 1 ,
where the first inequality follows from Lemma 1
and Lemma 2, which hold simultaneously with
probability at least 1? ?, and the second follows
from (1 + a)b ? eab for a, b ? 0.
715
delay interconnectwiresizing elmore-basedrouting tree
mobile clients hoard server client database
policy decisionmarkov pomdpspartially uncertainty
learning lifelong training tasks invariances control learning lifelong training tasks invariances control
? Locally Weighted Learning for Control
? Discovering Structure in Multiple Learning Tasks: The TC Al-
gorithm
? Learning One More Thing
? Explanation Based Learning for Mobile Robot Perception
? Learning Analytically and Inductively
mobile clients hoard server client database
? A Database Architecture for Handling Mobile Clients
? An Architecture for Mobile Databases
? Database Server Organization for Handling Mobile Clients
? Mobile Wireless Computing: Solutions and Challenges in Data
Management
? Energy Efficient Query Optimization
Figure 5: Example threads sampled from a 4-SDPP with thread length T = 5 on the Cora dataset. We
project from word-space to two dimensions by running PCA on the centroids of the threads. The nodes not
on the thread paths form a representative subset of the other documents from Cora. Displayed beside each
thread are a few of its maximum-tfidf words. Paper titles from two of the threads are shown to the right.
6 Experiments
We begin by showing the performance of random
projections on a small, synthetic threading task
where the exact model is tractable, with n = 600
and D = 150. Figure 4 shows the L1 variational
distance (estimated by sampling) as well as the
actual memory required for a variety of projec-
tion dimensions d. Note that, as predicted by
Theorem 1, fidelity to the true model increases
rapidly with d.
6.1 Cora citation graph
To qualitatively illustrate our model, we apply
it to Cora (McCallum et al2000). Cora is a
large collection of academic papers on computer
science topics, plus citations between them. We
construct a directed graph with papers as nodes
and citations as edges; after removing papers
with missing metadata or zero outgoing citations,
our graph contains n = 28,155 papers.
To obtain useful threads, we set edge weights
to reflect the degree of textual similarity between
the citing and cited papers, and set node weights
to reflect paper ?importance?. Edge weights
are given by normalized cosine similarity (NCS),
which for two documents i and j is the dot prod-
uct of their normalized tfidf vectors:
?
w?W tfidfi(w)tfidfj(w)??
w?W tfidfi(w)
2
??
w?W tfidfj(w)
2
,
where W is a subset of the words found in the
documents. We select W by filtering according
to document frequency; that is, we remove words
that are too common or too rare. After filtering,
there are 50,912 unique words. The node weights
are given by LexRank scores (Erkan and Radev,
2004), which are similar to node degrees.
Finally, we build a similarity feature map ? to
encourage diversity. We represent each document
by the 1000 documents to which it is most similar
according to NCS; this results in binary ? of
dimension m = n with exactly 1000 non-zeros.
The dot product between the similarity features
of two documents is thus proportional to the
fraction of top-1000 similar documents they have
in common. As described in Section 5, we then
randomly project this large feature set from D ?
28,000 to d = 50 dimensions.
We illustrate the behavior of the resulting
model in Figure 5. The discovered threads oc-
cupy distinct regions of word-space, standing
apart visually, and contain diverse salient terms.
6.2 News articles
For quantitative evaluation, we use newswire
data. Our dataset comprises over 200,000 arti-
cles from the New York Times, collected from
2005-2007 as part of the English Gigaword cor-
pus (Graff and Cieri, 2009). We split the articles
into six-month time periods, with an average of
716
n = 34,504 articles per period. After filtering,
there are a total of 36,356 unique words.
For each time period, we generate a graph with
articles as nodes. We use NCS for edge weights,
and throw away edges with weight < 0.1. We
also require that edges go forward in time; this
enforces the chronological ordering of our threads.
The supplement contains illustrations of one of
the resulting graphs. We use LexRank for node
weights and the top-1000 similar documents as
similarity features ?, projecting to d = 50, as
before (Section 6.1). We also add a constant fea-
ture ? to ?, which controls the overall degree of
repulsion; large values of ? make all documents
more similar. This makes the k-SDPP distri-
bution more peaked around diverse sets. For
all of the following results, we use T = 8 and
k = 10 so that the resulting timelines are of a
manageable size for analysis. However, we tried
several values of k and T in our experiments, and
did not see significant differences in relative per-
formance. We report all metrics averaged over
100 random samples from the model for each
six-month period.
6.2.1 Graph visualizations
The (very large) news graph for the first
half of 2005 can be viewed interactively at
http://zoom.it/jOKV. In this graph each node
(dark circle) represents a news article, and is an-
notated with its headline. Node size corresponds
to weight (LexRank score). Nodes are laid out
chronologically, left-to-right, from January to
June of 2005. The five colored paths indicate a
set of threads sampled from the k-SDPP. Head-
lines of the articles in each thread are colored
to match the thread. Edges are included as de-
scribed in the paper, but due to the scale of this
dataset, only 1% of the edges are shown. Edge
thickness corresponds to weight (NCS).
We provide a view of a small subgraph for
illustration purposes in Figure 6, which shows
the incoming and outgoing edges for a single
node. A zoomable version of this subgraph is
available at http://zoom.it/GUCR.
STUDY ANALYZES DATA ON ILLEGAL IMMIGRANTS
WELCOME TO 'TEH-JAS,' LAND OF THE ALAMO AND COWBOYFOR IMMIGRANTS, SUCCESS OFTEN STARTS WITH BIZARRE STREET SIGNSDOMINICANS TAKE THEIR PLACE AS AN AMERICAN SUCCESS STORY
MEXICAN MANUAL ON ILLEGAL IMMIGRATION DRAWS FIRECALIFORNIA REPUBLICAN COUNTERS BUSH IMMIGRATION PLANHOUSE BILL TARGETS FAKE SOCIAL SECURITY CARDS; PROPOSAL CALLS FOR DIGITAL PHOTO, ELECTRONIC STRIPGARCIA SEEKS MAJOR FOR HIS RESUMEVIDEOCONFERENCES LINK IMMIGRANTS AND LOVED ONESBORDER CROSSING: A GUIDE FOR THE ILLEGAL MIGRANTPOLITICIANS' DREAM WOULD BECOME A NIGHTMARE FOR COPSNEW SOCIAL SECURITY CARD COULD THWART ILLEGAL IMMIGRANTSAS HISPANICS EMBRACE LIFE IN U.S., SOME PREFER TO LIMIT FAMILY SIZETEXAS CONGRESSMAN CORNYN TO LEAD IMMIGRATION PANEL; SENATOR'S BILL, REFLECTIVE OF WHITE HOUSE REFORM GOALS, MEETS OPPOSITIONFIGHTING FOR U.S., AND FOR GREEN CARDSBUSH VOWS TO PUSH IMMIGRATION PLAN THROUGH THIS TIMEON SCREEN, TACKLING EUROPE'S NEW REALITYBUSH AGENDA FACES SOME GOP RESISTANCE
EDITORIAL: THE PRESIDENT'S SHOELACESPROBLEMS WITH SPEAKING ENGLISH MULTIPLY IN A DECADEGUEST WORKER PLAN DIVIDES LAWMAKERS PRESIDENT SUPPORTS IDEA TO HELP ILLEGAL ALIENS TOILING IN U.S.ALLEGED LEADER IN HUMAN-SMUGGLING DEATHS WANTS TO WITHDRAW GUILTY PLEAJURY SELECTION TO BEGIN TUESDAY IN HUMAN-SMUGGLING TRIAL OF ACCUSED TRUCKER IN DEATHS OF 19 ILLEGAL IMMIGRANTSNEW MIGRANT LAW IRKS MEXICOHELPING EDUCATORS THROW OUT OLD RULES AND TAKE A FEW RISKSRECORD IMMIGRATION CHANGING NEW YORK'S NEIGHBORHOODSATTORNEYS SAY TESTIMONY WILL SHOW OFFICIALS LET TRUCK PASS WITH ILLEGAL IMMIGRANTSFEINSTEIN BILL WOULD PROTECT FOREIGN KIDS IN U.S. CUSTODY SENATE BILL WOULD PROTECT FOREIGN CHILDREN IN U.S. CUSTODYIMMIGRATION BOOM COOLINGREPUBLICANS SQUARING OFF OVER BUSH PLAN ON IMMIGRATIONSMUGGLING-DEFENDANT-HNSBUSH VOWS COOPERATION ON IMMIGRATION REFORM; DIFFERENCES OVER SCOPE, AGENDA MAY STALL PLAN
JUDGE SAYS GUILTY PLEA IN DEADLY TEXAS SMUGGLING MUST STANDHOUSING, IMMIGRATION CALLED KEYS TO THE FUTUREPRESIDENT REIGNITES EMOTIONAL DEBATE OVER IMMIGRATION POLICYGUEST WORKER PLAN WILL BE TOUGH SELL FOR BUSHMEXICAN POLITICIANS FIND BENEFITS IN U.S. CAMPAIGNSSEN. CORNYN FOCUESES IN IMMIGRATIONTANCREDO WEIGHS PRESIDENTIAL RUN WITH PILGRIMAGE TO N.H.BRITAIN, SPAIN, BOTH IN EU, ANNOUNCE DIVERGENT IMMIGRATION POLICIESSPAIN LETS ILLEGAL IMMIGRANTS SEEK RESIDENCYIMMIGRANT-LICENSES-HNSBUSH BACKS DRIVER'S LICENSE BANDEPORTED FROM MEXICO, 3 MORE IN ALLEGED SMUGGLING RING MAY FACE CAPITAL PUNISHMENT IN DEATHS OF 19 IMMIGRANTSHOUSE APPROVES TOUGHER IMMIGRATION BILLTAKING HARD LINE ON ILLEGAL IMMIGRANTS: HOUSE PASSES BILL TO MAKE IT TOUGHER TO GET ASYLUM OR DRIVER'S LICENSES
HOUSE PASSES TIGHTENING OF LAWS ON IMMIGRATIONHOUSE OKS BAN ON LICENSES FOR ILLEGAL IMMIGRANTSMEXICANS HELP TRANSFORM HOMES THEY LEFTANDY GARCIA NEARS END OF HIS QUEST: A FILM ON CUBAMEXICO HAS JOBS PLAN FOR CITIZENS DEPORTED FROM U.S.REPORT LINKS SOCIAL SECURITY FINANCES IN PART TO LEVELS OF IMMIGRATIONIN DEPORTATIONS OF PARENTS, FATE OF CHILDREN IS OFTEN AN AFTERTHOUGHTJUDGE BLOCKS NEW YORK DENIAL OF IMMIGRANT DRIVER LICENSESIMMIGRANT VOTERS DEFY POLITICAL PATTERNSKC-AFGHAN-NEWSPOLICY SHIFT IN GERMANY TRIMS JEWISH MIGRATIONIN JOB MARKET, SOME WIN, SOME LOSEHUNDREDS GET AID AT VALLEY SHELTERSPOLITICAL PRESSURE MOUNTING TO BOOST BORDER PATROL AGENTS ALONG BORDER
P1 A23 MEXICO-HNSMEXICO-VOTE-HNSBILL TO LET MEXICAN MIGRANTS VOTE HITS ROADBLOCKSMORE DUTCH PLAN TO EMIGRATE AS MUSLIM INFLUX TIPS SCALESGONZALES LAYS OUT HIS PRIORITIES AT JUSTICE DEPT.MOST UNDOCUMENTED IMMIGRANTS RECEPTIVE TO GUEST WORKER PROGRAMSURVEY: MOST MEXICAN IMMIGRANTS WOULD USE GUEST WORKER PROGRAMSURVEY: MOST UNDOCUMENTED ALIENS SUPPORT GUEST WORKER PLANNEW STUDY PAINTS CLEARER PICTURE OF MEXICANS IN NEW YORK CITYIMMIGRATION CHANGES COULD CUT BACK ASYLUM SEEKERSTEXAS TO HOST U.S.-MEXICO-CANDADA SUMMITYOUNG BULLDOGS LEARN HARD WAYTRIAL STARTS IN NATION'S DEADLIEST HUMAN SMUGGLING CASERICE SAYS AL-QAIDA FOCUSED ON BREACHING U.S. BORDERS, ANNOUNCES WATER AGREEMENT WITH MEXICOBORDER-PATROL-HNS
RICE SEEKS THAW IN MEXICO-U.S. RELATIONSCASE FOCUSES ON DEFINITION OF TORTURE FOR DEPORTEESFIRST THEY WERE SOLDIERS -- NOW THEY'RE CITIZENS; IMMIGRANTS WHO FOUGHT FOR U.S. ARE NATURALIZED, GREETED BY BUSH SR.ADVANCE FOR SUNDAY, MARCH 13 IMMIGRANTS MAY GET TO VOTE HERE IN MEXICO'S 2006 ELECTIONDESPITE NEW EFFORTS ALONG ARIZONA BORDER, 'SERIOUS PROBLEMS' REMAINMYTH CITED REPEATEDLY IN IMMIGRATION DEBATESWEEP NETS 103 SUSPECTS OF MS-13 GANG IN SEVEN CITIESFEDS SAY SWEEP NETS 100 MEMBERS OF IMMIGRANT GANGU.S.-MEXICO BORDER STILL TOO POROUS, OFFICIALS SAYALLEGED OBSCENE GESTURE DELAYS IMMIGRANT SMUGGLING TRIAL; DEATH PENALTY PROTESTERS CLAIM JUROR HAS ALREADY MADE UP HIS MINDFOX REFUTES U.S. CLAIMS ON AL-QAIDA, VOWS LEGAL ACTION TO HALT VIGILANTESFOX TO PUSH IMMIGRATION, SECURITY, TRADE ISSUES DURING MEETING WITH BUSH, CANADA'S PRIME MINISTERTESTIMONY IN TRUCK DRIVER'S IMMIGRANT SMUGGLING CASE HALTED AFTER PROSECUTION RESTS; JUDGE QUESTIONS HARBORING CHARGES57 BRAZILIANS HELD AFTER BRIBE IS ALLEGED
WAL-MART TO PAY $11 MILLION IN ILLEGAL IMMIGRANT CASEWAL-MART SETTLES ILLEGAL IMMIGRANT CASE FOR $11 MILLIONGARCIA WANTS TO BE PART OF THE CONVERSATIONEDITORIAL OBSERVER: ENLIGHTENED IMMIGRATIONEDITORIAL: OUR TERRORIST-FRIENDLY BORDERS
10.3 MILLION FROM MEXICO IN U.S. ILLEGALLY, RESEARCHER ON LATINOS SAYSBUSH FOCUSES ON BORDER ISSUES WITH MEXICO, CANADALANGUAGE PLAYS A LOUD VOICE IN DEBATE ABOUT IMMIGRATION REFORMU.S. BEGINS TO SEE NATIONAL SECURITY GAP IN MEXICAN SMUGGLINGMEXICANS VOTING IN U.S. COULD ALTER POLITICSTEXAS ADVOCATES FOR IMMIGRATION REFORMS JOIN OTHERS AROUND NATION IN RALLIES URGING BUSH, FOX TO ACT QUICKLYSECURITY, TRADE TO BE PRIMARY FOCUS OF BUSH-FOX-MARTIN SUMMITNORTH AMERICAN LEADERS MAKE BORDERS AND TRADE A PRIORITYBUSH TELLS MEXICAN LEADER HE'LL CONTINUE TO SEEK IMMIGRATION LAW CHANGESBUSH TELLS MEXICAN LEADER HE'LL SEEK IMMIGRATION LAW CHANGESLEAVING A YEAR EARLY, BUT A YEAR TOO LATEBUSH SUMMIT VOWS CLOSER TIES, BETTER TIMES AHEADU.S. SIGNS TRADE, SECURITY DEAL WITH MEXICO, CANADA; BUSH PUSHES FOR IMPROVED TIES WITH SOUTH AMERICAKEEPING IMMIGRATION LEGAL
DUKE BLOCKS GEORGIA'S ROAD TO INDYTHAT BURGER-FLIPPER IS NO KID ANYMOREMOTHERS IMMIGRATING TO BECOME BREADWINNERSLAST OF THREE PARTS; WITH PHOTOS, GRAPHIC CANADA'S OPEN BORDER BOON TO HUMAN TRAFFICKERSBEST, BRIGHTEST MUST CHOOSE BETWEEN MENIAL JOBS IN U.S., ROCKY FUTURE AT HOMEU.S. TO REINFORCE POROUS ARIZONA BORDERREPORT URGES CUTS IN CARE FOR ILLEGAL IMMIGRANTSDNA HELPS IDENTIFIES MEXICAN MIGRANTS IN PAUPERS' GRAVESCIVILIAN PATROL TO RAISE BORDER CONCERNSFALLEN BROTHER INSPIRATION FOR GARCIAARMED VOLUNTEERS WAIT ALONG ARIZONA BORDER TO STOP ILLEGAL IMMIGRANTSKC-5LOUVILLE1,WANTED: BORDER HOPPERS. AND SOME EXCITEMENT, TOO.VOLUNTEERS SET TO PATROL ARIZ. BORDER
IMMIGRATION FOES BEGIN ARIZONA BORDER WATCHHOW SOCIAL SECURITY BALANCES BOOKS ON BACKS OF IMMIGRANTSCITIZEN PATROL SPREADS FEAR, RESOLVE AT US-MEXICO BORDERCITIZEN PATROL SPREADS FEAR, RESOLVE AT BORDERFEW VOLUNTEERS FOR BORDER PROJECTWHITE POWER GROUPS TRY NEW TACTICS AND TOOLSPOLICE SAY IMMIGRANT POLICY IS A HINDRANCEBATTLE OVER LICENSES FOR IMMIGRANTS BACK IN COURTTHE INVISIBLE DELIVERYMANGIRL CALLED WOULD-BE BOMBER WAS DRAWN TO ISLAMRAID NETS 53 ILLEGAL IMMIGRANTS IN SOUTHWEST HOUSTON HOMEBUSINESSES MAKING A PUSH FOR GUEST WORKER PLAN MOVING IN WASHINGTON AND FINANCIAL CATEGORIES FOR RELEASE SUNDAY, APRIL 10.OUTRAGE AT ARREST OF GIRL, 16, AS TERRORIST THREATADVANCE FOR USE SUNDAY, APRIL 10, AND THEREAFTER. "MINUTEMEN" SEE LITTLE ACTION ALONG BORDER
COMMENTARY: AILING HEALTH CARELOCAL BRAZILIANS SAY THEY'RE TARGETED UNFAIRLYEDITORIAL: A WEST TOO WILDSIERRA CLUB ASKS MEMBER VOTE ON IMMIGRATION LIMITSSIERRA CLUB SPLIT AGAIN ON IMMIGRATION STANCEFRIST OPPOSES AMENDMENTS ON IMMIGRANTSBORDER RESIDENTS SAY 'MINUTEMAN' PATROLS HIGHLIGHT A CRISISIMMIGRATION MEASURE HITS SENATE ROADBLOCKHOTEL FIRE SHEDS LIGHT ON FRANCE'S ILLEGAL IMMIGRANTSDEEPLY SPLIT SENATE REJECTS GUEST FARMWORKER BILLSENATE CLEARS WAY FOR VOTE ON SPENDING FOR MILITARYSENATE APPROVES $81.26 BILLION IN A MILITARY EMERGENCY BILLIMMIGRATION CONTROL ADVOCATES DESCEND ON CAPITOL HILLPOLICE REPORT NONCITIZENS TO U.S., OFFICIAL SAYSBRITISH ELECTION DEBATE SPOTLIGHTS CONCERN ABOUT IMMIGRATIONTOP DOGS! GYM DOGS TAKE TITLE
ILLEGAL IMMIGRATION FOES DEMANDING ACTIONSIERRA CLUB STANDS PAT ON IMMIGRATION POLICYKOSOVAR FEARS ID PROPOSAL WILL JEOPARDIZE SAFE LIFE IN U.S.A MISTAKEN ID LAW (FOR USETRAFFICKING LEADS LATINO SUMMIT AGENDAIMMIGRATION-SCAM-HNSLATINO KIDS LAG IN HEALTH COVERAGELAWMAKERS TO DECIDE FATE OF DRIVER'S LICENSE IMMIGRATION BILLWHITE HOUSE BACKS LEGISLATION THAT WOULD TOUGHEN IMMIGRATION RULESIN RARE ACCORD, SPURNED ASYLUM SEEKER TO GET $87,500COMMENTARY: A PRIVATE OBSESSIONEX-VALLEY MAN IN VANGUARD OF MINUTEMAN PROJECTSCHWARZENEGGER ENDORSES ARMED VOLUNTEERS ON BORDERGOVERNOR SIGNALS HE'D WELCOME MINUTEMEN ON CALIFORNIA BORDER
VALLEY HOSPITAL BOOM UNDER WAYACTIVISTS, OPPONENTS CLASH AT IMMIGRATION RALLYMEXICAN SENATOR WANTS TO BLOCK WOULD-BE ILLEGAL IMMIGRANTS FROM ENTERING U.S.MAYANS HERE TRY TO SAVE OLD WAYSSTATE OFFICIALS WARY OF NEW DRIVER'S LICENSE REQUIREMENTSEDITORIAL: AN UNREALISTIC 'REAL ID'ROUTINE LICENSE CHECK CAN MEAN JAIL AND DEPORTATIONHOUSE PASSES EMERGENCY SPENDING BILLBILL WOULD PROTECT ILLEGAL IMMIGRANT DRIVERS' CARS FROM IMPOUNDHOUSE OKS $82 BILLION MORE FOR WARS
IMMIGRANTS IN TENNESSEE ISSUED CERTIFICATES TO DRIVE ARIEL HART CONTRIBUTED REPORTING FOR THIS ARTICLE FROM ATLANTA.
PAYMENTS TO HELP HOSPITALS CARE FOR ILLEGAL IMMIGRANTSIMMIGRANTS' PLIGHT BECOMES A RALLYING CRY AMONG LATINO, U.S. MUSICIANSCATHOLIC GROUPS LAUNCH IMMIGRATION REFORM CAMPAIGNBORDER STATES COMPLAIN THAT U.S. ISN'T FOOTING THE BILL FOR JAILING ILLEGAL IMMIGRANTSNATIONAL CHILDREN'S STUDY STARVING FOR FUNDS, BACKERS SAYSENATE APPROVES MONEY FOR IRAQ WAR; RESTRICTS DRIVER'S LICENSES FOR ILLEGAL IMMIGRANTSIMMIGRANTS ENCOURAGED TO RIDE BUSIMMIGRATION-CRACKDOWN-HNSSENATE UNANIMOUSLY OKS WAR FUNDING AND DRIVERS LICENSE RESTRICTIONS FOR IMMIGRANTSDENIAL OF DRIVER'S LICENSES TO MANY IMMIGRANTS VOIDED IN NEW YORKMINUTEMEN-IMMIGRANTS-HNSMAJOR IMMIGRATION REFORM MEASURE TO BE INTRODUCEDGARCIA MAY HAVE CRASHED, BUT HE'S NOT BURNED UPBILL WOULD ALLOW ILLEGAL IMMIGRANTS TO BECOME LEGAL TEMPORARY WORKERS
MCCAIN, KENNEDY BILL WOULD PUT MILLIONS OF ILLEGALS ON PATH TO GREEN CARDKENNEDY, MCCAIN BILL ADDRESSES IMMIGRANTSIMMIGRATION-REFORM-HNSIMMIGRANT LABOR BILL CREATES 3-YEAR VISAS FOR GUEST WORKERSU.S. OFFICIALS, AFRICAN AMERICAN LEADERS SEEK APOLOGY OVER MEXICAN PRESIDENT'S REMARKSSMUGGLING OF IMMIGRANTS IS DETAILED AS TRIAL STARTSFOX MEETS JACKSON SEEKING TO EASE UPROAR OVER REMARKSEDITORIAL: MAJOR IMMIGRATION SURGERYN.H. POLICE CHIEF'S TACTICS STIR A STORM ON IMMIGRATIONNH-IMMIGRATION-ART-BOSPOST-9/11 PROGRAM MAY END FAMILY'S AMERICAN DREAMSTRESSFUL LIVES BURDEN REFUGEESECUADORANS LEAD DANBURY IMMIGRATION PROTEST RALLYEARLY HEAT WAVE KILLS 12 ILLEGAL IMMIGRANTS IN THE ARIZONA DESERT
FEDERAL RESERVE PROGRAM GIVES BANKS A SHOT AT TRANSFERS TO MEXICOBILL WOULD FORCE SAVINGS ON MEDICAID SPENDINGBILL BY GOP SENATORS INCREASES BORDER GUARDS; NEW SECURITY IS PART OF AN OVERALL IMMIGRATION PLANA BATTLE AGAINST ILLEGAL WORKERS, WITH AN UNLIKELY DRIVING FORCEPOLICE ACROSS U.S. DON'T CHECK IMMIGRANT STATUS DURING STOPSBOOK REVIEW: EXPLORING IMMIGRANT SMUGGLING TRAGEDYIMMIGRATION MAY BE MAJOR ISSUE IN 2008 ELECTION EUNICE MOSCOSOBULLDOGS SET PACE IN NCAASTEXAN PLANS TO BRING MINUTEMEN PATROLS TO MEXICAN BORDERGEORGIA TO BATTLE JACKETS FOR TITLESOME SKILLED FOREIGNERS FIND JOBS SCARCE IN CANADAAT VATICAN'S DOORSTEP, A CONTEST FOR IMMIGRANT SOULSBABY SURVIVES AGAINST ALL ODDSIDENTITY CRISIS: SOCIAL SECURITY NUMBERS FOR RENT
NATION PONDERS IMMIGRANT WORKER PARADOXWEB CLASSES FROM MEXICO HELP MIGRANTSNUMBER OF NON-MEXICAN ALIENS CROSSING SOUTHERN BORDER SKYROCKETINGIMMIGRATION OFFICIALS SEEK EXPANSION OF PROGRAM THAT ALLOWS BORDER AGENTS TO QUICKLY DEPORT ILLEGAL IMMIGRANTSLAZARUS AT LARGE COLUMN HEALTH CARE A DRAG ON U.S. BUSINESSMOST ILLEGAL ALIENS FREED ON BAIL, OWN RECOGNIZANCEDELAY SAYS BUSH PROMISES BETTER EFFORT ON IMMIGRATION LAWBUSH-IMMIGRATION-HNSGROWTH RATE OF HISPANIC POPULATION IS RISING, CENSUS BUREAU SAYSREPORT DESCRIBES IMMIGRANTS AS YOUNGER, MORE DIVERSESHARED LANGUAGE (FOR USEDIPLOMAT: MIGRANT BILL NEEDEDIMMIGRATION REFORM AT TOP OF MANY AGENDAS; SIMILAR PROPOSALS BY BUSH, SEN. CORNYN TO TACKLE GUEST WORKERS, BORDER SECURITYSOUTH TEXAS COUNTY OVERWHELMED BY ILLEGAL IMMIGRANTS
STUDY TRACKS SURGE IN ILLEGAL IMMIGRATION FROM MEXICONO WORRIES AT PINEHURST FOR 'EL NINO'ONE IN 11 MEXICAN NATIVES IN U.S., HALF ILLEGALLOW-PROFILE KENTUCKY TOBACCO MAN BUYS UP TEXAS RANCH LANDBOOK REVIEW: CREATING A NEW AMERICANISMOCORNYN-IMMIGRATION-HNSLAWMAKER SAYS ILLEGAL IMMIGRANTS SHOULDN'T COUNT IN THE CENSUSGEORGIA STATE LOOKS AT FOOTBALLGARCIA HAS ALL THE SHOTS BUT NOT A MAJOR TITLEGUARDSMAN KILLED IN AFGHANISTAN BURIEDTWO IMMIGRATION PLANS TAKE SHAPE IN SENATEUP TO 64 LABORERS LIVED IN A SMALL HOUSE, AUTHORITIES SAY
THE VALUE OF IMMIGRANTSFEDS FAIL TO GO AFTER COMPANIES HIRING ILLEGAL IMMIGRANTSMINUTEMAN GROUP MAKES PLANS FOR TEXAS PATROL GEORGIA LAGS BEHIND IN LOCAL EMERGENCY PLANNING GROUPSEDITORIAL: SHAM SANCTIONSON LONG ISLAND, A RAID STIRS DISPUTE OVER INFLUX OF IMMIGRANTSHISPANIC POLITICAL POWER LAGS BEHIND RECORD GROWTH , STUDY SAYSLEGISLATION TO LICENSE UNDOCUMENTED IMMIGRANTS MOVES FORWARDBUSH ADMINISTRATION BORDER SURVEY NOT RELEASEDMEXICO TO LET MIGRANTS VOTE BY MAILLAWMAKERS IN MEXICO APPROVE ABSENTEE VOTING FOR MIGRANTSGARCIA: TOO GOOD TO BE TRUE?BUSH'S STAND ON IMMIGRATION RILES SOME OF THE PARTY'S BASE
BRAZILIANS STREAMING INTO U.S. THROUGH MEXICAN BORDERBUSH ADMINISTRATION SAYS MEXICAN STAMPS ARE INAPPROPRIATETECH ASSISTANT TAPPED FOR GEORGIA STATE ADLONG ISLAND OFFICIALS TRY A DIFFERENT APPROACH TO IMMIGRANT CRACKDOWN
Figure 6: Snapshot of a single article node
and all of its neghboring article nodes. See
http://zoom.it/GUCR for the zoomable image.
6.2.2 Baselines
k-means baseline: A simple baseline is to
split each six-month period of articles into T
equal time slices, then apply k-means clustering
to each slice, using NCS to measure distance.
We then select the most central article from each
cluster, and finally match the k articles from
time slice i one-to-one with those from slice i+ 1
by computing the pairing that maximizes the
average NCS of the pairs, i.e., the coherence of
the threads. The result is a set of k threads
of length T , where no two threads contain the
same article. In its use of clustering, this base-
line is somewhat similar to the ?event threading?
baseline of Shahaf and Guestrin (2010).
DTM baseline: A more sophisticated base-
line is the dynamic topic model (Blei and Lafferty,
2006), which explicitly attempts to find topics
that are smooth through time. We use code
provided by the authors to fit DTMs with the
number of topics set to k and with the data split
into T equal slices, as before. We then choose,
for each topic at each time step, the document
with the highest per-word probability of being
generated by that topic. Documents from the
same topic form a single thread.
717
CosSim
ROUGE-1 ROUGE-2 ROUGE-SU4
F Prec/ Rec F Prec / Rec F Prec/ Rec
k-means 29.9 16.5 17.3/15.8 0.695 0.725 / 0.669 3.76 3.94/3.60
DTM 27.0 14.7 15.5/14.0 0.750 0.813 / 0.698 3.44 3.63/3.28
k-SDPP 33.2 17.2 17.7/16.7 0.892 0.917/0.870 3.98 4.11/3.87
Table 1: Similarity of automatically generated timelines to human summaries. Bold entries are significantly
higher than others in the column at 99% confidence, computed using bootstrapping (Hesterberg et al2003).
6.2.3 Comparison to human summaries
We compare the threads generated by our
baselines and sampled from the k-SDPP to a
set of human-generated news summaries. The
human summaries are not threaded; they are
flat, roughly daily news summaries published by
Agence France-Presse and found in the Gigaword
corpus, distinguished by their ?multi? type tag.
A sample summary is included in the supplement.
These summaries tend to focus on world news,
which is only a subset of the contents of our
dataset. However, they allow us to provide an
extrinsic evaluation of our method without gold
standard timelines. We compute four statistics:
? Cosine similarity: NCS (in percent) be-
tween the concatenated threads and con-
catenated human summaries. The hyper-
parameters for all methods?such as the
constant feature magnitude ? for k-SDPPs
and the parameter governing topic propor-
tions for DTMs?were tuned to optimize
cosine similarity on a development set from
January-June 2005.
? ROUGE-1, 2, and SU4: Standard
ROUGE scores for summarization evalua-
tion (Lin, 2004).
Table 1 shows the results of these comparisons,
averaged across all six half-year intervals. Under
each measure, the k-SDPP threads more closely
resemble human summaries.
6.2.4 Mechanical Turk evaluation
An important distinction between the base-
lines and the k-SDPP is that the former are
topic-oriented, choosing articles that relate to
broad subject areas, while our approach is story-
oriented, chaining together articles with direct
Rating Interlopers
k-means 2.73 0.71
DTM 3.19 1.10
k-SDPP 3.31 1.15
Table 2: Rating: average coherence score from 1
(worst) to 5 (best). Interlopers: average number of
interloper articles identified (out of 2). Bold entries
are significantly higher with 95% confidence.
individual relationships. An example of this dis-
tinction can be seen in Figure 2.
To obtain a large-scale evaluation of thread co-
herence, we turn to Mechanical Turk. We asked
Turkers to read the headlines and first few sen-
tences of each article in a timeline and then rate
the overall narrative coherence of the timeline on
a scale of 1 (?the articles are totally unrelated?)
to 5 (?the articles tell a single clear story?). Five
separate Turkers rated each timeline; the average
ratings are shown in Table 2. Note that k-means
does particularly poorly in terms of coherence
since it has no way to ensure that clusters are
similar between time slices.
We also had Turkers evaluate threads implic-
itly by performing a simple task. We showed
them timelines into which two additional ?in-
terloper? articles selected at random had been
inserted, and asked them to remove the two ar-
ticles that they thought should be removed to
?improve the flow of the timeline?. A screenshot
of the task is provided in the supplement. Intu-
itively, the interlopers should be selected more
often when the original timeline is coherent. The
average number of interloper articles correctly
identified is shown in Table 2.
718
Runtime
k-means 625.63
DTM 19,433.80
k-SDPP 252.38
Table 3: Time (in seconds) required to produce a
complete set of threads. The test machine has eight
Intel Xeon E5450 cores and 32GB of memory.
6.2.5 Runtimes
Finally, we report in Table 3 the time required
to produce a complete set of threads for each
method. This time includes clustering for k-
means, model fitting for DTM and random pro-
jections, computation of the covariance matrix,
and sampling for k-SDPP. We view the graph
as an input (much like tfidf vectors for the base-
lines), and so do not include its computation in
the runtime for the k-SDPP. Constructing the
graph only requires an additional 160 seconds
though.
6.3 Analysis
Below we briefly summarize the main differences
between the k-SDPP and the baselines, and dis-
cuss their significance.
? Neither baseline directly models the docu-
ment threads themselves. In contrast, the
k-SDPP defines a probability distribution
over all possible sets of document threads.
This makes the k-SDPP a better choice for
applications where, for instance, the coher-
ence of individual threads is important.
? While the baselines seek threads that cover
or explain as much of the dataset as possible,
k-SDPPs are better suited for tasks where
a balance between quality and diversity is
key, since its hyperparameters correspond
to weights on these quantities. With news
timelines, for example, we want not just
topical diversity but also a focus on the
most important stories.
? Both baselines require input to be split into
time slices, whereas the k-SDPP does not;
this flexibility allows the k-SDPP to put
multiple articles from a single time slice in
a thread, or to build threads that span only
part of the input period.
? While clustering and topic models rely on
EM to approximately optimize their objec-
tives, the k-SDPP comes with an exact,
polynomial-time sampling algorithm.
Revisiting Figure 2, we can see all of these
advantages in action. The k-SDPP produces
more consistent threads due to its use of graph
information, while the DTM threads, though
topic-focused, are less coherent as a story. Fur-
thermore, DTM threads span the entire time
period, while our method selects threads cover-
ing only relevant spans. The quantitative results
in this section underscore the empirical value of
these characteristics.
7 Conclusion
We introduced the novel problem of finding di-
verse and salient threads in graphs of large doc-
ument collections. We developed a probabilistic
approach, combining SDPPs and k-SDPPs, and
showed how random projections make inference
efficient and yield an approximate model with
bounded variational distance to the original. We
then demonstrated that the method produces
qualitatively reasonable results, and, relative to
several baslines, reproduces human news sum-
maries more faithfully, builds more coherent story
threads, and is significantly faster. It would be
interesting to extend our model to structures be-
yond linear chains to trees and other structures.
8 Acknowledgements
This material is based upon work supported un-
der a National Science Foundation Graduate Re-
search Fellowship and NSF award 0803256.
References
[Ahmed and Xing2010] A. Ahmed and E. Xing. 2010.
Timeline: A Dynamic Hierarchical Dirichlet Pro-
cess Model for Recovering Birth/Death and Evolu-
tion of Topics in Text Stream. In Proc. UAI.
[Allan et al01] J. Allan, R. Gupta, and V. Khan-
delwal. 2001. Temporal Summaries of New Topics.
In Proc. SIGIR.
719
[Blei and Lafferty2006] D. Blei and J. Lafferty. 2006.
Dynamic Topic Models. In Proc. ICML.
[Chieu and Lee2004] H. Chieu and Y. Lee. 2004.
Query Based Event Extraction along a Timeline.
In Proc. SIGIR.
[Erkan and Radev2004] G. Erkan and D.R. Radev.
2004. LexRank: Graph-Based Lexical Central-
ity as Salience in Text Summarization. Journal of
Artificial Intelligence Research, 22(1):457?479.
[Graff and Cieri2009] D. Graff and C. Cieri. 2009. En-
glish Gigaword.
[Hesterberg et al03] T. Hesterberg, S. Monaghan,
D. Moore, A. Clipson, and R. Epstein. 2003. Boot-
strap Methods and Permutation Tests.
[Johnson and Lindenstrauss1984] W. B. Johnson and
J. Lindenstrauss. 1984. Extensions of Lipschitz
Mappings into a Hilbert Space. Contemporary
Mathematics, 26:189?206.
[Kulesza and Taskar2010] A. Kulesza and B. Taskar.
2010. Structured Determinantal Point Processes.
In Proc. NIPS.
[Kulesza and Taskar2011] A. Kulesza and B. Taskar.
2011. k-DPPs: Fixed-Size Determinantal Point
Processes. In Proc. ICML.
[Leskovec et al09] J. Leskovec, L. Backstrom, and
J. Kleinberg. 2009. Meme-tracking and the Dy-
namics of the News Cycle. In Proc. KDD.
[Lin2004] C.Y. Lin. 2004. Rouge: A package for
automatic evaluation of summaries. In Proc. WAS.
[Magen and Zouzias2008] A. Magen and A. Zouzias.
2008. Near Optimal Dimensionality Reductions
that Preserve Volumes. Approximation, Random-
ization and Combinatorial Optimization. Algo-
rithms and Techniques, pages 523?534.
[McCallum et al00] A. McCallum, K. Nigam,
J. Rennie, and K. Seymore. 2000. Automating
the Construction of Internet Portals with Machine
Learning. Information Retrieval Journal, 3:127?
163.
[Mei and Zhai2005] W. Mei and C. Zhai. 2005. Dis-
covering Evolutionary Theme Patterns From Text:
An Exploration of Temporal Text Mining. In Proc.
KDD.
[Shahaf and Guestrin2010] D. Shahaf and
C. Guestrin. 2010. Connecting the Dots
Between News Articles. In Proc. KDD.
[Shahaf et al12] D. Shahaf, C. Guestrin, and
E. Horvitz. 2012. Trains of Thought: Generating
Information Maps. In Proc. WWW.
[Swan and Jensen2000] R. Swan and D. Jensen. 2000.
TimeMines: Constructing Timelines with Statisti-
cal Models of Word Usage. In Proc. KDD.
[Wayne2000] C. Wayne. 2000. Multilingual Topic De-
tection and Tracking: Successful Research Enabled
by Corpora and Evaluation. In Proc. LREC.
[Yan et al11] R. Yan, X. Wan, J. Otterbacher,
L. Kong, X. Li, and Y. Zhang. 2011. Evolutionary
Timeline Summarization: A Balanced Optimiza-
tion Framework via Iterative Substitution. In Proc.
SIGIR.
720
