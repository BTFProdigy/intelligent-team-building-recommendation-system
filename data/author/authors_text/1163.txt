Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL 2007, pp. 1112?1118,
Prague, June 2007. c?2007 Association for Computational Linguistics
Multilingual Dependency Parsing and Domain Adaptation using DeSR 
Giuseppe Attardi 
Felice Dell?Orletta 
Maria Simi 
Dipartimento di Informatica 
largo B. Pontecorvo 3 
I-56127 Pisa, Italy 
attardi@di.unipi.it 
felice.dellorletta@
ilc.cnr.it 
simi@di.unipi.it 
Atanas Chanev 
Universit? di Trento 
via Matteo del Ben 5 
I-38068 Rovereto, Italy 
Fondazione Bruno Kessler-irst 
via Sommarive 18 
I-38050 Povo, Italy 
chanev@form.unitn.it 
 
Massimiliano Ciaramita 
Yahoo! Research Barcelona 
Ocata 1 
S-08003 Barcelona, Spain 
massi@yahoo-inc.com 
 
Abstract 
We describe our experiments using the 
DeSR parser in the multilingual and do-
main adaptation tracks of the CoNLL 2007 
shared task. DeSR implements an incre-
mental deterministic Shift/Reduce parsing 
algorithm, using specific rules to handle 
non-projective dependencies. For the multi-
lingual track we adopted a second order 
averaged perceptron and performed feature 
selection to tune a feature model for each 
language. For the domain adaptation track 
we applied a tree revision method which 
learns how to correct the mistakes made by 
the base parser on the adaptation domain. 
1 Introduction 
Classifier-based dependency parsers (Yamada and 
Matsumoto, 2003; Nivre and Scholz, 2004) learn 
from an annotated corpus how to select an 
appropriate sequence of Shift/Reduce actions to 
construct the dependency tree for a sentence. 
Learning is based on techniques such as SVM 
(Vapnik 1998) or Memory Based Learning 
(Daelemans 2003), which provide high accuracy 
but are often computationally expensive. For the 
multilingual track in the CoNLL 2007 Shared 
Task, we employed a Shift/Reduce parser which 
uses a perceptron algorithm with second-order 
feature maps, in order to verify whether a simpler 
and faster algorithm can still achieve comparable 
accuracy. 
For the domain adaptation track we wished to 
explore the use of tree revisions in order to 
incorporate language knowledge from a new 
domain. 
2 Multilingual Track 
The overall parsing algorithm is a deterministic 
classifier-based statistical parser, which extends 
the approach by Yamada and Matsumoto (2003), 
by using different reduction rules that ensure 
deterministic incremental processing of the input 
sentence and by adding specific rules for handling 
non-projective dependencies. The parser also 
performs dependency labeling within a single 
processing step. 
The parser is modular and can use several 
learning algorithms. The submitted runs used a 
second order Average Perceptron, derived from the 
multiclass perceptron of Crammer and Singer 
(2003). 
No additional resources were used. No pre-
processing or post-processing was used, except 
stemming for English, by means of the Snowball 
stemmer (Porter 2001). 
3 Deterministic Classifier-based Parsing 
DeSR (Attardi, 2006) is an incremental determinis-
tic classifier-based parser. The parser constructs 
dependency trees employing a deterministic bot-
tom-up algorithm which performs Shift/Reduce 
actions while analyzing input sentences in left-to-
right order. 
Using a notation similar to (Nivre and Scholz, 
2003), the state of the parser is represented by a 
1112
quadruple ?S, I, T, A?, where S is the stack of past 
tokens, I is the list of (remaining) input tokens, T is 
a stack of temporary tokens and A is the arc rela-
tion for the dependency graph. 
Given an input string W, the parser is initialized 
to ?(), W, (), ()?, and terminates when it reaches a 
configuration ?S, (), (), A?. 
The three basic parsing rule schemas are as fol-
lows: ?S, n|I, T, A? Shift ?n|S, I, T, A? ?s|S, n|I, T, A? Rightd ?S, n|I, T, A?{(s, d, n)}? ?s|S, n|I, T, A? Leftd ?S, s|I, T, A?{(n, d, s)}? 
The schemas for the Left and Right rules are in-
stantiated for each dependency type d ? D, for a 
total of 2|D| + 1 rules. These rules perform both 
attachment and labeling. 
At each step the parser uses classifiers trained 
on a treebank corpus in order to predict which ac-
tion to perform and which dependency label to as-
sign given the current configuration. 
4 Non-Projective Relations 
For handling non-projective relations, Nivre and 
Nilsson (2005) suggested applying a pre-
processing step to a dependency parser, which con-
sists in lifting non-projective arcs to their head re-
peatedly, until the tree becomes pseudo-projective. 
A post-processing step is then required to restore 
the arcs to the proper heads. 
In DeSR non-projective dependencies are han-
dled in a single step by means of the following ad-
ditional parsing rules, slightly different from those 
in (Attardi, 2006): 
 ?s1|s2|S, n|I, T, A? Right2d ? S, s1|n|I, T, A?{(s2, d, n)}? ?s1|s2|S, n|I, T, A? Left2d ?s2|S, s1|I, T, A?{(n, d, s2)}? ?s1|s2|s3|S, n|I, T, A? Right3d ? S, s1|s2|n|I, T, A?{(s3, d, n)}? ?s1|s2|s3|S, n|I, T, A? Left3d ?s2|s3|S, s1|I, T, A?{(n, d, s3)}? 
 ?s1|s2|S, n|I, T, A? Extract ?n|s1|S, I, s2|T, A? ?S, I, s1|T, A? Insert ?s1|S, I, T, A? 
Left2, Right2 are similar to Left and Right, except 
that they create links crossing one intermediate 
node, while Left3 and Right3 cross two intermedi-
ate nodes. Notice that the RightX actions put back 
on the input the intervening tokens, allowing the 
parser to complete the linking of tokens whose 
processing had been delayed. Extract/Insert gener-
alize the previous rules by moving one token to the 
stack T and reinserting the top of T into S. 
5 Perceptron Learning and 2nd-Order 
Feature Maps 
The software architecture of the DeSR parser is 
modular. Several learning algorithms are available, 
including SVM, Maximum Entropy, Memory-
Based Learning, Logistic Regression and a few 
variants of the perceptron algorithm. 
We obtained the best accuracy with a multiclass 
averaged perceptron classifier based on the 
ultraconservative formulation of Crammer and 
Singer (2003) with uniform negative updates. The 
classifier function is: { }xxF k
k
?= ?maxarg)(  
where each parsing action k is associated with a 
weight vector ?k. To regularize the model the final 
weight vectors are computed as the average of all 
weight vectors posited during training. The number 
of learning iterations over the training data, which 
is the only adjustable parameter of the algorithm, 
was determined by cross-validation.  
In order to overcome the limitations of a linear 
perceptron, we introduce a feature map ?: IRd ? 
IRd(d+1)/2 that maps a feature vector x into a higher 
dimensional feature space consisting of all un-
ordered feature pairs: ?(x) = ?xixj | i = 1, ?, d, j = i, ?, d? 
In other words we expand the original 
representation in the input space with a feature 
map that generates all second-order feature 
combinations from each observation. We call this 
the 2nd-order model, where the inner products are 
computed as ?k ? ?(x), with ?k a vector of dimen-
sion d(d+1)/2. Applying a linear perceptron to this 
feature space corresponds to simulating a polyno-
mial kernel of degree two.  
A polynomial kernel of degree two for SVM 
was also used by Yamada and Matsumoto (2003). 
However, training SVMs on large data sets like 
those arising from a big training corpus was too 
1113
computationally expensive, forcing them to resort 
to partitioning the training data (by POS) and to 
learn several models. 
Our implementation of the perceptron algorithm 
uses sparse data structures (hash maps) so that it 
can handle efficiently even large feature spaces in 
a single model. For example the feature space for 
the 2nd-order model for English contains over 21 
million. Parsing unseen data can be performed at 
tens of sentences per second. More details on such 
aspects of the DeSR parser can be found in (Ci-
aramita and Attardi 2007). 
6 Tuning 
The base parser was tuned on several parameters to 
optimize its accuracy as follows. 
6.1 Feature Selection 
Given the different characteristics of languages and 
corpus annotations, it is worth while to select a 
different set of features for each language. For ex-
ample, certain corpora do not contain lemmas or 
morphological information so lexical information 
will be useful. Vice versa, when lemmas are pre-
sent, lexical information might be avoided, reduc-
ing the size of the feature set. 
We performed a series of feature selection ex-
periments on each language, starting from a fairly 
comprehensive set of 43 features and trying all 
variants obtained by dropping a single feature. The 
best of these alternatives feature models was cho-
sen and the process iterated until no further gains 
were achieved. The score for the alternatives was 
computed on a development set of approximately 
5000 tokens, extracted from a split of the original 
training corpus. 
Despite the process is not guaranteed to produce 
a global optimum, we noticed LAS improvements 
of up to 4 percentage points on some languages. 
The set of features to be used by DeSR is con-
trolled by a number of parameters supplied through 
a parameter file. Each parameter describes a fea-
ture and from which tokens to extract it. Tokens 
are referred through positive numbers for input 
tokens and negative numbers for tokens on the 
stack. For example 
PosFeatures -2 -1 0 1 2 3 
means to use the POS tag of the first two tokens on 
the stack and of the first four tokens on the input. 
The parameter PosPrev refers to the POS of the 
preceding token in the original sentence, PosLeftChild refers to the POS of the left chil-
dren of a token, PastActions tells how many 
previous actions to include as features. 
The selection process was started from the fol-
lowing base feature model: 
LexFeatures -1 0 1 LemmaFeatures -2 -1 0 1 2 3 LemmaPrev  -1 0 LemmaSucc  -1 0 LemmaLeftChild -1 0 LemmaRightChild -1 MorphoFeatures -1 0 1 2 PosFeatures -2 -1 0 1 2 3 PosNext  -1 0 PosPrev  -1 0 PosLeftChild -1 0 PosRightChild -1 0 CPosFeatures -1 0 1 DepFeatures -1 0 DepLeftChild -1 0 DepRightChild -1 PastActions 1 
The selection process produced different variants 
for each language, sometimes suggesting dropping 
certain intermediate features, like the lemma of the 
third next input token in the case of Catalan: 
LemmaFeatures -2 -1 0 1 3 LemmaPrev  0 LemmaSucc  -1 LemmaLeftChild 0 LemmaRightChild -1 PosFeatures -2 -1 0 1 2 3 PosPrev  0 PosSucc  -1 PosLeftChild -1 0 PosRightChild -1 0 CPosFeatures -1 0 1 MorphoFeatures 0 1 DepLeftChild -1 0 DepRightChild -1 
For Italian, instead, we ran a series of tests in par-
allel using a set of manually prepared feature mod-
els. The best of these models achieved a LAS of 
80.95%. The final run used this model with the 
addition of the morphological agreement feature 
discussed below. 
 
English was the only language for which no feature 
selection was done and for which lexical features 
1114
were used. English is also the language where the 
official score is significantly lower than what we 
had been getting on our development set (90.01% 
UAS). 
6.2 Prepositional Attachment 
Certain languages, such as Catalan, use detailed 
dependency labeling, that for instance distinguish 
between adverbials of location and time. We ex-
ploited this information by introducing a feature 
that captures the entity type of a child of the top 
word on the stack or in the input. During training a 
list of nouns occurring in the corpus as dependent 
on prepositions with label CCL (meaning ?com-
plement of location? for Catalan) was created and 
similarly for CCT (complement of time). The en-
tity type TIME is extracted as a feature depending 
on whether the noun occurs in the time list more 
than ? times than in the location list, and similarly 
for the feature LOCATION. ? was set to 1.5 in our 
experiments. 
6.3 Morphological Agreement 
Certain languages require gender and number 
agreement between head and dependent. The fea-
ture MorphoAgreement is computed for such lan-
guages and provided noticeable accuracy 
improvements. 
For example, for Italian, the improvement was 
from: 
  LAS: 80.95%,  UAS: 85.03% 
to: 
  LAS: 81.34%,  UAS: 85.54% 
For Catalan, adding this feature we obtained an 
unofficial score of: 
  LAS: 87.64%,  UAS: 92.20% 
with respect to the official run: 
  LAS: 86.86%,  UAS: 91.41% 
7 Accuracy 
Table 1 reports the accuracy scores in the multilin-
gual track. They are all considerably above the 
average and within 2% from the best for Catalan, 
3% for Chinese, Greek, Italian and Turkish. 
8 Performance 
The experiments were performed on a 2.4 Ghz 
AMD Opteron machine with 32 GB RAM. Train-
ing the parser using the 2nd-order perceptron on the 
English corpus required less than 3 GB of memory 
and about one hour for each iteration over the 
whole dataset. Parsing the English test set required 
39.97 sec. For comparison, we tested the MST 
parser version 0.4.3 (Mstparser, 2007), configured 
for second-order, on the same data: training took 
73.9 minutes to perform 10 iterations and parsing 
took 97.5 sec. MST parser achieved: 
LAS: 89.01%, UAS: 90.17% 
9 Error Analysis on Catalan 
The parser achieved its best score on Catalan, so 
we performed an analysis on its output for this lan-
guage. 
Among the 42 dependency relations that the 
parser had to assign to a sentence, the largest num-
ber of errors occurred assigning CC (124), SP (33), CD (27), SUJ (26), CONJUNCT (22), SN (23). 
The submitted run for Catalan did not use the 
entity feature discussed earlier and indeed 67 er-
rors were due to assigning CCT or CCL instead of 
CC (generic complement of circumstance). How-
ever over half of these appear as underspecified 
annotation errors in the corpus rather than parser 
errors. 
By adding the ChildEntityType feature, 
which distinguishes better between CCT and CCL, 
the UAS improved, while the LAS dropped 
slightly, due to the effect of underspecified annota-
tions in the corpus: 
   LAS: 87.22%,    UAS: 91.71% 
Table 1. Multilingual track official scores. 
LAS UAS 
Task 
1st DeSR Avg 1st DeSR Avg 
Arabic  76.52  72.66 68.34  86.09  82.53 78.84  
Basque  76.92  69.48 68.06  82.80  76.86 75.15  
Catalan  88.70  86.86 79.85  93.40  91.41 87.98  
Chinese  84.69  81.50 76.59  88.94  86.73 81.98  
Czech  80.19  77.37 70.12  86.28  83.40 77.56  
English  89.61  85.85 80.95  90.63  86.99 82.67  
Greek  76.31  73.92 70.22  84.08  80.75 77.78  
Hungarian  80.27  76.81 71.49  83.55  81.81 76.34  
Italian  84.40  81.34 78.06  87.91  85.54 82.45  
Turkish  79.81  76.87 73.19  86.22  83.56 80.33  
1115
A peculiar aspect of the original Catalan corpus 
was the use of a large number (195) of dependency 
labels. These labels were reduced to 42 in the ver-
sion used for CoNNL 2007, in order to make it 
comparable to other corpora. However, performing 
some preliminary experiments using the original 
Catalan collection with all 195 dependency labels, 
the DeSR parser achieved a significantly better 
score: 
LAS: 88.80%, UAS: 91.43% 
while with the modified one, the score dropped to: 
LAS: 84.55%, UAS: 89.38% 
This suggests that accuracy might improve for 
other languages as well if the training corpus was 
labeled with more precise dependencies. 
10 Adaptation Track 
The adaptation track originally covered two do-
mains, the CHILDES and the Chemistry domain.  
The CHILDES (Brown, 1973; MacWhinney, 
2000) consists of transcriptions of dialogues with 
children, typically short sentences of the kind: 
Would you like more grape juice ? 
That 's a nice box of books . 
Phrases are short, half of them are questions. The 
only difficulty that appeared from looking at the 
unlabeled collection supplied for training in the 
domain was the presence of truncated terms like goin (for going), d (for did), etc. However none 
of these unusually spelled words appeared in the 
test set, so a normal English parser performed rea-
sonably well on this task. Because of certain in-
consistencies in the annotation guidelines, the 
organizers decided to make this task optional and 
hence we submitted just the parse produced by the 
parser trained for English. 
For the second adaptation task we were given a 
large collection of unlabeled data in the chemistry 
domain (Kulick et al 2004) as well as a test set of 
5000 tokens (200 sentences) to parse (eng-lish_pchemtbtb_test.conll). 
There were three sets of unlabeled documents: 
we chose the smallest (unlab1) consisting of over 
300,000 tokens (11663 sentences). unlab1 was 
tokenized, POS and lemmas were added using our 
version of TreeTagger (Schmid, 1994), and lem-
mas replaced with stems, which had turned out to 
be more effective than lemmas. We call this set pchemtb_unlab1.conll. 
We trained the DeSR parser on English using english_ptb_train.conll, the WSJ PTB col-
lection provided for CoNLL 2007. This consists of 
WSJ sections 02-11, half of the usual set 02-23, for 
a total of 460,000 tokens with dependencies gener-
ated with the converter by Johansson and Nugues 
(2007). 
We added stems and produced a parser called DeSRwsj. By parsing eng-lish_pchem_test.conll with DeSRwsj we 
obtained pchemtb_test_base.desr, our base-
line for the task. 
By visual inspection using DgAnnotator 
(DgAnnotator, 2006), the parses looked generally 
correct. Most of the errors seemed due to improper 
handling of conjunctions and disjunctions. The 
collection in fact contains several phrases like: 
Specific antibodies raised against 
P450IIB1 , P450 IA1 or IA2 , 
P450IIE1 , and P450IIIA2 inhibited 
the activation in liver microsomes 
from rats pretreated with PB , BNF , 
INH and DEX respectively 
The parser did not seem to have much of a problem 
with terminology, possibly because the supplied 
gold POS were adequate. 
For the adaptation we proceeded as follows. We 
parsed pchemtb_unlab1.conll using DeSRwsj 
obtaining pchemtb_unlab1.desr. 
We then extracted a set of 12,500 sentences 
from ptb_train.conll and 7,500 sentences 
from pchemtb_unlab1.desr, creating a corpus 
of 20,000 sentences called combined.conll. In 
both cases the selection criteria was to choose sen-
tences shorter than 30 tokens. 
We then trained a low accuracy parser (called DesrCombined) on combined.conll, by using 
a 1st-order averaged perceptron. DesrCombined 
was used to parse english_ptb_train.conll, 
the original training corpus for English. By com-
paring this parse with the original, one can detect 
where such parser makes mistakes. The rationale 
for using an inaccurate parser is to obtain parses 
with many errors so that they form a suitably large 
training set for the next step: parser revision. 
We then used a parsing revision technique (At-
tardi and Ciaramita, 2007) to learn how to correct 
these errors, producing a parse reviser called DesrReviser. The revision technique consists of 
comparing the parse trees produced by the parser 
with the gold standard parse trees, from the 
annotated corpus. Where a difference is noted, a 
1116
revision rule is determined to correct the mistake. 
Such rules consist in movements of a single link to 
a different head. Learning how to revise a parse 
tree consists in training a classifier on a set of 
training examples consisting of pairs ?(wi, d, wj), 
ti?, i.e. the link to be modified and the 
transformation rule to apply. Attardi and Ciaramita 
(2007) showed that 80% of the corrections can be 
typically dealt with just 20 tree revision rules. For 
the adaptation track we limited the training to 
errors recurring at least 20 times and to 30 rules. DesrReviser was then applied to pchemtb_test_base.desr producing pchemtb_test_rev.desr, our final submission. 
Many conjunction errors were corrected, in par-
ticular by moving the head of the sentence from a 
coordinate verb to the conjunction ?and? linking 
two coordinate phrases. 
The revision step produced an improvement of 
0.42% LAS over the score achieved by using just 
the base DeSRwsj parser. 
Table 2 reports the official accuracy scores on 
the closed adaptation track. DeSR achieved a close 
second best UAS on the ptchemtb test set and 
third best on CHILDES. The results are quite en-
couraging, particularly considering that the revi-
sion step does not yet correct the dependency 
labels and that our base English parser had a lower 
rank in the multilingual track. 
 
LAS UAS 
Task 
1st DeSR Avg 1st DeSR Avg 
CHILDES     61.37 58.67 57.89 
Pchemtb  81.06 80.40 73.03 83.42  83.08 76.42 
Table 2. Closed adaptation track scores. 
Notice that the adaptation process could be iter-
ated. Since the combination DeSRwsj+DesrReviser is a more accurate parser 
than DeSRwsj, we could use it again to parse pchemtb_unlab1.conll and so on. 
11 Conclusions 
For performing multilingual parsing in the CoNLL 
2007 shared task we employed DeSR, a classifier-
based Shift/Reduce parser. We used a second order 
averaged perceptron as classifier and achieved ac-
curacy scores quite above the average in all lan-
guages. For proper comparison with other 
approaches, one should take into account that the 
parser is incremental and deterministic; hence it is 
typically faster than other non linear algorithms. 
For the adaptation track we used a novel ap-
proach, based on the technique of tree revision, 
applied to a parser trained on a corpus combining 
sentences from both the training and the adaptation 
domain. The technique achieved quite promising 
results and it also offers the interesting possibility 
of being iterated, allowing the parser to incorporate 
language knowledge from additional domains. 
Since the technique is applicable to any parser, 
we plan to test it also with more accurate English 
parsers. 
Acknowledgments.  The following treebanks 
were used for training the parser: (Aduriz et al, 
2003; B?hmov? et al, 2003; Chen et al, 2003; Ha-
ji? et al, 2004; Marcus et al, 1993; Mart? et al, 
2002; Montemagni et al 2003; Oflazer et al, 2003; 
Prokopidis et al, 2005; Csendes et al, 2005). 
Ryan McDonald and Jason Baldridge made avail-
able mstparser and helped us using it. We grate-
fully acknowledge Hugo Zaragoza and Ricardo 
Baeza-Yates for supporting the first author during 
a sabbatical at Yahoo! Research Barcelona. 
References 
A. Abeill?, editor. 2003. Treebanks: Building and Using 
Parsed Corpora. Kluwer. 
I. Aduriz, M. J. Aranzabe, J. M. Arriola, A. Atutxa, A. 
Diaz de Ilarraza, A. Garmendia and M. Oronoz. 
2003. Construction of a Basque Dependency Tree-
bank. In Proc. of the 2nd Workshop on Treebanks 
and Linguistic Theories (TLT), 201?204. 
G. Attardi. 2006. Experiments with a Multilanguage 
non-projective dependency parser. In Proc. of the 
Tenth CoNLL, 2006. 
G. Attardi, M. Ciaramita. 2007. Tree Revision Learning 
for Dependency Parsing. In Proc. of NAACL/HLTC 
2007. 
A. B?hmov?, J. Hajic, E. Hajicov? and B. Hladk?. 2003. 
The PDT: a 3-level annotation scenario. In Abeill? 
(2003), chapter 7, 103?127. 
R. Brown. 1973. A First Language: The Early Stages. 
Harvard University Press. 
K. Chen, C. Luo, M. Chang, F. Chen, C. Chen, C. 
Huang and Z. Gao. 2003. Sinica Treebank: Design 
Criteria, Representational Issues and Implementation. 
In Abeill? (2003), chapter 13, 231?248. 
1117
M. Ciaramita, G. Attardi. 2007. Dependency Parsing 
with Second-Order Feature Maps and Annotated Se-
mantic Information. Proc. of the 12th International 
Workshop on Parsing Technologies (IWPT), 2007. 
K. Crammer, Y. Singer. 2003. Ultraconservative Online 
Algorithms for Multiclass Problems. Journ. of Ma-
chine Learning Research. 
D. Csendes, J. Csirik, T. Gyim?thy, and A. Kocsor. 
2005. The Szeged Treebank. Springer.  
DgAnnotator. 2006. 
http://medialab.di.unipi.it/Project/Parser/DgAnnotato
r/. 
J. Hajic, O. Smrz, P. Zem?nek, J. Snaidauf and E. 
Beska. 2004. Prague Arabic Dependency Treebank: 
Development in Data and Tools. In Proc. of the 
NEMLAR Intern. Conf. on Arabic Language Re-
sources and Tools, 110?117. 
R. Johansson and P. Nugues. 2007. Extended 
constituent-to-dependency conversion for English. In 
Proc. of the 16th Nordic Conference on 
Computational Linguistics (NODALIDA).  
S. Kulick, A. Bies, M. Liberman, M. Mandel, R. Mc- 
Donald, M. Palmer, A. Schein, and L. Ungar. 2004. 
Integrated annotation for biomedical information ex- 
traction. In Proc. of the Human Language 
Technology Conference and the Annual Meeting of 
the North American Chapter of the Association for 
Computational Linguistics (HLT/NAACL).  
B. MacWhinney. 2000. The CHILDES Project: Tools 
for Analyzing Talk. Lawrence Erlbaum. 
M. Marcus, B. Santorini, and M. Marcinkiewicz. 1993. 
Building a large annotated corpus of English: the 
Penn Treebank. Computational Linguistics, 
19(2):313?330. 
M. A. Mart?, M. Taul?, L. M?rquez and M. Bertran. 
2007. CESS-ECE: A Multilingual and Multilevel 
Annotated Corpus. Available for download from: 
http://www.lsi.upc.edu/~mbertran/cess-ece/. 
R. McDonald, et al 2005. Non-projective Dependency 
Parsing using Spanning Tree Algorithms. In Proc. of 
HLT-EMNLP. 
B. MacWhinney. 2000. The CHILDES Project: Tools 
for Analyzing Talk. Lawrence Erlbaum. 
S. Montemagni, F. Barsotti, M. Battista, N. Calzolari, 
O. Corazzari, A. Lenci, A. Zampolli, F. Fanciulli, M. 
Massetani, R. Raffaelli, R. Basili, M. T. Pazienza, D. 
Saracino, F. Zanzotto, N. Nana, F. Pianesi, and R. 
Delmonte. 2003. Building the Italian Syntactic-
Semantic Treebank. In Abeill? (2003), chapter 11, 
189?210.  
Mstparser 0.4.3. 2007.  
http://sourceforge.net/projects/mstparser/ 
J. Nivre, et al 2004. Memory-based Dependency Pars-
ing. In Proc.s of the Eighth CoNLL, ed. H. T. Ng and 
E. Riloff, Boston, Massachusetts, 49?56. 
J. Nivre and J. Nilsson. 2005. Pseudo-Projective De-
pendency Parsing. In Proc. of the 43rd Annual Meet-
ing of the ACL, 99?106. 
J. Nivre and M. Scholz. 2004. Deterministic Depend-
ency Parsing of English Text. In Proc. of COLING 
2004, Geneva, Switzerland, 64?70. 
J. Nivre, J. Hall, S. K?bler, R. McDonald, J. Nilsson, S. 
Riedel, and D. Yuret. 2007. The CoNLL 2007 shared 
task on dependency parsing. In Proc. of the CoNLL 
2007 Shared Task. Joint Conf. on Empirical Methods 
in Natural Language Processing and Computational 
Natural Language Learning (EMNLP-CoNLL). 
K. Oflazer, B. Say, D. Zeynep Hakkani-T?r, and G. T?r. 
2003. Building a Turkish treebank. In Abeill? (2003), 
chapter 15, 261?277.  
M.F. Porter. 2001. Snowball Stemmer.  
http://www.snowball.tartarus.org/ 
P. Prokopidis, E. Desypri, M. Koutsombogera, H. 
Papageorgiou, and S. Piperidis. 2005. Theoretical 
and practical issues in the construction of a Greek 
depen- dency treebank. In Proc. of the 4th Workshop 
on Treebanks and Linguistic Theories (TLT), pages 
149?160. 
H. Schmid. 1994. Probabilistic Part-of-Speech Tagging 
Using Decision Trees. In Proc. of International Con-
ference on New Methods in Language Processing. 
V. N. Vapnik. 1998. The Statistical Learning Theory. 
Springer. 
H. Yamada and Y. Matsumoto. 2003. Statistical De-
pendency Analysis with Support Vector Machines. In 
Proc. of the 8th International Workshop on Parsing 
Technologies (IWPT), 195?206. 
 
1118
Proceedings of SSST-5, Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 79?87,
ACL HLT 2011, Portland, Oregon, USA, June 2011. c?2011 Association for Computational Linguistics
A Dependency Based Statistical Translation Model 
 
Giuseppe Attardi 
 
Universit? di Pisa 
Dipartimento di Informatica 
attardi@di.unipi.it 
Atanas Chanev 
 
Universit? di Pisa 
Dipartimento di Informatica 
chanev@di.unipi.it 
Antonio Valerio Miceli Barone 
 
Universit? di Pisa 
Dipartimento di Informatica 
miceli@di.unipi.it 
 
 
Abstract 
We present a translation model based on 
dependency trees. The model adopts a tree-
to-string approach and extends Phrase-
Based translation (PBT) by using the de-
pendency tree of the source sentence for 
selecting translation options and for reor-
dering them. Decoding is done by translat-
ing each node in the tree and combining its 
translations with those of its head in alter-
native orders with respect to its siblings. 
Reordering of the siblings exploits a heu-
ristic based on the syntactic information 
from the parse tree which is learned from 
the corpus. The decoder uses the same 
phrase tables produced by a PBT system 
for looking up translations of single words 
or of partial sub-trees. A mathematical 
model is presented and experimental re-
sults are discussed.  
1 Introduction 
Several efforts are being made to incorporate syn-
tactic analysis into phrase-base statistical transla-
tion (PBT) (Och 2002; Koehn et. al. 2003), which 
represents the state of the art in terms of robust-
ness in modeling local word reordering and effi-
ciency in decoding. Syntactic analysis is meant to 
improve some of the pitfalls of PBT: 
 Translation options selection: candidate phrases 
for translation are selected as consecutive n-
grams. This may miss to consider certain syn-
tactic phrases if their component words are far 
apart. 
 Phrase reordering: especially for languages 
with different word order, e.g. subject-verb-
object (SVO) and subject-object-verb (SVO) 
languages, long distance reordering is a prob-
lem. This has been addressed with a distance 
based distortion model (Och 2002; Koehn et al 
2003), lexicalized phrase reordering (Tillmann, 
2004; Koehn, et.al., 2005; Al-Onaizan and Pa-
pineni, 2006), by hierarchical phrase reordering 
model (Galley and Manning, 2008) or by reor-
dering the nodes in a dependency tree (Xu et 
al., 2009) 
 Movement of translations of fertile words: a 
word with fertility higher than one can be trans-
lated into several words that do not occur con-
secutively. For example, the Italian sentence 
?Lui partir? domani? translates into German as 
?Er wird morgen abreisen?. The Italian word 
?partir?? (meaning ?will leave?) translates into 
?wird gehen? in German, but the infinite ?ab-
reisen? goes to the end of the sentence with a 
movement that might be quite long. 
Reordering of phrases is necessary because of dif-
ferent word order typologies of languages: consti-
tuent word order like SOV for Hindi vs. SVO for 
English; order of modifiers like noun?adjective for 
French, Italian vs. adjective-noun in English. Xu et 
al. (2009) tackle this issue by introducing a reor-
dering approach based on manual rules that are 
applied to the parse tree produced by a dependen-
cy parser. 
However the splitting phenomenon mentioned 
above requires more elaborate solutions than sim-
ple reordering grammatical rules. 
Several schemes have been proposed for im-
proving PBMT systems based on dependency 
trees.  Our approach extends basic PBT as de-
79
scribed in (Koehn et. al., 2003) with the following 
differences: 
 we perform tree-to-string translation. The de-
pendency tree of the source language sentence 
allows identifying syntactically meaningful 
phrases as translation options, instead of n-
grams. However these phrases are then still 
looked up in a Phrase Translation Table (PT) 
quite similarly to PBT. Thus we avoid the 
sparseness problem that other methods based 
on treelets suffer (Quirk et al, 2005). 
 reordering of phrases is carried out traversing 
the dependency tree and selecting as options 
phrases that are children of each head. Hence a 
far away but logically connected portion of a 
phrase can be included in the reordering. 
 phrase combination is performed by combining 
the translations of a node with those of its head. 
Hence only phrases that have a syntactic rela-
tion are connected. The Language Model (LM) 
is still consulted to ensure that the combination 
is proper, and the overall score of each transla-
tion is carried along.  
 when all the links in the parse tree have been 
reduced, the root node contains candidate trans-
lations for the whole sentences 
 alternative visit orderings of the tree may pro-
duce different translations so the final transla-
tion is the one with the highest score. 
Some of the benefits of our approach include: 
1) reordering is based on syntactic phrases rather 
than arbitrary chunks 
2) computing the future cost estimation can be 
avoided, since the risk of choosing an easier n-
gram is mitigated by the fact that phrases are 
chosen according to the dependency tree 
3) since we are translating from tree to string, we 
can directly exploit the standard phrase tables 
produced by PBT tools such as giza++ (Och 
and Ney, 2000) and Moses (Koehn, 2007) 
4) integration with the parser: decoding can be 
performed incrementally while a dependency 
Shift/Reduce parser builds the parse tree (At-
tardi, 2006). 
2 The  Dependency Based Decoder 
We describe in more detail the approach by pre-
senting a simple example. 
The translation of an input sentence is generated 
by reducing the dependency tree one link at a time, 
i.e. merging one node with its parent and combin-
ing their translations, until a single node remains. 
Links must be chosen in an order that preserves 
the connectivity of the dependency tree. Since 
there is a one-to-one correspondence between 
links and nodes (i.e. the link between a node and 
its head), we can use any ordering that corres-
ponds to a topological ordering of the nodes of the 
tree. 
A sentence is a sequence of words (w1, ? , wn), 
so we can use their index to identify words and 
hence each ordering is a permutation of those in-
dexes. 
Consider for example the dependency tree for 
the Italian sentence: Il ragazzo alto (?The tall 
boy?). 
 
There are only two possible topological orderings 
for this tree: 1-3-2 and 3-1-2.  
In principle the decoding process should ex-
plore all possible topological orderings for gene-
rating translations, but their number is too big, 
being proportional to the factorial of the number of 
words, so we will introduce later a criterion for 
selecting a subset of these, which conform best 
with the rules of the languages. 
Given a permutation we obtain a translation by 
merging in that order each node with its parent. 
The initialization step of the decoder creates 
nodes corresponding to the parse tree and collects 
translations for each individual word from the PT. 
 
ragazzo 
boy 
 
alto 
tall 
high 
Il 
The 
Il   ragazzo   alto 
80
Case 1: Permutation 1-3-2 
The first merge step is applied to the nodes for w1 
and its head w2, performing the concatenation of 
the translations of nodes il (the) and ragazzo (boy), 
both in normal and reverse order. Hence expansion 
of this hypothesis reduces the tree to the follow-
ing, where we show also the partial translations 
associated to each node. Each translation has asso-
ciated weights (i.e. the LM weight, the translation 
model weight, etc.) and a cumulative score. The 
score is the dot product of the weights for the sen-
tence and the vector of tuning parameters for the 
model. The score is used to rank the sentences and 
also to limit how many of them are kept according 
to the beam size parameter of the algorithm. 
 
The second step merges the node for word w3 (?al-
to?) with that of its head w2 (?ragazzo?) producing 
a single node with four translations: ?the boy tall?, 
?boy the tall?, ?tall the boy? and ?tall boy the?. 
 
Case 2: Permutation 3-1-2 
The first merge between w3 and w2 generates two 
translation fragments: ?boy tall? and ?tall boy?. 
The second one creates four translations: ?the boy 
tall?, ?boy tall the?, ?the tall boy?, ?tall boy the?. 
 
When the tree has been reduced to a single root 
node and the results of both permutations are col-
lected, the node will contain all eight alternative 
translations ranked according to the language 
model, so that the best one, possibly ?the tall boy?, 
can be selected as overall sentence translation. 
3 Node Merge 
The operation of node merge consists of taking all 
possible translations for the two nodes and conca-
tenating them in either sequential or reverse order, 
adding them to the translation of the parent node 
and dropping the child. 
In certain cases though, for example idiomatic 
phrases, the best translation is not obtained by 
combining the individual translations of each 
word, but instead a proper translation might be 
found in the Phrase Translation Table (PT). Hence 
besides performing combination of translations, 
we also consider the sub-tree rooted at the head 
node hri of node ri. We consider the phrase corres-
ponding to the leaves of the sub-tree rooted at hri 
and all children already merged into it, including 
ri: if this phrase is present in the PT, then its trans-
lations are also added to the node. 
This is sometimes useful, since it allows the de-
coder to exploit phrases that only correspond to 
partial sub-trees that it will otherwise miss. 
4 Reordering Rules 
In order to restrict the number of permutations to 
consider, we introduce a reordering step based on 
rules that examine the dependency tree of the 
source sentence. 
The rules are dependent on the language pair 
and they can be learned automatically from the 
corpus. 
We report first a simple set of hand crafted rules 
devised for the pair Italian-English that we used as 
a baseline. 
The default ordering is to start numbering the 
left children of a node backwards, i.e. the node 
closer to the head comes first, then continuing 
with the right children in sequential order. 
Special rules handle these cases: 
1) The head is a verb: move an adverb child to 
first position.  This lets a sequence of VA VM 
V R be turned into VA VM R V, where VA is 
the POS for auxiliary verbs, VM for modals, 
V for main verb and R for adverbs. 
2) The head is a noun: move adjectives or prepo-
sitions immediately following the head to the 
beginning. 
Il ragazzo alto 
the boy tall 
boy the tall 
tall the boy 
tall boy the 
Il ragazzo 
the boy 
boy the 
alto 
tall 
high 
81
4.1 Learning Reordering Rules 
In order to learn the reordering rules we created a 
word-aligned parallel corpus from 1.3 million 
source sentences selected from the parallel corpus. 
The corpus is parsed and each parse tree is ana-
lyzed using the giza++ word alignments of its 
translation to figure out node movements. 
For each source-language word, we estimate a 
unique alignment to a target-language word. If the 
source word is aligned to more than one target 
word we select the first one appearing in the 
alignment file. If a source word is not aligned to 
any word, we choose the first alignment in its des-
cendants in the dependency tree. If no alignment 
can be found in the descendants, we assume that 
the word stays in its original position. 
We reorder the source sentence according to 
this alignment, putting it in target-language order. 
We produce a training event consisting of a pair 
(context, offset) for each non-root word. The con-
text of the event consists of a set of features (the 
POS tag of a word, its dependency tag and the 
POS of its head) extracted for the word and its 
children. The outcome of the event is the offset of 
the word relative to its parent (negative for words 
that appear on the left of their parent in target-
language order, positive otherwise). 
We calculate the relative frequency of each 
event conditioned on the context, deriving rules of 
the form: 
(context, offset, Pr[Offset = offset | Context = 
context]). 
During decoding, we compute a reordering posi-
tion for each source word by adding to the word 
position to the offset predicted by the most likely 
reordering rule matching the word context (or 0 if 
no matching context is found). 
The reordering position drives the children 
combination procedure in the decoder. 
Our reordering rules are similar to those pro-
posed by Xu at al. (2009), except that we derive 
them automatically from the training set, rather 
than being hand-coded. 
4.2 Beam Search 
Search through the space of hypotheses generated 
is performed using beam search that keeps in each 
node the list of the top best translations for the 
node. The score for the translation is computed 
using the weights of the individual phrases that 
make up the translation and the overall LM proba-
bility of the combination. 
The scores are computed querying the standard 
Moses Phrase Table and the LM for the target lan-
guage; other weights uses by moses such as the 
reordering weights or the future cost estimates are 
discarded or not computed. 
5 The Model 
A mathematical model of the dependency based 
translation process can be formulated as follows. 
Consider the parse of a sentence f of length n. 
Let R denote all topological ordering of the nodes 
according to the dependency tree. 
Let fr denote the parse tree along with a consis-
tent node ordering r. Each ordering gives rise to 
several different translations. Let Er denote the set 
of translations corresponding to fr. We assign to 
each translation er  Er a probability according to 
the formula below. The final translation is the best 
result obtained through combinations over all or-
derings. 
Error! Objects cannot be created from editing field 
codes. 
Where er denotes any of the translations of f ob-
tained when nodes are combined according to 
node ordering r.  
The probability of a translation er corresponding 
to a node ordering r for a phrase f, p(er | f ) is de-
fined as: 
Error! Objects cannot be created from editing field 
codes. 
where 
Error! Objects cannot be created from editing 
field codes. andError! Objects cannot be 
created from editing field codes.denote the leaf 
words from node ri and those of its head node hri,  
respectively. 
Error! Objects cannot be created from edit-
ing field codes.is either Error! Objects cannot 
82
be created from editing field codes.or Error! 
Objects cannot be created from editing field 
codes. 
p(f, e) = pPT(str(f), e) if str(f)  PT 
str(f) is the sentence at the leaves of node ri 
pLM is the Language Model probability 
pPT is the Phrase Table probability 
6 Related Work 
Yamada and Knight (2001) introduced a syntax-
based translation model that incorporated source-
language syntactic knowledge within statistical 
translation. Many similar approaches are based on 
constituent grammars, among which we mention 
(Chiang, 2005) who introduced hierarchical trans-
lation models. 
The earliest approach based on dependency 
grammars is the work by Ashlawi et al (2000), 
who developed a tree-to-tree translation model, 
based on middle-out string transduction capable of 
phrase reordering. It translated transcribed spoken 
utterances from English to Spanish and from Eng-
lish to Japanese. Improvements were reported over 
a word-for-word baseline. 
Ambati (2008) presents a survey of other ap-
proaches based on dependency trees. 
Quirk et. al. (2005) explore a tree-to-tree ap-
proach, called treelet translation, that extracts tree-
lets, i.e. sub-trees, from both source and target 
language by means of a dependency parser. A 
word aligner is used to align the parallel corpus. 
The source dependency is projected onto the target 
language sentence in order to extract treelet trans-
lation pairs. Given a foreign input sentence, their 
system first generates its dependency tree made of 
treelets. These treelets are translated into treelets 
of the target language, according to the dependen-
cy treelet translation model. Translated treelets are 
then reordered according to a reorder model. 
The ordering model is trained on the parallel 
corpus. Treelet translation pairs are used for de-
coding. The reordering is done at the treelet level 
where all the child nodes of a node are allowed all 
possible orders. The results show marginal im-
provements in the BLEU score (40.66) in compar-
ison with Pharaoh and MSR-MT.  But the treelet 
translation algorithm is more than an order of 
magnitude slower. 
Shen et. al. (2008) present a hierarchical ma-
chine translation method from string to trees. The 
scheme uses the dependency structure of the target 
language to use transfer rules while generating a 
translation. The scheme uses well-formed depen-
dency structure which involves fixed and floating 
type structures. The floating structures allow the 
translation scheme to perform different concatena-
tion, adjoining and unification operations still be-
ing within the definition of well-formed structures. 
While decoding the scheme uses the probability of 
a word being the root, and also the left-side, right-
side generative probabilities. The number of rules 
used varies from 27 M (for a string to dependency 
system) to 140 M (baseline system). The perfor-
mance reached 37.25% for the system with 3-
grams, 39.47% for 5-grams. 
Marcu and Wong (2002) propose a joint- prob-
ability model. The model establishes a correspon-
dence between a source phrase and a target phrase 
through some concept. The reordering is inte-
grated into the joint probability model with the 
help of: 
3) Phrase translation probabilities Error! Ob-
jects cannot be created from editing field 
codes. denoting the probability that concept ci 
generates the translation Error! Objects can-
not be created from editing field codes. for 
the English and Error! Objects cannot be 
created from editing field codes. for the for-
eign language inputs. 
4) Distortion probabilities based on absolute po-
sitions of the phrases.  
Decoding uses a hill-climbing algorithm.  Perfor-
mance wise the approach records an average 
BLEU score of 23.25%, with about 2% of im-
provement over the baseline IBM system. 
Zhang et. al. (2007) present a reordering model 
that uses linguistic knowledge to guide both 
phrase reordering and translation between linguis-
tically correct phrases by means of rules. Rules are 
encoded in the form of weighted synchronous 
grammar and express transformations on the parse 
trees. They experiment also mixing constituency 
and dependency trees achieving some improve-
83
ments in BLEU score (27.37%) over a baseline 
system (26.16%). 
Cherry (2008) introduces a cohesion feature in-
to a traditional phrase based decoder. It is imple-
mented as a soft constraint which is based on the 
dependency syntax of the source language. He 
reports a BLEU score improvement on French-
English translation. 
The work by Xu et al (2009) is the closest to 
our approach. They perform preprocessing of the 
foreign sentences by parsing them with a depen-
dency parser and applying a set of hand written 
rules to reorder the children of certain nodes. The 
preprocessing is applied to both the training cor-
pus and to the sentences to translate, hence after 
reordering a regular hierarchical system can be 
applied. Translation experiments between English 
and five non SVO Asian languages show signifi-
cant improvements in accuracy in 4 out of 5 lan-
guages. With respect to our approach the solution 
by Xu et al does not require any intervention on 
the translation tools, since the sentences are rewrit-
ten before being passed to the processing chain: on 
the other hand the whole collection has to undergo 
full parsing with higher performance costs and 
higher dependency on the accuracy of the parser. 
Dyer and Resnik (2010) introduce a translation 
model based on a Synchronous Context Free 
Grammar (SCFG). In their model, translation 
examples are stored as a context-free forest. The 
process of translation comprise two steps: tree-
based reordering and phrase transduction. While 
reordering is modeled with the context-free forest, 
the reordered source is transduced into the target 
language by a Finite State Transducer (FST). The 
implemented model is trained on those portions of 
the data which it is able to generate. An increase 
of BLEU score is achieved for Chinese-English 
when compared to the phrase based baseline. 
Our approach is a true tree-to-string model and 
differs from (Xu et al, 2009), which uses trees 
only as an intermediate representation to rearrange 
the original sentences. We perform parsing and 
reordering only on the phrases to be translated. 
The training collection is kept in the original form, 
and this has two benefits: training is not subject to 
parsing errors and our system can share the same 
model of a regular hierarchical system. 
Another difference is in the selection of transla-
tion options: our method exploits the parse tree to 
select grammatical phrases as translation options. 
7 Implementation 
The prototype decoder consists of the following 
components: 
1) A specialized table lookup server, providing 
an XML-RPC interface for querying both the 
phrase table and the LM 
2) A parser engine based on DeSR (DeSR, 2009) 
3) A reordering algorithm that adds ordering 
numbers to the output produced by DeSR in 
CoNLL-X format. Before reordering, this step 
also performs a restructuring of the parse tree, 
converting from the conventions of the Italian 
Tanl Treebank to a structure that helps the 
analysis. In particular it converts conjunctions, 
which are represented as chains, where each 
conjunct connects to the previous, to a tree 
where they are all dependent of the same head 
word. Compound verbs are also revised: in the 
dependency tree each auxiliary of a verb is a 
direct child of the main verb. For example in 
?avrebbe potuto vedere?, both the auxiliary 
?avrebbe? and the modal ?potuto? depend on 
the verb ?vedere?.  This steps groups all aux-
iliaries of a verb under the first one, i.e. ?potu-
to?. This helps so that the full auxiliary can be 
looked up separately from the verb in the 
phrase table. 
4) A decoder that uses the output produced by 
the reordering algorithm, queries the phrase 
table and performs a beam search on the hypo-
theses produced according to the suggested 
reordering. 
8 Experimental Setup and Results 
Moses (Koehn et al, 2007) is used as a baseline 
phrase-based SMT system. The following tools 
and data were used in our experiments:  
1) the IRSTLM toolkit (Marcello and Cettolo, 
2007) is used to train a 5-gram language mod-
84
el with Kneser-Ney smoothing on a set of 4.5 
million sentences from the Italian Wikipedia. 
2) the Europarl version 6 corpus, consisting of 
1,703,886 sentence pairs, is used for training. 
A tuning set of 2000 sentences from ACL 
WMT 2007 is used to tune the parameters.  
3) the model is trained with lexical reordering. 
4) the model is tuned with mert (Bertoldi, et al ) 
5) the official test set from ACL WMT 2008 
(Callison-Burch et al, 2008), consisting of 
2000 sentences, is used as test set. 
6) the open-source parser DeSR (DeSR, 2009) is 
used to parse Italian sentences, trained on the 
Evalita 2009 corpus (Bosco et al, 2009). Pars-
er domain adaptation is obtained by adding to 
this corpus a set of 1200 sentences from the 
ACL WMT 2005 test set, parsed by DeSR and 
then corrected by hand. 
Both the training corpora and the test set had to be 
cleaned in order to normalize tokens: for example 
the English versions contained possessives split 
like this ?Florence' s?. We applied the same toke-
nizer used by the parser which conforms to the 
PTB standard. 
DeSR achieved a Labeled Accuracy Score of 
88.67% at Evalita 2009, but for the purpose of 
translation, just the Unlabeled Accuracy is rele-
vant, which was 92.72%. 
The table below shows the results of our decod-
er (Desrt) in the translation from Italian to English, 
compared to a baseline Moses system trained on 
the same corpora and to the online version of 
Google translate. 
Desrt was run with a beam size of 10, since ex-
periments showed no improvements with a larger 
beam size. 
We show two versions of Desrt, one with parse 
trees as obtained by the parser and one (Desrt 
gold) where the trees were corrected by hand. The 
difference is minor and this confirms that the de-
coder is robust and not much affected by parsing 
errors. 
System BLEU NIST 
Moses 29.43 7.22 
Moses tree phrases 28.55 7.10 
Desrt gold 26.26 6.88 
Desrt 26.08 6.86 
Google Translate 24.96 6.86 
Desrt learned 24.37 6.76 
Table 1. Results of the experiments. 
Since we used the same phrase table produced by 
Moses also for Desrt, Moses has an advantage, 
because it can look up n-grams that do not corres-
pond to grammatical phrases, which Desrt never 
considers. In order to determine how this affects 
the results, we tested Moses restricting its choice 
to phrases corresponding to treelets form the parse 
tree. The result is shown in the row in the table 
labeled as ?Moses tree phrases?. The score is low-
er, as expected, but this confirms that Desrt makes 
quite good use of the portion of the phrase table it 
uses. 
Since the version of the reordering algorithm we 
used produces a single reordering, the Desrt de-
coder has linear complexity on the length of the 
sentence. Indeed, despite being written in Python 
and having to query the PT as a network service, it 
is quite faster than Moses.  
9 Error Analysis 
Despite that fact that Desrt is driven by the parse 
tree, it is capable of selecting fairly good and even 
long sentences for look up in the phrase table. 
How close is the Desrt translation from those of 
the Moses baseline can be seen from this table: 
 1-gram 2-gram 3-gram 4-gram 5-gram 
NIST 7.28 3.05 1.0 0.27 0.09 
BLEU 84.73 67.69 56.94 48.59 41.78 
Sometimes Desrt fails to select a better translation 
for a verb, since it looks up prepositional phrases 
separately from the verb, while Moses often con-
nects the preposition to the verb. 
This could be improved by performing a check 
and scoring higher translations which include the 
translation of the preposition dependent on the 
verb. 
Another improvement could come from creating 
phrase tables limited to treelet phrases, i.e. phrases 
corresponding to treelets from the parser. 
85
10 Enhancements 
The current algorithm needs to be improved to 
fully deal with certain aspects of long distance 
dependencies. Consider for example the sentence 
?The grass around the house is wet?. The depen-
dency tree of the sentence contains the non-
contiguous phrases ?The grass? and ?wet?, whose 
Italian translation must obey a morphological 
gender agreement between the subject ?grass? 
(?erba?, feminine), and the adjective ?wet? (?bag-
nata?). 
However, the current combination algorithm 
does not exploit this dependence, because the last 
phases of node merge will occur when the tree has 
been reduced to this: 
The PT however could tell us that ?erba bagnata? 
is more likely than ?erba bagnato? and allow us to 
score the former higher. 
11 Conclusions 
We have described a decoding algorithm guided 
by the dependency tree of the source sentence. By 
exploiting the dependency tree and deterministic 
reordering rules among the children of a node, the 
decoder is fast and can be kept simple by avoiding 
to consider multiple reorderings, to use reordering 
weights and to estimate future costs. 
There is still potential for improving the algo-
rithm exploiting information implicit in the PT in 
terms of morphological constraints, while main-
taining a simple decoding algorithm that does not 
involve complex grammatical transformation 
rules. 
The experiments show encouraging results with 
respect to state of the art PBT systems. We plan to 
test the system on other language pairs to see how 
it generalizes to other situations where phrase 
reordering is relevant. 
Acknowledgments 
Zauhrul Islam helped setting up our baseline sys-
tem and Niladri Chatterjie participated in the early 
design of the model.  
References 
G. Attardi. 2006. Experiments with a Multilanguage 
Non-Projective Dependency Parser. Proc. of the 
Tenth Conference on Natural Language Learning, 
New York, (NY). 
H. Alshawi, S. Douglas and S. Bangalore. 2000. 
Learning Dependency Translation Models as 
Collections of Finite State Head Transducers. 
Computational Linguistics 26(1), 45?60. 
N. Bertoldi, B. Haddow, J-B. Fouet. 2009. Improved 
Minimum Error Rate Training in Moses. In Proc. of 
3rd MT Marathon, Prague, Czech Republic. 
V. Ambati. 2008. Dependency Structure Trees in Syn-
tax Based Machine Translation. Adv. MT Seminar 
Course Report. 
C. Bosco, S. Montemagni, A. Mazzei, V. Lombardo, F. 
Dell?Orletta and A. Lenci. 2009. Evalita?09 Parsing 
Task: comparing dependency parsers and treebanks. 
Proc. of Evalita 2009. 
P. F. Brown, V. J. Della Pietra, S. A. and  R. L. Mercer. 
1993. The Mathematics of Statistical Machine Trans-
lation: Parameter Estimation. Computational Lin-
guistics, 19(2), 263?311. 
Callison-Burch et al 2008. Further Meta-Evaluation of 
Machine Translation. Proc. of ACL WMT 2008. 
C. Cherry. 2008. Cohesive phrase-based decoding for 
statistical machine translation. Proc. of ACL 2008: 
HLT. 
D. Chiang. 2005. A hierarchical phrase-based model for 
statistical machine translation. In Proc. of ACL 2005.  
DeSR. Dependency Shift Reduce parser. 
http://sourceforge.net/projects/desr/ 
Y. Ding, and M. Palmer. 2005.  Machine Translation 
using Probabilistic Synchronous Dependency Inser-
tion Grammar.  Proc. of ACL?05, 541?548. 
C. Dyer and P. Resnik. 2010. Context-free reordering, 
finite-state translation. Proc. of HLT: The 2010 
Annual Conference of the North American Chapter 
of the ACL, 858?866. 
grass 
L? erba intorno alla casa 
is 
? 
wet 
bagnata 
bagnato 
 
 
86
F. Marcello, M. Cettolo. 2007. Efficient Handling of N-
gram Language Models for Statistical Machine 
Translation. Workshop on Statistical Machine Trans-
lation 2007. 
M. Galley and C. D. Manning. 2008. A Simple and 
Effective Hierarchical Phrase Reordering Model. In 
Proc. of EMNLP 2008. 
R. Hwa, P. Resnik, A. Weinberg, C. Cabezas and O. 
Kolak, 2005.  Bootstrapping Parsers via Syntactic 
Projection across Parallel texts. Natural Language 
Engineering 11(3), 311-325. 
P. Koehn, F. J. Och and D. Marcu.  2003. Statistical 
Phrase-Based Translation. Proc. of Human Lan-
guage Technology and North American Association 
for Computational Linguistics Conference 
(HLT/NAACL), 127?133. 
P. Koehn, H. Hoang, A. Birch, C. Callison-Burch, M. 
Federico, N. Bertoldi, B. Cowan, W. Shen, C. Mo-
ran, R. Zens, C. Dyer, O. Bojar, A. Constantin, and 
E. Herbst. 2007. Moses: Open source toolkit for sta-
tistical machine translation. In Proc. of the 45th An-
nual Meeting of the ACL, demonstration session, 
177?180, Prague, Czech Republic. 
P. Koehn. 2009. Statistical Machine Translation.  
Cambridge University Press. 
Y. Liu, Q. Liu and S. Lin. 2006. Tree-to-string Align-
ment Template for Statistical Machine Translation, 
In Proc. of COLING-ACL. 
D. Marcu and W. Wong. 2002. A Phrase-Based Joint 
Probability Model for Statistical Machine Transla-
tion. Proc. Empirical Methods in Natural Language 
Processing (EMNLP), 133?139. 
C. Quirk, A. Menzes and C. Cherry. 2005. Dependency 
Treelet Translation: Syntactically Informed Phrasal 
SMT. Proc. 43rd Annual Meeting of the ACL, 217?
279. 
S. Libin, J. Xu and R. Weischedel. 2008. A New String-
to-Dependency Machine Translation Algorithm with 
a Target Dependency Language Model. Proc. ACL-
08, 577?585. 
F. J. Och 2002. Statistical Machine Translation: From 
Single Word Models to Alignment Template. Ph.D. 
Thesis, RWTH Aachen, Germany. 
F.J. Och, H. Ney. 2000. Improved Statistical Alignment 
Models. Proc. of the 38th Annual Meeting of the 
ACL.  Hong Kong, China. 440-447. 
K. Yamada and K. Knight. 2001. A Syntax-Based Sta-
tistical Translation Model. Proc. 39th Annual Meet-
ing of ACL (ACL-01), 6?11. 
P. Xu, J. Kang, M. Ringgaard and F. Och. 2009. Using 
a Dependency Parser to Improve SMT for Subject-
Object-Verb Languages. Proc. of NAACL 2009, 245?
253, Boulder, Colorado. 
D. Zhang, Mu Li, Chi-Ho Li and M. Zhou.  2007. 
Phrase Reordering Model Integrating Syntactic 
Knowledge for SMT.  Proc. Joint Conference on 
Empirical Methods in Natural Language Processing 
and Computational  Natural Language Processing: 
533?540. 
 
 
87
