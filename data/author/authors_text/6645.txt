BUPT Systems in the SIGHAN Bakeoff 2007 
Ying Qin   Caixia Yuan   Jiashen Sun   Xiaojie Wang 
Center of Intelligent Science and Technology Research 
Beijing University of Posts and Telecommunications 
Beijing, 100876, China 
qinyingmail@163.com, yuancx@gmail.com, 
b.bigart911@gmail.com, xjwang@bupt.edu.cn 
 
 
Abstract 
Chinese Word Segmentation(WS), Name 
Entity Recognition(NER) and Part-Of-
Speech(POS) are three important Chinese 
Corpus annotation tasks. With the great 
improvement in these annotations on some 
corpus, now, the robustness, a capability of 
keeping good performances for a system by 
automatically fitting the different corpus 
and standards, become a focal problem. 
This paper introduces the work on 
robustness of WS and POS annotation 
systems from Beijing University of Posts 
and Telecommunications(BUPT), and two 
NER systems. The WS system combines a 
basic WS tagger with an adaptor used to fit 
a specific standard given. POS taggers are 
built for different standards under a two 
step frame, both steps use ME but with 
incremental features. A multiple 
knowledge source system and a less 
knowledge Conditional Random Field 
(CRF) based systems are used for NER. 
Experiments show that our WS and POS 
systems are robust. 
1 Introduction 
In the last SIGHAN bakeoff, there is no single 
system consistently outperforms the others on 
different test standards of Chinese WS and NER 
standards(Sproat and Emerson, 2003). 
Performances of some systems varied significantly 
on different corpus and different standards, this 
kind of systems can not satisfy demands in 
practical applications. The robustness, a capability 
of keeping good performances for a system by 
automatically fitting the different corpus and 
standard, thus become a focal problem in WS and 
NER, it is the same for Chinese Part-of-
Speech(POS) task which is new in the SIGHAN 
bakeoff 2007.  
It is worthy to distinguish two kinds of different 
robustness, one is for different corpus (from 
different sources or different domain and so on) 
under a same standard, we call it corpus robustness, 
and another is for different standards (for different 
application goals or demands and so on) for a same 
corpus. We call it standard robustness. The 
SIGHAN bakeoff series seems to focus more on 
later. We think corpus robustness should be 
received more attentions in the near future. 
We participant all simplified Chinese track on 
WS, NER and POS task in the SIGHAN bakeoff 
2007. There are more than two tracks for WS and 
POS. This gives us a chance to test the robustness 
of our systems. This paper reports our WS, NER 
and POS systems in the SIGHAN Bakeoff 2007, 
especially on the work of achieving robustness of 
WS and POS systems.  
This paper is arranged as follows, we introduce 
our WS, NER and POS system separately in 
section 2, section 3 and section 4, experiments and 
results are listed in section 5, finally we draw some 
conclusions. 
2 Word Segmentation 
WS system includes three sequent steps, which are 
basic segmentation, disambiguation and out-of 
vocabulary (OOV) recognition. In each step, we 
construct a basic work unit first, and then have an 
adaptor to tune the basic unit to fit different 
standards. 
94
Sixth SIGHAN Workshop on Chinese Language Processing
2.1 Basic Segmentation 
For constructing a basic work unit for WS, a 
common wordlist containing words ratified by four 
different segmentation standards (from SXU, NCC, 
PKU and CTB separately) are built. We finally get 
64,000 words including about 1500 known entity 
words as the common wordlist. A forward-
backward maximum matching algorithm with the 
common wordlist is employed as the common unit 
of our basic segmentor.  
To cater for different characteristics in different 
segmentation standards, we construct another 
wordlist containing words for each specification.  
A wordlist based adaptor is built to implement the 
tuning task after basic segmentation.  
2.2 Disambiguation 
Disambiguation of overlapping Ambiguity (OA) is 
a major task in this step.  
Strings with OA are also detected during basic 
forward-backward maximum matching in basic 
WS step. These strings are common OA strings for 
different standards. Class-based bigram model is 
applied to resolve the ambiguities. In class-based 
bigram, all named entities, all punctuation and 
factoids is one class respectively and each word is 
one class. We train the bigram transition 
probability based on the corpus of Chinese 
People?s Daily 2000 newswire.  
For corpus from different standards, overlapping 
ambiguity strings with less than 3 overlapping 
chain are extracted from each train corpus. We do 
not work on all of them but on some strings with a 
frequency that is bigger than a given value. A 
disambiguation adaptor using the highest 
probability segmentations is built for OA strings 
from each different standard.  
2.3 OOV Recognition 
In OOV recognition, we have a similar model 
which consists of a common part based on 
common characteristics and an individual part 
automatically constructed for each standard. 
We divide OOV into factoid which contains 
non-Chinese characters like date, time, ordinal 
number, cardinal number, phone number, email 
address and non-factoid.  
Factoid is recognized by an automaton. To 
compatible to different standards, we also built 
core automata and several adaptors. 
Non-factoid is tackled by a unified character-
based segmentation model based on CRF. We first 
transform the WS training dataset into character-
based two columns format as the training dataset in 
NER task. The right column is a boundary tag of 
each character. The boundary tags are B I and S, 
which B is the tag of the first character of a word 
which contains more than two characters, I is the 
other non-initial characters in a word, S is for the 
single character word. Then the transformed 
training data is used to train the CRF model. 
Features in the model are current character and 
other three characters within the context and 
bigrams.  
The trigger of non-factoid recognition is 
continual single character string excluding all the 
punctuations in a line after basic word matching, 
disambiguation and factoid incorporation. The 
model will tell whether these consecutive 
characters can form multi-character words in a 
given context. 
At last, several rules are used to recognize some 
proper names separated by coordinate characters 
like ???, ???, ??? and symbol ??? in foreign 
person names.  
3 Named Entity Recognition 
We built two NER systems separately. One is a 
unified named entity model based on CRF. It used 
only a little knowledge include a small scale of 
entity dictionary, a few linguistic rules to process 
some special cases such as coordinate relation in 
corpus and some special symbols like dot among a 
transliteration foreign person name.  
Another one is an individual model for each 
kind of entity based on Maximum Entropy where 
more rules found from corpus are used on entity 
boundary detection. Some details on this model 
can be found in Suxiang Zhang et al2006. 
4 POS Tagging 
In POS, we construct POS taggers for different 
standards under a two steps frame, both steps use 
ME but with incremental features. First, we use 
normal features based Maximum Entropy (ME) to 
train a basic model, and then join some 
probabilistic features acquired from error analysis 
to training a finer model.  
95
Sixth SIGHAN Workshop on Chinese Language Processing
4.1 Normal Features for ME 
In the first step of feature selection for ME 
tagger, we select contextual syntactic features for 
all words basing on a series of incremental 
experiments. 
For shrinking the search space, the model only 
assigns each word a label occurred in the training 
data. That is, the model builds a subset of all POS 
tags for each token and restricts all possible labels 
of a word within a small candidate set, which 
greatly saves computing cost. 
We enlarged PKU training corpus by using one 
month of Peking University's China Daily corpus 
(June in 2003) and CTB training corpus by using 
CTB 2.0 data which includes 325 passages. 
To adapt with the given training corpus, the 
samples whose labels are not included in the 
standard training data were omitted firstly. After 
preprocessing, we get two sets of training samples 
for PKU and CTB with 1178 thousands tokens and 
206 thousands tokens respectively. But the NCC 
test remains its original data due to we have no 
corpus with this standard. 
4.2 Probabilistic feature for ME 
By detecting the label errors when training and 
testing using syntactic features such as words 
around the current tokens and tags of previous 
tokens, words with multiple possible tags are 
obviously error-prone. We thus define some 
probabilistic features especially for multi-tag 
words.  
We find labels of these tokens are most closely 
related to POS tag of word immediately previous 
to them. For instance, in corpus of Peking 
University, word ?Report? has three different tags 
of ?n(noun), v(verb), vn(noun verb)?. But when we 
taken into account its immediately previous words, 
we can find that when previous word's label is 
?q(quantifier)?, ?Report? is labeled as ?n? with a 
frequency of 91.67%, ?v? with a frequency of 
8.33% and ?vn? with a frequency of 0.0%. We can 
assume that ?Report? is labeled as ?n? with the 
91.67% probability when previous word's label is 
?q?, and so on. 
 Such probability is calculated from the whole 
training data and is viewed as discriminating 
probabilistic feature when choosing among the 
multiple tags for each word.  But for words with 
only one possible tag, no matter what the label of 
previous word is, the label for them is always the 
tag occurred in the training data.  
5 Experiments 
We participant all simplified Chinese tracks on WS, 
NER and POS task in the SIGHAN bakeoff 2007. 
Our systems only deal with Chinese in GBK code. 
There are some mistakes in some results submitted 
to bakeoff organizer due to coding transform from 
GBK to UTF-16. We then use WS evaluation 
program in the SIGHAN bakeoff 2006 to re-
evaluate WS system using same corpus, as for POS, 
since there is no POS evaluation in the SIGHAN 
bakeoff 2006, we implement a evaluation using 
ourselves? program using same corpus.  
Table 1 shows evaluation results of WS using 
evaluation programs from both the SIGHAN 
bakeoff 2007 and the SIGHAN bakeoff 2006. 
Table 2 lists evaluation results of NER using 
evaluation program from the SIGHAN bakeoff 
2007. Table 3 gives evaluation results of POS 
using evaluation programs from both the SIGHAN 
bakeoff 2007 and ourselves(BUPT).  
 
 
Track UTF-16 
(SIGHAN4) 
GBK 
(SIGHAN 3) 
CTB 0.9256 0.950 
SXU 0.8741 0.969 
NCC 0.9592 0.972 
Table 1. WS results (F-measure) 
 
 
SIGHAN 4 R P F 
System-1 0.8452 0.872 0.8584 
System-2 0.8675 0.9163 0.8912 
Table 2. NER results (F-measure) 
 
 
Track UTF-16 
(SIGHAN 4) 
GBK 
(BUPT) 
CTB 0.9689 0.9689 
NCC 0.9096 0.9096 
PKU 0.6649 0.9462 
Table 3. POS Results (F-measure) 
 
From the table 1 and Table 3, we can find our 
system is robust enough. WS system keeps at a 
relatively steady performance. Difference in POS 
96
Sixth SIGHAN Workshop on Chinese Language Processing
between NCC and other two tracks is mainly due 
to the difference of the training corpus.  
6 Conclusion 
Recently, the robustness, a capability of keeping 
good performances for a system by automatically 
fitting the different corpus and standards, become a 
focal problem. This paper introduces our WS, NER 
and POS systems, especially on how they can get a 
robust performance. 
The SIGHAN bakeoff series seems to focus 
more on standard robustness. We think corpus 
robustness should be received more attentions in 
the near future. 
 
Acknowledgement 
Thanks to Zhang Yan, Zhang Bichuan, Zhang 
Taozheng, Liu Haipeng and Jiang Huixing for all 
the work they done to make the WS, NER and 
POS systems go on wheels in a very short time.  
References 
Berger, A., Della Pietra, S. and Della Pietra, V.: A 
Maximum Entropy Approach to Natural 
Language Processing. Computational 
Linguistics. 22(1): pp 39-71, 1996. 
Thomas Emerson. 2005. The Second International 
Chinese Word Segmentation Bakeoff. In 
Proceedings of the Fourth SIGHAN Workshop 
on Chinese Language Processing, Jeju Island, 
Republic of Korea. 
NanYuan Liang. 1987 A Written Chinese 
Segmentation system? CDWS.  Journal of 
Chinese Information Processing, Vol.2: 44-52 
YaJuan Lv, Tie-jun Zhao, et al 2001. Leveled 
unknown Chinese Words resolution by dynamic 
programming. Journal Information Processing, 
15(1): 28-33.  
Yintang Yan, XiaoQiang Zhou. 2000. Study of 
Segmentation Strategy on Ambiguous Phrases 
of Overlapping Type  Journal of The China 
Society For Scientific and Technical Information  
Vol. 19 , ?6  
Richard Sproat and Thomas Emerson. 2003. The 
First International Chinese Word Segmentation 
Bakeoff. In Proceedings of the Second SIGHAN 
Workshop on Chinese Language Processing, 
Sapporo, Japan. 
Caixia Yuan, Xiaojie Wang, Yixin Zhong. Some 
Improvements on Maximum Entropy Based 
Chinese POS Tagging. The Journal of China 
Universities of Posts and Telecommunications, 
Vol. 13, pp 99-103, 2006. 
Suxiang Zhang, Xiaojie Wang, Juan Wen, Ying 
Qin, Yixin Zhong. A Probabilistic Feature 
Based Maximum Entropy Model for Chinese 
Named Entity Recognition, in proceedings of 
21st International Conference on the Computer 
Processing of Oriental Languages,December 
17-19, 2006, Singapore.  
 
 
97
Sixth SIGHAN Workshop on Chinese Language Processing
Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing, pages 158?161,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Word Segmentation and Named Entity Recognition for SIGHAN 
Bakeoff3 
 
Zhang Suxiang 
CISTR,  
Beijing University of 
Posts and 
Telecommunications 
zsuxiang@163.com 
Qin Ying  
CISTR,  
Beijing University of 
Posts and 
Telecommunications 
qinyingmail@163.com 
Wen Juan 
CISTR,  
Beijing University of 
Posts and 
Telecommunications 
mystery999@163.com 
Wang Xiaojie 
CISTR,  
Beijing University of 
Posts and 
Telecommunications 
xjwang@bupt.edu.cn
 
 
Abstract 
We have participated in three open tracks 
of Chinese word segmentation and 
named entity recognition tasks of 
SIGHAN Bakeoff3. We take a 
probabilistic feature based Maximum 
Entropy (ME) model as our basic frame 
to combine multiple sources of 
knowledge. Our named entity recognizer 
achieved the highest F measure for 
MSRA, and word segmenter achieved the 
medium F measure for MSRA. We find 
effective combining of the external 
multi-knowledge is crucial to improve 
performance of word segmentation and 
named entity recognition. 
1 Introduction 
Word Segmentation (WS) and Named Entity 
Recognition (NER) are two basic tasks for 
Chinese Processing. The main difficulty is 
ambiguities widely exist in these two tasks. Our 
system is thus pay special attentions on various 
ambiguities resolution. After preprocessing we 
take Maximum Entropy (ME) model as the 
unified frame for WS and NER. ME is a 
effective model which often used to combine 
multiple sources of knowledge into various 
features. For finer-grain utilization of features, 
we use probabilistic features instead of binary 
features normally used. By exploring some often 
used features and some new features, our system 
performs well in this SIGHAN contest.  
In the rest sections of this paper, we give a 
brief introduction to our system sequentially. 
Section 2 describes the preprocessing in the 
system, including rough segmentation and 
factoid identification. Section 3 is on ambiguity 
resolution of WS. NER is introduced in Section 4. 
We give some experimental results in Section 5. 
Finally we draw some conclusions. 
2 Preprocessing 
The first step in preprocessing is to do a rough 
segmentation. By using both Forward Maximum 
Matching (FMM) and Backward Maximum 
Matching (BMM) approaches, we get an initial 
segmentation simultaneously detecting some of 
segmentation ambiguities in text. We use two 
different wordlists in this step. One is a basic 
wordlists with about 60 thousands words. We 
think this wordlist is relatively steady in Chinese. 
Another includes some words from special 
training corpus.  
We then cope with factoid recognition by 
using automata. Four automata are built to 
identify time, date, number and other (like 
telephone number and model of product) 
respectively. For covering some exceptional 
structures, we use some templates to post-
process some outputs from automata. 
Overlapping and combination ambiguities 
detected in preprocessing will be treated in next 
round of our system. It is the topic of next 
section. 
3 Disambiguation 
3.1 Overlapping ambiguity 
We only detect overlapping ambiguity with 
length of chain no more than 3 because these 
kinds of overlapping account for over 98% of all 
occurrences according to (Yan, 2000). The class-
based bigram model trained on tagged corpus of 
People?s Daily 2000 (about 12 million Chinese 
characters) is applied to resolve the ambiguities. 
In class-based bigram, all named entities, all 
punctuation and factoids is one class separately 
and each word is one class. For MSRA test we 
158
evaluate the performance of our overlapping 
disambiguation with precision of 84.1%. 
3.2 Combination ambiguity 
We use some templates to describe the POS 
properties of combination ambiguity and their 
segmentation words. In our system there are 155 
most frequent combination words. Due to the 
fact that instances of combination ambiguity is 
deficient in given training corpus, to enlarge 
training examples we convert the People Daily 
2000 to meet the standard of different guidelines 
then extract examples for training besides the 
given training corpora. For example, ??  is a 
combination ambiguity according to the 
guideline of MSRA whereas it is always one unit 
??in People Daily 2000. Noticing that when  
takes the sense of result, it is always tagged as a 
noun and a verb when it takes the meaning of 
fructification, we can easily enlarge the training 
examples of  ??.  
We then use ME model to combination 
ambiguity resolution. There are six features used 
in the model as below. 
(1) Contextual words; 
(2) Contextual characters; 
(3) Bigram collocations; 
(4) If the transfer probability of adjacent 
words to the target word exists; 
(5) If keywords indicate segmentation exists; 
(6) The most frequent segmentation from prior 
distribution 
 
4 Named entity recognition 
4.1 Personal name recognition 
We propose a probabilistic feature based 
maximum entropy approach to NER. Where, 
probabilistic feature functions are used instead of 
binary feature functions, it is one of the several 
differences between this model and the most of 
the previous ME based model. We also explore 
several new features in our model, which 
includes confidence functions, position of 
features etc. Like those in some previous works, 
we use sub-models to model Chinese Person 
Names, Foreign Names respectively, but we 
bring some new techniques in these sub-models. 
In standard ME, feature function is a binary 
function, for example, if we use CPN denotes the 
Chinese person Name, SN denotes Surname, a 
typical feature is: 
)1(),(
??
? ??=
otherwise
SNxandCPNy
yxfi ?
?????
 
But in Chinese, firstly, most of words used as 
surname are also used as normal words. The 
probabilities are different for them to be used as 
surname. Furthermore, a surname is not always 
followed by a given name, both cases are not 
binary. To model these phenomena, we give 
probability values to features, instead of binary 
values.  
For example, a feature function can be set 
value as follows: 
)2(
0
andCPNyif0.985 
),(
??
? ??=
otherwise
x
yxf
?
 
Or 
)3(
0
xCPNyif0.01805 
),(
??
? ??=
otherwise
and
yxf
?
 
Chinese characters used for translating foreign 
personal name are different from those in 
Chinese personal name. We built the foreign 
name model by collecting suffixes, prefixes, 
frequently-used characters, estimate their 
probabilities used in foreign personal name. 
These probabilities also used in model as 
probability features. 
We also design a confidence function for a 
character sequence nCCCW ...21=  to help model to 
estimate the probability of W as a person name. 
iC  may be a character or a word. Let Ff1 is 
probability of the C1, iMf is the probability of the 
iC , nEf  is the probability of the Cn. So the 
confidence function is 
)4(),(
12
1 nE
ni
iMF fffPERSONwK ++= ?
?<=<=
 
This function is included in ME frame as a 
feature. 
Candidate person name collection is the first 
step of NER. Since the ambiguity of Chinese 
word segmentation always exists. We propose 
some patterns for model different kind of 
segmentation ambiguity. Some labels are used to 
express specific roles of Chinese characters in 
person names. 
We have seven patterns as follows; first two 
patterns are non-ambiguity, while the others 
model some possible ambiguity in Chinese 
person name brought by word segmenter. 
(1) BCD: the Chinese personal name is 
composed of three Hanzi ((Chinese character). 
B: Surname of a Chinese personal name. 
159
C: Head character of 2-Hanzi given names. 
D: Tail character of 2-Hanzi of given names. 
(2) BD: the Chinese personal name is 
composed of two Hanzi (Chinese character). 
(3) BCH:  
H: the last given name and its next context are 
composed of a word. 
(4) UCD: 
U: the surname and its previous context are 
composed of a word.  
(5) BE: 
E: the first given name and the last given name 
are composed of a word.  
(6) UD: 
U: the surname and the first given name are 
composed of a word. 
(7) CD?The Chinese personal name is only 
composed of two given names. 
Based on the People?s Daily corpus and 
maximum entropy, we achieve models of 
Chinese personal name and transliterated 
personal name respectively.  
Here, How can we know whether a person 
name is composed of two or three Hanzi, we 
used another technology to limit boundary. We 
think out the co-appearing about the last given 
name and its next context, now, we have made a 
statistics about personal name and its next 
context to decide the length of the Chinese 
personal name. For example: 
????????????,  
In this sentence, we collect a candidate 
Chinese person name ???? ?, but the last 
given name ??? is a specific character, it has 
different meaning, now, we make a decision 
whether ??? is belong to personal name or not. 
????? 3)()( NRnumberNRnumber <  
So, ??? is not included in the personal name, 
???? is a correct choice. 
Another problem we have met is to recognize 
transliterated personal name, because many 
transliterated personal characters has included 
the Chinese surname, however, the condition that 
we can recognize the Chinese personal name is 
Chinese surname, therefore, a section of the 
transliterated personal name will often be 
recognized a Chinese personal name. 
In our system, we design a dynamitic priority 
method to check ambiguous character, when we 
examine a ambiguous character like ??? or ???, 
we will search different characters which maybe 
belong to Chinese personal name or transliterated 
personal name with forward and backward 
direction. According to the collection result, we 
will decide to use Chinese personal model or 
transliterated personal model to recognize 
personal name. 
For example: 
??/?/???/?/??/??/?/??/?/?/?/
?/?/?/?/?/?/?/?/??/??/??/??/?/
?/??/?/?/?/?/??/???/?? 
The correct candidate personal name is ???
?????? and not ?????. 
4.2 Location recognition 
We collect 196 keywords such like ??,?,?,?,
?,??, when the system search these keywords 
in a string, it will collect some characters or 
words which maybe belong to a location with 
backward direction, and the candidate location 
can be inputted into location model to recognize. 
The approach is similar to the personal name 
recognition, the difference is its contextual, the 
contextual used for location is 
2112 ++?? iiiii wwwww , which always can be 
used as feature during location entity recognition. 
We trained model based on the People?s Daily. 
We design some rules to help rectify wrong 
result, when a transliterated location name is lack 
of keyword like ???, it maybe recognized as a 
transliterated personal name. We collect some 
specific words list such as ???,?,??,??? 
to correct the wrong personal name. If the 
current word is in the list, the following words 
are accepted as candidate location entity. 
4.3 Organization recognition 
Organization name recognition is very different 
from other kinds of entities. An organization is 
often composed of several characters or words, 
and its length is dynamitic. According to 
statistical result about People?s Daily and MSR 
corpus, we decided the maximum length of an 
organization is 7 in a sentence.  
We computed the probability of every word or 
character of an organization, and defined the 
probability threshold. 
According to the different keyword, we 
designed sixteen classifiers; every classifier has 
its knowledge base, the different classifier can 
achieve organization recognition goal. 
We computed the probability threshold (>0.02) 
of a candidate organization.  
Combined the BIO-tagged method and the 
probability threshold, the organization can be 
recognized. 
160
4.4 Combination of Knowledge from 
Various Sources 
Human knowledge is very useful for NER. 
Knowledge from various sources can be 
incorporated into ME model, which are shown as 
follows. 
1. Chinese family name list (including 925 
items) and given names list (including 2453 
items):  
2. Transliterated character list (including 1398 
items). 
3. Location keyword list (including 607 items): 
If the word belongs to the list, 2~6 words before 
the salient word are accepted as candidate 
Location. 
4. Abbreviated location like ??/Beijing?, ??
/Tianjin? name list. Moreover, on Microsoft 
corpus, the word ??? of ?????? is also 
labeled as location ???/China?. 
5. Organization keyword list (including 875 
items): If the current word is in organization 
keyword list, 2~6 words before keywords are 
accepted as the candidate Organization. 
6. A location name dictionary. Some 
frequently used locations are included in the 
dictionary, like ???/United States? and ???
?/Singapore?. 
7. An organization name dictionary. Some 
frequently used organization names are included 
in the dictionary, like ????/State Council? 
and ????/United Nations?. 
8. Person name list: we collect some person 
names which come from the MSR train corpus. 
Moreover, the famous person name are included 
in the list such as ????,????. 
5 Evaluation result 
We evaluated our word segmenter and named 
entity recognizer on the SIGHAN Microsoft 
Research Asia (MSRA) corpus in open track. 
The Table 1 is the official result of word 
segmentation by our system. 
 
Corpus OOV- 
Rate 
OOV- 
Recall 
IV 
Recall-
rate 
F 
measure 
MSR 0.034 0.804 0.976 0.97 
UPUC 0.087 0.593 0.957 0.911 
 
Table 1 Official SIGHAN evaluation result for word 
segmentation in the open track 
 
Table 2 shows the official result of entity 
recognition. 
 
Type R P F 
Person 95.39% 96.71% 96.04% 
Location 87.77% 93.06% 90.34% 
Organization 87.68% 84.20% 85.90% 
 
Table2 Official SIGHAN evaluation result for entity 
recognition in the open track 
 
6 Conclusions 
A probabilistic feature based ME model is used 
to Chinese word segmentation and named entity 
recognition tasks. Our word segmenter achieved 
the medium result in the open word segmentation 
track of MSRA corpus, while entity recognition 
achieved the top one performance. 
Acknowledgement 
The research work is supported by China 
Ministry Of Education funded project (MZ115-
022): ?Tools for Chinese and Minority Language 
Processing? 
References 
A L Berger. 1996.  A Maximum Entropy Approach to 
Natural Language Processing.  Computational Linguistic, 
22 (1): 39- 71. 
Yan Yintang, Zhou XiaoQiang. 2000.12 Study of 
Segmentation Strategy on Ambiguous Phrases of 
Overlapping Type  Journal of The China Society For 
Scientific and Technical Information  Vol. 19 , ?6  
Liang NanYuan. 1987 A Written Chinese Segmentation 
system? CDWS.  Journal of Chinese Information Processing, 
Vol.2: 44-52 
ZHANG Hua-ping and Liu Qun. 2004 Automatic 
Recognition of Chinese Personal Name Based on Role 
Tagging. CHINESE JOURNAL OF COMPUTERS Vol (27) 
pp 85-91. 
Lv YaJuan, ZhaoTie-jun et al 2001. Leveled unknown 
Chinese Words resolution by dynamic programming. 
Journal Information Processing, 15(1): 28-33.  
Borthwick .A 1999.  Maximum Entropy Approach to Named 
Entity Recognition.  hD Dissertation.  
161
