Proceedings of the NAACL HLT Workshop on Semantic Evaluations: Recent Achievements and Future Directions, pages 129?137,
Boulder, Colorado, June 2009. c?2009 Association for Computational Linguistics
Relation detection between named entities: report of a shared task
Cla?udia Freitas, Diana Santos
Cristina Mota
SINTEF ICT
claudiafreitas@puc-rio.br
Diana.Santos@sintef.no
cmota@ist.utl.pt
Hugo Gonc?alo Oliveira
CISUC, DEI - FCTUC
hroliv@dei.uc.pt
Paula Carvalho
Univ. Lisbon, FCUL, XLDB
pcc@di.fc.ul.pt
Abstract
In this paper we describe the first evalu-
ation contest (track) for Portuguese whose
goal was to detect and classify relations be-
tween named entities in running text, called
ReRelEM. Given a collection annotated with
named entities belonging to ten different se-
mantic categories, we marked all relationships
between them within each document. We used
the following fourfold relationship classifi-
cation: identity, included-in, located-in, and
other (which was later on explicitly detailed
into twenty different relations). We provide a
quantitative description of this evaluation re-
source, as well as describe the evaluation ar-
chitecture and summarize the results of the
participating systems in the track.
1 Motivation
Named entity recognition can be considered the first
step towards semantic analysis of texts and a crucial
subtask of information extraction systems. Proper
names, besides their high frequency in language, do
more than just refer ? they convey additional infor-
mation as instances of general semantic categories.
But NE recognition is, as just mentioned, only the
first step for full language processing. If we want to
go beyond the detection of entities, a natural step is
establishing semantic relations between these enti-
ties, and this is what this paper is about.
There are two fairly independent communities
that focus on the task of detecting relations between
named entities: the work on anaphora resolution, il-
lustrated by (Mitkov, 2000; Collovini et al, 2007;
de Souza et al, 2008) and the work on relation de-
tection in information extraction, see e.g. (Agichtein
and Gravano, 2000; Zhao and Grishman, 2005; Cu-
lotta and Sorensen, 2004). Although both commu-
nities are doing computational semantics, the two
fields are largely non-overlapping, and one of the
merits of our work is that we tried to merge the two.
Let us briefly describe both traditions: as (Mitkov,
2000) explains, anaphora resolution is concerned
with studying the linguistic phenomenon of pointing
back to another expression in the text. The seman-
tic relations between the referents of these expres-
sions can be of different types, being co-reference a
special case when the relation is identity. The focus
of anaphora resolution is determining the antecedent
chains, although it implicitly also allows to elicit se-
mantic relations between referents. This task has a
long tradition in natural language processing (NLP)
since the early days of artificial intelligence (Web-
ber, 1978), and has from the start been considered a
key ingredient in text understanding.
A different tradition, within information extrac-
tion and ontology building, is devoted to fact ex-
traction. The detection of relations involving named
entities is seen as a step towards a more structured
model of the meaning of a text. The main concerns
here (see e.g. (Zhao and Grishman, 2005)) are the
extraction of large quantities of facts, generally cou-
pled with machine learning approaches.1
Although mentions of named entities may ex-
1Other authors use the term relation detection in still other
ways: for example, (Roth and tau Yih, 2004) use it for the trans-
lation of any natural language sentences into ?logical form?, as
in kill (x,y). This task does not concern us here.
129
Relations Works
orgBased-in, Headquarters, Org-Location, Based-in RY, AG, DI, Sn, CS, ACE07, ACE04, ZG
live-in, Citizen-or-Resident RY, ACE04, ZG, ACE07,CS
Employment, Membership, Subsidiary ZG, CS, ACE04, ACE07
located(in), residence, near ACE04, ACE07,CS, ZG
work-for, Affiliate, Founder, Management,
Client, Member, Staff CS, ACE04, ACE07, RY, ZG
Associate, Grandparent, Parent, Sibling,
Spouse, Other-professional, Other-relative, Other-personal CS, ACE04, ACE07
User, Owner,Inventor, Manufacturer ACE04,ACE07, ZG, CS
DiseaseOutbreaks AG
Metonymy ACE07
identity ARE
synonym ARE
generalisation ARE
specialisation ARE
Table 1: Relations used in other works or evaluation contests.
press semantic relations other than identity or de-
pendency, the main focus of the first school has
been limited to co-reference. Yet, relations such
as part-of have been considered under the label
of indirect anaphora, also known as associative or
bridging anaphora.
Contrarywise, the list of relations of interest for
the second school is defined simply by world knowl-
edge (not linguistic clues), and typical are the rela-
tions between an event and its location, or an orga-
nization and its headquarters. Obviously, these rela-
tions do occur between entities that do not involve
(direct or indirect) anaphora in whatever broad un-
derstanding of the term.
Also, relation detection in the second school does
not usually cover identity (cf. ACE?s seven relation
types): identity or co-reference is often considered
an intermediate step before relation extraction (Cu-
lotta and Sorensen, 2004).
Table 1 displays a non-exhaustive overview of the
different relations found in the literature.2
In devising the ReRelEM3 pilot track, our goal
was twofold: to investigate which relations could
2There is overlap between ACE 2007 and 2004 types of re-
lations. In order to ease the comparison, we used the names of
subtypes for ACE relations.
3ReRelEM stands for Reconhecimento de Relac?o?es entre
Entidades Mencionadas, Portuguese for ?recognition of rela-
tions between named entities?, see (Freitas et al, 2008).
be found between named entities in Portuguese text,
and how could a pilot task be devised that compared
the performance of different automatic systems sup-
posed to identify them. It should be emphasized that
both MUC and ACE were key inspiration sources for
ReRelEM, which stems from Linguateca?s emphasis
on evaluation.
In fact, we were conversant with MUC co-
reference track and the way it was scored, as well
as aware of two other related evaluation contests:
ACE (Doddington et al, 2004; NIST and ACE,
2007), which extended MUC by dropping the re-
quirement that entities had to be named, and ARE
(Ora?san et al, 2008), which requested the identifi-
cation of an anaphoric relation in certain types of
pre-defined relations (identity, synonymy, general-
ization and specification), but which ignored indirect
anaphora (that may convey meronymy, or inclusion,
in a broad sense).
ReRelEM, although maintaining (or adding) the
restriction to named entitites, is, from our point of
view, an advance in the field of relation detection,
since we proposed the detection (and classification)
of all (relevant) kinds of relations between NEs in a
document, providing thus both a merge and an ex-
tension of the previous evaluation campaigns.
130
Category/gloss #
PESSOA/person 196
LOCAL/place 145
ORGANIZACAO/org 102
TEMPO/time 84
OBRA/title 33
VALOR/value 33
ACONTECIMENTO/event 21
ABSTRACCAO/abstraction 17
OUTRO/other 6
COISA/thing 5
Table 2: Category distribution in the golden collection
2 Track description
The purpose of ReRelEM is to assess systems that
try to recognize the most relevant relations between
named entities, even if those relations do not involve
coreference or anaphora.
2.1 Context
In order for it to be feasible in the short time we
had, the track definition required that both referring
expression and their semantic referent were named
entities. Pronouns and definite descriptions were
hence excluded. Note also that ReRelEM was de-
fined in the context of the second edition of a larger
evaluation contest dealing with NE detection and
classification in Portuguese, HAREM (Santos et al,
2008) (for a detailed description of HAREM, in Por-
tuguese, see also (Santos and Cardoso, 2007; Mota
and Santos, 2008)). HAREM required systems to
choose among ten categories (see Table 2), 43 types
and 21 subtypes, the later concerning the categories
TEMPO (time) and LOCAL (place).
So, it should be emphasized that ReRelEM fo-
cuses only on the classification and detection of
the relations, not limiting in any way the kinds of
(named) entities that can be related (as usualy done
in other detection tasks). It only enforces the kinds
of relations that must be identified.
2.2 Relation inventory
The establishment of an inventory of the most rele-
vant relations between NEs is ultimately subjective,
depending on the kind of information that each par-
ticipant aims to extract. We have nevertheless done
an exploratory study and annotated exhaustively a
few texts to assess the most frequent and less con-
troversial (or easier to assign) relations, and came
up with just the following relation types for the task
proposal:
? identity (ident);
? inclusion (inclui (includes) or incluido
(included));
? placement (ocorre-em (occurs-in) or
sede-de (place-of));
? other (outra)
For further description and examples see section 3.
However, during the process of building
ReRelEM?s golden collection (a subset of the
HAREM collection used as gold standard), human
annotation was felt to be more reliable ? and also
more understandable ? if one specified what ?other?
actually meant, and so a further level of detail
(twenty new relations) was selected and marked,
see Table 3. (In any case, since this new refinement
did not belong to the initial task description, all
were mapped back to the coarser outra relation
for evaluation purposes.)
2.3 ReRelEM features and HAREM
requirements
The annotation process began after the annotation
of HAREM?s golden collection, that is, the relations
started to be annotated after all NE had been tagged
and totally revised. For ReRelEM, we had therefore
no say in that process ? again, ReRelEM was only
concerned with the relations between the classified
NEs. However, our detailed consideration of rela-
tions helped to uncover ? and correct some mistakes
in the original classification.
In order to explain the task(s) at hand, let us de-
scribe shortly ReRelEM?s syntax: In ReRelEM?s
golden collection, each NE has a unique ID. A re-
lation between NE is indicated by the additional at-
tributes COREL (filled with the ID of the related en-
tity) and TIPOREL (filled with the name of the re-
lation) present in the NE that corresponds to one of
the arguments of the relation. (Actually, there?s no
difference if the relation is marked in the first or in
the second argument.)
131
One referring expression can be associated with
one or more NEs through several semantic relations.
In such cases, all possible relations must be assigned
to the referring expression, in the form of a list, as
illustrated by UTAD in Figure 1.
In this example, the NE with name UTAD (and
id ex1-42) corresponds to an acronym of Univer-
sidade de Tra?s-os-Montes e Alto Douro (a univer-
sity in Portugal), maintaining with this entity an
identity relation (ident). The TIPOREL field of
ex1-42 contains another relation, inclui, which
stands for the relation of inclusion, this time with
the previously mentioned Servic?os Administrativos
(ex1-40), a specific department of the university.
In order to minimize human labour and also to
let systems mark relations the way it would better
suit them, we have postulated from the start that, for
all purposes, it would be equivalent to annotate ev-
erything or just enough relations so that all others
can be automatically computed. So, the evaluation
programs, in an obvious extension of what was pro-
posed in (Vilain et al, 1995) for identity,
1. add/expand all relations with their inverses
(e.g., ?A includes B? entails ?B is included in
A?), and
2. apply a set of expansion rules (see examples in
Table 4) to compute the closure
As a consequence, different systems may tag the
same text in different ways, but encoding the same
knowledge.
2.4 What is a relevant relation?
An important difference as to what we expect as rel-
evant relations should be pointed out: instead of re-
quiring explicit (linguistic) clues, as in traditional
research on anaphor, we look for all relations that
may make sense in the specific context of the whole
document. Let us provide two arguments supporting
this decision:
? the first one is philosophical: the borders be-
tween world knowledge and contextual infer-
ence can be unclear in many cases, so it is not
easy to distinguish them, even if we did believe
in that separation in the first place;
? the second is practical: marking all possible re-
lations is a way to also deal with unpredictable
informational needs, for example for text min-
ing applications. Take a sentence like ?When I
lived in Peru, I attended a horse show and was
able to admire breeds I had known only from
pictures before, like Falabella and Paso.?. From
this sentence, few people would infer that Paso
is a Peruvian breed, but a horse specialist might
at once see the connection. The question is:
should one identify a relation between Peru and
Paso in this document? We took the affirmative
decision, assuming the existence of users inter-
ested in the topic: ?relation of breeds to horse
shows: are local breeds predominant??.
However, and since this was the first time such eval-
uation contest was run, we took the following mea-
sure: we added the attribute INDEP to the cases
where the relation was not possible to be inferred
by the text. In this way, it is possible to assess
the frequency of these cases in the texts, and one
may even filter them out before scoring the system
runs to check their weight in the ranking of the sys-
tems. Interestingly, there were very few cases (only
6) marked INDEP in the annotated collection.
3 Qualitative relation description
Identity (or co-reference) does not need to be ex-
plained, although we should insist that this is not
identity of expression, but of meaning. So the same
string does not necessarily imply identity, cf.:
Os adeptos do Porto invadiram a cidade
do Porto em ju?bilo.4
Interestingly, even though organization is only the
third most frequent category, Figure 2 shows that we
found more co-reference among organizations than
among any other category.
As to inclusion (see Figure 3), it was defined be-
tween NEs of the same sort, as the folowing ex-
amples, respectively illustrating LOCAL, PESSOA,
OBRA and ORGANIZACAO, show:
Centenas de pessoas recepcionaram no
Aeroporto da Portela num clima de
enorme entusiasmo e euforia, a selecc?a?o
4The (FC) Porto fans invaded the (city of) Porto, very happy
132
<EM ID="ex1-39" CATEG="PESSOA" TIPO="INDIVIDUAL"> Miguel Rodrigues</EM>
, chefe dos <EM ID="ex1-40" CATEG="ORGANIZACAO" TIPO="INSTITUICAO"
COREL="ex1-39" TIPOREL="outra">Servic?os Administrativos</EM> da <EM
ID="ex1-41" CATEG="ORGANIZACAO" TIPO="INSTITUICAO" COREL="ex1-40"
TIPOREL="inclui"> Universidade de Tra?s-os-Montes e Alto Douro</EM> <EM
ID="ex1-42" CATEG="ORGANIZACAO" TIPO="INSTITUICAO" COREL="ex1-41 ex1-40"
TIPOREL="ident inclui">UTAD</EM>
Figure 1: Full example of ReRelEM syntax.
Figure 2: Distribution of NE categories for identity.
portuguesa de ra?guebi. A boa prestac?a?o
global da equipa (...) na?o passou desperce-
bida em Portugal.5
Lewis Hamilton, colega de Alonso na
McLaren6
da assinatura do Tratado de Lisboa (...)
de ver reconhecido o valor juridicamente
vinculativo da Carta um passo ?essencial
no quadro de reforma dos Tratados7
por participar na cerimo?nia de
proclamac?a?o da Carta dos Direitos
Fundamentais da UE (...) salientou
ainda o compromisso assumido pelas tre?s
instituic?o?es - PE8
5Hundreds of people waited with enthusiasm and eupho-
ria at the Portela Airport for the Portuguese national rugby
team.(...) The team?s good performance did not go unnoticed in
Portugal
6Lewis Hamilton, Alonso?s team-mate in McLaren ? Note
that, in HAREM, teams are considered groups of people, there-
fore an individual and a team have the same category PESSOA
(person), but differ in the type.
7the signing of the Lisbon Treaty (...) juridically vincula-
tive value of the Charter, a crucial step for the Treaties reform
policy
8to participate in the proclamation ceremony of the Charter
Figure 3: NE categories related by inclusion.
Placement is clearly skewed towards placement of
organizations (518 cases) as opposed to occurrence
of events (just 98 instances). However, if we con-
sider the relative distribution of organizations and
events (see Table 2), we can state that, relative to
their places, events have 4.8 relations in average and
organizations 5.0, which is a far more interesting re-
sult, not favouring any of the NE classes.
Examples of this relation are:
GP Brasil ? Na?o faltou emoc?a?o em Inter-
lagos no Circuito Jose? Carlos Pace9
As to the refinement of outra, Table 3 presents the
relations found in the material.
3.1 Vague categories
It is important to stress that the basic tenets of
HAREM had to be followed or reckoned with, not
only the classification grid (see Table 2) but par-
ticularly the fact that some named entities are con-
sidered to be vague among different categories in
of Fundamental Rights of the EU (...) stressed the commitment
assumed by the three institutions - EP
9GP Brasil ? There was no lack of excitement in Interlagos
at the Jose? Carlos Pace Circuit.
133
Relation / gloss Number
vinculo-inst / inst-commitment 936
obra-de / work-of 300
participante-em / participant-in 202
ter-participacao-de / has-participant 202
relacao-familiar / family-tie 90
residencia-de / home-of 75
natural-de / born-in 47
relacao-profissional / professional-tie 46
povo-de / people-of 30
representante-de / representative-of 19
residente-de / living-in 15
personagem-de / character-of 12
periodo-vida / life-period 11
propriedade-de / owned-by 10
proprietario-de / owner-of 10
representado-por / represented-by 7
praticado-em / practised-in 7
outra-rel/other 6
nome-de-ident / name-of 4
outra-edicao / other-edition 2
Table 3: Frequency of other relations.
HAREM.10
This last property, namely that named entities
could belong to more than one category, posed some
problems, since it was not straightforward whether
different relations would involve all or just some (or
one) category. So, in order to specify clearly the
relations between vague NEs, we decided to spec-
ify separate relations between facets of vague named
entities. Cf. the following example, in which vague-
ness is conveyed by a slash:
(...) a ideia de uma Europa (LO-
CAL/PESSOA) unida. (...) um dia feliz
para as cidada?s e os cidada?os da Unia?o
Europeia (LOCAL). (...) Somos essen-
cialmente uma comunidade de valores ?
sa?o estes valores comuns que constituem
o fundamento da Unia?o Europeia (AB-
STRACCAO/ORG/LOCAL).11
10This is different from considering metonymy classes, in
that no classifications are considered more basic than others, see
(Santos, 2006) for vagueness as an intrinsic property of natural
language.
11the idea of a united Europe (...) a happy day for the citizens
The several relations between the three bold-faced
NEs have been found to be as follows: The LO-
CAL facet of the first NE is identical with the LO-
CAL facets of the second and third NEs, while the
ORG(ANIZACAO) facet of the third NE is located
in the LOCAL facet of the second and first NEs.
(Two kinds of relations are therefore involved here:
ident and inclui.)
4 Evaluation: architecture and measures
Our first concern in this pilot track was to make a
clear separation between the evaluation of relations
and the evaluation of NE detection, which was the
goal of HAREM. So, ReRelEM ?s evaluation uses as
a starting point the set of alignments that correspond
to a mapping of the NE in the golden collection (GC)
to a (candidate) NE in the participation.
Evaluation has the following stages:
? Maximization: the sets of relations annotated in
both the GC and in the participation are maxi-
mized, applying the rules in Table 4;
? Selection: the alignments where the NE in the
GC is different from the corresponding one in
the participation are removed, and so are all re-
lations held between removed NEs;
? Normalization: The identifiers of the NE in the
participation are normalized in order to make it
possible to compare the relations in both sides,
given that each system uses its own identifiers.
? Translation: The alignments are translated to
triples: arg1 relation arg2, where the
arguments consist of the identifiers of the
NE together with the facet, for example x67
LOCAL sede-de ty45 ORGANIZACAO.
? Filtering: removing relations of types not be-
ing evaluated (because HAREM, and therefore
ReRelEM, allows for partial participation ? and
evaluation ? scenarios12).
? Individual evaluation: the triples in the GC are
compared to the triples in the participation.
of the European Union (...) We are mainly a community of
values and these common values constitute the foundation of
the European Union.
12In other words, it is possible to select a subset of the classi-
fication hierarchy.
134
A ident B ? B ident C ? A ident C
A inclui B ? B inclui C ? A inclui C
A inclui B ? B sede de C ? A sede de C
A ident B ? B any rel C ? A any rel C
Table 4: Maximization rules
System NE task Relations
Rembr. all all
SeRelEP only identification all but outra
SeiGeo only LOCAL detection inclusion
Table 5: Participant systems
? Global evaluation: measures (precision, recall
and F-measure) are calculated based on the
score of each triple.
Each triple is scored as correct, missing or incor-
rect. We only considered as correct triples (and cor-
rect relations) those which linked the correct NEs
and whose relation was well classified. So, a system
doesn?t score if it correctly matches the NEs to be re-
lated, but fails to recognize the kind of relation. We
assign one point to each correct relation and none to
incorrect or missing relations, and then we compute
precision, recall and F-measure.
ReRelEM?s golden collection includes 12 texts
with 4,417 words and 573 NEs (corresponding to
642 different facets). In all we annotated 6,790 re-
lations (1436 identity; 1612 inclusion; 1232 place-
ment; 2510 other).
5 Participation and results
For this first edition, only three systems (totalling
nine runs) participated, namely REMBRANDT
(Cardoso, 2008), SEI-Geo (Chaves, 2008), and
SeRelEP (Bruckschen et al, 2008), whose results
are found in Figure 4. However, they did not com-
pare well: they selected different NER tasks and dif-
ferent relation types, as shown in Table 5. So, given
the little and diverse participation in ReRelEM, we
cannot do a useful state of the art, but we were def-
initely able to provide an interesting and important
resource for empirical studies and for training of fu-
ture systems, as well as a set of publicly available
programs to manipulate, evaluate and display this
Figure 4: ReRelEM results: F-measure, all relations
kind of semantic data13.
6 Discussion and further work
Although this was just a pilot, a lot of knowledge
about the task and the problems to be dealt with were
gathered for the future, and important resources
were offered to the community.
We intend to annotate further sections of the
HAREM golden collection (as well as other kinds
of texts and materials) with more relations in order
to have more quantitative empirical data for studying
the semantic fabric of Portuguese.
Although from an organization point of view it
made sense to couple ReRelEM with HAREM, one
should reflect over the consequences of inheriting a
lot of decisions taken in HAREM, somehow going
counter the intuitive and easier task of just annotat-
ing relations in a first round. However, despite initial
fears to the contrary, we found out that the consid-
erably fine-grained HAREM grid was in fact benefi-
cial to the task of specifying relations: it is, after all,
much more informative to have a relation of inclu-
sion between a COISA-MEMBROCLASSE (concrete
instance of a class of objects) and a COISA-CLASSE
(a class of objects), than just a relation of inclusion
13http://www.linguateca.pt/HAREM/
135
tout court. In fact, in the next sentence, a kind of
specialization relation can be uncovered.
Astro?nomos brasileiros esperam fotogra-
far os primeiros planetas fora do Sistema
Solar com a ajuda do maior telesco?pio
do mundo, o Gemini (...) os telesco?pios
Gemini te?m capacidade cient??fica...14
Likewise, an inclusion relation held between
PESSOA-GRUPOCARGO (a group of roles performed
by people) and PESSOA-INDIVIDUAL (an individ-
ual person) , as in the following example, is more
informative than a simple relation of inclusion be-
tween NEs, or even inclusion between PESSOA enti-
ties without further discrimination.
Po?ttering, So?crates e Barroso assinam
Carta dos Direitos Fundamentais da UE.
Depois de a Carta ser assinada pelos
Presidentes das tre?s instituic?o?es, ouviu-se
o hino europeu...15
Furthermore, this relation is also different from
an inclusion relation held between PESSOA-
INDIVIDUAL (an individual) and PESSOA-
GRUPOMEMBRO (a group of people):
Lobos recebidos em apoteose. (...) o
capita?o Vasco Uva explicou por que houve
uma empatia ta?o grande entre... 16
Conversely, the specification of relations between
different NEs in a text may help in detecting and jus-
tifying different facets of a particular NE, i.e., mul-
tiple semantic categories that should be assigned to
it.
This illustrates the often observed case that it may
be easier for a human annotator to decide and choose
a specific issue than a too general one, and that there-
fore categories or choices should be more dependent
on ease of human interpretation than quantitative
factors (such as few categories or balanced ones).
14Brazilian astronomers expect to take the first pictures of
planets beyond the solar system with the help of the largest
telescope in the world, Gemini (...) Gemini telescopes have
a capacity...
15Po?ttering, So?crates e Barroso sign the declaration... After
being signed by the Presidents of the three institutions, ...
16Lobos received apoteothically. (...) Captain Vasco Uva
explained why ...
For future work, we obviously intend to increase
the size of the annotated collection (to the whole
HAREM collection and even beyond), and investi-
gate a couple of issues that interest us: which strate-
gies are used to avoid repetition of proper names
and establish textual cohesion? How do relations
between noun phrases in general compare with re-
lations between entities?
We would also like to investigate closer rela-
tionships between different relations: for exam-
ple, is it more appropriate to also develop a hi-
erarchy of relations, reconsidering, for example,
affiliation (currently one of the other) as a
kind of inclusion?
In order to understand better what this task is
about, we would also like to investigate whether
there are interesting correlations between NE cate-
gories and relations, as well as text genre and this
sort of connectivity. Even though we only studied
and annotated in depth 12 different texts, it was at
once obvious that they had quite different properties
as far as the number and kinds of relations was con-
cerned.
From an evaluation point of view, we would like
to improve our inconsistency detection programs
and be able to reason about possible contradictions
(of the annotation or of the interpretation) as well
as experiment with different weights and evaluation
measures, taking into account criteria such as pre-
dictability of relationships between NEs.
In any case, we believe this was an important first
step to understand a number of issues and to reflect
about what computational systems should be doing
to harvest semantic knowledge. We would like to
receive feedback on whether the task design seems
sound to the rest of the community, and whether sys-
tems which would perform well in such task could
be put to good use in real world applications.
Acknowledgments
This work was done in the scope of the Linguateca
project, jointly funded by the Portuguese Govern-
ment and the European Union (FEDER and FSE)
under contract ref. POSC/339/1.3/C/NAC.
136
References
Eugene Agichtein and Luis Gravano. 2000. Snowball:
Extracting Relations from Large Plain-Text Collec-
tions. In Proc. of the 5th ACM International Con-
ference on Digital Libraries (ACM DL), pages 85?94,
San Antonio, Texas, USA, June, 2-7.
M??rian Bruckschen, Jose? Guilherme Camargo de Souza,
Renata Vieira, and Sandro Rigo. 2008. Sistema
SeRELeP para o reconhecimento de relac?o?es entre en-
tidades mencionadas. In Mota and Santos (Mota and
Santos, 2008).
Nuno Cardoso. 2008. REMBRANDT - Reconhecimento
de Entidades Mencionadas Baseado em Relac?o?es e
ANa?lise Detalhada do Texto. In Mota and Santos
(Mota and Santos, 2008).
Marc??rio Chaves. 2008. Geo-ontologias e padro?es para
reconhecimento de locais e de suas relac?o?es em textos:
o SEI-Geo no Segundo HAREM. In Mota and Santos
(Mota and Santos, 2008).
Sandra Collovini, Thiago Ianez Carbonel, Ju-
liana Thiesen Fuchs, Jorge Ce?sar Coelho, Lucia
Helena Machado Rino, and Renata Vieira. 2007.
Summ-it: Um corpus anotado com informac?o?es
discursivas visando a` sumarizac?a?o automa?tica. In
Anais do XXVII Congresso da SBC: V Workshop em
Tecnologia da Informac?a?o e da Linguagem Humana
? TIL, pages 1605?1614, Rio de Janeiro, RJ, Brazil,
junho/julho.
Aron Culotta and Jeffrey Sorensen. 2004. Dependency
tree kernels for relation extraction. In Proceedings of
the 42rd Annual Meeting of the Association for Com-
putational Linguistics (ACL?04), pages 423?429. As-
sociation for Computational Linguistics, July.
Jose? Guilherme Camargo de Souza, Patr??cia Nunes
Gonc?alves, and Renata Vieira. 2008. Learning coref-
erence resolution for portuguese texts. In Anto?nio
Teixeira, Vera Lu?cia Strube de Lima, Lu??s Caldas
de Oliveira, and Paulo Quaresma, editors, PROPOR,
volume 5190 of Lecture Notes in Computer Science,
pages 153?162. Springer.
Georde Doddington, Alexis Mitchell, Mark Przybocki,
Lance Ramshaw, Stephanie Strassel, and Ralph
Weischedel. 2004. The automatic content extraction
(ace) programm. tasks, data and evaluation. In Pro-
ceedings of the Fourth International Conference on
Language Resources and Evaluation, pages 837?840,
Lisbon, Portugal.
Cla?udia Freitas, Diana Santos, Hugo Gonc?alo Oliveira,
Paula Carvalho, and Cristina Mota. 2008. Relac?o?es
sema?nticas do ReRelEM: ale?m das entidades no Se-
gundo HAREM. In Mota and Santos (Mota and San-
tos, 2008).
Ruslan Mitkov. 2000. Towards a more consistent and
comprehensive evaluation of anaphora resolution al-
gorithms and systems. In Proceedings of the Dis-
course Anaphora and Anaphora Resolution Collo-
quium (DAARC-2000), pages 96?107, Lancaster, UK.
Cristina Mota and Diana Santos, editors. 2008. Desafios
no reconhecimento de entidades mencionadas: O Se-
gundo HAREM. Linguateca.
NIST and ACE. 2007. Automatic Content Extrac-
tion 2008 Evaluation Plan (ACE08) ? Assessment of
Detection and Recognition of Entities and Relations
within and across Documents. Technical report, NIST.
Constantin Ora?san, Dan Cristea, Ruslan Mitkov, and An-
tonio Branco. 2008. Anaphora resolution exercise:
An overview. In Proceedings of the Sixth International
Language Resources and Evaluation (LREC?08), Mar-
rakech, Morocco, May, 28 - 30.
Dan Roth and Wen tau Yih. 2004. A linear programming
formulation for global inference in natural language
tasks. In Proceedings of CoNLL-2004, pages 1?8.
Diana Santos and Nuno Cardoso, editors. 2007. Re-
conhecimento de entidades mencionadas em por-
tugue?s: Documentac?a?o e actas do HAREM, a primeira
avaliac?a?o conjunta na a?rea. Linguateca, Portugal.
Diana Santos, Cla?udia Freitas, Hugo Gonc?alo Oliveira,
and Paula Carvalho. 2008. Second HAREM: new
challenges and old wisdom. In Anto?nio Teixeira, Vera
Lu?cia Strube de Lima, Lu??s Caldas de Oliveira, and
Paulo Quaresma, editors, Computational Processing
of the Portuguese Language, 8th International Con-
ference, Proceedings (PROPOR 2008), volume LNAI
5190, pages 212?215. Springer Verlag.
Diana Santos. 2006. What is natural language? Dif-
ferences compared to artificial languages, and conse-
quences for natural language processing, 15 May. In-
vited lecture, SBLP2006 and PROPOR?2006.
Marc Vilain, John Burger, John Aberdeen, Dennis Con-
nolly, and Lynette Hirschman. 1995. A model-
theoretic coreference scoring scheme. In Proceed-
ings of the Sixth Message Understanding Conference
(MUC-6), pages 45?52. Morgan Kaufmann.
Bonnie Lynn Webber. 1978. A formal approach to dis-
course anaphora. Outstanding dissertations in linguis-
tics. Garland Publishing, New York, NY, USA.
Shubin Zhao and Ralph Grishman. 2005. Extracting re-
lations with integrated information using kernel meth-
ods. In Proceedings of the 43rd Annual Meeting on As-
sociation for Computational Linguistics (ACL 2005),
pages 419?426, Morristown, NJ, USA. Association for
Computational Linguistics.
137
Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 35?40,
Avignon, France, April 23 - 27 2012. c?2012 Association for Computational Linguistics
Folheador: browsing through Portuguese semantic relations
Hugo Gonc?alo Oliveira
CISUC, University of Coimbra
Portugal
hroliv@dei.uc.pt
Hernani Costa
FCCN, Linguateca &
CISUC, University of Coimbra
Portugal
hpcosta@dei.uc.pt
Diana Santos
FCCN, Linguateca &
University of Oslo
Norway
d.s.m.santos@ilos.uio.no
Abstract
This paper presents Folheador, an online
service for browsing through Portuguese
semantic relations, acquired from differ-
ent sources. Besides facilitating the ex-
ploration of Portuguese lexical knowledge
bases, Folheador is connected to services
that access Portuguese corpora, which pro-
vide authentic examples of the semantic re-
lations in context.
1 Introduction
Lexical knowledge bases (LKBs) hold informa-
tion about the words of a language and their in-
teractions, according to their possible meanings.
They are typically structured on word senses,
which may be connected by means of semantic re-
lations. Besides important resources for language
studies, LKBs are key resources in the achieve-
ment of natural language processing tasks, such
as word sense disambiguation (see e.g. Agirre et
al. (2009)) or question answering (see e.g. Pasca
and Harabagiu (2001)).
Regarding the complexity of most knowledge
bases, their data formats are generally not suited
for being read by humans. User interfaces have
thus been developed for providing easier ways of
exploring the knowledge base and assessing its
contents. For instance, for LKBs, in addition to
information on words and semantic relations, it is
important that these interfaces provide usage ex-
amples where semantic relations hold, or at least
where related words co-occur.
In this paper, we present Folheador1, an on-
line browser for Portuguese LKBs. Besides an
1See http://www.linguateca.pt/Folheador/
interface for navigating through semantic rela-
tions acquired from different sources, Folheador
is linked to two services that provide access to
Portuguese corpora, thus allowing observation of
related words co-occurring in authentic contexts
of use, some of them even evaluated by humans.
After introducing several well-known LKBs
and their interfaces, we present Folheador and
its main features, also detailing the contents of
the knowledge base currently browseable through
this interface, which contains information ac-
quired from public domain lexical resources of
Portuguese. Then, before concluding, we discuss
additional features planned for the future.
2 Related Work
Here, we mention a few interfaces that ease the
exploration of well-known knowledge bases. Re-
garding the knowledge base structure, some of the
interfaces are significantly different.
Princeton WordNet (Fellbaum, 1998) is the
most widely used LKB to date. In addition to
other alternatives, the creators of WordNet pro-
vide online access to their resource through the
WordNet Search interface (Princeton University,
2010)2. As WordNet is structured around synsets
(groups of synonymous lexical items), querying
for a word prompts all synsets containing that
word to be presented. For each synset, its part-
of-speech (PoS), a gloss and a usage example are
provided. Synsets can also be expanded to access
the semantic relations they are involved in.
As a resource also organised in synsets, the
2http://wordnetweb.princeton.edu/perl/
webwn
35
Brazilian Portuguese thesaurus TeP3 has a sim-
ilar interface (Maziero et al 2008). Neverthe-
less, since TeP does not contain relations besides
antonymy, its interface is simpler and provides
only the synsets containing a queried word and
their part-of-speech.
MindNet (Vanderwende et al 2005) is a LKB
extracted automatically, mainly from dictionar-
ies, and structured on semantic relations connect-
ing word senses to words. Its authors provide
MNEX4, an online interface for MindNet. After
querying for a pair of words, MNEX provides all
the semantic relation paths between them, estab-
lished by a set of links that connect directly or
indirectly one word to another. It is also possible
to view the definitions that originated the path.
FrameNet (Baker et al 1998) is a man-
ually built knowledge base structured on se-
mantic frames that describe objects, states or
events. There are several means for explor-
ing FrameNet easily, including FrameSQL (Sato,
2003)5, which allows searching for frames, lexi-
cal units and relations in an integrated interface,
and FrameGrapher6, a graphical interface for the
visualization of frame relations. For each frame,
in both interfaces, a textual definition, annotated
sentences of the frame elements, lists of the frame
relations, and lists with the lexical units in the
frame are provided.
ReVerb (Fader et al 2011) is a Web-scale
information extraction system that automatically
acquires binary relations from text. Using ReVerb
Search7, a web interface for ReVerb extractions, it
is possible to obtain sets of relational triples where
the predicate and/or the arguments contain given
strings. Regarding that each of the former is op-
tional, it is possible, for instance, to search for all
triples with the predicate loves and first argument
Portuguese. Search results include the matching
triples, organised according to the name of the
predicate, as well as the number of times each
triple was extracted. The sentences where each
triple was extracted from are as well provided.
3http://www.nilc.icmc.usp.br/tep2
4http://stratus.research.microsoft.com/
mnex/
5http://framenet2.icsi.berkeley.edu/
frameSQL/fn2_15/notes/
6https://framenet.icsi.berkeley.edu/
fndrupal/FrameGrapher
7http://www.cs.washington.edu/research/
textrunner/reverbdemo.html
Finally, Visual Thesaurus (Huiping et al
2006)8 is a proprietary graphical interface that
provides an alternative way of exploring a knowl-
edge base structured on word senses, synonymy,
antonymy and hypernymy relations. It presents a
graph centered on a queried word, connected to its
senses, as well as semantic relations between the
senses and other words. Nodes and edges have a
different color or look, respectively according to
the PoS of the sense or to the type of semantic re-
lation. If a word is clicked, a new graph, centered
on that word, is drawn.
3 Folheador
Folheador, in figure 2, is an online service for
browsing through instances of semantic relations,
represented as relational triples.
Folheador was originally designed as an inter-
face for PAPEL (Gonc?alo Oliveira et al 2010),
a public domain lexical-semantic network, auto-
matically extracted from a proprietary dictionary.
It was soon expanded to other (public) resources
for Portuguese as well (see Santos et al(2010) for
an overview of Portuguese LKBs).
The current version of Folheador browses
through a LKB that, besides PAPEL, in-
tegrates semantic triples from the following
sources: (i) synonymy acquired from two hand-
crafted thesauri of Portuguese9, TeP (Dias-Da-
Silva and de Moraes, 2003; da Silva et al
2002) and OpenThesaurus.PT10; (ii) relations ex-
tracted automatically in the scope of the project
Onto.PT (Gonc?alo Oliveira and Gomes, 2010;
Gonc?alo Oliveira et al 2011), which include
triples extracted from Wiktionary.PT11, and from
Diciona?rio Aberto (Simo?es and Farinha, 2011),
both public domain dictionaries.
Underlying relation triples in Folheador are
thus in the form x RELATED-TO y, where x and
y are lexical items and RELATED-TO is a predi-
cate. Their interpretation is as follows: one sense
of x is related to one sense of y, by means of a re-
lation whose type is identified by RELATED-TO.
8http://www.visualthesaurus.com/
9We converted the thesauri to triples x synonym-of y,
where x and y are lexical items in the same synset.
10http://openthesaurus.caixamagica.pt/
11http://pt.wiktionary.org/
36
Figure 1: Folheador?s interface.
3.1 Navigation
It is possible to use Folheador for searching for
all relations with one, two, or no fixed arguments,
and one or no types (relation names). Combining
these options, Folheador can be used, for instance,
to obtain: all lexical items related to a particular
item; all relations between two lexical items; or a
sample of relations involving a particular type.
The matching triples are listed and may be
filtered according to the resource they were ex-
tracted from. For each triple, the PoS of the ar-
guments is shown, as well as a list with the iden-
tification of the resources from where it was ac-
quired. The arguments of each triple are also links
that make navigation easier. When clicked, Fol-
heador behaves the same way as if it had been
queried with the clicked word as argument. Also,
since the queried lexical item may occur in the
first or in the second argument of a triple, when
it occurs in the second, Folheador inverts the rela-
tion, so that the item appears always as the first ar-
gument. Therefore, there is no need to store both
the direct and the inverse triples.
Consider the example in figure 2: it shows
the triples retrieved after searching for the word
computador (computer, in English). In most of
the retrieved triples, computador is a noun (e.g.
computador HIPONIMO DE ma?quina), but there
are relations where it is an adjective (e.g. com-
putador PROPRIEDADE DO QUE computar).
Moreover, as hypernymy relations are stored in
the form x HIPERONIMO DE y, some of the
triples presented, such as computador HIPON-
IMO DE ma?quina and computador HIPON-
IMO DE aparelho, have been inverted on the fly.
Furthermore, for each triple, Folheador
presents: a confidence value based on the mere
co-occurrence of the words in corpora; and
another based on the co-occurrence of the related
words instantiating discriminating patterns of the
particular relation.
3.2 Graph visualization
Currently, Folheador contains a very simple visu-
alization tool, which draws the semantic relation
graph established by the search results in a page,
as in figure 3.2. In the future, we aim to provide an
alternative for navigation based on textual links,
which would be made through the graph.
3.3 The use of corpora
One of the problems of most lexical resources is
that they do not integrate or contain frequency in-
37
Figure 2: Graph for the results in figure 2.
formation. This is especially true when one is not
simply listing words but going deeper into mean-
ing, and listing semantic properties like word
senses or relationships between senses.
So, a list of relations among words can con-
flate a number of highly specialized and obsolete
words (or word senses) that co-occur with im-
portant and productive relations in everyday use,
which is not a good thing for human and auto-
matic users alike. On the other hand, using cor-
pora allows one to add frequency information to
both participants in the relation and the triples
themselves, and thus provide another axis to the
description of words.
In addition, it is always interesting to observe
language use in context, especially in cases where
the user is not sure whether the relation is cor-
rect or still in use (and the user can and should
be fairly suspicious when s/he is browsing auto-
matically compiled information). A corpus check
therefore provides illustration, and confirmation,
to a user facing an unusual or surprising relation,
in addition to evaluation data for the relation cu-
rator or lexicographer. If these checks have been
done before by a set of human beings (as is the
case of VARRA (Freitas et al forthcomming)),
one can have much more confidence on the data
browsed, something that is important for users.
Having this in mind, besides allowing to query
for stored relational triples, Folheador is con-
nected to AC/DC (Santos and Bick, 2000; San-
tos, 2011), an online service that provides ac-
cess to a large set of Portuguese corpora. In just
one click, it is possible to query for all the sen-
tences in the AC/DC corpora connecting the argu-
ments of a retrieved triple. Figure 3.3 shows some
of the results for the words computador (com-
puter) and aparelho (apparatus). While some of
the returned sentences might contain the related
words co-occurring almost by chance or without
a clear semantic relation, other sentences validate
the triple (e.g. sentence par=saude16727 in fig-
ure 3.3). Sometimes, the sentences might as well
invalidate the triple.
Furthermore, for some of the relation types, it
is possible to connect to another online service,
VARRA (Freitas et al forthcomming), which is
based on a set of patterns that express some of the
relation types, in corpora text. After clicking on
the VARRA link, this service is queried for occur-
rences of the corresponding triple in AC/DC. The
presented sentences (a subset of those returned
by the previous service) will thus contain the re-
lated words connected by a discriminating pat-
tern for the relation they hold. Figure 3.3 shows
two sentences returned for the relation computa-
dor HIPONIMO DE ma?quina.
These patterns, as those proposed by Hearst
(1992) and used in many projects since, may not
be 100% reliable. So, VARRA was designed to
allow human users to classify the sentences ac-
cording to whether the latter validate the relation,
are just compatible with it, or not even that.
In fact, people do not usually write defini-
tions, especially when using common sense terms
in ordinary discourse. Thus, co-occurrence of
semantically-related terms frequently indicates a
particular relation only implicitly. The choice
of assessing sentences as good validators of a
semantic relation is related to the task of auto-
matically finding good illustrative examples for
dictionaries, which is a surprisingly complex
task (Rychly? et al 2008).
This kind of information, amassed with the
help of VARRA, is much more difficult to cre-
ate, but is of great value to Folheador, since it
provides good illustrative contexts for the related
lexical items.
4 Further work and concluding remarks
We have shown that, as it is, Folheador is very
useful, as it enables to browse for triples with
fixed arguments, it identifies the source of the
triples, and, in one click, it provides real sentences
38
Figure 3: AC/DC: some sentences returned for the related words computador and aparelho.
Figure 4: VARRA: sentences that exemplify the relation computador hyponym-of ma?quina.
where related lexical items co-occur. Still, we are
planning to implement new basic features, such as
the suggestion of words, when the searched word
is not in the LKB. Also, while currently Folheador
only directly connects to AC/DC and VARRA, in
order to increase its usability, we plan to connect it
automatically to online definitions and other ser-
vices available on the Web. We intend as well to
crosslink Folheador from the AC/DC interface, in
the sense that one can invoke Folheador also by
just one click (Santos, forthcomming).
Currently, Folheador gives access to 169,385
lexical items: 93,612 nouns, 38,409 verbs, 33,497
adjectives and 3,867 adverbs, in a total of 722,589
triples, and it can browse through the following
types of semantic relations: synonymy, hyper-
nymy, part-of, member-of, causation, producer-
of, purpose-of, place-of, and property-of. How-
ever, as the underlying resources, especially the
ones created automatically, will continue to be up-
dated, one important challenge is to create a ser-
vice that does not get outdated, by accompany-
ing the progress of these resources, ideally doing
an automatic update every month. Furthermore,
we believe that quantitative studies on the com-
parison and the aggregation of the integrated re-
sources should be made, deeper than what is pre-
sented in Gonc?alo Oliveira et al(2011).
We would like to end by emphasizing that we
are aware that the proper interpretation of the
semantic relations may vary in the different re-
sources, even disregarding possible mistakes in
the automatic harvesting. It is enough to consider
the (regular morphological) relation between a
verb and an adjective/noun ended in -dor in Por-
tuguese (and which can be paraphrased by one
who Vs). For instance, in relations such as {sofrer
- sofredor}, {correr - corredor}, {roer - roedor},
the kind of verb defines the kind of temporal re-
lation conveyed: a rodent is essentially roendo,
while a sofredor (sufferer) suffers hopefully in a
particular situation and can stop suffering, and a
corredor (runner) runs as job or as role.
The source code of Folheador is open source12,
so it may be used by other authors to explore their
knowledge bases. Technical information about
Folheador may be found in Costa (2011).
Acknowledgements
Folheador was developed under the scope of Lin-
guateca, throughout the years jointly funded by
the Portuguese Government, the European Union
(FEDER and FSE), UMIC, FCCN and FCT. Hugo
Gonc?alo Oliveira is supported by the FCT grant
SFRH/BD/44955/2008 co-funded by FSE.
References
Eneko Agirre, Oier Lopez De Lacalle, and Aitor
Soroa. 2009. Knowledge-based WSD on spe-
cific domains: performing better than generic su-
pervised WSD. In Proceedings of 21st Interna-
12Available from http://code.google.com/p/
folheador/
39
tional Joint Conference on Artifical Intelligence,
IJCAI?09, pages 1501?1506, San Francisco, CA,
USA. Morgan Kaufmann Publishers Inc.
Collin F. Baker, Charles J. Fillmore, and John B.
Lowe. 1998. The Berkeley FrameNet project. In
Proceedings of the 17th international conference
on Computational linguistics, pages 86?90, Morris-
town, NJ, USA. ACL Press.
Hernani Costa. 2011. O desenho do novo Folheador.
Technical report, Linguateca.
Bento C. Dias da Silva, Mirna F. de Oliveira, and
Helio R. de Moraes. 2002. Groundwork for the
Development of the Brazilian Portuguese Wordnet.
In Nuno Mamede and Elisabete Ranchhod, editors,
Advances in Natural Language Processing (PorTAL
2002), LNAI, pages 189?196, Berlin/Heidelberg.
Springer.
Bento Carlos Dias-Da-Silva and Helio Roberto
de Moraes. 2003. A construc?a?o de um the-
saurus eletro?nico para o portugue?s do Brasil. ALFA,
47(2):101?115.
Anthony Fader, Stephen Soderland, and Oren Etzioni.
2011. Identifying relations for open information ex-
traction. In Proceedings of the Conference of Em-
pirical Methods in Natural Language Processing,
EMNLP ?11, Edinburgh, Scotland, UK.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database (Language, Speech, and
Communication). The MIT Press.
Cla?udia Freitas, Diana Santos, Hugo Gonc?alo Oliveira,
and Violeta Quental. forthcomming. VARRA:
Validac?a?o, Avaliac?a?o e Revisa?o de Relac?o?es
sema?nticas no AC/DC. In Atas do IX Encontro de
Lingu??stica de Corpus, ELC 2010.
Hugo Gonc?alo Oliveira and Paulo Gomes. 2010.
Onto.PT: Automatic Construction of a Lexical On-
tology for Portuguese. In Proceedings of 5th Eu-
ropean Starting AI Researcher Symposium (STAIRS
2010), pages 199?211. IOS Press.
Hugo Gonc?alo Oliveira, Diana Santos, and Paulo
Gomes. 2010. Extracc?a?o de relac?o?es sema?nticas
entre palavras a partir de um diciona?rio: o PAPEL e
sua avaliac?a?o. Linguama?tica, 2(1):77?93.
Hugo Gonc?alo Oliveira, Leticia Anto?n Pe?rez, Hernani
Costa, and Paulo Gomes. 2011. Uma rede le?xico-
sema?ntica de grandes dimenso?es para o portugue?s,
extra??da a partir de diciona?rios electro?nicos. Lin-
guama?tica, 3(2):23?38.
Marti A. Hearst. 1992. Automatic acquisition of hy-
ponyms from large text corpora. In Proceedings
of 14th Conference on Computational Linguistics,
pages 539?545, Morristown, NJ, USA. ACL Press.
Du Huiping, He Lin, and Hou Hanqing. 2006.
Thinkmap visual thesaurus:a new kind of knowl-
edge organization system. Library Journal, 12.
Erick G. Maziero, Thiago A. S. Pardo, Ariani Di Fe-
lippo, and Bento C. Dias-da-Silva. 2008. A Base de
Dados Lexical e a Interface Web do TeP 2.0 - The-
saurus Eletro?nico para o Portugue?s do Brasil. In VI
Workshop em Tecnologia da Informac?a?o e da Lin-
guagem Humana, TIL 2008, pages 390?392.
Marius Pasca and Sanda M. Harabagiu. 2001. The in-
formative role of WordNet in open-domain question
answering. In Proceedings of NAACL 2001 Work-
shop on WordNet and Other Lexical Resources: Ap-
plications, Extensions and Customizations, pages
138?143, Pittsburgh, USA.
Princeton University. 2010. Princeton university
?About Wordnet?. http://wordnet.princeton.edu.
Pavel Rychly?, Milos? Husa?k, Adam Kilgarriff, Michael
Rundell, and Katy McAdam. 2008. GDEX: Auto-
matically finding good dictionary examples in a cor-
pus. In Proceedings of the XIII EURALEX Interna-
tional Congress, pages 425?432, Barcelona. Institut
Universitari de Lingu???stica Aplicada.
Diana Santos and Eckhard Bick. 2000. Providing
Internet access to Portuguese corpora: the AC/DC
project. In Proceedings of 2nd International Con-
ference on Language Resources and Evaluation,
LREC?2000, pages 205?210. ELRA.
Diana Santos, Anabela Barreiro, Cla?udia Freitas,
Hugo Gonc?alo Oliveira, Jose? Carlos Medeiros, Lu??s
Costa, Paulo Gomes, and Rosa?rio Silva. 2010.
Relac?o?es sema?nticas em portugue?s: comparando o
TeP, o MWN.PT, o Port4NooJ e o PAPEL. In
A. M. Brito, F. Silva, J. Veloso, and A. Fie?is, editors,
Textos seleccionados. XXV Encontro Nacional da
Associac?a?o Portuguesa de Lingu??stica, pages 681?
700. APL.
Diana Santos. 2011. Linguateca?s infrastructure
for Portuguese and how it allows the detailed
study of language varieties. OSLa: Oslo Stud-
ies in Language, 3(2):113?128. Volume edited by
J.B.Johannessen, Language variation infrastructure.
Diana Santos. forthcomming. Corpora at linguateca:
vision and roads taken. In Tony Berber Sardinha
and Telma S ao Bento Ferreira, editors, Working
with Portuguese corpora.
Hiroaki Sato. 2003. FrameSQL: A software tool for
FrameNet. In Proceedings of Asialex 2003, pages
251?258, Tokyo. Asian Association of Lexicogra-
phy, Asian Association of Lexicography.
Alberto Simo?es and Rita Farinha. 2011. Diciona?rio
Aberto: Um novo recurso para PLN. Vice-Versa,
pages 159?171.
Lucy Vanderwende, Gary Kacmarcik, Hisami Suzuki,
and Arul Menezes. 2005. Mindnet: An
automatically-created lexical resource. In Proceed-
ings of HLT/EMNLP 2005 Interactive Demonstra-
tions, pages 8?9, Vancouver, British Columbia,
Canada. ACL Press.
40
Proceedings of the 2010 Workshop on Graph-based Methods for Natural Language Processing, ACL 2010, pages 10?18,
Uppsala, Sweden, 16 July 2010. c?2010 Association for Computational Linguistics
Towards the Automatic Creation of a Wordnet from a Term-based Lexical
Network
Hugo Gonc?alo Oliveira?
CISUC, University of Coimbra
Portugal
hroliv@dei.uc.pt
Paulo Gomes
CISUC, University of Coimbra
Portugal
pgomes@dei.uc.pt
Abstract
The work described here aims to create
a wordnet automatically from a semantic
network based on terms. So, a cluster-
ing procedure is ran over a synonymy net-
work, in order to obtain synsets. Then, the
term arguments of each relational triple
are assigned to the latter, originating a
wordnet. Experiments towards our goal
are reported and their results validated.
1 Introduction
In order perform tasks where understanding the in-
formation conveyed by natural language is criti-
cal, today?s applications demand better access to
semantic knowledge. Knowledge about words
and their meanings is typically structured in lex-
ical ontologies, such as Princeton WordNet (Fell-
baum, 1998), but this kind of resources is most of
the times handcrafted, which implies much time-
consuming human effort. So, the automatic con-
struction of such resources arises as an alterna-
tive, providing less intensive labour, easier mainte-
nance and allowing for higher coverage, as a trade-
off for lower, but still acceptable, precision.
This paper is written in the scope of a project
where several textual resources are being exploited
for the construction of a lexical ontology for Por-
tuguese. We have already made a first approach
on the extraction of relational triples from text,
where, likewise Hearst (1992), we take advantage
of textual patterns indicating semantic relations.
However, the extracted triples are held between
two terms, which is not enough to build a lexical
ontology capable of dealing with ambiguity.
Therefore, we present our current approach to-
wards the automatic integration of lexico-semantic
knowledge into a single independent lexical on-
tology, which will be structured on concepts and
?supported by FCT scholarship SFRH/BD/44955/2008.
adopt a model close to WordNet?s. The task of es-
tablishing synsets and mapping term-based triples
to them is closely related to word sense disam-
biguation, where the only available context con-
sists of the connections in the term-base network.
After contextualising this work, our approach is
described. It involves (i) a clustering procedure for
obtaining a thesaurus from a synonymy network,
(ii) the augmentation of the later with manually
created thesaurus, and (iii) mapping term-based
relational triples to the thesaurus, to obtain a word-
net. Then, our experimentation results, as well as
their validation, are presented. Briefly, we have
tested the proposed approach on a term-based lex-
ical network, extracted automatically from a dic-
tionary. Synsets were validated manually while
the attached triples were validated with the help
of a web search engine.
2 Context
Our ultimate goal is the automatic construction of
a broad-coverage structure of words according to
their meanings, also known as a lexical ontology,
the first subject of this section. We proceed with
a brief overview on work concerned with mov-
ing from term-based knowledge to synset-based
knowledge, often called ontologising.
2.1 Lexical Ontologies
Despite some terminological issues, lexical on-
tologies can be seen both as a lexicon and as an on-
tology (Hirst, 2004) and are significantly different
from classic ontologies (Gruber, 1993). They are
not based on a specific domain and are intended
to provide knowledge structured on lexical items
(words) of a language by relating them according
to their meaning. Moreover, the main goal of a
lexical ontology is to assemble lexical and seman-
tic information, instead of storing common-sense
knowledge (Wandmacher et al, 2007).
10
Princeton WordNet (Fellbaum, 1998) is the
most representative lexico-semantic resource for
English and also the most accepted model of a
lexical ontology. It is structured around groups of
synonymous words (synsets), which describe con-
cepts, and connections, denoting semantic rela-
tions between those groups. The success of Word-
Net led to the adoption of its model by lexical re-
sources in different languages, such as the ones
in the EuroWordNet project (Vossen, 1997), or
WordNet.PT (Marrafa, 2002), for Portuguese.
However, the creation of a wordnet, as well as
the creation of most ontologies, is typically man-
ual and involves much human effort. Some au-
thors (de Melo and Weikum, 2008) propose trans-
lating Princeton WordNet to wordnets in other lan-
guages, but if this might be suitable for several ap-
plications, a problem arises because different lan-
guages represent different socio-cultural realities,
do not cover exactly the same part of the lexicon
and, even where they seem to be common, several
concepts are lexicalised differently (Hirst, 2004).
Another popular alternative is to extract lexico-
semantic knowledge and learn lexical ontologies
from text. Research on this field is not new and
varied methods have been proposed to achieve dif-
ferent steps of this task including the extraction of
semantic relations (e.g. (Hearst, 1992) (Girju et
al., 2006)) or sets of similar words (e.g. (Lin and
Pantel, 2002) (Turney, 2001)).
Whereas the aforementioned works are based
on unstructured text, dictionaries started earlier
(Calzolari et al, 1973) to be seen as an attrac-
tive target for the automatic acquisition of lexico-
semantic knowledge. MindNet (Richardson et al,
1998) is both an extraction methodology and a lex-
ical ontology different from a wordnet, since it
was created automatically from a dictionary and
its structure is based on such resources. Neverthe-
less, it still connects sense records with semantic
relations (e.g. hyponymy, cause, manner).
For Portuguese, PAPEL (Gonc?alo Oliveira et
al., 2009) is a lexical network consisting of triples
denoting semantic relations between words found
in a dictionary. Other Portuguese lexical ontolo-
gies, created by different means, are reviewed and
compared in (Santos et al, 2009) and (Teixeira et
al., 2010).
Besides corpora and dictionary processing, in
the later years, semi-structured collaborative re-
sources, such as Wikipedia or Wiktionary, have
proved to be important sources of lexico-semantic
knowledge and have thus been receiving more and
more attention by the community (see for instance
(Zesch et al, 2008) (Navarro et al, 2009)).
2.2 Other Relevant Work
Most of the methods proposed to extract relations
from text have term-based triples as output. Such
a triple, term1 RELATION term2, indicates that a
possible meaning of term1 is related to a possible
meaning of term2 by means of a RELATION.
Although it is possible to create a lexical
network from the latter, this kind of networks
is often impractical for computational applica-
tions, such as the ones that deal with infer-
ence. For instance, applying a simple transitive
rule, a SYNONYM OF b ? b SYNONYM OF c
? a SYNONYM OF c over a set of term-based
triples can lead to serious inconsistencies. A curi-
ous example in Portuguese, where synonymy be-
tween two completely opposite words is inferred,
is reported in (Gonc?alo Oliveira et al, 2009):
queda SYNONYM OF ru??na ? queda SYN-
ONYM OF habilidade? ru??na SYNONYM OF
habilidade. This happens because natural lan-
guage is ambiguous, especially when dealing with
broad-coverage knowledge. In the given example,
queda can either mean downfall or aptitude, while
ru??na means ruin, destruction, downfall.
A possible way to deal with ambiguity is to
adopt a wordnet-like structure, where concepts
are described by synsets and ambiguous words
are included in a synset for each of their mean-
ings. Semantic relations can thereby be unambigu-
ously established between two synsets, and con-
cepts, even though described by groups of words,
bring together natural language and knowledge en-
gineering in a suitable representation, for instance,
for the Semantic Web (Berners-Lee et al, 2001).
Of course that, from a linguistic point of view,
word senses are complex and overlapping struc-
tures (Kilgarriff, 1997) (Hirst, 2004). So, despite
word sense divisions in dictionaries and ontologies
being most of the times artificial, this trade-off is
needed in order to increase the usability of broad-
coverage computational lexical resources.
In order to move from term-based triples to
an ontology, Soderland and Mandhani (2007) de-
scribe a procedure where, besides other stages,
terms in triples are assigned to WordNet synsets.
Starting with all the synsets containing a term in
11
a triple, the term is assigned to the synset with
higher similarity to the contexts from where the
triple was extracted, computed based on the terms
in the synset, sibling synsets and direct hyponym
synsets.
Two other methods for ontologising term-based
triples are presented by Pantel and Pennacchiotti
(2008). One assumes that terms with the same
relation to a fixed term are more plausible to de-
scribe the correct sense, so, to select the correct
synset, it exploits triples of the same type sharing
one argument. The other method, which seems to
perform better, selects suitable synsets using gen-
eralisation through hypernymy links in WordNet.
There are other works where WordNet is
enriched, for instance with information in its
glosses, domain knowledge extracted from text
(e.g. (Harabagiu and Moldovan, 2000) (Navigli
et al, 2004)) or wikipedia entries (e.g. (Ruiz-
Casado et al, 2005)), thus requiring a disambigua-
tion phase where terms are assigned to synsets.
In the construction of a lexical ontology, syn-
onymy plays an important role because it defines
the conceptual base of the knowledge to be rep-
resented. One of the reasons for using WordNet
synsets as a starting point for its representation is
that, while it is quite straightforward to define a set
of textual patterns indicative of several semantic
relations between words (e.g. hyponymy, part-of,
cause) with relatively good quality, the same does
not apply for synonymy. In opposition to other
kinds of relation, synonymous words, despite typi-
cally sharing similar neighbourhoods, may not co-
occur frequently in unstructured text, especially in
the same sentence (Dorow, 2006), leading to few
indicative textual patterns. Therefore, most of the
works on synonymy extraction from corpora rely
on statistics or graph-based methods (e.g. (Lin
and Pantel, 2002) (Turney, 2001) (Dorow, 2006)).
Nevertheless, methods for synonymy identifica-
tion based on co-occurrences (e.g. (Turney, 2001))
are more prone to identify similar words or near
synonyms than real synonyms.
On the other hand, synonymy instances can be
quite easily extracted from resources structured on
words and meanings, such as dictionaries, by tak-
ing advantage not only of textual patterns, more
frequent in those resources (e.g. tambe?m con-
hecido por/como, o mesmo que, for Portuguese),
but also of definitions consisting of only one word
or a enumeration, which typically contain syn-
onyms of the defined word. So, as it is possible
to create a lexical network from a set of relational
triples (a R b), a synonymy network can be created
out of synonymy instances (a SYNONYM OF
b). Since these networks tend to have a clustered
structure, Gfeller et al (2005) propose a clustering
procedure to improve their utility.
3 Research Goals
The research presented here is in the scope of a
project whose final goal is to create a lexical ontol-
ogy for Portuguese by automatic means. Although
there are clear advantages of using resources al-
ready structured on words and meanings, dictio-
naries are static resources which contain limited
knowledge and are not always available for this
kind of research. On the other hand, there is much
text available on the most different subjects, but
free text has few boundaries, leading to more am-
biguity and parsing issues.
Therefore, it seems natural to create a lexi-
cal ontology with knowledge from several tex-
tual sources, from (i) high precision structured re-
sources, such as manually created thesaurus, to
(ii) semi-structured resources such as dictionaries
or collaborative encyclopedias, as well as (iii) un-
structured textual corpora. Likewise Wandmacher
et al (2007) propose for creating a lexical ontol-
ogy for German, these are the general lines we will
follow in our research, but for Portuguese.
Considering each resource specificities, includ-
ing its organisation or the vocabulary used, the ex-
traction procedures might be significantly differ-
ent, but they should all have one common output:
a set of term-based relational triples that will be
integrated in a single lexical ontology.
Whereas the lexical network established by the
triples could be used, these networks are not suit-
able for several tasks, as discussed in Section 2.2.
A fragment of a synonymy network extracted from
a Portuguese dictionary can be seen in Figure 1.
Since all the connections imply synonymy, the
network suggests that all the words are synony-
mous, which is not true. For example, the word
copista may have two very distinct meanings: (a) a
person who writes copies of written documents or
(b) someone who drinks a lot of wine. On the other
hand, other words which may refer to the same
concept as, for instance, meaning (a) of copista,
such as escrevente, escriva?o or transcritor.
So, in order to deal with ambiguity in natural
12
language, we will adopt a wordnet-like structure
which enables the establishment of unambiguous
semantic relations between synsets.
Figure 1: Fragment of a synonymy network.
4 Approach
Considering our goal, a set of term-based triples
goes through the following stages: (i) clustering
over the synonymy network for the establishment
of synsets, to obtain a thesaurus; (ii) augmenta-
tion of the thesaurus by merging it with synsets
from other resources; (iii) assignment of each ar-
gument of a term-based triple (except synonymy)
to a synset in the thesaurus, to obtain a wordnet.
Note that stages (i) and (ii) are not both manda-
tory, but at least one must be performed to obtain
the synsets.
Looking at some of the works referred in Sec-
tion 2.2, ours is different because it does not re-
quire a conceptual base such as WordNet. Also,
it integrates knowledge from different sources and
tries to disambiguate each word using only knowl-
edge already extracted and not the context where
the word occurs.
4.1 Clustering for a thesaurus
This stage was originally defined after looking
at disconnected pieces of a synonymy network
extracted from a dictionary, which had a clus-
tered structure apparently suitable for identifying
synsets. This is also noticed by Gfeller et al
(2005) who have used the Markov Clustering al-
gorithm (MCL) (van Dongen, 2000) to find clus-
ters in a synonymy network.
Therefore, since MCL had already been applied
to problems very close to ours (e.g. (Gfeller et al,
2005), (Dorow, 2006)), it seemed to suit our pur-
pose ? it would not only organise a term-based net-
work into a thesaurus, but, if a network extracted
from several resources is used, clustering would
homogenise the synonymy representation.
MCL finds clusters by simulating random walks
within a graph by alternately computing random
walks of higher length, and increasing the prob-
abilities of intra-cluster walks. It can be briefly
described in five steps: (i) take the adjacency ma-
trix A of the graph; (ii) normalise each column of
A to 1 in order to obtain a stochastic matrix S;
(iii) compute S2; (iv) take the ?th power of every
element of S2 and normalise each column to 11;
(v) go back to (ii) util MCL converges to a matrix
idempotent under steps (ii) and (iii).
Since MCL is a hard-clustering algorithm, it as-
signs each term to only one cluster thus remov-
ing ambiguities. To deal with this, Gfeller et al
(2005) propose an extension to MCL for finding
unstable nodes in the graph, which frequently de-
note ambiguous words. This is done by adding
random stochastic noise, ?, to the non-zero entries
of the adjacency matrix and then running MCL
with noise several times. Looking at the clusters
obtained by each run, a new matrix can be filled
based on the probability of each pair of words be-
longing to the same cluster.
We have adopted this procedure, with slight dif-
ferences. First, we observed that, for the network
we used, the obtained clusters were closer to the
desired results if?0.5 < ? < 0.5. Additionally, in
the first step of MCL, we use frequency-weighted
adjacency matrixes F , where each element Fij
corresponds to the number of existing synonymy
instances between i and j. Although using only
one dictionary each synonymy instance will be ex-
tracted at most two times (a SYNONYM OF b
and b SYNONYM OF a), if more resources are
used, it will strengthen the probability that two
words appearing frequently as synonyms belong
to the same cluster.
Therefore, the clustering stage has the follow-
ing steps: (i) split the original network into sub-
networks, such that there is no path between two
elements in different sub-networks, and calculate
the frequency-weighted adjacency matrix F of
each sub-network; (ii) add stochastic noise to each
entry of F , Fij = Fij + Fij ? ?; (iii) run MCL,
with ? = 1.6, over F for 30 times; (iv) use the
(hard) clustering obtained by each one of the 30
runs to create a new matrix P with the probabil-
1Increasing ? (typically 1.5 < ? < 2) increases the gran-
ularity of the clusters.
13
ities of each pair of words in F belonging to the
same cluster; (v) create the clusters based on P
and on a given threshold ? = 0.2. If Pij > ?, i and
j belong to the same cluster; (vi) in order to clean
the results, remove: (a) big clusters, B, if there
is a group of clusters C = C1, C2, ...Cn such that
B = C1?C2? ...?Cn; (b) clusters completely in-
cluded in other clusters. Applying this procedure
to the network in Figure 1 results in the four repre-
sented clusters. There, ambiguous words escriva?o
and escriba are included in two different clusters.
4.2 Merging synsets for thesaurus
augmentation
In this stage, other resources with synsets, such as
manually created thesaurus, are merged together
and then merged with the thesaurus obtained in the
previous stage, by the following procedure: (i) de-
fine one thesaurus as the basis B and the other as
T ; (ii) create a new empty thesaurus M and copy
all the synsets in B to M ; (iii) for each synset
Ti ? T , find the synsets Bi ? B with higher Jac-
card coefficient2 c, and add them to a set of synsets
J ? B. (iv) considering c and J , do one of the
following: (a) if c = 1, it means that the synset is
already in M , so nothing is done; (b) if c = 0, Ti
is copied to M ; (c) if |J | = 1, the synset in J is
copied toM ; (d) if |J | > 1, a new set, n = Ti?J ?
where J ? = ?|J |i=0Ji, Ji ? J , is created, and all
elements of J are removed from M .
The synsets of the resulting thesaurus will be
used as the conceptual base in which the term-
based triples are going to be mapped.
4.3 Assigning terms to synsets
After the previous stages, the following are avail-
able: (i) a thesaurus T and (ii) a term-based se-
mantic network, N , where each edge has a type,
R, and denotes a semantic relation held between
the meaning of the terms in the two nodes it con-
nects. Using T andN , this stage tries to map term-
based triples to synset-based triples, or, in other
words, assign each term, a and b, in each triple,
(a R b) ? N , to suitable synsets. The result is a
knowledge base organised as a wordnet.
In order to assign a to a synset A, b is fixed
and all the synsets containing a, Sa ? T , are col-
lected. If a is not in the thesaurus, it is assigned to
a new synset A = (a). Otherwise, for each synset
Sai ? Sa, nai is the number of terms t ? Sai such
2Jaccard(A,B) = A ?B/A ?B
that (t R b) holds3. Then, pai =
nai
|Sai|
is calcu-
lated. Finally, all the synsets with the highest pai
are added to C and (i) if |C| = 1 , a is assigned to
the only synset inC; (ii) if |C| > 1, C ? is the set of
elements ofC with the highest na and, if |C ?| = 1,
a is assigned the synset in C ?, unless pai < ? 4;
(iii) if it is not possible to assign a synset to a, it
remains unassigned. Term b is assigned to a synset
using this procedure, but fixing a.
If hypernymy links are already established,
semi-mapped triples, where one of the arguments
is assigned to a synset and the other is not, (A
R b) or (a R B), go to a second phase. There,
hypernymy is exploited together with the assign-
ment candidates, in C, to help assigning the unas-
signed term in each semi-mapped triple, or to re-
move triples that can be inferred. Take for instance
(A R b). If there is one synset Ci ? C with:
? a hypernym synset H , (H HYPERNYM OF
Ci) and a triple (A R H), b would be as-
signed to Ci, but, since hyponyms inherit all
the properties of their hypernym, the result-
ing triple can be inferred and is thus ignored:
(A R H) ? (H HYPERNYM OF Ci)? (A R Ci)5
For example, if H=(mammal) and Ci=(dog), possi-
ble values of A and R are A=(hair) R=PART OF;
A=(animal) R=HYPERNYM OF
? a hyponym synset H , (Ci HYPERNYM OF
H) and a triple (A R H), b is assigned to Ci.
Furthermore, if all the hyponyms of Ci, (Ci
HYPERNYM OF Ii), are also related toA in
the same way, (AR Ii), it can be inferred that
Ii inherits the relation from Ci. So, all the
later triples can be inferred and thus removed.
For example, if H=(dog), Ii=(cat), Ij=(mouse)
and Ci=(mammal), possible values of A and
R are A=(hair) R=PART OF; A=(animal)
R=HYPERNYM OF
3If R is a transitive relation, the procedure may benefit
from applying one level of transitivity to the network: x R y
? y R z? x R z. However, since relations are held between
terms, some obtained triples might be incorrect. So, although
the latter can be used to help selecting a suitable synset, they
should not be mapped to synsets themselves.
4? is a threshold defined to avoid that a is assigned to a
big synset where a, itself, is the only term related to b
5Before applying these rules it is necessary to make sure
that all relations are represented only in one way, otherwise
they might not work. For instance, if the decision is to rep-
resent part-of triples in the form part PART OF whole,
triples whole HAS PART part must be reversed. Further-
more, these rules assume that hypernymy relations are all rep-
resented hypernym HYPERNYM OF hyponym and not
hyponym HYPONYM OF hypernym.
14
5 Experimentation
In this section we report experimental results ob-
tained after applying our procedure to part of the
lexical network of PAPEL (Gonc?alo Oliveira et al,
2009). The clustering procedure was first ran over
PAPEL?s noun synonymy network in order to ob-
tain the synsets which were later merged with two
manually created thesaurus. Finally, hypernym-
of, member-of and part-of triples of PAPEL were
mapped to the thesaurus by assigning a synset to
each term argument.
5.1 Resources used
For experimentation purposes, freely available
lexical resources for Portuguese were used. First,
the last version of PAPEL, 2.0, a lexical network
for Portuguese created automatically from a dic-
tionary, as referred in Section 2. PAPEL 2.0
contains approximately 100,000 words, identified
by their orthographical form, and approximately
200,000 term-based triples relating the words by
different types of semantic relations.
In order to enrich the thesaurus obtained from
PAPEL, TeP (Dias-Da-Silva and de Moraes, 2003)
and OpenThesaurus.PT6 (OT), were used. Both of
them are manually created thesaurus, for Brazil-
ian Portuguese and European Portuguese respec-
tively, modelled after Princeton WordNet (Fell-
baum, 1998) and thus containing synsets. Besides
being the only freely available thesaurus for Por-
tuguese we know about, TeP and OT were used to-
gether with PAPEL because, despite representing
the same kind of knowledge, they are mostly com-
plementary, which is also observed by (Teixeira et
al., 2010) and (Santos et al, 2009).
Note that, for experimentation purposes, we
have only used the parts of these resources con-
cerning nouns.
5.2 Thesaurus creation
The first step for applying the clustering proce-
dure is to create PAPEL?s synonymy network,
which is established by its synonymy instances,
a SYNONYM OF b. After splitting the network
into independent disconnected sub-networks, we
noticed that it was composed by a huge sub-
network, with more than 16,000 nodes, and sev-
eral very small networks. If ambiguity was not
resolved, this would suggest that all the 16,000
words had the same meaning, which is not true.
6http://openthesaurus.caixamagica.pt/
TeP OT CLIP TOP
Words
Quantity 17,158 5,819 23,741 30,554
Ambiguous 5,867 442 12,196 13,294
Most ambiguous 20 4 47 21
Synsets
Quantity 8,254 1,872 7,468 9,960
Avg. size 3.51 3.37 12.57 6.6
Biggest 21 14 103 277
Table 1: (Noun) thesaurus in numbers.
Hypernym of Part of Member of
Term-based triples 62,591 2,805 5,929
1st
Mapped 27,750 1,460 3,962
Same synset 233 5 12
Already present 3,970 40 167
Semi-mapped triples 7,952 262 357
2nd
Mapped 88 1 0
Could be inferred 50 0 0
Already present 13 0 0
Synset-based triples 23,572 1,416 3,783
Table 2: Results of triples mapping
A small sample of this problem can be observed
in Figure 1.
We then ran the clustering procedure and the
thesaurus of PAPEL, CLIP, was obtained. Finally,
we used TeP as the base thesaurus and merged it,
first with OT, and then with CLIP, giving rise to
the noun thesaurus we used in the rest of the ex-
perimentation, TOP.
Table 1 contains information about each one
of the thesaurus, more precisely, the quantity
of words, words belonging to more than one
synset (ambiguous), the number of synsets where
the most ambiguous word occurs, the quantity
of synsets, the average synset size (number of
words), and the size of the biggest synset7.
5.3 Mapping the triples
The mapping procedure was applied to all the
hypernym-of, part-of and member-of term-based
triples of PAPEL, distributed according to Table 2
where additional numbers on the mapping are pre-
sented. After the first phase of the mapping,
33,172 triples had both of their terms assigned to
a synset, and 10,530 had only one assigned. How-
ever, 4,427 were not really added, either because
the same synset was assigned to both of the terms
or because the triple had already been added after
analysing other term-based triple. In the second
phase, only 89 new triples were mapped and, from
those, 13 had previously been added while other
50 triples were discarded or not attached because
they could be inferred. Another interesting fact is
that 19,638 triples were attached to a synset with
only one term. From those, 5,703 had a synset
7Synsets with only one word were ignored in the construc-
tion of Table 1.
15
with only one term in both arguments.
We ended up with a wordnet with 27,637
synsets, 23,572 hypernym-of, 1,416 part-of and
3,783 member-of synset-based triples.
6 Validation of the results
Evaluation of a new broad-coverage ontology is
most of the times performed by one of two means:
(i) manual evaluation of a representative subset of
the results; (ii) automatic comparison with a gold
standard. However, while for English most re-
searchers use Princeton WordNet as a gold stan-
dard, for other languages it is difficult to find
suitable and freely available consensual resources.
Considering Portuguese, as we have said earlier,
TeP and OT are effectively two manually created
thesaurus but, since they are more complementary
than overlapping to PAPEL, we thought it would
be better to use them to enrich our resource.
There is actually a report (Raman and Bhat-
tacharyya, 2008) with an automatic evaluation of
synsets, but we decided no to follow it because
this evaluation is heavily based on a dictionary and
we do not have unrestricted access to a full and
updated dictionary of Portuguese and also, indi-
rectly by PAPEL, a dictionary was one of our main
sources of information.
Therefore, our choice relied on manual valida-
tion of the synsets of CLIP and TOP. Furthermore,
synset-based triples were validated in an alterna-
tive automatic way using a web search engine.
6.1 Manual validation of synsets
Ten reviewers took part in the validation of ten ran-
dom samples with approximately 50 synsets from
each thesaurus. We made sure that each synset was
not in more than one sample and synsets with more
than 50 terms were not validated. Also, in order to
measure the reviewer agreement, each sample was
analysed by two different reviewers. Given a sam-
ple, each reviewer had to classify each synset as:
correct (1), if, in some context, all the terms of the
synset could have the same meaning, or incorrect
(0), if at least one term of the synset could never
mean the same as the others. The reviewers were
advised to look for the possible meanings of each
word in different dictionaries. Still, if they could
not find them, or if they did not know how to clas-
sify the synset, they had a third option, N/A (2).
In the end, 519 synsets of CLIP and 480 of
TOP were validated. When organising the vali-
dation results we noticed that the biggest synsets
were the ones with more problems. So, besides the
complete validation results, Table 3 also contains
the results considering only synsets of ten or less
words, when a ? is after the name of the thesaurus.
The presented numbers are the average between
the classifications given by the two reviewers and
the agreement rate corresponds to the number of
times both reviewers agreed on the classification.
Even though these results might be subjec-
tive, since they are based on the reviewers cri-
teria and on the dictionaries they used, they can
give an insight on the quality of the synsets.
The precision results are acceptable and are im-
proved if the automatically created thesaurus is
merged with the ones created manually, and
also when bigger synsets are ignored. Most
of the times, big synsets are confusing because
they bring together more than one concept that
share at least one term. For instance, take the
synset: insobriedade, desmedida, imoderac?a?o,
excesso, nimiedade, desmando, desbragamento,
troco, descontrolo, superabunda?ncia, desbunda,
desregramento, demasia, incontine?ncia, imodici-
dade, superac?a?o, intemperanc?a, descomedimento,
superfluidade, sobejida?o, acrasia, where there is a
mix of the concepts: (a) insobriety, not following
all the rules, heedless of the consequences and, (b)
surplus. Both of these concepts can be referred to
as an excess (excesso).
6.2 Automatic validation of triples
The automatic validation of the triples attached to
our wordnet consisted of using Google web search
engine to look for evidence on their truth. This
procedure started by removing terms whose oc-
currences in Google were less than 5,000. Synsets
that became empty were not considered and, from
the rest, a sample was selected for each one of the
three types of relation.
Following the idea in (Gonc?alo Oliveira et al,
2009), a set of natural language generic patterns,
indicative of each relation, was defined having in
mind their input to Google8. Then, for each triple
(A R B), the patterns were used to search for ev-
8Hypernymy patterns included: [hypo] e? um|uma
(tipo|forma|variedade|...)* de [hyper], [hypo] e outros|outras
[hyper] or [hyper] tais como [hypo]. Patterns for part-of and
member-of were the same because these relations can be ex-
pressed in very similar ways, and included: [part/member] e?
(parte|membro|porc?a?o) do|da [whole/group], [part/member]
(faz parte)* do|da [whole/group] or [whole/group] e? um
(grupo|conjunto|...) de [part/member].
16
Sample Correct Incorrect N/A Agreement
CLIP 519 sets 65.8% 31.7% 2.5% 76.1%
CLIP? 310 sets 81.1% 16.9% 2.0% 84.2%
TOP 480 sets 83.2% 15.8% 1.0% 82.3%
TOP? 448 sets 86.8% 12.3% 0.9% 83.0%
Table 3: Results of manual synset validation.
Relation Sample size Validation
Hypernymy of 419 synsets 44,1%
Member of 379 synsets 24,3%
Part of 290 synsets 24,8%
Table 4: Automatic validation of triples
idence on each combination of terms a ? A and
b ? B connected by a pattern indicative of R.
The triple validation score was then calculated by
expression 1, where found(A,B,R) = 1 if evi-
dence is found for the triple or 0 otherwise.
score =
|A|?
i=1
|B|?
j=1
found(A,B,R)
|A| ? |B|
(1)
Table 4 shows the results obtained for each val-
idated sample. Pantel and Pennacchiotti (2008)
perform a similar task and present precision results
for part-of (40.7%-57.4%) and causation (40.0%-
45%) relations. It is however not possible to make
a straight comparison. For their experimentation,
they selected only correct term-based triples ex-
tracted from text and their results were manually
validated by human judges. On the other hand, we
have used term-based triples extracted automati-
cally from a dictionary, with high but not 100%
precision, from where we did not choose only the
correct ones, and we have used synsets obtained
from our clustering procedure which, once again,
have lower precision. Moreover, we validated our
results with Google where, despite its huge dimen-
sion, there are plenty of ways to denote a seman-
tic relation, when we had just a small set textual
patterns. Also, despite occurring more than 5,000
times in Google, some terms correctly included in
a synset were conveying less common meanings.
Nevertheless, we could not agree more with
Pantel and Pennacchiotti (2008) who state that at-
taching term-based triples to an ontology is not an
easy task. Therefore, we believe our results to be
promising and, if more refined rules are added to
our set, which is still very simple, they will surely
be improved.
7 Concluding remarks
We have presented our first approach on two cru-
cial steps on the automatic creation of a wordnet
lexical ontology. Clustering proved to be a good
alternative to create a thesaurus from a dictionary?s
synonymy network, while a few rules can be de-
fined to attach a substantial number of term-based
triples to a synset based resource.
Despite interesting results, in the future we will
work on refining the attachment rules and start in-
tegrating other relations such as causation or pur-
pose. Furthermore, we are devising new methods
for attaching terms to synsets. For instance, we
have recently started to do some experiences with
an attaching method which uses the lexical net-
work?s adjacency matrix to find the most similar
pair of synsets, each of them containing one of the
arguments of a term-based triple.
References
Tim Berners-Lee, James Hendler, and Ora Lassila.
2001. The Semantic Web. Scientific American,
May.
Nicoletta Calzolari, Laura Pecchia, and Antonio Zam-
polli. 1973. Working on the italian machine dictio-
nary: a semantic approach. In Proc. 5th Conference
on Computational Linguistics, pages 49?52, Morris-
town, NJ, USA. Association for Computational Lin-
guistics.
Gerard de Melo and Gerhard Weikum. 2008. On the
utility of automatically generated wordnets. In Proc.
4th Global WordNet Conf. (GWC), pages 147?161,
Szeged, Hungary. University of Szeged.
Bento Carlos Dias-Da-Silva and Helio Roberto
de Moraes. 2003. A construc?a?o de um the-
saurus eletro?nico para o portugue?s do Brasil. ALFA,
47(2):101?115.
Beate Dorow. 2006. A Graph Model for
Words and their Meanings. Ph.D. thesis, Institut
fur Maschinelle Sprachverarbeitung der Universitat
Stuttgart.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database (Language, Speech, and
Communication). The MIT Press.
David Gfeller, Jean-Ce?dric Chappelier, and Paulo
De Los Rios. 2005. Synonym Dictionary Im-
provement through Markov Clustering and Cluster-
ing Stability. In Proc. of International Symposium
on Applied Stochastic Models and Data Analysis
(ASMDA), pages 106?113.
17
Roxana Girju, Adriana Badulescu, and Dan Moldovan.
2006. Automatic discovery of part-whole relations.
Computational Linguistics, 32(1):83?135.
Hugo Gonc?alo Oliveira, Diana Santos, and Paulo
Gomes. 2009. Relations extracted from a por-
tuguese dictionary: results and first evaluation. In
Local Proc. 14th Portuguese Conf. on Artificial In-
telligence (EPIA).
Thomas R. Gruber. 1993. A translation approach to
portable ontology specifications. Knowledge Acqui-
sition, 5(2):199?220.
Sanda M. Harabagiu and Dan I. Moldovan. 2000.
Enriching the wordnet taxonomy with contextual
knowledge acquired from text. In Natural language
processing and knowledge representation: language
for knowledge and knowledge for language, pages
301?333. MIT Press, Cambridge, MA, USA.
Marti A. Hearst. 1992. Automatic acquisition of hy-
ponyms from large text corpora. In Proc. 14th Conf.
on Computational Linguistics, pages 539?545, Mor-
ristown, NJ, USA. Association for Computational
Linguistics.
Graeme Hirst. 2004. Ontology and the lexicon. In
Steffen Staab and Rudi Studer, editors, Handbook
on Ontologies, International Handbooks on Informa-
tion Systems, pages 209?230. Springer.
Adam Kilgarriff. 1997. ?I don?t believe in word
senses?. Computing and the Humanities, 31(2):91?
113.
Dekang Lin and Patrick Pantel. 2002. Concept discov-
ery from text. In Proc. 19th Intl. Conf. on Computa-
tional Linguistics (COLING), pages 577?583.
Palmira Marrafa. 2002. Portuguese Wordnet: gen-
eral architecture and internal semantic relations.
DELTA, 18:131?146.
Emmanuel Navarro, Franck Sajous, Bruno Gaume,
Laurent Pre?vot, ShuKai Hsieh, Tzu Y. Kuo, Pierre
Magistry, and Chu R. Huang. 2009. Wiktionary
and nlp: Improving synonymy networks. In Proc.
Workshop on The People?s Web Meets NLP: Col-
laboratively Constructed Semantic Resources, pages
19?27, Suntec, Singapore. Association for Compu-
tational Linguistics.
Roberto Navigli, Paola Velardi, Alessandro Cuc-
chiarelli, and Francesca Neri. 2004. Extending
and enriching wordnet with ontolearn. In Proc.
2nd Global WordNet Conf. (GWC), pages 279?284,
Brno, Czech Republic. Masaryk University.
Patrick Pantel and Marco Pennacchiotti. 2008. Auto-
matically harvesting and ontologizing semantic rela-
tions. In Paul Buitelaar and Phillip Cimmiano, ed-
itors, Ontology Learning and Population: Bridging
the Gap between Text and Knowledge. IOS Press.
J. Raman and Pushpak Bhattacharyya. 2008. Towards
automatic evaluation of wordnet synsets. In Proc.
4th Global WordNet Conf. (GWC), pages 360?374,
Szeged, Hungary. University of Szeged.
Stephen D. Richardson, William B. Dolan, and Lucy
Vanderwende. 1998. Mindnet: Acquiring and struc-
turing semantic information from text. In Proc. 17th
Intl. Conf. on Computational Linguistics (COLING),
pages 1098?1102.
Maria Ruiz-Casado, Enrique Alfonseca, and Pablo
Castells. 2005. Automatic assignment of wikipedia
encyclopedic entries to wordnet synsets. In Proc.
Advances in Web Intelligence Third Intl. Atlantic
Web Intelligence Conf. (AWIC), pages 380?386.
Springer.
Diana Santos, Anabela Barreiro, Lu??s Costa, Cla?udia
Freitas, Paulo Gomes, Hugo Gonc?alo Oliveira,
Jose? Carlos Medeiros, and Rosa?rio Silva. 2009. O
papel das relac?o?es sema?nticas em portugue?s: Com-
parando o TeP, o MWN.PT e o PAPEL. In Actas do
XXV Encontro Nacional da Associac?a?o Portuguesa
de Lingu??stica (APL). forthcomming.
Stephen Soderland and Bhushan Mandhani. 2007.
Moving from textual relations to ontologized rela-
tions. In Proc. AAAI Spring Symposium on Machine
Reading.
Jorge Teixeira, Lu??s Sarmento, and Euge?nio C.
Oliveira. 2010. Comparing verb synonym resources
for portuguese. In Computational Processing of the
Portuguese Language, 9th Intl. Conference, Proc.
(PROPOR), pages 100?109.
Peter D. Turney. 2001. Mining the web for synonyms:
PMI?IR versus LSA on TOEFL. In Proc. 12th Euro-
pean Conf. on Machine Learning (ECML), volume
2167, pages 491?502. Springer.
S. M. van Dongen. 2000. Graph Clustering by Flow
Simulation. Ph.D. thesis, University of Utrecht.
Piek Vossen. 1997. Eurowordnet: a multilingual
database for information retrieval. In Proc. DE-
LOS workshop on Cross-Language Information Re-
trieval, Zurich.
Tonio Wandmacher, Ekaterina Ovchinnikova, Ulf
Krumnack, and Henrik Dittmann. 2007. Extrac-
tion, evaluation and integration of lexical-semantic
relations for the automated construction of a lexical
ontology. In Third Australasian Ontology Workshop
(AOW), volume 85 of CRPIT, pages 61?69, Gold
Coast, Australia. ACS.
Torsten Zesch, Christof Mu?ller, and Iryna Gurevych.
2008. Extracting lexical semantic knowledge from
Wikipedia and Wiktionary. In Proc. 6th Intl.
Language Resources and Evaluation (LREC), Mar-
rakech, Morocco.
18
