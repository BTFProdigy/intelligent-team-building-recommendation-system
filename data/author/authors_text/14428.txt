Proceedings of the NAACL HLT 2010 First International Workshop on Formalisms and Methodology for Learning by Reading, pages 78?86,
Los Angeles, California, June 2010. c?2010 Association for Computational Linguistics
Unsupervised techniques for discovering ontology 
elements from Wikipedia article links 
Zareen Syed Tim Finin 
University of Maryland, Baltimore County University of Maryland, Baltimore County 
1000 Hilltop Circle 1000 Hilltop Circle 
Baltimore, MD 21250, USA Baltimore, MD 21250, USA 
zarsyed1@umbc.edu finin@umbc.edu 
 
 
 
 
Abstract 
We present an unsupervised and unrestricted 
approach to discovering an infobox like on-
tology by exploiting the inter-article links 
within Wikipedia. It discovers new slots and 
fillers that may not be available in the 
Wikipedia infoboxes. Our results demonstrate 
that there are certain types of properties that 
are evident in the link structure of resources 
like Wikipedia that can be predicted with high 
accuracy using little or no linguistic analysis. 
The discovered properties can be further used 
to discover a class hierarchy. Our experiments 
have focused on analyzing people in Wikipe-
dia, but the techniques can be directly applied 
to other types of entities in text resources that 
are rich with hyperlinks.  
1 Introduction  
One of the biggest challenges faced by the Seman-
tic Web vision is the availability of structured data 
that can be published as RDF. One approach is to 
develop techniques to translate information in 
spreadsheets, databases, XML documents and 
other traditional data formats into RDF (Syed et al 
2010). Another is to refine the technology needed 
to extract structured information from unstructured 
free text (McNamee and Dang, 2009). 
For both approaches, there is a second problem 
that must be addressed: do we start with an ontol-
ogy or small catalog of ontologies that will be used 
to encode the data or is extracting the right ontol-
ogy part of the problem. We describe exploratory 
work on a system that can discover ontological 
elements as well as data from a free text with em-
bedded hyperlinks. 
Wikipedia is a remarkable and rich online en-
cyclopedia with a wealth of general knowledge 
about varied concepts, entities, events and facts in 
the world. Its size and coverage make it a valuable 
resource for extracting information about different 
entities and concepts. Wikipedia contains both free 
text and structured information related to concepts 
in the form of infoboxes, category hierarchy and 
inter-article links. Infoboxes are the most struc-
tured form and are composed of a set of subject-
attribute-value triples that summarize or highlight 
the key features of the concept or subject of the 
article. Resources like DBpedia (Auer et al, 2007) 
and Freebase (Bollacker et al, 2007) have har-
vested this structured data and have made it avail-
able as triples for semantic querying.  
While infoboxes are a readily available source 
of structured data, the free text of the article con-
tains much more information about the entity. 
Barker et al (2007) unified the state of the art ap-
proaches in natural language processing and 
knowledge representation in their prototype system 
for understanding free text. Text resources which 
are rich in hyperlinks especially to knowledge 
based resources (such as encyclopedias or diction-
aries) have additional information encoded in the 
form of links, which can be used to complement 
the existing systems for text understanding and 
knowledge discovery. Furthermore, systems such 
as Wikify (Mihalcea and Csomai, 2007) can be 
employed to link words in free text to knowledge 
resources like Wikipedia and thus enrich the free 
text with hyperlinks. 
We describe an approach for unsupervised on-
tology discovery from links in the free text of the 
Wikipedia articles, without specifying a relation or 
set of relations in advance. We first identify candi-
date slots and fillers for an entity, then classify en-
78
tities and finally derive a class hierarchy. We have 
evaluated our approach for the Person class, but it 
can be easily generalized to other entity types such 
as organizations, places, and products.   
The techniques we describe are not suggested 
as alternatives to natural language understanding or 
information extraction, but as a source for addi-
tional evidence that can be used to extract onto-
logical elements and relations from the kind of text 
found in Wikipedia and other heavily-linked text 
collections. This approach might be particularly 
useful in ?slot fillings? tasks like the one in the 
Knowledge Base Population track (McNamee and 
Dang, 2010) at the 2009 Text Analysis Confer-
ence.  We see several contributions that this work 
has to offer: 
? Unsupervised and unrestricted ontology discov-
ery. We describe an automatic approach that 
does not require a predefined list of relations or 
training data. The analysis uses inter-article 
links in the text and does not depend on existing 
infoboxes, enabling it to suggest slots and fillers 
that do not exist in any extant infoboxes. 
? Meaningful slot labels. We use WordNet (Mil-
ler et al, 1990) nodes to represent and label 
slots enabling us to exploit WordNet?s hy-
pernym and hyponym relations as a property hi-
erarchy. 
? Entity classification and class labeling. We in-
troduce a new feature set for entity classifica-
tion, i.e. the discovered ranked slots, which per-
forms better than other feature sets extracted 
from Wikipedia. We also present an approach 
for assigning meaningful class label vectors us-
ing WordNet nodes. 
? Deriving a class hierarchy. We have developed 
an approach for deriving a class hierarchy based 
on the ranked slot similarity between classes 
and the label vectors.  
In the remainder of the paper we describe the de-
tails of the approach, mention closely related work, 
present and discuss preliminary results and provide 
some conclusions and possible next steps. 
2 Approach 
Figure 1 shows our ontology discovery framework 
and its major steps. We describe each step in the 
rest of this section.  
2.1 Discovering Candidate Slots and Fillers 
Most Wikipedia articles represent a concept, i.e., a 
generic class of objects (e.g., Musician), an indi-
vidual object (e.g., Michael_Jackson), or a generic 
relation or property (e.g., age). Inter-article links 
within Wikipedia represent relations between con-
cepts. In our approach we consider the linked con-
cepts as candidate fillers for slots related to the 
primary article/concept. There are several cases 
where the filler is subsumed by the slot label for 
example, the infobox present in the article on ?Mi-
chael_Jackson? (Figure 2) mentions pop, rock and 
soul as fillers for the slot Genre and all three of 
these are a type of Genre. The Labels slot contains 
fillers such as Motown, Epic and Legacy which are 
all Record Label Companies. Based on this obser-
vation, we discover and exploit ?isa? relations be-
tween fillers (linked concepts) and WordNet nodes 
to serve as candidate slot labels.  
In order to find an ?isa? relation between a con-
cept and a WordNet synset we use manually cre-
ated mappings by DBpedia, which links about 
467,000 articles to synsets. However, Wikipedia 
has more than two million articles1, therefore, to 
map any remaining concepts we use the automati-
cally generated mappings available between 
WordNet synsets and Wikipedia categories 
(Ponzetto and Navigli, 2009). A single Wikipedia 
article might have multiple categories associated 
with it and therefore multiple WordNet synsets. 
Wikipedia?s category system serves more as a way 
to tag articles and facilitate navigation rather than 
                                                 
1 This estimate is for the English version and does not 
include redirects and administrative pages such as dis-
ambiguation pages. 
 
Figure 1: The ontology discovery framework com-
prises a number of steps, including candidate slot and 
filler discovery followed by slot ranking, slot selec-
tion, entity classification, slot re-ranking, class label-
ing, and class hierarchy discovery. 
79
to categorize them. The article on Michael Jordan, 
for example, has 36 categories associated with it. 
In order to select an individual WordNet synset as 
a label for the concept?s type, we use two heuris-
tics: 
? Category label extraction. Since the first sen-
tence in Wikipedia articles usually defines the 
concept, we extract a category label from the 
first sentence using patterns based on POS tags 
similar to Kazama and Torisawa (2007). 
? Assign matching WordNet synset. We con-
sider all the WordNet synsets associated with 
the categories of the article using the category 
to WordNet mapping (Ponzetto and Navigli, 
2009) and assign the WordNet synset if any of 
the words in the synset matches with the ex-
tracted category label. We repeat the process 
with hypernyms and hyponyms of the synset 
up to three levels.  
2.2 Slot Ranking 
All slots discovered using outgoing links might not 
be meaningful, therefore we have developed tech-
niques for ranking and selecting slots. Our ap-
proach is based on the observation that entities of 
the same type have common slots. For example, 
there is a set of slots common for musical artists 
whereas, a different set is common for basketball 
players. The Wikipedia infobox templates based 
on classes also provide a set of properties or slots 
to use for particular types of entities or concepts.  
In case of people, it is common to note that 
there is a set of slots that are generalized, i.e., they 
are common across all types of persons.  Examples 
are name, born, and spouse.  There are also sets of 
specialized slots, which are generally associated 
with a given profession.  For example, the slots for 
basketball players have information for basketball 
related activities and musical artists have slots with 
music related activities. The slots for ?Mi-
chael_Jordan? include Professional Team(s), NBA 
Draft, Position(s) and slots for ?Michael_Jackson? 
include Genres, Instruments and Labels. 
Another observation is that people engaged in a 
particular profession tend to be linked to others 
within the same profession.  Hence the maxim ?A 
man is known by the company he keeps.? For ex-
ample, basketball players are linked to other bas-
ketball players and politicians are linked to other 
politicians. We rank the slots based on the number 
of linked persons having the same slots. We gener-
ated a list of person articles in Wikipedia by get-
ting all Wikipedia articles under the Person type in 
Freebase2. We randomly select up to 25 linked per-
sons (which also link back) and extract their candi-
date slots and vote for a slot based on the number 
of times it appears as a slot in a linked person nor-
malized by the number of linked persons to assign 
a slot score.  
2.3 Entity Classification and Slot Re-Ranking 
The ranked candidate slots are used to classify en-
tities and then further ranked based on number of 
times they appear among the entities in the cluster. 
We use complete link clustering using a simple slot 
similarity function: 
 
 
 
This similarity metric for slots is computed as the 
cosine similarity between tf.idf weighted slot vec-
tors, where the slot score represents the term fre-
                                                 
2 We found that the Freebase classification for Person 
was more extensive that DBpedia?s in the datasets avail-
able to us in early 2009. 
 
 
 
 
Figure 2.  The Wikipedia infobox 
for the Michael_Jackson article has 
a number of slots from appropriate 
infobox templates. 
 
80
quency component and the inverse document fre-
quency is based on the number of times the slot 
appears in different individuals. 
We also collapsed location expressing slots 
(country, county, state, district, island etc.) into the 
slot labeled location by generating a list of location 
words from WordNet as these slots were causing 
the persons related to same type of geographical 
location to cluster together.  
After clustering, we re-score the slots based on 
number of times they appear among the individuals 
in the cluster normalized by the cluster size. The 
output of clustering is a vector of scored slots as-
sociated with each cluster. 
2.4 Slot Selection 
The slot selection process identifies and filters out 
slots judged to be irrelevant. Our intuition is that 
specialized slots or attributes for a particular entity 
type should be somehow related to each other. For 
example, we would expect attributes like league, 
season and team for basketball players and genre, 
label, song and album for musical artists. If an at-
tribute like album appears for basketball players it 
should be discarded as it is not related to other at-
tributes. 
We adopted a clustering approach for finding 
attributes that are related to each other. For each 
pair of attributes in the slot vector, we compute a 
similarity score based on how many times the two 
attribute labels appear together in Wikipedia per-
son articles within a distance of 100 words as 
compared to the number of times they appear in 
total and weigh it using weights of the individual 
attributes in the slot vector. This metric is captured 
in the following equation, where Df is the docu-
ment frequency and wt is the attribute weight. 
 
 
Our initial experiments using single and com-
plete link clustering revealed that single link was 
more appropriate for slot selection. We got clusters 
at a partition distance of 0.9 and selected the larg-
est cluster from the set of clusters. In addition, we 
also added any attributes exceeding a 0.4 score into 
the set of selected attributes. Selected ranked slots 
for Michael Jackson are given in Table 1.   
2.5 Class Labeling 
Assigning class labels to clusters gives additional 
information about the type of entities in a cluster. 
We generate a cluster label vector for each cluster 
which represents the type of entities in the cluster. 
We compute a list of person types by taking all 
hyponyms under the corresponding person sense in 
WordNet. That list mostly contained the profes-
sions list for persons such as basketball player, 
president, bishop etc. To assign a WordNet type to 
a person in Wikipedia we matched the entries in 
the list to the words in the first sentence of the per-
son article and assigned it the set of types that 
matched. For example, for Michael Jordan the 
matching types found were basketball_player, 
businessman and player. 
We assigned the most frequent sense to the 
matching word as followed by Suchanek et al 
(2008) and Wu and Weld (2008), which works for 
majority of the cases. We then also add all the hy-
pernyms of the matching types under the Person 
node. The vector for Michael Jordan has entries 
basketball_player, athlete, businessperson, person, 
contestant, businessman and player. After getting 
matching types and their hypernyms for all the 
members of the cluster, we score each type based 
on the number of times it occurs in its members 
normalized by the cluster size. For example for one 
of the clusters with 146 basketball players we got 
the following label vector: {player:0.97, contest-
ant:0.97, athlete:0.96, basketball_player:0.96}. To 
select an individual label for a class we can pick 
the label with the highest score (the most general-
Slot Score Fillers Example 
Musician 1.00 ray_charles, sam_cooke ...  
Album 0.99 bad_(album), ... 
Location 0.97 gary,_indiana,  chicago,  ? 
Music_genre 0.90 pop_music, soul_music, ... 
Label 0.79 a&m_records, epic_records, ... 
Phonograph_ 
record 
0.67 
give_in_to_me, 
this_place_hotel ? 
Act 0.59 singing 
Movie 0.46 moonwalker ? 
Company 0.43 war_child_(charity), ? 
Actor 0.41 stan_winston, eddie_murphy,  
Singer 0.40 britney_spears, ? 
Magazine 0.29 entertainment_weekly,? 
Writing_style 0.27 hip_hop_music 
Group 0.21 'n_sync, RIAA 
Song 0.20 d.s._(song) ? 
 
  Table 1: Fifteen slots were discovered for musician 
Michael Jackson along with scores and example fillers. 
81
ized label) or the most specialized label having a 
score above a given threshold. 
2.6 Discovering Class Hierarchy 
We employ two different feature sets to discover 
the class hierarchy, i.e., the selected slot vectors 
and the class label vectors and combine both func-
tions using their weighted sum. The similarity 
functions are described below. 
The common slot similarity function is the co-
sine similarity between the common slot tf.idf vec-
tors, where the slot score represents the tf and the 
idf is based on the number of times a particular slot 
appears in different clusters at that iteration. We 
re-compute the idf term in each iteration. We de-
fine the common slot tf.idf vector for a cluster as 
one where we assign a non-zero weight to only the 
slots that have non-zero weight for all cluster 
members. The label similarity function is the co-
sine similarity between the label vectors for clus-
ters.  The hybrid similarity function is a weighted 
sum of the common slot and label similarity func-
tions. Using these similarity functions we apply 
complete link hierarchical clustering algorithm to 
discover the class hierarchy. 
 
 
3 Experiments and Evaluation 
For our experiments and evaluation we used the 
Wikipedia dump from March 2008 and the DBpe-
dia infobox ontology created from Wikipedia 
infoboxes using hand-generated mappings (Auer et 
al., 2007). The Person class is a direct subclass of 
the owl:Thing class and has 21 immediate sub-
classes and 36 subclasses at the second level. We 
used the persons in different classes in DBpedia 
ontology at level two to generate data sets for ex-
periments.  
There are several articles in Wikipedia that are 
very small and have very few out-links and in-
links. Our approach is based on the out-links and 
availability of information about different related 
things on the article, therefore, in order to avoid 
data sparseness, we randomly select articles with 
greater than 100 in-links and out-links, at least 
5KB page length and having at least five links to 
entities of the same type that link back (in our case 
persons).  
We first compare our slot vector features with 
other features extracted from Wikipedia for entity 
classification task and then evaluate their accuracy. 
We then discover the class hierarchy and compare 
the different similarity functions.  
3.1 Entity Classification 
We did some initial experiments to compare our 
ranked slot features with other feature sets ex-
tracted from Wikipedia. We created a dataset com-
posed of 25 different classes of Persons present at 
level 2 in the DBpedia ontology by randomly se-
lecting 200 person articles from each class. For 
several classes we got less than 200 articles which 
fulfilled our selection criteria defined earlier. We 
generated twelve types of feature sets and evalu-
ated them using ground truth from DBpedia ontol-
ogy. 
We compare tf.idf vectors constructed using 
twelve different feature sets: (1) Ranked slot fea-
tures, where tf is the slot score; (2) Words in first 
sentence of an article; (3) Associated categories; 
(4) Assigned WordNet nodes (see section 2.2); (5) 
Associated categories tokenized into words; (6) 
Combined Feature Sets 1 to 5 (All); (7-11) Feature 
sets 7 to 11 are combinations excluding one feature 
set at a time; (12) Unranked slots where tf is 1 for 
all slots. We applied complete link clustering and 
evaluated the precision, recall and F-measure at 
different numbers of clusters ranging from one to 
100.  Table 2 gives the precision, recall and num-
ber of clusters where we got the maximum F-
measure using different feature sets. 
82
 Feature set 10 (all features except feature 2) gave 
the best F-measure i.e. 0.74, whereas, feature set 1 
(ranked slots only) gave the second best F-measure 
i.e. 0.73 which is very close to the best result. Fea-
ture set 12 (unranked slots) gave a lower F-
measure i.e. 0.61 which shows that ranking or 
weighing slots based on linked entities of the same 
type performs better for classification. 
3.2 Slot and Filler Evaluation 
To evaluate our approach to finding slot fillers, we 
focused on DBpedia classes two levels below Per-
son (e.g., Governor and FigureSkater). We ran-
domly selected 200 articles from each of these 
classes using the criteria defined earlier to avoid 
data sparseness. Classes for which fewer than 20 
articles were found were discarded. The resulting 
dataset comprised 28 classes and 3810 articles3. 
We used our ranked slots tf.idf feature set and 
ran a complete link clustering algorithm producing 
clusters at partition distance of 0.8. The slots were 
re-scored based on the number of times they ap-
peared in the cluster members normalized by the 
cluster size. We applied slot selection over the re-
scored slots for each cluster. In order to evaluate 
our slots and fillers we mapped each cluster to a 
DBpedia class based on the maximum number of 
members of a particular DBpedia class in our clus-
ter. This process predicted 124 unique properties 
for the classes.  Of these, we were able to manually 
align 46 to properties in either DBpedia or Free-
                                                 
3 For some of the classes, fewer than the full comple-
ment of 200 articles were found. 
base for the corresponding class. We initially tried 
to evaluate the discovered slots by comparing them 
with those found in the ontologies underlying 
DBpedia and Freebase, but were able to find an 
overlap in the subject and object pairs for very few 
properties. 
We randomly selected 20 subject object pairs 
for each of the 46 properties from the correspond-
ing classes and manually judged whether or not the 
relation was correct by consulting the correspond-
No. Property Accuracy 
1 automobile_race 1.00 
2 championship 1.00 
3 expressive_style 1.00 
4 fictional_character 1.00 
5 label 1.00 
6 racetrack 1.00 
7 team_sport 1.00 
8 writing_style 1.00 
9 academic_degree 0.95 
10 album 0.95 
11 book 0.95 
12 contest 0.95 
13 election 0.95 
14 league 0.95 
15 phonograph_record 0.95 
16 race 0.95 
17 tournament 0.94 
18 award 0.90 
19 movie 0.90 
20 novel 0.90 
21 school 0.90 
22 season 0.90 
23 serial 0.90 
24 song 0.90 
25 car 0.85 
26 church 0.85 
27 game 0.85 
28 musical_instrument 0.85 
29 show 0.85 
30 sport 0.85 
31 stadium 0.85 
32 broadcast 0.80 
33 telecast 0.80 
34 hockey_league 0.75 
35 music_genre 0.70 
36 trophy 0.70 
37 university 0.65 
38 character 0.60 
39 disease 0.60 
40 magazine 0.55 
41 team 0.50 
42 baseball_club 0.45 
43 club 0.45 
44 party 0.45 
45 captain 0.30 
46 coach 0.25 
  Avg. Accuracy: 0.81 
 
Table 3: Manual evaluation of discovered properties 
 
No. Feature Set k P R F 
1 Ranked Slots  40 0.74 0.72 0.73 
2 First Sentence 89 0.07 0.53 0.12 
3 Categories 1 0.05 1.00 0.10 
4 WordNet Nodes 87 0.40 0.22 0.29 
5 (3 tokenized) 93 0.85 0.47 0.60 
6 All (1 to 5) 68 0.87 0.62 0.72 
7 (All ? 5) 82 0.79 0.46 0.58 
8 (All ? 4) 58 0.78 0.63 0.70 
9 (All ? 3) 53 0.76 0.65 0.70 
10 (All ? 2) 58 0.88 0.63 0.74 
11 (All ? 1) 57 0.77 0.60 0.68 
12 (1 unranked) 34 0.57 0.65 0.61 
 
Table 2: Comparison of the precision, recall and F-
measure for different feature sets for entity classifi-
cation.  The k column shows the number of clusters 
that maximized the F score.  
 
83
ing Wikipedia articles (Table 3).  The average ac-
curacy for the 46 relations was 81%. 
3.3 Discovering Class Hierarchy 
In order to discover the class hierarchy, we took all 
of the clusters obtained earlier at partition distance 
of 0.8 and their corresponding slot vectors after 
slot selection. We experimented with different 
similarity functions and evaluated their accuracy 
by comparing the results with the DBpedia ontol-
ogy. A complete link clustering algorithm was ap-
plied using different settings of the similarity func-
tions and the resulting hierarchy compared to 
DBpedia?s Person class hierarchy. Table 4 shows 
the highest F measure obtained for Person?s imme-
diate sub-classes (L1), ?sub-sub-classes? (L2) and 
the number of clusters (k) for which we got the 
highest F-measure using a particular similarity 
function. 
The highest F-measure both at level 2 (0.63) and 
level 1 (0.79) was obtained by simhyb with wc=0.2, 
wl=0.8 and also at lowest number of clusters at L1 
(k=8). The simhyb (wc=wl=0.5) and simlabel functions 
gave almost the same F-measure at both levels. 
The simcom_slot function gave better performance at 
L1 (F=0.65) than the base line simslot (F=0.55) 
which was originally used for entity clustering. 
However, both these functions gave the same F-
measure at L2 (F=0.61). 
4 Discussion  
In case of property evaluation, properties for which 
the accuracy was 60% or below include coach, 
captain, baseball_club, club, party, team and 
magazine. For the magazine property (correspond-
ing to Writer and ComicsCreator class) we ob-
served that many times a magazine name was men-
tioned in an article because it published some news 
about a person rather than that person contributing 
any article in that magazine. For all the remaining 
properties we observed that these were related to 
some sort of competition. For example, a person 
played against a team, club, coach or captain. The 
political party relation is a similar case, where arti-
cles frequently mention a politician?s party affilia-
tion as well as significant opposition parties. For 
such properties, we need to exploit additional con-
textual information to judge whether the person 
competed ?for? or ?against? a particular team, 
club, coach or party. Even if the accuracy for fill-
ers for such slots is low, it can still be useful to 
discover the kind of slots associated with an entity.  
We also observed that there were some cases 
where the property was related to a family member 
of the primary person such as for disease, school 
and university. Certain other properties such as 
spouse, predecessor, successor, etc. require more 
contextual information and are not directly evident 
in the link structure. However, our experiments 
show that there are certain properties that can be 
predicted with high accuracy using the article links 
only and can be used to enrich the existing infobox 
ontology or for other purposes.  
While our work has mostly experimented with 
person entities, the approach can be applied to oth-
er types as well. For example, we were able to dis-
cover software as a candidate slot for companies 
like Microsoft, Google and Yahoo!, which ap-
peared among the top three ranked slots using our 
slot ranking scheme and corresponds to the prod-
ucts slot in the infoboxes of these companies.  
For class hierarchy discovery, we have ex-
ploited the specialized slots after slot selection. 
One way to incorporate generalized slots in the 
hierarchy is to consider all slots for class members 
(without slot selection) and recursively propagate 
the common slots present at any level to the level 
above it. For example, if we find the slot team to 
be common for different types of Athletes such as 
basketball players, soccer players etc. we can 
propagate it to the Athlete class, which is one level 
higher in the hierarchy.  
5 Related Work 
Unsupervised relation discovery was initially in-
troduced by Hasegawa et al (2004). They devel-
oped an approach to discover relations by cluster-
ing pairs of entities based on intervening words 
represented as context vectors. Shinyama and Se-
kine (2006) generated basic patterns using parts of 
text syntactically connected to the entity and then 
Similarity Function k (L=2) 
F 
(L=2) 
k 
(L=1) 
F 
(L=1) 
simslot  56 0.61 13 0.55 
simcom_slot  74 0.61 15 0.65 
simlabel  50 0.63 10 0.76 
simhyb wc=wl=0.5 59 0.63 10 0.76 
simhyb wc=0.2, wl=0.8 61 0.63 8 0.79 
 
Table 4: Evaluation results for class hierarchy predic-
tion using different similarity functions. 
84
generated a basic cluster composed of a set of 
events having the same relation. 
Several approaches have used linguistic analysis 
to generate features for supervised or un-
supervised relation extraction (Nguyen et al, 2007; 
Etzioni et al, 2008; Yan et al, 2009). Our ap-
proach mainly exploits the heavily linked structure 
of Wikipedia and demonstrates that there are sev-
eral relations that can be discovered with high ac-
curacy without the need of features generated from 
a linguistic analysis of the Wikipedia article text.  
Suchanek et al (2008) used Wikipedia catego-
ries and infoboxes to extract 92 relations by apply-
ing specialized heuristics for each relation and in-
corporated the relations in their YAGO ontology, 
whereas our techniques do not use specialized heu-
ristics based on the type of relation.  Kylin (Weld 
et al, 2008) generated infoboxes for articles by 
learning from existing infoboxes, whereas we can 
discover new fillers for several existing slots and 
also discover new slots for infoboxes. KOG (Wu 
and Weld, 2008) automatically refined the Wiki-
pedia infobox ontology and integrated Wikipedia?s 
infobox-class schemata with WordNet. Since we 
already use the WordNet nodes for representing 
slots, it eliminates the need for several of KOG?s 
infobox refinement steps. 
While YAGO, Kylin and KOG all rely on rela-
tions present in the infoboxes, our approach can 
complement these by discovering new relations 
evident in inter-article links in Wikipedia. For ex-
ample, we could add slots like songs and albums to 
the infobox schema for Musical Artists, movies for 
the Actors infobox schema, and party for the Poli-
ticians schema. 
6 Conclusions and Future Work 
People have been learning by reading for thou-
sands of years.  The past decade, however, has 
seen a significant change in the way people read.  
The developed world now does much of its reading 
online and this change will soon be nearly univer-
sal.  Most online content is read as hypertext via a 
Web browser or custom reading device. Unlike 
text, hypertext is semi-structured information, es-
pecially when links are drawn from global name-
space, making it easy for many documents to link 
unambiguously to a common referent. 
The structured component of hypertext aug-
ments the information in its plain text and provides 
an additional source of information from which 
both people and machines can learn.  The work 
described in this paper is aimed at learning useful 
information, both about the implicit ontology and 
facts, from the links embedded in collection of hy-
pertext documents. 
Our approach is fully unsupervised and does 
not require having a pre-defined catalogue of rela-
tions. We have discovered several new slots and 
fillers that are not present in existing Wikipedia 
infoboxes and also a scheme to rank the slots based 
on linked entities of the same type. We compared 
our results with ground truth from the DBpedia 
infobox ontology and Freebase for the set of prop-
erties that were common and manually evaluated 
the accuracy of the common properties. Our results 
show that there are several properties that can be 
discovered with high accuracy from the link struc-
ture in Wikipedia and can also be used to discover 
a class hierarchy.  
We plan to explore the discovery of slots from 
non-Wikipedia articles by linking them to Wikipe-
dia concepts using existing systems like Wikify 
(Mihalcea and Csomai, 2007). Wikipedia articles 
are encyclopedic in nature with the whole article 
revolving around a single topic or concept.  Con-
sequently, linked articles are a good source of 
properties and relations. This might not be the case 
in other genres, such as news articles, that discuss 
a number of different entities and events.  One way 
to extend this work to other genres is by first de-
tecting the entities in the article and then only 
processing links in sentences that mention an entity 
to discover its properties. 
Acknowledgements 
The research described in this paper was supported 
in part by a Fulbright fellowship, a gift from Mi-
crosoft Research, NSF award IIS-0326460 and the 
Johns Hopkins University Human Language Tech-
nology Center of Excellence. 
85
 References 
S?ren Auer, Christian Bizer, Georgi Kobilarov, Jens 
Lehmann and Zachary Ives. 2007. DBpedia: A nu-
cleus for a web of open data. In Proceedings of the 
6th International Semantic Web Conference: 11?15. 
Ken Barker et al 2007. Learning by reading: A proto-
type system, performance baseline and lessons 
learned, Proceedings of the 22nd National Confer-
ence on Artificial Intelligence, AAAI Press. 
K. Bollacker, R. Cook, and P. Tufts. 2007. Freebase: A 
Shared Database of Structured General Human 
Knowledge. Proceedings of the National Conference 
on Artificial Intelligence (Volume 2): 1962-1963.  
Oren Etzioni, Michele Banko, Stephen Soderland, and 
Daniel S. Weld. 2008. Open information extraction 
from the web. Communications of the ACM 51, 12 
(December): 68-74. 
Takaaki Hasegawa, Satoshi Sekine, and Ralph Grish-
man. 2004. Discovering relations among named enti-
ties from large corpora. In Proceedings of the 42nd 
Annual Meeting of the Association for Computa-
tional Linguistics: 415-422.  
Jun?ichi Kazama and Kentaro Torisawa. 2007. Exploit-
ing Wikipedia as external knowledge for named en-
tity recognition. In Proceedings of the 2007 Joint 
Conference on Empirical Methods in Natural Lan-
guage Processing and Computational Natural Lan-
guage Learning: 698?707. 
Paul McNamee and Hoa Trang Dang. 2009. Overview 
of the TAC 2009 knowledge base population track. 
In Proceedings of the 2009 Text Analysis Confer-
ence. National Institute of Standards and Technol-
ogy, November. 
Rada Mihalcea and Andras Csomai. 2007. Wikify!: 
linking documents to encyclopedic knowledge. In 
Proceedings of the 16th ACM Conference on 
Information and Knowledge Management: 233?242.  
George A. Miller, Richard Beckwith, Christiane Fell-
baum, Derek Gross, and Katherine Miller. 1990. 
WordNet: An on-line lexical database. International 
Journal of Lexicography, 3:235?244.  
Dat P. T. Nguyen, Yutaka Matsuo, and Mitsuru Ishizu-
ka. 2007. Subtree mining for relation extraction from 
Wikipedia. In Proceedings of Human Language 
Technologies: The Annual Conference of the North 
American Chapter of the Association for Computa-
tional Linguistics:125?128. 
Fabian M. Suchanek, Gjergji Kasneci, and Gerhard 
Weikum. 2008. Yago: A large ontology from 
Wikipedia and WordNet. Web Semantics, 6(3):203?
217. 
Zareen Syed, Tim Finin, Varish Mulwad and Anupam 
Joshi. 2010. Exploiting a Web of Semantic Data for 
Interpreting Tables, Proceedings of the Second Web 
Science Conference. 
Simone P. Ponzetto and Roberto Navigli. 2009. Large-
scale taxonomy mapping for restructuring and inte-
grating Wikipedia. In Proceedings of the Twenty-
First International Joint Conference on Artificial In-
telligence: 2083?2088.  
Yusuke Shinyama and Satoshi Sekine. 2006. Pre-emp-
tive information extraction using unrestricted relation 
discovery. In Proceedings of Human Language Tech-
nologies: The Annual Conference of the North 
American Chapter of the Association for Computa-
tional Linguistics:.  
Daniel S. Weld, Raphael Hoffmann, and Fei Wu. 2008. 
Using Wikipedia to bootstrap open information ex-
trac-tion. SIGMOD Record, 37(4): 62?68. 
Fei Wu and Daniel S. Weld. 2008. Automatically refin-
ing the Wikipedia infobox ontology. In Proceedings 
of the 17th International World Wide Web Confer-
ence, pages 635?644. 
Wikipedia. 2008. Wikipedia, the free encyclopedia. 
Yulan Yan, Naoaki Okazaki, Yutaka Matsuo, Zhenglu 
Yang, and Mitsuru Ishizuka. 2009. Unsupervised re-
lation extraction by mining Wikipedia texts using in-
formation from the web. In Proceedings of the 47th 
Annual Meeting of the Association for Computa-
tional Linguistics: Volume 2: 1021?1029.  
 
86
Proceedings of the NAACL HLT 2010 First International Workshop on Formalisms and Methodology for Learning by Reading, pages 105?113,
Los Angeles, California, June 2010. c?2010 Association for Computational Linguistics
A Hybrid Approach to Unsupervised Relation Discovery Based on 
Linguistic Analysis and Semantic Typing 
 
Zareen Syed Evelyne Viegas 
University of Maryland Baltimore County Microsoft Research 
1000 Hilltop Circle One Microsoft Way 
Baltimore, MD 21229, USA Redmond, WA 98052, USA 
 
Abstract 
 This paper describes a hybrid approach for 
unsupervised and unrestricted relation discov-
ery between entities using output from linguis-
tic analysis and semantic typing information 
from a knowledge base. We use Factz (en-
coded as subject, predicate and object triples) 
produced by Powerset as a result of linguistic 
analysis. A particular relation may be ex-
pressed in a variety of ways in text and hence 
have multiple facts associated with it. We 
present an unsupervised approach for collaps-
ing multiple facts which represent the same 
kind of semantic relation between entities.  
Then a label is selected for the relation based 
on the input facts and entropy based label 
ranking of context words.  Finally, we demon-
strate relation discovery between entities at 
different levels of abstraction by leveraging 
semantic typing information from a know-
ledge base.     
1 Introduction 
There are a number of challenges involved when 
using facts extracted from text to enrich a know-
ledge base (KB) with semantic relations between 
entities:  co-reference resolution as there are 
many co-referent objects; entity resolution in 
order to link the entities mentioned in text to the 
right entities in the KB; handling co-referent re-
lations, as a particular semantic relation between 
entities can be expressed in a variety of ways in 
the text and therefore have multiple facts asso-
ciated between the entities. In addition,  the facts 
extracted from linguistic analysis are usually noi-
sy and sparse. 
Our work focuses on a recent line of explora-
tory work in the direction of Unrestricted Rela-
tion Discovery which is defined as: the automatic 
identification of different relations in text with-
out specifying a relation or set of relations in ad-
vance (Shinyama and Sekine, 2006). We use the 
facts which are the output of linguistic analysis 
from Powerset (www.Powerset.com). Powerset 
is an online search engine for querying Wikipe-
dia using Natural Language Queries. Powerset 
performs a linguistic analysis of the sentences 
within Wikipedia and outputs facts in the form of 
subject, predicate and object triples which can be 
queried through the online interface. For most 
entities like persons, places and things, Powerset 
shows a summary of facts from across Wikipedia 
(figure 1). In our approach we use the readily 
available ?Factz? from Powerset as input to our 
system. Powerset is Wikipedia independent and 
can run on any corpus with well-formed sen-
tences and hence our approach is also not limited 
to Wikipedia. The Factz output from Powerset 
may represent relations between named entities 
or just nouns for example, 
 
Bank of America   <acquired>  bank 
Bank of America   <acquired>  Merrill Lynch 
Bank of America    <owned>  building 
 
Linguistic analysis has been recently de-
scribed as an effective technique for relation ex-
traction (Yan et al, 2009; Kambhatla, 2004; 
Nguyen et al, 2007).  Following that trend, we 
incorporate Factz, that are the output of linguistic 
analysis done by Powerset, to discover semantic 
relations between entities.  
Information from existing knowledge re-
 
Figure 1. Demonstration of Powerset Factz available 
online 
105
sources can help in tasks like named entity dis-
ambiguation by providing additional context in 
the form of linked entities in the KB and aid in 
linking the entities mentioned in the text to the 
entities in the KB. The KB can also provide in-
formation about the entity types which can in 
turn be used to discover relations between entity 
types at different levels of abstraction and help in 
enriching the KB itself. This could allow ontolo-
gy engineers  to explore the kind of relations ex-
isting between different entity types in a corpus 
and then design an ontology which is representa-
tive of the entities and relations evident in the 
corpus. 
Our overall approach to automatic relation 
discovery consists in  a hybrid approach  based 
on Powerset Factz that are the output of linguis-
tic analysis, and serve as input to our system; 
Text based label ranking by directly considering 
the context words in the sentences; and, Seman-
tic Typing information from existing knowledge 
resources to discover relations between Entity 
types at different levels of abstraction.  
The paper is organized as follows. We discuss 
the related work in the next section. In section 3 
we propose our approach and give the details of 
different components in our system. In section 4, 
we discuss preliminary experiments and results. 
In the last section we conclude our work and 
give future work directions. 
2 Related Work 
Hasegawa et al (2004) developed an approach 
for unsupervised relation discovery by clustering 
pairs of entities based on intervening words 
represented as context vectors. They used the 
most frequent common word to label the cluster 
and hence the relation represented by the cluster. 
Shinyama and Sekine (2006) developed an 
approach to preemptively discover relations in a 
corpus and present them as tables with all the 
entity pairs in the table having the same relations 
between them. For pairs of entities they generate 
basic patterns that are parts of text syntactically 
connected to the Entity and use the predicate ar-
gument structure to make the basic patterns more 
generalized. They generate a basic cluster from 
articles based on having similar basic patterns to 
represent the same event and then they cluster 
the basic clusters to get a set of events having the 
same relation. 
Davidov et al (2007) developed a web mining 
approach for discovering relations in which a 
specified concept participates based on clustering 
patterns in which the concept words and other 
words appear. Their system is based on the initial 
seed of two or more words representing the type 
of concept one is interested in. 
Linguistic analysis has been reported as an ef-
fective technique for semantic relation extrac-
tion. Harabagiu et al (2005) used shallow se-
mantic parsers to enhance dependency tree ker-
nels and to build semantic dependency structures 
to improve relation extraction, they reported that 
their method improved the quality of the ex-
tracted relations as compared to kernel-based 
models that used semantic class information on-
ly.  
Nguyen et al (2007) presented an approach 
for relation extraction from Wikipedia by ex-
tracting features from subtrees mined from the 
syntactic structure of text. Kambhatla (2004) de-
veloped a method for extracting relations by ap-
plying Maximum Entropy models to combine 
lexical, syntactic and semantic features and re-
port that they obtain improvement in results 
when they combine variety of features.  Most of 
the existing approaches have used linguistic 
analysis to generate features for supervised or 
semi-supervised relation extraction.  
Recently, Yan et al (2009) have developed an 
approach for unsupervised relation discovery by 
integrating linguistic analysis done on Wikipedia 
with context generated from the Web. They de-
velop a clustering approach based on dependency 
patterns from dependency analysis of Wikipedia 
and surface patterns by querying the web to in-
troduce redundancy. They report that dependen-
cy patterns improve the precision whereas, the 
surface patterns improved the coverage.  
Banko et al (2008) introduce the TextRunner 
system which takes a small corpus sample as 
input and uses a linguistic parser to generate 
training data which they use to train the extractor 
which can run at web scale. However, Kok and 
Domingos (2008) have reported that the triples 
output from the TextRunner system are noisy, 
sparse and contain many co-referent objects and 
relations which is also the case with Powerset. 
Their system uses the output from the TextRun-
ner system and uses Multiple Relational Cluster-
ing model to get object clusters and relation clus-
ters.   
106
3 Approach 
In this section we describe in detail the different 
steps in our approach involving querying Factz 
from Powerset, collapsing facts expressing same 
type of relation, Label Selection and introducing 
Semantic Typing information. Figure 2 gives an 
overview of our approach and Figure 3 shows the 
different components in our system. We discuss 
each component in detail below.  
3.1 Querying Powerset and Retrieving 
Factz 
In the first step we query Powerset API by giving 
as input a list of entities or list of entity pairs and 
retrieve all the Factz and sentences that are asso-
ciated with the entities or entity pairs from the 
Powerset API output. 
3.2 Collapsing Similar Relations 
A particular semantic relationship can be ex-
pressed in different ways in sentences. For ex-
ample words like ?purchase?, ?buy? and ?ac-
quire? may represent the same semantic relation 
between the subject and the object. Sometimes 
the words might be direct synonyms in which 
case resources like WordNet (Miller et al, 1990) 
can help in identifying the same relation whereas 
in other cases the words might not be synonyms 
at all but may still imply the same semantic rela-
tion between the subject and the object. For ex-
ample, we queried Powerset to get a sample of 
relations between companies and products. We 
got relations like introduce, produce, sell, manu-
facture and make. It is often the case that compa-
nies introduce and sell the products that they 
manufacture, make or produce.  However, all of 
these words are not synonyms of each other and 
it may not be feasible to express the relation be-
tween a company and a product in all these dif-
ferent ways in a KB.  
We have developed an approach for collaps-
ing relations expressed using different words in 
the facts and represent it using the dominating 
relation between the pair of entities. We explain 
the different steps in our approach below.  
3.2.1 Relation Clustering 
We consider relations to be similar if they appear 
between the same subjects and the objects. We 
take the set of Factz that we got by querying Po-
 
Figure 3. System Framework 
 
 
Figure 2. The Knowledge Discovery approach uses Powerset Factz which are the output from linguistic analy-
sis, article text for entropy based label ranking and existing knowledge resources for discovering relations at 
different levels of abstraction and hence aiding in enriching the existing knowledge resources. 
 
107
werset in the previous step and based on those 
Factz we construct a similarity matrix to 
represent similarity between all pairs of relations 
in the data set. Each entry in the similarity matrix 
represents the number of times the pair of rela-
tions had the same subject and object in the Factz 
data set. For example, in the sample dataset in 
table 1, the similarity matrix entry for the pair 
acquired and purchased would be 3. We use that 
similarity matrix as input and apply average link 
agglomerative clustering algorithm over it.  
 
Subject Predicate Object 
Bank of America acquired Merrill Lynch 
Bank of America acquired MBNA 
Bank of America acquired FleetBoston 
Bank of America purchased FleetBoston 
Bank of America purchased Merrill Lynch 
Bank of America purchased MBNA 
 
Table 1. Relations between same subjects and objects 
in Powerset 
3.2.2 Filtering Ambiguous Relations 
After the clustering step we have a step for filter-
ing ambiguous relations from the clusters. We 
explain the filtering procedure using an example 
from one of the experiments in which two clus-
ters were produced. First cluster had acquire, 
purchase, buy and own relations and the second 
cluster had introduce, produce, make and say 
about relations. After clustering the relations we 
have the following steps: 
1. We take each pair of entities and get the 
set of relations between the pair of entities. For 
example, the set of relation between ?Bank of 
America? and ?Merrill Lynch? are acquire, pur-
chase and say about (figure 4). 
2. By considering the set of relations be-
tween each pair of entities we assign it to a clus-
ter based on the maximum number of overlap-
ping relations between the set and the cluster 
members. In our example clusters, we assign it to 
cluster one with which there is an overlap of two 
relations i.e. acquire and buy instead of assigning 
it to cluster two with which it has an overlap of 
one relation i.e. say about (figure 4).  
3. Once an entity pair is assigned to a clus-
ter, we consider other relations in the set of rela-
tions present between that entity pair and if any 
of those relations exists as a member of another 
cluster we filter out that relation from that clus-
ter. For example, one of the relations present be-
tween ?Bank of America? and ?Merill Lynch? is 
say about, and this relation is actually a member 
of cluster two whereas, this pair is assigned to 
cluster one and therefore, we filter out say about 
from cluster two. After cluster filtering, the label 
for the cluster is selected as the label that is the 
most frequent relation found in the set of entity 
pairs being assigned to the cluster. 
3.3 Relation Label Selection 
A pair of entities might have more than one fact 
associated with them. We select a representative 
label based on a hybrid approach by combining 
the output from entropy based label ranking 
(Chen et al, 2005) and clusters of similar rela-
tions found by relational clustering. We select 
the relation label as the cluster label of the clus-
ter which has the maximum member overlap 
with the predicates in the set of facts between a 
pair of entities.  In case there is an overlap of just 
one relation, we select the label that is ranked 
highest through entropy based label ranking ap-
proach (Chen et al, 2005). According to their 
algorithm, the importance of terms can be as-
sessed using the entropy criterion, which is based 
on the assumption that a term is irrelevant if its 
presence obscures the separability of the dataset. 
There may be cases where there are multiple re-
lations existing between a given pair of entities, 
however, in our approach we select the relation 
label that is evident in the majority of the facts 
associated with the pair.   
3.4 Semantic Typing 
For certain applications there might be the need 
of discovering relations between specific types of 
entities rather than instances of entities. For ex-
ample, for ontology engineering, the ontology 
 
 
Figure 4. Filtering ambiguous relations from exist-
ing clusters 
 
108
engineer might want to explore the kind of rela-
tions that exist between different entity types 
based on the data set and then develop an ontol-
ogy representing those relations. Therefore, we 
have a component in our system that incorpo-
rates semantic type information into the Factz 
before collapsing the relations present in the 
facts. The semantic type module queries a know-
ledge base for the entity type and replaces the 
entity instance names with entity types in the 
Factz data set. We have used the Freebase (Me-
taweb Technologies, 2009) Knowledge base to 
associate the entity types for the entities that we 
experimented with. When this modified version 
of the Factz dataset is given as input to the next 
component of the system i.e. Collapse Relations, 
the similarity between relations is computed 
based on having the same subject and object enti-
ty types rather than entity instances. Following 
the Semantic Typing path in the system would 
output the relations discovered between types of 
entities. Introducing Semantic Typing informa-
tion can also help in creating redundancy in the 
dataset and overcome the data sparseness prob-
lem. For example in case of relations such as ac-
quire and purchase if we cannot get evidence of 
overlap in the subject and object in the Factz da-
taset then we cannot assign them any similarity 
score in the similarity matrix however, if we re-
place the instance names with instance types and 
consider the overlap between the instance types 
we can get more evidence about their similarity.  
4 Experiments and Results 
In this section, we present the preliminary expe-
riments we conducted to evaluate the approach. 
We start by an initial evaluation of Powerset 
Factz by comparing them with ground truth and 
text based label ranking (Chen et al, 2005). We 
then use our approach to discover relations be-
tween different entity types. The details of the 
experiments and results are discussed below. 
 
4.1 Preliminary Evaluation of Powerset 
Factz 
Our first experiment was targeted towards a pre-
liminary evaluation of the accuracy of Powerset 
Factz themselves and their performance when 
compared with ground truth and with Entropy 
based label ranking approach which does not use 
any linguistic analysis. To achieve this we took 
the ?acquisitions? table from Freebase. The ?ac-
quisitions? table has a list of companies and their 
acquisitions.  We considered the acquisitions 
table as ground truth as this information is either 
entered manually by contributors or imported 
from Wikipedia via DBpedia. We queried Po-
werset by giving the entity pairs as input and 
were able to retrieve Factz for 170 pairs out of 
1107 entity pairs present in Freebase table. The 
number of pairs for which Powerset returned 
Factz is low because Powerset currently extracts 
Factz from well formed sentences and not semi-
structured or structured information such as 
tables or info-boxes in Wikipedia and the acqui-
sition relation is mostly expressed in the form of 
tables or lists in Wikipedia articles. We applied 
relational clustering and stopped clustering when 
the similarity between the clusters was less than 
4. We identified one cluster (acquire, purchase, 
buy) having more than one member and got 146 
relations labeled accurately i.e. 85% accuracy 
through our approach. We repeated the experi-
ment using Entropy based label ranking approach 
(Chen et al, 2005). We were mainly focusing on 
relations that were expressed by verbs. We took 
all sentences between a pair of entities from 
which Powerset had extracted Factz. We ex-
tracted verbs from those sentences and ranked 
those verbs based on the entropy based label 
ranking approach and considered any of the la-
bels matching with the cluster members (acquire, 
purchase, buy) as correct prediction. We com-
pared the results with the ground truth and got 
the accuracy of 72% (table 2). Our preliminary 
experiment on the sample dataset demonstrated 
that the relation labels assigned by Powerset 
have reasonably high accuracy when compared 
with ground truth i.e. 85% and also give higher 
accuracy as compared to the entropy based label 
ranking approach for the sample data set. 
4.2 Discovering Relations between Different 
Types of Entity Pairs 
In this experiment we wanted to explore if our 
approach was successful in discovering relations 
existing between different types of entity pairs 
and clusters the pairs into separate clusters.  
We constructed two datasets using Wikipedia 
page links between articles on entities namely 
Persons and Organizations. Using ?person? type 
and ?organization? type specified in Freebase, 
Approach Accuracy 
Powerset Factz based approach 85% 
Entropy based Label ranking 72% 
 
Table 2. Comparison of Powerset Factz based 
approach and Entropy based label ranking 
109
we were able to construct a list of Wikipedia ar-
ticles that were on Persons and Organizations. 
The Wikipedia article links served the purpose of 
finding out which organizations are related to 
which other organizations and which persons are 
related to which organizations. The first dataset 
represented relations between Organizations 
whereas the second dataset represented relations 
between Persons and Organizations. We applied 
relational clustering for collapsing similar rela-
tions and evaluated the output clusters at differ-
ent thresholds to see if they represented relations 
between different types of entities. At stopping 
with a threshold of 2 we found the following two 
clusters having more than one member: one of 
the clusters represented the relations present be-
tween a pair of Organizations (acquire, pur-
chase, buy, own, say about, take over) and the 
other cluster represented the relations between 
Persons and Organizations (formed, found, lead) 
(table 3). The experiment confirmed the effec-
tiveness of clustering approach as it clusters rela-
tions between different kinds of entity pairs into 
different clusters. 
 
Relations Clusters 
Org-Org 
 
Cluster 1: acquire, purchase, buy, own, say 
about, take over over 
Pers-Org  Cluster 2: found, lead, form 
 
Table 3. Relations between different types of entity 
pairs are clustered into different clusters 
4.3 Improving Recall  
In this experiment we were interested in finding 
if Factz from Powerset can help in discovering 
relations between entities that are not present in 
resources like DBpedia and Freebase. We took a 
list of organization (with > 28,000 organization 
names from Freebase and an internal Knowledge 
Base) and retrieved Powerset Factz having those 
organizations as subjects. We performed relation 
clustering and output clusters at different thre-
sholds. We selected the minimum threshold for 
which there were at least two clusters with more 
than one member. From the two clusters, one 
cluster had manufacture, produce and make rela-
tions and the second had acquire, purchase, own, 
operate and buy relations (table 4). Our intuition 
was that the first cluster represented relations 
between organizations and products. Therefore, 
we took the ?company-products? table from 
Freebase and compared it with our dataset. How-
ever, we could only find an overlap of 3 subject 
object pairs. The second cluster had relations that 
we earlier found to exist between organizations 
having the acquisition relation between them, 
therefore, we took the ?acquisitions? table from 
Freebase and compared it against our dataset. 
Comparing the pairs with our list of organiza-
tions, we found 104 pairs that had an organiza-
tion as a subject and an object. Out of those 104 
pairs 97 pairs were assigned to cluster 2 and 7 
pairs were assigned to cluster 1. When we com-
pared those 97 pairs with Freebase ?acquisition? 
table (which had 73 pairs of organizations that 
overlapped with our dataset) we found that 66 
existed in the set and were therefore predicted 
correctly. We then inspected the rest of the pairs 
manually and found that there were 16 additional 
pairs that were predicted to have the acquire re-
lation and which were not present in the Freebase 
table. Therefore, this approach helped in identi-
fying 16 additional organization pairs having 
acquisition relation between them correctly.  
 
Cluster Cluster Members 
1 manufacture, produce, make 
2 acquire, purchase, own, operate, buy 
 
Table 4. Clustering results for Relations having Or-
ganizations as subjects 
 
Statistics 
No. of pairs in Freebase table 73 
No. of discovered pairs matching Freebase 66 
No. of additional pairs discovered 16 
Total no. of correctly discovered pairs 82/104 
Accurate Predictions %age 78% 
 
Table 5. Evaluation results for improving recall by 
discovering additional entity pairs having the acquisi-
tion relation 
 
Another observation worth mentioning is that the 
acquisition relation is represented mostly in the 
form of tables in Wikipedia whereas Powerset 
only processes information that is present in sen-
tences. In spite of that, our approach was able to 
find new entity pairs from text that did not al-
ready exist in information extracted by other 
sources (table 5).   
4.4 Discovering Relations at Different Le-
vels of Abstraction 
In this experiment we introduced Semantic Type 
information in the Factz data set to discover rela-
tions at different levels of abstraction i.e. be-
tween Entity Types at different levels (For ex-
ample School or Organization, where School is a 
type of Organization).  
We took a list of 13000 organizations for 
which we had their Organization Types available 
110
from an internal KB and queried Powerset for 
Factz between all pairs of organizations and were 
able to retrieve more than 88,000 Factz. We 
passed on the Factz to the Semantic Typing 
module to replace the Organization names with 
their types. The Factz dataset with Semantic 
Type information was given as input for collaps-
ing relations, where the similarity matrix was 
constructed based on the same subject and object 
types (rather than same subject and object in-
stances), after which the clustering was per-
formed. We evaluated the clusters at different 
stopping thresholds but the system did not gener-
ate any meaningful clusters. We then looked into 
the dataset and realized that a lot of noise was 
introduced into the system due to various organi-
zation names which were very ambiguous and 
replacing the ambiguous organization names 
with organization types had magnified the noise. 
For example, in our organizations list there is an 
organization with the name ?Systems? which is 
of type ?Medical Instrument Supplies?. It had the 
following fact related to it: <3d systems> <man-
ufacture> <systems>. Replacing the organization 
name with the type resulted in the following fact 
i.e., <multimedia graphics software> <manufac-
ture> <medical instruments supplies>. Such am-
biguous names when replaced with wrong types 
further magnified the noise. 
4.4.1 Resolving Ambiguity 
As discussed, ambiguous organization names 
introduced noise and replacing them with organi-
zation types magnified the noise. Therefore, it 
was important to resolve the ambiguity in the 
names of entities before applying Semantic Typ-
ing. There are different approaches than can be 
used to recognize and disambiguate Named Enti-
ties, which we discuss below.  
4.4.1.1 Named Entity Recognition 
Powerset has Factz that are extracted from 
sentences. The Factz may be present between 
Named Entities or even just words in sentences. 
For example ?Accord? is a name of a trade union 
and is also a word. Running Named Entity Rec-
ognition systems over the sentences from which 
the Factz have been extracted can help in identi-
fying named entities and in eliminating such 
factz which are not between named entities. In 
general, the relation extraction systems have an 
initial step where they identify entities in sen-
tences through NER systems and then discover 
relations between those entities.  
Most of Named Entity Recognition and Dis-
ambiguation systems use the contextual informa-
tion to disambiguate between entities. The con-
textual information could be words in the sen-
tences or other entities in the sentences where the 
entity is mentioned. Having some evidence that 
two entities are related in some way can also 
help in eliminating much of the ambiguity.  In 
general, the relation extraction systems have an 
initial step where they find related entity pairs 
based on Co-occurrences and then discover rela-
tions between those pairs of entities which fre-
quently co-occur with each other in sentences.  
We followed the approach of getting addition-
al context by using entity pairs for querying Po-
werset for which we have background know-
ledge that the pairs are related through some rela-
tion and only retrieved the Factz that were be-
tween those entity pairs. We repeated the same 
experiment. However, this time we gave as input 
pairs of entity names for which we have evidence 
that the entities are related and then ran the expe-
riment with and without semantic typing infor-
mation to validate if introducing semantic typing 
can give us some additional advantage. We dis-
cuss the details of our experiment below. 
 
Relations between Entity Types Freebase Source 
person - organization PersonEmployment table 
person- school Education table 
organization-organization Acquisitions table 
 
Table 6. Data Set with relations between different 
types of entities extracted from Freebase tables 
 
Using Freebase tables we extracted datasets 
for relations present between three different 
kinds of entity pairs i.e persons and organizations 
(e.g. Person-join-Organization), persons and 
school (e.g. Person-attend-School) and Organiza-
tions and Organizations (e.g. Organization- ac-
quire-Organization) (table 6). We used the pairs 
of entities (Persons - Organizations, Persons - 
Schools and Organizations - Organizations) to 
query Powerset and extracted the Factz that cor-
responded to those pairs. Table 7 gives an exam-
ple of the predicates in the Factz found between 
the different types of entity pairs.  
After clustering we evaluated the clusters and 
were expecting to get the relations between three 
different kinds of entity pairs namely Person - 
Organization, Person - School, Organization - 
Organization into three separate clusters. We 
evaluated the output clusters at different stopping 
thresholds but were not able to get three clusters 
using any threshold. Table 8 shows the clusters 
111
found at threshold of 2. There were two possible 
reasons for this outcome, one reason was that we 
did not have enough redundancy in the data set 
to get meaningful clusters and secondly, 
?school? is a type of ?organization? which could 
have introduced ambiguity. In order to introduce 
redundancy we replaced all the entity names with 
their types (i.e., Person, Organization, School) in 
the Factz and repeated the experiment with Enti-
ty Type information rather than Entity names. 
We evaluated the clusters at different thresholds 
and were able to separate the relation sets into 
three clusters with greater than one member. Ta-
ble 9 gives the results of clustering where we got 
three clusters with more than one member at 
minimum threshold.  
The clusters represented the relations present 
between the three different types of entity pairs 
i.e., person and school, organization and organi-
zation and person and organization (table 9). 
Wikipedia is a very non-redundant resource 
and redundancy helps in getting more evidence 
about the similarity between relations.  Other 
approaches (Yan et al, 2009) have used the web 
for getting redundant information and improving 
recall. In addition, there are many sentences in 
Wikipedia for which Powerset has no corres-
ponding Factz associated (it might be due to 
some strong filtering heuristics). Using semantic 
typing helped in introducing redundancy, without 
which we were not able to cluster the relations 
between different types of entity pairs into sepa-
rate clusters. Semantic Typing also helped in 
identifying the relations present between entities 
at different levels of abstraction. This can help in 
suggesting relations between different entity 
types evident in the corpus during the Ontology 
engineering process.  
5 Conclusions 
We have developed a hybrid approach for unsu-
pervised and unrestricted relation discovery be-
tween entities using linguistic analysis via Po-
werset, entropy based label ranking and semantic 
typing information from a Knowledge base. We 
initially compared the accuracy of Powerset 
Factz with ground truth and with entropy based 
label ranking approach on a sample dataset and 
observed that the relations discovered through 
Powerset Factz gave higher accuracy than the 
entropy based approach for the sample dataset. 
We also developed an approach to collapse a set 
of relations represented in facts as a single domi-
nating relation and introduced a hybrid approach 
for label selection based on relation clustering 
and entropy based label ranking. Our experi-
ments showed that the relational clustering ap-
proach was able to cluster different kinds of enti-
ty pairs into different clusters. For the case where 
the kinds of entity pairs were at different levels 
of abstraction, introducing Semantic Typing in-
formation helped in introducing redundancy and 
also in clustering relations between different 
kinds of entity pairs whereas, the direct approach 
was not able to identify meaningful clusters. We 
plan to further test our approach on a greater va-
riety of relations and on a larger scale.  
  
Relation Example of Powerset Factz Predicates  
Person- Organization join, leave, found, form, start, create 
Person ? School attend, enter, return to, enroll at, study at 
Organization - Or-
ganization 
acquire, purchase, buy, own 
 
Table 7. Example of Predicates in Powerset Factz 
representing relations between different types of entity 
pairs 
 
No. Cluster Members Semantic Types 
1 enroll at, return to Person-School 
2 found, purchase, buy, acquire, 
create, say about, own 
Organization- Organi-
zation,  
Person-Organization 
 
Table 8. Results of Clustering Relations between Enti-
ty Pairs without using Semantic Typing 
 
No. Cluster Members Semantic Relation 
1 lead, prep at, play for, enter, 
study, play, graduate, transfer 
to, play at, enroll in, go to, 
remain at, enroll at, teach at, 
move to, attend, join, leave, 
teach, study at, return to, work 
at 
Person- School 
2 acquire, purchase, buy, own, 
say about 
Organization - Organi-
zation 
3 found, create Person - Organization 
 
Table 9. Results of Clustering Relations with Semantic 
Typing 
112
References  
Dat P. T. Nguyen, Yutaka Matsuo, and Mitsuru Ishi-
zuka. 2007. Subtree mining for relation extraction 
from Wikipedia. In Proc. of NAACL ?07: pages 
125?128. 
Dmitry Davidov, Ari Rappoport and Moshe Koppel. 
2007. Fully unsupervised discovery of concept-
specific relationships by Web mining. Proceedings 
of the 45th Annual Meeting of the Association of 
Computational Linguistics,  pp. 232?239. 
George A. Miller ,  Richard Beckwith ,  Christiane 
Fellbaum ,  Derek Gross ,  Katherine Miller. 1990. 
Wordnet: An on-line lexical database. International 
Journal of Lexicography, 3(4):235-312. 
Jinxiu Chen, Donghong Ji, Chew Lim Tan and Zhen-
gyu Niu. Unsupervised Feature Selection for Rela-
tion Extraction. In Proc. of  IJCNLP-2005. 
Metaweb Technologies, Freebase Data Dumps, 
http://download.freebase.com/datadumps/ July, 
2009 
Michele Banko ,  Michael J Cafarella ,  Stephen So-
derl ,  Matt Broadhead ,  Oren Etzioni. 2008. Open 
information extraction from the web. Commun. 
ACM 51, 12 (Dec. 2008), 68-74.  
Nanda Kambhatla. 2004. Combining lexical, syntactic 
and semantic features with maximum entropy 
models. In Proceedings of the ACL 2004 on Inter-
active poster and demonstration sessions. 
Sanda Harabagiu, Cosmin Andrian Bejan, and Paul 
Morarescu. 2005. Shallow semantics for relation 
extraction. In Proc. of IJCAI 2005.  
Soren Auer, Christian Bizer, Georgi Kobilarov, Jens 
Lehmann, Richard Cyganiak, and Zachary Ives. 
2007. Dbpedia: A nucleus for a web of open data. 
In Proc. of ISWC 2007.  
Stanley Kok and Pedro Domingos. 2008. Extracting 
Semantic Networks from Text Via Relational Clus-
tering. In Proc. of the ECML-2008.  
Takaaki Hasegawa, Satoshi Sekine and Ralph Grish-
man. 2004. Discovering Relations among Named 
Entities from Large Corpora. In Proc. of ACL-04. 
Powerset. www.Powerset.com 
Yulan Yan, Naoaki Okazaki, Yutaka Matsuo, Zhenglu 
Yang, and Mitsuru Ishizuka. 2009. Unsupervised 
relation extraction by mining Wikipedia texts using 
information from the web. In ACL-IJCNLP ?09: 
Volume 2, pages 1021?1029.  
Yusuke Shinyama and Satoshi Sekine. 2006. Preemp-
tive information extraction using unrestricted rela-
tion discovery. In HLT/NAACL-2006.  
 
 
 
113
