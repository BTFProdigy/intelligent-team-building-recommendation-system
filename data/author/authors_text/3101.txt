Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational
Natural Language Learning, pp. 610?619, Prague, June 2007. c?2007 Association for Computational Linguistics
A Discriminative Learning Model for Coordinate Conjunctions
Masashi Shimbo?
Graduate School of Information Science
Nara Institute of Science and Technology
Ikoma, Nara 630-0192, Japan
shimbo@is.naist.jp
Kazuo Hara?
Graduate School of Information Science
Nara Institute of Science and Technology
Ikoma, Nara 630-0192, Japan
kazuo-h@is.naist.jp
Abstract
We propose a sequence-alignment based
method for detecting and disambiguating co-
ordinate conjunctions. In this method, av-
eraged perceptron learning is used to adapt
the substitution matrix to the training data
drawn from the target language and domain.
To reduce the cost of training data con-
struction, our method accepts training exam-
ples in which complete word-by-word align-
ment labels are missing, but instead only
the boundaries of coordinated conjuncts are
marked. We report promising empirical re-
sults in detecting and disambiguating coor-
dinated noun phrases in the GENIA corpus,
despite a relatively small number of train-
ing examples and minimal features are em-
ployed.
1 Introduction
Coordination, along with prepositional phrase at-
tachment, is a major source of syntactic ambiguity
in natural language. Although only a small number
of previous studies in natural language processing
have dealt with coordinations, this does not mean
disambiguating coordinations is easy and negligible;
it still remains one of the difficulties for state-of-the-
art parsers. in Charniak and Johnson?s recent work
(Charniak and Johnson, 2005), for instance, two of
the features incorporated in their parse reranker are
aimed specifically at resolving coordination ambi-
guities.
Previous work on coordinations includes (Agar-
wal and Boggess, 1992; Chantree et al, 2005; Kuro-
?Equal contribution.
hashi and Nagao, 1994; Nakov and Hearst, 2005;
Okumura and Muraki, 1994; Resnik, 1999). Ear-
lier studies (Agarwal and Boggess, 1992; Okumura
and Muraki, 1994) attempted to find heuristic rules
to disambiguate coordinations. More recent re-
search are concerned with capturing structural sim-
ilarity between conjuncts using thesauri and cor-
pora (Chantree et al, 2005), or web-based statistics
(Nakov and Hearst, 2005).
We identify three problems associated with the
previous work.
1. Most of these studies evaluate the proposed
heuristics against restricted forms of conjunc-
tions. In some cases, they only deal with co-
ordinations with exactly two conjuncts, leaving
the generality of these heuristics unclear.
2. Most of these studies assume that the bound-
aries of coordinations are known in advance,
which, in our opinion, is impractical.
3. The proposed heuristics and statistics capture
many different aspects of coordination. How-
ever, it is not clear how they interact and how
they can be combined.
To address these problems, we propose a new
framework for detecting and disambiguating coor-
dinate conjunctions. Being a discriminative learning
model, it can incorporate a large number of overlap-
ping features encoding various heuristics for coordi-
nation disambiguation. It thus provides a test bed for
examining combined use of the proposed heuristics
as well as new ones. As the weight on each feature
is automatically tuned on the training data, assessing
these weights allows us to evaluate the relative merit
of individual features.
610
w
r
i
t
e
r
n nt e riv
Figure 1: An alignment between ?writer? and ?vint-
ner,? represented as a path in an edit graph
Our learning model is also designed to admit ex-
amples in which only the boundaries of coordinated
conjuncts are marked, to reduce the cost of training
data annotation.
The state space of our model resembles that of
Kurohashi and Nagao?s Japanese coordination de-
tection method (Kurohashi and Nagao, 1994). How-
ever, they considered only the decoding of coordi-
nated phrases and did not address automatic param-
eter tuning.
2 Coordination disambiguation as
sequence alignment
It is widely acknowledged that coordinate conjunc-
tions often consist of two or more conjuncts having
similar syntactic constructs. Our coordination detec-
tion model also follows this observation. To detect
such similar constructs, we use the sequence align-
ment technique (Gusfield, 1997).
2.1 Sequence alignment
Sequence alignment is defined in terms of transfor-
mation of one sequence (string) into another through
an alignment, or a series of edit operations. Each of
the edit operations has an associated cost, and the
cost of an alignment is defined as the total cost of
edit operations involved in the alignment. The min-
imum cost alignment can be computed by dynamic
programming in a state space called an edit graph,
such as illustrated in Figure 1. In this graph, a com-
plete path starting from the upper-left initial vertex
and arriving at the lower-right terminal vertex con-
stitutes a global alignment. Likewise, a partial path
corresponds to a local alignment.
Sequence alignment can also be formulated with
the scores of edit operations instead of their costs. In
this case, the sequence alignment problem is that of
finding a series of edit operations with the maximum
score.
2.2 Edit graph for coordinate conjunctions
A fundamental difference between biological local
sequence alignment and coordination detection is
that the former deals with finding local homologies
between two (or more) distinct sequences, whereas
coordination detection is concerned with local simi-
larities within a single sentence.
The maximal local alignment between two iden-
tical sequences is a trivial (global) alignment of
identity transformation (the diagonal path in an edit
graph). Coordination detection thus reduces to find-
ing off-diagonal partial paths with the highest sim-
ilarity score. Such paths never cross the diagonal,
and we can limit our search space to the upper trian-
gular part of the edit graph, as illustrated in Figure 2.
3 Automatic parameter tuning
Given a suitable substitution matrix, i.e., function
from edit operations to scores, it is straightforward
to find optimal alignments, or coordinate conjunc-
tions in our task, by running the Viterbi algorithm in
an edit graph.
In computational biology, there exist established
substitution matrices (e.g., PAM and BLOSUM)
built on a generative model of mutations and their
associated probabilities.
Such convenient substitution matrices do not ex-
ist for coordination detection. Moreover, optimal
score functions are likely to vary from one domain
(or language) to another. Instead of designing a
specific function for a single domain, we propose a
general discriminative learning model in which the
score function is a linear function of the features as-
signed to vertices and edges in the state space, and
the weight of the features are automatically tuned for
given gold standard data (training examples) drawn
from the application domain. Designing heuristic
rules for coordination detection, such as those pro-
posed in previous studies, translates to the design of
suitable features in our model.
Our learning method is an extension of Collins?s
perceptron-based method for sequence labeling
(Collins, 2002). However, a few incompatibilities
exists between Collins? sequence labeling method
and edit graphs used for sequence alignment.
611
median
dose
intensity
was
99%
for
standard
arm
182%
the
dose
arm
and
for
the
dense
.
m
ed
ia
n
do
se
in
te
ns
ity
w
as
99
%
fo
r
sta
nd
ar
d
ar
m
18
2%
th
e
do
se
ar
m
an
d
fo
r
th
e
de
ns
e
.
Figure 2: An edit graph for coordinate detection
1. Collins?s method, like the linear-chain condi-
tional random fields (CRFs) (Lafferty et al,
2001; Sha and Pereira, 2003), seeks for a com-
plete path from the initial vertex to the terminal
using the Viterbi algorithm. In an edit graph, on
the other hand, coordinations are represented
by partial paths. And we somehow need to
complement the partial path to make a com-
plete path.
2. A substitution matrix, which defines the score
of edit operations, can be represented as a func-
tion of features defined on edges. But to deal
with complex coordinations, a more expressive
score function is sometimes desirable, so that
scores can be computed not only on the basis of
a single edit operation, but also on consecutive
edit operations. Edit graphs are not designed to
accommodate features for such a higher-order
interaction of edit operations.
To reconcile these incompatibilities, we derive
a more finer-grained model from the original edit
graph. In presenting the description of our model be-
low, we reserve the terminology ?vertex? and ?edge?
for the original edit graph, and use ?node? and ?arc?
for our new model, to avoid confusion.
3.1 State space for learning coordinate
conjunctions
The new model is also based on the edit graph. In
this model, we create a node for each triple (v, p,e),
(a) (b) (c) (d) (e)
Figure 3: Five node types created for a vertex in an
edit graph: (a) Inside Delete, (b) Inside Insert, (c) In-
side Substitute, (d) Outside Delete, and (e) Outside
Insert.
(a) (b)
Figure 4: Series of edit operations with an equiv-
alent net effect. (a) (Insert,Delete), and (b)
(Delete, Insert). (b) is prohibited in our model.
where v is a vertex in the original edit graph, e ?
{Delete, Insert,Substitute} is an admissible1 edit op-
eration at v, and p ? {Inside,Outside} is a polarity
denoting whether or not the edit operation e is in-
volved in an alignment.
For a node (v, p,e), we call the pair (p,e) its type.
All five possible node types for a single vertex of an
edit graph are shown in Figure 3. We disallow type
(Outside,Substitute), as it is difficult to attribute an
intuitive meaning to substitution when two words
are not aligned (i.e., Outside).
Arcs between nodes are built according to the
transitions allowed in the original edit graph. To be
precise, an arc between node (v1, p1,e1) and node
(v2, p2,e2) is created if and only if the following
three conditions are met. (i) Edit operations e1 and
e2 are admissible at v1 and v2, respectively; (ii) the
sink of the edge for e1 at v1 is v2; and (iii) it is not
the case with p1 = p2 and (e1,e2) = (Delete, Insert).
Condition (iii) is introduced so as to disallow tran-
sition (Delete, Insert) depicted in Figure 4(b). In
contrast, the sequence (Insert,Delete) (Figure 4(a))
is allowed. The net effects of these edit operation
sequences are identical, in that they both skip one
word each from the two sequences to be aligned. As
a result, there is no use in discriminating between
these two, and one of them, namely (Delete, Insert),
is prohibited.
1For a vertex v at the border of an edit graph, some edit op-
erations are not applicable (e.g., Insert and Substitute at vertices
on the right border in Figure 2); we say such operations are in-
admissible at v. Otherwise, an edit operation is admissible.
612
A
,
B
,
C
and
D
an
d
A B ,, C D
A
,
B
,
C
and
D
an
d
A B ,, C D
(a) chainable (b) non-chainable
Figure 5: A coordination with four conjuncts repre-
sented as (a) chainable, and (b) non-chainable partial
paths. We take (a) as the canonical representation.
3.2 Learning task
By the restriction of condition (iii) introduced above
and the omission of (Outside, Substitute) from the
node types, we can uniquely determine the com-
plete path (from the initial node to the terminal node)
that conjoins all the local alignments by Outside
nodes (which corresponds to edges in the original
edit graph). In Figure 2, the augmented Outside
edges in this unique path are plotted as dotted lines
for illustration.
Thus we obtain a complete path which is compat-
ible with Collins?s perceptron-based sequence learn-
ing method. The objective of the learning algo-
rithms, which we will describe in Section 4, is to
optimize the weight of features so that running the
Viterbi algorithm will yield the same path as the gold
standard.
Because a node in our state space corresponds to
an edge in the original edit graph (see Figure 3), an
arc in our state space is actually a pair of consec-
utive edges (or equivalently, edit operations) in the
original graph. Hence our model is more expressive
than the original edit graph in that the score function
can have a term (feature) defined on a pair of edit
operations instead of one.
3.3 More complex coordinations
Even if a coordination comprises three or more con-
juncts, our model can handle them, as it can be rep-
resented as a set of pairwise local alignments that
are chainable (Gusfield, 1997, Section 13.3). If pair-
wise local alignments are chainable, a unique com-
plete path that conjoins all these alignments can be
determined, allowing the same treatment as the case
with two conjuncts.
For instance, a coordination with four conjuncts
(A, B, C and D) can be decomposed into a set of pair-
wise alignments {(A,B),(B,C),(C,D)} as depicted
in Figure 5(a). This set of alignments are chain-
able and thus constitute the canonical encoding for
this coordination; any other pairwise decomposition
for these four conjuncts, like {(A,B),(B,C),(A,D)}
(Figure 5(b)), is not chainable.
Our model can handle multiple non-nested coor-
dinations in a single sentence as well, as they can
also be decomposed into chainable pairwise align-
ments. It cannot encode nested coordinations like
(A, B, and (C and D)), however.
4 Algorithms
4.1 Reducing the cost of training data
construction
Our learning method is supervised, meaning that it
requires training data annotated with correct labels.
Since a label in our problem is local alignments
(or paths in an edit graph) representing coordina-
tions, the training sentences have to be annotated
with word-by-word alignments.
There are two reasons relaxing this requirement
is desirable. First, it is expensive to construct such
data. Second, there are coordinate conjunctions
in which word-by-word correspondence is unclear
even for humans. In Figure 2, for example, a word-
by-word alignment of ?standard? with ?dense? is de-
picted, but it might be more natural to regard a word
?standard? as being aligned with two words ?dose
dense? combined together.
Even if word-by-word alignment is uncertain, the
boundaries of conjuncts are often obvious, and it is
also much easier for human annotators to mark only
the beginning and end of each conjunct. Thus we
would like to allow for training examples in which
only alignment boundaries are specified, instead of
a full word-by-word alignment.
For these examples, conjunct boundaries corre-
sponds to a rectangular region rather than a sin-
gle path in an edit graph. The shaded box in Fig-
ure 2 illustrates the rectangular region determined by
the boundaries of an alignment between the phrases
?182% for the dose dense arm? and ?99% for the
standard arm.? There are many possible alignment
paths in this box, among which we do not know
which one is correct (or even likely). To deal with
613
input: Set of examples S = {(xi,Yi)}
Iteration cutoff T
output: Averaged weight vector w?
1: w? ? 0; w ? 0
2: for t ? 1 . . .T do
3: ?w ? 0
4: for each (xi,Yi) ? S do
5: y ? argmaxy?Yi w ? f (xi,y)
6: y? ? argmaxy?A(xi) w ? f (xi,y)
7: ? f ? f (xi,y)? f (xi,y?)
8: ?w ? ?w+? f
9: end for
10: if ?w = 0 then
11: return w?
12: end if
13: w ? w+?w
14: w? ? [(t ?1)w?+w]/t
15: end for
16: return w?
Figure 6: Path-based algorithm
this difficulty, we propose two simple heuristics we
call the (i) path-based and (ii) box-based methods.
As mentioned earlier, both of these methods are
based on Collins?s averaged-perceptron algorithm
for sequence labeling (Collins, 2002).
4.2 Path-based method
Our first method, which we call the ?path-based?
algorithm, is shown in Figure 6. We denote by A(x)
all possible alignments (paths) over x. The algorithm
receives T , the maximum number of iterations, and
a set of examples S = {(xi,Yi)} as input, where xi is a
sentence (a sequence of words with their attributes,
e.g., part-of-speech, lemma, prefixes, and suffixes)
and Yi ? A(xi) is the set of admissible alignments
(paths) for xi. When a sentence is fully annotated
with a word-by-word alignment y, Yi = {y} is a sin-
gleton set. In general boundary-only examples we
described in Section 4.1, Yi holds all possible align-
ments compatible with the marked range, or equiv-
alently, paths that pass through the upper-left and
lower-right corners of a rectangular region. Note
that it is not necessary to explicitly enumerate all the
member paths of Yi; the set notation here is only for
the sake of presentation.
The external function f (x,y) returns a vector
(called the global feature vector in (Sha and Pereira,
2003)) of the number of feature occurrences along
the alignment path y. In the beginning (line 5 in the
figure) of the inner loop, the target path (alignment)
input: Set of examples S = {(xi,Yi)}
Iteration cutoff T
output: Averaged weight vector w?
1: w? ? 0; w ? 0
2: for each (xi,Yi) ? S do
3: gi ? (1/|Yi|)?y?Yi f (xi,y)
4: end for
5: for t ? 1 . . .T do
6: ?w ? 0
7: for each (xi,Yi) ? S do
8: y? ? argmaxy?A(xi) w ? f (xi,y)
9: Convert y? into its box representation Y ?
10: g? ? (1/|Y ?i |)?y?Y ?i f (xi,y)
11: ? f ? gi ?g?
12: ?w ? ?w+? f
13: end for
14: if ?w = 0 then
15: return w?
16: end if
17: w ? w+?w
18: w? ? [(t ?1)w?+w]/t
19: end for
20: return w?
Figure 7: Box-based algorithm
is recomputed with the current weight vector w. The
argmax in lines 5 and 6 can be computed efficiently
(O(n2), where n is the number of words in x) by run-
ning a pass of the Viterbi algorithm in the edit graph
for x. The weight vector w varies between iterations,
and so does the most likely alignment with respect
to w. Hence the recomputation in line 5 is needed.
4.3 Box-based method
Our next method, called ?box-based,? is designed
on the following heuristic. Given a rectangle region
representing a local alignment (hence all nodes in
the region are of polarity Inside) in an edit graph,
we distribute feature weights in proportion to the
probability of a node (or an arc) being passed by a
path from the initial (upper left) node to the termi-
nal (lower right) node of the rectangle. We assume
paths are uniformly distributed.
Figure 8 displays an 8? 8 sub-grid of an edit
graph. The figure under each vertex shows the num-
ber of paths passing through the vertex. Vertices
near the upper-left and the lower-right corner have
a large frequency, and the frequency drops exponen-
tially towards the top right corner and the bottom
left corner, hence placing a strong bias on the paths
near diagonals. This distribution fits our preference
614
Figure 8: Number of paths passing through the ver-
tices of an 8?8 grid.
towards alignments with a larger number of substi-
tutions.
The pseudo-code for the box-based algorithm is
shown in Figure 7. For each example xi and its pos-
sible target labels (alignments)Yi, this algorithm first
(line 3) computes and stores in the vector gi the aver-
age number of feature occurrences in all possible tar-
get paths in Yi. This quantity can be computed sim-
ply by summing over all nodes and edges feature oc-
currences multiplied by the pre-computed frequency
of each nodes and arcs at which these features occur.
analogously to the forward-backward algorithm. In
each iteration, the algorithm scans every example
(lines 7?13), computing the Viterbi path y? (line 8)
according to the current weight vector w. Line 9
then converts y? to its box representation Y ?, by se-
quentially collapsing consecutive Inside nodes in y?
as a box. For instance, let y? be the local alignment
depicted as the bold line in Figure 2. The box Y ?
computed in line 9 for this y? is the shaded area in the
figure. In parallel to the initialization step in line 3,
we store in g? the average feature occurrences in Y ?
and update the current weight vector w by the differ-
ence between the target gi and g?. These steps can
be interpreted as a Viterbi approximation for com-
puting the optimal set Y ? of alignments directly.
5 Related work
5.1 Discriminative learning of edit distance
In our model, the state space of sequence alignment,
or edit graph, is two-dimensional (which is actu-
ally three-dimensional if the dimension for labels is
taken into account). This is contrastive to the one
dimensional models used by Collins?s perceptron-
based sequence method (Collins, 2002) which our
algorithms are based upon, and by the linear-chain
CRFs.
McCallum et al (McCallum et al, 2005) pro-
posed a CRF tailored to learning string edit distance
for the identity uncertainty problem. The state space
in their work is two dimensional just like our model,
but it is composed of two decoupled subspaces, each
corresponding to ?match? and ?mismatch,? thus shar-
ing only the initial state. It is not possible to make
a transition from a state in the ?match? state space to
the ?mismatch? space (and vice versa). As we can
see from the decoupled state space, this method is
based on global alignment rather than local align-
ment; it is not clear whether their method can iden-
tify local homologies in sequences. Our method uses
a single state space in which both ?match (inside)?
and ?mismatch (outside)? nodes co-exist and transi-
tion between them is permitted.
5.2 Inverse sequence alignment in
computational biology
In computational biology, the estimation of a sub-
stitution matrix from data is called the inverse se-
quence alignment problem. Until recently, there
have been a relatively small number of papers in
this field despite a large body of literature in se-
quence alignment. Theoretical studies in the inverse
sequence alignment include (Pachter and Sturmfels,
2004; Sun et al, 2004). Recently, CRFs have been
applied for optimizing the substitution matrix in the
context of global protein sequence alignment (Do et
al., 2006).
6 Empirical evaluation
6.1 Dataset and Task
We used the GENIA Treebank beta corpus (Kim et
al., 2003)2 for evaluation of our methods. The cor-
2http://www-tsujii.is.s.u-tokyo.ac.jp/GENIA
615
pus consists of 500 parsed abstracts in Medline with
a total of 4529 sentences.
Although the Penn Treebank Wall Street Journal
(WSJ) is the de facto standard corpus for evaluating
chunking and parsing performance, it lacks adequate
structural information on coordinate conjunctions,
and therefore does not serve our purpose. Many
coordinations in the Penn Treebank are given a flat
bracketing like (A, B, and C D), and thus we cannot
tell which of ((A, B, and C) D) and ((A), (B), and
(C D)) gives a correct alignment. The GENIA cor-
pus, in contrast, distinguishes ((A, B, and C) D) and
((A), (B), and (C D)) explicitly, by providing more
detailed bracketing. In addition, the corpus contains
an explicit tag ?COOD? for marking coordinations.
To avoid nested coordinations, which admittedly
require techniques other than the one proposed in
this paper, we selected from the GENIA corpus sen-
tences in which the conjunction ?and? occurs just
once. After this operation, the number of sentences
reduced to 1668, from which we further removed 32
that are not associated with the ?COOD? tag, and
3 more whose annotated tree structures contained
obvious errors. Of the remaining 1633 sentences,
1061 were coordinated noun phrases annotated with
NP-COOD tags, 226 coordinated verb phrases (VP-
COOD), 142 coordinated adjective phrases (ADJP-
COOD), and so on. Because the number of VP-
COOD, ADJP-COOD, and other types of coordi-
nated phrases are too small to make a meaningful
benchmark, we focus on coordinated noun phrases
in this experiment.
The task hence amounts to identifying coordi-
nated NPs and their constituent conjuncts in the
1633 sentences, all of which contain a coordination
marker ?and? but only 1061 of which are actually
coordinated NPs.
6.2 Baselines
We used several publicly available full parsers
as baselines: (i) the Bikel parser (Bikel,
2005) version 0.9.9c with configuration file
bikel.properties (denoted as Bikel/Bikel),
(ii) the Bikel parser in the Collins parser emula-
tion mode (using collins.properties file)
(Bikel/Collins), and (iii) Charniak and Johnson?s
reranking parser (Charniak-Johnson) (Charniak and
Johnson, 2005). We trained Bikel?s parser and its
Collins emulator with the GENIA corpus, WSJ, and
the combination of the two. Charniak and Johnson?s
parser was used as distributed at Charniak?s home
page (and is WSJ trained).
Another baseline we used is chunkers based
on linear-chain CRFs and the standard BIO la-
bels. We trained two types of CRF-based chun-
kers by using different BIO sequences, one for
the conjunct bracketing and the other for coor-
dination bracketing. The chunkers were imple-
mented with T. Kudo?s CRF++ package version
0.45. We varied its regularization parameters C
among C ? {0.01,0.1,1,10,100,1000}, and the best
results among these are reported below.
6.3 Features
Let x = (x1, . . . ,xn) be a sentence, with its member
xk a vector of attributes for the kth word. The at-
tributes include word surface, part-of-speech (POS),
and suffixes, among others.
Table 1 summarizes (i) the features assigned to a
node whose corresponding edge in the original edit
graph for x is emanating from row i and column j,
and (ii) the features assigned to the arcs (consisting
of two edges in the original edit graph) whose joint
(the vertex between the two edges) is a vertex at row
i and column j.
We also tested the path-based and box-based
methods, and the CRF chunkers both with and with-
out the word and suffix features.
Although this is not a requirement of our model or
algorithms, every feature we use in this experiment
is binary; if the condition associated with a feature
is satisfied, the feature takes a value of 1; otherwise,
it is 0. A condition typically asks whether or not
specific attributes match those at a current node, arc,
or their neighbors.
We used the POS tags from the GENIA corpus
as the POS attribute. The morphological features
include 3- and 4-gram suffixes and indicators of
whether a word includes capital letters, hyphens, and
digits.
For the baseline CRF-based chunkers, we assign
the word, POS (from GENIA), and the morphologi-
cal features to nodes, and the POS features to edges.
The feature set is identical to those used for our pro-
posed methods, except for features defined on row-
column combination (i.e., those defined over both i
616
Table 1: Features for the proposed methods
Substitute (diagonal) nodes
(?,Substitute,?)
Indicators of the word, POS, and morphological attributes of xi, x j , (xi?1,xi),
(xi,xi+1), (x j?1,x j), (x j,x j+1), and (xi, x j), respectively combined with the
type of the node.
For each of the word, POS, and morphological attributes, an indicator of
whether the respective attribute is identical in xi and x j , combined with the
type of the node.
Delete (vertical) nodes
(?,Delete,?)
Indicators of the word, POS, and morphological attributes of xi, x j , x j?1,
(xi?1,xi), (xi,xi+1), and (x j?1,x j), combined with the type of the node.
Insert (horizontal) nodes
(?, Insert,?)
Indicators of the word, POS, and morphological attributes of xi, xi?1, x j,
(xi?1,xi), (x j?1,x j), and (x j, x j+1), combined with the type of the node.
Any arcs
(?,?,?)? (?,?,?)
Indicators of the POS attribute of xi, xi?1, x j, x j?1, (xi?2,xi?1), (xi?1,xi),
(xi,xi+1), (x j?2,x j?1), (x j?1,x j), (x j,x j+1), (xi?1,x j?1), (xi?1,x j), (xi, x j?1)
and (xi,x j), combined with the type pair of the arc.
Arcs between nodes of different polarity
(?, Inside,?)? (?,Outside,?) and
(?,Outside,?)? (?, Inside,?)
Indicator of the distance j? i between two words xi and x j, combined with the
type pair of the arc.
and j in Table 1. The latter cannot be incorporated
as a local features in chunkers based on linear chain.
For the Bikel (and its Collins emulation) parsers
which accepts POS tags output by external taggers
upon testing, we gave them the POS tags from the
GENIA corpus, for fair comparison with the pro-
posed methods and CRF-based chunkers.
6.4 Evaluation criteria
We employed two evaluation criteria: (i) correctness
of the conjuncts output by the algorithm, and (ii) cor-
rectness of the range of coordinations as a whole.
For the correctness of conjuncts, we further use
two evaluation criteria. The first evaluation method
(?pairwise evaluation?) is based on the decomposi-
tion of coordinations into the canonical set of pair-
wise alignments, as described in Section 3.3. After
the set of pairwise alignments is obtained, each pair-
wise alignment is transformed into a box surrounded
by their boundaries. Using these boxes, we evaluate
precision, recall and F rates through the following
definition. The precision measures how many of the
boxes output by the algorithm exactly match those
in the gold standard, and the recall rate is the per-
centage of boxes found by the algorithm. The F rate
is the harmonic mean of the precision and the recall.
The second evaluation method (?chunk-based
evaluation?) for conjuncts is based on whether the
algorithm correctly outputs the beginning and end of
each conjunct, in the same manner as the chunking
tasks. Here, we adopt the evaluation criteria for the
CoNLL 99 NP bracketing task3; the precision equals
how many of the NP conjuncts output by the algo-
rithm are correct, and the recall is the percentage of
NP conjuncts found by the algorithm.
Of these two evaluation methods for conjuncts, it
is harder to obtain a higher pairwise evaluation score
than the chunk-based evaluation. To be counted as a
true positive in the pairwise evaluation, two consec-
utive chunks must be output correctly by the algo-
rithm.
For the correctness of the coordination range, we
check if both the start of the first coordinated con-
junct and the end of the last conjunct in the gold
match those output by the algorithm The reason we
evaluate coordination range is to compare our pro-
posed method with the full parsers trained on WSJ
(but applied to GENIA). Although WSJ and GE-
NIA differ in the way conjuncts are annotated, they
are mostly identical on how the range of coordina-
tions are annotated, and hence comparison is feasi-
ble in terms of coordination range. For the baseline
parsers, we regard the bracketing directly surround-
ing the coordination marker ?and? as their output.
In (Clegg and Shepherd, 2007), an F score of 75.5
is reported for the Bikel parser on coordination de-
tection. Their evaluation is based on dependencies,
which is different from our evaluation criteria which
are all based on boundaries. Generally speaking, our
evaluation criterion seems stricter, as exemplified in
Figures 7 and 8 of Clegg and Shepherd?s paper; in
these figures, our evaluation criterion would result
3http://www.cnts.ua.ac.be/conll99/npb/
617
Table 2: Performance on conjunct bracketing. P: precision (%), R: recall (%), F: F rate.
Pairwise evaluation Chunk-based evaluation
Method P R F P R F
Path-based method 61.4 56.2 58.7 70.9 66.9 68.9
Path-based method without word and suffix features 61.7 58.8 60.2 71.2 69.7 70.5
Box-based method 60.6 58.3 59.4 70.5 69.1 69.8
Box-based method without word and suffix features 59.5 58.3 58.9 69.7 69.5 69.6
Linear-chain CRF chunker (conjunct bracketing) 62.6 51.4 56.4 71.0 66.1 68.5
Bikel/Collins, trained with GENIA 50.0 48.6 49.3 65.0 64.2 64.6
Bikel/Bikel, trained with GENIA 50.1 47.8 49.0 63.9 61.3 62.6
Table 3: Performance on coordination bracketing. P: precision (%), R: recall (%), F: F rate.
Method P R F
Path-based method 58.2 55.3 56.7
Path-based method without words and suffix features 57.7 56.6 57.2
Box-based method 55.6 54.4 55.0
Box-based method without words and suffix features 54.8 54.6 54.7
Linear-chain CRF chunker, trained with conjunct bracketing 43.9 46.7 45.3
Linear-chain CRF chunker, trained with coordination bracketing 58.4 51.0 54.5
Bikel/Collins, trained with GENIA 44.0 45.4 44.7
Bikel/Collins, trained with WSJ 42.3 43.2 42.7
Bikel/Collins, trained with GENIA+WSJ 43.3 45.1 44.1
Bikel/Bikel, trained with GENIA 44.8 45.4 45.1
Bikel/Bikel, trained with WSJ 40.7 41.5 41.1
Bikel/Bikel, trained with GENIA+WSJ 43.9 45.8 44.9
Charniak-Johnson reranking parser 48.3 45.2 46.7
in zero true positive, whereas their evaluation counts
the dependency arc from ?genes? to ?human? as one
true positive.
6.5 Results
The results of conjunct and coordination bracketing
are shown in Tables 2 and 3, respectively. These
are the results of a five-fold cross validation. We
ran the proposed methods until convergence or the
cutoff iteration of T = 10000, whichever comes first.
The path-based method (without words and suf-
fixes) and box-based method (with full features)
each achieved 2.0 and 1.3 point improvements over
the CRF chunker in terms of the F score in conjunct
identification (chunk-based evaluation), 3.8 and 3.0
point improvement in terms of pairwise evaluation,
and 2.7 and 0.5 points in coordinate identification,
respectively. Our methods also showed a perfor-
mance considerably higher than the baseline parsers.
The performance of the path-based method was
better when the word and suffix features were re-
moved, while the box-based method and CRF chun-
kers performed better with these features.
7 Conclusions
We have proposed a new coordination learning and
disambiguation method that can incorporate many
different features, and automatically optimize their
weights on training data.
In the experiment of Section 6, the proposed
method obtained a performance superior to a linear-
chain chunker and to the state-of-art full parsers.
We used only syntactic and morphological fea-
tures, and did not use external similarity measures
like thesauri and corpora, although they are reported
to be effective for disambiguating coordinations. We
note that it is easy to incorporate such external sim-
ilarity measures as a feature in our model, thanks to
its two-dimensional state space. The similarity of
two words derived from an external knowledge base
can be assigned to a Substitute node at a correspond-
ing location in the state space in a straightforward
manner. This is a topic we are currently working on.
We are also planning to reimplement our algo-
rithms using CRFs instead of the averaged percep-
tron algorithm.
618
References
Rajeev Agarwal and Lois Boggess. 1992. A simple but
useful approach to conjunct identification. In Proceed-
ings of the 30th Annual Meeting of the Association for
Computing Linguistics (ACL?92), pages 15?21.
Daniel M. Bikel. 2005. Multilingual statistical pars-
ing engine version 0.9.9c. http://www.cis.upenn.edu/
?dbikel/software.html.
Francis Chantree, Adam Kilgarriff, Anne de Roeck, and
Alistair Willis. 2005. Disambiguating coordina-
tions using word distribution information. In Pro-
ceedings of the International Conference on Recent
Advances in Natural Language Processing (RANLP
2005), Borovets, Bulgaria.
Eugene Charniak and Mark Johnson. 2005. Coarse-to-
fine n-best parsing and MaxEnt discriminative rerank-
ing. In Proceedings of the Annual Meeting of the As-
sociation for Computational Linguistics (ACL-2005).
Andrew B Clegg and Adrian J Shepherd. 2007. Bench-
marking natural-language parsers for biological appli-
cations using dependency graphs. BMC Bioinformat-
ics, 8(24).
Michael Collins. 2002. Discriminative training meth-
ods for hidden Markov models: theory and experi-
ments with perceptron algorithms. In Proceedings of
the Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP 2002).
C. B. Do, S. S. Gross, and S. Batzoglou. 2006. CON-
TRAlign: discriminative training for protein sequence
alignment. In Proceedings of the Tenth Annual Inter-
national Conference on Computational Molecular Bi-
ology (RECOMB 2006).
Dan Gusfield. 1997. Algorithms on Strings, Trees, and
Sequences. Cambridge University Press.
J.-D. Kim, T. Ohta, Y. Tateisi, and J. Tsujii. 2003. GE-
NIA corpus: a semantically annotated corpus for bio-
textmining. Bioinformatics, 19(Suppl. 1):i180?i182.
Sadao Kurohashi and Makoto Nagao. 1994. A syntactic
analysis method of long Japanese sentences based on
the detection of conjunctive structures. Computational
Linguistics, 20:507?534.
John Lafferty, Andrew McCallum, and Fernando Pereira.
2001. Conditional random fields: probabilistic mod-
els for segmenting and labeling sequence data. In Pro-
ceedings of the 18th International Conference on Ma-
chine Learning (ICML-2001), pages 282?289. Morgan
Kaufmann.
Andrew McCallum, Kedar Bellare, and Fernando Pereira.
2005. A conditional random field for discriminatively-
trained finite-state string edit distance. In Proceedings
of the 21st Conference on Uncertainty in Artificial In-
telligence (UAI-2005).
Preslav Nakov and Marti Hearst. 2005. Using the web as
an implicit training set: application to structural ambi-
guity resolution. In Proceedings of Human Language
Technology Conference and Conference on Empirical
Methods in Natural Language (HLT/EMNLP), pages
835?842, Vancouver.
Akitoshi Okumura and Kazunori Muraki. 1994. Sym-
metric pattern matching analysis for English coordi-
nate structures. In Proceedings of the Fourth Confer-
ence on Applied Natural Language Processing, pages
41?46.
Lior Pachter and Bernd Sturmfels. 2004. Parametric
inference for biological sequence analysis. Proceed-
ings of the National Academy of Sciences of the USA,
101(46):16138?16143.
Philip Resnik. 1999. Semantic similarity in a taxonomy:
an information-based measure and its application to
problems of ambiguity in natural language. Journal
of Artificial Intelligence Research, 11:95?130.
Fei Sha and Fernando Pereira. 2003. Shallow pars-
ing with conditional random fields. In Proceedings
of the Human Language Technology Conference North
American Chapter of Association for Computational
Linguistics (HLT-NAACL 2003), pages 213?220, Ed-
monton, Alberta, Canada. Association for Computa-
tional Linguistics.
Fangting Sun, David Ferna?ndez-Baca, and Wei Yu. 2004.
Inverse parametric sequence alignment. Journal of Al-
gorithms, 53:36?54.
619
Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 967?975,
Suntec, Singapore, 2-7 August 2009. c?2009 ACL and AFNLP
Coordinate Structure Analysis with Global Structural Constraints and
Alignment-Based Local Features
Kazuo Hara Masashi Shimbo Hideharu Okuma Yuji Matsumoto
Graduate School of Information Science
Nara Institute of Science and Technology
Ikoma, Nara 630-0192, Japan
{kazuo-h,shimbo,hideharu-o,matsu}@is.naist.jp
Abstract
We propose a hybrid approach to coor-
dinate structure analysis that combines
a simple grammar to ensure consistent
global structure of coordinations in a sen-
tence, and features based on sequence
alignment to capture local symmetry of
conjuncts. The weight of the alignment-
based features, which in turn determines
the score of coordinate structures, is op-
timized by perceptron training on a given
corpus. A bottom-up chart parsing al-
gorithm efficiently finds the best scor-
ing structure, taking both nested or non-
overlapping flat coordinations into ac-
count. We demonstrate that our approach
outperforms existing parsers in coordina-
tion scope detection on the Genia corpus.
1 Introduction
Coordinate structures are common in life sci-
ence literature. In Genia Treebank Beta (Kim et
al., 2003), the number of coordinate structures is
nearly equal to that of sentences. In clinical pa-
pers, the outcome of clinical trials is typically de-
scribed with coordination, as in
Median times to progression and median
survival times were 6.1 months and 8.9
months in arm A and 7.2 months and 9.5
months in arm B. (Schuette et al, 2006)
Despite the frequency and implied importance
of coordinate structures, coordination disambigua-
tion remains a difficult problem even for state-of-
the-art parsers. Figure 1(a) shows the coordinate
structure extracted from the output of Charniak
and Johnson?s (2005) parser on the above exam-
ple. This is somewhat surprising, given that the
symmetry of conjuncts in the sentence is obvious
to human eyes, and its correct coordinate structure
shown in Figure 1(b) can be readily observed.
6.1 
months and
8.9 
months
in 
arm A
7.2 
months
and 9.5 
months
in
arm Band
6.1 
months
and 8.9 
months
in 
arm A
7.2 
months
and 9.5 
months
in 
arm Band
(b)
(a)
Figure 1: (a) Output from the Charniak-Johnson
parser and (b) the correct coordinate structure.
Structural and semantic symmetry of conjuncts
is one of the frequently observed features of coor-
dination. This feature has been explored by previ-
ous studies on coordination, but these studies often
dealt with a restricted form of coordination with
apparently too much information provided from
outside. Sometimes it was assumed that the co-
ordinate structure contained two conjuncts each
solely composed of a few nouns; and in many
cases, the longest span of coordination (e.g., outer
noun phrase scopes) was given a priori. Such rich
information might be given by parsers, but this is
still an unfounded assumption.
In this paper, we approach coordination by tak-
ing an extreme stance, and assume that the input is
a whole sentence with no subsidiary information
except for the parts-of-speech of words.
As it assumes minimal information about syn-
tactic constructs, our method provides a baseline
for future work exploiting deeper syntactic infor-
mation for coordinate structure analysis. More-
over, this stand-alone approach has its own merits
as well:
1. Even apart from parsing, the output coordi-
nate structure alone may provide valuable in-
formation for higher-level applications, in the
same vein as the recent success of named
entity recognition and other shallow parsing
967
technologies. One such potential application
is extracting the outcome of clinical tests as
illustrated above.
2. As the system is designed independently
from parsers, it can be combined with any
types of parsers (e.g., phrase structure or de-
pendency parsers), if necessary.
3. Because coordination bracketing is some-
times inconsistent with phrase structure
bracketing, processing coordinations apart
from phrase structures might be beneficial.
Consider, for example,
John likes, and Bill adores, Sue.
(Carston and Blakemore, 2005)
This kind of structure might be treated by as-
suming the presence of null elements, but the
current parsers have limited ability to detect
them. On the other hand, the symmetry of
conjuncts, John likes and Bill adores, is rather
obvious and should be easy to detect.
The method proposed in this paper builds a
tree-like coordinate structure from the input sen-
tence annotated with parts-of-speech. Each tree
is associated with a score, which is defined in
terms of features based on sequence alignment be-
tween conjuncts occurring in the tree. The feature
weights are optimized with a perceptron algorithm
on a training corpus annotated with the scopes of
conjuncts.
The reason we build a tree of coordinations is to
cope with nested coordinations, which are in fact
quite common. In Genia Treebank Beta, for ex-
ample, about 1/3 of the whole coordinations are
nested. The method proposed in this paper im-
proves upon our previous work (Shimbo and Hara,
2007) which also takes a sentence as input but is
restricted to flat coordinations. Our new method,
on the other hand, can successfully output the cor-
rect nested structure of Figure 1(b).
2 Related work
Resnik (1999) disambiguated coordinations of the
form [n1 and n2 n3], where ni are all nouns. This
type of phrase has two possible readings: [(n1)
and (n2 n3)] and [((n1) and (n2)) n3]. He demon-
strated the effectiveness of semantic similarity cal-
culated from a large text collection, and agreement
of numbers between n1 and n2 and between n1 and
n3. Nakov and Hearst (2005) collected web-based
statistics with search engines and applied them to
a task similar to Resnik?s.
Hogan (2007) improved the parsing accuracy
of sentences in which coordinated noun phrases
are known to exist. She presented a generative
model incorporating symmetry in conjunct struc-
tures and dependencies between coordinated head
words. The model was then used to rerank the n-
best outputs of the Bikel parser (2005).
Recently, Buyko et al (2007; 2008) and
Shimbo and Hara (2007) applied discriminative
learning methods to coordinate structure analysis.
Buyko et al used a linear-chain CRF, whereas
Shimbo and Hara proposed an approach based on
perceptron learning of edit distance between con-
juncts.
Shimbo and Hara?s approach has its root in
Kurohashi and Nagao?s (1994) rule-based method
for Japanese coordinations. Other studies on co-
ordination include (Agarwal and Boggess, 1992;
Chantree et al, 2005; Goldberg, 1999; Okumura
and Muraki, 1994).
3 Proposed method
We propose a method for learning and detecting
the scopes of coordinations. It makes no assump-
tion about the number of coordinations in a sen-
tence, and the sentence can contain either nested
coordinations, multiple flat coordinations, or both.
The method consists of (i) a simple gram-
mar tailored for coordinate structure, and (ii) a
perceptron-based algorithm for learning feature
weights. The features are defined in terms of se-
quence alignment between conjuncts.
We thus use the grammar to filter out incon-
sistent nested coordinations and non-valid (over-
lapping) conjunct scopes, and the alignment-based
features to evaluate the similarity of conjuncts.
3.1 Grammar for coordinations
The sole objective of the grammar we present be-
low is to ensure the consistency of two or more
coordinations in a sentence; i.e., for any two co-
ordinations, either (i) they must be totally non-
overlapping (non-nested coordinations), or (ii) one
coordination must be embedded within the scope
of a conjunct of the other coordination (nested co-
ordinations).
Below, we call a parse tree built from the gram-
mar a coordination tree.
968
Table 1: Non-terminals
COORD Complete coordination.
COORD? Partially-built coordination.
CJT Conjunct.
N Non-coordination.
CC Coordinate conjunction like ?and,?
?or,? and ?but?.
SEP Connector of conjuncts other than CC:
e.g., punctuations like ?,? and ?;?.
W Any word.
Table 2: Production rules for coordination trees.
(. . . | . . . | . . .) denotes a disjunction (matches any
one of the elements). A ?*? matches any word.
Rules for coordinations:
(i) COORDi,m ? CJTi, j CC j+1,k?1 CJTk,m
(ii) COORDi,n ? CJTi, j SEP j+1,k?1 COORD?k,n[m]
(iii) COORD?i,m[ j]? CJTi, j CC j+1,k?1 CJTk,m
(iv) COORD?i,n[ j]? CJTi, j SEP j+1,k?1 COORD?k,n[m]
Rules for conjuncts:
(v) CJTi, j ? (COORD | N)i, j
Rules for non-coordinations:
(vi) Ni,k ? COORDi, j N j+1,k
(vii) Ni, j ? Wi,i (COORD|N)i+1, j
(viii) Ni,i ? Wi,i
Rules for pre-terminals:
(ix) CCi,i ? (and | or | but )i
(x) CCi,i+1 ? ( , | ; )i (and | or | but )i+1
(xi) SEPi,i ? ( , | ; )i
(xii) Wi,i ? ?i
3.1.1 Non-terminals
The grammar is composed of non-terminal sym-
bols listed in Table 1. The distinction between
COORD and COORD? is made to cope with three or
more conjuncts in a coordination. For example
?a , b and c? is treated as a tree of the form (a ,
(b and c))), and the inner tree (b and c) is not a
complete coordination, until it is conjoined with
the first conjunct a. We represent this inner tree
by a COORD? (partial coordination), to distinguish it
from a complete coordination represented by CO-
ORD. Compare Figures 2(a) and (b), which respec-
tively depict the coordination tree for this exam-
ple, and a tree for nested coordination with a sim-
ilar structure.
3.1.2 Production rules
Table 2 lists the production rules. Rules are shown
with explicit subscripts indicating the span of their
production. The subscript to a terminal word
(shown in a box) specifies its position within a sen-
tence (word index). Non-terminals have two sub-
script indices denoting the span of the production.
COORD? in rules (iii) and (iv) has an extra in-
dex j shown in brackets. This bracketed index
maintains the end of the first conjunct (CJT) on
the right-hand side. After a COORD? is produced
by these rules, it may later constitute a larger CO-
ORD or COORD? through the application of produc-
tions (ii) or (iv). At this point, the bracketed in-
dex of the constituent COORD? allows us to identify
the scope of the first conjunct immediately under-
neath. As we describe in Section 3.2.4, the scope
of this conjunct is necessary to compute the score
of coordination trees.
These grammar rules are admittedly minimal
and need further elaboration to cover all real use
cases of coordination (e.g., conjunctive phrases
like ?as well as?, etc.). Yet they are sufficient to
generate the basic trees illustrated in Figure 2. The
experiments of Section 5 will apply this grammar
on a real biomedical corpus.
Note that although non-conjunction cue expres-
sions, such as ?both? and ?either,? are not the
part of this grammar, such cues can be learned
(through perceptron training) from training exam-
ples if appropriate features are introduced. Indeed,
in Section 5 we use features indicating which
words precede coordinations.
3.2 Score of a coordination tree
Given a sentence, our system outputs the coordina-
tion tree with the highest score among all possible
trees for the sentence. The score of a coordination
tree is simply the sum of the scores of all its nodes,
and the node scores are computed independently
from each other. Hence a bottom-up chart parsing
algorithm can be designed to efficiently compute
the highest scoring tree.
While scores can be assigned to any nodes, we
have chosen to assign a non-zero score only to two
types of coordination nodes, namely COORD and
COORD?, in the experiment of Section 5; all other
nodes are ignored in score computation. The score
of a coordination node is defined via sequence
alignment (Gusfield, 1997) between conjuncts be-
low the node, to capture the symmetry of these
969
(a) a , b and c
W W W
COORD
COORD?
N SEP N CC N
(b) a or b and c
W
CC
W
CC
W
N N N
COORD
COORD
(c) a
W
b
W
c
W
N
N
N
Figure 2: Coordination trees for (a) a coordination with three conjuncts, (b) nested coordinations, and
(c) a non-coordination. The CJT nodes in (a) and (b) are omitted for brevity.
W W CC W W W W W CC W W CC W W W W W
N
N
N
N
N
N
N
N
N
N
N
N
COORD
N
N
COORD
N
N
COORD
6.1 
months 
8.
9 
m
on
th
s 
9.
5 
m
on
th
s 
7.2 
months 
6.1 
months 
and
8.9
months
in
arm
A
7.
2 
m
on
th
s 
an
d
9.
5
m
on
th
s
in ar
m
B
M
ed
ia
n 
tim
es
 
to
 
pr
og
re
ss
io
n 
an
d
m
ed
ia
n 
su
rv
iv
al
 
tim
es
 
w
er
e 
6.
1 
m
on
th
s 
an
d 
8.
9 
m
on
th
s in
ar
m A
an
d
7.
2
m
on
th
s 
an
d
9.
5
m
on
th
s in
ar
m B
W W W W CC W W W
N
N
NN
N
N
N
COORD
W
N
N
Median
times
to
progression
m
ed
ia
n
su
rv
iv
al
tim
es
Figure 3: A coordination tree for the example sen-
tence presented in Section 1, with the edit graphs
attached to COORD nodes.
m
ed
ia
n
su
rv
iv
al
tim
es
Median
times
to
progression
initial vertex
terminal vertex
Figure 4: An edit graph and an alignment path
(bold line).
conjuncts.
Figure 3 schematically illustrates the relation
between a coordination tree and alignment-based
computation of the coordination nodes. The score
of this tree is given by the sum of the scores of the
four COORD nodes, and the score of a COORD node
is computed with the edit graph shown above the
node.
3.2.1 Edit graph
The edit graph is a basic data structure for comput-
ing sequence alignment. An example edit graph is
depicted in Figure 4 for word sequences ?Median
times to progression? and ?median survival times.?
A diagonal edge represents alignment (or sub-
stitution) between the word at the top of the edge
and the one on the left, while horizontal and ver-
tical edges represent skipping (or deletion) of re-
spective word. With this representation, a path
starting from the top-left corner (initial vertex) and
arriving at the bottom-right corner (terminal ver-
tex) corresponds one-to-one to a sequence of edit
operations transforming one word sequence to the
other.
In standard sequence alignment, each edge of an
edit graph is associated with a score representing
the merit of the corresponding edit operation. By
defining the score of a path as the total score of its
component edges, we can assess the similarity of
a pair of sequences as the maximum score over all
paths in its edit graph.
3.2.2 Features
In our model, instead of assigning a score inde-
pendently to edges of an edit graph, we assign a
vector of features to edges. The score of an edge
is the inner product of this feature vector and an-
other vector w, called global weight vector. Fea-
ture vectors may differ from one edge to another,
but the vector w is unique in the entire system and
consistently determines the relative importance of
individual features.
In parallel to the definition of a path score, the
feature vector of a path can be defined as the sum
of the feature vectors assigned to its component
edges. Then the score of a path is equal to the
inner product ?w, f? of w and the feature vector f
of the path.
A feature assigned to an edge can be an arbi-
trary indicator of edge directions (horizontal, ver-
tical, or diagonal), edge coordinates in the edit
graph, attributes (such as the surface form, part-
of-speech, and the location in the sentence) of the
current or surrounding words, or their combina-
tion. Section 5.3 will describe the exact features
used in our experiments.
970
3.2.3 Averaged path score as the score of a
coordination node
Finally, we define the score of a COORD (or COORD?)
node in a coordination tree as the average score
of all paths in its associated edit graph. This is an-
other deviation from standard sequence alignment,
in that we do not take the maximum scoring paths
as representing the similarity of conjuncts, but in-
stead use the average over all paths.
Notice that the average is taken over paths, and
not edges. In this way, a natural bias is incurred
towards features occurring near the diagonal con-
necting the initial vertex and the terminal vertex.
For instance, in an edit graph of size 8? 8, there
is only one path that goes through the vertex at the
top-right corner, while more than 3,600 paths pass
through the vertex at the center of the graph. In
other words, the features associated with the cen-
ter vertex receives 3,600 times more weights than
those at the top-right corner after averaging.
The major benefit of this averaging is the re-
duced computation during training. During the
perceptron training, the global weight vector w
changes and the score of individual paths changes
accordingly. On the other hand, the average fea-
ture vector f (as opposed to the average score
?w, f?) over all paths in the edit graph remains
constant. This means that f can be pre-computed
once before the training starts, and the score com-
putation during training reduces to simply taking
the inner product of the current w and the pre-
computed f.
Alternatively, the alignment score could be de-
fined as that of the best scoring path with respect
to the current w, following the standard sequence
alignment computation. However, it would require
running the Viterbi algorithm in each iteration of
the perceptron training, for all possible spans of
conjuncts. While we first pursued this direction,
it was abandoned as the training was intolerably
slow.
3.2.4 Coordination with three or more
conjuncts
For a coordination with three or more conjuncts,
we define its score as the sum of the similarity
scores of all pairwise consecutive conjuncts; i.e.,
for a coordination ?a, b, c, and d? with four con-
juncts, the score is the sum of the similarity scores
for conjunct pairs (a, b), (b, c), and (c, d). Ide-
ally, we should take all combinations of conjuncts
into account, but it would lead to a combinatorial
a , b , c and d
W W W W
COORD
COORD?
COORD?
N SEP N SEP N CC N
Figure 5: A coordination tree with four conjuncts.
All CJT nodes are omitted.
explosion and is impractical.
Recall that in the grammar introduced in Sec-
tion 3.1, we attached a bracketed index to COORD?.
This bracketed index was introduced for the com-
putation of this pairwise similarity.
Figure 5 shows the coordination tree for ?a, b,
c, and d.? The pairwise similarity scores for (a,
b), (b, c), and (c, d) are respectively computed at
the top COORD, left COORD?, and right COORD? nodes,
using the scheme described in Section 3.2.3. To
compute the similarity of a and b, we need to lift
the information about the end position of b upward
to the COORD node. The same applies to computing
the similarity of b and c; the end position of c is
needed at the left COORD?. The bracketed index of
COORD? exactly maintains this information, i.e., the
end of the first conjunct below the COORD?. See
production rules (iii) and (iv) in Table 2.
3.3 Perceptron learning of feature weights
As we saw above, our model is a linear model with
the global weight vector w acting as the coefficient
vector, and hence various existing techniques can
be exploited to optimize w.
In this paper, we use the averaged perceptron
learning (Collins, 2002; Freund and Schapire,
1999) to optimize w on a training corpus, so that
the system assigns the highest score to the correct
coordination tree among all possible trees for each
training sentence.
4 Discussion
4.1 Computational complexity
Given an input sentence of N words, finding its
maximum scoring coordination tree by a bottom-
up chart parsing algorithm incurs a time complex-
ity of O(N3).
While the right-hand side of rules (i)?(iv) in-
volves more than three variables and thus appears
to increase complexity, this is not the case since
971
some of the variables ( j and k in rules (i) and (iii),
and j, k, and m in rules (ii) and (iv)) are con-
strained by the location of conjunct connectors (CC
and SEP), whose number in a sentence is negligi-
ble compared to the sentence length N. As a result,
these rules can be processed in O(N2) time. Hence
the run-time complexity is dominated by rule (vi),
which has three variables and leads to O(N3).
Each iteration of the perceptron algorithm for
a sentence of length N also incurs O(N3) for the
same reason.
Our method also requires pre-processing in the
beginning of perceptron training, to compute the
average feature vectors f for all possible spans
(i, j) and (k,m) of conjuncts in a sentence. With a
reasoning similar to the complexity analysis of the
chart parsing algorithm above, we can show that
the pre-processing takes O(N4) time.
4.2 Difference from Shimbo and Hara?s
method
The method proposed in this paper extends the
work of Shimbo and Hara (2007). Both take a
whole sentence as input and use perceptron learn-
ing, and the difference lies in how hypothesis co-
ordination(s) are encoded as a feature vector.
Unlike our new method which constructs a tree
of coordinations, Shimbo and Hara used a chain-
able partial paths (representing non-overlapping
series of local alignments; see (Shimbo and Hara,
2007, Figure 5)) in a global triangular edit graph.
In our method, we compute many edit graphs of
smaller size, one for each possible conjunct pair in
a sentence. We use global alignment (a complete
path) in these smaller graphs, as opposed to chain-
able local alignment (partial paths) in a global edit
graph used by Shimbo and Hara.
Since nested coordinations cannot be encoded
as chainable partial paths (Shimbo and Hara,
2007), their method cannot cope with nested coor-
dinations such as those illustrated in Figure 2(b).
4.3 Integration with parsers
Charniak and Johnson (2005) reported an im-
proved parsing accuracy by reranking n-best parse
trees, using features based on similarity of coor-
dinated phrases, among others. It should be inter-
esting to investigate whether alignment-based fea-
tures like ours can be built into their reranker, or
more generally, whether the coordination scopes
output by our method help improving parsing ac-
curacy.
The combinatory categorial grammar (CCG)
(Steedman, 2000) provides an account for vari-
ous coordination constructs in an elegant manner,
and incorporating alignment-based features into
the CCG parser (Clark and Curran, 2007) is also
a viable possibility.
5 Evaluation
We evaluated the performance of our method1 on
the Genia corpus (Kim et al, 2003).
5.1 Dataset
Genia Treebank Beta is a collection of Penn
Treebank-like phrase structure trees for 4529 sen-
tences from Medline abstracts.
In this corpus, each scope of coordinate struc-
tures is annotated with an explicit tag, and the
conjuncts are always placed inside brackets. Not
many treebanks explicitly mark the scope of con-
juncts; for example, the Penn Treebank frequently
omits bracketing of coordination and conjunct
scopes, leaving them as a flat structure.
Genia contains a total of 4129 occurrences of
COOD tags indicating coordination. These tags are
further subcategorized into phrase types such as
NP-COOD and VP-COOD. Among coordinations anno-
tated with COOD tags, we selected those surround-
ing ?and,? ?or,? and ?but.? This yielded 3598 co-
ordinations (2997, 355, and 246 for ?and,? ?or,?
and ?but,? respectively) in 2508 sentences. These
coordinations constitute nearly 90% of all coordi-
nations in Genia, and we used them as the evalua-
tion dataset. The length of these sentences is 30.0
words on average.
5.2 Evaluation method
We tested the proposed method in two tasks:
(i) identify the scope of coordinations regardless
of phrase types, and
(ii) detect noun phrase (NP) coordinations and
identify their scopes.
While the goal of task (i) is to determine the scopes
of 3598 coordinations, task (ii) demands both to
judge whether each of the coordinations constructs
an NP, and if it does, to determine its scope.
1A C++ implementation of our method can be found
at http://cl.naist.jp/project/coordination/, along with supple-
mentary materials including the preliminary experimental re-
sults of the CCG parser on the same dataset.
972
Table 3: Features in the edit graph for conjuncts wkwk+1 ? ? ?wm and wlwl+1 ? ? ?wn.
edge/vertex type vertical edge horizontal edge diagonal edge initial vertex terminal vertex
? ? ?
w j?1 w j w j+1
? ? ?
.
.
.
wi?1
wi
wi+1
.
.
.
? ? ?
w j?1 w j w j+1
? ? ?
.
.
.
wi?1
wi
wi+1
.
.
.
? ? ?
w j?1 w j w j+1
? ? ?
.
.
.
wi?1
wi
wi+1
.
.
.
wl wl+1 ? ? ?
wk
wk+1
.
.
.
? ? ?
wn?1 wn
.
.
.
wm?1
wm
vertical bigrams wi?1wi
wiwi+1
wi?1wi wi?1wi
wiwi+1
wk?2wk?1
wk?1wk
wkwk+1
wm?2wm?1
wm?1wm
wmwm+1
horizontal bigrams wj?1wj w j?1wj
w jw j+1
wj?1wj
w jw j+1
wl?2wl?1
wl?1wl
wlwl+1
wn?2wn?1
wn?1wn
wnwn+1
orthogonal bigrams wiw j wk?1wl?1
wk?1wl
wkwl?1
wkwl
wm?1wn?1
wm?1wn
wmwn?1
wmwn
For comparison, two parsers, the Bikel-Collins
parser (Bikel, 2005)2 and Charniak-Johnson
reranking parser3, were applied in both tasks.
Task (ii) imitates the evaluation reported by
Shimbo and Hara (2007), and to compare our
method with their coordination analysis method.
Because their method can only process flat coordi-
nations, in task (ii) we only used 1613 sentences in
which ?and? occurs just once, following (Shimbo
and Hara, 2007). Note however that the split of
data is different from their experiments.
We evaluate the performance of the tested meth-
ods by the accuracy of coordination-level brack-
eting (Shimbo and Hara, 2007); i.e., we count
each of the coordination (as opposed to conjunct)
scopes as one output of the system, and the system
output is deemed correct if the beginning of the
first output conjunct and the end of the last con-
junct both match annotations in the Genia Tree-
bank.
In both tasks, we report the micro-averaged re-
sults of five-fold cross validation.
The Bikel-Collins and Charniak-Johnson
parsers were trained on Genia, using all the phrase
structure trees in the corpus except the test set;
i.e., the training set alo contains (in addition to
the four folds) 2021(= 4129 ? 2508) sentences
which are not in the five folds. Since the two
parsers were also trained on Genia, we interpret
the bracketing above each conjunction in the
parse tree output by them as the coordination
scope output by the parsers, in accordance with
how coordinations are annotated in Genia. In
2http://www.cis.upenn.edu/?dbikel/software.html
3ftp://ftp.cs.brown.edu/pub/nlparser/
reranking-parserAug06.tar.gz
testing, the Bikel-Collins parser and Shimbo-Hara
method were given the gold parts-of-speech
(POS) of the test sentences in Genia. We trained
the proposed method twice, once with the gold
POS tags and once with the POS tags output by
the Charniak-Johnson parser. This is because the
Charniak-Johnson parser does not accept POS
tags of the test sentences.
5.3 Features
To compute features for our method, each word
in a sentence was represented as a list of at-
tributes. The attributes include the surface word,
part-of-speech, suffix, prefix, and the indicators
of whether the word is capitalized, whether it is
composed of all uppercase letters or digits, and
whether it contains digits or hyphens. All fea-
tures are defined as an indicator of an attribute in
two words coming from either a single conjunct
(either horizontal or vertical word sequences asso-
ciated with the edit graph) or two conjuncts (one
from the horizontal word sequence and one from
the vertical sequence). We call the first type hori-
zontal/vertical bigrams and the second orthogonal
bigrams.
Table 3 summarizes the features in an edit
graph for two conjuncts (wkwk+1 ? ? ?wm) and
(wlwl+1 ? ? ?wn), where wi denotes the ith word in
the sentence.
As seen from the table, features are assigned
to the initial and terminal vertices as well as to
edges. A wiwj in the table indicates that for each
attribute (e.g., part-of-speech, etc.), an indicator
function for the combination of the attribute val-
ues in wi and wj is assigned to the vertex or edge
shown in the figure above. Note that the features
973
Table 4: Results of Task (i). The number of coor-
dinations of each type (#), and the recall (%) for
the proposed method, Bikel-Collins parser (BC),
and Charniak-Johnson parser (CJ).
gold POS CJ POS
COOD # Proposed BC Proposed CJ
Overall 3598 61.5 52.1 57.5 52.9
NP 2317 64.2 45.5 62.5 50.1
VP 465 54.2 67.7 42.6 61.9
ADJP 321 80.4 66.4 76.3 48.6
S 188 22.9 67.0 15.4 63.3
PP 167 59.9 53.3 53.9 58.1
UCP 60 36.7 18.3 38.3 26.7
SBAR 56 51.8 85.7 33.9 83.9
ADVP 21 85.7 90.5 85.7 90.5
Others 3 66.7 33.3 33.3 0.0
assigned to different types of vertex or edge are
treated as distinct even if the word indices i and j
are identical; i.e., all features are conditioned on
edge/vertex types to which they are assigned.
5.4 Results
Task (i) Table 4 shows the results of task (i). We
only list the recall score in the table, as precision
(and hence F1-measure, too) was equal to recall
for all methods in this task; this is not surpris-
ing given that in this data set, conjunctions ?and?,
?or?, and ?but? always indicate the existence of a
coordination, and all methods successfully learned
this trend from the training data.
The proposed method outperformed parsers on
the coordination scope identification overall. The
table also indicates that our method considerably
outperformed two parsers on NP-COOD, ADJP-COOD,
and UCP-COOD categories, but it did not work well
on VP-COOD, S-COOD, and SBAR-COOD. In contrast,
the parsers performed quite well in the latter cate-
gories.
Task (ii) Table 5 lists the results of task (ii).
The proposed method outperformed Shimbo-Hara
method in this task, although the setting of this
task is mostly identical to (Shimbo and Hara,
2007) and does not include nested coordinations.
Note also that both methods use roughly equiva-
lent features.
One reason should be that our grammar rules
can strictly enforce the scope consistency of con-
juncts in coordinations with three or more con-
juncts. Because the Shimbo-Hara method repre-
sents such coordinations as a series of sub-paths
in an edit graph which are output independently
of each other without enforcing consistency, their
Table 5: Results of Task (ii). Proposed method,
BC: Bikel-Collins, CJ: Charniak-Johnson, SH:
Shimbo-Hara.
gold POS CJ POS
Proposed BC SH Proposed CJ
Precision 61.7 45.6 55.9 60.2 49.0
Recall 57.9 46.1 53.7 55.6 46.8
F1 59.7 45.8 54.8 57.8 47.9
method can produce inconsistent scopes of con-
juncts in the middle.
In fact, the advantage of the proposed method in
task (ii) is noticeable especially in coordinations
with three or more conjuncts; if we restrict the test
set only to coordinations with three or more con-
juncts, the F-measures in the proposed method and
Shimbo-Hara become 53.0 and 42.3, respectively;
i.e., the margin increases to 10.7 from 4.9 points.
6 Conclusion and outlook
We have proposed a method for learning and
analyzing generic coordinate structures including
nested coordinations. It consists of a simple gram-
mar for coordination and perceptron learning of
alignment-based features.
The method performed well overall and on co-
ordinated noun and adjective phrases, but not on
coordinated verb phrases and sentences. The lat-
ter coordination types are in fact easy for parsers,
as the experimental results show.
The proposed method failing in verbal and sen-
tential coordinations is as expected, since con-
juncts in these coordinations are not necessarily
similar, if they are viewed as a sequence of words.
We will investigate similarity measures different
from sequence alignment, to better capture the
symmetry of these conjuncts.
We will also pursue integration of our method
with parsers. Because they have advantages in dif-
ferent coordination phrase types, their integration
looks promising.
Acknowledgments
We thank anonymous reviewers for helpful com-
ments and the pointer to the combinatory catego-
rial grammar.
References
Rajeev Agarwal and Lois Boggess. 1992. A simple but
useful approach to conjunct identification. In Pro-
ceedings of the 30th Annual Meeting of the Associa-
974
tion for Computational Linguistics (ACL?92), pages
15?21.
Daniel M. Bikel. 2005. Multilingual statistical pars-
ing engine version 0.9.9c. http://www.cis.upenn.
edu/?dbikel/software.html.
Ekaterina Buyko and Udo Hahn. 2008. Are morpho-
syntactic features more predicative for the resolution
of noun phrase coordination ambiguity than lexico-
semantic similarity scores. In Proceedings of the
22nd International Conference on Computational
Linguistics (COLING 2008), pages 89?96, Manch-
ester, UK.
Ekaterina Buyko, Katrin Tomanek, and Udo Hahn.
2007. Resolution of coordination ellipses in bi-
ological named entities using conditional random
fields. In Proceedings of the Pacific Association
for Computational Linguistics (PACLIC?07), pages
163?171.
Robyn Carston and Diane Blakemore. 2005. Editorial:
Introduction to coordination: syntax, semantics and
pragmatics. Lingua, 115:353?358.
Francis Chantree, Adam Kilgarriff, Anne de Roeck,
and Alistair Willis. 2005. Disambiguating coor-
dinations using word distribution information. In
Proceedings of the Int?l Conference on Recent Ad-
vances in Natural Language Processing, Borovets,
Bulgaria.
Eugene Charniak and Mark Johnson. 2005. Coarse-
to-fine n-best parsing and MaxEnt discriminative
reranking. In Proceedings of the 43rd Annual Meet-
ing of the Association for Computational Linguistics
(ACL 2005), pages 173?180, Ann Arbor, Michigan,
USA.
Stephen Clark and James R. Curran. 2007. Wide-
coverage efficient statistical parsing with CCG
and log-linear models. Computational Linguistics,
33(4):493?552.
Michael Collins. 2002. Discriminative training meth-
ods for hidden Markov models: theory and experi-
ments with perceptron algorithms. In Proceedings
of the Conference on Empirical Methods in Natu-
ral Language Processing (EMNLP 2002), pages 1?
8, Philadelphia, PA, USA.
Yoav Freund and Robert E. Schapire. 1999. Large
margin classification using the perceptron algorithm.
Machine Learning, 37(3):277?296.
Miriam Goldberg. 1999. An unsupervised model
for statistically determining coordinate phrase at-
tachment. In Proceedings of the Annual Meeting
of the Association for Computational Linguistics
(ACL 1999), pages 610?614, College Park, Mary-
land, USA.
Dan Gusfield. 1997. Algorithms on Strings, Trees, and
Sequences. Cambridge University Press.
Deirdre Hogan. 2007. Coordinate noun phrase disam-
biguation in a generative parsing model. In Proceed-
ings of the 45th Annual Meeting of the Association of
Computational Linguistics (ACL 2007), pages 680?
687, Prague, Czech Republic.
J.-D. Kim, T. Ohta, Y. Tateisi, and J. Tsujii. 2003.
GENIA corpus: a semantically annotated corpus for
bio-textmining. Bioinformatics, 19(Suppl. 1):i180?
i182.
Sadao Kurohashi and Makoto Nagao. 1994. A syn-
tactic analysis method of long Japanese sentences
based on the detection of conjunctive structures.
Computational Linguistics, 20:507?534.
Preslav Nakov and Marti Hearst. 2005. Using the web
as an implicit training set: application to structural
ambiguity resolution. In Proceedings of the Human
Language Technology Conference and Conference
on Empirical Methods in Natural Language (HLT-
EMNLP 2005), pages 835?842, Vancouver, Canada.
Akitoshi Okumura and Kazunori Muraki. 1994. Sym-
metric pattern matching analysis for English coordi-
nate structures. In Proceedings of the Fourth Con-
ference on Applied Natural Language Processing,
pages 41?46.
Philip Resnik. 1999. Semantic similarity in a tax-
onomy. Journal of Artificial Intelligence Research,
11:95?130.
Wolfgang Schuette, Thomas Blankenburg, Wolf
Guschall, Ina Dittrich, Michael Schroeder, Hans
Schweisfurth, Assaad Chemaissani, Christian Schu-
mann, Nikolas Dickgreber, Tabea Appel, and Di-
eter Ukena. 2006. Multicenter randomized trial for
stage iiib/iv non-small-cell lung cancer using every-
3-week versus weekly paclitaxel/carboplatin. Clini-
cal Lung Cancer, 7:338?343.
Masashi Shimbo and Kazuo Hara. 2007. A discrimi-
native learning model for coordinate conjunctions.
In Proceedings of Joint Conference on Empirical
Methods in Natural Language Processing and Com-
putational Natural Language Learning (EMNLP-
CoNLL 2007), pages 610?619, Prague, Czech Re-
public.
Mark Steedman. 2000. The Syntactic Process. MIT
Press, Cambridge, MA, USA.
975
Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 5?8,
Suntec, Singapore, 4 August 2009. c?2009 ACL and AFNLP
Bypassed Alignment Graph for Learning Coordination in Japanese
Sentences
Hideharu Okuma Kazuo Hara Masashi Shimbo Yuji Matsumoto
Graduate School of Information Science
Nara Institute of Science and Technology
Ikoma, Nara 630-0192, Japan
{okuma.hideharu01,kazuo-h,shimbo,matsu}@is.naist.jp
Abstract
Past work on English coordination has fo-
cused on coordination scope disambigua-
tion. In Japanese, detecting whether coor-
dination exists in a sentence is also a prob-
lem, and the state-of-the-art alignment-
based method specialized for scope dis-
ambiguation does not perform well on
Japanese sentences. To take the detection
of coordination into account, this paper in-
troduces a ?bypass? to the alignment graph
used by this method, so as to explicitly
represent the non-existence of coordinate
structures in a sentence. We also present
an effective feature decomposition scheme
based on the distance between words in
conjuncts.
1 Introduction
Coordination remains one of the challenging prob-
lems in natural language processing. One key
characteristic of coordination explored in the past
is the structural and semantic symmetry of con-
juncts (Chantree et al, 2005; Hogan, 2007;
Resnik, 1999). Recently, Shimbo and Hara (2007)
proposed to use a large number of features to
model this symmetry, and optimize the feature
weights with perceptron training. These features
are assigned to the arcs of the alignment graph (or
edit graph) originally developed for biological se-
quence alignment.
Coordinate structure analysis involves two re-
lated but different tasks:
1. Detect the presence of coordinate structure in
a sentence (or a phrase).
2. Disambiguate the scope of coordinations in
the sentences/phrases detected in Task 1.
The studies on English coordination listed
above are concerned mainly with scope disam-
biguation, reflecting the fact that detecting the
presence of coordinations in a sentence (Task 1)
is straightforward in English. Indeed, nearly 100%
precision and recall can be achieved in Task 1 sim-
ply by pattern matching with a small number of
coordination markers such as ?and,? ?or,? and ?as
well as?.
In Japanese, on the other hand, detecting coor-
dination is non-trivial. Many of the coordination
markers in Japanese are ambiguous and do not al-
ways indicate the presence of coordinations. Com-
pare sentences (1) and (2) below:
rondon to pari ni itta
(London) (and) (Paris) (to) (went)
(I went to London and Paris)
(1)
kanojo to pari ni itta
(her) (with) (Paris) (to) (went)
(I went to Paris with her)
(2)
These sentences differ only in the first word. Both
contain a particle to, which is one of the most fre-
quent coordination markers in Japanese?but only
the first sentence contains a coordinate structure.
Pattern matching with particle to thus fails to filter
out sentence (2).
Shimbo and Hara?s model allows a sentence
without coordinations to be represented as a nor-
mal path in the alignment graph, and in theory it
can cope with Task 1 (detection). In practice, the
representation is inadequate when a large number
of training sentences do not contain coordinations,
as demonstrated in the experiments of Section 4.
This paper presents simple yet effective modi-
fications to the Shimbo-Hara model to take coor-
dination detection into account, and solve Tasks 1
and 2 simultaneously.
5
a 
policeman 
and 
warehouse
guard
a po
lic
em
an
 
an
d 
w
ar
eh
ou
se
gu
ar
d
a 
policeman 
and 
warehouse
guard
a po
lic
em
an
 
an
d 
w
ar
eh
ou
se
gu
ar
d
(a) Alignment graph (b) Path 1
a 
policeman 
and 
warehouse
guard
a po
lic
em
an
 
an
d 
w
ar
eh
ou
se
gu
ar
d
a 
policeman 
and 
warehouse
guard
a po
lic
em
an
 
an
d 
w
ar
eh
ou
se
gu
ar
d
(c) Path 2 (d) Path 3 (no coordination)
Figure 1: Alignment graph for ?a policeman and
warehouse guard? ((a)), and example paths repre-
senting different coordinate structure ((b)?(d)).
2 Alignment-based coordinate structure
analysis
We first describe Shimbo and Hara?s method upon
which our improvements are made.
2.1 Triangular alignment graph
The basis of their method is a triangular align-
ment graph, illustrated in Figure 1(a). Kurohashi
and Nagao (1994) used a similar data structure in
their rule-based method. Given an input sentence,
the rows and columns of its alignment graph are
associated with the words in the sentence. Un-
like the alignment graph used in biological se-
quence alignment, the graph is triangular because
the same sentence is associated with rows and
columns. Three types of arcs are present in the
graph. A diagonal arc denotes coordination be-
tween the word above the arc and the one on the
right; the horizontal and vertical arcs represent
skipping of respective words.
Coordinate structure in a sentence is repre-
sented by a complete path starting from the top-
left (initial) node and arriving at the bottom-right
(terminal) node in its alignment graph. Each arc
in this path is labeled either Inside or Outside de-
pending on whether its span is part of coordina-
tion or not; i.e., the horizontal and vertical spans
of an Inside segment determine the scope of two
conjuncts. Figure 1(b)?(d) depicts example paths.
Inside and Outside arcs are depicted by solid and
dotted lines, respectively. Figure 1(b) shows a
path for coordination between ?policeman? (ver-
tical span of the Inside segment) and ?warehouse
guard? (horizontal span). Figure 1(c) is for ?po-
liceman? and ?warehouse.? Non-existence of co-
ordinations in a sentence is represented by the
Outside-only path along the top and the rightmost
borders of the graph (Figure 1(d)).
With this encoding of coordinations as paths,
coordinate structure analysis can be reduced to
finding the highest scoring path in the graph,
where the score of an arc is given by a measure
of how much two words are likely to be coordi-
nated. The goal is to build a measure that assigns
the highest score to paths denoting the correct co-
ordinate structure. Shimbo and Hara defined this
measure as a linear function of many features as-
sociated to arcs, and used perceptron training to
optimize the weight coefficients for these features
from corpora.
2.2 Features
For the description of features used in our adap-
tation of the Shimbo-Hara model to Japanese, see
(Okuma et al, 2009). In this model, all features
are defined as indicator functions asking whether
one or more attributes (e.g., surface form, part-of-
speech) take specific values at the neighbor of an
arc. One example of a feature assigned to a diag-
onal arc at row i and column j of the alignment
graph is
f =
?
?
?
1 if POS[i] = Noun, POS[ j] = Adjective,
and the label of the arc is Inside,
0 otherwise.
where POS[i] denotes the part-of-speech of the ith
word in a sentence.
3 Improvements
We introduce two modifications to improve the
performance of Shimbo and Hara?s model in
Japanese coordinate structure analysis.
3.1 Bypassed alignment graphs
In their model, a path for a sentence with no coor-
dination is represented as a series of Outside arcs
as we saw in Figure 1(d). However, Outside arcs
also appear in partial paths between two coordina-
tions, as illustrated in Figure 2. Thus, two differ-
6
Aand
B
are
X
and
Y
A an
d
B ar
e 
X an
d
Y
Figure 2: Original alignment graph for sentence
with two coordinations. Notice that Outside (dot-
ted) arcs connect two coordinations
Figure 3: alignment graph with a ?bypass?
ent roles are given to Outside arcs in the original
Shimbo-Hara model.
We identify this to be a cause of their model not
performing well for Japanese, and propose to aug-
ment the original alignment graph with a ?bypass?
devoted to explicitly indicate that no coordination
exists in a sentence; i.e., we add a special path di-
rectly connecting the initial node and the terminal
node of an alignment graph. See Figure 3 for il-
lustration of a bypass.
In the new model, if the score of the path
through the bypass is higher than that of any paths
in the original alignment graph, the input sentence
is deemed not containing coordinations.
We assign to the bypass two types of features
capturing the characteristics of a whole sentence;
i.e., indicator functions of sentence length, and of
the existence of individual particles in a sentence.
The weight of these features, which eventually de-
termines the score of the bypass, is tuned by per-
ceptron just like the weights of other features.
3.2 Making features dependent on the
distance between conjuncts
Coordinations of different type (e.g., nominal and
verbal) have different relevant features, as well as
different average conjunct length (e.g., nominal
coordinations are shorter).
This observation leads us to our second modi-
fication: to make all features dependent on their
occurring positions in the alignment graph. To be
precise, for each individual feature in the original
model, a new feature is introduced which depends
on whether the Manhattan distance d in the align-
ment graph between the position of the feature oc-
currence and the nearest diagonal exceeds a fixed
threshold1 ? . For instance, if a feature f is an in-
dicator function of condition X , a new feature f ? is
introduced such that
f ? =
{
1, if d ? ? and condition X holds,
0, otherwise.
Accordingly, different weights are learned and as-
sociated to two features f and f ?. Notice that the
Manhattan distance to the nearest diagonal is equal
to the distance between word pairs to which the
feature is assigned, which in turn is a rough esti-
mate of the length of conjuncts.
This distance-based decomposition of features
allows different feature weights to be learned for
coordinations with conjuncts shorter than or equal
to ? , and those which are longer.
4 Experimental setup
We applied our improved model and Shimbo and
Hara?s original model to the EDR corpus (EDR,
1995). We also ran the Kurohashi-Nagao parser
(KNP) 2.02, a widely-used Japanese dependency
parser to which Kurohashi and Nagao?s (1994)
rule-based coordination analysis method is built
in. For comparison with KNP, we focus on bun-
setsu-level coordinations. A bunsetsu is a chunk
formed by a content word followed by zero or
more non-content words like particles.
4.1 Dataset
The Encyclopedia section of the EDR corpus was
used for evaluation. In this corpus, each sentence
is segmented into words and is accompanied by a
syntactic dependency tree, and a semantic frame
representing semantic relations among words.
A coordination is indicated by a specific relation
of type ?and? in the semantic frame. The scope of
conjuncts (where a conjunct may be a word, or a
series of words) can be obtained by combining this
information with that of the syntactic tree. The
detail of this procedure can be found in (Okuma et
al., 2009).
1We use ? = 5 in the experiments of Section 4.
2http://nlp.kuee.kyoto-u.ac.jp/nl-resource/knp-e.html
7
Table 1: Accuracy of coordination scopes and end of conjuncts, averaged over five-fold cross validation.
The numbers in brackets are the improvements (in points) relative to the Shimbo-Hara (SH) method.
Scope of coordinations End of conjuncts
Method Precision Recall F1 measure Precision Recall F1 measure
KNP n/a n/a n/a 58.8 65.3 61.9 (?2.6)
Shimbo and Hara?s method (SH; baseline) 53.7 49.8 51.6 (?0.0) 67.0 62.1 64.5 (?0.0)
SH + distance-based feature decomposition 55.3 52.1 53.6 (+2.0) 68.3 64.3 66.2 (+1.7)
SH + distance-based feature decomposition + bypass 55.0 57.6 56.3 (+4.7) 66.8 69.9 68.3 (+3.8)
Of 10,072 sentences in the Encyclopedia sec-
tion, 5,880 sentences contain coordinations. We
excluded 1,791 sentences in which nested coordi-
nations occur, as these cannot be processed with
Shimbo and Hara?s method (with or without our
improvements).
We then applied Japanese morphological ana-
lyzer JUMAN 5.1 to segment each sentence into
words and annotate them with parts-of-speech,
and KNP with option ?-bnst? to transform the se-
ries of words into a bunsetsu series. With this
processing, each word-level coordination pair is
also translated into a bunsetsu pair, unless the
word-level pair is concatenated into a single bun-
setsu (sub-bunsetsu coordination). Removing sub-
bunsetsu coordinations and obvious annotation er-
rors left us with 3,257 sentences with bunsetsu-
level coordinations. Combined with the 4,192 sen-
tences not containing coordinations, this amounts
to 7,449 sentences used for our evaluation.
4.2 Evaluation metrics
KNP outputs dependency structures in Kyoto Cor-
pus format (Kurohashi et al, 2000) which spec-
ifies the end of coordinating conjuncts (bunsetsu
sequences) but not their beginning.
Hence two evaluation criteria were employed:
(i) correctness of coordination scopes3 (for com-
parison with Shimbo-Hara), and (ii) correctness of
the end of conjuncts (for comparison with KNP).
We report precision, recall and F1 measure, with
the main performance index being F1 measure.
5 Results
Table 1 summarizes the experimental results.
Even Shimbo and Hara?s original method (SH)
outperformed KNP. KNP tends to output too many
coordinations, yielding a high recall but low pre-
cision. By contrast, SH outputs a smaller number
3A coordination scope is deemed correct only if the brack-
eting of constituent conjuncts are all correct.
of coordinations; this yields a high precision but a
low recall.
The distance-based feature decomposition of
Section 3.2 gave +2.0 points improvement over the
original SH in terms of F1 measure in coordination
scope detection. Adding bypasses to alignment
graphs further improved the performance, making
a total of +4.7 points in F1 over SH; recall signifi-
cantly improved, with precision remaining mostly
intact. Finally, the improved model (SH + decom-
position + bypass) achieved an F1 measure +6.4
points higher than that of KNP in terms of end-of-
conjunct identification.
References
F. Chantree, A. Kilgarriff, A. de Roeck, and A. Willis.
2005. Disambiguating coordinations using word
distribution information. In Proc. 5th RANLP.
EDR, 1995. The EDR dictionary. NICT. http://www2.
nict.go.jp/r/r312/EDR/index.html.
D. Hogan. 2007. Coordinate noun phrase disambigua-
tion in a generative parsing model. In Proc. 45th
ACL, pages 680?687.
S. Kurohashi and M. Nagao. 1994. A syntactic analy-
sis method of long Japanese sentences based on the
detection of conjunctive structures. Comput. Lin-
guist., 20:507?534.
S. Kurohashi, Y. Igura, and M. Sakaguchi, 2000. An-
notation manual for a morphologically and sytac-
tically tagged corpus, Ver. 1.8. Kyoto Univ. In
Japanese. http://nlp.kuee.kyoto-u.ac.jp/nl-resource/
corpus/KyotoCorpus4.0/doc/syn guideline.pdf.
H. Okuma, M. Shimbo, K. Hara, and Y. Matsumoto.
2009. Bypassed alignment graph for learning coor-
dination in Japanese sentences: supplementary ma-
terials. Tech. report, Grad. School of Information
Science, Nara Inst. Science and Technology. http://
isw3.naist.jp/IS/TechReport/report-list.html#2009.
P. Resnik. 1999. Semantic similarity in a taxonomy. J.
Artif. Intel. Res., 11:95?130.
M. Shimbo and K. Hara. 2007. A discriminative learn-
ing model for coordinate conjunctions. In Proc.
2007 EMNLP/CoNLL, pages 610?619.
8
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 613?623,
Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational Linguistics
Centering Similarity Measures to Reduce Hubs
Ikumi Suzuki
National Institute of Genetics
Mishima, Shizuoka, Japan
suzuki.ikumi@gmail.com
Kazuo Hara
National Institute of Genetics
Mishima, Shizuoka, Japan
kazuo.hara@gmail.com
Masashi Shimbo
Nara Institute of Science and Technology
Ikoma, Nara, Japan
shimbo@is.naist.jp
Marco Saerens
Universite? catholique de Louvain
Louvain-la-Neuve, Belgium
marco.saerens@uclouvain.be
Kenji Fukumizu
The Institute of Statistical Mathematics
Tachikawa, Tokyo, Japan
fukumizu@ism.ac.jp
Abstract
The performance of nearest neighbor methods
is degraded by the presence of hubs, i.e., ob-
jects in the dataset that are similar to many
other objects. In this paper, we show that the
classical method of centering, the transforma-
tion that shifts the origin of the space to the
data centroid, provides an effective way to re-
duce hubs. We show analytically why hubs
emerge and why they are suppressed by cen-
tering, under a simple probabilistic model of
data. To further reduce hubs, we also move
the origin more aggressively towards hubs,
through weighted centering. Our experimental
results show that (weighted) centering is effec-
tive for natural language data; it improves the
performance of the k-nearest neighbor classi-
fiers considerably in word sense disambigua-
tion and document classification tasks.
1 Introduction
1.1 Background
The k-nearest neighbor (kNN) algorithm is a sim-
ple nonparametric method of classification. It has
been applied to various natural language process-
ing (NLP) tasks such as document classification
(Masand et al, 1992; Yang and Liu, 1999), part-
of-speech tagging (S?gaard, 2011), and word sense
disambiguation (Navigli, 2009).
To apply the kNN algorithm, data is typically rep-
resented as a vector object in a feature space, and
(dis)similarity between data is measured by the dis-
tance between the vectors, their inner product, or co-
sine of the angle between them (Jurafsky and Mar-
tin, 2008). With such a (dis)similarity measure, the
unknown class label of a test object is predicted by
a majority vote of the classes of its k most similar
objects in the labeled training set.
Recent studies (Radovanovic? et al, 2010a;
Radovanovic? et al, 2010b) have shown that if the
feature space is high-dimensional, some objects in
the dataset emerge as hubs; i.e., these objects fre-
quently appear in the k nearest neighbors of other
objects.
The emergence of hubs may deteriorate the per-
formance of kNN classification and nearest neighbor
search in general:
? If hub objects exist in the training set, they have
a strong chance to be a kNN of many test ob-
jects. Because the class of a test object is pre-
dicted by a majority vote from its k nearest
neighbors, prediction is biased toward the la-
bels of the hubs.
? In information retrieval, nearest neighbor
search finds objects in the database that are
most relevant, or similar, to user-provided
queries. If particular objects, such as hubs, are
nearly always returned for any query, the re-
trieved results are probably not very useful.
These drawbacks may hinder application of near-
est neighbor methods in NLP, as typical natural lan-
guage data are extremely high-dimensional (Juraf-
sky and Martin, 2008) and thus prone to produce
hubs.
1.2 Contributions
Centering (Mardia et al, 1979; Fisher and Lenz,
1996; Eriksson et al, 2006) is a standard technique
613
for removing observation bias in the data. It is a
transformation of feature space in a way that the ori-
gin of the space is moved to the data centroid (sam-
ple mean). The distance between data objects is not
changed by centering, but their inner product and co-
sine are affected; see Section 3 for detail.
In this paper, we advocate the use of centering as a
means of reducing hubs. Specifically, we propose to
measure the similarity of objects by the inner prod-
uct (not distance or cosine) in the centered feature
space.
Our approach is motivated by the observation that
the objects similar to the data centroid tend to be-
come hubs (Radovanovic? et al, 2010a). This ob-
servation suggests that the number of hubs may be
reduced if we can define a similarity measure that
makes all objects in a dataset equally similar to the
centroid (Suzuki et al, 2012). The inner product in
the centered space indeed enjoys this property.
In Section 4, we analyze why hubs emerge under
a simple probabilistic model of data, and also give
an account of why they are suppressed by centering.
Using both synthetic and real datasets, we show
that objects similar to the centroid also emerge as
hubs in multi-cluster data (Section 5), so the applica-
tion of centering is wider than expected. To further
reduce hubs, we also propose to move the origin of
the space more aggressively towards hubs, through
weighted centering (Section 6).
In Section 7, we show that centering and weighted
centering are effective for natural language data.
these methods markedly improve the performance
of kNN classifiers in word sense disambiguation and
document classification tasks.
2 Related work
Centering is a classical technique widely used in
many fields of science. For instance, centering
forms a preprocessing step in principal component
analysis and Fisher linear discriminant analysis.
In NLP, however, centering is seldom used; the
use of cosine and inner product similarities is quite
common, but they are nearly always used uncen-
tered. Non-centered cosine is used, for instance, in
word sense disambiguation (Schu?tze, 1998; Navigli,
2009), paraphrasing (Erk and Pado?, 2008; Thater
et al, 2010), and compositional semantics (Mitchell
and Lapata, 2008), to name a few.
There have been several approaches to improv-
ing kNN classification: learning similarity/distance
measures from training data (metric learning)
(Weinberger and Saul, 2009; Qamar et al, 2008),
weighting nearest neighbors for similarity-based
classification (Chen et al, 2009), and neighbor-
hood size selection (Wang et al, 2006; Guo and
Chakraborty, 2010). However, none of these have
addressed the reduction of hubs.
More recently, Schnitzer et al (2012) proposed
the Mutual Proximity transformation that rescales
distance measures to decrease hubs in a dataset.
Suzuki et al (2012) showed that kernels based on
graph Laplacian, such as the commute-time kernels
(Saerens et al, 2004) and the regularized Laplacian
(Chebotarev and Shamis, 1997; Smola and Kondor,
2003), make all objects equally similar to the data
centroid, which in turn reduce hubs.
In Section 7, we evaluate centering, Mutual Prox-
imity, and Laplacian kernels in NLP tasks, and
demonstrate that centering is equally or even more
effective. Section 4 presents a theoretical justifica-
tion for using centering to reduce hubs, but this kind
of analysis is missing for the Laplacian kernels.
Centering is easier to compute as well. For a
dataset of n objects, it takes O(n2) time to com-
pute, whereas computing a Laplacian-based kernel
requires O(n3) time for matrix inversion. Mutual
Proximity also has a time complexity of O(n2).
3 Centering
Consider a dataset of n objects in an m-dimensional
feature space, x1, ? ? ? , xn ? Rm. Throughout this
paper, we use the inner product ?xi, x j? as a measure
of similarity between xi and x j. Let K be the Gram
matrix of the n feature vectors, i.e., the n ? n matrix
whose (i, j) element holds ?xi, x j?. Using m? n data
matrix X = [x1, ? ? ? , xn], we can write K as
K = XTX,
where XT represents the matrix transpose of X.
Centering is a transformation in which the origin
of the feature space is shifted to the data centroid
x? =
1
n
n?
i=1
xi, (1)
614
and object x is mapped to the centered feature vector
xcent = x ? x?. (2)
The similarity between two objects x and x? is now
measured by ?xcent, x?cent? = ?x ? x?, x? ? x??.
After centering, the inner product between any
object and the data centroid (which is a zero vector
because x?cent = x? ? x? = 0) is uniformly 0; in other
words, all objects in the dataset have an equal simi-
larity to the centroid. According to the observation
that the objects similar to the centroid become hubs
(Radovanovic? et al, 2010a), we can expect hubs to
be reduced after centering.
Intuitively, centering reduces hubs because it
makes the length of the feature vector xcent short
for (hub) objects x that lie close to the data centroid
x?; see Eq. (2). And since we measure object simi-
larity by inner product, shorter vectors tend to pro-
duce smaller similarity scores. Hence objects close
to the data centroid become less similar to other ob-
jects after centering, and no longer be hubs. In Sec-
tion 4, we analyze the effect of centering on hubness
in more detail.
3.1 Centered Gram matrix
Let I be an n ? n identity matrix and 1 be an n-
dimensional all-ones vector. The symmetric matrix
H = I?(1/n)11T is called centering matrix, because
the centered data matrix Xcent = [xcent1 , ? ? ? , x
cent
n ]
can be computed by Xcent = XH (Mardia et al,
1979).
The Gram matrix Kcent of the centered feature
vectors, whose (i, j) element holds the inner prod-
uct ?xcenti , x
cent
j ?, can be calculated from the original
Gram matrix K by
Kcent =
(
Xcent
)T (
Xcent
)
= HXTXH = HKH. (3)
Eq. (3) implies that the original data matrix X is
not needed to compute the centered Gram matrix
Kcent, provided that K is given. It is hence possi-
ble to use the so-called kernel trick; i.e., centering
can be applied even if data matrix X is not available
but the similarity of objects can be measured by a
kernel function in an implicit feature space.
4 Theoretical analysis of the effect of
centering on hubness
We now analyze why objects most similar to the
centroid tend to be hubs in the dataset, and give an
explanation as to why centering may suppress the
emergence of hubs.
4.1 Before centering
Consider a dataset of m-dimensional feature vectors,
with each vector x ? Rm generated independently
from a distribution with a finite mean vector ?. In
other words, objects x in this dataset are drawn from
a distribution P(x), i.e.,
x ? P(x),
and
? = E[x] =
?
x dP(x) (4)
where E[?] denotes the expectation of a random vari-
able.
We will use the following elementary lemma on
the distributions of inner product subsequently.
Lemma 1. Let a ? Rm be a fixed vector, and x ? Rm
be an object sampled according to distribution P(x).
Then the inner product ?a, x? follows a distribution
with mean ?a,??.
Proof. From the linearity of the inner product and
Eq. (4), we obtain
E[?a, x?] =
?
?a, x? dP(x)
= ?a,
?
x dP(x)? = ?a,??. 
Now, imagine that we have an object x sam-
pled from P(x), and we want to compute its nearest
neighbor in a dataset. Let h and ` be two fixed ob-
jects in the dataset, such that the inner product to the
true mean ? is higher for h than for `, i.e.,
?h,?? ? ?`,?? > 0. (5)
We are interested in which of h and ` is more similar
to x (in terms of inner product), or in other words,
the difference of two inner products
z = ?h, x? ? ?`, x? = ?h ? `, x?. (6)
615
Because x is a random variable, so is z. Let Q(z) be
the distribution of z; i.e., z ? Q(z).
Using Lemma 1 with a = h ? `, together with
Eq. (5), we have
E[z] = ?h ? `,?? = ?h,?? ? ?`,?? > 0. (7)
Note that the above statement is only concerned
about the mean, so it does not in general assure that
?h, x? > ?`, x? (8)
holds with high probability; there is a chance that
a small number of outliers are inflating the mean.
To assure that inequality (8) holds with probability
greater than 1/2 for instance, the median rather than
the mean of the distribution Q(z) must be greater
than 0.
If the distribution Q(z) is symmetric, the median
occurs at the same point as the mean, and the above
claim holds. Indeed, if the components of x are gen-
erated independently from (possibly non-identical)
normal distributions, we can show that Q(z) also
obeys a normal distribution. Because it is a symmet-
ric distribution, we can safely say that in this case,
Eq. (8) holds with probability greater than 1/2.
For a general non-symmetric distribution with a
finite variance, the median is known to be within the
standard deviation of the mean (Mallows, 1991), so
we could still say that Eq. (8) is likely to hold if ?h?
`,?? is sufficiently large compared to the standard
deviation.
Now, if we let h be the object in a given dataset
with the highest similarity (inner product) to the
mean ?, and let ` be any other object in the set, then
we see from the above discussion that h is likely to
have higher similarity to x, a test sample drawn from
distribution P(x). Because this holds for any ` in
the dataset, the conclusion is that the objects in the
dataset most similar to ? are likely to become hubs.
4.2 After centering
Next let us investigate what happens if the dataset
is centered. Let x? be the sample (empirical) mean
given by Eq. (1). After centering, the similarity of x
with each of the two fixed objects h and ` are evalu-
ated by ?h? x?, x? x?? and ?`? x?, x? x??, respectively.
Their difference zcent is given by
zcent = ?h ? x?, x ? x?? ? ?` ? x?, x ? x??
= ?h ? `, x ? x??
= ?h ? `, x? ? ?h ? `, x??
= z ? ?h ? `, x??.
The last equality follows from Eq. (6). By definition
we have z ? Q(z), and since ?h ? `, x?? is a constant,
zcent = z ? ?h ? `, x?? ? Q(z + ?h ? `, x??).
In other words, the shape of the distribution does not
change, but the mean is shifted to
E[zcent] = E[z] ? ?h ? `, x??
= ?h ? `,?? ? ?h ? `, x??
= ?h ? `,? ? x??,
where E[z] is given by Eq. (7). If the sample mean
x? is close enough to the true mean ?, i.e., x? ? ?, we
have an approximation
E[zcent] = ?h ? `,? ? x?? ? 0. (9)
Thus, if the median and the mean of distribution
Q(z) are again not far apart, Eq. (9) suggests that
h ? x? and ` ? x? are about equally likely to be more
similar to x ? x?; i.e., neither has a greater chance to
become a hub.
5 Hubs in multi-cluster data
In this section, we discuss emergence of hubs when
the data consists of multiple clusters. In fact, the
analysis of Section 4 is distribution-free, and thus
also applies to the case of multi-modal P(x). How-
ever, one might still argue that objects similar to the
data centroid should hardly occur in that case. Us-
ing both synthetic and real datasets, we demonstrate
below that even in multi-cluster data, objects that
are only slightly more similar to the data mean (cen-
troid) may emerge as hubs.
5.1 Synthetic data
5.1.1 Data generation
We generated a high-dimensional multi-cluster
dataset by modeling it as a mixture of ten von Mises-
Fisher distributions (Mardia and Jupp, 2000) in
616
0 50 100 1500.45
0.5
0.55
0.6
N10
Similar
ity with
 centro
id
(a) Before centering: N10 vs. inner
product similarity to the data cen-
troid
200 400 600 800 1000
200
400
600
800
1000
Object ID
Object I
D
 
 
510
1520
2530
3540
4550
(b) Before centering: kNN matrix
200 400 600 800 1000150
100
50
0
50
100
150
Object ID
Freque
ncy
(c) Before centering: Breakdown of
N10 by cluster match/mismatch
between objects and neighbors
0 50 100 150?0.1
?0.05
0
0.05
0.1
N10
Similar
ity with
 centro
id
(d) After centering: N10 vs. inner
product similarity to the data cen-
troid
200 400 600 800 1000
200
400
600
800
1000
Object ID
Object I
D
 
 
510
1520
2530
3540
4550
(e) After centering: kNN matrix
200 400 600 800 1000150
100
50
0
50
100
150
Object ID
Freque
ncy
(f) After centering: Breakdown of
N10 by cluster match/mismatch
between objects and neighbors
Figure 1: 300-dimensional synthetic data. (a), (d): scatter plot of the N10 value of objects and their similarity to
centroid. (b), (e): kNN matrices. The points are colored according to the N10 value of object x; warmer colors indicate
higher N10 values. (c), (f): the number of times (y-axis) an object (whose ID is on the x-axis) appears in the 10 nearest
neighbors of objects of the same cluster (black bars), and those of different clusters (magenta).
R300. The von Mises-Fisher distribution is a distri-
bution of unit vectors (it can roughly be thought of
as a normal distribution on a unit hypersphere), so
for objects (feature vectors) sampled from this dis-
tribution, inner product reduces to cosine similarity.
We sampled1 100 objects from each of the ten dis-
tributions (clusters), and made a dataset of 1,000 ob-
jects in total.
The von Mises-Fisher distribution has two param-
eters, the mean direction vector ?, and the concen-
tration parameter ? characterizing how strongly the
population is concentrated around the direction ?.
We set ? = 500 for all ten distributions, but the mean
directions ? were made distinct; all mean direction
1We used the random sampling code available at http:
//people.kyb.tuebingen.mpg.de/suvrit/work/progs/movmf.html
(Banerjee et al, 2005).
vectors had 30 components set to 0.5 while the re-
maining 270 components were set to 1, but the 30
components with value 0.5 were chosen to be dis-
tinct among the ten clusters. This configuration as-
sures that all ten mean directions have the same an-
gle from the all-ones vector [1, . . . , 1]T, which is the
direction of the mean of the entire data distribution.
Note that even though all sampled objects reside
on the surface of the unit hypersphere, the data cen-
troid lies not on the surface but inside the hyper-
sphere. And after centering, the length of the fea-
ture vectors may vary from one another, but we do
not normalize these vectors; i.e., object similarity is
measured by raw inner product, not by cosine.
617
5.1.2 Correlation between hubness and
centroid similarity
The scatter plot in Figure 1(a) shows the correla-
tion between the degree of hubness (N10) of an ob-
ject and its inner product similarity to the data cen-
troid. The N10 value of an object is defined as the
number of times the object appears in the 10 nearest
neighbors of other objects in the dataset. It was used
in (Radovanovic? et al, 2010a) to measure the degree
of hubness of individual objects.
The plot clearly shows that the hub objects (i.e.,
those with high N10) consist of objects that are simi-
lar to the centroid. Figure 1(d) shows the scatter plot
after the data is centered, created in the same way
as Figure 1(a). The similarity to the centroid is uni-
formly 0 as a result of centering, and no objects have
an N10 value greater than 33.
5.1.3 Influence of hubs on objects in different
clusters
The kNN matrix of Figure 1(b) depicts the kNN
relations with k = 10 among objects before center-
ing. In this matrix, both the x- and y- axes represent
the ID of the objects. If object x is in the 10 nearest
neighbors of object y, a point is plotted at coordi-
nates (x, y). As a result, there are exactly k = 10
points in each row. The color of points indicates the
degree of hubness of object x; warmer color repre-
sents higher N10 value of the object.
In this matrix, object IDs are sorted by the clus-
ter the objects belong to. Hence in the ideal case in
which the k nearest neighbors of every object consist
genuinely of objects from the same cluster, only the
diagonal blocks would be colored, and off-diagonal
areas would be left blank.
As Figure 1(b) shows, the actual situation is far
from ideal, even though ten diagonal blocks are still
identifiable. The presence of many warm colored
vertical lines suggests that many hub objects appear
in the 10 nearest neighbors of other objects that are
not in the same cluster as the hubs. Thus these hubs
may have a strong influence on the kNN prediction
of other objects.
Figure 1(e) shows the kNN matrix after centering.
The warm colored lines have disappeared, and the
diagonal blocks are now more visible.
The bar graphs of Figures 1(c) and (f) plot the N10
value of each object (whose ID is on the x-axis). Re-
call that N10 is the number of times an object appears
in the 10 nearest neighbors of other objects. The
bar for each object is broken down by whether the
object and its neighbors belong to the same cluster
(black bar) or in different clusters (magenta bar). In
terms of kNN classification, having a large number
of nearest neighbors with the same class improves
the classification performance, so longer black bars
and shorter magenta bars are more desirable.
Before centering (Figure 1(c)), hub objects with
large N10 values are similar not only to objects be-
longing to the same cluster (as indicated by black
bars), but also to objects belonging to different clus-
ters (magenta bars). After centering (Figure 1(f)),
the number of tall magenta bars decreases.
Before centering, 22.7% of the 10 nearest neigh-
bors of an object have the same class label as the
object (as indicated by the ratio of the total height of
black bars relative to that of all bars in Figure 1(c)).
After centering, the percentage increases to 31.6%.
5.2 Real dataset
We did the same analysis as Sections 5.1.2?5.1.3
to a real dataset with multiple-cluster structure: the
Reuters Transcribed dataset. This multi-class docu-
ment classification dataset has ten classes, and each
class roughly forms a cluster. We will also use this
dataset in an experiment in Section 7.2.
The results are shown in Figure 2. We can ob-
serve the same trends as we saw in Figure 1 for the
synthetic data: positive correlation between hubness
(N10) and inner product with the data centroid be-
fore centering; hubs appearing in the nearest neigh-
bors of many objects of different classes; and both
are reduced after centering.
The ratio of the height of black bars to that of
all bars in Figure 2(c) is 38.4% before centering,
whereas it improves to 41.0% after centering (Fig-
ure 2(f)).
6 Hubness weighted centering
Centering shifts the origin of the space to the data
centroid, and objects similar to the centroid tend to
become hubs. Thus in a sense, centering can be
interpreted as an operation that shifts the origin to-
wards hubs.
In this section, we extrapolate this interpretation,
618
0 10 20 30 40 500
0.01
0.02
0.03
0.04
0.05
0.06
N10
Simila
rity w
ith ce
ntroid
(a) Before centering: N10 vs. inner
product similarity to the data cen-
troid
50 100 150 200
50
100
150
200
Object ID
Object
 ID
 
 
5
10
15
20
25
30
(b) Before centering: kNN matrix
50 100 150 20040
20
0
20
40
Object ID
Frequ
ency
(c) Before centering: Breakdown of
N10 by class match/mismatch be-
tween objects and neighbors
0 10 20 30 40 50?0.03
?0.02
?0.01
0
0.01
0.02
0.03
N10
Simila
rity w
ith ce
ntroid
(d) After centering: N10 vs. inner
product similarity to the data cen-
troid
50 100 150 200
50
100
150
200
Object ID
Object
 ID
 
 
5
10
15
20
25
30
(e) After centering: kNN matrix
50 100 150 20040
20
0
20
40
Object ID
Frequ
ency
(f) After centering: Breakdown of N10
by class match/mismatch between
objects and neighbors
Figure 2: Reuters Transcribed data.
and move the origin more actively towards hub ob-
jects in the dataset, rather than towards the data cen-
troid. To this end, we consider weighted centering,
a variation of centering in which each object is asso-
ciated with a weight, and the origin is shifted to the
weighted mean of the data. Specifically, we define
the weight of an object as the sum of the similarities
(inner products) between the object and all objects,
regarding this sum as the index of how likely the ob-
ject can be a hub.
6.1 Weighted centering
In weighted centering, we associate weight wi to
each object i in the dataset, and move the origin to
the weighted centroid
x?weighted =
n?
i=1
wixi
where
?n
i=1 wi = 1 and 0 ? wi ? 1 for i = 1, . . . , n.
Thus, object x is mapped to a new feature vector
xweighted = x ? x?weighted = x ?
n?
i=1
wixi.
Notice that the original centering formula (2) is re-
covered by letting wi = 1/n for all i = 1, . . . , n.
Weighted centering can also be kernelized by us-
ing the weighted centering matrix H(w) = I ? 1wT
in place of H in Eq. (3). The resulting Gram matrix
is
Kweighted = H(w)KH(w)T. (10)
6.2 Similarity-dependent weighting
To move the origin towards hubs more aggressively,
we place more weights on objects that are more
likely to become hubs. This likelihood is estimated
by the similarity of individual objects to all objects
in the data set.
619
Let di be the sum of the similarity between object
xi and all objects in the dataset. So,
di =
n?
j=1
?xi, x j? = n ?xi,
1
n
n?
j=1
x j?.
As seen from the last equation, di is proportional to
the similarity (inner product) between object xi and
the data centroid.
Now we define {wi}ni=1 from {di}
n
i=1 by
wi =
d?i
?n
j=1 d
?
j
,
where ? is a parameter controlling how much we
emphasize the effect of di. Setting ? = 0 results in
wi = 1 for every i, and hence is equivalent to normal
centering. When ? > 0, weighted centering moves
the origin closer to the objects with a large di than
normal centering would.
7 Experiments
We evaluated the effect of centering in two natural
language tasks: word sense disambiguation (WSD)
and document classification. We are interested in
whether hubs are actually reduced after centering,
and whether the performance of kNN classification
is improved.
Throughout this section, K denotes cosine simi-
larity matrix; i.e., inner product of feature vectors
normalized to unit length; Kcent denotes the cen-
tered similarity matrix computed by Eq. (3) from K;
Kweighted denotes its hubness weighted variant given
by Eq. (10). Depending on context, these symbols
are also used to denote kNN classifiers using respec-
tive similarity measures.
For comparison, we also tested two recently pro-
posed approaches to hub reduction: transformation
of the base similarity measure (in our case, K) by
Mutual Proximity (Schnitzer et al, 2012)2, and the
one (Suzuki et al, 2012) based on graph Laplacian
kernels. Since the Laplacian kernels are defined for
graph nodes, we computed them by taking the co-
sine similarity matrix K as the weighted adjacency
(affinity) matrix of a graph. For Laplacian kernels,
2We used the Matlab script downloaded from http://www.
ofai.at/?dominik.schnitzer/mp/.
we computed both the regularized Laplacian ker-
nel (Chebotarev and Shamis, 1997; Smola and Kon-
dor, 2003) with several parameter values, as well as
the commute-time kernel (Saerens et al, 2004), but
present only the best results among these kernels.
7.1 Word sense disambiguation
7.1.1 Task and dataset
In the WSD experiment, we used the dataset for
the Senseval-3 English Lexical Sample (ELS) task
(Mihalcea et al, 2004). It is a collection of sen-
tences containing 57 polysemous words, and each
of these sentences is annotated with a gold standard
sense of the target word. The goal of the ELS task
is to build a classifier for each target word, which,
given a context around the word, predicts a sense
from the known set of senses.
We used a basic bag-of-words representation for
the context surrounding a target word (Mihalcea,
2004; Navigli, 2009). A context is thus represented
as a high-dimensional feature vector holding the tf-
idf weighted frequency of words3 in context.
7.1.2 Compared methods
We applied kNN classification using cosine sim-
ilarity K, and its four transformed similarity mea-
sures: centered similarity Kcent, its weighted vari-
ant Kweighted, Mutual Proximity and graph Laplacian
kernels. The sense of a test object was predicted by
voting from the k training objects most similar to the
test object, as measured by the respective similarity
measures.
We used leave-one-out cross validation within the
training data to tune neighborhood size k for the
kNN classification and the voting scheme, i.e., ei-
ther (unweighted) majority vote, or weighted vote in
which votes from individual objects are weighted by
their similarity score to the test objects. We also se-
lected parameter ? in Kweighted and the best graph
Laplacian kernel among the regularized Laplacian
and commute time kernels using the training data.
7.1.3 Evaluation
We computed two indices for each similarity mea-
sure: (i) skewness of the N10 distribution to evaluate
3We removed stop words listed in the on-line appendix of
(Lewis et al, 2004).
620
Method F1 score Skewness
K 60.3 4.55
Kcent 64.0 1.19
Kweighted 64.8 1.02
Mutual Proximity 63.0 1.00
Graph Laplacian 61.2 4.51
GAMBL (Decadt et al, 2004) 64.5 ?
Table 1: WSD results: Macro-averaged F1 score (points)
of the compared methods (larger is better) and empirical
skewness of the N10 distribution for each similarity mea-
sure (smaller is better).
the emergence of hubs, and (ii) macro-averaged F1
score to evaluate the classification performance.
Skewness To evaluate the degree of hub emer-
gence for each similarity measure, we followed
(Radovanovic? et al, 2010a) and counted Nk(x), the
number of times object x occurs in the kNN lists
of other objects in the dataset (we fix k = 10 be-
low). The emergence of hubs in a dataset can then
be quantified with skewness, defined as follows:
S Nk =
E
[(
Nk ? ?Nk
)3
]
?3Nk
.
In this equation, E[ ? ] denotes expectation, and ?Nk
and ?Nk are the mean and the standard deviation of
the Nk distribution, respectively.
When hubs exist in a dataset, the distribution of
Nk is expected to skew to the right, and yields a large
S Nk (Radovanovic? et al, 2010a). In other words,
similarity measures that yield smaller S Nk are more
desirable in terms of hub reduction.
Skewness can only be computed for each dataset,
and in the WSD task, each target word has its own
dataset. Hence we computed the skewness S N10 for
each word and then took average.
Macro-averaged F1 score Classification perfor-
mance was measured by the F1 score macro-
averaged over all the 57 target words in the Senseval-
3 ELS dataset. The standard Senseval-3 ELS scor-
ing method is based on micro average, but we used
macro average to make the evaluation consistent
with skewness computation, which, as mentioned
above, can only be computed for each dataset (i.e.,
word).
Dataset #classes #objects #features
Reuters Transcribed 10 201 2730
Mini Newsgroups 20 2000 8811
Table 2: Document classification datasets: Number of
classes, data size, and number of features.
7.1.4 Result
Table 1 shows the F1 scores and the skewness of
the N10 distributions, macro averaged over the 57
target words. The table also includes the macro-
averaged F1 score4 of the GAMBL system, the best
memory-based system participated in the Senseval-
3 ELS task. Note however that GAMBL uses more
elaborate features (e.g., part-of-speech of words)
than just a plain bag-of-words used by other methods
in this comparison. GAMBL also employs complex
post-processing of the kNN outputs.
After centering (Kcent and Kweighted) skewness
became markedly smaller than that of the non-
centered cosine K. F1 score also improved with the
decrease in skewness. In particular, weighted cen-
tering (Kweighted) slightly outperformed GAMBL,
though the difference was small. Recall however
that Kcent and Kweighted only use naive bag-of-words
features, unlike GAMBL.
7.2 Document classification
7.2.1 Task and dataset
Two multiclass document classification datasets
were used: Reuters Transcribed and Mini News-
groups, distributed at http://archive.ics.uci.edu/ml/.
The properties of the datasets are summarized in Ta-
ble 2.
7.2.2 Evaluation
The performance was evaluated by the F1 score
(equivalent to accuracy in this task) of prediction us-
ing leave-one-out cross validation, due to the limited
number of documents.
7.2.3 Compared methods
We used the cosine similarity as the base sim-
ilarity matrix (K). The centered similarity matrix
(Kcent) and its weighted variant (Kweighted), Mutual
4The macro-averaged F1 of GAMBL was calculated from
the per-word F1 scores listed in Table 1 of (Decadt et al, 2004).
621
Method F1 score Skewness
K 56.7 1.61
Kcent 61.2 0.11
Kweighted 60.2 0.04
Mutual Proximity 60.2 ?0.10
Graph Laplacian 57.2 0.37
(a) Reuters Transcribed
Method F1 score Skewness
K 76.5 4.37
Kcent 79.0 1.56
Kweighted 79.4 1.68
Mutual Proximity 79.0 0.49
Graph Laplacian 77.6 2.13
(b) Mini Newsgroups
Table 3: Document classification results: F1 score (%)
(larger is better) and skewness of the N10 distribution for
each similarity measure (smaller is better).
Proximity, and graph Laplacian based kernels were
computed from K.
kNN classification was done in a standard way:
The class of object x is predicted by the majority
vote from k = 10 objects most similar to x, mea-
sured by a specified similarity measure. The param-
eter k for the kNN classification, the voting scheme
(i.e., either unweighted or weighted majority vote),
? in Kweighted, and the best graph Laplacian kernel
were selected by leave-one-out cross validation.
7.2.4 Result
Table 3 shows the F1 score and the skewness of
the N10 distribution of the respective methods in
document classification. Centered cosine (Kcent)
outperformed uncentered cosine similarity K, and
achieved an F1 score comparable to Mutual Proxim-
ity. Weighted centering (Kweighted) further improved
F1 on the Mini Newsgroups data.
8 Conclusion
We have shown that centering similarity matrices re-
duces the emergence of hubs in the data, and conse-
quently improves the accuracy of nearest neighbor
classification. We have theoretically analyzed why
objects most similar to the mean tend to make hubs,
and also proved that centering cancels the bias in the
distribution of inner products, and thus is expected
to reduce hubs.
In WSD and document classification tasks, kNN
classifiers showed much better performance with
centered similarity measures than non-centered
ones. Weighted centering shifts the origin towards
hubs more aggressively, and further improved the
classification performance in some cases.
In future work, we plan to exploit the class distri-
bution in the dataset to make more effective similar-
ity measures; notice that the hubness weighted cen-
tering of Section 6 is an unsupervised method, in the
sense that class information was not used for deter-
mining weights. We will investigate if more effec-
tive weighting can be done using this information.
Acknowledgments
We thank anonymous reviewers for helpful com-
ments.
References
Arindam Banerjee, Inderjit S. Dhillon, Joydeep Ghosh,
and Suvrit Sra. 2005. Clustering on the unit hyper-
sphere using von Mises-Fisher distributions. Journal
of Machine Learning Research, 6:1345?1382.
P. Yu. Chebotarev and E. V. Shamis. 1997. The matrix-
forest theorem and measuring relations in small social
groups. Automation and Remote Control, 58(9):1505?
1514.
Yihua Chen, Eric K. Garcia, Maya R. Gupta, Ali Rahimi,
and Luca Cazzanti. 2009. Similarity-based classifi-
cation: Concepts and algorithms. Journal of Machine
Learning Research, 10:747?776.
Bart Decadt, Ve?ronique Hoste, Walter Daelemans, and
Antal Van den Bosch. 2004. GAMBL, genetic algo-
rithm optimization of memory-based WSD. In Rada
Mihalcea and Phil Edmonds, editors, Proceedings of
the 3rd International Workshop on the Evaluation of
Systems for the Semantic Analysis of Text (Senseval-
3), pages 108?112.
L. Eriksson, E. Johansson, N. Kettaneh-Wold, J. Trygg,
C. Wikstro?m, and S. Wold. 2006. Multi- and
Megavariate Data Analysis, Part 1, Basic Principles
and Applications. Umetrics, Inc.
Katrin Erk and Sebastian Pado?. 2008. A structured vec-
tor space model for word meaning in context. In Pro-
ceedings of the 2008 Conference on Empirical Meth-
ods in Natural Language Processing (EMNLP ?08),
pages 897?906, Honolulu, Hawaii, USA.
Douglas H. Fisher and Hans-Joachim Lenz, editors.
1996. Learning from Data: Artificial Intelligence and
622
Statistics V: Workshop on Artificial Intelligence and
Statistics. Lecture Notes in Statistics 112. Springer.
Ruixin Guo and Sounak Chakraborty. 2010. Bayesian
adaptive nearest neighbor. Statistical Analysis and
Data Mining, 3(2):92?105.
Daniel Jurafsky and James H. Martin. 2008. Speech and
Language Processing. Prentice Hall, 2nd edition.
David D. Lewis, Yiming Yang, Tony G. Rose, and Fan
Li. 2004. RCV1: a new benchmark collection for text
categorization research. Journal of Machine Learning
Research, 5:361?397.
Colin Mallows. 1991. Another comment on O?Cinneide.
The American Statistician, 45(3):257.
K. V. Mardia and P. Jupp. 2000. Directional Statistics.
John Wiley and Sons, 2nd edition.
K. V. Mardia, J. T. Kent, and J. M. Bibby. 1979. Multi-
variate Analysis. Academic Press.
Brij M. Masand, Gordon Linoff, and David L. Waltz.
1992. Classifying news stories using memory based
reasoning. In Proceedings of the 15th Annual Interna-
tional ACM SIGIR Conference on Research and De-
velopment in Information Retrieval (SIGIR ?92), pages
59?65.
Rada Mihalcea, Timothy Chklovski, and Adam Kilgar-
riff. 2004. The Senseval-3 English lexical sample
task. In Rada Mihalcea and Phil Edmonds, editors,
Proceedings of the 3rd International Workshop on the
Evaluation of Systems for the Semantic Analysis of
Text (Senseval-3), pages 25?28, Barcelona, Spain.
Rada Mihalcea. 2004. Co-training and self-training for
word sense disambiguation. In Hwee Tou Ng and
Ellen Riloff, editors, Proceedings of the 8th Confer-
ence on Computational Natural Language Learning
(CoNLL ?04), pages 33?40, Boston, Massachusetts,
USA.
Jeff Mitchell and Mirella Lapata. 2008. Vector-based
models of semantic composition. In Proceedings of
the 46th Annual Meeting of the Association of Compu-
tational Linguistics: Human Language Technologies
(ACL ?08), pages 236?244, Columbus, Ohio, USA.
Roberto Navigli. 2009. Word sense disambiguation: A
survey. ACM Computing Surveys, 41:10:1?10:69.
Ali Mustafa Qamar, E?ric Gaussier, Jean-Pierre Cheval-
let, and Joo-Hwee Lim. 2008. Similarity learning for
nearest neighbor classification. In Proceedings of the
8th International Conference on Data Mining (ICDM
?08), pages 983?988, Pisa, Italy.
Milos? Radovanovic?, Alexandros Nanopoulos, and Mir-
jana Ivanovic?. 2010a. Hubs in space: Popular nearest
neighbors in high-dimensional data. Journal of Ma-
chine Learning Research, 11:2487?2531.
Milos? Radovanovic?, Alexandros Nanopoulos, and Mir-
jana Ivanovic?. 2010b. On the existence of obstinate
results in vector space models. In Proceedings of the
33rd Annual International ACM SIGIR Conference on
Research and Development in Information Retrieval
(SIGIR ?10), pages 186?193, Geneva, Switzerland.
Marco Saerens, Franc?ois Fouss, Luh Yen, and Pierr
Dupont. 2004. The principal components analysis
of graph, and its relationships to spectral clustering.
In Proceedings of the 15th European Conference on
Machine Learning (ECML ?04), Lecture Notes in Ar-
tificial Intelligence 3201, pages 371?383, Pisa, Italy.
Springer.
Dominik Schnitzer, Arthur Flexer, Markus Schedl, and
Gerhard Widmer. 2012. Local and global scaling re-
duce hubs in space. Journal of Machine Learning Re-
search, 13:2871?2902.
Hinrich Schu?tze. 1998. Automatic word sense discrimi-
nation. Computational Linguistics, 24:97?123.
Alexander J. Smola and Risi Kondor. 2003. Kernels and
regularization on graphs. In Learning Theory and Ker-
nel Machines: 16th Annual Conference on Learning
Theory and 7th Kernel Workshop, Proceedings, Lec-
ture Notes in Artificial Intelligence 2777, pages 144?
158. Springer.
Anders S?gaard. 2011. Semisupervised condensed near-
est neighbor for part-of-speech tagging. In Proceed-
ings of the 49th Annual Meeting of the Association
for Computational Linguistics (ACL ?11), pages 48?
52, Portland, Oregon, USA.
Ikumi Suzuki, Kazuo Hara, Masashi Shimbo, Yuji Mat-
sumoto, and Marco Saerens. 2012. Investigating the
effectiveness of Laplacian-based kernels in hub reduc-
tion. In Proceedings of the 26th AAAI Conference on
Artificial Intelligence (AAAI-12), pages 1112?1118,
Toronto, Ontario, Canada.
Stefan Thater, Hagen Fu?rstenau, and Manfred Pinkal.
2010. Contextualizing semantic representations us-
ing syntactically enriched vector models. In Proceed-
ings of the 48th Annual Meeting of the Association for
Computational Linguistics (ACL ?10), pages 948?957,
Uppsala, Sweden.
Jigang Wang, Predrag Neskovic, and Leon N. Cooper.
2006. Neighborhood size selection in the k-nearest-
neighbor rule using statistical confidence. Pattern
Recognition, 39(3):417?423.
Kilian Q. Weinberger and Lawrence K. Saul. 2009. Dis-
tance metric learning for large margin nearest neighbor
classification. Journal of Machine Learning Research,
10:207?244.
Yiming Yang and Xin Liu. 1999. A re-examination of
text categorization methods. In Proceedings of the
22nd Annual International ACM SIGIR Conference on
Research and Development in Information Retrieval
(SIGIR ?99), pages 42?49, Berkeley, California, USA.
623
