Urdu and the Parallel Grammar Project
Miriam Butt
Cent. for Computational Linguistics
UMIST
PO Box 88
Manchester M60 1QD GB
mutt@csli.stanford.edu
Tracy Holloway King
Palo Alto Research Center
3333 Coyote Hill Rd.
Palo Alto, CA 94304 USA
thking@parc.com
Abstract
We report on the role of the Urdu grammar in the
Parallel Grammar (ParGram) project (Butt et al,
1999; Butt et al, 2002).1 The ParGram project was
designed to use a single grammar development plat-
form and a unified methodology of grammar writ-
ing to develop large-scale grammars for typologi-
cally different languages. At the beginning of the
project, three typologically similar European gram-
mars were implemented. The addition of two Asian
languages, Urdu and Japanese, has shown that the
basic analysis decisions made for the European lan-
guages can be applied to typologically distinct lan-
guages. However, the Asian languages required the
addition of a small number of new standard analy-
ses to cover constructions and analysis techniques
not found in the European languages. With these ad-
ditional standards, the ParGram project can now be
applied to other typologically distinct languages.
1 Introduction
In this paper, we report on the role of the Urdu
grammar in the Parallel Grammar (ParGram) project
(Butt et al, 1999; Butt et al, 2002). The ParGram
project originally focused on three closely related
European languages: English, French, and German.
Once grammars for these languages were estab-
lished, two Asian languages were added: Japanese
and Urdu.2 Both grammars have been successfully
integrated into the project. Here we discuss the Urdu
grammar and what special challenges it brought to
the ParGram project. We are pleased to report that
creating an Urdu grammar within the ParGram stan-
dards has been possible and has led to typologically
useful extensions to the project.
The ParGram project uses the XLE parser
1We would like to thank Mary Dalrymple, Ron Kaplan, Hi-
roshi Masuichi, and Tomoko Ohkuma for their comments.
2Norwegian was also added at this time.
and grammar development platform (Maxwell
and Kaplan, 1993) to develop deep grammars
for six languages. All of the grammars use the
Lexical-Functional Grammar (LFG) formalism
which produces c(onstituent)-structures (trees)
and f(unctional)-structures (AVMs) as syntactic
analyses.
LFG assumes a version of Chomsky?s Universal
Grammar hypothesis, namely that all languages are
governed by similar underlying structures. Within
LFG, f-structures encode a language universal level
of analysis, allowing for cross-linguistic parallelism.
The ParGram project aims to test the LFG formal-
ism for its universality and coverage limitations and
to see how far parallelism can be maintained across
languages. Where possible, the analyses produced
for similar constructions in each language are paral-
lel. This parallelism requires a standard for linguistic
analysis. In addition, the LFG theory itself limits the
set of possible analyses, thus restricting the possible
analyses to choose from. The standardization of the
analyses has the computational advantage that the
grammars can be used in similar applications, and
it can simplify cross-language applications (Frank,
1999).
The conventions developed within the ParGram
grammars are extensive. The ParGram project dic-
tates not only the form of the features used in the
grammars, but also the types of analyses that are
chosen for constructions. In addition, the XLE plat-
form necessarily restricts how the grammars can be
written. In all cases, the Urdu grammar has success-
fully, and straightforwardly, incorporated the stan-
dards that were originally designed for the European
languages. In addition, it has contributed to the for-
mulation of new standards of analysis. Below we
discuss several aspects of this: morphology, lexicon,
and grammar development for the Urdu grammar
within the ParGram project.
2 Morphology
The grammars in the ParGram project depend on
finite-state morphologies as input (Beesley and
Karttunen, 2002). Without this type of resource, it
is difficult to build large-scale grammars, especially
for languages with substantial morphology. For
the original three languages, such morphologies
were readily available. As they had been developed
for information extraction applications instead of
deep grammar applications, there were some minor
problems, but the coverage of these morphologies
is excellent. An efficient, broad-coverage mor-
phology was also available for Japanese (Asahara
and Matsumoto, 2000) and was integrated into the
grammar. This has aided in the Japanese grammar
rapidly achieving broad coverage. It has also helped
control ambiguity because in the case of Japanese,
the morphology determines the part of speech of
each word in the string with very little ambiguity.
While some morphological analyzers al-
ready exist for Hindi,3 e.g., as part of the
tools developed at the Language Technolo-
gies Research Centre (LTRC), IIT Hyderabad
(http://www.iiit.net/ltrc/index.html), they are not
immediately compatible with the XLE grammar
development platform, nor is it clear that the
morphological analyses they produce conform to
the standards and methods developed within the
ParGram project. As such, part of the Urdu project
is to build a finite-state morphology that will serve
as a resource to the Urdu grammar and could be
used in other applications.
The development of the Urdu morphology in-
volves a two step process. The first step is to de-
termine the morphological class of words and their
subtypes in Urdu. Here we hope to use existing re-
sources and lexicons. The morphological paradigms
which yield the most efficient generalizations from
an LFG perspective must be determined. Once the
basic paradigms and morphological classes have
been identified, the second step is to enter all words
in the language with their class and subtype informa-
tion. These steps are described below. Currently we
are working on the first step; grant money is being
sought for further development.
The finite-state morphologies used in the Par-
Gram project associate surface forms of words with
a canonical form (a lemma) and a series of morpho-
logical tags that provide grammatical information
3An on-line morphological analyzer is available at:
http://ccat.sas.upenn.edu/plc/tamilweb/hindi.html
about that form. An example for English is shown
in (1) and for Urdu in (2).
(1) pushes: push +Verb +Pres +3sg
push +Noun +Pl
(2) bOlA bOl +Verb +Perf +Masc +Sg
(1) states the English surface form pushes can either
be the third singular form of the verb push or the plu-
ral of the noun push. (2) states that the Urdu surface
form bOlA is the perfect masculine singular form of
the verb bOl.
The first step of writing a finite-state morphology
for Urdu involves determining which tags are as-
sociated with which surface forms. As can be seen
from the above examples, determining the part of
speech (e.g., verb, noun, adjective) is not enough for
writing deep grammars. For verbs, tense, aspect, and
agreement features are needed. For nouns, number
and gender information is needed, as well as infor-
mation as to whether it is a common or proper noun.
Furthermore, for a number of problematic morpho-
logical phenomena such as oblique inflection on
nominal forms or default agreement on verbs, the
most efficient method of analyzing this part of the
morphology-syntax interface must be found (Butt
and Kaplan, 2002).
After having determined the tag ontology, the pat-
terns of how the surface forms map to the stem-tag
sets must be determined. For example, in English the
stem-tag set dog +Noun +Pl corresponds to the sur-
face form dogs in which an s is added to the stem,
while box +Noun +Pl corresponds to boxes in which
an es is added. At this point in time, the basic tag set
for Urdu has been established. However, the mor-
phological paradigms that correspond to these tag
combinations have not been fully explored.
Once the basic patterns are determined, the sec-
ond stage of the process begins. This stage involves
greatly increasing the coverage of the morphology
by adding in all the stems in Urdu and marking them
for which set of tags and surface forms they appear
with. This is a very large task. However, by using
frequency lists for the language and existing lexi-
cons,4 the most common words can be added first to
obtain a major gain in coverage.
In addition, a guesser can be added to guess words
that the morphology does not yet recognize (Chanod
4A web search on Hindi dictionary results in several
promising sites.
and Tapanainen, 1995). This guessing is based on
the morphological form of the surface form. For ex-
ample, if a form ending in A is encountered and not
recognized, it could be considered a perfect mascu-
line singular form, similar to bOlA in (2).
3 Lexicon
One advantage of the fact that the XLE system in-
corporates large finite-state morphologies is that the
lexicons for the languages can then be relatively
small. This is because lexicons are not needed for
words whose syntactic lexical entry can be deter-
mined based on their morphological analysis. This is
particularly true for nouns, adjectives, and adverbs.
Consider the case of nouns. The Urdu morphol-
ogy provides the following analysis for the proper
noun nAdyA.
(3) nAdyA +Noun +Name +Fem
The tags provide the information that it is a noun, in
particular a type of proper noun (Name), and is fem-
inine. The lexical entries for the tags can then pro-
vide the grammar with all of the features that it needs
to construct the analysis of nAdyA; this resulting f-
structure analysis is seen in Figures 2 and 4. Thus,
nAdyA itself need not be in the lexicon of the gram-
mar because it is already known to the morphologi-
cal analyzer.
Items whose lexical entry cannot be predicted
based on the morphological tags need explicit lex-
ical entries. This is the case for items whose subcat-
egorization frames are not predictable, primarily for
verbs. Currently, the Urdu verb lexicon is hand con-
structed and only contains a few verbs, generally one
for each subcategorization frame for use in grammar
testing. To build a broad-coverage Urdu grammar, a
more complete verb lexicon will be needed. To pro-
vide some idea of scale, the current English verb lex-
icon contains entries for 9,652 verbs; each of these
has an average of 2.4 subcategorization frames; as
such, there are 23,560 verb-subcategorization frame
pairs. However, given that Urdu employs produc-
tive syntactic complex predicate formation for much
of its verbal predication, the verb lexicon for Urdu
will be smaller than its English counterpart. On the
other hand, writing grammar rules for the productive
combinatorial possibilities between adjectives and
verbs (e.g., sAf karnA ?clean do?=?clean?), nouns and
verbs (e.g., yAd karnA ?memory do?=?remember?)
and verbs and verbs (e.g., kHA lEnA ?eat take?=?eat
up?) is anticipated to require significant effort.
There are a number of ways to obtain a broad-
coverage verb lexicon. One is to extract the informa-
tion from an electronic dictionary. This does not ex-
ist for Urdu, as far as we are aware. Another is to ex-
tract it from Urdu corpora. Again, these would have
to be either collected or created as part of the gram-
mar development project. A final way is to enter the
information by hand, depending on native speaker
knowledge and print dictionaries; this option is very
labor intensive. Fortunately, work is being done on
verb subcategorization frames in Hindi.5 We plan to
incorporate this information into the Urdu grammar
verb lexicon.
4 Grammar
The current Urdu grammar is relatively small, com-
prising 25 rules (left-hand side categories) which
compile into a collection of finite-state machines
with 106 states and 169 arcs. The size of the other
grammars in the ParGram project are shown in (4)
for comparison.
(4)
Language Rules States Arcs
German 444 4883 15870
English 310 4935 13268
French 132 1116 2674
Japanese 50 333 1193
Norwegian 46 255 798
Urdu 25 106 169
It is our intent to drastically expand the Urdu gram-
mar to provide broad-coverage on standard (gram-
matical, written) texts. The current size of the Urdu
grammar is not a reflection of the difficulty of the
language, but rather of the time put into it. Like the
Japanese and Norwegian grammars, it is less than
two years in development, compared with seven
years6 for the English, French, and German gram-
mars. However, unlike the Japanese and Norwe-
gian grammars, there has been no full-time gram-
mar writer on the Urdu grammar. Below we discuss
the Urdu grammar analyses and how they fit into the
ParGram project standardization requirements.
Even within a linguistic formalism, LFG for Par-
Gram, there is often more than one way to ana-
5One significant effort is the Hindi Verb Project run by Prof.
Alice Davison at the University of Iowa; further information is
available via their web site.
6Much of the effort in the initial years went into developing
the XLE platform and the ParGram standards. Due to these ini-
tial efforts, new grammars can be developed more quickly.
lyze a construction. Moreover, the same theoreti-
cal analysis may have different possible implemen-
tations in XLE. These solutions often differ in ef-
ficiency or conceptual simplicity. Whenever possi-
ble, the ParGram grammars choose the same anal-
ysis and the same technical solution for equivalent
constructions. This was done, for example, with im-
peratives. Imperatives are assigned a null pronomi-
nal subject within the f-structure and a feature indi-
cating that they are imperatives.
Parallelism, however, is not maintained at the cost
of misrepresenting the language. Situations arise in
which what seems to be the same construction in
different languages cannot have the same analysis.
An example of this is predicate adjectives (e.g., It
is red.). In English, the copular verb is considered
the syntactic head of the clause, with the pronoun
being the subject and the predicate adjective be-
ing an XCOMP. However, in Japanese, the adjective
is the main predicate, with the pronoun being the
subject. As such, these constructions receive non-
parallel analyses.
Urdu contains several syntactic constructions
which find no direct correlate in the European
languages of the ParGram project. Examples are
correlative clauses (these are an old Indo-European
feature which most modern European languages
have lost), extensive use of complex predication,
and rampant pro-drop. The ability to drop argu-
ments is not correlated with agreement or case
features in Urdu, as has been postulated for Italian,
for example. Rather, pro-drop in Urdu correlates
with discourse strategies: continuing topics and
known background information tend to be dropped.
Although the grammars do not encode discourse
information, the Japanese grammar analyzes pro-
drop effectively via technical tools made available
by the grammar development platform XLE. The
Urdu grammar therefore anticipates no problems
with pro-drop phenomena.
In addition, many constructions which are stal-
warts of English syntax do not exist in Asian lan-
guages. Raising constructions with seem, for exam-
ple, find no clear correlate in Urdu: the construction
is translated via a psych verb in combination with
a that-clause. This type of non-correspondence be-
tween European and South Asian languages raises
challenges of how to determine parallelism across
analyses. A similar example is the use of expletives
(e.g., There is a unicorn in the garden.) which do not
exist in Urdu.
4.1 Existing Analysis Standards
While Urdu contains syntactic constructions which
are not mirrored in the European languages, it shares
many basic constructions, such as sentential com-
plementation, control constructions, adjective-noun
agreement, genitive specifiers, etc. The basic analy-
sis of these constructions was determined in the ini-
tial stage of the ParGram project in writing the En-
glish, French, and German grammars. These analy-
sis decisions have not been radically changed with
the addition of two typologically distinct Asian lan-
guages, Urdu and Japanese.
The parallelism in the ParGram project is pri-
marily across the f-structure analyses which encode
predicate-argument structure and other features that
are relevant to syntactic analysis, such as tense and
number.7 A sample analysis for the sentence in (5)
is shown in Figures 1 and 2.
(5) nAdyA kA kuttA AyA
Nadya Gen.M.Sg dog.Nom come-Perf.M.Sg
?Nadya?s dog came.?
The Urdu f-structure analysis of (5) is similar to that
of its English equivalent. Both have a PRED for the
verb which takes a SUBJ argument at the top level
f-structure. This top level structure also has TNS-
ASP features encoding tense and aspect information,
as well as information about the type of sentence
(STMT-TYPE) and verb (VTYPE); these same fea-
tures are found in the English structure. The analy-
sis of the subject is also the same, with the posses-
sive being in the SPEC POSS and with features such
as NTYPE, NUM, and PERS. The sentence in (5) in-
volves an intransitive verb and a noun phrase with a
possessive; these are both basic constructions whose
analysis was determined before the Urdu gram-
mar was written. Yet, despite the extensive differ-
ences between Urdu and the European languages?
indeed, the agreement relations between the genitive
and the head noun are complex in Urdu but not in
English?there was no problem using the standard
analysis for the Urdu construction.
4.2 New Analysis Standards
Analyses of new constructions have been added for
constructions found in the new project languages.
7The c-structures are less parallel in that the languages differ
significantly in their word orders. Japanese and Urdu are SOV
while English is SVO. However, the standards for naming the
nodes in the trees and the types of constituents formed in the
trees, such as NPs, are similar.
CS 1: ROOT
S
KP
NP
KPposs
NP
N
nAdyA
Kposs
kA
N
kuttA
VCmain
Vmain
V
AyA
Figure 1: C-structure tree for (5)
"nAdyA kA kuttA AyA"
?A<[14:kutt]>?PRED
?kutt?PRED
massGRAINNTYPE
?Nadya?PRED
namePROPERNTYPE
+SPECIFIC
CASE gen, GEND fem, NMORPH nom, NUM sg, PERS 30
POSSSPEC
CASE nom, GEND masc, NUM sg, PERS 314
SUBJ
perfASPECT
inflMTYPEVMORPH
PASSIVE ,  decl, VFORM perf, VTYPE unacc34
Figure 2: F-structure AVM for (5)
These analyses have not only established new stan-
dards within the ParGram project, but have also
guided the development of the XLE grammar de-
velopment platform. Consider the analysis of case
in Urdu. Although the features used in the analysis
of case were sufficient for Urdu, there was a prob-
lem with implementing it. In Urdu, the case mark-
ers constrain the environments in which they occur
(Butt and King, to appear). For example, the ergative
marker ne only occurs on subjects. However, not all
subjects are ergative. To the contrary, subjects can
occur in the ergative, nominative, dative, genitive,
and instrumental cases. Similarly, direct objects can
be marked with (at least) an accusative or nomina-
tive, depending on the semantics of the clause. Min-
imal pairs such as in (6) for subjects and (7) for ob-
jects suggest a constructive (Nordlinger, 1998) ap-
proach to case.
(6) a. rAm kH ?As-A
Ram.Nom cough-Perf.M.Sg
?Ram coughed.?
b. rAm nE kH ?As-A
Ram=Erg cough-Perf.M.Sg
?Ram coughed (purposefully).?
(7) a. nAdyA nE gArI calAyI
Nadya=Erg car.Nom drive-Perf.F.Sg
hai
be.Pres.3.Sg
?Nadya has driven a car.?
b. nAdyA nE gArI kO calAyA
Nadya=Erg car=Acc drive-Perf.M.Sg
hai
be.Pres.3.Sg
?Nadya has driven the car.?
We therefore designed the lexical entries for the case
markers so that they specify information about what
grammatical relations they attach to and what se-
mantic information is needed in the clausal analysis.
The lexical entry for the ergative case, for example,
states that it applies to a subject.
These statements require inside-out functional
uncertainty (Kaplan, 1988) which had not been used
in the other grammars. Inside-out functional uncer-
tainty allows statements about the f-structure that
contains an item. The lexical entry for nE is shown
in (8).
(8) nE K @(CASE erg) line 1
(SUBJ ($) ? ) line 2
@VOLITION line 3
In (8), the K refers to the part of speech (a case
clitic). Line 1 calls a template that assigns the CASE
feature the value erg; this is how case is done in
the other languages. Line 2 provides the inside-out
functional uncertainty statement; it states that the f-
structure of the ergative noun phrase, referred to as
?, is inside a SUBJ. Finally, line 3 calls a template
that assigns the volitionality features associated with
ergative noun phrases. The analysis for (9) is shown
in Figures 3 and 4.
(9) nAdyA nE yassin ko mArA
Nadya=Erg Yassin=Acc hit-Perf.M.Sg
?Nadya hit Yassin.?
CS 1: ROOT
S
KP
NP
N
nAdyA
K
nE
KP
NP
N
yassin
K
kO
VCmain
Vmain
V
mArA
Figure 3: C-structure tree for (9)
"nAdyA nE yassin kO mArA"
?hit<[0:Nadya], [16:Yassin]>?PRED
?Nadya?PRED
namePROPERNTYPE
+SPECIFIC
CASE erg, GEND fem, NUM sg, PERS 30
SUBJ
?Yassin?PRED
namePROPERNTYPE
+SPECIFIC
CASE acc, GEND masc, NUM sg, PERS 316
OBJ
perfASPECT
inflMTYPEVMORPH
GEND masc, NUM sg, PASSIVE ,  decl, VFORM perf, VTYPE agentive32
Figure 4: F-structure AVM for (9)
There are two intesting points about this analy-
sis of case in Urdu. The first is that although the
Urdu grammar processes case differently than the
other grammars, the resulting f-structure in Figure
4 is similar to its counterparts in English, German,
etc. English would have CASE nom on the subject in-
stead of erg, but the remaining structure is the same:
the only indication of case is the CASE feature. The
second point is that Urdu tested the application of
inside-out functional uncertainty to case both theo-
retically and computationally. In both respects, the
use of inside-out functional uncertainty has proven a
success: not only is it theoretically desirable for lan-
guages like Urdu, but it is also implementationally
feasible, efficiently providing the desired output.
Another interesting example of how Urdu has ex-
tended the standards of the ParGram project comes
from complex predicates. The English, French, and
German grammars do not need a complex predicate
analysis. However, as complex predicates form an
essential and pervasive part of Urdu grammar, it is
necessary to analyze them in the project. At first, we
attempted to analyze complex predicates using the
existing XLE tools. However, this proved to be im-
possible to do productively because XLE did not al-
low for the manipulation of PRED values outside of
the lexicon. Given that complex predicates in Urdu
are formed in the syntax and not the lexicon (Butt,
1995), this poses a significant problem. The syntac-
tic nature of Urdu complex predicate formation is il-
lustrated by (10), in which the two parts of the com-
plex predicate l?kh ?write? and diya ?gave? can be
separated.
(10) a. [anjum nE] [saddaf kO] [ciTTHI]
Anjum.F=Erg Saddaf.F=Dat note.F.Nom
[likHnE dI]
write-Inf.Obl give-Perf.F.Sg
?Anjum let Saddaf write a note.?
b. anjum nE dI saddaf kO [ciTTHI likHnE]
c. anjum nE [ciTTHI likHnE] saddaf kO dI
The manipulation of predicational structures in the
lexicon via lexical rules (as is done for the English
passive, for example), is therefore inadequate for
complex predication. Based on the needs of the Urdu
grammar, XLE has been modified to allow the anal-
ysis of complex predicates via the restriction oper-
ator (Kaplan and Wedekind, 1993) in conjunction
with predicate composition in the syntax. These new
tools are currently being tested by the implementa-
tion of the new complex predicates analysis.
5 Script
One issue that has not been dealt with in the Urdu
grammar is the different script systems used for
Urdu and Hindi. As seen in the previous discussions
and the Figures, transcription into Latin ASCII is
currently used by the Urdu grammar. This is not a
limitation of the XLE system: the Japanese grammar
has successfully integrated Japanese Kana and Kanji
into their grammar.
The approach taken by the Urdu grammar is dif-
ferent from that of the Japanese, largely because two
scripts are involved. The Urdu grammar uses the
ASCII transcription in the finite-state morphologies
and the grammar. At a future date, a component will
be built onto the grammar system that takes Urdu
(Arabic) and Hindi (Devanagari) scripts and tran-
scribes them for use in the grammar. This compo-
nent will be written using finite-state technology and
hence will be compatible with the finite-state mor-
phology. The use of ASCII in the morphology al-
lows the same basic morphology to be used for both
Urdu and Hindi. Samples of the scripts are seen in
(11) for Urdu and (12) for Hindi.
(11)
(12)
6 Conclusion
The ParGram project was designed to use a single
grammar development platform and a unified
methodology of grammar writing to develop
large-scale grammars for typologically different
languages. At the beginning of the project, three
typologically similar European grammars were
used to test this idea. The addition of two Asian
languages, has shown that the basic analysis de-
cisions made for the European languages can be
applied to typologically distinct languages. How-
ever, the Asian languages required the addition of a
few new standard analyses to the project to cover
constructions and analysis techniques not found
in the European languages. With this new set of
standards, the ParGram project can now be applied
to other typologically distinct languages.
The parallelism between the grammars in the Par-
Gram project can be exploited in applications using
the grammars: the fewer the differences, the simpler
a multi-lingual application can be. For example, a
translation system that uses the f-structures as input
and output can take advantage of the fact that similar
constructions have the same analysis (Frank, 1999).
The standardization also aids further grammar de-
velopment efforts. Many of the basic decisions about
analyses and formalism have already been made in
the project. Thus, the grammar writer for a new lan-
guage can use existing technology to bootstrap a
grammar for the new language and can parse equiv-
alent constructions in the existing languages to see
how to analyze a construction. This allows the gram-
mar writer to focus on more difficult constructions
not yet encountered in the existing grammars.
References
Masayuki Asahara and Yuji Matsumoto. 2000. Ex-
tended models and tools for high-performance
part-of-speech tagger. In Proceedings of COL-
ING.
Kenneth Beesley and Lauri Karttunen. 2002.
Finite-State Morphology: Xerox Tools and
Techniques. Cambridge University Press. To
Appear.
Miriam Butt and Ron Kaplan. 2002. The mor-
phology syntax interface in LFG. Presented at
LFG02, Athens, Greece; to appear in the proceed-
ings (CSLI Publications).
Miriam Butt and Tracy Holloway King. to appear.
The status of case. In Veneeta Dayal and Anoop
Mahajan, editors, Clause Structure in South Asian
Languages. Kluwer.
Miriam Butt, Tracy Holloway King, Mar??a-Eugenia
Nin?o, and Fre?de?rique Segond. 1999. A Grammar
Writer?s Cookbook. CSLI Publications.
Miriam Butt, Helge Dyvik, Tracy Holloway King,
Hiroshi Masuichi, and Christian Rohrer. 2002.
The parallel grammar project. In Proceedings of
COLING 2002. Workshop on Grammar Engi-
neering and Evaluation.
Miriam Butt. 1995. The Structure of Complex Pred-
icates in Urdu. CSLI Publications.
Jean-Pierrre Chanod and Pasi Tapanainen. 1995.
Creating a tagset, lexicon, and guesser for a
French tagger. In Proceedings of the ACL SIG-
DAT Workshop: From Texts To Tags. Issues in
Multilingual Language Analysis, pages 58?64.
Anette Frank. 1999. From parallel grammar devel-
opment towards machine translation. In Proceed-
ings of MT Summit VII, pages 134?142.
Ron Kaplan and Ju?rgen Wedekind. 1993. Restric-
tion and correspondence-based translation. In
Proceedings of the Sixth European Conference
of the Association for Computational Linguistics,
pages 193?202.
Ron Kaplan. 1988. Correspondences and their in-
verses. Presented at the Titisee Workshop on Uni-
fication Formalisms: Syntax, Semantics, and Im-
plementation, Titisee, Germany.
John T. Maxwell, III and Ron Kaplan. 1993. The
interface between phrasal and functional con-
straints. Computational Lingusitics, 19:571?589.
Rachel Nordlinger. 1998. Constructive Case: Evi-
dence from Australian Languages. CSLI Publica-
tions.
The Parallel Grammar Project
Miriam Butt
Cent. for Computational Linguistics
UMIST
Manchester M60 1QD GB
mutt@csli.stanford.edu
Helge Dyvik
Dept. of Linguistics
University of Bergen
N5007 Bergen NORWAY
helge.dyvik@lili.uib.no
Tracy Holloway King
Palo Alto Research Center
Palo Alto, CA 94304 USA
thking@parc.com
Hiroshi Masuichi
Corporate Research Center
Fuji Xerox Co., Ltd.
Kanagawa 259-0157, JAPAN
hiroshi.masuichi@fujixerox.co.jp
Christian Rohrer
IMS Universita?t Stuttgart
D-70174 Stuttgart GERMANY
rohrer@ims.uni-stuttgart.de
Abstract
We report on the Parallel Grammar (ParGram)
project which uses the XLE parser and grammar
development platform for six languages: English,
French, German, Japanese, Norwegian, and Urdu.1
1 Introduction
Large-scale grammar development platforms are ex-
pensive and time consuming to produce. As such, a
desideratum for the platforms is a broad utilization
scope. A grammar development platform should be
able to be used to write grammars for a wide variety
of languages and a broad range of purposes. In this
paper, we report on the Parallel Grammar (ParGram)
project (Butt et al, 1999) which uses the XLE parser
and grammar development platform (Maxwell and
Kaplan, 1993) for six languages: English, French,
German, Japanese, Norwegian, and Urdu. All of
the grammars use the Lexical-Functional Gram-
mar (LFG) formalism which produces c(onstituent)-
structures (trees) and f(unctional)-structures (AVMs)
as the syntactic analysis.
LFG assumes a version of Chomsky?s Universal
Grammar hypothesis, namely that all languages are
structured by similar underlying principles. Within
LFG, f-structures are meant to encode a language
universal level of analysis, allowing for cross-
linguistic parallelism at this level of abstraction. Al-
though the construction of c-structures is governed
1We would like to thank Emily Bender, Mary Dalrymple,
and Ron Kaplan for help with this paper. In addition, we would
like to acknowledge the other grammar writers in the Par-
Gram project, both current: Stefanie Dipper, Jean-Philippe Mar-
cotte, Tomoko Ohkuma, and Victoria Rose?n; and past: Caroline
Brun, Christian Fortmann, Anette Frank, Jonas Kuhn, Veronica
Lux, Yukiko Morimoto, Mar??a-Eugenia Nin?o, and Fre?de?rique
Segond.
by general wellformedness principles, this level of
analysis encodes language particular differences in
linear word order, surface morphological vs. syntac-
tic structures, and constituency.
The ParGram project aims to test the LFG formal-
ism for its universality and coverage limitations and
to see how far parallelism can be maintained across
languages. Where possible, the analyses produced
by the grammars for similar constructions in each
language are parallel. This has the computational
advantage that the grammars can be used in simi-
lar applications and that machine translation (Frank,
1999) can be simplified.
The results of the project to date are encouraging.
Despite differences between the languages involved
and the aims and backgrounds of the project groups,
the ParGram grammars achieve a high level of paral-
lelism. This parallelism applies to the syntactic anal-
yses produced, as well as to grammar development
itself: the sharing of templates and feature decla-
rations, the utilization of common techniques, and
the transfer of knowledge and technology from one
grammar to another. The ability to bundle grammar
writing techniques, such as templates, into transfer-
able technology means that new grammars can be
bootstrapped in a relatively short amount of time.
There are a number of other large-scale gram-
mar projects in existence which we mention briefly
here. The LS-GRAM project (Schmidt et al, 1996),
funded by the EU-Commission under LRE (Lin-
guistic Research and Engineering), was concerned
with the development of grammatical resources for
nine European languages: Danish, Dutch, English,
French, German, Greek, Italian, Portuguese, and
Spanish. The project started in January 1994 and
ended in July 1996. Development of grammatical
resources was carried out in the framework of the
Advanced Language Engineering Platform (ALEP).
The coverage of the grammars implemented in LS-
GRAM was, however, much smaller than the cov-
erage of the English (Riezler et al, 2002) or Ger-
man grammar in ParGram. An effort which is closer
in spirit to ParGram is the implemention of gram-
mar development platforms for HPSG. In the Verb-
mobil project (Wahlster, 2000), HPSG grammars for
English, German, and Japanese were developed on
two platforms: LKB (Copestake, 2002) and PAGE.
The PAGE system, developed and maintained in the
Language Technology Lab of the German National
Research Center on Artificial Intelligence DFKI
GmbH, is an advanced NLP core engine that facili-
tates the development of grammatical and lexical re-
sources, building on typed feature logics. To evalu-
ate the HPSG platforms and to compare their mer-
its with those of XLE and the ParGram projects, one
would have to organize a special workshop, partic-
ularly as the HPSG grammars in Verbmobil were
written for spoken language, characterized by short
utterances, whereas the LFG grammars were devel-
oped for parsing technical manuals and/or newspa-
per texts. There are some indications that the Ger-
man and English grammars in ParGram exceed the
HPSG grammars in coverage (see (Crysmann et al,
2002) on the German HPSG grammar).
This paper is organized as follows. We first pro-
vide a history of the project. Then, we discuss how
parallelism is maintained in the project. Finally, we
provide a summary and discussion.
2 Project History
The ParGram project began in 1994 with three lan-
guages: English, French, and German. The gram-
mar writers worked closely together to solidify the
grammatical analyses and conventions. In addition,
as XLE was still in development, its abilities grew
as the size of the grammars and their needs grew.
After the initial stage of the project, more lan-
guages were added. Because Japanese is typolog-
ically very different from the initial three Euro-
pean languages of the project, it represented a chal-
lenging case. Despite this typological challenge, the
Japanese grammar has achieved broad coverage and
high performance within a year and a half. The
South Asian language Urdu also provides a widely
spoken, typologically distinct language. Although it
is of Indo-European origin, it shares many character-
istics with Japanese such as verb-finality, relatively
free word order, complex predicates, and the abil-
ity to drop any argument (rampant pro-drop). Nor-
wegian assumes a typological middle position be-
tween German and English, sharing different prop-
erties with each of them. Both the Urdu and the Nor-
wegian grammars are still relatively small.
Each grammar project has different goals, and
each site employs grammar writers with different
backgrounds and skills. The English, German, and
Japanese projects have pursued the goal of hav-
ing broad coverage, industrial grammars. The Nor-
wegian and Urdu grammars are smaller scale but
are experimenting with incorporating different kinds
of information into the grammar. The Norwegian
grammar includes a semantic projection; their anal-
yses produce not only c- and f-structures, but also
semantic structures. The Urdu grammar has imple-
mented a level of argument structure and is test-
ing various theoretical linguistic ideas. However,
even when the grammars are used for different pur-
poses and have different additional features, they
have maintained their basic parallelism in analysis
and have profited from the shared grammar writing
techniques and technology.
Table (1) shows the size of the grammars. The first
figure is the number of left-hand side categories in
phrase-structure rules which compile into a collec-
tion of finite-state machines with the listed number
of states and arcs.
(1)
Language Rules States Arcs
German 444 4883 15870
English 310 4935 13268
French 132 1116 2674
Japanese 50 333 1193
Norwegian 46 255 798
Urdu 25 106 169
3 Parallelism
Maintaining parallelism in grammars being devel-
oped at different sites on typologically distinct lan-
guages by grammar writers from different linguis-
tic traditions has proven successful. At project meet-
ings held twice a year, analyses of sample sentences
are compared and any differences are discussed; the
goal is to determine whether the differences are jus-
tified or whether the analyses should be changed
to maintain parallelism. In addition, all of the f-
structure features and their values are compared; this
not only ensures that trivial differences in naming
conventions do not arise, but also gives an overview
of the constructions each language covers and how
they are analyzed. All changes are implemented be-
fore the next project meeting. Each meeting also in-
volves discussion of constructions whose analysis
has not yet been settled on, e.g., the analysis of parti-
tives or proper names. If an analysis is agreed upon,
all the grammars implement it; if only a tentative
analysis is found, one grammar implements it and
reports on its success. For extremely complicated or
fundamental issues, e.g., how to represent predicate
alternations, subcommittees examine the issue and
report on it at the next meeting. The discussion of
such issues may be reopened at successive meetings
until a concensus is reached.
Even within a given linguistic formalism, LFG for
ParGram, there is usually more than one way to an-
alyze a construction. Moreover, the same theoreti-
cal analysis may have different possible implemen-
tations in XLE. These solutions often differ in effi-
ciency or conceptual simplicity and one of the tasks
within the ParGram project is to make design deci-
sions which favor one theoretical analysis and con-
comitant implementation over another.
3.1 Parallel Analyses
Whenever possible, the ParGram grammars choose
the same analysis and the same technical solution
for equivalent constructions. This was done, for
example, with imperatives. Imperatives are always
assigned a null pronominal subject within the f-
structure and a feature indicating that they are im-
peratives, as in (2).
(2) a. Jump! Saute! (French)
Spring! (German) Tobe! (Japanese)
Hopp! (Norwegian) kuudoo! (Urdu)
b. PRED jump SUBJ
SUBJ PRED pro
STMT-TYPE imp
Another example of this type comes from the
analysis of specifiers. Specifiers include many dif-
ferent types of information and hence can be ana-
lyzed in a number of ways. In the ParGram analysis,
the c-structure analysis is left relatively free accord-
ing to language particular needs and slightly vary-
ing theoretical assumptions. For instance, the Nor-
wegian grammar, unlike the other grammars, im-
plements the principles in (Bresnan, 2001) concern-
ing the relationship between an X -based c-structure
and the f-structure. This allows Norwegian speci-
fiers to be analyzed as functional heads of DPs etc.,
whereas they are constituents of NPs in the other
grammars. However, at the level of f-structure, this
information is part of a complex SPEC feature in
all the grammars. Thus parallelism is maintained
at the level of f-structure even across different the-
oretical preferences. An example is shown in (3)
for Norwegian and English in which the SPEC con-
sists of a QUANT(ifier) and a POSS(essive) (SPEC
can also contain information about DETerminers and
DEMONstratives).
(3) a. alle mine hester (Norwegian)
all my horses
?all my horses?
b. PRED horse
SPEC
QUANT PRED all
POSS
PRED pro
PERS 1
NUM sg
Interrogatives provide an interesting example be-
cause they differ significantly in the c-structures of
the languages, but have the same basic f-structure.
This contrast can be seen between the German ex-
ample in (4) and the Urdu one in (5). In German,
the interrogative word is in first position with the
finite verb second; English and Norwegian pattern
like German. In Urdu the verb is usually in final po-
sition, but the interrogative can appear in a number
of positions, including following the verb (5c).
(4) Was hat John Maria gegeben? (German)
what has John Maria give.PerfP
?What did John give to Mary??
(5) a. jon=nee marii=koo kyaa diiyaa? (Urdu)
John=Erg Mary=Dat what gave
?What did John give to Mary?
b. jon=nee kyaa marii=koo diiyaa?
c. jon=nee marii=ko diiyaa kyaa?
Despite these differences in word order and hence in
c-structure, the f-structures are parallel, with the in-
terrogative being in a FOCUS-INT and the sentence
having an interrogative STMT-TYPE, as in (6).
(6) PRED give SUBJ,OBJ,OBL
FOCUS-INT
PRED pro
PRON-TYPE int
SUBJ PRED John
OBJ [ ]
OBL PRED Mary
STMT-TYPE int
In the project grammars, many basic construc-
tions are of this type. However, as we will see in
the next section, there are times when parallelism is
not possible and not desirable. Even in these cases,
though, the grammars which can be parallel are;
so, three of the languages might have one analysis,
while three have another.
3.2 Justified Differences
Parallelism is not maintained at the cost of misrepre-
senting the language. This is reflected by the fact that
the c-structures are not parallel because word order
varies widely from language to language, although
there are naming conventions for the nodes. Instead,
the bulk of the parallelism is in the f-structure. How-
ever, even in the f-structure, situations arise in which
what seems to be the same construction in different
languages do not have the same analysis. An exam-
ple of this is predicate adjectives, as in (7).
(7) a. It is red.
b. Sore wa akai. (Japanese)
it TOP red
?It is red.?
In English, the copular verb is considered the syn-
tactic head of the clause, with the pronoun being the
subject and the predicate adjective being an XCOMP.
However, in Japanese, the adjective is the main pred-
icate, with the pronoun being the subject. As such,
these receive the non-parallel analyses seen in (8a)
for Japanese and (8b) for English.
(8) a. PRED red SUBJ
SUBJ PRED pro
b. PRED be XCOMP SUBJ
SUBJ PRED pro
XCOMP
PRED red SUBJ
SUBJ [ ]
Another situation that arises is when a feature
or construction is syntactically encoded in one lan-
guage, but not another. In such cases, the informa-
tion is only encoded in the languages that need it.
The equivalence captured by parallel analyses is not,
for example, translational equivalence. Rather, par-
allelism involves equivalence with respect to gram-
matical properties, e.g. construction types. One con-
sequence of this is that a typologically consistent
use of grammatical terms, embodied in the feature
names, is enforced. For example, even though there
is a tradition for referring to the distinction between
the pronouns he and she as a gender distinction in
English, this is a different distinction from the one
called gender in languages like German, French,
Urdu, and Norwegian, where gender refers to nom-
inal agreement classes. Parallelism leads to the sit-
uation where the feature GEND occurs in German,
French, Urdu, and Norwegian, but not in English
and Japanese. That is, parallelism does not mean
finding the same features in all languages, but rather
using the same features in the same way in all lan-
guages, to the extent that they are justified there. A
French example of grammatical gender is shown in
(9); note that determiner, adjective, and participle
agreement is dependent on the gender of the noun.
The f-structure for the nouns crayon and plume are
as in (10) with an overt GEND feature.
(9) a. Le petit crayon est casse?. (French)
the-M little-M pencil-M is broken-M.
?The little pencil is broken.?
b. La petite plume est casse?e. (French)
the-F little-F pen-F is broken-F.
?The little pen is broken.?
(10)
PRED crayon
GEND masc
PERS 3
PRED plume
GEND fem
PERS 3
F-structures for the equivalent words in English and
Japanese will not have a GEND feature.
A similar example comes from Japanese dis-
course particles. It is well-known that Japanese has
syntactic encodings for information such as honori-
fication. The verb in the Japanese sentence (11a)
encodes information that the subject is respected,
while the verb in (11b) shows politeness from the
writer (speaker) to the reader (hearer) of the sen-
tence. The f-structures for the verbs in (11) are as in
(12) with RESPECT and POLITE features within the
ADDRESS feature.
(11) a. sensei ga hon wo oyomininaru.
teacher Nom book Acc read-Respect
?The teacher read the book.? (Japanese)
b. seito ga hon wo yomimasu.
student Nom book Acc read-Polite
?The student reads the book.? (Japanese)
(12) a. PRED yomu SUBJ,OBJ
ADDRESS RESPECT +
b. PRED yomu SUBJ,OBJ
ADDRESS POLITE +
A final example comes from English progres-
sives, as in (13). In order to distinguish these two
forms, the English grammar uses a PROG feature
within the tense/aspect system. (13b) shows the f-
structure for (13a.ii).
(13) a. John hit Bill. i. He cried.
ii. He was crying.
b. PRED cry SUBJ
SUBJ PRED pro
TNS-ASP
TENSE past
PROG +
However, this distinction is not found in the other
languages. For example, (14a) is used to express
both (13a.i) and (13a.ii) in German.
(14) a. Er weinte. (German)
he cried
?He cried.?
b. PRED weinen SUBJ
SUBJ PRED pro
TNS-ASP TENSE past
As seen in (14b), the German f-structure is left un-
derspecified for PROG because there is no syntactic
reflex of it. If such a feature were posited, rampant
ambiguity would be introduced for all past tense
forms in German. Instead, the semantics will deter-
mine whether such forms are progressive.
Thus, there are a number of situations where hav-
ing parallel analyses would result in an incorrect
analysis for one of the languages.
3.3 One Language Shows the Way
Another type of situation arises when one language
provides evidence for a certain feature space or type
of analysis that is neither explicitly mirrored nor
explicitly contradicted by another language. In the-
oretical linguistics, it is commonly acknowledged
that what one language codes overtly may be harder
to detect for another language. This situation has
arisen in the ParGram project. Case features fall un-
der this topic. German, Japanese, and Urdu mark
NPs with overt case morphology. In comparison,
English, French, and Norwegian make relatively lit-
tle use of case except as part of the pronominal sys-
tem. Nevertheless, the f-structure analyses for all the
languages contain a case feature in the specification
of noun phrases.
This ?overspecification? of information expresses
deeper linguistic generalizations and keeps the f-
structural analyses as parallel as possible. In addi-
tion, the features can be put to use for the isolated
phenomena in which they do play a role. For exam-
ple, English does not mark animacy grammatically
in most situations. However, providing a ANIM +
feature to known animates, such as people?s names
and pronouns, allows the grammar to encode infor-
mation that is relevant for interpretation. Consider
the relative pronoun who in (15).
(15) a. the girl[ANIM +] who[ANIM +] left
b. the box[ANIM +] who[ANIM +] left
The relative pronoun has a ANIM + feature that is as-
signed to the noun it modifies by the relative clause
rules. As such, a noun modified by a relative clause
headed by who is interpreted as animate. In the case
of canonical inanimates, as in (15b), this will result
in a pragmatically odd interpretation, which is en-
coded in the f-structure.
Teasing apart these different phenomena crosslin-
guistically poses a challenge that the ParGram mem-
bers are continually engaged in. As such, we have
developed several methods to help maintain paral-
lelism.
3.4 Mechanics of Maintaining Parallelism
The parallelism among the grammars is maintained
in a number of ways. Most of the work is done dur-
ing two week-long project meetings held each year.
Three main activities occur during these meetings:
comparison of sample f-structures, comparison of
features and their values, and discussions of new or
problematic constructions.
A month before each meeting, the host site
chooses around fifteen sentences whose analysis is
to be compared at the meeting. These can be a ran-
dom selection or be thematic, e.g., all dealing with
predicatives or with interrogatives. The sentences
are then parsed by each grammar and the output is
compared. For the more recent grammars, this may
mean adding the relevant rules to the grammars, re-
sulting in growth of the grammar; for the older gram-
mars, this may mean updating a construction that has
not been examined in many years. Another approach
that was taken at the beginning of the project was to
have a common corpus of about 1,000 sentences that
all of the grammars were to parse. For the English,
French, and German grammars, this was an aligned
tractor manual. The corpus sentences were used for
the initial f-structure comparisons. Having a com-
mon corpus ensured that the grammars would have
roughly the same coverage. For example, they all
parsed declarative and imperative sentences. How-
ever, the nature of the corpus can leave major gaps
in coverage; in this case, the manual contained no in-
terrogatives.
The XLE platform requires that a grammar de-
clare all the features it uses and their possible val-
ues. Part of the Urdu feature table is shown in (16)
(the notation has been simplified for expository pur-
poses). As seen in (16) for QUANT, attributes which
take other attributes as their values must also be de-
clared. An example of such a feature was seen in
(3b) for SPEC which takes QUANT and POSS fea-
tures, among others, as its values.
(16) PRON-TYPE: pers poss null .
PROPER: date location name title .
PSEM: locational directional .
PTYPE: sem nosem .
QUANT: PRED QUANT-TYPE
QUANT-FORM .
The feature declarations of all of the languages are
compared feature by feature to ensure parallelism.
The most obvious use of this is to ensure that the
grammars encode the same features in the same way.
For example, at a basic level, one feature declaration
might have specified GEN for gender while the oth-
ers had chosen the name GEND; this divergence in
naming is regularized. More interesting cases arise
when one language uses a feature and another does
not for analyzing the same phenomena. When this is
noticed via the feature-table comparison, it is deter-
mined why one grammar needs the feature and the
other does not, and thus it may be possible to elim-
inate the feature in one grammar or to add it to an-
other.
On a deeper level, the feature comparison is use-
ful for conducting a survey of what constructions
each grammar has and how they are implemented.
For example, if a language does not have an ADE-
GREE (adjective degree) feature, the question will
arise as to whether the grammar analyzes compar-
ative and superlative adjectives. If they do not, then
they should be added and should use the ADEGREE
feature; if they do, then the question arises as to why
they do not have this feature as part of their analysis.
Finally, there is the discussion of problematic
constructions. These may be constructions that al-
ready have analyses which had been agreed upon in
the past but which are not working properly now that
more data has been considered. More frequently,
they are new constructions that one of the grammars
is considering adding. Possible analyses for the con-
struction are discussed and then one of the gram-
mars will incorporate the analysis to see whether it
works. If the analysis works, then the other gram-
mars will incorporate the analysis. Constructions
that have been discussed in past ParGram meet-
ings include predicative adjectives, quantifiers, par-
titives, and clefts. Even if not all of the languages
have the construction in question, as was the case
with clefts, the grammar writers for that language
may have interesting ideas on how to analyze it.
These group discussions have proven particularly
useful in extending grammar coverage in a parallel
fashion.
Once a consensus is reached, it is the responsi-
bility of each grammar to make sure that its anal-
yses match the new standard. As such, after each
meeting, the grammar writers will rename features,
change analyses, and implement new constructions
into their grammars. Most of the basic work has now
been accomplished. However, as the grammars ex-
pand coverage, more constructions need to be inte-
grated into the grammars, and these constructions
tend to be ones for which there is no standard analy-
sis in the linguistic literature; so, differences can eas-
ily arise in these areas.
4 Conclusion
The experiences of the ParGram grammar writers
has shown that the parallelism of analysis and imple-
mentation in the ParGram project aids further gram-
mar development efforts. Many of the basic deci-
sions about analyses and formalism have already
been made in the project. Thus, the grammar writer
for a new language can use existing technology to
bootstrap a grammar for the new language and can
parse equivalent constructions in the existing lan-
guages to see how to analyze a construction. This
allows the grammar writer to focus on more diffi-
cult constructions not yet encountered in the existing
grammars.
Consider first the Japanese grammar which was
started in the beginning of 2001. At the initial stage,
the work of grammar development involved imple-
menting the basic constructions already analyzed in
the other grammars. It was found that the grammar
writing techniques and guidelines to maintain par-
allelism shared in the ParGram project could be ef-
ficiently applied to the Japanese grammar. During
the next stage, LFG rules needed for grammatical is-
sues specific to Japanese have been gradually incor-
porated, and at the same time, the biannual ParGram
meetings have helped significantly to keep the gram-
mars parallel. Given this system, in a year and a half,
using two grammar writers, the Japanese grammar
has attained coverage of 99% for 500 sentences of a
copier manual and 95% for 10,000 sentences of an
eCRM (Voice-of-Customer) corpus.
Next consider the Norwegian grammar which
joined the ParGram group in 1999 and also empha-
sized slightly different goals from the other groups.
Rather than prioritizing large textual coverage from
the outset, the Norwegian group gave priority to the
development of a core grammar covering all major
construction types in a principled way based on the
proposals in (Bresnan, 2001) and the inclusion of a
semantic projection in addition to the f-structure. In
addition, time was spent on improving existing lexi-
cal resources ( 80,000 lemmas) and adapting them
to the XLE format. Roughly two man-years has been
spent on the grammar itself. The ParGram cooper-
ation on parallelism has ensured that the derived f-
structures are interesting in a multilingual context,
and the grammar will now serve as a basis for gram-
mar development in other closely related Scandina-
vian languages.
Thus, the ParGram project has shown that it is
possible to use a single grammar development plat-
form and a unified methodology of grammar writing
to develop large-scale grammars for typologically
different languages. The grammars? analyses show a
large degree of parallelism, despite being developed
at different sites. This is achieved by intensive meet-
ings twice a year. The parallelism can be exploited in
applications using the grammars: the fewer the dif-
ferences, the simpler a multilingual application can
be (see (Frank, 1999) on a machine-translation pro-
totype using ParGram).
References
Joan Bresnan. 2001. Lexical-Functional Syntax.
Blackwell.
Miriam Butt, Tracy Holloway King, Mar??a-Eugenia
Nin?o, and Fre?de?rique Segond. 1999. A Grammar
Writer?s Cookbook. CSLI Publications.
Ann Copestake. 2002. Implementing Typed Feature
Structure Grammars. CSLI Publications.
Berthold Crysmann, Anette Frank, Bernd Keifer, St.
Mu?ller, Gu?nter Neumann, Jakub Piskorski, Ulrich
Scha?fer, Melanie Siegel, Hans Uszkoreit, Feiyu
Xu, Markus Becker, and Hans-Ulrich Krieger.
2002. An integrated architecture for shallow and
deep parsing. In Proceedings of the Annual Meet-
ing of the Association for Computational Linguis-
tics, University of Pennsylvania.
Anette Frank. 1999. From parallel grammar devel-
opment towards machine translation. In Proceed-
ings of MT Summit VII, pages 134?142.
John T. Maxwell, III and Ron Kaplan. 1993. The
interface between phrasal and functional con-
straints. Computational Lingusitics, 19:571?589.
Stefan Riezler, Tracy Holloway King, Ronald Ka-
plan, Dick Crouch, John T. Maxwell, III, and
Mark Johnson. 2002. Parsing the wall street jour-
nal using a lexical-functional grammar and dis-
criminative estimation techniques. In Proceed-
ings of the Annual Meeting of the Association for
Computational Linguistics, University of Penn-
sylvania.
Paul Schmidt, Sibylle Rieder, Axel Theofilidis, and
Thierry Declerck. 1996. Lean formalisms, lin-
guistic theory, and applications: Grammar devel-
opment in alep. In Proceedings of COLING.
Wolfgang Wahlster, editor. 2000. Verbmobil:
Foundations of Speech-to-Speech Translation.
Springer.
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 305?310,
Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational Linguistics
Towards Tracking Semantic Change by Visual Analytics
Christian Rohrdantz1 Annette Hautli2 Thomas Mayer2
Miriam Butt2 Daniel A. Keim1 Frans Plank2
Department of Computer Science1 Department of Linguistics2
University of Konstanz
Abstract
This paper presents a new approach to detect-
ing and tracking changes in word meaning by
visually modeling and representing diachronic
development in word contexts. Previous stud-
ies have shown that computational models
are capable of clustering and disambiguat-
ing senses, a more recent trend investigates
whether changes in word meaning can be
tracked by automatic methods. The aim of our
study is to offer a new instrument for inves-
tigating the diachronic development of word
senses in a way that allows for a better under-
standing of the nature of semantic change in
general. For this purpose we combine tech-
niques from the field of Visual Analytics with
unsupervised methods from Natural Language
Processing, allowing for an interactive visual
exploration of semantic change.
1 Introduction
The problem of determining and inferring the sense
of a word on the basis of its context has been the
subject of quite a bit of research. Earlier investiga-
tions have mainly focused on the disambiguation of
word senses from information contained in the con-
text, e.g. Schu?tze (1998) or on the induction of word
senses (Yarowsky, 1995). Only recently, the field
has added a diachronic dimension to its investiga-
tions and has moved towards the computational de-
tection of sense development over time (Sagi et al,
2009; Cook and Stevenson, 2010), thereby comple-
menting theoretical investigations in historical lin-
guistics with information gained from large corpora.
These approaches have concentrated on measuring
general changes in the meaning of a word (e.g., nar-
rowing or pejoration), whereas in this paper we deal
with cases where words acquire a new sense by ex-
tending their contexts to other domains.
For the scope of this investigation we restrict our-
selves to cases of semantic change in English even
though the methodology is generally language in-
dependent. Our choice is on the one hand moti-
vated by the extensive knowledge available on se-
mantic change in English. On the other hand, our
choice was driven by the availability of large cor-
pora for English. In particular, we used the New
York Times Annotated Corpus.1 Given the variety
and the amount of text available, we are able to track
changes from 1987 until 2007 in 1.8 million news-
paper articles.
In order to be able to explore our approach in a
fruitful manner, we decided to concentrate on words
which have acquired a new dimension of use due
to the introduction of computing and the internet,
e.g., to browse, to surf, bookmark. In particular,
the Netscape Navigator was introduced in 1994 and
our data show that this does indeed correlate with a
change in use of these words.
Our approach combines methods from the fields
of Information Visualization and Visual Analyt-
ics (Thomas and Cook, 2005; Keim et al, 2010)
with unsupervised techniques from Natural Lan-
guage Processing (NLP). This combination provides
a novel instrument which allows for tracking the di-
achronic development of word meaning by visual-
izing the contexts in which the words occur. Our
overall aim is not to replace linguistic analysis in
1http://http://www.ldc.upenn.edu/
305
this field with an automatic method, but to guide re-
search by generating new hypotheses about the de-
velopment of semantic change.
2 Related work
The computational modeling of word senses is based
on the assumption that the meaning of a word can
be inferred from the words in its immediate con-
text (?context words?). Research in this area mainly
focuses on two related tasks: Word Sense Disam-
biguation (WSD) and Word Sense Induction (WSI).
The goal of WSD is to classify occurrences of pol-
ysemous words according to manually predefined
senses. One popular method for performing such
a classification is Latent Semantic Analysis (LSA)
(Deerwester et al, 1990), with other methods also
suitable for the task (see Navigli (2009) for an ex-
tensive survey).
The aim of WSI is to learn word senses from
text corpora without having a predefined number of
senses. This goal is more difficult to achieve, as it
is not clear beforehand how many senses should be
extracted and how a sense could be described in an
abstract way. Recently, however, Brody and Lapata
(2009) have shown that Latent Dirichlet Allocation
(LDA) (Blei et al, 2003) can be successfully applied
to perform word sense induction from small word
contexts.
The original idea of LSA and LDA is to learn ?top-
ics? from documents, whereas in our scenario word
contexts rather than documents are used, i.e., a small
number of words before and after the word under
investigation (bag of words). Sagi et al (2009)
have demonstrated that broadening and narrowing
of word senses can be tracked over time by applying
LSA to small word contexts in diachronic corpora.
In addition, we will use LDA, which has proven even
more reliable in the course of our investigations.
In general, the aim of our paper is to go beyond
the approach of Sagi et al (2009) and analyze se-
mantic change in more detail. Ideally, a starting
point of change is found and the development over
time can be tracked, paired with a quantitative com-
parison of prevailing senses. We therefore suggest
to visualize word contexts in order to gain a better
understanding of diachronic developments and also
generate hypotheses for further investigations.
3 An interactive visualization approach to
semantic change
In order to test our approach, we opted for a large
corpus with a high temporal resolution. The New
York Times Annotated Corpus with 1.8 million
newspaper articles from 1987 to 2007 has a rather
small time depth of 20 years but provides a time
stamp for the exact publication date. Therefore,
changes can be tracked on a daily basis.
The data processing involved context extraction,
vector space creation, and sense modeling. As
Schu?tze (1998) showed, looking at a context win-
dow of 25 words before and after a key word pro-
vides enough information in order to disambiguate
word senses. Each extracted context is comple-
mented with the time stamp from the corpus. To
reduce the dimensionality, all context words were
lemmatized and stop words were filtered out.
For the set of all contexts of a key word, a global
LDA model was trained using the MALLET toolkit2
(McCallum, 2002). Each context is assigned to its
most probable topic/sense, complemented by a spe-
cific point on the time scale according to its time
stamp from the corpus. Contexts for which the high-
est probability was less than 40% were omitted be-
cause they could not be assigned to a certain sense
unambiguously. The distribution of senses over time
was then visualized.
3.1 Visualization
Different visualizations provide multidimensional
views on the data and yield a better understanding
of the developments. While plotting every word oc-
currence individually offers the opportunity to detect
and inspect outliers, aggregated views on the data
are able to provide insights on overall developments.
Figure 1 provides a view where the percentages of
word contexts belonging to different senses are plot-
ted over time. For the verbs to browse and to surf
seven senses are learned with LDA. Each sense cor-
responds to one row and is described by the top five
terms identified by LDA. The higher the gray area
at a certain x-axis point, the more of the contexts of
the corresponding year belong to the specific sense.
Each shade of gray represents 10% of the overall
data, i.e., three shades of gray mean that between
2http://mallet.cs.umass.edu/
306
to browse to surf
time, library, 
student, music, 
people
shop, street, 
book, store, art
book, read, 
bookstore, find, 
year
deer, plant, 
tree, garden, 
animal
software, microsoft, 
internet, netscape, 
windows
web, internet, 
site, mail , 
computer
store, shop, 
buy, day, 
customer
sport, wind, 
water, ski, offer
wave, surfer, 
board, year, 
sport
channel,  
television, 
show, watch, tv
web, internet, 
site, computer, 
company
film, boy, 
movie, show, 
ride
year, day, time, 
school, friend
beach, wave, 
surfer, long, 
coast
a
b
c
d
e
f
g
h
i
j
k
l
m
n
Figure 1: Temporal development of different senses concerning the verbs to browse (left) and to surf (right)
20% and 30% of the contexts can be attributed to
that sense. For each year one value has been gener-
ated and values between two years are linearly inter-
polated.
Figure 2 shows the development of contexts over
time, with each context plotted individually. The
more recent the context, the darker the color.3 Each
axis represents one sense of to browse, in each sub-
figure different combinations of senses are plotted.
A random jitter has been introduced to avoid over-
laps. Contexts in the middle (not the lower left cor-
ner, but the middle of the graph, e.g., see e vs. f)
belong to both senses with at least 40% probabil-
ity. Senses that share many ambiguous contexts are
usually similar. By mousing over a colored dot, its
context is shown, allowing for an in depth analysis.
3.2 Case studies
In order to be able to judge the effectiveness of our
new approach, we chose key words that are likely
candidates for a change in use in the time from 1987
to 2007. That is, we concentrated on terms relat-
ing to the relatively recent introduction of the inter-
net. The advantage of these terms is that the cause
of change can be located precisely in time.
Figure 1 shows the temporal sense development
of the verbs to browse and to surf, together with
the descriptive terms for each sense. Sense e for to
3The pdf version of this paper contains a bipolar color map.
browse and sense k for to surf pattern quite similarly.
Inspecting their contexts reveals that both senses ap-
pear with the invention of web browsers, peaking
shortly after the introduction of Netscape Navigator
(1994). For to browse, another broader sense (sense
f) concerning browsing in both the internet and dig-
ital media collections shows a continuous increase
over time, dominating in 2007.
The first occurrences assigned to sense f in 1987
are ?browse data bases?, ?word-by-word brows-
ing? in databases and ?browsing files in the cen-
ter?s library?, referring to physical files, namely pho-
tographs. We speculate that the sense of browsing
physical media might haven given rise to the sense
which refers to browsing electronic media, which in
turn becomes the dominating sense with the advent
of the web.
Figure 2 shows pairwise comparisons of word
senses with respect to the contexts they share, i.e.,
contexts that cannot unambiguously be assigned to
one or the other. Each context is represented by
one dot colored according to its time stamp. It can
be seen that senses d (animals that browse) and e
(browsing the web) share no contexts at all. Senses
d (animals that browse) and f (browsing files) share
only few contexts. In turn, senses e and f share a
fair number of contexts, which is to be expected, as
they are closely related. Single contexts, each rep-
resented by a colored dot, can be inspected via a
307
Figure 2: Pairwise comparisons of different senses for the verb ?to browse?. In each subfigure different combinations
of LDA dimensions are mapped on the axes.
LSA dimensions
1 web 0.40, internet 0.38, software 0.36, microsoft 0.28, win-
dows 0.18
2 microsoft 0.24, software 0.23, windows 0.13, internet 0.13,
netscape 0.12
3 microsoft 0.27, store 0.22, shop 0.20, windows 0.19, software
0.16
4 shop 0.32, netscape 0.23, web 0.23, store 0.19, software 0.19
5 book 0.48, netscape 0.26, software 0.17, world 0.13, commu-
nication 0.12
6 internet 0.58, shop 0.25, service 0.16, computer 0.13, people
0.11
7 make 0.39, shop 0.34, site 0.16, windows 0.13, art 0.08
... ...
15 find 0.30, people 0.22, year 0.19, deer 0.16, day 0.15
Table 1: Descriptive terms for the top LSA dimensions for
the contexts of to browse. For each dimension the top 5
positively associated terms were extracted, together with
their value in the corresponding dimension.
mouse roll over. This allows for an in-depth look at
specific data points and a better understanding how
the data points relate to a sense.
3.3 LSA vs. LDA
In comparison, Table 1 shows the LSA dimensions
learned from the contexts of the verb to browse. The
top five associated terms for each dimension have
been extracted as descriptor. The dimensions are
heavily dominated by senses strongly represented
in the corpus (e.g., browsing the web). Infrequent
senses (e.g., animals that browse) only occur in very
low-ranked dimensions and are mixed with other
senses (see the bold term deer in dimension 15).
4 Evaluation
We compared the findings provided by our visual-
ization with word sense information coming from
various resources, namely the 2007 Collins dictio-
nary (COLL), the English WordNet4 (WN) (Fell-
baum, 1998) and the Longman Dictionary (LONG)
from 1987. Senses that evolved later than 1987
should not appear in LONG, but should appear in
later dictionaries.
However, we are well aware that dictionaries are
by no means good gold standards as lexicogra-
phers themselves vary greatly when assigning word
senses. Nevertheless, this comparison can provide a
first indication as to whether the results of our tool
is in line with other methods of identifying senses.
In the case of to browse, COLL and WordNet
suggest the senses ?shopping around; not necessar-
ily buying?, ?feed as in a meadow or pasture? and
?browse a computer directory, surf the internet or the
world wide web.? These senses are also identified in
our visualizations, which even additionally differen-
tiate between the senses of ?browsing the web? and
?browsing a computer directory.? A WordNet sense
that cannot be detected in the data is the meaning ?to
eat lightly and try different dishes.?
Table 2 shows the results of comparing dictionary
word senses (DIC) with the results from our visual-
ization (VIS). What can be seen is that our method
is able to track semantic change diachronically and
4http://wordnetweb.princeton.edu
308
to browse to surf messenger bug bookmark
# of word senses # of word senses # of word senses # of word senses # of word senses
DIC VIS DIC VIS DIC VIS DIC VIS DIC VIS
1987 (LONG) 2 3 1 1 1 2 6 3 1 1
1998 (WN) 5 4 3 3 1 3 5 3 1 2
2007 (COLL) 3 4 3 2 1 3 5 3 2 2
Table 2: A comparison of different word senses as given in dictionaries with the visualization results across time
in the majority of cases, the number of our senses
correspond to the information coming from the dic-
tionaries. In some cases we are even more accurate
in discriminating them. In the case of ?messenger?,
the visualizations suggest another sense related to
?instant messaging? that arises with the advent of
the AOL instant messenger in 1997. This leads us to
the conclusion that our method is appropriate from a
historical linguistic point of view.
5 Discussion and conclusions
When dealing with a complex phenomenon such as
semantic change, one has to be aware of the limita-
tions of an automatic approach in order to be able
to draw the right conclusions from its results. The
first results of the case studies presented in this pa-
per show that LDA is useful for distinguishing dif-
ferent word senses on the basis of word contexts and
performs better than LSA for this task. Further, it
has been demonstrated by exemplary cases that the
emergence of a new word sense can be detected by
our new methodology
One of the main reasons for an interactive visu-
alization approach is the possibility of being able to
detect conspicuous patterns at-a-glance, yet at the
same time being able to delve into the details of the
data by zooming in on the occurrences of particu-
lar words in their contexts. This makes it possible
to compensate for one of the major disadvantages
of generative and vector space models, namely their
functioning as ?black boxes? whose results cannot
be tracked easily.
The biggest problem in dealing with a corpus-
based method of detecting meaning change is the
availability of suitable corpora. First, computing se-
mantic information on the basis of contexts requires
a large amount of data in order to be able to infer re-
liable results. Second, the words in the context from
which the meanings will be distinguished should be
both semantically and orthographically stable over
time so that comparisons between different stages in
the development of the language can be made. Un-
fortunately, both requirements are not always met.
On the one hand words do change their meaning,
after all this is what the present study is all about.
However, we assume that the meanings in a certain
context window are stable enough to infer reliable
results provided it is possible that the forms of the
same words in different periods can be linked. This
of course limits the applicability of the approach to
smaller time ranges due to changes in the phonetic
form of words. Moreover, in particular for older pe-
riods of the language, different variants for the same
word, either due to sound changes or different (or
rather no) spelling conventions, abound. For now,
we circumvent this problem by testing our tool on
corpora where the drawbacks of historical texts are
less severe but at the same time interesting develop-
ments can be detected to prove our approach correct.
For future research, we want to test our methodol-
ogy on a broader range of terms, texts and languages
and develop novel interactive visualizations to aid
investigations in two ways. As a first aim, the user
should be allowed to check the validity and quality
of the visualizations by experimenting with param-
eter settings and inspecting their outcome. Second,
the user is supposed to gain a better understanding of
semantic change by interactively exploring a corpus.
Acknowledgments
This work has partly been funded by the Research
Initiative ?Computational Analysis of Linguistic
Development? at the University of Konstanz and by
the German Research Society (DFG) under the grant
GK-1042, Explorative Analysis and Visualization of
Large Information Spaces, Konstanz. The authors
would like to thank Zdravko Monov for his program-
ming support.
309
References
David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent dirichlet alocation. Journal of Machine
Learning Research, 3:993?1022.
Samuel Brody and Mirella Lapata. 2009. Bayesian word
sense induction. In Proceedings of the 12th Con-
ference of the European Chapter of the Association
for Computational Linguistics, EACL ?09, pages 103?
111, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.
Paul Cook and Suzanne Stevenson. 2010. Automati-
cally Identifying Changes in the Semantic Orientation
of Words. In Proceedings of the Seventh conference
on International Language Resources and Evaluation
(LREC?10), pages 28?34, Valletta, Malta.
Scott Deerwester, Susan T. Dumais, George W. Furnas,
Thomas K. Landauer, and Richard Harshman. 1990.
Indexing by latent semantic analysis. Journal of the
American Society for Information Science, 41:391?
407.
Christiane Fellbaum. 1998. WordNet: An Electronic
Lexical Database. MIT Press, Cambridge, MA.
Daniel A. Keim, Joern Kohlhammer, Geoffrey Ellis, and
Florian Mansmann, editors. 2010. Mastering The In-
formation Age - Solving Problems with Visual Analyt-
ics. Goslar: Eurographics.
Andrew Kachites McCallum. 2002. MALLET:
A Machine Learning for Language Toolkit.
http://mallet.cs.umass.edu.
Roberto Navigli. 2009. Word sense disambiguation: A
survey. ACMComputing Surveys (CSUR), 41(2):1?69.
Eyal Sagi, Stefan Kaufmann, and Brady Clark. 2009.
Semantic Density Analysis: Comparing Word Mean-
ing across Time and Phonetic Space. In Proceedings
of the EACL 2009 Workshop on GEMS: GEometical
Models of Natural Language Semantics, pages 104?
111, Athens, Greece.
Hinrich Schu?tze. 1998. Automatic word sense discrimi-
nation. Computational Linguistics, 24(1):97?123.
James J. Thomas and Kristin A. Cook. 2005. Illuminat-
ing the Path The Research and Development Agenda
for Visual Analytics. National Visualization and Ana-
lytics Center.
David Yarowsky. 1995. Unsupervised word sense dis-
ambiguation rivaling supervised methods. In Proceed-
ings of the 33rd annual meeting on Association for
Computational Linguistics (ACL ?95), pages 189?196,
Cambridge, Massachusetts.
310
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 550?560,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
ParGramBank: The ParGram Parallel Treebank
Sebastian Sulger and Miriam Butt
University of Konstanz, Germany
{sebastian.sulger|miriam.butt}@uni-konstanz.de
Tracy Holloway King
eBay Inc., USA
tracyking@ebay.com
Paul Meurer
Uni Research AS, Norway
paul.meurer@uni.no
Tibor Laczko? and Gyo?rgy Ra?kosi
University of Debrecen, Hungary
{laczko.tibor|rakosi.gyorgy}@arts.unideb.hu
Cheikh Bamba Dione and Helge Dyvik and Victoria Rose?n and Koenraad De Smedt
University of Bergen, Norway
dione.bamba@lle.uib.no, {dyvik|victoria|desmedt}@uib.no
Agnieszka Patejuk
Polish Academy of Sciences
aep@ipipan.waw.pl
O?zlem C?etinog?lu
University of Stuttgart, Germany
ozlem@ims.uni-stuttgart.de
I Wayan Arka* and Meladel Mistica+
*Australian National University and Udayana University, Indonesia
+Australian National University
wayan.arka@anu.edu.au, meladel.mistica@gmail.com
Abstract
This paper discusses the construction of
a parallel treebank currently involving ten
languages from six language families. The
treebank is based on deep LFG (Lexical-
Functional Grammar) grammars that were
developed within the framework of the
ParGram (Parallel Grammar) effort. The
grammars produce output that is maxi-
mally parallelized across languages and
language families. This output forms the
basis of a parallel treebank covering a
diverse set of phenomena. The treebank
is publicly available via the INESS tree-
banking environment, which also allows
for the alignment of language pairs. We
thus present a unique, multilayered paral-
lel treebank that represents more and dif-
ferent types of languages than are avail-
able in other treebanks, that represents
deep linguistic knowledge and that allows
for the alignment of sentences at sev-
eral levels: dependency structures, con-
stituency structures and POS information.
1 Introduction
This paper discusses the construction of a parallel
treebank currently involving ten languages that
represent several different language families, in-
cluding non-Indo-European. The treebank is based
on the output of individual deep LFG (Lexical-
Functional Grammar) grammars that were deve-
loped independently at different sites but within
the overall framework of ParGram (the Parallel
Grammar project) (Butt et al, 1999a; Butt et al,
2002). The aim of ParGram is to produce deep,
wide coverage grammars for a variety of lan-
guages. Deep grammars provide detailed syntactic
analysis, encode grammatical functions as well as
550
other grammatical features such as tense or aspect,
and are linguistically well-motivated. The Par-
Gram grammars are couched within the linguis-
tic framework of LFG (Bresnan, 2001; Dalrymple,
2001) and are constructed with a set of grammati-
cal features that have been commonly agreed upon
within the ParGram group. ParGram grammars are
implemented using XLE, an efficient, industrial-
strength grammar development platform that in-
cludes a parser, a generator and a transfer sys-
tem (Crouch et al, 2012). XLE has been devel-
oped in close collaboration with the ParGram
project. Over the years, ParGram has continu-
ously grown and includes grammars for Ara-
bic, Chinese, English, French, German, Georgian,
Hungarian, Indonesian, Irish, Japanese, Mala-
gasy, Murrinh-Patha, Norwegian, Polish, Spanish,
Tigrinya, Turkish, Urdu, Welsh and Wolof.
ParGram grammars produce output that has
been parallelized maximally across languages ac-
cording to a set of commonly agreed upon uni-
versal proto-type analyses and feature values. This
output forms the basis of the ParGramBank paral-
lel treebank discussed here. ParGramBank is con-
structed using an innovative alignment methodol-
ogy developed in the XPAR project (Dyvik et al,
2009) in which grammar parallelism is presup-
posed to propagate alignment across different pro-
jections (section 6). This methodology has been
implemented with a drag-and-drop interface as
part of the LFG Parsebanker in the INESS infras-
tructure (Rose?n et al, 2012; Rose?n et al, 2009).
ParGramBank has been constructed in INESS and
is accessible in this infrastructure, which also of-
fers powerful search and visualization.
In recent years, parallel treebanking1 has gained
in importance within NLP. An obvious applica-
tion for parallel treebanking is machine transla-
tion, where treebank size is a deciding factor for
whether a particular treebank can support a par-
ticular kind of research project. When conduct-
ing in-depth linguistic studies of typological fea-
tures, other factors such as the number of in-
cluded languages, the number of covered phe-
nomena, and the depth of linguistic analysis be-
come more important. The treebanking effort re-
ported on in this paper supports work of the lat-
ter focus, including efforts at multilingual depen-
dency parsing (Naseem et al, 2012). We have
1Throughout this paper ?treebank? refers to both phrase-
structure resources and their natural extensions to depen-
dency and other deep annotation banks.
created a parallel treebank whose prototype in-
cludes ten typologically diverse languages and re-
flects a diverse set of phenomena. We thus present
a unique, multilayered parallel treebank that rep-
resents more languages than are currently avail-
able in other treebanks, and different types of lan-
guages as well. It contains deep linguistic knowl-
edge and allows for the parallel and simultane-
ous alignment of sentences at several levels. LFG?s
f(unctional)-structure encodes dependency struc-
tures as well as information that is equivalent to
Quasi-Logical Forms (van Genabith and Crouch,
1996). LFG?s c(onstituent)-structure provides in-
formation about constituency, hierarchical rela-
tions and part-of-speech. Currently, ParGramBank
includes structures for the following languages
(with the ISO 639-3 code and language fam-
ily): English (eng, Indo-European), Georgian (kat,
Kartvelian), German (deu, Indo-European), Hun-
garian (hun, Uralic), Indonesian (ind, Austrone-
sian), Norwegian (Bokma?l) (nob, Indo-European),
Polish (pol, Indo-European), Turkish (tur, Altaic),
Urdu (urd, Indo-European) and Wolof (wol, Niger-
Congo). It is freely available for download under
the CC-BY 3.0 license via the INESS treebanking
environment and comes in two formats: a Prolog
format and an XML format.2
This paper is structured as follows. Section
2 discusses related work in parallel treebanking.
Section 3 presents ParGram and its approach to
parallel treebanking. Section 4 focuses on the tree-
bank design and its construction. Section 5 con-
tains examples from the treebank, focusing on ty-
pological aspects and challenges for parallelism.
Section 6 elaborates on the mechanisms for paral-
lel alignment of the treebank.
2 Related Work
There have been several efforts in parallel tree-
banking across theories and annotation schemes.
Kuhn and Jellinghaus (2006) take a mini-
mal approach towards multilingual parallel tree-
banking. They bootstrap phrasal alignments over
a sentence-aligned parallel corpus of English,
French, German and Spanish and report concrete
treebank annotation work on a sample of sen-
tences from the Europarl corpus. Their annotation
2http://iness.uib.no. The treebank is in the
public domain (CC-BY 3.0). The use of the INESS platform
itself is not subject to any licensing. To access the treebank,
click on ?Treebank selection? and choose the ParGram collec-
tion.
551
scheme is the ?leanest? possible scheme in that it
consists solely of a bracketing for a sentence in
a language (where only those units that play the
role of a semantic argument or modifier in a larger
unit are bracketed) and a correspondence relation
of the constituents across languages.
Klyueva and Marec?ek (2010) present a small
parallel treebank using data and tools from two
existing treebanks. They take a syntactically an-
notated gold standard text for one language and
run an automated annotation on the parallel text
for the other language. Manually annotated Rus-
sian data are taken from the SynTagRus treebank
(Nivre et al, 2008), while tools for parsing the cor-
responding text in Czech are taken from the Tec-
toMT framework (Popel and Z?abokrtsky?, 2010).
The SMULTRON project is concerned with con-
structing a parallel treebank of English, German
and Swedish. The sentences have been POS-tagged
and annotated with phrase structure trees. These
trees have been aligned on the sentence, phrase
and word level. Additionally, the German and
Swedish monolingual treebanks contain lemma in-
formation. The treebank is distributed in TIGER-
XML format (Volk et al, 2010).
Megyesi et al (2010) discuss a parallel English-
Swedish-Turkish treebank. The sentences in each
language are annotated morphologically and syn-
tactically with automatic tools, aligned on the
sentence and the word level and partially hand-
corrected.3
A further parallel treebanking effort is Par-
TUT, a parallel treebank (Sanguinetti and Bosco,
2011; Bosco et al, 2012) which provides depen-
dency structures for Italian, English and French
and which can be converted to a CCG (Combina-
tory Categorial Grammar) format.
Closest to our work is the ParDeepBank, which
is engaged in the creation of a highly paral-
lel treebank of English, Portuguese and Bulgar-
ian. ParDeepBank is couched within the linguistic
framework of HPSG (Head-Driven Phrase Struc-
ture Grammar) and uses parallel automatic HPSG
grammars, employing the same tools and imple-
mentation strategies across languages (Flickinger
et al, 2012). The parallel treebank is aligned on
the sentence, phrase and word level.
In sum, parallel treebanks have so far fo-
cused exclusively on Indo-European languages
3The paper mentions Hindi as the fourth language, but
this is not yet available: http://stp.lingfil.uu.
se/?bea/turkiska/home-en.html.
(with Turkish providing the one exception) and
generally do not extend beyond three or four
languages. In contrast, our ParGramBank tree-
bank currently includes ten typologically differ-
ent languages from six different language families
(Altaic, Austronesian, Indo-European, Kartvelian,
Niger-Congo, Uralic).
A further point of comparison with ParDeep-
Bank is that it relies on dynamic treebanks, which
means that structures are subject to change dur-
ing the further development of the resource gram-
mars. In ParDeepBank, additional machinery is
needed to ensure correct alignment on the phrase
and word level (Flickinger et al, 2012, p. 105).
ParGramBank contains finalized analyses, struc-
tures and features that were designed collabora-
tively over more than a decade, thus guaranteeing
a high degree of stable parallelism. However, with
the methodology developed within XPAR, align-
ments can easily be recomputed from f-structure
alignments in case of grammar or feature changes,
so that we also have the flexible capability of
allowing ParGramBank to include dynamic tree-
banks.
3 ParGram and its Feature Space
The ParGram grammars use the LFG formalism
which produces c(onstituent)-structures (trees)
and f(unctional)-structures as the syntactic anal-
ysis. LFG assumes a version of Chomsky?s Uni-
versal Grammar hypothesis, namely that all lan-
guages are structured by similar underlying prin-
ciples (Chomsky, 1988; Chomsky, 1995). Within
LFG, f-structures encode a language universal
level of syntactic analysis, allowing for crosslin-
guistic parallelism at this level of abstraction. In
contrast, c-structures encode language particular
differences in linear word order, surface morpho-
logical vs. syntactic structures, and constituency
(Dalrymple, 2001). Thus, while the Chomskyan
framework is derivational in nature, LFG departs
from this view by embracing a strictly representa-
tional approach to syntax.
ParGram tests the LFG formalism for its uni-
versality and coverage limitations to see how far
parallelism can be maintained across languages.
Where possible, analyses produced by the gram-
mars for similar constructions in each language are
parallel, with the computational advantage that the
grammars can be used in similar applications and
that machine translation can be simplified.
552
The ParGram project regulates the features and
values used in its grammars. Since its inception
in 1996, ParGram has included a ?feature com-
mittee?, which collaboratively determines norms
for the use and definition of a common multilin-
gual feature and analysis space. Adherence to fea-
ture committee decisions is supported technically
by a routine that checks the grammars for com-
patibility with a feature declaration (King et al,
2005); the feature space for each grammar is in-
cluded in ParGramBank. ParGram also conducts
regular meetings to discuss constructions, analy-
ses and features.
For example, Figure 1 shows the c-structure
of the Urdu sentence in (1) and the c-structure
of its English translation. Figure 2 shows the f-
structures for the same sentences. The left/upper
c- and f-structures show the parse from the En-
glish ParGram grammar, the right/lower ones from
Urdu ParGram grammar.4,5 The c-structures en-
code linear word order and constituency and thus
look very different; e.g., the English structure is
rather hierarchical while the Urdu structure is flat
(Urdu is a free word-order language with no evi-
dence for a VP; Butt (1995)). The f-structures, in
contrast, are parallel aside from grammar-specific
characteristics such as the absence of grammati-
cal gender marking in English and the absence of
articles in Urdu.6
(1) ? Aj J
K. Q?K
QK A 	JK @ ?

	
G
	
?A??
kisAn=nE apnA
farmer.M.Sg=Erg self.M.Sg
TrEkTar bEc-A
tractor.M.Sg sell-Perf.M.Sg
?Did the farmer sell his tractor??
With parallel analyses and parallel features, maxi-
mal parallelism across typologically different lan-
guages is maintained. As a result, during the con-
struction of the treebank, post-processing and con-
version efforts are kept to a minimum.
4The Urdu ParGram grammar makes use of a translitera-
tion scheme that abstracts away from the Arabic-based script;
the transliteration scheme is detailed in Malik et al (2010).
5In the c-structures, dotted lines indicate distinct func-
tional domains; e.g., in Figure 1, the NP the farmer and the
VP sell his tractor belong to different f-structures: the former
maps onto the SUBJ f-structure, while the latter maps onto the
topmost f-structure (Dyvik et al, 2009). Section 6 elaborates
on functional domains.
6The CASE feature also varies: since English does not
distinguish between accusative, dative, and other oblique
cases, the OBJ is marked with a more general obl CASE.
Figure 1: English and Urdu c-structures
We emphasize the fact that ParGramBank is
characterized by a maximally reliable, human-
controlled and linguistically deep parallelism
across aligned sentences. Generally, the result of
automatic sentence alignment procedures are par-
allel corpora where the corresponding sentences
normally have the same purported meaning as
intended by the translator, but they do not nec-
essarily match in terms of structural expression.
In building ParGramBank, conscious attention is
paid to maintaining semantic and constructional
parallelism as much as possible. This design fea-
ture renders our treebank reliable in cases when
the constructional parallelism is reduced even at f-
structure. For example, typological variation in the
presence or absence of finite passive constructions
represents a case of potential mismatch. Hungar-
ian, one of the treebank languages, has no produc-
tive finite passives. The most common strategy in
translation is to use an active construction with a
topicalized object, with no overt subject and with
3PL verb agreement:
(2) A fa?-t ki-va?g-t-a?k.
the tree-ACC out-cut-PAST-3PL
?The tree was cut down.?
In this case, a topicalized object in Hungarian has
to be aligned with a (topical) subject in English.
Given that both the sentence level and the phrase
level alignments are human-controlled in the tree-
bank (see sections 4 and 6), the greatest possible
parallelism is reliably captured even in such cases
of relative grammatical divergence.
553
Figure 2: Parallel English and Urdu f-structures
4 Treebank Design and Construction
For the initial seeding of the treebank, we focused
on 50 sentences which were constructed manu-
ally to cover a diverse range of phenomena (tran-
sitivity, voice alternations, interrogatives, embed-
ded clauses, copula constructions, control/raising
verbs, etc.). We followed Lehmann et al (1996)
and Bender et al (2011) in using coverage of
grammatical constructions as a key component for
grammar development. (3) lists the first 16 sen-
tences of the treebank. An expansion to 100 sen-
tences is scheduled for next year.
(3) a. Declaratives:
1. The driver starts the tractor.
2. The tractor is red.
b. Interrogatives:
3. What did the farmer see?
4. Did the farmer sell his tractor?
c. Imperatives:
5. Push the button.
6. Don?t push the button.
d. Transitivity:
7. The farmer gave his neighbor an old
tractor.
8. The farmer cut the tree down.
9. The farmer groaned.
e. Passives and traditional voice:
10. My neighbor was given an old tractor
by the farmer.
11. The tree was cut down yesterday.
12. The tree had been cut down.
13. The tractor starts with a shudder.
f. Unaccusative:
14. The tractor appeared.
g. Subcategorized declaratives:
15. The boy knows the tractor is red.
16. The child thinks he started the tractor.
The sentences were translated from English
into the other treebank languages. Currently, these
languages are: English, Georgian, German, Hun-
garian, Indonesian, Norwegian (Bokma?l), Polish,
Turkish, Urdu and Wolof. The translations were
done by ParGram grammar developers (i.e., expert
linguists and native speakers).
The sentences were automatically parsed with
ParGram grammars using XLE. Since the pars-
ing was performed sentence by sentence, our re-
sulting treebank is automatically aligned at the
sentence level. The resulting c- and f-structures
were banked in a database using the LFG Parse-
banker (Rose?n et al, 2009). The structures were
disambiguated either prior to banking using XLE
or during banking with the LFG Parsebanker and
its discriminant-based disambiguation technique.
The banked analyses can be exported and down-
loaded in a Prolog format using the LFG Parse-
banker interface. Within XLE, we automatically
convert the structures to a simple XML format and
make these available via ParGramBank as well.
The Prolog format is used with applications
which use XLE to manipulate the structures, e.g.
for further semantic processing (Crouch and King,
2006) or for sentence condensation (Crouch et al,
2004).
554
5 Challenges for Parallelism
We detail some challenges in maintaining paral-
lelism across typologically distinct languages.
5.1 Complex Predicates
Some languages in ParGramBank make extensive
use of complex predicates. For example, Urdu uses
a combination of predicates to express concepts
that in languages like English are expressed with
a single verb, e.g., ?memory do? = ?remember?,
?fear come? = ?fear?. In addition, verb+verb com-
binations are used to express permissive or as-
pectual relations. The strategy within ParGram is
to abstract away from the particular surface mor-
phosyntactic expression and aim at parallelism
at the level of f-structure. That is, monoclausal
predications are analyzed via a simple f-structure
whether they consist of periphrastically formed
complex predicates (Urdu, Figure 3), a simple
verb (English, Figure 4), or a morphologically de-
rived form (Turkish, Figure 5).
In Urdu and in Turkish, the top-level PRED
is complex, indicating a composed predicate. In
Urdu, this reflects the noun-verb complex predi-
cate sTArT kar ?start do?, in Turkish it reflects a
morphological causative. Despite this morphosyn-
tactic complexity, the overall dependency struc-
ture corresponds to that of the English simple verb.
(4) ?


?
f
A

KQ ? HPA

J ? ? ? Q

 ? K
Q

K P?

J K
 @P

X
DrAIvar TrEkTar=kO
driver.M.Sg.Nom tractor.M.Sg=Acc
sTArT kartA hE
start.M.Sg do.Impf.M.Sg be.Pres.3Sg
?The driver starts the tractor.?
(5) su?ru?cu? trakto?r-u? c?al?s?-t?r-?yor
driver.Nom tractor-Acc work-Caus-Prog.3Sg
?The driver starts the tractor.?
The f-structure analysis of complex predicates
is thus similar to that of languages which do not
use complex predicates, resulting in a strong syn-
tactic parallelism at this level, even across typo-
logically diverse languages.
5.2 Negation
Negation also has varying morphosyntactic sur-
face realizations. The languages in ParGramBank
differ with respect to their negation strategies.
Languages such as English and German use inde-
pendent negation: they negate using words such as
Figure 3: Complex predicate: Urdu analysis of (4)
Figure 4: Simple predicate: English analysis of (4)
adverbs (English not, German nicht) or verbs (En-
glish do-support). Other languages employ non-
independent, morphological negation techniques;
Turkish, for instance, uses an affix on the verb, as
in (6).
555
Figure 5: Causative: Turkish analysis of (5)
(6) du?g?me-ye bas-ma
button-Dat push-Neg.Imp
?Don?t push the button.?
Within ParGram we have not abstracted away
from this surface difference. The English not in
(6) functions as an adverbial adjunct that modifies
the main verb (see top part of Figure 6) and infor-
mation would be lost if this were not represented
at f-structure. However, the same cannot be said of
the negative affix in Turkish ? the morphological
affix is not an adverbial adjunct. We have there-
fore currently analyzed morphological negation as
adding a feature to the f-structure which marks the
clause as negative, see bottom half of Figure 6.
5.3 Copula Constructions
Another challenge to parallelism comes from co-
pula constructions. An approach advocating a uni-
form treatment of copulas crosslinguistically was
advocated in the early years of ParGram (Butt et
al., 1999b), but this analysis could not do justice to
the typological variation found with copulas. Par-
GramBank reflects the typological difference with
three different analyses, with each language mak-
ing a language-specific choice among the three
possibilities that have been identified (Dalrymple
et al, 2004; Nordlinger and Sadler, 2007; Attia,
2008; Sulger, 2011; Laczko?, 2012).
The possible analyses are demonstrated here
with respect to the sentence The tractor is red.
The English grammar (Figure 7) uses a raising ap-
proach that reflects the earliest treatments of cop-
ulas in LFG (Bresnan, 1982). The copula takes
a non-finite complement whose subject is raised
to the matrix clause as a non-thematic subject of
the copula. In contrast, in Urdu (Figure 8), the
Figure 6: Different f-structural analyses for nega-
tion (English vs. Turkish)
copula is a two-place predicate, assigning SUBJ
and PREDLINK functions. The PREDLINK function
is interpreted as predicating something about the
subject. Finally, in languages like Indonesian (Fig-
ure 9), there is no overt copula and the adjective is
the main predicational element of the clause.
Figure 7: English copula example
556
Figure 8: Urdu copula example
Figure 9: Indonesian copula example
5.4 Summary
This section discussed some challenges for main-
taining parallel analyses across typologically di-
verse languages. Another challenge we face is
when no corresponding construction exists in a
language, e.g. with impersonals as in the English
It is raining. In this case, we provide a translation
and an analysis of the structure of the correspond-
ing translation, but note that the phenomenon be-
ing exemplified does not actually exist in the lan-
guage. A further extension to the capabilities of
the treebank could be the addition of pointers from
the alternative structure used in the translation to
the parallel aligned set of sentences that corre-
spond to this alternative structure.
6 Linguistically Motivated Alignment
The treebank is automatically aligned on the sen-
tence level, the top level of alignment within Par-
GramBank. For phrase-level alignments, we use
the drag-and-drop alignment tool in the LFG Parse-
banker (Dyvik et al, 2009). The tool allows the
alignment of f-structures by dragging the index
of a subsidiary source f-structure onto the index
of the corresponding target f-structure. Two f-
structures correspond if they have translationally
matching predicates, and the arguments of each
predicate correspond to an argument or adjunct in
the other f-structure. The tool automatically com-
putes the alignment of c-structure nodes on the
basis of the manually aligned corresponding f-
structures.7
7Currently we have not measured inter-annotator agree-
ment (IAA) for the f-structure alignments. The f-structure
alignments were done by only one person per language pair.
We anticipate that multiple annotators will be needed for this
This method is possible because the c-structure
to f-structure correspondence (the ? relation) is
encoded in the ParGramBank structures, allow-
ing the LFG Parsebanker tool to compute which c-
structure nodes contributed to a given f-structure
via the inverse (??1) mapping. A set of nodes
mapping to the same f-structure is called a ?func-
tional domain?. Within a source and a target
functional domain, two nodes are automatically
aligned only if they dominate corresponding word
forms. In Figure 10 the nodes in each func-
tional domain in the trees are connected by whole
lines while dotted lines connect different func-
tional domains. Within a functional domain, thick
whole lines connect the nodes that share align-
ment; for simplicity the alignment is only indi-
cated for the top nodes. The automatically com-
puted c-structural alignments are shown by the
curved lines. The alignment information is stored
as an additional layer and can be used to ex-
plore alignments at the string (word), phrase (c-
)structure, and functional (f-)structure levels.
We have so far aligned the treebank pairs
English-Urdu, English-German, English-Polish
and Norwegian-Georgian. As Figure 10 illustrates
for (7) in an English-Urdu pairing, the English ob-
ject neighbor is aligned with the Urdu indirect ob-
ject (OBJ-GO) hamsAyA ?neighbor?, while the En-
glish indirect object (OBJ-TH) tractor is aligned
with the Urdu object TrEkTar ?tractor?. The c-
structure correspondences were computed auto-
matically from the f-structure alignments.
(7) AK
X Q?K
QK A 	K @QK ?? ?
G
A???f ?

	
?K @ ?

	
G
	
?A??
kisAn=nE apnE
farmer.M.Sg=Erg self.Obl
hamsAyE=kO purAnA
neighbor.M.Sg.Obl=Acc old.M.Sg
TrEkTar di-yA
tractor.M.Sg give-Perf.M.Sg
?The farmer gave his neighbor an old tractor.?
The INESS platform additionally allows for the
highlighting of connected nodes via a mouse-over
technique. It thus provides a powerful and flexible
tool for the semi-automatic alignment and subse-
task in the future, in which case we will measure IAA for this
step.
557
Figure 10: Phrase-aligned treebank example English-Urdu: The farmer gave his neighbor an old tractor.
quent inspection of parallel treebanks which con-
tain highly complex linguistic structures.8
7 Discussion and Future Work
We have discussed the construction of ParGram-
Bank, a parallel treebank for ten typologically
different languages. The analyses in ParGram-
Bank are the output of computational LFG Par-
Gram grammars. As a result of ParGram?s cen-
trally agreed upon feature sets and prototypical
analyses, the representations are not only deep
in nature, but maximally parallel. The representa-
tions offer information about dependency relations
as well as word order, constituency and part-of-
speech.
In future ParGramBank releases, we will pro-
vide more theory-neutral dependencies along with
the LFG representations. This will take the form of
triples (King et al, 2003). We also plan to provide
a POS-tagged and a named entity marked up ver-
sion of the sentences; these will be of use for more
general NLP applications and for systems which
use such markup as input to deeper processing.
8One reviewer inquires about possibilities of linking
(semi-)automatically between languages, for example using
lexical resources such as WordNets or Panlex. We agree that
this would be desirable, but unrealizable, since many of the
languages included in ParGramBank do not have a WordNet
resource and are not likely to achieve an adequate one soon.
Third, the treebank will be expanded to include
100 more sentences within the next year. We also
plan to include more languages as other ParGram
groups contribute structures to ParGramBank.
ParGramBank, including its multilingual sen-
tences and all annotations, is made freely avail-
able for research and commercial use under the
CC-BY 3.0 license via the INESS platform, which
supports alignment methodology developed in the
XPAR project and provides search and visualiza-
tion methods for parallel treebanks. We encourage
the computational linguistics community to con-
tribute further layers of annotation, including se-
mantic (Crouch and King, 2006), abstract knowl-
edge representational (Bobrow et al, 2007), Prop-
Bank (Palmer et al, 2005), or TimeBank (Mani
and Pustejovsky, 2004) annotations.
References
Mohammed Attia. 2008. A Unified Analysis of Cop-
ula Constructions. In Proceedings of the LFG ?08
Conference, pages 89?108. CSLI Publications.
Emily M. Bender, Dan Flickinger, and Stephan Oepen.
2011. Grammar Engineering and Linguistic Hy-
pothesis Testing: Computational Support for Com-
plexity in Syntactic Analysis. In Emily M. Bender
and Jennifer E. Arnold, editors, Languages from a
Cognitive Perspective: Grammar, Usage and Pro-
cessing, pages 5?30. CSLI Publications.
558
Daniel G. Bobrow, Cleo Condoravdi, Dick Crouch,
Valeria de Paiva, Lauri Karttunen, Tracy Holloway
King, Rowan Nairn, Lottie Price, and Annie Zaenen.
2007. Precision-focused Textual Inference. In Pro-
ceedings of the ACL-PASCAL Workshop on Textual
Entailment and Paraphrasing.
Cristina Bosco, Manuela Sanguinetti, and Leonardo
Lesmo. 2012. The Parallel-TUT: a multilingual and
multiformat treebank. In Proceedings of the Eighth
International Conference on Language Resources
and Evaluation (LREC-2012), pages 1932?1938, Is-
tanbul, Turkey. European Language Resources As-
sociation (ELRA).
Joan Bresnan. 1982. The Passive in Lexical Theory. In
Joan Bresnan, editor, The Mental Representation of
Grammatical Relations, pages 3?86. The MIT Press.
Joan Bresnan. 2001. Lexical-Functional Syntax.
Blackwell Publishing.
Miriam Butt, Stefanie Dipper, Anette Frank, and
Tracy Holloway King. 1999a. Writing Large-
Scale Parallel Grammars for English, French and
German. In Proceedings of the LFG99 Conference.
CSLI Publications.
Miriam Butt, Tracy Holloway King, Mar??a-Eugenia
Nin?o, and Fre?de?rique Segond. 1999b. A Grammar
Writer?s Cookbook. CSLI Publications.
Miriam Butt, Helge Dyvik, Tracy Holloway King, Hi-
roshi Masuichi, and Christian Rohrer. 2002. The
Parallel Grammar Project. In Proceedings of the
COLING-2002 Workshop on Grammar Engineering
and Evaluation, pages 1?7.
Miriam Butt. 1995. The Structure of Complex Predi-
cates in Urdu. CSLI Publications.
Noam Chomsky. 1988. Lectures on Government and
Binding: The Pisa Lectures. Foris Publications.
Noam Chomsky. 1995. The Minimalist Program. MIT
Press.
Dick Crouch and Tracy Holloway King. 2006. Seman-
tics via F-structure Rewriting. In Proceedings of the
LFG06 Conference, pages 145?165. CSLI Publica-
tions.
Dick Crouch, Tracy Holloway King, John T. Maxwell
III, Stefan Riezler, and Annie Zaenen. 2004. Ex-
ploiting F-structure Input for Sentence Condensa-
tion. In Proceedings of the LFG04 Conference,
pages 167?187. CSLI Publications.
Dick Crouch, Mary Dalrymple, Ronald M. Kaplan,
Tracy Holloway King, John T. Maxwell III, and
Paula Newman, 2012. XLE Documentation. Palo
Alto Research Center.
Mary Dalrymple, Helge Dyvik, and Tracy Holloway
King. 2004. Copular Complements: Closed or
Open? In Proceedings of the LFG ?04 Conference,
pages 188?198. CSLI Publications.
Mary Dalrymple. 2001. Lexical Functional Gram-
mar, volume 34 of Syntax and Semantics. Academic
Press.
Helge Dyvik, Paul Meurer, Victoria Rose?n, and Koen-
raad De Smedt. 2009. Linguistically Motivated Par-
allel Parsebanks. In Proceedings of the Eighth In-
ternational Workshop on Treebanks and Linguistic
Theories (TLT8), pages 71?82, Milan, Italy. EDU-
Catt.
Dan Flickinger, Valia Kordoni, Yi Zhang, Anto?nio
Branco, Kiril Simov, Petya Osenova, Catarina Car-
valheiro, Francisco Costa, and Se?rgio Castro. 2012.
ParDeepBank: Multiple Parallel Deep Treebank-
ing. In Proceedings of the 11th International Work-
shop on Treebanks and Linguistic Theories (TLT11),
pages 97?107, Lisbon. Edic?o?es Colibri.
Tracy Holloway King, Richard Crouch, Stefan Riezler,
Mary Dalrymple, and Ronald Kaplan. 2003. The
PARC700 Dependency Bank. In Proceedings of the
EACL03: 4th International Workshop on Linguisti-
cally Interpreted Corpora (LINC-03).
Tracy Holloway King, Martin Forst, Jonas Kuhn, and
Miriam Butt. 2005. The Feature Space in Paral-
lel Grammar Writing. In Emily M. Bender, Dan
Flickinger, Frederik Fouvry, and Melanie Siegel, ed-
itors, Research on Language and Computation: Spe-
cial Issue on Shared Representation in Multilingual
Grammar Engineering, volume 3, pages 139?163.
Springer.
Natalia Klyueva and David Marec?ek. 2010. To-
wards a Parallel Czech-Russian Dependency Tree-
bank. In Proceedings of the Workshop on Anno-
tation and Exploitation of Parallel Corpora, Tartu.
Northern European Association for Language Tech-
nology (NEALT).
Jonas Kuhn and Michael Jellinghaus. 2006. Multilin-
gual Parallel Treebanking: A Lean and Flexible Ap-
proach. In Proceedings of the LREC 2006, Genoa,
Italy. ELRA/ELDA.
Tibor Laczko?. 2012. On the (Un)Bearable Lightness
of Being an LFG Style Copula in Hungarian. In Pro-
ceedings of the LFG12 Conference, pages 341?361.
CSLI Publications.
Sabine Lehmann, Stephan Oepen, Sylvie Regnier-
Prost, Klaus Netter, Veronika Lux, Judith Klein,
Kirsten Falkedal, Frederik Fouvry, Dominique Esti-
val, Eva Dauphin, Herve? Compagnion, Judith Baur,
Lorna Balkan, and Doug Arnold. 1996. TSNLP ?
Test Suites for Natural Language Processing. In
Proceedings of COLING, pages 711 ? 716.
Muhammad Kamran Malik, Tafseer Ahmed, Sebastian
Sulger, Tina Bo?gel, Atif Gulzar, Ghulam Raza, Sar-
mad Hussain, and Miriam Butt. 2010. Transliter-
ating Urdu for a Broad-Coverage Urdu/Hindi LFG
Grammar. In Proceedings of the Seventh Con-
ference on International Language Resources and
Evaluation (LREC 2010), Valletta, Malta.
559
Inderjeet Mani and James Pustejovsky. 2004. Tem-
poral Discourse Models for Narrative Structure. In
Proceedings of the 2004 ACL Workshop on Dis-
course Annotation, pages 57?64.
Bea?ta Megyesi, Bengt Dahlqvist, E?va A?. Csato?, and
Joakim Nivre. 2010. The English-Swedish-Turkish
Parallel Treebank. In Proceedings of the Seventh
International Conference on Language Resources
and Evaluation (LREC?10), Valletta, Malta. Euro-
pean Language Resources Association (ELRA).
Tahira Naseem, Regina Barzilay, and Amir Globerson.
2012. Selective Sharing for Multilingual Depen-
dency Parsing. In Proceedings of the 50th Annual
Meeting of the Association for Computational Lin-
guistics (Volume 1: Long Papers), pages 629?637,
Jeju Island, Korea, July. Association for Computa-
tional Linguistics.
Joakim Nivre, Igor Boguslavsky, and Leonid Iomdin.
2008. Parsing the SynTagRus Treebank. In Pro-
ceedings of COLING08, pages 641?648.
Rachel Nordlinger and Louisa Sadler. 2007. Verb-
less Clauses: Revealing the Structure within. In An-
nie Zaenen, Jane Simpson, Tracy Holloway King,
Jane Grimshaw, Joan Maling, and Chris Manning,
editors, Architectures, Rules and Preferences: A
Festschrift for Joan Bresnan, pages 139?160. CSLI
Publications.
Martha Palmer, Daniel Gildea, and Paul Kingsbury.
2005. The Proposition Bank: An Annotated Cor-
pus of Semantic Roles. Computational Linguistics,
31(1):71?106.
Martin Popel and Zdene?k Z?abokrtsky?. 2010. Tec-
toMT: Modular NLP Framework. In Proceedings
of the 7th International Conference on Advances in
Natural Language Processing (IceTAL 2010), pages
293?304.
Victoria Rose?n, Paul Meurer, and Koenraad de Smedt.
2009. LFG Parsebanker: A Toolkit for Building and
Searching a Treebank as a Parsed Corpus. In Pro-
ceedings of the 7th International Workshop on Tree-
banks and Linguistic Theories (TLT7), pages 127?
133, Utrecht. LOT.
Victoria Rose?n, Koenraad De Smedt, Paul Meurer, and
Helge Dyvik. 2012. An Open Infrastructure for Ad-
vanced Treebanking. In META-RESEARCH Work-
shop on Advanced Treebanking at LREC2012, pages
22?29, Istanbul, Turkey.
Manuela Sanguinetti and Cristina Bosco. 2011. Build-
ing the Multilingual TUT Parallel Treebank. In Pro-
ceedings of Recent Advances in Natural Language
Processing, pages 19?28.
Sebastian Sulger. 2011. A Parallel Analysis of have-
Type Copular Constructions in have-Less Indo-
European Languages. In Proceedings of the LFG
?11 Conference. CSLI Publications.
Josef van Genabith and Dick Crouch. 1996. Direct and
Underspecified Interpretations of LFG f-structures.
In Proceedings of the 16th International Conference
on Computational Linguistics (COLING-96), vol-
ume 1, pages 262?267, Copenhagen, Denmark.
Martin Volk, Anne Go?hring, Torsten Marek,
and Yvonne Samuelsson. 2010. SMUL-
TRON (version 3.0) ? The Stock-
holm MULtilingual parallel TReebank.
http://www.cl.uzh.ch/research/paralleltreebanks en.
html.
560
Proceedings of the 2010 Workshop on NLP and Linguistics: Finding the Common Ground, ACL 2010, pages 70?78,
Uppsala, Sweden, 16 July 2010. c?2010 Association for Computational Linguistics
Consonant Co-occurrence in Stems Across Languages: Automatic
Analysis and Visualization of a Phonotactic Constraint
Thomas Mayer1, Christian Rohrdantz2, Frans Plank1,
Peter Bak2, Miriam Butt1, Daniel A. Keim2
1Department of Linguistics, 2Department of Computer Science
University of Konstanz, Germany
{thomas.mayer,christian.rohrdantz}@uni-konstanz.de
Abstract
In this paper, we explore the phenomenon
of Similar Place Avoidance (SPA), ac-
cording to which successive consonants
within stems sharing the same place of
articulation are avoided. This principle
has recently been hypothesized as a uni-
versal tendency although evidence from
only a few languages scattered across the
world has been considered. Using meth-
ods taken from the field of Visual Analyt-
ics, which have demonstrably been shown
to help with understanding complex in-
teractions across large data sets, we in-
vestigated a large crosslinguistic lexical
database (comprising data on more than
4,500 languages) and found that a univer-
sal tendency can indeed be maintained.
1 Introduction
Linguistic knowledge has traditionally been ac-
quired by analyzing a manageable set of data, on
the basis of which generalizations are posited that
can then be tested on an extended set of data from
the same language or comparative data from other
languages. Tendencies, rather than absolute prin-
ciples, are difficult to detect under this approach.
This is true especially when they are obscured by
counterexamples that happen to occur with high
frequency, but that may be restricted to just a
small minority of the overall pattern. This may
prompt a researcher to discard a valid generaliza-
tion from the outset. In recent years, a plethora of
statistical and stochastic methods have therefore
been pursued within linguistic research, leading to
approaches such as stochastic Optimality Theory
(Boersma and Hayes, 2001) or the use of statis-
tics to detect crosslinguistic tendencies (Bickel, in
press).
However, although the various statistical meth-
ods deal with data which exhibit very complex and
often ill-understood interactions, analyses have
not to date availed themselves of methodology
currently being developed in the field of Visual
Analytics, which allows us to use our powerful vi-
sual processing ability to understand and evaluate
complex data sets (Keim et al, 2008; Thomas and
Cook, 2005).
In this paper, we present an interdisciplinary
effort whereby linguistically interesting patterns
are automatically extracted, analyzed and visually
presented so that an at-a-glance evaluation of lin-
guistically significant patterns is made possible. In
order to demonstrate that this technique is espe-
cially useful with phenomena that do not mani-
fest themselves in absolute principles, but rather
in statistical tendencies, we investigated a phe-
nomenon that, on the basis of a comparatively
sparse and unrepresentative data set, has recently
been claimed to be a universal tendency (Pozdni-
akov and Segerer, 2007): Similar Place Avoidance
(SPA). In this paper, we conduct a more represen-
tative study of about 4,500 languages. Our results
allow an at-a-glance evaluation which shows that
SPA indeed seems to be a valid language universal
tendency.
Our work on SPA is part of a more widespread
effort currently being conducted with respect to vi-
sually representing crosslinguistic sound patterns.
In Rohrdantz et al (2010), we already showed that
phonological patterns in languages can be auto-
matically extracted and visualized from corpora.
Figure 1 displays the vowel harmony patterns that
were extracted for Turkish in comparison with the
lack of such patterns in a non-harmonic language
like Spanish.
The remainder of this article is organized as fol-
lows. Section 2 introduces SPA. Section 3 pro-
vides an overview of the material that was used. A
description of the calculations and statistical anal-
yses is given in Section 4. Section 5 presents
the results of the geo-spatial visualizations, partly
70
Figure 1: Turkish vowel harmony patterns (left).
The matrix visualizaton was generated on the
basis of the Turkish Bible text and shows the
palatal (front/back) and labial (rounding) harmony
blocks. Rows and columns are automatically
sorted according to the similarity of vowels. For
non-harmonic languages, such as Spanish (right),
no such patterns can be detected.
with respect to a WALS map (Haspelmath et al,
2005). In the final section, we consider some im-
plications of our findings and raise some questions
for future research.
2 Similar Place Avoidance (SPA)
It has long been noted in studies on Semitic lan-
guages, especially Arabic, that there are con-
straints on the structure of triliteral consonant
roots (
?
CCC) with respect to the phonological
features of the individual consonants (Greenberg,
1950). The basic observation is that consonants
with a similar place of articulation are avoided
in non-derived forms. A similar observation has
also been made with respect to the Proto-Indo-
European (PIE) roots. Among other things, Iver-
son and Salmons (1992) note that Stop-V-Stop
roots were very rare in PIE, representing only
3.5% of a lexicon of more than 2,000 items. Plank
(1981:221f) observes that Modern German tends
to avoid verbal stems with identical consonants
in initial and final positions (allowing for differ-
ences in voicing), and that those verbs with iden-
tical initial and final consonants which do exist
are all morphologically regular. This indicates that
they are not basic verbs, but represent a technique
of word formation, perhaps derivative of redupli-
cation as especially common in child or child-
directed language.1
1Note that the early speech of children is characterized by
the opposite effect of SPA: both consonants and vowels tend
to share the same place of articulation (Fikkert and Levelt,
2010), with greater and greater differentiation being achieved
in the course of language acquisition. The reasons for this
remain to be investigated.
Looking at suprasegmental features, Leben
(1973) argued that a similar restriction holds for
the co-occurrence of tones in underlying repre-
sentations. In the framework of Autosegmental
Phonology this has become known as the Oblig-
atory Contour Principle (OCP), which precludes
sequences of identical tones from underlying rep-
resentations. This principle has since been under-
stood more generally as a prohibition on similar
items and has thus also been used in relation with
the SPA bias in Semitic radicals.
More recently, the application of SPA with
respect to stem-internal consonants has been
claimed for other non-Semitic languages as well.
Pozdniakov and Segerer (2007) found impres-
sive support for it in their sample of Atlantic
and Bantu languages of Niger-Congo and fur-
ther tested its crosslinguistic validity for some
more languages or language groups (Mande, Kwa,
Ubangi, Sara-Bongo-Bagirmi, Chadic, Malagasy,
Indo-European, Nostratic, Mongolian, Basque,
Quechua, Kamilaroi, Port Moresby Pidgin En-
glish) with similar results. Table 1 shows their
findings across all 31 languages in their sample.
It can be seen that the highest negative numbers
are in the main diagonal of the matrix, which is
exactly what SPA would predict.
P T C K
P ?15 +11 +5 ?5
T +12 ?10 ?5 +13
C +8 ?5 ?6 +8
K ?3 +8 +5 ?15
Table 1: Results in Pozdniakov and Segerer
(2007). The numbers indicate the overall sum of
cells with negative vs. positive values with regard
to successions of places of articulation (see Sec-
tion 3 for a description of the labels P, T, C and K)
for all languages in their sample. Positive and neg-
ative values have been assigned if the observed ab-
solute value was at least 15% above (respectively
below) the expected value. Compare their results
with the left matrix in Figure 3.
3 Database and methodology
The data that underlies all the subsequent work
presented in this paper have been taken from the
Automated Similarity Judgment Program (ASJP;
Wichmann et al, 2010), which aims at achiev-
71
ing a computerized lexicostatistical analysis of the
world?s languages. To this end, Wichmann and his
collaborators have collected Swadesh list items for
over 4,500 languages. The so-called Swadesh list
was developed by Morris Swadesh in the 1940?
50s with the aim of having a basic set of vocabu-
lary items which are culturally neutral and which
one would expect to be stable over time. The orig-
inal idea of a Swadesh list was to be able to com-
pare and test languages with respect to genealogi-
cal relations.
The Swadesh items in the Wichmann et al
database are transcribed in the ASJP orthogra-
phy, which uses standard ASCII characters to en-
code the sounds of the world?s languages, but does
merge some of the distinctions made by the IPA.
Furthermore, stress, tone and vowel length are not
recorded in the database. However, for the pur-
pose of our investigation the transcription is suit-
able because place of articulation is sufficiently
distinguished.
We decided to experiment with two different ap-
proaches for dividing up the place of articulation
features. One approach (PTCK) is based on the ar-
rangement in Pozdniakov and Segerer (2007) and
distinguishes four places of articulation for labial
(P), dental (and alveolar) (T), (alveo-)palatal (C)
and velar (K) consonants. A second grouping
(LCD) only distinguishes three places of articula-
tion: labial (L), coronal (C) and dorsal (D).2 Ac-
cording to this classification the consonants of all
the items in the database can be assigned to one of
these symbols, as shown in Table 2.
LCD PTCK ASJP IPA
L P
p, b, m, f, v, w p, F, b, B, m,
f, v, w
C
T
8, 4, t, d, s, z,
c, n, S, Z
T, D, n
?
, t, d, s,
z, ts, dz, n, S,
Z
C
C, j, T, l, L, r,
y
?, ?, c, ?, l, L,
?, L, r, R, j
D K
5, k, g, x, N,
q, G, X, 7, h
?, k, g, x, G, N,
q, G, X, K, ?,
Q, P, h, H,
Table 2: Assignment of consonants to symbols.
All varieties of ?click?-sounds have been ignored.
2Radical and laryngeal, which are commonly employed
in the phonological literature as yet another place distinction,
are subsumed under dorsal.
Experiments with using the four-way distinc-
tion vs. the three-way distinction showed that T
and C in the four-way grouping behave very simi-
larly with respect to the transitions to other places
of articulation (see Section 4.2). We therefore de-
cided to use the three-way distinction for the bulk
of our calculations and visualizations and only
sporadically resort to the four-way grouping when
a more fine-grained distinction is needed.
Furthermore, we decided to only include those
cases where the first and second consonants are
preceded (or followed, respectively) by another
vowel or a word boundary and are therefore not
part of a consonant cluster. We mainly did this in
order to minimize the noise caused by consonants
of inflectional markers that tend to assimilate in
such clusters.
In the literature on root morphemes in Semitic,
it has been noted that the consonants within trilit-
eral radicals behave differently with respect to
OCP. Greenberg (1950:162) remarks that while
the first and second consonants are usually not
identical, the same does not hold for the sec-
ond and third consonants, which frequently consti-
tute the well-known geminate subtype of Semitic
verbs. However, for our work we understand OCP
as it was later formulated within the framework
of autosegmental phonology (Leben, 1973; Mc-
Carthy, 1986; Goldsmith, 1976) in that adjacent
identical elements (here in the sense of identical
with respect to place of articulation) are prohib-
ited, under the assumption that consonants are ad-
jacent to each other (on the C tier) even when they
are separated by vowels in the linear sequence of
phonemes within the word.
For the purposes of our experiment, we con-
sidered the relevant context for adjacency to be
one where consonants are separated by exactly one
vowel.3 Note that since the basis for our calcula-
tions were not stems in the language but the cita-
tion forms that are used in the Swadesh lists, we
also get noise from inflectional markers that are
attached to these forms and might have the same
place of articulation irrespective of the stem to
which they attach.4
Finally, there are several shortcomings of the
3Since vowel length is not marked in the ASJP database,
long vowels are also included.
4Assimilation processes are far more frequent than dis-
similation processes in this context so that it is more likely
that the same place of articulation features are to be expected
when an inflectional marker is present.
72
material in the database with respect to our investi-
gation which must be kept in mind. OCP/SPA has
been claimed to apply with respect to underlying
or non-derived representations. Previous work has
been done on the basis of stem (or root) lists. De-
pending on the language, Swadesh list items are
not always stems, but whole words in their cita-
tion forms. For instance, while both English and
German use the infinitive as the citation form for
verbal stems, in English the infinitive is identical
to the stem whereas in German it is marked with
the suffix -en. In other languages, verbs can also
be cited by inflected forms other than the infinitive
(e.g., the 3rd person singular perfective in Arabic,
or the first person singular indicative present in
Latin). The same holds for nouns or other word
classes that are included in the Swadesh list. An-
other problematic aspect is the fact that it also con-
tains items (such as personal pronouns) that are
not lexical in the strict sense of the meaning and
are realized as bound forms in many languages.
Apart from that, the number of items for each
language in the ASJP database varied greatly from
only a few to one hundred. Moreover, the num-
ber of CVC sequences within the items differed
greatly from one language to another, depending
on the phonotactic properties of the languages.
Previous statistical studies have relied on a much
larger number of stems and consonant sequences.
Pozdniakov and Segerer?s (2007) statistics, for ex-
ample, were calculated on the basis of 495 to
17,944 CVC successions for the languages in their
sample.5 In contrast, our statistics are based on
much fewer CVC successions, ranging from 21 to
246 per language. Nevertheless, our results actu-
ally correspond to the main findings of their study
so that we think that the data are good enough for
our purposes.
4 Automated statistical analysis
4.1 Methodology
In a first step, for each language in the sample
an elementary statistical processing is performed.
Thereby, all successions of places of articulation
occurring in the Swadesh list items are identified
and counted. To do so, we define a succession of
5Note that they also included cases where the first and
second consonant are part of a consonant cluster, which we
ignored for our calculations. Furthermore, those languages
where the number of consonant successions in the data was
20 or below were not included in our visualizations, thereby
reducing the number of languages from about 4,500 to 3,200.
places of articulation as a binary sequence of con-
sonants (C-C). These consonants have to appear
within a word and have to be separated by exactly
one vowel (V). Before and after the succession ei-
ther word boundaries (#) or vowels have to ap-
pear. Hence, the following regular expression is
used to extract C-C successions (marked in bold):
[#|V ]CV C[#|V ]. Next, each consonant is as-
signed to one of the three major articulation place
categories labial, coronal and dorsal. The succes-
sion counts are summarized in a quadratic matrix
where the rows represent the preceding place of ar-
ticulation and the columns the following place of
articulation. Each matrix cell contains the number
of times the respective place of articulation suc-
cession could be observed in the corpus. Subse-
quently, for each of the 9 possible successions a
contingency table was created (Table 3).
P2 ?P2
P1 A : n(P1 ? P2) B: n(P1 ? ?P2)
?P1 C : n(?P1 ? P2) D : n(?P1 ? ?P2)
Table 3: Contingency table for the articulation
place (P) succession from P1 to P2.
The succession counts were used to calculate ?
coefficients, where A,B,C and D correspond to
the four cells in Table 3.
? =
?
?2
(A+B + C +D)
(1)
The ? coefficient is a measure for the degree
of association between two variables which can
be derived from the fourfold ?2 statistical signif-
icance test (see Rummel, 1970:298f for details).
Sample ? values for the place of articulation suc-
cessions of Egyptian Arabic can be seen in Table
4. A visual representation of the same matrix is
provided in Figure 2. Note the at-a-glance analy-
sis made possible by Figure 2 vs. Table 4.
labial coronal dorsal
labial ?0.360 +0.187 +0.183
coronal +0.259 ?0.243 ?0.068
dorsal ?0.010 +0.097 ?0.121
Table 4: Matrix of ? values for Egyptian Arabic.
Figure 2 shows an example in which all diag-
onal values (self-successions of places of articu-
lation) have negative associations. This tendency
73
Figure 2: Visualization of the ? matrix from Ta-
ble 4 (Egyptian Arabic), L stands for labial, C for
coronal and D for dorsal. It can be seen that all di-
agonal values (successions of the same place of ar-
ticulation) have negative associations (red color).
to alternate places of articulation can be observed
in most languages and in the overall matrix visu-
alizations including all data from all languages in
the database (Figure 4).
4.2 General relations among places of
articulation
As already mentioned, we tested whether it is use-
ful to distinguish the two different subcategories
dental (and alveolar) (T), and (alveo-)palatal (C).
Figure 3 shows the resulting association values ?
of place successions.
It can clearly be seen that T and C behave very
similarly. A further interesting observation is that
places of articulation tend to alternate (negative di-
agonal values for self-successions). As revealed in
the succession graph of Figure 3, the places of ar-
ticulation do not remain the same, but change to
the closest alternative(s). In the case of P and K
the closest distinct places of articulation (T and C)
are preferred. In the case of T and C, however, this
is somewhat different. Apparently, direct alterna-
tions between both are less probable. One plau-
sible explanation could be that they are not dis-
tinct enough and thus either K or P are preferred
as a following place of articulation, both having
roughly the same distance. These observations
led us to merge the places T and C in our further
analyses and distinguish labial, coronal and dorsal
consonants only, as in Figure 4.
Note that the cross pattern on the left in Figure
4, which now emerges very clearly, reinforces the
hypothesis that the closest distinct place of articu-
lation is preferred as successor.
Figure 4: The ? matrix considering only the three
main categories for all the data across languages.
In the left figure, the categories are sorted accord-
ing to their position in the oral cavity. In the
right figure, the categories are sorted automati-
cally, which shows that D and L are more similar
to each other than D and C.
4.3 Distribution across languages
Next, we examined the distribution of ? values for
self-successions of places of articulation in about
3,200 languages. Self-successions correspond to
the diagonal values of the ? matrices from the up-
per left to the lower right. As can be seen in the
histogram in Figure 6, the peak of the distribution
is clearly located in the area of negative associa-
tion values. In the box-plots of Figure 5, which
show the distributions for all three places of ar-
ticulation separately, it is clearly visible that for
each of the three places of articulation at least 75%
of the languages included show negative associa-
tions. Furthermore, it can be seen that most out-
liers disappear when taking only the languages for
which most data is available and thus statistics are
more reliable. The same can be seen in the scat-
ter plot in Figure 6, where the average ? value is
always negative if the number of successions ex-
ceeds a certain threshold. For all three categories,
the figures demonstrate that the same place of ar-
ticulation is generally less frequently maintained
than expected if there were no interdependencies
between consonant co-occurrences.
5 Visualization of geo-spatial patterns
The most common approach to visually represent
crosslinguistic information on areal (or genealog-
ical) patterns is to put each language as a single
pixel or a small icon to its location on a map.
For instance, the WALS database (Haspelmath et
al., 2005) includes 141 maps on diverse structural
(phonological, grammatical, lexical) properties of
languages. We transformed the results of our SPA
statistics for each language in the ASJP database
74
P
T C
K
Figure 3: Successions of P, T, C and K in all languages. The ?+? and ??? signs indicate the polarity
of a succession (going from row to column category). The color saturation of the background indicates
the strength of association. In the left figure, places of articulation are sorted according to their position
in the oral cavity, in the middle figure an automatic similarity sorting of matrix rows and columns was
applied. The right part of the figure shows an alternative view only on those successions that have a
positive association.
l
l
l
ll
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l l
l
l
l
l
l
ll
l
l
l
l
l
ll
l
l
l
lll
l
l
l
l
l
l
ll
l
l
l
l
l
l
Labial?Labial Coronal?Coronal Dorsal?Dorsal
?
1.0
?
0.5
0.0
0.5
1.0
Distribution of association values across languages (all)
ll
l
l
ll
Labial?Labial Coronal?Coronal Dorsal?Dorsal
?
1.0
?
0.5
0.0
0.5
1.0
Distribution of association values across languages (top)
Figure 5: Boxplots showing the distribution of association strength values (?) for self-successions of
places of articulation. For the left boxplots about 3,200 languages were considered for which the
Swadesh lists contained more than 20 successions. For the right boxplots only the top 99 languages
were considered for which the Swadesh lists contained at least 100 successions, thereby removing most
outliers and reducing the variance.
that is also included in the WALS database into a
WALS map (Figure 7). The matrix visualization
has been simplified in that the color of the icon
represents the number of cells in the diagonal of
the matrix whose value was below zero, i.e., the
higher the number (0-3) the better the language
conforms to SPA.
Some of the drawbacks of these maps include a
high degree of overlap of data points in densely
populated areas and the lack of correlation be-
tween information content and area size. In Figure
7, the fact that those languages with fewer negative
diagonal cells are plotted on top of those with a
higher number slightly distorts the overall picture
that most languages adhere to the principle.6 Be-
sides that, the overall pattern in the densely popu-
lated areas is hardly visible, while sparsely popu-
lated areas waste space and hide the informational
6Likewise, the visualization would suggest to much ad-
herence to the principle if those languages with more nega-
tive diagonal cells were plotted on top of those with fewer
negative cells.
75
ll
lll
l
ll
l
l
l
ll
l
l
l
ll
lll
l
l
l
l
l
l
l
l
l
l
l
l
lll
ll
l
l
l
l
lll
l
l
l
l
l
l
l
l
ll
l
l
ll
l
l
l
l
lll
ll
l
l
l
l
llll
l
ll
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
ll
l
ll
ll
lll
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
ll
l
ll
l
l
l
l
l
l
l
ll
l
ll
l
lll
l
l
lll
l
l
ll
ll
l
l
l
l
l
l
l
l
l
l
l
l
lll
ll
lll
l
l
l
l
l
ll
ll
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
ll
l
l
l
l
ll
l
l
l
l
l
ll
l
l
l
l
llll
l
l
lll
l
l
l
l
l
l
l
ll
ll
l
l
ll
l
lll
l
l
l
l
l
l
l
l
l
l
l
l
l
llll
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
lll
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
ll
l
ll
l
l
l
ll
l
l
l
l
l
l
l
l
ll
l
l
l
ll
ll
l
l
l
ll
l
lll
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
llll
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
ll
l
l
l
l
l
l
l
ll
l
l
ll
ll
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
ll
l
l
l
l
l
l
ll
l
l
l
l
l
ll
l
l
l
l
ll
l
ll
l
l
l
l
l
l
l
l
l
l
ll
lll
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
ll
l
l
l
ll
l
l
l
l
l
l
l
l
ll
l
l
l
ll
l
l
l
l
l
ll
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
ll
l
ll
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
lll
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
ll
l
l
ll
l
l
ll
l
lll
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
ll
l
l
l
ll
l
l
l
l
l
l
l
l
l
lll
l
l
l
l
ll
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
ll
l
ll
l
l
lll
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
llll
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
l
ll
ll
l
l
l
ll
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
ll
l
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
l
ll
l
l
50 100 150 200
?
0.4
?
0.2
0.0
0.2
0.4
Average phi values in dependence of data amount
Number of consonant successions in dataset
Ave
rage
 phi 
valu
e
Labial, Coronal and Dorsal
Distribution of association values for all self?successions across languages
Freq
uen
cy
?1.0 ?0.5 0.0 0.5 1.0
0
100
200
300
400
500
600
Figure 6: The scatter plot on the left displays the average ? values for self-successions of all places of
articulation depending on the number of consonant successions (CVC) for each language in the sample.
The histogram on the right shows the distribution of association strength values (?) for self-successions
of places of articulation in more than 3200 languages.
details. Finally, small clusters are difficult to find
? they are not noticeable, and are sometimes even
obscured by large clusters.
In order to avoid overlapping pixels we used
a circular arrangement around the original loca-
tion in the current analysis, taking the given order-
ing of elements into account (Bak et al, 2009a).
The ordering usually corresponds to the coloring
attribute starting with colors that occur least fre-
quently. With this arrangement a natural looking
visualization without artifacts is generated.
A way to obtain more space for regions with a
high point density are Cartograms, which distort
regions such that their size corresponds to a statis-
tical attribute (Bak et al, 2009b; Tobler, 2004), in
this case the number of languages in the database.
The advantage is that more space is reserved to
plot all important information on the map. In Fig-
ure 8, we show the density equalized distortion by
cartograms and the overlap-free representation of
the data points using pixel placement. Neighbor-
hood relations and region shapes are at the same
time maintained as accurately as possible in order
to guarantee recognizability despite of distortion.
The visualization reveals several clusters of non-
conforming languages (marked with boxes). It re-
mains for future work to investigate whether these
clusters are an artifact of the database that we used
or if they manifest an areal feature. Figure 8, in
contrast to Figure 7, shows the 3,200 languages
we investigated more closely and not just the ones
included in WALS.
The representation thereby enables investigat-
ing spatial patterns free of hidden data and distri-
butional biases.
6 Conclusions and future work
Our crosslinguistic investigation of SPA has con-
firmed the hypothesis that the phenomenon of
Similar Place Avoidance is not a particular trait
of Semitic languages, for which it was previously
described, but is a linguistic universal tendency
which can be observed in languages which are
both genealogically and geographically unrelated.
This can clearly be seen in the visualizations that
display the conformity of each language in the
database with respect to SPA. The overall pic-
ture for all languages not only shows that succes-
sive consonants with the same place of articulation
tend to be avoided, but also that there is a tendency
to avoid places of articulation that are too far away
from the preceding place (cf. Figures 3 and 4).
We combine methods from statistics, NLP and
Visual Analytics to provide a novel way of auto-
matically assessing and visualizing linguistic fea-
tures across a wide range of languages, thus al-
76
Figure 7: WALS map of the languages and their behavior with respect to SPA. The color indicates the
number of self-succession ? values which are negative, i.e., which adhere to the SPA principle. Color
mapping is from blue (conforming to SPA) to red. The numbers in square brackets indicate the number
of languages in this group.
Figure 8: Density equalized distribution of the languages with respect to SPA. The area of the geographic
regions corresponds to the number of languages in that location ? represented by dots. Overlap is avoided
using pixel-placement. The color mapping corresponds to the one used in the WALS map (Figure 7). Lo-
cations of nonconforming languages are highlighted with red boxes. Note that the number of languages
in this map is about twice the number in the WALS map (7).
77
lowing for a gain of new insights and raising fur-
ther interesting research questions that otherwise
might easily go unrecognized.
With respect to SPA a more detailed exploration
of the intricacies of phonological interdepencies is
needed as part of our more widespread study of
visually representing sound patterns in languages.
As already hinted at in Pozdniakov and Segerer
(2007), there are various other fascinating phe-
nomena that are worth looking at, especially in re-
gard to the interaction of vowels and consonants or
vowel dependencies (such as vowel harmony) and
consonant dependencies (such as SPA or conso-
nant harmony). In particular, one could investigate
why some languages apparently do not conform to
SPA and if there is any co-variation to be uncov-
ered between the adherence to the principle and
other factors that might be interesting to explore
and possibly reveal new insights into the structure
of languages.
Acknowledgments
This work has been funded by the research ini-
tiative ?Computational Analysis of Linguistic De-
velopment? at the University of Konstanz. The
authors would like to thank Aditi Lahiri and two
anonymous reviewers for valuable comments and
suggestions.
References
Peter Bak, Florian Mansmann, Halldor Janetzko, and
Daniel Keim. 2009a. Spatiotemporal analysis of
sensor logs using growth ring maps. IEEE Trans-
actions on Visualization and Computer Graphics,
15(6):913?920.
Peter Bak, Matthias Schaefer, Andreas Stoffel, Daniel
Keim, and Itzhak Omer. 2009b. Density equalizing
distortion of large geographic point sets. Journal of
Cartographic and Geographic Information Science
(CaGIS), 36(3):237?250.
Balthasar Bickel. in press. Absolute and statistical uni-
versals. In Patrick C. Hogan, editor, The Cambridge
Encyclopedia of the Language Sciences. Cambridge:
Cambridge University Press.
Paul Boersma and Bruce Hayes. 2001. Empirical tests
of the gradual learning algorithm. Linguistic In-
quiry, 32:45?86.
Paula Fikkert and Clara C. Levelt. 2010. How does
place fall into place? The lexicon and emergent con-
straints in the developing phonological grammar. In
Peter Avery, B. Elan Dresher, and Keren Rice, edi-
tors, Contrast in Phonology: Perception and Acqui-
sition. Berlin: Mouton de Gruyter.
John Goldsmith. 1976. Autosegmental phonology.
Ph.D. thesis, Massachusetts Institute of Technology.
Joseph H. Greenberg. 1950. The patterning of root
morphemes in Semitic. Word, 6:161?182.
Martin Haspelmath, Matthew S. Dryer, David Gil, and
Bernard Comrie. 2005. The World Atlas of Lan-
guage Structures Online. URL: http://wals.
info/.
Gregory K. Iverson and Joseph C. Salmonts. 1992.
The phonology of the Proto-Indo-European root
structure constraint. Lingua, 87:293?320.
Daniel A. Keim, Florian Mansmann, Joern Schnei-
dewind, Jim Thomas, and Hartmut Ziegler. 2008.
Visual analytics: Scope and challenges. In Visual
Data Mining: Theory, Techniques and Tools for Vi-
sual Analytics, Lecture Notes in Computer Science,
pages 76?91. Springer.
Wiliam R. Leben. 1973. Suprasegmental phonology.
Ph.D. thesis, Massachusetts Institute of Technology.
John J. McCarthy. 1986. OCP effects: Gemination and
antigemination. Linguistic Inquiry, 17:207?263.
Frans Plank. 1981. Morphologische (Ir-)Regularita?-
ten: Aspekte der Wortstrukturtheorie. Tu?bingen:
Gunter Narr Verlag.
Konstantin Pozdniakov and Guillaume Segerer. 2007.
Similar Place Avoidance: A statistical universal.
Linguistic Typology, 11(2):307?348.
Christian Rohrdantz, Thomas Mayer, Miriam Butt,
Frans Plank, and Daniel A. Keim. 2010. Compar-
ative visual analysis of cross-linguistic features. In
Proceedings of the International Symposium on Vi-
sual Analytics Science and Technology (EuroVAST
2010), pages 27?32.
Rudolph J. Rummel. 1970. Applied Factor Analysis.
Evanston, IL: Nortwestern University Press.
James J. Thomas and Kristin A. Cook. 2005. Illu-
minating the Path: The Research and Development
Agenda for Visual Analytics. National Visualization
and Analytics Ctr.
Waldo Tobler. 2004. Thirty five years of computer
cartograms. Association of American Geographer,
94(1):58?73.
78
Discovering Semantic Classes for Urdu N-V Complex Predicates
Tafseer Ahmed
Universita?t Konstanz
tafseer.khan@uni-konstanz.de
Miriam Butt
Universita?t Konstanz
miriam.butt@uni-konstanz.de
Abstract
This paper reports on an exploratory investigation as to whether classes of Urdu N-V com-
plex predicates can be identified on the basis syntactic patterns and lexical choices associated
with the N-V complex predicates. Working with data from a POS annotated corpus, we show
that choices with respect to the number of arguments, case marking on subjects and which
light verbs are felicitous with which nouns depend heavily on the semantics of the noun in
the N-V complex predicate. This initial work represents an important step towards identi-
fying semantic criteria relevant for complex predicate formation. Identifying the semantic
criteria and being able to systematically code them in turn represents a first step towards
building up a lexical resource for nouns as part of developing natural language processing
tools for the underresourced South Asian language Urdu.
1 Introduction
Urdu is an Indo-Aryan South Asian language spoken primarily in Pakistan and India. It is structurally al-
most identical to Hindi and together Urdu and Hindi consitute the third-most spoken language (Graddol,
2004). At the same time, Urdu/Hindi is a severely underresourced language. We are currently engaged
in building a broad-coverage, robust computational ParGram grammar for Urdu (Butt and King, 2007;
Butt et al, 2009) and one of the major bottlenecks for development is the lack of lexical resources, which
are needed, for example, for the development of a verb lexicon with subcategorization frames or lists of
argument taking nouns and verbs.
Urdu actually has only about 700 simple verbs (Humayoun, 2006), so the task of finding the range
of possible subcategorization frames could be done mostly manually in a reasonable amount of time.
However, as is characteristic of South Asian languages in general, Urdu employs wide variety of different
types of complex predicates (Butt, 1995; Mohanan, 1994) to express its full range of verbal predication.
The complex predicates can be V-V, Adj-V, PP-V or N-V combinations. In this paper, we focus on the
highly productive N-V complex predicates in order to try to identify: 1) possible constraints on the range
of combinatory possibilities; 2) possible systematic semantic groupings/classes of the nouns involved.
The paper is organized as follows. In section 2 we first describe the basic phenomenon. In section 3
we describe the corpus-based study we performed to see if we can identify systematic semantic classes
for nouns. The results are presented in section 4 and the paper is concluded by section 5.
305
2 Combinatory Possibilities for N-V Complex Predicates
Urdu makes use of only about 700 simple verbs. The bulk of verbal predication in Urdu is effected by
complex predicates of various types. The complex predicates are highly productive and different types
can be stacked on top of one another (Butt and Ramchand, 2005), so capturing their use computationally
in a systematic, generalizable and efficient manner is a challenge. One cannot just trawl a corpus to
extract and then list various possibilities as there are potentially infinitely many combinations (though
one can choose to list the 100 or so most frequently occurring ones, as done in the Hindi WordNet, for
example; Bhattacharyya 2010).
In this paper, we focus on the combinatorial possibilities in N-V complex predicates. In N-V complex
predicates the noun contains the main predicational content. The verb, usually referred to as the light
verb, dictates the case marking of the subject, determines agreement patterns, carries information about
tense/aspect and adds information about agentivity vs. experiencer subjects and makes some further
subtle semantic contributions. We illustrate the basics of the construction with respect to the noun yad
?memory? and the light verbs kar ?do? and ho ?be?. Other light verbs may be used as well, but these are
two of the most basic ones.
(1) a. nadya=ne kahani yad k-i
Nadya.F.Sg=Erg story.F.Sg.Nom memory do-Perf.F.Sg
?Nadya remembered a/the story.? (lit.: ?Nadya did memory of the story.?)
b. nadya=ko kahani yad hE
Nadya.F.Sg=Dat story.F.Sg.Nom memory be.Pres.3.Sg
?Nadya remembers/knows a/the story.? (lit.: ?Memory of the story is at Nadya.?)
c. nadya=ko kahani yad hu-i
Nadya.F.Sg=Dat story.F.Sg.Nom memory be.Part-Perf.F.Sg
?Nadya came to remember a/the story.? (lit.: ?Memory of the story became to be at Nadya.?)
In all of the examples in (1), it is evident that the noun and the verb form a single predicational
element. The object kahani ?story? is thematically licensed by the noun yad ?memory?, but it is not
realized as a genitive, as would be typical for arguments of nouns (and as in the English translations).
Rather, kahani ?story? functions as the syntactic object of the joint predication (see Mohanan 1994 for
details on the argument structure and agreement patterns).
In (1a) the noun yad ?memory? is combined with the light verb kar ?do?. In this case the subject must
be ergative and overall reading is one of an agentive, deliberate remembering. In (1b), in contrast, Nadya
is already taken to be in the state of remembering the story. The difference between (1b) and (1c) is one
of eventive vs. stative, so that in (1b), Nadya is already taken to be in the state of remembering the story
(and not actively entering a state of remembering the story). In (1c) the light verb is the participial form
of ho ?be? and essentially means ?become?.
A superficial look at Urdu patterns shows that not all nouns are as versatile as yad ?memory?. That
is, certain nouns are only compatible with a subset of the potentially available light verbs. What has not
so far been explored, however, is what the semantic constraints on N-V complex predicate formation
are. In order to achieve a first understanding of the relevant patterns, we follow Levin (1993)?s classic
assumption that semantic predicational classes can be identified on the basis of a study of the syntactic
contexts the predicates occur in (cf. also Schulte im Walde 2009). Our main aim is therefore to identify
semantic classes of nouns on the basis of their syntactic patterns with respect to complex predicates.
306
3 Corpus Study
According to the best of our knowledge there is no systematic inventory of which types of nouns are
allowed to combine with which types of light verbs in Urdu, though the basic problem has been recog-
nized for Hindi by Hwang et al (2010), who are developing annotation guidelines for complex predicate
constructions. We used a small Part-of-Speech (POS) tagged corpus to extract a number of N-V complex
predicates and then used native speaker judgements to further manually explore their ability to appear
with each of the light verbs kar ?do?, ho ?be?, hu- ?become?.1 The manual exploration was necessary due
to a data sparseness problem, since the available tagged corpora for Urdu are of a limited size.
3.1 Corpus
We used an Urdu POS tagged corpus compiled by the Center for Research in Urdu Language Processing
(CRULP) in Lahore, Pakistan (available at http://www.crulp.org/software/ling resources/UrduNepali-
EnglishParallelCorpus.htm). The corpus consists of 100 000 words from the English Penn Treebank
that have been (manually) translated into Urdu. The corpus consists of three files and the tag-set contains
a specialized POS tag called VBL for the light verbs that are used in N-V complex predicates.
3.2 Method
We manually collected N-V complex predicates starting from the beginning of each of the corpus files.
Given that we were interested in conducting an initial feasibility study, we stopped going through the files
once we had collected 45 distinct nouns that appeared in N-V complex predicates containing the light
verbs kar ?do?, ho ?be? hu- ?become?. We compiled a full set of combinatorial (im)possibilities of these
45 nouns with the three light verbs by taking the instances identified in the corpora and supplementing
the ?missing cells?, so to speak, via native speaker judgements as to whether the combination is possible.
An analysis of the resulting patterns did allow an identification of several distinct semantically coher-
ent classes. Pertinent semantic factors appear to be stative vs. eventive nouns, agentivity vs. experiencer
verbs (psych predications) and the licensing of a dative recipient.
4 Results
4.1 Class A: Full Range
4 out of 45 nouns allowed the full range of patterns shown in (1). The complex predicates these nouns
appear in are psych verbs and include the nouns yad ?memory? and yAqin ?belief?.
4.2 Class B: Exclusion of Dative Subjects
The bulk of the nouns, namely 38 out of the 45, allow an agentive (ergative) subject, but this subject does
not alternate with a dative subject, as shown in (2).
(2) a. b?lal=ne mAkan tAmir ki-ya
Bilal.M.Sg=Erg house.M.Sg.Nom construction.F.Sg do-Perf.M.Sg
?Bilal built a/the house.?
1Further common light verbs are de ?give? and a ?come?. These light verbs have a more complex distribution and so we
chose to concentrate initially on just three basic and very common light verbs. Further light verbs could be investigated in an
extension of this work.
307
b. *b?lal=ko mAkan tAmir hE/hu-a
Bilal.M.Sg=Dat house.M.Sg.Nom construction.F.Sg be.Pres.3.Sg/be.Part-Perf.M.Sg
?Bilal built a/the house.?
The nouns here are eventive nouns which presuppose an agent. As such, a non-agentive dative subject
N-V complex predicate cannot be formed with this version of the noun. As shown in (3), grammatical
combinations of these nouns with the light verb hu- ?become? do exist ? this has an intransitivizing
effect. Semantically, these are resultative state readings that are straightforwardly related to (2).
(3) mAkan tAmir hu-a/*hE
house.M.Sg.Nom construction.F.Sg be.Part-Perf.M.Sg
?A/The house was/*is built.?
One noun in our set patterns essentially as shown in (2) and (3) with the difference that the noun
licenses a dative recipient rather than a direct object (which can be marked as nominative or accusative,
depending on the definiteness of the object in a well-known pattern of object alternation). In (3) the
nominative object of (2a) is realized as a nominative subject. Similarly, as shown in (4), a dative object
in a complex predicate with kar ?do? is realized as a dative subject when the light verb is hu- ?become?.
Other nouns in Urdu which display this pattern are: ?Sara ?signal?, xAbAr ?news? and ?nkar ?refusal?.
(4) a. nadya=ne b?lal=ko ?Sara ki-ya
Nadya.F.Sg=Erg Bilal.M.Sg=Dat signal.M.Sg do-Perf.M.Sg
?Nadya signaled Bilal.?
b. b?lal=ko ?Sara hu-a
Bilal.M.Sg=Dat signal.M.Sg be.Part-Perf.M.Sg
?Bilal was signaled.? (lit.: A signal came to be at Bilal.?)
4.3 Class C: Exclusion of Light Verb hu- ?become?
Another class (2 nouns in our set) allows for combinations with the light verbs kar ?do? and ho ?be?, but
not with hu- ?become?, as illustrated in (5) for the noun ?nt?zar ?wait?. Other nouns like this are tAslim
?acceptance? and bArdaSt ?tolerance?. Presumably the hu- ?become? does not work with these nouns
because the subject is too agentive to be felicitous as the undergoer of a ?become? predication.
(5) a. b?lal=ne nadya=ka ?nt?zar ki-ya
Bilal.M.Sg=Erg Nadya.F.Sg=Gen.M.Sg wait.M.Sg do-Perf.M.Sg
?Bilal waited for Nadya.?
b. b?lal=ko nadya=ka ?nt?zar hE/*hu-a
Bilal.M.Sg=Dat Nadya.F.Sg=Gen.M.Sg wait.M.Sg be.Pres.3.Sg
?Bilal is waiting/*waited for Nadya.?
5 Discussion and Conclusions
Our corpus study showed that one can identify at least 3 different classes of nouns with one class con-
sisting of at least two subclasses (Class B). The identification of classes was based on an investigation of
their syntactic distribution in N-V complex predicates with respect to the light verbs kar ?do?, hu- ?be-
come? and hE ?be?. A follow up study could include an extension of the set of light verbs. Another follow
308
up study could look at the N-V complex predicates in relation to another set of light verbs which occur
with V-V complex predicates. The N-V complex predicate is predicationally equivalent to a simple verb
and as such can further combine with light verbs. Initial investigations have shown that the semantics
of the noun governs the choice of this further light verb, so that the phenomenon of complex predicate
stacking could provide further clues as to a semantic basis for the classification of Urdu nouns.2
The semantic factors identified so far include the eventive vs. statitivity of the nouns, the agentivity
vs. experience of the action and whether the noun licenses a dative recipient. The first identification of
noun classes in terms of systematic syntactic and semantic differences achieved in this paper represents
a step towards overcoming the lack of lexical resources for natural language processing of Urdu.
References
Bhattacharyya, P. (2010). IndoWordNet. In Proceedings of LREC2010. Malta, May.
Butt, M. (1995). The Structure of Complex Predicates in Urdu. Stanford: CSLI Publications.
Butt, M., T. Bo?gel, A. Hautli, and S. Sulger (2009). Urdu and the modular architecture of ParGram. In
Proceedings of the Conference on Language and Technology 2009 (CLT09), pp. 1?7.
Butt, M. and T. H. King (2007). Urdu in a parallel grammar development environment. Language
Resources and Evaluation 41, 191?207.
Butt, M. and G. Ramchand (2005). Complex aspectual structure in Hindi/Urdu. In N. Ertischik-Shir and
T. Rapoport (Eds.), The Syntax of Aspect, pp. 117?153. Oxford: Oxford University Press.
Graddol, D. (2004). The future of language. Science 303, 1329?1331.
Humayoun, M. (2006). Urdu morphology, orthography and lexicon extraction. MSc Thesis, Department
of Computing Science, Chalmers University of Technology.
Hwang, J. D., A. Bhatia, C. Bonial, A. Mansouri, A. Vaidya, N. Xue, and M. Palmer (2010). Propbank
annotation of multilingual light verb constructions. In Proceedings of the Fourth Linguistic Annotation
Workshop (LAW), ACL 2010, Uppsala, Sweden, pp. 82?90.
Levin, B. (1993). English Verb Classes and Alternations. A Preliminary Investigation. Chicago: The
University of Chicago Press.
Mohanan, T. (1994). Argument Structure in Hindi. Stanford: CSLI Publications.
Schulte im Walde, S. (2009). The induction of verb frames and verb classes from corpora. In A. Lu?deling
and M. Kyto? (Eds.), Corpus Linguistics. An International Handbook. Berlin: Mouton de Gruyter.
2A reviewer asks whether our method could scale up for larger corpora and whether resources such as WordNet could
be used to assist the investigation. We here are faced with a lack of resources. We would first need a larger POS tagged
corpora with a more differentiated POS tag set. However, in order to achieve this larger and more differentiated tagging, more
information about the language is needed. We see our paper as contributing to this effort. With respect to WordNet, we face the
problem that the classes provided for the English WordNet do not always match what we find in Urdu. In our Class B, nouns
of communication form an identifiable subclass in Urdu and are also found to be related in English. However, the members of
our Class C do not form a related net in English WordNet. With respect to Hindi WordNet, the ontology provided is not deep
enough as yet to be able to provide useful information for investigations of this type.
309
Proceedings of the EACL 2012 Joint Workshop of LINGVIS & UNCLH, pages 1?6,
Avignon, France, April 23 - 24 2012. c?2012 Association for Computational Linguistics
Visualization of Linguistic Patterns
and
Uncovering Language History from Multilingual Resources
Miriam Butt1 Jelena Prokic?2 Thomas Mayer2 Michael Cysouw3
1Department of Linguistics, University of Konstanz
2Research Unit Quantitative Language Comparison, LMU Munich
3Research Center Deutscher Sprachatlas, Philipp University of Marburg
1 Introduction
The LINGVIS and UNCLH (Visualization of Lin-
guistic Patterns & Uncovering Language His-
tory from Multilingual Resources) were originally
conceived of as two separate workshops. Due to
perceived similarities in content, the two work-
shops were combined and organized jointly.
The overal aim of the joint workshop was to
explore how methods developed in computational
linguistics, statistics and computer science can
help linguists in exploring various language phe-
nomena. The workshop focused particularly on
two topics: 1) visualization of linguistic patterns
(LINGVIS); 2) usage of multilingual resources in
computational historical linguistics (UNCLH).
2 LINGVIS
The overall goal of the first half of the work-
shop was to bring together researchers work-
ing within the emerging subfield of computa-
tional linguistics ? using methods established
within Computer Science in the fields of Infor-
mation Visualization (InfoVis) and Visual Ana-
lytics in conjunction with methodology and anal-
yses from theoretical and computational linguis-
tics. Despite the fact that statistical methods for
language analysis have proliferated in the last
two decades, computational linguistics has so far
only marginally availed itself of techniques from
InfoVis and Visual Analytics (e.g., Honkela et
al. (1995); Neumann et al (2007); Collins et
al. (2009); Collins (2010); Mayer et al (2010a);
Mayer et al (2010b); Rohrdantz et al (2011)).
The need to integrate methods from InfoVis and
Visual Analytics arises particularly with respect
to situations in which the amount of data to be
analyzed is huge and the interactions between rel-
evant features are complex. Both of these situ-
ations hold for much of current (computational)
linguistic analysis. The usual methods of sta-
tistical analysis do not allow for quick and easy
grasp and interpretation of the patterns discovered
through statistical processing and an integration
of innovative visualization techniques has become
imperative.
The overall aim of the first half of the workshop
was thus to draw attention to this need and to the
newly emerging type of work that is beginning to
respond to the need. The workshop succeeded in
bringing together researchers interesting in com-
bining techniques and methodology from theo-
retical and computational linguistics with InfoVis
and Visual Analytics.
Three of the papers in the workshop focused
on the investigation and visualization of lexical
semantics. Rohrdantz et al present a diachronic
study of fairly recently coined derivational suf-
fixes (-gate, -geddon, -athon) as used in newspa-
per corpora across several languages. Their anal-
ysis is able to pin-point systematic differences in
contextual use as well as some first clues as to
how and why certain new coinages spread bet-
ter than others. Heylen et al point out that me-
thods such as those used in Rohrdantz et al,
while producing interesting results, are essentially
black boxes for the researchers ? it is not clear
exactly what is being calculated. Their paper
presents some first steps towards making the black
box more transparent. In particular, they take
a close look at individual tokens and their se-
mantic use with respect to Dutch synsets. Cru-
cially, they anticipate an interactive visualization
that will allow linguistically informed lexicogra-
1
phers to work with the available data and patterns.
A slightly different take on synset relations is pre-
sented by Lohk et al, who use visualization me-
thods to help identify errors in WordNets across
different languages.
Understanding differences and relatedness be-
tween languages or types of a language is the sub-
ject of another three papers. Littauer et al use
data from the WALS (World Atlas of Language
Structures; Dryer and Haspelmath (2011)) to
model language relatedness via heat maps. They
overcome two difficulties: one is the sparseness
of the WALS data; another is that WALS does
not directly contain information about possible ef-
fects of language contact. Littauer et al attempt
to model the latter by taking geographical infor-
mation about languages into account (neighboring
languages and their structure). A different kind
of language relatedness is investigated by Yan-
nakoudakis et al, who look at learner corpora and
develop tools that allow an assessment of learner
competence with respect to various linguistic fea-
tures found in the corpora. The number of rel-
evant features is large and many of them are in-
terdependent or interact. Thus, the amount and
complexity of the data present a classic case of
complex data sets that are virtually impossible to
analyze well without the application of visualiza-
tion methods. Finally, Lyding et al take academic
texts and investigate the use of modality across
academic registers and across time in order to
identify whether the academic language used in
different subfields (or adjacent fields) of an aca-
demic field has an effect on the language use of
that field.
3 UNCLH
The second half of the workshop focused on
the usage of multilingual resources in computa-
tional historical linguistics. In the past 20 years,
the application of quantitative methods in his-
torical linguistics has received increasing atten-
tion among linguists (Dunn et al, 2005; Heg-
garty et al, 2010; McMahon and McMahon,
2006), computational linguists (Kondrak, 2001;
Hall and Klein, 2010) and evolutionary anthropol-
ogists (Gray and Atkinson, 2003). Due to the ap-
plication of these quantitative methods, the field
of historical linguistics is undergoing a renais-
sance. One of the main problems that researchers
face is the limited amount of suitable compara-
tive data, often falling back on relatively restricted
?Swadesh type? wordlists. One solution is to use
synchronic data, like dictionaries or texts, which
are available for many languages. For example,
in Kondrak (2001), vocabularies of four Algo-
nquian languages were used in the task of au-
tomatic cognate identification. Another solution
employed by Snyder et al (2010) is to apply a
non-parametric Bayesian framework to two non-
parallel texts in the task of text deciphering. Al-
though very promising, these approaches have so
far only received modest attention. Thus, many
questions and challenges in the automatization
of language resources in computational historical
linguistics remain open and ripe for investigation.
In dialectological studies, there is a long tra-
dition, starting with Se?guy (1971), in which lan-
guage varieties are grouped together on the ba-
sis of their similarity with respect to certain prop-
erties. Later work in this area has incorporated
methods of string alignment for a quantitative
comparison of individual words to obtain an aver-
age measure of the similarity of languages. This
line of research became known as dialectome-
try. Unlike traditional dialectology which is based
on the analysis of individual items, dialectometry
shifts focus on the aggregate level of differences.
Most of the work done so far in dialectometry
is based on the carefully selected wordlists and
problems with the limited amount of suitable data
(i.e. computer readable and comparable across di-
alects) are also present in this field.
This workshop brings together researchers in-
terested in computational approaches that uncover
sound correspondences and sound changes, auto-
matic identification of cognates across languages
and language comparison based both on wordlists
and parallel texts. First, Wettig et al investigate
the sound correspondences in cognate sets in a
sample of Uralic languages. Then, List?s contri-
bution to the volume introduces a novel method
for automatic cognate detection in multilingual
wordlists which combines various previous ap-
proaches for string comparison. The paper by
Mayer & Cysouw presents a first step to use par-
allel texts for a quantitative comparison of lan-
guages. The papers by Scherrer and Prokic? et
al. both are in the spirit of the dialectometric line
of research. Further, Ja?ger reports on quantify-
ing language similarity via phonetic alignment of
core vocabulary items. Finally, some of the pa-
2
pers presented in this workshop deal with further
topics in quantitative language comparison, like
the application of phylogenetic methods in cre-
ole research in the paper by Daval-Markussen &
Bakker, and the study of the evolution of the Aus-
tralian kinship terms reported on in the paper by
McConvell & Dousset.
In the next section, we give a brief introduc-
tion into the papers presented in this workshop,
ordered according to the program of the oral pre-
sentations at the workshop.
4 Papers
Christian Rohrdantz, Andreas Niekler, Annette
Hautli, Miriam Butt and Daniel A. Keim (?Lex-
ical Semantics and Distribution of Suffixes ?
A Visual Analysis) present a quantitative cross-
linguistic investigation of the lexical semantic
content expressed by three suffixes originating in
English: -gate, -geddon and -athon. Using data
from newspapers, they look at the distribution and
lexical semantic usage of these morphemes across
several languages and also across time, with a
time-depth of 20 years for English. Using tech-
niques from InfoVis and Visual Analytics is cru-
cial for the analysis as the occurrence of these suf-
fixes in the available corpora is comparatively rare
and it is only by dint of processing and visualiz-
ing huge amounts of data that a clear pattern can
begin to emerge.
Kris Heylen, Dirk Speelman and Dirk Geer-
aerts (?Looking at Word Meaning. An Interac-
tive Visualization of Semantic Vector Spaces for
Dutch synsets?) focus on the pervasive use of Se-
mantic Vector Spaces (SVS) in statistical NLP
as a standard technique for the automatic mod-
eling of lexical semantics. They take on the
fact that while the method appears to work fairly
well (though they criticize the standardly avail-
able evaluation measures via some created gold
standard), it is in fact quite unclear how it captures
word meaning. That is, the standard technology
can be seen as a black box. In order to find a way
of providing some transparency to the method,
they explore the way an SVS structures the indi-
vidual occurrences of words with respect to the
occurrences of 476 Dutch nouns. These were
grouped into 214 synsets in previous work. This
paper looks at a token-by-token similarity matrix
in conjunction with a visualization that uses the
Google Chart Tools and compares the results with
previous work, especially in light of different uses
in different versions of Dutch.
Ahti Lohk, Kadri Vare and Leo Vo?handu
(?First Steps in Checking and Comparing Prince-
ton WordNet and Estonian WordNet?) use visu-
alization methods to compare two existing Word-
Nets (English and Estonian) in order to identify
errors and semantic inconsistencies that are a re-
sult of the manual coding. Their method opens
up a potentially interesting way of automatically
checking for inconsistencies and errors not only
at a fairly basic and surface level, but by work-
ing with the lexical semantic classification of the
words in question.
Richard Littauer, Rory Turnbull and Alexis
Palmer (?Visualizing Typological Relationships:
Plotting WALS with Heat Maps?) present a novel
way of visualizing relationships between lan-
guages. The paper is based on data extracted from
the World Atlas of Language Structures (WALS),
which is the most complete set of typological and
digitized data available to date, but which presents
two challenges: 1) it actually has very low cover-
age both in terms of languages represented and
in terms of feature description for each language;
2) areal effects are not coded for. While the au-
thors find a way to overcome the first challenge,
the paper?s real contribution lies in proposing a
method for overcoming the second challenge. In
particular, the typological data is filtered by geo-
graphical proximity and then displayed by means
of heat maps, which reflect the strength of similar-
ity between languages for different linguistic fea-
tures. Thus, the data should allow one to be able
to ascertain areal typological effects via a single
integrated visualization.
Helen Yannakoudakis, Ted Briscoe and
Theodora Alexopoulou (?Automatic Second
Language Acquisition Research: Integrating
Information Visualisation and Machine Learn-
ing?) look at yet another domain of application.
They show how data-driven approaches to
learner corpora can support Second Language
Acquisition (SLA) research when integrated
with visualization tools. Learner corpora are
interesting because their analysis requires a good
understanding of a complex set of interacting
linguistic features across corpora with different
distributional patterns (since each corpus po-
tentially diverges from the standard form of the
language by a different set of features). The paper
3
presents a visual user interface which supports
the investigation of a set of linguistic features
discriminating between pass and fail exam
scripts. The system displays directed graphs to
model interactions between features and supports
exploratory search over a set of learner texts.
A very useful result for SLA is the proposal
of a new method for empirically quantifying
the linguistic abilities that characterize different
levels of language learning.
Verena Lyding, Ekaterina Lapshinova-
Koltunski, Stefania Degaetano-Ortlieb, Henrik
Dittmann and Chris Culy (?Visualizing Linguistic
Evolution in Academic Discourse?) describe
methods for visualizing diachronic language
changes in academic writing. In particular, they
look at the use of modality across different aca-
demic subfields and investigate whether adjacent
subfields affect the use of language in a given
academic subfield. Their findings potentially
provide crucial information for further NLP tasks
such as automatic text classification.
Grzegorz Kondrak?s invited contribution
(?Similarity Patterns in Words?) sketches a num-
ber of the author?s research projects on diachronic
linguistics. He first discusses computational tech-
niques for implementing several steps of the
comparative method. These techniques include
algorithms that deal with a wide range of prob-
lems: pairwise and multiple string alignment,
calculation of phonetic similarity between two
strings, automatic extraction of recurrent sound
correspondences, quantification of semantic
similarity between two words, identification of
sets of cognates and building of phylogenetic
trees. In the second part, Kondrak sketches
several NLP projects that directly benefitted
from his research on diachronic linguistics:
statistical machine translation, word align-
ment, identification of confusable drug names,
transliteration, grapheme-to-phoneme conver-
sion, letter-phoneme alignment and mapping of
annotations.
Thomas Mayer and Michael Cysouw (?Lan-
guage Comparison through Sparse Multilingual
Word Alignment?) present a novel approach on
how to calculate similarities among languages
with the help of massively parallel texts. In-
stead of comparing languages pairwise they sug-
gest a simultaneous analysis of languages with re-
spect to their co-occurrence statistics for individ-
ual words on the sentence level. These statistics
are then used to group words into clusters which
are considered to be partial (or ?sparse?) align-
ments. These alignments then serve as the basis
for the similarity count where languages are taken
to be more similar the more words they share in
the various alignments, regardless of the actual
form of the words. In order to cope with the
computationally demanding multilingual analysis
they introduce a sparse matrix representation of
the co-occurrence statistics.
Yves Scherrer (?Recovering Dialect Geogra-
phy from an Unaligned Comparable Corpus?) pro-
poses a simple metric of dialect distance, based
on the ratio between identical word pairs and cog-
nate word pairs occurring in two texts. Scherrer
proceeds from a multidialectal corpus and applies
techniques from machine translation in order to
extract identical words and cognate words. The
dialect distance is defined as as function of the
number of cognate word pairs and identical word
pairs. Different variations of this metric are tested
on a corpus containing comparable texts from dif-
ferent Swiss German dialects and evaluated on the
basis of spatial autocorrelation measures.
Jelena Prokic?, C?ag?r? Co?ltekin and John Ner-
bonne (?Detecting Shibboleths?) propose a gen-
eralization of the well-known precision and re-
call scores to deal with the case of detecting dis-
tinctive, characteristic variants in dialect groups,
in case the analysis is based on numerical differ-
ence scores. This method starts from the data that
has already been divided into groups using clus-
ter analyses, correspondence analysis or any other
technique that can identify groups of language va-
rieties based on linguistic or extra-linguistic fac-
tors (e.g. geography or social properties). The
method seeks items that differ minimally within a
group but differ a great deal with respect to ele-
ments outside it. They demonstrate the effective-
ness of their approach using Dutch and German
dialect data, identifying those words that show
low variation within a given dialect area, and high
variation outside a given area.
Gerhard Ja?ger (?Estimating and Visualizing
Language Similarities Using Weighted Align-
ment and Force-Directed Graph Layout?) reports
several studies to quantify language similarity
via phonetic alignment of core vocabulary items
(taken from the Automated Similarity Judgement
Program data base). Ja?ger compares several string
4
comparison measures based on Levenshtein dis-
tance and based on Needleman-Wunsch similar-
ity score. He also tests two normalization func-
tions, one based on the average score and the
other based on the informatic theoretic similar-
ity measure. The pairwise similarity between all
languages are analyzed and visualized using the
CLANS software, a force directed graph layout
that does not assume an underlying tree structure
of the data.
Aymeric Daval-Markussen and Peter Bakker
(?Explorations in Creole Research with Phyloge-
netic Tools?) employ phylogenetic tools to inves-
tigate and visualize the relationship of creole lan-
guages to other (non-)creole languages on the ba-
sis of structural features. Using the morphosyn-
tactic features described in the monograph on
Comparative Creole Syntax (Holm and Patrick,
2007), they create phylogenetic trees and net-
works for the languages in the sample, which
show the similarity between the various languages
with respect to the grammatical features inves-
tigated. Their results lend support to the uni-
versalist approach which assumes that creoles
show creole-specific characteristics, possibly due
to restructuring universals. They also apply their
methodology to the comparison of creole lan-
guages to other languages, on the basis of typo-
logical features from the World Atlas of Language
Structures. Their findings confirm the hypothe-
sis that creole languages form a synchronically
distinguishable subgroup among the world?s lan-
guages.
Patrick McConvell and Laurent Dousset
(?Tracking the Dynamics of Kinship and So-
cial Category Terms with AustKin II?) give an
overview of their ongoing work on kinship and
social category terms in Australian languages.
They describe the AustKin I database which
allows for the reconstruction of older kinship
systems as well as the visualization of patterns
and changes. In particular, their method recon-
structs so-called ?Kariera? kinship systems for the
proto-languages in Australia. This supports ear-
lier hypotheses about the primordial world social
organization from which Dravidian-Kariera sys-
tems are considered to have evolved. They also
report on more recent work within the AustKin II
project which is devoted to the co-evoluation of
marriage and social category systems.
Hannes Wettig, Kirill Reshetnikov and Roman
Yangarber (?Using Context and Phonetic Fea-
tures in Models of Etymological Sound Change?)
present a novel method for a context-sensitive
alignment of cognate words, which relies on the
information theoretic concept of Minimum De-
scription Length to decide on the most compact
representation of the data given the model. Start-
ing with an initial random alignment for each
word pair, their algorithm iteratively rebuilds de-
cision trees for each feature and realigns the cor-
pus while monotonically decreasing the cost func-
tion until convergence. They also introduce a
novel test for the quality of the models where one
word pair is omitted from the training phase. The
rules that have been learned are then used to guess
one word from the other in the pair. The Lev-
enshtein distance of the correct and the guessed
word is then computed to give an idea of how
good the model actually learned the regularities
in the sound correspondences.
Johann-Mattis List (?LexStat: Automatic De-
tection of Cognates in Multilingual Wordlists?)
presents a new method for automatic cognate
detection in multilingual wordlists. He com-
bines different approaches to sequence compari-
son in historical linguistics and evolutionary bi-
ology into a new framework which closely mod-
els central aspects of the comparative method.
The input sequences, i.e. words, are converted to
sound classes and their sonority profiles are deter-
mined. In step 2, a permutation method is used to
create language specific scoring schemes. In step
3, the pairwise distances between all word pairs,
based on the language-specific scoring schemes,
are computed. In step 4, the sequences are clus-
tered into cognate sets whose average distance is
beyond a certain threshold. The method is tested
on 9 multilingual wordlists.
5 Final remarks
The breadth and depth of the research collected
in this workshop more than testify to the scope
and possibilities for applying new methods that
combine quantitative methods with not only a so-
phisticated linguistic understanding of language
phenomena, but also with visualization methods
coming out of the Computer Science fields of In-
foVis and Visual Analytics. The papers in the
workshop addressed how the emerging new body
of work can provide advances and new insights
for questions pertaining to theoretical linguistics
5
(lexical semantics, derivational morphology, his-
torical linguistics, dialectology and typology) and
applied linguistic fields such as second language
acquisition and statistical NLP.
6 Acknowledgments
We are indebted to the members of the pro-
gram committee of the workshop for their ef-
fort in thoroughly reviewing the papers: Quentin
Atkinson, Christopher Collins, Chris Culy, Dan
Dediu, Michael Dunn, Sheila Embleton, Simon
Greenhill, Harald Hammarstro?m, Annette Hautli,
Wilbert Heeringa, Gerhard Heyer, Eric Hol-
man, Gerhard Ja?ger, Daniel Keim, Tibor Kiss,
Jonas Kuhn, Anke Lu?deling, Steven Moran, John
Nerbonne, Gerald Penn, Don Ringe, Christian
Rohrdantz, Tandy Warnow, S?ren Wichmann.
We also thank the organizers of the EACL 2012
conference for their help in setting up the joint
workshop.
References
Christopher Collins, Sheelagh Carpendale, and Ger-
ald Penn. 2009. Docuburst: Visualizing document
content using language structure. Computer Graph-
ics Forum (Proceedings of Eurographics/IEEE-
VGTC Symposium on Visualization (EuroVis ?09)),
28(3):1039?1046.
Christopher Collins. 2010. Interactive Visualizations
of Natural Language. Ph.D. thesis, University of
Toronto.
Matthew S. Dryer and Martin Haspelmath, editors.
2011. The World Atlas of Language Structures On-
line. Max Planck Digital Library, Munich, 2011
edition.
Michael Dunn, Angela Terrill, Ger Resnik, Robert A.
Foley, and Stephen C. Levinson. 2005. Structural
phylogenetics and the reconstruction of ancient lan-
guage history. Science, 309(5743):2072?2075.
Russell Gray and Quentin Atkinson. 2003. Language-
tree divergence times support the Anatolian theory
of Indo-European origins. Nature, 426:435?439.
David LW Hall and Dan Klein. 2010. Finding cognate
groups using phylogenies. In Proceedings of the
Association for Computational Linguistics.
Paul Heggarty, Warren Maguire, and April McMahon.
2010. Splits or waves? trees or webs? how diver-
gence measures and network analysis can unravel
language histories. In Philosophical Transactions
of the Royal Society (B), volume 365, pages 3829?
3843.
John Holm and Peter L. Patrick, editors. 2007. Com-
parative Creole Syntax. London: Battlebridge.
Timo Honkela, Ville Pulkki, and Teuvo Kohonen.
1995. Contextual relations of words in grimm tales,
analyzed by self-organizing map. In Proceedings of
International Conference on Artificial Neural Net-
works (ICANN-95), pages 3?7.
Grzegorz Kondrak. 2001. Identifying cognates by
phonetic and semantic similarity. In Proceedings
of the North American Chapter of the Association
of Computational Linguistics.
Thomas Mayer, Christian Rohrdantz, Miriam Butt,
Frans Plank, and Daniel A. Keim. 2010a. Visualiz-
ing vowel harmony. Linguistic Issues in Language
Technology (LiLT), 2(4).
Thomas Mayer, Christian Rohrdantz, Frans Plank,
Peter Bak, Miriam Butt, and Daniel A. Keim.
2010b. Consonant co-occurrence in stems across
languages: Automatic analysis and visualization of
a phonotactic constraint. In Proceedings of the
2010 Workshop on NLP and Linguistics: Finding
the Common Ground, ACL 2010, pages 70?78.
April McMahon and Robert McMahon. 2006. Lan-
guage Classification by Numbers. OUP.
Petra Neumann, Annie Tat, Torre Zuk, and Shee-
lagh Carpendale. 2007. Keystrokes: Personaliz-
ing typed text with visualization. In Proceedings
of Eurographics IEEE VGTC Symposium on Visu-
alization.
Christian Rohrdantz, Annette Hautli, Thomas Mayer,
Miriam Butt, Daniel A. Keim, and Frans Plank.
2011. Towards tracking semantic change by visual
analytics. In Proceedings of the 49th Annual Meet-
ing of the Association for Computational Linguis-
tics (Short Papers), pages 305?310. Portland, Ore-
gon.
Jean Se?guy. 1971. La relation entre la distance spa-
tiale et la distance lexicale. Revue de Linguistique
Romane, 35(138):335?357.
Benjamin Snyder, Regina Barzilay, and Kevin Knight.
2010. A statistical model for lost language deci-
pherment. In Proceedings of the Association for
Computational Linguistics.
6
Proceedings of the EACL 2012 Joint Workshop of LINGVIS & UNCLH, pages 7?15,
Avignon, France, April 23 - 24 2012. c?2012 Association for Computational Linguistics
Lexical Semantics and Distribution of Suffixes ? A Visual Analysis
Christian Rohrdantz1 Andreas Niekler2 Annette Hautli1 Miriam Butt1 Daniel A. Keim1
1 University of Konstanz
first.last@uni-konstanz.de
2Leipzig University of Applied Sciences
aniekler@fbm.htwk-leipzig.de
Abstract
We present a quantitative investigation of
the cross-linguistic usage of some (rel-
atively) newly minted derivational mor-
phemes. In particular, we examine the lexi-
cal semantic content expressed by three suf-
fixes originating in English: -gate, -geddon
and -athon. Using data from newspa-
pers, we look at the distribution and lex-
ical semantic usage of these morphemes
not only within English, but across sev-
eral languages and also across time, with
a time-depth of 20 years. The occurrence
of these suffixes in available corpora are
comparatively rare, however, by investigat-
ing huge amounts of data, we are able to
arrive at interesting insights into the dis-
tribution, meaning and spread of the suf-
fixes. Processing and understanding the
huge amounts of data is accomplished via
visualization methods that allow the pre-
sentation of an overall distributional pic-
ture, with further details and different types
of perspectives available on demand.
1 Introduction
It is well-known that parts of a compound can be-
gin to lead an additional life as derivational suf-
fixes, or even as stand-alone items. A famous
example is burger, which is now used to denote
a food-item (e.g., burger, cheese burger, veggie
burger) and is originally from the word Ham-
burger, which designates a person from the Ger-
man city of Hamburg. These morphemes are gen-
erally known as cranberry morphemes (because
of the prolific use of cran). Some other examples
are -(o)nomics, -(o)mat or (o)rama.
While it is well-known that this morpholog-
ical process exists, it is less clear what condi-
tions trigger it and how the coinage ?catches? on
to become a regular part of a language. Given
the current availability of huge amounts of dig-
ital data, we decided to investigate whether we
could gain an insight into the use and spread of
some of these morphemes via quantitative meth-
ods, thereby confirming our intuitions.
Furthermore, we decided to focus not just on
the use of the cranberry morphemes in their lan-
guage of origin, but also on their use and spread in
other languages. In particular, we want to model
the contexts in which these suffixes are used to
coin new words and how these neologisms trans-
port to other languages. We chose to look at the
following three morphemes: -gate, -geddon and
-athon because they tend to be used in ?newswor-
thy? contexts and are therefore likely to appear
in newswire and newspaper corpora, which are
available to us in large amounts.
This paper describes work in progress, where
we visually analyze the lexical semantics and use
of the three suffixes -gate, -geddon and -athon.
We were able to add some time-depth to our in-
vestigation via an analysis of the New York Times
corpus from 1987?2007. This means that while
we cannot pin-point the first occurrence and fur-
ther spread of the morpheme uses, we can gain
some idea as to their historical development.
Given that the amount of data we analyze is
huge, we use methods from Visual Analytics in
order to make the vast amount of information gen-
erated from the computational models easily ac-
cessible to the human eye and mind.
We proceed as follows: After a review of re-
lated work in Section 2, we describe our study in
Section 3 and discuss the visual analysis in Sec-
tion 4. In a case study we compare the meaning of
7
words with the suffix -gate to other semantically
related words (4.1) based on an optimized topic
model. We also develop, customize and apply vi-
sualizations to investigate the productivity of new
suffixes and their spread across news sources and
languages (4.2). We conclude with Section 5.
2 Related Work
As already mentioned, the coinage and spread of
new suffixes is well-known in theoretical linguis-
tics. However, linguists are generally not sure
what effects exactly are involved in the process
(Baayen, 1992; Plag, 1999). We are not aware of
any other computational work on cranberry mor-
phemes. Work by Lu?deling and Evert (2005) on
the German non-medical suffix -itis is closest to
this paper; however, the type of the morpheme in-
vestigated is different and their focus is mainly on
productivity. We concentrate more on the lexi-
cal semantic content of the suffixes, look at them
across languages in bigger corpora to investigate
their distribution and use and provide a layer of
visual analysis.
One question we asked ourselves is whether
we could predict from the context the likelihood
of the suffixes -gate, -geddon and -athon and
whether one can identify the lexical semantic con-
tent of the suffixes more precisely. This task can
be formulated as a topic modeling problem for
which we chose to employ Latent Dirichlet Al-
location (LDA) (Blei et al, 2003). It has recently
been used to perform word sense induction from
small word contexts (e.g. Brody (2009)) and has
also proven successful when detecting changes in
word meanings over time on small word contexts
in diachronic corpora (Rohrdantz et al, 2011).
We applied an optimized topic model and com-
bined the statistical results with methods from
Visual Analytics. Visual Analytics is based on
the tight coupling of algorithms for automatic
data analysis and interactive visual components
(Thomas and Cook, 2005; Keim et al, 2010). The
idea is to exploit human perceptive abilities to
support the detection of interesting patterns (see
Card et al (1999) for details). Examples for visu-
alizations used previously to investigate linguis-
tic questions are Mayer et al (2010a) on vowel
harmony, Mayer et al (2010b) on consonant pat-
terns, Honkela et al (1995) on syntactic cate-
gories, Rohrdantz et al (2011) on lexical seman-
tics across time.
We also used visualizations to look at cross-
linguistic use and productivity of the suffixes.
Prominent theoretical work on the productivity of
morphemes has been done by Baayen (1992) and
Plag (1999), most computational approaches have
worked on English due to the availability of large
enough corpora (Nishimoto, 2004). To the best of
our knowledge, no large-scale quantitative study
has been performed which takes into account both
the diachronic as well as the cross-linguistic di-
mension of the development.
3 Our Approach
3.1 Research Questions & Analysis Tasks
The object of research are three productive suf-
fixes, namely -gate, geddon and -athon. What
these suffixes have in common is that they trig-
ger neologisms in various languages and all of
them seem to carry some lexical semantic infor-
mation. Whereas -gate, which was coined by the
Watergate affair, is used for scandalous events or
affairs, -geddon seems to denote a similar con-
cept but more of a disastrous event, building on its
original use in the bible. Usually, -athon, coming
from marathon, denotes a long-lasting event. We
assume that the lexical semantic content of these
suffixes can be modeled with standard topic mod-
els.
3.2 Data & Statistics
Our investigations are based on two different data
sets, one is a diachronic news corpus, the New
York Times Annotated Corpus1 containing 1.8
million newspaper articles from 1987 to 2007. To
generate the second data set, we performed an on-
line scan of the EMM news service,2 which links
to multilingual news articles from all over the
world and enriches them with metada (Atkinson
and der Goot, 2009; Krstajic et al, 2010). Be-
tween May 2009 and January 2012, we scanned
about eleven million news articles in English,
German and French.
For both data sources, we extract a context of
25 words before and after the word under inves-
tigation, together with its timestamp. In the case
of the EMM data, we also save information on the
news source, the source country and the language
of the article. In a manual postprocessing step, we
1http://www.ldc.upenn.edu/
2http://emm.newsexplorer.eu/
8
clean the dataset from words ending in the suffixes
by coincidence, many of which are proper names
of persons and locations.
From the EMM metadata, we can attribute the
employment of the suffixes to the countries they
were used in. Table 1 shows the figures for the
-gate suffix, what language it was used in, and
its country of origin. We can see that the suffix
was used in many countries and different world
regions between May 2009 and January 2012.
Lang. Country
English GB (1142), USA (840), Ireland
(364), Pakistan (275), South Africa
(190), India (131), Australia (129),
Canada (117), Zimbabwe (73)
French France (2089), Switzerland (429),
Belgium (108), Senegal (30)
German Germany (493), Switzerland (151),
Austria (151)
Table 1: Usage of the suffix -gate in different lan-
guages/countries. For each language only the coun-
tries with the most occurrences are listed.
Among the total 7,500 -gate appearances,
Rubygate ? the affair of Italian?s ex prime min-
ister Silvio Berlusconi with an under-aged girl
from Morocco ? was the most frequent word with
1558 matches, followed by Angolagate with 1025
matches and Climategate with 752 matches. The
NYT corpus has 1,000 matches of -gate words,
the top ones were Iraqgate with 148, Travelgate
with 122, and Irangate with 105 matches. The
frequency of -geddon and -athon was much lower.
3.3 Topic Modeling
The task of the topic modeling in this paper is to
discover meaning relationships between our the
suffixes and semantically related words, i.e. we
want to determine from the word contexts whether
-gate words share context features with words
such as scandal or affair. For this task, we use
LDA, which describes a generative hierarchical
Bayesian model that relates the words and doc-
uments within a corpus through a latent variable.
The interpretation of this latent variable could be
seen as topics that are responsible for the usage
of words within the documents. Within the LDA
framework we can describe the generation of a
document by the following process
1. draw K multinomials ?k ? Dir(?k), one for
each topic k
2. for each document d, d = 1, . . . , D
(a) draw multinomial ?d ? Dir(?d)
(b) for each word wdn in document d, n =
1, . . . , Nd
i. draw a topic zdn ?
Multinomial(?d)
ii. draw a wordwdn from p(wdn|?zdn),
the multinomial probability condi-
tioned on topic zdn
Following this generative process we identify the
hidden variables for every document in a corpus
by computing the posterior distribution:
p(?, ?, z|w, ?, ?) =
p(?, ?, z,w|?, ?)
p(w|?, ?)
. (1)
Exact inference for this posterior distribution
is not tractable and we use collapsed Gibbs sam-
pling as in Griffiths and Steyver (2004). We com-
pute the posterior distribution over all variables
and model parameters instead of inferring ? and
? directly. The Gibbs sampling procedure sam-
ples a topic zdn for each word in all documents
of the corpus. This procedure is iterated until
the approximated posterior distribution does not
change the likelihood of the model with more it-
erations. As a result we get a sampled topic zdn
for each word in the corpus and can trace ? and
?. For our problem we can use the counts of zdn,
the count of words belonging to a topic, for each
document in combination with the timestamps to
see which word in question appears how often in
a specific topic in which time slice. This allows
us to observe the usage of a word within a cer-
tain timespan. The hidden variable ? can be in-
terpreted as a matrix having the conditional prob-
ability p(wi|zk) at the matrix position ?i,k. This
means that every column vector in ? is a probabil-
ity distribution over the whole vocabulary. These
distributions can be seen as topics since they de-
scribe a mixture of words with exact probabilities.
Having those distributions at hand we can analyze
which words occur significantly often in the same
topic or semantic context.
The purpose of the LDA model is to analyze the
latent structure of the passages extracted from the
NYT corpus. We decided to use the contexts of
Watergate, scandal, affair, crisis, controversy in
combination with the suffix -gate. We can then
9
0 = society, art, culture 
Society, Art, 
and Culture 
Watergate 
Economy 
Foreign 
Policy 
Domestic 
Policy 
Sports 
Society, Art, 
and Culture 
Watergate 
Economy 
Foreign 
Policy 
Domestic 
Policy 
Sports 
1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 
1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 
Figure 1: The diachronic distribution of the words under investigation over the 6 topics learned from the New
York Times Corpus.
10
see where these terms co-occur and hence what
the semantic context is. We infer a model which
consists of six topics under the assumption that if
the word senses of the six words given above do
not overlap at all, there should not be more than
six senses to analyze. The fixed parameter K in
the model leads us to an optimization problem of
the hyper-parameter ?. The hyper-parameter ?
is not as important as ? since it scales the topic
per document mixture. For that reason we do not
optimize ? explicitly. We rather estimate the opti-
mal value after optimizing the value for ?. Since
the ? parameter is of crucial impact to the gener-
ation of the hidden variable ? and thus the topics,
we need to find the optimal hyper-parameter that
generalizes the model to the given data. Most ap-
proaches show that one can optimize the model
for fixed parameters ? and ? when testing mod-
els with different values for K as in (Griffiths and
Steyver, 2004). Since we are fixing K we must
test the dataset for an optimal model given differ-
ent values for ?. This can be done by utilizing
the model perplexity (Blei et al, 2003) and thus
maximizing the likelihood of a test dataset from
the same corpus.
In our experiment we used a relatively small
number of topics and we expected a large number
of words aligned to a topic.
4 Visual Analytics
4.1 Topic Modeling
The topics extracted from the NYT corpus by the
model described in Section 3.3 was further inves-
tigated with respect to the correlation between the
lexical semantic content of the suffixed words and
a development over time. For this purpose we de-
signed a pixel visualization (see Figure 1), map-
ping the data facets to the visual variables as fol-
lows: The data is divided according to the topics
mapping each topic to one horizontal band. The
descriptive words of a topic as found by LDA are
listed above its band. In addition, each topic is
manually assigned an interpretive label. These la-
bels are at the far left of a topic band.
Each topic band is further subdivided according
to the words under investigation. Under the label
?gate-aggregated?, all words with -gate suffixes
(except Watergate) are summarized. The bands
are aligned with a time axis and vertically divided
into cells, each cell representing one week of data.
The cell color indicates whether the correspond-
ing word under investigation occurred within the
corresponding topic in the corresponding week.
The black color means that there was no such oc-
currence, whereas the brightest white is assigned
to the cell of the week where most occurrences
(max) of a word under investigation are found,
independent from the topic. Other occurrence
counts are colored in grey tones according to a lin-
ear mapping into the normalized color range from
black=0 to white=max. Note that the normaliza-
tion depends on the word under investigation, i.e.
is relative to its maximal occurrence.
In Figure 1, the data has to be split into two
chunks to fit the page. The upper part shows the
years from 1987 to 1997 and the lower part from
1997 to 2007. There are several possibilities for
user interaction: A semantic zoom allows the data
to be displayed in different levels of time granu-
larity, e.g. day, week, month, year. By mousing
over a cell, the underlying text passages are dis-
played in a tooltip.
Findings Figure 1 shows that the topics are
dominated by different words under investiga-
tion, i.e. the words under investigation cannot be
clearly separated into self-contained meanings.
This mixture indicates that the words under
investigation have similar meanings, but that
in different contexts they are used in different
combinations:
1. Society, Art, and Culture: This seems to be
the most general topic with the broadest usage of
the words under investigation. The descriptive
terms show that it is a lot about interpersonal re-
lations and dominated by ?affair?. In 1989/1990
the play Mastergate becomes visible in the
?gate-aggregated? band.
2. Economy: This topic is strongly related to
?crisis? and apart from the moderate frequency
of ?scandal?, other words are rarely used in this
context. Apparently, financial scandals were
usually not described attaching the suffix ?-gate?
in the years between 1987 and 2007.
3. Foreign Policy: This is another topic domi-
nated by ?crisis?, with moderate occurrences of
?controversy?. Some ?gate-words? also appear.
4. Sports: Here, ?controversy? is the dominating
element, with a raised frequency of ?affair? and
small frequency of ?scandal?. Again, ?gate-
words? appear from time to time, with a slightly
11
increased frequency towards the end.
5. Domestic Politics: The dominant words are
?controversy? and ?crisis?. It?s noteworthy that
?controversy? is a lot more frequent here than
for Foreign Policy. Especially in the last years
?gate-words? appeared from time to time.
In sum, we find that there are preferred contexts
in which -gate is used, namely mainly in topics to
do with society, art and culture and that topics to
do with the economy, -gate is hardly used. The
lexical semantic content of -gate seems to be most
closely linked to the word affair.
4.2 Productivity
The cases of suffixation presented above should
also be considered from the standpoint of mor-
phological productivity. For Baayen (1992), mor-
phological productivity is a complex phenomenon
in which factors like the structure of the lan-
guage, its processing complexities and social con-
ventions mingle. Whereas he focuses on the the
correlation between productivity and frequency,
we can take into account another variable for pro-
ductivity. In particular, we can consider the num-
ber of newspapers that use a certain term. This
will normalize the measures usually taken in that
a term like ?Watergate?, which is highly frequent
and mentioned in a variety of sources is more
productive than a term that occurs frequently, but
only in one source. Using this methodology we
can at least partly circumvent the problem of pro-
ductivity effects that are merely based on the spe-
cific style of one particular newspaper.
First, we visually evaluate the productivity of
the different suffixes plotting the sum of different
coinages against time, see Figure 2. As can be ex-
pected, in all three cases there is a steeper slope in
the beginning of the monitored period. This is an
artifact because all older coinages that had been
around before the monitoring started will be ob-
served for the first time. As more time passes all
plots show a linear overall trend, indicating that
the rate with which new coinages appear remains
somewhat constant. Yet, there are some local os-
cillations in the rate that become more visible in
the plots of -geddon- and -athon-coinages, which
are in general much more infrequent than -gate-
coinages. It can be concluded that over the last
two and a half years the suffixes kept their rate
of productivity in English, German, and French
newswire texts fairly constant.
To investigate the cross-linguistic productivity
of the new coinages we customized a visualiza-
tion with the Tableau software.3 Figure 3 shows
the appearances of the 15 most frequent -gate-
coinages across the three languages over time.
Along the y-axis the data is divided according to
-gate-coinages and languages, whereas the x-axis
encodes the time. Whenever a certain coinage ap-
pears in a certain language at a certain point in
time, a colored triangle is plotted to the corre-
sponding position. The color redundantly encodes
the language for easier interpretation.
Figure 3 shows many interesting patterns. The
most salient patterns can be summarized as:
1. No language barrier: The top -gate-coinages
belong to scandals that are of international
interest and once they are coined in English they
immediately spread to the other languages, see
Rubygate, Climategate, Cablegate, Antennagate,
and Crashgate. Only in the case of Angolagate
and Karachigate there is a certain delay in the
spread, possibly due to the fact that it was coined
in French first and initially did not achieve the
same attention as coinages in English.
2. Pertinacity partly depends on language:
Some -gate-coinages re-appear over and over
again only in individual languages. This espe-
cially holds for words that were coined before
the monitoring started, e.g. Sachsgate, Oilgate,
Troopergate, and Travelgate which all persist in
English. Examples can be found for other lan-
guages, e.g. Angolagate for French. Interestingly,
in German Nipplegate persists over the whole
monitored period, but only in German, and even
outperforms its German spelling Nippelgate.
3. Some coinages are special: Some of the
recent coinages such as Memogate, Asiagate, and
Weinergate reach an extremely high frequency
within very short time ranges, but can be found
almost exclusively in English. These will be
subject of further investigation in Section 4.2.1.
It has to be noted that many of the infrequent
coinages appear only once and are never adopted.
4.2.1 Spread across News Sources and
Countries
Figure 3 clearly shows that Memogate is heav-
ily mentioned within English speaking news
3http://www.tableausoftware.com/
12
Su
m
 of
 di
ffe
re
nt
 co
in
ag
es
 
Su
m
 of
 di
ffe
re
nt
 co
in
ag
es
 
Su
m
 of
 di
ffe
re
nt
 co
in
ag
es
 
days days days 
Different geddon-coinages over time Different athon-coinages over time Different gate-coinages over time 
Figure 2: The number of different coinages containing the suffixes under investigation (on the y-axis) plotted
against the number of days passed during the monitoring process (on the x-axis)
Data  used 
in Figure  4  
PDWFK ODQJXDJH
$SU $XJ 'H] $SU $XJ 'H] $SU $XJ 'H]
7DJYRQHPPBSXEOLFDWLRQGDWH
:XOIJDWH H
<DFKWJDWH HQ
<DFKWVJDWH HQ
<HRQJSRJDWH HQ
<HRQJSRJDWH HQ
<RXQJSRJDWH HQ
<XQXVJDWH HQ
=DKLDJDWH IU
=LIDJDWH HQ
=LPEDEZHJDWH HQ
=LQHEJDWH IU
=LSSHUJDWH HQ
=LVFRJDWH HQ
=RUEDJDWH HQ
=XPDJDWH HQ
%ODW
ODQJXDJH
GH
HQ
IU
HPPBSXEOLFDWLRQGDWH7DJI?UMHGHODQJXDJHXQWHUWHLOWQDFKPDWFK)DUEH]HLJW'HWDLOV]XODQJXDJHDQ'HWDLOVZHUGHQI?UFRQWH[WXQGHPPBVRXUFHBFRXQWU\DQJH]HLJW'LH$QVLFKW
ZLUGXQWHUODQJXDJHXQGPDWFKJHILOWHUW'HU)LOWHUODQJXDJHVFKOLH?W,/XQG]KDXV'HU)LOWHUPDWFKVFKOLH?W1RWIDOVWURPDJUHJDWH1RWVURPDJJUHJDWH1RWVWURPDJJHJDWHXQG
1RWVWURPDJUHJDWHDXV
Figure 3: The appearances of the 15 most frequent -gate coinages over time and across the different languages
13
Figure 4: Detailed analysis of the Memogate cluster highlighted in Figure 3 using alternative visual mappings:
Sequence of spread over different countries and news sources.
sources within a short time range. We developed
a further visualization that shows how these men-
tions sequentially distribute over different news
sources and countries. In Figure 4 each article
mentioning Memogate is represented by a col-
ored icon. The y-axis position encodes the news
source, the x-axis position encodes the temporal
order of the occurrences. Note that exact time
differences are omitted to make the display more
compact. The shape of an icon indicates the lan-
guage of the article; Circles (English) heavily
dominate. The color encodes the country of origin
of the news source, here green (Pakistan), yellow
(India), and purple (USA) dominate.
Findings: While the first three mentions of
Memogate could be found in British and Amer-
ican Newspapers, early on it was adopted by
http://tribune.com.pk/ in Pakistan (fourth line
from the top) and used so heavily that it kept being
adopted and became constantly used by further
sources from Pakistan and also India. Apparently,
individual sources may have a huge influence on
the spread of a new coinage.
5 Future work and conclusion
We have presented initial experiments with re-
spect to the application of topic modeling and vi-
sualization to gain a better understanding of de-
velopments in morphological coinage and lexical
semantics. We investigated three relatively new
productive suffixes, namely -gate, -geddon, and
-athon based on their occurrences in newswire
data. Even though our data set was huge, the oc-
currences of the suffixes are comparatively rare
and so we only had enough data for -gate to inves-
tigate the contexts it occurs in with an optimized
topic modeling. The results indicate that it is used
in broader contexts than affair, with which it is
most related. Different domains of usage could be
distinguished, even though a clear development
over time could not be detected based the NYT
corpus. Investigating the multilingual newswire
data it became evident that all three suffixes un-
der investigation have a relatively stable rate of
appearance. Many more different -gate-coinages
could be found, though. We could observe that
-gate was usually attached to one specific single
event, and especially in many of the less frequent
coinages the suffix was combined with proper
names of persons, institutions, or locations. In
contrast, -athon and -mageddon coinages seem to
be easier to generalize. For example, the two most
widely spread coinages Snowmageddon and Car-
mageddon, while initially referring to a certain
snow storm and a certain traffic jam, have been
applied to further such events and can be found
listed in resources such as the Urban Dictionary.4
In conclusion, we demonstrated that visual
analyses can help to gain insight and generate new
hypotheses about the behavior of the distribution
and use of new morphemes. In our future research
we aim to investigate how much the success of a
certain coinage depends on the event as such and
its news dynamics, and what role linguistic fea-
tures like e.g. phonology (two vs. three syllables,
etc.) might play.
4http://www.urbandictionary.com/define.php?term=Carmageddon
14
Acknowledgments
This work has partly been funded by the Research
Initiative ?Computational Analysis of Linguistic
Development? at the University of Konstanz and
by the German Research Society (DFG) under the
grant GK-1042, Explorative Analysis and Visu-
alization of Large Information Spaces, Konstanz.
The authors would like to thank Volker Rehberg
for his programming support and Thomas Mayer
for comments on previous versions of the paper.
References
Martin Atkinson and Erik Van der Goot. 2009. Near
real time information mining in multilingual news.
In Juan Quemada, Gonzalo Leo?n, Yoe?lle S. Maarek,
and Wolfgang Nejdl, editors, Proceedings of the
18th International Conference on World Wide Web,
WWW 2009, Madrid, Spain, April 20-24, 2009,
pages 1153?1154.
R. Harald Baayen. 1992. On frequency, transparency,
and productivity. Yearbook of Morphology, pages
181?208.
David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent dirichlet alocation. Journal of Ma-
chine Learning Research, 3:993?1022.
Samuel Brody and Mirella Lapata. 2009. Bayesian
word sense induction. In Proceedings of the 12th
Conference of the European Chapter of the Asso-
ciation for Computational Linguistics, EACL ?09,
pages 103?111, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Stuart K. Card, Jock D. Mackinlay, and Ben Shneider-
man, editors. 1999. Readings in information visu-
alization: using vision to think. Morgan Kaufmann
Publishers Inc., San Francisco, CA, USA.
Thomas L. Griffiths and Mark Steyver. 2004. Find-
ing scientific topics. In Proceedings of the National
Academy of Sciences 101, pages 5228?5235.
Timo Honkela, Ville Pulkki, and Teuvo Kohonen.
1995. Contextual relations of words in grimm tales,
analyzed by self-organizing map. In Proceedings of
International Conference on Artificial Neural Net-
works (ICANN-95), pages 3?7.
Daniel A. Keim, Joern Kohlhammer, Geoffrey Ellis,
and Florian Mansmann, editors. 2010. Mastering
The Information Age - Solving Problems with Visual
Analytics. Goslar: Eurographics.
Milos Krstajic, Florian Mansmann, Andreas Stoffel,
Martin Atkinson, and Daniel A. Keim. 2010. Pro-
cessing Online News Streams for Large-Scale Se-
mantic Analysis. In Proceedings of the 1st Inter-
national Workshop on Data Engineering meets the
Semantic Web (DESWeb 2010).
Anke Lu?deling and Stefan Evert. 2005. The emer-
gence of productive non-medical -itis. corpus ev-
idence and qualitative analysis. In S. Kepser
and M. Reis, editors, Linguistic Evidence. Empir-
ical, Theoretical, and Computational Perspectives,
pages 351?370. Berlin: Mouton de Gruyter.
Thomas Mayer, Christian Rohrdantz, Miriam Butt,
Frans Plank, and Daniel Keim. 2010a. Visualiz-
ing vowel harmony. Journal of Linguistic Issues in
Language Technology (LiLT), 4(2).
Thomas Mayer, Christian Rohrdantz, Frans Plank,
Peter Bak, Miriam Butt, and Daniel A. Keim.
2010b. Consonant co-occurrence in stems across
languages: Automatic analysis and visualization of
a phonotactic constraint. In Proceedings of the ACL
2010 Workshop on NLP and Linguistics: Finding
the Common Ground (NLPLING 2010), pages 67?
75.
Eiji Nishimoto. 2004. Defining new words in corpus
data: Productivity of english suffixes in the british
national corpus. In 26th Annual Meeting of the
Cognitive Science Society.
Ingo Plag. 1999. Morphological productivity. Struc-
tural constraints in English derivation. Berlin/New
York: Mouton de Gruyter.
Christian Rohrdantz, Annette Hautli, Thomas Mayer,
Miriam Butt, Daniel A. Keim, and Frans Plank.
2011. Towards tracking semantic change by vi-
sual analytics. In Proceedings of the 49th An-
nual Meeting of the Association for Computational
Linguistics: Human Langauge Technologies (ACL-
HLT ?11): shortpapers, pages 305?310, Portland,
Oregon. Association for Computational Linguistics.
James J. Thomas and Kristin A. Cook. 2005. Illu-
minating the Path The Research and Development
Agenda for Visual Analytics. National Visualization
and Analytics Center.
15
Proceedings of the EACL 2014 Workshop on Computational Approaches to Causality in Language, pages 20?27,
Gothenburg, Sweden, April 26, 2014.
c
?2014 Association for Computational Linguistics
Automatic detection of causal relations in German multilogs
Tina B
?
ogel Annette Hautli-Janisz Sebastian Sulger Miriam Butt
Department of Linguistics
University of Konstanz
firstname.lastname@uni-konstanz.de
Abstract
This paper introduces a linguistically-
motivated, rule-based annotation system
for causal discourse relations in transcripts
of spoken multilogs in German. The over-
all aim is an automatic means of determin-
ing the degree of justification provided by
a speaker in the delivery of an argument
in a multiparty discussion. The system
comprises of two parts: A disambiguation
module which differentiates causal con-
nectors from their other senses, and a dis-
course relation annotation system which
marks the spans of text that constitute the
reason and the result/conclusion expressed
by the causal relation. The system is eval-
uated against a gold standard of German
transcribed spoken dialogue. The results
show that our system performs reliably
well with respect to both tasks.
1 Introduction
In general, causality refers to the way of know-
ing whether one state of affairs is causally related
to another.
1
Within linguistics, causality has long
been established as a central phenomenon for in-
vestigation. In this paper, we look at causality
from the perspective of a research question from
political science, where the notion is particularly
important when it comes to determining (a.o.) the
deliberative quality of a discussion. The notion of
deliberation is originally due to Habermas (1981),
who assumes that within a deliberative democ-
racy, stakeholders participating in a multilog, i.e.
a multi-party conversation, justify their positions
truthfully, rationally and respectfully and eventu-
ally defer to the better argument. Within polit-
ical science, the question arises whether actual
1
This work is part of the BMBF funded eHumanities
project VisArgue, an interdisciplinary cooperation between
political science, computer science and linguistics.
multilogs conducted in the process of a demo-
cratic decision making indeed follow this ideal
and whether/how one can use automatic means to
analyze the degree of deliberativity of a multilog
(Dryzek (1990; 2000), Bohman (1996), Gutmann
and Thompson (1996), Holzinger and Landwehr
(2010)). The disambiguation of causal discourse
markers and the determination of the relations they
entail is a crucial aspect of measuring the delibera-
tive quality of a multilog. In this paper, we develop
a system that is designed to perform this task.
We describe a linguistically motivated, rule-
based annotation system for German which disam-
biguates the multiple usages of causal discourse
connectors in the language and reliably annotates
the reason and result/conclusion relations that the
connectors introduce. The paper proceeds as fol-
lows: Section 2 briefly reviews related work on the
automatic extraction and annotation of causal rela-
tions, followed by a set of examples that illustrate
some of the linguistic patterns in German (Sec-
tion 3). We then introduce our rule-based anno-
tation system (Section 4) and evaluate it against a
hand-crafted gold standard in Section 5, where we
also present the results from the same annotation
task performed by a group of human annotators.
In Section 6, we provide an in-depth system error
analysis. Section 7 concludes the paper.
2 Related work
The automatic detection and annotation of causal-
ity in language has been approached from various
angles, for example by providing gold-standard,
(manually) annotated resources such as the Penn
Discourse Treebank for English (Prasad et al.,
2008), which was used, e.g., in the disambigua-
tion of English connectives by Pitler and Nenkova
(2009), the Potsdam Commentary Corpus for Ger-
man (Stede, 2004) and the discourse annotation
layer of Tu?ba-D/Z, a corpus of written German
text (Versley and Gastel, 2012). Training auto-
20
matic systems that learn patterns of causality (Do
et al., 2011; Mulkar-Mehta et al., 2011b, inter
alia) is a crucial factor in measuring discourse
coherence (Sanders, 2005), and is beneficial in
approaches to question-answering (Girju, 2003;
Prasad and Joshi, 2008).
With respect to automatically detecting causal
relations in German, Versley (2010) uses English
training data from the Penn Discourse Treebank in
order to train an English annotation model. These
English annotations can be projected to German
in an English-German parallel corpus and on the
basis of this a classifier of German discourse rela-
tions is trained. However, as previous studies have
shown (Mulkar-Mehta et al., 2011a, inter alia), the
reliability of detecting causal relations with auto-
matic means differs highly between different gen-
res. Our data consist of transcriptions of originally
spoken multilogs and this type of data differs sub-
stantially from newspaper or other written texts.
Regarding the disambiguation of German con-
nectives, Schneider and Stede (2012) carried out
a corpus study of 42 German discourse connec-
tives which are listed by Dipper and Stede (2006)
as exhibiting a certain degree of ambiguity. Their
results indicate that for a majority of ambigu-
ous connectives, plain POS tagging is not reliable
enough, and even contextual POS patterns are not
sufficient in all cases. This is the same conclu-
sion drawn by Dipper and Stede (2006), who also
state that off-the-shelf POS taggers are too unre-
liable for the task. They instead suggest a map-
ping approach for 9 out of the 42 connectives
and show that this assists considerably with dis-
ambiguation. As this also tallies with our experi-
ments with POS taggers, we decided to implement
a rule-based disambiguation module. This mod-
ule takes into account contextual patterns and fea-
tures of spoken communication and reliably de-
tects causal connectors as well as the reason and
result/conclusion discourse relations expressed in
the connected clauses.
3 Linguistic phenomenon
In general, causality can hold between single
concepts, e.g. between ?smoke? and ?fire?, or be-
tween larger phrases. The phrases can be put into
a causal relation via overt discourse connectors
like ?because? or ?as?, whereas other phrases en-
code causality implicitly by taking into account
world knowledge about the connected events. In
this paper, we restrict ourselves to the analysis of
explicit discourse markers; in particular we inves-
tigate the eight most frequent German causal con-
nectors, listed in Table 1. The markers of reason
on the left head a subordinate clause that describes
the cause of an effect stated in the matrix clause
(or in the previous sentence(s)). The markers of
result/conclusion on the other hand introduce a
clause that describes the overall effect of a cause
contained in the preceding clause/sentence(s). In
the genre of argumentation that we are working
with, the ?results? tend to be logical conclusions
that the speaker sees as following irrevocably from
the cause presented in the argument.
Reason Result
?because of? ?thus?
da daher
weil darum
denn deshalb
zumal deswegen
Table 1: German causal discourse connectors
The sentences in (1) and (2) provide exam-
ples of the phenomenon of explicit causal mark-
ers in German in our multilogs. Note that all
of the causal markers in Table 1 connect a re-
sult/conclusion with a cause/reason. The differ-
ence lies in which of these relations is expressed
in the clause headed by the causal connector.
The constructions in (1) and (2) exemplify this.
2
In (1), da ?since? introduces the reason for the con-
clusion in the matrix clause, i.e., the reason for
the travel times being irrelevant is that they are not
carried out as specified. In (2), daher ?thus? heads
the conclusion of the reason which is provided in
the matrix clause: Because the speaker has never
stated a fact, the accusation of the interlocutor is
not correct.
There are several challenges in the automatic
annotation of these relations. First, some of the
connectors can be ambiguous. In our case, four
out of the eight causal discourse connectors in Ta-
ble 1 are ambiguous (da, denn, daher and darum)
and have, in addition to their causal meaning, tem-
poral, locational or other usages. In example (3),
denn is used as a particle signaling disbelief, while
daher is used as a locational verb particle, having,
together with the verb ?to come?, the interpretation
2
These examples are taken from the Stuttgart 21 arbitra-
tion process, see section 5.1 for more information.
21
(1) Diese Fahrzeiten sind irrelevant, da sie so nicht gefahren werden.
Art.Dem travel time.Pl be.3.Pl irrelevant because they like not drive.Perf.Part be.Fut.3.Pl
Result/Conclusion Reason
?These travel times are irrelevant, because they are not executed as specified.?
(2) Das habe ich nicht gesagt, daher ist Ihr Vorwurf nicht richtig
Pron have.Pres.1.Sg I not say.Past.Part thus be.3.Sg you.Sg.Pol/Pl accusation not correct
Reason Result/Conclusion
?I did not say that, therefore your accusation is not correct.?
(3) Wie kommen Sie denn daher?
how come.Inf you.Sg.Pol then VPart
?What is your problem anyway?? (lit. ?In what manner are you coming here??)
(4) Da bin ich mir nicht sicher.
there be.Pres.1.Sg I I.Dat not sure
?I?m not sure about that.?
(5) Das kommt daher, dass keiner etwas sagt.
Pron come.Pres.3.Sg thus that nobody something say.Pres.3.Sg
Result/Conclusion Reason
?This is because nobody says anything.?
of ?coming from somewhere to where the speaker
is? (literally and metaphorically). In a second ex-
ample in (4), da is used as the pronominal ?there?.
Second, some of the causal connectors do not
always work the same way. In (5), the re-
sult/conclusion connector daher does not head
an embedded clause, rather it is part of the
matrix clause. In this case, the embedded
clause expresses the reason rather than the re-
sult/conclusion. A third challenge is the span of
the respective reason and result. While there are
some indications as to how to define the stretch
of these spans, there are some difficult challenges,
further discussed in the error analysis in Section 6.
In the following, we present the rule-based an-
notation system, which deals with the identifica-
tion of phrases expressing the result and reason,
along the lines illustrated in (1) and (2), as well as
with the disambiguation of causal connectors.
4 Rule-based annotation system
The automatic annotation system that we intro-
duce is based on a linguistically informed, hand-
crafted set of rules that deals with the disambigua-
tion of causal markers and the identification of
causal relations in text. As a first step, we divide
all of the utterances into smaller units of text in or-
der to be able to work with a more fine-grained
structure of the discourse. Following the liter-
ature, we call these discourse units. Although
there is no consensus in the literature on what ex-
actly a discourse unit consists of, it is generally
assumed that each discourse unit describes a sin-
gle event (Polanyi et al., 2004). Following Marcu
(2000), we term these elementary discourse units
(EDUs) and approximate the assumption made by
Polanyi et al. (2004) by inserting a boundary at
every punctuation mark and every clausal con-
nector (conjunctions, complementizers). Sentence
boundaries are additionally marked.
The annotation of discourse information is per-
formed at the level of EDUs. There are sometimes
instances in which a given relation such as ?rea-
son? spans multiple EDUs. In these cases, each of
the EDUs involved is marked/annotated individu-
ally with the appropriate relation.
In the following, we briefly lay out the two ele-
ments of the annotation system, namely the disam-
biguation module and the system for identifying
the causal relations.
22
4.1 Disambiguation
As shown in the examples above, markers like
da, denn, darum and daher ?because/thus? have a
number of different senses. The results presented
in Dipper and Stede (2006) indicate that POS tag-
ging alone does not help in disambiguating the
causal usages from the other functions, particu-
larly not for our data type, which includes much
noise and exceptional constructions that are not
present in written corpora. As a consequence, we
propose a set of rules built on heuristics, which
take into account a number of factors in the clause
in order to disambiguate the connector. To il-
lustrate the underlying procedure, (6) schematizes
part of the disambiguation rule for the German
causal connector da ?since?.
(6) IF da is not followed directly by a verb AND
no other particle or connector precedes da
AND
da is not late in the EDU THEN
da is a causal connector.
In total, the system comprises of 37 rules that
disambiguate the causal connectors shown in Ta-
ble 1. The evaluation in Section 5 shows that the
system performs well overall.
3
4.2 Relation identification
After disambiguation, a second set of rules anno-
tates discourse units as being part of the reason or
the result portion of a causal relation. One aspect
of deliberation is the assumption that participants
in a negotiation justify their positions. Therefore,
in this paper, we analyze causal relations within a
3
Two reviewers expressed interest in being able to access
our full set of rules. Their reasons were two-fold. For one,
sharing our rules would benefit a larger community. For an-
other, the reviewers cited concerns with respect to replicabil-
ity. With respect to the first concern, we will naturally be
happy to share our rule set with interested researchers. With
respect to the second concern, it is not clear to us that we
have understood it. As far as we can tell, what seems to be at
the root of the comments is a very narrow notion of replica-
bility, one which involves a freely available corpus in combi-
nation with a freely available automatic processing tool (e.g.,
a machine learning algorithm) that can then be used together
without the need of specialist language knowledge. We freely
admit that our approach requires specialist linguistic training,
but would like to note that linguistic analysis is routinely sub-
ject to replicability in the sense that given a set of data, the
linguistic analysis arrived at should be consistent across dif-
ferent sets of linguists. In this sense, our work is immediately
replicable. Moreover, given the publically available S21 data
set and the easily accessible and comprehensive descriptions
of German grammar, replication of our work is eminently
possible.
single utterance of a speaker, i.e., causal relations
that are expressed in a sequence of clauses which
a speaker utters without interference from another
speaker. As a consequence, the annotation system
does not take into account causal relations that are
split up between utterances of one speaker or ut-
terances of different speakers.
Nevertheless, the reason and result portion
of a causal relation can extend over multiple
EDUs/sentences and this means that not only EDUs
which contain the connector itself are annotated,
but preceding/following units that are part of the
causal relation also have to be marked. This in-
volves deep linguistic knowledge about the cues
that delimit or license relations, information which
is encoded in a set of heuristics that feed the 20 dif-
ferent annotation rules and mark the relevant units.
An example for a (simplified) relation annotation
is given in (7).
(7) IF result connector not in first EDU of sen-
tence AND
result connector not preceded by other con-
nector within same sentence THEN
mark every EDU from sentence beginning to
current EDU with reason.
ELSIF result connector in first EDU of sen-
tence THEN
mark every EDU in previous sentence with
reason UNLESS
encountering another connector.
5 Evaluation
The evaluation is split into two parts. On the one
hand, we evaluate the inter-annotator agreement
between five, minimally trained annotators (?5.2).
On the other hand, we evaluate the rule-based
annotation system against this hand-crafted gold-
standard (?5.3). Each evaluation is again split into
two parts: One concerns the successful identifica-
tion of the causal connectors. The other concerns
the identification of the spans of multilog that in-
dicate a result/conclusion vs. a reason.
5.1 Data
The underlying data comprises of two data sets,
the development and the test set. The develop-
ment set, on which the above-mentioned heuristics
for disambiguation and relation identification are
based, consists of the transcribed protocols of the
Stuttgart 21 arbitration process (henceforth: S21).
This public arbitration process took place in 2010
23
and was concerned with a railway and urban de-
velopment project in the German city of Stuttgart.
The project remains highly controversial and has
gained international attention. In total, the tran-
scripts contain around 265.000 tokens in 1330 ut-
terances of more than 70 participants.
4
The test set is based on different, but also tran-
scribed natural speech data, namely on experi-
ments simulating deliberative processes for estab-
lishing a governmental form for a hypothetical
new African country.
5
For testing, we randomly
collected utterances from two versions of the ex-
periment. Each utterance contained at least two
causal discourse connectors. In total, we extracted
60 utterances with an average length of 71 words.
There are a total of 666 EDUs and 105 instances
of the markers in Table 1. The composition of the
test set for each (possible) connector is in Table 2.
Reason Result
?because of? ?due to?
da 23 daher 10
weil 17 darum 11
denn 17 deshalb 12
zumal 4 deswegen 11
Total: 61 44
Table 2: Structure of the evaluation set
For the creation of a gold standard, the test set
was manually annotated by two linguistic experts.
238 out of 666 EDUs were marked as being part
of the reason of a causal relation, with the re-
sult/conclusion contributed by 180 EDUs. Out of
105 connectors found in the test set, 87 have a
causal usage. In 18 cases, the markers have other
functions.
5.2 Inter-annotator agreement
The task for the annotators comprised of two parts:
First, five students (undergraduates in linguistics)
had to decide wether an occurence of one of the
elements in Table 1 was a causal marker or not.
In a second step, they had to mark the bound-
aries for the reason and result/conclusion parts of
the causal relation, based on the boundaries of the
automatically generated EDUs. Their annotation
choice was not restricted by, e.g., instructing them
4
The transcripts are publicly available for down-
load under http://stuttgart21.wikiwam.de/
Schlichtungsprotokolle
5
These have been produced by our collaborators in polit-
ical science, Katharina Holzinger and Valentin Gold.
to choose a ?wider? or more ?narrow? span when
in doubt. These tasks served two purposes: On
the one hand, we were able to evaluate how easily
causal markers can be disambiguated from their
other usages and how clearly they introduce either
the reason or the result/conclusion of a causal re-
lation. On the other hand, we gained insights into
what span of discourse native speakers take to con-
stitute a result/conclusion and cause/reason.
For calculating the inter-annotator agreement
(IAA), we used Fleiss? kappa (Fleiss, 1971), which
measures the reliability of the agreement between
more than two annotators. In the disambiguation
task, the annotators? kappa is ? = 0.96 (?almost
perfect agreement?), which shows that the annota-
tors exhibit a high degree of confidence when dif-
ferentiating between causal and other usages of the
markers. When marking whether a connector an-
notates the reason or the result/conclusion portion
of a causal relation, the annotators have a kappa
of ? = 0.86. This shows that not only are anno-
tators capable of reliably disambiguating connec-
tors, they are also reliably labeling each connector
with the correct causal relation.
In evaluating the IAA of the spans, we mea-
sured three types of relations (reason, result and
no causal relation) over the whole utterance, i.e.
each EDU which is neither part of the result nor the
reason relation was tagged as having no causal re-
lation. We calculated four different ? values: one
for each relation type (vs. all other relation types),
and one across all relation types. The IAA fig-
ures are summarized in Table 3: For the causal
relation types, ?
Reason
=0.86 and ?
Result
=0.90 in-
dicate near-perfect agreement. ? is significantly
higher for causal EDUs than for non-causal (i.e.,
unmarked) EDUs (?
Non-causal
=0.82); this is in fact
expected since causal EDUs are the marked case
and are thus easier to identify for annotators in a
coherent manner.
IAA
?
Reason
0.86
?
Result
0.90
?
Non-causal
0.82
?
All
0.73
Table 3: IAA of span annotations
Across all relation types, ?
All
=0.73 indicates
?substantial agreement?. The drop in the agree-
ment is anticipated and mirrors the problem that
24
is generally found in the literature when evalu-
ating spans of discourse relations (Sporleder and
Lascarides, 2008). First, measuring ?
All
involves
three categories, whereas the other measures in-
volve two. Second, a preliminary error analysis
shows that there is substantial disagreement re-
garding the extent of both reason and result spans.
The examples in (8)?(9) illustrate this. While an-
notator 1 marks the result span (indicated by the
( S tag) as starting at the beginning of the sentence,
annotator 2 excludes the first EDU from the result
span.
6
In such cases, we thus register a mismatch
in the annotation of the first EDU.
Nevertheless, the numbers indicate a substantial
agreement. We thus conclude that the task we set
the annotators could be accomplished reliably.
5.3 System performance
In order to evaluate the automatic annotation sys-
tem described in Section 4, we match the system
output against the manually-annotated gold stan-
dard, calculating precision, recall and (balanced)
f-score of the annotation. For the disambiguation
of the connectors in terms of causal versus other
usages, the system performs as shown in Table 4
(the ? indicates the average of both values).
Precision Recall F-score
Causal 1 0.94 0.97
Non-causal 0.85 1 0.92
? 0.93 0.97 0.95
Table 4: Causal marker disambiguation
This result is very promising and shows that
even though the development data consists of data
from a different source, the patterns in the de-
velopment set are mirrored in the test set. This
means that the genre of the spoken exchange of
arguments in a multilog does not exhibit the dif-
ferences usually found when looking at data from
different genres, as Mulkar-Mehta et al. (2011a)
report when comparing newspaper articles from fi-
nance and sport.
For evaluating the annotated spans of reason
and result, we base the calculation on whether an
EDU is marked with a particular relation or not, i.e.
if the system marks an EDU as belonging to the
reason or result part of a particular causal marker
and the gold standard encodes the same informa-
tion, then the two discourse units match. As a con-
6
We use the | sign to indicate EDU boundaries.
sequence, spans which do not match perfectly, for
example in cases where their boundaries do not
match, are not treated as non-matching instances
as a whole, but are considered to be made up of
smaller units which match individually. Table 5
shows the results.
Precision Recall F-score
Reason 0.88 0.75 0.81
Result 0.81 0.94 0.87
? 0.84 0.84 0.84
Table 5: Results for relation identification
These results are promising insofar as the de-
tection of spans of causal relations is known to be
a problem. Again, this shows that development
and test set seem to exhibit similar patterns, de-
spite their different origins (actual political argu-
mentation vs. an experimental set-up). In the fol-
lowing, we present a detailed error analysis and
show that we find recurrent patterns of mismatch,
most of which can in principle be dealt with quite
straightforwardly.
6 Error analysis
Figure 1: Error analysis, in percent.
Figure 1 shows a pie chart in which each prob-
lem is identified and shown with its share in
the overall error occurrence. In total, the sys-
tem makes 26 annotation errors. Starting from
the top, empty connector position refers to struc-
tures which an annotator can easily define as rea-
son/result, but which do not contain an overt con-
nector. This causes the automatic annotation sys-
25
(8) Annotator 1:
( S Ich mo?chte an dieser Stelle einwerfen, | dass die Frage, ob ...
I would like.Pres.1.Sg at this point add.Inf that the question if ...
?I?d like to add at this point that the question if...
(9) Annotator 2:
Ich mo?chte an dieser Stelle einwerfen, | ( S dass die Frage, ob ...
I would like.Pres.1.Sg at this point add.Inf that the question if ...
?I?d like to add at this point that the question if...
tem to fail. The group of other connectors refers to
cases where a non-causal connector (e.g., the ad-
versative conjunction aber ?but?) signals the end
of the result/conclusion or cause span for a human
annotator. The presence of these other connectors
and their effect is not yet taken into account by the
automatic annotation system. The error group iaa
refers to the cases where we find a debatable dif-
ference of opinion with respect to the length of a
span. Speaker opinion refers to those cases where
a statement starts with expressions like ?I believe
/ I think / in my opinion etc.?. These are mostly
excluded from a relation span by human anno-
tators, but (again: as of yet) not by the system.
Span over several sentences refers to those cases
where the span includes several sentences. And
last, but not least, since the corpus consists of spo-
ken data, an external transcriptor had to transcribe
the speech signal into written text. Some low-level
errors in this category are missing sentence punc-
tuation. The human annotators were able to com-
pensate for this, but not the automatic system.
Roughly, three groups of errors can be distin-
guished. Some of the errors are relatively easy
to solve, by, e.g., adding another class of con-
nectors, by adding expressions or by correcting
the transcriptors script. A second group (span
over several sentences and empty connector po-
sition) needs a much more sophisticated system,
including deep linguistic knowledge on semantics,
pragmatics and notoriously difficult aspects of dis-
course analysis like anaphora resolution.
7 Conclusion
In conclusion, we have presented an automatic an-
notation system which can reliably and precisely
detect German causal relations with respect to
eight causal connectors in multilogs in which ar-
guments are exchanged and each party is trying to
convince the other of the rightness of their stance.
Our system is rule-based and takes into account
linguistic knowledge at a similar level as that used
by human annotators. Our work will directly ben-
efit research in political science as it can flow into
providing one measure for the deliberative qual-
ity of a multilog, namely, do interlocutors support
their arguments with reasons or not?
References
James Bohman. 1996. Public Deliberation: Plural-
ism, Complexity and Democracy. The MIT Press,
Cambridge, MA.
Stefanie Dipper and Manfred Stede. 2006. Disam-
biguating potential connectives. In Proceedings of
KONVENS (Conference on Natural Language Pro-
cessing) 2006.
Quang Xuan Do, Yee Seng Chan, and Dan Roth. 2011.
Minimally Supervised Event Causality Identifica-
tion. In Proceedings of EMNLP?11, pages 294?303.
John S. Dryzek. 1990. Discursive Democracy: Poli-
tics, Policy, and Political Science. Cambridge Uni-
versity Press, Cambridge, MA.
John S. Dryzek. 2000. Deliberative Democracy and
Beyond: Liberals, Critics, Contestations. Oxford
University Press, Oxford.
Joseph L. Fleiss. 1971. Measuring nominal scale
agreement among many raters. Psychological Bul-
letin, 76(5):378?382.
Roxana Girju. 2003. Automatic Detection of Causal
Relations for Question-Answering. In Proceedings
of the ACL Workshop on Multilingual summariza-
tion and question-answering, pages 76?83.
Amy Gutmann and Dennis Frank Thompson. 1996.
Democracy and Disagreement. Why moral conflict
cannot be avoided in politics, and what should be
done about it. Harvard University Press, Cam-
bridge, MA.
Ju?rgen Habermas. 1981. Theorie des kommunikativen
Handelns. Suhrkamp, Frankfurt am Main.
Katharina Holzinger and Claudia Landwehr. 2010. In-
stitutional determinants of deliberative interaction.
European Political Science Review, 2:373?400.
26
Daniel Marcu. 2000. The Theory and Practice of
Discourse Parsing and Summarization. MIT Press,
Cambridge, Mass.
Rutu Mulkar-Mehta, Andrew S. Gordon, Jerry Hobbs,
and Eduard Hovy. 2011a. Causal markers across
domains and genres of discourse. In The 6th Inter-
national Conference on Knowledge Capture.
Rutu Mulkar-Mehta, Christopher Welty, Jerry R.
Hoobs, and Eduard Hovy. 2011b. Using granularity
concepts for discovering causal relations. In Pro-
ceedings of the FLAIRS conference.
Emily Pitler and Ani Nenkova. 2009. Using syntax to
disambiguate explicit discourse connectives in text.
In Proceedings of ACL-IJCNLP, pages 13?16.
Livia Polanyi, Chris Culy, Martin van den Berg,
Gian Lorenzo Thione, and David Ahn. 2004. Sen-
tential structure and discourse parsing. In Proceed-
ings of the 2004 ACL Workshop on Discourse Anno-
tation, pages 80?87.
Rashmi Prasad and Aravind Joshi. 2008. A Discourse-
based Approach to Generating Why-Questions from
Texts. In Proceedings of the Workshop on the Ques-
tion Generation Shared Task and Evaluation Chal-
lenge.
Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Milt-
sakaki, Livio Robaldo, Aravind Joshi, and Bonnie
Webber. 2008. The Penn Discourse Treebank 2.0.
In Proceedings of LREC 2008, pages 2961?2968.
Ted Sanders. 2005. Coherence, Causality and Cog-
nitive Complexity in Discourse. In Proceedings of
SEM-05, First International Symposium on the Ex-
ploratiaon and Modelling of Meaning, pages 105?
114.
Angela Schneider and Manfred Stede. 2012. Ambi-
guity in German Connectives: A Corpus Study. In
Proceedings of KONVENS (Conference on Natural
Language Processing) 2012.
Caroline Sporleder and Alex Lascarides. 2008. Us-
ing Automatically Labelled Examples to Classify
Rhetorical Relations: An Assessment. Natural Lan-
guage Engineering, 14(3):369?416.
Manfred Stede. 2004. The Potsdam Commentary Cor-
pus. In In Proceedings of the ACL?04 Workshop on
Discourse Annotation, pages 96?102.
Yannick Versley and Anna Gastel. 2012. Linguistic
Tests for Discourse Relations in the Tu?ba-D/Z Cor-
pus of Written German. Dialogue and Discourse,
1(2):1?24.
Yannick Versley. 2010. Discovery of Ambiguous and
Unambiguous Discourse Connectives via Annota-
tion Projection. In Workshop on the Annotation and
Exploitation of Parallel Corpora (AEPC).
27
