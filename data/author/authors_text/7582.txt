Recognition of synonyms by a lexical graph
Peter Siniakov
siniakov@inf.fu-berlin.de
Database and Information Systems Group, Freie Universita?t Berlin
Takustr. 9, 14195 Berlin, Germany
Abstract
Semantic relationships between words
comprised by thesauri are essential fea-
tures for IR, text mining and informa-
tion extraction systems. This paper in-
troduces a new approach to identifica-
tion of semantic relations such as syn-
onymy by a lexical graph. The graph
is generated from a text corpus by em-
bedding syntactically parsed sentences
in the graph structure. The vertices
of the graph are lexical items (words),
their connection follows the syntactic
structure of a sentence. The struc-
ture of the graph and distances be-
tween vertices can be utilized to define
metrics for identification of semantic
relations. The approach has been eval-
uated on a test set of 200 German syn-
onym sets. Influence of size of the text
corpus, word generality and frequency
has been investigated. Conducted ex-
periments for synonyms demonstrate
that the presented methods can be ex-
tended to other semantic relations.
1 Introduction
Once predominantly used by human authors
to improve their style avoiding repetitions of
words or phrases, thesauri now serve as an im-
portant source of semantic and lexical infor-
mation for automatic text processing. The
electronic online thesauri such as WordNet
(2005) and OpenThesaurus (2005) have been
increasingly employed for many IR and NLP
problems. However, considerable human ef-
fort is required to keep up with the evolving
language and many subdomains are not suffi-
ciently covered (Turney, 2001). Many domain-
specific words or word senses are not included;
inconsistency and bias are often cited as fur-
ther major deficiencies of hand-made thesauri
(Curran and Moens, 2002), (Senellart and
Blondel, 2003). There is a continuous demand
for automatic identification of semantic rela-
tions and thesaurus generation. Such tools
do not only produce thesauri that are more
adapted to a particular application in a cer-
tain domain, but provide also assistance for
lexicographers in manual creation and keeping
the hand-written thesauri up to date. Numer-
ous applications in IR (e.g. query expansion)
and text mining (identification of relevant con-
tent by patterns) underline their usefulness.
2 Related work
Identification of semantic relations has been
approached by different communities as a com-
ponent of a knowledge management system or
application of a developed NLP framework.
Many approaches are guided by the assump-
tion that similar terms occur in similar context
and obtain a context representation of terms
as attribute vectors or relation tuples (Cur-
ran and Moens, 2002), (Ruge, 1997), (Lin,
1998). A similarity metric defined on the con-
text representations is used to cluster similar
terms (e.g. by the nearest neighbor method).
The actual definitions of context (whole doc-
ument (Chen and Lynch, 1992), textual win-
dow, some customized syntactic contexts, cf.
(Senellart and Blondel, 2003)) and similar-
ity metric (cf. (Manning and Schu?tze, 1999),
(Curran and Moens, 2002)) are the essential
distinguishing features of the approaches.
A pattern-based method is proposed by
Hearst (Hearst, 1998). Existing relations in
the WordNet database are used to discover
regular linguistic patterns that are character-
istic for these relations. The patterns contain
lexical and syntactic elements and are acquired
32
from a text corpus by identifying common con-
text of word pairs for which a semantic rela-
tion holds. Identified patterns are applied to a
large text corpus to detect new relations. The
method can be enhanced by applying filtering
steps and iterating over new found instances
(Phillips and Riloff, 2002).
Lafourcade and Prince base their approach
on reduction of word semantics to conceptual
vectors (vector space is spanned by a hierarchy
of concepts provided by a thesaurus, (Lafour-
cade, 2001)). Every term is projected in the
vector space and can be expressed by the linear
combination of conceptual vectors. The angle
between the vectorial representations of two
terms is used in calculation of thematic close-
ness (Lafourcade and Prince, 2001). The ap-
proach is more closely related to our approach
since it offers a quantitative metric to measure
the degree of synonymy between two lexical
items.
In contrast, Turney (Turney, 2001) tries to
solve a quite simpler ?TOEFL-like? task of se-
lecting a synonym to a given word from a set
of words. Mutual information related to the
co-occurrence of two words combined with in-
formation retrieval is used to assess the degree
of their statistical independency. The least in-
dependent word is regarded synonymous.
Blondell et al (Blondel et al, 2004) encode
a monolingual dictionary as a graph and iden-
tify synonyms by finding subgraphs that are
similar to the subgraph corresponding to the
queried term.
The common evaluation method for similar-
ity metrics is comparing their performance on
the same test set with the same context repre-
sentations with some manually created seman-
tic source as the gold standard (Curran and
Moens, 2002). Abstracting from results for
concrete test sets, Weeds et al (2004) try to
identify statistical and linguistic properties on
that the performance of similarity metrics gen-
erally depends. Different bias towards words
with high or low frequency is recognized as one
reason for the significant variance of k-nearest
neighbors sets of different similarity metrics.
3 Construction of the lexical graph
The assumption that similar terms occur in
similar context leads to the establishing of ex-
plicit context models (e.g. in form of vectors or
relation tuples) by most researchers. We build
an implicit context representation connecting
lexical items in a way corresponding to the sen-
tence structure (as opposed to (Blondel et al,
2004)), where a term is linked to every word
in its definition). The advantage of the graph
model is its transitivity: not only terms in the
immediate context but also semantically re-
lated terms that have a short path to the ex-
amined term (but perhaps have never occurred
in its immediate context) can contribute to
identification of related terms. The similarity
metric can be intuitively derived from the dis-
tance between the lexical vertices in the graph.
Figure 1: Main steps during graph construc-
tion
To construct the lexical graph articles from
five volumes of two German computer jour-
nals have been chunk-parsed and POS tagged
using TreeTagger (2004). To preserve the se-
mantic structure of the sentences during the
graph construction, i.e. to connect words that
build the actual statement of the sentence,
parsed sentences are preprocessed before be-
ing inserted in the graph (fig. 1). The punc-
tuation signs and parts of speech that do not
carry a self-contained semantics (such as con-
junctions, pronouns, articles) are removed in
a POS filtering step. Tokenization errors are
heuristically removed and the words are re-
placed by their normal forms (e.g. infinitive
form for verbs, nominative singular for nouns).
German grammar is characterized by a very
frequent use of auxiliary and modal verbs that
in most cases immediately precede or follow
the semantically related sentence parts such
as direct object or prepositional phrase while
the main verb is often not adjacent to the
related parts in a sentence. Since the direct
edge between the main verb and non-adjacent
related sentence parts cannot be drawn, the
33
sentence is syntactically reorganized by replac-
ing the modal or auxiliary verbs by the corre-
sponding main verb. Another syntactic rear-
rangement takes place when detachable pre-
fixes are attached to the corresponding main
verb. In German some prefixes of verbs are
detached and located at the end of the main
clause. Since verbs without a prefix have a
different meaning prefixes have to be attached
to the verb stem. The reorganized sentence
Figure 2: An example of a sentence trans-
formed in a lexical graph
can be added to the graph inserting the nor-
malized words in a sentence as vertices and
connecting the adjacent words by a directed
edge. However, some adjacent words are not
semantically related to each other, therefore
the lexical graph features two types of edges
(see an example in fig. 2). A property edge
links the head word of a syntactic chunk (verb
or noun phrase) with its modifiers (adverbs or
adjectives respectively) that characterize the
head word and is bidirectional. A sequential
edge connects the head words (e.g. main verbs,
head nouns) of syntactic chunks reflecting the
?semantic backbone? of the sentence.
The length of an edge represents how strong
two lexical items are related to each other and
depends therefore on the frequency of their
co-occurrence. It is initialized with a maxi-
mum length M . Every time an existing edge
is found in the currently processed sentence,
its current length CurLen is modified accord-
ing to CurLen = MM
CurLen+1
; hence the length
of an edge is inversely proportional to the fre-
quency of co-occurrence of its endpoints.
After all sentences from the text corpus
have been added to the lexical graph, vertices
(words) with a low frequency (? ?) are re-
moved from the graph to primarily acceler-
ate the distance calculation. Such rarely oc-
curring words are usually proper nouns, ab-
breviations, typos etc. Because of the low
frequency semantic relations for these words
cannot be confidently identified. Therefore
removing such vertices reduces the size of
the graph significantly without performance
penalty (the graph generated from 5 journal
volumes contained ca. 300000 vertices and
52191 after frequency filtering with ? = 8).
Experimental results feature even a slightly
better performance on filtered graphs. To pre-
serve semantic consistency of the graph and
compensate removal of existing paths the con-
nections between the predecessors and succes-
sors of removed vertices have to be taken into
account: the edge length e(p, s) between the
predecessor p to the successor s of the re-
moved vertex r can incorporate the length of
the path length(p, r, s) from p to s through
r by calculating the halved harmonic mean:
e(p, s) = e(p,s)?lprse(p,s)+lprs . e(p, s) is the more re-
duced the smaller length(p, r, s) is and if they
are equal, e(p, s) is half as long after merging.
Beside direct edges an important indication
of semantic closeness is the distance, i.e. the
length of the shortest path between two ver-
tices. Distances are calculated by the Dijk-
stra algorithm with an upper threshold ?.
Once the distances from a certain vertex reach
the threshold, the calculation for this vertex
is aborted and the not calculated distances
are considered infinite. Using the threshold
reduces the runtime and space considerably
while the semantic relation between the ver-
tices with distances > ? is negligible.
The values of M , ? and ? depend on
the particular text corpus and are chosen
to keep the size of the graph feasible. ?
can be determined experimentally increment-
ing it as long as the results on the test set
are improving. The resulting graph gener-
ated from five computer journals volumes with
M = 220, ? = 8, ? = 60000 con-
tained 52191 vertices, 4,927,365 edges and
376,000,000 distances.
4 Identification of synonyms
The lexical graph is conceived as an instru-
ment to identify semantic relations such as
synonymy and hypernymy between lexical
items represented by its vertices. The main
34
focus of our research was finding synonyms al-
beit some results can be immediately trans-
ferred for identification of hyponyms. To pro-
vide a quantitative measure of synonymy dif-
ferent similarity metrics were defined on the
lexical graph. Given a word, the system uses
the metric to calculate the closest vertices to
the vertex that represents this word. The re-
sult is a ranked list of words sorted by the de-
gree of synonymy in descending order. Every
metric sim is normalized to be a probability
measure so that given a vertex vi the value
sim(vi, vj) can be interpreted as the probabil-
ity of vj being synonym to vi. The normaliza-
tion is performed for each metric sim by the
following functions:
nmin(sim(vi, vj)) = min(sim(vi,v1),...,sim(vi,vn))sim(vi,vj)
for metrics that indicate maximum similarity
to a vertex vi by a minimum value and
nmax(sim(vi, vj)) = sim(vi,vj)max(sim(vi,v1),...,sim(vi,vn))
for metrics that indicate maximum similarity
to a vertex vi by a maximum value, where
v1 . . . vn are the set of graph vertices. In both
cases the top-ranked word has the maximum
likelihood of 1 to be a synonym of vi. The
normalized ranked lists are used for the com-
parison of different metrics and the evaluation
of the approach (see sec. 5).
A similarity metric is supposed to assess the
semantic similarity between two vertices of the
lexical graph. Since the distance metric Dis-
tanceM used for calculation of distances be-
tween the vertices in the graph indicates how
semantically related two vertices are, it can be
used as a similarity metric. As the graph is di-
rected, the distance metric is asymmetric, i.e.
the distance from vj to vi does not have to
be equal to the distance from vi to vj . The
major drawback of the DistanceM is that it
takes into account only one path between the
examined vertices. Even though the shortest
path indicates a strong semantic relation be-
tween the vertices, it is not sufficient to con-
clude synonymy that presupposes similar word
senses.
Therefore more evidence for strong seman-
tic relation with the particular aspect of sim-
ilar word senses should be incorporated in
the similarity metric. The property neigh-
bors of a vertex vi (adjacent vertices connected
with vi by the property edge) play significant
role in characterizing similar senses. If two
terms share many characteristic properties,
there is a strong evidence of their synonymy.
A shared property can be regarded as a witness
of the similarity of two word senses. There
are other potential witnesses, e.g. transitive
verbs shared by their direct objects; however,
we restricted this investigation to the property
neighbors as the most reliable witnesses.
The simple method to incorporate the con-
cept of the witnesses into the metric is to
determine the number of common property
neighbors:
NaivePropM(vi, vj) = |prop(vi) ? prop(vj)|
where prop(vi) = {vk|e(i, k) is a property edge}
This method disregards, however, the different
degree of correlation between the vertices and
their property neighbors that is reflected by
the length of property edges. A property is the
more significant, the stronger the correlation
between the property and the vertex is, that
is the shorter the property edge is. The degree
of synonymy of two terms depends therefore
on the number of common properties and
the lengths of paths between these terms
leading through the properties. Analogously
to the electric circuit one can see the single
paths through different shared properties as
channels in a parallel connection and path
lengths as ?synonymy resistances?. Since a
bigger number of channels and smaller single
resistances contribute to the decreasing of the
total resistance (i.e. the evidence of synonymy
increases), the idea of WeiPropM metric is to
determine the similarity value analogously to
the total resistance in a parallel connection:
WeiPropM ?(vi, vj) =
( n
?
k=1
1
length(vi, pk, vj)
)?1
where length(vi, pk, vj) = e(vi, pk) + e(pk, vj)
is the length of the path from vi to vj through
pk and pk ? prop(vi) ? prop(vj).
Another useful observation is that some
properties are more valuable witnesses than
the others. There are very general properties
that are shared by many different terms and
35
some properties that are characteristic only
for certain word senses. Thus the number of
property neighbors of a property can be re-
garded as a measure of its quality (in the sense
of characterizing the specific word meaning).
WeiPropM integrates the quality of a prop-
erty by weighting the paths leading through it
by the number of its property neighbors:
WeiPropM(vi, vj) =
( n
?
k=1
1
(e(vi, pk) + e(pk, vj)) ? |prop(pk)|
)?1
where pk ? prop(vi) ? prop(vj).
WeiPropM measures the correlation be-
tween two terms based on the path lengths.
Frequently occurring words tend to be ranked
higher because the property edge lengths indi-
rectly depend on the absolute word frequency.
Because of high absolute frequency of words
the frequency of their co-occurrence with dif-
ferent properties is generally also higher and
the property edges are shorter. Therefore to
compensate this deficiency (i.e. to eliminate
the bias discussed in (Weeds et al, 2004))
an edge length from a property to a ranked
term e(pk, vj) is weighted by the square root
of its absolute frequency
?
freq(vj). Using
the weighted edge length between the property
and the ranked term we cannot any longer cal-
culate the path length between vi and vj as the
sum length(vi, pk, vj) = e(vi, pk) + e(pk, vj) ?
?
freq(vj) because the multiplied second com-
ponent significantly outweighs the first sum-
mand. Relative path length can be used in-
stead where both components are adequately
taken into account and added relatively
to the minimum of the respective compo-
nent: let min1 be min(e(vi, pa), . . . , e(vi, pn))
where pk ? prop(vi) and min2 =
min(. . . , e(pk, vj) ?
?
freq(vj), . . .) where
pk ? prop(vi)? prop(vj). Relative path length
would be e(vi,pk)min1 +
e(pk,vj)?
?
freq(vj)
min2 . Further
experimental observation suggests that when
searching for synonyms of vi the connection
between vi and the property is more signifi-
cant than the second component of the path ?
the connection between the property and the
ranked term vj . Therefore when calculating
the relative path length the first component
has to be weighted stronger (the examined ra-
tio was 2:1). The corresponding metric can be
defined as follows:
FirstCompM(vi, vj) =
(
?n
k=1
1
RelPathLength(k)?
?
|prop(pk)|
)?1
where RelPathLength(x) =
2
3 ?
e(vi, px)
min1 +
1
3 ?
e(px, vj) ?
?
freq(vj)
min2
As opposed to NaivePropM and WeiPropM
FirstCompM is not symmetric because of the
emphasis on the first component.
5 Experiments
For evaluation purposes a test corpus of
200 synonym sets was prepared consulting
(OpenThesaurus, 2005). The corpus con-
sists of 75 everyday words (e.g. ?Pra?sident?
(president), ?Eingang? (entrance) ?Gruppe?
(group)), 60 abstract terms (e.g. ?Ursache?
(reason), ?Element?, ?Merkmal? (feature))
and 65 domain-specific words (e.g. ?Software?,
?Prozessor? (CPU)). The evaluation strat-
egy is similar to that pursued in(Curran and
Moens, 2002). The similarity metrics do not
distinguish between different word senses re-
turning synonyms of all senses of the polyse-
mous words in a single ranked list. Therefore
the synonym set of a word in the test cor-
pus is the union of synonym sets of its senses.
To provide a measure for overall performance
and to compare the different metrics a func-
tion measuring the similarity score (SimS) was
defined that assigns a score to a metric for
correctly found synonyms among the 25 top-
ranked. The function assigns 25 points to
the correctly found top-ranked synonym of vi
(SimS(0, vi) = 25) and 1 point to the syn-
onym with the 25th rank (SimS(25, vi) = 1).
The rank of a synonym is decreased only by
false positives that are ranked higher (i.e. each
of correctly identified top n synonyms has rank
0). In order to reward the top-ranked syn-
onyms stronger the scoring function features a
hyperbolic descent. For a synonym of vi with
the rank x:
SimS(x, vi) =
?
?
?
0, if x /? synset(vi)
24?
?
26
(
?
26?1)?
?
x+1 + 1?
24?
26?1
?
?
?
36
To compare performance of different
metrics the SimS values of the top 25
words in the ranked list were summed
for each word of a test corpus. The to-
tal score of a similarity metric Sim is
?200
i=1
?25
j=1 SimS(rank(RankedList(vi, j)), vi)
where RankedList(vi, j) returns the word at
the position j from the ranked list produced
by Sim for vi and v1, . . . , v200 are the words
of the test corpus.
Besides, a combined precision and recall
measure ? was used to evaluate the ranked
lists. Given the word vi, we examined the first
n words (n = 1, 5, 25, 100) of the ranked list
returned by a similarity metric for vi whether
they belong to the synset(vi) of the test cor-
pus. ?(n) will measure precision if n is less
than the size of the synset(vi) because the
maximum recall can not be reached for such
n and recall otherwise because maximum pre-
cision cannot be reached for n > |synset(vi)|.
The ? values were averaged over 200 words.
Table 1 presents the result of evaluating the
similarity metrics introduced in sec. 4. The
results of DistanceM confirm that regarding
distance between two vertices alone is not
sufficient to conclude their synonymy. Dis-
tanceM finds many related terms ranking gen-
eral words with many outgoing and incoming
edges higher, but it lacks the features pro-
viding the particular evidence of synonymy.
NaivePropM is clearly outperformed by the
both weighted metrics. The improvement rel-
ative to the DistanceM and acceptable pre-
cision of the top-ranked synonyms ?(1) show
that considering shared properties is an ad-
equate approach to recognition of synonyms.
Ignoring the strength of semantic relation in-
dicated by the graph and the quality of prop-
erties is the reason for the big gap in the
total score and recall value (?(100)). Both
weighted metrics achieved results comparable
with those reported by Curran and Moens
in (Curran and Moens, 2002) and Turney in
(Turney, 2001). Best results of FirstCompM
confirm that the criteria identified in sec. 4
such as generality of a property, abstraction
from the absolute word frequency etc. are rel-
evant for identification of synonyms. First-
CompM performed particularly better in find-
ing synonyms with the low frequency of occur-
rence.
In another set of experiments we investi-
gated the influence of the size of the text cor-
pus (cf. fig. 3). The plausible assumption
is the more texts are processed, the better
the semantic connections between terms are
reflected by the graph, the more promising re-
sults are expected. The fact that the num-
ber of vertices does not grow proportionally
to the size of text corpus can be explained by
word recurrence and growing filtering thresh-
old ?. However, the number of edges increases
linearly and reflects the improving semantic
coverage. As expected, every metric performs
considerably better on bigger graphs. While
NaivePropM seems to converge after three
volumes, the both weighted metrics behave
strictly monotonically increasing. Hence an
improvement of results can be expected on big-
ger corpora. On the small text corpora the re-
sults of single metrics do not differ significantly
since there is not sufficient semantic informa-
tion captured by the graph, i.e. the edge and
path lengths do not fully reflect the seman-
tic relations between the words. The scores
of both weighted metrics grow, though, much
faster than that of NaivePropM. FirstCompM
achieves the highest gradient demonstrating
the biggest potential of leveraging the grow-
ing graph for finding synonymy.
Figure 3: Influence of the size of the text cor-
pus.
To examine the influence of the word cat-
egories results on the subsets of the text cor-
pus corresponding to a category are compared.
All metrics show similar behavior, therefore
we restrict the analysis to the ? values of
37
Metric Score ?(1) ?(5) ?(25) ?(100)
DistanceM 2990.7 0.20 0.208 0.199 0.38
NaivePropM 6546.3 0.415 0.252 0.271 0.440
WeiPropM 9411.7 0.54 0.351 0.398 0.607
FirstCompM 11848 0.575 0.412 0.472 0.637
Table 1: Results of different metrics on the test corpus
FirstCompM (fig. 4). Synonyms of domain-
specific words are recognized better than those
of abstract and everyday words. Their se-
mantics are better reflected by the technically
oriented texts. The ? values for abstract
and everyday words are pretty similar except
for the high precision of top-ranked abstract
synonyms. Everyday words suffer from the
fact that their properties are often too gen-
eral to uniquely characterize them, which in-
volves loss of precision. Abstract words can
be extremely polysemous and have many sub-
tle aspects that are not sufficiently covered by
the texts of computer journals.
Figure 4: Dependency of ?(n) on word cate-
gory (results of FirstCompM metric)
To test whether the metrics perform bet-
ter for the more frequent words the test set
was divided in 9 disjunctive frequency clus-
ters (table 2). FirstCompM achieved consid-
erably better results for very frequently occur-
ring words (? 4000 occurrences). This con-
firms indirectly the better results on the big-
ger text corpora: while low frequency does not
exclude random influence, frequent occurrence
involves adequate capturing of the word se-
mantics in the graph by inserting and adjust-
ing all relevant property edges. These results
do not contradict the conclusion that First-
CompM is not biased towards words with a
certain frequency because the mentioned bias
pertains to retrieval of synonyms with a cer-
tain frequency, whereas in this experiment the
performance for different word frequencies of
queried words is compared.
6 Conclusion
We have introduced the lexical graph as an
instrument for finding semantic relations be-
tween lexical items in natural language cor-
pora. The big advantage of the graph in com-
parison to other context models is that it cap-
tures not only the immediate context but es-
tablishes many transitive connections between
related terms. We have verified its effective-
ness searching for synonymy. Different met-
rics have been defined based on shortest path
lengths and shared properties. Similarity met-
ric FirstCompM that best leverages the graph
structure achieved the best results confirming
the significant role of number of shared proper-
ties, frequency of their co-occurrence and the
degree of their generality for detecting of syn-
onymy. Significantly improving results for big-
ger text corpora and more frequently occurring
words are encouraging and promising for de-
tection of other semantic relations. New meth-
ods that increasingly employ the graph struc-
ture e.g. regarding the lengths and number
of short paths between two terms or extend-
ing the witness concept to other morphological
types are the subject of further research.
Acknowledgements
I would like to thank Heiko Kahmann for
the valuable assistance in implementation and
evaluation of the approach. This research is
supported by NaFo?G scholarship of the fed-
eral state Berlin.
References
Vincent D. Blondel, Anah Gajardo, Maureen Hey-
mans, Pierre Senellart, and Paul Van Dooren.
38
Frequency 9-249 250-499 500-999 1000-1499 1500-2499 2500-3999 4000-5499 5500-7499 >7500
Words/cluster 27 25 44 30 27 15 11 8 13
Aver. score 53.23 51.52 45.80 60.75 56.51 58.75 97.21 106.11 73.85
?(1) 0.556 0.52 0.432 0.567 0.667 0.667 0.818 0.75 0.615
?(5) 0.381 0.392 0.342 0.395 0.393 0.413 0.600 0.675 0.503
?(25) 0.447 0.432 0.446 0.494 0.474 0.419 0.531 0.550 0.600
?(100) 0.561 0.645 0.618 0.610 0.690 0.623 0.705 0.642 0.748
Table 2: Influence of word frequency on the results of FirstCompM metric
2004. A measure of similarity between graph
vertices. With applications to synonym extrac-
tion and web searching. In SIAM Review, pages
647?666.
Hsinchun Chen and Kevin J. Lynch. 1992. Auto-
matic construction of networks of concepts char-
acterizing document databases. In IEEE Trans-
actions on Systems, Man and Cybernetics, vol-
ume 22(5), pages 885?902.
James R. Curran and Marc Moens. 2002. Improve-
ments in automatic thesaurus extraction. In
Proceedings of the Workshop of the ACL Special
Interest Group on the Lexicon (SIGLEX), pages
59?66. Association for Computational Linguis-
tics.
M. A. Hearst. 1998. Automated discovery of
Wordnet relations. In C. Fellbaum, editor,
Wordnet An Electronic Lexical Database, pages
131?151. MIT Press, Cambridge, MA.
Mathieu Lafourcade and Violaine Prince. 2001.
Relative synonymy and conceptual vectors. In
Proceedings of the NLPRS, Tokyo, Japan.
Mathieu Lafourcade. 2001. Lexical sorting and
lexical transfer by conceptual vectors. In Pro-
ceedings of the First International Workshop on
MultiMedia Annotation, Tokyo, Japan.
Dekang Lin. 1998. An information-theoretic
definition of similarity. In Proceedings of the
Fifteenth International Conference on Machine
Learning, pages 296?304, Madison, WI.
Christopher D. Manning and Hinrich Schu?tze.
1999. Foundations of Statistical Natural Lan-
guage Processing. MIT Press, Cambridge, MA
2000.
OpenThesaurus. 2005. OpenThesaurus
- Deutscher Thesaurus. http://www.
openthesaurus.de.
William Phillips and Ellen Riloff. 2002. Exploit-
ing strong syntactic heuristics and co-training
to learn semantic lexicons. In Proceedings of the
2002 Conference on Empirical Methods in NLP.
Gerda Ruge. 1997. Automatic detection of the-
saurus relations for information retrieval appli-
cations. Foundations of Computer Science: Po-
tential - Theory - Cognition, LNCS 1337:499?
506.
Pierre P. Senellart and Vincent D. Blondel. 2003.
Automatic discovery of similar words. In
Michael Berry, editor, Survey of Text Mining.
Clustering, classification, and retrieval, pages
25?44. Springer Verlag, Berlin.
TreeTagger. 2004. http://www.ims.
uni-stuttgart.de/projekte/corplex/
TreeTagger/.
Peter D. Turney. 2001. Mining the Web for syn-
onyms: PMI?IR versus LSA on TOEFL. Lec-
ture Notes in Computer Science, 2167:491?502.
Julie Weeds, David Weir, and Diana McCarthy.
2004. Characterising measures of lexical distri-
butional similarity.
WordNet. 2005. http://wordnet.princeton.
edu/w3wn.html.
39
Querying XML documents with multi-dimensional markup
Peter Siniakov
siniakov@inf.fu-berlin.de
Database and Information Systems Group, Freie Universita?t Berlin
Takustr. 9, 14195 Berlin, Germany
Abstract
XML documents annotated by differ-
ent NLP tools accommodate multi-
dimensional markup in a single hier-
archy. To query such documents one
has to account for different possible
nesting structures of the annotations
and the original markup of a docu-
ment. We propose an expressive pat-
tern language with extended seman-
tics of the sequence pattern, support-
ing negation, permutation and regu-
lar patterns that is especially appropri-
ate for querying XML annotated docu-
ments with multi-dimensional markup.
The concept of fuzzy matching allows
matching of sequences that contain tex-
tual fragments and known XML ele-
ments independently of how concurrent
annotations and original markup are
merged. We extend the usual notion of
sequence as a sequence of siblings al-
lowing matching of sequence elements
on the different levels of nesting and
abstract so from the hierarchy of the
XML document. Extended sequence
semantics in combination with other
language patterns allows more power-
ful and expressive queries than queries
based on regular patterns.
1 Introduction
XML is widely used by NLP tools for anno-
tating texts. Different NLP tools can produce
overlapping annotations of text fragments.
While a common way to cope with concur-
rent markup is using stand-off markup (Witt,
2004) with XPointer references to the anno-
tated regions in the source document, another
solution is to consolidate the annotations in a
single document for easier processing. In that
case concurrent markup has to be merged and
accommodated in a single hierarchy. There are
many ways to merge the overlapping markup
so that different nesting structures are pos-
sible. Besides, the annotations have to be
merged with the original markup of the doc-
ument (e.g. in case of a HTML document).
The problem of merging overlapping markup
has been treated in (Siefkes, 2004) and we do
not consider it here. Instead we focus on the
problem of finding a universal querying mech-
anism for documents with multi-dimensional
markup. The query language should abstract
from the concrete merging algorithm for con-
current markup, that is to identify desired
elements and sequences of elements indepen-
dently from the concrete nesting structure.
The development of the query language was
motivated by an application in text mining.
In some text mining systems the linguistic
patterns that comprise text and XML anno-
tations (such as syntactic annotations, POS
tags) made by linguistic tools are matched
with semistructured texts to find desired infor-
mation. These texts can be HTML documents
that are enriched with linguistic information
by NLP tools and therefore contain multi-
dimensional markup. The linguistic annota-
tions are specified by XML elements that con-
tain the annotated text fragment as CDATA.
Due to the deliberate structure of the HTML
document the annotations can be nested in ar-
bitrary depth and vice versa ? the linguistic
XML element can contain some HTML ele-
ments with nested text it refers to. To find
a linguistic pattern we have to abstract from
the concrete DTD and actual structure of the
XML document ignoring irrelevant markup,
which leads to some kind of ?fuzzy? match-
ing. Hence it is sufficient to specify a sequence
43
of text fragments and known XML elements
(e.g. linguistic tags) without knowing by what
elements they are nested. During the match-
ing process the nesting markup will be omitted
even if the sequence elements are on different
nesting levels.
We propose an expressive pattern language
with the extended semantics of the sequence
pattern, permutation, negation and regular
patterns that is especially appropriate for
querying XML annotated documents. The
language provides a rich tool set for specify-
ing complex sequences of XML elements and
textual fragments. We ignore some important
aspects of a fully-fledged XML query language
such as construction of result sets, aggregate
functions or support of all XML Schema struc-
tures focusing instead on the semantics of the
language.
Some modern XML query languages impose
a relational view of data contained in the XML
document aiming at retrieval of sets of ele-
ments with certain properties. While these ap-
proaches are adequate for database-like XML
documents, they are less appropriate for doc-
uments in that XML is used rather for anno-
tation than for representation of data. Tak-
ing the rather textual view of a XML doc-
ument its querying can be regarded as find-
ing patterns that comprise XML elements and
textual content. One of the main differences
when querying annotated texts is that the
query typically captures parts of the docu-
ment that go beyond the boundaries of a sin-
gle element disrupting the XML tree structure
while querying a database-like document re-
turns its subtrees remaining within a scope of
an element. Castagna (Castagna, 2005) dis-
tinguishes path expressions that rather corre-
spond to the database view and regular ex-
pression patterns as complementary ?extrac-
tion primitives? for XML data. Our approach
enhances the concept of regular expression
patterns making them mutually recursive and
matching across the element boundaries.
2 Related Work
After publishing the XML 1.0 recommenda-
tion the early proposals for XML query lan-
guages focused primarily on the representa-
tion of hierarchical dependencies between el-
ements and the expression of properties of a
single element. Typically, hierarchical rela-
tions are defined along parent/child and an-
cestor/descendant axis as done in XQL and
XPath. XQL (Robie, 1998) supports posi-
tional relations between the elements in a sib-
ling list. Sequences of elements can be queried
by ?immediately precedes? and ?precedes? op-
erators restricted on the siblings. Negation,
conjunction and disjunction are defined as fil-
tering functions specifying an element. XPath
1.0 (Clark and DeRose, 1999) is closely re-
lated addressing primarily the structural prop-
erties of an XML document by path expres-
sions. Similarly to XQL sequences are de-
fined on sibling lists. Working Draft for Xpath
2.0 (Berglund et al, September 2005) provides
support for more data types than its precur-
sor, especially for sequence types defining set
operations on them.
XML QL (Deutsch et al, 1999) follows the
relational paradigm for XML queries, intro-
duces variable binding to multiple nodes and
regular expressions describing element paths.
The queries are resolved using an XML graph
as the data model, which allows both ordered
and unordered node representation. XQuery
(Boag et al, 2003) shares with XML QL the
concept of variable bindings and the ability
to define recursive functions. XQuery fea-
tures more powerful iteration over elements
by FLWR expression borrowed from Quilt
(Chamberlin et al, 2001), string operations,
?if else? case differentiation and aggregate
functions. The demand for stronger support
of querying annotated texts led to the integra-
tion of the full-text search in the language (Re-
quirements, 2003) enabling full-text queries
across the element boundaries.
Hosoya and Pierce propose integration of
XML queries in a programming language
(Hosoya and Pierce, 2001) based on regular
patterns Kleene?s closure and union with the
?first-match? semantics. Pattern variables can
be declared and bound to the correspond-
ing XML nodes during the matching process.
A static type inference system for pattern vari-
ables is incorporated in XDuce (Hosoya and
Pierce, 2003) ? a functional language for XML
processing. CDuce (Benzaken et al, 2003)
extends XDuce by an efficient matching al-
44
gorithm for regular patterns and first class
functions. A query language CQL based on
regular patterns of CDuce uses CDuce as a
query processor and allows efficient processing
of XQuery expressions (Benzaken et al, 2005).
The concept of fuzzy matching has been inro-
duced in query languages for IR (Carmel et
al., 2003) relaxing the notion of context of an
XML fragment.
3 Querying by pattern matching
The general purpose of querying XML doc-
uments is to identify and process their frag-
ments that satisfy certain criteria. We re-
duce the problem of querying XML to pat-
tern matching. The patterns specify the query
statement describing the desired properties of
XML fragments while the matching fragments
constitute the result of the query. Therefore
the pattern language serves as the query lan-
guage and its expressiveness is crucial for the
capabilities of the queries. The scope for the
query execution can be a collection of XML
documents, a single document or analogously
to XPath a subtree within a document with
the current context node as its root. Since in
the scope of the query there may be several
XML fragments matching the pattern, multi-
ple matches are treated according to the ?all-
match? policy, i.e. all matching fragments are
included in the result set. The pattern lan-
guage does not currently support construc-
tion of new XML elements (however, it can be
extended adding corresponding syntactic con-
structs). The result of the query is therefore a
set of sequences of XML nodes from the doc-
ument. Single sequences represent the XML
fragments that match the query pattern. If no
XML fragments in the query scope match the
pattern, an empty result set is returned.
In the following sections the semantics, main
components and features of the pattern lan-
guage are introduced and illustrated by exam-
ples. The complete EBNF specification of the
language can be found on
http://page.mi.fu-berlin.de/~siniakov/patlan.
3.1 Extended sequence semantics
Query languages based on path expressions
usually return sets (or sequences) of elements
that are conform with the original hierarchical
structure of the document. In not uniformly
structured XML documents, though, the hi-
erarchical structure of the queried documents
is unknown. The elements we may want to
retrieve or their sequences can be arbitrarily
nested. When retrieving the specified elements
the nesting elements can be omitted disrupt-
ing the original hierarchical structure. Thus
a sequence of elements does no longer have to
be restricted to the sibling level and may be
extended to a sequence of elements following
each other on different levels of XML tree.
Figure 1: Selecting the sequence (NE ADV
V) from a chunk-parsed POS-tagged sentence.
XML nodes are labeled with preorder num-
bered OID|right bound (maximum descen-
dant OID)
To illustrate the semantics and features of
the language we will use the mentioned text
mining scenario. In this particular text mining
task some information in HTML documents
with textual data should be found. The doc-
uments contain linguistic annotations inserted
by POS tagger and syntactic chunk parser as
XML elements that include the annotated text
fragment as a text node. The XML output
of the NLP tools is merged with the HTML
markup so that various nestings are possible.
A common technique to identify the relevant
information is to match linguistic patterns de-
scribing it with the documents. The fragments
of the documents that match are likely to con-
tain relevant information. Hence the problem
is to identify the fragments that match our lin-
guistic patterns, that is, to answer the query
where the queried fragments are described by
linguistic patterns. Linguistic patterns com-
prise sequences of text fragments and XML el-
ements added by NLP tools and are specified
in our pattern language. When looking for lin-
guistic patterns in an annotated HTML docu-
45
ment, it cannot be predicted how the linguistic
elements are nested because nesting depends
on syntactic structure of a sentence, HTML
layout and the way both markups are merged.
Basically, the problem of unpredictable nest-
ing occurs in any document with a hetero-
geneous structure. Let us assume we would
search for a sequence of POS tags: NE ADV V
in a subtree of a HTML document depicted
in fig. 1. Some POS tags are chunked in
noun (NP), verb (VP) or prepositional phrases
(PP). Named entity ?Nanosoft? is emphasized
in boldface and therefore nested by the HTML
element <b>. Due to the syntactic structure
and the HTML markup the elements NE, ADV
and V are on different nesting levels and not
children of the same element. According to
the extended sequence semantics we can ig-
nore the nesting elements we are not inter-
ested in (NPOID2 and bOID3 when matching
NE, VPOID8 when matching V) so that the se-
quence (NEOID4, ADVOID6, VOID9) matches
the sequence pattern NE ADV V, in short form
NE ADV V ?= (NE4, ADV6, V9).
By the previous example we introduced
the matching relation ?= as a binary relation
?= ? P ? F where P is the set of patterns
and F a set of XML fragments. An XML frag-
ment f is a sequence of XML nodes n1 . . . nn
that belong to the subtree of the context node
(i.e. the node whose subtree is queried, e.g.
document root). Each XML node in the sub-
tree is labeled by the pair OID|right bound.
OID is obtained assigning natural numbers
to the nodes during the preorder traversal.
Right bound is the maximum OID of a de-
scendant of the node ? the OID of the right-
most leaf in the rightmost subtree. To match
a sequence pattern an XML fragment has to
fulfil four important requirements.
1. Consecutiveness: All elements of the se-
quence pattern have to match the consec-
utive parts of the XML fragment
2. Order maintenance: Its elements must be
in the ?tree order?, i.e., the OIDs of the
nodes according to the preorder number-
ing schema must be in ascending order.
3. Absence of overlaps: No node in the se-
quence can be the predecessor of any
other node in the sequence on the way to
the root. E.g. NP PP NP 6?= (NP11, PP18,
NP21) because PP18 is a predecessor of
NP21 and therefore subsumes it in its sub-
tree. The semantics of the sequence im-
plies that a sequence element cannot be
subsumed by the previous one but has
to follow it in another subtree. To de-
termine whether a node m is a predeces-
sor of the node n the OIDs of the nodes
are compared. The predecessor must have
a smaller OID according to the preorder
numbering scheme, however any node in
left subtrees of n has a smaller OID too.
Therefore the right bounds of the nodes
can be compared since the right bound of
a predecessor will be greater or equal to
the right bound of n while the right bound
of any element in the left subtree will be
smaller:
pred(m,n) =
OID(m)<OID(n) ? rightBound(m)?rightBound(n)
4. Completeness: XML fragment must not
contain any gaps, i.e. there should not be
a node that is not in the XML fragment,
not predecessor of one of the nodes, whose
OID however lies between the OIDs of
the fragment nodes. Since such a node
is not a predecessor, it must be an el-
ement of the sequence; otherwise it is
omitted and the sequence is not complete.
Hence, the pattern V NP NP 6?= (V9, NP11,
NP21) because the node PR19 lying be-
tween NP11 and NP21 is not a predeces-
sor of any of the fragment nodes and not
an element of the fragment. If the nodes
lying between NP11 and NP21 cannot be
exactly specified, we can use wildcard pat-
tern (see sec. 3.3) to enable matching:
V NP * NP ?= (V9, NP11, PR19, NP21):
Using these requirements we can formally
specify the semantics of the sequence:
Let s = s1 . . . sk be a sequence pattern and
f = n1 . . . nn the matching XML fragment.
s ?= f ?
(I) s1?=(n1...ni), s2?=(ni+1...nj),...,sk?=(nl...nn)
(II) ? 1?i<n OID(ni)<OID(ni+1)
(III) 6? 1?i<n pred(ni,ni+1)
(IV ) ? 1?i<n 6? m OID(ni)<OID(m)<OID(ni+1)?
??pred(m,ni+1)
46
The fourth requirement stresses the impor-
tant aspect of ?exhaustive? sequence: we are
interested in a certain sequence of known ele-
ments that can be arbitrarily nested and cap-
tured by some elements that are irrelevant
for our sequence (e.g. html layout elements
when searching for a sequence of linguistic el-
ements). We call such a sequence an exhaus-
tive non-sibling sequence (ENSS ). It is exhaus-
tive because all predecessors omitted during
the matching are covered at some level by the
matching descendants so that there is no path
to a leaf of the predecessor subtree that leads
through an unmatched node. If such a path
existed, the fourth requirement would not be
met. If the sequence does not begin at the left-
most branch or does not end at the rightmost
branch of an omitted predecessor, the subtree
of the respective predecessor is not fully cov-
ered. In ADJ NN PR ?= (ADJ14, NN16, PR19)
the omitted predecessors NP11 and PP18 are
not completely a part of the sequence because
they have descendants outside the sequence
borders. Nevertheless the sequence is exhaus-
tive since there is no path to a leaf through an
unmatched node within its borders.
Another important aspect of ENSS is that it
can match XML fragments across the element
borders. XPath imposes a query context by
specifying the path expression that usually ad-
dresses a certain element, XQuery restricts it
indirect by iterating over and binding variables
to certain nodes. Matching ENSS there is no
additional restriction of the query scope, that
is, the sequence can begin and end at any node
provided that the ENSS requirements are met.
The dashed line in the fig. 1 points up the re-
gion covered by the sample sequence.
According to the specification of the se-
quence pattern in the pattern language (cf.
appendix ??):
Pattern ::= Pattern? ?? Pattern
any pattern can be the element of the se-
quence. Therefore the sequence can also
contain textual elements, which is especially
important when processing annotated texts.
Textual nodes represent leaves in an XML tree
and are treated as other XML nodes so that
arbitrary combinations of XML elements and
text are possible: "released" NP "of" NE ?=
(?released?10, NP11, ?of?20, NE22)
Exhaustive sequence allows a much greater
abstraction from the DTD of a document than
the usually used sequence of siblings. The ex-
pressiveness of the language significantly bene-
fits from the combination of backtracking pat-
terns (cf. sec. 3.3) with exhaustive sequence.
3.2 Specification of XML nodes
Patterns matching single XML nodes are the
primitives that the more complex patterns are
composed from. The pattern language sup-
ports matching for document, element, at-
tribute, text and CDATA nodes while some
DOM node types such as entities and process-
ing instructions are not supported. Some ba-
sic patterns matching element and text nodes
have been already used as sequence elements
in the previous section. Besides the simple ad-
dressing of an element by its name it is pos-
sible to specify the structure of its subtree:
Pattern ::=? \?XML-Tag(?[?Pattern?]?)?
A pattern specifying an element node will
match if the element has the name correspond-
ing to the XML-Tag and the pattern in the
square brackets matches the XML fragment
containing the sequence of its children. E.g.
\PP[ PR NE] ?= (PP18) because the name of
the element is identical and PR NE ?= (PR19,
NE22). As this example shows, the extended
sequence semantics applies also when the se-
quence is used as the inner pattern of another
pattern. Therefore the specification of ele-
ments can benefit from the ENSS because we
again do not have to know the exact structure
of their subtrees, e.g. their children, but can
specify the nodes we expect to occur in a cer-
tain order.
Attribute nodes can be accessed by ele-
ment pattern specifying the attribute values
as a constraint: \V {@normal="release"} ?=
(V9), assumed that the element V9 has the
attribute ?normal? that stores the principal
form of its textual content. Besides equality
tests, numeric comparisons and boolean func-
tions on string attribute values can be used as
constraints.
Patterns specifying textual nodes comprise
quoted strings:
Pattern ::= QuotedString
and match a textual node of an XML element
if it has the same textual content as the quoted
string. Textual patterns can be used as ele-
47
ments of any other patterns as already demon-
strated in the previous section. An element
may be, for instance, described by a complex
sequence of text nodes combined with other
patterns: \sentence[NE * \V{@normal=release}
\NP[* "new" "version"] "of" NE *] ?= (sentence1)
The pattern above can already be used as a
linguistic pattern identifying the release of a
new product version.
3.3 Backtracking patterns and
variables
In contrast to the database-like XML docu-
ments featuring very rigid and repetitive struc-
tures annotated texts are distinguished by a
very big structural variety. To handle this va-
riety one needs patterns that can cover several
different cases ?at once?. So called backtrack-
ing patterns have this property and constitute
therefore a substantial part of the pattern lan-
guage. Their name comes from the fact that
during the matching process backtracking is
necessary to find a match.
The pattern language features complex and
primitive patterns. Complex patterns consist
of at least one inner element that is a pattern
itself. Primitive patterns are textual patterns
or XML attribute and element specifications
if the specification of the inner structure of
the element is omitted, e.g. "released", NP.
If at least one of the inner patterns does not
match, the matching of the complex pattern
fails. Backtracking patterns except for wild-
card pattern are complex patterns.
Let us assume, we look for a sequence
"released" NE and do not care what is be-
tween the two sequence elements. In the sub-
tree depicted in fig. 1 no XML fragment
will match because there are several nodes be-
tween ?released?10 and NE22 and the com-
pleteness requirement is not met. If we in-
clude the wildcard pattern in the sequence,
"released" * NE ?= (?released?10 NP11 PR19
NE22), the wildcard pattern matches the
nodes lying between V9 and NE22. Thus, ev-
ery time we do not know what nodes can oc-
cur in a sequence or we are not interested in
the nodes in some parts of the sequence, we
can use wildcard pattern to specify the se-
quence without losing its completeness. Wild-
card pattern matches parts of the sequence
that are in turn sequences themselves. There-
fore it matches only those XML fragments that
fulfil the ENSS requirements II-IV. Since there
are often multiple possibilities to match a se-
quence on different levels, wildcard matches
nodes that are at the highest possible level
such as NP11 in the previous example.
If one does not know whether an XML frag-
ment occurs, but wants to account for both
cases the option pattern should be used:
Pattern ::=? (?Pattern?)??
Pattern ::=? (?Pattern?)??
Kleene closure differs from the option by the
infinite number of repetitions. It matches a se-
quence of any number of times repeated XML
fragments that match the inner pattern of the
Kleene closure pattern. Since Kleene closure
matches sequences, the ENSS requirements
have to be met by matching XML fragments.
Let O = (p)? be an option, K = (p)? a Kleene
closure pattern, f ? F an XML fragment:
O ?= f ? p ?= f ? {} ?= f
K ?= f ? {} ?= f ? p ?= f ? p p ?= f ? . . .
where f fulfils ENSS requirements I-IV.
The option pattern matches either an empty
XML fragment or its inner pattern.
An alternative occurrence of two XML
fragments is covered by the union pattern:
Pattern ::=? (?Pattern(?|?Pattern)+?)?
Different order of nodes in the sequence can
be captured in the permutation pattern:
Pattern ::=? (?Pattern Pattern+?)%?
Let U = (p1|p2) be a union pattern,
P = (p1, . . . , pn)% a permutation pattern
U ?= f ? p1 ?= f ? p2 ?= f
P ?= f ? p1 p2...pn ?= f ? p1 p2...pn pn?1 ?= f ????
???? p1 pn...p2?=f ? ???? pn pn?1...p2 p1?=f
Permutation can not be expressed by regular
constructs and is therefore not a regular ex-
pression itself.
The backtracking patterns can be arbitrar-
ily combined to match complex XML frag-
ments. E.g. the pattern ((PP | PR)? NP)%
matches three XML fragments: (NP2), (NP11,
PP18) and (PR19, NP21). Using the backtrack-
ing patterns recursively enlarges the expres-
sivity of the patterns a lot allowing to specify
very complex and variable structures without
significant syntactic effort.
48
Variables can be assigned to any pattern
Pattern ::= Pattern? =:? String
accomplishing two functions. Whenever a
variable is referenced within a pattern by the
reference pattern Pattern ::=? $?String?$?
it evaluates to the pattern it
was assigned to. The pattern
(NP)?=:noun_phrase * $noun_phrase$
?= (NP2, ADV6, VP8, NP11) so that the
referenced pattern matches NP11. A pattern
referencing the variable v matches XML
fragments that match the pattern that has
been assigned to v. To make the matching
results more persistent and enable further
processing variables can be bound to the
XML fragment that matched the pattern the
variable is assigned to. After matching the
pattern \sentence[NE=:company *
\V{@normal=release} \NP[* "new" "version"]
"of" NE=:product *] ?= (sentence1)
the variable company refers to NE4(Nanosoft)
and product is bound to NE22(NanoOS).
The relevant parts of XML fragment can
be accessed by variables after a match
has been found. Assigning variable to the
wildcard pattern can be used to extract
a subsequence between two known nodes:
"released" * =:direct_object "of" ?=
(?released?10 NP11 ?of?20) with the variable
direct_object bound to NP11.
Let A = p =: v be an assignment pattern:
A ?= f ? p ?= f
Matching backtracking patterns can involve
multiple matching variants of the same XML
fragment, which usually leads to different
variable bindings for each matching variant.
As opposed to multiple matchings when
different fragments match the same pattern
discussed above, the first-match policy is ap-
plied when the pattern ambiguously matches
a XML fragment. For instance,two different
matching variants are possible for the pattern
(NP)?:=noun_phrase (NP |PR)?:=noun_prep
?= (NP11, PR19). In the first case
(NP)?:=noun_phrase ?= (NP11) so that
noun_phrase is bound to NP11 and
noun_prep to PR19. In the second
case (NP)?:=noun_phrase ?= {} and
(NP | PR)?:=noun_prep ?= (NP11, PR19)
so that noun_phrase is bound to {} and
noun_prep to (NP11, PR19). In such cases
the first found match is returned as the final
result. The order of processing of single
patterns is determined by a convention.
3.4 Negation
When querying an XML document it is often
useful not only to specify what is expected but
also to specify what should not occur. This
is an efficient way to exclude some unwanted
XML fragments from the query result because
sometimes it is easier to characterize an XML
fragment by not wanted rather than desirable
properties. Regular languages (according to
Chomsky?s classification) are not capable of
representing that something should not appear
stating only what may or has to appear. In the
pattern language the absence of some XML
fragment can be specified by negation .
As opposed to most XML query languages
negation is a pattern and not a unary boolean
operator. Therefore it has no boolean value,
but matches the empty XML fragment.
Since the negation pattern specifies what
should not occur, it does not ?consume? any
XML nodes during the matching process so
that we call it ?non-substantial? negation.
The negation pattern !(p) matches the
empty XML fragment if its inner pattern
p does not occur in the current context
node. To underline the difference to logical
negation, consider the double negation. The
double negation !(!(p)) is not equivalent
to p, but matches an empty XML element
if !(p) matches the current context node,
which is only true if the current context
node is empty. Since the negation pattern
only specifies what should not occur, the
standalone usage of negation is not reason-
able. It should be used as an inner pattern of
other complex patterns. Specifying a sequence
VP *=:wildcard_1 !(PR) *=:wildcard_2 NP
we want to identify sequences starting with
VP and ending with NP where PR is not
within a sequence. Trying to find a match
for the sequence starting in VP8 and ending
in NP21 there are multiple matching variants
for wildcard patterns. Some of them enable
the matching of the negation pattern binding
PR to one of the wildcards, e.g. wildcard_1
is bound to (NP11, PR19), !(PR) ?= {},
wildcard_2 is bound to {}. However, there
49
is a matching variant when the negated
pattern is matched with PR19 (wildcard_1
is bound to NP11, wildcard_2 is bound
to {}). We would certainly not want the
sequence (VP8, NP11, PR19, NP21) to match
our pattern because the occurrence of PR in
the sequence should be avoided. Therefore we
define the semantics of the negation so that
there is no matching variant that enables the
occurrence of negated pattern:
Let P1 !(p) P2 be a complex pattern compris-
ing negation as inner pattern. P1 and P2 are
the left and right syntactic parts of the pat-
tern and may be not valid patterns themselves
(e.g. because of unmatched parentheses). The
pattern obtained from the concatenation of
both parts P1 P2 is a valid pattern because it
is equivalent to the replacing of the negation
by an empty pattern.
P1 !(p) P2 ?= f ?
P1 p P2 6?= f ? P1 P2 ?= f
Requiring P1 p P2 6?= f guarantees that no
matching variant exists in that the negated
pattern p occurs. Since !(p) matches an empty
fragment, the pattern P1P2 has to match com-
plete f . It is noteworthy that the negation is
the only pattern that influences the semantics
of a complex pattern as its inner pattern. In-
dependent of its complexity any pattern can
be negated allowing very fine-grained specifi-
cation of undesirable XML fragments.
4 Conclusion
XML documents with multi-dimensional
markup feature a heterogeneous structure
that depends on the algorithm for merging
of concurrent markup. We present a pattern
language that allows to abstract from the
concrete structure of a document and formu-
late powerful queries. The extended sequence
semantics allows matching of sequences across
element borders and on different levels of the
XML tree ignoring nesting levels irrelevant
for the query. The formal specification of
the sequence semantics guarantees that the
properties of ?classic? sibling sequence such
as ordering, absence of gaps and overlaps
between the neighbors are maintained. The
combination of fully recursive backtracking
patterns with the ENSS semantics allows
complex queries reflecting the complicated
positional and hierarchical dependencies
of XML nodes within a multi-dimensional
markup. Negation enhances the expressivity
of the queries specifying an absence of a
pattern in a certain context.
References
V. Benzaken, G. Castagna, and A. Frisch. 2003.
CDuce: an XML-centric general-purpose language.
In In ICFP ?03, 8th ACM International Conference
on Functional Programming, pages 51?63.
V. Benzaken, G. Castagna, and C. Miachon. 2005.
A full pattern-based paradigm for XML query pro-
cessing. In Proceedings of the 7th Int. Symposium on
Practical Aspects of Decl. Languages, number 3350.
A. Berglund, S. Boag, D. Chamberlin, M. Fernndez,
M. Kay, J. Robie, and J. Simon. September 2005.
XML Path Language (XPath) 2.0. http://www.w3.
org/TR/2005/WD-xpath20-20050915/.
S. Boag, D. Chamberlin, M. Fernandez, D. Florescu,
J. Robie, J. Simon, and M. Stefanescu. 2003.
XQuery 1.0: An XML Query Language. http:
//www.w3c.org/TR/xquery.
David Carmel, Yoelle S. Maarek, Matan Mandelbrod,
Yosi Mass, and Aya Soffer. 2003. Searching XML
documents via XML fragments. In SIGIR ?03: Pro-
ceedings of the 26th annual int. ACM SIGIR confer-
ence, pages 151?158, New York,USA. ACM Press.
G. Castagna. 2005. Patterns and types for querying
XML. In DBPL - XSYM 2005 joint keynote talk.
Don Chamberlin, Jonathan Robie, and Daniela Flo-
rescu. 2001. Quilt: An XML query language for
heterogeneous data sources. LNCS, 1997:1?11.
J. Clark and S. DeRose. 1999. XML Path Language
(XPath). http://www.w3.org/TR/Xpath.
Alin Deutsch, Mary F. Fernandez, D. Florescu, A.Y.
Levy, and D. Suciu. 1999. A query language for
XML. Computer Networks, 31(11-16):1155?1169.
H. Hosoya and P.C. Pierce. 2001. Regular expression
patern matching for XML. In In POPL ?01, 25th
Symposium on Principles of Prog. Languages.
Haruo Hosoya and Benjamin C. Pierce. 2003. XDuce:
A statically typed XML processing language. ACM
Trans. Inter. Tech., 3(2):117?148.
XQuery and XPath Full-Text Require-
ments. 2003. http://www.w3.org/TR/2003/
WD-xquery-full-text-requirements-20030502/.
Jonathan Robie. 1998. The design of XQL. http:
//www.ibiblio.org/xql/xql-design.html.
C. Siefkes. 2004. A shallow algorithm for correcting
nesting errors and other well-formedness violations
in XML-like input. In Extreme Markup Languages.
A. Witt. 2004. Multiple hierarchies: new aspects of an
old solution. In Extreme Markup Languages 2004.
50
