Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 13?25,
Edinburgh, Scotland, UK, July 27?31, 2011. c?2011 Association for Computational Linguistics
Predicting Thread Discourse Structure over Technical Web Forums
Li Wang,?? Marco Lui,?? Su Nam Kim,?? Joakim Nivre? and Timothy Baldwin??
? Dept. of Computer Science and Software Engineering, University of Melbourne
? NICTA Victoria Research Laboratory
? Dept. of Linguistics and Philology, Uppsala University
li.wang.d@gmail.com, saffsd@gmail.com,
sunamkim@gmail.com, joakim.nivre@lingfil.uu.se, tb@ldwin.net
Abstract
Online discussion forums are a valuable
means for users to resolve specific information
needs, both interactively for the participants
and statically for users who search/browse
over historical thread data. However, the com-
plex structure of forum threads can make it
difficult for users to extract relevant informa-
tion. The discourse structure of web forum
threads, in the form of labelled dependency re-
lationships between posts, has the potential to
greatly improve information access over web
forum archives. In this paper, we present the
task of parsing user forum threads to deter-
mine the labelled dependencies between posts.
Three methods, including a dependency pars-
ing approach, are proposed to jointly clas-
sify the links (relationships) between posts
and the dialogue act (type) of each link. The
proposed methods significantly surpass an in-
formed baseline. We also experiment with ?in
situ? classification of evolving threads, and es-
tablish that our best methods are able to per-
form equivalently well over partial threads as
complete threads.
1 Introduction
Web user forums (or simply ?forums?) are online
platforms for people to discuss information and ob-
tain information via a text-based threaded discourse,
generally in a pre-determined domain (e.g. IT sup-
port or DSLR cameras). With the advent of Web
2.0, there has been an explosion of web authorship in
this area, and forums are now widely used in various
areas such as customer support, community devel-
opment, interactive reporting and online eduction.
In addition to providing the means to interactively
participate in discussions or obtain/provide answers
to questions, the vast volumes of data contained in
forums make them a valuable resource for ?support
sharing?, i.e. looking over records of past user inter-
actions to potentially find an immediately applica-
ble solution to a current problem. On the one hand,
more and more answers to questions over a wide
range of domains are becoming available on forums;
on the other hand, it is becoming harder and harder
to extract and access relevant information due to the
sheer scale and diversity of the data.
This research aims at enhancing information ac-
cess and support sharing, by mining the discourse
structure of troubleshooting-oriented web user fo-
rum threads. Previous research has shown that sim-
ple thread structure information (e.g. reply-to struc-
ture) can enhance tasks such as forum information
retrieval (Seo et al, 2009) and post quality assess-
ment (Lui and Baldwin, 2009). We aim to move be-
yond simple threading, to predict not only the links
between posts, but also show the manner of each
link, in the form of the discourse structure of the
thread. In doing so, we hope to be able to perform
richer visualisation of thread structure (e.g. high-
lighting the key posts which appear to have led to
a successful resolution to a problem), and more fine-
grained weighting of posts in threads for search pur-
poses.
To illustrate the task, we use an example thread,
made up of 5 posts from 4 distinct participants, from
the CNET forum dataset of Kim et al (2010b), as
shown in Figure 1. The discourse structure of the
thread is modelled as a rooted directed acyclic graph
13
HTML Input Code...Please can someone tell me how to create an input box that asks the user to enter their ID, and then allows them to press go. It will then redirect to the page ...
User APost 1
User BPost 2
User CPost 3
Re: html input codePart 1: create a form with a text field. See ... Part 2: give it a Javascript action
asp.net c\# videoI?ve prepared for you video.link click ...
Thank You!Thanks a lot for that ... I have Microsoft Visual Studio 6, what program should I do this in? Lastly, how do I actually include this in my site? ...
A little more help... You would simply do it this way: ... You could also just ... An example of this is ...
User APost 4
User DPost 5
0+Question-Question
2+Answer-Answer
4+Answer-Answer
1+Answer-Answer
1+Answer-Confirmation
3+Question-Add
?
Figure 1: A snippeted and annotated CNET thread
(DAG) with a dialogue act label associated with each
edge of the graph. In this example, UserA initiates
the thread with a question (dialogue act = Question-
Question) in the first post, by asking how to create
an interactive input box on a webpage. In response,
UserB and UserC provide independent answers (di-
alogue act = Answer-Answer). UserA responds to
UserC to confirm the details of the solution (dia-
logue act = Answer-Confirmation), and at the same
time, adds extra information to his/her original ques-
tion (dialogue act = Question-Add); i.e., this one
post has two distinct dependency links associated
with it. Finally, UserD proposes a different solution
again to the original question.
To predict thread discourse structure of this type,
we jointly classify the links and dialogue acts be-
tween posts, experimenting with a variety of su-
pervised classification methods, namely dependency
parsing and linear-chain conditional random fields.
In this, we build on the earlier work of Kim et al
(2010b) who first proposed the task of thread dis-
course analysis, but only carried out experiments on
post linking and post dialogue act classification as
separate tasks. In addition to achieving state-of-the-
art accuracy over the task, we carry out in-depth
analysis of classification effectiveness at different
thread depths, and establish that the accuracy of our
method over partial threads is equivalent to that over
full threads, indicating that the method is applica-
ble to in-situ thread classification. Finally, we in-
vestigate the role of user-level features in discourse
structure analysis.
2 Related Work
This work builds directly on earlier work of a subset
of the authors (Kim et al, 2010b), whereby a novel
post-level dialogue act set was proposed, and used
as the basis for annotation of a set of threads taken
from CNET. In the original work, we proposed a set
of novel features, which we applied to the separate
tasks of post link classification and dialogue act clas-
sification. We later applied the same basic method-
ology to dialogue act classification over one-on-one
live chat data with provided message dependencies
(Kim et al, 2010a), demonstrating the generalisabil-
ity of the original method. In both cases, however,
we tackled only a single task, either link classifica-
tion (optionally given dialogue act tags) or dialogue
act classification, but never the two together. In this
paper, we take the obvious step of exploring joint
classification of post link and dialogue act tags, to
generate full thread discourse structures.
Discourse disentanglement (i.e. link classifica-
tion) and dialogue act tagging have been studied
largely as independent tasks. Discourse disentangle-
ment is the task of dividing a conversation thread
(Elsner and Charniak, 2008; Lemon et al, 2002)
or document thread (Wolf and Gibson, 2005) into
a set of distinct sub-discourses. The disentangled
discourse is sometimes assumed to take the form of
a tree structure (Grosz and Sidner, 1986; Lemon et
al., 2002; Seo et al, 2009), an acyclic graph struc-
ture (Rose? et al, 1995; Schuth et al, 2007; Elsner
and Charniak, 2008; Wang et al, 2008; Lin et al,
2009), or a more general cyclic chain graph struc-
ture (Wolf and Gibson, 2005). Dialogue acts are
used to describe the function or role of an utterance
in a discourse, and have been applied to the anal-
ysis of mediums of communication including con-
versational speech (Stolcke et al, 2000; Shriberg et
al., 2004; Murray et al, 2006), email (Cohen et al,
2004; Carvalho and Cohen, 2005; Lampert et al,
2008), instant messaging (Ivanovic, 2008; Kim et
al., 2010a), edited documents (Soricut and Marcu,
2003; Sagae, 2009) and online forums (Xi et al,
14
2004; Weinberger and Fischer, 2006; Wang et al,
2007; Fortuna et al, 2007; Kim et al, 2010b). For a
more complete review of models for discourse dis-
entanglement and dialogue act tagging, see Kim et
al. (2010b).
Joint classification has been applied in a number
of different contexts, based on the intuition that it
should be possible to harness interactions between
different sub-tasks to the mutual benefit of both.
Warnke et al (1997) jointly performed segmenta-
tion and dialogue act classification over a German
spontaneous speech corpus. In their approach, the
predictions of a multi-layer perceptron classifier on
dialogue act boundaries were fed into an n-gram
language model, which was used for the joint seg-
mentation and classification of dialogue acts. Sut-
ton and McCallum (2005) performed joint parsing
and semantic role labelling (SRL), using the results
of a probabilistic SRL system to improve the accu-
racy of a probabilistic parser. Finkel and Manning
(2009) built a joint, discriminative model for pars-
ing and named entity recognition (NER), address-
ing the problem of inconsistent annotations across
the two tasks, and demonstrating that NER bene-
fited considerably from the interaction with parsing.
Dahlmeier et al (2009) proposed a joint probabilis-
tic model for word sense disambiguation (WSD) of
prepositions and SRL of prepositional phrases (PPs),
and achieved state-of-the-art results over both tasks.
There has been a recent growth in user-level
research over forums. Lui and Baldwin (2009)
explored a range of user-level features, including
replies-to and co-participation graph analysis, for
post quality classification. Lui and Baldwin (2010)
introduced a novel user classification task where
each user is classified against four attributes: clar-
ity, proficiency, positivity and effort. User commu-
nication roles in web forums have also been studied
(Chan and Hayes, 2010; Chan et al, 2010).
Threading information has been shown to en-
hance retrieval effectiveness for post-level retrieval
(Xi et al, 2004; Seo et al, 2009), thread-level
retrieval (Seo et al, 2009; Elsas and Carbonell,
2009), sentence-level shallow information extrac-
tion (Sondhi et al, 2010), and near-duplicate thread
detection (Muthmann et al, 2009). These results
suggest that the thread structural representation used
in this research, which includes both linking struc-
ture and the dialogue act associated with each link,
could potentially provide even greater leverage in
these retrieval tasks.
Another related research area is post-level classi-
fication, such as general post quality classification
(Weimer et al, 2007; Weimer and Gurevych, 2007;
Wanas et al, 2008; Lui and Baldwin, 2009), and
post descriptiveness in particular domains (e.g. med-
ical forums: Leaman et al (2010)). It has been
demonstrated (Wanas et al, 2008; Lui and Bald-
win, 2009) that thread discourse structure can signif-
icantly improve the classification accuracy for post-
level tasks.
Initiation?response pairs (e.g. question?answer,
assessment?agreement, and blame?denial) from on-
line forums have the potential to enhance thread
summarisation or automatically generate knowledge
bases for Community Question Answering (cQA)
services such as Yahoo! Answers. While initiation?
response pair identification has been explored as a
pairwise ranking problem (Wang and Rose?, 2010),
question?answer pair identification has been ap-
proached via the two separate sub-tasks of ques-
tion classification and answer detection (Cong et al,
2008; Ding et al, 2008; Cao et al, 2009). Our
thread discourse structure prediction task includes
joint classification of post roles (i.e. dialogue acts)
and links, and could potentially be performed at the
sub-post sentence level to extract initiation?response
pairs.
3 Task Description and Data Set
The main task performed in this research is joint
classification of inter-post links (Link) and dialogue
acts (DA) within forum threads. In this, we assume
that a post can only link to an earlier post (or a vir-
tual root node), and that dialogue acts are labels on
edges. It is possible for there to be multiple edges
from a given post, e.g. if a post both confirms the va-
lidity of an answer and adds extra information to the
original question (as happens in Post4 in Figure 1).
We experiment with two different approaches to
joint classification: (1) a linear-chain CRF over
combined Link/DA post labels; and (2) a depen-
dency parser. The joint classification task is a nat-
ural fit for dependency parsing, in that the task is
intrinsically one of inferring labelled dependencies
15
between posts, but it has a number of special prop-
erties that distinguish it from standard dependency
parsing:
strict reverse-chronological directionality: the
head always precedes the dependent, in terms
of the chronological sequencing of posts.
non-projective dependencies: threads can contain
non-projective dependencies, e.g. in a 4-post
thread, posts 2 and 3 may be dependent on
post 1, and post 4 dependent on post 2; around
2% of the threads in our dataset contain non-
projective dependencies.
multi-headedness: it is possible for a given post to
have multiple heads, including the possibility
of multiple dependency links to the same post
(e.g. adding extra information to a question
[Question-Add] as well as retracting infor-
mation from the original question [Question-
Correction]); around 6% of the threads in our
dataset contain multi-headed dependencies.
disconnected sub-graphs: it is possible for there to
be disconnected sub-graphs, e.g. in instances
where a user hijacks a thread to ask their
own unrelated question, or submit an unrelated
spam post; around 2% of the threads in our
dataset contain disconnected sub-graphs.
The first constraint potentially simplifies depen-
dency parsing, and non-projective dependencies are
relatively well understood in the dependency parsing
community (Tapanainen and Jarvinen, 1997; Mc-
Donald et al, 2005). Multi-headedness and dis-
connected sub-graphs pose greater challenges to de-
pendency parsing, although there has been research
done on both (McDonald and Pereira, 2006; Sagae
and Tsujii, 2008; Eisner and Smith, 2005). The
combination of non-projectivity, multi-headedness
and disconnected sub-graphs in a single dataset,
however, poses a challenge for dependency parsing.
In addition to performing evaluation in batch
mode over complete threads, we consider the task of
?in situ thread classification?, whereby we predict
the discourse structure of a thread after each post.
This is intended to simulate the more realistic set-
ting of incrementally crawling/updating thread data,
but needing to predict discourse structure for partial
threads. We are interested in determining the rela-
tive degradation in accuracy for in situ classification
vs. batch classification.
As our dataset, we use the CNET forum dataset
of Kim et al (2010b),1 which contains 1332 an-
notated posts spanning 315 threads, collected from
the Operating System, Software, Hardware and Web
Development sub-forums of cnet.2 Each post is la-
belled with one or more links (including the possi-
bility of null-links, where the post doesn?t link to
any other post), and each link is labelled with a di-
alogue act. The dialogue act set is made up of 5
super-categories: Question, Answer, Resolution
(confirmation of the question being resolved), Re-
production (external confirmation of a proposed so-
lution working) and Other. The Question category
contains 4 sub-classes: Question, Add, Confirma-
tion and Correction. Similarly, the Answer cate-
gory contains 5 sub-classes: Answer, Add, Confir-
mation, Correction and Objection. For example,
the label Question-Add signifies the Question su-
perclass and Add subclass, i.e. addition of extra in-
formation to a question. For full details of the dia-
logue act tagset, see Kim et al (2010b).
Dependency links are represented by their relative
position in the chronologically-sorted list of posts,
e.g. 1 indicates a link back to the preceding post,
and 2 indicates a link back two posts.
Unless otherwise noted, evaluation is over the
combined link and dialogue act tag, including the
combination of superclass and subclass for the
Question and Answer dialogue acts. For ex-
ample, 1+Answer-Answer indicates a dependency
link back one post, which is an answer to a question.
The most common label in the dataset is 1+Answer-
answer (28.4%).
4 Learners and Features
4.1 Learners
To predict thread discourse structure, we use a struc-
tured classification approach ? based on the find-
ings of Kim et al (2010b) and Kim et al (2010a)
? and a dependency parser. The structured clas-
sification approach we experiment with is a linear-
1Available from http://www.csse.unimelb.edu.
au/research/lt/resources/conll2010-thread/
2http://forums.cnet.com/
16
chain conditional random field learner (CRF: Laf-
ferty et al (2001)), within which we explore two
simple approaches to joint classification, as is ex-
plained in Section 5.1. Dependency parsing (Ku?bler
et al, 2009) is the task of automatically predicting
the dependency structure of a token sequence, in
the form of binary asymmetric dependency relations
with dependency types.
Standardly, CRFs have been applied to tasks such
as part-of-speech tagging, named entity recognition,
semantic role labelling and supertagging, where the
individual tokens are single words. Similarly, de-
pendency parsing is conventionally applied to sen-
tences, with single-word tokens. In our case, our
tokens are thread posts, with much greater scope for
feature engineering than single words, and techni-
cal challenges in scaling the underlying implemen-
tations to handle potentially much larger feature sets.
As our learners, we deployed CRFSGD (Bot-
tou, 2011) to learn the CRF, and MaltParser (Nivre
et al, 2007) as our dependency parser. CRFSGD
uses stochastic gradient descent to efficiently solve
the convex optimisation problem, and scales well to
large feature sets. We used the default parameter set-
tings for CRFSGD, with feature templates includ-
ing all unigram features of the current token as well
as bigram features combining the previous output to-
ken with the current token.
MaltParser implements transition-based parsing,
where no formal grammar is considered, and a tran-
sition system, or state machine, is learned to map a
sentence onto its dependency graph. One feature of
MaltParser that makes it well suited to our task is
that it is possible to define feature models of arbi-
trary complexity for each token. In presenting the
thread data to MaltParser, we represent the null-
link from the initial post of each thread, as well as
any disconnected posts, as the root.
To the best of our knowledge, there is no past
work on using dependency parsing to learn thread
discourse structure. Based on extensive experimen-
tation, we determined that the MaltParser configu-
ration that obtains the best results for our task is the
Nivre algorithm in arc-standard mode (Nivre, 2003;
Nivre, 2004), using LIBSVM (Chang and Lin, 2011)
with a linear kernel as the learner, and a feature
model with exhaustive combinations of features re-
lating to the features and predictions of the first/top
three tokens from both ?Input? and ?Stack?.3 As
such, MaltParser is actually unable to predict any
non-projective structures, as experiments with algo-
rithms supporting non-projective structures invari-
ably led to lower results. In our choice of parsing al-
gorithm, we are also unable to detect posts with mul-
tiple heads, but can potentially detect disconnected
sub-graphs.
4.2 Features
The features used in our classifiers are as follows:
Structural Features:
Initiator a binary feature indicating whether the
current post?s author is the thread initiator.
Position the relative position of the current post,
as a ratio over the total number of posts in the
thread.
Semantic Features:
TitSim the relative location of the post which has
the most similar title (based on unweighted co-
sine similarity) to the current post.
PostSim the relative location of the post which
has the most similar content (based on un-
weighted cosine similarity) to the current post.
Punct the number of question marks (QuCount),
exclamation marks (ExCount) and URLs
(UrlCount) in the current post.
UserProf the class distribution (in the training
thread) of the author of the current post.
These features are drawn largely from the work
of Kim et al (2010b), with two major differences:
(1) we do not use post context features because our
learners (i.e. CRFSGD and MaltParser) inherently
capture Markov chains; and (2) our UserProf fea-
tures are customised to the class set associated with
the task at hand, e.g. the UserProf features for the
standalone linking task take the form of the link la-
bels (and not dialogue act labels) of the posts by the
relevant author in the training data. Table 1 shows
the feature representation of the third post in a thread
17
Feature Value Explanation
Initiator 1.0 post from the initiator
ExCount 4.0 4 exclamation marks
QuCount 0.0 0 question marks
UrlCount 0.0 0 URLs
Position 0.25 i?1n = 3?18PostSim 2.0 most similar to post 1
TitSim 2.0 most similar to post 1
UserProf ~x counts for posts of each
class from the same author
in the training data
Table 1: The feature presentation of the third post in a
thread of length 8
of length 8. The values of each feature are scaled to
the range [0, 1] before being fed into the learners.
We also experimented with other features,
including raw bag-of-words lexical features,
dimensionality-reduced lexical features (using
principal components analysis), and different post
similarity measures such as longest common subse-
quence (LCS) match. While we were able to obtain
gains in isolation, when combined with the other
features, these features had no impact, and are thus
not included in the results presented in this paper.
5 Classification Methodology
All our experiments were carried out based on strati-
fied 10-fold cross-validation, stratifying at the thread
level to ensure that all posts from a given thread
occur in a single fold. The results are primarily
evaluated using post-level micro-averaged F-score
(F?: ? = 1), and additionally with thread-level F-
score/classification accuracy (i.e. the proportion of
threads where all posts have been correctly classi-
fied4), where space allows. Statistical significance
is tested using randomised estimation (Yeh, 2000)
with p < 0.05. Initial experiments showed it is
hard for learners to discover which posts have multi-
ple links, largely due to the sparsity of multi-headed
posts (which account for less than 5% of the total
posts). Therefore, only the the most recent link for
3http://maltparser.org/userguide.html#
parsingalg
4Classification accuracy = F-score at the thread-level, as
each thread is assigned a single label of correct or incorrect.
each multi-headed post was included in training, but
evaluation still considers all links.
5.1 Joint classification
In our experiments, we test two basic approaches to
joint classification for the CRF: (1) classifying the
Link and DA separately, and composing the predic-
tions to form the joint classification (Composition);
and (2) combining the Link and DA labels into a sin-
gle class, and applying the learner over the posts
with the combined class (Combine). Note that
Composition has the potential for mismatches in
the number of Link and DA predictions it gener-
ates, causing complications in the class composition.
Even if the same number of labels is predicted for
both Link and DA, if multiple tags are predicted in
both cases, we are left with the problem of determin-
ing which link label to combine with which dialogue
act label. As such, we have our reservations about
Composition, but as the CRF performs strict 1-of-
n labelling, these are not issues in the experiments
reported herein.
MaltParser natively handles the combination of
Link and DA in its dependency parsing formulation.
5.2 In Situ Thread Classification
One of the biggest challenges in classifying the dis-
course structure of a forum thread is that threads
evolve over time, as new posts are posted. In or-
der to capture this phenomenon, and compare the
accuracy of different models when applied to partial
thread data (artificially cutting off a thread at post
N ) vs. complete threads.5 This is done in the fol-
lowing way: classification over the first two posts
only ([1, 2]), the first four posts ([1, 4]), the first six
posts ([1, 6]), the first eight posts ([1, 8]), and all
posts ([all]). In each case, we limit the test data
only, meaning that the only variable in play is the
extent of thread context used to learn the thread dis-
course structure for the given set of posts. We break
down the results in each case into the indicated sub-
threads, e.g. we take the predictions for [all], and
break them down into the results for [1, 2], [1, 4],
[1, 6], [1, 8] and [all], for direct comparison with the
predictions over the respective sub-thread data.
5In practice, completeness is defined at a given point in time,
when the crawl was done, and it is highly likely that some of the
?complete? threads had extra posts after the crawl.
18
Method Link DA
Kim et al (2010b) .863 / .676 .751 / .543
CRFSGD .891 / .727 .795 / .609
Table 2: Post/thread-level component-wise classification
F-scores for Link and DA classes
6 Experiments and Analysis
6.1 Joint classification
As our baseline for the task, we first use a sim-
ple majority class classifier in the form of the sin-
gle joint class of 1+Answer-Answer for all posts,
which has a post-level F-score of 0.284. A stronger
baseline is to classify all first posts as 0+Question-
Question and all subsequent posts as 1+Answer-
answer, which achieves a post-level F-score of
0.515 (labelled as Heuristic).
As described in Section 5.1, one approach to joint
classification with CRFSGD is to firstly conduct
component-wise classification over Link and DA
separately, and compose the predictions. The results
for the separate Link and DA classification tasks are
presented in Table 2, along with the best results for
Link and DA classification from Kim et al (2010b).
At the component-wise tasks, our method is superior
to Kim et al (2010b), based on a different learner
and slightly different feature set.
Next, we compose the component-wise clas-
sifications for the CRF into joint classifications
(Composition). We contrast this with the com-
bined class approach for CRFSGD and MaltParser
(jointly presented as Joint in Table 3). With the
combined class results, we additionally ablate each
of the feature types from Section 4.2, and also
present results for a dummy model, where no fea-
tures are provided and the prediction is based simply
on sequential priors (Dummy). The results are pre-
sented in Table 3, along with the Heuristic baseline
result.
Several interesting things can be observed from
the post-level F-score results in Table 3. First, with
no features (Dummy), while CRFSGD performs
slightly worse than the Heuristic baseline, Malt-
Parser significantly surpasses the baseline. This is
due to the richer sequential context model of Malt-
Parser. Second, the single feature with the greatest
impact on results is UserProf, i.e. user profile fea-
Method CRFSGD MaltParser
Heuristic .515?/ .311?
Dummy .508?/ .394? .533?/ .356?
Composition .728?/ .553? ?
Joint +ALL .756 / .578 .738 / .578
?Initiator .745 / .569 .708?/ .534?
?Position .750 / .565 .736 / .568
?PostSim .753 / .578 .737 / .568
?TitSim .760 / .587 .734 / .571
?Punct .745 / .571 .735 / .578
?UserProf .672?/ .527? .701?/ .536?
Table 3: Post/thread-level Link-DA joint classification F-
scores (??? signifies a significantly worse result than that
for the same learner with ALL features)
tures extracted from the training data; CRFSGD in
particular benefits from this feature. We return to ex-
plore this effect in Section 6.4. Third, although the
Initiator feature does not have much effect on CRF-
SGD, it affects the performance of MaltParser sig-
nificantly. Further experiments shown that the com-
bination of Initiator and UserProf is sufficient to
achieve a competitive result (i.e. 0.731). It therefore
seems that MaltParser is more robust than CRF-
SGD, whose performance relies crucially on user-
level features which must be learned from the train-
ing data (i.e. UserProf).
Looking to the thread-level F-scores, we observe
some interesting divergences from the post-level F-
score results. First, with no features (Dummy),
CRFSGD significantly outperforms both the base-
line and MaltParser. This appears to be because
CRFSGD performs particularly well over short
threads (e.g. of length 3 and 4), but worse over
longer threads. Second, the best thread-level F-
scores from CRFSGD (i.e. 0.587) and MaltParser
(i.e. 0.578) are not significantly different, despite the
discrepancy in post-level F-score (where CRFSGD
is markedly superior in this case). With the extra
features, the performance of MaltParser on short
threads appears to pick up noticeably, and the differ-
ence in post-level predictions is over longer threads.
If we evaluate the two models over DA super-
classes only (ignoring mismatches at the subclass
level for Question and Answer), the post-level F-
scores for joint classification with ALL features for
CRFSGD and MaltParser are 0.803 and 0.787, re-
spectively.
19
Approaches Link DA
Component-wise .891 / .727? .795 / .609
CRFSGD decomp .893 / .749 .785 / .603
MaltParser decomp .870?/ .730? .766?/ .571?
Table 4: Post/thread-level Link and DA F-scores from
component-wise classification, and from Link-DA clas-
sification decomposition (??? signifies a significantly
worse result than the best result in that column)
Looking at the performance of CRFSGD (in
Combine mode) and MaltParser on disconnected
sub-graphs, while both models did predict a small
number of non-initial posts with null-links (includ-
ing MaltParser predicting 5 out of 6 posts in a sin-
gle thread as having null-links), none were correct,
and neither model was able to correctly predict any
of the 6 actual non-initial instances of null-links in
the dataset.
Finally, we took the joint classification results
from CRFSGD and MaltParser using ALL fea-
tures, and decomposed the predictions into Link and
DA. The results are presented in Table 4, along with
the results for component-wise classification from
Table 2. Somewhat surprisingly, the decomposed
predictions are mostly slightly worse than the re-
sults for the component-wise classification, despite
achieving higher F-score for the joint classification
task. This is simply due to the combined method
tending to get both labels correct or both labels
wrong, for a given post.
6.2 Post Position-based Result Breakdown
One question in thread discourse structure classifica-
tion is how accurate the predictions are at different
depths in a thread (e.g. the first two posts vs. the sec-
ond two posts). A breakdown of results across posts
at different positions is presented in Figure 2.
The overall trend for both CRFSGD and Malt-
Parser is that it becomes increasingly hard to clas-
sify posts as we continue through a thread, due to
greater variability in discourse structure and greater
sparsity in the data. However, it is interesting to note
that the results for CRFSGD actually improve from
posts 7 and 8 ([7, 8]) to posts 9 and onwards ([9, ]).
To further investigate this effect, we performed class
decomposition over the joint classification predic-
tions, and performed a similar breakdown of posts
[1,2] [3,4] [5,6] [7,8] [9,] All0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Posts
F ?
 
 CRFSGDMaltParser
Figure 2: Breakdown of post-level Link-DA results for
CRFSGD and MaltParser based on post position
[1,2] [3,4] [5,6] [7,8] [9,] All0
0.5
1
Posts
F ?
Decomposed Link
 
 CRFSGDMaltParser
[1,2] [3,4] [5,6] [7,8] [9,] All0
0.5
1
Posts
F ?
Decomposed DA
 
 CRFSGDMaltParser
Figure 3: Breakdown of post-level Link and DA F-score
based on the decomposition of CRFSGD and Malt-
Parser classifications
for Link and DA; the results are presented in Fig-
ure 3. It is clear that the anomaly for CRFSGD
comes from the DA component, due to there being
greater predictability in the dialogue for final posts
in a thread (users tend to confirm a successful reso-
lution of the problem, or report on successful exter-
nal reproduction of the solution). MaltParser seems
less adept at identifying that a post is at the end
of a thread, and predicting the dialogue act accord-
ingly. This observation is congruous with the find-
ings of McDonald and Nivre (2007) that errors prop-
agate, due to MaltParser?s greedy inference strat-
egy. The higher results for Link are to be expected,
as throughout the thread, most posts tend to link lo-
cally.
20
XXXXXXXXXTest
B/down [1, 2] [1, 4] [1, 6] [1, 8] [All]
[1, 2] .947/.947 ? ? ? ?
[1, 4] .946/.947 .836/.841 ? ?
[1, 6] .946/.947 .840/.841 .800/.794 ? ?
[1, 8] .946/.947 .840/.841 .800/.794 .780/.769 ?
[All] .946/.946 .840/.838 .800/.791 .776/.767 .756/.738
Table 5: Post-level Link-DA F-score for CRFSGD/MaltParser, based on in situ classification over sub-threads of
different lengths (indicated in the rows), broken down over different post extents (indicated in the columns)
6.3 In Situ Structure Prediction
As described in Section 5.2, we simulate in situ
thread discourse structure prediction by removing
differing numbers of posts from the tail of the thread,
and applying the trained model over the resultant
sub-threads. The results for in situ classification are
presented in Table 5, with the rows indicating the
size of the test sub-thread, and the columns being a
breakdown of results over different portions of the
classified thread. The reason that we do not pro-
vide numbers for all cells in the table is that the size
of the test sub-thread determines the post extents we
can breakdown the results into, e.g. we cannot return
results for posts 1?4 ([1, 4]) when the size of the test
thread was only two posts ([1, 2]).
From the results, we can see that both CRFSGD
and MaltParser are very robust when applied to par-
tial threads, to the extent that we actually achieve
higher results over shortened versions of the thread
than over the complete thread in some instances, al-
though the only difference that is statistically signif-
icant is over [1, 8] for CRFSGD, where the predic-
tion over the partial thread is actually superior to that
over the complete thread. From this, we can con-
clude that it is possible to apply our method to partial
threads without any reduction in effectiveness rela-
tive to classification over complete threads. As such,
our method is shown to be robust when applied to
real-time analysis of dynamically evolving threads.
6.4 User profile feature analysis
In our experiments, we noticed that the user profile
feature (UserProf) is the most effective feature for
both CRFSGD and MaltParser. To gain a deeper
insight into the behaviour of the feature, we binned
the posts according to the number of times the author
had posted in the training data, evaluated based on a
Bin uscore Posts Total Totalper user users posts
High 224.6 251 1 251
Medium 1?41.7 4?48 45 395
Low 0 2?4 157 377
Very Low 0 1 309 309
Table 6: Statistics for the 4 groups of users
user score (uscore) for each user:
uscorei =
?ni
j=1 spi,j
ni
where ni is the number of posts by user i, and spi,j is
the number of posts by user i that occur as training
instances for other posts by the same author. uscore
reflects the average training?test post ratio per user
in cross-validation. Note that as we include all posts
from a given thread in a single partition during cross-
validation, it is possible for an author to have posted
4 times, but have a uscore of 0 due to those posts all
occurring in the same thread.
We ranked the users in the dataset in descending
order of uscore, sub-ranking on ni in cases of a tie
in uscore. The users were binned into 4 groups
of roughly equal post size. The detailed statistics
are shown in Table 6, noting that the high-frequency
bin (?High?) contains posts from a single user. We
present the post-level micro-averaged F-score for
posts in each bin based on CRFSGD, with and with-
out user profile features, in Figure 4.
Contrary to expectation, the UserProf features
have the greatest impact for users with fewer posts.
In fact, a statistically significant difference was ob-
served only for users with no posts in the training
data (uscore = 0), where the F-score jumped over
10% in absolute terms for both the Low and Very
Low bins. Our explanation for this effect is that the
21
High Median Low Very Low0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
User Group
F ?
 
 With UserProfWithout UserProf
Figure 4: Post-level joint classification results for users
binned by uscore, based on CRFSGD with and without
UserProf features)
lack of user profile information is predictive of the
sort of posts we can expect from a user (i.e. they
tend to be newbie users, asking questions).
7 Conclusions and Future Work
In this research, we explored the joint classification
of web user forum thread discourse structure, in the
form of a rooted directed acyclic graph over posts,
with edges labelled with dialogue acts. Three classi-
fication approaches were proposed: separately pre-
dicting Link and DA labels, and composing them
into a joint class; predicting a combined Link-DA
class using a structured classifier; and applying de-
pendency parsing to the problem. We found the
combined approach based on CRFSGD to perform
best over the task, closely followed by dependency
parsing with MaltParser.
We also examined the task of in situ classification
of dialogue structure, in the form of predicting the
discourse structure of partial threads, as contrasted
with classifying only complete threads. We found
that there was no drop in F-score over different sub-
extents of the thread in classifying partial threads,
despite the relative lack of thread context.
In future work, we plan to delve further into de-
pendency parsing, looking specifically at the impli-
cations of multi-headedness and disconnected sub-
graphs on dependency parsing. We also intend to
carry out meta-classification, combining the predic-
tions of CRFSGD and MaltParser.
Our user profile features were found to be the
pick of our features, but counter-intuitively, to bene-
fit users with no posts in the training data, rather than
prolific users. We wish to explore this effect further,
including incorporating unsupervised user-level fea-
tures into our classifiers.
Acknowledgements
The authors wish to acknowledge the development
efforts of Johan Hall in configuring MaltParser to
handle numeric features, and be able to parse thread
structures. NICTA is funded by the Australian gov-
ernment as represented by Department of Broad-
band, Communication and Digital Economy, and the
Australian Research Council through the ICT Centre
of Excellence programme.
References
Le?on Bottou. 2011. CRFSGD software. http://
leon.bottou.org/projects/sgd.
Xin Cao, Gao Cong, Bin Cui, Christian S. Jensen, and
Ce Zhang. 2009. The use of categorization infor-
mation in language models for question retrieval. In
Proceedings of the 18th ACM Conference on Informa-
tion and Knowledge Management (CIKM 2009), pages
265?274, Hong Kong, China.
Vitor R. Carvalho and William W. Cohen. 2005. On
the collective classification of email ?speech acts?. In
Proceedings of 28th International ACM-SIGIR Con-
ference on Research and Development in Information
Retrieval (SIGIR 2005), pages 345?352.
Jeffrey Chan and Conor Hayes. 2010. Decomposing dis-
cussion forums using user roles. In Proceedings of the
WebSci10: Extending the Frontiers of Society On-Line
(WebSci10), pages 1?8, Raleigh, USA.
Jeffrey Chan, Conor Hayes, and Elizabeth M. Daly.
2010. Decomposing discussion forums using user
roles. In Proceedings of the Fourth International AAAI
Conference on Weblogs and Social Media (ICWSM
2010), pages 215?8, Washington, USA.
Chih-Chung Chang and Chih-Jen Lin. 2011. LIB-
SVM: A library for support vector machines. ACM
Transactions on Intelligent Systems and Technology,
2(3):27:1?27:27. Software available at http://
www.csie.ntu.edu.tw/?cjlin/libsvm.
William W. Cohen, Vitor R. Carvalho, and Tom M.
Mitchell. 2004. Learning to classify email into
?speech acts?. In Proceedings of the 2004 Conference
on Empirical Methods in Natural Language Process-
ing (EMNLP 2004), pages 309?316, Barcelona, Spain.
Gao Cong, Long Wang, Chin-Yew Lin, Young-In Song,
and Yueheng Sun. 2008. Finding question-answer
22
pairs from online forums. In Proceedings of 31st Inter-
national ACM-SIGIR Conference on Research and De-
velopment in Information Retrieval (SIGIR?08), pages
467?474, Singapore.
Daniel Dahlmeier, Hwee Tou Ng, and Tanja Schultz.
2009. Joint learning of preposition senses and seman-
tic roles of prepositional phrases. In Proceedings of
the 2009 Conference on Empirical Methods in Natural
Language Processing (EMNLP 2009), pages 450?458,
Singapore. Association for Computational Linguistics.
Shilin Ding, Gao Cong, Chin-Yew Lin, and Xiaoyan Zhu.
2008. Using conditional random fields to extract con-
text and answers of questions from online forums. In
Proceedings of the 46th Annual Meeting of the ACL:
HLT (ACL 2008), pages 710?718, Columbus, USA.
Jason Eisner and Noah A. Smith. 2005. Parsing with soft
and hard constraints on dependency length. In Pro-
ceedings of the Ninth International Workshop on Pars-
ing Technology, pages 30?41, Vancouver, Canada.
Jonathan L. Elsas and Jaime G. Carbonell. 2009. It
pays to be picky: An evaluation of thread retrieval
in online forums. In Proceedings of 32nd Interna-
tional ACM-SIGIR Conference on Research and De-
velopment in Information Retrieval (SIGIR?09), pages
714?715, Boston, USA.
Micha Elsner and Eugene Charniak. 2008. You talk-
ing to me? a corpus and algorithm for conversation
disentanglement. In Proceedings of the 46th Annual
Meeting of the ACL: HLT (ACL 2008), pages 834?842,
Columbus, USA.
Jenny Rose Finkel and Christopher D. Manning. 2009.
Joint parsing and named entity recognition. In Pro-
ceedings of Human Language Technologies: The 2009
Annual Conference of the North American Chap-
ter of the Association for Computational Linguistics
(NAACL HLT 2009), pages 326?334, Boulder, Col-
orado. Association for Computational Linguistics.
Blaz Fortuna, Eduarda Mendes Rodrigues, and Natasa
Milic-Frayling. 2007. Improving the classification of
newsgroup messages through social network analysis.
In Proceedings of the 16th ACM Conference on In-
formation and Knowledge Management (CIKM 2007),
pages 877?880, Lisbon, Portugal.
Barbara J. Grosz and Candace L. Sidner. 1986. Atten-
tion, intention and the structure of discourse. Compu-
tational Linguistics, 12(3):175?204.
Edward Ivanovic. 2008. Automatic instant messaging
dialogue using statistical models and dialogue acts.
Master?s thesis, University of Melbourne.
Su Nam Kim, Lawrence Cavedon, and Timothy Bald-
win. 2010a. Classifying dialogue acts in one-on-one
live chats. In Proceedings of the 2010 Conference on
Empirical Methods in Natural Language Processing
(EMNLP 2010), pages 862?871, Boston, USA.
Su Nam Kim, Li Wang, and Timothy Baldwin. 2010b.
Tagging and linking web forum posts. In Proceedings
of the 14th Conference on Computational Natural Lan-
guage Learning (CoNLL-2010), pages 192?202, Upp-
sala, Sweden.
Sandra Ku?bler, Ryan McDonald, and Joakim Nivre.
2009. Dependency parsing. Synthesis Lectures on Hu-
man Language Technologies, 2(1):1?127.
John Lafferty, Andrew McCallum, and Fernando Pereira.
2001. Conditional random fields: Probabilistic mod-
els for segmenting and labeling sequence data. In Pro-
ceedings of the 18th International Conference on Ma-
chine Learning, pages 282?289, Williamstown, USA.
Andrew Lampert, Robert Dale, and Ce?cile Paris. 2008.
The nature of requests and commitments in email mes-
sages. In Proceedings of the AAAI 2008 Workshop on
Enhanced Messaging, pages 42?47, Chicago, USA.
Robert Leaman, Laura Wojtulewicz, Ryan Sullivan, An-
nie Skariah, Jian Yang, and Graciela Gonzalez. 2010.
Towards internet-age pharmacovigilance: Extracting
adverse drug reactions from user posts in health-
related social networks. In Proceedings of the 2010
Workshop on Biomedical Natural Language Process-
ing (ACL 2010), pages 117?125, Uppsala, Sweden.
Oliver Lemon, Alex Gruenstein, and Stanley Peters.
2002. Collaborative activities and multi-tasking in di-
alogue systems. Traitement Automatique des Langues
(TAL), Special Issue on Dialogue, 43(2):131?154.
Chen Lin, Jiang-Ming Yang, Rui Cai, Xin-Jing Wang,
Wei Wang, and Lei Zhang. 2009. Modeling semantics
and structure of discussion threads. In Proceedings of
the 18th International Conference on the World Wide
Web (WWW 2009), pages 1103?1104, Madrid, Spain.
Marco Lui and Timothy Baldwin. 2009. You are what
you post: User-level features in threaded discourse. In
Proceedings of the 14th Australasian Document Com-
puting Symposium (ADCS 2009), Sydney, Australia.
Marco Lui and Timothy Baldwin. 2010. Classifying
user forum participants: Separating the gurus from the
hacks, and other tales of the internet. In Proceedings
of the 2010 Australasian Language Technology Work-
shop (ALTW 2010), pages 49?57, Melbourne, Aus-
tralia.
Ryan McDonald and Joakim Nivre. 2007. Charac-
terizing the errors of data-driven dependency parsing
models. In Proceedings of the 2007 Joint Confer-
ence on Empirical Methods in Natural Language Pro-
cessing and Computational Natural Language Learn-
ing (EMNLP-CoNLL 2007), pages 122?131, Prague,
Czech Republic.
Ryan McDonald and Fernando Pereira. 2006. On-
line learning of approximate dependency parsing al-
gorithms. In Proceedings of the 11th Conference of
23
the European Chapter of the Association for Computa-
tional Linguistics (EACL 2006), pages 81?88, Trento,
Italy.
Ryan McDonald, Fernando Pereira, Kiril Ribarov, and
Jan Hajic. 2005. Non-projective dependency pars-
ing using spanning tree algorithms. In Proceedings of
Human Language Technology Conference and Confer-
ence on Empirical Methods in Natural Language Pro-
cessing, pages 523?530, Vancouver, Canada.
Gabriel Murray, Steve Renals, Jean Carletta, and Johanna
Moore. 2006. Incorporating speaker and discourse
features into speech summarization. In Proceedings
of the Main Conference on Human Language Technol-
ogy Conference of the North American Chapter of the
Association of Computational Linguistics, pages 367?
374.
Klemens Muthmann, Wojciech M. Barczyn?ski, Falk
Brauer, and Alexander Lo?ser. 2009. Near-duplicate
detection for web-forums. In Proceedings of the 2009
International Database Engineering & Applications
Symposium (IDEAS 2009), pages 142?151, Cetraro,
Italy.
Joakim Nivre, Johan Hall, Jens Nilsson, Atanas Chanev,
Gu?lsen Eryigit, Sandra Ku?bler, Svetoslav Marinov,
and Erwin Marsi. 2007. MaltParser: A language-
independent system for data-driven dependency pars-
ing. Natural Language Engineering, 13(02):95?135.
Joakim Nivre. 2003. An efficient algorithm for projec-
tive dependency parsing. In Proceedings of the 8th In-
ternational Workshop on Parsing Technologies (IWPT
03), pages 149?160, Nancy, France.
Joakim Nivre. 2004. Incrementality in determinis-
tic dependency parsing. In Proceedings of the ACL
Workshop Incremental Parsing: Bringing Engineer-
ing and Cognition Together (ACL-2004), pages 50?57,
Barcelona, Spain.
Carolyn Penstein Rose?, Barbara Di Eugenio, Lori S.
Levin, and Carol Van Ess-Dykema. 1995. Discourse
processing of dialogues with multiple threads. In Pro-
ceedings of the 33rd Annual Meeting of the Asso-
ciation for Computational Linguistics, pages 31?38,
Cambridge, USA.
Kenji Sagae and Jun?ichi Tsujii. 2008. Shift-reduce
dependency DAG parsing. In Proceedings of the
22nd International Conference on Computational Lin-
guistics (COLING 2008), pages 753?760, Manchester,
UK.
Kenji Sagae. 2009. Analysis of discourse structure with
syntactic dependencies and data-driven shift-reduce
parsing. In Proceedings of the 11th International Con-
ference on Parsing Technologies (IWPT-09), pages 81?
84, Paris, France.
Anne Schuth, Maarten Marx, and Maarten de Rijke.
2007. Extracting the discussion structure in comments
on news-articles. In Proceedings of the 9th Annual
ACM International Workshop on Web Information and
Data Management, pages 97?104, Lisboa, Portugal.
Jangwon Seo, W. Bruce Croft, and David A. Smith.
2009. Online community search using thread struc-
ture. In Proceedings of the 18th ACM Conference
on Information and Knowledge Management (CIKM
2009), pages 1907?1910, Hong Kong, China.
Elinzabeth Shriberg, Raj Dhillon, Sonali Bhagat, Jeremy
Ang, and Hannah Carvey. 2004. The ICSI meeting
recorder dialog act (MRDA) corpus. In Proceedings of
the 5th SIGdial Workshop on Discourse and Dialogue,
pages 97?100, Cambridge, USA.
Parikshit Sondhi, Manish Gupta, ChengXiang Zhai, and
Julia Hockenmaier. 2010. Shallow information ex-
traction from medical forum data. In Proceedings of
the 23rd International Conference on Computational
Linguistics (COLING 2010), Posters Volume, pages
1158?1166, Beijing, China.
Radu Soricut and Daniel Marcu. 2003. Sentence level
discourse parsing using syntactic and lexical infor-
mation. In Proceedings of the 2003 Human Lan-
guage Technology Conference of the North American
Chapter of the Association for Computational Linguis-
tics (HLT-NAACL 2003), pages 149?156, Edmonton,
Canada.
Andreas Stolcke, Klaus Ries, Noah Coccaro, Eliza-
beth Shriberg, Rebecca Bates, Daniel Jurafsky, Pail
Taylor, Rachel Martin, Carol Van Ess-Dykema, and
Marie Meteer. 2000. Dialogue act modeling for
automatic tagging and recognition of conversational
speech. Computational Linguistics, 26(3):339?373.
Charles Sutton and Andrew McCallum. 2005. Joint
parsing and semantic role labeling. In Proceedings of
the Ninth Conference on Computational Natural Lan-
guage Learning (CoNLL-2005), pages 225?228, Ann
Arbor, Michigan. Association for Computational Lin-
guistics.
Pasi Tapanainen and Timo Jarvinen. 1997. A non-
projective dependency parser. In Proceedings of the
Fifth Conference on Applied Natural Language Pro-
cessing, pages 64?71, Washington, USA.
Nayer Wanas, Motaz El-Saban, Heba Ashour, and
Waleed Ammar. 2008. Automatic scoring of online
discussion posts. In Proceeding of the 2nd ACM work-
shop on Information credibility on the web (WICOW
?08), pages 19?26, Napa Valley, USA.
Yi-Chia Wang and Carolyn P. Rose?. 2010. Mak-
ing conversational structure explicit: identification of
initiation-response pairs within online discussions. In
Human Language Technologies: The 2010 Annual
Conference of the North American Chapter of the As-
sociation for Computational Linguistics (NAACL HLT
2010), pages 673?676.
24
Yi-Chia Wang, Mahesh Joshi, and Carolyn Rose?. 2007.
A feature based approach to leveraging context for
classifying newsgroup style discussion segments. In
Proceedings of the 45th Annual Meeting of the As-
sociation for Computational Linguistics Companion
Volume Proceedings of the Demo and Poster Sessions
(ACL 2007), pages 73?76, Prague, Czech Republic.
Yi-Chia Wang, Mahesh Joshi, William W. Cohen, and
Carolyn Rose?. 2008. Recovering implicit thread
structure in newsgroup style conversations. In Pro-
ceedings of the Second International Conference on
Weblogs and Social Media (ICWSM 2008), pages 152?
160, Seattle, USA.
V. Warnke, R. Kompe, H. Niemann, and E. No?th. 1997.
Integrated dialog act segmentation and classification
using prosodic features and language models. In Proc.
Eurospeech, volume 1, pages 207?210.
Markus Weimer and Iryna Gurevych. 2007. Predicting
the perceived quality of web forum posts. In Proceed-
ings of the 2007 International Conference on Recent
Advances in Natural Language Processing (RANLP
2007), pages 643?648, Borovets, Bulgaria.
Markus Weimer, Iryna Gurevych, and Max Mu?hlha?user.
2007. Automatically assessing the post quality in on-
line discussions on software. In Proceedings of the
45th Annual Meeting of the ACL: Interactive Poster
and Demonstration Sessions, pages 125?128, Prague,
Czech Republic.
Armin Weinberger and Frank Fischer. 2006. A
framework to analyze argumentative knowledge con-
struction in computer-supported collaborative learn-
ing. Computers & Education, 46:71?95, January.
Florian Wolf and Edward Gibson. 2005. Representing
discourse coherence: A corpus-based study. Compu-
tational Linguistics, 31(2):249?287.
Wensi Xi, Jesper Lind, and Eric Brill. 2004. Learning
effective ranking functions for newsgroup search. In
Proceedings of 27th International ACM-SIGIR Con-
ference on Research and Development in Informa-
tion Retrieval (SIGIR 2004), pages 394?401. Sheffield,
UK.
Alexander Yeh. 2000. More accurate tests for the sta-
tistical significance of result differences. In Proceed-
ings of the 18th International Conference on Compu-
tational Linguistics (COLING 2000), pages 947?953,
Saarbru?cken, Germany.
25
Proceedings of the NAACL HLT 2010 Workshop on Computational Linguistics in a World of Social Media, pages 15?16,
Los Angeles, California, June 2010. c?2010 Association for Computational Linguistics
Intelligent Linux Information Access by Data Mining: the ILIAD Project
Timothy Baldwin,? David Martinez,? Richard B. Penman,? Su Nam Kim,?
Marco Lui,? Li Wang? and Andrew MacKinlay?
? Dept of Computer Science and Software Engineering, University of Melbourne, Australia
? NICTA Victoria Research Laboratory
Abstract
We propose an alternative to conventional in-
formation retrieval over Linux forum data,
based on thread-, post- and user-level analysis,
interfaced with an information retrieval engine
via reranking.
1 Introduction
Due to the sheer scale of web data, simple keyword
matching is an effective means of information ac-
cess for many informational web queries. There
still remain significant clusters of information access
needs, however, where keyword matching is less
successful. One such instance is technical web fo-
rums and mailing lists (collectively termed ?forums?
for the purposes of this paper): technical forums
are a rich source of information when troubleshoot-
ing, and it is often possible to resolve technical
queries/problems via web-archived data. The search
facilities provided by forums and web search en-
gines tend to be over-simplistic, however, and there
is a desperate need for more sophisticated search (Xi
et al, 2004; Seo et al, 2009), including: favour-
ing threads which have led to a successful resolu-
tion; reflecting the degree of clarity/reproducibility
of the proposed solution in a given thread; repre-
senting threads via their threaded rather than sim-
ple chronological structure; the ability to highlight
key aspects of the thread, in terms of the problem
description and solution which led to a successful
resolution; and ideally, the ability to represent the
problem and solution in normalised form via infor-
mation extraction.
This paper provides a brief outline of an attempt
to achieve these and other goals in the context of
Linux web user forum data, in the form of the IL-
IAD (Intelligent Linux Information Access by Data
Mining) project. Linux users and developers rely
particularly heavily on web user forums and mail-
ing lists, due to the nature of the community, which
is highly decentralised ? with massive proliferation
of packages and distributions? and notoriously bad
at maintaining up-to-date documentation at a level
suitable for newbie and even intermediate users.
2 Project Outline
Our proposed solution is as follows: (1) crawl data
from a variety of web user forums; (2) analyse each
thread, to identify named entities and generate meta-
data; (3) analyse post-level linkages; (4) predict
user-level features which are expected to impinge on
the quality of search results; and finally (5) draw to-
gether the features from (1) to (4) to enhance the
quality of a traditional ranked IR approach. We
briefly review each step below. Given space limi-
tations, we focus on outlining our interpretation of
the task in this paper. For further details and results,
the reader is referred to the key papers cited herein.
2.1 Crawling
The first step is to crawl data from a variety of fo-
rums and mailing lists, for which we have developed
open-source scraping software in the form of SITE-
SCRAPER.1 SITESCRAPER is designed such that the
user simply copies relevant content from a browser-
rendered version of a given set of pages, which it
interprets as a structured record, and translates into
a generalised XPATH query.
2.2 Thread-level analysis
Next, we perform named entity recognition (NER)
over each thread to identify entities such as package
and distribution names, version numbers and snip-
pets of code; as part of this, we perform version
1http://sitescraper.googlecode.com/
15
anchoring, in identifying what entity each version
number relates to.
To generate thread-level metadata, we classify
each thread for the following three features, based
on an ordinal scale of 1?5 (Baldwin et al, 2007):
Complete: Is the problem description complete?
Solved: Is a solution provided in the thread?
Task Oriented: Is the thread about a specific
problem?
We additionally automatically classify the nature
of the thread content, in terms of, e.g., whether it
contains documentation or installation details, or re-
lates to software, hardware or programming.
Our experiments on thread-level classification are
based on a set of 250 annotated threads from Lin-
uxQuestions and other forums, as well as a dataset
from CNET.
2.3 Post-level analysis
We automatically analyse the post-to-post discourse
structure of each thread, in terms of which (preced-
ing) post(s) each post relates to, and how, building
off the work of Rose? et al (1995) and Wolf and Gib-
son (2005). For example, a given post may refute
the solution proposed in an earlier post, and also
propose a novel solution in response to the initiat-
ing post.
Separately, we are developing techniques for
identifying whether a new post to a given forum
is sufficiently similar to other (ideally resolved)
threads that the author should be prompted to first
check the existing threads for redundancy before a
new thread is initiated.
Our experiments on post-level analysis are, once
again, based on data from LinuxQuestions and
CNET.
2.4 User-level analysis
We are also experimenting with profiling users vari-
ously, based on a 5-point ordinal scale across a range
of user characteristics. Our experiments are based
on data from LinuxQuestions (Lui, 2009).
2.5 IR ranking
The various features are interfaced with an ad hoc
information retrieval (IR) system via a learning-to-
rank approach (Cao et al, 2007). In order to carry
out IR evaluation, we have developed a set of queries
and relevance judgements over a large-scale set of
forum data.
Our experiments to date have been based on com-
bination over three IR engines (LUCENE, ZETTAIR
and LEMUR), and involved thread-level metadata
only, but we have achieved encouraging results, sug-
gesting that thread-level metadata can enhance IR
effectiveness.
3 Conclusions
This paper provides an outline of the ILIAD project,
focusing on the tasks of crawling, thread-level anal-
ysis, post-level analysis, user-level analysis and IR
reranking. We have designed a series of class sets
for the component tasks, and carried out experimen-
tation over a range of data sources, achieving en-
couraging results.
Acknowledgements
NICTA is funded by the Australian Government as rep-
resented by the Department of Broadband, Communica-
tions and the Digital Economy and the Australian Re-
search Council through the ICT Centre of Excellence pro-
gram.
References
T Baldwin, D Martinez, and RB Penman. 2007. Auto-
matic thread classification for Linux user forum infor-
mation access. In Proc of ADCS 2007.
Z Cao, T Qin, TY Liu, MF Tsai, and H Li. 2007. Learn-
ing to rank: from pairwise approach to listwise ap-
proach. In Proc of ICML 2007.
M Lui. 2009. Impact of user characteristics on online fo-
rum classification tasks. Honours thesis, University of
Melbourne. http://repository.unimelb.edu.
au/10187/5745.
CP Rose?, B Di Eugenio, LS Levin, and C Van Ess-
Dykema. 1995. Discourse processing of dialogues
with multiple threads. In Proc of ACL 1995.
J Seo, WB Croft, and DA Smith. 2009. Online commu-
nity search using thread structure. In Proc of CIKM
2009.
F Wolf and E Gibson. 2005. Representing discourse co-
herence: A corpus-based study. Comp Ling, 31(2).
W Xi, J Lind, and E Brill. 2004. Learning effective rank-
ing functions for newsgroup search. In Proc of SIGIR
2004.
16
Proceedings of the Fourteenth Conference on Computational Natural Language Learning, pages 192?202,
Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational Linguistics
Tagging and Linking Web Forum Posts
Su Nam Kim, Li Wang and Timothy Baldwin
Dept of Computer Science and Software Engineering
University of Melbourne, Australia
sunamkim@gmail.com, li.wang.d@gmail.com, tb@ldwin.net
Abstract
We propose a method for annotating post-
to-post discourse structure in online user
forum data, in the hopes of improving
troubleshooting-oriented information ac-
cess. We introduce the tasks of: (1) post
classification, based on a novel dialogue
act tag set; and (2) link classification. We
also introduce three feature sets (structural
features, post context features and seman-
tic features) and experiment with three dis-
criminative learners (maximum entropy,
SVM-HMM and CRF).We achieve above-
baseline results for both dialogue act and
link classification, with interesting diver-
gences in which feature sets perform well
over the two sub-tasks, and go on to per-
form preliminary investigation of the inter-
action between post tagging and linking.
1 Introduction
With the advent of Web 2.0, there has been an ex-
plosion of web authorship from individuals of all
walks of life. Notably, social networks, blogs and
web user forums have entered the mainstream of
modern-day society, creating both new opportuni-
ties and challenges for organisations seeking to en-
gage with clients or users of any description. One
area of particular interest is web-based user sup-
port, e.g. to aid a user in purchasing a gift for a
friend, or advising a customer on how to config-
ure a newly-acquired wireless router. While such
interactions traditionally took place on an indi-
vidual basis, leading to considerable redundancy
for frequently-arising requests or problems, user
forums support near-real-time user interaction in
the form of a targeted thread made up of individ-
ual user posts. Additionally, they have the poten-
tial for perpetual logging to allow other users to
benefit from them. This in turn facilitates ?sup-
port sharing??i.e. the ability for users to look
over the logs of past support interactions to deter-
mine whether there is a documented, immediately-
applicable solution to their current problem?on a
scale previously unimaginable. This research is
targeted at this task of enhanced support sharing,
in the form of text mining over troubleshooting-
oriented web user forum data (Baldwin et al, to
appear).
One facet of our proposed strategy for enhanc-
ing information access to troubleshooting-oriented
web user forum data is to preprocess threads to
uncover the ?content structure? of the thread, in
the form of its post-to-post discourse structure.
Specifically, we identify which earlier post(s) a
given post responds to (linking) and in what man-
ner (tagging), in an amalgam of dialogue act tag-
ging (Stolcke et al, 2000) and coherence-based
discourse analysis (Carlson et al, 2001; Wolf and
Gibson, 2005). The reason we do this is gauge
the relative role/import of individual posts, to in-
dex and weight component terms accordingly, ul-
timately in an attempt to enhance information ac-
cess. Evidence to suggest that this structure can
enhance information retrieval effectiveness comes
from Xi et al (2004) and Seo et al (2009) (see
Section 2).
To illustrate the task, consider the thread from
the CNET forum shown in Figure 1, made up of
5 posts (Post 1, ..., Post 5) with 4 distinct partici-
pants (A, B, C, D). In the first post, A initiates the
thread by requesting assistance in creating a web
form. In response, B proposes a Javascript-based
solution (i.e. responds to the first post with a pro-
posed solution), and C proposes an independent
solution based on .NET (i.e. also responds to the
first post with a proposed solution). Next, A re-
sponds to C?s post asking for details of how to in-
clude this in a web page (i.e. responds to the third
post asking for clarification), and in the final post,
D proposes a different solution again (i.e. responds
to the first post with a different solution again).
192
HTML Input Code - CNET Coding & scripting Forums
User A HTML Input Code
Post 1 . . . Please can someone tell me how to create an
input box that asks the user to enter their ID,
and then allows them to press go. It will then
redirect to the page . . .
User B Re: html input code
Post 2 Part 1: create a form with a text field. See
. . . Part 2: give it a Javascript action . . .
User C asp.net c# video
Post 3 Ive prepared for you video.link click . . .
User A Thank You!
Post 4 Thanks a lot for that . . . I have Microsoft Vi-
sual Studio 6, what program should I do this
in? Lastly, how do I actually include this in my
site?. . .
User D A little more help
Post 5 . . . You would simply do it this way: . . . You
could also just . . . An example of this is:. . .
Figure 1: Snippeted posts in a CNET thread



	
A



	ABCDAEBF
EBFEBF
Figure 2: Post links and dialogue act labels for the
example thread in Figure 1
In this, we therefore end up with a tree-based de-
pendency link structure, with each post (other than
the initial post) relating back to a unique preced-
ing post via a range of link types, as indicated in
Figure 2. Note, however, that more generally, it
is possible for a post to link to multiple preced-
ing posts (e.g. refuting one proposed solution, and
proposing a different solution to the problem in the
initial post).
Our primary contributions in this paper are: (1)
a novel post label set for post structure in web
forum data, and associated dataset; and (2) a se-
ries of results for post dependency linking and la-
belling, which achieve strong results for the re-
spective tasks.
2 Related Work
Related work exists in the broad fields of dialogue
processing, discourse analysis and information re-
trieval, and can be broken down into the following
tasks: (1) dialogue act tagging; (2) discourse ?dis-
entanglement?; (3) community question answer-
ing; and (4) newsgroup/user forum search.
Dialogue act (DA) tagging is a means of cap-
turing the function of a given utterance relative
to an encompassing discourse, and has been pro-
posed variously as a means of enhancing dialogue
summarisation (Murray et al, 2006), and track-
ing commitments and promises in email (Cohen
et al, 2004; Lampert et al, 2008), as well as be-
ing shown to improve speech recognition accu-
racy (Stolcke et al, 2000). A wide range of DA
tag sets have been proposed, usually customised
to a particular medium such as speech dialogue
(Stolcke et al, 2000; Shriberg et al, 2004), task-
focused email (Cohen et al, 2004; Wang et al,
2007; Lampert et al, 2008) or instant messag-
ing (Ivanovic, 2008). The most immediately rel-
evant DA-based work we are aware of is that of
Xi et al (2004), who proposed a 5-way classifi-
cation for newsgroup data (including QUESTION
and AGREEMENT/AMMENDMENT), but did not
present any results based on the tagset.
A range of supervised models have been applied
to DA classification, including graphical mod-
els (Ji and Bilmes, 2005), kernel methods (Wang
et al, 2007), dependency networks (Carvalho
and Cohen, 2005), transformation-based learning
(Samuel et al, 1998), maxent models (Ang et
al., 2005) and HMMs (Ivanovic, 2008). There is
some contention about the import of context in DA
classification, with the prevailing view being that
context aids classification (Carvalho and Cohen,
2005; Ang et al, 2005; Ji and Bilmes, 2005), but
also evidence to suggest that strictly local mod-
elling is superior (Ries, 1999; Serafin and Di Eu-
genio, 2004).
In this work, we draw on existing work (esp.
Xi et al (2004)) in proposing a novel DA tag
set customised to the analysis of troubleshooting-
oriented web user forums (Section 3), and com-
pare a range of text classification and structured
classification methods for post-level DA classifi-
cation.
Discourse disentanglement is the process of
automatically identifying coherent sub-discourses
in a single thread (in the context of user fo-
rums/mailing lists), chat session (in the context of
IRC chat data: Elsner and Charniak (2008)), sys-
tem interaction (in the context of HCI: Lemon et
al. (2002)) or document (Wolf and Gibson, 2005).
The exact definition of what constitutes a sub-
discourse varies across domains, but for our pur-
poses, entails an attempt to resolve the informa-
193
tion need of the initiator by a particular approach;
if there are competing approaches proposed in a
single thread, multiple sub-discourses will neces-
sarily arise. The data structure used to represent
the disentangled discourse varies from a simple
connected sub-graph (Elsner and Charniak, 2008),
to a stack/tree (Grosz and Sidner, 1986; Lemon
et al, 2002; Seo et al, 2009), to a full directed
acyclic graph (DAG: Rose? et al (1995), Wolf and
Gibson (2005), Schuth et al (2007)). Disentan-
glement has been carried out via analysis of di-
rect citation/user name references (Schuth et al,
2007; Seo et al, 2009), topic modelling (Lin et al,
2009), and clustering over content-based features
for pairs of posts, optionally incorporating various
constraints on post recency (Elsner and Charniak,
2008; Wang et al, 2008; Seo et al, 2009).
In this work, we follow Rose? et al (1995) and
Wolf and Gibson (2005) in adopting a DAG repre-
sentation of discourse structure, and draw on the
wide set of features used in discourse entangle-
ment to model coherence.
Community question answering (cQA) is the
task of identifying question?answer pairs in a
given thread, e.g. for the purposes of thread sum-
marisation (Shrestha and McKeown, 2004) or au-
tomated compilation of resources akin to Yahoo!
Answers. cQA has been applied to both mail-
ing list and user forum threads, conventionally
based on question classification, followed by rank-
ing of candidate answers relative to each question
(Shrestha and McKeown, 2004; Ding et al, 2008;
Cong et al, 2008; Cao et al, 2009). The task is
somewhat peripheral to our work, but relevant in
that it involves the implicit tagging of certain posts
as containing questions/answers, as well as link-
ing the posts together. Once again, we draw on the
features used in cQA in this research.
There has been a spike of recent interest in
newsgroup/user forum search. Xi et al (2004)
proposed a structured information retrieval (IR)
model for newsgroup search, based on author fea-
tures, thread structure (based on the tree defined by
the reply-to structure), thread ?topology? features
and content-based features, and used a supervised
ranking method to improve over a baseline IR sys-
tem. Elsas and Carbonell (2009) ? building on
earlier work on blog search (Elsas et al, 2008) ?
proposed a probabilistic IR approach which ranks
user forum threads relative to selected posts in the
overall thread, and again demonstrated the superi-
ority of this method over a model which ignores
thread structure. Finally, Seo et al (2009) auto-
matically derived thread structure from user forum
threads, and demonstrated that the IR effectiveness
over the ?threaded? structure was superior to that
using a monolithic document representation.
The observations and results of Xi et al (2004)
and Seo et al (2009) that threading information
(or in our case ?disentangled? DAG structure) en-
hances IR effectiveness is a core motivator for this
research.
3 Post Label Set
Our post label set contains 12 categories, intended
to capture the typical interactions that take place in
troubleshooting-oriented threads on technical fo-
rums. There are 2 super-categories (QUESTION,
ANSWER) and 3 singleton classes (RESOLUTION,
REPRODUCTION, and OTHER). QUESTION, in
turn, contains 4 sub-classes (QUESTION, ADD,
CONFIRMATION, CORRECTION), while ANSWER
contains 5 sub-classes (ANSWER, ADD, CONFIR-
MATION, CORRECTION, and OBJECTION), par-
tially mirroring the sub-structure of QUESTION.
We represent the amalgam of a super- and sub-
class as QUESTION-ADD, for example.
All tags other than QUESTION-QUESTION and
OTHER are relational, i.e. relate a given post to a
unique earlier post. A given post can potentially
be labelled with multiple tags (e.g. confirm details
of a proposed solution, in addition to providing ex-
tra details of the problem), although, based on the
strictly chronological ordering of posts in threads,
a post can only link to posts earlier in the thread
(and can also not cross thread boundaries). Addi-
tionally, the link structure is assumed to be tran-
sitive, in that if post A links to post B and post B
to post C, post A is implicitly linked to post C. As
such, an explicit link from post A to post C should
exist only in the case that the link between them is
not inferrable transitively.
Detailed definitions of each post tag are given
below. Note that initiator refers to the user who
started the thread with the first post.
QUESTION-QUESTION (Q-Q): the post con-
tains a new question, independent of the
thread context that precedes it. In general,
QUESTION-QUESTION is reserved for the
first post in a given thread.
QUESTION-ADD (Q-ADD): the post supple-
194
ments a question by providing additional
information, or asking a follow-up question.
QUESTION-CONFIRMATION (Q-CONF): the
post points out error(s) in a question without
correcting them, or confirms details of the
question.
QUESTION-CORRECTION (Q-CORR): the post
corrects error(s) in a question.
ANSWER-ANSWER (A-A): the post proposes an
answer to a question.
ANSWER-ADD (A-ADD): the post supplements
an answer by providing additional informa-
tion.
ANSWER-CONFIRMATION (A-CONF): the
post points out error(s) in an answer without
correcting them, or confirms details of the
answer.
ANSWER-CORRECTION (A-CORR): the post
corrects error(s) in an answer.
ANSWER-OBJECTION (A-OBJ): the post ob-
jects to an answer on experiential or theoreti-
cal grounds (e.g. It won?t work.).
RESOLUTION (RES): the post confirms that an
answer works, on the basis of implementing
it.
REPRODUCTION (REP): the post either: (1)
confirms that the same problem is being ex-
perienced (by a non-initiator, e.g. I?m seeing
the same thing.); or (2) confirms that the an-
swer should work.
OTHER (OTHER): the post does not belong to
any of the above classes.
4 Feature Description
In this section, we describe our post feature repre-
sentation, in the form of four feature types.
4.1 Lexical features
As our first feature type, we use simple lexical fea-
tures, in the form of unigram and bigram tokens
contained within a given post (without stopping).
We also POS tagged and lemmatised the posts,
postfixing the lemmatised token with its POS tag
(using Lingua::EN::Tagger and morpha (Min-
nen et al, 2001)). Finally, we bin together the
counts for each token, and represent it via its raw
frequency.
4.2 Structural features
The identity of the post author, and position of the
post within the thread, can be indicators of the
post/link structure of a given post. We represent
the post author as a simple binary feature indicat-
ing whether s/he is the thread initiator, and the post
position via its relative position in the thread (as a
ratio, relative to the total number of posts).
4.3 Post context features
As mentioned in Section 2, post context has gen-
erally (but not always) been shown to enhance the
classification accuracy of DA tagging tasks, in the
form of Markov features providing predicted post
labels for previous posts, or more simply, post-to-
post similarity. We experiment with a range of
post context features, all of which are compatible
with features both from the same label set as that
being classified (e.g. link features for link classifi-
cation), as well as features from a second label set
(e.g. DA label features for link classification).
Previous Post: There is a strong prior for posts
to link to their immediately preceding post (as ob-
served for 79.9% of the data in our dataset), and
also strong sequentiality in our post label set (e.g.
a post following a Q-Q is most likely to be an A-
A). As such, we represent the predicted post label
of the immediately preceding post, as a first-order
Markov feature, as well as a binary feature to in-
dicate whether the author of the previous post also
authored the current post.
Previous Post from Same Author: A given
user tends to author posts of the same basic type
(e.g. QUESTION or ANSWER) in a given thread,
and pairings such as A-A and A-CONF from a
given author are very rare. To capture this obser-
vation, we look to see if the author of the current
post has posted earlier in the thread, and if so, in-
clude the label and relative location (in posts) of
their most recent previous post.
Full History: As a final option, we include the
predictions for all posts P1, ..., Pi?1 preceding the
current post Pi.
4.4 Semantic features
We tested four semantic features based on post
content and title.
195
Title Similarity: For forums such as CNET
which include titles for individual posts (as rep-
resented in Figure 1), a post having the same or
similar title as a previous post is often a strong
indicator that it responds to that post. This both
provides a strong indicator of which post a given
post responds (links) to, and can aid in DA tag-
ging. We use simple cosine similarity to find the
post with the most-similar title, and represent its
relative location to the current post.
Post Similarity: Posts of the same general type
tend to have similar content and be linked. For
example, A-A and A-ADD posts tend to share
content. We capture this by identifying the post
with most-similar content based on cosine similar-
ity, and represent its relative location to the current
post.
Post Characteristics: We separately represent
the number of question marks, exclamation marks
and URLs in the current post. In general, ques-
tion marks occur in QUESTION and CONFIRMA-
TION posts, exclamation marks occur in RES and
OBJECTION posts, and URLs occur in A-A and
A-ADD posts.
User Profile: Some authors tend to answer ques-
tions more, while others tend to ask more ques-
tions. We capture the class priors for the author of
the current post by the distribution of post labels
in their posts in the training data.
5 Experimental Setup
As our dataset, we collected 320 threads contain-
ing a total of 1,332 posts from the Operating Sys-
tem, Software, Hardware, and Web Development
sub-forums of CNET.1
The annotation of post labels and links was car-
ried by two annotators in a custom-built web inter-
face which supported multiple labels and links for
a given post. For posts with multilabels, we used
a modified version of Cohen?s Kappa, which re-
turned ? values of 0.59 and 0.78 for the post label
and link annotations, respectively. Any disagree-
ments in labelling were resolved through adjudi-
cation.
Of the 1332 posts, 65 posts have multiple labels
(which possibly link to a common post) and 22
posts link to two different links. The majority post
label in the dataset is A-A (40.30%).
1http://forums.cnet.com/?tag=
TOCleftColumn.0
We built machine learners using a conven-
tional Maximum Entropy (ME) learner,2 as well as
two structural learners, namely: (1) SVM-HMMs
(Joachims et al, 2009), as implemented in SVM-
struct3, with a linear kernel; and (2) conditional
random fields (CRFs) using CRF++.4 SVM-
HMMs and CRFs have been successfully applied
to a range of sequential tagging tasks such as
syllabification (Bartlett et al, 2009), chunk pars-
ing (Sha and Pereira, 2003) and word segmen-
tation (Zhao et al, 2006). Both are discrimina-
tive models which capture structural dependen-
cies, which is highly desirable in terms of mod-
elling sequential preferences between post labels
(e.g. A-CONF typically following a A-A). SVM-
HMM has the additional advantage of scaling to
large numbers of features (namely the lexical fea-
tures). As such, we only experiment with lexical
features for SVM-HMM and ME.
All of our evaluation is based on stratified 10-
fold cross-validation, stratifying at the thread level
to ensure that if a given post is contained in the
test data for a given iteration, all other posts in
that same thread are also in the test data (or more
pertinently, not in the training data). We evalu-
ate using micro-averaged precision, recall and F-
score (? = 1). We test the statistical significance
of all above-baseline results using randomised es-
timation (p < 0.05; Yeh (2000)), and present all
such results in bold in our results tables.
In our experiments, we first look at the post
classification task in isolation (i.e. we predict
which labels to associate with each post, under-
specifying which posts those labels relate to). We
then move on to look at the link classification task,
again in isolation (i.e. we predict which previous
posts each post links to, underspecifying the na-
ture of the link). Finally, we perform preliminary
investigation of the joint task of DA and link clas-
sification, by incorporating DA class features into
the link classification task.
6 DA Classification Results
Our first experiment is based on post-level dia-
logue act (DA) classification, ignoring link struc-
ture in the first instance. That is, we predict the
labels on edges emanating from each post in the
DAG representation of the post structure, without
2http://maxent.sourceforge.net/
3http://www.cs.cornell.edu/People/tj/
svm_light/svm_hmm.html
4http://crfpp.sourceforge.net/
196
Features CRF SVM-HMM ME
Lexical ? .566 .410
Structural .742 .638 .723
Table 1: DA classification F-score with lexical and
structural features (above-baseline results in bold)
specifying the edge destination. Returning to our
example in Figure 2, e.g., the gold-standard clas-
sification for Post 1 would be Q-Q, Post 2 would
be A-A, etc.
As a baseline for DA classification, simple ma-
jority voting attains an F-score of 0.403, based on
the A-A class. A more realistic baseline, how-
ever, is a position-conditioned variant, where the
first post is always classified as Q-Q, and all sub-
sequent posts are classified as A-A, achieving an
F-score of 0.641.
6.1 Lexical and structural features
First, we experiment with lexical and structural
features (recalling that we are unable to scale the
CRF model to full lexical features). Lexical fea-
tures produce below-baseline performance, while
simple structural features immediately lead to an
improvement over the baseline for CRF and ME.
The reason for the poor performance with lex-
ical features is that our dataset contains only
around 1300 posts, each of which is less than 100
words in length on average. The models are sim-
ply unable to generalise over this small amount of
data, and in the case of SVM-HMM, the presence
of lexical features, if anything, appears to obscure
the structured nature of the labelling task (i.e. the
classifier is unable to learn the simple heuristic
used by the modified majority class baseline).
The success of the structural features, on the
other hand, points to the presence of predictable
sequences of post labels in the data. That SVM-
HMM is unable to achieve baseline performance
with structural features is slightly troubling.
6.2 Post context features
Next, we test the two post context features: Previ-
ous Post (P) and Previous Post from Same Author
(A). Given the success of structural features, we
retain these in our experiments. Note that the la-
bels used in the post context are those which are
interactively learned by that model for the previ-
ous posts.
Table 2 presents the results for structural fea-
Features CRF SVM-HMM ME
Struct+R .740 .640 .632
Struct+A .742 .676 .693
Struct+F .744 .641 .577
Struct+RA .397 .636 .665
Struct+AF .405 .642 .586
Table 2: DA classification F-score with structural
and DA-based post context features (R = ?Previ-
ous Post?, A = ?Previous Post from Same Author?,
and F = ?Full History?; above-baseline results in
bold)
tures combined with DA-based post context; we
do not present any combinations of Previous Post
and Full History, as Full History includes the Pre-
vious Post.
Comparing back to the original results using
only the structural results, we can observe that Pre-
vious Post from Same Author and Full History (A
and F, resp., in the table) lead to a slight incre-
ment in F-score for both CRF and SVM-HMM,
but degrade the performance of ME. Previous Post
leads to either a marginal improvement, or a drop
in results, most noticeably for ME. It is slightly
surprising that the CRF should benefit from con-
text features at all, given that it is optimising over
the full tag sequence, but the impact is relatively
localised, and when all sets of context features
are used, the combined weight of noisy features
appears to swamp the learner, leading to a sharp
degradation in F-score.
6.3 Semantic features
We next investigate the relative impact of the se-
mantic features, once again including structural
features in all experiments. Table 3 presents the F-
score using the different combinations of semantic
features.
Similarly to the post context features, the se-
mantic features produced slight increments over
the structural features in isolation, especially for
CRF and ME. For the first time, SVM-HMM
achieved above-baseline results, when incorporat-
ing title similarity and post characteristics. Of the
individual semantic features, title and post simi-
larity appear to be the best performers. Slightly
disappointingly, the combination of semantic fea-
tures generally led to a degradation in F-score, al-
most certainly due to data sparseness. The best
overall result was achieved with CRF, incorporat-
197
Features CRF SVM-HMM ME
Struct+T .751 .636 .660
Struct+P .747 .636 .662
Struct+C .738 .587 .630
Struct+U .722 .564 .620
Struct+TP .740 .627 .720
Struct+TC .744 .646 .589
Struct+TU .738 .600 .609
Struct+PC .745 .630 .583
Struct+PU .736 .626 .605
Struct+CU .730 .599 .619
Struct+TPC .739 .622 .580
Struct+TPU .729 .613 .6120
Struct+TCU .750 .611 .6120
Struct+PCU .738 .616 .614
Struct+TPCU .737 .619 .605
Table 3: DA classification F-score with semantic
features (T = ?Title Similarity?, P = ?Post Simi-
larity?, C = ?Post Characteristics?, and U = ?User
Profile?; above-baseline results in bold)
ing structural features and title similarity, at an F-
score of 0.751.
To further explore the interaction between post
context and semantic features, we built CRF clas-
sifiers for different combinations of post context
and semantic features, and present the results in
Table 4.5 We achieved moderate gains in F-score,
with all post context features, in combination with
structural features, post similarity and post char-
acteristics achieving an F-score of 0.753, slightly
higher than the best result achieved for just struc-
tural and post context features.
It is important to refer back to the results for
lexical features (comparable to what would have
been achieved with a standard text categorisation
approach to the task), and observe that we have
achieved far higher F-scores using features cus-
tomised to user forum data. It is also important
to reflect that post context (in terms of the features
and the structured classification results of CRF)
appears to markedly improve our results, contrast-
ing with the results of Ries (1999) and Serafin and
Di Eugenio (2004).
5We omit the results for Full History post context for rea-
sons of space, but there is relatively little deviation from the
numbers presented.
Features R A RA
Struct+T .649 .649 .649
Struct+P .737 .736 .742
Struct+C .741 .741 .742
Struct+U .745 .742 .737
Struct+TP .645 .656 .658
Struct+TC .383 .402 .408
Struct+TU .650 .652 .652
Struct+PC .730 .743 .753
Struct+PU .232 .232 .286
Struct+CU .719 .471 .710
Struct+TPC .498 .469 .579
Struct+TPU .248 .232 .248
Struct+TCU .388 .377 .380
Struct+PCU .231 .231 .261
Struct+TPCU .231 .231 .231
Table 4: DA classification F-score for CRF with
different combinations of post context features and
semantic features (R = ?Previous Post?, and A
= ?Previous Post from Same Author?; T = ?Ti-
tle Similarity?, P = ?Post Similarity?, C = ?Post
Characteristics?, and U = ?User Profile?; above-
baseline results in bold)
7 Link Classification Results
Our second experiment is based on link classifi-
cation in isolation. Here, we predict unlabelled
edges, e.g. in Figure 2, the gold-standard classifi-
cation for Post 1 would be NULL, Post 2 would be
Post 1, Post 3 would be Post 1, etc.
Note that the initial post cannot link to any other
post, and also that the second post always links
to the first post. As this is a hard constraint on
the data, and these posts simply act to inflate the
overall numbers, we exclude all first and second
posts from our evaluation of link classification.
We experimented with a range of baselines as
presented in Table 5, but found that the best per-
former by far was the simple heuristic of linking
each post (except for the initial post) to its imme-
diately preceding post. This leads to an F-score of
0.631, comparable to that for the post classifica-
tion task.
7.1 Lexical and structural features
Once again, we started by exploring the effective-
ness of lexical and structural features using the
three learners, as detailed in Table 6.
Similarly to the results for post classification,
198
Baseline Prec Rec F-score
Previous post .641 .622 .631
First post .278 .269 .274
Title similarity .311 .301 .306
Post similarity .255 .247 .251
Table 5: Baselines for link classification
Features CRF SVM-HMM ME
Lexical ? .154 .274
Structural .446 .220 .478
Table 6: Link classification F-score with lexical
and structural features (above-baseline results in
bold)
structural features are more effective than lexical
features for link classification, but this time, nei-
ther feature set approaches the baseline F-score
for any of the learners. Once again, the results for
SVM-HMM are well below those for the other two
learners.
7.2 Post context features
Next, we experiment with link-based post con-
text features, in combination with the structural
features, as the results were found to be consis-
tently better when combined with the structural
features (despite the below-baseline performance
of the structural features in this case). The link-
based post context features in all cases are gener-
ated using the CRF with structural features from
Table 6. As before, we do not present any combi-
nations of Previous Post and Full History, as Full
History includes the Previous Post
As seen in Table 9, here, for the first time, we
achieve an above-baseline result for link classifi-
cation, for SVM and ME based on Previous Post
from Same Author in isolation, and also some-
times in combination with the other feature sets.
The results for CRF also improve, but not to a
level of statistical significance over the baseline.
Similarly to the results for DA classification, the
results for CRF drop appreciably when we com-
bine feature sets.
7.3 Semantic features
Finally, we experiment with semantic features,
once again in combination with structural features.
The results are presented in Table 8.
The results for semantic features largely mir-
Features CRF SVM-HMM ME
Struct+R .234 .605 .618
Struct+A .365 .665 .665
Struct+F .624 .648 .615
Struct+RA .230 .615 .661
Struct+AF .359 .663 .621
Table 7: Link classification F-score with structural
and link-based post context features (R = ?Previ-
ous Post?, A = ?Previous Post from Same Author?,
and F = ?Full History?; above-baseline results in
bold)
Features CRF SVM-HMM ME
Struct+T .464 .223 .477
Struct+P .433 .198 .453
Struct+C .438 .213 .419
Struct+U .407 .160 .376
Struct+TP .459 .194 .491
Struct+TC .449 .229 .404
Struct+TU .456 .174 .353
Struct+PC .422 .152 .387
Struct+PU .439 .166 .349
Struct+CU .397 .178 .366
Struct+TPC .449 .185 .418
Struct+TPU .449 .160 .365
Struct+TCU .459 .185 .358
Struct+PCU .439 .161 .358
Struct+TPCU .443 .163 .365
Table 8: Link classification F-score with semantic
features (T = ?Title Similarity?, P = ?Post Simi-
larity?, C = ?Post Characteristics?, and U = ?User
Profile?; above-baseline results in bold)
ror those for post classification: small improve-
ments are observed for title similarity with CRF,
but otherwise, the results degrade across the board,
and the combination of different feature sets com-
pounds this effect.
The best overall result achieved for link classifi-
cation is thus the 0.743 for CRF with the structural
and post context features.
We additionally experimented with combina-
tions of features as for post classification, but were
unable to improve on this result.
7.4 Link Classification using DA Features
Ultimately, we require both DA and link classifica-
tion of each post, which is possible by combining
the outputs of the component classifiers described
199
Features CRF SVM-HMM ME
Struct+R .586 .352 .430
Struct+A .591 .278 .568
Struct+F .704 .477 .546
Struct+RA .637 .384 .551
Struct+AF .743 .527 .603
Table 9: Link classification F-score with structural
and post-based post context features (R = ?Previ-
ous Post?, A = ?Previous Post from Same Author?,
and F = ?Full History?; above-baseline results in
bold)
above, by rolling the two tasks into a single clas-
sification task, or alternatively by looking to joint
modelling methods. As a preliminary step in this
direction, and means of exploring the interaction
between the two tasks, we repeat the experiment
based on post context features from above (see
Section 7.2), but rather than using link-based post
context, we use DA-based post context.
As can be seen in Table 9, the results for SVM-
HMM and ME drop appreciably as compared to
the results using link-based post context in Table 9,
while the results for CRF jump to the highest level
achieved for the task for all three learners. The
effect can be ascribed to the ability of CRF to
natively model the (bidirectional) link classifica-
tion history in the process of performing structured
learning, and the newly-introduced post features
complementing the link classification task.
8 Discussion and Future Work
Ultimately, we require both DA and link classifica-
tion of each post, which is possible in (at least) the
following three ways: (1) by combining the out-
puts of the component classifiers described above;
(2) by rolling the two tasks into a single classifi-
cation task; or (3) by looking to joint modelling
methods. Our results in Section 7.4 are suggestive
of the empirical potential of performing the two
tasks jointly, which we hope to explore in future
work.
One puzzling effect observed in our experi-
ments was the generally poor results for SVM. Er-
ror analysis indicates that the classifier was heav-
ily biased towards the high-frequency classes, e.g.
classifying all posts as either Q-Q or A-A for DA
classification. The classifications for the other two
learners were much more evenly spread across the
different classes.
CRF was limited in that it was unable to cap-
ture lexical features, but ultimately, lexical fea-
tures were found to be considerably less effec-
tive than structural and post context features for
both tasks, and the ability of the CRF to opti-
mise the post labelling over the full sequence of
posts in a thread more than compensated for this
shortcoming. Having said this, there is more work
to be done exploring synergies between the dif-
ferent feature sets, especially for DA classifica-
tion where all feature sets were found to produce
above-baseline results.
Another possible direction for future research is
to explore the impact of inter-post time on link
structure, based on the observation that follow-
up posts from the initiator tend to be tempo-
rally adjacent to posts they respond to with rela-
tively short time intervals, while posts from non-
initiators which are well spaced out tend not to re-
spond to one another. Combining this with pro-
filing of the cross-thread behaviour of individual
forum participants (Weimer et al, 2007; Lui and
Baldwin, 2009), and formal modelling of ?forum
behaviour? is also a promising line of research,
taking the lead from the work of Go?tz et al (2009),
inter alia.
9 Conclusion
In this work, we have proposed a method for
analysing post-to-post discourse structure in on-
line user forum data, in the form of post link-
ing and dialogue act tagging. We introduced
three feature sets: structural features, post con-
text features and semantic features. We exper-
imented with three learners (maximum entropy,
SVM-HMM and CRF), and established that CRF
is the superior approach to the task, achieving
above-baseline results for both post and link clas-
sification. We also demonstrated the complemen-
tarity of the proposed feature sets, especially for
the post classification task, and carried out a pre-
liminary exploration of the interaction between the
linking and dialogue act tagging tasks.
Acknowledgements
This research was supported in part by funding
from Microsoft Research Asia.
References
Jeremy Ang, Yang Liu, and Elizabeth Shriberg. 2005.
Automatic dialog act segmentation and classifica-
200
tion in multiparty meetings. In Proceedings of
the 2005 IEEE International Conference on Acous-
tics, Speech, and Signal Processing (ICASSP 2005),
pages 1061?1064, Philadelphia, USA.
Timothy Baldwin, David Martinez, Richard Penman,
Su Nam Kim, Marco Lui, Li Wang, and Andrew
MacKinlay. to appear. Intelligent Linux informa-
tion access by data mining: the ILIAD project. In
Proceedings of the NAACL 2010 Workshop on Com-
putational Linguistics in a World of Social Media:
#SocialMedia, Los Angeles, USA.
Susan Bartlett, Grzegorz Kondrak, and Colin Cherry.
2009. On the syllabification of phonemes. In Pro-
ceedings of the North American Chapter of the As-
sociation for Computational Linguistics ? Human
Language Technologies 2009 (NAACL HLT 2009),
pages 308?316, Boulder, USA.
Xin Cao, Gao Cong, Bin Cui, Christian S. Jensen, and
Ce Zhang. 2009. The use of categorization infor-
mation in language models for question retrieval. In
Proceedings of the 18th ACM Conference on Infor-
mation and Knowledge Management (CIKM 2009),
pages 265?274, Hong Kong, China.
Lynn Carlson, Daniel Marcu, and Mary Ellen
Okurowski. 2001. Building a discourse-tagged
corpus in the framework of rhetorical structure the-
ory. In Proceedings of the Second SIGdial Work-
shop on Discourse and Dialogue, pages 1?10, Aal-
borg, Denmark. Association for Computational Lin-
guistics Morristown, NJ, USA.
Vitor R. Carvalho and William W. Cohen. 2005. On
the collective classification of email ?speech acts?.
In Proceedings of 28th International ACM-SIGIR
Conference on Research and Development in Infor-
mation Retrieval (SIGIR 2005), pages 345?352.
William W. Cohen, Vitor R. Carvalho, and Tom M.
Mitchell. 2004. Learning to classify email into
?speech acts?. In Proceedings of the 2004 Con-
ference on Empirical Methods in Natural Lan-
guage Processing (EMNLP 2004), pages 309?316,
Barcelona, Spain.
Gao Cong, Long Wang, Chin-Yew Lin, Young-In
Song, and Yueheng Sun. 2008. Finding question-
answer pairs from online forums. In Proceedings of
31st International ACM-SIGIR Conference on Re-
search and Development in Information Retrieval
(SIGIR?08), pages 467?474, Singapore.
Shilin Ding, Gao Cong, Chin-Yew Lin, and Xiaoyan
Zhu. 2008. Using conditional random fields to ex-
tract context and answers of questions from online
forums. In Proceedings of the 46th Annual Meet-
ing of the ACL: HLT (ACL 2008), pages 710?718,
Columbus, USA.
Jonathan L. Elsas and Jaime G. Carbonell. 2009. It
pays to be picky: An evaluation of thread retrieval
in online forums. In Proceedings of 32nd Inter-
national ACM-SIGIR Conference on Research and
Development in Information Retrieval (SIGIR?09),
pages 714?715, Boston, USA.
Jonathan L. Elsas, Jaime Arguello, Jamie Callan, and
Jaime G. Carbonell. 2008. Retrieval and feed-
back models for blog feed search. In Proceedings of
31st International ACM-SIGIR Conference on Re-
search and Development in Information Retrieval
(SIGIR?08), pages 347?354, Singapore.
Micha Elsner and Eugene Charniak. 2008. You talk-
ing to me? a corpus and algorithm for conversation
disentanglement. In Proceedings of the 46th Annual
Meeting of the ACL: HLT (ACL 2008), pages 834?
842, Columbus, USA.
Michaela Go?tz, Jure Leskovec, Mary McGlohon, and
Christos Faloutsos. 2009. Modeling blog dynamics.
In Proceedings of the Third International Confer-
ence on Weblogs and Social Media (ICWSM 2009),
pages 26?33, San Jose, USA.
Barbara J. Grosz and Candace L. Sidner. 1986. Atten-
tion, intention and the structure of discourse. Com-
putational Linguistics, 12(3):175?204.
Edward Ivanovic. 2008. Automatic instant messaging
dialogue using statistical models and dialogue acts.
Master?s thesis, University of Melbourne.
Gang Ji and Jeff Bilmes. 2005. Dialog act tag-
ging using graphical models. In Proceedings of
the 2005 IEEE International Conference on Acous-
tics, Speech, and Signal Processing (ICASSP 2005),
pages 33?36, Philadelphia, USA.
Thorsten Joachims, Thomas Finley, and Chun-
Nam John Yu. 2009. Cutting-plane training of
structural SVMs. Machine Learning, 77(1):27?59.
Andrew Lampert, Robert Dale, and Ce?cile Paris.
2008. The nature of requests and commitments in
email messages. In Proceedings of the AAAI 2008
Workshop on Enhanced Messaging, pages 42?47,
Chicago, USA.
Oliver Lemon, Alex Gruenstein, and Stanley Pe-
ters. 2002. Collaborative activities and multi-
tasking in dialogue systems. Traitement Automa-
tique des Langues (TAL), Special Issue on Dialogue,
43(2):131?154.
Chen Lin, Jiang-Ming Yang, Rui Cai, Xin-Jing Wang,
Wei Wang, and Lei Zhang. 2009. Modeling se-
mantics and structure of discussion threads. In Pro-
ceedings of the 18th International Conference on the
World Wide Web (WWW 2009), pages 1103?1104,
Madrid, Spain.
Marco Lui and Timothy Baldwin. 2009. You are what
you post: User-level features in threaded discourse.
In Proceedings of the Fourteenth Australasian Doc-
ument Computing Symposium (ADCS 2009), Syd-
ney, Australia.
201
Guido Minnen, John Carroll, and Darren Pearce. 2001.
Applied morphological processing of English. Nat-
ural Language Engineering, 7(3):207?223.
Gabriel Murray, Steve Renals, Jean Carletta, and Jo-
hanna Moore. 2006. Incorporating speaker and dis-
course features into speech summarization. In Pro-
ceedings of the Main Conference on Human Lan-
guage Technology Conference of the North Amer-
ican Chapter of the Association of Computational
Linguistics, pages 367?374.
Klaus Ries. 1999. HMM and neural network
based speech act detection. In Proceedings of the
1999 IEEE International Conference on Acoustics,
Speech, and Signal Processing (ICASSP-99), pages
497?500, Phoenix, USA.
Carolyn Penstein Rose?, Barbara Di Eugenio, Lori S.
Levin, and Carol Van Ess-Dykema. 1995.
Discourse processing of dialogues with multiple
threads. In Proceedings of the 33rd Annual Meet-
ing of the Association for Computational Linguis-
tics, pages 31?38, Cambridge, USA.
Ken Samuel, Carbeery Sandra Carberry, and K. Vijay-
Shanker. 1998. Dialogue act tagging with
transformation-based learning. In Proceedings of
the 36th Annual Meeting of the ACL and 17th In-
ternational Conference on Computational Linguis-
tics (COLING/ACL-98), pages 1150?1156, Mon-
treal, Canada.
Anne Schuth, Maarten Marx, and Maarten de Rijke.
2007. Extracting the discussion structure in com-
ments on news-articles. In Proceedings of the 9th
Annual ACM International Workshop on Web Infor-
mation and Data Management, pages 97?104, Lis-
boa, Portugal.
Jangwon Seo, W. Bruce Croft, and David A. Smith.
2009. Online community search using thread struc-
ture. In Proceedings of the 18th ACM Conference
on Information and Knowledge Management (CIKM
2009), pages 1907?1910, Hong Kong, China.
Riccardo Serafin and Barbara Di Eugenio. 2004.
FLSA: Extending latent semantic analysis with fea-
tures for dialogue act classification. In Proceedings
of the 42nd Annual Meeting of the Association for
Computational Linguistics (ACL 2004), pages 692?
699, Barcelona, Spain.
Fei Sha and Fernando Pereira. 2003. Shallow pars-
ing with conditional random fields. In Proceedings
of the 3rd International Conference on Human Lan-
guage Technology Research and 4th Annual Meeting
of the NAACL (HLT-NAACL 2003), pages 213?220,
Edmonton, Canada.
Lokesh Shrestha and Kathleen McKeown. 2004. De-
tection of question-answer pairs in email conver-
sations. In Proceedings of the 20th International
Conference on Computational Linguistics (COLING
2004), pages 889?895, Geneva, Switzerland.
Elinzabeth Shriberg, Raj Dhillon, Sonali Bhagat,
Jeremy Ang, and Hannah Carvey. 2004. The ICSI
meeting recorder dialog act (MRDA) corpus. In
Proceedings of the 5th SIGdial Workshop on Dis-
course and Dialogue, pages 97?100, Cambridge,
USA.
Andreas Stolcke, Klaus Ries, Noah Coccaro, Eliz-
abeth Shriberg, Rebecca Bates, Daniel Jurafsky,
Pail Taylor, Rachel Martin, Carol Van Ess-Dykema,
and Marie Meteer. 2000. Dialogue Act Mod-
eling for Automatic Tagging and Recognition of
Conversational Speech. Computational Linguistics,
26(3):339?373.
Yi-ChiaWang, Mahesh Joshi, and Carolyn Rose?. 2007.
A feature based approach to leveraging context for
classifying newsgroup style discussion segments. In
Proceedings of the 45th Annual Meeting of the As-
sociation for Computational Linguistics Companion
Volume Proceedings of the Demo and Poster Ses-
sions (ACL 2007), pages 73?76, Prague, Czech Re-
public.
Yi-Chia Wang, Mahesh Joshi, William W. Cohen, and
Carolyn Rose?. 2008. Recovering implicit thread
structure in newsgroup style conversations. In Pro-
ceedings of the Second International Conference on
Weblogs and Social Media (ICWSM 2008), pages
152?160, Seattle, USA.
Markus Weimer, Iryna Gurevych, and Max
Mu?hlha?user. 2007. Automatically assessing
the post quality in online discussions on software.
In Proceedings of the 45th Annual Meeting of
the ACL: Interactive Poster and Demonstration
Sessions, pages 125?128, Prague, Czech Republic.
Florian Wolf and Edward Gibson. 2005. Representing
discourse coherence: A corpus-based study. Com-
putational Linguistics, 31(2):249?287.
Wensi Xi, Jesper Lind, and Eric Brill. 2004. Learning
effective ranking functions for newsgroup search.
In Proceedings of 27th International ACM-SIGIR
Conference on Research and Development in In-
formation Retrieval (SIGIR 2004), pages 394?401.
Sheffield, UK.
Alexander Yeh. 2000. More accurate tests for the sta-
tistical significance of result differences. In Pro-
ceedings of the 18th International Conference on
Computational Linguistics (COLING 2000), pages
947?953, Saarbru?cken, Germany.
Hai Zhao, Chang-Ning Huang, and Mu Li. 2006. An
improved Chinese word segmentation system with
conditional random field. In Proceedings of the Fifth
SIGHAN Workshop on Chinese Language Process-
ing, pages 162?165. Sydney, Australia.
202
