Representation and Treatment of Multiword Expressions in Basque 
I?aki Alegria, Olatz Ansa, Xabier Artola 
Nerea Ezeiza, Koldo Gojenola and Ruben Urizar 
Ixa Group 
University of the Basque Country 
649 pk E-20.080 
Donostia. Basque Country 
rubenu@sc.ehu.es 
Abstract 
This paper describes the representation of 
Basque Multiword Lexical Units and the 
automatic processing of Multiword 
Expressions. After discussing and stating 
which kind of multiword expressions we 
consider to be processed at the current 
stage of the work, we present the 
representation schema of the 
corresponding lexical units in a general-
purpose lexical database. Due to its 
expressive power, the schema can deal 
not only with fixed expressions but also 
with morphosyntactically flexible 
constructions. It also allows us to 
lemmatize word combinations as a unit 
and yet to parse the components 
individually if necessary. Moreover, we 
describe HABIL, a tool for the automatic 
processing of these expressions, and we 
give some evaluation results. This work 
must be placed in a general framework of 
written Basque processing tools, which 
currently ranges from the tokenization 
and segmentation of single words up to 
the syntactic tagging of general texts. 
1 Introduction 
2 
Most texts are rich in multiword expressions, 
which must be necessarily processed if we want 
any NLP tool to perform accurately. Jackendoff 
(1997) estimates that their number in the speakers' 
lexicon ?is of the same order of magnitude as the 
number of single words?. 
There is no agreement among authors about the 
definition of the term Multiword Expression. 
However, in this article, Multiword Expressions 
(hereafter MWE) refer to any word combinations 
ranging from idioms, over proper names, 
compounds, lexical and grammatical 
collocations? to institutionalized phrases. MWEs 
comprise both semantically compositional and 
non-compositional combinations, and both 
syntactically regular and idiosyncratic phrases, 
including complex named entities such as proper 
nouns, dates and number expressions (see section 
2). 
In contrast, Multiword Lexical Units (hereafter 
MWLU) comprise lexicalized phrases ?
semantically non-compositional or syntactically 
idiosyncratic word combinations? which are 
represented and stored in the lexical database of 
Basque (EDBL). 
The remaining sections are organized as 
follows. Section 2 presents the main features of 
MWEs in Basque, and defines which are currently 
considered for automatic processing. Section 3 
describes the representation of MWLUs in the 
lexical database. Section 4 is devoted to the 
description and evaluation of the automatic 
treatment of MWEs by means of HABIL. Section 
5 summarizes future work. And, finally, section 6 
outlines some conclusions. 
Multiword Expressions in the 
processing of real texts in Basque 
The definition of the term Multiword Expression 
and the types of such MWEs to be treated in NLP 
may vary considerably depending on the purposes 
or "the depth of processing being undertaken" 
(Copestake et al, 2002). Multiword itself is a 
Second ACL Workshop on Multiword Expressions: Integrating Processing, July 2004, pp. 48-55
vague term. At text level, a word could be defined 
as "any string of characters between two blanks" 
(Fontenelle et al, 1994). This is not applicable to 
languages as Japanese, which are typically written 
without spaces. Besides, a great number of MWEs 
that in uninflected languages would be multiword, 
constitute a single typographic unit in agglutinative 
languages such as Basque (ziurrenik 'most 
probably', aurrerantzean 'from now on', aurretiaz 
'in advance'). Therefore, we consider them single 
words and they are included in the lexical database 
as such (or recognized by means of morphological 
analysis). 
In our case, when deciding which Basque 
MWEs to include in the database, we mostly rely 
on lexicographers' expertise since we consider 
lexicalized phrases have a top priority for both 
lemmatizing and syntactic purposes. So, the 
MWEs dealt with in the database comprise fixed 
expressions, which admit no morphosyntactic or 
internal modification ?including foreign 
expressions such as in situ, a priori, strictu sensu, 
etc.?, idioms, both decomposable and non-
decomposable, and lexicalized compounds. We 
also consider light verb constructions when they 
are syntactically idiosyncratic.  
However, currently we do not treat open 
collocations, proverbs, catch phrases and similes. 
Mostly, we don't include proper names in the 
database either, since complex named entities are 
given a separate treatment. Apart from proper 
nouns, also dates and number expressions are 
treated separately (see 4.1). 
So far we have described 2,270 MWLUs in our 
database. This work has been carried out in two 
phases. For the first phase, we made use of the 
Statistical Corpus of 20th Century Basque 
(http://www.euskaracorpusa.net) that contains 
about 4.7 million words. As a starting point, we 
chose the MWLUs that occurred more than 10 
times in this manually lemmatized corpus. This 
amounted to about 1,300 expressions. For the 
second phase, this list has been enlarged using the 
Hiztegi Batua, a dictionary of standard Basque that 
the Basque Language Academy updates regularly 
(http://www2.euskaltzaindia.net/hiztegibatua). 
2.1 
3 
Main features of lexicalized phrases 
Many of the lexicalized phrases are semantically 
non-compositional (or partially compositional), i.e. 
they can hardly be interpreted in terms of the 
meaning of their constituents (adarra jo 'to pull 
someone's leg', literally 'to play the horn'). 
Often, a component of these sequences hardly 
occurs in any other context and it is difficult to 
assign it a part of speech. For example, the word 
noizik is an archaism of modern noiztik 'from 
when', which occurs just in the expressions noizik 
behin, noizik behinean, noizik noizera, and noizik 
behinka all meaning 'once in a while'. Besides, it is 
not clear which is the part of speech of the words 
laprast in laprast egin 'to slip' or dir-dir in dir-dir 
egin 'to shine'. 
From a syntactic point of view, many of these 
MWEs present an unusual structure. For example, 
many complex verbs in Basque are light verb 
constructions, being the meaning of the compound 
quite compositional, e.g. lo egin 'to sleep' literally 
'to make (a) sleep' or lan egin 'to work' literally 'to 
make (a) work'. However, lo egin and lan egin can 
be considered 'syntactically idiomatic' since the 
nouns in these expressions, lo and lan, take no 
determiner, which would be completely 
ungrammatical for a noun functioning as a regular 
direct object (*arroz jan nuen 'I ate rice'). 
Morphosyntactic flexibility, being significant in 
this type of constructions in Basque, may vary 
considerably. For example in lo egin 'to sleep' the 
noun lo admits modification (lo asko egin zuen 'he 
slept very much') and may take the partitive 
assignment (ez dut lorik egin 'I haven't slept') while 
the verb egin can be subject to focalization (egin 
duzu lorik bart? 'did you sleep at all last night?'); 
besides, the components of the construction may 
change positions and some elements and phrases 
may be placed between them (mendian egin omen 
zuen lasai lo 'it is said that he slept peacefully in 
the mountain'). In contrast, alde egin 'to escape' is 
morphosyntactically quite rigid. In all the cases, 
the verb egin can take any inflection. 
For our database, we have worked out a single 
representation that covers all MWLUs ranging 
from fixed expressions to these of highest 
morphosyntactic flexibility. 
Representation of MWLUs in the lexical 
database 
In this section we explain how MWLUs are 
represented in EDBL (Aldezabal et al, 2001), a 
lexical database oriented to language processing 
that currently contains more than 80,000 entries, 
out of which 2,270 are MWLUs. Among these: 
? ~69% are always unambiguous. The average 
number of Surface Realization Schemas 
(SRS, see section 3.2) is 1.02. 
? ~23% are sometimes unambiguous and have 
3.6 SRSs in average, half of them 
ambiguous. 
? ~8% are always ambiguous and have 1.2 
SRSs in average. 
We want to point out that almost all of the 
unambiguous MWLUs have only one SRS, their 
components appearing in contiguous positions and 
always in the same order. About half of them are 
inflected, so, even if we discard the interpretations 
of the components, there is still some 
morphosyntactic ambiguity left. However, the 
identification of these MWLUs helps in 
disambiguation, as the input of tagging is more 
precise. 
 
The description of MWLUs within a general-
purpose lexical database must include, at least, two 
aspects (see Figure 1): (1) their composition, i.e. 
which the components of the MWLU are, whether 
each of them can be inflected or not, and according 
to which one-word lexical unit (OWLU 1 ) it 
inflects; and (2), what we call the surface 
realization, that is, the order in which the 
components may occur in the text, the mandatory 
or optional contiguousness of components, and the 
inflectional restrictions applicable to each one of 
the components. 
3.1 
                                                          
Composition 
As it has just been said, the description of the 
composition of MWLUs in EDBL gathers two 
aspects: on the one side, it depicts which the 
individual components of a MWLU are; on the 
other side, it links the inflectable components of a 
MWLU to the corresponding OWLU according to 
which each of them inflects. 
In Figure 1, we can see that the composed of 
relationship links every MWLU to up to 9 
individual components (MWLU_Components). 
Each component is characterized by the following 
attributes: 
1 We consider OWLUs lexical units with no spaces within its 
orthographical form; so, we also take hyphenated compounds 
as OWLUs. 
? Component_Position: this indicates 
the position of the component word-form in 
the canonical form of the MWLU. 
? Component_Form: i.e. the word-form 
itself as it appears in the canonical form of 
the MWLU. 
? Conveys_Morph_Info?: this is a 
Boolean value, indicating whether the 
component inflection conveys the 
morphological information corresponding to 
the whole MWLU or not2. 
(0,n)
(1,1)
(1,1)
(1,n)
(2,9)
(1,1)
 
MWLUs
Surface_Realization_Schemas
Order_Contiguousness
Sureness
Inflection_Restrictions
MWLU_Components
Component_Position
Component_Form
Conveys_Morph_Info?
OWLUs
corresp.
SR schemas
inflects
according to
composed of
Figure 1. Composition and surface realization of 
MWLUs. 
Moreover, the components of a MWLU are 
linked to its corresponding OWLU (according to 
which it inflects). This is represented by means of 
the inflects according to relationship 
(see Figure 1). 
                                                          
2 The morphological information that the attribute refers to is 
the set of morphological features the inflection takes in the 
current component instance. 
These two aspects concerning the composition 
of a MWLU are physically stored in a single table 
of the relational database in which EDBL resides.  
The columns of the table are the following: 
Entry, Homograph_Id, Component_ 
Position, Component_Form, Conveys_ 
Morph_Info?, OWLU_Entry, and OWLU_ 
Homograph_Id. In the example below, the 
composition of the MWLU begi bistan egon 'to be 
evident' is described. Note that one row is used per 
component: 
<begi bistan egon, 0, 1, begi, -, begi, 2> 
<begi bistan egon, 0, 2, bistan, -, bista, 1> 
<begi bistan egon, 0, 3, egon, +, egon, 1> 
This expression allows different realizations 
such as begi bistan dago 'it is evident' (literally 'it 
is at reach of the eyes'), begi bistan daude 'they are 
evident', begien bistan egon, 'to be evident', etc. In 
the table rows above, it can be seen that the last 
component egon 1 'to be' conveys the 
morphological information for the whole MWLU 
(+ in the corresponding column). 
3.2 Surface realization 
As for surface realization, we have already 
mentioned that the components of a MWLU can 
occur in a text either contiguously or dispersed. 
Besides, the order of the constituents may be fixed 
or not, and they may either inflect or occur in an 
invariable form. In the case of inflected 
components, some of them may accept any 
inflection according to its corresponding OWLU, 
whilst others may only inflect in a restricted way. 
Moreover, some MWLUs are unambiguous and 
some are not, since it cannot be certainly assured 
that the very same sequence of words in a text 
corresponds undoubtedly to a multiword entry in 
every context. For example, in the sentence Emilek 
buruaz baiezko keinu bat egin zuen 'Emile nodded 
his head' the words bat and egin do not correspond 
to the complex verb bat egin 'to unite' but to two 
separate phrases. 
According to these features, we use a formal 
description where different realization patterns 
may be defined for each MWLU. The corresp. 
SR schemas relationship in Figure 1 links every 
MWLU to one or more Surface_Realiza-
tion_Schemas. Each SRS is characterized by 
the following attributes: 
? Order_Contiguousness: an expression 
that indicates both the order in which the 
components may appear in the different 
instances of the MWLU and the 
contiguousness of these components. In 
these expressions the position of the digits 
indicate the position each component takes 
in a particular SRS, * indicates that 0 or 
more words may occur between two 
components, and ? indicates that at most 
one single word may appear between two 
given components of the MWLU. 
? Unambiguousness: a Boolean value, 
indicating whether the particular SRS 
corresponds to an unambiguous MWLU or 
not. It expresses whether the sequence of 
words matching this SRS must be 
unambiguously analyzed as an instance of 
the MWLU or, on the contrary, may be 
analyzed as separate OWLUs in some 
contexts. 
? Inflection_Restrictions: an 
expression that indicates the inflection 
paradigm according to which the MWLU 
may inflect in this specific SRS. In these 
expressions each component of the MWLU 
is represented by one list component (in the 
same order as the components of the 
MWLU appear in its canonical form): % 
indicates that the whole inflection paradigm 
of the corresponding inflectable component 
may occur; the minus sign (-) is used for 
non-inflectable components (no inflection at 
all may occur); finally, a logical expression 
(and, or, and not are allowed) composed 
of attribute-value pairs is used to express the 
inflectional restrictions and the 
morphotactics the component undergoes in 
this particular SRS of the MWLU (in 
brackets in the examples below). 
In the examples below, it can be seen that one 
row is used per SRS. The columns of the table are 
the following: Entry, Homograph_Id, Or-
der_Contiguousness, Unambiguousness, 
and Inflection_Restrictions: 
<begi bistan egon, 0, 123, +, 
 (((CAS=ABS) and (DEF=-)) or 
  ((CAS=GEN) and (NUM=PL)), -, %)> 
<begi bistan egon, 0, 312, +, 
 (((CAS=ABS) and (DEF=-)) or 
  ((CAS=GEN) and (NUM=PL)), -, %)> 
<begi bistan egon, 0, 3?12, +, 
 (((CAS=ABS) and (DEF=-)), -, %)> 
 
The first SRS matches occurrences such as begi 
bistan dago hau ez dela aski 'it is evident that it is 
not enough' or begien bistan zegoen honela 
bukatuko genuela 'it was evident that we would 
end up this way', where the components are 
contiguous and the analysis as an instance of the 
MWLU would be unambiguous. This SRS allows 
the inflection of the first component as absolutive 
case (non-definite) or as genitive (plural), and the 
whole set of inflection morphemes of the third one. 
The third SRS matches occurrences such as ez 
dago horren begi bistan 'it is not so evident', where 
the components are not contiguous (at most one 
word is allowed between the ?third? component 
and the ?first one?) and they occur in a non-
canonical order: 3?12. In this case, the 
interpretation as an instance of the MWLU would 
also be unambiguous. However, this SRS only 
allows the inflection of the first component as 
absolutive case (non-definite). 
3.3 
4 
Different information requirements in 
lemmatization and syntax processing 
The first prototype for the treatment of MWEs in 
Basque HABIL (Ezeiza et al, 1998; Ezeiza, 2003) 
was built for lemmatization purposes. However, 
we are nowadays involved in the construction of a 
deep syntactic parser (Aduriz et al, 2004) and the 
MWEs seem to need a different treatment. The fact 
that many MWEs may be syntactically regular but, 
above all, that an external element may have a 
dependency relation with one of the constituents, 
forces us to analyze the elements independently. 
For example, in the verb beldur izan 'to be afraid 
(of)' an external noun phrase may have a modifier-
noun dependency relation with beldur 'fear' as in 
sugeen beldur naiz 'I'm afraid of snakes'. In loak 
hartu 'to fall asleep' there is a subject-verb relation 
as in loak hartu nau 'I have fallen asleep', literally 
'sleep has caught me'; therefore subject-auxiliary 
verb agreement would fade if both components 
were analyzed as one. 
The MWLU representation we have adopted 
allows us to lemmatize the word combination as a 
unit and yet to parse the components individually 
whenever necessary. In order to do so, when 
describing each MWLU, we specify whether the 
elements in the MWLU must be analyzed 
separately or not3. 
Treatment of multiword expressions 
MWEs could be treated at different stages of the 
language process. Some approaches treat them at 
tokenization stage, identifying fixed phrases, such 
as prepositional phrases or compounds, included in 
a list (Carmona et al, 1998; Karlsson et al, 1995). 
Other approaches rely on morphological analysis 
to better identify the features of the MWE using 
finite state technology (Breidt et al, 1996). 
Finally, there is another approach that identifies 
them after the tagging process, allowing the 
correction of some tagging errors (Leech et al, 
1994). 
All of these approaches are based on the use of 
a closed set of MWLUs that could be included in a 
list or a database. However, some groups of MWEs 
are not subject to be included in a database, 
because they comprise an open class of 
expressions. That is the case of collocations, 
compounds or named entities. The group of 
collocations and compounds should be delimited 
using statistical approaches, such as Xtract 
(Smadja, 1993) or LocalMax (Silva et al, 1999), 
so that only the most relevant?those of higher 
frequency? are included in the database.  
Named entity recognition task has been solved 
for a large set of languages. Most of these works 
are linked to the Message Understanding 
Conference (Chinchor, 1997). There is a variety of 
methods that have been used in NE recognition, 
such as HMM, Maximum Entropy Models, 
Decision Trees, Boosting and Voted Perceptron 
(Collins, 2002), Syntactic Structure based 
approaches and WordNet-based approaches 
(Magnini et al, 2002; Ar?valo, 2002). Most 
references on NE task might be accessed at 
http://www.muc.saic.com. 
4.1 
                                                          
Processing MWEs with HABIL 
We have implemented HABIL, a tool for the 
treatment of multiword expressions (MWE), based 
3  Currently we are studying the MWLUs in the lexical 
database in order to determine which of them deserve to be 
parsed as separate elements. We have not defined yet how this 
will be formally represented in the database. 
on the features described in the lexical database. 
The most important features of HABIL are the 
following: 
? It deals with both contiguous and split 
MWEs. 
? It takes into account all the possible orders 
of the components (SRS). 
? It checks that inflectional restrictions are 
complied with. 
? It generates morphosyntactic interpretations 
for the MWE. 
This tool has two different components: on the 
one hand, there is a searching engine that identifies 
MWEs along the text, and, on the other hand, there 
is a morphosyntactic processor that assigns the 
corresponding interpretations to the components of 
the MWE. 
The morphosyntactic processor generates the 
interpretations for MWEs using category and 
subcategory information in the lexical database. 
When one of the components adds information to 
the MWE, the processor applies pattern-matching 
techniques to extract the corresponding 
morphological features of the analyses of that 
component, and these features are included in the 
interpretation of the MWE. Then, it replaces all the 
morphosyntactic interpretations of the components 
of unambiguous MWEs with the MWE 
interpretations. When MWEs are ambiguous, the 
new interpretations are added to the existing ones. 
HABIL also identifies and treats dates and 
numerical expressions. As they make up an open 
class, they are not obviously included in the lexical 
database. Furthermore, their components are 
always contiguous, have a very strict structure, and 
use a closed lexicon. Thus, it is quite easy to 
identify them using simple finite state transducers. 
For the morphosyntactic treatment of dates and 
numerical expressions, we use the morphosyntactic 
component of HABIL. These expressions may 
appear inflected and, in this case, the last 
component adds morphosyntactic features to the 
MWE. Finally, as they are unambiguous 
expressions, the processor discards the 
interpretations of the components and assigns them 
all the interpretations of the whole expression. 
4.2 Evaluation 
We performed several experiments using 650 
unambiguous, contiguous and ordered MWEs. We 
treated a reference corpus of around 36,000 tokens 
and there were 386 instances of 149 different 
MWEs. We also applied this process to a small test 
corpus of around 7,100 tokens in which there were 
87 instances of 45 MWEs. Taking both corpora 
into account, there were 473 instances of 167 
different MWEs, which amounted to 25% of the 
expressions considered, and 50% of the instances 
were ambiguous. Besides, only 14 dates and 12 
numerical expressions were found in the reference 
corpus, and 18 dates and 9 numerical expressions 
in the test corpus. 
 
  Ambiguity 
Rate 
Interpretations 
per Token 
Recall
word-
forms: 
before
after 
81.78% 
79.83% 
3.37 
3.30 
99.31%
99.31%
all 
tokens: 
before
after 
67.47% 
65.86% 
2.96 
2.89 
99.43%
99.43%
Table 1. Results of HABIL. 
The ambiguity measures of the test corpus are 
shown in Table 1. The ambiguity rate of word-
forms decreases by 2% and the average ambiguity 
rate by 1.5% after the processing of MWEs. It is 
important to point out that no error is made along 
the process. Furthermore, some important MWEs, 
more specifically, some complex sentence 
connectors that have highly ambiguous 
components, are correctly disambiguated. 
Bearing in mind the proportion of words treated 
by HABIL, these results help significantly in 
improving precision results of tagging and 
avoiding almost 10% of the errors, as shown in 
Table 2.  
 
 Precision Error 
before MWE processing 94.96% 5.04% 
after MWE processing 95.42% 4.58% 
Table 2. Tagging results. 
5 Future work 
After confirming the viability of the system and the 
good results in POS tagging, our main goal is to 
increase the number of MWLUs in the database, 
which will improve the identification of MWEs in 
corpora. 
A remaining difficulty that we are facing is the 
problem of ambiguous split MWEs. At present, we 
are creating a disambiguation grammar that will 
discard or select the multiword interpretations in 
ambiguous MWLUs. We are developing similar 
rules using both the Constraint Grammar 
formalism and finite state transducers (XFST tools, 
Kartunnen et al 1997). The very first rules seem to 
be quite effective. Soon, we will be assessing the 
first results, and then we will be able to choose the 
method that performs best with a lesser effort. 
Once we have chosen the best formalism, we 
intend to develop a comprehensive grammar that 
will disambiguate as many ambiguous MWLUs as 
possible. 
In addition, we are developing new processes 
after POS tagging in order to identify complex 
named entities and terminological units. These 
units constitute an open class and so their 
exhaustive inclusion in a database would not be 
viable. 
6 Conclusion 
7 
In this paper we have described a whole 
framework for the representation and treatment of 
MWEs, which is being currently used at the IXA 
Research Group to process this kind of expressions 
in general texts. Although it has been conceived 
and so far used for Basque, a highly inflected 
language, we think that it is general enough to be 
applied to other languages. 
A general representation schema for MWLUs at 
the lexical level has been proposed. This schema 
allows us to state which components a MWLU has 
and to formally encode all the different surface 
realizations it can adopt in the text. 
The problems that diverse information require-
ments in lemmatization and syntactic processing 
can eventually pose have been explained, and a 
possible solution for the representation of these 
phenomena has also been outlined. 
As for the processing aspects, we have 
described HABIL, the tool for the treatment of 
MWEs. HABIL processes MWEs based on their 
description in the lexical database, dealing also 
with some types of open class MWEs. 
One of the remaining problems when split and 
ambiguous MWEs are to be tagged is related with 
disambiguation procedures using Hidden Markov 
Models, which are not able to manage different 
paths with variable lengths. This problem can be 
solved using rule-based methods or lattice 
structures for tagging. 
Acknowledgements 
This research is being partially funded by the 
European Commission (MEANING project, IST-
2001-34460) and the Basque Government 
(Etortek-Hizking, Saiotek-Ihardetsi). 
References 
Aduriz I., Aranzabe M., Arriola J., D?az de Ilarraza A., 
Gojenola K., Oronoz M., Uria L. 2004. A cascaded 
syntactic analyser for Basque. Fifth International 
Conference on Intelligence Text Processing and 
Computational Linguistics (CICLing2004). Seoul, 
Korea. 
Aldezabal I., Ansa O., Arrieta B., Artola X., Ezeiza N., 
Hern?ndez G., Lersundi M. 2001. EDBL: a General 
Lexical Basis for the Automatic Processing of 
Basque. IRCS Workshop on Linguistic Databases. 
Philadelphia. 
Ar?valo M. 2002. MICE, un recurso para la resoluci?n 
de la an?fora. International Workshop on 
Computational Linguistics. http://www.lsi.upc.es/ 
~nlp/iwcl02. 
Breidt E., Segond F., Valetto G. 1996. Local grammars 
for the description of multi-word lexemes and their 
automatic recognition in texts. Proceedings of 
COMPLEX'96, 19-28. Budapest. 
Carmona J., Cervell S., M?rquez L., Mart? M.A., Padr? 
L., Placer R., Rodr?guez H., Taul? M., Turmo J. 
1998. An environment for morphosyntactic 
processing of unrestricted Spanish text. Proceedings 
of LREC'98. 915-922. 
Chinchor N. 1997. MUC-7 Named Entity Task 
Definition. Version 3.5. http://www.itl.nist.gov/iaui/ 
894.02/related_projects/muc/  
Collins M. 2002. Ranking Algorithms for Named-Entity 
Extraction: Boosting and the Voted Percetron. 
Proceedings of ACL-2002. 
Collins M., Singer Y. 1999. Unsupervised Models for 
Named Entity Classification. Proceedings of the 
Joint Conference on Empirical Methods in Natural 
Language Processing and Workshop on Very Large 
Corpora (EMNLP-VLC-99). 
Copestake A., Lambean F., Villavicencio A., Bond F., 
Baldwin T., Sag I., Flickinger D. 2002. Multiword 
Expressions: linguistic precision and reusability. 
Proceedings of the Third International Conference 
on Language Resources and Evaluation (LREC 
2002), Las Palmas, pp. 1941-7. 
Ezeiza N. 2003. Corpusak ustiatzeko tresna 
linguistikoak. Euskararen etiketatzaile sintaktiko 
sendo eta malgua. PhD thesis, University of the 
Basque Country. 
Ezeiza N., Aduriz I., Alegria I., Arriola J.M., Urizar R.  
1998. Combining Stochastic and Rule-Based 
Methods for Disambiguation in Agglutinative 
Languages. COLING-ACL'98, Montreal (Canada). 
Fontenelle T., Adriaens G., De Braekeleer G. 1994. The 
Lexical Unit in the Metal? MT System, MT. The 
Netherlands. v9. 1-19. 
Jackendoff R. 1997. The Architecture of the Language 
Faculty. Cambridge, MA MIT Press. 
Karlsson F., Voutilainen A., Heikkila J,. Anttila A. 
1995. Constraint Grammar: A Language-
independent System for Parsing Unrestricted Text. 
Mouton de Gruyter. 
Karttunen L., Chanod J-P., Grefenstette G., Schiller A. 
1997. Regular expressions for language engineering. 
Natural Language Engineering, Cambridge 
University Press. 
Leech G., Garside R., Bryan M. 1994. CLAWS4: The 
tagging of the British National Corpus. Proceedings 
of COLING-94, 622-628. 
Magnini B., Negri M., Prevete R., Tanev H. 2002. A 
WordNet Approach to Named Entities Recognition. 
Proceeding of the Workshop SemaNet'02: Binding 
and Using Semantic Networks. 
Silva J., Dias G., Guillor? S., Lopes G. 1999. Using 
localmaxs algorithm for the extraction of contiguous 
and non-contiguous multiword lexical units. 
Proceedings of 9th Portuguese Conference in 
Artificial Inteligence, 21-24. 
Smadja F. 1993. Retrieving Collocations from Text: 
Xtract. Computational Linguistics, 19(1), 143-177. 
Named Entities Translation Based on Comparable Corpora
In?aki Alegria
IXA NLP Group
EHU
Donostia, Basque Country
i.alegria@ehu.es
Nerea Ezeiza
IXA NLP Group
EHU
Donostia, Basque Country
n.ezeiza@ehu.es
Izaskun Fernandez
IXA NLP Group
EHU
Donostia, Basque Country
acbfegoi@si.ehu.es
Abstract
In this paper we present a system for
translating named entities from Basque
to Spanish based on comparable corpora.
For that purpose we have tried two ap-
proaches: one based on Basque linguis-
tic features, and a language-independent
tool. For both tools we have used Basque-
Spanish comparable corpora, a bilingual
dictionary and the web as resources.
1 Introduction
Person, location and organization names, main
types of named entities (NEs), are expressions
commonly used in all kinds of written texts. Re-
cently, these expressions have become indispens-
able units of information for many applications
in the area of information extraction as well as
for many searching engines. A lot of tools that
deal with the identification and classification of
named entities for a specific language have been
presented (CoNLL1). But there are few researches
for translation of NEs.
Our main goal is to get a multilingual NE data-
base, which can be very useful for translation
systems, multilingual information extraction tools
(i.e. Question Answering) or many multilingual
systems in general. As getting that multilingual
source is a complex task, we have started design-
ing a system for translating named entities from
Basque to Spanish based on comparable corpora.
Looking at the works published on NE trans-
lation, we can distinguish 3 types of systems: the
systems more often used are the ones based on par-
allel corpora; then the ones based on comparable
1http://www.cnts.ua.ac.be/conll2003/ner/
corpora; and finally the ones that only use the web
as an open corpus.
As we have mentioned before, most of the re-
lated works use parallel corpora. However and as
it is widely known, obtaining parallel corpus is not
an easy task, and it becomes harder when one of
the languages in the pair is a minority language,
as is the case of Basque. We can avoid working
with parallel corpora using comparable corpora.
Comparable corpora are those data sets which are
written in different languages, treat similar sub-
jects and are written in a similar style, but are not
necessarily texts? translations. Obtaining that kind
of corpora is much easier than obtaining parallel
one, although sometimes it is not possible to get
neither of them. In this case, we can use the web
as a multilingual corpus, in order to search it for
any possible entity translation.
We have a comparable data set available for
Basque and Spanish. But besides using that data
source, we decided also to resort to the web as a
complementary data set too, as in (Moore, 2003).
Apart from these two data sets, we have also
used some other information sources to develop
the Basque-Spanish bilingual NE translation sys-
tem. We have carried out two main different ex-
periments: one using a language-dependent gram-
mar, implementing transliteration transformations
(Al-Onaizan et al, 2002b) and rules related to
elements? order; and another one based on the
edition distance (Kukich, 1992) grammar, sim-
ulating simple cognates and transliteration trans-
formations, but in a language-independent way.
In both experiments, we have used a Basque-
Spanish bilingual dictionary for the words in
which transliteration transformations were not
enough to obtain the correct translated form.
Furthermore, we have always worked using
1
Basque as source language, and Spanish as target
language.
Since Basque and Spanish do not follow the
same syntactic pattern, entity elements may occur
in different positions in both languages. That is
why the elements need to be arranged when trans-
lating Basque entities into Spanish.
The paper is structured as follows. Section 2
presents the related works. Section 3 presents
the experimental settings. In section 4 we de-
scribe the development of NE translation system
explaining both possible systems, the language-
dependent system and the language-independent
one, and the system that combines both language-
dependent and independent sources. In section 5,
we present the results of the experiments, and fi-
nally, section 6 presents some conclusions and fu-
ture works.
2 Related Works
Despite the difficulty of getting bilingual parallel
corpus, most of the NE translation researches car-
ried out work with parallel data-sets. Furthermore,
those bilingual corpora are used to be aligned at
paragraph or even at phrase level. For example,
Moore?s work (Moore, 2003) uses a bilingual
parallel aligned English-French corpora, and ap-
plying different statistical techniques, he obtains a
French form for each English entity.
Although it has been less experimented with
comparable corpora there are some known sys-
tems designed to work with them as well. Most
of them deal with language pairs that have dif-
ferent kinds of alphabets. For instance, the
Chinese-English translation tool presented in ACL
2003 (Chen et al, 2003), or the one published
in the ACL 2002 edition for translating entity
names from Arabic to English (Al-Onaizan et
al., 2002a). The main goal of both systems is to
obtain the corresponding form for English, tak-
ing Chinese and Arabic respectively as source lan-
guages. Two kinds of translations can be distin-
guished in both systems: direct/simple translations
and transliterations (Al-Onaizan et al, 2002b).
However, the techniques used by each tool for
both kinds of translations are different. Frequency
based methods are used in Chinese-English trans-
lations, while in the Arabic-English language pair,
a more complex process is applied, which involves
the combination of different kinds of techniques.
In this paper, we present the research carried
out for translating entity names from Basque into
Spanish. For the first step, we have based on the
system presented by Y. Al Onaizan and K. Knight
in ACL 2002. With this system, they first obtain
a candidate translation list for the entity in the tar-
get language, using both monolingual and bilin-
gual resources. Once they have this list, they build
a ranking with candidates applying different meth-
ods (such as statistical measures, web-counting,
etc.). Finally, if they consider that the correct
translation does not appear in the list, they extract
an extended list version using the web and they
apply again the ranking step.
3 Experimental settings
We have obtained a Basque-Spanish comparable
corpora processing news from two newspapers,
one for each language: Euskaldunon Egunkaria,
the only newspaper written entirely in Basque for
Basque texts, and EFE for Spanish texts. We have
collected the articles written in the 2002 year in
both newspapers and we have obtained 40,648 ar-
ticles with 9,655,559 words for Basque and 16,914
with 5,192,567 words for Spanish. Both newspa-
pers deal with similar topics: international news,
sports, politics, economy, culture, local issues and
opinion articles, but with different scope.
In order to extract Basque NEs, we have used
Eihera (Alegria et al, 2003), a Basque NE rec-
ognizer developed in the IXA Group. Giving a
written text in Basque as input, this tool applies
a grammar based on linguistic features in order
to identify the entities in the text. For the clas-
sification of the identified expressions, we use a
heuristic that combines both internal and external
evidence. We labeled this corpus for the HER-
MES project2(news databases: cross-lingual infor-
mation retrieval and semantic extraction). Thus,
we obtained automatically 142,464 different per-
son, location and organization names.
Since we have participated at the HERMES
project, we have available labeled corpora for the
other languages processed by other participants. It
was the TALP3 research group the one that was in
charge of labeling EFE 2002 newspaper?s articles
for the Spanish version, in which 106,473 differ-
ent named entities were dealt with. We have built
the comparable corpus using this data-set together
with the Basque set mentioned above.
2http://nlp.uned.es/hermes/
3http://www.lsi.upc.edu/ nlp/web/
2
Being Basque an agglutinative language, entity
elements may contain more than just lexical infor-
mation. So before doing any translation attempt
a morphosyntactic analysis is required in order to
obtain all the information from each element. Fur-
thermore, Eihera works on a lemmatized text, so
lematizing the input text is a strong requirement.
For that purpose, we apply the lemmatizer/tagger
for Basque (Alegria et al, 1998) developed by the
IXA group.
The goal of our system is to translate Basque
person, location and organization names into
Spanish entities. These two languages share a
lot of cognates, that is, words that are similar in
both languages and only have small, usually pre-
dictable spelling differences. Two experts have re-
viewed an extended list of word pairs4 extracted
from EDBL (Basque Lexical Data-base) in order
to detect these differences. All the observed varia-
tions have been listed in a spelling-rule list. These
rules are in fact the ones that will be applied for the
translation of some of the words, but obviously not
for all.
When translating Basque words into Spanish,
usually the correct form is not obtained by ap-
plying the rules mentioned before, and a different
strategy is required. For these words in particu-
lar, we have used bilingual dictionaries as in Al-
Onaizan and Knight?s work.
We have used the Elhuyar 2000 bilingual dic-
tionary, one of the most popular for that language
pair. This dictionary has 74,331 Basque entries,
and it contains the corresponding Spanish syn-
onyms.
For the evaluation, we have used a set of 180
named entity-pairs. We have borrowed that set
from the Euskaldunon Egunkaria 2002 newspaper.
Concretely we applied Eihera, the Basque NE rec-
ognizer, to extract all the named entities in the cor-
pus. Then we estimated the normalized frequency
of each entity in the corpus, and we selected the
most common ones. Finally we translated them
manually into Spanish.
In order to carry out an evaluation starting from
correct Basque NEs, although the NEs were au-
tomatically extracted from the corpus, we verified
that all the entities were correctly identified. Be-
cause if the original entity was not a correct ex-
pression, the translation system could not get a
4One expert has revised adjective and nouns in general,
while the other one has only treated proper noun pairs
correct translation.
4 Systems? Development
As we have mentioned before, we have done two
different experiments in order to get a Basque-
Spanish NE translation tool. For both trials we
have used bilingual dictionaries and grammars to
translate and transliterate entity elements, respec-
tively. But the methodologies used to implement
each transliteration grammar are different: on the
one hand, we have used Basque linguistic knowl-
edge to develop the grammar; on the other hand,
we have defined a language-independent grammar
based on edition distance.
Those dictionaries and grammars have been
used in order to obtain translation proposals for
each entity element. But another methodology is
needed for the system to propose the translation of
whole entities. For the system based on linguistic
information, a specific arranging rule set has been
applied getting a candidate list. In order to decide
which is the most suitable one, we have created a
ranked list based on a simple web count.
For the language-independent system a more
simple methodology has been applied. We have
generated all the possible candidate combinations,
considering that every element can appear at any
position in the entity. Then, a comparable corpus
has been used in order to decide which is the most
probable candidate.
Now we will present the design of each experi-
ment in detail.
4.1 Linguistic Tool
We can see the pseudo-code of the linguistic tool
at Figure 1.
Figure 1: Linguistic Tool
The linguistic tool, first tries to obtain a transla-
tion proposal for each entity element using bilin-
gual dictionaries. If no candidate is obtained from
3
that search, the transliteration grammar is applied.
Once the system has obtained at least one proposal
for each element, the arranging grammar is ap-
plied, and finally, the resultant entire entity pro-
posals are ranked based on their occurrence on the
web.
4.1.1 Transliteration
Reviewing the extended list of words from
EDBL (a Basque Lexical Data-base) we have ob-
tained 24 common phonologic/spelling transfor-
mations, some of which depend on others, and can
usually be used together, although not always. We
have implemented these 24 transformations using
the XFST (Beesley and Karttunen, 2003) tool and
we have defined 30 rules. These rules have been
ordered in such a way that rules with possible in-
teractions are firstly applied and then the rest of
them. This way we have avoided interaction prob-
lems.
For instance, lets say that we want to translate
Kolonbia into Colombia and that our grammar has
the following two simple transformation rules: nb
? mb and b ? v. If we apply the first rule and
then the second one, the candidate we will obtain
is Colomvia, and this is not the correct translation.
However, if we do not allow to apply the second
rule after the nb ? mb transformation, the gram-
mar will propose the following candidates: Colon-
via and Colombia. So it would generate bad forms
but the correct forms too.
We can conclude from this fact that it is neces-
sary to apply the rules in a given order.
The possible combinations of rules are so wide
that it causes an overgeneration of candidates. To
avoid working with such a big number of can-
didates in the following steps, we have decided
to rank and select candidates using some kind of
measure.
We have estimated rules probabilities using the
bilingual dictionary Elhuyar 2000. We have sim-
ply apply all possible rule combinations on every
Basque word in the dictionary, and measured the
normalized frequency of each rule and each rule
pair. Thus, translation proposals are attached a
probability based on the probability of a rule be-
ing applied, and only the most probable ones are
proposed for the following steps.
4.1.2 Entire Entity Construction
At this point, we have N translation candidates
for each input entity element at the most, and they
have been obtained applying the grammar or from
the dictionary search. Our next goal is to create
entire entity translation proposals combining all
these candidates. But some words features, such
as gender and number, must be considered and
treated beforehand.
The number of an entity element will be re-
flected in the whole entity. Let?s say, for instance,
translate the organization name Nazio Batuak5.
The translation proposals from the previous mod-
ules for these two words are Nacio?n (for Nazio)
and Unida (for Batuak). If we do not consider that
the corresponding Basque word of the Unida ele-
ment is in the plural form, then the whole transla-
tion candidate will not be correct. In this case, we
will need to pluralize the corresponding Spanish
words.
Unlike Spanish, Basque has no morphological
gender. This means that for some Basque words
the generation of both male and female form is re-
quired. The word idazkari, for example, has no
morphological gender, and it has two correspond-
ing Spanish words: the masculine secretario and
the feminine secretaria. If we search for idazkari
on the bilingual dictionary, we will only obtain the
masculine form, but the feminine form is needed
for some entities , as it is the case with Janet Reno
Idazkaria6 . Since Janet Reno is a woman?s proper
name, the correct translation of Idazkaria would
be Secretaria. So before constructing the entire
entity translation, both male and female forms
have been generated for each element.
The simplest entities to construct are the ones
whose elements keep the same order in both the
Basque and the Spanish forms. Person names usu-
ally follow this pattern.
However, there are some translations that are
not as regular and easy to translate as the pre-
vious ones. Suppose that we want to translate
the Basque entity Lomeko Bake Akordio7 into the
Spanish form Acuerdo de Paz de Lome. After ap-
plying grammar and bilingual dictionaries, we ob-
tain the following translated elements (in order to
simplify the explanation, we have assumed that the
system will only return one translation candidate
per element): Lome Acuerdo and Paz. As you can
see, if we do not arrange those elements, the pro-
posal will not be the appropriate Spanish transla-
5United Nations
6Secretary Janet Reno
7Lome Peace Agreement
4
tion.
An expert?s manual work has been carried out in
order to define the element arranging needed when
turning from one language to the other. The mor-
phosyntactic information of the Basque entity el-
ements (such as PoS, declension, and so on) has
been used in this task.
Using this manual work, we have defined 10
element-arranging rules using the XFST tool. In
the example above, it is clear that some element-
arranging rules are needed in order to obtain the
correct translation. Let?s see how our grammar?s
rules arranges those elements.
When the system starts arranging the Lome
Acuerdo and Paz Spanish words to get the correct
translation for the Basque named entity Lomeko
Bake Akordio it starts from the right to the left us-
ing the Basque elements? morphosyntactic infor-
mation. So it will start arranging the translated
elements for Bake Akordio from right to left. Both
forms are common nouns with no declension case.
Looking at the grammar the system will find a rule
for this structure that switches position of the el-
ements and inserts the preposition de in between.
So the partial translation would be Acuerdo de Paz.
The next step is to find the correct position for the
translation of Lomeko, which is a location name
declined in genitive. There is a rule in the gram-
mar, that places the elements declined in genitive
at the end of the partial entity and adds the preposi-
tion de before this element. So, the system will ap-
ply that rule, obtaining the Spanish translation of
the whole entity Acuerdo de Paz de Lome, which
is the correct form.
4.1.3 Web Search
As we have explained, we combine at the most
the N translation candidates per entity elements
with each other using the corresponding arrang-
ing rule to get the translation of the whole entity.
So, at the most we will obtain NxN entity transla-
tion proposals. In order to know which candidate
is the correct one, the tool makes a web search, but
as the number of candidates is so high, we use the
same candidate selection technique applied previ-
ously for element selection.
This time we will use elements probability in or-
der to obtain a measured proposal list. The x can-
didates with the highest probability are searched
and ranked in a final candidate list of translated
entities.
In our experiments, we have used the Google
API to consult the web. Searching entities in
Google has the advantage of getting the most com-
mon forms for entities in any type of document.
But if you prefer to get a higher precision (rather
than a good recall), you can obtain a higher cer-
tainty rate by making a specialized search in the
web. For those specialized searches we have used
Wikipedia, a free encyclopedia written collabora-
tively by many of its readers in many languages.
4.2 Language Independent Tool
Since creating transformation rules for every lan-
guage pairs is not always a viable task, we have de-
signed a general transformation grammar, which
fits well for most language pairs that use the same
alphabetical system. All we need is a written cor-
pus for each language and a bilingual dictionary.
Figure 2: Language Independent Tool
We have constructed a NE translation tool based
on comparable corpora using that general gram-
mar. As you can see in Figure 2, the system
finds Basque translation proposals for entity ele-
ments applying the pseudo-transliteration module.
Once it gets at least one translation candidate for
each element, it applies the whole entity construc-
tion module obtaining all the possible whole entity
candidates. Finally, it searches each candidate in
the corresponding comparable corpus and returns
a ranked candidate list based on that search, in or-
der to obtain the correct translation form.
4.2.1 Pseudo-transliteration module
The pseudo-transliteration module has two
main sources: an edition distance (Kukich, 1992)
grammar and a Spanish lexicon.
The edition distance grammar is composed of
three main rules:
1. a character can be replaced in a word
2. a character can disappear from a word
3. a new character can be inserted in a word
5
There is no specific rule in the grammar for
switching adjacent characters, because we can
simulate that transformation just combining the
deleting and inserting rules mentioned above.
Since each rule can be applied n times for each
word, the set of all translated words that we ob-
tain, applying rules independently and combining
them, is too extent.
In order to reduce the output proposal-set, we
have combined the grammar with a Spanish lex-
icon, and we have restricted the transformation
rules to two applications. So words with more than
two transformations have been avoided. Thus,
when the system applies the resultant automa-
ton of this combination, only the Spanish words
that can be obtained with a maximum of two
transformations would be proposed as pseudo-
transliterations of a Basque entity element.
The Spanish lexicon has been constructed with
all the words of EFE 2002 (the Spanish corpus of
the 2002 year) and the bilingual dictionary Elhu-
yar 2000. And as we have considered this cor-
pus as a comparable corpus with regard to the Eu-
skaldunon Egunkaria 2002, Basque corpus ver-
sion, we assume that most of the Basque words
would have their corresponding translation in the
Spanish set.
However, there are some words that do not
have their corresponding translation at EFE 2002,
or their translation cannot be obtained applying
only two transformations. In order to obtain
their translations in a different way, we have used
the Basque-Spanish Elhuyar 2000 bilingual dic-
tionary. To be precise, we have converted the
bilingual dictionary into an automaton, and we
combined it with the resultant automaton obtained
from applying the transliteration grammar in the
Spanish lexicon.
In this way the system is able to translate not
only the transliterated words in EFE 2002 corpus,
but also, the words that cannot be translated us-
ing transformation knowledge and that need infor-
mation from a bilingual dictionary, such as ?Er-
akunde? vs. ?Organizacio?n?8 .
4.2.2 Entire Entity Construction
Since we want to build a language independent
system that works just having two different lan-
guage data-sets, we cannot use any linguistic fea-
ture for arranging entity elements and getting the
8Organization
correct whole translated entity.
We might use many approaches to arrange ele-
ments, but we have chosen the simplest one: com-
bining each proposed element with the rest, con-
sidering that each proposal can appear in any po-
sition within the entity. Thus, the system will re-
turn a large list of candidates, but we have ensured
that it will include the correct one, when the in-
dependent translation of all the elements has been
correctly done.
Although in some cases prepositions and arti-
cles are needed to obtain the correct Spanish form,
the translation candidates for the whole entity will
not contain any element apart from the translated
words of the original entity. So, in the following
step the lack of these elements will be taken into
account.
4.2.3 Comparable Corpus Search
Once the system has calculated all possible
translation candidates for the whole entity , the
following step is to select the most suitable pro-
posal. For that purpose, we have used the web in
the linguistic tool. But this time, we have made
used of the data-set in the Spanish-news articles,
in which entities were tagged. This set is smaller
and permits faster searching; furthermore, since
Basque and Spanish-sets are comparable, the cor-
rect translation form is expected to occur in this
smaller corpus, so it is very probable that the sys-
tem will propose us the right translation.
Therefore, every translation proposal will be
searched in the Spanish data-set and will be po-
sitioned at the ranked list according to their fre-
quency. Thus, the most repeated entities in the
corpus would appear on the top of the list.
4.2.4 Combining web and comparable corpus
rankings
Both Euskaldunon Egunkaria 2002 and EFE
2002 data-sets are 2002 year news-sets, and a lot
of named entities are due to occur in both sets. But
since they are articles taken from newspaper of
different countries, there may be some non-shared
named entities.
When the system finds these special entities in
the Spanish comparable corpus, it is very probable
that it will find none of the candidates, and so, the
list will not be arranged.
To avoid that random list ranking, when all
translation candidates have a very low frequency,
we propose to use the web to do a better rank-
6
ing. As we will present below, this optional second
ranking step improves final results.
5 Experiments
As we have mentioned before, we have first ex-
tracted a set of 180 person, location and organi-
zation name-pairs from Euskaldunon Egunkaria
2002 newspaper and then we have translated them
manually.
We have used three evaluation measures to
present the result of all the experiments:
? Precision = correctly translated NEsTranslated NEs
? Recall = correctly translated NEsAll NEs
? F ? score = 2?Precision?RecallPrecision+Recall
For the evaluation of the linguistic tool, we have
used a parameter (x in the tables) which deter-
mines how many translation candidates will be
used in each module at the most. This threshold is
necessary since the output of both transliteration
and arranging grammar is too big to work with in
the next modules.
The fr-min parameter in the tables specifies how
often a candidate must occur in a data-set to be
considered a likely NE translation proposal.
fr. min ? x Precision Recall F-score
10 ? 1 73.96% 69.44% 71.63%
100 ? 1 75.75% 69.44% 72.25%
250 ? 1 78.71% 67.77% 72.83%
500 ? 1 79.86% 61.66% 69.59%
10 ? 3 79.29% 74.44% 76.79%
100 ? 3 80.6% 73.88% 77.09%
250 ? 3 83.87% 72.22% 77.61%
500 ? 3 83.45% 64.4% 72.7%
10 ? 10 79.88% 75% 77.36%
100 ? 10 81.21% 74.44% 77.68%
250 ? 10 84.52% 72.78% 78.21%
500 ? 10 84.17% 65% 73.35%
Table 1: Linguistic knowledge + Google
Table 1 presents the results obtained applying
the linguistic tool, and searching its proposals in
Google. If we observe these results taking into
account the values of the x parameter, it seems
that the bigger the x value is, the better results we
get. But note that the best improvement is obtained
when we use the maximum of 3 candidate instead
of using just 1. We improved the system perfor-
mance in 5%. While using 10 candidates, the per-
formance increases in less than 1% compared to
the results obtained when x value is 3.
Regarding to the fr-min parameter, it seems that
the best value is around 250. Moreover, duplicat-
ing this value, performance decreases. So we can
say that when fr-min value exceeds 250, the sys-
tem performs worse.
For next comparatives, we will take the re-
sults given by the experiments using the values fr-
min=250 and x=1 as reference.
When we search Wikipedia instead of Google
(see Table 2), the system?s recall decreases from
69.44% to 66.67%. This time the only search-
ing restriction is that the candidate occurs at least
once, and not n times. This is because the data-set
offered by Wikipedia is significantly smaller than
the one given by Google. Moreover, precision re-
mains similar. So although it is a smaller data-set,
Wikipedia seems to be similar to Google as far as
the information significance of terms is concerned.
fr. min ? x Precision Recall F-score
1 ? 1 81.63% 66.67% 73.4%
1 ? 3 83.67% 68.33% 75.23%
1 ? 10 84.35% 68.88% 75.83%
Table 2: Linguistic knowledge + Wikipedia
When we use the comparable corpus instead of
the web, the linguistic tool performs a consider-
able enhancement in precision, a 13% improve-
ment, but gets worse coverage. On the other hand,
the language-independent tool achieves similar re-
sults with regard to the linguistic tool searching
in the web. So the language-independent tool
seems to be a good alternative for dealing with NE
translation without no exhaustive linguistic work.
Those results are detailed in Table 3.
System Precision Recall F-score
Ling. Tool 91.85% 68.8% 78.67%
Lang. Indep. 83.3% 72.2% 77.35%
Table 3: Results using comparable corpus
Finally, we have tried searching the proposals
from the linguistic tool first in the comparable
corpus. When no successful candidate is found
in it, the system tries searching the web, in both
Google and Wikipedia (See Table 4). In both ex-
periments, precision is significantly lower than the
one obtained when the system proposes candidates
found in the comparable corpus, without no fur-
ther search. However, the coverage increases in al-
most 5% in the trials carried out both with Google
and Wikipedia. Therefore, the system?s F-score
7
remains similar. Note that this time instead of per-
forming better when Google is used, the searches
done in Wikipedia give better results. Further-
more, the best results are obtained when combin-
ing comparable corpus and Wikipedia searches in
the Linguistic tool.
Web search Precision Recall F-score
Google, 250 81.36% 73.3% 77.12%
Wikipedia, 1 84.21% 73.3% 78.38%
Table 4: Ling. Tool + Comp. corpus + Web search
6 Conclusions and Further Works
We have presented an approach for the design and
development of an entity translation system from
Basque to Spanish and the different techniques
and resources we have used for this work.
On the one hand, we have combined bilingual
dictionaries with a phonologic/spelling grammar
for the entity elements? translation; on the other
hand, we have applied a language-independent
grammar based on edition distance. Both com-
binations perform well, and although the lin-
guistic tool obtains better results, the language-
independent grammar may be very useful for other
experiments carried out with language-pairs others
than Basque and Spanish.
Because of the differences of the syntactical
structures of Basque and Spanish, it is necessary to
arrange the entity elements for the correct transla-
tion of whole NEs; in particular, for those entities
with more than one element. For that purpose, we
have used two different techniques: probabilistic
rules and a simple combination method (all candi-
dates combined with all).
Finally, we have applied different resources and
techniques for the selection of the best candidates.
On the one hand, we have tried searching the web
(Google and Wikipedia); on the other hand, we
have used a comparable Basque-Spanish corpus.
We have verified, that although Google is a bigger
data-set, the significance of the information for NE
translation task is similar to the information given
by Wikipedia.
All the experiments carried out with compara-
ble corpus have performed very well, and the best
results have been obtained when combining it with
Wikipedia. So developing a NE translation system
based on comparable information have proved to
be a good way to build a robust system.
However, some modules can be improved.
Firstly, the methods to rank and select candidates
are very simple, so if we use more complex ones,
the number of candidates for the following mod-
ules would decrease considerably, and so, the sys-
tem?s final selection would be easier and more pre-
cise.
Regarding to the use of the web, actually we
have only used Google and Wikipedia. Searches
in Wikipedia are more precise than the ones made
in Google and so the information they offer can
be considered complementary. Furthermore, we
can obtain very valuable information for other en-
tity processes. For instance, since Wikipedia is
a topic-classified encyclopedia, when you do an
entity search, you can get information about the
kind of documents in which the entity can occur;
in other words, which is the most usual topic for
it to occur in. Besides, that classification category
can be very useful for entity disambiguation too.
With all the improvements presented so far, we
hope to get a stronger entity name translation sys-
tem in the future.
References
Aduriz I., Alegria I., Arriola J.M., Ezeiza N., Urizar R.
1998. Combining Stochastic and Rule-Based Meth-
ods for Disambiguation in Agglutinative Languages.
Proceedings of COLING-ACL?98.
Alegria I., Balza I., Ezeiza N., Fernandez I., Urizar R.
2003. Named Entity Recognition and Classification
for texts in Basque. Proceedings of JOTRI II.
Al-Onaizan Y., Knight K. 2002. Translating
Named Entities Using Monolingual and Bilingual
Resources. Proceedings of ACL 2002.
Al-Onaizan Y., Knight K. 2002. Machine Translitera-
tion of Names in Arabic Text. Proceedings of ACL
2002.
Beesley K.R., Karttunen L. 2003. Finite State Mor-
phology. CSLI
Chen H., Yang C., Lin Y. 2003. Learning Formulation
and Transformation Rules for Multilingual Named
Entities. Proceedings of the ACL 2003 Workshop
on Multilingual and Mixed-language Named Entity
Recognition.
Kukich K., 1992. Techniques for automatically cor-
recting word in text. ACM Computing Surveys Vol.
24 No. 4 377-439
Moore R. C., 2003. Learning Translations of Named-
Entity Phrases from Parallel Corpora. Proceedings
of EACL 2003.
8
Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically Rich Languages, pages 71?77,
Seattle, Washington, USA, 18 October 2013. c?2013 Association for Computational Linguistics
Exploiting the Contribution of Morphological Information to Parsing: the
BASQUE TEAM system in the SPRML?2013 Shared Task
Iakes Goenaga, Nerea Ezeiza
IXA NLP Group
Faculty of Computer Science
Univ. of the Basque Country UPV/EHU
iakesg@gmail.com, n.ezeiza@ehu.es
Koldo Gojenola
IXA NLP Group
Technical School of Engineering, Bilbao
Univ. of the Basque Country UPV/EHU
koldo.gojenola@ehu.es
Abstract
This paper presents a dependency parsing
system, presented as BASQUE TEAM at
the SPMRL?2013 Shared Task, based on
the analysis of each morphological feature
of the languages. Once the specific rel-
evance of each morphological feature is
calculated, this system uses the most sig-
nificant of them to create a series of ana-
lyzers using two freely available and state
of the art dependency parsers, MaltParser
and Mate. Finally, the system will com-
bine previously achieved parses using a
voting approach.
1 Introduction
Morphologically rich languages present new chal-
lenges, as the use of state of the art parsers for
more configurational and non-inflected languages
like English does not reach similar performance
levels in languages like Basque, Greek or Turk-
ish (Nivre et al, 2007). Using morphological in-
formation as features in parsing has been a com-
monly used method for parsing MRLs (Tsarfaty et
al., 2010). In some cases the effect of this infor-
mation is positive but in others it does not help or
causes a negative effect.
In most of the work on dependency parsing, the
specific relevance of each morphological feature
in the final result is unknown. The authors include
all the morphological features1 in their systems
with the aim of taking advantage of the diversity
of the used information. This approach commonly
produces very good results but they are not always
the best ones (see table 2).
On the other hand, some authors have made ex-
periments to specify which is the real impact of
1That is, they treat all the morphological features in the
same way in the feature specification, and let the learning
algorithms decide the weight assigned to each one.
the morphological features. Ambati et al (2010)
explore ways of integrating local morphosyntactic
features into Hindi dependency parsing. They ex-
periment with different sets of features on a graph-
based and a transition-based dependency parser.
They show that using some morphological fea-
tures (root, case, and suffix) outperforms a base-
line using POS as the only feature, with both gold
and predicted settings .
Bengoetxea and Gojenola (2010) make use of
MaltParser?s feature configuration file to take ad-
vantage of morphological features in parsing with
gold data. Their experiments show that case and
subordination type considerably increase parsing
accuracy.
Marton et al (2013) also explore which mor-
phological features could be useful in dependency
parsing of Arabic. They observe the effect of fea-
tures by adding them one at a time separately and
comparing the outcomes. Experiments showed
that when gold morphology is provided, case
markers help the most, whereas when the mor-
phology is automatically predicted the outcome
is the opposite: using case harms the results the
most. When features are combined in a greedy
heuristic, using definiteness, person, number, and
gender information improves accuracy.
Similarly, Seeker and Kuhn (2013) also deter-
mine that the use of case is specially relevant for
parsing, demonstrating that morpho-syntactic con-
straints can delimit the search space of a statistical
dependency parser to outperform state-of-the-art
baselines for Czech, German and Hungarian.
Following this line of research, our first step
will be to determine which is the concrete value of
each feature on dependency parsing, adding one of
the morphological features at a time starting with
an empty FEATS column.
C?etinog?lu and Kuhn (2013) have shown that
some parsers tend to improve the results when
swapping or replacing POS by some of the mor-
71
phological features. They have made use of the
METU-Sabanc Turkish Treebank (Oflazer et al,
2003) for training and the ITU validation set
(Eryigit, 2007) for testing. In their work, it is ob-
served that moving CASE to the POS field helps
with a 0.3% LAS absolute increase in the gold
pipeline settings and using CASE instead of nom-
inal POS improves the labelled accuracy by 0.3%
absolute for the training set.
These experiments suggest that in some way
the parser is not making an optimal use of all the
available morpho-syntactic information, and that
the parser algorithm (or the feature specification
for the learning phase) is geared towards POS and
CPOS, giving a lower status to other types of in-
formation. Although this strategy is good in gen-
eral, it seems that, at least for some languages, spe-
cific features (e.g. CASE) are crucial in obtaining
a high parsing performance. Taking these ideas
into consideration, we will work on three different
approaches:
? We will experiment the effect of using only
the best three morphological features in the
FEATS column (see table 1), compared to
working with the full set of morpho-syntactic
features. This can have the effect of speed-
ing the learning and parsing processes, as the
number of features can be smaller. On the
other hand, the elimination of non-relevant
features can also help to improve the parser?s
results, because some features can even be
detrimental for parsing.
? Following C?etinog?lu and Kuhn (2013), once
our system resolves which feature is the most
significant, it will be used to replace the POS
and CPOS fields one by one and we will test
the effect of these variants on the parsers. Fi-
nally, we will also try right-to-left versions
of those 3 variants (baseline, and replacing
POS and CPOS) completing a set of 6 differ-
ent parsers.
? Finally, we will experiment the combination
of the different or parsers with a voting ap-
proach (Hall et al, 2010) using the Malt-
Blender tool2.
All of the experiments will be performed on
automatically predicted POS and morphosyntactic
data, taking the tags given in the Shared Task data,
2http://w3.msi.vxu.se/users/jni/blend/
that is, we will not made use of any specifically
trained morphological tagger.
In the rest of this paper we will first present
the resources we have used to carry out our ex-
periments in section 2, followed by a study of the
contribution of the morphological information to
parsing in section 3 and the effect of this infor-
mation on the individual parsers in subsection 4.1.
The final results of the best parser combinations
are showed in subsection 4.2 and the main conclu-
sions of the work in section 5.
2 Resources
This section will describe the main resources that
have been used in the experiments. Subsection
2.1 will describe the languages we have used in
our experiments, subsection 2.2 will explain the
parsers we use, while subsection 2.3 will present
briefly the MaltBlender tool.
2.1 Selected Languages
Although the SPMRL?2013 Shared Task (Seddah
et al, 2013) offers the opportunity to parse nine
morphologically rich languages, to carry out our
experiments we have selected five of them, due in
part to time constraints, but also taking into ac-
count the relevance of the morpho-syntactic infor-
mation (FEATS column, see table 1) . The selected
five languages are: Basque (Aduriz et al, 2003),
French (Abeille? et al, 2003), German (Seeker and
Kuhn, 2012), Hungarian (Vincze et al, 2010) and
Swedish (Nivre et al, 2006).
2.2 Parsers
We have made use of MaltParser (Nivre et al,
2007b) and Mate (Bohnet and Nivre, 2012), two
state of the art dependency parsers3 representing
the dominant approaches in data-driven depen-
dency parsing, and that have been successfully
applied to typologically different languages and
treebanks.
MaltParser is a representative of local, greedy,
transition-based dependency parsing models,
where the parser obtains deterministically a
dependency tree in a single pass over the input
using two data structures: a stack of partially
analyzed items and the remaining input sequence.
To determine the best action at each step, the
3Due to time constraints, we did not have enough time to
experiment with other options such as the MST parser or the
EasyFirst parser.
72
parser uses history-based feature models and dis-
criminative machine learning. The specification
of the learning configuration can include any
kind of information (such as word-form, lemma,
category, subcategory or morphological features).
We will use one of its latest versions (MaltParser
version 1.7).
To fine-tune Maltparser we have used MaltOp-
timizer (Ballesteros and Nivre, 2012a; Ballesteros
and Nivre, 2012b). This tool is an interactive sys-
tem that first performs an analysis of the training
set in order to select a suitable starting point for
optimization and then guides the user through the
optimization of parsing algorithm, feature model,
and learning algorithm. Empirical evaluation on
data from the CoNLL 2006 and 2007 shared tasks
on dependency parsing shows that MaltOptimizer
consistently improves over the baseline of default
settings and sometimes even surpasses the result
of manual optimization.
The Mate parser (Bohnet and Nivre, 2012) is a
development of the algorithms described in (Car-
reras, 2007; Johansson and Nugues, 2008). It basi-
cally adopts the second order maximum spanning
tree dependency parsing algorithm. In particular,
this parser exploits a hash kernel, a new parallel
parsing and feature extraction algorithm that im-
proves accuracy as well as parsing speed (Bohnet,
2010).
2.3 Parser Combinations
The MaltBlender tool makes a two-stage optimiza-
tion of the result of several parser outcomes, based
on the work of Sagae and Lavie (2006), and it was
used for the first time for the ten languages in the
multilingual track of the CoNLL 2007 shared task
on dependency parsing(Hall et al, 2010). The first
stage consists in tuning several single-parser sys-
tems. The second stage consists in building an
ensemble system that will combine the different
parsers. When this system was evaluated on the
official test sets at the CoNLL 2007 shared task,
the ensemble system significantly outperformed
the single-parser system and achieved the highest
average labelled attachment score of all participat-
ing systems.
3 Contribution of Morphological
Information to Parsing
We examined the effect of each type of morpho-
logical information, contained in the FEATS col-
umn, to investigate their overall contribution to
parsing. This will help us to determine which are
the most relevant features for parsing. To carry out
this task we have used the Mate parser, due to lack
of time for testing, and also taking into consid-
eration that it gives better results than MaltParser
for all the languages?s baselines. Firstly, we will
obtain the baseline for each language parsing the
files with an empty FEATS column. This baseline
will help us to determine the contribution of each
morphological feature to parsing. Next, we trained
the parsers using one feature at a time obtaining as
many results as features for each language. Table
1 shows the effect of each information on the Mate
parser.
In this table we can observe that Basque is one
of the most sensitive languages regarding the influ-
ence of its features. Using case (KAS) as a unique
feature improves the labelled attachment score
over using an empty FEATS column by almost
5.7%. The next two better features are number
(NUM) and type of subordinate sentence (ERL).
They help with a 1.1% and 0.6% increase, respec-
tively. The rest of the features do not contribute
much in isolation, with a maximum of 0.2%. On
the other hand, including all the features results in
an improvement of 6.5%.
If we analyze the results for French we see that,
in contrast to Basque, the influence of the features
on the parser is minimum. The most significant
feature is gender (g), which helps with a 0.1% in-
crease. With respect to the improvement using the
other features, although they do not provide big in-
creases all of them contribute positively. In clos-
ing, including all the features we obtain a 84.6%
labelled attachment score with a 0.4% improve-
ment over not using any features.
As with French, the German morphological fea-
tures provide small increases. The most two sig-
nificant features are case and gender, which obtain
increases of 0.2%, 0.13%, respectively. It is inter-
esting to observe how including all the features we
obtain worse results than using only the case, al-
though the difference is not significant. That could
occur due to the weak influence of its features in
the final result and the negative influence of some
of them.
Hungarian is the language which offers more
features, 14 altogether. This language, in line with
Basque, tends to vary significantly its labelled at-
tachment score depending on the used morpholog-
73
Basque French German Hungarian Swedish
all feats 83.0 all feats 84.6 all feats 91.0 all feats 82.8 all feats 76.7
no feats 76.5 no feats 84.2 no feats 90.9 no feats 75.3 no feats 76.9
KAS 82.2 g 84.3 case 91.0 Cas 80.9 verbform 77.0
NUM 77.7 n 84.3 gender 91.0 PerP 76.3 definiteness 76.8
ERL 77.1 p 84.3 number 90.9 NumP 76.3 degree 76.8
DADUDIO 76.8 c 84.2 person 90.9 SubPOS 75.9 case 76.8
NORK 76.7 m 84.2 tense 90.9 Def 75.7 number 76.3
MDN 76.6 s 84.2 degree 90.8 Num 75.7 perfectform 76.3
NOR 76.6 t 84.2 mood 90.8 PerP 75.7 abbrv 76.3
ASP 76.4 Mood 75.5 mood 76.2
NORI 76.2 NumPd 75.4 pronounform 76.1
ADM 76.5 Coord 75.3 gender 76.0
Form 75.3
Tense 75.3
Type 75.3
Deg 75.0
Table 1: The effect of each feature sorted by language (MATE parser)
ical feature. If we focus on the three most signif-
icant features, the case (Cas) helps with a 5.6%
increase, person of possessor (PerP) with a 1%,
while number of possessor helps with a 0.9%. The
grammatical subcategory within the main part of
speech (SubPOS) improves the baseline in a 0.6%
and the number and person in a 0.4%. The remain-
ing features do not contribute very appreciatively
even obtaining negative results. Including all the
features we obtain a labelled attachment score of
82.83%. That means the real contribution of all
the features is 7.5%, this improvement being the
most important among all the used languages.
In common with French and German, the
Swedish morphological features do not seem to
help the parsers to achieve significant improve-
ments in terms of LAS. However, we can observe
some interesting phenomena. While in the other
languages the case is one of the best features, in
Swedish is does not help, achieving a negative re-
sult. In general, excluding the verb form (verb-
form), all the features obtain negative results with
respect to not using any feature. In this scenario
it is not surprising to verify that including all the
features does not help the Mate parser. Having
said this, the best three features are the verb form
(verbform), definiteness (definiteness) and degree
(degree).
4 Testing the Effect of Different
Morphosyntactic features on parsers
We examined the effect of the most significant
morphological features, examined in the previous
step, to investigate their overall contribution to
parsing. For this task, we created three variants for
each parser, apart from the baseline using all the
morphosyntactic features. We obtain these vari-
ants by: i) using the most 3 relevant features in
the FEATS column (see table 1 in previous sec-
tion), ii) moving the most relevant feature for each
language to the POS column and iii) moving the
most relevant feature to the CPOS column. Next,
we have tested parser combinations including all
the baselines and their variants in subsection 4.2.
4.1 Individual Parsers
Table 2 shows the effect of each information on
both parsers, Maltparser and Mate parser. If we
analyze the results on Basque, the difference be-
tween the two parsers is noticeable, as Mate ob-
tains on average a 3 point improvement with re-
spect to MaltParser. A similar difference occurs
on all the used languages. The best LAS in Basque
is acquired using the 3 best features in the FEATS
column with the Mate parser (83.4%). On a com-
parison with the LAS obtained by the Mate base-
line (All-Feats), that means a 0.4 improvement.
Regarding Maltparser?s results for Basque, we get
the best LAS (81.0%) moving the best feature
(case) to POS in its right-to-left version, increas-
ing the LAS baseline (All-Feats) by 1.0. We no-
tice that Maltparser and Mate tend to improve their
baseline scores using some of the presented vari-
ants.
On the other hand, the best score for French
is obtained using the baseline (All-Feats and
74
Basque French German Hungarian Swedish
Baselines
All ? FeatsMalt 80.0 79.9 87.6 77.3 73.4
All ? FeatsMate 83.0 84.6 91.0 82.3 76.7
Left2right
3? bestMalt 79.9 79.9 87.6 75.9 73.4
CPOS ? bestMalt 80.3 79.7 87.5 76.6 72.9
POS ? bestMalt 78.7 78.7 86.6 77.2 72.8
3? bestMate 83.4 84.3 90.8 82.4 76.6
CPOS ? bestMate 82.7 84.3 91.0 82.7 76.8
POS ? bestMate 82.2 83.4 90.5 82.5 76.5
Right2left
3? bestMalt 80.1 78.9 86.9 75.3 69.3
CPOS ? bestMalt 80.0 79.0 86.7 76.6 69.3
POS ? bestMalt 81.0 77.8 85.4 74.9 70.2
3? bestMate 83.3 84.3 90.9 82.1 76.5
CPOS ? bestMate 83.1 84.6 91.0 82.6 77.0
POS ? bestMate 81.6 83.5 90.6 82.4 76.4
Table 2: Testing the effect of features on MaltParser and Mate
the Mate parser, 84,6%). Contrary to Basque,
in French, although some of the used variants
achieve similar scores with respect to their base-
lines (All-Feats), they do not give noticeable in-
creases. The unique variant that equals its base-
line (79,9%) is 3? bestMalt using the left-to-right
version and the three best features (gender, num-
ber and person) in the FEATS column using Malt-
parser.
With respect to German, the only variant that
equals the baseline is CPOS ? bestMate with
91.0% LAS. . If we focus on Maltparser?s (Mal-
tOptimizer) scores, we get the best result among
the variants with 3 ? bestMalt (87.6%) using the
left-to-right version. The variants do not improve
Maltparser?s baseline.
Although some of the Hungarian variant scores
are very similar to their baselines, they give some
improvements over the baseline. The best two re-
sults on the Mate parser are 82.7% and 82.6%. We
obtain the first score moving the best feature (case)
to CPOS in its left-to-right version, and the second
one using the same configuration in its right-to-left
version. The best two scores on Maltparser with-
out taking the baseline into account are 77.2% and
76.6%, obtained when moving the best feature to
POS and moving the best feature to CPOS in its
right-to-left version, respectively.
The best two results for Swedish on the Mate
parser are 77.0% and 76.8%. We get the first re-
sult moving the best feature (verbform) to CPOS
in its right-to-left version and the second one in its
standard version. These two results are the only
variants that improve the baseline (76.7% LAS)
with a 0.30 and 0.17 increase, respectively. On the
other hand, if we focus on Maltparser, the variants
do not improve the baseline (73.4% LAS) where
the best two results are 73.4% and 72.9% LAS.
For the best result we use the three best features
(verbform, definiteness and degree) in the FEATS
column, while for the second one the best feature
(verbform) has been moved to CPOS.
Despite that only the Basque and Swedish vari-
ants haven been able to significantly improve their
baselines, in the next subsection we present a com-
bination system expecting to take advantage on the
variety of the parsed files (Surdeanu and Manning,
2010).
4.2 Parser Combinations
Although in several cases the use of specific mor-
phosyntactic information does not give noticeable
increases, we also tested the effect on parser com-
binations. Table 3 presents the result of combin-
ing the extended parsers with the baselines (us-
ing all the features) obtained in individual parsers.
The table shows that the Basque language has
achieved the biggest increase. Parser combination
in Basque helps with an improvement of 3.2 with
respect to the Mate baseline. Contrary to Basque,
French is the language that has obtained the small-
est increases in parser combination if we compare
it with the Mate (highest) parser baseline. The
combined system improves the Mate parser base-
75
Basque French German Hungarian Swedish
MaltParser baseline 80.0 79.9 87.6 77.3 73.4
Mate parser baseline 83.0 84.6 91.0 82.8 76.7
Parser combination 86.2 85.1 91.8 84.1 78.1
Table 3: Results of parser combinations
line by 0.5. Parser combination in German gives a
0.8 increase with respect to the best single parser
(Mate, 91.0). Our system achieves a 1.3 increase
for Hungarian with respect to the Mate parser?s
baseline. Finally, if we focus on Swedish, the
parser combination helps with a 1.4 increase with
respect to the Mate parser.
After examining the parsers involved in parser
combinations we noticed that there are always sev-
eral variants included in the best parser combina-
tions, although the only variant that appears in all
the best parser combinations is CPOS?bestMate
in its left-to-right version. Taking into account
that the most relevant feature for Basque, German
and Hungarian is the case, it would be interest-
ing to use the CPOS?caseMate variant for other
languages. Finally, the presented results suggest
that the introduced variants contribute positively
on parsing and they help to improve the scores ob-
tained by the base parsers.
5 Conclusion and Future Work
We have presented a combined system that was
designed after analyzing the relevance of the mor-
phological features in order to take advantage on
the effect of those features on some parsers. In
general the improvements have been noticeable,
specially for Basque. We can point out some in-
teresting avenues for research:
? Use of new parsing algorithms for testing
the effect of different morphological fea-
tures. The results of this work show that the
used techniques are specially useful for lan-
guages where the FEATS column, contain-
ing morpho-syntactic information, gives the
biggest increments with respect to not us-
ing the features, like Basque and Hungar-
ian. We expect that similar improvements
could be obtained for languages like Turkish
or Czech, which share many characteristics
with Basque and Hungarian.
? Experimenting different models for parser
combinations using new parsers. Several of
the parser variants we have used give only
slight modifications over the base algorithms,
even though when combined they give sig-
nificant increases. Widening the spectrum of
parsers and adding new algorithms can imply
an important boost in parser combination.
? Application to the rest of the languages of the
SPMRL 2013 Shared Task: Korean, Hebrew,
Arabic and Polish.
Acknowledgements
This research was supported by the Department of
Industry of the Basque Government (IT344-10, S
PE11UN114), the University of the Basque Coun-
try (GIU09/19) and the Spanish Ministry of Sci-
ence and Innovation (MICINN, TIN2010-20218).
References
Anne Abeille?, Lionel Cle?ment, and Franc?ois Toussenel.
2003. Building a treebank for french. In Anne
Abeille?, editor, Treebanks. Kluwer, Dordrecht.
I. Aduriz, M. J. Aranzabe, J. M. Arriola, A. Atutxa,
A. D??az de Ilarraza, A. Garmendia, and M. Oronoz.
2003. Construction of a Basque dependency tree-
bank. pages 201?204.
Bharat Ram Ambati, Samar Husain, Sambhav Jain,
Dipti Misra Sharma, and Rajeev Sangal. 2010. Two
methods to incorporate local morphosyntactic fea-
tures in hindi dependency parsing. In Proceedings of
the NAACL HLT 2010 First Workshop on Statistical
Parsing of Morphologically-Rich Languages, pages
22?30.
Miguel Ballesteros and Joakim Nivre. 2012a. Maltop-
timizer: A system for maltparser optimization. In
LREC, pages 2757?2763.
Miguel Ballesteros and Joakim Nivre. 2012b. Mal-
toptimizer: an optimization tool for maltparser. In
Proceedings of the Demonstrations at the 13th Con-
ference of the European Chaptr of the Association
for Computational Linguistics, pages 58?62.
Kepa Bengoetxea and Koldo Gojenola. 2010. Appli-
cation of different techniques to dependency pars-
ing of basque. In Proceedings of the NAACL
HLT 2010 First Workshop on Statistical Parsing of
Morphologically-Rich Languages, pages 31?39.
76
Bernd Bohnet and Joakim Nivre. 2012. A transition-
based system for joint part-of-speech tagging and la-
beled non-projective dependency parsing. In Pro-
ceedings of the 2012 Joint Conference on Empiri-
cal Methods in Natural Language Processing and
Computational Natural Language Learning, pages
1455?1465.
Bernd Bohnet. 2010. Very high accuracy and fast de-
pendency parsing is not a contradiction. In Proceed-
ings of the 23rd International Conference on Com-
putational Linguistics, pages 89?97.
Xavier Carreras. 2007. Experiments with a higher-
order projective dependency parser. In Proceed-
ings of the CoNLL Shared Task Session of EMNLP-
CoNLL 2007, Prague, Czech Republic, June.
O?zlem C?etinog?lu and Jonas Kuhn. 2013. Towards
joint morphological analysis and dependency pars-
ing of turkish. In Proceedings of the Second In-
ternational Conference on Dependency Linguistics
(DepLing 2013), pages 23?32, Prague, Czech Re-
public, August. Charles University in Prague, Mat-
fyzpress, Prague, Czech Republic.
Gu?lsen Eryigit. 2007. Itu validation set for metu-
sabanc? turkish treebank. URL: http://www3. itu.
edu. tr/ gulsenc/papers/validationset. pdf.
Johan Hall, Jens Nilsson, and Joakim Nivre. 2010.
Single malt or blended? a study in multilingual
parser optimization. In Trends in Parsing Technol-
ogy, pages 19?33. Springer.
Richard Johansson and Pierre Nugues. 2008.
Dependency-based syntactic-semantic analysis with
propbank and nombank. In Proceedings of the
Twelfth Conference on Computational Natural Lan-
guage Learning, pages 183?187.
Yuval Marton, Nizar Habash, and Owen Rambow.
2013. Dependency parsing of modern standard ara-
bic with lexical and inflectional features. Computa-
tional Linguistics, 39(1):161?194.
Joakim Nivre, Jens Nilsson, and Johan Hall. 2006. Tal-
banken05: A Swedish treebank with phrase struc-
ture and dependency annotation. In Proceedings of
LREC, pages 1392?1395, Genoa, Italy.
Joakim Nivre, Johan Hall, Sandra Ku?bler, Ryan Mc-
Donald, Jens Nilsson, Sebastian Riedel, and Deniz
Yuret. 2007. The CoNLL 2007 shared task
on dependency parsing. In Proceedings of the
CoNLL Shared Task Session of EMNLP-CoNLL
2007, Prague, Czech Republic, June.
Joakim Nivre, Johan Hall, Jens Nilsson, Atanas
Chanev, Gu?lsen Eryigit, Sandra Ku?bler, Svetoslav
Marinov, and Erwin Marsi. 2007b. Maltparser:
A language-independent system for data-driven de-
pendency parsing. Natural Language Engineering,
13(2):95?135.
Kemal Oflazer, Bilge Say, Dilek Zeynep Hakkani-
Tu?r, and Go?khan Tu?r. 2003. Building a turkish
treebank. Building and Exploiting Syntactically-
annotated Corpora.
Kenji Sagae and Alon Lavie. 2006. Parser com-
bination by reparsing. In Proceedings of the Hu-
man Language Technology Conference of the North
American Chapter of the ACL.
Djame? Seddah, Reut Tsarfaty, Sandra Ku?bler, Marie
Candito, Jinho Choi, Richa?rd Farkas, Jennifer Fos-
ter, Iakes Goenaga, Koldo Gojenola, Yoav Goldberg,
Spence Green, Nizar Habash, Marco Kuhlmann,
Wolfgang Maier, Joakim Nivre, Adam Przepi-
orkowski, Ryan Roth, Wolfgang Seeker, Yannick
Versley, Veronika Vincze, Marcin Wolin?ski, Alina
Wro?blewska, and Eric Villemonte de la Cle?rgerie.
2013. Overview of the spmrl 2013 shared task: A
cross-framework evaluation of parsing morpholog-
ically rich languages. In Proceedings of the 4th
Workshop on Statistical Parsing of Morphologically
Rich Languages: Shared Task, Seattle, WA.
Wolfgang Seeker and Jonas Kuhn. 2012. Making El-
lipses Explicit in Dependency Conversion for a Ger-
man Treebank. In Proceedings of the 8th Interna-
tional Conference on Language Resources and Eval-
uation, pages 3132?3139, Istanbul, Turkey. Euro-
pean Language Resources Association (ELRA).
Wolfgang Seeker and Jonas Kuhn. 2013. Morphologi-
cal and syntactic case in statistical dependency pars-
ing. Computational Linguistics, 39(1):23?55.
Mihai Surdeanu and Christopher D. Manning. 2010.
Ensemble models for dependency parsing: Cheap
and good? In Proceedings of the North Ameri-
can Chapter of the Association for Computational
Linguistics Conference (NAACL-2010), Los Ange-
les, CA, June.
Reut Tsarfaty, Djam Seddah, Yoav Goldberg, San-
dra Ku?bler, Marie Candito, Jennifer Foster, Yan-
nick Versley, Ines Rehbein, and Lamia Tounsi.
2010. Statistical parsing of morphologically rich
languages (spmrl) what, how and whither. In In Pro-
ceedings of the NAACL HLT 2010 First Workshop
on Statistical Parsing of Morphologically-Rich Lan-
guages.
Veronika Vincze, Do?ra Szauter, Attila Alma?si, Gyo?rgy
Mo?ra, Zolta?n Alexin, and Ja?nos Csirik. 2010. Hun-
garian dependency treebank. In LREC.
77
