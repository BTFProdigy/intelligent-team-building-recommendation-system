Proceedings of the Second Workshop on Psychocomputational Models of Human Language Acquisition, pages 20?27,
Ann Arbor, June 2005. c?2005 Association for Computational Linguistics
Using Morphology and Syntax Together 
in Unsupervised Learning 
Yu Hu and Irina Matveeva  
Department of  
Computer Science 
The University of Chicago 
Chicago IL 60637 
yuhu@cs.uchicago.edu
matveeva 
@uchicago.edu 
John Goldsmith 
Departments of Linguistics and 
Computer Science  
The University of Chicago 
Chicago IL 60637 
ja-goldsmith 
@uchicago.edu 
 
Colin Sprague 
Department of Linguistics 
The University of Chicago 
Chicago IL 60637 
sprague 
@uchicago.edu 
  
Abstract 
Unsupervised learning of grammar is a 
problem that can be important in many 
areas ranging from text preprocessing 
for information retrieval and 
classification to machine translation. 
We describe an MDL based grammar 
of a language that contains morphology 
and lexical categories. We use an 
unsupervised learner of morphology to 
bootstrap the acquisition of lexical 
categories and use these two learning 
processes iteratively to help and 
constrain each other. To be able to do 
so, we need to make our existing 
morphological analysis less fine 
grained. We present an algorithm for 
collapsing morphological classes 
(signatures) by using syntactic context. 
Our experiments demonstrate that this 
collapse preserves the relation between 
morphology and lexical categories 
within new signatures, and thereby 
minimizes the description length of the 
model. 
1 Introduction 
Our long term goal is the development of 
methods which will allow one to produce 
optimal analyses from arbitrary natural language 
corpora, where by optimization we understand 
an MDL (minimum description length; 
Rissanen, 1989) interpretation of the term: an 
optimal analysis is one which finds a grammar 
which simultaneously minimizes grammar 
length and data compression length. Our specific 
and primary focus is on morphology, and on 
how knowledge of morphology can be a useful 
step towards a more complete knowledge of a 
language?s linguistic structure. 
Our strategy is based on the following 
observation: knowing the rightmost suffix of a 
word is very useful information in inferring (or 
guessing) a word?s part of speech (POS), but due 
to the ambiguity of many suffixes, it is even 
better to know both a word?s suffix and the 
range of other suffixes that the word?s stem 
appears with elsewhere, i.e., its signature. As we 
will see below, this conjunction of ?better? 
information is what we call the signature 
transform, and in this paper, we explore how 
knowledge of signature transform can be merged 
with knowledge of the context vector to draw 
conclusions about morphology and syntax.  
In the distant future, we would like to be able 
to use the signature transform in a general 
process of grammar induction, but that day is 
not here; we therefore test our experiments by 
seeing how well we are able to predict POS as 
assigned by an available tagger (TreeTagger; 
Schmid 1994). In particular, we wish to decrease 
the uncertainty of a word?s POS through the 
morphological analysis described here. This 
decrease of uncertainty will enter into our 
calculation through an increase in the 
probability assigned to our test corpus once the 
corpus has been augmented with TreeTagger 
assigned POS tags. But to be clear on our 
20
process: we analyze a completely raw text 
morphologically, and use the POS tags from 
TreeTagger only to evaluate the signature 
transforms that we generate. 
We assume without argument here that any 
adequate natural language grammar will contain 
a lexicon which includes both lexical stems 
which are specified for morphological 
properties, such as the specific affixes with 
which they may occur, and affixes associated 
with lexical categories. We also explicitly note 
that many affixes are homophonous: they are 
pronounced (or written) identically, but have 
different morphological or syntactic 
characteristics, such as the English plural ?s and 
the verbal 3rd person singular present ?s. 
We focus initially on unsupervised learning 
of morphology for three reasons: first, because 
we already have a quite successful unsupervised 
morphological learner; second, the final suffix of 
a word is typically the strongest single indicator 
of its syntactic category; and third, analysis of a 
word into a stem T plus suffix F allows us 
(given our knowledge that the suffix F is a 
stronger indicator of category than the stem T) 
to collapse many distinct stems into a single 
cover symbol for purposes of analysis, 
simplifying our task, as we shall see.1 We 
eschew the use of linguistic resources with hand-
(i.e., human-)assigned morphological infor-
mation in order for this work to contribute, 
eventually, to a better theoretical understanding 
of human language acquisition. 
We present in this paper an algorithm that 
modifies the output of the morphology analyzer 
by combining redundant signatures. Since we 
ultimately want to use signatures and signature 
transforms to learn syntactic categories, we 
developed an algorithm that uses the syntactic 
contextual information. We evaluate the changes 
to the morphological analysis from the 
standpoint of efficient and adequate 
representation of lexical categories. This paper 
presents a test conducted on English, and thus 
can only be considered a preliminary step in the 
                                                          
1 See Higgins 2002 for a study similar in some ways; 
Higgins uses morphology as a bootstrap heuristic in one 
experimental set-up. This paper is heavily indebted to prior 
work on unsupervised learning of position categories such 
as Brown et al1992, Sch?tze 1997, Higgins 2002, and 
others cited there.  
eventually development of a language-
independent tool for grammar induction based 
on morphology. Nonetheless, the concepts that 
motivate the process are language-independent, 
and we are optimistic that similar results would 
be found in tests based on texts from other 
languages.  
In section 2 we discuss the notion of 
signature and signature transform, and section 3 
present a more explicit formulation of the 
general problem. In section 4 we present our 
algorithm for signature collapse. Section 5 
describes the experiments we ran to test the 
signature collapsing algorithm, and section 6 
presents and discusses our results. 
2 Signatures and signature transforms 
We employ the unsupervised learning of 
morphology developed by Goldsmith 
(Goldsmith, 2001). Regrettably, some of the 
discussion below depends rather heavily on 
material presented there, but we attempt to 
summarize the major points here. 
Two critical terms that we employ in this 
analysis are signature and signature transform. 
A signature found in a given corpus is a pair of 
lists: a stem-list and a suffix-list (or in the 
appropriate context, a prefix-list). By definition 
of signature ?, the concatenation of every stem 
in the stem-list of ? with every suffix in the 
suffix-list of ? is found in the corpus, and a 
morphological analysis of a corpus can be 
viewed as a set of signatures that uniquely 
analyze each word in the corpus. For example, a 
corpus of English that includes the words jump, 
jumps, jumped, jumping, walk, walks, walked, 
and walking might include the signature ?1 
whose stem list is { jump, walk } and whose 
suffix list is { ?, ed, ing , s }. For convenience, 
we label a signature with the concatenation of its 
suffixes separated by period ?.?. On such an 
analysis, the word jump is analyzed as belonging 
to the signature ?.ed.ing.s, and it bears the 
suffix ?. We say, then, that the signature 
transform of jump is ?.ed.ing.s_ ?, just as the 
signature transform of jumping is 
?.ed.ing.s_ing; in general, the signature 
transform of a word W, when W is morpho-
logically analyzed as stem T followed by suffix 
F, associated with signature ?, is defined as ?_F. 
21
In many of the experiments described below, 
we use a corpus in which all words whose 
frequency rank is greater than 200 have been 
replaced by their signature transforms. This 
move is motivated by the observation that high 
frequency words in natural languages tend to 
have syntactic distributions poorly predictable 
by any feature other than their specific identity, 
whereas the distribution properties of lower 
frequency words (which we take to be words 
whose frequency rank is 200 or below) are better 
predicted by category membership.  
In many cases, there is a natural connection 
between a signature transform and a lexical 
category. Our ultimate goal is to exploit this in 
the larger context of grammar induction. For 
example, consider the signature ?.er.ly, which 
occurs with stems such as strong and weak; in 
fact, words whose signature transform is 
?.er.ly_ ? are adjectives, those whose signature 
transform is ?.er.ly_er are comparative 
adjectives, and those whose signature transform 
is ?.er.ly_ly are adverbs. 
The connection is not perfect, however. 
Consider the signature ?.ed.ing.s and its four 
signature transforms. While most words whose 
? -transform is ?.ed.ing.s_s are verbs (indeed, 
3rd person singular present tense verbs, as in he 
walks funny), many are in fact plural nouns (e.g., 
walks in He permitted four walks in the eighth 
inning is a plural noun). We will refer to this 
problem as the signature purity problem?it is 
essentially the reflex of the ambiguity of 
suffixes. 
In addition, many 3rd person singular present 
tense verbs are associated with other signature 
transforms, such as ?.ing.s_s, ?.ed.s_s, and so 
forth; we will refer to this as the signature-
collapsing problem, because all other things 
being equal, we would like to collapse certain 
signatures, such as ?.ed.ing.s and ?.ed.ing, 
since a stem that is associated with the latter 
signature could have appeared in the corpus with 
an -s suffix; removing the ?.ed.ing signature and 
reassigning its stems to the ?.ed.ing.s signature 
will in general give us a better linguistic analysis 
of the corpus, one that can be better used in the 
problem of lexical category induction. This is 
the reflex of the familiar data sparsity concern.2   
Since we ultimately want to use signatures 
and signature transforms to learn syntactic 
categories, we base the similarity measure 
between the signatures on the context.   
3 A more abstract statement of the 
problem  
A minimum description length (MDL) analysis 
is especially appropriate for machine learning of 
linguistic analysis because simultaneously it 
puts a premium both on analytical simplicity and 
on goodness of fit between the model and the 
data (Rissanen 1989).  
We will present first the mathematical 
statement of the MDL model of the morphology, 
in (1), following the analysis in Goldsmith 
(2001), followed by a description of the meaning 
of the terms of the expressions, and then present 
the modified version which includes additional 
terms regarding part of speech (POS) 
information, in (2) and (3).  
(1) Morphology 
a. Grammar g =   
[ ])|(log)(minarg gDataprobgLength
Gg
?
?
 
b. =)(gLength  
 ? ?
=? <?
??
???
? +
stemsofsetTt ti itfreqt
W
||0 ][
1log
)]([
][log ?  
? ?
=? <?
+
affixesofsetFf fi iffreq||0 ][
1log  
??
?? ?
??
???
? +?+ ? ? ?
?
f f
W
f ][
][log
][
][log  
                                                          
2 The signature-collapsing problem has another side to it as 
well. An initial morphological analysis of English will 
typically give rise to a morphological analysis of words 
such as move, moves, moved, moving with a signature 
whose stems include mov and whose affixes are e.ed.es.ing. 
A successful solution to the signature-collapsing problem 
will collapse ?.ed.ing.s with e.ed.es.ing, noting that ? ~ e, 
ed ~ed, es ~ s, and ing ~ ing in an obvious sense. 
22
c. =)|(log gDataprob  
?
+=? ?
??
?
?
??
?
?
?
+
+
? ?
?
?
, ),|(log
)|(log
)(log
ftw
Dataw tfprob
tprob
prob
 
 
Equation (1a) states that our goal is to find 
the (morphological) grammar that 
simultaneously minimizes the sum of its own 
length and the compressed length of the data it 
analyzes, while (1b) specifies the grammar 
length (or model length) as the sum of the 
lengths of the links between the major 
components of the morphology: the list of letters 
(or phonemes) comprising the morphemes, the 
morphemes (stems and affixes), and the 
signatures. We use square brackets ?[.]? to 
denote the token counts in a corpus containing a 
given morpheme or word. The first line of (1b) 
expresses the notion that each stem consists of a 
pointer to its signature and a list of pointers to 
the letters that comprise it; ?(t) is the signature 
associated with stem t, and we take its 
probability to be 
][
)]([
W
t? , the empirical count of 
the words associated with ?(t) divided by the 
total count of words in the data. The second line 
expresses the idea that the morphology contains 
a list of affixes, each of which contains a list of 
pointers to the letters that comprise it. The third 
line of (1b) expresses the notion that a signature 
consists of a list of pointers to the component 
affixes. (1c) expresses the compressed length of 
each word in the data.3 
We now consider extending this model to 
include part of speech labeling, as sketched in 
(2). The principal innovation in (2) is the 
addition of part of speech tags; each affix is 
associated with one or more POS tags. As we 
                                                          
3 We do not sum over all occurrences of a word in the 
corpus; we count the compressed length of each word type 
found in the corpus. This decision was made based on the 
observation that the (compressed length of the) data term 
grows much faster than the length of the grammar as the 
corpus gets large, and the loss in ability of the model to 
predict word frequencies overwhelms any increase in 
model simplicity when we count word tokens in the data 
terms. We recognize the departure from the traditional 
understanding of MDL here, and assume the responsibility 
to explain this in a future publication. 
have seen, a path from a particular signature ? to 
a particular affix f constitutes what we have 
called a particular signature transform ?_f ; and 
we condition the probabilities of the POS tags in 
the data on the preceding signature 
transformation. As a result, our final model takes 
the form in (3). 
 
(2)  
t1
t2
t3
tn
...
Stems Signatures Affixes POSs
?1
?2
?m
...
f1
f2
f3
fk
...
?1
?2
?3
?l
...
 
(3) 
a. Grammar g =   [ ])|(log)(minarg gDataprobgLength
Gg
?
?
 
b. =)(gLength  
? ?
=? <?
??
???
? +
stemsofsetTt ti itfreqt
W
||0 ][
1log
)]([
][log ?
 
? ?
=? <?
+
affixesofsetFf fi iffreq||0 ][
1log  
?? ??? ?
?? ?
??
?
?
?
??
??
?
?
??
?
++?+
? ?
? ??
?
?
?
f
f
f
f
W
f
][
][log
][
][log
][
][log
 
c. =)|(log gDataprob  
 ?
+=? ?
??
?
?
??
?
?
?
+
+
+
? ??
?
??
, ),|(log
),|(log
)|(log)(log
ftw
Dataw fprob
tfprob
tprobprob
 
 
The differences between the models are 
found in the added final term in (3b), which 
specifies the information required to predict, or 
specify, the part of speech given the signature 
23
transform, and the corresponding term in the 
corpus compression expression (3c).  
The model in (3) implicitly assumes that the 
true POSs are known; in a more complete 
model, the POSs play a direct role in assigning a 
higher probability to the corpus (and hence a 
smaller compressed size to the data). In the 
context of such a model, an MDL-based learning 
device searches for the best assignment of POS 
tags over all possible assignments. Instead of 
doing that in this paper, we employ the 
TreeTagger (Schmid, 1994) based tags (see 
section 5 below), and make the working 
assumption that optimization of description 
length over all signature-analyses and POS tags 
can be approximated by optimization over all 
signature-analyses, given the POS tags provided 
by TreeTagger. 
4 The collapsing of signatures 
We describe in this section our proposed 
algorithm, using context vectors to collapse 
signatures together, composed of a sequence of 
operations, all but the first of which may be 
familiar to the reader:  
Replacement of words by signature-
transforms: The input to our algorithm for 
collapsing signatures is a modified version of 
the corpus which integrates the (unsupervised) 
morphological analyses in the following way. 
First of all, we leave unchanged the 200 most 
frequent words (word types). Next, we replace 
words belonging to the K most reliable 
signatures (where K=50 in these experiments) 
by their associated signature transforms, and we 
in effect ignore all other words, by replacing 
them by a distinguished ?dummy? symbol. In 
the following, we refer to our high frequency 
words and signature transforms together as 
elements?so an element is any member of the 
transformed corpus other than the ?dummy?.   
Context vectors based on mutual 
information: By reading through the corpus, we 
populate both left and right context vectors for 
each element (=signature-transform and high-
frequency word)  by observing the elements that 
occur adjacent to it. The feature indicating the 
appearance of a particular word on the left is 
always kept distinct from the feature indicating 
the appearance of the same word on the right. 
The features in a context vector are thus 
associated with the members of the element 
vocabulary (and indeed, each member of the 
element vocabulary occurs as two features: one 
on the left, one on the right). We assign the 
value of each feature y of x?s context vector as 
the pointwise mutual information of the 
corresponding element pair (x, y), defined as 
)()(
),(log
yprxpr
yxpr . 
Simplifying context vectors with ?idf?: In 
addition, because of the high dimensionality of 
the context vector and the fact that some features 
are more representative than others, we trim the 
original context vector. For each context vector, 
we sort features by their values, and then keep 
the top N (in general, we set N to 10) by setting 
these values to 1, and all others to 0. However, 
in this resulting simplified context vector, not all 
features do equally good jobs of distinguishing 
syntactical categories. As Wicentowski (2002) 
does in a similar context, we assign a weight  
if
w  to each feature fi in a fashion parallel to 
inverse document frequency (idf; see Sparck 
Jones 1973), or 
inappearsfeaturethiselements
elementsdistincttotal
#
#log . 
We view these as the diagonal elements of a 
matrix M (that is, mi,i = ifw ). We then check the 
similarity between two simplified context 
vectors by computing the weighted sum of the 
dot product of them. That is, given two 
simplified context vectors c and d, their 
similarity is defined as cTMd. If this value is 
larger than a threshold ? that is set as one 
parameter, we deem these two context vectors to 
be similar. Then we determine the similarity 
between elements by checking whether both left 
and right simplified context vectors of them are 
similar (i.e., their weighted dot products exceed 
a threshold ?). In the experiments we describe 
below, we explore four settings ? for this 
threshold: 0.8 (the most ?liberal? in allowing 
greater signature transform collapse, and hence 
greater signature collapse), 1.0, 1.2, and 1.5. 
Calculate signature similarity: To avoid 
considering many unnecessary pairs of 
signatures, we narrow the candidates into 
signature pairs in which the suffixes of one 
constitute a subset of suffixes of the other, and 
we set a limit to the permissible difference in the 
24
lengths of the signatures in the collapsed pairs, 
so that the difference in number of affixes 
cannot exceed 2. For each such pair, if all 
corresponding signature transforms are similar 
in the sense defined in the preceding paragraph, 
we deem the two signatures to be similar. 
Signature graph: Finally, we construct a 
signature graph, in which each signature is 
represented as a vertex, and an edge is drawn 
between two signatures iff they are similar, as 
just defined. In this graph, we find a number of 
cliques, each of which, we believe, indicates a 
cluster of signatures which should be collapsed. 
If a signature is a member of two or more 
cliques, then it is assigned to the largest clique 
(i.e., the one containing the largest number of 
signatures).4  
5 Experiments 
We obtain the morphological analysis of the 
Brown corpus (Ku?era and Francis, 1967) using 
the Linguistica software (http://linguistica. 
uchicago.edu), and we use the TreeTagger to 
assign a Penn TreeBank-style part-of-speech tag 
to each token in the corpus. We then carry out 
our experiment using the Brown corpus 
modified in the way we described above. Thus, 
for each token of the Brown corpus that our 
morphology analyzer analyzed, we have the 
following information: its stem, its signature 
                                                          
4 Our parameters are by design restrictive, so 
that we declare only few signatures to be similar, 
and therefore the cliques that we find in the 
graph are relatively small. One way to enlarge 
the size of collapsed signatures would be to 
loosen the similarity criterion. This, however, 
introduces too many new edges in the signatures 
graph, leading in turn to spurious collapses of 
signatures. We take a different approach, and 
apply our algorithms iteratively. The idea is that 
if in the first iteration, two cliques did not have 
enough edges between their elements to become 
a single new signature, they may be more 
strongly connected in the second iteration if 
many of their elements are sufficiently similar. 
On the other hand, cliques that were dissimilar 
in the first iteration remain weakly connected in 
the second.  
 
(i.e., the signature to which the stem is 
assigned), the suffix which the stem attains in 
this occurrence of the word (hence, the 
signature-transform), and the POS tag. For 
example, the token polymeric is analyzed into 
the stem polymer and the suffix ic, the stem is 
assigned to the signature ?.ic.s, and thus this 
particular token has the signature transform 
?.ic.s_ic. Furthermore, it was assigned POS-tag 
JJ, so that we have the following entry: 
?polymeric JJ ?.ic.s_ic?. 
Before performing signature collapsing, we 
calculate the description length of the 
morphology and the compressed length of the 
words that our algorithm analyzes and call it 
baseline description length (DL0). 
Now we apply our signature collapsing 
algorithm under several different parameter 
settings for the similarity threshold ?, and 
calculate the description length DL? of the 
resulting morphological and lexical analysis 
using  (3).  We know that the smaller the set of 
signatures, the smaller is the cost of the model. 
However, a signature collapse that combines 
signatures with different distributions over the 
lexical categories will result in a high cost of the 
data term (3c). The goal was therefore to find a 
method of collapsing signatures such that the 
reduction in the model cost will be higher than 
the increase in the compressed length of the data 
so that the total cost will decrease.  
As noted above, we perform this operation 
iteratively, and refer to the description length of 
the ith iteration, using a threshold ?, as ? iiterDL = . 
We used random collapsing in our 
experiments to ensure the expected relationship 
between appropriate collapses and description 
length. For each signature collapsing, we created 
a parallel situation in which the number of 
signatures collapsed is the same, but their choice 
is random.  We calculate the description length 
using this ?random? analysis as 
?
randomDL . We 
predict that this random collapsing will not 
produce an improvement in the total description 
length. 
25
6 Results and discussion 
Table 1 presents the description length, broken 
into its component terms (see (3)), for the 
baseline case and the alternative analyses 
resulting from our algorithm. The table shows 
the total description length of the model, as well 
as the individual terms: the signature term 
DL(?), the suffix term DL(F), the lexical 
categories term, DL(P), total morphology, 
DL(M), and the compressed length of the data, 
DL(D). We present results for two iterations for 
four threshold values (?=0.8,1.0,1.2,1.5) using 
our collapsing algorithm.  
Table 2 presents 
?
randomDL  derived from the 
random collapsing, in a fashion parallel to Table                
1. We show the results for only one iteration of 
random collapsing, since the first iteration 
already shows a substantial increase in 
description length. 
Figure 1 and Figure 2 present graphically the 
total description length from Tables 1 and 2 
respectively. The reader will see that all 
collapsing of signatures leads to a shortening of 
the description length of the morphology per se, 
and an increase in the compressed length of the 
data. This is an inevitable formal consequence of 
the MDL-style model used here. The empirical 
question that we care about is whether the 
combined description length increases or 
decreases, and what we find is that when 
collapsing the signatures in the way that we 
propose to do, the combined description length 
decreases, leading us to conclude that this is, 
overall, a superior linguistic description of the 
data. On the other hand, when signatures are 
collapsed randomly, the combined description 
length increases. This makes sense; randomly 
decreasing the formal simplicity of the 
grammatical description should not improve the 
overall analysis. Only an increase in the formal 
simplicity of a grammar that is grammatically 
sensible should have this property. Since our 
goal is to develop an algorithm that is 
completely data-driven and can operate in an  
Compa rison of DL 
362,500
363,000
363,500
364,000
364,500
365,000
365,500
366,000
DL0 DL1 DL2
?=0.8 ?=1 ?=1.2 ?=1.5  
Figure 1 Comparison of DL, 2 iterations and 4 
threshold values 
Compa rison of ra ndomly c olla psing DL
364,000
364,500
365,000
365,500
366,000
366,500
367,000
367,500
368,000
DL0 Drandom
D
L
?=0.8 ?=1 ?=1.2 ?=1.5
 
Figure 2 Comparison of DLs with random 
collapse of signatures (see text)
 DL0 8.0 1
=
=
?
iterDL  
8.0
2
=
=
?
iterDL
0.1
1
=
=
?
iterDL
0.1
2
=
=
?
iterDL
2.1
1
=
=
?
iterDL
2.1
2
=
=
?
iterDL  
5.1
1
=
=
?
iterDL  
5.1
2
=
=
?
iterDL
#? 50 41 35 41 34 44 42 46 45 
DL(?) 47,630 45,343 42,939 45,242 43,046 44,897 44,355 46,172 45,780 
DL(F) 160 156 156 153 143 158 147 163 164 
DL(P) 2,246 2,087 1,968 2,084 1,934 2,158 2,094 2,209 2,182 
DL(M) 50,218 47,768 45,244 47,659 45,304 47,395 46,777 48,724 48,306 
DL(D) 315,165 316,562 318,687 316,615 318,172 316,971 317,323 315,910 316,251 
Total 
DL 
365,383 364,330 363,931 364,275 363,476 364,367 364,101 364,635 364,558 
Table 1.   DL and its individual components for baseline and the resulting cases when collapsing 
signatures using our algorithm. 
26
 
 DL0 8.0=?
randomDL  
0.1=?
randomDL  
2.1=?
randomDL  
5.1=?
randomDL  
#? 50 41 41 44 46 
DL(?) 47,630 44,892 45,126 45,788 46,780 
DL(F) 160 201 198 187 177 
DL(P) 2,246 2,193 2,195 2,212 2,223 
DL(M) 50,218 47,468 47,700 48,369 49,362 
DL(D) 315,165 320,200 319,551 318,537 316,874 
Total DL 365,383 367,669 367,252 366,907 366,237 
Table 2. DL and its individual components for baseline and the 
resulting cases when collapsing signatures randomly.
 
 
 
unsupervised fashion, we take this evidence as 
supporting the appropriateness of our algorithm as 
a means of collapsing signatures in a 
grammatically and empirically reasonable way. 
We conclude that the collapsing of signatures 
on the basis of similarity of context vectors of 
signature transforms (in a space consisting of high 
frequency words and signature transforms) 
provides us with a useful and significant step 
towards solving the signature collapsing problem. 
In the context of the broader project, we will be 
able to use signature transforms as a more effective 
means for projecting lexical categories in an 
unsupervised way. 
As Table 1 shows, we achieve up to 30% 
decrease in the number of signatures through our 
proposed collapse. We are currently exploring 
ways to increase this value through powers of the 
adjacency matrix of the signature graph. 
In other work in progress, we explore the 
equally important signature purity problem in 
graph theoretic terms: we split ambiguous 
signature transforms into separate categories when 
we can determine that the edges connecting left-
context features and right-context features can be 
resolved into two sets (corresponding to the 
distinct categories of the transform) whose left-
features have no (or little) overlap and whose right 
features have no (or little) overlap. We employ the 
notion of minimum cut of a weighted graph to 
detect this situation.
 
References  
Brown, Peter F., Vincent J. Della Pietra, Peter V. 
deSouza, Jennifer C. Lai, and Robert L. Mercer. 
1992. Class-based n-gram models of natural 
language. Computational Linguistics, 18(4): 467-
479.  
Goldsmith, John. 2001. Unsupervised learning of the 
morphology of a natural language. Computational 
Linguistics, 27(2): 153-198.  
Higgins, Derrick. 2002. A Multi-modular Approach to 
Model Selection in Statistical NLP. University of 
Chicago Ph.D. thesis. 
Schmid, Helmut. 1994. Probabilistic part-of-speech 
tagging using decision trees.. International 
Conference on New Methods in Language 
Processing 
Kucera, Henry and W. Nelson Francis. 1967. 
Computational Analysis of Present-day American 
English. Brown University Press.  
Rissanen, Jorma. 1989. Stochastic Complexity in 
Statistical Inquiry. Singapore: World Scientific.  
Sch?tze, Hinrich. 1997. Ambiguity Resolution in 
Language Learning. CSLI Publications. Stanford 
CA.  
Sparck Jones, Karen. 1973. Index term weighting. 
Information Storage and Retrieval 9:619-33. 
Wicentowski, Richard. 2002. Modeling and Learning 
Multilingual Inflectional Morphology in a Minimally 
Supervised Framework. Johns Hopkins University 
Ph.D. thesis. 
27
Proceedings of the Second Workshop on Psychocomputational Models of Human Language Acquisition, pages 28?35,
Ann Arbor, June 2005. c?2005 Association for Computational Linguistics
The SED heuristic for morpheme discovery:  
a  look at Swahili 
 
 
Yu Hu and Irina Matveeva  
Department of  
Computer Science 
The University of Chicago 
Chicago IL 60637 
yuhu@cs.uchicago.edu
matveeva 
@uchicago.edu  
John Goldsmith 
Departments of Linguistics and 
Computer Science  
The University of Chicago 
Chicago IL 60637 
ja-goldsmith 
@uchicago.edu 
 
Colin Sprague 
Department of Linguistics 
The University of Chicago 
Chicago IL 60637 
sprague 
@uchicago.edu  
  
Abstract 
This paper describes a heuristic for 
morpheme- and morphology-learning 
based on string edit distance. 
Experiments with a 7,000 word corpus 
of Swahili, a language with a rich 
morphology, support the effectiveness 
of this approach. 
1 Introduction 
This paper describes work on a technique for the 
unsupervised learning of the morphology of 
natural languages which employs the familiar 
string edit distance (SED) algorithm (Wagner 
and Fischer 1974 and elsewhere) in its first 
stage;  we refer to it here as the SED heuristic. 
The heuristic finds 3- and 4-state finite state 
automata (FSAs) from untagged corpora. We 
focus on Swahili, a Bantu language of East 
Africa, because of the very high average number 
of morphemes per word, especially in the verbal 
system, a system that presents a real challenge to 
other systems discussed in the literature.1 
In Section 2, we present the SED heuristic, 
with precision and recall figures for its 
application to a corpus of Swahili. In Section 3, 
we propose three elaborations and extensions of 
                                                     
1 An earlier version of this paper, with a more detailed 
discussion of the material presented in Section 3, is 
available at Goldsmith et al(2005). 
this approach, and in Section 4, we describe and 
evaluate the results from applying these 
extensions to the corpus of Swahili.2  
2 SED-based heuristic 
Most systems designed to learn natural language 
morphology automatically can be viewed as 
being composed of an initial heuristic 
component and a subsequent explicit model. The 
initial or bootstrapping heuristic, as the name 
suggests, is designed to rapidly come up with a 
set of candidate strings of morphemes, while the 
model consists of an explicit formulation of 
either (1) what constitutes an adequate 
morphology for a set of data, or (2) an objective 
function that must be optimized, given a corpus 
of data, in order to find the correct 
morphological analysis.  
The best known and most widely used 
heuristic is due to Zellig Harris (1955) (see also 
Harris (1967) and Hafer and Weiss (1974) for an 
evaluation based on an English corpus), using a 
notion that Harris called successor frequency 
(henceforth, SF). Harris' notion can be 
succinctly described in contemporary terms: if 
we encode all of the data in the data structure 
known as a trie, with each node in the trie 
dominating all strings which share a common 
                                                     
2 SED has been used in unsupervised language learning in a 
number of studies; see, for example, van Zaanen (2000) 
and references there, where syntactic structure is studied in 
a similar context. To our knowledge, it has not been used in 
the context of morpheme detection. 
28
string prefix,3 then each branching node in the 
trie is associated with a morpheme break. For 
example, a typical corpus of English may 
contain the words governed, governing, 
government, governor, and governs. If this data 
is encoded in the usual way in a trie, then a 
single node will exist in the trie which represents 
the string prefix govern and which dominates 
five leaves corresponding to these five words. 
Harris's SF-based heuristic algorithm would 
propose a morpheme boundary after govern on 
this basis. In contemporary terms, we can 
interpret Harris?s heuristic as providing sets of 
simple finite state automata, as in (1), which 
generate a string prefix (PF1) followed by a set 
of string suffixes (SFi) based on the 
measurement of a successor frequency greater 
than 1 (or some threshold value) at the string 
position following PF1. 
(1)  
SF1
SF3
PF1 SF2
 
A variant on the SF-based heuristic, 
predecessor frequency (henceforth, PF), calls for 
encoding words in a trie from right to left. In 
such a PF-trie, each node dominates all strings 
that share a common string suffix. In general, we 
expect SF to work best in a suffixing language, 
and PF to work best in prefixing language; 
Swahili, like all the Bantu languages, is 
primarily a prefixing language, but it has a 
significant number of important suffixes in both 
the verbal and the nominal systems. 
Goldsmith (2001) argues for using the 
discovery of signatures as the bootstrapping 
heuristic, where a signature is a maximal set of 
stems and suffixes with the property that all 
combinations of stems and suffixes are found in 
the corpus in question. We interpret Goldsmith?s 
signatures as extensions of FSAs as in (1) to 
                                                     
3 We use the terms string prefix and string suffix in the 
computer science sense: a string S is a string prefix of a 
string X iff there exists a string T such that X = S.T, where 
?.? is the string concatenation operator; under such 
conditions, T is likewise a string suffix of X. Otherwise, we 
use the terms prefix and suffix in the linguistic sense, and a 
string prefix (e.g., jump) may be a linguistic stem, as in 
jump-ing. 
FSAs as in (2); (2) characterizes Goldsmith?s 
notion of signature in term of FSAs. In 
particular, a signature is a set of forms that can 
be characterized by an FSA of 3 states. 
(2)  
PF1 SF1
PF3 SF2
PF2
 
 
We propose a simple alternative heuristic 
which utilizes the familiar dynamic 
programming algorithm for calculating string-
edit distance, and finding the best alignment 
between two arbitrary strings (Wagner and 
Fischer 1974). The algorithm finds subsets of 
the data that can be exactly-generated by 
sequential finite state automata of 3 and 4 states, 
as in (3), where the labels mi should be 
understood as cover terms for morphemes in 
general. An automaton exactly-generates a set of 
strings S if it generates all strings in S and no 
other strings; a sequential FSA is one of the 
form sketched graphically in (1)-(3), where there 
is a unique successor to each state. 
(3)  
M1 M4
M3 M6
M2
M7
M9
M5 M8
 
2.1 First stage: alignments. 
If presented with the pair of strings anapenda 
and anamupenda from an unknown language, it 
is not difficult for a human being to come up 
with the hypothesis that mu is a morpheme 
inside a larger word that is composed of at least 
two morphemes, perhaps ana- and -penda. The 
SED heuristic makes this observation explicit by 
building small FSAs of the form in (4), where at 
most one of m1 or m4 may be null, and at most 
one of m2 and m3 may be null: we refer to these 
as elementary alignments. The strings m2 and m3 
are called counterparts; the pairs of strings m1 
and m4 are called the context (of the 
counterparts). (Indeed, we consider this kind of 
string comparison to be a plausible candidate for 
human language learning; see Dahan and Brent 
1999). 
 
29
 
 
(4)  
1 432m1 m4
m3
m2
 
The first stage of the algorithm consists of 
looking at all pairs of words S, T in the corpus, 
and passing through the following steps:  
We apply several initial heuristics to 
eliminate a large proportion of the pairs of 
strings before applying the familiar SED 
algorithm to them, in view of the relative 
slowness of the SED algorithm; see Goldsmith 
et al(2005) for further details.  
We compute the optimal alignment of S and 
T using the SED algorithm, where alignment 
between two identical letters (which we call 
twins) is assigned a cost of 0, alignment between 
two different letters (which we call siblings) is 
assigned a cost of 1.5, and a letter in one string 
not aligned with a segment on the other string 
(which we call an orphan) is assigned a cost of 
1. An alignment as in (5) is thus assigned a cost 
of 5, based on a cost of 1.5 assigned to each 
broken line, and 1  to each dotted line that ends 
in a square box. 
(5)   
n i l i m u p e n d a
n i t a k a m u p e n d a  
There is a natural map from every alignment 
to a unique sequence of pairs, where every pair 
is either of the form (S[i], T[j]) (representing 
either a twin or sibling case) or of the form (S[i], 
0) or (0, T[j]) (representing the orphan case). We 
then divide the alignment up into perfect and 
imperfect spans: perfect spans are composed of 
maximal sequences of twin pairs, while 
imperfect spans are composed of maximal 
sequences of sibling or orphan pairs. This is 
illustrated in (6). 
(6)  
 
 
 
 
 
 
There is a natural equivalence between 
alignments and sequential FSAs as in (4), where 
perfect spans correspond to pairs of adjacent 
states with unique transitions and imperfect 
spans correspond to pairs of adjacent states with 
two transitions, and we will henceforth use the 
FSA notation to describe our algorithm. 
2.2 Collapsing alignments 
As we noted above (4), for any elementary 
alignment, a context is defined: the pair of 
strings (one of them possibly null) which 
surround the pair of counterparts. Our first goal 
is to collapse alignments that share their context. 
We do this in the following way. 
Let us define the set of strings associated 
with the paths leaving a state S as the production 
of state S. A four-state sequential FSA, as in (4), 
has three states with non-null productions; if this 
particular FSA corresponds to an elementary 
alignment, then two of the state-productions 
contain exactly one string?and these state-
productions define the context? and one of the 
state-productions contains exactly two strings 
(one possibly the null string)?this defines the 
counterparts. If we have two such four-state 
FSAs whose context are identical, then we 
collapse the two FSAs into a single conflated 
FSA in which the context states and their 
productions are identical, and the states that 
produced the counterparts are collapsed by 
creating a state that produces the union of the 
productions of the original states. This is 
illustrated in (7): the two FSAs in (7a) share a 
context, generated by their states 1 and 3, and 
they are collapsed to form the FSA in (7b), in 
which the context states remain unchanged, and 
the counterpart states, labeled ?2?, are collapsed 
to form a new state ?2? whose production is the 
union of the productions of the original states. 
(7)  
a.  
1 432m1 m4
1 432m1 m4
m7
m8
m3
m2
 
 
n i   l i   m u p e n d a
n i   t a k a   m u p e n d a
30
 
 
b. 
1 432m1 m4
m8
m7
m3
m2
 
2.3 Collapsing the resulting sequential 
FSAs 
We now generalize the procedure described in 
the preceding section to collapse any two 
sequential FSAs for which all but one of the 
corresponding states have exactly the same 
production. For example, the two sequential 
FSAs in (8a) are collapsed into (8b). 
Three and four-state sequential FSAs as in 
(8b), where at least two of the state-transitions 
generate more than one morpheme, form the set 
of templates derived from our bootstrapping 
heuristic. Each such template can be usefully 
assigned a quantitative score based on the 
number of letters ?saved? by the use of the 
template to generate the words, in the following 
sense. The template in (8b) summarizes four 
words: aliyesema, alimfuata, anayesema, and 
anamfuata. The total string length of these 
words is 36, while the total number of letters in 
the strings associated with the transitions in the 
FSA is 1+4+12 = 17; we say that the FSA saves 
36-17 = 19 letters. In actual practice, the 
significant templates discovered save on the 
order of 200 to 5,000 letters, and ranking them 
by the number of letters saved is a good measure 
of how significant they are in the overall 
morphology of the language. We refer to this 
score as a template?s robustness; we employ this 
quantity again in section 3.1 below. 
By this ranking, the top template found in our 
Swahili corpus of 50,000 running words was one 
that generated a and wa (class 1 and 2 subject 
markers) and followed by 246 correct verb 
continuations (all of them polymorphemic); the 
first 6 templates are summarized informally in 
Table 1. We note that the third and fourth 
template can also be collapsed to form a 
template of the form in (3), a point we return to 
below. Precision, recall, and F-score for these 
experiments are given in Table 2.  
 
(8)   
a. 
1 432a yesema
na
li
1 432a mfuata
na
li
 
 
b.  
1 432a
na
li yesema
mfuata  
 
State 1 State 2 State 3 
a, wa (sg., pl. 
human subject 
markers) 
246 stems  
ku, hu 
(infinitive, 
habitual 
markers) 
51 stems  
wa (pl. subject 
marker) 
ka, li (tense 
markers) 
25 stems 
a (sg. subject 
marker) 
ka, li (tense 
markers) 
29 stems 
a (sg. subject 
marker) 
ka, na (tense 
markers 
28 stems 
37 strings w (passive 
marker) 
a 
Table 1 Top templates in Swahili 
 
 Precision Recall  F-score 
SED 0.77 0.57 0.65 
SF 0.54 0.14 0.22 
PF 0.68 0.20 0.31 
Table 2 Results 
31
3 Further developments 
In this section, we describe three developments 
of the SED-based heuristic sketched in section 2. 
The first disambiguates which state it is that 
string material should be associated with in 
cases of ambiguity; the second collapses 
templates associated with similar morphological 
structure; the third uses the FSAs to predict 
words that do not actually occur in the corpus by 
hypothesizing stems on the basis of the 
established FSAs and as yet unanalyzed words 
in the corpus. 
3.1 Disambiguating FSAs 
In the case of a sequential FSA, when the final 
letter of the production of a (non-final) state S 
are identical, then that letter can be moved from 
being the string-suffix of all of the productions 
of state S to being the string-prefixes of all of 
the productions of the following state. More 
generally, when the n final letters of the 
productions of a state are identical, there is an n-
way ambiguity in the analysis, and the same 
holds symmetrically for the ambiguity that arises 
when the n initial letters of the production of a 
(non-initial) state.  
Thus two successive states, S and T, must (so 
to speak) fight over which will be responsible 
for generating the ambiguous string. We employ 
two steps to disambiguate these cases.  
Step 1: The first step is applicable when the 
number of distinct strings associated with states 
S and T are quite different in size (typically 
corresponding to the case where one generates 
grammatical morphemes and the other generates 
stems); in this case, we assign the ambiguous 
material to the state that generates the smaller 
number of strings. There is a natural motivation 
for this choice from the perspective of our desire 
to minimize the size of the grammar, if we 
consider the size of the grammar to be based, in 
part, on the sum of the lengths of the morphemes 
produced by each state. 
Step 2: It often happens that an ambiguity 
arises with regard to a string of one or more 
letters that could potentially be produced by 
either of a pair of successive states involving 
grammatical morphemes. To deal with this case, 
we make a decision that is also (like the 
preceding step) motivated by a desire to 
minimize the description length of the grammar. 
In this case, however, we think of the FSA as 
containing explicit strings (as we have assumed 
so far), but rather pointers to strings, and the 
?length? of a pointer to a string is inversely 
proportional to the logarithm of its frequency. 
Thus the overall use of a string in the grammar 
plays a crucial role in determining the length of 
a grammar, and we wish to maximize the 
appearance in our grammar of morphemes that 
are used frequently, and minimize the use of 
morphemes that are used rarely. 
We implement this idea by collecting a table 
of all of the morphemes produced by our FSA, 
and assigning each a score which consists of the 
sum of the robustness scores of each template 
they occur in (see discussion just above (8)). 
Thus morphemes occurring in several high 
robustness templates will have high scores; 
morphemes appearing in a small number of 
lowly ranked templates will have low scores. 
To disambiguate strings which could be 
produced by either of two successive states, we 
consider all possible parsings of the string 
between the states, and score each parsing as the 
sum of the scores of the component morphemes; 
we chose the parsing for which the total score is 
a maximum. 
 For example, Swahili has two common tense 
markers, ka and ki, and this step corrected a 
template from {ak}+{a,i}+{stems} to 
{a}+{ka,ki}+{stems}, and others of similar 
form. It also did some useful splitting of joined 
morphemes, as when it modified a template 
{wali} + {NULL, po} + {stems} to {wa} + {li, 
lipo} + {stems}. In this case, wali should indeed 
be split into wa + li (subject and tense markers, 
resp.), and while the change creates an error (in 
the sense that lipo is, in fact, two morphemes; po 
is a subordinate clause marker), the resulting 
error occurs considerably less often in the data, 
and the correct template will better be able to be 
integrated with out templates. 
3.2 Template collapsing 
From a linguistic point of view, the SED-based 
heuristic creates too many FSAs because it stays 
too close to the data provided by the corpus. The 
only way to get a more correct grammar is by 
collapsing the FSAs, which will have as a 
32
consequence the generation of new words not 
found in the corpus. We apply the following 
relatively conservative strategy for collapsing 
two templates. 
We compare templates of the same number 
of states, and distinguish between states that 
produce grammatical morphemes (five or fewer 
in number) and those that produce stems (that is, 
lexical morphemes, identified as being six or 
more in number). We collapse two templates if 
the productions of the corresponding states 
satisfy the following conditions: if the states 
generate stems, then the intersection of the 
productions must be at least two stems, while if 
the states are grammatical morphemes, then the 
productions of one pair of corresponding states 
must be identical, while for the other pair, the 
symmetric difference of the productions must be 
no greater than two in number (that is, the 
number of morphemes produced by the state of 
one template but not the other must not exceed 
2).  
3.3 Reparsing words in the corpus and 
predicting new words 
When we create robust FSAs?that is, FSAs that 
generate a large number of words?we are in a 
position to go back to the corpus and reanalyze a 
large number of words that could not be 
previously analyzed. That is, a 4-state FSA in 
which each state produced two strings generates 
8 words, and all 8 words must appear in the 
corpus for the method described so far in order 
for this particular FSA to generate any of them. 
But that condition is unlikely to be satisfied for 
any but the most common of morphemes, so we 
need to go back to the corpus and infer the 
existence of new stems (as defined operationally 
in the preceding paragraph) based on their 
occurrence in several, but not all possible, 
words.  If there exist 3 distinct words in the 
corpus which would all be generated by a 
template if a given stem were added to the 
template, we add that stem to the template. 
4 Experiments and Results 
In this section, we present three sets of 
evaluations of the refinements of the SED 
heuristics described in the preceding section. We 
used a corpus of 7,180 distinct words occurring 
in 50,000 running words from a Swahili 
translation of the Bible obtained on the internet. 
4.1 Disambiguating FSAs 
In order to evaluate the effects of the 
disambiguating of FSAs described in section 
3.1, we compare precision and recall of the 
identification of morpheme boundaries using the 
SED method with and without the 
disambiguation procedure described above. In 
Figures 1 and 2, we graph precision and recall 
for the top 10% of the templates, displayed as 
the leftmost point, for the top 20% of the 
templates, displayed as the second point from 
the left; and so on, because the higher ranked 
FSAs are more intrinsically more reliable than 
the lower ranked ones. We see that 
disambiguation repairs almost 50% of the 
previous errors, and increases recalls by about 
10%. With these increases in precision and 
recall, it is clear that the disambiguating step 
provides a considerably more accurate 
morpheme boundary discovery procedure. 
Precision
0.7
0.75
0.8
0.85
0.9
0.95
1
10 20 30 40 50 60 70 80 90 10
0
Deciles(%)
Pr
ec
is
io
n
Without
With
 
Figure 1 Comparison of precision 
 
Compare Recalls 
0.3
0.34
0.38
0.42
0.46
0.5
10 20 30 40 50 60 70 80 90 100
Deciles(%)
R
ec
al
ls
Without
With
Figure 2 Comparison of recall 
33
4.2 Template collapsing 
The second refinement discussed above 
consists of finding pairs of similar templates, 
collapsing them as appropriate, and thus creating 
patterns that generate new words that did not 
participate in the formation of the original 
templates. These new words may or may not 
themselves appear in the corpus. We are, 
however, able to judge their morphological well-
formedness by inspection. We list in Table 3 the 
entire list of eight templates that are collapsed in 
this step. 
All of the templates which are collapsed in 
this step are in fact of the same morphological 
structure (with one very minor exception4): they 
are of the form subject marker + tense marker + 
stem, and the collapsing induced in this 
procedure correctly creates larger templates of 
precisely the same structure, generating new 
words not seen in the corpus that are in fact 
correct from our (non-native speaker) 
inspection. We submitted the new words to 
Yahoo to test the words ?existence? by their 
existence on the internet, and actually found an 
average of 87% of the predicted words in a 
template; see the last column in Table 3 for 
details. 
4.3 Reparsing 
After previous refinements, we obtain a 
number of robust FSAs, for example, those 
collapsed templates in Table 3. With them, we 
then search the corpus for those words that can 
only be partly fitted into these FSAs and 
generate associated stems. Table 4 shows the 
reparsed words that had not been parsed by 
earlier templates and also newly added stems for 
some robust FSAs (the four collapsed templates 
in Table 3).  Stems such as anza ?begin? and 
fanya ?do? are thus added to the first template, 
and all words derived by prepending a tense 
marker and a subject marker are indeed accurate 
words. As the words in Table 4 suggest, the 
reparsing process adds new, common stems to 
the stem-column of the templates, thus making it 
                                                     
4 The exception involves the distinct morpheme po, a 
subordinate clause marker which must ultimately be 
analyzed as appearing in a distinct template column to the 
right of the tense markers. 
easier for the collapsing function to find 
similarities across related templates. 
In future work, we will take use the larger 
templates, populated with more stems, and input 
them to the collapsing function described in 3.2.  
5 Conclusions 
On the basis of the experiments with Swahili 
described in this paper, the SED heuristic 
appears to be a useful tool for the discovery of 
morphemes in languages with rich 
morphologies, and for the discovery of the FSAs 
that constitute the morphologies of those 
languages. 
Ultimately, the value of the heuristic is best 
tested against a range of languages with complex 
concatenative morphologies. While a thorough 
discussion would take us well beyond the limits 
of this paper, we have applied the SED heuristic 
to English, Hungarian, and Finnish as well as 
Swahili. For English, unsurprisingly, the method 
works as well as the SF and PF methods, though 
a bit more slowly, while for Hungarian and 
Finnish, the results appear promising, and a 
comparison with Creutz and Lagus (2004) for 
Finnish, for example, would be appealing. 
34
 
  
One Template 
 
The other template Collapsed Template 
% found on 
Yahoo search 
1 {a}-{ka,na}-{stems} {a}-{ka,ki}-{stems} {a}-{ka,ki,na}-{stems} 86 (37/43) 
2 {wa}-{ka,na}-{stems} {wa}-{ka,ki}-{stems} {wa}-{ka,ki,na}-{stems} 95 (21/22) 
3 {a}-{ka,ki,na}-{stems} {wa}-{ka,ki,na}-{stems} {a,wa}-{ka,ki,na}-{stems} 84 (154/183) 
4 {a}-{liye,me}-{stems} {a}-{liye,li}-{stems} {a}-{liye,li,me}-{stems} 100 (21/21) 
5 {a}-{ki,li}-{stems} {wa}-{ki,li}-{stems} {a,wa}-{ki,li}-{stems} 90 (36/40) 
6 {a}-{lipo,li}-{stems} {wa}-{lipo,li}-{stems} {a,wa}-{lipo,li}-{stems} 90 (27/30) 
7 {a,wa}-{ki,li}-{stems} {a,wa}-{lipo,li}-{stems} {a,wa}-{ki,lipo,li}-{stems} 74 (52/70) 
8 {a}-{na,naye}-{stems} {a}-{na,ta}-{stems} {a}-{na,ta,naye}-{stems} 80 (12/15) 
Table 3  Collapsed Templates and Created Words Sample. 
 
 
 
 
 Template Reparsed Words Not Parsed 
Before 
Added Stems  
1 {a, wa}-{ka,ki,na}-{stems} akawakweza, akiwa, anacho, 
akibatiza,  ? 
toka, anza, waita, fanya, enda, ? 
2 {a}-{li,liye,me }-{stems} ameinuka, ameugua, alivyo,  
aliyoniagiza,  ? 
zaliwa, kuwa, fanya, sema 
3 {a, wa}-{ki,li,lipo}-{stems} alimtoboa,  alimtaka,  
waliamini,  ? 
pata, kuwa, kaa, fanya, chukua, 
fika, ? 
4 {a} ? {na,naye,ta}-{stems} analazwa,  atanitukuza,  anaye,  
anakuita,   ? 
ingia, sema 
Table 4 Reparsed words and "discovered" stems 
 
References 
Creutz, Mathias, and Krista Lagus. (2004). Induction 
of a simple morphology for highly inflecting 
languages. Proceedings of the Workshop of 
SIGPHON (Barcelona). 
Dahan, Delphine, and Michael Brent. (1999). On the 
discovery of novel world-like units from 
utterances. Journal of Experimental Psychology: 
General  128: 165-185. 
Goldsmith, John. (2001).  Unsupervised Learning of 
the Morphology of a Natural Language. 
Computational Linguistics 27(2): 153-198. 
Goldsmith, John, Yu Hu, Irina Matveeva, and Colin 
Sprague. 2005. A heuristic for morpheme 
discovery based on string edit distance. Technical 
Report TR-2005-4. Department of Computer 
Science. University of Chicago. 
Hafer, M. A., Weiss, S. F.  (1974). Word 
segmentation by letter successor varieties. 
Information Storage and Retrieval 10: 371-385. 
Harris, Zellig. (1955). From Phoneme to Morpheme. 
Language 31: 190-222. 
Harris, Zellig. (1967). Morpheme Boundaries within 
Words: Report on a Computer Test. 
Transformations and Discourse Analysis Papers 
73.  
Oliver, Antoni, Irene Bastell?n, and Llu?s M?rquez. 
(2003). Uso de Internet para aumentar la cobertura 
de un sistema de adquisici?n l?xica del ruso. 
SEPLN 2003. 
Wagner, R. A., Fischer, M. J.  (1974). The string-to-
string correction problem. Journal of the 
Association for Computing Machinery 21(1): 168-
73. 
van Zaanen,  Menno. 2000. ABL: Alignment-Based 
Learning. Proceedings of the 17th Conference on 
Computational Linguistics, vol. 2. p. 961-67.
 
35
