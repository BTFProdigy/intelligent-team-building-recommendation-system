Resources for Urdu Language Processing 
Sarmad Hussain 
Center for Research in Urdu Language Processing 
National University of Computer and Emerging Sciences 
B Block, Faisal Town, Lahore, Pakistan 
sarmad.hussain@nu.edu.pk 
 
Abstract 
Urdu is spoken by more than 100 million 
speakers.  This paper summarizes the cor-
pus and lexical resources being developed 
for Urdu by the CRULP, in Pakistan.     
1 Introduction 
Urdu is the national language of Pakistan and one 
of the state languages of India and has more than 
60 million first language speakers and more than 
100 million total speakers in more than 20 coun-
tries (Gordon 2005) .  Urdu is written in Nastalique 
writing style based on Perso-Arabic script.  This 
paper focuses on the Urdu resources being devel-
oped, which can be used for research in computa-
tional linguistics.   
2 Urdu Text Encoding 
Urdu computing started early, in 1980s, creating 
multiple encodings, as a standard encoding scheme 
was missing at that time.  With the advent of Uni-
code in early 1990s, some online publications have 
switched to Unicode, but much of the publication 
still continues to follow the ad hoc encodings 
(Hussain et al 2006).   Two main on-line sources 
of Urdu text in Unicode are Jang News  
(www.Jang.net/Urdu) and BBC Urdu service 
(www.BBC.co.uk/Urdu) and are thus good sources 
of corpus.  Encoding conversion may be required if 
data is acquired from other sources. 
3 Corpora 
EMILLE Project, initiated by Lancaster Univer-
sity is one of the first initiatives to make Urdu cor-
pus available for research and development of lan-
guage processing (McEnery et al 2000).  The pro-
ject has released 200,000 words of English text 
translated into Bengali, Gujarati, Hindi, Punjabi 
and Urdu, creating a parallel corpus across these 
languages.  In addition, the corpus also has 
512,000 words of Spoken Urdu, from BBC Radio.  
Moreover, the corpus also contains 1,640,000 
words of Urdu text.  These Urdu corpus resources 
are also annotated with a large morpho-syntactic 
tag-set (Hardie 2003).   
Center for Research in Urdu Language Process-
ing (CRULP) at National University of Computer 
and Emerging Sciences in Pakistan has also been 
developing corpora and associated tools for Urdu.  
A recent project collected a raw corpus of 19 mil-
lion words of Urdu text mostly from Jang News, 
reduced to 18 million words after cleaning.  The 
corpus collection has been based on LC-STAR II 
guidelines1.  The domain-wise figures are given in 
Table 1.  Further details of the corpus and associ-
ated information are discussed by Ijaz et al (2007). 
 
Table 1: Distribution of Urdu Corpus 
Cleaned Corpus 
Domains Total 
Words 
Distinct 
Words 
C1. Sports/Games 1529066 15354 
C2. News 8425990 36009 
C3. Finance 1123787 13349 
C4. Culture/Entertainment 3667688 34221 
C5. Consumer Information 1929732 24722 
C6. Personal communica-
tions 
1632353 23409 
Total 18308616 50365 
 
Agreement between CRULP and Jang News al-
lows internal use.  However, due to distribution 
restrictions in this agreement, the corpus has not 
been made publicly available.  The distribution 
rights are still being negotiated with Jang News. 
The tag set developed by Hardie (2003) is based 
on morpho-syntactic analysis.  A (much reduced) 
syntactic tag set has also been developed by 
                                                 
1 See www.lc-star.org/docs/LC-STAR_D1.1_v1.3.doc  
The 6th Workshop on Asian Languae Resources, 2008
99
CRULP (on the lines of PENN Treebank tagset), 
available at its website www.CRULP.org.  A cor-
pus of 100,000 words manually tagged on this tag 
set has also been developed based on text from 
Jang online news service.  This CRULP POS 
Tagged Jang News Corpus is available through the 
center.   
Recently another corpus of about 40,000 words 
annotated with Named Entity tags was also made 
available for Workshop on NER for South and 
South East Asian Languages organized at IJCNLP 
2008.  The annotated corpus was donated by 
CRULP and IIIT Hyderabad and is available at 
http://ltrc.iiit.ac.in/ner-ssea-08/index.cgi?topic=5.  
Tag set contains 12 tags.  Details of these tags are 
discussed at the link http://ltrc.iiit.ac.in/ner-ssea-
08/index.cgi?topic=3.  The CRULP portion of the 
data is also available at CRULP website, and is a 
subset of the CRULP POS Tagged Jang News 
Corpus.   
In earlier work at CRULP, a 230 spelling errors 
corpus has also been developed based on typo-
graphical errors in Newspapers and student term 
papers.  See Naseem et al (2007) for details.   
A corpus of Urdu Names has also been devel-
oped by CRULP, based on the collective telephone 
directories of Pakistan Telecommunications Cor-
poration Limited (PTCL) from across all major 
cities of Pakistan.  A name list has also been ex-
tracted from the corpus for all person names, ad-
dresses and cities of Pakistan.   
4 Lexica 
Lexica are as critical for development of language 
computing as corpora.  One of the most 
comprehensive lexica available for Urdu was 
recently released by CRULP (available through 
CRULP website).  The online version, called 
Online Urdu Dictionary (OUD) contains 120,000 
entries, with 80,000 words annotated with 
significant information.  The data of OUD is XML 
tagged, as per the annotation schema discussed by 
Rahman (2005; pp. 15), which contains about 20 
etymological, phonetic, morphological, syntactic, 
semantic and other parameters of information 
about a word.  The dictionary also gives translation 
of 12000 words in English and work is under way 
to enable runtime user-defined queries on the 
available XML tags.  The contents of this lexicon 
are based on the 21 volume Urdu Lughat 
developed by Urdu Dictionary Board of 
Government of Pakistan.  See www.crulp.org/oud 
for details.   
CRULP has also developed a corpus based lexi-
con of 50,000 words with frequency data and an-
notation specifications defined by LC-STAR II 
project (at http://www.lc-star.org/docs/LC-
STAR_D1.1_v1.3.doc).  Details of the lexicon an-
notation scheme are given by Ijaz et al (2007).   
There are also additional tools available through 
CRULP, and documented at its website, including 
normalization, collations, spell checking, POS tag-
ging and word segmentation applications. 
5 Conclusions 
This paper lists some core linguistic resources of 
Urdu, available through CRULP and other sources.  
However, the paper identifies licensing constraints, 
a challenge for open distribution, which needs to 
be addressed.   
References 
Gordon, Raymond G., Jr. (ed.). (2005). Ethnologue: 
Languages of the World, Fifteenth edition. Dallas, 
Tex.: SIL International. Online ver-
sion: http://www.ethnologue.com/. 
Hardie, A. (2003). Developing a tag-set for automated 
part-of-speech tagging in Urdu. In Archer, D, Ray-
son, P, Wilson, A, and McEnery, T (eds.) Proceed-
ings of the Corpus Linguistics 2003 conference. 
UCREL Technical Papers Volume 16. Department of 
Linguistics, Lancaster University, UK. 
Ijaz, M. and Hussain, S. (2007).  Corpus Based Urdu 
Lexicon Development.  In the Proceedings of Con-
ference on Language Technology ?07, University of 
Peshawar, Peshawar, Pakistan. 
Naseem, T. and Hussain, S. (2007).  Spelling Error 
Trends in Urdu.  In the Proceedings of Conference 
on Language Technology ?07, University of Pesha-
war, Peshawar, Pakistan. 
McEnery, A., Baker, J., Gaizauskas, R. & Cunningham, 
H. (2000). EMILLE: towards a corpus of South 
Asian languages, British Computing Society Machine 
Translation Specialist Group, London, UK. 
Rahman, S. (2005).  Lexical Content and Design Case 
Study.  Presented at From Localization to Language 
Processing, Second Regional Training of PAN Local-
ization Project.  Online presentation version: 
http://panl10n.net/Presentations/Cambodia/Shafiq/Le
xicalContent&Design.pdf.  
The 6th Workshop on Asian Languae Resources, 2008
100
Letter-to-Sound Conversion for Urdu Text-to-Speech System  
Sarmad HUSSAIN 
Center for Research in Urdu Language Processing,  
National University of Computer and Emerging Sciences  
B Block, Faisal Town 
Lahore, Pakistan 
sarmad.hussain@nu.edu.pk 
 
Abstract 
Urdu is spoken by more than 100 million 
people across a score countries and is the 
national language of Pakistan (http://www. 
ethnologue.com).  There is a great need for 
developing a text-to-speech system for Urdu 
because this population has low literacy rate 
and therefore speech interface would greatly 
assist in providing them access to information.  
One of the significant parts of a text-to-speech 
system is a natural language processor which 
takes textual input and converts it into an 
annotated phonetic string.  To enable this, it is 
necessary to develop models which map 
textual input onto phonetic content.  These 
models may be very complex for various 
languages having unpredictable behaviour 
(e.g. English), but Urdu shows a relatively 
regular behaviour and thus Urdu pronunciation 
may be modelled from Urdu text by defining 
fairly regular rules.  These rules have been 
identified and explained in this paper. 
1 Introduction 
Text-to-speech synthesis is logically divided into 
two stages.  The first stage takes raw text input, 
processes it and converts it into precise phonetic 
string to be spoken, appropriately annotated with 
prosodic markers (e.g. stress and intonation).  The 
second stage takes this phonetic representation of 
speech and generates the appropriate digital signal 
using a particular synthesis technique.  These 
stages may be referred to as Natural Language 
Processing (NLP) and Speech Synthesis (SS) 
respectively (e.g. Dutoit 1997, p.14).   
For SS, formant based techniques (e.g. Klatt 
1980) or diphone based techniques (e.g. Dutoit 
1997) are normally employed and are generally 
script independent (as they are only dependent on 
temporal and spectral acoustic properties of the 
language and take input in script-neutral form, e.g. 
in IPA).  However, NLP is very dependent on 
cultural and linguistic specific usage of script.   
 
 
NLP may also be divided into further parts.  The 
first component is dedicated to pre-processing, 
?cleaning? and normalizing input text.  Once the 
input text is normalized, the second component 
does phonological processing to generate a more 
precise phonetic string to be spoken.  One of the 
first tasks in the Phonological Processing 
Component is to convert the input text into a 
phonemic string using Letter-to-Sound (LTS) 
rules.  This string is then eventually converted to 
precise phonetic transcription after application of 
sound change rules and other annotations, as 
explained later.  This paper overviews Urdu 
writing system, phonemic inventory, NLP for TTS 
and gives details of the LTS rules for Urdu (also 
see Rafique et at. (2001) and Hussain (1997: 
Appendix A), for introductory work). 
2 Urdu Writing System and Phonemic 
Inventory 
Urdu is written in Arabic script in Nastaleeq 
style using an extended Arabic character set.  
Nastaleeq is a cursive, context-sensitive and highly 
complex writing system (Hussain 2003).  The 
character set includes basic and secondary letters, 
aerab (or diacritical marks), punctuation marks and 
special symbols (Hussain and Afzal 2001, Afzal 
and Hussain 2001).  Urdu is normally written with 
only the letters.  However, the letters represent just 
the consonantal content of the string and in some 
cases (under-specified) vocalic content.  The 
vocalic content can be (optionally) completely 
specified by using the aerab with the letters.  Aerab 
are normally not written and are assumed to be 
known by the native speaker, thus making it very 
hard for a foreigner to read.  Certain aerab are also 
used to specify additional consonants.  Urdu letters 
and aerab are given in Table 1 below.  
 ? ? ? ? ? ? ? ?
? ? ? ? ? ? ? ?
? ? ? ? ? ? ? ?
? ? ? ? ? ? ? ?
   ? ? ? ? ?
        
    ? ? ? ?
        
 ? ? ? ? ? ? ? 
 
Table 1: Urdu basic (top) and secondary 
(middle) letters and aerab (bottom) 
 
Combination of these characters realizes a rich 
inventory of 44 consonants, 8 long oral vowels, 7 
long nasal vowels, 3 short vowels and numerous 
diphthongs (e.g. Saleem et al 2002, Hussain 1997; 
set of Urdu diphthongs is still under analysis).  
This phonemic inventory is given in Table 2.   
The italicized phonemes, whose existence is still 
not determined, are not considered any further (see 
Saleem et al 2002 for further discussion).  
Mapping of this phonetic inventory to the 
characters given in Table 1 is discussed later. 
 
 (a) 
p b p? b? m m?  
t? d? t?? d?? n n?  
? ? ?? ??    
k ? k? ?? ? ??  
t? d? t?? d?? q ?  
f v s z    
? ? x ? h   
r r? ? ?? j l l? 
 
(b) 
i e ? ? 
u o ? ? 
? ? ?  
i? e? ??  
u? o? ?? ?? 
 
Table 2: Urdu (a) Consonantal and (b) Vocalic 
phonemic inventory 
 
3 NLP for Urdu TTS 
As discussed earlier, to enable text-to-speech 
system for any language, a Natural Language 
Processing component is required.  The NLP 
system may have differing requirement for 
different languages.  However, it always takes raw 
text input and always outputs precise phonetic 
transcription for a language.  The system can be 
divided into two parts, Text-Normalization 
Component and Phonological Processing 
Component.  These components may be further 
divided.  A simplified schematic is shown in 
Figure 11. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 1: NLP architecture for Urdu TTS system 
 
                                                     
1 This diagram is based on the architecture of Urdu 
Text to Speech system under development at Center for 
Research in Urdu Language Processing 
(www.crulp.org). 
Tokenizer
Semantic 
Tagger
String 
Generator
Letter to Sound 
Converter
Sound Change 
Manager
Syllabifier 
Stress Marker 
Intonation 
Marker
Urdu Raw 
Text Input
Normalized 
Urdu Text 
Annotated Phonetic 
Output 
The Text Normalization component takes a 
character string as input and converts it into a 
string of letters.  Within it, the Tokenizer uses the 
punctuation marks and space between words to 
mark token boundaries which are then stamped as 
words, punctuation, date, time and other relevant 
categories by the Semantic Tagger.  The String 
Generator takes any non-letter based input (e.g. a 
number or a date containing digits) and converts it 
into a letter string.   
After the input is converted into a string 
comprising only of letters, the Phonological 
Processing Component generates the 
corresponding phonetic transcription.  This is done 
through a series of processes.  The first process is 
to use Letter-to-Sound Converter (detailed below) 
to convert the normalized text input to a phonemic 
string.  This process may also be referred to as 
grapheme-to-phoneme conversion.  This is 
followed by Syllabifier, which marks syllable 
boundaries.  The intermediate output is then 
forwarded to a module which applies Urdu sound 
change rules to generate the corresponding 
phonetic string.  Following these modules, Stress 
Marker and Intonation Marker modules add stress 
and intonation to the string being processed.  Re-
syllabification is also performed after sound 
change rules are applied, in case phones are 
epenthesized or deleted and syllable boundaries 
require re-adjustment.  Urdu shows a reasonably 
regular behavior and most of these tasks can be 
achieved through rule-based systems (e.g. see 
Hussain 1997 for stress assignment algorithm).  
This paper focuses on Letter-to-Sound rules for 
Urdu, the first in the series of modules in 
Phonological Processing Component.   
4 Urdu Letter to Sound Rules 
Urdu shows a very regular mapping from 
graphemes to phonemes.  However, to explain the 
behavior, the letters need to be further classified 
into the following categories: 
 
a. Consonantal characters 
b. Dual (consonantal and vocalic) behavior 
characters 
c. Vowel modifier character 
d. Consonant modifier character 
e. Composite (consonantal and vocalic) character 
 
Similarly, the aerab set can also be divided into 
the following categories: 
 
f. Basic vowel specifier 
g. Extended vowel specifier 
h. Consonantal gemination specifier 
i. Dual (vocalic and consonantal) insertor 
 
Finally, there is a third category which may take 
shape of an letter and aerab: 
 
j. Vowel-aerab placeholder  
 
The Consonantal characters in (a) above always 
represent a consonant of Urdu.  In Urdu, there is 
always a single consonant corresponding to a 
single character of this category, unlike some other 
languages e.g. English maps ?ph? string to 
phoneme /f/.  Most of the Urdu consonantal 
characters fall into this category.  These characters 
and corresponding consonantal phonemes are 
given in Table 3 below.  A simple mapping rule 
would generate the phoneme corresponding to 
these characters.   
 
? ? ? ? ? ? ?
t? d? s ? t? p b 
? ? ? ? ? ? ?
? r z ? d? x h 
? ? ? ? ? ? ? 
t? z s ? s ? z 
? ? ? ? ? ? ?
? k q f ? ? z 
  ? ? ? ? ?
  t? h n m l 
 
Table 3: Consonantal characters and their 
corresponding phonemes 
 
Three characters of Urdu show dual behavior, 
i.e. in certain contexts they transform into 
consonants, but in certain other contexts, they 
transform into vowels.  These characters are Alef 
(?), vao (?), and Yay (? or ?).  Alef acts 
exceptionally in this category and therefore it is 
discussed separately in (j) below.  Vao changes to 
/v/ and Yay changes to the approximant /j/ when 
they occur in consonantal positions (in onset or 
coda of a syllable).  However, when they occur as 
nucleus of a syllable, they form long vowels.  As 
an example, Yay occurs as a consonant when it 
occurs in the onset of single syllable word  ?/Z?  
(/jar/, ?friend?) but is a vowel when it occurs word 
medially in L?? ??Z (/b?l/, ?ox?).  These characters 
represent category (b) listed above. 
There is only one character in category (c), the 
letter Noon Ghunna (?), which does not add any 
additional sound to the string but only nasalizes the 
preceding vowel.  This letter follows and combines 
with the category (b) characters (when occurring as 
vowels) to form the nasal long vowels, e.g. /?? 
(/d??/, ?go?) vs. ?/??  ( /d???/, ?life?).  Catergory 
(d) is the letter Do-Chashmey Hay (?), which 
combines with all the stops and affricates to form 
aspirated (breathy or voiceless) consonants but 
does not add an additional phoneme.  It may also 
combine with nasal stops and approximants to 
form their aspirated versions, though these sounds 
are not clearly established phonetically.  As an 
example, adding this character adds aspiration to 
the phoneme /p/:  LZ? ( /p?l/, ?moment?) vs. L? ?\ 
(/p??l/, ?fruit?).  Finally, there is also a single 
character in category (e), the Alef Madda (?).  This 
character is a stylistic way of writing two Alefs 
and thus represents an Alef in consonantal position 
(see (j) below) and an Alef in vocalic position, 
forming /a/ vowel, e.g. ???  (/?b/, ?now?) vs. ???  
(/?b/, ?water?).   
There are three Basic vowel aerab used in Urdu 
called Zabar (Arabic Fatha), Zer (Arabic Kasra) 
and Pesh (Arabic Damma).  In addition, absence of 
these aerab also define certain vowels and thus this 
absence is referred to as Null aerab.  They combine 
with characters to form vowels according to the 
following principles: 
 
(i) Short vowels, when they occur with category 
(a) and (b) consonants not followed by 
category (b) letters.   
(ii) Long vowels, when they occur with category 
(a) and (b) consonants followed and 
combined by category (b) characters.   
(iii) Long nasal vowels, when they combine with  
category (a) and (b) consonants followed by 
category (b) characters followed by category 
(c) Noon Ghunna.   
 
Different combination of these aerab with 
category (b) characters generate the various 
vowels, as indicated in Table  4 (all vowels shown 
in combination with ? (phoneme /b/) as a 
consonant character is required as a placeholder for 
the aerab).   
 
 
Bay + Zabar ?? ? 
Bay + Zer ?? ? 
Bay + Pesh ?? ? 
   
Bay + NULL + Alef /Z? ? 
Bay + NULL + Vao P?? o 
Bay + Zabar + Vao P??? ? 
Bay + Pesh + Vao P??? u 
Bay + NULL + Yay U^? e 
Bay + Zabar + Yay U?^? ? 
Bay + (NULL | Zer)2 + Yay T?] i 
   
Bay + NULL + Alef + Noon 
Ghunna ?/Z? ?? 
Bay + NULL + Vao + Noon 
Ghunna ?P?? o? 
Bay + Zabar + Vao + Noon 
Ghunna ?P??? ?? 
Bay + Pesh + Vao + Noon 
Ghunna ?P??? u? 
Bay + NULL + Yay + Noon 
Ghunna Z???O e? 
Bay + Zabar + Yay + Noon 
Ghunna Z????O ?? 
                                                     
2 NULL or Zer.  It is controversial whether Zer is 
present for the representation of vowel /i/.  One solution 
is to process both cases till the diction controversy is 
solved. 
Bay + (Null | Zer) + Yay + 
Noon Ghunna  
(see Footnote 2) 
Z???O ? i? 
 
Table 4: Letter and aerab combinations and 
corresponding vowels 
 
Existence of the remaining vocalic phoneme /?/ 
is controversial in Urdu as there is no way of 
expressing it using the Urdu writing system and 
because it is schwa conditioned by the following 
/h/ phoneme and only occurs in this context.  
However, it may exist phonetically e.g. in the word 
<?? (/??h?r/, ?city?) (see discussion in Qureshi, 
1992; also see some supporting acoustic evidence 
in Fatima et. al, 2003, e.g. duration of /?/ is 136 ms 
compared with 235 ms for /?/). 
The next category (g) consists of Khari Zabar.  
This represents the vowel Alef and, whenever 
occurs on top of a Vao or Yay, replaces these 
sounds with the Alef vowel sound /a/ as in words 
?P???  (/z?k?t/,"zakat") and T ????  (/??l?/, special").  
Sporadically Khari Zer and Ulta Pesh are referred 
to in Urdu as well but they generally do not occur 
on Urdu words.  These are not considered here.   
The gemination mark of category (h) is called 
Shad in Urdu and occurs on consonantal characters 
(of categories (a, b) except Alef).  Shad geminates 
the consonant on which it occurs, which is 
normally word medially and inter-vocalically.  As 
a result of gemination, the duplicate consonant acts 
as coda of previous syllable and onset of following 
syllable.  For example, 9?? ( /??.d??/, "a poor 
person") vs. 9???   ( /??d?.d??/, "mattress"). 
The category (i) aerab, called Do-Zabar only 
occurs on Alef (in vocalic position) and converts 
the long vowel /a/ to short schwa followed by 
consonant /n/, e.g. in word ??P??  (/f?r?n/, 
"immediately").  Do-Zer and Do-Pesh are similarly 
referred to in Urdu but are not generatively used 
and are mostly in foreign words especially of 
Arabic and are not considered further here.  If 
considered, they would present a similar analysis.  
Finally, (j) is a very interesting category as it 
represents allo-graphs Alef and Hamza (former a 
character and latter (arguably) an aerab and 
character3).  Both of them are default markers and 
occur in complimentary distribution, Alef always 
word initially and Hamza always otherwise.  As 
discussed earlier, aerab in Urdu always need a 
Kursi (?seat").  If  a short vowel occurs word 
initially without a consonant (i.e. in a syllable 
which has no onset), there is no placeholder for 
aerab.  A default place holder is necessary and Alef 
is used.  Word medially, if there is an onset-less 
syllable, Urdu faces the same problem.  In these 
cases, Hamza (instead of Alef) is used as a 
placeholder for aerab.  There are two further 
possible sub-cases.  In one, the preceding syllable 
is open and ends with a vowel.  This case is very 
frequent and Hamza is introduced inter.-vocalically 
(e.g.  ?/??9? /fa.?d?h/, ?advantage?).  In the second 
less productive sub-case, the preceding syllable is 
closed by a coda consonant. In this case, Hamza is 
(optionally) used with Alef (e.g. both forms are 
correct: ??<?? / ?<? 
?? ??  /d??r.?t/, ?courage?).  
Hindi which employs a different mechanism by 
defining different shapes for vowels word-initially 
and word-medially (Matras).  The Matras are 
anchored onto the consonants, e.g. in Aana? 
vaalaa , ?about to come? vowel /a/ is written as 
Aa word initially, but is written as a word 
medially).   
These rules have been implemented in an on-
going project (see Footnote 1 above) and are 
successfully generating the desired phonemic 
output.  This phonemic output is passed through 
sound change rule module to generate the desired 
phonetic form.   
5 Conclusion 
This paper briefly discusses the architecture of 
Natural Language Processing portion of an Urdu 
Text-to-Speech system.  It explains the details of 
Urdu consonantal and vocalic system and Urdu 
letters. Urdu shows regular behavior and thus the 
phonemic forms are predictable from the textual 
input.  The letter-to-sound rules define this 
                                                     
3 Hamza sometimes requires a Kursi or seat (L?/? and 
not ?/?? ) and sometimes does not (???Z?  and not P???Z? ) 
indicating it behaves both like a character and an aerab.  
It is still unclear on how this behavior is distributed and 
whether it is predictable.  As it is a script centric issue, it 
is not discussed further here. 
mapping and are thus essential for developing 
Urdu TTS.     
6 Acknowledgements 
This work has been partially supported by the 
grant for "Urdu Localization Project: MT, TTS and 
Lexicon" by E-Government Directorate of 
Ministry of IT and Telecommunications, 
Government of Pakistan.   
The author also wishes to thank anonymous 
reviewers for comments, especially on glottal stop 
and Hamza and Tahira Khizar and Qasim Vaince 
for eventual discussion on the role of Hamza in 
Urdu script. 
References  
M. Afzal and S. Hussain. 2001.  Urdu Computing 
Standards: Development of Urdu Zabta Takhti 
(UZT 1.01). Proceedings of IEEE International 
Multi-topic Conference, Lahore, Pakistan. 
T. Dutoit. 1997. An Introduction to Text-to-Speech 
S?ntesis. Kluwer Academic Publishers, 
Dordrecht, The Netherlands. 
N. Fatima and R. Aden.  Vowel Structure of Urdu.  
2003.  CRULP Annual Student Report published 
in Akhbar-e-Urdu,  April-May, National 
Language Authority, Islamabad, Pakistan. 
S. Hussain.  2003.  www.LICT4D.aisa/Fonts/ 
Nafees_Nastalique. Proceedings of 12th AMIC 
Annual Conference on E-Worlds: Governments, 
Business and Civil Society, Asian Media 
Information Center, Singapore. 
S. Hussain. 1997.  Phonetic Correlates of Lexical 
Stress in Urdu. Unpublished Doctoral 
Dissertation, Northwestern University, Evanston, 
USA. 
S. Hussain, and M. Afzal. 2001.  Urdu Computing 
Standards: Urdu Zabta Takhti (UZT 1.01). 
Proceedings of IEEE International Multi-topic 
Conference, Lahore, Pakistan. 
D. H. Klatt. 1980. Software for Cascade/Parallel 
Formant SynthesiZer.  JASA 67: 971-995. 
M. M. Rafique, M. K. Riaz, and S.R. Shahid. 2002.  
Vowel Insertion Grammar. CRULP Annual 
Student Report published in Akhbar-e-Urdu,  
April-May, National Language Authority, 
Islamabad, Pakistan. 
B. A. Qureshi. 1992. Standard Twentieth Centuary 
Dictionary: Urdu to English. Educational 
Publishing House, New Dehli, India. 
A. M. Saleem, H. Kabir, M.K. Riaz, M.M. 
Rafique, N. Khalid, and S.R. Shahid. 2002.  
Urdu Consonantal and Vocalic Sounds. CRULP 
Annual Student Report published in Akhbar-e-
Urdu,  April-May, National Language Authority, 
Islamabad, Pakistan. 
 
Urdu Localization Project: Lexicon, MT and TTS (ULP) 
Sarmad HUSSAIN 
Center for Research in Urdu Language Processing,  
National University of Computer and Emerging Sciences  
B Block, Faisal Town 
Lahore, Pakistan 
sarmad.hussain@nu.edu.pk 
 
Abstract 
Pakistan has a population of 140 million 
speaking more than 56 different languages.  
Urdu is the lingua franca of these people, as 
many speak Urdu as a second language, also 
the national language of Pakistan.  Being a 
developing population, Pakistani people need 
access to information.  Most of the 
information over the ICT infrastructure is only 
available in English and only 5-10% of these 
people are familiar with English.  Therefore, 
Government of Pakistan has embarked on a 
project which will generate software to 
automatically translate the information 
available in English to Urdu.  The project will 
also be able to convert Urdu text to speech to 
extend this information to the illiterate 
population as well.  This paper overviews the 
overall architecture of the project and provides 
briefs on the three components of this project, 
namely Urdu Lexicon, English to Urdu 
Machine Translation System and Urdu Text to 
Speech System. 
1 Introduction 
In today?s information age it is critical to provide 
access to information to people for their 
development.  One precursor to this access is 
availability of information in the native languages.  
Due to limitations in technology, it has not been 
possible to generate information in many 
languages of the world.  However, with recent 
advances in internationalization and localization 
technology, many languages are not enabled.  
However, as this is recent development, the 
published content in these languages is still 
limited, and far lags behind the content available 
for English, Spanish and some other languages 
spoken in developed countries.  Realizing this gap 
in content and the need to provide access to 
information to its citizens, Government of Pakistan 
has recently launched Urdu Localization Project1.  
                                                     
1 Urdu Localization Project is a three-year initiative 
being undertaken by Center for Research in Urdu 
Language Processing (www.crulp.org) and is funded 
This project will enable translation and access of 
English content to literate and illiterate Urdu 
speakers.   
Urdu Localization Project aims to provide access 
to existing English language content to Urdu 
language speakers.  The project has three 
components: Urdu Computational Lexicon, 
English-to-Urdu Machine Translation System, 
Urdu Text-to-Speech system.  This paper briefly 
describes the architecture and work achieved to-
date for different systems within ULP. 
2 ULP Architecture 
As indicated, ULP comprises of three largely 
independent systems: Lexicon, MT and TTS, 
though these components may also be integrated to 
develop a written and oral interface to information.  
The project has three architectural layers.  At the 
base are the core data and engines for Lexicon, MT 
and TTS.  The middle layer provides public 
programming interfaces to these engines (APIs) so 
that they may be integrated with end-user 
applications at the top layer or used by third-party 
applications.  Both the engine and API layer 
components are being developed in standard 
C/C++ to enable them to compile on all platforms 
(e.g. Microsoft, Linux, Unix).  The user-end/top 
layer has to be technology centric and is currently 
being enabled in Microsoft platform.  The lexicon 
will be given a web interface for user access.  In 
addition, plug-ins for internet and email clients will 
be developed for MT and TTS to enable end-users 
to translate and re-display English websites in 
Urdu and also enable them to convert the translated 
Urdu text to speech.  This is shown in Figure 1 
below.  In the figure the layers and systems are 
demarcated (horizontally and vertically 
respectively).  The figure also shows that MT and 
TTS may be using the Lexicon through the APIs 
for getting appropriate data.   
 
                                                                                   
through a grant by E-Government Directorate of 
Ministry of IT&Telecom., Government of Pakistan. 
Figure 1: Architecture Diagram for ULP 
 
These three systems are discussed briefly below.   
 
2.1 Urdu Lexicon 
Urdu Computational Lexicon being designed 
would be holding more than 25 dimensions of a 
single headword.  The first task to date has been to 
determine this hierarchical storage structure.  The 
structure required for end-user has been finalized.  
However, requirements for computational 
applications, e.g. MT, are still being finalized.  
This was perhaps one of the most challenging tasks 
as there are currently no standards which exist, 
although some guidelines are available.  In 
addition, Urdu also had some additional 
requirements (e.g. multiple plural forms, 
depending on whether the word is derived from 
Arabic or Sanskrit).  Entries of more than thirty 
thousand headwords and complete entry of about a 
thousand headwords along with specification of at 
least 15 entries has already been done.  Currently 
more content is being generated.  In addition, work 
is under progress to define the physical structure of 
the lexicon (e.g. storage and retrieval models).  
The prototype showing this application is also 
available in Microsoft platform. 
2.2 English-Urdu Machine Translation 
Work is under progress to develop English to 
Urdu MT engine.  The translation is based on LFG 
formalism and is developing grammars, lexica and 
the parsing/mapping/generation engine for LFG.  
Mapping and Generation prototypes have already 
been developed and are integrated with a freely 
available LFG parser for internal testing.  In 
addition sample grammars for English, Urdu and 
English-Urdu mapping have also been written.  
The prototype covers about 10 percent of 
grammatical rules and already translates within the 
limited vocabulary of the engine.  The work is 
being extended to write the parser and rewrite 
mapper and generator and to develop English, 
Urdu and English Urdu grammars and lexica. 
2.3 Urdu Text to Speech System 
The Urdu TTS is divided into two main part, the 
Urdu Natural Language Processor and Urdu 
Speech Synthesizer.  The work on NLP is 
completed (except the intonational module, on 
which preliminary work has been completed).  The 
NLP processor inputs Urdu Unicode text and 
output narrow phonetic transcription with syllable 
and stress markers.  The NLP processor is 
integrated with Festival speech synthesis system 
(though by-passes its NLP module).  A vocabulary 
of about 500 words is already defined at the 
diphones have been created.  Prototype application 
is already developed which synthesized these 
single words.  Work is currently in progress to 
define Urdu intonational and durational model.  In 
addition, work is also under progress to extend the 
vocabulary and functionality to synthesize 
complete sentences.  The functional prototype 
works on both Linux an Microsoft platforms. 
3 Conclusion 
Most of the work being done in the project is 
novel.  Urdu language is not very well defined for 
use with computers.  Script, speech and language 
aspects of Urdu are being studied, documented and 
implemented in this project.  The project is also 
testing the work which has been matured on 
western languages but only being recently exposed 
to other languages, e.g. the lexical 
recommendations by ISLE, LFG framework, use 
of LFG for MT, speech modeling of Urdu (both 
spectral and temporal) and more.  Non-functional 
issues including performance are also being 
negotiated.  Pre-compiled lexica, user-centric pre-
stored performance-enhancing profiles and 
frequency lists, etc. are part of the architectural 
tasks being addressed.  Though only initial work 
has been done, this work in itself is substantial, and 
has raised many questions which will be answered 
as the project progresses.   
MT 
Engine 
Lexicon 
Engine 
TTS 
Engine 
MT API Lexicon 
API
TTS API
Website/ 
Email 
Translator 
Online 
Urdu 
Dictionary 
Website/ 
Email 
Reader 
End User Third Party 
Applications
Proceedings of the 7th Workshop on Asian Language Resources, ACL-IJCNLP 2009, pages 24?31,
Suntec, Singapore, 6-7 August 2009. c?2009 ACL and AFNLP
 
 
Analysis and Development of Urdu POS Tagged Corpus 
 
Ahmed Muaz 
Center for Research in Urdu 
Language Processing 
NUCES, Pakistan 
ahmed.muaz@nu.edu.pk 
 
Aasim Ali 
Center for Research in Urdu 
Language Processing,  
NUCES, Pakistan 
aasim.ali@nu.edu.pk 
 
Sarmad Hussain 
Center for Research in Urdu 
Language Processing 
NUCES, Pakistan 
sarmad.hussain@nu.edu.pk
 
Abstract 
In this paper, two corpora of Urdu (with 110K 
and 120K words) tagged with different POS 
tagsets are used to train TnT and Tree taggers. 
Error analysis of both taggers is done to identi-
fy frequent confusions in tagging. Based on 
the analysis of tagging, and syntactic structure 
of Urdu, a more refined tagset is derived.  The 
existing tagged corpora are tagged with the 
new tagset to develop a single corpus of 230K 
words and the TnT tagger is retrained.  The re-
sults show improvement in tagging accuracy 
for individual corpora to 94.2% and also for 
the merged corpus to 91%.  Implications of 
these results are discussed.    
1 Introduction 
There is increasing amount of work on computa-
tional modeling of Urdu language.  As various 
groups work on the language, diversity in analy-
sis is also developed.  In this context, there has 
been some work on Urdu part of speech (POS) 
tagging, which has caused multiple tagsets to 
appear.  Thus, there is also need to converge 
these efforts.  
Current work compares the existing tag-
sets of Urdu being used for tagging corpora in an 
attempt to look at the differences, and understand 
the reasons for the variation.  The work then un-
dertakes experiments to develop a common tag-
set, which is syntactically and computationally 
coherent.  The aim is to make a robust tagset and 
then to port the differently tagged Urdu corpora 
onto the same tagset.  As Urdu already has very 
few annotated corpora, this will help consolidat-
ing them for better modeling. 
The next sections present the existing tag-
sets and accuracies of the POS taggers reported 
using them. Sections 4 and 5 present baseline 
experiment and the methodology used for the 
analysis for updating the tagset. Section 6 de-
scribes the proposed tagset. Section 7 reports 
experiments comparing the new tagset with ex-
isting ones. Section 8 discusses the results 
achieved and future directions. 
2 Relevant  Resources of Urdu 
2.1 Urdu Corpora  
Several annotated corpora have been built during 
last few years to facilitate computational 
processing for Urdu language.  The initial work 
was undertaken through EMILLE project to 
build multi-lingual corpora for South Asian lan-
guages (McEnery et al, 2000). They released 
200,000 words parallel corpus of English, Urdu, 
Bengali, Gujarati, Hindi and Punjabi. In addition, 
there are 1,640,000 words of Urdu text in this 
corpus. These text collections are also annotated 
with part of speech tags (Hardie 2003).  
Center for Research in Urdu Language 
Processing (CRULP1) gathered 18 million words 
corpus in order to build a lexicon. It has cleaned 
text from news websites from multiple domains 
(Ijaz et.al. 2007).  Following this work, a syntac-
tic tagset was developed based on work by exist-
ing grammarians and a corpus of 110,000 words 
was manually tagged. This annotated corpus is 
available through the center (Sajjad 2007, Hus-
sain 2008). 
Recently an English-Urdu parallel cor-
pus has also been developed by CRULP, by 
translating the first 140,000 words of PENN 
Treebank corpus. In addition, a tagset has also 
been designed following the PENN Treebank 
guidelines. These words have been tagged ma-
nually with this new tagset. This collection is 
also available from CRULP, and the tagset is still 
unpublished.  
2.2 Urdu Part of Speech tagsets 
Hardie (2003) developed the first POS tagset for 
Urdu using EAGLES guidelines for computa-
tional processing. The tagset contains 282 mor-
pho-syntactic tags, differentiating on the basis of 
number, gender and other morphological details 
                                                 
1 www.crulp.org  
24
 
 
in addition to the syntactic categories. Punctua-
tion marks are tagged as they are, and not in-
cluded in 282 tags. The tags include the gender 
and number agreement, in addition to syntactic 
information.  
The complications of Urdu tagset design 
are also discussed. One of these complexities is 
word segmentation issue of the language. Suffix-
es in Urdu are written with an orthographic 
space. Words are separated on the basis of space 
and so suffixes are treated same as lexical words. 
Hence it is hard to assign accurate tag for an au-
tomatic tagger. Although the tagset is designed 
considering details, but due to larger number of 
tags it is hard to get a high accuracy with a small 
sized corpus. Due to its morphological depen-
dence and its large size, this tagset is not consi-
dered in our analysis.   
Two much smaller tagsets are considered 
for this work.  They are compared in detail in 
Section 6.  The first tagset, containing 42 tags, is 
designed by Sajjad (2007), based on the work of 
Urdu grammarians (e.g. Schmidt 1999, Haq 
1987, Javed 1981, Platts 1909) and computation-
al work by Hardie (2003). The main features of 
the tagset include multiple pronouns (PP, KP, 
AKP, AP, RP, REP, G, and GR) and demonstra-
tives (PD, KD, AD, and RD). It has only one tag 
for all forms of verbs (VB), except for auxiliaries 
to show aspect (AA) and tense (TA) information 
about the verb. All noun types are assigned sin-
gle tag (NN) except for Proper Nouns (PN). It 
also has a special tag NEG to mark any occur-
rence negation words (?Yl? ?not? and ?? ?no? or 
?neither?) regardless of context. It also has a tag 
SE to mark every occurrence of ?5 (?from?) 
without considering the context. Another exam-
ple of such a context-free lexical tag is WALA to 
mark every occurrence (including all the inflec-
tions) of the word ???. This tagset is referred to as 
T1 subsequently in this paper.   
Recently Sajjad and Schmid (2009) used 
the tagged data of 107,514 words and carried out 
an experiment for tagger comparison.  A total of 
100,000 words are used as training set and rest as 
test data. Four taggers (TnT, Tree, RF and SVM) 
are trained using training corpus and then tested 
accordingly. Reported results of this work show 
that SVM tagger is the most accurate, showing 
94.15% correct prediction of tags. Remaining 
three taggers have accuracies of 93.02% (Tree 
tagger), 93.28% (RF tagger) and 93.40% (TnT 
tagger).   
 
Another tagset has recently been devel-
oped as a part of a project to develop English-
Urdu parallel corpus at CRULP, following the 
Penn Treebank guidelines (Santorini 1990).  It 
contains 46 tags, with fewer grades of pronouns 
(PR, PRP$, PRRF, PRRFP$, and PRRL) and 
demonstratives (DM and DMRL), as compared 
to T1. It has several tags for verbs on the basis of 
their forms and semantics (VB, VBI, VBL, 
VBLI, and VBT) in addition to the tags for aux-
iliaries showing aspect (AUXA) and tense 
(AUXT). The NN tag is assigned for both singu-
lar and plural nouns and includes adverbial kaf 
pronoun, kaf pronoun, and adverbial pronoun 
categories of T1. Yet, it has several other grades 
of common nouns (NNC, NNCR, NNCM). It 
also has two shades of Proper Nouns (NNP, 
NNPC), which are helpful in identifying phrase 
boundary of compound proper nouns. It also has 
a tag WALA that is assigned to every occurrence 
(and inflection) of word ??? )wala( . However, 
marking of token ?5 (?from?) is context depen-
dent: either it is CM when marking case or it is 
RBRP when occurring as an adverbial particle. 
This tagset is referred to as T2 subsequently in 
this paper. 
3 Tools and Resource Selection 
The decision of selecting the tagger, the tagset, 
and the data is the starting point for the task of 
POS tagging. This section gives details of the 
taggers chosen and the corpora used for the expe-
riments conducted.  
3.1 Selection of taggers 
There are a number of existing taggers available 
for tagging.  Two POS taggers are used in the 
initial step of this work to compare the initial 
tagging accuracies. 
 One of the selected taggers is Trigram-
and-Tag (TnT).  It is a trigram based HMM tag-
ger in which two preceding tags are used to find 
the transition probability of a tag. Brants (2000) 
tested PENN Treebank (English) and NEGRA 
(German) corpora and reported 96-97% accuracy 
of the tagger.  
Schmid (1994) proposed probabilistic 
POS tagger that uses decision trees to store the 
transition probabilities. The trained decision tree 
is used for identification of highest probable tags. 
Schmid reported an accuracy of 95-96% on 
PENN Treebank for this tagger. 
25
 
 
Both taggers give good accuracy for Ur-
du tagging, as reported by Sajjad and Schmid 
(2009). 
3.2 Data Used for Experimentation 
Corpora annotated with the different tagsets are 
acquired from CRULP. The corpus originally 
tagged with T1 tagset is referred to as C1 (news 
from non-business domain) and the corpus in-
itially annotated with T2 tagset is referred to as 
C2 (news from business domain), subsequently 
in the current work. Both C1 and C2 are taken 
and cleaned. The data is re-counted and approx-
imately 100,000 words are separated for training 
and rest are kept for testing.  The details of data 
are given in Tables 1 and 2 below. 
 
Table 1. Number of tokens in Urdu corpora 
 
Tokens C1 C2 
Training 101,428 102,454 
Testing 8,670 21,181 
Total 110,098 123,635 
 
Table 2. Number of sentences in Urdu corpora 
 
Sentences C1 C2 
Training 4,584 3,509 
Testing 404 755 
Total 4,988 4,264 
4 Baseline Estimation 
The comparison is initiated with training of ex-
isting tagsets on their respective annotated data 
(T1 on C1 and T2 on C2). Both corpora are 
tested on TnT and Tree Tagger to obtain the con-
fusion matrices for errors. These confusion ma-
trices are used to analyze misclassification of 
tags. TnT tagger shows that overall accuracy of 
using T1 with C1 is 93.01% and is significantly 
better than using T2 with C2, which gives 
88.13% accuracy.  Tree tagger is also trained on 
the corpora. The overall accuracy of T1 on C1 
(93.37%) is better than that of T2 on C2 
(90.49%).  The results are shown in Table 3. 
 
Table 3. Results of both tagsets on their respec-
tive corpora with TnT and Tree taggers 
 
  T1 on C1 T2 on C2 
TnT Tagger 93.01% 88.13% 
Tree Tagger 93.37% 90.49% 
 
The accuracies reported (for T1 on C1) by 
Sajjad and Schmid (2009) are comparable to 
these accuracies. They have reported 93.40% for 
TnT Tagger and 93.02% for Tree Tagger. 
Further experimentation is performed only 
using TnT tagger.  
5 Methodology 
The current work aims to build a larger corpus of 
around 230,000 manually tagged words for Urdu 
by combining C1 and C2. These collections are 
initially annotated with two different tagsets (T1 
and T2 respectively, and as described above). 
For this unification, it was necessary to indentify 
the differences in the tagsets on which these cor-
pora are annotated, analyzed the differences and 
then port them to unified tagset. 
The work starts with the baseline estimation 
(described in Section 4 above). The results of 
baseline estimation are used to derive a new tag-
set (detailed in Section 6 below), referred to as 
T3 in this paper. Then a series of experiments are 
executed to compare the performance of three 
tagsets (T1, T2, and T3) on data from two differ-
ent domains (C1 and C2), as reported in Section 
7 below and summarized in Table 4.  
 
Table 4. Summary of experiments conducted 
 
 Experiment Tagset Corpus
0 
Baseline Estimation: 
Original tagsets with 
respective corpora 
T1 C1 
T2 C2 
1 Experiment1: For 
comparison of results 
of T1 and T3 on C1 
T3 C1 
2 
Experiment2: For 
comparison of T1, T2 
and T3 on C2 
T3 C2 
T1 C2 
3 
Experiment3: Compar-
ison of T1 and T3 with 
no unknowns 
T3 C2 
T1 C2 
4 
Experiment4: Compar-
ison of T1 and T3 over 
complete corpus 
T3 C1+C2 
T1 C1+C2 
 
The performance of T1 on C1 is already 
better than T2 on C2, so the first comparison for 
the merged tagset T3 is with T1 on C1, which is 
the basis of the first experiment. Then the per-
formance of better performing tagsets (T1 and 
T3) are compared on the corpus C2 in the second 
26
 
 
experiment to compare them with T2. One possi-
ble reason of relatively better performance could 
be the difference in application of open classes 
for unknown words in the test data. Therefore, 
the third experiment is performed using the same 
data as in second experiment (i.e. corpus C2) 
with combined lexicon of training and test data 
(i.e. no unknown words). Finally, an experiment 
is conducted with the merged corpus. Following 
table summarizes these experiments. 
6 Tagset design 
After establishing the baseline, the existing tag-
sets are reviewed with the following guidelines: 
? Focus on the syntactic variation (instead of 
morphological or semantic motivation) to ei-
ther collapse existing tags or introduce new 
ones 
? Focus on word level tagging and not try to ac-
commodate phrase level tagging (e.g. to sup-
port chunking, compounding or other similar 
tasks) 
? Tag according to the syntactic role instead of 
having a fixed tag for a string, where possible 
? Use PENN Treebank nomenclature to keep the 
tagset easy to follow and share 
 
Comparison of T1 and T2 showed that there 
are 33 tags in both tagsets which represent same 
syntactic categories, as shown in Appendix A. 
The tag I (Intensifier) in T2 labels the words 
which are marked as ADV in T1. The words an-
notated as NNC, NNCR and NNCM (under T2) 
are all labeled as NN under T1. The words 
tagged as VBL, VBLI, VBI, and VBLI (under 
T2) are all labeled as VB under T1. Range of 
distinct tags for demonstratives of T1 are all 
mapped to DM in T2 except RD (of T1) which 
maps to DMRL (of T2). 
In order to identify the issues in tagging, a 
detailed error analysis of existing tagsets is per-
formed. Following tables represent the major tag 
confusions for tagging C2 with T2 using Tree 
and TnT taggers. 
 
Table 5. Major misclassifications in C2 with T2 
tagset using Tree tagger 
Tag 
Total 
tokens Errors  
Maximum  
misclassification
VB 888 214 183 VBL 
VBL 328 168 151 VB 
VBI 202 47 38 VBLI 
VBLI 173 52 46 VBI 
AUXT 806 145 121 VBT 
Table 6. Major misclassifications in C2 with T2 
tagset using TnT-tagger 
Tag 
Total 
tokens Error  
Maximum  
misclassification
VB 888 240 181 VBL 
VBL 328 154 135 VB 
VBI 202 46 34 VBLI 
VBLI 173 61 55 VBI 
AUXT 806 136 111 VBT 
 
The proposed tagset for Urdu part-of-
speech tagging contains 32 tags. The construc-
tion of new tagset (T3) is initiated by adopting 
T2 as the baseline, because T2 uses the tagging 
conventions of PENN Treebank. There are 17 
tags in T3 that are same as in T1 and T2. These 
tags (CC, CD, DM, DMRL, JJ, NN, OD, PM, 
PRP, PRP$, PRRF, PRRF$, PRRL, Q, RB, SM, 
SYM) are not discussed in detail. The complete 
tagset alng with short description and examples 
of each tag is given in Appendix B. 
RBRP (Adverbial Particle) and CM 
(Case Marker) are merged to make up a new tag 
PP (Postposition), so every postposition particle 
comes under this new tag ignoring semantic con-
text. I (Intensifier) is used to mark the intensifi-
cation of an adjective, which is a semantic grada-
tion, and syntactically merged with Q (Quantifi-
er). NNCM (Noun after Case Marker), NNC 
(Noun Continuation), NNCR (Continuing Noun 
Termination) are merged into NN (Noun) be-
cause syntactically they always behave similarly 
and the difference is motivated by phrase level 
marking.   U (Unit) is also merged with NN be-
cause the difference is semantically motivated.   
DATE is not syntactic, and may be either 
treated as NN (Noun) or CD (Cardinal), depend-
ing upon the context. Similarly, R (Reduplica-
tion), MOPE (Meaningless Pre-word), and MO-
PO (Meaningless Post-word) always occur in 
pair with NN, JJ, or another tag.  Thus they are 
phrasal level tags, and can be replaced by rele-
vant word level tag in context. NNPC (Proper 
Noun Continuation) tag identifies compounding 
but syntactically behaves as NNP (Proper Noun), 
and is not used.  
VBL (Light Verb) is used in complex predi-
cates (Butt 1995), but its syntactic similarity with 
VB (Verb) is a major source of confusion in au-
tomatic tagging.  It is collapsed with VB (Verb). 
Similarly, VBLI (Light Verb Infinitive) is 
merged with VBI (Verb Infinitive). AUXT 
(Tense Auxiliary) is highly misclassified as VBT 
(To be Verb) because both occur as last token in 
a clause or sentence, and both include tense in-
27
 
 
formation. The word is labeled as VBT only 
when there is no other verb in the sentence or 
clause, otherwise these words are tagged as 
AUXT. The syntactic similarity of both tags is 
also evident from statistically misclassifying 
AUXT as VBT.  Therefore both are collapsed 
into single tag VBT (Tense Verb). 
In T1, NEG (Negation) is used to mark all 
the negation words without context, but they 
mostly occur as adverbs.  Therefore, NEG tag is 
removed. Similarly, SE (Postposition ?5 , 
?from?) is not separated from postpositions and 
marked accordingly. PRT (Pre-Title) and POT 
(Post-Title) always occur before or after Proper 
Noun, respectively. Therefore, they behave as 
Proper Nouns, hence proposed to be labeled as 
NNP (Proper Noun). 
7 Experiments 
After designing a new tagset, a series of experi-
ments are conducted to investigate the proposed 
changes. The rationale of the sequence of expe-
riments has been discussed in Section 5 above, 
however the reasoning for each experiment is 
also given below. As T2 tags have much more 
semantic and phrasal information, and C2 tagged 
with T2 shows lower accuracy than T1 on C1, 
therefore further experiments are conducted to 
compare the performance of T1 and T3 only.  
Comparisons on C2 with T3 may also be drawn. 
7.1 Experiment 1 
As baseline estimation shows that T1 on C1 out-
performs T2 on C2, the first experiment is to 
compare the performance of T3 on C1. In this 
experiment C1 is semi-automatically tagged with 
T3. TnT tagger is then trained and tested. T3 
gives 93.44% accuracy, which is slightly better 
than the results already obtained for T1 
(93.01%). The results are summarized in Table 7. 
 
Table 7. Accuracies of T3 and T1 on C1  
 
Corpus Tagset Accuracy
C1 T3 93.44% 
C1 T1 93.01% 
7.2 Experiment 2 
Now to test the effect of change in domain of the 
corpus, the performance T1 and T3 on C2 is 
compared in this experiment. C2 is manually 
tagged with T3, then trained and tested using 
TnT tagger. The results obtained with T3 are 
91.98%, which are significantly better than the 
results already obtained for T2 on C2 (88.13%). 
C2 is also semi-automatically re-tagged 
with T1. T1 shows better performance (91.31%) 
than T2 (88.13%). However, the accuracy of us-
ing T3 (on C2) is still slightly higher.  The re-
sults are summarized in Table 8. 
 
Table 8. Accuracies of T3 on C1, and accura-
cies of T3 and T1 on C2 
 
Corpus Tagset Accuracy 
C2 T3 91.98% 
C2 T1 91.31% 
7.3 Experiment 3 
Due to the change in open class set there may be 
a difference of performance on unknown words, 
therefore in this experiment, all the unknown 
words of test set are also included in the vocabu-
lary. This experiment again involves T3 and T1 
with C2. Combined lexica are built using testing 
and training parts of the corpus, to eliminate the 
factor of unknown words. This experiment also 
shows that T3 performs better than T1, as shown 
in Table 9. 
 
Table 9. Accuracies of T3 and T1 with ALL 
known words in test data 
 
Corpus Tagset Accuracy 
C2 T3 94.21% 
C2 T1 93.47% 
7.4 Experiment 4 
Finally both corpora (C1 and C2) were com-
bined, forming a training set of 203,882 words 
and a test set of 29,851 words. The lexica are 
generated only from the training set. Then TnT 
tagger is trained separately for both T1 and T3 
tagsets and the accuracies are compared. The 
results show that T3 gives better tagging accura-
cy, as shown in Table 10. 
 
Table 10. Accuracies of T3 and T1 using 
combined C1 and C2 corpora 
 
Corpus Tagset Accuracy 
C1+C2 T3 90.99% 
C1+C2 T1 90.00% 
 
Partial confusion matrices for both the tag-
sets are given in Tables 11 and 12.   
28
 
 
The error analysis shows that the accuracy 
drops for both tagsets when trained on multi-
domain corpus, which is expected.  The highest 
error count is for the confusion between noun 
and adjective.  There is also confusion between 
proper and common nouns.  T3 also gives signif-
icant confusion between personal pronouns and 
demonstratives, as they represent the same lexi-
cal entries.   
 
Table 11. Major misclassifications in merged 
corpus with T1 using TnT tagger 
 
Tag 
Total 
tokens Error  
Maximum  
misclassification
A 18 5 3 ADJ 
AD 18 7 4 ADJ 
ADJ 2510 551 371 NN 
ADV 431 165 59 ADJ 
INT 8 6 6 ADV 
KD 16 9 6 Q 
KER 77 28 19 P 
NN 7642 548 218 PN 
OR 75 24 9 Q 
PD 205 55 12 PP 
PN 2246 385 264 NN 
PP 239 51 11 PD 
Q 324 119 53 ADJ 
QW 24 12 11 VB 
RD 71 62 61 RP 
RP 11 5 2 NN 
U 24 8 8 NN 
 
Table 12. Major misclassifications in merged 
corpus with T3 using TnT tagger 
 
Tag 
Total 
tokens Error  
Maximum  
misclassification
CVRP 77 24 15 PP 
DM 242 77 58 PRP 
DMRL 71 64 63 PRRL 
INJ 8 6 6 RB 
JJ 2510 547 376 NN 
JJRP 18 4 4 JJ 
NN 7830 589 234 NNP 
NNP 2339 390 267 NN 
OD 75 23 8 JJ 
PRP 642 119 33 DM 
 
8 Discussion and Conclusion 
The current work looks at the existing tagsets of 
Urdu being used for tagging corpora and analyz-
es them from two perspectives.  First, the tagsets 
are analyzed to see their linguistic level differ-
ences.  Second, they are compared based on their 
inter-tag confusion after training with two differ-
ent POS taggers.  These analyses are used to de-
rive a more robust tagset.   
The results show that collapsing categories 
which are not syntactically motivated improves 
the tagging accuracy in general.  Specifically, 
light and regular verbs are merged, because they 
may come in similar syntactic frames.  Redupli-
cated categories are given the same category tag 
(instead of a special repetition tag).  Units and 
dates are also not considered separately as the 
differences have been semantically motivated 
and they can be categorized with existing tags at 
syntactic level.   
Though, the measuring unit is currently 
treated as a noun, it could be collapsed as an ad-
jective as well.  The difference is sometimes lex-
ical, where kilogram is more adjectival, vs. 
minute is more nominal in nature in Urdu, 
though both are units.    
NNP (Proper Noun) tag could also have 
been collapsed with NN (Common Noun), as 
Urdu does not make clear between them at syn-
tactic level.  However, these two tags are kept 
separate due to their cross-linguistic importance.  
One may expect that extending the genre or 
domain of corpus reduces accuracy of tagging 
because of increase in the variety in the syntactic 
patterns and diverse use of lexical items. One 
may also expect more accuracy with increase in 
size.  The current results show that effect on ad-
ditional domain (when C1 and C2 are mixed) is 
more pronounced than the increase in size (from 
approximately 100k to 200k), reducing accuracy 
from 94.21% (T3 with C2) to 90.99% (T3 with 
C1 + C2).  The increase in accuracy for T3 vs. 
T1 may be caused by reduced size of T3.  How-
ever, the proposed reduction does not compro-
mise the syntactic word level information, as the 
collapsed categories are where they were either 
semantically motivated or motivated due to 
phrasal level tags. 
The work has been motivated to consolidate 
the existing Urdu corpora annotated with differ-
ent tagsets.  This consolidation will help build 
more robust computational models for Urdu.   
References 
Brants, T. 2000. TnT ? A statistical part-of-speech 
tagger. Proceedings of the Sixth Applied Natural 
Language Processing Conference ANLP-2000 
Seattle, WA, USA. 
29
 
 
Butt, M.  1995.  The structure of complex predicates 
in Urdu. CSLI, USA.  ISBN: 1881526585. 
Haq, A,. 1987. ?\?a ?a??Da ????  Amjuman-e-Taraqqi 
Urdu.   
Hardie, A. 2003. Developing a tag-set for automated 
part-of-speech tagging in Urdu. Archer, D, Rayson, 
P, Wilson, A, and McEnery, T (eds.) Proceedings 
of the Corpus Linguistics 2003 conference. UCREL 
Technical Papers Volume 16. Department of Lin-
guistics, Lancaster University, UK.  
Hussain, S. 2008. Resources for Urdu Language 
Processing.  The Proceedings of the 6th Workshop 
on Asian Language Resources, IJCNLP?08, IIIT 
Hyderabad, India. 
Ijaz, M. and Hussain, S. 2007. Corpus Based Urdu 
Lexicon Development. The Proceedings of Confe-
rence on Language Technology (CLT07), Universi-
ty of Peshawar, Pakistan. 
Javed, I.  1981.  ?<??Ka ????a t5?aTaraqqi Urdu Bureau, 
New Delhi, India. 
Platts, J. 1909. A grammar of the Hindustani or Urdu 
language.  Reprinted by Sang-e-Meel Publishers, 
Lahore, Pakistan. 
Sajjad, H.  2007.  Statistical Part of Speech Tagger for 
Urdu.  Unpublished MS Thesis, National Universi-
ty of Computer and Emerging Sciences, Lahore, 
Pakistan. 
Sajjad, H. and Schmid, H. 2009. Tagging Urdu Text 
with Parts Of Speech: A Tagger Comparison.12th 
conference of the European chapter of the associa-
tion for computational Linguistics 
Santorini, B. 1990. Part_of_Speech Tagging Guide-
lines for the Penn Treebank Project (3rd printing, 
2nd revision). Accessed from 
ftp://ftp.cis.upenn.edu/pub/treebank/doc/tagguide.ps.gz 
on 3rd May, 2009. 
Schmid, H. 1994.  Probabilistic part-of-speech tag-
ging using decision trees. Institut f?r Maschinelle 
Sprachverarbeitung, Universit?t Stuttgart, Germa-
ny. 
Schmidt, R. 1999. Urdu: an essential grammar. Rout-
ledge, London, UK. 
McEnery, A., Baker, J. Gaizauskas, R. and Cunning-
ham, H. 2000. EMILLE: towards a corpus of South 
Asian languages, British Computing Society Ma-
chine Translation Specialist Group, London, UK.  
 
 
 
 
 
 
Appendix A: Mappings of tags between Tag-
sets T1 and T2. 
 
 Tagset T1 Tagset T2 
1.  A JJRP 
2.  AA AUXA 
3.  ADJ JJ 
4.  ADV RB 
5.  CA CD 
6.  CC CC 
7.  DATE DATE 
8.  EXP SYM 
9.  FR FR 
10.  G PRP$ 
11.  GR PRRFP$ 
12.  I ITRP 
13.  INT INJ 
14.  KER KER 
15.  MUL MUL 
16.  NN NN 
17.  OR OD 
18.  P CM 
19.  PD DM 
20.  PM PM 
21.  PN NNP 
22.  PP PR 
23.  Q Q 
24.  QW QW 
25.  RD DMRL 
26.  REP PRRL 
27.  RP PRRF 
28.  SC SC 
29.  SE RBRP 
30.  SM SM 
31.  TA AUXT 
32.  U U 
33.  WALA WALA 
30
 
 
Appendix B: New Tagset T3. 
 
 Tag Meaning Example 
1. AUX Auxiliary a?La?gTWO?5hBa?P a May 
2. CC Coordinate Conjunction asYO??O??a?????a?5a?????a??lHat5O?h@ a Or 
3. CD Cardinal ???a?La??????a???>?O a One 
4. CVRP Conjunctive Verb Par-ticle 
avY?a??jKat?Y^???J?La??at5??a?7a?5?Q?6a??WJat?6aa After  
5. DM Demonstrative a???7????aa??a??dK??a?58a?6?6?a?5a?5?P a Like this 
6. DMRL Demonstrative Relative 
a?5a?????at5H?C?a???>aa23??aa?5?a??a?8a??B
a?Y?a
That 
7. FR Fraction ?5??a?YOa?5WmM a Half 
8. INJ Interjection ???a!?5a?6?a?YL a Hurrah 
9. ITRP Intensive Particle a??a?m8a??lMa??t5a???a?5??at5?6 a Too 
10. JJ Adjective ?8a?Wj6a?8?Ba?5a??TM? a Taller 
11. JJRP Adjective Particle apl6at5a?5??a???6t5a?Y?a?5hBa??Ba?La????>? a As 
12. MRP Multiplicative Particle at5M??K? a Double 
13. NN Noun ??Baa?5??I?aa?YO??P??J?a?7 a Year 
14. NNP Proper Noun a???6?a?lLa?5 a Robert 
15. OD Ordinal ?l7a?6?`WOaqWO?<?U?? a First 
16. PM Phrase Marker ?a , 
17. PP Postposition ?5?Pa?5?Q?6a?8a??apYWL?a?6??a To 
18. PRP Pronoun Personal 
??aa???La?W^7a???Pa???a?5a??kdTB?a?La???a???F
?5a
They 
19. PRP$ Pronoun Personal  Possessive 
??YOa?5at???a?WYMa?Y? a My 
20. PRRF Pronoun Reflexive a?5??a?5at5SkL??at5?]6a?L a Oneself 
21. PRRF$ Pronoun Reflexive  Possessive 
?5??a?8?J?at5?kT>? a Own 
22. PRRL Pronoun Relative 
a?5a?????at5H?C?a???>aa23??aa?5?a??a?8a??B
a?Y?a
That 
23. Q Quantitative ?W?a??N a Some 
24. QW Question Word a?W`Oa?????YLa??a??LasYg? a Why 
25. RB Adverb ?_YkPat5Mat5Y? a Always 
26. SC Subordinate Conjunction at5a?5L?a?WTL?h??YLa????L??a?[L a Because 
27. SM Sentence Marker ?a ? 
28. SYM any Symbol $a $ 
29. VB Verb a??SLa?5WlO?5???a?58 a Wanted 
30. VBI Verb Infinitive form a?5a?5?5??>a?5Na?5 a To go 
31. VBT Verb Tense `8a?kHa?6?Ka??5? a Is 
32. WALA Association Marking Morpheme 
a?5mL???5? a
a?5?La???<??? a
Associated 
Bearing 
 
31
Proceedings of the 7th Workshop on Asian Language Resources, ACL-IJCNLP 2009, pages 40?47,
Suntec, Singapore, 6-7 August 2009. c?2009 ACL and AFNLP
Assas-Band, an Affix-Exception-List Based Urdu Stemmer  
 
Qurat-ul-Ain Akram  
Center for Research in Urdu 
Language Processing  
NUCES, Pakistan 
ainie.akram@nu.edu.pk 
Asma Naseer  
Center for Research in Urdu 
Language Processing  
NUCES, Pakistan 
asma.naseer@nu.edu.pk
Sarmad Hussain  
Center for Research in Urdu 
Language Processing  
NUCES, Pakistan 
sarmad.hussain@nu.edu.pk
 
Abstract 
 
Both Inflectional and derivational morphology lead 
to multiple surface forms of a word. Stemming 
reduces these forms back to its stem or root, and is 
a very useful tool for many applications.  There has 
not been any work reported on Urdu stemming.  
The current work develops an Urdu stemmer or 
Assas-Band and improves the performance using 
more precise affix based exception lists, instead of 
the conventional lexical lookup employed for 
developing stemmers in other languages.  Testing 
shows an accuracy of 91.2%.  Further 
enhancements are also suggested. 
 
1. Introduction 
A stemmer extracts stem from various forms of 
words, for example words actor, acted, and acting all 
will reduce to stem act.  Stemmers are very useful for 
a variety of applications which need to acquire root 
form instead of inflected or derived forms of words.  
This is especially true for Information Retrieval tasks, 
which search for the base forms, instead of inflected 
forms.  The need of stemmers becomes even more 
pronounced for languages which are morphologically 
rich, and have a variety of inflected and derived 
forms. 
Urdu is spoken by more than a 100 million people 
(accessed from http://www.ethnologue.com/show_ 
language.asp ?code =urd). It is the national language 
of Pakistan and a state language of India.   It is an 
Indo-Aryan language, and is morphologically rich. 
Currently there is no stemmer for Urdu, however 
recent work has shown that it may have much utility 
for a variety of applications, much wider than some 
other languages.  Due to the morphological richness 
of Urdu, its application to information retrieval tasks 
is quite apparent.  However, there are also a few other 
areas of application, including automatic 
diacritization for text to speech systems, chunking, 
word sense disambiguation and statistical machine 
translation.  In most of these cases, stemming 
addresses the sparseness of data caused by multiple 
surface forms which are caused mostly by inflections, 
though also applicable to some derivations. 
Due to urgent need for some applications, an Urdu 
stemmer called Assas-Band1, has been developed.  
The current work explains the details of Assas-Band 
and its enhancements using exceptions lists instead of 
lexical lookup methods, to improve its accuracy.  
Finally results are reported and discussed.  
 
2. Literature Review 
Urdu is rich in both  inflectional and derivational 
morphology. Urdu verbs inflect to show agreement 
for number, gender, respect and case.  In addition to 
these factors, verbs in Urdu also have different 
inflections for infinitive, past, non-past, habitual and 
imperative forms.   All these forms (twenty in total) 
for a regular verb are duplicated for transitive and 
causative (di-transitive) forms, thus giving a total of 
more than sixty inflected variations.  Urdu nouns also 
show agreement for number, gender and case.  In 
addition, they show diminutive and vocative 
affixation.  Moreover, the nouns show derivational 
changes into adjectives and nouns.  Adjectives show 
similar agreement changes for number, gender and 
case. A comprehensive computational analysis of 
Urdu morphology is given by Hussain (2004).   
Stemmers may be developed by using either rule-
based or statistical approaches. Rule-based stemmers 
require prior morphological knowledge of the 
language, while statistical stemmers use corpus to 
calculate the occurrences of stems and affixes. Both 
rule-based and statistical stemmers have been 
developed for a variety of languages.   
A rule-based stemmer is developed for English by 
Krovetz (1993) using machine-readable dictionaries.  
Along with a dictionary, rules for inflectional and 
derivational morphology are defined. Due to high 
dependency on dictionary the systems lacks 
consistency (Croft and Xu 1995). In Porter Stemmer 
(Porter 1980) the algorithm enforces some 
terminating conditions of a stem. Until any of the 
conditions is achieved, it keeps on removing endings 
of the word iteratively. Thabet has proposed a 
stemmer that performs stemming of classical Arabic 
                                                          
1 In Urdu Assas means stem and Assas-Band means 
stemmer 
40
in Quran (Thabet 2004) using stop-word list. The 
main algorithm for prefix stemming creates lists of 
words from each surah. If words in the list do not 
exist in stop-word list then prefixes are removed. The 
accuracy of this algorithm is 99.6% for prefix 
stemming and 97% for postfix stemming. An 
interesting stemming approach is proposed by Paik 
and Parui (2008), which presents a general analysis of 
Indian languages. With respect to the occurrences of 
consonants and vowels, characters are divided into 
three categories. Different equivalence classes are 
made of all the words in the lexicon using the match 
of prefix of an already defined length. This technique 
is used for Bengali2, Hindi and Marathi languages. A 
rule-based stemming algorithm is proposed for 
Persian language by Sharifloo and Shamsfard (2008), 
which uses bottom up approach for stemming. The 
algorithm identifies substring (core) of words which 
are derived from some stem and then reassembles 
these cores with the help of some rules. Morpheme 
clusters are used in rule matching procedure. An anti-
rule procedure is also employed to enhance the 
accuracy. The algorithm gives 90.1 % accuracy. 
Besides rule-based stemmers there are a number of 
statistical stemmers for different languages. Croft and 
Xu provide two methods for stemming i.e. Corpus-
Specific Stemming and Query-Specific Stemming 
(Croft and Xu 1995). Corpus-Specific Stemming 
gathers unique words from the corpus, makes 
equivalence classes, and after some statistical 
calculations and reclassification makes a dictionary. 
Query-Based Stemming utilizes dictionary that is 
created by Corpus-Based Stemming. Thus the usual 
process of stemming is replaced with dictionary 
lookup.  Kumar and Siddiqui (2008) propose an 
algorithm for Hindi stemmer which calculates n-
grams of the word of length l. These n-grams are 
treated as postfixes. The algorithm calculates 
probabilities of stem and postfix. The combination of 
stem and postfix with highest probability is selected. 
The algorithm achieves 89.9% accuracy. Santosh 
et.al. (2007) presents three statistical techniques for 
stemming Telugu language. In the first technique the 
word is divided into prefix and postfix. Then scores 
are calculated on the basis of frequency of prefix, 
length of prefix, frequency of postfix, and length of 
postfix. The accuracy of this approach is 70.8%. The 
second technique is based on n-grams. Words are 
clustered using n-grams. Within the cluster a smallest 
word is declared as the stem of the word. The 
algorithm gives 65.4% accuracy. In the third 
approach a successive verity is calculated for each 
                                                          
2 Also see Islam et al (2007) for Bengali stemming 
word?s prefix. This approach increases accuracy to 
74.5%.  
Looking at various techniques, they can generally 
be divided into rule based or statistical methods.  Rule 
based methods may require cyclical application of 
rules.  Stem and/or affix look-ups are needed for the 
rules and may be enhanced by maintaining a lexicon. 
Statistical stemmers are dependent on corpus size, 
and their performance is influenced by morphological 
features of a language. Morphologically richer 
languages require deeper linguistic analysis for better 
stemming. Three different statistical approaches for 
stemming Telugu (Kumar and Murthy 2007) words 
reveal very low accuracy as the language is rich in 
morphology. On the other hand rule-based techniques 
when applied to morphologically rich languages 
reveal accuracy up to 99.6% (Thabet 2004).  Like 
other South Asian languages, Urdu is also 
morphologically rich.  Therefore, the current work 
uses a rule based approach with a variation from 
lexical look-up, to develop a stemmer for Urdu.  The 
next sections discuss the details of development and 
testing results of this stemmer. 
 
3. Corpus Collection 
An important phase of developing Assas-Band is  
corpus collection. For this four different lexica and 
corpora3: C1 (Sajjad 2007), C24, C3 (Online Urdu 
Dictionary, available at www.crulp.org/oud) and C4 
(Ijaz and Hussain 2007) are used for analysis and 
testing. Furthermore, prefix and postfix lists5 are also 
used during the analysis. The summary of each of the 
resources is given in table 1.  
 
Table 1: Corpora Words Statistics 
 
4. Methodology 
The proposed technique uses some conventions 
for the Urdu stemmer Assas-Band. The stem returned 
by this system is the meaningful root e.g. the stem of 
L?NY??  larkiyan (girls) is 5?Nt   larki (girl) and not the 
??N larak  (boy/girl-hood; not a surface from). It also 
maintains distinction between the masculine and 
                                                          
3 Available from CRULP (www.crulp.org) 
4 Unpublished, internally developed by CRULP 
5 Internally developed at  CRULP 
Corpus Total No. of 
Words 
Unique 
Words 
C1  63,298 10,604 
C2  96,890 7,506 
C3  149,486 149,477 
C4  19,296,846 50,000 
41
feminine forms of the stem. Assas-Band gives the 
stem ???N larka (boy) for word ??L?N larkon (boys) and 
stem 5?Nt  larki (girl) for L?NY??   larkiyan (girls). The 
reason for maintaining the gender difference is its 
usability for other tasks in Urdu, e.g. machine 
translation, automatic diacritization etc.  The word 
can easily be converted to  underlying stem (e.g. ??N 
larak  (boy/girl-hood)), if needed. 
Assas-Band is trained to work with Urdu words, 
though it can also process foreign words, e.g.  
Persian, Arabic and English words, to a limited 
extent. Proper nouns are considered stems, though 
only those are handled which appear in the corpora.    
 
Figure 1: Flow Chart for the Stemming Process 
 
An Urdu word is composed of a sequence of 
prefixes, stem and postfixes. A word can be divided 
into (Prefix)-Stem-(Postfix). Assas-Band extracts 
Stem from the given word, and then converts it to 
surface form, as per requirement.   The algorithm of 
the system is as follows. First the prefix (if it exists) 
is removed from the word. This returns the Stem-
(Postfix) sequence.  Then postfix (if it exists) is 
removed and Stem is extracted. The post-processing 
step (if required) is performed at the end to generate 
the surface form.  
However, while applying affix rules for any 
word, the algorithm checks for exceptional cases and 
applies the affix stripping rules only if the exceptional 
cases are not found. This is different from other 
methods which first strip and then repair.   
The algorithm for Assas-Band is given in Figure 
1 and explained in more detail below. 
Prefix Extraction: To remove the prefix from 
the word, first it is checked whether the input word 
exists in the Prefix-Global-Exceptional-List (PrGEL). 
If it exists in PrGEL, then it means that the word has 
an initial string of letters which matches a prefix but 
is part of the stem and thus should not be stripped.  If 
the word does not exist in PrGEL, then prefix rules 
list is looked up.  If an applicable prefix is found, 
starting from longest matching prefix to shorter 
prefix, appropriate rule is applied to separate prefix 
from stem-postfix. Both parts of the word are retained 
for further processing and output.  
Postfix Extraction: This process separates the 
postfix from word and performs the post-processing 
step, if required, for generating the surface form. 
First the remaining Stem-(Postfix) is looked up in 
a general Postfix-Global-Exceptional-List (PoGEL). 
If the word exists in the list, then it is marked as the 
stem. If the word does not exist in this list, it indicates 
that a possible postfix is attached. Postfix matching is 
then performed.  The candidate postfix rules are 
sorted in descending order according to the postfix 
length. In addition, a Postfix-Rule-Exception-List 
(PoREL) is also maintained for each postfix.  The 
first applicable postfix from the list is taken and it is 
checked if the word to be stemmed exists in PoREL.  
If the word does not exist in PoREL, then the current 
postfix rule is applied and the Stem and Postfix are 
extracted.  If the word exists in the PoREL then the 
current postfix rule is not applied and the next postfix 
rule is considered.  This process is repeated for all 
candidate postfix rules, until a rule is applied or the 
list is exhausted. In both cases the resultant word is 
marked as Stem. 
A complete list of prefixes and postfixes are 
derived by analyzing various lexica and corpora (and 
using grammar books).  In addition, complete rule 
exception list for each postfix (PoREL), complete 
general exception list for prefixes PrGEL and general 
exception list for postfixes PoGEL are developed 
using C1, C2, C3 and C4.  PrGEL and PoGEL are 
also later extended to include all stems generated 
through this system. 
 After applying prefix and postfix rules, post 
processing is performed to create the surface form of 
the stem. The stem is looked up in the Add-Character-
Lists (ACL). There are only five lists, maintained for 
each of the following letter(s): ?? ?? ?? ?? =?   (yay-hay, 
choti-yah, gol-hay, tay, alif), because only these can 
be possibly added. If the stem is listed, the 
corresponding letter(s) are appended at the end to 
42
generate the surface form, else the stem is considered 
the surface form.   
Though the algorithm is straight forward, to the 
lists have been developed manually after repeated 
analysis, which has been a very difficult task, as 
explained in next section.  Some sample words in 
these lists are given in the Appendices A and B. 
 
5. Analysis Phase 
The analysis has been divided into two phases. First 
phase involved the extraction of prefixes and 
postfixes.  The second phase dealt with the 
development of Prefix and Postfix Global Exceptional 
Lists (PrGEL, PoGEL), Postfix Rule Exceptional 
Lists (PoREL) and Add Character Lists (ACL).  
These are discussed here. 
 
5.1. Extraction of Affixes  
C1 and C2 are used for the extraction of affixes. 
These corpora are POS tagged. The analysis is 
performed on 11,000 high frequency words.  The 
details of these corpora are given in Table 1. By 
looking at each word, prefixes and postfixes are 
extracted.  Words may only have a prefix e.g. ???D?6 
bud-surat (ugly), only a postfix, e.g. 8`???? tasawr-
aat (imaginations), or both prefix and postfix, e.g. 
5?A?6?t  bud-ikhlaq-i (bad manners).  After analysis, 40 
prefixes and 300 postfixes are extracted. This list is 
merged with an earlier list of available postfixes and 
prefixes6. A total of 174 prefixes and 712 postfixes 
are identified. They are listed in Appendix C. In this 
phase, the post-processing rules are also extracted 
separately.  
 
5.2. Extraction of Exception and Word Lists 
The following lists are used to improve the 
accuracy of Assas-Band.  
1. Prefix and Postfix Global Exceptional Lists 
(PrGEL, PoGEL) 
2. Postfix Rule Exceptional List (PoREL) for each 
postfix 
3. Add Character List (ACL) for each letter/sequence 
The second phase of analysis is performed to 
generate these lists.  This analysis is based on C3.   
Development of PrGEL: The PrGEL contains 
all those words from which a prefix cannot be 
extracted. The list contains words with first few 
letters which match a prefix but do not contain this 
prefix, e.g. ?5?;?6 bandh-ay (tied).  This word exists in 
PrGEL to ensure that the prefix ?6 ba (with) is not 
                                                          
6 Internally developed at CRULP 
 
removed to give invalid stem ?5?; ndhay.  This single 
list is maintained globally for all prefixes. 
Development of PoGEL: There are also many 
words which do not contain any postfix but their final 
few letters may match with one.  If they are not 
identified and prevented from postfix removal 
process, they may result in erroneous invalid stems.  
For example, ?8??t  hathi (elephant) may be truncated 
to ?8?? hath (hand), which is incorrect removal of the 
postfix ? (letter choti-yay). All such words are kept in 
the PoGEL, and considered as a stem. This single list 
is maintained globally for all the postfixes.  
Rule Exceptional Lists: Candidate postfixes are 
applied in descending order of length.  For example, 
for the word T^6Y??a  bastiyan (towns), the following 
postfixes can be applied: ?Y??  tiyan, =??  yan, ?? aan 
and ? noon-gunna. 
First, if the maximal length postfix matches, it is 
stripped.  However, there are cases, when there is a 
match, but the current postfix should not be detached  
(a shorter postfix needs to be detached).  In this case a 
postfix specific list is needed to list the exceptions to 
ensure preventing misapplication of the longer 
postfix.  For this situation PoREL is maintained for 
each postfix separately. So for T^6Y??  bastiyan 
(towns), first the maximum length postfix ?Y??  tiyan is 
matched. However, this creates the stem y6 bas (bus) 
which is incorrect.    Thus, T^6Y??  bastiyan (towns) is 
stored in the PrREL of ?Y??  tiyan. Due to this, this 
postfix is not extracted and the next longest postfix 
rule is applied. Even in this case nonsense stem p^6 
bast is generated.  Thus, T^6Y??  bastiyan (towns) is 
also stored in the PrREL of postfix =??  yan. Next the 
postfix ?? an is applied. This yields 5^6t  basti (town), 
which is correct. This checking and PrREL 
development process is manually repeated for all the 
words in the corpus.  
Add Character Lists: During second phase the 
ACLs (already developed in the first phase) are 
updated against each of the five possible letter 
sequences, i.e. ????????=? , to generate correct surface 
forms. For example, when postfix 5t  gi is removed 
from 5?;?t  zindagi (life), it creates the stem ?;? zind, 
which is not a surface form. The letter ? hay has to be 
appended at the end to produce the correct surface 
form ?;?? zinda (alive).  So ?;? zind is stored in the 
ACL of letter ?. In the same way the lists are 
developed and maintained for the five letters 
separately. After applying a particular postfix rule on 
43
the word, the result is checked in each ACL. If the 
string is found in any of the lists then respective 
character is attached at the end.   
 
Instead of manually doing all the work, the process is 
automated using an online Urdu dictionary (OUD) 
(available at www.crulp.org/oud) using the following 
algorithm.  
 
1. Take a word from corpus. 
2. Generate all applicable rules. 
3. Sort all rules in descending order according to the 
maximum length of each. 
4. Extract upper- most rule from the rules list. 
5. Apply extracted rule on the word. Check 
remaining word?s existence in the dictionary. 
a. If remaining word exists in the dictionary, store 
that original word in the respective rule?s Stem 
List and stop the loop. 
b. Otherwise store original word in the Rule 
Exceptional List of the respective rule and go to 
Step 4 for the next rule. 
6. Repeat steps 4 and 5 until 
a. Stop condition (5a) occurs, or 
b. All the generated rules have been traversed. 
7. If termination of the loop is due to step 6b, then 
the word is stored in the Global Exceptional List 
which is universal for all the rules. 
8. Repeat step 1-7 for all the words in the corpus. 
 
The above algorithm is first run for prefixes. Once a 
complete manual check is performed on the results, 
the same algorithm is applied for the postfixes.  
 
6. Manual Corrections 
Manual inspection is needed to fix the errors 
generated by the automated system.  The stem list is 
manually scanned to identify real-word errors, i.e. the 
stemming is incorrect but results in a valid word. For 
example when ??  ri postfix is applied to the word 
?L?9?  tokri (basket), the word ?9? tok (stop) is 
obtained which exists in the dictionary but is incorrect 
stemming. The inspection is also needed to ensure 
that the distinction between the masculine and 
feminine forms of a word is maintained. As discussed 
the gender distinction is kept to ensure better use in 
other applications.   
Postfix Rule Exceptional List is scanned 
manually to check for any missing entries (in case the 
lexicon contains incomplete information about a 
word) or spurious entries (in case a word is not in the 
lexicon).  Similarly, the process is also useful in 
identifying additional missing prefixes and postfixes.  
For example, the word ?;^??? aansuon (tears) is 
found in the Exceptional List during manual analysis, 
because the postfix ??  on was not initially identified. 
Thus, the algorithm applied the postfix ? n, leaving 
the incorrect stem ?;^?? aansuo.  This was 
(obviously) not found in OUD dictionary, so it was 
placed in PoGEL. By manually scanning each of the 
words in this list, new postfix was found, which 
created the correct stem ?^;?  aansu (tear). ACL is 
also updated by this manual analysis. 
 
7. Testing 
The test results are given in this section.   
Testing Phase 1: The corpora C1 and C2 are used 
which have combined 11,339 unique words.  The 
following table summarizes the testing results. 
 
Table 2: Initial Testing Results  
Testing Results Values
Total Number of tested words 11339
Accurately Stemmed 7241
Incorrect Stemming 4098
Accuracy Rate 64%
    
Inaccurate  Add Character  278
Inaccurate  Prefix Stripping 754
Inaccurate Postfix Stripping 1006
Errors due to Foreign Words  2107
    
Number of Times Prefix Rules Applied 1656
Correct 942
Incorrect 714
    
Number of Times Postfix Rules  Applied 5990
Correct 4984
Incorrect 1006
    
Number of Times Character Added 819
Correct 541
Incorrect 278
 
The accuracy of 64% is achieved.  Some of the 
stems created are not in the lists and are erroneous.  
They are created by invalid prefix/postfix removal.  
Analysis showed that some prefixes and postfixes 
contributed to this error rate because they were 
derived from foreign words transliterated in Urdu. For 
example ?  z postfix is correctly applied to the English 
44
word ?Y?=?  ladiez (ladies)  yielding the stem ?Y??  ladie 
(lady). But this ? z postfix rule when applied to Urdu 
words increases the error rate. Similarly Arabic prefix 
?? al (the), which applies to Arabic words correctly 
e.g. ???gN? al-Quran (the Quran), wrongly applies to 
Urdu words.  
Another reason for error in stemming is  
ineffective post-processing due to insufficient words 
in the lists. There are also some other sources of 
errors which are not directly associated with 
stemming but are common for Urdu corpora.  Errors 
are caused by spelling errors, including space 
character related errors (Naseem and Hussain 2007). 
There are also encoding normalization issues, which 
need to be corrected before string matching.  This is 
caused by the variation in keyboards. 
Testing Phase II: On the basis of previous result 
analysis, prefix and postfix rules which are applicable 
to only foreign words are removed from the rule lists. 
Such rules create errors in Urdu word stemming, 
while trying to cater  non-essential task of stemming 
transliterated foreign words. The foreign words found 
in C1 and C2 are stored in global lists i.e. PrGEL and 
PoGEL to ensure that they are not processed. 
 
Table 3: Test Results after Removing Foreign 
Prefixes and Postfixes Rules 
Testing Results Values 
Total Number of tested words 10418
Accurately Stemmed 9476
Incorrect Stemming 942
Accuracy Rate 90.96%
    
Inaccurate  Add Character  35
Inaccurate  Prefix Stripping 473
Inaccurate Postfix Stripping 469
Errors due to Foreign Words  0
  
Number of Times Prefix Rules 
Applied 660
Correct 187
Incorrect 473
    
Number of Times Postfix Rules  
Applied  3445
Correct 2976
Incorrect 469
    
Number of Times Character Added 626
Correct 591
Incorrect 35
As errors from C1 and C2 have been manually 
fixed, testing is again performed by using 10,418 high 
frequency Urdu words from C4 (Ijaz and Hussain 
2007). The summary of testing results is in Table 3. 
Table 3 shows that removing foreign language 
affixes improves the results significantly.  The prefix 
error rate is higher than the postfix error rate. In 
addition, the ACL has to be more comprehensive.  
There are also some errors because some words 
require both prefix and postfix to be extracted, but 
during stemming, if the prefix is wrongly applied and 
a faulty stem is generated, then the postfix is also 
incorrectly applied.     
Testing Phase III: After analyzing test results of 
the second phase, amendments are made in the 
algorithm. Following post-processing, the stem 
generated is verified in PoGEL. If it does not exist, it 
is assumed that wrong rule is applied and thus it is 
skipped and the next rule is applied.  This is repeated 
until the resulting stem is found in PoGEL. By 
implementing this methodology, the accuracy is 
enhanced from 90.96% to 91.18% for C4 corpus 
based word list as shown in Table 4. 
 
Table 4:  Test Results after Enhancing Algorithm 
Testing Results Values 
Total Number of tested words 10418
Accurately Stemmed 9499
Incorrect Stemming 919
Accuracy Rate 91.18%
    
Inaccurate  Add Character  35
Inaccurate  Prefix Stripping 473
Inaccurate Postfix Stripping 446
Errors due to Foreign Words  0
  
Number of Times Prefix Rules Applied 660
Correct 187
Incorrect 473
    
Number of Times Postfix Rules  Applied 3445
Correct 2999
Incorrect 446
    
Number of Times Character Added 626
Correct 591
Incorrect 35
 
The methodology does not affect prefix removal and 
the process of adding characters. The improvement 
made by this methodology is only in the accuracy of 
45
postfixes because this modification is only performed 
on the second phase i.e. extraction of postfixes.  
  
8. Conclusion 
The current paper presents work performed to 
develop an Urdu stemmer.  It first removes the prefix, 
then the postfix and then adds letter(s) to generate the 
surface form of the stem.  In the first two steps it uses 
exception lists if a prefix and/or postfix can be 
applied.  A successful lookup bypasses the stripping 
process.  This is different from lexical or stem look 
up in other work which triggers the stripping process.  
The current stemming accuracy can be further 
improved by  making the lists more comprehensive.  
ACL should also be maintained against each postfix 
for more accuracy.  The developed system is 
currently being used for various other applications for 
Urdu language processing, including automatic 
diacritization.   
 
Acknowledgements 
The work has been partially supported by PAN 
Localization Project grant by International 
Development Research Center (IDRC) of Canada. 
 
References 
Croft, W. B. and Xu, J. 1995. Corpus-Specific Stemming 
using Word Form Co-occurrences. In Fourth Annual 
Symposium on Document Analysis and Information 
Retrieval.  
Krovetz, R. 1993. View Morphology as an Inference 
Process. In the Proceedings of 5th International 
Conference on Research and Development in 
Information Retrieval. 
Porter, M. 1980. An Algorithm for Suffix Stripping. 
Program, 14(3): 130-137.  
Thabet, N. 2004. Stemming the Qur?an. In the Proceedings 
of the Workshop on Computational Approaches to 
Arabic Script-based Languages. 
Hussain, Sara. 2004.  Finite-State Morphological Analyzer 
for Urdu. Unpublished MS thesis, Center for Research 
in Urdu Language Processing, National University of 
Computer and Emerging Sciences, Pakistan. 
Sajjad, H. 2007. Statistical Part-of-Speech for Urdu. 
Unpublished MS Thesis, Center for Research in Urdu 
Language Processing, National University of Computer 
and Emerging Sciences, Pakistan. 
Ijaz, M and Hussain, S. 2007. Corpus Based Urdu Lexicon 
Development.  In the Proceedings of Conference on 
Language Technology (CLT07), Pakistan. 
Naseem, T., Hussain, S. 2007. Spelling Error Trends in 
Urdu. In the Proceedings of Conference on Language 
Technology (CLT07), Pakistan. 
Kumar, M. S.  and Murthy, K. N. 2007. Corpus Based 
Statistical Approach for Stemming Telugu.  Creation of 
Lexical Resources for Indian Language Computing and   
Processing (LRIL), C-DAC, Mumbai, India.  
Paik, J. H. and  Parui, S. K. 2008. A Simple Stemmer for 
Inflectional Languages. Forum for Information Retrieval 
Evaluation, 
Islam, M. Z., Uddin, M. N. and Khan, M. 2007. A Light 
Weight Stemmer for Bengali and Its Use in Spelling 
Checker.  In the Proceedings of 1st Intl. Conf. on Digital 
Comm. and Computer, Amman, Jordan. 
Sharifloo, A. A. and Shamsfard, M. 2008. A Bottom up 
Approach to Persian Stemming. In the Proceedings of 
the Third International Joint Conference on Natural 
Language Processing. Hyderabad, India. 
Kumar, A. and Siddiqui, T. 2008. An Unsupervised Hindi 
Stemmer with Heuristics Improvements.  In Proceedings 
of the Second Workshop on Analytics for Noisy 
Unstructured Text Data. 
 
  
46
Appendix A  
A.1 Postfix Rule Exceptional List Samples 
Postfix Some Exceptional Words 
?6?a L?8Y??Ra
?5?a ?5??B?B,?M?5?5,??C?5,???kj8a
?5a ?a=a??5,?Ka??5,alOa??5,?5??A,O?CY?5?,?5?8,?5??m8a
?Y?a ???J?Y?,???;Y?,???LY?,??W??>Y?,??????Y?,???BY?a
 
A.2 Postfix Global Exception List Samples 
_6Y?a ?Y???a wj^Oa ??l_Oa ????a
??hBa ?;?<?Ja ??>a sP?a ?=a????a
?TB??a BY?Ra ?h;??a ?@??a ??TJ?a
 
A.3 Prefix Global Exception List Samples 
=??=?a ?5N??;a ??;Y??a ?WlOta
=??^ha ?5??mh;a 5?SC?;ta ?5?WOa
=??^hYpa ???;Y?a ?;=??a 5?WOta
5??kPta 5??;ta ????;a ??iWOa
 
Appendix B 
Add Character List Samples 
 ?  Add ?  Add 
a?T??a+a?=a?lT??a KY??aa+a?=aKY???a
?=?aa+aa?=aa??=?a a???a+a?=apC??a
?=yaa+a?=a?=?^a ay?Ba+a?=ap^B?a
pLaa+a?=aa?TLa a
?
?Ca+a?=a?
?
?Ca
?  Add ?  Add 
a?8?a+?aa=5?8ta ??O??aa+a?a=???O??a
a ?O?=?aa+?aa=?O?=?ha
a a??TJ?a+a?a=???TJ?a
 a a??O??a+a?a=???O??a
 
Appendix C 
C.1 List of Sample Prefixes 
yOa n@?Da ?8a ?6?a ?Oa
??6a ??Ja ?C?a ?Ia ?;a
ySCa ??a ??;a ?j?a ?7a
y7a ???Ba ?W?a ?Ca ?5?6?a
?7??a ?6?a s6a ?Y?a ??6?a
???a ?RKa ??6?a ?Da ?;??a
5?9?ta ?7?a ?6??a ?d6?Oa ?;a
N?Fa 5?ta ??a ?6a ???a
????a ??Aa ?7a ??a ?=yha
??J?Oa sOa IY?a ?6?a ?5??a
sP?a z8?a ?8a ??a ???Ma
?6?a 5F?6ta ?5a ??a ??a
 
C.2 List of Sample Postfixes 
iW??Y??a ?;??a t5??aa ??>???a 5?ta ??B?a
i;Y?a ??W?aa pB?a ?=?a 5???ta 5?k;ta
?=?7???a ?=?7???a ?5??a =?a ?;?ta ?f;ta
?=?6????a ?YiY??a ?5?a ?<??a 5??Jta i;?Y??a
???a ?=;????a ?5?;a J??MY?a 5??Bta 5?;ta
??B=??a ?Y????a ?5a ?a 5???Mta 5?ta
????Y??a AY?=??a ?a ??Ba 5?B?ta 5?m8ta
??WhCa ???a ?5a ??5?a ??7??a 5?ta
B?6Y??a X???Y?a ?5?a ?J??Ma O?Y??a 5?7ta
?=?=??a ?=;????a ?5??a ?O??a 5?ta ?Y5?ta
?M=??a ?Y??Y??a ?5a ?;???a a_;aY5ta ??6???a
??WLa ??_JY??a ?5?Aa ?=?a 5?TBta 5?ta
?=????a ?;?????a a??5a ??O?a ?????a ??A?a
????Ba ?6=??a ??La LY?^a ??M?a 5??;ta
???=??a ?;=??^a a???a ???;a 5?ta ????a
A???Y??a ??MY??a ??a ???a ?W??a 5WBta
???Y??a C?8?Y??a ?5?a ?7???a ?J?a=5ta 5?_Jta
 
47
Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 528?536,
Los Angeles, California, June 2010. c?2010 Association for Computational Linguistics
Urdu Word Segmentation 
 
Nadir Durrani Sarmad Hussain 
Institute for NLP Center for Research in Urdu Language Processing 
Universit?t Stuttgart National University of Computer and Emerging Sciences 
durrani@ims.uni-stuttgart.de sarmad.hussain@nu.edu.pk 
 
 
  
Abstract 
Word Segmentation is the foremost obligatory task in 
almost all the NLP applications where the initial phase 
requires tokenization of input into words. Urdu is 
amongst the Asian languages that face word segmenta-
tion challenge. However, unlike other Asian languages, 
word segmentation in Urdu not only has space omission 
errors but also space insertion errors. This paper dis-
cusses how orthographic and linguistic features in Urdu 
trigger these two problems. It also discusses the work 
that has been done to tokenize input text. We employ a 
hybrid solution that performs an n-gram ranking on top 
of rule based maximum matching heuristic. Our best 
technique gives an error detection of 85.8% and over-
all accuracy of 95.8%.  Further issues and possible fu-
ture directions are also discussed. 
1 Introduction 
All language processing applications require input 
text to be tokenized into words for further 
processing.  Languages like English normally use 
white spaces or punctuation marks to identify word 
boundaries, though with some complications, e.g. 
the word ?e.g.? uses a period in between and thus 
the period does not indicate a word boundary. 
However, many Asian languages like Thai, Khmer, 
Lao and Dzongkha do not have word boundaries 
and thus do not use white space to consistently 
mark word endings.  This makes the process of 
tokenization of input into words for such languages 
very challenging. 
 
Urdu is spoken by more than 100 million people, 
mostly in Pakistan and India1.  It is an Indo-Aryan 
language, written using Arabic script from right to 
left, and Nastalique writing style (Hussain, 2003).  
                                                          
1
 Ethnologue.com 
http://www.ethnologue.com/14/show_language.asp?code=UR
D 
Nastalique is a cursive writing system, which also 
does not have a concept of space.  Thus, though 
space is used in typing the language, it serves other 
purposes, as discussed later in this paper.  This en-
tails that space cannot be used as a reliable delimi-
ter for words.  Therefore, Urdu shares the word 
segmentation challenge for language processing, 
like other Asian languages. 
 
This paper explains the problem of word segmen-
tation in Urdu.  It gives details of work done to 
investigate linguistic typology of words and moti-
vation of using space in Urdu.  The paper then 
presents an algorithm developed to automatically 
process the input to produce consistent word seg-
mentation, and finally discusses the results and 
future directions. 
2 Urdu Writing System 
Urdu is written in cursive Arabic script. Characters 
in general join with the neighbors within a word 
and in doing so acquire different shapes. Logically, 
a character can acquire up to four shapes, i.e. ini-
tial, medial, final position in a connected sequence 
or an isolated form.  The characters having this 
four-way shaping are known as joiners. However, 
another set of characters only join with characters 
before them but do not join with character after 
them, and are termed as non-joiners.  The non-
joiners only have final and isolated forms.  For 
example Arabic Letter Farsi Yeh ? is a joiner and 
has four shapes ? ,? ,? and ? respectively and 
Arabic letter Dal ? is a non-joiner and has two 
forms ? and ? only. The shape that these characters 
acquire depends upon the context. 
 
Table 1 lists the orthographic rules that Urdu cha-
racters follow. For example, the table shows that in 
the middle of a word, if the character is a non-
joiner, it acquires final shape when following a 
528
joiner and isolated shape when following a non-
joiner.  This joining behavior results in formation 
of multiple connected portions within a word, each 
called a ligature.   
 
 
Table 1: Orthographic Rules for Urdu 
 
The concept of space as a word boundary marker is 
not present in Urdu writing. As an Urdu learner, a 
person is not taught to leave a space between 
words, but only to generate correct shaping while 
writing. Thus, the concept of space is only learnt 
later on when the person learns how to use a com-
puter.  However, space is introduced as a tool to 
control the correct letter shaping and not to consis-
tently separate words.  For example, the native 
speaker learns to insert a space within the word 
????? ??? (?needy?) to generate the correct shape 
of ?.  Without space it appears as ???????? which 
is visually incorrect. On contrary, the user finds it 
unnecessary to insert a space between the two 
words ???????? (?Urdu Center?), because the cor-
rect shaping is produced automatically as the first 
word ends with a non-joiner. Therefore ???????? 
and ???? ???? look identical. 
 
Though space character is not present in Urdu, 
with increasing usage of computer it is now being 
used, both to generate correct shaping (as dis-
cussed above) and also to separate words (a habit 
being carried over to Urdu from English literate 
computer users).  This makes space an unreliable 
cue for word boundary. The problem is further ob-
fuscated by the lack of a clear definition of a work 
in Urdu in some contexts.  The next section dis-
cusses these issues. 
3 Segmentation Issues in Urdu Text 
The segmentation challenges can be divided into 
two categories, challenges caused due to joiner and 
non-joiner characters.   
3.1 Space Omission 
As discussed, for words ending with non-joiners 
correct shaping is generated even when space is 
not typed and thus, many times a user omits the 
space.  Though there is no visible implication, 
from the perspective of computational processing 
not typing a space merges current word with the 
next word.  Figure 1 below illustrates an example, 
where the phrase has eight words (or tokens) each 
ending with a non-joiner and thus the whole 
phrase can be written without a space and is still 
visibly same and equally readable. 
 
????? ?? ??? ???? ??? ???? ?? ??? 
(a) 
?????????????????????????? 
(b) 
Figure 1: All Words Ending with Non-Joiners (a) 
with Spaces, (b) without Spaces between Words 
(?Troop Leader Ahmed Sher Dogar Said?) 
 
Another frequent set of space omissions are caused 
due to variation in the definition of a word in Urdu.  
There are certain function words in Urdu which 
may be combined with other function words and 
content words by some writers but may be written 
separately by others.  Shape variation may also 
occur in some of these cases, but is overlooked by 
the writers.  Table 2 gives some examples of such 
cases.  Though the merged form is not considered 
correct diction, it is still frequently used and thus 
has to be handled.  It is not considered spelling 
error but a writing variation. 
 
POS Combined Separated Translation 
Pn+CM ?? ?? ???? Yours 
D+ NN ?? ??? ????? at that time 
CM+ NN ?? ??? ????? Towards 
V+TA ??? ?? ????? will do 
CM + P ?? ??? ????? For 
Pn  = Pronoun, D = Demonstrative, NN = Noun, CM 
= Case Marker, V=Verb, P = Particle 
 
Table 2: Multiple Words Written in Connected 
Form Causing Shaping Changes 
 
Due to reasonable frequency of such cases, these 
may be considered as acceptable alternatives, and 
thus Urdu word segmentation system would need 
to deal with both forms and consider them equiva-
lent.  This process is productively applicable and 
Word J-Shape Example NJ-Shape Example 
Start I ???? Is ???? 
 
Middle 
M after J ???? F after J ???? 
I after NJ ???? Is after J ???? 
 
End 
F after J ??? F after J ??? 
Is after NJ ??? Is after NJ ?? 
J = Joiners, NJ = Non-Joiners 
I = Initial, Is = Isolated, M = Medial, F = Final 
Underlined = Shape in Consideration 
529
not limited to a few pre-determined cases. Addi-
tional complication in the process arises from the 
fact that in some cases (last two cases in Table 2) 
the spellings also change when two words are writ-
ten in combined form, due to the way these charac-
ters are encoded.  Urdu considers ? and ? both 
logically same characters at a certain level, though 
with different shapes to indicated different vowels 
(Hussain, 2004).  In combined form they render the 
same shape.  However, Unicode terms ? as a non-
joiner with no medial shape.  Thus, the Urdu writ-
ers use ? to generate the medial position of ? in 
combined form. 
3.2 Space Insertion 
When multiple morphemes are juxtaposed within a 
word, many of them tend to retain their shaping as 
separate ligatures.  If ending characters are joiners, 
space is usually inserted by writers to prevent them 
from joining and thus to retain the separate ligature 
identity.  This causes an extra space within a word.  
Though this creates the visually acceptable form, it 
creates two tokens from a single word in the con-
text of its processing.  If the writers do not type a 
space between these two morphemes within a word 
they would join and create a visually incorrect 
shape. Such examples are common in Urdu2.  Few 
of these cases are given in Table 3.   
 
Class A B Translation 
i ??????? ???? ??? Married 
ii ?????? ??? ??? Candle 
iii ????????? ???? ????? Unnecessarily 
iv ??????? ???? ??? Telephone 
v ??????? ?? ??? ?? PhD 
i= Affixation, ii = Compounding ,  
iii = Reduplication, iv = Foreign Word,  
v = Abbreviations 
 
Table 3: (A) Separated Form (Correct Shaping, but 
Two Tokens), (B) Combined Form (Erroneous 
Shaping, with one Token) 
 
As categorized in Table 3, the space insertion 
problem is caused due to multiple reasons.  Data 
analyzed shows that space is inserted (i) to keep 
affixes separate from the stem, (ii) in some cases, 
                                                          
2
 Though Unicode recommends using Zero Width Non-Joiner 
character in these context, this is not generally known by Urdu 
typists and thus not practiced; Further, this character is not 
available on most Urdu keyboards. 
to keep two words compounded together from vi-
sually merging, (iii) to keep reduplicated words 
from combining, (iv) to enhance readability of 
some foreign words written in Urdu, and (v) to 
keep English letters separate and readable when 
English abbreviations are transliterated. 
3.3 Extent of Segmentation Issues in Urdu 
In an earlier work on Urdu spell checking (Naseem 
and Hussain, 2007) report that a significant number 
of spelling errors3 are due to irregular use of space, 
as discussed above.  The study does a spelling 
check of an Urdu corpus.  The errors reported by 
the spelling checker are manually analyzed.  A to-
tal of 975 errors are found and of which 736 errors 
were due to irregular use of space (75.5%) and 239 
errors are non-space-related errors (24.5%). Of the 
space related errors, majority of errors (672 or 70% 
of total errors) are due to space omission and 53 
errors (5%) were due to space insertion. Thus irre-
gular use of space causes an extremely high per-
centage of all errors and has to be addressed for all 
language processing applications for Urdu.   
 
A study of Urdu words was also conducted as part 
of the current work. Text was used from popular 
Urdu online news sites (www.bbc.co.uk/urdu and 
http://search.jang.com.pk/). A data of 5,000 words 
from both corpora was observed and space inser-
tion and omission cases were counted. These 
counts are given in Table 4.  Counts for Space In-
sertion are sub-divided into the four categories 
identified earlier.   
 
Problem BBC Jang Total 
Space Omission 373 563 936 
Space Insertion  
 Affixation 298 467 765 
 Reduplication 52 76 128 
 Compounding 133 218 351 
 Abbreviation 263 199 462 
Total 1119 1523 2642 
 
Table 4: Space Omission and Insertion Counts 
from Online BBC and Jang Urdu News Websites 
 
The data shows that a significantly high percentage 
of errors related to space, with significant errors 
                                                          
3
 Errors based on tokenization on space and punctuation mark-
ers 
530
related to both omission and insertion.  Within in-
sertion errors, affixation, compounding and ab-
breviation related errors are more significant 
(because reduplication is a less frequent phenome-
non).  
 
In summary, the space related errors are significant 
and must be addressed as a precursor to any signif-
icant language and speech processing of the lan-
guage 
3.4 Ambiguity in Defining Urdu Word 
Another confounding factor in this context it that 
there is no clear agreement on word boundaries of 
Urdu in some cases.  
 
Compound words are hard to categorize as single 
or multiple words.  Urdu forms compounds in 
three ways: (i) by placing two words together, e.g. 
??? ??? (?parents?, literally ?father mother?), (ii) 
by putting a combining mark between them4, e.g. 
???? ???? (?prime minister?), and (iii) by putting 
the conjunction ? between two words, e.g.  ??? ?
??? (?Discipline?).  
 
Similarly certain cases of reduplication are also 
considered a single word by a native speaker, e.g. 
???? (?fluently?) and ????? (?equal?), while others 
are not, e.g. ????? ????? (?slowly?).  There are also 
cases which are ambiguous, as there is no agree-
ment even within native speakers.   
 
Moreover, certain function words, normally case 
markers, postpositions and auxiliaries, may be 
written joined with other words in context or sepa-
rately.  The words like ??? ??  may also be written 
in joined form ?????, and the different forms may 
be perceived as multiple or single words respec-
tively. 
 
This is demonstrated by the results of a study done 
with 30 native speakers of Urdu (including univer-
sity students, language researchers and language 
teachers).  The subjects were asked to mark wheth-
er they considered some text a single word or a 
sequence of two words.   Some relevant results are 
given in Table 5.  The table indicates that for the 
types of phenomena in Table 4, the native speakers 
                                                          
4
 The diacritics (called zer-e-izafat or hamza-e-izafat) are op-
tional, and are not written in the example given. 
do not always agree on the word boundary, that 
certain cases are very ambiguous, and that writing 
with or without space also changes the perception 
of where the word boundary should lie.   
 
Word(s) # of Words Category 
1 2 
6 24 ????????? Compounding with 
conjunctive diacritic 
13 17 ?????? ??????? -do- 
2 28 ????? ??? -do- 
2 28 ??????? -do- 
5 25 ??? ????? Compounding with 
conjunctive character ? 
1 29 ??? ???? -do- 
0 30 ????? ???? Suffixation 
8 22 ????? ???? -do- 
27 3 ??? ??? Reduplication 
27 3 ???? ???? -do- 
15 15 ???? Space omission between 
two auxiliaries 
12 18 ?????? Space omission between 
verb and auxiliary 
25 5 ???? ?? Same as above but 
without space omission 
 
Table 5: Survey on Word Definition 
 
As the word boundary is ambiguously perceived, it 
is not always clear when to mark it.  To develop a 
more consistent solution, the current work tags the 
different levels of boundaries, and it is left up to 
the application provider using the output to decide 
which tags to translate to word level boundaries. 
Free morphemes are placed and identified at first 
level.  At second level we identify strings that are 
clearly lexicalized as a single word.  Compounds, 
reduplication and abbreviations are dealt at third 
level. 
4 Summary of Existing Techniques 
Rule based techniques have been extensively used 
for word segmentation.  Techniques including 
longest matching (Poowarawan, 1986; Rarunrom, 
1991) try to match longest possible dictionary 
look-up. If a match is found at nth letter next look-
up is performed starting from n+1 index. Longest 
matching with word binding force is used for Chi-
nese word segmentation (Wong and Chang, 1997). 
However, the problem with this technique is that it 
consistently segments a letter sequence the same 
way, and does not take the context into account.  
531
Thus, shorter word sequences are never generated, 
even where they are intended. 
Maximum matching is another rule based tech-
nique that was proposed to solve the shortcomings 
of longest matching. It generates all possible seg-
mentations out of a given sequence of characters 
using dynamic programming. It then selects the 
best segmentation based on some heuristics.  Most 
popularly used heuristic selects the segmentation 
with minimum number of words. This heuristic 
fails when alternatives have same number of 
words. Some additional heuristics are then often 
applied, including longest match (Sornlertlamva-
nich, 1995). Many variants of maximum matching 
have been applied (Liang, 1986; Li et al, 1991; Gu 
and Mao, 1994; Nie et al, 1994). 
There is a third category of rule based techniques, 
which also use additional linguistic information for 
generating intermediate solutions which are then 
eventually mapped onto words.  For example, rule 
based techniques have also been applied to lan-
guages like Thai and Lao to determine syllables, 
before syllables are eventually mapped onto words, 
e.g. see (Phissamy et al, 2007).   
 
There has been an increasing application of statis-
tical methods, including n-grams, to solve word 
segmentation.  These techniques are based at let-
ters, syllables and words, and use contextual in-
formation to resolve segmentation ambiguities, e.g.  
(Aroonmanakul, 2002; Krawtrakul et al, 1997).   
The limitation of statistical methods is that they 
only use immediate context and long distance de-
pendencies cannot be directly handled. Also the 
performance is based on training corpus. Neverthe-
less, statistical methods are considered to be very 
effective to solve segmentation ambiguities.  
 
Finally, another class of segmentation techniques 
applies several types of features, e.g. Winnow and 
RIPPER algorithms (Meknavin et al, 1997; Blum 
1997). The idea is to learn several sources of fea-
tures that characterize the context in which each 
word tends to occur. Then these features are com-
bined to remove the segmentation ambiguities 
(Charoenpornsawat and Kijsirikul 1998). 
 
 
 
5 Segmentation Model for Urdu 
Although many other languages share the same 
problem of word boundary identification for lan-
guage processing, Urdu problem is unique due to 
its cursive script and its irregular use of space to 
create proper shaping.  Though other languages 
only have space omission challenge, Urdu has both 
omission and insertion problems further confound-
ing the issue.   
 
We employ a combination of techniques to inves-
tigate an effective algorithm to achieve Urdu seg-
mentation.  These techniques are incorporated 
based on knowledge of Urdu linguistic and writing 
system specific information for effective segmen-
tation.  For space omission problem a rule based 
maximum matching technique is used to generate 
all the possible segmentations. The resulting possi-
bilities are ranked using three different heuristics, 
namely min-word, unigram and bigram techniques.   
 
For space insertion, we first sub-classify the prob-
lem based on linguistic information, and then use 
different techniques for the different cases. Space 
insertion between affixes is done by extracting all 
possible affixes from Urdu corpus. Some affixes in 
Urdu are also free morphemes so it is important to 
identify in segmentation process whether or not 
they are part of preceding or following word. For 
example ??? is also a free morpheme (?nose?) and 
a suffix that makes adjective from noun, e.g. in 
word ??? ??? (?dangerous?).   This is done based 
on the part of speech information of the words in 
the context. 
 
Reduplication is handled using edit distance algo-
rithm. In Urdu the reduplicated morpheme is either 
the same or a single edit-distance from the base 
morpheme, e.g. ???? has same string repeated, ????? 
has one insertion, and ???? ???? has one substitu-
tion.  Thus, if a string is less than two edits from its 
neighbor it is an instance of reduplication5. As the 
examples suggest, the reduplication may not only 
be limited to word initial position and may also 
occur word medially.  However, if the length of 
base word is less than four, it is further to avoid 
function words (case markers, postpositions, aux-
                                                          
5
 Insertion, deletion and substitution are all considered contri-
buting a single edit distance here.  
532
iliaries, etc.) from being mistakenly identified as a 
case of reduplication, e.g. ??? ??? (?was done?) has 
two words with a single edit distance but is not a 
reduplicated sequence.  
 
Urdu does not abbreviate strings, but abbreviations 
from English are frequently transliterated into Ur-
du. This sequence can be effectively recognized by 
developing a simple finite automaton. The automa-
ton treats marks all such co-occurring morphemes 
because they are likely to be an English abbrevia-
tion transliterated into Urdu, e.g. ?? ??? ?? 
(?PhD?). If such morphemes are preceding proper 
names then these are not combined as they are 
more likely to be the initials of an abbreviated 
name, e.g. ?? ???? ???  (?N. D. Shakir?).  This ap-
proach confuses the morpheme ?? (genitive case 
marker) of Urdu with the transliteration of English 
letter ?k?.  If we write ?? ?? ??? ?? ???  (?after 
PhD?), it is interpreted as ?P H D K after?.  This 
has to be explicitly handled. 
 
As classification of compounds into one or two 
word sequences is unclear, unambiguous cases are 
explicitly handled via lexical look-up.  An initial 
lexicon of 1850 compound words has been devel-
oped for the system based on a corpus of Urdu. 
Common foreign words are also included in this 
list.   
5.1 Algorithm 
The segmentation process starts with pre-
processing, which involves removing diacritics (as 
they are optionally used in Urdu and not consi-
dered in the current algorithm because they are 
frequently incorrectly marked by users6) and nor-
malizing the input text to remove encoding ambi-
guities7.  Input is then tokenized based on space 
and punctuation characters in the input stream. As 
has been discussed, space does not necessarily in-
dicate word boundary.  However presence of space 
does imply word or morpheme boundary in many 
                                                          
6
 The word  ????? is written with the super-script Alef placed 
on Lam and Yay characters.  The latter variation is correct but 
the former incorrect variation is also common in the corpus.   
7
 Unicode provides multiple codes for a few letters, and both 
composed and decomposed forms for others.  These have to be 
mapped onto same underlying encoding sequence for further 
processing.  See 
http://www.crulp.org/software/langproc/urdunormalization.ht
m for details.   
cases, which can still be useful. The tokenization 
process gives what we call an Orthographic Word 
(OW).  OW is used instead of ?word? because one 
OW may eventually give multiple words and mul-
tiple OWs may combine to give a single word.  
Keeping space related information also keeps the 
extent of problem to be solved within a reasonable 
computational complexity.  For example input 
string ???? ??? ????? (the name of the first author) 
with spaces giving three OWs, creates 2 x 1 x 7 = 
14 possible segmentations when sent separately to 
the maximum matching module (space omission 
error removal - see Figure 2). However, if we re-
move the spaces from the input and send input as a 
single OW ???????????? to maximum matching 
process, we get 77 possible segmentations. This 
number grows exponentially with the length of 
input sentence. Throwing away space character 
means we are losing important information so we 
keep that intact to our use. 
 
After pre-processing a series of modules further 
process the input string and convert the OWs into a 
sequence of words.  This is summarized in Figure 
2 and explained below. 
 
Each OW is sent to a module which deals with 
space omission errors. This module extracts all 
possible morpheme segmentations out of an OW. 
Ten best segmentations of these are selected based 
on minimum-word heuristic.  This heuristic prefers 
segmentations with minimum number of mor-
phemes. Such a heuristic is important to prevent 
the search space to explode. We observed that us-
ing 10-best segmentations proved to be sufficient 
in most cases as OW normally encapsulates two or 
three Urdu words but as a heuristic we also added a 
feature which increases this number of 10-best 
segmentations to 15, 20, 25-best and so on depend-
ing upon number of characters in an OW. Ten best 
segmentations for each OW are merged with the 
extracted segmentations of other OWs. Up till here 
we have successfully resolved all space omission 
errors and the input sentence has been segmented 
into morphemes. The 10n (where ?n? is No. of 
OWs) segmentations are then passed on to space 
insertion error removal module. This module has 
several sub-modules that handle different linguistic 
phenomena like reduplication, affixation, abbrevia-
tions and compounding. 
 
533
The reduplication identification module employs 
single edit distance algorithm to see if adjacent 
morphemes are at single edit-distance of each oth-
er. If the edit distance is less than two, then the 
reduplication is identified and marked. 
 
 
Diacritic Removal / Tokenization 
 
Space Omission Error Removal 
 
Check for Reduplication within an OW 
 
Lexical Look-ups for Spelling Variations 
 
Maximum Matching Module 
 
Ranking-based on Min-Word Heuristic 
 
 
Space Insertion Error Removal 
 
Reduplication Handling 
 
English Abbreviation Handling 
 
Affixation Handling 
 
Compound Word Tagging 
 
 
N-Gram Based Ranking 
 
Figure 2: Urdu Word Segmentation Process 
 
 For example the module will correctly recognize 
consecutively occurring OWs ????? and ????? as a 
case of reduplication.  Reduplication is also ap-
plied earlier in space omission error module as 
there may also be a case of reduplication within a 
single OW. This module handles such cases, by 
dividing words in halves and identifying possible 
reduplications.  Thus, if the words are written 
without space, e.g. ?????????? (innocent) they are 
still identified and tagged as reduplicated words 
????? and ?????. 
 
This list of words is then fed into an automaton 
which recognizes the sequence of abbreviations 
generated by transliterating English letters.   
 
A complete affix list is compiled, and in the next 
stage the short listed word sequences are processed 
through a process which looks through this list to 
determine if any of the OWs may be combined.  
Part of speech information of stem is also used to 
confirm if OWs can be merged. 
Urdu compounds are finally identified.  This is 
done by using a compound list generated through 
the corpus.  As compounding is arbitrary, where 
speakers are not certain in many cases that a se-
quence of morphemes form a single compound or 
not, the segmentation process leaves this level to 
the discretion of the user.  Whichever compounds 
are listed in a compound lexicon are treated as a 
single compound word.  Those not listed are not 
tagged as compounds.  User may enhance this list 
arbitrarily.  The lexicon is initialized with a list of 
non-controversial compound, as verified from pub-
lished dictionaries.   
 
Eventually, all the segmentations are re-ranked. 
We used three different re-ranking methods name-
ly minimum-word heuristic, unigram and bi-gram 
based sequence probabilities, comparative analysis. 
 
Based on the segmentation process, the output se-
quence contains the following tagging.  As dis-
cussed earlier, the word segmentation may be 
defined based on this tagging by the individual 
application using this process. 
 
Phenomenon Tags Examples 
Word <W></W> <W>?????</W> 
Root <R></R> <W><R>?????</R> 
<S>???</S></W> 
Suffix <S></S> <W><R>????</R> 
<S>?????</S></W> 
Prefix <P></P> <W><P>??</P> 
<R>??????</R></W> 
XY Com-
pounds 
<C1></C1> <C1><W>?????</W> 
<W>????</W></C1> 
X-e-Y Com-
pounds 
<C2></C2> <C2><W>????</W> 
<W> ???? </W></C2> 
X-o-Y Com-
pounds 
<C3></C3> <C3><W>???</W> 
<W>?</W> 
<W>????</W></C3> 
Reduplication <Rd></Rd> <Rd><W>????</W> 
<W>????</W></Rd> 
Abbreviations <A></A> <A><W>??</W> 
<W>??</W> </A> 
Figure 3: Urdu Word Segmentation Tag Set 
 
A regular word is tagged using <w> ?</w> pair.  
Roots, suffixes and prefixes are also tagged within 
a word. Reduplication, compounding and abbrevia-
tions are all considered to be multi-word tags and 
relevant words are grouped within these tags. 
Three different kind of compounding is separately 
tagged. 
534
6 Results 
The algorithm was tested on a very small, manual-
ly segmented corpus of 2367 words. The corpus 
we selected contained 404 segmentation errors 
with 221 cases of space omissions and 183 cases of 
space insertions. In space insertion category there 
were 66 cases of affixation, 63 cases of compound-
ing, 32 cases of reduplication and 22 cases of ab-
breviations. The results for all three techniques are 
shown below: 
 
 Categories Errors %ages 
 Affixation 59/66 89.39 
 Reduplication 27/32 84.37 
Abbreviations 19/22 86.36 
Compounds 28/63 44.44 
Total 133/183 72.67 
 
Table 6: Percentages of Number of Errors Detected 
in Different Categories of Space Insertion Error 
There were 221 cases of space omission errors 
where multiple words were written in a continuum. 
Given below is a table that shows how many of 
these were correctly identified by each of the used 
techniques. Clearly, statistical techniques outper-
form a simple minimum number of words heuris-
tic. Bigrams are likely to produce better results if 
the training corpus is improved. Our training cor-
pus contained manually segmented 70K words. 
The bigram probabilities are obtained using 
SRILM-Toolkit (Stolcke, 2002). 
 Categories Errors %ages 
Maximum Matching 186/221 84.16 
Unigram 214/221 96.83 
Bigram 209/221 94.5 
 
Table 7: %age of No. of Errors Detected in Space 
Omission with Different Ranking Techniques 
Following table gives cumulative results for cor-
rectly identified space omission and insertion er-
rors.  
 
Categories Errors %ages 
Maximum Matching 323/404 79.95 
Unigram 347/404 85.8 
Bigram 339/404 83.9 
 
Table 8: %age of No. of Errors Detected Cumula-
tively 
 
Final table counts total number of words (redupli-
cation, compounds and abbreviations cases are in-
clusive) in test corpus and total number of 
correctly identified words after running the entire 
segmentation process. 
 
 
Categories Detected %ages 
Maximum Matching 2209/2367 93.3 
Unigram 2269/2367 95.8 
Bigram 2266/2367 95.7 
 
Table 9: Percentage of Correctly Detected Words 
7 Future Work  
This work presents a preliminary effort on word 
segmentation problem in Urdu. It is a multi-
dimensional problem. Each dimension requires a 
deeper study and analysis. Each sub-problem has 
been touched in this work and a basic solution for 
all has been devised. However to improve on re-
sults each of these modules require a separate 
analysis and study. Statistics is only used in rank-
ing of segmentations. In future work bi-gram sta-
tistics can be used to merge morphemes. More data 
can be tagged to find out joining probabilities for 
the affixes that occur as free morpheme. Such 
analysis will reveal whether an affix is more in-
clined towards joining or occurs freely more fre-
quently. Similarly a corpus can be tagged on 
compounds. For each morpheme its probability to 
occur in compound can be calculated. If two or 
more morphemes with higher compounding proba-
bilities co-occur they can be joined together. Simi-
larly corpus can be tagged for abbreviations.  
 
Ranking of segmentations and affix merging can 
be improved if POS tags are also involved with 
bigram probabilities. Use of POS tags with n-gram 
technique is proven to be very helpful in solving 
unknown word problems. Our model does not ex-
plicitly handle unknown words. Currently the max-
imum matching module splits an unknown OW 
into smaller Urdu morphemes. For example 
?????????? (Kolesnikov) is erroneously split into 
?????????????. More serious problems occur in 
cases when OW is a mixture of known and un-
known words. For example in case ????????????? 
(?Fraser must go?). All these are to be addressed in 
future work. 
 
535
References 
Andreas, S. 2002. SRILM - an extensible language 
modeling toolkit. In Intl. Conf. Spoken Language 
Processing, Denver, Colorado.  
 
Aroonmanakul, W. 2002. Collocation and Thai 
Word Segmentation. In proceeding of SNLPOrien-
tal COCOSDA. 
 
Blum, A. 1997. Empirical Support for Winnow and 
Weighted-Majority Algorithm: Results on a Ca-
lendar Scheduling Domain, Machine Learning, 
26:5-23. 
 
Charoenpornsawat, P., Kijsirikul, B. 1998. Fea-
ture-Based Thai Unknown Word Boundary Identi-
fication Using Winnow. In Proceedings of the 
1998 IEEE Asia-Pacific Conference on Circuits 
and Systems (APCCAS?98). 
 
Gu, P. and Mao, Y. 1994. The adjacent matching 
algorithm of Chinese automatic word segmentation 
and its implementation in the QHFY Chinese-
English system. In International Conference on 
Chinese Computing, Singapore. 
 
Hussain, S. 2003. www. LICT4D . asia / Fonts / 
Nafees_Nastalique.  In the Proceedings of 12th 
AMIC Annual Conference on E-Worlds: Govern-
ments, Business and Civil Society, Asian Media 
Information Center, Singapore.  Also available at 
http://www.crulp.org/Publication/papers/2003/ww
w.LICT4D.asia.pdf.   
 
Hussain, S. 2004. Letter to Sound Rules for Urdu 
Text to Speech System.  In the Proceedings of 
Workshop on Computational Approaches to Arabic 
Script-based Languages, COLING 2004, Geneva, 
Switzerland, 2004. 
 
 
Krawtrakul, A., Thumkanon. C., Poovorawan. Y. 
and Suktarachan. M. 1997. Automatic Thai Un-
known Word Recognition. In Proceedings of the 
natural language Processing Pacific Rim Sympo-
sium. 
Li, B.Y., S. Lin, C.F. Sun, and M.S. Sun. 1991. A 
maximum-matching word segmentation algorithm 
using corpus tags for disambiguation. In 
ROCLING IV, pages: 135-146, Taipei. ROCLING 
 
Liang, N. 1986. A written Chinese automatic seg-
mentation system-CDWS. In Journal of Chinese 
Information Processing, 1(1):44-52. 
 
Meknavin. S., Charenpornsawat. P. and Kijsirikul. 
B. 1997. Feature-based Thai Words Segmentation. 
NLPRS, Incorporating SNLP. 
 
Naseem, T., Hussain, S. 2007.  Spelling Error 
Trends in Urdu.  In the Proceedings of Conference 
on Language Technology (CLT07), University of 
Peshawar, Pakistan. 
 
Nie, J., Jin W., and Hannan, M. 1994. A hybrid 
approach to unknown word detection and segmen-
tation of Chinese. In International Conference on 
Chinese Computing, Singapore. 
 
Phissamay, P., Dalolay,V., Chanhsililath, C., Sili-
masak, O. Hussain, S., and Durrani, N.  2007.  Syl-
labification of Lao Script for Line Breaking.  In 
PAN Localization Working Papers 2004-2007.  . 
 
Poowarawan, Y., 1986. Dictionary-based Thai Syl-
lable Separation. In Proceedings of the Ninth Elec-
tronics Engineering Conference 
 
Rarunrom, S., 1991. Dictionary-based Thai Word 
Separation. Senior Project Report. 
 
Sornlertlamvanich, V. 1995. Word Segmentation 
for Thai in a Machine Translation System (in 
Thai), Papers on Natural Language Processing, 
NECTEC, Thailand 
 
Wong, P., Chan, C. 1996. Chinese Word Segmen-
tation based on Maximum Matching and Word 
Binding Force. In Proceedings of COLING 96, pp. 
200-203. 
 
536
Proceedings of the 8th Workshop on Asian Language Resources, pages 88?94,
Beijing, China, 21-22 August 2010. c?2010 Asian Federation for Natural Language Processing
Word Segmentation for Urdu OCR System 
Misbah Akram 
National University of Computer 
and Emerging Sciences  
misbahakram@gmail.com 
Sarmad Hussain 
Center for Language Engineering,  
Al-Khawarizmi Institute of Computer 
Science, University of Engineering and 
Technology, Lahore, Pakistan 
sarmad.hussain@kics.edu.pk 
 
Abstract 
This paper presents a technique for word 
segmentation for the Urdu OCR system. 
Word segmentation or word tokeniza-
tion is a preliminary task for Urdu lan-
guage processing. Several techniques 
are available for word segmentation in 
other languages. A methodology is pro-
posed for word segmentation in this pa-
per which determines the boundaries of 
words given a sequence of ligatures, 
based on collocation of ligatures and 
words in the corpus. Using this tech-
nique, word identification rate of 
96.10% is achieved, using trigram prob-
abilities normalized over the number of 
ligatures and words in the sequence. 
1 Introduction 
Urdu uses Nastalique style of Arabic script 
for writing, which is cursive in nature.  Charac-
ters join together to form ligatures, which end 
either with a space or with a non-joining charac-
ter.  A word may be composed of one of more 
ligatures.  In Urdu, space is not used to separate 
two consecutive words in a sentence; instead 
readers themselves identify the boundaries of 
words, as the sequence of ligatures, as they read 
along the text. Space is used to get appropriate 
character shapes and thus it may even be used 
within a word to break the word into constituent 
ligatures (Naseem 2007, Durrani 2008). There-
fore, like other languages (Theeramunkong & 
Usanavasin, 2001; Wan and Liu, 2007; Khanka-
sikam & Muansuwan, 2005; Haruechaiyasak et 
al., 2008; Haizhou & Baosheng, 1998), word 
segmentation or word tokenization is a prelimi-
nary task for Urdu language processing. It has 
applications in many areas like spell checking, 
POS tagging, speech synthesis, information re-
trieval etc. This paper focuses on the word seg-
mentation problem from the point of view of 
Optical Character Recognition (OCR) System. 
As space is not visible in typed and scanned text, 
spacing cues are not available to the OCR for 
word separation and therefore segmentation has 
to be done more explicitly. This word segmenta-
tion model for Urdu OCR system takes input in 
the form of a sequence of ligatures recognized 
by an OCR to construct a sequence of words 
from them.   
2 Literature Review 
Many languages, e.g., English, French, 
Hindi, Nepali, Sinhala, Bengali, Greek, Russian, 
etc. segment text into a sequence of words using 
delimiters such as space, comma and semi colon 
etc., but on the other hand many Asian languag-
es like Urdu, Persian, Arabic, Chinese, 
Dzongkha, Lao and Thai have no explicit word 
boundaries. In such languages, words are seg-
mented using more advanced techniques, which 
can be categorized into three methods:   
 
(i) Dictionary/lexicon based approaches  
(ii) Linguistic knowledge based approaches  
(iii) Machine learning based approach-
es/statistical approaches  
(Haruechaiyasak et al, 2008) 
 
Longest matching (Poowarawan, 1986; Richard 
Sproat, 1996) and maximum matching (Sproat 
et al, 1996; Haizhou & Baosheng, 1998) are 
examples of lexicon based approaches. These 
techniques segment text using the lexicon. Their 
88
accuracy depends on the quality and size of the 
dictionary. 
N-Grams (Chang et al, 1992; Li Haizhou 
et al, 1997; Richard Sproat, 1996; Dai & Lee, 
1994; Aroonmanakun, 2002) and Maximum 
collocation (Aroonmanakun, 2002) are Linguis-
tic knowledge based approaches, which also 
rely very much on the lexicon. These approach-
es select most likely segmentation from the set 
of possible segmentations using a probabilistic 
or cost-based scoring mechanism. 
Word segmentation using decision trees 
(Sornlertlamvanich et al, 2000; Theeramun-
kong & Usanavasin, 2001) and similar other 
techniques fall in the third category of word 
segmentation techniques. These approaches use 
a corpus in which word boundaries are explicit-
ly marked. These approaches do not require dic-
tionaries. In these approaches ambiguity prob-
lems are handled by providing a sufficiently 
large set of training examples to enable accurate 
classification. 
A knowledge based approach has been 
adopted for earlier work on Urdu word segmen-
tation (Durrani 2007; also see Durrani and Hus-
sain 2010). In this technique word segmentation 
of Urdu text is achieved by employing know-
ledge based on the Urdu linguistics and script. 
The initial segmentations are ranked using min-
word, unigram and bigram techniques. It reports 
95.8 % overall accuracy for word segmentation 
of Urdu text. Mukund et al (2009) propose us-
ing character model along with linguistic rules 
and report 83% precision.  Lehal (2009) propos-
es a two stage process, which first uses Urdu 
linguistic knowledge, and then uses statistical 
information of Urdu and Hindi (also using 
transliteration into Hindi) in the second stage 
for words not addressed in the first stage, re-
porting an accuracy of 98.57%.   
These techniques use characters or words in 
the input, whereas an OCR outputs a series of 
ligatures.  The current paper presents work done 
using statistical methods as an alternative, 
which works with ligatures as input.   
3 Methodology 
Current work uses the co-occurrence in-
formation of ligatures and words to construct a 
statistical model, based on manually cleaned 
and segmented training corpora.  Ligature and 
word statistics are derived from these corpora. 
In the decoding phase, first all sequences of 
words are generated from input set of ligatures 
and ranking of these sequences is done based on 
lexical lookup. Top k sequences are selected for 
further processing, based on the number of valid 
words. Finally, the probability of each of the k 
sequences is calculated for the final decision. 
Details are described in the subsequent sections. 
3.1 Data collection and preparation 
An existing lexicon of 49630 unique words 
is used (derived from Ijaz et al 2007). The cor-
pus used for building ligature grams consists of 
half a million words. Of these, 300,000 words 
are taken from the Sports, Consumer Informa-
tion and Culture/Entertainment domains of the 
18 million word corpus (Ijaz et al 2007), 
100,000 words are obtained from Urdu-Nepali-
English Parallel Corpus (available at 
www.PANL10n.net), and another 100,000 
words are taken from a previously POS tagged 
corpus (Sajjad, 2007; tags of this corpus are re-
moved before further processing).  This corpus 
is manually cleaned for word segmentation er-
rors, by adding missing spaces between words 
and replacing spaces with Zero Width Non-
Joiner (ZWNJ) within words.  For the computa-
tion of word grams, the 18 million word corpus 
of Urdu is used (Ijaz et al 2007). 
3.2 Count and probability calculations 
Table 1 and Table 2 below give the counts 
for unigram, bigrams and trigram of the liga-
tures and the words derived from the corpora 
respectively. 
 
Ligature 
Tokens 
Ligature 
Unigram 
Ligature 
Bigrams 
Ligature 
Trigrams 
1508078 10215 35202 65962 
Table 1. Unigram, bigram and trigram counts of 
the ligature corpus 
Word 
Tokens 
Word 
Unigrams 
Word 
Bigrams 
Word 
Trigrams 
17352476 157379 1120524 8143982 
Table 2. Unigram, bigram and trigram counts of 
the word corpus 
After deriving word unigrams, bigrams, 
and trigrams, the following cleaning of corpus is 
89
performed.  In the 18 million word corpus, cer-
tain words are combined due to missing space, 
but are separate words. Some of these words 
occur with very high frequency in the corpus. 
For example ?????? (ho ga, ?will be?) exists as 
single word rather than two words due to miss-
ing space. To solve this space insertion problem, 
a list of about 700 words with frequency greater 
than 50 is obtained from the word unigrams. 
Each word of the list is manually reviewed and 
space is inserted, where required. Then these 
error words are removed from the word unigram 
and added to the word unigram frequency list as 
two or three individual words incrementing re-
spective counts.  
For the space insertion problem in word 
bigrams, each error word in joined-word list 
(700-word list) is checked. Where these error 
words occurs in a bigram word frequency list, 
for example ???? ????? (kiya ho ga ?will have 
done?) exists in the bigram list and contains 
????" " error word, then this bigram entry ???? ????? 
is removed from the bigram list and counts of 
? ?? ?? ? and ???? ??? are increased by the count of 
???? ?????. If these words do not exist in the word 
bigram list then they are added as a new bi-
grams with the count of ???? ?????. Same proce-
dure is performed for the word trigrams. 
The second main issue is with word-affixes, 
which are sometimes separated by spaces from 
the words. Therefore, in calculations, these are 
treated as separate words and exist as bigram 
entries in the list rather than a unigram entry. 
For example "??? ???" (sehat+mand, ?healthy?) 
exists as a bigram entry but in Urdu it is a single 
word.  To cope with this problem, a list of 
word-affixes is used. If any entry of word bi-
gram matches with an affix, then this word is 
combined by removing spurious space from it 
(and inserting ZWNJ, if required to maintain its 
glyph shape). Then this word is inserted in the 
unigram list with its original bigram count and 
unigram list updated accordingly. Same proce-
dure is performed if a trigram word matches 
with an affix.  
After cleaning, unigram, bigram and tri-
gram counts for both words and ligatures are 
calculated.  To avoid data sparseness One Count 
Smoothing (Chen & Goodman, 1996) is applied.  
3.3 Word sequences generation from input 
The input, in the form of sequence of liga-
tures is used to generate all possible words.  
These sequences are then ranked based on real 
words. For this purpose, a tree of these se-
quences is incrementally built. The first ligature 
is added as a root of tree, and at each level two 
to three additional nodes are added. For exam-
ple the second level of the tree contains the fol-
lowing tree nodes. 
? Current ligature forms a separate word, se-
parated with space, from the sequence at its 
parent, l1 l2 
? Current ligature concatenates, without a 
space, with the sequence at its parent, l1l2 
? Current ligature concatenates, without a 
space, with the sequence at its parent but 
with an additional, l1ZWNJl2  
For each node, at each level of the tree, a nu-
meric value is assigned, which is the sum of 
squares of the number of ligatures in each word 
which is in the dictionary.  If a word does not 
exist in dictionary then it does not contribute to 
the total sum. If a node-string has only one word 
and this word does not occur in the dictionary as 
a valid word then it is checked that this word 
may occur at the start of any dictionary entry. In 
this case numeric value is also assigned.   
After assignment, nodes are ranked ac-
cording to these values and best k (beam value) 
nodes are selected. These selected nodes are 
further ranked using statistical methods dis-
cussed below. 
3.4 Best word segmentation selection 
For selection of the most probable word 
segmentation sequence word and ligature mod-
els are used.  For word probabilities the follow-
ing is used. 
PW =      argmax ? SPw  
To reduce the complexity of computing, Mar-
kov assumption are taken to give bigram and 
trigram approximations (e.g., see Jurafsky & 
Martin 2006) as given below. 
PW =      argmax ? S? P w|w            PW =      argmax ? S? Pw|wwProceedings of the 8th Workshop on Asian Language Resources, pages 95?102,
Beijing, China, 21-22 August 2010. c?2010 Asian Federation for Natural Language Processing
Dzongkha Word Segmentation
Sithar Norbu, Pema Choejey, Tenzin Dendup
Research Division
Department of Information Technology & 
Telecom
{snorbu, pchoejay, tdendup}@dit.gov.bt
Sarmad Hussain, Ahmed Mauz
   Center for Research in Urdu Language Processing
National University of Computer & Emerging 
Sciences
{sarmad.hussain, ahmed.mauz}@nu.edu.pk
Abstract
Dzongkha,  the  national  language  of 
Bhutan, is continuous in written form 
and it fails to mark the word boundary. 
Dzongkha word segmentation is one of 
the  fundamental  problems  and  a 
prerequisite  that  needs  to  be  solved 
before  more  advanced  Dzongkha  text 
processing and other natural  language 
processing  tools  can  be  developed. 
This paper presents our initial attempt 
at segmenting Dzongkha sentences into 
words.  The  paper  describes  the 
implementation of Maximal  Matching 
(Dictionary based Approach) followed 
by bigram techniques  (Non-dictionary 
based  Approach)  in  segmenting  the 
Dzongkha  scripts.  Although  the  used 
techniques  are  basic  and  naive,  it 
provides  a  baseline  of  the  Dzongkha 
word  segmentation  task.  Preliminary 
experimental  results  show  percentage 
of  segmentation  accuracy.  However, 
the segmentation accuracy is dependent 
on the  type  of  document  domain  and 
size and quality of the lexicon and the 
corpus. Some of the related issues for 
future directions are also discussed.
Keywords:  Dzongkha  script,  word 
segmentation,  maximal  matching,  bigram 
technique, smoothing technique.
1    Introduction
Segmentation of a sentence into word is one of 
the  necessary  preprocessing  tasks  and  is 
essential  in  the  analysis  of  natural  language 
processing.  This  is  because  word  is  both 
syntactically  and  semantically,  the 
fundamental  unit  for  analyzing  language 
structure.  Like  in  any  other  language 
processing task, Dzongkha word segmentation 
is also viewed as one of the fundamental and 
foremost  steps in Dzongkha related language 
processing tasks.
The most challenging features of Dzongkha 
script is the lack of word boundary separation 
between  the  words1.  So,  in  order  to  do  the 
further  linguistic  and  natural  language 
processing  tasks,  the  scripts  should  be 
transformed into a chain of words. Therefore, 
segmenting  a  word  is  an  essential  role  in 
Natural  Language  Processing.  Like  Chinese, 
Japanese  and  Korean  (CJK)  languages, 
Dzongkha  script  being  written  continuously 
without  any  word  delimiter  causes  a  major 
problem in natural language processing tasks. 
But,  in  case  of  CJK,  Thai,  and  Vietnamese 
languages,  many  solutions  have  been 
published  before.  For  Dzongkha,  this  is  the 
first  ever  word  segmentation  solution  to  be 
documented. 
In  this  paper,  we  describe  the  Dzongkha 
word segmentation, which is performed firstly 
using the Dictionary based approach where the 
principle  of  maximal  matching  algorithm  is 
applied  to  the  input  text.  Here,  given  the 
collection  of  lexicon,  the  maximal  matching 
algorithm selects the segmentation that yields 
the minimum number of words token from all 
possible segmentations of  the input  sentence. 
Then,  it  uses  non-dictionary  based  approach 
where  bigram  technique  is  applied.  The 
probabilistic  model  of  a  word  sequence  is 
1http://www.learntibetan.net/grammar/sentence.htm  
95
studied  using  the  Maximum  Likelihood 
Estimation  (MLE).  The  approach  using  the 
MLE has an obvious disadvantage because of 
the  unavoidably  limited  size  of  the  training 
corpora (Nuges, 2006). To this problem of data 
sparseness,  the  idea  of  Katz  back-off  model 
with  Good-Turing  smoothing  technique  is 
applied. 
2    Dzongkha Script
Dzongkha language is the official and national 
language of  Bhutan.  It  is  spoken as  the  first 
language  by  approximately  130,000  people 
and as the second language by about 470,000 
people (Van Driem and Tshering, 1998).
Dzongkha  is  very  much  related  to  Sino-
Tibetan  language  which  is  a  member  of 
Tibeto-Burmese  language  family.  It  is  an 
alphabetic  language,  with  phonetic 
characteristics  that  mirror  those  of  Sanskrit. 
Like many of the alphabets of India and South 
East  Asia,  the  Bhutanese  script  called 
Dzongkha script is also a syllabic2. A syllable 
can  contain  as  little  as  one  character  or  as 
many as six characters. And a word can be of 
one syllable, two syllable or multiple syllables. 
In the written form, Dzongkha script contains a 
dot, called Tsheg (  ? ) that serve as syllable and 
phrase delimiter, but words are not separated at 
all. 
For example,
Dzongkha Transliteration English Syllables
????? dmarpo red Single-syllabled
???????? slop-pon Teacher Two-syllabled
?????????? hjam-tog-to easy Three-syllabled
??????????? har-ri-hur-ri crowdedness/confusion Four-syllabled
Table 1: Different syllabled Dzongkha scripts. 
The  sentence  is  terminated  with  a  vertical 
stroke  called Shad (   ? ).  This  Shad acts  as  a 
full_stop.  The  frequent  appearance  of 
2http://omniglot.com/writing/tibetan.htm  
whitespace in the Dzongkha sentence serves as 
a phrase boundary or comma, and is a faithful 
representation  of  speech:  after  all  in  speech, 
we pause not between words, but either after 
certain phrases or at the end of sentence. 
The  sample  dzongkha  sentence  reads  as 
follows:
??????????????????????????? ????????????? ?????????
?????? ?????????????????????? ?????????????????????
??? ????????????????????????????? ?????????????????
????????? ???????????????? ????????????? ???????
??????????????????????????????? ?????????????????????
???????????????????????????????????? ?????? ???? ??
??????????????????????
(English Translation of example text)
[The  Dzongkha  Development  Commission  is 
the  leading  institute  in  the  country  for  the 
advancement  of  Dzongkha,  the  national 
language  of  Bhutan.  It  is  an  independent 
organization established by the Fourth King of 
Bhutan,  His  Majesty the  King  Jigme  Singye 
Wangchuck, in 1986.]
3    Materials and Methods
Since,  our  language  has  no  word  boundary 
delimiter,  the  major  resource  for  Dzongkha 
word segmentation  is  a  collection of  lexicon 
(dictionary).  For  such  languages,  dictionaries 
are  needed  to  segment  the  running  texts. 
Therefore, the coverage of a dictionary plays a 
significant  role  in  the  accuracy  of  word 
segmentation (Pong and Robert, 1994). 
The dictionary that we used contains 23,333 
word  lists/lexicons.  The  lexicons  were 
collected  from  ?Dzongkha  Dictionary?,  2nd 
Edition, Published by Dzongkha Development 
Authority,  Ministry  of  Education,  2005, 
(ddc@druknet.bt).  The  manually  segmented 
text corpus containing 41,739 tokens are also 
used  for  the  method.  The  text  corpora  were 
collected  from  different  sources  like 
newspaper articles, dictionaries, printed books, 
etc.  and  belong  to  domains  such  as  World 
Affairs,  Social  Sciences,  Arts,  Literatures, 
Adventures, Culture and History.  Some texts 
like poetry and songs were added manually. 
96
Table  below  gives  the  glimpse  of  textual 
domains contained in the text corpora used for 
the method (Chungku et al, 2010).
Domain Sub domain (%)
World Affairs Bilateral relations 12%
Social Science Political Science 2%
Arts Poetry/Songs/Ballad 9%
Literatures Essays/Letters/Dictionary 72%
Adventures Travel Adventures 1%
Culture Culture Heritage/Tradition 2%
History Myths/Architecture 2%
 
Table 2:  Textual domain contained in Corpus
Figure  1  below  shows  the  Dzongkha  Word 
Segmentation Process. 
Figure  1:  Dzongkha  Word  Segmentation 
Process. 
Dzongkha  word  segmentation  implements  a 
principle  of  maximal  matching  algorithm 
followed by statistical (bigram) method. It uses 
a word list/lexicon at first to segment the raw 
input sentences. It then uses MLE principles to 
estimate  the  bigram  probabilities  for  each 
segmented words.  All  possible segmentation 
of an input sentence by Maximal Matching are 
then  re-ranked  and  picked  the  mostly  likely 
segmentation  from  the  set  of  possible 
segmentations  using  a  statistical  approach 
(bigram technique). This is to decide the best 
possible  segmentation  among  all  the  words 
(Huor et al, 2007) generated by the maximal 
matching  algorithm.  These  mechanisms  are 
described in the following
3.1    Maximal Matching Algorithm
The basic idea of Maximal matching algorithm 
is, it first generates all possible segmentations 
for  an  input  sentence  and  then  selects  the 
segmentation  that  contains  the  minimum 
number  of  word  tokens.  It  uses  dictionary 
lookup. 
We used the following steps to segment the 
given input sentence.
1. Read  the  input  of  string  text.  If  an 
input  line  contains  more  than  one 
sentence,  a  sentence  separator  is 
applied  to  break  the  line  into 
individual sentences.
2. Split input string of text by Tsheg(   ? ) 
into syllables.
3. Taking the next syllables, generate all 
possible strings
4. If the number of string is greater than 
n for some value n3
? Look  up  the  series  of  string  in  the 
dictionary to find matches, and assign 
some weight-age4 accordingly.
? Sort the string on the given weight-age
? Delete  (number  of  strings  ?  n)  low 
count strings.
5. Repeat from Step 2 until all syllables 
are processed.
The  above  mentioned  steps  produced  all 
possible segmented words from the given input 
sentence based on the provided lexicon. Thus, 
the overall accuracy and performance depends 
on the coverage of lexicon (Pong and Robert, 
1994).
3The greater the value of n, the better the chances of 
selecting the sentence with the fewest words from 
the possible segmentation. 
4If the possible string is found in the dictionary 
entries, the number of syllable in the string is 
counted. Then, the weight-age for the string is 
calculated as (number of syllable)2 else it carries the 
weight-age 0
97
3.2    Bigram Method
(a)    Maximum Likelihood Estimation5
In the bigram method, we make the 
approximation that the probability of a word 
depends on identifying the immediately 
preceding word. That is, we calculate the 
probability of next word given the previous 
word, as follows:
P ?w1n?=? i=1n P ?wi/w i?1?
where
? P ?wi /wi?1?= count ?wi?1w i ?count ?wi?1 ?
where
? count ?wi?1wi ? is  a  total  occurrence 
of  a  word  sequence  w i?1wi in  the 
corpus, and
? count ?wi?1? is a total occurrence of a 
word w i?1 in the corpus.
To make  P ?wi /wi?1? meaningful  for  i=1 , 
we  use  the  distinguished  token  <s>  at  the 
beginning of the sentence; that is, we pretend 
w0 = <s>. In addition, to make the sum of the 
probabilities  of  all  strings  equal  1,  it  is 
necessary to place a distinguished token </s> 
at the end of the sentence.
One of the key problems with the MLE is 
insufficient  data.  That  is,  because  of  the 
unavoidably limited size of the training corpus, 
vast majority of the word are uncommon and 
some of the bigrams may not occur at all in the 
corpus, leading to zero probabilities. 
Therefore,  following  smoothing  techniques 
were used to count the probabilities of unseen 
bigram.  
(b)    Smoothing Bigram Probabilistic
The  above  problem  of  data  sparseness 
underestimates the probability of some of the 
sentences  that  are  in  the  test  set.  The 
smoothing technique helps to prevent errors by 
making  the  probabilities  more  uniform. 
Smoothing  is  the  process  of  flattening  a 
5P.M, Nugues. An Introduction to Language 
Processing with Perl and Prolog: An Outline of 
Theories, Implementation, and Application with 
Special Consideration of English, French, and 
German (Cognitive Technologies) (95 ? 104). 
probability distribution implied by a language 
model  so that  all  reasonable  word sequences 
can  occur  with  some  probability.  This  often 
involves  adjusting  zero  probabilities  upward 
and high probabilities  downwards.  This way, 
smoothing  technique  not  only  helps  prevent 
zero probabilities but  the overall  accuracy of 
the  model  are  also  significantly  improved 
(Chen and Goodman, 1998).
In Dzongkha word segmentation, Katz back-
off  model  based  on  Good-Turing  smoothing 
principle is applied to handle the issue of data 
sparseness.  The  basic  idea  of  Katz  back-off 
model is to use the frequency of n-grams and if 
no n-grams are available, to back off to  (n-1) 
grams,  and  then  to  (n-2) grams  and  so  on 
(Chen and Goodman, 1998).
The  summarized  procedure  of  Katz 
smoothing technique is given by the following 
algorithm:6
Pkatz ?wi?wi?1 ?={ C ?wi?1 /wi ? ifr>kdrC ?wi?1 /wi ? ifk?r>0? ?wi?1 ?P ?wi ? ifr=0 }
where
? r is the frequency of bigram counts
? k  is  taken  for  some  value  in  the 
range of  5  to  10,  other  counts  are 
not re-estimated. 
? dr =
r?
r ??k+1 ?
nK+1
n1
1? ?k+1 ? nk+1n1
?
? ?wi?1? =
1? ?
wi :r>0
PKatz ?wi?w i?1?
1? ?
wi :r>0
PKatz ?w i ?
With the above equations, bigrams with non-
zero count  r  are discounted according to the 
6X. Huang, A. Acero, H.-W.Hon, Spoken Language 
Processing: A Guide to Theory, Algorithm and 
System Development, (Prentice-Hall Inc., New 
Jersey 07458, 2001), 559 - 561.
98
discount  ratio  dr= r
?
r  i.e.,  the  count 
subtracted  from  the  non-zero  count  are 
redistributed  among  the  zero  count  bigrams 
according to the next lower-order distribution, 
the unigram model.
4    Evaluations and Results
Subjective evaluation has been performed by 
comparing  the  experimental  results  with  the 
manually segmented tokens. The method was 
evaluated  using  different  sets  of  test 
documents from various domains consisting of 
714  manually  segmented  words.  Table  3 
summarizes the evaluation results.
Document text Correct Detect
(Correctly segmented 
tokens / total no. of 
words)
Accuracy
Astrology.txt 102/116 87.9%
dzo_linux.txt 85/93 91.4%
movie_awards.txt 76/84 90.5%
News.txt 78/85 91.8%
Notice.txt 83/92 90.2%
Religious.txt 63/73 89.0%
Song.txt 57/60 95.0%
Tradition.txt 109/111 98.2%
Total 653/714 91.5%
Table 3: Evaluation Results
Accuracy in %age are measured as:
Accuracy(%) = NT?100
where
? N is  the  number  of  correctly 
segmented tokens
? T is  the  total  number  of  manually 
segmented tokens/ Total number of 
words. 
We have taken the extract of different test data 
hoping it may contain fair amount of general 
terms, technical terms and common nouns. The 
manually segmented corpus containing 41,739 
tokens are used for the method. 
In the sample comparison below, the symbol 
(   ? )  does  not  make  the  segmentation  unit's 
mark,  but  (   ? )  takes  the  segmentation  unit's 
mark,  despite  its  actual  mark  for  comma  or 
full_stop. The  whitespace in the sentence are 
phrase boundary or comma,  and is  a faithful 
representation of speech where we pause not 
between words, but either after certain phrases 
or at the end of sentence. 
Consider the sample input sentence:
?????????????????? ????????????????????????????????? ???
?????????????????????????? ??????????????? ?????????
??????????????? ??????????????????????????????????????
???????? ??????? ??????????????????????????????????????
????????????????????
Manually  segmented  sentence  of  the  sample 
input sentence:
?????????????????? ????????????????????????????????? 
????????????????????????????? ??????????????? ?????
??????????????????? ??????????????????????????????
???????????????? ??????? ???????????????????????????
???????????????????????????????
Using maximal matching algorithm:
??????  ???  ?????  ????  ??????  ????????  ???  ????? 
?????  ????  ??  ???????  ????  ??  ?????  ???  ????? 
???  ???????  ???  ?????  ?????????  ????????  ??????? 
???????  ???  ????????  ????  ????  ????  ????  ???? 
????????  ???  ????  ?????  ???  ???????  ????  ???? 
????  ???????  ????  ????  ???  ??  ??  ?????  ????
System segmented version of the sample input 
sentence: Underlined text shows the incorrect 
segmentation.
?????????????????? ????????????????????????????????? 
?????????????????????????????  ????????????????????
???????????????????  ??????????????????????????????
99
????????????????  ??????????????????????????????????
??????????????????????????? ????  
5    Discussions
During the process of word segmentation, it is 
understood  that  the  maximal  matching 
algorithm is simply effective and can produce 
accurate segmentation only if all the words are 
present  in  the  lexicon.  But  since  not  all  the 
word entry can be found in lexicon database in 
real  application,  the  performance  of  word 
segmentation  degrades  when  it  encounters 
words that are not in the lexicon (Chiang et al, 
1992).
Following are the significant problems with 
the  dictionary-based  maximal  matching 
method  because  of  the  coverage  of  lexicon 
(Emerson, 2000):
? incomplete and inconsistency of the 
lexicon database
? absence of technical domains in the 
lexicon
? transliterated foreign names
? some  of  the  common  nouns  not 
included in the lexicon
? lexicon/word  lists  do  not  contains 
genitive  endings  ??? (expresses  the 
genitive relationship as a quality or 
characteristic of the second element, 
for  example,  ????????? 'son  of  a 
pauper') and  ?? (first  singular 
possessive,  for  example,  ???????? 
which  actually  is ????????? 'my 
daughter') that  indicates  possession 
or a part-to-whole relationship, like 
English 'of'.  
A Dzongkha sentence like:
????????????? ??????????????? ????
may include the following ambiguous possible 
segmentation based on simple dictionary 
lookup:
1.???????????????????????????????
this | Dzongkha | of | research | written 
document | is
2.???????????????????????????????
this | Dzongkha | of | arrange together | search/
expose | written document | is
3.???????????????????????????????
this | fortress | mouth/surface | of | research | 
written document | is
These  problems  of  ambiguous  word 
divisions, unknown proper names, are lessened 
and solved partially when it is re-ranked using 
the bigram techniques. Still the solution to the 
following issues needs to be discussed in the 
future. Although the texts were collected from 
widest range of domains possible, the lack of 
available  electronic  resources  of  informative 
text adds to the following issues:
? small  number  of  corpus  were  not 
very impressive for the method
? ambiguity  and  inconsistent  of 
manual  segmentation of a token in 
the  corpus  resulting  in 
incompatibility  and  sometimes  in 
conflict.
Ambiguity  and  inconsistency  occurs 
because of  difficulties  in  identifying  a  word. 
Since the manual segmentation of corpus entry 
was  carried  out  by  humans  rather  than 
computer, such humans have to be well skilled 
in identifying or understanding what a word is. 
The problem with the Dzongkha scripts that 
also hampers the accuracy of dzongkha word 
segmentation  includes  the  issues  such  as 
ambiguous  use  of  Tsheg  (   ? ) in  different 
documents.  There  are  two  different  types  of 
Tsheg: Unicode 0F0B (  ? ) called Tibetan mark 
inter  syllabic  tsheg is  a  normal  tsheg that 
provides  a  break  opportunity.  Unicode  0F0C 
(  ? ) called Tibetan Mark Delimiter Tsheg Bstar 
is  a  non-breaking  tsheg and  it  inhibits  line 
breaking.
For example,
input sentence with Tsheg 0F0B: 
?????????????????????? ????????????????????? ??????
???????????????
achieves 100% segmentation as follow:
100
??????? ??? ??????? ????? ??????? ??? ???? ???? ??? 
?? ???? ??? ????? ???? ??? 
whereas  the  same input  sentence with Tsheg 
0F0C is incorrectly segmented as follows:
??????????????????????? ?????????????????????? 
?????????????????????
There are also cases like shortening of words, 
removing  of  inflectional  words  and 
abbreviating of words for the convenience of 
the writer.  But  this  is  not  so reflected in the 
dictionaries, thus affecting the accuracy of the 
segmentation. 
Following words has a special abbreviated way 
of writing a letter or sequence of letters at the 
end of a syllable as
?????    as ???
??????  as ??? 
etc..  
6    Conclusion and Future works
This  paper  describes  the  initial  effort  in 
segmenting  the  Dzongkha  scripts.  In  this 
preliminary  analysis  of  Dzongkha  word 
segmentation,  the  preprocessing  and 
normalizations are not dealt with. Numberings, 
special  symbols  and  characters  are  also  not 
included. These issues will have to be studied 
in the future.  A lot of discussions and works 
also  have  to  be  done  to  improve  the 
performance of word segmentation. Although 
the study was a success,  there are still  some 
obvious limitations, such as its dependency on 
dictionaries/lexicon, and the current Dzongkha 
lexicon  is  not  comprehensive.  Also,  there  is 
absence  of  large  corpus  collection  from 
various  domains.  Future  work  may  include 
overall improvement of the method for better 
efficiency,  effectiveness and functionality,  by 
exploring  different  algorithms.  Furthermore, 
the inclusion of POS Tag sets  applied on n-
gram techniques which is proven to be helpful 
in handling the unknown word problems might 
enhance  the  performance  and  accuracy. 
Increasing  corpus  size  might  also  help  to 
improve the results. 
Acknowledgment
This research work was carried out as a part of 
PAN  Localization  Project 
(http://www.PANL10n.net)  with  the  aid  of  a 
grant  from  the  International  Development 
Research  Centre  (IDRC),  Ottawa,  Canada, 
administered through the Center of Research in 
Urdu Language Processing (CRULP), National 
University  of  Computer  and  Emerging 
Sciences  (NUCES),  Pakistan.  The  research 
team would also like to express the gratitude to 
all the PAN Localization Project members of 
Bhutanese  team  based  at  Department  of 
Information  Technology  and  Telecom,  for 
their  efforts  in  collecting,  preparing  and 
providing  with  the  lexicon,  corpus,  useful 
training  and  testing  materials  and  finally  for 
the their valuable support and contribution that 
made this research successful. 
References
Chen,  Stanley  F.,  Joshua  Goodman,  1998.  An 
Empirical  Study  of  Smoothing  Techniques  for  
Language Modeling,  Computer  Science Group, 
Harvard University, Cambridge, Massachusetts
Chiang,  T-Hui., J-Shin Chang,,  M-Yu Lin,  K-Yih 
Su,  2007.  Statistical  models  for  word 
segmentation  and  unknown  word  resolution.  
Department of Electrical Engineering , National 
Tsing Hua University, Hsinchu, Taiwan.
Chungku.,  Jurmey  Rabgay,  Gertrud  Faa?,  2010. 
NLP  Resources  for  Dzongkha.  Department  of 
Information Technology & Telecom, Ministry of 
Information  &  Communications,  Thimphu, 
Bhutan.
Durrani,  Nadir  and  Sarmad Hussain,  2010.  Urdu 
Word  Segmentation.  Human  Language 
Technologies:  11th  Annual  Conference  of  the 
North American Chapter of the Association for 
Computational  Linguistics,  Los  Angeles,  June 
2010.
Emerson,  Thomas.  2000.  Segmenting  Chinese  in  
Unicode. 16th International Unicode conference, 
Amsterdam, The Netherlands, March 2000
Haizhou,  Li  and  Yuan  Baosheng,  1998.  Chinese 
Word Segmentation. Language, Information and 
Computation (PACLIC12), 1998.
Haruechaiyasak,  C.,  S  Kongyoung,  M.N.  Dailey, 
2008.  A  Comparative  Study  on  Thai  Word  
101
Segmentation  Approaches.  In  Proceedings  of 
ECTI-CON, 2008.
Huang,  X.,  A.  Acero,  H.-W.  Hon,  2001.  Spoken  
Language  Processing:  A  Guide  to  Theory,  
Algorithm and System Development (pp. 539 ?  
578). Prentice-Hall Inc., New Jersey 07458.
Huor,  C.S.,  T.  Rithy,   R.P.  Hemy,  V.  Navy,  C. 
Chanthirith,  C.  Tola,  2007.  Word  Bigram  Vs 
Orthographic Syllable Bigram in Khmer Word 
Segmentation.  PAN  Localization  Working 
Papers 2004 - 2007. PAN Localization Project, 
National University of Computer and Emerging 
Sciences, Lahore, Pakistan.
Jurafsky, D., A. Acero, H.-W. Hon, 1999.  Speech  
and  Language  Processing:  An  Introduction  to  
Natural  Language  Processing,  Computational 
Linguistics and Speech Recognition (pp. 189 ?  
230). Prentice-Hall Inc., New Jersey 07458.
Nugues,  P.M. 2006.  An Introduction to Language 
Processing with Perl and Prolog: An Outline of  
Theories, Implementation, and Application with 
Special  Consideration of  English,  French,  and  
German  (Cognitive  Technologies)  (pp.  87  ? 
104). Springer-Verlag Berlin Heidelberg 
Pong,  L.W.  and  Robert.  1994.  Chinese  word 
segmentation  based  on  maximal  matching and  
bigram  techniques.  Retrieved  from  The 
Association  for  Computational  Linguistics  and 
Chinese  Language  Processing.  On-line: 
http://www.aclclp.org.tw/rocling/1994/P04.pdf
Sunthi,  Thepchai.  2007.  Word  Segmentation  and 
POS  tagging.  ADD-2  Workshop,  SIIT, 
NECTEC, Thailand.
Van Driem, George. and Karma Tshering, (Collab), 
?Languages  of  Greater  Himalayan  Region?, 
1998.
102
Proceedings of the 8th Workshop on Asian Language Resources, pages 137?143,
Beijing, China, 21-22 August 2010. c?2010 Asian Federation for Natural Language Processing
	

	



	
	

