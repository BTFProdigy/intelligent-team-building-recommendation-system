Chinese Text Summarization Based on Thematic Area Detection 
Po Hu 
Department of Computer 
Science 
Central China Normal 
University 
Wuhan, China, 430079 
geminihupo@163.com 
Tingting He 
Department of Computer 
Science 
Central China Normal 
University 
Wuhan, China, 430079 
 hett@163.net 
Donghong Ji 
Institute for Infocomm 
Research 
Heng Mui Keng Terrace, 
Singapore, 119613 
dhji@i2r.a-star.edu.sg 
 
Abstract 
Automatic summarization is an active research 
area in natural language processing. This paper has 
proposed a special method that produces text 
summary by detecting thematic areas in Chinese 
document. The specificity of the method is that the 
produced summary can both cover many different 
themes and reduce its redundancy obviously at the 
same time. In this method, the detection of latent 
thematic areas is realized by adopting K-medoids 
clustering method as well as a novel clustering 
analysis method, which can be used to determine 
automatically K, the number of clusters.. In 
addition, a novel parameter, which is known as 
representation entropy, is used for summarization 
redundancy evaluation. Experimental results 
indicate a clear superiority of the proposed method  
over the traditional non-thematic-area-detection 
method under the proposed evaluation scheme 
when dealing with different genres of text 
documents with free style and flexible theme 
distribution. 
1 Introduction 
With the approaching information explosion, 
people begin to feel at a loss about the mass of 
information. Because the effectiveness  of the 
existing information retrieval technology is still 
unsatisfactory, it becomes a problem to efficiently 
find the information mostly related to the needs of 
customers retrieval results so that customers can 
easily accept or reject the retrieved information 
without needing to look at the original retrieval 
results. This paper has proposed a new 
summarization method, where K-medoid 
clustering method is applied to detect all possible 
partitions of thematic areas, and a novel clustering 
analysis method, which is based on a self-defined 
objective function, is applied to automatically 
determine K, the number of latent thematic areas in a 
document  
This method consists of three main stages: 1) Find 
out the thematic areas in the document by adopting the 
K-medoid clustering method (Kaufmann and 
Rousseeuw, 1987as well as a novel clustering analysis 
method. 2) From each thematic area, find a sentence 
which has the maximum semantic similarity value 
with this area as the representation. 3) Output the 
selected sentences to form the final summary 
according to their pos itions in the original document. 
To validate the effectiveness of the proposed 
method, use this method as well as the traditional 
non-thematic -areas-detection method on our 
experimental samples to generate two groups of 
summaries. Next, make a comparison between them. 
The final results show a clear superiority of our 
method over the traditional one in the scores of the 
evaluation parameters. 
The remainder of this paper is organized as 
follows. In the next section, we review related 
methods that are commonly discussed in the 
automatic summarization literature. Section 3 
describes our method in detail. The evaluation 
methodology and experimental results are presented 
in Section 4. Finally, we conclude with a discussion 
and future work. 
2 Related Work  
The research of automatic summarization begins with 
H.P.Luhn?s work. By far, a large number of scholars 
have taken part in the research and had many 
achievements. Most of the researchers have 
concentrated on the sentence-extraction 
summarization method (the so-called shallower 
approach) (Wang et al, 2003; Nomoto and 
Matsumoto, 2001; Gong and Liu, 2001), but not the 
sentence-generation method (the so-called deeper 
approach)(Yang and Zhong., 1998). On the one hand, 
it is caused by the high complexity and the severe 
limitation of practical fields of rational natural 
language processing technology and knowledge 
engineering technology. On the other hand, it is 
closely associated with the great achievements in 
many fields of natural language processing by 
statistical research methods, machine learning 
methods and pattern recognition methods in recent 
years (Mani, 2001). 
The summarization method of sentence-
extraction can roughly be divided into two kinds: 
supervised and unsupervised (Nomoto and 
Matsumoto, 2001). Generally, the realization of the 
former relies on plenty of manual summaries, that 
is so-called ?Gold Standards? which help 
determining the relevant parameters of the 
statistical model for summarization. However, not 
all people believe that manual summaries are 
reliable, so the researchers have begun to 
investigate the general unsupervised method, 
which can avoid the requirement of support of 
manual summaries. Nevertheless it is soon 
discovered that the summaries produced by this 
method can?t cover all the themes and have great 
redundancy at the same time. Usually, it can only 
cover those intensively distributed themes while 
neglects others. So researchers in Nanjing 
University proposed a summarization method 
based on the analysis of the discourse structure to 
overcome these problems (Wang et al, 2003). By 
making statistics of the reduplicated words in the 
adjacent paragraphs of the document, the semantic 
distances among them can be worked out. Then 
analyse the thematic structure of the document and 
extract sentences from each theme to form a 
summary. It is ideal to employ this method while 
dealing with those documents with standard 
discourse structure, because it can effectively 
avoid the problems caused by the summarization 
method without discourse structure analysis. Yet 
when the writing style of a document is rather free 
and the distribution of the themes is variable, that 
is the same theme can be distributed in several 
paragraphs not adjacent to each other, then the use 
of this method can?t be equally effective. 
To deal with a lot of Chinese documents which 
have free style of writing and flexible themes, a 
sentence-extraction summarization method created 
by detecting thematic areas is tried following such 
work as (Nomoto and Matsumoto, 2001; Salton et 
al., 1996; Salton et al, 1997; Carbonell and 
Goldstein, 1998; Lin and Hovy, 2000). The 
thematic areas detection in a document is obtained 
through the adaptive clustering of paragraphs (cf. 
Moens et al 1999), so it can overcome in a certain 
degree the defects of the above methods in dealing 
with the documents with rather flexible theme 
distribution. 
3 The Algorithm 
In this section, the proposed method will be 
introduced in detail. The method consists of the 
following three main stages: 
Stage 1: Find the different thematic areas in the 
document through paragraph clustering and 
clustering analysis. 
Stage 2: Select the most suitable sentence from 
each thematic area as the representative 
one. 
Stage 3: Make the representative sentences form 
the final summary according to certain 
requirements. 
3.1 Stage 1: Thematic Area Detection 
The process of thematic area detection is displayed in 
Figure 1. 
The each step of Figure 1 is explained in the 
following subsections. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 1: The process of thematic area detection (4 
steps in all) 
 
 
 
3.1.1 Step 1: Term Extraction 
 
Different from the general word segmentation 
operation adopted in the traditional Chinese 
automatic summarization research, we do not take the 
general operation when pre-processing the original 
Original document 
Term extraction 
Vector representation of paragraph 
Weight calculation of paragraph 
Paragraph clustering 
Clustering analysis 
Thematic area detection 
1 
2 
3 
4 
document, but make use of the method introduced 
by (Liu et al, 2003) to extract terms 
from the document and then express its content by 
such metadata elements as terms.  
The greatest advantage of term extraction 
technology is that it needs no support of fixed 
thesaurus, only through the continuous updating 
and making statistics of a real corpus. We can 
dynamically establish and update a term bank and 
improve the extraction quality through continuous 
correcting of the parameters for extraction. Thus it 
is of wide practical prospects for natural language 
processing. In addition, the terms can represent a 
relative specific meaning, because most of them 
are phrases, which consist of multi-characters. 
 
3.1.2 Step 2: Vector Representation and Weight 
Calculation of Paragraph 
 
The advantage of the vector space model (VSM) is 
that it successfully makes the unstructured 
documents structured which makes it possible to 
handle the massive real documents by adopting the 
existing mathematical instruments. All the terms 
extracted from the document are considered as the 
features of a vector, while the values of the 
features are statistics of the terms. According to 
this, we can set up the VSM of paragraphs, that is 
each paragraph Pi (i:1~M,M is the number of all 
paragraphs in a document) is represented as the 
vector of weights of terms, VPi, VPi =
( WPi1,WPi2,?,WPiN)  
Where N is the total number of terms, WPij 
denotes the weight of the j-th term in the i-th 
paragraph. There are many methods of calculating 
WPij, such as tf, tf*idf, mutual information (Patrick 
Pantel and Lin, 2002), etc. The method adopted 
here (Gong and Liu, 2001) is shown as follows: 
 
WPi j= log(1+TF(Ti j))*log(M/Mj ) (1) 
 
Where TF(Tij) denotes the number of occurrence 
of the j-th term in the i-th paragraph, M/Mj denotes 
the inverse paragraph frequency of term j, and Mj 
denotes the number of paragraphs in which term j 
occurs. In accordance, on the basis of defining 
WPij, we can further define the weight of 
paragraph P i, W(P i), by the follwing formula: 
 (2) 
 
In formula (2), n represents the total number of 
different terms occurring in the i-th paragraph. 
3.1.3 Step 3: Paragraph Clustering and 
Clustering Analysis  
 
1) Paragraph clustering 
The existing clustering algorithms can be 
categorized as hierarchical (e.g. agglomerative etc) 
and partitional (e.g. K-means, K-medoids, etc) 
(Pantel and Lin, 2002). 
The complexity of the hierarchical clustering 
algorithm is O(n2Log(n)) , where n is the number 
of elements to be clustered, which is usually 
greater than that of the partitional method. For 
example, the complexity of K-means is linear in n. 
So in order to achieve high efficiency of algorithm, 
we choose the latter to cluster paragraphs. 
K-means clustering algorithm is a fine choice in 
many circumstances, because it is simple and 
effective. But in the process of clustering by means 
of K-means, the quality of clustering is greatly 
affected by the elements that marginally belong to 
the cluster, and the centroid can?t represent the real 
element in the cluster, So while choosing the 
paragraphs clustering algorithm, we adopt K-
medoids (Kaufmann and Rousseeuw, 1987; Moens 
et al 1999) which is less sensitive to the effect of 
marginal elements than K-means. 
Suppose that every sample point in the N-
dimensional sample space respectively represent a 
paragraph vector, and the clustering of paragraphs 
can be visualized as that of the M sample points in 
the sample space. Here N is the number of terms in 
the document and M is the number of paragraphs. 
Table 1 shows the formal description of the 
paragraph clustering process based on K-medoids 
method. 
2) Clustering analysis 
A classical problem when adopting K-medoid 
clustering method and many other clustering 
methods is the determination of K, the number of 
clusters. In traditional K-medoid method, K must 
be offered by the user in advance. In many cases, 
it?s impractical. As to clustering of paragraphs, 
customers can?t predict the latent thematic number 
in the document, so it?s impossible to offer K 
correctly. 
In view of the problem, the authors put forward a 
new clustering analysis method to automatically 
determine the value of K according to the 
distribution of values of the self-defined objective 
function. The basic idea is that if K, the number of 
clusters,  is  determined  with  each  value of K, and   
  
  
 
Input: <a, b>, they respectively denote the 
paragraph matrix composed by all the 
paragraph vectors in the document and 
the number of clusters, k (the range of k 
is set to 2~M). 
 
Step 1: randomly select k paragraph vectors as 
the initial medoids of the clusters (here, 
the medoids denote the representative 
paragraphs of k clusters). 
Step 2: assign each paragraph vector to a cluster 
according to the medoid X closest to it. 
Step 3: calculate the Euclidean distance between 
all the paragraph vectors and their closest 
medoids. 
Step  4: randomly select a paragraph vector Y. 
Step 5: to all the X, if it can reduce the 
Euclidean distance between all the 
paragraph vectors and their closest 
medoids by interchanging X and Y, then 
change their positions, otherwise keep as 
the original. 
Step 6: repeat from step 2 to 5 until no changes 
take place. 
 
Output: <A, B, C>, they respectively denote the 
cluster id, the representative paragraph 
vector and all the paragraph vectors of 
each cluster under the k clusters. 
Table 1: Paragraph clustering process based on 
K-medoid method 
suitably, then the corresponding clustering 
results can well distinguish the different themes 
in the document, and correspondingly the 
average of the sum of the weight of the 
representative paragraph under each theme will 
tend to maximize. We call this the maximum 
property of the objective function. 
 
Correspondingly, we define the following 
objective function Objf(K) to reflect clustering 
quality and determine the number of clusters, K. 
1
( )
( )
K
j
j
W P
O b j f K
K
==
?
 (3) 
Where W(Pj) denotes the weight of the 
selected representative paragraph in the j-th 
cluster, here the selected representative 
paragraph Pj can be regarded as the medoid in 
the j-th cluster which is determined by the final 
output of the presented K-medoid paragraph 
clustering process, and the weight of Pj is 
calculated by formula (2). Put the objective 
function in K clustering results corresponding 
then make good use of the maximum property of 
the objective function to adaptively determine the 
final number of clusters, K. 
Figure 2 shows the concrete distribution of the 
values of objective function obtained in the 
example document ?On the Situation and Measures 
That Face Fishing in the Sea in Da Lian City? 
when adopting the proposed clustering analysis 
method. According to the maximum property of 
objective function, that is take the value of K when 
the values of the objective function take maximum 
as the final number of clusters. From the results in 
Figure 2, we can know that K equals to six, that is 
we find six latent thematic areas from nine 
paragraphs in the document with this method. 
1
1.05
1 . 1
1.15
1 . 2
1.25
1 . 3
k=2 k=3 k=4 k=5 k=6 k=7 k=8 k=9
k?
Figure 2: The distribution of the values of the 
objective function when K takes different values 
 
 
Figure 3 displays the paragraph clustering results 
when K equals six in the process of adopting K-
medoid clustering method on the example 
document. 
 
 
Component 1
C
om
po
ne
nt
 2
-10 -5 0 5
-5
0
5
These two components explain 54.44 % of the point variability.  
Figure 3: The paragraphs clustering result when K 
equals to six 
 
 
 
3.1.4 Step 4: Thematic Area Detection 
 
Output the complete information table of each 
thematic area in the form of the representative 
paragraph and all the paragraphs and sentences 
covered by the thematic area. 
 
3.2 Stage 2: Selection of the Thematic 
Representative Sentences 
 
To select a most suitable representative sentence 
from each thematic area, the author proposes the 
following method. This is in contrast  with a 
method proposed by Radev (Radev et al, 2000 ), 
where the centroid of a cluster is selected as the 
representative one. 
Method: select the sentence which is most 
similar to the thematic area semantically as 
representative one. 
Before carrying out the method in detail, there 
are two problems to be solved: 
1) The vector representation of sentence and 
thematic area 
The vector representation of sentence and 
thematic area is similar to that of paragraph 
introduced before. We only need to change the 
weight calculation field of the terms from the 
interior of paragraph to the interior of sentence 
or thematic area. Accordingly, we can describe 
the sentence vector and thematic area vector as 
follows 
VSj= ( WSj1,WSj2,?,WSjN)  
VAk= ( WAk1,WAk2,?,WAkN)  
 
2) The semantic similarity calculation between 
sentence and thematic area 
The calculation of semantic similarity of 
sentence and thematic area can be achieved by 
calculating the vector distance between sentence 
vector and thematic area vector. Here we adopt 
the traditional cosine method for vector distance 
calculation. Correspondingly, the distance 
between the sentence vector VSj and the thematic 
area vector VAk is calculated by the following 
formula: 
( ) ,2 2
1 1 1
( , )
N N N
j k ji ki ji ki
i i i
WS WA WS WAVS VACos
= = =
? ? ? ?= ? ?? ? ? ?? ? ? ?
? ? ?  (4) 
 
Principles of evaluating summarization redundancy 
 
At the premise of the same number of 
summarization sentences selected out by 
different summarization methods: 
 
The higher the value of RE calculated by the 
covariance matrix of the summarization sentence 
vectors. 
The lower the summarization redundancy. 
 
Table 2: The evaluation principles of the 
summarization redundancy based on RE 
 
3.3 Stage 3: The Creation of the Summary 
 
Ouput the selected representative sentences from 
each thematic area according to their postions in the 
original document to form the final summary.  
 
4 Experimental Results and Performance 
Evaluation 
4.1 Evaluation Methodology 
It is challenging to objectively evaluate the qua lity of 
different automatic summarization methods. Methods 
for evaluation can be broadly classified into two 
categories: intrinsic and extrinsic (Mani, 2001). We 
adopt the former to evaluate the quality of 
summarization by defining the following parameters 
for evaluation. 
1) Theme coverage (TC) 
The definition of TC is the percentage of the 
thematic contents covered by the selected 
summarization sentences. The value of the 
parameter can be got by means of the works of 
some experts. 
2) Representation entropy (RE) 
In order to effectively and objectively evaluate the 
redundancy of the produced summary, we refer to 
the parameter which was initially proposed by 
(Mitra et al, 2002) for evaluating the feature 
redundancy in the process of feature selection and 
transform it into the novel parameter to evaluate 
the summarization redundancy. 
According to this, some important notations are 
defined as follows: 
 
 
N Number of terms in the original 
document ;  
Nz Number of sentences in the 
produced summary ;  
Lz 
Nz-by-N matrix composed by 
all the sentence vectors in the 
produced summary ;  
?z 
Nz-by-Nz covariance matrix 
composed by all the sentence 
vectors in the produced 
summary ;  
l i Eigenvalues of ?z i:1~Nz ;  
? i ? i= l i /
1
Nz
i =
l  ? i ;  
 
 
 
 
 
 
 
Theme coverage (TC) Representation 
entropy (RE) 
Genre Sample ID Number 
of 
characters  
Number 
of 
paragraphs 
Number 
of 
detected 
thematic 
areas  
Method1 Method2 Method1 Method2 
d10000801 1461 11 5 0.6 0.56 1.44 1.25 
d10000901 1192 7 5 0.64 0.6 1.36 1.35 
d10100101 1936 14 9 0.66 0.64 2.14 2.06 
d10100201 1778 12 6 0.8 0.5 1.62 1.54 
d10100301 2472 4 3 0.64 0.4 0.81 1.05 
d10100601 1553 11 7 0.9 0.64 1.79 1.83 
d29600501 2400 6 4 0.7 0.56 1.33 1.01 
d29800101 670 4 3 0.64 0.6 1.06 1.01 
d40000301 2026 8 5 0.56 0.52 1.45 1.54 
Economy 
d40100101 1529 7 4 0.6 0.58 1.19 1.31 
e10000101 907 4 2 0.72 0.56 0.64 0.24 
e10000201 845 5 3 0.9 0.6 1.06 0.89 
e29600201 2035 5 4 0.72 0.5 1.36 1.21 
Art 
e29800201 1831 7 2 0.56 0.52 0.67 0.57 
f20000101 2354 12 7 0.58 0.5 1.92 1.79 Prose 
f20000201 1769 9 6 0.64 0.52 1.72 1.50 
g00000201 1163 5 4 0.84 0.56 1.34 1.21 
g00000501 790 6 4 0.64 0.54 1.31 1.26 
g00001201 425 5 5 0.92 0.62 1.45 1.49 
g00100101 1629 10 3 0.84 0.6 0.93 0.82 
g00100301 817 6 4 0.76 0.7 1.32 1.26 
g00100501 1355 4 4 0.84 0.5 1.31 1.12 
g09600901 2179 7 6 0.72 0.62 1.75 1.73 
Military 
g09601601 1271 5 3 0.7 0.52 1.03 0.98 
h00000401 1224 6 6 0.72 0.54 1.75 1.60 
h00000601 1331 15 7 0.6 0.5 1.88 1.80 
h00000901 1507 7 3 0.64 0.68 1.05 0.83 
h00001801 1604 8 6 0.68 0.64 1.73 1.66 
h00100301 960 6 3 0.9 0.4 1.04 1.05 
Life 
h00100601 1228 6 3 0.8 0.6 1.06 0.89 
 
Table 3: Experimental data 
 
 
 
 
Mean of theme 
coverage ( TC ) 
Mean of representation 
entropy ( R E ) 
Ratio of 
information and 
noise (F) 
Genre Number 
of samples 
Method 
1 
Method 
2 
Method 
1 
Method 
2 
Method 
1 
Method 
2 
Economy 10 0.68 0.56 1.42 1.40 2.81 2.27 
Art 4 0.72 0.54 0.93 0.73 1.82 1.12 
Prose 2 0.62 0.52 1.82 1.65 3.83 2.71 
Military  8 0.78 0.58 1.31 1.23 2.89 1.98 
Life 6 0.72 0.56 1.42 1.31 2.98 2.08 
Table 4: Evaluation results of parameters 
 
 
 
The value of RE (Mitra et al, 2002) is calculated 
as follows: 
RE= -
1
N z
i =
?  ?  ? i * il o g  (5) 
The evaluation principles of the summarization 
redundancy based on RE  are demonstrated in 
Table 2. 
 
3) Ratio of information and noise (F) 
F=TC/e ?RE (6) 
 
The novel evaluation parameter proposed by us 
can objectively evaluate the quality of the produced 
summary by effectively combining the above two 
parameters. The more the value of F, the better the 
quality of the produced summary. 
 
4.2 Experimental Results 
We randomly extract 200 documents of different 
genres from the Modern Chinese Corpus of State 
Language Commission to form the experimental 
corpus. Because summarizing short documents 
doesn?t make much sense in real applications (Gong 
and Liu, 2001), we select 30 documents of more 
than 400 characters from the corpus as the samples 
which are summarized by the proposed 
summarization method (method 1 for abbreviation) 
and the traditional non-thematic -area-detection 
method (method 2 for abbreviation), that is the 
method of determining the weights of sentences in a 
document, sorting them in a decreasing order, and 
selecting the top sentences in the end. The specific 
experimental data and evaluation results of 
parameters are given in table 3 and table 4. 
The synthetic evaluation of the 30 samples proves 
that our method under the above evaluation 
parameters is superior to the traditional non-
thematic-area-detection  summarization method 
when dealing with different genres of text 
documents with free style and flexible theme 
distribution, and the results we have achieved are 
encouraging. 
 
5 Conclusions 
In this paper, we have proposed a new 
summarization method based on thematic areas 
detection. By adopting a novel clustering analysis 
method, it can adaptively detect the different 
thematic areas in the document, and automatically 
determine K, the number of thematic areas. So the 
produced summary can both cover as many as 
different themes and reduce its redundancy 
obviously at the same time. 
 For our experiment, we used three different 
parameters to evaluate the quality of the produced 
summaries in theme coverage and summarization 
redundancy. We achieved a better performance than 
the traditional non-thematic -areas-detection method 
in the proposed evaluation scheme. As a future 
work , we need the additional research for testing 
the proposed method on la rger-scale real corpora , 
and have the further comparison with earlier similar 
works such as MMR, etc. In addition, we?ll 
improve our summarization system by considering 
the structure of thematic areas and user?s 
requirement. 
 
References  
Jaime Carbonell and Jade Goldstein. 1998. The use 
of MMR, diversity-based reranking for reordering 
documents and producing summaries. In 
Proceedings of the 21th Annual International 
ACM SIGIR Conference on Research and 
Development in Information Retrieval. ACM, 
New York. 
Yihong Gong, Xin Liu. 2001. Generic text 
summarization using relevance measure and 
latent semantic analysis. In Proceedings of ACM 
SIGIR?01, pages 19-25, ACM, New York. 
L. Kaufmann and P.J. Rousseeuw. 1987. Clustering 
by means of medoids. In Statistical Data Analysis 
Based on the L1 Norm,Y.Dodge,Ed,Amsterdam, 
405-416. 
Chin-Yew Lin and Eduard Hovy. 2000. The 
automatic acquisition of topic signatures for text 
summarization. In Proceedings of the 18th 
International Conference of Computational 
Linguistics (COLING 2000). 
Jian-Zhou Liu, Ting-Ting He, and Dong-Hong Ji. 
2003. Extracting Chinese term based on open 
corpus. In Proceedings of the 20th International 
Conference on Computer Processing of Oriental 
Languages,pages 43-49. ACM, New York.  
Inderjeet Mani. 2001. Summarization evaluation: an 
overview. In Proceedings of the NTCIR 
Workshop 2 Meeting on Evaluation of Chinese 
and Japanese Text Retrieval and Text 
Summarization. 
Inderjeet Mani. 2001. Recent developments in text 
summarization. In Proceedings of CIKM?01, 529-
531. 
Pabitra Mitra, C.A. Murthy, Sankar and K.Pal. 
2002. Unsupervised feature selection using 
feature similarity. IEEE Transactions of Pattern 
Analysis and Machine Intelligence: 1-13. 
Marie-Francine Moens, Caroline Uyttendaele and 
Jos Dumortier. 1999. Abstracting of legal cases: 
The potential of clustering based on the selection 
of representative objects. Journal of the American 
Society for Information Science, 50 (2): 151-161.  
Tadashi Nomoto, Yuji Matsumoto. 2001. A new 
approach to unsupervised text summarization. In 
Proceedings of ACM SIGIR?01, pages 26-34. 
ACM, New York.  
Patrick Pantel and Dekang Lin. 2002. Document 
clustering with committees. In Proceedings of 
ACM SIGIR?02, pages 199-206. ACM, New 
York.  
Dragomir R. Radev, Hongyan Jing, and Malgorzata 
Budzikowska. 2000. Centroid-based 
summarization of multiple documents: sentence 
extraction, utility-based evaluation, and user 
studies. In ANLP/NAACL Workshop on 
Summarization.  
Gerard Salton, Amit Singhal, Chris Buckley and 
Mandar Mitra. 1996. Automatic text 
decomposition using text segments and text 
themes. Hypertext 1996: 53-65. 
Gerard Salton, Amit Singhal, Mandar Mitra and 
Chris Buckley. 1997. Automatic text structuring 
and summarization. In Information Processing 
and Management, 33(2):193-208. 
Ji-Cheng Wang, Gang-Shan Wu, Yuan-Yuan Zhou, 
Fu-Yan Zhang. 2003. Research on automatic 
summarization of web document guided by 
discourse. Journal of Computer Research and 
Development, 40(3):398-405. 
Xiao-Lan Yang and Yi-Xin Zhong. 1998. Study and 
realization for text interpretation and automatic 
abstracting. Acta Electronica Sinica, 26(7):155-
158. 
The Standard of Chinese Corpus Metadata
He Tingting 
Huazhong Normal University 
tthe@mail.ccnu.edu.cn
Xu Xiaoqi 
Huazhong Normal University 
Xu_xiaoqi@hotmail.com
                                                          
 The paper is supported by National Language Application Project of Tenth five-years plan of China, (Grant No. ZDI105-
B01, ZDI105-43B); 
National Natural Science Foundation of China (NSFC), (Grant No.10071028);
Ministry of education of China,  Research Project for Science and technology, (Grant No. 105117). 
Abstract
The normalization of corpus metadata 
plays a key role in building sharable 
corpora. However, there is no uniform 
specification for defining and process-
ing metadata in Chinese corpus nowa-
days. This paper introduces a 
metadata system we?ve proposed for 
Chinese corpus. 46 elements are de-
fined in all, which can be divided into 6 
classes: information about copyright, 
information about background of lin-
guistic material creator, information 
about medium of linguistic material, 
information about the content of lin-
guistic material, information about 
collecting linguistic material, and in-
formation about management of lin-
guistic material. To distinguish one 
element from another, or our elements 
from someone else?s, we provide a po-
tent description method, where 10 sub-
sections are designed to describe the 
detailed properties for each element.
1 Introduction 
?Metadata? is first defined in computer science. 
It plays an important role in the management of 
electronic resources, especially the huge infor-
mation from Internet. By cataloguing the web 
pages, we can obtain a better search more effi-
ciently. Nowadays, metadata becomes a popular 
tool to describe administrative information about 
all kinds of resources. It defines schemes for 
resource description, and also provides universal 
mechanism for resource retrieval.
In corpus linguistic, metadata description has 
existed for a long time, and is generally referred 
to heading information. By defining metadata, 
more accurate and profuse annotation contents 
can be provided for corpus, such as, information 
about time, area, author and etc. However, there 
is no uniform specification for processing meta-
data in Chinese corpus at present. Thus, we de-
fine a core metadata set for Chinese corpus and 
normalize the description of set element. Basing 
on the Dublin Core metadata, which is widely 
accepted in philology, the definition takes much 
attention on the linguistic characteristics of Chi-
nese corpus, and is compatible to the OLAC 
metadata standards as well. Both creator and 
users of the corpus can get regulations of textual 
description and annotation strategy from this 
standard.
In section 2, we discuss some referenced 
standards and resources, including DC and 
OLAC metadata. Section 3 presents a frame-
work within which we design our metadata, and 
lists the main problems to be solved. Section 4 
summarizes our metadata description and re-
ports some further development of the standard. 
Conclusion is drawn in section 5. 
2 Related metadata resources 
2.1 Dublin Core metadata 
Dublin Core Metadata has been present in 
OCLC?NCSA ?National Center for Super-
computer Applications? Meta Workshop in 
1995.It?s a standard for cross-domain informa-
tion resource description, and has no fundamen-
tal restrictions to the types of resources to which 
the metadata can be assigned. DC metadata de-
fined 15 core elements, which are maintained 
and managed by DCMI (Dublin Core Metadata 
Initiative). The core elements are listed in table 
1.
24
In DC metadata, each element is described in 
10 property items that defined in ISO/IEC 
11179.They are: ?Name?, ?Identifier?, ?Ver-
sion?, ?Registration Authority?, ?Language?, 
?Definition?, ?Obligation?, ?Datatype?, ?Maxi-
mum Occurrence? and ?Comment?. However, 6 
items among them have settled value for each 
element as following:  
Version:1.1
Registration Authority: Dublin Core Meta-
data Initiative 
Language:en
Obligation: Optional 
Datatype: Character String 
Maximum Occurrence: Unlimited 
Elements
about Re-
source Con-
tent
Elements
about Copy-
right
Elements
about External 
Attribute de-
scription
Title Creator Date
Subject Publisher Type 
Description Contributor Format 
Language Rights Identifier 
Source
Relation 
&RYHUDJH
Table 1 Fifteen core elements in DC, 
which are divided into 3 classes. 
DC metadata is an important reference for 
the definition of Chinese corpus metadata. There 
are at least two reasons for this. 
(1) Both DC and corpus metadata are designed 
for large-scale users, who are not always pro-
fessional catalogue person. Thus apprehensi-
ble and general are two pivotal aims to 
achieve.
(2) DC metadata has been mostly assigned to 
electronic text from Internet webs, which are 
primary source of linguistic material as well. 
Therefore, it?s expected that the corpus can be 
used directly without reannotation if they are 
annotated with DC metadata before. 
2.2 OLAC metadata 
The OLAC?Open Language Archives Com-
munity Metadata?metadata set is based on the 
Dublin Core metadata set. In order to meet the 
specific needs of the language archiving com-
munity, the OLAC metadata set qualifies with 
three kinds of qualification: element refinement, 
encoding scheme, and content language. With 
these three attributes, an element in OLAC can 
indicate more information than the same one in 
DC does. Take the element ?Date? in OLAC for 
example, with the element refinement, it can 
represent either date of create, or date of issue, 
or date of modification in different occasions  
The elements in OLAC are listed in table 
2,and we can see that it uses all the 15 elements 
in DC. Element in OLAC are described in 5 
property items which are ?Name?, ?Definition?, 
?Comments?, ? Attributes? and ? Examples?. 
Elements about 
Resource Con-
tent
Elements
about
Copyright
Elements about 
External At-
tribute descrip-
tion
Title Creator Date
&RYHUDJH Publisher Identifier 
Description Contributor Format 
Language Rights Format.cpu 
Source Format.markup 
Relation Format.os 
Subject Format.sourcecode
Subject.language Format.encoding 
Type
Type.data
Type.function 
Table 2  Elements in OLAC, this set 
uses all fifteen elements in DC. 
Genre= Prose 
Style= narrative 
Mode= Written 
Topics= Literature 
Medium= Textbook 
Name= 
Sex=
Nationality= 
Language=Chinese
Publish House= National Institute for 
Compilation and Translation
Publish Place=Taiwan 
Publish Data= 
Title= starlight
Table 3 Example of metadata 
describing in Sinica corpus 
2.3 Research on large-scale corpus meta-
data
2.3.1 Sinica corpus metadata
Sinica corpus is developed and maintained by 
Institute of Information Science and CKIP group 
in Academia Sinica. It?s designed for analyzing 
modern Chinese. Texts are collected from dif-
ferent areas and classified according to five cri-
teria: genre, style, mode, topic, and source. 
25
Therefore, this corpus is a representative sample 
of modern Chinese language. 
Metadata in Sinica corpus lays special emphasis 
on describing the linguistics information of lin-
guistic material, such as ?Mode?, ?Style?, ?Me-
dium?, and ?Topic?. An example of metadata 
describing in Sinica corpus is  given in table 3. 
2.3.2 National modern Chinese corpus meta-
data
National modern Chinese corpus is the largest 
balance corpus in China at present. The selec-
tion of linguistic material follows the principles 
of commonality, description and practicability. 
In order to reflect the panorama of modern Chi-
nese, a lot of work has been done on designing 
balance gene. And the finally selected samples 
have a wide span on time, domain and medium. 
Metadata in National modern Chinese corpus 
pay much attention on copyright information 
and publish information of linguistic material. 
Furthermore, both a global serial number and a 
category number are designed to identify a cer-
tain sample. 
2.3.3 BNC metadata
The British National Corpus (BNC) is a 100 
million word collection of samples of written 
and spoken language from a wide range of 
sources, designed to represent a wide cross-
section of current British English, both spoken 
and written. Each text in BNC has a TEI header 
to indicate the identification and classification of 
individual text, special details such as speakers?, 
and the housekeeping information. The defini-
tion of text classification is meticulous. For spo-
ken text material, age, sex, and class of 
respondent are all make sense as well as the do-
main, region and type of the content. And for 
written text material classification, age, sex, type 
of author, audience, circulation, status, medium, 
and domain are laid emphasis on. However, 
some classification were still poorly defined and 
partially populated, such a ?dating?(date of copy 
or date of first publication?) and ?domain? (has 
something different with text-type?). 
2.3.4 Metadata in balanced corpus
In recent years, the awareness that text is not 
just text, but that texts comes in several forms, 
has spread from more theoretical and literary 
subfields of linguistics to the more practically 
oriented information retrieval and natural lan-
guage processing fields. As a consequence, sev-
eral test collections available for research 
explicitly attempt to cover many or most well-
established textual genres, or functional styles in 
well-balanced proportions 
In practice, choosing balance gene is a profes-
sional work that needs a scientific programming 
strategy. Sinclair suggested a minimum set of 
balance gene for general corpus in 1991 that 
indicates a popular classify principle for linguis-
tic: the style of linguistic (on-the-spot record or 
literature); the form of linguistic (formal or in-
formal); the medium type of linguistic (from 
book or magazine or paper); and the age, sex of 
the author. From the Sinica corpus and National 
modern Chinese corpus we?ve discussed above, 
we can see that the gene of time, style, area and 
subject are most in frequent use, which become 
our crucial reference for metadata designing. 
2.4 ISO1179 standard 
ISO1179 is an international standard about de-
veloping metadata. There are 6 parts in this 
standard, which are considered as our basic rule 
to follow. 
3 Framework of metadata description 
We describe metadata information from three 
aspects, which we consider as: content structure, 
syntax structure and semantic structure. Content 
structure is used to decide the elements in a 
metadata set. Syntax structure introduces a 
model or syntax to represent metadata, while 
semantic structure declares the signification 
concourse of elements. 
FIG.1.The framework of develop metadata 
A consistent strategy is essential when these 
three structures are used to define metadata. Our 
research is to solve three problems especially. 
3.1 Element selection 
Elements in metadata set are used to describe a 
resource from different aspects. Thus, the selec-
tion or designing of elements becomes an impor-
tant issue. When the selection depends on the 
26
experience of corpus creator rather than a nor-
mative rule, it?s hard for the metadata to assert 
the resource sufficiently. 
We referenced a lot from DC and OLAC 
metadata. For the universal use of these two 
metadata standards and the similarity between 
DC metadata and corpus metadata we discuss 
above, we finally used all the fifteen elements 
defined in DC standard. However, some ele-
ments are refined or splitted into several new 
elements on the basis of the old definition. For 
example, the elements ?Date? is extended as 
?Indite Date?, ?Issued Date?, ?Created Date? 
and ?Modified Date?, thus more detailed and 
definite information of date can be obtained for 
either a single sample or the whole corpus. And 
the same case for the element ?Language? from 
DC. We defined three kinds of information 
about language to describe both creator informa-
tion and content information. 
To fully consider the linguistic characteristics 
of Chinese corpus, we?ve introduced several 
popular metadata elements in balanced corpus, 
such as style, mode, medium and so on, which 
are also important balance gene for corpus de-
signing.
Therefore, we define 46 elements in all, 
which can be divided into 6 classes. They are: 
information about copyright, information about 
background of linguistic material creator, infor-
mation about medium of linguistic material, in-
formation about the content of linguistic 
material, information about collecting linguistic 
material, and information about management of 
linguistic material. Most elements we defined 
are intellectual metadata, while some structural 
metadata, access control metadata and critical 
metadata are included as well. 
3.2 Description field 
Metadata is structured data about data. It?s usu-
ally expressed with several property fields or 
subsections, which is regarded as its own data 
structure or syntax. Different metadata system 
may use different way to describe and naming 
its elements, thus it?s hard for metadata com-
munion or understanding the same element from 
two dissimilar systems.  
A unified method for description is helpful, 
and it?s expected to be succinct, general and dis-
tinguished. Our standard has provided 10 fields 
for a metadata description. Some are obligatory, 
that is to say you must give a value to such 
fields in order to confirm an element. And some 
are optional for the individuation use. This 
seems to do a better work than DC, while 6 
fields in it always have settled value. We spe-
cially introduce two subsections for naming an 
element, thus elements can be distinguished ex-
actly from either ?Name? or ?Long Name? field. 
We have exhibited such format in XML (eXten-
sible Markup Language), and created the DTD 
(Document Type Definition) file for it as well. 
3.3 Semantic description 
Semantic structure defines the detailed value of 
metadata, and finally affirms how to use it. 
Value land should be carefully considered to 
avoid confusion use. Many famous metadata 
standards have formed a maturity definition of 
elements. For example, DC use ISO 8601 to de-
fine element ?date?, Dublin Core Types for ele-
ment ?Resource Type? and URL or ISBN to 
define element ?Identifier?. We took much ac-
count of the linguistic characteristics of Chinese 
corpus and some value are assigned refer to lin-
guistics literature. 
4 Metadata standard 
4.1 Element set 
Our corpus metadata set is based on the Dublin 
Core metadata set and uses all fifteen elements 
defined in that standard. We?ve summarized 
some annotation items in other large-scale cor-
pus and developed an element set listed in table 
4.There are 46 elements in all. They are ex-
pected to describe the resources from six aspects. 
4.1.1 Information about copyright
The intellectual property right of corpus is copy-
right. According to the copyright law, corpus 
must show clearly its copyright information 
when being published or promulgated. Metadata 
in this class is about corpus? created or issued 
information, mainly including: 
?Title: the title of original linguistic material, 
such as books, articles, webs and so on.
?Source Identifier: the tag of source linguis-
tic material, such as ISBN for books and 
URL for webs. 
? Indite Date: is used to describe the writing 
time of original linguistic material, or the 
27
recording time of the oral linguistic mate-
rial.
? Issued Date: describe the publish time of a 
given linguistic material. 
?Copyright: show the composer, publishing 
company or the web site of the original lin-
guistic material. 
?Resource Type: resource?s physical type 
can be various, such as papery, electronic, 
recordy, or kinescope. 
4.1.2 Information about background of lin-
guistic material creator
We pay some attention on the individual infor-
mation of corpus? creator, because it?s helpful 
for analyzing linguistics characteristic about 
corpus. Such information includes native lan-
guage, born place, age, sex as well as creator?s 
name. For corpus? creator is not always a single 
person, we define ?Agent Type? to clarify such 
instance, and introduce other creators in ?Con-
tributor?.
4.1.3 Information about medium of linguistic 
material
Information about medium of linguistic material 
provides detailed data of publish region, influ-
ence area, circulation extent and so on, which 
are all important to evaluate the corpus? balance 
gene.
?Medium Type: linguistic material is usually 
selected from different published medium 
including paper, book, magazine, web or 
else.
?Publish Type and Publish Area: respec-
tively indicate the geographical area type or 
size, such as national or local, and the idio-
graphic cantons the area covers. 
?Publish Period and Amount: respectively 
show the publish frequency and copies of 
the publication. 
4.1.4 Information about the content of lin-
guistic material
Information about the content of linguistic mate-
rial describe corpus from the point of view of 
linguistics, such as mode and style. And other 
elements in this class focus on two things, that is 
what the material expressed and how it ex-
pressed. For example: 
?Subject: is used to express the theme of the 
linguistic material, while ?Description? 
gives some further detail of what is talk 
about.
?Markup Language: is especially defined to 
indicate the coding language of electronic 
resources.
4.1.5 Information about collecting linguistic 
material
Corpus is not a simple set of corpus. When se-
lect linguistic material, many factors are consid-
ered. We discuss the information about 
collecting linguistic material in written corpus 
and oral corpus respectively. 
In written corpus, elements mostly describe 
the information of material sample, such as how 
to abstract the sample or how long the sample 
linguistic material should be. Oral corpus has its 
particular way to collect materials, so we de-
scribe them from the scene character of the 
interlocution.
4.1.6 Information about management of lin-
guistic material
Information about management of linguistic ma-
terial record data for corpus management and 
further-processing. Most elements are designed 
for system administrator and it?s recommended 
that the data is user- sightless. Such as Tag in-
formation of linguistic material: 
? Identifier: defined for system to identify 
each linguistic material from this unique 
identifier.
?Sample Name: the material title in the cor-
pus .It can either be the original title of the 
material, or new name the corpus? creator 
gives afterward if it has. 
Log information of linguistic material process-
ing are defined for corpus updating and backup, 
such as input type, annotate type, create date and 
modified date. And system information, such as 
operation system (format.os) and CPU (for-
mat.cpu) are defined to describe the running en-
vironment of the corpus. 
28
in -
lecting linguistic material
Table.4.We define 46 elements in all. They are expected 
to describe the resources from six aspects.
4.2 Subsections
To distinguish one element from another, or our 
elements from someone else?s, we provide a 
potent description method. Ten subsections are 
defined as mutual attribute field. Each metadata 
element can be described with these subsections 
selectively or whole. 
4.2.1 Name
Unique for each element. Used as identifier 
when preserve data. Name is a sting of English 
letter.
4.2.2 Long Name
Displayed as full name in Chinese. 
4.2.3 Definition
Semantic content of an element. 
4.2.4 Comments
Extra or special explanations are put in com-
ments. 
4.2.5 Value Land
Specify the possible value land of metadata. 
4.2.6 Type
A ?Type? subsegment can be either ?basic ele-
ment? or ?file citation?, while ?file citation?  
denotes that the element?s definition has  
referenced some content from another file. 
4.2.7 DefinedIn
Indicate where the metadata has been ever de-
fined. It may be from DC, OLAC or user-
defined.
4.2.8 Obligation
Elements could be either obligatory or optional. 
When a metadata is obligatory, it must be used 
in corpus. 
4.2.9 Publish Date
Indicate the publish date of the metadata 
4.2.10 Publish File
Indicate the name of file in which the metadata 
first defined. 
4.3 Metadata description 
The way to describe a metadata element is to 
assign semantic content to each subsection we 
formation about col
information 
about
copyright
information
about
background 
of linguistic 
material
creator
information 
about me-
dium of 
linguistic 
material
information
about the 
content of 
linguistic 
material
Written
corpus Oral corpus 
information
about man-
agement of 
linguistic ma-
terial
Title Agent Type Medium Type Mode AbstractionType Environment Identifier
Source Iden-
tifier Creator Publish Type Style Position Event Sample Name
Indite Date Sex Publish Area Subject
Words
Amount of 
Resource
Place Input Type 
Issued Date Native Place Amount Description
Words
Amount of 
Sample 
Annotate Type
Copyright Native Lan-guage
Publish Pe-
riod Language Software
Resource
Type Age
Markup Lan-
guage Create Date
Contributor Relation Modified Date
Source Copyright after Annotation
Description of 
Copyright 
Limitation 
Format 
Format.cpu
Format.os 
29
defined before. There are 46 elements in all, and 
we give description of two elements to show the 
model.
'HVFULSWLRQ
Name:  Agent Type 
Long Name: ?????
Definition: The way in which corpus? crea-
tor organized. 
Comments: The creator of a corpus may be 
one person, several persons or an organization. 
Value Land: Defined as {sole, multiple, 
corporate, unknown, unclassified } according to
the design of BNC corpus. ?unknown? represent 
this property has not been obtained, while ?un-
classified? indicate the organized form has not 
been defined in our value land (equivalent to 
NULL in relation database). 
Type: basic element 
DefinedIn: user-defined
Obligation: commendatory 
Publish Date:  2005.1. 
Publish File: Standard of corpus metadata 
'HVFULSWLRQ
Name: Mode 
Long Name: ??
Definition: Type of writing 
Comments: 
Value Land: {kouyupingshi, kouyuyishu, 
shumianpingshi, shumianyishu} 
Type: basic element 
DefinedIn: user-defined
Obligation: commendatory 
Publish Date: 2005.1. 
Publish File: Standard of corpus metadata 
4.4 Encoding syntax 
4.4.1 XML
XML is a widely used language for defining 
data formats. It provides a very rich system to 
define complex documents and data structures. 
As long as a programmer has the XML defini-
tion for a collection of data (often called a 
"schema"), they can create a program to process 
any data format according to those rules. We?ve 
defined our metadata format by using XML in 
several schema files. 
4.4.2 Example of schema
The following codes define the element ?Style?, 
which is proposed to describe the style of article 
material in corpus. We defined four types of 
mode in our standard: narrative writing, exposi-
tory writing, argumentative writing and practical 
writing. In the schema, they are represented as 
?jixuwen?, ?shuomingwen?, ?lunshuwen?, and 
?yingyongwen? respectively. 
<?xml version="1.0" encoding="GB2312"?> 
<schema 
xmlns="http://www.w3.org/2001/XMLSchema"> 
  <annotation> 
    <documentation> 
      CMD Schema for Article Style, seiga, 1/7/05 
    </documentation> 
  </annotation> 
  <simpleType name="CMD-Style-Code"> 
    <restriction base="string"> 
      <enumeration value="jixuwen"/> 
      <enumeration value="shuomingwen"/> 
      <enumeration value="lunshuwen"/> 
      <enumeration value="yingyongwen"/> 
    </restriction> 
  </simpleType> 
</schema> 
Code1.define element ?Mode? in a schema
5 Conclusion 
Metadata is ?data about data?. In our norm, a lot 
work has been done to describe such data. We 
normalized data item, naming regulation, data 
type and data width.46 metadata elements have 
been defined to register information of resource, 
within which 15 belong to DC Metadata, 3 be-
long to OLAC Metadata, 15 belong to both DC 
and OLAC Metadata, and 28 are user-defined. 
According to this, we tag each metadata by its 
?DefinedIn? item. Corpus designers are able to 
choose element during the annotation. They can 
also add new elements to satisfy various re-
quirements basing on this standard. 
The standard use English string when de-
nominating metadata element, because some 
software cannot support Chinese variable. We 
develop DTD files and an assistant software 
(FIG.2-FIG.4) for the convenient of corpus an-
notation. By filling blanks with some metadata 
information in this software, users can directly 
get the XML code of an annotated corpus. 
We are to do some further experiment on corpus 
annotation and corpus management. With vari-
ous information the metadata interpreted, more 
works may lead to resources discovery and con-
tent rating. 
30
FIG.2Interface to input the information about 
copyright, background of linguistic material 
creator and medium of linguistic material 
 FIG.3Interface to input information about 
the content of linguistic material and collect-
ing linguistic material 
FIG.4 Interface to input information about 
management of linguistic material
References
[1]He tingting.Study on corpus. Doctoral dissertation 
of central china normal university 2003.4. 
[2]Dublin Core Metadata Initiative. 
http://dublincore.org/index.shtml
[3]OLAC Metadata Set . http://www.language-
archives.org/OLAC/olacms.html.
[4]International Organization for Standardza-
tion .http://www.iso.org/iso/en/ISOOnline.fromtpage.
[5]The standard and normalization construction of 
digital library. http://cdls.nstl.gov.cn/
[6]What is BNC. 
http://www.hcn.ox.ac.uk/BNC/what/index.html
[7]XML http://www.w3.org/TR/RE-XML
[8]Sun xiaofei. XML and modern digital library. 
Modern books information,2000,(4) 
[9]Cui gang,Sheng yongmei. Annotion of corpus. 
Pekin? Tsinghua. University press?2000?15(1) 
31
