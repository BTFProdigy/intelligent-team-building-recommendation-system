Proceedings of the EACL 2009 Workshop on Language Technologies for African Languages ? AfLaT 2009, pages 89?95,
Athens, Greece, 31 March 2009. c?2009 Association for Computational Linguistics
A repository of free lexical resources for African languages:  
the project and the method 
Piotr Ba?ski 
Institute of English Studies 
University of Warsaw 
Warsaw, Poland 
bansp@o2.pl 
Beata W?jtowicz 
Institute of Oriental Studies 
University of Warsaw 
Warsaw, Poland 
b.wojtowicz@uw.edu.pl 
 
Abstract 
We report on a project which we believe to 
have the potential to become home to, among 
others, bilingual dictionaries for African lan-
guages. Kept in a well-structured XML for-
mat with several possible degrees of confor-
mance, the dictionaries will be able to get us-
able even in their early versions, which will 
be then subject to supervised improvement as 
user feedback accumulates. The project is 
FreeDict, part of SourceForge, a well-known 
Internet repository of open source content.  
We demonstrate a possible process of dic-
tionary development on the example of one 
of FreeDict dictionaries, a Swahili-English 
dictionary that we maintain and have been 
developing through subsequent stages of in-
creasing complexity and machine-
processability. The aim of the paper is to 
show that even a small bilingual lexical re-
source can be submitted to this project and 
gradually developed into a machine-
processable form that can then interact with 
other FreeDict resources. We also present the 
immediate benefits of locating bilingual Afri-
can dictionaries in this project. 
We have found FreeDict to be a very promis-
ing project with a lot of potential, and the 
present paper is meant to spread the news 
about it, in the hope to create an active com-
munity of linguists and lexicographers of 
various backgrounds, where common re-
search subprojects can be fruitfully carried 
out. 
1 Introduction 
The FreeDict project was started by Horst Eyer-
mann in 2000 and initially hosted bilingual dic-
tionaries produced by concatenating (crossing) 
the contents of the dictionaries in the Ergane pro-
ject (http://download.travlang.com/Ergane/), 
with Esperanto as the interlanguage. At first, the 
data was kept in the DICT format (Faith and 
Martin, 1997). 
DICT (Dictionary Server Protocol) is by now 
a well-established TCP-based query/response 
protocol that allows a client to access definitions 
from a set of various dictionary databases. It 
provides data in textual form, but it also has the 
potential of providing MIME-encoded content. 
The clients can be free-standing desktop applica-
tions or they can be integrated into editors or 
web browsers. DICT web gateways also exist  
(see e.g. http://dict.org/). 
The DICT format is a plain text format with an 
accompanying index file. The FreeDict-DICT 
interface initially used so-called ?c5 files?.1 A c5 
example of an entry from version 0.0.1 of Swa-
hili-English dictionary is presented below. 
 
abiria 
     passenger(s) 
 
Later on, the project adopted the TEI P4 standard 
(Sperberg-McQueen and Burnard, 2002) as its 
primary format, and with the help of its second 
administrator, Michael Bunk, created tools for 
conversion from the TEI into a variety of other 
dictionary platforms. A simple dictionary editor 
was also created. The change of the primary 
format was a very fortunate move, thanks to 
which we can today recommend the project as 
the possible home for free African language dic-
tionaries big and small. 
We are going to base our discussion on the 
Swahili-English dictionary, the first FreeDict 
dictionary encoded according to the guidelines of 
TEI P5 XML standard (TEI Consortium, 2007). 
The dictionary in its current form is an offshoot 
of a different project of ours that we decided to 
make available on a free license and in version 
0.4 contains over 2600 headwords. We use it to 
demonstrate a possible process of dictionary de-
                                                 
1 C5 is the format used, among others, by the CIA World 
Factbook, where the heading is at the left edge and the con-
tents are indented by 5 spaces. 
89
velopment, from the simplest to the advanced, 
machine-processable form. 
2 From glossaries to rich lexical data-
bases: the possible shapes of FreeDict 
dictionaries 
A dictionary can begin its life at FreeDict as a 
simple glossary, with the simplest format possi-
ble, as shown in the made-up entry below: 
 
<entry> 
<form><orth>alasiri</orth></form> 
<def>afternoon</def> 
</entry> 
 
The next example entry comes from Swahili-
English xFried Freedict Dictionary, version 
0.0.2, compiled by Beata W?jtowicz. That dic-
tionary contained around 1500 entries of varied 
quality. It was based on a dictionary extracted 
from Morris P. Fried?s Swahili-Kiswahili to Eng-
lish Translation Program, to which selected en-
tries from the first FreeDict Swahili-English dic-
tionary (compiled by Horst Eyermann) were 
added. That version also introduced information 
on parts of speech. 
 
<entry> 
<form><orth>alasiri</orth></form> 
<def>   afternoon</def> 
<gramGrp> <pos>n</pos> </gramGrp> 
</entry> 
 
On the way to version 0.3, the entry looked as 
follows: 
 
<entry xml:id="alasiri">      
  <form><orth>alasiri</orth></form>             
  <gramGrp><pos>n</pos></gramGrp> 
  <sense> 
 <def>afternoon (period between 3   
  p.m. and 5 p.m.)</def> 
  </sense> 
</entry> 
 
All the bracketed information was then turned 
into separate <note/> elements, in order to 
make the translation equivalents easily proc-
essable (see Prinsloo and de Schryver, 2002, for 
remarks on processability of translation equiva-
lents). The change was performed by regex 
search-and-replace, roughly from 
\((.+)\)</def> into </def><note 
type="hint">$1</note>2, with a subsequent 
                                                 
2 This is in fact a slight simplification of what has been 
done, made for the purpose of clarity. Naturally, the regexes 
have to be adopted to the circumstances (regularity of mar-
kup, regularity of expressions in brackets, the number of 
review of all the new <note/> elements ex-
tracted by an XPath query. 
Depending on the regularity of expressions in 
brackets, some additional words would be in-
serted into the search string, to be converted into 
<note/> elements of the appropriate type. Ini-
tially, only @type="hint" was used, as the 
most generic. At the moment, there are several 
more specialized type values, including 
@type="editor", which contains editorial re-
marks that will not be shown to the user but will 
remain in the source. @type-less <note/> ele-
ments are used for quick localized communica-
tion between editors and are discarded by XSLT 
scripts when preparing the source version for 
release (they are also clearly marked by the CSS 
stylesheet that accompanies the dictionary, so 
that the editors can easily spot each note when 
reviewing the dictionary in a browser). FreeDict 
advocates the use of some other types of notes: 
recording the last editor of the entry, the date of 
the latest modification, and the degree of cer-
tainty, valuable in this kind of projects (where, 
e.g., some automated changes would set the cer-
tainty level to ?low? and as such requiring edito-
rial approval). 
In the current version, 0.4, the <sense/> 
element looks as follows. 
 
<sense> 
<def>afternoon</def> 
<note type="def">period between 3    
   p.m. and 5 p.m.</note> 
</sense> 
 
This is what we decided to keep in version 0.4, 
exactly for the purpose of illustrating the possi-
ble development stages of dictionaries. In the 
next version, the <sense/> element will eventu-
ally attain the form currently (i.e., after Septem-
ber 2007) recommended by the TEI Guidelines 
for translation equivalents: 
 
<sense> 
<cit type="trans"> 
    <quote>afternoon</quote> 
<def>period between 3 p.m. and 
5 p.m.</def> 
</cit> 
</sense> 
 
The <quote/> element holds the translation 
equivalent that can be an anchor for dictionary 
                                                                          
such expressions per single element content, etc.). Some-
times, an XSL transformation may turn out to do a better 
job, thanks to the many string-handling functions of XPath 
2.0. 
90
reversal or concatenation. The <def/> element 
above is not abused anymore and holds a real 
definition, i.e., an ?explanatory equivalent?, 
which may become a sense-discriminating note 
in the reversed dictionary. 
We stress that each of the XML structures pre-
sented above (some of them admittedly border-
ing on tag abuse) conforms to the general P5 
format and can be easily processed and pub-
lished. In other words, dictionary editors are not 
forced to conform to the final format in order to 
see their work being used and commented on. 
The next section presents another aspect of 
dictionary creation, where what matters is the 
ease of data manipulation and filling in the pre-
dictable information for the developer. 
3 Plural forms: an illustration of auto-
mated creation of entries 
At the stage of development at which brackets 
have been eliminated from translation equiva-
lents, a relatively simple entry might look as 
shown below. This is an entry as created by a 
developer, to be further processed by XSLT.3 
 
<entry> 
<form> 
 <orth>adui</orth> 
 <ref target="#maadui"/> 
</form> 
<gramGrp><pos>n</pos></gramGrp> 
<sense><def>enemy</def></sense> 
<sense> 
 <def>opponent</def> 
 <note type="hint">in games or     
 sports</note> 
</sense> 
</entry> 
 
This entry is then processed and turned into the 
form presented below. 
 
<entry xml:id="adui"> 
<form> 
 <orth>adui</orth> 
</form> 
<xr type="plural-form"><ref tar-
get="#maadui">maadui</ref></xr> 
<gramGrp> 
 <pos>n</pos> 
</gramGrp> 
<sense xml:id="adui.1" n="1"> 
 <def>enemy</def> 
</sense> 
<sense xml:id="adui.2" n="2"> 
                                                 
3 The verbosity of XML markup can be overwhelming, but 
many XML editors feature content completion and can save 
the developer a lot of typing, the more so that TEI schemas 
are often part of the editor package.  
 <def>opponent</def> 
 <note type="hint">in games or     
 sports</note> 
</sense> 
</entry> 
 
If the plural form does not exist in the dictionary, 
the script creates an entry for it: 
 
<entry xml:id="maadui"> 
<form> 
 <orth>maadui</orth> 
</form> 
<gramGrp> 
 <pos>n</pos> 
</gramGrp> 
<sense> 
 <xr type="plural-sense">Plural of    
 <ref target="#adui">adui</ref> 
 </xr> 
 <def>enemy</def> 
 <def>opponent <note type="hint">in   
 games or sports</note></def> 
</sense> 
</entry> 
 
The equivalents in this kind of automatically cre-
ated entries for plurals will remain within 
<def/> elements even after we adopt the 
cit/quote system mentioned above in the discus-
sion of alasiri. This is because <def/> elements 
are not anchors for dictionary reversal, and plural 
entries will be skipped by the reversal tools, 
unless the plural/collective form has its own 
unique meaning, as is the case with e.g. majani, 
which is morphologically the plural form of jani 
?leaf; blade of grass?, but apart from that, it 
should also be glossed as ?grass?, and it is the 
latter form that should become a headword in the 
reversed, English-Swahili dictionary. 
Another area where the XML format and tools 
give excellent results is text normalization. An 
earlier example shows unnecessary spaces in 
version 0.0.2: <def>   afternoon</def>. 
Handling these required only the use of an XPath 
function normalize-space(), which strips all 
the unwanted whitespace characters.4 
All the indexing is also done automatically. 
The indexing system in this particular dictionary 
is based on the shape of the headword, which it 
is easy to convert into form acceptable by the 
XML ID attributes (the XPath translate() 
and replace() functions are handy here). All 
                                                 
4 That version contained more traps for machine-processing, 
such as bracketed parts of words ? sometimes this was 
done in a nontrivial manner, as in the entry for adui: 
<def>   enemy(-ies)</def>. See Prinsloo and de 
Schryver (2002) for remarks on the non-friendliness of such 
space-saving devices. 
91
the entries are first reordered alphabetically, then 
the script checks for homographs and assigns 
them appropriate indexes (e.g. chapa-1 for the 
noun meaning ?brand?, chapa-2 for the verb 
meaning ?beat?) and appropriate attributes used 
later in the creation of superscripts (suppressed 
in the plain-text DICT format). Multiple senses 
are also treated similarly ? each receives its 
own @xml:id attribute and numbering (see the 
example of adui above). 
We emphasize the fact that the encoding for-
mat makes it possible to reduce the developer?s 
workload, with each stage of the dictionary en-
hancement being publishable. This allows one to 
work on the dictionary on and off, in their spare 
time. 
4 Visualization of underlying structure 
Some Swahili words are best lemmatized as 
stems. Version 0.4 of our dictionary does not yet 
display the differences between bound stems and 
free forms, but we will transfer this functionality 
(which we use in another project) to one of the 
future versions. This will make it possible for us 
to, e.g., add hyphens to bound forms and prepend 
?-a ? to adjectives introduced by the ?-a of rela-
tionship?, adding extra structure visible to the 
end user, but ignored in sorting or queries. 
Disjunctively written languages can be han-
dled similarly. Kiango (2000:36) lists the follow-
ing examples from Haya, discussing the prob-
lems surrounding alphabetization of nouns in 
print dictionaries: 
 
a ka yaga ?air? 
e m pambo ?seed? 
o mu twe  ?head? 
The vocalic pre-prefixes should not be used for 
the purpose of arranging headwords, because if 
they are, all nouns end up under one of the three 
letters. Instead, class prefixes (ka, m, mu) should 
form the basis for alphabetization. In the 
XML/TEI format adopted by FreeDict, such 
problems are easily solved, either by using a 
separate element to hold the pre-prefix, or by the 
use of an appropriate attribute. The former solu-
tion is illustrated below. 
 
<entry> 
<form> 
 <orth extent="ppref">a</orth> 
 <orth>ka yaga</orth> 
</form> 
<def>air</def> 
</entry> 
The default value for the @extent attribute is 
?full?, so it only needs to be mentioned where 
the value is different.  
An AfLaT reviewer rightly points out that in 
an electronic dictionary, alphabetization is irrele-
vant. Indeed, the DICT format features separate 
?dictionary? and ?index? files, and searching is 
done on the index file, which addresses the rele-
vant portions of the dictionary file. The issue of 
alphabetization arises, however, in two cases: 
when preparing a print version of the dictionary, 
or when using the dictionary outside of the DICT 
system (this is a ?working view? for the main-
tainers that can also be used as an out-of-the-box 
view for users). 
In connection with the first case ? preparing 
print/PDF versions of dictionaries ? it is worth 
pointing out that conversion from TEI XML into 
various publication formats is made easy thanks 
to the open-source XSLT conversion suite main-
tained by Sebastian Rahtz (http://www.tei-
c.org/Tools/Stylesheets/). 
As for the ?out-of-the-box preview?, FreeDict 
dictionaries, by virtue of being marked up in 
XML, can be equipped with CSS stylesheets that 
make it possible to display the XML source in 
the browser, as if it were an HTML page. Here, 
because the user can search the page for the 
given form, alphabetization is not so relevant, 
but it can be handy, if only for aesthetic reasons. 
Below is a screenshot of a fragment of the CSS 
view of the file swa-eng.tei from version 0.4 dis-
tribution package, opened directly in the Firefox 
browser. 
 
 
Figure 1: A CSS preview of the source XML 
 
The CSS adds some text (e.g. ?[sg=pl]?, ?(pl:?, 
or sense numbering) and imposes visual structure 
onto the source XML. As can be seen in the en-
try for kiungo, we give precedence to formal 
92
properties of headwords over the semantic dis-
tinctions, but other macrostructural decisions are 
obviously possible as well. The figure below 
shows one more CSS view, demonstrating sub-
categorization, treatment of notes (all the brack-
eted strings are contents of separate XML ele-
ments, with parentheses supplied by the CSS), as 
well as the treatment of homographs.  
 
 
Figure 2: Subcategorization and grammar notes (an-
other CSS view of the source XML) 
 
Our use of colours (here: shades of grey) is also a 
function of the CSS, introduced mainly with the 
developer in mind, as a kind of an error-checking 
device. 
5 Other possible enhancements of the 
microstructure 
In section 3, we have illustrated a possible 
method of refining dictionary structure in an 
automatic fashion. Thanks to the many possible 
variations of the format, other features may be 
introduced stage by stage. They include, e.g., 
adding the corresponding plurals (illustrated 
above) or marking forms where the plural is the 
same as the singular, as done below by the use of 
the @type attribute. This example also illustrates 
the addition of cross-references to synonyms, 
where eropleni is linked to the second, inani-
mate, sense of ndege ?bird; airplane?. 
 
<entry xml:id="eropleni"> 
<form type="N"> 
 <orth>eropleni</orth> 
</form> 
<gramGrp> 
 <pos>n</pos> 
</gramGrp> 
<sense> 
 <def>airplane</def> 
 <xr type="syn">(synonym: <ref tar  
 get="#ndege.2">ndege</ref>)</xr> 
</sense> 
</entry> 
 
The <form/> element below illustrates the han-
dling of alternative spellings of the noun af-
isa/ofisa ?officer?. Both headwords are used in 
retrieval. 
 
<entry xml:id="afisa"> 
  <form> 
<orth n="1">afisa</orth> 
<orth type="variant"  
          n="2">ofisa</orth> 
<ref target="#maafisa" n="1"/> 
<ref target="#maofisa" n="2"/> 
  </form> 
The above is the source as prepared by a devel-
oper. This is then processed, the plural forms are 
created if they do not exist in the dictionary, and 
the result is as in figure 3 below. 
 
Figure 3: Illustration of alternative spellings/plurals 
(CSS view) 
 
Other examples of what can be gradually intro-
duced into the dictionary include addition of 
subcategorization information (illustrated by 
pako in Figure 2, where ?pron? is the POS and 
?poss? is the content of the <subc/> element), 
addition of explicit noun-class- and agreement-
marking, introduction of irregularly inflected 
forms, tables with inflection (linked to the ap-
propriate stems), nested entries, and, obviously, 
the continuous improvement of lexicographic 
information (the arrangement and selection of 
senses, selection of headwords, an appropriate 
POS system). 
Crucially, this system allows a developer to 
?publish early, publish often?, and few of the 
enhancements mentioned here depend on others 
? developers are free to choose and to extend 
the dictionary at their own pace. 
In our case, this is a gradual move towards 
structures of finer granularity, suitable for rever-
sal (into English-Swahili) and concatenation with 
other dictionaries (we are going to use English as 
the bridge language for pairing the Swahili-
English dictionary with English-* dictionaries).  
6 Potential for the future 
We wish to stress the potential that the encoding 
format and the entire project have for producing 
lexical resources for ?non-commercial? lan-
guages, where funding and the time that the de-
velopers may spend on the dictionary are not al-
ways guaranteed. FreeDict dictionary develop-
ment can proceed in stages, one can start with a 
93
simple format and get the dictionary published 
on-line practically within days. The project has 
all the SourceForge publishing facilities at its 
disposal, together with bug/patch/etc. trackers 
and community forums. It also has a mailing list 
and a wiki that can serve to document some pos-
sibly difficult aspects of dictionary creation. 
Thanks to the robust build system of FreeDict, 
creating a tarball containing a DICT-formatted 
dictionary and index is only a matter of issuing 
the ?make? command with appropriate argu-
ments, and submitting the resulting archive to the 
SourceForge file release system.5 
FreeDict is the nexus for the following: 
? XML, with its potential for creating 
well-structured documents, 
? TEI P5, a de-facto standard taking ad-
vantage of this potential,  
? the SourceForge repository as well as 
distribution and content-management net-
work, 
? the DICT distribution network: apart 
from being able to query DICT servers 
straight from the desktop, Firefox users 
can also take advantage of an add-on cli-
ent that returns definitions for highlighted 
words on a web page, 
? FreeDict tools (still under development 
for TEI P5) as means to manipulate dic-
tionaries and to create, among others, the 
DICT format (usable directly from DICT 
servers and by other dictionary-providing 
projects, e.g., StarDict or Open Dict).6 
Additionally, lexical resources submitted to 
FreeDict may undergo further transformations: 
reversal or concatenation, which means that 
work put into developing a single resource may 
well be re-used in developing others. Consider-
ing the possible re-use of lexical resources, they 
are expected to be prepared with a view towards 
clean exposure of translation equivalents (in the 
cit/quote system or at least by judicious use of 
separators and brackets). 
The project has its own distribution system, in 
the form of GNU/Linux packages ? for exam-
                                                 
5 This is something that a dictionary creator need not bother 
about ? submitting a TEI source of the dictionary to the 
mailing list is enough. 
6 The FreeDict build process provides targets for platforms 
other than DICT, e.g. the Evolutionary Dictionary 
(http://www.mrhoney.de/y/1/html/evolutio.htm) or zbedic 
(http://bedic.sourceforge.net/). 
ple, K?stutis Bili?nas is the packager for Debian 
Linux and maintains a page tracking the usage of 
Debian-FreeDict packages; 
Apart from the above, the content published 
by FreeDict is guaranteed to be free.  
7 The costs of developing for FreeDict 
An AfLaT reviewer suggested that we provide a 
measure of the effort required to develop a re-
source for FreeDict. We hope to show here that 
this is very much dependent on the quality and 
form of the resource and on how much time the 
dictionary creator is willing to invest into it. Cru-
cially, given the open-source nature of the pro-
ject, even a simple, small list of near-binary pair-
ings of equivalents can be a) quickly made useful 
to e.g. the readers of web pages written in the 
given language, and b) extended by others into a 
more satisfying resource. 
It may be that the effort needed to create lan-
guage resources in e.g. Lexique Pro, an excellent 
free tool by SIL International 
(http://www.lexiquepro.com/) is smaller, but 
there are differences in that Lexique Pro is a 
Windows-only closed-source program whose 
native MDF (Multi-Dictionary-Formatter) format 
is not as flexible as XML and therefore cannot be 
processed by the many tools that handle XML 
and TEI in particular. Consequently, the perspec-
tives for re-use of Lexique Pro dictionaries in 
computational linguistic applications are much 
smaller. To our knowledge, Lexique Pro does not 
make it possible for users to query words straight 
off web pages, which can be done thanks to dict, 
a Firefox add-on (http://dict.mozdev.org/). It ad-
mittedly has other advantages that make it a seri-
ous alternative.7 
The ideal solution would be to have an editing 
front-end such as Lexique Pro coupled with the 
openness and modifiability of the data offered by 
FreeDict. Indeed, there are plans for creating a 
converter from the new LIFT interchange stan-
dard (http://code.google.com/p/lift-standard/) 
that the beta versions of Lexique Pro can read 
                                                 
7 We do not discuss professional commercial dictionary 
writing systems such as TshwaneLex 
(http://tshwanedje.com/tshwanelex/) because, despite the 
academic discounts, they may be out of range for the aver-
age developer. It is worth mentioning that the discounted 
versions of TshwaneLex come with the understandable ?no-
commercial-use? restriction, which is in conflict with either 
the GNU Public License or the nearly equivalent Creative 
Commons BY-SA license that all SourceForge resources 
must be under (cf. http://www.gnu.org/licenses/gpl-
faq.html). 
94
and write, to the version of the TEI format used 
by FreeDict. That would undoubtedly enhance 
the attractiveness of the project. 
To sum up, developing for FreeDict minimally 
requires some basic knowledge of XML. Free 
XML editors exist (e.g. XML Copy Editor, 
http://sourceforge.net/projects/xml-copy-editor/) 
that can make editing easier by autocompleting 
the elements (inserting closing tags, suggesting 
elements and attributes that are allowed at the 
given place in the structure) and signalling en-
coding mistakes. 
8 African Languages and FreeDict 
A reviewer remarked that the link to African lan-
guage technology in this paper appears only to be 
present in the examples. Indeed, FreeDict is not a 
project that focuses on African-languages ? it is 
a project where African language resources can 
be hosted and quickly become useful to users. 
Given an opportunity, we will encourage re-
searches dealing with other languages to join the 
project ? which will hopefully result in the crea-
tion of more cross-language resources, especially 
given that the encoding format is not tied to any 
particular language and is able to easily accom-
modate features characteristic of practically any 
language. 
During the session on ?African Languages in 
Advance? at the 2008 Pozna? Linguistic Meet-
ing, where we presented our Swahili-Polish pro-
ject and also mentioned FreeDict as the place 
where we wanted to donate parts of our test 
Swahili-English dictionary that would otherwise 
remain on our disks, we talked to an organizer of 
that session, Karien Brits, about the advantages 
that this project can have for some of her col-
leagues working on South-African languages. 
This is what encouraged us to move on with the 
FreeDict Swahili-English dictionary and we hope 
that others will also find this project, and the 
possibilities that it offers, attractive. 
The FreeDict project has recently awoken af-
ter a period of lower activity, and at the moment, 
every week brings something new. Currently, as 
far as African languages are concerned, apart 
from Swahili?English dictionaries, the project 
hosts very basic Afrikaans?English dictionaries, 
and an Afrikaans-German dictionary (all of them 
in need of a maintainer).8 We hope that FreeDict 
                                                 
8 Dictionary sources can be accessed from the ?download? 
link on the project page: http://sourceforge.net/projects/ 
freedict/. They can be queried online at e.g. http://dict.org/, 
by setting the appropriate language pair in the database. 
will become home to many African language 
resources, and, thanks to the possibility of dic-
tionary concatenation, facilitate also the creation 
of many African?European dictionary pairs as 
well as all-African bilingual dictionaries. 
Acknowledgements 
We are grateful to three anonymous AfLaT-2009 
reviewers for their helpful comments on the pre-
vious version of this paper, and to Michael Bunk 
for confirming that our version of the history of 
the project is close to reality. We also wish to 
thank Janusz S. Bie? for turning our attention to 
the FreeDict project a few years ago.  
References  
DICT: http://www.dict.org/ 
Faith, Rik and Martin, Brett. 1997. A Dictionary 
Server Protocol. Request for Comments: 2229 
(RFC #2229). Network Working Group. Available 
from ftp://ftp.isi.edu/in-notes/rfc2229.txt (last ac-
cessed on January 19, 2009). 
FreeDict: http://www.freedict.org/, 
http://freedict.sourceforge.net/ 
Kiango, John G. 2000. Bantu lexicography: a criti-
cal survey of the principles and process of 
constructing dictionary entries. Tokyo: Institute 
for the Study of Languages and Cultures of Asia 
and Africa, Tokyo University of Foreign Studies. 
Prinsloo, Danie J. and Gilles-Maurice de Schryver. 
2002. Reversing an African-language lexicon: the 
Northern Sotho Terminology and Orthography No. 
4 as a case in point. South African Journal of Afri-
can Languages, 22/2: 161?185 
Sperberg-McQueen, Michael and Lou Burnard (eds). 
2002. The Text Encoding Initiative Guidelines 
(P4). Text Encoding Initiative, Oxford. 
TEI Consortium, eds. 2007. TEI P5: Guidelines for 
Electronic Text Encoding and Interchange. 
Version 1.2.0. Last updated on October 31st 2008. 
TEI Consortium.   Available from                             
http://www.tei-c.org/Guidelines/P5/ (last accessed 
on January 19, 2009). 
95
Proceedings of the Third Linguistic Annotation Workshop, ACL-IJCNLP 2009, pages 64?67,
Suntec, Singapore, 6-7 August 2009. c?2009 ACL and AFNLP
Stand-off TEI Annotation: the Case of the National Corpus of Polish 
Piotr Ba?ski
Institute of English Studies
University of Warsaw
Nowy ?wiat 4, 00-497 Warszawa, Poland
pkbanski@uw.edu.pl
Adam Przepi?rkowski
Institute of Computer Science
Polish Academy of Sciences
Ordona 21, 01-237 Warszawa, Poland
adamp@ipipan.waw.pl
Abstract
We present the annotation architecture of 
the National Corpus of Polish and discuss 
problems identified in the TEI stand-off 
annotation system,  which,  in  its  current 
version, is still very much unfinished and 
untested,  due  to  both  technical  reasons 
(lack  of  tools  implementing  the  TEI-
defined  XPointer  schemes)  and  certain 
problems concerning data representation. 
We  concentrate  on  two  features  that  a 
stand-off system should possess and that 
are conspicuously missing in the current 
TEI Guidelines.
1 Introduction
The present paper presents the National Corpus 
of  Polish  (NCP).1 The  project  is  a  joint 
undertaking  of  a  consortium  consisting  of 
institutions that created their own large corpora 
of Polish in the past (see (Przepi?rkowski et al, 
2008)  for  details);  these  corpora  formed  the 
initial data bank of the corpus. The intended size 
of the corpus is  one billion (109) tokens and as 
such, at the time of completion in 2010, the NCP 
is  going  to  be  one  of  the  largest  corpora 
available,  possibly  the  largest  corpus  featuring 
multiple levels of linguistic annotation of various 
kinds.  Currently,  a  hand-verified  one-million-
token subcorpus is being completed, and a basic, 
automatically created 430-million-token demo is 
available online at http://nkjp.pl/.
The project uses an extended morphosyntactic 
tagset with several years of practical use behind 
it  in  one  of  the  source  corpora  (cf. 
http://korpus.pl/)  and an open-source query en-
gine with a powerful, regex-based language and 
a graphical front-end.
Section  2  of  this  paper  talks  about  the 
encoding format adopted for the corpus, section 
1 The  Polish  name  of  the  corpus  is  Narodowy  Korpus 
J?zyka  Polskiego,  hence  the  abbreviation  NKJP,  used  in 
web addresses and namespace identifiers.
3 presents its general architecture, and section 4 
discusses  the  reasons  for,  and  our  implemen-
tation  of,  the  suggested  NCP  enhancements  to 
the TEI Guidelines.
2 The encoding format: stand-off TEI
The Text Encoding Initiative (TEI Consortium, 
2007) has been at the forefront of text annotation 
and resource interchange for many years. It has 
influenced corpus linguistic practices in at least 
three related ways. Firstly,  the formalism itself, 
in the mature  form,  has been used to  mark  up 
linguistic  corpora,  e.g.  the  British  National 
Corpus.  An  early  application  of  the  TEI,  the 
Corpus  Encoding  Standard  (CES;  see 
http://www.cs.vassar.edu/CES/), together with its 
XML  version,  XCES  (http://www.xces.org/), 
have served as de facto standards for corpus en-
coding  in  numerous  projects.  Finally,  the  ex-
perience gained in creating and using XCES (to-
gether with e.g. the feature-structure markup of 
the TEI) has served as a foundation for the Lin-
guistic  Annotation  Format  (LAF,  Ide  and  Ro-
mary, 2007), within ISO TC37 SC4.  LAF pro-
mises to provide a standard interchange format 
for  linguistic  resources  of  many  diverse  kinds 
and origins.
The relationship between the TEI (especially 
in its stand-off version) and the LAF is straight-
forward.  Both are implemented in XML, which 
makes transduction between a rigorous TEI for-
mat and the LAF ?dump? (pivot) format mostly a 
matter of fleshing out some data structures.
3 NCP ? general architecture 
Stand-off annotation is by now a well-grounded 
data representation technique,  pioneered by the 
CES and continuing to be the foundation of the 
LAF. In short, it assumes that the source text in 
the corpus, ideally kept in an unannotated form 
and in read-only files,  is the root of a possibly 
multi-file  system  of  data  descriptions  (each 
description focusing on a distinct aspect of the 
64
source data). The source text is typically accom-
panied by a level of primary segmentation, which 
may  be  the  lowest-level  XML  layer  of  anno-
tation.  The  other  files  form  a  possibly  multi-
leaved  and  multi-leveled  hierarchy  referencing 
either  the  level  of  primary  segmentation,  or 
higher  order  levels  of  description.  The  NCP 
follows these guidelines to the extent allowed by 
the TEI schema.
Each corpus text is kept in a separate directory 
together with the annotation files that reference it 
directly or indirectly, and with the header that is 
included  by  all  these  files.  Contents  of  an 
example directory are shown below.
(1) text.xml
header.xml
ann_morphosyntax.xml
ann_segmentation.xml
ann_structure.xml
All of these files contain TEI documents (or, in 
the case of header.xml, proper subsets thereof). 
They form a  hierarchy of  annotation levels,  as 
presented  in  Figure  1.  The  text.xml  file  is  the 
root,  referenced  by  the  layer  of  text  structure 
(providing  markup  from  the  paragraph  level 
upwards)  and  the  layer  of  segmentation.  The 
segmentation layer  is  further referenced by the 
layer of morphosyntactic information and word-
sense annotation. The morphosyntactic level, in 
turn,  is  the  basis  for  the  level  identifying  syn-
tactic  words,  which  constitutes  the  foundation 
upon  which  the  levels  identifying  syntactic 
chunks and named entities are built.
In  text.xml,  the  normalized  source  text  is 
divided in paragraph-sized chunks (enclosed in 
anonymous blocks, <ab>, to be further refined in 
the  text-structure  level  of  annotation).2 It  also 
2 Ideally,  as mentioned above,  the primary text should be 
stored without markup, and the segmentation layer should 
constitute the lowest-level XML document. This is exactly 
includes  two  headers:  the  main  corpus  header, 
which encodes information relevant to all  parts 
of  the  corpus,  and  the  local  header,  which 
records the information on the particular text and 
its annotations.
The segmentation file provides what the LAF 
calls the base segmentation level that is further 
used as the basis for other kinds of annotation. It 
is implemented as a TEI document with <seg> 
elements that contain XInclude instructions (see 
example (4) in the next section). As such, it may 
serve both as a separate annotation layer or as a 
merged  structure,  after  the  inclusion  directives 
are resolved. Crucially, in the latter case, which 
is  the  default  with  many parsers,  the  XPointer 
indexing information is lost. We shall come back 
to this issue in section 4.1.
The text-structure layer is defined similarly to 
the segmentation layer.  Other annotation layers 
replace the mechanism of XInclude with XLink, 
in the way advocated by the XCES.
The morphosyntactic layer of annotation con-
sists of a series of <seg> elements that contain 
TEI feature structures (i) providing basic infor-
mation on the segment,  (ii)  specifying the pos-
sible interpretations as identified by the morpho-
logical analyser, and (iii) pointing at the morpho-
what  the  LAF-encoded  American  National  Corpus  does, 
requiring dedicated tools for merging plain text corpus files 
with  the  segmentation  documents.  Unfortunately,  this  is 
where we reach the technological boundary of the XInclude 
system: it is unable to reference substrings in a plain text 
file,  due  to  a  weakly  motivated  ban  on  the  concurrent 
presence  of  @parse=?text?  attribute  and  the  @xpointer 
attribute.  We  therefore  enclose  the  source  text  in  ano-
nymous  blocks  (<ab>)  that  we  can  easily  address  with 
XPointers. An anonymous reviewer agrees that the lack of a 
single,  immutable  text  file  is  a  serious  weakness  of  this 
system and notes that being able to derive plain text from 
markup is no remedy. This may constitute either a case for 
XLink, or an argument for lifting the @parse/@pointer ban.
Figure 1: The logical data structure of the NCP
65
syntactic  description  selected  by  the  disambi-
guating agent.
The  higher-order  annotation  layers  also 
contain feature structures, which usually point at 
the  selected segments  of  annotation layers  that 
are one level  lower, and identify their  function 
within the given data structure.
4 Enhancements  to  the  TEI  stand-off 
recommendations
In this section, we first illustrate a case where the 
stand-off annotation system as advocated by the 
TEI  loses  information  on  the  boundedness  of 
segments,  and  then  move  on  to  illustrate  a 
different  issue  stemming  from  the  lack  of  a 
neutral bracket-like element in the TEI markup. 
4.1 Identification of bound segments
Segmentation  of  Polish  texts  is  not  a  trivial 
matter,  partially  because  of  the  person-number 
enclitics ? elements that can attach to almost any 
part  of  the  clause,  while  being  functionally 
related to  the  main  verb.  Segmenting them to-
gether  with  their  hosts,  apart  from  being  a 
methodologically  bad  move,  would  greatly  in-
crease the complexity of  the linguistic analysis 
built on top of such segmentations. The diamond 
in  (2)  below marks  alternative  positions  where 
the  2nd Person  Plural  clitic  (separated  by  a 
vertical  bar)  may  appear.  All  of  the  resulting 
sentences have the same interpretation.
(2) Czemu|?cie znowu? wczoraj? Piotra? gonili??
why|2pl again yesterday Piotr chased.prt
?Why did you chase Piotr yesterday again??
Yet  another  group  of  segmentation  problems 
concerns  compounds,  right-headed  (3a)  or  co-
ordinative (3b).
(3) a. ???to|czerwony materia?
yellow|red fabric
?yellowish red fabric?
b. ???to-czerwony materia?
?yellow and red fabric?
Inline markup of the above examples preserves 
information on which segment is bound (attached 
to  the  preceding  one)  or  free-standing.  This  is 
due  to  the  whitespace  intervening  between the 
<seg> elements in this kind of markup.
When,  however,  stand-off  markup  using  the 
XInclude  mechanism  is  applied  here,  com-
plications  arise.  The  segmental  level  of  anno-
tation with unresolved inclusions provides clear 
hints about the status of segments. This is due to 
XPointer  offsets,  as  can be seen  in  (4)  below, 
which is an example assuming that the adjective 
???to-czerwony is the first word in an <ab> ele-
ment bearing the @xml:id attribute set to ?t1?.3
(4)
<seg xml:id="segm_1.1-seg">
 <xi:include href="text.xml"
 xpointer="string-range(t1,0,5)"/></seg>
<seg xml:id="segm_1.2-seg">
 <xi:include href="text.xml"  
 xpointer="string-range(t1,5,1)"/></seg>
<seg xml:id="segm_1.3-seg">
 <xi:include href="text.xml" 
 xpointer="string-range(t1,6,8)"/></seg>
However, after inclusions are resolved, all of the 
offset  information  is  lost,  because  all  the 
@xpointer attributes (indeed, all the <xi:include> 
elements)  are  gone  and  all  that  remains  is  a 
sequence  of  <seg>  elements  such  as 
<seg>???to</seg><seg>-</seg><seg>cze
rwony</seg>.
While, in many cases, information on bound-
edness  could  be  recovered  from  the  morpho-
syntactic description of the given segment,  this 
does not resolve the issue because, firstly, a re-
course  to  morphosyntactic  annotation  layer  in 
order to recover information lost in the segmen-
tation layer is methodologically flawed (in some 
cases, it is perfectly imaginable that a text is only 
accompanied by the segmentation layer of anno-
tation and nothing else), and, secondly, morpho-
syntactic identity will not resolve all such cases. 
Consider the example of ???to-czerwony ?yellow 
and red?: the segment  czerwony here is bound, 
but  both  graphically  and  morphosyntactically 
identical  to  the  frequent  free-standing  segment 
czerwony ?red?.
In order to accommodate such cases, we have 
defined  an  additional  attribute  of  the  <seg> 
element,  @nkjp:nps,  where  ?nkjp:?  is  the  non-
TEI  namespace  prefix,  while  ?nps?  stands  for 
?no  preceding  space?  and  its  default  value  is 
?false?.  Naturally,  this  attribute  solves  issues 
specific to Polish and similar languages. It can be 
generalized  and  become  something  like 
@bound={?right?,  ?left?,  ?both?},  and  in  this 
shape, get incorporated into the TEI Guidelines. 
4.2 Structural  disjunction  between  alter-
native segmentations
One strategy to handle alternative segmentations, 
where the choice is between a single segment of 
3Note  that  here,  string-range()  is  an  XPointer  scheme 
defined by the TEI. It is not to be confused with the string-
range() function of the XPointer xpointer() scheme, defined 
by the W3C permanent working draft at http://www.w3.org/
TR/xptr-xpointer/.
66
the form <seg>New York</seg> and a sequence 
of two separate segments, <seg>New</seg> and 
<seg>York</seg>, is to perform radical segmen-
tation (always segment New and York separately) 
and provide an extra layer of alternative segmen-
tation that  may link the two parts  of  the name 
into  a  single  unit.  This  is  what  we  do  in  the 
creation  of  the  annotation  level  of  syntactic 
words that may, e.g., need to link the three seg-
ments of ???to-czerwony above into a single unit, 
because this is how they function in the syntactic 
representation.
In some cases, however, radical segmentation 
may create  false  or  misleading  representations, 
and  Polish  again  provides  numerous  relevant 
examples.  Sometimes  bound segments,  such as 
the person-number clitics illustrated in (2) above, 
are homophonous with parts of words.
(5) a. mia?|em vs. mia?em
had.prt|1sg fines.instr.sg
b. czy|m vs. czym
whether|1sg what.instr
c. gar|?cie vs. gar?cie
pot.acc|2pl fistful.nom.pl
One may attempt to defend radical segmentation 
for  case  (a)  on  the  not-so-innocent  assumption 
that segmenting tools might sometimes reach in-
side  morphological  complexes  and separate  af-
fixes  from stems,  rather  than clitics  from their 
hosts. However, examples (b) and (c) show that 
this is not a feasible approach here: the Instru-
mental  czym in (b) is monomorphemic, and the 
segmentation of  gar?cie ?fistfuls? into  gar- and 
-?cie is  likewise  false,  because  the  putative 
segment division would fall inside the root gar??.
Thus, radical segmentation is not an available 
strategy  in  the  case  at  hand.  What  we  need 
instead  is  a  way  to  express  the  disjunction 
between  a  sequence  such  as  <seg>mia?</seg> 
<seg>em</seg> (cf.  (5a)) on the one hand, and 
the  single  segment  <seg>mia?em</seg>  on  the 
other. It turns out that the TEI has no way of ex-
pressing this kind of relationship structurally.
The  TEI  Guidelines  offer  the  element 
<choice>, but it can only express disjunction bet-
ween  competing  segments,  and  never  between 
sequences thereof. The Guidelines also offer two 
non-structural methods of encoding disjunction. 
The first  uses the element  <join> (which is  an 
ID-based equivalent of a bracket ? it points to the 
segments that are to be virtually joined) and the 
element  <alt>  (which  points  at  encoding  alter-
natives).  The  other  utilizes  the  @exclude  at-
tribute, which, placed in one segment, points at 
elements that are to be ignored if the segment at 
hand  is  valid  (the  excluded  elements,  in  turn, 
point back at the excluding segment).
 Recall that the intended size of the corpus is 
one billion segments. Tools that process corpora 
of this size should not be forced to backtrack or 
look forward to see what forms a sequence and 
what the alternative to this sequence is. Instead, 
we  need  a  simple  structural  statement  of  dis-
junction between sequences.  The solution  used 
by  the  NCP  consists  in  (i)  adding  an  element 
meant to provide a semantically neutral bracket 
(<nkjp:paren>)  and  (ii)  including  <nkjp:paren> 
in the content model of <choice>. Note that this 
representation can be readily converted into the 
pivot format of the LAF:
(6)   <choice>
<seg>mia?em</seg>
<nkjp:paren>
<seg>mia?</seg>
<seg nkjp:nps=?true?>em</seg>
</nkjp:paren>
    </choice>
5 Conclusion
We have presented the TEI-P5-XML architecture 
of the National Corpus of Polish and identified 
some  weak  points  of  the  TEI-based  stand-off 
approach:  the  impossibility  of  keeping  the 
primary text unannotated in the XInclude system, 
the loss of information on segment-boundedness, 
and  the  absence  of  a  structural  statement  of 
disjunction between sequences of segments (this 
last  issue  is  also  due  to  the  lack,  among  the 
numerous detailed markup options provided by 
the  TEI,  of  a  semantically  neutral  bracket-like 
element  whose only role  would be to  embrace 
sequences of elements). 
We are grateful to the two anonymous LAW-
09 reviewers for their helpful comments.
References
Ide, N. and L. Romary. (2007). Towards International 
Standards  for  Language  Resources.  In  Dybkjaer, 
L.,  Hemsen, H., Minker, W. (eds.), Evaluation of 
Text and Speech Systems, Springer, 263-84. 
Przepi?rkowski, A., R. L. G?rski, B. Lewandowska-
Tomaszczyk and M. ?azi?ski. (2008). Towards the 
National  Corpus of Polish.  In  the proceedings of 
the  6th  Language  Resources  and  Evaluation 
Conference (LREC 2008), Marrakesh, Morocco.
TEI Consortium, eds.  2007.  TEI P5:  Guidelines  for 
Electronic Text Encoding and Interchange. Version 
1.2.0.  Last  updated  on  February  1st  2009.  TEI 
Consortium.
67
