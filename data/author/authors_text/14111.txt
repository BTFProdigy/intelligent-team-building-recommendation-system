Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 229?232,
The University of Tokyo, September 24-25, 2010. c?2010 Association for Computational Linguistics
Pamini: A framework for assembling mixed-initiative human-robot
interaction from generic interaction patterns
Julia Peltason and Britta Wrede
Applied Informatics, Faculty of Technology
Bielefeld University, Germany
jpeltaso, bwrede@techfak.uni-bielefeld.de
Abstract
Dialog modeling in robotics suffers from
lack of generalizability, due to the fact
that the dialog is heavily influenced by
the tasks the robot is able to perform.
We introduce interleaving interaction pat-
terns together with a general protocol for
task communication which enables us to
systematically specify the relationship be-
tween dialog structure and task structure.
We argue that this approach meets the re-
quirements of advanced dialog modeling
on robots and at the same time exhibits a
better scalability than existing concepts.
1 Introduction
The need for interaction modeling on robots is
widely acknowledged, not only for instructing
them but also for enabling them to learn from hu-
mans within interaction. Yet, today?s robotic sys-
tems often do not have a dedicated dialog system
but employ simple command-matching techniques
(e.g. (Bo?hme et al, 2003)). Other systems rely
on finite-state based dialog managers (e.g. (Bauer
et al, 2009)) that couple dialog and task man-
agement which hampers maintainability and reuse
and does not scale well for more complex interac-
tion scenarios.
On the other hand, concepts for reusable dialog
frameworks have been established within the spo-
ken dialog community for traditional information-
seeking domains where the system first collects
the required parameters, then presents the desired
information to the user, e.g. an accommodation
or travel information (e.g. (Bohus and Rudnicky,
2009)). However, these concepts are not directly
transferable to robotics, due to the situated nature
of human-robot interaction. A robot perceives the
world and acts on it ? and it is supposed to com-
municate about that. For instance, a robot manip-
Figure 1: The Curious Robot set-up.
ulating objects needs to be able to verbalize its in-
tended actions and give feedback about its internal
state, but it also needs to react on feedback com-
ments or corrections uttered by the human tutor. In
order to equip a robot with such fine-grained com-
munication skills, tight integration of action exe-
cution into interaction is required. In simple terms,
while the dialog frameworks mentioned can be re-
ferred to as information-oriented, we need rather
action-oriented approaches for robotics.
R: What is that? ?points?
H: This is a lemon.
R: A melon. OK.
H: No, I said ?lemon?!
R: A lemon. OK.
R: How should I grasp the lemon?
H: That way. ?demonstrates grip?
R: Alright, with the power grasp.
R: I am going to grasp it ?starts grasping?
R: I start grasping now.
H: Robot, what objects do you know?
R: Lemon.
R: OK, I finished grasping. ?stops grasping?
Table 1: A typical interaction with the Curious Robot.
2 The Pamini framework
This paper presents the Pamini (Pattern-based
mixed-initiative) human-robot interaction frame-
work. Pamini proposes a new approach for dialog
229
modeling on robots that includes (1) a task-state
protocol providing a fine-grained interface to the
complex domain processing of the robotic system
and (2) the concept of generic interaction patterns
that support rapid prototyping of human-robot in-
teractions and can be combined in a flexible way.
Previous versions of the Pamini framework
have been applied in several mixed-initiative
learning scenarios. For example, in the Home-
Tour scenario a mobile robot builds up a spatial
model of its environment and gradually improves
its model by attempting to obtain information from
the human (Peltason et al, 2009). In the Curious
Robot scenario shown in figure 1, an anthropomor-
phic robot learns to label and grasp objects, apply-
ing a proactive dialog strategy that provides guid-
ance for untrained users (Lu?tkebohle et al, 2009).
A dialog excerpt is shown in table 1.
2.1 The task state protocol
A dialog system for robotics needs to coordinate
with a number of components, e.g. for perceptual
analysis, motor control or components generating
nonverbal feedback. To realize this, we use the
concept of tasks that can be performed by com-
ponents. Tasks are described by an execution state
and a task specification containing the information
required for execution. A protocol specifies task
states relevant for coordination and possible tran-
sitions between them as shown in figure 2. Task
updates, i.e. updates of the task state and possi-
bly the task specification, cause event notifications
which are delivered to the participating compo-
nents whereupon they take an appropriate action.
update requested
running
cancel requested
initiated
CANCELLED
DONEfailed
accepted
result_availablerejected cancel_failedcancel
accept, rejectupdate
Figure 2: The task life-cycle. A task gets initiated, ac-
cepted, may be cancelled or updated, may deliver intermedi-
ate results and finally is completed. Alternatively, it can be
rejected by the handling component or execution may fail.
Tight integration with action execution A
robot performing e.g. a grasp action supervised
by the human requires multi-step communication
between the dialog system and the arm control as
illustrated in figure 3. Generally, with the accepted
state, the proposed protocol enables the dialog sys-
tem to provide feedback during slow-going actions
indicating the internal system state. Further, with
the update and result available states, it supports
the modification of the task specification during
execution and thus gives the robot the ability to
react to comments, corrections and commands on-
the-fly.
Arm ControlSpeech recognition Text-to-Speech Dialog
accept Grasp3: 
cancel_failed7: 
complete Grasp9: 
receive (Grasp the apple)1: 
receive (Stop)5: 
initiate Grasp2: say(I am going to grasp the apple.)
4: 
cancel Grasp6: 
say(I can not stop)8: 
say(I finished)10: 
Figure 3: The component communication for a grasp ac-
tion requested by the human. As the dialog manager (DLG)
receives the grasp command, it initiates a grasp task which
is accepted by the arm control. The DLG is notified about
the task state update and acknowledges task execution. As
the human commands cancelling, the DLG sets the task state
cancel. Since the arm control fails to cancel the task, it sets
the task state cancel failed which the DLG reacts on by ex-
pressing an excuse. Finally the task is completed, and the
DLG acknowledges successful task execution.
Mixed-initiative interaction The Pamini dialog
manager offers dialog tasks for other components,
e.g. greeting the human, informing the human
about anything or conversely requesting informa-
tion from the human. While human initiative is re-
alized whenever input from a speech understand-
ing component is received, robot initiative occurs
when a system component requests a dialog task to
be executed. Situation permitting, the dialog man-
ager will accept the dialog task, go into interaction
with the human, and finally complete the dialog
task. Thus, it can react to the system?s and the hu-
man?s initiative using the same task-state protocol
Learning within interaction The task state pro-
tocol supports robotic learning within interaction
by establishing mechanisms for information trans-
fer from the dialog system to the robotic sub-
system. Once information is available from the
human, Pamini augments the task specification
230
with the new information and sets the task state
result available. Since this transition may be
taken multiple times, given information can be
corrected. Also, mixed-initiative enables active
learning, where the learner provokes a situation
providing new information instead of waiting un-
til such situation eventually presents itself.
2.2 Interaction patterns
In an interaction, dialog acts are not unrelated
events, but form coherent sequences. For exam-
ple, a question is usually followed by an answer,
and a request is typically either accepted or re-
jected. Influenced by the concepts of adjacency
pairs (Schegloff and Sacks, 1973), conversation
policies (Winograd, 1986) and software design
patterns, we propose the concept of interaction
patterns that describe recurring dialog structures
on a high level. Interaction patterns can be formal-
ized as transducer augmented with internal state
actions, consisting of
? a set of human dialog acts H and a set of robot dialog
acts R, e.g. H.request or R.assert;
? a set of incoming task events T , e.g. accepted or failed;
? a set of states S representing the interaction state;
? a set of actions A the dialog manager performs, e.g.
initiating or updating a task or reset interaction;
? an input alphabet ? ? (H ? T );
? an output alphabet ? ? R;
? a transition function T : S ? ?? ?? S ?A? ? ??.
By admitting task events as input and internal
actions that perform task initiation and update,
the dialog level is linked with the domain level.
The patterns have been implemented as statecharts
(Harel, 1987), an extended form of finite state ma-
chines, which provides both an executable model
and an understandable graphical representation as
shown in figure 5. For instance, the cancellable
state nameaction, when enteredH.dialog-act / state nameH.dialog-act / R.dialog-act state nametask event / R.dialog-act //
Figure 5: Interaction patterns are represented as transducer
that takes as input human dialog acts and task events and pro-
duces robot dialog acts as output.
action request pattern shown in figure 4 describes
an action request initiated by the human that can
be cancelled during execution. The normal course
of events is that the human requests the action to
be executed, the dialog manager initiates the do-
main task, the responsible system component ac-
cepts execution so that the dialog manager will
assert execution. Finally, the task is completed
and the robot acknowledges. In contrast, the cor-
rectable information request pattern is initiated by
the human. Here, on receiving the respective di-
alog task request, the dialog manager will ask for
the desired information and accept the dialog task.
Once the human provides the answer, the robot
will repeat it as implicit confirmation that can be
corrected if necessary. Table 2 lists all patterns that
have been identified so far.
Initiated by user Initiated by robot
Cancellable action request Self-initiated cancellable action
Simple action request Self-initiated simple action
Information request Correctable information request
Interaction opening Simple information request
Interaction closing Clarification
Interaction restart
System reset
Table 2: Available interaction patterns.
Pattern configuration The patterns themselves
do not determine what kind of task is to be ex-
ecuted or what kind of information to obtain ex-
actly. These specifics are defined by the configu-
ration associated with each pattern, and a concrete
scenario is realized by configuring a set of patterns
using a domain-specific language and registering
them with the dialog manager.
In detail, it needs to be specified for the human?s
dialog acts what kind of (possibly multimodal) in-
put is interpreted as a given dialog act which is
done by formulating conditions over the input. For
the robot?s dialog acts, their surface form needs to
be specified. Up to now, speech output and point-
ing gestures are implemented as output modalities
and can be combined. Moreover, also the task
communication needs to be configured, i.e. the
task specification itself as well as possible task
specification updates. In addition, the developer
can define context variables and use them to pa-
rameterize the robot?s dialog acts and in task spec-
ification updates. This is how e.g. for the robot?s
information request the answer is transferred from
the human to the responsible system component.
Interleaving patterns during interaction Dur-
ing interaction, the registered patterns are em-
ployed in a flexible way by admitting patterns to
be interrupted by other patterns and possibly re-
sumed later which leads to interleaving patterns.
By default, simpler patterns are permitted to be
nested within temporally extended patterns. For
example, it seems reasonable to permit monitoring
questions uttered by the human to be embedded in
the robot?s slow-going grasp execution as shown
231
initiateinitiate-system-task(ShortTerm)stae nemH.d. asserted mimHeloHgm-ogcce/HeR.d.ktgmmeaH
refused 
mimHeloHgm-oaevecHeR.d.ktaenme cancel_requestedupdate-system-task-state(abort)
stcgce.d.
failed mimHeloHgm-ogeR.d.ktg/Proceedings of the SIGDIAL 2011: the 12th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 341?343,
Portland, Oregon, June 17-18, 2011. c?2011 Association for Computational Linguistics
Engagement-based Multi-party Dialog with a Humanoid Robot
David Klotz and Johannes Wienke and Julia Peltason and Britta Wrede and Sebastian Wrede
Applied Informatics Group
Bielefeld University
{dklotz, jwienke, jpeltaso, bwrede, swrede}@techfak.uni-bielefeld.de
Vasil Khalidov and Jean-Marc Odobez
IDIAP Research Institute
{vasil.khalidov, odobez}@idiap.ch
Abstract
When a robot is situated in an environment
containing multiple possible interaction part-
ners, it has to make decisions about when to
engage specific users and how to detect and
react appropriately to actions of the users that
might signal the intention to interact.
In this demonstration we present the integra-
tion of an engagement model in an existing di-
alog system based on interaction patterns. As
a sample scenario, this enables the humanoid
robot Nao to play a quiz game with multiple
participants.
1 Introduction
Giving robotic systems the ability to join in conver-
sation with one or multiple users poses many new
challenges for the development of appropriate dia-
log systems and models. When a dialog system is
situated in the real, physical world and used in more
open settings, more effort needs to be spent on estab-
lishing and maintaining clear communication chan-
nels between the system and its users. E.g. the sys-
tem first needs to detect that there are potential users
with whom interacting would be possible, it needs to
decide if a detected person wants to interact with the
system at all and it needs to make decisions when
and how it should try to start an interaction with that
person.
Bohus and Horvitz (2009) have developed a
model for representing the current relation of a user
with such a system (their engagement state) and de-
termining if they want to be involved in an interac-
tion with the system (using explicit engagement ac-
tions and the more abstract engagement intention).
Each user can be engaged in specific interactions
(denoting different ?basic unit[s] of sustained, in-
teractive problem-solving?) and there can be multi-
ple such interactions, each with potentially different
users.
This demonstration shows how an engagement
model inspired by these ideas was integrated into
an existing dialog system and how it helps in real-
izing interactive scenarios with a robot that incorpo-
rate cues for the dialog from the system?s environ-
ment. Section 3 gives more details about this model
and how it is used by the dialog.
2 Scenario
As a scenario for this demonstration we chose a sim-
ple quiz game involving the robot Nao as a host play-
ing with one or multiple human users. At first, the
robot waits until one of the human interaction part-
ners approaches. When the person opens the interac-
tion (i.e. by greeting the robot), the system responds
with an appropriate greeting. While the person con-
tinues to show the intention to interact with the robot
(determined by the process described in section 3.1),
the robot will ask questions randomly chosen from
a predefined set and will try to judge if the person
answered them correctly.
When another person enters the robot?s field of
view, the system also tries to determine if they have
the intention to interact with it. If that is the case, the
system suspends the current interaction with the first
person and actively tries to engage the second per-
son, encouraging him or her to join the ongoing quiz
game. The prospective new player can then choose
341
Figure 1: Two persons interacting with the developed system.
to join or decline the request.
As long as one of the engaged participants shows
the intention to interact, the robot continues to ask
questions which all participants can try to answer.
The quiz game is stopped either by an explicit re-
quest of one the users or after all participants have
left the scene.
This scenario serves as a good testbed for the in-
tegration of different cues for the engagement model
and how that model affects the actions taken by the
dialog system. The right-hand side of figure 1 shows
two people interacting with the robot during the quiz
game.
3 System Overview
Figure 2 shows an overview of the different com-
ponents involved in the demonstrated system. This
includes components for the perception (e.g. access-
ing images from the robot?s camera and audio from
its microphones), for generating actions (e.g. using
the robot?s text-to-speech system), the dialog system
itself and a memory system for connecting these di-
verse components.
The dialog system used for this demonstration
is called PaMini, which is short for ?Pattern-based
Mixed-Initiative human-robot Interaction? and is
described in more detail by Peltason and Wrede
(2010). This dialog system was modified in Klotz
(2010) with a model of engagement based on the
ideas presented by Bohus and Horvitz (2009). In
our adaptation of this model, there are extension
points for integrating different sources of informa-
tion about the user?s engagement intentions and ac-
tions, described in the following section.
3.1 Determining the User?s Actions &
Intention
For determining the user?s actions (e.g. if the user
explicitly wants to start an interaction with the sys-
tem), this demonstration uses a set of possible utter-
ances which are simply matched against the results
of a speech recognition module.
To get an estimation of the user?s intention to in-
teract, the image from the robot?s camera is first used
to detect the faces of users and to estimate their cur-
rent visual focus of attention. A module based on
a framework by Ba and Odobez (2009) is used to
determine probabilities that the user is looking at
each of a pre-defined list of possible focus targets,
including the robot itself and other users visible in
the scene. The upper left of figure 1 shows a visu-
alization of this module?s output. Nao denotes the
robot as the focus target with the highest probabil-
ity, while the designation UN is short for the ?unfo-
cused? target.
This list of probabilities is then stored in a mem-
342
Figure 2: Components of the developed system.
ory system developed by Wienke and Wrede (2011).
The memory system provides temporal query capa-
bilities which are finally used to guess a user?s cur-
rent intention of interacting with the robot based on
the history of the probabilities that the robot was the
user?s current visual focus of attention target. This
result is also stored in the memory system together
will all other information known about a user.
3.2 Engagement Cues for the Dialog
The dialog system receives the information about the
user?s state and intention from the memory system
and uses it in several rules for controlling its own en-
gagement actions. The intention is e.g. used to deter-
mine if there is a new user that should be persuaded
to join the quiz game described in section 2 and if
any of the users still shows interest so that a new
question should be asked. The general state of the
detected users is also used e.g. to observe when the
users leave the robot?s field of view for a longer pe-
riod of time which causes the dialog system to close
its current interaction.
4 Conclusion
We have shown how an existing dialog system that
was enhanced using an explicit model of engage-
ment can be used to realize interactive scenarios
with a robot that is situated in the physical world.
An estimation of the user?s current visual focus of
attention is used to gauge their intention to engage
the robot in conversation.
A video recording of two people interacting with
the developed system is available online at http:
//youtu.be/pWZLVF2Xa8g
Acknowledgments
This work was done in the HUMAVIPS project,
funded by the European Commission Seventh
Framework Programme, Theme Cognitive Systems
and Robotics, Grant agreement no. 247525.
References
S. Ba and J.-M. Odobez. 2009. Recognizing Visual Fo-
cus of Attention from Head Pose in Natural Meetings.
IEEE Trans. on System, Man and Cybernetics: part B,
Cybernetics, 39:16?34.
Dan Bohus and Eric Horvitz. 2009. Models for multi-
party engagement in open-world dialog. In Proceed-
ings of the SIGDIAL 2009 Conference, pages 225?234,
London, UK. Association for Computational Linguis-
tics.
David Klotz. 2010. Modeling engagement in a multi-
party human-robot dialog. Master?s thesis, Bielefeld
University.
Julia Peltason and Britta Wrede. 2010. Modeling
human-robot interaction based on generic interaction
patterns. In AAAI Fall Symposium: Dialog with
Robots, Arlington, VA, USA.
Johannes Wienke and Sebastian Wrede. 2011. A spatio-
temporal working memory for multi-level data fusion.
In Proc. of IEEE/RSJ International Conference on In-
telligent Robots and Systems. submitted.
343
