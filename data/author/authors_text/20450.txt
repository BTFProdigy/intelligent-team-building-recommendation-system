Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic
Evaluation (SemEval 2013), pages 501?507, Atlanta, Georgia, June 14-15, 2013. c?2013 Association for Computational Linguistics
SSA-UO: Unsupervised Twitter Sentiment Analysis
Reynier Ortega, Adrian Fonseca
CERPAMID, University of Oriente
Ave Patricio Lumumba S/N
Santiago de Cuba, Cuba
Yoan Gutie?rrez
DI, University of Matanzas
Autopista a Varadero Km 312
Matanzas, Cuba
Andre?s Montoyo
DLSI, University of Alicante
Carretera de San Vicente S/N
Alicante,Spain
Abstract
This paper describes the specifications and re-
sults of SSA-UO, unsupervised system, pre-
sented in SemEval 2013 for Sentiment Analy-
sis in Twitter (Task 2) (Wilson et al, 2013).
The proposal system includes three phases:
data preprocessing, contextual word polarity
detection and message classification. The
preprocessing phase comprises treatment of
emoticon, slang terms, lemmatization and
POS-tagging. Word polarity detection is car-
ried out taking into account the sentiment as-
sociated with the context in which it appears.
For this, we use a new contextual sentiment
classification method based on coarse-grained
word sense disambiguation, using WordNet
(Miller, 1995) and a coarse-grained sense in-
ventory (sentiment inventory) built up from
SentiWordNet (Baccianella et al, 2010). Fi-
nally, the overall sentiment is determined us-
ing a rule-based classifier. As it may be ob-
served, the results obtained for Twitter and
SMS sentiment classification are good consid-
ering that our proposal is unsupervised.
1 Introduction
The explosion of Web 2.0 has marked a new age
for the human society. The huge use of Social Me-
dia such as Facebook1 , MySpace2 , LinkedIn3 and
Twitter4 , offers a place for people to share informa-
tion in real time. Twitter is one of the most popular
1https://www.facebook.com
2http://www.myspace.com/
3http://www.linkedin.com
4https://www.twitter.com/
social network websites and has been growing at a
very fast pace. The number of active users exceeds
500 million and the number of tweets posted by day
exceeds 500 million (as of May 2012)5. Through the
twitter applications, users shared opinions about per-
sonalities, politicians, products, companies, events,
etc. This has been attracting the attention of dif-
ferent research communities interested in analyz-
ing its content and motivated many natural language
tasks, such as sentiment analysis, emotions detec-
tion, opinions retrieval, product recommendation or
opinion summarization.
One of the most popular sentiment analysis tasks
is polarity classification. This task is a new field
that classifies opinion texts as positive, negative or
neutral (Pang et al, 2002; Turney, 2002; Esuli and
Sebastiani, 2006; Wilson et al, 2006; Wiegand et
al., 2010). Determining polarity might seem an easy
task, as many words have some polarity by them-
selves. However, words do not always express the
same sentiment, and in most cases the polarity of a
word depends on the context in which the word is
used. So, terms that clearly denote negative feel-
ings can be neutral, or even positive, depending
on their context. Hence, sentiment analysis sys-
tems should include semantic-level analysis in order
to solve word ambiguity and correctly capture the
meaning of each word according to its context. Also,
complex linguistic processing is needed to deal with
problems such as the effect of negations and infor-
mal language. Moreover, understanding the senti-
mental meaning of the different textual units is im-
portant to accurately determine the overall polarity
5http://www.statisticbrain.com/twitter-statistics/
501
of a text.
In this paper, we present a system that has as main
objective to analyze the sentiments of tweets and
classify these as positive, negative or neutral. The
proposal system includes three phases: data prepro-
cessing, contextual word polarity detection and mes-
sage classification. The preprocessing phase com-
prises treatment of emoticons, spell-errors, slang
terms, lemmatization and POS-tagging. Word po-
larity detection is carried out taking into account the
sentiment associated with the context within which
it appears. For this, we use a new contextual senti-
ment classification method based on coarse-grained
word sense disambiguation, using WordNet (Miller,
1995) and a coarse-grained sense inventory (senti-
ment inventory) built up from SentiWordNet (Bac-
cianella et al, 2010). Finally, the polarity is deter-
mined using a rule-based classifier. The paper is
organized as follows. Section 2 describes of SSA-
UO system. In Section 3 we evaluate our proposal
and discuss the results obtained in the SemEval 2013
Task No. 2. Finally, section 4 provides concluding
remarks.
2 SSA-UO System
We use an unsupervised strategy consisting in a
coarse-grained clustering-based word sense disam-
biguation (WSD) method that differentiates positive,
negative, highly positive, highly negative and objec-
tive uses of every word on context which it occurs.
The proposal method uses WordNet and a coarse-
grained sense inventory (sentiment inventory) built
up from SentiWordNet. The overall architecture of
our sentiment classifier is shown in Figure 1.
Firstly, data preprocessing is done to eliminate in-
complete, noisy or inconsistent information. A Sen-
timent Word Sense Disambiguation method (Section
2.3) is then applied to content words (nouns, adjec-
tives, verbs and adverbs). Once all content words
are disambiguated, we apply a rule-based classifier
(Section 2.4) to decide whether the tweet is positive,
negative or neutral.
Unsupervised word sense disambiguation method
proposed by (Anaya-Sa?nchez et al, 2006) was
adapted for sentiment word sense disambiguation.
Unlike the authors, who aim to obtain the correct
sense of a word, we use the method to determine
Figure 1: Overall architecture of Sentiment Classifier
when a word is used with highly positive (HP), posi-
tive (P), highly negative (HN), negative (N) or objec-
tive (O) meaning based on a sentiment sense inven-
tory. We make sentiment sense inventory based on
sense-level annotation in SentiWordNet. Finally, we
apply a rule-based classifier to determine the overall
sentiment in tweet.
2.1 Data Preprocessing
The tweets differ from the text in articles, books, or
even spoken language. It is limited to 140 charac-
ters, also includes many idiosyncratic uses, such as
emoticons, slang terms, misspellings, URLs, ?RT?
for re-tweet, ?@? for user mentions, ?#? for hash-
tags, and character repetitions. Therefore it is nec-
essary to preprocess the text, in order to reduce the
noise information. The preprocessing step involve
the following task. The text is tokenized and URL,
re-tweets and author mentions are removed. Hash-
tag tokens frequently contain relevant information
related to the topic of the tweet, this is included as
part of the text but without the ?#? character. We
replace emoticon tokens by emotion words using
an emoticons dictionary, obtained from Wikipedia
502
6. Each emoticon was manually annotated with an
emotion word and polarity value. Emoticons that
suggest positive emotions - ?:-)?, ?:)?, ?X-D? - are
annotated with the emotion word ?happy? and neg-
ative emoticons - ?:-(?, ?:-c?, ?:,(? - are annotated
with the emotion word ?sad?. The presence of ab-
breviations within a tweet is noted, therefore abbre-
viations are replaced by their meaning (e.g., LOL ?
laughing out loud) using a dictionary7. Finally the
text is POS-tagged and lemmatized using TreeTag-
ger (Schmid, 1994) and stopwords are discarded.
2.2 Sentiment Sense Inventory
We considered SentiWordNet for building senti-
ment coarse-grained sense inventory. SentiWordNet
contain positive, negative and objective scores be-
tween 0 and 1 for all senses in WordNet. Based
on this sense level annotation, we define a new
rule (SentiS) for classifying senses in five sentiment
class. The senses are classified in the following man-
ner (Alexandra et al, 2009): senses whose positive
score is greater than or equal to 0.75 are consid-
ered to be highly positive (HP), senses with posi-
tive score greater than or equal to 0.5 and lower than
0.75 are considered positive (P), senses with nega-
tive score greater than or equal 0.75 are considered
highly negative (HN), whereas those whose negative
score is lower than 0.75 and greater than or equal to
0.5 are considered to be negative (N). In the remain-
ing cases, the senses are considered to be objective
(O) (see equation(1)).
sentiS(s)=
?
???????
???????
HP i f ScoreP(s)? 0.75
HN i f ScoreN(s)? 0.75
P i f ScoreP(s) < 0.75 and ScoreP(s)? 0.5
N i f ScoreN(s) < 0.75 and ScoreN(s)? 0.5
O in other case
(1)
Table 1 summarizes the distribution of the five
sentiment classes once classified all senses of Sen-
tiWordNet.
A notable unbalance can be observed between the
number of highly positive, highly negative, positive,
negative and objective senses.
6http://en.wikipedia.org/wiki/List of emoticons
7http://www.noslang.com/dictionary/
Once all senses were classified in a five sentiment
sense class, we create a coarse sense inventory based
on this classification. This inventory is defined in the
following manner: For each word in SentiWordNet
we grouped its senses with the same sentiment class
in a single sense (coarse-sense), in case of objective
senses these are kept separated.
2.3 Contextual Word Polarity Detection
Much work on sentiment analysis have been di-
rected to determine the polarity of opinion using
anotated lexicons with prior polarity (Hatzivas-
siloglou and McKeown, 1997; Kamps and Marx,
2002; Turney, 2002). However a word can mod-
ify your prior polarity in relation to the context
within which it is invoked. For example the word
?earthquake? is used with negative meaning in the
sentence :
?Selling the company caused an earthquake amount
the employees?.
Whereas it is used in an neutral meaning in the
sentence:
?An earthquake is the result of a sudden release of
energy in the Earth?s crust that creates seismic waves?.
For this reason, our system uses a coarse-grained
WSD method for obtaining the contextual polarity
of all words in tweets. The selected disambigua-
tion method (Anaya-Sa?nchez et al, 2006) was de-
veloped for the traditional WSD task. In this WSD
method, the senses are represented as topic signa-
tures (Lin and Hovy, 2000) built from the repository
of concepts of WordNet. The disambiguation pro-
cess starts from a clustering distribution of all pos-
sible senses of the ambiguous words by applying
the Extended Star clustering algorithm (Gil-Garc??a
et al, 2003). Such a clustering tries to identify co-
hesive groups of word senses, which are assumed
to represent different meanings for the set of words.
Resource HP HN P N O
SWN 310 938 2242 2899 109035
Table 1: Senses highly positive, highly negative, positive,
negative and objective distributions.
503
Then, clusters that match the best with the context
are selected. If the selected clusters disambiguate
all words, the process stops and the senses belong-
ing to the selected clusters are interpreted as the dis-
ambiguating ones. Otherwise, the clustering is per-
formed again (regarding the remaining senses) until
a complete disambiguation is achieved. It does not
distinguish between highly positive, positive, nega-
tive, highly negative or objective meaning of a word.
In this paper, we propose a strategy to built a coarse-
grained sense representation. Firstly, a topic signa-
tures for all senses into WordNet is built and the
topic signatures for coarse-grained senses is the sum
of the topic signatures of the corresponding fine-
grained senses that was grouped.
We explain coarse-grained sense representation
using the following example:
Let us consider the adjective ?sad?. This adjec-
tive has three word senses into WordNet 2.0
sad#a#1 ? experiencing or showing sorrow or unhappiness
sad#a#2 ? of things that make you feel sad
sad#a#3 ? bad; unfortunate
Firstly the topic signature are built for each word
sense:
vector1 = topicSignature(sad#a#1)
vector2 = topicSignature(sad#a#2)
vector3 = topicSignature(sad#a#3)
The senses are classified using equation (1)(in
Section 2.2), sense 1 and 3 were considered as
highly negative, whereas the sense 2 is objective.
The topic signature associated to highly negative
coarse-grained sense is computed as:
topicSignature(sad#a#HN) = sum(vector1+ vector3)
and objective coarse-grained sense is kept as
vector2
topicSignature(sad#a#O) = vector2
2.4 Rule-based Sentiment Classifier
We use a rule-based classifier to classify tweets into
positive, negative or neutral. A polarity value is as-
signed to each word, based on equation 2, after these
were disambiguated. It is necessary to clarify that
emotion words that replaced emoticons in the pre-
processing phase, are not disambiguated. Instead,
we give a prior polarity value equal to 4 if emotion
word is ?happy? and -4 in case that emotion word is
?sad?. It is important to mention that the polarity of
a word is forced into the opposite class if it is pre-
ceded by a valence shifter (obtained from the Negate
category in GI (Stone et al, 1966)).
polarity(w) =
?
???????
???????
4
?4
2
?2
0
i f w is disambiguated as HP
i f w is disambiguated as HN
i f w is disambiguated as P
i f w is disambiguated as N
i f w is disambiguated as O
(2)
The polarity of the tweet is determined from the
scores of positive and negative words it contains. To
sum up, for each tweet the overall positive (PosS(t))
value and overall negative value (NegS(t)) , are com-
puted as:
PosS(t) = ?
wi?WP
polarity(wi) (3)
WP: Words disambiguated as highly positive or
positive in tweet t
NegS(t) = ?
wi?WN
polarity(wi) (4)
WN : Words disambiguated as highly negative or
negative in tweet t
If PosS(t) is greater than NegS(t) then the tweet
is considered as positive. On the contrary, if PosS(t)
is less than NegS(t) the tweet is negative. Finally, if
PosS(t) is equal to NegS(t) the tweet is considered
as neutral.
2.5 A Tweet Sentiment Classification Example
The general operation of the algorithm is illustrated
in the following example:
Let us consider the following tweet:
@JoeyMarchant: I really love Jennifer Aniston :-)
#loving, she is very cooooollll and sexy. I?m married to
her... LOL, http://t.co/2RShsRNSDW
504
After applying the preprocessing phase, we
obtain the following normalized text:
I really love Jennifer Aniston ?happy? loving, she
is very cooll and sexy. I?m married to her... lots of laughs.
When the text is lemmatized and stopwords are
removed, we obtain the following bag of words (for
each word we show: lemma and part-of-speech n-
noun, v-verb, a-adjective, r-adverb and u-unknown):
really#r love#v jennifer#a aniston#n ?happy?#a
loving#a cooll#a sexy#a marry#v lot#n laugh#n.
After contextual word polarity detection, we
obtain the following result (for each word we
shown lemma, part-of-speech and sentiment sense,
HP-highly positive, HN-highly negative, P-positive,
N-negative and O-objective).
really#r#P love#v#P jennifer#a#O aniston#n#O
?happy?#a loving#a#HP cooll#a#O sexy#a#P
marry#v#O lot#n#O laugh#n#P
Once that all words were disambiguated we
obtained their polarities using the equation 2 intro-
duced in section 2.4. We show the polarities values
assigned to each word, in Table 2.
Word POS Sentiment Polarity
really r P 2
love v P 2
jennifer a O 0
aniston n O 0
?happy? a - 4
loving a HP 4
cooll a O 0
sexy a P 2
marry a O 0
lot n O 0
laugh n P 2
Table 2: Polarity assigned to each word
Note that the word ?happy? has not been dis-
ambiguated, its polarity is assigned according
to the emoticon associated in the original tweet.
Afterward we compute overall positive and negative
polarity value:
NegS(t) = 0
PosS(t) = 2+2+4+4+2+2 = 16
Therefore, the tweet t is classified as positive.
3 Results
This section presents the evaluation of our system in
the context of SemEval 2013 Task No.2 Subtask B
(Sentiment Analysis in Twitter). For evaluating the
participant?s systems two unlabeled datasets were
provided, one composed of Twitter messages and
another of SMS messages. For each dataset two
runs can be submitted, the first (constrained), the
system can only be used the provided training data
and other resources such as lexicons. In the second
(unconstrained), the system can use additional data
for training. Our runs are considered as constrained
because SSA-UO only use lexical resources for sen-
timent classification.
Runs Dataset F1 all runs Rank
twitter-1 Twitter 50.17 33(48)
sms-1 SMS 44.39 33 (42)
Table 3: SSA-UO results in polarity classification, all
runs summited
Runs Dataset F1 constrained runs Rank
twitter-1 Twitter 50.17 25 (35)
sms-1 SMS 44.39 22 (28)
Table 4: SSA-UO results in polarity classification, con-
strained runs summited
In Table 3 we summarize the results obtained by
SSA-UO system. As may be observed average F1
measure for Twitter dataset is the 50.17 and 44.39
for the SMS dataset. A total of 48 runs were sub-
mitted by all systems participant?s in Twitter and 42
for SMS dataset. Our runs were ranked 33th for both
datasets.
In Table 4 we compare our results with those runs
that can be considered as constrained. A total of 35
runs for Twitter and 28 for SMS were submitted ,
505
ours runs were ranked in 25th and 22th respectively.
It?s worth mentioning that, the results obtained can
be considered satisfactory, considering the complex-
ity of the task and that our system is unsupervised.
4 Conclusion
In this paper, we have described the SSA-UO system
for Twitter Sentiment Analysis Task at SemEval-
2013. This knowledge driven system relies on unsu-
pervised coarse-grained WSD to obtain the contex-
tual word polarity. We used a rule-based classifier
for determining the polarity of a tweet. The experi-
mental results show that our proposal is accurate for
Twitter sentiment analysis considering that our sys-
tem does not use any corpus for training.
Acknowledgments
This research work has been partially funded by
the Spanish Government through the project TEXT-
MESS 2.0 (TIN2009-13391-C04), ?Ana?lisis de Ten-
dencias Mediante Te?cnicas de Opinio?n Sema?ntica?
(TIN2012-38536-C03-03) and ?Te?cnicas de Decon-
struccio?n en la Tecnolog??as del Lenguaje Humano?
(TIN2012-31224); and by the Valencian Govern-
ment through the project PROMETEO (PROME-
TEO/2009/199).
References
Balahur Alexandra, Steinberger Ralf, Goot Erik van der,
Pouliquen Bruno, and Kabadjov Mijail. 2009. Opin-
ion mining on newspaper quotations. In Proceed-
ings of the 2009 IEEE/WIC/ACM International Joint
Conference on Web Intelligence and Intelligent Agent
Technology - Volume 03, WI-IAT ?09, pages 523?526,
Washington, DC, USA. IEEE Computer Society.
Henry Anaya-Sa?nchez, Aurora Pons-Porrata, and Rafael
Berlanga-Llavori. 2006. Word sense disambiguation
based on word sense clustering. In Proceedings of
the 2nd international joint conference, and Proceed-
ings of the 10th Ibero-American Conference on AI 18th
Brazilian conference on Advances in Artificial Intelli-
gence, IBERAMIA-SBIA?06, pages 472?481, Berlin,
Heidelberg. Springer-Verlag.
Stefano Baccianella, Andrea Esuli, and Fabrizio Sebas-
tiani. 2010. Sentiwordnet 3.0: An enhanced lexi-
cal resource for sentiment analysis and opinion min-
ing. In Nicoletta Calzolari (Conference Chair), Khalid
Choukri, Bente Maegaard, Joseph Mariani, Jan Odijk,
Stelios Piperidis, Mike Rosner, and Daniel Tapias, edi-
tors, Proceedings of the Seventh International Confer-
ence on Language Resources and Evaluation (LREC
?10), Valletta, Malta, may. European Language Re-
sources Association (ELRA).
Andrea Esuli and Fabrizio Sebastiani. 2006. Sentiword-
net: A publicly available lexical resource for opinion
mining. In In Proceedings of the 5th Conference on
Language Resources and Evaluation (LREC?06, pages
417?422.
R. Gil-Garc??a, J. M. Bad??a-Contelles, and A. Pons-
Porrata. 2003. Extended Star Clustering Algorithm.
In CIARP 2003, LNCS, vol. 2905, pages 480?487.
Vasileios Hatzivassiloglou and Kathleen R. McKeown.
1997. Predicting the semantic orientation of adjec-
tives. In Proceedings of the eighth conference on Eu-
ropean chapter of the Association for Computational
Linguistics, EACL ?97, pages 174?181, Stroudsburg,
PA, USA. Association for Computational Linguistics.
Jaap Kamps and Maarten Marx. 2002. Words with atti-
tude. In First International WordNet conference.
Chin-Yew Lin and Eduard Hovy. 2000. The automated
acquisition of topic signatures for text summarization.
In Proceedings of the 18th conference on Computa-
tional linguistics - Volume 1, COLING ?00, pages 495?
501, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.
George A. Miller. 1995. Wordnet: A lexical database for
english. Communications of the ACM, 38:39?41.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up? sentiment classification using ma-
chine learning techniques. In Proceeding of Empirical
Methods in Natural Language Processing, pages 79?
86.
Helmut Schmid. 1994. Probabilistic part-of-speech tag-
ging using decision trees.
Philip J. Stone, Dexter C. Dunphy, Marshall S. Smith,
and Daniel M. Ogilvie. 1966. The General Inquirer:
A Computer Approach to Content Analysis. MIT
Press, Cambridge, MA.
Peter Turney. 2002. Thumbs up or thumbs down? se-
mantic orientation applied to unsupervised classifica-
tion of reviews. pages 417?424.
Michael Wiegand, Alexandra Balahur, Benjamin Roth,
Dietrich Klakow, and Andre?s Montoyo. 2010. A sur-
vey on the role of negation in sentiment analysis. In
Proceedings of the Workshop on Negation and Spec-
ulation in Natural Language Processing, NeSp-NLP
?10, pages 60?68, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Theresa Wilson, Janyce Wiebe, and Rebecca Hwa. 2006.
Recognizing strong and weak opinion clauses. Com-
putational Intelligence, 22:73?99.
506
Theresa Wilson, Zornitsa Kozareva, Preslav Nakov, Sara
Rosenthal, Veselin Stoyanov, and Alan Ritter. 2013.
SemEval-2013 task 2: Sentiment analysis in twitter.
In Proceedings of the International Workshop on Se-
mantic Evaluation, SemEval ?13, June.
507
Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 773?778,
Dublin, Ireland, August 23-24, 2014.
UO UA: Using Latent Semantic Analysis to Build a Domain-Dependent
Sentiment Resource
Reynier Ortega
Adrian Fonseca
Carlos Mu
?
niz
CERPAMID
Ave Patricio Lumumba, S/N
Santigo de Cuba, Cuba
reynier.ortega@cerpamid.co.cu
adrian@cerpamid.co.cu
Yoan Guti
?
errez
Andr
?
es Montoyo
DLSI, University of Alicante
Carretera de San Vicente, S/N
Alicante, Spain
ygutierrez@dlsi.ua.es
montoyo@dlsi.ua.es
Abstract
In this paper we present our contribution to
SemEval-2014 Task 4: Aspect Based Sen-
timent Analysis (Pontiki et al., 2014), Sub-
task 2: Aspect Term Polarity for Laptop
domain. The most outstanding feature in
this contribution is the automatic building
of a domain-depended sentiment resource
using Latent Semantic Analysis. We in-
duce, for each term, two real scores that in-
dicate its use in positive and negative con-
texts in the domain of interest. The aspect
term polarity classification is carried out
in two phases: opinion words extraction
and polarity classification. The opinion
words related with an aspect are obtained
using dependency relations. These rela-
tions are provided by the Stanford Parser
1
.
Finally, the polarity of the feature, in a
given review, is determined from the pos-
itive and negative scores of each word re-
lated to it. The results obtained by our ap-
proach are encouraging if we consider that
the construction of the polarity lexicon is
performed fully automatically.
1 Introduction
Hundreds of millions of people and thousands
of companies around the world, actively use So-
cial Media
2
. Every day are more amazing web-
sites and applications (Facebook, Twitter, MyS-
pace, Amazon, etc.) that allow the easy sharing
of information in near real time. For this rea-
son, at present, the Web is flooded with subjec-
tive, personal and affective data. Mining this huge
This work is licensed under a Creative Commons At-
tribution 4.0 International Licence. Page numbers and pro-
ceedings footer are added by the organisers. Licence details:
http://creativecommons.org/licenses/by/4.0/
1
http://nlp.stanford.edu:8080/parser/
2
http://en.wikipedia.org/wiki/Social media
volume of information offer both interesting chal-
lenges and useful intelligent applications such as
recommendation systems (Dong et al., 2013; Sun
et al., 2009) and customer?s reviews summariza-
tion (Bafna and Toshniwal, 2013; Balahur and
Montoyo, 2008).
Nowadays, companies have redirected their
marketing strategies toward the Web. Each one
of them advertises that their products are the best,
amazing, easy to use, long lasting and cheap. But
are these advertisements really true? Obviously,
not everything is true. The companies usually ex-
aggerate the product?s quality and in many cases
tend not to advertise the limitations of their prod-
ucts. Therefore, taking a rational decision about
which product is the best among the variety of ex-
isting options can be very stressful.
To avoid this situation, frequently we trust in
the experiences gained by others who have pur-
chased the product of our interest, or one similar.
The existence of websites like Ciao
3
, Epinions
4
and Cnet
5
make possible to the customers to inter-
change their experiences about a specific product,
and to future clients avoid products advertising
However, the existence of a large volume of re-
views entails that it is impossible to conduct an
effective exploration before making a final deci-
sion. The most important benefit of having that
amount of user-generated content on hand, specif-
ically product?s reviews, is that, these data can be
explored by a computer system to obtain informa-
tion about products and their features.
The task of aspect-based sentiment analysis
(Liu, 2012) is a fine-grained level of Sentiment
Analysis (Pang and Lee, 2008). This aim to iden-
tify the aspects (e.g., battery, screen, food, ser-
vice, size, weight, time-life) of given target entities
3
www.ciao.com
4
www.epinions.com
5
www.cnet.com
773
(e.g., laptops, restaurants, camera) and the senti-
ment expressed towards each aspect (e.g., positive,
negative, neutral). This are composed by two ba-
sic phases: feature extraction and feature polarity
classification.
In this paper we present our contribution for
SemEval-2014 Task 4: Aspect Based Sentiment
Analysis (Pontiki et al., 2014), Subtask 2: Aspect
Term Polarity. In this approach we only focus on
the polarity classification problem. For this, we
induce a domain-dependent sentiment lexicon ap-
plying Latent Semantic Analysis (LSA) on prod-
uct reviews corpus, gathered from Ciao. The clas-
sification phase is carried out as follow: the opin-
ion words related with the product aspect are draw
out using the dependency relations provided by
Stanford Parser, then the polarity of the extracted
words are combined to obtain overall aspect polar-
ity.
The paper is organized as follows. Section 2 de-
scribes our approach. Further on, in Section 3, we
discuss the results obtained in the SemEval 2014
Task No. 4 subtask 2. Finally, section 4 provides
concluding remarks.
2 UO UA System
One of major challenge in sentiment analysis into
product reviews, is dealing with a quite domain de-
pendence. For instance, the word ?unpredictable?
can be considered as positive in Movie domain,
however it is very negative in Airplane domain.
For this reason, we propose to create a specific
sentiment lexicon for addressing aspect based sen-
timent analysis in reviews.
Our proposal is divided in two main phases. The
first one aims to build a domain-dependent senti-
ment resource for Laptop domain applying LSA.
The second phase obtains the words related by
means of some dependency relation with the as-
pect, and later, the polarity of these words are
obtained from induced polarity lexicon and com-
bined for computing overall aspect polarity.
2.1 Domain-Dependent Polarity Lexicon
The use of sentiment resource has been proven
to be useful to build, train, and evaluate systems
for sentiment analysis (Guti?errez et al., 2013; Bal-
ahur, 2011). In order to build sentiment resource,
several approach has been presented. In one of
the first works, presented by (Hatzivassiloglou and
McKeown, 1997), was proposed to take into ac-
count if adjectives are linked by adversative or
copulative conjunctions for detecting its polarity.
In (Turney and Littman, 2003) the authors exposed
a method for inferring the semantic orientation of
a word from its statistical association with a set
of positive and negative paradigm words, mea-
sured by point-wise mutual information (PMI). In
(2004), Hu and Liu suggested a technique to ex-
pand the lexicon using the relations of synonymy
and antonym provided by WordNet (Fellbaum,
1998). In (2009), Cruz et al., created a sentiment
resource based on a graph, constructed from con-
junctive expressions between pairs of adjectives,
observed in a review corpus. PageRank algorithm
(Page et al., 1999) was adapted to be used on
graphs with positive and negative edges, in order
to obtain the semantic orientation of words.
Despite the wide range of existing proposals
for resources construction, the results achieved
with them are far from expected. As we have
already seen, in aspect based sentiment analy-
sis, the polarity of a word is heavily dependent
on the domain; and general propose sentiment
resource such as General Inquirer (Stone et al.,
1966), WordNet-Affect(Strapparava and Valitutti,
2004), SentiWordNet(Baccianella et al., 2010) or
HowNet (Dong et al., 2010) do not capture this
dependency. On the other hand, the human anno-
tators can not create specific sentiment resources
for each new product launched to market. There-
fore, propose methods to create these resources is
a challenging task.
In this paper we address this task, presenting a
framework for building domain-dependent senti-
ment resource. Our proposal is compounded of
four phases. (See figure 1).
Firstly, review pages about the product of in-
terest can be retrieved from different websites, for
instance, Ciao, Epinions and Cnet (in this work
we only use reviews from Ciao). This reviews
are parsed and cleaned (this time we use Python
XML Parser
6
). For each page we extract: pros,
cons, title, full review and rating. In this work we
have only focus on the pros and cons attributes be-
cause they are usually very brief, consist of short
phrases or sentence segments and give a positive
and negative evaluation about the product aspects.
Each pros and cons in remainder paper will be
considered as positive and negative samples, re-
spectively.
6
https://docs.python.org/2/library/xml.html
774
Figure 1: Building domain-dependent sentiment
resource.
Subsequently, the samples are preprocessed,
applying a POS-Tagging tool (Padr?o and
Stanilovsky, 2012) to convert all words in lem-
mas. After that, the stopwords are removed
from text. Afterward each sample is represented
using the classic vector space model (Salton et
al., 1975). Intending to measure the association
between term and class we add a special term to
the vectors. In positive samples the term t
pos
is
added whereas in the negative samples the term
t
neg
is aggregated.
Later, we apply a Latent Semantic Analysis
(this time we use, Gensim python package) to cal-
culate the strength of the semantic association be-
tween words and classes. LSA uses the Singular
Value Decomposition (SVD) to analyze the statis-
tical relationships among words in a corpus.
The first step is construct a matrix M
n?m
, in
which the row vectors v
i
represent lemmas and the
column vectors s
i
the positive and negative sample
(pros and cons). In each cell t
ij
, we have the TF
score (Term Frequency) of the i
th
lemma in j
th
sample. The next step is apply Singular Value De-
composition to matrix M
n?m
to decompose it into
a product of three matrices U?V
T
, then, we select
the k largest singular values, and their correspond-
ing singular vectors from U and V , obtained an
approximation
?
M = U
k
?
k
V
T
k
of rank k to orig-
inal matrix M
n?m
. After LSA is performed, we
use the new matrix
?
M to measure the association
between lemmas l
i
and l
j
computing the cosine
measure between vectors v
i
and v
j
, with the equa-
tion 1.
LSA
score
(l
i
, l
j
) =
< v
i
, v
j
>
? v
i
? ? ? v
j
?
(1)
Finally, the polarity lexicon contains lemmas
l
i
and its positive and negative scores. This val-
ues are computed using LSA
score
(l
i
, t
pos
) and
LSA
score
(l
i
, t
neg
) respectively. The table 1 show
some top positive and negative words computed
with this strategy.
Positive Score Negative Score
sturdy 0.8249 prone 0.8322
superb 0.7293 weak 0.8189
durable 0.7074 disaster 0.8120
sexy 0.6893 erm 0.8118
powerfull 0.6700 ill 0.8107
robust 0.6686 uncomfortable 0.8084
affordable 0.6630 noisy 0.7917
suuupeerrr 0.6550 overwhelm 0.7514
lighweight 0.6550 unsturdy 0.7491
unbreakable 0.6542 lousy 0.7143
Table 1: Examples of positive and negative words.
With aim to do our contribution to SemEval-
2014, Task 4: Aspect Based Sentiment Analysis
(Pontiki et al., 2014), Subtask 2: Aspect Term Po-
larity, we gathered 3010 Laptop Reviews, from
Ciao and create a corpus with 6020 samples, 3010
positives (Pros) and 3010 negatives (Cons). This
corpus was used as input in the developed frame-
work (See figure 1). In this time we utilize Freel-
ing
7
as POS-Tagging tool and Gensim Python
Packages
8
to perform LSA (only the most 100
most significant eigenvalue are used). After that,
a domain-dependent sentiment resource (DLSR)
with 4482 term was created for Laptop reviews.
2.2 Aspect Polarity Classification
In order to exploit our domain-dependent senti-
ment resource building for Laptop domain, we de-
velop an unsupervised method based on language
rule to classify the product aspect. The basic rules
are used to find dependency relation between as-
pect and their attributes. The figure 2 show the
architecture of our proposal.
The proposed method receive as input a tuple
(P
feature
, R), where P
feature
represent the aspect
to evaluate, and R is the context (review) in it ap-
pears.
7
http://nlp.lsi.upc.edu/freeling/
8
https://pypi.python.org/pypi/gensim
775
Figure 2: Apect polarity classification.
The dependency parsed is applied to review R,
using Stanford Parser. Following that, we extract
a set of tuples W , each tuple is represented as a
pair (Att,Mod) where Att is a word related with
the aspect P
feature
through some dependency re-
lations shown in Table 2, and Mod is a integer
value indicating if Att is modified by a valence
shifter (Polanyi and Zaenen, 2004), (we only con-
sider negation words, e.g., never, no, not, don?t,
nothing, etc.) , and default value of 0 is assign, in
case that, the Att is modified by a valence shifter,
we assign value of -1.
Dependency relations
mod subj nsubj
amod csub csubpass
advmod obj dobj
vmod iobj pobj
rcmod npadvmod nn
subj xcomp advcl
Table 2: Stanford Parser dependency relations.
Once, the set of pairs W was obtained, the po-
larity of the feature P
feature
is determined from
the scores of the attributes (related words) that de-
scribe it. To sum up, for each pair (Att,Mod) ?
W , the positive Pos((Att,Mod)) and negative
Neg((Att,Mod)) scores are calculated as:
Neg((Att,Mod)) =
{
?N(Att) if Mod < 0
N(Att) otherwise
(2)
Pos((Att,Mod)) =
{
?P (Att) if Mod < 0
P (Att) otherwise
(3)
Where P (Att) and N(Att) are the positive and
negative score for Att in domain-dependent senti-
ment resource DLSR.
Finally, the global positive and negative scores
(SO
pos
, SO
neg
) are calculated as:
SO
pos
(P
feature
) =
?
w?W
Pos(w) (4)
SO
neg
(P
feature
) =
?
w?W
Neg(w) (5)
If SO
pos
is greater than SO
neg
then the aspect is
considered as positive. On the contrary, if SO
pos
is less than SO
neg
the aspect is negative. Finally,
if SO
pos
is equal to SO
neg
the aspect is considered
as neutral.
3 Results
In this section we present the evaluation of our
system in the context of SemEval-2014, Task 4:
Aspect Based Sentiment Analysis (Pontiki et al.,
2014), Subtask 2: Aspect Term Polarity. For
evaluating the participant?s system two unlabeled
domain-specific datasets for laptops and restau-
rants were distributed. For each dataset two runs
can be submitted, the first (constrained), the sys-
tem can only be used the provided training data
and other resources such as lexicons. In the sec-
ond (unconstrained), the system can use additional
data for training. We send one run for laptop
dataset and it only use external data retrieved from
Ciao website (the training data was not used) (un-
constrained).
The results achieve by our method are illustrate
in Table 3. As may be observed, the accuracy
Label Pr Rc F1
conflict 0.0 0.0 0.0
negative 0,5234 0,3764 0,4379
neutral 0,4556 0,4074 0,4302
positive 0,6364 0,7561 0,6911
Accuracy 0.55198777
Table 3: Results in aspect polarity classification
for laptop dataset.
achieve by UA OU was 0.55, and F1 measure for
negative, neutral and positive were 0,4379, 0,4302
and 0,6911 respectively. In case of conflict polar-
ity we reached a 0.0 F1 value because our system
not handle this situation. For this subtask (Laptop
domain) a total of 32 runs was submitted by all
776
systems participant?s and our run was ranked as
25
th
. The results despite not achieving expected,
are encouraging. These evidence the feasibility of
building resources from data available on the web,
for aspect-based sentiment analysis.
4 Conclusions
In this article, we presented and evaluated the
approach considered for our participation in
SemEval-2014 Task 4: Aspect Based Sentiment
Analysis (Pontiki et al., 2014), Subtask 2: Aspect
Term Polarity, specifically for Laptop Domain.
We present a framework for building domain-
dependent sentiment resources applying Latent
Semantic Analysis and build a special resource for
polarity classification in Laptop domain. This re-
source was combined into unsupervised method to
compute the polarity associated to different aspect
in reviews. The results obtained by our approach
are encouraging if we consider that the construc-
tion of the polarity lexicon is performed fully au-
tomatically.
Acknowledgements
This research work has been partially funded by
the University of Alicante, Generalitat Valenciana,
Spanish Government and the European Com-
mission through the projects, ?Tratamiento in-
teligente de la informaci?on para la ayuda a la toma
de decisiones? (GRE12-44), ATTOS (TIN2012-
38536-C03-03), LEGOLANG (TIN2012-31224),
SAM (FP7-611312), FIRST (FP7-287607) and
ACOMP/2013/067.
References
Stefano Baccianella, Andrea Esuli, and Fabrizio Se-
bastiani. 2010. SentiWordnet 3.0: An enhanced
lexical resource for sentiment analysis and opinion
mining. Proceedings of the Seventh International
Conference on Language Resources and Evaluation,
LREC ?10, Valletta, Malta, May.
Kushal Bafna and Durga Toshniwal. 2013. Fea-
ture based summarization of customers? reviews
of online products. Procedia Computer Science,
22(0):142 ? 151. 17th International Conference in
Knowledge Based and Intelligent Information and
Engineering Systems - KES2013.
Alexandra Balahur and Andr?es Montoyo. 2008. Mul-
tilingual feature-driven opinion extraction and sum-
marization from customer reviews. In Epaminon-
das Kapetanios, Vijayan Sugumaran, and Myra
Spiliopoulou, editors, Natural Language and Infor-
mation Systems, volume 5039 of Lecture Notes in
Computer Science, pages 345?346. Springer Berlin
Heidelberg.
Alexandra Balahur. 2011. Methods and Resources
for Sentiment Analysis in Multilingual Documents
of Different Text Types. Ph.D. thesis, Department
of Software and Computing Systems. Alcalant, Al-
calant University.
Ferm??n Cruz, Jos?e Antonio Troyano, Francisco Javier
Ortega, and Carlos Garc??a Vallejo. 2009. In-
ducci?on de un lexic?on de opini?on orientado al do-
minio. Procesamiento del Lenguaje Natural, 43:5?
12.
Zhendong Dong, Qiang Dong, and Changling Hao.
2010. HowNet and its computation of meaning. In
Proceedings of the 23rd International Conference on
Computational Linguistics: Demonstrations, COL-
ING?10, pages 53?56, Stroudsburg, PA, USA.
Ruihai Dong, Markus Schaal, Michael P. O?Mahony,
Kevin McCarthy, and Barry Smyth. 2013. Opinion-
ated product recommendation. In Sarah Jane Delany
and Santiago Onta?n?on, editors, Case-Based Rea-
soning Research and Development, volume 7969 of
Lecture Notes in Computer Science, pages 44?58.
Springer Berlin Heidelberg.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. MIT Press.
Yoan Guti?errez, Andy Gonz?alez, Roger P?erez, Jos?e
Abreu, Antonio Fern?andez Orqu??n, Alejandro Mos-
quera, Andr?es Montoyo, Rafael Mu?noz, and Franc
Camara. 2013. UMCC DLSI-(SA): Using a rank-
ing algorithm and informal features to solve senti-
ment analysis in Twitter. Atlanta, Georgia, USA,
page 443.
Vasileios Hatzivassiloglou and Kathleen McKeown.
1997. Predicting the semantic orientation of adjec-
tives. In Proceedings of the Joint ACL/EACL Con-
ference, pages 174?181.
Minqing Hu and Bing Liu. 2004. Mining opinion fea-
tures in customer reviews. In Proceedings of AAAI,
pages 755?760.
Bing Liu. 2012. Sentiment Analysis and Opinion Min-
ing. Synthesis Lectures on Human Language Tech-
nologies, 5(1):1?167.
Llu??s Padr?o and Evgeny Stanilovsky. 2012. Freel-
ing 3.0: Towards wider multilinguality. Proceed-
ings of the Eight International Conference on Lan-
guage Resources and Evaluation (LREC?12), Istan-
bul, Turkey, May. European Language Resources
Association (ELRA).
Lawrence Page, Sergey Brin, Rajeev Motwani, and
Terry Winograd. 1999. The PagerRank Citation
Ranking: Bringing Order to the Web.
777
Bo Pang and Lillian Lee. 2008. Opinion Mining and
Sentiment Analysis.
Livia Polanyi and Annie Zaenen. 2004. Contextual
lexical valence shifters. In Yan Qu, James Shana-
han, and Janyce Wiebe, editors, Proceedings of the
AAAI Spring Symposium on Exploring Attitude and
Affect in Text: Theories and Applications. AAAI
Press. AAAI technical report SS-04-07.
Maria Pontiki, Dimitrios Galanis, John Pavlopou-
los, Harris Papageorgiou, Ion Androutsopoulos, and
Suresh Manandhar. 2014. Semeval-2014 task 4:
Aspect Based Sentiment Analysis. In International
Workshop on Semantic Evaluation (SemEval), 2014.
Gerard Salton, Andrew Wong, and Chung Shu Yang.
1975. A vector space model for automatic indexing.
Communications of the ACM, 18(11):613?620.
Philip James Stone, Dexter Colboyd Dunphy, Marshall
Smith, and Daniel Ogilvie. 1966. The General In-
quirer: A Computer Approach to Content Analysis.
MIT Press, Cambridge, MA.
Carlo Strapparava and Alessandro Valitutti. 2004.
WordNet-Affect: an affective extension of Word-
Net. In In Proceedings of the 4th International
Conference on Language Resources and Evaluation,
LREC, pages 1083?1086, Lisbon, Portugal, May
26-28. European Language Resources Association.
Jianshu Sun, Chong Long, Xiaoyan Zhu, and Minlie
Huang. 2009. Mining reviews for product compar-
ison and recommendation. Polibits, pages 33 ? 40,
06.
Peter Turney and Michael Lederman Littman. 2003.
Measuring praise and criticism: Inference of seman-
tic orientation from association. ACM Transactions
on Information Systems (TOIS), 21(4):315?346.
778
