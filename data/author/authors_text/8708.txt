Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing, pages 217?220,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Designing Special Post-processing Rules for SVM-based
Chinese Word Segmentation
Muhua Zhu, Yilin Wang, Zhenxing Wang, Huizhen Wang, Jingbo Zhu
Natural Language Processing Lab
Northeastern University
No.3-11, Wenhua Road, Shenyang, Liaoning, China, 110004
{zhumh, wangyl, wangzx, wanghz}@ics.neu.edu.cn
zhujingbo@mail.neu.edu.cn
Abstract
We participated in the Third Interna-
tional Chinese Word Segmentation Bake-
off. Specifically, we evaluated our Chi-
nese word segmenter NEUCipSeg in
the close track, on all four corpora,
namely Academis Sinica (AS), City Uni-
versity of Hong Kong (CITYU), Mi-
crosoft Research (MSRA), and Univer-
sity of Pennsylvania/University of Col-
orado (UPENN). Based on Support Vec-
tor Machines (SVMs), a basic segmenter
is designed regarding Chinese word seg-
mentation as a problem of character-based
tagging. Moreover, we proposed post-
processing rules specially taking into ac-
count the properties of results brought
out by the basic segmenter. Our system
achieved good ranks in all four corpora.
1 SVM-based Chinese Word Segmenter
We built out segmentation system following (Xue
and Shen, 2003), regarding Chinese word segmen-
tation as a problem of character-based tagging.
Instead of Maximum Entropy, we utilized Sup-
port Vector Machines as an alternate. SVMs are
a state-of-the-art learning algorithm, owing their
success mainly to the ability in control of general-
ization error upper-bound, and the smooth integra-
tion with kernel methods. See details in (Vapnik,
1995). We adopted svm-light1 as the specific
implementation of the model.
1.1 Problem Formalization
By formalizing Chinese word segmentation into
the problem of character-based tagging, we as-
1http://svmlight.joachims.org/
signed each character to one and only one of the
four classes: word-prefix, word-suffix,
word-stem and single-character. For
example, given a two-word sequence????
??, the Chinese words for ?Southeast Asia(?
??) people(?) ?, the character ???is as-
signed to the category word-prefix, indicating
the beginning of a word;???is assigned to the
category word-stem, indicating the middle po-
sition of a word; ???belongs to the category
word-suffix, meaning the ending of a Chinese
word; and last,???is assigned to the category
single-character, indicating that the single
character itself is a word.
1.2 Feature Templates
We utilized four of the five basic feature templates
suggested in (Low et al , 2005), described as
follows:
? Cn(n = ?2,?1, 0, 1, 2)
? CnCn+ 1(n = ?2,?1, 0, 1)
? Pu(C0)
? T (C?2)T (C?1)T (C0)T (C1)T (C2)
where C refers to a Chinese character. The first
two templates specify a context window with the
size of five characters, where C0 stands for the
current character: the former describes individual
characters and the latter presents bigrams within
the context window. The third template checks
if current character is a punctuation or not, and
the last one encodes characters? type, including
four types: numbers, dates, English letters and
the type representing other characters. See de-
tail description and the example in (Low et al
, 2005). We dropped template C?1C1, since,
217
in experiments, it seemed not to perform well
when incorporated by SVMs. Slightly different
from (Low et al , 2005), character set repre-
senting dates are expanded to include ????
???????????????????,
the Chinese characters for ?day?, ?month?, ?year?,
?hour?,?minute?,?second?, respectively.
2 Post-processing Rules
Segmentation results of SVM-based segmenter
have their particular properties. In respect to the
properties of segmentation results produced by the
SVM-based segmenter, we extracted solely from
training data comprehensive and effective post-
processing rules, which are grouped into two cate-
gories: The rules, termed IV rules, make ef-
forts to fix segmentation errors of character se-
quences, which appear both in training and test-
ing data; Rules seek to recall some OOV(Out
Of Vocabulary) words, termed OOV rules. In
practice, we sampled out a subset from train-
ing dataset as a development set for the analysis
of segmentation results produced by SVM-based
segmenter. Note that, in the following, we defined
Vocabulary to be the collection of words ap-
pearing in training dataset and Segmentation
Unit to be any isolated character sequence as-
sumed to be a valid word by a segmenter. A
segmentation unit can be a correctly seg-
mented word or an incorrectly segmented charac-
ter sequence.
2.1 IV Rules
The following rules are named IV rules, pur-
suing the consistence between segmentation re-
sults and training data. The intuition underlying
the rules is that since training data give somewhat
specific descriptions for most of the words in it, a
character sequence in testing data should be seg-
mented in accordance with training data as much
as possible.
Ahead of post-processing, all words in the
training data are grouped into two distinct sets:
the uniquity set, which consists of words
with unique segmentation in training data and the
ambiguity set, which includes words having
more than one distinct segmentations in training
data. For example, the character sequence???
??has two kinds of segmentations, as?? ?
??(new century) and?????(as a compo-
nent of some Named-Entity, such as the name of a
restaurant).
? For each word in the uniquity set, check
whether it is wrongly segmented into more
than one segmentation units by the SVM-
based segmenter. If true, the continuous seg-
mentation units corresponding to the word
are grouped into the united one. The in-
tuition underlying this post-processing rule
is that SVM-based segmenter prefers two-
character words or single-character words
when confronting the case that the segmenter
has low self-confidence in some character-
sequence segmentation. For example, ??
???(duplicate) was segmented as ??
???and ????(unify) was split
into ?? ??. This phenomenon is
caused by the imbalanced data distribution.
Specifically, characters belonging to category
word-stem are much less than other three
categories.
? For each segmentation unit in the result
produced by SVM-based segmenter, check
whether the unit can be segmented into more
than one IV words and, meanwhile, the words
exist in a successive form for at least once in
training data . If true, replace the segmen-
tation unit with corresponding continuously
existing words. The intuition underlying this
rule is that SVM-based segmenter tends to
combine a word with some suffix, such as
???????, two Chinese characters
representing ?person?. For example, ??
? ??(Person in registration) tends to be
grouped as a single unit.
? For any sequence in the ambiguity set, such
as ?????, check if the correct seg-
mentation can be determined by the con-
text surrounding the sequence. Without los-
ing the generality, in the following explana-
tion, we assume each sequence in the am-
biguity set has two distinct segmentations.
we collected from training data the word
preceding a sequence where each existence
of the sequence has one of its segmenta-
tions, into a collection, named preceding
word set, and, correspondingly, the fol-
lowing word into another set, which is
termed following word set. Analog-
ically, we can produce preceding word
218
set and following word set for an-
other case of segmentation. When an am-
biguous sequence appears in testing data, the
surrounding context (in fact, just one preced-
ing word and a following word) is extracted.
If the context has overlapping with either of
the pre-extracted contexts of the same se-
quence which are from training data, the seg-
mentation corresponding to one of the con-
texts is retained.
? More over, we took a look into the annotation
errors existing in training data. We assume
there unavoidably exist some annotation mis-
takes. For example, in UPENN, the sequence
????(abbreviation for China and Amer-
ica) exists, for eighty-seven times, as a whole
word and only one time, exists as?? ??.
We regarded the segmentation?? ??as
an annotation error. Generally, when the ra-
tio of two kinds of segmentations is greater
than a pre-determined threshold (the value is
set seven in our system), the sequence is re-
moved from the ambiguity set and added as
a word of unique segmentation into the uniq-
uity set.
2.2 OOV Rules
The following rules are termed OOV rules,
since they are utilized to recall some of the
wrongly segmented OOV words. A OOV word
is frequently segmented into two continuous OOV
segmentation units. For example, the OOV
word?????(Vatican) was frequently seg-
mented as ??? ??, where both ??
??and ???are OOV character sequences.
Continuous OOVs present a strong clue of po-
tential segmentation errors. A rule is designed
to merge some of continuous OOVs into a cor-
rect segmentation unit. The designed rule is ap-
plicable to all four corpora. Moreover, since dis-
tinction between different segmentation standards
frequently leads to very different segmentation of
a same OOV words in different corpora, we de-
signed rules particularly for MSRA and UPENN
respectively, to recall more OOVs.
? For two continuous OOVs, check whether
at least one of them is a single-character
word. If true, group the continuous OOVs
into a segmentation unit. The reason for
the constraint of at least one of continuous
OOVs being single-character word is that not
all continuous OOVs should be combined,
for example, ??? ???, both ??
??(Germany merchant) and????(the
company name) are OOVs, but this sequence
is a valid segmentation unit. On the other
hand, we assume appropriately that most of
the cases for character being single-character
word have been covered by training data.
That is, once a single character is a OOV seg-
mentation unit, there exists a segmentation
error with high possibility.
? MSRA has very different segmentation stan-
dard from other three corpora, mainly be-
cause it requires to group several continuous
words together into a Name Entity. For ex-
ample, the word???????(the Min-
istry of Foreign Affairs of China) appear-
ing in MSRA is generally annotated into two
words in other corpora, as????(China)
and?????(the Ministry of Foreign Af-
fairs). In our system, we first gathered all
the words from the training data whose length
are greater than six Chinese characters, filter-
ing out dates and numbers, which was cov-
ered by Finite State Automation as
a pre-processing stage. For each words col-
lected, regard the first two and three charac-
ters as NE prefix, which indicates the be-
ginning of a Name Entity. The collection of
prefixes is termed Sp(refix). Analogously, the
collection Ss(uffix) of suffixes is brought up
in the same way. Obviously not all the pre-
fixes (suffixes) are good indicators for Name
Entities. Partly inheriting from (Brill, 1995),
we applied error-driven learning to filter pre-
fixes in Sp and suffixes in Ss. Specifically,
if a prefix and a suffix are both matched in
a sequence, all the characters between them,
together with the prefix and the suffix, are
merged into a single segmentation unit. The
resulted unit is compared with corresponding
sequence in training data. If they were not ex-
actly matched, the prefix and suffix were re-
moved from collections respectively. Finally
resulted Sp and Ss are utilized to recognize
Name Entities in the initial segmentation re-
sults.
? UPENN has different segmentation standard
from other three corpora in that, for some
219
Corpus R P F ROOV RIV
AS 0.949 0.940 0.944 0.694 0.960
MSRA 0.955 0.956 0.956 0.650 0.966
UPENN 0.940 0.914 0.927 0.634 0.969
CITYU 0.965 0.971 0.968 0.719 0.981
Table 1: Our official SIGHAN bakeoff results
Locations, such as ?????(Beijing
) and Organizations, such as ???
??(the Ministry of Foreign Affairs), the
last Chinese character presents a clue that
the character with high possibility is a suf-
fix of some words. In fact, SVM-based seg-
menter sometimes mistakenly split an OOV
word into a segmentation unit followed by a
suffix. Thus, when some suffixes exist as a
single-character segmentation unit, it should
be grouped with the preceding segmentation
unit. Undoubtedly not all suffixes are appro-
priate to this rule. To gather a clean collec-
tion of suffixes, we first clustered together the
words with the same suffix, filtering accord-
ing to the number of instances in each clus-
ter. Second, the same as above, error-driven
method is utilized to retain effective suffixes.
3 Evaluation Results
We evaluated the Chinese word segmentation
system in the close track, on all four cor-
pora, namely Academis Sinica (AS), City Uni-
versity of Hong Kong (CITYU), Microsoft Re-
search (MSRA), and University of Pennsylva-
nia/University of Colorado (UPENN). The results
are depicted in Table 1, where columns R,P and
F refer to Recall, Precision, F measure
respectively, and ROOV , RIV for the recall of out-
of-vocabulary words and in-vocabulary words.
In addition to final results reported in Bake-
off, we also conducted a series of experiments to
evaluate the contributions of IV rules and OOV
rules. The experimental results are showed in
Table 2, where V1, V2, V3 represent versions
of our segmenters, which compose differently of
components. In detail, V1 represents the basic
SVM-based segmenter; V2 represents the seg-
menter which applied IV rules following SVM-
based segmentation; V3 represents the segmenter
composing of all the components, that is, includ-
ing SVM-based segmenter, IV rules and OOV
rules. Since the OOV ratio is much lower than IV
correspondence, the improvement made by OOV
rules is not so dramatic as IV rules.
Corpus V1 v2 v3
AS 0.932 0.94 0.944
MSRA 0.939 0.954 0.956
UPENN 0.914 0.923 0.927
CITYU 0.955 0.966 0.968
Table 2: Word segmentation accuracy(F Measure)
resulted from post-processing rules
4 Conclusions and future work
We added post-processing rules to SVM-based
segmenter. By doing so, we our segmentation sys-
tem achieved comparable results in the close track,
on all four corpora. But on the other hand, post-
processing rules have the problems of confliction,
which limits the number of rules. We expect to
transform rules into features of SVM-based seg-
menter, thus incorporating information carried by
rules in a more elaborate manner.
Acknowledgements
This research was supported in part by the Na-
tional Natural Science Foundation of China(No.
60473140) and by Program for New Century Ex-
cellent Talents in University(No. NCET-05-0287).
References
Nianwen Xue and Libin Shen. 2003. Chinese Word
segmentation as LMR tagging. In Proceedings of
the Second SIGHAN Workshop on Chinese Lan-
guage Processing,pages 176-179.
Vladimir N. Vapnik. 1995. The Nature of Statistical
Learning Theory. Berlin: Springer-Verlag.
Jin Kiat Low, Hwee Tou Ng and Wenyuan Guo. 2005.
A Maximum Entropy Approach to Chinese Word
Segmentation. In Proceeding of the Fifth SIGHAN
Workshop on Chinese Language Processing, pages
161-164.
Eric.Brill. 1995. Transformation-based error-driven
learning and natural language processing:A case
study in part-of-speech tagging. Computational Lin-
guistics, 21(4):543-565.
220
Which Performs Better on In-Vocabulary Word Segmentation:  
Based on Word or Character? 
Zhenxing Wang1,2, Changning Huang2 and Jingbo Zhu1 
1 Institute of Computer Software and Theory, Northeastern University,  
Shenyang, China, 110004 
2 Microsoft Research Asia, 49, Zhichun Road,  
Haidian District, Beijing, China, 100080 
zxwang@ics.neu.edu.cn 
v-cnh@microsoft.com 
zhujingbo@mail.neu.edu.cn 
 
Abstract* 
Since the first Chinese Word Segmenta-
tion (CWS) Bakeoff on 2003, CWS has 
experienced a prominent flourish be-
cause Bakeoff provides a platform for 
the participants, which helps them rec-
ognize the merits and drawbacks of their 
segmenters. However, the evaluation 
metric of bakeoff is not sufficient 
enough to measure the performance tho-
roughly, sometimes even misleading.  
One typical example caused by this in-
sufficiency is that there is a popular be-
lief existing in the research field that 
segmentation based on word can yield a 
better result than character-based tag-
ging (CT) on in-vocabulary (IV) word 
segmentation even within closed tests of 
Bakeoff. Many efforts were paid to bal-
ance the performance on IV and out-of-
vocabulary (OOV) words by combining 
these two methods according to this be-
lief. In this paper, we provide a more de-
tailed evaluation metric of IV and OOV 
words than Bakeoff to analyze CT me-
thod and combination method, which is 
a typical way to seek such balance. Our 
evaluation metric shows that CT outper-
forms dictionary-based (or so called 
word-based in general) segmentation on 
both IV and OOV words within Bakeoff 
                                               
* The work is done when the first author is working 
in MSRA as an intern. 
closed tests. Furthermore, our analysis 
shows that using confidence measure to 
combine the two segmentation results 
should be under certain limitation. 
1 Introduction 
Chinese Word Segmentation (CWS) has been 
witnessed a prominent progress in the last three 
Bakeoffs (Sproat and Emerson, 2003), (Emer-
son, 2005), (Levow, 2006). One of the reasons 
for this progress is that Bakeoff provides stan-
dard corpora and objective metric, which makes 
the result of each system comparable. Through 
those evaluations researchers can recognize the 
advantage and disadvantage of their methods 
and improve their systems accordingly. Howev-
er, in the evaluation metric of Bakeoff, only the 
overall F measure, precision, recall, IV (in-
vocabulary) recall and OOV (out-of-vocabulary) 
recall are included and such a metric is not suffi-
cient to give a completely measure on the per-
formance, especially when the performance on 
IV and OOV word segmentation need to be eva-
luated. An important issue is that segmentation 
based on which, word or character, can yield the 
better performance on IV words. We give a de-
tailed explanation about this issue as following. 
      Since CWS was firstly treated as a character-
based tagging task (we call it ?CT? for short he-
reafter) in (Xue and Converse, 2002), this me-
thod has been widely accepted and further de-
veloped by researchers (Peng et al, 2004), 
(Tseng et al, 2005), (Low et al, 2005), (Zhao et 
al., 2006). Relatively to dictionary-based 
61
Sixth SIGHAN Workshop on Chinese Language Processing
segmentation (we call it ?DS? for short hereaf-
ter), CT method can achieve a higher accuracy 
on OOV word recognition and a better perfor-
mance of segmentation in whole. Thus, CT has 
drawn more and more attention and became the 
dominant method in the Bakeoff 2005 and 2006.    
  Although CT has shown its merits in word 
segmentation task, some researchers still hold 
the belief that on IV words DS can perform bet-
ter than CT even in the restriction of Bakeoff 
closed test. Consequently, many strategies are 
proposed to balance the IV and OOV perfor-
mance (Goh et al, 2005), (Zhang et al, 2006a). 
Among these strategies, the confidence measure 
used to combine the results of CT and DS is a 
straight-forward one, which is introduced in 
(Zhang et al, 2006a). The basic assumption of 
such combination is that DS method performs 
better on IV words and Zhang derives this belief 
from the fact that DS achieves higher IV recall 
rate as Table 1 shows. In which AS, CityU, 
MSRA and PKU are four corpora used in Ba-
keoff 2005 (also see Table 2 for detail). We pro-
vide a more detailed evaluation metric to ana-
lyze these two methods, including precision and 
F measure of IV and OOV respectively and our 
experiments show that CT outperforms DS on 
both IV and OOV words within Bakeoff closed 
test. The precision and F measure are existing 
metrics and the definitions of them are clear. 
Here we just employ them to evaluate segmenta-
tion results.   Furthermore, our error analysis on 
the results of combination reveals that confi-
dence measure in (Zhang et al, 2006a) has a 
representation flaw and we propose an EIV tag 
method to revise it. Finally, we give an empiri-
cal comparison between existing pure CT me-
thod and combination, which shows that pure 
CT method can produce state-of-the-art results 
on both IV word and overall segmentation.    
Corpus 
RIV ROOV 
DS CT DS CT 
AS 0.982 0.967 0.038 0.647 
CityU 0.989 0.967 0.164 0.736 
MSRA 0.993 0.972 0.048 0.716 
PKU 0.981 0.955 0.408 0.754 
Table 1 IV and OOV recall in  
(Zhang et al,   2006a) 
       The rest of this paper is organized as fol-
lows. In Section 2, we give a brief introduction 
to Zhang?s DS method and subword-based tag-
ging, which is a special CT method. And by 
comparing the results of this special CT method 
and DS according our detailed metric, we show 
that CT performs better on both IV and OOV. 
We review in Section 3 how confidence measure 
works and indicate its representation flaw. Fur-
thermore, an ?EIV? tag method is proposed to 
revise the confidence measure. In Section 4, the 
experimental results of existing pure CT method 
are demonstrated to compare with combination 
result, based on which we discuss the related 
work. In Section 5, we conclude the contribu-
tions of this paper and discuss the future work. 
2 Comparison between DS and CT 
Based on Detailed Metric 
We proposed a detailed evaluation metric for IV 
and OOV word identification in this section and 
experiments based on the new metric show that 
CT outperforms DS not only on OOV words but 
also on IV words with F-measure of IV.  All the 
experiments in this paper conform to the 
constraints of closed test in Bakeoff 2005 
(Emerson, 2005). It means that any resource 
beyond the training corpus is excluded. We first 
review how DS and CT work and then present 
our evaluation metric and experiment results. 
There is one thing should be emphasized, by 
comparing DS and CT result we just want to 
verify that our new metric can show the 
performance on IV words more objectively. 
Since either DS or CT implementation has 
specific setting here we should not extend the 
comparison result to a general sense between 
those generative models and discriminative 
models. 
2.1 Dictionary-based segmentation 
For the dictionary-based word segmentation, we 
collect a dictionary from training corpus first. 
Instead of Maximum Match, trigram language 
model2 trained on training corpus is employed 
for disambiguation. During the disambiguation 
procedure, a beam search decoder is used to seek 
the most possible segmentation. Since the setting 
in our paper is consistent with the closed test of 
                                               
2 Language model used in this paper is SLRIM from 
http://www.speech.sri.com/projects/srilm/ 
62
Sixth SIGHAN Workshop on Chinese Language Processing
Bakeoff, we can only use the information we 
learn from training corpus though other open 
resources may be helpful to improve the perfor-
mance further. For detail, the decoder reads cha-
racters from the input sentence one at a time, 
and generates candidate segmentations incre-
mentally. At each stage, the next incoming cha-
racter is combined with an existing candidate in 
two different ways to generate new candidates: it 
is either appended to the last word in the candi-
date, or taken as the start of a new word. This 
method guarantees exhaustive generation of 
possible segmentations for any input sentence. 
However, the exponential time and space of the 
length of the input sentence are needed for such 
a search and it is always intractable in practice. 
Thus, we use the trigram language model to se-
lect top B (B is a constant predefined before 
search and in our experiment 3 is used) best 
candidates with highest probability at each stage 
so that the search algorithm can work in practice. 
Finally, when the whole sentence has been read, 
the best candidate with the highest probability 
will be selected as the segmentation result.  
Here, the term ?dictionary-based? is exactly the 
method implemented in (Zhang et al, 2006a), it 
does not mean the generative language model in 
general.  
2.2 Character-based tagging  
Under CT scheme, each character in one sen-
tence is labeled as ?B? if it is the beginning of a 
word, ?O? tag means the current character is a 
single-character word, other character is labeled 
as ?I?. For example, ???? (whole China)? is 
labeled as ??  (whole)/O ?  (central)/B ? 
(country)/I?. 
     In (Zhang et al, 2006a), the above CT me-
thod is developed as subword-based tagging. 
First, the most frequent multi-character words 
and all single characters in training corpus are 
collected as subwords. During the subword-
based tagging, a subword is viewed as an unit 
instead of several separate characters and given 
only one tag. For example, in subword-based 
tagging, ???? (whole China)? is labeled as ?
? (whole)/O ?? (China)/O?, if the word ??
? (China)? is collected as a subword. As the 
preprocessing, both training and test corpora are 
segmented by maximum match with subword set 
as dictionary. After this preprocessing, every 
sentence in both training and test corpora be-
comes subword sequence. Finally, the tagger is 
trained by CRFs approach3 on the training data. 
Although word information is integrated into 
this method, it still works in the scheme of 
?IOB? tagging. Thus, we still call subword-
based tagging as a special CT method and in the 
reminder of this paper ?CT? means subword-
based tagging in Zhang?s paper and ?Pure CT? 
means CT without subword. 
2.3 A detailed evaluation metric 
In this paper, data provided by Bakeoff 2005 is 
used in our experiments in order to compare 
with the published results in (Zhang et al, 
2006a).   The statistics of the corpora for Ba-
keoff 2005 are listed in Table 2 (Emerson, 2005). 
Corpus Encoding 
#Training 
words 
#Test 
words 
OOV 
rate 
AS Big5 5.45M 122K 0.043 
CityU Big5 1.46M 41K 0.074 
MSRA GB 2.37M 107K 0.026 
PKU GB 1.1M 104K 0.058 
Table 2 Corpora statistics of Bakeoff 2005 
      Evaluation standard is also provided by Ba-
keoff, including overall precision, recall, F 
measure, IV recall and OOV recall (Sproat and 
Emerson, 2003), (Emerson, 2005). However, 
some important metrics, such as F measure and 
precision of both IV and OOV words are omit-
ted, which are necessary when the performance 
of IV or OOV word identification need to be 
judged. Thus, in order to judge the results of 
each experiment, a more detailed evaluation 
with precision and F measure of both IV and 
OOV words included is used. To calculate the 
IV and OOV precision and recall, we firstly di-
vide words of the segmenter?s output and gold 
data into IV word and OOV word sets respec-
tively with the dictionary collected from the 
training corpus. Then, for IV and OOV word 
sets respectively, the IV (or OOV) recall is the 
proportion of the correctly segmented IV (or 
OOV) word tokens to all IV (or OOV) word to-
kens in the gold data, and IV (or OOV) precision 
is the proportion of the correctly segmented IV 
                                               
3 CRF tagger in this paper  is implemented by CRF++   
downloaded from http://crfpp.sourceforge.net/ 
63
Sixth SIGHAN Workshop on Chinese Language Processing
(or OOV) word tokens to all IV (or OOV) word 
tokens in the segmenter?s output. One thing have 
to be emphasized is that the single character in 
test corpus will be defined as OOV if it does not 
appear in training corpus. We will see later in 
this section, by this evaluation, some facts cov-
ered by the bakeoff evaluation can be illustrated 
by our new evaluation metric.  
     Here, we repeat two experiments described in 
(Zhang et al, 2006a), namely dictionary-based 
approach and subword-based tagging. For CT 
method, top 2000 most frequent multi-character 
words and all single characters in training corpus 
are selected as subwords and the feature tem-
plates used for CRF model is listed in Table 3.  
We present all the segmentation results in Table 
6 to see the strength and weakness of each me-
thod conveniently.     
Based on IV and OOV recall as we show in 
Table 1, Zhang argues that the DS performs bet-
ter on IV word identification while CT performs 
better on OOV words. But we can see from the 
results in Table 6 (the lines about DS and CT), 
the IV precision of DS approach is much lower 
than that of CT on all the four corpora, which 
also causes a lower F measure of IV. The reason 
for low IV precision of DS is that many OOV 
words are segmented into two IV words by DS. 
For example, OOV word ????(choral)? is 
segmented into???(sing) ?(class)? by DS. 
These wrongly identified IV words increase the 
number of all IV words in the segmenter?s out-
put and cause the low IV precision of the DS 
result. Since the F measure of IV is a more rea-
sonable metric of performance of IV than IV 
recall only, Table 6 shows that CT method out-
performs the DS on IV word segmentation over 
all four corpora. The comparison also shows that 
CT outperforms the DS on OOV and overall 
segmentation as well. 
Type Feature Function 
Unigram C-2, C-1, C0, C1, C2 Previous two, current and next two subword 
Bigram C-2 C-1, C-1 C0, C0 C1, C1 C2 Two adjacent subwords  
Jump C-1 C1 Previous character and next subwords 
  Table 3 Feature templates used for CRF in our experiments
3 Balance between IV and OOV Per-
formance 
There are other strategies such as (Goh et al, 
2005) trying to seek balance between IV and 
OOV performance. In (Goh et al 2005), infor-
mation in a dictionary is used in a statistical 
model. In this way, the dictionary-based ap-
proach and the statistical model are combined. 
We choose the confidence measure to study be-
cause it is straight-forward. We show in this sec-
tion that there is a representation flaw in the 
formula of confidence measure in (Zhang et al, 
2006a). And we propose an ?EIV? tag method to 
solve this problem. Our experiments show that 
confidence measure with EIV tag outperforms 
CT and DS alone. 
3.1 Confidence measure 
Confidence Measure (CM) means to seek an 
optimal tradeoff between performance on IV and 
OOV words. The basic idea of CM comes from 
the belief that CT performs better on OOV 
words while DS performs better on IV words. 
When both results of CT and DS are available, 
the CM can be calculated according to the fol-
lowing formula in (Zhang et al, 2006a): 
ngiobwiobiobiob ttwtCMwt ),()1()|()|(CM ??? ???  
Here, w  is a subword, iobt  is ?IOB? tag given 
by CT and 
wt  is ?IOB? tag generated by DS. In 
the first term of the right hand side of the formu-
la, )|( wtCM iobiob  is the marginal probability of 
iobt (we call this marginal probability ?MP? for 
short). And in the second term, 
ngiobw tt ),(?  is a 
Kronecker delta function, returning 1 if and only 
if 
wt  and  iobt  are identical, else returning 0. But 
if 1),( ?ngiobw tt?  , there is no requirement of re-
placement at all. While if 0),( ?ngiobw tt?  , when 
iobw tt ? , CM depends on the first term of its 
right hand side only and ? is unnecessary to be 
set as a weight. Finally, ?  in the formula is a 
weight to seek balance between CT tag and DS 
tag. Another parameter here is a threshold t  for 
the CM. If CM is less than t , wt  replaces iobt as 
64
Sixth SIGHAN Workshop on Chinese Language Processing
the final tag, otherwise 
iobt will be remained as 
the final tag. However, two parameters in the 
CM, namely ?  and t , are unnecessary, because 
when MP is greater than or equal to ?/t , iobt  
will be kept, otherwise it will be replaced with 
wt .  Thus, the CM ultimately is the marginal 
probability of the ?IOB? tag (MP). In the expe-
riment of this paper, MP is used as CM because 
it is equivalent to Zhang?s CM but more conve-
nient to express. 
3.2 Experiments and error analysis about 
combination 
We repeat the experiments about CM in Zhang?s 
paper (Zhang et al, 2006a) and show that there 
is a representation flaw in the CM formula. Fur-
thermore, we propose an EIV tag method to 
make CM yield a better result. 
     In this paper, ? = 0.8 and t = 0.7 (Parameters 
in two papers, Zhang et al 2006a and Zhang et 
al. 2006b, are different. And our parameters are 
consistent with Zhang et al 2006b which is con-
firmed by Dr Zhang through email) are used in 
CM, namely MP= 0.875 is the threshold. Here, 
in Table 4, we provide some statistics on the 
results of CT when MP is less than 0.875. From 
Table 4 we can see that even with MP less than 
0.875, most of the subwords are still tagged cor-
rectly by CT and should not be revised by DS 
result. Besides, lots of the subwords with low 
MP contained by OOV words in test data, espe-
cially for the corpus whose OOV rate is high 
(i.e. on CityU corpus more than one third sub-
words with low MP belong to OOV word) and 
performance on OOV recognition is the advan-
tage of CT rather than that of DS approach. Thus 
when combining the results of the two methods, 
it is the 
iobt should be maintained if the subword 
is contained by an OOV word. Therefore, the 
CM formula seems somewhat unreasonable.  
      The error analysis about how many original 
errors are eliminated and how many new errors 
are introduced by CM is provided in Table 5 (the 
columns about CM). Table 5 illustrates that, af-
ter combining the two results, most original er-
rors on IV words are corrected because DS can 
achieve higher IV recall as described in Zhang?s 
paper. But on OOV part, more new errors are 
introduced by CM and these new errors decrease 
the precision of the IV words. For example, the 
OOV words ????? (guard member)? and ?
??? (design fee)? is recognized correctly by 
CT but with low CM. In the combining proce-
dure, these words are wrongly split as IV errors: 
??? (guard) ?? (member)? and ??? (de-
sign) ?  (fee)?.  Thus, for two corpora (i.e. 
CityU and AS), F measure of IV and overall F 
measure decreases since there are more new er-
rors introduced than original ones eliminated 
and only on the other two corpora (MSRA and 
PKU), overall F measure of combination method 
is higher than CT alone, which is shown in Ta-
ble 6 by the lines about combination. 
3.3 EIV tag method 
Since combining the two results by CM may 
produce an even worse performance in some 
case, it is worthy to study how to use this CM to 
get an enhanced result. Intuitively, if we can 
change only the CT tags of the subwords which 
contained in IV word while keep the CT tags of 
those contained in OOV words unchanged, we 
will improve the final result according to our 
error analysis in Table 5. Unfortunately, only 
from the test data, we can get the information 
whether a subword contained in an IV word, just 
as what we do to get Table 4. However, we can 
get an approximate estimation from DS result. 
When using subwords to re-segment DS result4, 
all the fractions re-segmented out of multiple-
character words, including both multiple-
character words and single characters, will be 
given an ?EIV? tag, which means that the cur-
rent multiple-character word or single character 
is contained in an IV word with high probability. 
For example, ????? (human resource)? in 
DS result is a whole word. However, only ??? 
(resource)? belongs to the subword set, so dur-
ing the re-segmentation ????? (human re-
source)? will be re-segmented as ?? (people) ? 
(force) ?? (resource)?. All these three frac-
tions will be labeled with an ?EIV? tag respec-
tively. It is reasonable because all the multiple-
character words in the DS result can match an 
IV word. After this procedure, when combining 
                                               
4 For the detail, please refer to (Zhang et al, 2006a). 
65
Sixth SIGHAN Workshop on Chinese Language Processing
Corpus AS CityU MSRA PKU 
# subword tokens belong to IV 10010 4404 9552 9619 
# subword tokens belong to IV and tagged correctly by CT 7452 3434 7452 7213 
# subword tokens belong to IV and tagged wrongly by CT 2558 970 2100 2406 
# subword tokens belong to OOV  5924 2524 2685 3580 
# subword tokens belong to OOV and tagged correctly by CT 3177 1656 1725 2208 
# subword tokens belong to OOV and tagged wrongly by CT 2747 868 960 1372 
Table 4 Results of CT when MP is less than 0.875  
Corpus AS CityU MSRA PKU 
Method CM EIV CM EIV CM EIV CM EIV 
#original errors eliminated on IV  1905 1003 904 469 1959 1077 1923 1187 
#original errors eliminated on OOV 755 75 155 80 104 30 230 76 
#original errors eliminated totally 2660 1078 1059 549 2063 1107 2153 1263 
#new errors introduced on IV 441 185 80 50 148 68 211 118 
#new errors introduced on OOV 2487 77 1320 103 1517 57 1681 58 
# new errors introduced totally 2928 262 1400 153 1665 125 1892 176 
Table 5 Error analysis of confidence measure with and without EIV tag 
the two results, only the CT tag with EIV tags 
and low MP will be replaced by DS tag, other-
wise the original CT tag will be maintained. Un-
der this condition the errors introduced by OOV 
will not happen and enhanced results are listed 
in Table 6 lines about EIV. We can see that on 
all four corpora the overall F measure of EIV 
result is higher than that of CT alone, which 
show that our EIV method works well. Now, 
let?s check what changes happened in the num-
ber of error tags after EIV condition added into 
the CM. We can see from the Table 5 columns 
about EIV, there are more errors eliminated than 
the new errors introduced after EIV condition 
added into CM and most CT tags of subwords 
contained in OOV words maintained unchanged 
as we supposed. And then, our results (in Table 
6 lines about EIV) are comparable with that in 
Zhang?s paper. Thus, there may be some similar 
strategies in Zhang?s CM too but not presented 
in Zhang?s paper. 
4  Discussion and Related Works 
Although the method such as confidence meas-
ure can be helpful at some circumstance, our 
experiment shows that pure character-based tag-
ging (pure CT) can work well with reasonable 
features and tag set. In (Zhao et al, 2006), an 
enhanced CRF tag set is proposed to distinguish 
different positions in the multi-character words 
when the word length is less than 6. In this me-
thod, feature templates are almost the same as 
shown in Table 3 with a 3-character window and 
a 6-tag set {B, B2, B3, M, E, O} is used. Here, 
tag B and E stand for the first and the last posi-
tion in a multi-character word, respectively. S 
stands up a single-character word. B2 and B3 
stand for the second and the third position in a 
multi-character word, whose length is larger 
than two-character or three-character. M stands 
for the fourth or more rear position in a multi-
character word, whose length is larger than four-
character. 
     In Table 6, the lines about ?pure CT? provide 
the results generated by pure CT with 6-tag set. 
We can see from the Table 6 this pure CT ap-
proach achieves the state-of-the-art results on all 
the corpora. On three of the four corpora (AS, 
MSRA and PKU) this pure CT method gets the 
best result. Even on IV word, this pure CT ap-
proach outperforms Zhang?s CT method and 
produces comparable results with combination 
with EIV tags, which shows that pure CT me-
thod can perform well on IV words too. Moreo-
ver, this character-based tagging approach is 
more clear and simple than the confidence 
measure method.  
Although character-based tagging became 
mainstream approach in the last two Bakeoffs, it 
does not mean that word information is valueless 
in Chinese word segmentation.  A word-based 
perceptron algorithm is proposed recently 
(Zhang and Clark, 2007), which views Chinese 
word segmentation task from a new angle in-
stead of character-based tagging and gets com-
parable results with the best results of Bakeoff. 
66
Sixth SIGHAN Workshop on Chinese Language Processing
 Corpus Method R P F RIV PIV FIV ROOV POOV FOOV 
AS DS 0.943 0.881 0.911 0.984 0.892 0.935 0.044 0.217 0.076 
CT 0.954 0.938 0.946 0.967 0.960 0.964 0.666 0.606 0.635 
Combination 0.958 0.929 0.943 0.980 0.945 0.962 0.487 0.593 0.535 
EIV tag 0.960 0.942 0.951 0.973 0.962 0.968 0.667 0.624 0.645 
Pure CT 0.958 0.947 0.953 0.971 0.963 0.967 0.682 0.618 0.648 
CityU DS 0.928  0.848 0.886 0.989 0.865 0.923 0.162 0.353 0.223 
CT 0.947 0.940 0.944 0.963 0.964 0.964 0.739 0.717 0.728 
Combination 0.954 0.922 0.938 0.984 0.938 0.961 0.581 0.693 0.632 
EIV tag 0.953 0.949 0.951 0.970 0.968 0.969 0.744 0.750 0.747 
Pure CT 0.947 0.948 0.948 0.967 0.973 0.970 0.692 0.660 0.676 
MSRA DS 0.969 0.927 0.947 0.994 0.930 0.961 0.036 0.358 0.066 
CT 0.963 0.964 0.963 0.970 0.979 0.975 0.698 0.662 0.680 
Combination 0.977 0.961 0.969 0.990 0.970 0.980 0.511 0.653 0.574 
EIV tag 0.972 0.970 0.971 0.980 0.982 0.981 0.696 0.679 0.688 
Pure CT 0.972  0.975 0.973 0.978 0.986 0.982 0.750 0.632 0.686 
PKU DS 0.948 0.911 0.929 0.981 0.920 0.950 0.403 0.711 0.515 
CT 0.944 0.945 0.945 0.955 0.966 0.961 0.763 0.727 0.745 
Combination 0.955 0.942 0.949 0.973 0.953 0.963 0.664 0.782 0.718 
EIV tag 0.950 0.952 0.951 0.961 0.970 0.966 0.768 0.753 0.760 
Pure CT 0.946 0.957 0.951 0.956 0.973 0.964 0.672 0.580 0.623 
           Table 6 Results of different approach used in our experiments (White background lines are 
           the results we repeat Zhang?s methods and they have some trivial difference with Table 1.) 
Therefore, the most important thing worth to pay 
attention in future study is how to integrate lin-
guistic information into the statistical model effec-
tively, no matter character or word information. 
5 Conclusions and Future Work 
In this paper, we first provided a detailed evalua-
tion metric, which provides the necessary infor-
mation to judge the performance of each method 
on IV and OOV word identification. Second, by 
this evaluation metric, we show that character-
based tagging outperforms dictionary-based seg-
mentation not only on OOV words but also on IV 
words within Bakeoff closed tests. Furthermore, 
our experiments show that confidence measure in 
Zhang?s paper has a representation flaw and we 
propose an EIV tag method to revise the combina-
tion. Finally, our experiments show that pure cha-
racter-based approach also can achieve good IV 
word and overall performance. Perhaps, there are 
two reasons that existing combination results 
don?t outperform the pure CT. One is that most 
information contained in statistic language model 
is already captured by the CT feature templates in 
CRF framework. The other is that confidence 
measure may not be the effective way to combine 
the DS and CT results.  
 In the future work, our research will focus on 
how to integrate word information into CRF fea-
tures rather than using it to modify the results of 
CRF tagging. In this way, we can capture the 
word information meanwhile avoid destroying the 
optimal output of CRF tagging. 
Acknowledgement 
The authors appreciate Dr. Hai Zhao in City Uni-
versity of Hong Kong and Dr. Ruiqiang Zhang in 
Spoken Language Communications Lab, ATR, 
Japan providing a lot of help for this paper. Thank 
those reviewers who gave the valuable comment 
to improve this paper. 
References 
Thomas Emerson. 2005. The Second International Chi-
nese Word Segmentation Bakeoff. In Proceedings of the 
Fourth SIGHAN Workshop on Chinese Language 
Processing, pages 123-133, Jeju Island, Korea:  
Chooi-Ling Goh, Masayuku Asahara and Yuji Matsu-
moto. 2005. Chinese Word Segmentatin by Classifi-
cation of Characters. Computational Linguistics and 
67
Sixth SIGHAN Workshop on Chinese Language Processing
Chinese Language Processing, Vol. 10(3): pages 
381-396. 
Gina-Anne Levow. 2006. The Third International Chi-
nese Language Processing Bakeoff: Word Segmen-
tation and Named Entity Recognition. In  Proceed-
ings of the Fifth SIGHAN Workshop on Chinese 
Language Processing , pages 108-117, Sydney: Ju-
ly. 
Jin Kiat Low, Hwee Tou Ng, and Wenyuan Guo. 2005. 
A Maximum Entropy Approach to Chinese Word 
Segmentation. In Proceedings of the Fourth SIGHAN 
Workshop on Chinese Language Processing, pages 161-
164, Jeju Island, Korea. 
Fuchun Peng, Fangfang Feng, and Andrew McCallum. 
2004. Chinese segmentation and new word detection 
using conditional random fields. In COLING 2004, 
pages 562?568. Geneva, Switzerland. 
Richard Sproat and Thomas Emerson. 2003. The First 
International Chinese Word Segmentation Bakeoff. In 
Proceedings of the Second SIGHAN Workshop on Chi-
nese Language Processing, pages 133-143, Sapporo, Ja-
pan: July 11-12,  
Huihsin Tseng, Pichuan Chang et al 2005. A Conditional 
Random Field Word Segmenter for SIGHAN Bakeoff 
2005. In Proceedings of the Fourth SIGHAN Workshop 
on Chinese Language Processing, pages 168-171, Jeju 
Island, Korea. 
Neinwen Xue and Susan P. Converse. 2002. Combin-
ing Classifiers for Chinese Word Segmentation. In 
Proceedings of the First SIGHAN Workshop on 
Chinese Language Processing, pages 63-70, Taipei, 
Taiwan.  
Ruiqiang Zhang, Genichiro Kikui and Eiichiro Sumita. 
2006a. Subword-based Tagging by Conditional 
Random Fields for Chinese Word Segmentation. In 
Proceedings of the Human Language Technology 
Conference of the NAACL, Companion volume, pag-
es 193-196. New York, USA. 
Ruiqiang Zhang, Genichiro Kikui and Eiichiro Sumita. 
2006b. Subword-based Tagging for Confidence-
dependent Chinese Word Segmentaion. In Proceed-
ings of the COLING/ACL, Main Conference Poster 
Sessions, pages 961-968. Sydney, Australia. 
Yue Zhang and Stephen Clark. 2007. Chinese Segmenta-
tion with a Word-Based Perceptron Algorithm. In 
Proceedings of the 45th Annual Meeting of the As-
sociation for Computational Linguistics, pages 840-
847. Prague, Czech Republic.  
Hai Zhao, Changning Huang et al 2006. Effective Tag 
Set Selection in Chinese Word Segmentation via 
Conditional Random Field Modeling. In Proceed-
ings of PACLIC-20. pages 87-94. Wuhan, China, 
Novemeber. 
 
68
Sixth SIGHAN Workshop on Chinese Language Processing
The Character-based CRF Segmenter of MSRA&NEU 
 for the 4th Bakeoff 
Zhenxing Wang1,2, Changning Huang2 and Jingbo Zhu1 
1 Institute of Computer Software and Theory, Northeastern University,  
Shenyang, China, 110004 
2 Microsoft Research Asia, 49, Zhichun Road,  
Haidian District, Beijing, China, 100080 
zxwang@ics.neu.edu.cn 
v-cnh@microsoft.com 
zhujingbo@mail.neu.edu.cn 
 
Abstract 
This paper describes the Chinese Word 
Segmenter for the fourth International 
Chinese Language Processing Bakeoff. 
Base on Conditional Random Field (CRF) 
model, a basic segmenter is designed as a 
problem of character-based tagging.  To 
further improve the performance of our 
segmenter, we employ a word-based ap-
proach to increase the in-vocabulary (IV) 
word recall and a post-processing to in-
crease the out-of-vocabulary (OOV) word 
recall. We participate in the word segmen-
tation closed test on all five corpora and 
our system achieved four second best and 
one the fifth in all the five corpora.  
1 Introduction 
Since Chinese Word Segmentation was firstly 
treated as a character-based tagging task in (Xue 
and Converse, 2002), this method has been widely 
accepted and further developed by researchers 
(Peng et al, 2004), (Tseng et al, 2005), (Low et 
al., 2005), (Zhao et al, 2006). Thus, as a powerful 
sequence tagging model, CRF became the domi-
nant method in the Bakeoff 2006 (Levow, 2006).  
      In this paper, we improve basic segmenter un-
der the CRF work frame in two aspects, namely 
IV and OOV identification respectively. We use 
the result from word-based segmentation to revise 
the CRF output so that we gain a higher IV word 
recall. For the OOV part a post-processing rule is 
proposed to find those OOV words which are 
wrongly segmented into several fractions. Our 
system performs well in the Fourth Bakeoff, 
achieving four second best and on the fifth in all 
the five corpora. In the following of this paper, we 
describe our method in more detail.    
      The rest of this paper is organized as follows. 
In Section 2, we first give a brief review to the 
basic CRF tagging approach and then we propose 
our methods to improve IV and OOV performance 
respectively. In Section 3 we give the experiment 
results on the fourth Bakeoff corpora to show that 
our method is effective to improve the perfor-
mance of the segmenter. In Section 4, we con-
clude our work. 
2 Our Word Segmentation System 
In this section, we describe our system in more 
detail. Our system includes three modules: a basic 
CRF tagger, a word-base segmenter to improve 
the IV recall and a post-processing rule to 
improve the OOV recall. In the following of this 
section, we introduce these three modules 
respectively. 
2.1 Basic CRF tagger 
Sequence tagging approach treat Word Segmenta-
tion task as a labeling problem. Every character in 
input sentences will be given a label which indi-
cates whether this character is a word boundary. 
Our basic CRF1 tagger is almost the same as the 
system described in (Zhao et al, 2006) except we 
add a feature to incorporate word information, 
which is learned from training corpus.  
                                               
1 CRF tagger in this paper  is implemented by CRF++ 
which is downloaded from http://crfpp.sourceforge.net/ 
98
Sixth SIGHAN Workshop on Chinese Language Processing
Type Feature Function 
Unigram C-1, C0, C1 Previous, current and next character 
Bigram C-1 C0, C0 C1 Two adjacent character  
Jump C-1 C1 Previous character and next character 
Word Flag F0 F1 Whether adjacent characters form an IV word 
  Table 1 Feature templates used for CRF in our system 
 Under the CRF tagging scheme, each character 
in one sentence will be given a label by CRF 
model to indicate which position this character 
occupies in a word. In our system, CRF tag set is 
proposed to distinguish different positions in the 
multi-character words when the word length is 
less than 6, namely 6-tag set {B, B2, B3, M, E, 
O}. Here, Tag B and E stand for the first and the 
last position in a multi-character word, respective-
ly. S stands up a single-character word. B2 and B3 
stand for the second and the third position in a 
multi-character word, whose length is larger than 
two-character or three-character. M stands for the 
fourth or more rear position in a multi-character 
word, whose length is larger than four-character. 
      We add a new feature, which also used in 
maximum entropy model for word segmentation 
task by (Low et al, 2005), to the feature templates 
for CRF model while keep the other features same 
as (Zhao et al, 2006). The feature templates are 
defined in table 1. In the feature template, only the 
Word Flag feature needs an explanation. The bi-
nary function F0 = 1 if and only if C-1 C0  form a IV 
word, else F0 = 0 and F1 = 1 if and only if C0 C1 
form a IV word, else F1 = 0.   
2.2 Word based segmenter and revise rules 
For the word-based word segmentation, we collect 
dictionary from training corpus first. Instead of 
Maximum Match, trigram language model 2 
trained on training corpus is employed for disam-
biguation. During the disambiguation procedure, a 
beam search decoder is used to seek the most 
possible segmentation. For detail, the decoder 
reads characters from the input sentence one at a 
time, and generates candidate segmentations in-
crementally. At each stage, the next incoming cha-
racter is combined with an existing candidate in 
two different ways to generate new candidates: it 
is either appended to the last word in the candidate, 
or taken as the start of a new word. This method 
guarantees exhaustive generation of possible seg-
                                               
2 Language model used in this paper is SLRIM down-
loaded from http://www.speech.sri.com/projects/srilm/ 
mentations for any input sentence. However, the 
exponential time and space of the length of the 
input sentence are needed for such a search and it 
is always intractable in practice. Thus, we use the 
trigram language model to select top B (B is a 
constant predefined before search and in our expe-
riment 3 is used) best candidates with highest 
probability at each stage so that the search algo-
rithm can work in practice. Finally, when the 
whole sentence has been read, the best candidate 
with the highest probability will be selected as the 
segmentation result.  
      After we get word-based segmentation result, 
we use it to revise the CRF tagging result similar 
to (Zhang et al, 2006). Since word-based segmen-
tation result also corresponds to a tag sequence 
according to the 6-tag set, we now have two tags 
for each character, word-based tag (WT) and CRF 
tag (CT). Which tag will be kept as the final result 
depends on Marginal Probability (MP) of the CT. 
      Here, we give a short explanation about what 
is the MP of the CT. Suppose there is a sentence 
McccC ...10? , where ic  is the character this sen-
tence containing. CRF model gives this sentence a 
optimal tag sequence 
MtttT ...10? , where it is the 
tag for 
ic . If tti ? and },,,,,{ 32 SEMBBBt ? , 
the MP of 
it is defined as: 
?
? ???
T
ttT
i CTP
CTP
tt i )|(
)|(
)(MP ,
 
Here, )|( CTP is the conditional probability giv-
en by CRF model. For more detail about how to 
calculate this conditional probability, please refer 
to (Lafferty et al, 2001). 
      Assume that the tag assigned to the current 
character is CT by CRF and WT by word-based 
segmenter respectively. The rules under which we 
revise CRF result with word-based result is that if 
MP(CT) of a character is less than a predefined 
threshold and WT is not ?S?, the WT of this cha-
racter will be kept as the final result, else the CT 
of the character will be kept as the final result.  
99
Sixth SIGHAN Workshop on Chinese Language Processing
      The restriction that WT should not be ?S? is 
reasonable because word-based segmentation is 
incapable to recognize the OOV word and always 
segments OOV word into single characters. Be-
sides CRF model is better at dealing with OOV 
word than our word-based segmentation. When 
WT is ?S? it is possible that current word is an 
OOV word and segmented into single character 
wrongly by the word-based segmenter, so the CT 
of the character should be kept under such situa-
tion. For more detail about this analysis please 
refer to (Wang et al, 2008). 
2.3 Post-processing rule  
The rules we described in last subsection is help-
ful to improve the IV word recall and now we in-
troduce our post-processing rule to improve the 
OOV recall.  
      Our post-processing rule is designed to deal 
with one typical type of OOV errors, namely an 
OOV word wrongly segmented into several parts.  
In practice many OOV errors belong to such type. 
      The rule is quite simple. When we read a sen-
tence from the result we get by the last step, we 
also kept the last N sentences in memory, in our 
system we set N equals to 20. We do this because 
adjacent sentences are always relevant and some 
named entity likely occurs repeatedly in these sen-
tences. Then, we scan these sentences to find all 
n-grams (n from 2 to 7) and count their occur-
rence. If certain n-gram appears more than a thre-
shold and this n-gram never appears in training 
corpus, the n-gram will be selected as a word can-
didate. Then, we filter these word candidates ac-
cording to the context entropy (Luo and Song, 
2004). Assume w  is a word candidate appears 
n times in the current sentence and last N sen-
tences and },...,,{ 10 laaa?? is the set of left side 
characters of w . Left Context Entropy (LCE) can 
be defined as: 
?
?
?
?ia i
i waC
nwaCnwLCE ),(log),(
1)(
 
Here, ),( waC i is the count of concurrence of 
ia and w . For the Right Context Entropy, the de-
finition is the same except change left into right. 
Now, we define Context Entropy (CE) of a word 
candidate w as ))(),(min( wRCEwLCE . The 
word candidates with CE larger than a predefined 
threshold will be bind as a whole word in test cor-
pus no matter what tag sequence the segmenter 
giving it. If a shorter n-gram is contained in a 
longer n-gram and both of them satisfy the above 
condition, the shorter n-gram will be overlooked 
and the longer n-gram is bind as a whole word. 
3 Evaluation of Our System 
On the corpora of the Fourth Bakeoff, we evaluate 
our system.  We carry out our evaluation on the 
closed tracks. It means that we do not use any ad-
ditional knowledge beyond the training corpus. 
The thresholds set for MP and CE on each corpus 
are tuned on left-out data of training corpus by 
cross validation. To analyze our methods on IV 
and OOV words, we use a detailed evaluation me-
tric than Bakeoff 2006 (Levow, 2006) which in-
cludes Foov and Fiv. Our results are shown in Ta-
ble 2. In Table 2, the row ?Basic Model? means 
the results produced by our basic CRF tagger, the 
row ?+IV? means the results produced by the 
combination of CRF tagger and word-based seg-
menter and the row ?+IV+OOV? means the result 
we get by executing post-processing rule on the 
combination results. The F measure of the basic 
CRF tagger alone in the Table 2 is within the top 
three in the closed tests except Cityu. Performance 
on Cityu corpus is not so good because the incon-
sistencies existing in Cityu training and test corpo-
ra. In the training corpus the quotation marks are
??while in test corpus quotation marks are??, 
which never apper in the training corpus. As a 
reult, a lot of errors were caused by quotation 
marks. For example, the following four character
????were combined as a one word in our 
result and fragment????was tagged as two 
words?? and ??. Because CRF tagger never 
met ? and ? in training corpus so the tagger 
gave the most common tags, namely B and E to 
the quotation marks, which cause segmentation 
errors not only on quotation marks themselves but 
also on the characters adjacent to them. We 
remove these inconsistencies munually and got 
the F measure 0.5 percentage higer than the rusult 
in table 2. This result is within the top three in the 
closed tests. On all the five corpora, our ?+IV? 
module can increase the Fiv and our ?+OOV? 
module can increase Foov respectively. However, 
these improvements are not significant.  
100
Sixth SIGHAN Workshop on Chinese Language Processing
Corpus Method R P F ROOV POOV FOOV RIV PIV FIV 
CKIP 
Basic Model 0.946 0.923 0.940 0.651 0.719 0.683 0.969 0.948 0.958 
+ IV 0.949 0.935 0.942 0.647 0.741 0.691 0.973 0.948 0.960 
+ IV + OOV 0.950 0.936 0.943 0.656 0.748 0.699 0.973 0.949 0.961 
CityU 
Basic Model 0.944 0.934 0.939 0.654 0.721 0.686 0.970 0.951 0.960 
+ IV 0.946 0.936 0.941 0.655 0.738 0.694 0.972 0.951 0.962 
+ IV + OOV 0.949 0.937 0.943 0.678 0.759 0.716 0.973 0.951 0.962 
CTB 
Basic Model 0.953 0.951 0.952 0.703 0.727 0.715 0.967 0.964 0.965 
+ IV 0.954 0.952 0.953 0.697 0.747 0.721 0.969 0.963 0.966 
+ IV + OOV 0.954 0.953 0.953 0.703 0.749 0.725 0.969 0.964 0.966 
NCC 
Basic Model 0.940 0.928 0.934 0.438 0.580 0.499 0.965 0.940 0.952 
+ IV 0.944 0.930 0.936 0.434 0.603 0.504 0.969 0.941 0.955 
+ IV + OOV 0.945 0.932 0.939 0.450 0.620 0.522 0.970 0.943 0.956 
SXU 
Basic Model 0.960 0.953 0.956 0.636 0.674 0.654 0.977 0.967 0.972 
+ IV 0.962 0.955 0.958 0.637 0.696 0.665 0.980 0.967 0.973 
+ IV + OOV 0.962 0.955 0.959 0.645 0.702 0.673 0.979 0.968 0.974 
Table 2 performance each step of our system achieves 
4 Conclusions and Future Work 
In this paper, we propose a three-stage strategy in 
Chinese Word Segmentation. Based on the results 
produced by basic CRF, our word-based segmen-
tation module and post-processing module are 
designed to improve IV and OOV performance 
respectively. The results above show that our sys-
tem achieves the state-of-the-art performance. 
Since only the CRF tagger is good enough as we 
shown in our experiment, in the future work we 
will pay effort on the semi-supervised learning for 
CRF model in order to mining more useful infor-
mation from training and test corpus for CRF tag-
ger. 
References 
John Lafferty, Andrew McCallum, and Fernando Perei-
ra. 2001. Conditional random fields: probabilistic 
models for segmenting and labeling sequence data. 
In Proceedings of ICML-2001, pages 591?598. 
Gina-Anne Levow. 2006. The Third International Chi-
nese Language Processing Bakeoff: Word Segmen-
tation and Named Entity Recognition. In  Proceed-
ings of the Fifth SIGHAN Workshop on Chinese 
Language Processing , pages 108-117, Sydney: Ju-
ly. 
Jin Kiat Low, Hwee Tou Ng, and Wenyuan Guo. 2005. 
A Maximum Entropy Approach to Chinese Word 
Segmentation. In Proceedings of the Fourth SIGHAN 
Workshop on Chinese Language Processing, pages 161-
164, Jeju Island, Korea. 
Zhiyong Luo, Rou Song, 2004. ?An integrated method 
for Chinese unknown word extraction?, In Proceed-
ings of Third SIGHAN Workshop on Chinese Lan-
guage Processing, pages 148-154. Barcelona, Spain. 
Fuchun Peng, Fangfang Feng, and Andrew McCallum. 
2004. Chinese segmentation and new word detection 
using conditional random fields. In COLING 2004, 
pages 562?568. Geneva, Switzerland. 
Huihsin Tseng, Pichuan Chang et al 2005. A Conditional 
Random Field Word Segmenter for SIGHAN Bakeoff 
2005. In Proceedings of the Fourth SIGHAN Workshop 
on Chinese Language Processing, pages 168-171, Jeju 
Island, Korea. 
Zhenxing Wang, Changning Huang and Jingbo Zhu. 
2008. Which Performs Better on In-Vocabulary 
Word Segmentation: Based on Word or Character? 
In Proceeding of the Sixth Sighan Workshop on 
Chinese Language Processing. To be published.  
Neinwen Xue and Susan P. Converse. 2002. Combin-
ing Classifiers for Chinese Word Segmentation. In 
Proceedings of the First SIGHAN Workshop on 
Chinese Language Processing, pages 63-70, Taipei, 
Taiwan. 
Ruiqiang Zhang, Genichiro Kikui and Eiichiro Sumita. 
2006. Subword-based Tagging by Conditional Ran-
dom Fields for Chinese Word Segmentation. In Pro-
ceedings of the Human Language Technology Con-
ference of the NAACL, Companion volume, pages 
193-196. New York, USA. 
Hai Zhao, Changning Huang et al 2006. Effective Tag 
Set Selection in Chinese Word Segmentation via 
Conditional Random Field Modeling. In Proceed-
ings of PACLIC-20. pages 87-94. Wuhan, China, 
Novemeber. 
 
101
Sixth SIGHAN Workshop on Chinese Language Processing
