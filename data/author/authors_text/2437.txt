Standards going concrete: from LMF to Morphalou
Laurent Romary
Laboratoire Loria-INRIA
B.P. 239
54506 Vand?uvre Les Nancy
France
Laurent.Romary@loria.fr
Susanne Salmon-Alt
ATILF-CNRS
B.P. 30687
54063 Nancy
France
Susanne.Salmon-Alt@atilf.fr
Gil Francopoulo
INRIA-Syntax
B.P. 239
54506 Vandoeuvre Les Nancy,
France
Gil.francopoulo@wanadoo.fr
Abstract
Lexical resources are key components for
applications related to human language technology.
Various models of lexical resources have been
designed and implemented during the last twenty
years and the scientific community has now gained
enough experience to design a common standard at
an international level. This paper thus describes the
ongoing activity within ISO/TC 37/SC 4 on LMF
(Lexical Markup Framework) and shows how it
can be concretely implemented for the design of an
on-line morphological resource for French in the
Morphalou project.
1 Introduction
Lexical resources play a crucial role in most
applications related to human language technology.
They may be used by both human readers and
automatic processors for a wide range of activities
that require an even wider variety of lexical
structures. Some applications may demand broad
linguistic coverage, where the word is the entry
point and all the possible senses are attached to
them, whereas other applications could require a
concept-based organization of the lexical data,
from which the relevant words (or terms) may be
derived. Some applications barely need more then
a simple list of words, whereas other may require a
precise morpho-syntactic, syntactic and semantic
description of the various lexical entries.
Furthermore, the huge cost of creating and
maintaining a lexical resource in any of these
domains requires that they should not be designed
in isolation but that they may potentially be linked
with one another for mutual enrichment.
As a consequence, we believe that there is a
strong need for more widely accepted methods for
specifying lexical structures, so that the conditions
under which the corresponding databases can
exchange data are precisely defined. Moreover, it
seems that enough knowledge has been gathered
across the years to contemplate the idea that such
technical principles and methods could be the
source of an international standard that would
preserve the possibility of both describing various
types of formats and ensuring interoperability
among them.
This paper will present such a methodology as
currently under discussion in the context of ISO
committee TC 37/SC 4 in its on-going project
called LMF (Lexical Markup Framework, which
will become the future ISO 24613 standard). This
international context also provides us with a
unique opportunity to experiment with these most
recent proposals in the context of the concrete
necessity to deploy an open morphological
dictionary for French (the Morphalou project). We
will centre the discussion here on mapping the
modelling principles that have been agreed upon so
far in the LMF project with the actual requirements
associated with the design of a morphological
lexicon, hoping that it may lead to similar activities
on lexical modelling in the future.
2 Standards for lexical resources
Before describing the ongoing standardization
efforts within the LMF project, it is essential to get
an idea of the actual background available to us in
lexical representation at large and see how LMF
may build upon, or rather receive input from, other
past or ongoing standardization activities.
Lexical structures can classically be viewed
according to the way they organize the relation
between words and senses: either senses are
considered as subdivisions of the lexical entry (the
semasiological view of lexical data, which is the
one usually applied in print dictionaries) or on the
contrary, it is assumed that words (or ?terms?) are
described as ways of expressing a priori concepts,
(the onomasiological view).
The onomasiological view has formed the basis
for most previous standardization efforts since it is
at the focus of many applied contexts. This trend
started quite a while ago when the first standards
for thesaurus representation were issued in the
documentary field (ISO 2788 and ISO 5964).
Those standards basically organize lexical matter
as hierarchies of terms (e.g. broader-narrower
terms), with the possibility of adding some basic
lexical information (e.g. equivalences). More
recently, the terminological field has provided
more elaborate standards within ISO committee
TC 37, starting from the definition of an initial
SGML/XML-based  represen ta t ion  for
terminologies (ISO 12200), and progressing on to
the design of a flexible platform for specifying
terminological structures (ISO 16642). The main
problem with the onomasiological view is that
even if it is well suited for providing homogeneous
lexical descriptions within an application domain,
it is hardly extensible when broader linguistic
coverage is required.
In contrast, the semasiological view allows an
exhaustive survey of lexical content for a given
language. In particular, it provides the basis for any
classical editorial (or print) dictionary, but the wide
variety of possible dictionary formats seems to
have hampered the development of international
standards in this domain. The two main initiatives
that can be cited here are on the one hand the ISO
1951 standard dedicated solely to the
representation of dictionary entries, and on the
other hand, the seminal work done within the TEI
1
on print dictionaries, which, even though it has
already been applied to some large scale projects
such as the OED
2
, the Deutsches W?rterbuch
3
 or
the Anglo-Norman dictionary
4
, has never been
considered by publishers in particular as a real
international standard. As a consequence, many
relevant projects such as the TLFi
5
 ( Dendien &
Pierrel, 2003) have designed their own proprietary
structure for the description of their lexical
archives.
If one moves away from classical dictionaries
proper and considers lexical resources dedicated to
the domain of NLP, there are numerous projects
that have worked toward the definition of
standardized lexical structures in the domain of
NLP (Multext for basic morphological lexica;
Genelex, Simple, Isle/Mile for complex
multilingual entries; OLIF 1&2 for translation
lexica, etc.), but none of them has lead to a
standard that reflects a wide international
consensus and that is effectively maintained by an
authoritative body.
From a more theoretical point of view, it has
been shown that such lexical structures can be
modelled as feature structures (Ide et ali, 1995;
Veronis & Ide, 1992), leading to inheritance
properties within entries (Ide et ali, 2000), as
partially implemented in the TEI Print Dictionary
chapter (Ide &Veronis, 1995). It has also been
                                                       
1
 Text Encoding Initiative (http://www.tei-c.or)
2
 http://dictionary.oed.com/
3
 http://www.DWB.uni-trier.de
4
 http://www.mhra.org.uk/
5
 http://www.atilf.fr/_ns/produits/tlfi.htm
shown that, with respect to describing the micro-
structure of such lexica, at least three
configurations are possible: 2-layered, 3-layered
and 7-layered models. In the 2-layered approach,
following Ferdinand de Saussure (1974), a word is
described by a signifier/signified pair, corres-
ponding to a morphological/semantic description.
The syntactic behaviour of the word is then
systematically attached to the semantic description.
This is the approach that has been retained for
LMF. In the 3-layer approach (Antoni-Lay et ali,
1994), a word is described by three units: a
morphological, a syntactic and a semantic unit as
in Genelex or Eagles. It should be noted that due to
the fact that the syntactic unit is a mandatory
connection between morphology and semantics,
such a model is necessarily heavy and complex. In
the 7-layered approach (Mel?cuk et ali, 1995), a
word is described by various units in surface
phonology, deep phonology, surface morphology,
deep morphology, surface syntax, deep syntax and
semantics. This approach imposes a heavy burden
on the lexical description task.
Let us stress here the necessity of guaranteeing
that the methods used to describe onomasiological
and semasiological structures shall not be
completely different, so that it is possible (as
required by industrial applications in particular) to
combine various kinds of lexical resources, but
also to open the way for lexical architectures to
combine concept-based and word-based
descriptions as evidenced in the EDR dictionary
6
,
the Papillon project
7
, or IBM?s TransLexis
resource.
3 The Lexical Markup Framework project
The LMF proposal, as currently being developed
in ISO committee TC 37/SC 4, is conceived as a
generic platform for the specification of lexical
structures at any level of linguistic description. As
such, it does not provide one single model, but
rather a mechanism by which implementers com-
bine elementary lexical subsystems to design
models that can be both as close as possible to their
needs and comparable to any other lexical models
based on the same principles and, possibly, on the
same components.
The underlying data model for LMF follows the
general principles of the linguistic annotation
scheme design stated in Ide & Romary, 2003 and
implemented in the context of ISO standard 16642
for the representation of terminological data
(Romary, 2001). Those principles provide a
mechanism for combining a given structural
                                                       
6
 http://www2.crl.go.jp/kk/e416/EDR/index.html
7
 http://www.papillon-dictionary.org/
metamodel that informs the general organization of
a certain level of linguistic information (morpho-
logy, syntax, etc.) with elementary descriptors (so-
called data categories). Data categories reflect
basic linguistic concepts (e.g. /part of speech/,
/grammatical  number/, /paucal number/, etc.) and
allow for recording language-specific properties
independently of linguistic level specific models.
In order to share data categories within the
community, on-going work (in ISO/TC 37) is in
the process of deploying an on-line registry
8
 of
them, especially for use in conjunction with the
other standardization activities.
According to these principles, LMF consists of
the following elements:
? a core metamodel (i.e. the structural skeleton
shared by any linguistic description at the
lexical level);
? mechanisms for attaching lexical extensions
(see below) to the core metamodel in order to
build up more complex metamodels;
? mechanisms for selecting data categories used
for lexical description and for determining how
they relate to a metamodel;
? mechanisms for expressing any combination of
the core metamodel and data categories as
XML structures, i.e. by deciding to implement
a given data category (/gender/) as an XML
element rather than as an attribute and by
providing the corresponding vocabularies
(?gen?, ?gender?, ?genre?);
? methods for describing how to extend LMF to
analyze, design, and describe a variety of more
specific lexical resources.
As shown in Figure 1, the core metamodel of
LMF is organized as a purely hierarchical structure
built upon the following components:
The Lexical database component gathers up all
information related to a given lexicon;
The Global information component groups
together all the metadata  (e.g. version,
contributors, up-date, etc.) that can be globally
attached to the lexicon (see 4.4);
The Lexical entry component comprises the
elementary lexical unit in a lexical database. This
component can, of course, be iterated, but no
specific constraint is expressed as to  its level of
granularity in a lexical database (e.g. proper
treatment of homonyms), since this depends highly
on languages and local editorial practices;
The Form component groups together all the
general graphical or phonetic descriptions attached
to the lexical entry (reference orthographic form,
transliteration, hyphenation, pronunciation, etc.);
                                                       
8
 An experimental on-line data category registry is
accessible under http://syntax.loria.fr
Finally, the Sense component is the one that
actually organizes the lexical entry since it can be
both repeated and further subdivided into senses.
In a word-to-sense lexical structure, it is indeed
thought that this central way of organizing a lexical
entry should be part of the metamodel.
Lexical DB
1..1
Global Info
1..1
Lexical Entry
0..n
1..1
1..1
Form
1..1
Sense
0..n
1..1
0..n
1..1
Lexical
extensions
Lexical
extension
Lexical
extension
Figure 1: Core model and lexical extensions in LMF
In order to specify more complex models than
would be expressible with just the core metamodel,
LMF introduces the notion of lexical extensions.
Those extensions correspond to clusters of com-
ponents dedicated to the representation of a
specific type of lexical information (e.g. morpho-
logy, syntactic constructions, transfer patterns
(socalled interlingua), and theory dependant lexi-
cographical approaches such as Mel?cuk et al
1995 or V?ronis, 2000). Each lexical extension is
characterized by an anchor component, which is
either a component of the core metamodel or of
another lexical extension when more complex
combinations are being considered (e.g. descrip-
tion of morphological operations used to extend a
simple morphological lexical extension).
The future LMF standard as such should not
provide a specific list of data categories to be used
for lexical descriptions. This would by far be too
complex given, as we have seen, the potential
variety of applications. It is thus expected that
implementers will systematically refer to the
ISO/TC 37 data category registry to find the
adequate descriptive background for their own
purposes. Still, we can outline the basic types of
data categories that one could encounter in an LMF
based application, namely:
? data categories that may be considered as
rather specific to the domain of lexical
description: these are typically those attached
to the Form component (/pronunciation/,
/syllabification/, /stress pattern/ etc.) or to the
Sense component (e.g. /definition/, /example/,
/etymology/, etc.). Some of these categories
have already been partially described in the
?old? ISO 12620:1999 standard, but a more
precise list should be compiled as the work on
LMF is being completed;
? data categories that relate to a specific level of
linguistic description such as morphology, syn-
tax, etc. The strategy here is to avoid defining
ad hoc descriptors dedicated to lexical struc-
tures and to enforce coherence with other stan-
dardization activities by adopting those asso-
ciated with the development of related stan-
dards. For instance, data categories such as
/grammatical category/, /grammatical gender/
or /grammatical case/ should be shared
between POS tagging applications and corres-
ponding lexical descriptions;
? data categories corresponding to metadata des-
criptors used to document the production and
maintenance of a lexical database, a lexical
entry and probably, of any component in a
lexical structure (see 4.4).
To conclude this brief presentation of LMF,
which can only be considered to be a snapshot of
the ongoing discussions about it, it is important to
consider how it provides a whole standardization
spectrum for implementers who will want to apply
it for their own purposes. At a first level, they can
limit themselves to the core model, to standardized
lexical extensions and to the data categories that
are available in the DCR. Doing so, they will have
the certainty of being fully interoperable with any
other implementation that has adopted the same
scope. If necessary, it is possible for implementers
to define some proprietary data categories or
maybe their own lexical extensions, knowing that
the corresponding part of their lexical model will
probably require more work if they wants to
interchange data with other applications. Still, such
a strategy is probably the optimal one in the
current stage of LMF, since, for instance, we do
not know yet which lexical extensions will be
sufficiently consensual to be further adopted as
international standards. This is indeed the spirit in
which the Morphalou project has been established,
i.e. to design a simple morphological lexical
extension to the LMF core principles and see how
it could be validated when confronted with the real
development of a lexical resource. In the long run,
we do expect that some combinations of the core
metamodel and some standardized lexical
extensions may also be seen as possible future
standards when they match specific industrial
needs (e.g. transfer lexica ? la OLIF) or existing
practices (e.g. TEI Print Dictionary format).
4 An LMF-based model for a morphological
lexicon
4.1 Requirements for a morphological lexicon
Morphological dictionaries typically associate
inflected word forms (for example plural nouns or
past tense verb forms) with values for relevant
morphological features, such as gender and num-
ber for adjectives or person and tense for verbs. In
addition, there is often a link to one particular word
form, conventionally chosen as being the lemma.
Those dictionaries are basic resources in the field
of NLP (needed for any application based on
tagged and/or lemmatized input data) and in the
field of computer-assisted language acquisition.
Most existing morphological resources for NLP
(MulText, V?ronis 1999; LEFFF
9
, Cl?ment &
Sagot) occur as text files, whose lines display the
inflected word form, one or more morphological
tags (relative to a given tag-set) and the lemma.
This kind of representation, directly inspired by
one specific type of usage of such resources (i.e.
morphological tagging) takes the inflected form as
an entry point. At the same time, the
morphological point of view is an extensional one,
in the sense that the resource explicitly contains the
list of all inflected forms for one lemma.
Furthermore, the linguistic concepts underlying the
morphological description are not directly
transparent and accessible, since the tags are
generally synthetic tags for a set of values relative
to a set of relevant features. Finally, if any
metadata (such as the contributor or the last up-
date) are associated with such a resource, they are
often encoded in proprietary formats and there is
no possibility to parameterize their scope to
various description levels of the lexicon.
Starting from these observations, we tested LMF
as a formal framework for the design of a
morphological dictionary for French, based on
existing data originally compiled during the
digitization of a wide coverage French dictionary
(TFLi). From a theoretical point of view, the aim
of this experiment is to test the suitability of LMF
at a quite simple level of lexical description. On
the practical side, we wish to generate a resource
that is accessible on-line and that implements the
standardization proposals of ISO/TC 37/SC 4, and
that is application-independent, well documented,
extensible and provides the possibility to add
further lexical description levels, such as syntactic
and semantic information. Therefore, we have tried
to overcome the aforementioned shortcomings of
current morphological dictionaries by structuring
the data around lemmas rather than around
inflected forms, by proposing a data model that
combines the co-occurrence of extensional and
intensional morphological information (lists of
inflexions vs. reference to inflexion classes or
paradigms) and by paying special attention to the
issue of the metadata necessary to qualify the
identification of the source data (origin,
contributor, up-date, etc.) and the status of the data
(validated by an editorial committee, testified in a
corpus, etc.).
                                                       
9
 http://atoll.inria.fr/~lclement/lefff/
4.2 The lexical model of Morphalou
The underlying lexical model of the Morphalou
project is a direct application of the LMF prince-
ples with the sole addendum of a simple lexical
extension dedicated to the description of morpho-
logy. This extension can be directly linked to the
lexical entry component of the core metamodel. It
associates a single morphological description
(Morphology component) to each lexical entry.
This morphological description is made up of two
sub-components:
? a Paradigm  component that refers to or
possibly describes the inflexion rules that
govern the flexional behaviour of the entry;
? an Inflexion component that groups together
zero up to n  inflected forms related to the
lexical entry.
 
Lexical 
Entry 
Morphology 
1..1 
1..1 
Lexical Entry 
or gy 
0..1 
Paradigm 
1..1 
Inflexion 
0..n 
1..1 
Figure 2: Lexical extension for morphology
As stated in section 3, to build up a full model
for a concrete lexical database, one needs to
associate a selection of data categories anchored at
the different components of the metamodel (core
metamodel + morphological lexical extension).
To the Lexical entry component, we basically
associate to this component the data categories
/lemma/ and /grammatical category/. A /key form/
is used in order to uniquely identify the entry
within the lexical database. Possible orthographic
variants may be recorded as /spelling variant/?s.
Finally, depending on editorial choices, one could
also decide to attach /gender/ information here, for
example for nouns, in the case that gender
variation is not considered as inflexional variation,
as opposed to adjectives.
To the Inflexion component: beside /word form/,
which identifies the actual inflected form in the
component, it is necessary to associate the set of
morphological features to provide a unique
specification of the inflexion. The corresponding
data categories are complementary to the general
grammatical category of the entry: /gender/ and
/number/ for adjectives; /tense/, /person/, /number/
and /mood/ for verbs, etc. Appendix 1 provides a
complete list of the data categories we have
considered for the first version of the database;
? Paradigm component: here we essentially need
a /paradigm identifier/ to identify the inflexion
class to which the lexical entry belongs. In
order to integrate further data categories for the
description of the inflexion rules, we still need
to investigate linguistic practices for different
language families.
4.3 Implementing the model: basic examples
 Example 1 implements, in a generic XML
format (GMT, see Romary 2001), a simple lexical
entry and its morphological extension for the
French noun chat (?cat?). The data categories
associated with the lexical entry are /lemma/,
/grammatical category/ and /key form/,
respectively taking the values of chat, noun and
chat_1. The morphology component contains the
identification of the plural inflexion paradigm for
regular French nouns (/fr-s-plural/) and the
complete list of inflected word forms with
associated morphological features, i.e. /number/.
Example 1
<struct type=?lexical entry?>
<feat type=?lemma?>chat</feat>
<feat type=?grammatical category?>common
noun </feat>
<feat type=?key form?>chat_1</feat>
<struct type=?morphology?>
<struct type=?paradigm?>
<feat type=?paradigm identifier?>
fr-s-plural</feat>
</struct>
<struct type=?inflexion?>
<feat type=?word form?>chat</feat>
<feat type=?number?>singular</feat>
</struct>
<struct type=?inflexion?>
<feat type=?word form?>chats</feat>
<feat type=?number?>plural</feat>
</struct>
</struct>
</struct>
In the case that spelling variants exist such as
cheik vs. cheikh (Example 2), these are referred to
in the lexical entry component by means of the
data category /spelling variant/ and an associated
pointer to the /key form/ of the related lexical
entry. Additional mechanisms such as unification
may be envisaged in order to avoid duplication of
the lexical information that is independent from
this variation (syntactic or semantic information,
for example).
Example 2
<struct type=?lexical entry?>
<feat type=?lemma?>cheikh</feat>
<feat type=?spelling variant?
 target=?#cheik_noun?</feat>
<feat type=?grammatical category?>
common noun</feat>
<feat type=?key form?>cheikh_1</feat>
<struct type=?morphology?>
?
</struct>
</struct>
Example 3 to Example 5 ? afghan, ?afghani?,
used as masculine and feminine noun and as an
adjective ?  shows how data categories, here
/gender/, can be used in a flexible way. Depending
on editorial practices, the implementers may, for
example, chose to attach this feature to the lexical
entry for nouns, and to the inflexion component for
adjectives. They will thus consider masculine and
feminine forms of a noun as different lexical
entries (afghan_1 vs. afghane), while grouping
variations for adjectives into one single gender
(afghan_2).
Example 3
<struct type=?lexical entry?>
<feat type=?lemma?>afghan</feat>
<feat type=?grammatical category?>
common noun</feat>
<feat type=?gender?>masculine</feat>
<feat type=?key form?>afghan_1</feat>
<struct type=?morphology?>
?
<struct type=?inflexion?>
<feat type=?word form?>afghan</feat>
<feat type=?number?>singular</feat>
</struct>
<struct type=?inflexion?>
<feat type=?word form?>afghans</feat>
<feat type=?number?>plural</feat>
</struct>
</struct>
</struct>
Example 4
<struct type=?lexical entry?>
<feat type=?lemma?>afghane</feat>
<feat type=?grammatical category?>
common noun</feat>
<feat type=?gender?>feminine</feat>
<feat type=?key form?>afghan_2</feat>
<struct type=?morphology?>
?
<struct type=?inflexion?>
<feat type=?word form?>afghane</feat>
<feat type=?number?>singular</feat>
</struct>
<struct type=?inflexion?>
<feat type=?word form?>afghanes</feat>
<feat type=?number?>plural</feat>
</struct>
</struct>
</struct>
Example 5
<struct type=?lexical entry?>
<feat type=?lemma?>afghan</feat>
<feat type=?grammatical category?>
adjective</feat>
<feat type=?key form?>afghan_2</feat>
<struct type=?morphology?>
?
<struct type=?inflexion?>
<feat type=?word form?>afghan</feat>
?
</struct>
<struct type=?inflexion?>
<feat type=?word form?>afghans</feat>
?
</struct>
<struct type=?inflexion?>
<feat type=?word form?>afghane</feat>
?
</struct>
<struct type=?inflexion?>
<feat type=?word form?>afghanes</feat>
?
</struct>
</struct>
4.4 Integrating metadata descriptors
One important issue for the management, up-
dating and distribution of lexical databases is the
appropriate management of metadata, related either
to the identification of data sources or to the
characterization of the data.
Our proposal is based on several international
initiatives related to the definition of descriptors
for language data collections (cf. OLAC
10
,
IMDI
11
). We currently identify those descriptors
that may be relevant for lexical databases, such as
the language identifiers (ISO 16620) or the ?roles?
defined in OLAC (depositor, developer, research-
er, annotator, sponsor, etc.). Concerning data
characterization, existing standards (ISO 16620)
also contain an inventory of possible useful des-
criptors related to the updating process (origination
date, input date, modification date, approval date,
withdrawal date, etc.).
Additional information should be more speci-
fically related to the morphological extension: One
could for example wish to keep track of morpho-
syntactic tags (relative to a given tagset, such as
Multext) currently used to refer to certain in-
flexions (see Example 6). Other useful metadata
would be information about testimony and fre-
quency of inflected forms in corpora, completeness
of an inflexion list (relevant for defective verbs
such as pleuvoir (?to rain?) or indication of special
usages (diachronic, diatopic or diastratic variation).
Example 6
<struct type=?inflexion?>
<brack>
<feat type=?POS tag?>Nms__</feat>
<feat type=?tagset?>Multext</feat>
</brack>
<feat type=?word form?>chat</feat>
<feat type=?number?>singular</feat>
<struct/>
4.5 Morphalou?: current state
The basic model described in this paper (apart
from inflexion paradigms and metadata descrip-
tors, currently under definition) has been used to
build an electronic lexical database of inflected
forms for French
12
. It contains 539413 inflected
forms distributed over 68075 lemmas, converted
from data previously collected at the ATILF
laboratory. The whole database is encoded in
XML. Since we envisage on-line access and the
ability to up-date the data, we devoted particular
attention to the interfaces and to documentation.
The database is searchable through the web, via a
graphical interface or direct XPath queries. The
                                                       
10
 http://www.language-archives.org/
11
 http://www.mpi.nl/IMDI/
12
 http://loreley.loria.fr/morphalou/
graphical interface allows for lemmatization of a
given form and generation of all inflected forms
for a given lemma, whereas the XPath requests
allows for combining search criteria over any
combination of features and strings (for example,
all lexical entries for common nouns having an
inflected form containing the string aba). The next
steps are the development of a JAVA API and web
services to integrate search results directly into
NLP applications and the development of an
editorial line for efficient and coherent update of
the database. Preliminary updating experiments
based on freely accessible morphological databases
such as LEFFF and ABU
13
 are currently running
and reveal the most important problems to be
tackled (conversion of the input format, efficient
comparison of two XML files, linguistic validation
procedures and interfaces for submitted data,
fusion of lexical data).
5 References
Antoni-Lay MH., Francopoulo G., Zaysser L.
(1994). A generic model for reusable lexicons :
The Genelex project. Literary and Linguistic
Computing.
Dendien J., Pierrel J.-M. (2003). Le TLFi et le
logiciel Stella, au centre d'un ensemble de res-
sources informatis?es pour l'?tude du fran?ais.
Traitement Automatique des Langues, 44(2), 11-
37.
Ide N., V?ronis, J. (1995). Encoding dictionaries.
Computers and the Humanities, 29(2), 167-179.
Ide N., Kilgarriff A., Romary L. (2000). A Formal
Model of Dictionary Structure and Content.
Proceedings of Euralex 2000. Stuttgart, 113-126.
Ide N., Le Maitre J.,  V?ronis J. (1995). Outline of
a Model for Lexical Databases. Current Issues in
Computational Linguistics: In Honour of Don
Walker, Pisa, 283-320.
Ide N., Romary L. (2003).  Outline of the
International Standard Linguistic Annotation
Framework. ACL Workshop on Linguistic
Annotation: Getting the Model Right, Sapporo,
1-5.
ISO 12200:1999, Machine-readable terminology
interchange format (MARTIF) ? Negotiated
interchange.
ISO 12620:1999, Data categories.
ISO 16642:2003, Terminological markup frame-
work.
ISO 1951:1997, Lexicographical symbols and
typographical conventions for use in
terminography.
ISO 2788, Guidelines for the Establishment and
Development of Monolingual Thesauri.
ISO 5964, Guidelines for the Establishment and
Development of Multilingual Thesauri.
Mangeot-Lerebours M., S?rasset G., Lafourcade
M. (2003). Construction collaborative de base
                                                       
13
 http://abu.cnam.fr/DICO/mots-communs.html
donn?es lexicales multilingues : le projet
Papillon. Traitement Automatique des Langues,
44(2), 151-176.
Mel?cuk I., Clas A., Polgu?re A. (1995)
Introduction ? la lexicologie explicative et
combinatoire. Duculot, Bruxelles.
Romary L. (2001) Towards an Abstract
Representation of Terminological Data
Collections - the TMF model, TAMA 2001 ?
Terminology in Advanced Microcomputer
Applications, Antwerp.
Saussaure F. de (1974). Cours de linguistique
g?n?rale. Payot, 1974.
V?ronis J. (1999). Multext-Corpora. An annotated
corpus for five European languages [CD-ROM,
ELRA-ELDA].
V?ronis, J. (2000). Sense tagging: Don't look for
the meaning but for the use. Computational
Lexicography and Multimedia Dictionaries
(COMLEX'2000), Greece.
V?ronis J., Ide N. (1992). A feature-based model
for lexical databases, 14th International
Conference on Computational Linguistics
(COLING'92), Nantes (France), 588-594.
6 Acknowledgement
The work presented in this paper has received
support from the national RNTL/Outilex project,
the INRIA corporate action Syntax and the
Morphalou project (CPER Lorraine). Many thanks
to Monte George, Sue-Ellen Wright and Kornel
Bangha for their valuable comments.
7 Appendix : Data categories of the Inflexion
component of Morphalou (04/2004)
Component Data Category Conceptual Domain
/lemma/ String
/spelling variant/ String
/common noun/
/verb/
/adjective/
/adverb/
/interjection/
/onomatope/
Entry
/grammatical
category/
/function word/
/word form/ String
/indicative/
/conjunctive/
/conditional/
/past participle/
/present participle/
/mood/
/infinitive/
/present/
/imperfect/
/simple past/
/tense/
/future/
/first person/
/second person/
/person/
/third person/
/feminine/
/gender/
/masculine/
/singular/
Inflexion
/number/
/plural/
Proceedings of the Workshop on Multilingual Language Resources and Interoperability, pages 1?8,
Sydney, July 2006. c?2006 Association for Computational Linguistics
LEXICAL MARKUP FRAMEWORK (LMF)  
FOR NLP MULTILINGUAL RESOURCES 
Gil Francopoulo1, Nuria Bel2, Monte George3, Nicoletta Calzolari4, 
Monica Monachini5, Mandy Pet6, Claudia Soria7
 
1INRIA-Loria: gil.francopoulo@wanadoo.fr 
2UPF: nuria.bel@upf.edu 
3ANSI: dracalpha@earthlink.net 
4CNR-ILC: glottolo@ilc.cnr.it 
5CNR-ILC: monica.monachini@ilc.cnr.it 
6MITRE: mpet@mitre.org 
7CNR-ILC: claudia.soria@ilc.cnr.it 
 
Abstract 
Optimizing the production, maintenance 
and extension of lexical resources is one 
the crucial aspects impacting Natural 
Language Processing (NLP). A second 
aspect involves optimizing the process 
leading to their integration in applica-
tions. With this respect, we believe that 
the production of a consensual specifica-
tion on multilingual lexicons can be a 
useful aid for the various NLP actors. 
Within ISO, one purpose of LMF (ISO-
24613) is to define a standard for lexi-
cons that covers multilingual data. 
1 Introduction 
Lexical Markup Framework (LMF) is a model 
that provides a common standardized framework 
for the construction of Natural Language Proc-
essing (NLP) lexicons. The goals of LMF are to 
provide a common model for the creation and 
use of lexical resources, to manage the exchange 
of data between and among these resources, and 
to enable the merging of a large number of indi-
vidual electronic resources to form extensive 
global electronic resources. 
Types of individual instantiations of LMF can 
include monolingual, bilingual or multilingual 
lexical resources. The same specifications are to 
be used for both small and large lexicons. The 
descriptions range from morphology, syntax, 
semantic to translation information organized as 
different extensions of an obligatory core pack-
age. The model is being developed to cover all 
natural languages. The range of targeted NLP 
applications is not restricted. LMF is also used to 
model machine readable dictionaries (MRD), 
which are not within the scope of this paper. 
2 History and current context 
In the past, this subject has been studied and de-
veloped by a series of projects like GENELEX 
[Antoni-Lay], EAGLES, MULTEXT, PAROLE, 
SIMPLE, ISLE and MILE [Bertagna]. More re-
cently within ISO1 the standard for terminology 
management has been successfully elaborated by 
the sub-committee three of ISO-TC37 and pub-
lished under the name "Terminology Markup 
Framework" (TMF) with the ISO-16642 refer-
ence. Afterwards, the ISO-TC37 National dele-
gations decided to address standards dedicated to 
NLP. These standards are currently elaborated as 
high level specifications and deal with word 
segmentation (ISO 24614), annotations 
(ISO 24611, 24612 and 24615), feature struc-
tures (ISO 24610), and lexicons (ISO 24613) 
with this latest one being the focus of the current 
paper. These standards are based on low level 
specifications dedicated to constants, namely 
data categories (revision of ISO 12620), lan-
guage codes (ISO 639), script codes 
(ISO 15924), country codes (ISO 3166), dates 
(ISO 8601) and Unicode (ISO 10646). 
 
This work is in progress. The two level organiza-
tion will form a coherent family of standards 
with the following simple rules: 
1) the low level specifications provide standard-
ized constants; 
                                                 
1 www.iso.org 
1
2) the high level specifications provide struc-
tural elements that are adorned by the standard-
ized constants. 
3 Scope and challenges 
The task of designing a lexicon model that satis-
fies every user is not an easy task. But all the 
efforts are directed to elaborate a proposal that 
fits the major needs of most existing models. 
In order to summarise the objectives, let's see 
what is in the scope and what is not. 
 
LMF addresses the following difficult chal-
lenges: 
? Represent words in languages where 
multiple orthographies (native scripts or 
transliterations) are possible, e.g. some 
Asian languages. 
? Represent explicitly (i.e. in extension) 
the morphology of languages where a de-
scription of all inflected forms (from a list 
of lemmatised forms) is manageable, e.g. 
English. 
? Represent the morphology of languages 
where a description in extension of all in-
flected forms is not manageable (e.g. Hun-
garian). In this case, representation in in-
tension is the only manageable issue. 
? Easily associate written forms and spo-
ken forms for all languages. 
? Represent complex agglutinating com-
pound words like in German. 
? Represent fixed, semi-fixed and flexible 
multiword expressions. 
? Represent specific syntactic behaviors, 
as in the Eagles recommendations. 
? Allow complex argument mapping be-
tween syntax and semantic descriptions, as 
in the Eagles recommendations. 
? Allow a semantic organisation based on 
SynSets (like in WordNet) or on semantic 
predicates (like in FrameNet). 
? Represent large scale multilingual re-
sources based on interlingual pivots or on 
transfer linking. 
LMF does not address the following topics: 
? General sentence grammar of a language 
? World knowledge representation 
In other words, LMF is mainly focused on the 
linguistic representation of lexical information. 
4 Key standards used by LMF 
LMF utilizes Unicode in order to represent the 
orthographies used in lexical entries regardless of 
language. 
Linguistic constants, like /feminine/ or 
/transitive/, are not defined within LMF but are 
specified in the Data Category Registry (DCR) 
that is maintained as a global resource by 
ISO TC37 in compliance with ISO/IEC 11179-
3:2003. 
The LMF specification complies with the 
modeling principles of Unified Modeling Lan-
guage (UML) as defined by OMG2 [Rumbaugh 
2004]. A model is specified by a UML class dia-
gram within a UML package: the class name is 
not underlined in the diagrams. The various ex-
amples of word description are represented by 
UML instance diagrams: the class name is under-
lined.  
5 Structure and core package 
LMF is comprised of two components: 
1) The core package consists of a structural 
skeleton that describes the basic hierarchy of in-
formation in a lexical entry. 
2) Extensions to the core package are ex-
pressed in a framework that describes the reuse 
of the core components in conjunction with addi-
tional components required for the description of 
the contents of a specific lexical resource. 
In the core package, the class called Database 
represents the entire resource and is a container 
for one or more lexicons. The Lexicon class is 
the container for all the lexical entries of the 
same language within the database. The Lexicon 
Information class contains administrative infor-
mation and other general attributes. The Lexical 
Entry class is a container for managing the top 
level language components. As a consequence, 
the number of representatives of single words, 
multi-word expressions and affixes of the lexicon 
is equal to the number of lexical entries in a 
given lexicon. The Form and Sense classes are 
parts of the Lexical Entry. Form consists of a text 
string that represents the word. Sense specifies or 
identifies the meaning and context of the related 
form. Therefore, the Lexical Entry manages the 
relationship between sets of related forms and 
their senses. If there is more than one orthogra-
                                                 
2 www.omg.org 
2
phy for the word form (e.g. transliteration) the 
Form class may be associated with one to many 
Representation Frames, each of which contains a 
specific orthography and one to many data cate-
gories that describe the attributes of that orthog-
raphy. 
The core package classes are linked by the re-
lations as defined in the following UML class 
diagram: 
 
Representation Frame
Lexicon Information
Form Sense
Entry Relation
Sense Relation
Lexical Entry
Database
Lexicon
0..* 0..*
0..*1
0..* 0..*
0..*1
1
0..*
1
1
1
0..*
1
1..*
1
0..*
1
1..*
1..*
1
 
 
Form class can be sub-classed into Lemmatised 
Form and Inflected Form class as follows: 
 
Lemmatised Form Inflected Form
Form
 
 
A subset of the core package classes are ex-
tended to cover different kinds of linguistic data. 
All extensions conform to the LMF core package 
and cannot be used to represent lexical data in-
dependently of the core package. From the point 
of view of UML, an extension is a UML pack-
age. Current extensions for NLP dictionaries are: 
NLP Morphology3, NLP inflectional paradigm, 
NLP Multiword Expression pattern, NLP Syntax, 
NLP Semantic and Multilingual notations, which 
is the focus of this paper. 
6 NLP Multilingual Extension 
The NLP multilingual notation extension is 
dedicated to the description of the mapping be-
tween two or more languages in a LMF database. 
The model is based on the notion of Axis that 
links Senses, Syntactic Behavior and examples 
pertaining to different languages. "Axis" is a 
                                                 
3 Morphology, Syntax and Semantic packages are 
described in [Francopoulo]. 
3
term taken from the Papillon4 project [S?rasset 
2001] 5 . Axis can be organized at the lexicon 
manager convenience in order to link directly or 
indirectly objects of different languages.  
 
6.1 Considerations for standardizing multi-
lingual data  
The simplest configuration of multilingual 
data is a bilingual lexicon where a single link is 
used to represent the translation of a given 
form/sense pair from one language into another. 
But a survey of actual practices clearly reveals 
other requirements that make the model more 
complex. Consequently, LMF has focused on the 
following ones: 
 
(i) Cases where the relation 1-to-1 is impos-
sible because of lexical differences among lan-
guages. An example is the case of English word 
?river? that relates to French words ?rivi?re? and 
?fleuve?, where the latter is used for specifying 
that the referent is a river that flows into the sea. 
The bilingual lexicon should specify how these 
units relate. 
 
(ii) The bilingual lexicon approach should 
be optimized to allow the easiest management of 
large databases for real multilingual scenarios. In 
order to reduce the explosion of links in a multi-
bilingual scenario, translation equivalence can be 
managed through an intermediate "Axis". This 
object can be shared in order to contain the num-
ber of links in manageable proportions. 
 
(iii) The model should cover both transfer 
and pivot approaches to translation, taking also 
into account hybrid approaches. In LMF, the 
pivot approach is implemented by a ?Sense 
Axis?. The transfer approach is implemented by 
a ?Transfer Axis?. 
 
(iv) A situation that is not very easy to deal 
with is how to represent translations to languages 
that are similar or variants. The problem arises, 
for instance, when the task is to represent transla-
tions from English to both European Portuguese 
and Brazilian Portuguese. It is difficult to con-
                                                 
4 www.papillon-dictionary.org  
5 To be more precise, Papillon uses the term "axie" 
from "axis" and "lexie". In the beginning of the LMF 
project, we used the term "axie" but after some bad 
comments about using a non-English term in a stan-
dard, we decided to use the term "axis". 
sider them as two separate languages. In fact, one 
is a variant of the other. The differences are mi-
nor: a certain number of words are different and 
some limited phenomena in syntax are different. 
Instead of managing two distinct copies, it is 
more effective to manage one lexicon with some 
objects that are marked with a dialectal attribute. 
Concerning the translation from English to Por-
tuguese: a limited number of specific Axis in-
stances record this variation and the vast major-
ity of Axis instances is shared. 
 
(v) The model should allow for representing 
the information that restricts or conditions the 
translations. The representation of tests that 
combine logical operations upon syntactic and 
semantic features must be covered. 
6.2 Structure 
The model is based on the notion of Axis that 
link Senses, Syntactic Behavior and examples 
pertaining to different languages. Axis can be 
organized at the lexicon manager convenience in 
order to link directly or indirectly objects of dif-
ferent languages. A direct link is implemented by 
a single axis. An indirect link is implemented by 
several axis and one or several relations. 
The model is based on three main classes: 
Sense Axis, Transfer Axis, Example Axis. 
6.3 Sense Axis 
Sense Axis is used to link closely related 
senses in different languages, under the same 
assumptions of the interlingual pivot approach, 
and, optionally, it can also be used to refer to one 
or several external knowledge representation sys-
tems.  
The use of the Sense Axis facilitates the repre-
sentation of the translation of words that do not 
necessarily have the same valence or morpho-
logical form in one language than in another. For 
example, in a language, we can have a single 
word that will be translated by a compound word 
into another language: English ?wheelchair? to 
Spanish ?silla de ruedas?. Sense Axis may have 
the following attributes: a label, the name of an 
external descriptive system, a reference to a spe-
cific node inside an external description. 
6.4 Sense Axis Relation 
Sense Axis Relation permits to describe the 
linking between two different Sense Axis in-
stances. The element may have attributes like 
label, view, etc. 
4
6.6 Transfer Axis Relation 
Transfer Axis Relation links two Transfer Axis 
instances. The element may have attributes like: 
label, variation. 
The label enables the coding of simple inter-
lingual relations like the specialization of 
?fleuve? compared to ?rivi?re? and ?river?. It is 
not, however, the goal of this strategy to code a 
complex system for knowledge representation, 
which ideally should be structured as a complete 
coherent system designed specifically for that 
purpose. 
6.7 Source Test and Target Test 
Source Test permits to express a condition on 
the translation on the source language side while 
Target Test does it on the target language side. 
Both elements may have attributes like: text and 
comment. 
6.5 Transfer Axis 
Transfer Axis is designed to represent multi-
lingual transfer approach. Here, linkage refers to 
information contained in syntax. For example, 
this approach enables the representation of syn-
tactic actants involving inversion, such as (1): 
6.8 Example Axis  
Example Axis supplies documentation for 
sample translations. The purpose is not to record 
large scale multilingual corpora. The goal is to 
link a Lexical Entry with a typical example of 
translation. The element may have attributes like: 
comment, source. 
 
(1) fra:?elle me manque? => 
eng:?I miss her? 
 
Due to the fact that a lexical entry can be a 
support verb, it is possible to represent transla-
tions that start from a plain verb to a support verb 
like (2) that means "Mary dreams": 
6.9 Class Model Diagram 
The UML class model is an UML package. The 
diagram for multilingual notations is as follows:  
(2)  fra:?Marie r?ve? =>  
  jpn:"Marie wa yume wo miru"  
Transfer Axis Relation
Sense Axis Relation
Syntactic Behavior
SenseExample
Transfer Axis
Example Axis
Source Test
Sense Axis
Target Test
SynSet
Sense
0..*
0..*
0..*
0..*
1
0..*
0..* 0..*
0..*
0..*
1
0..*
1
0..1
1
0..*
0..1
1
1
0..*
1
0..*
1
0..*
5
7 Three examples 
7.1 First example 
The first example is about the interlingual ap-
proach with two axis instances to represent a 
near match between "fleuve" in French and 
"river" in English. In the diagram, French is lo-
cated on the left side and English on the right 
side. The axis on the top is not linked directly to 
any English sense because this notion does not 
exist in English.  
: Sense Axis Relation
comment = flows into the sea
label = more precise
: Sense
label = eng:riverlabel = fra:rivi?re
: Sense
: Sense
label = fra:fleuve
: Sense Axis
: Sense Axis
 
 
7.2 Second example 
Let's see now an example about the transfer 
approach about slight variations between vari-
ants. The example is about English on one side 
and European Portuguese and Brazilian on the 
other side. Due to the fact that these two last 
variants have a very similar syntax, but with 
some local exceptions, the goal is to avoid a full 
and dummy duplication. For instance, the nomi-
native forms of the third person clitics are largely 
preferred in Brazilian rather than the oblique 
form as in European Portuguese. The transfer 
axis relations hold a label to distinguish which 
axis to use depending on the target object. 
 
: Transfer Axis Relation
label = European Portuguese
: Transfer Axis Relation
label = Brazilian
: Syntactic Behavior
label = let me see
: Syntactic Behavior
label = Deixa eu ver
: Syntactic Behavior
label = Deixa-me ver
: Transfer Axis
: Transfer Axis
: Transfer Axis
 
7.3 Third example 
A third example shows how to use the Trans-
fer Axis relation to relate different information in 
a multilingual transfer lexicon. It represents the 
translation of the English ?develop? into Italian 
and Spanish. Recall that the more general sense 
links ?eng:develop? and ?esp:desarrollar?. Both, 
Spanish and Italian, have restrictions that should 
6
be tested in the source language: if the second 
argument of the construction refers to certain 
elements (picture, mentalCreation, building) it 
should be translated into specific verbs.  
 
: Source Test
semanticRestriction = eng:mentalCreation
syntacticArgument = 2
: Source Test
semanticRestriction = eng:picture
syntacticArgument = 2
: Source Test
semanticRestriction = eng:building
syntacticArgument = 2
: Transfer Axis Relation
: Transfer Axis Relation
: Transfer Axis Relation
: Syntactic Behavior
label = esp:revelar
: Syntactic Behavior
label = ita:sviluppare
: Syntactic Behavior
label = ita:costruire
: Syntactic Behavior
label = eng:develop
: Syntactic Behavior
label = esp:construir
: Syntactic Behavior
label = esp:desarrollar
: Transfer Axis
: Transfer Axis
: Transfer Axis
: Transfer Axis
 
8 LMF in XML  
During the last three years, the ISO group fo-
cused on the UML specification. In the last ver-
sion of the LMF document [LMF 2006] a DTD 
has been provided as an informative annex. The 
following conventions are adopted: 
? each UML attribute is transcoded as a 
DC (for Data Category) element 
? each UML class is transcoded as an 
XML element 
? UML aggregations are transcoded as 
content inclusion 
? UML shared associations (i.e. associa-
tions that are not aggregations) are 
transcoded as IDREF(S) 
The first example (i.e. "river") can be represented 
with the following XML tags: 
 
 
<Database> 
<!?   French section ? 
<Lexicon> 
<LexiconInformation 
<DC att="name" val=?French Extract?/> 
<DC att="language" val="fra"/> 
</LexiconInformation> 
<LexicalEntry > 
<DC att="partOfSpeech" val=?noun?/> 
<LemmatisedForm> 
<DC att="writtenForm" val=?fleuve?/> 
</LemmatisedForm> 
<Sense id=?fra.fleuve1?> 
 <SemanticDefinition> 
                  <DC att="text" 
val=?Grande rivi?re lorsqu'elle aboutit ? la mer?/> 
<DC att="source" val=?Le Petit Robert 2003?/> 
</SemanticDefinition> 
</Sense> 
</LexicalEntry> 
<LexicalEntry> 
<DC att="partOfSpeech" val=?noun?/> 
<LemmatisedForm> 
  <DC att="writtenForm" val=?rivi?re?/> 
</LemmatisedForm> 
<Sense id=?fra.riviere1?> 
 <SemanticDefinition> 
<DC att="text"  
val=?Cours d'eau naturel de moyenne importance?/> 
<DC att="source" val=?Le Petit Robert 2003?/> 
</SemanticDefinition> 
</Sense> 
</LexicalEntry> 
</Lexicon> 
<!?                                                 Multilingual section ? 
<SenseAxis id=?A1? senses="fra.fleuve1"> 
7
<SenseAxisRelation targets="A2"> 
 <DC att="comment" val="flows into the sea"/> 
 <DC att="label" val="more precise"/> 
</SenseAxisRelation> 
</SenseAxis> 
<SenseAxis id=?A2? senses="fra.riviere1 eng.river1"/> 
<!?                                                English section ? 
<Lexicon> 
<LexiconInformation> 
<DC att="name" val=?English Extract?/> 
<DC att="language" val="eng"/> 
</LexiconInformation> 
<LexicalEntry> 
<DC att="partOfSpeech" val=?noun?/> 
<LemmatisedForm> 
<DC att="writtenForm" val=?river?/> 
</LemmatisedForm> 
<Sense id=?eng.river1?> 
 <SemanticDefinition> 
<DC att="text" 
val=?A natural and continuous flow of water in a long 
line across a country into the sea?/> 
<DC att="source" val=?Longman DCE 2005?/> 
</SemanticDefinition> 
</Sense> 
</LexicalEntry> 
</Lexicon> 
</Database> 
 
 
9 Comparison 
A serious comparison with previously existing 
models is not possible in this current paper due 
to the lack of space. We advice the interested 
colleague to consult the technical report "Ex-
tended examples of lexicons using LMF" located 
at:  "http://lirics.loria.fr" in the document area. 
The report explains how to use LMF in order to 
represent OLIF-2, Parole/Clips, LC-Star, Word-
Net, FrameNet and BD?f. 
10 Conclusion 
In this paper we presented the results of the 
ongoing research activity of the LMF ISO stan-
dard. The design of a common and standardized 
framework for multilingual lexical databases will 
contribute to the optimization of the use of lexi-
cal resources, specially their reusability for dif-
ferent applications and tasks. Interoperability is 
the condition of a effective deployment of usable 
lexical resources. 
In order to reach a consensus, the work done 
has paid attention to the similarities and differ-
ences of existing lexicons and the models behind 
them. 
Acknowledgements 
The work presented here is partially funded by 
the EU eContent-22236 LIRICS project 6 , par-
tially by the French TECHNOLANGUE 7 + 
OUTILEX8 programs. 
References 
Antoni-Lay M-H., Francopoulo G., Zaysser L. 1994 
A generic model for reusable lexicons: the 
GENELEX project. Literary and linguistic comput-
ing 9(1) 47-54 
Bertagna F., Lenci A., Monachini M., Calzolari N. 
2004 Content interoperability of lexical resources, 
open issues and MILE perspectives LREC Lisbon 
Francopoulo G., George M., Calzolari N., Monachini 
M., Bel N., Pet M., Soria C. 2006 Lexical Markup 
Framework (LMF) LREC Genoa. 
LMF 2006 Lexical Markup Framework ISO-
CD24613-revision-9, ISO Geneva 
Rumbaugh J., Jacobson I.,Booch G. 2004 The unified 
modeling language reference manual, second edi-
tion, Addison Wesley 
S?rasset G., Mangeot-Lerebours M. 2001 Papillon 
Lexical Database project: monolingual dictionaries 
& interlingual links NLPRS Tokyo 
                                                 
6 http://lirics.loria.fr 
7 www.technolangue.net 
8 www.at-lci.com/outilex/outilex.html 
8
Coling 2008: Proceedings of the workshop on Cross-Framework and Cross-Domain Parser Evaluation, pages 36?43
Manchester, August 2008
Large Scale Production of Syntactic Annotations to Move Forward
Patrick Paroubek, Anne Vilnat, Sylvain Loiseau
LIMSI-CNRS
BP 133 91403 Orsay Cedex
France
prenom.nom@limsi.fr
Gil Francopoulo
Tagmatica
126 rue de Picpus 75012 Paris
France
gil.francopoulo@tagmatica.com
Olivier Hamon
ELDA and LIPN-P13
55-57 rue Brillat-Savarin 75013 Paris,
France
hamon@elda.org
Eric Villemonte de la Clergerie
Alpage-INRIA
Dom. de Voluceau Rocquencourt,
B.P. 105, 78153 Le Chesnay, France
Eric.De La Clergerie@inria.fr
Abstract
This article presents the methodology of
the PASSAGE project, aiming at syntacti-
cally annotating large corpora by compos-
ing annotations. It introduces the anno-
tation format and the syntactic annotation
specifications. It describes an important
component of the methodolgy, namely an
WEB-based evaluation service, deployed
in the context of the first PASSAGE parser
evaluation campaign.
1 Introduction
The last decade has seen, at the international level,
the emergence of a very strong trend of researches
on statistical methods in Natural Language Pro-
cessing. In our opinion, one of its origins, in
particular for English, is the availability of large
annotated corpora, such as the Penn Treebank
(1M words extracted from the Wall Street journal,
with syntactic annotations; 2
nd
release in 1995
1
,
the British National Corpus (100M words cover-
ing various styles annotated with parts of speech
2
),
or the Brown Corpus (1M words with morpho-
syntactic annotations). Such annotated corpora
were very valuable to extract stochastic grammars
or to parametrize disambiguation algorithms. For
instance (Miyao et al, 2004) report an experiment
where an HPSG grammar is semi-automatically
aquired from the Penn Treebank, by first annotat-
ing the treebank with partially specified derivation
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
1
http://www.cis.upenn.edu/
?
treebank/
2
http://www.natcorp.ox.ac.uk/
trees using heuristic rules , then by extracting lex-
ical entries with the application of inverse gram-
mar rules. (Cahill et al, 2004) managed to ex-
tract LFG subcategorisation frames and paths link-
ing long distance dependencies reentrancies from
f-structures generated automatically for the Penn-
II treebank trees and used them in an long distance
dependency resolution algorithm to parse new text.
They achieved around 80% f-score for fstructures
parsing on the WSJ part of the Penn-II treebank,
a score comparable to the ones of the state-of-
the-art hand-crafted grammars. With similar re-
sults, (Hockenmaier and Steedman, 2007) trans-
lated the Penn Treebank into a corpus of Combina-
tory Categorial Grammar (CCG) derivations aug-
mented with local and long-range word to word
dependencies and used it to train wide-coverage
statistical parsers. The development of the Penn
Treebank have led to many similar proposals of
corpus annotations
3
. However, the development of
such treebanks is very costly from an human point
of view and represents a long standing effort, in
particular for getting of rid of the annotation errors
or inconsistencies, unavoidable for any kind of hu-
man annotation. Despite the growing number of
annotated corpora, the volume of data that can be
manually annotated remains limited thus restrict-
ing the experiments that can be tried on automatic
grammar acquisition. Furthermore, designing an
annotated corpus involves choices that may block
future experiments from acquiring new kinds of
linguistic knowledge because they necessitate an-
notation incompatible or difficult to produce from
the existing ones.
With PASSAGE (de la Clergerie et al, 2008b),
we believe that a new option becomes possible.
3
http://www.ims.uni-stuttgart.de/
projekte/TIGER/related/links.shtml
36
Funded by the French ANR program on Data
Warehouses and Knowledge, PASSAGE is a 3-
year project (2007?2009), coordinated by INRIA
project-team Alpage. It builds up on the re-
sults of the EASy French parsing evaluation cam-
paign, funded by the French Technolangue pro-
gram, which has shown that French parsing sys-
tems are now available, ranging from shallow to
deep parsing. Some of these systems were nei-
ther based on statistics, nor extracted from a tree-
bank. While needing to be improved in robustness,
coverage, and accuracy, these systems has nev-
ertheless proved the feasibility to parse medium
amount of data (1M words). Preliminary experi-
ments made by some of the participants with deep
parsers (Sagot and Boullier, 2006) indicate that
processing more than 10 M words is not a prob-
lem, especially by relying on clusters of machines.
These figures can even be increased for shallow
parsers. In other words, there now exists sev-
eral French parsing systems that could parse (and
re-parse if needed) large corpora between 10 to
100 M words.
Passage aims at pursuing and extending the
line of research initiated by the EASy campaign
by using jointly 10 of the parsing systems that
have participated to EASy. They will be used to
parse and re-parse a French corpus of more than
100 M words along the following feedback loop
between parsing and resource creation as follows
(de la Clergerie et al, 2008a):
1. Parsing creates syntactic annotations;
2. Syntactic annotations create or enrich linguis-
tic resources such as lexicons, grammars or
annotated corpora;
3. Linguistic resources created or enriched on
the basis of the syntactic annotations are then
integrated into the existing parsers;
4. The enriched parsers are used to create richer
(e.g., syntactico-semantic) annotations;
5. etc. going back to step 1
In order to improve the set of parameters of
the parse combination algorithm (inspired from
the Recognizer Output Voting Error Reduction,
i.e. ROVER, experiments), two parsing evalu-
ation campaigns are planned during PASSAGE,
the first of these already took place at the end of
2007 (de la Clergerie et al, 2008b). In the follow-
ing, we present the annotation format specification
and the syntactic annotation specifications of PAS-
SAGE, then give an account of how the syntactic
annotations were compared in the first evaluation
campaign, by first describing the evaluation met-
rics and the web server infrastructure that was de-
ployed to process them. We conclude by showing
how the results so far achieved in PASSAGE will
contribute to the second part of the project, extract-
ing and refining enriched linguistic annotations.
2 PASSAGE Annotation Format
The aim is to allow an explicit representation of
syntactic annotations for French, whether such an-
notations come from human annotators or parsers.
The representation format is intended to be used
both in the evaluation of different parsers, so the
parses? representations should be easily compara-
ble, and in the construction of a large scale anno-
tation treebank which requires that all French con-
structions can be represented with enough details.
The format is based on three distinct specifica-
tions and requirements:
1. MAF (ISO 24611)
4
and SynAF (ISO 24615)
5
which are the ISO TC37 specifications for
morpho-syntactic and syntactic annotation
(Ide and Romary, 2002) (Declerck, 2006)
(Francopoulo, 2008). Let us note that these
specifications cannot be called ?standards?
because they are work in progress and these
documents do not yet have the status Pub-
lished Standard. Currently, their official sta-
tus is only Committee Draft.
2. The format used during the previous TECH-
NOLANGUE/EASY evaluation campaign
in order to minimize porting effort for the ex-
isting tools and corpora.
3. The degree of legibility of the XML tagging.
From a technical point of view, the format is a
compromise between ?standoff? and ?embedded?
notation. The fine grain level of tokens and words
is standoff (wrt the primary document) but higher
levels use embedded annotations. A standoff nota-
tion is usually considered more powerful but less
4
http://lirics.loria.fr/doc pub/maf.pdf
5
http://lirics.loria.fr/doc pub/
N421 SynAF CD ISO 24615.pdf
37
Figure 1: UML diagram of the structure of an an-
notated document
readable and not needed when the annotations fol-
low a (unambiguous) tree-like structure. Let us
add that, at all levels, great care has been taken to
ensure that the format is mappable onto MAF and
SynAF, which are basically standoff notations.
The structure of a PASSAGE annotated docu-
ment may be summarized with the UML diagram
in Figure1. The document begins by the declara-
tion of all the morpho-syntactic tagsets (MSTAG)
that will be used within the document. These dec-
larations respect the ISO Standard Feature Struc-
ture Representation (ISO 24610-1). Then, tokens
are declared. They are the smallest unit address-
able by other annotations. A token is unsplittable
and holds an identifier, a character range, and a
content made of the original character string. A
word form is an element referencing one or sev-
eral tokens. It has has two mandatory attributes:
an identifier and a list of tokens. Some optional at-
tributes are allowed like a part of speech, a lemma,
an inflected form (possibly after spelling correc-
tion or case normalization) and morpho-syntactic
tags. The following XML fragment shows how
the original fragment ?Les chaises? can be repre-
sented with all the optional attributes offered by
the PASSAGE annotation format :
<T id="t0" start="0" end="3">
Les
</T>
<W id="w0" tokens="t0"
pos="definiteArticle"
lemma="le"
form="les"
mstag="nP"/>
<T id="t1" start="4" end="11">
chaises
</T>
<W id="w1" tokens="t1"
pos="commonNoun"
lemma="chaise"
form="chaises"
mstag="nP gF"/>
Note that all parts of speech are taken from the
ISO registry
6
(Francopoulo et al, 2008). As in
MAF, a word may refer to several tokens in or-
der to represent multi-word units like ?pomme de
terre?. Conversely, a unique token may be refered
by two different words in order to represent results
of split based spelling correction like when ?un-
etable? is smartly separated into the words ?une?
and ?table?. The same configuration is required to
represent correctly agglutination in fused preposi-
tions like the token ?au? that may be rewritten into
the sequence of two words ?`a? ?le?. On the con-
trary of MAF, cross-reference in token-word links
for discontiguous spans is not allowed for the sake
of simplicity. Let us add that one of our require-
ment is to have PASSAGE annotations mappable
onto the MAF model and not to map all MAF an-
notations onto PASSAGE model. A G element de-
notes a syntactic group or a constituent (see details
in section 3). It may be recursive or non-recursive
and has an identifier, a type, and a content made of
word forms or groups, if recursive. All group type
values are taken from the ISO registry. Here is an
example :
<T id="t0" start="0" end="3">
Les
</T>
<T id="t1" start="4" end="11">
chaises
</T>
<G id="g0" type="GN">
<W id="w0" tokens="t0"/>
<W id="w1" tokens="t1"/>
</G>
A group may also hold optional attributes like syn-
tactic tagsets of MSTAG type. The syntactic re-
lations are represented with a standoff annotations
which refer to groups and word forms. A relation
is defined by an identifier, a type, a source, and a
target (see details in section 3. All relation types,
like ?subject? or ?direct object? are mappable onto
the ISO registry. An unrestricted number of com-
ments may be added to any element by means of
the mark element (i.e. M). Finally, a ?Sentence?
6
Data Category Registry, see http://syntax.
inist.fr
38
element gathers tokens, word forms, groups, rela-
tions and marks and all sentences are included in-
side a ?Document? element.
3 PASSAGE Syntactic Annotation
Specification
3.1 Introduction
The annotation formalism used in PASSAGE
7
is
based on the EASY one(Vilnat et al, 2004) which
whose first version was crafted in an experimental
project PEAS (Gendner et al, 2003), with inspira-
tion taken from the propositions of (Carroll et al,
2002). The definition has been completed with the
input of all the actors involved in the EASY evalu-
ation campaign (both parsers? developers and cor-
pus providers) and refined with the input of PAS-
SAGE participants. This formalism aims at mak-
ing possible the comparison of all kinds of syn-
tactic annotation (shallow or deep parsing, com-
plete or partial analysis), without giving any ad-
vantage to any particular approach. It has six
kinds of syntactic ?chunks?, we call constituents
and 14 kinds of relations The annotation formal-
ism allows the annotation of minimal, continuous
and non recursive constituents, as well as the en-
coding of relations wich represent syntactic func-
tions. These relations (all of them being binary, ex-
cept for the ternary coordination) have sources and
targets which may be either forms or constituents
(grouping several forms). Note that the PASSAGE
annotation formalism does not postulate any ex-
plicit lexical head.
3.2 Constituent annotations
For the PASSAGE campaigns, 6 kinds of con-
stituents (syntactic ?chunks?) have been consid-
ered and are illustrated in Table 3.2:
? the Noun Phrase (GN for Groupe Nominal)
may be made of a noun preceded by a de-
terminer and/or by an adjective with its own
modifiers, a proper noun or a pronoun;
? the prepositional phrase (GP, for groupe
pr?epositionnel ) may be made of a preposi-
tion and the GN it introduces, a contracted
determiner and preposition, followed by the
introduced GN, a preposition followed by an
adverb or a relative pronoun replacing a GP;
7
Annotation guide: http://www.limsi.fr/
Recherche/CORVAL/PASSAGE/eval 1/2007 10
05PEAS reference annotations v11.12.html
? the verb kernel (NV for noyau verbal ) in-
cludes a verb, the clitic pronouns and possible
particles attached to it. Verb kernels may have
different forms: conjugated tense, present or
past participle, or infinitive. When the con-
jugation produces compound forms, distinct
NVs are identified;
? the adjective phrase (GA for groupe adjec-
tival) contains an adjective when it is not
placed before the noun, or past or present par-
ticiples when they are used as adjectives;
? the adverb phrase (GR for groupe adverbial )
contains an adverb;
? the verb phrase introduced by a preposition
(PV) is a verb kernel with a verb not inflected
(infinitive, present participle,...), introduced
by a preposition. Some modifiers or adverbs
may also be included in PVs.
GN - la tr`es grande porte
8
(the very big door);
- Rouletabille
- eux (they), qui (who)
GP - de la chambre (from the bedroom),
- du pavillon (from the lodge)
- de l`a (from there), dont (whose)
NV - j?entendais (I heared)
- [on ne l?entendait]
9
plus
(we could no more hear her)
- Jean [viendra] (Jean will come)
- [d?esob?eissant] `a leurs parents
(disobeying their parents),
- [ferm?ee] `a clef (key closed)
- Il [ne veut] pas [venir]
(He doesn?t want to come),
- [ils n??etaient] pas [ferm?es]
(they were not closed),
GA - les barreaux [intacts] (the intact bars)
- la solution [retenue] fut...
(the chosen solution has been...),
- les enfants [d?esob?eissants]
(the disobeying children)
GR - aussi (also)
- vous n?auriez [pas] (you would not)
PV - [pour aller] `a Paris (for going to Paris),
- de vraiment bouger (to really move)
Table 1: Constituent examples
39
3.2.1 Syntactic Relation annotations
The dependencies establish all the links between
the minimal constituents described above. All par-
ticipants, corpus providers and campaign organiz-
ers agreed on a list of 14 kinds of dependencies
listed below:
1. subject-verb (SUJ V): may be inside the
same NV as between elle and ?etait in elle
?etait (she was), or between a GN and a NV as
between mademoiselle and appelait in Made-
moiselle appelait (Miss was calling);
2. auxiliary-verb (AUX V), between two NVs
as between a and construit in: on a construit
une maison (we have built a house);
3. direct object-verb (COD V): the relation is
annotated between a main verb (NV) and a
noun phrase (GN), as between construit and
la premi`ere automobile in: on a construit la
premi`ere automobile (we have built the first
car);
4. complement-verb (CPL V): to link to the
verb the complements expressed as GP or PV
which may be adjuncts or indirect objects, as
between en quelle ann?ee and construit in en
quelle ann?ee a-t on construit la premi`ere au-
tomobile (In which year did we build the first
car);
5. modifier-verb (MOD V): concerns the con-
stituants which certainly modify the verb,
and are not mandatory, as adverbs or adjunct
clauses, as between profond?ement or quand
la nuit tombe and dort in Jean dort pro-
fond?ement quand la nuit tombe (Jean deeply
sleeps when the night falls);
6. complementor (COMP): to link the intro-
ducer and the verb kernel of a subordinate
clause, as between qu? and viendra in Je
pense qu?il viendra (I think that he will
come); it is also used to link a preposition and
a noun phrase when they are not contiguous,
preventing us to annotate them as GP;
7. attribute-subject/object (ATB SO): between
the attribute and the verb kernel, and precis-
ing that the attribute is relative to (a) the sub-
ject as between grand and est in il est grand
), or (b) the object as between ?etrange and
trouve in il trouve cette explication ?etrange;
8. modifier-noun (MOD N): to link to the noun
all the constituents which modify it, as the ad-
jective, the genitive, the relative clause... This
dependency is annotated between unique and
fen?etre in l?unique fen?etre (the unique win-
dow) or between de la chambre and la porte
in la porte de la chambre (the bedroom door);
9. modifier-adjective (MOD A): to relate to the
adjective the constituents which modify it, as
between tr`es et belle in ?la tr`es belle collec-
tion (the very impressive collection) or be-
tween de son fils and fi`ere in elle est fi`ere de
son fils (she is proud of her son);
10. modifier-adverb (MOD R): the same kind of
dependency than MOD A for the adverbs, as
between tr`es and gentiment in elle vient tr`es
gentiment (she comes very kindly);
11. modifier-preposition (MOD P): to relate to
a preposition what modifies it, as between
peu and avant in elle vient peu avant lui (she
comes just before him);
12. coordination (COORD): to relate the coor-
dinate and the coordinated elements, as be-
tween Pierre, Paul and et in Pierre et Paul
arrivent (Paul and Pierre are arriving);
13. apposition (APP): to link the elements which
are placed side by side, when they refer to the
same object, as between le d?eput?e and Yves
Tavernier in Le d?eput?e Yves Tavernier ... (the
Deputy Yves Tavernier...);
14. juxtaposition (JUXT): to link constituents
which are neither coordinate nor in an appo-
sition relation, as in enumeration. It also links
clauses as on ne l?entendait et elle ?etait in
on ne l? entendait plus ... elle ?etait peut-?etre
morte (we did not hear her any more... per-
haps she was dead).
Some dependencies are illustrated in the two an-
notated sentences illutrated in figure . These anno-
tations have been made using EasyRef, a specific
Web annotation tool developed by INRIA.
4 PASSAGE First Evaluation Campaign
4.1 Evalution Service
The first PASSAGE evaluation campaign was
carried out in two steps. During the ini-
tial one-month development phase, a develop-
ment corpus was used to improve the quality of
40
Figure 2: Example of two sentences annotations
parsers. This development corpus from the TECH-
NOLANGUE/EASY is composed of 40,000 sen-
tences, out of which 4,000 sentences have been
manually annotated for the gold standard. Based
on these annotated sentences, an automatic WEB-
based evaluation server provides fast performance
feedback to the parsers? developers. At the end
of this first phase, each participant indicated what
he thought was his best parser run and got evalu-
ated on a new set of 400 sentences selected from
another part of the developement corpus which
meanwhile had been manually annotated for the
purpose and kept undisclosed.
The two phases represent a strong effort for the
evaluators. To avoid adding the cost of managing
the distribution and installation of the evaluation
package at each developer?s site, the solution of the
WEB evaluation service was chosen. A few infras-
tructures have been already experimented in NLP,
like GATE (Cunningham et al, 2002) infrastruc-
tures, but to our knowledge none has been used to
provide an WEB-based evaluation service as PAS-
SAGE did. The server was designed to manage
two categories of users: parser developers and or-
ganizers. To the developers, it provides, almost in
real time, confidential and secure access to the au-
tomatic evaluation of their submitted parses. To
the organizers, it give access to statistics enabling
them to follow the progress made by the develop-
ers, and easy management of the test phase. The
evaluation server provides, through a simple WEB
browser, access to both coarse and fine grain statis-
tics to a developer?s performance evaluation, glob-
ally for the whole corpus, at the level of a partic-
ular syntactic annotation or of a particular genre
specific subcorpus, and also at the level of a single
annotation for a particular word form.
Figure 3: Overall functional relations results
4.2 Performance Results
Ten systems participated to the constituents anno-
tation task. For most of the systems, F-measure is
up to 90% and only three systems are between 80%
and 90%. The trend is quite the same for Recall
and Precision. Around 96.5% of the constituents
returned by the best system are correct and it found
95.5% of the constituents present in gold standard.
Figure 3 shows the results of the seven systems that
participated to the functional relations annotation
task. Performance is lower than for constituents
and differences between systems are larger, an evi-
dence that the task remains more difficult. No sys-
tems gets a performance above 70% in F-measure,
three are above 60% and two above 50%. The last
two systems are above 40%.
4.3 Systems Improvements
The higher system gets increasing results from the
beginning of the development phase to the test
phase for both constituents and relations. How-
ever, although the increase for relations is rather
continuous, constituents results grow during the
first few development evaluations, then reach a
threshold from which results do not vary. This
can be explained by the fact that the constituent
scores are rather high, while for relations, scores
are lower and starting from low scores.
Using the evaluation server, system improves
its performance by 50% for the constituents and
600% for the relations, although performance vary
according to the type of relation or constituent.
Moreover, in repeating development evaluations,
another consequence was the convergence of pre-
cision and recall.
41
5 Parser?s outputs combination
The idea to combine the output of systems partic-
ipating to an evalauation campaign in order to ob-
tain a combination with better performance than
the best one was invented to our knowledge by J.
Fiscus (Fiscus, 1997) in a DARPA/NIST speech
recognition evaluation (ROVER/Reduced Output
Voting Error Reduction). By aligning the out-
put of the participating speech transcription sys-
tems and by selecting the hypothesis which was
proposed by the majority of the systems, he ob-
tained better performances than these of the best
system. The idea gained support in the speech pro-
cessing community(L?o?of et al, 2007) and in gen-
eral better results are obtained with keeping only
the output of the two or three best performing sys-
tems, in which case the relative improvement can
go up to 20% with respect to the best performance
(Schwenk and Gauvain, 2000). For text process-
ing, the ROVER procedure was applied to POS
tagging (Paroubek, 2000) and machine translation
(Matusov et al, 2006).
In our case, we will use the text itself to realign
the annotations provided by the various parser be-
fore computing their combination, as we did for
our first experiments with the EASY evaluation
campaign data (Paroubek et al, 2008). Since it
is very likely taht the different parsers do not use
the same word and sentence segmentation, we will
realign all the data along a common word and sen-
tence segmentation obtained by majority vote from
the different outputs.
But our motivation for using such procedure
is not only concerned with performance improve-
ment but also with the obtention of a confidence
measure for the annotation since if all systems
agree on a particular annotation, then it is very
likely to be true.
At this stage many options are open for the way
we want to apply the ROVER algorithm, since we
have both constituents and relations in our anno-
tations. We could vary the selection order (be-
tween constituents and relations), or use differ-
ent comparison functions for the sources/targets of
constituents/relations(Patrick Paroubek, 2006), or
perform incremental/global merging of the annoa-
tions, or explore different weightings/thresholding
strategies etc. In passage, ROVER experiments
are only beginning and we have yet to determine
which is the best strategy before applying it to
word and sentence free segmentation data. In the
early experiment we did with the ?EASy classic?
PASSAGE track which uses a fixed word and sen-
tence segmentation, we measured an improvement
in precision for some specific subcorpora and an-
notations but improvement in recall was harder to
get.
6 Conclusion
The definition of a common interchange syntactic
annotation format is an essential element of any
methodology aiming at the creation of large an-
notated corpora from the cooperation of parsing
systems to acquire new linguistic knowledge. But
the formalism aquires all of its value when backed-
up by the deployment of a WEB-based evaluation
service as the PASSAGE examples shows. 167
experiments were carried out during the develop-
ment phase (around 17 experiments per participant
in one month). The results of the test phase were
available less than one hour after the end of the de-
velopment phase. The service proved so success-
ful that the participants asked after the evaluation,
that the evaluation service be extended to support
evaluation as a perennial service
References
Cahill, Aoife, Michael Burke, Ruth O?Donovan, Josef
Van Genabith, and Andy Way. 2004. Long-distance
dependency resolution in automatically acquired
wide-coverage pcfg-based lfg approximations. In
Proceedings of the 42nd Meeting of the Association
for Computational Linguistics (ACL?04), Main Vol-
ume, pages 319?326, Barcelona, Spain, July.
Carroll, J., D. Lin, D. Prescher, and H. Uszkoreit.
2002. Proceedings of the workshop beyond parse-
val - toward improved evaluation measures for pars-
ing systems. In Proceedings of the 3rd International
Conference on Language Resources and Evaluation
(LREC), Las Palmas, Spain.
Cunningham, Hamish, Diana Maynard, Kalina
Bontcheva, and Valentin Tablan. 2002. Gate:
an architecture for development of robust hlt ap-
plications. In ACL ?02: Proceedings of the 40th
Annual Meeting on Association for Computational
Linguistics, pages 168?175, Morristown, NJ, USA.
Association for Computational Linguistics.
Declerck, T. 2006. Synaf: towards a standard for syn-
tactic annotation. In In proceedings of the fifth in-
ternational conference on Language Resources and
Evaluation (LREC 2006), Genoa, Italy, May. ELRA.
Fiscus, Jonathan G. 1997. A post-processing system
to yield reduced word error rates: recognizer output
voting error reduction (rover). In In proceedings of
42
the IEEE Workshop on Automatic Speech Recogni-
tion and Understanding, pages 347?357, Santa Bar-
bara, CA.
Francopoulo, G., T. Declerck, V. Sornlertlamvanich,
E. de la Clergerie, and M. Monachini. 2008. Data
category registry: Morpho-syntactic and syntactic
profiles. Marrakech. LREC.
Francopoulo, Gil. 2008. Tagparser: Well on the way
to iso-tc37 conformance. In In proceedings of the
International Conference on Global Interoperability
for Language Resources (ICGL), pages 82?88, Hong
Kong, January.
Gendner, V?eronique, Gabriel Illouz, Mich`ele Jardino,
Laura Monceaux, Patrick Paroubek, Isabelle Robba,
and Anne Vilnat. 2003. Peas the first instanciation
of a comparative framework for evaluating parsers of
french. In Proceedings of the 10
th
Conference of the
European Chapter fo the Association for Computa-
tional Linguistics, pages 95?98, Budapest, Hungary,
April. ACL. Companion Volume.
Hockenmaier, Julia and Mark Steedman. 2007. Ccg-
bank: A corpus of ccg derivations and dependency
structures extracted from the penn treebank. Com-
putational Linguistics, 33(3):355?396.
Ide, N. and L. Romary. 2002. Standards for language
ressources. Las Palmas. LREC.
L?o?of, J., C. Gollan, S. Hahn, G. Heigold, B. Hoffmeis-
ter, C. Plahl, D. Rybach, R. Schl?uter, , and H. Ney.
2007. The rwth 2007 tc-star evaluation system for
european english and spanish. In In proceedings of
the Interspeech Conference, pages 2145?2148.
Matusov, Evgeny, N. Ueffing, and Herman Ney. 2006.
Automatic sentence segmentation and punctuation
prediction for spoken language translation. In Pro-
ceedings of the International Workshop on Spo-
ken Language Translation (IWSLT), pages 158?165,
Trento, Italy.
de la Clergerie, Eric, Christelle Ayache, Ga?el de Chal-
endar, Gil Francopoulo, Claire Gardent, and Patrick
Paroubek. 2008a. Large scale production of syntac-
tic annotations for french. In In proceedings of the
First Workshop on Automated Syntactic Annotations
for Interoperable Language Resources at IGCL?08,
pages 45?52, Hong Kong, January.
de la Clergerie, Eric, Olivier Hamon, Djamel Mostefa,
Christelle Ayache, Patrick Paroubek, and Anne Vil-
nat. 2008b. Passage: from french parser evalua-
tion to large sized treebank. In ELRA, editor, In
proceedings of the sixth international conference on
Language Resources and Evaluation (LREC), Mar-
rakech, Morroco, May. ELRA.
Miyao, Yusuke, Takashi Ninomiya, and Jun?ichi Tsu-
jii. 2004. Corpus-oriented grammar development
for acquiring a head-driven phrase structure gram-
mar from the penn treebank. In In Proceedings of
the First International Joint Conference on Natural
Language Processing (IJCNLP-04).
Paroubek, Patrick, Isabelle Robba, Anne Vilnat, and
Christelle Ayache. 2008. Easy, evaluation of parsers
of french: what are the results? In Proceedings of
the 6
th
International Conference on Language Re-
sources and Evaluation (LREC), Marrakech, Mor-
roco.
Paroubek, Patrick. 2000. Language resources as by-
product of evaluation: the multitag example. In
In proceedings of the Second International Con-
ference on Language Resources and Evaluation
(LREC2000), volume 1, pages 151?154.
Patrick Paroubek, Isabelle Robba, Anne Vilnat Chris-
telle Ayache. 2006. Data, annotations and mea-
sures in easy - the evaluation campaign for parsers
of french. In ELRA, editor, In proceedings of
the fifth international conference on Language Re-
sources and Evaluation (LREC 2006), pages 315?
320, Genoa, Italy, May. ELRA.
Sagot, Beno??t and Pierre Boullier. 2006. Efficient
parsing of large corpora with a deep lfg parser. In
In proceedings of the sixth international conference
on Language Resources and Evaluation (LREC),
Genoa, Italy, May. ELDA.
Schwenk, Holger and Jean-Luc Gauvain. 2000. Im-
proved rover using language model information. In
In proceedings of the ISCA ITRW Workshop on Au-
tomatic Speech Recognition: Challenges for the new
Millenium, pages 47?52, Paris, September.
Vilnat, A., P. Paroubek, L. Monceaux, I. Robba,
V. Gendner, G. Illouz, and M. Jardino. 2004. The
ongoing evaluation campaign of syntactic parsing of
french: Easy. In Proceedings of the 4
th
International
Conference on Language Resources and Evaluation
(LREC), pages 2023?2026, Lisbonne, Portugal.
43
