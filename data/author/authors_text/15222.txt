Proceedings of the Fourth Linguistic Annotation Workshop, ACL 2010, pages 113?117,
Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational Linguistics
Cross-lingual Validity of PropBank in the Manual Annotation of French
Lonneke van der Plas Tanja Samardz?ic?
Linguistics Department
University of Geneva
Rue de Candolle 5, 1204 Geneva
Switzerland
{Lonneke.vanderPlas,Tanja.Samardzic,Paola.Merlo}@unige.ch
Paola Merlo
Abstract
Methods that re-use existing mono-lingual
semantic annotation resources to annotate
a new language rely on the hypothesis that
the semantic annotation scheme used is
cross-lingually valid. We test this hypoth-
esis in an annotation agreement study. We
show that the annotation scheme can be
applied cross-lingually.
1 Introduction
It is hardly a controversial statement that elegant
language subtleties and powerful linguistic im-
agery found in literary writing are lost in trans-
lation. Yet, translation preserves enough meaning
across language pairs to be useful in many appli-
cations and for many text genres.
The belief that this layer of meaning which is
preserved across languages can be formally rep-
resented and automatically calculated underlies
methods that use parallel corpora for the automatic
generation of semantic annotations through cross-
lingual transfer (Pado?, 2007; Basili et al, 2009).
A methodology similar in spirit ? re-use of the
existing resources in a different language ? has
also been applied in developing manually anno-
tated resources. Monachesi et al (2007) annotate
Dutch sentences using the PropBank annotation
scheme (Palmer et al, 2005), while Burchardt et
al. (2009) use the FrameNet framework (Fillmore
et al, 2003) to annotate a German corpus. In-
stead of building special lexicons containing the
specific semantic information needed for the an-
notation for each language separately, which is a
complex and time-consuming endeavour in itself,
these approaches rely on the lexicons already de-
veloped for English.
In this paper, we hypothesize that the level
of abstraction that is necessary to develop a se-
mantic lexicon/ontology for a single language
based on observable linguistic behaviour ? that
is a mono-lingual, item-specific annotation ? is
cross-linguistically valid. We test this hypothe-
sis by manually annotating French sentences using
the PropBank frame files developed for English.
It has been claimed that semantic parallelism
across languages is smaller when using the
PropBank semantic annotations instead of the
FrameNet scheme, because FrameNet is more ab-
stract and less verb-specific (Pado?, 2007). We are
working with the PropBank annotation scheme,
contrary to other works that use the FrameNet
scheme, such as Pado? (2007) and Basili et al
(2009). We choose this annotation for two main
reasons. First, the primary use of our annotation is
to serve as a gold standard in the task of syntactic-
semantic parsing. FrameNet does not have a prop-
erly sampled hand-annotated corpus of English,
by design. So we cannot use it for this task. Sec-
ond, in Merlo and Van der Plas (2009), the seman-
tic annotations schemes of PropBank and VerbNet
(Kipper, 2005) are compared, based on annotation
of the SemLink project (Loper et al, 2007). The
authors conclude that PropBank is the preferred
annotation for a joint syntactic-semantic setting.
If the PropBank annotation scheme is cross-
lingually valid, annotators can reach a consensus
and can do so swiftly. Thus, cross-lingual valid-
ity is measured by how well-defined the manual
annotation task is (inter-annotator agreement) and
by how hard it is to reach an agreement (pre- and
post-consensus inter-annotator agreement). In ad-
dition, we measure the impact of the level of ab-
straction of the predicate labels. Conversely, how
often labels do not transfer and distributions of dis-
agreements are indicators of lack of parallelism
across languages that we study both by quantita-
tive and qualitative analysis.
To preview the results, we find that the Prop-
Bank annotation scheme developed for English
can be applied for a large portion of French sen-
113
tences without adjustments, which confirms its
cross-lingual validity. A high level of inter-
annotator agreement is reached when the verb-
specific PropBank labels are replaced by less fine-
grained verb classes after annotating. Non-parallel
cases are mostly due to idioms and collocations.
2 Materials and Methods
Our choices of formal representation and of la-
belling scheme are driven by the goal of produc-
ing useful annotations for syntactic-semantic pars-
ing in a setting based on an aligned corpus. In the
following subsections we describe the annotation
scheme and procedure, the corpus, and phases of
annotation.
2.1 The PropBank Annotation Framework
We use the PropBank scheme for the manual anno-
tations. PropBank is a linguistic resource that con-
tains information on the semantic structure of sen-
tences. It consists of a one-million-word corpus
of naturally occurring sentences annotated with
semantic structures and a lexicon (the PropBank
frame files) that lists all the predicates (verbs) that
can be found in the annotated sentences and the
sets of semantic roles they introduce.
Predicates are marked with labels that specify
the sense of the verb in the particular sentence. Ar-
guments are marked with the labels A0 to A5. The
labels A0 and A1 have approximately the same
value with all verbs. They are used to mark in-
stances of typical AGENTS (A0) and PATIENTS
(A1). The value of other numbers varies across
verbs. Modifiers are annotated in PropBank with
the label AM. This label can have different exten-
sions depending on the semantic type of the con-
stituent, for example locatives and adverbials.
2.2 Annotation Procedure
Annotators have access to PropBank frame files
and guidelines adapted for the current task. The
frame files provide verb-specific descriptions of all
possible semantic roles and illustrate these roles
with examples as shown for the verb paid in (1)
and the verb senses of pay in Table 1. Annotators
need to look up each verb in the frame files to be
able to label it with the right verb sense and to be
able to allocate the arguments consistently.
(1) [A0 The Latin American nation] has
[REL?PAY.01 paid] [A1 very little] [A3 on its
debt] [AM?TMP since early last year].
Frame Semantic roles
pay.01 A0: payer or buyer
A1: money or attention
A2: person being paid, destination of attention
A3: commodity, paid for what
pay.02 A0: payer
pay off A1: debt
A2: owed to whom, person paid
pay.03 A0: payer or buyer
pay out A1: money or attention
A2: person being paid, destination of attention
A3: commodity, paid for what
pay.04 A1: thing succeeding or working out
pay.05 A1: thing succeeding or working out
pay off
pay.06 A0: payer
pay down A1: debt
Table 1: The PropBank lexicon entry for pay.
In our cross-lingual setting, annotators used
the English PropBank frame files to annotate the
French sentences. This means that for every pred-
icate they find in the French sentence, they need
to translate it, and find an English verb sense that
is applicable to the French verb. If an appropri-
ate entry cannot be found in the frame files for a
given predicate, the annotator is instructed to use
the ?dummy? label for the predicate and fill in the
roles according to their own insights.
For the annotation of sentences we use an adap-
tation of the user-friendly, freely available Tree
Editor (TrEd, Pajas and S?te?pa?nek, 2008). The tool
shows the syntactic analysis and the plain sentence
in the same window allowing the user to add se-
mantic arcs and labels to the nodes in the syntactic
dependency tree.
The decision to show syntactic information is
merely driven by the fact that we want to guide the
annotator in selecting the heads of phrases during
the annotation process. The sentences are parsed
by a syntactic parser (Titov and Henderson, 2007)
that we trained on syntactic dependency annota-
tions for French (Candito et al, 2009). Although
the parser is state-of-the-art (87.2% Labelled At-
tachment Score), in case of parse errors, we ask
annotators to ignore the errors of the parser and
put the label on the actual head.
2.3 Corpus
We selected the French sentences for the man-
ual annotation from the parallel Europarl corpus
(Koehn, 2005). Because translation shifts are
known to pose problems for the automatic cross-
lingual transfer of semantic roles (Pado?, 2007)
and for machine translation (Ozdowska and Way,
114
2009), and these are more likely to appear in in-
direct translations, we decided to select only those
parallel sentences, for which we can infer from the
labels used in Europarl that they are direct trans-
lations from English to French, or vice versa. We
selected 1040 sentences for annotation (40 in to-
tal for the two training phases, 100 for calibration,
and 900 for the main annotation phase.)1
2.4 Annotation Phases
The training procedure described in Figure 1
is inspired by the methodology indicated in
Pado? (2007). A set of 130 sentences were anno-
tated manually by four annotators with very good
proficiency in both French and English for the
training and the calibration phase. The remaining
900 sentences are annotated by one annotator (out
of those four), a trained linguist. Inter-annotator
agreement was measured at several points in the
annotation process marked with an arrow in Fig-
ure 1. The guidelines were adjusted after the train-
ing phase.
? Training phase
-TrainingA: 10 sentences, all annotators together
-TrainingB: 30 sentences, all annotators individually?
-Reach consensus on Training B?
? Calibration phase
-100 sentences by main annotator, one third of those by
each of the other 3 annotators?
? Main annotation phase
-900 sentences by main annotator
Figure 1: The annotation phases.
3 Results
Cross-lingual validity is measured by comparing
inter-annotator agreement at several stages in the
annotation, by measuring the agreement on less
specific predicate labelling, and by a quantitative
and qualitative analysis of non-parallel cases.
3.1 Inter-annotator Agreement for Several
Annotation Phases
To assess the quality of the manual annotations we
measured the agreement between annotators as the
average F-measure of all pairs of annotators after
each phase of the annotation procedure.2 The first
1As usual practice in preprocessing for automatic align-
ment, the datasets were tokenised and lowercased and only
sentence pairs corresponding to a 1-to-1 alignment with
lengths ranging from 1 to 40 tokens on both French and En-
glish sides were considered.
2It is a known fact that measuring annotator agreement us-
ing the kappa score is problematic in categorisation tasks that
Predicates Arguments
Lab. F Unl. F Lab. F Unl. F
TrainingB 46 85 62 75
TrainingB(cons.) 95 97 91 95
Calibration 59 93 69 84
Table 2: Percent inter-annotator agreement (F-
measure) for labelled/unlabelled predicates and
for labelled/unlabelled arguments
row of Table 2 shows that the task is hard. But
the difference between the first row and the sec-
ond row shows that there were many differences
between annotators that could be resolved. After
discussions and individual corrections the scores
are between 91% and 95%. This indicates that
the task is well-defined. Row three shows that the
agreement in the calibration phase increases a lot
compared to the last training phase (row 1). This
might in part be due to the fact that the guidelines
were adjusted by the end of the training phase, but
could also be because the annotators are getting
more acquainted to the task and the software.
As expected, because annotators used the En-
glish PropBank frame files to annotate French
verbs, the task of labelling predicates proved more
difficult than labelling semantic roles. It results in
the lowest agreement scores overall. In the follow-
ing subsections we study the sources of disagree-
ment in predicate labelling in more detail.
3.2 Inter-annotator Agreement in Predicate
Labellings
Predicate labels in PropBank apply to particular
verb senses, for example walk.01 for the first sense
of the verb walk. Even though the senses are
coarser than, for example, the senses in Word-
Net (Fellbaum, 1998), the labels are rather spe-
cific. This specificity possibly poses problems
when working in a cross-lingual setting.
We compare the agreement reached using Prop-
Bank verb sense labels with the agreement reached
using the verb classifications from VerbNet (Kip-
per, 2005) and the mapping to PropBank labels
as provided in the type mappings of the SemLink
project3 (Loper et al, 2007). If two annotators
used two different predicate labels to annotate the
do not have a fixed number of items and categories (Burchardt
et al, 2006). The F-measure is a well-known measure used
for the evaluation of many task such as syntactic-semantic
parsing, the task that is the motivation for this paper. The
choice of the F-measure makes the comparison to the perfor-
mance of the future parser easier.
3(http://verbs.colorado.edu/semlink/)
115
same verb, but those verb senses belong to the
same verb class, we count those as correct4.
The average inter-annotator agreement is rela-
tively low when we compare the annotations on
the PropBank verb sense level: 59%. However, at
the level of verb classes, the inter-annotator agree-
ment increases to 81%. This raises the issue of
whether we should not label the predicates with
verb classes instead of verb senses. By using Prop-
Bank labels for the manual annotation and replac-
ing these with verb classes in post-processing, the
benefits are two-fold: We are able to reach a high
level of cross-lingual parallelism on the annota-
tions, while keeping the manual annotation task as
specific and less abstract as possible.
3.3 Analysis of Non-Parallel Cases
For a single annotator, the main measure of cross-
lingual validity is the percentage of dummy pred-
icates in the annotation. In the sentences from the
calibration and the main annotation phase from the
main annotator (1000 sentences in total), we find
130 predicates (tokens) for which the annotator
used the ?dummy? label.
Manual inspection reveals that the ?dummy? la-
bel is mainly used for French multi-word expres-
sions (82%), most of which can be translated by
a single English verb (47%), whereas others can-
not, because they are translated by a combination
that includes a form of ?be? that is not annotated
in PropBank (25%). The 47% of multi-word ex-
pressions that receive the ?dummy? label show the
annotator?s reluctance to put a single verb label on
a French multi-word expression. The annotation
guidelines could be adapted to instruct annotators
not to hesitate in such cases.
Similarly, collocations and idiomatic expres-
sions are the main sources of disagreement in
predicate labellings among annotators. We can
conclude that, as shown in studies on other lan-
guage pairs (Burchardt et al, 2009), collocations
and idiomatic expressions were identified as verb
uses where the verb?s predicate label cannot be
transferred directly from one language to another.
4 Discussion and Related Work
Burchardt et al (2009) use English FrameNet to
4The mappings from PropBank verb sense labels to Verb-
Net verb classes are one-to-many and not complete. We
counted a pair as matching if there exists a class to which
both verb senses belong. We found a verb class for both verb
senses in about 78% of the cases and discarded the rest.
annotate a corpus of German sentences manually.
They find that the vast majority of frames can be
applied to German directly. However, around one
third of the verb senses identified in the German
corpus were not covered by FrameNet. Also, a
number of German verbs were found to be under-
specified. Finally, some problems related to treat-
ing particular verb uses were identified, such as id-
ioms, metaphors, and support verb constructions.
Monachesi et al (2007) use PropBank labels for
semi-automatic annotation of a corpus of Dutch
sentences. Semantic roles were first annotated
using a rule-based semantic parser and then cor-
rected by one annotator. Although not all Dutch
verbs could be translated to an equivalent verb
sense in English, these cases were assessed as rel-
atively rare. What proved to be problematic was
identifying the correct label for modifiers.
Bittar (2009) makes use of cross-lingual lexi-
cal transfer in annotating French verbs with event
types, by adapting a small-scale English verb lex-
icon with specified event structure (TimeML).
The inter-annotator agreement in labelling pred-
icates reported in Burchardt et al (2009) reaches
85%, while our best score (when falling back to
verb classes) is 81%. However, unlike Burchardt
et al (2009) we did not introduce any new French
labels. We find, like Monachesi et al (2007), that
non-parallel cases are less frequent than what is re-
ported in Burchardt et al (2009), which could be
due to the properties of the annotations schemes.
5 Conclusions
We can conclude that the general task of anno-
tating French sentences using English PropBank
frame files is well-defined. Nevertheless, it is a
hard task that requires linguistic training. With re-
spect to the disagreements on labelling predicates,
we can conclude that a large part can be resolved
if we compare the annotations at the level of verb
classes instead of at the very fine-grained level of
verb senses. Non-parallel cases are mostly due to
idioms and collocations. Their rate is relatively
low and can be further reduced by adapting anno-
tation guidelines.
Acknowledgments
The research leading to these results has received fund-
ing from the EU FP7 programme (FP7/2007-2013) under
grant agreement nr 216594 (CLASSIC project: www.classic-
project.org). We would like to thank Goljihan Kashaeva and
James Henderson for valuable comments.
116
References
R. Basili, D. De Cao, D. Croce, B. Coppola, and A. Moschitti,
2009. Computational Linguistics and Intelligent Text Pro-
cessing, chapter Cross-Language Frame Semantics Trans-
fer in Bilingual Corpora, pages 332?345. Springer Berlin
/ Heidelberg.
A. Bittar. 2009. Annotation of events and temporal expres-
sions in French texts. In Proceedings of the third Linguis-
tic Annotation Workshop (LAW III), pages 48?51, Suntec,
Singapore.
A. Burchardt, K. Erk, A. Frank, A. Kowalski, S. Pado?, and
M. Pinkal. 2006. The SALSA corpus: a German cor-
pus resource for lexical semantics. In Proceedings of the
5th International Conference on Language Resources and
Evaluation (LREC 2006), pages 969?974, Genoa, Italy.
A. Burchardt, K. Erk, A. Frank, A. Kowalski, S. Pado, and
M. Pinkal, 2009. Multilingual FrameNets in Computa-
tional Lexicography: Methods and Applications, chapter
FrameNet for the semantic analysis of German: Annota-
tion, representation and automation, pages 209?244. De
Gruyter Mouton, Berlin.
M.-H. Candito, B. Crabbe?, P. Denis, and F. Gue?rin.
2009. Analyse syntaxique du franc?ais : des constitu-
ants aux de?pendances. In Proceedings of la Confe?rence
sur le Traitement Automatique des Langues Naturelles
(TALN?09), Senlis, France.
C. Fellbaum. 1998. WordNet, an electronic lexical database.
MIT Press.
C. J. Fillmore, R. Johnson, and M.R.L. Petruck. 2003. Back-
ground to FrameNet. International journal of lexicogra-
phy, 16.3:235?250.
K. Kipper. 2005. VerbNet: A broad-coverage, comprehen-
sive verb lexicon. Ph.D. thesis, University of Pennsylvnia.
P. Koehn. 2005. Europarl: A parallel corpus for statistical
machine translation. In Proceedings of the MT Summit,
pages 79?86, Phuket, Thailand.
E. Loper, S-T Yi, and M. Palmer. 2007. Combining lexical
resources: Mapping between PropBank and VerbNet. In
Proceedings of the 7th International Workshop on Com-
putational Semantics (IWCS-7), pages 118?129, Tilburg,
The Netherlands.
P. Merlo and L. van der Plas. 2009. Abstraction and gen-
eralisation in semantic role labels: PropBank, VerbNet
or both? In Proceedings of the Joint Conference of the
47th Annual Meeting of the ACL and the 4th International
Joint Conference on Natural Language Processing of the
AFNLP, pages 288?296, Suntec, Singapore.
P. Monachesi, G. Stevens, and J. Trapman. 2007. Adding
semantic role annotation to a corpus of written Dutch.
In Proceedings of the Linguistic Annotation Workshop
(LAW), pages 77?84, Prague, Czech republic.
S. Ozdowska and A. Way. 2009. Optimal bilingual data for
French-English PB-SMT. In Proceedings of the 13th An-
nual Conference of the European Association for Machine
Translation (EAMT?09), pages 96?103, Barcelona, Spain.
S. Pado?. 2007. Cross-lingual Annotation Projection Mod-
els for Role-Semantic Information. Ph.D. thesis, Saarland
University.
P. Pajas and J. S?te?pa?nek. 2008. Recent advances in a feature-
rich framework for treebank annotation. In Proceedings of
the 22nd International Conference on Computational Lin-
guistics (Coling 2008), pages 673?680, Manchester, UK.
M. Palmer, D. Gildea, and P. Kingsbury. 2005. The Proposi-
tion Bank: An annotated corpus of semantic roles. Com-
putational Linguistics, 31:71?105.
I. Titov and J. Henderson. 2007. A latent variable model
for generative dependency parsing. In Proceedings of the
International Conference on Parsing Technologies (IWPT-
07), pages 144?155, Prague, Czech Republic.
117
Proceedings of the 2010 Workshop on NLP and Linguistics: Finding the Common Ground, ACL 2010, pages 52?60,
Uppsala, Sweden, 16 July 2010. c?2010 Association for Computational Linguistics
Cross-lingual variation of light verb constructions: using parallel corpora
and automatic alignment for linguistic research
Tanja Samardz?ic?
Linguistics Department
University of Geneva
Tanja.Samardzic@unige.ch
Paola Merlo
Linguistics Department
University of Geneva
Paola.Merlo@unige.ch
Abstract
Cross-lingual parallelism and small-scale
language variation have recently become
subject of research in both computational
and theoretical linguistics. In this arti-
cle, we use a parallel corpus and an auto-
matic aligner to study English light verb
constructions and their German transla-
tions. We show that parallel corpus data
can provide new empirical evidence for
better understanding the properties of light
verbs. We also study the influence that the
identified properties of light verb construc-
tions have on the quality of their automatic
alignment in a parallel corpus. We show
that, even though characterised by limited
compositionality, these constructions can
be aligned better than fully compositional
phrases, due to an interaction between the
type of light verb construction and its fre-
quency.
1 Introduction
Fine-grained contrastive studies traditionally be-
long to the field of applied linguistics, notably to
translation and second language acquisition stud-
ies. Recently, however, interest for contrastive
studies has been renewed due to developments
in the general theory of language (the notion of
micro-parameters (Kayne, 2000)) on the one hand,
and due to advances in natural language process-
ing based on the exploitation of parallel corpora,
on the other hand.
Parallel corpora are collections of translations
with explicit alignment of sentences. They are im-
portant resources for the automatic acquisition of
the cross-linguistic translation equivalents that are
needed for machine translation. There is also in-
terest in using parallel corpora to automatically de-
velop new annotated linguistic resources by pro-
jecting the annotation that already exists in one
language (usually English) (Pado?, 2007; Basili et
al., 2009). Such resources can be used for train-
ing systems for automatic parsing for different lan-
guages. Recently, parallel multilingual corpora
have also been used to improve performance in
mono-lingual tasks (Snyder et al, 2009).
For most of these applications, the aligned sen-
tences in the parallel corpora need to be analysed
into smaller units (phrases and words), which, in
turn, need to be aligned. Although crucial for suc-
cessful use of parallel corpora, word (and phrase)
alignment is still a challenging task (Och and Ney,
2003; Collins et al, 2005; Pado?, 2007).
Our research concentrates on one type of con-
struction that needs a special treatment in the task
of aligning corpora and projecting linguistic an-
notation from one language to another, namely
light verb constructions. These constructions, usu-
ally identified as paraphrases of verbs (e.g. have
a laugh means laugh, give a talk means talk),
are frequent, cross-lingually productive forms,
where simple-minded parallelism often breaks
down. Their meaning is partially uncomposi-
tional, formed in a conventional way, which means
that they cannot be analysed as regular construc-
tions and that they cannot be translated to another
language directly word by word. Unlike colloca-
tions and idioms, however, these constructions are
formed according to the same ?semi-productive?
pattern in different languages. Due to their cross-
lingual analysability, they can be expected to be
aligned at the word level in a parallel corpus, even
if their components are not direct word-to-word
translations of each other. This means that word
alignment of these constructions, needed for au-
tomatic translation and transferring annotations, is
possible, but it is not straight-forward.
An in-depth study of these constructions in the
specific context of parallel corpora and alignment
can cast new light on the correlation of their lin-
guistic and statistical properties. On the one hand,
52
the statistical large-scale analysis of the behaviour
of these constructions as the output of an align-
ment process provides novel linguistic informa-
tion, which enlarges the empirical base for the
analysis of these constructions, and complements
the traditional grammaticality judgements. On the
other hand, the linguistically fine-grained analysis
of the statistical behaviour of these constructions
provides linguistically-informed performance and
error analyses that can be used to improve align-
ers.
2 Two Types of Light Verb Constructions
and their Alignment
Light verb constructions have already been iden-
tified as one of the major sources of problems
in transferring semantic annotation between lan-
guages as close as English and German (Burchardt
et al, 2009). Light verb constructions introduce
two kinds of divergences that can pose a problem
for automatic word alignment. In the case of true
light verb constructions (Kearns, 2002), English
phrases such as have a laugh, give [stg.] a wipe,
and take a look typically correspond to German
single words, lachen, wischen, and blicken respec-
tively. Such correspondences can be expected to
result in actual parallel sentences where English
verbs have, give, and take would be either aligned
with the verbs lachen, wischen, and blicken re-
spectively or would have no alignment at all. Such
alignments are not common cases and can be ex-
pected to pose a problem to an automatic aligner.
Another type of divergence concerns construc-
tions with vague action verbs (Kearns, 2002). In
this case, English phrases such as make an agree-
ment, make a decision, and give a talk correspond
to German phrases einen Vertrag schliessen, eine
Entscheidung treffen, and einen Vortrag halten,
respectively. Parallel sentences containing these
constructions should be aligned so that English
nouns agreement, decision, and talk are aligned
with German nouns Vertrag, Entscheidung, and
Vortrag. At the same time, English verb make
should be aligned with German schliessen in the
first example, with treffen in the second, and give
should be aligned with halten in the third example.
Aligning the nouns should not pose any problem,
since these alignments are direct lexical transla-
tions (c.f. (LEO, 2006 9) online dictionary, for ex-
ample) and they can be expected to be aligned in
many different sentences. However, aligning the
verbs is necessarily more complicated, since they
are not direct translations of each other and cannot
be expected to be aligned in other contexts.1
However, the difference between the two types
of light verb constructions is not clear cut. They
are better seen as two ends of a continuum of verb
usages with different degrees of verbs? lightness
and different degrees of compositionality of the
meaning of constructions. (Stevenson et al, 2004;
Butt and Geuder, 2001; Grimshaw and Mester,
1988). Even though several English verbs have
been identified as having light usages (e.g. take,
make, have, give, pay), there has been little re-
search on the influence that the properties of the
heading light verb can have on the degree of se-
mantic compositionality of the construction.
The purpose of the present research is to exam-
ine the German translation equivalents of the range
of different English light verb constructions occur-
ring in a parallel corpus and study the differential
performance of a standard aligner on this language
pair for these constructions.
3 Experiments
Our study is based on the assumption that the qual-
ity and bijectivity of the alignment are propor-
tional to the corpus frequency and linguistic com-
positionality of the construction. Therefore, we
identify two aspects of the alignment of these con-
structions as the relevant objects of study.
First, we quantify the amount and nature of cor-
rect word alignments for light verb constructions
compared to regular verbs, as determined by hu-
man inspection. Given the described divergences
between English and German, it can be expected
that light verb constructions will be aligned with a
single word more often than constructions headed
by a regular verb. Assuming that the properties
of the heading light verbs do influence semantic
compositionality of the constructions, it can also
be expected that light verb constructions headed
by different verbs will be differently aligned to the
German translations, constituting different types
of constructions.
1Direct word-to-word English translations of schliessen
listed in the LEO dictionary, for example, are: infer, com-
prise, imply, close, close down, conclude, consummate, draw
up, lock, shut, shutdown, sign off, quit, while make is only
listed within the phrase that is translation for this particular
collocation. Similarly, English word translations for treffen
are: encounter, hook up, cross, get together, meet, meet up,
hit, hurt, score, strike, while make can only be found as a part
of the phrase-to-phrase translations.
53
Second, we evaluate the quality of automatic
word alignments of light verb constructions.
Current word alignment models are based on
the assumption that the best word alignments are
composed of the best word-to-word translations
(as an effect of using Expectation-Maximisation
for training). Factors in the translations that de-
viate from one-to-one alignments are often lex-
ically specific (fertility) and require sufficient
statistics. Because of the interaction of these
properties of the alignment model and the semi-
compositionality of light verb constructions, these
constructions can be expected to pose a problem
for automatic word alignment. Specifically, we ex-
pect lower overall quality of word alignment in the
sentences containing light verb constructions than
in the sentences that contain corresponding regular
constructions.
As indicated, however, we also expect that the
quality of automatic word alignment will be influ-
enced by different distributional phenomena that
are not necessarily related to the linguistic prop-
erties of parallel texts, in particular related to fre-
quency of some of the components of the construc-
tion.
These predictions about the alignment of light
verb constructions in English and German and
their realisations in a corpus are examined in an
experiment.
3.1 Materials and Methods
A random sample of instances of each of the de-
fined types of construction was extracted from a
large word-aligned parallel corpus and manually
examined.
3.1.1 Corpus
The instances of the phrases were taken from the
English-German portion of the Europarl corpus
(Koehn, 2005) that contains the proceedings of the
sessions held in 1999, irrespective of the source
language and of the direction of translation. Be-
fore sampling, the corpus was word-aligned using
GIZA++ (Och and Ney, 2003). Alignments were
performed in both directions, with German as the
target language and with English as the target lan-
guage.
3.1.2 Word alignment using GIZA++
The program for automatic word alignment,
GIZA++, has been developed within a system for
automatic translation. It implements a series of
statistical word-based translation models. In these
models, word alignment is represented as a single-
valued function, mapping each word in the tar-
get sentence to one word in the source sentence.
To account for the fact that some target language
words cannot be aligned with any source language
word, a special empty word (?NULL?) is intro-
duced in the source sentence.
The definition of word alignment does not al-
low many-to-many mappings between the words
of two languages, needed for representing align-
ment of non-compositional multi-word expres-
sions. However, it allows aligning multiple words
in one language to a single word in the other lan-
guage, which is needed for successful alignment
of English light verb constructions.
3.1.3 Sampling phrase instances
To study light verb constructions in a parallel cor-
pus systematically, we group the instances of the
constructions into two types: light verb construc-
tions headed by the verb take, as an example of
true light verb constructions, and those headed
by the verb make, as an example of vague action
verbs. We compare both types of light verb con-
structions to regular constructions headed by the
verbs which are WordNet synonyms of the verb
make (create, produce, draw, fix, (re)construct,
(re)build, establish) with the same subcategoriza-
tion frame.
We analyse three samples of the constructions,
one for each of the types defined by the heading
verb. Each sample contains 100 instances ran-
domly selected from the word-aligned parallel cor-
pus. The constructions are represented as ordered
pairs of words, where the first word is the verb
that heads the construction and the second is the
noun that heads the verb?s complement. Only the
constructions where the complement is the direct
object were included in the analysis.2
3.1.4 Data collection
The following data were collected for each occur-
rence of the English word pairs.
The word or words in the German sentence that
are actual translation of the English words were
identified. If either the English or German verb
2This means that constructions such as take something
into consideration were not included. The only exception to
this were the instances of the construction take something into
account. This construction was included because it is used as
a variation of take account of something with the same trans-
lations to German.
54
form included auxiliary verbs or modals, these
were not considered. Only the lexical part of the
forms were regarded as word translations.
We then determine the type of mapping be-
tween the translations. If the German transla-
tion of an English word pair includes two words
too (e.g. take+decision? Beschluss+fassen), this
was marked as the ?2-2? type. If German trans-
lation is a single word, the mapping was marked
with ?2-1?. This type of alignment is further dis-
tinguished into ?2-1N? and ?2-1V?. In the first
subtype, the English construction corresponds to
a German noun (e.g. initiative+taken ? Initia-
tive). In the second subtype, the English construc-
tion corresponds to a German verb (e.g. take+look
? anschauen). In the cases where a translation
shift occurs so that no translation can be found,
the mapping is marked with ?2-0?.
We also collect the information on automatic
alignment for each element of the English word
pair for both alignment directions. These data
were collected for the elements of English word
pairs (verbs and nouns) separately. The alignment
was assessed as ?good? if the word was aligned
with its actual translation, as ?bad? if the word was
aligned with some other word, and as ?no align? if
no alignment was found. Note that the ?no align?
label could only occur in the setting were English
was the source language, since all the words in the
sentence had to be aligned in the case where it was
the target language.
For example, a record of an occurrence of the
English construction ?make+proposal? extracted
from the bi-sentence in (1) 3 would contain the in-
formation given in (2).
(1) Target language German
EN: He made a proposal.
DE: Er(1) hat(1) einen(3) Vorschlag(4)
gemacht(3).
Target language English
DE: Er hat einen Vorschlag gemacht.
EN: He(1) made(5) a(3) proposal(4).
(2) English instance: made + proposal
German alignment: Vorschlag + gemacht
Type of mapping: 2-2
3Glosses:
Er hat einen Vorschlag gemacht.
he has a proposal made
The numbers in the brackets in the target sentences indicate
the position of the automatically aligned source word.
English
LVC
take
LVC
make
Regular
G
er
m
an
tra
ns
la
tio
n 2? 2 57 50 94
2? 1N 8 18 2
2? 1V 30 28 2
2? 0 5 4 2
Total 100 100 100
Table 1: Types of mapping between English con-
structions and their translation equivalents in Ger-
man.
Automatic alignment, target German, noun:
good, verb: no align
Automatic alignment, target English, noun:
good, verb: good
4 Results
In this section, we present the results of the analy-
ses of both correct (manual) and automatic align-
ment of the three types of constructions, pointing
out the relevant asymmetries.
4.1 Results of Manual Alignment
Table 1 shows how many times each of the four
types of mapping (2-2; 2-1N; 2-1V; 2-0) between
English constructions and their German transla-
tion equivalents occurs in the sample.
We can see that the three types of construc-
tions tend to be mapped to their German equiva-
lents in different ways. First, both types of light
verb constructions are mapped to a single Ger-
man word much more often than the regular con-
structions (38 instances of light verb constructions
with take and 46 instances of light verb construc-
tions with make vs. only 4 instances of regular
constructions.). Confirming our initial hypothe-
sis, this result suggests that the difference between
fully compositional phrases and light verb con-
structions in English can be described in terms of
the degree of the ?2-1? mapping to German trans-
lation equivalents.
An asymmetry can be observed concerning the
two subtypes of the ?2-1? mapping too. The Ger-
man equivalent of an English construction is more
often a verb if the construction is headed by the
verb take (in 30 occurrences, that is 79% of the 2-
1 cases) than if the construction is headed by the
verb make (28 occurrences, 61% cases).
55
DE EN
LVCs with
take
Both EN words 5 57
EN noun 63 79
EN verb 6 57
LVCs with
make
Both EN words 5 40
EN noun 58 58
EN verb 6 52
Regular
construction
Both EN words 26 42
EN noun 68 81
EN verb 32 47
Table 2: Well-aligned instances of LVCs with take,
with make, and with regular constructions (out of
100), produced by an automatic alignment, in both
alignment directions (target is indicated).
In the case where the German translation equiv-
alent for an English construction is a verb, both
components of the English construction are in-
cluded in the corresponding German verb, the ver-
bal category of the light verb and the lexical con-
tent of the nominal complement. These instances
are less compositional, more specific and id-
iomatic (e.g. take+care? ku?mmern, take+notice
? beru?cksichtigen).
On the other hand, English constructions that
correspond to a German noun are more compo-
sitional, less idiomatic and closer to the regular
verb usages (e.g. make+proposal ? Vorschlag,
make+changes ? Korrekturen). The noun that
is regarded as their German translation equivalent
is, in fact, the equivalent of the nominal part of
the construction, while the verbal part is simply
omitted. This result suggests that English light
verb constructions with take are less composi-
tional than the light verb constructions with make.
4.2 Results on Automatic Alignment
We evaluate the quality of automatic alignment of
light verb constructions in comparison with reg-
ular phrases taking into account two factors, the
alignment direction and the frequency of the ele-
ments of the constructions. The results are pre-
sented in the next two sections.
4.2.1 Direction of Alignment
Table 2 shows how the quality of automatic align-
ment varies depending on the direction of align-
ment, as well as on the type of construction. Re-
call that more than one target word can be aligned
to the same source word and all words of the target
have to be aligned.
It can be noted that all the three types of con-
structions are better aligned if the target language
is English. However, the difference in the quality
is bigger in light verb constructions than in regular
constructions, clearly because in this direction the
multi-word property of the English light verb con-
structions can be represented. Both words are well
aligned in light verb constructions with take in 57
cases and with make in 40 cases if the target lan-
guages is English, which is comparable with regu-
lar constructions (42 cases). However, if the target
language is German, both types of light verb con-
structions are aligned well (both words) in only 5
cases, while regular constructions are well aligned
in 26 cases.
Looking into the alignment of the elements of
the constructions (verbs and nouns) separately, we
can notice that nouns are generally better aligned
than verbs for all the three types of constructions,
and in both directions. However, this difference
is not the same in all cases. The difference in
the quality of alignment of nouns and verbs is
the same in both alignment directions for regular
constructions, but it is more pronounced in light
verb constructions if German is the target. On the
other hand, if English is the target, the difference
is smaller in light verb construction than in regular
phrases. These results suggest that the direction of
alignment influences more the alignment of verbs
than the alignment of nouns in general. This influ-
ence is much stronger in light verb constructions
than in regular constructions.
Finally, our initial hypothesis that the quality of
alignment of light verb constructions is lower than
the quality of alignment of regular constructions
has only been confirmed in the case where German
is the target language (both words well aligned in
26 cases, compared to only 5 cases in both types
of light verb constructions). Regular verbs are es-
pecially better aligned than light verbs in this case
(32 : 6). However, if the target is English, the qual-
ity of alignment of regular constructions is simi-
lar to that of light verb constructions with make
(42 and 40 good alignments respectively), while
the constructions with take are aligned even bet-
ter than the other two types (57 good alignments).
These results suggest that the type of construction
which is the least compositional and the most id-
iomatic of the three is best aligned if the direction
of alignment suits its properties.
56
Frequency take LVC make LVC Regular
Low 12 25 62
High 76 35 8
Table 3: The three types of constructions parti-
tioned by the frequency of the complements in the
sample.
Well aligned
Freq take LVC make LVC Regular
Low Both 4 33 8 32 21 34
Freq N 8 66 8 32 47 75
V 4 33 12 48 53 85
High Both 47 62 18 51 4 50
Freq N 64 84 27 77 8 100
V 58 76 18 51 4 50
Table 4: Counts and percentages of well-aligned
instances of the three types of constructions in re-
lation with the frequency of the complements in
the sample. The percentages represent the number
of well-aligned instances out of the overall number
of instances within one frequency range. English
is the target language.
4.2.2 Frequency
Since the quality of alignment of the three types
of constructions proved different from what was
expected in the case where English was the target
language, we examine further the automatic align-
ment in this direction. In particular, we study its
interaction with frequency.
The frequency of the nouns is defined as the
number of occurrences in the sample. It ranges
from 1 to 20 occurrences in the sample of 100 in-
stances. The instances of the constructions were
divided into three frequency ranges: instances
containing nouns with 1 occurrence were con-
sidered as low frequency items; those contain-
ing nouns that occurred 5 and more times in the
sample were considered as high frequency items;
nouns occurring 2, 3, and 4 times were considered
as medium frequency items. Only low and high
frequency items were considered in this analysis.
Table 3 reports the number of instances belong-
ing to different frequency ranges. It can be noted
that light verb constructions with take exhibit a
small number of low frequency nouns. The num-
ber of low frequency nouns increases in the con-
structions with make (25/100), and it is much big-
ger in regular constructions (62/100). The op-
posite is true for high frequency nouns (LVCs
with take: 76/100, with make: 35/100, regular:
8/100). Such distribution of low/high frequency
items reflects different collocational properties of
the constructions. In the most idiomatic construc-
tions (with take), lexical selection is rather limited
which results in little variation. Verbs in regular
constructions select for a wide range of different
complements with little reoccurrence. Construc-
tions with make can be placed between these two
types.
Different trends in the quality of automatic
alignment can be identified for the three types of
constructions depending on the frequency range of
the complement in the constructions, as shown in
Table 4. The quality of alignment of both com-
ponents of the constructions is comparable for all
the three types of constructions in low frequency
items (in 33% of instances of light verb construc-
tions with take, 32% of light verb constructions
with make, and 34% of regular constructions both
the verb and the noun were well aligned). It is
also improved in high frequency items in all the
three types, compared to low frequency. However,
the improvement is bigger in light verb construc-
tions with take (62% well aligned cases) than in
LVCs with make (51%) and in regular construc-
tions (50%).4
Looking into the components of the construc-
tions separately, we can notice interesting differ-
ences in the quality of automatic alignment of
verbs. The proportion of well-aligned verbs in-
creases with the frequency of their complements in
light verb constructions with take (33% of low fre-
quency items compared to 76% of high frequency
items.) It stays almost the same in light verb con-
structions with make (48% of low frequency items
and 51% of high frequency items), and it even de-
creases in regular items (85% of low frequency
items compared to only 50% of high frequency
items).
5 Discussion
The results reported in the previous section con-
firm both components of our first hypothesis (on
the expected differences in cross-lingual mapping)
and refine the conditions under which the sec-
ond hypothesis (on the expected differences in the
quality of automatic alignment) is true. We discuss
4Note that the high frequency regular items are repre-
sented with only 8 instances, which is why the trends might
not be clear enough for this subtype.
57
these conclusions in detail here.
5.1 Manual Alignment
Recall that the first component of our first hypoth-
esis indicated that it is expected that light verb
constructions will be aligned with a single word
more often than constructions headed by a regular
verb.
The analysis of corpus data has shown that
there is a clear difference between English regu-
lar phrases and light verb constructions in the way
they are mapped to their translation equivalents in
German. Regular constructions are mapped word-
by-word, with the English verb being mapped to
the German verb, and the English noun to the Ger-
man noun. A closer look into the only 4 exam-
ples where regular constructions were mapped as
?2-1? shows that this mapping is not due to the
?lightness? of the verb. In two of these cases, it is
the content of the verb that is translated, not that
of the noun (produce+goods? Produktion; estab-
lishes+rights? legt). This never happens in light
verb constructions.
On the other hand, light verb constructions are
much more often translated with a single Ger-
man word. In both subtypes of the ?2-1? map-
ping of light verb constructions, it is the con-
tent of the nominal complement that is translated,
not that of the verb. The noun is either trans-
formed into a verb (take+look ? anschauen) or
it is translated directly with the verb being omitted
(take+initiative? Initiative).
This difference provides empirical grounds for
distinguishing between semantically full and se-
mantically impoverished verbs, a task that is often
difficult on the basis of syntactic tests, since they
often exhibit the same syntactic properties.
The second component of the first hypothesis
indicated that it was expected that the two types of
light verb constructions be differently aligned.
The finding that English light verb construc-
tions with take tend to be aligned more often with a
single German verb and less often to a single Ger-
man noun than the constructions with make justi-
fies classifying the instances into the types based
on the heading verb, which is not a common prac-
tice in the linguistic literature. It suggests that
some semantic or lexical properties of these verbs
can determine the type of the construction. More
precisely, the meaning of the constructions with
take can be regarded as less compositional than the
meaning of the constructions with make. This dif-
ference is also supported by the findings of a pre-
liminary study of Serbian translation equivalents
of these constructions (Samardz?ic?, 2008). English
constructions with take tend to be translated with
a single verb in Serbian, while the constructions
with make are usually translated word-by-word. 5
5.2 Automatic alignment
The second hypothesis conjectured that we would
find lower overall quality of word alignment in
the sentences containing light verb constructions
than in the sentences that contain corresponding
regular constructions. The findings of this re-
search show that the interactions between align-
ment and types of constructions is actually more
complicated than this simple hypothesis, in some
expected and some unexpected ways. To sum-
marise, we found, first, better alignment of regu-
lar constructions compared to light verb construc-
tions only if the target language is German; sec-
ond, overall, alignment if English is target is bet-
ter than if German is target; and thirdly, we found
a clear frequency by construction interaction in the
quality of alignment.
The quality of automatic alignment of both reg-
ular constructions and light verb constructions in-
teracts with the direction of alignment. First,
the alignment is considerably better if the target
language is English than if it is German, which
confirms the findings of (Och and Ney, 2003).
Second, the expected difference in the quality of
alignment between regular constructions and light
verb constructions has only been found in the di-
rection of alignment with German as the target
language, that is where the ?2-1? mapping is ex-
cluded. However, the overall quality of alignment
in this direction is lower than in the other.
This result could be expected, given the general
morphological properties of the two languages, as
well as the formalisation of the notion of word
alignment used in the system for automatic align-
ment. According to this definition, multiple words
in the target language sentence can be aligned with
a single word in the source language sentence,
but not the other way around. Since English is
5The difference in the level of semantic compositionality
of the constructions with take and make could follow from
some semantic properties of these verbs, such as different
aspectual properties or argument structures. However, es-
tablishing such a relation would require a more systematic
semantic study of light, as well as full lexical uses of these
verbs.
58
a morphologically more analytical language than
German, multiple English words often need to be
aligned with a single German word (a situation al-
lowed if English is the target but not if German is
the target).
The phrases in (3) illustrate the two most com-
mon cases of such alignments. First, English
tends to use functional words (the preposition of
in (3a)), where German applies inflection (geni-
tive suffixes on the article des and on the noun Ba-
nanensektors in (3b). Second, compounds are re-
garded as multiple words in English (banana sec-
tor), while they are single words in German (Ba-
nanensektors). This asymmetry explains both the
fact that automatic alignment of all the three types
of constructions is better when the target language
is English and that the alignment of light verb con-
structions is worse than the alignment of regular
phrases when it is forced to be expressed as one-
to-one mapping, which occurs when German is the
alignment target.
(3) a. the infrastructure of the banana sector
b. die Infrastruktur des Bananensektors
Practically, all these factors need to be taken
into consideration in deciding which version of
alignment should be taken, be it for evaluation or
for application in other tasks such as automatic
translation or annotation projection. The inter-
section of the two directions has been proved to
provide most reliable automatic alignment (Pado?,
2007; Och and Ney, 2003). However, it excludes,
by definition, all the cases of potentially useful
good alignments that are only possible in one di-
rection of alignment.
Linguistically, the fact that the expected differ-
ence in the quality of alignment between regular
constructions and light verb constructions has only
been found in the direction where English con-
structions could not be aligned with single German
words can be seen as another empirical indication
of semantic impoverishment of light verbs in com-
parison with full lexical verbs.
Finally, we found an unexpected frequency by
construction interaction (Table 4), which explains
the finding that regular phrases are not better
aligned than light verb constructions if English is
the target language (opposite to our second hy-
pothesis). This interaction, well known in lan-
guage processing and acquisition, occurs in those
cases where marked constructions are very fre-
quent. In our case, the marked construction is the
semi-compositional light verb construction with
take, which has frequent noun complements. In
this case, despite the non-regularity of the con-
struction, alignment is performed well if the di-
rection of alignment allows its mapping to a sin-
gle word. Also, with respect to this phenomenon,
the constructions with take behave more markedly
than those with make.
What is especially interesting about these data
is the fact that the alignment is different not just
between light verb constructions and regular con-
structions, but also between the two types of
light verb constructions. The constructions with
take exhibit more consistent properties of irregu-
lar items, while the constructions withmake can be
positioned somewhere between irregular and regu-
lar items. This additionally confirms the claim that
these two types of constructions differ in the level
of semantic compositionality, providing a basis for
an improvement in their linguistic account.
6 Conclusions and Future Work
In this paper we have proposed a contrastive study
of light verb constructions based on data collected
through alignments of parallel corpora. We have
shown how a linguistically refined analysis can
shed light on particularly difficult cases for an
alignment program, a useful result for improving
current statistical machine translation systems. We
have also shown how properties and behaviours of
these constructions that can be found only in large
parallel corpora and through sophisticated compu-
tational tools can shed light on the linguistic nature
of the constructions under study.
Much remains to be done, both in this general
methodology and for this particular kind of con-
struction. As an example, we note that the fact that
nouns are aligned better than verbs in all the three
types of constructions deserves more investiga-
tion. What we do not yet know is whether this fact
can be related to some known distributional differ-
ences between these two classes or not. It might
also mean that nominal lexical items are more sta-
ble across languages than verbal ones. This can
have implications for machine translations, as well
as for annotation projection, since the stable words
can be used as pivots for alignment and transfer al-
gorithms.
59
References
Roberto Basili, Diego De Cao, Danilo Croce, Bonaven-
tura Coppola, and Alessandro Moschitti. 2009.
Cross-language frame semantics transfer in bilin-
gual corpora. In Alexander F. Gelbukh, editor,
Proceedengs of the 10th International Conference
on Intelligent Text Processing and Computational
Linguistics, pages 332?345, Mexico City, Mexico.
Springer.
Aljoscha Burchardt, Katrin Erk, Anette Frank, An-
drea Kowalski, Sebastian Pado?, and Manfred Pinkal.
2009. FrameNet for the semantic analysis of Ger-
man: Annotation, representation and automation.
In Hans Boas, editor, Multilingual FrameNets in
Computational Lexicography: Methods and appli-
cations, pages 209?244. Mouton de Gruyter.
Miriam Butt and Wilhelm Geuder. 2001. On the
(semi)lexical status of light verbs. In Norbert Corver
and Henk van Riemsdijk, editors, Semilexical Cate-
gories: On the content of function words and the
function of content words, pages 323?370, Berlin.
Mouton de Gruyter.
Michael Collins, Philipp Koehn, and Ivona Kuc?erova?.
2005. Clause restructuring for statistical machine
translation. In Proceedings of the Annual Meet-
ing of the Association for Computational Linguistics
(ACL), pages 531?540, Ann Arbor. Association for
Computational Linguistics.
Jane Grimshaw and Armin Mester. 1988. Light verbs
and theta-marking. Linguistic Inquiry, 19:205?232.
Richard Kayne. 2000. Parameters and Universals.
Oxford University Press, New York.
Kate Kearns. 2002. Light verbs in English.
Manuscript.
Philipp Koehn. 2005. Europarl: A parallel corpus
for statistical machine translation. In Proceedings
of MT Summit 2005, Phuket, Thailand.
LEO. 2006-9. LEO Online Dictionary. LEO Dictio-
naryTeam, http://dict.leo.org.
Franz Josef Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Computational Linguistics, 29(1):19?52.
Sebastian Pado?. 2007. Cross-Lingual Annotation
Projection Models for Role-Semantic Information.
Ph.D. thesis, Saarland University.
Tanja Samardz?ic?. 2008. Light verb constructions in
English and Serbian. In English Language and Lit-
erature Studies ? Structures across Cultures, pages
59?73, Belgrade. Faculty of Philology.
Benjamin Snyder, Tahira Naseem, Jacob Eisenstein,
and Regina Barzilay. 2009. Adding more languages
improves unsupervised multilingual part-of-speech
tagging: a Bayesian non-parametric approach. In
Proceedings of Human Language Technologies: The
2009 Annual Conference of the North American
Chapter of the Association for Computational Lin-
guistics, pages 83?91, Boulder, Colorado, June. As-
sociation for Computational Linguistics.
Suzanne Stevenson, Afsaneh Fazly, and Ryan North.
2004. Statistical measures of the semiproductiv-
ity of light verb constructions. In Proceedings of
the ACL04 Workshop on Multiword Expressions:
Integrating Processing, pages 1?8. Association for
Computational Linguistics.
60
