Proceedings of the NAACL HLT 2010 Second Workshop on Computational Approaches to Linguistic Creativity, pages 40?48,
Los Angeles, California, June 2010. c?2010 Association for Computational Linguistics
Representing Story Plans in SUMO 
 
 
Jeffrey Cua   
Center for Human Language Technologies 
De La Salle University, Manila, Philippines 
  cuajeffreyleonardcompro1@yahoo.com 
Ethel Ong  
College of Computer Studies 
De La Salle University, Manila, Philippines 
ethel.ong@delasalle.ph 
 
Ruli Manurung 
Faculty of Computer Science 
University of Indonesia, Jakarta, Indonesia 
maruli@cs.ui.ac.id 
 
 
Adam Pease 
Articulate Software 
Angwin, California, USA 
apease@articulatesoftware.com 
 
 
Abstract 
Automatic story generation systems require a 
body of commonsense knowledge about the 
basic relationships between concepts we find 
everyday in our world in order to produce in-
teresting narratives that describe human ac-
tions and world events. This paper presents an 
ongoing work that investigates the use of 
Suggested Upper Merged Ontology (SUMO) 
to represent storytelling knowledge and its in-
ference engine Sigma to query actions and 
events that may take place in the story to be 
generated. The resulting story plan (fabula) is 
also represented in SUMO, allowing for a sin-
gle story representation to be realized in vari-
ous human languages. 
1 Introduction 
People combine words and events from their 
knowledge source of words, their meanings and 
their relationships in order to tell stories about their 
lives, their communities, and their daily expe-
riences. In order for computers to achieve the same 
level of expressiveness to provide a more fluent 
man-machine interaction, they must be provided 
with the same collection of knowledge about the 
basic relationships between things and events. 
Picture Books (Solis et al 2009), an automatic 
story generator that generates story text for child-
ren from a given input set of picture elements 
(backgrounds, characters and objects), utilized a 
semantic ontology whose design has been adapted 
from ConceptNet (Liu and Singh, 2004). The 
background serves as the setting of the story and is 
also used to determine the theme. Semantic con-
cepts needed by the story planner, specifically ob-
jects, story events, and character actions are 
classified according to the semantic categories of 
ConceptNet, namely things, spatial, events, ac-
tions, and functions. This mapping approach con-
strained the flexibility of the system, as new 
themes would entail repopulating the sequences of 
possible events manually into the knowledge base. 
Events and actions are selected according to their 
associated themes, and not marked with precondi-
tions that specify constraints under which certain 
actions can be performed and the corresponding 
consequential events that may arise. 
Swartjes (2006) developed a story world ontolo-
gy containing two layers, the upper story world 
ontology and the domain-specific world ontology. 
The upper story world ontology is independent of 
any story structures or story domains and models a 
vast amount of possible actions and events. It is 
also limited to high-level concepts that are meta, 
generic or abstract to address a broad range of do-
main areas. A domain-specific story world ontolo-
gy, on the other hand, applies the upper story 
world ontology to a certain story domain. 
Kooijman (2004) suggests the use of the Sug-
gested Upper Merged Ontology (SUMO) as an 
upper ontology to capture the semantics of world 
knowledge. SUMO (Niles and Pease, 2001) is an 
40
open source formal and public ontology. It is a col-
lection of well-defined and well-documented con-
cepts, interconnected into a logical theory. It 
numbers some 20,000 terms and 70,000 axioms. 
Axioms are in first-order logic form (with some 
higher order extensions) and reflect commonsense 
notions that are generally recognized among the 
concepts. They place a constraint on the interpreta-
tion of concepts and provide guidelines for auto-
mated reasoning systems such as Sigma (Pease, 
2003). Formal terms in SUMO are mapped to syn-
sets in WordNet (Pease, 2006). 
There are other noteworthy ontologies that can 
be considered. Like SUMO, Cyc (Lenat, 1995) is a 
large-scale, language-independent and extensible 
knowledge base and commonsense reasoning en-
gine, but it is proprietary and its open-source ver-
sion, OpenCyc1, has no inference rules. DOLCE 
(Gangemi, 2003) is a small-scale descriptive on-
tology with a cognitive orientation. BFO (Smith, 
1998) is another small-scale upper ontology sup-
porting domain ontologies developed for scientific 
research domain, such as biomedicine. Thus, no 
ontology other than SUMO had the characteristics 
of being comprehensive enough to include forma-
lizations that represent detailed elements of every-
day life (e.g., furniture, breaking an object, 
emotion), being open-source, having expressive-
ness of at least first order predicate calculus so that 
arbitrary rules about actions and consequences can 
be represented, having an associated open-source 
first-order inference engine, and a language gener-
ation capability so that stories can be automatically 
presented in multiple human languages 
This paper presents SUMOs (SUMO Stories), 
an automatic story generator that uses first-order 
logic to declaratively describe models of the world, 
specifically those aspects of the world that 
represent storytelling knowledge for children?s 
stories of the fable form. The story planner then 
utilizes an open source browsing and inference 
engine Sigma to infer this knowledge to generate a 
story plan (fabula) also in first-order logic form.  
Using first-order logic enables a less restricted 
semantics compared to description logic, which is 
commonly used for knowledge representation of 
large ontologies. Though having lesser constraints 
will have an impact on the speed of inference, it is 
overcome by the advantage of having greater re-
                                                          
1
 OpenCyc web site, http://www.opencyc.org/ 
presentational capability. In particular, the axi-
omatic nature of actions and their consequences, so 
essential for reasoning about narrative structures, is 
not supported by description logics, which focus 
on category and instance membership reasoning. 
Section 2 provides a background on the know-
ledge required by story generation and how these 
were represented in Picture Books, which is used 
as the basis for the storytelling knowledge. Section 
3 discusses the representation of the storytelling 
knowledge to SUMO. The SUMOs architecture 
depicting the interaction between the story planner 
and Sigma to derive the story plan is then pre-
sented in Section 4. The paper concludes with a 
summary of what we have accomplished so far, 
and presents further work that can be done. 
2 Storytelling Knowledge  
Theune and her colleagues (2006) presented five 
levels of the different aspects of a story that must 
be represented in the semantic network. These are 
the story world knowledge, character representa-
tions, a causal and temporal network to represent 
plot structures, representational model of narrato-
logical concepts, and the representation of the sto-
ry?s potential effects on the user. Only the first four 
levels are included in this study. 
According to Swartjes (2006), a story is com-
posed of a story world where the story takes place, 
the characters that interact in the story world, and 
the associated objects. Consider the story generat-
ed by Picture Books in Table 1 about Rizzy the 
rabbit who learns to be honest (Hong et al 2008). 
The afternoon was windy. Rizzy the rabbit was in the 
dining room. She played near a lamp. Rizzy broke the 
lamp. She was scared. Mommy Francine saw that the 
lamp was broken. Rizzy told Mommy Francine that Da-
niel broke the lamp. Daniel the dog told her that he did 
not break the lamp. Daniel was upset. He got punished. 
Mommy Francine told Daniel that he was grounded. He 
cried. Rizzy felt guilty. She told Mommy Francine that 
she broke the lamp. Mommy Francine told Rizzy that 
she should have been honest. Rizzy apologized to 
Mommy Francine. Mommy Francine forgave Rizzy. 
Rizzy apologized to Daniel. He forgave her. Mommy 
Francine told Rizzy to be honest. She told her that being 
honest is good. From that day onwards, Rizzy always 
was honest. 
Table 1. Sample story generated by Picture Books 
(Hong et al 2008) 
41
The story elements in Table 1 were determined 
from the background (i.e., dining room), the cha-
racters (i.e., Rizzy and her mommy Francine) and 
object (i.e., lamp) that the child user places into 
his/her picture using the Picture Editor of the sys-
tem in Figure 1. 
The background serves as the main setting of the 
story, and combined with the selected objects, is 
used to determine the theme. Consider the bed-
room setting. If the associated object is a lamp, 
then the theme is about bravery (i.e., do not be 
afraid of the dark). If the object is a set of toy 
blocks, the theme can be about being neat. In Pic-
ture Books, such associations are manually deter-
mined and entered into the database. In SUMOs, 
these associations should be inferred automatically 
through axioms that should be commonsense, and 
not be explicit encoding of narrative knowledge.  
 
Figure 2. Picture Editor (Hong et al 2008) 
 
Stories generated by Picture Books follow a ba-
sic plot dictated by Machado (2003) that flows 
from negative to positive and comprises four sub-
plots, namely the problem, rising action, solution 
and climax. The theme is subdivided into these 
four subplots, each representing a major event in 
the story. 
Each subplot contains at least two author goals 
representing the goal of the scene and the corres-
ponding consequence of the goal. An author goal is 
translated into one or more character goals, each 
representing an action performed by the character 
(main, secondary, or adult character) in order to 
achieve the author goal. A character goal translates 
directly to one declarative sentence in the generat-
ed story. Table 2 shows the author goals and the 
character goals for some of the sentences in the 
story in Table 1. 
The design of the character goal is based from 
the action operators of Uijlings (2006) which is 
easily transformed to a declarative sentence in ac-
tive voice using the surface realizer simpleNLG 
(Venour and Reiter, 2008). In the case of Picture 
Books, however, the approach resulted in a story 
where every sentence describes an action or a feel-
ing (i.e., scared, guilty, upset) that is performed by 
the character, as seen in Table 1. 
Subplot #1 
Author goal 1.1: 
Goal of the scene Child is doing an activity 
Character goal <character> plays <object> 
Resulting text Rizzy the rabbit played near a lamp. 
Author goal 1.2: 
Goal consequence Child caused a problem 
Character goal <character> destroys <object> 
Resulting text Rizzy broke the lamp. 
Subplot #2 
Author goal 2.1: 
Goal of the scene Child lied 
Character goal 
<main character> told <adult 
character> that <secondary 
character> <did the action> 
Resulting text Rizzy told Mommy Francine that Daniel the dog broke the lamp. 
Author goal 2.2: 
Goal consequence Another child gets punished 
Character goal #1 <secondary character> receives 
<punishment> 
Resulting text #1 Daniel the dog got punished. 
Character goal #2 
<adult character> issues <pu-
nishment> to <secondary cha-
racter> 
Resulting text #2 Mommy Francine told Daniel 
that he was grounded. 
Table 2. Sample author goals and character goals asso-
ciated with the theme Being Honest (Hong et al 2008) 
 
The story planner of Picture Books utilizes two 
types of knowledge, the operational knowledge 
and the domain knowledge. The operational know-
ledge contains a static description of the different 
backgrounds and their associated themes and ob-
jects, the child characters and their corresponding 
parent characters, as well as the occupation of the 
42
parents. For each theme, the set of character goals 
needed to instantiate the major events in the theme 
are also specified.  
The domain knowledge, on the other hand, con-
tains a semantic description of objects and events 
that can occur, as well as actions that can be per-
formed. For example, breaking an object results to 
getting punished, and grounded is a form of pu-
nishment. 
Character goals are instantiated by accessing the 
semantic ontology to search for concepts that are 
directly related to the input concept. There are two 
search methods. The first method searches for 
another concept that has a relationship with the 
given concept while satisfying the semantic cate-
gory. For example, ontoSpatial(?play?) triggers a 
search for all concepts connected to play within the 
spatial semantic category, such as the semantic 
relationship locationOf(?play?, ?park?). The second 
method searches for a path that semantically re-
lates the two given concepts. For example, ontoAc-
tion(?vase?, ?method of destruction?) triggers a 
search for a path to relate how a vase can be de-
stroyed, and yields the following relationships: 
CapableOf(?break?, ?vase?) 
Isa(?method of destruction?, ?break?)  
3 Representing Storytelling Knowledge in 
SUMO 
A crucial part of the work involved in the devel-
opment of SUMOs is the representation of the sto-
rytelling knowledge and the evolving story plan in 
SUMO and the use of the Sigma reasoning engine 
to infer story facts and events. 
The storytelling knowledge represented in 
SUMO includes the semantic description about 
concepts, objects and their relationships. From a 
given input set of story elements comprising the 
selected background, characters, and objects, a 
query is sent to Sigma to determine a possible 
starting action that can be performed by the main 
character in the story. The story then progresses 
based on the relationships of character actions and 
reactions, which are the stored facts in SUMO. 
Similar to Picture Books, the resulting story plan 
is created based on a pre-authored plot of problem, 
rising action, resolution and climax. But instead of 
attaching the next set of actions and emotions of 
characters to author goals, in SUMOs, the set of 
actions that a character can do ? reaction to events 
and objects, experience emotions such as joy and 
sadness, and subsequent actions based on their 
emotions ? are represented in SUMO logic. 
The storytelling knowledge was formulated us-
ing a set of predicates that can be classified into 
four main types. Factual predicates specify proper-
ties of characters, objects, and locations. Semantic 
predicates define the semantic relationships be-
tween concepts. Actions and events predicates de-
fine the causal relationships between actions and 
events. Thematic predicates represent a new set of 
predicates to relate story themes to actions. 
3.1 Conceptualizing Story Characters, Ob-
jects, and Backgrounds 
Factual predicates represent the characters, their 
roles, the locations, and the objects that may com-
prise a story. The class and subclass axioms of 
SUMO2 are used to define the set of characters, 
objects and locations.  
Children?s stories of the fable form are por-
trayed by animals that can capture the  imagina-
tion and attention of the readers. Animal characters 
are given names, such as Ellen the elephant, Rizzy 
the rabbit, and Leo the lion, to give the impression 
that the characters are friends that the children are 
getting to know better through reading the story 
(Solis et al 2009). Representing this in SUMO 
entails the use of the subclass axiom to represent 
class inheritance as shown below: 
(subclass RabbitCharacter StoryCharacter) 
Class definitions include slots that describe the 
attributes of instances of the class and their rela-
tions to other instances (Noy, 2001). A character in 
SUMOs has the attributes type (whether adult or 
child), gender, and name. An example axiom to 
represent a female child RabbitCharacter whose 
name will be ?Rizzy? is shown below. Similar 
axioms are defined for all the other characters. 
(=> 
  (and 
    (instance ?RABBIT RabbitCharacter) 
    (attribute ?RABBIT Female) 
    (attribute ?RABBIT Child)) 
  (name ?RABBIT "Rizzy")) 
Backgrounds and objects are also defined using 
the subclass axiom and inherit from existing 
classes in SUMO, for example, 
                                                          
2
 SUMO Ontology Portal, http://www.ontologyportal.org/ 
43
(subclass LivingRoom Room) 
(subclass Lamp LightFixture) 
(subclass Lamp ElectricDevice) 
(attribute Lamp Fragile) 
Further definitions can be provided for living 
room to differentiate it from other rooms, such as 
being disjoint from bathroom, and has a primary 
purpose of supporting social interaction, as shown 
below. Similarly, the definition for lamp can also 
be extended to distinguish it from other electric 
light fixtures, e.g., a lamp is moveable unlike a 
chandelier, but is plugged in when operating unlike 
a flashlight. 
(=> 
 (instance ?R LivingRoom) 
     (hasPurpose ?R 
          (exists (?S) 
              (and 
              (instance ?S SocialInteraction) 
              (located ?S ?R))))) 
(disjoint  LivingRoom Bathroom) 
3.2 Representing Semantic Concepts 
Aside from the properties of objects that are mod-
eled using the attribute axiom, semantic relation-
ships that may hold between two concepts 
involving types of activities or actions, character 
emotions, locations of objects, and abilities of cha-
racters or objects must also be modeled. Table 3 
shows sample semantic relationships for these con-
cepts as represented in Picture Books, following 
the semantic categories of ConceptNet (Liu and 
Singh, 2004). 
Objects IsA (doll, toys) 
Activities IsA (play games, activity) 
Concepts 
IsA (grounded, punishment) 
IsA (disorder, problem) 
IsA (no appetite, problem) 
IsA (dizzy, discomfort) 
IsA (itchy, discomfort) 
Emotions IsA (happy, emotion) IsA (scared, emotion) 
Reaction to 
Events 
EffectOf (break object, scared) 
EffectOf (meet new friends, smile) 
Location LocationOf (toys, toy store) 
Capability 
CapableOf (lamp, break) 
CapableOf (glass of water, break) 
CanBe (toys, scattered) 
Table 3. Semantic relationships in Picture Books based 
on ConceptNet (Hong et al 2008) 
In SUMOs, all isA(entity1, entity2) relations 
were replaced with the axiom (subclass entity1 
entity2). To specify that an entity is in a location, 
i.e., locationOf(toys, toy store), first, we create an 
instance of a toystore and then specify that a cer-
tain toy instance is in that toystore, as follows:  
(=> 
    (instance ?TOYSTORE ToyStore) 
    (exists (?TOY) 
        (and 
            (instance ?TOY Toy) 
            (located ?TOY ?TOYSTORE)))) 
The capability axiom is used to conceptualize 
the capability relation (capability ?process ?role 
?obj). It specifies that ?obj has the specified ?role 
in the ?process. For example, a lamp or a glass is 
the patient (receiver) of the process breaking, 
while a toy is the patient for the process scattering. 
(capability Breaking experiencer Lamp) 
(capability Breaking experiencer Glass) 
(capability Scattering experiencer Toy) 
Reaction to events is expressed using the if-else 
axiom of SUMO, for example, if a child character 
causes an accident (a damage), then he/she will 
feel anxiety. Emotions are represented using the 
attribute relation. 
 (=> 
    (and 
      (instance ?ACCIDENT Damaging) 
      (instance ?CHARACTER StoryCharacter) 
      (attribute ?CHARACTER Child) 
      (agent ?ACCIDENT ?CHARACTER)) 
    ((attribute ?CHARACTER Anxiety))) 
3.3 Conceptualizing Actions and Events 
Swartjes (2006) noted that organizing actions and 
events, and causally relating them, is an essential 
step in story generation. Independent of the story 
plot, the causes and effects of character actions can 
be used to describe the events that form the story.  
Actions define activities that can be performed 
by a character in the story, such as play, tell a lie, 
or cry. Events, on the other hand, occur in the story 
as a result of performing some actions, such as a 
lamp breaking as a result of a character or an ob-
ject hitting it. Swartjes (2006) further notes that 
events are not executed by a character. 
Action predicates are used to define the actions 
that may take place given a set of world state. Con-
sider the axiom below which provides a set of four 
44
possible actions ? RecreationOrExercise, Looking, 
Maintaining, and Poking ? that can be performed 
(as an agent) or experienced by a child character 
who is situated near a lamp object in the story 
world. These four actions are subclasses of the In-
tentionalProcess of SUMO. 
 (=> 
  (and 
    (orientation ?CHARACTER ?OBJECT Near) 
    (instance ?CHARACTER StoryCharacter) 
    (attribute ?CHARACTER Child) 
    (instance ?OBJECT Lamp)) 
  (and 
    (capability RecreationOrExercise  
experiencer ?CHARACTER) 
    (capability Looking experiencer ?CHARACTER) 
    (capability Maintaining experiencer ?CHARACTER) 
    (capability Poking experiencer ?CHARACTER))) 
Again, the capability relation is used but in this 
instance, to specify that the character has the role 
of experiencing the specified process. While both 
the agent and the experiencer roles represent the 
doer of a process, an experiencer does not entail a 
causal relation between its arguments. 
Event predicates are used to model explicit 
events that may take place as a result of some cha-
racter actions. Consider again the exists axiom be-
low which states that an instance of an event (in 
this case damaging) can occur when there is a 
child character (the agent) playing near a fragile 
object. The subprocess axiom is used to represent a 
temporally distinguished part of a process and also 
expresses a chain of cause and effect subprocesses 
for playing and damaging. The recipient (patient) 
of the event is the object. 
(=> 
 (and 
   (agent ?X ?CHARACTER) 
   (instance ?CHARACTER StoryCharacter) 
   (attribute ?CHARACTER Child) 
   (instance ?OBJECT Object) 
   (attribute ?OBJECT Fragile) 
   (instance ?X RecreationOrExercise) 
   (orientation ?CHARACTER ?OBJECT Near) 
 (exists (?DAMAGE) 
   (and 
     (instance ?DAMAGE Damaging) 
     (subProcess ?DAMAGE ?X) 
     (agent ?DAMAGE ?CHARACTER) 
     (patient ?DAMAGE ?OBJECT)))) 
Although suitable for inference, the given axiom 
does not fully capture the desired truth as the no-
tion of time is not represented. The axiom says ?if 
a child plays at any point in time, and is near an 
object at any point in time (not necessarily while 
playing), then the object gets damaged during 
playing?.  The more accurate axiom below uses 
holdsDuring to show that the time frames of the 
actual playing and being near the object are the 
same, thus increasing the likelihood of the charac-
ter who is playing to cause the damage. 
(=> 
 (and 
   (instance ?X RecreationOrExercise) 
   (agent ?X ?CHARACTER) 
   (instance ?CHARACTER StoryCharacter) 
   (attribute ?CHARACTER Child) 
   (instance ?OBJECT Object) 
   (attribute ?OBJECT Fragile) 
   (holdsDuring (WhenFn ?X) 
       (orientation ?CHARACTER ?OBJECT Near)) 
(exists (?DAMAGE) 
   (and 
     (instance ?DAMAGE Damaging) 
     (subProcess ?DAMAGE ?X) 
     (agent ?DAMAGE ?CHARACTER) 
     (patient ?DAMAGE ?OBJECT)))) 
As the representation shows, SUMO is quite ca-
pable of encoding temporal properties of events 
with its temporal qualification. However, inferenc-
ing with rules involving time relations between 
events is currently not supported by Sigma (Corda 
et al 2008). Nevertheless, efforts are underway to 
perform true higher-order logical inference (Sut-
cliffe et al 2009). 
The next step involves deriving axioms to 
represent the different ways in which an object can 
be damaged depending on its attribute, for exam-
ple, fragile objects can break while paper-based 
objects such as books and paintings can be torn. 
Consideration must also be made to determine if a 
damage is an accident or intentional. 
3.4 Conceptualizing Story Themes 
Themes can also be mapped to SUMO as thematic 
predicates, and the story planner can identify a 
theme either based on the first action that was per-
formed, or based on user selection. In the latter 
case, when Sigma returns all possible actions, the 
planner can choose one based on the theme. 
45
4 System Architecture 
The architecture of SUMOs, shown in Figure 2, 
has two main modules, the Story Editor and the 
Story Planner, both of which interact with Sigma3 
to retrieve story facts from the SUMO ontology as 
well as to assert new axioms representing the de-
veloping story plan back to SUMO. 
 
Figure 2. Architecture of SUMOs 
 
The Story Editor handles the generation of as-
sertions corresponding to the input picture ele-
ments specified by the user.  
The Story Planner is responsible for planning 
the flow of events in the story. It uses a meta-
knowledge about children?s story comprising of 
five phases ? introduction, problem, rising action, 
solution, and climax. The planner determines and 
phrases the queries that are sent to Sigma and ge-
nerates additional axioms based on the query re-
sults in order to expand the story plan. The 
generated axioms are asserted back to Sigma for 
inclusion in the SUMO ontology to be used again 
for further inferencing.  
Queries sent to Sigma can be classified into 
three categories. Concept-based queries concern 
classes and instances, and are used to determine 
direct and indirect subclass and class-instance rela-
tionships while relation-based queries infer know-
ledge by considering transitivity, symmetry and 
inversion of relations (Corda et al 2008). Action-
based queries identify a set of actions based on the 
                                                          
3
 Sigma Knowledge Engineering Environment,  
http://sigmakee.sourceforge.net  
current world state to drive the story. A fourth cat-
egory, time-event queries, currently not supported 
by Sigma, should reason about temporal and event-
based specifications. 
The interaction between the Story Planner and 
Sigma in Figure 2 raises an issue of search control. 
In Picture Books and SUMOs, information that 
guides the story planning can be bottom-up, i.e. the 
actions and events are determined based on what is 
possible within the story ontology, e.g. through the 
various capability axioms, or top-down, i.e. actions 
are selected based on Machado's narrative subplot 
knowledge. Currently, the Story Planner is respon-
sible for managing the process. However, if both 
these sources of knowledge and constraints can be 
represented in first-order logic, the search control 
of the story planning process can be recast as a 
theorem proving task, i.e. one that searches for a 
proof that satisfies all constraints. This is a future 
research direction. 
The following section presents a more detailed 
trace of system operation and the contents of a sto-
ry plan in first-order logic. 
4.1 Generating Story Plans 
The first part of the story plan contains assertions 
to represent the initial elements of the story. Using 
the story in Table 1 as an example, lines 1 to 6 be-
low assert the main child character and her parent, 
while lines 7 to 8 assert the background and the 
object, respectively.  
1>   (instance Rabbit1 RabbitCharacter) 
2>  (attribute Rabbit1 Child) 
3>  (attribute Rabbit1 Female) 
4>  (instance Rabbit2 RabbitCharacter) 
5>  (attribute Rabbit2 Adult) 
6>  (attribute Rabbit2 Female) 
7>  (instance LivingRoom1 LivingRoom) 
8>  (instance Lamp1 Lamp) 
The next step involves initializing the locations 
of these story elements. Currently, it is setup that 
all objects would be situated in the background and 
the first child character would always be near the 
first object, as shown in the assertions below.  
9>  (located Rabbit1 LivingRoom1) 
10>  (located Lamp1 LivingRoom1) 
11>  (orientation Rabbit1 Lamp1 Near) 
This, however, creates the assumption that the 
child character is already in the location near ob-
jects which he will interact with, which may not 
return 
results 
abstract 
story plan 
assertions 
assertions 
obtain 
results 
Story 
Editor SUMO 
Ontology 
(Story 
Ontology) 
SIGMA  
(Inference 
Engine) 
Story 
Planner 
Story plan  
(SUMO) 
query 
46
necessarily be true and reduces the flexibility of 
the system. In order to create more varied stories, 
the initial location can be identified based on the 
theme and the first event that the user would want 
to likely happen in the story. 
From the initial set of assertions, the story plan-
ner issues its first concept-based query to Sigma 
with ?(name Rabbit1 ?X)? to determine a name for 
the main character, Rabbit1, and receives ?Rizzy? 
as a result. This is asserted to the story plan as: 
12>  (name Rabbit1 ?Rizzy?) 
The next query is the first action-based query 
used to determine the first action to start the story 
flow. Given ?(capability ?X experiencer Rabbit1)?, 
which is intended for identifying the set of possible 
starting actions that the main character, Rabbit1, 
can perform with the object in the background, 
Sigma returns the following list (assuming the sto-
ry facts given in the previous section):  
X = [RecreationOrExercise, Looking, 
Maintaining, Poking]  
Assuming the planner selects RecreationOrEx-
ercise, the following assertions are then added to 
the story plan: 
13>  (instance RecOrEx1 RecreationOrExercise)  
14>  (agent RecOrEx1 Rabbit1) 
At this point, the introduction phase of the story 
plan has been completed. The problem phase be-
gins with a query to identify any instances of prob-
lems that can occur, i.e. ?(instance ?X Damaging)?. 
Damaging the object lamp causes its attribute to be 
changed, and again we query Sigma for this 
change of state with ?(attribute Lamp1 ?X)? yielding 
the result broken, and the corresponding emotional 
state of the character ?(attribute Rabbit1 ?X)?. The 
following assertions were added to the plan: 
15>  (instance (sk0 Rabbit1 Lamp1   
                   RecOrEx1) Damaging) 
16>  (attribute Lamp1 Broken) 
17>  (attribute Rabbit1 Anxiety) 
While a full explanation of skolemization is not 
possible here for space reasons, we note that the 
second argument of assertion #15 (derived from 
Sigma?s answer to the query) stands for the exis-
tence of an unnamed term, in this case, that there is 
an instance of a Damaging process. The agent 
(Rabbit1), patient (Lamp1), and the action (RecO-
rEx1) that caused the problem were all provided in 
the query result. 
4.2 Generating Surface Text 
SUMO-based story plans provide a form of inter-
lingua where story details are represented in logi-
cal form. The logical representation allows 
generation of the same story in different languages 
(that are connected to WordNet). Sigma already 
has a language generator, with templates for Eng-
lish, and an initial set for Tagalog (Borra et al 
2010).  Work is currently underway to enhance the 
existing language generator in Sigma and make the 
generated text more natural. Sigma can then be 
used to generate stories automatically from the 
knowledge asserted in the story generation process. 
5 Conclusions and Further Work 
The paper presented a preliminary work aimed at 
representing storytelling knowledge in SUMO and 
using Sigma as inference engine to assist the plan-
ner in generating story plans. Further work focuses 
on modeling the emotional state of the character as 
a result of some event (e.g., feeling worried, guilty 
or scared due to causing some problems in the 
world state), changes in character traits as the story 
progresses (e.g., from negative trait to positive trait 
as the story flows from rule violation to value ac-
quisition), and enhancing the representation for 
story themes. Once a set of knowledge has been 
developed, these should be evaluated systematical-
ly through validation of the rules for logical consis-
tency with the theorem prover. A future goal is to 
apply the metrics proposed by Callaway & Lester 
(2002) in StoryBook to evaluate with actual users 
if the generated stories are better and more varied 
as compared to that of Picture Books. 
Although SUMO is quite capable of 
representing time and sequences, reasoning with 
temporally qualified expression is challenging for 
any theorem prover. The works of (Sutcliffe et al 
2009) to extend the inference engine to handle rea-
soning over temporal relations should be explored 
further to allow SUMOs to generate story plans 
that consider temporal relations between actions 
and events. 
Finally, story generators will benefit its readers 
if the generated stories are narrated orally. SUMOs 
can be explored further to model various emotions 
to provide annotations in the surface story text 
which will then be fed to a text to speech tool for 
speech generation. 
47
References 
Borra, A., Pease, A., Roxas, R. and Dita, S. 2010. Intro-
ducing Filipino WordNet. In: Principles, Construc-
tion and Application of Multilingual Wordnets: 
Proceedings of the 5th Global WordNet Conference, 
Mumbai, India. 
Callaway, C. B., and Lester, J. C. 2002. Narrative Prose 
Generation. Artificial Intelligence, 139(2):213-252, 
Elsevier Science Publishers Ltd., Essex, UK.  
Corda, I., Bennett, B., and Dimitrova, V. 2008. Interact-
ing with an Ontology to Explore Historical Domains. 
Proceedings of the 2008 First International Work-
shop on Ontologies in Interactive Systems, 65-74, 
IEEE Computer Society. 
Gangemi, A., Guarino, N., Masolo, C., and Oltramari, 
A. 2003. AI Magazine, 24(3):13-24, Association for 
the Advancement of Artificial Intelligence. 
Kooijman, R. 2004. De virtuele verhalenverteller: 
voorstel voor het gebruik van een upper-ontology en 
een nieuwe architectuur. Technical  Report. Universi-
ty of Twente, Department of Electrical Engineering, 
Mathematics and Computer Science. 
Hong, A., Solis, C., Siy, J.T., and Tabirao, E. 2008. Pic-
ture Books: Automated Story Generator. Undergra-
duate Thesis, De La Salle University, Manila, 
Philippines. 
Lenat, D.B. 1995. Cyc: A Large-Scale Investment in 
Knowledge Infrastructure, Communications of the 
ACM, 38(11).  
Liu, H. and Singh, P. 2004. Commonsense Reasoning in 
and over Natural Language. Proceedings of the 8th 
International Conference on Knowledge-Based Intel-
ligent Information and Engineering Systems, 293-
306, Wellington, New Zealand, Springer Berlin. 
Machado, J. 2003. Storytelling. In Early Childhood 
Experiences in Language Arts: Emerging Literacy, 
304-319. Clifton Park, N.Y., Thomson/Delmar 
Learning. 
Niles, I. and Pease, A. 2001. Towards A Standard Upper 
Ontology.   Proceedings of Formal Ontology in 
Information Systems (FOIS 2001), 2-9, October 17-
19, Ogunquit, Maine, USA. 
Noy, N. and McGuinness, D. 2001. Ontology Develop-
ment 101: A Guide to Creating Your First Ontology. 
Stanford Knowledge Systems Laboratory Technical 
Report KSL-01-05 and Stanford Medical Informatics 
Technical Report SMI-2001-0880, March 2001. 
Ong, E. 2009. Prospects in Creative Natural Language 
Processing. Proceedings of the 6th National Natural 
Language Processing Research Symposium, De La 
Salle University, Manila, Philippines. 
 
 
 
 
 
Pease, A. 2006. Formal Representation of Concepts: 
The Suggested Upper Merged Ontology and Its Use 
in Linguistics. Ontolinguistics. How Ontological Sta-
tus Shapes the Linguistic Coding of Concepts. Schal-
ley, A.C. and Zaefferer, D. (ed.), Vorbereitung 
Berlin, New York. 
Pease, A. 2003. The Sigma Ontology Development En-
vironment. Working Notes of the IJCAI-2003 Work-
shop on Ontology and Distributed Systems, vol. 71 of 
CEUR Workshop Proceeding series. 
Riedl, M. and Young, R.M. 2004. An Intent-Driven 
Planner for Multi-Agent Story Generation. Proceed-
ings of the Third International Joint Conference on 
Autonomous Agents and Multi-Agent Systems, 186-
193, Washington DC, USA, IEEE Computer Society. 
Smith, B. 1998. The Basic Tools of Formal Ontology. 
Formal Ontology in Information Systems, Nicola Gu-
arino (ed),  IOS Press, Washington. Frontiers in Ar-
tificial Intelligence and Applications, 19-28. 
Solis, C., Siy, J.T., Tabirao, E., and Ong, E. 2009. Plan-
ning Author and Character Goals for Story Genera-
tion. Proceedings of the NAACL Human Language 
Technology 2009 Workshop on Computational Ap-
proaches to Linguistic Creativity, 63-70, Boulder, 
Colorado, USA. 
Sutcliffe, G., Benzm?ller, C., Brown, C.E., and Theiss, 
F. 2009. Progress in the Development of Automated 
Theorem Proving for Higher-order Logic. Automated 
Deduction, 22nd International Conference on Auto-
mated Deduction, Montreal, Canada, August 2-7, 
2009. Proceedings of the Lecture Notes in AI, vol. 
5663, 116-130, 2009, Springer. 
Swartjes, I. 2006. The Plot Thickens: Bringing Structure 
and Meaning into Automated Story Generation. Mas-
ter's Thesis, University of Twente, The Netherlands. 
Theune, M., Nijholt, A., Oinonen, K., and Uijlings J. 
2006. Designing a Story Database for Use in Auto-
matic Story Generation.  Proceedings 5th Interna-
tional Conference Entertainment Computing, 
Cambridge, UK. Lecturer Notes in Computer 
Science, 4161:298-301, Heidelberg, Springer Berlin. 
Uijlings, J.R.R. 2006. Designing a Virtual Environment 
for Story Generation. MS Thesis, University of Ams-
terdam, The Netherlands. 
Venour, C. and Reiter, E. 2008. A Tutorial for Sim-
plenlg. http://www.csd.abdn.ac.uk/~ereiter/simplenlg 
WordNet. 2006. WordNet: A Lexical Database for the 
English Language. Princeton University, New Jersey. 
48
Proceedings of the 8th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities (LaTeCH) @ EACL 2014, pages 128?136,
Gothenburg, Sweden, April 26 2014. c?2014 Association for Computational Linguistics
Towards Automatic Wayang Ontology Construction using 
Relation Extraction from Free Text 
 
Hadaiq Rolis Sanabila 
Faculty of Computer Science  
Universitas Indonesia 
hadaiq@cs.ui.ac.id 
Ruli Manurung 
Faculty of Computer Science  
Universitas Indonesia 
maruli@cs.ui.ac.id  
 
  
 
Abstract 
This paper reports on our work to 
automatically construct and populate an 
ontology of wayang (Indonesian shadow 
puppet) mythology from free text using 
relation extraction and relation clustering. A 
reference ontology is used to evaluate the 
generated ontology. The reference ontology 
contains concepts and properties within the 
wayang character domain. We examined the 
influence of corpus data variations, threshold 
value variations in the relation clustering 
process, and the usage of entity pairs or entity 
pair types during the feature extraction stages. 
The constructed ontology is examined using 
three evaluation methods, i.e. cluster purity 
(CP), instance knowledge (IK), and relation 
concept (RC). Based on the evaluation results, 
the proposed method generates the best 
ontology when using a consolidated corpus, 
the threshold value in relation clustering is 1, 
and entity pairs are used during feature 
extraction. 
1 Introduction 
As a country rich in cultural diversity, Indonesia 
certainly has an outstanding wealth of national 
culture. Wayang (shadow puppets performance 
art) is one instance of Indonesian culture that has 
cultural values and noble character. Although the 
stories are generally taken from the Mahabharata 
and Ramayana books, they involve the wisdom 
and greatness of the Indonesian culture. Wayang 
shows rely heavily on the knowledge and 
creativity of the puppeteer (dalang). Often, the 
story and knowledge about the shadow puppets 
is known only to the puppeteer and not set forth 
in writing. Such a lack of knowledge transfer 
process results in a lot of knowledge that is 
known only by the puppeteer cannot be shared to 
others, which leads to the loss of cultural 
richness. The knowledge held by the puppeteer 
ought to be propagated to future generations in 
order to be learned and developed. 
Information about the shadow puppets can be 
represented as textual data describing hundreds 
of characters. Constructing an ontology manually 
from such a large data source is time consuming 
and labor intensive. 
Work on relation extraction has already been 
conducted in the past. Initially, supervised 
learning approaches were used, for example 
feature-based supervised learning (Kambhatla, 
2004; Zhao and Grishman, 2005). Some features 
that are generally used are words that lie among 
the entities, the entity type, the number of words 
between two entities, and the number of entities 
between two entities. In addition, there are 
several studies that use kernel-based approach. 
The kernel K(x, y) defines the similarity between 
objects x and y in the high-dimensional objects. 
There are various elements used to construct 
kernels such as word subsequence (Bunescu and 
Mooney, 2005) and parse trees (Zelenko et al., 
2003; Culotta et al., 2004). 
In addition, several studies use semi-
supervised learning. DIPRE (Brin, 1998) tries to 
find the relationship between the author interest 
and the book he/she had written. Snowball 
(Agichtein and Gravano, 2000) uses an 
architecture that is not very different from 
DIPRE to determine the relationship between an 
organization and its location. Meanwhile, 
Knowitall (Etzioni at al., 2005) examines relation 
extraction in heterogeneous domains of text data 
128
from the web automatically. Finally TextRunner 
(Banko at al., 2007) is a system that 
automatically searches the relationships between 
entities that exist in a corpus. This method 
produces a binary relation (e1, r, e2) where e1 and 
e2 are entities and r is a relation between them. 
Work on automatic ontology construction has 
been done by several researchers. Celjuska et al. 
(2004) developed a semi-automatic ontology 
construction system named Ontosophie. The 
system generates an ontology with the instances 
derived from unstructured text. Shamsfard et al. 
(2004) developed an automatic ontology 
construction approach which utilizes a kernel 
based method. Alani et al. (2003) tries to 
construct an ontology using data from the web. 
The system, named Artefakt, performs 
information summarization about the artist. 
Furthermore, the constructed ontology is used to 
generate personalized narrative biographies. The 
system consists of three components, namely 
knowledge extraction, information management, 
and biography construction component. 
The majority of the information extraction 
methods mentioned above require reliable NLP 
tools and resources. Unfortunately these are not 
readily available for Indonesian, the language  
our wayang data is in. To overcome this 
challenge, we employ information extraction 
methods that only require simple resources such 
as gazetteers and stopword lists, which are 
potentially used in a variety of problem domains. 
In this study, we explore methods to 
automatically construct an ontology using a 
corpus of wayang character descriptions using 
relation extraction and clustering. This method 
requires a gazetteer which contains a list of 
entities from the text. The entity types that are 
contained in the gazetteer are the name of the 
puppet characters, their kingdoms of origin, and 
their various artefacts such as weapons or spells. 
We realize our method does not yet fully 
constitute the development of a complete 
ontology, but provides an important step towards 
that direction, namely the identification of 
relations to be found within the ontology.  
2 Automatic Ontology Construction 
We aim to automatically build a wayang 
ontology from free text. The information or 
knowledge that is contained within the text is 
extracted by employing relation extraction. This 
method will extract instance candidates that are 
subsequently clustered using relation clustering. 
Furthermore, the ontology will be evaluated 
using a reference ontology to examine the quality 
of the constructed ontology. The stages of 
automatic ontology construction and evaluation 
are depicted in Figure 1. 
2.1 Automatic Ontology Construction  
During this stage, the system attempts to find all 
possible relationships that occur between any 
two entities. These relationships are further 
analysed to obtain a set of valid relationships 
between entities. The valid relations will be used 
to construct the ontology. The ontology 
construction stage is depicted in Figure 2.  
 
Figure 1. Automatic ontology construction 
and evaluation stages 
 
Figure 2. The ontology construction stages 
Free 
Text 
(raw 
data) 
Entity 
tagging 
Pronoun 
Resolution 
Relation 
Extraction 
Feature 
extraction 
Relation 
Clustering 
129
The raw data is free text that consists of 
several paragraphs describing short biographies 
of wayang characters. Firstly, the free text is 
tagged using gazetteer data, i.e. a list of entities 
contained in the text. Every word contained in 
the gazetteer will be tagged in accordance to its 
entity type. The number of entities in the 
gazetteer is still general. Thus, the entities are 
subdivided into more specific groups. The entity 
group is based on Pitoyo Amrih (Amrih, 2011) 
which consists of 29 groups. In this study we 
used two tagging methods, i.e. by using a 
wayang entity that has not been detailed and by 
using detailed entities (based on the type of 
wayang entity). Different tagging treatment was 
conducted to examine whether this affects the 
ontology result or not. The example of tagged 
text using wayang entity that has not been 
detailed and detailed entities can be seen in 
Figures 3 and 4. 
Subsequently, pronoun resolution is employed 
to resolve the entity reference of a pronoun. The 
system will then perform relation extraction by 
analyzing the words occurring between tagged 
entities. This process will generate candidate 
relationship patterns between entities (X, r, Y), 
where X and Y are entities and r is the textual 
pattern that defines the relationship between the 
two entities.  
The patterns that are obtained from the 
previous process are passed on to the next step 
that is the process of eliminating irrelevant 
information, so that only valid are used in the 
next process. It runs as follows: 
1. Discard stopwords and honorifics. 
2. If there is a comma and punctuation located 
at the beginning of a pattern then the relation 
<BangsaKera> Anoman </BangsaKera> kera berbulu 
putih seperti kapas. Ia adalah anak <DewaDewi> 
Betara Guru </DewaDewi> dengan <BangsaKera> 
Dewi Anjani </BangsaKera>, seorang putri bermuka 
dan bertangan kera. <BangsaKera> Anoman 
</BangsaKera> juga bernama <BangsaKera> Maruti 
</BangsaKera>, karena mempunyai angin, seperti juga 
Raden <Pandawa> Werkudara </Pandawa> dan oleh 
karenanya <BangsaKera> Anoman </BangsaKera> 
disebut juga saudara <Pendawa> Werkudara 
</Pendawa> yang berkesaktian angin. <BangsaKera> 
Anoman </BangsaKera> juga bernama <BangsaKera> 
Ramadayapati </BangsaKera>, berarti yang diaku anak 
oleh Sri <KerabatAyodya> Rama 
</KerabatAyodya>;. <BangsaKera> Anoman 
</BangsaKera> juga bernama <BangsaKera> 
Bayutanaya </BangsaKera>, berarti yang diaku anak 
<DewaDewi> Betara Bayu </DewaDewi>;. 
<BangsaKera> Anoman </BangsaKera> juga bernama 
<BangsaKera> Kapiwara </BangsaKera>Bermula 
<BangsaKera> Anoman </BangsaKera> hidup pada 
jaman Sri <KerabatAyodya> Rama 
</KerabatAyodya>, membela Sri Ramapada waktu 
kehilangan permaisurinya, Dewi <KerabatAyodya> 
Sinta </KerabatAyodya>,yang dicuri oleh raja raksasa 
Prabu <KerabatAlengka> Dasamuka 
</KerabatAlengka> dari negara <Kingdom> Alengka 
</Kingdom>. 
Figure 4. Tagging result using detailed entities 
<Person> Anoman </Person> kera berbulu putih 
seperti kapas. Ia adalah anak <Person> Betara Guru 
</Person> dengan <Person> Dewi Anjani </Person>, 
seorang putri bermuka dan bertangan kera. <Person> 
Anoman </Person> juga bernama <Person> Maruti 
</Person>, karena mempunyai angin, seperti juga 
Raden <Person> Werkudara </Person> dan oleh 
karenanya <Person> Anoman </Person> disebut juga 
saudara <Person> Werkudara </Person> yang 
berkesaktian angin; <Person> Anoman </Person> 
juga bernama <Person> Ramadayapati </Person>, 
berarti yang diaku anak oleh Sri <Person> Rama 
</Person>;. <Person> Anoman </Person> juga 
bernama <Person> Bayutanaya </Person>, berarti 
yang diaku anak <Person> Betara Bayu </Person>;. 
<Person> Anoman </Person> juga bernama 
<Person> Kapiwara </Person>,. Bermula <Person> 
Anoman </Person> hidup pada jaman Sri <Person> 
Rama </Person>, membela Sri Ramapada waktu 
kehilangan permaisurinya, Dewi <Person> Sinta 
</Person>,yang dicuri oleh raja raksasa Prabu 
<Person> Dasamuka </Person> dari negara 
<Kingdom> Alengka </ Kingdom > 
Figure 3. Tagging result using non-detailed 
entities 
a) <Person> Anoman </Person>  anak <Person> Guru 
</Person>  
b) <Person> Anoman </Person> bernama <Person> 
Maruti </Person> 
c) <Person> Anoman </Person> disebut saudara 
<Person> Werkudara </Person>  
d) <Person> Anoman </Person> bernama <Person> 
Ramadayapati </Person> 
e) <Person> Anoman </Person> bernama <Person> 
Bayutanaya </Person> 
f) <Person> Bayutanaya </Person> berarti diaku anak 
<Person> Bayu </Person> 
g) <Person> Anoman </Person> bernama <Person> 
Kapiwara </Person> 
h) <Person> Anoman </Person> hidup jaman <Person> 
Rama </Person> 
i) <Person> Rama </Person>membela Ramapada 
waktu kehilangan permaisurinya <Person> Sinta 
</Person> 
j) <Person> Sinta </Person> dicuri raja raksasa 
<Person> Dasamuka </Person>  
k) <Person> Dasamuka </Person> negara <Kingdom> 
Alengka </Kingdom> 
 
Figure 5 The list of patterns as a result of 
eliminating irrelevant information 
 
130
is considered valid. 
3. Discard punctuation and do the trimming. 
4. If there is a pattern that is empty or exceeds 
5 words, the pattern is considered invalid. 
5. Change the pattern to lowercase. 
The result of the data in Figure 3 after this 
process can be seen in Figure 5. 
Subsequently, we perform feature extraction 
by converting the textual data into matrix form. 
This matrix contains the occurrence of candidate 
patterns between all possible pairs of entities. 
There are two types of feature extraction tried 
out in this study, i.e. based on entity pairs and 
entity type pairs. The cell in row i and column k 
of this feature matrix is the occurrence frequency 
of the ith pattern and the kth entity pair. The 
matrix form of Figure 5 when using feature 
extraction based on entity pairs is depicted in 
Figure 6. The next step is to perform relation 
clustering using semantic relational similarity as 
a similarity measure in a feature domain. The 
text patterns contained in each cluster are 
deemed to represent the same relationship. The 
clustering process will ignore candidate patterns 
that occur less than twice in the corpus. The 
result of this process is a set of clusters that each 
contains textual patterns that have a greater or 
equal similarity degree to a given threshold. The 
pseudocode of this algorithm is depicted in 
Figure 7. 
The generated clusters in this process 
comprise the relations found in the constructed 
ontology. The representative pattern, i.e. the 
candidate pattern that has the highest occurrence 
frequency within a cluster, will be used as a 
property that describes the relationship 
represented by a cluster. Suppose there is a 
cluster that contains three candidate patterns, e.g. 
?anak? (child of) with an occurrence frequency 
of 40, ?putera? (son of) with an occurrence 
frequency of 30, and ?mendekati? (come near to), 
with an occurrence frequency of 3. By using the 
representative pattern ?anak? as a property, it is 
assigned as the relation between pairs of entities 
found within this cluster. The illustration of the 
constructed ontology after clustering is depicted 
in Figure 8. 
Relation Clustering Algorithm 
Input   : pattern P = {p1, p2, .., pn}, threshold ? 
Output: cluster C 
1: 
2: 
3: 
4: 
5: 
6: 
7: 
8: 
9: 
10: 
11: 
12: 
13: 
14: 
15: 
16: 
17: 
18: 
19: 
SORT (P) 
C ?{} 
for pattern pi ? P do 
       max ? -? 
       c* ? null 
       for cluster cj ? C do 
             sim ? cosine (pi,cj) 
            if sim > max then 
                max ? sim 
                c* ? c* ? cj 
            end if 
       end for 
     if max ? ? then 
         c* ? c* pi 
     else 
           C ? C ? ?  
     end if 
end for 
return C 
Figure 7. Relation Clustering Pseudocode 
 
Figure 8. The illustration of constructed 
ontology subsequent to relation clustering 
 
Figure 6. The matrix form of Figure 5 
131
2.2 Evaluation  
2.2.1 Reference Ontology 
To measure and ensure that the quality of the 
constructed ontology is in accordance with what 
is desired, we evaluate the constructed ontology 
against a reference ontology. The reference 
ontology acts like a ?label? on the testing data in 
machine learning. The testing data label used in 
the evaluation process is used to determine how 
accurate and reliable the model established by 
machine learning is in recognizing unseen data. 
The evaluation process is performed by 
comparing the relations in the constructed 
ontology with the labeled testing data. As well as 
the data labels in machine learning, the reference 
ontology will be used to test how accurate the 
system is able to generate ontology from free text. 
We define several ontology components that 
can be obtained from the knowledge of a 
particular topic. This knowledge is obtained by 
looking at the types of entities and relations 
among them. It can also be obtained by looking 
at the group/category of any entity in the text. 
Each group/category defines the entity 
relationship that will occur between one entity to 
another one.  
The ontology components which are defined 
in the reference ontology are concept and 
property. An illustration of the relationship 
between concept and property can be seen in 
Figures 9 and 10. A concept is something that is 
described in the ontology and it can be one of: 
objects, category or class. Concepts in the 
reference ontology are entities that are 
incorporated within the gazetteer categories i.e. 
puppet character, spell, weapons, and nations.  
The ontology property describes the 
relationship between one concept to another. By 
observing the entity and relationship between 
them we can obtain the potential properties. For 
example, there are several entity groups, e.g. 
puppet character, kingdoms, weapons, and spell. 
Between each group there is the relationship that 
may occur. This relationship may occur between 
entities within the group/category or among 
entities contained in different group/categories. 
In this reference ontology, the authors define 
certain properties that potentially appear in the 
text. There are 14 properties which consist of 11 
properties describing the relationship between 
person and person, 1 property describing the 
relationship between person and country, 1 
property describing the relationship between 
person and weapon, and 1 property describing 
the relationship between person and spell. The 
relationship between concepts in the reference 
ontology is depicted in Figure 11. 
2.2.2 Evaluation method 
After relation clustering, each cluster is grouped 
based on the reference ontology property. This 
grouping is performed based on the synonym of 
the representative pattern on particular cluster 
and the property of reference ontology. If the 
representative pattern does not match (i.e. does 
not contain a synonym) with the ontology 
reference property then it is ignored. 
In this research we use three evaluation 
methods i.e. cluster purity, instances of 
knowledge, and relations concept. 
1. Cluster Purity (CP) 
Cluster purity (CP) is the ratio between the 
 
Figure 9. The relation between concept and 
property in ontology 
 
Figure 10. The example of concept and 
property relation 
 
Figure 11. The relationship amongst 
concept in a reference ontology 
132
number of representative patterns and the 
number of all patterns in a cluster. Cluster Purity 
(CP) calculation ignores singleton clusters, i.e. 
when there is only one pattern in a cluster. It can 
be formulated as seen below: 
CP = ??j jN 1
1  
where ? (?1, ?2, ..., ?j) is the set of 
representative patterns for each cluster and N is 
the number of patterns in a set of clusters. 
Each cluster contains textual patterns and its 
occurrence frequency. For example, the result of 
relation clustering can be seen below.  
Cluster 1 
 
anak 32 
putra 12 
Cluster 2 raja 3 
Cluster 3 negara 24 
menangis 3 
The CP value of that relation clustering is 
%87.78)3241232( )2432( ???? ?
 
2. Instances Knowledge (IK) 
Instances Knowledge (IK) evaluation is intended 
to measure the information degree on each 
property. There is the possibility that the 
relationship among two entities is valid but the 
knowledge therein is not as expected. This 
evaluation is performed by conducting queries of 
multiple instance samples. The queries are 
instance samples that have valid knowledge and 
are taken randomly from the corpus for each 
property. It can be formulated as seen below: 
IK (Propi) = 
???
?
???
? ?j j iopQNAvg 1 Pr
1   
where Propi is the i
th property, j is a query for the 
ith property, and N is the number of queries for 
the ith property. 
For example, there are 6 instances for 
property anak (child of). The instances are 
Kakrasana putra Basudewa , Werkudara putra 
Pandu., Kakrasana anak Baladewa, Rupakenca 
putra Palasara, Basukesti negara  Wirata, and 
Dandunwacana negara  Jodipati. 
Then there are 5 queries for this property i.e. 
Kakrasana putra Basudewa, Werkudara anak 
Pandu, Arjuna putra Pandu, Rupakenca putra 
Palasara, and Aswatama anak Durna. 
Based on that query, 3 instances are valid (1st, 
2nd, 4th) and the rest is invalid. Thus, the IK value 
is 
%6053 ?
 
3. Relation Concept (RC) 
Relation Concept is a measure to examine the 
valid relations in each property. A valid relation 
is an instance that has an appropriate relationship 
with the defined property in the reference 
ontology. This evaluation can be formulated 
below:  
(RC (Propi) = ?j opj iIvalidN 1 Pr )(
1  
where Propi is the i
th property , 
)( Pr iopjIvalid
 is 
the valid instances of the ith property, and N is 
the number of pattern. 
For example, there are 6 instances for 
property anak (child of). The instances are 
Kakrasana putra Basudewa ,Werkudara putra 
Pandu, Kakrasana anak Baladewa, Rupakenca 
putra Palasara, Basukesti negara Wirata and 
Dandunwacana negara  Jodipati. 
There are 4 instances (1st-4th) that are 
appropriate and 2 instance (5th-6th) that are not 
appropriate to property anak (child of). So that, 
the RC value is 
%66.6664 ?
 
3 Experimental Data and Setup 
In this research we obtain our raw web data from 
two separate sources: ki-demang.com and 
Wikipedia. Ki-demang.com is a website that 
contains various Javanese culture such as 
wayang, gamelan (Javanese orchestra), Javanese 
songs, Javanese calendar and Javanese literature. 
Meanwhile Wikipedia is the largest online 
encyclopedia, it provides a summary of 
Ramayana and Mahabharata characters.  
In this study, we will only use corpora in the 
Indonesian language, and use 3 types of corpora, 
namely ki-demang corpus (derived from ki-
demang.com), Wikipedia corpus (derived from 
id.wikipedia.org) and consolidated corpus 
(combination of ki-demang and Wikipedia 
corpus).   
Ki-demang corpus is containing wayang 
character annotations according to Javanese 
cultural community. The ki-demang corpus 
133
writing and spelling is not as good as the 
Wikipedia corpus. Punctuation and spelling 
errors frequently occur, as well as fairly complex 
sentence structures. This corpus consists of 363 
wayang characters; where there are 187 puppet 
characters that have annotations and 176 puppet 
characters that do not have annotations. 
The Wikipedia corpus has substances of 
wayang character annotation from the 
Mahabaratha and the Ramayana book and it also 
contains the description of particular characters 
in Indonesian culture. The Wikipedia corpus 
consists of 180 puppet characters, which all have 
their respective annotations.  
The last corpus is a combination of ki-demang 
and Wikipedia corpus. Merging data from both 
corpora is expected to enrich the annotation of 
wayang characters. Combining these data led to 
two perspectives in wayang character annotation, 
which is based on Mahabaratha/Ramayana book 
and based on the Javanese culture community. 
In this study, we will perform some 
experiments to examine the influence of various 
parameters. The parameters include the 
corpus data variety, the threshold value in the 
clustering process, and the usage of entity pair or 
entity type pair during feature extraction. 
4 Result and Analysis 
We conduct experiments for various parameters. 
The constructed ontology is evaluated using 
cluster purity (CP), instances knowledge (IK), 
and relation concept (RC).  The experiment 
results and details of various parameters can be 
seen in Figures 12 and 13.  
For the first experiment we want to evaluate 
the corpus variation. The objective of this 
experiment is to find the most representative 
corpus used in ontology construction. Based on 
the experiment, when the system is employing 
entity type pairs in feature extraction, ki-demang 
corpus has a high CP (76.54%) rate and a lower 
IK (11.49%) and RC (44.8%) rate. When the CP 
rate is high, it means that the pattern variation in 
particular cluster is modest and tends to be a 
singleton (only one pattern in a cluster). It is the 
impact of the information homogeneity of ki-
demang corpus compared to the other corpora. 
The IK and RC rate of Wikipedia corpus and 
consolidated corpus is better than ki-demang 
corpus. The Wikipedia corpus has better 
information content compared to the ki-demang 
corpus, thus the consolidated corpus has a better 
RC and IK rate compared to individual corpora. 
Meanwhile, when the system employs entity 
pairs during feature extraction stage, the the 
consolidated corpus has a fairly better result 
compare to single corpus. It means that the 
consolidated corpus has richer information than 
ki-demang or Wikipedia corpus. 
The second experiment was conducted to 
evaluate the threshold value in clustering process. 
The objective of this experiment is to find the 
best threshold value for relation clustering. For 
further analysis in a corpus variation, we used 
the average value of cluster purity (CP), 
instances knowledge (IK) and relation concept 
(RC) for all corpora. When the system employs 
entity type pairs during feature extraction, the CP 
rate is 97.15%, IK rate is 49.43%, and RC rate is 
          Threshold    
 
Corpus 
1 0.75 0.5 0.25 
CP IK RC CP IK RC CP IK RC CP IK RC 
Ki-demang 96.53 19.54 63.95 96.52 19.54 63.95 95.88 19.54 62.02 94.27 12.64 58.83 
Wikipedia 99.38 79.31 75.60 98.66 79.31 76.24 88.71 75.86 67.14 65.31 75.86 61.10 
Consolidated 98.50 93.10 80.08 62.29 91.95 79.82 53.95 91.95 75.61 46.94 88.51 71.41 
Figure 12. The evaluation result of entity pair usage in feature extraction 
          Threshold   
 
 Corpus 
1 0.75 0.5 0.25 
CP IK RC CP IK RC CP IK RC CP IK RC 
Ki-demang 96.30 14.94 60.02 95.80 14.94 58.45 58.74 13.79 50.05 55.34 2.30 10.70 
Wikipedia 97.57 55.17 61.62 83.02 17.24 42.43 27.92 10.34 16.61 12.29 5.75 10.86 
Consolidated 97.58 78.16 71.60 42.74 57.47 63.49 59.01 12.64 8.97 44.24 14.94 21.05 
Figure 3. The evaluation result of entity pair type usage in feature extraction 
134
64.41% for threshold value is 1. This result is 
always higher than using other threshold value.  
Hereafter, when the system employs entity 
pairs during feature extraction, the CP rate is 
98.14%, the IK rate is 49.43%, and RC rate is 
64.41% for threshold value is 1. Given the 
experiment result, it is clear that a threshold 
value of 1 always gives a better result than the 
other threshold values. The higher pattern 
similarity in a cluster will yield a better 
constructed ontology result. 
The last experiment was conducted to 
evaluate the consequence of using entity pairs or 
entity type pairs during feature extraction to the 
constructed ontology. For further analysis in a  
feature extraction variation, we used the average 
value of cluster purity (CP), instances knowledge 
(IK) and relation concept (RC) for all threshold 
value in a clustering process.. Based on the 
experiment result above, the usage of entity pairs 
in feature extraction always brings a better result 
than the entity type pairs. When using entity type 
pairs in feature extraction, it will reduce some 
detail of extracted feature. The feature only 
describes the relationship of entity type, not the 
entity itself. This leads to suboptimally 
constructed ontologies. 
5 Conclusion 
This paper presented a model for automatic 
ontology construction from free text. Firstly, 
relation extraction is used to retrieve the 
candidate patterns. Furthermore, relation 
clustering is used to group relations that have the 
same semantic tendency. An experiment has 
been carried out on various parameters such as 
on the corpus variety, the threshold value in 
relation clustering process, the usage of simple 
process for eliminating irrelevant information 
and the usage of entity pairs or entity type pairs 
during feature extraction. 
Based on the experimental result, the 
consolidated corpus (combination of ki-demang 
and Wikipedia corpus) is most beneficial in 
ontology construction. By integrating the corpus, 
it will increase the information quality which 
yields a better result. Meanwhile for the other 
parameters, the most beneficial result is obtained 
when using 1 as a threshold value in clustering 
process, and using entity pairs during feature 
extraction. The higher pattern similarity in a 
cluster will yield a better resulting ontology. 
Furthermore, simple processing is employed to 
remove some punctuation, stopwords and 
honorifics which are a source of noise in the 
extracted patterns. The usage of entity type pairs 
during feature extraction will result in reduced or 
lost detail of pattern features and bring a 
detrimental consequence to the ontology result.  
References  
Agichtein, Eugene, & Gravano, Luis. 2000. Snowball: 
Extracting relations from large plain-text 
collections. Proceedings of the Fifth ACM 
International Conference on Digital Libraries,  
Alani, Harith, Kim, Sanghee, Millard, David. E., 
Weal, Mark J., Hall, Wendy, Lewis, Paul. H. and 
Shadbolt, Nigel. R. 2003. Automatic Ontology-
Based Knowledge Extraction from Web 
Documents.  IEEE Intelligent Systems, 18 (1). pp. 
14-21,. 
Amrih, Pitoyo. Galeri Wayang Pitoyo.com. 
http://www.pitoyo.com/duniawayang/galery/index.
php (accessed at November 4th, 2011) 
Banko, Michele, Michael J. Cafarella, Stephen 
Soderland,Matt Broadhead, and Oren Etzioni. 2007. 
Open information extraction from the web. 
InIJCAI?07: Proceedings of the 20th international 
joint conference on Artifical intelligence, pages 
2670?2676. 
Brin, Sergey. 1998 . Extracting patterns and relations 
from the world wide web. WebDB Workshop at 
6th International Conference on Extending 
Database Technology, EDBT  
Bunescu, Razvan. C., & Mooney, Raymond. J. 2005. 
A shortest path dependency kernel for relation 
extraction. HLT ?05: Proceedings of the conference 
on Human LanguageTechnology and Empirical 
Methods in Natural Language Processing (pp. 724?
731). Vancouver, British Columbia, Canada: 
Association for Computational Linguistics 
Celjuska, David and Vargas-Vera, Maria. 2004. 
Ontosophie: A Semi-Automatic System for 
Ontology Population from Text. In Proceedings 
International Conference on Natural Language 
Processing ICON., Hyderabad, India 
Culotta, Aron, McCallum, Andrew, & Betz, Jonathan.  
2006. Integrating probabilistic extraction models 
and data mining to discover relations and patterns 
in text. Proceedings of the main conference on 
Human Language Technology Conference of the 
135
North American Chapter of the Association of 
Computational Linguistics (pp. 296?303). New 
York, New York: Association for Computational 
Linguistics. 
Etzioni, Oren, Cafarella, Michael, Downey, Doug, 
Popescu, Anna-Mariana, Shaked, Tal, Soderland, 
Stephen, Weld, Daniel S., & Yates, Alexander. 
2005. Unsupervised Named-Entity Extraction from 
the Web: An Experimental Study. Artificial 
Intelligence (pp. 191?134). 
Kambhatla, Nanda. 2004. Combining lexical, 
syntactic, and semantic features with maximum 
entropy models for extracting relations. 
Proceedings of the ACL  
Shamsfard Mehrnoush , Barforoush Ahmad 
Abdollahzadeh. 2004. Learning Ontologies from 
Natural Language Texts, International Journal of 
Human- Computer Studies, No. 60, pp. 17-63,  
Zelenko, Dmitry, Aone, Chinatsu, & Richardella, 
Anthony. Kernel methods for relation extraction. 
Journal of Machine Learning Research, 2003 . 
Zhao, Shubin, & Grishman, Ralph. Extracting 
relations with integrated information using kernel 
methods. Proceedings of the 43rd Annual Meeting 
on Association for Computational Linguistics (pp. 
419?426, 2005 
 
136
