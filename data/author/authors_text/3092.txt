The Queen?s Agents: Using Collaborating Object-Based Dialogue Agents  
in the Queen?s Communicator 
Ian O?Neill, Philip Hanna, Xingkun Liu 
School of Computer Science  
Queen?s University 
Belfast BT7 1NN, N. Ireland 
{i.oneill, p.hanna, 
xingkun.liu}@qub.ac.uk 
Michael McTear 
School of Computing and 
Mathematics 
University of Ulster 
Jordanstown, BT37 0QB, N. Ireland 
mf.mctear@ulster.ac.uk 
 
Abstract 
A dialogue manager provides the decision 
making at the heart of a spoken dialogue 
system. In an object-oriented approach to 
dialogue management, generic behaviour, such 
as confirming new or modified information that 
has been supplied by the user, is inherited by 
more specialised classes.  These specialised 
classes either encapsulate behaviour typical of a 
particular business domain (service agents) or 
make available dialogue abilities that may be 
required in many business domains (support 
agents).  In this paper we consider the interplay 
between the agents? generic and specialised 
behaviour and consider the manner in which 
service and support agents collaborate within 
and across their respective groups. 
1 Object-orientation and cross-domain, 
mixed initiative dialogue 
Object-orientation provides an intuitive 
separation of, on the one hand, inheritable generic 
functionality and, on the other hand, domain-
specific, specialized functionality that is supported 
by the generic elements of the system.  Applied to 
the area of natural language dialogue, this has 
enabled us to create a generic, automated dialogue 
confirmation strategy ? based on confirmation 
statuses and discourse pegs (see Section 3.3) ? 
which supports domain-specific strategies to gather 
and provide information relating to particular 
transactions ? for example booking a hotel or 
finding out about cinema times.  Heuristics, or 
expert rules, specific to each transaction domain, 
prompt the user for significant missing information 
or assist the user by providing choices from a 
database (e.g. names of available hotels). 
Thus, while our generic confirmation strategy 
ensures that information newly supplied by the 
user is confirmed, and information changed is 
reconfirmed, and so on, the nature of that 
information may differ significantly from domain 
to domain.  Likewise the system may respond to 
confirmed information in quite different ways 
depending on the domain ? as it either completes a 
domain-specific transaction or attempts to elicit 
important missing information from the user.   
In the Queen?s Communicator dialogue system, 
expertise for different transaction domains is 
encapsulated within corresponding expert classes 
or ?agents?.  We have used this to our advantage by 
enabling the system to transfer between domains 
either at the user?s or the system?s initiative ? in a 
mixed initiative dialogue either the user or the 
system may introduce new topics. Agents are able 
to announce their abilities to the system at large, or 
indeed to the user.  Thus, when key words or 
phrases uttered by the user indicate that the topic 
of conversation has turned, for example, from 
accommodation booking to payment, the system?s 
DomainSpotter (see Section 4) can ask the agents 
if any of them deal with payments.  The most 
suitable agent is then given the task of managing 
the specialised subdialogue.  
2 Spoken dialogue management 
A spoken dialogue system typically comprises a 
number of components: an automatic speech 
recogniser, a semantic parser, a dialogue manager 
(DM), a database ?back-end?, a natural language 
generator, and a text-to-speech engine.  The focus 
of our present research is the development of an 
object-based DM that can support mixed initiative 
dialogues that involve a number of business 
domains.  
Our DM operates within the DARPA1 
Communicator architecture, which is based on the 
Galaxy hub ? a software router  developed by the 
Spoken Language Systems group at MIT  
(www.sls.csail.mit.edu/sls/technologies/galaxy.shtml) 
and subsequently released as an open source 
package in collaboration with the MITRE 
Corporation (fofoca.mitre.org).  In the ?Queen?s 
Communicator? dialogue system, our newly 
developed DM interacts with a number of off-the-
shelf components. For semantic parsing we use 
Phoenix (W. Ward, 1994), available from the 
                                                     
1 Defense Advanced Research Projects Agency 
University of Colorado?s ?CU Communicator? 
download (communicator.colorado.edu).  For 
recognition we use the Microsoft English ASR 
Version 5 Engine as supplied with Windows XP.  
Synthesised speech is provided by Festival 
(www.cstr.ed.ac.uk/projects/festival/), also taken 
from the CU download.  Figure 1 shows a typical 
Communicator configuration. 
 The DM itself embodies decision-making 
similar to that of a human interlocutor as it queries, 
responds to and informs the user. Moreover, in 
mixed initiative dialogues that deal with more than 
one domain (e.g. enquiries about accommodation 
and events, and supporting exchanges about 
payment and addresses), the system has the 
additional task of identifying the (ongoing) topic of 
the dialogue and applying appropriate dialogue 
management expertise. 
3 Object-based dialogue agents 
3.1 A multi-agent approach to dialogue 
management 
In order to enable mixed initiative interactions 
across domains, we model the system?s behaviour 
as a collaboration between the cohort of 
implemented agents.  Other developers have also 
adopted an agent-based approach to dialogue, 
though sometimes dialogue agents each perform 
very simple tasks rather than engage in extensive 
discourse: in (Turunen and Hakulinen, 2001) for 
example, simple generic error-handling agents, 
based on Java and XML, ask the user to repeat 
misunderstood input.  In our case an agent is a 
specialist in a particular transactional area ? e.g. 
booking accommodation or eliciting an address.  
An agent uses its own domain-specific ?expert-
rules? to elicit information (e.g. information for 
making a hotel booking) that is then stored in a 
specialised dialogue frame.  Each agent thus 
encapsulates a skillset for a substantial dialogue or 
subdialogue.     
Like the Communicator team at Carnegie Mellon 
University, we view the dialogue product (the 
knowledge to be elicited) as a tree-like structure 
(Rudnicky and Xu, 1999) ? though for us the nodes 
are complete dialogue frames rather than 
individual data items.  In the Queen?s 
Communicator the discourse structure evolves 
dynamically as agents are selected by a 
DomainSpotter, in the light of the user?s utterances 
or as a consequence of the agents? own rules.  It is 
this process, rather than an overarching dialogue 
plan or agenda, that drives the discourse forward, 
sometimes across domain boundaries.  We do, 
however, maintain an ExpertFocusStack, which 
contains, in sequence, the name of the agent that is 
currently handling the dialogue and the names of 
agents that have last handled the dialogue and have 
unfinished business: this allows the system to 
quickly identify the current handler and to pass 
control back, once the current handling agent is 
finished. 
3.2 Inherited and domain-specific behaviour 
Our dialogue manager is implemented as a suite 
of Java classes (see Figure 2).  The object-based 
approach (Booch, 1994) (O?Neill and McTear, 
2000) has afforded us certain advantages.  The 
domain specialists or ?Experts? within our system 
? AccommodationExpert, TheatreExpert, 
CinemaExpert, CreditCardExpert, etc. ? all inherit 
generic dialogue handling skills from a 
DiscourseManager, whose role is to ensure that 
new information provided by the user is at least 
implicitly confirmed, and information that is 
changed or negated is subjected to more detailed, 
explicit confirmation (O?Neill and McTear, 2002) 
(O?Neill et al 2003).  The domain experts 
encapsulate specialised behaviour, which can be 
readily extended by additional classes.  There are 
two families of domain experts: 
y ?service agents? that provide front-line services 
to the user  ? like AccommodationExpert, 
whose behaviour emulates that of a human 
booking clerk, and 
y ?support agents? like CreditCardExpert that are 
able to elicit information required to complete 
one of the front-line service transactions. 
We refer to the corresponding discourse 
segments as ?service? and ?support? dialogues 
respectively.  By assigning the agents (and the 
corresponding dialogues) to one of two families we 
give ourselves the option of restricting user-led 
transitions between main and ancillary 
transactions. However, the overall objective of our 
implementation is to maintain a high degree of 
flexibility in the manner in which the system reacts 
to unsolicited user utterances. 
3.3 Using frames of information 
The agents, whether they provide service or 
support, collect and manipulate frames of 
Speech Recogniser
Natural Language
Semantic Parser
Dialogue Manager
Natural Language
Generator
Speech synthesiser
Database
Galaxy
hub
 
Figure 1. DARPA Communicator architecture. 
 
information related to their own sphere of 
competence.   The frames consist of Attribute 
objects, each of which stores:  
y the type and elicited value of a single piece of 
information (datum);  
y the confirmation status of the datum (e.g. 
new_for_system);  
y the level to which the datum has been 
confirmed (through repetition, or by the user?s 
affirmative response to a system prompt ? the 
level is represented by a simple numeric 
?peg?);  
y and the system intention regarding the datum 
(e.g. implicitly confirm new information; 
explicitly confirm information that has been 
negated; ask the user to specify information 
that is still required) (Heisterkamp and 
McGlashan, 1996). 
The Attribute objects thus give a multi-facetted 
view of each piece of information that it is being 
considered by the system.  The evolving domain-
specific (and thus generally agent-specific) frames 
of Attributes are maintained on a DiscourseStack 
within the DiscourseHistory object.  The agents 
use this stack to implement the inherited generic 
confirmation strategy. The frames of information 
are typically populated in the course of several 
discourse turns, as new or additional information is 
acquired from successive user-system interactions.   
Once it is handling a particular discourse segment, 
an agent uses its inherited confirmation strategy to 
compare the latest values in its current dialogue 
frame with the corresponding values and system 
intentions in the previous iteration of that frame.  
Thus the agent is able to determine which values 
have been confirmed (e.g. the user has not 
challenged an implicit confirmation request by the 
system) and which have been modified or negated. 
3.4 Applying expert rules 
In addition to its inherited confirmation 
strategies, each of the domain Experts, whether a 
service agent or a support agent, has its own expert 
rules, contained in one or more expert rule 
sequences.  Typically the expert rule sequences 
will be of one of two kinds: 
y ?user-focussed rules?, which determine the 
agent?s reaction to particular combinations of 
information supplied by the user ? must the 
system now ask a follow-up question, must it 
perform a database look-up, or can it conclude 
a transaction ? ? and  
y ?database-focussed rules?, which represent the 
agent?s dialogue furthering strategy when 
database queries based on user-supplied 
combinations of information fail: because of 
its access to database content, the system may 
be able to modify a user-supplied constraint 
and so formulate a database query that will 
succeed (e.g. the system might suggest a four-
star hotel if it cannot meet the user?s request 
for a five-star hotel in a particular locality.) 
These rules, encapsulated within the appropriate 
agent (e.g. AccommodationExpert), are applied to 
information that the agent has ?phrase-spotted? and 
placed in the appropriate dialogue frame (e.g. an 
AccommodationDialogueFrame). Sequences of 
rules, encapsulated within service and support 
agents and tested to see which rule can fire in the 
current discourse state, collectively embody the 
kinds of domain-specific behaviour that 
characterise a human expert. 
DiscourseHistory 
 
-- store generated dialog  
 frames 
-- contains 
UtteranceStore, 
InfoStore, and 
DiscourseStack 
* 
DialogServer 
 
-- provide Galaxy hub  
 interface 
DialogManager 
 
-- contains a number of  
 EnquiryExpert subclass  
 instances 
-- contains a DiscourseHistory  
 instance shared between  
 the instantiated experts. 
-- contains a DomainSpotter  
 instances to exercise high- 
 level control over experts. 
Discourse 
Manager 
-- implement generic  
    confirmation strategy 
 
EnquiryExpert 
 
-- generic processing  
 enquires 
-- enables an expert to  
 act as a service or  
 support agent 
 
DialogFrame 
 
-- provide generic dialog 
frame functionality 
 
Event 
DialogFrame 
 
-- event-specific dialog  
    frame 
Acco 
DialogFrame 
 
-- accommodation- 
    specific dialog frame 
Attribute 
 
-- individual dialog frame  
 attribute 
ExpertRuleSequence 
 
-- collection of related  
 expert rules 
 
DBRequest 
 
-- encapsulate expert  
  initiated DB request 
 
Accommodation 
Expert 
 
-- accommodation  
 enquiry expertise 
 
EventExpert 
 
-- domain-specific  
    processing for events 
TheatreExpert 
 
 
 
-- domain-specific theatre  
    enquiry expertise 
CinemaExpert 
 
 
 
-- domain-specific cinema  
 enquiry expertise 
1 1 
* 
Creates 
1 
1 1 * 
Invoice 
PaymentExpert 
 
 
-- domain-specific   
 cheque processing 
Cinema 
DialogFrame 
 
 
-- cinema-specific dialog   
    frame 
CreditCard 
PaymentExpert 
 
-- domain-specific credit- 
    card processing 
CreditCard 
DialogFrame 
 
 
-- credit-card specific  
    dialog frame 
Payment 
DialogFrame 
 
-- payment specific 
dialog frame 
PaymentExpert 
 
-- generic-payment  
 processing 
Theatre 
DialogFrame 
 
 
-- theatre-specific dialog  
    frame 
ExpertRule 
 
-- individual database-  
 or user-focussed rule 
 
1 
1 1 
* 
1 
* 1 
1 
Service Agent Hierarchy Support Agent Hierarchy Dialog Frame Hierarchy 
DomainSpotter 
 
-- determine and  
 maintain enquiry 
f
 
Figure 2: Class diagram of the dialogue manager. 
4 Finding the right agent 
4.1 Apppointing an initial handling agent 
To begin the dialogue, in order to identify the 
most appropriate ?handling agent?, the 
DomainSpotter supplies each service agent with 
the output of the semantic parse that represents the 
user?s utterance. As it attempts to find an initial 
handling agent, the DomainSpotter considers only 
service agents (like AccommodationExpert or 
CinemaExpert) and not support agents (like 
CreditCardExpert).  The service agents represent 
the primary transaction types (booking a hotel 
room, enquiring about a movie, etc.) that the 
system handles: the system is not, for example, 
intended to allow the user to process their credit 
account, though it may elicit credit card details in 
support of a service (a hotel booking for instance).  
Such restrictions help the system ground its 
primary functions with the user.  Each service 
agent scores the parse of the initial user utterance 
against the semantic categories that it can process 
(each agent has a range of integer values ? degrees 
of relevance ? that it will assign to different 
domain-specific parse tags) and returns the score to 
the DomainSpotter.  The service agent that scores 
highest is the one that the DialogManager asks to 
apply its domain-specific heuristics to the more 
detailed processing of the enquiry.  For example, 
an AccommodationExpert might score highest and 
so become handling agent if the user has been 
asking about hotels in Belfast.  Specialised agents 
give a higher score for specialised parser tags than 
generic agents.  For example, a user request ?I?d 
like to go to see Finding Nemo.? might parse as: 
event_enquiry:[Event_type].[Movies].FINDING 
NEMO. Although the EventExpert could award a 
score for event_enquiry, the CinemaExpert, as a 
child of EventExpert, would award a score not 
only for event_enquiry, but for Movies as well, and 
so would be the winner. 
4.2 Finding out what the system can do 
If the DomainSpotter is unable to identify a 
winning agent, it will ask the user to choose 
between the domains in closest contention.  
Indeed, if the user?s enquiry is so vague as to give 
no domain-related information (?I?d like to make 
an enquiry.?), the DomainSpotter will ask the user 
to choose from one of its highest level service 
agents: ?Please choose between event booking or 
accommodation booking.? ? the words in italics are 
actually provided by the service agents.  The 
DomainSpotter is in effect relaying to the user 
information that the system components know 
about themselves: it is part of the system?s design 
philosophy that higher level components are 
largely ignorant of the precise capabilities of lower 
level components. Similarly, if a service agent 
needs to avail of a support agent in a particular 
area, it tells the DomainSpotter to find it an expert 
that handles the particular specialism (payments, 
for instance): it does not name a specific expert 
object.  So that its area of expertise can be 
identified, each agent has, as one of its attributes, a 
vector of the specialisms it deals with.  The 
intention is that additional lower level expertise 
can be added to the system in such a way that 
higher level behaviour (i.e. requesting the 
expertise) remains unchanged.  Where more than 
one expert (e.g. CreditCardExpert and 
InvoiceExpert) can deal with the requested 
specialism (e.g. payments), the DomainSpotter 
asks the user to choose. 
4.3 Transferring control between service and 
support 
In order to maintain the enquiry focus we use an 
ExpertFocusStack in the DiscouseHistory.  Once 
an agent is selected to handle the current discourse 
segment, it is pushed on to the top of the stack.  
The agent then uses its expert rules to elicit all the 
information needed to complete its discourse 
segment: an AccommodationExpert, for example, 
will be looking for all information needed to 
complete an accommodation booking.  Depending 
on the rules it encapsulates, a service agent may 
require help from a support agent.  For example, if 
an AccommodationExpert has confirmed sufficient 
information to proceed with a reservation, it will 
request help from an agent whose specialism is 
payment, and the DomainSpotter will look for one   
Let us pursue this example further. The 
PaymentExpert is identified as an appropriate 
payment handler, and is placed above 
AccommodationExpert on the ExpertFocusStack.  
However, let us suppose that eliciting payment 
details first involves eliciting address details, and 
so the PaymentExpert in its turn asks the 
DomainSpotter to find it an agent specialising in 
address processing ? in this case the 
AddressExpert.  The AddressExpert now goes to 
the top of the ExpertFocusStack, above the 
PaymentExpert.  Just like any other agent the 
AddressExpert has its own rules that allow it to 
accept typical combinations of information 
supplied (prompted or unprompted) by the user 
and to ask appropriate follow-up questions for 
whatever information is still missing.  Once a 
support agent has all the information it needs, one 
of its rules will fire to ?pass control back?, along 
with a ?finished? message, to whatever agent was 
below it on the ExpertFocusStack.  The ?finished? 
agent is removed from the stack.  Thus 
AddressExpert will pass control back to 
PaymentExpert in this example, whose rules, if the 
user does not introduce a new topic, will continue 
to fire until all necessary payment information has 
been elicited and the payment subdialogue can be 
concluded ? at which point control is passed back 
to the AccommodationExpert. 
4.4 Dialogue frames and user-led focus shifts 
However, a mixed initiative dialogue manager 
needs to be able to cope with user-initiated shifts 
of discourse focus. For example, a user may supply 
address information unprompted while the 
system?s intention is first to elicit the information 
shown on the user?s credit card.  At present we 
permit transfer of dialogue control between service 
agents: a user may, for example, want to discuss an 
event booking more or less in parallel with making 
accommodation arrangements.  In order to ground 
the dialogue by eliciting information in a definite 
context, we impose some restrictions on user-
initiated shifts of focus between support dialogues, 
and between support and service dialogues.  
Dialogue frames are instrumental in implementing 
these policies. 
Dialogue frames help identify the support 
dialogues associated with each service dialogue: 
the specification of each frame type (e.g. an 
AccommodationDialogueFrame) indicates the type 
of each of its Attributes, some of which may 
themselves be links to other frames (e.g. a 
PaymentDialogueFrame).  Dialogue frames that 
are associated with service dialogues can be 
expanded into a tree-like structure by recursively 
traversing the various support frames that are 
linked to the service dialog frame.  For those 
frames which have already been in the discourse 
focus (i.e. frames representing dialogue tasks that 
have already been the subject of user-system 
interaction), this is a straightforward task.   
Additionally the frames of possible future handling 
agents can be predicted and included within the 
tree through the use of the DomainSpotter.  For 
example, at the outset of an accommodation 
enquiry, the related service dialogue frame will not 
generally contain an explicitly linked payment 
frame. However, the DomainSpotter is able to 
determine which agents can provide payment 
support, and so the system generates a number of 
potential discourse paths relating to payment. Key 
words in the user?s utterances determine which 
path is in fact used and which payment-related 
frames are linked to the accommodation frame.    
As the dialogue evolves, the DomainSpotter 
tests which agents are best placed to handle the 
user?s last utterance: the tree of dialogue frames 
indicates to the DomainSpotter which support 
agents have been or may be involved in the current 
service enquiry, and should therefore be 
considered; the DomainSpotter will poll service 
agents as a matter of course.  If the user?s utterance 
is scored most highly by a support agent (relevant 
to the current service) whose topic has already 
been in the discourse focus, the user can return to 
this topic (the shift may indicate the user?s 
intention to add to or modify information that was 
previously supplied). As a safeguard, the system 
places on the ExpertFocusStack any support agents 
whose rules fired on the previous path to the 
revisited agent, and these support agents will be 
allowed to test their rules again (new address 
information, for instance, may affect a credit card 
option ? e.g. if the revised address is in UK, the 
CreditCardExpert may mention UK cardholder 
offers, etc.).  The system uses the linked dialogue 
frames of topics that have already been in the 
discourse focus to determine the order in which 
such support experts should be placed on to the 
ExpertFocusStack   
 Other requests for shifts of focus from and 
between support agents are generally deferred 
(?Thanks, I?ll take the address details in a 
moment??), until the rules of the current support 
expert allow transfer.  The system does not ignore 
the contents of the utterance that led to the 
deferral: the DiscourseHistory contains an 
UtteranceStore, a stack of the parses of the user?s 
utterances.  When it takes control of the dialogue, 
because one of the handling expert?s rules has 
allowed it to, an agent first looks to the 
UtteranceStore to see if there is any unprocessed 
information that it can handle.  If there is, it takes 
the unprocessed parsed information and begins its 
processing as usual with its inherited confirmation 
strategy and its domain-specific expert rules (?So 
you said the street address was 18 Malone Road. 
Can I have the city please??). 
5 The Queen?s Communicator in action 
The following portion of dialogue is typical of 
the exchanges currently supported by the system.  
User utterances are shown as U1, U2, etc.  System 
utterances (S1a,?, S2, etc.) are taken from our 
new natural language generation (NLG) module, 
which we are continuing to develop.  The NLG 
module takes as its input the semantic constructs 
output from the DM.  These constructs are shown 
thus: MESSAGE: process?, etc.  A brief 
commentary, indicating which main features of the 
DM are being called into play, is given at key 
points in the dialogue and is printed in italics. 
 
U1: I?d like to book a three-star hotel in Belfast 
from the fifteenth of August to the twentieth of 
August.  
Key words like three-star and hotel fall within 
the accommodation domain, and are scored by the 
AccommodationExpert .  Accordingly the Domain-
Spotter appoints the AccommodationExpert 
?handling agent?.  The AccommodationExpert 
populates its AccommodationDialogFrame with 
whatever relevant information has been supplied 
by the user. 
 
S1a:  OK, let's start a new accommodation 
booking. OK, that's a three-star hotel in Belfast 
from 2004-08-15 until 2004-08-20.  Please wait... 
 
MESSAGE: process accommodation  
   booking 
MESSAGE: GIVEN  
         AccoType [ HOTEL  ]  
         AccoClass [ three-star  ]  
         Location [ BELFAST  ]  
         DateFrom [ 2004-08-15 ]  
         DateTo [ 2004-08-20 ]  
MESSAGE: database enquiry initiated 
 
The AccommodationExpert uses the generic 
confirmation strategies that it has inherited from 
the DiscourseManager to implicitly confirm new 
values, and it uses its own domain-specific rules to 
initiate a database lookup that will retrieve names 
of hotels that match the user?s criteria.  
 
S1b: You can choose between the following: the  
Jurys or Lisdara. Which would you prefer? 
 
PROMPT: SPECIFY  
AccoName [ jurys  ]  
         [ lisdara  ] 
 
U2:  Could you make that a four-star? 
Although the system in its utterance suggests 
that the user should select one of the hotel names 
retrieved from the database, the user may provide 
information different to that which was requested, 
since this is a mixed initiative system.  In this case 
the user changes the star-rating, instead of 
selecting a hotel name. 
   S2: Ok, got it. So that's a four-star? 
 
MESSAGE: user changed value  
         AccoClass [ four-star  ]  
QUERY: confirm changes 
 
Again, using its inherited confirmation strategy, 
the AccommodationExpert compares the value for 
the star-rating in the previous frame with the star-
rating in the current frame and performs a ?repair- 
confirm? on the changed value.   
 
U3: Yes, that?s right. 
 
S3a:  Please wait... 
 
MESSAGE: database enquiry initiated 
 
   S3b:  You can choose between the following: the  
Europa,  Malone Lodge,  Stormont or Holiday Inn. 
Which would you prefer? 
 
PROMPT: SPECIFY  
        AccoName [  europa  ] 
               [  malone-lodge  ]  
               [  stormont  ]  
               [  holiday-inn  ]     
 
U4:  I?ll go for a double room at the Europa. 
 
S4:  So that's the four-star Europa hotel in 
Belfast with a double room, from 2004-08-15 until 
2004-08-20. Is that correct? 
 
MESSAGE: explicit confirm values 
         AccoName [ europa  ]  
         AccoType [ HOTEL  ]     
         AccoClass [ four-star  ] 
         Location [ BELFAST  ]  
         AccoRoomType [ double  ]  
         DateFrom [ 2004-08-15 ]  
         DateTo [ 2004-08-20 ]  
QUERY: CONFIRM values 
 
In the current system implementation the 
handling agent explicitly confirms all ?key? values 
needed to conclude a major segment of the 
discourse ? once these have been supplied by the 
user.   
 
U5:  Make that a single room. 
In this case, however, the user again changes 
his/her mind.  The immediate next steps in the 
dialogue (not shown here) would be to reconfirm 
the ?key? values, including the newly changed 
value; then ask if the user wishes to check 
availability and reserve; and if so elicit payment 
details with the aid of the PaymentExpert and 
AddressExpert components... 
6 Related work 
Although some currently available dialogue 
systems use object components in accordance with 
the latest software engineering orthodoxy ? (Allen 
et al, 2000) ? little published research addresses 
the question of how established techniques of 
object-oriented software engineering (Booch, 
1994) (Booch et al, 1998) can contribute to the 
dialogue management task.   
Some research groups confirm the suitability of 
Java for the development of interactive, agent-
based systems ? for example COLLAGEN (Rich et 
al. 2001).  Indeed, the COLLAGEN architecture, 
like that of the Queen?s Communicator, manages 
discourse using a ?focus stack?, a classical idea in 
the theory of discourse structure (Grosz and 
Sidner, 1986).  
For dialogues that are not primarily transaction- 
based or frame-based, and where the system must 
establish the user?s broader objectives before 
offering advice or presenting options, a discourse 
management strategy based on problem-solving 
(PS) objects (objectives, recipes, actions and 
resources) is appropriate (Blaylock et al, 2003).  
We are currently investigating means of using PS 
objects to orient a dialogue, before using expertise 
like that currently encapsulated in our domain 
agents to complete those frame-filling tasks that 
are needed to support the user?s objectives.  
7 Conclusions 
We have decomposed the cross-domain dialogue 
management task intuitively into a number of sub-
dialogues, each conducted by an implemented 
domain specialist with its own expert rules and 
associated frame of information to collect.  By 
using inheritance we easily establish a common 
approach to dialogue management, independent of 
domain: all experts inherit the same confirmation 
strategy.  Through inheritance we ensure that 
domain experts have common characteristics: they 
all have sequences of ?expert rules? that they can 
apply to user-supplied information to determine 
what the system should do next.  Domain spotting 
enables us to identify appropriate dialogue 
handling expertise for each of the user?s utterances.  
Since our DomainSpotter actively looks for 
relevant expertise amongst the cohort of service 
and support agents, new expertise can readily be 
added without disturbing the system?s fundamental 
dialogue management strategies.  Additionally, 
division of the available experts into (front-line) 
service agents and (ancillary) support experts helps 
us maintain discourse context by deferring user-led 
shifts of focus that interrupt coherent data 
elicitation.   
Future developments are likely to include: 
addition of new dialogue domains (e.g. travel); and   
incorporation of multiple dialogue strategies (using 
frames for mixed initiative transactions, PS objects 
for collaborative problem solving, and finite state 
transition networks for system-led interaction). 
Multimodal input will also be considered, 
including input relating to the user?s emotional 
state, as a factor for dynamically determining an 
appropriate dialogue strategy for a particular 
discourse segment.  
8 Acknowledgements 
This research is supported by the EPSRC under 
grant number GR/R91632/01. 
References  
J. Allen, D. Byron, M. Dzikovska, G. Ferguson, L. 
Galescu and A. Stent. 2000. An Architecture for 
a Generic Dialogue Shell.  Natural Language 
Engineering 6 (3?4), pp. 1-16, Cambridge 
University Press. 
N. Blaylock, J. Allen and G. Ferguson. 2003.  
Managing communicative intentions with 
collaborative problem solving.  Current and New 
Directions in Discourse and Dialogue (eds. J. 
van Kuppevelt and R. Smith), pp. 63 ? 84, 
Kluwer, Dordrecht. 
G. Booch. 1994. Object-Oriented Analysis and 
Design with Applications (2nd Edition).  
Benjamin/Cummings, Redwood City, CA. 
G. Booch, J. Rumbaugh and I. Jacobson. 1998. The 
Unified Modeling Language User Guide.  
Addison Wesley Longman, Reading, MA. 
B. Grosz and C. Sidner. 1986. Attention, 
Intentions, and the Structure of Discourse. 
Computational Linguistics, 12:3, pp. 175 ? 204, 
Cambridge, MA. 
P. Heisterkamp and S. McGlashan. 1996. Units of 
Dialogue Management: An Example. 
Proceedings of ICSLP96, pp. 200?203, 
Philadelphia. 
I. O?Neill and M. McTear. 2000. Object-Oriented 
Modelling of Spoken Language Dialogue 
Systems.  Natural Language Engineering 6 (3?
4), pp. 341?362, Cambridge University Press. 
I. O?Neill and M. McTear.  2002.  A Pragmatic 
Confirmation Mechanism for an Object-Based 
Spoken Dialogue Manager. Proceedings of 
ICSLP-2002, Vol. 3, pp. 2045?2048. Denver, 
CO. 
I. O?Neill, P. Hanna, X. Liu and M. McTear. 2003.  
The Queen?s Communicator: an Object-Oriented 
Dialogue Manager.  Proceedings of Eurospeech 
2003, pp. 593?596, Geneva. 
C. Rich, C. Sidner and N. Lesh. 2001. 
COLLAGEN: Applying Collaborative Discourse 
Theory to Human-Computer Interaction. 
Artificial Intelligence Magazine, Vol 22, Issue 4, 
pp. 15-25, Menlo Park, CA. 
A. Rudnicky and W. Xu. 1999. An agenda-based 
dialog management architecture for spoken 
language systems. Proceedings of IEEE 
Automatic Speech Recognition and  
Understanding Workshop, p. I?337. 
M. Turunen and J. Hakulinen. 2001. Agent-Based 
Adaptive Interaction and Dialogue Management 
Architecture for Speech Applications. Text 
Speech and Dialogue?Proceedings of the Fourth 
International Conference TSD, pp. 357?364.  
W. Ward. 1994. Extracting information in 
spontaneous speech. Proceedings of ICSLP 94, 
pp. 83?86, Yokohama. 
Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 309?315,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Reduced n-gram models for English and Chinese corpora 
 
 
Le Q Ha, P Hanna, D W Stewart and F J Smith 
School of Electronics, Electrical Engineering and Computer Science, 
Queen?s University Belfast 
Belfast BT7 1NN, Northern Ireland, United Kingdom 
lequanha@lequanha.com 
 
  
 
Abstract 
Statistical language models should       
improve as the size of the n-grams         
increases from 3 to 5 or higher. However, 
the number of parameters and                 
calculations, and the storage requirement 
increase very rapidly if we attempt to 
store all possible combinations of           
n-grams. To avoid these problems, the 
reduced n-grams? approach previously 
developed by O?Boyle (1993) can be     
applied. A reduced n-gram language 
model can store an entire corpus?s 
phrase-history length within feasible 
storage limits. Another theoretical         
advantage of reduced n-grams is that they 
are closer to being semantically complete 
than traditional models, which include all 
n-grams. In our experiments, the reduced 
n-gram Zipf curves are first presented, 
and compared with previously obtained 
conventional n-grams for both English 
and Chinese. The reduced n-gram model 
is then applied to large English and       
Chinese corpora. For English, we can       
reduce the model sizes, compared to       
7-gram traditional model sizes, with       
factors of 14.6 for a 40-million-word 
corpus and 11.0 for a 500-million-word 
corpus while obtaining 5.8% and 4.2% 
improvements in perplexities. For              
Chinese, we gain a 16.9% perplexity       
reductions and we reduce the model size 
by a factor larger than 11.2. This paper is 
a step towards the modeling of English 
and Chinese using semantically complete 
phrases in an n-gram model. 
1 Introduction to the Reduced N-Gram 
Approach 
Shortly after this laboratory first published a 
variable n-gram algorithm (Smith and O?Boyle, 
1992), O?Boyle (1993) proposed a statistical 
method to improve language models based on the 
removal of overlapping phrases. 
A distortion in the use of phrase frequencies 
had been observed in the small railway timetable 
Vodis Corpus when the bigram ?RAIL            
ENQUIRIES? and its super-phrase ?BRITISH 
RAIL ENQUIRIES? were examined. Both occur 
73 times, which is a large number for such a 
small corpus. ?ENQUIRIES? follows ?RAIL? 
with a very high probability when it is preceded 
by ?BRITISH.? However, when ?RAIL? is      
preceded by words other than ?BRITISH,?        
?ENQUIRIES? does not occur, but words like 
?TICKET? or ?JOURNEY? may. Thus, the     
bigram ?RAIL ENQUIRIES? gives a misleading 
probability that ?RAIL? is followed by          
?ENQUIRIES? irrespective of what precedes it. 
At the time of their research, O?Boyle reduced 
the frequencies of ?RAIL ENQUIRIES? by        
subtracting the frequency of the larger trigram, 
which gave a probability of zero for                
?ENQUIRIES? following ?RAIL? if it was not 
preceded by ?BRITISH.? The phrase with a new 
reduced frequency is called a reduced phrase. 
Therefore, a phrase can occur in a corpus as a 
reduced n-gram in some places and as part of a 
larger reduced n-gram in other places. In a         
reduced model, the occurrence of an n-gram is 
not counted when it is a part of a larger reduced 
n-gram. One algorithm to detect/identify/extract 
reduced n-grams from a corpus is the so-called 
reduced n-gram algorithm. In 1992, O?Boyle was 
able to use it to analyse the Brown corpus of 
American English (Francis and Kucera, 1964) (of 
one million word tokens, whose longest phrase-
309
length is 30), which was a considerable               
improvement at the time. The results were used 
in an n-gram language model by O?Boyle, but 
with poor results, due to lack of statistics from 
such a small corpus. We have developed and       
present here a modification of his method, and 
we discuss its usefulness for reducing n-gram 
perplexity. 
2 Similar Approaches and Capability 
Recent progress in variable n-gram language 
modeling has provided an efficient                   
representation of n-gram models and made the 
training of higher order n-grams possible.    
Compared to variable n-grams, class-based     
language models are more often used to reduce 
the size of a language model, but this typically 
leads to recognition performance degradation. 
Classes can alternatively be used to smooth a 
language model or provide back-off estimates, 
which have led to small performance gains. For 
the LOB corpus, the varigram model obtained 
11.3% higher perplexity in comparison with the 
word-trigram model (Niesler and Woodland, 
1996.) 
Kneser (1996) built up variable-context length 
language models based on the North American 
Business News (NAB-240 million words) and 
the German Verbmobil (300,000 words with a 
vocabulary of 5,000 types.) His results show that 
the variable-length model outperforms            
conventional models of the same size, and if a 
moderate loss in performance is acceptable, that 
the size of a language model can be reduced 
drastically by using his pruning algorithm.      
Kneser?s results improve with longer contexts 
and a same number of parameters. For example, 
reducing the size of the standard NAB trigram 
model by a factor of 3 results in a loss of only 
7% in perplexity and 3% in the word error rate. 
The improvement obtained by Kneser?s method 
depended on the length of the fixed context and 
on the amount of available training data. In the 
case of the NAB corpus, the improvement was 
10% in perplexity. 
Siu and Ostendorf (2000) developed Kneser?s 
basic ideas further and applied the variable        
4-gram, thus improving the perplexity and word 
error rate results compared to a fixed trigram 
model. They obtained word error reductions of 
0.1 and 0.5% (absolute) in development and    
evaluation test sets, respectively. However, the 
number of parameters was reduced by 60%. By 
using the variable 4-gram, they were able to 
model a longer history while reducing the size of 
the model by more than 50%, compared to a 
regular trigram model, and at the same time      
improve both the test-set perplexity and           
recognition performance. They also reduced the 
size of the model by an additional 8%. 
Other related work are those of Seymore and 
Rosenfeld (1996); Hu, Turin and Brown (1997); 
Blasig (1999); and Goodman and Gao (2000.) 
In order to obtain an overview of variable        
n-grams, Table 1 combines all of their results. 
COMBINATION OF LANGUAGE MODEL TYPES 
Basic 
n-gram 
Variable 
n-grams 
Category Skipping 
distance 
Classes #params Perplexity Size Source 
Trigram?     987k 474 
  Bigram?   - 603.2 
  Trigram?   - 544.1 
 ? ?   - 534.1 
1M LOB 
Trigram?     743k 81.5 
 Trigram?    379k 78.1 
 Trigram?  ?  363k 78.0 
 Trigram?  ? ? 338k 77.7 
 4-gram?    580k 108 
 4-gram?  ?  577k 108 
 4-gram?  ? ? 536k 107 
 5-gram?    383k 77.5 
 5-gram?  ?  381k 77.4 
 5-gram?  ? ? 359k 77.2 
2M Switch
board 
Corpus 
Table 1. Comparison of combinations of variable n-grams and other Language Models 
310
3 Reduced N-Gram Algorithm 
The main goal of this algorithm (Ha, 2005) is to 
produce three main files from the training text: 
? The file that contains all the complete   
n-grams appearing at least m times is 
called the PHR file (m ? 2.) 
? The file that contains all the n-grams   
appearing as sub-phrases, following the 
removal of the first word from any other 
complete n-gram in the PHR file, is called 
the SUB file. 
? The file that contains any overlapping   
n-grams that occur at least m times in the 
SUB file is called the LOS file. 
The final list of reduced phrases is called the FIN 
file, where 
SUBLOSPHRFIN ?+=:
 
(1) 
Before O?Boyle?s work, a student (Craig) in an 
unpublished project used a loop algorithm that 
was equivalent to FIN:=PHR?SUB. This yields 
negative frequencies for some resulting n-grams 
with overlapping, hence the need for the LOS 
file. 
There are 2 additional files 
? To create the PHR file, a SOR file is 
needed that contains all the complete       
n-grams regardless of m (the SOR file is 
the PHR file in the special case where      
m = 1.) To create the PHR file, words are 
removed from the right-hand side of each 
SOR phrase in the SOR file until the      
resultant phrase appears at least m times (if 
the phrase already occurs more than m 
times, no words will be removed.) 
? To create the LOS file, O?Boyle applied 
a POS file: for any SUB phrase, if one 
word can be added back on the right-hand 
side (previously removed when the PHR 
file was created from the SOR file), then 
one POS phrase will exist as the added 
phrase. Thus, if any POS phrase appears at 
least m times, its original SUB phrase will 
be an overlapping n-gram in the LOS file. 
The application scope of O?Boyle?s reduced       
n-gram algorithm is limited to small corpora, 
such as the Brown corpus (American English) of 
1 million words (1992), in which the longest 
phrase has 30 words. Now their algorithm,        
re-checked by us, still works for medium size 
and large corpora. In order to work well for very 
large corpora, it has been implemented by file 
distribution and sort processes. 
Ha, Seymour, Hanna and Smith (2005) have 
investigated a reduced n-gram model for the 
Chinese TREC corpus of the Linguistic Data 
Consortium (LDC) (http://www.ldc.upenn.edu/), 
catalog no. LDC2000T52.  
4 Reduced N-Grams and Zipf?s Law 
By re-applying O?Boyle and Smith?s algorithm, 
we obtained reduced n-grams from two English  
large corpora and a Chinese large corpus. 
The two English corpora used in our            
experiments are the full text of articles appearing 
in the Wall Street Journal (WSJ) (Paul and 
Baker, 1992) for 1987, 1988, 1989, with sizes 
approximately 19 million, 16 million and 6    
million tokens respectively; and the North 
American News Text (NANT) corpus from the 
LDC, sizing 500 million tokens, including Los 
Angeles Times & Washington Post for May 
1994-August 1997, New York Times News    
Syndicate for July 1994-December 1996, Reuters 
News Service (General & Financial) for April 
1994-December 1996 and Wall Street Journal for 
July 1994-December 1996. Therefore, the WSJ 
parts from the two English corpora are not    
overlapping together. 
The Mandarin News corpus from the LDC, 
catalog no. LDC95T13 was obtained from the 
People?s Daily Newspaper from 1991 to 1996 
(125 million syllables); from the Xinhua News 
Agency from 1994 to 1996 (25 million             
syllables); and from transcripts of China Radio 
International broadcast from 1994 to 1996 (100 
million syllables), altogether over 250 million 
syllables. The number of syllable types (i.e.    
unigrams) in the Mandarin News corpus is 6,800. 
Ha, Sicilia-Garcia, Ming and Smith (2003)      
produced a compound word version of the     
Mandarin News corpus with 50,000 types; this 
version was employed in our study for reduced 
n-grams. 
We next present the Zipf curves (Zipf, 1949) 
for the English and Chinese reduced n-grams. 
4.1 Wall Street Journal 
The WSJ reduced n-grams can be created by the 
original O?Boyle-Smith algorithm implemented 
on a Pentium II 586 of 512MByte RAM for over 
40 hours, the disk storage requirement being  
only 5GBytes. 
311
The conventional 10-highest frequency WSJ 
words have been published by Ha et al (2002) 
and the most common WSJ reduced unigrams, 
bigrams and trigrams are shown in Table 2. It 
illustrates that the most common reduced word is 
not THE; even OF is not in the top ten. These 
words are now mainly part of longer n-grams 
with large n. 
The Zipf curves are plotted for reduced      
unigrams and n-grams in Figure 1 showing all 
the curves have slopes within [-0.6, -0.5]. The 
WSJ reduced bigram, trigram, 4-gram and          
5-gram curves become almost parallel and 
straight, with a small observed noise between the 
reduced 4-gram and 5-gram curves when they cut 
each other at the beginning. Note that               
information theory tells us that an ideal              
information channel would be made of symbols 
with the same probability. So having a slope of        
?0.5 is closer than ?1 to this ideal. 
Unigrams Bigrams Trigrams Rank 
Freq Token Freq Token Freq Token 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
4,273 
2,469 
2,422 
2,144 
1,918 
1,660 
1,249 
1,101 
1,007 
 997 
Mr. 
but 
and 
the 
says 
or 
said 
however 
while 
meanwhile 
2,268 
2,052 
1,945 
1,503 
1,332 
 950 
 856 
 855 
 832 
 754 
he said 
he says 
but the 
but Mr. 
and the 
says Mr. 
in addition 
and Mr. 
last year 
for example 
1,231 
709 
664 
538 
524 
523 
488 
484 
469 
466 
terms weren?t disclosed 
the company said 
as previously reported 
he said the 
a spokesman for 
the spokesman said 
as a result 
earlier this year 
in addition to 
according to Mr. 
Table 2. Most common WSJ reduced n-grams 
log rank
lo
g 
fr
eq
ue
nc
y
1-gram
2-gram
3-gram
4-gram
5-gram
0
1
2
3
4
 2  510  4 3 6  7
slope -1
 
Figure 1. The WSJ reduced n-gram Zipf curves 
4.2 North American News Text corpus 
The NANT reduced n-grams are created by the 
improved algorithm after over 300 hours           
processing, needing a storage requirement of 
100GBytes on a Pentium II 586 of 512MByte 
RAM. 
Their Zipf curves are plotted for reduced       
unigrams and n-grams in Figure 2 showing all 
the curves are just sloped around [-0.54, -0.5]. 
The reduced unigrams of NANT still show the    
2-slope behavior when it starts with slope ?0.54 
and then drop with slope nearly ?2 at the end of 
the curve. We have found that the traditional       
n-grams also show this behaviour, with an initial 
slope of ?1 changing to ?2 for large ranks (Ha 
and Smith, 2004.) 
log rank
lo
g 
fr
eq
ue
nc
y
1-gram
2-gram
3-gram
4-gram
5-gram
slope -1
 2 510 4 3 6 7 8
0
1
2
3
4
5
6
 
Figure 2. The NANT reduced n-gram Zipf curves 
4.3 Mandarin News compound words 
The Zipf curves are plotted for the smaller       
Chinese TREC reduced unigrams and n-grams 
were shown by Ha et al (2005.) 
312
log rank
lo
g 
fr
eq
ue
nc
y
1-gram
2-gram
3-gram
4-gram
5-gram
slope -1
 2  510  43 6 7
0
1
2
3
4
5
6
 
Figure 3. Mandarin reduced n-gram Zipf curves 
The Mandarin News reduced word n-grams were 
created in 120 hours, using 20GB of disk space.  
The Zipf curves are plotted in Figure 3 showing 
that the unigram curve now has a larger slope 
than ?1, it is around ?1.2. All the n-gram curves 
are now straighter and more parallel than the    
traditional n-gram curves, have slopes within      
[-0.67, -0.5]. 
Usually, Zipf?s rank-frequency law with a 
slope ?1 is confirmed by empirical data, but the 
reduced n-grams for English and Chinese shown 
in Figure 1, Figure 2 and Figure 3 do not confirm 
it. In fact, various more sophisticated models for 
frequency distributions have been proposed by 
Baayen (2001) and Evert (2004.) 
5 Perplexity for Reduced N-Grams 
The reduced n-gram approach was used to build 
a statistical language model based on the 
weighted average model of O?Boyle, Owens and 
Smith (1994.) We rewrite this model in formulae 
(2) and (3) 
( ) ( )( ) 11 2log +?? ?= jiijij wfwwgt
 
(2) 
( ) ( ) ( ) ( ) ( )( )?
?
?
=
?
?
=
?
??
?
+?
?+?
= 1
0
1
1
1
1
1 N
l
i
li
N
l
i
lii
i
liii
i
NiiWA
wwgt
wwPwwgtwPwwgt
wwP  
(3) 
This averages the probabilities of a word wi      
following the previous one word, two words, 
three words, etc. (i.e. making the last word of an 
n-gram.) The averaging uses weights that          
increase slowly with their frequency and rapidly 
with the length of n-gram. This weighted average 
model is a variable length model that gives        
results comparable to the Katz back-off method 
(1987), but is quicker to use. 
The probabilities of all of the sentences mw1 in 
a test text are then calculated by the weighted 
average model 
( ) ( ) ( ) ( )111211 ... ?= mmWAWAWAm wwPwwPwPwP
 
(4) 
and an average perplexity of each sentence is 
evaluated using Equation (5) 
( ) ( )( )?
?
??
?
??= ?
=
?
L
i
iiWA
m wwwwPLn
L
wPP
1
1211 ...
1exp
 
(5) 
Ha et al (2005) already investigated and         
analysed the main difficulties arising from       
perplexity calculations for our reduced model: a 
statistical model problem, an unseen word    
problem and an unknown word problem. Their 
solutions are applied in this paper also. Similar 
problems have been found by other authors, e.g. 
Martin, Liermann and Ney (1997); Kneser and 
Ney (1995.) 
The perplexity calculations for both the            
English and Chinese reduced n-grams includes 
statistics on phrase lengths starting with          
unigrams, bigrams, trigrams?and on up to the 
longest phrase which occur in the reduced model. 
The perplexities of the WSJ reduced model are 
shown in Table 3, North American News Text 
corpus in Table 4 and Mandarin News words in 
Table 5. 
The nature of the reduced model makes the       
reporting of results for limited sizes of n-grams 
to be inappropriate, although these are valid for a 
traditional n-gram model. Therefore we show 
results for several n-gram sizes for the traditional 
model, but only one perplexity for the reduced 
model. 
313
Tokens 0 Unknowns 
Types 0 
 Unigrams 762.69 
 Bigrams 144.33 
 Trigrams 75.36 
Traditional Model 4-grams 60.73 
 5-grams 56.85 
 6-grams 55.66 
 7-grams 55.29 
Reduced Model 70.98 
%Improvement of Reduced 
Model on baseline Trigrams 
5.81% 
Model size reduction 14.56 
Table 3. Reduced perplexities for English WSJ 
Tokens 24 Unknowns 
Types 23 
 Unigrams 1,442.99 
 Bigrams 399.61 
 Trigrams 240.52 
Traditional Model 4-grams 202.59 
 5-grams 194.06 
 6-grams 191.91 
 7-grams 191.23 
Reduced Model 230.46 
%Improvement of Reduced 
Model on baseline Trigrams 
4.18% 
Model size reduction 11.01 
Table 4. Reduced perplexities for English NANT 
Tokens 84 Unknowns 
Types 26 
 Unigrams 1,620.56 
 Bigrams 377.43 
 Trigrams 179.07 
Traditional Model 4-grams 135.69 
 5-grams 121.53 
 6-grams 114.96 
 7-grams 111.69 
Reduced Model 148.71 
%Improvement of Reduced 
Model on baseline Trigrams 
16.95% 
Model size reduction 11.28 
Table 5. Reduced perplexities for Mandarin 
News words 
In all three cases the reduced model produces a 
modest improvement over the traditional                
3-gram model, but is not as good as the                 
traditional 4-gram or higher models. However in 
all three cases the result is obtained with a      
significant reduction in model size, from a factor 
of 11 to almost 15 compared to the traditional        
7-gram model size.  
We did expect a greater improvement in          
perplexity than we obtained and we believe that a 
further look at the methods used to solve the          
difficult problems listed by Ha et al (2005) 
(mentioned above) and others mentioned by Ha 
(2005) might lead to an improvement. Missing 
word tests are also needed. 
6 Conclusions 
The conventional n-gram language model is   
limited in terms of its ability to represent        
extended phrase histories because of the            
exponential growth in the number of parameters. 
To overcome this limitation, we have                 
re-investigated the approach of O?Boyle (1993) 
and created reduced n-gram models. Our aim 
was to try to create an n-gram model that used 
semantically more complete n-grams than      
traditional n-grams in the expectation that this 
might lead to an improvement in language      
modeling. The improvement in perplexity is 
modest, but there is a large decrease in model 
size. So this represents an encouraging step     
forward, although still very far from the final 
step in language modelling. 
Acknowledgements 
The authors would like to thank Dr Ji Ming for 
his support and the reviewers for their valuable 
comments. 
References 
Douglas B. Paul and Janet B. Baker. 1992. The      
Design for the Wall Street Journal based CSR   
Corpus. In Proc. of the DARPA SLS Workshop, 
pages 357-361. 
Francis J. Smith and Peter O?Boyle. 1992. The         
N-Gram Language Model. The Cognitive Science 
of Natural Language Processing Workshop, pages 
51-58. Dublin City University.  
George K. Zipf. 1949. Human Behaviour and the 
Principle of Least Effort. Reading, MA: Addison- 
Wesley Publishing Co. 
Harald R. Baayen. 2001. Word Frequency                
Distributions. Kluwer Academic Publishers. 
Jianying Hu, William Turin and Michael K. Brown. 
1997. Language Modeling using Stochastic        
Automata with Variable Length Contexts.           
Computer Speech and Language, volume 11, pages 
1-16. 
314
Joshua Goodman and Jianfeng Gao. 2000. Language 
Model Size Reduction By Pruning And Clustering. 
ICSLP?00. Beijing, China. 
Kristie Seymore and Ronald Rosenfeld. 1996.        
Scalable Backoff Language Models. ICSLP?96, 
pages 232-235. 
Le Q. Ha and Francis. J. Smith. 2004. Zipf and Type-
Token rules for the English and Irish languages. 
MIDL workshop. Paris. 
Le Q. Ha, Elvira I. Sicilia-Garcia, Ji Ming and Francis 
J. Smith. 2002. Extension of Zipf?s Law to Words 
and Phrases. COLING?02, volume 1, pages 315-
320. 
Le Q. Ha, Elvira I. Sicilia-Garcia, Ji Ming and Francis 
J. Smith. 2003. Extension of Zipf?s Law to Word 
and Character N-Grams for English and Chinese. 
CLCLP, 8(1):77-102. 
Le Q. Ha, Rowan Seymour, Philip Hanna and Francis 
J. Smith. 2005. Reduced N-Grams for Chinese 
Evaluation. CLCLP, 10(1):19-34. 
Manhung Siu and Mari Ostendorf. 2000. Integrating a 
Context-Dependent Phrase Grammar in the         
Variable N-Gram framework. ICASSP?00, volume 
3, pages 1643-1646. 
Manhung Siu and Mari Ostendorf. 2000. Variable     
N-Grams and Extensions for Conversational 
Speech Language Modelling. IEEE Transactions 
on Speech and Audio Processing, 8(1):63-75. 
Nelson Francis and Henry Kucera. 1964. Manual of 
Information to Accompany A Standard Corpus of 
Present-Day Edited American English, for use with 
Digital Computers. Department of Linguistics, 
Brown University, Providence, Rhode Island. 
Peter  L.  O?Boyle.    1993.    A  study  of  an  N-Gram 
Language Model for Speech Recognition. PhD     
thesis. Queen?s University Belfast. 
Peter O?Boyle, John McMahon and Francis J. Smith. 
1995. Combining a Multi-Level Class Hierarchy 
with Weighted-Average Function-Based      
Smoothing. IEEE Automatic Speech Recognition 
Workshop. Snowbird, Utah. 
Peter O?Boyle, Marie Owens and Francis J. Smith. 
1994. A weighted average N-Gram model of     
natural language. Computer Speech and Language, 
volume 8, pages 337-349. 
Ramon Ferrer I. Cancho and Ricard V. Sol?. 2002. 
Two Regimes in the Frequency of Words and the 
Origin of Complex Lexicons. Journal of             
Quantitative Linguistics, 8(3):165-173. 
Reinhard Blasig. 1999. Combination of Words and 
Word Categories in Varigram Histories. 
ICASSP?99, volume 1, pages 529-532. 
Reinhard Kneser and Hermann Ney. 1995. Improved 
Backing-off for M-Gram Language Modeling. 
ICASSP?95, volume 1, pages 181-184. Detroit.  
Reinhard Kneser. 1996. Statistical Language            
Modeling Using a Variable Context Length. 
ICSLP?96, volume 1, pages 494-497. 
Slava M. Katz. 1987. Estimation of Probabilities from 
Sparse Data for the Language Model Component 
of a Speech Recognizer. In IEEE Transactions on 
Acoustics, Speech and Signal Processing, volume 
ASSP-35, pages 400-401. 
Stefan Evert. 2004. A Simple LNRE Model for      
Random Character Sequences. In Proc. of the 
7?mes Journ?es Internationales d'Analyse           
Statistique des Donn?es Textuelles, pages 411-422. 
Sven C. Martin, J?rg Liermann and Hermann Ney. 
1997. Adaptive Topic-Dependent Language      
Modelling Using Word-Based Varigrams.           
EuroSpeech?97, volume 3, pages 1447-1450.      
Rhodes. 
Thomas R. Niesler and Phil C. Woodland. 1996. A 
Variable-Length Category-Based N-Gram        
Language Model. ICASSP?96, volume 1, pages 
164-167. 
Thomas R. Niesler. 1997. Category-based statistical 
language models. St. John?s College, University of 
Cambridge. 
315
