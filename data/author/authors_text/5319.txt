Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational
Natural Language Learning, pp. 360?368, Prague, June 2007. c?2007 Association for Computational Linguistics
Syntactic Re-Alignment Models for Machine Translation
Jonathan May
Information Sciences Institute
University of Southern California
Marina del Rey, CA 90292
jonmay@isi.edu
Kevin Knight
Information Sciences Institute
University of Southern California
Marina del Rey, CA 90292
knight@isi.edu
Abstract
We present a method for improving word
alignment for statistical syntax-based ma-
chine translation that employs a syntacti-
cally informed alignment model closer to
the translation model than commonly-used
word alignment models. This leads to ex-
traction of more useful linguistic patterns
and improved BLEU scores on translation
experiments in Chinese and Arabic.
1 Methods of statistical MT
Roughly speaking, there are two paths commonly
taken in statistical machine translation (Figure 1).
The idealistic path uses an unsupervised learning
algorithm such as EM (Demptser et al, 1977)
to learn parameters for some proposed translation
model from a bitext training corpus, and then di-
rectly translates using the weighted model. Some
examples of the idealistic approach are the direct
IBM word model (Berger et al, 1994; Germann
et al, 2001), the phrase-based approach of Marcu
and Wong (2002), and the syntax approaches of Wu
(1996) and Yamada and Knight (2001). Idealistic
approaches are conceptually simple and thus easy to
relate to observed phenomena. However, as more
parameters are added to the model the idealistic ap-
proach has not scaled well, for it is increasingly dif-
ficult to incorporate large amounts of training data
efficiently over an increasingly large search space.
Additionally, the EM procedure has a tendency to
overfit its training data when the input units have
varying explanatory powers, such as variable-size
phrases or variable-height trees.
The realistic path also learns a model of transla-
tion, but uses that model only to obtain Viterbi word-
for-word alignments for the training corpus. The
bitext and corresponding alignments are then used
as input to a pattern extraction algorithm, which
yields a set of patterns or rules for a second trans-
lation model (which often has a wider parameter
space than that used to obtain the word-for-word
alignments). Weights for the second model are then
set, typically by counting and smoothing, and this
weighted model is used for translation. Realistic ap-
proaches scale to large data sets and have yielded
better BLEU performance than their idealistic coun-
terparts, but there is a disconnect between the first
model (hereafter, the alignment model) and the sec-
ond (the translation model). Examples of realistic
systems are the phrase-based ATS system of Och
and Ney (2004), the phrasal-syntax hybrid system
Hiero (Chiang, 2005), and the GHKM syntax sys-
tem (Galley et al, 2004; Galley et al, 2006). For
an alignment model, most of these use the Aachen
HMM approach (Vogel et al, 1996), the implemen-
tation of IBM Model 4 in GIZA++ (Och and Ney,
2000) or, more recently, the semi-supervised EMD
algorithm (Fraser and Marcu, 2006).
The two-model approach of the realistic path has
undeniable empirical advantages and scales to large
data sets, but new research tends to focus on devel-
opment of higher order translation models that are
informed only by low-order alignments. We would
like to add the analytic power gained from mod-
ern translation models to the underlying alignment
model without sacrificing the efficiency and empiri-
cal gains of the two-model approach. By adding the
360
u n s u p e r v i s e d
l
e a r n i n g
t
a r g e
t
s e n
t
e n c e s
s o u r c e
s e n
t
e n c e s
u n w e i g h
t
e d
m o d e
l
w e i g h
t
e d
m o d e
l
p a
t t
e r n s
(
u n w e i g h
t
e d
m o d e
l )
c o u n
t
i n g
a n d
s m o o
t
h i n g
w e i g h
t
e d
m o d e
l
d e c o d e r
s o u r c e
s e n
t
e n c e s
t
a r g e
t
s e n
t
e n c e s
p a
t t
e r n
e x
t
r a c
t
i o n
t
a r g e
t
s e n
t
e n c e s
s o u r c e
s e n
t
e n c e s
V
i
t
e r b i
a
l
i g n m e n
t
s
I d e a l i s t i c
S y
s t e m
R e a l i s t i c
S y
s t e m
d e c o d e r
s o u r c e
s e n
t
e n c e s
t
a r g e
t
s e n
t
e n c e s
Figure 1: General approach to idealistic and realistic statistical MT systems
syntactic information used in the translation model
to our alignment model we may improve alignment
quality such that rule quality and, in turn, system
quality are improved. In the remainder of this work
we show how a touch of idealism can improve an
existing realistic syntax-based translation system.
2 Multi-level syntactic rules for syntax MT
Galley et al (2004) and Galley et al (2006) de-
scribe a syntactic translation model that relates En-
glish trees to foreign strings. The model describes
joint production of a (tree, string) pair via a non-
deterministic selection of weighted rules. Each rule
has an English tree fragment with variables and a
corresponding foreign string fragment with the same
variables. A series of rules forms an explanation (or
derivation) of the complete pair.
As an example, consider the parsed English and
corresponding Chinese at the top of Figure 2. The
three columns underneath the example are different
rule sequences that can explain this pair; there are
many other possibilities. Note how rules specify ro-
tation (e.g. R10, R5), direct translation (R12, R8),
insertion and deletion (R11, R1), and tree traversal
(R7, R15). Note too that the rules explain variable-
size fragments (e.g. R6 vs. R14) and thus the possi-
ble derivation trees of rules that explain a sentence
pair have varying sizes. The smallest such deriva-
tion tree has a single large rule (which does not ap-
pear in Figure 2; we leave the description of such
a rule as an exercise for the reader). A string-to-
tree decoder constructs a derivation forest of deriva-
tion trees where the right sides of the rules in a tree,
taken together, explain a candidate source sentence.
It then outputs the English tree corresponding to the
highest-scoring derivation in the forest.
3 Introducing syntax into the alignment
model
We now lay the ground for a syntactically motivated
alignment model. We begin by reviewing an align-
ment model commonly seen in realistic MT systems
and compare it to a syntactically-aware alignment
model.
3.1 The traditional IBM alignment model
IBM Model 4 (Brown et al, 1993) learns a set of 4
probability tables to compute p(f |e) given a foreign
sentence f and its target translation e via the follow-
ing (greatly simplified) generative story:
361
NP-C
NPB
NPB
NNP
taiwan
POS
?s
NN
surplus
PP
IN
in
NP-C
NPB
NN
trade
PP
IN
between
NP-C
NPB
DT
the
CD
two
NNS
shores
? l ? ? ? ? 4 ? ~ ?
TAIWAN IN TWO-SHORES TRADE MIDDLE SURPLUS
R1: NP-C
NPB
x0:NPB x1:NN
x2:PP
? x0 x2 ? x1 R10: NP-C
NPB
x0:NPB x1:NN
x2:PP
? x0 x2 x1 R10: NP-C
NPB
x0:NPB x1:NN
x2:PP
? x0 x2 x1
R2: NPB
NNP
taiwan
POS
?s
? ? l R11: NPB
x0:NNP POS
?s
? x0 R17: NPB
NNP
taiwan
x0:POS
? x0
R12: NNP
taiwan
? ? l R18: POS
?s
? ? l
R3: PP
x0:IN x1:NP-C
? x0 x1 R13: PP
IN
in
x0:NP-C
? ? x0 ? R19: PP
IN
in
x0:NP-C
? x0
R4: IN
in
? ?
R5: NP-C
x0:NPB x1:PP
? x1 x0 R5: NP-C
x0:NPB x1:PP
? x1 x0 R20: NP-C
x0:NPB PP
x1:IN x2:NP-C
? x2 x0 x1
R6: PP
IN
between
NP-C
NPB
DT
the
CD
two
NNS
shores
? ? ? R14: PP
IN
between
x0:NP-C
? x0 R21: IN
between
? ?
R15: NP-C
x0:NPB
? x0 R15: NP-C
x0:NPB
? x0
R16: NPB
DT
the
CD
two
NNS
shores
? ? ? R22: NPB
x0:DT CD
two
x1:NNS
? x0 x1
R23: NNS
shores
? ? ? R24: DT
the
? ?
R7: NPB
x0:NN
? x0 R7: NPB
x0:NN
? x0 R7: NPB
x0:NN
? x0
R8: NN
trade
? ? 4 R9: NN
surplus
? ~ ? R8: NN
trade
? ? 4 R9: NN
surplus
? ~ ? R8: NN
trade
? ? 4 R9: NN
surplus
? ~ ?
Figure 2: A (English tree, Chinese string) pair and three different sets of multilevel tree-to-string rules that
can explain it; the first set is obtained from bootstrap alignments, the second from this paper?s re-alignment
procedure, and the third is a viable, if poor quality, alternative that is not learned.
362
S-C
NP-C
NPB
NNP
guangxi
POS
?s
VP
VBG
opening
PRT
RP
up
PP
TO
to
NP-C
NPB
DT
the
JJ
outside
NN
world
 ? ? i  8
GUANGXI OUTSIDE-WORLD OPENING-UP
R24: S-C
NP-C
NPB
x0:NNP POS
?s
VP
VBG
opening
PRT
RP
up
PP
TO
to
NP-C
NPB
DT
the
JJ
outside
NN
world
? x0 ? i  8 R25: NNP
guangxi
?  ?
R26: S-C
x0:NP-C x1:VP
? x0 x1 R15: NP-C
x0:NPB
? x0 R11: NPB
x0:NNP POS
?s
? x0 R27: VP
VBG
opening
PRT
RP
up
x0:PP
? x0  8
R28: PP
TO
to
x0:NP-C
? x0 R15: NP-C
x0:NPB
? x0 R29: NPB
DT
the
JJ
outside
NN
world
? ? i R25: NNP
guangxi
?  ?
Figure 3: The impact of a bad alignment on rule extraction. Including the alignment link indicated by the
dotted line in the example leads to the rule set in the second row. The re-alignment procedure described in
Section 3.2 learns to prefer the rule set at bottom, which omits the bad link.
1. A fertility y for each word ei in e is chosen
with probability pfert(y|ei).
2. A null word is inserted next to each
fertility-expanded word with probability
pnull.
3. Each token ei in the fertility-expanded
word and null string is translated into
some foreign word fi in f with probability
ptrans(fi|ei).
4. The position of each foreign word
fi that was translated from ei is
changed by ? (which may be posi-
tive, negative, or zero) with probability
pdistortion(?|A(ei),B(fi)), where A and
B are functions over the source and target
vocabularies, respectively.
Brown et al (1993) describes an EM algorithm
for estimating values for the four tables in the gener-
ative story. However, searching the space of all pos-
sible alignments is intractable for EM, so in practice
the procedure is bootstrapped by models with nar-
rower search space such as IBM Model 1 (Brown et
al., 1993) or Aachen HMM (Vogel et al, 1996).
363
3.2 A syntax re-alignment model
Now let us contrast this commonly used model for
obtaining alignments with a syntactically motivated
alternative. We recall the rules described in Section
2. Our model learns a single probability table to
compute p(etree, f) given a foreign sentence f and
a parsed target translation etree. In the following
generative story we assume a starting variable with
syntactic type v.
1. Choose a rule r to replace v, with proba-
bility prule(r|v).
2. For each variable with syntactic type vi in
the partially completed (tree, string) pair,
continue to choose rules ri with probabil-
ity prule(ri|vi) to replace these variables
until there are no variables remaining.
In Section 5.1 we discuss an EM learning proce-
dure for estimating these rule probabilities.
As in the IBM approach, we must miti-
gate intractability by limiting the parameter space
searched, which is potentially much wider than in
the word-to-word case. We would like to supply to
EM all possible rules that explain the training data,
but this implies a rule relating each possible tree
fragment to each possible string fragment, which is
infeasible. We follow the approach of bootstrapping
from a model with a narrower parameter space as is
done in, e.g. Och and Ney (2000) and Fraser and
Marcu (2006).
To reduce the model space we employ the rule ac-
quisition technique of Galley et al (2004), which
obtains rules given a (tree, string) pair as well as
an initial alignment between them. We are agnos-
tic about the source of this bootstrap alignment and
in Section 5 present results based on several differ-
ent bootstrap alignment qualities. We require an ini-
tial set of alignments, which we obtain from a word-
for-word alignment procedure such as GIZA++ or
EMD. Thus, we are not aligning input data, but
rather re-aligning it with a syntax model.
4 The appeal of a syntax alignment model
Consider the example of Figure 2 again. The left-
most derivation is obtained from the bootstrap align-
ment set. This derivation is reasonable but there are
some poorly motivated rules, from a linguistic stand-
point. The Chinese word ? ? roughly means ?the
SENTENCE PAIRS
DESCRIPTION CHINESE ARABIC
TUNE NIST 2002 short 925 696
TEST NIST 2003 919 663
Table 1: Tuning and testing data sets for the MT
system described in Section 5.2.
two shores? in this context, but the rule R6 learned
from the alignment incorrectly includes ?between?.
However, other sentences in the training corpus have
the correct alignment, which yields rule R16. Mean-
while, rules R13 and R14, learned from yet other
sentences in the training corpus, handle the ? ... ?
structure (which roughly translates to ?in between?),
thus allowing the middle derivation.
EM distributes rule probabilities in such a way as
to maximize the probability of the training corpus.
It thus prefers to use one rule many times instead
of several different rules for the same situation over
several sentences, if possible. R6 is a possible rule
in 46 of the 329,031 sentence pairs in the training
corpus, while R16 is a possible rule in 100 sentence
pairs. Well-formed rules are more usable than ill-
formed rules and the partial alignments behind these
rules, generally also well-formed, become favored
as well. The top row of Figure 3 contains an exam-
ple of an alignment learned by the bootstrap align-
ment model that includes an incorrect link. Rule
R24, which is extracted from this alignment, is a
poor rule. A set of commonly seen rules learned
from other training sentences provide a more likely
explanation of the data, and the consequent align-
ment omits the spurious link.
5 Experiments
In this section, we describe the implementation of
our semi-idealistic model and our means of evaluat-
ing the resulting re-alignments in an MT task.
5.1 The re-alignment setup
We begin with a training corpus of Chinese-English
and Arabic-English bitexts, the English side parsed
by a reimplementation of the standard Collins model
(Bikel, 2004). In order to acquire a syntactic rule set,
we also need a bootstrap alignment of each training
sentence. We use an implementation of the GHKM
364
BOOTSTRAP GIZA CORPUS RE-ALIGNMENT EXPERIMENT
ENGLISH WORDS CHINESE WORDS TYPE RULES TUNE TEST
9,864,294 7,520,779
baseline 19,138,252 39.08 37.77
initial 18,698,549 39.49 38.39
adjusted 26,053,341 39.76 38.69
Table 2: A comparison of Chinese BLEU performance between the GIZA baseline (no re-alignment), re-
alignment as proposed in Section 3.2, and re-alignment as modified in Section 5.4
algorithm (Galley et al, 2004) to obtain a rule set for
each bootstrap alignment.
Now we need an EM algorithm for learn-
ing the parameters of the rule set that maximize
?
corpus
p(tree, string). Such an algorithm is pre-
sented by Graehl and Knight (2004). The algorithm
consists of two components: DERIV, which is a pro-
cedure for constructing a packed forest of derivation
trees of rules that explain a (tree, string) bitext cor-
pus given that corpus and a rule set, and TRAIN,
which is an iterative parameter-setting procedure.
We initially attempted to use the top-down DE-
RIV algorithm of Graehl and Knight (2004), but as
the constraints of the derivation forests are largely
lexical, too much time was spent on exploring dead-
ends. Instead we build derivation forests using the
following sequence of operations:
1. Binarize rules using the synchronous bina-
rization algorithm for tree-to-string trans-
ducers described in Zhang et al (2006).
2. Construct a parse chart with a CKY parser
simultaneously constrained on the foreign
string and English tree, similar to the
bilingual parsing of Wu (1997) 1.
3. Recover all reachable edges by traversing
the chart, starting from the topmost entry.
Since the chart is constructed bottom-up, leaf lex-
ical constraints are encountered immediately, result-
ing in a narrower search space and faster running
time than the top-down DERIV algorithm for this
application. Derivation forest construction takes
around 400 hours of cumulative machine time (4-
processor machines) for Chinese. The actual run-
ning of EM iterations (which directly implements
the TRAIN algorithm of Graehl and Knight (2004))
1In the cases where a rule is not synchronous-binarizable
standard left-right binarization is performed and proper permu-
tation of the disjoint English tree spans must be verified when
building the part of the chart that uses this rule.
takes about 10 minutes, after which the Viterbi
derivation trees are directly recoverable. The Viterbi
derivation tree tells us which English words produce
which Chinese words, so we can extract a word-
to-word alignment from it. We summarize the ap-
proach described in this paper as:
1. Obtain bootstrap alignments for a training
corpus using GIZA++.
2. Extract rules from the corpus and align-
ments using GHKM, noting the partial
alignment that is used to extract each rule.
3. Construct derivation forests for each (tree,
string) pair, ignoring the alignments, and
run EM to obtain Viterbi derivation trees,
then use the annotated partial alignments
to obtain Viterbi alignments.
4. Use the new alignments as input to the MT
system described below.
5.2 The MT system setup
A truly idealistic MT system would directly apply
the rule weight parameters learned via EM to a ma-
chine translation task. As mentioned in Section 1,
we maintain the two-model, or realistic approach.
Below we briefly describe the translation model, fo-
cusing on comparison with the previously described
alignment model. Galley et al (2006) provides a
more complete description of the translation model
and DeNeefe et al (2007) provides a more complete
description of the end-to-end translation pipeline.
Although in principle the re-alignment model and
translation model learn parameter weights over the
same rule space, in practice we limit the rules used
for re-alignment to the set of smallest rules that ex-
plain the training corpus and are consistent with the
bootstrap alignments. This is a compromise made
to reduce the search space for EM. The translation
model learns multiple derivations of rules consistent
with the re-alignments for each sentence, and learns
365
(a) Chinese re-alignment corpus has 9,864,294 English and 7,520,779 Chinese words
BOOTSTRAP GIZA CORPUS RE-ALIGNMENT EXPERIMENT
ENGLISH WORDS CHINESE WORDS TYPE RULES TUNE TEST
9,864,294 7,520,779 baseline 19,138,252 39.08 37.77
re-alignment 26,053,341 39.76 38.69
221,835,870 203,181,379 baseline 23,386,535 39.51 38.93
re-alignment 33,374,646 40.17 39.96
(b) Arabic re-alignment corpus has 4,067,454 English and 3,147,420 Arabic words
BOOTSTRAP GIZA CORPUS RE-ALIGNMENT EXPERIMENT
ENGLISH WORDS ARABIC WORDS TYPE RULES TUNE TEST
4,067,454 3,147,420 baseline 2,333,839 47.92 47.33
re-alignment 2,474,737 47.87 47.89
168,255,347 147,165,003 baseline 3,245,499 49.72 49.60
re-alignment 3,600,915 49.73 49.99
Table 3: Machine Translation experimental results evaluated with case-insensitive BLEU4.
weights for these by counting and smoothing. A
dozen other features are also added to the rules. We
obtain weights for the combinations of the features
by performing minimum error rate training (Och,
2003) on held-out data. We then use a CKY decoder
to translate unseen test data using the rules and tuned
weights. Table 1 summarizes the data used in tuning
and testing.
5.3 Initial results
An initial re-alignment experiment shows a reason-
able rise in BLEU scores from the baseline (Table
2), but closer inspection of the rules favored by EM
implies we can do even better. EM has a tendency
to favor few large rules over many small rules, even
when the small rules are more useful. Referring to
the rules in Figure 2, note that possible derivations
for (taiwan ?s, ? l)2 are R2, R11-R12, and R17-
R18. Clearly the third derivation is not desirable,
and we do not discuss it further. Between the first
two derivations, R11-R12 is preferred over R2, as
the conditioning for possessive insertion is not re-
lated to the specific Chinese word being inserted.
Of the 1,902 sentences in the training corpus where
this pair is seen, the bootstrap alignments yield the
R2 derivation 1,649 times and the R11-R12 deriva-
tion 0 times. Re-alignment does not change the re-
sult much; the new alignments yield the R2 deriva-
tion 1,613 times and again never choose R11-R12.
The rules in the second derivation themselves are
2The Chinese gloss is simply ?taiwan?.
not rarely seen ? R11 is in 13,311 forests other than
those where R2 is seen, and R12 is in 2,500 addi-
tional forests. EM gives R11 a probability of e?7.72
? better than 98.7% of rules, and R12 a probability
of e?2.96. But R2 receives a probability of e?6.32
and is preferred over the R11-R12 derivation, which
has a combined probability of e?10.68.
5.4 Making EM fair
The preference for shorter derivations containing
large rules over longer derivations containing small
rules is due to a general tendency for EM to pre-
fer derivations with few atoms. Marcu and Wong
(2002) note this preference but consider the phe-
nomenon a feature, rather than a bug. Zollmann
and Sima?an (2005) combat the overfitting aspect
for parsing by using a held-out corpus and a straight
maximum likelihood estimate, rather than EM. We
take a modeling approach to the phenomenon.
As the probability of a derivation is determined by
the product of its atom probabilities, longer deriva-
tions with more probabilities to multiply have an in-
herent disadvantage against shorter derivations, all
else being equal. EM is an iterative procedure and
thus such a bias can lead the procedure to converge
with artificially raised probabilities for short deriva-
tions and the large rules that comprise them. The
relatively rare applicability of large rules (and thus
lower observed partial counts) does not overcome
the inherent advantage of large coverage. To com-
bat this, we introduce size terms into our generative
story, ensuring that all competing derivations for the
366
LANGUAGE PAIR TYPE RULES TUNE TEST
CHINESE-ENGLISH baseline 55,781,061 41.51 40.55EMD re-align 69,318,930 41.23 40.55
ARABIC-ENGLISH baseline 8,487,656 51.90 51.69EMD re-align 11,498,150 51.88 52.11
Table 4: Re-alignment performance with semi-supervised EMD bootstrap alignments
same sentence contain the same number of atoms:
1. Choose a rule size s with cost csize(s)s?1.
2. Choose a rule r (of size s) to replace the
start symbol with probability prule(r|s, v).
3. For each variable in the partially com-
pleted (tree, string) pair, continue to
choose sizes followed by rules, recur-
sively to replace these variables until there
are no variables remaining.
This generative story changes the derivation com-
parison from R2 vs R11-R12 to S2-R2 vs R11-R12,
where S2 is the atom that represents the choice of
size 2 (the size of a rule in this context is the number
of non-leaf and non-root nodes in its tree fragment).
Note that the variable number of inclusions implied
by the exponent in the generative story above en-
sures that all derivations have the same size. For ex-
ample, a derivation with one size-3 rule, a derivation
with one size-2 and one size-1 rule, and a deriva-
tion with three size-1 rules would each have three
atoms. With this revised model that allows for fair
comparison of derivations, the R11-R12 derivation
is chosen 1636 times, and S2-R2 is not chosen. R2
does, however, appear in the translation model, as
the expanded rule extraction described in Section 5.2
creates R2 by joining R11 and R12.
The probability of size atoms, like that of rule
atoms, is decided by EM. The revised generative
story tends to encourage smaller sizes by virtue of
the exponent. This does not, however, simply ensure
the largest number of rules per derivation is used in
all cases. Ill-fitting and poorly-motivated rules such
as R22, R23, and R24 in Figure 2 are not preferred
over R16, even though they are smaller. However,
R14 and R16 are preferred over R6, as the former
are useful rules. Although the modified model does
not sum to 1, it leads to an improvement in BLEU
score, as can be seen in the last row of Table 2.
5.5 Results
We performed primary experiments on two different
bootstrap setups in two languages: the initial exper-
iment uses the same data set for the GIZA++ initial
alignment as is used in the re-alignment, while an
experiment on better quality bootstrap alignments
uses a much larger data set. For each bootstrap-
ping in each language we compared the baseline
of using these alignments directly in an MT sys-
tem with the experiment of using the alignments ob-
tained from the re-alignment procedure described in
Section 5.4. For each experiment we report: the
number of rules extracted by the expanded GHKM
algorithm of Galley et al (2006) for the translation
model, converged BLEU scores on the tuning set,
and finally BLEU performance on the held-out test
set. Data set specifics for the GIZA++ bootstrapping
and BLEU results are summarized in Table 3.
5.6 Discussion
The results presented demonstrate we are able to
improve on unsupervised GIZA++ alignments by
about 1 BLEU point for Chinese and around 0.4
BLEU point for Arabic using an additional unsu-
pervised algorithm that requires no human aligned
data. If human-aligned data is available, the EMD
algorithm provides higher baseline alignments than
GIZA++ that have led to better MT performance
(Fraser and Marcu, 2006). As a further experi-
ment we repeated the experimental conditions from
Table 3, this time bootstrapped with the semi-
supervised EMD method, which uses the larger
bootstrap GIZA corpora described in Table 3 and
an additional 64,469/48,650 words of hand-aligned
English-Chinese and 43,782/31,457 words of hand-
aligned English-Arabic. The results of this advanced
experiment are in Table 4. We show a 0.42 gain in
BLEU for Arabic, but no movement for Chinese. We
believe increasing the size of the re-alignment cor-
pora will increase BLEU gains in this experimental
367
condition, but leave those results for future work.
We can see from the results presented that the im-
pact of the syntax-aware re-alignment procedure of
Section 3.2, coupled with the addition of size param-
eters to the generative story from Section 5.4 serves
to remove links from the bootstrap alignments that
cause less useful rules to be extracted, and thus in-
crease the overall quality of the rules, and hence the
system performance. We thus see the benefit to in-
cluding syntax in an alignment model, bringing the
two models of the realistic machine translation path
somewhat closer together.
Acknowledgments
We thank David Chiang, Steve DeNeefe, Alex
Fraser, Victoria Fossum, Jonathan Graehl, Liang
Huang, Daniel Marcu, Michael Pust, Oana Pos-
tolache, Michael Pust, Jason Riesa, Jens Vo?ckler,
and Wei Wang for help and discussion. This re-
search was supported by NSF (grant IIS-0428020)
and DARPA (contract HR0011-06-C-0022).
References
Adam Berger, Peter Brown, Stephen Della Pietra, Vin-
cent Della Pietra, John Gillett, John Lafferty, Robert
Mercer, Harry Printz, and Lubos? Ures?. 1994. The
candide system for machine translation. In Proc. HLT,
pages 157?162, Plainsboro, New Jersey, March.
Daniel Bikel. 2004. Intricacies of Collins? parsing
model. Computational Linguistics, 30(4):479?511.
Peter F. Brown, Vincent J. Della Pietra, Stephen A. Della
Pietra, and Robert L. Mercer. 1993. The mathemat-
ics of statistical machine translation: parameter esti-
mation. Computational Linguistics, 19(2):263?311.
David Chiang. 2005. A hierarchical phrase-based model
for statistical machine translation. In Proc. ACL, pages
263?270, Ann Arbor, Michigan, June.
Arthur P. Demptser, Nan M. Laird, and Donald B. Ru-
bin. 1977. Maximum likelihood from incomplete data
via the EM algorithm. Journal of the Royal Statistical
Society, Series B, 39(1):1?38.
Steve DeNeefe, Kevin Knight, Wei Wang, and Daniel
Marcu. 2007. What can syntax-based MT learn from
phrase-based MT? In Proc. EMNLP/CONLL, Prague,
June.
Alexander Fraser and Daniel Marcu. 2006. Semi-
supervised training for statistical word alignment. In
Proc. COLING-ACL, pages 769?776, Sydney, July.
Michel Galley, Mark Hopkins, Kevin Knight, and Daniel
Marcu. 2004. What?s in a translation rule? In Proc.
HLT-NAACL, pages 273?280, Boston, May.
Michel Galley, Jonathan Graehl, Kevin Knight, Daniel
Marcu, Steven DeNeefe, Wei Wang, and Ignacio
Thayer. 2006. Scalable inference and training of
context-rich syntactic models. In Proc. COLING-
ACL, pages 961?968, Sydney, July.
Ulrich Germann, Michael Jahr, Kevin Knight, Daniel
Marcu, and Kenji Yamada. 2001. Fast decoding and
optimal decoding for machine translation. In Proc.
ACL, pages 228?235, Toulouse, France, July.
Jonathan Graehl and Kevin Knight. 2004. Training tree
transducers. In Proc. HLT-NAACL, pages 105?112,
Boston, May.
Daniel Marcu and William Wong. 2002. A phrase-based,
joint probability model for statistical machine transla-
tion. In Proc. EMNLP, pages 133?139, Philadelphia,
July.
Franz Och and Hermann Ney. 2000. Improved statisti-
cal alignment models. In Proc. ACL, pages 440?447,
Hong Kong, October.
Franz Och and Hermann Ney. 2004. The alignment tem-
plate approach to statistical machine translation. Com-
putational Linguistics, 30(4):417?449.
Franz Och. 2003. Minimum error rate training for sta-
tistical machine translation. In Proc. ACL, pages 160?
167, Sapporo, Japan, July.
Stephan Vogel, Hermann Ney, and Christoph Tillmann.
1996. HMM-based word alignment in statistical trans-
lation. In Proc. COLING, pages 836?841, Copen-
hagen, August.
Dekai Wu. 1996. A polynomial-time algorithm for sta-
tistical machine translation. In Proc. ACL, pages 152?
158, Santa Cruz, California, June.
Dekai Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel corpora.
Computational Linguistics, 23(3):377?404.
Kenji Yamada and Kevin Knight. 2001. A syntax-based
statistical translation model. In Proc. ACL, pages 523?
530, Toulouse, France, July.
Hao Zhang, Liang Huang, Daniel Gildea, and Kevin
Knight. 2006. Synchronous binarization for machine
translation. In Proc. HLT-NAACL, pages 256?263,
New York City, June.
Andreas Zollmann and Khalil Sima?an. 2005. A consis-
tent and efficient estimator for data-oriented parsing.
Journal of Automata, Languages and Combinatorics,
10(2/3):367?388.
368
Training Tree Transducers
Jonathan Graehl?
University of Southern California
Kevin Knight??
University of Southern California
Jonathan May?
University of Southern California
Many probabilistic models for natural language are now written in terms of hierarchical tree
structure. Tree-based modeling still lacks many of the standard tools taken for granted in
(finite-state) string-based modeling. The theory of tree transducer automata provides a possible
framework to draw on, as it has been worked out in an extensive literature. We motivate the
use of tree transducers for natural language and address the training problem for probabilistic
tree-to-tree and tree-to-string transducers.
1. Introduction
Much natural language work over the past decade has employed probabilistic finite-
state transducers (FSTs) operating on strings. This has occurred somewhat under the
influence of speech recognition research, where transducing acoustic sequences to word
sequences is neatly captured by left-to-right stateful substitution. Many conceptual tools
exist, such as Viterbi decoding (Viterbi 1967) and forward?backward training (Baum
and Eagon 1967), as well as software toolkits like the AT&T FSM Library and USC/ISI?s
Carmel.1 Moreover, a surprising variety of problems are attackable with FSTs, from
part-of-speech tagging to letter-to-sound conversion to name transliteration.
However, language problems like machine translation break this mold, because
they involve massive re-ordering of symbols, and because the transformation processes
seem sensitive to hierarchical tree structure. Recently, specific probabilistic tree-based
models have been proposed not only for machine translation (Wu 1997; Alshawi,
Bangalore, and Douglas 2000; Yamada and Knight 2001; Eisner 2003; Gildea 2003), but
also for summarization (Knight and Marcu 2002), paraphrasing (Pang, Knight, and
Marcu 2003), natural language generation (Langkilde and Knight 1998; Bangalore and
Rambow 2000; Corston-Oliver et al 2002), parsing, and language modeling (Baker
1979; Lari and Young 1990; Collins 1997; Chelba and Jelinek 2000; Charniak 2001; Klein
? Information Sciences Institute, 4676 Admiralty Way, Marina del Rey, CA 90292. E-mail: graehl@isi.edu.
?? Information Sciences Institute, 4676 Admiralty Way, Marina del Rey, CA 90292. E-mail: knight@isi.edu.
? Information Sciences Institute, 4676 Admiralty Way, Marina del Rey, CA 90292. E-mail: jonmay@isi.edu.
1 www.research.att.com/sw/tools/fsm and www.isi.edu/licensed-sw/carmel.
Submission received: 30 October 2003; revised submission received: 30 August 2007; accepted for
publication: 20 October 2007.
? 2008 Association for Computational Linguistics
Computational Linguistics Volume 34, Number 3
and Manning 2003). It is useful to understand generic algorithms that may support all
these tasks and more.
Rounds (1970) and Thatcher (1970) independently introduced tree transducers as a
generalization of FSTs. Rounds was motivated by natural language:
Recent developments in the theory of automata have pointed to an extension of
the domain of definition of automata from strings to trees . . . parts of mathematical
linguistics can be formalized easily in a tree-automaton setting . . .We investigate
decision problems and closure properties. Our results should clarify the nature of
syntax-directed translations and transformational grammars . . . (Rounds 1970)
The Rounds/Thatcher tree transducer is very similar to a left-to-right FST, except that
it works top-down, pursuing subtrees independently, with each subtree transformed
depending only on its own passed-down state. This class of transducer, called R in
earlier works (G?cseg and Steinby 1984; Graehl and Knight 2004) for ?root-to-frontier,?
is often nowadays called T, for ?top-down?.
Rounds uses a mathematics-oriented example of a T transducer, which we repeat
in Figure 1. At each point in the top-down traversal, the transducer chooses a produc-
tion to apply, based only on the current state and the current root symbol. The traversal
continues until there are no more state-annotated nodes. Non-deterministic transducers
may have several productions with the same left-hand side, and therefore some free
choices to make during transduction.
A T transducer compactly represents a potentially infinite set of input/output tree
pairs: exactly those pairs (T1, T2) for which some sequence of productions applied to
T1 (starting in the initial state) results in T2. This is similar to an FST, which compactly
represents a set of input/output string pairs; in fact, T is a generalization of FST. If
we think of strings written down vertically, as degenerate trees, we can convert any
FST into a T transducer by automatically replacing FST transitions with T produc-
tions, as follows: If an FST transition from state q to state r reads input symbol A
and outputs symbol B, then the corresponding T production is q A(x0) ? B(r x0). If
the FST transition output is epsilon, then we have instead q A(x0) ? r x0, or if the
input is epsilon, then q x0? B(r x0). Figure 2 depicts a sample FST and its equivalent
T transducer.
T does have some extra power beyond path following and state-based record-
keeping. It can copy whole subtrees, and transform those subtrees differently. It can
also delete subtrees without inspecting them (imagine by analogy an FST that quits and
accepts right in the middle of an input string). Variants of T that disallow copying and
deleting are called LT (for linear) and NT (for nondeleting), respectively.
One advantage to working with tree transducers is the large and useful body of
literature about these automata; two excellent surveys are G?cseg and Steinby (1984)
and Comon et al (1997). For example, it is known that T is not closed under composition
(Rounds 1970), and neither are LT or B (the ?bottom-up? cousin of T), but the non-
copying LB is closed under composition. Many of these composition results are first
found in Engelfriet (1975).
The power of T to change the structure of an input tree is surprising. For example,
it may not be initially obvious how a T transducer can transform the English structure
S(PRO, VP(V, NP)) into the Arabic equivalent S(V, PRO, NP), as it is difficult to move
the subject PRO into position between the verb V and the direct object NP. First,
T productions have no lookahead capability?the left-hand-side of the S production
392
Graehl, Knight, and May Training Tree Transducers
Figure 1
Part of a sample T tree transducer, adapted from Rounds (1970).
consists only of q S(x0, x1), although we want the English-to-Arabic transformation to
apply only when it faces the entire structure q S(PRO, VP(V, NP)). However, we can
simulate lookahead using states, as in these productions:
q S(x0, x1)? S(qpro x0, qvp.v.np x1)
qpro PRO? PRO
qvp.v.np VP(x0, x1)? VP(qv x0, qnp x1)
393
Computational Linguistics Volume 34, Number 3
Figure 2
An FST and its equivalent T transducer.
By omitting rules like qpro NP? ..., we ensure that the entire production sequence
will dead-end unless the first child of the input tree is in fact PRO. So finite lookahead
(into inputs we don?t delete) is not a problem. But these productions do not actually
move the subtrees around. The next problem is how to get the PRO to appear between
the V and NP, as in Arabic. This can be carried out using copying. We make two copies
of the English VP, and assign them different states, as in the following productions.
States encode instructions for extracting/positioning the relevant portions of the VP.
For example, the state qleft.vp.v means ?assuming this tree is a VP whose left child is V,
output only the V, and delete the right child?:
q S(x0, x1)? S(qleft.vp.v x1, qpro x0, qright.vp.np x1)
qpro PRO? PRO
qleft.vp.v VP(x0, x1)? qv x0
qright.vp.np VP(x0, x1)? qnp x1
With these rules, the transduction proceeds as in Figure 3. This ends our informal pre-
sentation of tree transducers.
Although general properties of T are understood, there are many algorithmic ques-
tions. In this article, we take on the problem of training probabilistic T transducers. For
many language problems (machine translation, paraphrasing, text compression, etc.),
it is possible to collect training data in the form of tree pairs and to distill linguistic
knowledge automatically. Our problem statement is: Given (1) a particular transducer
394
Graehl, Knight, and May Training Tree Transducers
Figure 3
Multilevel re-ordering of nodes in a T-transducer.
with rules R, and (2) a finite training set of sample input/output tree pairs, we want
to produce (3) a probability estimate for each rule in R such that we maximize the
probability of the output trees given the input trees. As with the forward?backward
algorithm, we seek at least a local maximum. Tree transducers with weights have been
studied (Kuich 1999; Engelfriet, F?l?p, and Vogler 2004; F?l?p and Vogler 2004) but we
know of no existing training procedure.
Sections 2?4 of this article define basic concepts and recall the notions of relevant au-
tomata and grammars. Sections 5?7 describe a novel tree transducer training algorithm,
and Sections 8?10 describe a variant of that training algorithm for trees and strings.
Section 11 presents an example linguistic tree transducer and provides empirical evi-
dence of the feasibility of the training algorithm. Section 12 describes how the training
algorithm may be used for training context-free grammars. Section 13 discusses related
and future work.
2. Trees
T? is the set of (rooted, ordered, labeled, finite) trees over alphabet ?. An alphabet is a finite
set. (see Table 1)
T?(X) are the trees over alphabet ?, indexed by X?the subset of T??X where only
leaves may be labeled by X (T?(?) = T?). Leaves are nodes with no children.
The nodes of a tree t are identified one-to-one with its paths: pathst ? paths ? N
? ?
??
i=0 N
i (N0 ? {()}). The size of a tree is the number of nodes: |t| = |pathst|. The path
to the root is the empty sequence (), and p1 extended by p2 is p1 ? p2, where ? is the
concatenation operator:
(a1, . . . , an) ? (b1, . . . , bm) ? (a1, . . . , an, b1, . . . , bm)
For p ? pathst, rankt(p) is the number of children, or rank, of the node at p,
and labelt(p) ? ? is its label. The ranked label of a node is the pair labelandrankt(p) ?
(labelt(p), rankt(p)). For 1 ? i ? rankt(p), the ith child of the node at p is located at
395
Computational Linguistics Volume 34, Number 3
Table 1
Notation guide.
Notation Meaning
(w)FS(T,A) (weighted) finite-state string (transducers,acceptors)
(w)RTG (weighted) regular tree grammars (generalizes PCFG)
(x)(L)(N)T(s) (extended) (linear) (nondeleting) top?down tree(-to-string) transducers
(S)T(A,S)G (synchronous) tree (adjoining,substitution) grammars
(S,P)CFG (synchronous,probabilistic) context-free grammars
R+ positive real numbers
N natural numbers: {1, 2, 3, . . .}
? empty set
? equals (by definition)
|A| size of finite set A
X? Kleene star of X, i.e., strings over alphabet X: {(x1, . . . , xn) | n ? 0}
a ? b String concatenation: (1) ? (2, 3) = (1, 2, 3)
<lex lexicographic (dictionary) order: () < (1) < (1, 1) < . . . < (1, 2) < . . .
? alphabet (set of symbols) (commonly: input tree alphabet)
t ? T? t is a tree with label alphabet ?
T?(X) ... and with variables from additional leaf label alphabet X
A(t) tree constructed by placing a unary A above tree t
A((x1, . . . , xn)) tree constructed by placing an n-ary A over leaves (x1, . . . , xn)
p tree path, e.g., (a, b) is the bth child of the ath child of root
paths the set of all tree paths (? N?)
pathst subset of paths that lead to actual nodes in t
pathst({A,B}) paths that lead to nodes labeled A or B in t
t ? p the subtree of twith root at p, so that (t ? p) ? q = t ? (p ? q)
rankt(p) the number of children of the node p of t
labelt(p) the label of node p of t
labelandrankt(p) the pair (labelt(p), rankt(p))
t[p? t?] substitution of tree t? for the subtree t ? p
t[p? t?p,?p ?P] parallel substitution of tree t
?
p for each t ? p
yieldt(X) the left? right concatenation of the X labels of the leaves of t
S ? N start nonterminal of a regular tree grammar
P,R productions of a regular tree grammar, rules of a tree transducer
D(M) derivations (keeping a list of applied rewrites) ofM
LD(M) leftmost derivations ofM
wM(d ? D(M)) weight of a derivation d: product of weight of each rule usage
WM(x) total weight of x inM: sum of weight of all LD(M) producing x
L(M) weighted tree set, tree relation, or tree-to-string relation ofM
? output tree alphabet
Qi ? Q initial (start) state of a transducer
? ? xTPAT? functions from T? to {0, 1} that examine finitely many paths
True the tree pattern True(t) ? 1,?t
s ? ?? s is a string from alphabet ?, e.g., () the empty string
s[i] ith letter of string s - the ith projection ?i
indicess i such that s[i] exists: (1, . . . , |s|)
letterss set of all letters s[i] in s
|s| length of string; |s| = |indicess|, not |letterss|
spanss Analogous to tree paths, pairs (i,j) denoting substrings
s ? (i, j) The substring (s[i], . . . , s[j? 1]) indicated by the span (i, j) ? spanss
s ? [i] same as s[i]; [i] stands for the span (i, i+ 1)
s[p? s?] Substitution of string s? for span p of s
s[p? s?p,?p ?P] Parallel (non-overlapping) substitution of string s
?
p for each s ? p
396
Graehl, Knight, and May Training Tree Transducers
path p ? (i). The subtree at path p of t is t ? p, defined by pathst?p ? {q | p ? q ? pathst} and
labelandrankt?p(q) ? labelandrankt(p ? q).
The paths to X in t are pathst(X) ? {p ? pathst | labelt(p) ? X}.
A set of paths F ? paths is a frontier iff it is pairwise prefix-independent:
?p1, p2 ? F, p ? paths : p1 = p2 ? p =? p1 = p2
We write F for the set of all frontiers. F is a frontier of t, if F ? Ft is a frontier whose
paths are all valid for t?Ft ? F ? pathst.
For t, s ? T?(X), p ? pathst, t[p? s] is the substitution of s for p in t, where the subtree
at path p is replaced by s. For a frontier F of t, the parallel substitution of t?p for the frontier
F ? Ft in t is written t[p? t?p,?p ? F], where there is a t
?
p ? T?(X) for each path p. The
result of a parallel substitution is the composition of the serial substitutions for all p ? F,
replacing each t ? pwith t?p. (If Fwere not a frontier, the result would vary with the order
of substitutions sharing a common prefix.) For example: t[p? t ? p ? (1),?p ? F] would
splice out each node p ? F, replacing it by its first subtree.
Trees may be written as strings over? ? {(, )} in the usual way. For example, the tree
t = S(NP,VP(V,NP)) has labelandrankt((2)) = (VP, 2) and labelandrankt((2, 1)) = (V, 0).
Commas, written only to separate symbols in ? composed of several typographic
letters, should not be considered part of the string. For example, if we write ?(t) for
? ? ?, t ? T?, we mean the tree with label?(t)(()) ? ?, rank?(t)(()) ? 1 and ?(t) ? (1) ? t.
Using this notation, we can give a definition of T?(X):
If x ? X, then x ? T?(X) (1)
If ? ? ?, then ? ? T?(X) (2)
If ? ? ? and t1, . . . , tn ? T?(X), then ?(t1, . . . , tn) ? T?(X) (3)
The yield of X in t is yieldt(X), the concatenation (in lexicographic order
2) over paths
to leaves l ? pathst (such that rankt(l) = 0) of labelt(l) ? X?that is, the string formed by
reading out the leaves labeled with X in left-to-right order. The usual case (the yield of t)
is yieldt ? yieldt(?). More precisely,
yieldt(X) ?
?
?
?
l if r = 0 ? l ? X where (l, r) ? labelandrankt(())
() if r = 0 ? l ? X
?ri=1yieldt?(i)(X) otherwise where ?
r
i=1si ? s1 ? . . . ? sr
3. Regular Tree Grammars
In this section, we describe the regular tree grammar, a common way of compactly
representing a potentially infinite set of trees (similar to the role played by the regu-
lar grammar for strings). We describe the version where trees in a set have different
weights, in the same way that a weighted finite-state acceptor gives weights for strings
2 () <lex (a), (a1) <lex (a2) iff a1 < a2, (a1) ? b1 <lex (a2) ? b2 iff a1 < a2 ? (a1 = a2 ? b1 <lex b2).
397
Computational Linguistics Volume 34, Number 3
? = {S, NP, VP, PP, PREP, DET, N, V, run, the, of, sons, daughters}
N = {qnp, qpp, qdet, qn, qprep}
S = q
P = {q?1.0 S(qnp, VP(VB(run))),
qnp?0.6 NP(qdet, qn),
qnp?0.4 NP(qnp, qpp),
qpp?1.0 PP(qprep, np),
qdet?1.0 DET(the),
qprep?1.0 PREP(of),
qn?0.5 N(sons),
qn?0.5 N(daughters)}
Sample generated trees:
S(NP(DT(the), N(sons)),
VP(V(run)))
(with probability 0.3)
S(NP(NP(DT(the), N(sons)),
PP(PREP(of), NP(DT(the), N(daughters)))),
VP(V(run)))
(with probability 0.036)
Figure 4
A sample weighted regular tree grammar (wRTG).
in a regular language; when discussing weights, we assume the commutative semiring
({r ? R | r ? 0},+, ?, 0, 1) of nonnegative reals with the usual sum and product.
A weighted regular tree grammar (wRTG) G is a quadruple (?,N,S,P), where ? is
the alphabet, N is the finite set of nonterminals, S ? N is the start (or initial) nonterminal,
and P ? N ? T?(N)? R+ is a finite set of weighted productions (R+ ? {r ? R | r > 0}). A
production (lhs, rhs,w) is written lhs?w rhs (if w is omitted, the multiplicative identity
1 is assumed). Productions whose rhs contains no nonterminals (rhs ? T?) are called
terminal productions, and rules of the form A?w B, for A,B ? N are called -productions,
or state-change productions, and can be used in lieu of multiple initial nonterminals.
Figure 4 shows a sample wRTG. This grammar generates an infinite number of trees.
We define the binary derivation relation on terms T?(N) and derivation histories
(T?(N ? (paths? P)?):
?G?
{
((a, h), (b, h ? (p, (l, r,w)))) | (l, r,w) ? P?
p ? pathsa({l})?
b = a[p? r]
}
398
Graehl, Knight, and May Training Tree Transducers
That is, (a, h)?G (b, h ? (p, (l, r,w))) iff b may be derived from a by using the rule
l?w r to replace the nonterminal leaf l at path p with r. The reflexive, transitive closure
of ?G is written ??G, and the derivations of G, written D(G), are the ways the start
nonterminal may be expanded into entirely terminal trees:
D(G) ?
{
(t, h) ? T? ? (paths? P)? | (S, ())??G (t, h)
}
We also project the ??G relation so that it refers only to trees: t
? ??G t iff ?h
?, h ?
(paths? P)? : (t?, h?)??G (t, h).
We take the product of the used weights to get the weight of a derivation d ? D(G):
wG((t, (h1, . . . , hn)) ? D(G)) ?
n
?
i=1
wi where hi = (pi, (li, ri,wi))
The leftmost derivations of G build a tree preorder from left to right (always expand-
ing the leftmost nonterminal in its string representation):
LD(G) ?
{
(t, ((p1, r1), . . . , (pn, rn))) ? DG | ?1 ? i < n : pi+1 ?lex pi
}
The total weight of t in G is given byWG : T? ? R, the sum of the weights of leftmost
derivations producing t: WG(t) ?
?
(t,h)?LD(G) wG((t, h)). Collecting the total weight of
every possible (nonzero weight) output tree, we call L(G) the weighted tree language of
G, where L(G) = {(t,w) |WG(t) = w ? w > 0} (the unweighted tree language is simply
the first projection).
For every weighted context-free grammar, there is an equivalent wRTG that gener-
ates its weighted derivation trees (whose yield is a string in the context-free language),
and the yield of any regular tree language is a context-free string language (G?cseg
and Steinby 1984). We can also interpret a regular tree grammar as a context-free string
grammar with alphabet ? ? {(, )}.
wRTGs generate (ignoring weights) exactly the recognizable tree languages, which
are sets of trees accepted by a non-transducing automaton version of T. This acceptor
automaton is described in Doner (1970) and is actually a closer mechanical analogue
to an FSA than is the rewrite-rule-based wRTG. RTGs are closed under intersection
(G?cseg and Steinby 1984), and the constructive proof also applies to weighted wRTG
intersection. There is a normal form for wRTGs analogous to that of regular grammars:
Right-hand sides are a single terminal root with (optional) nonterminal children. What
is sometimes called a forest in natural language generation (Langkilde 2000; Nederhof
and Satta 2002) is a finite wRTG without loops?for all valid derivation trees, each
nonterminal may only occur once in any path from root to a leaf:
?n ? N, t ? T?(N), h ? (paths? P)? : (n, ())??G (t, h) =? pathst({n}) = ?
RTGs produce tree sets equivalent to those produced by tree substitution grammars
(TSGs) (Schabes 1990) up to relabeling. The relabeling is necessary because RTGs distin-
guish states and tree symbols, which are conflated in TSGs at the elementary tree root.
Regular tree languages are strictly contained in tree sets of tree adjoining grammars
(TAG; Joshi and Schabes 1997), which generate string languages strictly between the
context-free and indexed languages. RTGs are essentially TAGs without auxiliary trees
399
Computational Linguistics Volume 34, Number 3
and their adjunction operation; the productions correspond exactly to TAG?s initial trees
and the elementary tree substitution operation.
4. Extended-LHS Tree Transducers (xT)
Section 1 informally described the root-to-frontier transducer class T. We saw that T
allows, by use of states, finite lookahead and arbitrary rearrangement of non-sibling
input subtrees removed by a finite distance. However, it is often easier to write rules that
explicitly represent such lookahead and movement, relieving the burden on the user to
produce the requisite intermediary rules and states. We define xT, a generalization of
weighted T. Because of its good fit to natural language problems, xT is already briefly
touched on, though not defined, in Section 4 of Rounds (1970).
A weighted extended-lhs top-down tree transducer M is a quintuple (?,?,Q,Qi,R)
where ? is the input alphabet, and ? is the output alphabet, Q is a finite set of states,
Qi ? Q is the initial (or start, or root) state, and R ? Q? xTPAT? ? T?(Q? paths)? R+
is a finite set of weighted transformation rules. xTPAT? is the set of finite tree patterns:
predicate functions f : T? ? {0, 1} that depend only on the label and rank of a finite
number of fixed paths of their input. A rule (q, ?, rhs,w) is written q ? ?w rhs, mean-
ing that an input subtree matching ? while in state q is transformed into rhs, with
Q? paths leaves replaced by their (recursive) transformations. TheQ? paths leaves of a
rhs are called nonterminals (there may also be terminal leaves labeled by the output tree
alphabet ?).
xT is the set of all such transducers T; the set of conventional top-down trans-
ducers, is a subset of xT where the rules are restricted to use finite tree patterns that de-
pend only on the root: TPAT? ? {p?,r(t)}where p?,r(t) ? (labelt(()) = ? ? rankt(()) = r).
Rules whose rhs are a pure T? with no states/paths for further expansion are called
terminal rules. Rules of the form q ? ?w q? () are -rules, or state-change rules, which
substitute state q? for state q without producing output, and stay at the current input
subtree. Multiple initial states are not needed: we can use a single start state Qi, and
instead of each initial state qwith starting weight w add the rule Qi True?w q () (where
True(t) ? 1,?t).
We define the binary derivation relation for xT transducer M on partially trans-
formed terms and derivation histories T????Q ? (paths? R)?:
?M?
{
((a, h), (b, h ? (i, (q, ?, rhs,w)))) | (q, ?, rhs,w) ? R ?
i ? pathsa ? q = labela(i) ? ?(a ? (i ? (1))) = 1 ?
b = a
[
i? rhs
[
p? q?(a ? (i ? (1) ? i?)),
?p ? pathsrhs : labelrhs(p) = (q
?, i?)
]]
}
That is, b is derived from a by application of a rule q ? ?w rhs to an unprocessed
input subtree a ? i which is in state q, replacing it by output given by rhs with variables
(q?, i?) replaced by the input subtree at relative path i? in state q?.3
Let ??M, D(M), LD(M), wM, WM, and L(M) (the weighted tree relation of M) follow
from the single-step?M exactly as they did in Section 3, except that the arguments are
3 Recall that q(a) is the tree whose root is labeled q and whose single child is the tree a.
400
Graehl, Knight, and May Training Tree Transducers
input and output instead of just output, with initial terms Qi(t) for each input t ? T? in
place of S:
D(M) ?
{
(t, t?, h) ? T? ? T? ? (paths? R)? | (Qi(t), ())??M (t
?, h)
}
We have given a rewrite semantics for our transducer, similar to wRTG. In the
intermediate terms of a derivation, the active frontier of computation moves top-down,
with everything above that frontier forming the top portion of the final output. The next
rewrite always occurs somewhere on the frontier, and in a complete derivation, the frontier
finally shrinks and disappears. In wRTG, the frontier consisted of the nonterminal-
labeled leaves. In xT, the frontier items are not nonterminals, but pairs of state and input
subtrees. We choose to represent these pairs as subtrees of terms with labels taken from
? ?? ?Q, where the state is the parent of the input subtree. In fact, given an M ? xT
and an input tree t, we can take all the (finitely many) pairs of input subtrees and states
as nonterminals in a wRTGG, with all the (finitely many) possible single-step derivation
rewrites ofM applied to t as productions (taking the weight of the xT rule used), and the
initial term Qi(t) as the start nonterminal, isomorphic to the derivations of theMwhich
start withQi(t): (d, h) ? D(G) iff (t, d, h) ? D(M). Such derivations are exactly how all the
outputs of an input tree t are produced: when the resulting term d is in T?, we say that
(t, d) is in the tree relation and that d is an output of t.
Naturally, there may be input trees for which no complete derivation exists?such
inputs are not in the domain of the weighted tree relation, having no output. It is known
that domain(M) ? {i | ?o,w : (i, o,w) ? L(M)}, the set of inputs that produce any output,
is always a recognizable tree language (Rounds 1970).
The sources of a rule r = (q, l, rhs,w) ? R are the input-paths in the rhs:
sources(r) ? {i? | ?p ? pathsrhs(Q? paths), q
? ? Q : labelrhs(p) = (q?, i?)}
If the sources of a rule refer to input paths that do not exist in the input, then the
rule cannot apply (because a ? (i ? (1) ? i?) would not exist). In the traditional statement
of T, sources(r) are the variables xi, standing for the i
th child of the root at path (i),
and the right hand sides of rules refer to them by name: (qi, xi). In xT, however, we
refer to the mapped input subtrees by path (and we are not limited to the immediate
children of the root of the subtree under transformation, but may choose any frontier
of it).
A transducer is linear if for all its rules r, sources(r) are a frontier and occur at most
once: ?p1, p2 ? pathsrhs(Q? paths), p ? paths? {()} : p1 = p2 ? p. A transducer is determin-
istic if for any input, at most one rule matches per state:
?q ? Q, t ? T?, r = (q, p, r,w), r? = (q?, p?, r?,w?) ? R :
p(t) = 1 ? p?(t) = 1 =? r = r?
or in other words, the rules for a given state have patterns that partition possible input
trees. A transducer is deleting if there are rules in which (for some matching inputs)
entire subtrees are not used in their rhs.
In practice, we will be interested mostly in concrete transducers, where the patterns
fully specify the labels and ranks of an input subtree including all the ancestors
of sources(r). Naturally, T are concrete. We have taken to writing concrete rules?
patterns as trees with variables X in the leaves (at the sources), and using those same
401
Computational Linguistics Volume 34, Number 3
variables in the rhs instead of writing the corresponding path in the lhs. For example:
q A(x0:B,C) ?w q? x0 means a xT rule (q, ?, rhs,w) with rhs = (q?, (1)) and
? ? (labelandrankt(()) = (A, 1) ? labelt((1)) = B ? labelandrankt((2)) = (C, 0))
It might be convenient to convert any xT transducer to an equivalent T transducer,
then process it with T-based algorithms?in such a case, xT would just be syntactic sugar
for T. We can automatically generate T productions that use extra states to emulate the
finite lookahead and movement available in xT (as demonstrated in Section 1), but with
one fatal flaw: Because of the definition of ?M, xT (and thus T) only has the ability
to process input subtrees that produce corresponding output subtrees (alas, there is no
such thing as an empty tree), and because TPAT can only inspect the root node while
deriving replacement subtrees, T can check only the parts of the input subtree that lie
along paths that are referenced in the rhs of the xT rule. For example, suppose we want
to transform NP(DET, N) (but not, say, NP(ADJ, N)) into the tree N using rules in T.
Although this is a simple xT rule, the closest we can get with T would be q NP(x0,
x1) ? q.N x1, but we cannot check both subtrees without emitting two independent
subtrees in the output (which rules out producing just N). Thus, xT is a bit more
powerful than T.
5. Parsing an xT Tree Relation
Derivation trees for a transducer M = (?,?,Q,Qi,R) are TR (trees labeled by rules)
isomorphic to complete leftmost M-derivations. Figure 5 shows derivation trees for a
particular transducer. In order to generate derivation trees forM automatically, we build
a modified transducerM?. This new transducer produces derivation trees on its output
instead of normal output trees.M? is (?,R,Q,Qi,R
?), with4
R? ? {(q, ?, r(yieldrhs(Q? paths)),w) | r = (q, ?, rhs,w) ? R}
That is, the original rhs of rules are flattened into a tree of depth 1, with the root labeled
by the original rule, and all the non-expanding ?-labeled nodes of the rhs removed, so
that the remaining children are the nonterminal yield in left to right order. Derivation
trees deterministically produce a single weighted output tree, and for concrete trans-
ducers, a single input tree.
For every leftmost derivation there is exactly one corresponding derivation tree: We
start with a sequence of leftmost derivations and promote rules applied to paths that
are prefixes of rules occurring later in the sequence (the first will always be the root), or,
in the other direction, list out the rules of the derivation tree in order.5 The weights of
derivation trees are, of course, just the product of the weights of the rules in them.6
The derived transducer M? nicely produces derivation trees for a given input, but
in explaining an observed (input/output) pair, we must restrict the possibilities further.
Because the transformations of an input subtree depend only on that subtree and its
state, we can build a compact wRTG that produces exactly the weighted derivation
trees corresponding toM-transductions (I, ())??M (O, h) (Algorithm 1).
4 By r((t1, . . . , tn )), we mean the tree r(t1, . . . , tn ).
5 Some path concatenation is required, because paths in histories are absolute, whereas the paths in rule rhs
are relative to the input subtree.
6 Because our product is commutative, the order does not matter.
402
Graehl, Knight, and May Training Tree Transducers
Figure 5
Derivation trees for a T tree transducer.
Algorithm 1 makes use of memoization?the possible derivations for a given (q, i, o)
are constant, so we store answers for all past queries in a lookup table and return them,
avoiding needless recomputation. Even if we prove that there are no derivations for
some (q, i, o), successful subhypotheses met during the proof may recur and are kept,
but we do avoid adding productions we know can?t succeed. We have in the worst case
to visit all |Q| ? |I| ? |O| (q, i, o) pairs and apply all |R| transducer rules successfully at
each of them, so time and space complexity, proportional to the size of the (unpruned)
output wRTG, are both O(|Q| ? |I| ? |O| ? |R|), or O(Gn2), where n is the total size of the
403
Computational Linguistics Volume 34, Number 3
Algorithm 1. Deriv (derivation forest for I??xT O)
Input: xT transducerM = (?,?,Q,Qi,R) and observed tree pair I ? T?, O ? T?.
Output: derivation wRTG G = (R,N ? Q? pathsI ? pathsO,S,P) generating all
weighted derivation trees forM that produce O from I. Returns false instead if
there are no such trees. O(G|I||O|) time and space complexity, where G is a
grammar constant.
begin
S? (Qi, (), ()), N??, P??, memo??
if PRODUCEI,O(S) then
N?{n | ?(n?, rhs,w) ? P : n = n? ? n ? yieldrhs(Q? pathsI ? pathsO)}
return G = (R,N,S,P)
else
return false
end
PRODUCEI,O(? = (q, i, o) ? Q? pathsI ? pathsO) returns boolean ? begin
if ?(?, r) ? memo then return r
memo?memo ? {(?, true)}
anyrule?? false
for r = (q, ?, rhs,w) ? R : ?(I ? i) = 1 ?MatchO,?(rhs, o) do
(o1, . . . , on)? pathsrhs(Q? paths) sorted by o1 <lex . . . <lex on //n = 0 if there are
no rhs variables
labelandrankderivrhs(())? (r,n) //derivrhs is a newly created tree
for j? 1 to n do
(q?, i?)? labelrhs(oj)
?? (q?, i ? i?, o ? oj)
if ?PRODUCEI,O(?) then next r
labelandrankderivrhs((j))? (?, 0)
anyrule?? true
P?P ? {(?, derivrhs,w)}
memo?memo ? {(?,anyrule?)}
return anyrule?
end
Matcht,?(t
?, p) ? ?p? ? path(t?) : label(t?, p?) ? ? =? labelandrankt? (p?) =
labelandrankt(p ? p?)
input and output trees, and G is the grammar constant accounting for the states and
rules (and their size).
If the transducer contains cycles of state-change rules, then the generated derivation
forest may have infinitely many trees in it, and thus the memoization of PRODUCE
must temporarily assume that the alignment (q, i, o) under consideration will succeed
upon reaching itself, through such a cycle, even though the answer is not yet conclusive
(it may be conclusively true, but not false). Although it would be possible to detect these
cycles (setting ?pending? rather than true for the interim in memo) and deal with them
more severely, we can just remove the surplus later in linear time, using Algorithm 2,
which is an implementation (for wRTG) of a well-known method of pruning useless
404
Graehl, Knight, and May Training Tree Transducers
Algorithm 2. RTGPrune (wRTG useless nonterminal/production identification)
Input: wRTG G = (?,N,S,P), with P = (p1, . . . , pm) and pi = (qi, ti,wi).
Output: For all n ? N, B[n] = (?t ? T? : n??G t) (true if n derives some output tree t
with no remaining nonterminals, false if it?s useless), and
A[n] = (?t ? T?, t? ? T?({n}) : S??G t
? ??G t) (n additionally can be produced
from an S using only productions that can appear in complete derivations).
Time and space complexity are linear in the total size of the input:
O(|N|+
?m
i=1 (1+ |pathsti |)
begin
M??
for n ? N do B[n]? false, Adj[n]??
for i? 1 to m do
Y?{labelti (p) | p ? pathsti (N)}
// Y are the unique N in rhs of rule i
for n ? Y do Adj[n]?Adj[n] ? {i}
if |Y| = 0 thenM?M ? {i}
r[i]?|Y|
for n ?M do REACH(n)
/* Now that B[n] are decided, compute A[n] */
for n ? N do A[n]? false
USE(S)
end
REACH(n) ? begin
B[n]? true
for i ? Adj[n] do
if ?B[qi] then
r[i]? r[i]? 1
if r[i] = 0 then REACH(qi)
end
USE(n) ? begin
A[n]? true
for n? s.t. ?(n, t,w) ? R : n? ? yieldt(N) do
/* for n? that are in the rhs of rules whose lhs is n */
if ?A[n?] ? B[n?] then USE(n?)
end
productions from a CFG (Hopcroft and Ullman 1979).7 We eliminate all the remains
of failed subforests, by removing all nonterminals n, and any productions involving n,
where Algorithm 2 gives A[n] = false.
In the next section, we show how to compute the contribution of a nonterminal to
the weighted trees produced by a wRTG, in a generalization of Algorithm 2 that gives
us weights that we accumulate per rule over the training examples, for EM training.
7 The idea is to first remove all nonterminals (and productions referring to them) that don?t yield any
terminal string, and after that, to remove those which are not reachable top-down from S.
405
Computational Linguistics Volume 34, Number 3
6. Inside?Outside for wRTG
Given a wRTGG = (?,N,S,P), we can compute the sums of weights of trees derived us-
ing each production by adapting the well-known inside?outside algorithm for weighted
context-free (string) grammars (Lari and Young 1990).
Inside weights ?G for a nonterminal or production are the sum of weights of all trees
that can be derived from it:
?G(n ? N) ?
?
(n,r,w)?P
w ? ?G(r)
?G(r ? T?(N) | (n, r,w) ? P}) ?
?
p?pathsr(N)
?G(labelr(p))
By definition, ?G(S) gives the sum of the weights of all trees generated by G. For the
wRTG generated by Deriv(M, I,O), this is exactlyWM(I,O).
The recursive definition of ? does not assume a non-recursive wRTG. In the
presence of derivation cycles with weights less than 1, ? can still be evaluated as a
convergent sum over an infinite number of trees.
The output of Deriv will always be non-recursive provided there are no cycles of
-rules in the transducer. There is usually no reason to build such cycles, as the effect
(in the unweighted case) is just to make all implicated states equivalent.
Outside weights ?G are for each nonterminal the sums over all its occurrences in
complete derivations in the wRTG of the weight of the whole tree, excluding the
occurrence subtree weight (we define this without resorting to division for cancellation,
but in practice we may use division by ?G(n) to achieve the same result).
?G(n ? N) ?
?
?
?
?
?
?
?
?
?
?
?
?
?
1 if n = S
uses of n in productions
? ?? ?
?
p,(n?,r,w)?P:labelr(p)=n
w ? ?G(n?) ?
?
p??pathsr(N)?{p}
?G(labelr(p
?))
? ?? ?
sibling nonterminals
otherwise.
Provided that useless nonterminals and productions were removed by Algorithm 2,
and none of the rule weights are 0, all of the nonterminals in a wRTG will have nonzero
? and ?. Conversely, if useless nonterminals weren?t removed, they will be detected
when computing inside?outside weights by virtue of their having zero values, so they
may be safely pruned without affecting the generated weighted tree language.
Finally, given inside and outside weights, the sum of weights of trees using a
particular production is ?G((n, r,w) ? P) ? ?G(n) ? w ? ?G(r). Here we rely on the com-
mutativity of the product (the left-out inside part reappears on the right of the inside
part, even when it wasn?t originally the last term).
Computing ?G and ?G for nonrecursive wRTG is a straightforward translation of
the recursive definitions (using memoization to compute each result only once) and is
O(|G|) in time and space. Or, without using memoization, we can take a topological sort
406
Graehl, Knight, and May Training Tree Transducers
using the dependencies induced by the equations for the particular forest, and compute
in that order. In case of a recursive wRTG, the equations may still be solved (usually
iteratively), and it is easy to guarantee that the sums converge by appropriately keeping
the rule weights of state-change productions less than one.
7. EM Training
Expectation-Maximization (EM) training (Dempster, Laird, and Rubin 1977) works on
the principle that the likelihood (product over all training examples of the sum of all
model derivations for it) can be maximized subject to some normalization constraint on
the parameters,8 by repeatedly:
1. Computing the expectation of decisions taken for all possible ways of
generating the training corpus given the current parameters, accumulating
(over each training example) parameter counts c of the portion of all
possible derivations using that parameter?s decision:
?? ? parameters :
c? ? Et?training
?
?
?
?
?
d?derivationst
(# of times ? used in d) ? pparameters(d)
?
d?derivationst
pparameters(d)
?
?
?
?
2. Maximizing by assigning the counts to the parameters and renormalizing:
?? ? parameters : ?? c?
Z?(c )
Each iteration is guaranteed to increase the likelihood until a local maximum is
reached. Normalization may be affected by tying or fixing of parameters. The deriva-
tions for training examples do not change, but the model weights for them do. Us-
ing inside?outside weights, we can efficiently compute these weighted sums over all
derivations for a wRTG, and thus, using Algorithm 1, over all xT derivations explaining
a given input/output tree pair.
A simpler version of Deriv that computes derivation trees for a wRTG given an
output tree could similarly be used to train weights for wRTG rules.9
Each EM iteration takes time linear in the size of the transducer and linear in the
size of the derivation tree grammars for the training examples. The size of the derivation
trees is at worstO(Gn2), so for a corpus ofN examples with maximum input/output size
n, an iteration takes at worst timeO(NGn2). Typically, we expect only a small fraction of
possible states and rules will apply to a given input/output subtree mapping.
8 Each parameter gives the probability of a single model decision, and a derivation?s probability is the
product of all the decisions producing it.
9 One may also use Deriv unmodified to train an identity (or constant-input) transducer with one rule
per wRTG production, having exactly the range of the wRTG in question, and of course transforming
training trees to appropriate tree pairs.
407
Computational Linguistics Volume 34, Number 3
The recommended normalization function computes the sum of all the counts for
rules having the same state, which results in trained model weights that give a joint
probability distribution over input/output tree pairs.
Attempts at conditional normalization can be problematic, unless the patterns for all
the rules of a given state can be partitioned into sets so that for any input, only patterns
from at most one set may match. For example, if all the patterns specify the label and
rank of the root, then they may be partitioned along those lines. Input-epsilon rules,
which always match (with pattern True), would make the distribution inconsistent by
adding extra probability mass, unless they are required (in what is no longer a partition)
to have their counts normalized against all the partitions for their state (because they
transform inputs that could fall in any of them).
One can always marginalize a joint distribution for a particular input to get true
conditional probabilities. In fact, no method of assigning rule weights can generally
compute exact conditional probabilities; remarginalization is already required: take as
the normalization constant the inside weight of the root derivation forest corresponding
to all the derivations for the input tree in question.
Even using normalization groups that lead to inconsistent probability distributions,
EM may still compute some empirically useful local maximum. For instance, placing
each q lhs in its own normalization group might be of interest; although the inside
weights of a derivation forest would sum to some s > 1, Train would divide the counts
earned by each participating rule by s (Algorithm 3).
8. Strings
We have covered tree-to-tree transducers; we now turn to tree-to-string transducers.
In the automata literature, such transductions are called generalized syntax-directed
translation (Aho and Ullman 1971), and are used to specify compilers that (deter-
ministically) transform high-level source-language trees into linear target-language
code. Tree-to-string transducers have also been applied to the machine translation of
natural languages (Yamada and Knight 2001; Eisner 2003). Tree-to-string transduction
is appealing when trees are only available on the input side of a training corpus.
Furthermore, tree/string relationships are less constrained than tree/tree, allowing
the possibility of simpler models to account for natural language transformations.
(Though we will not pursue it here, string-to-string training should also be possible
with tree-based models, if only string-pair data is available; string/string relations
induced by tree transformations are sometimes called translations in the automata
literature.)
? are the strings over alphabet ?. For s = (s1, . . . , sn), the length of s is |s| ? n and
the ith letter is s[i] ? si, for all i ? indicess ? {i ? N | 1 ? i ? n}. indicess(X) is the subset
{i ? indicess | i[s] ? X}. The letters in s are letterss = {l|?i ? indicess : s[i] = l}. The spans
of s are spanss = {(a, b) ? {N
2 | 1 ? a ? b ? n+ 1}, and the substring at span p = (a, b) of
s is s ? p ? (sa, . . . sb?1), with s ? (a, a) = (). We use the shorthand [i] ? (i, i+ 1) for all
i ? N, so s ? [i] = s[i]. The substitution of t for a span (a, b) ? spanss in s is s[(a, b)? t] ?
(s ? (1, a)) ? t ? (s ? (b,n+ 1)).10
A partition is a set of non-overlapping spans P??(a, b), (c, d) ? P : c ? d ? a ? b ?
c ? d ? (a, b) = (c, d), and the parallel substitution of s?p for the partition P of s is writ-
ten s[p? s?p,?p ? P]. In contrast to parallel tree substitution, we cannot take any
10 a ? b is string concatenation, defined already in Section 2.
408
Graehl, Knight, and May Training Tree Transducers
composition of the individual substitutions, because the replacement substrings may
be of different length, changing the referent of subsequent spans. It suffices to perform
a series of individual substitutions, in right to left order?(an, bn), . . . , (ai, bi), . . . , (a1, b1)
(ai ? bi+1,?1 ? i < n).
Algorithm 3. Train (EM training for tree transducers)
Input: xR transducerM = (?,?,Q,Qd,R) with initial rule weights, observed weighted
tree pairs T ? T? ? T? ? R+, minimum relative log-likelihood change for
convergence  ? R+, maximum number of iterations maxit ? N, and for each
rule r ? R: prior counts (for a Dirichlet prior) prior : R ? R for smoothing, and
normalization function Zr : (R ? R) ? R used to update weights from counts
w?r? count(r)/Zr(count).
Output: New rule weightsW ? {wr | r ? R}.
begin
for (i, o,w) ? T do
di,o?Deriv(M, i, o) // Algorithm 1
if di,o = false then
T?T ? {(i, o,w)}
Warn(more rules are needed to explain (i, o))
Compute inside?outside weights for di,o
If Algorithm 2 (RTGPrune) has not already been used to do so, remove all useless
nonterminals n (and associated rules) whose ?di,o (n) = 0 or ?di,o (n) = 0
i? 0, L???, ?? 
for r = (q, ?, rhs,w) ? R do wr?w
while ? ?  ? i < maxit do
for r ? R do count[r]? prior(r)
L?? 0
for (i, o,wexample) ? T / / Estimate
do
let D ? di,o ? (R,N,S,P)
compute ?D,?D using latestW ? {wr | r ? R} // see Section 6
for ? = (n, rhs,w) ? P do
?D(?)??D(n) ? w ? ?D(rhs)
let r ? labelrhs(())
count[r]? count[r]+ wexample ?
?D(?)
?D(S)
L?? L? + log?D(S) ? wexample
for r ? R / / Maximize
do
wr?
count[r]
Zr(count)
// e.g., joint
Zr(c ) ?
?
r?=(qr,d,e,f )?R
c(r?),?r = (qr, ?, rhs,w) ? R
?? L
? ? L
|L?|
L? L?, i? i+ 1
end
409
Computational Linguistics Volume 34, Number 3
9. Extended Tree-to-String Transducers (xTs)
A weighted extended-lhs root-to-frontier tree-to-string transducer M is a quintuple
(?,?,Q,Qi,R) where ? is the input alphabet, ? is the output alphabet, Q is a finite
set of states, Qi ? Q is the initial (or start, or root) state, and R ? Q? xTPAT? ? (? ?
(Q? paths)) ? R+ is a finite set of weighted transformation rules, written q ??w rhs. A
rule says that to transform an input subtree matching ? while in state q, replace it by
the string of rhs with its nonterminal (Q? paths) letters replaced by their (recursive)
transformation.
xTs is the same as xT, except that the rhs are strings containing some nonterminals
instead of trees containing nonterminal leaves. By taking the yields of the rhs of an xT
transducer?s rules, we get an xTs that derives exactly the weighted strings that are the
yields of the weighted trees generated by its progenitor.
As discussed in Section 1, we may consider strings as isomorphic to degener-
ate, monadic-spined right-branching trees, for example, the string (a, b, c) is the tree
C(a,C(b,C(c,END))). Taking the yield of such a tree, but with END yielding the empty
string, we have the corresponding string. We choose this correspondence instead of flat
trees (e.g., C(a, b, c)) because our derivation steps proceed top-down, choosing the states
for all the children at once (what?s more, we don?t allow symbols C to have arbitrary
rank). If all the rhs of an xTs transducer are transformed into such trees, then we have
an xT transducer. The yields of that transducer?s output trees for any input are the
same as the outputs of the xTs transducer for the same input, but again, only if END is
considered to yield the empty string. Note that in general the produced output trees will
not have the canonical right-branching monadic spine that we use to encode strings,11 so
that yield-taking is a nontrivial operation. Finally, consider that for a given transducer,
the same output yield may be derived via many output trees, which may differ in the
number and location of END, and in the branching structure induced by multi-variable
rhs. Because this leads to additional difficulties in inferring the possible derivations
given an observed output string, we must study tree-to-string relations apart from tree
relations.
Just as wRTG can generate PCFG derivation trees, xTs can generate tree/string pairs
comparable to a Synchronous CFG (SCFG), with the tree being the CFG derivation tree
of the SCFG input string, with one caveat: an epsilon leaf symbol (we have used END)
must be introduced which must be excluded from yield-taking, after which the string-
to-string translations are identical.
We define the binary derivation relation on (? ? (Q? T?)) ? (N? R)? (strings of
output letters and state-labeled input trees and their derivation history)
?M?
{
((a, h), (b, h ? (i, (q, ?, rhs,w)))) | ?(q, ?, rhs,w) ? R, i ? indicesa :
a[i] = (q, I) ? Q? T? ?
?(I) = 1 ?
b = a
[
[i]? rhs
[
[p]? (q?, I ? i?),
?p ? indicesrhs : rhs[p] = (q?, i?) ? Q? paths
]]
}
11 In the special case that all rhs contain at most one variable, and that every variable appears in the final
position of its rhs, the output trees do, in fact, have the same canonical monadic-spined form. For these
transducers there is no meaningful difference between xTs and xT.
410
Graehl, Knight, and May Training Tree Transducers
where at position i, an input tree I (labeled by state q) in the string a is replaced by
a rhs from a rule that matches it. Of course, the variables (q?, i?) ? Q? paths in the rhs
get replaced by the appropriate pairing of (q?, I ? i?). Each rewrite flattens the string of
trees by breaking one of the trees into zero or more smaller trees, until (in a complete
derivation) only letters from the output alphabet ? remain. As with xT, rules may only
apply if the paths in them exist in the input (if i? ? pathsI), even if the tree pattern doesn?t
mention them.
Let??M, D(M), LD(M), wM,WM, and L(M) (the weighted tree-to-string relation ofM)
follow from the single-step?M exactly as they did in Section 4.12
10. Parsing an xTs Tree-to-String Relation
Derivation trees for an xTs transducer are defined by an analogous xT transducer,
exactly as they were for derivation trees for xT, where the nodes are labeled by rules
to be applied preorder, with the ith child rewriting the ith variable in the rhs of its parent
node.
Algorithm 4 (SDeriv) is the tree-to-string analog of Algorithm 1 (Deriv), building a
tree grammar that generates all the weighted derivation trees explaining an observed
input tree/output string pair for an xTs transducer.
SDeriv differs from Deriv in the use of arbitrary output string spans instead of
output subtrees. The looser alignment constraint causes additional complexity: There
areO(m2) spans of an observed output stringO of lengthm, and each binary production
over a span has O(m) ways of dividing the span in two (we also have the n different
input subtrees and q different rule states).
There is no way to fix in advance a tree structure over the training example and
transducer rule output strings without constraining the derivations to be consistent with
the bracketing. Another way to think of this is that any xTs derivation implies a specific
tree bracketing over the output string. In order to compute the derivations using the
tree-to-tree Deriv, we would have to take the union of forests for all the possible output
trees with the given output yield.
SDeriv takes time and space linear to the size of the output: O(Gnm3) where G
combines the states and rules into a single grammar constant, and n is the size of the
input tree. The reduced O(m2) space bound from 1-best CFG parsing does not apply,
because we want to keep all successful productions and split points, not only the best
for each item.
We use the presence of terminals in the right hand side of rules to constrain the
alignments of output subspans to nonterminals, giving us minimal-sized subproblems
tackled by VarsToSpan.
The canonicalization of same-substring spans is most obviously applicable to zero-
length spans (which become (1, 1), no matter where they arose), but in the worst case,
every input label and output letter is unique, so nothing further is gained. Canonical-
ization may also be applied to input subtrees. By canonicalizing, we effectively name
subtrees and substrings by value, instead of by path/span, increasing best-case sharing
and reducing the size of the output. In practice, we still use paths and spans, and hash
to a canonical representative if desired.
12 Because the locations in derivation histories are string indexes now rather than tree paths, we use the
usual < on naturals as the ordering constraint for leftmost derivations.
411
Computational Linguistics Volume 34, Number 3
Algorithm 4. SDeriv (derivation forest for I??xTs O)
Input: xTs transducerM = (?,?,Q,Qi,R), observed input tree I ? T?, and output
string O = (o1, . . . , on) ? ??
Output: derivation wRTG G = (R ? {},N ? N?,S,P) generating all weighted
derivation trees forM that produce O from I, with
N? ? ((Q? pathsI ? spansO)?
(pathsI ? spansO ? (Q? paths)
?)). Returns false instead if there are no such trees.
begin
S? (Qi, (), (1,n)), N? ?, P??,memo??
if PRODUCEI,O(S) then
N?{n | ?(n?, rhs,w) ? P : n = n? ? n ? yieldrhs(N
?)}
return G = (R ? {},N,S,P)
else
return false
end
PRODUCEI,O(? = (q ? Q, in ? pathsI, out = (a, b) ? spansO)) returns boolean ? begin
if ?(?, r) ? memo then return r
memo?memo ? {(?, true)}
anyrule?? false
for rule = (q, pat, rhs,w) ? R : pat(I ? in) = 1 ? FeasibleO(rhs, out) do
(r1, . . . , rk)? indicesrhs(?) in increasing order
/* k? 0 if there are none */
p0? a? 1, pk+1? b
r0? 0, rk+1?|rhs|+ 1
for p = (p1, . . . , pk) : (?1 ? i ? k : O[pi] = rhs[ri])?
(?0 ? i ? k : pk < pk+1 ? (rk+1 ? rk = 1 =? pk+1 ? pk = 1)) do
/* for all alignments p between rhs[ri] and O[pi], such that
order, beginning/end, and immediate adjacencies in rhs
are observed in O. The degenerate k = 0 has just p = ().
*/
labelderivrhs(())? (rule)
v? 0
for i? 0 to k do
/* variables rhs ? (ri + 1, ri+1) must generate O ? (pi + 1, pi+1)
*/
if ri + 1 = ri+1 then next i
v? v+ 1
spangen? (in, (pi + 1, pi+1), rhs ? (ri + 1, ri+1))
n?VarsToSpanI,O(spangen)
if n = false then next p
labelandrankderivrhs((v))? (n, 0)
anyrule?? true
rankderivrhs(()) = v
P?P ? {?, derivrhs,w)}
memo?memo ? {(?,anyrule?)}
return anyrule?
end
FeasibleO(rhs, span) ? ?l ? lettersrhs : l ? ? =? l ? lettersO?span
412
Graehl, Knight, and May Training Tree Transducers
Algorithm SDeriv (cont.) -labeled nodes are generated as artifacts of sharing by
cons-nonterminals of derivations for the same spans.
VarsToSpanI,O
(wholespan = (in ? pathsI, out = (a, b) ? spansO,nonterms ? (Q? paths)
?)) returns
N? ? {false} ?
/* Adds all the productions that can be used to map from parts of the
nonterminal string referring to subtrees of I ? in into O ? out and
returns the appropriate derivation-wRTG nonterminal if there was a
completely successful derivation, or false otherwise. */
begin
ret? false
if |nonterms| = 1 then
(q?, i?)? nonterms[1]
if PRODUCEI,O(q
?, in ? i?, out) then return (q?, in ? i?, out)
return false
wholespan? (in,CANONICALO(out),nonterms)
if ?(wholespan, r) ? memo then return r
for s? b to a do
/* the first nonterminal will cover the span (a,s) */
(q?, i?)? nonterms[1] /* nonterms will never be empty */
spanfirst? (q?, i ? i?, (a, s))
if ?PRODUCEI,O(spanfirst) then next s
labelspanlist(())? 
/* cons node for sharing; left child expands to rules used for this
nonterminal, right child expands to rest of nonterminal/span
derivation */
labelandrankspanlist((1))? (spanfirst, 0)
/* first child: expansions of first nonterminal */
rankspanlist(())? 2
spanrest? (in, (s, b),nonterms ? (2, |nonterms|+ 1))
/* second child: expansions of rest of nonterminals */
n?VarsToSpanI,O(spanrest)
if n = false then next s
labelandrankspanlist((2))? (n, 0)
P?P ? (wholespan, spanlist, 1)
ret?wholespan
memo?memo ? {(wholespan,ret)}
return ret
end
CANONICALO((a, b)) ? min{(x, y) | O ? (x, y) = O ? (a, b) ? x ? 1}
The enumeration of matching rules and alignments of terminals in the rule rhs to
positions in the output substring is best interleaved; the loops are nested for clarity
of presentation only. We use an FSA of subsequences of the output string (skipping
forward to a desired letter in constant time with an index on outgoing transitions), and
a trie of the rules? outputs (grouping by collapsing rhs variable sequences into a single
?skip? symbol), and intersect them, visiting alignments and sets of rules in the rule
413
Computational Linguistics Volume 34, Number 3
index. The choice of expansion sites against an input subtree proceeds by exhaustive
backtracking, since we want to enumerate all matching patterns. Each of these sets of
rules is further indexed against the input tree in a kind of leftmost trie.13 Feasible is
redundant in the presence of such indexing.
Static grammar analysis could also show that certain transducer states always (or
never) produce an empty string, or can only produce a certain subset of the terminal al-
phabet. Such proofs would be used to restrict the alignments considered in VarsToSpan.
We have modified the usual derivation tree structure to allow sharing the ways
an output span may align to a rhs substring of multiple consecutive variables; as a
consequence, we must create some non-rule-labeled nodes, labeled by  (with rank 2).
Train collects counts only for rule-labeled nodes, and the inside?outside weight compu-
tations proceed in ignorance of the labels, so we get the same sums and counts as if we
had non-binarized derivation trees. Instead of a consecutive rhs variable span of length
n generating n immediate rule-labeled siblings, it generates a single right-branching
binarized list of length n with each suffix generated from a (shared) nonterminal. As
in LISP, the left child is the first value in the list, and the right child is the (binarized)
rest of the list. As the base case, we have (n1,n2) as a list of two nonterminals (single
variable runs refer to their single nonterminal directly without any  wrapping; we use
no explicit null list terminator). Just as in CFG parsing, it would be necessary without
binarization to consider exponentially many productions, corresponding to choosing
an n-partition of the span length; the binarized nonterminals in our derivation RTG
effectively share the common suffixes of the partitions.
SDeriv could be restated in terms of parsing with a binarized set of rules, where
only some of the binary nonterminals have associated input trees; however, this would
complicate collecting counts for the original, unbinarized transducer rules.
If there are many cyclical state-change transitions (e.g., q x0 ? q? x0), a nearly
worst-case results for the memoized top-down recursive descent parsing of SDeriv,
because for every reachable alignment, nearly every state would apply (but after prun-
ing, the training proceeds optimally). An alternative bottom-up SDeriv would be better
suited in general to input-epsilon heavy transducers (where there is no tree structure
consumed to guide the top-down choice of rules). The worst-case time and space
bounds would be the same, but (output) lexical constraints would be used earlier.
The weighted derivation tree grammar produced by SDeriv may be used (after re-
moving useless productions with Algorithm 2) exactly as before to perform EM train-
ing with Train. In doing so, we generalize the standard inside?outside training of
probabilistic context-free grammar (PCFG) on raw text (Baker 1979). In Section 12,
we demonstrate this by creating an xTs transducer that transforms a fixed single-node
dummy tree to the strings of some arbitrary CFG, and train it on a corpus in which the
dummy input tree is paired with each training string as its output.
11. Translation Modeling Experiment
It is possible to cast many current probabilistic natural language models as T-type tree
transducers. In this section, we implement the translation model of Yamada and Knight
(2001) and train it using the EM algorithm.
13 To make a trie of complete tree patterns, represent them canonically as strings interleaving paths leftmost
for expansion, and labelandrank that must agree with the concurrent location in the input tree.
414
Graehl, Knight, and May Training Tree Transducers
Figure 6 shows a portion of the bilingual English-tree/Japanese-string corpus used
in Yamada and Knight (2001) and here. Figures 7 and 8 show the generative model and
parameters; the parameter values shown were learned via specialized EM re-estimation
formulae described in this article?s appendix. According to the model, an English tree
becomes a Japanese string in four steps.
First, every node is re-ordered, that is, its children are permuted probabilistically.
If there are three children, then there are six possible permutations whose probabilities
add up to 1. The re-ordering depends only on the child label sequence, and not on any
wider or deeper context. Note that the English trees in Figure 6 are already flattened in
pre-processing because the model cannot perform complex re-orderings such as the one
we described in Section 1, S(PRO,VP(V,NP))? V, PRO, NP.
Figure 6
A portion of a bilingual tree/string training corpus.
415
Computational Linguistics Volume 34, Number 3
Figure 7
The translation model of Yamada and Knight (2001).
Figure 8
The parameter tables of Yamada and Knight (2001).
Second, at every node, a decision is made about inserting a Japanese function word.
This is a three-way decision at each node?insert to the left, insert to the right, or do not
insert?and it depends on the labels of the node and its parent.
Third, English leaf words are translated probabilistically into Japanese, independent
of context.
Fourth, the internal nodes are removed, leaving only the Japanese string.
416
Graehl, Knight, and May Training Tree Transducers
This model effectively provides a formula for P(Japanese string | English tree) in
terms of individual parameters, and EM training seeks to maximize the product of these
conditional probabilities across the whole tree/string corpus.
We now build a trainable xTs tree-to-string transducer that embodies the same
P(Japanese string | English tree).
It is a four-state transducer. For the main state (and start state) q, meaning ?translate
this (sub)tree,? we have three rules:
q x0? i x0, r x0
q x0? r x0, i x0
q x0? r x0
State i means ?produce a Japanese function word out of thin air.? We include an i
rule for every Japanese word in the vocabulary:
i x0? ?de?
i x0? ?kuruma?
i x0? ?wa?
. . .
State r means ?re-order my children and then recurse.? For internal nodes, we
include a rule for every parent/child sequence and every permutation thereof:
r NN(x0:CD, x1:NN)? q x0, q x1
r NN(x0:CD, x1:NN)? q x1, q x0
. . .
The rhs sends the child subtrees back to state q for recursive processing. However,
for English leaf nodes, we instead transition to a different state t, so as to prohibit any
subsequent Japanese function word insertion:
r NN(x0:?car?)? t x0
r CC(x0:?and?)? t x0
. . .
State t means ?translate this word,? and we have a rule for every pair of co-
occurring English and Japanese words:
t ?car?? ?kuruma?
t ?car?? ?wa?
t ?car?? *e*
. . .
This follows Yamada and Knight (2001) in also allowing English words to disappear
(the rhs of the last rule is an empty string).
Every rule in the xTs transducer has an associated weight and corresponds to
exactly one of the model parameters.
The transducer just described, which we will subsequently call simple, is unfaithful
in one respect so far: The insert-function-word decision is independent of context,
whereas Yamada and Knight (2001) specifies it is conditioned on the node and parent
labels. We modify the simple transducer into a new exact transducer by replacing the q
417
Computational Linguistics Volume 34, Number 3
state with a set of states of the form q.parent, indicating the parent symbol of the current
node being processed. The start state then becomes q.TOP, and the q rules are rewritten
to specify the current node. Thus, every parent/child pair in the corpus gets its own set
of insert-function-word rules:
q.TOP x0:VB? i x0, r x0
q.TOP x0:VB? r x0, i x0
q.TOP x0:VB? r x0
q.VB x0:NN? i x0, r x0
q.VB x0:NN? r x0, i x0
q.VB x0:NN? r x0
. . .
The r rules now need to send parent information when they recurse to the q.parent
states:
r NN(x0:CD, x1:NN)? q.NN x0, q.NN x1
r NN(x0:CD, x1:NN)? q.NN x1, q.NN x0
. . .
The i and t rules stay the same.
This modification adds to our new transducer model all the contextual information
specified in Yamada and Knight (2001). However, upon closer inspection one can see
that the exact transducer is in fact overspecified in the reordering, or r rules. Yamada
and Knight only conditions reordering on the child sequence, thus, for example, the
reordering of JJ(JJ NN) is not distinct from the reordering of NN(JJ NN). As specified
in Train a separate parameter is estimated for each rule in the transducer. We thus
introduce rule tying to ensure the exact transducer is not misnamed. By designating
a set of transducer rules as tied we indicate that a single count collection and parameter
estimation is performed for the entire set during Train. We denote tied rules by marking
each rule in the same tied class with the symbol @ and a common integer. Thus the JJ(JJ
NN) and NN(JJ NN) reordering rules described previously are modified as follows:
r JJ(x0:JJ, x1:NN)? q.JJ x0, q.JJ x1 @ 1
r JJ(x0:JJ, x1:NN)? q.JJ x1, q.JJ x0 @ 2
r NN(x0:JJ, x1:NN)? q.NN x0, q.NN x1 @ 1
r NN(x0:JJ, x1:NN)? q.NN x1, q.NN x0 @ 2
All reordering rules with the same input and output variable sequence are in the
same tied class, and thus receive the same probability, independent of their parent
symbols. We consider the four-state transducer initially specified as our simple model,
and the modification that introduces parent-dependent q states and tied reordering
rules as the exact model, since it is a precise xTs transducer formulation of the model
of Yamada and Knight (2001).
As a means of providing empirical evidence of the utility of this approach, we
built both the simple and exact transducers and trained them using the EM algorithm
described in Section 7. We next compare the alignments and transition probabilities
achieved by generic tree transducer operations with the model-specific implementation
of Yamada and Knight (2001).
We obtained the corpus used as training data in Yamada and Knight (2001). This
corpus is a set of 2,060 Japanese/English sentence pairs from a dictionary, preprocessed
418
Graehl, Knight, and May Training Tree Transducers
Table 2
A comparison of the three transducer models used to simulate the model of Yamada and
Knight (2001).
model states initial rules rules after training time % link match % sent. match
training (hours)
simple 4 98,033 12,413 16.95 87.42 52.66
exact 28 98,513 12,689 17.42 96.58 81.46
perfect 29 186,649 24,492 53.19 99.85 99.47
as described in Yamada and Knight. There are on average 6.9 English words per sen-
tence and sentences range in size from 2 to 20 words. We built the simple and exact
unweighted transducers described above; Table 2 summarizes their initial sizes. The
exact model has 24 more states than the simple; this is due to the parent-dependent
modification to q. The 480 additional rules are due to insertion rules dependent on
parent and child information.
We then ran our training algorithm on the unweighted transducers and the training
corpus. Because the derivation tree grammars produced by SDeriv can be large and
time-intensive to compute, we calculated them once prior to training, saved them
to disk, and then read them at each iteration of the training algorithm.14 Following
Yamada and Knight (2001), we chose a normalization partition (Z in Train) such that
we obtain the probabilities of all the rules given their complete left hand side,15 and
set the Dirichlet prior counts uniformly to 0. We ran 20 iterations of the EM algorithm
using Train. The time to construct derivation forests and run 20 iterations of EM for
the various models is in Table 2. Note also the size of the transducers after training in
Table 2; a rule is considered to be no longer in the transducer if it is estimated to have
conditional probability 0.0001 or less.
Because we are trying to duplicate the training experiment of Yamada and Knight
(2001), we wish to compare the word-to-word alignments discovered by that work to
those discovered by ours. We recovered alignments from our trained transducers as
follows: For each tree/string pair we obtained the most likely sequence of rules that
derives the output string from an input tree, the Viterbi derivation. Figure 9 shows the
Viterbi derivation tree and rules for an example sentence. By following the sequence of
applied rules we can also determine which English words translate to which Japanese
words, and thus construct the Viterbi word alignment. We obtained the full set of align-
ments induced in Yamada and Knight and compared them to the alignments learned
from our transducers.
In Table 2 we report link match accuracy16 as well as sentence match accuracy.
The simple transducer is clearly only a rough approximation of the model of Yamada
and Knight (2001). The exact model is much closer, but the low percentage of exact
sentence matches is a concern. When comparing the parameter table values reported
by Yamada and Knight with our rule weights we see that the two systems learned
14 In all models the size on disk in native Java binary object format was about 2.7 GB.
15 Zr(c ) ?
?
r?=(qr ,?,e,f )?R c(r
? ),?r = (qr, ?, g, h) ? R.
16 As this model induces 1-to-1 word alignments, we report accuracy as the number of links matching those
reported by Yamada and Knight (2001) as a percentage of the total number of links.
419
Computational Linguistics Volume 34, Number 3
Figure 9
A Viterbi derivation tree and the referenced rules.
different probability distributions in multiple instances. A sample of these parameter
value differences can be seen in Figure 10.
In an effort to determine the reason for the discrepancy in weights between the
parameter values learned in our exact transducer representation of Yamada and Knight
(2001), we contacted the authors17 and learned that, unreported in the paper, the original
code contained a constraint that specifically bars an unaligned foreign word insertion
immediately prior to a NULL English word translation. We incorporate this change to
our model by simply modifying our transducer, rather than by changing our program-
ming code. The new transducer, which we call perfect, is a modification of the exact
transducer as follows.
We introduce an additional state s, denoting a translation taking place immediately
after an unaligned foreign function word insertion. We then introduce the following
additional rules.
For every rule that inserts a foreign function word, add an additional rule denoting
an insertion immediately before a translation, and tie these rules together, for example:
q.VB x0:NN? i x0, r x0 @ 23
q.VB x0:NN? i x0, s x0 @ 23
q.VB x0:NN? r x0, i x0 @ 24
q.VB x0:NN? s x0, i x0 @ 24
. . .
To allow subsequent translation, ?transition? rules for state s analogous to the
transition rules described previously must also be added, for example:
s NN(x0:?car?)? s x0
s CC(x0:?and?)? s x0
. . .
17 We are grateful to Kenji Yamada for providing full parameter tables and Viterbi alignments from the
original source.
420
Graehl, Knight, and May Training Tree Transducers
Figure 10
Rule probabilities corresponding to the parameter tables of Yamada and Knight (2001).
Finally, for each non-null translation rule, add an identical translation rule starting
with s instead of t, and tie these rules, for example:
t ?car?? ?kuruma? @ 54
t ?car?? ?wa? @ 55
t ?car?? *e*
s ?car?? ?kuruma? @ 54
s ?car?? ?wa? @ 55
. . .
Note that there is no corresponding null translation rule from state s; this is in
accordance with the insertion/NULL translation restriction.
As can be seen in Table 2 the Viterbi alignments learned from this ?perfect?
transducer are virtually identical to those reported in Yamada and Knight (2001). No
421
Computational Linguistics Volume 34, Number 3
rule probability in the learned transducer differs from its corresponding parameter
value in the original table by more than 0.000066. The 11 sentences with different
alignments, which account for 0.53% of the corpus, were due to two derivations
having the same probability; this was true in Yamada and Knight (2001) as well,
and the choice between equal-scoring derivations is arbitrary. Transducer rules that
correspond to the parameter tables presented in Figure 8 and a comparison of their
learned weights over the three models with the weight learned in Yamada and Knight
are in Figure 10. Note that the final perfect model matches the original parameter
tables perfectly, indicating we can reproduce complicated models with our transducer
formalism.
There are several benefits to this xTs formulation. First, it makes the model very
clear, in the same way that Knight and Al-Onaizan (1998) and Kumar and Byrne (2003)
elucidate other machine translation models in easily grasped FST terms. Second, the
model can be trained with generic, off-the-shelf tools?versus the alternative of working
out model-specific re-estimation formulae and implementing custom training software,
whose debugging is a significant engineering challenge. Third, we can easily extend the
model in interesting ways. For example, we can add rules for multi-level and lexical
re-ordering:
r NP(x0:NP, PP(IN(?of?), x1:NP))? q x1, ?no?, q x0
We can eschew pre-processing that flattens trees prior to training, and instead
incorporate flattening rules into the explicit model.
We can add rules for phrasal translations:
r NP(JJ(?big?), NN(?cars?))? ?ooki?, ?kuruma?
This can include non-constituent phrasal translations:
r S(NP(PRO(?there?)), VP(VB(?are?)), x0:NP)? q x0, ?ga?, ?arimasu?
Such non-constituent phrase pairs are commonly used in statistical machine translation
(Och, Tillmann, and Ney 1999; Marcu and Wong 2002) and are vital to accuracy (Koehn,
Och, and Marcu 2003). We can also eliminate many epsilon word-translation rules in
favor of more syntactically-controlled ones, for example:
r NP(DT(?the?), x0:NN)? q x0
Removing epsilons serves to reduce practical complexity in training and especially in
decoding (Yamada and Knight 2002).
We can make many such changes without modifying the training procedure, as long
as we stick to the tree automata.
The implementation of EM training we describe here is part of Tiburon, a generic
weighted tree automata toolkit described in May and Knight (2006) and available at
http://www.isi.edu/licensed-sw/tiburon/.
422
Graehl, Knight, and May Training Tree Transducers
12. PCFG Modeling Experiment
In this section, we demonstrate another application of the xTs training algorithm. We
show its generality by applying it to the standard task of training a probabilistic context-
free grammar (PCFG) on string examples. Consider the following grammar:
S? NP VP
NP? DT N
NP? NP PP
PP? P NP
VP? V NP
VP? V NP PP
DT? the N? the V? the P? the
DT? window N? window V? window P? window
DT? father N? father V? father P? father
DT? mother N? mother V? mother P? mother
DT? saw N? saw V? saw P? saw
DT? sees N? sees V? sees P? sees
DT? of N? of V? of P? of
DT? through N? through V? through P? through
Also consider the following observed string data:
the father saw the window
the father saw the mother through the window
the mother sees the father of the mother
We would like to assign probabilities to the grammar rules such that the probability of
the string data is maximized (Baker 1979; Lari and Young 1990). We can exploit the xTs
training algorithm by pretending that each string was probabilistically transduced from
a tree consisting of the single node ?. All we require is to transform the grammar into
an xTs transducer:
Start state: qs
qs x0? qnp x0, qvp x0
qnp x0?0.99 qdt x0, qn x0
qnp x0?0.01 qnp x0, qpp x0
qpp x0? qp x0, qnp x0
qvp x0?0.99 qv x0, qnp x0
qvp x0?0.01 qv x0, qnp x0, qpp x0
qdt ? ? the qn ? ? the qv ? ? the qp ? ? the
qdt ? ? window qn ? ? window qv ? ? window qp ? ? window
qdt ? ? father qn ? ? father qv ? ? father qp ? ? father
qdt ? ? mother qn ? ? mother qv ? ? mother qp ? ? mother
qdt ? ? saw qn ? ? saw qv ? ? saw qp ? ? saw
qdt ? ? sees qn ? ? sees qv ? ? sees qp ? ? sees
qdt ? ? of qn ? ? of qv ? ? of qp ? ? of
qdt ? ? through qn ? ? through qv ? ? through qp ? ? through
423
Computational Linguistics Volume 34, Number 3
We also transform the observed string data into tree/string pairs:
? ? the father saw the window
? ? the father saw the mother through the window
? ? the mother sees the father of the mother
After running the xTs training algorithm, we obtain maximum likelihood values for the
rules. For example, after one iteration, we find the following values for rules that realize
verbs:
qv ? ?0.11 of
qv ? ?0.11 through
qv ? ?0.22 sees
qv ? ?0.56 saw
After more iterations, values converge to:
qv ? ?0.33 sees
qv ? ?0.67 saw
Viterbi parses for the strings can also be obtained from the derivations forests computed
by the SDeriv procedure. We note that our use of xTs training relies on copying.18
13. Related and Future Work
Concrete xLNT transducers are similar to (weighted) Synchronous TSG (STSG). STSG,
like TSG, conflate tree labels with states, and so cannot reproduce all the relations in
L(xLNT) without a subsequent relabeling step, although in some versions the root labels
of the STSG rules? input and output trees are allowed to differ. Regular lookahead19 for
deleted input subtrees could be added explicitly to xT. Eisner (2003) briefly discusses
training for STSG. For bounded trees, xTs can be represented as an FST (Bangalore and
Riccardi 2002).
Our training algorithm is a generalization of forward?backward EM training
for finite-state (string) transducers, which is in turn a generalization of the origi-
nal forward?backward algorithm for Hidden Markov Models. Eisner (2002) describes
string-based training under different semirings, and Carmel (Graehl 1997) imple-
ments FST string-to-string training. In our tree-based training algorithm, inside?outside
weights replace forward?backward, and paths in trees replace positions in strings. Ex-
plicit construction and pruning of derivation trees saves time over many EM iterations,
and could accelerate string-to-string training as well.
Yamada and Knight (2001) give a training algorithm for a specific tree-to-string
machine translation model. Gildea (2003) introduces a variation of tree-to-tree mapping
that allows for cloning (copying a subtree into an arbitrary position elsewhere), in order
18 Curiously, these rules can have ?x0? in place of ???, because the training routine also supports deleting
transducers. Such a transducer would transform any input tree to the output PCFG.
19 Tree patterns ? of arbitrary regular tree languages, as described in Engelfriet (1977).
424
Graehl, Knight, and May Training Tree Transducers
to better robustly model the substantial tree transformations found in human language
translation data.
Using a similar approach to Deriv, exploiting the independence (except on state) of
input-subtree/output-subtree mappings, we can build wRTG for the xT derivation trees
matching an observed input tree (forward application), or matching an observed output
tree (backward application).20 For backward application through concrete transducers,
each derivation tree implies a unique input tree, except where deletion occurs (the
deleted input subtree could have been anything). For copying transducers, backward
application requires wRTG intersection in order to ensure that only input-subtree hy-
potheses possible for all their derived output subtrees are allowed. For noncopying
xTs transducers with complete tree patterns, backward application is just exhaustive
context-free grammar parsing, generating a wRTG production from the left-hand-side
of each xTs rule instance applied in parsing. Training and backward application algo-
rithms for xTs can be extended in the usual way to parse given finite-state output lattices
instead of single strings.21
14. Conclusion
We have motivated the use of tree transducers for natural language processing, and
presented algorithms for training them. The tree-input/tree-output algorithm runs in
O(Gn2) time and space, whereG is a grammar constant, n is the total size of the tree pair,
and the tree-input/string-output algorithm runs in O(Gnm3) time and space, where n is
the size of the input tree and m is the size of the output string. Training works in both
cases by building the derivation forest for each example, pruning it, and then (until
convergence) collecting fractional counts for rules from those forests and normalizing.
We have also presented an implementation and experimental results.
References
Aho, A. V. and J. D. Ullman. 1971.
Translations of a context-free grammar.
Information and Control, 19:439?475.
Alshawi, Hiyan, Srinivas Bangalore,
and Shona Douglas. 2000. Learning
dependency translation models as
collections of finite state head transducers.
Computational Linguistics, 26(1):45?60.
Baker, J. K. 1979. Trainable grammars
for speech recognition. In Speech
Communication Papers for the 97th Meeting
of the Acoustical Society of America,
pages 547?550, Boston, MA.
Bangalore, Srinivas and Owen Rambow.
2000. Exploiting a probabilistic hierarchical
model for generation. In International
Conference on Computational Linguistics
(COLING 2000), pages 42?48, Saarbrucken,
Germany.
Bangalore, Srinivas and Giuseppe Riccardi.
2002. Stochastic finite-state models for
spoken language machine translation.
Machine Translation, 17(3):165?184.
Baum, L. E. and J. A. Eagon. 1967. An
inequality with application to statistical
estimation for probabilistic functions
of Markov processes and to a model
for ecology. Bulletin of the American
Mathematicians Society, 73:360?363.
Charniak, Eugene. 2001. Immediate-head
parsing for language models. In
Proceedings of the 39th Annual Meeting
of the Association for Computational
Linguistics, pages 116?123, Tolouse,
France.
Chelba, C. and F. Jelinek. 2000. Structured
language modeling. Computer Speech and
Language, 14(4):283?332.
Collins, Michael. 1997. Three generative,
lexicalised models for statistical parsing.
In Proceedings of the 35th Annual Meeting
of the ACL (jointly with the 8th Conference
of the EACL), pages 16?23, Madrid, Spain.
20 In fact, forward and backward application can also be made to work on wRTG tree sets, with the result
still being a wRTG of possible derivations, except in the case of forward application with copying.
21 Instead of pairs of string indices, spans are pairs of lattice states.
425
Computational Linguistics Volume 34, Number 3
Comon, H., M. Dauchet, R. Gilleron,
F. Jacquemard, D. Lugiez, S. Tison,
and M. Tommasi. 1997. Tree automata
techniques and applications. Available at
http://www.grappa.univ-lille3.fr/tata.
Release of 12 October 2007.
Corston-Oliver, Simon, Michael Gamon,
Eric K. Ringger, and Robert Moore.
2002. An overview of Amalgam: A
machine-learned generation module.
In Proceedings of the International Natural
Language Generation Conference,
pages 33?40, New York.
Dempster, A. P., N. M. Laird, and D. B.
Rubin. 1977. Maximum likelihood from
incomplete data via the em algorithm.
Journal of the Royal Statistical Society,
Series B, 39(1):1?38.
Doner, J. 1970. Tree acceptors and some of
their applications. Journal of Computer and
System Sciences, 4:406?451.
Eisner, Jason. 2002. Parameter estimation for
probabilistic finite-state transducers. In
Proceedings of the 40th Annual Meeting of the
Association for Computational Linguistics
(ACL), pages 1?8, Philadelphia, PA.
Eisner, Jason. 2003. Learning non-isomorphic
tree mappings for machine translation. In
Proceedings of the 41st Annual Meeting of the
Association for Computational Linguistics
(companion volume), pages 205?208,
Sapporo, Japan.
Engelfriet, Joost. 1975. Bottom-up and
top-down tree transformations?a
comparison.Mathematical Systems
Theory, 9(3):198?231.
Engelfriet, Joost. 1977. Top-down tree
transducers with regular look-ahead.
Mathematical Systems Theory, 10:289?303.
Engelfriet, Joost, Zolt?n F?l?p, and Heiko
Vogler. 2004. Bottom-up and top-down
tree series transformations. Journal of
Automata, Languages and Combinatorics,
7(1):11?70.
F?l?p, Zolt?n and Heiko Vogler. 2004.
Weighted tree transducers. Journal of
Automata, Languages and Combinatorics,
9(1):31?54.
G?cseg, Ferenc and Magnus Steinby. 1984.
Tree Automata. Akad?miai Kiad?,
Budapest.
Gildea, Daniel. 2003. Loosely tree-based
alignment for machine translation. In
Proceedings of the 41st Annual Meeting of the
Association for Computational Linguistics,
pages 80?87, Sapporo, Japan.
Graehl, Jonathan. 1997. Carmel finite-state
toolkit. Available at http://www.isi.edu/
licensed-sw/carmel/.
Graehl, Jonathan and Kevin Knight. 2004.
Training tree transducers. In HLT-NAACL
2004: Main Proceedings, pages 105?112,
Boston, MA.
Hopcroft, John and Jeffrey Ullman. 1979.
Introduction to Automata Theory, Languages,
and Computation. Addison-Wesley Series
in Computer Science. Addison-Wesley,
London.
Joshi, Aravind and Yves Schabes. 1997.
Tree-adjoining grammars. In G. Rozenberg
and A. Salomaa, editors, Handbook of
Formal Languages, volume 3. Springer,
Berlin, pages 69?124.
Klein, Dan and Christopher D. Manning.
2003. Accurate unlexicalized parsing. In
Proceedings of the 41st Annual Meeting of the
Association for Computational Linguistics,
pages 423?430, Sapporo, Japan.
Knight, Kevin and Yaser Al-Onaizan. 1998.
Translation with finite-state devices. In
Proceedings of the 3rd Conference of the
Association for Machine Translation in
the Americas on Machine Translation
and the Information Soup (AMTA-98),
pages 421?437, Berlin.
Knight, Kevin and Daniel Marcu. 2002.
Summarization beyond sentence
extraction: A probabilistic approach
to sentence compression. Artificial
Intelligence, 139(1):91?107.
Koehn, Phillip, Franz Och, and Daniel
Marcu. 2003. Statistical phrase-based
translation. In HLT-NAACL 2003: Main
Proceedings, pages 127?133, Edmonton,
Alberta, Canada.
Kuich, Werner. 1999. Tree transducers and
formal tree series. Acta Cybernetica,
14:135?149.
Kumar, Shankar and William Byrne. 2003.
A weighted finite state transducer
implementation of the alignment template
model for statistical machine translation.
In HLT-NAACL 2003: Main Proceedings,
pages 142?149, Edmonton, Alberta,
Canada.
Langkilde, Irene. 2000. Forest-based
statistical sentence generation. In
Proceedings of the 6th Applied Natural
Language Processing Conference,
pages 170?177, Seattle, WA.
Langkilde, Irene and Kevin Knight. 1998.
Generation that exploits corpus-based
statistical knowledge. In Proceedings
of the Conference of the Association for
Computational Linguistics (COLING/ACL),
pages 704?710, Montreal, Canada.
Lari, K. and S. J. Young. 1990. The estimation
of stochastic context-free grammars using
426
Graehl, Knight, and May Training Tree Transducers
the inside?outside algorithm. Computer
Speech and Language, 4(1):35?56.
Marcu, Daniel and William Wong. 2002.
A phrase-based, joint probability
model for statistical machine translation.
In Proceedings of the Conference on
Empirical Methods in Natural Language
Processing (EMNLP), pages 133?139,
Philadelphia, PA.
May, Jonathan and Kevin Knight. 2006.
Tiburon: A weighted tree automata
toolkit. Implementation and Application of
Automata: 10th International Conference,
CIAA 2005, volume 4094 of Lecture
Notes in Computer Science, pages 102?113,
Taipei, Taiwan.
Nederhof, Mark-Jan and Giorgio Satta. 2002.
Parsing non-recursive CFGs. In Proceedings
of the 40th Annual Meeting of the Association
for Computational Linguistics (ACL),
pages 112?119, Philadelphia, PA.
Och, Franz, Christoph Tillmann, and
Hermann Ney. 1999. Improved alignment
models for statistical machine translation.
In Proceedings of the Joint Conference of
Empirical Methods in Natural Language
Processing and Very Large Corpora,
pages 20?28, College Park, MD.
Pang, Bo, Kevin Knight, and Daniel Marcu.
2003. Syntax-based alignment of multiple
translations extracting paraphrases and
generating new sentences. In HLT-NAACL
2003: Main Proceedings, pages 181?188,
Edmonton, Alberta, Canada.
Rounds, William C. 1970. Mappings and
grammars on trees.Mathematical Systems
Theory, 4(3):257?287.
Schabes, Yves. 1990.Mathematical and
Computational Aspects of Lexicalized
Grammars. Ph.D. thesis, Department of
Computer and Information Science,
University of Pennsylvania.
Thatcher, James W. 1970. Generalized2
sequential machine maps. Journal of
Computer and System Sciences, 4:339?367.
Viterbi, Andrew. 1967. Error bounds for
convolutional codes and an asymptotically
optimum decoding algorithm. IEEE
Transactions on Information Theory,
IT-13:260?269.
Wu, Dekai. 1997. Stochastic inversion
transduction grammars and bilingual
parsing of parallel corpora. Computational
Linguistics, 23(3):377?404.
Yamada, Kenji and Kevin Knight. 2001. A
syntax-based statistical translation model.
In Proceedings of the 39th Annual Meeting of
the Association for Computational Linguistics,
pages 523?530, Tolouse, France.
Yamada, Kenji and Kevin Knight. 2002. A
decoder for syntax-based statistical MT. In
Proceedings of the 40th Annual Meeting of the
Association for Computational Linguistics
(ACL), pages 303?310, Philadelphia, PA.
427

Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 351?358,
New York, June 2006. c?2006 Association for Computational Linguistics
A Better -Best List: Practical Determinization of Weighted Finite Tree
Automata
Jonathan May
Information Sciences Institute
University of Southern California
Marina del Rey, CA 90292
jonmay@isi.edu
Kevin Knight
Information Sciences Institute
University of Southern California
Marina del Rey, CA 90292
knight@isi.edu
Abstract
Ranked lists of output trees from syn-
tactic statistical NLP applications fre-
quently contain multiple repeated entries.
This redundancy leads to misrepresenta-
tion of tree weight and reduced informa-
tion for debugging and tuning purposes.
It is chiefly due to nondeterminism in the
weighted automata that produce the re-
sults. We introduce an algorithm that de-
terminizes such automata while preserv-
ing proper weights, returning the sum of
the weight of all multiply derived trees.
We also demonstrate our algorithm?s ef-
fectiveness on two large-scale tasks.
1 Introduction
A useful tool in natural language processing tasks
such as translation, speech recognition, parsing, etc.,
is the ranked list of results. Modern systems typ-
ically produce competing partial results internally
and return only the top-scoring complete result to
the user. They are, however, also capable of pro-
ducing lists of runners-up, and such lists have many
practical uses:
The lists may be inspected to determine
the quality of runners-up and motivate
model changes.
The lists may be re-ranked with extra
knowledge sources that are difficult to ap-
ply during the main search.
The lists may be used with annotation and
a tuning process, such as in (Collins and
Roark, 2004), to iteratively alter feature
weights and improve results.
Figure 1 shows the best 10 English translation
parse trees obtained from a syntax-based translation
system based on (Galley, et. al., 2004). Notice
that the same tree occurs multiple times in this list.
This repetition is quite characteristic of the output of
ranked lists. It occurs because many systems, such
as the ones proposed by (Bod, 1992), (Galley, et. al.,
2004), and (Langkilde and Knight, 1998) represent
their result space in terms of weighted partial results
of various sizes that may be assembled in multiple
ways. There is in general more than one way to as-
semble the partial results to derive the same com-
plete result. Thus, the -best list of results is really
an -best list of derivations.
When list-based tasks, such as the ones mentioned
above, take as input the top results for some con-
stant , the effect of repetition on these tasks is dele-
terious. A list with many repetitions suffers from a
lack of useful information, hampering diagnostics.
Repeated results prevent alternatives that would be
highly ranked in a secondary reranking system from
even being considered. And a list of fewer unique
trees than expected can cause overfitting when this
list is used to tune. Furthermore, the actual weight of
obtaining any particular tree is split among its repeti-
tions, distorting the actual relative weights between
trees.
(Mohri, 1997) encountered this problem in speech
recognition, and presented a solution to the prob-
lem of repetition in -best lists of strings that are
derived from finite-state automata. That work de-
scribed a way to use a powerset construction along
351
34.73: S(NP-C(NPB(DT(this) NNS(cases))) VP(VBD(had) VP-C(VBN(caused) NP-C(NPB(DT(the) JJ(american) NNS(protests))))) .(.))
34.74: S(NP-C(NPB(DT(this) NNS(cases))) VP(VBD(had) VP-C(VBN(aroused) NP-C(NPB(DT(the) JJ(american) NNS(protests))))) .(.))
34.83: S(NP-C(NPB(DT(this) NNS(cases))) VP(VBD(had) VP-C(VBN(caused) NP-C(NPB(DT(the) JJ(american) NNS(protests))))) .(.))
34.83: S(NP-C(NPB(DT(this) NNS(cases))) VP(VBD(had) VP-C(VBN(aroused) NP-C(NPB(DT(the) JJ(american) NNS(protests))))) .(.))
34.84: S(NP-C(NPB(DT(this) NNS(cases))) VP(VBD(had) VP-C(VBN(caused) NP-C(NPB(DT(the) JJ(american) NNS(protests))))) .(.))
34.85: S(NP-C(NPB(DT(this) NNS(cases))) VP(VBD(had) VP-C(VBN(caused) NP-C(NPB(DT(the) JJ(american) NNS(protests))))) .(.))
34.85: S(NP-C(NPB(DT(this) NNS(cases))) VP(VBD(had) VP-C(VBN(aroused) NP-C(NPB(DT(the) JJ(american) NNS(protests))))) .(.))
34.85: S(NP-C(NPB(DT(this) NNS(cases))) VP(VBD(had) VP-C(VBN(aroused) NP-C(NPB(DT(the) JJ(american) NNS(protests))))) .(.))
34.87: S(NP-C(NPB(DT(this) NNS(cases))) VP(VBD(had) VP-C(VB(arouse) NP-C(NPB(DT(the) JJ(american) NNS(protests))))) .(.))
34.92: S(NP-C(NPB(DT(this) NNS(cases))) VP(VBD(had) VP-C(VBN(aroused) NP-C(NPB(DT(the) JJ(american) NNS(protests))))) .(.))
Figure 1: Ranked list of machine translation results with repeated trees. Scores shown are negative logs of
calculated weights, thus a lower score indicates a higher weight. The bulleted sentences indicate identical
trees.
with an innovative bookkeeping system to deter-
minize the automaton, resulting in an automaton that
preserves the language but provides a single, prop-
erly weighted derivation for each string in it. Put an-
other way, if the input automaton has the ability to
generate the same string with different weights, the
output automaton generates that string with weight
equal to the sum of all of the generations of that
string in the input automaton. In (Mohri and Riley,
2002) this technique was combined with a procedure
for efficiently obtaining -best ranked lists, yielding
a list of string results with no repetition.
In this paper we extend that work to deal with
grammars that produce trees. Regular tree gram-
mars (Brainerd, 1969), which subsume the tree sub-
stitution grammars developed in the NLP commu-
nity (Schabes, 1990), are of particular interest to
those wishing to work with additional levels of
structure that string grammars cannot provide. The
application to parsing is natural, and in machine
translation tree grammars can be used to model
syntactic transfer, control of function words, re-
ordering, and target-language well-formedness. In
the world of automata these grammars have as a nat-
ural dual the finite tree recognizer (Doner, 1970).
Like tree grammars and packed forests, they are
compact ways of representing very large sets of
trees. We will present an algorithm for determiniz-
ing weighted finite tree recognizers, and use a vari-
ant of the procedure found in (Huang and Chiang,
2005) to obtain -best lists of trees that are weighted
correctly and contain no repetition.
Section 2 describes related work. In Section 3, we
introduce the formalisms of tree automata, specifi-
cally the tree-to-weight transducer. In Section 4, we
present the algorithm. Finally, in Section 5 we show
the results of applying weighted determinization to
recognizers obtained from the packed forest output
of two natural language tasks.
2 Previous Work
The formalisms of tree automata are summarized
well in (Gecseg and Steinby, 1984). Bottom-up
tree recognizers are due to (Thatcher and Wright,
1968), (Doner, 1970), and (Magidor and Moran,
1969). Top-down tree recognizers are due to (Rabin,
1969) and (Magidor and Moran, 1969). (Comon, et.
al., 1997) show the determinization of unweighted
finite-state tree automata, and prove its correctness.
(Borchardt and Vogler, 2003) present determiniza-
tion of weighted finite-state tree automata with a dif-
ferent method than the one we present here. While
our method is applicable to finite tree sets, the previ-
ous method claims the ability to determinize some
classes of infinite tree sets. However, for the fi-
nite case the previous method produces an automa-
ton with size on the order of the number of deriva-
tions, so the technique is limited when applied to
real world data.
3 Grammars, Recognizers, and
Transducers
As described in (Gecseg and Steinby, 1984), tree au-
tomata may be broken into two classes, recognizers
and transducers. Recognizers read tree input and de-
cide whether the input is in the language represented
by the recognizer. Formally, a bottom-up tree recog-
nizer is defined by :1
is a finite set of states,
1Readers familiar with (Gecseg and Steinby, 1984) will no-
tice that we have introduced a start state, modified the notion of
initial assignment, and changed the arity of nullary symbols to
unary symbols. This is to make tree automata more palatable to
those accustomed to string automata and to allow for a useful
graphical interpretation.
352
Figure 2: Visualization of a bottom-up tree recog-
nizer
is a ranked alphabet,
is the initial state,
is a set of final states, and
is a finite set
of transitions from a vector of states to
one state that reads a -ary symbol.
Consider the following tree recognizer:
2
As with string automata, it is helpful to have a vi-
sualization to understand what the recognizer is rec-
ognizing. Figure 2 provides a visualization of the
recognizer above. Notice that some members of
are drawn as arcs with multiple (and ordered) tails.
This is the key difference in visualization between
string and tree automata ? to capture the arity of the
symbol being read we must visualize the automata
as an ordered hypergraph.
The function of the members of in the hyper-
graph visualization leads us to refer to the vector of
states as an input vector of states, and the single
state as an output state. We will refer to as the
transition set of the recognizer.
In string automata, a path through a recognizer
consists of a sequence of edges that can be followed
from a start to an end state. The concatenation of la-
bels of the edges of a path, typically in a left-to-right
order, forms a string in the recognizer?s language.
In tree automata, however, a hyperpath through a
recognizer consists of a sequence of hyperedges that
can be followed, sometimes in parallel, from a start
2The number denotes the arity of the symbol.
Figure 3: Bottom-up tree-to-weight transducer
to an end state. We arrange the labels of the hy-
peredges to form a tree in the recognizer?s language
but must now consider proper order in two dimen-
sions. The proper vertical order is specified by the
order of application of transitions, i.e., the labels of
transitions followed earlier are placed lower in the
tree than the labels of transitions followed later. The
proper horizontal order within one level of the tree is
specified by the order of states in a transition?s input
vector. In the example recognizer, the trees
and are valid. Notice that may be
recognized in two different hyperpaths.
Like tree recognizers, tree transducers read tree
input and decide whether the input is in the lan-
guage, but they simultaneously produce some out-
put as well. Since we wish to associate a weight
with every acceptable tree in a language, we will
consider transducers that produce weights as their
output. Note that in transitioning from recognizers
to transducers we are following the convention es-
tablished in (Mohri, 1997) where a transducer with
weight outputs is used to represent a weighted rec-
ognizer. One may consider the determinization of
tree-to-weight transducers as equivalent to the de-
terminization of weighted tree recognizers.
Formally, a bottom-up tree-to-weight transducer
is defined by where ,
, , and are defined as for recognizers, and:
is a
finite set of transitions from a vector of
states to one state, reading a -ary symbol
and outputting some weight
is the initial weight function mapping
to
is the final weight function mapping
353
to .
We must also specify a convention for propagat-
ing the weight calculated in every transition. This
can be explicitly defined for each transition but we
will simplify matters by defining the propagation of
the weight to a destination state as the multiplication
of the weight at each source state with the weight of
the production.
We modify the previous example by adding
weights as follows: As an example, consider the fol-
lowing tree-to-weight transducer ( , , , and are
as before):
Figure 3 shows the addition of weights onto the
automata, forming the above transducer. Notice the
tree yields the weight 0.036 (
), and yields the weight 0.012 (
) or 0.054 ( ), depending on
the hyperpath followed.
This transducer is an example of a nonsubsequen-
tial transducer. A tree transducer is subsequential if
for each vector v of states and each there
is at most one transition in with input vector v and
label . These restrictions ensure a subsequential
transducer yields a single output for each possible
input, that is, it is deterministic in its output.
Because we will reason about the destination state
of a transducer transition and the weight of a trans-
ducer transition separately, we make the following
definition. For a given v where
v is a vector of states, , , and
, let v and v . Equiva-
lent shorthand forms are and .
4 Determinization
The determinization algorithm is presented as Algo-
rithm 1. It takes as input a bottom-up tree-to-weight
transducer and returns as output a subsequential
bottom-up tree-to-weight transducer such that the
tree language recognized by is equivalent to that
of and the output weight given input tree on is
equal to the sum of all possible output weights given
on . Like the algorithm of (Mohri, 1997), this
Figure 4: a) Portion of a transducer before deter-
minization; b) The same portion after determiniza-
tion
algorithm will terminate for automata that recognize
finite tree languages. It may terminate on some au-
tomata that recognize infinite tree languages, but we
do not consider any of these cases in this work.
Determinizing a tree-to-weight transducer can be
thought of as a two-stage process. First, the structure
of the automata must be determined such that a sin-
gle hyperpath exists for each recognized input tree.
This is achieved by a classic powerset construction,
i.e., a state must be constructed in the output trans-
ducer that represents all the possible reachable desti-
nation states given an input and a label. Because we
are working with tree automata, our input is a vector
of states, not a single state. A comparable power-
set construction on unweighted tree automata and a
proof of correctness can be found in (Comon, et. al.,
1997).
The second consideration to weighted deter-
minization is proper propagation of weights. For this
we will use (Mohri, 1997)?s concept of the residual
weight. We represent in the construction of states
in the output transducer not only a subset of states
of the input transducer, but also a number associated
with each of these states, called the residual. Since
we want ?s hyperpath of a particular input tree to
have as its associated weight the sum of the weights
of the all of ?s hyperpaths of the input tree, we re-
place a set of hyperedges in that have the same
input state vector and label with a single hyperedge
in bearing the label and the sum of ?s hyper-
edge weights. The destination state of the hyper-
edge represents the states reachable by ?s applica-
ble hyperedges and for each state, the proportion of
the weight from the relevant transition.
Figure 4 shows the determinization of a portion
of the example transducer. Note that the hyperedge
354
Figure 5: Determinized bottom-up tree-to-weight
transducer
leading to state in the input transducer contributes
of the weight on the output transducer hyperedge
and the hyperedge leading to state in the input
transducer contributes the remaining . This is re-
flected in the state construction in the output trans-
ducer. The complete determinization of the example
transducer is shown in Figure 5.
To encapsulate the representation of states from
the input transducer and associated residual weights,
we define a state in the output transducer as a set of
tuples, where and . Since
the algorithm builds new states progressively, we
will need to represent a vector of states from the
output transducer, typically depicted as v. We may
construct the vector pair q w from v, where q is
a vector of states of the input transducer and w is
a vector of residual weights, by choosing a (state,
weight) pair from each output state in v. For ex-
ample, let . Then two possible out-
put transducer states could be and
. If we choose v then a
valid vector pair q w is q , w .
The sets v , v , and v are defined
as follows:
v q w from v
q .
v q w from v
q .
v q w from v
q .
.
v is the set of vector pairs q w con-
structed from v where each q is an input vector in
a transition with label . v is the set of
unique transitions paired with the appropriate pair
for each q w in v . v is the set of states
reachable from the transitions in v .
The consideration of vectors of states on the in-
cident edge of transitions effects two noticeable
changes on the algorithm as it is presented in
(Mohri, 1997). The first, relatively trivial, change
is the inclusion of the residual of multiple states in
the calculation of weights and residuals on lines 16
and 17. The second change is the production of
vectors for consideration. Whereas the string-based
algorithm considered newly-created states in turn,
we must consider newly-available vectors. For each
newly created state, newly available vectors can be
formed by using that state with the other states of
the output transducer. This operation is performed
on lines 7 and 22 of the algorithm.
5 Empirical Studies
We now turn to some empirical studies. We examine
the practical impact of the presented work by show-
ing:
That the multiple derivation problem is
pervasive in practice and determinization
is effective at removing duplicate trees.
That duplication causes misleading
weighting of individual trees and the
summing achieved from weighted deter-
minization corrects this error, leading to
re-ordering of the -best list.
That weighted determinization positively
affects end-to-end system performance.
We also compare our results to a commonly used
technique for estimation of -best lists, i.e., sum-
ming over the top derivations to get weight
estimates of the top unique elements.
5.1 Machine translation
We obtain packed-forest English outputs from 116
short Chinese sentences computed by a string-to-
tree machine translation system based on (Galley,
et. al., 2004). The system is trained on all Chinese-
English parallel data available from the Linguistic
Data Consortium. The decoder for this system is a
CKY algorithm that negotiates the space described
in (DeNeefe, et. al., 2005). No language model was
used in this experiment.
The forests contain a median of En-
glish parse trees each. We remove cycles from each
355
Algorithm 1: Weighted Determinization of Tree Automata
Input: BOTTOM-UP TREE-TO-WEIGHT TRANSDUCER .
Output: SUBSEQUENTIAL BOTTOM-UP TREE-TO-WEIGHT TRANSDUCER .
begin1
2
3
PRIORITY QUEUE4
5
6
ENQUEUE7
while do8
v head9
v10
for each v such that do11
if such that then12
s.t.13
14
for each such that v do15
v
v16
v
v
v
v s.t.17
v v v18
/* RANK returns the largest hyperedge size that can leave state .
COMBINATIONS returns all possible vectors of length
containing members of and at least one member of . */
if v is a new state then19
for each u COMBINATIONS v
v
RANK do
20
if u is a new vector then21
ENQUEUE u22
v23
DEQUEUE24
end25
forest,3 apply our determinization algorithm, and ex-
tract the -best trees using a variant of (Huang and
Chiang, 2005). The effects of weighted determiniza-
tion on an -best list are obvious to casual inspec-
tion. Figure 7 shows the improvement in quality of
the top 10 trees from our example translation after
the application of the determinization algorithm.
The improvement observed circumstantially
holds up to quantitative analysis as well. The
forests obtained by the determinized grammars have
between 1.39% and 50% of the number of trees of
their undeterminized counterparts. On average, the
determinized forests contain 13.7% of the original
3As in (Mohri, 1997), determinization may be applicable to
some automata that recognize infinite languages. In practice,
cycles in tree automata of MT results are almost never desired,
since these represent recursive insertion of words.
number of trees. Since a determinized forest con-
tains no repeated trees but contains exactly the same
unique trees as its undeterminized counterpart, this
indicates that an average of 86.3% of the trees in an
undeterminized MT output forest are duplicates.
Weighted determinization also causes a surpris-
ingly large amount of -best reordering. In 77.6%
of the translations, the tree regarded as ?best? is
different after determinization. This means that in
a large majority of cases, the tree with the high-
est weight is not recognized as such in the undeter-
minized list because its weight is divided among its
multiple derivations. Determinization allows these
instances and their associated weights to combine
and puts the highest weighted tree, not the highest
weighted derivation, at the top of the list.
356
method Bleu
undeterminized 21.87
top-500 ?crunching? 23.33
determinized 24.17
Figure 6: Bleu results from string-to-tree machine
translation of 116 short Chinese sentences with no
language model. The use of best derivation (unde-
terminized), estimate of best tree (top-500), and true
best tree (determinized) for selection of translation
is shown.
We can compare our method with the more com-
monly used methods of ?crunching? -best lists,
where . The duplicate sentences in the
trees are combined, hopefully resulting in at least
unique members with an estimation of the true
tree weight for each unique tree. Our results indi-
cate this is a rather crude estimation. When the top
500 derivations of the translations of our test cor-
pus are summed, only 50.6% of them yield an esti-
mated highest-weighted tree that is the same as the
true highest-weighted tree.
As a measure of the effect weighted determiniza-
tion and its consequential re-ordering has on an ac-
tual end-to-end evaluation, we obtain Bleu scores
for our 1-best translations from determinization, and
compare them with the 1-best translations from the
undeterminized forest and the 1-best translations
from the top-500 ?crunching? method. The results
are tabulated in Figure 6. Note that in 26.7% of
cases determinization did not terminate in a reason-
able amount of time. For these sentences we used
the best parse from top-500 estimation instead. It is
not surprising that determinization may occasionally
take a long time; even for a language of monadic
trees (i.e. strings) the determinization algorithm is
NP-complete, as implied by (Casacuberta and de la
Higuera, 2000) and, e.g. (Dijkstra, 1959).
5.2 Data-Oriented Parsing
Weighted determinization of tree automata is also
useful for parsing. Data-Oriented Parsing (DOP)?s
methodology is to calculate weighted derivations,
but as noted in (Bod, 2003), it is the highest ranking
parse, not derivation, that is desired. Since (Sima?an,
1996) showed that finding the highest ranking parse
is an NP-complete problem, it has been common to
estimate the highest ranking parse by the previously
method Recall Precision F-measure
undeterminized 80.23 80.18 80.20
top-500 ?crunching? 80.48 80.29 80.39
determinized 81.09 79.72 80.40
Figure 8: Recall, precision, and F-measure results
on DOP-style parsing of section 23 of the Penn Tree-
bank. The use of best derivation (undeterminized),
estimate of best tree (top-500), and true best tree (de-
terminized) for selection of parse output is shown.
described ?crunching? method.
We create a DOP-like parsing model4 by extract-
ing and weighting a subset of subtrees from sec-
tions 2-21 of the Penn Treebank and use a DOP-
style parser to generate packed forest representa-
tions of parses of the 2416 sentences of section 23.
The forests contain a median of parse
trees. We then remove cycles and apply weighted
determinization to the forests. The number of trees
in each determinized parse forest is reduced by a
factor of between 2.1 and . On aver-
age, the number of trees is reduced by a factor of
900,000, demonstrating a much larger number of du-
plicate parses prior to determinization than in the
machine translation experiment. The top-scoring
parse after determinization is different from the top-
scoring parse before determinization for 49.1% of
the forests, and when the determinization method
is ?approximated? by crunching the top-500 parses
from the undeterminized list only 55.9% of the top-
scoring parses are the same, indicating the crunch-
ing method is not a very good approximation of
determinization. We use the standard F-measure
combination of recall and precision to score the
top-scoring parse in each method against reference
parses. The results are tabulated in Figure 8. Note
that in 16.9% of cases determinization did not ter-
minate. For those sentences we used the best parse
from top-500 estimation instead.
6 Conclusion
We have shown that weighted determinization is
useful for recovering -best unique trees from a
weighted forest. As summarized in Figure 9, the
4This parser acquires a small subset of subtrees, in contrast
with DOP, and the beam search for this problem has not been
optimized.
357
31.87: S(NP-C(NPB(DT(this) NNS(cases))) VP(VBD(had) VP-C(VBN(aroused) NP-C(NPB(DT(the) JJ(american) NNS(protests))))) .(.))
32.11: S(NP-C(NPB(DT(this) NNS(cases))) VP(VBD(had) VP-C(VBN(caused) NP-C(NPB(DT(the) JJ(american) NNS(protests))))) .(.))
32.15: S(NP-C(NPB(DT(this) NNS(cases))) VP(VBD(had) VP-C(VB(arouse) NP-C(NPB(DT(the) JJ(american) NNS(protests))))) .(.))
32.55: S(NP-C(NPB(DT(this) NNS(cases))) VP(VBD(had) VP-C(VB(cause) NP-C(NPB(DT(the) JJ(american) NNS(protests))))) .(.))
32.60: S(NP-C(NPB(DT(this) NNS(cases))) VP(VBD(had) VP-C(VBN(attracted) NP-C(NPB(DT(the) JJ(american) NNS(protests))))) .(.))
33.16: S(NP-C(NPB(DT(this) NNS(cases))) VP(VBD(had) VP-C(VB(provoke) NP-C(NPB(DT(the) JJ(american) NNS(protests))))) .(.))
33.27: S(NP-C(NPB(DT(this) NNS(cases))) VP(VBG(causing) NP-C(NPB(DT(the) JJ(american) NNS(protests)))) .(.))
33.29: S(NP-C(NPB(DT(this) NN(case))) VP(VBD(had) VP-C(VBN(aroused) NP-C(NPB(DT(the) JJ(american) NNS(protests))))) .(.))
33.31: S(NP-C(NPB(DT(this) NNS(cases))) VP(VBD(had) VP-C(VBN(aroused) NP-C(NPB(DT(the) NN(protest)) PP(IN(of) NP-C(NPB(DT(the)
NNS(united states))))))) .(.))
33.33: S(NP-C(NPB(DT(this) NNS(cases))) VP(VBD(had) VP-C(VBN(incurred) NP-C(NPB(DT(the) JJ(american) NNS(protests))))) .(.))
Figure 7: Ranked list of machine translation results with no repeated trees.
experiment undeterminized determinized
machine translation
parsing
Figure 9: Median trees per sentence forest in ma-
chine translation and parsing experiments before and
after determinization is applied to the forests, re-
moving duplicate trees.
number of repeated trees prior to determinization
was typically very large, and thus determinization is
critical to recovering true tree weight. We have im-
proved evaluation scores by incorporating the pre-
sented algorithm into our MT work and we believe
that other NLP researchers working with trees can
similarly benefit from this algorithm.
Further advances in determinization will provide
additional benefit to the community. The transla-
tion system detailed here is a string-to-tree system,
and the determinization algorithm returns the -best
unique trees from a packed forest. Users of MT sys-
tems are generally interested in the string yield of
those trees, and not the trees per se. Thus, an algo-
rithm that can return the -best unique strings from
a packed forest would be a useful extension.
We plan for our weighted determinization algo-
rithm to be one component in a generally available
tree automata package for intersection, composition,
training, recognition, and generation of weighted
and unweighted tree automata for research tasks
such as the ones described above.
Acknowledgments
We thank Liang Huang for fruitful discussions
which aided in this work and David Chiang, Daniel
Marcu, and Steve DeNeefe for reading an early draft
and providing useful comments. This work was sup-
ported by NSF grant IIS-0428020.
References
Rens Bod. 1992. A Computational model of language perfor-
mance: data oriented parsing. In Proc. COLING
Rens Bod. 2003. An efficient implementation of a new DOP
model. In Proc. EACL,
Bjo?rn Borchardt and Heiko Vogler. 2003. Determinization of
finite state weighted tree automata. Journal of Automata,
Languages and Combinatorics, 8(3).
W. S. Brainerd. 1969. Tree generating regular systems. Infor-
mation and Control, 14.
F. Casacuberta and C. de la Higuera. 2000. Computa-
tional complexity of problems on probabilistic grammars
and transducers. In Proc. ICGI.
Michael Collins and Brian Roark. 2004. Incremental parsing
with the perceptron algorithm. In Proc. ACL.
H. Comon and M. Dauchet and R. Gilleron and F. Jacquemard
and D. Lugiez and S. Tison and M. Tommasi. 1997 Tree
Automata Techniques and Applications.
S. DeNeefe and K. Knight and H. Chan. 2005. Interactively
exploring a machine translation model. Poster in Proc. ACL.
Edsger W. Dijkstra 1959. A note on two problems in connexion
with graphs Numerische Mathematik, 1.
J. E. Doner 1970. Tree acceptors and some of their applications
J. Comput. System Sci., 4.
M. Galley and M. Hopkins and K. Knight and D. Marcu. 2004.
What?s in a translation rule? In Proc. HLT-NAACL.
Ferenc Ge?cseg and Magnus Steinby 1984. Tree Automata.
Akade?miai Kiado?, Budapest.
Liang Huang and David Chiang 2005. Better k-best parsing In
Proc. IWPT.
Irene Langkilde and Kevin Knight 1998 The Practical Value of
N-Grams in Generation In Proc. INLG.
M. Magidor and G. Moran. 1969. Finite automata over finite
trees Technical Report 30. Hebrew University, Jerusalem.
Mehryar Mohri. 1997. Finite-state transducers in language and
speech processing. Computational Linguistics, 23(2).
Mehryar Mohri and Michael Riley. 2002. An efficient algo-
rithm for the -best strings problem. In Proc. ICSLP.
M. O. Rabin. 1969. Decidability of second-order theories and
automata on infinite trees. Trans. Amer. Math. Soc., 141.
Yves Schabes. 1990. Mathematical and computational aspects
of lexicalized grammars. Ph.D. thesis. University of Penn-
sylvania, Philadelphia, PA.
Khalil Sima?an. 1996. Computational complexity of proba-
bilistic disambiguation by means of tree-grammars. In Proc.
COLING.
J. W. Thatcher and J. B. Wright. 1968. Generalized finite au-
tomata theory with an application to a decision problem of
second order logic. Mathematical Systems Theory, 2.
358
Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1352?1362,
Edinburgh, Scotland, UK, July 27?31, 2011. c?2011 Association for Computational Linguistics
Tuning as Ranking
Mark Hopkins and Jonathan May
SDL Language Weaver
Los Angeles, CA 90045
{mhopkins,jmay}@sdl.com
Abstract
We offer a simple, effective, and scalable
method for statistical machine translation pa-
rameter tuning based on the pairwise approach
to ranking (Herbrich et al, 1999). Unlike
the popular MERT algorithm (Och, 2003), our
pairwise ranking optimization (PRO) method
is not limited to a handful of parameters and
can easily handle systems with thousands of
features. Moreover, unlike recent approaches
built upon the MIRA algorithm of Crammer
and Singer (2003) (Watanabe et al, 2007; Chi-
ang et al, 2008b), PRO is easy to imple-
ment. It uses off-the-shelf linear binary classi-
fier software and can be built on top of an ex-
isting MERT framework in a matter of hours.
We establish PRO?s scalability and effective-
ness by comparing it to MERT and MIRA and
demonstrate parity on both phrase-based and
syntax-based systems in a variety of language
pairs, using large scale data scenarios.
1 Introduction
The MERT algorithm (Och, 2003) is currently the
most popular way to tune the parameters of a sta-
tistical machine translation (MT) system. MERT
is well-understood, easy to implement, and runs
quickly, but can behave erratically and does not scale
beyond a handful of features. This lack of scalability
is a significant weakness, as it inhibits systems from
using more than a couple dozen features to discrimi-
nate between candidate translations and stymies fea-
ture development innovation.
Several researchers have attempted to address
this weakness. Recently, Watanabe et al (2007)
and Chiang et al (2008b) have developed tuning
methods using the MIRA algorithm (Crammer and
Singer, 2003) as a nucleus. The MIRA technique of
Chiang et al has been shown to perform well on
large-scale tasks with hundreds or thousands of fea-
tures (2009). However, the technique is complex and
architecturally quite different from MERT. Tellingly,
in the entire proceedings of ACL 2010 (Hajic? et al,
2010), only one paper describing a statistical MT
system cited the use of MIRA for tuning (Chiang,
2010), while 15 used MERT.1
Here we propose a simpler approach to tuning that
scales similarly to high-dimensional feature spaces.
We cast tuning as a ranking problem (Chen et al,
2009), where the explicit goal is to learn to correctly
rank candidate translations. Specifically, we follow
the pairwise approach to ranking (Herbrich et al,
1999; Freund et al, 2003; Burges et al, 2005; Cao et
al., 2007), in which the ranking problem is reduced
to the binary classification task of deciding between
candidate translation pairs.
Of primary concern to us is the ease of adoption of
our proposed technique. Because of this, we adhere
as closely as possible to the established MERT ar-
chitecture and use freely available machine learning
software. The end result is a technique that scales
and performs just as well as MIRA-based tuning,
but which can be implemented in a couple of hours
by anyone with an existing MERT implementation.
Mindful that many would-be enhancements to the
1The remainder either did not specify their tuning method
(though a number of these used the Moses toolkit (Koehn et al,
2007), which uses MERT for tuning) or, in one case, set weights
by hand.
1352
state-of-the-art are false positives that only show im-
provement in a narrowly defined setting or with lim-
ited data, we validate our claims on both syntax and
phrase-based systems, using multiple language pairs
and large data sets.
We describe tuning in abstract and somewhat for-
mal terms in Section 2, describe the MERT algo-
rithm in the context of those terms and illustrate its
scalability issues via a synthetic experiment in Sec-
tion 3, introduce our pairwise ranking optimization
method in Section 4, present numerous large-scale
MT experiments to validate our claims in Section 5,
discuss some related work in Section 6, and con-
clude in Section 7.
2 Tuning
In Figure 1, we show an example candidate space,
defined as a tuple ??, I, J, f, e,x? where:
? ? is a positive integer referred to as the dimen-
sionality of the space
? I is a (possibly infinite) set of positive integers,
referred to as sentence indices
? J maps each sentence index to a (possibly infi-
nite) set of positive integers, referred to as can-
didate indices
? f maps each sentence index to a sentence from
the source language
? e maps each pair ?i, j? ? I ? J(i) to the jth
target-language candidate translation of source
sentence f(i)
? x maps each pair ?i, j? ? I ? J(i) to a
?-dimension feature vector representation of
e(i, j)
The example candidate space has two source sen-
tences, three candidate translations for each source
sentence, and feature vectors of dimension 2. It is
an example of a finite candidate space, defined as
a candidate space for which I is finite and J maps
each index of I to a finite set.
A policy of candidate space ??, I, J, f, e,x? is a
function that maps each member i ? I to a member
of J(i). A policy corresponds to a choice of one
candidate translation for each source sentence. For
the example in Figure 1, policy p1 = {1 7? 2, 2 7?
3} corresponds to the choice of ?he does not go? for
the first source sentence and ?I do not go? for the
second source sentence. Obviously some policies
are better than others. Policy p2 = {1 7? 3, 2 7? 1}
corresponds to the inferior translations ?she not go?
and ?I go not.?
We assume the MT system distinguishes between
policies using a scoring function for candidate trans-
lations of the form hw(i, j) = w ? x(i, j), where w
is a weight vector of the same dimension as feature
vector x(i, j). This scoring function extends to a
policy p by summing the cost of each of the policy?s
candidate translations: Hw(p) = ?i?I hw(i, p(i)).
As can be seen in Figure 1, using w = [?2, 1],
Hw(p1) = 9 and Hw(p2) = ?8.
The goal of tuning is to learn a weight vector w
such that Hw(p) assigns a high score to good poli-
cies, and a low score to bad policies.2 To do so,
we need information about which policies are good
and which are bad. This information is provided by
a ?gold? scoring function G that maps each policy
to a real-valued score. Typically this gold function
is BLEU (Papineni et al, 2002), though there are
several common alternatives (Lavie and Denkowski,
2009; Melamed et al, 2003; Snover et al, 2006;
Chiang et al, 2008a).
We want to find a weight vector w such that Hw
behaves ?similarly? to G on a candidate space s.
We assume a loss function ls(Hw, G) which returns
the real-valued loss of using scoring function Hw
when the gold scoring function is G and the candi-
date space is s. Thus, we may say the goal of tuning
is to find the weight vector w that minimizes loss.
3 MERT
In general, the candidate space may have infinitely
many source sentences, as well as infinitely many
candidate translations per source sentence. In prac-
tice, tuning optimizes over a finite subset of source
sentences3 and a finite subset of candidate transla-
tions as well. The classic tuning architecture used
in the dominant MERT approach (Och, 2003) forms
the translation subset and learns weight vector w via
2Without loss of generality, we assume that a higher score
indicates a better translation.
3See Section 5.2 for the tune sets used in this paper?s exper-
iments.
1353
Source Sentence Candidate Translations
i f(i) j e(i, j) x(i, j) hw(i, j) g(i, j)
1 ?il ne va pas? 1 ?he goes not? [2 4] 0 0.28
2 ?he does not go? [3 8] 2 0.42
3 ?she not go? [6 1] -11 0.12
2 ?je ne vais pas? 1 ?I go not? [-3 -3] 3 0.15
2 ?we do not go? [1 -5] -7 0.18
3 ?I do not go? [-5 -3] 7 0.34
Figure 1: Example candidate space of dimensionality 2. Note: I = {1, 2}, J(1) = J(2) = {1, 2, 3}. We also show a
local scoring function hw(i, j) (where w = [?2, 1]) and a local gold scoring function g(i, j).
Algorithm TUNE(s, G):
1: initialize pool: let s? = ??, I ?, J ?, f, e,x?,
where I ? ? I and J ? = ?
2: for the desired number of iterations do
3: candidate generation: choose index pairs
(i, j); for each, add j to J ?(i)
4: optimization: find vector w that minimizes
ls?(Hw, G)
5: return w
Figure 2: Schema for iterative tuning of base candidate
space s = ??, I, J, f, e,x? w.r.t. gold function G.
a feedback loop consisting of two phases. Figure 2
shows the pseudocode. During candidate genera-
tion, candidate translations are selected from a base
candidate space s and added to a finite candidate
space s? called the candidate pool. During optimiza-
tion, the weight vector w is optimized to minimize
loss ls?(Hw, G).
For its candidate generation phase, MERT gener-
ates the k-best candidate translations for each source
sentence according to hw, where w is the weight
vector from the previous optimization phase (or an
arbitrary weight vector for the first iteration).
For its optimization phase, MERT defines the loss
function as follows:
ls(Hw, G) = maxp G(p)?G(arg maxp
Hw(p))
In other words, it prefers weight vectors w such
that the gold function G scores Hw?s best policy as
highly as possible (if Hw?s best policy is the same
as G?s best policy, then there is zero loss). Typically
the optimization phase is implemented using Och?s
line optimization algorithm (2003).
MERT has proven itself effective at tuning candi-
date spaces with low dimensionality. However, it is
often claimed that MERT does not scale well with
dimensionality. To test this claim, we devised the
following synthetic data experiment:
1. We created a gold scoring function G that is
also a linear function of the same form as Hw,
i.e.,G(p) = Hw?(p) for some gold weight vec-
tor w?. Under this assumption, the role of the
optimization phase reduces to learning back the
gold weight vector w?.
2. We generated a ?-dimensionality candidate
pool with 500 source ?sentences? and 100 can-
didate ?translations? per sentence. We created
the corresponding feature vectors by drawing
? random real numbers uniformly from the in-
terval [0, 500].
3. We ran MERT?s line optimization on this syn-
thetic candidate pool and compared the learned
weight vector w to the gold weight vector w?
using cosine similarity.
We used line optimization in the standard way,
by generating 20 random starting weight vectors and
hill-climbing on each independently until no further
progress is made, then choosing the final weight vec-
tor that minimizes loss. We tried various dimen-
sionalities from 10 to 1000. We repeated each set-
ting three times, generating different random data
each time. The results in Figure 3 indicate that as
the dimensionality of the problem increases MERT
rapidly loses the ability to learn w?. Note that this
synthetic problem is considerably easier than a real
MT scenario, where the data is noisy and interdepen-
dent, and the gold scoring function is nonlinear. If
1354
MERT cannot scale in this simple scenario, it has lit-
tle hope of succeeding in a high-dimensionality de-
ployment scenario.
4 Optimization via Pairwise Ranking
We would like to modify MERT so that it scales well
to high-dimensionality candidate spaces. The most
prominent example of a tuning method that per-
forms well on high-dimensionality candidate spaces
is the MIRA-based approach used by Watanabe et
al. (2007) and Chiang et al (2008b; 2009). Unfortu-
nately, this approach requires a complex architecture
that diverges significantly from the MERT approach,
and consequently has not been widely adopted. Our
goal is to achieve the same performance with mini-
mal modification to MERT.
With MERT as a starting point, we have a choice:
modify candidate generation, optimization, or both.
Although alternative candidate generation methods
have been proposed (Macherey et al, 2008; Chiang
et al, 2008b; Chatterjee and Cancedda, 2010), we
will restrict ourselves to MERT-style candidate gen-
eration, in order to minimize divergence from the
established MERT tuning architecture. Instead, we
focus on the optimization phase.
4.1 Basic Approach
While intuitive, the MERT optimization module fo-
cuses attention on Hw?s best policy, and not on its
overall prowess at ranking policies. We will cre-
ate an optimization module that directly addresses
Hw?s ability to rank policies in the hope that this
more holistic approach will generalize better to un-
seen data.
Assume that the gold scoring function G decom-
poses in the following way:
G(p) =
?
i?I
g(i, p(i)) (1)
where g(i, j) is a local scoring function that scores
the single candidate translation e(i, j). We show an
example g in Figure 1. For an arbitrary pair of can-
didate translations e(i, j) and e(i, j?), the local gold
function g tells us which is the better translation.
Note that this induces a ranking on the candidate
translations for each source sentence.
We follow the pairwise approach to ranking (Her-
brich et al, 1999; Freund et al, 2003; Burges et al,
2005; Cao et al, 2007). In the pairwise approach,
the learning task is framed as the classification of
candidate pairs into two categories: correctly or-
dered and incorrectly ordered. Specifically, for can-
didate translation pair e(i, j) and e(i, j?), we want:
g(i, j) > g(i, j?) ? hw(i, j) > hw(i, j?). We can
re-express this condition:
g(i, j) > g(i, j?)? hw(i, j) > hw(i, j?)
? hw(i, j)? hw(i, j?) > 0
? w ? x(i, j)?w ? x(i, j?) > 0
? w ? (x(i, j)? x(i, j?)) > 0
Thus optimization reduces to a classic binary clas-
sification problem. We create a labeled training in-
stance for this problem by computing difference vec-
tor x(i, j) ? x(i, j?), and labeling it as a positive
or negative instance based on whether, respectively,
the first or second vector is superior according to
gold function g. To ensure balance, we consider
both possible difference vectors from a pair. For ex-
ample, given the candidate space of Figure 1, since
g(1, 1) > g(1, 3), we would add ([?4, 3],+) and
([4,?3],?) to our training set. We can then feed this
training data directly to any off-the-shelf classifica-
tion tool that returns a linear classifier, in order to ob-
tain a weight vector w that optimizes the above con-
dition. This weight vector can then be used directly
by the MT system in the subsequent candidate gen-
eration phase. The exact loss function ls?(Hw, G)
optimized depends on the choice of classifier.4
Typical approaches to pairwise ranking enumer-
ate all difference vectors as training data. For tuning
however, this means O(|I| ? J2max) vectors, where
Jmax is the cardinality of the largest J(i). Since
I and Jmax commonly range in the thousands, a
full enumeration would produce billions of feature
vectors. Out of tractability considerations, we sam-
ple from the space of difference vectors, using the
sampler template in Figure 4. For each source sen-
tence i, the sampler generates ? candidate transla-
tion pairs ?j, j??, and accepts each pair with proba-
bility ?i(|g(i, j) ? g(i, j?)|). Among the accepted
pairs, it keeps the ? with greatest g differential, and
adds their difference vectors to the training data.5
4See (Chen et al, 2009) for a brief survey.
5The intuition for biasing toward high score differential is
1355
 
0
 
0.2
 
0.4
 
0.6
 
0.8 1  0
 
200
 
400
 
600
 
800
 
1000
Cosine similarity 
of learned parameter weights
Dimen
sional
ity
Synth
etic pa
ramet
er lear
ning
of ME
RT an
d PRO PRO
Noisy
 PRO MERT
Noisy
 MER
T
Figure 3: Result of synthetic data learning experiment
for MERT and PRO, with and without added noise. As
the dimensionality increases MERT is unable to learn the
original weights but PRO still performs adequately.
4.2 Scalability
We repeated the scalability study from Section 3,
now using our pairwise ranking optimization (here-
after, PRO) approach. Throughout all experiments
with PRO we choose ? = 5000, ? = 50, and the
following step function ? for each ?i: 6
?(n) =
{
0 if n < 0.05
1 otherwise
We used MegaM (Daume? III, 2004) as a binary
classifier in our contrasting synthetic experiment and
ran it ?out of the box,? i.e., with all default settings
for binary classification.7 Figure 3 shows that PRO
is able to learn w? nearly perfectly at all dimension-
alities from 10 to 1000.
As noted previously, though, this is a rather sim-
ple task. To encourage a disconnect between g and
hw and make the synthetic scenario look more like
MT reality, we repeated the synthetic experiments
that our primary goal is to ensure good translations are preferred
to bad translations, and not to tease apart small differences.
6We obtained these parameters by trial-and-error experi-
mentation on a single MT system (Urdu-English SBMT), then
held them fixed throughout our experiments. We obtained sim-
ilar results using ? = ? = 100, and for each ?i, a logistic sig-
moid function centered at the mean g differential of candidate
translation pairs for the ith source sentence. This alternative ap-
proach has the advantage of being agnostic about which gold
scoring function is used.
7With the sampling settings previously described and
MegaM as our classifier we were able to optimize two to three
times faster than with MERT?s line optimization.
Algorithm SAMPLERs,g( ?, ?, i, ?i ):
1: V = ??
2: for ? samplings do
3: Choose ?j, j?? ? J(i)?J(i) uniformly at ran-
dom.
4: With probability ?i(|g(i, j)-g(i, j?)|), add
(x(i, j),x(i, j?), |g(i, j)-g(i, j?)|) to V .
5: Sort V decreasingly by |g(i, j)-g(i, j?)|.
6: return (x(i, j) ? x(i, j?), sign(g(i, j)-g(i, j?))
and (x(i, j?)-x(i, j), sign(g(i, j?)-g(i, j))) for
each of the first ? members of V .
Figure 4: Pseudocode for our sampler. Arguments: s =
??, I, J, f, e,x? is a finite candidate space; g is a scoring
function; ?, ?, i are nonnegative integers; ?i is a func-
tion from the nonnegative real numbers to the real interval
[0, 1].
but added noise to each feature vector, drawn from
a zero-mean Gaussian with a standard deviation of
500. The results of the noisy synthetic experiments,
also in Figure 3 (the lines labeled ?Noisy?), show
that the pairwise ranking approach is less successful
than before at learning w? at high dimensionality,
but still greatly outperforms MERT.
4.3 Discussion
The idea of learning from difference vectors also lies
at the heart of the MIRA-based approaches (Watan-
abe et al, 2007; Chiang et al, 2008b) and the ap-
proach of Roth et al (2010), which, similar to our
method, uses sampling to select vectors. Here, we
isolate these aspects of those approaches to create
a simpler tuning technique that closely mirrors the
ubiquitous MERT architecture. Among other sim-
plifications, we abstract away the choice of MIRA
as the classification method (our approach can use
any classification technique that learns a separating
hyperplane), and we eliminate the need for oracle
translations.
An important observation is that BLEU does not
satisfy the decomposability assumption of Equa-
tion (1). An advantage of MERT is that it can di-
rectly optimize for non-decomposable scoring func-
tions like BLEU. In our experiments, we use
the BLEU+1 approximation to BLEU (Liang et al,
2006) to determine class labels. We will neverthe-
less use BLEU to evaluate the trained systems.
1356
PBMT
Language Experiment BLEUfeats method tune test
Urdu-English
base
MERT 20.5 17.7
MIRA 20.5 17.9
PRO 20.4 18.2
ext MIRA 21.8 17.8PRO 21.6 18.1
Arabic-English
base
MERT 46.8 41.2
MIRA 47.0 41.1
PRO 46.9 41.1
ext MIRA 47.5 41.7PRO 48.5 41.9
Chinese-English
base
MERT 23.8 22.2
MIRA 24.1 22.5
PRO 23.8 22.5
ext MIRA 24.8 22.6PRO 24.9 22.7
SBMT
Language Experiment BLEUfeats method tune test
Urdu-English
base
MERT 23.4 21.4
MIRA 23.6 22.3
PRO 23.4 22.2
ext MIRA 25.2 22.8PRO 24.2 22.8
Arabic-English
base
MERT 44.7 39.0
MIRA 44.6 39.0
PRO 44.5 39.0
ext MIRA 45.8 39.8PRO 45.9 40.3
Chinese-English
base
MERT 25.5 22.7
MIRA 25.4 22.9
PRO 25.5 22.9
ext MIRA 26.0 23.3PRO 25.6 23.5
Table 1: Machine translation performance for the experiments listed in this paper. Scores are case-sensitive IBM
BLEU. For every choice of system, language pair, and feature set, PRO performs comparably with the other methods.
5 Experiments
We now turn to real machine translation condi-
tions to validate our thesis: We can cleanly replace
MERT?s line optimization with pairwise ranking op-
timization and immediately realize the benefits of
high-dimension tuning. We now detail the three
language pairs, two feature scenarios, and two MT
models used for our experiments. For each language
pair and each MT model we used MERT, MIRA, and
PRO to tune with a standard set of baseline features,
and used the latter two methods to tune with an ex-
tended set of features.8 At the end of every experi-
ment we used the final feature weights to decode a
held-out test set and evaluated it with case-sensitive
BLEU. The results are in Table 1.
5.1 Systems
We used two systems, each based on a different MT
model. Our syntax-based system (hereafter, SBMT)
follows the model of Galley et al (2004). Our
8MERT could not run to a satisfactory completion in any
extended feature scenario; as implied in the synthetic data ex-
periment of Section 3, the algorithm makes poor choices for
its weights and this leads to low-quality k-best lists and dismal
performance, near 0 BLEU in every iteration.
phrase-based system (hereafter, PBMT) follows the
model of Och and Ney (2004). In both systems
we learn alignments with GIZA++ (Och and Ney,
2000) using IBM Model 4; for Urdu-English and
Chinese-English we merged alignments with the re-
fined method, and for Arabic-English we merged
with the union method.
5.2 Data
Table 2 notes the sizes of the datasets used in our ex-
periments. All tune and test data have four English
reference sets for the purposes of scoring.
Data U-E A-E C-E
Train lines 515K 6.5M 7.9Mwords 2.2M 175M 173M
Tune lines 923 1994 1615words 16K 65K 42K
Test lines 938 1357 1357words 18K 47K 37K
Table 2: Data sizes for the experiments reported in this
paper (English words shown).
1357
Class
Urdu-English Arabic-English Chinese-English
PBMT SBMT PBMT SBMT PBMT SBMT
base ext base ext base ext base ext base ext base ext
baseline 15 15 19 19 15 15 19 19 15 15 19 19
target word ? 51 ? 50 ? 51 ? 50 ? 51 ? 299
discount ? 11 ? 11 ? 11 ? 10 ? 11 ? 10
node count ? ? ? 99 ? ? ? 138 ? ? ? 96
rule overlap ? ? ? 98 ? ? ? 136 ? ? ? 93
word pair ? 2110 ? ? ? 6193 ? ? ? 1688 ? ?
phrase length ? 63 ? ? ? 63 ? ? ? 63 ? ?
total 15 2250 19 277 15 6333 18 352 15 1828 19 517
Table 3: Summary of features used in experiments in this paper.
5.2.1 Urdu-English
The training data for Urdu-English is that made
available in the constrained track in the NIST 2009
MT evaluation. This includes many lexicon entries
and other single-word data, which accounts for the
large number of lines relative to word count. The
NIST 2008 evaluation set, which contains newswire
and web data, is split into two parts; we used roughly
half each for tune and test. We trained a 5-gram
English language model on the English side of the
training data.
5.2.2 Arabic-English
The training data for Arabic English is that made
available in the constrained track in the NIST 2008
MT evaluation. The tune set, which contains only
newswire data, is a mix from NIST MT evaluation
sets from 2003?2006 and from GALE development
data. The test set, which contains both web and
newswire data, is the evaluation set from the NIST
2008 MT evaluation. We trained a 4-gram English
language model on the English side of the training
data.
5.2.3 Chinese-English
For Chinese-English we used 173M words of
training data from GALE 2008. For SBMT we used
a 32M word subset for extracting rules and building
a language model, but used the entire training data
for alignments, and for all PBMT training. The tune
and test sets both contain web and newswire data.
The tune set is selected from NIST MT evaluation
sets from 2003?2006. The test set is the evaluation
set from the NIST 2008 MT evaluation. We trained a
3-gram English language model on the English side
of the training data.
5.3 Features
For each of our systems we identify two feature sets:
baseline, which correspond to the typical small fea-
ture set reported in current MT literature, and ex-
tended, a superset of baseline, which adds hundreds
or thousands of features. Specifically, we use 15
baseline features for PBMT, similar to the baseline
features described by Watanabe et al (2007). We
use 19 baseline features for SBMT, similar to the
baseline features described by Chiang et al (2008b).
We used the following feature classes in SBMT
and PBMT extended scenarios:
? Discount features for rule frequency bins (cf.
Chiang et al (2009), Section 4.1)
? Target word insertion features9
We used the following feature classes in SBMT ex-
tended scenarios only (cf. Chiang et al (2009), Sec-
tion 4.1):10
? Rule overlap features
? Node count features
9For Chinese-English and Urdu-English SBMT these fea-
tures only fired when the inserted target word was unaligned to
any source word.
10The parser used for Arabic-English had a different nonter-
minal set than that used for the other two SBMT systems, ac-
counting for the wide disparity in feature count for these feature
classes.
1358
 
20
 
21
 
22
 
23
 
24
 
25
 
26  0
 
5
 
10
 
15
 
20
 
25
 
30
4-ref BLEU
Iterati
on
Urdu-
Englis
h SBM
T base
line fe
ature 
tuning
TUNE TEST
MER
T MIRA PRO
 
20
 
21
 
22
 
23
 
24
 
25
 
26  0
 
5
 
10
 
15
 
20
 
25
 
30
4-ref BLEU
Iterati
on
Urdu-
Englis
h SBM
T exte
nded f
eature
 tunin
g
TUNE TEST
MIRA PRO
Figure 5: Comparison of MERT, PRO, and MIRA on tuning Urdu-English SBMT systems, and test results at every
iteration. PRO performs comparably to MERT and MIRA.
We used the following feature classes in PBMT
extended scenarios only:
? Unigram word pair features for the 80 most fre-
quent words in both languages plus tokens for
unaligned and all other words (cf. Watanabe et
al. (2007), Section 3.2.1)11
? Source, target, and joint phrase length fea-
tures from 1 to 7, e.g. ?tgt=4?, ?src=2?, and
?src/tgt=2,4?
The feature classes and number of features used
within those classes for each language pair are sum-
marized in Table 3.
5.4 Tuning settings
Each of the three approaches we compare in this
study has various details associated with it that may
prove useful to those wishing to reproduce our re-
sults. We list choices made for the various tuning
methods here, and note that all our decisions were
made in keeping with best practices for each algo-
rithm.
5.4.1 MERT
We used David Chiang?s CMERT implementation
of MERT that is available with the Moses system
(Koehn et al, 2007). We ran MERT for up to 30 it-
erations, using k = 1500, and stopping early when
11This constitutes 6,723 features in principle (822 ? 1 since
?unaligned-unaligned? is not considered) but in practice far
fewer co-occurrences were seen. Table 3 shows the number of
actual unigram word pair features observed in data.
the accumulated k-best list does not change in an it-
eration. In every tuning iteration we ran MERT once
with weights initialized to the last iteration?s chosen
weight set and 19 times with random weights, and
chose the the best of the 20 ending points according
to G on the development set. The G we optimize
is tokenized, lower-cased 4-gram BLEU (Papineni et
al., 2002).
5.4.2 MIRA
We for the most part follow the MIRA algorithm
for machine translation as described by Chiang et al
(2009)12 but instead of using the 10-best of each of
the best hw, hw +g, and hw-g, we use the 30-best
according to hw.13 We use the same sentence-level
BLEU calculated in the context of previous 1-best
translations as Chiang et al (2008b; 2009). We ran
MIRA for 30 iterations.
5.4.3 PRO
We used the MegaM classifier and sampled as de-
scribed in Section 4.2. As previously noted, we used
BLEU+1 (Liang et al, 2006) for g. MegaM was easy
to set up and ran fairly quickly, however any linear
binary classifier that operates on real-valued features
can be used, and in fact we obtained similar results
12and acknowledge the use of David Chiang?s code
13This is a more realistic scenario for would-be implementers
of MIRA, as obtaining the so-called ?hope? and ?fear? transla-
tions from the lattice or forest is significantly more complicated
than simply obtaining a k-best list. Other tests comparing these
methods have shown between 0.1 to 0.3 BLEU drop using 30-
best hw on Chinese-English (Wang, 2011).
1359
using the support vector machine module of WEKA
(Hall et al, 2009) as well as the Stanford classifier
(Manning and Klein, 2003). We ran for up to 30 iter-
ations and used the same k and stopping criterion as
was used for MERT, though variability of sampling
precluded list convergence.
While MERT and MIRA use each iteration?s final
weights as a starting point for hill-climbing the next
iteration, the pairwise ranking approach has no ex-
plicit tie to previous iterations. To incorporate such
stability into our process we interpolated the weights
w? learned by the classifier in iteration t with those
from iteration t ? 1 by a factor of ?, such that
wt = ? ?w? + (1??) ?wt?1. We found ? = 0.1
gave good performance across the board.
5.5 Discussion
We implore the reader to avoid the natural tendency
to compare results using baseline vs. extended fea-
tures or between PBMT and SBMT on the same lan-
guage pair. Such discussions are indeed interesting,
and could lead to improvements in feature engineer-
ing or sartorial choices due to the outcome of wagers
(Goodale, 2008), but they distract from our thesis.
As can be seen in Table 1, for each of the 12 choices
of system, language pair, and feature set, the PRO
method performed nearly the same as or better than
MIRA and MERT on test data.
In Figure 5 we show the tune and test BLEU us-
ing the weights learned at every iteration for each
Urdu-English SBMT experiment. Typical of the rest
of the experiments, we can clearly see that PRO ap-
pears to proceed more monotonically than the other
methods. We quantified PRO?s stability as compared
to MERT by repeating the Urdu-English baseline
PBMT experiment five times with each configura-
tion. The tune and test BLEU at each iteration is
depicted in Figure 6. The standard deviation of the
final test BLEU of MERT was 0.13 across the five
experiment instances, while PRO had a standard de-
viation of just 0.05.
6 Related Work
Several works (Shen et al, 2004; Cowan et al,
2006; Watanabe et al, 2006) have used discrimina-
tive techniques to re-rank k-best lists for MT. Till-
mann and Zhang (2005) used a customized form of
 
17
 
18
 
19
 
20
 
21  0
 
5
 
10
 
15
 
20
 
25
 
30
4-ref BLEU
Iterati
on
Urdu-
Englis
h PBM
T tuni
ng sta
bility
TUNE TEST
MERT PRO
Figure 6: Tune and test curves of five repetitions of the
same Urdu-English PBMT baseline feature experiment.
PRO is more stable than MERT.
multi-class stochastic gradient descent to learn fea-
ture weights for an MT model. Och and Ney (2002)
used maximum entropy to tune feature weights but
did not compare pairs of derivations. Ittycheriah and
Roukos (2005) used a maximum entropy classifier to
train an alignment model using hand-labeled data.
Xiong et al (2006) also used a maximum entropy
classifier, in this case to train the reordering com-
ponent of their MT model. Lattice- and hypergraph-
based variants of MERT (Macherey et al, 2008; Ku-
mar et al, 2009) are more stable than traditional
MERT, but also require significant engineering ef-
forts.
7 Conclusion
We have described a simple technique for tuning
an MT system that is on par with the leading tech-
niques, exhibits reliable behavior, scales gracefully
to high-dimension feature spaces, and is remark-
ably easy to implement. We have demonstrated, via
a litany of experiments, that our claims are valid
and that this technique is widely applicable. It is
our hope that the adoption of PRO tuning leads to
fewer headaches during tuning and motivates ad-
vanced MT feature engineering research.
Acknowledgments
Thanks to Markus Dreyer, Kevin Knight, Saiyam
Kohli, Greg Langmead, Daniel Marcu, Dragos
Munteanu, and Wei Wang for their assistance.
Thanks also to the anonymous reviewers, especially
the reviewer who implemented PRO during the re-
view period and replicated our results.
1360
References
Chris Burges, Tal Shaked, Erin Renshaw, Ari Lazier,
Matt Deeds, Nicole Hamilton, and Greg Hullender.
2005. Learning to rank using gradient descent. In Pro-
ceedings of the 22nd International Conference on Ma-
chine Learning, ICML ?05, pages 89?96, Bonn, Ger-
many. ACM.
Zhe Cao, Tao Qin, Tie-Yan Liu, Ming-Feng Tsai, and
Hang Li. 2007. Learning to rank: From pairwise
approach to listwise approach. In Proceedings of the
24th International Conference on Machine Learning,
pages 129?136, Corvalis, OR.
Samidh Chatterjee and Nicola Cancedda. 2010. Mini-
mum error rate training by sampling the translation lat-
tice. In Proceedings of the 2010 Conference on Empir-
ical Methods in Natural Language Processing, pages
606?615, Cambridge, MA, October. Association for
Computational Linguistics.
Wei Chen, Tie-Yan Liu, Yanyan Lan, Zhi-Ming Ma, and
Hang Li. 2009. Ranking measures and loss functions
in learning to rank. In Y. Bengio, D. Schuurmans,
J. Lafferty, C. K. I. Williams, and A. Culotta, editors,
Advances in Neural Information Processing Systems
22, pages 315?323.
David Chiang, Steve DeNeefe, Yee Seng Chan, and
Hwee Tou Ng. 2008a. Decomposability of transla-
tion metrics for improved evaluation and efficient al-
gorithms. In Proceedings of the 2008 Conference on
Empirical Methods in Natural Language Processing,
pages 610?619, Honolulu, HI, October. Association
for Computational Linguistics.
David Chiang, Yuval Marton, and Philip Resnik. 2008b.
Online large-margin training of syntactic and struc-
tural translation features. In Proceedings of the 2008
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 224?233, Honolulu, HI, Oc-
tober. Association for Computational Linguistics.
David Chiang, Kevin Knight, and Wei Wang. 2009.
11,001 new features for statistical machine transla-
tion. In Proceedings of Human Language Technolo-
gies: The 2009 Annual Conference of the North Ameri-
can Chapter of the Association for Computational Lin-
guistics, pages 218?226, Boulder, CO, June. Associa-
tion for Computational Linguistics.
David Chiang. 2010. Learning to translate with source
and target syntax. In Proceedings of the 48th Annual
Meeting of the Association for Computational Linguis-
tics, pages 1443?1452, Uppsala, Sweden, July. Asso-
ciation for Computational Linguistics.
Brooke Cowan, Ivona Kuc?erova?, and Michael Collins.
2006. A discriminative model for tree-to-tree trans-
lation. In Proceedings of the 2006 Conference on
Empirical Methods in Natural Language Processing,
pages 232?241, Sydney, Australia, July. Association
for Computational Linguistics.
Koby Crammer and Yoram Singer. 2003. Ultraconserva-
tive online algorithms for multiclass problems. Jour-
nal of Machine Learning Research, 3:951?991.
Hal Daume? III. 2004. Notes on CG and LM-BFGS
optimization of logistic regression. Paper available at
http://pub.hal3.name#daume04cg-bfgs,
implementation available at http://hal3.name/
megam/, August.
Yoav Freund, Raj Iyer, Robert E. Schapire, and Yoram
Singer. 2003. An efficient boosting algorithm for
combining preferences. Journal of Machine Learning
Research, 4:933?969.
Michel Galley, Mark Hopkins, Kevin Knight, and Daniel
Marcu. 2004. What?s in a translation rule? In HLT-
NAACL 2004: Main Proceedings, pages 273?280,
Boston, MA, May. Association for Computational Lin-
guistics.
Gloria Goodale. 2008. Language Weaver: fast
in translation. The Christian Science Monitor,
October 1. http://www.csmonitor.com/
Innovation/Tech-Culture/2008/1001/
language-weaver-fast-in-translation.
Jan Hajic?, Sandra Carberry, Stephen Clark, and Joakim
Nivre, editors. 2010. Proceedings of the 48th Annual
Meeting of the Association for Computational Linguis-
tics. Association for Computational Linguistics, Upp-
sala, Sweden, July.
Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard
Pfahringer, Peter Reutemann, and Ian H. Witten.
2009. The WEKA data mining software: An update.
SIGKDD Explorations, 11(1).
Ralf Herbrich, Thore Graepel, and Klaus Obermayer.
1999. Support vector learning for ordinal regression.
In Proceedings of the 1999 International Conference
on Artificial Neural Networks, pages 97?102.
Abraham Ittycheriah and Salim Roukos. 2005. A max-
imum entropy word aligner for Arabic-English ma-
chine translation. In Proceedings of Human Language
Technology Conference and Conference on Empiri-
cal Methods in Natural Language Processing, pages
89?96, Vancouver, Canada, October. Association for
Computational Linguistics.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondrej Bojar, Alexandra Con-
stantin, and Evan Herbst. 2007. Moses: Open source
toolkit for statistical machine translation. In Proceed-
ings of the 45th Annual Meeting of the Association for
Computational Linguistics Companion Volume Pro-
ceedings of the Demo and Poster Sessions, pages 177?
1361
180, Prague, Czech Republic, June. Association for
Computational Linguistics.
Shankar Kumar, Wolfgang Macherey, Chris Dyer, and
Franz Och. 2009. Efficient minimum error rate train-
ing and minimum bayes-risk decoding for translation
hypergraphs and lattices. In Proceedings of the Joint
Conference of the 47th Annual Meeting of the ACL and
the 4th International Joint Conference on Natural Lan-
guage Processing of the AFNLP, pages 163?171, Sun-
tec, Singapore, August. Association for Computational
Linguistics.
Alon Lavie and Michael J. Denkowski. 2009. The
METEOR metric for automatic evaluation of machine
translation. Machine Translation, 23(2?3):105?115,
September.
Percy Liang, Alexandre Bouchard-Co?te?, Dan Klein, and
Ben Taskar. 2006. An end-to-end discriminative ap-
proach to machine translation. In Proceedings of the
21st International Conference on Computational Lin-
guistics and 44th Annual Meeting of the Association
for Computational Linguistics, pages 761?768, Syd-
ney, Australia, July. Association for Computational
Linguistics.
Wolfgang Macherey, Franz Josef Och, Ignacio Thayer,
and Jakob Uszkoreit. 2008. Lattice-based minimum
error rate training for statistical machine translation.
In Proceedings of the 2008 Conference on Empirical
Methods in Natural Language Processing, pages 725?
734, Honolulu, HI, October. Association for Compu-
tational Linguistics.
Christopher Manning and Dan Klein. 2003. Optimiza-
tion, maxent models, and conditional estimation with-
out magic. Tutorial at HLT-NAACL 2003 and ACL
2003.
I. Dan Melamed, Ryan Green, and Joseph P. Turian.
2003. Precision and recall of machine translation. In
Companion Volume of the Proceedings of HLT-NAACL
2003 - Short Papers, pages 61?63, Edmonton, Canada,
May?June. Association for Computational Linguis-
tics.
Franz Och and Hermann Ney. 2000. Improved statistical
alignment models. In Proceedings of the 38th Annual
Meeting of the Association for Computational Linguis-
tics, pages 440?447, Hong Kong, October.
Franz Josef Och and Hermann Ney. 2002. Discrimi-
native training and maximum entropy models for sta-
tistical machine translation. In Proceedings of 40th
Annual Meeting of the Association for Computational
Linguistics, pages 295?302, Philadelphia, PA, July.
Association for Computational Linguistics.
Franz Och and Hermann Ney. 2004. The alignment tem-
plate approach to statistical machine translation. Com-
putational Linguistics, 30(4):417?449.
Franz Och. 2003. Minimum error rate training in statis-
tical machine translation. In Proceedings of the 41st
Annual Meeting of the Association for Computational
Linguistics, pages 160?167, Sapporo, Japan, July. As-
sociation for Computational Linguistics.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic
evaluation of machine translation. In Proceedings of
40th Annual Meeting of the Association for Computa-
tional Linguistics, pages 311?318, Philadelphia, PA,
July. Association for Computational Linguistics.
Benjamin Roth, Andrew McCallum, Marc Dymetman,
and Nicola Cancedda. 2010. Machine translation us-
ing overlapping alignments and samplerank. In Pro-
ceedings of Association for Machine Translation in the
Americas, Denver, CO.
Libin Shen, Anoop Sarkar, and Franz Josef Och. 2004.
Discriminative reranking for machine translation. In
Daniel Marcu Susan Dumais and Salim Roukos, ed-
itors, HLT-NAACL 2004: Main Proceedings, pages
177?184, Boston, MA, May 2 - May 7. Association
for Computational Linguistics.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciulla, and John Makhoul. 2006. A study of
translation edit rate with targeted human annotation.
In Proceedings of Association for Machine Translation
in the Americas, pages 223?231.
Christoph Tillmann and Tong Zhang. 2005. A localized
prediction model for statistical machine translation. In
Proceedings of the 43rd Annual Meeting of the ACL,
pages 557?564, Ann Arbor, MI, June. Association for
Computational Linguistics.
Wei Wang. 2011. Personal communication.
Taro Watanabe, Jun Suzuki, Hajime Tsukada, and Hideki
Isozaki. 2006. NTT statistical machine translation for
IWSLT 2006. In Proceedings of IWSLT 2006, pages
95?102.
Taro Watanabe, Jun Suzuki, Hajime Tsukada, and Hideki
Isozaki. 2007. Online large-margin training for sta-
tistical machine translation. In Proceedings of the
2007 Joint Conference on Empirical Methods in Nat-
ural Language Processing and Computational Natu-
ral Language Learning (EMNLP-CoNLL), pages 764?
773, Prague, Czech Republic, June. Association for
Computational Linguistics.
Deyi Xiong, Qun Liu, and Shouxun Lin. 2006. Maxi-
mum entropy based phrase reordering model for sta-
tistical machine translation. In Proceedings of the 21st
International Conference on Computational Linguis-
tics and 44th Annual Meeting of the Association for
Computational Linguistics, pages 521?528, Sydney,
Australia, July. Association for Computational Lin-
guistics.
1362
Re-structuring, Re-labeling, and Re-aligning
for Syntax-Based Machine Translation
Wei Wang?
Language Weaver, Inc.
Jonathan May??
USC/Information Sciences Institute
Kevin Knight?
USC/Information Sciences Institute
Daniel Marcu?
Language Weaver, Inc.
This article shows that the structure of bilingual material from standard parsing and alignment
tools is not optimal for training syntax-based statistical machine translation (SMT) systems.
We present three modifications to the MT training data to improve the accuracy of a state-of-the-
art syntax MT system: re-structuring changes the syntactic structure of training parse trees to
enable reuse of substructures; re-labeling alters bracket labels to enrich rule application context;
and re-aligning unifies word alignment across sentences to remove bad word alignments and
refine good ones. Better structures, labels, and word alignments are learned by the EM algorithm.
We show that each individual technique leads to improvement as measured by BLEU, and we
also show that the greatest improvement is achieved by combining them. We report an overall
1.48 BLEU improvement on the NIST08 evaluation set over a strong baseline in Chinese/English
translation.
1. Background
Syntactic methods have recently proven useful in statistical machine translation (SMT).
In this article, we explore different ways of exploiting the structure of bilingual material
for syntax-based SMT. In particular, we ask what kinds of tree structures, tree labels,
and word alignments are best suited for improving end-to-end translation accuracy.
We begin with structures from standard parsing and alignment tools, then use the EM
algorithm to revise these structures in light of the translation task. We report an overall
+1.48 BLEU improvement on a standard Chinese-to-English test.
? 6060 Center Drive, Suite 150, Los Angeles, CA, 90045, USA. E-mail: wwang@languageweaver.com.
?? 4676 Admiralty Way, Marina del Rey, CA, 90292, USA. E-mail: jonmay@isi.edu.
? 4676 Admiralty Way, Marina del Rey, CA, 90292, USA. E-mail: knight@isi.edu.
? 6060 Center Drive, Suite 150, Los Angeles, CA, 90045, USA. E-mail: dmarcu@languageweaver.com.
Submission received: 6 November 2008; revised submission received: 10 September 2009; accepted for
publication: 1 January 2010.
? 2010 Association for Computational Linguistics
Computational Linguistics Volume 36, Number 2
We carry out our experiments in the context of a string-to-tree translation system.
This system accepts a Chinese string as input, and it searches through a multiplicity of
English tree outputs, seeking the one with the highest score. The string-to-tree frame-
work is motivated by a desire to improve target-language grammaticality. For example,
it is common for string-basedMT systems to output sentences with no verb. By contrast,
the string-to-tree framework forces the output to respect syntactic requirements?for
example, if the output is a syntactic tree whose root is S (sentence), then the S will gen-
erally have a child of type VP (verb phrase), which will in turn contain a verb. Another
motivation is better treatment of function words. Often, these words are not literally
translated (either by themselves or as part of a phrase), but rather they control what
happens in the translation, as with case-marking particles or passive-voice particles.
Finally, much of the re-ordering we find in translation is syntactically motivated, and
this can be captured explicitly with syntax-based translation rules. Tree-to-tree systems
are also promising, but in this work we concentrate only on target-language syntax. The
target-language generation problem presents a difficult challenge, whereas the source
sentence is fixed and usually already grammatical.
To prepare training data for such a system, we begin with a bilingual text that has
been automatically processed into segment pairs. We require that the segments be single
sentences on the English side, whereas the corresponding Chinese segments may be
sentences, sentence fragments, or multiple sentences. We then parse the English side of
the bilingual text using a re-implementation of the Collins (1997) parsing model, which
we train on the Penn English Treebank (Marcus, Santorini, and Marcinkiewicz 1993).
Finally, we word-align the segment pairs according to IBMModel 4 (Brown et al 1993).
Figure 1 shows a sample (tree, string, alignment) triple.
We build two generative statistical models from this data. First, we construct a
smoothed n-gram language model (Kneser and Ney 1995; Stolcke 2002) out of the
English side of the bilingual data. This model assigns a probability P(e) to any candidate
translation, rewarding translations whose subsequences have been observed frequently
in the training data.
Second, we build a syntax-based translation model that we can use to produce
candidate English trees fromChinese strings. Following previouswork in noisy-channel
Figure 1
A sample learning case for the syntax-based machine translation system described in this article.
248
Wang et al Re-structuring, Re-labeling, and Re-aligning
SMT (Brown et al 1993), our model operates in the English-to-Chinese direction?
we envision a generative top?down process by which an English tree is gradually
transformed (by probabilistic rules) into an observed Chinese string. We represent a
collection of such rules as a tree transducer (Knight and Graehl 2005). In order to
construct this transducer from parsed and word-aligned data, we use the GHKM rule
extraction algorithm of Galley et al (2004). This algorithm computes the unique set of
minimal rules needed to explain any sentence pair in the data. Figure 2 shows all the
minimal rules extracted from the example (tree, string, alignment) triple in Figure 1.
Note that rules specify rotation (e.g., R1, R5), direct translation (R3, R10), insertion and
deletion (R2, R4), and tree traversal (R9, R7). The extracted rules for a given example
form a derivation tree.
We collect all rules over the entire bilingual corpus, and we normalize rule counts
in this way: P(rule) = count(rule)count(LHS-root(rule)) . When we apply these probabilities to derive an
English sentence e and a corresponding Chinese sentence c, we wind up computing the
joint probability P(e, c). We smooth the rule counts with Good?Turing smoothing (Good
1953).
This extraction method assigns each unaligned Chinese word to a default rule in
the derivation tree. We next follow Galley et al (2006) in allowing unaligned Chinese
words to participate in multiple translation rules. In this case, we obtain a derivation
forest of minimal rules. Galley et al show how to use EM to count rules over deriva-
tion forests and obtain Viterbi derivation trees of minimal rules. We also follow Galley
et al in collecting composed rules, namely, compositions of minimal rules. These larger
rules have been shown to substantially improve translation accuracy (Galley et al 2006;
DeNeefe et al 2007). Figure 3 shows some of the additional rules.
With these models, we can decode a new Chinese sentence by enumerating and
scoring all of the English trees that can be derived from it by rule. The score is a
weighted product of P(e) and P(e, c). To search efficiently, we employ the CKY dynamic-
programming parsing algorithm (Yamada and Knight 2002; Galley et al 2006). This
algorithm builds English trees on top of Chinese spans. In each cell of the CKY matrix,
we store the non-terminal symbol at the root of the English tree being built up. We also
Figure 2
Minimal rules extracted from the learning case in Figure 1 using the GHKM procedure.
249
Computational Linguistics Volume 36, Number 2
Figure 3
Additional rules extracted from the learning case in Figure 1.
store English words that appear at the left and right corners of the tree, as these are
needed for computing the P(e) score when cells are combined. For CKY to work, all
transducer rules must be broken down, or binarized, into rules that contain at most two
variables?more efficient search can be gained if this binarization produces rules that
can be incrementally scored by the language model (Melamed, Satta, and Wellington
2004; Zhang et al 2006). Finally, we employ cube pruning (Chiang 2007) for further
efficiency in the search.
When scoring translation candidates, we add several smaller models. One model
rewards longer translation candidates, off-setting the language model?s desire for short
output. Other models punish rules that drop Chinese content words or introduce
spurious English content words. We also include lexical smoothing models (Gale and
Sampson 1996; Good 1953) to help distinguish good low-count rules from bad low-
count rules. The final score of a translation candidate is a weighted linear combination
of log P(e), log P(e, c), and the scores from these additional smaller models. We obtain
weights through minimum error-rate training (Och 2003).
The system thus constructed performs fairly well at Chinese-to-English translation,
as reflected in the NIST06 common evaluation of machine translation quality.1
However, it would be surprising if the parse structures and word alignments in our
bilingual data were somehow perfectly suited to syntax-based SMT?we have so far
used out-of-the-box tools like IBM Model 4 and a Treebank-trained parser. Huang and
Knight (2006) already investigated whether different syntactic labels would be more
appropriate for SMT, though their study was carried out on a weak baseline translation
system. In this article, we take a broad view and investigate how changes to syntactic
structures, syntactic labels, and word alignments can lead to substantial improvements
in translation quality on top of a strong baseline. We design our methods around
problems that arise in MT data whose parses and alignments use some Penn Treebank-
style annotations. We believe that some of the techniques will apply to other annotation
schemes, but conclusions here are limited to Penn Treebank-style trees.
The rest of this article is structured as follows. Section 2 describes the corpora and
model configurations used in our experiments. In each of the next three sections we
present a technique for modifying the training data to improve syntax MT accuracy:
tree re-structuring in Section 3, tree re-labeling in Section 4, and re-aligning in Section 5.
In each of these three sections, we also present experiment results to show the impact
of each individual technique on end-to-end MT accuracy. Section 6 shows the improve-
ment made by combining all three techniques. We conclude in Section 7.
1 http://nist.gov/speech/tests/mt/2006/doc/mt06eval official results.html.
250
Wang et al Re-structuring, Re-labeling, and Re-aligning
2. Corpora for Experiments
For our experiments, we use a 245 million word Chinese/English bitext, available from
LDC. A re-implementation of the Collins (1997) parser runs on the English half of the
bitext to produce parse trees, and GIZA runs on the entire bitext to produce M4 word
alignments. We extract a subset of 36 million words from the entire bitext, by selecting
only sentences in the mainland news domain. We extract translation rules from these
selected 36 million words. Experiments show that our Chinese/English syntax MT
systems built from this selected bitext give as high BLEU scores as from the entire bitext.
Our development set consists of 1,453 lines and is extracted from the NIST02?
NIST05 evaluation sets, for tuning of feature weights. The development set is from the
newswire domain, andwe chose it to represent awide period of time rather than a single
year. We use the NIST08 evaluation set as our test set. Because the NIST08 evaluation set
is a mix of newswire text andWeb text, we also report the BLEU scores on the newswire
portion.
We use two 5-gram languagemodels. One is trained on the English half of the bitext.
The other is trained on one billion words of monolingual data. Kneser?Ney smoothing
(Kneser and Ney 1995) is applied to both language models. Language models are
represented using randomized data structures similar to those of Talbot and Osborne
(2007) in decoding for efficient RAM usage.
To test the significance of improvements over the baseline, we compute paired boot-
strap p-values (Koehn 2004) for BLEU between the baseline system and each improved
system.
3. Re-structuring Trees for Training
Our translation system is trained on Chinese/English data, where the English side
has been automatically parsed into Penn Treebank-style trees. One striking fact about
these trees is that they contain many flat structures. For example, base noun phrases
frequently have five or more direct children. It is well known in monolingual parsing
research that these flat structures cause problems. Although thousands of rewrite rules
can be learned from the Penn Treebank, these rules still do not cover the new rewrites
observed in held-out test data. For this reason, and to extract more general knowl-
edge, many monolingual parsing models aremarkovized so that they can produce flat
structures incrementally and horizontally (Collins 1997; Charniak 2000). Other parsing
systems binarize the training trees in a pre-processing step, then learn to model the
binarized corpus (Petrov et al 2006); after parsing, their results are flattened back
in a post-processing step. In addition, Johnson (1998b) shows that different types of
tree structuring (e.g., the Chomsky adjunction representation vs. the Penn Treebank II
representation) can have a large effect on the parsing performance of a PCFG estimated
from these trees.
We find that flat structures are also problematic for syntax-based machine transla-
tion. The rules we learn from tree/string/alignment triples often lack sufficient gener-
alization power. For example, consider the training samples in Figure 4. We should be
able to learn enough from these two samples to translate the new phrase
?.W-#L?? Z ?{ 3?
VIKTOR CHERNOMYRDIN AND HIS COLLEAGUE
into its English equivalent victor chernomyrdin and his colleagues.
251
Computational Linguistics Volume 36, Number 2
Figure 4
Learning translation rules from flat English structures.
However, the learned rules R12 and R13 do not fit together nicely. R12 can translate
?.W-#L?? into an English base noun phrase (NPB) that includes viktor
chernomyrdin, but only if it is preceded by words that translate into an English JJ and
an English NNP. Likewise, R13 can translate
Z ?{ 3?
into an NPB that includes
and his colleagues, but only if preceded by two NNPs. Both rules want to create an NPB,
and neither can supply the other with what it needs.
If we re-structure the training trees as shown in Figure 5, we get much better
behavior. Now rule R14 translates
?.W-#L?? into a free-standing NPB. This
gives rule R15 the ability to translate
Z ?{ 3?
, because it finds the necessary
NPB to its left.
Here, we are re-structuring the trees in our MT training data by binarizing them.
This allows us to extract better translation rules, though of course an extracted rule may
have more than two variables. Whether the rules themselves should be binarized is a
separate question, addressed in Melamed, Satta, andWellington (2004) and Zhang et al
(2006). One can decide to re-structure training data trees, binarize translation rules, or
do both, or do neither. Here we focus on English tree re-structuring.
In this section, we explore the generalization ability of simple re-structuring meth-
ods like left-, right-, and head-binarization, and also their combinations. Simple bina-
rization methods binarize syntax trees in a consistent fashion (left-, right-, or head-)
and thus cannot guarantee that all the substructures can be factored out. For example,
consistent right binarization of the training examples in Figure 4 makes available R14,
but misses R15. We therefore also introduce a parallel re-structuring method in which
we binarize both to the left and right at the same time, resulting in a binarization
forest. We employ the EM algorithm (Dempster, Laird, and Rubin 1977) to learn the
binarization bias for each tree node in the corpus from the parallel alternatives.
252
Wang et al Re-structuring, Re-labeling, and Re-aligning
Figure 5
Learning translation rules from binarized English structures.
3.1 Some Concepts
We now explain some concepts to facilitate the descriptions of the re-structuring meth-
ods. We train our translation model on alignment graphs (Galley et al 2004). An
alignment graph is a tuple of a source-language sentence f, a target-language parse tree
that yields e and translates from f, and the word alignments a between e and f. The
graphs in Figures 1, 4, and 5 are examples of alignment graphs.
In the alignment graph, a node in the parse tree is called admissible if rules can be
extracted from it.We can extract rules from a node if and only if the yield of the tree node
is consistent with the word alignments?the f string covered by the node is contiguous
but not empty, and the f string does not align to any e string that is not covered by
the node. An admissible tree node is one where rules overlap. Figure 6 shows different
binarizations of the left tree in Figure 4. In this figure, the NPB node in tree (1) is not
admissible because the f string, V-C, that the node covers also aligns to NNP3, which is
not covered by the NPB. Node NPB in tree (2), on the other hand, is admissible.
A set of sibling tree nodes is called factorizable if we can form an admissible
new node dominating them. In Figure 6, sibling nodes NNP1, NNP2, and NNP3 are
factorizable because we can factorize them out and form a new node NPB, resulting
in tree (2). Sibling tree nodes JJ, NNP1, and NNP2 are not factorizable. Not all sibling
nodes are factorizable, so not all sub-phrases can be acquired and syntactified. Ourmain
purpose is to re-structure parse trees by factorization such that syntactified sub-phrases
can be employed in translation.
With these concepts defined, we now present the re-structuring methods.
253
Computational Linguistics Volume 36, Number 2
Figure 6
Left, right, and head binarizations on the left tree in Figure 4. Tree leaves of nodes JJ and NNP1
are omitted for convenience. Heads are marked with ?. New nonterminals introduced by
binarization are denoted by X-bars.
3.2 Binarizing Syntax Trees
We re-structure parse trees by binarizing the trees. We are going to binarize a tree node
n that dominates r children n1, ..., nr. Binarization is performed by introducing new tree
nodes to dominate a subset of the children nodes. We allow ourselves to form only one
new node at a time to avoid over-generalization. Because labeling is not the concern of
this section, we re-label the newly formed nodes as n.
3.2.1 Simple Binarization Methods. The left binarization of node n (e.g., the NPB in tree
(1) of Figure 6) factorizes the leftmost r ? 1 children by forming a new node n (i.e., the
NPB in tree (1)) to dominate them, leaving the last child nr untouched; and then makes
the new node n the left child of n. The method then recursively left-binarizes the newly
formed node n until two leaves are reached. We left-binarize the left tree in Figure 4 into
Figure 6 (1).
The right binarization of node n factorizes the rightmost r ? 1 children by forming
a new node n (i.e., the NPB in tree (2)) to dominate them, leaving the first child n1
untouched; and then makes the new node n the right child of n. The method then
recursively right-binarizes the newly formed node n. For instance, we right-binarize
the left tree in Figure 4 into Figure 6 (2) and then into Figure 6 (6).
The head binarization of node n left-binarizes n if the head is the first child;
otherwise, it right-binarizes n. We prefer right-binarization to left-binarization when
both are applicable under the head restriction because our initial motivation was to
generalize the NPB-rooted translation rules. As we show in experiments, binarization
of other types of phrases contributes to translation accuracy as well.
Any of these simple binarization methods is easy to implement, but each in itself
is incapable of giving us all the factorizable sub-phrases. Binarizing all the way to the
left, for example, from unbinarized tree to tree (1) and to tree (3) in Figure 6, does not
enable us to acquire a substructure that yields NNP2, NNP3, and their translational
equivalences. To obtain more factorizable sub-phrases, we need to parallel-binarize in
both directions.
254
Wang et al Re-structuring, Re-labeling, and Re-aligning
Figure 7
Packed forest obtained by packing trees (3) and (6) in Figure 6.
3.2.2 Parallel Binarization. Simple binarizations transform a parse tree into another single
parse tree. Parallel binarization transforms a parse tree into a binarization forest, packed
to enable dynamic programming when we extract translation rules from it.
Borrowing terms from parsing semirings (Goodman 1999), a packed forest is com-
posed of additive forest nodes (?-nodes) and multiplicative forest nodes (?-nodes). In
the binarization forest, a ?-node corresponds to a tree node in the unbinarized tree or a
new tree node introduced during tree binarization; and this ?-node composes several
?-nodes, forming a one-level substructure that is observed in the unbinarized tree or
in one of its binarized tree. A ?-node corresponds to alternative ways of binarizing the
same tree node and it contains one or more ?-nodes. The same ?-node can appear in
more than one place in the packed forest, enabling sharing. Figure 7 shows a packed
forest obtained by packing trees (3) and (6) in Figure 6 via the following tree parallel
binarization algorithm.
We use a memoization procedure to recursively parallel-binarize a parse tree.
To parallel-binarize a tree node n that has children n1, ...,nr, we employ the following
steps:
 If r ? 2, parallel-binarize tree nodes n1, ..., nr, producing binarization
?-nodes ?(n1), ..., ?(nr), respectively. Construct node ?(n) as the parent
of ?(n1), ...,?(nr). Construct an additive node ?(n) as the parent of ?(n).
Otherwise, execute the following steps.
 Right-binarize n, if any contiguous2 subset of children n2, ...,nr is
factorizable, by introducing an intermediate tree node labeled as n. We
recursively parallel-binarize n to generate a binarization forest node ?(n).
We also recursively parallel-binarize n1, forming a binarization forest
node ?(n1). We form a multiplicative forest node ?R as the parent of
?(n1) and ?(n).
 Left-binarize n if any contiguous subset of n1, ...,nr?1 is factorizable and
if this subset contains n1. Similar to the previous right-binarization,
we introduce an intermediate tree node labeled as n, recursively
parallel-binarize n to generate a binarization forest node ?(n), recursively
2 For practical purposes we factorize only subsets that cover contiguous spans to avoid introducing
discontiguous constituents. In principle, the algorithm works fine without this condition.
255
Computational Linguistics Volume 36, Number 2
parallel-binarize nr to generate a binarization forest node ?(nr), and then
form a multiplicative forest node ?L as the parent of ?(n) and ?(nr).
 Form an additive node ?(n) as the parent of the two already formed
multiplicative nodes ?L and ?R.
The (left and right) binarization conditions consider any subset to enable the fac-
torization of small constituents. For example, in the left tree of Figure 4, although the
JJ, NNP1, and NNP2 children of the NPB are not factorizable, the subset JJ NNP1 is
factorizable. The binarization from this tree to the tree in Figure 6 (1) serves as a relaying
step for us to factorize JJ and NNP1 in the tree in Figure 6 (3). The left-binarization
condition is stricter than the right-binarization condition to avoid spurious binarization,
that is, to avoid the same subconstituent being reached via both binarizations.
In parallel binarization, nodes are not always binarizable in both directions. For
example, we do not need to right-binarize tree (2) because NNP2 and NNP3 are not
factorizable, and thus cannot be used to form sub-phrases. It is still possible to right-
binarize tree (2) without affecting the correctness of the parallel binarization algorithm,
but that will spuriously increase the branching factor of the search for the rule extrac-
tion, because we will have to expand more tree nodes.
A special version of parallel binarization is the parallel head binarization, where
both the left and the right binarization must respect the head propagation property
at the same time. Parallel head binarization guarantees that new nodes introduced by
binarization always contain the head constituent, which will become convenient when
head-driven syntax-based language models are integrated into a bottom?up decoding
search by intersecting with the trees inferred from the translation model.
Our re-structuring of MT training trees is realized by tree binarization, but this does
not mean that our re-structuring method can factor out phrases covered only by two
(binary) constituents. In fact, a nice property of parallel binarization is that for any
factorizable substructure in the unbinarized tree, we can always find a corresponding
admissible ?-node in the parallel-binarized packed forest, and thus we can always
extract that phrase. A leftmost substructure like the lowest NPB-subtree in tree (3) of
Figure 6 can be made factorizable by several successive left binarizations, resulting in
the ?5(NPB)-node in the packed forest in Figure 7. A substructure in the middle can be
factorized by the composition of several left- and right-binarizations. Therefore, after a
tree is parallel-binarized, to make the sub-phrases available to the MT system, all we
need to do is to extract rules from the admissible nodes in the packed forest. Rules that
can be extracted from the original unrestructured tree can be extracted from the packed
forest as well.
Parallel binarization results in parse forests. Thus translation rules need to be ex-
tracted from training data consisting of (e-forest, f, a)-tuples.
3.3 Extracting Translation Rules from (e-forest, f, a)-tuples
Our algorithm to extract rules from (e-forest, f, a)-tuples is a natural generalization
of the (e-parse, f, a)-based rule extraction algorithm in Galley et al (2006). A similar
problem is also elegantly addressed in Mi and Huang (2008) in detail. The forest-based
rule extraction algorithm takes as input a (e-forest, f, a)-triple, and outputs a derivation
forest (Galley et al 2006), which consists of overlapping translation rules. The algorithm
recursively traverses the e-forest top?down, extracts rules only at admissible e-forest
256
Wang et al Re-structuring, Re-labeling, and Re-aligning
nodes, and transforms e-forest nodes into synchronous derivation-forest nodes via the
following two procedures, depending on which condition is met.
 Condition 1: If we reach an additive e-forest node, for each of its children,
which are multiplicative e-forest nodes, we go to condition 2 to recursively
extract rules from it to obtain a set of multiplicative derivation-forest
nodes, respectively. We form an additive derivation-forest node, and take
these newly produced multiplicative derivation-forest nodes (by going to
condition 2) as children. After this, we return the additive
derivation-forest node.
For instance, at node ?1(NPB) in Figure 7, for each of its children, e-forest
nodes ?2(NPB) and ?11(NPB), we go to condition 2 to extract rules on it,
to form multiplicative derivation forest nodes, ?(R16) and ?(R17) in
Figure 8.
 Condition 2: If we reach a multiplicative e-forest node, we extract a set of
rules rooted at it using the procedure in Galley et al (2006); and for each
rule, we form a multiplicative derivation-forest node, and go to condition 1
to form the additive derivation-forest nodes for the additive frontier
e-forest nodes of the newly extracted rule, and then make these additive
derivation-forest nodes the children of the multiplicative derivation-forest
node. After this, we return a set of multiplicative derivation-forest nodes,
each corresponding to one rule extracted from the multiplicative e-forest
node we just reached.
Figure 8
A synchronous derivation forest built from a (e-forest, f, a) triple. The e-forest is shown in
Figure 7.
257
Computational Linguistics Volume 36, Number 2
For example, at node ?11(NPB) in Figure 7, we extract a rule from it and
form derivation-forest node ?(R17) in Figure 8. We then go to condition 1
to obtain, for each of the additive frontier e-forest nodes (in Figure 7) of
this rule, a derivation-forest node, namely, ?(NNP), ?(NNP), and ?(NPB)
in Figure 8. We make these derivation-forest ?-nodes the children of
derivation-forest node ?(R17).
This procedure transforms the packed e-forest in Figure 7 into a packed synchro-
nous derivation in Figure 8. This algorithm is an extension of the extraction algorithm
in Galley et al (2006), in the sense that we have an extra condition (1) to relay rule
extraction on additive e-forest nodes.
The forest-based rule extraction algorithm produces much larger grammars than
the tree-based one, making it difficult to scale to very large training data. From a
50M-word Chinese-to-English parallel corpus, we can extract more than 300 million
translation rules, while the tree-based rule extraction algorithm gives approximately
100 million. However, the restructured trees from the simple binarization methods are
not guaranteed to give the best trees for syntax-based machine translation. What we
desire is a binarization method that still produces single parse trees, but is able to mix
left binarization and right binarization in the same tree. In the following, we use the EM
algorithm to learn the desirable binarization on the forest of binarization alternatives
proposed by the parallel binarization algorithm.
3.4 Learning How to Binarize Via the EM Algorithm
The basic idea of applying the EM algorithm to choose a re-structuring is as follows. We
perform a set {?} of binarization operations on a parse tree ?. Each binarization ? is
the sequence of binarizations on the necessary (i.e., factorizable) nodes in ? in pre-order.
Each binarization ? results in a restructured tree ??. We extract rules from (??, f, a),
generating a translation model consisting of parameters (i.e., rule probabilities) ?. Our
aim is to first obtain the rule probabilities that are the maximum likelihood estimate
of the training tuples, and then produce the Viterbi binarization tree for each training
tuple.
The probability P(??, f, a) of a (??, f, a)-tuple is what the basic syntax-based trans-
lation model is concerned with. It can be further computed by aggregating the rule
probabilities P(r) in each derivation? in the set of all derivations ? (Galley et al 2004).
That is,
P(??, f, a) =
?
???
?
r??
P(r) (1)
The rule probabilities are estimated by the inside?outside algorithm (Lari and
Young 1990; Knight, Graehl, and May 2008), which needs to run on derivation forests.
Our previous sections have already presented algorithms to transform a parse tree into
a binarization forest, and then transform the (e-forest, f, a)-tuples into derivation forests
(e.g., Figure 8), on which the inside?outside algorithm can then be applied.
In the derivation forests, an additive node labeled as A dominates several mul-
tiplicative nodes, each corresponding to a translation rule resulting from either left
binarization or right binarization of the original structure. We use rule r to either refer
to a rule or to a multiplicative node in the derivation forest. We use root(r) to represent
the root label of the rule, and parent(r) to refer to the additive node that is the parent
258
Wang et al Re-structuring, Re-labeling, and Re-aligning
of the node corresponding to the r. Each rule node (or multiplicative node) dom-
inates several other additive children nodes, and we present the ith child node as
childi(r), among the total number of n children. For example, in Figure 8, for the rule r
corresponding to the left child of the forest root (labeled as NPB), parent(r) is NPB, and
child1(NPB) = r. Based on these notations, we can compute the inside probability ?(A)
of an additive node labeled as A and the outside probability ?(B) of an additive forest
node labeled as B as follows.
?(A) =
?
r?{child(A)}
P(r)?
?
i=1...n
?(childi(r)) (2)
?(B) =
?
r:B?{child(r)}
P(r)? ?(parent(r))?
?
C?{child(r)}?{B}
?(C) (3)
In the expectation step, the contribution of each occurrence of a rule in a derivation-
forest to the total expected count of that rule is computed as
?(parent(r))? P(r)?
?
i=1...n
?(childi(r)) (4)
In the maximization step, we use the expected counts of rules, #r, to update the proba-
bilities of the rules.
P(r) = #r?
rule q:root(q)=root(r) #q
(5)
Because it is well known that applying EM with tree fragments of different sizes
causes overfitting (Johnson 1998a), and because it is also known that syntax MT models
with larger composed rules in the mix significantly outperform rules that minimally
explain the training data (minimal rules) in translation accuracy (Galley et al 2006), we
use minimal rules to construct the derivation forests from (e-binarization-forest, f, a)-
tuples during running of the EM algorithm, but, after the EM re-structuring is finished,
we build the final translation model using composed rules for MT evaluation.
Figure 9 is the actual pipeline that we use for EM binarization. We first generate a
packed e-forest via parallel binarization. We then extract minimal translation rules from
Figure 9
Using the EM algorithm to choose re-structuring.
259
Computational Linguistics Volume 36, Number 2
the (e-forest, f, a)-tuples, producing synchronous derivation forests. We run the inside?
outside algorithm on the derivation forests until convergence. We obtain the Viterbi
derivations and project the English parses from the derivations. Finally, we extract
composed rules using Galley et al (2006)?s (e-tree, f, a)-based rule extraction algorithm.
When extracting composed rules from (e-parse, f, a)-tuples, we use an ?ignoring-X-
node? trick to the rule extraction method in Galley et al (2006) to avoid breaking the
local dependencies captured in complex rules. The trick is that new nodes introduced
by binarization are not counted when computing the rule size limit unless they appear
as the rule roots. The motivation is that newly introduced nodes break the local depen-
dencies, deepening the parses. In Galley et al, a composed rule is extracted only if the
number of internal nodes it contains does not exceed a limit, similar to the phrase length
limit in phrase-based systems. This means that rules extracted from the restructured
trees will be smaller than those from the unrestructured trees, if the X nodes are deleted
from the rules. As shown in Galley et al, smaller rules lose context, and thus give
lower translation accuracy. Ignoring X nodes when computing the rule sizes preserves
the unrestructured rules in the resulting translation model and adds substructures as
bonuses.
3.5 Experimental Results
We carried out experiments to evaluate different tree binarization methods in terms
of translation accuracy for Chinese-to-English translation. The baseline syntax MT sys-
tem was trained on the original, non-restructured trees. We also built one MT system
by training on left-binarizations of training trees, and another by training on EM-
binarizations of training trees.
Table 1 shows the results on end-to-endMT. The bootstrap p-values were computed
for the pairwise BLEU comparison between the EM binarization and the baseline. The
results show that tree binarization improves MT system accuracy, and that EM binariza-
tion outperforms left binarization. The results also show that the EM re-structuring sig-
nificantly outperforms (p <0.05) the no re-structuring baseline on the NIST08 eval set.
The MT improvement by tree re-structuring is also validated by our previous work
(Wang, Knight, and Marcu 2007), in which we reported a 1 BLEU point gain from EM
binarization under other training/testing conditions; other simple binarizationmethods
were examined in that work aswell, showing that simple binarizations also improveMT
accuracy, and that EM binarization consistently outperforms the simple binarization
methods.
Table 1
Translation accuracy versus binarization algorithms. In this and all other tables reporting BLEU
performance, statistically significant improvements over the baseline are highlighted. p = the
paired bootstrap p-value computed between each system and the baseline, showing the level at
which the two systems are significantly different.
EXPERIMENT NIST08 NIST08-NW
BLEU p BLEU p
no binarization (baseline) 29.12 ? 35.33 ?
left binarization 29.35 0.184 35.46 0.360
EM binarization 29.74 0.010 36.12 0.016
260
Wang et al Re-structuring, Re-labeling, and Re-aligning
Table 2
# admissible nodes, # rules versus re-structuring methods.
RE-STRUCTURING METHOD # ADMISSIBLE NODES (M) # RULES (M)
no binarization 13 76.0
left binarization 17.2 153.4
EM binarization 17.4 154.8
We think that these improvements are explained by the fact that tree re-structuring
introduces more admissible trees nodes in the training trees and enables the forming
of additional rules. As a result, re-structuring produces more rules. Table 2 shows the
number of admissible nodes made available by each re-structuring method, as well as
by the baseline. Table 2 also shows the sizes of the resulting grammars.
The EM binarization is able to introduce more admissible nodes because it mixes
both left and right binarizations in the same tree. We computed the binarization biases
learned by the EM algorithm for each nonterminal from the binarization forest of
parallel head binarizations of the training trees (Table 3). Of course, the binarization
bias chosen by left-/right-binarization methods would be 100% deterministic. One
noticeable message from Table 3 is that most of the categories are actually biased toward
left-binarization. The reason might be that the head sub-constituents of most English
categories tend to be on the left.
Johnson (1998b) argues that the more nodes there are in a treebank, the stronger
the independence assumptions implicit in the PCFG model are, and the less accurate
the estimated PCFG will usually be?more nodes break more local dependencies. Our
experiments, on the other hand, show MT accuracy improvement by introducing more
admissible nodes. This initial contradiction actually makes sense. The key is that we use
composed rules to build our final MT system and that we introduce the ?ignoring-X-
node? trick to preserve the local dependencies. More nodes in training trees weaken the
accuracy of a translation model of minimal rules, but boost the accuracy of a translation
model of composed rules.
Table 3
Binarization bias learned by the EM re-structuring method on the model 4 word alignments.
nonterminal left-binarization (%) right-binarization (%)
NP 98 2
NPB 1 99
VP 95 5
PP 86 14
ADJP 67 33
ADVP 76 24
S 94 6
S-C 17 83
SBAR 93 7
QP 89 11
WHNP 98 2
SINV 94 6
CONJP 69 31
261
Computational Linguistics Volume 36, Number 2
4. Re-Labeling Trees for Training
The syntax translation model explains (e-parse, f, a)-tuples by a series of applications
of translation rules. At each derivation step, which rule to apply next depends only
on the nonterminal label of the frontier node being expanded. In the Penn Treebank
annotation, the nonterminal labels are too coarse to encode enough context information
to accurately predict the next translation rule to apply. As a result, using the Penn
Treebank annotation can license ill-formed subtrees (Figure 10). This subtree contains
an error that induces a VP as an SG-C when the head of the VP is the finite verb dis-
cussed. The translation error leads to the ungrammatical ?... confirmed discussed ... ?. This
translation error occurs due to the fact that there is no distinction between finite VPs
and non-finite VPs in Penn Treebank annotation. Monolingual parsing suffers similarly,
but to a lesser degree.
Re-structuring of training trees enables the reuse of sub-constituent structures, but
further introduces new nonterminals and actually reduces the context for rules, thus
making this ?coarse nonterminal? problem more severe. In Figure 11, R23 may be
extracted from a construct like S(S CC S) via tree binarization, and R24 may be extracted
from a construct like S(NP NP-C VP) via tree binarization. Composing R23 and R24
forms the structure in Figure 11(b), which, however, is ill-formed. This wrong structure
in Figure 11(b) yields ungrammatical translations like he likes reading she does not like
reading. Tree binarization enables the reuse of substructures, but causes over-generation
of trees at the same time.
We solve the coarse-nonterminal problem by refining/re-labeling the training tree
labels. Re-labeling is done by enriching the nonterminal label of each tree node based
on its context information.
Re-labeling has already been used in monolingual parsing research to improve
parsing accuracy of PCFGs. We are interested in two types of re-labeling methods:
Linguistically motivated re-labeling (Klein and Manning 2003; Johnson 1998b) enriches
the labels of parser training trees using parent labels, head word tag labels, and/or
sibling labels. Automatic category splitting (Petrov et al 2006) refines a nonterminal
Figure 10
MT output errors due to coarse Penn Treebank annotations. Oval nodes in (b) are rule
overlapping nodes. Subtree (b) is formed by composing the LHSs of R20, R21, and R22.
262
Wang et al Re-structuring, Re-labeling, and Re-aligning
Figure 11
Tree binarization over-generalizes the parse tree. Translation rules R23 and R24 are acquired
from binarized training trees, aiming for reuse of substructures. Composing R23 and R24,
however, results in an ill-formed tree. The new nonterminal S introduced in tree binarization
needs to be refined into different sub-categories to prevent R23 and R24 from being composed.
Automatic category splitting can be employed for refining the S.
by classifying the nonterminal into a fine-grained sub-category, and this sub-classing
is learned via the EM algorithm. Category splitting is realized by several splitting-and-
merging cycles. In each cycle, the nonterminals in the PCFG rules are split by splitting
each nonterminal into two. The EM algorithm is employed to estimate the split PCFG on
the Penn Treebank training trees. After that, 50% of the new nonterminals are merged
based on some loss function, to avoid overfitting.
4.1 Linguistic Re-labeling
In the linguistically motivated approach, we employ the following set of rules to re-label
tree nodes. In our MT training data:
 SPLIT-VP: annotates each VP nodes with its head tag, and then merges all
finite VP forms to a single VPF.
 SPLIT-IN: annotates each IN node with the combination of IN and its
parent node label. IN is frequently overloaded in the Penn Treebank. For
instance, its parent can be PP or SBAR.
These two operations re-label the tree in Figure 12(a1) to Figure 12(b1). Example
rules extracted from these two trees are shown in Figure 12(a2) and Figure 12(b2),
respectively. We apply this re-labeling on the MT training tree nodes, and then acquire
rules from these re-labeled trees. We chose to split only these two categories because
our syntax MT system tends to frequently make parse errors in these two categories,
and because, as shown by Klein and Manning (2003), further refining the VP and IN
categories is very effective in improving monolingual parsing accuracy.
This type of re-labeling fixes the parse error in Figure 10. SPLIT-VP transforms the
R18 root to VPF, and the R17 frontier node to VP.VBN. Thus R17 and R18 can never be
composed, preventing the wrong tree being formed by the translation model.
4.2 Statistical Re-labeling
Our second re-labeling approach is to learn the split categories for the node labels of
the training trees via the EM algorithm, as in Petrov et al (2006). Rather than using
263
Computational Linguistics Volume 36, Number 2
Figure 12
Re-labeling of parse trees.
264
Wang et al Re-structuring, Re-labeling, and Re-aligning
their parser to directly produce category-split parse trees for the MT training data, we
separate the parsing step and the re-labeling step. The re-labeling method is as follows.
1. Run a parser to produce the MT training trees.
2. Binarize the MT training trees via the EM binarization algorithm.
3. Learn an n-way split PCFG from the binarized trees via the algorithm
described in Petrov et al (2006).
4. Produce the Viterbi split annotations on the binarized training trees with
the learned category-split PCFG.
As we mentioned earlier, tree binarization sometimes makes the decoder over-
generalize the trees in the MT outputs, but we still binarize the training trees before
performing category splitting, for two reasons. The first reason is that the improve-
ment on MT accuracy we achieved by tree re-structuring indicates that the benefit
we obtained from structure reuse triumphs the problem of tree over-generalization.
The second is that carrying out category splitting on unbinarized training trees blows
up the grammar?splitting a CFG rule of rank 10 results in 211 split rules. This re-
labeling procedure tries to achieve further improvement by trying to fix the tree over-
generalization problem of re-structuring while preserving the gain we have already
obtained from tree re-structuring.
Figure 12(c1) shows a category-split tree, and Figure 12(c2) shows the minimal xRs
rules extracted from the split tree. In Figure 12(c2), the two VPs (VP-0 and VP-2) now
belong to two different categories and cannot be used in the same context.
In this re-labeling procedure, we separate the re-labeling step from the parsing step,
rather than using a parser like the one in Petrov et al (2006) to directly produce category-
split parse trees on the English corpus. We think that we benefit from this separation in
the following ways: First, this gives us the freedom to choose the parser to produce the
initial trees. Second, this enables us to train the re-labeler on the domains where the MT
system is trained, instead of on the Penn Treebank. Third, this enables us to choose our
own tree binarization methods.
Tree re-labeling fragments the translation rules. Each refined rule now fits in fewer
contexts than its corresponding coarse rule. Re-labeling, however, does not explode
the grammar size, nor does re-labeling deteriorate the reuse of substructures. This
is because the re-labeling (whether linguistic or automatic) results in very consistent
annotations. Table 4 shows the sizes of the translation grammars from different re-
labelings of the training trees, as well as that from the unrelabeled ones.
Table 4
Grammar size vs. re-labeling methods. Re-labeling does not explode the grammar size.
RE-LABELING METHOD # RULES (M) NONTERMINAL SET SIZE
No re-labeling 154.80 144
Linguistically motivated re-labeling 154.97 210
4-way splitting (90% merging) 158.89 178
8-way splitting (90% merging) 160.62 195
4-way splitting (50% merging) 164.15 326
265
Computational Linguistics Volume 36, Number 2
It would be very interesting to perform automatic category splitting with synchro-
nous translation rules and run the EM algorithm on the synchronous derivation forests.
Synchronous category splitting is computationally much more expensive, so we do not
study it here.
4.3 Experimental Results
We ran end-to-end MT experiments by re-labeling the MT training trees. Our two base-
line systems were a syntax MT system with neither re-structuring nor re-labeling, and
a syntax MT system with re-structuring but no re-labeling. The linguistically motivated
re-labeling method was applied directly on the original (unrestructured) training trees,
so that it could be compared to the first baseline. The automatic category splitting re-
labeling method was applied to binarized trees so as to avoid the explosion of the split
grammar, so it is compared to the second baseline. The experiment results are shown in
Table 5.
Both re-labeling methods help MT accuracy. Putting both re-structuring and re-
labeling together results in 0.93 BLEU points improvement on NIST08 set, and 1 BLEU
point improvement on the newswire subset. All p-values are computed between the
re-labeling systems and Baseline1. The improvement made by the linguistically moti-
vated re-labeling method is significant at the 0.05 level. Because the automatic category
splitting is carried out on the top of EM re-structuring and because, as we have already
shown, EM re-structuring significantly improves Baseline1, putting them together re-
sults in better translations with more confidence.
If we compare these results to those in Table 1, we notice that re-structuring tends
to help MT accuracy more than re-labeling. We mentioned earlier that re-structuring
overgeneralizes structures, but enables reuse of substructures. Results in Table 5 and
Table 1 show substructure reuse mitigates structure over-generalization in our tree re-
structuring method.
5. Re-aligning (Tree, String) Pairs for Training
So far, we have improved the English structures in our parsed, aligned training corpus.
We now turn to improving the word alignments.
Some MT systems use the same model for alignment and translation?examples
include Brown et al (1993), Wu (1997), Alshawi, Bangalore, and Douglas (1998), Yamada
and Knight (2001, 2002), and Cohn and Blunsom (2009). Other systems use Brown et al
for alignment, then collect counts for a completely different model, such as Och andNey
Table 5
Impact of re-labeling methods on MT accuracy as measured by BLEU. Four-way splitting was
carried out on EM-binarized trees; thus, it already benefits from tree re-structuring. All p-values
are computed against Baseline1.
EXPERIMENT NIST08 NIST08-NW
BLEU p BLEU p
Baseline1 (no re-structuring and no re-labeling) 29.12 ? 35.33 ?
Linguistically motivated re-labeling 29.57 0.029 35.85 0.050
Baseline2 (EM re-structuring but no re-labeling) 29.74 ? 36.12 ?
4-way splitting (w/ 90% merging) 30.05 0.001 36.42 0.003
266
Wang et al Re-structuring, Re-labeling, and Re-aligning
(2004) or Chiang (2007). Our basic syntax-based system falls into this second category,
as we learn our syntactic translation model from a corpus aligned with word-based
techniques. We would like to inject more syntactic reasoning into the alignment process.
We start by contrasting two generative translation models.
5.1 The Traditional IBM Alignment Model
IBMModel 4 (Brown et al 1993) learns a set of four probability tables to compute P( f |e)
given a foreign sentence f and its target translation e via the following (simplified)
generative story:
1. A fertility y for each word ei in e is chosen with probability Pfert(y|ei).
2. A null word is inserted next to each fertility-expanded word with
probability Pnull.
3. Each token ei in the fertility-expanded word and null string is translated
into some foreign word fi in f with probability Ptrans( fi|ei).
4. The position of each foreign word fi that was translated from ei is changed
by? (which may be positive, negative, or zero) with probability
Pdistortion(?|A(ei),B( fi)), where A and B are functions over the source and
target vocabularies, respectively.
Brown et al (1993) describe an EM algorithm for estimating values for the four
tables in the generative story. With those values in hand, we can calculate the highest-
probability (Viterbi) alignment for any given string pair.
Two scale problems arise in this algorithm. The first is the time complexity of enu-
merating alignments for fractional count collection. This is solved by considering only
a subset of alignments, and by bootstrapping the Ptrans table with a simpler model that
admits fast count collection via dynamic programming, such as IBM Model 1 (Brown
et al 1993) or Aachen HMM (Vogel, Ney, and Tillmann 1996). The second problem is
one of space. In theory, the initial Ptrans table contains a cell for every English word
paired with every Chinese word?this would be infeasible. Fortunately, in practice, the
table can be initialized with only those word pairs observed co-occurring in the parallel
training text.
5.2 A Syntax Re-alignment Model
Our syntax translation model learns a single probability table to compute P(etree, f )
given a foreign sentence f and a parsed target translation etree. In the following gen-
erative story we assume a starting variable with syntactic type v.
1. Choose a rule r to replace v, with probability Prule(r|v).
2. For each variable with syntactic type vi in the partially completed (tree,
string) pair, continue to choose rules ri with probability Prule(ri|vi) to
replace these variables until there are no variables remaining.
We can use this model to explain unaligned (tree, string) pairs from our training
data. With a large enough rule set, any given (tree, string) pair will admit many deriva-
tions. Consider again the example from Figure 1. The particular alignment associated
267
Computational Linguistics Volume 36, Number 2
with that (tree, string) pair yields the minimal rules of Figure 2. A different alignment
yields different rules. Figure 13 shows two other alignments and their corresponding
minimal rules. As noted before, a set of minimal rules in proper sequence forms
a derivation tree of rules that explains the (tree, string) pair. Because rules explain
variable-size fragments (e.g., R35 vs. R6), the possible derivation trees of rules that
explain a sentence pair have varying sizes. The smallest such derivation tree has a single
large rule (which does not appear in Figure 13). When our model chooses a particular
derivation tree of minimal rules to explain a given (tree, string) pair it implicitly chooses
the alignment that produced these rules as well.3 Our model can choose a derivation by
using any of the rules in Figures 13 and 2. We would prefer it select the derivation that
yields the good alignment in Figure 1.
We can also develop an EM learning approach for this model. As in the IBM
approach, we have both time and space issues. Time complexity, as we will see sub-
sequently, is O(mn3), where m is the number of nodes in the English training tree and
n is the length of the corresponding Chinese string. Space is more of a problem. We
would like to initialize EM with all the rules that might conceivably be used to explain
the training data. However, this set is too large to practically enumerate.
To reduce the model space we first create a bootstrap alignment using a simpler
word-based model. Then we acquire a set of minimal translation rules from the (tree,
string, alignment) triples. Armed with these rules, we can discard the word-based
alignments and re-alignwith the syntax translation model.
We summarize the approach described in this section as:
1. Obtain bootstrap alignments for a training corpus using word-based
alignment.
2. Extract minimal rules from the corpus and alignments using GHKM,
noting the partial alignment that is used to extract each rule.
3. Construct derivation forests for each (tree, string) pair, ignoring the
alignments, and run EM to obtain Viterbi derivation trees, then use the
annotated partial alignments to obtain Viterbi alignments.
4. Use the new alignments to re-train the full MT system, this time collecting
composed rules as well as minimal rules.
5.3 EM Training for the Syntax Translation Model
Consider the example of Figure 13 again. The top alignment was the bootstrap align-
ment, and thus prior to any experiment we obtained the corresponding indicated
minimal rule set and derivation. This derivation is reasonable but there are some poorly
motivated rules, from a linguistic standpoint. The Chinese word
??
roughly means
the two shores in this context, but the rule R35 learned from the alignment incorrectly
includes between. However, other sentences in the training corpus have the correct
3 Strictly speaking there is actually a one-to-many mapping between a derivation tree of minimal rules and
the alignment that yields these rules, due to the handling of unaligned words. However, the choice of one
partial alignment over another does not affect results and in practice we impose a one-to-one mapping
between minimal rules and the partial alignments that imply them by selecting the most frequently
observed partial alignment for a given minimal rule.
268
Wang et al Re-structuring, Re-labeling, and Re-aligning
Figure 13
The minimal rules extracted from two different alignments of the sentence in Figure 1.
alignment, which yields rules in Figure 2, such as R8. Figure 2 also contains rules R4
and R6, learned from yet other sentences in the training corpus, which handle the
?
...
?
structure (which roughly translates to in between), thus allowing a derivation which
contains the minimal rule set of Figure 2 and implies the alignment in Figure 1.
EM distributes rule probabilities in such a way as to maximize the probability of the
training corpus. It thus prefers to use one rule many times instead of several different
269
Computational Linguistics Volume 36, Number 2
rules for the same situation over several sentences, if possible. R35 is a possible rule
in 46 of the 329,031 sentence pairs in the training corpus, and R8 is a possible rule in
100 sentence pairs. Well-formed rules are more usable than ill-formed rules and the
partial alignments behind these rules, generally also well-formed, become favored as
well. The top row of Figure 14 contains an example of an alignment learned by the
bootstrap alignment model that includes an incorrect link. Rule R25, which is extracted
from this alignment, is a poor rule. A set of commonly seen rules learned from other
training sentences provide a more likely explanation of the data, and the consequent
alignment omits the spurious link.
Figure 14
The impact of a bad alignment on rule extraction. Including the alignment link indicated by the
dotted line in the example leads to the rule set in the second row. The re-alignment procedure
described in Section 5.2 learns to prefer the rule set at bottom, which omits the bad link.
270
Wang et al Re-structuring, Re-labeling, and Re-aligning
Table 6
Translation performance, grammar size versus the re-alignment algorithm proposed in
Section 5.2, and re-alignment as modified in Section 5.4.
EXPERIMENT NIST08 NIST08-NW # RULES (M)
BLEU p BLEU p
no re-alignment (baseline) 29.12 ? 35.33 ? 76.0
EM re-alignment 29.18 0.411 35.52 0.296 75.1
EM re-alignment with size prior 29.37 0.165 35.96 0.050 110.4
Now we need an EM algorithm for learning the parameters of the rule set that
maximize
?
corpus
P(tree, string). Knight, Graehl, andMay (2008) present a generic such algo-
rithm for tree-to-string transducers that runs in O(mn3) time, as mentioned earlier. The
algorithm consists of two components: DERIV, which is a procedure for constructing
a packed forest of derivation trees of rules that explain a (tree, string) bitext corpus
given that corpus and a rule set, and TRAIN, which is an iterative parameter-setting
procedure.
We initially attempted to use the top-down DERIV algorithm of Knight, Graehl, and
May (2008), but as the constraints of the derivation forests are largely lexical, too much
time was spent on exploring dead-ends. Instead we build derivation forests using the
following sequence of operations:
1. Binarize rules using the synchronous binarization algorithm for
tree-to-string transducers described in Zhang et al (2006).
2. Construct a parse chart with a CKY parser simultaneously constrained on
the foreign string and English tree, similar to the bilingual parsing of Wu
(1997).4
3. Recover all reachable edges by traversing the chart, starting from the
topmost entry.
Because the chart is constructed bottom-up, leaf lexical constraints are encountered
immediately, resulting in a narrower search space and faster running time than the
top-down DERIV algorithm for this application. The Viterbi derivation tree tells us
which English words produce which Chinese words, so we can extract a word-to-word
alignment from it.
Although in principle the re-alignment model and translation model learn parame-
ter weights over the same rule space, in practice we limit the rules used for re-alignment
to the set of minimal rules.
5.4 Adding a Rule Size Prior
An initial re-alignment experiment shows a small rise in BLEU scores from the baseline
(Table 6), but closer inspection of the rules favored by EM implies we can do even better.
4 In the cases where a rule is not synchronous-binarizable, standard left?right binarization is performed
and proper permutation of the disjoint English tree spans must be verified when building the part of the
chart that uses this rule.
271
Computational Linguistics Volume 36, Number 2
EM has a tendency to favor a few large rules over many small rules, even when the
small rules are more useful. Referring to the rules in Figures 2 and 13, note that possible
derivations for (taiwan?s,
?l
)5 are R33, R2?R3, and R38?R40. Clearly the third deriva-
tion is not desirable, and we do not discuss it further. Between the first two derivations,
R2?R3 is preferred over R33, as the conditioning for possessive insertion is not related to
the specific Chinese word being inserted. Of the 1,902 sentences in the training corpus
where this pair is seen, the bootstrap alignments yield the R33 derivation 1,649 times
and the R2?R3 derivation 0 times. Re-alignment does not change the result much; the
new alignments yield the R33 derivation 1,613 times and again never choose R2?R3. The
rules in the second derivation themselves are not rarely seen?R2 is in 13,311 forests
other than those where R33 is seen, and R3 is in 2,500 additional forests. EM gives R2 a
probability of e?7.72?better than 98.7% of rules, and R3 a probability of e?2.96. But R33
receives a probability of e?6.32 and is preferred over the R2?R3 derivation, which has a
combined probability of e?10.68.
The preference for shorter derivations containing large rules over longer derivations
containing small rules is due to a general tendency for EM to prefer derivations with
few atoms. Marcu and Wong (2002) note this preference but consider the phenomenon
a feature, rather than a bug. Zollmann and Sima?an (2005) combat the overfitting aspect
for parsing by using a held-out corpus and a straight maximum likelihood estimate,
rather than EM. DeNero, Bouchard-Co?te?, and Klein (2008) encourage small rules with a
modeling approach; they put a Dirichlet process prior of rule size over their model and
learn the parameters of the geometric distribution of that prior with Gibbs sampling.We
use a simpler modeling approach to accomplish the same goals as DeNero, Bouchard-
Co?te?, and Klein which, although less elegant, is more scalable and does not require a
separate Bayesian inference procedure.
As the probability of a derivation is determined by the product of its atom probabil-
ities, longer derivations with more probabilities to multiply have an inherent disadvan-
tage against shorter derivations, all else being equal. EM is an iterative procedure and
thus such a bias can lead the procedure to converge with artificially raised probabilities
for short derivations and the large rules that constitute them. The relatively rare ap-
plicability of large rules (and thus lower observed partial counts) does not overcome the
inherent advantage of large coverage. To combat this, we introduce size terms into our
generative story, ensuring that all competing derivations for the same sentence contain
the same number of atoms:
1. Choose a rule size s with cost csize(s)
s?1.
2. Choose a rule r (of size s) to replace the start symbol with probability
Prule(r|s, v).
3. For each variable in the partially completed (tree, string) pair, continue to
choose sizes followed by rules, recursively to replace these variables until
there are no variables remaining.
This generative story changes the derivation comparison from R33 vs. R2?R3 to S2?
R33 vs. R2?R3, where S2 is the atom that represents the choice of size 2 (the size of a rule
5 The Chinese gloss is simply ?taiwan?.
272
Wang et al Re-structuring, Re-labeling, and Re-aligning
in this context is the number of non-leaf and non-root nodes in its tree fragment). Note
that the variable number of inclusions implied by the exponent in the generative story
above ensures that all derivations have the same size. For example, a derivation with
one size-3 rule, a derivation with one size-2 and one size-1 rule, and a derivation with
three size-1 rules would each have three atoms. With this revised model that allows for
fair comparison of derivations, the R2?R3 derivation is chosen 1,636 times, and S2?R33
is not chosen. R33 does, however, appear in the translation model, as the expanded rule
extraction described in Section 1 creates R33 by joining R2 and R3.
The probability of size atoms, like that of rule atoms, is decided by EM. The revised
generative story tends to encourage smaller sizes by virtue of the exponent. This does
not, however, simply ensure the largest number of rules per derivation is used in all
cases. Ill-fitting and poorly motivated rules such as R42, R43, and R44 in Figure 13 are
not preferred over R8, even though they are smaller. However, R6 and R8 are preferred
over R35, as the former are useful rules. Although the modified model does not sum to
1, it can nevertheless lead to an improvement in BLEU score.
5.5 Experimental Results
The end-to-end MT experiment used as baseline and described in Sections 3.5 and 4.3
was trained on IBMModel 4 word alignments, obtained by running GIZA, as described
in Section 2. We compared this baseline to an MT system that used alignments obtained
by re-aligning the GIZA alignments using the method of Section 5.2 with the 36 million
word subset of the training corpus used for re-alignment learning. We next compared
the baseline to an MT system that used re-alignments obtained by also incorporating
the size prior described in Section 5.4. As can be seen by the results in Table 6, the size
prior method is needed to obtain reasonable improvement in BLEU. These results are
consistent with those reported in May and Knight (2007), where gains in Chinese and
ArabicMT systemswere observed, though over aweaker baseline andwith less training
data than is used in this work.
6. Combining Techniques
We have thus far seen gains in BLEU score by independent improvements in training
data tree structure, syntax labeling, and alignment. This naturally raises the question
of whether the techniques can be combined, that is, if improvement in one aspect of
training data aids in improvement of another. As reported in Section 4.3 and Table 5,
we were able to improve re-labeling efforts and take advantage of the split-and-merge
technique of Petrov et al (2006) by first re-structuring via the method described in Sec-
tion 3.4. It is unlikely that such re-structuring or re-labeling would aid in a subsequent
re-alignment procedure like that of Section 5.2, for re-structuring changes trees based
on a given alignment, and re-alignment can only change links when multiple instances
of a (subtree, substring) tuple are found in the data with different partial alignments.
Re-structuring beforehand changes the trees over different alignments differently. It is
unlikely that many (subtree, substring) tuples with more than one partial alignment
would remain after a re-structuring.
However, re-structuring may benefit from a prior re-alignment. We do not want re-
structuring decisions to be made over bad alignments, so unifying alignments based
on common syntax should lead EM to make a more confident binarization decision.
273
Computational Linguistics Volume 36, Number 2
Table 7
Summary of experiments in this article, including a combined experiment with re-alignment,
re-structuring, and re-labeling.
EXPERIMENT NIST08 NIST08-NW # RULES (M)
BLEU p BLEU p
Baseline (no binarization, no re-labeling, 29.12 ? 35.33 ? 76.0
Model 4 alignments)
left binarization 29.35 0.184 35.46 0.360 153.4
EM binarization 29.74 0.010 36.12 0.016 154.8
Linguistic re-labeling 29.57 0.029 35.85 0.050 154.97
EM binarization + EM re-labeling 30.05 0.001 36.42 0.003 158.89
(4-way splitting w/ 90% merging)
EM re-alignment 29.18 0.411 35.52 0.296 75.1
Size prior EM re-alignment 29.37 0.165 35.96 0.050 110.4
Size prior EM re-alignment + 30.6 0.001 36.73 0.002 222.0
EM binarization + EM re-labeling
Better re-structuring should in turn lead to better re-labeling, and this should increase
the performance of the overall MT pipeline.
To test this hypothesis we pre-processed alignments using the modified re-
alignment procedure described in Section 5.4. We next used those alignments to obtain
new binarizations of trees following the EM binarization method described in Sec-
tion 3.4. Finally, re-labeling was done on these binarized trees using 4-way splitting with
90% merging, as described in Section 4. The final trees, along with the alignments used
to get these trees and of course the parallel Chinese sentences, were then used as the
training data of our MT pipeline. The results of this combined experiment are shown
in Table 7 along with the other experiments from this article, for ease of comparison.
As can be seen from this table, the progressive improvement of training data leads
to an overall improvement in MT system performance. As noted previously, there
tends to be a correspondence between the number of unique rules extracted and MT
performance. The final combined experiment has the greatest number of unique rules.
The improvements made to syntax and alignment described in this article unify these
two independently determined annotations over the bitext, and this thus leads to more
admissible nodes and a greater ability to extract rules. Such a unification can lead to
over-generalization, as rules lacking sufficient context may be extracted and used to the
system?s detriment. This is why a re-labeling technique is also needed, to ensure that
sufficient rule specificity is maintained.
7. Conclusion
This article considered three modifications to MT training data that encourage im-
proved performance in a state-of-the-art syntactic MT system. The improvements
changed syntactic structure, altered bracket labels, and unified alignment across sen-
tences, and when combined led to an improvement of 1.48 BLEU points over a strong
baseline in Chinese?English translation. The techniques herein described require only
274
Wang et al Re-structuring, Re-labeling, and Re-aligning
the training data used in the original MT task and are thus applicable to a string-to-tree
MT system for any language pair.
Acknowledgments
Some of the results in this article appear
in Wang, Knight, and Marcu (2007) and
May and Knight (2007). The linguistically
motivated re-labeling method is due to
Steve DeNeefe, Kevin Knight, and David
Chiang. The authors also wish to thank
Slav Petrov for his help with the Berkeley
parser, and the anonymous reviewers
for their helpful comments. This research
was supported under DARPA Contract
No. HR0011-06-C-0022, BBN subcontract
9500008412.
References
Alshawi, Hiyan, Srinivas Bangalore,
and Shona Douglas. 1998. Automatic
acquisition of hierarchical transduction
models for machine translation. In
Proceedings of the 36th Annual Meeting of
the Association for Computational Linguistics
(ACL) and 17th International Conference on
Computational Linguistics (COLING) 1998,
pages 41?47, Montre?al.
Brown, Peter F., Stephen A. Della Pietra,
Vincent J. Della Pietra, and Robert L.
Mercer. 1993. The mathematics of
statistical machine translation: Parameter
estimation. Computational Linguistics,
19(2):263?312.
Charniak, Eugene. 2000. A maximum-
entropy-inspired parser. In Proceedings of
the 1st North American Chapter of the
Association for Computational Linguistics
Conference (NAACL), pages 132?139,
Seattle, WA.
Chiang, David. 2007. Hierarchical
phrase-based translation. Computational
Linguistics, 33(2):201?228.
Cohn, Trevor and Phil Blunsom. 2009.
A Bayesian model of syntax-directed
tree to string grammar induction. In
Proceedings of the 2009 Conference on
Empirical Methods in Natural Language
Processing, pages 352?361, Singapore.
Collins, Michael. 1997. Three generative,
lexicalized models for statistical parsing.
In Proceedings of the 35th Annual Meeting of
the Association for Computational Linguistics
(ACL), pages 16?23, Madrid.
Dempster, Arthur P., Nan M. Laird, and
Donald B. Rubin. 1977. Maximum
likelihood from incomplete data via the
EM algorithm. Journal of the Royal
Statistical Society, 39(1):1?38.
DeNeefe, Steve, Kevin Knight, Wei Wang,
and Daniel Marcu. 2007. What can
syntax-based MT learn from phrase-based
MT? In Proceedings of EMNLP?CoNLL-2007,
pages 755?763, Prague.
DeNero, John, Alexandre Bouchard-Co?te?,
and Dan Klein. 2008. Sampling alignment
structure under a Bayesian translation
model. In Proceedings of the 2008 Conference
on Empirical Methods in Natural Language
Processing (EMNLP), pages 314?323,
Honolulu, HI.
Gale, William A. and Geoffrey Sampson.
1996. Good-Turing frequency estimation
without tears. Journal of Quantitative
Linguistics, 2(3):217?237.
Galley, Michel, Jonathan Graehl, Kevin
Knight, Daniel Marcu, Steve DeNeefe,
Wei Wang, and Ignacio Thayer. 2006.
Scalable inference and training of
context-rich syntactic translation models.
In Proceedings of the 21st International
Conference on Computational Linguistics
(COLING) and 44th Annual Meeting of the
Association for Computational Linguistics
(ACL), pages 961?968, Sydney.
Galley, Michel, Mark Hopkins, Kevin Knight,
and Daniel Marcu. 2004. What?s in a
translation rule? In Proceedings of the
Human Language Technology Conference and
the North American Association for
Computational Linguistics (HLT-NAACL),
pages 273?280, Boston, MA.
Good, Irving J. 1953. The population
frequencies of species and the estimation
of population parameters. Biometrika,
40(3):237?264.
Goodman, Joshua. 1999. Semiring parsing.
Computational Linguistics, 25(4):573?605.
Huang, Bryant and Kevin Knight. 2006.
Relabeling syntax trees to improve
syntax-based machine translation
accuracy. In Proceedings of the main
conference on Human Language Technology
Conference of the North American Chapter
of the Association of Computational
Linguistics (NAACL-HLT), pages 240?247,
New York, NY.
Johnson, Mark. 1998a. The DOP estimation
method is biased and inconsistent.
Computational Linguistics, 28(1):71?76.
Johnson, Mark. 1998b. PCFG models of
linguistic tree representations.
Computational Linguistics, 24(4):613?632.
Klein, Dan and Chris Manning. 2003.
Accurate unlexicalized parsing. In
275
Computational Linguistics Volume 36, Number 2
Proceedings of the 40th Annual Meeting of
the Association for Computational Linguistics
(ACL), pages 423?430, Sapporo.
Kneser, Reinhard and Hermann Ney.
1995. Improved backing-off for
m-gram language modeling. In
Proceedings of the International Conference
on Acoustics, Speech, and Signal
Processing (ICASSP) 1995, pages 181?184,
Detroit, MI.
Knight, Kevin and Jonathan Graehl. 2005.
An overview of probabilistic tree
transducers for natural language
processing. In Proceedings of the Sixth
International Conference on Intelligent
Text Processing and Computational
Linguistics (CICLing), pages 1?25,
Mexico City.
Knight, Kevin, Jonathan Graehl, and
Jonathan May. 2008. Training tree
transducers. Computational Linguistics,
34(3):391?427.
Koehn, Philipp. 2004. Statistical significance
tests for machine translation evaluation.
In Proceedings of the 2004 Conference on
Empirical Methods in Natural Language
Processing (EMNLP), pages 388?395,
Barcelona.
Lari, Karim and Steve Young. 1990. The
estimation of stochastic context-free
grammars using the inside-outside
algorithm. Computer Speech and Language,
4:35?56.
Marcu, Daniel and William Wong. 2002.
A phrase-based, joint probability model
for statistical machine translation.
In Proceedings of the 2002 Conference
on Empirical Methods in Natural Language
Processing (EMNLP), pages 133?139,
Philadelphia, PA.
Marcus, Mitchell P., Beatrice Santorini, and
Mary Ann Marcinkiewicz. 1993. Building a
large annotated corpus of English: The
Penn Treebank. Computational Linguistics,
19(2):313?330.
May, Jonathan and Kevin Knight. 2007.
Syntactic re-alignment models for
machine translation. In Proceedings
of the 2007 Joint Conference on Empirical
Methods in Natural Language Processing
and Computational Natural Language
Learning (EMNLP?CoNLL), pages 360?368,
Prague.
Melamed, I. Dan, Giorgio Satta, and
Benjamin Wellington. 2004. Generalized
multitext grammars. In Proceedings of the
42nd Annual Meeting of the Association
for Computational Linguistics (ACL),
pages 662?669, Barcelona.
Mi, Haitao and Liang Huang. 2008.
Forest-based translation rule extraction.
In Proceedings of the 2008 Conference on
Empirical Methods in Natural Language
Processing (EMNLP), pages 206?214,
Honolulu, HI.
Och, Franz and Hermann Ney. 2004. The
alignment template approach to statistical
machine translation. Computational
Linguistics, 30(4):417?449.
Och, Franz Josef. 2003. Minimum error rate
training for machine translation. In
Proceedings of the 40th Annual Meeting of
the Association for Computational Linguistics
(ACL), pages 160?167, Sapporo.
Petrov, Slav, Leon Barrett, Romain
Thibaux, and Dan Klein. 2006. Learning
accurate, compact, and interpretable
tree annotation. In Proceedings of the
21st International Conference on
Computational Linguistics (COLING) and
44th Annual Meeting of the Association
for Computational Linguistics (ACL),
pages 433?440, Sydney.
Stolcke, Andreas. 2002. SRILM?an
extensible language modeling toolkit.
In Proceedings of the 7th International
Conference on Spoken Language
Processing (ICSLP) 2002, pages 901?904,
Denver, CO.
Talbot, David and Miles Osborne. 2007.
Randomised language modelling for
statistical machine translation. In
Proceedings of the 45th Annual Meeting of
the Association of Computational Linguistics
(ACL), pages 512?519, Prague.
Vogel, Stephan, Hermann Ney, and
Christoph Tillmann. 1996. HMM-based
word alignment in statistical translation. In
Proceedings of the International Conference on
Computational Linguistics (COLING) 1996,
pages 836?841, Copenhagen.
Wang, Wei, Kevin Knight, and Daniel
Marcu. 2007. Binarizing syntax trees
to improve syntax-based machine
translation accuracy. In Proceedings
of the 2007 Joint Conference on Empirical
Methods in Natural Language Processing
and Computational Natural Language
Learning (EMNLP?CoNLL), pages 746?754,
Prague.
Wu, Dekai. 1997. Stochastic inversion
transduction grammars and bilingual
parsing of parallel corpora. Computational
Linguistics, 23(3):377?404.
Yamada, Kenji and Kevin Knight. 2001.
A syntax-based statistical translation
model. In Proceedings of the 39th
Annual Meeting of the Association for
276
Wang et al Re-structuring, Re-labeling, and Re-aligning
Computational Linguistics (ACL),
pages 523?530, Toulouse.
Yamada, Kenji and Kevin Knight. 2002.
A decoder for syntax-based statistical
MT. In Proceedings of the 40th Annual
Meeting of the Association for Computational
Linguistics (ACL), pages 303?310,
Philadelphia, PA.
Zhang, Hao, Liang Huang, Daniel Gildea,
and Kevin Knight. 2006. Synchronous
binarization for machine translation.
In Proceedings of the main conference
on Human Language Technology
Conference of the North American Chapter
of the Association of Computational
Linguistics (HLT-NAACL), pages 256?263,
New York, NY.
Zollmann, Andreas and Khalil Sima?an.
2005. A consistent and efficient estimator
for data-oriented parsing. Journal of
Automata, Languages and Combinatorics,
10(2/3):367?388.
277

Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1058?1066,
Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational Linguistics
Efficient Inference Through Cascades of Weighted Tree Transducers
Jonathan May and Kevin Knight
Information Sciences Institute
University of Southern California
Marina del Rey, CA 90292
{jonmay,knight}@isi.edu
Heiko Vogler
Technische Universita?t Dresden
Institut fu?r Theoretische Informatik
01062 Dresden, Germany
heiko.vogler@tu-dresden.de
Abstract
Weighted tree transducers have been pro-
posed as useful formal models for rep-
resenting syntactic natural language pro-
cessing applications, but there has been
little description of inference algorithms
for these automata beyond formal founda-
tions. We give a detailed description of
algorithms for application of cascades of
weighted tree transducers to weighted tree
acceptors, connecting formal theory with
actual practice. Additionally, we present
novel on-the-fly variants of these algo-
rithms, and compare their performance
on a syntax machine translation cascade
based on (Yamada and Knight, 2001).
1 Motivation
Weighted finite-state transducers have found re-
cent favor as models of natural language (Mohri,
1997). In order to make actual use of systems built
with these formalisms we must first calculate the
set of possible weighted outputs allowed by the
transducer given some input, which we call for-
ward application, or the set of possible weighted
inputs given some output, which we call backward
application. After application we can do some in-
ference on this result, such as determining its k
highest weighted elements.
We may also want to divide up our problems
into manageable chunks, each represented by a
transducer. As noted by Woods (1980), it is eas-
ier for designers to write several small transduc-
ers where each performs a simple transformation,
rather than painstakingly construct a single com-
plicated device. We would like to know, then,
the result of transformation of input or output by
a cascade of transducers, one operating after the
other. As we will see, there are various strate-
gies for approaching this problem. We will con-
sider offline composition, bucket brigade applica-
tion, and on-the-fly application.
Application of cascades of weighted string
transducers (WSTs) has been well-studied (Mohri,
1997). Less well-studied but of more recent in-
terest is application of cascades of weighted tree
transducers (WTTs). We tackle application of WTT
cascades in this work, presenting:
? explicit algorithms for application of WTT cas-
cades
? novel algorithms for on-the-fly application of
WTT cascades, and
? experiments comparing the performance of
these algorithms.
2 Strategies for the string case
Before we discuss application of WTTs, it is help-
ful to recall the solution to this problem in the WST
domain. We recall previous formal presentations
of WSTs (Mohri, 1997) and note informally that
they may be represented as directed graphs with
designated start and end states and edges labeled
with input symbols, output symbols, and weights.1
Fortunately, the solution for WSTs is practically
trivial?we achieve application through a series
of embedding, composition, and projection oper-
ations. Embedding is simply the act of represent-
ing a string or regular string language as an iden-
tity WST. Composition of WSTs, that is, generat-
ing a single WST that captures the transformations
of two input WSTs used in sequence, is not at all
trivial, but has been well covered in, e.g., (Mohri,
2009), where directly implementable algorithms
can be found. Finally, projection is another triv-
ial operation?the domain or range language can
be obtained from a WST by ignoring the output or
input symbols, respectively, on its arcs, and sum-
ming weights on otherwise identical arcs. By em-
bedding an input, composing the result with the
given WST, and projecting the result, forward ap-
plication is accomplished.2 We are then left with
a weighted string acceptor (WSA), essentially a
weighted, labeled graph, which can be traversed
1We assume throughout this paper that weights are in
R+ ? {+?}, that the weight of a path is calculated as the
product of the weights of its edges, and that the weight of a
(not necessarily finite) set T of paths is calculated as the sum
of the weights of the paths of T .
2For backward applications, the roles of input and output
are simply exchanged.
1058
A B
a : a / 1 a : a / 1
C
(a) Input string ?a a? embedded in an
identity WST
E
a : b / . 1 a : a / . 9
b : a / . 5 D
a : b / . 4
a : a / . 6
b : a / . 5
b : b / . 5
b : b / . 5
(b) first WST in cascade
a : c / . 6
b
: c / . 7
F
a : d / . 4
b
: d / . 3
(c) second WST in cascade
E F
a : c / . 0 7
a : c / . 5 4
b
: c / . 6 5
b
: d / . 3 5
D F
a : c / . 2 8
a : c / . 3 6
b
: c / . 6 5
b
: d / . 3 5
a : d / . 3 6
a : d / . 0 3 a : d / . 2 4
a : d / . 1 2
(d) Offline composition approach:
Compose the transducers
A D
B D C
D
a : b / . 1
B E
a : a / . 9
C
E
(e) Bucket brigade approach:
Apply WST (b) to WST (a)
A D F
B D F C
D F
d / . 0 3
c
/ . 0 7
B E F
c / . 5 4
C
E F
c
/ . 5 4
c / . 3 6
c
/ . 2 8
c
/ . 0 7
d / . 3 6
d / . 0 3
d / . 3 6
d / . 1 2
d / . 2 4
(f) Result of offline or bucket application
after projection
A D F
B D F C
D F
d / . 0 3
B E F
c
/ . 5 4
C
E F
c / . 3 6
c
/ . 2 8
c
/ . 0 7
d / . 3 6
d / . 1 2
d / . 2 4
(g) Initial on-the-fly
stand-in for (f)
A D F
B D F C
D F
d / . 0 3
B E F
c / . 5 4
C E F
c / . 3 6
c
/ . 2 8
c
/ . 0 7
d / . 3 6
d / . 1 2
d / . 2 4
(h) On-the-fly stand-in after exploring
outgoing edges of state ADF
A D F
B D F C
D F
d / . 0 3
B E F
c / . 5 4
C
E Fc / . 3 6
c
/ . 2 8
c
/ . 0 7
d / . 3 6
d / . 1 2
d / . 2 4
(i) On-the-fly stand-in after best path has been found
Figure 1: Three different approaches to application through cascades of WSTs.
by well-known algorithms to efficiently find the k-
best paths.
Because WSTs can be freely composed, extend-
ing application to operate on a cascade of WSTs
is fairly trivial. The only question is one of com-
position order: whether to initially compose the
cascade into a single transducer (an approach we
call offline composition) or to compose the initial
embedding with the first transducer, trim useless
states, compose the result with the second, and so
on (an approach we call bucket brigade). The ap-
propriate strategy generally depends on the struc-
ture of the individual transducers.
A third approach builds the result incrementally,
as dictated by some algorithm that requests in-
formation about it. Such an approach, which we
call on-the-fly, was described in (Pereira and Ri-
ley, 1997; Mohri, 2009; Mohri et al, 2000). If
we can efficiently calculate the outgoing edges of
a state of the result WSA on demand, without cal-
culating all edges in the entire machine, we can
maintain a stand-in for the result structure, a ma-
chine consisting at first of only the start state of
the true result. As a calling algorithm (e.g., an im-
plementation of Dijkstra?s algorithm) requests in-
formation about the result graph, such as the set of
outgoing edges from a state, we replace the current
stand-in with a richer version by adding the result
of the request. The on-the-fly approach has a dis-
tinct advantage over the other two methods in that
the entire result graph need not be built. A graphi-
cal representation of all three methods is presented
in Figure 1.
3 Application of tree transducers
Now let us revisit these strategies in the setting
of trees and tree transducers. Imagine we have a
tree or set of trees as input that can be represented
as a weighted regular tree grammar3 (WRTG) and
a WTT that can transform that input with some
weight. We would like to know the k-best trees the
WTT can produce as output for that input, along
with their weights. We already know of several
methods for acquiring k-best trees from a WRTG
(Huang and Chiang, 2005; Pauls and Klein, 2009),
so we then must ask if, analogously to the string
case, WTTs preserve recognizability4 and we can
form an application WRTG. Before we begin, how-
ever, we must define WTTs and WRTGs.
3.1 Preliminaries5
A ranked alphabet is a finite set ? such that ev-
ery member ? ? ? has a rank rk(?) ? N. We
call ?(k) ? ?, k ? N the set of those ? ? ?
such that rk(?) = k. The set of variables is de-
notedX = {x1, x2, . . .} and is assumed to be dis-
joint from any ranked alphabet used in this paper.
We use ? to denote a symbol of rank 0 that is not
in any ranked alphabet used in this paper. A tree
t ? T? is denoted ?(t1, . . . , tk) where k ? 0,
? ? ?(k), and t1, . . . , tk ? T?. For ? ? ?(0) we
3This generates the same class of weighted tree languages
as weighted tree automata, the direct analogue of WSAs, and
is more useful for our purposes.
4A weighted tree language is recognizable iff it can be
represented by a wrtg.
5The following formal definitions and notations are
needed for understanding and reimplementation of the pre-
sented algorithms, but can be safely skipped on first reading
and consulted when encountering an unfamiliar term.
1059
write ? ? T? as shorthand for ?(). For every set
S disjoint from ?, let T?(S) = T??S , where, for
all s ? S, rk(s) = 0.
We define the positions of a tree
t = ?(t1, . . . , tk), for k ? 0, ? ? ?(k),
t1, . . . , tk ? T?, as a set pos(t) ? N? such that
pos(t) = {?} ? {iv | 1 ? i ? k, v ? pos(ti)}.
The set of leaf positions lv(t) ? pos(t) are those
positions v ? pos(t) such that for no i ? N,
vi ? pos(t). We presume standard lexicographic
orderings < and ? on pos.
Let t, s ? T? and v ? pos(t). The label of t
at position v, denoted by t(v), the subtree of t at
v, denoted by t|v, and the replacement at v by s,
denoted by t[s]v, are defined as follows:
1. For every ? ? ?(0), ?(?) = ?, ?|? = ?, and
?[s]? = s.
2. For every t = ?(t1, . . . , tk) such that
k = rk(?) and k ? 1, t(?) = ?, t|? = t,
and t[s]? = s. For every 1 ? i ? k and
v ? pos(ti), t(iv) = ti(v), t|iv = ti|v, and
t[s]iv = ?(t1, . . . , ti?1, ti[s]v, ti+1, . . . , tk).
The size of a tree t, size (t) is |pos(t)|, the car-
dinality of its position set. The yield set of a tree
is the set of labels of its leaves: for a tree t, yd (t)
= {t(v) | v ? lv(t)}.
Let A and B be sets. Let ? : A ? T?(B)
be a mapping. We extend ? to the mapping ? :
T?(A)? T?(B) such that for a ?A, ?(a) = ?(a)
and for k ? 0, ? ? ?(k), and t1, . . . , tk ? T?(A),
?(?(t1, . . . , tk)) = ?(?(t1), . . . , ?(tk)). We indi-
cate such extensions by describing ? as a substi-
tution mapping and then using ? without further
comment.
We use R+ to denote the set {w ? R | w ? 0}
and R?+ to denote R+ ? {+?}.
Definition 3.1 (cf. (Alexandrakis and Bozapa-
lidis, 1987)) A weighted regular tree grammar
(WRTG) is a 4-tuple G = (N,?, P, n0) where:
1. N is a finite set of nonterminals, with n0 ? N
the start nonterminal.
2. ? is a ranked alphabet of input symbols, where
? ?N = ?.
3. P is a tuple (P ?, pi), where P ? is a finite set
of productions, each production p of the form
n ?? u, n ? N , u ? T?(N), and pi : P ? ? R+
is a weight function of the productions. We will
refer to P as a finite set of weighted produc-
tions, each production p of the form n
pi(p)
??? u.
A production p is a chain production if it is
of the form ni
w
?? nj , where ni, nj ? N .6
6In (Alexandrakis and Bozapalidis, 1987), chain produc-
tions are forbidden in order to avoid infinite summations. We
explicitly allow such summations.
A WRTG G is in normal form if each produc-
tion is either a chain production or is of the
form n
w
?? ?(n1, . . . , nk) where ? ? ?(k) and
n1, . . . , nk ? N .
For WRTG G = (N,?, P, n0), s, t, u ? T?(N),
n ? N , and p ? P of the form n
w
?? u, we
obtain a derivation step from s to t by replacing
some leaf nonterminal in s labeled n with u. For-
mally, s ?pG t if there exists some v ? lv(s)
such that s(v) = n and s[u]v = t. We say this
derivation step is leftmost if, for all v? ? lv(s)
where v? < v, s(v?) ? ?. We henceforth as-
sume all derivation steps are leftmost. If, for
some m ? N, pi ? P , and ti ? T?(N) for all
1 ? i ? m, n0 ?p1 t1 . . . ?pm tm, we say
the sequence d = (p1, . . . , pm) is a derivation
of tm in G and that n0 ?? tm; the weight of d
is wt(d) = pi(p1) ? . . . ? pi(pm). The weighted
tree language recognized by G is the mapping
LG : T? ? R?+ such that for every t ? T?, LG(t)
is the sum of the weights of all (possibly infinitely
many) derivations of t in G. A weighted tree lan-
guage f : T? ? R?+ is recognizable if there is a
WRTG G such that f = LG.
We define a partial ordering  on WRTGs
such that for WRTGs G1 = (N1,?, P1, n0) and
G2 = (N2,?, P2, n0), we say G1  G2 iff
N1 ? N2 and P1 ? P2, where the weights are
preserved.
Definition 3.2 (cf. Def. 1 of (Maletti, 2008))
A weighted extended top-down tree transducer
(WXTT) is a 5-tupleM = (Q,?,?, R, q0) where:
1. Q is a finite set of states.
2. ? and ? are the ranked alphabets of in-
put and output symbols, respectively, where
(? ??) ?Q = ?.
3. R is a tuple (R?, pi), where R? is a finite set
of rules, each rule r of the form q.y ?? u for
q ? Q, y ? T?(X), and u ? T?(Q ? X).
We further require that no variable x ? X ap-
pears more than once in y, and that each vari-
able appearing in u is also in y. Moreover,
pi : R? ? R?+ is a weight function of the
rules. As for WRTGs, we refer to R as a finite
set of weighted rules, each rule r of the form
q.y
pi(r)
??? u.
A WXTT is linear (respectively, nondeleting)
if, for each rule r of the form q.y
w
?? u, each
x ? yd (y) ? X appears at most once (respec-
tively, at least once) in u. We denote the class
of all WXTTs as wxT and add the letters L and N
to signify the subclasses of linear and nondeleting
WTT, respectively. Additionally, if y is of the form
?(x1, . . . , xk), we remove the letter ?x? to signify
1060
the transducer is not extended (i.e., it is a ?tradi-
tional? WTT (Fu?lo?p and Vogler, 2009)).
For WXTT M = (Q,?,?, R, q0), s, t ? T?(Q
? T?), and r ? R of the form q.y
w
?? u, we obtain
a derivation step from s to t by replacing some
leaf of s labeled with q and a tree matching y by a
transformation of u, where each instance of a vari-
able has been replaced by a corresponding subtree
of the y-matching tree. Formally, s?rM t if there
is a position v ? pos(s), a substitution mapping
? : X ? T?, and a rule q.y
w
?? u ? R such that
s(v) = (q, ?(y)) and t = s[??(u)]v, where ?? is
a substitution mapping Q ? X ? T?(Q ? T?)
defined such that ??(q?, x) = (q?, ?(x)) for all
q? ? Q and x ? X . We say this derivation step
is leftmost if, for all v? ? lv(s) where v? < v,
s(v?) ? ?. We henceforth assume all derivation
steps are leftmost. If, for some s ? T?, m ? N,
ri ? R, and ti ? T?(Q ? T?) for all 1 ? i ? m,
(q0, s) ?r1 t1 . . . ?rm tm, we say the sequence
d = (r1, . . . , rm) is a derivation of (s, tm) in M ;
the weight of d is wt(d) = pi(r1) ? . . . ? pi(rm).
The weighted tree transformation recognized by
M is the mapping ?M : T? ? T? ? R?+ , such
that for every s ? T? and t ? T?, ?M (s, t) is the
sum of the weights of all (possibly infinitely many)
derivations of (s, t) inM . The composition of two
weighted tree transformations ? : T??T? ? R?+
and ? : T??T? ? R?+ is the weighted tree trans-
formation (? ;?) : T? ? T? ?R?+ where for every
s ? T? and u ? T?, (? ;?)(s, u) =
?
t?T?
?(s, t)
? ?(t, u).
3.2 Applicable classes
We now consider transducer classes where recog-
nizability is preserved under application. Table 1
presents known results for the top-down tree trans-
ducer classes described in Section 3.1. Unlike
the string case, preservation of recognizability is
not universal or symmetric. This is important for
us, because we can only construct an application
WRTG, i.e., a WRTG representing the result of ap-
plication, if we can ensure that the language gen-
erated by application is in fact recognizable. Of
the types under consideration, only wxLNT and
wLNT preserve forward recognizability. The two
classes marked as open questions and the other
classes, which are superclasses of wNT, do not or
are presumed not to. All subclasses of wxLT pre-
serve backward recognizability.7 We do not con-
sider cases where recognizability is not preserved
in the remainder of this paper. If a transducer M
of a class that preserves forward recognizability is
applied to a WRTG G, we can call the forward ap-
7Note that the introduction of weights limits recognizabil-
ity preservation considerably. For example, (unweighted) xT
preserves backward recognizability.
plication WRTG M(G). and ifM preserves back-
ward recognizability, we can call the backward ap-
plication WRTG M(G)/.
Now that we have explained the application
problem in the context of weighted tree transduc-
ers and determined the classes for which applica-
tion is possible, let us consider how to build for-
ward and backward application WRTGs. Our ba-
sic approach mimics that taken for WSTs by us-
ing an embed-compose-project strategy. As in
string world, if we can embed the input in a trans-
ducer, compose with the given transducer, and
project the result, we can obtain the application
WRTG. Embedding a WRTG in a wLNT is a triv-
ial operation?if the WRTG is in normal form and
chain production-free,8 for every production of the
form n
w
?? ?(n1, . . . , nk), create a rule of the form
n.?(x1, . . . , xk)
w
?? ?(n1.x1, . . . , nk.xk). Range
projection of a wxLNT is also trivial?for every
q ? Q and u ? T?(Q ? X) create a production
of the form q
w
?? u? where u? is formed from u
by replacing all leaves of the form q.x with the
leaf q, i.e., removing references to variables, and
w is the sum of the weights of all rules of the form
q.y ?? u in R.9 Domain projection for wxLT is
best explained by way of example. The left side of
a rule is preserved, with variables leaves replaced
by their associated states from the right side. So,
the rule q1.?(?(x1), x2)
w
?? ?(q2.x2, ?(?, q3.x1))
would yield the production q1
w
?? ?(?(q3), q2) in
the domain projection. However, a deleting rule
such as q1.?(x1, x2)
w
?? ?(q2.x2) necessitates the
introduction of a new nonterminal ? that can gen-
erate all of T? with weight 1.
The only missing piece in our embed-compose-
project strategy is composition. Algorithm 1,
which is based on the declarative construction of
Maletti (2006), generates the syntactic composi-
tion of a wxLT and a wLNT, a generalization
of the basic composition construction of Baker
(1979). It calls Algorithm 2, which determines
the sequences of rules in the second transducer
that match the right side of a single rule in the
first transducer. Since the embedded WRTG is of
type wLNT, it may be either the first or second
argument provided to Algorithm 1, depending on
whether the application is forward or backward.
We can thus use the embed-compose-project strat-
egy for forward application of wLNT and back-
ward application of wxLT and wxLNT. Note that
we cannot use this strategy for forward applica-
8Without loss of generality we assume this is so, since
standard algorithms exist to remove chain productions
(Kuich, 1998; E?sik and Kuich, 2003; Mohri, 2009) and con-
vert into normal form (Alexandrakis and Bozapalidis, 1987).
9Finitely many such productions may be formed.
1061
tion of wxLNT, even though that class preserves
recognizability.
Algorithm 1 COMPOSE
1: inputs
2: wxLTM1 = (Q1,?,?, R1, q10)
3: wLNTM2 = (Q2,?,?, R2, q20)
4: outputs
5: wxLTM3 = ((Q1?Q2),?,?, R3, (q10 , q20)) such
thatM3 = (?M1 ; ?M2).
6: complexity
7: O(|R1|max(|R2|size(u?), |Q2|)), where u? is the
largest right side tree in any rule in R1
8: Let R3 be of the form (R?3, pi)
9: R3 ? (?, ?)
10: ?? {(q10 , q20)} {seen states}
11: ?? {(q10 , q20)} {pending states}
12: while ? 6= ? do
13: (q1, q2)?any element of ?
14: ?? ? \ {(q1, q2)}
15: for all (q1.y
w1??? u) ? R1 do
16: for all (z, w2) ? COVER(u,M2, q2) do
17: for all (q, x) ? yd (z)? ((Q1?Q2)?X) do
18: if q 6? ? then
19: ?? ? ? {q}
20: ?? ? ? {q}
21: r ? ((q1, q2).y ?? z)
22: R?3 ? R
?
3 ? {r}
23: pi(r)? pi(r) + (w1 ? w2)
24: return M3
4 Application of tree transducer cascades
What about the case of an input WRTG and a cas-
cade of tree transducers? We will revisit the three
strategies for accomplishing application discussed
above for the string case.
In order for offline composition to be a viable
strategy, the transducers in the cascade must be
closed under composition. Unfortunately, of the
classes that preserve recognizability, only wLNT
is closed under composition (Ge?cseg and Steinby,
1984; Baker, 1979; Maletti et al, 2009; Fu?lo?p and
Vogler, 2009).
However, the general lack of composability of
tree transducers does not preclude us from con-
ducting forward application of a cascade. We re-
visit the bucket brigade approach, which in Sec-
tion 2 appeared to be little more than a choice of
composition order. As discussed previously, ap-
plication of a single transducer involves an embed-
ding, a composition, and a projection. The embed-
ded WRTG is in the class wLNT, and the projection
forms another WRTG. As long as every transducer
in the cascade can be composed with a wLNT
to its left or right, depending on the application
type, application of a cascade is possible. Note
that this embed-compose-project process is some-
what more burdensome than in the string case. For
strings, application is obtained by a single embed-
ding, a series of compositions, and a single projec-
Algorithm 2 COVER
1: inputs
2: u ? T?(Q1 ?X)
3: wTM2 = (Q2,?,?, R2, q20)
4: state q2 ? Q2
5: outputs
6: set of pairs (z, w) with z ? T?((Q1 ? Q2) ? X)
formed by one or more successful runs on u by rules
in R2, starting from q2, and w ? R?+ the sum of the
weights of all such runs.
7: complexity
8: O(|R2|size(u))
9: if u(?) is of the form (q1, x) ? Q1 ?X then
10: zinit ? ((q1, q2), x)
11: else
12: zinit ? ?
13: ?last ? {(zinit, {((?, ?), q2)}, 1)}
14: for all v ? pos(u) such that u(v) ? ?(k) for some
k ? 0 in prefix order do
15: ?v ? ?
16: for all (z, ?, w) ? ?last do
17: for all v? ? lv(z) such that z(v?) = ? do
18: for all (?(v, v?).u(v)(x1, . . . , xk)
w?
??h)?R2
do
19: ?? ? ?
20: Form substitution mapping ? : (Q2 ? X)
? T?((Q1 ? Q2 ?X) ? {?}).
21: for i = 1 to k do
22: for all v?? ? pos(h) such that
h(v??) = (q?2, xi) for some q
?
2 ? Q2 do
23: ??(vi, v?v??)? q?2
24: if u(vi) is of the form
(q1, x) ? Q1 ?X then
25: ?(q?2, xi)? ((q1, q
?
2), x)
26: else
27: ?(q?2, xi)? ?
28: ?v ? ?v ? {(z[?(h)]v? , ?
?, w ? w?)}
29: ?last ? ?v
30: Z ? {z | (z, ?, w) ? ?last}
31: return {(z,
X
(z,?,w)??last
w) | z ? Z}
tion, whereas application for trees is obtained by a
series of (embed, compose, project) operations.
4.1 On-the-fly algorithms
We next consider on-the-fly algorithms for ap-
plication. Similar to the string case, an on-the-
fly approach is driven by a calling algorithm that
periodically needs to know the productions in a
WRTG with a common left side nonterminal. The
embed-compose-project approach produces an en-
tire application WRTG before any inference al-
gorithm is run. In order to admit an on-the-fly
approach we describe algorithms that only gen-
erate those productions in a WRTG that have a
given left nonterminal. In this section we ex-
tend Definition 3.1 as follows: a WRTG is a 6-
tuple G = (N,?, P, n0,M,G) where N,?, P,
and n0 are defined as in Definition 3.1, and either
M = G = ?,10 orM is a wxLNT and G is a nor-
mal form, chain production-free WRTG such that
10In which case the definition is functionally unchanged
from before.
1062
type preserved? source
w[x]T No See w[x]NT
w[x]LT OQ (Maletti, 2009)
w[x]NT No (Ge?cseg and Steinby, 1984)
wxLNT Yes (Fu?lo?p et al, 2010)
wLNT Yes (Kuich, 1999)
(a) Preservation of forward recognizability
type preserved? source
w[x]T No See w[x]NT
w[x]LT Yes (Fu?lo?p et al, 2010)
w[x]NT No (Maletti, 2009)
w[x]LNT Yes See w[x]LT
(b) Preservation of backward recognizability
Table 1: Preservation of forward and backward recognizability for various classes of top-down tree
transducers. Here and elsewhere, the following abbreviations apply: w = weighted, x = extended LHS, L
= linear, N = nondeleting, OQ = open question. Square brackets include a superposition of classes. For
example, w[x]T signifies both wxT and wT.
Algorithm 3 PRODUCE
1: inputs
2: WRTG Gin = (Nin,?, Pin, n0,M,G) such
that M = (Q,?,?, R, q0) is a wxLNT and
G = (N,?, P, n?0,M
?, G?) is a WRTG in normal
form with no chain productions
3: nin ? Nin
4: outputs
5: WRTG Gout = (Nout, ?, Pout, n0,M,G), such that
Gin  Gout and
(nin
w
?? u) ? Pout? (nin
w
?? u) ?M(G).
6: complexity
7: O(|R||P |size(y?)), where y? is the largest left side tree
in any rule in R
8: if Pin contains productions of the form nin
w
?? u then
9: return Gin
10: Nout ? Nin
11: Pout ? Pin
12: Let nin be of the form (n, q), where n ? N and q ? Q.
13: for all (q.y
w1??? u) ? R do
14: for all (?, w2) ? REPLACE(y,G, n) do
15: Form substitution mapping ? : Q ? X ?
T?(N ?Q) such that, for all v ? yd (y) and q? ?
Q, if there exist n? ?N and x ?X such that ?(v)
= n? and y(v) = x, then ?(q?, x) = (n?, q?).
16: p? ? ((n, q)
w1?w2????? ?(u))
17: for all p ? NORM(p?, Nout) do
18: Let p be of the form n0
w
?? ?(n1, . . . , nk) for
? ? ?(k).
19: Nout ? Nout ? {n0, . . . , nk}
20: Pout ? Pout ? {p}
21: return CHAIN-REM(Gout)
G M(G).. In the latter case, G is a stand-in for
M(G)., analogous to the stand-ins for WSAs and
WSTs described in Section 2.
Algorithm 3, PRODUCE, takes as input a
WRTG Gin = (Nin,?, Pin, n0,M,G) and a de-
sired nonterminal nin and returns another WRTG,
Gout that is different from Gin in that it has more
productions, specifically those beginning with nin
that are in M(G).. Algorithms using stand-ins
should call PRODUCE to ensure the stand-in they
are using has the desired productions beginning
with the specific nonterminal. Note, then, that
PRODUCE obtains the effect of forward applica-
Algorithm 4 REPLACE
1: inputs
2: y ? T?(X)
3: WRTG G = (N,?, P, n0,M,G) in normal form,
with no chain productions
4: n ? N
5: outputs
6: set ? of pairs (?, w) where ? is a mapping
pos(y) ? N and w ? R?+ , each pair indicating
a successful run on y by productions in G, starting
from n, and w is the weight of the run.
7: complexity
8: O(|P |size(y))
9: ?last ? {({(?, n)}, 1)}
10: for all v ? pos(y) such that y(v) 6? X in prefix order
do
11: ?v ? ?
12: for all (?, w) ? ?last do
13: ifM 6= ? and G 6= ? then
14: G? PRODUCE(G, ?(v))
15: for all (?(v) w
?
?? y(v)(n1, . . . , nk)) ? P do
16: ?v ? ?v?{(??{(vi, ni), 1 ? i ? k}, w?w?)}
17: ?last ? ?v
18: return ?last
Algorithm 5 MAKE-EXPLICIT
1: inputs
2: WRTG G = (N,?, P, n0,M,G) in normal form
3: outputs
4: WRTG G? = (N ?,?, P ?, n0,M,G), in normal form,
such that ifM 6= ? andG 6= ?, LG? = LM(G). , and
otherwise G? = G.
5: complexity
6: O(|P ?|)
7: G? ? G
8: ?? {n0} {seen nonterminals}
9: ?? {n0} {pending nonterminals}
10: while ? 6= ? do
11: n?any element of ?
12: ?? ? \ {n}
13: ifM 6= ? and G 6= ? then
14: G? ? PRODUCE(G?, n)
15: for all (n w?? ?(n1, . . . , nk)) ? P ? do
16: for i = 1 to k do
17: if ni 6? ? then
18: ?? ? ? {ni}
19: ?? ? ? {ni}
20: return G?
1063
g0
g0
w1??? ?(g0, g1)
g0
w2??? ? g1
w3??? ?
(a) Input WRTG G
a0
a0.?(x1, x2)
w4??? ?(a0.x1, a1.x2)
a0.?(x1, x2)
w5??? ?(a2.x1, a1.x2)
a0.?
w6??? ? a1.?
w7??? ? a2.?
w8??? ?
(b) First transducerMA in the cascade
b0
b0.?(x1, x2)
w9??? ?(b0.x1, b0.x2)
b0.?
w10??? ?
(c) Second transducerMB in the cascade
g0a0
w1?w4????? ?(g0a0, g1a1)
g0a0
w1?w5????? ?(g0a2, g1a1)
g0a0
w2?w6????? ? g1a1
w3?w7????? ?
(d) Productions ofMA(G). built as a consequence
of building the completeMB(MA(G).).
g0a0b0
g0a0b0
w1?w4?w9??????? ?(g0a0b0, g1a1b0)
g0a0b0
w2?w6?w10???????? ? g1a1b0
w3?w7?w10???????? ?
(e) CompleteMB(MA(G).).
Figure 2: Forward application through a cascade
of tree transducers using an on-the-fly method.
tion in an on-the-fly manner.11 It makes calls to
REPLACE, which is presented in Algorithm 4, as
well as to a NORM algorithm that ensures normal
form by replacing a single production not in nor-
mal form with several normal-form productions
that can be combined together (Alexandrakis and
Bozapalidis, 1987) and a CHAIN-REM algorithm
that replaces a WRTG containing chain productions
with an equivalent WRTG that does not (Mohri,
2009).
As an example of stand-in construction, con-
sider the invocation PRODUCE(G1, g0a0), where
G1 = ({g0a0}, {?, ?, ?, ?}, ?, g0a0, MA, G), G
is in Figure 2a,12 and MA is in 2b. The stand-in
WRTG that is output contains the first three of the
four productions in Figure 2d.
To demonstrate the use of on-the-fly application
in a cascade, we next show the effect of PRO-
DUCE when used with the cascadeG?MA ?MB ,
where MB is in Figure 2c. Our driving al-
gorithm in this case is Algorithm 5, MAKE-
11Note further that it allows forward application of class
wxLNT, something the embed-compose-project approach did
not allow.
12By convention the initial nonterminal and state are listed
first in graphical depictions of WRTGs and WXTTs.
rJJ.JJ(x1, x2, x3) ?? JJ(rDT.x1, rJJ.x2, rVB.x3)
rVB.VB(x1, x2, x3) ?? VB(rNNPS.x1, rNN.x3, rVB.x2)
t.?gentle? ?? ?gentle?
(a) Rotation rules
iVB.NN(x1, x2) ?? NN(INS iNN.x1, iNN.x2)
iVB.NN(x1, x2) ?? NN(iNN.x1, iNN.x2)
iVB.NN(x1, x2) ?? NN(iNN.x1, iNN.x2, INS)
(b) Insertion rules
t.VB(x1, x2, x3) ?? X(t.x1, t.x2, t.x3)
t.?gentleman? ?? j1
t.?gentleman? ?? EPS
t.INS ?? j1
t.INS ?? j2
(c) Translation rules
Figure 3: Example rules from transducers used
in decoding experiment. j1 and j2 are Japanese
words.
EXPLICIT, which simply generates the full ap-
plication WRTG using calls to PRODUCE. The
input to MAKE-EXPLICIT is G2 = ({g0a0b0},
{?, ?}, ?, g0a0b0,MB ,G1).13 MAKE-EXPLICIT
calls PRODUCE(G2, g0a0b0). PRODUCE then
seeks to cover b0.?(x1, x2)
w9?? ?(b0.x1, b0.x2)
with productions from G1, which is a stand-in for
MA(G).. At line 14 of REPLACE, G1 is im-
proved so that it has the appropriate productions.
The productions of MA(G). that must be built
to form the complete MB(MA(G).). are shown
in Figure 2d. The complete MB(MA(G).). is
shown in Figure 2e. Note that because we used
this on-the-fly approach, we were able to avoid
building all the productions in MA(G).; in par-
ticular we did not build g0a2
w2?w8????? ?, while a
bucket brigade approach would have built this pro-
duction. We have also designed an analogous on-
the-fly PRODUCE algorithm for backward appli-
cation on linear WTT.
We have now defined several on-the-fly and
bucket brigade algorithms, and also discussed the
possibility of embed-compose-project and offline
composition strategies to application of cascades
of tree transducers. Tables 2a and 2b summa-
rize the available methods of forward and back-
ward application of cascades for recognizability-
preserving tree transducer classes.
5 Decoding Experiments
The main purpose of this paper has been to
present novel algorithms for performing applica-
tion. However, it is important to demonstrate these
algorithms on real data. We thus demonstrate
bucket-brigade and on-the-fly backward applica-
tion on a typical NLP task cast as a cascade of
wLNT. We adapt the Japanese-to-English transla-
13Note that G2 is the initial stand-in for MB(MA(G).).,
since G1 is the initial stand-in forMA(G)..
1064
method WST wxLNT wLNT
oc
?
?
?
bb
?
?
?
otf
? ? ?
(a) Forward application
method WST wxLT wLT wxLNT wLNT
oc
?
? ? ?
?
bb
? ? ? ? ?
otf
? ? ? ? ?
(b) Backward application
Table 2: Transducer types and available methods of forward and backward application of a cascade.
oc = offline composition, bb = bucket brigade, otf = on the fly.
tion model of Yamada and Knight (2001) by trans-
forming it from an English-tree-to-Japanese-string
model to an English-tree-to-Japanese-tree model.
The Japanese trees are unlabeled, meaning they
have syntactic structure but all nodes are labeled
?X?. We then cast this modified model as a cas-
cade of LNT tree transducers. Space does not per-
mit a detailed description, but some example rules
are in Figure 3. The rotation transducer R, a sam-
ple of which is in Figure 3a, has 6,453 rules, the
insertion transducer I, Figure 3b, has 8,122 rules,
and the translation transducer, T , Figure 3c, has
37,311 rules.
We add an English syntax language model L to
the cascade of transducers just described to bet-
ter simulate an actual machine translation decod-
ing task. The language model is cast as an iden-
tity WTT and thus fits naturally into the experimen-
tal framework. In our experiments we try several
different language models to demonstrate varying
performance of the application algorithms. The
most realistic language model is a PCFG. Each
rule captures the probability of a particular se-
quence of child labels given a parent label. This
model has 7,765 rules.
To demonstrate more extreme cases of the use-
fulness of the on-the-fly approach, we build a lan-
guage model that recognizes exactly the 2,087
trees in the training corpus, each with equal
weight. It has 39,455 rules. Finally, to be ultra-
specific, we include a form of the ?specific? lan-
guage model just described, but only allow the
English counterpart of the particular Japanese sen-
tence being decoded in the language.
The goal in our experiments is to apply a single
tree t backward through the cascadeL?R?I?T ?t
and find the 1-best path in the application WRTG.
We evaluate the speed of each approach: bucket
brigade and on-the-fly. The algorithm we use to
obtain the 1-best path is a modification of the k-
best algorithm of Pauls and Klein (2009). Our al-
gorithm finds the 1-best path in a WRTG and ad-
mits an on-the-fly approach.
The results of the experiments are shown in
Table 3. As can be seen, on-the-fly application
is generally faster than the bucket brigade, about
double the speed per sentence in the traditional
LM type method time/sentence
pcfg bucket 28s
pcfg otf 17s
exact bucket >1m
exact otf 24s
1-sent bucket 2.5s
1-sent otf .06s
Table 3: Timing results to obtain 1-best from ap-
plication through a weighted tree transducer cas-
cade, using on-the-fly vs. bucket brigade back-
ward application techniques. pcfg = model rec-
ognizes any tree licensed by a pcfg built from
observed data, exact = model recognizes each of
2,000+ trees with equal weight, 1-sent = model
recognizes exactly one tree.
experiment that uses an English PCFG language
model. The results for the other two language
models demonstrate more keenly the potential ad-
vantage that an on-the-fly approach provides?the
simultaneous incorporation of information from
all models allows application to be done more ef-
fectively than if each information source is consid-
ered in sequence. In the ?exact? case, where a very
large language model that simply recognizes each
of the 2,087 trees in the training corpus is used,
the final application is so large that it overwhelms
the resources of a 4gb MacBook Pro, while the
on-the-fly approach does not suffer from this prob-
lem. The ?1-sent? case is presented to demonstrate
the ripple effect caused by using on-the fly. In the
other two cases, a very large language model gen-
erally overwhelms the timing statistics, regardless
of the method being used. But a language model
that represents exactly one sentence is very small,
and thus the effects of simultaneous inference are
readily apparent?the time to retrieve the 1-best
sentence is reduced by two orders of magnitude in
this experiment.
6 Conclusion
We have presented algorithms for forward and
backward application of weighted tree trans-
ducer cascades, including on-the-fly variants, and
demonstrated the benefit of an on-the-fly approach
to application. We note that a more formal ap-
proach to application of WTTs is being developed,
1065
independent from these efforts, by Fu?lo?p et al
(2010).
Acknowledgments
We are grateful for extensive discussions with
Andreas Maletti. We also appreciate the in-
sights and advice of David Chiang, Steve De-
Neefe, and others at ISI in the preparation of
this work. Jonathan May and Kevin Knight were
supported by NSF grants IIS-0428020 and IIS-
0904684. Heiko Vogler was supported by DFG
VO 1011/5-1.
References
Athanasios Alexandrakis and Symeon Bozapalidis.
1987. Weighted grammars and Kleene?s theorem.
Information Processing Letters, 24(1):1?4.
Brenda S. Baker. 1979. Composition of top-down and
bottom-up tree transductions. Information and Con-
trol, 41(2):186?213.
Zolta?n E?sik and Werner Kuich. 2003. Formal tree se-
ries. Journal of Automata, Languages and Combi-
natorics, 8(2):219?285.
Zolta?n Fu?lo?p and Heiko Vogler. 2009. Weighted tree
automata and tree transducers. In Manfred Droste,
Werner Kuich, and Heiko Vogler, editors, Handbook
of Weighted Automata, chapter 9, pages 313?404.
Springer-Verlag.
Zolta?n Fu?lo?p, Andreas Maletti, and Heiko Vogler.
2010. Backward and forward application of
weighted extended tree transducers. Unpublished
manuscript.
Ferenc Ge?cseg and Magnus Steinby. 1984. Tree Au-
tomata. Akade?miai Kiado?, Budapest.
Liang Huang and David Chiang. 2005. Better k-best
parsing. In Harry Bunt, Robert Malouf, and Alon
Lavie, editors, Proceedings of the Ninth Interna-
tional Workshop on Parsing Technologies (IWPT),
pages 53?64, Vancouver, October. Association for
Computational Linguistics.
Werner Kuich. 1998. Formal power series over trees.
In Symeon Bozapalidis, editor, Proceedings of the
3rd International Conference on Developments in
Language Theory (DLT), pages 61?101, Thessa-
loniki, Greece. Aristotle University of Thessaloniki.
Werner Kuich. 1999. Tree transducers and formal tree
series. Acta Cybernetica, 14:135?149.
Andreas Maletti, Jonathan Graehl, Mark Hopkins, and
Kevin Knight. 2009. The power of extended top-
down tree transducers. SIAM Journal on Comput-
ing, 39(2):410?430.
Andreas Maletti. 2006. Compositions of tree se-
ries transformations. Theoretical Computer Science,
366:248?271.
Andreas Maletti. 2008. Compositions of extended top-
down tree transducers. Information and Computa-
tion, 206(9?10):1187?1196.
Andreas Maletti. 2009. Personal Communication.
Mehryar Mohri, Fernando C. N. Pereira, and Michael
Riley. 2000. The design principles of a weighted
finite-state transducer library. Theoretical Computer
Science, 231:17?32.
Mehryar Mohri. 1997. Finite-state transducers in lan-
guage and speech processing. Computational Lin-
guistics, 23(2):269?312.
Mehryar Mohri. 2009. Weighted automata algo-
rithms. In Manfred Droste, Werner Kuich, and
Heiko Vogler, editors, Handbook of Weighted Au-
tomata, chapter 6, pages 213?254. Springer-Verlag.
Adam Pauls and Dan Klein. 2009. K-best A* parsing.
In Keh-Yih Su, Jian Su, Janyce Wiebe, and Haizhou
Li, editors, Proceedings of the Joint Conference of
the 47th Annual Meeting of the ACL and the 4th In-
ternational Joint Conference on Natural Language
Processing of the AFNLP, pages 958?966, Suntec,
Singapore, August. Association for Computational
Linguistics.
Fernando Pereira and Michael Riley. 1997. Speech
recognition by composition of weighted finite au-
tomata. In Emmanuel Roche and Yves Schabes, ed-
itors, Finite-State Language Processing, chapter 15,
pages 431?453. MIT Press, Cambridge, MA.
William A. Woods. 1980. Cascaded ATN gram-
mars. American Journal of Computational Linguis-
tics, 6(1):1?12.
Kenji Yamada and Kevin Knight. 2001. A syntax-
based statistical translation model. In Proceedings
of 39th Annual Meeting of the Association for Com-
putational Linguistics, pages 523?530, Toulouse,
France, July. Association for Computational Lin-
guistics.
1066
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1416?1424,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
Models of Translation Competitions
Mark Hopkins and Jonathan May
SDL Research
6060 Center Drive, Suite 150
Los Angeles, CA 90045
{mhopkins,jmay}@sdl.com
Abstract
What do we want to learn from a trans-
lation competition and how do we learn
it with confidence? We argue that a dis-
proportionate focus on ranking competi-
tion participants has led to lots of differ-
ent rankings, but little insight about which
rankings we should trust. In response, we
provide the first framework that allows an
empirical comparison of different analy-
ses of competition results. We then use
this framework to compare several analyt-
ical models on data from the Workshop on
Machine Translation (WMT).
1 The WMT Translation Competition
Every year, the Workshop on Machine Transla-
tion (WMT) conducts a competition between ma-
chine translation systems. The WMT organizers
invite research groups to submit translation sys-
tems in eight different tracks: Czech to/from En-
glish, French to/from English, German to/from
English, and Spanish to/from English.
For each track, the organizers also assemble a
panel of judges, typically machine translation spe-
cialists.1 The role of a judge is to repeatedly rank
five different translations of the same source text.
Ties are permitted. In Table 1, we show an ex-
ample2 where a judge (we?ll call him ?jdoe?) has
ranked five translations of the French sentence ?Il
ne va pas.?
Each such elicitation encodes ten pairwise com-
parisons, as shown in Table 2. For each compe-
tition track, WMT typically elicits between 5000
and 20000 comparisons. Once the elicitation pro-
cess is complete, WMT faces a large database
of comparisons and a question that must be an-
swered: whose system is the best?
1Although in recent competitions, some of the judging has
also been crowdsourced (Callison-Burch et al, 2010).
2The example does not use actual system output.
rank system translation
1 bbn ?He does not go.?
2 (tie) uedin ?He goes not.?
2 (tie) jhu ?He did not go.?
4 cmu ?He go not.?
5 kit ?He not go.?
Table 1: WMT elicits preferences by asking
judges to simultaneously rank five translations,
with ties permitted. In this (fictional) example, the
source sentence is the French ?Il ne va pas.?
source text sys1 sys2 judge preference
?Il ne va pas.? bbn cmu jdoe 1
?Il ne va pas.? bbn jhu jdoe 1
?Il ne va pas.? bbn kit jdoe 1
?Il ne va pas.? bbn uedin jdoe 1
?Il ne va pas.? cmu jhu jdoe 2
?Il ne va pas.? cmu kit jdoe 1
?Il ne va pas.? cmu uedin jdoe 2
?Il ne va pas.? jhu kit jdoe 1
?Il ne va pas.? jhu uedin jdoe 0
?Il ne va pas.? kit uedin jdoe 2
Table 2: Pairwise comparisons encoded by Ta-
ble 1. A preference of 0 means neither translation
was preferred. Otherwise the preference specifies
the preferred system.
2 A Ranking Problem
For several years, WMT used the following heuris-
tic for ranking the translation systems:
ORIGWMT(s) = win(s) + tie(s)win(s) + tie(s) + loss(s)
For system s, win(s) is the number of pairwise
comparisons in which s was preferred, loss(s) is
the number of comparisons in which s was dispre-
ferred, and tie(s) is the number of comparisons in
which s participated but neither system was pre-
ferred.
Recently, (Bojar et al, 2011) questioned the ad-
equacy of this heuristic through the following ar-
1416
gument. Consider a competition with systems A
and B. Suppose that the systems are different but
equally good, such that one third of the time A
is judged better than B, one third of the time B
is judged better than A, and one third of the time
they are judged to be equal. The expected values
of ORIGWMT(A) and ORIGWMT(B) are both
2/3, so the heuristic accurately judges the systems
to be equivalently good. Suppose however that
we had duplicated B and had submitted it to the
competition a second time as system C. Since B
and C produce identical translations, they should
always tie with one another. The expected value
of ORIGWMT(A) would not change, but the ex-
pected value of ORIGWMT(B) would increase to
5/6, buoyed by its ties with system C.
This vulnerability prompted (Bojar et al, 2011)
to offer the following revision:
BOJAR(s) = win(s)win(s) + loss(s)
The following year, it was BOJAR?s turn to be crit-
icized, this time by (Lopez, 2012):
Superficially, this appears to be an im-
provement....couldn?t a system still be
penalized simply by being compared
to [good systems] more frequently than
its competitors? On the other hand,
couldn?t a system be rewarded simply
by being compared against a bad system
more frequently than its competitors?
Lopez?s concern, while reasonable, is less obvi-
ously damning than (Bojar et al, 2011)?s criti-
cism of ORIGWMT. It depends on whether the
collected set of comparisons is small enough or
biased enough to make the variance in competi-
tion significant. While this hypothesis is plausi-
ble, Lopez makes no attempt to verify it. Instead,
he offers a ranking heuristic of his own, based on
a Minimum Feedback Arc solver.
The proliferation of ranking heuristics contin-
ued from there. The WMT 2012 organizers
(Callison-Burch et al, 2012) took Lopez?s ranking
scheme and provided a variant called Most Proba-
ble Ranking. Then, noting some potential pitfalls
with that, they created two more, called Monte
Carlo Playoffs and Expected Wins. While one
could raise philosophical objections about each of
these, where would it end? Ultimately, the WMT
2012 findings presented five different rankings for
the English-German competition track, with no
guidance about which ranking we should pay at-
tention to. How can we know whether one rank-
ing is better than other? Or is this even the right
question to ask?
3 A Problem with Rankings
Suppose four systems participate in a translation
competition. Three of these systems are extremely
close in quality. We?ll call these close1, close2,
and close3. Nevertheless, close1 is very slightly
better3 than close2, and close2 is very slightly bet-
ter than close3. The fourth system, called terrific,
is a really terrific system that far exceeds the other
three.
Now which is the better ranking?
terrific, close3, close1, close2 (1)
close1, terrific, close2, close3 (2)
Spearman?s rho4 would favor the second ranking,
since it is a less disruptive permutation of the gold
ranking. But intuition favors the first. While its
mistakes are minor, the second ranking makes the
hard-to-forgive mistake of placing close1 ahead of
the terrific system.
The problem is not with Spearman?s rho. The
problem is the disconnnect between the knowl-
edge that we want a ranking to reflect and the
knowledge that a ranking actually contains. With-
out this additional knowledge, we cannot deter-
mine whether one ranking is better than another,
even if we know the gold ranking. We need to
determine what information they lack, and define
more rigorously what we hope to learn from a
translation competition.
4 From Rankings to Relative Ability
Ostensibly the purpose of a translation competi-
tion is to determine the relative ability of a set
of translation systems. Let S be the space of all
translation systems. Hereafter, we will refer to S
as the space of students. We choose this term to
evoke the metaphor of a translation competition as
a standardized test, which shares the same goal: to
assess the relative abilities of a set of participants.
But what exactly do we mean by ?ability?? Be-
fore formally defining this term, first recognize
that it means little without context, namely:
3What does ?better? mean? We?ll return to this question.
4Or Pearson?s correlation coefficient.
1417
1. What kind of source text do we want the
systems to translate well? Say system A is
great at translating travel-related documents,
but terrible at translating newswire. Mean-
while, system B is pretty good at both. The
question ?which system is better?? requires
us to state how much we care about travel
versus newswire documents ? otherwise the
question is underspecified.
2. Who are we trying to impress? While it?s
tempting to think that translation quality is
a universal notion, the 50-60% interannota-
tor agreement in WMT evaluations (Callison-
Burch et al, 2012) suggests otherwise. It?s
also easy to imagine reasons why one group
of judges might have different priorities than
another. Think a Fortune 500 company ver-
sus web forum users. Lawyers versus lay-
men. Non-native versus native speakers.
Posteditors versus Google Translate users.
Different groups have different uses for trans-
lation, and therefore different definitions of
what ?better? means.
With this in mind, let?s define some additional el-
ements of a translation competition. Let X be the
space of all possible segments of source text, J be
the space of all possible judges, and ? = {0, 1, 2}
be the space of pairwise preferences.5 We as-
sume all spaces are countable. Unless stated oth-
erwise, variables s1 and s2 represent students from
S, variable x represents a segment from X , vari-
able j represents a judge from J , and variable pi
represents a preference from ?. Moreover, define
the negation p?i of preference pi such that p?i = 2 (if
pi = 1), p?i = 1 (if pi = 2), and p?i = 0 (if pi = 0).
Now assume a joint distribution
P (s1, s2, x, j, pi) specifying the probability
that we ask judge j to evaluate students s1 and
s2?s respective translations of source text x, and
that judge j?s preference is pi. We will further
assume that the choice of student pair, source
text, and judge are marginally independent of one
another. In other words:
P (s1, s2, x, j, pi)
=
P (pi|s1, s2, x, j) ? P (x|s1, s2, j)
?P (j|s1, s2) ? P (s1, s2)
= P (pi|s1, s2, x, j) ? P (x) ? P (j) ? P (s1, s2)
= PX (x) ? PJ (j) ? P (s1, s2) ? P (pi|s1, s2, x, j)
5As a reminder, 0 indicates no preference.
It will be useful to reserve notation PX and PJ
for the marginal distributions over source text and
judges. We can marginalize over the source seg-
ments and judges to obtain a useful quantity:
P (pi|s1, s2)
=
?
x?X
?
j?J
PX (x) ? PJ (j) ? P (pi|s1, s2, x, j)
We refer to this as the ?PX , PJ ?-relative ability of
students s1 and s2. By using different marginal
distributions PX , we can specify what kinds of
source text interest us (for instance, PX could
focus most of its probability mass on German
tweets). Similarly, by using different marginal
distributions PJ , we can specify what judges we
want to impress (for instance, PJ could focus all
of its mass on one important corporate customer
or evenly among all fluent bilingual speakers of a
language pair).
With this machinery, we can express the pur-
pose of a translation competition more clearly:
to estimate the ?PX , PJ ?-relative ability of a set
of students. In the case of WMT, PJ presum-
ably6 defines a space of competent source-to-
target bilingual speakers, while PX defines a space
of newswire documents.
We?ll refer to an estimate of P (pi|s1, s2) as
a preference model. In other words, a prefer-
ence model is a distribution Q(pi|s1, s2). Given
a set of pairwise comparisons (e.g., Table 2),
the challenge is to estimate a preference model
Q(pi|s1, s2) such that Q is ?close? to P . For mea-
suring distributional proximity, a natural choice is
KL-divergence (Kullback and Leibler, 1951), but
we cannot use it here because P is unknown.
Fortunately, if we have i.i.d. data drawn from P ,
then we can do the next best thing and compute the
perplexity of preference model Q on this heldout
test data. LetD be a sequence of triples ?s1, s2, pi?
where the preferences pi are i.i.d. samples from
P (pi|s1, s2). The perplexity of preference model
Q on test data D is:
perplexity(Q|D) = 2?
?
?s1,s2,pi??D
1
|D| log2Q(pi|s1,s2)
How do we obtain such a test set from competi-
tion data? Recall that a WMT competition pro-
duces pairwise comparisons like those in Table 2.
6One could argue that it specifies a space of machine
translation specialists, but likely these individuals are thought
to be a representative sample of a broader community.
1418
Let C be the set of comparisons ?s1, s2, x, j, pi?
obtained from a translation competition. Com-
petition data C is not necessarily7 sampled i.i.d.
from P (s1, s2, x, j, pi) because we may intention-
ally8 bias data collection towards certain students,
judges or source text. Also, because WMT elicits
its data in batches (see Table 1), every segment x
of source text appears in at least ten comparisons.
To create an appropriately-sized test set that
closely resembles i.i.d. data, we isolate the sub-
set C? of comparisons whose source text appears
in at most k comparisons, where k is the smallest
positive integer such that |C?| >= 2000. We then
create the test set D from C?:
D = {?s1, s2, pi?|?s1, s2, x, j, pi? ? C?}
We reserve the remaining comparisons for training
preference models. Table 3 shows the resulting
dataset sizes for each competition track.
Unlike with raw rankings, the claim that
one preference model is better than another has
testable implications. Given two competing mod-
els, we can train them on the same comparisons,
and compare their perplexities on the test set. This
gives us a quantitative9 answer to the question of
which is the better model. We can then publish
a system ranking based on the most trustworthy
preference model.
5 Baselines
Let?s begin then, and create some simple prefer-
ence models to serve as baselines.
5.1 Uniform
The simplest preference model is a uniform distri-
bution over preferences, for any choice of students
s1, s2:
Q(pi|s1, s2) =
1
3 ?pi ? ?
This will be our only model that does not require
training data, and its perplexity on any test set will
be 3 (i.e. equal to number of possible preferences).
5.2 Adjusted Uniform
Now suppose we have a set C of comparisons
available for training. Let Cpi ? C denote the
subset of comparisons with preference pi, and let
7In WMT, it certainly is not.
8To collect judge agreement statistics, for instance.
9As opposed to philosophical.
C(s1, s2) denote the subset comparing students s1
and s2.
Perhaps the simplest thing we can do with the
training data is to estimate the probability of ties
(i.e. preference 0). We can then distribute the
remaining probability mass uniformly among the
other two preferences:
Q(pi|s1, s2) =
?
????
????
|C0|
|C| if pi = 0
1? |C0||C|
2 otherwise
6 Simple Bayesian Models
6.1 Independent Pairs
Another simple model is the direct estimation of
each relative ability P (pi|s1, s2) independently. In
other words, for each pair of students s1 and s2, we
estimate a separate preference distribution. The
maximum likelihood estimate of each distribution
would be:
Q(pi|s1, s2) =
|Cpi(s1, s2)|+ |Cp?i(s2, s1)|
|C(s1, s2)|+ |C(s2, s1)|
However the maximum likelihood estimate would
test poorly, since any zero probability estimates
for test set preferences would result in infinite per-
plexity. To make this model practical, we assume a
symmetric Dirichlet prior with strength ? for each
preference distribution. This gives us the follow-
ing Bayesian estimate:
Q(pi|s1, s2) =
?+ |Cpi(s1, s2)|+ |Cp?i(s2, s1)|
3?+ |C(s1, s2)|+ |C(s2, s1)|
We call this the Independent Pairs preference
model.
6.2 Independent Students
The Independent Pairs model makes a strong inde-
pendence assumption. It assumes that even if we
know that student A is much better than student B,
and that student B is much better than student C,
we can infer nothing about how student A will fare
versus student C. Instead of directly estimating the
relative ability P (pi|s1, s2) of students s1 and s2,
we could instead try to estimate the universal abil-
ity P (pi|s1) = ?s2?S P (pi|s1, s2) ? P (s2|s1) ofeach individual student s1 and then try to recon-
struct the relative abilities from these estimates.
For the same reasons as before, we assume a
symmetric Dirichlet prior with strength ? for each
1419
preference distribution, which gives us the follow-
ing Bayesian estimate:
Q(pi|s1) =
?+
?
s2?S |Cpi(s1, s2)|+ |Cp?i(s2, s1)|
3?+
?
s2?S |C(s1, s2)|+ |C(s2, s1)|
The estimatesQ(pi|s1) do not yet constitute a pref-
erence model. A downside of this approach is that
there is no principled way to reconstruct a pref-
erence model from the universal ability estimates.
We experiment with three ad-hoc reconstructions.
The asymmetric reconstruction simply ignores any
information we have about student s2:
Q(pi|s1, s2) = Q(pi|s1)
The arithmetic and geometric reconstructions
compute an arithmetic/geometric average of the
two universal abilities:
Q(pi|s1, s2) =
Q(pi|s1) +Q(p?i|s2)
2
Q(pi|s1, s2) = [Q(pi|s1) ?Q(p?i|s2)]
1
2
We respectively call these the (Asymmet-
ric/Arithmetic/Geometric) Independent Students
preference models. Notice the similarities be-
tween the universal ability estimates Q(pi|s1) and
the BOJAR ranking heuristic. These three models
are our attempt to render the BOJAR heuristic as
preference models.
7 Item-Response Theoretic (IRT) Models
Let?s revisit (Lopez, 2012)?s objection to the BO-
JAR ranking heuristic: ?...couldn?t a system still be
penalized simply by being compared to [good sys-
tems] more frequently than its competitors?? The
official WMT 2012 findings (Callison-Burch et al,
2012) echoes this concern in justifying the exclu-
sion of reference translations from the 2012 com-
petition:
[W]orkers have a very clear preference
for reference translations, so includ-
ing them unduly penalized systems that,
through (un)luck of the draw, were pit-
ted against the references more often.
Presuming the students are paired uniformly at
random, this issue diminishes as more compar-
isons are elicited. But preference elicitation is ex-
pensive, so it makes sense to assess the relative
ability of the students with as few elicitations as
possible. Still, WMT 2012?s decision to eliminate
references entirely is a bit of a draconian mea-
sure, a treatment of the symptom rather than the
(perceived) disease. If our models cannot function
in the presence of training data variation, then we
should change the models, not the data. A model
that only works when the students are all about the
same level is not one we should rely on.
We experiment with a simple model that relaxes
some independence assumptions made by previ-
ous models, in order to allow training data vari-
ation (e.g. who a student has been paired with)
to influence the estimation of the student abili-
ties. Figure 1(left) shows plate notation (Koller
and Friedman, 2009) for the model?s indepen-
dence structure. First, each student?s ability dis-
tribution is drawn from a common prior distribu-
tion. Then a number of translation items are gen-
erated. Each item is authored by a student and has
a quality drawn from the student?s ability distri-
bution. Then a number of pairwise comparisons
are generated. Each comparison has two options,
each a translation item. The quality of each item
is observed by a judge (possibly noisily) and then
the judge states a preference by comparing the two
observations.
We investigate two parameterizations of this
model: Gaussian and categorical. Figure 1(right)
shows an example of the Gaussian parameteriza-
tion. The student ability distributions are Gaus-
sians with a known standard deviation ?a, drawn
from a zero-mean Gaussian prior with known stan-
dard deviation ?0. In the example, we show
the ability distributions for students 6 (an above-
average student, whose mean is 0.4) and 14 (a
poor student, whose mean is -0.6). We also show
an item authored by each student. Item 43 has
a somewhat low quality of -0.3 (drawn from stu-
dent 14?s ability distribution), while item 205 is
not student 6?s best work (he produces a mean
quality of 0.4), but still has a decent quality at 0.2.
Comparison 1 pits these items against one another.
A judge draws noise from a zero-mean Gaussian
with known standard deviation ?obs, then adds this
to the item?s actual quality to get an observed qual-
ity. For the first option (item 43), the judge draws a
noise of -0.12 to observe a quality of -0.42 (worse
than it actually is). For the second option (item
205), the judge draws a noise of 0.15 to observe a
quality of 0.35 (better than it actually is). Finally,
the judge compares the two observed qualities. If
the absolute difference is lower than his decision
1420
student.6.ability 
Gauss(0.4, ?a) 
item.43.author 
14 
item.43.quality 
-0.3 
comp.1.opt1 
43 
comp.1.opt1.obs 
-0.42 
comp.1.pref 
2 
comp.1.opt2 
205 
comp.1.opt2.obs 
0.35 
student.prior 
Gauss(0.0, ?0)  
decision.radius 
0.5 
obs.parameters 
Gauss(0.0, ?obs) 
item.205.author 
6 
item.205.quality 
0.2 
student.14.ability 
Gauss(-0.6, ?a) 
student.s.ability item.i.author 
item.i.quality 
comp.c.opt1 
comp.c.opt1.obs 
comp.c.pref 
comp.c.opt2 
comp.c.opt2.obs 
S 
I 
C 
student.prior 
decision.radius 
obs.parameters 
Figure 1: Plate notation (left) showing the independence structure of the IRT Models. Example instan-
tiated subnetwork (right) for the Gaussian parameterization. Shaded rectangles are hyperparameters.
Shaded ellipses are variables observable from a set of comparisons.
radius (which here is 0.5), then he states no prefer-
ence (i.e. a preference of 0). Otherwise he prefers
the item with the higher observed quality.
The categorical parameterization is similar to
the Gaussian parameterization, with the following
differences. Item quality is not continuous, but
rather a member of the discrete set {1, 2, ...,?}.
The student ability distributions are categorical
distributions over {1, 2, ...,?}, and the student
ability prior is a symmetric Dirichlet with strength
?a. Finally, the observed quality is the item qual-
ity ? plus an integer-valued noise ? ? {1 ?
?, ...,?? ?}. Noise ? is drawn from a discretized
zero-mean Gaussian with standard deviation ?obs.
Specifically, Pr(?) is proportional to the value of
the probability density function of the zero-mean
Gaussian N (0, ?obs).
We estimated the model parameters with Gibbs
sampling (Geman and Geman, 1984). We found
that Gibbs sampling converged quickly and con-
sistently10 for both parameterizations. Given the
parameter estimates, we obtain a preference model
Q(pi|s1, s2) through the inference query:
Pr(comp.c?.pref = pi | item.i?.author = s1,
item.i??.author = s2,
comp.c?.opt1 = i?,
comp.c?.opt2 = i??)
10We ran 200 iterations with a burn-in of 50.
where c?, i?, i?? are new comparison and item ids
that do not appear in the training data.
We call these models Item-Response Theo-
retic (IRT) models, to acknowledge their roots
in the psychometrics (Thurstone, 1927; Bradley
and Terry, 1952; Luce, 1959) and item-response
theory (Hambleton, 1991; van der Linden and
Hambleton, 1996; Baker, 2001) literature. Item-
response theory is the basis of modern testing
theory and drives adaptive standardized tests like
the Graduate Record Exam (GRE). In particular,
the Gaussian parameterization of our IRT models
strongly resembles11 the Thurstone (Thurstone,
1927) and Bradley-Terry-Luce (Bradley and Terry,
1952; Luce, 1959) models of paired compari-
son and the 1PL normal-ogive and Rasch (Rasch,
1960) models of student testing. From the test-
ing perspective, we can view each comparison as
two students simultaneously posing a test question
to the other: ?Give me a translation of the source
text which is better than mine.? The students can
answer the question correctly, incorrectly, or they
can provide a translation of analogous quality. An
extra dimension of our models is judge noise, not
a factor when modeling multiple-choice tests, for
which the right answer is not subject to opinion.
11These models are not traditionally expressed using
graphical models, although it is not unprecedented (Mislevy
and Almond, 1997; Mislevy et al, 1999).
1421
wmt10 wmt11 wmt12
lp train test train test train test
ce 3166 2209 1706 3216 5969 6806
fe 5918 2376 2556 4430 7982 5840
ge 7422 3002 3708 5371 8106 6032
se 8411 2896 1968 3684 3910 7376
ec 10490 3048 8859 9016 13770 9112
ef 5720 2242 3328 5758 7841 7508
eg 10852 2842 5964 7032 10210 7191
es 2962 2212 4768 6362 5664 8928
Table 3: Dataset sizes for each competition track
(number of comparisons).
Figure 2: WMT10 model perplexities. The per-
plexity of the uniform preference model is 3.0 for
all training sizes.
8 Experiments
We organized the competition data as described at
the end of Section 4. To compare the preference
models, we did the following:
? Randomly chose a subset of k compar-
isons from the training set, for k ?
{100, 200, 400, 800, 1600, 3200}.12
? Trained the preference model on these com-
parisons.
? Evaluated the perplexity of the trained model
on the test preferences, as described in Sec-
tion 4.
For each model and training size, we averaged
the perplexities from 5 trials of each competition
track. We then plotted average perplexity as a
function of training size. These graphs are shown
12If k was greater than the total number of training com-
parisons, then we took the entire set.
Figure 3: WMT11 model perplexities.
Figure 4: WMT12 model perplexities.
in Figure 2 (WMT10)13, and Figure 4 (WMT12).
For WMT10 and WMT11, the best models were
the IRT models, with the Gaussian parameteriza-
tion converging the most rapidly and reaching the
lowest perplexity. For WMT12, in which refer-
ence translations were excluded from the compe-
tition, four models were nearly indistinguishable:
the two IRT models and the two averaged Indepen-
dent Student models. This somewhat validates the
organizers? decision to exclude the references, par-
ticularly given WMT?s use of the BOJAR ranking
heuristic (the nucleus of the Independent Student
models) for its official rankings.
13Results for WMT10 exclude the German-English and
English-German tracks, since we used these to tune our
model hyperparameters. These were set as follows. The
Dirichlet strength for each baseline was 1. For IRT-Gaussian:
?0 = 1.0, ?obs = 1.0, ?a = 0.5, and the decision radius was
0.4. For IRT-Categorical: ? = 8, ?obs = 1.0, ?a = 0.5, and
the decision radius was 0.
1422
Figure 6: English-Czech WMT11 results (average of 5 trainings on 1600 comparisons). Error bars
(left) indicate one stddev of the estimated ability means. In the heatmap (right), cell (s1, s2) is darker if
preference model Q(pi|s1, s2) skews in favor of student s1, lighter if it skews in favor of student s2.
Figure 5: WMT10 model perplexities (crowd-
sourced versus expert training).
The IRT models proved the most robust at han-
dling judge noise. We repeated the WMT10 ex-
periment using the same test sets, but using the
unfiltered crowdsourced comparisons (rather than
?expert?14 comparisons) for training. Figure 5
shows the results. Whereas the crowdsourced
noise considerably degraded the Geometric Inde-
pendent Students model, the IRT models were re-
markably robust. IRT-Gaussian in particular came
close to replicating the performance of Geometric
Independent Students trained on the much cleaner
expert data. This is rather impressive, since the
crowdsourced judges agree only 46.6% of the
time, compared to a 65.8% agreement rate among
14I.e., machine translation specialists.
expert judges (Callison-Burch et al, 2010).
Another nice property of the IRT models is
that they explicitly model student ability, so they
yield a natural ranking. For training size 1600 of
the WMT11 English-Czech track, Figure 6 (left)
shows the mean student abilities learned by the
IRT-Gaussian model. The error bars show one
standard deviation of the ability means (recall that
we performed 5 trials, each with a random training
subset of size 1600). These results provide fur-
ther insight into a case analyzed by (Lopez, 2012),
which raised concern about the relative ordering
of online-B, cu-bojar, and cu-marecek. Accord-
ing to IRT-Gaussian?s analysis of the data, these
three students are so close in ability that any order-
ing is essentially arbitrary. Short of a full ranking,
the analysis does suggest four strata. Viewing one
of IRT-Gaussian?s induced preference models as
a heatmap15 (Figure 6, right), four bands are dis-
cernable. First, the reference sentences are clearly
the darkest (best). Next come students 2-7, fol-
lowed by the slightly lighter (weaker) students 8-
10, followed by the lightest (weakest) student 11.
9 Conclusion
WMT has faced a crisis of confidence lately, with
researchers raising (real and conjectured) issues
with its analytical methodology. In this paper,
we showed how WMT can restore confidence in
15In the heatmap, cell (s1, s2) is darker if preference model
Q(pi|s1, s2) skews in favor of student s1, lighter if it skews
in favor of student s2.
1423
its conclusions ? by shifting the focus from rank-
ings to relative ability. Estimates of relative ability
(the expected head-to-head performance of system
pairs over a probability space of judges and source
text) can be empirically compared, granting sub-
stance to previously nebulous questions like:
1. Is my analysis better than your analysis?
Rather than the current anecdotal approach
to comparing competition analyses (e.g. pre-
senting example rankings that seem some-
how wrong), we can empirically compare the
predictive power of the models on test data.
2. How much of an impact does judge noise
have on my conclusions? We showed
that judge noise can have a significant im-
pact on the quality of our conclusions, if we
use the wrong models. However, the IRT-
Gaussian appears to be quite noise-tolerant,
giving similar-quality conclusions on both
expert and crowdsourced comparisons.
3. How many comparisons should I elicit?
Many of our preference models (including
IRT-Gaussian and Geometric Independent
Students) are close to convergence at around
1000 comparisons. This suggests that we can
elicit far fewer comparisons and still derive
confident conclusions. This is the first time
a concrete answer to this question has been
provided.
References
F.B. Baker. 2001. The basics of item response theory.
ERIC.
Ondej Bojar, Milos? Ercegovc?evic?, Martin Popel, and
Omar Zaidan. 2011. A grain of salt for the wmt
manual evaluation. In Proceedings of the Sixth
Workshop on Statistical Machine Translation, pages
1?11, Edinburgh, Scotland, July. Association for
Computational Linguistics.
Ralph Allan Bradley and Milton E Terry. 1952. Rank
analysis of incomplete block designs: I. the method
of paired comparisons. Biometrika, 39(3/4):324?
345.
C. Callison-Burch, P. Koehn, C. Monz, K. Peterson,
M. Przybocki, and O.F. Zaidan. 2010. Findings of
the 2010 joint workshop on statistical machine trans-
lation and metrics for machine translation. In Pro-
ceedings of the Joint Fifth Workshop on Statistical
Machine Translation and MetricsMATR, pages 17?
53. Association for Computational Linguistics.
Chris Callison-Burch, Philipp Koehn, Christof Monz,
Matt Post, Radu Soricut, and Lucia Specia. 2012.
Findings of the 2012 workshop on statistical ma-
chine translation. In Proceedings of the Seventh
Workshop on Statistical Machine Translation.
S. Geman and D. Geman. 1984. Stochastic relaxation,
gibbs distributions, and the bayesian restoration of
images. IEEE Transactions on Pattern Analysis and
Machine Intelligence, 6(6):721?741.
R.K. Hambleton. 1991. Fundamentals of item re-
sponse theory, volume 2. Sage Publications, Incor-
porated.
D. Koller and N. Friedman. 2009. Probabilistic graph-
ical models: principles and techniques. MIT press.
S. Kullback and R.A. Leibler. 1951. On information
and sufficiency. The Annals of Mathematical Statis-
tics, 22(1):79?86.
Adam Lopez. 2012. Putting human assessments of
machine translation systems in order. In Proceed-
ings of WMT.
R. Ducan Luce. 1959. Individual Choice Behavior a
Theoretical Analysis. John Wiley and sons.
R.J. Mislevy and R.G. Almond. 1997. Graphical mod-
els and computerized adaptive testing. UCLA CSE
Technical Report 434.
R.J. Mislevy, R.G. Almond, D. Yan, and L.S. Stein-
berg. 1999. Bayes nets in educational assessment:
Where the numbers come from. In Proceedings
of the fifteenth conference on uncertainty in artifi-
cial intelligence, pages 437?446. Morgan Kaufmann
Publishers Inc.
G. Rasch. 1960. Studies in mathematical psychology:
I. probabilistic models for some intelligence and at-
tainment tests.
Louis L Thurstone. 1927. A law of comparative judg-
ment. Psychological review, 34(4):273?286.
W.J. van der Linden and R.K. Hambleton. 1996.
Handbook of modern item response theory.
Springer.
1424
