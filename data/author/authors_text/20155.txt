Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 215?222,
Beijing, August 2010
An ontology-driven system for detecting global health events
Nigel Collier
National Inst. Informatics
collier@nii.ac.jp
Reiko Matsuda Goodwin
Fordham University
reikogoodwin@gmail.com
John McCrae
Bielefeld University
johnmccrae@gmail.com
Son Doan
Vanderbilt University
son.doan@vanderbilt.edu
Ai Kawazoe
Tsuda College
zoeai@tsuda.ac.jp
Mike Conway
University of Pittsburgh
conwaym@pitt.edu
Asanee Kawtrakul
Kasetart University
ak@ku.ac.th
Koichi Takeuchi
Okayama University
koichi@cs.okayama-u.ac.jp
Dinh Dien
VietNam National University
ddien66@yahoo.com
Abstract
Text mining for global health surveillance
is an emerging technology that is gaining
increased attention from public health or-
ganisations and governments. The lack
of multilingual resources such as Word-
Nets specifically targeted at this task have
so far been a major bottleneck. This pa-
per reports on a major upgrade to the
BioCaster Web monitoring system and
its freely available multilingual ontology;
improving its original design and extend-
ing its coverage of diseases from 70 to 336
in 12 languages.
1 Introduction
The number of countries who can sustain teams
of experts for global monitoring of human/animal
health is limited by scarce national budgets.
Whilst some countries have advanced sensor net-
works, the world remains at risk from the health
impacts of infectious diseases and environmen-
tal accidents. As seen by the recent A(H5N1),
A(H1N1) and SARS outbreaks, a problem in one
part of the world can be rapidly exported, leading
to global hardship.
The World Health Organization (WHO) esti-
mates that in the future, between 2 to 7.4 mil-
lion people could be at risk worldwide from a
highly contageous avian flu virus that spreads
rapidly through the international air travel net-
work (WHO, 2005). Pandemics of novel
pathogens have the capacity to overwhelm health-
care systems, leading to widespread morbidity,
mortality and socio-economic disruption (Cox
et al, 2003). Furthermore, outbreaks of live-
stock diseases, such as foot-and-mouth disease or
equine influenza can have a devastating impact on
industry, commerce and human health (Blake et
al., 2003). The challenge is to enhance vigilance
and control the emergence of outbreaks. Whilst
human analysis remains essential to spot complex
relationships, automated analysis has a key role
to play in filtering the vast volume of data in real
time and highlighting unusual trends using reli-
able predictor indicators.
BioCaster (http://born.nii.ac.jp) (Collier et al,
2008) is a Web 2.0 monitoring station for the early
detection of infectious disease events. The sys-
tem exploits a high-throughput semantic process-
ing pipeline, converting unstructured news texts
to structured records, alerting events based on
time-series analysis and then sharing this informa-
tion with users via geolocating maps (Fig. 1(a)),
graphs (Fig. 1(b)) and alerts. Underlying the sys-
tem is a publicly available multilingual applica-
tion ontology. Launched in 2006 (Collier et al,
2006) the BioCaster Ontology (BCO) has been
downloaded by over 70 academic and industrial
groups worldwide. This paper reports on a ma-
jor upgrade to the system and the ontology - ex-
panding the number of languages from 6 to 12,
redefining key relations and extending coverage in
the number of diseases from 70 to 336, including
many veterinary diseases.
215
(a) Bio-geographic map (b) Trend graph analyser
(c) BioCaster processes
Figure 1: (a)BioCaster?s bio-geographic map for a suspected foot-and-mouth outbreak on 22nd March,
2010 with links to the multilingual ontology, NCBI, HighWire, GoPubMed and Google Scholar; (b)
The trends analyser showing aggregated document counts for health events in China between 13nd
March and 12th April, 2010; (c) The system?s pipeline of processes with example semantic markup.
216
2 Background
As the world becomes more interconnected and
urbanized and animal production becomes in-
creasingly intensive, the speed with which epi-
demics spread becomes faster, adding to pressure
on biomedical experts and governments to make
quick decisions. Traditional validation methods
such as field investigations or laboratory analysis
are the mainstay of public health but can require
days or weeks to issue reports. The World Wide
Web with its economical and real time delivery of
information represents a new modality in health
surveillance (Wagner and Johnson, 2006) and has
been shown to be an effective source by the World
Health Organization (WHO) when Public Health
Canada?s GPHIN system detected the SARS out-
break in southern China from news reports dur-
ing November 2002. The recent A(H1N1) ?swine
flu? pandemic highlighted the trend towards agen-
cies using unvalidated sources. The technologi-
cal basis for such systems can be found in sta-
tistical classification approaches and light weight
ontological reasoning. For example, Google Flu
Trends (Ginsberg et al, 2009) is a system that de-
pends almost entirely on automatic statistical clas-
sification of user queries; MedISys-PULS (Yan-
garber et al, 2008), HealthMap (Freifeld et al,
2008) and BioCaster use a mixture of statisti-
cal and ontological classification; and GPHIN
(Mawudeku and Blench, 2006) and Argus (Wil-
son, 2007) rely on a mixture of ontological classi-
fication and manual analysis.
Compared to other similar systems BioCaster
is characterized by its richly featured and pub-
licly downloadable ontology and emphasizes crit-
ical evaluation of its text mining modules. Em-
pirical results have included: topic classification,
named entity recognition, formal concept anal-
ysis and event recognition. In the absence of
a community gold standard, task performance
was assessed on the best available ?silver? stan-
dard - the ProMED-mail network (Madoff and
Woodall, 2005), achieving F-score of 0.63 on 14
disease-country pairs over a 365-day period (Col-
lier, 2010).
Despite initial skepticism within the public
health community, health surveillance systems
based on NLP-supported human analysis of me-
dia reports are becoming firmly established in
Europe, North America and Japan as sources of
health information available to governments and
the public (Hartley et al, 2010). Whilst there is no
substitute for trained human analysts, automated
filtering has helped experts save time by allow-
ing them to sift quickly through massive volumes
of media data. It has also enabled them to sup-
plement traditional sources with a broader base of
information.
In comparison with other areas of biomedical
NLP such as the clinical and genetics? domains, a
relative lack of building block resources may have
hindered the wider participation of NLP groups
in public health applications. It is hoped that the
provision of common resources like the BCO can
help encourage further development and bench-
marking.
3 Method
BioCaster performs analysis of over 9000 news ar-
ticles per day using the NPACI Rocks cluster mid-
dleware (http://www.rockcsclusters.org) on a plat-
form of 48 3.0GHz Xeon cores. Data is ingested
24/7 into a semantic processing pipeline in a short
1 hour cycle from over 1700 public domain RSS
feeds such as Google news, the European Media
Monitor and ProMED-mail. Since 2009, news has
also being gathered under contract from a com-
mercial news aggregation company, providing ac-
cess to over 80,000 sources across the world?s lan-
guages.
The new 2010 version of BioCaster uses ma-
chine translation into English (eleven languages)
to source news stories related to currently oc-
curring infectious and environmental disease out-
breaks in humans, animals and plants.
Access to the site is freely available but lo-
gin registration applies to some functions such as
email alerts. Processing is totally automatic, but
we have the potential within the login system to
enable human moderated alerts which broadcast
to Twitter and RSS.
Below we describe in detail two key aspects of
the system that have been significantly upgraded:
the BCO and the event detection system.
217
3.1 Ontology
3.1.1 Aim
The BioCaster Ontology aims:
? To describe the terms and relations necessary
to detect and risk assess public health events
in the grey literature;
? To bridge the gap between (multilingual)
grey literature and existing standards in
biomedicine;
? To mediate integration of content across lan-
guages;
? To be freely available.
The central knowledge source for BioCaster
is the multilingual ontology containing domain
terms such as diseases, agents, symptoms, syn-
dromes and species as well as domain sensitive
relations such as a disease causing symptoms or
an agent affecting particular host species. This al-
lows the text mining system to have a basic un-
derstanding of the key concepts and relationships
within the domain to fill in gaps not mentioned
explicitly in the news reports. To the best of our
knowledge the BCO is unique as an application
ontology, providing freely available multilingual
support to system developers interested in out-
break surveillance in the language of the open me-
dia.
The BCO however has little to say outside of
its application domain, e.g. in disease-gene in-
teraction or for supporting automatic diagnosis.
As discussed in Grey Cowell and Smith (2010),
there are many other resources available that have
the potential to support applications for infec-
tious disease analysis including controlled vocab-
ularies and ontologies such as the the Unified
Medical Language System (UMLS) (Lindberg et
al., 1993), International Classification of Diseases
(ICD-10) (WHO, 2004), SNOMED CT (Stearns
et al, 2001), Medical Subject Headings (MeSH)
(Lipscomb, 2000) and the Infectious Disease On-
tology (IDO) (Grey Cowell and Smith, 2010). In
(Collier et al, 2006) we discussed how BCO com-
pared to such ontologies so we will focus from
now on the implication of the extensions.
3.1.2 Scope
The new version of the BCO now covers 12 lan-
guages including all the United Nation?s official
languages: Arabic (968 terms), English (4113),
French (1281), Indonesian (1081), Japanese
(2077), Korean (1176), Malaysian (1001), Rus-
sian (1187), Spanish (1171), Thai (1485), Viet-
namese (1297) and Chinese (1142). The multi-
lingual ontology can be used as a direct knowl-
edge source in language-specific text mining mod-
ules, as an indexing resource for searching across
concepts in various languages and as a dictionary
for future translation modules. Currently news in
all 12 languages is available via the Web portal
but news in additional languages such as German,
Italian and Dutch are being added using machine
translation.
3.1.3 Design
Like EuroWordNet (Vossen, 1998), on which
it is loosely based, the BCO adopts a thesaurus-
like structure with synonym sets linking to-
gether terms across languages with similar mean-
ing. Synonym sets are referred to using root
terms. Root terms themselves are fully defined in-
stances that provide bridges to external classifica-
tion schemes and nomenclatures such as ICD10,
MeSH, SNOMED CT and Wikipedia. The central
backbone taxonomy is deliberately shallow and
taken from the ISO?s Suggested Upper Merged
Ontology (Niles and Pease, 2001). To maintain
consistency and computability we kept a single
inheritance structure throughout. 18 core domain
concepts corresponding to named entities in the
text mining system such as DISEASE and SYMP-
TOM were the results of analysis using a formal
theory (Guarino and Welty, 2000).
We have endeavoured to construct definitions
for root terms along Aristotelean principles by
specifying the difference to the parent. For ex-
ample in the case of Eastern encephalitis virus:
Eastern equine encephalitis virus is a
species of virus that belongs to the
genus Alphavirus of the family Togaviri-
dae (order unassigned) of the group
IV ((+)ssRNA) that possesses a positive
single stranded RNA genome. It is the
218
etiological agent of the eastern equine
encephalitis.
We are conscious though that terms used in
the definitions still require more rigorous control
to be considered useful for machine reasoning.
To aid both human and machine analysis root
terms are linked by a rich relational structure
reflecting domain sensitive relations such as
causes(virus,disease), has symptom(disease,
symptom), has associated syndrome(disease,
syndrome), has reservoir(virus, organism).
In such a large undertaking, the order of work
was critical. We proceeded by collecting a list of
notifiable diseases from national health agencies
and then grouped the diseases according to per-
ceived relevance to the International Health Reg-
ulations 2005 (Lawrence and Gostin, 2004). In
this way we covered approximately 200 diseases,
and then explored freely available resources and
the biomedical literature to find academic and lay-
man?s terminology to describe their agents, af-
fected hosts, vector species, symptoms, etc. We
then expanded the coverage to less well known
human diseases, zoonotic diseases, animal dis-
eases and diseases caused by toxic substances
such as sarin, hydrogen sulfide, sulfur dioxide and
ethylene. At regular stages we checked and val-
idated terms against those appearing in the news
media.
As we expanded the number of conditions to in-
clude veterinary diseases we found a major struc-
tural reorganization was needed to support animal
symptoms. For example, a high temperature in
humans would not be the same as one in bovids.
This prompted us in the new version to group dis-
eases and symptoms around major animal familes
and related groups, e.g. high temperature (human)
and high temperature (bovine).
A second issue that we encountered was the
need to restructure the hierarchy under Organi-
cObject which was divided between MicroOrgan-
ism and Animal. The structure of the previous
version meant that the former were doing dou-
ble duty as infecting agents and the later were af-
fected hosts. The MicroOrganism class contained
bacterium, helminth, protozoan, fungus and virus,
which then became the domain in a relation ?x
causes y?. Expansion forced us to accomodate the
fact that some animals such as worms and mites
(e.g. scabies) also infect humans as well as ani-
mals. The result was a restructuring of the organic
classes using the Linnean taxonomy as a guide-
line, although this is probably not free from errors
(e.g. virus is typically not considered to be an or-
ganism).
3.2 Event alerting system
Figure 1(c) shows a schematic of the modular de-
sign used by the BioCaster text mining system.
Following on from machine translation and topic
classification is named entity recognition and tem-
plate recognition which we describe in more detail
below. The final structured event frames include
slot values normalized to ontology root terms for
disease, pathogen (virus or bacterium), country
and province. Additionally we also identify 15 as-
pects of public health events critical to risk assess-
ment such as: spread across international borders,
hospital worker infection, accidental or deliberate
release, food contamination and vaccine contami-
nation.
Latitude and longitude of events down to the
province level are found in two ways: using the
Google API up to a limit of 15000 lookups per
day, and then using lookup on the BCO taxonomy
of 5000 country and province names derived from
open sources such as Wikipedia.
Each hour events are automatically alerted to
a Web portal page by comparing daily aggre-
gated event counts against historical norms (Col-
lier, 2010). Login users can also sign up to receive
emails on specific topics. A topic would normally
specify a disease or syndrome, a country or region
and a specific risk condition.
In order to extract knowledge from docu-
ments, BioCaster maintains a collection of rule
patterns in a regular expression language that
converts surface expressions into structured in-
formation. For example the surface phrase
?man exposes airline passengers to measles?
would be converted into the three templates
?species(human); disease(measles); interna-
tional travel(true)?. Writing patterns to produce
such templates can be very time consuming and
so the BioCaster project has developed its own
219
D3: :- name(disease){ list(@undiagnosed) words(,1) list(@disease) }
S2: :- name(symptom) { list(@severity) list(@symptom)}
CF1: contaminated food(?true?) :- ?caused? ?by? list(@contaminate verbs past)
list(@injested material)
SP4: species(?animal?) :- name(animal,A) words(,3) list(@cull verbs past)
Table 1: Examples of SRL rules for named entity and template recognition. Template rules contain
a label, a head and a body, where the head specifies the template pattern to be output if the body
expression matches. The body can contain word lists, literals, and wild cards. Various conditions can
be placed on each of these such as orthographic matching.
light weight rule language - called the Simple
Rule Language (SRL) and a pattern building inter-
face for maintaining the rule base (McCrae et al,
2009). Both are freely available to the research
community under an open source license. Cur-
rently BioCaster uses approximately 130 rules for
entity recognition, 1000 word lists and 3200 tem-
plate rules (of which half are for location recogni-
tion) to identify events of interest in English. Us-
ing SRL allows us to quickly adapt the system to
newly emerging terminology such as the 11+ des-
ignations given to A(H1N1) during the first stages
of the 2009 pandemic.
The SRL rulebook for BioCaster can recognize
a range of entities related to the task of disease
surveillance such as bacteria, chemicals, diseases,
countries, provinces, cities and major airports.
Many of these classes are recognized using terms
imported from the BCO. The rule book also con-
tains specialised thesauri to recognize subclasses
of entities such as locations of habitation, eater-
ies and medical service centres. Verb lists are
maintained for lexical classes such as detection,
mutation, investigation, causation, contamination,
culling, blaming, and spreading.
Some examples of SRL rules for named entity
recognition are shown in Table 1 and described
below:
Rule D3 in the rulebook tags phrases like ?mys-
tery illness? or ?unknown killer bug? by matching
on strings contained within two wordlists, @un-
diagnosed and @disease, separated by up to one
word.
Rule S2 allows severity indicators such as ?se-
vere? or ?acute? to modify a list of known symp-
toms in order to identify symptom entities.
Rule CF1 is an example of a template rule. If
the body of the rule matches by picking out ex-
pressions such as ?was caused by tainted juice?,
this triggers the head to output an alert for con-
taminated food.
Rule SP4 identifies the victim species as ?ani-
mal? in contexts like ?250 geese were destroyed?.
The rulebook also supports more complex in-
ferences such as the home country of national
public health organizations.
Since BioCaster does not employ systematic
manual checking of its reports, it uses a number of
heuristic filters to increase specificity (the propor-
tion of correctly identified negatives) for reports
that appear on the public Web portal pages. For
example, reports with no identified disease and
country are rejected. Since these heuristics may
reduce sensitivity they are not applied to news that
appears on the user login portal pages.
4 Results and Discussion
Version 3 of the ontology represents a significant
expansion in the coverage of diseases, symptoms
and pathogens on version 2. Table 2 summarizes
the number of root terms for diseases classified by
animal familes.
The thesaurus like structure of the BCO is com-
patible in many respects to the Simple Knowledge
Organization System (SKOS) (Miles et al, 2005).
In order to extend exchange and re-use we have
produced a SKOS version of the BCO which is
available from the BCO site. We have also con-
verted the BCO terms into 12 SRL rule books (1
for each language) for entity tagging. These too
are freely available from the BCO site.
As the ontology expands we will consider
adopting a more detailed typing of diseases such
as hasInfectingPart to indicate the organ affected
220
Species N Example
Avian 22 Fowl pox
Bee 6 Chalk brood
disease
Bovine 24 Bluetongue
Canine 4 Blastomycosis
(Canine)
Caprine 14 Contagious
agalactia
Cervine 2 Chronic wasting
disease
Equine 17 Strangles
Feline 4 Feline AIDS
Fish 2 Viral hemorr
hagic septicemia
Human 216 Scarlet fever
Lagomorph 2 Myxomatosis
Non-human 16 Sylvan
primate yellow fever
Other 2 Crayfish plague
Rodent 8 Colorado tick
fever (Rodent)
Swine 12 Swine erysipelas
Table 2: Major disease groups organized by af-
fected animal family. N represents the number of
root terms.
or hasProtectionMethod to indicate broad classes
of methods used to prevent or treat a condition.
The typology of diseases could also be extended
in a more fine grained manner to logically group
conditions, e.g. West Nile virus encephalitis,
Powassan encephalitis and the Japanese B en-
cephalitis could be connected through a hasType
relation on encephalitis.
5 Conclusion
Multilingual resources specifically targeted at the
task of global health surveillance have so far been
very rare. We hope that the release of version 3
can be used to support a range of applications such
as text classification, cross language search, ma-
chine translation, query expansion and so on.
The BCO has been constructed to provide core
vocabulary and knowledge support to the Bio-
Caster project but it has also been influential
in the construction of other public health ori-
ented application ontologies such as the Syn-
dromic Surveillance Ontology (Okhamatovskaia
et al, 2009). The BCO is freely available from
http://code.google.com/p/biocaster-ontology/ un-
der a Creative Commons license.
Acknowledgements
The authors greatly acknowledge the many co-
workers who have provided comments and feed-
back on BioCaster. Funding support was pro-
vided in part by the Japan Science and Technology
Agency under the PRESTO programme.
References
Blake, A., M. T. Sinclair, and G. Sugiyarto. 2003.
Quantifying the impact of foot and mouth disease on
tourism and the UK economy. Tourism Economics,
9(4):449?465.
Collier, N., A. Kawazoe, L. Jin, M. Shigematsu,
D. Dien, R. Barrero, K. Takeuchi, and A. Kaw-
trakul. 2006. A multilingual ontology for infectious
disease surveillance: rationale, design and chal-
lenges. Language Resources and Evaluation, 40(3?
4). DOI: 10.1007/s10579-007-9019-7.
Collier, N., S. Doan, A. Kawazoe, R. Matsuda Good-
win, M. Conway, Y. Tateno, Q. Ngo, D. Dien,
A. Kawtrakul, K. Takeuchi, M. Shigematsu, and
K. Taniguchi. 2008. BioCaster:detecting public
health rumors with a web-based text mining sys-
tem. Bioinformatics, 24(24):2940?1, December.
doi:10.1093/bioinformatics/btn534.
Collier, N. 2010. What?s unusual in online dis-
ease outbreak news? Biomedical Semantics, 1(1),
March. doi:10.1186/2041-1480-1-2.
Cox, N., S. Temblyn, and T. Tam. 2003. Influenza
pandemic planning. Vaccine, 21(16):1801?1803.
Freifeld, C., K. Mandl, B. Reis, and J. Brownstein.
2008. Healthmap: global infectious disease mon-
itoring through automated classification and visual-
ization of internet media reports. J. American Med-
ical Informatics Association, 15:150?157.
Ginsberg, J., M. Mohebbi, R. Patel, L. Brammer,
M. Smolinski, and L. Brilliant. 2009. Detecting
influenza epidemics using search engine query data.
Nature, 457:1012?1014.
Grey Cowell, L. and B. Smith. 2010. Infectious dis-
ease informatics. In Sintchenko, V., editor, Infec-
tious Disease Informatics, pages 373?395. Springer
New York.
221
Guarino, N. and C. Welty. 2000. A formal ontology
of properties. In Dieng, R. and O. Corby, editors,
EKAW-2000: Proc. 12th Int. Conf. on Knowledge
Engineering and Knowledge Management, pages
97?112.
Hartley, D., N. Nelson, R. Walters, R. Arthur, R. Yan-
garber, L. Madoff, J. Linge, A. Mawudeku, N. Col-
lier, J. Brownstein, G. Thinus, and N. Lightfoot.
2010. The landscape of international biosurveil-
lance. Emerging Health Threats J., 3(e3), January.
doi:10.1093/bioinformatics/btn534.
Lawrence, O. and J. Gostin. 2004. International
infectious disease law - revision of the World
Health Organization?s international health regula-
tions. J. American Medical Informatics Associa-
tion, 291(21):2623?2627.
Lindberg, Donald A.B., L. Humphreys, Betsy, and
T. McCray, Alexa. 1993. The unified medical lan-
guage system. Methods of Information in Medicine,
32:281?291.
Lipscomb, C. 2000. Medical subject headings
(MeSH). Bulletin of the Medical Library Assoca-
tion, 88:256?266.
Madoff, Lawrence C. and John P. Woodall. 2005. The
internet and the global monitoring of emerging dis-
eases: Lessons from the first 10 years of promed-
mail. Archives of Medical Research, 36(6):724 ?
730. Infectious Diseases: Revisiting Past Problems
and Addressing Future Challenges.
Mawudeku, A. and M. Blench. 2006. Global pub-
lic health intelligence network (gphin). In Proc. 7th
Int. Conf. of the Association for Machine Transla-
tion in the Americas, Cambridge, MA, USA, August
8?12.
McCrae, J., M. Conway, and N. Collier. 2009. Simple
rule language editor. Google code project, Septem-
ber. Available from: http://code.google.com/p/srl-
editor/.
Miles, A., B. Matthews, and M. Wilson. 2005. SKOS
Core: Simple knowledge organization for the web.
In Proc. Int. Conf. on Dublin Core and Metadata
Applications, Madrid, Spain, 12?15 September.
Niles, I. and A. Pease. 2001. Towards a standard up-
per ontology. In Welty, C. and B. Smith, editors,
2nd Int. Conf. on Formal Ontology in Information
Systems FOIS-2001, Maine, USA, October 17?19.
Okhamatovskaia, A., W. Chapman, N. Collier, J. Es-
pino, and D. Buckeridge. 2009. SSO: The syn-
dromic surveillance ontology. In Proc. Int. Soc. for
Disease Surveillance, Miami, USA, December 3?4.
Stearns, M. Q., C. Price, K. A. Spackman, and A. Y.
Wang. 2001. SNOMED clinical terms: overview of
the development process and project status. In Proc.
American Medical Informatics Association (AMIA)
Symposium, pages 662?666.
Vossen, P. 1998. Introduction to EuroWordNet. Com-
puters and the Humanities, 32:73?89.
Wagner, M. and H. Johnson. 2006. The internet as
sentinel. In Wagner, M. et al, editor, The Hand-
book of Biosurveillance, pages 375?385. Academic
Press.
WHO. 2004. ICD-10, International Statistical Classi-
fication of Diseases and Related Health Problems,
Tenth Revision. World Health Organization, De-
cember.
WHO. 2005. Avian influenza: assessing the pandemic
threat. Technical Report WHO/CDS/2005.29,
World Health Organization, Geneva, January.
Wilson, J. 2007. Argus: a global detection and track-
ing system for biological events. Advances in Dis-
ease Surveillance, 4.
Yangarber, R., P. von Etter, and R. Steinberger. 2008.
Content collection and analysis in the domain of
epidemiology. In Proc. Int. Workshop on Describ-
ingMedical Web Resources (DRMED 2008), Goten-
burg, Sweden, May 27th.
222
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1732?1740,
Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational Linguistics
Orthonormal Explicit Topic Analysis for Cross-lingual Document Matching
John Philip McCrae
University Bielefeld
Inspiration 1
Bielefeld, Germany
Philipp Cimiano
University Bielefeld
Inspiration 1
Bielefeld, Germany
{jmccrae,cimiano,rklinger}@cit-ec.uni-bielefeld.de
Roman Klinger
University Bielefeld
Inspiration 1
Bielefeld, Germany
Abstract
Cross-lingual topic modelling has applications
in machine translation, word sense disam-
biguation and terminology alignment. Multi-
lingual extensions of approaches based on la-
tent (LSI), generative (LDA, PLSI) as well as
explicit (ESA) topic modelling can induce an
interlingual topic space allowing documents
in different languages to be mapped into the
same space and thus to be compared across
languages. In this paper, we present a novel
approach that combines latent and explicit
topic modelling approaches in the sense that
it builds on a set of explicitly defined top-
ics, but then computes latent relations between
these. Thus, the method combines the ben-
efits of both explicit and latent topic mod-
elling approaches. We show that on a cross-
lingual mate retrieval task, our model signif-
icantly outperforms LDA, LSI, and ESA, as
well as a baseline that translates every word in
a document into the target language.
1 Introduction
Cross-lingual document matching is the task of,
given a query document in some source language,
estimating the similarity to a document in some tar-
get language. This task has important applications in
machine translation (Palmer et al, 1998; Tam et al,
2007), word sense disambiguation (Li et al, 2010)
and ontology alignment (Spiliopoulos et al, 2007).
An approach that has become quite popular in re-
cent years for cross-lingual document matching is
Explicit Semantics Analysis (ESA, Gabrilovich and
Markovitch (2007)) and its cross-lingual extension
CL-ESA (Sorg and Cimiano, 2008). ESA indexes
documents by mapping them into a topic space de-
fined by their similarity to predefined explicit top-
ics ? generally articles from an encyclopaedia ? in
such a way that there is a one-to-one correspondence
between topics and encyclopedic entries. CL-ESA
extends this to the multilingual case by exploiting
a background document collection that is aligned
across languages, such as Wikipedia. A feature of
ESA and its extension CL-ESA is that, in contrast to
latent (e.g. LSI, Deerwester et al (1990)) or genera-
tive topic models (such as LDA, Blei et al (2003)),
it requires no training and, nevertheless, has been
demonstrated to outperform LSI and LDA on cross-
lingual retrieval tasks (Cimiano et al, 2009).
A key choice in Explicit Semantic Analysis is the
document space that will act as the topic space. The
standard choice is to regard all articles from a back-
ground document collection ? Wikipedia articles are
a typical choice ? as the topic space. However, it
is crucial to ensure that these topics cover the se-
mantic space evenly and completely. In this pa-
per, we present an alternative approach where we
remap the semantic space defined by the topics in
such a manner that it is orthonormal. In this way,
each document is mapped to a topic that is distinct
from all other topics. Such a mapping can be con-
sidered as equivalent to a variant of Latent Seman-
tic Indexing (LSI) with the main difference that our
model exploits the matrix that maps topic vectors
back into document space, which is normally dis-
carded in LSI-based approaches. We dub our model
ONETA (OrthoNormal Explicit Topic Analysis) and
empirically show that on a cross-lingual retrieval
1732
task it outperforms ESA, LSI, and Latent Dirichlet
Allocation (LDA) as well as a baseline consisting of
translating each word into the target language, thus
reducing the task to a standard monolingual match-
ing task. In particular, we quantify the effect of dif-
ferent approximation techniques for computing the
orthonormal basis and investigate the effect of vari-
ous methods for the normalization of frequency vec-
tors.
The structure of the paper is as follows: we situate
our work in the general context of related work on
topic models for cross-lingual document matching
in Section 2. We present our model in Section 3 and
present our experimental results and discuss these
results in Section 4.
2 Related Work
The idea of applying topic models that map docu-
ments into an interlingual topic space seems a quite
natural and principled approach to tackle several
tasks including the cross-lingual document retrieval
problem.
Topic modelling is the process of finding a rep-
resentation of a document d in a lower dimensional
space RK where each dimension corresponds to one
topic that abstracts from specific words and thus al-
lows us to detect deeper semantic similarities be-
tween documents beyond the computation of the
pure overlap in terms of words.
Three main variants of document models have
been mainly considered for cross-lingual document
matching:
Latent methods such as Latent Semantic Indexing
(LSI, Deerwester et al (1990)) induce a de-
composition of the term-document matrix in
a way that reduces the dimensionality of the
documents, while minimizing the error in re-
constructing the training data. For example,
in Latent Semantic Indexing, a term-document
matrix is approximated by a partial singu-
lar value decomposition, or in Non-Negative
Matrix Factorization (NMF, Lee and Seung
(1999)) by two smaller non-negative matrices.
If we append comparable or equivalent doc-
uments in multiple languages together before
computing the decomposition as proposed by
Dumais et al (1997) then the topic model is
essentially cross-lingual allowing to compare
documents in different languages once they
have been mapped into the topic space.
Probabilistic or generative methods instead at-
tempt to induce a (topic) model that has the
highest likelihood of generating the documents
actually observed during training. As with la-
tent methods, these topics are thus interlin-
gual and can generate words/terms in differ-
ent languages. Prominent representatives of
this type of method are Probabilistic Latent Se-
mantic Indexing (PLSI, Hofmann (1999)) or
Latent Dirichlet Allocation (LDA, Blei et al
(2003)), both of which can be straightforwardly
extended to the cross-lingual case (Mimno et
al., 2009).
Explicit topic models make the assumption that
topics are explicitly given instead of being in-
duced from training data. Typically, a back-
ground document collection is assumed to be
given whereby each document in this corpus
corresponds to one topic. A mapping from doc-
ument to topic space is calculated by comput-
ing the similarity of the document to every doc-
ument in the topic space. A prominent exam-
ple for this kind of topic modelling approach is
Explicit Semantic Analysis (ESA, Gabrilovich
and Markovitch (2007)).
Both latent and generative topic models attempt to
find topics from the data and it has been found that
in some cases they are equivalent (Ding et al, 2006).
However, this approach suffers from the problem
that the topics might be artifacts of the training data
rather than coherent semantic topics. In contrast, ex-
plicit topic methods can use a set of topics that are
chosen to be well-suited to the domain. The princi-
ple drawback of this is that the method for choosing
such explicit topics by selecting documents is com-
paratively crude. In general, these topics may be
overlapping and poorly distributed over the seman-
tic topic space. By comparison, our method takes the
advantage of the pre-specified topics of explicit topic
models, but incorporates a training step to learn la-
tent relations between these topics.
1733
3 Orthonormal explicit topic analysis
Our approach follows Explicit Semantic Analysis in
the sense that it assumes the availability of a back-
ground document collection B = {b1, b2, ..., bN}
consisting of textual representations. The map-
ping into the explicit topic space is defined by a
language-specific function ? that maps documents
into RN such that the jth value in the vector is given
by some association measure ?j(d) for each back-
ground document bj . Typical choices for this associ-
ation measure ? are the sum of the TF-IDF scores or
an information retrieval relevance scoring function
such as BM-25 (Sorg and Cimiano, 2010).
For the case of TF-IDF, the value of the j-th ele-
ment of the topic vector is given by:
?j(d) =
????
tf-idf(bj)
T ????tf-idf(d)
Thus, the mapping function can be represented as
the product of a TF-IDF vector of document dmulti-
plied by anW?N matrix, X, each element of which
contains the TF-IDF value of word i in document bj :
?(d) =
?
?
?
?
????
tf-idf(b1)T
...
????
tf-idf(bN )T
?
?
?
?
????
tf-idf(d) = XT ?
????
tf-idf(d)
For simplicity, we shall assume from this point on
that all vectors are already converted to a TF-IDF
or similar numeric vector form. In order to com-
pute the similarity between two documents di and
dj , typically the cosine-function (or the normalized
dot product) between the vectors ?(di) and ?(dj) is
computed as follows:
sim(di, dj) = cos(?(di),?(dj)) =
?(di)T?(dj)
||?(di)||||?(dj)||
If we represent the above using our above defined
W ?N matrix X then we get:
sim(di, dj) = cos(X
Tdi,X
Tdj) =
dTi XX
Tdj
||XTdi||||XTdj ||
The key challenge with ESA is choosing a good
background document collection B = {b1, ..., bN}.
A simple minimal criterion for a good background
document collection is that each document in this
collection should be maximally similar to itself and
less similar to any other document:
?i 6= j 1 = sim(bj , bj) > sim(bi, bj) ? 0
While this criterion is trivially satisfied if we have
no duplicate documents in our collection, our intu-
ition is that we should choose a background collec-
tion that maximizes the slack margin of this inequal-
ity, i.e. |sim(bj , bj) ? sim(bi, bj)|. We can see that
maximizing this margin for all i,j is the same as
minimizing the semantic overlap of the background
documents, which is given as follows:
overlap(B) =
?
i = 1, . . . , N
j = 1, . . . , N
i 6= j
sim(bi, bj)
We first note that we can, without loss of general-
ity, normalize our background documents such that
||Xbj || = 1 for all j, and in this case we can re-
define the semantic overlap as the following matrix
expression1
overlap(X) = ||XTXXTX? I||1
It is trivial to verify that this equation has a mini-
mum when XTXXTX = I. This is the case when
the topics are orthonormal:
(XTbi)T(XTbj) = 0 if i 6= j
(XTbi)T(XTbi) = 1
Unfortunately, this is not typically the case as the
documents have significant word overlap as well as
semantic overlap. Our goal is thus to apply a suitable
transformation to X with the goal of ensuring that
the orthogonality property holds.
Assuming that this transformation of X is done
by multiplication with some other matrix A, we can
define the learning problem as finding that matrix A
such that:
(AXTX)T(AXTX) = I
1||A||p =
?
i,j |aij |
p is the p-norm. ||A||F =
?
||A||2 is
the Frobenius norm.
1734
If we have the case that W ? N and that the rank
of X is N , then XTX is invertible and thus A =
(XTX)?1 is the solution to this problem.2
We define the projection function of a document
d, represented as a normalized term frequency vec-
tor, as follows:
?ONETA(d) = (X
TX)?1XTd
For the cross-lingual case we assume that we have
two sets of background documents of equal size,
B1 = {b11, . . . , b
1
N}, B
2 = {b21, . . . , b
2
N} in lan-
guages l1 and l2, respectively and that these doc-
uments are aligned such that for every index i, b1i
and b2i are documents on the same topic in each
language. Using this we can construct a projec-
tion function for each language which maps into the
same topic space. Thus, as in CL-ESA, we obtain
the cross-lingual similarity between a document di
in language l1 and a document dj in language l2 as
follows:
sim(di, dj) = cos(?
l1
ONETA(di),?
l2
ONETA(dj))
We note here that we assume that ? could be rep-
resented as a symmetric inner product of two vec-
tors. However, for many common choices of asso-
ciation measures, including BM25, this is not the
case. In this case the expression XTX can be re-
placed with a kernel matrix specifying the associ-
ation of each background document to each other
background document.
3.1 Relationship to Latent Semantic Indexing
In this section we briefly clarify the relationship be-
tween our method ONETA and Latent Semantic In-
dexing. Latent Semantic Indexing defines a map-
ping from a document represented as a term fre-
quency vector to a vector in RK . This transforma-
tion is defined by means of calculating the singu-
lar value decomposition (SVD) of the matrix X as
above, namely
2In the case that the matrix is not invertible we can in-
stead solve ||XTXA ? I||F , which has a minimum at A =
V??1UT where XTX = U?VT is the singular value de-
composition of XTX.
As usual we do not in fact compute the inverse for our exper-
iments, but instead the LU Decomposition and solve by Gaus-
sian elimination at test time.
X = U?VT
Where ? is diagonal and U V are the eigenvec-
tors of XXT and XTX., respectively. Let ?K de-
note the K ? K submatrix containing the largest
eigenvalues, and UK ,VK denote the corresponding
eigenvectors. Thus LSI can be defined as:
?LSI(d) = ?
?1
K UKd
With regards to orthonormalized topics, we see
that using the SVD, we can simply derive the fol-
lowing:
(XTX)?1XT = V??1UT
When we set K = N and thus choose the maxi-
mum number of topics, ONETA is equivalent to LSI
modulo the fact that it multiplies the resulting topic
vector by V, thus projecting back into document
space, i.e. into explicit topics.
In practice, both methods differ significantly in
that the approximations they make are quite differ-
ent. Furthermore, in the case that W  N and X
has n non-zeroes, the calculation of the SVD is of
complexity O(nN + WN2) and requires O(WN)
bytes of memory. In contrast, ONETA requires com-
putation time ofO(Na) for a > 2, which is the com-
plexity of the matrix inversion algorithm3, and only
O(n+N2) bytes of memory.
3.2 Approximations
The computation of the inverse has a complexity
that, using current practical algorithms, is approxi-
mately cubic and as such the time spent calculating
the inverse can grow very quickly. There are sev-
eral methods for obtaining an approximate inverse.
The most commonly used are based on the SVD or
eigendecomposition of the matrix. As XTX is sym-
metric positive definite, it holds that:
XTX = U?UT
Where U are the eigenvectors of XTX and ? is
a diagonal matrix of the eigenvalues. With UK ,?K
3Algorithms with a = 2.3727 are known but practical algo-
rithms have a = 2.807 or a = 3 (Coppersmith and Winograd,
1990)
1735
as the first K eigenvalues and eigenvectors, respec-
tively, we have:
(XTX)?1 ' UK?
?1
K U
T
K (1)
We call this the orthonormal eigenapproxima-
tion or ON-Eigen. The complexity of calculating
(XTX)?1XT from this is O(N2K + Nn), where
n is the number of non-zeros in X.
Similarly, using the formula derived in the previ-
ous section we can derive an approximation of the
full model as follows:
(XTX)?1XT ' UK?
?1
K V
T
K (2)
We call this approximation Explicit LSI as it first
maps into the latent topic space and then into the
explicit topic space.
We can consider another approximation by notic-
ing that X is typically very sparse and moreover
some rows of X have significantly fewer non-zeroes
than others (these rows are for terms with low fre-
quency). Thus, if we take the first N1 columns (doc-
uments) in X, it is possible to rearrange the rows
of X with the result that there is some W1 such
that rows with index greater than W1 have only ze-
roes in the columns up to N1. In other words, we
take a subset of N1 documents and enumerate the
words in such a way that the terms occurring in the
first N1 documents are enumerated 1, . . . ,W1. Let
N2 = N ? N1, W2 = W ?W1. The result of this
row permutation does not affect the value of XTX
and we can write the matrix X as:
X =
(
A B
0 C
)
where A is a W1 ? N1 matrix representing term
frequencies in the first N1 documents, B is a W1 ?
N2 matrix containing term frequencies in the re-
maining documents for terms that are also found in
the firstN1 documents, and C is aW2?N2 contain-
ing the frequency of all terms not found in the first
N1 documents.
Application of the well-known divide-and-
conquer formula (Bernstein, 2005, p. 159) for
matrix inversion yields the following easily verifi-
able matrix identity, given that we can find C? such
that C?C = I.
(
(ATA)?1AT ?(ATA)?1ATBC?
0 C?
)(
A B
0 C
)
= I
(3)
We denote the above equation using a matrix L
as LTX = I. We note that L 6= (XTX)?1X,
but for any document vector d that is representable
as a linear combination of the background doc-
ument set (i.e., columns of X) we have that
Ld = (XTX)?1XTd and in this sense L '
(XTX)?1XT.
We further relax the assumption so that we only
need to find a C? such that C?C ' I. For this,
we first observe that C is very sparse as it contains
only terms not contained in the first N1 documents
and we notice that very sparse matrices tend to be
approximately orthogonal, hence suggesting that it
should be very easy to find a left-inverse of C. The
following lemma formalizes this intuition:
Lemma: If C is a W ? N matrix with M non-
zeros, distributed randomly and uniformly across the
matrix, and all the non-zeros are 1, then DCTC has
an expected value on each non-diagonal value of MN2
and a diagonal value of 1 if D is the diagonal matrix
whose values are given by ||ci||?2, the square of the
norm of the corresponding column of C.
Proof: We simply observe that if D? = DCTC,
then the (i, j)th element of D? is given by
dij =
cTi cj
||ci||2
If i 6= j then the cTi cj is the number of non-zeroes
overlapping in the ith and jth column of C and under
a uniform distribution we expect this to be M
2
N3 . Sim-
ilarly, we expect the column norm to be MN such that
the overall expectation is MN2 . The diagonal value is
clearly equal to 1.
As long as C is very sparse, we can use the fol-
lowing approximation, which can be calculated in
O(M) operations, where M is the number of non-
zeroes.
C? '
?
?
?
||c1||?2 0
. . .
0 ||cN2 ||
?2
?
?
?CT
We call this method L-Solve. The complexity
of calculating a left-inverse by this method is of
1736
Document
Normalization
Frequency Normalization No Yes
TF 0.31 0.78
Relative 0.23 0.42
TFIDF 0.21 0.63
SQRT 0.28 0.66
Table 1: Effect of Term Frequency and Document Nor-
malization on Top-1 Precision
order O(Na1 ), being much more efficient than the
eigenvalue methods. However, it is potentially more
error-prone as it requires that a left-inverse of C ex-
ists. On real data this might be violated if we do not
have linear independence of the rows of C, for ex-
ample if W2 < N2 or if we have even one document
which has only words that are also contained in the
first N1 documents and hence there is a row in C
that consists of zeros only. This can be solved by
removing documents from the collection until C is
row-wise linear independent.4
3.3 Normalization
A key factor in the effectiveness of topic-based
methods is the appropriate normalization of the el-
ements of the document matrix X. This is even
more relevant for orthonormal topics as the matrix
inversion procedure can be very sensitive to small
changes in the matrix. In this context, we con-
sider two forms of normalization, term and docu-
ment normalization, which can also be considered
as row/column normalizations of X.
A straightforward approach to normalization is to
normalize each column of X to obtain a matrix as
follows:
X? =
(
x1
||x1||
. . .
xN
||xN ||
)
If we calculate X?TX? = Y then we get that the
(i, j)-th element of Y is:
yij =
xTi xj
||xi||||xj ||
4In the experiments in the next section we discarded 4.2% of
documents at N1 = 1000 and 47% of documents at N1 = 5000
l
l
l
l
l
l
l
l l l
l l
l l l l
l
l
l l
100 200 300 400 500
0.0
0.2
0.4
0.6
0.8
Approximation rate
Pre
cisio
n
l l
l
l
l
l l
l
l l l
l l
l l
l
l
l
?
ON?EigenL?SolveExplicit LSILSIESA
Figure 1: Effect on Top-1 Precision by various approxi-
mation method
Thus, the diagonal of Y consists of ones only and
due to the Cauchy-Schwarz inequality we have that
|yij | ? 1, with the result that the matrix Y is al-
ready close to I. Formally, we can use this to state
a bound on ||X?TX? ? I||F , but in practice it means
that the orthonormalizing matrix has more small or
zero values.
A further option for normalization is to consider
some form of term frequency normalization. For
term frequency normalization, we use TF (tfwn),
Relative ( tfwnFw ), TFIDF (tfwn log(
N
dfw
)), and SQRT
( tfwn?
Fw
). Here, tfwn is the term frequency of word w
in document n, Fw is the total frequency of word
w in the corpus, and dfw is the number of docu-
ments containing the words w. The first three of
these normalizations have been chosen as they are
widely used in the literature. The SQRT normaliza-
tion has been shown to be effective for explicit topic
methods in previous experiments not reported here.
4 Experiments and Results
For evaluation, we consider a cross-lingual mate re-
trieval task from English/Spanish on the basis of
Wikipedia as aligned corpus. The goal is to, for each
document of a test set, retrieve the aligned document
or mate. For each test document, on the basis of
1737
Method Top-1 Prec. Top-5 Prec. Top-10 Prec. MRR Time Memory
ONETA L-Solve (N1 = 1000) 0.290 0.501 0.596 0.390 73s 354MB
ONETA L-Solve (N1 = 2000) 0.328 0.531 0.600 0.423 2m18s 508MB
ONETA L-Solve (N1 = 3000) 0.462 0.662 0.716 0.551 4m12s 718MB
ONETA L-Solve (N1 = 4000) 0.599 0.755 0.781 0.667 7m44s 996MB
ONETA L-Solve (N1 = 5000) 0.695 0.817 0.843 0.750 12m28s 1.30GB
ONETA L-Solve (N1 = 6000) 0.773 0.883 0.905 0.824 18m40s 1.69GB
ONETA L-Solve (N1 = 7000) 0.841 0.928 0.937 0.881 26m31s 2.14GB
ONETA L-Solve (N1 = 8000) 0.896 0.961 0.968 0.927 37m39s 2.65GB
ONETA L-Solve (N1 = 9000) 0.924 0.981 0.987 0.950 52m52s 3.22GB
ONETA (No Approximation) 0.929 0.987 0.990 0.956 57m10s 3.42GB
Word Translation 0.751 0.884 0.916 0.812 n/a n/a
ESA (SQRT Normalization) 0.498 0.769 0.835 0.621 72s 284MB
LDA (K=1000) 0.287 0.568 0.659 0.417 4h12m 8.4GB
LSI (K=4000) 0.615 0.756 0.783 0.676 13h51m 19.7GB
ONETA + Word Translation 0.932 0.987 0.993 0.958 n/a n/a
Table 2: Result on large-scale mate-finding studies for English to Spanish matching
the similarity of the query document to all indexed
documents, we compute the value ranki indicating
at which position the mate of the ith document oc-
curs. We use two metrics: Top-k Precision, defined
as the percentage of documents for which the mate is
retrieved among the first k elements, and Minimum
Reciprocal Rank, defined as
MRR =
?
i?test
1
ranki
For our experiments, we first extracted a subset
of documents (every 20th) from Wikipedia, filtering
this set down to only those that have aligned pages
in both English and Spanish with a minimum length
of 100 words. This gives us 10,369 aligned doc-
uments in total, which form the background docu-
ment collection B. We split this data into a training
and test set of 9,332 and 1,037 documents, respec-
tively. We then removed all words whose total fre-
quencies were below 50. This resulted in corpus of
6.7 millions words in English and 4.2 million words
in Spanish.
Normalization Methods: In order to investigate
the impact of different normalization methods, we
ran small-scale experiments using the first 500 doc-
uments from our dataset to train ONETA and then
evaluate the resulting models on the mate-finding
task on 100 unseen documents. The results are pre-
sented in Table 1, which shows the Top-1 Precision
for the different normalization methods. We see that
the effect of applying document normalization in
all cases improves the quality of the overall result.
Surprisingly, we do not see the same result for fre-
quency normalization yielding the best result for the
case where we do no normalization at all5 . In the re-
maining experiments we thus employ document nor-
malization and no term frequency normalization.
ApproximationMethods: In order to evaluate the
different approximation methods, we experimen-
tally compare 4 different approximation methods:
standard LSI, ON-Eigen (Equation 1), Explicit LSI
(Equation 2), L-Solve (Equation 3) on the same
small-scale corpus. For convenience we plot an ap-
proximation rate which is either K or N1 depending
on method; at K = 500 and N1 = 500, these ap-
proximations become exact. This is shown in Figure
1. We also observe the effects of approximation and
see that the performance increases steadily as we
increase the computational factor. We see that the
orthonormal eigenvector (Equation 1) method and
the L-solve (Equation 3) method are clearly simi-
lar in approximation quality. We see that the explicit
LSI method (Equation 2) and the LSI method both
perform significantly worse for most of the approxi-
5A likely explanation for this is that low frequency terms are
less evenly distributed and the effect of calculating the matrix
inverse magnifies the noise from the low frequency terms
1738
mation amounts. Explicit LSI is worse than the other
approximations as it first maps the test documents
into a K-dimensional LSI topic space, before map-
ping back into theN -dimensional explicit space. As
expected this performs worse than standard LSI for
all but high values of K as there is significant error
in both mappings. We also see that the (CL-)ESA
baseline, which is very low due to the small number
of documents, is improved upon by even the least ap-
proximation of orthonormalization. In the remain-
ing of this section, we report results using the L-
Solve method as it has a very good performance and
is computationally less expensive than ON-Eigen.
Evaluation and Comparison: We compare
ONETA using the L-Solve method with N1 values
from 1000 to 9000 topics with (CL-)ESA (using
SQRT normalization), LDA (using 1000 topics)
and LSI (using 4000 topics). We choose the largest
topic count for LSI and LDA we could to provide
the best possible comparison. For LSI, the choice of
K was determined on the basis of operating system
memory limits, while for LDA we experimented
with higher values for K without any performance
improvement, likely due to overfitting. We also
stress that for L-Solve ONETA, N1 is not the topic
count but an approximation rate of the mapping. In
all settings we use N topics as with standard ESA,
and so should not be considered directly comparable
to the K values of these methods.
We also compare to a baseline system that re-
lies on word-by-word translation, where we use the
most likely single translation of a word as given by a
phrase table generated by the Moses system (Koehn
et al, 2007) on the EuroParl corpus (Koehn, 2005).
Top 1, Top 5 and Top 10 Precision as well as Mean
Reciprocal Rank are reported in Table 2.
Interestingly, even for a small number of docu-
ments (e.g., N1 = 6000) our results improve both
the word-translation baseline as well as all other
topic models, ESA, LDA and LSI in particular. We
note that at this level the method is still efficiently
computable and calculating the inverse in practice
takes less time than training the Moses system. The
significance for results (N1 ? 7000) have been
tested by means of a bootstrap resampling signifi-
cance test, finding out that our results significantly
improve on the translation base line at a 99% level.
Further, we consider a straightforward combina-
tion of our method with the translation system con-
sisting of appending the topic vectors and the trans-
lation frequency vectors, weighted by the relative
average norms of the vectors. We see that in this
case the translations continue to improve the perfor-
mance of the system (albeit not significantly), sug-
gesting a clear potential for this system to help in im-
proving machine translation results. While we have
presented results for English and Spanish here, simi-
lar results were obtained for the German and French
case but are not presented here due to space limita-
tions.
In Table 2 we also include the user time and peak
resident memory of each of these processes, mea-
sured on an 8 Core Intel Xeon 2.50 GHz server.
We do not include the results for Word Translation
as many hours were spent learning a phrase table,
which includes translations for many phrases not in
the test set. We see that the ONETA method signif-
icantly outperforms LSI and LDA in terms of speed
and memory consumption. This is in line with the
theoretical calculations presented earlier where we
argued that inverting the N ?N dense matrix XTX
when W  N is computationally lighter than find-
ing an eigendecomposition of the W ? W sparse
matrix XXT. In addition, as we do not multiply
(XTX)?1 and XT, we do not need to allocate a
large W ? K matrix in memory as with LSI and
LDA.
The implementations of ESA, ONETA,
LSI and LDA used as well as the data
for the experiments are available at
http://github.com/jmccrae/oneta.
5 Conclusion
We have presented a novel method for cross-lingual
topic modelling, which combines the strengths of
explicit and latent topic models and have demon-
strated its application to cross-lingual document
matching. We have in particular shown that the
method outperforms widely used topic models such
as Explicit Semantic Analysis (ESA), Latent Seman-
tic Indexing (LSI) and Latent Dirichlet Allocation
(LDA). Further, we have shown that it outperforms
a simple baseline relying on word-by-word transla-
tion of the query document into the target language,
1739
while the induction of the model takes less time
than training the machine translation system from a
parallel corpus. We have also presented an effec-
tive approximation method, i.e. L-Solve, which sig-
nificantly reduces the computational cost associated
with computing the topic models.
Acknowledgements
This work was funded by the Monnet Project
and the Portdial Project under the EC Sev-
enth Framework Programme, Grants No.
248458 and 296170. Roman Klinger has been
funded by the ?Its OWL? project (?Intelli-
gent Technical Systems Ostwestfalen-Lippe?,
http://www.its-owl.de/), a leading-edge
cluster of the German Ministry of Education and
Research.
References
Dennis S Bernstein. 2005. Matrix mathematics, 2nd Edi-
tion. Princeton University Press Princeton.
David M Blei, Andrew Y Ng, and Michael I Jordan.
2003. Latent Dirichlet Allocation. Journal of Ma-
chine Learning Research, 3:993?1022.
Philipp Cimiano, Antje Schultz, Sergej Sizov, Philipp
Sorg, and Steffen Staab. 2009. Explicit versus la-
tent concept models for cross-language information re-
trieval. In IJCAI, volume 9, pages 1513?1518.
Don Coppersmith and Shmuel Winograd. 1990. Matrix
multiplication via arithmetic progressions. Journal of
symbolic computation, 9(3):251?280.
Scott C. Deerwester, Susan T Dumais, Thomas K. Lan-
dauer, George W. Furnas, and Richard A. Harshman.
1990. Indexing by latent semantic analysis. JASIS,
41(6):391?407.
Chris Ding, Tao Li, and Wei Peng. 2006. NMF and
PLSI: equivalence and a hybrid algorithm. In Pro-
ceedings of the 29th annual international ACM SIGIR,
pages 641?642. ACM.
Susan T Dumais, Todd A Letsche, Michael L Littman,
and Thomas K Landauer. 1997. Automatic cross-
language retrieval using latent semantic indexing. In
AAAI spring symposium on cross-language text and
speech retrieval, volume 15, page 21.
Evgeniy Gabrilovich and Shaul Markovitch. 2007. Com-
puting semantic relatedness using Wikipedia-based ex-
plicit semantic analysis. In Proceedings of the 20th In-
ternational Joint Conference on Artificial Intelligence,
volume 6, page 12.
Thomas Hofmann. 1999. Probabilistic latent semantic
indexing. In Proceedings of the 22nd annual interna-
tional ACM SIGIR conference, pages 50?57. ACM.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, et al 2007. Moses: Open source toolkit for sta-
tistical machine translation. In Proceedings of the 45th
Annual Meeting of the ACL, pages 177?180. Associa-
tion for Computational Linguistics.
Philipp Koehn. 2005. Europarl: A parallel corpus for sta-
tistical machine translation. In MT summit, volume 5.
Daniel D Lee and H Sebastian Seung. 1999. Learning
the parts of objects by non-negative matrix factoriza-
tion. Nature, 401(6755):788?791.
Linlin Li, Benjamin Roth, and Caroline Sporleder. 2010.
Topic models for word sense disambiguation and
token-based idiom detection. In Proceedings of the
48th Annual Meeting of the Association for Computa-
tional Linguistics, pages 1138?1147. Association for
Computational Linguistics.
David Mimno, Hanna M Wallach, Jason Naradowsky,
David A Smith, and Andrew McCallum. 2009.
Polylingual topic models. In Proceedings of the 2009
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 880?889. Association for
Computational Linguistics.
Martha Palmer, Owen Rambow, and Alexis Nasr. 1998.
Rapid prototyping of domain-specific machine trans-
lation systems. In Machine Translation and the Infor-
mation Soup, pages 95?102. Springer.
Philipp Sorg and Philipp Cimiano. 2008. Cross-lingual
information retrieval with explicit semantic analysis.
In Proceedings of the Cross-language Evaluation Fo-
rum 2008.
Philipp Sorg and Philipp Cimiano. 2010. An experi-
mental comparison of explicit semantic analysis im-
plementations for cross-language retrieval. In Natural
Language Processing and Information Systems, pages
36?48. Springer.
Vassilis Spiliopoulos, George A Vouros, and Vangelis
Karkaletsis. 2007. Mapping ontologies elements us-
ing features in a latent space. In IEEE/WIC/ACM
International Conference on Web Intelligence, pages
457?460. IEEE.
Yik-Cheung Tam, Ian Lane, and Tanja Schultz. 2007.
Bilingual LSA-based adaptation for statistical machine
translation. Machine Translation, 21(4):187?207.
1740
Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 119?122,
Dublin, Ireland, August 23-24, 2014.
Bielefeld SC: Orthonormal Topic Modelling for Grammar Induction
John P. M
c
Crae
CITEC, Bielefeld University
Inspiration 1
Bielefeld, Germany
jmccrae@cit-ec.uni-bielefeld.de
Philipp Cimiano
CITEC, Bielefeld University
Inspiration 1
Bielefeld, Germany
cimiano@cit-ec.uni-bielefeld.de
Abstract
In this paper, we consider the application
of topic modelling to the task of induct-
ing grammar rules. In particular, we look
at the use of a recently developed method
called orthonormal explicit topic analysis,
which combines explicit and latent models
of semantics. Although, it remains unclear
how topic model may be applied to the
case of grammar induction, we show that
it is not impossible and that this may allow
the capture of subtle semantic distinctions
that are not captured by other methods.
1 Introduction
Grammar induction is the task of inducing high-
level rules for application of grammars in spoken
dialogue systems. In practice, we can extract rel-
evant rules and the task of grammar induction re-
duces to finding similar rules between two strings.
As these strings are not necessarily similar in sur-
face form, what we really wish to calculate is
the semantic similarity between these strings. As
such, we could think of applying a semantic anal-
ysis method. As such we attempt to apply topic
modelling, that is methods such as Latent Dirich-
let Allocation (Blei et al., 2003), Latent Seman-
tic Analysis (Deerwester et al., 1990) or Explicit
Semantic Analysis (Gabrilovich and Markovitch,
2007). In particular we build on the recent work
to unify latent and explicit methods by means of
orthonormal explicit topics.
In topic modelling the key choice is the docu-
ment space that will act as the corpus and hence
topic space. The standard choice is to regard all
articles from a background document collection
? Wikipedia articles are a typical choice ? as the
This work is licensed under a Creative Commons At-
tribution 4.0 International Licence. Page numbers and pro-
ceedings footer are added by the organisers. Licence details:
http://creativecommons.org/licenses/by/4.0/
topic space. However, it is crucial to ensure that
these topics cover the semantic space evenly and
completely. Following McCrae et al. (McCrae et
al., 2013) we remap the semantic space defined by
the topics in such a manner that it is orthonormal.
In this way, each document is mapped to a topic
that is distinct from all other topics.
The structure of the paper is as follows: we de-
scribe our method in three parts, first the method
in section 2, followed by approximation method in
section 3, the normalization methods in section 4
and finally the application to grammar induction
in section 5, we finish with some conclusions in
section 6.
2 Orthonormal explicit topic analysis
ONETA (McCrae et al., 2013, Orthonormal ex-
plicit topic analysis) follows Explicit Semantic
Analysis in the sense that it assumes the avail-
ability of a background document collection B =
{b
1
, b
2
, ..., b
N
} consisting of textual representa-
tions. The mapping into the explicit topic space
is defined by a language-specific function ? that
maps documents into R
N
such that the j
th
value in
the vector is given by some association measure
?
j
(d) for each background document b
j
. Typical
choices for this association measure ? are the sum
of the TF-IDF scores or an information retrieval
relevance scoring function such as BM-25 (Sorg
and Cimiano, 2010).
For the case of TF-IDF, the value of the j-th
element of the topic vector is given by:
?
j
(d) =
????
tf-idf(b
j
)
T
????
tf-idf(d)
Thus, the mapping function can be represented
as the product of a TF-IDF vector of document d
multiplied by a word-by-document (W ?N ) TF-
IDF matrix, which we denote as a X:
1
1T
denotes the matrix transpose as usual
119
?(d) =
?
?
?
????
tf-idf(b
1
)
T
.
.
.
????
tf-idf(b
N
)
T
?
?
?
????
tf-idf(d) = X
T
?
????
tf-idf(d)
For simplicity, we shall assume from this point
on that all vectors are already converted to a TF-
IDF or similar numeric vector form.
In order to compute the similarity between two
documents d
i
and d
j
, typically the cosine-function
(or the normalized dot product) between the vec-
tors ?(d
i
) and ?(d
j
) is computed as follows:
sim(d
i
, d
j
) = cos(?(d
i
),?(d
j
)) =
?(d
i
)
T
?(d
j
)
||?(d
i
)||||?(d
j
)||
sim(d
i
, d
j
) = cos(X
T
d
i
,X
T
d
j
) =
d
T
i
XX
T
d
j
||X
T
d
i
||||X
T
d
j
||
The key challenge with topic modelling is
choosing a good background document collection
B = {b
1
, ..., b
N
}. A simple minimal criterion
for a good background document collection is that
each document in this collection should be maxi-
mally similar to itself and less similar to any other
document:
?i 6= j 1 = sim(b
j
, b
j
) > sim(b
i
, b
j
) ? 0
As shown in McCrae et al. (2013), this property
is satisfied by the following projection:
?
ONETA
(d) = (X
T
X)
?1
X
T
d
And hence the similarity between two docu-
ments can be calculated as:
sim(d
i
, d
j
) = cos(?
ONETA
(d
i
),?
ONETA
(d
j
))
3 Approximations
ONETA relies on the computation of a matrix in-
verse, which has a complexity that, using current
practical algorithms, is approximately cubic and
as such the time spent calculating the inverse can
grow very quickly.
We notice that X is typically very sparse and
moreover some rows ofX have significantly fewer
non-zeroes than others (these rows are for terms
with low frequency). Thus, if we take the first N
1
columns (documents) in X, it is possible to re-
arrange the rows of X with the result that there
is some W
1
such that rows with index greater
than W
1
have only zeroes in the columns up to
N
1
. In other words, we take a subset of N
1
doc-
uments and enumerate the words in such a way
that the terms occurring in the first N
1
documents
are enumerated 1, . . . ,W
1
. Let N
2
= N ? N
1
,
W
2
= W ?W
1
. The result of this row permuta-
tion does not affect the value of X
T
X and we can
write the matrix X as:
X =
(
A B
0 C
)
where A is a W
1
? N
1
matrix representing
term frequencies in the first N
1
documents, B is a
W
1
?N
2
matrix containing term frequencies in the
remaining documents for terms that are also found
in the first N
1
documents, and C is a W
2
? N
2
containing the frequency of all terms not found in
the first N
1
documents.
Application of the well-known divide-and-
conquer formula (Bernstein, 2005, p. 159) for ma-
trix inversion yields the following easily verifiable
matrix identity, given that we can find C
?
such that
C
?
C = I.
(
(A
T
A)
?1
A
T
?(A
T
A)
?1
A
T
BC
?
0 C
?
)(
A B
0 C
)
= I
(1)
The inverse C
?
is approximated by the Jacobi
Preconditioner, J, of C
T
C:
C
?
' JC
T
(2)
=
?
?
?
||c
1
||
?2
0
.
.
.
0 ||c
N
2
||
?2
?
?
?
C
T
4 Normalization
A key factor in the effectiveness of topic-based
methods is the appropriate normalization of the el-
ements of the document matrix X. This is even
more relevant for orthonormal topics as the matrix
inversion procedure can be very sensitive to small
changes in the matrix. In this context, we con-
sider two forms of normalization, term and docu-
ment normalization, which can also be considered
as row/column normalizations of X.
A straightforward approach to normalization is
to normalize each column of X to obtain a matrix
as follows:
120
X?
=
(
x
1
||x
1
||
. . .
x
N
||x
N
||
)
If we calculate X
?
T
X
?
= Y then we get that the
(i, j)-th element of Y is:
y
ij
=
x
T
i
x
j
||x
i
||||x
j
||
Thus, the diagonal of Y consists of ones only and
due to the Cauchy-Schwarz inequality we have
that |y
ij
| ? 1, with the result that the matrix Y
is already close to I. Formally, we can use this
to state a bound on ||X
?
T
X
?
? I||
F
, but in prac-
tice it means that the orthonormalizing matrix has
more small or zero values. Previous experiments
have indicated that in general term normalization
such as TF-IDF is not as effective as using the di-
rect term frequency in ONETA, so we do not apply
term normalization.
5 Application to grammar induction
The application to grammar induction is simply
carried out by taking the rules and creating a sin-
gle ground instance. That is if we have a rule of
the form
LEAVING FROM <CITY>
We would replace the instance of <CITY> with
a known terminal for this rule, e.g.,
leaving from Berlin
This reduces the task to that of string simi-
larity which can be processed by means of any
string similarity function, for example such as the
ONETA function described above. As such the
procedure is as follows:
1. Ground the input grammar rule to an English
string d
2. Ground each candidate matching rule to an
English string d
i
3. Calculate for each d
i
, the similarity
sim
ONETA
(d, d
i
)
4. Add the rule to the grammar class with the
highest similarity
This approach has the obvious drawback that it
removes all information about the valence of the
rule, however the effect of this loss of information
remains unclear.
For application, we used 20,000 Wikipedia ar-
ticles, filtered to contain only those of over 100
words, giving us a corpus of 15.6 million tokens.
We applied ONETA using document normaliza-
tion but no term normalization and the valueN
1
=
5000. These parameters were chosen based on the
best results in previous experiments.
6 Conclusions
The results show that such a naive approach is
not directly applicable to the case of grammar in-
duction, however we believe that it is possible
that the subtle semantic similarities captured by
topic modelling may yet prove useful for gram-
mar induction. However it is clear from the pre-
sented results that the use of a topic model alone
does not suffice to solve this task. We notice that
from the data many of the distinctions rely on
antonyms and stop words, especially distinctions
such as ?to?/?from?, which are not captured by a
topic model as topic models generally ignore stop
words, and generally consider antonyms to be in
the same topic, as they frequently occur together
in text. The question of when semantic similarity
such as provided by topic modelling is applicable
remains an open question.
References
Dennis S Bernstein. 2005. Matrix mathematics, 2nd
Edition. Princeton University Press Princeton.
David M Blei, Andrew Y Ng, and Michael I Jordan.
2003. Latent Dirichlet Allocation. Journal of Ma-
chine Learning Research, 3:993?1022.
Scott C. Deerwester, Susan T Dumais, Thomas K. Lan-
dauer, George W. Furnas, and Richard A. Harshman.
1990. Indexing by latent semantic analysis. JASIS,
41(6):391?407.
Evgeniy Gabrilovich and Shaul Markovitch. 2007.
Computing semantic relatedness using Wikipedia-
based explicit semantic analysis. In Proceedings of
the 20th International Joint Conference on Artificial
Intelligence, volume 6, page 12.
John P. McCrae, Philipp Cimiano, and Roman Klinger.
2013. Orthonormal explicit topic analysis for cross-
lingual document matching. In Proceedings of the
2013 Conference on Empirical Methods in Natural
Language Processing, pages 1732?1740.
121
Philipp Sorg and Philipp Cimiano. 2010. An experi-
mental comparison of explicit semantic analysis im-
plementations for cross-language retrieval. In Natu-
ral Language Processing and Information Systems,
pages 36?48. Springer.
122
Proceedings of SSST-5, Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 116?125,
ACL HLT 2011, Portland, Oregon, USA, June 2011. c?2011 Association for Computational Linguistics
Combining statistical and semantic approaches to the translation of
ontologies and taxonomies
John McCrae
AG Semantic Computing
Universita?t Bielefeld
Bielefeld, Germany
jmccrae@cit-ec.uni-bielefeld.de
Mauricio Espinoza
Universidad de Cuenca
Cuenca, Ecuador
mauricio.espinoza@ucuenca.edu.ec
Elena Montiel-Ponsoda, Guadalupe Aguado-de-Cea
Ontology Engineering Group
Universidad Polite?cnica de Madrid
Madrid, Spain
{emontiel, lupe}@fi.upm.es
Philipp Cimiano
AG Semantic Computing
Universita?t Bielefeld
Bielefeld, Germany
cimiano@cit-ec.uni-bielefeld.de
Abstract
Ontologies and taxonomies are widely used to
organize concepts providing the basis for ac-
tivities such as indexing, and as background
knowledge for NLP tasks. As such, trans-
lation of these resources would prove use-
ful to adapt these systems to new languages.
However, we show that the nature of these
resources is significantly different from the
?free-text? paradigm used to train most sta-
tistical machine translation systems. In par-
ticular, we see significant differences in the
linguistic nature of these resources and such
resources have rich additional semantics. We
demonstrate that as a result of these linguistic
differences, standard SMT methods, in partic-
ular evaluation metrics, can produce poor per-
formance. We then look to the task of leverag-
ing these semantics for translation, which we
approach in three ways: by adapting the trans-
lation system to the domain of the resource;
by examining if semantics can help to predict
the syntactic structure used in translation; and
by evaluating if we can use existing translated
taxonomies to disambiguate translations. We
present some early results from these experi-
ments, which shed light on the degree of suc-
cess we may have with each approach.
1 Introduction
Taxonomies and ontologies are data structures that
organise conceptual information by establishing re-
lations among concepts, hierarchical and partitive
relations being the most important ones. Nowadays,
ontologies have a wide range of uses in many do-
mains, for example, finance (International Account-
ing Standards Board, 2007), bio-medicine (Col-
lier et al, 2008) (Ashburner et al, 2000) and li-
braries (Mischo, 1982). These resources normally
attach labels in natural language to the concepts and
relations that define their structure, and these la-
bels can be used for a number of purposes, such
as providing user interface localization (McCrae et
al., 2010), multilingual data access (Declerck et al,
2010), information extraction (Mu?ller et al, 2004)
and natural language generation (Bontcheva, 2005).
It seems natural that for applications that use such
ontologies and taxonomies, translation of the natu-
ral language descriptions associated with them is re-
quired in order to adapt these methods to new lan-
guages. Currently, there has been some work on
this in the context of ontology localisation, such
as Espinoza et al (2008) and (2009), Cimiano et
al. (2010), Fu et al (2010) and Navigli and Pen-
zetto (2010). However, this work has focused on the
case in which exact or partial translations are found
in other similar resources such as bilingual lexica.
Instead, in this paper we look at how we may gain an
adequate translation using statistical machine trans-
lation approaches that also utilise the semantic in-
formation beyond the label or term describing the
concept, that is relations among the concepts in the
ontology, as well as the attributes or properties that
describe concepts, as will be explained in more de-
tail in section 2.
Current work in machine translation has shown
that word sense disambiguation can play an im-
portant role by using the surrounding words as
context to disambiguate terms (Carpuat and Wu,
2007) (Apidianaki, 2009). Such techniques have
116
been extrapolated to the translation of taxonomies
and ontologies, in which the ?context? of a taxon-
omy or ontology label corresponds to the ontology
structure that surrounds the label in question. This
structure, which is made up of the lexical informa-
tion provided by labels and the semantic informa-
tion provided by the ontology structure, defines the
sense of the concept and can be exploited in the dis-
ambiguation process (Espinoza et al, 2008).
2 Definition of Taxonomy and Ontology
Translation
2.1 Formal Definition
We define a taxonomy as a set of concepts, C, with
equivalence (synonymy) links, S, subsumption (hy-
pernymy) links, H , and a labelling function l that
maps each concept to a single label from a language
??. Formally we define a taxonomy, T , as a set of
tuples (C, S,H, l) such that S ? P(C ? C) and
H ? P(C ? C) and l is a function in C ? ??. We
also require that S is a transitive, symmetric and re-
flexive relation, and H is transitive. While we note
here that this abstraction does not come close to cap-
turing the full expressive power of many ontologies
(or even taxonomies), it is sufficient for this paper to
focus on the use of only equivalence and subsump-
tion relationships for translation.
2.2 Analysis of ontology labels
Another important issue to note here is that the
kind of language used within ontologies and tax-
onomies is significantly different from that found
within free text. In particular, we observe that the
terms used to designate concepts are frequently just
noun phrases and are significantly shorter than a
usual sentence. In the case of the relations between
concepts (dubbed object properties) and attributes
of concepts (data type properties), these are occa-
sionally labelled by means of verbal phrases. We
demonstrate this by looking at three widely used on-
tologies/taxonomies.
1. Friend of a friend: The Friend of a Friend
(FOAF) ontology is used to describe social
networks on the Semantic Web (Brickley and
Miller, 2010). It is a small taxonomy with very
short labels. Labels for concepts are compound
words made up of up to three words.
2. Gene Ontology: The Gene Ontology (Ash-
burner et al, 2000) is a very large database of
terminology related to genetics. We note that
while some of the terms are technical and do
not require translation, e.g., ESCRT-I, the ma-
jority do, e.g., cytokinesis by cell plate forma-
tion.
3. IFRS 2009: The IFRS taxonomy (International
Accounting Standards Board, 2007) is used for
providing electronic financial reports for audit-
ing. The terms contained within this taxon-
omy are frequently long and are entirely noun
phrases.
We applied tokenization and manual phrase anal-
ysis to the labels in these resources and the results
are summarized in table 1. As can be observed,
the variety of types of labels we may come across
when linguistically analysing and translating ontol-
ogy and taxonomy labels is quite large. We can
identify the two following properties that may influ-
ence the translation process of taxonomy and ontol-
ogy labels. Firstly, the length of terms ranges from
single words to highly complex compound phrases,
but is still generally shorter than a sentence. Sec-
ondly, terms are frequently about highly specialized
domains of knowledge.
For properties in the ontology we also identify
terms which consist of:
? Noun phrases identifying concepts.
? Verbal phrases that are only made up of the
verb with an optional preposition.
? Complex verbal phrases that include the predi-
cate.
? Noun phrases that indicate possession of a par-
ticular characteristic (e.g., interest meaning X
has an interest in Y).
3 Creation of a corpus for taxonomy and
ontology translation
For the purpose of training systems to work on the
translation of ontologies and taxonomies, it is nec-
essary to create a corpus that has similar linguistic
structure to that found in ontologies and taxonomies.
We used the titles of Wikipedia1 for the following
1http://www.wikipedia.org
117
Size Mean tokens per label Noun Phrases Verb Phrases
FOAF 79 1.57 94.9% 8.9%
Gene Ontology 33795 4.45 100.0% 0.0%
IFRS 2009 2757 8.39 100.0% 0.0%
Table 1: Lexical Analysis of labels
Link Direct Fragment Broken
German 487372 484314 1735 1323
Spanish 347953 346941 330 682
Table 2: Number of translation for pages in Wikipedia
reasons:
? Links to articles in different languages can be
viewed as translations of the page titles.
? The titles of articles have similar properties to
the ontologies labels mentioned above with an
average of 2.46 tokens.
? There are a very large number of labels. In fact
we found that there were 5,941,8902 articles of
which 3,515,640 were content pages (i.e., not
special pages such as category pages)
We included non-content pages (in particular, cat-
egory pages) in the corpus as they were generally
useful for translation, especially the titles of cat-
egory pages. In table 2 we see the number of
translations, which we further grouped according to
whether they actually corresponded to pages in the
other languages, as it is also possible that the trans-
lations links pointed to subsections of an article or
to missing pages.
Wikipedia also includes redirect links that allow
for alternative titles to be mapped to a given con-
cept. These can be useful as they contain synonyms,
but also introduce a lot more noise into the corpus
as they also include misspelled and foreign terms.
To evaluate the effectiveness of including these data
for creating a machine translation corpus, we took
a random sample of 100 pages which at least one
page redirects to (there are 1,244,647 of these pages
in total). We found that these pages had a total
of 242 extra titles from the redirect page of which
2All statistics are based on the dump on 17th March 2011
204 (84.3%) where true synonyms, 19 (7.9%) were
misspellings, 8 (3.3%) were foreign names for con-
cepts (e.g., the French name for ?Zeebrugge?), and
11 (4.5%) were unrelated. As such, we conclude
that these extra titles were useful for constructing the
corpus, increasing the size of the corpus by approx-
imately 50% across all languages. There are sev-
eral advantages to deriving a corpus fromWikipedia,
for example it is possible to provide some hierarchi-
cal links by the use of the category that a page be-
longs to, such as has been performed by the DBpedia
project (Auer et al, 2007).
4 Evaluation metrics for taxonomy and
ontology translation
Given the linguistic differences in taxonomy and
ontology labels, it seems necessary to investigate
the effectiveness of various metrics for the evalua-
tion of translation quality. There are a number of
metrics that are widely used for evaluating trans-
lation. Here we will focus on some of the most
widely used, namely BLEU (Papineni et al, 2002),
NIST (Doddington, 2002), METEOR (Banerjee and
Lavie, 2005) and WER (McCowan et al, 2004).
However, it is not clear which of these methods cor-
relate best with human evaluation, particularly for
the ontologies with short labels. To evaluate this
we collected a mixture of ontologies with short la-
bels on the topics of human diseases, agriculture,
geometry and project management, producing 437
labels. These were translated with web transla-
tion services from English to Spanish, in particu-
lar Google Translate3, Yahoo! BabelFish4 and SDL
FreeTranslation5. Having obtained translations for
each label in the ontology we calculated the evalua-
tion scores using the four metrics mentioned above.
We found that the source ontologies had an average
3http://translate.google.com
4http://babelfish.yahoo.com
5http://www.freetranslation.com
118
BLEU NIST METEOR WER
Evaluator 1,
Fluency 0.108 0.036 0.134 0.122
Evaluator 1,
Adequacy 0.209 0.214 0.303 0.169
Evaluator 2,
Fluency 0.183 0.062 0.266 0.164
Evaluator 2,
Adequacy 0.177 0.111 0.251 0.194
Evaluator 3,
Fluency 0.151 0.067 0.210 0.204
Evaluator 3,
Adequacy 0.143 0.129 0.221 0.120
Table 3: Correlation between manual evaluation results
and automatic evaluation scores
label length of 2.45 tokens and the translations gen-
erated had an average length of 2.16 tokens. We then
created a data set by mixing the translations from the
web translation services with a number of transla-
tions from the source ontologies, to act as a control.
We then gave these translations to 3 evaluators, who
scored them for adequacy and fluency as described
in Koehn (2010). Finally, we calculated the Pearson
correlation coefficient between the automatic scores
and the manual scores obtained. These are presented
in table 3 and figure 1.
As we can see from these results, one metric,
namely METEOR, seems to perform best in evaluat-
ing the quality of the translations. In fact this is not
surprising as there is a clear mathematical deficiency
that both NIST and BLEU have for evaluating trans-
lations for very short labels like the ones we have
here. To illustrate this, we recall the formulation of
BLEU as given in (Papineni et al, 2002):
BLEU = BP ? exp(
N
?
n=1
wn log pn)
WhereBP is a brevity penalty, wn a weight value
and pn represents the n-gram precision, indicating
how many times a particular n-gram in the source
text is found among the target translations. We note,
however, that for very short labels it is highly likely
that pn will be zero. This creates a significant issue,
as from the equation above, if any of the values of pn
are zero, the overall score, BLEU, will also be zero.
Figure 1: Correlation between manual evaluation results
and automatic evaluation scores
For the results above we chose N = 2, and cor-
rected for single-word labels. However, the scores
were still significantly worse, similar problems af-
fect the NIST metric. As such, for the taxonomy
and ontology translation task we do not recommend
using BLEU or NIST as an evaluation metric. We
note that METEOR is a more sophisticated method
than WER and, as expected, performs better.
5 Approaches for taxonomy and ontology
translation
5.1 Domain adaptation
It is generally the case that many ontologies and tax-
onomies focus on only a very specific domain, thus
it seems likely that adaptation of translation systems
by use of an in-domain corpus may improve trans-
lation quality. This is particularly valid in the case
of ontologies which frequently contain ?subject? an-
notations6 for not only the whole data structure but
often individual elements. To demonstrate this we
tried to translate the IFRS 2009 taxonomy using
the Moses Decoder (Koehn et al, 2007), which we
trained on the EuroParl corpus (Koehn, 2005), trans-
lating from Spanish to English. As the IFRS taxon-
omy is on the topic of finance and accounting, we
6For example from the Dublin Core vocabulary: see http:
//dublincore.org/
119
Baseline With domain adaptation
WER? 0.135 0.138
METEOR 0.324 0.335
NIST 1.229 1.278
BLEU 0.090 0.116
Table 4: Results of domain-adapted translation. ?Lower
WER scores are better
chose all terms from our Wikipedia corpus which
belonged to categories containing the words: ?fi-
nance?, ?financial?, ?accounting?, ?accountancy?,
?bank?, ?banking?, ?economy?, ?economic?, ?in-
vestment?, ?insurance?and ?actuarial? and as such
we had a domain corpus of approximately 5000
terms. We then proceeded to recompute the phrase
table using the methodology as described in Wu et
al, (2008), computing the probabilities as follows for
some weighting factor 0 < ? < 1:
p(e|f) = ?p1(e|f) + (1? ?)pd(e|f)
Where p1 is the EuroParl trained probability and pd
the scores on our domain subset. The evaluation for
these metrics is given in table 4. As can be seen
with the exception of the WER metric, the domain
adaption does seem to help in translation, which cor-
roborates the results obtained by other authors.
5.2 Syntactic Analysis
One key question to figure out is: if we have a se-
mantic model can this be used to predict the syntac-
tic structure of the translation to a significant degree?
As an example of this we consider the taxonomic
term ?statement?, which is translated by Google
Translate7 to German as ?Erkla?rung?, whereas the
term ?annual statement? is translated as ?Jahresab-
schluss?. However, if the taxonomy contains a sub-
sumption (hypernymy) relationship between these
terms we can deduce that the translation ?Erkla?rung?
is not correct and the translation ?Abschluss? should
be preferred. We chose to evaluate this idea on the
IFRS taxonomy as the labels it contains are much
longer and more structured than some of the other
resources. Furthermore, in this taxonomy the origi-
nal English labels have been translated into ten lan-
guages, so that it is already a multilingual resource
7Translations results obtained 8th March 2011
P (syn|s) P (syn|p) P (syn|n)
English 0.147 0.012 0.001
Dutch 0.137 0.011 0.001
German 0.125 0.007 0.001
Spanish 0.126 0.012 0.001
Table 5: Probability of syntactic relationship given a se-
mantic relationship in IFRS labels
that can be used as gold standard. Regarding the
syntax of labels, it is often the case that one term is
derived from another by addition of a complemen-
tary phrase. For example the following terms all ex-
ist in the taxonomy:
1. Minimum finance lease payments receivable
2. Minimum finance lease payments receivable, at
present value
3. Minimum finance lease payments receivable, at
present value, end of period not later than one
year
4. Minimum finance lease payments receivable, at
present value, end of period later than one year
and not later than five years
A high-quality translation of these terms would
ideally preserve this same syntactic structure in the
target language.We attempt to answer how useful
ontological structure is by trying to deduce if there
is a semantic relationship between terms then is it
more likely that there is a syntactic relationship. We
started by simplifying the idea of syntactic depen-
dency to the following: we say that two terms are
syntactically related if one label is a sub-string of
another, so that in the example above the first label
is syntactically related to the other three and the sec-
ond is related to the last two. For English, we found
that there were 3744 syntactically related terms ac-
cording to this criteria, corresponding to 0.1% of all
label pairs within the taxonomy, for all languages.
For ontology structure we used the number of rela-
tions indicated in the taxonomy, of which there are
1070 indicating a subsumption relationship and 987
indicating a partitive relationship8. This means that
8IFRS includes links for calculating certain values, i.e., that
?Total Assets? is a sum of values such as ?Total Assets in Prop-
120
e ? f P (synf |syne, s) P (synf |syne, p) P (synf |syne, n)
English ? Spanish 0.813 ? 0.059 0.750 ? 0.205 0.835 ? 0.013
English ? German 0.835 ? 0.062 0.417 ? 0.212 0.790 ? 0.013
English ? Dutch 0.875 ? 0.063 0.833 ? 0.226 0.898 ? 0.013
Average 0.841 ? 0.035 0.665 ? 0.101 0.841 ? 0.008
Table 6: Probability of cross-lingual preservation of syntax given semantic relationship in IFRS. Note here s refers to
the source language and t to the target language. Error values are 95% of standard deviation.
0.08% of label pairs were semantically related. We
then examined if the semantic relation could predict
whether there was a syntactic relationship between
the terms in a single language. We define Ns as the
number of label pairs with a subsumption relation-
ship and similarly define Np, Nn and Nsyn for parti-
tive, semantically unrelated and syntactically related
pairs. We also define Ns?syn, Np?syn and Nn?syn
for label pairs with both subsumption, partitive or no
semantic relation and a syntactic relationships. As
such we define the following values
P (syn|s) = Ns?syn
Ns
Similarly we define P (syn|p) and P (syn|n) and
present these values in table 5 for four languages.
As we can see from these results, it seems that
both subsumption and partitive relationships are
strongly indicative of syntactic relationships as we
might expect. The second question is: is it more
likely that we see a syntactic dependency in trans-
lation if we have a semantic relationship, i.e., is the
syntax more likely to be preserved if these terms are
semantically related. We define Nsyne as the value
of Nsyn for a language e, e.g., Nsynen is the num-
ber of syntactically related English label pairs in the
taxonomy. As each label has exactly one transla-
tion we can also define Nsyne?synf?s as the number
of concepts whose labels are syntactically related in
both language e and f and are semantically related
by a subsumption relationship; similarly we define
Nsyne?synf?p and Nsyne?synf?n. Hence we can de-
fine
P (synf |syne, s) =
Nsynf?syne?s
Nsyne?s
erty, Plant and Equipment?, we view such a relationship as se-
mantically indicative that one term is part of another, i.e., as
partitive or meronymic
And similarly define P (synf |syne, p) and
P (synf |syne, n). We calculated these values on
the IFRS taxonomies, the results of which are
represented in table 6.
The partitive data was very sparse, due to the fact
that only 15 concepts in the source taxonomy had a
partitive relationship and were syntactically related,
so we cannot draw any strong conclusions from it.
For the subsumption relationship we have a clearer
result and in fact averaged across all language pairs
we found that the likelihood of the syntax being pre-
served in the translation was nearly exactly the same
for semantically related and semantically unrelated
concepts. From this result we can conclude that
the probability of syntax given either subsumptive or
partitive relationship is not very large, at least from
the reduced syntactic model we used here. While
our model reduces syntax to n-gram overlap, we
believe that if there was a stronger correlation us-
ing a more sophisticated syntactic model, we would
still see some noticable effect here as we did mono-
lingually. We also note that we applied this to only
one taxonomy and it is possible that the result may
be different in a different resource. Furthermore,
we note there is a strong relationship between se-
mantics and syntax in a mono-lingual context and
as such adaption of a language model to incorporate
this bias may improve the translation of ontologies
and taxonomies.
5.3 Comparison of ontology structure
Our third intuition in approaching ontology trans-
lation is that the comparison of ontology or taxon-
omy structures containing source and target labels
may help in the disambiguation process of transla-
tion candidates. A prerequisite in this sense is the
availability of equivalent (or similar) ontology struc-
tures to be compared.
121
Figure 2: Two approaches to translate ontology labels.
From a technical point of view, we consider the
translation task as a word sense disambiguation task.
We identify two methods for comparing ontology
structures, which are illustrated in Figure 2.
The first method relies on a multilingual resource,
i.e., a multilingual ontology or taxonomy. The on-
tology represented on the left-hand side of the fig-
ure consists of several monolingual conceptualiza-
tions related to each other by means of an inter-
lingual index, as is the case in the EuroWordNet lex-
icon (Vossen, 1999). For example, if the original
label is chair for seat in English, several translations
for it are obtained in Spanish such as: silla (for seat),
ca?tedra (for university position), presidente (for per-
son leading a meeting). Each of these correspond
to a sense in the English WordNet, and hence each
translation selects a hierachical structure with En-
glish labels. The next step is to compare the input
structure of the original ontology containing chair
against the three different structures in English rep-
resenting the several senses of chair and obtain the
corresponding label in Spanish.
The second method relies on a monolingual re-
source, i.e., on monolingual ontologies in the tar-
get language, which means that we need to compare
structures documented with labels in different lan-
guages. As such we obtain a separate translated on-
tologies for each combination of label translations
suggested by the baseline system. Selecting the cor-
rect translations is then clearly a hard optimization
problem.
For the time being, we have only experimented
with the first approach using EuroWordNet. Sev-
eral solutions have been proposed in the context of
ontology matching in a monolingual scenario (see
(Shvaiko and Euzenat, 2005) or (Giunchiglia et al,
2006)). The ranking method we use to compare
structures relies on an equivalence probability mea-
sure between two candidate structures, as proposed
in (Trillo et al, 2007).
We assume that we have a taxonomy or ontology
entity o1 and we wish to deduce if it is similar to
another taxonomy or ontology entity o2 from a ref-
erence taxonomy or ontology (i.e., EuroWordNet) in
the same language. We shall make a simplifying as-
sumption that each ontology entity is associated with
a unique label, e.g., lo1 . As such we wish to deduce
if o1 represents the same concept as o2 and hence if
lo2 is a translation for lo1 . Our model relies on the
Vector Space Model (Raghavan and Wong, 1986)
to calculate the similarity between different labels,
which essentially involves calculating a vector from
the bag of words contained within each labels and
then calculating the cosine similarity between these
vectors. We shall denotes this as v(o1, o2). We then
use four main features in the calculation of the sim-
ilarity
? The VSM-similarity between the labels of enti-
ties, o1, o2.
? The VSM-similarity between any glosses (de-
scriptions) that may exist in the source or refer-
ence taxonomy/ontology.
? The hypernym similarity given to a fixed depth
d, given that set of hypernyms of an entity oi is
given as a set
hO(oi) = {h|(oi, h) ? H}
Then we calculate the similarity for d > 1 re-
cursively as
122
sh(o1, o2, d) =
?
h1?hO(o1),h2?hO(o2) ?(h1, h2, d)
|hO(o1)||hO(o2)|
?(h1, h2, d) = ?v(h1, h2)+(1??)sh(h1, h2, d?1)
And for d = 1 it is given as
sh(o1, o2, 1) =
?
h1?hO(o1),h2?hO(o2) v(h1, h2)
|hO(o1)||hO(o2)|
? The hyponym similarity, calculated as the hy-
pernym similarity but using the hyponym set
given by
HO(oi) = {h|(h, oi) ? H}
We then incorporate these factors into a vector x
and calculate the similarity of two entities as
s(o1, o2) = wTx
Where w is a weight vector of non-negative reals
and satisfies ||w|| = 1, which we set manually.
We then applied this to the FOAF ontol-
ogy (Brickley and Miller, 2010), which was manu-
ally translated to give us a reference translation. Af-
ter that, we collected a set of candidate translations
obtained by using the web translation resources ref-
erenced in section 3, along with additional candi-
dates found in our multilingual resource. Finally,
we used EuroWordNet (Vossen, 1999) as the refer-
ence taxonomy and ranked the translations accord-
ing to the score given by the metric above. In table
7, we present the results where our system selected
the candidate translation with the highest similarity
to our source ontology entity. In the case that we
could not find a reference translation we split the la-
bel into tokens and found the translation by select-
ing the best token. We compared these results to a
baseline method that selected one of the reference
translations at random.
These results are in all cases significantly stronger
than the baseline results showing that by compar-
ing the structure of ontology elements it is possible
to significantly improve the quality of translation.
These results are encouraging and we believe that
more research is needed in this sense. In particular,
we would like to investigate the benefits of perform-
ing a cross-lingual ontology alignment in which we
measure the semantic similarity of terms in different
languages.
Baseline Best Translation
WER? 0.725 0.617
METEOR 0.089 0.157
NIST 0.070 0.139
BLEU 0.103 0.187
Table 7: Results of selecting translation by structural
comparison. ?Lower WER scores are better
6 Conclusion
In this paper we presented the problem of ontology
and taxonomy translation as a special case of ma-
chine translation that has certain extra characteris-
tics. Our examination of the problem showed that
the main two differences are the presence of struc-
tured semantics and shorter, hence more ambiguous,
labels. We demonstrated that as a result of this lin-
guistic nature, some machine translation metrics do
not perform as well as they do in free-text trans-
lations. We then presented the results of early in-
vestigations into how we may use the special fea-
tures of taxonomy and ontology translation to im-
prove quality of translation. The first of these was
domain adaptation, which in line with other authors
is useful for texts in a particular domain. We also in-
vestigated the possibility of using the link between
syntactic similarity and semantic similarity to help,
however although we find that mono-lingually there
was a strong correspondence between syntax and se-
mantics, this result did not seem to extend well to a
cross-lingual setting. As such we believe there may
only be slight benefits of using techniques, however
further investigation is needed. Finally, we looked at
using word sense disambiguation by comparing the
structure of the input ontology to that of an already
translated reference ontology. We found this method
to be very effective in choosing the best translations.
However it is dependent on the existence of a mul-
tilingual resource that already has such terms. As
such, we view the topic of taxonomy and ontology
translation as an interesting sub-problem of machine
translation and believe there is still much fruitful
work to be done to obtain a system that can cor-
rectly leverage the semantics present in these data
structures in a way that improves translation quality.
123
References
Marianna Apidianaki. 2009. Data-driven semantic anal-
ysis for multilingual WSD and lexical selection in
translation. In Proceedings of the 12th Conference of
the European Chapter of the Association for Compu-
tational Linguistics (EACL).
Michael Ashburner, Catherine Ball, Judith Blake, David
Botstein, Heather Butler, J. Michael Cherry, Allan
Davis, et al 2000. Gene ontology: tool for the uni-
fication of biology. The Gene Ontology Consortium.
Nature genetics, 25(1):25?29.
So?ren Auer, Christian Bizer, Georgi Kobilarov, Jens
Lehmann, Richard Cyganiak, and Zachary Ives. 2007.
Dbpedia: A nucleus for a web of open data. The Se-
mantic Web, 4825:722?735.
Satanjeev Banerjee and Alon Lavie. 2005. METEOR:
An automatic metric for MT evaluation with improved
correlation with human judgments. Intrinsic and Ex-
trinsic Evaluation Measures for Machine Translation
and/or Summarization, page 65.
Kalina Bontcheva. 2005. Generating tailored textual
summaries from ontologies. In The Semantic Web:
Research and Applications, pages 531?545. Springer.
Dan Brickley and Libby Miller, 2010. FOAF Vocabulary
Specification 0.98. Accessed 3 December 2010.
Marine Carpuat and Dekai Wu. 2007. Improving Sta-
tistical Machine Translation using Word Sense Disam-
biguation. In Proceedings of the 2007 Joint Confer-
ence on Empirical Methods in Natural Language Pro-
cessing and Computational Natural Language Learn-
ing (EMNLP-CoNLL 2007).
Philipp Cimiano, Elena Montiel-Ponsoda, Paul Buite-
laar, Mauricio Espinoza, and Asuncio?n Go?mez-Pe?rez.
2010. A note on ontology localization. Journal of Ap-
plied Ontology (JAO), 5:127?137.
Nigel Collier, Son Doan, Ai Kawazoe, Reiko Matsuda
Goodwin, Mike Conway, Yoshio Tateno, Quoc-Hung
Ngo, Dinh Dien, Asanee Kawtrakul, Koichi Takeuchi,
Mika Shigematsu, and Kiyosu Taniguchi. 2008. Bio-
Caster: detecting public health rumors with a Web-
based text mining system. Oxford Bioinformatics,
24(24):2940?2941.
Thierry Declerck, Hans-Ullrich Krieger, Susan Marie
Thomas, Paul Buitelaar, Sean O?Riain, Tobias Wun-
ner, Gilles Maguet, John McCrae, Dennis Spohr, and
Elena Montiel-Ponsoda. 2010. Ontology-based Mul-
tilingual Access to Financial Reports for Sharing Busi-
ness Knowledge across Europe. In Jo?zsef Roo?z and
Ja?nos Ivanyos, editors, Internal Financial Control As-
sessment Applying Multilingual Ontology Framework,
pages 67?76. HVG Press Kft.
George Doddington. 2002. Automatic evaluation of ma-
chine translation quality using n-gram co-occurrence
statistics. In Proceedings of the second interna-
tional conference on Human Language Technology
Research, pages 138?145. Morgan Kaufmann Publish-
ers Inc.
Mauricio Espinoza, Asuncio?n Go?mez-Pe?rez, and Ed-
uardo Mena. 2008. Enriching an Ontology with
Multilingual Information. In Proceedings of the 5th
Annual of the European Semantic Web Conference
(ESWC08), pages 333?347.
Mauricio Espinoza, Elena Montiel-Ponsoda, and
Asuncio?n Go?mez-Pe?rez. 2009. Ontology Local-
ization. In Proceedings of the 5th International
Conference on Knowledge Capture (KCAP09), pages
33?40.
Bo Fu, Rob Brennan, and Declan O?Sullivan. 2010.
Cross-Lingual Ontology Mapping and Its Use on the
Multilingual Semantic Web. In Proceedings of the
1st Workshop on the Multilingual Semantic Web, at
the 19th International World Wide Web Conference
(WWW 2010).
Fausto Giunchiglia, Pavel Shvaiko, and Mikalai Yatske-
vich. 2006. Discovering missing background knowl-
edge in ontology matching. In Proceeding of the 17th
European Conference on Artificial Intelligence, pages
382?386.
International Accounting Standards Board, 2007. Inter-
national Financial Reporting Standards 2007 (includ-
ing International Accounting Standards (IAS) and In-
terpretations as at 1 January 2007).
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, et al 2007. Moses: Open source toolkit for sta-
tistical machine translation. In Proceedings of the 45th
Annual Meeting of the ACL on Interactive Poster and
Demonstration Sessions, pages 177?180.
Philipp Koehn. 2005. Europarl: A parallel corpus for
statistical machine translation. In Proceedings of the
Tenth Machine Translation Summit.
Philipp Koehn. 2010. Statistical Machine Translation.
Cambridge University Press.
Iain McCowan, Darren Moore, John Dines, Daniel
Gatica-Perez, Mike Flynn, Pierre Wellner, and Herve?
Bourlard. 2004. On the use of information retrieval
measures for speech recognition evaluation. Technical
report, IDIAP.
John McCrae, Jesu?s Campana, and Philipp Cimiano.
2010. CLOVA: An Architecture for Cross-Language
Semantic Data Querying. In Proceedings of the First
Mutlilingual Semantic Web Workshop.
William Mischo. 1982. Library of Congress Subject
Headings. Cataloging & Classification Quarterly,
1(2):105?124.
124
Hans-Michael Mu?ller, Eimear E Kenny, and Paul W
Sternberg. 2004. Textpresso: An ontology-based in-
formation retrieval and extraction system for biologi-
cal literature. PLoS Biol, 2(11):e309.
Roberto Navigli and Simone Paolo Ponzetto. 2010. Ba-
belnet: Building a very large multilingual semantic
network. In Proceedings of the 48th Annual Meet-
ing of the Association for Computational Linguistics,
pages 216?225.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic eval-
uation of machine translation. In Proceedings of the
40th annual meeting on association for computational
linguistics, pages 311?318. Association for Computa-
tional Linguistics.
V.Vijay Raghavan and S.K.M. Wong. 1986. A criti-
cal analysis of vector space model for information re-
trieval. Journal of the American Society for Informa-
tion Science, 37(5):279?287.
Pavel Shvaiko and Jerome Euzenat. 2005. A survey of
schema-based matching approaches. Journal on Data
Semantics IV, pages 146?171.
Fabian Suchanek, Gjergji Kasneci, and Gerhard Weikum.
2007. Yago: a core of semantic knowledge. In Pro-
ceedings of the 16th international conference on World
Wide Web, pages 697?706.
Raquel Trillo, Jorge Gracia, Mauricio Espinoza, and Ed-
uardo Mena. 2007. Discovering the semantics of user
keywords. Journal of Universal Computer Science,
13(12):1908?1935.
Piek Vossen. 1999. EuroWordNet a multilingual
database with lexical semantic networks. Computa-
tional Linguistics, 25(4).
Hua Wu, Haifeng Wang, and Chengqing Zong. 2008.
Domain adaptation for statistical machine translation
with domain dictionary and monolingual corpora. In
Proceedings of the 22nd International Conference
on Computational Linguistics-Volume 1, pages 993?
1000. Association for Computational Linguistics.
125
Zock/Rapp/Huang (eds.): Proceedings of the 4th Workshop on Cognitive Aspects of the Lexicon, pages 138?143,
Dublin, Ireland, August 23, 2014.
Default Physical Measurements in SUMO
Francesca Quattri
The Hong Kong Polytechnic University
Hong Kong
francesca.quattri@connect.polyu.hk
Adam Pease
?
adam.pease@articulatesoftware.com
John P. M
c
Crae
Universit?at Bielefeld
Germany
jmccrae@cit-ec.uni-bielefeld.de
Abstract
The following paper presents a further extension of the Suggested Upper Merged Ontology
(SUMO), i. e. the development of default physical measurements for most of its classes
(Artifacts, Devices, Objects) and respective children. The extension represents an ar-
bitrary, computable and reproducible approximation of defaults for upper and middle-level con-
cepts. The paper illustrates advantages of such extension, challenges encountered during the
compilation, related work and future research.
1 Introduction
Over the last fourteen years SUMO (Pease, 2011; Niles and Pease, 2001) has been developed into a large,
general-domain ontology, which currently
1
includes 20,000 terms and 80,000 axioms stated in higher-
order logic (Pease and Schulz, 2014). SUMO provides an open source environment for the development
of logical theories called SIGMA (Pease, 2011; Pease, 2003b). This enables the manipulation of different
formal languages (including TPTP and OWL), (Adam Pease and Sams, 2003; Pease, 2003a). Among
them, the logical formal language SUO-KIF has been selected for the development of knowledge-based
(or KB) terms, through which SUMO can be searched. Another possible search of terms in SUMO is via
the Princeton WordNet ?, to which the ontology has been fully mapped(Pease and Niles, 2003; Pease
and Li, 2003; Pease and Murray, 2003).
In the first part of this paper, after introducing SUMO in generic terms, we explain the motivation
behind the undergone extension of 300+ physical default measurements (the term ?default? is hereby used
as synonym for ?approximation? or ?estimation?). The second part deals with the advantages and issues
encountered during the compilation of the defaults, and presents some practical examples of defaults and
higher-order annotation. Related research and future work follow.
2 Default physical measurements in SUMO
The original intent behind the development of default physical measurements in SUMO is to provide
factual peer-reviewed information about physical measurements of ontological classes. Almost all ap-
proximations of the default values have been established with reference to current ISO standards or norms
set by governmental regulations. Only in the case that standard values are not provided or could not be
retrieved, the compiler of the defaults has relied on personal judgment. In both cases, all defaults have
been manually double-checked for validity by the compiler and the SUMO developer.
SUMO seems to be one of the first general-knowledge ontologies to provide extensive information on
physical default measurements. Other data bases like DBpedia have (according to the authors? knowl-
edge) just recently started to provide a similar kind of information.
2
The physical defaults represent a big
repository of approximated values based on physical properties, such as length, volume, size, width and
?
Same affiliation of the first author.
This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer
are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/
1
As for the year 2014.
2
http://dbpedia.org/property/reference
138
height. The approximation, as the term itself says, is partly arbitrary, computable, and comprehensively
conducted. The measurements are formalized in minimum and maximum default values. The wording
?maximum? and ?minimum? should not been treated as the highest and lowest values attached to the
respective Artifacts, but as some high or low values these Entitys can own.
2.1 Advantages
We believe that the compilation of the defaults accomplishes three major advantages in the current format
of the SUMO ontology:
1. Ontological formalization.
2. Objective adjustable values of physical properties.
3. Computable reproducible estimations of physical values.
Point (1) mirrors SUMO attempt as extensive ontology of general knowledge. Natural language fails
in providing specificity for every single word and predicate, partly due to polysemy, synonymy as well as
objective limitations of extensive precise formal description. We often refer to a term in vague sense and
meaning, such as in the case of ?car? or ?truck?. For further specification of the same, we tend to create
new lemmas, derivatives and compounds. SUMO underscores a lemma in its definitional and ontolog-
ical extent and the defaults consider the lemma as prototypical. As for its definitional extent, SUMO
provides the definition of the lemma as reported in the Princeton WordNet ?. As ontological and proto-
typical entity, the lemma is described in first-order and/or higher-order logic and thus transformed into a
SUO-KIF KB term. In the case of Truck, the term is enlisted under TransportationDevice
in SUMO. The following description in first-order logic (containing the quantifier ?exists?) specifi-
cally states: ?If a TransportationDevice is an instance of a Truck, then there exists a kind
of Object such that a kind of Object is a subclass of Object and kind of Object is a Cargo type
of TransportationDevice.
(=>
(instance ?T Truck)
(exists (?L)
(and
(subclass ?L Object)
(cargoType ?T ?L))))
Figure 1.: Example of a first-order axiom in SUO-KIF
Entity 2
Physical 5
Object 11
Artifact 58
Device 112
TransportationDevice 9
Vehicle 12
LandVehicle 10
RoadVehicle 6
PoweredVehicle 12
SelfPoweredRoadVehicle 4
CargoVehicle 1
Truck 3
MilitarySupplyTruck
LightTruck
TruckTractor 1
PeterbiltTruck
Figure 2.: Graphic documentation of the relation subclass for the term Truck with relative enumerated
direct-children
Fig. 2 represents a graphic documentation of the same term as taxonomically listed (with the selected
levels ?above? and ?below? Truck set to the value 10). The graph can be further extended to more levels,
thus enabling a comprehensive look of all the branches that depart from the upper concept Entity. As
for fig. 2., SUMO provides a specific taxonomy of the different kinds of Truck.
139
The default measurements in fig. 3 have been partly set by looking at standard measures for the same
Artifact
3
:
;; Truck
(defaultMinimumLength Truck (MeasureFn 39 Foot))
(defaultMaximumLength Truck (MeasureFn Fn 49 Foot))
(defaultMinimumHeight Truck (MeasureFn 13 Foot))
(defaultMaximumHeight Truck (MeasureFn 15 Foot))
(defaultMinimumWidth Truck (MeasureFn 8.4 Foot))
(defaultMaximumWidth Truck (MeasureFn 9 Foot))
;;Vehicle
(defaultMinimumLength Vehicle (MeasureFn 13.5 Foot))
(defaultMaximumLength Vehicle (MeasureFn 14 Foot))
(defaultMinimumHeight Vehicle (MeasureFn 4.6 Foot))
(defaultMaximumHeight Vehicle (MeasureFn 4.8 Foot))
(defaultMinimumWeight Vehicle (MeasureFn 1 TonMass))
(defaultMaximumWeight Vehicle (MeasureFn 1.7 TonMass))
Figure 3.: Extensions of physical defaults for Truck and Vehicle
In fig. 4 the physical default values for CreditCard have been established according to the interna-
tional standard ISO/IEC 7810:2003.
;;CreditCard
(defaultMinimumLength CreditCard (MeasureFn 3.4 Inch))
(defaultMaximumLength CreditCard (MeasureFn 3.4 Inch))
(defaultMinimumHeight CreditCard (MeasureFn 2.1 Inch))
(defaultMaximumHeight CreditCard (MeasureFn 2.1 Inch))
Figure 4.: Extensions of physical defaults for CreditCard
The (2) advantage in having physical default measurements is the objectivity of the properties they
are calculated upon. The defaults are set on objectively comparable properties, such as height, volume,
weight, length and width. These are all features of size and mass that can be counted and approximated,
with different units of measures.
Finally, the (3) advantage that we reckon exists in having the defaults is their computability. De-
spite being relative and partially arbitrary measures
4
, the defaults are adjustable and reproducible, which
makes them adaptable to representation models, peer-review and further estimations. We believe that this
way of calculating defaults of physical Objects is certainly more reliable than other attempted methods
(e. g. (Bennett, 2001):117-118).
5
2.2 Issues encountered during the research
Some challenges were encountered during the compilation of default measurements.
? The defaults cover classes of upper concepts in SUMO, and part of their children, but not the
predicates that can possibly collocate with them. For example, concepts like Aircraft or
Helicopter are covered in SUMO, but not expressions like ?light aircraft? or ?civilian helicopter?.
Sometimes, SUMO already provides a logical description of these adjectives as incorporated in
the concept itself, as in the case of MilitaryAircraft, SelfPoweredRoadVehicle, or
PrintedBook (fig. 4), meaning that rather then specifying the predicate, a new term is created.
SUMO users should bare in mind that the Artifacts in SUMO always aim at representing a
3
As in the case of Truck the defaults have been established by looking at the standard sizes as set by the U.S. Department of
Transportation and Federal Highway Administration, http://www.ops.fhwa.dot.gov/freight/sw/index.htm
4
As previously discussed in the paper, the defaults have been assigned on a subjective basis in case standard defaults could
not been retrieved/are not available. Also, the defaults sometimes apply to one country?s regulations, and are therefore not
internationally valid. Finally, the defaults have been given with selected units of measures (e. g. inches instead of centimeters,
or pounds instead of kilograms. This specified, one should bear in mind the intention of the default extensions, namely to
provide an approximation of prototypical, not universal Artifacts.
5
Bennett, in his study on physical objects and geographic concepts, tries to delimit the boundaries of vague entities by providing
answers to size-related questions (e. g. ?How large an area must a forest occupy? Are there any constraints in its shape? Must
it be maximal or could it share a border with another region of forest??). In SUMO, we believe that the defaults, through which
some of these questions can be answered, are more reliable, since anchored to standard values.
140
prototypical form of the same Object, i. e. a kind that is possibly shared in the collective think-
ing. The representation for Book as showed below aims therefore at representing the possibly most
commonly form of Book known, namely a printed and not an electronic version of the same.
(=>
(instance ?BOOK PrintedBook)
(exists (?SHEET1 ?SHEET2)
(and
(component ?SHEET1 ?BOOK)
(component ?SHEET2 ?BOOK)
(instance ?SHEET1 PrintedSheet)
(instance ?SHEET2 PrintedSheet)
(not
(equal ?SHEET1 ?SHEET2)))))
(=>
(and
(instance ?ARTICLE1 Article)
(instance ?BOOK Book)
(subsumesContentInstance ?BOOK ?
ARTICLE1))
(exists (?ARTICLE2)
(and
(instance ?ARTICLE2 Article)
(not
(equal ?ARTICLE2 ?ARTICLE1))
(subsumesContentInstance ?
BOOK ?ARTICLE2))))
Figure 5.: Comparison between the logical annotation for Book in SUMO with the collocational
unit printed + Book
It needs to be specified that the concept of Attribute in SUMO is differently interpreted from the
concept of predicate or adjective in natural language. Attributes in the Upper Merged Ontology are
instances of upper classes, but there also exists classes of Attributes. The Attribute class can
contain subclasses (e. g. Female, Male, BiologicalAttribute), but these have not been
assigned default physical values. The motivation is basically that we cannot numerically define
abstracta, such as gender, color, or emotions and feelings. In the case of abstract concepts, such as
StockMarket or InterestRate, we have tried to figure out these, where possible, as physical
objects (e. g. the place where financial transactions take place, or the sheet where rates are printed
on).
Other sort of literally definable attributes (including comparative forms) are included in SUMO
in the form of relations, which express, inter alia, equations and inequalities (greaterThan,
smallerThan, larger, earlier, interiorPart, temporalPart, (Pease,
2011):113). Finally, what is defined in SUMO as PhysicalAttribute should
not be confused with the physical default values added to the ontology. Instances of
this class include Compliance, Conductivity, Flammable, Inductance,
MutualInductance, Resistivity, Stiffness.
Despite the lack of a comprehensive cover of linguistically definable collocational compounds in
SUMO (as above mentioned), we estimate that it is not impossible to approximate values for them,
given the existence of defaults for the concept that carries the predicate. For instance, it can be
derived that BigHouse (not enlisted in SUMO) is something that can be 1.9 times bigger than a
Studio, or 0.1 times smaller than a Mansion, once the standard values for House, Studio
and Mansion are given.
Given a partial ordering of gradable adjectives
6
that apply to a particular noun, we could create
axioms (thus inducing a productive process) which would then partition the physical space with
respect to that particular adjective. The fact that we have axioms would eventually release us from
defining defaults for each class. In other words, the most frequently an adjective collocates with a
class or a subclass, the higher is the chance to develop an axiom(s) that enables us to calculate the
defaults for these same classes automatically.
? SUMO provides ontological information regarding concepts in their a-contextual and unidiomatic
form. SUMO terms are not polysemous, therefore there is no notion of reusing a term to mean
something else. This also means that specific cases of use for a term in specific ontologies, or
as applied to metaphorical/idiomatic expressions, are not taken into account (e.?g. turning tables?;
?cleared table?). Instead, we specialize terms via subclassing and adding axioms on the subclasses
term when a new term is needed for a specific domain.
6
As interpreted by: (de Melo and Bansal, 2013; Schulam and Fellbaum, 2010; de Melo, 2014a; de Melo, 2014b).
141
? The defaults are based on arbitrary subjective approximations of prototypes. The provided informa-
tion has been carefully peer-reviewed and the defaults can be used, re-used, or changed according
to the user?s needs. The intent is in fact to provide a basic estimation of the physical values for that
concept. Furthermore, we have used specific units of measurements to carry on the approximations
(e. g. inches versus centimeters, tons and pounds versus kilos). We acknowledge that this might
hinder or slow down the reausability process.
3 Practical applications of defaults in linguistic disambiguation
Since the development of the first several hundreds physical default measurements, their applicability
and usefulness has been tested in two research studies.
7
The defaults have proven helpful in linguistic
analysis, particularly in the disambiguation of vague terms, such as vague predicates and concepts, as
well as more complex linguistic forms, such as similes and metaphors. The advantage of having physical
defaults based on standards and norms has given further validity to the disambiguation process.
3.1 Default measurements and adjectives (lemonOILS and SUMO
The use of first order logic seems to break in the case of adjectives. In a recent research, we therefore
make an in-depth analysis of different kinds of attributes and how they can be represented in different
ontology-lexicon interfaces (lemonOILS and SUMO), and discuss the implications of the modelling with
application to ontology-based question answering.
3.2 Default measurements, metaphors and similes
In another current study (see previous footnote), we use default physical measurements to disambiguate
similes frommetaphors. Starting from the claim that the taught difference between metaphors and similes
in terms of which has or does not have ?like? or ?as? in its form is not a linguistically and cognitively
satisfactory statement, we design a computable model to test the validity of novel metaphors and similes
and use the physical default measurements for our purpose.
4 Future work
The extension of physical default measurements in SUMO is not intended to be the last of its kind. In our
future work, we plan for instance a better specification of dimensionality. During the compilation of the
physical defaults, we have in fact sometimes encountered the challenge of defining first the geometrical
property proper of the concept. For instance, taking a Leaf, do we usually refer to its length, or to its
height? Google can help to a certain extent in cases like this. A better disambiguation of contextually
dependent measurements (length versus height, or width versus length) is therefore needed. A further
improvement includes the compilation of mostly all subclasses and their children in higher-order logic
as KB terms, as well as the assignment to them of physical defaults. To enable an automatic productive
process in the generation of automatic axioms (as mentioned in 2.2), both with respect to collocational
forms and with regards to the similar physical defaults that may exist between parent and child, we still
need to evaluate whether there should exist a mechanism for conflict resolution or overwrite. If we take
for instance the example of Snake, we consider at the moment that this instance of Reptile most
probably can inherit some of the properties of the parent, and viceversa. As showed in 2.1 (fig. 3) above
though, this derivation does not seem so obvious or even applicable, since there might be prototypical
properties that might appear for one concept, but not for the other, or given the too high discrepancy of
measurements.
Finally, once this comprehensive framework of properties and intuitive specification of defaults has
been created, we could conduct psycholinguistic empirical experiments to determine what are the de-
faults and prototypes and examples that different classes of human beings hold to be true. This could
give us indication on how and if prototypicality overlayers with dimensionality.
7
Submitted accepted papers for the CogALex Workshop, COLING 2014, Dublin, Ireland and the CCLCC Workshop at ESSLI
2014, Tuebingen, Germany.
142
5 Conclusion
In this paper we present a current extension of the general-domain ontology SUMO, i. e. the compilation
of default physical measurements for 300+ classes and subclasses. The aim of this extension is to provide
a peer-reviewed reliable, reusable and reproducible estimation of physical values for the ontology. The
defaults have already proven to be helpful in the disambiguation of vague predicates and concepts, as
well as similes and metaphors. As open-source application, constantly updated and improved, it is
planned to apply further changes to the SUMO ontology, which include an even more comprehensive
development of physical defaults, as well as the inclusion of other defaults for other properties. Despite
their approximation, the defaults represent a computational ground for representation models and further
calculations.
References
W.R. Murray Adam Pease and Michael Sams. 2003. Applying formal methods and representations in a natural
language tutor to teach tactical reasoning. In Proceedings of the 11
th
International Conference on Artificial
Intelligence in Education (AIED) Conference, pages 349?356. IOS Publications.
Brandon Bennett. 2001. Application of supervaluation semantics to vaguely defined concepts. In Daniel R.
Montello, editor, Proceedings of the 5
th
International Conference on Spatial Information Theory (COSIT?01),
number 2205 in LNCS, pages 108?123, Morro Bay. Springer.
Gerard de Melo and Mohit Bansal. 2013. Good, great, excellent: Global inference of semantic intensities. Trans-
actions of the Association for Computational Linguistics, 1:279?290.
Gerard de Melo. 2014a. From linked data to tighly integrated data. LREC 2014 Workshop on Linked Data in
Linguistics (LDL-2014). Invited speaker.
Gerard de Melo. 2014b. Link prediction in semantic knowledge graphs. The Hong Kong Polytechnic University,
March. Invited speaker.
Ian Niles and Adam Pease. 2001. Towards a standard upper ontology. In Christopher A. Welty and Barry Smith,
editors, Proceedings of the 2
nd
International Conference on Formal Ontology in Information Systems (FOIS
2001).
Adam Pease and John Li. 2003. Agent-mediated knowledge engineering collaboration. In Proceedings of the
AAAI 2003 Spring Symposium on Agent-Mediated Knowledge Management.
Adam Pease and W.R. Murray. 2003. An english to logic translator for ontology-based knowledge representation
languages. In Proceedings of the 2003 IEEE International Conference on Natural Language Processing and
Knowledge Engineering, pages 777?783.
Adam Pease and Ian Niles. 2003. Linking lexicons and ontologies: Mapping wordnet to the suggested upper
merged ontology. In Proceedings of the IEEE International Conference on Information and Knowledge Engi-
neering, pages 412?416.
Adam Pease and Stephan Schulz. 2014. Knowledge engineering for large ontologies with sigmakee 3.0. Submit-
ted accepted version for journal paper.
Adam Pease. 2003a. Mapping linguistic elements to logical expressions. In Workshop on Ontological Knowledge
and Linguistic Coding at the 25
th
Annual Meeting of the German Linguistics Society (Deutsche Gesellschaft
f
?
?ur Sprachwissenschaft).
Adam Pease. 2003b. The sigma ontology development environment. In Working Notes of the IJCAI-2003 Work-
shop on Ontology and Distributed Systems, volume 71.
Adam Pease. 2011. Ontology: A Practical Guide. Articulate Software Press, Angwin, CA.
Peter F. Schulam and Christiane Fellbaum. 2010. Automatically determining the semantic gradiation of german
adjectives. In Proceedings of KONVENS.
143
Zock/Rapp/Huang (eds.): Proceedings of the 4th Workshop on Cognitive Aspects of the Lexicon, pages 198?209,
Dublin, Ireland, August 23, 2014.
Modelling the Semantics of Adjectives in the Ontology-Lexicon Interface
John P. M
c
Crae
Universit?at Bielefeld
Bielefeld
Germany
jmccrae@cit-ec.uni-bielefeld.de
Christina Unger
Universit?at Bielefeld
Bielefeld
Germany
cunger@cit-ec.uni-bielefeld.de
Francesca Quattri
Hong Kong Polytechnic University
Hong Kong
francesca.quattri@connect.polyu.hk
Philipp Cimiano
Universit?at Bielefeld
Bielefeld
Germany
cimiano@cit-ec.uni-bielefeld.de
Abstract
The modelling of the semantics of adjectives is notoriously challenging. We consider this prob-
lem in the context of the so called ontology-lexicon interface, which attempts to capture the
semantics of words by reference to an ontology in description logics or some other, typically
first-order, logical formalism. The use of first order logic (hence also description logics), while
effective for nouns and verbs, breaks down in the case of adjectives. We argue that this is primar-
ily due to a lack of logical expressivity in the underlying ontology languages. In particular, be-
yond the straightforward intersective adjectives, there exist gradable adjectives, requiring fuzzy
or non-monotonic semantics, as well as operator adjectives, requiring second-order logic for
modelling. We consider how we can extend the ontology-lexicon interface as realized by extant
models such as lemon in the face of the issues mentioned above, in particular those arising in the
context of modelling the ontological semantics of adjectives. We show howmore complex logical
formalisms that are required to capture the ontological semantics of adjectives can be backward
engineered into OWL-based modelling by means of pseudo-classes. We discuss the implications
of this modelling in the context of application to ontology-based question answering.
1 Introduction
Ontology-lexicon models, such as lemon (Lexicon Model for Ontologies) (M
c
Crae et al., 2012) model
the semantics of open class words by capturing their semantics with respect to the semantic vocabulary
defined in a given ontology. Such ontology-lexica are built around the separation of a lexical layer, de-
scribing how a word or phrase acts syntactically and morphologically, and a semantic layer describing
how the meaning of a word is expressed in a formal logical model, such as OWL (Web Ontology Lan-
guage) (Deborah L. M
c
Guinness and others, 2004). As such, the modelling is based around a lexical
entry which describes the morphology and syntax of a word, and is linked by means of a lexical sense
to an ontology entity defined in a given ontology described in formal logic. It has been shown that this
principle known as semantics by reference (Buitelaar, 2010) is an effective model that can support the
task of developing question answering systems (Unger and Cimiano, 2011) and natural language gen-
eration (Cimiano et al., 2013) over backends based on Semantic Web data models. The Pythia system,
which builds on the lemon formalism to declaratively capture the lexicon-ontology interface, for exam-
ple, has been instantiated to the case of answering questions from DBpedia (Unger and Cimiano, 2011).
However, as has been shown by the Question Answering over Linked Data (Lopez et al., 2013, QALD)
benchmarking campaigns, there are many questions that can be asked over this database that require a
deeper representation of the semantics of words, adjectives in particular. For example, questions such
This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer
are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/
198
as (1a) require understanding of the semantics of ?high? in a manner that goes beyond the expressivity of
OWL. The formalization of this question as an executable query formulated with respect to the SPARQL
query language is provided in (1b). In particular, the interpretation of this question involves the formal
interpretation of the word ?high? as relating to the property dbo:elevation, including ordering and
subset selection operations.
1. (a) What is the highest mountain in Australia?
(b) SELECT DISTINCT ?uri WHERE {
?uri rdf:type dbo:Mountain .
?uri dbo:locatedInArea res:Australia .
?uri dbo:elevation ?elevation .
} ORDER BY DESC(?elevation) LIMIT 1
In the above query, we select an entity denoted by the query variable ?uri that has the properties
that i) the entity?s type is a mountain, ii) it is located in Australia, and iii) it has an elevation bound to
the variable ?elevation. We then sort the query in descending order by the value of the elevation
and limit so the query returns only the first result, in effect choosing the largest value in the data set.
It has been claimed that first-order logic and thus by extension description logics, such as OWL, ?fail
decidedly when it comes to adjectives? (Bankston, 2003). In fact, we largely agree that the semantics of
many adjectives are difficult or impossible to describe in first-order logic. However, from the point of
view of the ontology-lexicon interface, the logical expressivity of the ontology is not a limiting factor. In
fact, due to the separation of the lexical and ontology layers in a model such as lemon, it is possible to
express the meaning of words without worrying about the formalism used in the ontology. To this extent,
we will first demonstrate that adjectives are in general a case where the use of description logics (DL)
breaks down, and for which more sophisticated logical formalisms must be applied. We then consider
to what extent this can be handled in the context of the ontology-lexicon, and introduce pseudo-classes,
that is OWL classes with annotations, which we use to express the semantics of adjectives in a manner
that would allow reasoning with fuzzy, high-order models. To this extent, we base our models on the
previously introduced design patterns (M
c
Crae and Unger, 2014) for modelling ontology-lexica. Finally,
we show how these semantics can be helpful in practical applications of question answering over the
DBpedia knowledge base.
2 Classification of adjectives
There are a number of classifications of adjectives. First we will start with the most fundamental dis-
tinction between attributive and predicative usage, that is the use of adjectives in noun phrases (?X is a
A N?) versus as objects of the copula (?X is A?). It should be noted that there are many adjectives for
which only predicative or attributive usage is allowed, as shown in (3a) and (3).
2. (a) Clinton is a former president.
(b)
?
Clinton is former.
3. (a) The baby is awake.
(b)
?
The awake baby.
One of the principle classifications of the semantics of adjectives (for example (Partee, 2003; Bouillon
and Viegas, 1999; Morzycki, 2013b)) is based on the meaning of adjective noun compounds relative to
the meaning of the single words that form the compound. This classification is as follows (where ?
denotes entailment).
Intersective (X is a A N ? X is A ? X is a N ) Such adjectives work as if they were another noun
and indicate that the compound noun phrase is a member of class denoted by the noun and the class
denoted by the adjective. For example, in the phrase ?Belgian violinist? it refers to a person in the
class intersection Belgian ? V iolinist(X), and hence we can infer that a ?Belgian violinist? is a
subclass of a ?Belgian?. Furthermore, we could conclude that if the same person were a surgeon,
he/she would also be a ?Belgian Surgeon?.
199
Subsective (X is a AN ? X is a N , but X is a A N ?? X is A) Such adjectives acquire their specific
meaning in combination with the noun the modify. For example, a ?skilful violinist? is certainly in
the class V iolinist(X) but the described person is ?skilful as a violinist?, but not skilful in general,
e.g. as a surgeon.
Privative (X is a A N ?? X is a N ) These adjectives modify the meaning of a noun phrase to create a
noun phrase that is potentially incompatible with the original meaning. For example, a ?fake gun?
is not a member of the class of guns.
Another important distinction is whether adjectives are gradable, i.e. whether a comparative or su-
perlative statement with these adjectives makes sense. For example, adjectives such as ?big? or ?tall? can
express relationships such as ?X is bigger than Y ?. However it is not possible to say that one individ-
ual is ?more former?. Most gradable adjectives are subsective (e. g.?a big mouse? is not ?a big animal?
(Morzycki, 2013a)).
Finally, we consider operator or property-modifying adjectives. They can be understood along the
lines of privative adjectives but differ in that they represent operators that modify some property in the
qualia structure (Pustejovsky, 1991) of the class. For instance, we may express the adjective ?former? in
lambda calculus as a function that takes a class C as input and returns the class of entities that were a
member of C to some prior time point t (Partee, 2003):
?C[?x?tC(x, t) ? t < now]
Such adjectives have not only a difference in semantic meaning but can also frequently have syntactic
impact, for example in adjective ordering restrictions, as they may be reordered with only semantic
impact (Teodorescu, 2006), e.g.,
4. (a) A big red car.
(b)
?
A red big car.
5. (a) A famous former actor.
(b) A former famous actor.
Finally, we define object-relational adjectives as those adjectives which have a meaning that expresses
a relationship between two individuals or events
1
, for example:
6. He is related to her.
7. She is similar to her brother.
8. This is useful for something.
3 Representation of adjectives in the ontology-lexicon interface
In general it is assumed that adjectives form frames with exactly one argument except for extra arguments
provided by adjuncts, typically prepositional phrases. Most adjectives are thus associated with a pred-
icative frame, which much like the standard noun predicate frame (X is a N ) is stereotyped in English
as:
X is A
The attributive usage of an adjective is associate to a stereotypical frame where the N? argument is
not semantically bound, but can instead be obtained by syntactic unification to a noun predicate frame:
X is A N?
As such, when we encounter the attributive usage of an adjective such as in 9, we understand this as
the realization of two frames, given in 10.
9. Juan is a Spanish researcher.
10. (a) Juan is a researcher.
(b) Juan is a Spanish N?
Note that we do not provide modelling for adjectives where the meaning is unique for a particular
noun phrase, such as ?polar bear?, which we would capture as a normal noun phrase with meaning ursus
maritimus.
1
Our definition of relational here is borrowed from the idea of relational nouns (De Bruin and Scha, 1988) as a word that requires
an argument. Our definition is also different from the one for ?relational adjectives? as proposed by (Morzycki, 2013a).
200
Figure 1: Modelling of an intersective adjective ?Belgian? in lemon
3.1 Intersective adjectives
Intersective adjectives are the most straightforward class, as in many cases they can be modelled es-
sentially as a noun or verb (e.g. deverbal adjectives such as ?broken?). Intersective adjectives take one
argument and can thus be modelled as unary predicates in first-order logic or classes in OWL, as de-
scribed by M
c
Crae and Unger (2014). For practical modelling examples, we will use the lemon model,
since it is the most prominent implementation of the ontology-lexicon interface.
The primary mechanism of modelling the syntax-semantics interface in the context of lemon is by
means of assigning a frame as a syntactic behaviour of an entry and giving it syntactic arguments, which
can then be linked to the lexical sense, which stands proxy for a true semantic frame in the ontology. For
example, the modelling of an adjective such as ?Belgian? can be achieved as follows (depicted in Figure
1)
2
.
lexicon:belgian a lemon:LexicalEntry ;
lemon:canonicalForm belgian:Lemma ;
lemon:synBehavior belgian:AttrFrame ,
belgian:PredFrame ;
lemon:sense belgian:Sense .
belgian:Lemma lemon:writtenRep "Belgian"@eng .
belgian:AttrFrame lexinfo:attributiveArg belgian:AttrSynArg .
belgian:PredFrame lexinfo:copulativeArg belgian:PredSynArg .
belgian:sense lemon:reference [ a owl:Restriction ;
owl:onProperty dbpedia:nationality ;
owl:hasValue dbpedia:Belgium ] ;
lemon:isA belgian:AttrSynArg , belgian:PredSynArg .
In this example, the word ?Belgian? is associated with a lemma with representation ?Belgian?, two
frame objects and a lexical sense. The frame objects describe the attributive and predicative usage,
and are associated with an attributive and copulative argument respectively. The sense links the word
to the anonymous ontological class for objects that have ?Belgium? as the value of their ?national-
ity? property and furthermore the arguments of each frame are linked to the sense in order to estab-
lish a correspondence between the ontology class and the syntactic frames. Note that here we use
the external vocabulary defined in the LexInfo ontology (Cimiano et al., 2011) to define the mean-
ing of the arguments of the frame as the attributive argument, corresponding to the frame stereo-
type ?X is A N?? and the copulative argument for the frame stereotype ?X is A?. Furthermore, the
2
We assume that the namespaces are defined for the lexicon as lexicon, e.g., http://www.example.org/lexicon
and for the entry, e.g., belgian is http://www.example.org/lexicon/belgian#. Other namespaces are as-
sumed to be as usual.
201
class of Belgians is not named in our reference ontology DBpedia, so we introduce an anonymous
class with the axiomatization, i.e. ? nationality .Belgium. It is in fact common that the referent of
an adjective is not named in an ontology. An obvious choice is thus to model denominal adjec-
tives as classes of the form ? prop.Value, where Value is an individual that represents the seman-
tics of the noun from which the adjective was derived. This modelling is so common that it has al-
ready been encoded as two design patterns, called IntersectiveObjectPropertyAdjective
and IntersectiveDatatypePropertyAdjective (see (M
c
Crae and Unger, 2014)). Simi-
larly, most deverbal adjectives refer to an event, and as such a common modelling is of the form
? theme
?1
.EventClass. For example, ?vandalized? may be ? theme
?1
.VandalismEvent.
3.2 Gradable adjectives and relevant observables
Gradable adjectives have a number of properties which differentiate them from intersective adjectives:
? They occur in comparative constructions, in English with either ?-er? or ?more? (Kennedy and Mc-
Nally, 1999), e.g. ?smaller? and ?more frequent?, as opposed to intersectives such as ?*less geologi-
cal? and ?*more wooden?.
? Gradable adjectives can be defined as ?scalar?, since their value can ideally be measured on a scale
of set degrees
? They have a context-dependent truth-conditional variability, meaning that their positive form is un-
derstood in relation to the class of the object modified by the adjective. For example, an ?expensive
watch? has a different price scale to an ?expensive bottle of water?.
? They are frequently fuzzy (or vague) (Kennedy, 2007).
? There may be a minimum or maximum of the adjective?s scale, which can be determined by, for
example, whether they can modified by adverbs such as ?completely? or ?utterly?.
As such, we define gradable adjectives relative to a particular property. These adjectives are also
called ?observable? (Bennett, 2006)
3
as they are related to some observable or measurable property, e.g.
size in the case of ?big?. However, a specification of the observable property is clearly not sufficient to
differentiate between the meaning of antonyms such as big and small. Thus, we introduce the notions of
covariance and contravariance, which specify whether the comparative form indicates a higher property
value for the subject or the object. In this sense ?big? is covariant with size, as bigger things have a
higher size value, and ?small? is contravariant with size.
4
We also introduce a third concept, i.e. the one
of absolute gradability, which expresses the fact that the degree of membership in the denotation of the
adjective is stronger the more it approaches a prototypical or ideal value. A common example of this is
colours, where we may say that some object is redder than another if it is closer to some ideal value of
red (e.g., RGB 0xff0000).
While these notions can handle the comparative structure of the semantics of adjectives, the predicative
and superlative usage of adjectives is complicated by three factors that we will outline below. We notice
that gradable classes are not crisply defined like in the case of many intersective adjectives. In fact, while
we can clearly define all people in the world as ?Belgian? or ?not Belgian?, according to whom holds
a Belgian passport or not, it is not easy to split the world?s population into ?tall? and ?not tall? (This is
known as sorites paradox (Bennett, 2006)). Furthermore, while it may be easy to say that someone with
height 6?6? (198cm) is ?tall?, it is not clear whether someone with height 6? (182cm) is ?tall?, although
compared to an average (different) height for a man, they are ?taller?. As such, one frequently used way
to deal with this class of vague adjectives (and nouns) is via fuzzy logic (Goguen, 1969; Zadeh, 1975;
Zadeh, 1965; Dubois and Prade, 1988; Bennett, 2006). Secondly, we notice that these class boundaries
are non-monotonic, that is that with knowledge of more instances of the relative class we must revise
our class boundaries. This is especially the case for superlatives, as the discovery of a new tallest person
3
Note that in many cases the property is quite abstract such as in ?breakable?.
4
The use of these terms is borrowed from type systems, and resembles the concept of ?converse observables? as introduced by
((Bennett, 2006):42). As stated by the author, adjectives often come in pairs of polar opposites (e. g. conv(tall) = short, and
both refer to the same observable (in this case size). Some observables analogously hold converse relationships with other
observables (e. g. conv(flexibility) = rigidity or conv(tallness) = shortness).
202
in the world would remove the existing tallest person in the world from the class of tallest person in the
world. This non-monotonicity also affects the class boundaries of the gradable class itself. For example,
in the 18th century, the average height of a male was 5?5? (165cm)
5
; as such a male of 6? would have
clearly been considered tall.
It follows from this that each instance added to our ontology might lead to a revision of the class
boundaries of a gradable class, hence leading to the fact that gradable adjectives are fundamentally non-
monotonic. We must also notice that gradability can only be understood relative to the class that we wish
to grade. Thus, while it is a priori unclear whether 6? is tall for a male, it is clear that 6? is tall for a
female given the current average height of a female being about 5?4? (162cm).
We can therefore conclude that gradable adjectives are fuzzy, non-monotonic and context-sensitive, all
of which are incompatible with the description logic used in OWL.
Pseudo-classes in lemonOILS
Currently there are only limited models for representing fuzzy logic in the context of the Web (Zhao and
Boley, 2008). In order to capture the properties of gradable adjectives, we introduce a new model which
we name lemonOILS (The lemon Ontology for the Interpretation of Lexical Semantics)
6
. This ontology
introduces three new classes:
? CovariantScalar, indicating that the adjective is covariant with its bound property
? ContravariantScalar, indicating that the adjective is contravariant with its bound property
? AbsoluteScalar, indicating that the property represents similarity to an absolute value
In addition, the following properties are introduced to enable the description of gradable adjectives.
Note that all these properties are typed as annotation properties in the OWL ontology, so that they do
not interfere with the standard OWL reasoning.
? boundTo indicates the property that a scalar refers to (e.g., ?size? for ?big?)
? threshold specifies a sensible minimal value for which the adjective can be said to hold
? absoluteValue is the ideal value of an absolute scalar
? degree is specified as weak, medium, strong or very strong, corresponding to approxi-
mately 50%, 25%, 5% or 1% of all known individuals
? comparator indicates an object property that is equivalent to the comparison of the adjective
(e.g., an object property biggerThan may be considered a comparator for the adjective class
big)
? measure indicates a unit that can be used as a measure for this adjective, e.g., ?John is 175 cen-
timetres tall?.
Using such classes we can capture the semantics of gradable adjectives syntactically but not formally
within an OWL model. As such, we call these introduced classes pseudo-classes. An example of mod-
elling an adjective such as ?high? is given below (and depicted in Figure 2).
lexicon:high a lemon:LexicalEntry ;
lemon:canonicalForm high:Lemma ;
lemon:synBehavior high:PredFrame ;
lemon:sense high:Sense .
high:Lemma lemon:writtenRep "high"@eng .
high:PredFrame lexinfo:copulativeArg high:PredArg .
high:Sense lemon:reference [
rdfs:subClassOf oils:CovariantScalar ;
oils:boundTo dbpedia:elevation ;
oils:degree oils:strong ] ;
lemon:isA high:PredArg .
5
https://en.wikipedia.org/wiki/Human_height
6
http://lemon-model.net/oils
203
Figure 2: An example of the modelling of ?high? in lemon
As an example of a logic in which these annotations could be interpreted, we consider Markov
Logic (Richardson and Domingos, 2006), which is an extension of first-order logic in which each clause
is given a cost. The process of reasoning is thus transformed into an optimization problem of finding
the extension which minimizes the summed weight of all violated clauses. As such, we can formulate
a gradable adjective based on the number of known instances. For example, we can specify ?big? with
respect to size for some class C as in (11).
11. ?x ? C, y ? C : size(x) > size(y) ? big
C
(x) : ?
?x ? C, y ? C : size(x) < size(y) ? ?big
C
(x) : ?
In this way, the classification of an object into ?big? or ?small? can be defined as follows. For an individual
x ? C, the property big
C
(x) holds if and only if:
|{y ? C, size(y) > size(x)}|? < |{y ? C, size(y) < size(x)}|?
where the values of ? and ? are related to the degree defined in the ontology.
We see that ?big? defined in this way has the three properties outlined above: it is non-monotonic (in
that more individuals may change whether we consider an individual to be ?big? or not), it is fuzzy (given
by the strength of the probability of the proposition big
C
(x)), and it is context-sensitive (as whether an
individual counts as big or not depends on the class C). Furthermore, our definition does not rely on
defining ?big? for a given class, but instead is inferred from some known number of instances of this
class. This eliminates the need to define a threshold for each individual class, or even to define the
predicate big
C
on a per-class basis.
The supervaluation theory and SUMO
Another way to capture the meaning of these vague terms can be achieved by supervaluation semantics.
Through supervaluation theory, the modelling or positioning of sorites vague concepts is grounded in a
judgement or meaning that lies on arbitrary thresholds, but these thresholds are based on a number of
relevant objective measures (Bennett, 2006).
A recent extension of the SUMO ontology (Niles and Pease, 2001, Suggested Upper Merged On-
tology)
7
includes default measurements (currently amounting to 300+) added to the Artifacts,
Devices and Objects enlisted in the ontology (and marked with capitals). The compilation of
defaultMeasurements in SUMO has been just conducted on observables, not on predicates. Given
for instance an Artifact such as Book, the compilation of its default measurements would look like:
;;Book
(defaultMinimumHeight Book (MeasureFn 10 Inch))
(defaultMaximumHeight Book (MeasureFn 11 Inch))
(defaultMinimumLength Book (MeasureFn 5.5 Inch))
(defaultMaximumLength Book (MeasureFn 7 Inch))
(defaultMinimumWidth Book (MeasureFn 1.2 Inch))
(defaultMaximumWidth Book (MeasureFn 5.5 Inch))
7
www.ontologyportal.org
204
The example for Book shows that the default measurements for the observable reflect a standard kind
of book, i.e., one of the most commonly known kinds of the same artifact. As for this case, SUMO
implies Book to be a physical object with a certain length, height and width (and possibly weight). A
weakness here is that the there is no systematic connection between the defaultMinimumHeight
and Height or Width, since these physical properties have been defined in SUMO just in terms of
first-order logic, and have not been assigned default measurements yet. With lemonOILS we can add this
information as follows:
sumo:Book oils:default [
oils:defaultFor sumo:height ;
oils:defaultMin "10in" ;
oils:defaultMax "11in" ] .
Then, if we understand a lexical entry ?high? as referring to a scalar covariant pseudo-class for
sumo:height, it is possible to understand that a ?high? object exceeds the default minimum set es-
tablished for the same object and owns at the same time a value for ?high? which does not go beyond the
established default maximum. A further weakness of this approach is captured by the following example:
12. Avery Johnson is a short basketball player.
Here, we see the difficulty in interpreting the sentence, as Avery Johnson is in fact of average height
(5?10?) but for the class of basketball players he is unusually short. While SUMO has some very specific
listings of subsets for the same Artifact
8
, SUMO does not provide a well-structured subset net for
e. g. Person.As a way to address this bottleneck, we could introduce default values for every subclass
of Person, as well as to introduce default values for the same Artifact in conjunction with a predicate
or adjective (e. g. BigPerson, BulkyPerson). The creation of such ad hoc subclasses is not feasible
in general, as we would have to introduce a new class into the ontology for every combination of an
adjective and a noun. On the other side though, the SUMO default measurements serve the purpose
they were originally conceived for, namely to be an arbitrary, yet computable approximation of physical
measures.
3.3 Operator adjectives
Operator adjectives are those that combine with a noun to modify the meaning of the noun itself. There
are two primary issues with the understanding of the adjective in this manner. Firstly, the reference
of the lexical item does not generally refer to an existing item in the ontology, but rather is novel and
productive, in the sense that it generates a new class. Secondly, the compositional nature of adjective-
noun compounds is no longer simple, as in the cases of intersective and gradable adjectives. This means
that, in order to understand a concept such as a ?fake gun?, we must first derive a class of FakeGuns
from the class of Guns. Thus the modified noun phrase must be an argument of the operator adjective.
To this extent we claim that it is not generally possibly to represent the meaning of an operator adjective
within the context of an OWL ontology. Instead, following Bankston (Bankston, 2003), we claim that the
reference of an operator adjective must be a higher order predicate. If we assume that there are operators
of the form of a function, then the argument of an operator is the attributed noun phrase. As such, we
introduce a frame operator attributive, that has one argument which is the noun. Thus we understand
that the interpretation of ?fake gun? is by means of an operator fake, which is a function that takes
a class and produces a new class, i.e., [fake(Gun)](X). Capturing such an operator lies beyond the
expressivity of first-order logic. To fully capture the semantics of such an operator adjective, formalisms
beyond first-order logic are thus clearly needed.
3.4 Object-relational adjectives
Object-relational adjectives are those that require a second argument, such as ?known?, which can only
be understood as being ?known? to some person, in comparison to ?famous?. Thus, the modelling of the
relational adjective known is quite similar to the semantics of the corresponding verb know. It can be
modelled for instance via the frame ?X is known to Y ? and reference foaf:knows as:
8
For example, some of the subsets Car are: CrewDormCar, GalleryCar, MotorRailcar, FreightCar, BoxCar,
RefrigeratorCar, FiveWellStackCar, and more.
205
lexicon:known a lemon:LexicalEntry ;
lemon:canonicalForm known:Lemma ;
lemon:sense known:Sense ;
lemon:synBehavior known:Frame .
known:Lemma lemon:writtenRep "known"@eng .
known:Frame lexinfo:attributeArg known:Subject ;
lexinfo:prepositionalObject known:Object .
known:Sense lemon:reference foaf:knows ;
lemon:subjOfProp known:Subject ;
lemon:objOfProp known:Object .
known:Object lemon:marker lexicon:to .
4 Adjectives in question answering
In this section we empirically analyze the adequacy of the modelling proposed in this paper with respect
to the QALD-4
9
dataset, a shared dataset for Question Answering over Linked Data. The 250 training
and test questions of the QALD-4 benchmark contain 76 adjectives in total (not counting adjectives in
names such as ?Mean Hamster Software?).
18 of the occurring adjectives do not have a semantic contribution w.r.t. the underlying DBpedia
ontology, or at least none that is separable from the noun, as exemplified in the noun phrases in (13) and
(14).
10
13. (a) [[official website]] = dbo:website
(b) [[national anthem]] = dbo:anthem
14. (a) [[official languages]] = dbo:officialLanguages
(b) [[military conflicts]] = dbo:battle
Otherwise, the most common kinds of adjectives among them are gradable (27) and intersective (13)
adjectives.
All intersective adjectives denote restriction classes that are not explicitely named in DBpedia, in
correspondence with the modelling proposed in Section 3.1 above, for example:
15. (a) [[Danish]] = ?dbo:country .res:Denmark
(b) [[female]] = ?dbo:gender .res:Female
(c) [[Methodist]] = ?dbo:religion .res:Methodism
In some cases these intersectives have a context-dependent and highly ontology-specific meaning,
often tightly interwoven with the meaning of the noun, as in the following examples:
16. (a) [[first president of the United States]] = ?dbo:office . ?1st President of the United States?
(b) [[first season]] = ?dbo:seasonNumber . 1
All gradable adjectives that occur in the QALD-4 question set can be captured in terms of lemonOILS
as CovariantScalar (e.g. ?high?) or ContravariantScalar (e.g. ?young?) (cf. Section 3.2
above), bound to a DBpedia datatype property (e.g. elevation or birthDate). The positive form
of those adjectives only occurs in ?how (much)? questions, denoting the property they are bound to, for
example:
17. (a) [[deep]] = dbo:depth in ?How deep is Lake Placid??
(b) [[tall]] = dbo:height in ?How tall is Michael Jordan??
9
http://www.sc.cit-ec.uni-bielefeld.de/qald/
10
[[?]] stands for ?denotes? and the prefixes dbo and res abbreviate the DBpedia namespaces
http://dbpedia.org/ontology/ and http://dbpedia.org/resource/, respectively.
206
The comparative form denotes the property they are bound to, together with an aggregation operation,
usually a filter invoking a term of comparison that depends on whether the adjective is covariant or
contravariant.
18. (a) [[Which mountains are higher than the Nanga Parbat?]] =
SELECT DISTINCT ?uri WHERE {
res:Nanga_Parbat dbo:elevation ?x .
?uri rdf:type dbo:Mountain .
?uri dbo:elevation ?y .
FILTER (?y > ?x)
}
Finally, the superlative form denotes the property they are bound to, together with an aggregation
operation, usually an ordering with a cut-off of all results except the first one, as exemplified in (19). In
some cases, the superlative property is already encoded in the ontology, e.g., in the case of the property
dbo:highestPlace.
19. [[What is the longest river?]] =
SELECT DISTINCT ?uri WHERE {
?uri rdf:type dbo:River .
?uri dbo:length ?l .
} ORDER BY DESC(?l) OFFSET 0 LIMIT 1
There are three instances of operator adjectives. Examples are ?former?, as in 20, which does not
refer to an element in the DBpedia ontology but is instead a disambiguation clue in the given query, and
?professional?, which refers to the property dbo:occupation, see 21.
20. [[the former Dutch queen Juliana]] = res:Juliana
21. [[professional surfer]] = ?dbo:occupation .res:Surfing
Finally, there were 8 remaining adjectives totalling 15 occurrences, which do not correspond to mean-
ing in an ontology, but instead are part of the discourse structure, each ?same?, ?other?.
5 Related work
The categorization of adjectives in terms of formal semantics goes back to Montague (1970) and
Vendler (1968). However, one of the most significant attempts to assign a formal meaning was car-
ried out in the Mikrokosmos project (Raskin and Nirenburg, 1995). The approach to adjective modelling
in the Mikrokosmos provided one of the first computational implementations of a microtheory of adjec-
tive meaning. The modelling of adjectives presented in this paper is clearly inspired by the modelling
of adjectives adopted in the Mikrokosmos project. In particular, scalar adjectives in the Microkosmos
project are modeled by association with an attribute and a range, e.g., ?big? is described as being >0.75
(i.e., 75% of all known instances) on the size-attribute. Still, these classifications do not clearly
separate meaning and syntax and also require a separate modelling of comparatives and class-specific
meanings for many adjectives.
Amoia and Gardent (2006) handled the problem of adjectives in the context of textual entailment. They
analyzed 15 classes that show the subtle interaction between the semantic class (e.g., ?privative?) and the
issues of attributive/predicative use and gradability. Abdullah and Frost (2005) focused on the modelling
of privative adjectives by arguing that these adjectives modify the underlying set itself in a manner that
is naturally second-order. Similarly, Partee (2003) proposed a limited second-order model by means of
the ?head primary principle? requiring that adjectives are interpreted within their context. Bankston?s
analysis (2003), however, shows that the fundamental nature of many adjectives is higher-order, and pro-
vides a very sophisticated formal representation framework for adjectives. A more thorough discussion
of non-gradable, non-intersective adjectives is given by Morzycki (2013a). Bouillion and Viegas (1999)
consider the case of the French adjective ?vieux? (?old?), which they interprete as selecting two differ-
ent elements in the event structure of an attributed noun, that is whether the state, e.g., ?being a mayor?
for ?mayor?, is considered old or the individual itself. In this way, the introduction of two senses for
?vieux? is avoided, however it remains unclear if such reasoning introduces more complexity than the
207
extra senses. In his analysis of adjectives, Larson (1998) suggests that many adjectives denote properties
of events, rather than of simple heads or nouns (which does not fall very far from the statement, made
above, that relational adjectives denote properties of kinds). Pustejovsky (1992; 1991) and Lenci (2000)
state that lexical and semantic decomposition can be achieved generatively, assigning to each lexical item
a specific qualia structure. For instance, in an expression like:
22. The round, heavy, wooden, inlaid magnifying glass
? ?round? represents the Formal role (giving indications of shape and dimensionality)
? ?heavy? and ?wooden? related to the Constitutive role and indicate the relation between the
object and its parts (e. g. by specifying weight, material, parts and components)
? ?inlaid? is the Agentive role of the lexical item, denoting the factors that have been involved in
the generation of the objects, such as creator, artifact, natural kind, and causal chain
? ?magnifying? describes the Telic role of ?glass?, since it shows its purpose and function
Finally, Peters and Peters (2000) provide one of the few other practical reports on modelling adjectives
with ontologies, in the context of the SIMPLE lexica. This work is primarily focussed on the categoriza-
tion of by means of intensional and extensional properties, rather than due to their logical modelling.
6 Conclusion
In this paper we have proposed an approach to model the semantics of adjectives in the context of the
lexicon-ontology interface with a focus on the ontology-lexicon model lemon. We have argued that the
semantics of adjectives, in particular gradable and privative adjectives, is beyond what can be expressed
in first-order logics, OWL in particular. Instead, capturing the semantics of such adjectives requires
formalisms that are non-monotonic, second-order and can represent fuzzy concepts. We have proposed
an extension of lemon by the lemonOILS vocabulary that adds ?syntactic sugar? that allows us to represent
the semantics of adjectives in a way that abstracts from the actual representational formalism used. This
work has been used in the construction of lexical resources to support a question answering system,
and we found that this framework is sufficient to enable tractable computation of natural language to
SPARQL mapping over at least a small but varied set of test questions used in the QALD evaluation
task. Future work will show whether this model is scalable and applicable to most adjectives as well as
domains and natural languages.
References
Nabil Abdullah and Richard A Frost. 2005. Adjectives: A uniform semantic approach. In Advances in Artificial
Intelligence, pages 330?341. Springer.
Marilisa Amoia and Claire Gardent. 2006. Adjective based inference. In Proceedings of the Workshop KRAQ?06
on Knowledge and Reasoning for Language Processing, pages 20?27. Association for Computational Linguis-
tics.
Paul Bankston. 2003. Modeling nonintersective adjectives using operator logics. The Review of Modern Logic,
9(1-2):9?28.
Brandon Bennett. 2006. A theory of vague adjectives grounded in relevant observables. In John Mylopoulos
Patrick Doherty and Christopher A. Welty, editors, Proceedings of the Tenth International Conference on Prin-
ciples of Knowledge Representation and Reasoning, pages 36?45. AAAI Press.
Pierrette Bouillon and Evelyne Viegas. 1999. The description of adjectives for natural language processing: Theo-
retical and applied perspectives. In Proceedings of Description des Adjectifs pour les Traitements Informatiques.
Traitement Automatique des Langues Naturelles. Citeseer.
Pierrette Bouillon. 1999. The adjective ?vieux?: The point of view of ?generative lexicon?. In Breadth and depth
of semantic lexicons, pages 147?166. Springer.
Paul Buitelaar, 2010. Ontology-based Semantic Lexicons: Mapping between Terms and Object Descriptions,
pages 212?223. Cambridge University Press.
Philipp Cimiano, Paul Buitelaar, John M
c
Crae, and Michael Sintek. 2011. Lexinfo: A declarative model for the
lexicon-ontology interface. Web Semantics: Science, Services and Agents on the World Wide Web, 9(1):29?51.
Philipp Cimiano, Janna L?uker, David Nagel, and Christina Unger. 2013. Exploiting ontology lexica for generating
natural language texts from rdf data. In Proceedings of the 14th European Workshop on Natural Language
Generation, pages 10?19.
208
Jos De Bruin and Remko Scha. 1988. The interpretation of relational nouns. In Proceedings of the 26th annual
meeting on Association for Computational Linguistics, pages 25?32. Association for Computational Linguistics.
Frank Van Harmelen Deborah L. M
c
Guinness et al. 2004. Owl web ontology language overview. W3C recom-
mendation, 10(2004-03):10.
Didier Dubois and Henri Prade. 1988. Possibility theory. Plenum Press, New York.
Joseph H. Goguen. 1969. The logic of inexact concepts. Synthese, 19:325?373.
Christopher Kennedy and Louise McNally. 1999. Deriving the scalar structure of deverbal adjectives. Catalan
Working Papers in Linguistics, 7:125?139.
Christopher Kennedy. 2007. Vagueness and grammar: the semantics of relative and absolute gradable adjectives.
Linguistics and philosophy, 30:1?45.
Richard K. Larson. 1998. Events and modification in nominals. In Devon Strolovitch and Aaron Lawson, editors,
Proceedings from Semantics and Linguistic Theory (SALT) VIII, pages 145?168. CLC Publications, Itaca, New
York.
Alessandro Lenci et al. 2000. Simple work package 2, linguistic specifications, deliverable d2.1.
Vanessa Lopez, Christina Unger, Philipp Cimiano, and Enrico Motta. 2013. Evaluating question answering over
linked data. Web Semantics: Science, Services and Agents on the World Wide Web, 21:3?13.
Louise McNally and Gemma Boleda. 2004. Relational adjectives as properties of kinds. Empirical issues in
formal syntax and semantics, 5:179?196.
Richard Montague. 1970. English as a formal language. In Bruno Visentini et al, editor, Linguaggi nella societa
e nella tecnica, pages 189?224. Milan: Edizioni di Comunit`a.
Marcin Morzycki. 2013a. The lexical semantics of adjectives: More than just scales. Ms., Michigan State
University. Draft of a chapter in Modification, a book in preparation for the Cambridge University Press series
Key Topics in Semantics and Pragmatics.
Marcin Morzycki. 2013b. Modification. Cambridge University Press.
John P. M
c
Crae and Christina Unger. 2014. Design patterns for the ontology-lexicon interface. In Paul Buitelaar
and Philipp Cimiano, editors, Towards the Multilingual Semantic Web: Principles, Methods and Applications.
Springer.
John M
c
Crae, Guadalupe Aguado-de Cea, Paul Buitelaar, Philipp Cimiano, Thierry Declerck, Asunci?on G?omez-
P?erez, Jorge Gracia, Laura Hollink, Elena Montiel-Ponsoda, Dennis Spohr, et al. 2012. Interchanging lexical
resources on the semantic web. Language Resources and Evaluation, 46(4):701?719.
Ian Niles and Adam Pease. 2001. Towards a standard upper ontology.
Barbara H Partee. 2003. Are there privative adjectives. In Conference on the Philosophy of Terry Parsons,
University of Massachusetts, Amherst.
Ivonne Peters and Wim Peters. 2000. The treatment of adjectives in simple: Theoretical observations. In LREC.
James Pustejovsky. 1991. The generative lexicon. Computational linguistics, 17(4):409?441.
James Pustejovsky. 1992. The syntax of event structure. In Bett Levin and Steven Pinker, editors, Lexical &
Conceptual Semantics, pages 47?83. Oxford: Blackwell.
Victor Raskin and Sergei Nirenburg. 1995. Lexical semantics of adjectives. New Mexico State University, Com-
puting Research Laboratory Technical Report, MCCS-95-288.
Matthew Richardson and Pedro Domingos. 2006. Markov logic networks. Machine learning, 62(1-2):107?136.
Alexandra Teodorescu. 2006. Adjective ordering restrictions revisited. In Proceedings of the 25th West Coast
Conference on Formal Linguistics, pages 399?407. Citeseer.
Christina Unger and Philipp Cimiano. 2011. Pythia: Compositional meaning construction for ontology-based
question answering on the semantic web. In Rafael Munoz, editor, Natural Language Processing and Infor-
mation Systems: 16th International Conference on Applications of Natural Language to Information Systems,
NLDB 2011, Alicante, Spain, June 28-30, 2011. Proceedings, volume 6716, pages 153?160. Springer.
Zeno Vendler. 1968. Adjectives and nominalizations. Number 5 in Papers on formal linguistics. Mouton.
Lofti A. Zadeh. 1965. Fuzzy sets. Information and Control, 8:338?353.
Lofti A. Zadeh. 1975. The concept of linguistic variable and its application to approximate reasoningi. Informa-
tion Sciences, 8:199?249.
Jidi Zhao and Harold Boley. 2008. Uncertainty treatment in the rule interchange format: From encoding to
extension. In URSW.
209
