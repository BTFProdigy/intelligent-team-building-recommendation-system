Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 550?560,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
ParGramBank: The ParGram Parallel Treebank
Sebastian Sulger and Miriam Butt
University of Konstanz, Germany
{sebastian.sulger|miriam.butt}@uni-konstanz.de
Tracy Holloway King
eBay Inc., USA
tracyking@ebay.com
Paul Meurer
Uni Research AS, Norway
paul.meurer@uni.no
Tibor Laczko? and Gyo?rgy Ra?kosi
University of Debrecen, Hungary
{laczko.tibor|rakosi.gyorgy}@arts.unideb.hu
Cheikh Bamba Dione and Helge Dyvik and Victoria Rose?n and Koenraad De Smedt
University of Bergen, Norway
dione.bamba@lle.uib.no, {dyvik|victoria|desmedt}@uib.no
Agnieszka Patejuk
Polish Academy of Sciences
aep@ipipan.waw.pl
O?zlem C?etinog?lu
University of Stuttgart, Germany
ozlem@ims.uni-stuttgart.de
I Wayan Arka* and Meladel Mistica+
*Australian National University and Udayana University, Indonesia
+Australian National University
wayan.arka@anu.edu.au, meladel.mistica@gmail.com
Abstract
This paper discusses the construction of
a parallel treebank currently involving ten
languages from six language families. The
treebank is based on deep LFG (Lexical-
Functional Grammar) grammars that were
developed within the framework of the
ParGram (Parallel Grammar) effort. The
grammars produce output that is maxi-
mally parallelized across languages and
language families. This output forms the
basis of a parallel treebank covering a
diverse set of phenomena. The treebank
is publicly available via the INESS tree-
banking environment, which also allows
for the alignment of language pairs. We
thus present a unique, multilayered paral-
lel treebank that represents more and dif-
ferent types of languages than are avail-
able in other treebanks, that represents
deep linguistic knowledge and that allows
for the alignment of sentences at sev-
eral levels: dependency structures, con-
stituency structures and POS information.
1 Introduction
This paper discusses the construction of a parallel
treebank currently involving ten languages that
represent several different language families, in-
cluding non-Indo-European. The treebank is based
on the output of individual deep LFG (Lexical-
Functional Grammar) grammars that were deve-
loped independently at different sites but within
the overall framework of ParGram (the Parallel
Grammar project) (Butt et al, 1999a; Butt et al,
2002). The aim of ParGram is to produce deep,
wide coverage grammars for a variety of lan-
guages. Deep grammars provide detailed syntactic
analysis, encode grammatical functions as well as
550
other grammatical features such as tense or aspect,
and are linguistically well-motivated. The Par-
Gram grammars are couched within the linguis-
tic framework of LFG (Bresnan, 2001; Dalrymple,
2001) and are constructed with a set of grammati-
cal features that have been commonly agreed upon
within the ParGram group. ParGram grammars are
implemented using XLE, an efficient, industrial-
strength grammar development platform that in-
cludes a parser, a generator and a transfer sys-
tem (Crouch et al, 2012). XLE has been devel-
oped in close collaboration with the ParGram
project. Over the years, ParGram has continu-
ously grown and includes grammars for Ara-
bic, Chinese, English, French, German, Georgian,
Hungarian, Indonesian, Irish, Japanese, Mala-
gasy, Murrinh-Patha, Norwegian, Polish, Spanish,
Tigrinya, Turkish, Urdu, Welsh and Wolof.
ParGram grammars produce output that has
been parallelized maximally across languages ac-
cording to a set of commonly agreed upon uni-
versal proto-type analyses and feature values. This
output forms the basis of the ParGramBank paral-
lel treebank discussed here. ParGramBank is con-
structed using an innovative alignment methodol-
ogy developed in the XPAR project (Dyvik et al,
2009) in which grammar parallelism is presup-
posed to propagate alignment across different pro-
jections (section 6). This methodology has been
implemented with a drag-and-drop interface as
part of the LFG Parsebanker in the INESS infras-
tructure (Rose?n et al, 2012; Rose?n et al, 2009).
ParGramBank has been constructed in INESS and
is accessible in this infrastructure, which also of-
fers powerful search and visualization.
In recent years, parallel treebanking1 has gained
in importance within NLP. An obvious applica-
tion for parallel treebanking is machine transla-
tion, where treebank size is a deciding factor for
whether a particular treebank can support a par-
ticular kind of research project. When conduct-
ing in-depth linguistic studies of typological fea-
tures, other factors such as the number of in-
cluded languages, the number of covered phe-
nomena, and the depth of linguistic analysis be-
come more important. The treebanking effort re-
ported on in this paper supports work of the lat-
ter focus, including efforts at multilingual depen-
dency parsing (Naseem et al, 2012). We have
1Throughout this paper ?treebank? refers to both phrase-
structure resources and their natural extensions to depen-
dency and other deep annotation banks.
created a parallel treebank whose prototype in-
cludes ten typologically diverse languages and re-
flects a diverse set of phenomena. We thus present
a unique, multilayered parallel treebank that rep-
resents more languages than are currently avail-
able in other treebanks, and different types of lan-
guages as well. It contains deep linguistic knowl-
edge and allows for the parallel and simultane-
ous alignment of sentences at several levels. LFG?s
f(unctional)-structure encodes dependency struc-
tures as well as information that is equivalent to
Quasi-Logical Forms (van Genabith and Crouch,
1996). LFG?s c(onstituent)-structure provides in-
formation about constituency, hierarchical rela-
tions and part-of-speech. Currently, ParGramBank
includes structures for the following languages
(with the ISO 639-3 code and language fam-
ily): English (eng, Indo-European), Georgian (kat,
Kartvelian), German (deu, Indo-European), Hun-
garian (hun, Uralic), Indonesian (ind, Austrone-
sian), Norwegian (Bokma?l) (nob, Indo-European),
Polish (pol, Indo-European), Turkish (tur, Altaic),
Urdu (urd, Indo-European) and Wolof (wol, Niger-
Congo). It is freely available for download under
the CC-BY 3.0 license via the INESS treebanking
environment and comes in two formats: a Prolog
format and an XML format.2
This paper is structured as follows. Section
2 discusses related work in parallel treebanking.
Section 3 presents ParGram and its approach to
parallel treebanking. Section 4 focuses on the tree-
bank design and its construction. Section 5 con-
tains examples from the treebank, focusing on ty-
pological aspects and challenges for parallelism.
Section 6 elaborates on the mechanisms for paral-
lel alignment of the treebank.
2 Related Work
There have been several efforts in parallel tree-
banking across theories and annotation schemes.
Kuhn and Jellinghaus (2006) take a mini-
mal approach towards multilingual parallel tree-
banking. They bootstrap phrasal alignments over
a sentence-aligned parallel corpus of English,
French, German and Spanish and report concrete
treebank annotation work on a sample of sen-
tences from the Europarl corpus. Their annotation
2http://iness.uib.no. The treebank is in the
public domain (CC-BY 3.0). The use of the INESS platform
itself is not subject to any licensing. To access the treebank,
click on ?Treebank selection? and choose the ParGram collec-
tion.
551
scheme is the ?leanest? possible scheme in that it
consists solely of a bracketing for a sentence in
a language (where only those units that play the
role of a semantic argument or modifier in a larger
unit are bracketed) and a correspondence relation
of the constituents across languages.
Klyueva and Marec?ek (2010) present a small
parallel treebank using data and tools from two
existing treebanks. They take a syntactically an-
notated gold standard text for one language and
run an automated annotation on the parallel text
for the other language. Manually annotated Rus-
sian data are taken from the SynTagRus treebank
(Nivre et al, 2008), while tools for parsing the cor-
responding text in Czech are taken from the Tec-
toMT framework (Popel and Z?abokrtsky?, 2010).
The SMULTRON project is concerned with con-
structing a parallel treebank of English, German
and Swedish. The sentences have been POS-tagged
and annotated with phrase structure trees. These
trees have been aligned on the sentence, phrase
and word level. Additionally, the German and
Swedish monolingual treebanks contain lemma in-
formation. The treebank is distributed in TIGER-
XML format (Volk et al, 2010).
Megyesi et al (2010) discuss a parallel English-
Swedish-Turkish treebank. The sentences in each
language are annotated morphologically and syn-
tactically with automatic tools, aligned on the
sentence and the word level and partially hand-
corrected.3
A further parallel treebanking effort is Par-
TUT, a parallel treebank (Sanguinetti and Bosco,
2011; Bosco et al, 2012) which provides depen-
dency structures for Italian, English and French
and which can be converted to a CCG (Combina-
tory Categorial Grammar) format.
Closest to our work is the ParDeepBank, which
is engaged in the creation of a highly paral-
lel treebank of English, Portuguese and Bulgar-
ian. ParDeepBank is couched within the linguistic
framework of HPSG (Head-Driven Phrase Struc-
ture Grammar) and uses parallel automatic HPSG
grammars, employing the same tools and imple-
mentation strategies across languages (Flickinger
et al, 2012). The parallel treebank is aligned on
the sentence, phrase and word level.
In sum, parallel treebanks have so far fo-
cused exclusively on Indo-European languages
3The paper mentions Hindi as the fourth language, but
this is not yet available: http://stp.lingfil.uu.
se/?bea/turkiska/home-en.html.
(with Turkish providing the one exception) and
generally do not extend beyond three or four
languages. In contrast, our ParGramBank tree-
bank currently includes ten typologically differ-
ent languages from six different language families
(Altaic, Austronesian, Indo-European, Kartvelian,
Niger-Congo, Uralic).
A further point of comparison with ParDeep-
Bank is that it relies on dynamic treebanks, which
means that structures are subject to change dur-
ing the further development of the resource gram-
mars. In ParDeepBank, additional machinery is
needed to ensure correct alignment on the phrase
and word level (Flickinger et al, 2012, p. 105).
ParGramBank contains finalized analyses, struc-
tures and features that were designed collabora-
tively over more than a decade, thus guaranteeing
a high degree of stable parallelism. However, with
the methodology developed within XPAR, align-
ments can easily be recomputed from f-structure
alignments in case of grammar or feature changes,
so that we also have the flexible capability of
allowing ParGramBank to include dynamic tree-
banks.
3 ParGram and its Feature Space
The ParGram grammars use the LFG formalism
which produces c(onstituent)-structures (trees)
and f(unctional)-structures as the syntactic anal-
ysis. LFG assumes a version of Chomsky?s Uni-
versal Grammar hypothesis, namely that all lan-
guages are structured by similar underlying prin-
ciples (Chomsky, 1988; Chomsky, 1995). Within
LFG, f-structures encode a language universal
level of syntactic analysis, allowing for crosslin-
guistic parallelism at this level of abstraction. In
contrast, c-structures encode language particular
differences in linear word order, surface morpho-
logical vs. syntactic structures, and constituency
(Dalrymple, 2001). Thus, while the Chomskyan
framework is derivational in nature, LFG departs
from this view by embracing a strictly representa-
tional approach to syntax.
ParGram tests the LFG formalism for its uni-
versality and coverage limitations to see how far
parallelism can be maintained across languages.
Where possible, analyses produced by the gram-
mars for similar constructions in each language are
parallel, with the computational advantage that the
grammars can be used in similar applications and
that machine translation can be simplified.
552
The ParGram project regulates the features and
values used in its grammars. Since its inception
in 1996, ParGram has included a ?feature com-
mittee?, which collaboratively determines norms
for the use and definition of a common multilin-
gual feature and analysis space. Adherence to fea-
ture committee decisions is supported technically
by a routine that checks the grammars for com-
patibility with a feature declaration (King et al,
2005); the feature space for each grammar is in-
cluded in ParGramBank. ParGram also conducts
regular meetings to discuss constructions, analy-
ses and features.
For example, Figure 1 shows the c-structure
of the Urdu sentence in (1) and the c-structure
of its English translation. Figure 2 shows the f-
structures for the same sentences. The left/upper
c- and f-structures show the parse from the En-
glish ParGram grammar, the right/lower ones from
Urdu ParGram grammar.4,5 The c-structures en-
code linear word order and constituency and thus
look very different; e.g., the English structure is
rather hierarchical while the Urdu structure is flat
(Urdu is a free word-order language with no evi-
dence for a VP; Butt (1995)). The f-structures, in
contrast, are parallel aside from grammar-specific
characteristics such as the absence of grammati-
cal gender marking in English and the absence of
articles in Urdu.6
(1) ? Aj J
K. Q?K
QK A 	JK @ ?

	
G
	
?A??
kisAn=nE apnA
farmer.M.Sg=Erg self.M.Sg
TrEkTar bEc-A
tractor.M.Sg sell-Perf.M.Sg
?Did the farmer sell his tractor??
With parallel analyses and parallel features, maxi-
mal parallelism across typologically different lan-
guages is maintained. As a result, during the con-
struction of the treebank, post-processing and con-
version efforts are kept to a minimum.
4The Urdu ParGram grammar makes use of a translitera-
tion scheme that abstracts away from the Arabic-based script;
the transliteration scheme is detailed in Malik et al (2010).
5In the c-structures, dotted lines indicate distinct func-
tional domains; e.g., in Figure 1, the NP the farmer and the
VP sell his tractor belong to different f-structures: the former
maps onto the SUBJ f-structure, while the latter maps onto the
topmost f-structure (Dyvik et al, 2009). Section 6 elaborates
on functional domains.
6The CASE feature also varies: since English does not
distinguish between accusative, dative, and other oblique
cases, the OBJ is marked with a more general obl CASE.
Figure 1: English and Urdu c-structures
We emphasize the fact that ParGramBank is
characterized by a maximally reliable, human-
controlled and linguistically deep parallelism
across aligned sentences. Generally, the result of
automatic sentence alignment procedures are par-
allel corpora where the corresponding sentences
normally have the same purported meaning as
intended by the translator, but they do not nec-
essarily match in terms of structural expression.
In building ParGramBank, conscious attention is
paid to maintaining semantic and constructional
parallelism as much as possible. This design fea-
ture renders our treebank reliable in cases when
the constructional parallelism is reduced even at f-
structure. For example, typological variation in the
presence or absence of finite passive constructions
represents a case of potential mismatch. Hungar-
ian, one of the treebank languages, has no produc-
tive finite passives. The most common strategy in
translation is to use an active construction with a
topicalized object, with no overt subject and with
3PL verb agreement:
(2) A fa?-t ki-va?g-t-a?k.
the tree-ACC out-cut-PAST-3PL
?The tree was cut down.?
In this case, a topicalized object in Hungarian has
to be aligned with a (topical) subject in English.
Given that both the sentence level and the phrase
level alignments are human-controlled in the tree-
bank (see sections 4 and 6), the greatest possible
parallelism is reliably captured even in such cases
of relative grammatical divergence.
553
Figure 2: Parallel English and Urdu f-structures
4 Treebank Design and Construction
For the initial seeding of the treebank, we focused
on 50 sentences which were constructed manu-
ally to cover a diverse range of phenomena (tran-
sitivity, voice alternations, interrogatives, embed-
ded clauses, copula constructions, control/raising
verbs, etc.). We followed Lehmann et al (1996)
and Bender et al (2011) in using coverage of
grammatical constructions as a key component for
grammar development. (3) lists the first 16 sen-
tences of the treebank. An expansion to 100 sen-
tences is scheduled for next year.
(3) a. Declaratives:
1. The driver starts the tractor.
2. The tractor is red.
b. Interrogatives:
3. What did the farmer see?
4. Did the farmer sell his tractor?
c. Imperatives:
5. Push the button.
6. Don?t push the button.
d. Transitivity:
7. The farmer gave his neighbor an old
tractor.
8. The farmer cut the tree down.
9. The farmer groaned.
e. Passives and traditional voice:
10. My neighbor was given an old tractor
by the farmer.
11. The tree was cut down yesterday.
12. The tree had been cut down.
13. The tractor starts with a shudder.
f. Unaccusative:
14. The tractor appeared.
g. Subcategorized declaratives:
15. The boy knows the tractor is red.
16. The child thinks he started the tractor.
The sentences were translated from English
into the other treebank languages. Currently, these
languages are: English, Georgian, German, Hun-
garian, Indonesian, Norwegian (Bokma?l), Polish,
Turkish, Urdu and Wolof. The translations were
done by ParGram grammar developers (i.e., expert
linguists and native speakers).
The sentences were automatically parsed with
ParGram grammars using XLE. Since the pars-
ing was performed sentence by sentence, our re-
sulting treebank is automatically aligned at the
sentence level. The resulting c- and f-structures
were banked in a database using the LFG Parse-
banker (Rose?n et al, 2009). The structures were
disambiguated either prior to banking using XLE
or during banking with the LFG Parsebanker and
its discriminant-based disambiguation technique.
The banked analyses can be exported and down-
loaded in a Prolog format using the LFG Parse-
banker interface. Within XLE, we automatically
convert the structures to a simple XML format and
make these available via ParGramBank as well.
The Prolog format is used with applications
which use XLE to manipulate the structures, e.g.
for further semantic processing (Crouch and King,
2006) or for sentence condensation (Crouch et al,
2004).
554
5 Challenges for Parallelism
We detail some challenges in maintaining paral-
lelism across typologically distinct languages.
5.1 Complex Predicates
Some languages in ParGramBank make extensive
use of complex predicates. For example, Urdu uses
a combination of predicates to express concepts
that in languages like English are expressed with
a single verb, e.g., ?memory do? = ?remember?,
?fear come? = ?fear?. In addition, verb+verb com-
binations are used to express permissive or as-
pectual relations. The strategy within ParGram is
to abstract away from the particular surface mor-
phosyntactic expression and aim at parallelism
at the level of f-structure. That is, monoclausal
predications are analyzed via a simple f-structure
whether they consist of periphrastically formed
complex predicates (Urdu, Figure 3), a simple
verb (English, Figure 4), or a morphologically de-
rived form (Turkish, Figure 5).
In Urdu and in Turkish, the top-level PRED
is complex, indicating a composed predicate. In
Urdu, this reflects the noun-verb complex predi-
cate sTArT kar ?start do?, in Turkish it reflects a
morphological causative. Despite this morphosyn-
tactic complexity, the overall dependency struc-
ture corresponds to that of the English simple verb.
(4) ?


?
f
A

KQ ? HPA

J ? ? ? Q

 ? K
Q

K P?

J K
 @P

X
DrAIvar TrEkTar=kO
driver.M.Sg.Nom tractor.M.Sg=Acc
sTArT kartA hE
start.M.Sg do.Impf.M.Sg be.Pres.3Sg
?The driver starts the tractor.?
(5) su?ru?cu? trakto?r-u? c?al?s?-t?r-?yor
driver.Nom tractor-Acc work-Caus-Prog.3Sg
?The driver starts the tractor.?
The f-structure analysis of complex predicates
is thus similar to that of languages which do not
use complex predicates, resulting in a strong syn-
tactic parallelism at this level, even across typo-
logically diverse languages.
5.2 Negation
Negation also has varying morphosyntactic sur-
face realizations. The languages in ParGramBank
differ with respect to their negation strategies.
Languages such as English and German use inde-
pendent negation: they negate using words such as
Figure 3: Complex predicate: Urdu analysis of (4)
Figure 4: Simple predicate: English analysis of (4)
adverbs (English not, German nicht) or verbs (En-
glish do-support). Other languages employ non-
independent, morphological negation techniques;
Turkish, for instance, uses an affix on the verb, as
in (6).
555
Figure 5: Causative: Turkish analysis of (5)
(6) du?g?me-ye bas-ma
button-Dat push-Neg.Imp
?Don?t push the button.?
Within ParGram we have not abstracted away
from this surface difference. The English not in
(6) functions as an adverbial adjunct that modifies
the main verb (see top part of Figure 6) and infor-
mation would be lost if this were not represented
at f-structure. However, the same cannot be said of
the negative affix in Turkish ? the morphological
affix is not an adverbial adjunct. We have there-
fore currently analyzed morphological negation as
adding a feature to the f-structure which marks the
clause as negative, see bottom half of Figure 6.
5.3 Copula Constructions
Another challenge to parallelism comes from co-
pula constructions. An approach advocating a uni-
form treatment of copulas crosslinguistically was
advocated in the early years of ParGram (Butt et
al., 1999b), but this analysis could not do justice to
the typological variation found with copulas. Par-
GramBank reflects the typological difference with
three different analyses, with each language mak-
ing a language-specific choice among the three
possibilities that have been identified (Dalrymple
et al, 2004; Nordlinger and Sadler, 2007; Attia,
2008; Sulger, 2011; Laczko?, 2012).
The possible analyses are demonstrated here
with respect to the sentence The tractor is red.
The English grammar (Figure 7) uses a raising ap-
proach that reflects the earliest treatments of cop-
ulas in LFG (Bresnan, 1982). The copula takes
a non-finite complement whose subject is raised
to the matrix clause as a non-thematic subject of
the copula. In contrast, in Urdu (Figure 8), the
Figure 6: Different f-structural analyses for nega-
tion (English vs. Turkish)
copula is a two-place predicate, assigning SUBJ
and PREDLINK functions. The PREDLINK function
is interpreted as predicating something about the
subject. Finally, in languages like Indonesian (Fig-
ure 9), there is no overt copula and the adjective is
the main predicational element of the clause.
Figure 7: English copula example
556
Figure 8: Urdu copula example
Figure 9: Indonesian copula example
5.4 Summary
This section discussed some challenges for main-
taining parallel analyses across typologically di-
verse languages. Another challenge we face is
when no corresponding construction exists in a
language, e.g. with impersonals as in the English
It is raining. In this case, we provide a translation
and an analysis of the structure of the correspond-
ing translation, but note that the phenomenon be-
ing exemplified does not actually exist in the lan-
guage. A further extension to the capabilities of
the treebank could be the addition of pointers from
the alternative structure used in the translation to
the parallel aligned set of sentences that corre-
spond to this alternative structure.
6 Linguistically Motivated Alignment
The treebank is automatically aligned on the sen-
tence level, the top level of alignment within Par-
GramBank. For phrase-level alignments, we use
the drag-and-drop alignment tool in the LFG Parse-
banker (Dyvik et al, 2009). The tool allows the
alignment of f-structures by dragging the index
of a subsidiary source f-structure onto the index
of the corresponding target f-structure. Two f-
structures correspond if they have translationally
matching predicates, and the arguments of each
predicate correspond to an argument or adjunct in
the other f-structure. The tool automatically com-
putes the alignment of c-structure nodes on the
basis of the manually aligned corresponding f-
structures.7
7Currently we have not measured inter-annotator agree-
ment (IAA) for the f-structure alignments. The f-structure
alignments were done by only one person per language pair.
We anticipate that multiple annotators will be needed for this
This method is possible because the c-structure
to f-structure correspondence (the ? relation) is
encoded in the ParGramBank structures, allow-
ing the LFG Parsebanker tool to compute which c-
structure nodes contributed to a given f-structure
via the inverse (??1) mapping. A set of nodes
mapping to the same f-structure is called a ?func-
tional domain?. Within a source and a target
functional domain, two nodes are automatically
aligned only if they dominate corresponding word
forms. In Figure 10 the nodes in each func-
tional domain in the trees are connected by whole
lines while dotted lines connect different func-
tional domains. Within a functional domain, thick
whole lines connect the nodes that share align-
ment; for simplicity the alignment is only indi-
cated for the top nodes. The automatically com-
puted c-structural alignments are shown by the
curved lines. The alignment information is stored
as an additional layer and can be used to ex-
plore alignments at the string (word), phrase (c-
)structure, and functional (f-)structure levels.
We have so far aligned the treebank pairs
English-Urdu, English-German, English-Polish
and Norwegian-Georgian. As Figure 10 illustrates
for (7) in an English-Urdu pairing, the English ob-
ject neighbor is aligned with the Urdu indirect ob-
ject (OBJ-GO) hamsAyA ?neighbor?, while the En-
glish indirect object (OBJ-TH) tractor is aligned
with the Urdu object TrEkTar ?tractor?. The c-
structure correspondences were computed auto-
matically from the f-structure alignments.
(7) AK
X Q?K
QK A 	K @QK ?? ?
G
A???f ?

	
?K @ ?

	
G
	
?A??
kisAn=nE apnE
farmer.M.Sg=Erg self.Obl
hamsAyE=kO purAnA
neighbor.M.Sg.Obl=Acc old.M.Sg
TrEkTar di-yA
tractor.M.Sg give-Perf.M.Sg
?The farmer gave his neighbor an old tractor.?
The INESS platform additionally allows for the
highlighting of connected nodes via a mouse-over
technique. It thus provides a powerful and flexible
tool for the semi-automatic alignment and subse-
task in the future, in which case we will measure IAA for this
step.
557
Figure 10: Phrase-aligned treebank example English-Urdu: The farmer gave his neighbor an old tractor.
quent inspection of parallel treebanks which con-
tain highly complex linguistic structures.8
7 Discussion and Future Work
We have discussed the construction of ParGram-
Bank, a parallel treebank for ten typologically
different languages. The analyses in ParGram-
Bank are the output of computational LFG Par-
Gram grammars. As a result of ParGram?s cen-
trally agreed upon feature sets and prototypical
analyses, the representations are not only deep
in nature, but maximally parallel. The representa-
tions offer information about dependency relations
as well as word order, constituency and part-of-
speech.
In future ParGramBank releases, we will pro-
vide more theory-neutral dependencies along with
the LFG representations. This will take the form of
triples (King et al, 2003). We also plan to provide
a POS-tagged and a named entity marked up ver-
sion of the sentences; these will be of use for more
general NLP applications and for systems which
use such markup as input to deeper processing.
8One reviewer inquires about possibilities of linking
(semi-)automatically between languages, for example using
lexical resources such as WordNets or Panlex. We agree that
this would be desirable, but unrealizable, since many of the
languages included in ParGramBank do not have a WordNet
resource and are not likely to achieve an adequate one soon.
Third, the treebank will be expanded to include
100 more sentences within the next year. We also
plan to include more languages as other ParGram
groups contribute structures to ParGramBank.
ParGramBank, including its multilingual sen-
tences and all annotations, is made freely avail-
able for research and commercial use under the
CC-BY 3.0 license via the INESS platform, which
supports alignment methodology developed in the
XPAR project and provides search and visualiza-
tion methods for parallel treebanks. We encourage
the computational linguistics community to con-
tribute further layers of annotation, including se-
mantic (Crouch and King, 2006), abstract knowl-
edge representational (Bobrow et al, 2007), Prop-
Bank (Palmer et al, 2005), or TimeBank (Mani
and Pustejovsky, 2004) annotations.
References
Mohammed Attia. 2008. A Unified Analysis of Cop-
ula Constructions. In Proceedings of the LFG ?08
Conference, pages 89?108. CSLI Publications.
Emily M. Bender, Dan Flickinger, and Stephan Oepen.
2011. Grammar Engineering and Linguistic Hy-
pothesis Testing: Computational Support for Com-
plexity in Syntactic Analysis. In Emily M. Bender
and Jennifer E. Arnold, editors, Languages from a
Cognitive Perspective: Grammar, Usage and Pro-
cessing, pages 5?30. CSLI Publications.
558
Daniel G. Bobrow, Cleo Condoravdi, Dick Crouch,
Valeria de Paiva, Lauri Karttunen, Tracy Holloway
King, Rowan Nairn, Lottie Price, and Annie Zaenen.
2007. Precision-focused Textual Inference. In Pro-
ceedings of the ACL-PASCAL Workshop on Textual
Entailment and Paraphrasing.
Cristina Bosco, Manuela Sanguinetti, and Leonardo
Lesmo. 2012. The Parallel-TUT: a multilingual and
multiformat treebank. In Proceedings of the Eighth
International Conference on Language Resources
and Evaluation (LREC-2012), pages 1932?1938, Is-
tanbul, Turkey. European Language Resources As-
sociation (ELRA).
Joan Bresnan. 1982. The Passive in Lexical Theory. In
Joan Bresnan, editor, The Mental Representation of
Grammatical Relations, pages 3?86. The MIT Press.
Joan Bresnan. 2001. Lexical-Functional Syntax.
Blackwell Publishing.
Miriam Butt, Stefanie Dipper, Anette Frank, and
Tracy Holloway King. 1999a. Writing Large-
Scale Parallel Grammars for English, French and
German. In Proceedings of the LFG99 Conference.
CSLI Publications.
Miriam Butt, Tracy Holloway King, Mar??a-Eugenia
Nin?o, and Fre?de?rique Segond. 1999b. A Grammar
Writer?s Cookbook. CSLI Publications.
Miriam Butt, Helge Dyvik, Tracy Holloway King, Hi-
roshi Masuichi, and Christian Rohrer. 2002. The
Parallel Grammar Project. In Proceedings of the
COLING-2002 Workshop on Grammar Engineering
and Evaluation, pages 1?7.
Miriam Butt. 1995. The Structure of Complex Predi-
cates in Urdu. CSLI Publications.
Noam Chomsky. 1988. Lectures on Government and
Binding: The Pisa Lectures. Foris Publications.
Noam Chomsky. 1995. The Minimalist Program. MIT
Press.
Dick Crouch and Tracy Holloway King. 2006. Seman-
tics via F-structure Rewriting. In Proceedings of the
LFG06 Conference, pages 145?165. CSLI Publica-
tions.
Dick Crouch, Tracy Holloway King, John T. Maxwell
III, Stefan Riezler, and Annie Zaenen. 2004. Ex-
ploiting F-structure Input for Sentence Condensa-
tion. In Proceedings of the LFG04 Conference,
pages 167?187. CSLI Publications.
Dick Crouch, Mary Dalrymple, Ronald M. Kaplan,
Tracy Holloway King, John T. Maxwell III, and
Paula Newman, 2012. XLE Documentation. Palo
Alto Research Center.
Mary Dalrymple, Helge Dyvik, and Tracy Holloway
King. 2004. Copular Complements: Closed or
Open? In Proceedings of the LFG ?04 Conference,
pages 188?198. CSLI Publications.
Mary Dalrymple. 2001. Lexical Functional Gram-
mar, volume 34 of Syntax and Semantics. Academic
Press.
Helge Dyvik, Paul Meurer, Victoria Rose?n, and Koen-
raad De Smedt. 2009. Linguistically Motivated Par-
allel Parsebanks. In Proceedings of the Eighth In-
ternational Workshop on Treebanks and Linguistic
Theories (TLT8), pages 71?82, Milan, Italy. EDU-
Catt.
Dan Flickinger, Valia Kordoni, Yi Zhang, Anto?nio
Branco, Kiril Simov, Petya Osenova, Catarina Car-
valheiro, Francisco Costa, and Se?rgio Castro. 2012.
ParDeepBank: Multiple Parallel Deep Treebank-
ing. In Proceedings of the 11th International Work-
shop on Treebanks and Linguistic Theories (TLT11),
pages 97?107, Lisbon. Edic?o?es Colibri.
Tracy Holloway King, Richard Crouch, Stefan Riezler,
Mary Dalrymple, and Ronald Kaplan. 2003. The
PARC700 Dependency Bank. In Proceedings of the
EACL03: 4th International Workshop on Linguisti-
cally Interpreted Corpora (LINC-03).
Tracy Holloway King, Martin Forst, Jonas Kuhn, and
Miriam Butt. 2005. The Feature Space in Paral-
lel Grammar Writing. In Emily M. Bender, Dan
Flickinger, Frederik Fouvry, and Melanie Siegel, ed-
itors, Research on Language and Computation: Spe-
cial Issue on Shared Representation in Multilingual
Grammar Engineering, volume 3, pages 139?163.
Springer.
Natalia Klyueva and David Marec?ek. 2010. To-
wards a Parallel Czech-Russian Dependency Tree-
bank. In Proceedings of the Workshop on Anno-
tation and Exploitation of Parallel Corpora, Tartu.
Northern European Association for Language Tech-
nology (NEALT).
Jonas Kuhn and Michael Jellinghaus. 2006. Multilin-
gual Parallel Treebanking: A Lean and Flexible Ap-
proach. In Proceedings of the LREC 2006, Genoa,
Italy. ELRA/ELDA.
Tibor Laczko?. 2012. On the (Un)Bearable Lightness
of Being an LFG Style Copula in Hungarian. In Pro-
ceedings of the LFG12 Conference, pages 341?361.
CSLI Publications.
Sabine Lehmann, Stephan Oepen, Sylvie Regnier-
Prost, Klaus Netter, Veronika Lux, Judith Klein,
Kirsten Falkedal, Frederik Fouvry, Dominique Esti-
val, Eva Dauphin, Herve? Compagnion, Judith Baur,
Lorna Balkan, and Doug Arnold. 1996. TSNLP ?
Test Suites for Natural Language Processing. In
Proceedings of COLING, pages 711 ? 716.
Muhammad Kamran Malik, Tafseer Ahmed, Sebastian
Sulger, Tina Bo?gel, Atif Gulzar, Ghulam Raza, Sar-
mad Hussain, and Miriam Butt. 2010. Transliter-
ating Urdu for a Broad-Coverage Urdu/Hindi LFG
Grammar. In Proceedings of the Seventh Con-
ference on International Language Resources and
Evaluation (LREC 2010), Valletta, Malta.
559
Inderjeet Mani and James Pustejovsky. 2004. Tem-
poral Discourse Models for Narrative Structure. In
Proceedings of the 2004 ACL Workshop on Dis-
course Annotation, pages 57?64.
Bea?ta Megyesi, Bengt Dahlqvist, E?va A?. Csato?, and
Joakim Nivre. 2010. The English-Swedish-Turkish
Parallel Treebank. In Proceedings of the Seventh
International Conference on Language Resources
and Evaluation (LREC?10), Valletta, Malta. Euro-
pean Language Resources Association (ELRA).
Tahira Naseem, Regina Barzilay, and Amir Globerson.
2012. Selective Sharing for Multilingual Depen-
dency Parsing. In Proceedings of the 50th Annual
Meeting of the Association for Computational Lin-
guistics (Volume 1: Long Papers), pages 629?637,
Jeju Island, Korea, July. Association for Computa-
tional Linguistics.
Joakim Nivre, Igor Boguslavsky, and Leonid Iomdin.
2008. Parsing the SynTagRus Treebank. In Pro-
ceedings of COLING08, pages 641?648.
Rachel Nordlinger and Louisa Sadler. 2007. Verb-
less Clauses: Revealing the Structure within. In An-
nie Zaenen, Jane Simpson, Tracy Holloway King,
Jane Grimshaw, Joan Maling, and Chris Manning,
editors, Architectures, Rules and Preferences: A
Festschrift for Joan Bresnan, pages 139?160. CSLI
Publications.
Martha Palmer, Daniel Gildea, and Paul Kingsbury.
2005. The Proposition Bank: An Annotated Cor-
pus of Semantic Roles. Computational Linguistics,
31(1):71?106.
Martin Popel and Zdene?k Z?abokrtsky?. 2010. Tec-
toMT: Modular NLP Framework. In Proceedings
of the 7th International Conference on Advances in
Natural Language Processing (IceTAL 2010), pages
293?304.
Victoria Rose?n, Paul Meurer, and Koenraad de Smedt.
2009. LFG Parsebanker: A Toolkit for Building and
Searching a Treebank as a Parsed Corpus. In Pro-
ceedings of the 7th International Workshop on Tree-
banks and Linguistic Theories (TLT7), pages 127?
133, Utrecht. LOT.
Victoria Rose?n, Koenraad De Smedt, Paul Meurer, and
Helge Dyvik. 2012. An Open Infrastructure for Ad-
vanced Treebanking. In META-RESEARCH Work-
shop on Advanced Treebanking at LREC2012, pages
22?29, Istanbul, Turkey.
Manuela Sanguinetti and Cristina Bosco. 2011. Build-
ing the Multilingual TUT Parallel Treebank. In Pro-
ceedings of Recent Advances in Natural Language
Processing, pages 19?28.
Sebastian Sulger. 2011. A Parallel Analysis of have-
Type Copular Constructions in have-Less Indo-
European Languages. In Proceedings of the LFG
?11 Conference. CSLI Publications.
Josef van Genabith and Dick Crouch. 1996. Direct and
Underspecified Interpretations of LFG f-structures.
In Proceedings of the 16th International Conference
on Computational Linguistics (COLING-96), vol-
ume 1, pages 262?267, Copenhagen, Denmark.
Martin Volk, Anne Go?hring, Torsten Marek,
and Yvonne Samuelsson. 2010. SMUL-
TRON (version 3.0) ? The Stock-
holm MULtilingual parallel TReebank.
http://www.cl.uzh.ch/research/paralleltreebanks en.
html.
560
Coling 2008: Proceedings of the workshop on Grammar Engineering Across Frameworks, pages 33?40
Manchester, August 2008
Speeding up LFG Parsing Using C-Structure Pruning
Aoife Cahill? John T. Maxwell III? Paul Meurer? Christian Rohrer? Victoria Rose?n?
?IMS, University of Stuttgart, Germany, {cahillae, rohrer}@ims.uni-stuttgart.de
?Palo Alto Research Center, 3333 Coyote Hill Road, Palo Alto, CA 94304, maxwell@parc.com
?Unifob Aksis, Bergen, Norway, paul.meurer@aksis.uib.no
?Unifob Aksis and University of Bergen, Norway, victoria@uib.no
Abstract
In this paper we present a method for
greatly reducing parse times in LFG pars-
ing, while at the same time maintaining
parse accuracy. We evaluate the method-
ology on data from English, German and
Norwegian and show that the same pat-
terns hold across languages. We achieve
a speedup of 67% on the English data and
49% on the German data. On a small
amount of data for Norwegian, we achieve
a speedup of 40%, although with more
training data we expect this figure to in-
crease.
1 Introduction
Efficient parsing of large amounts of natural lan-
guage is extremely important for any real-world
application. The XLE Parsing System is a large-
scale, hand-crafted, deep, unification-based sys-
tem that processes raw text and produces both
constituent structures (phrase structure trees) and
feature structures (dependency attribute-value ma-
trices). A typical breakdown of parsing time
of XLE components with the English grammar
is Morphology (1.6%), Chart (5.8%) and Unifier
(92.6%). It is clear that the major bottleneck in
processing is in unification. Cahill et al (2007)
carried out a preliminary experiment to test the
theory that if fewer c-structures were passed to
the unifier, overall parsing times would improve,
while the accuracy of parsing would remain sta-
ble. Their experiments used state-of-the-art prob-
abilistic treebank-based parsers to automatically
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
mark certain constituents on the input sentences,
limiting the number of c-structures the XLE pars-
ing system would build. They achieved an 18%
speedup in parse times, while maintaining the ac-
curacy of the output f-structures. The experiments
presented in Cahill et al (2007) used the XLE sys-
tem as a black box and did not make any changes to
it. However, the results were encouraging enough
for a c-structure pruning mechanism to be fully in-
tegrated into the XLE system.
The paper is structured as follows: we present
the pruning model that has been integrated into the
XLE system (Section 2), and how it can be ap-
plied successfully to more than one language. We
present experiments for English (Section 3), Ger-
man (Section 4) and Norwegian (Section 5) show-
ing that for both German and English, a significant
improvement in speed is achieved, while the qual-
ity of the f-structures remains stable. For Norwe-
gian a speedup is also achieved, but more training
data is required to sustain the accuracy of the f-
structures. In Section 7 we present an error anal-
ysis on the German data. We then relate the work
presented in this paper to similar efficient parsing
strategies (Section 8) before concluding in Section
9.
2 XLE and the C-Structure Pruning
Mechanism
The XLE system is designed to deal with large
amounts of data in a robust manner. There are
several mechanisms which facilitate this, including
fragmenting and skimming. Fragmenting is called
when the grammar is unable to provide a complete
parse for the input sentence, and a fragment anal-
ysis of largest possible chunks is built. Skimming
is called when too much time or memory has been
used by XLE. Any constituents that have not been
33
fully processed are ?skimmed?, which means that
the amount of work carried out in processing the
constituent is limited. This guarantees that XLE
will finish processing the sentence in polynomial
time.
XLE uses a chart-based mechanism for build-
ing parses, and has been complemented with a c-
structure pruning mechanism to speed up parsing
time. During pruning, subtrees at a particular cell
in the chart are pruned if their probabilities are not
higher than a certain threshold. The chart pruner
uses a simple stochastic CFG model. The proba-
bility of a tree is the product of the probabilities
of each of the rules used to form the tree, includ-
ing the rules that lead to lexical items (such as N
? dog). The probability of a rule is basically the
number of times that that particular form of the
rule occurs in the training data divided by the num-
ber of times the rule?s category occurs in the train-
ing data, plus a smoothing term. This is similar
to the pruning described in Charniak and Johnson
(2005) where edges in a coarse-grained parse for-
est are pruned to allow full evaluation with fine-
grained categories.
The pruner prunes at the level of individual con-
stituents in the chart. It calculates the probabil-
ities of each of the subtrees of a constituent and
compares them. The probability of each subtree
is compared with the best subtree probability for
that constituent. If a subtree?s probability is lower
than the best probability by a given factor, then the
subtree is pruned. In practice, the threshold is the
natural logarithm of the factor used. So a value of
5 means that a subtree will be pruned if its prob-
ability is about a factor of 150 less than the best
probability.
If two different subtrees have different num-
bers of morphemes under them, then the proba-
bility model is biased towards the subtree that has
fewer morphemes (since there are fewer probabil-
ities multiplied together). XLE counteracts this by
normalizing the probabilities based on the differ-
ence in length.
To illustrate how this works, we give the follow-
ing example. The string Fruit flies like bananas has
two different analyses. Figures 1 and 2 give their
analyses along with hypothetical probabilities for
each rule.
These two analyses come together at the S con-
stituent that spans the whole sentence. The proba-
bility of the first analysis is 8.4375E-14. The prob-
S
NP
N
Fruit
N
flies
VP
V
like
NP
N
bananas
S ? NP VP 0.5000
NP ? N N 0.1500
N ? Fruit 0.0010
N ? flies 0.0015
VP ? V NP 0.2000
V ? like 0.0050
NP ? N 0.5000
N ? bananas 0.0015
8.4375E-14
Figure 1: Analysis (1) for the string Fruit flies like
bananas with hypothetical probabilities
S
NP
N
Fruit
VP
V
flies
PP
P
like
NP
N
bananas
S ? NP VP 0.5000
NP ? N 0.5000
N ? Fruit 0.0010
V ? flies 0.0025
VP ? V PP 0.1000
P ? like 0.0500
PP ? P NP 0.9000
NP ? bananas 0.0015
4.21875E-12
Figure 2: Analysis (2) for the string Fruit flies like
bananas with hypothetical probabilities
ability of the second analysis is 4.21875E-12. This
means that the probability of the second analysis
is 50 times higher than the probability of the first
analysis. If the threshold is less than the natural
logarithm of 50 (about 3.9), then the subtree of the
first analysis will be pruned from the S constituent.
3 Experiments on English
We carried out a number of parsing experiments to
test the effect of c-structure pruning, both in terms
of time and accuracy. We trained the c-structure
pruning algorithm on the standard sections of Penn
Treebank Wall Street Journal Text (Marcus et al,
1994). The training data consists of the original
WSJ strings, marked up with some of the Penn
34
Treebank constituent information. We marked up
NPs and SBARs as well as adjective and verbal
POS categories. This is meant to guide the train-
ing process, so that it does learn from parses that
are not compatible with the original treebank anal-
ysis. We evaluated against the PARC 700 Depen-
dency Bank (King et al, 2003), splitting it into 140
sentences as development data and the remaining
unseen 560 for final testing (as in Kaplan et al
(2004)). We experimented with different values
of the pruning cutoff on the development set; the
results are given in Table 1.
The results show that the lower the cutoff value,
the quicker the sentences can be parsed. Using
a cutoff of 4, the development sentences can be
parsed in 100 CPU seconds, while with a cutoff
of 10, the same experiment takes 182 seconds.
With no cutoff, the experiment takes 288 CPU sec-
onds. However, this increase in speed comes at a
price. The number of fragment parses increases,
i.e. there are more sentences that fail to be analyzed
with a complete spanning parse. With no pruning,
the number of fragment parses is 23, while with
the most aggressive pruning factor of 4, there are
39 fragment parses. There are also many more
skimmed sentences with no c-structure pruning,
which impacts negatively on the results. The ora-
cle f-score with no pruning is 83.07, but with prun-
ing (at all thresholds) the oracle f-score is higher.
This is due to less skimming when pruning is acti-
vated, since the more subtrees that are pruned, the
less likely the XLE system is to run over the time
or memory limits needed to trigger skimming.
Having established that a cutoff of 5 performs
best on the development data, we carried out the
final evaluation on the 560-sentence test set using
this cutoff. The results are given in Table 2. There
is a 67% speedup in parsing the 560 sentences, and
the most probable f-score increases significantly
from 79.93 to 82.83. The oracle f-score also in-
creases, while there is a decrease in the random f-
score. This shows that we are throwing away good
solutions during pruning, but that overall the re-
sults improve. Part of this again is due to the fact
that with no pruning, skimming is triggered much
more often. With a pruning factor of 5, there are
no skimmed sentences. There is also one sentence
that timed out with no pruning, which also lowers
the most probable and oracle f-scores.
Pruning Level None 5
Total Time 1204 392
Most Probable F-Score 79.93 82.83
Oracle F-Score 84.75 87.79
Random F-Score 75.47 74.31
# Fragment Parses 96 91
# Time Outs 1 0
# Skimmed Sents 33 0
Table 2: Results of c-structure pruning experi-
ments on English test data
4 Experiments on German
We carried out a similar set of experiments on
German data to test whether the methodology de-
scribed above ported to a language other than En-
glish. In the case of German, the typical time of
XLE components is: Morphology (22.5%), Chart
(3.5%) and Unifier (74%). As training data we
used the TIGER corpus (Brants et al, 2002). Set-
ting aside 2000 sentences for development and
testing, we used the remaining 48,474 sentences as
training data. In order to create the partially brack-
eted input required for training, we converted the
original TIGER graphs into Penn-style trees with
empty nodes and retained bracketed constituents of
the type NP, S, PN and AP. The training data was
parsed by the German ParGram LFG (Rohrer and
Forst, 2006). This resulted in 25,677 full parses,
21,279 fragmented parses and 1,518 parse fail-
ures.1 There are 52,959 features in the final prun-
ing model.
To establish the optimal pruning settings for
German, we split the 2,000 saved sentences into
371 development sentences and 1495 test sen-
tences for final evaluation. We evaluated against
the TiGer Dependency Bank (Forst et al, 2004)
(TiGerDB), a dependency-based gold standard for
German parsers that encodes grammatical rela-
tions similar to, though more fine-grained than,
the ones in the TIGER Treebank as well as mor-
phosyntactic features. We experimented with the
same pruning levels as in the English experiments.
The results are given in Table 3.
The results on the development set show a sim-
ilar trend to the English results. A cutoff of 4 re-
sults in the fastest system, however at the expense
1The reason there are more fragment parses than, for ex-
ample, the results reported in Rohrer and Forst (2006) is that
the bracketed input constrains the parser to only return parses
compatible with the bracketed input. If there is no solution
compatible with the brackets, then a fragment parse is re-
turned.
35
Pruning Level None 4 5 6 7 8 9 10
Oracle F-Score 83.07 84.50 85.47 85.75 85.57 85.57 85.02 84.10
Time (CPU seconds) 288 100 109 123 132 151 156 182
# Time Outs 0 0 0 0 0 0 0
# Fragments 23 39 36 31 29 27 27 24
# Skimmed Sents 8 0 0 1 1 1 1 3
Table 1: Results of c-structure pruning experiments on English development data
Pruning Level None 4 5 6 7 8 9 10
Oracle F-Score 83.69 83.45 84.02 82.86 82.82 82.95 83.03 82.81
Time (CPU seconds) 1313 331 465 871 962 1151 1168 1163
# Time Outs 6 0 0 5 5 5 5 6
# Fragments 65 104 93 81 74 73 73 68
Table 3: Results of c-structure pruning experiments on German development data
Pruning Level None 5
Total Time 3300 1655
Most Probable F-Score 82.63 82.73
Oracle F-Score 84.96 84.79
Random F-Score 73.58 73.72
# Fragment Parses 324 381
# Time Outs 2 2
Table 4: Results of c-structure pruning experi-
ments on German test data
of accuracy. A cutoff of 5 seems to provide the
best tradeoff between time and accuracy. Again,
most of the gain in oracle f-score is due to fewer
timeouts, rather than improved f-structures. In the
German development set, a cutoff of 5 leads to a
speedup of over 64% and a small increase in or-
acle f-score of 0.33 points. Therefore, for the fi-
nal evaluation on the unseen test-set, we choose a
cutoff of 5. The results are given in Table 4. We
achieve a speedup of 49% and a non-significant in-
crease in most probable f-score of 0.094. The time
spent by the system on morphology is much higher
for German than for English. If we only take the
unification stage of the process into account, the
German experiments show a speedup of 65.5%.
5 Experiments on Norwegian
As there is no treebank currently available for Nor-
wegian, we were unable to train the c-structure
pruning mechanism for Norwegian in the same
way as was done for English and German. There
is, however, some LFG-parsed data that has been
completely disambiguated using the techniques
described in Rose?n et al (2006). In total there
are 937 sentences from various text genres includ-
ing Norwegian hiking guides, Sophie?s World and
the Norwegian Wikipedia. We also use this dis-
ambiguated data as a gold standard for evaluation.
The typical time of XLE components with the Nor-
wegian grammar is: Morphology (1.6%), Chart
(11.2%) and Unifier (87.2%).
From the disambiguated text, we can automati-
cally extract partially bracketed sentences as input
to the c-structure pruning training method. We can
also extract sentences for training that are partially
disambiguated, but these cannot be used as part of
the test data. To do this, we extract the bracketed
string for each solution. If all the solutions pro-
duce the same bracketed string, then this is added
to the training data. This results in an average of
4556 features. As the data set is small, we do not
split it into development, training and test sections
as was done for English and German. Instead we
carry out a 10-fold cross validation over the entire
set. The results for each pruning level are given in
Table 5.
The results in Table 5 show that the pattern that
held for English and German does not quite hold
for Norwegian. While, as expected, the time taken
to parse the test set is greatly reduced when using
c-structure pruning, there is also a negative impact
on the quality of the f-structures. One reason for
this is that there are now sentences that could pre-
viously be parsed, and that now no longer can be
parsed, even with a fragment grammar.2 With c-
structure pruning, the number of fragment parses
increases for all thresholds, apart from 10. It is
also difficult to compare the Norwegian experi-
ment to the English and German, since the gold
standard is constrained to only consist of sentences
that can be parsed by the grammar. Theoretically
the oracle f-score for the experiment with no prun-
2With an extended fragment grammar, this would not hap-
pen.
36
Pruning Level None 4 5 6 7 8 9 10
Oracle F-Score 98.76 94.45 95.60 96.40 96.90 97.52 98.00 98.33
Time (CPU seconds) 218.8 106.2 107.4 109.3 112 116.2 124 130.7
# Time Outs 0 0 0 0 0 0 0 0
# Parse Failures 0.2 5.7 3.9 2 3.2 4.2 4.6 4.2
# Fragments 1.3 7.7 6.5 4.7 2.8 1.8 1.5 1.2
Table 5: Results of c-structure pruning 10-fold cross validation experiments on Norwegian data
55
60
65
70
75
80
85
90
95
None 4 5 6 7 8 9 10
Figure 3: The lower-bound results for each of the
10 cross validation runs across the thresholds
ing should be 100. The slight drop is due to a
slightly different morphological analyzer used in
the final experiments that treats compound nouns
differently. A threshold of 10 gives the best results,
with a speedup of 40% and a drop in f-score of 0.43
points. It is difficult to choose the ?best? thresh-
old, as the amount of training data is probably not
enough to get an accurate picture of the data. For
example, Figure 3 shows the lower-bound results
for each of the 10 runs. It is difficult to see a clear
pattern for all the runs, indicating that the amount
of training data is probably not enough for a reli-
able experiment.
6 Size of Training Data Corpus
The size of the Norwegian training corpus is con-
siderably smaller than the training corpora for En-
glish or German, so the question remains how
much training data we need in order for the c-
structure pruning to deliver reliable results. In or-
der to establish a rough estimate for the size of
training corpus required, we carried out an experi-
ment on the German TIGER training corpus.
We randomly divided the TIGER training cor-
pus into sets of 500 sentences. We plot the learn-
ing curve of the c-structure pruning mechanism in
Figure 4, examining the effect of increasing the
size of the training corpus on the oracle f-score on
the development set of 371 sentences. The curve
shows that, for the German data, the highest oracle
f-score of 84.98 was achieved with a training cor-
pus of 32,000 sentences. Although the curve fluc-
tuates, the general trend is that the more training
data, the better the oracle f-score.3
7 Error Analysis
Given that we are removing some subtrees during
parsing, it can sometimes happen that the desired
analysis gets pruned. We will take German as an
example, and look at some of these cases.
7.1 Separable particles vs pronominal
adverbs
The word dagegen (?against it?) can be a separable
prefix (VPART) or a pronominal adverb (PADV).
The verb protestieren (?to protest?) does not take
dagegen as separable prefix. The verb stimmen
(?to agree?) however does. If we parse the sen-
tence in (1) with the verb protestieren and activate
pruning, we do not get a complete parse. If we
parse the same sentence with stimmen as in (2) we
do get a complete parse. If we replace dagegen
by dafu?r, which in the current version of the Ger-
man LFG can only be a pronominal adverb, the
sentence in (3) gets a parse. We also notice that
if we parse a sentence, as in (4), where dagegen
occurs in a position where our grammar does not
allow separable prefixes to occur, we get a com-
plete parse for the sentence. These examples show
that the pruning mechanism has learned to prune
the separable prefix reading of words that can be
both separable prefixes and pronominal adverbs.
(1) Sie
they
protestieren
protest
dagegen.
against-it
?They protest against it.?
(2) Sie
they
stimmen
vote
dagegen.
against-it
?They vote against it.?
3Unexpectedly, the curve begins to decline after 32,000
sentences. However, the differences in f-score are not statis-
tically significant (using the approximate randomization test).
Running the same experiment with a different random seed
results in a similarly shaped graph, but any decline in f-score
when training on more data was not statistically significant at
the 99% level.
37
32000, 84.97698
84
84.1
84.2
84.3
84.4
84.5
84.6
84.7
84.8
84.9
85
50
0
20
00
35
00
50
00
65
00
80
00
95
00
11
00
0
12
50
0
14
00
0
15
50
0
17
00
0
18
50
0
20
00
0
21
50
0
23
00
0
24
50
0
26
00
0
27
50
0
29
00
0
30
50
0
32
00
0
33
50
0
35
00
0
36
50
0
38
00
0
39
50
0
41
00
0
42
50
0
44
00
0
45
50
0
47
00
0
48
50
0
Number of Training Sentences
F-
Sc
o
re
Figure 4: The effect of increasing the size of the training data on the oracle f-score
(3) Er
he
protestiert
protests
dafu?r.
for-it
?He protests in favour of it.?
(4) Dagegen
against-it
protestiert
protests
er.
he
?Against it, he protests.?
7.2 Derived nominal vs non-derived nominal
The word Morden can be the dative plural of the
noun Mord (?murder?) or the nominalized form of
the verb morden (?to murder?). With c-structure
pruning activated (at level 5), the nominalized
reading, as in (6), gets pruned, whereas the dative
plural reading is not (5). At pruning level 6, both
readings are assigned a full parse. We see simi-
lar pruning of nominalized readings as in (7). If
we look in more detail at the raw counts for re-
lated subtrees gathered from the training data, we
see that the common noun reading for Morden oc-
curs 156 times, while the nominalized reading only
occurs three times. With more training data, the c-
structure pruning mechanism could possibly learn
when to prune correctly in such cases.
(5) Er
he
redet
speaks
von
of
Morden.
murders
?He speaks of murders.?
(6) Das
the
Morden
murdering
will
wants
nicht
not
enden.
end
?The murdering does not want to end.?
(7) Das
the
Arbeiten
working
endet.
ends
?The operation ends.?
7.3 Personal pronouns which also function as
determiners
There are a number of words in German that can
function both as personal pronouns and determin-
ers. If we take, for example, the word ihr, which
can mean ?her?, ?their?, ?to-her?, ?you-pl? etc.,
the reading as a determiner gets pruned as well as
some occurrences as a pronoun. In example (8),
we get a complete parse for the sentence with the
dative pronoun reading of ihr. However, in ex-
ample (9), the determiner reading is pruned and
we fail to get a complete parse. In example (10),
we also fail to get a complete parse, but in exam-
ple (11), we do get a complete parse. There is a
parameter we can set that sets a confidence value
in certain tags. So, for example, we set the con-
fidence value of INFL-F BASE[det] (the tag given
to the determiner reading of personal pronouns) to
be 0.5, which says that we are 50% confident that
the tag INFL-F BASE[det] is correct. This results in
38
examples 8, 9 and 11 receiving a complete parse,
with the pruning threshold set to 5.
(8) Er
he
gibt
gives
es
it
ihr.
her
?He gives it to her.?
(9) Ihr
her/their
Auto
car
fa?hrt.
drives
?Her/Their car drives.
(10) Ihr
you(pl)
kommt.
come
?You come.?
(11) Er
he
vertraut
trusts
ihr.
her
?He trusts her.?
7.4 Coordination of Proper Nouns
Training the German c-structure pruning mecha-
nism on the TIGER treebank resulted in a pecu-
liar phenomenon when parsing coordinated proper
nouns. If we parse four coordinated proper nouns
with c-structure pruning activated as in (12), we
get a complete parse. However, as soon as we add
a fifth proper noun as in (13), we get a fragment
parse. This is only the case with proper nouns,
since the sentence in (14) which coordinates com-
mon nouns gets a complete parse. Interestingly, if
we coordinate n proper nouns plus one common
noun, we also get a complete parse. The reason for
this is that proper noun coordination is less com-
mon than common noun coordination in our train-
ing set.
(12) Hans, Fritz, Emil und Maria singen.
?Hans, Fritz, Emil and Maria sing.?
(13) Hans, Fritz, Emil, Walter und Maria sin-
gen.
?Hans, Fritz, Emil, Walter and Maria sing.?
(14) Hunde, Katzen, Esel, Pferde und Affen
kommen.
?Dogs, cats, donkeys, horses and apes
come.?
(15) Hans, Fritz, Emil, Walter, Maria und
Kinder singen.
?Hans, Fritz, Emil, Walter, Maria and chil-
dren sing.?
We ran a further experiment to test what effect
adding targeted training data had on c-structure
pruning. We automatically extracted a specialized
corpus of 31,845 sentences from the Huge Ger-
man Corpus. This corpus is a collection of 200
million words of newspaper and other text. The
sentences we extracted all contained examples of
proper noun coordination and had been automati-
cally chunked. Training on this sub-corpus as well
as the original TIGER training data did have the
desired effect of now parsing example (13) with
c-structure pruning activated.
8 Related Work
Ninomiya et al (2005) investigate beam threshold-
ing based on the local width to improve the speed
of a probabilistic HPSG parser. In each cell of a
CYK chart, the method keeps only a portion of the
edges which have higher figure of merits compared
to the other edges in the same cell. In particular,
each cell keeps the edges whose figure of merit is
greater than ?
max
- ?, where ?
max
is the high-
est figure of merit among the edges in the chart.
The term ?beam thresholding? is a little confusing,
since a beam search is not necessary ? instead, the
CYK chart is pruned directly. For this reason, we
prefer the term ?chart pruning? instead.
Clark and Curran (2007) describe the use of
a supertagger with a CCG parser. A supertag-
ger is like a tagger but with subcategorization in-
formation included. Chart pruners and supertag-
gers are conceptually complementary, since chart
pruners prune edges with the same span and the
same category, whereas supertaggers prune (lexi-
cal) edges with the same span and different cate-
gories. Ninomiya et al (2005) showed that com-
bining a chunk parser with beam thresholding pro-
duced better results than either technique alone. So
adding a supertagger should improve the results
described in this paper.
Zhang et al (2007) describe a technique to
selectively unpack an HPSG parse forest to ap-
ply maximum entropy features and get the n-best
parses. XLE already does something similar when
it applies maximum entropy features to get the
n-best feature structures after having obtained a
packed representation of all of the valid feature
structures. The current paper shows that pruning
the c-structure chart before doing (packed) unifica-
tion speeds up the process of getting a packed rep-
resentation of all the valid feature structures (ex-
cept the ones that may have been pruned).
39
9 Conclusions
In this paper we have presented a c-structure prun-
ing mechanism which has been integrated into the
XLE LFG parsing system. By pruning the number
of c-structures built in the chart, the next stage of
processing, the unifier, has considerably less work
to do. This results in a speedup of 67% for En-
glish, 49% for German and 40% for Norwegian.
The amount of training data for Norwegian was
much less than that for English or German, there-
fore further work is required to fully investigate
the effect of c-structure pruning. However, the re-
sults, even from the small training data, were en-
couraging and show the same general patterns as
English and German. We showed that for the Ger-
man training data, 32,000 sentences was the opti-
mal number in order to achieve the highest oracle
f-score. There remains some work to be done in
tuning the parameters for the c-structure pruning,
as our error analysis shows. Of course, with sta-
tistical methods one can never be guaranteed that
the correct parse will be produced; however we can
adjust the parameters to account for known prob-
lems. We have shown that the c-structure pruning
mechanism described is an efficient way of reduc-
ing parse times, while maintaining the accuracy of
the overall system.
Acknowledgements
The work presented in this paper was supported
by the COINS project as part of the linguistic
Collaborative Research Centre (SFB 732) at the
University of Stuttgart and by the Norwegian Re-
search Council through the LOGON and TREPIL
projects.
References
Brants, Sabine, Stefanie Dipper, Silvia Hansen, Wolf-
gang Lezius, and George Smith. 2002. The TIGER
Treebank. In Proceedings of the Workshop on Tree-
banks and Linguistic Theories, Sozopol, Bulgaria.
Cahill, Aoife, Tracy Holloway King, and John T.
Maxwell III. 2007. Pruning the Search Space of
a Hand-Crafted Parsing System with a Probabilistic
Parser. In ACL 2007 Workshop on Deep Linguistic
Processing, pages 65?72, Prague, Czech Republic,
June. Association for Computational Linguistics.
Charniak, Eugene and Mark Johnson. 2005. Coarse-
to-Fine n-Best Parsing and MaxEnt Discriminative
Reranking. In Proceedings of the 43rd Annual Meet-
ing of the Association for Computational Linguis-
tics (ACL?05), pages 173?180, Ann Arbor, Michi-
gan, June. Association for Computational Linguis-
tics.
Clark, Stephen and James R. Curran. 2007. Wide-
Coverage Efficient Statistical Parsing with CCG and
Log-Linear Models. Computational Linguistics,
33(4):493?552.
Forst, Martin, Nu?ria Bertomeu, Berthold Crysmann,
Frederik Fouvry, Silvia Hansen-Schirra, and Valia
Kordoni. 2004. Towards a dependency-based gold
standard for German parsers ? The TiGer Depen-
dency Bank. In Proceedings of the COLING Work-
shop on Linguistically Interpreted Corpora (LINC
?04), Geneva, Switzerland.
Kaplan, Ronald M., John T. Maxwell, Tracy H. King,
and Richard Crouch. 2004. Integrating Finite-state
Technology with Deep LFG Grammars. In Pro-
ceedings of the ESSLLI 2004 Workshop on Combin-
ing Shallow and Deep Processing for NLP, Nancy,
France.
King, Tracy Holloway, Richard Crouch, Stefan Riezler,
Mary Dalrymple, and Ronald M. Kaplan. 2003. The
PARC 700 Dependency Bank. In Proceedings of the
EACL Workshop on Linguistically Interpreted Cor-
pora (LINC ?03), Budapest, Hungary.
Marcus, Mitchell P., Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1994. Building a Large Annotated
Corpus of English: The Penn Treebank. Computa-
tional Linguistics, 19(2):313?330.
Ninomiya, Takashi, Yoshimasa Tsuruoka, Yusuke
Miyao, and Jun?ichi Tsujii. 2005. Efficacy of Beam
Thresholding, Unification Filtering and Hybrid Pars-
ing in Probabilistic HPSG Parsing. In Proceed-
ings of the Ninth International Workshop on Pars-
ing Technology, pages 103?114, Vancouver, British
Columbia, October. Association for Computational
Linguistics.
Rohrer, Christian and Martin Forst. 2006. Improving
Coverage and Parsing Quality of a Large-scale LFG
for German. In Proceedings of the Language Re-
sources and Evaluation Conference (LREC-2006),
Genoa, Italy.
Rose?n, Victoria, Paul Meurer, and Koenraad de Smedt.
2006. Towards a Toolkit Linking Treebanking and
Grammar Development. In Hajic, Jan and Joakim
Nivre, editors, Proceedings of the Fifth Workshop
on Treebanks and Linguistic Theories, pages 55?66,
December.
Zhang, Yi, Stephan Oepen, and John Carroll. 2007.
Efficiency in Unification-Based N-Best Parsing. In
Proceedings of the Tenth International Conference
on Parsing Technologies, pages 48?59, Prague,
Czech Republic, June. Association for Computa-
tional Linguistics.
40
