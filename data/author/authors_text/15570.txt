Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1377?1381,
Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational Linguistics
Improving Statistical Machine Translation with Word Class Models
Joern Wuebker, Stephan Peitz, Felix Rietig and Hermann Ney
Human Language Technology and Pattern Recognition Group
RWTH Aachen University
Aachen, Germany
<surname>@cs.rwth-aachen.de
Abstract
Automatically clustering words from a mono-
lingual or bilingual training corpus into
classes is a widely used technique in statisti-
cal natural language processing. We present
a very simple and easy to implement method
for using these word classes to improve trans-
lation quality. It can be applied across differ-
ent machine translation paradigms and with
arbitrary types of models. We show its ef-
ficacy on a small German?English and a
larger French?German translation task with
both standard phrase-based and hierarchical
phrase-based translation systems for a com-
mon set of models. Our results show that with
word class models, the baseline can be im-
proved by up to 1.4% BLEU and 1.0% TER
on the French?German task and 0.3% BLEU
and 1.1% TER on the German?English task.
1 Introduction
Data sparsity is one of the major problems for statis-
tical learning methods in natural language process-
ing (NLP) today. Even with the huge training data
sets available in some tasks, for many phenomena
that need to be modeled only few training instances
can be observed. This is partly due to the large vo-
cabularies of natural languages. One possiblity to
reduce the sparsity for model estimation is to re-
duce the vocabulary size. By clustering the vocab-
ulary into a fixed number of word classes, it is pos-
sible to train models that are less prone to sparsity
issues. This work investigates the performance of
standard models used in statistical machine transla-
tion when they are trained on automatically learned
word classes rather than the actual word identities.
In the popular tooklit GIZA++ (Och and Ney,
2003), word classes are an essential ingredient to
model alignment probabilities with the HMM or
IBM translation models. It contains the mkcls tool
(Och, 1999), which can automatically cluster the vo-
cabulary into classes.
Using this tool, we propose to re-parameterize the
standard models used in statistical machine transla-
tion (SMT), which are usually conditioned on word
identities rather than word classes. The idea is that
this should lead to a smoother distribution, which
is more reliable due to less sparsity. Here, we fo-
cus on the phrase-based and lexical channel models
in both directions, simple count models identifying
frequency thresholds, lexicalized reordering models
and an n-gram language model. Although our re-
sults show that it is not a good idea to replace the
original models, we argue that adding them to the
log-linear feature combination can improve transla-
tion quality. They can easily be computed for dif-
ferent translation paradigms and arbitrary models.
Training and decoding is possible without or with
only little change to the code base.
Our experiments are conducted on a medium-
sized French?German task and a small
German?English task and with both phrase-
based and hierarchical phrase-based translation
decoders. By using word class models, we can
improve our respective baselines by 1.4% BLEU and
1.0% TER on the French?German task and 0.3%
BLEU and 1.1% TER on the German?English task.
Training an additional language model for trans-
1377
lation based on word classes has been proposed in
(Wuebker et al, 2012; Mediani et al, 2012; Koehn
and Hoang, 2007). In addition to the reduced spar-
sity, an advantage of the smaller vocabulary is that
longer n-gram context can be modeled efficiently.
Mathematically, our idea is equivalent to a special
case of the Factored Translation Models proposed
by Koehn and Hoang (2007). We will go into more
detail in Section 4. Also related to our work, Cherry
(2013) proposes to parameterize a hierarchical re-
ordering model with sparse features that are condi-
tioned on word classes trained with mkcls. How-
ever, the features are trained with MIRA rather than
estimated by relative frequencies.
2 Word Class Models
2.1 Standard Models
The translation model of most phrase-based and hi-
erarchical phrase-based SMT systems is parameter-
ized by two phrasal and two lexical channel models
(Koehn et al, 2003) which are estimated as relative
frequencies. Their counts are extracted heuristically
from a word aligned bilingual training corpus.
In addition to the four channel models, our base-
line contains binary count features that fire, if the
extraction count of the corresponding phrase pair is
greater or equal to a given threshold ? . We use the
thresholds ? = {2, 3, 4}.
Our phrase-based baseline contains the hierarchi-
cal reordering model (HRM) described by Galley
and Manning (2008). Similar to (Cherry et al,
2012), we apply it in both translation directions
with separate scaling factors for the three orientation
classes, leading to a total of six feature weights.
An n-gram language model (LM) is another im-
portant feature of our translation systems. The
baselines apply 4-gram LMs trained by the SRILM
toolkit (Stolcke, 2002) with interpolated modified
Kneser-Ney smoothing (Chen and Goodman, 1998).
The smaller vocabulary size allows us to efficiently
model larger context, so in addition to the 4-gram
LM, we also train a 7-gram LM based on word
classes. In contrast to an LM of the same size trained
on word identities, the increase in computational re-
sources needed for translation is negligible for the
7-gram word class LM (wcLM).
2.2 Training
By replacing the words on both source and target
side of the training data with their respective word
classes and keeping the word alignment unchanged,
all of the above models can easily be trained con-
ditioned on word classes by using the same training
procedure as usual. We end up with two separate
model files, usually in the form of large tables, one
with word identities and one with classes. Next, we
sort both tables by their word classes. By walking
through both sorted tables simultaneously, we can
then efficiently augment the standard model file with
an additonal feature (or additional features) based on
word classes. The word class LM is directly passed
on to the decoder.
2.3 Decoding
The decoder searches for the best translation given
a set of models hm(eI1, s
K
1 , f
J
1 ) by maximizing the
log-linear feature score (Och and Ney, 2004):
e?I?1 = argmax
I,eI1
{
M?
m=1
?mhm(e
I
1, s
K
1 , f
J
1 )
}
, (1)
where fJ1 = f1 . . . fJ is the source sentence, e
I
1 =
e1 . . . eI the target sentence and sK1 = s1 . . . sK the
hidden alignment or derivation.
All the above mentioned models can easily be in-
tegrated into this framework as additional features
hm. The feature weights ?m are tuned with mini-
mum error rate training (MERT) (Och, 2003).
3 Experiments
3.1 Data
Our experiments are performed on a
French?German task. In addition to some
project-internal data, we train the system on the data
provided for the WMT 2012 shared task1. Both the
dev and the test set are composed of a mixture
of broadcast news and broadcast conversations
crawled from the web and have two references.
Table 1 shows the data statistics.
To confirm our results we also run experiments
on the German?English task of the IWSLT 2012
evaluation campaign2.
1http://www.statmt.org/wmt12/
2http://hltc.cs.ust.hk/iwslt/
1378
French German
train Sentences 1.9M
Running Words 57M 50M
dev Sentences 1900
Running Words 61K 55K
test Sentences 2037
Running Words 60K 54K
Table 1: Corpus statistics for the French?German task.
The running word counts for the German side of dev and
test are averaged over both references.
3.2 Setup
In the French?German task, our baseline is a stan-
dard phrase-based system augmented with the hier-
archical reordering model (HRM) described in Sec-
tion 2.1. The language model is a 4-gram LM
trained on all German monolingual sources provided
for WMT 2012. For the class-based models, we
run mkcls on the source and target side of the
bilingual training data to cluster the vocabulary into
100 classes each. This clustering is used to train
the models described above for word classes on the
same training data as their counterparts based on
word identity. This also holds for the wcLM, which
is a 4-gram LM trained on the same data as the base-
line LM. Further, the smaller vocabulary allows us
to build an additional wcLM with a 7-gram context
length. On this task we also run additional experi-
ments with 200 and 500 classes.
On the German?English task, we evaluate our
method for both a standard phrase-based and the hi-
erarchical phrase-based baseline. Again, the phrase-
based baseline contains the HRM model. As bilin-
gual training data we use the TED talks, which we
cluster into 100 classes on both source and target
side. The 4-gram LM is trained on the TED, Eu-
roparl and news-commentary corpora. On this data
set, we directly use a 7-gram wcLM.
In all setups, the feature weights are optimized
with MERT. Results are reported in BLEU (Pap-
ineni et al, 2002) and TER (Snover et al, 2006),
confidence level computation is based on (Koehn,
2004). Our experiments are conducted with the open
source toolkit Jane (Wuebker et al, 2012; Vilar et
al., 2010).
dev test
BLEU TER BLEU TER
[%] [%] [%] [%]
-TM +wcTM 21.2 64.2 24.7 59.5
-LM +wcLM 22.2 62.9 25.9 58.9
-HRM +wcHRM 24.6 61.9 27.5 58.1
phrase-based 24.6 61.8 27.8 57.6
+ wcTM 24.7 61.4 28.1 57.1
+ wcLM 24.9 61.2 28.4 57.1
+ wcHRM 25.4? 60.9? 28.9? 56.9?
+ wcLM7 25.5? 60.7? 29.2? 56.6?
+ wcModels200 25.5? 60.8? 29.3? 56.4?
+ wcModels500 25.2? 60.8? 29.0? 56.6?
Table 2: BLEU and TER results on the French?German
task. Results marked with ? are statistically significant
with 95% confidence, results marked with ? with 90%
confidence. -X +wcX denote the systems, where the
model X in the baseline is replaced by its word class
counterpart. The 7-gram word class LM is denoted
as wcLM7. wcModelsX denotes all word class models
trained on X classes.
3.3 Results
Results for the French?German task are given in
Table 2. In a first set of experiments we replaced one
of the standard TM, LM and HRM models by the
same model based on word classes. Unsurprisingly,
this degrades performance with different levels of
severity. The strongest degradation can be seen
when replacing the TM, while replacing the HRM
only leads to a small drop in performance. However,
when the word class models are added as additional
features to the baseline, we observe improvements.
The wcTM yields 0.3% BLEU and 0.5% TER on
test. By adding the 4-gram wcLM, we get another
0.3% BLEU and the wcHRM shows further improve-
ments of 0.5% BLEU and 0.2% TER. Extending the
context length of the wcLM to 7-grams gives an ad-
ditional boost, reaching a total gain over the baseline
of 1.4% BLEU and 1.0% TER. Using 200 classes
instead of 100 seems to perform slightly better on
test, but with 500 classes, translation quality de-
grades again.
On the German?English task, the results shown
in Table 3 are similar in TER, but less pronounced
in BLEU. Here we are able to improve over the
phrase-based baseline by 0.3% BLEU and 1.1% TER
1379
dev test
BLEU TER BLEU TER
[%] [%] [%] [%]
phrase-based 30.2 49.6 28.6 51.6
+ wcTM 30.2 49.2 28.9 51.3
+ wcLM7 30.5 48.3? 29.0 50.6?
+ wcHRM 30.8 48.3? 28.9 50.5?
hiero 29.6 50.3 27.9 52.5
+ wcTM 29.8 50.3 28.1 52.3
+ wcLM7 30.0 49.8 28.2 51.7
Table 3: BLEU and TER results on the German?English
task. Results marked with ? are statistically significant
with 95% confidence, results marked with ? with 90%
confidence.
by adding the wcTM, the 7-gram wcLM and the
wcHRM. With the hierarchical decoder we gain
0.3% BLEU and 0.8% TER by adding the wcTM and
the 7-gram wcLM.
4 Equivalence to Factored Translation
Koehn and Hoang (2007) propose to integrate differ-
ent levels of annotation (e.g. morphologial analysis)
as factors into the translation process. Here, the sur-
face form of the source word is analyzed to produce
the factors, which are then translated and finally the
surface form of the target word is generated from the
target factors. Although the translations of the fac-
tors operate on the same phrase segmentation, they
are assumed to be independent. In practice this is
done by phrase expansion, which generates a joint
phrase table as the cross product from the phrase ta-
bles of the individual factors.
In contrast, in this work each word is mapped to
a single class, which means that when we have se-
lected a translation option for the surface form, the
target side on the word class level is predetermined.
Thus, no phrase expansion or generation steps are
necessary to incorporate the word class information.
The phrase table can simply be extended with addi-
tional scores, keeping the set of phrases constant.
Although the implementation is simpler, our ap-
proach is mathematically equivalent to a special
case of the factored translation framework, which is
shown in Figure 1. The generation step from target
word e to its target class c(e) assigns all probability
Input Output
word f word e
class c(f) class c(e)
analysis
translation
translation
generation   
Figure 1: The factored translation model equivalent to
our approach. The generation step assigns all probability
mass to a single event: pgen(c(e)|e) = 1.
mass to a single event:
pgen(c|e) =
{
1, if c = c(e)
0, else
(2)
5 Conclusion
We have presented a simple and very easy to im-
plement method to make use of word clusters for
improving machine translation quality. It is appli-
cable across different paradigms and for arbitrary
types of models. Depending on the model type,
it requires little or no change to the training and
decoding software. We have shown the efficacy
of this method on two translation tasks and with
both the standard phrase-based and the hierarchi-
cal phrase-based translation paradigm. It was ap-
plied to relative frequency translation probabilities,
the n-gram language model and a hierarchical re-
ordering model. In our experiments, the baseline
is improved by 1.4% BLEU and 1.0% TER on the
French?German task and by 0.3% BLEU and 1.1%
TER on the German?English task.
In future work we plan to apply our method to a
wider range of languages. Intuitively, it should be
most effective for morphologically rich languages,
which naturally have stronger sparsity problems.
Acknowledgments
This work was partially realized as part of the
Quaero Programme, funded by OSEO, French State
agency for innovation. The research leading to these
results has also received funding from the European
Union Seventh Framework Programme (FP7/2007-
2013) under grant agreement no 287658.
1380
References
Stanley F. Chen and Joshuo Goodman. 1998. An Em-
pirical Study of Smoothing Techniques for Language
Modeling. Technical Report TR-10-98, Computer
Science Group, Harvard University, Cambridge, MA,
August.
Colin Cherry, Robert C. Moore, and Chris Quirk. 2012.
On Hierarchical Re-ordering and Permutation Parsing
for Phrase-based Decoding. In Proceedings of the 7th
Workshop on Statistical Machine Translation, WMT
?12, pages 200?209, Montral, Canada.
Colin Cherry. 2013. Improved reordering for phrase-
based translation using sparse features. In The 2013
Conference of the North American Chapter of the As-
sociation for Computational Linguistics: Human Lan-
guage Technologies (NAACL-HLT 2013), pages 22?
31, Atlanta, Georgia, USA, June.
Michel Galley and Christopher D. Manning. 2008. A
Simple and Effective Hierarchical Phrase Reordering
Model. In Proceedings of the 2008 Conference on
Empirical Methods in Natural Language Processing,
pages 847?855, Honolulu, Hawaii, USA, October.
Philipp Koehn and Hieu Hoang. 2007. Factored Transla-
tion Models. In Proceedings of the 2007 Joint Confer-
ence on Empirical Methods in Natural Language Pro-
cessing and Computational Natural Language Learn-
ing, pages 868?876, Prague, Czech Republic, June.
P. Koehn, F. J. Och, and D. Marcu. 2003. Statistical
Phrase-Based Translation. In Proceedings of the 2003
Meeting of the North American chapter of the Associa-
tion for Computational Linguistics (NAACL-03), pages
127?133, Edmonton, Alberta.
Philipp Koehn. 2004. Statistical Significance Tests for
Machine Translation Evaluation. In Proc. of the Conf.
on Empirical Methods for Natural Language Process-
ing (EMNLP), pages 388?395, Barcelona, Spain, July.
Mohammed Mediani, Yuqi Zhang, Thanh-Le Ha, Jan
Niehues, Eunah Cho, Teresa Herrmann, and Alex
Waibel. 2012. The kit translation systems for iwslt
2012. In Proceedings of the International Work-
shop for Spoken Language Translation (IWSLT 2012),
Hong Kong.
Franz Josef Och and Hermann Ney. 2003. A Systematic
Comparison of Various Statistical Alignment Models.
Computational Linguistics, 29(1):19?51, March.
Franz Josef Och and Hermann Ney. 2004. The align-
ment template approach to statistical machine transla-
tion. Computational Linguistics, 30(4):417?449, De-
cember.
F. J. Och. 1999. An efficient method for determining
bilingual word classes. In Proc. of the Ninth Conf.
of the Europ. Chapter of the Association of Compu-
tational Linguistics, pages 71?76, Bergen, Norway,
June.
Franz Josef Och. 2003. Minimum Error Rate Train-
ing in Statistical Machine Translation. In Proc. of the
41th Annual Meeting of the Association for Compu-
tational Linguistics (ACL), pages 160?167, Sapporo,
Japan, July.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a Method for Automatic Eval-
uation of Machine Translation. In Proceedings of the
41st Annual Meeting of the Association for Computa-
tional Linguistics, pages 311?318, Philadelphia, Penn-
sylvania, USA, July.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciulla, and John Makhoul. 2006. A Study
of Translation Edit Rate with Targeted Human Anno-
tation. In Proceedings of the 7th Conference of the
Association for Machine Translation in the Americas,
pages 223?231, Cambridge, Massachusetts, USA, Au-
gust.
Andreas Stolcke. 2002. SRILM ? An Extensible Lan-
guage Modeling Toolkit. In Proc. of the Int. Conf. on
Speech and Language Processing (ICSLP), volume 2,
pages 901?904, Denver, CO, September.
David Vilar, Daniel Stein, Matthias Huck, and Hermann
Ney. 2010. Jane: Open source hierarchical transla-
tion, extended with reordering and lexicon models. In
ACL 2010 Joint Fifth Workshop on Statistical Machine
Translation and Metrics MATR, pages 262?270, Upp-
sala, Sweden, July.
Joern Wuebker, Matthias Huck, Stephan Peitz, Malte
Nuhn, Markus Freitag, Jan-Thorsten Peter, Saab Man-
sour, and Hermann Ney. 2012. Jane 2: Open
source phrase-based and hierarchical statistical ma-
chine translation. In International Conference on
Computational Linguistics, pages 483?491, Mumbai,
India, December.
1381
Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 174?179,
Gothenburg, Sweden, April 26-30 2014.
c?2014 Association for Computational Linguistics
Simple and Effective Approach for Consistent Training of Hierarchical
Phrase-based Translation Models
Stephan Peitz
1
and David Vilar
2
and Hermann Ney
1
1
Lehrstuhl f?ur Informatik 6
Computer Science Department
2
Pixformance GmbH
RWTH Aachen University D-10587 Berlin, Germany
D-52056 Aachen, Germany david.vilar@gmail.com
{peitz,ney}@cs.rwth-aachen.de
Abstract
In this paper, we present a simple ap-
proach for consistent training of hierarchi-
cal phrase-based translation models. In
order to consistently train a translation
model, we perform hierarchical phrase-
based decoding on training data to find
derivations between the source and tar-
get sentences. This is done by syn-
chronous parsing the given sentence pairs.
After extracting k-best derivations, we
reestimate the translation model proba-
bilities based on collected rule counts.
We show the effectiveness of our proce-
dure on the IWSLT German?English and
English?French translation tasks. Our
results show improvements of up to 1.6
points BLEU.
1 Introduction
In state of the art statistical machine translation
systems, the translation model is estimated by fol-
lowing heuristic: Given bilingual training data,
a word alignment is trained with tools such as
GIZA
++
(Och and Ney, 2003) or fast align (Dyer
et al., 2013). Then, all valid translation pairs are
extracted and the translation probabilities are com-
puted as relative frequencies (Koehn et al., 2003).
However, this extraction method causes several
problems. First, this approach does not consider,
whether a translation pair is extracted from a likely
alignment or not. Further, during the extraction
process, models employed in decoding are not
considered.
For phrase-based translation, a successful ap-
proach addressing these issues is presented in
(Wuebker et al., 2010). By applying a phrase-
based decoder on the source sentences of the train-
ing data and constraining the translations to the
corresponding target sentences, k-best segmenta-
tions are produced. Then, the phrases used for
these segmentations are extracted and counted.
Based on the counts, the translation model prob-
abilities are recomputed. To avoid over-fitting,
leave-one-out is applied.
However, for hierarchical phrase-based transla-
tion an equivalent approach is still missing.
In this paper, we present a simple and effec-
tive approach for consistent reestimation of the
translation model probabilities in a hierarchical
phrase-based translation setup. Using a heuristi-
cally extracted translation model as starting point,
the training data are parsed bilingually. From the
resulting hypergraphs, we extract k-best deriva-
tions and the rules applied in each derivation. This
is done with a top-down k-best parsing algorithm.
Finally, the translation model probabilities are re-
computed based on the counts of the extracted
rules. In our procedure, we employ leave-one-out
to avoid over-fitting. Further, we consider all mod-
els which are used in translation to ensure a con-
sistent training.
Experimental results are presented on the
German?English and English?French IWSLT
shared machine translation task (Cettolo et al.,
2013). We are able to gain improvements of up to
1.6% BLEU absolute and 1.4% TER over a com-
petitive baseline. On all tasks and test sets, the
improvements are statistically significant with at
least 99% confidence.
The paper is structured as follow. First, we re-
vise the state of the art hierarchical phrase-based
extraction and translation process. In Section 3,
we propose our training procedure. Finally, ex-
perimental results are given in Section 4 and we
conclude with Section 5.
2 Hierarchical Phrase-based Translation
In hierarchical phrase-based translation (Chiang,
2005), discontinuous phrases with ?gaps? are
allowed. The translation model is formalized
as a synchronous context-free grammar (SCFG)
174
and consists of bilingual rules, which are based
on bilingual standard phrases and discontinuous
phrases. Each bilingual rule rewrites a generic
non-terminal X into a pair of strings
?
f and e?
with both terminals and non-terminals in both lan-
guages
X ? ?
?
f, e??. (1)
In a standard hierarchical phrase-based translation
setup, obtaining these rules is based on a heuristic
extraction from automatically word-aligned bilin-
gual training data. Just like in the phrase-based
approach, all bilingual rules of a sentence pair
are extracted given an alignment. The standard
phrases are stored as lexical rules in the rule set.
In addition, whenever a phrase contains a sub-
phrase, this sub-phrase is replaced by a generic
non-terminal X . With these hierarchical phrases
we can define the hierarchical rules in the SCFG.
The rule probabilities which are in general defined
as relative frequencies are computed based on the
joint counts C(X ? ?
?
f, e??) of a bilingual rule
X ? ?
?
f, e??
p
H
(
?
f |e?) =
C(X ? ?
?
f, e??)
?
?
f
?
C(X ? ?
?
f
?
, e??)
. (2)
The translation probabilities are computed in
source-to-target as well as in target-to-source di-
rection. In the translation processes, these proba-
bilities are integrated in the log-linear combination
among other models such as a language model,
word lexicon models, word and phrase penalty and
binary features marking hierarchical phrases, glue
rule and rules with non-terminals at the bound-
aries.
The translation process of hierarchical phrase-
based approach can be considered as parsing prob-
lem. Given an input sentence in the source lan-
guage, this sentence is parsed using the source lan-
guage part of the SCFG. In this work, we perform
this step with a modified version of the CYK+ al-
gorithm (Chappelier and Rajman, 1998). The out-
put of this algorithm is a hypergraph, which rep-
resents all possible derivations of the input sen-
tence. A derivation represents an application of
rules from the grammar to generate the given in-
put sentence. Using the the associated target part
of the applied rule, for each derivation a transla-
tion can be constructed. In a second step, the lan-
guage model score is incorporated. Given the hy-
pergraph, this is done with the cube pruning algo-
rithm presented in (Chiang, 2007).
3 Translation Model Training
We propose following pipeline for consistent hi-
erarchical phrase-based training: First we train a
word alignment, from which the baseline trans-
lation model is extracted as described in the pre-
vious section. The log-linear parameter weights
are tuned with MERT (Och, 2003) on a develop-
ment set to produce the baseline system. Next,
we perform decoding on the training data. As the
translations are constrained to the given target sen-
tences, we name this step forced decoding in the
following. Details are given in the next subsection.
Given the counts C
FD
(X ? ?
?
f, e??) of the rules,
which have been applied in the forced decoding
step, the translation probabilities p
FD
(
?
f |e?) for the
translation model are recomputed:
p
FD
(
?
f |e?) =
C
FD
(X ? ?
?
f, e??)
?
?
f
?
C
FD
(X ? ?
?
f
?
, e??)
. (3)
Finally, using the translation model with the
reestimated probabilities, we retune the log-linear
parameter weights and obtain our final system.
3.1 Forced Decoding
In this section, we describe the forced decoding
for hierarchical phrase-based translation in detail.
Given a sentence pair of the training data, we
constrain the translation of the source sentence to
produce the corresponding target sentence. For
this constrained decoding process, the language
model score is constant as the translation is fixed.
Hence, the incorporation of the a language model
is not needed. This results in a simplification of
the decoding process as we do not have to employ
the cube pruning algorithm as described in the pre-
vious section. Consequently, forced decoding for
hierarchical phrase-based translation is equivalent
to synchronous parsing of the training data. Dyer
(2010) has described an approach to reduce the
average-case run-time of synchronous parsing by
splitting one bilingual parse into two successive
monolingual parses. We adopt this method and
first parse the source sentence and then the target
sentence with CYK+.
If the given sentence pair has been parsed suc-
cessfully, we employ a top-down k-best parsing
algorithm (Chiang and Huang, 2005) on the re-
sulting hypergraph to find the k-best derivations
between the given source and target sentence. In
this step, all models of the translation process are
175
included (except for the language model). Further,
leave-one-out is applied to counteract overfitting.
Note, that the model weights of the baseline sys-
tem are used to perform forced decoding.
Finally, we extract and count the rules which
have been applied in the derivations. These counts
are used to recompute the translation probabilities.
3.2 Recombination
In standard hierarchical phrase-based decoding,
partial derivations that are indistinguishable from
each other are recombined. In (Huck et al., 2013)
two schemes are presented. Either derivations that
produce identical translations or derivations with
identical language model context are recombined.
As in forced decoding the translation is fixed and
a language model is missing, both schemes are not
suitable.
However, a recombination scheme is necessary
to avoid derivations with the same application
of rules. Further, recombining such derivations
increases simultaneously the amounts of consid-
ered derivations during k-best parsing. Given two
derivations with the same set of applied rules, the
order of application of the rules may be different.
Thus, we propose following scheme for recom-
bining derivations in forced decoding: Derivations
that produce identical sets of applied rules are re-
combined. Figure 1 shows an example for k = 3.
Employing the proposed scheme, derivations d
1
and d
2
are recombined since both share the same
set of applied rules ({r
1
, r
3
, r
2
}).
d
1
: {r
1
, r
3
, r
2
}
d
2
: {r
3
, r
2
, r
1
}
d
3
: {r
4
, r
5
, r
1
, r
2
}
(a)
d
1
: {r
1
, r
3
, r
2
}
d
3
: {r
4
, r
5
, r
1
, r
2
}
d
4
: {r
6
, r
5
, r
2
, r
3
}
(b)
Figure 1: Example search space before (a) and af-
ter (b) applying recombination.
4 Experiments
4.1 Setup
The experiments were carried out on the IWSLT
2013 German?English shared translation task.
1
1
http://www.iwslt2013.org
German English English French
Sentences 4.32M 5.23M
Run. Words 108M 109M 133M 147M
Vocabulary 836K 792K 845K 888K
Table 1: Statistics for the bilingual training
data of the IWSLT 2013 German?English and
English?French task.
It is focusing the translation of TED talks. Bilin-
gual data statistics are given in Table 1. The base-
line system was trained on all available bilingual
data and used a 4-gram LM with modified Kneser-
Ney smoothing (Kneser and Ney, 1995; Chen and
Goodman, 1998), trained with the SRILM toolkit
(Stolcke, 2002). As additional data sources for the
LM we selected parts of the Shuffled News and
LDC English Gigaword corpora based on cross-
entropy difference (Moore and Lewis, 2010). In
all experiments, the hierarchical search was per-
formed as described in Section 2.
To confirm the efficacy of our approach, addi-
tional experiments were run on the IWSLT 2013
English?French task. Statistics are given in Ta-
ble 1.
The training pipeline was set up as described
in the previous section. Tuning of the log-linear
parameter weights was done with MERT on a pro-
vided development set. As optimization criterion
we used BLEU (Papineni et al., 2001).
Forced decoding was performed on the TED
talks portion of the training data (?140K sen-
tences). In both tasks, around 5% of the sentences
could not be parsed. In this work, we just skipped
those sentences.
We report results in BLEU [%] and TER [%]
(Snover et al., 2006). All reported results are av-
erages over three independent MERT runs, and
we evaluated statistical significance with MultE-
val (Clark et al., 2011).
4.2 Results
Figure 2 shows the performance of setups us-
ing translation models with reestimated translation
probabilities. The setups vary in the k-best deriva-
tion size extracted in the forced decoding (fd) step.
Based on the performance on the development set,
we selected two setups with k = 500 using leave-
one-out (+l1o) and k = 750 without leave-one-
out (-l1o). Table 2 shows the final results for
the German?English task. Performing consistent
translation model training improves the translation
176
dev
*
eval11 test
BLEU
[%]
TER
[%]
BLEU
[%]
TER
[%]
BLEU
[%]
TER
[%]
baseline 33.1 46.8 35.7 44.1 30.5 49.7
forced decoding -l1o 33.2 46.3 36.3 43.4 31.2 48.8
forced decoding +l1o 33.6 46.2 36.6 43.0 31.8 48.3
Table 2: Results for the IWSLT 2013 German?English task. The development set used for MERT is
marked with an asterisk (*). Statistically significant improvements with at least 99% confidence over the
baseline are printed in boldface.
dev
*
eval11 test
BLEU
[%]
TER
[%]
BLEU
[%]
TER
[%]
BLEU
[%]
TER
[%]
baseline 28.1 55.7 37.5 42.7 31.7 49.5
forced decoding +l1o 28.8 55.0 39.1 41.6 32.4 49.0
Table 3: Results for the IWSLT 2013 English?French task. The development set used for MERT is
marked with an asterisk (*). Statistically significant improvements with at least 99% confidence over the
baseline are printed in boldface.
 31.5
 32
 32.5
 33
 33.5
 34
 1  10  100  1000  10000
B
L
E
U
[
%
]
k
dev fd +l1odev fd -l1odev baseline
Figure 2: BLEU scores on the IWSLT
German?English task of setups using trans-
lation models trained with different k-best
derivation sizes. Results are reported on dev with
(+l1o) and without leave-one-out (-l1o).
quality on all test sets significantly. We gain an
improvement of up to 0.7 points in BLEU and 0.9
points in TER. Applying leave-one-out results in
an additional improvement by up to 0.4 % BLEU
and 0.5 % TER. The results for English?French
are given in Table 3. We observe a similar im-
provement by up to 1.6 % BLEU and 1.1 % TER.
The improvements could be the effect of do-
main adaptation since we performed forced decod-
ing on the TED talks portion of the training data.
Thus, rules which were applied to decode the in-
domain data might get higher translation probabil-
ities.
Furthermore, employing leave-one-out seems to
avoid overfitting as the average source rule length
in training is reduced from 5.0 to 3.5 (k = 500).
5 Conclusion
We have presented a simple and effective approach
for consistent training of hierarchical phrase-based
translation models. By reducing hierarchical de-
coding on parallel training data to synchronous
parsing, we were able to reestimate the trans-
lation probabilities including all models applied
during the translation process. On the IWSLT
German?English and English?French tasks, the
final results show statistically significant improve-
ments of up to 1.6 points in BLEU and 1.4 points
in TER.
Our implementation was released as part of Jane
(Vilar et al., 2010; Vilar et al., 2012; Huck et al.,
2012; Freitag et al., 2014), the RWTH Aachen
University open source statistical machine trans-
lation toolkit.
2
Acknowledgments
The research leading to these results has received
funding from the European Union Seventh Frame-
work Programme (FP7/2007-2013) under grant
agreements no 287658 and no 287755.
2
http://www.hltpr.rwth-aachen.de/jane/
177
References
Mauro Cettolo, Jan Nieheus, Sebastian St?uker, Luisa
Bentivogli, and Marcello Federico. 2013. Report on
the 10th iwslt evaluation campaign. In Proc. of the
International Workshop on Spoken Language Trans-
lation, Heidelberg, Germany, December.
J.-C. Chappelier and M. Rajman. 1998. A general-
ized CYK algorithm for parsing stochastic CFG. In
Proceedings of the First Workshop on Tabulation in
Parsing and Deduction, pages 133?137, April.
Stanley F. Chen and Joshuo Goodman. 1998. An
Empirical Study of Smoothing Techniques for Lan-
guage Modeling. Technical Report TR-10-98, Com-
puter Science Group, Harvard University, Cam-
bridge, MA, August.
David Chiang and Liang Huang. 2005. Better k-best
Parsing. In Proceedings of the 9th Internation Work-
shop on Parsing Technologies, pages 53?64, Octo-
ber.
David Chiang. 2005. A Hierarchical Phrase-Based
Model for Statistical Machine Translation. In Proc.
of the 43rd Annual Meeting of the Association for
Computational Linguistics (ACL), pages 263?270,
Ann Arbor, Michigan, June.
David Chiang. 2007. Hierarchical phrase-based trans-
lation. Computational Linguistics, 33(2):201?228,
June.
Jonathan H. Clark, Chris Dyer, Alon Lavie, and
Noah A. Smith. 2011. Better hypothesis test-
ing for statistical machine translation: Controlling
for optimizer instability. In 49th Annual Meet-
ing of the Association for Computational Linguis-
tics:shortpapers, pages 176?181, Portland, Oregon,
June.
Chris Dyer, Victor Chahuneau, and Noah A. Smith.
2013. A Simple, Fast, and Effective Reparameter-
ization of IBM Model 2. In Proceedings of NAACL-
HLT, pages 644?648, Atlanta, Georgia, June.
Chris Dyer. 2010. Two monolingual parses are better
than one (synchronous parse). In In Proc. of HLT-
NAACL.
Markus Freitag, Matthias Huck, and Hermann Ney.
2014. Jane: Open source machine translation sys-
tem combination. In Conference of the European
Chapter of the Association for Computational Lin-
guistics, Gothenburg, Sweden, April. To appear.
Matthias Huck, Jan-Thorsten Peter, Markus Freitag,
Stephan Peitz, and Hermann Ney. 2012. Hierar-
chical Phrase-Based Translation with Jane 2. The
Prague Bulletin of Mathematical Linguistics, 98:37?
50, October.
Matthias Huck, David Vilar, Markus Freitag, and Her-
mann Ney. 2013. A performance study of cube
pruning for large-scale hierarchical machine transla-
tion. In Proceedings of the NAACL 7th Workshop on
Syntax, Semantics and Structure in Statistical Trans-
lation, pages 29?38, Atlanta, Georgia, USA, June.
Reinerd Kneser and Hermann Ney. 1995. Improved
backing-off for M-gram language modeling. In Pro-
ceedings of the International Conference on Acous-
tics, Speech, and Signal Processingw, volume 1,
pages 181?184, May.
P. Koehn, F. J. Och, and D. Marcu. 2003. Statisti-
cal Phrase-Based Translation. In Proceedings of the
2003 Meeting of the North American chapter of the
Association for Computational Linguistics (NAACL-
03), pages 127?133, Edmonton, Alberta.
R.C. Moore and W. Lewis. 2010. Intelligent Selection
of Language Model Training Data. In ACL (Short
Papers), pages 220?224, Uppsala, Sweden, July.
Franz Josef Och and Hermann Ney. 2003. A System-
atic Comparison of Various Statistical Alignment
Models. Computational Linguistics, 29(1):19?51,
March.
Franz Josef Och. 2003. Minimum Error Rate Training
in Statistical Machine Translation. In Proc. of the
41th Annual Meeting of the Association for Compu-
tational Linguistics (ACL), pages 160?167, Sapporo,
Japan, July.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2001. Bleu: a Method for Automatic
Evaluation of Machine Translation. IBM Research
Report RC22176 (W0109-022), IBM Research Di-
vision, Thomas J. Watson Research Center, P.O. Box
218, Yorktown Heights, NY 10598, September.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciulla, and John Makhoul. 2006. A Study of
Translation Edit Rate with Targeted Human Annota-
tion. In Proceedings of the 7th Conference of the As-
sociation for Machine Translation in the Americas,
pages 223?231, Cambridge, Massachusetts, USA,
August.
Andreas Stolcke. 2002. SRILM ? An Extensible Lan-
guage Modeling Toolkit. In Proc. of the Int. Conf.
on Speech and Language Processing (ICSLP), vol-
ume 2, pages 901?904, Denver, CO, September.
David Vilar, Daniel Stein, Matthias Huck, and Her-
mann Ney. 2010. Jane: Open source hierarchi-
cal translation, extended with reordering and lexi-
con models. In ACL 2010 Joint Fifth Workshop on
Statistical Machine Translation and Metrics MATR,
pages 262?270, Uppsala, Sweden, July.
David Vilar, Daniel Stein, Matthias Huck, and Her-
mann Ney. 2012. Jane: an advanced freely avail-
able hierarchical machine translation toolkit. Ma-
chine Translation, 26(3):197?216, September.
178
Joern Wuebker, Arne Mauser, and Hermann Ney.
2010. Training phrase translation models with
leaving-one-out. In Proceedings of the 48th Annual
Meeting of the Assoc. for Computational Linguistics,
pages 475?484, Uppsala, Sweden, July.
179
Proceedings of the 6th Workshop on Statistical Machine Translation, pages 358?364,
Edinburgh, Scotland, UK, July 30?31, 2011. c?2011 Association for Computational Linguistics
Joint WMT Submission of the QUAERO Project
?Markus Freitag, ?Gregor Leusch, ?Joern Wuebker, ?Stephan Peitz, ?Hermann Ney,
?Teresa Herrmann, ?Jan Niehues, ?Alex Waibel,
?Alexandre Allauzen, ?Gilles Adda,?Josep Maria Crego,
?Bianka Buschbeck, ?Tonio Wandmacher, ?Jean Senellart
?RWTH Aachen University, Aachen, Germany
?Karlsruhe Institute of Technology, Karlsruhe, Germany
?LIMSI-CNRS, Orsay, France
?SYSTRAN Software, Inc.
?surname@cs.rwth-aachen.de
?firstname.surname@kit.edu
?firstname.lastname@limsi.fr ?surname@systran.fr
Abstract
This paper describes the joint QUAERO sub-
mission to the WMT 2011 machine transla-
tion evaluation. Four groups (RWTH Aachen
University, Karlsruhe Institute of Technol-
ogy, LIMSI-CNRS, and SYSTRAN) of the
QUAERO project submitted a joint translation
for the WMT German?English task. Each
group translated the data sets with their own
systems. Then RWTH system combination
combines these translations to a better one. In
this paper, we describe the single systems of
each group. Before we present the results of
the system combination, we give a short de-
scription of the RWTH Aachen system com-
bination approach.
1 Overview
QUAERO is a European research and develop-
ment program with the goal of developing multi-
media and multilingual indexing and management
tools for professional and general public applica-
tions (http://www.quaero.org). Research in machine
translation is mainly assigned to the four groups
participating in this joint submission. The aim of
this WMT submission was to show the quality of a
joint translation by combining the knowledge of the
four project partners. Each group develop and main-
tain their own different machine translation system.
These single systems differ not only in their general
approach, but also in the preprocessing of training
and test data. To take the advantage of these dif-
ferences of each translation system, we combined
all hypotheses of the different systems, using the
RWTH system combination approach.
1.1 Data Sets
For WMT 2011 each QUAERO partner trained their
systems on the parallel Europarl and News Com-
mentary corpora. All single systems were tuned on
the newstest2009 dev set. The newstest2008 dev set
was used to train the system combination parame-
ters. Finally the newstest2010 dev set was used to
compare the results of the different system combi-
nation approaches and settings.
2 Translation Systems
2.1 RWTH Aachen Single Systems
For the WMT 2011 evaluation the RWTH utilized
RWTH?s state-of-the-art phrase-based and hierar-
chical translation systems. GIZA++ (Och and Ney,
2003) was employed to train word alignments, lan-
guage models have been created with the SRILM
toolkit (Stolcke, 2002).
2.1.1 Phrase-Based System
The phrase-based translation (PBT) system is
similar to the one described in Zens and Ney (2008).
After phrase pair extraction from the word-aligned
bilingual corpus, the translation probabilities are es-
timated by relative frequencies. The standard feature
set alo includes an n-gram language model, phrase-
level IBM-1 and word-, phrase- and distortion-
penalties, which are combined in log-linear fash-
ion. Parameters are optimized with the Downhill-
Simplex algorithm (Nelder and Mead, 1965) on the
word graph.
358
2.1.2 Hierarchical System
For the hierarchical setups described in this pa-
per, the open source Jane toolkit (Vilar et al, 2010)
is employed. Jane has been developed at RWTH
and implements the hierarchical approach as intro-
duced by Chiang (2007) with some state-of-the-art
extensions. In hierarchical phrase-based translation,
a weighted synchronous context-free grammar is in-
duced from parallel text. In addition to contiguous
lexical phrases, hierarchical phrases with up to two
gaps are extracted. The search is typically carried
out using the cube pruning algorithm (Huang and
Chiang, 2007). The model weights are optimized
with standard MERT (Och, 2003) on 100-best lists.
2.1.3 Phrase Model Training
For some PBT systems a forced alignment pro-
cedure was applied to train the phrase translation
model as described in Wuebker et al (2010). A
modified version of the translation decoder is used
to produce a phrase alignment on the bilingual train-
ing data. The phrase translation probabilities are es-
timated from their relative frequencies in the phrase-
aligned training data. In addition to providing a sta-
tistically well-founded phrase model, this has the
benefit of producing smaller phrase tables and thus
allowing more rapid and less memory consuming
experiments with a better translation quality.
2.1.4 Final Systems
For the German?English task, RWTH conducted
experiments comparing the standard phrase extrac-
tion with the phrase training technique described in
Section 2.1.3. Further experiments included the use
of additional language model training data, rerank-
ing of n-best lists generated by the phrase-based sys-
tem, and different optimization criteria.
A considerable increase in translation quality can
be achieved by application of German compound
splitting (Koehn and Knight, 2003). In comparison
to standard heuristic phrase extraction techniques,
performing force alignment phrase training (FA)
gives an improvement in BLEU on newstest2008
and newstest2009, but a degradation in TER. The
addition of LDC Gigaword corpora (+GW) to the
language model training data shows improvements
in both BLEU and TER. Reranking was done on
1000-best lists generated by the the best available
system (PBT (FA)+GW). Following models were
applied: n-gram posteriors (Zens and Ney, 2006),
sentence length model, a 6-gram LM and IBM-1 lex-
icon models in both normal and inverse direction.
These models are combined in a log-linear fashion
and the scaling factors are tuned in the same man-
ner as the baseline system (using TER?4BLEU on
newstest2009).
The final table includes two identical Jane sys-
tems which are optimized on different criteria. The
one optimized on TER?BLEU yields a much lower
TER.
2.2 Karlsruhe Institute of Technology Single
System
2.2.1 Preprocessing
We preprocess the training data prior to training
the system, first by normalizing symbols such as
quotes, dashes and apostrophes. Then smart-casing
of the first words of each sentence is performed. For
the German part of the training corpus we use the
hunspell1 lexicon to learn a mapping from old Ger-
man spelling to new German spelling to obtain a cor-
pus with homogeneous spelling. In addition, we per-
form compound splitting as described in (Koehn and
Knight, 2003). Finally, we remove very long sen-
tences, empty lines, and sentences that probably are
not parallel due to length mismatch.
2.2.2 System Overview
The KIT system uses an in-house phrase-based
decoder (Vogel, 2003) to perform translation. Op-
timization with regard to the BLEU score is done
using Minimum Error Rate Training as described
by Venugopal et al (2005). The translation model
is trained on the Europarl and News Commentary
Corpus and the phrase table is based on a GIZA++
Word Alignment. We use two 4-gram SRI language
models, one trained on the News Shuffle corpus and
one trained on the Gigaword corpus. Reordering is
performed based on continuous and non-continuous
POS rules to cover short and long-range reorder-
ings. The long-range reordering rules were also ap-
plied to the training corpus and phrase extraction
was performed on the resulting reordering lattices.
Part-of-speech tags are obtained using the TreeTag-
1http://hunspell.sourceforge.net/
359
ger (Schmid, 1994). In addition, the system applies
a bilingual language model to extend the context of
source language words available for translation. The
individual models are described briefly in the fol-
lowing.
2.2.3 POS-based Reordering Model
We use a reordering model that is based on parts-
of-speech (POS) and learn probabilistic rules from
the POS tags of the words in the training corpus and
the alignment information. In addition to continu-
ous reordering rules that model short-range reorder-
ing (Rottmann and Vogel, 2007), we apply non-
continuous rules to address long-range reorderings
as typical for German-English translation (Niehues
and Kolss, 2009). The reordering rules are applied
to the source sentences and the reordered sentence
variants as well as the original sequence are encoded
in a word lattice which is used as input to the de-
coder.
2.2.4 Lattice Phrase Extraction
For the test sentences, the POS-based reordering
allows us to change the word order in the source sen-
tence so that the sentence can be translated more eas-
ily. If we apply this also to the training sentences, we
would be able to extract also phrase pairs for origi-
nally discontinuous phrases and could apply them
during translation of reordered test sentences.
Therefore, we build reordering lattices for all
training sentences and then extract phrase pairs from
the monotone source path as well as from the re-
ordered paths. To limit the number of extracted
phrase pairs, we extract a source phrase only once
per sentence, even if it is found in different paths and
we only use long-range reordering rules to generate
the lattices for the training corpus.
2.2.5 Bilingual Language Model
In phrase-based systems the source sentence is
segmented by the decoder during the search pro-
cess. This segmentation into phrases leads to the
loss of context information at the phrase boundaries.
The language model can make use of more target
side context. To make also source language context
available we use a bilingual language model, an ad-
ditional language model in the phrase-based system
in which each token consist of a target word and all
source words it is aligned to. The bilingual tokens
enter the translation process as an additional target
factor.
2.3 LIMSI-CNRS Single System
2.3.1 System overview
The LIMSI system is built with n-code2, an open
source statistical machine translation system based
on bilingual n-grams.
2.3.2 n-code Overview
In a nutshell, the translation model is im-
plemented as a stochastic finite-state transducer
trained using a n-gram model of (source,target)
pairs (Casacuberta and Vidal, 2004). Training this
model requires to reorder source sentences so as to
match the target word order. This is performed by a
stochastic finite-state reordering model, which uses
part-of-speech information3 to generalize reordering
patterns beyond lexical regularities.
In addition to the translation model, eleven fea-
ture functions are combined: a target-language
model; four lexicon models; two lexicalized reorder-
ing models (Tillmann, 2004) aiming at predicting
the orientation of the next translation unit; a weak
distance-based distortion model; and finally a word-
bonus model and a tuple-bonus model which com-
pensate for the system preference for short transla-
tions. The four lexicon models are similar to the ones
use in a standard phrase based system: two scores
correspond to the relative frequencies of the tuples
and two lexical weights estimated from the automat-
ically generated word alignments. The weights asso-
ciated to feature functions are optimally combined
using a discriminative training framework (Och,
2003), using the newstest2009 data as development
set.
The overall search is based on a beam-search
strategy on top of a dynamic programming algo-
rithm. Reordering hypotheses are computed in a
preprocessing step, making use of reordering rules
built from the word reorderings introduced in the tu-
ple extraction process. The resulting reordering hy-
potheses are passed to the decoder in the form of
word lattices (Crego and Marin?o, 2007).
2http://www.limsi.fr/Individu/jmcrego/n-code
3Part-of-speech information for English and German is com-
puted using the TreeTagger.
360
2.3.3 Data Preprocessing
Based on previous experiments which have
demonstrated that better normalization tools provide
better BLEU scores (K. Papineni and Zhu, 2002),
all the English texts are tokenized and detokenized
with in-house text processing tools (De?chelotte et
al., 2008). For German, the standard tokenizer sup-
plied by evaluation organizers is used.
2.3.4 Target n-gram Language Models
The English language model is trained assuming
that the test set consists in a selection of news texts
dating from the end of 2010 to the beginning of
2011. This assumption is based on what was done
for the 2010 evaluation. Thus, a development cor-
pus is built in order to create a vocabulary and to
optimize the target language model.
Development Set and Vocabulary In order to
cover different period, two development sets are
used. The first one is newstest2008. However, this
corpus is two years older than the targeted time pe-
riod. Thus a second development corpus is gath-
ered by randomly sampling bunches of 5 consecu-
tive sentences from the provided news data of 2010
and 2011.
To estimate a LM, the English vocabulary is first
defined by including all tokens observed in the Eu-
roparl and news-commentary corpora. This vocabu-
lary is then expanded with all words that occur more
that 5 times in the French-English giga-corpus, and
with the most frequent proper names taken from the
monolingual news data of 2010 and 2011. This pro-
cedure results in a vocabulary around 500k words.
Language Model Training All the training data
allowed in the constrained task are divided into 9
sets based on dates on genres. On each set, a
standard 4-gram LM is estimated from the 500k
word vocabulary with in-house tools using abso-
lute discounting interpolated with lower order mod-
els (Kneser and Ney, 1995; Chen and Goodman,
1998).
All LMs except the one trained on the news cor-
pora from 2010-2011 are first linearly interpolated.
The associated coefficients are estimated so as to
minimize the perplexity evaluated on the dev2010-
2011. The resulting LM and the 2010-2011 LM are
finally interpolated with newstest2008 as develop-
ment data. This two steps interpolation aims to avoid
an overestimate of the weight associated to the 2010-
2011 LM.
2.4 SYSTRAN Software, Inc. Single System
The data submitted by SYSTRAN were obtained by
the SYSTRAN baseline system in combination with
a statistical post editing (SPE) component.
The SYSTRAN system is traditionally classi-
fied as a rule-based system. However, over the
decades, its development has always been driven by
pragmatic considerations, progressively integrating
many of the most efficient MT approaches and tech-
niques. Nowadays, the baseline engine can be con-
sidered as a linguistic-oriented system making use of
dependency analysis, general transfer rules as well
as of large manually encoded dictionaries (100k ?
800k entries per language pair).
The basic setup of the SPE component is identi-
cal to the one described in (L. Dugast and Koehn,
2007). A statistical translation model is trained on
the rule-based translation of the source and the tar-
get side of the parallel corpus. This is done sepa-
rately for each parallel corpus. Language models are
trained on each target half of the parallel corpora and
also on additional in-domain corpora. Moreover, the
following measures ? limiting unwanted statistical
effects ? were applied:
? Named entities are replaced by special tokens
on both sides. This usually improves word
alignment, since the vocabulary size is signif-
icantly reduced. In addition, entity translation
is handled more reliably by the rule-based en-
gine.
? The intersection of both vocabularies (i.e. vo-
cabularies of the rule-based output and the ref-
erence translation) is used to produce an addi-
tional parallel corpus (whose target is identical
to the source). This was added to the parallel
text in order to improve word alignment.
? Singleton phrase pairs are deleted from the
phrase table to avoid overfitting.
? Phrase pairs not containing the same number
of entities on the source and the target side are
also discarded.
361
? Phrase pairs appearing less than 2 times were
pruned.
The SPE language model was trained 15M
phrases from the news/europarl corpora, provided
as training data for WMT 2011. Weights for these
separate models were tuned by the MERT algorithm
provided in the Moses toolkit (P. Koehn et al, 2007),
using the provided news development set.
3 RWTH Aachen System Combination
System combination is used to produce consensus
translations from multiple hypotheses produced with
different translation engines that are better in terms
of translation quality than any of the individual hy-
potheses. The basic concept of RWTH?s approach
to machine translation system combination has been
described by Matusov et al (2006; 2008). This ap-
proach includes an enhanced alignment and reorder-
ing framework. A lattice is built from the input hy-
potheses. The translation with the best score within
the lattice according to a couple of statistical mod-
els is selected as consensus translation. A deeper
description will be also given in the WMT11 sys-
tem combination paper of RWTH Aachen Univer-
sity. For this task only the A2L framework has been
used.
4 Experiments
We tried different system combinations with differ-
ent sets of single systems and different optimiza-
tion criteria. As RWTH has two different transla-
tion systems, we put the output of both systems into
system combination. Although both systems have
the same preprocessing, their hypotheses differ. Fi-
nally, we added for both RWTH systems two addi-
tional hypotheses to the system combination. The
two hypotheses of Jane were optimized on differ-
ent criteria. The first hypothesis was optimized on
BLEU and the second one on TER?BLEU. The first
RWTH phrase-based hypothesis was generated with
force alignment, the second RWTH phrase-based
hypothesis is a reranked version of the first one as
described in 2.1.4. Compared to the other systems,
the system by SYSTRAN has a completely different
approach (see section 2.4). It is mainly based on a
rule-based system. For the German?English pair,
SYSTRAN achieves a lower BLEU score in each
test set compared to the other groups. But since the
SYSTRAN system is very different to the others, we
still obtain an improvement when we add it also to
system combination.
We obtain the best result from system combina-
tion of all seven systems, optimizing the parameters
on BLEU. This system was the system we submitted
to the WMT 2011 evaluation.
For each dev set we obtain an improvement com-
pared to the best single systems. For newstest2008
and newstest2009 we get an improvement of 0.5
points in BLEU and 1.8 points in TER compared to
the best single system of Karlsruhe Institute of Tech-
nology. For newstest2010 we get an improvement
of 1.8 points in BLEU and 2.7 points in TER com-
pared to the best single system of RWTH. The sys-
tem combination weights optimized for the best run
are listed in Table 2. We see that although the single
system of SYSTRAN has the lowest BLEU scores,
it gets the second highest system weight. This high
value shows the influence of a completely different
system. On the other hand, all RWTH systems are
very similar, because of their same preprocessing
and their small variations. Therefor the system com-
bination parameter of all four systems by themselves
are relatively small. The summarized ?RWTH ap-
proach? system weight, though, is again on par with
the other systems.
5 Conclusion
The four statistical machine translation systems of
Karlsruhe Institute of Technology, RWTH Aachen
and LIMSI and the very structural approach of SYS-
TRAN produce hypotheses with a huge variability
compared to the others. Finally the RWTH Aachen
system combination combined all single system hy-
potheses to one hypothesis with a higher BLEU
compared to each single system. If the system
combination implementation can handle enough sin-
gle systems we would recommend to add all single
systems to the system combination. Although the
single system of SYSTRAN has the lowest BLEU
scores and the RWTH single systems are similar we
achieved the best result in using all single systems.
362
newstest2008 newstest2009 newstest2010 description
BLEU TER BLEU TER BLEU TER
22.73 60.73 22.50 59.82 25.26 57.37 sc (all systems) BLEU opt
22.61 60.60 22.28 59.39 25.07 56.95 sc (all systems - (1)) TER?BLEU opt
22.50 60.41 22.52 59.61 25.23 57.40 sc (all systems) TER?BLEU opt
22.19 60.09 22.05 59.31 24.74 56.89 sc (all systems - (4)) TER?BLEU opt
22.21 60.71 21.89 59.95 24.72 57.58 sc (all systems - (4,7)) TER?BLEU opt
22.22 60.45 21.79 59.72 24.32 57.59 sc (all systems - (3,4)) TER?BLEU opt
22.27 60.60 21.75 59.92 24.35 57.64 sc (all systems - (3,4)) BLEU opt
22.10 62.59 22.01 61.64 23.34 60.35 (1) Karlsruhe Institute of Technology
21.41 62.77 21.12 61.91 23.44 60.06 (2) RWTH PBT (FA) rerank +GW
21.11 62.96 21.06 62.16 23.29 60.26 (3) RWTH PBT (FA)
21.47 63.89 21.00 63.33 22.93 61.71 (4) RWTH jane + GW BLEU opt
20.89 61.05 20.36 60.47 23.42 58.31 (5) RWTH jane + GW TER?BLEU opt
20.33 64.50 19.79 64.91 21.97 61.44 (6) Limsi-CNRS
17.06 69.48 17.52 67.34 18.68 66.37 (7) SYSTRAN Software
Table 1: All systems for the WMT 2011 German?English translation task (truecase). BLEU and TER results are in
percentage. FA denotes systems with phrase training, +GW the use of LDC data for the language model. sc denotes
system combination.
system weight
Karlsruhe Institute of Technology 0.350
RWTH PBT (FA) rerank +GW 0.001
RWTH PBT (FA) 0.046
RWTH jane + GW BLEU opt 0.023
RWTH jane + GW TER?BLEU opt 0.034
Limsi-CNRS 0.219
SYSTRAN Software 0.328
Table 2: Optimized systems weights for each system of the best system combination result.
Acknowledgments
This work was achieved as part of the QUAERO
Programme, funded by OSEO, French State agency
for innovation.
References
F. Casacuberta and E. Vidal. 2004. Machine translation
with inferred stochastic finite-state transducers. Com-
putational Linguistics, 30(3):205?225.
S.F. Chen and J.T. Goodman. 1998. An empirical
study of smoothing techniques for language modeling.
Technical Report TR-10-98, Computer Science Group,
Harvard University.
D. Chiang. 2007. Hierarchical Phrase-Based Transla-
tion. Computational Linguistics, 33(2):201?228.
J.M. Crego and J.B. Marin?o. 2007. Improving statistical
MT by coupling reordering and decoding. Machine
Translation, 20(3):199?215.
D. De?chelotte, O. Galibert G. Adda, A. Allauzen, J. Gau-
vain, H. Meynard, and F. Yvon. 2008. LIMSI?s statis-
tical translation systems for WMT?08. In Proc. of the
NAACL-HTL Statistical Machine Translation Work-
shop, Columbus, Ohio.
L. Huang and D. Chiang. 2007. Forest Rescoring: Faster
Decoding with Integrated Language Models. In Proc.
Annual Meeting of the Association for Computational
Linguistics, pages 144?151, Prague, Czech Republic,
June.
T. Ward K. Papineni, S. Roukos and W. Zhu. 2002. Bleu:
363
a method for automatic evaluation of machine transla-
tion. In ACL ?02: Proc. of the 40th Annual Meeting
on Association for Computational Linguistics, pages
311?318. Association for Computational Linguistics.
R. Kneser and H. Ney. 1995. Improved backing-off for
m-gram language modeling. In Proceedings of the In-
ternational Conference on Acoustics, Speech, and Sig-
nal Processing, ICASSP?95, pages 181?184, Detroit,
MI.
P. Koehn and K. Knight. 2003. Empirical Methods
for Compound Splitting. In Proceedings of European
Chapter of the ACL (EACL 2009), pages 187?194.
J. Senellart L. Dugast and P. Koehn. 2007. Statistical
post-editing on systran?s rule-based translation system.
In Proceedings of the Second Workshop on Statisti-
cal Machine Translation, StatMT ?07, pages 220?223,
Stroudsburg, PA, USA. Association for Computational
Linguistics.
E. Matusov, N. Ueffing, and H. Ney. 2006. Computing
Consensus Translation from Multiple Machine Trans-
lation Systems Using Enhanced Hypotheses Align-
ment. In Conference of the European Chapter of the
Association for Computational Linguistics (EACL),
pages 33?40.
E. Matusov, G. Leusch, R.E. Banchs, N. Bertoldi,
D. Dechelotte, M. Federico, M. Kolss, Y.-S. Lee,
J.B. Mari no, M. Paulik, S. Roukos, H. Schwenk, and
H. Ney. 2008. System Combination for Machine
Translation of Spoken and Written Language. IEEE
Transactions on Audio, Speech and Language Pro-
cessing, 16(7):1222?1237.
J.A. Nelder and R. Mead. 1965. The Downhill Simplex
Method. Computer Journal, 7:308.
J. Niehues and M. Kolss. 2009. A POS-Based Model for
Long-Range Reorderings in SMT. In Fourth Work-
shop on Statistical Machine Translation (WMT 2009),
Athens, Greece.
F.J. Och and H. Ney. 2003. A Systematic Comparison of
Various Statistical Alignment Models. Computational
Linguistics, 29(1):19?51.
F.J. Och. 2003. Minimum Error Rate Training for Statis-
tical Machine Translation. In Proc. Annual Meeting of
the Association for Computational Linguistics, pages
160?167, Sapporo, Japan, July.
A. Birch P. Koehn, H. Hoang, C. Callison-Burch, M. Fed-
erico, N. Bertoldi, B. Cowan, W. Shen, C. Moran,
R. Zens, C. Dyer, O. Bojar, A. Constantin, and
E. Herbst. 2007. Moses: open source toolkit for
statistical machine translation. In Proceedings of the
45th Annual Meeting of the ACL on Interactive Poster
and Demonstration Sessions, ACL ?07, pages 177?
180, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.
K. Rottmann and S. Vogel. 2007. Word Reordering in
Statistical Machine Translation with a POS-Based Dis-
tortion Model. In TMI, Sko?vde, Sweden.
H. Schmid. 1994. Probabilistic Part-of-Speech Tagging
Using Decision Trees. In International Conference
on NewMethods in Language Processing, Manchester,
UK.
A. Stolcke. 2002. SRILM - an extensible language mod-
eling toolkit. In Proc. Int. Conf. on Spoken Language
Processing, volume 2, pages 901?904, Denver, Col-
orado, USA, September.
C. Tillmann. 2004. A unigram orientation model for sta-
tistical machine translation. In Proceedings of HLT-
NAACL 2004, pages 101?104. Association for Com-
putational Linguistics.
A. Venugopal, A. Zollman, and A. Waibel. 2005. Train-
ing and Evaluation Error Minimization Rules for Sta-
tistical Machine Translation. In Workshop on Data-
drive Machine Translation and Beyond (WPT-05), Ann
Arbor, MI.
D. Vilar, S. Stein, M. Huck, and H. Ney. 2010. Jane:
Open Source Hierarchical Translation, Extended with
Reordering and Lexicon Models. In ACL 2010 Joint
Fifth Workshop on Statistical Machine Translation and
Metrics MATR, pages 262?270, Uppsala, Sweden,
July.
S. Vogel. 2003. SMT Decoder Dissected: Word Re-
ordering. In Int. Conf. on Natural Language Process-
ing and Knowledge Engineering, Beijing, China.
J. Wuebker, A. Mauser, and H. Ney. 2010. Training
Phrase Translation Models with Leaving-One-Out. In
Proceedings of the 48th Annual Meeting of the Assoc.
for Computational Linguistics, pages 475?484, Upp-
sala, Sweden, July.
R. Zens and H. Ney. 2006. N-gram Posterior Proba-
bilities for Statistical Machine Translation. In Human
Language Technology Conf. / North American Chap-
ter of the Assoc. for Computational Linguistics Annual
Meeting (HLT-NAACL), Workshop on Statistical Ma-
chine Translation, pages 72?77, New York City, June.
R. Zens and H. Ney. 2008. Improvements in Dynamic
Programming Beam Search for Phrase-based Statisti-
cal Machine Translation. In Proc. of the Int. Workshop
on Spoken Language Translation (IWSLT), Honolulu,
Hawaii, October.
364
Proceedings of the 6th Workshop on Statistical Machine Translation, pages 405?412,
Edinburgh, Scotland, UK, July 30?31, 2011. c?2011 Association for Computational Linguistics
The RWTH Aachen Machine Translation System for WMT 2011
Matthias Huck, Joern Wuebker, Christoph Schmidt, Markus Freitag, Stephan Peitz,
Daniel Stein, Arnaud Dagnelies, Saab Mansour, Gregor Leusch and Hermann Ney
RWTH Aachen University
Aachen, Germany
surname@cs.rwth-aachen.de
Abstract
This paper describes the statistical machine
translation (SMT) systems developed by
RWTH Aachen University for the translation
task of the EMNLP 2011 Sixth Workshop on
Statistical Machine Translation. Both phrase-
based and hierarchical SMT systems were
trained for the constrained German-English
and French-English tasks in all directions. Ex-
periments were conducted to compare differ-
ent training data sets, training methods and op-
timization criteria, as well as additional mod-
els on dependency structure and phrase re-
ordering. Further, we applied a system com-
bination technique to create a consensus hy-
pothesis from several different systems.
1 Overview
We sketch the baseline architecture of RWTH?s se-
tups for the WMT 2011 shared translation task by
providing an overview of our translation systems in
Section 2. In addition to the baseline features, we
adopted several novel methods, which will be pre-
sented in Section 3. Details on the respective se-
tups and translation results for the French-English
and German-English language pairs (in both trans-
lation directions) are given in Sections 4 and 5. We
finally conclude the paper in Section 6.
2 Translation Systems
For the WMT 2011 evaluation we utilized RWTH?s
state-of-the-art phrase-based and hierarchical trans-
lation systems as well as our in-house system com-
bination framework. GIZA++ (Och and Ney, 2003)
was employed to train word alignments, language
models have been created with the SRILM toolkit
(Stolcke, 2002).
2.1 Phrase-Based System
We applied a phrase-based translation (PBT) system
similar to the one described in (Zens and Ney, 2008).
Phrase pairs are extracted from a word-aligned bilin-
gual corpus and their translation probability in both
directions is estimated by relative frequencies. The
standard feature set moreover includes an n-gram
language model, phrase-level single-word lexicons
and word-, phrase- and distortion-penalties. To lexi-
calize reordering, a discriminative reordering model
(Zens and Ney, 2006a) is used. Parameters are opti-
mized with the Downhill-Simplex algorithm (Nelder
and Mead, 1965) on the word graph.
2.2 Hierarchical System
For the hierarchical setups described in this paper,
the open source Jane toolkit (Vilar et al, 2010) was
employed. Jane has been developed at RWTH and
implements the hierarchical approach as introduced
by Chiang (2007) with some state-of-the-art exten-
sions. In hierarchical phrase-based translation, a
weighted synchronous context-free grammar is in-
duced from parallel text. In addition to contiguous
lexical phrases, hierarchical phrases with up to two
gaps are extracted. The search is typically carried
out using the cube pruning algorithm (Huang and
Chiang, 2007). The standard models integrated into
our Jane systems are: phrase translation probabil-
ities and lexical translation probabilities on phrase
level, each for both translation directions, length
405
penalties on word and phrase level, three binary fea-
tures marking hierarchical phrases, glue rule, and
rules with non-terminals at the boundaries, source-
to-target and target-to-source phrase length ratios,
four binary count features and an n-gram language
model. The model weights are optimized with stan-
dard MERT (Och, 2003) on 100-best lists.
2.3 System Combination
System combination is used to produce consensus
translations from multiple hypotheses produced with
different translation engines that are better in terms
of translation quality than any of the individual hy-
potheses. The basic concept of RWTH?s approach
to machine translation system combination has been
described by Matusov et al (Matusov et al, 2006;
Matusov et al, 2008). This approach includes an
enhanced alignment and reordering framework. A
lattice is built from the input hypotheses. The trans-
lation with the best score within the lattice according
to a couple of statistical models is selected as con-
sensus translation.
3 Translation Modeling
We incorporated several novel methods into our sys-
tems for the WMT 2011 evaluation. This section
provides a short survey of three of the methods
which we suppose to be of particular interest.
3.1 Language Model Data Selection
For the English and German language models,
we applied the data selection method proposed in
(Moore and Lewis, 2010). Each sentence is scored
by the difference in cross-entropy between a lan-
guage model trained from in-domain data and a lan-
guage model trained from a similar-sized sample of
the out-of-domain data. As in-domain data we used
the news-commentary corpus. The out-of-domain
data from which the data was selected are the news
crawl corpus for both languages and for English the
109 corpus and the LDC Gigaword data. We used a
3-gram trained with the SRI toolkit to compute the
cross-entropy. For the news crawl corpus, only 1/8
of the sentences were discarded. Of the 109 corpus
we retained 1/2 and of the LDC Gigaword data we
retained 1/4 of the sentences to train the language
models.
3.2 Phrase Model Training
For the German?English and French?English
translation tasks we applied a forced alignment pro-
cedure to train the phrase translation model with the
EM algorithm, similar to the one described in (DeN-
ero et al, 2006). Here, the phrase translation prob-
abilities are estimated from their relative frequen-
cies in the phrase-aligned training data. The phrase
alignment is produced by a modified version of the
translation decoder. In addition to providing a statis-
tically well-founded phrase model, this has the ben-
efit of producing smaller phrase tables and thus al-
lowing more rapid experiments. A detailed descrip-
tion of the training procedure is given in (Wuebker
et al, 2010).
3.3 Soft String-to-Dependency
Given a dependency tree of the target language,
we are able to introduce language models that span
over longer distances than the usual n-grams, as in
(Shen et al, 2008). To obtain dependency structures,
we apply the Stanford parser (Klein and Manning,
2003) on the target side of the training material.
RWTH?s open source hierarchical translation toolkit
Jane has been extended to include dependency infor-
mation in the phrase table and to build dependency
trees on the output hypotheses at decoding time from
this information.
Shen et al (2008) use only phrases that meet cer-
tain restrictions. The first possibility is what the au-
thors call a fixed dependency structure. With the
exception of one word within this phrase, called
the head, no outside word may have a dependency
within this phrase. Also, all inner words may only
depend on each other or on the head. For a second
structure, called a floating dependency structure, the
head dependency word may also exist outside the
phrase. If the dependency structure of a phrase con-
forms to these restrictions, it is denoted as valid.
In our phrase table, we mark those phrases that
possess a valid dependency structure with a binary
feature, but all phrases are retained as translation op-
tions. In addition to storing the dependency informa-
tion, we also memorize for all hierarchical phrases
if the content of gaps has been dependent on the left
or on the right side. We utilize the dependency in-
formation during the search process by adding three
406
French English
Sentences 3 710 985
Running Words 98 352 916 87 689 253
Vocabulary 179 548 216 765
Table 1: Corpus statistics of the preprocessed high-
quality training data (Europarl, news-commentary, and
selected parts of the 109 and UN corpora) for the
RWTH systems for the WMT 2011 French?English and
English?French translation tasks. Numerical quantities
are replaced by a single category symbol.
features to the log-linear model: merging errors to
the left, merging errors to the right, and the ratio of
valid vs. non-valid dependency structures. The de-
coder computes the corresponding costs when it tries
to construct a dependency tree of a (partial) hypothe-
sis on-the-fly by merging the dependency structures
of the used phrase pairs.
In an n-best reranking step, we compute depen-
dency language model scores on the dependencies
which were assembled on the hypotheses by the
search procedure. We apply one language model
for left-side dependencies and one for right-side de-
pendencies. For head structures, we also compute
their scores by exploiting a simple unigram language
model. We furthermore include a language count
feature that is incremented each time we compute
a dependency language model score. As trees with
few dependencies have less individual costs to be
computed, they tend to obtain lower overall costs
than trees with more complex structures in other
sentences. The intention behind this feature is thus
comparable to the word penalty in combination with
a normal n-gram language model.
4 French-English Setups
We set up both hierarchical and standard phrase-
based systems for the constrained condition of the
WMT 2011 French?English and English?French
translation tasks. The English?French RWTH pri-
mary submission was produced with a single hierar-
chical system, while a system combination of three
systems was used to generate a final hypothesis for
the French?English primary submission.
Besides the Europarl and news-commentary cor-
pora, the provided parallel data also comprehends
French English
Sentences 29 996 228
Running Words 916 347 538 778 544 843
Vocabulary 1 568 089 1 585 093
Table 2: Corpus statistics of the preprocessed full training
data for the RWTH primary system for the WMT 2011
English?French translation task. Numerical quantities
are replaced by a single category symbol.
the large French-English 109 corpus and the French-
English UN corpus. Since model training with
such a huge amount of data requires a consider-
able computational effort, RWTH decided to select
a high-quality part of altogether about 2 Mio. sen-
tence pairs from the latter two corpora. The selec-
tion of parallel sentences was carried out according
to three criteria: (1) Only sentences of minimum
length of 4 tokens are considered, (2) at least 92%
of the vocabulary of each sentence occurs in new-
stest2008, and (3) the ratio of the vocabulary size
of a sentence and the number of its tokens is mini-
mum 80%. Word alignments in both directions were
trained with GIZA++ and symmetrized according to
the refined method that was proposed in (Och and
Ney, 2003). The phrase tables of the translation
systems are extracted from the Europarl and news-
commentary parallel training data as well as the se-
lected high-quality parts the 109 and UN corpora
only. The only exception is the hierarchical system
used for the English?French RWTH primary sub-
mission which comprehends a second phrase table
with lexical (i.e. non-hierarchical) phrases extracted
from the full parallel data (approximately 30 Mio.
sentence pairs).
Detailed statistics of the high-quality parallel
training data (Europarl, news-commentary, and the
selected parts of the 109 and UN corpora) are given
in Table 1, the corpus statistics of the full parallel
data from which the second phrase table with lexi-
cal phrases for the English?French RWTH primary
system was created are presented in Table 2.
The translation systems use large 4-gram lan-
guage models with modified Kneser-Ney smooth-
ing. The French language model was trained on
most of the provided French data including the
monolingual LDC Gigaword corpora, the English
407
newstest2009 newstest2010
French?English BLEU TER BLEU TER
System combination of ? systems (primary) 26.7 56.0 27.4 54.9
PBT with triplet lexicon, no forced alignment (contrastive) ? 26.2 56.7 27.2 55.3
Jane as below + improved LM (contrastive) 26.3 57.4 26.7 56.2
Jane with parse match + syntactic labels + dependency ? 26.2 57.5 26.5 56.4
PBT with forced alignment phrase training ? 26.0 57.1 26.3 56.0
Table 3: RWTH systems for the WMT 2011 French?English translation task (truecase). BLEU and TER results are
in percentage.
newstest2009 newstest2010
English?French BLEU TER BLEU TER
Jane shallow + in-domain TM + lexical phrases from full data 25.3 60.1 27.1 57.2
Jane shallow + in-domain TM + triplets + DWL + parse match 24.8 60.5 26.6 57.5
PBT with triplets, DWL, sentence-level word lexicon, discrim. reord. 24.8 60.1 26.5 57.3
Table 4: RWTH systems for the WMT 2011 English?French translation task (truecase). BLEU and TER results are
in percentage.
language model was trained on automatically se-
lected English data (cf. Section 3.1) from the pro-
vided resources including the 109 corpus and LDC
Gigaword.
The scaling factors of the log-linear model com-
bination are optimized towards BLEU on new-
stest2009, newstest2010 is used as an unseen test set.
4.1 Experimental Results French?English
The results for the French?English task are given in
Table 3. RWTH?s three submissions ? one primary
and two contrastive ? are labeled accordingly in the
table. The first contrastive submission is a phrase-
based system with a standard feature set plus an ad-
ditional triplet lexicon model (Mauser et al, 2009).
The triplet lexicon model was trained on in-domain
news commentary data only. The second contrastive
submission is a hierarchical Jane system with three
syntax-based extensions: A parse match model (Vi-
lar et al, 2008), soft syntactic labels (Stein et al,
2010), and the soft string-to-dependency extension
as described in Section 3.3. The primary submis-
sion combines the phrase-based contrastive system,
a hierarchical system that is very similar to the Jane
contrastive submission but with a slightly worse lan-
guage model, and an additional PBT system that has
been trained with forced alignment (Wuebker et al,
2010) on WMT 2010 data only.
4.2 Experimental Results English?French
The results for the English?French task are given
in Table 4. We likewise submitted two contrastive
systems for this translation direction. The first con-
trastive submission is a phrase-based system, en-
hanced with a triplet lexicon model and a discrim-
inative word lexicon model (Mauser et al, 2009) ?
both trained on in-domain news commentary data
only ? as well as a sentence-level single-word lex-
icon model and a discriminative reordering model
(Zens and Ney, 2006a). The second contrastive sub-
mission is a hierarchical Jane system with shallow
rules (Iglesias et al, 2009), a triplet lexicon model, a
discriminative word lexicon, the parse match model,
and a second phrase table extracted from in-domain
data only. Our primary submission is very similar
to the latter Jane setup. It does not comprise the ex-
tended lexicon models and the parse match exten-
sion, but instead includes lexical phrases from the
full 30 Mio. sentence corpus as described above.
5 German-English Setups
We trained phrase-based and hierarchical transla-
tion systems for both translation directions of the
German-English language pair. The corpus statis-
408
German English
Sentences 1 857 745
Running Words 48 449 977 50 559 217
Vocabulary 387 593 123 470
Table 5: Corpus statistics of the preprocessed train-
ing data for the WMT 2011 German?English and
English?German translation tasks. Numerical quantities
are replaced by a single category symbol.
tics can be found in Table 5. Word alignments were
generated with GIZA++ and symmetrized as for the
French-English setups.
The language models are 4-grams trained on the
bilingual data as well as the provided News crawl
corpus. For the English language model the 109
French-English and LDC Gigaword corpora were
used additionally. For the 109 French-English and
LDC Gigaword corpora RWTH applied the data se-
lection technique described in Section 3.1. We ex-
amined two different language models, one with
LDC data and one without.
Systems were optimized on the newstest2009 data
set, newstest2008 was used as test set. The scores
for newstest2010 are included for completeness.
5.1 Morpho-Syntactic Analysis
In order to reduce the source vocabulary size for
the German?English translation, the source side
was preprocessed by splitting German compound
words with the frequency-based method described
in (Koehn and Knight, 2003). To further reduce
translation complexity, we performed the long-range
part-of-speech based reordering rules proposed by
(Popovic? et al, 2006). For additional experiments
we used the TreeTagger (Schmid, 1995) to produce
a lemmatized version of the German source.
5.2 Optimization Criterion
We studied the impact of different optimization cri-
teria on tranlsation performance. The usual prac-
tice is to optimize the scaling factors to maximize
BLEU. We also experimented with two different
combinations of BLEU and Translation Edit Rate
(TER): TER?BLEU and TER?4BLEU. The first
denotes the equally weighted combination, while for
the latter BLEU is weighted 4 times as strong as
TER.
5.3 Experimental Results German?English
For the German?English task we conducted ex-
periments comparing the standard phrase extraction
with the phrase training technique described in Sec-
tion 3.2. For the latter we applied log-linear phrase-
table interpolation as proposed in (Wuebker et al,
2010). Further experiments included the use of addi-
tional language model training data, reranking of n-
best lists generated by the phrase-based system, and
different optimization criteria. We also carried out
a system combination of several systems, including
phrase-based systems on lemmatized German and
on source data without compound splitting and two
hierarchical systems optimized for different criteria.
The results are given in Table 6.
A considerable increase in translation quality can
be achieved by application of German compound
splitting. The system that operates on German
surface forms without compound splitting (SUR)
clearly underperforms the baseline system with mor-
phological preprocessing. The system on lemma-
tized German (LEM) is at about the same level as
the system on surface forms.
In comparison to the standard heuristic phrase ex-
traction technique, performing phrase training (FA)
gives an improvement in BLEU on newstest2008
and newstest2009, but a degradation in TER. The
addition of LDC Gigaword corpora (+GW) to the
language model training data shows improvements
in both BLEU and TER. Reranking was done on
1000-best lists generated by the the best available
system (PBT (FA)+GW). Following models were
applied: n-gram posteriors (Zens and Ney, 2006b),
sentence length model, a 6-gram LM and single-
word lexicon models in both normal and inverse di-
rection. These models are combined in a log-linear
fashion and the scaling factors are tuned in the same
manner as the baseline system (using TER?4BLEU
on newstest2009).
The table includes three identical Jane systems
which are optimized for different criteria. The one
optimized for TER?4BLEU offers the best balance
between BLEU and TER, but was not finished in
time for submission. As primary submission we
chose the reranked PBT system, as secondary the
system combination.
409
newstest2008 newstest2009 newstest2010
German?English opt criterion BLEU TER BLEU TER BLEU TER
Syscombi of ? (secondary) TER?BLEU 21.1 62.1 20.8 61.2 23.7 59.2
Jane +GW ? BLEU 21.5 63.9 21.0 63.3 22.9 61.7
Jane +GW TER?4BLEU 21.4 62.6 21.1 62.0 23.5 60.3
PBT (FA) rerank +GW (primary) ? TER?4BLEU 21.4 62.8 21.1 61.9 23.4 60.1
PBT (FA) +GW ? TER?4BLEU 21.1 63.0 21.1 62.2 23.3 60.3
Jane +GW ? TER?BLEU 20.9 61.1 20.4 60.5 23.4 58.3
PBT (FA) TER?4BLEU 21.1 63.2 20.6 62.4 23.2 60.4
PBT TER?4BLEU 20.6 62.7 20.3 61.9 23.3 59.7
PBT (SUR) ? TER?4BLEU 19.5 66.5 18.9 65.8 21.0 64.9
PBT (LEM) ? TER?4BLEU 19.2 66.1 18.9 65.4 21.0 63.5
Table 6: RWTH systems for the WMT 2011 German?English translation task (truecase). BLEU and TER results
are in percentage. FA denotes systems with phrase training, +GW the use of LDC data for the language model.
SUR and LEM denote the systems without compound splitting and on the lemmatized source, respectively. The three
hierarchical Jane systems are identical, but used different parameter optimization criterea.
newstest2008 newstest2009 newstest2010
English?German opt criterion BLEU TER BLEU TER BLEU TER
PBT + discrim. reord. (primary) TER?4BLEU 15.3 70.2 15.1 69.8 16.2 65.6
PBT + discrim. reord. BLEU 15.2 70.6 15.2 70.1 16.2 66.0
PBT TER?4BLEU 15.2 70.7 15.2 70.2 16.2 66.1
Jane BLEU 15.1 72.1 15.4 71.2 16.4 67.4
Jane TER?4BLEU 15.1 68.4 14.6 69.5 14.6 65.9
Table 7: RWTH systems for the WMT 2011 English?German translation task (truecase). BLEU and TER results are
in percentage.
5.4 Experimental Results English?German
We likewise studied the effect of using BLEU only
versus using TER?4BLEU as optimization crite-
rion in the English?German translation direction.
Moreover, we tested the impact of the discriminative
reordering model (Zens and Ney, 2006a). The re-
sults can be found in Table 7. For the phrase-based
system, optimizing towards TER?4BLEU leads to
slightly better results both in BLEU and TER than
optimizing towards BLEU. Using the discriminative
reordering model yields some improvements both on
newstest2008 and newstest2010. In the case of the
hierarchical system, the effect of the optimization
criterion is more pronounced than for the phrase-
based system. However, in this case it clearly leads
to a tradeoff between BLEU and TER, as the choice
of TER?4BLEU harms the translation results of
test2010 with respect to BLEU.
6 Conclusion
For the participation in the WMT 2011 shared trans-
lation task, RWTH experimented with both phrase-
based and hierarchical translation systems. We used
all bilingual and monolingual data provided for the
constrained track. To limit the size of the lan-
guage model, a data selection technique was applied.
Several techniques yielded improvements over the
baseline, including three syntactic models, extended
lexicon models, a discriminative reordering model,
forced alignment training, reranking methods and
different optimization criteria.
Acknowledgments
This work was achieved as part of the Quaero Pro-
gramme, funded by OSEO, French State agency for
innovation.
410
References
D. Chiang. 2007. Hierarchical Phrase-Based Transla-
tion. Computational Linguistics, 33(2):201?228.
J. DeNero, D. Gillick, J. Zhang, and D. Klein. 2006.
Why Generative Phrase Models Underperform Surface
Heuristics. In Proceedings of the Workshop on Statis-
tical Machine Translation, pages 31?38.
L. Huang and D. Chiang. 2007. Forest Rescoring: Faster
Decoding with Integrated Language Models. In Proc.
Annual Meeting of the Association for Computational
Linguistics, pages 144?151, Prague, Czech Republic,
June.
G. Iglesias, A. de Gispert, E.R. Banga, and W. Byrne.
2009. Rule Filtering by Pattern for Efficient Hierar-
chical Translation. In Proceedings of the 12th Con-
ference of the European Chapter of the ACL (EACL
2009), pages 380?388.
D. Klein and C.D. Manning. 2003. Accurate Unlexi-
calized Parsing. In Proceedings of the 41st Annual
Meeting on Association for Computational Linguistics
- Volume 1, ACL ?03, pages 423?430.
P. Koehn and K. Knight. 2003. Empirical Methods
for Compound Splitting. In Proceedings of European
Chapter of the ACL (EACL 2009), pages 187?194.
E. Matusov, N. Ueffing, and H. Ney. 2006. Computing
Consensus Translation from Multiple Machine Trans-
lation Systems Using Enhanced Hypotheses Align-
ment. In Conference of the European Chapter of the
Association for Computational Linguistics (EACL),
pages 33?40.
E. Matusov, G. Leusch, R.E. Banchs, N. Bertoldi,
D. Dechelotte, M. Federico, M. Kolss, Y.-S. Lee,
J.B. Marino, M. Paulik, S. Roukos, H. Schwenk, and
H. Ney. 2008. System Combination for Machine
Translation of Spoken and Written Language. IEEE
Transactions on Audio, Speech and Language Pro-
cessing, 16(7):1222?1237.
A. Mauser, S. Hasan, and H. Ney. 2009. Extending Sta-
tistical Machine Translation with Discriminative and
Trigger-Based Lexicon Models. In Conference on
Empirical Methods in Natural Language Processing,
pages 210?217.
R.C. Moore and W. Lewis. 2010. Intelligent Selection
of Language Model Training Data. In ACL (Short Pa-
pers), pages 220?224, Uppsala, Sweden, July.
J.A. Nelder and R. Mead. 1965. The Downhill Simplex
Method. Computer Journal, 7:308.
F.J. Och and H. Ney. 2003. A Systematic Comparison of
Various Statistical Alignment Models. Computational
Linguistics, 29(1):19?51.
F.J. Och. 2003. Minimum Error Rate Training for Statis-
tical Machine Translation. In Proc. Annual Meeting of
the Association for Computational Linguistics, pages
160?167, Sapporo, Japan, July.
M. Popovic?, D. Stein, and H. Ney. 2006. Statistical
Machine Translation of German Compound Words.
In FinTAL - 5th International Conference on Natural
Language Processing, Springer Verlag, LNCS, pages
616?624.
H. Schmid. 1995. Improvements in Part-of-Speech Tag-
ging with an Application to German. In Proceedings
of the ACL SIGDAT-Workshop, pages 47?50, Dublin,
Ireland, March.
L. Shen, J. Xu, and R. Weischedel. 2008. A New String-
to-Dependency Machine Translation Algorithm with a
Target Dependency Language Model. In Proceedings
of ACL-08: HLT. Association for Computational Lin-
guistics, pages 577?585, June.
D. Stein, S. Peitz, D. Vilar, and H. Ney. 2010. A Cocktail
of Deep Syntactic Features for Hierarchical Machine
Translation. In Conference of the Association for Ma-
chine Translation in the Americas 2010, page 9, Den-
ver, USA, October.
A. Stolcke. 2002. SRILM - an extensible language mod-
eling toolkit. In Proc. Int. Conf. on Spoken Language
Processing, volume 2, pages 901 ? 904, Denver, Col-
orado, USA, September.
D. Vilar, D. Stein, and H. Ney. 2008. Analysing Soft
Syntax Features and Heuristics for Hierarchical Phrase
Based Machine Translation. In Proc. of the Int. Work-
shop on Spoken Language Translation (IWSLT), pages
190?197, Waikiki, Hawaii, October.
D. Vilar, S. Stein, M. Huck, and H. Ney. 2010. Jane:
Open Source Hierarchical Translation, Extended with
Reordering and Lexicon Models. In ACL 2010 Joint
Fifth Workshop on Statistical Machine Translation and
Metrics MATR, pages 262?270, Uppsala, Sweden,
July.
J. Wuebker, A. Mauser, and H. Ney. 2010. Training
Phrase Translation Models with Leaving-One-Out. In
Proceedings of the 48th Annual Meeting of the Assoc.
for Computational Linguistics, pages 475?484, Upp-
sala, Sweden, July.
R. Zens and H. Ney. 2006a. Discriminative Reordering
Models for Statistical Machine Translation. In Human
Language Technology Conf. / North American Chap-
ter of the Assoc. for Computational Linguistics Annual
Meeting (HLT-NAACL), Workshop on Statistical Ma-
chine Translation, pages 55?63, New York City, June.
R. Zens and H. Ney. 2006b. N-gram Posterior Proba-
bilities for Statistical Machine Translation. In Human
Language Technology Conf. / North American Chap-
ter of the Assoc. for Computational Linguistics Annual
Meeting (HLT-NAACL), Workshop on Statistical Ma-
chine Translation, pages 72?77, New York City, June.
411
R. Zens and H. Ney. 2008. Improvements in Dynamic
Programming Beam Search for Phrase-based Statisti-
cal Machine Translation. In Proc. of the Int. Workshop
on Spoken Language Translation (IWSLT), Honolulu,
Hawaii, October.
412
Proceedings of the 7th Workshop on Statistical Machine Translation, pages 304?311,
Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational Linguistics
The RWTH Aachen Machine Translation System for WMT 2012
Matthias Huck, Stephan Peitz, Markus Freitag, Malte Nuhn and Hermann Ney
Human Language Technology and Pattern Recognition Group
Computer Science Department
RWTH Aachen University
D-52056 Aachen, Germany
<surname>@cs.rwth-aachen.de
Abstract
This paper describes the statistical ma-
chine translation (SMT) systems developed at
RWTH Aachen University for the translation
task of the NAACL 2012 Seventh Workshop on
Statistical Machine Translation (WMT 2012).
We participated in the evaluation campaign
for the French-English and German-English
language pairs in both translation directions.
Both hierarchical and phrase-based SMT sys-
tems are applied. A number of different tech-
niques are evaluated, including an insertion
model, different lexical smoothing methods,
a discriminative reordering extension for the
hierarchical system, reverse translation, and
system combination. By application of these
methods we achieve considerable improve-
ments over the respective baseline systems.
1 Introduction
For the WMT 2012 shared translation task1 RWTH
utilized state-of-the-art phrase-based and hierarchi-
cal translation systems as well as an in-house sys-
tem combination framework. We give a survey of
these systems and the basic methods they implement
in Section 2. For both the French-English (Sec-
tion 3) and the German-English (Section 4) language
pair, we investigate several different advanced tech-
niques. We concentrate on specific research direc-
tions for each of the translation tasks and present the
respective techniques along with the empirical re-
sults they yield: For the French?English task (Sec-
tion 3.1), we apply a standard phrase-based system.
1http://www.statmt.org/wmt12/
translation-task.html
For the English?French task (Section 3.2), we aug-
ment a hierarchical phrase-based setup with a num-
ber of enhancements like an insertion model, dif-
ferent lexical smoothing methods, and a discrimina-
tive reordering extension. For the German?English
(Section 4.3) and English?German (Section 4.4)
tasks, we utilize morpho-syntactic analysis to pre-
process the data (Section 4.1) and employ sys-
tem combination to produce a consensus hypothesis
from normal and reverse translations (Section 4.2) of
phrase-based and hierarchical phrase-based setups.
2 Translation Systems
2.1 Phrase-Based System
The phrase-based translation (PBT) system used
in this work is an in-house implementation of the
state-of-the-art decoder described in (Zens and Ney,
2008). We use the standard set of models with
phrase translation probabilities and lexical smooth-
ing in both directions, word and phrase penalty,
distance-based distortion model, an n-gram target
language model and three binary count features. The
parameter weights are optimized with minimum er-
ror rate training (MERT) (Och, 2003).
2.2 Hierarchical Phrase-Based System
For our hierarchical phrase-based translation
(HPBT) setups, we employ the open source trans-
lation toolkit Jane (Vilar et al, 2010; Stein et
al., 2011; Vilar et al, 2012), which has been
developed at RWTH and is freely available for
non-commercial use. In hierarchical phrase-based
translation (Chiang, 2007), a weighted synchronous
context-free grammar is induced from parallel text.
304
In addition to contiguous lexical phrases, hierar-
chical phrases with up to two gaps are extracted.
The search is carried out with a parsing-based
procedure. The standard models integrated into our
Jane systems are: phrase translation probabilities
and lexical smoothing probabilities in both trans-
lation directions, word and phrase penalty, binary
features marking hierarchical phrases, glue rule,
and rules with non-terminals at the boundaries,
four binary count features, and an n-gram language
model. Optional additional models comprise IBM
model 1 (Brown et al, 1993), discriminative word
lexicon (DWL) models and triplet lexicon models
(Mauser et al, 2009), discriminative reordering ex-
tensions (Huck et al, 2011a), insertion and deletion
models (Huck and Ney, 2012), and several syntactic
enhancements like preference grammars (Stein
et al, 2010) and string-to-dependency features
(Peter et al, 2011). We utilize the cube pruning
algorithm (Huang and Chiang, 2007) for decoding
and optimize the model weights with MERT.
2.3 System Combination
System combination is used to produce consen-
sus translations from multiple hypotheses generated
with different translation engines. The basic concept
of RWTH?s approach to machine translation system
combination is described in (Matusov et al, 2006;
Matusov et al, 2008). This approach includes an
enhanced alignment and reordering framework. A
lattice is built from the input hypotheses. The trans-
lation with the best score within the lattice according
to a couple of statistical models is selected as con-
sensus translation.
2.4 Other Tools and Techniques
We employ GIZA++ (Och and Ney, 2003) to train
word alignments. The two trained alignments are
heuristically merged to obtain a symmetrized word
alignment for phrase extraction. All language mod-
els (LMs) are created with the SRILM toolkit (Stol-
cke, 2002) and are standard 4-gram LMs with in-
terpolated modified Kneser-Ney smoothing (Kneser
and Ney, 1995; Chen and Goodman, 1998). We
evaluate in truecase, using the BLEU (Papineni et al,
2002) and TER (Snover et al, 2006) measures.
French English
EP + NC Sentences 2.1M
Running Words 63.3M 57.6M
Vocabulary 147.8K 128.5K
Singletons 5.4K 5.1K
+ 109 Sentences 22.9M
Running Words 728.6M 624.0M
Vocabulary 1.7M 1.7M
Singletons 0.8M 0.8M
+ UN Sentences 35.4M
Running Words 1 113.5M 956.4M
Vocabulary 1.9M 2.0M
Singletons 0.9M 1.0M
Table 1: Corpus statistics of the preprocessed French-
English parallel training data. EP denotes Europarl, NC
denotes News Commentary. In the data, numerical quan-
tities have been replaced by a single category symbol.
3 French-English Setups
We trained phrase-based translation systems for
French?English and hierarchical phrase-based
translation systems for English?French. Corpus
statistics for the French-English parallel data are
given in Table 1. The LMs are 4-grams trained on
the provided resources for the respective language
(Europarl, News Commentary, UN, 109, and mono-
lingual News Crawl language model training data).2
For French?English we also investigate a smaller
English LM on Europarl and News Commentary
data only. For English?French we experiment with
additional target-side data from the LDC French Gi-
gaword Second Edition (LDC2009T28), which is an
archive of newswire text data that has been acquired
over several years by the LDC.3 The LDC French
Gigaword v2 is permitted for constrained submis-
sions in the WMT shared translation task. As a de-
velopment set for MERT, we use newstest2009 in all
setups.
3.1 Experimental Results French?English
For the French?English task, the phrase-based
SMT system (PBT) is set up using the standard mod-
els listed in Section 2.1. We vary the training data
we use to train the system and compare the results.
2The parallel 109 corpus is often also referred to as WMT
Giga French-English release 2.
3http://www.ldc.upenn.edu
305
newstest2008 newstest2009 newstest2010 newstest2011
French?English BLEU TER BLEU TER BLEU TER BLEU TER
PBT baseline 20.3 63.8 23.0 60.0 23.2 59.1 24.7 57.3
+ LM: +109+UN 22.5 61.4 26.2 57.3 26.6 56.1 27.7 54.5
+ TM: +109 23.3 60.8 27.6 56.2 27.6 55.4 29.1 53.4
Table 2: Results for the French?English task (truecase). newstest2009 is used as development set. BLEU and TER
are given in percentage.
newstest2008 newstest2009 newstest2010 newstest2011
English?French BLEU TER BLEU TER BLEU TER BLEU TER
HPBT 20.9 66.0 23.6 62.5 25.1 60.2 27.4 57.6
+ 109 and UN 22.5 63.2 25.4 59.8 27.0 57.1 29.9 53.9
+ LDC Gigaword v2 23.0 63.0 25.9 59.4 27.3 56.9 29.6 54.1
+ insertion model 23.0 62.9 26.1 59.2 27.2 56.8 30.0 53.7
+ noisy-or lexical scores 23.2 62.5 26.1 59.0 27.6 56.4 30.2 53.4
+ DWL 23.3 62.5 26.2 58.9 27.9 55.9 30.4 53.2
+ IBM-1 23.4 62.3 26.2 58.8 28.0 55.7 30.4 53.1
+ discrim. RO 23.5 62.2 26.7 58.5 28.1 55.9 30.8 52.8
Table 3: Results for the English?French task (truecase). newstest2009 is used as development set. BLEU and TER
are given in percentage.
It should be noted that these setups do not use any
English LDC Gigaword data for LM training at all.
Our baseline system uses the Europarl and News
Commentary data for training LM and phrase table.
Corpus statistics are shown in the ?EP+NC? section
of Table 1. This results in a performance of 24.7
points BLEU on newstest2011. Then we add the 109
as well as UN data and more monolingual English
data from the News Crawl corpus to the data used
for training the language model. This system ob-
tains a score of 27.7 points BLEU on newstest2011.
Our final system uses Europarl, News Commentary,
109 and UN data and News Crawl monolingual data
for LM training and the Europarl, News Commen-
tary and 109 data (Table 1) for phrase table training.
Using these data sets the system reaches 29.1 points
BLEU.
The experimental results are summarized in Ta-
ble 2.
3.2 Experimental Results English?French
For the English?French task, the baseline system is
a hierarchical phrase-based setup including the stan-
dard models as listed in Section 2.2, apart from the
binary count features. We limit the recursion depth
for hierarchical rules with a shallow-1 grammar (de
Gispert et al, 2010).
In a shallow-1 grammar, the generic non-terminal
X of the standard hierarchical approach is replaced
by two distinct non-terminals XH and XP . By
changing the left-hand sides of the rules, lexical
phrases are allowed to be derived from XP only, hi-
erarchical phrases from XH only. On all right-hand
sides of hierarchical rules, the X is replaced by XP .
Gaps within hierarchical phrases can thus solely be
filled with purely lexicalized phrases, but not a sec-
ond time with hierarchical phrases. The initial rule
is substituted with
S ? ?XP?0,XP?0?
S ? ?XH?0,XH?0? ,
(1)
and the glue rule is substituted with
S ? ?S?0XP?1, S?0XP?1?
S ? ?S?0XH?1, S?0XH?1? .
(2)
The main benefit of a restriction of the recursion
depth is a gain in decoding efficiency, thus allow-
ing us to set up systems more rapidly and to explore
more model combinations and more system config-
urations.
306
The experimental results for English?French are
given in Table 3. Starting from the shallow hi-
erarchical baseline setup on Europarl and News
Commentary parallel data only (but Europarl, News
Commentary, 109, UN, and News Crawl data for LM
training), we are able to improve translation qual-
ity considerably by first adopting more parallel (109
and UN) and monolingual (French LDC Gigaword
v2) training resources and then employing several
different models that are not included in the baseline
already. We proceed with individual descriptions of
the methods we use and report their respective effect
in BLEU on the test sets.
109 and UN (up to +2.5 points BLEU) While the
amount of provided parallel data from Europarl
and News Commentary sources is rather lim-
ited (around 2M sentence pairs in total), the
UN and the 109 corpus each provide a substan-
tial collection of further training material. By
appending both corpora, we end up at roughly
35M parallel sentences (cf. Table 1). We utilize
this full amount of data in our system, but ex-
tract a phrase table with only lexical (i.e. non-
hierarchical) phrases from the full parallel data.
We add it as a second phrase table to the base-
line system, with a binary feature that enables
the system to reward or penalize the application
of phrases from this table.
LDC Gigaword v2 (up to +0.5 points BLEU)
The LDC French Gigaword Second Edition
(LDC2009T28) provides some more monolin-
gual French resources. We include a total of
28.2M sentences from both the AFP and APW
collections in our LM training data.
insertion model (up to +0.4 points BLEU) We add
an insertion model to the log-linear model com-
bination. This model is designed as a means to
avoid the omission of content words in the hy-
potheses. It is implemented as a phrase-level
feature function which counts the number of in-
serted words. We apply the model in source-to-
target and target-to-source direction. A target-
side word is considered inserted based on lexi-
cal probabilities with the words on the foreign
language side of the phrase, and vice versa for
a source-side word. As thresholds, we compute
individual arithmetic averages for each word
from the vocabulary (Huck and Ney, 2012).
noisy-or lexical scores (up to +0.4 points BLEU) In
our baseline system, the tNorm(?) lexical scor-
ing variant as described in (Huck et al, 2011a)
is employed with a relative frequency (RF) lex-
icon model for phrase table smoothing. The
single-word based translation probabilities of
the RF lexicon model are extracted from word-
aligned parallel training data, in the fashion
of (Koehn et al, 2003). We exchange the base-
line lexical scoring with a noisy-or (Zens and
Ney, 2004) lexical scoring variant tNoisyOr(?).
DWL (up to +0.3 points BLEU) We augment
our system with phrase-level lexical scores
from discriminative word lexicon (DWL) mod-
els (Mauser et al, 2009; Huck et al, 2011a)
in both source-to-target and target-to-source di-
rection. The DWLs are trained on News Com-
mentary data only.
IBM-1 (up to +0.1 points BLEU) On News Com-
mentary and Europarl data, we train IBM
model-1 (Brown et al, 1993) lexicons in both
translation directions and also use them to com-
pute phrase-level scores.
discrim. RO (up to +0.4 points BLEU) The modi-
fication of the grammar to a shallow-1 version
restricts the search space of the decoder and is
convenient to prevent overgeneration. In order
not to be too restrictive, we reintroduce more
flexibility into the search process by extending
the grammar with specific reordering rules
XP ? ?XP?0XP?1,XP?1XP?0?
XP ? ?XP?0XP?1,XP?0XP?1? .
(3)
The upper rule in Equation (3) is a swap rule
that allows adjacent lexical phrases to be trans-
posed, the lower rule is added for symmetry
reasons, in particular because sequences as-
sembled with these rules are allowed to fill gaps
within hierarchical phrases. Note that we apply
a length constraint of 10 to the number of ter-
minals spanned by an XP . We introduce two
binary indicator features, one for each of the
two rules in Equation (3). In addition to adding
307
German English
Sentences 2.0M
Running Words 55.3M 55.7M
Vocabulary 191.6K 129.0K
Singletons 75.5K 51.8K
Table 4: Corpus statistics of the preprocessed German-
English parallel training data (Europarl and News Com-
mentary). In the data, numerical quantities have been re-
placed by a single category symbol.
these rules, a discriminatively trained lexical-
ized reordering model is applied (Huck et al,
2012).
4 German-English Setups
We trained phrase-based and hierarchical transla-
tion systems for both translation directions of the
German-English language pair. Corpus statistics for
German-English can be found in Table 4. The lan-
guage models are 4-grams trained on the respective
target side of the bilingual data as well as on the pro-
vided News Crawl corpus. For the English language
model the 109 French-English, UN and LDC Giga-
word Fourth Edition corpora are used additionally.
For the 109 French-English, UN and LDC Gigaword
corpora we apply the data selection technique de-
scribed in (Moore and Lewis, 2010). We examine
two different language models, one with LDC data
and one without. All German?English systems are
optimized on newstest2010. For English?German,
we use newstest2009 as development set. The news-
test2011 set is used as test set and the scores for new-
stest2008 are included for completeness.
4.1 Morpho-Syntactic Analysis
In order to reduce the source vocabulary size for
the German?English translation, the German text
is preprocessed by splitting German compound
words with the frequency-based method described in
(Koehn and Knight, 2003). To further reduce trans-
lation complexity of PBT, we employ the long-range
part-of-speech based reordering rules proposed by
Popovic? and Ney (2006).
4.2 Reverse Translation
For reverse translations we need to change the word
order of the bilingual corpus. For example, if we re-
verse both source and target language, the original
training example ?der Hund mag die Katze . ? the
dog likes the cat .? is converted into a new training
example ?. Katze die mag Hund der? . cat the likes
dog the?. We call this type of modification of source
or target language reversion. A system trained of
this data is called reverse. This modification changes
the corpora and hence the language model and align-
ment training produce different results.
4.3 Experimental Results German?English
Our results for the German?English task are shown
in Table 5. For this task, we apply the idea of reverse
translation for both the phrase-based and the hierar-
chical approach. It seems that the reversed systems
perform slightly worse. However, when we em-
ploy system combination using both reverse trans-
lation setups (PBT reverse and HPBT reverse) and
both baseline setups (PBT baseline and HPBT base-
line), the translation quality is improved by up to 0.4
points in BLEU and 1.0 points TER compared to the
best single system.
The addition of LDC Gigaword corpora (+GW)
to the language model training data of the baseline
setups shows improvements in both BLEU and TER.
Furthermore, with the system combination including
these setups, we are able to report an improvement
of up to 0.7 points BLEU and 1.0 points TER over the
best single setup. Compared to the system combina-
tion based on systems which are not using the LDC
Gigaword corpora, we gain 0.3 points in BLEU and
0.4 points in TER.
4.4 Experimental Results English?German
Our results for the English?German task are shown
in Table 6. For this task, we first compare sys-
tems using one, two or three language models of
different parts of the data. The language model
for systems with only one language model is cre-
ated with all monolingual and parallel data. A lan-
guage model with all monolingual data and a lan-
guage model with all parallel data is created for the
systems with two language models. For the systems
with three language models, we also split the parallel
data in two parts consisting of either only Europarl
data or only News Commentary data. For PBT the
system with two language models performs best for
all test sets. Further, we apply the idea of reverse
308
newstest2008 newstest2009 newstest2010 newstest2011
German?English BLEU TER BLEU TER BLEU TER BLEU TER
PBT baseline 21.1 62.3 20.8 61.4 23.7 59.3 21.3 61.3
PBT reverse 20.8 62.4 20.6 61.5 23.6 59.2 21.2 61.2
HPBT baseline 21.3 62.5 20.9 61.7 23.9 59.4 21.3 61.6
HPBT reverse 21.2 63.5 20.9 62.0 23.6 59.2 21.4 61.9
system combination (secondary) 21.5 61.6 21.2 60.6 24.3 58.3 21.7 60.3
PBT baseline +GW 21.5 61.9 21.2 61.1 24.0 59.0 21.3 61.4
PBT reverse 20.8 62.4 20.6 61.5 23.6 59.2 21.2 61.2
HPBT baseline +GW 21.6 62.3 21.3 61.3 24.0 59.4 21.6 61.5
HPBT reverse 21.2 63.5 20.9 62.0 23.6 59.2 21.4 61.9
system combination (primary) 21.9 61.2 21.4 60.5 24.7 58.0 21.9 60.2
Table 5: Results for the German?English task (truecase). +GW denotes the usage of LDC Gigaword data for the
language model, newstest2010 serves as development set. BLEU and TER are given in percentage.
newstest2008 newstest2009 newstest2010 newstest2011
English?German BLEU TER BLEU TER BLEU TER BLEU TER
PBT baseline 1 LM 14.6 71.7 14.8 70.8 15.8 66.9 15.3 70.0
PBT baseline 2 LM (*) 14.9 70.9 14.9 70.4 16.0 66.3 15.4 69.5
PBT baseline 3 LM 14.8 71.5 14.9 70.5 16.0 66.7 15.1 70.1
PBT reverse 2 LM (*) 14.9 71.4 15.1 70.2 15.9 66.5 15.0 69.7
HPBT baseline 2 LM (*) 15.1 71.8 15.3 71.1 16.2 67.4 15.4 70.3
HPBT baseline 2 LM opt on 4bleu-ter 15.2 68.4 15.0 67.7 15.9 64.6 15.1 67.1
HPBT reverse 2 LM (*) 15.4 71.3 15.3 70.7 16.7 66.9 15.5 70.1
syscombi of (*) 15.6 69.2 15.4 68.9 16.5 65.0 15.6 68.0
Table 6: Results for the English?German task (truecase). newstest2009 is used as development set. BLEU and TER
are given in percentage.
translation for both the phrase-based and the hier-
archical approach. The PBT reverse 2 LM systems
perform slightly worse compared to PBT baseline 2
LM. The HPBT reverse 2 LM performs better com-
pared to HPBT baseline 2 LM. When we employ
system combination using both reverse translation
setups (PBT reverse 2 LM and HPBT reverse 2 LM)
and both baseline setups (PBT baseline 2 LM and
HPBT baseline 2 LM), the translation quality is im-
proved by up to 0.2 points in BLEU and 2.1 points in
TER compared to the best single system.
5 Conclusion
For the participation in the WMT 2012 shared trans-
lation task, RWTH experimented with both phrase-
based and hierarchical translation systems. Several
different techniques were evaluated and yielded con-
siderable improvements over the respective base-
line systems as well as over our last year?s setups
(Huck et al, 2011b). Among these techniques are
an insertion model, the noisy-or lexical scoring vari-
ant, additional phrase-level lexical scores from IBM
model 1 and discriminative word lexicon models, a
discriminative reordering extension for hierarchical
translation, reverse translation, and system combi-
nation.
Acknowledgments
This work was achieved as part of the Quaero Pro-
gramme, funded by OSEO, French State agency for
innovation.
References
Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della
Pietra, and Robert L. Mercer. 1993. The Mathemat-
309
ics of Statistical Machine Translation: Parameter Es-
timation. Computational Linguistics, 19(2):263?311,
June.
Stanley F. Chen and Joshua Goodman. 1998. An Em-
pirical Study of Smoothing Techniques for Language
Modeling. Technical Report TR-10-98, Computer
Science Group, Harvard University, Cambridge, Mas-
sachusetts, USA, August.
David Chiang. 2007. Hierarchical Phrase-Based Trans-
lation. Computational Linguistics, 33(2):201?228.
Adria` de Gispert, Gonzalo Iglesias, Graeme Blackwood,
Eduardo R. Banga, and William Byrne. 2010. Hierar-
chical Phrase-Based Translation with Weighted Finite-
State Transducers and Shallow-n Grammars. Compu-
tational Linguistics, 36(3):505?533.
Liang Huang and David Chiang. 2007. Forest Rescoring:
Faster Decoding with Integrated Language Models. In
Proceedings of the 45th Annual Meeting of the Associ-
ation for Computational Linguistics, pages 144?151,
Prague, Czech Republic, June.
Matthias Huck and Hermann Ney. 2012. Insertion
and Deletion Models for Statistical Machine Trans-
lation. In Proceedings of the North American Chap-
ter of the Association for Computational Linguistics -
Human Language Technologies conference, Montreal,
Canada, June.
Matthias Huck, Saab Mansour, Simon Wiesler, and Her-
mann Ney. 2011a. Lexicon Models for Hierarchical
Phrase-Based Machine Translation. In International
Workshop on Spoken Language Translation, pages
191?198, San Francisco, California, USA, December.
Matthias Huck, Joern Wuebker, Christoph Schmidt,
Markus Freitag, Stephan Peitz, Daniel Stein, Arnaud
Dagnelies, Saab Mansour, Gregor Leusch, and Her-
mann Ney. 2011b. The RWTH Aachen Machine
Translation System for WMT 2011. In EMNLP 2011
Sixth Workshop on Statistical Machine Translation,
pages 405?412, Edinburgh, UK, July.
Matthias Huck, Stephan Peitz, Markus Freitag, and Her-
mann Ney. 2012. Discriminative Reordering Exten-
sions for Hierarchical Phrase-Based Machine Transla-
tion. In 16th Annual Conference of the European As-
sociation for Machine Translation, Trento, Italy, May.
Reinhard Kneser and Hermann Ney. 1995. Improved
Backing-Off for M-gram Language Modeling. In Pro-
ceedings of the International Conference on Acoustics,
Speech, and Signal Processing, volume 1, pages 181?
184, May.
Philipp Koehn and Kevin Knight. 2003. Empirical Meth-
ods for Compound Splitting. In Proceedings of Euro-
pean Chapter of the ACL (EACL 2009), pages 187?
194.
Philipp Koehn, Franz Joseph Och, and Daniel Marcu.
2003. Statistical Phrase-Based Translation. In
Proc. of the Human Language Technology Conf.
(HLT-NAACL), pages 127?133, Edmonton, Canada,
May/June.
Evgeny Matusov, Nicola Ueffing, and Hermann Ney.
2006. Computing Consensus Translation from Multi-
ple Machine Translation Systems Using Enhanced Hy-
potheses Alignment. In Conference of the European
Chapter of the Association for Computational Linguis-
tics (EACL), pages 33?40, Trento, Italy, April.
E. Matusov, G. Leusch, R.E. Banchs, N. Bertoldi,
D. Dechelotte, M. Federico, M. Kolss, Y.-S. Lee,
J.B. Marino, M. Paulik, S. Roukos, H. Schwenk, and
H. Ney. 2008. System Combination for Machine
Translation of Spoken and Written Language. IEEE
Transactions on Audio, Speech and Language Pro-
cessing, 16(7):1222?1237.
Arne Mauser, Sas?a Hasan, and Hermann Ney. 2009. Ex-
tending Statistical Machine Translation with Discrimi-
native and Trigger-Based Lexicon Models. In Proc. of
the Conf. on Empirical Methods for Natural Language
Processing (EMNLP), pages 210?218, Singapore, Au-
gust.
Robert C. Moore and William Lewis. 2010. Intelli-
gent Selection of Language Model Training Data. In
ACL (Short Papers), pages 220?224, Uppsala, Swe-
den, July.
Franz Josef Och and Hermann Ney. 2003. A Systematic
Comparison of Various Statistical Alignment Models.
Computational Linguistics, 29(1):19?51, March.
Franz Josef Och. 2003. Minimum Error Rate Train-
ing in Statistical Machine Translation. In Proc. of the
41th Annual Meeting of the Association for Compu-
tational Linguistics (ACL), pages 160?167, Sapporo,
Japan, July.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a Method for Automatic Eval-
uation of Machine Translation. In Proceedings of the
41st Annual Meeting of the Association for Computa-
tional Linguistics, pages 311?318, Philadelphia, Penn-
sylvania, USA, July.
Jan-Thorsten Peter, Matthias Huck, Hermann Ney, and
Daniel Stein. 2011. Soft String-to-Dependency Hier-
archical Machine Translation. In International Work-
shop on Spoken Language Translation, pages 246?
253, San Francisco, California, USA, December.
Maja Popovic? and Hermann Ney. 2006. POS-based
Word Reorderings for Statistical Machine Translation.
In International Conference on Language Resources
and Evaluation, pages 1278?1283, Genoa, Italy, May.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciulla, and John Makhoul. 2006. A Study
of Translation Edit Rate with Targeted Human Anno-
tation. In Proceedings of the 7th Conference of the
310
Association for Machine Translation in the Americas,
pages 223?231, Cambridge, Massachusetts, USA, Au-
gust.
Daniel Stein, Stephan Peitz, David Vilar, and Hermann
Ney. 2010. A Cocktail of Deep Syntactic Features
for Hierarchical Machine Translation. In Conf. of the
Association for Machine Translation in the Americas
(AMTA), Denver, Colorado, USA, October/November.
Daniel Stein, David Vilar, Stephan Peitz, Markus Fre-
itag, Matthias Huck, and Hermann Ney. 2011. A
Guide to Jane, an Open Source Hierarchical Trans-
lation Toolkit. The Prague Bulletin of Mathematical
Linguistics, (95):5?18, April.
Andreas Stolcke. 2002. SRILM ? An Extensible Lan-
guage Modeling Toolkit. In Proc. of the Int. Conf. on
Speech and Language Processing (ICSLP), volume 2,
pages 901?904, Denver, Colorado, USA, September.
David Vilar, Daniel Stein, Matthias Huck, and Hermann
Ney. 2010. Jane: Open source hierarchical transla-
tion, extended with reordering and lexicon models. In
ACL 2010 Joint Fifth Workshop on Statistical Machine
Translation and Metrics MATR, pages 262?270, Upp-
sala, Sweden, July.
David Vilar, Daniel Stein, Matthias Huck, and Hermann
Ney. 2012. Jane: an advanced freely available hier-
archical machine translation toolkit. Machine Trans-
lation, pages 1?20. http://dx.doi.org/10.1007/s10590-
011-9120-y.
Richard Zens and Hermann Ney. 2004. Improve-
ments in Phrase-Based Statistical Machine Transla-
tion. In Proc. Human Language Technology Conf. /
North American Chapter of the Association for Com-
putational Linguistics Annual Meeting (HLT-NAACL),
pages 257?264, Boston, Massachusetts, USA, May.
Richard Zens and Hermann Ney. 2008. Improvements
in Dynamic Programming Beam Search for Phrase-
based Statistical Machine Translation. In Interna-
tional Workshop on Spoken Language Translation,
pages 195?205, Honolulu, Hawaii, USA, October.
311
Proceedings of the 7th Workshop on Statistical Machine Translation, pages 322?329,
Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational Linguistics
Joint WMT 2012 Submission of the QUAERO Project
?Markus Freitag, ?Stephan Peitz, ?Matthias Huck, ?Hermann Ney,
?Jan Niehues, ?Teresa Herrmann, ?Alex Waibel,
?Le Hai-son, ?Thomas Lavergne, ?Alexandre Allauzen,
?Bianka Buschbeck, ?Josep Maria Crego, ?Jean Senellart
?RWTH Aachen University, Aachen, Germany
?Karlsruhe Institute of Technology, Karlsruhe, Germany
?LIMSI-CNRS, Orsay, France
?SYSTRAN Software, Inc.
?surname@cs.rwth-aachen.de
?firstname.surname@kit.edu
?firstname.lastname@limsi.fr ?surname@systran.fr
Abstract
This paper describes the joint QUAERO sub-
mission to the WMT 2012 machine transla-
tion evaluation. Four groups (RWTH Aachen
University, Karlsruhe Institute of Technol-
ogy, LIMSI-CNRS, and SYSTRAN) of the
QUAERO project submitted a joint translation
for the WMT German?English task. Each
group translated the data sets with their own
systems and finally the RWTH system combi-
nation combined these translations in our final
submission. Experimental results show im-
provements of up to 1.7 points in BLEU and
3.4 points in TER compared to the best single
system.
1 Introduction
QUAERO is a European research and develop-
ment program with the goal of developing multi-
media and multilingual indexing and management
tools for professional and general public applica-
tions (http://www.quaero.org). Research in machine
translation is mainly assigned to the four groups
participating in this joint submission. The aim of
this WMT submission was to show the quality of a
joint translation by combining the knowledge of the
four project partners. Each group develop and main-
tain their own different machine translation system.
These single systems differ not only in their general
approach, but also in the preprocessing of training
and test data. To take the advantage of these dif-
ferences of each translation system, we combined
all hypotheses of the different systems, using the
RWTH system combination approach.
This paper is structured as follows. In Section
2, the different engines of all four groups are in-
troduced. In Section 3, the RWTH Aachen system
combination approach is presented. Experiments
with different system selections for system combi-
nation are described in Section 4. Finally in Section
5, we discuss the results.
2 Translation Systems
For WMT 2012 each QUAERO partner trained their
systems on the parallel Europarl and News Com-
mentary corpora. All single systems were tuned
on the newstest2009 or newstest2010 development
set. The newstest2011 dev set was used to train
the system combination parameters. Finally, the
newstest2008-newstest2010 dev sets were used to
compare the results of the different system combina-
tion settings. In this Section all four different system
engines are presented.
2.1 RWTH Aachen Single Systems
For the WMT 2012 evaluation the RWTH utilized
RWTH?s state-of-the-art phrase-based and hierar-
chical translation systems. GIZA++ (Och and Ney,
2003) was employed to train word alignments, lan-
guage models have been created with the SRILM
toolkit (Stolcke, 2002).
2.1.1 Phrase-Based System
The phrase-based translation (PBT) system is
similar to the one described in Zens and Ney (2008).
After phrase pair extraction from the word-aligned
parallel corpus, the translation probabilities are esti-
mated by relative frequencies. The standard feature
322
set alo includes an n-gram language model, phrase-
level IBM-1 and word-, phrase- and distortion-
penalties, which are combined in log-linear fash-
ion. The model weights are optimized with standard
Mert (Och, 2003) on 200-best lists. The optimiza-
tion criterium is BLEU.
2.1.2 Hierarchical System
For the hierarchical setups (HPBT) described in
this paper, the open source Jane toolkit (Vilar et
al., 2010) is employed. Jane has been developed at
RWTH and implements the hierarchical approach as
introduced by Chiang (2007) with some state-of-the-
art extensions. In hierarchical phrase-based transla-
tion, a weighted synchronous context-free grammar
is induced from parallel text. In addition to contigu-
ous lexical phrases, hierarchical phrases with up to
two gaps are extracted. The search is typically car-
ried out using the cube pruning algorithm (Huang
and Chiang, 2007). The model weights are opti-
mized with standard Mert (Och, 2003) on 100-best
lists. The optimization criterium is 4BLEU ?TER.
2.1.3 Preprocessing
In order to reduce the source vocabulary size
translation, the German text was preprocessed
by splitting German compound words with the
frequency-based method described in (Koehn and
Knight, 2003a). To further reduce translation com-
plexity for the phrase-based approach, we performed
the long-range part-of-speech based reordering rules
proposed by (Popovic? et al, 2006).
2.1.4 Language Model
For both decoders a 4-gram language model is ap-
plied. The language model is trained on the par-
allel data as well as the provided News crawl, the
109 French-English, UN and LDC Gigaword Fourth
Edition corpora. For the 109 French-English, UN
and LDC Gigaword corpora RWTH applied the data
selection technique described in (Moore and Lewis,
2010).
2.2 Karlsruhe Institute of Technology Single
System
2.2.1 Preprocessing
We preprocess the training data prior to training
the system, first by normalizing symbols such as
quotes, dashes and apostrophes. Then smart-casing
of the first words of each sentence is performed. For
the German part of the training corpus we use the
hunspell1 lexicon to learn a mapping from old Ger-
man spelling to new German spelling to obtain a cor-
pus with homogenous spelling. In addition, we per-
form compound splitting as described in (Koehn and
Knight, 2003b). Finally, we remove very long sen-
tences, empty lines, and sentences that probably are
not parallel due to length mismatch.
2.2.2 System Overview
The KIT system uses an in-house phrase-based
decoder (Vogel, 2003) to perform translation and op-
timization with regard to the BLEU score is done us-
ing Minimum Error Rate Training as described in
Venugopal et al (2005).
2.2.3 Translation Models
The translation model is trained on the Europarl
and News Commentary Corpus and the phrase ta-
ble is based on a discriminative word alignment
(Niehues and Vogel, 2008).
In addition, the system applies a bilingual lan-
guage model (Niehues et al, 2011) to extend the
context of source language words available for trans-
lation.
Furthermore, we use a discriminative word lexi-
con as introduced in (Mauser et al, 2009). The lex-
icon was trained and integrated into our system as
described in (Mediani et al, 2011).
At last, we tried to find translations for
out-of-vocabulary (OOV) words by using quasi-
morphological operations as described in Niehues
and Waibel (2011). For each OOV word, we try to
find a related word that we can translate. We modify
the ending letters of the OOV word and learn quasi-
morphological operations to be performed on the
known translation of the related word to synthesize
a translation for the OOV word. By this approach
we were for example able to translate Kaminen into
chimneys using the known translation Kamin # chim-
ney.
2.2.4 Language Models
We use two 4-gram SRI language models, one
trained on the News Shuffle corpus and one trained
1http://hunspell.sourceforge.net/
323
on the Gigaword corpus. Furthermore, we use a 5-
gram cluster-based language model trained on the
News Shuffle corpus. The word clusters were cre-
ated using the MKCLS algorithm. We used 100
word clusters.
2.2.5 Reordering Model
Reordering is performed based on part-of-speech
tags obtained using the TreeTagger (Schmid, 1994).
Based on these tags we learn probabilistic continu-
ous (Rottmann and Vogel, 2007) and discontinuous
(Niehues and Kolss, 2009) rules to cover short and
long-range reorderings. The rules are learned from
the training corpus and the alignment. In addition,
we learned tree-based reordering rules. Therefore,
the training corpus was parsed by the Stanford parser
(Rafferty and Manning, 2008). The tree-based rules
consist of the head node of a subtree and all its
children as well as the new order and a probability.
These rules were applied recursively. The reordering
rules are applied to the source sentences and the re-
ordered sentence variants as well as the original se-
quence are encoded in a word lattice which is used
as input to the decoder. For the test sentences, the
reordering based on parts-of-speech and trees allows
us to change the word order in the source sentence
so that the sentence can be translated more easily.
In addition, we build reordering lattices for all train-
ing sentences and then extract phrase pairs from the
monotone source path as well as from the reordered
paths.
2.3 LIMSI-CNRS Single System
LIMSI?s system is built with n-code (Crego et al,
2011), an open source statistical machine translation
system based on bilingual n-gram2. In this approach,
the translation model relies on a specific decomposi-
tion of the joint probability of a sentence pair P(s, t)
using the n-gram assumption: a sentence pair is de-
composed into a sequence of bilingual units called
tuples, defining a joint segmentation of the source
and target. In the approach of (Marin?o et al, 2006),
this segmentation is a by-product of source reorder-
ing which ultimately derives from initial word and
phrase alignments.
2http://ncode.limsi.fr/
2.3.1 An Overview of n-code
The baseline translation model is implemented as
a stochastic finite-state transducer trained using a
n-gram model of (source,target) pairs (Casacuberta
and Vidal, 2004). Training this model requires to
reorder source sentences so as to match the target
word order. This is performed by a stochastic finite-
state reordering model, which uses part-of-speech
information3 to generalize reordering patterns be-
yond lexical regularities.
In addition to the translation model, eleven fea-
ture functions are combined: a target-language
model; four lexicon models; two lexicalized reorder-
ing models (Tillmann, 2004) aiming at predicting
the orientation of the next translation unit; a ?weak?
distance-based distortion model; and finally a word-
bonus model and a tuple-bonus model which com-
pensate for the system preference for short transla-
tions. The four lexicon models are similar to the ones
used in a standard phrase based system: two scores
correspond to the relative frequencies of the tuples
and two lexical weights estimated from the automat-
ically generated word alignments. The weights asso-
ciated to feature functions are optimally combined
using a discriminative training framework (Och,
2003), using the newstest2009 development set.
The overall search is based on a beam-search
strategy on top of a dynamic programming algo-
rithm. Reordering hypotheses are computed in a
preprocessing step, making use of reordering rules
built from the word reorderings introduced in the tu-
ple extraction process. The resulting reordering hy-
potheses are passed to the decoder in the form of
word lattices (Crego and Marin?o, 2007).
2.3.2 Continuous Space Translation Models
One critical issue with standard n-gram transla-
tion models is that the elementary units are bilingual
pairs, which means that the underlying vocabulary
can be quite large. Unfortunately, the parallel data
available to train these models are typically smaller
than the corresponding monolingual corpora used to
train target language models. It is very likely then,
that such models should face severe estimation prob-
lems. In such setting, using neural network language
3Part-of-speech labels for English and German are com-
puted using the TreeTagger (Schmid, 1995).
324
model techniques seem all the more appropriate. For
this study, we follow the recommendations of Le et
al. (2012), who propose to factor the joint proba-
bility of a sentence pair by decomposing tuples in
two (source and target) parts, and further each part
in words. This yields a word factored translation
model that can be estimated in a continuous space
using the SOUL architecture (Le et al, 2011).
The design and integration of a SOUL model for
large SMT tasks is far from easy, given the computa-
tional cost of computing n-gram probabilities. The
solution used here was to resort to a two pass ap-
proach: the first pass uses a conventional back-off
n-gram model to produce a k-best list; in the second
pass, the k-best list is reordered using the probabil-
ities of m-gram SOUL translation models. In the
following experiments, we used a fixed context size
for SOUL of m = 10, and used k = 300.
2.3.3 Corpora and Data Preprocessing
The parallel data is word-aligned using
MGIZA++4 with default settings. For the En-
glish monolingual training data, we used the same
setup as last year5 and thus the same target language
model as detailed in (Allauzen et al, 2011).
For English, we took advantage of our in-house
text processing tools for tokenization and detok-
enization steps (De?chelotte et al, 2008) and our sys-
tem was built in ?true-case?. As German is mor-
phologically more complex than English, the default
policy which consists in treating each word form
independently is plagued with data sparsity, which
is detrimental both at training and decoding time.
Thus, the German side was normalized using a spe-
cific pre-processing scheme (Allauzen et al, 2010;
Durgar El-Kahlout and Yvon, 2010), which notably
aims at reducing the lexical redundancy by (i) nor-
malizing the orthography, (ii) neutralizing most in-
flections and (iii) splitting complex compounds.
2.4 SYSTRAN Software, Inc. Single System
The data submitted by SYSTRAN were obtained by
a system composed of the standard SYSTRAN MT
engine in combination with a statistical post editing
(SPE) component.
4http://geek.kyloo.net/software
5The fifth edition of the English Gigaword (LDC2011T07)
was not used.
The SYSTRAN system is traditionally classi-
fied as a rule-based system. However, over the
decades, its development has always been driven by
pragmatic considerations, progressively integrating
many of the most efficient MT approaches and tech-
niques. Nowadays, the baseline engine can be con-
sidered as a linguistic-oriented system making use of
dependency analysis, general transfer rules as well
as of large manually encoded dictionaries (100k -
800k entries per language pair).
The SYSTRAN phrase-based SPE component
views the output of the rule-based system as the
source language, and the (human) reference trans-
lation as the target language, see (L. Dugast and
Koehn, 2007). It performs corrections and adaptions
learned from the 5-gram language model trained on
the parallel target-to-target corpus. Moreover, the
following measures - limiting unwanted statistical
effects - were applied:
? Named entities, time and numeric expressions
are replaced by special tokens on both sides.
This usually improves word alignment, since
the vocabulary size is significantly reduced. In
addition, entity translation is handled more re-
liably by the rule-based engine.
? The intersection of both vocabularies (i.e. vo-
cabularies of the rule-based output and the ref-
erence translation) is used to produce an addi-
tional parallel corpus to help to improve word
alignment.
? Singleton phrase pairs are deleted from the
phrase table to avoid overfitting.
? Phrase pairs not containing the same number
of entities on the source and the target side are
also discarded.
The SPE language model was trained on 2M bilin-
gual phrases from the news/Europarl corpora, pro-
vided as training data for WMT 2012. An addi-
tional language model built from 15M phrases of
the English LDC Gigaword corpus using Kneser-
Ney (Kneser and Ney, 1995) smoothing was added.
Weights for these separate models were tuned by
the Mert algorithm provided in the Moses toolkit
(P. Koehn et al, 2007), using the provided news de-
velopment set.
325
3 RWTH Aachen System Combination
System combination is used to produce consensus
translations from multiple hypotheses produced with
different translation engines that are better in terms
of translation quality than any of the individual hy-
potheses. The basic concept of RWTH?s approach
to machine translation system combination has been
described by Matusov et al (2006; 2008). This ap-
proach includes an enhanced alignment and reorder-
ing framework. A lattice is built from the input hy-
potheses. The translation with the best score within
the lattice according to a couple of statistical models
is selected as consensus translation.
4 Experiments
This year, we tried different sets of single systems
for system combination. As RWTH has two dif-
ferent translation systems, we put the output of
both systems into system combination. Although
both systems have the same preprocessing and lan-
guage model, their hypotheses differ because of
their different decoding approach. Compared to
the other systems, the system by SYSTRAN has a
completely different approach (see section 2.4). It
is mainly based on a rule-based system. For the
German?English pair, SYSTRAN achieves a lower
BLEU score in each test set compared to the other
groups. However, since the SYSTRAN system is
very different to the others, we still obtain an im-
provement when we add it also to system combina-
tion.
We did experiments with different optimization
criteria for the system combination optimization.
All results are listed in Table 1 (unoptimized), Table
2 (optimized on BLEU) and Table 3 (optimized on
TER-BLEU). Further, we investigated, whether we
will loose performance, if a single system is dropped
from the system combination. The results show that
for each optimization criteria we need all systems to
achieve the best results.
For the BLEU optimized system combination, we
obtain an improvement compared to the best sin-
gle systems for all dev sets. For newstest2008, we
get an improvement of 1.5 points in BLEU and 1.5
points in TER compared to the best single system of
Karlsruhe Institute of Technology. For newstest2009
we get an improvement of 1.9 points in BLEU and
1.5 points in TER compared to the best single sys-
tem. The system combination of all systems outper-
forms the best single system with 1.9 points in BLEU
and 1.9 points in TER for newstest2010. For new-
stest2011 the improvement is 1.3 points in BLEU
and 2.9 points in TER.
For the TER-BLEU optimized system combina-
tion, we achieved more improvement in TER com-
pared to the BLEU optimized system combination.
For newstest2008, we get an improvement of 0.8
points in BLEU and 3.0 points in TER compared to
the best single system of Karlsruhe Institute of Tech-
nology. The system combinations performs better
on newstest2009 with 1.3 points in BLEU and 2.7
points in TER. For newstest2010, we get an im-
provement of 1.7 points in BLEU and 3.4 points in
TER and for newstest2011 we get an improvement
of 0.7 points in BLEU and 2.5 points in TER.
5 Conclusion
The four statistical machine translation systems of
Karlsruhe Institute of Technology, RWTH Aachen
and LIMSI and the very structural approach of SYS-
TRAN produce hypotheses with a huge variability
compared to the others. Finally, the RWTH Aachen
system combination combined all single system hy-
potheses to one hypothesis with a higher BLEU and
a lower TER score compared to each single sys-
tem. For each optimization criteria the system com-
binations using all single systems outperforms the
system combinations using one less single system.
Although the single system of SYSTRAN has the
worst error scores and the RWTH single systems are
similar, we achieved the best result in using all single
systems. For the WMT 12 evaluation, we submitted
the system combination of all systems optimized on
BLEU.
Acknowledgments
This work was achieved as part of the Quaero Pro-
gramme, funded by OSEO, French State agency for
innovation.
References
Alexandre Allauzen, Josep M. Crego, I?lknur Durgar El-
Kahlout, and Francois Yvon. 2010. LIMSI?s statis-
tical translation systems for WMT?10. In Proc. of the
326
Table 1: All systems for the WMT 2012 German?English translation task (truecase). BLEU and TER results are in
percentage. sc denotes system combination. All system combinations are unoptimized.
system newstest2008 newstest2009 newstest2010 newstest2011
BLEU TER BLEU TER BLEU TER BLEU TER TER-BLEU
KIT 22.2 61.8 21.3 61.0 24.1 59.0 22.4 60.2 37.9
RWTH.PBT 21.4 62.0 21.3 61.1 23.9 59.1 21.4 61.2 39.7
Limsi 22.2 63.0 22.0 61.8 23.9 59.9 21.8 62.0 40.2
RWTH.HPBT 21.5 62.6 21.5 61.6 23.6 60.2 21.5 61.8 40.4
SYSTRAN 18.3 64.6 17.9 63.4 21.1 60.5 18.3 63.1 44.8
sc-withAllSystems 23.4 59.7 22.9 59.0 26.2 56.5 23.3 58.8 35.5
sc-without-RWTH.PBT 23.2 59.8 22.8 59.0 25.9 56.6 23.1 58.7 35.6
sc-without-RWTH.HPBT 23.2 59.6 22.7 58.9 26.1 56.2 23.1 58.7 35.6
sc-without-Limsi 22.7 60.1 22.4 59.2 25.5 56.7 22.8 58.8 36.0
sc-without-SYSTRAN 23.0 60.3 22.5 59.5 25.7 57.2 23.1 59.2 36.1
sc-without-KIT 23.0 59.9 22.5 59.1 25.9 56.6 22.9 59.1 36.3
Table 2: All systems for the WMT 2012 German?English translation task (truecase). BLEU and TER results are in
percentage. sc denotes system combination. All system combinations are optimized on BLEU .
system newstest2008 newstest2009 newstest2010 newstest2011
BLEU TER BLEU TER BLEU TER BLEU TER TER-BLEU
sc-withAllSystems 23.7 60.3 23.2 59.5 26.0 57.1 23.7 59.2 35.6
sc-without-RWTH.PBT 23.4 61.1 23.1 59.8 25.5 57.6 23.5 59.5 36.1
sc-without-SYSTRAN 23.3 61.1 22.6 60.5 25.3 58.1 23.5 60.0 36.5
sc-without-Limsi 23.1 60.7 22.6 59.7 25.4 57.5 23.3 59.4 36.2
sc-without-KIT 23.4 60.7 23.0 59.7 25.6 57.7 23.3 59.8 36.5
sc-without-RWTH.HPBT 23.3 59.4 22.8 58.6 26.1 56.0 23.1 58.4 35.2
Table 3: All systems for the WMT 2012 German?English translation task (truecase). BLEU and TER results are in
percentage. sc denotes system combination. All system combinations are optimized on TER-BLEU .
system newstest2008 newstest2009 newstest2010 newstest2011
BLEU TER BLEU TER BLEU TER BLEU TER TER-BLEU
sc-withAllSystems 23.0 58.8 22.4 58.3 25.8 55.6 23.1 57.7 34.6
sc-without-RWTH.PBT 23.0 59.3 22.5 58.5 25.6 56.0 23.1 58.0 34.9
sc-without-RWTH.HPBT 23.1 59.0 22.6 58.3 25.8 55.6 23.0 58.0 35.0
sc-without-SYSTRAN 22.9 59.7 22.4 59.1 25.6 56.7 23.2 58.5 35.3
sc-without-Limsi 22.7 59.4 22.2 58.7 25.3 56.1 22.7 58.1 35.5
sc-without-KIT 22.9 59.3 22.4 58.5 25.7 55.8 22.7 58.1 35.4
327
Joint Workshop on Statistical Machine Translation and
MetricsMATR, pages 54?59, Uppsala, Sweden.
Alexandre Allauzen, Gilles Adda, He?le`ne Bonneau-
Maynard, Josep M. Crego, Hai-Son Le, Aure?lien Max,
Adrien Lardilleux, Thomas Lavergne, Artem Sokolov,
Guillaume Wisniewski, and Franc?ois Yvon. 2011.
LIMSI @ WMT11. In Proceedings of the Sixth Work-
shop on Statistical Machine Translation, pages 309?
315, Edinburgh, Scotland, July. Association for Com-
putational Linguistics.
F. Casacuberta and E. Vidal. 2004. Machine translation
with inferred stochastic finite-state transducers. Com-
putational Linguistics, 30(3):205?225.
D. Chiang. 2007. Hierarchical Phrase-Based Transla-
tion. Computational Linguistics, 33(2):201?228.
J.M. Crego and J.B. Marin?o. 2007. Improving statistical
MT by coupling reordering and decoding. Machine
Translation, 20(3):199?215.
Josep M. Crego, Franois Yvon, and Jos B. Mario.
2011. N-code: an open-source Bilingual N-gram SMT
Toolkit. Prague Bulletin of Mathematical Linguistics,
96:49?58.
D. De?chelotte, O. Galibert G. Adda, A. Allauzen, J. Gau-
vain, H. Meynard, and F. Yvon. 2008. LIMSI?s statis-
tical translation systems for WMT?08. In Proc. of the
NAACL-HTL Statistical Machine Translation Work-
shop, Columbus, Ohio.
Ilknur Durgar El-Kahlout and Franois Yvon. 2010. The
pay-offs of preprocessing for German-English Statis-
tical Machine Translation. In Marcello Federico, Ian
Lane, Michael Paul, and Franois Yvon, editors, Pro-
ceedings of the seventh International Workshop on
Spoken Language Translation (IWSLT), pages 251?
258.
L. Huang and D. Chiang. 2007. Forest Rescoring: Faster
Decoding with Integrated Language Models. In Proc.
Annual Meeting of the Association for Computational
Linguistics, pages 144?151, Prague, Czech Republic,
June.
R. Kneser and H. Ney. 1995. Improved backing-off for
m-gram language modeling. In Proceedings of the In-
ternational Conference on Acoustics, Speech, and Sig-
nal Processing, ICASSP?95, pages 181?184, Detroit,
MI.
P. Koehn and K. Knight. 2003a. Empirical Methods for
Compound Splitting. In EACL, Budapest, Hungary.
P. Koehn and K. Knight. 2003b. Empirical Methods
for Compound Splitting. In Proceedings of European
Chapter of the ACL (EACL 2009), pages 187?194.
J. Senellart L. Dugast and P. Koehn. 2007. Statistical
post-editing on systran?s rule-based translation system.
In Proceedings of the Second Workshop on Statisti-
cal Machine Translation, StatMT ?07, pages 220?223,
Stroudsburg, PA, USA. Association for Computational
Linguistics.
Hai-Son Le, Ilya Oparin, Alexandre Allauzen, Jean-Luc
Gauvain, and Franc?ois Yvon. 2011. Structured output
layer neural network language model. In Proceedings
of ICASSP?11, pages 5524?5527.
Hai-Son Le, Alexandre Allauzen, and Franc?ois Yvon.
2012. Continuous space translation models with neu-
ral networks. In NAACL ?12: Proceedings of the
2012 Conference of the North American Chapter of the
Association for Computational Linguistics on Human
Language Technology.
Jose? B. Marin?o, R. Banchs, J.M. Crego, A. de Gispert,
P. Lambert, J.A.R. Fonollosa, and M.R. Costa-jussa`.
2006. N-gram-based machine translation. Computa-
tional Linguistics, 32(4).
E. Matusov, N. Ueffing, and H. Ney. 2006. Computing
Consensus Translation from Multiple Machine Trans-
lation Systems Using Enhanced Hypotheses Align-
ment. In Conference of the European Chapter of the
Association for Computational Linguistics (EACL),
pages 33?40.
E. Matusov, G. Leusch, R.E. Banchs, N. Bertoldi,
D. Dechelotte, M. Federico, M. Kolss, Y.-S. Lee,
J.B. Mari no, M. Paulik, S. Roukos, H. Schwenk, and
H. Ney. 2008. System Combination for Machine
Translation of Spoken and Written Language. IEEE
Transactions on Audio, Speech and Language Pro-
cessing, 16(7):1222?1237.
Arne Mauser, Sas?a Hasan, and Hermann Ney. 2009. Ex-
tending Statistical Machine Translation with Discrim-
inative and Trigger-based Lexicon Models. In Pro-
ceedings of the 2009 Conference on Empirical Meth-
ods in Natural Language Processing: Volume 1 - Vol-
ume 1, EMNLP ?09, Singapore.
Mohammed Mediani, Eunah Cho, Jan Niehues, Teresa
Herrmann, and Alex Waibel. 2011. The KIT English-
French Translation Systems for IWSLT 2011. In Pro-
ceedings of the Eighth International Workshop on Spo-
ken Language Translation (IWSLT).
R.C. Moore and W. Lewis. 2010. Intelligent Selection
of Language Model Training Data. In ACL (Short Pa-
pers), pages 220?224, Uppsala, Sweden, July.
J. Niehues and M. Kolss. 2009. A POS-Based Model for
Long-Range Reorderings in SMT. In Fourth Work-
shop on Statistical Machine Translation (WMT 2009),
Athens, Greece.
J. Niehues and S. Vogel. 2008. Discriminative Word
Alignment via Alignment Matrix Modeling. In Proc.
of Third ACL Workshop on Statistical Machine Trans-
lation, Columbus, USA.
Jan Niehues and Alex Waibel. 2011. Using Wikipedia
to Translate Domain-specific Terms in SMT. In Pro-
328
ceedings of the Eighth International Workshop on Spo-
ken Language Translation (IWSLT), San Francisco,
CA.
Jan Niehues, Teresa Herrmann, Stephan Vogel, and Alex
Waibel. 2011. Wider Context by Using Bilingual Lan-
guage Models in Machine Translation. In Sixth Work-
shop on Statistical Machine Translation (WMT 2011),
Edinburgh, UK.
F.J. Och and H. Ney. 2003. A Systematic Comparison of
Various Statistical Alignment Models. Computational
Linguistics, 29(1):19?51.
F.J. Och. 2003. Minimum Error Rate Training for Statis-
tical Machine Translation. In Proc. Annual Meeting of
the Association for Computational Linguistics, pages
160?167, Sapporo, Japan, July.
A. Birch P. Koehn, H. Hoang, C. Callison-Burch, M. Fed-
erico, N. Bertoldi, B. Cowan, W. Shen, C. Moran,
R. Zens, C. Dyer, O. Bojar, A. Constantin, and
E. Herbst. 2007. Moses: open source toolkit for
statistical machine translation. In Proceedings of the
45th Annual Meeting of the ACL on Interactive Poster
and Demonstration Sessions, ACL ?07, pages 177?
180, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.
M. Popovic?, D. Stein, and H. Ney. 2006. Statistical
Machine Translation of German Compound Words.
In FinTAL - 5th International Conference on Natural
Language Processing, Springer Verlag, LNCS, pages
616?624.
Anna N. Rafferty and Christopher D. Manning. 2008.
Parsing three German treebanks: lexicalized and un-
lexicalized baselines. In Proceedings of the Workshop
on Parsing German.
K. Rottmann and S. Vogel. 2007. Word Reordering in
Statistical Machine Translation with a POS-Based Dis-
tortion Model. In TMI, Sko?vde, Sweden.
H. Schmid. 1994. Probabilistic Part-of-Speech Tagging
Using Decision Trees. In International Conference
on NewMethods in Language Processing, Manchester,
UK.
Helmut Schmid. 1995. Improvements in part-of-speech
tagging with an application to German. In Evelyne
Tzoukermann and SusanEditors Armstrong, editors,
Proceedings of the ACL SIGDATWorkshop, pages 47?
50. Kluwer Academic Publishers.
A. Stolcke. 2002. SRILM - an extensible language mod-
eling toolkit. In Proc. Int. Conf. on Spoken Language
Processing, volume 2, pages 901?904, Denver, Col-
orado, USA, September.
C. Tillmann. 2004. A unigram orientation model for sta-
tistical machine translation. In Proceedings of HLT-
NAACL 2004, pages 101?104. Association for Com-
putational Linguistics.
A. Venugopal, A. Zollman, and A. Waibel. 2005. Train-
ing and Evaluation Error Minimization Rules for Sta-
tistical Machine Translation. In Workshop on Data-
drive Machine Translation and Beyond (WPT-05), Ann
Arbor, MI.
D. Vilar, S. Stein, M. Huck, and H. Ney. 2010. Jane:
Open Source Hierarchical Translation, Extended with
Reordering and Lexicon Models. In ACL 2010 Joint
Fifth Workshop on Statistical Machine Translation and
Metrics MATR, pages 262?270, Uppsala, Sweden,
July.
S. Vogel. 2003. SMT Decoder Dissected: Word Re-
ordering. In Int. Conf. on Natural Language Process-
ing and Knowledge Engineering, Beijing, China.
R. Zens and H. Ney. 2008. Improvements in Dynamic
Programming Beam Search for Phrase-based Statisti-
cal Machine Translation. In Proc. of the Int. Workshop
on Spoken Language Translation (IWSLT), Honolulu,
Hawaii, October.
329
Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 185?192,
Sofia, Bulgaria, August 8-9, 2013 c?2013 Association for Computational Linguistics
Joint WMT 2013 Submission of the QUAERO Project
?Stephan Peitz, ?Saab Mansour, ?Matthias Huck, ?Markus Freitag, ?Hermann Ney,
?Eunah Cho, ?Teresa Herrmann, ?Mohammed Mediani, ?Jan Niehues, ?Alex Waibel,
?Alexandre Allauzen, ?Quoc Khanh Do,
?Bianka Buschbeck, ?Tonio Wandmacher
?RWTH Aachen University, Aachen, Germany
?Karlsruhe Institute of Technology, Karlsruhe, Germany
?LIMSI-CNRS, Orsay, France
?SYSTRAN Software, Inc.
?surname@cs.rwth-aachen.de
?firstname.surname@kit.edu
?firstname.lastname@limsi.fr ?surname@systran.fr
Abstract
This paper describes the joint submis-
sion of the QUAERO project for the
German?English translation task of the
ACL 2013 Eighth Workshop on Statisti-
cal Machine Translation (WMT 2013).
The submission was a system combina-
tion of the output of four different transla-
tion systems provided by RWTH Aachen
University, Karlsruhe Institute of Technol-
ogy (KIT), LIMSI-CNRS and SYSTRAN
Software, Inc. The translations were
joined using the RWTH?s system com-
bination approach. Experimental results
show improvements of up to 1.2 points in
BLEU and 1.2 points in TER compared to
the best single translation.
1 Introduction
QUAERO is a European research and develop-
ment program with the goal of developing multi-
media and multilingual indexing and management
tools for professional and general public applica-
tions (http://www.quaero.org). Research in ma-
chine translation is mainly assigned to the four
groups participating in this joint submission. The
aim of this submission was to show the quality of
a joint translation by combining the knowledge of
the four project partners. Each group develop and
maintain their own different machine translation
system. These single systems differ not only in
their general approach, but also in the preprocess-
ing of training and test data. To take advantage
of these differences of each translation system, we
combined all hypotheses of the different systems,
using the RWTH system combination approach.
This paper is structured as follows. First, the
different engines of all four groups are introduced.
In Section 3, the RWTH Aachen system combina-
tion approach is presented. Experiments with dif-
ferent system selections for system combination
are described in Section 4. This paper is concluded
in Section 5.
2 Translation Systems
For WMT 2013, each QUAERO partner trained
their systems on the parallel Europarl (EPPS),
News Commentary (NC) corpora and the web-
crawled corpus. All single systems were tuned on
the newstest2009 and newstest2010 development
set. The newstest2011 development set was used
to tune the system combination parameters. Fi-
nally, on newstest2012 the results of the different
system combination settings are compared. In this
Section, all four different translation engines are
presented.
2.1 RWTH Aachen Single System
For the WMT 2013 evaluation, RWTH utilized a
phrase-based decoder based on (Wuebker et al,
2012) which is part of RWTH?s open-source SMT
toolkit Jane 2.1 1. GIZA++ (Och and Ney, 2003)
was employed to train a word alignment, language
models have been created with the SRILM toolkit
(Stolcke, 2002).
After phrase pair extraction from the word-
aligned parallel corpus, the translation probabil-
ities are estimated by relative frequencies. The
standard feature set alo includes an n-gram lan-
guage model, phrase-level IBM-1 and word-,
phrase- and distortion-penalties, which are com-
bined in log-linear fashion. Furthermore, we used
an additional reordering model as described in
(Galley and Manning, 2008). By this model six
1http://www-i6.informatik.rwth-aachen.
de/jane/
185
additional feature are added to the log-linear com-
bination. The model weights are optimized with
standard Mert (Och, 2003a) on 200-best lists. The
optimization criterion is BLEU.
2.1.1 Preprocessing
In order to reduce the source vocabulary size trans-
lation, the German text was preprocessed by split-
ting German compound words with the frequency-
based method described in (Koehn and Knight,
2003). To further reduce translation complexity
for the phrase-based approach, we performed the
long-range part-of-speech based reordering rules
proposed by (Popovic? et al, 2006).
2.1.2 Translation Model
We applied filtering and weighting for domain-
adaptation similarly to (Mansour et al, 2011) and
(Mansour and Ney, 2012). For filtering the bilin-
gual data, a combination of LM and IBM Model
1 scores was used. In addition, we performed
weighted phrase extraction by using a combined
LM and IBM Model 1 weight.
2.1.3 Language Model
During decoding a 4-gram language model is ap-
plied. The language model is trained on the par-
allel data as well as the provided News crawl,
the 109 French-English, UN and LDC Gigaword
Fourth Edition corpora.
2.2 Karlsruhe Institute of Technology Single
System
2.2.1 Preprocessing
The training data was preprocessed prior to the
training. Symbols such as quotes, dashes and
apostrophes are normalized. Then the first words
of each sentence are smart-cased. For the Ger-
man part of the training corpus, the hunspell2 lex-
icon was used, in order to learn a mapping from
old German spelling to new German writing rules.
Compound-splitting was also performed as de-
scribed in Koehn and Knight (2003). We also re-
moved very long sentences, empty lines, and sen-
tences which show big mismatch on the length.
2.2.2 Filtering
The web-crawled corpus was filtered using an
SVM classifier as described in (Mediani et al,
2011). The lexica used in this filtering task were
obtained from Giza alignments trained on the
2http://hunspell.sourceforge.net/
cleaner corpora, EPPS and NC. Assuming that this
corpus is very noisy, we biased our classifier more
towards precision than recall. This was realized
by giving higher number of false examples (80%
of the training data).
This filtering technique ruled out more than
38% of the corpus (the unfiltered corpus contains
around 2.4M pairs, 0.9M of which were rejected
in the filtering task).
2.2.3 System Overview
The in-house phrase-based decoder (Vogel, 2003)
is used to perform decoding. Optimization with
regard to the BLEU score is done using Minimum
Error Rate Training (MERT) as described in Venu-
gopal et al (2005).
2.2.4 Reordering Model
We applied part-of-speech (POS) based reordering
using probabilistic continuous (Rottmann and Vo-
gel, 2007) and discontinuous (Niehues and Kolss,
2009) rules. This was learned using POS tags gen-
erated by the TreeTagger (Schmid, 1994) for short
and long range reorderings respectively.
In addition to this POS-based reordering, we
also used tree-based reordering rules. Syntactic
parse trees of the whole training corpus and the
word alignment between source and target lan-
guage are used to learn rules on how to reorder the
constituents in a German source sentence to make
it match the English target sentence word order
better (Herrmann et al, 2013). The training corpus
was parsed by the Stanford parser (Rafferty and
Manning, 2008). The reordering rules are applied
to the source sentences and the reordered sentence
variants as well as the original sequence are en-
coded in a word lattice which is used as input to
the decoder.
Moreover, our reordering model was extended
so that it could include the features of lexicalized
reordering model. The reordering probabilities for
each phrase pair are stored as well as the origi-
nal position of each word in the lattice. During
the decoding, the reordering origin of the words
is checked along with its probability added as an
additional score.
2.2.5 Translation Models
The translation model uses the parallel data of
EPPS, NC, and the filtered web-crawled data. As
word alignment, we used the Discriminative Word
Alignment (DWA) as shown in (Niehues and Vo-
186
gel, 2008). The phrase pairs were extracted using
different source word order suggested by the POS-
based reordering models presented previously as
described in (Niehues et al, 2009).
In order to extend the context of source lan-
guage words, we applied a bilingual language
model (Niehues et al, 2011). A Discriminative
Word Lexicon (DWL) introduced in (Mauser et
al., 2009) was extended so that it could take the
source context also into the account. For this,
we used a bag-of-ngrams instead of representing
the source sentence as a bag-of-words. Filtering
based on counts was then applied to the features
for higher order n-grams. In addition to this, the
training examples were created differently so that
we only used the words that occur in the n-best list
but not in the reference as negative example.
2.2.6 Language Models
We build separate language models and combined
them prior to decoding. As word-token based
language models, one language model is built on
EPPS, NC, and giga corpus, while another one is
built using crawled data. We combined the LMs
linearly by minimizing the perplexity on the de-
velopment data. As a bilingual language model we
used the EPPS, NC, and the web-crawled data and
combined them. Furthermore, we use a 5-gram
cluster-based language model with 1,000 word
clusters, which was trained on the EPPS and NC
corpus. The word clusters were created using the
MKCLS algorithm.
2.3 LIMSI-CNRS Single System
2.3.1 System overview
LIMSI?s system is built with n-code (Crego et al,
2011), an open source statistical machine transla-
tion system based on bilingual n-gram3. In this
approach, the translation model relies on a spe-
cific decomposition of the joint probability of a
sentence pair using the n-gram assumption: a sen-
tence pair is decomposed into a sequence of bilin-
gual units called tuples, defining a joint segmen-
tation of the source and target. In the approach of
(Marin?o et al, 2006), this segmentation is a by-
product of source reordering which ultimately de-
rives from initial word and phrase alignments.
2.3.2 An overview of n-code
The baseline translation model is implemented as
a stochastic finite-state transducer trained using
3http://ncode.limsi.fr/
a n-gram model of (source,target) pairs (Casacu-
berta and Vidal, 2004). Training this model re-
quires to reorder source sentences so as to match
the target word order. This is performed by
a stochastic finite-state reordering model, which
uses part-of-speech information4 to generalize re-
ordering patterns beyond lexical regularities.
In addition to the translation model, eleven fea-
ture functions are combined: a target-language
model; four lexicon models; two lexicalized re-
ordering models (Tillmann, 2004) aiming at pre-
dicting the orientation of the next translation unit;
a ?weak? distance-based distortion model; and
finally a word-bonus model and a tuple-bonus
model which compensate for the system prefer-
ence for short translations. The four lexicon mod-
els are similar to the ones use in a standard phrase
based system: two scores correspond to the rel-
ative frequencies of the tuples and two lexical
weights estimated from the automatically gener-
ated word alignments. The weights associated to
feature functions are optimally combined using a
discriminative training framework (Och, 2003b).
The overall search is based on a beam-search
strategy on top of a dynamic programming algo-
rithm. Reordering hypotheses are computed in a
preprocessing step, making use of reordering rules
built from the word reorderings introduced in the
tuple extraction process. The resulting reordering
hypotheses are passed to the decoder in the form
of word lattices (Crego and Mario, 2006).
2.3.3 Continuous space translation models
One critical issue with standard n-gram translation
models is that the elementary units are bilingual
pairs, which means that the underlying vocabu-
lary can be quite large, even for small translation
tasks. Unfortunately, the parallel data available to
train these models are typically order of magni-
tudes smaller than the corresponding monolingual
corpora used to train target language models. It is
very likely then, that such models should face se-
vere estimation problems. In such setting, using
neural network language model techniques seem
all the more appropriate. For this study, we fol-
low the recommendations of Le et al (2012), who
propose to factor the joint probability of a sen-
tence pair by decomposing tuples in two (source
and target) parts, and further each part in words.
This yields a word factored translation model that
4Part-of-speech labels for English and German are com-
puted using the TreeTagger (Schmid, 1995).
187
can be estimated in a continuous space using the
SOUL architecture (Le et al, 2011).
The design and integration of a SOUL model for
large SMT tasks is far from easy, given the com-
putational cost of computing n-gram probabilities.
The solution used here was to resort to a two pass
approach: the first pass uses a conventional back-
off n-gram model to produce a k-best list; in the
second pass, the k-best list is reordered using the
probabilities of m-gram SOUL translation models.
In the following experiments, we used a fixed con-
text size for SOUL of m= 10, and used k = 300.
2.3.4 Corpora and data pre-processing
All the parallel data allowed in the constrained
task are pooled together to create a single par-
allel corpus. This corpus is word-aligned using
MGIZA++5 with default settings. For the English
monolingual training data, we used the same setup
as last year6 and thus the same target language
model as detailed in (Allauzen et al, 2011).
For English, we also took advantage of our in-
house text processing tools for the tokenization
and detokenization steps (Dchelotte et al, 2008)
and our system is built in ?true-case?. As Ger-
man is morphologically more complex than En-
glish, the default policy which consists in treat-
ing each word form independently is plagued with
data sparsity, which is detrimental both at training
and decoding time. Thus, the German side was
normalized using a specific pre-processing scheme
(described in (Allauzen et al, 2010; Durgar El-
Kahlout and Yvon, 2010)), which notably aims at
reducing the lexical redundancy by (i) normalizing
the orthography, (ii) neutralizing most inflections
and (iii) splitting complex compounds.
2.4 SYSTRAN Software, Inc. Single System
In the past few years, SYSTRAN has been focus-
ing on the introduction of statistical approaches
to its rule-based backbone, leading to Hybrid Ma-
chine Translation.
The technique of Statistical Post-Editing
(Dugast et al, 2007) is used to automatically edit
the output of the rule-based system. A Statistical
Post-Editing (SPE) module is generated from a
bilingual corpus. It is basically a translation mod-
ule by itself, however it is trained on rule-based
5http://geek.kyloo.net/software
6The fifth edition of the English Gigaword
(LDC2011T07) was not used.
translations and reference data. It applies correc-
tions and adaptations learned from a phrase-based
5-gram language model. Using this two-step
process will implicitly keep long distance re-
lations and other constraints determined by the
rule-based system while significantly improving
phrasal fluency. It has the advantage that quality
improvements can be achieved with very little
but targeted bilingual data, thus significantly
reducing training time and increasing translation
performance.
The basic setup of the SPE component is identi-
cal to the one described in (Dugast et al, 2007).
A statistical translation model is trained on the
rule-based translation of the source and the target
side of the parallel corpus. Language models are
trained on each target half of the parallel corpora
and also on additional in-domain corpora. More-
over, the following measures - limiting unwanted
statistical effects - were applied:
? Named entities are replaced by special tokens
on both sides. This usually improves word
alignment, since the vocabulary size is sig-
nificantly reduced. In addition, entity trans-
lation is handled more reliably by the rule-
based engine.
? The intersection of both vocabularies (i.e. vo-
cabularies of the rule-based output and the
reference translation) is used to produce an
additional parallel corpus (whose target is
identical to the source). This was added to the
parallel text in order to improve word align-
ment.
? Singleton phrase pairs are deleted from the
phrase table to avoid overfitting.
? Phrase pairs not containing the same number
of entities on the source and the target side
are also discarded.
? Phrase pairs appearing less than 2 times were
pruned.
The SPE language model was trained on 2M
phrases from the news/europarl and Common-
Crawl corpora, provided as training data for WMT
2013. Weights for these separate models were
tuned by the Mert algorithm provided in the Moses
toolkit (Koehn et al, 2007), using the provided
news development set.
188
0
1
5:
th
at
/1
7:
th
is/
3
2
3:
is/
3
8:
w
as
/1
3
0:
*E
PS
*/
3
4:
it/
1
4
0:
*E
PS
*/
3
2:
in
/1
5
0:
*E
PS
*/
3
6:
th
e/
1
6
0:
*E
PS
*/
1
1:
fu
tu
re
/3
Figure 1: Confusion network of four different hypotheses.
3 RWTH Aachen System Combination
System combination is used to produce consen-
sus translations from multiple hypotheses gener-
ated with different translation engines. First, a
word to word alignment for the given single sys-
tem hypotheses is produced. In a second step a
confusion network is constructed. Then, the hy-
pothesis with the highest probability is extracted
from this confusion network. For the alignment
procedure, each of the given single systems gen-
erates one confusion network with its own as pri-
mary system. To this primary system all other hy-
potheses are aligned using the METEOR (Lavie
and Agarwal, 2007) alignment and thus the pri-
mary system defines the word order. Once the
alignment is given, the corresponding confusion
network is constructed. An example is given in
Figure 1. The final network for one source sen-
tence is the union of all confusion networks gen-
erated from the different primary systems. That
allows the system combination to select the word
order from different system outputs.
Before performing system combination, each
translation output was normalized by tokenization
and lowercasing. The output of the combination
was then truecased based on the original truecased
output.
The model weights of the system combination
are optimized with standard Mert (Och, 2003a)
on 100-best lists. We add one voting feature for
each single system to the log-linear framework of
the system combination. The voting feature fires
for each word the single system agrees on. More-
over, a word penalty, a language model trained on
the input hypotheses, a binary feature which pe-
nalizes word deletions in the confusion network
and a primary feature which marks the system
which provides the word order are combined in
this log-linear model. The optimization criterion
is 4BLEU-TER.
4 Experimental Results
In this year?s experiments, we tried to improve the
result of the system combination further by com-
bining single systems tuned on different develop-
Table 1: Comparison of single systems tuned on
newstest2009 and newstest2010. The results are
reported on newstest2012.
single systems tuned on newstest2012
newstest BLEU TER
KIT 2009 24.6 58.4
2010 24.6 58.6
LIMSI 2009 22.5 61.5
2010 22.6 59.8
SYSTRAN 2009 20.9 63.3
2010 21.2 62.2
RWTH 2009 23.7 60.8
2010 24.4 58.8
ment sets. The idea is to achieve a more stable
performance in terms of translation quality, if the
single systems are not optimized on the same data
set. In Table 1, the results of each provided single
system tuned on newstest2009 and newstest2010
are shown. For RWTH, LIMSI and SYSTRAN,
it seems that the performance of the single system
depends on the chosen tuning set. However, the
translation quality of the single systems provided
by KIT is stable.
As initial approach and for the final submis-
sion, we grouped single systems with dissimilar
approaches. Thus, KIT (phrase-based SMT) and
SYSTRAN (rule-based MT) tuned their system on
newstest2010, while RWTH (phrase-based SMT)
and LIMSI (n-gram) optimized on newstest2009.
To compare the impact of this approach, all pos-
sible combinations were checked (Table 2). How-
ever, it seems that the translation quality can not be
improved by this approach. For the test set (new-
stest2012), BLEU is steady around 25.6 points.
Even if the single system with lowest BLEU are
combined (KIT 2010, LIMSI 2009, SYSTRAN
2010, RWTH 2009), the translation quality in
terms of BLEU is comparable with the combina-
tion of the best single systems (KIT 2009, LIMSI
2010, SYSTRAN 2010, RWTH 2010). However,
we could gain 1.0 point in TER.
Due to the fact, that for the final submission the
initial grouping was available only, we kept this
189
Table 2: Comparison of different system combination settings. For each possible combination of systems
tuned on different tuning sets, a system combination was set up, re-tuned on newstest2011 and evaluated
on newstest2012. The setting used for further experiments is set in boldface.
single systems system combinations
KIT LIMSI SYSTRAN RWTH newstest2011 newstest2012
tuned on newstest BLEU TER BLEU TER
2009 2009 2009 2009 24.6 58.0 25.6 56.8
2010 2010 2010 2010 24.2 58.1 25.6 57.7
2010 2009 2009 2009 24.5 57.9 25.7 57.4
2009 2010 2009 2009 24.4 58.3 25.7 57.0
2009 2009 2010 2009 24.5 57.9 25.6 57.0
2009 2009 2009 2010 24.5 58.0 25.6 56.8
2009 2010 2010 2010 24.1 57.5 25.4 56.4
2010 2009 2010 2010 24.3 57.6 25.6 56.9
2010 2010 2009 2010 24.2 58.0 25.6 57.3
2010 2010 2010 2009 24.3 57.9 25.5 57.6
2010 2010 2009 2009 24.4 58.1 25.6 57.5
2009 2009 2010 2010 24.4 57.8 25.5 56.6
2009 2010 2010 2009 24.4 58.2 25.5 57.0
2009 2010 2009 2010 24.2 57.8 25.5 56.8
2010 2009 2009 2010 24.4 57.9 25.6 57.4
2010 2009 2010 2009 24.4 57.7 25.6 57.4
Table 3: Results of the final submission (bold-
face) compared with best single system on new-
stest2012.
newstest2011 newstest2012
BLEU TER BLEU TER
best single 23.2 60.9 24.6 58.4
system comb. 24.4 57.7 25.6 57.4
+ IBM-1 24.6 58.1 25.6 57.6
+ bigLM 24.6 57.9 25.8 57.2
combination. To improve this baseline further, two
additional models were added. We applied lexi-
cal smoothing (IBM-1) and an additional language
model (bigLM) trained on the English side of the
parallel data and the News shuffle corpus. The re-
sults are presented in Table 3.
The baseline was slightly improved by 0.2
points in BLEU and TER. Note, this system com-
bination was the final submission.
5 Conclusion
For the participation in the WMT 2013 shared
translation task, the partners of the QUAERO
project (Karlsruhe Institute of Technology, RWTH
Aachen University, LIMSI-CNRS and SYSTRAN
Software, Inc.) provided a joint submission. By
joining the output of four different translation sys-
tems with RWTH?s system combination, we re-
ported an improvement of up to 1.2 points in
BLEU and TER.
Combining systems optimized on different tun-
ing sets does not seem to improve the translation
quality. However, by adding additional model, the
baseline was slightly improved.
All in all, we conclude that the variability in
terms of BLEU does not influence the final result.
It seems that using different approaches of MT in
a system combination is more important (Freitag
et al, 2012).
Acknowledgments
This work was achieved as part of the Quaero Pro-
gramme, funded by OSEO, French State agency
for innovation.
References
Alexandre Allauzen, Josep M. Crego, I?lknur Durgar El-
Kahlout, and Franc?ois Yvon. 2010. LIMSI?s statis-
tical translation systems for WMT?10. In Proc. of
190
the Joint Workshop on Statistical Machine Transla-
tion and MetricsMATR, pages 54?59, Uppsala, Swe-
den.
Alexandre Allauzen, Gilles Adda, He?le`ne Bonneau-
Maynard, Josep M. Crego, Hai-Son Le, Aure?lien
Max, Adrien Lardilleux, Thomas Lavergne, Artem
Sokolov, Guillaume Wisniewski, and Franc?ois
Yvon. 2011. LIMSI @ WMT11. In Proceedings of
the Sixth Workshop on Statistical Machine Transla-
tion, pages 309?315, Edinburgh, Scotland, July. As-
sociation for Computational Linguistics.
Francesco Casacuberta and Enrique Vidal. 2004. Ma-
chine translation with inferred stochastic finite-state
transducers. Computational Linguistics, 30(3):205?
225.
Josep M. Crego and Jose? B. Mario. 2006. Improving
statistical MT by coupling reordering and decoding.
Machine Translation, 20(3):199?215.
Josep M. Crego, Franois Yvon, and Jos B. Mario.
2011. N-code: an open-source Bilingual N-gram
SMT Toolkit. Prague Bulletin of Mathematical Lin-
guistics, 96:49?58.
Lo??c Dugast, Jean Senellart, and Philipp Koehn. 2007.
Statistical post-editing on systran?s rule-based trans-
lation system. In Proceedings of the Second Work-
shop on Statistical Machine Translation, StatMT
?07, pages 220?223, Stroudsburg, PA, USA. Asso-
ciation for Computational Linguistics.
Ilknur Durgar El-Kahlout and Franois Yvon. 2010.
The pay-offs of preprocessing for German-English
Statistical Machine Translation. In Marcello Fed-
erico, Ian Lane, Michael Paul, and Franois Yvon, ed-
itors, Proceedings of the seventh International Work-
shop on Spoken Language Translation (IWSLT),
pages 251?258.
Daniel Dchelotte, Gilles Adda, Alexandre Allauzen,
Olivier Galibert, Jean-Luc Gauvain, Hlne Maynard,
and Franois Yvon. 2008. LIMSI?s statistical
translation systems for WMT?08. In Proc. of the
NAACL-HTL Statistical Machine Translation Work-
shop, Columbus, Ohio.
Markus Freitag, Stephan Peitz, Matthias Huck, Her-
mann Ney, Teresa Herrmann, Jan Niehues, Alex
Waibel, Alexandre Allauzen, Gilles Adda, Bianka
Buschbeck, Josep Maria Crego, and Jean Senellart.
2012. Joint wmt 2012 submission of the quaero
project. In NAACL 2012 Seventh Workshop on Sta-
tistical Machine Translation, pages 322?329, Mon-
treal, Canada, June.
Michel Galley and Christopher D. Manning. 2008. A
simple and effective hierarchical phrase reordering
model. In Proceedings of the 2008 Conference on
Empirical Methods in Natural Language Process-
ing, pages 847?855, Honolulu, Hawaii, October. As-
sociation for Computational Linguistics.
Teresa Herrmann, Jan Niehues, and Alex Waibel.
2013. Combining Word Reordering Methods on
different Linguistic Abstraction Levels for Statisti-
cal Machine Translation. In Proceedings of the Sev-
enth Workshop on Syntax, Semantics and Structure
in Statistical Translation, Altanta, Georgia, USA,
June. Association for Computational Linguistics.
Philipp Koehn and Kevin Knight. 2003. Empirical
Methods for Compound Splitting. In EACL, Bu-
dapest, Hungary.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondr?ej Bojar, Alexandra
Constantine, and Evan Herbst. 2007. Moses: Open
Source Toolkit for Statistical Machine Translation.
pages 177?180, Prague, Czech Republic, June.
Alon Lavie and Abhaya Agarwal. 2007. ME-
TEOR: An Automatic Metric for MT Evaluation
with High Levels of Correlation with Human Judg-
ments. pages 228?231, Prague, Czech Republic,
June.
Hai-Son Le, Ilya Oparin, Alexandre Allauzen, Jean-
Luc Gauvain, and Franc?ois Yvon. 2011. Structured
output layer neural network language model. In Pro-
ceedings of ICASSP?11, pages 5524?5527.
Hai-Son Le, Alexandre Allauzen, and Franc?ois Yvon.
2012. Continuous space translation models with
neural networks. In NAACL ?12: Proceedings of
the 2012 Conference of the North American Chap-
ter of the Association for Computational Linguistics
on Human Language Technology.
Saab Mansour and Hermann Ney. 2012. A sim-
ple and effective weighted phrase extraction for ma-
chine translation adaptation. In International Work-
shop on Spoken Language Translation, pages 193?
200, Hong Kong, December.
Sab Mansour, Joern Wuebker, and Hermann Ney.
2011. Combining Translation and Language Model
Scoring for Domain-Specific Data Filtering. In Pro-
ceedings of the International Workshop on Spoken
Language Translation (IWSLT), San Francisco, CA,
December.
Jose? B. Marin?o, Rafael E. Banchs, Josep M. Crego,
Adria` de Gispert, Patrick Lambert, Jose? A.R. Fonol-
losa, and Marta R. Costa-Jussa`. 2006. N-gram-
based machine translation. Computational Linguis-
tics, 32(4):527?549.
Arne Mauser, Sas?a Hasan, and Hermann Ney. 2009.
Extending Statistical Machine Translation with Dis-
criminative and Trigger-based Lexicon Models. In
Proceedings of the 2009 Conference on Empirical
Methods in Natural Language Processing: Volume
1 - Volume 1, EMNLP ?09, Singapore.
191
Mohammed Mediani, Eunah Cho, Jan Niehues, Teresa
Herrmann, and Alex Waibel. 2011. The KIT
English-French Translation Systems for IWSLT
2011. In Proceedings of the Eighth Interna-
tional Workshop on Spoken Language Translation
(IWSLT).
Jan Niehues and Muntsin Kolss. 2009. A POS-Based
Model for Long-Range Reorderings in SMT. In
Fourth Workshop on Statistical Machine Translation
(WMT 2009), Athens, Greece.
Jan Niehues and Stephan Vogel. 2008. Discriminative
Word Alignment via Alignment Matrix Modeling.
In Proc. of Third ACL Workshop on Statistical Ma-
chine Translation, Columbus, USA.
Jan Niehues, Teresa Herrmann, Muntsin Kolss, and
Alex Waibel. 2009. The Universita?t Karlsruhe
Translation System for the EACL-WMT 2009. In
Fourth Workshop on Statistical Machine Translation
(WMT 2009), Athens, Greece.
Jan Niehues, Teresa Herrmann, Stephan Vogel, and
Alex Waibel. 2011. Wider Context by Using Bilin-
gual Language Models in Machine Translation. In
Sixth Workshop on Statistical Machine Translation
(WMT 2011), Edinburgh, UK.
Franz Josef Och and Hermann Ney. 2003. A System-
atic Comparison of Various Statistical Alignment
Models. Computational Linguistics, 29(1):19?51,
March.
Franz Josef Och. 2003a. Minimum Error Rate Train-
ing in Statistical Machine Translation. In Proc. of
the 41th Annual Meeting of the Association for Com-
putational Linguistics (ACL), pages 160?167, Sap-
poro, Japan, July.
Franz Josef Och. 2003b. Minimum error rate training
in statistical machine translation. In ACL ?03: Proc.
of the 41st Annual Meeting on Association for Com-
putational Linguistics, pages 160?167.
M. Popovic?, D. Stein, and H. Ney. 2006. Statistical
Machine Translation of German Compound Words.
In FinTAL - 5th International Conference on Nat-
ural Language Processing, Springer Verlag, LNCS,
pages 616?624.
Anna N. Rafferty and Christopher D. Manning. 2008.
Parsing three German treebanks: lexicalized and un-
lexicalized baselines. In Proceedings of the Work-
shop on Parsing German.
Kay Rottmann and Stephan Vogel. 2007. Word Re-
ordering in Statistical Machine Translation with a
POS-Based Distortion Model. In TMI, Sko?vde,
Sweden.
Helmut Schmid. 1994. Probabilistic Part-of-Speech
Tagging Using Decision Trees. In International
Conference on New Methods in Language Process-
ing, Manchester, UK.
Helmut Schmid. 1995. Improvements in part-of-
speech tagging with an application to German.
In Evelyne Tzoukermann and SusanEditors Arm-
strong, editors, Proceedings of the ACL SIGDAT-
Workshop, pages 47?50. Kluwer Academic Publish-
ers.
Andreas Stolcke. 2002. SRILM ? An Extensible Lan-
guage Modeling Toolkit. In Proc. Int. Conf. on Spo-
ken Language Processing, volume 2, pages 901?
904, Denver, Colorado, USA.
Christoph Tillmann. 2004. A unigram orientation
model for statistical machine translation. In Pro-
ceedings of HLT-NAACL 2004, pages 101?104. As-
sociation for Computational Linguistics.
Ashish Venugopal, Andreas Zollman, and Alex Waibel.
2005. Training and Evaluation Error Minimization
Rules for Statistical Machine Translation. In Work-
shop on Data-drive Machine Translation and Be-
yond (WPT-05), Ann Arbor, MI.
Stephan Vogel. 2003. SMT Decoder Dissected: Word
Reordering. In Int. Conf. on Natural Language
Processing and Knowledge Engineering, Beijing,
China.
Joern Wuebker, Matthias Huck, Stephan Peitz, Malte
Nuhn, Markus Freitag, Jan-Thorsten Peter, Saab
Mansour, and Hermann Ney. 2012. Jane 2: Open
source phrase-based and hierarchical statistical ma-
chine translation. In International Conference on
Computational Linguistics, pages 483?491, Mum-
bai, India, December.
192
Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 193?199,
Sofia, Bulgaria, August 8-9, 2013 c?2013 Association for Computational Linguistics
The RWTH Aachen Machine Translation System for WMT 2013
Stephan Peitz, Saab Mansour, Jan-Thorsten Peter, Christoph Schmidt,
Joern Wuebker, Matthias Huck, Markus Freitag and Hermann Ney
Human Language Technology and Pattern Recognition Group
Computer Science Department
RWTH Aachen University
D-52056 Aachen, Germany
<surname>@cs.rwth-aachen.de
Abstract
This paper describes the statistical ma-
chine translation (SMT) systems devel-
oped at RWTH Aachen University for
the translation task of the ACL 2013
Eighth Workshop on Statistical Machine
Translation (WMT 2013). We partici-
pated in the evaluation campaign for the
French-English and German-English lan-
guage pairs in both translation directions.
Both hierarchical and phrase-based SMT
systems are applied. A number of dif-
ferent techniques are evaluated, including
hierarchical phrase reordering, translation
model interpolation, domain adaptation
techniques, weighted phrase extraction,
word class language model, continuous
space language model and system combi-
nation. By application of these methods
we achieve considerable improvements
over the respective baseline systems.
1 Introduction
For the WMT 2013 shared translation task1
RWTH utilized state-of-the-art phrase-based and
hierarchical translation systems as well as an in-
house system combination framework. We give
a survey of these systems and the basic meth-
ods they implement in Section 2. For both
the French-English (Section 3) and the German-
English (Section 4) language pair, we investigate
several different advanced techniques. We con-
centrate on specific research directions for each
of the translation tasks and present the respec-
tive techniques along with the empirical results
they yield: For the French?English task (Sec-
tion 3.2), we apply a standard phrase-based sys-
tem with up to five language models including a
1http://www.statmt.org/wmt13/
translation-task.html
word class language model. In addition, we em-
ploy translation model interpolation and hierarchi-
cal phrase reordering. For the English?French
task (Section 3.1), we train translation mod-
els on different training data sets and augment
the phrase-based system with a hierarchical re-
ordering model, a word class language model,
a discriminative word lexicon and a insertion
and deletion model. For the German?English
(Section 4.3) and English?German (Section 4.4)
tasks, we utilize morpho-syntactic analysis to pre-
process the data (Section 4.1), domain-adaptation
(Section 4.2) and a hierarchical reordering model.
For the German?English task, an augmented hi-
erarchical phrase-based system is set up and we
rescore the phrase-based baseline with a continu-
ous space language model. Finally, we perform a
system combination.
2 Translation Systems
In this evaluation, we employ phrase-based trans-
lation and hierarchical phrase-based translation.
Both approaches are implemented in Jane (Vilar et
al., 2012; Wuebker et al, 2012), a statistical ma-
chine translation toolkit which has been developed
at RWTH Aachen University and is freely avail-
able for non-commercial use.2
2.1 Phrase-based System
In the phrase-based decoder (source cardinality
synchronous search, SCSS), we use the standard
set of models with phrase translation probabilities
and lexical smoothing in both directions, word and
phrase penalty, distance-based distortion model,
an n-gram target language model and three bi-
nary count features. Optional additional models
used in this evaluation are the hierarchical reorder-
ing model (HRM) (Galley and Manning, 2008), a
word class language model (WCLM) (Wuebker et
2http://www.hltpr.rwth-aachen.de/jane/
193
al., 2012), a discriminative word lexicon (DWL)
(Mauser et al, 2009), and insertion and deletion
models (IDM) (Huck and Ney, 2012). The param-
eter weights are optimized with minimum error
rate training (MERT) (Och, 2003). The optimiza-
tion criterion is BLEU.
2.2 Hierarchical Phrase-based System
In hierarchical phrase-based translation (Chiang,
2007), a weighted synchronous context-free gram-
mar is induced from parallel text. In addition to
continuous lexical phrases, hierarchical phrases
with up to two gaps are extracted. The search is
carried out with a parsing-based procedure. The
standard models integrated into our Jane hierar-
chical systems (Vilar et al, 2010; Huck et al,
2012c) are: phrase translation probabilities and
lexical smoothing probabilities in both translation
directions, word and phrase penalty, binary fea-
tures marking hierarchical phrases, glue rule, and
rules with non-terminals at the boundaries, four
binary count features, and an n-gram language
model. Optional additional models comprise IBM
model 1 (Brown et al, 1993), discriminative word
lexicon and triplet lexicon models (Mauser et al,
2009; Huck et al, 2011), discriminative reordering
extensions (Huck et al, 2012a), insertion and dele-
tion models (Huck and Ney, 2012), and several
syntactic enhancements like preference grammars
(Stein et al, 2010) and soft string-to-dependency
features (Peter et al, 2011). We utilize the cube
pruning algorithm for decoding (Huck et al, 2013)
and optimize the model weights with MERT. The
optimization criterion is BLEU.
2.3 System Combination
System combination is used to produce consensus
translations from multiple hypotheses generated
with different translation engines. First, a word
to word alignment for the given single system hy-
potheses is produced. In a second step a confusion
network is constructed. Then, the hypothesis with
the highest probability is extracted from this con-
fusion network. For the alignment procedure, one
of the given single system hypotheses is chosen as
primary system. To this primary system all other
hypotheses are aligned using the METEOR (Lavie
and Agarwal, 2007) alignment and thus the pri-
mary system defines the word order. Once the
alignment is given, the corresponding confusion
network is constructed. An example is given in
Figure 1.
The model weights of the system combination
are optimized with standard MERT on 100-best
lists. For each single system, a factor is added to
the log-linear framework of the system combina-
tion. Moreover, this log-linear model includes a
word penalty, a language model trained on the in-
put hypotheses, a binary feature which penalizes
word deletions in the confusion network and a pri-
mary feature which marks the system which pro-
vides the word order. The optimization criterion is
4BLEU-TER.
2.4 Other Tools and Techniques
We employ GIZA++ (Och and Ney, 2003) to train
word alignments. The two trained alignments are
heuristically merged to obtain a symmetrized word
alignment for phrase extraction. All language
models (LMs) are created with the SRILM toolkit
(Stolcke, 2002) and are standard 4-gram LMs
with interpolated modified Kneser-Ney smooth-
ing (Kneser and Ney, 1995; Chen and Goodman,
1998). The Stanford Parser (Klein and Manning,
2003) is used to obtain parses of the training data
for the syntactic extensions of the hierarchical sys-
tem. We evaluate in truecase with BLEU (Papineni
et al, 2002) and TER (Snover et al, 2006).
2.5 Filtering of the Common Crawl Corpus
The new Common Crawl corpora contain a large
number of sentences that are not in the labelled
language. To clean these corpora, we first ex-
tracted a vocabulary from the other provided cor-
pora. Then, only sentences containing at least
70% word from the known vocabulary were kept.
In addition, we discarded sentences that contain
more words from target vocabulary than source
vocabulary on the source side. These heuristics
reduced the French-English Common Crawl cor-
pus by 5,1%. This filtering technique was also ap-
plied on the German-English version of the Com-
mon Crawl corpus.
3 French?English Setups
We trained phrase-based translation systems for
French?English and for English?French. Cor-
pus statistics for the French-English parallel data
are given in Table 1. The LMs are 4-grams trained
on the provided resources for the respective lan-
guage (Europarl, News Commentary, UN, 109,
Common Crawl, and monolingual News Crawl
194
0
1
5:
th
at
/1
7:
th
is/
3
2
3:
is/
3
8:
w
as
/1
3
0:
*E
PS
*/
3
4:
it/
1
4
0:
*E
PS
*/
3
2:
in
/1
5
0:
*E
PS
*/
3
6:
th
e/
1
6
0:
*E
PS
*/
1
1:
fu
tu
re
/3
Figure 1: Confusion network of four different hypotheses.
Table 1: Corpus statistics of the preprocessed
French-English parallel training data. EPPS de-
notes Europarl, NC denotes News Commentary,
CC denotes Common Crawl. In the data, numeri-
cal quantities have been replaced by a single cate-
gory symbol.
French English
EPPS Sentences 2.2M
+ NC Running Words 64.7M 59.7M
Vocabulary 153.4K 132.2K
CC Sentences 3.2M
Running Words 88.1M 80.9.0M
Vocabulary 954.8K 908.0K
UN Sentences 12.9M
Running Words 413.3M 362.3M
Vocabulary 487.1K 508.3K
109 Sentences 22.5M
Running Words 771.7M 661.1M
Vocabulary 1 974.0K 1 947.2K
All Sentences 40.8M
Running Words 1 337.7M 1 163.9M
Vocabulary 2 749.8K 2 730.1K
language model training data).3
3.1 Experimental Results English?French
For the English?French task, separate translation
models (TMs) were trained for each of the five
data sets and fed to the decoder. Four additional
indicator features are introduced to distinguish the
different TMs. Further, we applied the hierar-
chical reordering model, the word class language
model, the discriminative word lexicon, and the
insertion and deletion model. Table 2 shows the
results of our experiments.
As a development set for MERT, we use new-
stest2010 in all setups.
3.2 Experimental Results French?English
For the French?English task, a translation model
(TM) was trained on all available parallel data.
For the baseline, we interpolated this TM with
3The parallel 109 corpus is often also referred to as WMT
Giga French-English release 2.
an in-domain TM trained on EPPS+NC and em-
ployed the hierarchical reordering model. More-
over, three language models were used: The first
language model was trained on the English side
of all available parallel data, the second one on
EPPS and NC and the third LM on the News Shuf-
fled data. The baseline was improved by adding a
fourth LM trained on the Gigaword corpus (Ver-
sion 5) and a 5-gram word class language model
trained on News Shuffled data. For the WCLM,
we used 50 word classes clustered with the tool
mkcls (Och, 2000). All results are presented in Ta-
ble 3.
4 German?English Setups
For both translation directions of the German-
English language pair, we trained phrase-based
translation systems. Corpus statistics for German-
English can be found in Table 4. The language
models are 4-grams trained on the respective tar-
get side of the bilingual data as well as on the
provided News Crawl corpus. For the English
language model the 109 French-English, UN and
LDC Gigaword Fifth Edition corpora are used ad-
ditionally.
4.1 Morpho-syntactic Analysis
In order to reduce the source vocabulary size for
the German?English translation, the German text
is preprocessed by splitting German compound
words with the frequency-based method described
in (Koehn and Knight, 2003). To further reduce
translation complexity, we employ the long-range
part-of-speech based reordering rules proposed by
Popovic? and Ney (2006).
4.2 Domain Adaptation
This year, we experimented with filtering and
weighting for domain-adaptation for the German-
English task. To perform adaptation, we define a
general-domain (GD) corpus composed from the
news-commentary, europarl and Common Crawl
corpora, and an in-domain (ID) corpus using
a concatenation of the test sets (newstest{2008,
2009, 2010, 2011, 2012}) with the correspond-
ing references. We use the test sets as in-domain
195
Table 2: Results for the English?French task (truecase). newstest2010 is used as development set.
BLEU and TER are given in percentage.
newstest2008 newstest2009 newstest2010 newstest2011 newstest2012
English?French BLEU TER BLEU TER BLEU TER BLEU TER BLEU TER
TM:EPPS + HRM 22.9 63.0 25.0 60.0 27.8 56.7 28.9 54.4 27.2 57.1
TM:UN + HRM 22.7 63.4 25.0 60.0 28.3 56.4 29.5 54.2 27.3 57.1
TM:109 + HRM 23.5 62.3 26.0 59.2 29.6 55.2 30.3 53.3 28.0 56.4
TM:CC + HRM 23.5 62.3 26.2 58.8 29.2 55.3 30.3 53.3 28.2 56.0
TM:NC 21.0 64.8 22.3 61.6 25.6 58.7 26.9 56.6 25.7 58.5
+ HRM 21.5 64.3 22.6 61.2 26.1 58.4 27.3 56.1 26.0 58.2
+ TM:EPPS,CC,UN 23.9 61.8 26.4 58.6 29.9 54.7 31.0 52.7 28.6 55.6
+ TM:109 24.0 61.5 26.5 58.4 30.2 54.2 31.1 52.3 28.7 55.3
+ WCLM, DWL, IDM 24.0 61.6 26.5 58.3 30.4 54.0 31.4 52.1 28.8 55.2
Table 3: Results for the French?English task (truecase). newstest2010 is used as development set.
BLEU and TER are given in percentage.
newstest2010 newstest2011 newstest2012
French?English BLEU TER BLEU TER BLEU TER
SCSS baseline 28.1 54.6 29.1 53.3 - -
+ GigaWord.v5 LM 28.6 54.2 29.6 52.9 29.6 53.3
+ WCLM 29.1 53.8 30.1 52.5 29.8 53.1
(newswire) as the other corpora are coming from
differing domains (news commentary, parliamen-
tary discussions and various web sources), and on
initial experiments, the other corpora did not per-
form well when used as an in-domain representa-
tive for adaptation. To check whether over-fitting
occurs, we measure the results of the adapted
systems on the evaluation set of this year (new-
stest2013) which was not used as part of the in-
domain set.
The filtering experiments are done similarly to
(Mansour et al, 2011), where we compare filtering
using LM and a combined LM and IBM Model 1
(LM+M1) based scores. The scores for each sen-
tence pair in the general-domain corpus are based
on the bilingual cross-entropy difference of the
in-domain and general-domain models. Denoting
HLM (x) as the cross entropy of sentence x ac-
cording to LM , then the cross entropy difference
DHLM (x) can be written as:
DHLM (x) = HLMID(x)?HLMGD(x)
The bilingual cross entropy difference for a sen-
tence pair (s, t) in the GD corpus is then defined
by:
DHLM (s) + DHLM (t)
For IBM Model 1 (M1), the cross-entropy
HM1(s|t) is defined similarly to the LM cross-
entropy, and the resulting bilingual cross-entropy
difference will be of the form:
DHM1(s|t) + DHM1(t|s)
The combined LM+M1 score is obtained by
summing the LM and M1 bilingual cross-entropy
difference scores. To perform filtering, the GD
corpus sentence pairs are scored by the appropri-
ate method, sorted by the score, and the n-best sen-
tences are then used to build an adapted system.
In addition to adaptation using filtering, we ex-
periment with weighted phrase extraction similar
to (Mansour and Ney, 2012). We differ from their
work by using a combined LM+M1 weight to per-
form the phrase extraction instead of an LM based
weight. We use a combined LM+M1 weight as
this worked best in the filtering experiments, mak-
ing scoring with LM+M1 more reliable than LM
scores only.
4.3 Experimental Results German?English
For the German?English task, the baseline is
trained on all available parallel data and includes
the hierarchical reordering model. The results of
the various filtering and weighting experiments are
summarized in Table 5.
196
Table 5: German-English results (truecase). BLEU and TER are given in percentage. Corresponding
development set is marked with *. ? labels the single systems selected for the system combination.
newstest2009 newstest2010 newstest2011 newstest2012 newstest2013
German?English BLEU TER BLEU TER BLEU TER BLEU TER BLEU TER
SCSS baseline 21.7 61.1 24.8* 58.9* 22.0 61.1 23.4 60.0 26.1 56.4
LM 800K-best 21.6 60.5 24.7* 58.3* 22.0 60.5 23.6 59.7 - -
LM+M1 800K-best 21.4 60.5 24.7* 58.1* 22.0 60.4 23.7 59.2 - -
(LM+M1)*TM 22.1 60.2 25.4* 57.8* 22.5 60.1 24.0 59.1 - -
(LM+M1)*TM+GW 22.8 59.5 25.7* 57.2* 23.1 59.5 24.4 58.6 26.6 55.5
(LM+M1)*TM+GW? 22.9* 61.1* 25.2 59.3 22.8 61.5 23.7 60.8 26.4 57.1
SCSS baseline 22.6* 61.6* 24.1 60.1 22.1 62.0 23.1 61.2 - -
CSLM rescoring? 22.0 60.4 25.1* 58.3* 22.4 60.2 23.9 59.3 26.0 56.0
HPBT? 21.9 60.4 24.9* 58.2* 22.3 60.3 23.6 59.6 25.9 56.3
system combination - - - - 23.4* 59.3* 24.7 58.5 27.1 55.3
Table 6: English-German results (truecase). newstest2009 was used as development set. BLEU and TER
are given in percentage.
newstest2008 newstest2009 newstest2010 newstest2011 newstest2012
English?German BLEU TER BLEU TER BLEU TER BLEU TER BLEU TER
SCSS baseline 14.9 70.9 14.9 70.4 16.0 66.3 15.4 69.5 15.7 67.5
LM 800K-best 15.1 70.9 15.1 70.3 16.2 66.3 15.6 69.4 15.9 67.4
(LM+M1) 800K-best 15.8 70.8 15.4 70.0 16.2 66.2 16.0 69.3 16.1 67.4
(LM+M1) ifelse 16.1 70.6 15.7 69.9 16.5 66.0 16.2 69.2 16.3 67.2
Table 4: Corpus statistics of the preprocessed
German-English parallel training data (Europarl,
News Commentary and Common Crawl). In the
data, numerical quantities have been replaced by a
single category symbol.
German English
Sentences 4.1M
Running Words 104M 104M
Vocabulary 717K 750K
For filtering, we use the 800K best sentences
from the whole training corpora, as this se-
lection performed best on the dev set among
100K,200K,400K,800K,1600K setups. Filtering
seems to mainly improve on the TER scores, BLEU
scores are virtually unchanged in comparison to
the baseline. LM+M1 filtering improves further
on TER in comparison to LM-based filtering.
The weighted phrase extraction performs best
in our experiments, where the weights from the
LM+M1 scoring method are used. Improvements
in both BLEU and TER are achieved, with BLEU
improvements ranging from +0.4% up-to +0.6%
and TER improvements from -0.9% and up-to -
1.1%.
As a final step, we added the English Gigaword
corpus to the LM (+GW). This resulted in further
improvements of the systems.
In addition, the system as described above was
tuned on newstest2009. Using this development
set results in worse translation quality.
Furthermore, we rescored the SCSS baseline
tuned on newstest2009 with a continuous space
language model (CSLM) as described in (Schwenk
et al, 2012). The CSLM was trained on the eu-
roparl and news-commentary corpora. For rescor-
ing, we used the newstest2011 set as tuning set and
re-optimized the parameters with MERT on 1000-
best lists. This results in an improvement of up to
0.8 points in BLEU compared to the baseline.
We compared the phrase-based setups with a
hierarchical translation system, which was aug-
mented with preference grammars, soft string-
to-dependency features, discriminative reordering
extensions, DWL, IDM, and discriminative re-
197
ordering extensions. The phrase table of the hier-
archical setup has been extracted from News Com-
mentary and Europarl parallel data only (not from
Common Crawl).
Finally, three setups were joined in a system
combination and we gained an improvement of up
to 0.5 points in BLEU compared to the best single
system.
4.4 Experimental Results English?German
The results for the English?German task are
shown in Table 6. While the LM-based filter-
ing led to almost no improvement over the base-
line, the LM+M1 filtering brought some improve-
ments in BLEU. In addition to the sentence fil-
tering, we tried to combine the translation model
trained on NC+EPPS with a TM trained on Com-
mon Crawl using the ifelse combination (Mansour
and Ney, 2012). This combination scheme con-
catenates both TMs and assigns the probabilities
of the in-domain TM if it contains the phrase,
else it uses the probabilities of the out-of-domain
TM. Appling this method, we achieved further im-
provements.
5 Conclusion
For the participation in the WMT 2013 shared
translation task, RWTH experimented with both
phrase-based and hierarchical translation systems.
Several different techniques were evaluated and
yielded considerable improvements over the re-
spective baseline systems as well as over our last
year?s setups (Huck et al, 2012b). Among these
techniques are a hierarchical phrase reordering
model, translation model interpolation, domain
adaptation techniques, weighted phrase extraction,
a word class language model, a continuous space
language model and system combination.
Acknowledgments
This work was achieved as part of the Quaero Pro-
gramme, funded by OSEO, French State agency
for innovation.
References
Peter F. Brown, Stephen A. Della Pietra, Vincent J.
Della Pietra, and Robert L. Mercer. 1993. The
Mathematics of Statistical Machine Translation: Pa-
rameter Estimation. Computational Linguistics,
19(2):263?311, June.
Stanley F. Chen and Joshua Goodman. 1998. An
Empirical Study of Smoothing Techniques for Lan-
guage Modeling. Technical Report TR-10-98, Com-
puter Science Group, Harvard University, Cam-
bridge, Massachusetts, USA, August.
David Chiang. 2007. Hierarchical Phrase-Based
Translation. Computational Linguistics, 33(2):201?
228.
Michel Galley and Christopher D. Manning. 2008. A
Simple and Effective Hierarchical Phrase Reorder-
ing Model. In Proceedings of the 2008 Conference
on Empirical Methods in Natural Language Pro-
cessing, pages 847?855, Honolulu, Hawaii, USA,
October.
Matthias Huck and Hermann Ney. 2012. Insertion and
Deletion Models for Statistical Machine Translation.
In Proceedings of the North American Chapter of the
Association for Computational Linguistics - Human
Language Technologies conference, pages 347?351,
Montre?al, Canada, June.
Matthias Huck, Saab Mansour, Simon Wiesler, and
Hermann Ney. 2011. Lexicon Models for Hierar-
chical Phrase-Based Machine Translation. In Pro-
ceedings of the International Workshop on Spoken
Language Translation (IWSLT), pages 191?198, San
Francisco, California, USA, December.
Matthias Huck, Stephan Peitz, Markus Freitag, and
Hermann Ney. 2012a. Discriminative Reordering
Extensions for Hierarchical Phrase-Based Machine
Translation. In 16th Annual Conference of the Eu-
ropean Association for Machine Translation, pages
313?320, Trento, Italy, May.
Matthias Huck, Stephan Peitz, Markus Freitag, Malte
Nuhn, and Hermann Ney. 2012b. The RWTH
Aachen Machine Translation System for WMT
2012. In NAACL 2012 Seventh Workshop on
Statistical Machine Translation, pages 304?311,
Montre?al, Canada, June.
Matthias Huck, Jan-Thorsten Peter, Markus Freitag,
Stephan Peitz, and Hermann Ney. 2012c. Hierar-
chical Phrase-Based Translation with Jane 2. The
Prague Bulletin of Mathematical Linguistics, 98:37?
50, October.
Matthias Huck, David Vilar, Markus Freitag, and
Hermann Ney. 2013. A Performance Study of
Cube Pruning for Large-Scale Hierarchical Machine
Translation. In Proceedings of the NAACL 7thWork-
shop on Syntax, Semantics and Structure in Statis-
tical Translation, pages 29?38, Atlanta, Georgia,
USA, June.
Dan Klein and Christopher D. Manning. 2003. Accu-
rate Unlexicalized Parsing. In Proc. of the 41th An-
nual Meeting of the Association for Computational
Linguistics (ACL), pages 423?430, Sapporo, Japan,
July.
198
Reinhard Kneser and Hermann Ney. 1995. Im-
proved Backing-Off for M-gram Language Model-
ing. In Proceedings of the International Conference
on Acoustics, Speech, and Signal Processing, vol-
ume 1, pages 181?184, May.
Philipp Koehn and Kevin Knight. 2003. Empirical
Methods for Compound Splitting. In Proceedings of
European Chapter of the ACL (EACL 2009), pages
187?194.
Alon Lavie and Abhaya Agarwal. 2007. METEOR:
An Automatic Metric for MT Evaluation with High
Levels of Correlation with Human Judgments. In
ACL 2007 Second Workshop on Statistical Machine
Translation, pages 228?231, Prague, Czech Repub-
lic, June.
Saab Mansour and Hermann Ney. 2012. A Simple and
Effective Weighted Phrase Extraction for Machine
Translation Adaptation. In Proceedings of the Inter-
national Workshop on Spoken Language Translation
(IWSLT), pages 193?200, Hong Kong, December.
Saab Mansour, Joern Wuebker, and Hermann Ney.
2011. Combining Translation and Language Model
Scoring for Domain-Specific Data Filtering. In Pro-
ceedings of the International Workshop on Spoken
Language Translation (IWSLT), pages 222?229, San
Francisco, California, USA, December.
Arne Mauser, Sas?a Hasan, and Hermann Ney. 2009.
Extending Statistical Machine Translation with Dis-
criminative and Trigger-Based Lexicon Models. In
Proc. of the Conf. on Empirical Methods for Natu-
ral Language Processing (EMNLP), pages 210?218,
Singapore, August.
Franz Josef Och and Hermann Ney. 2003. A System-
atic Comparison of Various Statistical Alignment
Models. Computational Linguistics, 29(1):19?51,
March.
Franz Josef Och. 2000. mkcls: Training
of word classes for language modeling.
http://www.hltpr.rwth-aachen.de/
web/Software/mkcls.html.
Franz Josef Och. 2003. Minimum Error Rate Training
in Statistical Machine Translation. In Proc. of the
41th Annual Meeting of the Association for Compu-
tational Linguistics (ACL), pages 160?167, Sapporo,
Japan, July.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a Method for Automatic
Evaluation of Machine Translation. In Proceed-
ings of the 41st Annual Meeting of the Associa-
tion for Computational Linguistics, pages 311?318,
Philadelphia, Pennsylvania, USA, July.
Jan-Thorsten Peter, Matthias Huck, Hermann Ney, and
Daniel Stein. 2011. Soft String-to-Dependency
Hierarchical Machine Translation. In International
Workshop on Spoken Language Translation, pages
246?253, San Francisco, California, USA, Decem-
ber.
Maja Popovic? and Hermann Ney. 2006. POS-based
Word Reorderings for Statistical Machine Transla-
tion. In International Conference on Language Re-
sources and Evaluation, pages 1278?1283, Genoa,
Italy, May.
Holger Schwenk, Anthony Rousseau, and Mohammed
Attik. 2012. Large, Pruned or Continuous Space
Language Models on a GPU for Statistical Machine
Translation. In NAACL-HLT 2012 Workshop: Will
We Ever Really Replace the N-gram Model? On the
Future of Language Modeling for HLT, pages 11?
19, Montre?al, Canada, June.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciulla, and John Makhoul. 2006. A Study of
Translation Edit Rate with Targeted Human Annota-
tion. In Proceedings of the 7th Conference of the As-
sociation for Machine Translation in the Americas,
pages 223?231, Cambridge, Massachusetts, USA,
August.
Daniel Stein, Stephan Peitz, David Vilar, and Hermann
Ney. 2010. A Cocktail of Deep Syntactic Fea-
tures for Hierarchical Machine Translation. In Conf.
of the Association for Machine Translation in the
Americas (AMTA), Denver, Colorado, USA, Octo-
ber/November.
Andreas Stolcke. 2002. SRILM ? An Extensible Lan-
guage Modeling Toolkit. In Proc. of the Int. Conf.
on Speech and Language Processing (ICSLP), vol-
ume 2, pages 901?904, Denver, Colorado, USA,
September.
David Vilar, Daniel Stein, Matthias Huck, and Her-
mann Ney. 2010. Jane: Open Source Hierarchi-
cal Translation, Extended with Reordering and Lex-
icon Models. In ACL 2010 Joint Fifth Workshop on
Statistical Machine Translation and Metrics MATR,
pages 262?270, Uppsala, Sweden, July.
David Vilar, Daniel Stein, Matthias Huck, and Her-
mann Ney. 2012. Jane: an advanced freely avail-
able hierarchical machine translation toolkit. Ma-
chine Translation, 26(3):197?216, September.
Joern Wuebker, Matthias Huck, Stephan Peitz, Malte
Nuhn, Markus Freitag, Jan-Thorsten Peter, Saab
Mansour, and Hermann Ney. 2012. Jane 2:
Open Source Phrase-based and Hierarchical Statis-
tical Machine Translation. In International Confer-
ence on Computational Linguistics, pages 483?491,
Mumbai, India, December.
199
Proceedings of the 10th Workshop on Multiword Expressions (MWE 2014), pages 48?56,
Gothenburg, Sweden, 26-27 April 2014. c?2014 Association for Computational Linguistics
German Compounds and Statistical Machine Translation.
Can they get along?
Carla Parra Escart?n
University of Bergen
Bergen, Norway
carla.parra@uib.no
Stephan Peitz
RWTH Aachen University
Aachen, Germany
peitz@cs.rwth-aachen.de
Hermann Ney
RWTH Aachen University
Aachen, Germany
ney@cs.rwth-aachen.de
Abstract
This  paper  reports  different  experiments
created  to  study  the  impact  of  using
linguistics  to  preprocess  German  com-
pounds  prior  to  translation  in  Statistical
Machine  Translation  (SMT).  Compounds
are a known challenge both in Machine
Translation (MT) and Translation in gen-
eral as well as in other Natural Language
Processing (NLP) applications. In the case
of SMT, German compounds are split into
their constituents to decrease the number
of  unknown words  and  improve  the  re-
sults of evaluation measures like the Bleu
score. To assess to which extent it is neces-
sary to deal with German compounds as a
part of preprocessing in SMT systems, we
have  tested  different  compound splitters
and strategies, such as adding lists of com-
pounds and their translations to the train-
ing set. This  paper  summarizes  the re-
sults of our experiments and attempts to
yield better translations of German nom-
inal compounds into Spanish and shows
how our approach improves by up to 1.4
Bleu points with respect to the baseline.
1 Introduction
The pair of languages German?Spanish is not a
widely researched combination in Statistical Ma-
chine Translation (SMT) and yet it is a challenging
one as both languages belong to different language
families (Germanic and Romance) and their char-
acteristics and inner structure differ greatly. As it
may happen with other language pair combinations
involving a Germanic and a Romance language,
when it comes to the translation of German com-
pounds into Spanish, the challenge is greater than
when translating into other Germanic languages
such as English. The translation of the German
compound does not correspond to the translation
of its parts, but rather constitutes a phraseological
structure which must conform the Spanish gram-
matical rules. Examples 1 and 2 show the split-
tings of the German compoundsWarmwasserbere-
itung andW?rmer?ckgewinnungssysteme and their
translations into English and Spanish.
(1) Warm
caliente
warm
Wasser
agua
water
Bereitung
preparaci?n
production
[ES]: ?Preparaci?n de agua caliente?
[EN]: ?Warm water production?
(2) W?rme
calor
heat
R?ckgewinnung
recuperaci?n
recovery
s
?
?
Systeme
sistemas
Systems
[ES]: ?sistemas de recuperaci?n de calor?
[EN]: ?heat recovery systems?
As may be observed in Examples 1 and 2, in
Spanish not only there is word reordering, but also
there is usage of other word categories such as
prepositions. While the examples above are quite
simple, the work done by researchers such as An-
gele (1992), G?mez P?rez (2001) and Oster (2003)
for the pair of languages German?Spanish shows
that the translational equivalences in Spanish not
only are very varied, but also unpredictable to a
certain extent. Thus, while a mere compound split-
ting strategy may work for English, in the case of
Spanish further processing is required to yield the
correct translation.
According  to  Atkins  et  al.  (2001)
1
, complex
nominals  (i.e. nominal  compounds  and  some
nominal phrases) are to be considered a special
type of MWE because they do have some partic-
ular features and to some extent they behave as
a single unit because they refer to a single con-
cept. Despite focusing on another language pair
1
Appendix  F of  Deliverable  D2.2-D3.2  of  the  ISLE
project.
48
(English?Italian), in the case of our language pair
(German?Spanish) a similar claim could be done.
Besides, the issue of compounds being translated
into phrases in different languages is essentially a
MWE problem.
In this paper, we report on the results of our
research facing this  particular  challenge. More
concretely, Section 2 briefly discusses the prob-
lem of compounds in general and Section 3 de-
scribes our case of study. Subsection 3.1 briefly
discusses the large presence of German nominal
compounds in specialized corpora and presents the
results of a preliminary study and Subsection 3.2
summarizes the state-of-the-art strategies to deal
with compounds in SMT. Section 4 focuses on the
experiments carried out and reported here and the
results thereof are presented and discussed in Sec-
tion 5. Finally, Section 6 summarizes the findings
of our research and discusses future work.
2 German Compounds
German compounds  may be  lexicalized  or  not.
Lexicalized compounds are those which can be
found  in  general  dictionaries, such  as Stra?en-
lampe (?street lamp/light? in German). Non lex-
icalized compounds are formed in a similar man-
ner  to  that  of  phrases  and/or  sentences and are
coined on-the-fly (i.e. Warmwasserbereitungsan-
lagen, see  Example  3). Non  lexicalized  com-
pounds usually appear in technical and formal texts
and German shows a great tendency to produce
them. In SMT, the translational correspondences
are computed from a sentence aligned training cor-
pus and translation dictionaries  are  not  present.
Rather, word alignment algorithms are used to pro-
duce the phrase tables that will  in turn be used
to produce the translations. Thus, although non
lexicalized compounds pose a greater  challenge
(they are unpredictable), lexicalized compounds
are not distinguished either. As this formal distinc-
tion cannot be done when dealing with SMT, here
we will refer to compounds irrespectively whether
they are lexicalized or not, unless otherwise spec-
ified.
Moreover, German compounds may be nouns,
adjectives, adverbs and verbs, although the largest
group is the one corresponding to nominal com-
pounds. Finally, it is also important to highlight
that sometimes more than one compound-forming
phenomenon may take place subsequently to form
a new, longer, compound. Previous Example 1 is
the result of such a process, and as illustrated in Ex-
ample 3 it can, in turn, be the base for a yet newer
compound.
(3) warm (ADJ) + Wasser(N) =Warmwasser (N)
+ Bereitung(N) =Warmwasserbereitung
(N) + s + Anlagen(N) =
Warmwasserbereitungsanlagen (N) [EN:
warm water production systems]
As may also be observed in Example 3, the word
class of the compound is determined by the ele-
ment located in the rightmost position of the com-
pound (i.e. the combination of the adjective warm
and the nounWasser yields a nominal compound).
Finally, it is also important to highlight that be-
sides words, compounds may also include particles
to join those words together, as the ?s? between
Warmwasserbereitung and Anlagen in Example 3
or truncations (part of one of the component words
is deleted). Example 4 illustrates the case when
one of the component words has been truncated:
(4) abstellen(V) - en + Anlagen(N) =
Abstellanlagen (N) [EN: parking facilities]
The  morphology  of  German  compounds  has
been  widely  researched, both  within  linguistics
(Fleischer, 1975; Wellman, 1984; Eichinger, 2000,
among others), as in NLP (Langer, 1998; Girju et
al., 2005; Marek, 2006; Girju, 2008, among oth-
ers). Here, we will focus on the impact of prepro-
cessing nominal compounds in SMT.
Baroni et al. (2002) report that 47% of the vo-
cabulary (types)  in  the APA corpus
2
were com-
pounds. As will be observed in Section 4, the com-
pound splitters we used also detected a high per-
centage of compounds in the corpora used in our
experiments. This fact confirms that it is crucial to
find a successful way of processing compounds in
NLP applications and in our case in SMT.
3 Case Study
The experiments carried out here have used the
texts corresponding to the domain B00: Construc-
tion of  the TRIS corpus  (Parra Escart?n, 2012),
and an internally compiled version of the Europarl
Corpus (Koehn, 2005) for the pair of languages
German-Spanish
3
. The domain (B00: Construc-
tion) was selected because it is the biggest one of
2
Corpus of the Austria Presse Agentur (APA). Recently it
has been released as the AMC corpus (Austrian Media Cor-
pus) (Ransmayr et al., 2013).
3
See Table 2 for an overview of the corpus statistics.
49
the three domains currently available in the TRIS
corpus
4
. Only one domain was used because we
aimed at testing in-domain translation. Besides,
the TRIS corpus was selected because it is a spe-
cialised German-Spanish parallel corpus. As op-
posed to the Europarl, the TRIS corpus is divided in
domains and the source and target languages have
been verified (i.e. the texts were originally written
in German and translated into Spanish). Moreover,
the texts included in the Europarl are transcrip-
tions of the sessions of the European Parliament,
and thus the style is rather oral and less technical.
As compounds tend to be more frequent in domain
specific texts, the TRIS corpus has been used for
testing, while the Europarl Corpus has been used
in the training set to avoid data scarcity problems
and increase the vocabulary coverage of the SMT
system.
In the case of Machine Translation (MT), both
rule-based MT systems (RBMT systems) and Sta-
tistical MT systems (SMT systems) encounter prob-
lems when dealing with compounds. For the pur-
poses of this paper, the treatment of compounds
in German has been tested within the SMT toolkit
Jane (Wuebker et al., 2012; Vilar et al., 2010).
We have carried out several experiments translat-
ing German specialized texts into Spanish to test
to which extent incorporating a linguistic analy-
sis of the corpora and compiling compound lists
improves the overall SMT results. At this stage, in-
cluding further linguistic information such as Part-
of-Speech tagging (POS tagging) or phrase chunk-
ing has been disregarded. Forcing the translation
of compounds in the phrase tables produced by
Jane has also been disregarded. The overall aim
was to test how the SMT system performs using dif-
ferent pre-processing strategies of the training data
but without altering its mechanism. Since it is a
challenge to factor out what is really the translation
of the compounds, the overall quality of the trans-
lations at document level has been measured as an
indirect way of assessing the quality of the com-
pound translations
5
. To evaluate the compound
translations into Spanish, these need to be man-
ually validated because we currently do not have
access to fully automatic methods. A qualitative
analysis of the compound translations will be done
in future work.
4
The domain C00A: Agriculture, Fishing and Foodstuffs
has 137.354 words and the domain H00: Domestic Leisure
Equipment has 58328 words).
5
The results of this evaluation are reported in Section 5.
3.1 Preliminary study
With the purpose of assessing the presence of com-
pounds in the TRIS corpus and evaluating the split-
tings at a later stage as well as the impact of such
splittings in SMT, we analysed manually two short
texts of the TRIS corpus. The two files correspond
to the subcorpus B30: Construction - Environment
and account for 261 sentences and 2870 words.
For this  preliminary study, all  German nominal
compounds and their corresponding Spanish trans-
lations were manually extracted. Adjectival and
verbal compounds were not included at this stage.
Abbreviated nominal compounds (i.e. ?EKZ? in-
stead of ?Energiekennzahl?, [energy index]) were
not included either. Table 1 offers an overview of
the number of running words in each file without
punctuation, the number of nominal compounds
found (with an indication as to which percentage
of the total number of words they account for),
the number of unique compounds (i.e. compound
types), and the number of lexicalized and non lexi-
calized compounds in total (with the percentage of
the text they account for), and unique. For the pur-
poses of this study, all compounds found in a Ger-
man monolingual dictionary were considered lex-
icalized, whereas those not appearing where con-
sidered non-lexicalized.
As can be seen in Table 1, compound nominals
constitute a relatively high percentage of the total
number of words in a text. This is specially the
case of domain specific texts such as the ones taken
into consideration here. We can thus assume that
finding a way to translate compounds appropri-
ately into other languages would improve the over-
all quality of the translations produced by SMT.
3.2 Related work: compounds in SMT
RBMT systems  require  that  compounds  are  in-
cluded in their dictionaries to be able to retrieve
the appropriate translation in each case. Alterna-
tively, they should include a special rule for han-
dling compounds which are beyond their lexical
coverage. On the other hand, SMT systems en-
counter problems when dealing with compounds
because they rely on the words observed during the
training phase. Thus, if the compound did not ap-
pear in the training set of the system its translation
will subsequently fail. The state-of-the-art strat-
egy to deal with compounds in SMT systems con-
sists on splitting the compounds to reduce the num-
ber of unseen words. Previous research (Koehn
50
Text A Text B
Number of words 2431 439
Number of comp. 265 (10.9%) 62 (14.12%)
Number of unique comp. 143 25
Lexicalized comp. 99 (4.07%) 18 (4.1%)
Unique lexicalized comp. 63 4
Not lexicalized comp. 166 (6.8%) 44 (10.06%)
Unique not lexicalized comp. 80 21
Table 1: Compound nominals found in the two texts taken for the preliminary study.
and Knight, 2003; Popovi? et al., 2006; Stymne,
2008; Fritzinger and Fraser, 2010; Stymne et al.,
2013) has shown that splitting the compounds in
German results in better Bleu scores (Papineni et
al., 2001) and vocabulary coverage (fewer ?un-
known? words). However, the experiments car-
ried out so far have also claimed that significant
changes in error measures were not to be expected
because the percentage of running words affected
by compound splitting was rather low (Popovi? et
al., 2006; Stymne, 2008). As will be observed in
Section 4.1, in our case the percentage of running
words affected by compound splitting was higher.
This might be due to the kind of texts used in our
experiments.
4 Experiments
As  mentioned  in  Section 3, for  the  experi-
ments reported here two corpora have been used:
the TRIS corpus  and  the  Europarl  corpus  for
German?Spanish. In order to focus on in-domain
translation, only the largest subcorpus of TRIS has
been used.
Table 2 summarizes the number of sentences
and words in our experiment setup.
To reduce possible mistakes and mismatches ob-
served in the corpora used in the experiments, the
spelling of the German vowels named umlaut (???)
was simplified. Thus, ??, ?, ?, ?, ?, ?? were trans-
formed into ?Ae, Oe, Ue, ae, oe, ue? correspond-
ingly. Also the German ??? was substituted by a
double s: ?ss?. By doing this, words appearing in
the corpus and written differently were unified and
thus their frequencies were higher.
Additionally, a list of 185 German nominal com-
pounds present in the training set was manually ex-
tracted together with their translations into Span-
ish. If different translations had been found for
the same compound, these were included in our
list too. This list was used in some of our exper-
iments to determine whether extracting such lists
has an impact in the overall translation quality of
SMT systems. As the texts belong to the same
domain, there was partial overlap with the com-
pounds found in the test set. However, not all com-
pounds in the test set were present in the training
corpus and viceversa.
4.1 Training environments
Taking the normalised version of our corpus as
a baseline, different training environments have
been tested. We designed five possible training
environments in which German compounds were
preprocessed.
In our first experiment (hereinafter ?compList?),
the list of manually extracted compounds was ap-
pended to the end of the training set and no further
preprocessing was carried out.
In our second experiment (hereinafter ?RWTH?),
the state-of-the-art compound splitting approach
implemented by Popovi? et al. (2006) was used to
split all possible compounds. As also implemented
by Koehn and Knight (2003), this approach uses
the corpus itself to create a vocabulary that is then
subsequently used to calculate the possible split-
tings in the corpus. It has the advantage of being
a stand-alone approach which does not depend on
any external resources. A possible drawback of
this approach would be that it relies on a large cor-
pus to be able to compute the splittings. Thus, it
may not be as efficient with smaller corpora (i.e. if
we were to use only the TRIS corpus, for instance).
The  third  experiment  (hereinafter
?RWTH+compList?)  used  the  split  corpus  pre-
pared  in  our  second  experiment  (?RWTH?) but
merged with the list of compounds that was also
used in the first experiment. In total, 128 of all
compounds detected by the splitter were also in
our compound list. In order to avoid noise, the
compounds present in the list were deleted from
51
training dev test
Sentences 1.8M 2382 1192
Running words without punctuation (tokens) 40.8M 20K 11K
Vocabulary size (types) 338K 4050 2087
Table 2: Corpus statistics. The training corpus is a concatenation of the complete Europarl Corpus
German?Spanish and a greater part of the TRIS corpus, while in dev and test only texts from the
TRIS corpus were used.
the list of splittings to be carried out in the corpus.
Thus, after all possible splittings were calculated,
those splittings that were present in the manually
compiled compound list  were deleted to ensure
that they were not split in the corpus and remained
the same.
In the fourth experiment (hereinafter ?IMS?) we
used another compound splitter developed at the
Institut f?r Maschinelle Sprachverarbeitung of the
University of Stuttgart (Weller and Heid, 2012).
This splitter was also developed using a frequency-
based approach. However, in this case the train-
ing data consists  of  a  list  of  lemmatized word-
forms together with their POS tags. A set of rules
to model transitional elements is also used. While
this splitter might be used by processing our corpus
with available tools such as TreeTagger (Schmid,
1994)
6
and then computing frequencies, in our ex-
periments we used the CELEX
7
database for Ger-
man (Baayen et al., 1993). This was done so be-
cause CELEX is an extensive high quality lexical
database which already included all the informa-
tion we needed to process and did not require any
further preprocessing and clean up of our corpus.
In  the  fifth  experiment  (hereinafter
?IMS+compList?), we repeated the same procedure
of our third experiment (?RWTH+compList?): we
added the compound list  to  our training corpus
already split, but this time using the compound
splitter  developed  in  Stuttgart. In  total, 125
of  all  compounds  detected  by  the  splitter  were
also in our compound list. The splitting of such
compounds was avoided.
4.2 Compounds detected
Table 3 summarizes the number of compounds de-
tected by the two compound splitters and the per-
centage they account for with respect to the vocab-
ulary and the number of running words.
6http://www.ims.uni-stuttgart.de/projekte/
corplex/TreeTagger/
7http://wwwlands2.let.kun.nl/members/
As can be observed in Table 3, the percentage
of compounds in the test set is considerably higher
than in the training set. This is due to the fact that
in the test set only a subcorpus of the TRIS corpus
was used, whereas in the training corpus Europarl
was also used and as stated earlier (cf. Subsec-
tion 3.1 and table 1), domain specific corpora tend
to have more compounds. It is also noticeable that
the compound splitter developed in Stuttgart de-
tects and splits fewer compounds. A possible ex-
planation would be that Weller and Heid (2012)
only split words into content words and use POS
tags to filter out other highly frequent words that do
not create compounds. The presence of lexicalized
compounds in the CELEX database does not seem
to have affected the accuracy of the splitter (i.e.
they were not skipped by the splitter). Finally, it is
also noticeable that the percentage of compounds
detected in the training set is similar to the one re-
ported by Baroni et al. (2002) and referenced to in
Section 2. This seems to indicate that both splitting
algorithms perform correctly. A thorough analy-
sis of their outputs has been carried out confirm-
ing this hypothesis as the accuracies of both split-
ters were considerably high: 97.19% (RWTH) and
97.49% IMS (Parra Escart?n, forthcoming)
8
.
As SMT system, we  employ  the  state-of-the-
art  phrase-based translation approach (Zens and
Ney, 2008) implemented in Jane. The baseline is
trained on the concatination of the TRIS and Eu-
roparl corpus. Word alignments are trained with
fastAlign (Dyer et al., 2013). Further, we apply
a 4-gram language model trained with the SRILM
toolkit (Stolcke, 2002) on the target side of the
training corpus. The log-linear parameter weights
are tuned with MERT (Och, 2003) on the develop-
ment set (dev). As optimization criterion we use
Bleu. The parameter setting for all experiments
was the same to allow for comparisons.
software/celex_gug.pdf
8
The analysis was done following the method proposed by
Koehn and Knight (2003).
52
Popovic et al. (2006) Weller and Heid (2012)
Compounds in training 182334 141789
% Vocabulary 54% 42%
% Running words 0.4% 0.3%
Compounds in test 924 444
% Vocabulary 44.3% 21.3%
% Running words 8.5% 4%
Table 3: Number of compounds detected by each of the splitters used and the percentages they account
for with respect to the vocabulary (types) and the number of running words (tokens) in the corpora used
in the experiments.
5 Results
Table 4 reports the results of the five training en-
vironments described in Subsection 4.1 and the
baseline. We report results in Bleu [%] and Ter
[%] (Snover et al., 2006). All reported results are
averages over three independent MERT runs, and
we evaluate statistical significance with MultEval
(Clark et al., 2011).
As can be observed in Table 4, adding com-
pound  lists  to  the  training  set  significantly  im-
proves the Bleu and Ter scores with respect to the
baseline. This is also the case when compounds
were preprocessed and split. Moreover, while the
Bleu scores for both splitters are the same when
processing the entire corpus, adding the compound
list to the training corpus yields better scores. In
fact, the combination of the compound list  and
the compound splitter  developed by Weller  and
Heid (2012) improves by 3.8 points in Bleu, while
the approach by Popovi? et al. (2006) improves by
3.4 Bleu points against Baseline. When comparing
it with compList, the improvements are of 3% and
2.4% Bleu respectively. To ensure a fair compar-
ison, RWTH is defined as second baseline. Again,
we observe significant improvement over this sec-
ond baseline by adding the compound list to the
training corpus. In terms of Bleu we gain an im-
provement of up to 1.4 points.
These results seem promising as they show sig-
nificant improvements both in terms of Bleu and
Ter scores. As  previously  mentioned  in  Sec-
tion 3.2, one possible explanation to the higher
Bleu scores we obtained might be that the num-
ber of running words affected by compound split-
ting  was  higher  than  in  other  experiments  like
the  ones  carried  out  by  Popovi?  et  al. (2006)
and Stymne (2008). Fritzinger and Fraser (2010)
used a hybrid splitting algorithm which combined
the  corpus-based  approach  and  linguistic  infor-
mation and also reported better Bleu scores for
German?English translations than splitting algo-
rithms based only in corpus frequencies. They sug-
gested that fewer split compounds but better split
could yield better results. However, in our case the
two splitters score the same in terms of Bleu. Fur-
ther experiments with other language pairs should
be carried out to test whether this is only the case
with  German?Spanish translation tasks  or  not.
If this were to be confirmed, a language depen-
dent approach to dealing with compounds in SMT
might then be needed. The improvements in terms
of Bleu and Ter obtained when adding the man-
ually extracted compound list to our training cor-
pus (particularly in the IMS+compList experiment)
suggest that further preprocessing than just split-
ting the compounds in the corpora would result
in  overall  better  quality  translations. It  is  par-
ticularly noticeable that while the fewest number
of unknown words occurs when using a corpus-
based splitting algorithm (experiments RWTH and
RWTH+compList), this does not seem to directly
correlate with better Bleu and Ter scores. Exper-
iments IMS and IMS+compList had in fact a larger
number of unknown words and yet obtain better
scores.
Table 5 reports the number of compounds of the
compound list found in the test sets across the dif-
ferent experiments. As the compound list was not
preprocessed, the number of compounds found in
RWTH and IMS is smaller than those found in Base-
line and compList. In the case of RWTH+compList
and IMS+compList, however, the productivity of
German compounds mentioned earlier in Section 2
may have influenced the number of compounds
found. If a compound found in our compound list
was present in other compounds and those were
split in such a way that it resulted in one of the
53
test
Experiment Splitting Method Compound List Bleu
[%]
Ter
[%]
OOVs
Baseline - no 45.9 43.9 181
compList - yes 46.7 42.9 169
RWTH Popovi? et al. (2006) no 48.3 40.8 104
RWTH+compList yes 49.1 40.5 104
IMS Weller and Heid (2012) no 48.3 40.5 114
IMS+compList yes 49.7 39.2 114
Table 4: Results for the German?Spanish TRIS data. Statistically significant improvements with at least
99% confidence over the respective baselines (Baseline and RWTH) are printed in boldface.
formants being that compound, its frequency got
higher. As can be observed, the highest number of
correct translations of compounds corresponds to
RWTH+compList and IMS+compList.
Table 6 shows the results of a sample sentence
in our test set including several compounds. As
can be observed, in the IMS+compList experiment
all compounds are correctly translated. This seems
to indicate that the manually compiled list of com-
pounds added to the training corpus helped to in-
crease the probabilities of alignment of 1:n corre-
spondences (German compound ? Spanish MWE)
and thus the compound translations in the phrase
tables are better.
6 Conclusion and future work
In this paper, we have reported the results of our
experiments processing German compounds and
carrying out SMT tasks into Spanish. As has been
observed, adding manually handcrafted compound
lists to the training set significantly improves the
qualitative results of SMT and therefore a way of
automating their extraction would be desired. Fur-
thermore, a combination of splitting compounds
and adding them already aligned to their transla-
tions in the training corpus yields also significant
improvements with respect to the baseline. A qual-
itative analysis is currently being done to assess the
kind of improvements that come from the splitting
and/or the compound list added to training.
As a follow up of the experiments reported here,
the compound splitters used have being evaluated
to assess their precision and recall and determine
which splitting algorithms could be more promis-
ing for SMT tasks and whether or not their quality
has a correlation with better translations. From the
experiments carried out so far, it seems that it may
be the case, but this shall be further explored as our
results do not differ greatly between each other.
In future work we will research whether the ap-
proach suggested here also yields better results in
data used by the MT community. Obtaining bet-
ter overall results would confirm that our approach
is right, in which case we will research how we
can combine both strategies (compound splitting
and adding compound lists and their translations
to training corpora) in a successful and automatic
way. We also intend to explore how we can do
so minimizing the amount of external resources
needed.
Obtaining positive results in these further ex-
periments would suggest that a similar approach
may also yield positive results in dealing with other
types of MWEs within SMT.
Acknowledgments
The research reported in this paper has received
funding from the EU under FP7, Marie Curie Ac-
tions, SP3 People ITN, grant agreement n
o
238405
(project CLARA
9
). The authors would also like to
thank the anonymous reviewers for their valuable
comments.
References
Sybille  Angele. 1992. Nominalkomposita  des
Deutschen und ihre Entsprechungen im Spanischen.
Eine  kontrastive  Untersuchung  anhand  von  Tex-
ten aus Wirtschaft und Literatur. iudicium verlag
GmbH, M?nchen.
S. Atkins, N. Bel, P. Bouillon, T. Charoenporn, D. Gib-
bon, R. Grishman, C.-R. Huan, A. Kawtrakul, N. Ide,
H.-Y.  Lee, P. J. K.  Li, J. McNaught, J. Odijk,
M. Palmer, V. Quochi, R. Reeves, D. M. Sharma,
V. Sornlertlamvanich, T. Tokunaga, G. Thurmair,
M.Villegas, A. Zampolli, and E. Zeiton. 2001. Stan-
dards and Best Practice for Multiligual Computa-
tional Lexicons. MILE (the Multilingual ISLE Lex-
9http://clara.uib.no
54
Experiment Compounds (DE) Compound translations (ES)
Baseline 154 48
compList 154 54
RWTH 85 61
RWTH+compList 175 80
IMS 46 57
IMS+compList 173 76
Table 5: Number of compounds present in our compound list found in the test set for each of the experi-
ments both in German and in Spanish. The experiments with the highest number of translations present
in our compound list are printed in boldface.
Sentence type Example
Original (DE) Abstellanlagen fuer Kraftfahrzeuge in Tiefgaragen oder in Parkdecks
mit mindestens zwei Geschossen
Reference (ES) instalaciones de estacionamiento de autom?viles en garajes subterr?neos
o en estacionamientos cubiertos que tengan como m?nimo dos plantas
Baseline (DE) Abstellanlagen fuer Kraftfahrzeuge in Tiefgaragen oder in Parkdecks
mit mindestens zwei Geschossen
Baseline (ES) plazas para veh?culos en aparcamientos subterr?neos o en plantas
con al menos dos pisos
IMS (DE) abstellen Anlagen fuer Kraft fahren Zeuge in tief Garagen oder in Park Decks
mit mindestens zwei Geschossen
IMS (ES) plazas para veh?culos en aparcamientos subterr?neos o en plantas
con al menos dos pisos
IMS+compList (DE) Abstellanlagen fuer Kraftfahrzeuge in Tiefgaragen oder in Parkdecks
mit mindestens zwei Geschossen
IMS+compList (ES) instalaciones de estacionamiento para autom?viles estacionamientos cubiertos
en garajes subterr?neos o en plantas con al menos dos pisos
Table 6: Sample  translations  for  German?Spanish  for  the  baseline  and  the  experiments IMS and
IMS+compList. Each compound and its translation have the same format.
ical Entry) Deliverable D2.2-D3.2. ISLE project:
ISLE Computational Lexicon Working Group.
R. H. Baayen, R. Piepenbrock, and H. van Rijn. 1993.
The CELEX Lexical Database (CD-ROM). Linguis-
tic  Data  Consortium, University  of  Pennsylvania,
Philadelphia, PA.
Marco Baroni, Johannes Matiasek, and Harald Trost.
2002. Wordform- and Class-based Prediction of the
Components of German Nominal Compounds in an
AAC System. In 19th International Conference on
Computational Linguistics, COLING 2002, Taipei,
Taiwan, August 24 - September 1, 2002.
Jonathan H.  Clark, Chris  Dyer, Alon  Lavie, and
Noah A.  Smith. 2011. Better  hypothesis  test-
ing for statistical machine translation: Controlling
for  optimizer  instability. In 49th  Annual  Meet-
ing of the Association for Computational Linguis-
tics:shortpapers, pages  176?181, Portland, Ore-
gon, June.
Chris Dyer, Victor Chahuneau, and Noah A. Smith.
2013. A simple, fast, and effective reparameteriza-
tion of ibm model 2. In Proc. of NAACL.
Ludwig M. Eichinger. 2000. Deutsche Wortbildung.
Eine Einf?hrung. Gunter Narr Verlag T?bingen.
Wolfgang Fleischer. 1975. Wortbildung der deutschen
Gegenwartssprache. Max Niemeyer Verlag T?bin-
gen, 4 edition.
Fabienne Fritzinger and Alexander Fraser. 2010. How
to  Avoid  Burning  Ducks: Combining  Linguistic
Analysis  and Corpus Statistics  for  German Com-
pound Processing. In Proceedings of the Joint Fifth
Workshop on Statistical  Machine Translation and
MetricsMATR, WMT ?10, pages 224?234, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
Roxana Girju, Dan Moldovan, Marta Tatu, and Daniel
Antohe. 2005. On  the  semantics  of  noun
compounds. Computer  Speech  and  Language,
(4):479?496.
Roxana  Girju. 2008. The  Syntax  and  Semantics
of  Prepositions  in  the  Task  of  Automatic  Inter-
pretation of Nominal Phrases and Compounds: A
Cross-Linguistic Study. Computational Linguistics,
35(2):185?228.
Carmen G?mez P?rez. 2001. La composici?n nominal
alemana desde la perspectiva textual: El compuesto
nominal como dificultad de traducci?n del alem?n al
espa?ol. Ph.D. thesis, Departamento de Traducci?n
55
e Interpretaci?n, Universidad de Salamanca, Sala-
manca.
Philipp  Koehn and Kevin  Knight. 2003. Empiri-
cal Methods for Compound splitting. In Proceed-
ings of the Tenth Conference of the European Chap-
ter of the Association for Computational Linguistics,
pages 187?193, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Philipp Koehn. 2005. Europarl: A Parallel Corpus
for Statistical Machine Translation. In Conference
Proceedings: the Tenth Machine Translation Sum-
mit, pages 79?86, Phuket, Thailand.
Stefan Langer. 1998. Zur morphologie und seman-
tik  von  nominalkomposita. In Tagungsband  der
4. Konferenz zur Verarbeitung nat?rlicher Sprache
(KOVENS).
Torsten Marek. 2006. Analysis of German Compounds
Using Weighted Finite State Transducers. Technical
report, Eberhard-Karls-Universit?t T?bingen.
Franz Josef Och. 2003. Minimum Error Rate Training
in Statistical Machine Translation. pages 160?167,
Sapporo, Japan, July.
Ulrike Oster. 2003. Los t?rminos de la cer?mica en
alem?n y en espa?ol. An?lisis sem?ntico orientado
a la traducci?n de los compuestos nominales ale-
manes. Ph.D. thesis, Departament de Traducci? i
Comunicaci?, Universitat Jaume I, Castell?n.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2001. Bleu: a Method for Automatic
Evaluation of Machine Translation. IBM Research
Report RC22176 (W0109-022), IBMResearch Divi-
sion, Thomas J. Watson Research Center, P.O. Box
218, Yorktown Heights, NY 10598, September.
Carla  Parra Escart?n. 2012. Design and compila-
tion of a specialized Spanish-German parallel cor-
pus. In Proceedings  of  the  Eight  International
Conference on Language Resources and Evaluation
(LREC?12), Istanbul, Turkey, May. European Lan-
guage Resources Association.
Carla Parra Escart?n. forthcoming. Chasing the perfect
splitter: A comparison of different compound split-
ting tools. In Proceedings of the Ninth Conference
on International Language Resources and Evalua-
tion (LREC?14), Reykjavik, Island, May. European
Language Resources Association.
Maja Popovi?, Daniel Stein, and Hermann Ney. 2006.
Statistical machine translation of german compound
words. In Proceedings of the 5th international con-
ference on Advances in Natural Language Process-
ing, FinTAL?06, pages 616?624, Berlin, Heidelberg.
Springer-Verlag.
Jutta Ransmayr, Karlheinz Moerth, and Matej Durco.
2013. Linguistic variation in the austrian media cor-
pus. dealing with the challenges of large amounts of
data. In Proceedings of International Conference on
Corpus Linguistics (CILC), Alicante. University Al-
icante, University Alicante.
Helmut Schmid. 1994. Probabilistic Part-of-Speech
Tagging  Using  Decision  Trees. In International
Conference on New Methods in Language Process-
ing, pages 44?49, Manchester, UK.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciulla, and John Makhoul. 2006. A Study of
Translation Edit Rate with Targeted Human Annota-
tion. In Proceedings of the 7th Conference of the As-
sociation for Machine Translation in the Americas,
pages 223?231, Cambridge, Massachusetts, USA,
August.
Andreas Stolcke. 2002. SRILM ? An Extensible Lan-
guage Modeling Toolkit. In Proc. of the Int. Conf.
on Speech and Language Processing (ICSLP), vol-
ume 2, pages 901?904, Denver, CO, September.
Sara Stymne, Nicola Cancedda, and Lars Ahrenberg.
2013. Generation of Compound Words in Statistical
Machine Translation into Compounding Languages.
Computational Linguistics, pages 1?42.
Sara  Stymne. 2008. German Compounds in  Fac-
tored Statistical Machine Translation. InGoTAL?08:
Proceedings of the 6th international conference on
Advances in Natural Language Processing, pages
464?475. Springer-Verlag.
David Vilar, Daniel  Stein, Matthias Huck, and Her-
mann Ney. 2010. Jane: open source hierarchi-
cal translation, extended with reordering and lexi-
con models. In Proceedings of the Joint Fifth Work-
shop on Statistical Machine Translation and Met-
ricsMATR, WMT ?10, pages 262?270, Stroudsburg,
PA, USA. Association for Computational Linguis-
tics.
Marion Weller and Ulrich Heid. 2012. Analyzing
and Aligning German compound nouns. In Pro-
ceedings of the Eight International Conference on
Language Resources and Evaluation (LREC?12), Is-
tanbul, Turkey, May. European Language Resources
Association.
Hans Wellman, 1984. DUDEN. Die Grammatik. Un-
entbehrlich f?r richtiges Deutsch, volume 4, chapter
Die Wortbildung. Duden Verlag.
Joern Wuebker, Matthias Huck, Stephan Peitz, Malte
Nuhn, Markus  Freitag, Jan-Thorsten  Peter, Saab
Mansour, and Hermann Ney. 2012. Jane 2: Open
source phrase-based and hierarchical statistical ma-
chine translation. In International Conference on
Computational Linguistics, pages 483?491, Mum-
bai, India, December.
Richard Zens and Hermann Ney. 2008. Improvements
in Dynamic Programming Beam Search for Phrase-
based Statistical Machine Translation. In Interna-
tional Workshop on Spoken Language Translation,
pages 195?205, Honolulu, Hawaii, October.
56
Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 105?113,
Baltimore, Maryland USA, June 26?27, 2014.
c?2014 Association for Computational Linguistics
EU-BRIDGE MT: Combined Machine Translation
?
Markus Freitag,
?
Stephan Peitz,
?
Joern Wuebker,
?
Hermann Ney,
?
Matthias Huck,
?
Rico Sennrich,
?
Nadir Durrani,
?
Maria Nadejde,
?
Philip Williams,
?
Philipp Koehn,
?
Teresa Herrmann,
?
Eunah Cho,
?
Alex Waibel
?
RWTH Aachen University, Aachen, Germany
?
University of Edinburgh, Edinburgh, Scotland
?
Karlsruhe Institute of Technology, Karlsruhe, Germany
?
{freitag,peitz,wuebker,ney}@cs.rwth-aachen.de
?
{mhuck,ndurrani,pkoehn}@inf.ed.ac.uk
?
v1rsennr@staffmail.ed.ac.uk
?
maria.nadejde@gmail.com,p.j.williams-2@sms.ed.ac.uk
?
{teresa.herrmann,eunah.cho,alex.waibel}@kit.edu
Abstract
This paper describes one of the col-
laborative efforts within EU-BRIDGE to
further advance the state of the art in
machine translation between two Euro-
pean language pairs, German?English
and English?German. Three research
institutes involved in the EU-BRIDGE
project combined their individual machine
translation systems and participated with a
joint setup in the shared translation task of
the evaluation campaign at the ACL 2014
Eighth Workshop on Statistical Machine
Translation (WMT 2014).
We combined up to nine different machine
translation engines via system combina-
tion. RWTH Aachen University, the Uni-
versity of Edinburgh, and Karlsruhe In-
stitute of Technology developed several
individual systems which serve as sys-
tem combination input. We devoted spe-
cial attention to building syntax-based sys-
tems and combining them with the phrase-
based ones. The joint setups yield em-
pirical gains of up to 1.6 points in BLEU
and 1.0 points in TER on the WMT news-
test2013 test set compared to the best sin-
gle systems.
1 Introduction
EU-BRIDGE
1
is a European research project
which is aimed at developing innovative speech
translation technology. This paper describes a
1
http://www.eu-bridge.eu
joint WMT submission of three EU-BRIDGE
project partners. RWTH Aachen University
(RWTH), the University of Edinburgh (UEDIN)
and Karlsruhe Institute of Technology (KIT) all
provided several individual systems which were
combined by means of the RWTH Aachen system
combination approach (Freitag et al., 2014). As
distinguished from our EU-BRIDGE joint submis-
sion to the IWSLT 2013 evaluation campaign (Fre-
itag et al., 2013), we particularly focused on trans-
lation of news text (instead of talks) for WMT. Be-
sides, we put an emphasis on engineering syntax-
based systems in order to combine them with our
more established phrase-based engines. We built
combined system setups for translation from Ger-
man to English as well as from English to Ger-
man. This paper gives some insight into the tech-
nology behind the system combination framework
and the combined engines which have been used
to produce the joint EU-BRIDGE submission to
the WMT 2014 translation task.
The remainder of the paper is structured as fol-
lows: We first describe the individual systems by
RWTH Aachen University (Section 2), the Uni-
versity of Edinburgh (Section 3), and Karlsruhe
Institute of Technology (Section 4). We then
present the techniques for machine translation sys-
tem combination in Section 5. Experimental re-
sults are given in Section 6. We finally conclude
the paper with Section 7.
2 RWTH Aachen University
RWTH (Peitz et al., 2014) employs both the
phrase-based (RWTH scss) and the hierarchical
(RWTH hiero) decoder implemented in RWTH?s
publicly available translation toolkit Jane (Vilar
105
et al., 2010; Wuebker et al., 2012). The model
weights of all systems have been tuned with stan-
dard Minimum Error Rate Training (Och, 2003)
on a concatenation of the newstest2011 and news-
test2012 sets. RWTH used BLEU as optimiza-
tion objective. Both for language model estima-
tion and querying at decoding, the KenLM toolkit
(Heafield et al., 2013) is used. All RWTH sys-
tems include the standard set of models provided
by Jane. Both systems have been augmented with
a hierarchical orientation model (Galley and Man-
ning, 2008; Huck et al., 2013) and a cluster lan-
guage model (Wuebker et al., 2013). The phrase-
based system (RWTH scss) has been further im-
proved by maximum expected BLEU training sim-
ilar to (He and Deng, 2012). The latter has been
performed on a selection from the News Commen-
tary, Europarl and Common Crawl corpora based
on language and translation model cross-entropies
(Mansour et al., 2011).
3 University of Edinburgh
UEDIN contributed phrase-based and syntax-
based systems to both the German?English and
the English?German joint submission.
3.1 Phrase-based Systems
UEDIN?s phrase-based systems (Durrani et al.,
2014) have been trained using the Moses toolkit
(Koehn et al., 2007), replicating the settings de-
scribed in (Durrani et al., 2013b). The features
include: a maximum sentence length of 80, grow-
diag-final-and symmetrization of GIZA
++
align-
ments, an interpolated Kneser-Ney smoothed 5-
gram language model with KenLM (Heafield,
2011) used at runtime, a lexically-driven 5-gram
operation sequence model (OSM) (Durrani et al.,
2013a), msd-bidirectional-fe lexicalized reorder-
ing, sparse lexical and domain features (Hasler
et al., 2012), a distortion limit of 6, a maxi-
mum phrase length of 5, 100-best translation op-
tions, Minimum Bayes Risk decoding (Kumar and
Byrne, 2004), cube pruning (Huang and Chiang,
2007), with a stack size of 1000 during tuning and
5000 during testing and the no-reordering-over-
punctuation heuristic. UEDIN uses POS and mor-
phological target sequence models built on the in-
domain subset of the parallel corpus using Kneser-
Ney smoothed 7-gram models as additional factors
in phrase translation models (Koehn and Hoang,
2007). UEDIN has furthermore built OSM mod-
els over POS and morph sequences following
Durrani et al. (2013c). The English?German
system additionally comprises a target-side LM
over automatically built word classes (Birch et
al., 2013). UEDIN has applied syntactic pre-
reordering (Collins et al., 2005) and compound
splitting (Koehn and Knight, 2003) of the source
side for the German?English system. The sys-
tems have been tuned on a very large tuning set
consisting of the test sets from 2008-2012, with
a total of 13,071 sentences. UEDIN used news-
test2013 as held-out test set. On top of UEDIN
phrase-based 1 system, UEDIN phrase-based 2
augments word classes as additional factor and
learns an interpolated target sequence model over
cluster IDs. Furthermore, it learns OSM models
over POS, morph and word classes.
3.2 Syntax-based Systems
UEDIN?s syntax-based systems (Williams et al.,
2014) follow the GHKM syntax approach as pro-
posed by Galley, Hopkins, Knight, and Marcu
(Galley et al., 2004). The open source Moses
implementation has been employed to extract
GHKM rules (Williams and Koehn, 2012). Com-
posed rules (Galley et al., 2006) are extracted in
addition to minimal rules, but only up to the fol-
lowing limits: at most twenty tree nodes per rule,
a maximum depth of five, and a maximum size of
five. Singleton hierarchical rules are dropped.
The features for the syntax-based systems com-
prise Good-Turing-smoothed phrase translation
probabilities, lexical translation probabilities in
both directions, word and phrase penalty, a rule
rareness penalty, a monolingual PCFG probability,
and a 5-gram language model. UEDIN has used
the SRILM toolkit (Stolcke, 2002) to train the lan-
guage model and relies on KenLM for language
model scoring during decoding. Model weights
are optimized to maximize BLEU. 2000 sentences
from the newstest2008-2012 sets have been se-
lected as a development set. The selected sen-
tences obtained high sentence-level BLEU scores
when being translated with a baseline phrase-
based system, and each contain less than 30 words
for more rapid tuning. Decoding for the syntax-
based systems is carried out with cube pruning
using Moses? hierarchical decoder (Hoang et al.,
2009).
UEDIN?s German?English syntax-based setup
is a string-to-tree system with compound splitting
106
on the German source-language side and syntactic
annotation from the Berkeley Parser (Petrov et al.,
2006) on the English target-language side.
For English?German, UEDIN has trained var-
ious string-to-tree GHKM syntax systems which
differ with respect to the syntactic annotation. A
tree-to-string system and a string-to-string system
(with rules that are not syntactically decorated)
have been trained as well. The English?German
UEDIN GHKM system names in Table 3 denote:
UEDIN GHKM S2T (ParZu): A string-to-tree
system trained with target-side syntactic an-
notation obtained with ParZu (Sennrich et
al., 2013). It uses a modified syntactic label
set, target-side compound splitting, and addi-
tional syntactic constraints.
UEDIN GHKM S2T (BitPar): A string-to-tree
system trained with target-side syntactic
annotation obtained with BitPar (Schmid,
2004).
UEDIN GHKM S2T (Stanford): A string-to-
tree system trained with target-side syntactic
annotation obtained with the German Stan-
ford Parser (Rafferty and Manning, 2008a).
UEDIN GHKM S2T (Berkeley): A string-to-
tree system trained with target-side syntactic
annotation obtained with the German Berke-
ley Parser (Petrov and Klein, 2007; Petrov
and Klein, 2008).
UEDIN GHKM T2S (Berkeley): A tree-to-
string system trained with source-side syn-
tactic annotation obtained with the English
Berkeley Parser (Petrov et al., 2006).
UEDIN GHKM S2S (Berkeley): A string-to-
string system. The extraction is GHKM-
based with syntactic target-side annotation
from the German Berkeley Parser, but we
strip off the syntactic labels. The final gram-
mar contains rules with a single generic non-
terminal instead of syntactic ones, plus rules
that have been added from plain phrase-based
extraction (Huck et al., 2014).
4 Karlsruhe Institute of Technology
The KIT translations (Herrmann et al., 2014) are
generated by an in-house phrase-based transla-
tions system (Vogel, 2003). The provided News
Commentary, Europarl, and Common Crawl par-
allel corpora are used for training the translation
model. The monolingual part of those parallel
corpora, the News Shuffle corpus for both direc-
tions and additionally the Gigaword corpus for
German?English are used as monolingual train-
ing data for the different language models. Opti-
mization is done with Minimum Error Rate Train-
ing as described in (Venugopal et al., 2005), using
newstest2012 and newstest2013 as development
and test data respectively.
Compound splitting (Koehn and Knight, 2003)
is performed on the source side of the corpus for
German?English translation before training. In
order to improve the quality of the web-crawled
Common Crawl corpus, noisy sentence pairs are
filtered out using an SVM classifier as described
by Mediani et al. (2011).
The word alignment for German?English is
generated using the GIZA
++
toolkit (Och and Ney,
2003). For English?German, KIT uses discrimi-
native word alignment (Niehues and Vogel, 2008).
Phrase extraction and scoring is done using the
Moses toolkit (Koehn et al., 2007). Phrase pair
probabilities are computed using modified Kneser-
Ney smoothing as in (Foster et al., 2006).
In both systems KIT applies short-range re-
orderings (Rottmann and Vogel, 2007) and long-
range reorderings (Niehues and Kolss, 2009)
based on POS tags (Schmid, 1994) to perform
source sentence reordering according to the target
language word order. The long-range reordering
rules are applied to the training corpus to create
reordering lattices to extract the phrases for the
translation model. In addition, a tree-based re-
ordering model (Herrmann et al., 2013) trained
on syntactic parse trees (Rafferty and Manning,
2008b; Klein and Manning, 2003) as well as a lex-
icalized reordering model (Koehn et al., 2005) are
applied.
Language models are trained with the SRILM
toolkit (Stolcke, 2002) and use modified Kneser-
Ney smoothing. Both systems utilize a lan-
guage model based on automatically learned
word classes using the MKCLS algorithm (Och,
1999). The English?German system comprises
language models based on fine-grained part-of-
speech tags (Schmid and Laws, 2008). In addi-
tion, a bilingual language model (Niehues et al.,
2011) is used as well as a discriminative word lex-
icon (Mauser et al., 2009) using source context to
guide the word choices in the target sentence.
107
In total, the English?German system uses the
following language models: two 4-gram word-
based language models trained on the parallel data
and the filtered Common Crawl data separately,
two 5-gram POS-based language models trained
on the same data as the word-based language mod-
els, and a 4-gram cluster-based language model
trained on 1,000 MKCLS word classes.
The German?English system uses a 4-gram
word-based language model trained on all mono-
lingual data and an additional language model
trained on automatically selected data (Moore and
Lewis, 2010). Again, a 4-gram cluster-based
language model trained on 1000 MKCLS word
classes is applied.
5 System Combination
System combination is used to produce consen-
sus translations from multiple hypotheses which
are outputs of different translation engines. The
consensus translations can be better in terms of
translation quality than any of the individual hy-
potheses. To combine the engines of the project
partners for the EU-BRIDGE joint setups, we ap-
ply a system combination implementation that has
been developed at RWTH Aachen University.
The implementation of RWTH?s approach to
machine translation system combination is de-
scribed in (Freitag et al., 2014). This approach
includes an enhanced alignment and reordering
framework. Alignments between the system out-
puts are learned using METEOR (Banerjee and
Lavie, 2005). A confusion network is then built
using one of the hypotheses as ?primary? hypoth-
esis. We do not make a hard decision on which
of the hypotheses to use for that, but instead com-
bine all possible confusion networks into a single
lattice. Majority voting on the generated lattice
is performed using the prior probabilities for each
system as well as other statistical models, e.g. a
special n-gram language model which is learned
on the input hypotheses. Scaling factors of the
models are optimized using the Minimum Error
Rate Training algorithm. The translation with the
best total score within the lattice is selected as con-
sensus translation.
6 Results
In this section, we present our experimental results
on the two translation tasks, German?English
and English?German. The weights of the in-
dividual system engines have been optimized on
different test sets which partially or fully include
newstest2011 or newstest2012. System combina-
tion weights are either optimized on newstest2011
or newstest2012. We kept newstest2013 as an un-
seen test set which has not been used for tuning
the system combination or any of the individual
systems.
6.1 German?English
The automatic scores of all individual systems
as well as of our final system combination sub-
mission are given in Table 1. KIT, UEDIN and
RWTH are each providing one individual phrase-
based system output. RWTH (hiero) and UEDIN
(GHKM) are providing additional systems based
on the hierarchical translation model and a string-
to-tree syntax model. The pairwise difference
of the single system performances is up to 1.3
points in BLEU and 2.5 points in TER. For
German?English, our system combination pa-
rameters are optimized on newstest2012. System
combination gives us a gain of 1.6 points in BLEU
and 1.0 points in TER for newstest2013 compared
to the best single system.
In Table 2 the pairwise BLEU scores for all in-
dividual systems as well as for the system combi-
nation output are given. The pairwise BLEU score
of both RWTH systems (taking one as hypothesis
and the other one as reference) is the highest for all
pairs of individual system outputs. A high BLEU
score means similar hypotheses. The syntax-based
system of UEDIN and RWTH scss differ mostly,
which can be observed from the fact of the low-
est pairwise BLEU score. Furthermore, we can
see that better performing individual systems have
higher BLEU scores when evaluating against the
system combination output.
In Figure 1 system combination output is com-
pared to the best single system KIT. We distribute
the sentence-level BLEU scores of all sentences of
newstest2013. To allow for sentence-wise evalu-
ation, all bi-, tri-, and four-gram counts are ini-
tialized with 1 instead of 0. Many sentences have
been improved by system combination. Neverthe-
less, some sentences fall off in quality compared
to the individual system output of KIT.
6.2 English?German
The results of all English?German system setups
are given in Table 3. For the English?German
translation task, only UEDIN and KIT are con-
108
system newstest2011 newstest2012 newstest2013
BLEU TER BLEU TER BLEU TER
KIT 25.0 57.6 25.2 57.4 27.5 54.4
UEDIN 23.9 59.2 24.7 58.3 27.4 55.0
RWTH scss 23.6 59.5 24.2 58.5 27.0 55.0
RWTH hiero 23.3 59.9 24.1 59.0 26.7 55.9
UEDIN GHKM S2T (Berkeley) 23.0 60.1 23.2 60.8 26.2 56.9
syscom 25.6 57.1 26.4 56.5 29.1 53.4
Table 1: Results for the German?English translation task. The system combination is tuned on news-
test2012, newstest2013 is used as held-out test set for all individual systems and system combination.
Bold font indicates system combination results that are significantly better than the best single system
with p < 0.05.
KIT UEDIN RWTH scss RWTH hiero UEDIN S2T syscom
KIT 59.07 57.60 57.91 55.62 77.68
UEDIN 59.17 56.96 57.84 59.89 72.89
RWTH scss 57.64 56.90 64.94 53.10 71.16
RWTH hiero 57.98 57.80 64.97 55.73 70.87
UEDIN S2T 55.75 59.95 53.19 55.82 65.35
syscom 77.76 72.83 71.17 70.85 65.24
Table 2: Cross BLEU scores for the German?English newstest2013 test set. (Pairwise BLEU scores:
each entry is taking the horizontal system as hypothesis and the other one as reference.)
system newstest2011 newstest2012 newstest2013
BLEU TER BLEU TER BLEU TER
UEDIN phrase-based 1 17.5 67.3 18.2 65.0 20.5 62.7
UEDIN phrase-based 2 17.8 66.9 18.5 64.6 20.8 62.3
UEDIN GHKM S2T (ParZu) 17.2 67.6 18.0 65.5 20.2 62.8
UEDIN GHKM S2T (BitPar) 16.3 69.0 17.3 66.6 19.5 63.9
UEDIN GHKM S2T (Stanford) 16.1 69.2 17.2 67.0 19.0 64.2
UEDIN GHKM S2T (Berkeley) 16.3 68.9 17.2 66.7 19.3 63.8
UEDIN GHKM T2S (Berkeley) 16.7 68.9 17.5 66.9 19.5 63.8
UEDIN GHKM S2S (Berkeley) 16.3 69.2 17.3 66.8 19.1 64.3
KIT 17.1 67.0 17.8 64.8 20.2 62.2
syscom 18.4 65.0 18.7 63.4 21.3 60.6
Table 3: Results for the English?German translation task. The system combination is tuned on news-
test2011, newstest2013 is used as held-out test set for all individual systems and system combination.
Bold font indicates system combination results that are significantly (Bisani and Ney, 2004) better than
the best single system with p< 0.05. Italic font indicates system combination results that are significantly
better than the best single system with p < 0.1.
tributing individual systems. KIT is providing a
phrase-based system output, UEDIN is providing
two phrase-based system outputs and six syntax-
based ones (GHKM). For English?German, our
system combination parameters are optimized on
newstest2011. Combining all nine different sys-
tem outputs yields an improvement of 0.5 points
in BLEU and 1.7 points in TER over the best sin-
gle system performance.
In Table 4 the cross BLEU scores for all
English?German systems are given. The individ-
ual system of KIT and the syntax-based ParZu sys-
tem of UEDIN have the lowest BLEU score when
scored against each other. Both approaches are
quite different and both are coming from differ-
ent institutes. In contrast, both phrase-based sys-
tems pbt 1 and pbt 2 from UEDIN are very sim-
ilar and hence have a high pairwise BLEU score.
109
pbt 1 pbt 2 ParZu BitPar Stanford S2T T2S S2S KIT syscom
pbt 1 75.84 51.61 53.93 55.32 54.79 54.52 60.92 54.80 70.12
pbt 2 75.84 51.96 53.39 53.93 53.97 53.10 57.32 54.04 73.75
ParZu 51.57 51.91 56.67 55.11 56.05 52.13 51.22 48.14 68.39
BitPar 54.00 53.45 56.78 64.59 65.67 56.33 56.62 49.23 62.08
Stanford 55.37 53.98 55.19 64.56 69.22 58.81 61.19 50.50 61.51
S2T 54.83 54.02 56.14 65.64 69.21 59.32 60.16 50.07 62.81
T2S 54.57 53.15 52.21 56.30 58.81 59.32 59.34 50.01 63.13
S2S 60.96 57.36 51.29 56.59 61.18 60.15 59.33 53.68 60.46
KIT 54.75 53.98 48.13 49.13 50.41 49.98 49.93 53.59 63.33
syscom 70.01 73.63 68.32 61.92 61.37 62.67 62.99 60.32 63.27
Table 4: Cross BLEU scores for the German?English newstest2013 test set. (Pairwise BLEU scores:
each entry is taking the horizontal system as reference and the other one as hypothesis.)
 0
 50
 100
 150
 200
 250
 300
 350
 400
 0  20  40  60  80  100
amo
unt 
sent
ence
s
sBLEU
bettersameworse
Figure 1: Sentence distribution for the
German?English newstest2013 test set compar-
ing system combination output against the best
individual system.
As for the German?English translation direction,
the best performing individual system outputs are
also having the highest BLEU scores when evalu-
ated against the final system combination output.
In Figure 2 system combination output is com-
pared to the best single system pbt 2. We distribute
the sentence-level BLEU scores of all sentences
of newstest2013. Many sentences have been im-
proved by system combination. But there is still
room for improvement as some sentences are still
better in terms of sentence-level BLEU in the indi-
vidual best system pbt 2.
7 Conclusion
We achieved significantly better translation perfor-
mance with gains of up to +1.6 points in BLEU
and -1.0 points in TER by combining up to nine
different machine translation systems. Three dif-
ferent research institutes (RWTH Aachen Univer-
sity, University of Edinburgh, Karlsruhe Institute
of Technology) provided machine translation en-
gines based on different approaches like phrase-
 0
 50
 100
 150
 200
 250
 300
 350
 400
 0  20  40  60  80  100
amo
unt 
sent
ence
s
sBLEU
bettersameworse
Figure 2: Sentence distribution for the
English?German newstest2013 test set compar-
ing system combination output against the best
individual system.
based, hierarchical phrase-based, and syntax-
based. For English?German, we included six
different syntax-based systems, which were com-
bined to our final combined translation. The au-
tomatic scores of all submitted system outputs for
the actual 2014 evaluation set are presented on the
WMT submission page.
2
Our joint submission is
the best submission in terms of BLEU and TER for
both translation directions German?English and
English?German without adding any new data.
Acknowledgements
The research leading to these results has received
funding from the European Union Seventh Frame-
work Programme (FP7/2007-2013) under grant
agreement n
o
287658.
Rico Sennrich has received funding from the
Swiss National Science Foundation under grant
P2ZHP1 148717.
2
http://matrix.statmt.org/
110
References
Satanjeev Banerjee and Alon Lavie. 2005. METEOR:
An Automatic Metric for MT Evaluation with Im-
proved Correlation with Human Judgments. In 43rd
Annual Meeting of the Assoc. for Computational
Linguistics: Proc. Workshop on Intrinsic and Extrin-
sic Evaluation Measures for MT and/or Summariza-
tion, pages 65?72, Ann Arbor, MI, USA, June.
Alexandra Birch, Nadir Durrani, and Philipp Koehn.
2013. Edinburgh SLT and MT System Description
for the IWSLT 2013 Evaluation. In Proceedings
of the 10th International Workshop on Spoken Lan-
guage Translation, pages 40?48, Heidelberg, Ger-
many, December.
Maximilian Bisani and Hermann Ney. 2004. Bootstrap
Estimates for Confidence Intervals in ASR Perfor-
mance Evaluation. In IEEE International Confer-
ence on Acoustics, Speech, and Signal Processing,
volume 1, pages 409?412, Montr?eal, Canada, May.
Michael Collins, Philipp Koehn, and Ivona Kucerova.
2005. Clause Restructuring for Statistical Ma-
chine Translation. In Proceedings of the 43rd An-
nual Meeting of the Association for Computational
Linguistics (ACL?05), pages 531?540, Ann Arbor,
Michigan, June.
Nadir Durrani, Alexander Fraser, Helmut Schmid,
Hieu Hoang, and Philipp Koehn. 2013a. Can
Markov Models Over Minimal Translation Units
Help Phrase-Based SMT? In Proceedings of the
51st Annual Meeting of the Association for Compu-
tational Linguistics, Sofia, Bulgaria, August.
Nadir Durrani, Barry Haddow, Kenneth Heafield, and
Philipp Koehn. 2013b. Edinburgh?s Machine Trans-
lation Systems for European Language Pairs. In
Proceedings of the Eighth Workshop on Statistical
Machine Translation, Sofia, Bulgaria, August.
Nadir Durrani, Helmut Schmid, Alexander Fraser, Has-
san Sajjad, and Richard Farkas. 2013c. Munich-
Edinburgh-Stuttgart Submissions of OSM Systems
at WMT13. In Proceedings of the Eighth Workshop
on Statistical Machine Translation, Sofia, Bulgaria.
Nadir Durrani, Barry Haddow, Philipp Koehn, and
Kenneth Heafield. 2014. Edinburgh?s Phrase-based
Machine Translation Systems for WMT-14. In Pro-
ceedings of the ACL 2014 Ninth Workshop on Sta-
tistical Machine Translation, Baltimore, MD, USA,
June.
George Foster, Roland Kuhn, and Howard Johnson.
2006. Phrasetable Smoothing for Statistical Ma-
chine Translation. In EMNLP, pages 53?61.
M. Freitag, S. Peitz, J. Wuebker, H. Ney, N. Dur-
rani, M. Huck, P. Koehn, T.-L. Ha, J. Niehues,
M. Mediani, T. Herrmann, A. Waibel, N. Bertoldi,
M. Cettolo, and M. Federico. 2013. EU-BRIDGE
MT: Text Translation of Talks in the EU-BRIDGE
Project. In International Workshop on Spoken Lan-
guage Translation, Heidelberg, Germany, Decem-
ber.
Markus Freitag, Matthias Huck, and Hermann Ney.
2014. Jane: Open Source Machine Translation Sys-
tem Combination. In Conference of the European
Chapter of the Association for Computational Lin-
guistics, Gothenburg, Sweden, April.
Michel Galley and Christopher D. Manning. 2008. A
Simple and Effective Hierarchical Phrase Reorder-
ing Model. In Proceedings of the 2008 Conference
on Empirical Methods in Natural Language Pro-
cessing, pages 847?855, Honolulu, HI, USA, Octo-
ber.
Michel Galley, Mark Hopkins, Kevin Knight, and
Daniel Marcu. 2004. What?s in a translation rule?
In Proc. of the Human Language Technology Conf.
/ North American Chapter of the Assoc. for Compu-
tational Linguistics (HLT-NAACL), pages 273?280,
Boston, MA, USA, May.
Michel Galley, Jonathan Graehl, Kevin Knight, Daniel
Marcu, Steve DeNeefe, Wei Wang, and Ignacio
Thayer. 2006. Scalable Inference and Training
of Context-Rich Syntactic Translation Models. In
Proc. of the 21st International Conf. on Computa-
tional Linguistics and 44th Annual Meeting of the
Assoc. for Computational Linguistics, pages 961?
968, Sydney, Australia, July.
Eva Hasler, Barry Haddow, and Philipp Koehn. 2012.
Sparse Lexicalised features and Topic Adaptation
for SMT. In Proceedings of the seventh Interna-
tional Workshop on Spoken Language Translation
(IWSLT), pages 268?275.
Xiaodong He and Li Deng. 2012. Maximum Expected
BLEU Training of Phrase and Lexicon Translation
Models. In Proceedings of the 50th Annual Meet-
ing of the Association for Computational Linguis-
tics (ACL), pages 292?301, Jeju, Republic of Korea,
July.
Kenneth Heafield, Ivan Pouzyrevsky, Jonathan H.
Clark, and Philipp Koehn. 2013. Scalable modi-
fied Kneser-Ney language model estimation. In Pro-
ceedings of the 51st Annual Meeting of the Associa-
tion for Computational Linguistics, pages 690?696,
Sofia, Bulgaria, August.
Kenneth Heafield. 2011. KenLM: Faster and Smaller
Language Model Queries. In Proceedings of the
Sixth Workshop on Statistical Machine Translation,
pages 187?197, Edinburgh, Scotland, UK, July.
Teresa Herrmann, Jan Niehues, and Alex Waibel.
2013. Combining Word Reordering Methods on
different Linguistic Abstraction Levels for Statisti-
cal Machine Translation. In Proceedings of the Sev-
enth Workshop on Syntax, Semantics and Structure
in Statistical Translation, Atlanta, GA, USA, June.
111
Teresa Herrmann, Mohammed Mediani, Eunah Cho,
Thanh-Le Ha, Jan Niehues, Isabel Slawik, Yuqi
Zhang, and Alex Waibel. 2014. The Karlsruhe In-
stitute of Technology Translation Systems for the
WMT 2014. In Proceedings of the ACL 2014 Ninth
Workshop on Statistical Machine Translation, Balti-
more, MD, USA, June.
Hieu Hoang, Philipp Koehn, and Adam Lopez. 2009.
A Unified Framework for Phrase-Based, Hierarchi-
cal, and Syntax-Based Statistical Machine Transla-
tion. pages 152?159, Tokyo, Japan, December.
Liang Huang and David Chiang. 2007. Forest Rescor-
ing: Faster Decoding with Integrated Language
Models. In Proceedings of the 45th Annual Meet-
ing of the Association of Computational Linguistics,
pages 144?151, Prague, Czech Republic, June.
Matthias Huck, Joern Wuebker, Felix Rietig, and Her-
mann Ney. 2013. A Phrase Orientation Model
for Hierarchical Machine Translation. In ACL 2013
Eighth Workshop on Statistical Machine Transla-
tion, pages 452?463, Sofia, Bulgaria, August.
Matthias Huck, Hieu Hoang, and Philipp Koehn.
2014. Augmenting String-to-Tree and Tree-to-
String Translation with Non-Syntactic Phrases. In
Proceedings of the ACL 2014 Ninth Workshop on
Statistical Machine Translation, Baltimore, MD,
USA, June.
Dan Klein and Christopher D. Manning. 2003. Accu-
rate Unlexicalized Parsing. In Proceedings of ACL
2003.
Philipp Koehn and Hieu Hoang. 2007. Factored Trans-
lation Models. In EMNLP-CoNLL, pages 868?876,
Prague, Czech Republic, June.
Philipp Koehn and Kevin Knight. 2003. Empirical
Methods for Compound Splitting. In EACL, Bu-
dapest, Hungary.
Philipp Koehn, Amittai Axelrod, Alexandra B. Mayne,
Chris Callison-Burch, Miles Osborne, and David
Talbot. 2005. Edinburgh System Description for
the 2005 IWSLT Speech Translation Evaluation. In
Proceedings of the International Workshop on Spo-
ken Language Translation (IWSLT), Pittsburgh, PA,
USA.
P. Koehn, H. Hoang, A. Birch, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,
and E. Herbst. 2007. Moses: Open Source Toolkit
for Statistical Machine Translation. In Proceedings
of the 45th Annual Meeting of the ACL on Interactive
Poster and Demonstration Sessions, pages 177?180,
Prague, Czech Republic, June.
Shankar Kumar and William Byrne. 2004. Mini-
mum Bayes-Risk Decoding for Statistical Machine
Translation. In Proc. Human Language Technol-
ogy Conf. / North American Chapter of the Associa-
tion for Computational Linguistics Annual Meeting
(HLT-NAACL), pages 169?176, Boston, MA, USA,
May.
Saab Mansour, Joern Wuebker, and Hermann Ney.
2011. Combining Translation and Language Model
Scoring for Domain-Specific Data Filtering. In Pro-
ceedings of the International Workshop on Spoken
Language Translation (IWSLT), pages 222?229, San
Francisco, CA, USA, December.
Arne Mauser, Sa?sa Hasan, and Hermann Ney. 2009.
Extending Statistical Machine Translation with Dis-
criminative and Trigger-Based Lexicon Models. In
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 210?217, Singapore, Au-
gust.
Mohammed Mediani, Eunah Cho, Jan Niehues, Teresa
Herrmann, and Alex Waibel. 2011. The KIT
English-French Translation systems for IWSLT
2011. In Proceedings of the Eight Interna-
tional Workshop on Spoken Language Translation
(IWSLT), San Francisco, CA, USA.
Robert C. Moore and William Lewis. 2010. Intelligent
selection of language model training data. In Pro-
ceedings of the ACL 2010 Conference Short Papers,
pages 220?224, Uppsala, Sweden, July.
Jan Niehues and Muntsin Kolss. 2009. A POS-Based
Model for Long-Range Reorderings in SMT. In
Fourth Workshop on Statistical Machine Translation
(WMT 2009), Athens, Greece.
Jan Niehues and Stephan Vogel. 2008. Discriminative
Word Alignment via Alignment Matrix Modeling.
In Proceedings of Third ACL Workshop on Statisti-
cal Machine Translation, Columbus, USA.
Jan Niehues, Teresa Herrmann, Stephan Vogel, and
Alex Waibel. 2011. Wider Context by Using Bilin-
gual Language Models in Machine Translation. In
Sixth Workshop on Statistical Machine Translation
(WMT 2011), Edinburgh, UK.
Franz Josef Och and Hermann Ney. 2003. A System-
atic Comparison of Various Statistical Alignment
Models. Computational Linguistics, 29(1):19?51.
Franz Josef Och. 1999. An Efficient Method for De-
termining Bilingual Word Classes. In EACL?99.
Franz Josef Och. 2003. Minimum Error Rate Training
in Statistical Machine Translation. In Proc. of the
41th Annual Meeting of the Association for Compu-
tational Linguistics (ACL), pages 160?167, Sapporo,
Japan, July.
Stephan Peitz, Joern Wuebker, Markus Freitag, and
Hermann Ney. 2014. The RWTH Aachen German-
English Machine Translation System for WMT
2014. In Proceedings of the ACL 2014 Ninth Work-
shop on Statistical Machine Translation, Baltimore,
MD, USA, June.
112
Slav Petrov and Dan Klein. 2007. Improved Inference
for Unlexicalized Parsing. In Human Language
Technologies 2007: The Conference of the North
American Chapter of the Association for Computa-
tional Linguistics; Proceedings of the Main Confer-
ence, pages 404?411, Rochester, New York, April.
Slav Petrov and Dan Klein. 2008. Parsing German
with Latent Variable Grammars. In Proceedings of
the Workshop on Parsing German at ACL ?08, pages
33?39, Columbus, OH, USA, June.
Slav Petrov, Leon Barrett, Romain Thibaux, and Dan
Klein. 2006. Learning Accurate, Compact, and In-
terpretable Tree Annotation. In Proc. of the 21st In-
ternational Conference on Computational Linguis-
tics and 44th Annual Meeting of the Assoc. for
Computational Linguistics, pages 433?440, Sydney,
Australia, July.
Anna N. Rafferty and Christopher D. Manning. 2008a.
Parsing Three German Treebanks: Lexicalized and
Unlexicalized Baselines. In Proceedings of the
Workshop on Parsing German at ACL ?08, pages 40?
46, Columbus, OH, USA, June.
Anna N. Rafferty and Christopher D. Manning. 2008b.
Parsing Three German Treebanks: Lexicalized and
Unlexicalized Baselines. In Proceedings of the
Workshop on Parsing German.
Kay Rottmann and Stephan Vogel. 2007. Word Re-
ordering in Statistical Machine Translation with a
POS-Based Distortion Model. In Proceedings of
the 11th International Conference on Theoretical
and Methodological Issues in Machine Translation
(TMI), Sk?ovde, Sweden.
Helmut Schmid and Florian Laws. 2008. Estimation
of Conditional Probabilities with Decision Trees and
an Application to Fine-Grained POS Tagging. In
COLING 2008, Manchester, UK.
Helmut Schmid. 1994. Probabilistic Part-of-Speech
Tagging Using Decision Trees. In International
Conference on New Methods in Language Process-
ing, Manchester, UK.
Helmut Schmid. 2004. Efficient Parsing of Highly
Ambiguous Context-Free Grammars with Bit Vec-
tors. In Proc. of the Int. Conf. on Computational
Linguistics (COLING), Geneva, Switzerland, Au-
gust.
Rico Sennrich, Martin Volk, and Gerold Schneider.
2013. Exploiting Synergies Between Open Re-
sources for German Dependency Parsing, POS-
tagging, and Morphological Analysis. In Proceed-
ings of the International Conference Recent Ad-
vances in Natural Language Processing 2013, pages
601?609, Hissar, Bulgaria.
Andreas Stolcke. 2002. SRILM ? An Extensible Lan-
guage Modeling Toolkit. In Proc. of the Int. Conf.
on Speech and Language Processing (ICSLP), vol-
ume 2, pages 901?904, Denver, CO, USA, Septem-
ber.
Ashish Venugopal, Andreas Zollman, and Alex Waibel.
2005. Training and Evaluation Error Minimization
Rules for Statistical Machine Translation. In Work-
shop on Data-drive Machine Translation and Be-
yond (WPT-05), Ann Arbor, Michigan, USA.
David Vilar, Daniel Stein, Matthias Huck, and Her-
mann Ney. 2010. Jane: Open Source Hierarchi-
cal Translation, Extended with Reordering and Lex-
icon Models. In ACL 2010 Joint Fifth Workshop on
Statistical Machine Translation and Metrics MATR,
pages 262?270, Uppsala, Sweden, July.
Stephan Vogel. 2003. SMT Decoder Dissected: Word
Reordering. In International Conference on Natural
Language Processing and Knowledge Engineering,
Beijing, China.
Philip Williams and Philipp Koehn. 2012. GHKM
Rule Extraction and Scope-3 Parsing in Moses. In
Proceedings of the Seventh Workshop on Statisti-
cal Machine Translation (WMT), pages 388?394,
Montr?eal, Canada, June.
Philip Williams, Rico Sennrich, Maria Nadejde,
Matthias Huck, Eva Hasler, and Philipp Koehn.
2014. Edinburgh?s Syntax-Based Systems at
WMT 2014. In Proceedings of the ACL 2014 Ninth
Workshop on Statistical Machine Translation, Balti-
more, MD, USA, June.
Joern Wuebker, Matthias Huck, Stephan Peitz, Malte
Nuhn, Markus Freitag, Jan-Thorsten Peter, Saab
Mansour, and Hermann Ney. 2012. Jane 2:
Open Source Phrase-based and Hierarchical Statisti-
cal Machine Translation. In COLING ?12: The 24th
Int. Conf. on Computational Linguistics, pages 483?
491, Mumbai, India, December.
Joern Wuebker, Stephan Peitz, Felix Rietig, and Her-
mann Ney. 2013. Improving Statistical Machine
Translation with Word Class Models. In Conference
on Empirical Methods in Natural Language Pro-
cessing, pages 1377?1381, Seattle, WA, USA, Oc-
tober.
113
Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 157?162,
Baltimore, Maryland USA, June 26?27, 2014.
c?2014 Association for Computational Linguistics
The RWTH Aachen German-English Machine Translation System for
WMT 2014
Stephan Peitz, Joern Wuebker, Markus Freitag and Hermann Ney
Human Language Technology and Pattern Recognition Group
Computer Science Department
RWTH Aachen University
D-52056 Aachen, Germany
<surname>@cs.rwth-aachen.de
Abstract
This paper describes the statistical ma-
chine translation (SMT) systems devel-
oped at RWTH Aachen University for the
German?English translation task of the
ACL 2014 Eighth Workshop on Statisti-
cal Machine Translation (WMT 2014).
Both hierarchical and phrase-based SMT
systems are applied employing hierarchi-
cal phrase reordering and word class lan-
guage models. For the phrase-based sys-
tem, we run discriminative phrase training.
In addition, we describe our preprocessing
pipeline for German?English.
1 Introduction
For the WMT 2014 shared translation task
1
RWTH utilized state-of-the-art phrase-based and
hierarchical translation systems. First, we describe
our preprocessing pipeline for the language pair
German?English in Section 2. Furthermore, we
utilize morpho-syntactic analysis to preprocess the
data (Section 2.3). In Section 3, we give a survey
of the employed systems and the basic methods
they implement. More details are given about the
discriminative phrase training (Section 3.4) and
the hierarchical reordering model for hierarchical
machine translation (Section 3.5). Experimental
results are discussed in Section 4.
2 Preprocessing
In this section we will describe the modification of
our preprocessing pipeline compared to our 2013
WMT German?English setup.
2.1 Categorization
We put some effort in building better categories for
digits and written numbers. All written numbers
1
http://www.statmt.org/wmt14/
translation-task.html
were categorized. In 2013 they were just handled
as normal words which leads to a higher number of
out-of-vocabulary words. For German?English,
in most cases for numbers like ?3,000? or ?2.34?
the decimal mark ?,? and the thousands separator
?.? has to be inverted. As the training data and also
the test sets contain several errors for numbers in
the source as well as in the target part, we put more
effort into producing correct English numbers.
2.2 Remove Foreign Languages
The WMT German?English corpus contains
some bilingual sentence pairs with non-German
source or/and non-English target sentences. For
this WMT translation task, we filtered all non-
matching language pairs (in terms of source lan-
guage German and target language English) from
our bilingual training set.
First, we filtered languages which contain non-
ascii characters. For example Chinese, Arabic or
Russian can be easily filtered when deleting sen-
tences which contain more than 70 percent non-
ascii words. The first examples of Table 1 was
filtered due to the fact, that the source sentence
contains too many non-ascii characters.
In a second step, we filtered European lan-
guages containing ascii characters. We used the
WMT monolingual corpora in Czech, French,
Spanish, English and German to filter these lan-
guages from our bilingual data. We could both
delete a sentence pair if it contains a wrong source
language or a wrong target language. That is the
reason why we even search for English sentences
in the source part and for German sentences in
the target part. For each language, we built a
word count of all words in the monolingual data
for each language separately. We removed punc-
tuation which are no indicator of a language. In
our experiments, we only considered words with
frequency higher than 20 (e.g. to ignore names).
Given the word frequency, we removed a bilingual
157
Table 1: Examples of sentences removed in preprocessing.
Example
remove non-ascii symbols ????????? .
zum Bericht A?noveros Tr??as de Bes
remove wrong languages from target Honni soit qui mal y pense !
as you yourself have said : travailler plus pour gagner plus
remove wrong languages from source je d?eclare interrompue la session du Parlement europ?een .
Quelle der Tabelle : ? what Does the European Union do ? ?
sentence pair from our training data if more than
70 percent of the words had a higher count in a
different language then the one we expected. In
Table 1 some example sentences, which were re-
moved, are illustrated.
In Table 2 the amount of sentences and the cor-
responding vocabulary sizes of partial and totally
cleaned data sets are given. Further we provide the
number of out-of-vocabulary words (OOVs) for
newstest2012. The vocabulary size could be re-
duced by ?130k words for both source and target
side of our bilingual training data while the OOV
rate kept the same. Our experiments showed, that
the translation quality is the same with or with-
out removing wrong sentences. Nevertheless, we
reduced the training data size and also the vocabu-
lary size without any degradation in terms of trans-
lation quality.
2.3 Morpho-syntactic Analysis
In order to reduce the source vocabulary size for
the German?English translation further, the Ger-
man text is preprocessed by splitting German com-
pound words with the frequency-based method de-
scribed in (Koehn and Knight, 2003). To reduce
translation complexity, we employ the long-range
part-of-speech based reordering rules proposed by
Popovi?c and Ney (2006).
3 Translation Systems
In this evaluation, we employ phrase-based trans-
lation and hierarchical phrase-based translation.
Both approaches are implemented in Jane (Vilar et
al., 2012; Wuebker et al., 2012), a statistical ma-
chine translation toolkit which has been developed
at RWTH Aachen University and is freely avail-
able for non-commercial use.
2
In the newest inter-
nal version, we use the KenLM Language Model
Interface provided by (Heafield, 2011) for both de-
coders.
2
http://www.hltpr.rwth-aachen.de/jane/
3.1 Phrase-based System
In the phrase-based decoder (source cardinality
synchronous search, SCSS, Wuebker et al. (2012)),
we use the standard set of models with phrase
translation probabilities and lexical smoothing in
both directions, word and phrase penalty, distance-
based distortion model, an n-gram target language
model and three binary count features. Additional
models used in this evaluation are the hierarchical
reordering model (HRM) (Galley and Manning,
2008) and a word class language model (wcLM)
(Wuebker et al., 2013). The parameter weights
are optimized with minimum error rate training
(MERT) (Och, 2003). The optimization criterion
is BLEU (Papineni et al., 2002).
3.2 Hierarchical Phrase-based System
In hierarchical phrase-based translation (Chiang,
2007), a weighted synchronous context-free gram-
mar is induced from parallel text. In addition to
contiguous lexical phrases, hierarchical phrases
with up to two gaps are extracted. The search is
carried out with a parsing-based procedure. The
standard models integrated into our Jane hierar-
chical systems (Vilar et al., 2010; Huck et al.,
2012) are: Phrase translation probabilities and lex-
ical smoothing probabilities in both translation di-
rections, word and phrase penalty, binary features
marking hierarchical phrases, glue rule, and rules
with non-terminals at the boundaries, three binary
count features, and an n-gram language model.
We utilize the cube pruning algorithm for decod-
ing (Huck et al., 2013a) and optimize the model
weights with MERT. The optimization criterion is
BLEU.
3.3 Other Tools and Techniques
We employ GIZA
++
(Och and Ney, 2003) to train
word alignments. The two trained alignments
are heuristically merged to obtain a symmetrized
word alignment for phrase extraction. All lan-
158
Table 2: Corpus statistics after each filtering step and compound splitting.
Vocabulary OOVs
Sentences German English newstest2012
Preprocessing 2013 4.19M 1.43M 784K 1019
Preprocessing 2014 4.19M 1.42M 773K 1018
+ remove non-ascii symbols 4.17M 1.36M 713K 1021
+ remove wrong languages from target 4.15M 1.34M 675K 1027
+ remove wrong languages from source 4.08M 1.30M 655K 1039
+ compound splitting 4.08M 652K 655K 441
guage models (LMs) are created with the SRILM
toolkit (Stolcke, 2002) or with the KenLM lan-
guage model toolkit (Heafield et al., 2013) and are
standard 4-gram LMs with interpolated modified
Kneser-Ney smoothing (Kneser and Ney, 1995;
Chen and Goodman, 1998). We evaluate in true-
case with BLEU and TER (Snover et al., 2006).
3.4 Discriminative Phrase Training
In our baseline translation systems the phrase ta-
bles are created by a heuristic extraction from
word alignments and the probabilities are esti-
mated as relative frequencies, which is still the
state-of-the-art for many standard SMT systems.
Here, we applied a more sophisticated discrimi-
native phrase training method for the WMT 2014
German?English task. Similar to (He and Deng,
2012), a gradient-based method is used to opti-
mize a maximum expected BLEU objective, for
which we define BLEU on the sentence level with
smoothed 3-gram and 4-gram precisions. To that
end, the training data is decoded to generate 100-
best lists. We apply a leave-one-out heuristic
(Wuebker et al., 2010) to make better use of the
training data. Using these n-best lists, we itera-
tively perform updates on the phrasal translation
scores of the phrase table. After each iteration,
we run MERT, evaluate on the development set
and select the best performing iteration. In this
work, we perform two rounds of discriminative
training on two separate data sets. In the first
round, training is performed on the concatenation
of newstest2008 through newstest2010 and an au-
tomatic selection from the News-commentary, Eu-
roparl and Common Crawl corpora. The selec-
tion is based on cross-entropy difference of lan-
guage models and IBM-1 models as described by
Mansour et al. (2011) and contains 258K sentence
pairs. The training took 4.5 hours for 30 iterations.
On top of the final phrase-based systems, a second
round of discriminative training is run on the full
news-commentary corpus concatenated with new-
stest2008 through newstest2010.
3.5 A Phrase Orientation Model for
Hierarchical Machine Translation
In Huck et al. (2013b) a lexicalized reorder-
ing model for hierarchical phrase-based machine
translation was introduced. The model scores
monotone, swap, and discontinuous phrase ori-
entations in the manner of the one presented by
(Tillmann, 2004). Since improvements were re-
ported on a Chinese?English translation task, we
investigate the impact of this model on a European
language pair. As in German the word order is
more flexible compared with the target language
English, we expect that an additional reordering
model could improve the translation quality. In
our experiments we use the same settings which
worked best in (Huck et al., 2013b).
4 Setup
We trained the phrase-based and the hierarchical
translation system on all available bilingual train-
ing data. Corpus statistics can be found in the
last row of Table 2. The language model are
4-grams trained on the respective target side of
the bilingual data,
1
2
of the Shuffled News Crawl
corpus,
1
4
of the 10
9
French-English corpus and
1
2
of the LDC Gigaword Fifth Edition corpus.
The monolingual data selection is based on cross-
entropy difference as described in (Moore and
Lewis, 2010). For the baseline language model,
we trained separate models for each corpus, which
were then interpolated. For our final experiments,
we also trained a single unpruned language model
on the concatenation of all monolingual data with
KenLM.
159
Table 3: Results (truecase) for the German?English translation task. BLEU and TER are given in
percentage. All HPBT setups are tuned on the concatenation of newstest2012 and newstest2013. The
very first SCSS setups are optimized on newstest2012 only.
newstest2011 newstest2012 newstest2013
BLEU TER BLEU TER BLEU TER
SCSS +HRM 22.4 60.1 23.7 59.0 25.9 55.7
+wcLM 22.8 59.6 24.0 58.6 26.3 55.4
+1st round discr. 23.0 59.5 24.2 58.2 26.8 55.1
+tune11+12. 23.4 59.5 24.2 58.6 26.8 55.2
+unprunedLM 23.6 59.5 24.2 58.6 27.1 55.0
+2nd round discr. 23.7 59.5 24.4 58.5 27.2 55.0
HPBT baseline 23.3 59.9 24.2 58.9 26.7 55.6
+wcLM 23.4 59.8 24.1 58.9 26.8 55.6
+HRM 23.3 60.0 24.2 58.9 26.9 55.5
+HRM +wcLM 23.3 59.9 24.1 59.1 26.7 55.9
4.1 Experimental Results
The results of the phrase-based system (SCSS)
as well as the hierarchical phrase-based system
(HPBT) are summarized in Table 3.
The phrase-based baseline system, which in-
cludes the hierarchical reordering model by (Gal-
ley and Manning, 2008) and is tuned on new-
stest2012, reaches a performance of 25.9% BLEU
on newstest2013. Adding the word class language
model improves performance by 0.4% BLEU ab-
solute and the first round of discriminative phrase
training by 0.5% BLEU absolute. Next, we
switched to tuning on a concatenation of new-
stest2011 and newstest2012, which we expect to
be more reliable with respect to unseen data. Al-
though the BLEU score does not improve and TER
goes up slightly, we kept this tuning set in the sub-
sequent setups, as it yielded longer translations,
which in our experience will usually be preferred
by human evaluators. Switching from the inter-
polated language model to the unpruned language
model trained with KenLM on the full concate-
nated monolingual training data in a single pass
gained us another 0.3% BLEU. For the final sys-
tem, we ran a second round of discriminative train-
ing on different training data (cf. Section 3.4),
which increased performance by 0.1% BLEU to
the final score 27.2.
For the phrase-based system, we also exper-
imented with weighted phrase extraction (Man-
sour and Ney, 2012), but did not observe improve-
ments.
The hierarchical phrase-based baseline without
any additional model is on the same level as the
phrase-based system including the word class lan-
guage model, hierarchical reordering model and
discriminative phrase training in terms of BLEU.
However, extending the system with a word class
language model or the additional reordering mod-
els does not seem to help. Even the combination
of both models does not improve the translation
quality. Note, that the hierarchical system was
tuned on the concatenation newstest2011 and new-
stest2012. The final system employs both word
class language model and hierarchical reordering
model.
Both phrase-based and hierarchical phrase-
based final systems are used in the EU-Bridge sys-
tem combination (Freitag et al., 2014).
5 Conclusion
For the participation in the WMT 2014 shared
translation task, RWTH experimented with both
phrase-based and hierarchical translation systems.
For both approaches, we applied a hierarchical
phrase reordering model and a word class lan-
guage model. For the phrase-based system we em-
ployed discriminative phrase training. Addition-
ally, improvements of our preprocessing pipeline
compared to our WMT 2013 setup were described.
New introduced categories lead to a lower amount
of out-of-vocabulary words. Filtering the corpus
for wrong languages gives us lower vocabulary
sizes for source and target without loosing any per-
formance.
160
Acknowledgments
The research leading to these results has partially
received funding from the European Union Sev-
enth Framework Programme (FP7/2007-2013) un-
der grant agreement n
o
287658.
Furthermore, this material is partially based
upon work supported by the DARPA BOLT
project under Contract No. HR0011- 12-C-0015.
Any opinions, findings and conclusions or recom-
mendations expressed in this material are those of
the authors and do not necessarily reflect the views
of DARPA.
References
Stanley F. Chen and Joshua Goodman. 1998. An
Empirical Study of Smoothing Techniques for Lan-
guage Modeling. Technical Report TR-10-98, Com-
puter Science Group, Harvard University, Cam-
bridge, Massachusetts, USA, August.
David Chiang. 2007. Hierarchical Phrase-Based
Translation. Computational Linguistics, 33(2):201?
228.
Markus Freitag, Stephan Peitz, Joern Wuebker, Her-
mann Ney, Matthias Huck, Rico Sennrich, Nadir
Durrani, Maria Nadejde, Philip Williams, Philipp
Koehn, Teresa Herrmann, Eunah Cho, and Alex
Waibel. 2014. EU-BRIDGE MT: Combined Ma-
chine Translation. In Proceedings of the ACL 2014
Ninth Workshop on Statistical Machine Translation,
Baltimore, MD, USA, June.
Michel Galley and Christopher D. Manning. 2008. A
Simple and Effective Hierarchical Phrase Reorder-
ing Model. In Proceedings of the 2008 Conference
on Empirical Methods in Natural Language Pro-
cessing, pages 847?855, Honolulu, Hawaii, USA,
October.
Xiaodong He and Li Deng. 2012. Maximum Expected
BLEU Training of Phrase and Lexicon Translation
Models. In Proceedings of the 50th Annual Meet-
ing of the Association for Computational Linguistics
(ACL), pages 292?301, Jeju, Republic of Korea, Jul.
Kenneth Heafield, Ivan Pouzyrevsky, Jonathan H.
Clark, and Philipp Koehn. 2013. Scalable modi-
fied Kneser-Ney language model estimation. In Pro-
ceedings of the 51st Annual Meeting of the Associa-
tion for Computational Linguistics, pages 690?696,
Sofia, Bulgaria, August.
Kenneth Heafield. 2011. KenLM: faster and smaller
language model queries. In Proceedings of the
EMNLP 2011 Sixth Workshop on Statistical Ma-
chine Translation, pages 187?197, Edinburgh, Scot-
land, United Kingdom, July.
Matthias Huck, Jan-Thorsten Peter, Markus Freitag,
Stephan Peitz, and Hermann Ney. 2012. Hierar-
chical Phrase-Based Translation with Jane 2. The
Prague Bulletin of Mathematical Linguistics, 98:37?
50, October.
Matthias Huck, David Vilar, Markus Freitag, and Her-
mann Ney. 2013a. A Performance Study of
Cube Pruning for Large-Scale Hierarchical Machine
Translation. In Proceedings of the NAACL 7thWork-
shop on Syntax, Semantics and Structure in Statis-
tical Translation, pages 29?38, Atlanta, Georgia,
USA, June.
Matthias Huck, Joern Wuebker, Felix Rietig, and Her-
mann Ney. 2013b. A phrase orientation model
for hierarchical machine translation. In ACL 2013
Eighth Workshop on Statistical Machine Transla-
tion, pages 452?463, Sofia, Bulgaria, August.
Reinhard Kneser and Hermann Ney. 1995. Im-
proved Backing-Off for M-gram Language Model-
ing. In Proceedings of the International Conference
on Acoustics, Speech, and Signal Processing, vol-
ume 1, pages 181?184, May.
Philipp Koehn and Kevin Knight. 2003. Empirical
Methods for Compound Splitting. In Proceedings of
European Chapter of the ACL (EACL 2009), pages
187?194.
Saab Mansour and Hermann Ney. 2012. A Simple and
Effective Weighted Phrase Extraction for Machine
Translation Adaptation. In Proceedings of the Inter-
national Workshop on Spoken Language Translation
(IWSLT), pages 193?200, Hong Kong, December.
Saab Mansour, Joern Wuebker, and Hermann Ney.
2011. Combining Translation and Language Model
Scoring for Domain-Specific Data Filtering. In Pro-
ceedings of the International Workshop on Spoken
Language Translation (IWSLT), pages 222?229, San
Francisco, California, USA, December.
Robert C. Moore and William Lewis. 2010. Intelligent
Selection of Language Model Training Data. In ACL
(Short Papers), pages 220?224, Uppsala, Sweden,
July.
Franz Josef Och and Hermann Ney. 2003. A System-
atic Comparison of Various Statistical Alignment
Models. Computational Linguistics, 29(1):19?51,
March.
Franz Josef Och. 2003. Minimum Error Rate Training
in Statistical Machine Translation. In Proc. of the
41th Annual Meeting of the Association for Compu-
tational Linguistics (ACL), pages 160?167, Sapporo,
Japan, July.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a Method for Automatic
Evaluation of Machine Translation. In Proceed-
ings of the 41st Annual Meeting of the Associa-
tion for Computational Linguistics, pages 311?318,
Philadelphia, Pennsylvania, USA, July.
161
Maja Popovi?c and Hermann Ney. 2006. POS-based
Word Reorderings for Statistical Machine Transla-
tion. In International Conference on Language Re-
sources and Evaluation, pages 1278?1283, Genoa,
Italy, May.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciulla, and John Makhoul. 2006. A Study of
Translation Edit Rate with Targeted Human Annota-
tion. In Proceedings of the 7th Conference of the As-
sociation for Machine Translation in the Americas,
pages 223?231, Cambridge, Massachusetts, USA,
August.
Andreas Stolcke. 2002. SRILM ? An Extensible Lan-
guage Modeling Toolkit. In Proc. of the Int. Conf.
on Speech and Language Processing (ICSLP), vol-
ume 2, pages 901?904, Denver, Colorado, USA,
September.
Christoph Tillmann. 2004. A Unigram Orientation
Model for Statistical Machine Translation. In Pro-
ceedings of HLT-NAACL 2004: Short Papers, HLT-
NAACL-Short ?04, pages 101?104, Boston, MA,
USA.
David Vilar, Daniel Stein, Matthias Huck, and Her-
mann Ney. 2010. Jane: Open Source Hierarchi-
cal Translation, Extended with Reordering and Lex-
icon Models. In ACL 2010 Joint Fifth Workshop on
Statistical Machine Translation and Metrics MATR,
pages 262?270, Uppsala, Sweden, July.
David Vilar, Daniel Stein, Matthias Huck, and Her-
mann Ney. 2012. Jane: an advanced freely avail-
able hierarchical machine translation toolkit. Ma-
chine Translation, 26(3):197?216, September.
Joern Wuebker, Arne Mauser, and Hermann Ney.
2010. Training phrase translation models with
leaving-one-out. In Proceedings of the 48th Annual
Meeting of the Assoc. for Computational Linguistics,
pages 475?484, Uppsala, Sweden, July.
Joern Wuebker, Matthias Huck, Stephan Peitz, Malte
Nuhn, Markus Freitag, Jan-Thorsten Peter, Saab
Mansour, and Hermann Ney. 2012. Jane 2:
Open Source Phrase-based and Hierarchical Statis-
tical Machine Translation. In International Confer-
ence on Computational Linguistics, pages 483?491,
Mumbai, India, December.
Joern Wuebker, Stephan Peitz, Felix Rietig, and Her-
mann Ney. 2013. Improving statistical machine
translation with word class models. In Conference
on Empirical Methods in Natural Language Pro-
cessing, pages 1377?1381, Seattle, USA, October.
162
