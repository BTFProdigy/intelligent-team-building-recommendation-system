Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 185?192,
The University of Tokyo, September 24-25, 2010. c?2010 Association for Computational Linguistics
Enhanced Monitoring Tools and Online Dialogue Optimisation Merged
into a New Spoken Dialogue System Design Experience
Ghislain Putois
Orange Labs
Lannion, France
Romain Laroche
Orange Labs
Issy-les-Moulineaux, France
firstname.surname@orange-ftgroup.com
Philippe Bretier
Orange Labs
Lannion, France
Abstract
Building an industrial spoken dialogue
system (SDS) requires several iterations
of design, deployment, test, and evalua-
tion phases. Most industrial SDS develop-
ers use a graphical tool to design dialogue
strategies. They are critical to get good
system performances, but their evaluation
is not part of the design phase.
We propose integrating dialogue logs into
the design tool so that developers can
jointly monitor call flows and their asso-
ciated Key Performance Indicators (KPI).
It drastically shortens the complete devel-
opment cycle, and offers a new design ex-
perience.
Orange Dialogue Design Studio (ODDS),
our design tool, allows developers to de-
sign several alternatives and compare their
relative performances. It helps the SDS
developers to understand and analyse the
user behaviour, with the assistance of a re-
inforcement learning algorithm. The SDS
developers can thus confront the different
KPI and control the further SDS choices
by updating the call flow alternatives.
Index Terms : Dialogue Design, Online Learning,
Spoken Dialogue Systems, Monitoring Tools
1 Introduction
Recent research in spoken dialogue systems
(SDS) has called for a ?synergistic convergence?
between research and industry (Pieraccini and
Huerta, 2005). This call for convergence concerns
architectures, abstractions and methods from both
communities. Under this motivation, several re-
search orientations have been proposed. This pa-
per discusses three of them : dialogue design, di-
alogue management, and dialogue evaluation. Di-
alogue design and dialogue management reflect in
this paper the respective paths that industry and
research have followed for building their SDS. Di-
alogue evaluation is a concern for both communi-
ties, but remains hard to put into operational per-
spectives.
The second Section presents the context and
related research. The third Section is devoted to
the presentation of the tools : the historical design
tool, its adaptation to provide monitoring function-
alities and the insertion of design alternatives. It is
eventually concluded with an attempt to reassess-
ing the dialogue evaluation. The fourth Section de-
scribes the learning integration to the tool, the con-
straints we impose to the learning technique and
the synergy between the tools and the embedded
learning capabilities. Finally, the last Section con-
cludes the paper.
2 Context
The spoken dialogue industry is structured
around the architecture of the well known in-
dustrial standard VoiceXML 1. The underlying di-
alogue model of VoiceXML is a mapping of
the simplistic turn-based linguistic model on the
browser-server based Web architecture (McTear,
2004). The browser controls the speech engines
(recognition and text-to-speech) integrated into
the voice platform according to the VoiceXML
document served by an application server. A
VoiceXML document contains a set of prompts to
play and the list of the possible interactions the
user is supposed to have at each point of the di-
alogue. The SDS developers 2, reusing Web stan-
dards and technologies (e.g. J2EE, JSP, XML. . .),
are used to designing directed dialogues modelled
by finite state automata. Such controlled and de-
terministic development process allows the spoken
1. http ://www.w3c.org/TR/voicexml20/
2. In this paper, the term ?SDS developers? denotes with-
out any distinction VUI designers, application developers,
and any industry engineers acting in SDS building.
185
dialogue industry to reach a balance between us-
ability and cost (Paek, 2007). This paper argues
that tools are facilitators that improve both the us-
ability vs. cost trade-off and the reliability of new
technologies.
Spoken dialogue research has developed vari-
ous models and abstractions for dialogue manage-
ment : rational agency (Sadek et al, 1997), Infor-
mation State Update (Bos et al, 2003), functional
models (Pieraccini et al, 2001), planning problem
solving (Ferguson and Allen, 1998). Only a very
small number of these concepts have been trans-
ferred to industry. Since the late 90?s, the research
has tackled the ambitious problem of automating
the dialogue design (Lemon and Pietquin, 2007),
aiming at both reducing the development cost
and optimising the dialogue efficiency and robust-
ness. Recently, criticisms (Paek and Pieraccini,
2008) have been formulated and novel approaches
(Williams, 2008) have been proposed, both aiming
at bridging the gap between research ?focused on
Markov-Decision-Process (Bellman, 1957) based
dialogue management? and industry ?focused on
dialogue design process, model, and tools. This
paper contributes to extend this effort. It addresses
all these convergence questions together as a way
for research and industry to reach a technological
breakthrough.
Regarding the dialogue evaluation topic, Paek
(Paek, 2007) has pointed out that while research
has exerted attention about ?how best to evaluate
a dialogue system ??, the industry has focused on
?how best to design dialogue systems ??. This pa-
per unifies those two approaches by merging sys-
tem and design evaluation in a single graphical
tool. To our knowledge, ODDS is the only indus-
trial tool which handles the complete system life-
cycle, from design to evaluation.
The tools and methods presented below have
been tested and validated during the design and
implementation of a large real-world commercial
system : the 1013+ service is the Spoken Dialogue
System for landline troubleshooting for France.
It receives millions of calls a year and schedules
around 8, 000 appointments a week. When the
user calls the system, she is presented with an open
question asking her for the reason of her call. If
her landline is out of service, the Spoken Dialogue
System then performs some automated tests on
the line, and if the problem is confirmed, try and
schedule an appointment with the user for a man-
ual intervention. If the system and the user cannot
agree on an appointment slot, the call is transferred
to a human operator.
3 The tools
Industry follows the VUI-completeness princi-
ple (Pieraccini and Huerta, 2005) : ?the behaviour
of an application needs to be completely speci-
fied with respect to every possible situation that
may arise during the interaction. No unpredictable
user input should ever lead to unforeseeable be-
haviour?. The SDS developers consider reliable
the technologies, tools, and methodologies that
help them to reach the VUI-completeness and to
control it.
3.1 The Dialogue Design Tool
The graphical abstraction proposed by our dia-
logue design tool conforms to the general graph
representation of finite state automata, with the
difference that global and local variables enable to
factorise several dialogue states in a single node.
Transitions relate to user inputs or to internal ap-
plication events such as conditions based on in-
ternal information from the current dialogue state,
from the back-end, or from the dialogue history. In
that sense, dialogue design in the industry gener-
ally covers more than strict dialogue management,
since its specification may indicate the type of spo-
ken utterance expected from the user at each stage
of the dialogue, up to the precise speech recogni-
tion model and parameter values to use, and the
generation of the system utterance, from natural
language generation to speech synthesis or audio
recordings.
Our dialogue design tool offers to the SDS de-
velopers a graphical abstraction of the dialogue
logic, sometimes also named the call flow. Thanks
to a dynamic VoiceXML generation functional-
ity, our dialogue design tool brings the SDS de-
velopers the guarantee that VUI-completeness at
the design level automatically implies a similar
completeness at the implementation level. During
maintenance, If the SDS developers modify a spe-
cific part of the dialogue design, the tool guar-
antees that solely the corresponding code is im-
pacted. This guarantee impacts positively VUI-
completeness, reliability, and development cost.
Figure 1 presents the design of a typical
VoiceXML page. This page is used when the sys-
tem asks the user to accept an appointment time
186
FIGURE 1 ? 1013+ design excerpt : the system asks the user to confirm an appointment slot
slot. It first begins with a prompt box mixing
static and dynamic prompts (the dynamic parts are
underlined and realised by service-specific java
code). A log box is then used some contextual ses-
sion variables. Then, an interaction box is used to
model the system reaction to the user behaviour :
on the lower part of the Figure, we program the
reaction to user inactivity or recognizer misunder-
standing. In the upper part, we use a recognition
box followed by a Natural Language Understand-
ing (NLU), and we program the different output
classes : repeat, yes, no and not understood. Each
output is linked to a transition box, which indi-
cates which VoiceXML page the service should
call next.
3.2 Monitoring Functionalities inside the
Design Tool
While researchers are focused on measuring the
progress they incrementally reach, industry engi-
neers have to deal with SDS tuning and upgrade.
Their first dialogue evaluation KPI is task com-
pletion also called the automation rate because a
SDS is deployed to automate specifically selected
tasks. Most of the time, task completion is esti-
mated thanks to the KPI. The KPI are difficult to
exhaustively list and classify. Some are related to
system measures, others are obtained thanks to di-
alogue annotations and the last ones are collected
from users through questionnaires.
Some studies (Abella et al, 2004) investigated
graphical monitoring tools. The corpus to visualise
is a set of dialogue logs. The tool aims at reveal-
ing how the system transits between its possible
states. As a dialogue system is too complex to enu-
merate all its possible states, the dialogue logs are
regarded as a set of variables that evolve during
time and the tool proposes to make a projection on
a subset of these variables. This way, the generated
graphs can either display the call flow, how the dif-
ferent steps are reached and where they lead, or
display how different variables, as the number of
errors evolve. This is mainly a tool for understand-
ing how the users behave, because it has no direct
connection with the way how the system was built.
As consequence to this, it does not help to diag-
nose how to make it better. In other words, it does
evaluate the system but does not meet one of our
goal : the convergence between design and evalu-
ation.
On the opposite, our graphical design tool pro-
vides an innovative functionality : local KPI pro-
jection into the original dialogue design thanks to
an extensive logging. A large part of the KPI are
automatically computed and displayed. As a con-
sequence, it is possible to display percentage of
which responses the system recognised, the users
actually gave, and see how these numbers match
the various KPI. It is one example among the nu-
merous analysis views this graphical tool can pro-
vide.
3.3 Insertion of Alternatives
The 1013+ service has been used to test three
kinds of design alternatives. The first kind is a
strategy alternative : the service can choose be-
tween offering an appointment time slot to the
client, or asking her for a time slot. This deci-
sion defines whether the next dialogue step will
be system-initiative or user-initiative. The second
kind is a speaking style alternative : the service
can either be personified by using the ?I? pronoun,
adopt a corporate style by using the ?We? pro-
noun, or speak in an impersonal style by using the
passive mode. The third kind is a Text-To-Speech
alternative : the service can use a different wording
or prosody for a given sentence.
Figure 2 displays a monitoring view of an in-
teraction implementation with alternatives. The
recognition rate is the projected KPI on the graph
at each branch. Other performance indicators are
displayed at the bottom of the window : here, it
187
FIGURE 2 ? Some user experience feedbacks related to a selected prompt alternative.
is the actual rate of correct semantic decoding, the
semantic substitution rate, and the semantic rejec-
tion rate. The selection of the highlighted box con-
ditions the displayed logs.
Our design tool also provides a multivariate
testing functionality. This method consists in test-
ing multiple alternatives and selecting the best one
on a fixed set of predetermined criteria. Regarding
the VUI-completeness, presenting the complete
automaton to the SDS developers is acceptable, as
long as they can inspect and control every branch
of the design. In general, they even come up with
several competing designs or points of choice,
which can only be properly selected from in a sta-
tistical manner. The ability to compare all the di-
alogue design alternatives in the same test-field is
a major factor to boost up SDS enhancement by
drastically reducing the time needed. When we
were developing the current 1013+ version, we
have been able to develop the 5 main alternatives
in less than a month, where it had taken a month
and a half for a unique alternative in previous ver-
sions. It brings a statistical relevance in the causal
link between the tested alternatives and the differ-
ences in performance measures, because it ensures
a good random input space coverage.
The KPI graphical projection into the dialogue
design covers the dialogue alternatives : KPI com-
putation just needs to be conditioned by the alter-
natives. Figure 2 illustrates the merge of several
system prompt alternatives inside a single design.
It represents the prompt alternatives the system
can choose when proposing an appointment time
slot. An action block informs the Learning Man-
ager about the current dialogue state and avail-
able dialogue alternatives. An ?If? block then ac-
tivates the prompt alternative corresponding to a
local variable ?choixPDC? filled by the Learning
Manager. The rest of the design is identical to the
design presented in Figure 1.
The displayed KPI are conditioned by the se-
lected alternative (here, the second wording cir-
cled in bold grey). ODDS then indicates how the
dialogue call flow is breakdown into the different
alternatives. As we have here conditioned the dis-
played information by the second alternative, this
alternative receives 100% of the calls displayed,
when the other alternatives are not used. We can
then see the different outcomes for the selected
alternative : the customer answer have lead to a
timeout of the recognition in 11.78% of the cases,
and amongst the recognised sentences, 80% were
an agreement, 13.33% were a reject, and 6.67%
were not understood.
On the bottom-left part, one can display more
specific KPI, such as good interpretation rate, sub-
stitution rate, and reject rate. These KPI are com-
puted after the collected logs have been manually
annotated, which remains an indispensable pro-
cess to monitor and improve the recognition and
NLU quality, and thus the overall service quality.
Conditioning on another alternative would have
immediately led to different results, and someway,
embedding the user experience feedback inside the
dialogue design forms a new material to touch and
feel : the SDS developers can now sculpt a unique
reactive material which contains the design and the
KPI measures distribution. By looking at the influ-
ence of each alternative on the KPI when graphi-
cally selecting the alternatives, the SDS develop-
ers are given a reliable means to understand how
to improve the system.
188
3.4 Reassessing Dialogue Evaluation
The traditional approaches to dialogue evalu-
ation attempt to measure how best the SDS is
adapted to the users. We remind that each inter-
action between the user and the SDS appears to
be a unique performance. First, each new dialogue
is co-built in a unique way according to both the
person-specific abilities of the user and the possi-
bilities of the SDS. Second, the user adapts very
quickly to new situations and accordingly changes
her practices. The traditional approaches to dia-
logue evaluation are eventually based on the frag-
ile reference frame of the user, not reliable enough
for a scientific and an industrial approach of the
spoken dialogue field, mostly because of the in-
ability to get statistical call volumes for all the di-
alogue alternatives.
This suggests for a shift in the reference frame
used for dialogue evaluation : instead of trying to
measure the adequacy between the SDS and the
user in the user?s reference frame, one can measure
the adequacy between the user and the SDS in the
design reference frame composed by the dialogue
logic, the KPI and their expected values. Taking
the design as the reference allows reassessing the
dialogue evaluation. The proposed basis for dia-
logue evaluation is reliable for the SDS developers
because it is both stable and entirely under con-
trol. Deviations from the predicted situations are
directly translated into anomalous values of mea-
surable KPI that raise alerts. These automatically
computable alerts warn the SDS developers about
the presence of issues in their dialogue design.
4 Dialogue design learning
As presented in previous Section, the alterna-
tive insertion is an enabler for the dialogue system
analysis tools. It provides the SDS developers with
a novel call flow visualisation experience. The fur-
ther step to this approach is to automate at least
a part of those analyses and improvements with
learning capabilities.
4.1 Constraints
The objective is to automatically choose online
the best alternative among those proposed in the
design tool, and to report this choice to the SDS
developers via the monitoring functionalities that
are integrated to the design tool. This approach
differs from the classical reinforcement learning
methods used in the dialogue literature, which
make their decisions at the dialogue turn level.
We use a technique from a previous work
(Laroche et al, 2009). It does not need to de-
clare the reachable states : they are automatically
created when reached. This is also a parameter-
free algorithm, which is very important when we
consider that most dialogue application developers
are not familiar with reinforcement learning the-
ory. We keep the developer focussed on its main
task. The two additional tasks required for the re-
inforcement learning are to define the variable set
on which the alternative choice should depend,
and to implement a reward function based on the
expected evaluation of the task completion, in or-
der to get a fully automated optimisation with an
online evaluation. The dialogue system automatic
evaluation is a large problem that goes beyond
the scope of this paper. However, sometimes, the
dialogue application enables to have an explicit
validation from the user. For instance, in an ap-
pointment scheduling application, the user is re-
quired to explicitly confirm the schedule he was
proposed. This user performative act completes
the task and provides a reliable automatic evalu-
ation.
4.2 Learning and Monitoring Synergy in the
Design Optimisation
The learning algorithm and the SDS developers
are two actors on the same object : the dialogue
system. But, they work at a different time space.
The learning algorithm updates its policy after
each dialogue while the SDS developers moni-
tor the system behaviour more occasionally. The
same kind of opposition can be made on the action
space of those actors. The learning algorithm can
only change its policy among a limited amount of
alternatives, while the SDS developers can make
deeper changes, such as implementing a new dia-
logue branch, adding new alternatives, new alter-
native points, removing alternatives, etc. . .
Last but not least, their sight ranges vary a lot
too. The learning algorithm is concentrated on the
alternative sets and automatic evaluation and ig-
nores the rest, while the SDS developers can ap-
prehend the dialogue application as a whole, as a
system or as a service. They can also have access
to additional evaluations through annotations, or
user subjective evaluations.
These functionality differences make their re-
spective roles complementary. The SDS develop-
189
0 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30
19
20
21
22
23
24
day
S
co
re
3-day means
daily score
FIGURE 3 ? Evolution of the system score
ers have the responsibility for the whole appli-
cation and the macro-strategic changes while the
learning manager holds the real-time optimisation.
4.3 Control vs. Automation : the Trusting
Threshold
As argued by Pieraccini and Huerta (Pieraccini
and Huerta, 2005), finite state machine applied to
dialogue management does not restrict the dia-
logue model to strictly directed dialogues. Finite
state machines are easily extensible to powerful
and flexible dialogue models. Our dialogue design
tool offers various extensions : dialogue modules,
hierarchical design, arbitrary function invocation
at any point of the design, conditional statements
to split the flow in different paths. All those ex-
tensions allow designing any topology of the fi-
nite state machine required to handle complex dia-
logue models like mixed-initiative interaction. Di-
alogue model is not the point where research and
industry fail to converge.
The divergence point concerns the control as-
pect of VUI-completeness versus the automation
of the dialogue design. As pointed out by recent
works (Paek and Pieraccini, 2008), MDP-based
dialogue management aiming at automating the
whole dialogue design is rejected by the SDS de-
velopers. Even more adaptive, it is seen as an un-
controllable black box sensitive to the tuning pro-
cess. The SDS developers do not rely on systems
that dynamically build their dialogue logic without
a sufficient degree of monitoring and control.
Williams (Williams, 2008) has made a substan-
tial effort to meet this industrial requirement. His
system is a hybridisation of a conventional dia-
logue system following an industrial process, with
a POMDP decision module, which is a MDP-
based approach to dialogue management enhanced
with dialogue state abstractions to model uncer-
tainties. The responsibilities of each part of the
system are shared as follows : the conventional
system elects several candidate dialogue moves
and the POMDP decision module selects the most
competitive one. This is a great step towards in-
dustry because the dialogue move chosen by the
POMDP module has been first controlled by the
conventional system design. Nevertheless, the so-
built hybrid system is still not fully compliant with
the industrial constraints for the following reasons.
First, contrary to our approach, the SDS devel-
oper is called upon specific skills that cannot be
demanded to a developer (modeling and tuning a
(PO)MDP). This is a no-go for further integration
in an industrial process.
Second, such a predictive module is not self-
explanatory. Although the SDS developers have
the control on the possible behaviour presented to
the POMDP decision module, they are given no
clue to understand how the choices are made. In
fact, a learnt feature can never be exported to an-
other context. At the opposite, our approach al-
lows us to learn at the design level and conse-
quently to report in the automaton the optimisa-
tion. The learning results are therefore understand-
190
able, analysable and replicable on a larger scale, in
a way similar to classical ergonomics guidelines
(but statistically proved).
4.4 Learning results on the 1013+ service
In the 1013+ service, our experiments have fo-
cused on the appointment scheduling domain. We
have chosen to integrate the following rewards in
the service : each time a user successfully man-
ages to get an appointment, the system is given a
+30 reward. If the system is unable to provide an
appointment, but manages to transfer the user to a
human operator, the system is given a +10 (a ?re-
sit?). Last, if the user hangs up, the system is not
given any positive reward. Every time the system
does not hear nor understand the user, it is given a
penalty of 1.
In the beginning of the experiment, when the
system is still using a random policy, the comple-
tion rate is as low as 51%, and the transfer rate is
around 36%. When the system has learned its op-
timal policy, the completion rate raises up to 70%,
with a transfer rate around 20%. In our experi-
ment, the system has learned to favour an imper-
sonal speaking style (passive mode) and it prefers
proposing appointment time slots rather than ask-
ing the user to make a proposition (the later case
leading to lot of ?in private? user talks and hesita-
tions, and worse recognition performance).
Figure 3 shows the evolution of the mean di-
alogue score during the first month. Each server
have its own Learning Manager database, and op-
timises separately. This is a welcome feature, as
each server can address a different part of the
user population, which is a frequent operational
requirement.
The dialogue score drawn on Figure 3 is com-
puted by averaging the mean dialogue score per
server. The crossed line represents the daily mean
dialogue score. The normal line represents the 3-
day smoothed dialogue mean score. The grayed
area represents the 95% confidence interval. Dur-
ing this first month of commercial exploitation,
one can notice two major trends : at first, the di-
alogue score is gradually increasing until day 20,
then the performances noticeably drops, before
rising up again. It turns out that new servers were
introduced on day 20, which had to learn the op-
timal dialogue policy. Ultimately (on the second
month), they converge to the same solution as the
first servers.
5 Conclusion
5.1 A New Basis for Trusting Automatic
Learning
This paper presents an original dialogue design
tool that mixes dialogue design and dialogue eval-
uation in the same graphical interface. The de-
sign paradigm supported by the tool leads the SDS
developers to predict value ranges of local KPI
while designing the dialogue logic. It results a new
evaluation paradigm using the system design as
the reference and trying to measure deviations be-
tween the predicted and the measured values of
the designed local KPI. The SDS developers rely
on the tool to fulfil the VUI-completeness princi-
ple. Classically applied to dialogue design, the tool
enables its application to the dialogue evaluation,
leading to the comparison of dialogue design al-
ternatives.
This places the SDS developers in a dialogue
design improvement cycle close to the reinforce-
ment learning decision process. Moreover, the in-
spector offered by the user experience feedback
functionality allows the SDS developers to un-
derstand, analyse and generalize all the decisions
among the dialogue design alternatives. Combin-
ing the learning framework and the design tool
guarantees the SDS developers keep control of the
system. It preserves VUI-completeness and opens
the way to a reliable learning based dialogue man-
agement.
5.2 Implementation
This approach to learning led us to deploy in
October 2009 the first commercial spoken dia-
logue system with online learning. The system?s
task is to schedule an appointment between the
customer and a technician. This service receives
approximately 8, 000 calls every month. At the
time those lines are written, we are already in a vir-
tuous circle of removing low-rated alternatives and
replacing them with new ones, based on what the
system learnt and what the designer understands
from the data.
5.3 Future Work
On a social studies side, we are interested in
collaborations to test advanced dialogue strategies
and/or information presentation via generation. In-
deed, we consider our system as a good opportu-
nity for large scope experiments.
191
6 Acknowledgements
This research has received funding from the
European Community?s Seventh Framework Pro-
gramme (FP7/2007-2013) under grant agreement
number 216594 (CLASSIC project : www.classic-
project.org).
References
A. Abella, J.H. Wright, and A.L. Gorin. 2004. Dia-
log trajectory analysis. In IEEE International Con-
ference on Acoustics, Speech and Signal Processing
(ICASSP), volume 1, pages 441?444, May.
R.E. Bellman. 1957. A markovian decision process.
Journal of Mathematics and Mechanics, 6 :679?684.
J. Bos, E. Klein, O. Lemon, and T. Oka. 2003. Dipper :
Description and formalisation of an information-
state update dialogue system architecture.
George Ferguson and James F. Allen. 1998. Trips : An
integrated intelligent problem-solving assistant. In
In Proc. 15th Nat. Conf. AI, pages 567?572. AAAI
Press.
R. Laroche, G. Putois, P. Bretier, and B. Bouchon-
Meunier. 2009. Hybridisation of expertise and
reinforcement learning in dialogue systems. In
Proceedings of Interspeech. Special Session : Ma-
chine Learning for Adaptivity in Spoken Dialogue,
Brighton (United Knigdom), September.
O. Lemon and O. Pietquin. 2007. Machine learn-
ing for spoken dialogue systems. In Proceedings
of the European Conference on Speech Commu-
nication and Technologies (Interspeech?07), pages
2685?2688, August.
M. F. McTear. 2004. Spoken Dialogue Technol-
ogy : Toward the Conversational User Interface.
Springer, August.
T. Paek and R. Pieraccini. 2008. Automating spoken
dialogue management design using machine learn-
ing : An industry perspective. Speech Communica-
tion, 50 :716?729.
T. Paek. 2007. Toward evaluation that leads to
best practices : Reconciling dialog evaluation in re-
search and industry. In Proceedings of the Work-
shop on Bridging the Gap : Academic and Indus-
trial Research in Dialog Technologies, pages 40?
47, Rochester, NY, April. Association for Compu-
tational Linguistics.
R. Pieraccini and J. Huerta. 2005. Where do we go
from here ? research and commercial spoken dialog
systems. In Laila Dybkjaer and Wolfgang Minker,
editors, Proceedings of the 6th SIGdial Workshop on
Discourse and Dialogue, pages 1?10.
R. Pieraccini, S. Caskey, K. Dayanidhi, B. Carpenter,
and M. Phillips. 2001. Etude, a recursive dialog
manager with embedded user interface patterns. In
Automatic Speech Recognition and Understanding,
2001 IEEE Workshop on, pages 244?247.
M. D. Sadek, P. Bretier, and F. Panaget. 1997. Ar-
timis : Natural dialogue meets rational agency. In
in Proceedings of IJCAI-97, pages 1030?1035. Mor-
gan Kaufmann.
J. D. Williams. 2008. The best of both worlds : Uni-
fying conventional dialog systems and POMDPs. In
International Conference on Speech and Language
Processing.
192
Proceedings of the SIGDIAL 2013 Conference, pages 97?101,
Metz, France, 22-24 August 2013. c?2013 Association for Computational Linguistics
Will my Spoken Dialogue System be a Slow Learner ?
Layla El Asri
Orange Labs / UMI 2958 (IMS-MaLIS)
Issy-les-Moulineaux (France) / Metz (France)
layla.elasri@orange.com
Romain Laroche
Orange Labs
Issy-les-Moulineaux (France)
romain.laroche@orange.com
Abstract
This paper presents a practical
methodology for the integration of
reinforcement learning during the
design of a Spoken Dialogue System
(SDS). It proposes a method that
enables SDS designers to know, in
advance, the number of dialogues that
their system will need in order to learn
the value of each state-action couple.
We ask the designer to provide a user
model in a simple way. Then, we run
simulations with this model and we
compute confidence intervals for the
mean of the expected return of the
state-action couples.
1 Introduction
The Dialogue Manager (DM) of a Spoken Di-
alogue System (SDS) selects actions accord-
ing to its current beliefs concerning the state
of the dialogue. Reinforcement Learning (RL)
has been more and more used for the optimisa-
tion of dialogue management, freeing designers
from having to fully implement the strategy of
the DM.
A framework known as Module-Variable
Decision Process (MVDP) was proposed by
Laroche et al (2009) who integrated RL into
an automaton-based DM. This led to the de-
ployment of the first commercial SDS imple-
menting RL (Putois et al, 2010).
Our work intends to continue this effort in
bridging the gap between research advances
on RL-based SDS and industrial release. One
important issue concerning the design of an
RL-based SDS is that it is difficult to evalu-
ate the number of training dialogues that will
be necessary for the system to learn an opti-
mal behaviour. The underlying mathematical
problem is the estimation of the training sam-
ple size needed by the RL algorithm for con-
vergence. Yet, designers are often not experts
in RL. Therefore, this paper presents a simple
methodology for evaluating the necessary sam-
ple size for an RL algorithm embedded into an
SDS. This methodology does not require any
RL expertise from designers. The latter are
asked to provide a model of user behaviour in
a simple way. According to this model, numer-
ous simulations are run and the sample size
for each module-state-action triple of the DM
is estimated. This methodology was tested on
an SDS designed during the CLASSiC Euro-
pean project1 (Laroche et al, 2011) and we
show that these computations are robust to
varying models of user behaviour.
2 Dialogue Management as a
Module-Variable Decision
Process
Module-Variable Decision Processes (MVDP)
factorise learning into modules, each module
having its own state and action spaces. For-
mally, an MVDP is a tuple (M,VM , AM , T )
where M is the module space, VM is the space
of local contexts, for each module m, Vm ? VM
is the set of variables which are relevant for
m?s decision making. Am ? AM is the set of
possible actions, an action beeing a transition
in the automaton. T ? R is the time scale. In
the following, time is measured in number of
dialogue turns, a turn being the time elapsed
between two ASR results.
1Computational Learning in Adaptive Systems for
Spoken Conversation, http://www.classic-project.org/
97
2.1 The Compliance Based
Reinforcement Learning
Algorithm
The Compliance-Based Reinforcement Learn-
ing algorithm (CBRL, Laroche et al, 2009) is
an adaptation of the Monte Carlo algorithm
to online off-policy learning. Each evaluation
phase in the Monte Carlo procedure requires
numerous new episodes. CBRL enables to ac-
celerate this process by adjusting the current
policy not after a set of many new episodes
but right after each episode and using all the
previous episodes to evaluate the policy. Each
dialogue is modelled as a sequence of decisions
dt = (mt, st, at, t) where mt is the module en-
countered at time t, st is the current local con-
text of mt and at is the action chosen by mt.
Each decision dt leads to an immediate reward
Rt. With ? a discount factor, the return for a
decision dt is rt =
?tf
ti=t ?ti?tRti , tf being the
final turn of the dialogue. For a given module
m, the value of any state-action couple (s, a)
is the expected return starting from (s, a) and
then choosing actions according to ?, the pol-
icy of the system: Qpim(s, a) = E[rt | mt =
m, st = s, at = a, ?]. ? is the set of all the
policies of the modules: ? = {?m1 , ..., ?m|M|}.
After a dialogue is taken under policy ?, the
value of any triple (m, s, a) is updated as in
Equation 1.
Qpim(s, a) =
?
?m(s,a)
?trt
?m(s, a)
(1)
where ?m(s, a) =
?
?m(s,a)
?t,
and ?m(s, a) = {dt}mt=m;st=s;at=a (2)
For any module m, the algorithm evaluates
the value of each couple (s, a) according to all
the decisions in which this tuple has been in-
volved from the beginning of learning (the set
of decisions ?m(s, a)). After each evaluation
of the Q-function, the policy ? is updated fol-
lowing an exploratory strategy based on the
Upper Confidence Bound 1 - Tuned approach
(Auer et al, 2002). The weights ?t in Equa-
tion 1 are there to take into account the fact
that ? is evaluated according to all the rewards
observed since the beginning of learning, re-
wards that were obtained following other poli-
cies. A local compliance cpi(dt) is associated
with each decision dt: it is the expected re-
gret induced by at not being the optimal ac-
tion according to the system?s current policy
?, cpi(dt) = Qpimt(st, at)?maxa?AmtQpimt(st, a).
The global compliance with ? of the decisions
following dt is a discounted sum of the local
compliances. The weight wt is then an increas-
ing function of the global compliance.
3 Problem Resolution
3.1 Approach
The problem to be solved is the follow-
ing. Let an MVDP (M,VM , AM , T ). For
each triple (m, s, a), we want to compute
the error made on the estimate Qm(s, a) of
E[r | m, s, a] according to the number of ob-
servations ?m(s, a). Let r1, ..., r|?m(s,a)| be
the returns corresponding to the decisions in
?m(s, a) and ?m(s,a) the variance of these re-
turns. We build a confidence interval for
E[r |m, s, a], centered in the estimateQm(s, a)
from user simulations with a bi-gram model
specified by the designer.
3.2 User Simulations
User simulation has been an active line of
research as it is often costly to gather real
data (Scheffler and Young, 2002; Georgila et
al., 2006; Yang and Heeman, 2007; Pietquin
and Hastie, 2010). Task-oriented systems such
as commercial ones aim to respond to a spe-
cific need. They are often conceived as slot-
filling systems (Raux et al, 2003; Chandramo-
han et al, 2011). The dialogue is relatively
well-guided by the system so there is no need
to take into account complex conversational
groundings to simulate user behaviour. There-
fore, we choose here to ask the designer to pro-
vide a bi-gram model (Eckert et al, 1997): a
probability distribution of user behaviour only
conditioned on the latest system action. For
each possible response, the designer provides
a lower and an upper bound for its probability
of occurring. Eckert et al (1997) showed that
slight modifications of user behaviour in the
bi-gram model did not entail great differences
of system performance. We support this claim
in Section 4 where we show that the confidence
intervals computation is robust to varying user
behaviour.
98
3.3 Confidence Intervals
According to the Lyapunov central limit
theorem, Qm(s, a) converges in law to the
normal distribution of mean E[Qm(s, a)] =
E[r | m, s, a] and variance var(Qm(s, a)) =?
?m(s,a) w2k
?2m(s, a)
?2m(s, a). However, since ?2m(s, a)
is unknown and the observations are not nec-
essarily distributed according to a normal law,
we can only rely on an asymptotic result ac-
cording to which, for a sufficiently large num-
ber of samples, the previous convergence re-
sult holds with the unbiased estimate of the
returns variance ??m(s, a). A confidence inter-
val of probability 1 ? ? for E[r | m, s, a] is
then:
[Qm(s, a)? ?m,s,a, Qm(s, a) + ?m,s,a] (3)
We note u? = ??1N(0,1)(1? ?2 ), with ?N(0,1) the
cumulative distribution function of N(0, 1):
?m,s,a =
?
?m(s,a)
?2k
?m(s, a)
??m(s, a)u? (4)
In the non-weighted case, the previous asymp-
totic result is generally considered to hold for
a number of samples greater than 30. We thus
consider the confidence intervals to be valid for
?m(s, a) =
?2m(s, a)?
?m(s,a) ?2k
> 30.
3.4 ?-Convergence Definition
A confidence interval can be computed for each
(m, s, a) triple of the system. From this com-
putation, we deduce the number of dialogues
necessary for convergence i.e. for the width
of the confidence interval to be under a given
threshold. The confidence interval radius of a
triple (m, s, a) depends on the variance of ob-
served returns (see equation 4) so we define
the normalised confidence interval radius:
?m,s,a =
?m,s,a
??m(s, a)
= u??
?m(s, a)? 1
(5)
We will consider that a triple (m, s, a) will
have ?-converged once the normalised confi-
dence interval radius will have come under ?.
Figure 1: A schematic view of the system.
4 Experiments
4.1 System Description
The negotiation strategy of the system is hard-
coded (see Figure 1). The system starts each
dialogue proposing to the user its first avail-
ability (module 1). Then, if the user rejects
the proposition, the system asks them to give
their first availability (module 3). If the first
two steps have not resulted in success, the sys-
tem proposes its next availabilities (module 2)
until an appointment is booked (module 7) or
the system has no more propositions to make
(module 8). When a user proposes a date, the
system asks for a confirmation through mod-
ule 4. Two error-repair modules (modules 6
and 5) notify the user that they have not been
understood or heard (in case of a time out).
More details can be found in (Laroche et al,
2011). Each module has to choose between
three actions: uttering with a calm (action 1),
neutral (action 2) or dynamic (action 3) tone.
In our experiments, user simulation was mod-
elled so that the first two alternatives were ar-
tificially disadvantaged: the number of failures
was slightly increased whenever one of them
was chosen. We modelled here the fact that
users would always prefer the dynamic intona-
tion.
We ran 2000 simulations, one simulation
consisting of a complete dialogue ending with
an update of the state-action value function for
each of the system?s modules. The following
results are averages on 100 runs.
We set the hanging-up rate to 10%. ? was
set to 0.05 and ? to 0.1. In the following sec-
tion, we use the notation (i, j, k) to refer to
(mi, sj , ak).2
2sj is always equal to 1 because the local contexts
space is equal to the module space
99
Figure 2: Evolution of ?m,s,a for triples (1, 1,
1), (1, 1, 3), (4, 1, 2) and (4, 1, 3) according
to the total number of dialogues. Users prefer
action 3.
4.2 Results
By the end of our experiments, modules 4, 5
and 8 had not ?0.1-converged. Module 5 was
not likely to be visited quite often according to
our specification of user behaviour. The same
happened for module 4, only accessible from
module 3 (see Figure 1), which was not itself
often visited. Module 1 is, with module 8, a
starting module of the system. At the begin-
ning of a dialogue, module 1 had a 95% proba-
bility of being visited whereas this probability
was of 5% for module 8 (this only happened
when all available appointments had already
been booked). Therefore, module 1 was vis-
ited once during almost every dialogue. We
will now focus on modules 1 and 4 for clarity
of presentation.
We can conclude from Figure 2 that triple
(1, 1, 3) ?0.1-converged after about 640 di-
alogues, corresponding to about 425 visits
whereas neither triple (1, 1, 1) nor (4, 1, 2)
nor (4, 1, 3) ?0.1-converged, even after 2000 di-
alogues. Indeed, these triples did not receive
enough visits during the simulations. Triple
(1, 1, 3) ?0.1-converged whereas (1, 1, 1) did
not because, at one point, the growth of the
number of visits to (1, 1, 1) slowed down as
module 1 favoured action 3 and reduced its
exploration of other actions. The fact is that
the RL algorithm did not need such a precise
estimation for (1, 1, 1) to understand action 1
(the neutral tone) was suboptimal.
The variance over the 100 runs of the final
estimation of ?m,s,a was below 0.01. For all
triples of the system, the variance was very
low after about 500 dialogues only (from 10?5
to 0.02). This means that the approximate
user behaviour, defined with probability win-
dows, only had a limited impact on the reli-
ability of the computed confidence intervals.
The probability windows used in the experi-
ments were narrow (of an average size of 10%)
so user behaviour did not change drastically
from a run to another. With a behaviour much
more erratic (larger probability windows), the
variance over 10 runs was higher but did not
exceed 0.02.
5 Related Work
Suendermann et al (2010) tackled the issue of
reducing the risk induced by on-line learning
for commercial SDS with contender-based di-
alogue management. Our study relates to this
work but within the more complex learning
structure of RL.
Closer to our study, Tetreault et al (2007)
compared confidence intervals for the expected
return for different MDPs, all modelling the
same SDS but with a different state space.
They showed how the intervals bounds as well
as the expected cumulative returns estima-
tions could be used in order to select an appro-
priate state space. More recently, Daubigney
et al (2011) as well as Gasic et al (2011) de-
veloped an efficient exploration strategy for an
MDP-based DM based on the uncertainties on
the expected returns estimations. The differ-
ence between these two approaches and ours
is that they compute the confidence intervals
for a known policy whereas we compute the
expected confidence intervals for an unknown
policy that will be learnt on-line.
6 Conclusion
To help the development of SDS embedding
on-line RL, we have designed and implemented
an algorithm which computes the normalised
confidence interval radius for the value of a
state-action couple. We have illustrated this
algorithm on an appointment scheduling SDS.
We believe our method can be transferred to
any system implementing an RL episodic task,
as long as the environment can be simulated.
100
References
Senthilkumar Chandramohan, Matthieu Geist, Fabrice
Lefe`vre, and Olivier Pietquin. 2011. User simula-
tion in dialogue systems using inverse reinforcement
learning. In Proceedings of Interspeech.
Lucie Daubigney, Milica Gasic, Senthilkumar Chan-
dramohan, Matthieu Geist, Olivier Pietquin, and
Steve Young. 2011. Uncertainty management for
on-line optimisation of a pomdp-based large-scale
spoken dialogue system. In Proceedings of Inter-
speech, pages 1301?1304.
Wieland Eckert, Esther Levin, and Roberto Pieraccini.
1997. User modeling for spoken dialogue system
evaluation. In Proceedings of IEEE ASRU, pages
80?87.
Milica Gasic, Filip Jurcicek, Blaise Thomson, Kai Yu,
and Steve Young. 2011. On-line policy optimisation
of spoken dialogue systems via live interaction with
human subjects. In Proceedings of IEEE ASRU.
Kallirroi Georgila, James Henderson, and Oliver
Lemon. 2006. User simulation for spoken dialogue
systems: Learning and evaluation. In Proceedings of
Interspeech.
Romain Laroche, Ghislain Putois, Philippe Bretier,
and Bernadette Bouchon-Meunier. 2009. Hybridis-
ation of expertise and reinforcement learning in di-
alogue systems. In Proceedings of Interspeech.
Romain Laroche, Ghislain Putois, Philippe Bretier,
Martin Aranguren, Julia Velkovska, Helen Hastie,
Simon Keizer, Kai Yu, Filip Jurcicek, Oliver Lemon,
and Steve Young. 2011. D6.4: Final evaluation
of classic towninfo and appointment scheduling sys-
tems. Technical report, CLASSIC Project.
Olivier Pietquin and Helen Hastie. 2010. Metrics for
the evaluation of user simulations. Technical Report
Deliverable 3.5, CLASSIC Project.
Ghislain Putois, Romain Laroche, and Philippe
Bretier. 2010. Enhanced monitoring tools and on-
line dialogue optimisation merged into a new spoken
dialogue system design experience. In Proceedings of
SIGdial Workshop on Discourse and Dialogue, pages
185?192.
Antoine Raux, Brian Langner, Allan Black, and Max-
ine Eskenazi. 2003. LET?S GO: Improving Spoken
Dialog Systems for the Elderly and Non-natives. In
Proceedings of Eurospeech.
Konrad Scheffler and Steve Young. 2002. Automatic
learning of dialogue strategy using dialogue simula-
tion and reinforcement learning. In Proceedings of
HLT, pages 12?18.
David Suendermann, John Liscombe, and Roberto
Pieraccini. 2010. Contender. In Proceedings of
IEEE SLT, pages 330?335.
Joel R. Tetreault, Dan Bohus, and Diane J. Litman.
2007. Estimating the reliability of mdp policies:
A confidence interval approach. In Proceedings of
HLT-NAACL, pages 276?283.
Fan Yang and Peter A. Heeman. 2007. Exploring ini-
tiative strategies using computer simulation. In Pro-
ceedings of Interspeech, pages 106?109.
101
Proceedings of the SIGDIAL 2014 Conference, pages 98?107,
Philadelphia, U.S.A., 18-20 June 2014.
c?2014 Association for Computational Linguistics
An easy method to make dialogue systems incremental
Hatim KHOUZAIMI
Orange Labs
Laboratoire Informatique d?Avignon
hatim.khouzaimi@orange.com
Romain LAROCHE
Orange Labs,
Issy-les-Moulineaux,
France
romain.laroche@orange.com
Fabrice LEFEVRE
Laboratoire Informatique d?Avignon,
Avignon, France
fabrice.lefevre@univ-avignon.fr
Abstract
Incrementality as a way of managing the
interactions between a dialogue system
and its users has been shown to have
concrete advantages over the traditional
turn-taking frame. Incremental systems
are more reactive, more human-like, of-
fer a better user experience and allow the
user to correct errors faster, hence avoid-
ing desynchronisations. Several incremen-
tal models have been proposed, however,
their core underlying architecture is dif-
ferent from the classical dialogue systems.
As a result, they have to be implemented
from scratch. In this paper, we propose a
method to transform traditional dialogue
systems into incremental ones. A new
module, called the Scheduler is inserted
between the client and the service so that
from the client?s point of view, the sys-
tem behaves incrementally, even though
the service does not.
1 Introduction
An incremental compiler (Lock, 1965) processes
each instruction irrespectively from the others so
that local modifications of the source code do not
affect the global result. This idea of incrementality
has been adapted to the field of natural language
analysis (Wir?n, 1992): instead of feeding mod-
ules with full utterances, the input signal is deliv-
ered and processed chunk by chunk (word by word
for example) and each new piece engenders a new
output hypothesis.
Human beings behave similarly when interact-
ing with each other (Levelt, 1989; Clark, 1996).
They understand each other gradually when they
speak, they can interrupt each other and the lis-
tener is able to predict the end of an utterance be-
fore it is fully pronounced by the speaker (Tanen-
haus et al., 1995; Brown-Schmidt and Hanna,
2011; DeVault et al., 2011). Reading is also a task
that we perform incrementally (Ilkin and Sturt,
2011).
Traditional dialogue systems
1
work in a turn-
taking manner. The user pronounces his request
and after a silence is detected, the systems starts
processing the utterance and planning an answer.
Some systems can even allow the user to barge in
on them, however, they do not take the timing of
the interruption into account nor try to link it with
the system?s utterance. On the other hand, incre-
mental dialogue systems process the user?s request
chunk by chunk as the latter is divided in several
incremental units (IU) (Schlangen and Skantze,
2011). They keep a hypothetical user request that
evolves as new IUs arrive as input. The response
to this hypothesis can be used to make live feed-
back to the user using voice or other modalities if
available. As opposed to traditional systems, when
the user interrupts the system, the content and the
timing of its utterance are taken into account (Mat-
suyama et al., 2009; Selfridge et al., 2013) to de-
termine how to act on it. Therefore, incremental
systems have been shown to be more reactive, to
offer a more human-like experience (Edlund et al.,
2008) and to correct errors faster hence achieving
better results in terms of user experience (Skantze
and Schlangen, 2009; Baumann and Schlangen,
2013; El Asri et al., 2014) and task completion
(Matthias, 2008; El Asri et al., 2014).
Many incremental architectures have already
been proposed. Nevertheless, designing systems
based on them requires an implementation from
scratch as they are fundamentally different from
traditional dialogue systems. The objective of this
paper is to propose a method of transforming a tra-
ditional system into an incremental one at minimal
cost. A new module called the Scheduler is in-
serted between the client and the service so that
1
We will use the expression traditional dialogue systems
to talk about non incremental ones.
98
from the client?s point of view, the system behaves
incrementally, even though the service works in a
traditional way.
Section 2 draws a state-of-the-art concerning in-
cremental dialogue systems. The architecture pro-
posed here and the role of the Scheduler are pre-
sented in Section 3. In Section 4, two implemen-
tations of our method are presented: CFAsT and
DictaNum. Then, a discussion is held in Section
5 before concluding the paper and presenting our
next objectives in Section 6.
2 Related work
Dialogue systems can be split into four groups
according to how they integrate incrementality
in their behaviour. Traditional dialogue systems
(Laroche et al., 2011) form the first category
whereas the second one refers to systems that
propose some incremental strategies among tra-
ditional others (El Asri et al., 2014). The ar-
chitecture presented in this paper belongs to the
third group which contains incremental systems
based on a traditional inner behaviour (Hastie et
al., 2013; Selfridge et al., 2012). The fourth cate-
gory contains incremental systems where internal
modules work incrementally (Dohsaka and Shi-
mazu, 1997; Allen et al., 2001; Schlangen and
Skantze, 2011). Figure 1 discussed later provides
a list of the features that are available in each cat-
egory.
Several dialogue strategies have been imple-
mented in NASTIA (El Asri et al., 2014), a dia-
logue system helping the user to find a date and
a time for an appointment with a technician (com-
pleting the work made during the European project
CLASSiC (Laroche and Putois, 2010)). Among
them, List of Availabilities is an incremental strat-
egy where the system enumerates a list of alterna-
tives for the appointment. The user is supposed to
interrupt this enumeration when he hears an op-
tion that is convenient for him. An experiment
showed that List of Availabilities produced better
results than other traditional strategies in terms of
task completion and user satisfaction.
PARLANCE (Hastie et al., 2013) is an exam-
ple of a third category system (it was developed
in the European project PARLANCE). Its archi-
tecture is similar to the traditional ones but it inte-
grates a new module, called MIM (Micro-turn In-
teraction Manager), which decides when the sys-
tem should speak, listen to the user and when it
should generate back-channels. The closest ap-
proach to the method introduced in this paper is
presented in (Selfridge et al., 2012) : the IIM (In-
cremental Interaction Manager) is an intermediate
module between an incremental ASR and a TTS
on the one hand and the service on the other hand.
Instead of replicating the dialogue context as it is
suggested in this paper, different instances of the
service are run. Moreover, the IIM is introduced as
preliminary work in order to simulate incremen-
tal dialogue whereas in this paper, the Scheduler
approach is fully studied and placed into the con-
text of the current state-of-the-art concerning in-
cremental dialogue. It is also viewed as a new
layer that can be extended later on, into a smart
turn-taking manager.
The architecture proposed in (Dohsaka and Shi-
mazu, 1997) contains eight modules that work in
parallel: the Speech Recognizer, the Response
Analyzer, the Dialogue Controller, the Problem
Solver, the Utterance Planner, the Utterance Con-
troller, the Speech Synthesizer and the Pause Mon-
itor. The user asks the system to solve a problem.
Then, his request is submitted incrementally to the
Speech Recognizer which sends its output text to
the Response Analyzer that figures out concepts to
be sent to the Dialogue Controller. The latter in-
teracts with the Problem Solver and the Utterance
Planner in order to compute a solution that is com-
municated to the user through the Utterance Con-
troller then the Speech Synthesizer. This system
belongs to the fourth category as all its modules
behave incrementally in order to start suggesting
a solution to the user?s problem before it is to-
tally computed. In the same category, (Allen et al.,
2001) proposes another architectures split in three
main modules: the Interpretation Manager, the Be-
havioral Agent and the Generation Manager. The
first module catches the user?s request and broad-
casts it incrementally inside the system. The sec-
ond one manages the system?s action plan and the
third is in charge of the response delivery.
A general and abstract model is introduced in
(Schlangen and Skantze, 2011). A dialogue sys-
tem can be viewed as a chain of modules. Each
module has a Left Buffer (LB) where its inputs are
pushed, an Internal State (IS) and a Right Buffer
(RB) where it makes its outputs available. Data
(audio, text, concepts...) flows through these mod-
ules in the form of Incremental Units (IU). When
an IU is put in the LB of a module, it can be pro-
99
cessed immediately hence modifying its RB. For
example, every 500 ms, a new IU in the form of
a chunk of audio signal can be put into the LB
of the ASR which can modify its output accord-
ing to what the user said during this time window.
All dialogue systems from the four categories can
be viewed as instances of this general model: we
can now see that a non-incremental system can be
characterised as a special case of an incremental
system, namely one where IUs are always maxi-
mally complete [...] and where all modules update
in one go.
In this paper, we introduce an architecture that
belongs to the third category. In comparison with
the first two categories, these systems behave in-
crementally during the whole dialogue. On the
other hand, they can be built at a lower cost than
the systems from the fourth category.
3 Architecture
Traditional dialogue systems are generally com-
posed of a client on the user?s terminal and a ser-
vice that is deployed on a remote machine. They
work in a turn-taking manner as when the user
speaks, the system waits until the end of his re-
quest before processing it and vice versa (except
for some systems where the user can interrupt the
system). To make such a system incremental, we
suggest inserting a new module between the client
and the service: the Scheduler (this denomination
is taken from (Laroche, 2010)). This new archi-
tecture can be cast as an instance of the general
abstract model of (Schlangen and Skantze, 2011).
The client, the Scheduler and the service are the
three modules that compose the system. The first
two ones are incremental but the last one is not.
We will not use the notions of LB and RB and
will consider that these modules interact with each
other through some channel (network in the case
of our implementation, see Section 4).
3.1 The traditional architecture
In a traditional architecture, the client receives a
stream of data (audio signal, string...). If it is not
the case (a web interface where each button rep-
resents a request for example), it does not make
sense to transform such a system in an incremen-
tal one, so they are out of the scope of this paper.
The end of a request is determined by a condition
EndTurnCond. It can be a long enough silence
(Raux and Eskenazi, 2008; Wlodarczak and Wag-
ner, 2013) in the case of vocal services or a car-
riage return for text systems. A dialogue turn is
the time interval during which the user sends a re-
quest to the system and gets a response. These
turns will be called T
1
, T
2
, ..., T
k
... and each one
of them can be split into a user turn T
k,U
and a
system turn T
k,S
: T
k
= T
k,U
? T
k,S
. During the
user turn, a request Req
k
is sent and during the
system turn, the corresponding response Resp
k
is
received. The instant when a condition goes from
false to true will be called its activation time. As
a consequence, T
k,U
ends at the activation time
of EndTurnCond and T
k,S
is finished when the
system gives the floor to the user.
The service is made up of three parts: the inter-
nal interface, the internal context and the external
interface. The internal interface manages the inter-
actions between the service and the client. The in-
ternal context handles the way the client?s requests
should be acted on and the external interface is in
charge of the interactions with the external world
(database, remote device...).
3.2 Incrementality integration
The way the client sends the user?s request to the
service should be modified in order to make the
system incremental. A new sending condition is
defined: EndMicroTurnCond and it is less re-
strictive than EndTurnCond (which makes the
latter imply the former). Therefore, the new client
sends requests more frequently than the traditional
one. A user micro-turn is the time interval between
two activation times of EndMicroTurnCond so
the user turn T
k,U
can be divided into n
k,U
user
micro-turns ?T
k,U
i
: T
k,U
=
?
n
k,U
i=1
?T
k,U
i
. We
also define the p
th
sub-turn of the user turn T
k,U
as: T
k,U
p
=
?
p
i=1
?T
k,U
i
. The union symbol is
used as we concatenate time intervals. In gen-
eral, EndMicroTurnCond can be activated at
a constant frequency or at each new input made
by the user. Moreover, when EndTurnCond is
activated, the Scheduler is informed by the client
thanks to a dedicated signal: signal_ETC. At each
T
k,S
, the user makes a new request but at the
micro-turn ?T
k,S
i
with i < n
k,U
, the complete re-
quest is not available yet. Consequently, a tempo-
rary request which we will call sub-request (Req
k
i
)
is sent. Sending the whole request from the begin-
ning of the turn at each micro-turn is called restart
incremental processing (Schlangen and Skantze,
2011). Let us notice that if i
1
< i
2
then Req
k
i
1
100
is not necessarily a prefix of Req
k
i
2
(in spoken di-
alogue, a new input in the ASR can modify the
whole or a big part of the output).
The Scheduler is an intermediate module be-
tween the client and the service whose aim is to
make the combination {Scheduler + Service} be-
have incrementally from the client?s point of view.
We define ServiceReqCond as the condition con-
straining the Scheduler to send a request to the sys-
tem or not. At each user micro-turn ?T
k,S
i
, it re-
ceives a sub-request Req
k
i
. If ServiceReqCond
is true, the latter is sent to the system and the
corresponding response Resp
k
i
is stored so that
the client can ask for it later. For example,
ServiceReqCond can be constantly true which
makes the Scheduler send all the sub-requests that
it receives or it can be activated only if the new
sub-request is different from the previous one (if
the client already behaves the same way through
EndMicroTurnCond it is redundant to do so in
ServiceReqCond too).
The end of a turn is determined by the Sched-
uler. This module decides when to validate the
current sub-request and to no longer wait for new
information to complete it. It engages the di-
alogue in the direction of this hypothesis as it
is considered as the user?s intent. The Sched-
uler is said to commit the sub-request (Schlangen
and Skantze, 2011) (this notion is described in
Section 3.3). We define CommitCond as the
condition for the Scheduler to commit a hy-
pothesis. For example, in the case of a sys-
tem that asks for a 10 digits phone number,
CommitCond = (length(num) == 10) where
length(num) is the number of digits in each sub-
request. Hence, a user turn ends at the activa-
tion time of CommitCond and not when a sig-
nal_ETC is received. However, EndTurnCond
implies CommitCond.
The client is made of two threads: the send-
ing thread and the recuperation thread. The first
one is in charge of sending sub-requests at each
micro-turn and the second one gets the last re-
sponse hypothesis available in the Scheduler. The
recuperation thread is activated at the same fre-
quency as micro-turns so that the client is always
up to date. In the case of vocal services, it is the
Scheduler?s task to decide which intermediate re-
sponses should be pronounced by the system and
which ones should be ignored. Therefore, a flag
in the message must be set by this module to de-
clare whether it has to be outputted or not. When
the recuperation thread gets new messages from
the Scheduler, it decides whether to send it to the
Text-To-Speech module or not based on the value
of this flag.
The service in our architecture is kept un-
changed (apart from some changes at the ap-
plicative level, see Section 4.2). The only func-
tional modification is that the context is dupli-
cated: the simulation context (see Section 3.3) is
added. When a new sub-request is received by
the Scheduler and ServiceReqCond is true, an
incomplete request (sub-request) is sent to the ser-
vice. Therefore, the system knows what would be
the response of a sub-request if it has to be com-
mitted. As the service is not incremental and can-
not process the request chunk by chunk, all the in-
crements from the beginning of the turn have to
be sent and that is what justifies the choice of the
restart incremental mode.
The service can also order the Scheduler
to commit. This behaviour is described in
(Schlangen and Skantze, 2011) where the IUs in
the RB of a module are grounded in the ones in
the LB that generated them. Consequently, when
a module decides to commit to an output IU, all
the IUs that it is grounded in must be committed.
In our architecture, when the service commits to
the result of a request (if it already started deliv-
ering the response to the user for example), this
request has to be committed by the Scheduler.
On the other hand, as we defined the user
micro-turn, we can introduce the system micro-
turn. In traditional systems, the service?s re-
sponse is played by the TTS during the system turn
T
k,S
. In incremental dialogue, this turn can be di-
vided into n
k
S
system micro-turns ?T
k,S
i
: T
k,S
=
?
n
k
S
i=1
?T
k,S
i
. Their duration depends on the way
the service decides to chunk its response (for ex-
ample, every item in an enumeration can be con-
sidered as a chunk). When the user interrupts the
system, the timing of his interruption is given by
the micro-turn during which he reacted. Moreover,
when the user barges in, a new tour is started. Only
vocal systems are concerned with this behaviour as
textual systems cannot be interrupted (the whole
service response is displayed instantly).
3.3 Commit, rollback and double context
The request hypothesis fluctuates as long as new
increments are taken into account. However, at
101
some point, the system has to take an action that
is based on the last hypothesis and visible by the
user. For example, a response may be sent to the
TTS or a database can be modified. At that point,
the system is said to commit to its last hypothe-
sis which means that it engages the dialogue ac-
cording to its understanding of the request at that
moment. It no longer waits for other incremental
units to complete the request as it can no longer
change it. On the contrary, the system can decide
to forget its last hypothesis and come back to the
state it was in at the moment of the last commit.
This operation is called rollback (both terms are
taken from the database terminology).
Most of the requests sent by the Scheduler to the
service are aimed to know what would the latter
respond if the current hypothesis contains all the
information about the user?s intent. Consequently,
these requests should not modify the current con-
text of the dialogue. We suggest that the service
maintains two contexts: the real context and the
simulation context. The first one plays the same
role as the classical context whereas the second
one is a buffer that can be modified by partial re-
quests.
In our architecture, committing to a hypothesis
will be made by copying the content of the sim-
ulation context (generated by the current request
hypothesis) into the real context. On the opposite,
a rollback is performed by copying the real con-
text into the simulation one, hence going back to
the state the system was in right after the last com-
mit.
Every user micro-turn, the client sends to the
Scheduler the whole user?s sub-request since the
last commit. This incomplete request is then
sent to the service and the answer is stored in
the Scheduler. If during the next micro-turn, the
Scheduler does not ask for a commit but needs to
send a new sub-request instead, a rollback signal is
sent first as the system works in a restart incremen-
tal way (in this paper, rollbacks are only performed
in this case). Figures A.1 and A.2 represent the
way our three modules interact and how the dou-
ble context is handled. In Figure A.1, the con-
ditions EndTurnCond, EndMicroTurnCond,
ServiceReqCond and CommitCond are written
on the left of the streams they generate. On the left
of the figure, the times where the sending thread of
the client is active and inactive are represented and
dashed arrows represent streams that are received
by the recuperation thread. They are not synchro-
nized with the rest of the streams, even though
they are in this figure (for more clarity). Also, the
commit decision has been taken by the Scheduler
after it received a signal_ETC which is not always
the case.
We call ctxt(T
k
) the real context at the end of
T
k
(ctxt(T
0
) being the initial context at the begin-
ning of the dialogue). The context is not modified
during the system turn, hence, we may notice that
ctxt(T
k,U
) = ctxt(T
k
). During the commit at the
end of T
k,U
, the simulated context is copied into
the real context: ctxt(T
k
) = ctxt(T
k?1
+T
k,U
n
k,U
).
4 Implementations
We implemented our method in the case of two
dialogue systems developed at Orange Labs. The
first one is a text service where the client is a web
interface and the second one is a vocal service de-
signed to record numbers. With only a few modifi-
cations, these two systems have been made incre-
mental, showing that our solution is easy to im-
plement, and demonstrating the incremental be-
haviour of the transformed systems, in the limit
of the implemented strategies and according to
the modalities that have been used (text and vocal
modes).
4.1 CFAsT: Content Finder AssitanT
CFAsT is an application developed at Orange Labs
and which can be used to generate textual dialogue
systems and whose objective is to help the user
search for some specific content in a database.
The client is a web page with a text-box where
the user can type a request using natural language
(validated by a carriage return or by clicking on
the validate button). This page also contains
buttons representing keywords or content sugges-
tions. In this implementation, the content base
chosen is the list of accepted papers at the NIPS
2013 conference. A list of keywords is maintained
through the interaction. It is initially empty and for
each new request, if new keywords are detected,
they are added to the list. The interaction ends
when the user selects a unique content.
In our implementation
2
, the client is made of
two screens. The first one contains the same
view as the classical system and the second
one fluctuates incrementally. When the user is
typing a request, the second view is updated
2
http://dialogue.orange-labs.fr/CFAsTIncrEng/
102
each time the space button is hit: it shows
the answer that the service would have given
in case of a carriage return at that moment.
When a request is validated, a commit is per-
formed and the two views are identical. In this
case: EndMicroTurnCond is activated when
the space button is hit (ServiceReqCond does
not filtrate any sub-request) and EndTurnCond
is true if a carriage return is detected. In addition,
CommitCond = EndTurnCond.
4.2 DictaNum
The second implementation is a vocal system
called DictaNum and inspired by NUMBERS di-
alogue system (Skantze and Schlangen, 2009). It
asks the user to dictate a number and then gives
a feedback to confirm that it has been well un-
derstood. The client is an HTML web page that
interacts with the Scheduler using AJAX
3
. It uses
the Google web API for both the ASR and TTS
tasks. Other existing systems ask the user to dic-
tate a number (telephone, credit card...) such as
How may I help you? (Langkilde et al., 1999).
Here is an example of an interaction with the tra-
ditional version of DictaNum:
System: Welcome to the DictaNum service. Please dictate
your number.
User: 01 45 65 79 98.
System: The dictated number is: 01 45 67 79 98. Is that
correct?
User: No.
System: Sorry. Let us try again. Please dictate your number.
User: 01 45 65 79 98.
System: The dictated number is: 01 47 65 79 98. Is that
correct?
User: No.
System: Sorry. Let us try again. Please dictate your number.
[...]
System: The dictated number is: 01 45 65 79 98. Is that
correct?
User: Yes.
System: Thank you for using DictaNum. Bye.
If the user?s request has not been understood
correctly in one shot, he has to dictate it again.
This is not an optimal strategy. DictaNum has
been modified to support chunk by chunk dicta-
tion as in the following example:
3
http://dialogue.orange-labs.fr/DictaNumEng/
System: Welcome to the DictaNum service. Please dictate
your number.
User: 01 45
System: 01 45
User: 65 79
System: 67 79
User: No, 65 79
System: Sorry, 65 79
User: 98
System: 98
User: ...
System: The dictated number is: 01 45 65 79 98. Is that
correct?
User: Yes.
System: Thank you for using DictaNum. Bye.
In order to generate feedbacks, the service has
been modified at the applicative level. It maintains
a string that is supposed to contain the complete
number at the end of the interaction. Initially, this
string is empty. When a silence is detected af-
ter a chunk is dictated, the system repeats the lat-
ter as a feedback to the user and concatenates it
at the end of the number string. If the user be-
gins a new chunk with No, the system understands
that it has to correct the last one (starting the next
feedback with Sorry...), otherwise, it keeps it and
moves forward in the dictation. Finally, if after
a feedback a silence is detected with nothing dic-
tated, the system understands that the dictation is
over and makes a general feedback over the whole
number.
These modifications are not enough for the sys-
tem to be used in an incremental way. It is not
optimal for the user to insert silences in his dic-
tation. Of course, he can, but it is not convenient
nor natural. The client has been modified so that it
no longer waits for a silence to send the user?s re-
quest, instead, it sends a partial request every 500
ms (EndMicroTurnCond). The partial request
is sent on a restart incremental mode.
Also, DictaNum can detect silences in a micro-
turn level. We call ?
s
the silence threshold used
to determine the end of a request in the tradi-
tional system and we introduce a new threshold
?
s
such as ?
s
? ?
s
. A silence whose duration is
greater than ?
s
is called micro-silence. The sys-
tem has been modified in order to detect these
shorter silences during the dictation, to commit
(EndTurnCond = CommitCond) and deliver
a feedback right after. Additionally, our system?s
103
response time is very short, the feedback message
is available before the end of the micro-silence, so
it is fed to the TTS without any delay. If ?
s
= ?
s
,
it is more convenient to dictate the number in one
shot. Therefore, moving ?
s
between zero and ?
s
creates a continuum between traditional systems
and incremental ones. One may argue that these
modifications are enough and no incremental be-
haviour is required, but the response delay will be
higher, hence, the user will not wait for any feed-
back and will try to dictate his number in one shot.
If the user manifests a silence that is longer than
?
s
right after a feedback, the dictation ends and
a general feedback is made to confirm the whole
number. In our system, silences are determined by
the number micro-turns during which there is no
new input from the ASR but we could have used
the VAD (Voice Activity Detection) (Breslin et al.,
2013).
We set EndMicroTurnCond to be activated
by a 2 Hz clock and at every micro-turn, the
Scheduler checks whether the new request is dif-
ferent from the previous one (ServiceReqCond).
If that is the case, a rollback signal is sent followed
by all the digits in the current number fragment.
When a micro-silence is detected, a string silence
is sent to the Scheduler (as signal_ETC) and that is
when the Scheduler decides to commit. The recu-
peration thread requests the last message from the
service with the same frequency as micro-turns, so
when CommitCond is activated, the feedback is
already available and is delivered instantly to the
TTS.
Finally, it is also possible for the user to in-
terrupt the system during the final feedback. To
do so, the service sends a feedback message in
the following format: The dictated number is: 01
<sep> 45 <sep> 65 <sep> 79 <sep> 98. Is that
correct?. The <sep> is a separator that is used to
delimit the system micro-turns ?T
k,S
i
. They are
pronounced one after another by the TTS. As a re-
sult, a dictation may end like this:
System: The dictated number is: 01 45 67 ...
User: No, 65.
System: Sorry. The dictated number is: 01 45 65 79 98. Is
that correct?
User: Yes.
System: Thank you for using DictaNum. Bye.
After the interruption, a message sent to the ser-
vice under the following format: {part of the re-
quest that has been pronounced so far | barge-in
content}. In our example, this message is {The
dictated number is: 01 45 67 | No, 65} which
makes the service know how to perform the cor-
rection (or not, if the interruption is just a confir-
mation for example).
5 Discussion
Incremental dialogue systems present new fea-
tures compared to traditional ones. In this section,
we analyse the abilities of these systems given the
way they integrate incrementality. To do so, we
classify them as suggested in Section 2. Figure
1 summarizes the features discussed. These fea-
tures are specific to incremental dialogue systems,
so they do not exist in the first category. On the
contrary, they have all been implemented in sys-
tems from the fourth category.
To interact with the NASTIA service, the user
has to call a vocal platform which handles the ASR
and TTS tasks. It has been configured in order to
interrupt the TTS when activity is detected in the
ASR. When using the List of Availabilities strat-
egy, each item during an enumeration is a dialogue
turn where the timeout duration is set to a low
value (time to declare that the user did not answer)
so that if he does not barge-in, the system moves to
the next item of the list. If the user speaks, the TTS
is stopped by the vocal platform and the user?s ut-
terance and its timing are communicated to the ser-
vice. The latter can ignore the barge-in (if the user
says No for example) or select an item in the list
according to this input. Some traditional systems
allow the user to interrupt them but they do not
take the content of the utterance into account nor
its timing (in order to make the link with the utter-
ance of the TTS). Hence, these two features can be
implemented in a dialogue system provided that
it is permanently listening to the user and that it
catches his utterance and its timing. These condi-
tions are true for systems from the third category
which make it possible for them to integrate these
features.
Incremental dialogue systems can sometimes
detect desynchronisations before the user has fin-
ished his utterance. Therefore, the dialogue would
take less time if the system can interrupt the user
asking him to repeat his request. Feedbacks are
also a form of interrupt as it is the case for Dic-
taNum because they are uttered after a short si-
104
Features Category 1 Category 2 Category 3 Category 4
TTS interruption after input analysis - + + +
Link interruption time with TTS - + + +
User interruption by the system - - + +
Better reactivity - - + +
Optimal processing cost - - - +
Figure 1: Available features for dialogue systems given the way they integrate incrementality
lence (micro-silence). These features can only be
implemented in systems from the third and the
fourth group, as for the the first two ones, the sys-
tem is only requested at the end of a user?s utter-
ance.
As far as reactivity is concerned, systems from
the third and the fourth category process the user?s
request every time that a new increment is pushed
into the system. Therefore, when the end of the
request is detected (long enough silence), the ser-
vice?s response is already ready and can be de-
livered immediately. On the other hand, systems
from group 1 and 2 wait until the end of the user?s
utterance to send the request to the service, hence,
being less reactive. However, systems from the
third group work on a restart incremental, repro-
cessing the whole request at each new increment.
On the contrary, systems from the fourth cate-
gory can process the request increment by incre-
ment hence optimizing the processing cost. Some-
times, a new increment can modify the whole re-
quest (or a part of it) and those systems are de-
signed to handle this too by canceling some pre-
vious processing (revoke mechanism (Schlangen
and Skantze, 2011)). While integrating incremen-
tality in CFAsT and DictaNum, we noticed that
the system responded so quickly that no efforts are
necessary to optimise the processing time. How-
ever, systems from the fourth group can make the
difference if the system needs to process tasks that
create a delay (slow access to a remote database
for example).
In our method, the service is not modified in a
functional level (except from the double context
management). However, as it is the case for Dic-
taNum, some modifications at the applicative level
might be compulsory. The Scheduler is not sup-
posed to generate messages by himself or to per-
form traditional dialogue management tasks. As
a consequence, when one needs to add some new
feedback messages at the micro-turn level or the
possibility to correct an utterance, these features
must be implemented in the service.
Finally, in order for the Scheduler to decide
when to commit and when to take the floor in
an optimal way, it might need information com-
ing from the back-end modules. Once again, this
should be handled in the applicative level. A fu-
ture paper, focused on how to implement systems
using the Scheduler, will cover the ideas briefly
described in the last two paragraphs.
6 Conclusion and future work
This paper describes a method for transforming
a traditional dialogue system into an incremen-
tal one. The Scheduler is an intermediate mod-
ule that is inserted between the client and the ser-
vice. From the client?s point of view, the system?s
behaviour is incremental despite the fact that the
service works in a traditional turn-taking manner.
Most requests that are sent by the Scheduler to the
service are aimed to see what would be the answer
if the current request hypothesis is the final one.
In this case, the service?s context should not be
modified. Therefore, two context have to be main-
tained: the real context and the simulated one.
This solution has been implemented in the case
of a textual dialogue system generated by the
CFAsT application. It helps the user navigate
through the NIPS 2013 proceedings titles. It has
also been used to make a vocal system incremen-
tal: DictaNum. This service asks the users to dic-
tate a number and confirms that it has been well
understood.
In the future, we will explore how to make the
Scheduler learn when to commit the current re-
quest hypothesis and when to take the floor. We
will use reinforcement learning to figure out the
optimal strategies.
105
References
James Allen, George Ferguson, and Amanda Stent.
2001. An architecture for more realistic conversa-
tional systems. In 6th international conference on
Intelligent user interfaces.
Timo Baumann and David Schlangen. 2013. Open-
ended, extensible system utterances are preferred,
even if they require filled pauses. In Proceedings
of the SIGDIAL 2013 Conference.
Catherine Breslin, Milica Gasic, Matthew Henderson,
Dongho Kim, Martin Szummer, Blaise Thomson,
Pirros Tsiakoulis, and Steve Young. 2013. Con-
tinuous asr for flexible incremental dialogue. In
ICASSP, pages 8362?8366.
Sarah Brown-Schmidt and Joy E. Hanna. 2011.
Talking in another person?s shoes: Incremental
perspective-taking in language processing. Dia-
logue and Discourse, 2:11?33.
Herbert H. Clark. 1996. Using Language. Cambridge
University Press.
David DeVault, Kenji Sagae, and David Traum. 2011.
Incremental interpretation and prediction of utter-
ance meaning for interactive dialogue. Dialogue
and Discourse, 2:143?170.
Kohji Dohsaka and Akira Shimazu. 1997. A system
architecture for spoken utterance production in col-
laborative dialogue. In IJCAI.
Jens Edlund, Joakim Gustafson, Mattias Heldner, and
Anna Hjalmarsson. 2008. Towards human-like
spoken dialogue systems. Speech Communication,
50:630?645.
Layla El Asri, Remi Lemonnier, Romain Laroche,
Olivier Pietquin, and Hatim Khouzaimi. 2014.
NASTIA: Negotiating Appointment Setting Inter-
face. In Proceedings of LREC.
Helen Hastie, Marie-Aude Aufaure, et al. 2013.
Demonstration of the parlance system: a data-driven
incremental, spoken dialogue system for interactive
search. In Proceedings of the SIGDIAL 2013 Con-
ference.
Zeynep Ilkin and Patrick Sturt. 2011. Active predic-
tion of syntactic information during sentence pro-
cessing. Dialogue and Discourse, 2:35?58.
Irene Langkilde, Marilyn Anne Walker, Jerry Wright,
Allen Gorin, and Diane Litman. 1999. Auto-
matic prediction of problematic human-computer di-
alogues in how may i help you? In ASRU99.
R. Laroche and G. Putois. 2010. D5.5: Advanced
appointment-scheduling system ?system 4?. Proto-
type D5.5, CLASSIC Project.
R. Laroche, G. Putois, et al. 2011. D6.4: Final evalua-
tion of classic towninfo and appointment scheduling
systems. Report D6.4, CLASSIC Project.
Romain Laroche. 2010. Raisonnement sur les incerti-
tudes et apprentissage pour les systemes de dialogue
conventionnels. Ph.D. thesis, Paris VI University.
Willem J. M. Levelt. 1989. Speaking: From Intention
to Articulation. Cambridge, MA: MIT Press.
Kenneth Lock. 1965. Structuring programs for mul-
tiprogram time-sharing on-line applications. In
AFIPS ?65 (Fall, part I) Proceedings of the Novem-
ber 30?December 1, 1965, fall joint computer con-
ference, part I.
Kyoko Matsuyama, Kazunori Komatani, Tetsuya
Ogata, and Hiroshi G. Okuno. 2009. Enabling a
user to specify an item at any time during system
enumeration ? item identification for barge-in-able
conversational dialogue systems ?. In Proceedings
of the INTERSPEECH 2009 Conference.
Gary M. Matthias. 2008. Incremental speech un-
derstanding in a multimodal web-based spoken di-
alogue system. Master?s thesis, Massachusetts Insti-
tute of Technology.
Antoine Raux and Maxine Eskenazi. 2008. Optimiz-
ing endpointing thresholds using dialogue features
in a spoken dialogue system. In SIGDIAL.
David Schlangen and Gabriel Skantze. 2011. A gen-
eral, abstract model of incremental dialogue pro-
cessing. Dialogue and Discourse, 2:83?111.
Ethan O. Selfridge, Iker Arizmendi, Peter A. Heeman,
and Jason D. Williams. 2012. Integrating incremen-
tal speech recognition and pomdp-based dialogue
systems. In Proceedings of the 13th Annual Meet-
ing of the Special Interest Group on Discourse and
Dialogue, July.
Ethan Selfridge, Iker Arizmendi, Peter Heeman, and
Jason Williams. 2013. Continuously predicting and
processing barge-in during a live spoken dialogue
task. In Proceedings of the SIGDIAL 2013 Confer-
ence.
Gabriel Skantze and David Schlangen. 2009. Incre-
mental dialogue processing in a micro-domain. In
ACL.
Michael K. Tanenhaus, Michael J. Spivey-Knowlton,
Kathleen M. Eberhard, and Julie C. Sedivy. 1995.
Integration of visual and linguistic information
in spoken language comprehension. Science,
268:1632?1634.
Mats Wir?n. 1992. Studies in Incremental Natural
Language Analysis. Ph.D. thesis, Link?ping Uni-
versity, Link?ping, Sweden.
Marcin Wlodarczak and Petra Wagner. 2013. Effects
of talk-spurt silence boundary thresholds on distri-
bution of gaps and overlaps. In INTERSPEECH
Proceedings.
106
Scheduler ServiceClient
Req(1,1)
Req(1,1)
Processing Resp(1,1)
Req(1,2)
rollback + Req(1,2)
Processing Resp(1,2)
Resp(1,1)
Resp(1,1)
Resp(1.2)
Resp(1,2)
signal_ETC
commit
Resp(1,2)
Req(2,1)
Req(2,1)
Processing Resp(2,1)Resp(2,1)
Resp(2,1)
Req(2,2)
rollback + Req(2,2)
Processing Resp(2,2)Resp(2,2)
Resp(2,2)
Req(2,3)
EndMicroTurnCond
EndTurnCond
ServiceReqCond
CommitCond
EndMicroTurnCond
EndMicroTurnCond
EndMicroTurnCond
EndMicroTurnCond
ServiceReqCond
ServiceReqCond
ServiceReqCond
Figure A.1: The scheduler sub-requests management (The streams in dashed lines are received by the
recuperation thread of the client).
Turn User sub-turn Input Real context Simulation context
T
1
T
1,U
1
Req
1
1
ctxt(T
0
) ctxt(T
0
+ T
1,U
1
)
T
1,U
2
Req
1
2
ctxt(T
0
) ctxt(T
0
+ T
1,U
2
)
... ... ctxt(T
0
) ...
T
1,U
n
1,U
Req
1
n
1,U
ctxt(T
0
) ctxt(T
0
+ T
1,U
n
1,U
)
COMMIT: ctxt(T
1
) = ctxt(T
0
+ T
1,U
n
1,U
)
T
2
T
2,U
1
Req
2
1
ctxt(T
1
) ctxt(T
1
+ T
2,U
1
)
... ... ctxt(T
1
) ...
Figure A.2: A double context: the real context and the simulation context.
107
