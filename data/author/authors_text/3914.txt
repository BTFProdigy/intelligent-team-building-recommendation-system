Construction of an Objective Hierarchy of Abstract Concepts           
via Directional Similarity  
Kyoko Kanzaki  Eiko Yamamoto Hitoshi Isahara 
Computational Linguistics Group, 
National Institute of Information and Communications 
Technology 
3-5 Hikari-dai, Seika-cho, Souraku-gun, Kyoto, Japan,  
{kanzaki, eiko, isahara}@nict.go.jp 
Qing Ma 
Faculty of Science  
and Technology 
Ryukoku University 
Seta, Otsu,520-2194, Japan 
qma@math.ryukoku.ac.jp
Abstract 
The method of organization of word mean-
ings is a crucial issue with lexical databases. 
Our purpose in this research is to extract word 
hierarchies from corpora automatically. Our 
initial task to this end is to determine adjec-
tive hyperonyms. In order to find adjective 
hyperonyms, we utilize abstract nouns. We 
constructed linguistic data by extracting se-
mantic relations between abstract nouns and 
adjectives from corpus data and classifying 
abstract nouns based on adjective similarity 
using a self-organizing semantic map, which 
is a neural network model (Kohonen 1995). 
In this paper we describe how to hierarchi-
cally organize abstract nouns (adjective hy-
peronyms) in a semantic map mainly using 
CSM. We compare three hierarchical organi-
zations of abstract nouns, according to CSM, 
frequency (Tf.CSM) and an alternative simi-
larity measure based on coefficient overlap, to 
estimate hyperonym relations between words. 
1. Introduction 
A lexical database is necessary for computers, 
and even humans, to fully understand a word's 
meaning because the lexicon is the origin of lan-
guage understanding and generation. Progress is 
being made in lexical database research, notably 
with hierarchical semantic lexical databases such 
as WordNet, which is used for NLP research 
worldwide.  
When compiling lexical databases, it is impor-
tant to consider what rules or phenomena should 
be described as lexical meanings and how these 
lexical meanings should be formalized and stored 
electronically. This is a common topic of discus-
sion in computational linguistics, especially in 
the domain of computational lexical semantics. 
The method of organization of word meanings 
is also a crucial issue with lexical databases. In 
current lexical databases and/or thesauri, abstract 
nouns indicating concepts are identified manually 
and words are classified in a top-down manner 
based on human intuition. This is a good way to 
make a lexical database for users with a specific 
purpose. However, word hierarchies based on 
human intuition tend to vary greatly depending 
on the lexicographer, and there is often dis-
agreement as to the make-up of the hierarchy. If 
we could find an objective method to organize 
word meanings based on real data, we would 
avoid this variability. 
Our purpose in this research is to extract word 
hierarchies from corpora automatically. Our ini-
tial task to this end is to determine adjective hy-
peronyms. In order to find adjective hyperonyms, 
we utilize abstract nouns. Past linguistic research 
has focused on classifying the semantic relation-
ship between abstract nouns and adjectives 
(Nemoto 1969, Takahashi 1975).  
We constructed linguistic data by extracting 
semantic relations between abstract nouns and 
adjectives from corpus data and classifying ab-
stract nouns based on adjective similarity using a 
self-organizing semantic map (SOM), which is a 
neural network model (Kohonen 1995). The rela-
tive proximity of words in the semantic map in-
dicates their relative similarity.  
In previous research, word meanings have 
been statistically modeled based on syntactic in-
formation derived from a corpus. Hindle (1990) 
used noun-verb syntactic relations, and Hatzivas-
siloglou and McKeown (1993) used coordinated 
adjective-adjective modifier pairs. These meth-
ods are useful for the organization of words deep 
within a hierarchy, but do not seem to provide a 
solution for the top levels of the hierarchy.  
To find an objective hierarchical word struc-
ture, we utilize the complementary similarity 
measure (CSM), which estimates a one-to-many 
relation, such as superordinate?subordinate rela-
tions (Hagita and Sawaki 1995, Yamamoto and 
Umemura 2002).  
In this paper we propose an automated method 
for constructing adjective hierarchies by connect-
ing strongly related abstract nouns in a top-down 
fashion within a semantic map, mainly using 
CSM. We compare three hierarchical organiza-
tions of abstract nouns, according to CSM, fre-
quency (Tf.CSM) and an alternative similarity 
measure based on coefficient overlap, to estimate 
hyperonym relations between words. 
2. Linguistic clues to extract adjective hy-
peronyms from corpora 
In order to automatically extract adjective hy-
peronyms we use syntactic and semantic relations 
between words.  
There is a good deal of linguistic research fo-
cused on the syntactic and semantic functions of 
abstract nouns, including Nemoto (1969), Taka-
hashi (1975), and Schmid (2000). Takahashi 
(1975) illustrated the sentential function of ab-
stract nouns with the following examples. 
a.  Yagi  wa  seishitsu  ga  otonashii. 
(goat) topic (nature) subject (gentle) 
        The nature of goats is gentle 
b.   Zou    wa   hana   ga     nagai. 
    (elephant) topic  (a nose) subject  (long) 
         The nose of an elephant is long 
He examined the differences in semantic func-
tion between ?seishitsu (nature)? in (a) and ?hana 
(nose)? in (b), and explained that ?seishitsu (na-
ture)? in (a) indicates an aspect of something, i.e., 
the goat, and ?hana (nose)? in (b) indicates part 
of something, i.e., the elephant. He recognized 
abstract nouns in (a) as a hyperonym of the at-
tribute that the predicative adjectives express. 
Nemoto (1969) identified expressions such as 
?iro ga akai (the color is red)? and ?hayasa ga 
hayai (the speed is fast)? as a kind of meaning 
repetition, or tautology.  
In this paper we define such abstract nouns 
that co-occur with adjectives as adjective hy-
peronyms. We semi-automatically extracted from 
corpora 365 abstract nouns used as this kind of 
head noun, according to the procedures described 
in Kanzaki et al (2000). We collected abstract 
nouns from two year's worth of articles from the 
Mainichi Shinbun newspaper, and extracted ad-
jectives co-occurring with abstract nouns in the 
manner of (a) above from 100 novels, 100 essays 
and 42 year's worth of newspaper articles, includ-
ing 11 year's worth of Mainichi Shinbun articles, 
10 year's worth of Nihon Keizai Shinbun (Japa-
nese economic newspaper) articles, 7 year's wor-
th of Sangyoukinyuuryuutsu Shinbun (an eco-
nomic newspaper) articles, and 14 year's worth of 
Yomiuri Shinbun articles. The total number of 
abstract noun types is 365, the number of adjec-
tive types is 10,525, and the total number of ad-
jective tokens is 35,173. The maximum number 
of co-occurring adjectives for a given abstract 
noun is 1,594. 
3. On the Self-Organizing Semantic Map  
3.1  Input data 
Abstract nouns are located in the semantic map 
based on the similarity of co-occurring adjectives 
after iteratively learning over input data. 
In this research, we focus on abstract nouns 
co-occurring with adjectives. In the semantic 
map, there are 365 abstract nouns co-occurring 
with adjectives. The similarities between the 365 
abstract nouns are determined according to the 
number of common co-occurring adjectives. We 
made a list such as the following. 
OMOI (feeling): ureshii (glad), kanashii (sad), 
shiawasena (happy), ? 
KIMOCHI (though): ureshii (glad), tanoshii (pleased), 
hokorashii (proud), ? 
KANTEN (viewpoint): igakutekina (medical), 
rekishitekina (historical), ... 
When two (or more) sets of adjectives with 
completely different characteristics co-occur with 
an abstract noun and the meanings of the abstract 
noun can be distinguished correspondingly, we 
treat them as two different abstract nouns. For 
example, the Japanese abstract noun ?men? is 
treated as two different abstract nouns with 
?men1? meaning ?one side (of the characteristics 
of someone or something)? and ?men2? meaning 
?surface?. The former co-occurs with ?gentle?, 
?kind? and so on. The latter co-occurs with 
?rough?, ?smooth? and so on. 
3.2  The Self-Organizing Semantic Map 
Ma (2000) classified co-occurring words using 
a self-organizing semantic map (SOM). 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
We made a semantic map of the above-
mentioned 365 abstract nouns using SOM, based 
on the cosine measure. The distribution of the 
words in the map gives us a sense of the semantic 
distribution of the words. However, we could not 
precisely identify the relations between words in 
the map (Fig 1). In Fig. 1 lines on the maps indi-
cate close relations between word pairs. In the 
cosine-based semantic map, there is no clear cor-
respondence between word similarities and the 
distribution of abstract nouns in the map.    
To solve this problem we introduced the 
complementary similarity measure (CSM). This 
similarity measure estimates one-to-many 
relations, such as superordinate?subordinate 
relations (Hagita and Sawaki 1995, Yamamoto 
and Umemura 2002). We can find the 
hierarchical distribution of words in the semantic 
map according to the value of CSM (Fig 2). In 
the CSM-based SOM, lines are concentrated at 
the bottom right hand corner, that is, most ab-
stract nouns are located at the bottom right-hand 
corner.  
Next, we find hierarchical relations between 
whole abstract nouns, not between word pairs, on 
the map automatically. 
4. How to construct hierarchies of nominal 
adjective hyperonyms in the Semantic 
Map 
4.1 Similarity measures, CSM and Yates? 
correction 
A feature of CSM is its ability to estimate hi-
erarchical relations between words. This similar-
ity measure was developed for the recognition of 
degraded machine-printed text (Hagita and Sa-
waki, 1995). Yates? correction is often used in 
order to increase the accuracy of approximation. 
Hierarchical relations can be extracted accurately 
when the CSM value is high. Yates? correction 
can extract different relations from high CSM 
values. When the CSM value is low, the result is 
not reliable, in which case we use Yates? correc-
tion. 
According to Yamamoto and Umemura (2002), 
who adopted CSM to classify words, CSM is cal-
culated as follows. 
))(( dbca
bcadCSM
++
?
=  
Yates? correction is calculated as follows. 
))()()((
)2/|(| 2
dbcadcba
nbcadnYates
++++
??
=  
Here n is the sum of the number of co-
occurring adjectives; a indicates the number of 
times the two labels appear together; b indicates 
the number of times ?label 1? occurs but ?label 
2? does not; c is the number of times ?label 2? 
occurs but ?label 1? does not; and d is the num-
ber of times neither label occurs. In our research, 
each ?label? is an abstract noun, a indicates the 
number of adjectives co-occurring with both ab-
stract nouns, b and c indicate the number of ad-
jectives co-occurring with either abstract noun 
Figure 1. The Cosine-based SOM of word similarity Figure 2. The CSM-based SOM of word similarity
(?label 1? and ?label 2?, respectively), and d in-
dicates the number of adjectives co-occurring 
with neither abstract noun. We calculated hierar-
chical relations between word pairs using these 
similarity measures. 
4.2 Construction of a hierarchy of abstract 
nouns using CSM and Yates' correc-
tion 
The hierarchy construction process is as fol-
lows: 
1) Based on the results of CSM, ?koto (mat-
ter)? is the hyperonym of all abstract nouns. 
First, we connect super/sub-ordinate words 
with the highest CSM value while keeping the 
super-subordinate relation.  
2) When the normalized value of CSM is 
lower, the number of extracted word pairs be-
comes increasing overwhelmingly, and the reli-
ability of CSM diminishes. Word pairs with a 
normalized CSM value of less than 0.4 are lo-
cated far from the common hyperonym ?koto 
(matter)? on the semantic map. If we construct a 
hierarchy using CSM values only, a long hierar-
chy containing irrelevant words emerges. In this 
case, the word pairs calculated by Yates' correc-
tion are more accurate than those from CSM. We 
combine words using Yates? correction, when the 
value of CSM is less than 0.4. When we connect 
word pairs with a high Yates? value, we find a 
hyperonym of the super-ordinate noun of the pair 
and connect the pair to the hyperonym. If a word 
pair appears only in the Yates' correction data, 
that is, we cannot connect the pair with high 
Yates? value to the hyperonym with high CSM 
value, they are combined with ?koto (matter)?. 
3) Finally, if a short hierarchy is contained in a 
longer hierarchy, it is merged with the longer 
hierarchy and we insert ?koto (matter)? at the 
root of all hierarchies. 
4.3  Results 
The number of groups obtained was 161. At its 
deepest, the hierarchy was 15 words deep, and at 
its shallowest, it was 4 words deep. The 
following is a breakdown of the number of 
groups at different depths in the hierarchy.  
The greatest concentration of groups is at 
depth 7. There are 140 groups from depth 5 to 
depth 10, which is 87% of all groups. 
 
 
 
 
 
 
 
The word that has the strongest relation with 
?koto (matter)? is ?men1 (side1)?. The number of 
groups in which ?koto (matter)? and ?men1 
(side1)? are hyperonyms is 96 (59.6%). The larg-
est number of groups after that is a group in 
which ?koto (matter)?, ?men1 (side1)? and 
?imeeji (image)? are hyperonyms. The number of 
groups in this case is 59 groups, or 36.6% of the 
total. With respect to the value of CSM, the co-
occurring adjectives are similar to ?men1 (side1)? 
and ?imeeji (image)?.  
Other words that have a direct relation with 
?koto (matter)? are ?joutai (state)? and ?toki 
(when)?. They have the most number of groups 
after ?men1 (side1)? among all the children of 
?koto (matter)?. The number of groups subsumed 
by ?joutai (state)? group and ?toki (when)? are 21 
and 19, respectively. Other direct hyponyms of 
?koto (matter)? are: 
ki (feeling): 6 groups  
ippou (while or grow ?er and er): 3 groups  
me2 (eyes): 3 groups  
katachi1 (in the form of): 3 groups  
iikata (how to say): 2 groups  
yarikata (how to): 2 groups 
There is little hierarchical structure to these 
groups, as they co-occur with few adjectives. 
4.4 The Hierarchies of abstract concepts in 
the semantic map 
In the following semantic maps, where abstract 
nouns are distributed using SOM and CSM (see 
Section 3), hierarchies of abstract nouns are 
drawn with lines. The bottom right hand corner is 
?koto (matter)?, a starting point for the distribu-
tion of abstract nouns.  
Five main types of hierarchies are found from 
patterns of lines on the map, as follows: 
The first figure, Fig.3, is hierarchies of ?kanji 
(feeling), kimochi (feeling) ?? on the semantic 
map. The location of hierarchies of ?yousu (as-
pect), omomochi (look), kaotsuki (on one?s face), 
?? is similar to this type of the location. Hierar-
chies of ?sokumen (one side), imi (meaning), 
kanten (viewpoint),  kenchi (standpoint) ?? on 
Depth 4 5 6 7 8 9 
Groups 3 16 27 32 23 23 
Depth 10 11 12 13 14 15 
Groups 19 7 3 4 3 1 
Table 1: The depth of the hierarchy by CSM
  
 
 
 
 
 
the map are shown in Fig. 4. The lines of the hi-
erarchies go up from the bottom right hand cor-
ner to the upper left hand corner and then turn 
towards the upper right hand corner. The loca-
tion of hierarchies of ?nouryoku (ability), sainou 
(talent) ?? is similar to this one. 
The hyperonym of ?teido (degree)? is ?joutai 
(state)?. In Fig.5 these abstract nouns are located 
at the bottom of the map. The location of hierar-
chies of ?kurai (rather than)? and ?hou (compara-
tively)? are similar to this one. The hierarchies of 
?joutai (state), joukyou (situation), yousou (as-
pect), jousei (the state of affairs)? are shown in 
Fig.6. The lines are found at a higher location 
than the line of ?teido(degree)?. The lines of the 
hierarchies of ?joutai (state), ori (when), sakari 
(in the hight of), sanaka (while)? are similar to 
these lines. 
The lines of the hierarchies of ?seikaku (char-
acter)?, ?gaikan (appearance)?and ?utsukushisa 
(beauty)? are similar to each other. We show the 
hierarchies of ?seikaku (character)? in Fig.7. The-
se lines in Fig.7 are located from the right end to 
the upper left hand corner. From the following, 
we can find five main types of hierarchies. 
From the starting point ? koto (matter)?, 
-The hierarchies of ?men (side), inshou (impres-
sion), kanji (feeling), kibun (mood), kimochi 
(feeling)? 
-The hierarchies of ?men (side), sokumen (one- 
side), imi (meaning), kanten (viewpoint), kenchi 
(standpoint)? 
-The hierarchies of ?joutai (state), teido (degree)? 
-The hierarchies of ?joutai (state), jousei (situa-
tion)?  
-The hierarchies of ?men (side), inshou (impres-
sion), seikaku (character) or gaikan (appear-
ance) or utsukushisa (beauty)?.  
The lines in Fig.8 are not peculiar, and appear 
in an area of the hierarchies of ?seikaku (charac-
Fig.3: Hierarchies of  
?kimochi (feeling)? 
Fig.4:Hierarchies of 
?sokumen (one side)? 
Fig.5:Hierarchies of 
?teido (degree)? 
Fig8: Hierarchies of 
?kanshoku (feel)? 
Fig.6:  Hierarchies of  
?jousei (situation)? 
Fig.7:Hierarchies of 
?seikaku (character)? 
ter)? in Fig.7. As Fig.8 shows, the hierarchies of 
?men (side), inshou (impression), kanji (feeling), 
kanshoku (feel) or kansei (sensitivity)? are lo-
cated in the area of the hierarchies of ?seikaku 
(character)?, above the hierarchies of ?kimochi 
(feeling)? in Fig.3. 
5. Comparison of hierarchies of super-
ordinate nouns of adjectives. 
We compare the hierarchy mentioned above 
with ones obtained from two kinds of data. 
1) Hierarchies obtained by: 
CSM and Yate?s correction 
corpus occurrence data (no frequency). 
2) Hierarchies obtained by: 
Tf.CSM and Yate?s correction 
corpus frequency data. 
3) Hierarchies obtained by: 
Overlap coefficient and Yates' correction 
corpus occurrence data (no frequency). 
 
As both CSM and the Overlap coefficient are 
?measures of inclusion?, we compared CSM and 
Tf.CSM with the Overlap coefficient. 
The number of groups that were obtained by 
CSM, Tf.CSM and the Overlap coefficient are 
the following. 
Table 2. Total number of groups obtained from CSM, 
Tf.CSM and Ovlp (Overlap) 
 groups 
CSM 161 
Tf.CSM 158 
Ovlp 240 
The Depth of hierarchies obtained from CSM, 
Tf.CSM, and the Overlap coefficient are as fol-
lows: 
Table 3. The hierarchy depth for CSM, Tf.CSM,  
and the Overlap coefficient 
 
In the case of CSM, there are 32 groups at 
depth 7, which is the greatest number of groups. 
The greatest concentration of groups is at depth 5 
to 10. In the case of Tf.CSM, the greatest number 
of groups is 25 at depth 8. The greatest concen-
tration of groups is at depth 5 to 13. In the case of 
the overlap coefficient, the greatest number of 
groups is 61 at depth 5. The greatest concentra-
tion of groups is at depth 3 to 7. 
0
10
20
30
40
50
60
70
3 4 5 6 7 8 9 10 11 12 13 14 15
CSM
Tf.CSM
Ovlp
 
 
 
From this result, we can see that hierarchies 
generated by Tf.CSM are relatively deep, and 
those generated by the Overlap coefficient are 
relatively shallow.  
In the case of the Overlap coefficient, abstract 
nouns in lower layers are sometimes directly re-
lated to abstract nouns in the highest layers. On 
the other hand, in hierarchies generated by CSM 
and Tf.CSM, abstract nouns in the highest layers 
are related to those in the lowest layers via ab-
stract nouns in the middle layers. The following 
indicates the number of overlapping hierarchies 
for CSM, Tf.CSM and Overlap. 
Table 4. The number of overlapping hierarchies 
among CSM, Tf.CSM and Overlap 
CSM&Tf.CSM 37 
CSM&Ovlp 7 
Tf.CSM&Ovlp 2 
CSM&Tf.CSM&Ovlp 7 
The hierarchy generated by Tf.CSM is the 
deepest, and includes some hierarchies generated 
by CSM and the Overlap coefficient. The hierar-
chy generated by CSM is more similar to the one 
made by Tf.CSM than that for the Overlap coef-
ficient: the number of completely corresponding 
hierarchies for CSM and Tf.CSM is 37, that for 
CSM and the Overlap coefficient is 7, and that 
for Tf.CSM and the Overlap coefficient is 2. The 
total number of hierarchies that correspond com-
pletely between CSM, Tf.CSM and the Overlap 
coefficient is 7, and the number of hierarchies 
which are generated by two of the methods and 
included in the third is 57. 
depth 3 4 5 6 7 8 9
CSM 0 3 16 27 32 23 23
Tf.CSM 1 5 10 18 13 25 11
Ovlp 32 56 61 57 21 7 2
depth 10 11 12 13 14 15 
CSM 19 7 3 4 3 1 
Tf.CSM 24 13 14 14 7 2 
Ovlp 2 0 0 0 0 0 
Figure 9. Distribution of hierarchy depth for CSM, 
Tf.CSM, and Overlap coefficient 
We investigated these 64 hierarchies precisely, 
checking adjectives appearing at each depth as 
indicated by an abstract noun in this paper.  In 6 
of these hierarchies, the same adjectives were 
found at all levels of the hierarchy. In 14 of the 
remaining 58 hierarchies, the same adjectives 
were found in all but the deepest level.  These 
20 hierarchies are the most plausible in the strict 
sense of the word. Below, we give examples of 
these hierarchies. In the next stage of this re-
search, we intend to investigate the remaining 44 
hierarchies to determine the reason for the differ-
ence in adjective content. 
The common hyperonym: koto (matter) --- 
men1 (side) --- 
sokumen (one side) --- 
imi (meaning) --- 
kanten (viewpoint) --- 
me2 (eyes) --- 
mikata (view) --- 
hyouka (evaluation) --- 
ippou (while or grow -er and er) --- 
ikioi (force) --- 
sokudo (speed) --- 
jikoku (time) --- 
6. Conclusion 
We have suggested how to make a hierarchy 
of adjectives automatically by connecting 
strongly-related abstract nouns in a top-down 
fashion. We generated a word hierarchy from 
corpus data by using a combination of two 
methods: a self-organizing semantic map and a 
directional similarity measure. As our directional 
similarity measure, we utilized the complement-
ary similarity measure (CSM). Then we com-
pared the hierarchy generated by CSM with that 
generated by Tf.CSM and the Overlap coefficient. 
In the case of Tf.CSM, the hierarchy is deeper 
than the others because there are more abstract 
nouns in the middle layer. In the case of the 
Overlap coefficient, the hierarchy is shallow, but 
there are more hyponyms in the lower layer than 
with the other two methods. As a result, the 
hierarchies generated by CSM have more com-
mon hierarchical relations than those generated 
by the other two methods. In future work, we will 
analyze common hierarchies made by the three 
methods in detail and examine differences among 
them in order to generate an abstract conceptual 
hierarchy of adjectives. We will then compare 
our hierarchy with thesauri compiled manually. 
After we have completed the experiment on Jap-
anese adjectives, we are keen to investigate dif-
ferences and similarities in adjective hypero-
nyms between Japanese and other languages such 
as English by means of our method. 
Acknowledgement 
We would like to thank Dr. Masaki Murata of 
NICT for allowing us to use his drawing tool. 
References  
Nemoto, K. 1969. The combination of the noun with 
?ga-Case? and the adjective, Language research2 
for the computer, National Language Research In-
stitute: 63-73/ 
Takahashi, T. 1975. A various phase related to the 
part-whole relation investigated in the sentence, 
Studies in the Japanese language 103, The society 
of Japanese Linguistics: 1-16. 
Kohonen, T. 1995. Self-Organizing Maps, Springer. 
Hindle, D. 1990. Noun Classification From Predicate-
Argument Structures, In the Proceedings of the 28th 
Annual Meeting of the Association for Computa-
tional Linguistics: 268-275 
Hatzivassiloglou,V. and McKeown,R.K. 1993. To-
wards the Automatic Identification of Adjectival 
Scales: Clustering Adjectives According to Mean-
ing, In the Proceedings of the 31st Annual Meeting 
of the Association for Computational Linguistics: 
172-182.  
Hagita, N. and Sawaki, M. 1995. Robust Recognition 
of Degraded Machine-Printed Characters using 
Complimentary Similarity Measure and Error-
Correction Learning?In the Proceedings of the 
SPIE ?The International Society for Optical Engi-
neering, 2442: 236-244. 
Yamamoto, E. and Umemura, K. 2002. A Similarity 
Measure for estimation of One?to-Many Relation-
ship in Corpus, Journal of Natural Language Proc-
essing: 45-75.  
Hans-Jorg Shmid. 2000. English Abstract Nouns as 
Conceptual Shells, Mouton de Gruyter. 
Kanzaki, K., Ma., Q. and Isahara, H. (2000), Similari-
ties and Differences among Semantic Behaviors of 
Japanese Adnominal Constituents, In the Proceed-
ings of the Syntactic and Semantic Complexity in 
Natural Language Processing Systems, ANLP and 
NAACL. 
Ma, Q., Kanzaki, K., Murata, M., Uchimoto, K. and 
Isahara, H. 2000. Self-Organization Semantic Maps 
of Japanese Noun in Terms of Adnominal Constitu-
ents, In Proceedings of IJCNN?2000, Como, Italy, 
vol.6.: 91-96. 
Proceedings of HLT/EMNLP 2005 Demonstration Abstracts, pages 26?27,
Vancouver, October 2005.
Japanese Speech Understanding Using Grammar Specialization
Manny Rayner, Nikos Chatzichrisafis, Pierrette Bouillon
University of Geneva, TIM/ISSCO
40 bvd du Pont-d?Arve, CH-1211 Geneva 4, Switzerland
mrayner@riacs.edu
{Pierrette.Bouillon,Nikolaos.Chatzichrisafis}@issco.unige.ch
Yukie Nakao, Hitoshi Isahara, Kyoko Kanzaki
National Institute of Information and Communications Technology
3-5 Hikaridai, Seika-cho, Soraku-gun, Kyoto, Japan 619-0289
yukie-n@khn.nict.go.jp, {isahara,kanzaki}@nict.go.jp
Beth Ann Hockey
UCSC/NASA Ames Research Center
Moffet Field, CA 94035
bahockey@riacs.edu
Marianne Santaholma, Marianne Starlander
University of Geneva, TIM/ISSCO
40 bvd du Pont-d?Arve
CH-1211 Geneva 4, Switzerland
Marianne.Santaholma@eti.unige.ch
Marianne.Starlander@eti.unige.ch
The most common speech understanding archi-
tecture for spoken dialogue systems is a combination
of speech recognition based on a class N-gram lan-
guage model, and robust parsing. For many types
of applications, however, grammar-based recogni-
tion can offer concrete advantages. Training a
good class N-gram language model requires sub-
stantial quantities of corpus data, which is gen-
erally not available at the start of a new project.
Head-to-head comparisons of class N-gram/robust
and grammar-based systems also suggest that users
who are familiar with system coverage get better re-
sults from grammar-based architectures (Knight et
al., 2001). As a consequence, deployed spoken dia-
logue systems for real-world applications frequently
use grammar-based methods. This is particularly
the case for speech translation systems. Although
leading research systems like Verbmobil and NE-
SPOLE! (Wahlster, 2000; Lavie et al, 2001) usu-
ally employ complex architectures combining sta-
tistical and rule-based methods, successful practical
examples like Phraselator and S-MINDS (Phrasela-
tor, 2005; Sehda, 2005) are typically phrasal trans-
lators with grammar-based recognizers.
Voice recognition platforms like the Nuance
Toolkit provide CFG-based languages for writing
grammar-based language models (GLMs), but it is
challenging to develop and maintain grammars con-
sisting of large sets of ad hoc phrase-structure rules.
For this reason, there has been considerable inter-
est in developing systems that permit language mod-
els be specified in higher-level formalisms, normally
some kind of unification grammar (UG), and then
compile these grammars down to the low-level plat-
form formalisms. A prominent early example of this
approach is the Gemini system (Moore, 1998).
Gemini raises the level of abstraction signifi-
cantly, but still assumes that the grammars will be
domain-dependent. In the Open Source REGULUS
project (Regulus, 2005; Rayner et al, 2003), we
have taken a further step in the direction of increased
abstraction, and derive all recognizers from a sin-
gle linguistically motivated UG. This derivation pro-
cedure starts with a large, application-independent
UG for a language. An application-specific UG is
then derived using an Explanation Based Learning
(EBL) specialization technique. This corpus-based
specialization process is parameterized by the train-
ing corpus and operationality criteria. The training
corpus, which can be relatively small, consists of ex-
amples of utterances that should be recognized by
the target application. The sentences of the corpus
are parsed using the general grammar, then those
parses are partitioned into phrases based on the op-
erationality criteria. Each phrase defined by the
operationality criteria is flattened, producing rules
of a phrasal grammar for the application domain.
This application-specific UG is then compiled into
26
a CFG, formatted to be compatible with the Nuance
recognition platform. The CFG is compiled into the
runtime recognizer using Nuance tools.
Previously, the REGULUS grammar specialization
programme has only been implemented for English.
In this demo, we will show how we can apply the
same methodology to Japanese. Japanese is struc-
turally a very different language from English, so it
is by no means obvious that methods which work
for English will be applicable in this new context:
in fact, they appear to work very well. We will
demo the grammars and resulting recognizers in the
context of Japanese ? English and Japanese ?
French versions of the Open Source MedSLT medi-
cal speech translation system (Bouillon et al, 2005;
MedSLT, 2005).
The generic problem to be solved when building
any sort of recognition grammar is that syntax alone
is insufficiently constraining; many of the real con-
straints in a given domain and use situation tend to
be semantic and pragmatic in nature. The challenge
is thus to include enough non-syntactic constraints
in the grammar to create a language model that can
support reliable domain-specific speech recognition:
we sketch our solution for Japanese.
The basic structure of our current general
Japanese grammar is as follows. There are four main
groups of rules, covering NP, PP, VP and CLAUSE
structure respectively. The NP and PP rules each as-
sign a sortal type to the head constituent, based on
the domain-specific sortal constraints defined in the
lexicon. VP rules define the complement structure
of each syntactic class of verb, again making use of
the sortal features. There are also rules that allow
a VP to combine with optional adjuncts, and rules
which allow null constituents, in particular null sub-
jects and objects. Finally, clause-level rules form a
clause out of a VP, an optional subject and optional
adjuncts. The sortal features constrain the subject
and the complements combining with a verb, but the
lack of constraints on null constituents and optional
adjuncts still means that the grammar is very loose.
The grammar specialization mechanism flattens the
grammar into a set of much simpler structures, elim-
inating the VP level and only permitting specific pat-
terns of null constituents and adjuncts licenced by
the training corpus.
We will demo several different versions of the
Japanese-input medical speech translation system,
differing with respect to the target language and
the recognition architecture used. In particular, we
will show a) that versions based on the specialized
Japanese grammar offer fast and accurate recogni-
tion on utterances within the intended coverage of
the system (Word Error Rate around 5%, speed un-
der 0.1?RT), b) that versions based on the original
general Japanese grammar are much less accurate
and more than an order of magnitude slower.
References
P. Bouillon, M. Rayner, N. Chatzichrisafis, B.A. Hockey,
M. Santaholma, M. Starlander, Y. Nakao, K. Kanzaki,
and H. Isahara. 2005. A generic multi-lingual open
source platform for limited-domain medical speech
translation. In In Proceedings of the 10th Conference
of the European Association for Machine Translation
(EAMT), Budapest, Hungary.
S. Knight, G. Gorrell, M. Rayner, D. Milward, R. Koel-
ing, and I. Lewin. 2001. Comparing grammar-based
and robust approaches to speech understanding: a case
study. In Proceedings of Eurospeech 2001, pages
1779?1782, Aalborg, Denmark.
A. Lavie, C. Langley, A. Waibel, F. Pianesi, G. Lazzari,
P. Coletti, L. Taddei, and F. Balducci. 2001. Ar-
chitecture and design considerations in NESPOLE!:
a speech translation system for e-commerce applica-
tions. In Proceedings of HLT: Human Language Tech-
nology Conference, San Diego, California.
MedSLT, 2005. http://sourceforge.net/projects/medslt/.
As of 9 June 2005.
R. Moore. 1998. Using natural language knowledge
sources in speech recognition. In Proceedings of the
NATO Advanced Studies Institute.
Phraselator, 2005. http://www.phraselator.com/. As of 9
June 2005.
M. Rayner, B.A. Hockey, and J. Dowding. 2003. An
open source environment for compiling typed unifica-
tion grammars into speech recognisers. In Proceed-
ings of the 10th EACL (demo track), Budapest, Hun-
gary.
Regulus, 2005. http://sourceforge.net/projects/regulus/.
As of 9 June 2005.
Sehda, 2005. http://www.sehda.com/. As of 9 June 2005.
W. Wahlster, editor. 2000. Verbmobil: Foundations of
Speech-to-Speech Translation. Springer.
27
Hierarchy Extraction based on Inclusion of Appearance  
Eiko Yamamoto Kyoko Kanzaki Hitoshi Isahara 
Computational Linguistics Group, 
National Institute of Information and Communications Technology 
3-5 Hikari-dai, Seika-cho, Soraku-gun, Kyoto, 619-0289, Japan. 
eiko@nict.go.jp kanzaki@nict.go.jp isahara@nict.go.jp 
 
Abstract 
In this paper, we propose a method of auto-
matically extracting word hierarchies based on 
the inclusion relation of appearance patterns 
from corpora. We apply a complementary 
similarity measure to find a hierarchical word 
structure. This similarity measure was devel-
oped for the recognition of degraded machine-
printed text in the field and can be applied to 
estimate one-to-many relations. Our purpose is 
to extract word hierarchies from corpora 
automatically. As the initial task, we attempt 
to extract hierarchies of abstract nouns co-
occurring with adjectives in Japanese and 
compare with hierarchies in the EDR elec-
tronic dictionary.  
1 Introduction 
The hierarchical relations of words are useful as 
language resources. Hierarchical semantic lexical 
databases such as WordNet (Miller et al, 1990) 
and the EDR electronic dictionary (1995) are used 
for NLP research worldwide to fully understand a 
word meaning. In current thesauri in the form of 
hierarchical relations, words are categorized manu-
ally and classified in a top-down manner based on 
human intuition. This is a good way to make a 
lexical database for users having a specific purpose. 
However, word hierarchies based on human intui-
tion tend to vary greatly depending on the lexicog-
rapher. In addition, hierarchical relations based on 
various data may be needed depending on each 
user.  
Accordingly, we try to extract a hierarchical re-
lation of words automatically and statistically. In 
previous research, ways of extracting from defini-
tion sentences in dictionaries (Tsurumaru et al, 
1986; Shoutsu et al, 2003) or from a corpus by 
using patterns such as ?a part of?, ?is-a?, or ?and? 
(Berland and Charniak, 1999; Caraballo, 1999) 
have been proposed. Also, there is a method that 
uses the dependence relation between words taken 
from a corpus (Matsumoto et al, 1996). In contrast, 
we propose a method based on the inclusion rela-
tion of appearance patterns from corpora. 
In this paper, to verify the suitability of our 
method, we attempt to extract hierarchies of ab-
stract nouns co-occurring with adjectives in Japa-
nese. We select two similarity measures to estimate 
the inclusion relation between word appearance 
patterns. One is a complementary similarity meas-
ure; i.e., a similarity measure developed for the 
recognition of degraded machine-printed text in the 
field (Hagita and Sawaki, 1995). This measure can 
be used to estimate one-to-many relations such as 
superordinate?subordinate relations from appear-
ance patterns (Yamamoto and Umemura, 2002). 
The second similarity measure is the overlap coef-
ficient, which is a similarity measure to calculate 
the rate of overlap between two binary vectors. 
Using each measure, we extract hierarchies from a 
corpus. After that, we compare these with the EDR 
electronic dictionary. 
2 Experiment Corpus 
A good deal of linguistic research has focused on 
the syntactic and semantic functions of abstract 
nouns (Nemoto, 1969; Takahashi, 1975; Schmid, 
2000; Kanzaki et al, 2003). In the example, ?Yagi 
(goat) wa seishitsu (nature) ga otonashii (gentle) 
(The nature of goats is gentle).?, Takahashi (1975) 
recognized that the abstract noun ?seishitsu (na-
ture)? is a hypernym of the attribute that the predi-
cative adjective ?otonashi (gentle)? expresses. 
Kanzaki et al (2003) defined such abstract nouns 
that co-occur with adjectives as adjective hy-
pernyms, and extracted these co-occurrence rela-
tions between abstract nouns and adjectives from 
many corpora such as newspaper articles. In the 
linguistic data, there are sets of co-occurring 
adjectives for each abstract noun ? the total num-
ber of abstract noun types is 365 and the number of 
adjective types is 10,525. Some examples are as 
follows.  
OMOI  (feeling): ureshii (glad), kanashii (sad), 
shiawasena (happy), ? 
KANTEN (viewpoint): igakutekina (medical), 
rekishitekina (historical), ... 
3 Complementary Similarity Measure 
The complementary similarity measure (CSM) is 
used in a character recognition method for binary 
images which is robust against heavy noise or 
graphical designs (Sawaki and Hagita, 1996). Ya-
mamoto et al (2002) applied CSM to estimate one-
to-many relations between words. They estimated 
one-to-many relations from the inclusion relations 
between the appearance patterns of two words.  
The appearance pattern is expressed as an n-
dimensional binary feature vector. Now, let F = (f1, 
f2, ?, fn) and T = (t1, t2, ?, tn) (where fi, ti = 0 or 
1) be the feature vectors of the appearance patterns 
for a word and another word, respectively. The 
CSM of F to T is defined as 
dcban
tfdtfc
tfbtfa
dbca
bcadTFCSM
n
i ii
n
i ii
n
i ii
n
i ii
+++=
???=??=
??=?=
++
?=
??
??
==
==
,)1()1(,)1(
,)1(,
))((
),(
11
11
 
The CSM of F to T represents the degree to 
which F includes T; that is, the inclusion relation 
between the appearance patterns of two words.  
In our experiment, each ?word? is an abstract 
noun. Therefore, n is the number of adjectives in 
the corpus, a indicates the number of adjectives co-
occurring with both abstract nouns, b and c indi-
cate the number of adjectives co-occurring with 
either abstract noun, and d indicates the number of 
adjectives co-occurring with neither abstract noun. 
4 Overlap Coefficient 
The overlap coefficient (OVLP) is a similarity 
measure for binary vectors (Manning and Schutze, 
1999). OVLP is essentially a measure of inclusion. 
It has a value of 1.0 if every dimension with a non-
zero value for the first vector is also non-zero for 
the second vector or vice versa. In other words, the 
value is 1.0 when the first vector completely in-
cludes the second vector or vice versa. OVLP of F 
and T is defined as 
),(),(
),(
cabaMIN
a
TFMIN
TF
TFOVLP ++==
I
 
5 EDR hierarchy 
The EDR Electronic Dictionary (1995) was de-
veloped for advanced processing of natural lan-
guage by computers and is composed of eleven 
sub-dictionaries. The sub-dictionaries include a 
concept dictionary, word dictionaries, bilingual 
dictionaries, etc. We verify and analyse the hierar-
chies that are extracted based on a comparison with 
the EDR dictionary. However, the hierarchies in 
EDR consist of hypernymic concepts represented 
by sentences. On the other hand, our extracted hi-
erarchies consist of hypernyms such as abstract 
nouns. Therefore, we have to replace the concept 
composed of a sentence with the sequence of the 
words. We replace the description of concepts with 
entry words from the ?Word List by Semantic 
Principles? (1964) and add synonyms. We also add 
to abstract nouns in order to reduce any difference 
in representation. In this way, conceptual hierar-
chies of adjectives in the EDR dictionary are de-
fined by the sequence of words. 
6 Hierarchy Extraction Process 
The processes for hierarchy extraction from the 
corpus are as follows. ?TH? is a threshold value for 
each pair under consideration. If TH is low, we can 
obtain long hierarchies. However, if TH is too low, 
the number of word pairs taken into consideration 
increases overwhelmingly and the measurement 
reliability diminishes. In this experiment, we set 
0.2 as TH. 
1. Compute the similarity between appear-
ance patterns for each pair of words. The 
hierarchical relation between the two 
words in a pair is determined by the simi-
larity value. We express the pair as (X, Y), 
where X is a hypernym of Y and Y is a 
hyponym of X. 
2. Sort the pairs by the normalized similari-
ties and reduce the pairs where the simi-
larity is less than TH.  
3. For each abstract noun, 
A) Choose a pair (B, C) where word B is 
the hypernym with the highest value. 
The hierarchy between B and C is set 
to the initial hierarchy.  
B) Choose a pair (C, D) where hyponym 
D is not contained in the current hier-
archy and has the highest value in pairs 
where the last word of the current hier-
archy C is a hypernym. 
C) Connect hyponym D with the tail of 
the current hierarchy.  
D) While such a pair can be chosen, repeat 
B) and C). 
E) Choose a pair (A, B) where hypernym 
A is not contained in the current hier-
archy and has the highest value in pairs 
where the first word of the current hi-
erarchy B is a hypernym. 
F) Connect hypernym A with the head of 
the current hierarchy. 
G) While such a pair can be chosen, repeat 
E) and F). 
4. For the hierarchies that are built, 
A) If a short hierarchy is included in a 
longer hierarchy with the order of the 
words preserved, the short one is 
dropped from the list of hierarchies. 
B) If a hierarchy has only one or a few 
different words from another hierarchy, 
the two hierarchies are merged. 
7 Extracted Hierarchy 
Some extracted hierarchies are as follows. In our 
experiment, we get koto (matter) as the common 
hypernym.  
koto (matter) -- joutai (state) -- kankei (relation) 
-- kakawari (something to do with) -- tsukiai 
(have an acquaintance with) 
koto (matter) -- toki (when) -- yousu (aspect) -- 
omomochi (one?s face) -- manazashi (a look) -- 
iro (on one?s face) -- shisen (one?s eye) 
8 Comparison 
We analyse extracted hierarchies by using the 
number of nodes that agree with the EDR hierar-
chy. Specifically, we count the number of nodes 
(nouns) which agree with a word in the EDR hier-
archy, preserving the order of each hierarchy. Here, 
two hierarchies are ?A - B - C - D - E? and ?A - B 
- D - F - G.? They have three agreement nodes; ?A 
- B - D.?  
Table 1 shows the distribution of the depths of a 
CSM hierarchy, and the number of nodes that 
agree with the EDR hierarchy at each depth. Table 
2 shows the same for an OVLP one. ?Agreement 
Level? is the number of agreement nodes. The bold 
font represents the number of hierarchies com-
pletely included in the EDR hierarchy.  
8.1 Depth of Hierarchy 
The number of hierarchies made from the EDR 
dictionary (EDR hierarchy) is 932 and the deepest 
level is 14. The number of CSM hierarchies is 105 
and the depth is from 3 to 14 (Table 1). The num-
ber of OVLP hierarchies is 179 and the depth is 
from 2 to 9 (Table 2). These results show that 
CSM builds a deeper hierarchy than OVLP, though 
the number of hierarchies is less than OVLP. Also, 
the deepest level of CSM equals that of EDR. 
Therefore, comparison with the EDR dictionary is 
an appropriate way to verify the hierarchies that we 
have extracted.  
In both tables, we find most hierarchies have an 
agreement level from 2 to 4. The deepest agree-
ment level is 6. For an agreement level of 5 or bet-
ter, the OVLP hierarchy includes only two hierar-
chies while the CSM hierarchy includes nine hier-
archies. This means CSM can extract hierarchies 
having more nodes which agree with the EDR hi-
erarchy than is possible with OVLP.  
 
Depth of 
Hierarchy
Agreement Level 
  1        2        3       4       5       6  
3 1 4 1  
4 8 6 2 
5 9 8  1
6 8 9 4 1
7 2 6 1 1
8 1 5 2 2
9 3 2 3 1
10  1  2
11  4 1 
12  1  1
13  1  2
14    1
Table 1: Distribution of CSM hierarchy for each 
depth 
Depth of 
Hierarchy
Agreement Level 
1        2         3        4       5       6 
2 1   
3 2 8 1  
4 25 9 1 
5 24 13 7 
6 21 31 5 
7 5 12 1 1
8 3 5 2 1
9 1 3 1 
Table 2: Distribution of OVLP hierarchy for 
each depth 
Also, many abstract nouns agree with the hy-
peronymic concept around the top level. In current 
thesauri, the categorization of words is classified in 
a top-down manner based on human intuition. 
Therefore, we believe the hierarchy that we have 
built is consistent with human intuition, at least 
around the top level of hyperonymic concepts. 
9 Conclusion 
We have proposed a method of automatically ex-
tracting hierarchies based on an inclusion relation 
of appearance patterns from corpora. In this paper, 
we attempted to extract objective hierarchies of 
abstract nouns co-occurring with adjectives in 
Japanese. In our experiment, we showed that com-
plementary similarity measure can extract a kind of 
hierarchy from corpora, though it is a similarity 
measure developed for the recognition of degraded 
machine-printed text. Also, we can find interesting 
hierarchies which suit human intuition, though 
they are different from exact hierarchies. Kanzaki 
et al (2004) have applied our approach to verify 
classification of abstract nouns by using self-
organization map. We can look a suitability of our 
result at that work. 
In our future work, we will use our approach for 
other parts of speech and other types of word. 
Moreover, we will compare with current alterna-
tive approaches such as those based on sentence 
patterns.  
References  
Berland, M. and Charniak, E. 1999. Finding Parts 
in Very Large Corpora, In Proceedings of the 
37th Annual Meeting of the Association for Com-
putational Linguistics, pp.57-64. 
Caraballo, S. A. 1999. Automatic Construction of a 
Hypernym-labeled Noun Hierarchy from Text, 
In Proceedings of the 37th Annual Meeting of the 
Association for Computational Linguistics, 
pp.120-126. 
EDR Electronic Dictionary. 1995. 
 http://www2.nict.go.jp/kk/e416/EDR/index.html 
Hagita, N. and Sawaki, M. 1995. Robust Recogni-
tion of Degraded Machine-Printed Characters us-
ing Complementary Similarity Measure and Er-
ror-Correction Learning?In Proceedings of the 
SPIE ?The International Society for Optical En-
gineering, 2442: pp.236-244. 
Kanzaki, K., Ma, Q., Yamamoto, E., Murata, M., 
and Isahara, H. 2003. Adjectives and their Ab-
stract concepts --- Toward an objective thesaurus 
from Semantic Map. In Proceedings of the Sec-
ond International Workshop on Generative Ap-
proaches to the Lexicon, pp.177-184. 
Kanzaki, K., Ma, Q., Yamamoto, E., Murata, M., 
and Isahara, H. 2004. Extraction of Hyperonymy 
of Adjectives from Large Corpora by using the 
Neural Network Model. In Proceedings of the 
Fourth International Conference on Language 
Resources and Evaluation, Volume II, pp.423-
426. 
Kay, M. 1986. Parsing in Functional Unification 
Grammar. In ?Readings in Natural Language 
Processing?, Grosz, B. J., Spark Jones, K. and 
Webber, B. L., ed., pp.125-138, Morgan Kauf-
mann Publishers, Los Altos, California. 
Manning, C. D. and Schutze, H. 1999. Foundations 
of Statistical Natural Language Processing, The 
MIT Press, Cambridge MA. 
Matsumoto, Y. and Sudo, S., Nakayama, T., and 
Hirao, T. 1996. Thesaurus Construction from 
Multiple Language Resources, In IPSJ SIG 
Notes NL-93, pp.23-28 (In Japanese). 
Miller, A., Beckwith, R., Fellbaum, C., Gros, D., 
Millier, K., and Tengi, R. 1990. Five Papers on 
WordNet, Technical Report CSL Report 43, 
Cognitive Science Laboratory, Princeton Univer-
sity. 
Mosteller, F. and Wallace, D. 1964. Inference and 
Disputed Authorship: The Federalist. Addison-
Wesley, Reading, Massachusetts. 
Nemoto, K. 1969. The combination of the noun 
with ?ga-Case? and the adjective, Language re-
search2 for the computer, National Language 
Research Institute, pp.63-73 (In Japanese). 
Shmid, H-J. 2000. English Abstract Nouns as Con-
ceptual Shells, Mouton de Gruyter. 
Shoutsu, Y., Tokunaga, T., and Tanaka, H. 2003. 
The integration of Japanese dictionary and the-
saurus, In IPSJ SIG Notes NL-153, pp.141-146 
(In Japanese). 
Sparck Jones, K. 1972. A statistical interpretation 
of term specificity and its application in retrieval. 
Journal of Documentation, 28(1): pp.11-21. 
Takahashi, T. 1975. A various phase related to the 
part-whole relation investigated in the sentence, 
Studies in the Japanese language 103, The 
Society of Japanese Linguistics, pp.1-16 (In 
Japanese). 
Tsurumaru, H., Hitaka, T., and Yoshita, S. 1986. 
Automatic extraction of hierarchical relation be-
tween words, In IPSJ SIG Notes NL-83, pp.121-
128 (In Japanese). 
Yamamoto, E. and Umemura, K. 2002. A Similar-
ity Measure for Estimation of One?to-Many Re-
lationship in Corpus, In Journal of Natural Lan-
guage Processing, pp.45-75 (In Japanese). 
Word List by Semantic Principles. 1964. National 
Language Research Institute Publications, Shuei 
Shuppan (In Japanese). 
MedSLT: A Limited-Domain Unidirectional Grammar-Based Medical
Speech Translator
Manny Rayner, Pierrette Bouillon, Nikos Chatzichrisafis, Marianne Santaholma, Marianne Starlander
University of Geneva, TIM/ISSCO, 40 bvd du Pont-d?Arve, CH-1211 Geneva 4, Switzerland
Emmanuel.Rayner@issco.unige.ch
Pierrette.Bouillon@issco.unige.ch, Nikos.Chatzichrisafis@vozZup.com
Marianne.Santaholma@eti.unige.ch, Marianne.Starlander@eti.unige.ch
Beth Ann Hockey
UCSC/NASA Ames Research Center, Moffet Field, CA 94035
bahockey@email.arc.nasa.gov
Yukie Nakao, Hitoshi Isahara, Kyoko Kanzaki
National Institute of Information and Communications Technology
3-5 Hikaridai, Seika-cho, Soraku-gun, Kyoto, Japan 619-0289
yukie-n@khn.nict.go.jp, {isahara,kanzaki}@nict.go.jp
Abstract
MedSLT is a unidirectional medical
speech translation system intended for
use in doctor-patient diagnosis dialogues,
which provides coverage of several differ-
ent language pairs and subdomains. Vo-
cabulary ranges from about 350 to 1000
surface words, depending on the language
and subdomain. We will demo both the
system itself and the development envi-
ronment, which uses a combination of
rule-based and data-driven methods to
construct efficient recognisers, generators
and transfer rule sets from small corpora.
1 Overview
The mainstream in speech translation work is for the
moment statistical, but rule-based systems are still a
very respectable alternative. In particular, nearly all
systems which have actually been deployed are rule-
based. Prominent examples are (Phraselator, 2006;
S-MINDS, 2006; MedBridge, 2006).
MedSLT (MedSLT, 2005; Bouillon et al, 2005)
is a unidirectional medical speech translation system
for use in doctor-patient diagnosis dialogues, which
covers several different language pairs and subdo-
mains. Recognition is performed using grammar-
based language models, and translation uses a rule-
based interlingual framework. The system, includ-
ing the development environment, is built on top of
Regulus (Regulus, 2006), an Open Source platform
for developing grammar-based speech applications,
which in turn sits on top of the Nuance Toolkit.
The demo will show how MedSLT can be used
to carry out non-trivial diagnostic dialogues. In par-
ticular, we will demonstrate how an integrated intel-
ligent help system counteracts the brittleness inher-
ent in rule-based processing, and rapidly leads new
users towards the supported system coverage. We
will also demo the development environment, and
show how grammars and sets of transfer rules can be
efficiently constructed from small corpora of a few
hundred to a thousand examples.
2 The MedSLT system
The MedSLT demonstrator has already been exten-
sively described elsewhere (Bouillon et al, 2005;
Rayner et al, 2005a), so this section will only
present a brief summary. The main components are
a set of speech recognisers for the source languages,
a set of generators for the target languages, a transla-
tion engine, sets of rules for translating to and from
interlingua, a simple discourse engine for dealing
with context-dependent translation, and a top-level
which manages the information flow between the
other modules and the user.
MedSLT also includes an intelligent help mod-
ule, which adds robustness to the system and guides
the user towards the supported coverage. The help
module uses a backup recogniser, equipped with a
statistical language model, and matches the results
from this second recogniser against a corpus of utter-
ances which are within system coverage and trans-
late correctly. In previous studies, we showed that
the grammar-based recogniser performs much bet-
ter than the statistical one on in-coverage utterances,
but worse on out-of-coverage ones. Having the help
system available approximately doubled the speed
at which subjects learned, measured as the average
difference in semantic error rate between the results
for their first quarter-session and their last quarter-
session (Rayner et al, 2005a). It is also possible to
recover from recognition errors by selecting a dis-
played help sentence; this typically increases the
number of acceptably processed utterances by about
10% (Starlander et al, 2005).
We will demo several versions of the system, us-
ing different source languages, target languages and
subdomains. Coverage is based on standard exami-
nation questions obtained from doctors, and consists
mainly of yes/no questions, though there is also sup-
port for WH-questions and elliptical utterances. Ta-
ble 1 gives examples of the coverage in the English-
input headache version, and Table 2 summarises
recognition performance in this domain for the three
main input languages. Differences in the sizes of the
recognition vocabularies are primarily due to differ-
ences in use of inflection. Japanese, with little in-
flectional morphology, has the smallest vocabulary;
French, which inflects most parts of speech, has the
largest.
3 The development environment
Although the MedSLT system is rule-based, we
would, for the usual reasons, prefer to acquire these
rules from corpora using some well-defined method.
There is, however, little or no material available for
most medical speech translation domains, including
ours. As noted in (Probst and Levin, 2002), scarcity
of data generally implies use of some strategy to ob-
tain a carefully structured training corpus. If the cor-
pus is not organised in this way, conflicts between
alternate learned rules occur, and it is hard to in-
Where?
?do you experience the pain in your jaw?
?does the pain spread to the shoulder?
When?
?have you had the pain for more than a month?
?do the headaches ever occur in the morning?
How long?
?does the pain typically last a few minutes?
?does the pain ever last more than two hours?
How often?
?do you get headaches several times a week?
?are the headaches occurring more often?
How?
?is it a stabbing pain?
?is the pain usually severe?
Associated symptoms?
?do you vomit when you get the headaches?
?is the pain accompanied by blurred vision?
Why?
?does bright light make the pain worse?
?do you get headaches when you eat cheese?
What helps?
?does sleep make the pain better?
?does massage help?
Background?
?do you have a history of sinus disease?
?have you had an e c g?
Table 1: Examples of English MedSLT coverage
duce a stable set of rules. As Probst and Levin sug-
gest, one obvious way to attack the problem is to
implement a (formal or informal) elicitation strat-
egy, which biases the informant towards translations
which are consistent with the existing ones. This is
the approach we have adopted in MedSLT.
The Regulus platform, on which MedSLT
is based, supports rapid construction of com-
plex grammar-based language models; it uses an
example-based method driven by small corpora
of disambiguated parsed examples (Rayner et al,
2003; Rayner et al, 2006), which extracts most of
the structure of the model from a general linguis-
tically motivated resource grammar. The result is
a specialised version of the general grammar, tai-
lored to the example corpus, which can then be com-
piled into an efficient recogniser or into a genera-
Language Vocab WER SemER
English 441 6% 18%
French 1025 8% 10%
Japanese 347 4% 4%
Table 2: Recognition performance for English,
French and Japanese headache-domain recognisers.
?Vocab? = number of surface words in source lan-
guage recogniser vocabulary; ?WER? = Word Error
Rate for source language recogniser, on in-coverage
material; ?SemER? = semantic error rate for source
language recogniser, on in-coverage material.
tion module. Regulus-based recognisers and gen-
erators are easy to maintain, and grammar struc-
ture is shared automatically across different subdo-
mains. Resource grammars are available for several
languages, including English, Japanese, French and
Spanish.
Nuance recognisers derived from the resource
grammars produce both a recognition string and a
semantic representation. This representation con-
sists of a list of key/value pairs, optionally including
one level of nesting; the format of interlingua and
target language representations is similar. The for-
malism is sufficiently expressive that a reasonable
range of temporal and causal constructions can be
represented (Rayner et al, 2005b). A typical exam-
ple is shown in Figure 1. A translation rule maps
a list of key/value pairs to a list of key/value pairs,
optionally specifying conditions requiring that other
key/value pairs either be present or absent in the
source representation.
When developing new coverage for a given lan-
guage pair, the developer has two main tasks. First,
they need to add new training examples to the
corpora used to derive the specialised grammars
used for the source and target languages; second,
they must add translation rules to handle the new
key/value pairs. The simple structure of the Med-
SLT representations makes it easy to support semi-
automatic acquisition of both of these types of in-
formation. The basic principle is to attempt to find
the minimal set of new rules that can be added to the
existing set, in order to cover the new corpus exam-
ple; this is done through a short elicitation dialogue
with the developer. We illustrate this with a simple
example.
Suppose we are developing coverage for the En-
glish ? Spanish version of the system, and that
the English corpus sentence ?does the pain occur at
night? fails to translate. The acquisition tool first
notes that processing fails when converting from in-
terlingua to Spanish. The interlingua representation
is
[[utterance_type,ynq],
[pronoun,you],
[state,have_symptom],
[symptom,pain],[tense,present],
[prep,in_time],[time,night]]
Applying Interlingua ? Spanish rules, the result is
[[utterance_type,ynq],
[pronoun,usted],
[state,tener],[symptom,dolor],
[tense,present],
[prep,por_temporal],
failed:[time,night]]
where the tag failed indicates that the element
[time,night] could not be processed. The tool
matches the incomplete transferred representation
against a set of correctly translated examples, and
shows the developer the English and Spanish strings
for the three most similar ones, here
does it appear in the morning
-> tiene el dolor por la man?ana
does the pain appear in the morning
-> tiene el dolor por la man?ana
does the pain come in the morning
-> tiene el dolor por la man?ana
This suggests that a translation for ?does the pain
occur at night? consistent with the existing rules
would be ?tiene el dolor por la noche?. The devel-
oper gives this example to the system, which parses
it using both the general Spanish resource grammar
and the specialised grammar used for generation in
the headache domain. The specialised grammar fails
to produce an analysis, while the resource grammar
produces two analyses,
[[utterance_type,ynq],
[pronoun,usted],
[state,tener],[symptom,dolor],
[[utterance_type,ynq],[pronoun,you],[state,have_symptom],
[tense,present],[symptom,headache],[sc,when],
[[clause,[[utterance_type,dcl],[pronoun,you],
[action,drink],[tense,present],[cause,coffee]]]]
Figure 1: Representation of ?do you get headaches when you drink coffee?
[tense,present],
[prep,por_temporal],
[temporal,noche]]
and
[[utterance_type,dcl],
[pronoun,usted],
[state,tener],[symptom,dolor],
[tense,present],
[prep,por_temporal],
[temporal,noche]]
The first of these corresponds to the YN-question
reading of the sentence (?do you have the pain at
night?), while the second is the declarative reading
(?you have the pain at night?). Since the first (YN-
question) reading matches the Interlingua represen-
tation better, the acquisition tool assumes that it is
the intended one. It can now suggest two pieces of
information to extend the system?s coverage.
First, it adds the YN-question reading of ?tiene
el dolor por la noche? to the corpus used to train
the specialised generation grammar. The piece
of information acquired from this example is that
[temporal,noche] should be realised in this
domain as ?la noche?. Second, it compares the cor-
rect Spanish representation with the incomplete one
produced by the current set of rules, and induces a
new Interlingua to Spanish translation rule. This will
be of the form
[time,night] -> [temporal,noche]
In the demo, we will show how the development
environment makes it possible to quickly add new
coverage to the system, while also checking that old
coverage is not broken.
References
P. Bouillon, M. Rayner, N. Chatzichrisafis, B.A. Hockey,
M. Santaholma, M. Starlander, Y. Nakao, K. Kanzaki,
and H. Isahara. 2005. A generic multi-lingual open
source platform for limited-domain medical speech
translation. In In Proceedings of the 10th Conference
of the European Association for Machine Translation
(EAMT), Budapest, Hungary.
MedBridge, 2006. http://www.medtablet.com/index.html.
As of 15 March 2006.
MedSLT, 2005. http://sourceforge.net/projects/medslt/.
As of 15 March 2005.
Phraselator, 2006. http://www.phraselator.com. As of 15
March 2006.
K. Probst and L. Levin. 2002. Challenges in automatic
elicitation of a controlled bilingual corpus. In Pro-
ceedings of the 9th International Conference on The-
oretical and Methodological Issues in Machine Trans-
lation.
M. Rayner, B.A. Hockey, and J. Dowding. 2003. An
open source environment for compiling typed unifica-
tion grammars into speech recognisers. In Proceed-
ings of the 10th EACL (demo track), Budapest, Hun-
gary.
M. Rayner, P. Bouillon, N. Chatzichrisafis, B.A. Hockey,
M. Santaholma, M. Starlander, H. Isahara, K. Kankazi,
and Y. Nakao. 2005a. A methodology for comparing
grammar-based and robust approaches to speech un-
derstanding. In Proceedings of the 9th International
Conference on Spoken Language Processing (ICSLP),
Lisboa, Portugal.
M. Rayner, P. Bouillon, M. Santaholma, and Y. Nakao.
2005b. Representational and architectural issues in a
limited-domain medical speech translator. In Proceed-
ings of TALN/RECITAL, Dourdan, France.
M. Rayner, B.A. Hockey, and P. Bouillon. 2006. Putting
Linguistics into Speech Recognition: The Regulus
Grammar Compiler. CSLI Press, Chicago.
Regulus, 2006. http://sourceforge.net/projects/regulus/.
As of 15 March 2006.
S-MINDS, 2006. http://www.sehda.com. As of 15
March 2006.
M. Starlander, P. Bouillon, N. Chatzichrisafis, M. Santa-
holma, M. Rayner, B.A. Hockey, H. Isahara, K. Kan-
zaki, and Y. Nakao. 2005. Practicing controlled lan-
guage through a help system integrated into the medi-
cal speech translation system (MedSLT). In Proceed-
ings of the MT Summit X, Phuket, Thailand.
Proceedings of the 7th Workshop on Asian Language Resources, ACL-IJCNLP 2009, pages 1?8,
Suntec, Singapore, 6-7 August 2009. c?2009 ACL and AFNLP
Enhancing the Japanese WordNet
Francis Bond,? Hitoshi Isahara,? Sanae Fujita,?
Kiyotaka Uchimoto,? Takayuki Kuribayashi? and Kyoko Kanzaki?
? NICT Language Infrastructure Group, ? NICT Language Translation Group
<bond@ieee.org,{isahara,uchimoto,kuribayashi,kanzaki}@nict.go.jp>
? Sanae Fujita, NTT Communications Science Laboratory
<sanae@kecl.cslab.ntt.co.jp>
Abstract
The Japanese WordNet currently has
51,000 synsets with Japanese entries. In
this paper, we discuss three methods of
extending it: increasing the cover, linking
it to examples in corpora and linking it
to other resources (SUMO and GoiTaikei).
In addition, we outline our plans to make
it more useful by adding Japanese defini-
tion sentences to each synset. Finally, we
discuss how releasing the corpus under an
open license has led to the construction
of interfaces in a variety of programming
languages.
1 Introduction
Our goal is to make a semantic lexicon of
Japanese that is both accesible and usable. To
this end we are constructing and releasing the
Japanese WordNet (WN-Ja) (Bond et al, 2008a).
We have almost completed the first stage,
where we automatically translated the English
and Euro WordNets, and are hand correcting it.
We introduce this in Section 2. Currently, we
are extending it in three main areas: the first
is to add more concepts to the Japanese Word-
Net, either by adding Japanese to existing En-
glish synsets or by creating new synsets (? 3).
The second is to link the synsets to text exam-
ples (? 4). Finally, we are linking it to other re-
sources: the Suggested Upper Merged Ontology
(SUMO) (Niles and Pease, 2001), the Japanese
semantic lexicon GoiTaikei (Ikehara et al, 1997),
and a collection of illustrations taken from the
Open ClipArt Library (Phillips, 2005) (? 5).
2 Current State
Currently, the WN-Ja consists of 157,000 senses
(word-synset pairs) 51,000 concepts (synsets) and
81,000 unique Japanese words (version 0.91). The
relational structure (hypernym, meronym, do-
main, . . . ) is based entirely on the English Word-
Net 3.0 (Fellbaum, 1998). We have Japanese
words for 43.0% of the synsets in the English
WordNet. Of these synsets, 45% have been
checked by hand, 8% were automatically cre-
ated by linking through multiple languages and
46% were automatically created by adding non-
ambiguous translations, as described in Bond
et al (2008a). There are some 51,000 synsets with
Japanese candidate words that have not yet been
checked. For up-to-date information on WN-Ja
see: nlpwww.nict.go.jp/wn-ja.
An example of the entry for the synset
02076196-n is shown in Figure 1. Most fields
come from the English WordNet. We have added
the underlined fields (Ja Synonyms, Illustration,
links to GoiTaikei, SUMO) and are currently
adding the translated definition (Def (Ja)). In
the initial automatic construction there were 27
Japanese words associated with the synset,1 in-
cluding many inappropriate translations for other
senses of seal (e.g., ?? hanko ?stamp?). These
were reduced to three after checking: ????,
?? azarashi ?seal? and ?? ? shi-ru ?seal?.
Synsets with? in their names are those for which
there is currently no Japanese entry in the Word-
Net.
The main focus of this year?s work has been
this manual trimming of badly translated words.
The result is a WordNet with a reasonable cov-
erage of common Japanese words. The precision
per sense is just over 90%. We have aimed at high
coverage at the cost of precision for two reasons:
(i) we think that the WordNet must have a rea-
1????, ???, ????, ??, ?, ??, ??, ?
?, ??, ?, ??, ??, ??, ??, ??, ??, ??, ?
?, ???, ?, ???, ??, ??, ??, ??, ?? ?, ?
?, ??, ??, ??, ??, ??, ??,??,?, ??, ??
1
sonable coverage to be useful for NLP tasks and
(ii) we expect to continue refining the accuracy
over the following years. Our strategy is thus dif-
ferent from Euro WordNet (Vossen, 1998), where
initial emphasis was on building a consistent and
complete upper ontology.
3 Increasing Coverage
We are increasing the coverage in two ways. The
first is to continue to manually correct the auto-
matically translated synsets. This is being done
both by hand, as time permits, and also by com-
paring against other resources such as GoiTaikei
and Wikipedia. When we check for poor candi-
dates, we also add in missing words as they occur
to us.
More interestingly, we wish to add synsets for
Japanese concepts that may not be expressed in
the English WordNet. To decide which new con-
cepts to add, we will be guided by the other tasks
we are doing: annotation and linking. We intend
to create new synsets for words found in the cor-
pora we annotate that are not currently covered,
as well as for concepts that we want to link to.
An example for the first is the concept ?? go-
han ?cooked rice?, as opposed to the grain ?
kome ?rice?. An example of the second is???
? ?shinguru ?single: a song usually extracted
from a current or upcoming album to promote
the album?. This is a very common hypernym in
Wikipedia but missing from the English Word-
Net.
As far as possible, we want to coordinate the
creation of new synsets with other projects: for
example KorLex: the Korean WordNet aleady
makes the cooked rice/grain distinction, and the
English WordNet should also have a synset for
this sense of single.
4 Text Annotation
We are in the process of annotating four texts
(Table 1). The first two are translations of Word-
Net annotated English Texts (SemCor and the
WordNet definitions), the third is the Japanese
newspaper text that forms the Kyoto Corpus
and the fourth is an open corpus of bilingual
Japanese-English sentences (Tanaka). In 2009,
we expect to finish translating and annotate all
of SemCor, translate the WordNet definitions and
Name Sentences Words Content Words
SemCor 12,842 224,260 120,000
Definitions 165,977 1,468,347 459,000
Kyoto 38,383 969,558 527,000
Tanaka 147,190 1,151,892 360,000
Table 1: Corpora to be Sense Tagged
start annotation on the Kyoto and Tanaka Cor-
pora.
This annotation is essential for finding missing
senses in the Japanese WordNet, as well as get-
ting the sense distributions that are needed for
supervised word sense disambiguation.
4.1 SemCor
SemCor is a textual corpus in which words have
been both syntactically and semantically tagged.
The texts included in SemCor were extracted
from the Brown corpus (Francis and Kucera,
1979) and then linked to senses in the English
WordNet. The frequencies in this corpus were
used to give the sense frequencies in WordNet
(Fellbaum, 1998). A subset of this corpus (Mul-
tiSemCor) was translated into Italian and used
as a corpus for the Italian WordNet (Bentivogli
et al, 2004). We are translating this subset into
Japanese.
In the same way as Bentivogli et al (2004), we
are exploiting Cross-Language Annotation Trans-
fer to seed the Japanese annotation. For exam-
ple, consider (1)2. The content words answer,
was, simple, honest are tagged in SemCor. They
can be aligned with their translations ?? ko-
tae ?answer?, ?? kantan ?simple?, ?? soc-
choku ?honest? and ??? datta ?was?. This
allows us to tag the Japanese translation with
the same synsets as the English, and thus disam-
biguate them.
(1) His answeri wasj simplek but honestl .
??i ? ??k ???? ??l ? ??
???j ?
However, just because all the English words
have sysnets in WordNet, it is not always the
case for the translations. For example, the En-
glish phrase last night can be translated into ?
? zen?ya ?last-night?. Here the two English
words (and synsets) link to a single Japanese
2Sentence 96 in b13.
2
??
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
Synset 02076196-n
Synonyms
?
?
ja ??, ????, ???
en seal9
fr phoque
?
? Illustration
animal/seal.png
Def (en) ?any of numerous marine mammals that come on shore to breed; chiefly of cold regions?
Def (ja) ???????????????????????????????
Hypernyms ?????/pinniped
Hyponyms ?/crabeater seal ?/eared seal ??/earless seal
GoiTaikei ??537:beast??
SUMO ? Carnivore
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
Figure 1: Example Entry for Seal/??
word which has no suitable synset in the English
WordNet. In this case, we need to create a new
synset unique to the Japanese WordNet.3
We chose a translated SemCor as the basis of
annotation for two main reasons: (i) the cor-
pus can be freely redistributed ? we expect
the glosses to be useful as an aligned corpus of
Japanese-English-Italian and (ii) it has other an-
notations associated with it: Brown corpus POS
annotation, Penn Treebank syntactic annotation.
4.2 WordNet Definitions
Our second translated corpus is formed from
the WordNet definitions (and example sentences)
themselves (e.g., the def field shown in Figure 1).
The English definitions have been annotated with
word senses in the Princeton WordNet Gloss Cor-
pus. In the same way that we do for SemCor, we
are translating the definitions and examples, and
using the existing annotation to seed our annota-
tion.
Using the definitions as the base for a sense
annotated corpus is attractive for the following
reasons: (i) the translated corpus can be freely
redistributed ? we expect the definitions to be
useful as an aligned corpus and also to be useful
for many other open lexicons; (ii) the definitions
are useful for Japanese native speakers using the
WordNet, (iii) the definitions are useful for unsu-
pervised sense disambiguation techniques such as
LESK (Baldwin et al, 2008); (iv) other projects
3Arguably, the fact that one says last night (not yester-
day night) for the night proceeding today and tomorrow
night (not next night) for the night following today sug-
gests that these multi-word expressions are lexicalized and
synsets should be created for them in the English Word-
Net. However, in general we expect to create some synsets
that will be unique to the Japanese WordNet.
have also translated synset definitions (e.g. Span-
ish and Korean), so we can hope to create a multi-
lingual corpus here as well and (v) the definitions
can be used as a machine readable dictionary, and
various information extracted from there (Barn-
brook, 2002; Nichols et al, 2006)
4.3 Kyoto Text Corpus
The Kyoto Text Corpus consists of newspaper
text from the Mainichi Newspaper (1995), seg-
mented and annotated with Japanese POS tags
and dependency trees (Kurohashi and Nagao,
2003). The corpus is made up of two parts. The
first consists of 17 full days of articles and the sec-
ond of one year?s editorials. We hope to annotate
at least parts of it during 2009.
Even though the Kyoto Text Corpus is not
freely redistributable, we have chosen to anno-
tate it due to the wealth of annotation associated
with it: dependency trees, predicate-argument re-
lations and co-reference (Iida et al, 2007), trans-
lations into English and Chinese (Uchimoto et al,
2004) and sense annotations from the Hinoki
project (Bond et al, 2006). We also felt it was
important to tag some native Japanese text, not
only translated text.
4.4 Tanaka Corpus
Finally, we will also tag the Tanaka Corpus, an
open corpus of Japanese-English sentence pairs
compiled by Professor Yasuhito Tanaka at Hyogo
University and his students (Tanaka, 2001) and
released into the public domain. The corrected
version we use has around 140,000 sentence pairs.
This corpus is attractive for several reasons.
(i) it is freely redistributable; (ii) it has been in-
dexed to entries in the Japanese-English dictio-
3
nary JMDict (Breen, 2003); (iii) part of it has
also been used in an open HPSG-based treebank
(Bond et al, 2008b); (iv) further, translations in
other languages, most notably French, have been
added by the TATOEBA project.4 Our plan is
to tag this automatically using the tools devel-
oped for the Kyoto corpus annotation, and then
to open the data to the community for refinement.
We give a typical example sentence in (2).
(2) ??????????????????
?Some birds are sitting on the branch of that
tree.? (en)
?Des oiseaux se reposent sur la branche de cet
arbre.? (fr)
5 Linking to other resources
We currently link the Japanese WordNet to three
other resources: the Suggested Upper Merged
Ontology; GoiTaikei, a Japanese Lexicon; and a
collection of pictures from the Open Clip Art Li-
brary (OCAL: Phillips (2005)).
For SUMO we used existing mappings. For the
other resources, we find confident matches auto-
matically and then generalize from them. We find
matches in three ways:
MM Monosemous monolingual matches
e.g. cricket bat or ?? azarashi ?seal?
MB Monosemous bilingual matches
e.g. ????seal?
HH Hypernym/Hyponym pairs
e.g. ?seal ? mammal?
We intend to use the same techniques to link
other resources, such as the concepts from the
EDR lexicon (EDR, 1990) and the automati-
cally extracted hypernym-hyponym links from
Torishiki-kai (Kuroda et al, 2009).
5.1 SUMO
The Suggested Upper Merged Ontology (SUMO)
is a large formal public ontology freely released
by the IEEE (Niles and Pease, 2001).
Because the structure of the Japanese Word-
Net is closely linked to that of the English Word-
Net, we were able to take advantage of the ex-
isting mappings from the English WordNet to
SUMO. There are 102,669 mappings from SUMO
4wwwcyg.utc.fr/tatoeba/
Carnivore Business Competition
Figure 2: SUMO illustrations
to WordNet: 3,593 equivalent, 10,712 where the
WordNet synset subsumes the SUMO concept,
88,065 where the SUMO concept subsumes the
WordNet concept, 293 where the negation of the
SUMO concept subsumes the WordNet synset
and 6 where the negation of the SUMO concept
is equivalent to the WordNet synset. According
to the mapping, synset 02076196-n ?? azarashi
?seal?, shown in Figure 1 is subsumed by the
SUMO concept ??Carnivore??. There is no link
between seal and carnivore in WordNet, which
shows how different ontologies can complement
each other.
Linking to SUMO also allowed us to use the
SUMO illustrations.5 These consist of 12,237
links linking 4,607 concepts to the urls of 10,993
illustrations. These are mainly taken from
from Wikimedia (upload.wikimedia.org), with
around 1,000 from other sources. The pictures
can be linked quite loosely to the concepts. For
example, ??Carnivore?? is illustrated by a lion eat-
ing meat, and ??BusinessCompetition?? by a pic-
ture of Wall Street.
As we wanted our illustrations to be more con-
crete, we only use SUMO illustrations where the
SUMO-WordNet mapping is equivalence. This
gave 4,384 illustrations for 999 synsets.
5.2 GoiTaikei
Linking Goi-Taikei, we used not only the
Japanese dictionary published in Ikehara et al
(1997), but also the Japanese-English dictionary
used in the machine translation system ALT-J/E
(Ikehara et al, 1991). We attempted to match
synsets to semantic categories by matching the
5Available at http://sigmakee.cvs.sourceforge.
net/viewvc/sigmakee/KBs/pictureList.kif, thanks to
Adam Pease for letting us know about them.
4
Japanese, English and English-Japanese pairs to
unambiguous entries in Goi-Taikei. For example,
the synset shown in Figure 1 was automatically
assigned the semantic category ??537:beast??, as
?? appears only once in WN-Ja, with the synset
shown, and once in the Japanese dictionary for
ALT-J/E with a single semantic category.
We are currently evaluating our results against
an earlier attempt to link WordNet and GoiTaikei
that also matched synset entries to words in Goi-
Taikei (Asanoma, 2001), but did not add an extra
constraint (that they must be either monosemous
or match as a hypernym-hyponym pair).
Once we have completed the mapping, we will
use it to check for inconsistencies in the two re-
sources.
5.3 Open ClipArt Library
In order to make the sense distinctions more vis-
ible we have semi-automatically linked synsets
to illustrations from the Open Clip Art Library
(OCAL: Phillips (2005)) using the mappings pro-
duced by Bond et al (2008a).
We manually checked the mappings and added
a goodness score. Illustrations are marked as:
3 the best out of multiple illustrations
2 a good illustration for the synset
1 a suitable illustration, but not perfect
This tag was used for black and white im-
ages, outlines, and so forth.
After the scoring, there were 874 links for 541
synsets (170 scored 1, 642 scored 2 and 62 scored
3). This is only a small subset of illustrations in
OCAL and an even smaller proportion of word-
net. However, because any illustrated synset alo
(in theory) illustrates its hypernyms, we have in-
directly illustrated far more than 541 synsets:
these figures are better than they seem.
There are far fewer OCAL illustrations than
the SUMO linked illustrations. However, they are
in general more representative illustrations (espe-
cially those scored 2 and above), and the source of
the clipart is available as SVG source so it is easy
to manipulate them. We think that this makes
them particularly useful for a variety of tasks.
One is pedagogical ? it is useful to have pic-
tures in learners? dictionaries. Another is in cross-
cultural communication - for example in Pangea,
where children use pictons (small concept repre-
senting pictures) to write messages (Takasaki and
Mori, 2007).
The OCAL illustrations mapped through
WordNet to 541 SUMO concepts. We have given
these links to the SUMO researchers.
6 Interfaces
We released the Japanese WordNet in three for-
mats: tab-delimited text, XML and as an SQLite
database. The license was the same as English
WordNet. This is a permissive license, the data
can be reused within proprietary software on the
condition that the license is distributed with that
software (similar to the MIT X license). The
license is also GPL-compatible, meaning that
the GPL permits combination and redistribution
with software that uses it.
The tab delimited format consists of just a list
of synsets, Japanese words and the type of link
(hand, multi-lingual or monosemous):
02076196-n ?? hand
02076196-n ???? hand
02076196-n ??? hand
We also output in WordNet-LMF (Francopoulo
et al, 2006; Soria et al, 2009), to make the
program easily available for other WordNet re-
searchers. In this case the synset structure was
taken from the English WordNet and the lem-
mas from the Japanese WordNet. Because of the
incomplete coverage, not all synsets contain lem-
mas. This format is used by the Kyoto Project,
and we expect it to become the standard ex-
change format for WordNets (Vossen et al, 2008).
Finally, we also created an SQL database. This
contains information from the English WordNet,
the Japanese WordNet, and links to illustra-
tions. We chose SQLite,6 a self-contained, zero-
configuration, SQL database engine whose source
code is in the public domain. The core structure
is very simple with six tables, as shown in Fig-
ure 3.
As we prepared the release we wrote a perl
module for a basic interface. This was used to
develop a web interface: Figure 4 shows a screen-
shot.
6http://www.sqlite.org
5
word
wordid 
 lang 
 lemma 
 pron 
 pos 
sense
synset 
 wordid 
 lang 
 rank 
 lexid 
 freq 
 src 
1..*1
synset
pos 
 name 
 src 
11..*
synsetDef
synset 
 lang 
 def 
 sid 
11
synlink
synset1 
 synset2 
 link 
 src 
1 1..*
xlink
synset 
 resource 
 xref 
 misc 
 confidence
1 1..*
Figure 3: Database Schema
Figure 4: Web Search Screenshot
6
7 Discussion
In contrast to earlier WordNets, the Japanese
WordNet was released with two known major im-
perfections: (i) the concept hierarchy was en-
tirely based on English with no adaptation to
Japanese and (ii) the data was released with some
unchecked automatically created entries. The re-
sult was a WordNet that did not fully model the
lexical structure of Japanese and was known to
contain an estimated 5% errors. The motivation
behind this was twofold. Firstly, we wanted to try
and take advantage of the open source model. If
the first release was good enough to be useful, we
hoped to (a) let people use it and (b) get feedback
from them which could then be incorporated into
the next release. This is the strategy known as
release early, release often (Raymond, 1999).
Secondly, we anticipated the most common use
of the WordNet to be in checking whether one
word is a hypernym of another. In this case, even
if one word is wrong, it is unlikely that the other
will be, so a small percentage of errors should be
acceptable.
From the practical point of view, the early re-
lease appears to have been a success. The SQL
database proved very popular, and within two
weeks of the first release someone produced a
python API. This was soon followed by inter-
faces in java, ruby, objective C and gauche. We
also received feedback on effective indexing of the
database and some corrections of entries ? these
have been included in the most recent release
(0.91).
The data from the Japanese WordNet has al-
ready been incorporated into other projects. The
first was the Multi-Lingual Semantic Network
(MLSN) (Cook, 2008) a WordNet based net-
work of Arabic, Chinese, English, German and
Japanese. Because both the Japanese WordNet
and MLSN use very open licenses, it is possible
to share entries directly. We have already re-
ceived useful feedback and over a thousand new
entries from MLSN. The second project using our
data is the Asian WordNet (Charoenporn et al,
2008). They have a well developed interface for
collaborative development of linguistic resources,
and we hope to get corrections and additions
from them in the future. Another project us-
ing the Japanese WordNet data is the Language
Grid (Ishida, 2006) which offers the English and
Japanese WordNets as concept dictionaries.
We have also been linked to from other re-
sources. The Japanese-English lexicon project
JMDict (Breen, 2004) now links to the Japanese
WordNet, and members of that project are us-
ing WordNet to suggest new entries. We used
JMDict in the first automatic construction stage,
so it is particularly gratifying to be able to help
JMDict in turn.
Finally, we believe that data about language
should be shared ? language is part of the com-
mon heritage of its speakers. In our case, the
Japanese WordNet was constructed based on the
work that others made available to us and thus we
had a moral obligation to make our results freely
available to others. Further, projects that create
WordNets but do not release them freely hinder
research on lexical semantics in that language ?
people cannot use the unreleased resource, but it
is hard to get funding to duplicate something that
already exists.
In future work, in addition to the planned ex-
tensions listed here, we would like to work on
the following: Explicitly marking lexical variants;
linking to instances in Wikipedia; adding deriva-
tional and antonym links; using the WordNet for
word sense disambiguation.
8 Conclusion
This paper presents the current state of the
Japanese WordNet (157,000 senses, 51,000 con-
cepts and 81,000 unique Japanese words, with
links to SUMO, Goi-Taikei and OCAL) and out-
lined our plans for further work (more words,
links to corpora and other resources). We hope
that WN-Ja will become a useful resource not only
for natural language processing, but also for lan-
guage education/learning and linguistic research.
References
Naoki Asanoma. 2001. Alignment of ontologies:wordnet
and goi-taikei. In NAACL Wokshop on WordNet &
Other Lexical Resources, pages 89?94. Pittsburgh, USA.
Timothy Baldwin, Su Nam Kim, Francis Bond, Sanae Fu-
jita, David Martinez, and Takaaki Tanaka. 2008. MRD-
based word sense disambiguation: Further extending
Lesk. In Proc. of the 3rd International Joint Conference
on Natural Language Processing (IJCNLP-08), pages
775?780. Hyderabad, India.
Geoff Barnbrook. 2002. Defining Language ? A local
7
grammar of definition sentences. Studies in Corpus Lin-
guistics. John Benjamins.
Luisa Bentivogli, Pamela Forner, and Emanuele Pianta.
2004. Evaluating cross-language annotation transfer in
the MultiSemCor corpus. In 20th International Con-
ference on Computational Linguistics: COLING-2004,
pages 364?370. Geneva.
Francis Bond, Sanae Fujita, and Takaaki Tanaka.
2006. The Hinoki syntactic and semantic treebank of
Japanese. Language Resources and Evaluation, 40(3?
4):253?261. (Special issue on Asian language technol-
ogy).
Francis Bond, Hitoshi Isahara, Kyoko Kanzaki, and Kiy-
otaka Uchimoto. 2008a. Boot-strapping a WordNet
using multiple existing WordNets. In Sixth Interna-
tional conference on Language Resources and Evalua-
tion (LREC 2008). Marrakech.
Francis Bond, Takayuki Kuribayashi, and Chikara
Hashimoto. 2008b. Construction of a free Japanese
treebank based on HPSG. In 14th Annual Meeting of
the Association for Natural Language Processing, pages
241?244. Tokyo. (in Japanese).
James W. Breen. 2003. Word usage examples in an elec-
tronic dictionary. In Papillon (Multi-lingual Dictionary)
Project Workshop. Sapporo.
James W. Breen. 2004. JMDict: a Japanese-multilingual
dictionary. In Coling 2004 Workshop on Multilingual
Linguistic Resources, pages 71?78. Geneva.
Thatsanee Charoenporn, Virach Sornlerlamvanich,
Chumpol Mokarat, and Hitoshi Isahara. 2008. Semi-
automatic compilation of Asian WordNet. In 14th
Annual Meeting of the Association for Natural Lan-
guage Processing, pages 1041?1044. Tokyo.
Darren Cook. 2008. MLSN: A multi-lingual semantic net-
work. In 14th Annual Meeting of the Association for
Natural Language Processing, pages 1136?1139. Tokyo.
EDR. 1990. Concept dictionary. Technical report, Japan
Electronic Dictionary Research Institute, Ltd.
Christine Fellbaum, editor. 1998. WordNet: An Electronic
Lexical Database. MIT Press.
W. Nelson Francis and Henry Kucera. 1979. BROWN
CORPUS MANUAL. Brown University, Rhode Island,
third edition.
Gil Francopoulo, Monte George, Nicoletta Calzolari, Mon-
ica Monachini, Nuria Bel, Mandy Pet, and Claudia So-
ria. 2006. Lexical markup framework (LMF). In Pro-
ceedings of the 5th International Conference on Lan-
guage Resources and Evaluation (LREC 2006). Genoa,
Italy.
Ryu Iida, Mamoru Komachi, Kentaro Inui, and Yuji
Matsumoto. 2007. Annotating a Japanese text cor-
pus with predicate-argument and coreference relations.
In ACL Workshop: Linguistic Annotation Workshop,
pages 132?139. Prague.
Satoru Ikehara, Masahiro Miyazaki, Satoshi Shirai, Akio
Yokoo, Hiromi Nakaiwa, Kentaro Ogura, Yoshifumi
Ooyama, and Yoshihiko Hayashi. 1997. Goi-Taikei ?
A Japanese Lexicon. Iwanami Shoten, Tokyo. 5 vol-
umes/CDROM.
Satoru Ikehara, Satoshi Shirai, Akio Yokoo, and Hiromi
Nakaiwa. 1991. Toward an MT system without pre-
editing ? effects of new methods in ALT-J/E ?. In
Third Machine Translation Summit: MT Summit III,
pages 101?106. Washington DC.
Toru Ishida. 2006. Language grid: An infrastructure for in-
tercultural collaboration. In IEEE/IPSJ Symposium on
Applications and the Internet (SAINT-06), pages 96?
100. (keynote address).
Kow Kuroda, Jae-Ho Lee, Hajime Nozawa, Masaki Mu-
rata, and Kentaro Torisawa. 2009. Manual cleaning of
hypernyms in Torishiki-Kai. In 15th Annual Meeting of
The Association for Natural Language Processing, pages
C1?3. Tottori. (in Japanese).
Sadao Kurohashi and Makoto Nagao. 2003. Building a
Japanese parsed corpus ? while improving the parsing
system. In Anne Abeille?, editor, Treebanks: Building
and Using Parsed Corpora, chapter 14, pages 249?260.
Kluwer Academic Publishers.
Eric Nichols, Francis Bond, Takaaki Tanaka, Sanae Fu-
jita, and Daniel Flickinger. 2006. Robust ontology ac-
quisition from multiple sources. In Proceedings of the
2nd Workshop on Ontology Learning and Population:
Bridging the Gap between Text and Knowledge, pages
10?17. Sydney.
Ian Niles and Adam Pease. 2001. Towards a standard
upper ontology. In Chris Welty and Barry Smith, edi-
tors, Proceedings of the 2nd International Conference on
Formal Ontology in Information Systems (FOIS-2001).
Maine.
Jonathan Phillips. 2005. Introduction to the open
clip art library. http://rejon.org/media/writings/
ocalintro/ocal_intro_phillips.html. (accessed
2007-11-01).
Eric S. Raymond. 1999. The Cathedral & the Bazaar.
O?Reilly.
Claudia Soria, Monica Monachini, and Piek Vossen. 2009.
Wordnet-LMF: fleshing out a standardized format for
wordnet interoperability. In Second International Work-
shop on Intercultural Collaboration (IWIC-2009). Stan-
ford.
Toshiyuki Takasaki and Yumiko Mori. 2007. Design and
development of a pictogram communication system for
children around the world. In First International Work-
shop on Intercultural Collaboration (IWIC-2007), pages
144?157. Kyoto.
Yasuhito Tanaka. 2001. Compilation of a multilingual par-
allel corpus. In Proceedings of PACLING 2001, pages
265?268. Kyushu.
Kiyotaka Uchimoto, Yujie Zhang, Kiyoshi Sudo, Masaki
Murata, Satoshi Sekine, and Hitoshi Isahara. 2004.
Multilingual aligned parallel treebank corpus reflecting
contextual information and its applications. In Gilles
Se?rasset, editor, COLING 2004 Multilingual Linguistic
Resources, pages 57?64. COLING, Geneva, Switzerland.
P Vossen, E. Agirre, N. Calzolari, C. Fellbaum, S. Hsieh,
C. Huang, H. Isahara, K. Kanzaki, A. Marchetti,
M. Monachini, F. Neri, R. Raffaelli, G. Rigau, and
M. Tescon. 2008. KYOTO: A system for mining,
structuring and distributing knowledge across languages
and cultures. In Proceedings of the Sixth International
Language Resources and Evaluation (LREC?08). Mar-
rakech, Morocco.
Piek Vossen, editor. 1998. Euro WordNet. Kluwer.
8
Proceedings of the 7th Workshop on Asian Language Resources, ACL-IJCNLP 2009, pages 179?186,
Suntec, Singapore, 6-7 August 2009. c?2009 ACL and AFNLP
Word Segmentation Standard in Chinese, Japanese and Korean 
 
Key-Sun Choi 
KAIST 
Daejeon Korea 
kschoi@kaist.ac.kr 
Hitoshi Isahara 
NICT 
Kyoto Japan 
isahara@nict.go.jp 
Kyoko Kanzaki
NICT 
Kyoto Japan 
kanzaki@nict.go.jp
Hansaem Kim
National Inst. 
Korean Lang.
Seoul  Korea
thesis00@korea.kr
Seok Mun Pak 
Baekseok Univ. 
Cheonan Korea 
smpark@bu.ac.kr 
Maosong Sun 
Tsinghua Univ.
Beijing China 
sms@tsinghua.edu.cn
 
Abstract 
Word segmentation is a process to divide a 
sentence into meaningful units called ?word 
unit? [ISO/DIS 24614-1]. What is a word 
unit is judged by principles for its internal in-
tegrity and external use constraints. A word 
unit?s internal structure is bound by prin-
ciples of lexical integrity, unpredictability 
and so on in order to represent one syntacti-
cally meaningful unit. Principles for external 
use include language economy and frequency 
such that word units could be registered in a 
lexicon or any other storage for practical re-
duction of processing complexity for the fur-
ther syntactic processing after word segmen-
tation. Such principles for word segmentation 
are applied for Chinese, Japanese and Korean, 
and impacts of the standard are discussed. 
1 Introduction 
Word segmentation is the process of dividing of 
sentence into meaningful units. For example, 
?the White House? consists of three words but 
designates one concept for the President?s resi-
dence in USA. ?Pork? in English is translated 
into two words ?pig meat? in Chinese, Korean 
and Japanese. In Japanese and Korean, because 
an auxiliary verb must be followed by main verb, 
they will compose one word unit like ?tabetai? 
and ?meoggo sipda? (want to eat). So the word 
unit is defined by a meaningful unit that could be 
a candidate of lexicon or of any other type of 
storage (or expanded derived lexicon) that is use-
ful for the further syntactic processing. A word 
unit is more or less fixed and there is no syntactic 
interference in the inside of the word unit. In the 
practical sense, it is useful for the further syntac-
tic parsing because it is not decomposable by 
syntactic processing and also frequently occurred 
in corpora.  
There are a series of linguistic annotation 
standards in ISO: MAF (morpho-syntactic anno-
tation framework), SynAF (syntactic annotation 
framework), and others in ISO/TC37/SC4 1 . 
These standards describe annotation methods but 
not for the meaningful units of word segmenta-
tion. In this aspect, MAF and SynAF are to anno-
tate each linguistic layer horizontally in a stan-
dardized way for the further interoperability. 
Word segmentation standard would like to rec-
ommend what word units should be candidates to 
be registered in some storage or lexicon, and 
what type of word sequences called ?word unit? 
should be recognized before syntactic processing. 
In section 2, principles of word segmentation 
will be introduced based on ISO/CD 24614-1. 
Section 3 will describe the problems in word 
segmentation and what should be word units in 
each language of Chinese, Japanese and Korean. 
The conclusion will include what could be 
shared among three languages for word segmen-
tation. 
2 Word Segmentation: Framework and 
Principles 
Word unit is a layered pre-syntactical unit. That 
means that a word unit consists of the smaller 
word units. But the maximal word unit is fre-
quently occurred in corpora under the constraints 
that the syntactic processing will not refer the 
internal structure of the word unit 
Basic atoms of word unit are word form, mor-
pheme including bound morpheme, and non-
lexical items like punctuation mark, numeric 
string, foreign character string and others as 
shown in Figure 1. Usually we say that ?word? is 
lemma or word form. Word form is a form that a 
lexeme takes when used in a sentence. For ex-
ample, strings ?have?, ?has?, and ?having? are 
word forms of the lexeme HAVE, generally dis-
tinguished by the use of capital letters. [ISO/CD 
24614-1] Lemma is a conventional form used to 
represent a lexeme, and lexeme is an abstract 
unit generally associated with a set of word 
forms sharing a common meaning. 
                                                 
1 Refer to http://www.tc37sc4.org/ for documents 
MAF, SynAF and so on. 
179
 
Figure 1. Configuration of Word Unit 
 
BNF of word unit is as follows: 
<word unit> ::= <word form> | <morpheme> | 
<non lexical items> | <word unit>, 
where <word unit> is recursively defined be-
cause a longer word unit contains smaller word 
units. 
Bunsetsu in Japanese is the longest word unit, 
which is an example of layered maximized pre-
syntactical unit. Eojeol in Korean is a spacing 
unit that consists of one content word (noun, 
verb, adjective or adverb) plus a sequence of 
functional elements. Such language-specific 
word units will be described in section 3.  
Principles for word segmentation will set the 
criteria to validate each word unit, to recognize 
its internal structure and non-lexical word unit, to 
be a candidate of lexicon, and other consistency 
to be necessitated by practical applications for 
any text in any language. The meta model of 
word segmentation will be explained in the 
processing point of view, and then their prin-
ciples of word units in the following subsections.  
2.1 Metamodel of Word Segmentation 
A word unit has a practical unit that will be later 
used for syntactic processing. While the word 
segmentation is a process to identify the longest 
word unit and its internal structure such that the 
word unit is not the object to interfere any syn-
tactic operation, ?chunking? is to identify the 
constituents but does not specify their internal 
structure. Syntactic constituent has a syntactic 
role, but the word unit is a subset of syntactic 
constituent. For example, ?blue sky? could be a 
syntactic constituent but not a word unit. Figure 
2 shows the meta model of word segmentation. 
[ISO CD 24614-1]  
2.2 Principles of Word Unit Validation 
Principles for validating a word unit can be ex-
plained by two perspectives: one is linguistic one 
and the other is processing-oriented practical 
perspective.   
In ISO 24614-1, principles from a linguistic 
perspective, there are five principles: principles 
of (1) bound morpheme, (2) lexical integrity, (3) 
unpredictability, (4) idiomatization, and (5) un-
productivity.  
First, bound morpheme is something like ?in? 
of ? inefficient? . The principle of bound mor-
pheme says that each bound morpheme plus 
word will make another word. Second, principle 
of lexical integrity means that any syntactic 
processing cannot refer the internal structure of 
word (or word unit). From the principle, we can 
say that the longest word unit is the maximal 
meaningful unit before syntactic processing. 
Third, another criterion to recognize a word is 
the principle of unpredictability. If we cannot 
infer the real fact from the word, we consider it 
as a word unit. For example, we cannot image 
what is the colour of blackboard because some is 
green, not black. [ISO 24614-1] The fourth prin-
ciple is that the idiom should be one word, which 
could be a subsidiary principle that follows the 
principle of unpredictability. In the last principle, 
unproductivity is a stronger definition of word; 
there is no pattern to be copied to generate an-
other word from this word formation. For exam-
ple, in ????  (white vegetable) in Chinese, 
there is no other coloured vegetable like ?blue 
vegetable.? 
Another set of principles is derived from the 
practical perspective. There are four principles: 
frequency, Gestalt, prototype and language 
economy. Two principles of frequency and lan-
guage economy are to recognize the frequent 
occurrence in corpora. Gestalt and prototype 
principles are the terms in cognitive science 
about what are in our mental lexicon, and what 
are perceivable words.  
Principle of language economy is to say about 
very practical processing efficiency: ?if the in-
clusion of a word (unit) candidate into the lex-
icon can decrease the difficulty of linguistic 
analysis for it, then it is likely to be a word 
(unit).? 
Gestalt principle is to perceive as a whole. ?It 
supports some perceivable phrasal compounds 
into the lexicon even though they seem to be free 
combinations of their perceivable constituent 
parts,? [ISO/CD 24614-1] where the phrasal 
compound is frequently used linguistic unit and 
its meaning is predictable from its constituent 
elements. Similarly, principle of prototype pro-
180
vides a rationale for including some phrasal 
compounds into lexicon, and phrasal compounds 
serve as prototypes in a productive word forma-
tion pattern, like ?apple pie? with the pattern 
?fruit + pie? into the lexicon.  
 
 
Figure 2. Meta model of word segmentation proess 
[ISO/CD 24614-1] 
2.3 Principles for Word Unit Formation 
As a result of word segmentation of sentence, we 
will get word units. These principles will de-
scribe the internal structure of word unit. They 
have four principles: granularity, scope maximi-
zation of affixations, scope maximization of 
compounding, and segmentation for other strings. 
In the principle of granularity, a word unit has its 
internal structure, if necessary for various appli-
cation of word segmentation.  
Principles of scope maximization of affixa-
tions and compounding are to recognize the 
longest word unit as one word unit even if it is 
composed of stem + affixes or compound of 
word units. For example, ?unhappy? or ?happy? 
is one word unit respectively. ?Next generation 
Internet? is one word unit. The principle of seg-
mentation for other strings is to recognize non-
lexical strings as one word unit if it carries some 
syntactic function, for example, 2009 in ?Now 
this year is 2009.?  
3 Word Segmentation for Chinese, Jap-
anese and Korean 
If the word is derived from Chinese characters, 
three languages have common characteristics. If 
their word in noun consists of two or three Chi-
nese characters, they will be one word unit if 
they are ?tightly combined and steadily used.? 
Even if it is longer length, it will be a word unit 
if it is fixed expression or idiom. But if the first 
character is productive with the following num-
eral, unit word or measure word, it will be seg-
mented. If the last character is productive in a 
limited manner, it forms a word unit with the 
preceding word, for example, ????? (Tokyo 
Metropolis), ?8?? (August) or ????? (acce-
lerator). But if it is a productive suffix like plural 
suffix and noun for locality, it is segmented in-
dependently in Chinese word segmentation rule, 
for example, ???|?? (friends), ???|??? 
(north of the Yangtzi River ) or ???|?? (on 
the table) in Chinese. They may have different 
phenomena in each language. 
Negation character of verb and adjective is 
segmented independently in Chinese, but they 
form one word unit in Japanese. For example, 
?yasashikunai? (?????, not kind) is one 
word unit in Japanese, but ??|?? (not to write),  
??| ?? (cannot),  ??|??? (did not research) 
and ?? | ??? (not completed) will be seg-
mented independently in Chinese. In Korean, 
?chinjeolhaji anhta? (???? ??, not kind) 
has one space inserted between two eojeols but it 
could be one word unit. ?ji anhta? makes nega-
tion of adjectival stem ?chinjeolha?.  
We will carefully investigate what principles 
of word units will be applied and what kind of 
conflicts exists. Because the motivation of word 
segmentation standard is to recommend what 
word units should be registered in a type of lex-
icon (where it is not the lexicon in linguistics but 
any kind of practical indexed container for word 
units), it has two possibly conflicting principles. 
For example, principles of unproductivity, fre-
quency, and granularity could cause conflicts 
because they have different perspectives to de-
fine a word unit.  
3.1 Word Segmentation for Chinese 
For convenience of description, the specification 
in this section follows the convention that classi-
fies words into 13 types: noun, verb, adjective, 
pronoun, numeral, measure word, adverb, prepo-
sition, conjunction, auxiliary word, modal word, 
exclamation word, imitative word. 
3.1.1 Noun 
There is word unit specification for common 
nouns as follows: 
- Two-character word or compact two-character 
noun phrase, e.g., ??(beef) ??(steel) 
181
- Noun phrase with compact structure, if violate 
original meaning after segmentation, e.g., ??
?? (Active power) 
- Phrase consisting of adjective with noun, e.g., 
?? (green leave) 
- The meaning changed phrase consisting of ad-
jective, e.g., ???(young wife)  
- Prefix with noun, e.g., ??(elder brother) ?
? (old eagle) ??? (nonmetal)  ???
(ultrasonic) 
- Noun segmentation unit with following postfix 
(e.g. ? ? ? ? ? ? ? ? ?), e.g., ???
(scientist) 
- Noun segmentation unit with prefix and postfix, 
e.g., ???(superconductance) 
- Time noun or phrase, e.g., ??(May), 11 ? 
42 ? 8 ?(forty two minutes and eight seconds 
past eleven), ??(the day before yesterday), 
??(First day of a month in the Chinese lunar 
calendar )   
But the followings are independent word 
units for noun of locality (e.g., ??|? (on the 
table), ??|?? (north of the Yangtzi River)), 
and the ??? suffix referring to from a plural of 
front noun (e.g., ?? ?(friends) ) except ??
??, ?????(pals),  ?????(guys), etc. Prop-
er nouns have similar specification. 
3.1.2 Verb 
The following verb forms will be one word unit 
as: 
- Various forms of reiterative verb, e.g., ??
(look at), ????(come and go) 
- Verb?object structural word, or compact and 
stably used verb phrase, e.g., ??(meeting)  ?
?(dancing) 
- Verb?complement structural word (two-
character), or stably used Verb-complement 
phrase (two-character), e.g., ??(improve) 
- Adjective with noun word, and compact, and 
stably used adjective with noun phrase, e.g., ?
?(make trouble) ,  ??(talk nonsense) 
- Compound directional verb, e.g., ??(go out)  
??(come in). 
But the followings are independent word 
units: 
- ?AAB, ABAB? or ?A? A, A? A, A?? A?, 
e.g., ??|??(have a discuss), ?|?|? (have 
a good chat) 
- Verb delimited by a negative meaning charac-
ters, e.g., ?|?(not to write)   ?|?(cannot)    
?|??(did not research)    ?|??(not com-
pleted) 
- ?Verb + a negative meaning Chinese character 
+  the same verb" structure, e.g., ??|?|?(say 
or not say)?? 
- Incompact or verb?object structural phrase with 
many similar structures, e.g., ? |?(Eat fish)    
?|??(learn skiing) 
- ?2with1? or ?1with2? structural verb- comple-
ment phrase, e.g., ??|?(clean up), ?|??
(speak clearly),  ??|??(explain clearly) 
- Verb-complement word for phrase, if inserted 
with ?? or ??, e.g., ?|?|? (able to knock 
down), and compound directional verb of direc-
tion, e.g., ?|?|?(able to go out) 
- Phrase formed by verb with directional verb, 
e.g., ?|?(send), ?|?|?(run out) 
- Combination of independent single verbs with-
out conjunction, e.g., ?|?(cover with), ?|?,  
?|? (listen, speaking, read and write) 
- Multi-word verb without conjunction, e.g., ?
?|??(investigate and research) 
3.1.3 Adjective 
One word unit shall be recognized in the follow-
ing cases: 
- Adjective in reiterative form of ?AA, AABB, 
ABB, AAB, A+"?"+AB?, e.g., ??(big), ?
???(careless), except the adjectives in rei-
terative form of ?ABAB?, e.g., ?? |??
(snowy white)     
- Adjective phrase in from of ?? A? B??
A? B?? A? B?? A? B?? A? B?, 
e.g., ????(wholeheartedly) 
- Two single-character adjectives with word fea-
tures varied, ?? (long-short)  ?? (deep-
shallow)  ??(big-small) 
- Color adjective word or phrase, e.g., ??(light 
yellow)   ???(olive green) 
But the followings are segmented as indepen-
dent word units: 
- Adjectives in parataxis form and maintaining 
original adjective meaning, e.g., ? |???
(size), ?? |??(glory) 
- Adjective phrase in positive with negative form 
to indicate question, e.g., ??| ?| ??(easy 
or not easy), except the brachylogical one like 
????(easy or not). 
3.1.4 Pronoun 
The followings shall be one word unit: 
182
- Single-character pronoun with ???, e.g.,?? 
(we) 
- ??????? with unit word ??? or ???
????????, e.g., ??(this) 
- Interrogative adjective or phrase, e.g., ??
(how many) 
But, the following will be independent word 
units: 
- ???????  with numeral , unit word or 
noun word segmentation unit, e.g., ? |? ?
(these 10 days), ?| ?(that person) 
- Pronoun of ???????????????, 
etc. shall be segmented from followed measure 
word or noun, e.g., ?| ? (each country), ?| 
?(each type). 
3.1.5 Numeral 
The followings will be one word unit: 
- Chinese digit word, e.g., ?????????
???(180,040,723) 
- ???? percent in fractional number, e.g., ? 
???(third fifth) 
- Paratactic numerals indicating approximate 
number, e.g., ?? ??(eight or nine kg) 
On the other hand, Independent word unit cas-
es are as follows: 
- Numeral shall be segmented from measure 
word, e.g., ?| ?(three) 
- Ordinal number of ???  shall be segmented 
from followed numeral, e.g., ? ? (first) 
- ?????????????, used after adjec-
tive or verb for indicating approximate number. 
3.1.6 Measure word 
Reiterative measure word and compound meas-
ure word or phrase is a word unit, e.g., ??
(every year), ?? man/year. 
3.1.7 Adverb 
Adverb is one word unit. But????????
???, etc. acting as conjunction shall be seg-
mented, e.g., ? ? ? ?(sweet yet savory). 
3.1.8 Preposition 
It is one word unit. For example, ??(be born 
in), and  ????(according to the regulations). 
3.1.9 Conjunction 
Conjunction shall be deemed as segmentation 
unit. 
3.1.10 Auxiliary word 
Structural auxiliary word ????????? 
and tense auxiliary word ??????? are one 
word unit, e.g., ? |? |?  (his book), ? |?
(watched). But the auxiliary word ??? shall be 
segmented from its followed verb, e.g., ?  ?
(what one thinks).  
3.1.11 Modal word 
It is one word unit, e.g., ???? (How are 
you?). 
3.1.12 Exclamation word 
Exclamation word shall be deemed as segmenta-
tion unit. For example, ??????? (How 
beautiful it is!) 
3.1.13 Imitative word 
It is one word unit like ???? (tinkle).  
3.2 Word Segmentation for Japanese 
For convenience of description, the specification 
in this section follows the convention that classi-
fies words into mainly 10 types: meishi (noun), 
doushi (verb), keiyoushi (adjective), rentaishi 
(adnominal noun: only used in adnominal usage), 
fukushi (adverb), kandoushi (exclamation), set-
suzoushi (conjunction), setsuji (affix), joshi (par-
ticle), and jodoushi (auxiliary verb). These parts 
of speech are divided into more detailed classes 
in terms of grammatical function. 
The longest "word segmentation" corresponds 
to ?Bunsetsu? in Japanese. 
3.2.1 Noun 
When a noun is a member constituting a sentence, 
it is usually followed by a particle or auxiliary 
verb (e.g. ???? (neko_ga) which is composed 
from ?Noun + a particle for subject marker?). 
Also, if a word like an adjective or adnominal 
noun modifies a noun, then a modifier (adjec-
tives, adnominal noun, adnominal phrases) and a 
modificand (a noun) are not segmented. 
3.2.2 Verb 
A Japanese verb has an inflectional ending. The 
ending of a verb changes depending on whether 
it is a negation form, an adverbial form, a base 
form, an adnominal form, an assumption form, or 
an imperative form. Japanese verbs are often 
used with auxiliary verbs and/or particles, and a 
verb with auxiliary verbs and/or particles is con-
sidered as a word segmentation unit (e.g. ???
??? ? (aruki_mashi_ta) is composed from 
?Verb + auxiliary verb for politeness + auxiliary 
verb for tense?). 
3.2.3 Adjective 
A Japanese adjective has an inflectional ending. 
Based on the type of inflectional ending, there 
183
are two kinds of adjectives, "i_keiyoushi" and 
"na_keiyoushi". However, both are treated as 
adjectives. 
In terms of traditional Japanese linguistics, 
?keiyoushi? refers to ?i_keiyoushi?(e.g. ???, 
utsukushi_i) and ?keiyoudoushi?(e.g. ??? , 
shizuka_na) refers to ?na_keiyoushi.? In terms of 
inflectional ending of ?na_keiyoushi,? it is some-
times said to be considered as ?Noun + auxiliary 
verb (da)?. 
The ending of an adjective changes depending 
on whether it is a negation form, an adverbial 
form, a base form, an adnominal form, or an as-
sumption form. Japanese adjectives in predica-
tive position are sometimes used with auxiliary 
verbs and/or particles, and they are considered as 
a word segmentation unit. 
3.2.4 Adnominal noun 
An adnominal noun does not have an inflectional 
ending; it is always used as a modifier. An ad-
nominal noun is considered as one segmentation 
unit. 
3.2.5 Adverb 
An adverb does not have an inflectional ending; 
it is always used as a modifier of a sentence or a 
verb. It is considered as one segmentation unit. 
3.2.6 Conjunction 
A conjunction is considered as one segmentation 
unit. 
3.2.7 Exclamation 
An exclamation is considered as one segmenta-
tion unit. 
3.2.8 Affix 
A prefix and a suffix used as a constituent of a 
word should not be segmented as a word unit. 
3.2.9 Particle 
Particles can be divided into two main types. 
One is a case particle which serves as a case 
marker. The other is an auxiliary particle which 
appears at the end of a phrase or a sentence. 
Auxiliary particles represent a mood and a 
tense. 
Particles should not be segmented from a word. 
A particle is always used with a word like a noun, 
a verb, or an adjective, and they are considered 
as one segmentation unit. 
3.2.10 Auxiliary verb 
Auxiliary verbs represent various semantic func-
tions such as a capability, a voice, a tense, an 
aspect and so on. An auxiliary verb appears at 
the end of a phrase or a sentence. Some linguist 
consider ??? (da), which is Japanese copura, as 
a specific category such as ???(hanteishi).   
An auxiliary verb should not be segmented 
from a word. An auxiliary verb is always used 
with a word like a noun, a verb, or an adjective, 
and is considered as one segmentation unit. 
3.2.11 Idiom and proverb 
Proverbs, mottos, etc. should be segmented if 
their original meanings are not violated after 
segmentation. For example: 
Kouin yano  gotoshi 
noun  noun+particle auxiliary verb 
time  arrow  like (flying) 
Time flies fast. 
3.2.12 Abbreviation 
An abbreviation should not be segmented. 
3.3 Word Segmentation for Korean 
For convenience of description, the specification 
in this section follows the convention that classi-
fies words into 12 types: noun, verb, adjective, 
pronoun, numeral, adnominal, adverb, exclama-
tion, particle, auxiliary verb, auxiliary adjective, 
and copula. The basic parts of speech can be di-
vided into more detailed classes in terms of 
grammatical function. Classification in this paper 
is in accord with the top level of MAF. 
In addition, we treat some multi-Eojeol units 
as the word unit for practical purpose. Korean 
Eojeol is a spacing unit that consists of one con-
tent word (like noun, verb) and series of func-
tional elements (particles, word endings). Func-
tional elements are not indispensable. Eojeol is 
similar with Bunsetsu from some points, but an 
Eojeol is recognized by white space in order to 
enhance the readability that enables to use only 
Hangul alphabet in the usual writing.  
3.3.1 Noun 
When a noun is a member constituting a sentence, 
it is usually followed by a particle. (e.g. 
???_?? (saja_ga, ?a lion is?) which is com-
posed from ?Noun + a particle for subject mark-
er?). Noun subsumes common noun, proper noun, 
and bound noun.  
If there are two frequently concatenated Eoje-
ols that consist of modifier (an adjective or an 
adnominal) and modificand (a noun), they can be 
one word unit according to the principle of lan-
guage economy. Other cases of noun word unit 
are as follows: 
1) Compound noun that consists of two more 
nouns can be a word unit. For example, 
184
???? (son_mok, ?wrist?) where son+mok 
= ?hand?+?neck?. 
2) Noun phrase that denotes just one concept 
can be a word unit. For example, ???? 
??? (yesul_ui jeondang, ?sanctuary of the 
arts? that is used for the name of concert 
hall). 
3.3.2 Verb  
A Korean verb has over one inflectional endings. 
The endings of a verb can be changed and at-
tached depending on grammatical function of 
verb (e.g. ??/??/?/?/?/?/?? (break 
[+emphasis] [+polite] [+past] [+conjectural] final 
ending [+polite]). Compound verb (verb+verb, 
noun+verb, adverb+verb) can be a segmentation 
unit by right. For example, ?????? (dola-
ga-da, ?pass away?) is literally translated into 
?go+back? (verb+verb).  ????? (bin-na-da, 
?be shiny?) is derived from ?light + come out? 
(noun+verb). ?????? (baro-jap-da, ?cor-
rect?) is one word unit but it consists of 
?rightly+hold? (adverb+verb).  
3.3.3 Adjective 
A Korean adjective has inflectional endings like 
verb. For example, in ???/?/?/?/?/?? 
(pretty [+polite] [+past] [+conjectural] final end-
ing [+polite]), one adjective has five endings. 
Compound adjective can be a segmentation unit 
by right. (e.g. ????? (geom-buk-da, ?be 
blackish red?)) 
3.3.4 Adnominal  
An adnominal is always used as a modifier for 
noun. Korean adnominal is not treated as noun 
unlike Japanese one. (e.g. ?? ?? (sae jip, ?new 
house?)? which consist of ?adnominal + noun?). 
3.3.5 Adverb 
An adverb does not have an inflectional ending; 
it is always used as a modifier of a sentence or a 
verb. In Korean, adverb includes conjunction. It 
is considered as one segmentation unit. Com-
pound adverb can be a segmentation unit by right. 
Examples are ???? (bam-nat, ?day and night?), 
and ???? (gotgot, ?everywhere? whose literal 
translation is ?where where?). 
3.3.6 Pronoun 
A pronoun is considered as one segmentation 
unit. Typical examples are ??? (na, ?I?), ??? 
(neo, ?you?), and ???? (uri, ?we). Suffix of 
plural ??? (deul, ?-s?) can be attached to some 
of pronouns in Korean. (e.g. ????? (neohui-
deul, ?you+PLURAL?), ???? (geu-deul, ?they? 
= ?he/she+PLURAL?)). 
3.3.7 Numeral 
A numeral is considered as one segmentation 
unit: e.g. ???? (hana, ?one?), ???? (cheojjae, 
?first?). Also figures are treated as one unit like 
?2009?? (the year 2009). 
3.3.8 Exclamation 
An exclamation is considered as one segmenta-
tion unit. 
3.3.9 Particle 
Korean particles can not be segmented from a 
word just like Japanese particles. A particle is 
always used with a word like a noun, a verb, or 
an adjective, but it is considered as one segmen-
tation unit. 
Particles can be divided into two main types. 
One is a case particle that serves as a case marker. 
The other is an auxiliary particle that appears at 
the end of a phrase or a sentence. Auxiliary par-
ticle represents a mood and a tense. 
3.3.10 Auxiliary verb 
A Korean auxiliary verb represents various se-
mantic functions such as a capability, a voice, a 
tense, an aspect and so on.  
Auxiliary verb is only used with a verb plus 
endings with special word ending depending on 
the auxiliary verb. For example, ???? (boda, 
?try to?), an auxiliary verb has the same inflec-
tional endings but it should follow a main verb 
with a connective ending ??? (eo) or ??? (?go?).  
Consider ?try to eat? in English where ?eat? is a 
main verb, and ?try? is an auxiliary verb with 
specialized connective ?to?. In this case, we need 
two Korean Eojeols that corresponds to ?eat + 
to? and ?try?. Because ?to? is a functional ele-
ment that is attached after main verb ?eat?, it 
constitutes one Eojeol. It causes a conflict be-
tween Eojeol and word unit. That means every 
Eojeol cannot be a word unit. What are the word 
units and Eojeols in this case? There are two 
choices: (1) ?eat+to? and ?try?, (2) ?eat?+ ?to 
try?. According to the definition of Eojeol, (1) is 
correct for two concatenated Eojeols. But if the 
syntactic processing is preferable, (2) is more 
likely to be a candidate of word units.  
3.3.11 Auxiliary adjective 
Unlike Japanese, there is auxiliary adjective in 
Korean. Function and usage of it are very similar 
to auxiliary verb. Auxiliary adjective is consi-
dered as one segmentation unit. 
185
Auxiliary verb can be used with a verb or ad-
jective plus endings with special word ending 
depending on the auxiliary adjective. For exam-
ple, in ??? ??? (meokgo sipda, ?want to 
eat?), sipda is an auxiliary adjective whose mean-
ing is ?want? while meok is a main verb ?want? 
and go corresponds to ?to?; so meokgo is ?to eat?.  
3.3.12 Copula 
A copula is always used for changing the func-
tion of noun. After attaching the copula, noun 
can be used like verb. It can be segmented for 
processing. 
3.3.13 Idiom and proverb 
Proverbs, mottos, etc. should be segmented if 
their original meanings are not violated after 
segmentation like Chinese and Japanese. 
3.3.14 Ending 
Ending is attached to the root of verb and adjec-
tive. It means honorific, tense, aspect, modal, etc. 
There are two endings: prefinal ending and fi-
nal ending. They are functional elements to 
represent honorific, past, or future functions in 
prefinal position, and declarative (-da) or con-
cessive (-na)-functions in final ending. Ending is 
not a segmentation unit in Korean. It is just a unit 
for inflection. 
3.3.15 Affix 
A prefix and a suffix used as a constituent of a 
word should not be segmented as a word unit. 
4 Conclusion 
Word segmentation standard is to recommend 
what type of word sequences should be identified 
as one word unit in order to process the syntactic 
parsing. Principles of word segmentation want to 
provide the measure of such word units. But 
principles of frequency and language economy 
are based on a statistical measure, which will be 
decided by some practical purpose.  
Word segmentation in each language is 
somewhat different according to already made 
word segmentation regulation, even violating one 
or more principles of word segmentation. In the 
future, we have to discuss the more synchronized 
word unit concept because we now live in a mul-
ti-lingual environment. For example, consider 
figure 3. Its English literal translation is ?white 
vegetable and pig meat?, where ?white vegeta-
ble? (??) is an unproductive word pattern and 
forms one word unit without component word 
units, and ?pig meat? in Chinese means one Eng-
lish word ?pork?. So ?pig meat? (??) is the 
longest word unit in this case. But in Japanese 
and Korean, ?pig meat? in Chinese characters 
cannot be two word units, because each compo-
nent character is not used independently. 
 
Figure 3. Basic segmentation and word segmenta-
tion [ISO/CD 24614-1] 
What could be shared among three languages 
for word segmentation? The common things are 
not so much among CJK. The Chinese character 
derived nouns are sharable for its word unit 
structure, but not the whole. On the other hand, 
there are many common things between Korean 
and Japanese. Some Korean word endings and 
Japanese auxiliary verbs have the same functions. 
It will be an interesting study to compare for the 
processing purpose.  
The future work will include the role of word 
unit in machine translation. If the corresponding 
word sequences have one word unit in one lan-
guage, it is one symptom to recognize one word 
unit in other languages. It could be ?principle of 
multi-lingual alignment.?   
The concept of ?word unit? is to broaden the 
view about what could be registered in lexicon of 
natural language processing purpose, without 
much linguistic representation. In the result, we 
would like to promote such language resource 
sharing in public, not just dictionaries of words 
in usual manner but of word units. 
Acknowledgement 
This work has been supported by ISO/TC37, 
KATS and Ministry of Knowledge Economy 
(ROKorea), CNIS and SAC (China), JISC (Ja-
pan) and CSK (DPRK) with special contribution 
of Jeniffer DeCamp (ANSI) and Kiyong Lee. 
References 
ISO CD24614-1, Language Resource Management ? 
Word segmentation of written texts for monolin-
gual and multilingual information processing ? Part 
1: Basic concepts and general principles, 2009.  
ISO WD24614-2, ? Part 2: Word segmentation for 
Chinese, Japanese and Korean, 2009. 
186
A Limited-Domain English to Japanese Medical Speech Translator
Built Using REGULUS 2
Manny Rayner
Research Institute for Advanced
Computer Science (RIACS),
NASA Ames Research Center,
Moffet Field, CA 94035
mrayner@riacs.edu
Pierrette Bouillon
University of Geneva
TIM/ISSCO,
40, bvd du Pont-d?Arve,
CH-1211 Geneva 4,
Switzerland
pierrette.bouillon@issco.unige.ch
Vol Van Dalsem III
El Camino Hospital
2500 Grant Road
Mountain View, CA 94040
vvandal3@aol.com
Hitoshi Isahara, Kyoko Kanzaki
Communications Research Laboratory
3-5 Hikaridai
Seika-cho, Soraku-gun
Kyoto, Japan 619-0289
{isahara,kanzaki}@crl.go.jp
Beth Ann Hockey
Research Institute for Advanced
Computer Science (RIACS),
NASA Ames Research Center,
Moffet Field, CA 94035
bahockey@riacs.edu
Abstract
We argue that verbal patient diagnosis is a
promising application for limited-domain
speech translation, and describe an ar-
chitecture designed for this type of task
which represents a compromise between
principled linguistics-based processing on
the one hand and efficient phrasal transla-
tion on the other. We propose to demon-
strate a prototype system instantiating this
architecture, which has been built on top
of the Open Source REGULUS 2 platform.
The prototype translates spoken yes-no
questions about headache symptoms from
English to Japanese, using a vocabulary of
about 200 words.
1 Introduction and motivation
Language is crucial to medical diagnosis. Dur-
ing the initial evaluation of a patient in an emer-
gency department, obtaining an accurate history of
the chief complaint is of equal importance to the
physical examination. In many parts of the world
there are large recent immigrant populations that re-
quire medical care but are unable to communicate
fluently in the local language. In the US these im-
migrants are especially likely to use emergency fa-
cilities because of insurance issues. In an emer-
gency setting there is acute need for quick accurate
physician-patient communication but this communi-
cation is made substantially more difficult in cases
where there is a language barrier. Our system is
designed to address this problem using spoken ma-
chine translation.
Designing a spoken translation system to obtain
a detailed medical history would be difficult if not
impossible using the current state of the art. The
reason that the use of spoken translation technol-
ogy is feasible is because what is actually needed in
the emergency setting is more limited. Since medi-
cal histories traditionally are obtained through two-
way physician-patient conversations that are mostly
physician initiative, there is a preestablished limiting
structure that we can follow in designing the trans-
lation system. This structure allows a physician to
sucessfully use one way translation to elicit and re-
strict the range of patient responses while still ob-
taining the necessary information.
Another helpful constraint on the conversational
requirements is that the majority of medical condi-
tions can be initiatlly characterized by a relatively
small number of key questions about quality, quan-
tity and duration of symptoms. For example, key
questions about chest pain include intensity, loca-
tion, duration, quality of pain, and factors that in-
crease or decrease the pain. These answers to these
questions can be sucessfully communicated by a
limited number of one or two word responses (e.g.
yes/no, left/right, numbers) or even gestures (e.g.
pointing to an area of the body). This is clearly a
domain in which the constraints of the task are suf-
ficient for a limited domain, one way spoken trans-
lation system to be a useful tool.
2 An architecture for limited-domain
speech translation
The basic philosophy behind the architecture of the
system is to attempt an intelligent compromise be-
tween fixed-phrase translation on one hand (e.g.
(IntegratedWaveTechnologies, 2002)) and linguisti-
cally motivated grammar-based processing on the
other (e.g. VERBMOBIL (Wahlster, 2000) and Spo-
ken Language Translator (Rayner et al, 2000a)).
At run-time, the system behaves essentially like a
phrasal translator which allows some variation in the
input language. This is close in spirit to the approach
used in most normal phrase-books, which typically
allow ?slots? in at least some phrases (?How much
does ? cost??; ?How do I get to ? ??). However,
in order to minimize the overhead associated with
defining and maintaining large sets of phrasal pat-
terns, these patterns are derived from a single large
linguistically motivated unification grammar; thus
the compile-time architecture is that of a linguisti-
cally motivated system. Phrasal translation at run-
time gives us speed and reliability; the linguistically
motivated compile-time architecture makes the sys-
tem easy to extend and modify.
The runtime system comprises three main mod-
ules. These are respectively responsible for source
language speech recognition, including parsing and
production of semantic representation; transfer and
generation; and synthesis of target language speech.
The speech processing modules (recognition and
synthesis) are implemented on top of the standard
Nuance Toolkit platform (Nuance, 2003). Recogni-
tion is constrained by a CFG language model written
in Nuance Grammar Specification Language (GSL),
which also specifies the semantic representations
produced. This language model is compiled from
a linguistically motivated unification grammar us-
ing the Open Source REGULUS 2 platform (Rayner
et al, 2003; Regulus, 2003); the compilation pro-
cess is driven by a small corpus of examples. The
language processing modules (transfer and genera-
tion) are a suite of simple routines written in SICStus
Prolog. The speech and language processing mod-
ules communicate with each other through a mini-
mal file-based protocol.
The semantic representations on both the source
and target sides are expressed as attribute-value
structures. In accordance with the generally mini-
malistic design philosophy of the project, semantic
representations have been kept as simple as possi-
ble. The basic principle is that the representation of
a clause is a flat list of attribute-value pairs: thus for
example the representation of ?Did your headache
start suddenly?? is the attribute-value list
[[utterance_type,ynq],[tense,past],
[symptom,headache],[state,start],
[manner,suddenly]]
In a broad domain, it is of course trivial to con-
struct examples where this kind of representation
runs into serious problems. In the very narrow do-
main of a phrasebook translator, it has many desir-
able properties. In particular, operations on semantic
representations typically manipulate lists rather than
trees. In a broad domain, we would pay a heavy
price: the lack of structure in the semantic represen-
tations would often make them ambiguous. The very
simple ontology of the phrasebook domain however
means that ambiguity is not a problem; the compo-
nents of a flat list representation can never be de-
rived from more than one functional structure, so
this structure does not need to be explicitly present.
Transfer rules define mappings of sets of attribute-
value pairs to sets of attribute-value pairs; the ma-
jority of the rules map single attribute-value pairs
to single attribute-value pairs. Generation is han-
dled by a small Definite Clause Grammar (DCG),
which converts attribute-value structures into sur-
face strings; its output is passed through a minimal
post-transfer component, which applies a set of rules
which map fixed strings to fixed strings. Speech syn-
thesis is performed either by the Nuance Vocalizer
TTS engine or by concatenation of recorded wave-
files, depending on the output language.
One of the most important questions for a med-
ical translation system is that of reliability; we ad-
dress this issue using the methods of (Rayner and
Bouillon, 2002). The GSL form of the recognition
grammar is run in generation mode using the Nu-
ance generate utility to generate large numbers
of random utterances, all of which are by construc-
tion within system coverage. These utterances are
then processed through the system in batch mode us-
ing all-solutions versions of the relevant processing
algorithms. The results are checked automatically
to find examples where rules are either deficient or
ambiguous. With domains of the complexity under
consideration here, we have found that it is feasible
to refine the rule-sets in this way so that holes and
ambiguities are effectively eliminated.
3 A medical speech translation system
We have built a prototype medical speech transla-
tion system instantiating the functionality outlined
in Section 1 and the architecture of Section 2. The
system permits spoken English input of constrained
yes/no questions about the symptoms of headaches,
using a vocabulary of about 200 words. This is
enough to support most of the standard examina-
tion questions for this subdomain. There are two
versions of the system, producing spoken output in
French and Japanese respectively. Since English ?
Japanese is distinctly the more interesting and chal-
lenging language pair, we will focus on this version.
Speech recognition and source language analy-
sis are performed using REGULUS 2. The grammar
is specialised from the large domain-independent
grammar using the methods sketched in Section 2.
The training corpus has been constructed by hand
from an initial corpus supplied by a medical pro-
fessional; the content of the questions was kept un-
changed, but where necessary the form was revised
to make it more appropriate to a spoken dialogue.
When we felt that it would be difficult to remem-
ber what the canonical form of a question would
be, we added two or three variant forms. For exam-
ple, we permit ?Does bright light make the headache
worse?? as a variant for ?Is the headache aggra-
vated by bright light??, and ?Do you usually have
headaches in the morning?? as a variant for ?Does
the headache usually occur in the morning??. The
current training corpus contains about 200 exam-
ples.
The granularity of the phrasal rules learned by
grammar specialisation has been set so that the con-
stituents in the acquired rules are VBARs, post-
modifier groups, NPs and lexical items. VBARs
may include both inverted subject NPs and adverbs1.
Thus for example the training example ?Are the
headaches usually caused by emotional upset?? in-
duces a top-level rule whose context-free skeleton is
UTT --> VBAR, VBAR, POSTMODS
For the training example, the first VBAR in the in-
duced rule spans the phrase ?are the headaches usu-
ally?, the second VBAR spans the phrase ?caused?,
and the POSTMODS span the phrase ?by emotional
upset?. The same rule could potentially be used to
cover utterances like ?Is the pain sometimes pre-
ceded by nausea?? and ?Is your headache ever as-
sociated with blurred vision??. The same training
example will also induce several lower-level rules,
the least trivial of which are rules for VBAR and
POSTMODS with context-free skeletons
VBAR --> are, NP, ADV
POSTMODS --> P, NP
The grammar specialisation method is described in
full detail in (Rayner et al, 2000b).
With regard to the transfer component, we have
had two main problems to solve. Firstly, it is well-
known that translation from English to Japanese re-
quires major reorganisation of the syntactic form.
Word-order is nearly always completely different,
and category mismatches are very common. It is
mainly for this reason that we chose to use a flat
semantic representation. As long as the domain is
simple enough that the flat representations are un-
ambiguous, transfer can be carried out by mapping
lists of elements into lists of elements. For example,
we translate ?are your headaches caused by fatigue?
as ?tsukare de zutsu ga okorimasu ka? (lit. ?fatigue-
CAUSAL headache-SUBJ occur-PRESENT QUES-
TION?). Here, the source-language representation is
[[utterance_type,ynq],
[tense,present],
[symptom,headache],
[event,cause],
[cause,fatigue]]
and the target-language one is
[[utterance_type,sentence],
[tense,present],
[symptom,zutsu],
1This non-standard definition of VBAR has technical advan-
tages discussed in (Rayner et al, 2000c)
do your headaches often appear at night ?
yoku yoru ni zutsu ga arimasu ka
(often night-AT headache-SUBJ is-PRES-Q)
is the pain in the front of the head ?
itami wa atama no mae no hou desu ka
(pain-TOPIC head-OF front side is-PRES-Q)
did your headache start suddenly ?
zutsu wa totsuzen hajimari mashita ka
(headache-TOPIC sudden start-PRES-Q)
have you had headaches for weeks ?
sushukan zutsu ga tsuzuite imasu ka
(weeks headache-SUBJ have-CONT-PRES-Q)
is the pain usually superficial ?
itsumo itami wa hyomenteki desu ka
(usually pain-SUBJ superficial is-PRES-Q)
is the severity of the headaches increasing ?
zutsu wa hidoku natte imasu ka
(headache-TOPIC severe becoming is-PRES-Q)
Table 1: Examples of utterances covered by the pro-
totype
[event,okoru],[postpos,causal],
[cause,tsukare]]
Each line in the source representation maps into the
corresponding one in the target in the obvious way.
The target-language grammar is constrained enough
that there is only one Japanese sentence which can
be generated from the given representation.
The second major problem for transfer relates to
elliptical utterances. These are very important due
to the one-way character of the interaction: instead
of being able to ask a WH-question (?What does
the pain feel like??), the doctor needs to ask a se-
ries of Y-N questions (?Is the pain dull??, ?Is the
pain burning??, ?Is the pain aching??, etc). We
rapidly found that it was much more natural for
questions after the first one to be phrased ellipti-
cally (?Is the pain dull??, ?Burning??, ?Aching??).
English and Japanese have however different con-
ventions as to what types of phrase can be used
elliptically. Here, for example, it is only pos-
sible to allow some types of Japanese adjectives
to stand alone. Thus we can grammatically and
semantically say ?hageshii desu ka? (lit. ?burn-
ing is-QUESTION?) but not ?*uzukuyona desu
ka? (lit. ?*aching is-QUESTION?). The prob-
lem is that adjectives like ?uzukuyona? must com-
bine adnominally with a noun in this context:
thus we in fact have to generate ?uzukuyona itami
desu ka? (?aching-ADNOMINAL-USAGE pain is-
QUESTION?). Once again, however, the very lim-
ited domain makes it practical to solve the problem
robustly. There are only a handful of transforma-
tions to be implemented, and the extra information
that needs to be added is always clear from the sortal
types of the semantic elements in the target represen-
tation.
Table 1 gives examples of utterances covered by
the system, and the translations produced.
References
IntegratedWaveTechnologies, 2002. http://www.i-w-
t.com/investor.html. As of 15 Mar 2002.
Nuance, 2003. http://www.nuance.com. As of 25 Febru-
ary 2003.
M. Rayner and P. Bouillon. 2002. A phrasebook style
medical speech translator. In Proceedings of the 40th
Annual Meeting of the Association for Computational
Linguistics (demo track), Philadelphia, PA.
M. Rayner, D. Carter, P. Bouillon, V. Digalakis, and
M. Wire?n, editors. 2000a. The Spoken Language
Translator. Cambridge University Press.
M. Rayner, D. Carter, and C. Samuelsson. 2000b. Gram-
mar specialisation. In Rayner et al (Rayner et al,
2000a).
M. Rayner, B.A. Hockey, and F. James. 2000c. Compil-
ing language models from a linguistically motivated
unification grammar. In Proceedings of the Eighteenth
International Conference on Computational Linguis-
tics, Saarbrucken, Germany.
M. Rayner, B.A. Hockey, and J. Dowding. 2003. An
open source environment for compiling typed unifica-
tion grammars into speech recognisers. In Proceed-
ings of the 10th EACL (demo track), Budapest, Hun-
gary.
Regulus, 2003. http://sourceforge.net/projects/regulus/.
As of 24 April 2003.
W. Wahlster, editor. 2000. Verbmobil: Foundations of
Speech-to-Speech Translation. Springer.
Extraction and Verification of KO-OU Expressions from Large Corpora 
Atsuko kida?,  Eiko Yamamoto?,  Kyoko Kanzaki?,  and  Hitoshi Isahara? 
?The Institute of Behavioral Sciences                       ?Communications Research Laboratory 
2-9 Honmura-cho, Ichigaya, Shinjuku-ku,                 3-5 Hikari-dai, Seika-cho, Souraku-gun, 
Tokyo, 162-0845, Japan                                              Kyoto, 619-0289, Japan 
akida@ibs.or.jp {eiko,kanzaki,isahara}@crl.go.jp
 
 
 
Abstract 
In the Japanese language, as a predicate is 
placed at the end of a sentence, the con-
tent of a sentence cannot be inferred until 
reaching the end. However, when the con-
tent is complicated and the sentence is 
long, people want to know at an earlier 
stage in the sentence whether the content 
is negative, affirmative, or interrogative. 
In Japanese, the grammatical form called 
the KO-OU relation exists. The KO-OU 
relation is a kind of concord. If a KO ele-
ment appears, then an OU element ap-
pears in the latter part of a sentence. It is 
being pointed out that the KO-OU relation 
gives advance notice to the element that 
appears in the latter part of a sentence. In 
this paper, we present the method of ex-
tracting automatically the KO-OU expres-
sion data from large-scale electronic 
corpus and verify the usefulness of the 
KO-OU expression data. 
1 Introduction 
The Japanese language has a grammatical form 
called the KO-OU relation. The KO-OU relation is 
a kind of concord, also referring to a sort of bound 
relation that a KO element appearing in a sentence 
is followed by an OU element in the latter part of 
the same sentence. On the contrary, the cooccur-
rence relation refers to two words appearing in the 
same sentence. 
Because Japanese predicates are usually located 
at the end of sentences, the contents of Japanese 
sentences cannot be decided until reaching the end. 
Furthermore, in Japanese, it is hard to comprehend 
the meaning of the sentence without reading 
through the entire sentence. The KO-OU relation is 
the grammatical form which can be helpful for un-
derstanding the sentence meaning at the early stage. 
While in archaic Japanese, KAKARI-MUSUBI, 
which had morphemic KO-OU relation between 
KAKARI-JOSI1 and the conjugation at the end of a 
sentence, had been used. KAKARI-MUSUBI gave 
advance notice to the elements that would appear 
toward the end of a sentence due to KAKARI-JOSI. 
Today, KAKARI-MUSUBI has dropped out of use. 
However, the KO-OU relation such as "sika-nai 
(only)" or "kessite-nai (never)" is present. In this 
research, we have attempted to collect such ele-
ments to extract KO-OU expression data. In this 
paper, the main points of argument are as follows: 
(1) Method of extracting automatically the KO-OU 
expression data. 
(2) What the KO-OU expression data can be used 
for. 
2 The Previous Works and How to Posi-
tion this Study 
(Ohno, 1993) pointed out that there were expres-
sions that try to give advance notice to whether a 
sentence is affirmative, negative, or interrogative at 
the early stage of a language expression which 
continues timewise. It suggested that there were 
certain adverbs that have replaced KAKARI-JOSI 
in the archaic Japanese words. 
(Masuoka, 1991) described the KO-OU relation 
of sentence elements. According to Masuoka, some 
sentences have the KO-OU expressions as shown 
in Table 1.  
However, this has the following weaknesses. 
The KO and OU elements in a KO-OU relation are 
placed together in the same category, and there is 
                                                          
1 A Japanese particle. 
no description as to the OU element. Furthermore, 
only a limited number of elements are listed. And 
the objectivity of the KO and OU elements is not 
guaranteed. 
The KO-OU expression data is useful as basic 
data to dissolve ambiguity in parsing and to decide 
on the modification relation. However, first of all, 
it is necessary for the data to have a certain length 
for being useful basic data. Secondly, it also needs 
to be objective. Therefore, we have attempted to 
extract KO-OU relations automatically from large-
scale corpus. 
 
Table 1 Masuoka?s KO-OU expression data 
3 Assumed Usage of KO-OU Expression 
Data 
3.1 To Dissolve Ambiguity 
The KO-OU expression data is useful for dissolv-
ing ambiguity of parsing. Furthermore, it is useful 
for deciding the modification relation (Figure 1). 
3.2 Gradual Understanding 
Using the KO-OU expression data will enable the 
reader to guess the end expression midway through 
a sentence. This is because as the KO elements 
appear it is possible to predict the appearance of 
the OU elements (Figure 2). It can be used as a 
basic data for understanding sentences. In addition, 
this technology can be used to guess the point in 
the minutes of a meeting at which the speakers 
change. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 1 To Dissolve Ambiguity 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 2 Gradual Understanding 
 
KO element OU element 
Nee,  oi te-kudasai,  naa 
tabun,  doumo daro-u,  rasii,  you-da 
kessite,  kanarazu-si-mo nai 
conviction  
(If you chew it, you will certainly taste salmon.) 
                                                                          ??? 
 
??????????  ?? ?  ?  ?  ??     ?????  ? 
kamisimereba        kitto    sake  no  aji  ga   suru    ni-chiga-inai 
 
 
 
 
 
 
 
 
 
 
??????????  ?? ?  ?  ?  ??     ?????  ? 
kamisimereba        kitto    sake  no  aji  ga   suru    ni-chiga-inai 
 
To Dissolve 
Ambiguity  refer
KO element  OU element    Similarity score   Distance        Meaning 
 
kitto               ni-chigai-nai    0.004726           6.062697       conviction 
kitto               koto-daro-u      0.00418           11.297666       guess 
kitto hazu 0.003722 12.702345 conviction
KO-OU relation data (image) 
(Works that you see at the open seaside should look attractive.) 
 
???  ?? ? ?? ?? ?  ??? ???  ? ?? ?? ?? 
koudaina umibe de miru sakuhin wa   kitto  miryokuteki ni utsuru hazu  da 
 
 
? ? ? ? ? ? ? ? ?  ? ?  Gradual Understanding 
 
 
 
 
 
 
 
 
KO element  OU element    Similarity score   Distance        Meaning 
 
kitto               ni-chigai-nai    0.004726           6.062697       conviction
kitto               koto-daro-u      0.00418           11.297666       guess 
kitto               hazu               0.003722         12.702345     conviction
refer guess ? conviction ? 
 KO-OU relation data (image) 
4 Extraction of KO-OU Expression Data 
4.1 Method 
(Yamamoto and Umemura, 2002) considered the 
estimation of the one-to-many relation between 
entities in corpus. They carried out experiments 
on extracting one-to-many relation of phenomena 
from corpus using complementary similarity 
measure (CSM) which can cope very well with 
inclusion relation of appearance patterns. The KO-
OU relation in this research can be regarded as a 
type of one-to-many relation.  
4.2 Data Used 
In this paper, we dealt with what is called FUKU-
JOSI2, KAKARI-JOSI, and some adverbs shown 
below. We proceeded on the assumption that these 
are the KO elements in the KO-OU relation. For 
our research, we used newspaper articles from the 
Mainichi Shimbun, Nihon Keizai Shimbun, and 
Yomiuri Shimbun issued between 1991 and 2000. 
 
[Target words] 
koso, sika, sae, ha, mo, bakari, nomi, sura, nara, 
kurai, dake, nannte, kessite, osoraku, tabun, zehi, 
marude, mosi, kitto 
 
Figure 3 Process flow 
4.3 Process Flow 
Process flow is shown in Figure 3. 
(1) We calculated the similarity measure using 
CSM for newspaper articles data that had been 
morphologically analyzed with ChaSen3. 
(2) We extracted pairs containing the target words 
from the results of similarity measure calculation. 
                                                          
2 A Japanese particle. 
3 Morphological Analyzer ChaSen. See http://chasen.aist-
nara.ac.jp/. 
(3) Out of the pairs in (2), we extracted words that 
appeared in the order of KO and OU elements. 
(We judge the pairs based on this word order.) 
(4) We carried out judgment based on reliability. 
As a result of this process, we obtained 14 pairs 
of data which had "kesshite" as KO element, 16 
which had "sae," and 23 which had "wa." Data of 
approximately 20 pairs was obtained per target 
word.  
5 Verification of KO-OU Expression 
Data 
5.1 Necessity to Give Meaning/Information 
If the KO-OU expression data is used for gradual 
understanding of sentences, it was necessary for 
the data to be given meaning/information. When 
the KO element appears, it will be possible to suf-
ficiently grasp or guess the contents of a sentence 
by referring the KO-OU expression data (Figure2). 
However it is difficult to give mean-
ing/information using the data obtained from the 
process in Chapter 4 because the data is broken 
down into each morpheme by the morphological 
analysis, and each element is too short.  
In Japanese sentences, there are many cases in 
which continuation of a particle and an auxiliary 
verb builds a predicate. This continuation plays an 
important role in determining the event of the sen-
tence. Particles and auxiliary verbs are functional 
words. Therefore, it is not possible to determine 
the meaning of some of the particles and auxiliary 
verbs when they appeared independently. Fur-
thermore, there are some cases in which they 
change their meaning when paired with another 
word.  
Table 2 shows the OU elements obtained pursu-
ant to the procedure in Chapter 4 for KO element 
"kitto". "Da" listed in Table 2 has an assertive 
meaning when used in a sentence like "kyou wa 
ame da . (It is raining today.)" On the other hand, it 
has an inferential meaning in the context of "asu 
wa hareru daro-u . (It should be fine tomorrow.)" In 
addition, although "nai" is a negative auxiliary 
verb, when it is paired as in "ka-mo-shire-nai (may 
be)" and "chigai-nai (must be)," the negative mean-
ing disappears. And the overall pairing stands for 
guess and conviction. 
 
 
morphologically  
analyzed data
(1) Calculate similarity 
KO-OU expression data
(2) Extract pairs 
(3) Judgment based on word
(4) Judgment based on reliability. 
Table 2  KO-OU expression data 
KO element OU element KO element OU element 
Kitto u (auxiliary) kitto yo (particle) 
kitto da (auxiliary) kitto chigai (noun) 
kitto to (particle) kitto ka (particle) 
kitto omou (verb) kitto Ne (particle) 
kitto nai (auxiliary) kitto you (noun) 
kitto hazu (noun) : : 
5.2 Verification of OU Element Using 
"Kitto" 
In this section, we carry out an analytical example 
using OU element for KO element "kitto (cer-
tainly)." We can classify the OU elements obtained 
from the procedure in Chapter 4, as follows: 
(a) It can be an OU element by itself,  
(b) It can become an OU element when paired 
with others,  
(c) It does not have the possibility of becoming an 
OU element. 
Words of (c) were not found in the OU ele-
ments obtained for KO element "kitto." In the fol-
lowing, we will describe the details on (a) and (b). 
 (a) OU element by itself 
Out of the OU elements for KO element "kitto" in 
Table 2, "hazu" can be an OU element by itself. 
 
[1] koudaina umibe de miru sakuhin wa kitto miryokuteki 
ni utsuru hazu da . 
(Works that you see at the open seaside should look attractive.) 
 
This is the only sentence with an independent 
OU element for "kitto" in the data obtained from 
the process in Chapter 4. The same can be said of 
data for KO elements other than "kitto." Because 
of morphological analysis, the row of letters has 
been shortened. As a result, there are few ele-
ments that can be regarded as an OU element by 
itself. And just looking at this element does not 
determine the meaning. 
 (b) OU element when paired with others 
When "chigai" is paired with "ni" and "nai" to 
make "ni-chigai-nai (must be)," it becomes an OU 
element. Similarly, pairing "da" with "u" results in 
an OU element "daro-u (perhaps)." "Da" is the 
original form of "daro" and becomes "daro-u" 
when paired with "u." 
 
[2] kitto kintyou suru daro-u . 
(It is certain that one will be nervous.) 
[3] kamisimereba , kitto sake no aji ga suru ni-chiga-inai . 
(If you chew it, you will certainly taste salmon.) 
 
If we look over the entire pairing shown above, 
we can give meaning to such guess and conviction. 
6 Questions for the Future 
As we described in Chapter 5, it is necessary to 
pair multiple elements before giving mean-
ing/information. We currently persuade the issue 
of automatic generation of pairing multiple ele-
ments. Now, we are carrying out experiments on 
calculating the similarity measure of pairing of 
elements. These will give us pairing of automati-
cally generated elements and the similarity meas-
ure of the pairings. This should be useful data for 
resolving ambiguity (Figure 1).  
7 Conclusion 
This paper presented the process of extracting 
KO-OU expression data using CSM and the use-
fulness of the extracted KO-OU expression data. 
We are planning to report on the findings of ex-
periments on automatic generation of OU ele-
ments pairings.  
 
Acknowledgments To compile this paper, we used 
newspaper articles from The Mainichi Newspapers, 
The Yomiuri Shimbun, and Nihon Keizai Shimbun.  
We would like to sincerely thank Dr. M. Utiyama 
of the Communications Research Laboratory for allow-
ing us to use a KWIC tool "tea4." 
References 
A.Kida, E.Yamamoto and H.Isahara. 2002. Analysis of 
expression which projects the following elements 
beforehand. IPSJ SIG Notes NL-152, pp.137-143. 
A.Kida, E.Yamamoto, K.Kanzaki and H.Isahara. 2003. 
The key on the syntax which brings forth a concord 
relation. Proceedings of the 9th Annual Meeting of 
the Association for NLP. pp.23-26.  
T.Masuoka. 1991. Grammar of modality. Kurosio-
syuppan. 
S.Ohno. 1993. Research of a KAKARI-MUSUBI. Iwa-
nami-Shoten. 
E.Yamamoto and K.Umemura. 2002. A similarity 
Measure for Estimation of One-to-Many Relation-
ship in Corpus. Jourmal of Natural Lamguage Proc-
essing. Vol.9 No.2. pp.45-75. 
                                                          
4 See http://www2.crl.go.jp/jt/a132/members/mutiyama/ 
software.html. 
Similarities and Differences among Semantic Behaviors of 
Japanese Adnominal Constituents 
Kyoko Kanzaki and Qing Ma and Hitoshi Isahara 
Communications Research Laboratory 
588-2, Iwaoka, Iwaoka-cho, Nishi-ku, Kobe, 651-2492, Japan 
{kanzakilqma\[isahara} @crl.go.jp 
Abst rac t  
This paper treats the classification of the se- 
mantic functions performed by adnominal con- 
stituents in Japanese, where many parts of 
speech act as adnominal constituents. In order 
to establish a formal treatment of the semantic 
roles, the similarities and differences among ad- 
nominal constituents, i.e. adjectives and "noun 
+ NO (in English "of + noun")" structures, 
which have a broad range of semantic func- 
tions, are discussed. This paper also proposes 
an objective method of classifying these con- 
structs using a large amount of linguistic data. 
The feasibility of this was verified with a self- 
organizing semantic map based on a neural net- 
work model. 
1 In t roduct ion  
Pustejovsky (Pustejovsky, 1995) proposed the 
theory of a generative l xicon as a framework by 
which meanings of words are expressed in one 
unified representation. This kind ofgenerativity 
would be very useful for NLP, especially if it is 
applicable to the complex semantic structures 
represented by various modification relations. 
In our previous research on adjectives (Isahara 
and Kanzaki, 1999) we used Pustejovsky's the- 
ory to classify adjectives in Japanese. In this pa- 
per we take the first steps in a similar classifica- 
tion of the Japanese "noun + NO" construction. 
Bouillon (Bouillon, 1996) applied this theory 
to the adnominal constituent of mental states. 
Saint-Dizier (Saint-Dizier, 1998) discussed ad- 
jectives in French. 
Isahara and Kanzaki (Isahara and Kanzaki, 
1999) treated a much wider range of phenom- 
ena of adnominal constituents. They classified 
the semantic roles of adnominal constituents 
in .Japanese. where many parts of speech act 
as adnominal constituents, and discussed a for- 
mal treatment of their semantic roles. In their 
research, adnominal constituents, mainly ad- 
jectives which function as adverbials, are dis- 
cussed. The present paper describes the sim- 
ilarities and differences among adnominal con- 
stituents, i.e. adjectives and "noun + NO t (in 
English "of + noun")" structures which have 
a broad range of semantic functions. This pa- 
per proposes an objective method for classifying 
these structures using a large amount of linguis- 
tic data. The feasibility of this was verified with 
a self-organizing semantic map based on a neu- 
ral network model. 
In section 2, we explain the semantic func- 
tions performed by "noun + NO." In section 
3, we discuss how we can semi-automatically 
obtain and classify examples of adjectives and 
"noun + NO" structures which have similar se- 
mantic functions. In section 4, we introduce a
self-organizing semantic map to verify the result 
of this classification. In section 5, we discuss 
similarities and differences between adjectives 
and "noun + NO" structures. 
2 The  D ivers i ty  o f  Semant ic  
Re la t ions  between "noun -t- NO"  
and  the i r  Head Nouns  
Among Japanese adnominal constituents, "
noun + NO" represents a wider range of seman- 
tic relations than other adnominal constituents. 
Therefore, "noun + NO" does not always be- 
have like the other adnominal constituents. In 
previous work, some researchers have analyzed 
semantic relations between the noun in the 
"noun + NO" structure and its head noun (Shi- 
mazu et al, 1986). Here, we show several ex- 
amples that demonstrate he diversity of the se- 
l "NO" is a Japanese postpositiona| which can repre- 
sent a wide range of semantic relations. It is similar to 
"of" in English. 
59 
mantic relation between "noun + NO" struc- 
tures and their head nouns shown in their re- 
search. 
DENWA NO SECCHI 
DENSHA NO TUUKIN 
ASHITA NO DEITO 
BILU NO MAE 
KODOMO NO NAMAE 
BAKUHATSU NO GEN'IN 
KAISHI NO JIKOKU 
HEYA NO BANGOU 
KANOJO NO NOUTO 
BENGOSHI NO SMITH SAN 
installation of 
the telephone 
commuting by 
train 
a date for 
tomorrow 
in front of 
the building 
the name of 
the child 
the cause of 
the explosion 
the starting time 
the number of 
the room 
her note 
Mr. Smith, 
the lawyer 
These semantic relations between "noun + 
NO" structures and their head nouns are dif- 
ferent than those between other adnominal con- 
stituents, e.g. adjectives and their head nouns. 
However, some "noun + NO" behavior is sim- 
ilar to the behavior of adjectives and nominal 
adjectivals. In these cases "noun + NO" seems 
not to differ semantically from adjectives and 
nominal adjectivals. Let us consider the English 
examples: 
financial world / world of finance ("ZAIKAI") 
industrial center / center of industry 
("SANGYOU NO CHUUSHIN") 
In this case "noun + NO" need not be dis- 
tinguished from an adjective with respect o se- 
mantic behavior. However, in the following ex- 
amples it is necessary to distinguish them from 
one another. 
global center / center of tile globe 
("SEKAI NO CHUUSHIN 
/ CHIKYUU NO CHUUSHIN") 
We do not have a discrimination criteria that 
automatically recognizes whether a "noun + 
NO" structure is similar in its semantic behav- 
ior to that of adjectives or not. We have at- 
tempted to gather, semi-automatically, nolms in 
the "n(mn + NO" structure which behave like 
adjectives. 
3 The  Exp lorat ion  o f  the  S imi la r i t ies  
o f  Semant ic  Funct ions  o f  "noun + 
NO"  St ructures  and  Ad jec t ives .  
(The  Method  for th is  Research)  
3.1 The Basic Concept  
There is one case in which the meanings of ad- 
nominal constituents are semantically similar 
to the features of the referents of their head 
nouns, e.g. adnominal constituents represent 
the concrete contents of their head nouns. Let 
us consider the Japanese phrase "KANASHII 
KIMOCHI (sad feeling)" and "YOROKOBI NO 
KIMOCHI (feeling of delight)" as examples. 
KANASHII KIMOCHI 
adjective noun 
(sad) (feeling) 
sad feeling 
YOROKOBI NO KIMOCHI 
noun postp, noun 
(delight) (of) (feeling) 
feeling of delight 
NB: The English gloss of the "noun + NO" 
examples hould be read from right to left. 
One meaning of "KIMOCHI (feeling)" repre- 
sents the semantic element <mental state>. In 
the above examples, the adjective, "KANASHII 
(sad)", and "noun + NO", "YOROKOBI NO 
(of delight)", represent he concrete contents 
of their head noun "KIMOCHI (feeling)", i.e. 
they also represent the mental state: "feeling". 
Therefore, even though they belong to different 
parts of speech (adjective/noun), they must be 
classified in the same semantic category since 
both carry the same meaning. Neither the ad- 
jective, "KANASHII (sad)", nor the "noun + 
NO", "YOROKOBI NO (of delight)", can ap- 
pear in predicative position without changing 
their meaning. 
However, if adnominal constituents do not 
share the same semantic oncept as their head 
noun, they cannot represent he contents of 
head nouns. The examples below demonstrate 
this. 
KANASHII KIMOCHI 
adje(:tive noun 
(sad) (feeling) 
JOHN NO KIMOCHI 
noun postp, noun 
(John) (of) (feeling) 
John's feeling 
60 
In the above examples, the noun in "noun + 
NO", "JOHN", does not include the concept, 
<mental state>, so it cannot represent the con- 
tent of "KIMOCHI (feeling)." The adjective, 
"KANASHII (sad)", and the noun in the "noun 
+ NO", "JOHN" do not embody the same con- 
cept and have a different semantic relation with 
their head noun. We cannot find the seman- 
tic similarities between "KANASHII (sad)" and 
"JOHN" that we could between "YOROKOBI 
NO (of delight)" and "KANASHII (sad)." We 
focus on the phenomena where adnominal con- 
stituents represent the concrete contents of their 
head nouns. This makes it possible to identify 
adjectives and "noun + NO" structures which 
are similar in semantic behavior to the referents 
of their head nouns. These expressions are ex- 
tracted semi-automatically from large corpora. 
3.2 How to Ext ract  the Necessary 
In format ion  
When we collect words which have some sim- 
ilarities, it is difficult to select the semantic 
axis for classification by making use of only 
the co-occurring words. In collecting similar 
words, some previous research took not only co- 
occurring words but also the context of these 
words into account (Grefenstette, 1994). One 
of the important points of our analysis is the 
introduction of the distinct semantic elements 
that both "noun + NO" structures and adjecti- 
vals (adjectives and nominals) have in common 
with their head nouns. We wanted to ascertain 
the similarities between "noun + NO" and other 
adnominal constituents based on these common 
semantic elements. For this reason, we used 
the semantic relations, in which adnominal con- 
stituents represent the concrete content of their 
head nouns, as a key to classification. We au- 
tomatically 2 extracted these relations from one 
year of newspaper articles from Mainichi Shim- 
bun (1994), 100 novels from Shincho publishers 
and 100 books covering a variety of topics. We 
used the following procedure to extract he nec- 
essary information. 
Step 1) Extract from the corpora, all nouns 
which are preceded by the Japanese xpression 
"TOIU" which is something like "that" or "of." 
"TOIU + noun (noun that/of ...)" is a typical 
,Japanese xpression which introduces ome in- 
2Only Step 3) is done manually. 
formation about the referent of the noun, such 
as apposition. Therefore, nouns found in this 
pattern may have their content elucidated by 
means of their modifiers. 
Step 2) Extract from the corpora, all "noun 
+ NO" structures, adjectives and nominal ad- 
jectivals which modify the nouns extracted in 
step 1. 
NB, the relationships between adnominal 
constituents and their modified nouns extracted 
here include not only representations of the con- 
tents of the noun, but also other various rela- 
tions. 
Step 3) Extract "noun + NO" structures, ad- 
jectives and nominal adjectivals which represent 
the contents of the referents of the modified 
nouns. Step 3 is done manually. 
Step 4) In order to find the distribution of 
their semantic ategories and analyze the se- 
mantic similarities between "noun + NO" and 
other adnominal constituents in each semantic 
category, we clustered the modified nouns auto- 
matically. This clustering was based on sets of 
similar adnominal constituents which represent 
the content of the referent of the modified noun. 
4 The  Semant ic  Map of  the  
Mod i f ied  Nouns  Const ructed  by  
the Self-Organizing System of the 
Neural Network Model 
We can gather similar modified nouns when we 
classify the modified nouns according to the 
similarities of the adnominal constituents, be- 
cause in our data both adnominal constituents 
and their modified nouns have the same se- 
mantic elements in common that we mentioned 
above. 
We attempted toconstruct the Semantic Map 
of the modified nouns gathered by the above- 
mentioned method by using the self-organizing 
system of the neural network model (Ma et al, 
2000). We suppose that both modified nouns 
and adnominal constituents have common se- 
rnantic elements when adnominal constituents 
represent he concrete content of their head 
nouns. If this is true, nouns with similar mean- 
ings are located near each other oil the semantic 
map, self-organized by the similarities of seman- 
tic elements among the adnominal constituents. 
The result of our experiment verified this sup- 
position (Figure I). The nouns with a similar 
61 
meaning are located near each other on the map 
and we could divide the distribution of the mod- 
ified nouns into seven categories (Figure 2). 
Each group, i.e. the "mental state" 
group, "state/ situation" group, "characteris- 
tics" group, "range/ area" group, "viewpoint/ 
standpoint" group, "aspect" group, and "oth- 
ers," represents a meaning held in common by 
nouns in the group. Mental state can be fur- 
ther divided into the state of emotion, mood 
and intention. As we analyze the adnominal 
constituents in each category of modified nouns, 
we can find the possibility of the co-occurrence 
of an adnominal constituent with a head noun. 
Table 1 shows examples of adjectives and nouns 
in "noun + NO" structures in each group. 
UT~A 
? 
Table 1: List of adjectives and "noun + NO" 
Structures 
<menta l  state: emot ion> 
Adj: KANASHII (sad), URESHII 
(pleasurable) 
noun+no: KANASHIMI (sadness), 
YOROKOBI (delight) 
<state /s i tuat ion> 
Adj: ISOGASHII (busy), 
MUTITUJONA (disorderly) 
noun+no: KURAYAMI (darkness), 
MUISHIKI (unconscious) 
<aspect> 
Adj: YUUMOUNA (brave), 
HIGEKITEKINA (tragic) 
noun+no: KONTON (chaos), TAIHAI 
(decadence) 
<character i s t i c> 
Adj: NONKINA (carefree), 
KISAKUNA (open-hearted) 
noun+no: I J IPPARI (stubbornness), 
GOUMANNA (arrogance) 
<range/area> 
Adj: JOUSHIKITEKINA (comnmnsense), 
KOUTEKINA (official) 
noun+no: GAKUMON (studies), GYOUMU 
(duty) 
<v iewpo int / s tandpo in t> 
Adj: KYOUIKUTEKINA (educational), 
SHOUGYOUTEKINA (economic) 
noun+no: KYOUIKU (education), EISEI 
(hygiene) 
Figure 1: Semantic Map 1 
Figure 2: Semantic Map 2 
In the mental state, state/situation, aspect 
and characteristics groups~ adjectives appear 
more frequently than "noun + NO" construc- 
tions. These are simple adjectives. Ill the 
range/area nd viewpoint/standpoint groups, 
62 
"noun + NO" structures appear more fre- 
quently than simple adjectives. Nominal adjec- 
tivals derived from nouns plus the suffix "TEKI- 
na" appear often with these noun groups. Most 
nouns in the groups "mental state: emotion", 
"state/situation" and "characteristics", contain 
abstract nouns which represent emotions, situa- 
tions or characteristics. There are few concrete 
nouns. However, in the groups "range/area" 
and "viewpoint/standpoint', here are many 
concrete nouns which represent natural phe- 
nomena, organizations or professional domains 
and few abstract nouns. We can find differences 
among "noun + NO" structures, that is, there 
are adjectives which behave like nouns semanti- 
cally and there are nouns which behave seman- 
tically like adjectives. 
5 The  semant ic  behav ior  o f  the  
"noun -t- NO"  s t ruc ture  wh ich  is 
s imi la r  to  that  o f  ad jec t ives  
5.1 Types  of nouns in the "noun -'t- 
NO"  s t ruc ture  
As we mentioned in section 3, we extracted the 
"noun + NO" structures which have the same 
semantic element, along with similar adjectives, 
from large corpora. For example, 
KIKEN_NA JOUTAI 
(dangerous) (situation) 
dangerous ituation 
In this case "dangerous" represents the state 
concretely. 
MIKETTEI NO JOUTAI 
(indecision) (of) (situation) 
a situation of indecision 
In this case, the "MIKETTEI NO (of in- 
decision)" also represents the state concretely. 
Here, both "KIKENN_NA (dangerous)" and 
"MIKETTEI NO (of indecision)" have tile same 
semantic element "state" in common. We find 
that a "situation" can be represented by both 
an adjective and the "noun + NO" structure. 
When "MIKETTEI NO (of indecision)" co- 
occurs with modified nouns other than "situa- 
tion", it mostly represents the semantic notion, 
e.g. "MIKETTEI NO MONDAI (a problem of 
indecision)", and so on. That is,"MIKETTEI 
NO (of indecision)," represents the situation of 
a problem. So we see that "MIKETTEI NO (of 
indecision)" is in itself like an adjective. 
On the other hand, "KUMORI NO (cloudi- 
ness)" behaves ometimes like an adjective and 
sometimes not. 
KUMORI NO JOUTAI 
(cloudiness) (of) (state) 
a state of cloudiness 
The semantic behavior of "KUMORI NO 
(of cloudiness)" is like the behavior of adjec- 
tives in that the cloudiness represents the state 
as "KIKEN_NA (dangerous)," however, "KU- 
MORI NO (of cloudiness)" does not always rep- 
resent the state of the referent of the modified 
noun though "MIKETTEI NO (of indecision)" 
always represents that. "KUMORI (cloudi- 
ness)" is a natural phenomenon which can be 
pointed to concretely. For example, 
KUMORI NO NISSU 
(cloudiness) (of) (amount) 
WA 4 GATU NI SITEWA IJOU DA. 
The amount of cloudiness is unusual for April. 
In this example, "KUMORI NO (of cloudi- 
ness)" modifies "NISSU (the amount)," and 
does not represent a state but the possessor of 
the amount. 
As the examples of "MIKETTEI NO (of 
indecision)" and "KUMORI NO (of cloudi- 
ness)" show, there are nouns which have the 
same properties as adjectives intrinsically (e.g. 
"MIKETTEI (indecision)"), and other nouns 
which intrinsically have different properties 
from adjectives (e.g. "KUMORI (cloudiness)"). 
So, it is important o consider the properties of 
the noun in "noun + NO" when we analyze the 
"noun + NO" which behaves emantically like 
an adjective. Such an analysis enables us to find 
the situation in which they act like adjectives. 
We classified nouns in "noun + NO" structures 
into three types based on what the nouns refer 
to. Nouns from the last category, 3), are similar 
to adjectives emantically. As adjectives do not 
represent concrete objects or verb-like notions, 
nouns from these categories only occasionally 
resemble adjectives. 
63 
Noun Categories: 
1) nouns which refer to concrete objects. (like 
rain, book, science, and so on) 
2) nominalizations (like decision, work, and so 
on) 
3) nouns which belong to neither 1) nor 2), 
e.g. abstract nouns and so on. 
As our corpora contain mainly newspaper ar- 
ticles, many compound nouns appear. Since the 
last word in a compound noun determines the 
properties of the whole word, we focus on the 
last word in classifying them. 
Table 2 contains examples of the noun cate- 
gories. "KOUGYOU TOSHI (industry city)" is 
an example of a compound noun where the last 
word "TOSHI (city)" determines the properties. 
Table 2: Some "noun + NO" constructions with 
"impression" 
1) nouns which refer to concrete objects 
KOUGYOU TOSHI, HINOKI 
(industry city) (cypress) 
2) nominalizations 
SOKUBAKU, KOUTEN 
(restriction) (improvement) 
3) nouns which belong to neither 1) nor 2) 
MUTONTYAKU, JAKUSHOU 
(carelessness) (weakness) 
In the following section, we analyze the sim- 
ilarities and differences of the semantic behav- 
ior of "noun + NO" structures and adjectives. 
Firstly, we describe the case in which the se- 
mantic behavior of "noun + NO" is similar to 
that of adjectives and then we mention the case 
in which the semantic behavior of "noun + NO" 
is different from that of adjectives. Secondly, we 
analyze several types of nouns in "noun + NO" 
which behave like adjectives, ewm though nouns 
in "noun + NO" are not intrinsically similar to 
adjectiw; types. 
5.2 The di f ferences of semant ic  
behav ior  between nouns  in "noun 
-b NO"  and adject ives 
For example, "KANASHII (sad)", "URESHII 
(pleasurable)", "ZANNEN_NA (regrettable)", 
"KANASHIMI NO (of sadness)", "YOROKOBI 
NO (of delight)" and so on, modify nouns 
such as "OMOI (thought)", "KANJI (emo- 
tion)" and so on. Using a set of adnomi- 
nal constituents, such as "KANASHII (sad)", 
"URESHII (pleasurable)", "ZANNEN..NA (re- 
grettable)", as keys for classification, we can 
classify the modified nouns, "OMOI (thought)", 
"KANJI (feeling)" and so on, into the same 
group. Then we can find a semantic relation- 
ship between these adnominal constituents and 
their head nouns, in this case, <emotion>. In 
the following, we describe the similar and dif- 
fering semantic behaviors of "noun ? NO" and 
other adjectives in the same semantic ategory. 
As we described in the previous ection, we ex- 
tract sets of "noun + NO" structures and ad- 
jectives from data which was sorted semanti- 
cally. Words in each set represent he seman- 
tic substance of the similar nouns which they 
modify. Therefore, their semantic categories 
are similar. Examples of modified nouns of a 
similar semantic category and their modifiers 
which have a semantic ategory similar to that 
of the nouns are listed in Table 3. Included are 
some "noun ? NO" examples which though co- 
occurring with <mental state> nouns are not 
classified as such themselves. There are many 
adjectives and nominal adjectivals which can 
modify nouns in Table 3, such as "AWARENA 
(poor)", "IJIRASHII (moving)" and "HOKO- 
RASHII (triumphant)." Some "noun ? NO" 
structures are semantically similar to these ad- 
jectives ince they represent the contents of the 
emotion, e.g. "FUKAI NO KAN (sensation of 
displeasure)" and "YOROKOBI NO KIMOCHI 
(feeling of delight)." Most nouns in these "noun 
+ NO" structures in Table 3 are classified into 
"mental activity by humans" by the "Word List 
Classified by Semantic Principles3. '' "Noun + 
NO" structures, which have this kind of seman- 
tic; category, are similar to adjectives and nom- 
inal adjectivals, as both represent he content 
of the human mind. We call this semantic at- 
'~This list was compiled by The Natural Language Re- 
search Institute, Tokyo. 
64 
Table 3: The modified nouns and adjectives, 
nominal adjectivals, and "noun + NO" 
collected in the semantic ategory, 
<mental state> 
Modi f ied nouns 
KANJI (feeling), KAN (sensation), 
OMOI (thought), KI (intention), 
NEN (inclination), KIMOCHI (mind), 
KIBUN (mood), KANJO (emotion), 
JO (passion) 
Adject ives  and nominal  adject ivals 
AWARE_NA (poor), IJIRASHII (moving), 
HOKORASHII (triumphant), 
KINODOKU_NA (unfortunate), 
SHIAWASE_NA (happy), 
ZANNEN_NA (disappointing), 
URESHII (pleasurable), ...and so on. 
"Nouns"  in the "noun + NO"  s t ruc ture  
a) mental  act iv i ty  
KANASHIMI (sadness), FUKAI (displeasure), 
SHITASHIMI (familiarity), 
ZOUO (abhorrence), GAMAN (endurance), 
KOUKAI (regret), YOROKOBI (joy), 
MANZOKU (satisfaction), 
RAKUTAN (disappointment), 
IGAI (unexpected), ...and so on. 
b) nominal izat ions 
HOSHIN (self-defense), 
CHIKUZAI (moneymaking), 
INTAI (retirement), HIHAN (criticism), 
HIYAKU (rapid progress), ...and so on 
egory created by these adnominal constituents 
and their modified nouns "Feeling." 
On the other hand, some adnominal rela- 
tionships concerning a mental state can only 
be represented by "noun + NO" structures, 
such as "HOSHIN NO KIMOCHI (desire of de- 
fending one's own interest)," "CHIKUZAI NO 
NEN (thought of moneymaking)" and "INTAI 
NO KIMOCHI (idea of retirement)." Event 
nouns are mainly used in these "noun + NO" 
structures. Adnominal modifying relations of 
"nominalization + NO + mental state_noun" 
structures represent an intentional mental state. 
This kind of intentional mental state cannot be 
expressed by adjectives. We call this semantic 
category "Intentional mental state." 
We discussed two types of semantic represen- 
tations above, i.e. Feeling and Intentional men- 
tal state. Feeling can be represented by adjec- 
tives and "noun + NO" structures. However, 
Intentional mental state can be represented 
only by "noun + NO" structures. From the 
standpoint of the characteristics of the modified 
nouns (they represent human mental states), 
these two mental activities (Feeling and Inten- 
tional mental state) are similar, even though 
there are .differences in whether the activity is 
intentional or not. However, from the stand- 
point of the selection of an adnominal relation- 
ship in the surface structure, whether the activ- 
ity has active intention or not will be the decid- 
ing factor for the selection between adjectives 
and "noun + NO" structures. 
5.3 The case where  the semant ic  
behav ior  of "noun + NO"  
structures is similar to that of 
adjectives 
Here we focus on nouns whose properties are 
unlike those of adjectives, i.e. the nouns which 
refer to concrete objects, verbal notions and so 
on.  
(1) In the case where "noun + NO" represents 
characteristics, there is some overlap be- 
tween the semantic behavior of adjectives 
and "noun + NO" structures. 
I) The case where the noun in "noun + NO" 
is a compound noun 
Let us compare "noun + NO" with adjective 
usage. 
MUKUCHI_NA INSHOU 
(reticent) (impression) 
GA TUYOI JOHN-SAN WA "" 
Jotm who makes a reticent impression "-" 
KOUGYOUTOSHI NO INSHOU 
(industry city) (of) (impression) 
GA TUYOI KAWASAKISHI WA... 
65 
KAWASAKI city which gives a strong im- 
pression of an industrial city 4 
b) Modified nouns which represent instances 
of the concrete nouns in compound nouns 
In the previous two examples, the differences 
between "noun + NO" and adjectives depend 
only on whether the nouns they modify rep- 
resent a person or a city where both head 
nouns have characteristics in common. How- 
ever, "KOUGYOUTOSHI (industry city)" does 
not always have the same semantic relation to 
the modified noun, as seen in the following ex- 
ample: 
KOUGYOUTOSHI NO YUKYUTI 
(industry city) (of) (vacant land) 
NI TYAKUMOKU. 
They noticed the vacant land 
in the industrial city. 
In this example, the semantic relation be- 
tween "KOUGYOUTOSHI NO (of industry 
city)" and "YUKYUTI (the vacant land)" indi- 
cate the relation of possession so that it is not a 
semantic relation that adjectives can represent. 
When the modified nouns are abstract nouns 
that represent the property ("INSHOU (impres- 
sion)" or "SEIKAKU (characteristics)" etc.), or 
instances of the concrete nouns in compound 
nouns ("KAWASAKI SHI (KAWASAKI city)"), 
the semantic function of compound nouns in 
"noun + NO" constructions represent the char- 
acteristics of the referent of the modified nouns 
as adjectives do. 
a) Modified nouns which are abstract nouns 
that represent a property. 
KOUGYOUTOSHI NO IMEJI 
(industry city) (of) (image) 
GA OOKII. 
The image of an industrial city is strong. 
KOUKYUUHIN NO INSHOU 
(high quality item) (of) (impression) 
GA TUYOI SHANERU 
(with) CHANNEL the impression of 
a high-quality item is strong. 
4Note that some words which are nouns in Japanese 
(e.g. industry, high quality)must be translated as adjec- 
tiw~ in English (e.g. industrial, high-quality) 
<city-SUZUKA-SHI> 
KOUGYOUTOSHI NO SUZUKA SHI 
(industry city) (of) (SUZUKA city) 
SUZUKA city which is an industrial city 
<item-diamonds> 
KOUKYUUHIN NO DAIYA 
(high quality item) (of) (diamond) 
Diamonds are a high-quality item 
<company-IBM> 
YURYOUGAISHA NO 
(excellent company) (of) 
IBM is an excellent company 
IBM 
When the modified noun is an instance 
of the last word of the modifying com- 
pound noun, the semantic function of the 
whole compound noun is similar to that 
of adjectives because, in this type of com- 
pound, we focus on the adjectival semantic 
element. For example, "KOUGYOU (indus- 
try)" in "KOUGYOUTOSHI (industry city)", 
"KOUKYUU (high-quality)" in "KOUKYU- 
UHIN (high quality item)", and "YUURYOU 
(excellent)" in "YUURYOUGAISHA (excellent 
company)" are adjectival. 
II) the nouns that refer to the concrete object 
in "noun + NO" 
Originally the nouns that refer to a concrete 
object or event do not have the same meaning as 
adjectives, however, they have similar semantic 
behavior to that of adjectives in the following 
case. 
KARE WA OTONASHII KIHUU 
(mild) (disposition) 
NO MOTINUSHI DA. 
He has a mild disposition. 
The "mild" represents he characteristic (dis- 
position). In the following examples the "noun 
+ NO" also indicate the characteristics of some- 
thing. 
66 
KODOMOTACHI WA ... MASSUGU 
NOBIRU 
HINOKI 
(HINOKI-tree) 
These children 
NO INSHOU 
(of) (impression) 
GA ARIMASHITA. 
give the impression of a 
HINOKI-tree which grows straight. 
KAGAKUGAISHA TOIU KOTODE IPPAN 
NO HITO NIWA 
KANKYOUOSEN NO INSHOU 
(environment pollution) (of) (impression) 
impression of environmental pollution 
GA TUYOKATTA. 
Ordinary people have a strong impression of 
environmental pollution from the chemical 
company. 
The impression the children make is of a 
"HINOKI (HINOKI-tree)" and the impression 
the chemical company makes is of "KANKY- 
OUOSEN (environmental pollution)". These 
"noun + NO'structures represent he charac- 
teristics of children and a company in same 
manner that the adjective "mild" indicates his 
characteristic. In these examples, nouns in 
"noun + NO" represent objects and events and 
so on, i.e. "HINOKI-tree" and "environmental 
pollution" these nouns ordinarily do not behave 
like adjectives. That is, the adjective "mild" 
can represent a characteristic directly, however, 
these nouns in "noun + NO" cannot represent 
the characteristics of something directly. We 
cannot say "that children are HINOKI-tree" 
and "the company is the environmental pollu- 
tion" while we can say "He is mild." That is, in 
this case, "noun + NO" cannot appear in the 
predicative position with this meaning. When 
we show the characteristics of something by us- 
ing nouns that refer to concrete objects and 
events, we need to specify the modified nouns 
which indicate the characteristics like "impres- 
sion, .... disposition" and so on. 
(2) "Noun + NO" can represent quantification. 
Some adjectives (:an also represent quantifi- 
cation. 
NIHON NO.HASHIMOTO SHUSHOU NO 
TEIAN WA AIKAWARAZU 
67 
TYUUSHOUTEKI_NA IKI 
(abstract) (level) 
NI TODOMATTA. 
The suggestion of the Japanese prime minis- 
ter, Hashimoto, was still in an abstract state. 
HUSAINO HIRITU GA KAKEI NI TOTTE 
KIKEN_NA IKI NI TASSHITEIRU. 
(dangerous) (level) 
The rate of debt has reached a dangerous 
level for the household budget. 
The suggestion of the Japanese prime min- 
ister is at an "abstract" level on the "concrete- 
abstract" scale and the rate of debt is at a "dan- 
gerous" level on the "safety-dangerous" scale. 
The level of concreteness and safety is repre- 
sented by adjectives. On the other hand, the 
nouns that refer to concrete objects and verbal 
notions also represent a level by inference from 
the context. We can infer the scale from the 
contextual situation. For example, 
KOUNIN KOUHO WA 
UWASA NO DANKAI 
(rumor) (of) (stage) 
the stage of rumor 
DA GA BORUGA SHI 
Though it is completely at the stage of ru- 
mor, the candidate for the succession is Mr. 
Borgar ... 
SHUSHOU GAWA WA "" 
(the prime minister and his staff) 
ENZETU NO IKI 
(speech) (of) (level) 
WO KOERARENAKATTA. 
Though the prime minister and his staff said 
"we will specify the guidelines of the govern- 
ment proposal during the election", after all 
it was still at the level of speech. 
GIJUTUTEKINIWA 
KANSEI NO IKI 
(completeness) (of) (level) 
NI TASSHITEITA. 
It reached a level of completeness, technically. 
In the above case, we do not have a seman- 
tic element of actual "talk" in the "rumor" 
or "speech" meaning nor a semantic element 
"event" in the "completeness" meaning, but we 
have the level of "rumor" on the "truth-rumor" 
scale, the level of "speech" on the "statement- 
speech" scale and the level of "completeness" on 
the "incompleteness-completeness" scale. The 
nouns that refer to concrete objects and verbal 
actions are similar to adjectives when they rep- 
resent a level in context. 
6 Conc lus ion  
In this paper, we discussed the similarities 
and differences among adnominal constituents, 
i.e. adjectives and "noun + NO" structures 
which have a broad range of semantic functions. 
Nouns and adjectives differ in part of speech, 
but they sometimes have similarities when used 
adnominally. In such a case, we need not dis- 
tinguish them from each other semantically. We 
investigated explicit criteria to detect similari- 
ties and differences between nouns and adjec- 
tives in adnominal usage. This research was ver- 
ified by using large corpora and a self-organizing 
mapping system based on the neural network 
model. In future work, we will attempt o sys- 
tematically classify words used adnominally ac- 
cording to the semantic behavior of adnominal 
constituents following the theoretical insights of 
Pustejovsky. 
Acknowledgment 
We would like to thank Catherine Macleod of 
New York University and Kiyotaka Uchimoto 
of the Communications Research Laboratory for 
their invaluable help in writing this paper. 
References 
P. Bouillon. 1996. Mental State Adjectives: the 
Perspective of Generative Lexicon. In Proc. 
of COLING96. 
G. Grefenstette. 1994. Corpus-Derived First, 
Second and Third-Order Word Affinities. In ' 
Proc. off the EURALEX '9~. 
H. Isahara and K. Kanzaki. 1999. Lexical Se- 
mantics to Disambiguate Polysemous Phe- 
nomena of Japanese Adnominal Constituents. 
In Proc. of A CL99. 
Q. Ma, K. Kanzaki, M. Murata, K. Uchi- 
moto, and H. Isahara. 2000. Construction 
of a Japanese Semantic Map using Self- 
Organizing Neural Network Model. In 6th 
Annual Meeting of the Association for Nat- 
ural Language Processing, Japan. (will ap- 
pear). 
J. Pustejovsky. 1995. The Generative Lexicon. 
The MIT Press. 
P. Saint-Dizier. 1998. A Generative Lex- 
icon Perspective for Adjectival Modifica- 
tion. In Proc. of the Conference volume2 
in 36th Annual Meeting of the Associa- 
tion for Computational Linguistics and 17th 
International Conference on Computational 
Linguistics(COLING-A CL '98). 
A. Shimazu, S. Naito, and H. Nomura. 1986. 
Analysis of semantic relations between ouns 
connected by a Japanese particle "no". 
Keiryo Kokugogaku (Mathematical Linguis- 
tics), 15(7). (in Japanese). 
68 
 	

Coling 2008: Proceedings of the workshop on Speech Processing for Safety Critical Translation and Pervasive Applications, pages 32?35
Manchester, August 2008
The 2008 MedSLT System
Manny Rayner1, Pierrette Bouillon1, Jane Brotanek2, Glenn Flores2
Sonia Halimi1, Beth Ann Hockey3, Hitoshi Isahara4, Kyoko Kanzaki4
Elisabeth Kron5, Yukie Nakao6, Marianne Santaholma1
Marianne Starlander1, Nikos Tsourakis1
1 University of Geneva, TIM/ISSCO, 40 bvd du Pont-d?Arve, CH-1211 Geneva 4, Switzerland
{Emmanuel.Rayner,Pierrette.Bouillon,Nikolaos.Tsourakis}@issco.unige.ch
{Sonia.Halimi,Marianne.Santaholma,Marianne.Starlander}@eti.unige.ch
2 UT Southwestern Medical Center, Children?s Medical Center of Dallas
{Glenn.Flores,Jane.Brotanek}@utsouthwestern.edu
3 Mail Stop 19-26, UCSC UARC, NASA Ames Research Center, Moffett Field, CA 94035?1000
bahockey@ucsc.edu
4 NICT, 3-5 Hikaridai, Seika-cho, Soraku-gun, Kyoto, Japan 619-0289
{isahara,kanzaki}@nict.go.jp
5 3 St Margarets Road, Cambridge CB3 0LT, England
elisabethkron@yahoo.co.uk
6 University of Nantes, LINA, 2, rue de la Houssinie`re, BP 92208 44322 Nantes Cedex 03
yukie.nakao@univ-nantes.fr
Abstract
MedSLT is a grammar-based medical
speech translation system intended for
use in doctor-patient diagnosis dialogues,
which provides coverage of several dif-
ferent subdomains and multiple language
pairs. Vocabulary ranges from about 350 to
1000 surface words, depending on the lan-
guage and subdomain. We will demo three
different versions of the system: an any-
to-any multilingual version involving the
languages Japanese, English, French and
Arabic, a bidirectional English ? Span-
ish version, and a mobile version run-
ning on a hand-held PDA. We will also
demo the Regulus development environ-
ment, focussing on features which sup-
port rapid prototyping of grammar-based
speech translation systems.
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
1 Introduction
MedSLT is a medium-vocabulary grammar-based
medical speech translation system built on top of
the Regulus platform (Rayner et al, 2006). It is
intended for use in doctor-patient diagnosis dia-
logues, and provides coverage of several subdo-
mains and a large number of different language-
pairs. Coverage is based on standard examina-
tion questions obtained from physicians, and fo-
cusses primarily on yes/no questions, though there
is also support for WH-questions and elliptical ut-
terances.
Detailed descriptions of MedSLT can be found
in earlier papers (Bouillon et al, 2005; Bouil-
lon et al, 2008)1. In the rest of this note, we
will briefly sketch several versions of the system
that we intend to demo at the workshop, each of
which displays new features developed over the
last year. Section 2 describes an any-language-to-
any-language multilingual version of the system;
Section 3, a bidirectional English ? Spanish ver-
sion; Section 4, a version running on a mobile PDA
1All MedSLT publications are available on-line
at http://www.issco.unige.ch/projects/
medslt/publications.shtml.
32
platform; and Section 5, the Regulus development
environment.
2 A multilingual version
During the last few months, we have reorganised
the MedSLT translation model in several ways2. In
particular, we give a much more central role to the
interlingua; we now treat this as a language in its
own right, defined by a normal Regulus grammar,
and using a syntax which essentially amounts to
a greatly simplified form of English. Making the
interlingua into another language has made it easy
to enforce tight constraints on well-formedness of
interlingual semantic expressions, since checking
well-formedness now just amounts to performing
generation using the interlingua grammar.
Another major advantage of the scheme is that
it is also possible to systematise multilingual de-
velopment, and only work with translation from
source language to interlingua, and from interlin-
gua to target language; here, the important point
is that the human-readable interlingua surface syn-
tax makes it feasible in practice to evaluate transla-
tion between normal languages and the interlingua.
Development of rules for translation to interlingua
is based on appropriate corpora for each source
language. Development of rules for translating
from interlingua uses a corpus which is formed by
merging together the results of translating each of
the individual source-language corpora into inter-
lingua.
We will demonstrate our new capabilities in
interlingua-based translation, using a version of
the system which translates doctor questions in the
headache domain from any language to any lan-
guage in the set {English, French, Japanese, Ara-
bic}. Table 1 gives examples of the coverage of the
English-input headache-domain version, and Ta-
ble 2 summarises recognition performance in this
domain for the three input languages where we
have so far performed serious evaluations. Differ-
ences in the sizes of the recognition vocabularies
are primarily due to differences in use of inflec-
tion.
3 A bidirectional version
The system from the preceding section is unidi-
rectional; all communication is in the doctor-to-
patient direction, the expectation being that the pa-
2The ideas in the section are described at greater length in
(Bouillon et al, 2008).
Language Vocab WER SemER
English 447 6% 11%
French 1025 8% 10%
Japanese 422 3% 4%
Table 2: Recognition performance for English,
French and Japanese headache-domain recognis-
ers. ?Vocab? = number of surface words in source
language recogniser vocabulary; ?WER? = Word
Error Rate for source language recogniser, on in-
coverage material; ?SemER? = semantic error rate
for source language recogniser, on in-coverage
material.
tient will respond non-verbally. Our second demo,
an early version of which is described in (Bouillon
et al, 2007), supports bidirectional translation for
the sore throat domain, in the English ? Spanish
pair. Here, the English-speaking doctor typically
asks WH-questions, and the Spanish-speaking pa-
tient responds with elliptical utterances, which are
translated as full sentence responses. A short ex-
ample dialogue is shown in Table 3.
Doctor: Where is the pain?
?Do?nde le duele?
Patient: En la garganta.
I experience the pain in my throat.
Doctor: How long have you had a pain
in your throat?
?Desde cua?ndo le duele la garganta?
Patient: Ma?s de tres d??as.
I have experienced the pain in my
throat for more than three days.
Table 3: Short dialogue with bidirectional English
? Spanish version. System translations are in ital-
ics.
4 A mobile platform version
When we have shown MedSLT to medical profes-
sionals, one of the most common complaints has
been that a laptop is not an ideal platform for use
in emergency medical situations. Our third demo
shows an experimental version of the system us-
ing a client/server architecture. The client, which
contains the user interface, runs on a Nokia Linux
N800 Internet Tablet; most of the heavy process-
ing, including in particular speech recognition, is
hosted on the remote server, with the nodes com-
municating over a wireless network. A picture of
33
Where? Is the pain above your eye?
When? Have you had the pain for more than a month?
How long? Does the pain typically last a few minutes?
How often? Do you get headaches several times a week?
How? Is it a stabbing pain?
Associated symptoms? Do you vomit when you get the headaches?
Why? Does bright light make the pain worse?
What helps? Does sleep make the pain better?
Background? Do you have a history of sinus disease?
Table 1: Examples of English MedSLT coverage
the tablet, showing the user interface, is presented
in Figure 1. The sentences appearing under the
back-translation at the top are produced by an on-
line help component, and are intended to guide the
user into the grammar?s coverage (Chatzichrisafis
et al, 2006).
The architecture is described further in
(Tsourakis et al, 2008), which also gives perfor-
mance results for another Regulus applications.
These strongly suggest that recognition perfor-
mance in the client/server environment is no
worse than on a laptop, as long as a comparable
microphone is used.
5 The development environment
Our final demo highlights the new Regulus devel-
opment environment (Kron et al, 2007), which has
over the last few months acquired a large amount
of new functionality designed to facilitate rapid
prototyping of spoken language applications3 . The
developer initially constructs and debugs her com-
ponents (grammar, translation rules etc) in a text
view. As soon as they are consistent, she is able
to compile the source-language grammar into a
recogniser, and combine this with other compo-
nents to run a complete speech translation system
within the development environment. Connections
between components are defined by a simple con-
fig file. Figure 2 shows an example.
References
Bouillon, P., M. Rayner, N. Chatzichrisafis, B.A.
Hockey, M. Santaholma, M. Starlander, Y. Nakao,
K. Kanzaki, and H. Isahara. 2005. A generic multi-
lingual open source platform for limited-domain
medical speech translation. In Proceedings of the
10th Conference of the European Association for
3This work is presented in a paper currently under review.
Machine Translation (EAMT), pages 50?58, Bu-
dapest, Hungary.
Bouillon, P., G. Flores, M. Starlander,
N. Chatzichrisafis, M. Santaholma, N. Tsourakis,
M. Rayner, and B.A. Hockey. 2007. A bidirectional
grammar-based medical speech translator. In Pro-
ceedings of the ACL Workshop on Grammar-based
Approaches to Spoken Language Processing, pages
41?48, Prague, Czech Republic.
Bouillon, P., S. Halimi, Y. Nakao, K. Kanzaki, H. Isa-
hara, N. Tsourakis, M. Starlander, B.A. Hockey, and
M. Rayner. 2008. Developing non-european trans-
lation pairs in a medium-vocabulary medical speech
translation system. In Proceedings of LREC 2008,
Marrakesh, Morocco.
Chatzichrisafis, N., P. Bouillon, M. Rayner, M. Santa-
holma, M. Starlander, and B.A. Hockey. 2006. Eval-
uating task performance for a unidirectional con-
trolled language medical speech translation system.
In Proceedings of the HLT-NAACL International
Workshop on Medical Speech Translation, pages 9?
16, New York.
Kron, E., M. Rayner, P. Bouillon, and M. Santa-
holma. 2007. A development environment for build-
ing grammar-based speech-enabled applications. In
Proceedings of the ACL Workshop on Grammar-
based Approaches to Spoken Language Processing,
pages 49?52, Prague, Czech Republic.
Rayner, M., B.A. Hockey, and P. Bouillon. 2006.
Putting Linguistics into Speech Recognition: The
Regulus Grammar Compiler. CSLI Press, Chicago.
Tsourakis, N., M. Georghescul, P. Bouillon, and
M. Rayner. 2008. Building mobile spoken dialogue
applications using regulus. In Proceedings of LREC
2008, Marrakesh, Morocco.
34
Figure 1: Mobile version of the MedSLT system, running on a Nokia tablet.
Figure 2: Speech to speech translation from the development environment, using a Japanese to Arabic
translator built from MedSLT components. The user presses the Recognise button (top right), speaks in
Japanese, and receives a spoken translation in Arabic together with screen display of various processing
results. The application is defined by a config file which combines a Japanese recogniser and analy-
sis grammar, Japanese to Interlingua and Interlingua to Arabic translation rules, an Arabic generation
grammar, and recorded Arabic wavfiles used to construct a spoken result.
35
Coling 2008: Proceedings of the workshop on Cognitive Aspects of the Lexicon (COGALEX 2008), pages 73?76
Manchester, August 2008
The "Close-Distant" Relation of Adjectival Concepts                
Based on Self-Organizing Map 
Kyoko Kanzaki, Hitoshi Isahara 
National Institute of Information and 
Communications Technology 
3-5, Hikaridai, Seikacho, 
Sorakugun, Kyoto, 619-0289,  
Japan 
{kanzaki,isahara}@nict.go.jp
Noriko Tomuro 
School of Computer Science, Telecom-
munications and Information Systems 
DePaul University 
Chicago, IL 60604 
U.S.A 
tomuro@cs.depaul.edu 
 
Abstract 
In this paper we aim to detect some as-
pects of adjectival meanings. Concepts of 
adjectives are distributed by SOM (Self-
Organizing map) whose feature vectors 
are calculated by MI (Mutual Informa-
tion). For the SOM obtained, we make 
tight clusters from map nodes, calculated 
by cosine. In addition, the number of 
tight clusters obtained by cosine was in-
creased using map nodes and Japanese 
thesaurus. As a result, the number of ex-
tended clusters of concepts was 149 clus-
ters. From the map, we found 8 adjectival 
clusters in super-ordinate level and some 
tendencies of similar and dissimilar clus-
ters. 
1 Introduction 
This paper aims to find a diversity range of ad-
jectival meanings from a coordinate map in 
which  "close-distant" relationships between ad-
jectival classes is reflected. In related research 
over adjectives, Alonge et.al (2000), Solar (2003), 
Marrafa and Mendes (2006) suggested that 
WordNet and EuroWordNet lack sufficient ad-
jectival classes and semantic relations, and  ex-
tended the resources over such relations. 
For the sake of identifying the diversity of ad-
jectival meanings, it is necessary to analyze ad-
jectival semantics via "close-distant" relation-
ships extracted from texts. In our work on ex-
tracting adjective semantics, we consider abstract 
nouns as semantic proxies of adjectives. For the 
clustering method, we utilized a self-organizing 
                                                 
? 2008. Licensed under the Creative Commons Attri-
bution-Noncommercial-Share Alike 3.0 Unported 
license (http://creativecommons.org/licenses/by-nc-
sa/3.0/). Some rights reserved. 
map (SOM) based on a neural network model 
(Kohonen, 1997). One of the features of SOM is 
that it assigns words coordinates, allowing for 
the possibility of visualizing word similarity. 
SOM has two advantages for our task. One is 
that we can utilize the map nodes of words to 
locate members of clusters that clustering meth-
ods have failed to classify. The other is that the 
map shows the relative relations of whole clus-
ters of adjectival concepts. By observing such a 
map in which the relations of clusters are re-
flected, we can analyze the diversity of adjectival 
meaning. 
2 Abstract Nouns that Categorize Ad-
jectives 
Collocations between adjectives and nouns in 
?concrete value and its concept? relations can be 
used to represent adjectival semantics. Nemoto 
(1969) indicated that expressions such as ?iro ga 
akai (the color is red)? and ?hayasa ga hayai 
(literally, the speed is fast)? are a kind of 
tautology. Some studies have suggested that 
some abstract nouns collocating with adjectives 
are hypernymic concepts (or concepts) of those 
adjectives, and that some semantic relations 
between abstract nouns and adjectives represent 
a kind of repetition of meaning. 
   This paper defines such abstract nouns as the 
semantic categorization of an adjective (or an 
adjectival concept). 
The data for this study was obtained by ex-
tracting adjectives co-occurring with abstract 
nouns in 100 novels, 100 essays, and 42 years of 
newspaper articles. 
We extracted the abstract nouns according to 
the procedure described by Kanzaki et.al (2006). 
Here, they evaluated the category labels of adjec-
tives obtained by the proposed procedure and 
found that for 63% of the adjectives, the ex-
73
tracted categories were found to be appropriate. 
We constructed a list as follows: 
Abstract Nouns:  
Adjectives modifying abstract nouns   
KIMOCHI (feeling):  
ureshii (glad), kanashii (sad), 
shiawasena (happy) ? 
In this list,  ?KIMOCHI (feeling)? is defined by 
?ureshii (glad), kanashii (sad), and shiawasena 
(happy)?, for example. Here, each abstract noun 
conveys the concept or hypernym of the given 
adjectives. 
Next we classify these abstract nouns based on 
their co-occurring adjectives using SOM. 
3. A Map of Adjective Semantics  
3.1 Input Data 
In our SOM, we use adjectives which occur more 
than four times in our corpus. The number of 
such adjectives was 2374. Then we identified 
361 abstract nouns that co-occurred with four or 
more of the adjectives. The maximum number of 
co-occurring adjectives for a given abstract noun 
in the corpus was 1,594. 
    In the data, each abstract noun was defined by 
a feature vector, in the form of noun co-
occurrences represented by pointwise mutual 
information (Manning and Schutze, 1999). Mu-
tual information (MI) is an information theoric 
measure and has been used in many NLP tasks, 
including clustering words (e.g. Lin and Pantel, 
2002). 
3.2 SOM 
Kohonen?s self-organizing map (SOM) is an un-
supervised learning method, where input in-
stances are projected onto a grid/map of nodes 
arranged in an n-dimensional space. Input in-
stances are usually high-dimensional data, while 
the map is usually two-dimensional (i.e., n = 2). 
Thus, SOM essentially reduces the dimensional-
ity of the data, and can be used as an effective 
tool for data visualization ? projecting complex, 
high-dimensional data onto a low-dimensional 
map. SOM can also be utilized for clustering. 
Each node in a map represents a cluster and is 
associated with a reference vector of m-
dimensions, where m is the dimension of the in-
put instances. During learning, input instances 
are mapped to a map node whose (current) refer-
ence vector is the closest to the instance vector 
(where SOM uses Euclidean distance as the 
measure of similarity by default), and the refer-
ence vectors are gradually smoothed so that the 
differences between the reference vector and the 
instance vectors mapped to the node are mini-
mized. This way, instances mapped to the same 
node form a cluster, and the reference vector es-
sentially corresponds to the centroid of the clus-
ter. 
SOM maps are self-organizing in the sense 
that input instances that are similar are gradually 
pulled closer during learning and assigned to 
nodes that are topographically close to one an-
other on the map. The mapping from input in-
stances to map nodes is one-to-one (i.e., one in-
stance is assigned to exactly one node), but from 
map nodes to instances, the mapping is one-to-
many (i.e., one map node is assigned to zero, one, 
or more instances). 
The input data was the set of 361 abstract 
nouns defined by the 2,374 co-occurring adjec-
tives, as described in the previous section. These 
abstract nouns were distributed visually on the 2-
dimensional map based on co-occurring adjec-
tives. This map is a ?map of adjective semantics? 
because the abstract nouns are identified as prox-
ies for adjective semantics.  
As mentioned before, similar words are lo-
cated in neighboring nodes on the 2-dimensional 
map. The next step is to identify similar clusters 
on the map. 
4. Clusters of Adjective Semantics 
4.1 Tight Clusters from the Map Nodes 
In SOMs, each node represents a cluster, i.e. a set 
of nouns assigned to the same node. These nouns 
are very similar and can be considered to be 
synonyms. However, nouns that are similar 
might map to different nodes because the algo-
rithm?s self-organization is sensitive to the pa-
rameter settings. To account for this, and also to 
obtain a more (coarse-grained) qualitative de-
scription of the map, tight clusters?clusters of 
map nodes whose reference vectors are signifi-
cantly close?were extracted. All groupings of 
map nodes whose average cosine coefficient be-
tween the reference vectors in the group was 
greater than 0.96 were extracted (Salton and 
McGill, 1983).  
4.2 Result  
The total number of clusters was 213. Excluding 
singleton clusters, the number of clustes was 81. 
229 concepts were classified into 81 clusters, 
with 132 concepts not classified into any cluster. 
74
In order to evaluate the quality of the concep-
tual classification, we utilized the ?Bunruigoi-
hyou?  Japanese thesaurus (National Institute of 
Japanese Language, 1964). In ?Bunruigoihyou,? 
each category is assigned a 5-digit category 
number, with close numbers indicating similar 
categories.  
Among the 81 with two or more concepts, the 
number of clusters containing words with the 
same class was 36. That is, for 44% of the clus-
ters, the constituent nouns had the same ?Bun-
ruigoihyou? class label. The ratio of concept 
agreement between "Bunruigiohyou? and our 
obtained clusters was found to be  20.87/81=0.25.  
We also compared tight clusters by performing  
hierarchical clustering with the k-means algo-
rithm. 
The results of the hierarchical clustering were as 
follows: 
1) The rate of clusters agreeing with ?Bunruigoi-
hyou?: 30/96 = 0.31 
2) The average rate of agreement for each tight 
cluster: 21.07/96 = 0.21 
In the case of k-means: 
3)The rate of clusters agreeing with ?Bunruigoi-
hyou?: 33/143 = 0.23 
4) The average rate of agreement for each tight   
cluster: 28.37/143 = 0.198 
From these results, we can observe that clus-
ters obtained with cosine similarity agree more 
with the Japanese thesaurus than the other two 
methods. Therefore, in terms of quality, clusters 
obtained by cosine similarity seem to be superior 
to the others. 
4.3 Using the Position of Map Nodes 
However, even for the result obtained with co-
sine similarity, 132 concepts were not classified 
into any clusters. Additionally, the clusters ap-
pear to be overly fine grained: most tight clusters 
include 1, 2 or 3 concepts. In order to find simi-
lar concepts that cosine similarity failed to clus-
ter together, we used the position information of 
the map nodes.  
After we plotted clusters obtained by cosine 
similarity on the map, we checked for singleton 
concepts located near a cluster which are mem-
bers of the same ?Bunruigoihyou? class.  Also, 
we checked to see if concepts in clusters located 
at neighboring nodes could be clustered together  
using the category numbers of ?Bunruigoihyou. ? 
By extending the clusters, we generated a total 
of 149 clusters, including 68 with two or more 
elements and 81 singleton clusters. 
5. Interpreting the Adjectival Clusters 
In our final map, 361 concepts were distributed 
based on 2374 adjectives into 149 clusters. 
Among the 149 clusters, 68 contained two or 
more concepts.  
5.1 ?Close-Distant? Relations of Clusters and 
Adjectives 
In the final map, clusters at the superordinate 
level are located around the center of the map. 
Upper level concepts tend to agree with clusters 
in ?Bunruigoihyou.?  For examples, ?image and 
impression,? ?situation and state?, ?feeling and 
mood? are located around the center of the map. 
 
 
 
 
 
 
 
 
 
 
Cluster1 (Center of the map): koto (matter), 
in?shou (impression), men (side of some-
thing or someone), and kankaku 
(sense/feeling) 
Cluster2: seishitsu (characteristics of some-
one/something), yousou (aspect)  
Cluster3: kanten (viewpoint), tachiba (stand-
point), bun?ya (domain) 
Cluster4: taido (attitude), yarikata (way of do-
ing) 
Cluster5: gaikan, gaiken, sugata (outlook and 
appearance of someone/something) 
Cluster6:  fun?iki, kuuki, kehai (atmosphere) 
Cluster7:  kimochi, kanji (feeling) 
Cluster8:  joutai (state), joukyou (situation) 
 
In our experiment, at the top level, adjectival 
concepts seem to be divided into 8 basic clusters. 
From the distribution of the map, we find ?close-
distant? relationships between clusters, that is 
clusters located far from each other tend to be 
semantically disparate. In terms of adjective se-
mantics, the semantic relationship between ?ki-
mochi, kanji (feeling)? (Cluster7) and ?seishitsu 
(characteristics of someone/something), yousou 
(aspect)? are distant. 
However, ?kimochi, kanji (feeling)? (Cluster7) 
has a close relation to ?fun?iki, kuuki, kehai 
(atmosphere) ? (Cluster6) and also  ?joutai (state), 
joukyou (situation)? (Cluster8). 
Fig7. Cluster 7 on the map 
1
2 
4 3 
5
Center of a map 6
7
8
75
1. In our experiment, 77 adjectives belonged 
to one or two clusters. Though there is the 
possibility of data sparseness, there is also 
the possibility that the meanings of these 
adjectives are specific. Examples of adjec-
tives belonging to specific clusters are as 
follows: 
 
Adjectives in distant relationships; 
- Clusters 2: keisandakai (seeing everything in 
terms of money), ken?meina 
(wise), ? 
- Cluster 7: akkenai (disappointing/easily), kiya-
sui (feel at home),? 
 
Adjectives in close relationships; 
- Cluster 6: ayashigena (fishy) 
- Cluster7: akkenai (disappointing /easily), kiya-
sui (feel at home) 
- Cluster8: meihakuna (obvious), omoshiroi (in-
teresting), makkurana (dark) 
 
Japanese adjectives are often said to represent 
?kanjou (mental state)?, ?joutai (state),? ?seisitsu 
(characteristics)? and ?teido (degree)?, in addi-
tion to ?positive/negative image.? In our experi-
ment, the SOM unearthed not only these adjecti-
val meanings, but also ?inshou (impression)?, 
?taido (attitude)?, ?kanten (viewpoint)? and 
?sugata (outlook)?, which seem to be discrimina-
tive meanings of adjectives. 
6. Future work 
We classified 361 concepts based on 2374 adjec-
tives using a self-organizing map. Since the 
SOM shows the distribution visually, it provides 
not only clusters of adjectives but also ?close-
distant? relationships between clusters. As a re-
sult, adjectival concepts at the superordinate 
level are divided into 8 main clusters. The results 
not only verify previous work but also suggest 
new discriminative adjective classes. One of the 
advantages of SOM is that it presents its outputs 
visually. As a result, we can explore ?close- dis-
tant? relationships between clusters, and  analyze 
the meaning of each. In addition to increasing the 
range of adjectival classes and improving our 
method, our method provides the means to ana-
lyze concepts which did not agree with those in 
existing thesauri such as ?Bunruigoihyou?, the 
EDR dictionary or Japanese Word Net. 
 
 
 
References 
Alonge, Antonietta., Francesca Bertagna, Nicoletta 
Calzolari, Andriana Roventini and Antonio Zam-
polli. 2000. Encoding Information on Adjectives in 
a Lexical-semantic Net for Computational Applica-
tions, Proceedings of the 1st Conference of the 
North American Chapter of the Association for 
Computational Linguistics(NAACL-00) :42-49 
Kyoko Kanzaki,Qing Ma, Eiko Yamamoto and 
Hitoshi Isahara, 2006, Semantic Analysis of 
Abstract Nouns to Compile a Thesaurus of 
Adjectives, In Proceedings of The Interna-
tional Conference on Language Resources 
and Evaluation (LREC-06) 
Kohonen, Teuvo. 1997. Self-Organizing Maps, Sec-
ond Edition, Springer. 
Lin, Dekang., and Patrick Pantel. 2002. Concept Dis-
covery from Text, Proceedings of the 19th Interna-
tional Conference on Computational Linguis-
tics(COLING-02): 768-774  
Manning, Christopher D., and Hinrich Sh?tze. 1999. 
Foundations of Statistical Natural language Proc-
essing, The MIT Press. 
Marrafa, Palmira., and Sara Mendes. 2006. Modeling 
Adjectives in Computational Relational Lexica, 
Proceedings of the COLING/ACL2006:555-562 
National Institute for Japanese Language. 1964. Bun-
ruigoihyou (Word List by Semantic Principles). 
Nemoto, Kesao. 1969. The combination of the noun 
with ?ga-Case? and the adjective, Language re-
search 2 for the computer, National Language Re-
search Institute: 63-73 (in Japanese) 
Salton, Gerard., and Michael J. McGill. 1983. Intro-
duction to Modern Information Retrieval.  McGraw 
Hill. 
Solar, Clara. 2003. Extension of Spanish WordNet, 
Proceedings of the third International WordNet 
Conference(GWC-06):213-219 
 
76
