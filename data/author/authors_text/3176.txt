BioNLP 2007: Biological, translational, and clinical language processing, pages 25?32,
Prague, June 2007. c?2007 Association for Computational Linguistics
On the unification of syntactic annotations under the Stanford
dependency scheme: A case study on BioInfer and GENIA
Sampo Pyysalo, Filip Ginter, Katri Haverinen,
Juho Heimonen, Tapio Salakoski
Department of Information Technology
University of Turku,
Joukahaisenkatu 3-5
20014 Turku, Finland
first.last@utu.fi
Veronika Laippala
Department of French Studies
University of Turku,
Henrikinkatu 2
20014 Turku, Finland
veronika.laippala@utu.fi
Abstract
Several incompatible syntactic annotation
schemes are currently used by parsers and
corpora in biomedical information extrac-
tion. The recently introduced Stanford de-
pendency scheme has been suggested to be
a suitable unifying syntax formalism. In this
paper, we present a step towards such uni-
fication by creating a conversion from the
Link Grammar to the Stanford scheme. Fur-
ther, we create a version of the BioInfer cor-
pus with syntactic annotation in this scheme.
We present an application-oriented evalua-
tion of the transformation and assess the
suitability of the scheme and our conversion
to the unification of the syntactic annotations
of BioInfer and the GENIA Treebank.
We find that a highly reliable conversion is
both feasible to create and practical, increas-
ing the applicability of both the parser and
the corpus to information extraction.
1 Introduction
One of the main challenges in biomedical infor-
mation extraction (IE) targeting entity relationships
such as protein-protein interactions arises from the
complexity and variability of the natural language
statements used to express such relationships. To
address this complexity, many biomedical IE sys-
tems (Alphonse et al, 2004; Rinaldi et al, 2004;
Fundel et al, 2007) and annotated corpora (Kim et
al., 2003; Aubin, 2005; Pyysalo et al, 2007) incor-
porate full syntactic analysis. However, there are
significant differences between the syntactic anno-
tation schemes employed. This leads to difficulties
in sharing data between corpora and establishing the
relative performance of parsers as well as to a lack
of interchangeability of one parser for another in IE
systems, among other issues.
Syntax formalisms are broadly divided into con-
stituency and dependency. Constituency schemes
are dominant in many fields and are unified under
the established Penn Treebank (PTB) scheme (Bies
et al, 1995). However, dependency schemes have
been suggested to be preferable in IE, as they repre-
sent the semantic structure of the sentences more di-
rectly (see, e.g., de Marneffe et al (2006)). Further,
Lin (1998) argues for dependency-based evaluation
of both dependency and constituency parsers since
it allows evaluation metrics that are more relevant
to semantic interpretation as well as intuitively more
meaningful. Even though there is clearly a need for a
unifying scheme for dependency comparable to that
of PTB for constituency, no widely adopted standard
currently exists.
In this paper, we present a step towards unify-
ing the diverse syntax schemes in use in IE sys-
tems and corpora such as the GENIA Treebank1 and
the recently introduced BioInfer corpus (Pyysalo et
al., 2007). Clegg and Shepherd (2007) have re-
cently proposed to use the Stanford dependency
scheme (de Marneffe et al, 2006) as a common,
application-oriented syntax representation. To as-
sess this choice, we develop a set of conversion
rules for transforming the Link Grammar (LG) de-
pendency scheme (Sleator and Temperley, 1993) to
1http://www-tsujii.is.s.u-tokyo.ac.jp/ ?genia
25
the Stanford scheme and then create a version of
the BioInfer corpus in the Stanford scheme by ap-
plying the conversion rules and manually correcting
the errors. By making the BioInfer corpus available
in the Stanford scheme, we also increase the value
of the corpus for biomedical IE. The transforma-
tion has the further benefit of allowing Link Gram-
mar output to be normalized into a more application-
oriented form. Finally, to assess the practical value
of the conversion method and of the BioInfer syntac-
tic annotation in the Stanford scheme, we compare
the Charniak-Lease constituency parser2 (Charniak
and Lease, 2005) and BioLG,3 an adaptation of LG
(Pyysalo et al, 2006), on the newly unified dataset
combining the constituency-annotated GENIA Tree-
bank with the dependency-annotated BioInfer cor-
pus.
The transformation rules and software as well as
the Stanford annotation of the BioInfer corpus, the
main practical results of this work, are freely avail-
able at http://www.it.utu.fi/BioInfer.
2 Motivation
To support the development of IE systems, it is im-
portant for a corpus to provide three key types of
annotation capturing the named entities, their rela-
tionships and the syntax. To our knowledge, there
are only two corpora in the biomedical domain that
currently provide these three annotation types simul-
taneously, BioInfer and LLL (Aubin, 2005). In ad-
dition, GENIA, the de facto standard domain corpus
for named entity recognition and syntactic analysis,
is in the process of adding a relationship annota-
tion. The corpora have different strengths; BioInfer
provides a detailed relationship annotation, while
GENIA has a broader coverage of named entities
and a larger treebank. Unifying the syntactic anno-
tations of these two corpora allows these strengths
to be combined.
The BioInfer syntactic annotation follows the LG
dependency scheme, addressing the recent interest
in LG in the biomedical NLP community (Ding et
al., 2003; Alphonse et al, 2004; Aubin et al, 2005).
However, the LG scheme has been criticized for be-
ing oriented more towards structural than semantic
2http://nlp.stanford.edu/software/,
version 1.5.1
3http://www.it.utu.fi/BioLG, version 1.2.0
relations and having excessively detailed link types
whose functional meaning and value for semantic
analysis is questionable (Schneider, 1998; de Marn-
effe et al, 2006). Our experience with LG leads us
to largely agree with these criticisms.
De Marneffe et al (2006) have recently intro-
duced a transformation from PTB to the Stanford
scheme. Clegg and Shepherd (2007) have ap-
plied this transformation to perform a dependency-
based comparison of several statistical constituency
parsers on the GENIA Treebank and have argued for
the adoption of the Stanford scheme in biomedical
IE. Moreover, the IE system of Fundel et al (2007),
which employs the Stanford scheme, was shown to
notably outperform previously applied systems on
the LLL challenge dataset, finding an F-score of
72% against a previous best of 54%. This further
demonstrates the suitability of the Stanford scheme
to IE applications.
3 Dependency schemes
In this section, we present the Stanford and LG
dependency schemes and discuss their relative
strengths.
3.1 Stanford dependency scheme
A parse in the Stanford scheme (SF) is a directed
graph where the nodes correspond to the words and
the edges correspond to pairwise syntactic depen-
dencies between the words. The scheme defines
a hierarchy of 48 grammatical relations, or depen-
dency types. The most generic relation, dependent,
can be specialized as auxiliary, argument, or modi-
fier, which again have several subtypes (de Marneffe
et al, 2006).
The Stanford conversion transforms phrase struc-
ture parses into the Stanford scheme. First, the se-
mantic head of each constituent is identified using
head rules similar to those of Collins (1999) and un-
typed dependencies are then extracted and labeled
with the most specific grammatical relations possi-
ble using Tregex rules (Levy and Andrew, 2006).
The system additionally provides a set of collaps-
ing rules, suggested to be beneficial for IE appli-
cations (de Marneffe et al, 2006; Clegg and Shep-
herd, 2007). These rules collapse some dependen-
cies by incorporating certain parts of speech (mostly
26
Vimentin and actin were also up-regulated , whereas an isoform of myosin heavy chain was down-regulated .
A/ANPv Cs
Mp
Ss
A/AN PvDsuE
Js
MVsCC
Spx
CC
Vimentin and actin were also up-regulated , whereas an isoform of myosin heavy chain was down-regulated .
cc>
conj>
<nsubjpass
<auxpass
<advmod
advcl>
<mark
<det prep>
<nsubjpass
pobj>
<nmod
<nmod <auxpass
Vimentin and actin were also up-regulated , whereas an isoform of myosin heavy chain was down-regulated .
conj_and>
<nsubjpass
<nsubjpass
<auxpass
<advmod
advcl>
<mark
<det
prep_of>
<nsubjpass
<nmod
<nmod <auxpass
Figure 1: A sentence from the BioInfer corpus with its LG linkage (top), the Stanford parse (middle), and
the collapsed Stanford parse (bottom). The < and > symbols denote the direction of dependencies.
during incubation , actin suffered degradation
Jp
CO
Ss Os
actin suffered degradation during incubation
Jp
MVp
Ss Os
actin suffered degradation during incubation
JpMpSs Os
Figure 2: Variation in the link type connecting a
preposition: CO to the main noun in topicalized
prepositional phrases, MVp when modifying a verb,
and Mp when modifying a noun.
conjunctions and prepositions) in grammatical rela-
tions. This is realized by combining two relations
and denominating the resulting dependency with a
type based on the word to which the original two
relations were linked (see Figure 1).
In the LG-SF conversion, we target the uncol-
lapsed Stanford scheme, as the collapsing rules have
already been developed and reported by de Marn-
effe et al; reimplementing the collapsing would be
an unnecessary duplication of efforts. Also, the col-
lapsed relations can be easily created based on the
uncollapsed ones, whereas reversing the conversion
would be more complicated.
3.2 LG dependency scheme
Link Grammar (Sleator and Temperley, 1993) is
closely related to dependency formalisms. It is
based on the notion of typed links connecting words.
While links are not explicitly directional, the roles
of the words can be inferred from their left-to-right
order and the link type. An LG parse, termed link-
age, consists of a set of links that connect the words
so that no two links cross or connect the same two
words. When discussing LG, we will use the terms
dependency and link interchangeably.
Compared to the 48 dependency types of the Stan-
ford scheme, the LG English grammar defines over
100 main link types which are further divided into
400 subtypes. The unusually high number of dis-
tinct types is one of the properties of the LG English
grammar that complicate the application of LG in
information extraction. Consider, for instance, the
case of prepositional phrase attachment illustrated in
Figure 2, where all the alternative attachment struc-
tures receive different types. Arguably, this distinc-
tion is unimportant to current IE systems and there-
fore should be normalized. This normalization is in-
herent in the Stanford scheme, where the preposition
always attaches using a prep dependency.
In contrast to such unnecessarily detailed distinc-
tions, in certain cases LG types fail to make seman-
tically important distinctions. For instance, the CO
link type is used to mark almost all clause openers,
not distinguishing between, for example, adverbial
and prepositional openers.
4 Our contributions
In this section, we describe the LG-SF conversion
as well as SF BioInfer, the BioInfer corpus syntactic
27
annotation in the Stanford scheme. These are the
two primary contributions of this study.
4.1 LG-SF conversion
The LG-SF conversion transforms the undirected
LG links into directed dependencies that follow the
Stanford scheme. The transformation is based on
handwritten rules, each rule consisting of a pattern
that is matched in the LG linkage and generating a
single dependency in the Stanford parse. Since the
conversion rules only refer to the LG linkage, they
do not influence each other and are applied inde-
pendently in an arbitrary order. The pattern of each
rule is expressed as a set of positive or negative con-
straints on the presence of LG links. The constraints
typically restrict the link types and may also refer to
the lexical level, restricting only to links connecting
certain word forms. Since LG does not define link
directionality, the patterns refer to the left-to-right
order of tokens and the rules must explicitly specify
the directionality of the generated SF dependencies.
As an example, let us consider the rule
[X Pv? Y]? Y auxpass? X. The pattern matches two
tokens connected with an LG link of type Pv and
generates the corresponding directed auxpass de-
pendency. This rule applies twice in the linkage
in Figure 1. It is an example of a rare case of a
one-to-one correspondence between an LG and an
SF type. Many-to-many correspondences are much
more common: in these cases, rules specify multiple
restrictions and multiple rules are needed to gener-
ate all instances of a particular dependency type. As
a further example, we present the three rules below,
which together generate all left-to-right prep depen-
dencies. An exclamation mark in front of a restric-
tion denotes a negative restriction, i.e., the link must
not exist in order for the rule to apply. The link types
are specified as regular expressions.
[A Mp|MX[a-z]x? B]![B Cs? C]![A RS? D]? A prep? B
[A OF|MVx? B]![A RS? C]? A prep? B
[A MVp? B]![A RS? C]![C MVl? A]? A prep? B
The first of the above three rules generates the prep
dependency in the parse in Figure 1, with A=isoform
and B=of. The variables C and D are not bound to
any tokens in this sentence, as they only occur in
negative restrictions.
actin , profilin and cofilin
CC
CC CC
Figure 3: Example of a structure where the relative
order of the first two tokens cannot be resolved by
the rules.
To resolve coordination structures, it is crucial to
recognize the leftmost coordinated element, i.e. the
head of the coordination structure in the SF scheme.
However, the conversion rule patterns are unable to
capture general constraints on the relative order of
the tokens. For instance, in the linkage in Figure 3, it
is not possible to devise a pattern only matching one
of the tokens actin and profilin, while not matching
the other. Therefore, we perform a pre-processing
step to resolve the coordination structures prior to
the application of the conversion rules. After the
pre-processing, the conversion is performed with the
lp2lp software (Alphonse et al, 2004), previously
used to transform LG into the LLL competition for-
mat (Aubin, 2005).
In the development of the LG-SF conversion and
SF BioInfer, we make the following minor modifi-
cations to the Stanford scheme. The scheme dis-
tinguishes nominal and adjectival pre-modifiers of
nouns, a distinction that is not preserved in the
BioInfer corpus. Therefore, we merge the nom-
inal and adjectival pre-modifier grammatical rela-
tions into a single relation, nmod. For the same rea-
son, we do not distinguish between apposition and
abbreviation, and only use the appos dependency
type. Finally, we do not annotate punctuation.
Schneider (1998) has previously proposed a strat-
egy for identifying the head word for each LG link,
imposing directionality and thus obtaining a depen-
dency graph. Given the idiosyncrasies of the LG
linkage structures, this type of transformation into
dependency would clearly not have many of the nor-
malizing benefits of the LG-SF transformation.
4.2 SF BioInfer
For creating the BioInfer corpus syntactic annota-
tion in the Stanford scheme, the starting point of
the annotation process was the existing manual an-
notation of the corpus in the LG scheme to which
we applied the LG-SF conversion described in Sec-
tion 4.1. The resulting SF parses were then manu-
28
ally corrected by four annotators. In the manual cor-
rection phase, each sentence was double-annotated,
that is, two annotators corrected the converted out-
put independently. All disagreements were resolved
jointly by all annotators.
To estimate the annotation quality and the sta-
bility of the SF scheme, we determined annotator
agreement as precision and recall measured against
the final annotation. The average annotation preci-
sion and recall were 97.5% and 97.4%, respectively.
This high agreement rate suggests that the task was
well-defined and the annotation scheme is stable.
The BioInfer corpus consists of 1100 sentences
and, on average, the annotation consumed approxi-
mately 10 minutes per sentence in total.
5 Evaluation
In this section, we first evaluate the LG-SF conver-
sion. We then present an evaluation of the Charniak-
Lease constituency parser and the BioLG depen-
dency parser on BioInfer and GENIA.
5.1 Evaluation of the conversion rules
In the evaluation of the conversion rules against the
gold standard SF BioInfer annotation, we find a pre-
cision of 98.0% and a recall of 96.2%. Currently,
the LG-SF conversion consists of 114 rules, each
of which specifies, on average, 4.4 restrictions. Al-
together the rules currently generate 32 SF depen-
dency types, thus averaging 3.5 rules per SF type.
Only 9 of the SF types are generated by a single
rule, while the remaining require several rules. We
estimate that the current ruleset required about 100
hours to develop.
In Figure 4, we show the cumulative precision and
recall of the rules when added in the descending or-
der of their recall. Remarkably, we find that a recall
of 80% is reached with just 13 conversion rules, 90%
with 28 rules, and 95% with 56 rules. These fig-
ures demonstrate that while the SF and LG schemes
are substantially different, a high-recall conversion
can be obtained with approximately fifty carefully
crafted rules. Additionally, while precision is con-
sistently high, the highest-recall rules also have the
highest precision. This may be related to the fact
that the most common SF dependency types have a
straightforward correspondence in LG types.
 0
 10
 20
 30
 40
 50
 60
 70
 80
 90
 100
 0  20  40  60  80  100
Number of conversion rules
Recall
Precision
Figure 4: Cumulative precision and recall of the con-
version rules.
A common source of errors in the LG-SF conver-
sion are the Link Grammar idiomatic expressions,
which are analyzed as a chain of ID links (0.7% of
all links in the BioInfer corpus) and connected to
the linkage always through their last word. Some
examples of LG idiomatic expressions include each
other, no one, come of age, gotten rid of, for good,
and the like. These expressions are often problem-
atic in the SF conversion as well. We did not at-
tempt any wide-coverage systematic resolution of
the idiomatic expressions and, apart from the most
common cases such as in vitro, we preserve the LG
structure of connecting these expressions through
their last word. We note, however, that the list of
idiomatic LG expressions is closed and therefore a
case-by-case resolution leading to a full coverage is
possible, although not necessarily practical.
Similar to the LG idiomatic expressions are the
SF dep dependencies, generated when none of the
SF rules assigns a more specific type. In most cases,
dep is a result of a lack of coverage of the SF con-
version rules typically occurring in rare or idiomatic
expressions. We assume that many of the dep depen-
dencies will be resolved in the future, given that the
SF conversion and the SF dependency scheme itself
are presented by the authors as a work in progress.
Therefore, we do not attempt to replicate most of
the SF dep dependencies with the LG-SF conversion
rules; much of the effort would be obsoleted by the
progress of the SF conversion. The dep dependen-
cies account for 23% of the total 3.8% of dependen-
cies not recovered by the LG-SF conversion.
29
Charniak-Lease BioLG
corpus Prec. Rec. F Prec. Rec. F
GENIA 81.2 81.3 81.3 76.9 72.4 74.6
BioInfer 78.4 79.9 79.4 79.6 76.1 77.8
Table 1: Parser performance. Precision, recall and
F-measure for the two parsers on the two corpora.
5.2 Evaluated parsers and corpora
The Charniak-Lease parser is a statisti-
cal constituency parser developed by Char-
niak and Lease (2005). It is an adaptation of the
Charniak parser (Charniak, 1999) to the biomedical
domain. For example, it uses a POS-tagger trained
on the GENIA corpus, although the parser itself has
been trained on the Penn Treebank. The Charniak-
Lease parser is of particular interest, because in a
recent comparison performed by Clegg and Shep-
herd (2007) on the GENIA Treebank, it was the
best performing of several state-of-the-art statistical
constituency parsers.
The LG parser is a rule-based dependency parser
with a broad coverage grammar of newspaper-type
English. It has no probabilistic component and does
not perform pruning of ambiguous alternatives dur-
ing parsing. Instead, the parser generates all parses
accepted by the grammar. Simple heuristics are ap-
plied to rank the alternative parses.
Here, we evaluate a recently introduced adap-
tation of LG to the biomedical domain, BioLG
(Pyysalo et al, 2006), incorporating the GENIA
POS tagger (Tsuruoka et al, 2005) as well as a num-
ber of modifications to lexical processing and the
grammar.
To facilitate the comparison of results with those
of Clegg and Shepherd, we use their modified subset
of GENIA Treebank.4 As 600 of the 1100 BioInfer
sentences have previously been used in the develop-
ment of the BioLG parser, we only use the remaining
500 blind sentences of BioInfer in the evaluation.
5.3 Parser performance
To evaluate the performance of the parsers, we de-
termined the precision, recall and F-measure by
comparing the parser output against the corpus gold
4http://chomsky-ext.cryst.bbk.ac.uk/
andrew/downloads.html
BioLG
scheme Prec. Rec. F
LG 78.2 77.2 77.7
SF 79.6 76.1 77.8
Table 2: BioLG performance on the BioInfer corpus
with and without the LG-SF conversion.
standard dependencies. The matching criterion re-
quired that the correct words are connected and
that the direction and type of the dependency are
correct. The dependency-based evaluation results
for the Charniak-Lease and BioLG parsers on the
GENIA and BioInfer corpora are shown in Table 1.
We note that Clegg and Shepherd (2007) report
77% F-score performance of Charniak-Lease on the
GENIA corpus, using the collapsed variant of the SF
scheme. We replicated their experiment using the
uncollapsed variant and found an F-score of 80%.
Therefore, most of the approximately 4% difference
compared to our finding reported in Table 1 is due
to this difference in the use of collapsing, with our
modifications to the SF scheme having a lesser ef-
fect. The decrease in measured performance caused
by the collapsing is, however, mostly an artifact
caused by merging several dependencies into one; a
single mistake of the parser can have a larger effect
on the performance measurement.
We find that while the performance of the
Charniak-Lease parser is approximately 2 percent-
age units better on GENIA than on BioInfer, for
BioLG we find the opposite effect, with performance
approximately 3 percentage units better on BioInfer.
Thus, both parsers perform better on the corpora
closer to their native scheme. We estimate that this
total 5 percentage unit divergence represents an up-
per limit to the evaluation bias introduced by the two
sets of conversion rules. We discuss the possible
causes for this divergence in Section 5.4.
To determine whether the differences between the
two parsers on the two corpora were statistically
significant, we used the Wilcoxon signed-ranks test
for F-score performance using the Bonferroni cor-
rection for multiple comparisons (N = 2), follow-
ing the recent recommendation of Dems?ar (2006).
We find that the Charniak-Lease parser outperforms
BioLG statistically significantly on both the GENIA
corpus (p ? 0.01) and on the BioInfer corpus
30
  Z   protein  but  not  c-myb  protein 
<nmod <dep
cc>
<nmod
conj>
  Z   protein  but  not  c-myb  protein 
<nmod dep>
cc>
<nmod
conj>
Figure 5: Example of divergence on the interpreta-
tion of the Stanford scheme. Above: GENIA and
Stanford conversion interpretation. Below: BioInfer
and LG-SF rules interpretation.
(p < 0.01). Thus, the relative performance of the
parsers can, in this case, be established even in the
presence of opposing conversion biases on the two
corpora.
In Table 2, we present an evaluation of the BioLG
parser with and without the LG-SF conversion,
specifically evaluating the effect of the conversion
presented in this study. Here we find a substantially
more stable performance, including even an increase
in precision. This further validates the quality of the
conversion rules.
Finally, we note that the processing time required
to perform the conversions is insignificant compared
to the time consumed by the parsers.
5.4 Discussion
Evaluating BioLG on GENIA and the Charniak-
Lease parser on BioInfer includes multiple sources
of divergence. In addition to parser errors, differ-
ences can be created by the LG-SF conversion and
the Stanford conversion. Moreover, in examining
the outputs we identified that a further source of
divergence is due to differing interpretations of the
Stanford scheme. One such difference is illustrated
in Figure 5. Here the BioLG parser with the LG-
SF conversion produces an analysis that differs from
the result of converting the GENIA Treebank analy-
sis by the Stanford conversion. This is due to the
Stanford conversion producing an apparently flawed
analysis that is not replicated by the LG-SF con-
version. In certain cases of this type, the lack of a
detailed definition of the SF scheme prevents from
distinguishing between conversion errors and inten-
tional analyses. This will necessarily lead to differ-
ing interpretations, complicating precise evaluation.
6 Conclusions
We have presented a step towards unifying syntactic
annotations under the Stanford dependency scheme
and assessed the feasibility of this unification by
developing and evaluating a conversion from Link
Grammar to the Stanford scheme. We find that a
highly reliable transformation can be created, giv-
ing a precision and recall of 98.0% and 96.2%, re-
spectively, when compared against our manually an-
notated gold standard version of the BioInfer cor-
pus. We also find that the performance of the BioLG
parser is not adversely affected by the conversion.
Given the clear benefits that the Stanford scheme
has for domain analysis, the conversion increases the
overall suitability of the parser to IE applications.
Based on these results, we conclude that converting
to the Stanford scheme is both feasible and practical.
Further, we have developed a version of the
BioInfer corpus annotated with the Stanford scheme,
thereby increasing the usability of the corpus. We
applied the LG-SF conversion to the original LG
BioInfer annotation and manually corrected the er-
rors. The high annotator agreement of above 97%
precision and recall confirms the stability of the SF
scheme.
We have also demonstrated that the unification
permits direct parser comparison that was previously
impossible. However, we found that there is a cer-
tain accumulation of errors caused by the conver-
sion, particularly in a case when two distinct rule
sets are applied. In our case, we estimate this error
to be on the order of several percentage units, never-
theless, we were able to establish the relative perfor-
mance of the parses with a strong statistical signif-
icance. These results demonstrate the utility of the
Stanford scheme as a unifying representation of syn-
tax. We note that an authoritative definition of the
Stanford scheme would further increase its value.
Acknowledgments
We would like to thank Erick Alphonse, Sophie
Aubin and Adeline Nazarenko for providing us with
the lp2lp software and the LLL conversion rules. We
would also like to thank Andrew Brian Clegg and
Adrian Shepherd for making available the data and
evaluation tools used in their parser evaluation. This
work was supported by the Academy of Finland.
31
References
Erick Alphonse, Sophie Aubin, Philippe Bessie`res, Gilles
Bisson, Thierry Hamon, Sandrine Laguarigue, Ade-
line Nazarenko, Alain-Pierre Manine, Claire Ne?dellec,
Mohamed Ould Abdel Vetah, Thierry Poibeau, and
Davy Weissenbacher. 2004. Event-Based Information
Extraction for the biomedical domain: the Caderige
project. In N. Collier, P. Ruch, and A. Nazarenko, ed-
itors, COLING NLPBA/BioNLP Workshop, pages 43?
49, Geneva, Switzerland.
Sophie Aubin, Adeline Nazarenko, and Claire Ne?dellec.
2005. Adapting a general parser to a sublanguage. In
G. Angelova, K. Bontcheva, R. Mitkov, N. Nicolov,
and N. Nikolov, editors, Proceedings of the Interna-
tional Conference on Recent Advances in Natural Lan-
guage Processing (RANLP 05), Borovets, Bulgaria,
pages 89?93. Incoma, Bulgaria.
Sophie Aubin. 2005. LLL challenge - syntactic analysis
guidelines. Technical report, LIPN, Universite? Paris
Nord, Villetaneuse.
Ann Bies, Mark Ferguson, Karen Katz, and Robert Mac-
Intyre. 1995. Bracketing guidelines for treebank ii
style. Technical report, Penn Treebank Project, Uni-
versity of Pennsylvania.
Eugene Charniak and Matthew Lease. 2005. Parsing
biomedical literature. In R. Dale, K. F. Wong, J. Su,
and O. Y. Kwong, editors, Proceedings of the Sec-
ond International Joint Conference on Natural Lan-
gage Processing, Jeju Island, Korea, pages 58?69.
Eugene Charniak. 1999. A maximum-entropy-inspired
parser. Technical report, Brown University.
Andrew Brian Clegg and Adrian Shepherd. 2007.
Benchmarking natural-language parsers for biological
applications using dependency graphs. BMC Bioinfor-
matics, 8(1):24.
Michael Collins. 1999. Head-Driven Statistical Models
for Natural Language Parsing. Ph.D. thesis, Univer-
sity of Pennsylvania.
Marie-Catherine de Marneffe, Bill MacCartney, and
Christopher D. Manning. 2006. Generating typed
dependency parses from phrase structure parses. In
N. Calzolari, K. Choukri, A. Gangemi, B. Maegaard,
J. Mariani, J. Odijk, and D. Tapias, editors, Proceed-
ings of the 5th International Conference on Language
Resources and Evaluation (LREC 2006), pages 449?
454.
Janez Dems?ar. 2006. Statistical comparisons of clas-
sifiers over multiple data sets. Journal of Machine
Learning Research, 7:1?30.
Jing Ding, Daniel Berleant, Jun Xu, and Andy W. Fulmer.
2003. Extracting biochemical interactions from med-
line using a link grammar parser. In B. Werner, editor,
Proceedings of the 15th IEEE International Confer-
ence on Tools with Artificial Intelligence, pages 467?
471. IEEE Computer Society, Los Alamitos, CA.
Katrin Fundel, Robert Kuffner, and Ralf Zimmer. 2007.
RelEx?Relation extraction using dependency parse
trees. Bioinformatics, 23(3):365?371.
Jin-Dong Kim, Tomoko Ohta, Yuka Tateisi, and Jun?ichi
Tsujii. 2003. GENIA corpus?a semantically an-
notated corpus for bio-textmining. Bioinformatics,
19:i180?182.
Roger Levy and Galen Andrew. 2006. Tregex and Tsur-
geon: tools for querying and manipulating tree data
structures. In N. Calzolari, K. Choukri, A. Gangemi,
B. Maegaard, J. Mariani, J. Odijk, and D. Tapias, ed-
itors, Proceedings of the 5th International Conference
on Language Resources and Evaluation (LREC 2006),
pages 2231?2234.
Dekang Lin. 1998. A dependency-based method for
evaluating broad-coverage parsers. Natural Language
Engineering, 4(2):97?114.
Sampo Pyysalo, Tapio Salakoski, Sophie Aubin, and
Adeline Nazarenko. 2006. Lexical adaptation of link
grammar to the biomedical sublanguage: a compara-
tive evaluation of three approaches. BMC Bioinfor-
matics, 7(Suppl 3).
Sampo Pyysalo, Filip Ginter, Juho Heimonen, Jari
Bjo?rne, Jorma Boberg, Jouni Ja?rvinen, and Tapio
Salakoski. 2007. BioInfer: A corpus for information
extraction in the biomedical domain. BMC Bioinfor-
matics, 8(50).
Fabio Rinaldi, Gerold Schneider, Kaarel Kaljurand,
James Dowdall, Andreas Persidis, and Ourania Kon-
stanti. 2004. Mining relations in the genia corpus. In
Proceedings of the Workshop W9 on Data Mining and
Text Mining for Bioinformatics (ECML/PKDD?04),
pages 61?68, Pisa, Italy.
Gerold Schneider. 1998. A linguistic comparison of
constituency, dependency and link grammar. Master?s
thesis, University of Zu?rich.
Daniel D. Sleator and Davy Temperley. 1993. Parsing
English with a Link Grammar. In Third International
Workshop on Parsing Technologies.
Yoshimasa Tsuruoka, Yuka Tateishi, Jin-Dong Kim,
Tomoko Ohta, John McNaught, Sophia Ananiadou,
and Jun?ichi Tsujii. 2005. Developing a robust part-
of-speech tagger for biomedical text. In P. Bozanis and
E. N. Houstis, editors, 10th Panhellenic Conference on
Informatics, volume 3746, pages 382?392.
32
Proceedings of the Fourth Linguistic Annotation Workshop, ACL 2010, pages 137?141,
Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational Linguistics
Dependency-based PropBanking of clinical Finnish
Katri Haverinen,1,3 Filip Ginter,1 Timo Viljanen,1
Veronika Laippala2 and Tapio Salakoski1,3
1Department of Information Technology
2Department of French Studies
3Turku Centre for Computer Science, TUCS
20014 University of Turku, Finland
first.last@utu.fi
Abstract
In this paper, we present a PropBank of
clinical Finnish, an annotated corpus of
verbal propositions and arguments. The
clinical PropBank is created on top of a
previously existing dependency treebank
annotated in the Stanford Dependency
(SD) scheme and covers 90% of all verb
occurrences in the treebank.
We establish that the PropBank scheme
is applicable to clinical Finnish as well
as compatible with the SD scheme, with
an overwhelming proportion of arguments
being governed by the verb. This allows
argument candidates to be restricted to di-
rect verb dependents, substantially simpli-
fying the PropBank construction.
The clinical Finnish PropBank
is freely available at the address
http://bionlp.utu.fi.
1 Introduction
Natural language processing (NLP) in the clini-
cal domain has received substantial interest, with
applications in decision support, patient man-
aging and profiling, mining trends, and others
(see the extensive review by Friedman and John-
son (2006)). While some of these applications,
such as document retrieval and trend mining,
can rely solely on word-frequency-based methods,
others, such as information extraction and summa-
rization require a detailed linguistic analysis cap-
turing some of the sentence semantics. Among the
most important steps in this direction is an analysis
of verbs and their argument structures.
In this work, we focus on the Finnish lan-
guage in the clinical domain, analyzing its verbs
and their argument structures using the PropBank
scheme (Palmer et al, 2005). The choice of this
particular scheme is motivated by its practical,
application-oriented nature. We build the clinical
Finnish PropBank on top of the existing depen-
dency treebank of Haverinen et al (2009).
The primary outcome of this study is the
PropBank of clinical Finnish itself, consisting of
the analyses for 157 verbs with 2,382 occurrences
and 4,763 arguments, and covering 90% of all
verb occurrences in the underlying treebank. This
PropBank, together with the treebank, is an impor-
tant resource for the further development of clini-
cal NLP applications for the Finnish language.
We also establish the applicability of the
PropBank scheme to the clinical sublanguage with
its many atypical characteristics, and finally, we
find that the PropBank scheme is compatible with
the Stanford Dependency scheme of de Marneffe
and Manning (2008a; 2008b) in which the under-
lying treebank is annotated.
2 The PropBank scheme
Our annotation work is based on the PropBank se-
mantic annotation scheme of Palmer et al (2005).
For each verb, PropBank defines a number of
framesets, each frameset corresponding to a
coarse-grained sense. A frameset consists of a
roleset which defines a set of roles (arguments
numbered from Arg0 onwards) and their descrip-
tions, and a set of syntactic frames. Any element
that occurs together with a given verb sufficiently
frequently is taken to be its argument. Arg0 is gen-
erally a prototypical Agent argument and Arg1 is
a prototypical Patient or Theme argument. The
remaining numbered arguments have no consis-
tent overall meanings: they are defined on a verb-
by-verb basis. An illustration of a verb with two
framesets is given in Figure 1. In addition to the
numbered arguments, a verb occurrence can have
a number of modifiers, labeled ArgM, each modi-
fier being categorized as one of 14 subtypes, such
as temporal, cause and location.
137
kesta?a?.0: ?tolerate? kesta?a?.1: ?last?
Arg0: the one who tolerates Arg1: the thing that lasts
Arg1: what is being tolerated Arg2: how long it lasts
Figure 1: The PropBank framesets for kesta?a?
(translated to English from the original frames file)
correspond to two different uses of the verb.
Pitka? yo?vuoro Long nightshift
Jouduttu laittamaan Had to put to
illala bipap:lle, bipap in the evning,
nyt hapettuu hyvin. now oxidizes well.
DIUREESI: riitta?va?a? DIURESIS: sufficient
Tajunta: rauhallinen Consciousness: calm
hrhoja ei ena?a? ole there are no more hllucinations
Figure 2: Example of clinical Finnish (left col-
umn) and its exact translation (right column), with
typical features such as spelling errors preserved.
3 Clinical Finnish and the clinical
Finnish treebank
This study is based on the clinical Finnish tree-
bank of Haverinen et al (2009), which consists
of 2,081 sentences with 15,335 tokens and 13,457
dependencies. The text of the treebank comprises
eight complete patient reports from an intensive
care unit in a Finnish hospital. An intensive care
patient report describes the condition of the pa-
tient and its development in time. The clinical
Finnish in these reports has many characteristics
typical of clinical languages, including frequent
misspellings, abbreviations, domain terms, tele-
graphic style and non-standard syntactic structures
(see Figure 2 for an illustration). For a detailed
analysis, we refer the reader to the studies by Laip-
pala et al (2009) and Haverinen et al (2009).
The treebank of Haverinen et al is annotated
in the Stanford Dependency (SD) scheme of de
Marneffe and Manning (2008a; 2008b). This
scheme is layered, and the annotation variant of
the treebank of Haverinen et. al is the basic vari-
ant of the scheme, in which the analysis forms a
tree.
The SD scheme also defines a collapsed de-
pendencies with propagation of conjunct depen-
dencies variant (referred to as the extended vari-
ant of the SD scheme throughout this paper). It
adds on top of the basic variant a second layer
of dependencies which are not part of the strict,
syntactic tree. In particular, the xsubj dependency
marks external subjects, and dependencies involv-
ing the heads of coordinations are explicitly dupli-
PatientPotilas allowedsaanut to_haveottaa juicemehua andja breadleip?? ..
<nsubj xcomp> dobj> cc><xsubj conj>
dobj>punct>
Figure 3: The extended SD scheme. The dashed
dependencies denote the external subjects and
propagated conjunct dependencies that are only
part of the extended variant of the scheme. The
example can be translated as Patient [has been]
allowed to have juice and bread.
In_morningAamulla patientpotilas drankjuonut.0 littlev?h?n juicemehua ..
<nsubj:Arg0 <advmod<nommod:ArgM?tmp dobj:Arg1>
punct>
Figure 4: The PropBank annotation scheme on
top of the treebank syntactic annotation. The verb
juonut (drank) is marked with its frameset, in this
case the frameset number 0. This frameset spec-
ifies that Arg0 marks the agent doing the drink-
ing and Arg1 the liquid being consumed. The
ArgM-tmp label specifies that Aamulla is a tem-
poral modifier. The example can be translated as
In the morning patient drank a little juice.
cated also for the remaining coordinated elements
where appropriate. The extended variant of the SD
scheme is illustrated in Figure 3.
Due to the importance of the additional depen-
dencies for PropBanking (see Section 5 for discus-
sion), we augment the annotation of the underly-
ing treebank to conform to the extended variant of
the SD scheme by manual annotation, adding a to-
tal of 520 dependencies.
The PropBank was originally developed on top
of the constituency scheme of the Penn Tree-
bank and requires arguments to correspond to con-
stituents. In a dependency scheme, where there is
no explicit notion of constituents, we associate ar-
guments of a verb with dependencies governed by
it. The argument can then be understood as the
entire subtree headed by the dependent. The an-
notation is illustrated in Figure 4.
4 PropBanking clinical Finnish
When annotating the clinical Finnish PropBank,
we consider all verbs with at least three occur-
rences in the underlying treebank. In total, we
analyze 157 verbs with 192 framesets. Since the
treebank does not have gold-standard POS infor-
138
FuresisFuresis notei helpedauttanut.0 ,, stoppedlopetettu.0 for_nowtoistaiseksi ..
<neg:ArgM punct> advmod:ArgM?tmp><subj:Arg1 sdep:ArgM?csq>
<xarg:ArgM?cau<xarg:Arg1
punct>
Figure 5: The simplified PropBank annotation strategy. The dashed dependencies labeled with the tech-
nical dependency type xarg signify arguments and modifiers not in a syntactic relationship to the verb.
These arguments and modifiers, as well as those associated with a conj or sdep dependency (ArgM-csq
in this Figure), are only marked in the 100 sentence sample for quantifying unannotated arguments and
modifiers. The sentence can be translated as Furesis did not help, stopped for now.
mation, we identify all verbs and verbal participles
using the FinCG1 analyzer, which gives a verbal
reading to 2,816 tokens. With POS tagging er-
rors taken into account, we estimate the treebank
to contain 2,655 occurrences of verbs and verb
participles. Of these, 2,382 (90%) correspond to
verbs with at least three occurrences and are thus
annotated. In total, these verbs have 4,763 argu-
ments and modifiers.
Due to the telegraphic nature of clinical Finnish,
omissions of different sentence elements, even
main verbs, are very frequent. In order to be able
to analyze the syntax of sentences with a missing
main verb, Haverinen et al have added a so called
null verb to these sentences in the treebank. For
instance, the clinical Finnish sentence Putkesta
nestetta? (Liquid from the drain) lacks a main verb,
and the insertion of one produces Putkesta *null*
nestetta?. In total, there are 428 null verb occur-
rences, making the null verb the most common
verb in the treebank.
In the clinical PropBank annotation, we treat the
null verb in principle as if it was a regular verb,
and give it framesets accordingly. For each null
verb occurrence, we have determined which reg-
ular verb frameset it stands for, and found that,
somewhat surprisingly, there were only four com-
mon coarse senses of the null verb, roughly cor-
responding to four framesets of the verbs olla (to
be), tulla (to come), tehda? (to do) and laittaa (to
put). The 26 (6%) null verb occurrences that did
not correspond to any of these four framesets were
assigned to a ?leftover frameset?, for which no ar-
guments were marked.
1http://www.lingsoft.fi
5 Annotating the arguments on top of
the SD scheme
In contrast to the original PropBank, where any
syntactic constituent could be marked as an argu-
ment, we require arguments to be directly depen-
dent on the verb in the SD scheme (for an illustra-
tion, see Figure 5). This restriction is to consider-
ably simplify the annotation process ? instead of
all possible subtrees, the annotator only needs to
look for direct dependents of the verb. In addition,
this constraint should naturally also simplify pos-
sible automatic identification and classification of
the arguments.
In addition to restricting arguments to direct de-
pendents of the verb, coordination dependencies
conj and sdep (implicit coordination of top level
independent clauses, see Figure 5) are left outside
the annotation scope. This is due to the nature of
the clinical language, which places on these de-
pendencies cause-consequence relationships that
require strong inference. For instance, sentences
such as Patient restless, given tranquilizers where
there is clearly a causal relationship but no explicit
marker such as thus or because, are common.
Naturally, it is necessary to estimate the effect
of these restrictions, which can be justified only
if the number of lost arguments is minimal. We
have conducted a small-scale experiment on 100
randomly selected sentences with at least one verb
that has a frameset assigned. We have provided
this portion of the clinical PropBank with a full an-
notation, including the arguments not governed by
the verb and those associated with conj and sdep
dependencies. For an illustration, see Figure 5.
There are in total 326 arguments and modifiers
(169 arguments and 157 modifiers) in the 100 sen-
tence sample. Of these, 278 (85%) are governed
by the verb in the basic SD scheme and are thus in
a direct syntactic relationship with the verb. Fur-
139
ther 19 (6%) arguments and modifiers are gov-
erned by the verb in the extended SD scheme. Out
of the remaining 29 (9%), 23 are in fact modi-
fiers, leaving only 6 numbered arguments not ac-
counted for in the extended SD scheme. Thus,
96% (163/169) of arguments and 85% (134/157)
of modifiers are directly governed by the verb.
Of the 23 ungoverned modifiers, all are either
cause (CAU) or consequence (CSQ)2. Of the sdep
and conj dependencies only a small portion (9/68)
were associated with an argument or a modifier,
all of which were in fact CAU or CSQ modifiers.
Both these and the CAU and CSQ modifiers not
governed by the verb reflect strongly inferred rela-
tionships between clauses.
Based on these figures, we conclude that an
overwhelming majority of arguments and modi-
fiers is governed by the verb in the extended SD
scheme and restricting the annotation to depen-
dents of the verb as well as leaving sdep and conj
outside the annotation scope seems justified. Ad-
ditionally, we demonstrate the utility of the con-
junct dependency propagation and external subject
marking in the extended SD scheme.
6 Related work
Many efforts have been made to capture meanings
and arguments of verbs. For instance, the VerbNet
project (Kipper et al, 2000) strives to create a
broad on-line verb lexicon, and FrameNet (Rup-
penhofer et al, 2005) aims to document the range
of valences of each verb in each of its senses. The
PropBank project (Palmer et al, 2005) strives for
a practical approach to semantic representation,
adding a layer of semantic role labels to the Penn
Treebank (Marcus et al, 1993).
In addition to the original PropBank by Palmer
et al, numerous PropBanks have been devel-
oped for languages other than English (e.g. Chi-
nese (Xue and Palmer, 2003) and Arabic (Diab
et al, 2008)). Also applications attempting to
automatically recover PropBank-style arguments
have been proposed. For example, the CoNLL
shared task has focused on semantic role labeling
four times, twice as a separate task (Carreras and
Ma`rquez, 2004; Carreras and Ma`rquez, 2005), and
twice in conjunction with syntactic parsing (Sur-
deanu et al, 2008; Hajic? et al, 2009).
2CSQ is a new modifier subtype added by us, due to
the restriction of only annotating direct syntactic dependents,
which does not allow the annotation of all causal relation-
ships with the type CAU.
In semantic analysis of clinical language, Paek
et al (2006) have experimented on PropBank-
based machine learning on abstracts of Random-
ized Controlled Trials (RCTs), and Savova et
al. (2009) have presented work on temporal rela-
tion discovery from clinical narratives.
7 Conclusion
In this paper, we have presented a PropBank of
clinical Finnish, building a new layer of annotation
on top of the existing clinical treebank of Haver-
inen et al (2009). This PropBank covers all 157
verbs occurring at least three times in the treebank
and accounts for 90% of all verb occurrences.
This work has also served as a test case for the
PropBank annotation scheme in two senses. First,
the scheme has been tested on a highly specialized
language, clinical Finnish, and second, its compa-
tibility with the SD syntactic scheme has been ex-
amined. On both accounts, we find the PropBank
scheme a suitable choice.
In general, the specialized language did not
seem to cause problems for the scheme. For in-
stance, the frequent null verbs could be analyzed
similarly to regular verbs, with full 94% belonging
to one of only four framesets. This is likely due to
the very restricted clinical domain of the corpus.
We also find a strong correspondence between
the PropBank arguments and the verb dependents
in the extended SD scheme, with 96% of argu-
ments and 85% of modifiers being directly gov-
erned by the verb. The 15% ungoverned modifiers
are cause-consequence relationships that require
strong inference. This correspondence allowed us
to simplify the annotation task by only considering
direct verb dependents as argument candidates.
The new version of the treebank, manually
anonymized, including the enhanced SD scheme
annotation and the PropBank annotation, is freely
available at http://bionlp.utu.fi.
Acknowledgments
We are grateful to Helja? Lundgren-Laine, Riitta
Danielsson-Ojala and prof. Sanna Salantera? for
their assistance in the anonymization of the cor-
pus. We would also like to thank Lingsoft Ltd.
for making FinTWOL and FinCG available to us.
This work was supported by the Academy of Fin-
land.
140
References
Xavier Carreras and Llu??s Ma`rquez. 2004. In-
troduction to the CoNLL-2004 shared task: Se-
mantic role labeling. In HLT-NAACL 2004 Work-
shop: Eighth Conference on Computational Natu-
ral Language Learning (CoNLL-2004), pages 89?
97, Boston, Massachusetts, USA, May 6 - May 7.
Association for Computational Linguistics.
Xavier Carreras and Llu??s Ma`rquez. 2005. Intro-
duction to the CoNLL-2005 shared task: Semantic
role labeling. In Proceedings of the Ninth Confer-
ence on Computational Natural Language Learning
(CoNLL-2005), pages 152?164, Ann Arbor, Michi-
gan, June. Association for Computational Linguis-
tics.
Marie-Catherine de Marneffe and Christopher Man-
ning. 2008a. Stanford typed dependencies manual.
Technical report, Stanford University, September.
Marie-Catherine de Marneffe and Christopher Man-
ning. 2008b. Stanford typed dependencies repre-
sentation. In Proceedings of COLING?08, Workshop
on Cross-Framework and Cross-Domain Parser
Evaluation, pages 1?8.
Mona Diab, Mansouri Aous, Martha Palmer, Babko-
Malaya Olga, Wadji Zaghouani, Ann Bies, and
Mohammed Maamouri. 2008. A pilot Arabic
PropBank. In Proceedings of LREC?08, pages
3467?3472. Association for Computational Linguis-
tics.
Carol Friedman and Stephen Johnson. 2006. Natu-
ral language and text processing in biomedicine. In
Biomedical Informatics, pages 312?343. Springer.
Jan Hajic?, Massimiliano Ciaramita, Richard Johansson,
Daisuke Kawahara, Maria A. Mart??, Llu??s Ma`rquez,
Adam Meyers, Joakim Nivre, Sebastian Pado?, Jan
S?te?pa?nek, Pavel Stran?a?k, Mihai Surdeanu, Niawen
Xue, and Yi Zhang. 2009. The CoNLL-2008
shared task: Syntactic and semantic dependencies in
multiple languages. In Proceedings of CoNLL?09:
Shared Task, pages 1?18. Association for Computa-
tional Linguistics.
Katri Haverinen, Filip Ginter, Veronika Laippala, and
Tapio Salakoski. 2009. Parsing clinical Finnish:
Experiments with rule-based and statistical depen-
dency parsers. In Proceedings of NODALIDA?09,
Odense, Denmark, pages 65?72.
Karin Kipper, Hoa Trang Dang, and Martha Palmer.
2000. Class-based construction of a verb lexicon.
In Proceedings of the Seventeenth National Confer-
ence on Artificial Intelligence and Twelfth Confer-
ence on Innovative Applications of Artificial Intelli-
gence, pages 691?696. AAAI Press / The MIT Press.
Veronika Laippala, Filip Ginter, Sampo Pyysalo, and
Tapio Salakoski. 2009. Towards automatic process-
ing of clinical Finnish: A sublanguage analysis and
a rule-based parser. International Journal of Medi-
cal Informatics, Special Issue on Mining of Clinical
and Biomedical Text and Data, 78:7?12.
Mitchell Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1993. Building a large annotated
corpus of English: The Penn Treebank. Computa-
tional Linguistics, 19(2):313?330.
Hyung Paek, Yacov Kogan, Prem Thomas, Seymor
Codish, and Michael Krauthammer. 2006. Shallow
semantic parsing of randomized controlled trial re-
ports. In Proceedings of AMIA?06, pages 604?608.
Martha Palmer, Dan Gildea, and Paul Kingsbury. 2005.
The Proposition Bank: an annotated corpus of se-
mantic roles. Computational Linguistics, 31(1).
Josef Ruppenhofer, Michael Ellsworth, Miriam R. L.
Petruck, Christopher R. Johnson, and Jan Schef-
fczyk. 2005. FrameNet II: Extended theory and
practice. Technical report, ICSI.
Guergana Savova, Steven Bethard, Will Styler, James
Martin, Martha Palmer, James Masanz, and Wayne
Ward. 2009. Towards temporal relation discov-
ety from the clinical narrative. In Proceedings of
AMIA?09, pages 568?572.
Mihai Surdeanu, Richard Johansson, Adam Meyers,
Llu??s Ma`rquez, and Joakim Nivre. 2008. The
CoNLL-2008 shared task on joint parsing on syn-
tactic and semantic dependencies. In Proceedings of
CoNLL?08, pages 159?177. Association for Compu-
tational Linguistics.
Nianwen Xue and Martha Palmer. 2003. Annotating
the propositions in the Penn Chinese Treebank. In
Proceedings of the 2nd SIGHAN Workshop on Chi-
nese Language Processing, pages 47?54, Sapporo,
Japan. Association for Computational Linguistics.
141
