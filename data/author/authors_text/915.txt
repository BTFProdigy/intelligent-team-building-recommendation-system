Unsupervised Relation Extraction from Web Documents
Kathrin Eichler, Holmer Hemsen and Gu?nter Neumann
DFKI GmbH, LT-Lab, Stuhlsatzenhausweg 3 (Building D3 2), D-66123 Saarbru?cken
{FirstName.SecondName}@dfki.de
Abstract
The IDEX system is a prototype of an interactive dynamic Information Extraction (IE) system. A user of the system
expresses an information request in the form of a topic description, which is used for an initial search in order to retrieve
a relevant set of documents. On basis of this set of documents, unsupervised relation extraction and clustering is done by
the system. The results of these operations can then be interactively inspected by the user. In this paper we describe the
relation extraction and clustering components of the IDEX system. Preliminary evaluation results of these components are
presented and an overview is given of possible enhancements to improve the relation extraction and clustering components.
1. Introduction
Information extraction (IE) involves the process of au-
tomatically identifying instances of certain relations of
interest, e.g., produce(<company>, <product>, <lo-
cation>), in some document collection and the con-
struction of a database with information about each
individual instance (e.g., the participants of a meet-
ing, the date and time of the meeting). Currently, IE
systems are usually domain-dependent and adapting
the system to a new domain requires a high amount
of manual labour, such as specifying and implement-
ing relation?specific extraction patterns manually (cf.
Fig. 1) or annotating large amounts of training cor-
pora (cf. Fig. 2). These adaptations have to be made
offline, i.e., before the specific IE system is actually
made. Consequently, current IE technology is highly
statical and inflexible with respect to a timely adapta-
tion to new requirements in the form of new topics.
Figure 1: A hand-coded rule?based IE?system (schemat-
ically): A topic expert implements manually task?specific
extraction rules on the basis of her manual analysis of a
representative corpus.
1.1. Our goal
The goal of our IE research is the conception and im-
plementation of core IE technology to produce a new
Figure 2: A data?oriented IE system (schematically): The
task?specific extraction rules are automatically acquired by
means of Machine Learning algorithms, which are using
a sufficiently large enough corpus of topic?relevant docu-
ments. These documents have to be collected and costly
annotated by a topic?expert.
IE system automatically for a given topic. Here, the
pre?knowledge about the information request is given
by a user online to the IE core system (called IDEX)
in the form of a topic description (cf. Fig. 3). This
initial information source is used to retrieve relevant
documents and extract and cluster relations in an un-
supervised way. In this way, IDEX is able to adapt
much better to the dynamic information space, in par-
ticular because no predefined patterns of relevant re-
lations have to be specified, but relevant patterns are
determined online. Our system consists of a front-end,
which provides the user with a GUI for interactively in-
specting information extracted from topic-related web
documents, and a back-end, which contains the rela-
tion extraction and clustering component. In this pa-
per, we describe the back-end component and present
preliminary evaluation results.
1.2. Application potential
However, before doing so we would like to motivate
the application potential and impact of the IDEX ap-
Figure 3: The dynamic IE system IDEX (schematically):
a user of the IDEX IE system expresses her information
request in the form of a topic description which is used for
an initial search in order to retrieve a relevant set of doc-
uments. From this set of documents, the system extracts
and collects (using the IE core components of IDEX) a set
of tables of instances of possibly relevant relations. These
tables are presented to the user (who is assumed to be the
topic?expert), who will analyse the data further for her in-
formation research. The whole IE process is dynamic, since
no offline data is required, and the IE process is interactive,
since the topic expert is able to specify new topic descrip-
tions, which express her new attention triggered by a novel
relationship she was not aware of beforehand.
proach by an example application. Consider, e.g., the
case of the exploration and the exposure of corruptions
or the risk analysis of mega construction projects. Via
the Internet, a large pool of information resources of
such mega construction projects is available. These
information resources are rich in quantity, but also
in quality, e.g., business reports, company profiles,
blogs, reports by tourists, who visited these construc-
tion projects, but also web documents, which only
mention the project name and nothing else. One of
the challenges for the risk analysis of mega construc-
tion projects is the efficient exploration of the possibly
relevant search space. Developing manually an IE sys-
tem is often not possible because of the timely need
of the information, and, more importantly, is proba-
bly not useful, because the needed (hidden) informa-
tion is actually not known. In contrast, an unsuper-
vised and dynamic IE system like IDEX can be used
to support the expert in the exploration of the search
space through pro?active identification and clustering
of structured entities. Named entities like for example
person names and locations, are often useful indicators
of relevant text passages, in particular, if the names are
in some relationship. Furthermore, because the found
relationships are visualized using an advanced graph-
ical user interface, the user can select specific names
and find associated relationships to other names, the
documents they occur in or she can search for para-
phrases of sentences.
2. System architecture
The back-end component, visualized in Figure 4, con-
sists of three parts, which are described in detail in this
section: preprocessing, relation extraction and relation
clustering.
2.1. Preprocessing
In the first step, for a specific search task, a topic of
interest has to be defined in the form of a query. For
this topic, documents are automatically retrieved from
the web using the Google search engine. HTML and
PDF documents are converted into plain text files. As
the tools used for linguistic processing (NE recogni-
tion, parsing, etc.) are language-specific, we use the
Google language filter option when downloading the
documents. However, this does not prevent some doc-
uments written in a language other than our target
language (English) from entering our corpus. In ad-
dition, some web sites contain text written in several
languages. In order to restrict the processing to sen-
tences written in English, we apply a language guesser
tool, lc4j (Lc4j, 2007) and remove sentences not clas-
sified as written in English. This reduces errors on
the following levels of processing. We also remove sen-
tences that only contain non-alphanumeric characters.
To all remaining sentences, we apply LingPipe (Ling-
Pipe, 2007) for sentence boundary detection, named
entity recognition (NER) and coreference resolution.
As a result of this step database tables are created,
containing references to the original document, sen-
tences and detected named entities (NEs).
2.2. Relation extraction
Relation extraction is done on the basis of parsing po-
tentially relevant sentences. We define a sentence to be
of potential relevance if it at least contains two NEs.
In the first step, so-called skeletons (simplified depen-
dency trees) are extracted. To build the skeletons, the
Stanford parser (Stanford Parser, 2007) is used to gen-
erate dependency trees for the potentially relevant sen-
tences. For each NE pair in a sentence, the common
root element in the corresponding tree is identified and
the elements from each of the NEs to the root are col-
lected. An example of a skeleton is shown in Figure 5.
In the second step, information based on dependency
types is extracted for the potentially relevant sen-
tences. Focusing on verb relations (this can be ex-
tended to other types of relations), we collect for each
verb its subject(s), object(s), preposition(s) with ar-
guments and auxiliary verb(s). We can now extract
verb relations using a simple algorithm: We define a
verb relation to be a verb together with its arguments
(subject(s), object(s) and prepositional phrases) and
consider only those relations to be of interest where at
least the subject or the object is an NE. We filter out
relations with only one argument.
2.3. Relation clustering
Relation clusters are generated by grouping relation
instances based on their similarity.
web documents document
retrieval
topic specific documents plain text documents
sentence/documents+
 NE tables
languagefiltering
syntactic +typed dependencyparsing 
sov?relationsskeletons +
clustering
conversion
Preprocessing
Relation extraction
Relation clustering
sentencesrelevant
filtering of
relationfiltering
table of clustered relations
sentence boundary
resolutioncoreference
detection,NE recognition,
Figure 4: System architecture
Figure 5: Skeleton for the NE pair ?Hohenzollern? and ?Brandenburg? in the sentence ?Subsequent members of
the Hohenzollern family ruled until 1918 in Berlin, first as electors of Brandenburg.?
The comparably large amount of data in the corpus
requires the use of an efficient clustering algorithm.
Standard ML clustering algorithms such as k-means
and EM (as provided by the Weka toolbox (Witten
and Frank, 2005)) have been tested for clustering the
relations at hand but were not able to deal with the
large number of features and instances required for an
adequate representation of our dataset. We thus de-
cided to use a scoring algorithm that compares a re-
lation to other relations based on certain aspects and
calculates a similarity score. If this similarity score ex-
ceeds a predefined threshold, two relations are grouped
together.
Similarity is measured based on the output from the
different preprocessing steps as well as lexical informa-
tion from WordNet (WordNet, 2007):
? WordNet: WordNet information is used to deter-
mine if two verb infinitives match or if they are in
the same synonym set.
? Parsing: The extracted dependency information is
used to measure the token overlap of the two sub-
jects and objects, respectively. We also compare
the subject of the first relation with the object of
the second relation and vice versa. In addition,
we compare the auxiliary verbs, prepositions and
preposition arguments found in the relation.
? NE recognition: The information from this step
is used to count how many of the NEs occurring
in the contexts, i.e., the sentences in which the
two relations are found, match and whether the
NE types of the subjects and objects, respectively,
match.
? Coreference resolution: This type of information
is used to compare the NE subject (or object) of
one relation to strings that appear in the same
coreference set as the subject (or object) of the
second relation.
Manually analyzing a set of extracted relation in-
stances, we defined weights for the different similarity
measures and calculated a similarity score for each re-
lation pair. We then defined a score threshold and clus-
tered relations by putting two relations into the same
cluster if their similarity score exceeded this threshold
value.
3. Experiments and results
For our experiments, we built a test corpus of doc-
uments related to the topic ?Berlin Hauptbahnhof?
by sending queries describing the topic (e.g., ?Berlin
Hauptbahnhof?, ?Berlin central station?) to Google
and downloading the retrieved documents specifying
English as the target language. After preprocessing
these documents as described in 2.1., our corpus con-
sisted of 55,255 sentences from 1,068 web pages, from
which 10773 relations were automatically extracted
and clustered.
3.1. Clustering
From the extracted relations, the system built 306 clus-
ters of two or more instances, which were manually
evaluated by two authors of this paper. 81 of our clus-
ters contain two or more instances of exactly the same
relation, mostly due to the same sentence appearing in
several documents of the corpus. Of the remaining 225
clusters, 121 were marked as consistent, 35 as partly
consistent, 69 as not consistent. We defined consis-
tency based on the potential usefulness of a cluster to
the user and identified three major types of potentially
useful clusters:
? Relation paraphrases, e.g.,
accused (Mr Moore, Disney, In letter)
accused (Michael Moore, Walt Disney
Company)
? Different instances of the same pattern, e.g.,
operates (Delta, flights, from New York)
offers (Lufthansa, flights, from DC)
? Relations about the same topic (NE), e.g.,
rejected (Mr Blair, pressure, from Labour
MPs)
reiterated (Mr Blair, ideas, in speech, on
March)
created (Mr Blair, doctrine)
...
Of our 121 consistent clusters, 76 were classified as be-
ing of the type ?same pattern?, 27 as being of the type
?same topic? and 18 as being of the type ?relation para-
phrases?. As many of our clusters contain two instances
only, we are planning to analyze whether some clusters
should be merged and how this could be achieved.
3.2. Relation extraction
In order to evaluate the performance of the relation ex-
traction component, we manually annotated 550 sen-
tences of the test corpus by tagging all NEs and verbs
and manually extracting potentially interesting verb
relations. We define ?potentially interesting verb rela-
tion? as a verb together with its arguments (i.e., sub-
ject, objects and PP arguments), where at least two
of the arguments are NEs and at least one of them
is the subject or an object. On the basis of this crite-
rion, we found 15 potentially interesting verb relations.
For the same sentences, the IDEX system extracted 27
relations, 11 of them corresponding to the manually
extracted ones. This yields a recall value of 73% and
a precision value of 41%.
There were two types of recall errors: First, errors in
sentence boundary detection, mainly due to noisy in-
put data (e.g., missing periods), which lead to parsing
errors, and second, NER errors, i.e., NEs that were
not recognised as such. Precision errors could mostly
be traced back to the NER component (sequences of
words were wrongly identified as NEs).
In the 550 manually annotated sentences, 1300 NEs
were identified as NEs by the NER component. 402
NEs were recognised correctly by the NER, 588
wrongly and in 310 cases only parts of an NE were
recognised. These 310 cases can be divided into three
groups of errors. First, NEs recognised correctly, but
labeled with the wrong NE type. Second, only parts
of the NE were recognised correctly, e.g., ?Touris-
mus Marketing GmbH? instead of ?Berlin Tourismus
Marketing GmbH?. Third, NEs containing additional
words, such as ?the? in ?the Brandenburg Gate?.
To judge the usefulness of the extracted relations, we
applied the following soft criterion: A relation is con-
sidered useful if it expresses the main information given
by the sentence or clause, in which the relation was
found. According to this criterion, six of the eleven
relations could be considered useful. The remaining
five relations lacked some relevant part of the sen-
tence/clause (e.g., a crucial part of an NE, like the
?ICC? in ?ICC Berlin?).
4. Possible enhancements
With only 15 manually extracted relations out of 550
sentences, we assume that our definition of ?potentially
interesting relation? is too strict, and that more inter-
esting relations could be extracted by loosening the ex-
traction criterion. To investigate on how the criterion
could be loosened, we analysed all those sentences in
the test corpus that contained at least two NEs in order
to find out whether some interesting relations were lost
by the definition and how the definition would have to
be changed in order to detect these relations. The ta-
ble in Figure 6 lists some suggestions of how this could
be achieved, together with example relations and the
number of additional relations that could be extracted
from the 550 test sentences.
In addition, more interesting relations could be
found with an NER component extended by more
types, e.g., DATE and EVENT. Open domain NER
may be useful in order to extract NEs of additional
types. Also, other types of relations could be inter-
esting, such as relations between coordinated NEs,
option example additional relations
extraction of relations,
where the NE is not the
complete subject, object or
PP argument, but only part
of it
Co-operation with <ORG>M.A.X.
2001<\ORG> <V>is<\V> clearly of
benefit to <ORG>BTM<\ORG>.
25
extraction of relations with
a complex VP
<ORG>BTM<\ORG> <V>invited and or
supported<\V> more than 1,000 media rep-
resentatives in <LOC>Berlin<\LOC>.
7
resolution of relative pro-
nouns
The <ORG>Oxford Centre for Maritime
Archaeology<\ORG> [...] which will
<V>conduct<\V> a scientific symposium in
<LOC>Berlin<\LOC>.
2
combination of several of the
options mentioned above
<LOC>Berlin<\LOC> has <V>developed to
become<\V> the entertainment capital of
<LOC>Germany<\LOC>.
7
Figure 6: Table illustrating different options according to which the definition of ?potentially interesting relation?
could be loosened. For each option, an example sentence from the test corpus is given, together with the number
of relations that could be extracted additionally from the test corpus.
e.g., in a sentence like The exhibition [...] shows
<PER>Clemens Brentano<\PER>, <PER>Achim
von Arnim<\PER> and <PER>Heinrich von
Kleist<\PER>, and between NEs occurring in the
same (complex) argument, e.g., <PER>Hanns Peter
Nerger<\PER>, CEO of <ORG>Berlin Tourismus
Marketing GmbH (BTM) <\ORG>, sums it up [...].
5. Related work
Our work is related to previous work on domain-
independent unsupervised relation extraction, in par-
ticular Sekine (2006), Shinyama and Sekine (2006) and
Banko et al (2007).
Sekine (2006) introduces On-demand information ex-
traction, which aims at automatically identifying
salient patterns and extracting relations based on these
patterns. He retrieves relevant documents from a
newspaper corpus based on a query and applies a POS
tagger, a dependency analyzer and an extended NE
tagger. Using the information from the taggers, he ex-
tracts patterns and applies paraphrase recognition to
create sets of semantically similar patterns. Shinyama
and Sekine (2006) apply NER, coreference resolution
and parsing to a corpus of newspaper articles to ex-
tract two-place relations between NEs. The extracted
relations are grouped into pattern tables of NE pairs
expressing the same relation, e.g., hurricanes and their
locations. Clustering is performed in two steps: they
first cluster all documents and use this information to
cluster the relations. However, only relations among
the five most highly-weighted entities in a cluster are
extracted and only the first ten sentences of each arti-
cle are taken into account.
Banko et al (2007) use a much larger corpus, namely
9 million web pages, to extract all relations between
noun phrases. Due to the large amount of data, they
apply POS tagging only. Their output consists of mil-
lions of relations, most of them being abstract asser-
tions such as (executive, hired by, company) rather
than concrete facts.
Our approach can be regarded as a combination of
these approaches: Like Banko et al (2007), we extract
relations from noisy web documents rather than com-
parably homogeneous news articles. However, rather
than extracting relations from millions of pages we re-
duce the size of our corpus beforehand using a query in
order to be able to apply more linguistic preprocessing.
Like Sekine (2006) and Shinyama and Sekine (2006),
we concentrate on relations involving NEs, the assump-
tion being that these relations are the potentially in-
teresting ones. The relation clustering step allows us
to group similar relations, which can, for example, be
useful for the generation of answers in a Question An-
swering system.
6. Future work
Since many errors were due to the noisiness of the ar-
bitrarily downloaded web documents, a more sophisti-
cated filtering step for extracting relevant textual infor-
mation from web sites before applying NE recognition,
parsing, etc. is likely to improve the performance of
the system.
The NER component plays a crucial role for the qual-
ity of the whole system, because the relation extraction
component depends heavily on the NER quality, and
thereby the NER quality influences also the results of
the clustering process. A possible solution to improve
NER in the IDEX System is to integrate a MetaNER
component, combining the results of several NER com-
ponents. Within the framework of the IDEX project
a MetaNER component already has been developed
(Heyl, to appear 2008), but not yet integrated into the
prototype. The MetaNER component developed uses
the results from three different NER systems. The out-
put of each NER component is weighted depending on
the component and if the sum of these values for a pos-
sible NE exceeds a certain threshold it is accepted as
NE otherwise it is rejected.
The clustering step returns many clusters containing
two instances only. A task for future work is to in-
vestigate, whether it is possible to build larger clus-
ters, which are still meaningful. One way of enlarging
cluster size is to extract more relations. This could
be achieved by loosening the extraction criteria as de-
scribed in section 4. Also, it would be interesting to see
whether clusters could be merged. This would require
a manual analysis of the created clusters.
Acknowledgement
The work presented here was partially supported by a
research grant from the?Programm zur Fo?rderung von
Forschung, Innovationen und Technologien (ProFIT)?
(FKZ: 10135984) and the European Regional Develop-
ment Fund (ERDF).
7. References
Michele Banko, Michael J. Cafarella, Stephen Soder-
land, Matthew Broadhead, and Oren Etzioni. 2007.
Open information extraction from the web. In Proc.
of the International Joint Conference on Artificial
Intelligence (IJCAI).
Andrea Heyl. to appear 2008. Unsupervised relation
extraction. Master?s thesis, Saarland University.
Lc4j. 2007. Language categorization library for Java.
http://www.olivo.net/software/lc4j/.
LingPipe. 2007. http://www.alias-i.com/lingpipe/.
Satoshi Sekine. 2006. On-demand information extrac-
tion. In ACL. The Association for Computer Lin-
guistics.
Yusuke Shinyama and Satoshi Sekine. 2006. Preemp-
tive information extraction using unrestricted re-
lation discovery. In Proc. of the main conference
on Human Language Technology Conference of the
North American Chapter of the Association of Com-
putational Linguistics, pages 304?311. Association
for Computational Linguistics.
Stanford Parser. 2007. http://nlp.stanford.edu/
downloads/lex-parser.shtml.
Ian H. Witten and Eibe Frank. 2005. Data Min-
ing: Practical machine learning tools and techniques.
Morgan Kaufmann, San Francisco, 2nd edition.
WordNet. 2007. http://wordnet.princeton.edu/.
Proceedings of NAACL HLT 2009: Short Papers, pages 197?200,
Boulder, Colorado, June 2009. c?2009 Association for Computational Linguistics
The independence of dimensions in multidimensional dialogue act
annotation
Volha Petukhova and Harry Bunt
Tilburg Center for Creative Computing
Tilburg University, The Netherlands,
{v.petukhova,h.bunt}@uvt.nl
Abstract
This paper presents empirical evidence for the
orthogonality of the DIT++ multidimensional
dialogue act annotation scheme, showing that
the ten dimensions of communication which
underlie this scheme are addressed indepen-
dently in natural dialogue.
1 Introduction
Studies of human dialogue behaviour indicate that
natural dialogue utterances are very often multifunc-
tional. This observation has inspired the develop-
ment of multidimensional approaches to dialogue
analysis and annotation, e.g. (Allen & Core, 1997) ,
(Larsson, 1998), (Popescu-Belis, 2005), (Bunt,
2006). The most frequently used annotation scheme
that implements this approach is DAMSL (Allen
and Core, 1997), which allows multiple labels to be
assigned to utterances in four layers: Communica-
tive Status, Information Level, Forward-Looking
Function (FLF) and Backward-Looking Function
(BLF). The FLF layer is subdivided into five classes,
including (roughly) the classes of commissive and
directive functions, well known from speech act the-
ory. The BLF layer has four classes: Agreement,
Understanding, Answer, and Information Relation.
These nine classes, also referred to as ?dimensions?,
form mutually exclusive sets of tags; no further mo-
tivation is given for the particular choice of classes.
Popescu-Belis (2005) argues that dialogue act
tagsets should seek a multidimensional theoretical
grounding and defines the following aspects of ut-
terance function that could be relevant for choosing
dimensions (1) the traditional clustering of illocu-
tionary forces in speech act theory into five classes:
Representatives, Commissives, Directives, Expres-
sives and Declarations; (2) turn management; (3) ad-
jacency pairs; (4) topical organization in dialogue;
(5) politeness functions; and (6) rhetorical roles.
Structuring an annotation scheme by grouping re-
lated communicative functions into clusters makes
the structure of the schema more transparent. Such
clusters or ?dimensions? are usually defined as a
set of functions related to the same type of infor-
mation, such as Acknowledging, Signalling Under-
standing and Signalling Non-understanding, or Dia-
logue Opening and Dialogue Closing. Bunt (2006)
shows that this does not always lead to a notion of
dimension that has any conceptual and theoretical
significance, and argues that some of the function
classes of DAMSL do not constitute proper dimen-
sions.
In particular, a theoretically grounded multidi-
mensional schema should provide an account of the
possible multifunctionality of dialogue utterances.
In (Bunt, 2006); (Bunt and Girard, 2005) a dimen-
sion in dialogue act analysis is defined as an aspect
of participating in dialogue which can be addressed:
? by dialogue acts which have a function specifi-
cally for dealing with this aspect;
? independently of the other dimensions.
The independence of dimensions, required by this
definition, has the effect that an utterance may have
a function in one dimension independent of the func-
tions that it may have in other dimensions, and helps
to explain why utterances may have multiple func-
tions. Moreover, it leads to more manageable and
197
more adaptable annotation schemas (compared to,
for instance, DAMSL and its derivatives), since it al-
lows annotators to leave out certain dimensions that
they are not interested in, or to extend the schema
with additional dimensions; and it allows restricting
or modifying the set of tags in a particular dimension
without affecting the rest of the schema.
Based on the above definition and extensive theo-
retical and empirical studies, 10 dimensions are de-
fined in the DIT++ dialogue act annotation scheme1:
the domain or task/activity (Task); feedback on the
processing of previous utterances by the speaker
(Auto-feedback) or by other interlocutors (Allo-
feedback); managing difficulties in the speaker?s ut-
terance production (Own-Communication Manage-
ment, OCM) or that of other interlocutors (Partner
Communication Management, PCM); the speaker?s
need for time to continue the dialogue (Time Man-
agement); establishing and maintaining contact
(Contact Management); the allocation of the next
turn (Turn Management); the way the speaker is
planning to structure the dialogue (Dialogue Struc-
turing); and attention for social aspects of the inter-
action (Social Obligations Management, SOM).
This paper investigates the independence of these
ten dimensions. In Section 2 we discuss the notion
of independence of dimensions and how it can be
tested. Section 3 reports test results and Section 4
draws conclusions.
2 Independence of dimensions
We define two dimensions D1 and D2 in an anno-
tation scheme to be independent iff (1) an utterance
may be assigned a value in D1 regardless of whether
it is assigned a value in D2; and (2) it is not the case
that whenever an utterance has a value in D1, this
determines its value in D2.2
Dependences between dimensions can be de-
termined empirically by analyzing annotated dia-
logue data. Dimension tags which always co-occur
are nearly certainly dependent; zero co-occurrence
scores also suggest possible dependences. Besides
co-occurrence scores, we also provide a statistical
analysis using the phi coefficient as a measure of
1For more information about the scheme and its dimensions
please visit http://dit.uvt.nl/
2See Petukhova and Bunt (2009) for a more extensive dis-
cussion.
relatedness. The phi measure is related to the chi-
square statistic, used to test the independence of cat-
egorical variables, and is similar to the correlation
coefficient in its interpretation.
If a dimension is not independent from other di-
mensions, then there would be no utterances in the
data which address only that dimension. We there-
fore also investigate to which extent it happens that
an utterance addresses only one dimension. We also
investigate whether a dimension is addressed only in
reaction to a certain other dimension. For example,
the answer dimension as defined in DAMSL cannot
be seen as independent, because answers need ques-
tions in order to exist. The test here is to examine the
relative frequencies of pairs <dimension tag, previ-
ous dimension tag>.
To sum up, we performed four tests, examining:
1. the relative frequency of communicative func-
tion co-occurrences across dimensions;
2. the extent of relatedness between dimensions
measure with the phi coefficient;
3. for all dimensions whether there are utterances
addressing only that dimension;
4. the relative frequency of pairs of dimension and
previous dimension.
3 Test results
Since different types of dialogue may have differ-
ent tag distributions, three different dialogue corpora
have been examined:
? The DIAMOND corpus3 of two-party instruc-
tional human-human Dutch dialogues (1,408
utterances);
? The AMI corpus4 of task-oriented human-
human multi-party English dialogues (3,897 ut-
terances);
? The OVIS corpus5 of information-seeking
human-computer Dutch dialogues (3,942 utter-
ances).
All three corpora were manually segmented and
tagged according to the DIT++ annotation scheme.
3For more information see Geertzen, J., Girard, Y., and
Morante R. 2004. The DIAMOND project. Poster at CATA-
LOG 2004.
4Augmented Multi-party Interaction (http:
//www.amiproject.org/)
5Openbaar Vervoer Informatie System (Public Transport In-
formation System) http://www.let.rug.nl/v?annoord/Ovis/
198
Table 1: Co-occurrences of communicative functions across dimensions in AMI corpus expressed in relative frequency in %
implicated and entailed functions excluded and included (in brackets).
The test results presented in this section are similar
for all three corpora.
The co-occurrence results in Table 1 show no
dependences between dimensions, although some
combinations of dimensions occur frequently, e.g.
time and turn management acts often co-occur. A
speaker who wants to win some time to gather his
thoughts and uses Stalling acts mostly wants to con-
tinue in the sender role, and his stalling behaviour
may be intended to signal that as well (i.e., to be
interpreted as a Turn Keeping act). But stalling be-
haviour does not always have that function; espe-
cially an extensive amount of stallings accompanied
by relatively long pauses may be intended to elicit
support for completing an utterance.
It is also interesting to have a look at co-
occurrences of communicative functions taking im-
plicated and entailed functions into account (the cor-
pora were reannotated for this purpose). An impli-
cated function is for instance the positive feedback
(on understanding and evaluating the preceding ut-
terance(s) of the addressee) that is implied by an ex-
pression of thanks; examples of entailed functions
are the positive feedback on the preceding utterance
that is implied by answering a question, by accept-
ing an invitation, or by rejecting an offer.
Co-occurrence scores are higher when entailed
and implicated functions are taken into account (the
scores given in brackets in Table 1). For example,
questions, which mostly belong to the Task dimen-
sion, much of the time have an accompanying Turn
Management function, either releasing the turn or
assigning it to another dialogue participant, allow-
ing the question to be answered. Similarly, when
accepting a request the speaker needs to have the
turn, so communicative functions like Accept Re-
quest will often be accompanied by functions like
Turn Take or Turn Accept. Such cases contribute to
the co-occurrence score between the Task and Turn
Management dimensions.
Table 1 shows that some dimensions do not oc-
cur in combination. We do not find combinations of
Contact and Time Management, Contact and Part-
ner Communication Management, or Partner Com-
munication Management and Discourse Structuring,
for example. Close inspection of the definitions of
the tags in these pairs of dimensions does not re-
veal combination restrictions that would make one
of these dimensions depend on the others.
Table 2 presents the extent to which dimensions
are related when the corpus data are annotated with
or without taking implicated and entailed functions
into account, according to the calculated phi coeffi-
cient.
No strong positive (phi values from .7 to 1.0) or
negative (-.7 to -1.0) relations are observed. There
is a weak positive association (.6) between Turn
and Time Management (see co-occurrence analysis
above) and between OCM and Turn Management
(.4). Weak negative associations are observed be-
tween Task and Auto-feedback (-.5) when entailed
and implicated functions are not considered; be-
tween Task and Contact Management (-.6); and be-
tween Auto- and Allo-feedback (-.6) when entailed
and implicated functions are included in the analy-
sis. The weak negative association means that an
utterance does not often have communicative func-
tions in these two dimensions simultaneously. Some
negative associations become positive if we take en-
tailed and implicated functions into account, be-
cause, as already noted, dialogue acts like answers,
accepts and rejects, imply positive feedback.
199
Table 2: Extent of relation between dimensions for AMI corpus expressed in the Phi coefficient (implicated and entailed functions
excluded (white cells) and included (grey cells)).
The third independence test, mentioned above,
shows that each dimension may be addressed by
an utterance which does not address any other di-
mension. The Task dimension is independently ad-
dressed in 28.8% of the utterances; 14.2% of the ut-
terances have a function in the Auto-Feedback di-
mension only; for the other dimensions these fig-
ures are 0.7% - Allo-Feedback; 7.4% - Turn Man-
agement; 0.3% - Time Management; 0.1% - Contact
Management; 1.9% - Discourse Structuring; 0.5% -
OCM; 0.2% - PCM; and 0.3% - SOM.
Table 3: Overview of relative frequency (in%) of pairs of di-
mension and previous dimensions by previous utterances ob-
served in AMI data, per dimension, drawn from the set of 5
pairs from the dialogue history.
We finally investigated the occurrences of tags
given the tags of the previous utterances, taking five
previous utterances into account. Table 3 shows no
evidence of dependences across the dialogue his-
tory. There are some frequent patterns, for example,
retractions and self-corrections often follow hesita-
tions because the speaker, while monitoring his own
speech and noticing that part of it needs revision,
needs time to construct the corrected part.
4 Conclusions
In this paper we investigated the independence of
the dimensions defined in the DIT++ dialogue act
annotation scheme, using co-occurrences matrices
and the phi coefficient for measuring relatedness be-
tween dimensions.
The results show that, although some dimensions
are more related and co-occur more frequently than
others, on the whole the ten DIT++ dimensions
may be considered to be independent aspects of
communication.
Acknowledgments
This research was conducted as part of ISO project
24617-2: Semantic annotation framework, Part 2:
Dialogue acts, and sponsored by Tilburg University.
References
James F. Allen and Mark G. Core. 1997. Draft of
DAMSL: Dialog Act Markup in Several Layers.
Jens Allwood. 2000. An activity-based approach to prag-
matics. In Bunt, H., and Black, W. (eds.) Abduction,
Belief and Context in Dialogue; Studies in Computa-
tional Pragmatics, pp. 47?80. Benjamins, Amsterdam.
Harry Bunt and Yann Girard. 2005. Designing an open,
multidimensional dialogue act taxonomy. In Gardent,
C., and Gaiffe, B. (eds). Proc. 9th Workshop on the
Semantics and Pragmatics of Dialogue, pp. 37?44.
Harry Bunt. 2006. Dimensions in dialogue annotation.
In Proceedings of LREC 2006.
Mark G. Core and James F. Allen. 1997. Coding dia-
logues with the DAMSL annotation scheme. In Work-
ing Notes: AAAI Fall Symposium on Communicative
Action in Humans and Machines, pp. 28?35.
Staffan Larsson. 1998. Coding Schemas for Dialogue
Moves. Technical report from the S-DIME project.
Volha Petukhova and Harry Bunt. 2009. Dimensions
in communication. TiCC Technical Report 2009-002,
Tilburg University.
Andrei Popescu-Belis. 2005. Dialogue Acts: One or
More Dimensions? ISSCO Working Paper 62, ISSCO.
200
Proceedings of the 7th SIGdial Workshop on Discourse and Dialogue, pages 37?45,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Multidimensional Dialogue Management
Simon Keizer and Harry Bunt
Department of Language and Information Science
Faculty of Arts, Tilburg University
P.O. Box 90153, 5000 LE Tilburg, The Netherlands
{s.keizer,harry.bunt}@uvt.nl
Abstract
In this paper we present an approach to
dialogue management that supports the
generation of multifunctional utterances.
It is based on the multidimensional dia-
logue act taxonomy and associated con-
text model as developed in Dynamic Inter-
pretation Theory (DIT). The multidimen-
sional organisation of the taxonomy re-
flects that there are various aspects that di-
alogue participants have to deal with si-
multaneously during a dialogue. Besides
performing some underlying task, a par-
ticipant also has to pay attention to vari-
ous aspects of the communication process
itself, including social conventions.
Therefore, a multi-agent approach is pro-
posed, in which for each of the dimensions
in the taxonomy a specialised dialogue act
agent is designed, dedicated to the gener-
ation of dialogue acts from that particular
dimension. These dialogue act agents op-
erate in parallel on the information state of
the system. For a simplified version of the
taxonomy, a dialogue manager has been
implemented and integrated into an inter-
active QA system.
1 Introduction
During (task-oriented) dialogues, the participants
have to deal with many different aspects of com-
munication simultaneously. Besides some under-
lying task that may be performed through the dia-
logue, there are also various aspects of managing
the communicative process itself, including deal-
ing with social obligations. Therefore, speakers
often use utterances that are multifunctional.
We will present an approach to dialogue man-
agement that accounts for the generation of multi-
functional utterances. The approach is based on a
dialogue theory involving a multidimensional dia-
logue act taxonomy and associated context model.
In this theory, called Dynamic Interpretation The-
ory (DIT) (Bunt, 1996; Bunt, 2000a), a dialogue is
modelled as a sequence of (sets of) dialogue acts
operating on the Information State of each of the
participants. The dialogue acts are organised in a
taxonomy that is multidimensional, i.e., each ut-
terance may involve dialogue acts of at most one
type from each dimension. The taxonomy has di-
mensions for aspects like feedback, interaction-
management, social obligations management and
managing the underlying task.
In a dialogue system developed according to
the principles of DIT, the information state is rep-
resented through a context model, containing all
information considered relevant for interpreting
user utterances an generating system utterances in
terms of dialogue acts. Hence, given the multidi-
mensionality of the taxonomy, the input interpre-
tation components of the system result in several
dialogue acts for each utterance, at most one from
each of the dimensions. Using these recognised
user dialogue acts, the context model is updated.
On the other hand, the ultimate task for a di-
alogue manager component of a dialogue system
is deciding which dialogue acts to generate. So,
again with the multidimensional organisation of
the taxonomy in mind, we argue for a multi-agent
approach, in which the dialogue act generation
task is divided over several agents that operate in
parallel on the context model, each agent being
dedicated to the generation of dialogue acts from
one particular dimension in the taxonomy. This
leads to the design of a number of so-called Di-
37
alogue Act Agents, including e.g. a task-oriented
agent, two feedback agents and an agent dealing
with social obligations management.
The multi-agent approach to dialogue manage-
ment itself is not new: JASPIS (Turunen and
Hakulinen, 2000; Salonen et al, 2004) is a multi-
agent framework for dialogue systems which al-
lows for implementations of several agents for the
same tasks, varying from input interpretation and
output presentation to dialogue management. De-
pending on the situation, the agent that is most
appropriate for a given task is selected in a pro-
cess involving several so-called ?evaluators?. In
JASPIS the multi-agent approach is aimed at flex-
ibility and adaptiveness, while our approach fo-
cuses more on supporting multidimensionality in
communication.
In a very general sense, our dialogue manage-
ment approach follows an information state update
approach similar to the dialogue managers that are
developed within the TRINDI framework (Lars-
son and Traum, 2000). For example, Matheson
et al (2000) describe the implementation of a di-
alogue management system focusing in the con-
cepts of grounding and discourse obligations.
An approach to dialogue management which
identifies several simultaneous processes in the
generation of system utterances, is described in
(Stent, 2002). In this approach, which is imple-
mented in the TRIPS dialogue system, dialogue
contributions are generated through three core
components operating independently and concur-
rently, using a system of conversation acts or-
ganised in several levels (Traum and Hinkelman,
1992).
Although there are apparent similarities be-
tween our approach and that of the TRINDI based
dialogue managers and the TRIPS system, there
are clear differences as well, which for an impor-
tant part stem from the system of dialogue acts
used and the way the information state is organ-
ised. More particularly, the way in which mech-
anisms for generating dialogue acts along multi-
ple dimensions are modelled and implemented by
means of multiple agents, differs from existing ap-
proaches.
This paper is organised as follows. First we ex-
plain the closely connected DIT notions of dia-
logue act and information state, and the multi-
dimensional dialogue act taxonomy and context
model (Sections 2 and 3). We then introduce
the multi-agent approach to dialogue management
(Section 4) and illustrate it by a description of
the current implementation (Section 4.1). This
implementation is carried out in the PARADIME
project (PARallel Agent-based DIalogue Manage-
ment Engine), which is part of the multiproject
IMIX (Interactive Multimodal Information Ex-
traction). The PARADIME dialogue manager is
integrated into an interactive question-answering
system that is developed in a collaboration be-
tween several projects participating in IMIX. The
paper ends with conclusions and directions for fu-
ture research (Section 5).
2 The DIT dialogue act taxonomy
Based on studies of a variety of dialogues from
several dialogue corpora, a dialogue act taxonomy
was developed consisting of a number of dimen-
sions, reflecting the idea that during a dialogue,
several aspects of the communication need to be
attended to by the dialogue participants (Bunt,
2006). Even within single utterances, several as-
pects are dealt with at the same time, i.e., in gen-
eral, utterances are multifunctional. The multidi-
mensional organisation of the taxonomy supports
this multifunctionality in that it allows several di-
alogue acts to be performed in each utterance, at
most one from each dimension. The 11 dimen-
sions of the taxonomy are listed below, with brief
descriptions and/or specific dialogue act types in
that dimension. For convenience, the dimensions
are further grouped into so-called layers. At the
top level are two layers: one for dialogue con-
trol acts and one coinciding with the task-domain
dimension. Dialogue control is further divided
into 3 layers: Feedback (2 dimensions), Interac-
tion Management (7 dimensions), and a layer co-
inciding with the Social Obligations Management
dimension.
? Dialogue Control
? Feedback
1. Auto-Feedback: acts dealing with the
speaker?s processing of the addressee?s
utterances; contains positive and nega-
tive feedback acts on the levels of per-
ception, interpretation, evaluation, and
execution;
2. Allo-Feedback: acts dealing with the
addressee?s processing of the speaker?s
previous utterances (as viewed by the
38
speaker); contains positive and negative
feedback-giving acts and feedback elic-
itation acts, both on the levels of per-
ception, interpretation, evaluation, and
execution;
? Interaction management
3. Turn Management: turn accepting,
giving, grabbing, keeping;
4. Time Management: stalling, pausing;
5. Dialogue Structuring: opening,
preclosing, closing, dialogue act an-
nouncement;
6. Partner Processing Management:
completion, correct-misspeaking;
7. Own Processing Management: error
signalling, retraction, self-correction;
8. Contact Management: contact check,
contact indication;
9. Topic Management: topic introduction,
closing, shift, shift announcement;
10. Social Obligations Management: saluta-
tion, self-introduction, gratitude, apology,
valediction;
11. Task/domain: acts that concern the specific
underlying task and/or domain.
Formally, a dialogue act in DIT consists of a
Semantic Content and a Communicative Function,
the latter specifying how the information state
of the addressee is to be updated with the for-
mer. A dialogue act in a particular dimension
may have either a dimension-specific communica-
tive function, or a General-Purpose communica-
tive function with a content type (type of semantic
content) in that dimension. The general-purpose
communicative functions are hierarchically or-
ganised into the branches of Information Trans-
fer and Action Discussion functions, Information
Transfer consisting of information-seeking (e.g.,
WH-QUESTION, YN-QUESTION, CHECK) and
information-providing functions (e.g., INFORM,
WH-ANSWER, YN-ANSWER, CONFIRM), and
Action Discussion consisting of commissives
(e.g., OFFER, PROMISE, ACCEPT-REQUEST) and
directives (e.g., INSTRUCT, REQUEST, DECLINE-
OFFER).
The taxonomy is currently being evaluated in
annotation experiments, involving several anno-
tators and several dialogue corpora. Measuring
inter-annotator agreement will give an indication
of the usability of the taxonomy and annotation
scheme. A first analysis has resulted in promising
scores (Geertzen and Bunt, 2006).
3 The DIT context model
The Information State according to DIT is repre-
sented by a Context Model, containing all infor-
mation considered relevant for interpreting user
utterances (in terms of dialogue acts) and gener-
ating system dialogue acts (leading to system ut-
terances). The contents of the context model are
therefore very closely related to the dialogue act
taxonomy; in (Bunt and Keizer, 2005) it is ar-
gued that the context model serves as a formal se-
mantics for dialogue annotation, such an annota-
tion being a kind of underspecified semantic rep-
resentation. In combination with additional gen-
eral conceptual considerations, the context model
has evolved into a five component structure:
1. Linguistic Context: linguistic information
about the utterances produced in the dialogue
so far (a kind of ?extended dialogue history?);
information about planned system dialogue
acts (a ?dialogue future?);
2. Semantic Context: contains current infor-
mation about the task/domain, including as-
sumptions about the dialogue partner?s infor-
mation;
3. Cognitive Context: the current processing
states of both participants (on the levels of
perception, interpretation, evaluation, and
task execution), as viewed by the speaker;
4. Physical and Perceptual Context: the percep-
tible aspects of the communication process
and the task/domain;
5. Social Context: current communicative pres-
sures.
In Figure 1, a feature structure representation of
the context model is given, in which the five com-
ponents have been specified in further detail. This
specification forms the basis for the dialogue man-
ager being implemented in the PARADIME project.
The Linguistic Context contains features for
storing dialogue acts performed in the dialogue so
far: user utts and system utts, having lists of di-
alogue act representations as values. It also has
features for information about topics and conver-
sational structure: topic struct and conv state re-
spectively. Finally, there are two features that
39
??
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
LingContext :
?
?
?
?
?
?
?
?
?
user utts : ?last user dial act = uda0 , uda?1 , uda?2 , . . .?
system utts : ?last system dial act = sda0 , sda?1 , sda?2 , . . .?
topic struct : ?referents?
conv state : opening |body |closing
candidate dial acts : . . .
dial acts pres : . . .
?
?
?
?
?
?
?
?
?
SemContext :
?
?
?
?
task progress : comp quest |quest qa|answ eval |user sat
user info needs : ?. . . ,
[
question : . . .
satisfied : +|?
]
, . . .?
qa answers : ?. . .?
?
?
?
?
CogContext :
[
own proc state : [proc problem : perc|int |eval |exec|none]
partner proc state : [proc problem : perc|int |eval |exec|none]
]
PhysPercContext :
[ ]
SocContext :
[
reactive pressures : none|grt |apo|thk |valed
interactive pressures : none|grt |apo|thk |valed
]
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
Figure 1: Feature structure representation of the PARADIME context model.
are related to the actual generation of system di-
alogue acts: candidate dial acts stores the dia-
logue acts generated by the dialogue act agents,
and dial acts pres stores combined dialogue acts
for presentation as system output; in Section 4,
this will be discussed in more detail.
The specification of the Semantic Context is
determined by the character of the task-domain.
In Section 4.1, the task-domain of interactive
question-answering on encyclopedic medical in-
formation will be discussed and from that, the
specification of the Semantic Context for this pur-
pose.
The Cognitive Context is specified by means of
two features, representing the processing states of
the system (own proc state) and the user (part-
ner proc state). Both features indicate whether or
not a processing problem was encountered, and if
so, on which level of processing this happened.
The Physical and Perceptual Context is consid-
ered not to be relevant for the current system func-
tionality.
The Social Context is specified in terms of re-
active and interactive pressures; the correspond-
ing features indicate whether or not a pressure ex-
ists and if so, for which social obligations manage-
ment act it is a pressure (e.g., reactive pressures:
grt indicates a pressure for the system to respond
to a greeting).
4 Dialogue Act Agents
Having discussed the dialogue act taxonomy and
context model in DIT, we can now move on to the
dialogue management approach that is also closely
connected to these concepts. Having 11 dimen-
sions of dialogue acts that each attend to a dif-
ferent aspect of communication, the generation of
(system) dialogue acts should also happen along
those 11 dimensions. As a dialogue act in a di-
mension can be selected independent of the other
dimensions, we propose to divide the generation
process over 11 Dialogue Act Agents operating in
parallel on the information state of the system,
each agent dedicated to generating dialogue acts
from one particular dimension.
All of the dialogue act agents continuously
monitor the context model and, if appropriate, try
to generate candidate dialogue acts from their as-
sociated dimension. This process of monitoring
and act generation is modelled through a trigger-
ing mechanism: if the information state satisfies
the agent?s triggering conditions, i.e., if there is
a motivation for generating a dialogue act from a
particular dimension, the corresponding agent gets
triggered and tries to generate such a dialogue act.
For example, the Auto-Feedback Agent gets trig-
gered if a processing problem is recorded in the
Own Processing State of the Cognitive Context.
The agent then tries to generate a negative auto-
feedback act in order to solve the processing prob-
40
lem (e.g., ?Could you repeat that please?? or ?Did
you say ?five???). The Auto-Feedback Agent may
also be triggered if it has reason to believe that the
user is not certain that the system has understood
a previous utterance, or simply if it has not given
any explicit positive feedback for some time. In
these cases of triggering, the agent tries to gener-
ate a positive auto-feedback act.
Hence the dialogue management process in-
volves 11 dialogue act agents that operate in par-
allel on the context model. The dialogue acts gen-
erated by these agents are kept in the linguistic
context as candidates. The selection of dialogue
acts from different dimensions may happen inde-
pendently, but for their order of performance and
their combination, the relative importance of the
dimensions at the given point in the dialogue has
to be taken into account.
An additional Evaluation Agent monitors the
list of candidates and decides which of them can
be combined into a multifunctional system utter-
ance for generation, and when. Some of the dia-
logue act candidates may have higher priority and
should be generated at once, some may be stored
for possible generation in later system turns, and
some will already be implicitly performed through
the performance of other candidate acts.
4.1 A dialogue manager for interactive QA
The current implementation of the PARADIME
dialogue manager is integrated in an interactive
question-answering (QA) system, as developed
the IMIX multiproject. The task-domain at hand
concerns encyclopedic information in the medical
domain, in particular RSI (Repetitive Strain In-
jury). The system consists of several input anal-
ysis modules (ASR, syntactic analysis in terms
of dependency trees, and shallow semantic tag-
ging), three different QA modules that take self-
contained domain questions and return answers
retrieved from several electronic documents with
text data in the medical domain, and a presentation
module that takes the output from the dialogue
manager, possibly combining any QA-answers to
be presented, into a multimodal system utterance.
The dialogue management module provides
support for more interactive, coherent dialogues,
in which problems can be solved about both com-
munication and question-answering processes. In
interaction with the user, the system should play
the role of an Information Search Assistant (ISA).
This HCI metaphor posits that the dialogue system
is not an expert on the domain, but merely assists
the user in formulating questions about the domain
that will lead to QA answers from the QA mod-
ules satisfying the user?s information need (Akker
et al, 2005).
In the context model for this dialogue manager,
as represented by the feature structure in Figure 1,
the Semantic Context has been further specified
according to this underlying task. It contains a
state variable for keeping track of the question-
answering process (the feature task progress with
values to distinguish between the states of com-
posing a self-contained question to send to the QA
modules, waiting for the QA results in case a QA-
question has been sent, evaluating the QA results,
and discussing the results with the user). Also, the
Semantic Context keeps a record of user?s infor-
mation need, by means of a list user info needs
of ?information need? specifications in terms of
semantic descriptions of domain questions and
whether or not these info-needs have been satis-
fied.
For the first version of the dialogue manager
we have defined a limited system functionality,
and following from that a simplified version of
the dialogue act taxonomy. This simplification
means for example that Social Obligations Man-
agement (SOM) and the various dimensions in
the Interaction Management (IM) layer have been
merged into one dimension, following the obser-
vation that utterances with a SOM function very
often also have a function in the IM layer, es-
pecially in human-computer dialogue; see (Bunt,
2000b). Also several general-purpose commu-
nicative functions have been clustered into single
types. Table 1 lists the dialogue acts that the dia-
logue act recogniser is able to identify from user
utterances.
GP AUF IM-SOM
YN-Question PosAutoFb Init-Open
WH-Question NegAutoFb-Int Init-Close
H-Question NegAutoFb-Eval
Request
Instruct
Table 1: Dialogue act types for interpreting user
utterances.
Table 2 lists the dialogue acts that can be gen-
erated by the dialogue manager. Task-domain
acts, generally answers to questions about the do-
41
main, consist of a general-purpose function (either
a WH-ANSWER or UNC-WH-ANSWER; the latter
reflecting that the speaker is uncertain about the in-
formation provided) with a semantic content con-
taining the answers obtained from QA.
AUF ALF IM-SOM
NegAutoFb-Int Fb-Elicit React-Open
NegAutoFb-Exe React-Close
Table 2: Dialogue act types for generating system
responses.
The above considerations have resulted in a di-
alogue manager containing 4 dialogue act agents
that operate on a slightly simplified version of the
context model as specified in Figure 1: a Task-
Oriented (TO) Agent, an Auto-Feedback (AUF)
Agent, an Allo-Feedback (AUF) Agent, and an
Interaction Management and Social Obligations
Management (IMSOM) Agent. In addition, a (cur-
rently very simple) Evaluation Agent takes care of
merging candidate dialogue acts for output presen-
tation.
In Appendices A.1 and A.2, two example di-
alogues with the IMIX demonstrator system are
given, showing system responses based on can-
didate dialogue acts from several dialogue act
agents. The ISA metaphor is reflected in the sys-
tem behaviour especially in the way in which QA
results are presented to the user. In system utter-
ances S2 and S3 in Appendix A.1, for example,
the answer derived from the retrieved QA results is
isolated from the first part of the system utterance,
showing that the system has a neutral attitude con-
cerning that answer.
4.1.1 The Task-Oriented Agent
The TO-Agent is dedicated to the generation of
task-specific dialogue acts, which in practice in-
volves ANSWER dialogue acts intended to satisfy
the user?s information need about the (medical)
domain as indicated through his/her domain ques-
tions. The agent is triggered if a new information
need is recorded in the Semantic Context. Once it
has been triggered, the agent sends a request to the
QA modules to come up with answers to a ques-
tion asked, and evaluates the returned results. This
evaluation is based on the number of answers re-
ceived and the confidence scores of the answers;
the confidence scores are also part of the output of
the QA modules. If the QA did not find any an-
swers or if the answers produced had confidence
scores that were all below some lower threshold,
the TO-Agent will not generate a dialogue act, but
write an execution problem in the Own Process-
ing State of the Cognitive Context (which causes
the Auto-Feedback Agent to be triggered, see Sec-
tion 4.1.2; an example can be found in the dia-
logue in Appendix A.2). Otherwise, the TO-Agent
tries to make a selection from the QA answers
to be presented to the user. If this selection will
end up containing extremely many answers, again,
an execution problem is written in the Cognitive
Context (the question might have been too gen-
eral to be answerable). Otherwise, the selection
will be included in an answer dialogue act, either
a WHANSWER, or UNCWHANSWER (uncertain
wh-answer) in case the confidence scores are be-
low some upper threshold. System utterances S1
and S2 in the example dialogue in Appendix A.1
illustrate this variation. The selection is narrowed
down further if there is a subselection of answers
with confidences that are significantly higher than
those of the other answers in the selection.
4.1.2 The Auto-Feedback-Agent
The AUF-Agent is dedicated to the generation
of auto-feedback dialogue acts. It currently pro-
duces negative auto-feedback acts on the levels
of interpretation (?I didn?t understand what you
said?), evaluation (?I do not know what to do with
this?) and execution (?I could not find any answers
to your question?). It may also decide to occa-
sionally give positive feedback to the user. In the
future, we would also like this agent to be able
to generate articulate feedback acts, for example
with the purpose of resolving reference resolution
problems, as in:
U: what is RSI?
S: RSI (repetitive strain injury) is a pain or
discomfort caused by small repetitive move-
ments or tensions.
U: how can it be prevented?
S: do you mean ?RSI? or ?pain??
4.1.3 The Allo-Feedback Agent
The ALF-Agent is dedicated to the generation
of allo-feedback dialogue acts. For example, it
may generate a feedback-elicitation act if it has
reason to believe that the user might not be sat-
isfied with an answer (?Was this an answer to your
question??).
42
4.1.4 Interaction Management and Social
Obligations Management Agent
The IM-SOM Agent is dedicated to the gener-
ation of social obligations management acts, pos-
sibly also functioning as dialogue structuring acts
(opening resp. closing a dialogue through a greet-
ing resp. valediction act). It gets triggered if
communicative pressures are recorded in the So-
cial Context. Currently it only responds to re-
active pressures as caused by initiative greetings
and goodbyes. The example dialogues in Appen-
dices A.1 and A.2 illustrate this type of social be-
haviour.
4.1.5 Multi-agent Architecture of the
Dialogue Manager
In Figure 2, a schematic overview of the multi-
agent dialogue manager is given. It shows the
context model with four components (for now, the
Physical and Perceptual Context is considered to
be of minor importance and is therefore ignored),
a set of dialogue act agents, and an Evaluation
Agent. The dialogue act agents each monitor the
context model and may be triggered if certain con-
ditions are satisfied. The TO-agent may also write
to the Cognitive Context (particularly in case of
execution problems). All agents may construct
a dialogue act and write it in the candidates list
in the Linguistic Context. The Evaluation Agent
monitors this candidates list and selects one or
more dialogue acts from it for presentation as sys-
tem output. In this way, a control module may
decide to take this combination of dialogue act for
presentation anytime and send it to the presenta-
tion module to produce a system utterance.
With this initial design of a multi-agent dia-
logue manager, the system is able to support mul-
tifunctional output. The beginning of the example
dialogue in Appendix A.1 illustrates multifunc-
tionality, both in input interpretation and output
generation. The system has recognised two dia-
logue acts in processing U1 (a conventional open-
ing and a domain question), and S1 is generated
on the basis of two candidate dialogue acts gen-
erated by different dialogue act agents: the IM-
SOM-Agent (generated the react-greeting act) and
the TO-Agent (generated the answer act).
5 Conclusions and future work
We have presented a dialogue management ap-
proach supporting the generation of multifunc-
candidatedialogue acts
IM?SOM?Agent
TO?Agent
AUF?Agent
ALF?Agent
Semantic Context
Cognitive Context
Social Context
Linguistic Context
candidatedialogue acts
Eval?Agent
dialogue actsfor presentation
DIALOGUE ACT AGENTS
CONTEXT MODEL
Figure 2: Architecture of the PARADIME dialogue
manager.
tional utterances. The approach builds on a di-
alogue theory involving a multidimensional dia-
logue act taxonomy and an information state on
which the dialogue acts operate. Several dialogue
acts from different dimensions are generated by
dialogue act agents associated with these dimen-
sions, and can thus be combined into multifunc-
tional system utterances.
A first implementation of a dialogue manager
following this multi-agent approach has been in-
tegrated into an interactive QA system and sup-
ports a limited range of dialogue acts from the
DIT taxonomy, both for interpreting user utter-
ances and generating system utterances. The sys-
tem is able to attend to different aspects of the
communication simultaneously, involving reactive
social behaviour, answering domain questions and
giving feedback about utterance interpretation and
the question-answering process.
Future development will involve extending the
range of dialogue acts to be covered by the dia-
logue manager, for a part following from the def-
inition of an extended system functionality, and
consequently, extending the set of dialogue act
agents. This also has consequences for the Eval-
uation Agent: the process of combination and se-
lection will be more complex if more dialogue act
types can be expected and if the dialogue acts have
a semantic content that is more than just a collec-
tion of QA-answers.
In terms of system functionality we aim at sup-
43
port for generating articulate feedback, i.e., feed-
back acts that are not merely signalling processing
success or failure, but (in case of negative feed-
back) also contain a further specification of the
processing problem at hand. For example, the sys-
tem may have encountered problems in processing
certain parts of a user utterance, or in resolving an
anaphor; then it should be able to ask the user a
specific question in order to obtain the informa-
tion required to solve the processing problem (see
the example in Section 4.1.2). The articulate feed-
back acts may also involve dealing with problems
in the question answering process, where the sys-
tem should be able to give specific instructions to
the user to reformulate his question or give addi-
tional information about his information need.
In addition to supporting generation of articu-
late feedback acts, we also aim at dialogues be-
tween user and system that are more coherent and
natural, i.e., the system should be more aware of
the conversational structure, and display more re-
fined social behaviour. Not only should it gener-
ate simple reactions to greetings, apologies, and
goodbyes; it should also be able to generate initia-
tive social acts, for example, apologies after sev-
eral cases of negative auto-feedback.
The extended set of dialogue acts will also lead
to an extended context model. Related to the
context model and updating mechanism is on-
going work on belief dynamics and grounding
in DIT (Morante and Bunt, 2005). The defined
mechanisms for the creation, strengthening, adop-
tion, and cancelling of beliefs and goals in the
context model are currently being implemented
in a demonstrator tool and will also be integrated
in the information state update mechanism of the
PARADIME dialogue manager.
Acknowledgement
This work is part of PARADIME (Parallel Agent-
based Dialogue Management Engine), which is a
subproject of IMIX (Interactive Multimodal Infor-
mation eXtraction), a multiproject on Dutch lan-
guage and speech technology, funded by the Dutch
national science foundation (NWO).
We would like to thank the reviewers for their
valuable comments, which really helped us to im-
prove our paper.
References
R. op den Akker, H. Bunt, S. Keizer, and B. van
Schooten. 2005. From question answering to spo-
ken dialogue: Towards an information search assis-
tant for interactive multimodal information extrac-
tion. In Proceedings of the 9th European Confer-
ence on Speech Communication and Technology, In-
terspeech 2005, pages 2793?2796.
H. Bunt and S. Keizer. 2005. Dialogue semantics
links annotation to context representation. In Joint
TALK/AMI Workshop on Standards for Multimodal
Dialogue Context. http://homepages.inf.
ed.ac.uk/olemon/standcon-SOI.html.
H. Bunt. 1996. Dynamic interpretation and dia-
logue theory. In M.M. Taylor, F. Ne?el, and D.G.
Bouwhuis, editors, The Structure of Multimodal Di-
alogue, Volume 2, pages 139?166. John Benjamins.
H. Bunt. 2000a. Dialogue pragmatics and context
specification. In H. Bunt and W. Black, editors,
Abduction, Belief and Context in Dialogue, Studies
in Computational Pragmatics, pages 81?150. John
Benjamins.
H. Bunt. 2000b. Non-problems and social obliga-
tions in human-computer conversation. In Proceed-
ings of the 3rd International Workshop on Human-
Computer Conversation, pages 36?41.
H. Bunt. 2006. Dimensions in dialogue act anno-
tation. In Proceedings Fifth International Confer-
ence on Language Resources and Evaluation (LREC
2006).
J. Geertzen and H. Bunt. 2006. Measuring annotator
agreement in a complex hierarchical dialogue act an-
notation scheme. In 7th SIGdial Workshop on Dis-
course and Dialogue.
S. Larsson and D. Traum. 2000. Information state
and dialogue management in the TRINDI dialogue
move engine toolkit. Natural Language Engineer-
ing: Special Issue on Best Practice in Spoken Lan-
guage Dialogue Systems, 6(3?4):323?340.
C. Matheson, M. Poesio, and D. Traum. 2000. Mod-
eling grounding and discourse obligations using up-
date rules. In Proceedings of the First Annual Meet-
ing of the North American Chapter of the ACL.
R. Morante and H. Bunt. 2005. Micro-analysis of the
belief transfer in information dialogues. In C. Gar-
dent and B. Gaiffe, editors, DIALOR?05 Proceed-
ings of the Ninth Workshop on the Semantics and
Pragmatics of Dialogue, pages 135?138.
E.P. Salonen, M. Hartikainen, M. Turunen, J. Hakuli-
nen, and J.A. Funk. 2004. Flexible dialogue man-
agement using distributed and dynamic dialogue
control. In Proceedings of ICSLP 2004.
A.J. Stent. 2002. A conversation acts model for gen-
erating spoken dialogue contributions. Computer
44
Speech and Language, Special Issue on Spoken Lan-
guage Generation, 16(3?4):313?352.
D.R. Traum and E.R. Hinkelman. 1992. Conversa-
tion acts in task-oriented spoken dialogue. Compu-
tational Intelligence, 3(8):575?599.
M. Turunen and J. Hakulinen. 2000. Jaspis ? a frame-
work for multilingual adaptive speech applications.
In Sixth International Conference on Spoken Lan-
guage Processing (ICSLP 2000), volume 2, pages
719?722.
A Example dialogues
A.1 Example 1: greetings, answers and
unc-answers
U1: hallo, ik wilde graag weten wat rsi is
(hello, I wanted to know what is rsi)
[INIT-OPEN; INDWHQ, task-domain]
S1: Hallo. Ik heb de volgende informatie gevonden:
(repetitive strain injury) Algemene benaming voor
(blijvende) beschadigingen aan het lichaam ten gevolge
van langdurige, eentonige werkzaamheden.
(Hello. I found the following information: ...)
[REACT-OPEN; ANSWER, task-domain]
U2: wat moet ik doen als ik denk rsi te hebben
(what should I do if I think I have RSI)
[WHQUESTION, task-domain]
S2: De volgende informatie levert mogelijk een antwoord
op uw vraag:
Ontspanning betekent minder stress, minder aange-
spannen spieren en dus minder kans op RSI.
(The following information might answer your ques-
tion: ...)
[UNCANSWER, task-domain]
U3: helpt ontspanning ook als ik eenmaal rsi heb
(does relaxing help as well, once I have RSI)
[YNQUESTION, task-domain]
S3: Ik heb de volgende informatie gevonden:
Behandelmethoden bij RSI Er zijn vele wegen die naar
Rome leiden. Verbetering van de doorbloeding ...
(I found the following information: ...)
[ANSWER, task-domain]
U4: oke, bedankt
(okay, thanks)
[INIT-CLOSE]
S4: tot ziens. U kunt de buttons gebruiken om te stoppen
of om een nieuwe dialoog te beginnen.
(Goodbye. You may use the buttons to stop or to start a
new dialogue.)
[REACT-CLOSE]
A.2 Example 2: negative execution-feedback
U1: hallo!
(hello!)
[INIT-OPEN]
S1: Hallo. Stel uw vraag.
(Hello. Ask your question.)
[REACT-OPEN]
U2: wat kan ik als beelschermwerker tegen rugpijn doen
(what can I, a person working behind a computer
screen all the time, do against pain in the back)
[WHQUESTION, task-domain]
S2: Ik heb helaas geen antwoorden kunnen vinden; probeer
de vraag te herformuleren.
(Unfortunately, I could not find any answers; please try
to reformulate the question)
[NEGAUTOFB-EXEC]
U3: wat kan men tegen rugpijn doen
(what can be done against pain in the back)
[WHQUESTION, task-domain]
S3: ik heb de volgende informatie gevonden:
Deze is afhankelijk van de oorzaak. Rugpijn die door
instabiliteit of door tekortschietende spieren en ban-
den ontstaat, kan behandeld worden met houdingscor-
rigerende oefentherapie.
(I found the following information: ...)
[ANSWER, task-domain]
U4: bedankt!
(thanks!)
[INIT-CLOSE]
S4: Tot ziens. U kunt de buttons gebruiken om te stoppen
of om een nieuwe dialoog te beginnen.
(Goodbye. U may use the buttons to stop or to start a
new dialogue.)
[REACT-CLOSE]
45
Proceedings of the 7th SIGdial Workshop on Discourse and Dialogue, pages 126?133,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Measuring annotator agreement in a complex hierarchical dialogue act
annotation scheme
Jeroen Geertzen and Harry Bunt
Language and Information Science
Tilburg University, P.O. Box 90153
NL-5000 LE Tilburg, The Netherlands
{j.geertzen,h.bunt}@uvt.nl
Abstract
We present a first analysis of inter-
annotator agreement for the DIT++ tagset
of dialogue acts, a comprehensive, lay-
ered, multidimensional set of 86 tags.
Within a dimension or a layer, subsets of
tags are often hierarchically organised. We
argue that especially for such highly struc-
tured annotation schemes the well-known
kappa statistic is not an adequate measure
of inter-annotator agreement. Instead, we
propose a statistic that takes the structural
properties of the tagset into account, and
we discuss the application of this statistic
in an annotation experiment. The exper-
iment shows promising agreement scores
for most dimensions in the tagset and pro-
vides useful insights into the usability of
the annotation scheme, but also indicates
that several additional factors influence
annotator agreement. We finally suggest
that the proposed approach for measuring
agreement per dimension can be a good
basis for measuring annotator agreement
over the dimensions of a multidimensional
annotation scheme.
1 Introduction
The DIT++ tagset (Bunt, 2005) was designed to
combine in one comprehensive annotation scheme
the communicative functions of dialogue acts dis-
tinguished in Dynamic Interpretation Theory (DIT,
(Bunt, 2000; Bunt and Girard, 2005)), and many
of those in DAMSL (Allen and Core, 1997) and in
other annotation schemes. An important differ-
ence between the DIT++ and DAMSL schemes is the
more elaborate and fine-grained set of functions
for feedback and other aspects of dialogue control
that is available in DIT, partly inspired by the work
of Allwood (Allwood et al, 1993). As it is often
thought that more elaborate and fine-grained anno-
tation schemes are difficult for annotators to apply
consistently, we decided to address this issue in an
annotation experiment on which we report in this
paper. A frequently used way of evaluating hu-
man dialogue act classification is inter-annotator
agreement. Agreement is sometimes measured as
percentage of the cases on which the annotators
agree, but more often expected agreement is taken
into account in using the kappa statistic (Cohen,
1960; Carletta, 1996), which is given by:
? = po ? pe1 ? pe
(1)
where po is the observed proportion of agreement
and pe is the proportion of agreement expected by
chance. Ever since its introduction in general (Co-
hen, 1960) and in computational linguistics (Car-
letta, 1996), many researchers have pointed out
that there are quite some problems in using ? (e.g.
(Di Eugenio and Glass, 2004)), one of which is
the discrepancy between p0 and ? for skewed class
distribution.
Another is that the degree of disagreement is
not taken into account, which is relevant for any
non-nominal scale. To address this problem, a
weighted ? has been proposed (Cohen, 1968) that
penalizes disagreement according to their degree
rather than treating all disagreements equally. It
would be arguable that in a similar way, charac-
teristics of dialogue acts in a particular taxonomy
and possible pragmatic similarity between them
should be taken into account to express annotator
agreement. For dialogue act taxonomies which are
structured in a meaningful way, such as those that
126
express hierarchical relations between concepts in
the taxonomy, the taxonomic structure can be ex-
ploited to express how much annotators disagree
when they choose different concepts that are di-
rectly or indirectly related. Recent work that ac-
counts for some of these aspects is a metric for
automatic dialogue act classification (Lesch et al,
2005) that uses distance in a hierarchical structure
of multidimensional labels.
In the following sections of this paper, we will
first briefly consider the dimensions in the DIT++
scheme and highlight the taxonomic characteris-
tics that will turn out to be relevant in later stage.
We will then introduce a variant of weighted ? for
inter-annotator agreement called ?tw that adopts
a taxonomy-dependent weighting, and discuss its
use.
2 Annotation using DIT
DIT is a context-change (or information-state up-
date) approach to the analysis of dialogue, which
describes utterance meaning in terms of context
update operations called ?dialogue acts?. A dia-
logue act in DIT has two components: (1) the se-
mantic content, being the objects, events, proper-
ties, relations, etc. that are considered; and (2)
the communicative function, that describes how
the addressee is intended to use the semantic con-
tent for updating his context model when he un-
derstands the utterance correctly. DIT takes a mul-
tidimensional view on dialogue in the sense that
speakers may use utterances to address several as-
pects of the communication simultaneously, as re-
flected in the multifunctionality of utterances. One
such aspect is the performance of the task or ac-
tivity for which the dialogue takes place; another
is the monitoring of each other?s attention, under-
standing and uptake through feedback acts; others
include for instance the turn-taking process and
the timing of communicative actions, and finally
yet another aspect is formed by the social obli-
gations that may arise such as greeting, apologis-
ing, or thanking. The various aspects of commu-
nication that can be addressed independently are
called dimensions (Bunt and Girard, 2005; Bunt,
2006). The DIT++ tagset distinguishes 11 dimen-
sions, which all contain a number of communica-
tive functions that are specific to that dimension,
such as TURN GIVING, PAUSING, and APOLOGY.
Besides dimension-specific communicative
functions, DIT also distinguishes a layer of
communicative functions that are not specific to
any particular dimension but that can be used
to address any aspect of communication. These
functions, which include questions, answers,
statements, and commissive as well as directive
acts, are called general purpose functions. A
dialogue act falls within a specific dimension
if it has a communicative function specific for
that dimension or if it has a general-purpose
function and a semantic content relating to that
dimension. Dialogue utterances can in principle
have a function (but never more than one) in each
of the dimensions, so annotators using the DIT++
scheme can assign at most one tag for each of the
11 dimensions to any given utterance.
Both within the set of general-purpose com-
municative function tags and within the sets of
dimension-specific tags, tags can be hierarchically
related in such a way that a label lower in a hier-
archy is more specific than a label higher in the
same hierarchy. Tag F1 is more specific than tag
F2 if F1 defines a context update operation that in-
cludes the update operation corresponding to F2.
For instance, consider a part of the taxonomy for
general purpose functions (Figure 1).
INFO.SEEKING
IND-YNQ
YNQ
CHECK
POSI NEGA
IND-WHQ
WHQ
. . .
Figure 1: Two hierarchies in the information seek-
ing general purpose functions.
For an utterance to be assigned a YN-QUESTION,
we assume the speaker believes that the addressee
knows the truth value of the proposition presented.
For an utterance to be assigned a CHECK, we as-
sume the speaker additionally has a weak be-
lief that the proposition that forms the seman-
tic content is true. And for a POSI-CHECK, there
is the additional assumption that the speaker be-
lieves (weakly) that the hearer also believes that
the proposition is true.1
Similar to the hierarchical relations between
YN-Question, CHECK, and POSI-CHECK, other parts
1For a formal description of each function in the DIT++
tagset see http://ls0143.uvt.nl/dit/
127
of the annotation scheme contain hierarchically re-
lated functions.
The following example illustrates the use of
DIT++ communicative functions for a very simple
translated) dialogue fragment2.
1 S at what time do you want to travel today?
TASK = WH-Q, TURN-MANAGEMENT = GIVE
2 U at ten.
TASK = WH-A, TURN-MANAGEMENT = GIVE
3 S so you want to leave at ten in the morning?
TASK = POSI-CHECK, TURN-MANAGEMENT = GIVE
4 U yes that is right.
TASK = CONFIRM, TURN-MANAGEMENT = GIVE
3 Agreement using ?
3.1 Related work
Inter-annotator agreements have been calculated
with the purpose of qualitatively evaluating tagsets
and individual tags. For DAMSL, the first agree-
ment results were presented in (Core and Allen,
1997), based on the analysis of TRAINS 91-
93 dialogues (Gross et al, 1993; Heeman and
Allen, 1995). In this analysis, 604 utterances
were tagged by mostly two annotators. Follow-
ing the suggestions in (Carletta, 1996), Core et
al. consider kappa scores above 0.67 to indi-
cate significant agreement and scores above 0.8
reliable agreement. Another more recent analy-
sis was performed for 8 dialogues of the MON-
ROE corpus (Stent, 2000), counting 2897 utter-
ances in total, processed by two annotators for 13
DAMSL dimensions. Other analyses apply DAMSL
derived schemes (such as SWITCHBOARD-DAMSL)
to various corpora (e.g. (Di Eugenio et al, 1998;
Shriberg et al, 2004) ). For the comprehensive
DIT++ taxonomy, the work reported here repre-
sents the first investigation of annotator agree-
ment.
3.2 Experiment outline
As noted, existing work on annotator agreement
analysis has mostly involved only two annotators.
It may be argued that especially for annotation of
concepts that are rather complex, an odd number
of annotators is desirable. First, it allows having
majority agreement unless all annotators choose
entirely different. Second, it allows to deal bet-
ter with the undesirable situation that one annota-
tor chooses quite differently from the others. The
2Drawn from the OVIS corpus (Strik et al, 1997):
OVIS2:104/001/001:008-011
agreement scores reported in this paper are all cal-
culated on the basis of the annotations of three
annotators, using the method proposed in (Davies
and Fleiss, 1982).
The dialogues that were annotated are task-
oriented and are all in Dutch. To account for
different complexities of interaction, both human-
machine and human-human dialogues are consid-
ered. Moreover, the dialogues analyzed are drawn
from different corpora: OVIS (Strik et al, 1997),
DIAMOND (Geertzen et al, 2004), and a collec-
tion of Map Task dialogues (Caspers, 2000); see
Table 1, where the number of annotated utterances
is also indicated.
corpus domain type #utt
OVIS TRAINS like interactions H-M 193
on train connections
DIAMOND1 interactions on how to H-M 131
operate a fax device
DIAMOND2 interactions on how to H-H 114
operate a fax device
MAPTASK HCRC Map Task like H-H 120
interaction
558
Table 1: Characteristics of the utterances consid-
ered
Six undergraduate students annotated the se-
lected dialogue material. They had been intro-
duced to the DIT++ annotation scheme and the un-
derlying theory while participating in a course on
pragmatics. During this course they were exposed
to approximately four hours of lecturing and few
small annotation exercises. For all dialogues, the
audio recordings were transcribed and the annota-
tors annotated presegmented utterances for which
full agreement was established on segmentation
level beforehand. During the annotation sessions
the annotators had ? apart from the transcribed
speech ? access to the audio recordings, to the
on-line definitions of the communicative functions
in the scheme and to a very brief, 1-page set of an-
notation guidelines3 . The task was facilitated by
the use of an annotation tool that had been built
for this occasion; this tool allowed the subjects to
assign each utterance one DIT++ tag for each di-
mension without any further constraints. In total
1,674 utterances were annotated.
3.3 Problems with standard ?
If we were to apply the standard ? statistic to
DIT++ annotations, we would not do justice to an
important aspect of the annotation scheme con-
cerning the differences between alternative tags,
3See http://ls0143.uvt.nl/dit
128
and hence the possible differences in the dis-
agreement between annotators using alternative
tags. An aspect in which the DIT++ scheme dif-
fers from other taxonomies for dialogue acts is
that, as noted in Section 2, communicative func-
tions (CFs) within a dimension as well as general-
purpose CFs are often structured into hierarchies
in which a difference in level represents a relation
of specificity. When annotators differ in that they
assign tags which both belong to the same hier-
archy, they may differ in the degree of specificity
that they want to express, but they agree to the ex-
tent that these tags inherit the same elements from
tags higher in the hierarchy. Inter-annotator dis-
agreement is in such a case much less than if they
would choose two unrelated tags. This is for in-
stance obvious in the following example of the an-
notations of two utterances by two annotators:
1 S what do you want to know? WHQ YNQ
2 U can I print now? YNQ CHECK
With utterance 1, the annotators should be said
simply to disagree (in fact, annotator 2 incorrectly
assigns a YNQ function). Concerning utterance 2
the annotators also disagree, but Figure 1 and the
definitions given in Section 2 tell us that the dis-
agreement in this case is quite small, as a CHECK in-
herits the properties of a YNQ. We therefore should
not use a black-and-white measure of agreement,
like the standard ?, but we should have a measure
for partial annotator agreement.
In order to measure partial (dis-)agreement be-
tween annotators in an adequate way, we should
not just take into account whether two tags are hi-
erarchically related or not, but also how far they
are apart in the hierarchy, to reflect that two tags
which are only one level apart are semantically
more closely related than tags that are several lev-
els apart. We will take this additional requirement
into account when designing a weighted disagree-
ment statistic in the next section.
4 Agreement based on structural
taxonomic properties
The agreement coefficient we are looking for
should in the first place be weighted in the sense
that it takes into account the magnitude of dis-
agreement. Two such coefficients are weighted
kappa (?w, (Cohen, 1968)) and alpha (Krippen-
dorff, 1980). For our purposes, we adopt ?w for
its property to take into account a probability dis-
tribution typical for each annotator, generalize it to
the case for multiple annotators by taking the aver-
age over the scores of annotator pairs, and define
a function to be used as distance metric.
4.1 Cohen?s weighted ?
Assuming the case of two annotators, let pij de-
note the proportion of utterances for which the first
and second annotator assigned categories i and j,
respectively. Then Cohen defines ?w in terms of
disagreement rather than agreement where qo =
1 ? po and qe = 1 ? pe such that Equation 1 can
be rewritten to:
? = 1 ? qoqe
(2)
To arrive at ?w, the proportions qo and qe in Equa-
tion 2 are replaced by weighted functions over all
possible category pairs:
?w = 1 ?
? vij ? poij
? vij ? peij
(3)
where vij denotes the disagreement weight. To
calculate this weight we need to specify a distance
function as metric.
4.2 A taxonomic metric
The task of defining a function in order to calcu-
late the difference between a pair of categories re-
quires us to determine semantic-pragmatic related-
ness between the CFs in the taxonomy. For any an-
notation scheme, whether it is hierarchically struc-
tured or not, we could assign for each possible pair
of categories a value that expresses the semantic-
pragmatic relatedness between the two categories
compared to all other possible pairs. However, it
seems quite difficult to find universal characteris-
tics for CFs to be used to express relatedness on a
rational scale. When we consider a taxonomy that
is structured in a meaningful way, in this case one
that expresses hierarchical relations between CF
based on their effect on information states, the tax-
onomic structure can be exploited to express in a
systematic fashion how much annotators disagree
when they choose different concepts that are di-
rectly or indirectly related.
The assignment of different CFs to a specific ut-
terance by two annotators represents full disagree-
ment in the following cases:
1. the two CFs belong to different dimensions;
129
2. one of the two CFs is general-purpose; the
other is dimension-specific;4
3. the two CFs belong to the same dimension
but not to the same hierarchy;
4. the two CFs belong to the same hierarchy
but are not located in the same branch. Two
CFs are said to be located in the same branch
when one of the two CFs is an ancestor of the
other.
If, by contrast, the two CFs take part in a parent-
child relation within a hierarchy (either within a
dimension or among the general-purpose CFs),
then the CFs are related and this assignment repre-
sents partial disagreement. A distance metric that
measures this disagreement, which we denote as
?, should have the following properties:
1. ? should be a real number normalized in the
range [0 . . . 1];
2. Let C be the (unordered) set of CFs.5 For ev-
ery two CFs c1, c2 ? C , ?(c1, c2) = 0 when
c1 and c2 are not related;
3. Let C be the (unordered) set of CFs. For ev-
ery communicative function c ? C , ?(c, c) =
1;
4. Let C be the (unordered) set of CFs. For
every two CFs c1, c2 ? C , ?(c1, c2) =
?(c2, c1).
Furthermore, when c1 and c2 are related, we
should specify how distance between them in the
hierarchy should be expressed in terms of partial
disagreement. For this, we should take the follow-
ing aspects into account:
1. The distance in levels between c1 and c2 in
the hierarchy is proportional to the magnitude
of the disagreement;
4This is in fact a simplification. For instance, an INFORM
act of which the semantic content conveys that the speaker
did not understand the previous utterance forms an act in the
Auto-Feedback dimension (see Note 6), and a tagging to this
effect should perhaps not be considered to express full dis-
agreement with the assignment of the dimension-specific tag
AUTO-FEEDBACK-Int?. See also the next footnote.
5Strictly speaking, in DIT a dialogue act annotation tag is
either (a) the name of a dimension-specific function, or (b) a
pair consisting of the name of a general-purpose function and
the name of a dimension. However, in view of the simplifica-
tion mentioned in the previous note, for the sake of this paper
we may as well consider tags containing a general-purpose
function as simply consisting of that function.
Auto Feedback
Perc?
Int?
Eval?
Exec?
Perc+
Int+
Eval+
Exec+
Figure 2: Hierarchical structures in the auto feed-
back dimension.
2. The magnitude of disagreement between c1
and c2 being located in two different levels of
depths n and n+1 might be considered to be
more different than that between to levels of
depth n + 1 and n + 2. If this would be the
case, the deeper two levels are located in the
tree, the smaller the differences between the
nodes on those levels. For the hierarchies in
DIT, we keep the magnitude of disagreement
linear with the difference in levels, and inde-
pendent of level depth;
Given the considerations above, we propose the
following metric:
?(ci, cj) = a?(ci,cj) ? b?(ci,cj) (4)
where:
? a is a constant for which 0 < a < 1, express-
ing how much distance there is between two
adjacent levels in the hierarchy; a plausible
value for a could be 0.75;
? ? is a function that returns the difference in
depth between the levels of ci and cj;
? b is a constant for which 0 < b ? 1, express-
ing in what rate differences should become
smaller when the depth in the hierarchy gets
larger. If there is no reason to assume that
differences on a higher depth in the hierarchy
are of less magnitude than differences on a
lower depth, then b = 1;
? ?(ci, cj) is a function that returns the mini-
mal depth of ci and cj .
To provide some examples of how ? would be
calculated, let us consider the general purpose
functions in Figure 1. Consider also Figure 2,
that represents two hierarchies of CFs in the auto
130
feedback dimension6, and let us assume the values
of the various parameters those that are suggested
above. We then get the following calculations:
?(IND ? Y NQ,CHECK) = 0.752 ? 1 = 0.563
?(Y NQ,CHECK) = 0.751 ? 1 = 0.75
?(Perc+, P erc+) = 0.750 ? 1 = 1
?(Perc+, Eval+) = 0.752 ? 1 = 0.563
?(Int?, Int+) = 0
?(POSI,NEGA) = 0
To conclude, we can simply take ? to be the
weighting in Cohen?s ?w and come to a coefficient
which we will call taxonomically weighted kappa,
denoted by ?tw:
?tw = 1 ?
?(1 ? ?(i, j)) ? poij
?(1 ? ?(i, j)) ? peij
(5)
4.3 ?tw statistics for DIT
Considering the DIT++ taxonomy, it may be argued
that due to the many hierarchies in the topology
of the general-purpose functions, this is the part
where most is to be gained by employing ?tw.
Table 2 shows the statistics for each dimension,
averaged over all annotation pairs. With anno-
tation pair is understood the pair of assignments
an utterance received by two annotators for a par-
ticular dimension. The figures in the table are
based on those cases in which both annotators as-
signed a function to a specific utterance for a spe-
cific dimension. Cases where either one annotator
does not assign a function while the other does,
or where both annotators do not assign a function,
are not considered. Scores for standard ? and ?tw
can be found in the first two columns. The column
#pairs indicates on how many annotation pairs the
statistics are based. The last column shows the
ap-ratio. This figure indicates which fraction of
all annotated functions in that dimension are rep-
resented by annotation pairs. When #ap denotes
the number of annotation pairs and #pa denotes
the number of partial annotations (annotations in
which one annotator assigned a function and the
other did not), then the ap-ratio is calculated as
#ap/(#pa + #ap). We can observe that due to
the use of the taxonomic weighting both feedback
dimensions and the task dimension gained sub-
stantially in annotator agreement.
6Auto-feedback: feedback on the processing (perception,
understanding, evaluation,..) of previous utterances by the
speaker. DIT also distinguishes allo-feedback, where the
speaker provides or elicits information about the addressee?s
processing.
Dimension ? ?tw #pairs ap-ratio
task 0.47 0.71 848 0.87
task:action discussion 0.61 0.61 91 0.37
auto feedback 0.21 0.57 127 0.34
allo feedback 0.42 0.58 17 0.14
turn management 0.82 0.82 115 0.18
time management 0.58 0.58 68 0.72
contact management 1.00 1.00 8 0.17
topic management nav nav 2 0.08
own com. management 1.00 1.00 2 0.08
partner com. management nav nav 1 0.07
dialogue struct. management 0.74 0.74 15 0.31
social obl. management 1.00 1.00 61 0.80
Table 2: Scores for corrected ? and ?tw per DIT
dimension.
When we look at the agreement statistics and
consider ? scores above 0.67 to be significant
and scores above 0.8 considerably reliable, as is
usual for ? statistics, we can find the dimensions
TURN-MANAGEMENT, CONTACT MANAGEMENT, and
SOCIAL-OBLIGATIONS-MANAGEMENT to be reliable
and DIALOGUE STRUCT. MANAGEMENT to be signif-
icant. For some dimensions, the occurences of
functions in these dimensions in the annotated di-
alogue material were too few to draw conclusions.
When we also take the ap-ratio into account,
only the dimensions TASK, TIME MANAGEMENT,
and SOCIAL-OBLIGATIONS-MANAGEMENT combine
a fair agreement on functions with fair agreement
on whether or not to annotate in these dimensions.
Especially for the other dimensions, the question
should be raised for which cases and for what rea-
sons the ap-ratio is low. This question asks for
further qualitative analysis, which is beyond the
scope of this paper7.
5 Discussion
In the previous sections, we showed how the tax-
onomically weighted ?tw that we proposed can be
more suitable for taxonomies that contain hierar-
chical structures, like the DIT++) taxonomy. How-
ever, there are some specific and general issues
that deserve more attention.
A question that might be raised in using ?tw as
opposed to ordinary ?, is if the assumption that the
interpretations of ? proposed in literature in terms
of reliability is also valid for ?tw statistics. This
is ultimately an empirical issue, to be decided by
which ?tw scores researchers find to correspond to
fair or near agreement between annotators.
Another point of discussion is the arbitrariness
of the values of the parameters that can be cho-
sen in ?. In this paper we proposed a = 0.75 and
? = 0.5. Choosing different values may change
7See (Geertzen, 2006) for more details.
131
the disagreement of two distinct CFs located in the
same hierarchy considerably. Still, we think that
by interpolating smoothly between the intuitively
clear cases at the two extreme ends of the scale,
it is possible to choose reasonable values for the
parameters that scale well, given the average hier-
archy depth.
A more general problem, inherent in almost
any (dialogue act) annotation activity is that when
we consider the possible factors that influence the
agreement scores, we find that they can be nu-
merous. Starting with the tagset, unclear defini-
tions and vague concepts are a major source of
disagreement. Other factors are the quality and ex-
tensiveness of annotation instructions, and the ex-
perience of the annotators. These were kept con-
stant throughout the experiment reported in this
paper, but clearly the use of more experienced or
better trained annotators could have a great influ-
ence. Then there is the influence that the use of an
annotation tool can have. Does the tool gives hints
on annotation consistency (e.g. an ANSWER should
be preceded by a QUESTION), does it enforce con-
sistency, or does it not consider annotation consis-
tency at all? Are the possible choices for anno-
tators presented in such a way that each choice is
equally well visible and accessible? Clearly, when
we do not control these factors sufficiently, we run
the risk that what we measure does not express
what we try to quantify: (dis)agreement among
annotators about the description of what happens
in a dialogue.
6 Conclusion and future work
In this paper we have presented agreement scores
for Cohen?s unweighted ? and claimed that for
annotation schemes with hierarchically related
tags, a weighted ? gives a better indication of
(dis)agreement than unweighted ?. The ? scores
for some dimensions seem not particularly spec-
tacular but become more interesting when look-
ing at semantic-pragmatic differences between di-
alogue acts or CFs. Even though there are some-
what arbitrary aspects in weighting, when parame-
ters are carefully chosen a weighted metric gives a
better representation of the inter-annotator agree-
ments. More generally, we propose that semantic-
pragmatic relatedness between taxonomic con-
cepts should be taken into account when calculat-
ing inter-annotator (dis)agreement. While we used
DIT++ as tagset, the weighting function we pro-
posed can be employed in any taxonomy contain-
ing hierarchically related concepts, since we only
used structural properties of the taxonomy.
We have also quantitatively8 evaluated the
DIT++ tagset per dimension, and obtained an in-
dication of its usability. We focussed on agree-
ment per dimension, but when we desire a global
indication of the difference in semantic-pragmatic
interpretation of a complete utterance it requires
us to consider other aspects. A truly multidimen-
sional study of inter-annotator agreement should
not only take intra-dimensional aspects into ac-
count but also relate the dimensions to each other.
In (Bunt and Girard, 2005; Bunt, 2006) it is argued
that dimensions should be orthogonal, meaning
that an utterance can have a function in one dimen-
sion independent of functions in other dimensions.
This is a somewhat utopical condition, since there
are some functions that show correlations and de-
pendencies with across dimensions. For this rea-
son it makes sense to try to express the effect of the
presence of strong correlations, dependencies and
possible entailments in a multidimensional notion
of (dis)agreement. Additionally, it may be desir-
able to take into account the importance that a CF
can have. It is widely acknowledged that utter-
ances are often multifunctional, but it could be ar-
gued that in many cases an utterance has a primary
function and secondary functions; for instance, if
an utterance has both a task-related function and
one or more other functions, the task-related func-
tion is typically felt to be more important than the
other functions, and disagreement about the task-
related function is therefore felt to be more seri-
ous than disagreement about one of the other func-
tions. This might be taken into account by adding
a weighting function when combining agreement
measures over multiple dimensions.
Other future work we plan is more methodolog-
ical in nature, quantifying the relative effect of the
factors that may have influenced the scores that we
have found. This would create a situation in which
there is more insight in what exactly is evaluated.
As for evaluating the tagset, we for instance plan
to further analyze co-occurence matrices to iden-
tify frequent misannotations, and to have annota-
tors thinking aloud while performing the annota-
tion task.
8Kappa statistics are indicative. To get a full understand-
ing of what the figures represent, qualitative analysis by using
e.g. co-occurence matrices is required, which is beyond the
scope of this paper.
132
Acknowledgements
The authors thank three anonymous reviewers for
their helpful comments on an earlier version of this
paper.
References
James Allen and Mark Core. 1997. Draft of DAMSL:
Dialog act markup in several layers. Unpublished
manuscript.
J. Allwood, J. Nivre, and E. Ahlse?n. 1993. Manual for
coding interaction management. Technical report,
Go?teborg University. Project report: Semantik och
talspra?k.
Harry C. Bunt and Yann Girard. 2005. Designing an
open, multidimensional dialogue act taxonomy. In
Proceedings of the 9th Workshop on the Semantics
and Pragmatics of Dialogue (DIALOR 2005), pages
37?44, Nancy, France, June.
Harry C. Bunt. 2000. Dialogue pragmatics and con-
text specification. In Harry C. Bunt and William
Black, editors, Abduction, Belief and Context in Di-
alogue; Studies in Computational Pragmatics, pages
81?150. John Benjamins, Amsterdam, The Nether-
lands.
Harry C. Bunt. 2005. A framework for dialogue act
specification. In Joint ISO-ACL Workshop on the
Representation and Annotation of Semantic Infor-
mation, Tilburg, The Netherlands, January.
Harry C. Bunt. 2006. Dimensions in dialogue annota-
tion. In Proceedings of the 5th International Confer-
ence on Language Resources and Evaluation (LREC
2006), Genova, Italy, May.
Jean Carletta. 1996. Assessing agreement on classi-
fication tasks: The kappa statistic. Computational
Linguistics, 22(2):249?254.
Johanneke Caspers. 2000. Pitch accents, boundary
tones and turn-taking in dutch map task dialogues.
In Proceedings of the 6th International Conference
on Spoken Language Processing (ICSLP 2000), vol-
ume 1, pages 565?568, Beijing, China.
Jacob Cohen. 1960. A coefficient of agreement for
nominal scales. Education and Psychological Mea-
surement, 20:37?46.
Jacob Cohen. 1968. Weighted kappa: Nominal scale
agreement with provision for scaled disagreement or
partial credit. Psychological Bulletin, 70:213?220.
Mark G. Core and James F. Allen. 1997. Coding di-
alogues with the DAMSL annotation scheme. In
David Traum, editor, Working Notes: AAAI Fall
Symposium on Communicative Action in Humans
and Machines, pages 28?35, Menlo Park, CA, USA.
American Association for Artificial Intelligence.
Mark Davies and J.L. Fleiss. 1982. Measuring agree-
ment for multinomial data. Biometrics, 38:1047?
1051.
Barbara Di Eugenio and Michael Glass. 2004. The
kappa statistic: a second look. Computational Lin-
guistics, 30(1):95?101.
Barbara Di Eugenio, Pamela W. Jordan, Johanna D.
Moore, and Richmond H. Thomason. 1998. An em-
pirical investigation of proposals in collaborative di-
alogues. In Proceedings of the 17th International
Conference on Computational Linguistics and the
36th Annual Meeting of the Association for Com-
putational Linguistics (COLING-ACL 1998), pages
325?329, Montreal, Canada.
Jeroen Geertzen, Yann Girard, Roser Morante, Ielka
van der Sluis, Hans Van Dam, Barbara Suijkerbuijk,
Rintse van der Werf, and Harry Bunt. 2004. The
diamond project (poster,project description). In The
8th Workshop on the Semantics and Pragmatics of
Dialogue (Catalog?04). Barcelona, Spain.
Jeroen Geertzen. 2006. Inter-annotator agreement
within dit++ dimensions. Technical report, Tilburg
University, Tilburg, The Netherlands.
Derek Gross, James F. Allen, and David R. Traum.
1993. The TRAINS 91 dialogues. Technical Re-
port TN92-1, University of Rochester, Rochester,
NY, USA.
Peter A. Heeman and James F. Allen. 1995. The
TRAINS 93 dialogues. Technical Report TN94-2,
University of Rochester, Rochester, NY, USA.
Klaus Krippendorff. 1980. Content Analysis: An In-
troduction to its Methodology. Sage Publications,
Beverly Hills, CA, USA.
Stephan Lesch, Thomas Kleinbauer, and Jan Alexan-
dersson. 2005. A new metric for the evaluation
of dialog act classification. In Proceedings of the
9th Workshop on the Semantics and Pragmatics of
Dialogue (DIALOR 2005), pages 143?146, Nancy,
France, june.
Elizabeth Shriberg, Raj Dhillon, Sonali Bhagat, Jeremy
Ang, and Hannah Carvey. 2004. The ICSI meeting
recorder dialog act (MRDA) corpus. In Proceedings
of the 5th SIGdial Workshop on Discourse and Dia-
logue, pages 97?100, Boston, USA, April-May.
Amanda J. Stent. 2000. The monroe corpus. Techni-
cal Report TR728/TN99-2, University of Rochester,
Rochester, UK.
Helmer Strik, Albert Russel, Henk van den Heuvel, Ca-
tia Cucchiarini, and Lou Boves. 1997. A spoken di-
alog system for the dutch public transport informa-
tion service. International Journal of Speech Tech-
nology, 2(2):119?129.
133
Proceedings of the 8th International Conference on Computational Semantics, pages 33?44,
Tilburg, January 2009. c?2009 International Conference on Computational Semantics
Semantic annotations as complementary to
underspecified semantic representations
Harry Bunt
Department of Communication and Information Sciences
Tilburg University, Netherlands
harry.bunt@uvt.nl
Abstract
This paper presents a new perspective on the use of semantic an-
notations. We argue that semantic annotations should (1) capture
semantic information that is complimentary to the information that is
expressed in the source text; (2) have a formal interpretation. If these
conditions are fullfilled, then the information in semantic annotations
can be effectively combined with the information in the source text
by interpreting a semantic annotation language through the transla-
tion of annotations into the same formalism as underspecified semantic
representations obtained through compositional semantic analysis.
1 Introduction
Annotations add information to a source text. In the pre-digital age, ad-
notations characteristically took the form of an editor?s bibliographical or
historical comments, presented in notes that are added to the source text.
In the digital age, annotations take on a different form, but their function is
essentially the same: they add information to a source text. The following
example illustrates this.
In (1a) an annotation in the form of a note adds certain historical in-
formation to the text; it is indeed additive in the sense that it contains
information which is not in the text itself. In (1b), by contrast, the infor-
mation in the note is in fact already contained in the text itself, and the
annotation therefore does not make any sense.
(1) a. In 1634 he proposed to distinguish sixty-four elements.
132
)
Note 132. A proposal to this effect had in fact been made before
33
by Larochelle in 1544 in his epistle ?Plus d?aspects fondamentals de
la materia? )
b. In 1634 He proposed to distinguish sixty-four elements. (A proposal
to this effect had in fact been made before by Larochelle in 1544 in
his epistle ?Plus d?aspects fondamentals de la materia?).
132
)
Note 132. Also proposed by Larochelle in 1544.
It may seem obvious that annotations do not make sense if they do not
add any information, but consider the following example of annotating text
with temporal information using TimeML (Pustejovsky et al, 2003):
(2) <timeml>
The CEO announced that he would resign as of
<TIMEX3 tid="t1" type="date" value="2008-12-01"/ >
the first of December 2008
</TIMEX3>
</timeml>
The annotation in this case does not contain any information which is
not already in the text itself; it only casts the description of a date the first
of December 2008 in the alternative format ?2008-12-01.
By contrast, a case where semantic annotation would really add some-
thing, is the following.
(3) John called today.
In the absence of further temporal information (when was this sentence
uttered/written/published/..?) we don?t know what day is referred to by
?today?. In this case it would help to have the semantic annotation (4), added
by someone (or by a computer program) who possesses that information or
is able to find it, for instance by having access to relevant metadata.
(4) <timeml>
John
<EVENT called id="e1"/ >
<TIMEX3 tid=t1 type="date" value="2008-10-13"/ >
today
</TIMEX3>
<TLINK event="e1" relatedToTime="t1" relType="DURING"/ >
</timeml>
34
If the point of annotations is to add certain information to a given source
text, then the point of semantic annotations can only be to add semantic
information that is not already in the text. We suggest that this additional
information can be precisely the information whose absence causes the in-
terpretation of sentences to be underspecified, as illustrated in (3), or that
causes ambiguities such as the one in (5).
(5) John saw Peter when he left the house.
The semantic analysis of this sentence tells us that someone called ?John?
saw someone called ?Peter?, and that this happened at the moment that one
of them left the house. If it is known that ?he? actually refers to Peter, this
could be captured by the semantic annotation in (6):
(6) <refml>
<REFENTITY id=r1 John/ >
saw
<REFENTITY id=r2 Peter / >
when
<REFENTITY id=r3 he / >
left the house
<REFLINK anaphor=r3 antecedent=r2 relType=IDENTITY/ >
</refml>
Other types of ambiguity which could benefit from additional informa-
tion in semantic annotations for example concern relative scoping, semantic
roles, discourse relations, and dialogue acts, as illustrated in (7) - (10).
(7) Angry men and women demonstrated against the proposal.
(8) a. The movie scared Jane.
b. John scared Jane.
(intentionally: Agent role; unintentionally: Cause role)
(9) a. John called Mary; he missed her.
(Effect - Cause relation)
b. John called Mary; she was delighted to hear from him.
(Cause - Effect relation)
(10) You?re not going to the cinema tonight.
(Statement/verification/prohibition)
35
These examples all have in common that they contain an ambiguity which
cannot be resolved on the basis of the text alone. The additional information
that is needed to deal with such ambiguities has to come from elsewhere, such
as from donain knowledge, from knowledge about the situation of utterance,
or from metadata.
Ambiguities whose resolution requires information from outside the text
are a problem for compositional semantics approaches. Compositional gen-
eration of all the possible alternative semantic representations (and sub-
sequent filtering) leads to a combinatorial explosion in the interpretation
process (see Bunt & Muskens, 1999). Underspecified semantic representa-
tions (USRs) have been proposed as way to get around this, but suffer from
the limitation that reasoning directly with USRs is problematic; in most
applications, it is necessary to resolve the underspecifications at some stage
and to create a fully disambiguated representation.
In this paper we argue that semantic annotations can be helpful for
effectively dealing with ambiguities if they have a formal semantics, and
in particular if their interpretation makes use of the same representational
formalism as that of underspecified semantic representations.
Since digital texts and their annotations are machine-readable and elec-
tronically exchangeable, an issue for annotation in the digital age is that
it would be beneficial if different researchers use the same concepts for ex-
pressing the same information and put their annotations in a suitable inter-
change format, thus allowing the effective re-use of each other?s annotated
resources. This ideal has in recent years been taken up by an expert group
of the international organization for standardization ISO, concerned with
the interoperability of language resources.
The inspiration for this paper comes from participating in the ?Semantic
Annotation Framework? initiative of the ISO organization and the Euro-
pean eContent project LIRICS (Linguistic Infrastructure for Interoperable
Resources and Systems, http://lirics.loria.fr), that was set up and
carried out by ISO expert group members. Building on studies on in the LIR-
ICS project, two ISO projects have started in 2007 and 2008, respectively,
that aim at proposing standards for the annotation of temporal informa-
tion and for annotating the communicative functions of dialogue utterances.
Both projects include the design of sets of well-defined and well-documented
concepts for semantic annotation which are made publicly available in an on-
line registry (following ISO standard 12620 - see http://www.isocat.org).
Modern annotations typically take the form of XML tags, as illustrated
in (2), (4), and (6), where the kind of attributes and values in the tags
depend on the purpose of the annotation: morphosyntactic, part-of-speech,
36
syntactic, etc. Following the Linguistic Annotation Framework (Ide and
Romary, 2004; ISO, 2008b), ISO projects insist on using standoff annotation,
where the annotations are contained in a separate file with pointers to the
source text file, rather than using in-line annotation as in (2), (4), and (6).
We will return to this in section 3, where this will turn out to be important
for the correct combination of semantic annotations and USRs.
The rest of this paper is organized as follows. In Section 2 we very
briefly consider recent work aiming at the definition of semantic annota-
tion languages that have a formal semantics. Sections 3 and 4 deal with
two ?alignment? problems that arise in the combination of semantic anno-
tations with underspecified semantic representations. First, the two should
preferably be ?aligned? in using the same representation formalism. This is
the subject of Section 3. Second, the components of semantic annotation
structures and underspecified semantic representation structures should be
aligned in that they relate to the same stretches of source text. This is the
subject of Section 4. Section 5 closes with some concluding remarks.
2 The semantics of semantic annotations
Like other forms of annotation, such as POS annotation, semantic annota-
tion has mostly been viewed as a form of text labelling. This may for example
be useful in corpus-linguistic research, supporting the search of certain lin-
guistic patterns, or for finding certain types of information, such as temporal
information. On the other hand when we look at the (simplified) TimeML
annotations shown in (2) and (4), we note that there is in fact an effort to
use XML attributes and values to not just put a flag in a text, signalling
that there is temporal information there, but also to describe the content
that information. What is lacking ?only? is a semantics of this language.
Recent attempts to provide a semantics for semantic annotations in-
clude the Interval Temporal Logic semantics for TimeML by Pratt-Hartman
(2005); the event-based semantics for TimeML by Bunt & Overbeeke (2008a),
and other attempts to formally interpret temporal annotations by Katz
(2007) and Lee (2008). The most elaborate proposal for a semantics of
semantic annotation is formulated in Bunt (2007) and Bunt & Overbeeke
(2008b), where a semantic annotation language is presented with a formal
semantics, that integrates temporal information, semantic roles, and coref-
erence relations. This semantics translates annotations in a systematic,
compositional manner into first-order or second-order logic.
1
1
First-order logic suffices in most cases, but second-order logic is needed for cases of
37
Since first-order logic is formally equivalent with Discourse Representa-
tion Structures (and second-order logic to DRSs with second-order discourse
referents), this semantics can be recast in the form of a translation into
DRSs. Rather than spelling out how this can be done, we refer to Bunt &
Overbeeke (2008b) and exploit the well-established equivalence with DRSs.
For example, the annotation representation in (6) translates into the DRS
< {x, y, z}, {john(x), peter(y), saw(x, y),male(z), leftthehouse(z), z = y}} >
3 Combining USRs and semantic annotations
Reasoning is the combination of pieces of information ? so that?s what needs
to be done when the information in semantic annotations is combined with
that in USRs. If we are able to interpret semantic annotations by translating
them into the same representational format as USRs, then the reasoning
process can take on a very simple form: unification.
A range of representational and processing techniques have been pro-
posed for underspecified semantic representation; in the overview in Bunt
(2007), it is argued that the use of labels (as in UDRT, Reyle,1993) and
hole variables (as in Hole Semantics, Bos, 1996) or ?handles? (as in MRS,
Copestake et al, 1997), in combination with the use of metavariables (as
proposed e.g. by Pinkal, 1999) allows the underspecified representation of
a wide range of semantic phenomena. Labels etc. are particularly useful
for the underspecified respresentation of structural ambiguities like relative
scoping and PP attachment, while metavariables are suitable for local ambi-
guities like anaphora, metonymy, and sense ambiguities. We will therefore
cast the formal semantics of semantic annotations in the form of UDRSs
with labels and hole variables, extended by allowing metavariables to occur
in conditions.
2
3.1 Unifying USRs and annotation interpretation
We first illustrate the combination of USRs and semantic annotations for
simple cases of (a) relative scope resolution; (b) coreference resolution; (c)
the interpretation of temporal deixis. In the next subsection we show that
more complex cases may involve a technical complication for ensuring that
the underspecified parts of USRs and the information in semantic annota-
collective coreference.
2
Another extension, which we will not consider here, is that of allowing second-order
discourse referents; cf. previous footnote.
38
tions refer to the same segments of the source text, and we indicate how this
?alignment? problem can be solved.
In (11b) we see on the left the underspecified representation of the quan-
tifier scopes in (sentence 11a), and on the right the AIR of the annotation,
indicating in its bottom part that the universal quantifier has wider scope.
The bottom part of the USR contains the scope constraints on the possible
ways of combining the various conditions and sub-DRS?s contained in the
upper part into a complete DRS. The operator ??? constructs a DRS from
the labeled structures that it operates on.
(11) a. Every man loves a woman.
b.
USR AIR
L4: x, L8: y T1: a, T4: b
L1: L3 ? h1 T2: man(a),
L2: ?{h2,h3}, T3: ?{T1,T2},
L3: ?{L4,L5}, T5: woman(b),
L5: man(x), T6: ?{T4,T5}
L6: love(x,y),
L7: ?{L8,L9},
L9: woman(y)
L3 > L6, L7 > L6 T3 > T6
Unification of the two representations includes the label unifications T3=L3
and T6=L7, which has the effect that the AIR scope constraint adds the
constraint L3 > L7 to the USR. This has the result that of the two possible
?pluggings? of the hole variables in the USR (h0=L1, h1=L2, h2=L6, h3=L7;
and h0=L2, h1=L6, h2=L1, h3=L7) the second one is ruled out. This
reflects that the semantic annotation resolves the ambiguity.
In (12b), the part on the left shows the USR of the sentence (12a), while
the part on the right shows the Annotation Interpretation Representation
(AIR) in the same UDRS-based formalism. Combination of the two takes
the form of a simple unification, where label variables are unified as well as
discourse markers. The unification(with T1=L1, a=x; T3=L3, b=y; L2=T2;
L4=T4; L8=T6), results in (13), which is an ordinary DRS (of which the
unified labels have been suppressed).
(12) a. John saw Bill ? he was happy
39
b.
USR AIR
L1: x, L3: y, L5: e, L7: z T1: a, T3: b, T5: c
L2: john(x), T2: john(a),
L4: bill (y), T4: bill (b),
L6: saw (e,x,y), T6: he(c),
L8: he(z), T7: c=a,
L9: happy(z),
(13)
x, y, e, z
john(x),
bill (y),
saw (e,x,y),
he(z),
happy(z),
z=x
Example (14) shows the use of metavariables in the USR for representing
underspecified deictic information. The predicates representing ?me? and
?today? have an asterisk to indicate their status as metavariables.
(14) a. John called me today
b.
USR AIR.
L1: x, L3: y, L5: e, L7: t1 T1: a, T3: b, T5: t2
L2: john(x), T2: john(a),
L4: *ME(y), T4: harrybunt(b),
L6: call(e,x,y, t1), T6: 20080923(t2)
L8: *TODAY(t1)
The use of metavariables assumes an interpretation process where these
variables are at some stage instantiated by ordinary expressions of the rep-
resentation language. By treating metavariables indeed as variables in the
unification process, they are instantiated by the corresponding terms in the
semantic annotations.
The above examples all suggest that the information contained in se-
mantic annotations can be combined with that in underspecified semantic
representations in a straightforward way, using unification. There is a com-
plication, however, which does not turn up in these simple examples, namely
that the correct combination of the two pieces of information requires the
40
components of the two representation sructures to be ?aligned? in the sense
of being related to the same parts of the source text. This issue of ?textual
alignment? is addressed in the next subsection.
3.2 Textual alignment
Consider the text fragment (15), in which the anaphoric pronoun ?he? has
three occurrences, which are ambiguous between having John or Bill as their
antecedent.
(15) a. John saw Bill when he left the house. He was happy. Bill had
phoned him last week and warned that he might be unable to come.
b.
USR AIR
L1: x, L3: y, L5: e1, L6: t1, L8: z, T1: a, T3: b, T5: c, T8: d,
L11: t2, L12: e2, L15: u, L19: v T11: f, T14: g, T16: h
L2: john(x), T2: john(a),
L4: bill (y), T4: bill (b),
L7: saw (e1,x,y,t1), T6: he(c),
L9: he(z), T7: c=b,
L10: z=x ? z=y, T9: he(d),
L13: leftthehouse(e2,z,t2), T10: d=a,
L14: t1=t2, T12: bill(f),
L16: he(u), T13: f=b,
L17: happy(u), T1: him(g),
L18 bill(v), T15: g=a,
L20: T17: he(h),
etc. etc.
The AIR in (15) makes perfect sense if we interpret the discourse referent
?c? as corresponding to the first occurrence of ?he?; ?d? to the second; and
?h? to the third. There is however nothing in the AIR that enforces this
interpretation; the AIR is not in any way ?aligned? with the source text or
with the USR, and allows e.g. the components {T5: c, T6: he(c), T7: c=b}
to be unified with the USR components {L1: x, L2: john(x)}.
This problem can be resolved by taking into account that, as mentioned
above, according to the ISO Linguistic Annotation Framework annotations
should be represented in a stand-off format, in a separate file with pointers to
source text segments. This means that, instead of an in-line representation
like (6), we should consider annotations in a format like (16), where the
referential information is ?anchored? to source text segments:
41
(16) <refml>
<SOURCE m1="John" m2="saw" m3="Bill" m4="when" m5="he"
m6="left the house"/ >
<REFENTITY id="r1" anchor="m1" / >
<REFENTITY id="r2" anchor="m3" / >
<REFENTITY id="r3" anchor="m5" gender="male"/ >
<REFLINK anaphor="r3" antecedent="r2" relType="IDENTITY"/ >
<refml/ >
The interpretation of semantic annotations should not throw this textual
anchoring away. This information can subsequently be exploited when com-
bining the AIR with the USR, if the USR components are likewise anchored
to the source text segments that they interpret ? see (17).
(17) a. John saw Bill when he left the house. He was happy.
b. m1="John" m2="saw" m3="Bill" m4="when" m5="he" m6="left"
m7="the" m8="house" m9="he" m10="was" m11="happy"
USR AIR
<m1, L1: x>, <m3, L3: y>, <m1, T1: a>,
<m2, L5: e>, <m1..m3, L6: t1>, <m3, T3: b>,
<m5, L8: z>, <m9, L11:e2>, <m5, T5: c>,
<[m5..m8], L12:t2>, <m10, L15: u> <m9, T8: d>
<m1, L2: john(x)>, <m1, T2: john(a)>,
<m3, L4: bill (y)>, <m3, T4: bill (b)>,
<[m1,m2,m3]: L7: saw (e,x,y,t1)>, <m5: T6: he(c)>,
<m5, L9: he(z)>, <m5: T7: c=a>,
<m5, L10: z=x ? z=y>, <m9: T9: he(d)>,
<[m5..m8], L13:leftthehouse(e2,z,t2)>, <m9: T10: d=a>,
<m4, L14: t2=t1>, <[m1,m3,m4],
<m9, L16: he(u)>, T11: ?{T1,...,T10}>
<m9, L17: u=x ? u=y>
<[m9..m11], L18: happy(u)>,
<[m1,..,m7], L19: ?{L1,...,L18} >
By unifying pairs < m,L : ? > of the USR and < m
?
, T : ? > of the
AIR rather than elements < L : ? > and < T : ? >, we enforce that the
unifications consider only AIR and USR components that apply to the same
source text segments.
Note that, contrary to what the title of this paper suggests, the AIR
and the USR parts in the above examples are in fact not entirely compli-
mentary. In (12), for example, they both include representations of John
42
and Bill and of the discourse referent introduced by ?he?. The conditions
?john(a)?, ?bill(b)? and ?he(c)? would seem to anchor ?a?, ?b? and ?c? to their
intended antecedents in the USR, but example (15) showed that this is an
optical illusion. The textual anchoring of the AIR and the USR makes con-
ditions like ?john(a)? in the AIR fully redundant, and allows it to be reduced
to the introduction of the discourse referents and the conditions specify-
ing the coreference relations. The corresponding annotation is then indeed
complimentary to the USR.
4 Conclusions and perspectives
In this paper we have indicated how the information, contained in seman-
tic annotations, may effectively be used to resolve ambiguities and to nar-
row down underspecified meanings, by exploiting their semantics. We have
thereby assumed that the annotations are expressed in an annotation lan-
guage that has a formal semantics. This is often not the case, but under
the influence of efforts of the international organisation for standards ISO,
projects are under way that do indeed aim to define such annotation lan-
guages, and preliminary studies by Pratt-Hartmann, Katz, Lee, and the au-
thor have demonstrated the feasibility of doing so for substantial fragments
of semantic annotation languages.
This approach opens the possibility to exploit semantic annotations in a
computational interpretation process, as we have shown by casting the in-
terpretation of semantic annotations in a UDRS-like representation format
that is also suitable for underspecified semantic representation, allowing
fairly straightforward unification to combine the information from annota-
tions with that obtained through local, compositional semantic analysis.
Is this useful? Isn?t the (automatic) construction of the semantic anno-
tations the most difficult part of the interpretation enterprise, rather than
something that?s waiting to be exploited? Maybe so; that depends very
much on the kind of linguistic material to be interpreted and on the kinds
of semantic information that annotations aim to capture. One thing is
clear: semantic annotations are constructed using entirely different tech-
niques (machine learning from corpora, exploitation of domain ontologies,
searching metadata,..) than the compositional syntactic-semantic analysis
techniques that make the semantic content at sentence level explicit. The
approach that we have outlined here makes it possible to effectively combine
such very heterogeneous processes and sources of information.
43
References
[1] Bos, J. (1997). Predicate Logic Unplugged. In Proc. 10th Amsterdam Colloquium,
Amsterdam. ILLC.
[2] Bunt, H. (2007a). The Semantics of Semantic Annotation. In Proceedings of the
21st Pacific Asia Conference on Language, Information and Computation (PACLIC21),
pages 13?28.
[3] Bunt, H. (2007b). Underspecified semantic representation: Which technique for what
purpose? In Bunt, H. and Muskens, R. (eds.) Computing Meaning, Vol. 3, pages
115?140. Springer, Dordrecht.
[4] Bunt, H. and Muskens, R. (1999). Computational semantics. In H.Bunt and Muskens,
R., (eds.) Computing Meaning, Vol. 1, pages 1?15. Kluwer Academic Press, Dordrecht.
[5] Bunt, H. and Overbeeke, C. (2008a). An extensible compositional semantics for tem-
poral annotation. In Proceedings LAW-II: Second Linguistic Annotation Workshop,
Marrakech, Morocco. Paris: ELRA.
[6] Bunt, H. and Overbeeke, C. (2008b). Towards formal interpretation of semantic an-
notations. In Proceedings 6th International Conference on Language Resources and
Evaluation (LREC 2008), Marrakech, Morocco. Paris: ELRA.
[7] Bunt, H. and Romary, L. (2002). Towards Multimodal Content Representation. In
Choi, K. S. (ed.) Proceedings of LREC 2002, Workshop on International Standards of
Terminology and Language Resources Management, pages 54?60, Las Palmas, Spain.
Paris: ELRA.
[8] Copestake, A., Flickinger, D., and Sag, I. (1997). Minimal Recursion Semantics: an
Introduction. CSLI, Stanford University.
[9] Ide, N. and Romary, L. (2004). International Standard for a Linguistic Annotation
Framework. Natural Language Engineering, 10:211?225.
[10] Katz, G. (2007). Towards a Denotatial Semantics for TimeML. In Schilder, F., Katz,
G., and Pustejovsky, J. (eds.) Annotation, Extraction, and Reasoning about Time and
Events. Springer, Dordrecht.
[11] Lee, K. (2008). Formal Semantics for Interpreting Temporal Annotation. In P.
van Sterkenburg (ed)Unity and Diversity of Languages: Special Lectures for the 18th
International Congress of Linguists. Amsterdam: Benjamins.
[12] Pinkal, M. (1999). On semantic underspecification. In Bunt, H. and Muskens, R.
(eds.) Computing Meaning, vol. 1, pages 33?56. Kluwer, Dordrecht.
[13] Pratt-Hartmann, I. (2007). From TimeML to Interval Temporal Logic. In Proc.
Seventh International Workshop on Computational Semantics (IWCS-7), pages 166?
180, Tilburg.
[14] Pustejovsky, J., Castano, J., Ingria, R., Gaizauskas, R., Katz, G., Saur??, R., and
Setzer, A. (2003). TimeML: Robust Specification of Event and Temporal Expressions
in Text. In Proc. Fifth International Workshop on Computational Semantics (IWCS-5),
pages 337?353, Tilburg.
[15] Pustejovsky, J., Knippen, R., Littman, J., and Saur??, R. (2007). Temporal and Event
Information in Natural Language Text. In Bunt, H. and Muskens, R. (eds.) Computing
Meaning, vol. 3, pages 301?346. Springer, Dordrecht.
[16] Reyle, U. (1993). Dealing with ambiguities by underspecification: construction, rep-
resentation, and deduction. Journal of Semantics, 10:123?179.
44
Proceedings of the 8th International Conference on Computational Semantics, pages 157?168,
Tilburg, January 2009. c?2009 International Conference on Computational Semantics
Towards a Multidimensional Semantics of Discourse
Markers in Spoken Dialogue
Volha Petukhova and Harry Bunt
v.petukhova@uvt.nl; harry.bunt@uvt.nl
Abstract
The literature contains a wealth of theoretical and empirical anal-
yses of discourse marker functions in human communication. Some of
these studies address the phenomenon that discourse markers are often
multifunctional in a given context, but do not study this in systematic
and formal ways. In this paper we show that the use of multiple dimen-
sions in distinguishing and annotating semantic units supports a more
accurate analysis of the meaning of discourse markers. We present an
empirically-based analysis of the semantic functions of discourse mark-
ers in dialogue. We demonstrate that the multiple functions, which a
discourse marker may have, are automatically recognizable from utter-
ance surface-features using machine-learning techniques.
1 Introduction
Discourse markers are key indicators of discourse structure, and have been
shown to be useful devices for (a) segmenting discourse into meaningful
units, and (b) identifying relations between these units. The determination
of the meanings of discourse markers is often crucial for understanding the
communicated message.
Discourse markers have been studied for their role in the organization
of discourse structure in larger texts ([12], [16]), in argumentative dialogues
([6]), in interviews ([15], [10]) and in dialogues that are highly interactive in
nature and are characterized by rapid turn switching among participants,
such as task-oriented dialogues ([9]) or meeting conversations ([14]).
The research reported in this paper regards the use of discourse mark-
ers in spoken dialogue. In dialogue, discourse markers play an important
role in establishing boundaries between dialogue units and in indicating the
communicative functions of such units (see e.g. [14], [9], [10]).
157
(1) A1: it ties you on in terms of the technologies and the complexity that you want
A2: like for example voice recognition
A3: because that you might need to power a microphone and other things
A4: so thats one constraint there
In example (1) discourse markers are used by the speaker to indicate the
steps in a sequence of arguments: he makes a statement (Inform); then he
provides an example for this statement (Inform Exemplify); he justifies his
choice (Inform Justification); and he draws a conclusion (Inform Conclude).
An important goal of studies of dialogue structure is to explore possi-
ble meanings and functions of discourse markers in dialogue as reflected in
observable utterance features (prosodic, syntactic, lexical), to enable their
successful recognition and classification.
One aspect of the meaning of discourse markers is that they may not
only have a variety of semantic functions, but that they may also have sev-
eral functions simultaneously ? their multifunctionality (see [11], [1], [15]
among others). This paper introduces a formal and systematic, empirically-
based approach to the study of the multifunctionality of discourse markers.
We show how the multifunctionality of discourse markers can be described
systematically by using a multidimensional model of the interpretation of
communicative behaviour in dialogue (Section 2). Section 3 introduces the
analysed data and features. We illustrate the multifunctionality of discourse
markers in some detail for the example of and, as one of the most frequently
used and ambiguous dialogue markers. We provide the results of statisti-
cal and machine-learning experiments on the automatic recognizability of
discourse marker meanings, and give an overview of the observed multifunc-
tionality of markers that occur in our data (Section 4). Conclusions and
perspectives for further research are outlined in the final Section 5.
2 The notion of multifunctionality
The multifunctionality of discourse markers has been described first by
Schiffrin in [15]. She distinguishes between (1) ideational structure, with
relations between propositions, e.g. a cohesion relation, a topic relation or
a functional relation; (2) action structure, which describes the organisation
and constraints on the use of speech acts; (3) exchange structure, which is
?the outcome of decision procedures by which speakers alternate sequential
roles and define those alternations in relation to each other?. Schiffrin argues
that discourse markers may simultaneously have roles within each of these
three structures, e.g. the discourse marker and may ?coordinate ideas? and
158
?continue a speaker?s action?. However, the multifunctionality of discourse
markers in this study escaped extensive and formal description.
Hovy in [11] states that each discourse marker signals either (1) a ?seman-
tic interpropositional relation?, e.g. CAUSE or PART-OF, or (2) ?interper-
sonal intentions? (a communicative purpose of an utterance), e.g. to inform
someone about a fact, or to instruct someone to do something, or (3) both.
Moreover, according to Hovy each discourse marker ?articulates a rhetorical
relation?, such as Elaboration or Presentational-Sequence. Hovy argues that
there are several parallel simultaneous structures that underlie coherent dis-
course and argues that an adequate description of discourse requires at least
four distinct structural analyses: semantic, interpersonal/goal-oriented, at-
tentional/thematic, and rhetorical.
This approach seems to apply very well to the analysis of the meaning
of discourse markers in dialogue. Discourse markers may have various com-
municative purposes (also called communicative functions) in dialogue with
respect to the underlying task or goal, attention, topic or arguments, turn
management, etc. We only want to add that discourse markers may have
various communicative functions simultaneously. For example, if the speaker
wants to provide additional or more detailed information about something
that he mentioned before, he can signal the relation between the two pieces
of information by using discourse markers such as ?and?, ?also?, ?moreover?.
The discourse marker signals an elaboration relation and the communica-
tive purpose of the whole utterance, which contains the discourse marker, is
Inform with the rhetorical function Elaborate. Additionally, the discourse
marker is used here to show that the speaker wishes to continue in the
speaker role (Turn Keep function).
In our analysis by ?multifunctionality? we mean the phenomenon of hav-
ing multiple meanings simultaneously, which are related to the multiple
purposes that an utterance may have in communication.
There are different forms of multifunctionality. Allwood in [1] claims that
if an utterance is multifunctional, ?its multifunctionality can be sequential
and simultaneous?. Bunt in [5] examines this claim using empirical data from
several dialogue annotation experiments and concludes that sequential mul-
tifunctionality disappears if we take sufficiently fine-grained dialogue units
into account (so-called ?functional segments? rather than turns). A func-
tional segment is defined as ?a smallest(possibly discontinuous) stretch of
communicative behaviour that has one or more communicative functions?
([8]). It was shown in [5] that even if we consider fine-grained units of
communicative behaviour we do not get rid of simultaneous multifunction-
ality; and the minimum number of functions that one segment may have
159
in dialogue is 1.3 on average. The number of functions grows rapidly if we
take forms of multifunctionality into account such as implicated and entailed
functions, feedback levels, and indirect functions.
It is noticed in [5] that pragmatically implicated functions, e.g. an ex-
pression of thanks also expressing positive feedback, are a true source of
multifunctionality. Logically entailed functions, such as the positive feed-
back on understanding that is entailed by answering a question or accepting
an offer, can also be important. For the purpose of this study, however,
we left such forms of multifunctionality out of consideration. This has two
reasons. First, we believe that discourse markers as such do not signal any
implicated or entailed functions. Second, since we want to operate on the
basis of observable utterance features (prosodic and linguistic) that can be
extracted automatically from raw data, to investigate how dialogue partic-
ipants express and recognise the intended and explicitly indicated multiple
functions of dialogue utterances.
In the next section we first describe the relevant aspects of the semantic
framework that we will use to study the multiple meanings of discourse
markers in dialogue in a systematic fashion.
3 Semantic framework
The semantic framework of Dynamic Interpretation Theory (DIT, [3]) takes
a multidimensional view on dialogue, in the sense that it views participa-
tion in a dialogue as being engaged in several activities simultaneously, such
as trying to advance a task that motivates the dialogue, providing commu-
nicative feedback, taking turns, and so on. Communicative behaviour is
interpreted in terms of bundles of update operations on participants? infor-
mation states (or ?contexts?); such update operations consist of a semantic
(referential, propositional, or action-related) content and a communicative
function, which specifies what an addressee is supposed to do with the se-
mantic content in order to update his information state [5]. Consider the
following dialogue fragment:
(2) A1: that?s why i think the option of the kinetic thing
A2: which basically means as long as you shake it like an automatic watch
D1: -1.78
1
but
D2: are people gonna wanna shake their movie controller?
1
Here and further in text figures given in brackets indicate the token duration in sec-
onds; figures without brackets indicate silence pauses between tokens in seconds.
160
Utterance (D1) is multifunctional, since it indicates that (1) the speaker
wants to have the turn by interrupting the previous speaker (signalled by
?but? overlapping A3); (2) the speaker interpreted and evaluated the utter-
ances A1 and A2 successfully; and (3) the speaker encountered a problem
in applying the information from the previous utterances (due to the ad-
versative meaning of ?but? ) ? he probably does not agree with the previous
claim or needs some clarification, which is indeed expressed in D2. Thus,
as the example shows, the various functions of ?but? are related to different
?dimensions? of the interaction [4], such as the allocation of the speaker role
and the processing of previous utterances.
In DIT the information which can be addressed is divided into: the do-
main or task (Task), feedback on the processing of previous utterances by
the speaker (Auto-feedback) or by other interlocutors (Allo-feedback), manag-
ing difficulties in the speaker?s utterance production (Own-Communication
Management) or that of other interlocutors (Partner Communication Man-
agement), the speaker?s need for time to continue the dialogue (Time Man-
agement), establishing and maintaining contact (Contact Management), the
allocation of the next turn (Turn Management), the way the speaker is
planning to structure the dialogue (Dialogue Structuring), and attention for
social aspects of the interaction (Social Obligations Management).
It was observed in DIT that some utterances have communicative func-
tions that can be applied to any kind of semantic content (general-purpose
(GP) functions). In particular, they can be applied not only to content
information concerning a certain task or domain, but also to information
concerning the communication, e.g. an Inform like ?First of all we need to
discuss the project finances? is used to introduce a new topic into the dis-
cussion. Dimension-specific (DS) functions, by contrast, are applicable only
to information concerned with a specific dimension of communication, e.g.
using the utterance ?Let me see? the speaker indicates that he needs some
time to do something in preparation of continuing the dialogue (Stalling
act). The phenomenon of general-purpose functions means that, when a
stretch of communicative behaviour has a GP function, its full functional
characterization requires in addition also the specification of the dimension
that is addressed, so we get characterizations like Feedback Question and
Task Suggestion.
We found that discourse markers are used (i) as ?preface? of a range of GP
functions, in particular Informs of various rhetorical kinds; (ii) as indicators
of dialogue acts with a DS function, e.g. of topic shifts; and (iii) as full-
blown dialogue acts (without explicit semantic content), e.g. as a Turn Take
act. This means that discourse markers can have two kinds of meanings:
161
as a dialogue act, i.e. as a context update operator, and as an element
that contributes to the determination of the communicative function of a
dialogue act with either a GP- or a DS-function.
The DIT framework supports a ?multidimensional? semantics by relating
context update operators to different compartments of structured context
models which include, besides information states of the usual kind (beliefs
and goals related to a task domain), also a dialogue history, information
about the agent?s processing state, beliefs about dialogue partners? process-
ing states, information and goals concerning the allocation of turns, and so
on, relating to the various ?dimensions? that dialogue acts belong to. The
interpretation of a multifunctional stretch of communicative behaviour cor-
responds to updating the context models of the communicating agents in
multiple ways, combining the effects of each of the component functions.
For example:
(3) B1: what anybody wants to add about what they don?t like about remote controls
A1:0.48 and you keep losing them
Since it answers B?s Set-Question B1, utterance A1, which includes the
discourse marker and, updates the context model of participant B with the
information that
2
: (1) A believes that B wants to know which elements of a
given set have a given property ; (2) A believes that B believes that A knows
which elements of that set have that property ; (3) A believes to know which
elements of that set have that property ; and (4) A believes that B made the
turn available. Thus, the simultaneous performance of the turn management
and feedback acts through the use of A1, in particular of and, constitutes
the multidimensional interpretation of what A says.
4 Data analysis and classification experiments
4.1 Corpus data and automatically extracted features
For the empirical semantic analysis of discourse markers we selected three
meetings from the AMI meeting corpus.
3
Our data contain 17,335 words
which form 3,897 functional segments with an average length of 4.4 words.
Average turn length is 7.7 segments.
All the features that we used were low-level features, automatically ex-
tracted both from the transcriptions and from sound files. In this respect
our analysis differs from those where manually labelled intonational informa-
tion is used such as tones and pitch accents ([10]), or automatically derived
2
For a formal representation of updates in participants? information state see [13].
3
A
?
ugmented M
?
ulti-party I
?
nteraction (http://www.amiproject.org/).
162
syntactic information ([14], [16]) such as parts-of-speech. Our aim was to
discover how well a classifier can perform if no other external knowledge
sources are available and only the output of the speech recogniser is acces-
sible. The features relate to prosody, word occurrence, and collocations.
Prosodic features were minimum, maximum, mean, and standard devia-
tion of pitch (F0 in Hz), energy (RMS), voicing (fraction of locally unvoiced
frames and number of voice breaks), speaking rate (number of syllables per
second) and segment duration.
4
Word occurrence is represented by a bag-
of-words vector
5
indicating the presence or absence of words in the segment.
As lexical features bi- and trigram models were constructed.
4.2 Dialogue act tagset and notes on segmentation
The training data was manually annotated using the DIT
++
annotation
scheme.
6
The DIT
++
taxonomy is multilayered and multidimensional, with
a conceptually well-defined set of communicative functions, supporting dia-
logue act annotation in multiple dimensions simultaneously.
The utterances were segmented per dimension following the approach in
[8], which leads to a more accurate analysis of human communication than
the segmentation of dialogue in single sequences of utterances, since utter-
ances may contain functional ?holes? due to protractions, repairs, restarts,
etcetera. Moreover, participants may interrupt each other and talk simul-
taneously, and utterances may also spread over several turns. A meaningful
unit in this approach is a functional segment as defined in Section 3. An
example of per-dimension segmentation is given in Figure (1).
4.3 Results: multifunctionality of discourse markers
We do not aim in this paper to discuss all discourse markers which occur in
our corpus data, we rather demonstrate the minimal multifunctionality of
the most frequently used discourse markers in dialogue and discuss the case
of and in more detail.
Table 1 lists some discourse markers (DMs) identified in the studied cor-
pus with their absolute frequency in the corpus, gives an overview of their
4
We examined both raw and normalized versions of these features. Speaker-normalized
features were normalized by computing z-scores (z = (X- mean)/standard deviation),
where mean and standard deviation were calculated from all functional segments produced
by the same speaker in the dialogues. We also used normalizations by the first and prior
speaker turn.
5
With a size of 1,640 entries.
6
For more information about the tagset and the dimensions that are distinguished,
please visit: http://dit.uvt.nl/
163
Figure 1: Example of per-dimension segmentation.
observed mutlifunctionality by indicating the average number of commu-
nicative functions in our dialogues, and lists the observed communicative
functions. Note that all DMs serve more than one communicative func-
Table 1: Distribution and observed multifunctionality of discourse markers.
tion. And is the most multifunctional discourse marker in our corpus and
because the least multifunctional one. Because mostly prefaces Informs with
the rhetorical functions Justify or Explain, and only in 2.4% of all cases is
used to simultaneously perform Turn Keeping and Stalling acts. All dis-
course markers, except ?you know?, preface GP functions in Task or other
dimensions (often in Discourse Structuring and Feedback) and may perform
164
dialogue acts addressing other dimensions simultaneously, as we will illus-
trate for and below. This pattern is observed for 50.7% of all studied DMs.
A discourse marker may also perform full-fledged dialogue acts addressing
more than one dimension simultaneously (as in example 2). This is often the
case for Turn Management in combination with Feedback, Time Manage-
ment, Discourse Structuring and Own Communication Management (27.7%
of all discourse markers are observed to be used in this way). It was noticed
that at most 3 dialogue acts are performed by one discourse marker in a
given context, e.g. feedback, turn and time management acts. A third pat-
tern of DM use, which was observed in 18.2% of cases, is as a single dialogue
act, e.g. a turn taking act or a feedback act. In the rest (3.4%) discourse
markers are part of general purpose functions and do not perform a dialogue
act on their own.
And is one of the most frequently used discourse markers in our cor-
pus. The corpus contained 470 occurrences of and, where about 54.5% is
not used as a discourse marker and the rest of 45.5% as discourse marker.
Differentiating between and as non-DM and DM is important for segmenta-
tion purposes. Used in clause-initial position or as an autonomous segment,
and as DM so to speak brackets segments and helps define their boundaries.
We investigated the prosodic and durational differences, and differences in
surrounding material between the two basic uses of and, and performed
machine-learning recognition experiments.
Experiments using the RIPPER rule inducer [7] showed that the two uses
of and are well recognized automatically. An accuracy score of 80.6% was
obtained on unsegmented data. Baseline score, in this case the percentage
of the most frequent class (non-DMs), was 54.5%. There are significant
mean differences (p < .05) for both raw and speaker-normalized features in
terms of duration (DMs are almost twice as long as non-DMs: 289-327ms
and 173-217ms respectively); initial pause (there is no or a negligible small
pause before non-DMs, and initial pauses before DMs range between 59 and
228ms); mean pitch (and as DM has higher mean pitch: > 12Hz). Preceding
and following tokens as features also have high information gain. And as
DM is often so to speak backed up between um, uh, so, then and also.
As a discourse marker, and may have various and multiple communica-
tive functions (see Table 1). And may signal that the upcoming speech is
adding new information or used in explanatory sequences [15], like Inform
Explain in (4):
(4) A1: like you said a problem was how many components are in there
A2: um (0.4)
A3: 0.28 and (0.12) the power is basically a factor of that
165
A4: 0.55 um (0.47) and (0.32) this affects you in terms of the size of your device
A5: 0.59 um (0.26) and (0.16) that would have some impact
And can also mark the transition from one discussion topic to another
by introducing topic shifts, for example:
(5) A1: you could group plastic and rubber, but it might be easier to use one
D1: -0.29 mm-hmm
A2: 0.74 um (0.32)and (0.2) the other components are logic chips
Table 2: Overview of accuracy on the base-
line (BL) and the classifier on the prediction
of communicative functions of ?and? in differ-
ent dimensions obtained using 10-fold cross-
validation experiments. ? significant at p <
.05, one-tailed z-test.
In 57% of all cases and is used
as a marker of speaker contin-
uation (turn keeping) as illus-
trated in A3, A4 and A5 in (4).
And in A2 in (5) also has a pos-
itive allo-feedback function re-
lated to the utterance D1.
We trained the RIPPER rule in-
ducer to automatically classify
the communicative functions of
and in several dimensions. The
results are shown in Table 2.
The classifier outperforms the
baseline, which for all tasks is
the percentage of the majority
class (e.g. Elaboration in Task),
except for the classification of Discourse Structuring and Partner Commu-
nication Management functions, for which there were not enough instances
in the training set.
As for features, for the prediction of the Task dimension, the bag-of-
words feature representing word occurrence in the segment and word col-
location features were important. For example, Inform Elaborate is often
signalled by focusing adverbs like especially, mainly, additionally, etc, or
contains relative pronouns like who, whose, which and that. The pres-
ence of some expressions of comparision was noted in Exemplifications,
such as one of, rather than, like,comparing, by contrast, similar, etc. The
most frequent words that occurred in Suggestions were maybe, might, bet-
ter, should, could/can, probably and let?s; and Discourse Structuring func-
tions are marked by next, then, other and further. For all other dimensions
prosodic features were more important than the surrounding lexical mate-
rial. For example, for Turn Management functions duration, initial pause
166
and mean pitch are key features. Important is also the information about
the current and the previous speaker. Speaker switch is an important sign
of and in the Auto-Feedback dimension. Stallings were characterized by a
long duration (about 585ms) and long initial pause (365ms), and a pause
after (100ms). They also often were preceded and followed by um and uh.
5 Conclusions and future work
To summarize we can conclude that discourse markers are truly multifunc-
tional dialogue units. The analysis of discourse markers as important instru-
ments for the understanding of dialogue and its computational modelling can
only benefit from a multidimensional approach to the exploration of their
complex meaning.
We showed that discourse markers may simultaneously serve several com-
municative functions in different dimensions. They are good indicators of
(plentiful) general-purpose communicative functions, such as informs, elab-
orations of various kinds, suggestions, warnings, disagreements, etc., mostly
in relation to the task that underlies the dialogue, but they are also fre-
quently used to create or maintain the conditions for successful interaction
(indicating dialogue control acts). Our investigations showed that discourse
markers may have communicative functions in all the dimensions distin-
guished in DIT, except perhaps in Social Obligations Management. We
noted the importance of discourse markers for segmenting dialogue into
meaningful units, since they so to speak bracket functional segments. Binary
automatic classification of DM vs non-DM was successfully performed. The
automatic recognition of the various and multiple communicative functions
of discourse markers is even more important. Our automatic classification
experiments showed that machine learning techniques can be profitably used
in the automatic recognition of multiple meanings of dialogue markers.
For future work, we intend to extend the studies reported here in two
directions. First, we plan to collect more annotated data containing a richer
set of discourse markers and sufficient numbers of instances per class, so
that we may increase the accuracy of the classifier for further evaluation
of our model on unmarked examples (see [16]). Furthermore, since AMI
meetings are face-to-face interactions and video recordings are available, we
plan to consider other modalities besides speech audio, e.g. hand and head
gestures, for better understanding of discourse markers functions in support
of adequate computational dialogue modelling.
167
Acknowledgments
This research was conducted within the project ?Multidimensional Dialogue
Modelling?, sponsored by the Netherlands Organisation for Scientific Re-
search (NWO), under grant reference 017.003.090.
References
[1] Allwood, J. (1992). On dialogue cohesion. Gothenburg Papers in Theoretical Lin-
guistics 65. Gothenburg University, Department of Linguistics.
[2] Allwood, J. (2000). An activity-based approach to pragmatics. H. Bunt and W. Black
(eds.) Abduction, Belief and Context in Dialogue, Amsterdam: Benjamin, pp.47-81.
[3] Bunt, H. (2000). Dynamic Interpretation and Dialogue Theory. M.M. Taylor, D.G.
Bouwhuis and F. Neel (eds.) The Structure of Multimodal Dialogue, Vol 2., Ams-
terdam: John Benjamins, pp. 139?166.
[4] Bunt, H. (2006). Dimensions in Dialogue Act Annotation. Proceedings LREC 2006,
Genova.
[5] Bunt, H. (2007). Multifunctionality and Multidimensional Dialogue Act Annotation.
E. Ahlsen et al (ed.) Communication - Action - Meaning. Gothenburg, pp. 237 ?
259.
[6] Cohen, R. (1984). A computational theory of the function of clue words in argument
understanding. Coling-ACL 1984, Standford, pp. 251?258.
[7] Cohen, W.W. (1995). Fast effective rule induction. In Proceedings of the 12th Inter-
national Conference on Machine Learning (ICML?95), pp. 115?123.
[8] Geertzen, J. Petukhova, V. and Harry Bunt. (2007). A Multidimensional Approach
to Utterance Segmentation and Dialogue Act Classification. Proceedings of the 8th
SIGdial Workshop on Discourse and Dialogue, Antwerp, pp. 140?149.
[9] Heeman, P.A. and Allen, J.F. (1999). Speech repairs, intonational phrases and dis-
course markers: Modelling speakers utterances in spoken dialogue. Computational
Linguistics, 12(3): 1?45.
[10] Hirschberg, J. and Litman, D. (1993). Empirical studies on the disambiguqtion of
cue phrases. Computational Linguistics, 25(4): 501?530.
[11] Hovy, E.H. (1995). The multifunctionality of discourse markers. Proceedings of the
Workshop on Discourse Markers, Egmond-aan-Zee, The Nertherlands.
[12] Mann, W. and Thompson, S. (1988). Rhetorical structure theory: toward a functional
theory of text organisation. The MIT Press, Cambridge, MA.
[13] Morante, R. (2007). Computing Meaning in Interaction. PhD Thesis, Tilburg Uni-
versity.
[14] Popescu-Belis, A. and Zufferey, S. (2006). Automatic identification of discourse
markers in multiparty dialogues. Working paper 65, ISSCO, University of Geneva.
[15] Schiffrin, D. (1987). Discourse Markers. Cambridge: University Press.
[16] Sporleder, C. and Lascarides, A. (2008). Using Automatically Labelled Examples to
Classify Rhetorical Relations: An Assessment. Natural Language Engineering, 14.03:
369?416.
168
Proceedings of the 8th International Conference on Computational Semantics, pages 268?271,
Tilburg, January 2009. c?2009 International Conference on Computational Semantics
A note on the definition of semantic annotation
languages
Harry Bunt and Chwhynny Overbeeke
harry.bunt@uvt.nl, info@chwhynny.com
1 Introduction
In the last few years, the international organization for standards ISO has
started up various projects concerned with the definition of interoperable
concepts for syntactic, morphosyntactic, and semantic annotation, with
the ultimate aim to support the development of interoperable language re-
sources. The Linguistic Annotation Framework (LAF, Ide & Romary, 2004)
thereby serves as a meta-framework. LAF distinguishes between the con-
cepts of annotation and representation: ?annotation? refers to the process
of adding information to segments of language data, or to that information
itself, independent of the format in which this information is represented.
The term ?representation? refers to the format in which an annotation is ren-
dered, for instance in XML. According to LAF, annotations are the proper
level of standardization.
This distinction is reflected in the specification of ISO-TimeML, a pro-
posed ISO standard for temporal annotation (ISO, 2008) which consists of
an abstract syntax, a concrete syntax, and a semantics. The abstract syntax
specifies the elements making up the information in annotations, and how
these elements may be combined to form complex annotation structures;
these combinations are defined as set-theoretical structures. The concrete
syntax is a variant of the TimeML markup language (Pustejovsky et al,
2003). Any other representation that is a rendering of the abstract syntax
can be converted into this representation. The ISO-TimeML semantics is
associated with its abstract syntax, which explains why all concrete repre-
sentations of ISO-TimeML annotations are semantically equivalent.
In this note we argue that the distinction of an abstract and a concrete
syntax level is desirable not only from a standardization point of view, but
also for designing annotation languages with a representation that is con-
ceptually transparent for annotators and that allows a simple, systematic
268
interpretation. We illustrate this for the annotation and interpretation of
expressions denoting dates, times, and durations.
1.1 ISO-TimeML
The abstract syntax of ISO-TimeML consists of two parts: (a) a ?conceptual
inventory?, specifying the elements from which annotations are built up; and
(b) a set of syntax rules which describe the possible combinations of these
elements.
a. Conceptual inventory The concepts that can be used to build ISO-
TimeML annotations fall into the following five categories, all formed by
finite sets, plus the concepts of real and natural numbers.
? finite sets of elements called ?event classes?; ?tenses?, ?aspects?, ?polarities?,
and ?set-theoretic types? ;
? finite sets of elements called ?temporal relations?,?duration relations?, ?numer-
ical relations, ?event subordination relations?, and ?aspectual relations?;
? a finite set of elements called ?time zones?;
? finite sets of elements called ?calendar years?, ?calendar months?, ?calendar
day numbers?; ?clock times?;
? a finite set of elements called ?temporal units?.
b. Syntax rules Annotation structures in ISO-TimeML come in two va-
rieties, entity structures and link structures. Entity structures contain se-
mantic information about a segment of source text; link structures describe
semantic relations between segments of source text.
The simplest kind of ISO-TimeML structures are a single entity struc-
ture, which is a pair < m,a > consisting of a markable
1
m and an annotation
a, or a single link structure < e
1
, e
2
, R > which relates two entity structures.
More complex annotation structures consist of a set of entity structures and
a set of link structures which link the entity structures together.
Entity structures come in 6 types, containing information about (1) events;
(2) temporal intervals; (3) time points (or ?instants?); (4) amounts of time;
(5) frequencies of events; and (6) temporal relations. We focus here on the
tree types of temporal concepts: intervals, instants, and amounts of time.
1. An instant structure is either a triple < time zone, date, clocktime >, where
a date is a triple consisting of a calendar year, a calendar month, and a cal-
endar day number; or a triple < time-amount structure, instant structure,
temporal relation> (?an hour before midnight?).
1
The term markable is used to refer to the entities that the annotations are associated
with. There are two kinds of markables in ISO-TimeML: event markables and time mark-
ables, corresponding to segments of primary data that describe events, and to those that
describe temporal entities or relations, respectively.
269
2. An interval structure is either:
(a) a pair < t
1
, t
2
> of two instant structures (beginning and end);
(b) a calendar year, a pair consisting of a calendar year and a calendar
month, or a triple < cal.year, cal.month, cal.daynumber >;
(c) a triple < time-amount structure, interval structure, temporal
relation > (?three weeks before Christmas?);
(d) a triple < t
1
, t
2
, R > where t
1
and t
2
are either instant or interval
structures, and where R is a duration relation (?from ?92 until ?95?).
3. A time-amount structure is a pair < n, u >, where n is a real number and u
a temporal unit, or a triple < R,n, u >, where R is a numerical relation (like
greater than) and n and u as before;
Link structures specify the temporal anchoring of events in time; the tempo-
ral ordering of events, intervals or instants; the length of an interval; subor-
dination relations between events; and aspectual relations between events.
The semantics associated with this abstract syntax defines a mapping
from the set-theoretical structures defined by the abstact syntax to the lan-
guage of first-order predicate logic with lambda abstraction.
A concrete syntax in general consists of the specification of names for
the various sets that make up the conceptual vocabulary, plus a listing of
specific named elements of these sets, and for each rule of the abstract
syntax a specification of how to represent the constructed annotation struc-
ture. The TimeML-based concrete syntax that is part of the ISO-TimeML
specification makes use of a TIMEX3 tag to mark up explicit temporal ex-
pressions like dates, times and durations. Using this tag, the different types
of temporal expressions are represented by means of the attribute type. An
attribute called value has alphanumerical string values that follow a stan-
dard format to represent (combinations of) calendar days, weeks, months
and years (2007-03-16); clock hours, minutes and seconds; (T13:15:00), as
well as amounts of time (P60D) and frequencies. This representation does
not have a transparent relation to the conceptual distinctions made in the
abstract syntax.
A more transparent representation can be obtained by defining a con-
crete syntax where the categories (sets) of the conceptual inventory corre-
spond to XML tags, and elements in these sets to attribute values. This
gives annotation representations that wear there meaning on their sleeve,
which is optimal both for human annotators and for computing the formal
interpretation of the annotations. The following examples illustrate this,
where we show, for three types of temporal expressions, (a) the conceptual
annotation structure; (b) the TimeML-based representation; (c) an XML
representation that directly instantiates the conceptual structure; (d) the
270
formal interpretation.
2
In all cases, the representations (c) are intuitively
more transparent than the (b) ones, and have a more straightforward rela-
tion to the interpretations (d).
(1) March 2007 [m
1
= w
1
w
2
, w
1
=?March?, w
2
=?2007?]
a. < m
1
, <interval, <2007, march>>
b. <TIMEX3 id="t1" type="DATE" value="207-03-XX"?>
c. <INTERVAL id="t1" calYear="2007" calMonth="MARCH">
d. ?t.INTERVAL(t) ? Calyear(t)=2007 ? Calmonth(t)=march
(2) Twelve-thirty tomorrow
[m
1
= w
1
w
2
, w
1
=?Twelve-thirty?, w
2
=?tomorrow? ]
a. < m
1
, <instant, <2009, january, 8>,1230>>
b.<TIMEX3 id="t1" type="TIME" value="T12:30">
c. <TIME id="t1" calYear="2009" calMonth="JANUARY" calDayNum="8"
clockTime="1230" >
d. ?t.TIME(t) ? Calyear(t)=2009?Calmonth(t)=january ? Caldaynum(t)=8
? Clocktime(t)=1230
(3) two-and-a-half minutes [m
1
= w
1
w
2
, w
1
=?Two-and-a-half?,w
2
=?minutes?]
a. < m
1
, <time-amount, <2.5, minute>>
b. <TIMEX3 id="t1" type="DURATION" value="P2.5M">
c. <TIMEAMOUNT id="a1" num="2.5" unit="minute">
d. ?x.TIME-AMOUNT(x) ? Number(x)=2.5 ? Unit(x)=minute
References
[1] Bunt, H.C, Overbeeke, C. (2008) An Extensible Compositional Semantics for
Temporal Annotation. In: Proceedings of LAW II, the Second Workshop on Lin-
guistic Annotation, Satellite workshop at LREC 2008. Paris: ELRA.
[2] Bunt, H.C., Romary, L. (2002) Requirements on multimodal semantic repre-
sentations. In Proceedings of ISO TC37/SC4 Preliminary Meeting, Seoul, 59-68.
[3] Ide, N., Romary, L. (2004) International Standard for a Linguistic Anootation
Framework. Natural language Engineering, 10: 211-225.
[4] ISO (2008) ISO Draft International Standard 24617-1 ?Semantic annotation
framework Part 1: Time and events?. Geneva: ISO.
[5] Pustejovsky, J., Castano, J., Ingria, R., Gaizauskas, R., Katz, G., Sauri, R.,
Setzer, A. (2003) TimeML: Robust Specification of Event and Temporal Expres-
sions in Text. In Proceedings IWCS-5, Tilburg, pp. 337-353
2
Depending on the semantic interpretation framework in which this interpretation is
embedded, the semantic representations may be slightly different; e.g. Bunt & Over-
beeke (2008) assign to the first example the representation ?P.?t.INTERVAL(t) ? Ca-
lyear(t)=2007 ? Calmonth(t)=march ? P(t).
271
A New Life for Semantic
Annotations?
Harry Bunt
Tilburg University (The Netherlands)
email: harry.bunt@uvt.nl
Semantic annotation has so far been approached in essentially the same way as
annotation at other levels of linguistic information, namely as the business of labeling
text with certain tags which add certain information to the text, in this case, semantic
information. Semantic role labeling is a case in point. This may be very useful,
for instance for determining the variety of ways in which certain types of semantic
information tend to be expressed, but it seems to me that semantic annotations can
and should have a deeper significance and a more important role to play.
Since semantic annotations are intended to capture some of the meaning of the an-
notated text, it ought to be possible to use such annotations in reasoning, and hence to
apply that information in language processing tasks. However, reasoning with seman-
tic annotations presupposes that the annotation language has a formal semantics. (In
fact, one may wonder how much sense it makes to use a semantic annotation language
without a semantics, since there is a priori little reason to assume that semantically
undefined annotations would capture the meanings of natural language expressions
any better than the expressions themselves.)
1
2 Bunt
Still, existing work in this area, for instance on semantic role annotation (as in the
FrameNet and PropBank initiatives) or on the annotation of temporal information (as
in the TimeML effort) makes use of uninterpreted annotation languages.
In this talk, I will discuss some of the possibilities, perspectives, and problems in
defining semantic annotation languages with a well-defined semantics. I will do this
by starting from an attempt to integrate intermediate results from the design of a stan-
dard for temporal annotation in the International Organisation for Standards (ISO),
and from the definition of annotation schemas for coreference annotation and seman-
tic role labeling in the European project LIRICS. I will indicate the requirements for
integrated and multilayered semantic annotation approaches, and certain general prin-
ciples for semantic annotation. Moreover, I hope to address issues concerning the re-
lations between using semantic annotations with a formal semantics on the one hand,
and using underspecified semantic representations on the other. Finally, I will consider
some of the potential applications of the use of interpreted semantic annotations in ar-
eas such as information extraction, paraphrase generation, and textual entailment.
Proceedings of the Fourth Linguistic Annotation Workshop, ACL 2010, pages 247?255,
Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational Linguistics
Anatomy of Annotation Schemes:
Mapping to GrAF
Nancy Ide
Department of Computer Science
Vassar College
Poughkeepsie, NY, USA
ide@cs.vassar.edu
Harry Bunt
Tilburg Center for Creative Computing
Tilburg University, The Netherlands
harry.bunt@uvt.nl
Abstract
In this paper, we apply the annota-
tion scheme design methodology defined
in (Bunt, 2010) and demonstrate its use
for generating a mapping from an exist-
ing annotation scheme to a representa-
tion in GrAF format. The most impor-
tant features of this methodology are (1)
the distinction of the abstract and con-
crete syntax of an annotation language;
(2) the specification of a formal seman-
tics for the abstract syntax; and (3) the
formalization of the relation between ab-
stract and concrete syntax, which guar-
antees that any concrete syntax inherits
the semantics of the abstract syntax, and
thus guarantees meaning-preserving map-
pings between representation formats. By
way of illustration, we apply this map-
ping strategy to annotations from ISO-
TimeML, PropBank, and FrameNet.
1 Introduction
The Linguistic Annotation Framework (LAF, (Ide
and Romary, 2004); ISO 24612, 2009) defines
an abstract model for annotations together with
an XML serialization of the model, the Graph
Annotation Format (GrAF, (Ide and Suderman,
2007)). GrAF is intended to be a pivot format ca-
pable of representing diverse annotation types of
varying complexity, guaranteeing syntactic con-
sistency among the different annotations. GrAF
does not address the issue of semantic consis-
tency among annotation labels and categories; this
is assumed to be handled by other standardiza-
tion efforts such as ISOCat (Kemps-Snijders et al,
2009). ISOCat provides a set of data categories at
various levels of granularity, each accompanied by
a precise definition of its linguistic meaning. La-
bels applied in a user-defined annotation scheme
should be mapped to these categories in order to
ensure semantic consistency among annotations of
the same phenomenon.
While the mapping of annotation labels to a
common definition, coupled with the syntactic
consistency guaranteed by GrAF, takes a giant
step towards the harmonization of linguistic an-
notations, this is still not enough to ensure that
these annotations are sufficiently compatible to en-
able merging, comparison, and manipulation with
common software. For this, the conceptual struc-
ture of the annotation, in terms of the structural
relations among the defined annotation categories,
must also be consistent. It is therefore necessary to
consider this aspect of annotation scheme design
in order to achieve a comprehensive treatment of
the requirements for full harmonization of linguis-
tic annotations.
In (Bunt, 2010), a design methodology for se-
mantic annotation schemes is proposed, devel-
oped during the ISO project ?Semantic annota-
tion framework, Part 1: Time and events? (?Se-
mAF/Time?, for short), which is currently near-
ing completion (see ISO DIS 24617-1, 2009). The
methodology includes a syntax that specifies both
a class of representation structures and a class
of more abstract annotation structures. These
two components of the language specification are
called its concrete and abstract syntax, respec-
tively. A distinguishing feature of the proposed
methodology is that the semantics is defined for
the structures of the abstract syntax, rather than
for the expressions that represent these structures.
In this paper, we generalize the design method-
ology defined in (Bunt, 2010) and demonstrate
its use for generating a mapping from an ex-
isting annotation scheme to a representation in
GrAF format. By way of illustration, we apply
the mapping strategy to annotations from ISO-
TimeML (ISO, 2009), PropBank (Palmer et al,
2005), and FrameNet (Baker et al, 1998).
247
2 Background
The process of corpus annotation may consist of
attaching simple labels to textual elements, such
as part of speech and syntactic designations and
named entity tags. For more complex types of
annotation, annotations include a variety of ad-
ditional information about linguistic features and
relations. This is especially true for the kinds
of semantic annotation that have recently begun
to be undertaken in earnest, including semantic
role labeling (e.g., FrameNet and PropBank) and
time and event annotation (e.g., TimeML). How-
ever, these annotation schemes are not always de-
signed based on formal principles, and as a result,
comparing or merging information?even from two
schemes annotating the same phenomenon?can be
difficult or impossible without substantial human
effort.
A major source of difficulties in interpreting an-
notation scheme content is that information in the
annotation is implicit rather than explicit, making
(especially) structural relations among parts of the
linguistic information ambiguous. This often re-
sults from the use of an impoverished representa-
tion scheme, which provides only minimal mech-
anisms for bracketing and association. Consider,
for example, the two annotation fragments below,
expressed with parenthetic bracketing, taken from
a computational lexicon:
(1) (SUBC ((NP-TO-INF-LOC) (NP-PP)))
(2) (FEATURES ((NHUMAN) (COUNTABLE)))
In (1), the bracketed information is a list of alter-
natives, whereas in (2), it is a set of properties, but
there is no way to automatically distinguish the
two in order to process them differently. Another
example comes from PropBank:
wsj/00/wsj_0003.mrg 13 6 gold have.03
vn--a 0:2-ARG0 6:0-rel 7:1-ARG1
10:1-ARGM-ADV
Because of the ?flat? representation1, it is im-
possible to automatically determine if the mor-
phosyntactic descriptor ?vn?a? is associated with
the element annotated as ?rel?, vs. the ?gold?
descriptor that is (assumedly) associated with the
entire proposition. In both of these examples,
linguistically-informed humans have little diffi-
culty determining the structure because of the
knowledge they bring to the interpretation. This
knowledge is then embedded in the processing
1In PropBank annotation, this information appears on a
single line.
software so that the data are processed properly;
however, because it is not a part of the represen-
tation itself, it is not available to others who may
develop software for other kinds of processing.
To avoid these problems, annotation scheme de-
sign in ISO projects is split into two phases: the
specification of (1) an abstract model consisting
of annotation categories and structures and (2)
specification of (possibly multiple) representation
structures. An abstract model of annotation struc-
tures is typically implemented via development of
a ?metamodel?, i.e. a listing of the categories
of entities and relations to be considered, often
visualized by a UML-like diagram?i.e., a graph.
Schemes described via this method are trivially
mappable to GrAF, ensuring that syntactic con-
sistency among the different schemes, whatever
their original representation structures may be, is
achievable. It also ensures that these schemes are
trivially mappable to different representation for-
mats that are used in various software systems,
e.g., GATE, UIMA, NLTK, GraphViz, etc.
3 Anatomy of an annotation scheme
As specified in (Bunt, 2010), an annotation
scheme consists of a syntax that specifies a class of
more abstract annotation structures (the abstract
syntax) and a class of representation structures (the
concrete syntax), plus a semantics associated with
the abstract syntax.
3.1 Abstract syntax
The abstract syntax of an annotation scheme de-
fines the set-theoretical structures which constitute
the information that may be contained in annota-
tions. It consists of (a) a specification of the el-
ements from which these structures are built up,
called a conceptual inventory; and (b) annota-
tion construction rules, which describe the possi-
ble combinations of these elements into annota-
tion structures. The semantics of the annotation
scheme components is defined for the annotation
structures of the abstract syntax; Bunt (2010) pro-
vides a formal specification of the semantics of
ISO-TimeML in terms of Discourse Representa-
tion Structures (Kamp and Reyle, 1993), and de-
fines the class of concrete representations of the
structures defined by the abstract syntax.
For example, a fragment of the ISO-TimeML2
2All references to ISO-TimeML are based on the state
of the project as documented in ISO 264617-1:2009(E) from
248
conceptual inventory includes:3
? finite sets of elements called event types,
tenses, aspects, signatures, cardinalities, and
veracities.
? finite sets of elements called temporal rela-
tions, duration relations, event subordination
relations, aspectual relations, etc.
The annotation construction rules for ISO-
TimeML specify how to construct two types
of annotation structures: entity structures and
link structures. One type of entity structure,
called an event structure, is defined as a 6-tuple
?e, t, a, s, k, v? where e is a member of the set of
event types; t and a are a tense and an aspect,
respectively; s is a signature (a set-theoretical
type that is used for handling quantification over
events); k is a cardinality, used for expressing in-
formation about the size of a set of events in-
volved in a quantified relation; and v is a verac-
ity, which is used to represent whether an event is
claimed to have occurred, or claimed not to have
occurred (for dealing with positive and negative
polarity, respectively), or to have yet another sta-
tus such as ?possibly? or ?requested?, for handling
such cases as Please come back later today. A
time-amount structure is a pair ?n, u? or a triple
?R,n, u?, where n is a real number, R a numerical
relation, and u a temporal unit. The rules also de-
fine a link structure called an event duration struc-
ture as a triple ?event structure, time-amount
structure, duration relation?.
3.2 Concrete syntax
The concrete syntax provides the representation of
annotation structures defined in the abstract syn-
tax. A concrete syntax is said to be ideal for
a given abstract syntax if there is a one-to-one
correspondence between the structures defined by
the abstract syntax and those defined by the con-
crete syntax. An ideal concrete syntax RF1 de-
fines a function F1 from annotation structures to
RFi-representations, and an inverse function F
?1
i
from RF1-representations to annotation structures.
In other words, the abstract and the concrete syn-
tax are isomorphic. Since this holds for any ideal
concrete syntax, it follows that any two ideal rep-
resentation formats are isomorphic. Given two
September 2009.
3See (Bunt, 2010) for the full specification for ISO-
TimeML.
<isoTimeML-ICS1rep xml:id="a1">
<EVENT xml:id="e1" anchor="t2"
type ="FAST" tense=PAST
signature="INDIVIDUAL"/>
<TIME-AMOUNT xml:id="ta1"
anchor="t4" numeral="2" unit="day"/>
<MLINK event="e1"
duration="ta1" relType="FOR"/>
</isoTimeML-ICS1rep>
Tokens: [It1][fastedt2][fort3][twot4][dayst5].
Figure 1: ISO-TimeML ICS1 annotation
ideal representation formats RFi and RFj we can
define a homomorphic mapping Cij from RFi-
representations to RFj-representations by
(1) Cij =D Fj ? F?1i , i.e. Cij(r) = Fj(F
?1
i (r))
for any RFi-representation r
and conversely, we can define a homomorphic
mapping Cji from RFj-representations to RFi-
representations by
(2) Cji =D Fi ? F?1j , i.e. Cji(r) = Fi(F
?1
j (r))
for any RFj-representation r
These two mappings constitute conversions from
one format to the other, that is, they constitute
one-to-one meaning-preserving mappings: if ?(r)
denotes the meaning of representation r, then
?(Cij(r)) = ?(r) for any Fi-representation r,
and conversely, ?(Cji(r?)) = ?(r?) for any Fj-
representation r?.
Figure 1 shows a rendering of the sentence I
fasted for two days using a concrete XML-based
syntax for the annotation structures defined by
the ISO-TimeML abstract syntax, called the ICS-1
format, as described in (Bunt, 2010).
4 GrAF overview
GrAF is an exchange or pivot format intended to
simplify the processes of merging of annotations
from different sources and using annotations with
different software systems. The underlying data
model is a directed acyclic graph, which is iso-
morphic to UML-like structures that may be used
to define an abstract syntax for a given annotation
scheme, as described in section 3.
GrAF is an XML serialization of a formal graph
consisting of nodes and edges, either or both
of which are decorated with feature structures.
Nodes may have edges to one or more other nodes
249
<node xml:id="fn-n1"/>
<a label="FE" ref="fn-n1" as="FrameNet">
<fs>
<f name="FE" value="Recipient"/>
<f name="GF" value="Obj"/>
<f name="PT" value="NP"/>
</fs>
</a>
<edge id="e1" from="fn-n1"
to="fntok-n5"/>
Figure 2: FrameNet frame element annotation in
GrAF
in the graph, or they may be linked directly to re-
gions within the primary data that is being anno-
tated. The feature structure attached to a node or
edge provides the content of the annotation?that
is, the associated linguistic information expressed
as a set of attribute-value pairs. The feature struc-
tures in GrAF conform to formal feature struc-
ture specifications and may be subjected to op-
erations defined over feature structures, including
subsumption and unification. As a result, any rep-
resentation of an annotation in GrAF must consist
of a feature structure that provides all of the rele-
vant linguistic information.
Figure 2 shows a fragment of a FrameNet frame
element annotation, serialized in GrAF XML. It
consists of a graph node with id ?fn-n1? and an an-
notation with the label ?FE?4. The ref attribute on
the <a> (annotation) element associates the anno-
tation with node ?fn-n1?. The annotation contains
a feature structure with three features: FE (Frame
element), GF (Grammatical Function), and PT
(Phrase Type). An edge connects the node to an-
other node in the graph with the id ?fntok-n5? (not
shown here), which is associated with annotation
information for a token that in turn references the
span of text in primary data being annotated.
5 Mapping to GrAF
LAF specifies that an annotation representation R
is valid if it is mappable to a meaning-preserving
representation in GrAF, and that its GrAF repre-
sentation is in turn mappable to R. In terms of
the definitions in section 3, a LAF-valid repre-
sentation R is one where ?(R) = ?(CRG(R))
and ?(G) = ?(CGR(G)), where G is a GrAF
4Note that the value of the label attribute is, for practical
purposes, a convenience; it is used primarily when generating
alternative representation formats.
representation. We can also define a valid anno-
tation scheme in terms of conversion transitivity
through GrAF; that is, for two arbitrary annotation
schemes R and S, the following holds:
?(R) = ?(CRG(R)) = ?(CGS(S))
Our goal here is to provide a formal speci-
fication for the mapping function CRG, assum-
ing the existence of a formal specification of
an annotation scheme as outlined in section 3.
To accomplish this, it is necessary to identify
the two components of an abstract syntax for
annotation scheme R: the conceptual inventory
and the annotation construction rules that indi-
cate how elements of the conceptual inventory are
combined into annotation structures?specifically,
entity structures, which describe annotation ob-
jects, and link structures, which describe relations
among entity structures. Once these are available,
a general procedure for establishing a GrAF repre-
sentation of the annotation structures is as follows:
For each type of entity structure e:
? introduce a label Le, where Le is the entity
structure type;
? define a set of features f corresponding one-
to-one with the components of the n-tuple
of elements from the conceptual inventory
defining entity structure e.
A link structure is a triple ?E1, E2, r? consisting
of two sets of entity structures and a relational el-
ement defining a relation between them. For each
type of link structure:
1. introduce a label Lr, where Lr is the type
name of relation r.
2. If r is associated with a set of elements from
the conceptual inventory, then features are
created as in (2), above.
In GrAF, an annotation A consists of a label L
and a feature structure containing a set of features
f . Annotations may be associated with nodes or
edges in the graph. Typically, entity structures are
associated with nodes that have links into a region
of primary data or one or more edges connecting it
to other nodes in the graph. Link structures are as-
sociated with edges, identifying a relation among
two or more entity structures. In the simplest case,
a link structure consists of a relation between two
250
entity structures, each of a given type; in the cor-
responding GrAF representation, the link structure
label is associated with an edge d that connects
nodes n1, n2, each of which is decorated with an-
notations labeled L1, L2, respectively.
For example, for the ISO-TimeML abstract
syntax fragment provided in section 3, we de-
fine the labels EVENT and INSTANT cor-
responding to the two entity structures with
names event structure and time amount struc-
ture, and a link structure TIME-ANCHORING.
Because an event structure is defined as a 6-
tuple ?e, t, a, s, k, v?, we define six features event,
tense, aspect signature, cardinality, and verac-
ity.5 A time-amount structure may be a pair
?n, u? or a triple ?R,n, u?, where n is a real
number, R a numerical relation, and u a tem-
poral unit, so we introduce features numeral,
unit, and relType. Finally, the time anchoring
link structure is a triple ?event structure, time-
amountstructure, duration relation?. In this
case, the first two elements of the triple are the
entity structures being linked; these will be repre-
sented as nodes in the GrAF implementation. The
label and features associated with each entity and
link structure provide the template for an annota-
tion corresponding to that structure with appropri-
ate values filled in, which may then be associated
with a node or edge in the graph.
5.1 ISO-TimeML example
The GrAF representation of the ISO-TimeML an-
notation for the sentence I fasted for two days is
shown in Figure 3, based on the abstract syntax
given in section 3.1.
To create an annotation corresponding to an
ISO-TimeML entity structure, a node <node> el-
ement) is created and assigned a unique identi-
fier as the value of the XML attribute xml:id. An
annotation (<a>) element is also created, with a
label attribute whose value is the entity structure
name, and which contains a feature structure pro-
viding the appropriate feature/value pairs for that
entity structure. The annotation is associated with
the node by using the node?s unique identifier as
the value of the ref attribute on the <a> element.
An edge is then created from the node to another
node in the graph (r2) that references the data to be
annotated?in this case, one or more tokens defined
5The latter three attributes have the default values INDI-
VIDUAL, 1, and POSITIVE, respectively, and will be omit-
ted in the examples to follow if they have these values.
over regions of the primary data.
ISO-TimeML link structures define a relation
between two entity structures, and are rendered in
GrAF as a labeled edge between the nodes anno-
tated with the entity structure information. In the
ISO-TimeML example, an annotation with label
MLINK (?measure link?) is created with a single
feature relType. The from and to attributes on the
<edge> element link the node with the EVENT
entity structure annotation (node tml-n1 in the
example) to the node with the TIME-AMOUNT
annotation (tml-n2). This edge is then associ-
ated with the MLINK annotation (cf. Bunt and
Pustejovsky, 2009; Pustejovsky et al, 2010).
Figure 1 shows the rendering of the ISO-
TimeML abstract syntax in the ICS-1 concrete
syntax. Following Section 3.2, these two realiza-
tions of the abstract syntax for ISO-TimeML are
isomorphic.
<node xml:id="tml-n1"/>
<a label="EVENT" ref="tml-n1"
as="TimeML">
<fs>
<f name="event" value="fast"/>
<f name="tense" value="Past"/>
<f name="signature"
value="individual"/>
</fs>
</a>
<edge xml:id="tml-e1" from="tml-n1"
to="t2"/>
<node xml:id="tml-n2"/>
<a label="TIME-AMOUNT" ref="tml-n2"
as="TimeML">
<fs>
<f name="numeral" value="2"/>
<f name="unit" value="day"/>
</fs>
</a>
<edge xml:id="tml-e2" from="tml-n2"
to="t4"/>
<edge xml:id="tml-e3" from="tml-n2"
to="t5"/>
<edge xml:id="tml-e4" from="tml-n1"
to="tml-n2"/>
<a label="MLINK" ref="tml-e4"
as="TimeML">
<fs>
<f name="relType" value="FOR"/>
</fs>
</a>
Tokens: [It1][fastedt2][fort3][twot4][dayst5].
Figure 3: ISO-TimeML annotation in GrAF
251
5.2 Reverse engineering the abstract syntax
The previous two sections show how schemes for
which an abstract syntax is specified can be ren-
dered in GrAF as well as other concrete syn-
tax representations. However, as noted in sec-
tion 2, many annotation formats?especially legacy
formats?were not designed based on an underly-
ing data model. Therefore, in order to achieve a
mapping to GrAF, it is necessary to ?reverse en-
gineer? the annotation format to define its abstract
syntax. Because of problems such as those out-
lined in Section 2, this exercise may require some
extrapolation of information that is implicit, or not
specified, in the original annotation format. We
provide two examples below, one for PropBank
and one for FrameNet.
5.2.1 An abstract syntax for PropBank
The PropBank format specifies an annotation for
a sentence consisting of several columns, specify-
ing the file path; the sentence number within the
file; the number of the terminal in the sentence
that is the location of the verb; a status indica-
tion; a frameset identifier (frame and sense num-
ber); an inflection field providing person, tense,
aspect, voice, and form of the verb; and one or
more ?proplabels? representing an annotation as-
sociated with a particular argument or adjunct of
the proposition. Proplabels are associated with
primary data via reference to the Penn Treebank
(PTB) node in the syntax tree of the sentence.
Based on this we can specify a portion of a
PropBank conceptual Inventory:
? a special proposition type verb, designating
the verb (replaces PropBank ?rel?);
? a finite set PROP = {ARGA,ARGM,
ARG0, ARG1, ARG2} of proposition la-
bels;
? a finite set FEAT = {EXT,DIR,LOC,
TMP,REC,PRD,NEG,MOD,ADV,
MNR,CAU,PNC,DIS}, plus the set of
prepositions and ?null?, comprising the set of
features;
? a finite set of sets INF =
{form, tense, aspect, person, voice},
where form = {infinitive, gerund,
participle, finite}, tense = {future,
past, present}, aspect = {perfect,
progressive, both}, person =
{default, 3rd},
and voice = {active, passive}.
? a finite set FrameSets = {fs1, fs2, ...fsn}
where each fsi is a frame set defined in Prop-
Bank.
An abstract syntax for PropBank could specify
the following annotation construction rules:
? a proposition entity structure is a pair ?f,A?
where f is a frameset and A is a set of argu-
ment entity structures.6
? an argument entity structure is an argument
a ? PROP ? FEAT .
? a verb entity structure is a 5-tuple
?f, t, a, p, v? where f ? form, t ? tense,
a ? aspect, p ? person, and v ? voice.
Based on this, the PropBank annotation in Sec-
tion 2 can be rendered into a concrete syntax; in
this case, in GrAF as shown in Figure 4. Note that
the to attribute on <edge> elements have as val-
ues the reference to PTB nodes from the original
PropBank encoding; in GrAF, these values would
be identifers on the appropriate nodes in a GrAF
representation of PTB. We have also included role
names (e.g., ?owner?) in the annotation, which are
not present in the original; this was done for con-
venience and readability, and the values for the
?role? feature could have been given as arg-0, arg-
1, etc. instead.
The original PropBank encoding is close to an
ideal concrete syntax, as it can be generated from
the abstract syntax. However, the round trip back
to the abstract syntax is not possible, because it is
necessary to do some interpretation of associations
among bits of annotation information in order to
construct the abstract syntax and, subsequently,
map the PropBank format to GrAF. Specifically,
in the GrAF encoding the inflection information is
associated with the node referencing the verb, but
this association is not explicit in the original (and
in fact may not be what the annotation scheme de-
signers intended).
5.2.2 An abstract syntax for FrameNet
The FrameNet XML format is shown in Fig-
ure 5.7 The structure and content of this encod-
ing is highly oriented toward a presentation view,
6We do not include the bookkeeping information associ-
ated with a PropBank annotation in the abstract syntax.
7Some detail concerning the html display has been omit-
ted for brevity.
252
<node xml:id="pb-n1"/>
<a label="Proposition" ref="pb-n1"
as="PropBank">
<fs>
<f name="file"
value="wsj/00/wsj_0003.mrg"/>
<f name="sentenceNo" value="13"/>
<f name="verbOffset" value="6"/>
<f name="status" value="gold"/>
<f name="frameSet"
value="have.03"/>
</fs>
</a>
<node xml:id="pb-n2"/>
<a label="VERB" ref="pb-n2"
as="PropBank">
<fs>
<f name="role" value="rel"/>
<f name="form" value="finite"/>
<f name="tense" value="present"/>
<f name="voice" value="active"/>
</fs>
</a>
<edge xml:id="pb-e1" from="pb-n1"
to="pb-n2"/>
<edge xml:id="pb-e2" from="pb-n2"
to="ptb-6-0"/>
<node xml:id="pb-n3"/>
<a label="ARG0" ref="pb-n3"
as="PropBank">
<fs>
<f name="role" value="owner"/>
</fs>
</a>
<edge xml:id="pb-e3" from="pb-n1"
to="pb-n3"/>
<edge xml:id="pb-e4" from="pb-n3"
to="ptb-0-2"/>
<node xml:id="pb-n4"/>
<a label="ARG1" ref="pb-n4"
as="PropBank">
<fs>
<f name="role" value="possession"/>
</fs>
</a>
<edge xml:id="e5" from="pb-n1"
to="pb-n4"/>
<edge xml:id="e6" from="pb-n4"
to="ptb-7-1"/>
<node xml:id="pb-n5"/>
<a label="ARGM" ref="pb-n5"
as="PropBank">
<fs>
<f name="role" value="adjunct"/>
<f name="feature" value="adverbial"/>
</fs>
</a>
<edge xml:id="e7" from="pb-n1"
to="pb-n5"/>
<edge xml:id="e8" from="pb-n5"
to="ptb-10-1"/>
Figure 4: PropBank annotation in GrAF
intended to support display of the sentence and
frame elements in a browser.
A partial abstract syntax for FrameNet derived
from this format includes the following conceptual
inventory:
? a Target, designating the frame-evoking lex-
ical unit;
? a finite set FE = {Recipient, Supplier,
Means, ...} of frame element labels;
? a finite set GF = {Obj,Ext,Dep, ...} of
grammatical functions.
? a finite set PT = {NP,PP, ...} of phrase
types.
? a finite set LU = {u1, u2, ...un} where each
ui is a lexical unit.
? a finite set POS = {n, v, a, r} denoting
parts of speech;
? a finite set FrameNames = {f1, f2,...fn}
where each fi is a frame defined in
FrameNet.
An abstract syntax for this partial inventory
could specify the following annotation construc-
tion rules:
? a frame entity structure is a pair ?f,A? where
f is a frame name, u is a lexical unit, and F is
a set of frame element (FE) entity structures.
? an FE entity structure is a triple {f, g, p}, f ?
FE, g ? GF, p ? PT .
The GrAF rendering of the abstract syntax is
given in Figure 6, which was generated from the
FrameNet abstract syntax using the rules outlined
in section 5. Both the FrameNet XML and the
GrAF rendering provide an ideal concrete syntax
because they are isomorphic8 to the abstract syn-
tax and, by the definition in section 3.2, are con-
versions of one another.
6 Conclusion
In this paper we outlined a methodology for an-
notation scheme design and development; demon-
strated how schemes designed using this method-
ology may be easily mapped to GrAF; and demon-
strated how ?reverse engineering? an annotation
8Obviously, in the FrameNet XML additional elements
are introduced for display and bookkeeping purposes.
253
format whose abstract syntax is unspecified can
provide the information required to map that for-
mat to GrAF. This work was undertaken with two
goals in mind: (1) to provide a formal method for
mapping to GrAF; and (2) to demonstrate the ad-
vantages of a methodology for annotation scheme
design that is based on an abstract model, as
adopted in ISO TC37 SC4 projects and formalized
in (Bunt, 2010). The ultimate goal is, of course, to
achieve harmonization of annotation formats, so
that they can be merged, enabling the study of in-
teractions among information at different linguis-
tic levels; compared, in order to both evaluate and
improve automatic annotation accuracy; and to en-
able seamless transition from one software envi-
ronment to another when creating and using lin-
guistic annotations.
<annotationSet lexUnitRef="11673"
luName="provide.v" frameRef="1346"
frameName="Supply"
status="MANUAL" ID="2022935">
<layer rank="1" name="Target">
<label end="109" start="103"
name="Target"/>
</layer>
<layer rank="1" name="FE">
<label bgColor="0000FF" ... end="138"
start="111" name="Recipient"/>
<label bgColor="FF0000"... end="84"
start="83" name="Supplier"/>
<label bgColor="FF00FF"... end="79"
start="0" name="Means"/>
</layer>
<layer rank="1" name="GF">
<label end="138" start="111"
name="Obj"/>
<label end="84" start="83"
name="Ext"/>
<label end="79" start="0"
name="Dep"/>
</layer>
<layer rank="1" name="PT">
<label end="138" start="111"
name="NP"/>
<label end="84" start="83"
name="NP"/>
<label end="79" start="0" name="PP"/>
</layer>
...
</annotationSet>
Figure 5: FrameNet XML format
References
Collin F. Baker, Charles J. Fillmore, and John B. Lowe.
1998. The Berkeley FrameNet project. In Proceed-
<node xml:id="fn-as1"/>
<a label="annotationSet" ref="fn-as1"
as="FrameNet">
<fs>
<f name="lexUnitRef" value="11673"/>
<f name="luName" value="provide.v"/>
<f name="frameRef" value="1346"/>
<f name="frameName" value="Supply"/>
<f name="status" value="MANUAL"/>
<f name="ID" value="2022935"/>
</fs>
</a>
<node xml:id="fn-n1"/>
<a label="Target" ref="fn-n1"
as="FrameNet">
<fs>
<f name="name" value="Target"/>
</fs>
</a>
<edge xml:id="e69" from="fn-as1"
to="fn-n1"/>
<edge xml:id="e90" from="fn-n1"
to="fn-t1"/>
<node xml:id="fn-n2"/>
<a label="FE" ref="fn-n2"
as="FrameNet">
<fs>
<f name="FE" value="Recipient"/>
<f name="GF" value="Obj"/>
<f name="PT" value="NP"/>
</fs>
</a>
<edge xml:id="e67" from="fn-as1"
to="fn-n2"/>
<edge xml:id="e91" from="fn-n2"
to="fn-t2"/>
<node xml:id="fn-n3"/>
<a label="FE" ref="fn-n3"
as="FrameNet">
<fs>
<f name="FE" value="Supplier"/>
<f name="GF" value="Ext"/>
<f name="PT" value="NP"/>
</fs>
</a>
<edge xml:id="e46" from="fn-as1"
to="fn-n3"/>
<edge xml:id="e92" from="fn-n3"
to="fn-t3"/>
<node xml:id="fn-n4"/>
<a label="FE" ref="fn-n4"
as="FrameNet">
<fs>
<f name="FE" value="Means"/>
<f name="GF" value="Dep"/>
<f name="PT" value="PP"/>
</fs>
</a>
<edge xml:id="e10" from="fn-as1"
to="fn-n4"/>
<edge xml:id="e93" from="fn-n4"
to="fn-t4"/>
Figure 6: FrameNet in GrAF format
254
ings of the 17th international conference on Compu-
tational linguistics, pages 86?90, Morristown, NJ,
USA. Association for Computational Linguistics.
Harry Bunt and James Pustejovsky. 2010. Annotation
of temporal and event quantification. In Proceed-
ings of the Fifth International Workshop on Interop-
erable Semantic Annotation (ISA-5), pages 15?22,
Hong Kong SAR. City University of Hong Kong.
Harry Bunt. 2010. A methodology for designing
semantic annotation languages exploiting semantic-
syntactic isomorphisms. In Proceedings of the Sec-
ond International Conference on Global Interoper-
ability for Language Resources (ICGL2010), pages
29?46, Hong Kong SAR. City University of Hong
Kong.
Nancy Ide and Laurent Romary. 2004. Interna-
tional standard for a linguistic annotation frame-
work. Journal of Natural Language Engineering,
10(3?4):211?225.
Nancy Ide and Keith Suderman. 2007. GrAF: A graph-
based format for linguistic annotations. In Proceed-
ings of the First Linguistic Annotation Workshop,
pages 1?8, Prague.
ISO. 2009. Language Resource Management - Seman-
tic Annotation Framework (SemAF) - Part 1: Time
and Events. Secretariat KATS, October. ISO In-
ternational Standard 24617-1:2009(E)), 11 October
2009.
H. Kamp and U. Reyle. 1993. From Discourse to
Logic. Kluwer Academic Publishers, Dordrecht.
Marc Kemps-Snijders, Menzo Windhouwer, Peter Wit-
tenburg, and Sue Ellen Wright. 2009. ISOcat : Re-
modelling metadata for language resources. Inter-
national Journal of Metadata and Semantic Ontolo-
gies, 4(4):261?276.
Inderjeet Mani, James Pustejovsky, and Beth Sund-
heim. 2004. Introduction to the special issue on
temporal information processing. ACM Transac-
tions on Asian Language Information Processing
(TALIP), 3(1):1?10.
Martha Palmer, Daniel Gildea, and Paul Kingsbury.
2005. The Proposition Bank: An annotated cor-
pus of semantic roles. Computational Linguistics,
31(1):71?106, March.
James Pustejovsky, Harry Bunt, Kiyong Lee, and Lau-
rent Romary. 2010. ISO-TimeML: An International
Standard for Semantic Annotation. In Proceedings
of the Fifth International Workshop on Interoperable
Semantic Annotation (ISA-5), Paris. ELDA.
255
The Semantics of Dialogue Acts
Harry Bunt
TiCC, Tilburg Center for Cognition and Communication
Tilburg University, The Netherlands
harry.bunt@uvt.nl
Abstract
This paper presents an update semantic for dialogue acts, defined in terms of combinations of
very simple ?elementary update functions?. This approach allows fine-grained distinctions to be
made between related types of dialogue acts, and relations like entailment and exclusion between
dialogue acts to be established. The approach is applied to dialogue act representations as defined in
the Dialogue Act Markup Language (DiAML), part of the recently proposed ISO standard 24617-2
for dialogue act annotation.
1 Introduction
The notion of a dialogue act plays a key role in studies of dialogue, in particular in the interpretation
of the behaviour of dialogue participants and in the design of spoken dialogue systems. But in spite of
their popularity, their status is nearly always reduced to that of informal, intuitive concepts which lack
proper definitions (see Poesio and Traum, 1998 for one of the few attempts at formalization). A wide
range of alternative dialogue act taxonomies and inventories have been proposed, causing considerable
terminological and conceptual confusion, and problems for reusing annotated corpora. This has moti-
vated the International Organisation for Standards ISO to develop a standard for interoperable dialogue
act annotation, ISO 24617-2 (see ISO 2010). This proposed standard is partly based on the comprehen-
sive DIT++ taxonomy, which has added to the earlier DIT taxonomy (Bunt, 1994) a number of concepts
from other proposals and studies. Semantically, the DIT++ taxonomy is based on the dynamic approach
to utterance meaning taken in Dynamic Interpretation Theory (DIT), which views dialogue acts as cor-
responding to update operations on the information states of participants in the dialogue; an approach
commonly known as the ?information-state update approach? to meaning in dialogue ? see e.g. Bunt
(2000); Traum & Larsson (2003). A dialogue act, on this approach, has two main components: a seman-
tic content, which describes the objects, properties, relations, or actions that the dialogue act is about,
and a communicative function, which specifies how an addressee should update his information state
with the semantic content.
Utterances in dialogue are often multifunctional, i.e., they have more than one communicative func-
tion. Dialogue analysis and annotation frameworks are therefore often ?multidimensional? in the sense of
allowing the assignment of multiple functions to functional segments. The DAMSL annotation scheme
for example (DAMSL = Dialogue Act Markup using Several Layers) distinguishes nine ?dimensions? as
mutually exclusive groups of function tags.
Bunt (2006) introduces a notion of dimension based on the observation that participation in a dia-
logue involves, beyond activities strictly related to performing the underlying task, sharing information
about the processing of utterances, managing the use of time, taking turns, and various other types of
communicative activity, and defines dimensions as corresponding to such aspects of communication.
Each dimension in this sense constitutes a category of communicative activity, and the dialogue acts
involved in these activities are concerned with different types of information: feedback acts with the
success of processing previous utterances; turn management acts with the allocation of the speaker role,
task-related acts with the dialogue task; and so on. Dimensions thus classify semantic content.
1
Petukhova & Bunt (2009a; 2009b) formulate criteria for distinguishing dimensions, and apply these
in the analysis of the dimensions that occur in 18 existing annotation schemes, showing that the 10
dimensions of DIT++ form a well-founded set of dimensions. These are the following:
(1) 1. Task/Activity: dialogue acts for performing the task or activity underlying the dialogue
2. Auto-Feedback: providing information about the speaker?s processing of previous utterances.
3. Allo-Feedback: the speaker expresses opinions or elicits information about the addressee?s processing
of previous utterances;
4. Contact Management: dialogue acts for establishing and maintaining contact;
5. Turn Management: concerned with grabbing, keeping, giving, or accepting the speaker role;
6. Time Management: the speaker indicates to need some extra time to formulate his contribution;
7. Discourse Structuring: dialogue acts for explicitly structuring the conversation;
8. Own Communication Management: dialogue acts for editing the speaker?s current utterance;
9. Partner Communication Management: dialogue acts to assists or correct the current speaker;
10. Social Obligations Management: dialogue acts that take care of social conventions such as greetings,
apologies, and expressions of gratitude.
Some communicative functions are specific for a particular dimension; for instance Turn Accept
and Turn Release are specific for turn management; Stalling and Pausing for time management. Other
functions can be applied in any dimension; for instance a Check Question can be used with task-related
semantic content, but also for checking correct understanding (feedback). Similarly for commissive
and directive functions. These functions are therefore called general-purpose functions, as opposed
to dimension-specific functions. The DIT++ taxonomy therefore consists of two parts: a taxonomy
of general-purpose functions and one of dimension-specific functions - see Appendix A and http:
//dit.uvt.nl.
2 DiAML: Dialogue Act Markup Language
The Dialogue Act Markup Language (DiAML) which is part of the ISO standard under development for
dialogue act annotation (see Bunt et al, 2010, and http://semantic-annotation.uvt.nl)
has been designed in accordance with the ISO Linguistic Annotation Framework (Ide & Romary, 2004),
which makes a distinction between annotation and representation; ?annotation? refers to the linguistic
information that is added to segments of language data, independent of format; ?representation? refers to
the format in which an annotation is rendered, independent of content. This distinction is implemented in
the DiAML definition by a syntax that specifies, besides a class of XML-based representation structures,
also a class of more abstract annotation structures. These two components are called the concrete and
abstract syntax, respectively.
The abstract syntax defines a class of set-theoretical structures, called ?annotation structures?. It
consists of: (a) a specification of the elements from which annotation structures are built up, called a
?conceptual inventory?, and (b) a specification of the possible ways of combining these elements. The
conceptual inventory consists of finite sets of elements called ?functional segments?, ?dimensions?, ?com-
municative functions?, ?qualifiers?, and ?rhetorical relations?.
An annotation structure consists of a set of entity structures and a set of link structures. Entity
structures contain semantic information about a functional segment; link structures describe semantic
relations between segments. The most important kind of entity structure is a so-called ?dialogue act
structure?, which is a quadruple ?S,A, d, f? where S and A are the sender and addressee of a dialogue
act; d is a dimension; and f is a communicative function or a pair ?f, q?, where q is a list of qualifiers.
The concrete syntax defines a rendering of annotation structures in XML. It is defined in accordance
with the methodology for defining semantic annotation languages described in Bunt (2010), which intro-
duces the notion of an ideal representation format, defined as one where every representation represents
a uniquely determined annotation structureThe semantics of the language is then defined for the struc-
tures defined by the abstract syntax. This has the effect that any two ?ideal? representation formats
2
are semantically equivalent; every representation in one such format can be converted by a meaning-
preserving mapping into any other such format.1 The concrete syntax of DiAML is illustrated in (3)
and (2). P2?s utterance is segmented into two overlapping functional segments: one (fs2.1) in the Auto-
Feedback dimension and one (fs2.2) in the Task dimension, with value ?answer? qualified as ?uncertain?.
(#-prefixed elements are assumed to be identified in the metadata of the source material or in another
layer of annotation.)
(2)
1. P1: What time does the next train to Utrecht leave?
TA: fs1: What time does the next train to Utrecht leave?
2. P2: The next train to Utrecht leaves I think at 8:32.
AuFB fs2.1: The next train to Utrecht
TA fs2.2: The next train to Utrecht leaves I think at 8:32.
(3)
<diaml xmlns:"http://www.iso.org/diaml/">
<dialogueAct xml:id="da1" target="#fs1"
sender="#p1" addressee="#p2"
communicativeFunction="setQuestion" dimension="task"
conditionality="conditional"/>
<dialogueAct xml:id="da2" target="#fs2"
sender="#p2" addressee="#p1"
communicativeFunction="autoPositive" dimension="autoFeedback"/>
<feedbackDependence dact="#da2.1" fbSegment="#fs1"/>
<dialogueAct xml:id="da3" target="#fs2.2"
sender="#p2" addressee="#p1"
communicativeFunction="answer" certainty="uncertain"
dimension="task" />
<functionalDependence dact="#da3" functAntecedent="#da1"/>
</diaml>
3 Context Model Structure and Content
As the proposed semantics of dialogue acts is in terms of information-state updates, the question arises
as to what exactly is an information state in this context; what information does it contain, and how is it
structured. An information state will be assumed to have a number of components, an assumption which
is shared between all proposals for information states (e.g. Poesio & Traum, 1998; Bunt, 2000; Ahn,
2001; Cooper, 2004); moreover, certain types of information can be argued to be required in information
states. The details of an information-state update semantics also depend on whether only the information
state of an addressee is considered to be updated by dialogue acts, or also that of the sender, and on
whether these updates involve mutual beliefs, as e.g. argued in Bunt (2000). We consider here only the
updates of a single addressee?s information state, disregarding mutual beliefs; this is anyway the basis
for more complex approaches involving multiple information states and mutual beliefs. In DIT, it is
customary to speak of ?contexts? or context models?, rather than ?information states?, and we will use
this terminology in the rest of this paper.
A fundamental requirement for an adequate context model is that, for a given range of dialogue act
types, the model contains the kinds of information that are updated by a dialogue act. Bunt (forthc.)
argues that an agent?s context model does not necessarily have a separate component for each DIT di-
mension, but that it is convenient to distinguish the following five components:
(4) 1. Linguistic Context, which contains a record of the dialogue history, information about discourse plans
(if any), and wishes concerning the occupation of the speaker role;
2. Semantic Context, which contains the agent?s information and goals relating to the dialogue task, as
well as his assumptions about the dialogue partner?s task-related goals and beliefs;
3. Cognitive Context, which contains information about the agent?s cognitive processes concerned with
the processing and production of dialogue utterances, including time estimates for these processes;
1See Bunt (2010) for formal definitions and proofs relating to alternative representation formats sharing the same abstract
syntax, and Ide & Bunt (2010) for applying this to the GrAF framework for linguistic annotation.
3
4. Physical/Perceptual Context, which contains information about physical and perceptual properties of
the interactive situation;
5. Social Context, which contains information relevant for interpreting and generating ?social? acts like
greetings, apologies, expressions of gratitude.
Versions of such a 5-component context model have been implemented in the PARADIME dialogue
manager (Keizer and Bunt, 2006; 2007) and for experimentation by Petukhova et al (2010).
An update semantics has to take into account that update operations should not undermine the con-
sistency of the context model. A dialogue participant may change his mind during the dialogue, as an
effect of receiving some unexpected information, which can have the effect that the participant brings in
new information which contradicts something that was already grounded, and hence cannot simply be
added without making the context model inconsistent. Rather then building consistency checks into the
semantics of each dialogue act, we exploit the DIT distinction of five levels of utterance processing: (1)
attention, (2) perception, (3) understanding, (4) evaluation, and (5) execution. The level of understand-
ing determines the meaning of a dialogue segment in terms of dialogue acts. The evaluation level checks
whether the corresponding updates would keep the current context model consistent. If so, it performs
the updates. One way to implement this approach is to add to a context model a part called the pending
context, which serves as a buffer for items to be inserted in the main context once their consistency with
the current content of the main context has been established.2 Updating the pending context is a matter
of simply adding items to it. For convenience we will assume the pending context A? of an agent A?s
context model to be structured in the same way as the main context. We will use the notation (5a) to
specify the update consisting of adding the information z to component A?i i of A?s pending context. If
f is the update (5a) and g the update A?j =+u, then (5b) designates the combination of the two updates.3
(5) a. A?i =+z
b. f unionsq g
An analysis of the definitions of the DIT++ communicative functions shows that a formal description
of the update effects of dialogue acts with a general-purpose function requires the basic concepts listed in
Table 1. For convenience, we also introduce the following abbreviations: Bel(S, p) abbreviates BelS, p,
firm); Wk-Bel(S, p) abbreviates BelS, p, weak); Assumes(S,p) abbreviates Bel(S,p) ? Wk-Bel(S,p).
In all action-related attitude operators we suppress the argument > representing the ?empty? condition,
hence WilDo(S, ?) abbreviates WilDo(S, ?,>), and so on.
description notation meaning
believes that Bel(S, p, ?) S believes that p; ? indicates whether this is a firm belief
or an uncertain belief (? can have the values ?firm? and ?weak?)
knows value of Know-val(S, z) S possesses the information z
has goal Wantl(S, p) S has the goal that p
is able to do CanDo(S, ?) S is able to perform the action ?
is willing to do WilDo(S, ?,C?) S is willing to perform the action ? if the condition C? is
fulfilled; C? may be the universally true statement >
is committed to do CommitDo(S, ?,C?) S is committed to perform the action ? if the condition C? is
fulfilled; the condition C? may be ?empty? (>)
is committed to RefrainDo(S, ?,C?) S is committed to refrain from performing the action ?
refrain from doing if the condition C? is fulfilled C? may be ?empty? (>)
is considering ConsidDo (X,?, Y, C?) X is considering the action ?, to be performed by Y,
to be done if the condition C? is fulfilled C? may be ?empty? (>)
is in the interest of Interest(Y, ?) action ? is of interest to agent Y .
Table 1: Basic semantic concepts for general-purpose communicative function interpretation
2This approach has been implemented in the multimodal DenK dialogue system; see Kievit et al (2001).
3The combined update (f unionsq g) is undefined if the order of performing the two updates would make a difference.
4
Dimension Primitives
Auto- and Allo-feedback Attended, Perceived, Understood, Accepted, Executed, Attention-
Problem, Perception-Problem, Interpretation-Problem, Evaluation-
Problem, Execution-Problem
Turn Management Current-Speaker, Next-Speaker
Time Mangement Time-Need, small, substantial
Contact Management Present
Discourse Structuring Ready, Available, Start-Dialogue, Close-Dialogue
Own and Partner Communication Man. Delete, Replace, Append
Social Obligations Man. Available, Thankful, Regretful, Knows-id, Final
Table 2: Dimension-specific semantic primitives
Dimension-specific communicative functions are always concerned with a specific category of se-
mantic content, which requires certain specific semantic primitives for its representation. Table 2 lists
the basic concepts for describing their update semantics.
For expressing the semantics of a feedback act which is underspecified for the level of processing,
we introduce in (6) the predicates Succes-Processing, defined as successful at least at the level of under-
standing, and Unsuccessful-Processing, defined as unsuccessful at the level of understanding or lower.
(6) a. Succes-Processing = Understood ? Accepted ? Executed
b. Unsuccessful-Processing = Interpretation-Problem ? Perception-Problem ? Attention-Problem
4 Dialogue Act Semantics
In this section we outline a semantics of dialogue acts in the form of an update semantics for the ?dialogue
act structures? defined by the DiAML abstract syntax. A dialogue act structure does not correspond to
a full-blown dialogue act representation, since it does not include the full semantic content, but only
the dimension which classifies the semantic content. The semantics of a dialogue act structure should
therefore be something which can be combined with a semantic content in order to form the interpretation
of a full-blown dialogue act. This is precisely the case, for the recursive interpretation of a dialogue
act structure ?S,A, d, f? is defined through the recursive valuation function V as specified in (7). Of
the four arguments of V in the left-hand side of (7), S, A, and d are elements of the categories of the
DiAML conceptual inventory, so there is no recursion in their interpretation; for such elements, the
valuation function is defined by a value assignment function F , playing the same role as that of a ?model
assignment? function in model-theoretic semantics; F for example assigns to a sender and an addressee
certain individuals, identified in the metadata of an annotated dialogue (cf. #p1 and #p2 in (3)). To the
dimension argument d, F assigns that component of an information state that should be updated.
(7) V (<S, A, d, f>) = (V (f))(F (S), F (A), F (d))
4.1 The Update Semantics of Communicative Functions
A communicative function will be interpreted as a function which, applied to a given speaker, addressee,
and dimension, results in a function which can be applied to a semantic content in order to obtain a
context-update specification. Since related communicative functions often share parts of their defining
preconditions, we will construct such interpretations as combinations of elementary update functions,
each of which takes care of the update corresponding to a single dialogue act precondition; see Table
3 and Table 4 for illustration: Table 3 lists the definitions of the update semantics of the communica-
tive functions of the information-providing class, while Table 4 lists the elementary elementary update
functions used in these definitions.
5
4.1.1 General-Purpose Communicative Functions
The class of general-purpose communicative functions in the DIT++ taxonomy falls apart into the
information-transfer functions and action-discussion functions, further subdivided into information-providing
and information-seeking functions, and commissives and directives, respectively.
a. Information-Providing and Information-Seeking Functions The class of information-providing
functions has a hierarchical structure, with the communicative function Inform as the mother of all
information-providing functions; all other functions are specializations of this function. These func-
tions all have in common that (1) the speaker wants the addressee to possess certain information which
(2) the speaker assumes to be correct.
Using the epistemic operators introduced in Section 5, these preconditions are formalized as follows:
(8) 1. Want(S,U, Bel(A, p, ?))
2. Bel(A, p, ?)
The semantics of the Inform function, specified in Table 3, binds the variable ?, representing the belief
strength for both the elementary update functions involved. (See further below, section 4.2.)
The update semantics in terms of combinations of elementary update functions often brings out
immediately that some communicative functions are specializations of others (as visualized in Appendix
A), for instance, the update semantics of the Answer function shares with the Inform function the updates
defined by the elementary update functions U1 and U2, and adds to that the effects of U7 and U9; the
semantic of the Confirm function adds to that the update defined byU8. Hence Confirm is a specialization
of Answer, which is a specialization of Inform, or in other words Confirm entails Answer entails Inform.
F (Inform) = ?s.?X.?Y.?Di.?p.U1(X,Y,Di, p, s) unionsq U2(X,Y,Di, p, s)
F (Agreement) = ?s.?X.?Y.?Di.?p.U1(X,Y,Di, p, s) unionsq U2(X,Y,Di, p, s) unionsq U5(X,Y,Di, p)
F (Disagreement) = ?s.?X.?Y.?Di.?p.U1(X,Y,Di,?p, s) unionsq U2(X,Y,Di,?p, s) unionsq U5(X,Y,Di, p)
F (Correction) = ?s.?X.?Y.?Di.?p.U1(X,Y,Di, p1, s) unionsq U2(X,Y,Di,?p1, s) unionsq U6(X,Y,Di, p2)
F (Answer) = ?s.?X.?Y.?Di.?p.U1(X,Y,Di, p, s) unionsq U2(X,Y,Di, p, s) unionsq U9(X,Y,Di, p)
unionsq U7(X,Y,Di, p)
F (Confirm) = ?s.?X.?Y.?Di.?p.U1(X,Y,Di, p, s) unionsq U2(X,Y,Di, p, s) unionsq U8(X,Y,Di, p)
unionsq U9(X,Y,Di, p, s) unionsq U7(X,Y,Di, p)
F (Disconfirm) = ?s.?X.?Y.?Di.?p.U1(X,Y,Di,?p, s) unionsq U2(X,Y,Di,?p, s) unionsq U8(X,Y,Di,?p, s)
unionsq U9(X,Y,Di, p) unionsq U7(X,Y,Di, p)
F (Question) = ?X.?Y.?Di.?z.U10(X,Y,Di, z) unionsq U11(X,Y,Di, z)
F (Prop.Question) = ?X.?Y.?Di.?p.U10(X,Y,Di, p) unionsq U11(X,Y,Di, p) unionsq U12(X,Y,Di, p)
F (CheckQuestion) = ?X.?Y.?Di.?z.U10(X,Y,Di, p) unionsq U11(X,Y,Di, p) unionsq U4(X,Y,Di, p)
F (SetQuestion) = ?X.?Y.?Di.?z.U10(X,Y,Di, P ) unionsq U11(X,Y,Di, P ) unionsq U13(X,Y,Di, P )
F (ChoiceQuestion) = ?X.?Y.?Di.?p.U15a(X,Y,Di, p) unionsq U15(X,Y,Di, p) unionsq U16(X,Y,Di, p)
Table 3: Update semantics for information-providing and information-seeking communicative functions
As an illustration of the update semantics of information-providing functions, consider the case of the
answer in (9.2).
(9) 1. D: twenty-five euros, how much is that in pounds?
2. C: twenty-five euros is something like 20 pounds
Applying the semantics of the Answer function (see Table 3) to the participants C and D and the semantic
content of (9.2), we obtain:
(10) F (Answer)(C, D, Task, EU25=BP20) = U1(C,D,SemC, EU25=BP20) unionsq
unionsq U2(C,D,Task, EU25=BP20) unionsq U9(C, D, Task, EU25=BP20) unionsq U7(C, D, Task, EU25=BP20) =
D?SemC =+ Bel(D, Want(C, Bel(D, EU25=BP20))); D?SemC =+ Bel(D, Bel(C, EU25=BP20));
D?SemC =+ Bel(D, Bel(C, Want(D, Know-val(D, EU25=BP20)))); D?SemC =+ Bel(D, Bel(C, Assume(D,
Know-val(C, EU25=BP20))))
6
Hence the following beliefs are added to D?s pending Semantic Context: (1) C wants D to know that
EU25=BP20; (2) C believes that EU25=BP20; (3) C believes that D wants to knowwhether EU25=BP20;
and (4) C believes that D assumes C to know whether EU25=BP20.
U1(X,Y,Di, p, s) Y ?i =+ Bel(Y , Want(X,Bel(Y, p, s)))
U2(X,Y,Di, p, s) Y ?i =+ Bel(Y , Bel(X, p, s))
U3(X,Y,Di, p) Y ?i =+ Bel(Y , Assume(X, p))
U4(X,Y,Di, p) Y ?i =+ Bel(Y , Wk-Bel(X, p))
U5(X,Y,Di, p) Y ?i =+ Bel(Y , Bel(X, Assume(Y, p)))
U6(X,Y,Di, p) Y ?i =+ Bel(Y , Assume(X , Assume(Y, p)))
U7(X,Y,Di, p) Y ?i =+ Bel(Y , Bel(X, Assume(Y, Know-val(X,P ))))
U8(X,Y,Di, p) Y ?i =+ Bel(Y , Assume(X, Wk-Bel(Y, p))
U9(X,Y,Di, p) Y ?i =+ Bel(Y , Bel(X, Want(Y, Know-val(Y, p))))
U10(X,Y,Di, p) Y ?i =+ Bel(Y , Want(X, Know-val(X, )))
U11(X,Y,Di, p) Y ?i =+ Bel(Y , Assume(X, Know-val(Y, p))
U12(X,Y,Di, p) Y ?i =+ Bel(Y , Bel(X , p ? ?p))
U15(X,Y,Di, p) Y ?i =+ Bel(Y , Assume(X, p1 xor p2))
U15a(X,Y,Di, p) Y ?i =+ Bel(Y , Want(X, Bel(X, p1) ? Bel(X, p2))))
U16(X,Y,Di, p) Y ?i =+ Bel(Y , Assume(X,Bel(Y, p1) ? Bel(Y, p2))))
Table 4: Elementary update functions used in the semantics of information-transfer functions
b. Commissive and Directive Functions For the classes of commissive and directive communicative
functions, we provide for reasons of space the semantics of only a small selection of functions; see Bunt
(2011a) for more.
F (Offer) = ?C?.?X.?Y.?Di.??.U25a(X,Y,Di, ?) unionsq U20(X,Y,Di, ?, C?)
F (AddressRequest) =?C?.?X.?Y.?Di.??.U17a(X,Y,Di, ?, C?) unionsq U18(X,Y,Di, ?) unionsq U26b(X,Y,Di, ?)
F (AcceptRequest) =?C?.?X.?Y.?Di.??.U17(X,Y,Di, ?, C?) unionsq U18(X,Y,Di, ?) unionsq U26b(X,Y,Di, ?)
F (DeclineRequest) =?C?.?X.?Y.?Di.??.U27(X,Y,Di, ?,C?) unionsq U18(X,Y,Di, ?) unionsq U26b(X,Y,Di, ?)
F (Request) = ?C?.?X.?Y.?Di.??.U23(X,Y,Di, ?, C?) unionsq U26(X,Y,Di, ?)
F (Instruct) = ?C?.?X.?Y.?Di.??.U24(X,Y,Di, ?, C?) unionsq U26(X,Y,Di, ?) unionsq U25(X,Y,Di, ?)
F (AddressOffer) = ?C?.?X.?Y.?Di.??.U17b(X,Y,Di, ?, C?) unionsq U25(X,Y,Di, ?) unionsq U25b(X,Y,Di, ?)
F (AcceptOffer) = ?C?.?X.?Y.?Di.??.U24(X,Y,Di, ?) unionsq U25(X,Y,Di, ?) unionsq U25b(X,Y,Di, ?)
Table 5: Update semantics for a selection of commissive and directive functions
As an example of the interpretation of a directive dialogue act, consider the request in (11.2):
(11) 1. A: (...)
2. B: Could you please repeat that?
Applied to the participants A and B and the semantic content Repeat(u1), which situates the Request
act in the Auto-Feedback dimension, the definition of the Request semantics in Table 5 leads to:
(12) F (Request)(A, B, Auto-Feedback, ?Repeat(u1), unconditional?) = ?C?.?X.?Y.?Di.??.)
U23(X,Y,Di, ?, C? unionsq U26(X,Y,Di, ?)(A, B, Auto-Feedback, Repeat(u1), >) =
= U23(A,B, CC, Repeat(u1), >) unionsq U26(A,B, C, Repeat(u1)) =
B?CC =+ Bel(B, Want(A, [WilDo(A,Repeat(u1) ? CommitDo(B,Repeat(u1))]));
B?CC =+ Bel(B, Bel(A, CanDo(B,Repeat(u1))))
where ?CC? stands for Cognitive Context.
4.1.2 Dimension-Specific Communicative Functions
4.1.2.1 Feedback Functions The communicative functions for providing and eliciting feedback in DIT++
fall apart in those concerned with the speaker?s own processing of previous utterances (Auto-Feedback)
7
U17(X,Y,Di, ?, C?) Y ?i =+ Bel(Y , CommitDo(X,?,C?))
U17a(X,Y,Di, ?, C?) Y ?i =+ Bel(Y , ConsidDo(X,?,X,C?))
U17b(X,Y,Di, ?, C?) Y ?i =+ Bel(Y , ConsidDo(X,?, Y, C?))
U18(X,Y,Di, ?) Y ?i =+ Bel(Y , Bel(X,Want(Y,CommitDo(X,?,C?)))
U20(X,Y,Di, ?, C?) Y ?i =+ Bel(Y, WilDo(X,?,C?))
U21(X,Y,Di, ?) Y ?i =+ Bel(Y , Bel(X, Interest(?, Y )))
U23(X,Y,Di, ?) Y ?i =+ Bel(Y , Want(X, [WilDo(Y, ?,C?) ? CommitDo(Y, ?,C?)]))
U24(X,Y,Di, ?) Y ?i =+ Bel(Y , Want(X,CommitDo(Y, ?)))
U25(X,Y,Di, ?, C?) Y ?i =+ Bel(Y , Bel(X,WilDo(Y, ?,C?)))
U25a(X,Y,Di, ?, C?) Y ?i =+ Bel(Y , Want(X, Bel(Y, WilDo(X,?,C?))))
U25b(X,Y,Di, ?, C?) Y ?i =+ Bel(Y , Bel(X , Want(Y, Bel(X, WilDo(Y, ?,C?)))))
U26(X,Y,Di, ?) Y ?i =+ Bel(Y , Assume(X, CanDo(Y, ?)))
U26b(X,Y,Di, ?) Y ?i =+ Bel(Y , Bel(X, Assume(Y,CanDo(X,?)))
U27(X,Y,Di, ?, C?) Y ?i =+ Bel(Y , CommitRefrain(X,?,C?))
Table 6: Elementary update functions used in the semantics of action-discussion functions.
and those concerned with the addressee?s processing, as perceived by the speaker (Allo-Feedback). The
elementary update functions for both dimensions are nearly identical, only differing in whose processing
is concerned. Tables 7 and 8 show the update semantics of a small, representative subset of the (25)
DIT++ communicative functions for providing and eliciting feedback.
U31(X,Y,Di, z) Y ?CC =+ Bel(Y , Want(X, Bel(Y, Succes-Processing(X, z)))
U35(X,Y,Di, z) Y ?CC =+ Bel(Y , Want(X, Bel(Y, Accepted(X, z)))
U79(X,Y,Di, z) Y ?CC =+ Bel(Y , Want(X, Bel(Y, Perception-Problem(Y, z)))
U76(X,Y,Di, z) Y ?CC =+ Bel(Y , Want(X, Bel(Y, Execution-Problem(Y, z)))
U61(X,Y,Di, z) Y ?CC =+ Bel(Y , Bel(X, Success-Processing(X, z)))
U64(X,Y,Di, z) Y ?CC =+ Bel(Y , Bel(X, Accepted(X, z)))
U67(X,Y,Di, z) Y ?CC =+ Bel(Y , Bel(X, Perception-Problem(X, z)))
U85(X,Y,Di, z) Y ?CC =+ Bel(Y , Bel(X, Execution-Problem(Y, z)))
Table 7: Elementary update schemes for the semantics of auto- and allo-feedback functions (selection).
F (AutoPositive) = ?X.?Y.?Di.?p.U31(X,Y,Di, p) unionsq U61(X,Y,Di)
F (AlloPerceptionNegative) = ?X.?Y.?Di.?p.U33(X,Y,Di, p) unionsq U62(X,Y,Di)
F (AutoEvaluationPositive) = ?X.?Y.?Di.?p.U35(X,Y,Di, p) unionsq U64(X,Y,Di)
F (AlloExecutionNegative) = ?X.?Y.?Di.?p.U76(X,Y,Di, p) unionsq U85(X,Y,Di)
Table 8: Semantics of feedback functions (selection)
4.1.2.2 Turn Management Functions
The communicative functions for turn management serve to decide who has or will have the speaker role.
Hence the various functions for taking, accepting, grabbing, keeping, releasing, or assigning the turn are
all defined in terms in who currently occupies the speaker and who wants or should have it next.
For example, assigning the turn to somebody (Turn Assign) means that the participant A, who cur-
rently occupies the speaker role, wants the indicated other participant, B, to occupy the speaker role next.
This is expressed in the form of a combination of elementary update functions as shown in (13):
(13) F (TurnAssign)(A,B) = [?X.?Y.U101(X,Y, TurnM) unionsq U102(X,Y, TurnM ](A,B) =
= U101(A,B, TurnM) unionsq U102(X,Y, TurnM) =
= B?LiC =+ Bel(A, Current-Speaker(A)); B?LiC =+ Want(A, Next-Speaker(B))
In other words, the Linguistic Context component of B?s pending context is updated to contain the beliefs
that A is the current speaker and wants B to be the next speaker.
8
U101(X,Y,TurnM ) Y ?LiC =+ Bel(X, Current-Speaker(X))
U102(X,Y,TurnM ) Y ?LiC =+ Want(X, Next-Speaker(Y ))
U103(X,Y,TurnM ) Y ?LiC =+ Bel(X, Current-Speaker(Y ))
U104(X,Y,TurnM ) Y ?LiC =+ Wants(X, Current-Speaker(X))
U105(X,Y,TurnM ) Y ?LiC =+ Wants(X, Next-Speaker(X))
U105(X,Y,TurnM ) Y ?LiC =+ Want(X,? Next-Speaker(X))
U107(X,Y,TurnM ) Y ?LiC =+ Bel(X,? Next-Speaker(X) ? ? Next-Speaker(Y ))
U108(X,Y,TurnM ) Y ?LiC =+ Bel(X, Want(Y , Next-Speaker(X)))
Table 9: Elementary update schemes for the semantics of turn management functions.
F (TurnAccept) = ?X.?Y.?Di.U103(X,Y,Di) unionsq U105(X,Y,Di) unionsq U107(X,Y,Di)
F (TurnAssign) = ?X.?Y.?Di.U101(X,Y,Di) unionsq U102(X,Y,Di)
F (TurnGrab) = ?X.?Y.?Di.U103(X,Y,Di) unionsq U104(X,Y,Di)
F (TurnKeep) = ?X.?Y.?Di.U101(X,Y,Di) unionsq U105(X,Y,Di)
F (TurnRelease) = ?X.?Y.?Di.U101(X,Y,Di) unionsq U106(X,Y,Di)
F (TurnTake) = ?X.?Y.?Di.U105(X,Y,Di) unionsq U107(X,Y,Di)
Table 10: Update semantics of turn management functions
4.1.2.3 Time Management Functions Time management acts are used by a speaker to indicate that
he needs some time to compose his utterance, as signalled for instance by protracting (decreasing his
speech tempo) or filled pauses; or that he needs so much time that he suspends the dialogue as in Just a
moment. The semantics of such acts requires a context model to contain beliefs about the amount of time
needed by cetain cognitive processes; the DIT context model therefore assumes the representation of
estimates of amount of time to be represented in the Cognitive Context component, which also contains
other information about the speaker?s cognitive processing.
Consider for example consider the update semantics of a Stalling act:
(14)
V (<Sys,Usr, TimeM, Stalling>) = F (Stalling)(Sys, Usr, CogC)
= U111(Sys,Usr ,CogC ,Time-Need(Sys, small))
= Usr?CC =+ TimeNeed(Sys, small)
This update operation adds to the pending cognitive context of Usr the information that Sys needs a small
amount of time.
U111(X,Y,CC ) Y ?CC =+ TimeNeed(X, small)
U112(X,Y,CC ) Y ?CC =+ TimeNeed(X, substantial)
U111(X,Y,CC ) Y ?CC =+ TimeNeed(X, small)
U112(X,Y,CC ) Y ?CC =+ TimeNeed(X, substantial)
Table 11: Elementary update schemes for the semantics of time management functions.
4.1.2.4 Other Communicative Functions
The semantics of the dimension-specific communicative functions for Contact Management, Discourse
Structuring, Own Communication Management, Partner Communication Management, and Social Obli-
gations Management is quite similar to that of the dimension-specific communicative functions that
considered above. the main difference being the use of other, dimension-specific predicates.
4.2 The Interpretation of Communicative Function Qualifiers
Communicative function qualifiers come in two varieties, ?q-specifiers? and ?q-additives?. Q-specifiers
make preconditions of the communicative function that they qualify more specific, for instance spec-
ifying for an answer that there is some uncertainty about the correctness of its content. Q-additives
enrich a communicative function, for instance adding that an offer is accepted happily. Currently DIT
distinguishes two classes of q-specifiers, the ?certainty? and ?conditionality? qualifiers, and one type of
9
q-additive, for ?sentiment? representation.Qualifiers can apply only to general-purpose communicative
functions; certainty qualifiers to information-providing functions, and conditionality qualifiers to action-
discussion functions. Sentiment qualifiers can be attached in principle to every communicative function.
For the semantics of qualified communicative functions we thus have three possible cases to consider,
where fi is an unqualified communicative function: (a) ?fi, qsj? where qsj is a q-specifier; (b) ?fi, qak?
where qak is a q-additive; and (c) ?fi, qsj , ask? where qsj is a q-specifier and qak is a q-additive. The
following clauses in the definition of the recursive valuation function V for DiAML specify the semantic
interpretation in each of these cases:
(15) a. V (?fi, qsj?) = (F (fi))(F (qsj))
b. V (?fi, qak?) = ?S.?z.[(F (fi))(S, z) unionsq (F (qak))(S, z)]
c. V (?fi, qsj , qak?) = ?S.?z.[((F (fi))(F (qsj)))(S, z) unionsq (F (qak))(S, z)]
The semantics of each of the individual qualifiers is defined as follows:
(16)
F (certain) = ?firm?
F (uncertain) = ?weak?
F (conditional) = ?cond?
F (unconditional) = > (the ?empty? condition)
F (sentimentk) = ?X.?u. SENTIMENT-PREDICATEk(X,u)
We consider two examples. The first illustrates the semantics of an answer, qualified as uncertain, as
in (17) (?p5? abbreviates the proposition that the train to Tilburg leaves from platform 5):
(17) 1. A: Does the train to Tilburg leave from platform 5?
2. B: I think so, probably yes.
(18)
V (?B,A,Task, p5, ?Answer, uncertain?) = V (?Answer, uncertain?)(A,B,Task, p5)
= B?i =+ Bel(B, U1(A,B,Task, p5,weak) unionsq U2(A,B,Task, p5,weak) unionsq U9(A,B, Task, p)
unionsq U7(A,B, Tak, p)
= A?SemC =+ Bel(A, Want(B,Bel(A, p, weak))); A?SemC =+ Bel(A, Bel(B, p, weak));
A?SemC =+ Bel(A, Bel(B, Want(A, Know-val(A, p))));
A?SemC =+ Bel(A, Bel(B, Assume(A, Know-val(B, p))))
This means that A?s pending semantic context is extended with the following pieces of information:
(19) 1. Bel(B, p5,weak), or equivalently: Wk-Bel(B, p5); i.e., B holds the uncertain belief that p5;
2. Want(B, Wk-Bel(A, p5)), i.e. B has the goal that A also holds this uncertain belief;
3. Bel(B, Want(A, Know-val(A, p))), i.e. B believes that A wants to know whether p5.
4. Bel(B,Assume(A, Know-val(B, p))): B believes that A assumes that B knows whether p5.
Second, example (20) illustrates the semantics of an unconditional Accept Offer with a happy sentiment
(as in A: How about a cup of coffee? B: Oh yes, that would be wonderful!), using (15c).
(20)
V (?AcceptOffer, unconditional, happy?) =
= ?S.?z.[[F (AcceptOffer)(F (unconditional))](S, z) unionsq [F (happy)](S, z)]
= ?S.?z.[[[?X.?Y.?Di.??.?C?. U24(X,Y,Di, ?) unionsq U25(X,Y,Di, ?, C?) unionsq
U25b(X,Y,Di, ?, C?)](>)](S, z) unionsq HAPPY(S, z))]
= [[?S.?Y.?Di.?z.?Cz. U24(S, Y,Di, z) unionsq U25(S, Y,Di, z,>) unionsq
U25b(S, Y,Di, z,>)] unionsq HAPPY(S, z))]
Applied to the participants A and B and the action ?coffee?, we obtain:
(21)
= A?Task=+ Bel(A, Want(B,CommitDo(A, coffee)));
A?Task =+ Bel(A, Bel(B, WilDo(A, coffee)));
A?Task =+ Bel(A, Bel(B, Want(A, Bel(B, WilDo(A, coffee)))));
A?CC =+ HAPPY(B, coffee))]
10
In other words, the Task component of A?s pending context is extended with the beliefs that B wants
A to commit himself to arrange coffee; that A is willing to do s o; and that A wants B to believe that.
Moreover, the understanding thatB is happy to get some coffee is represented in the cognitive component
of A?s pending context.
Concerning the certainty regarding the correctness of provided information, as represented through
certainty qualifiers, the unmarked case in natural language is certain. A speaker who is quite certain about
something may indicate this by expressions like definitely, most certainly, but this tends to occur only
when doubt or disbelief has expressed about something that was claimed. When there is no expression
of uncertainty, the speaker?s utterance is therefore interpreted as expressing certainty. For conditionality,
the unmarked case is unconditional; an unconditional commitment or willingness to perform a certain
action can be expressed explicitly, but this tends to occur only if some doubt has been expressed about
someone?s commitment or willingness. When no conditions for performing an action are expressed, we
therefore interpret the utterance as unconditional.
5 Conclusion and Future Work
This paper has outlined an update semantics of dialogue acts, associated with annotation structures de-
fined by the abstract syntax of the DIAML language for semantic annotation, which forms part of ISO
standard (24617-2) under development for dialogue act annotation.
Future work that?s crying to be done includes further implementation, testing and evaluation beyond
what has already been done (see Petukhova, Bunt and Malchanau, 2010; Keizer, Bunt and Petukhova,
2010), and supplementing the approach with an interpretation of the relations between dialogue acts and
other units in dialogue (see Petukhova, Pre?vot and Bunt, 2011).
Acknowledgements
I thank the members of the Tilburg Dialogue Club, who over the years have contributed to shaping
Dynamic Interpretation Theory, as well as PhD students and colleagues in related projects. This includes
Volha Petukhova, Jeroen Geertzen, Simon Keizer, Roser Morante, Amanda Schiffrin, Ielka van der Sluis,
Hans van Dam, Yann Girard, Rintse van der Werff, Elyon Dekoven, Paul Piwek, Robbert-Jan Beun, Rene?
Ahn, and Leen Kievit. Important contributions have also come from collaborative work in ISO project
24617-2 ?Semantic Annotation Framework, Part 2: Dialogue Acts?, in particular with David Traum.
References
Ahn, R. (2001). Agents, Object and Events: A computational approach to knowledge, observation and
communication. PhD Thesis, Eindhoven University of Technology.
Bunt, H. (2000). Dialogue pragmatics and context specification. In H. Bunt and W. Black (Eds.), Abduc-
tion, Belief and Context in Dialogue. Studies in Computational Pragmatics, pp. 81?150. Amsterdam:
John Benjamins.
Bunt, H. (2006). Dimensions in dialogue annotation. In Proceedings of the 5th International Conference
on Language Resources and Evaluation (LREC 2006), Genova, Italy, Paris, pp. 919?924. ELRA.
Bunt, H. (2009). Multifunctionality and muldimensional dialogue semantics. In Proceedings of Dia-
Holmia, 13th Workshop on the Semantics and Pragmatics of Dialogue, Stockholm, pp. 3?14.
Bunt, H. (2010). A methodology for designing semantic annotation languages. In Proceedings of the 2nd
International Conference on Global Interoperability for Language Resources, Hong Kong, pp. 29?46.
Bunt, H. (2011a). Formal specification of an update semantics for dialogue acts. TiCC Technical Report
TR 2011-001, Tilburg Center for Cognition and Communication.
11
Bunt, H. (2011b). Multifunctionality in dialogue and its interpretation. Computer, Speech and Lan-
guage (25), 225 ? 245.
Bunt, H. (forthc.). Interpretation and generation of dialogue with multidimensional context models. In
A. Esposito (Ed.), Toward Autonomous, adaptive, and context-aware multimedia interfaces, pp. 81?
131. Berlin: Springer.
Bunt, H., J. Alexandersson, J. Carletta, J.-W. Choe, A. Fang, K. Hasida, K. Lee, V. Petukhova,
A. Popescu-Belis, L. Romary, C. Soria, and Traum (2010). Towards an ISO standard for dialogue
act formal annotation. In Proceedings 7th International Conference on Language Resources and
Evaluation (LREC 2010), Malta. Paris: ELRA.
Cooper, R. (2000). Information states, attitudes and dependent record types. In L. Cavedon, P. Blackburn,
N. Braisby, and A. Shimojima (Eds.), Logic, Language and Computation, Vol 3, pp. 85?106. Stanford:
CSLI Publications.
Core, M. and J. Allen (1997). Coding dialogs with the DAMSL annotation schema. In AAAI Fall
Symposium on Communicative Action in Humans and Machines, Boston, MA.
Ide, N. and H. Bunt (2010). Anatomy of semantic annotation schemes: Mappings to GrAF. In Proceed-
ings of the4th Linguistic Annotation Workshop (LAW-IV), Uppsala.
Ide, N. and L. Romary (2004). International standard for a linguistic annotation framework. Natural
Language engineering 10, 211?225.
ISO (2010). DIS 24617-2: Semantic annotation framework Part 2: Dialogue acts. ISO, Geneva: Draft
International Standard, July 2010.
Kievit, L., P.Piwek, R.-J. Beun, and H. Bunt (2001). Multimodal cooperative resolution of referential
expressions in the DenK system. In H. Bunt and R.-J. Beun (Eds.), Cooperative Multimodal Commu-
nication, pp. 197?214. Berlin: Springer.
Morante, R. (2007). Computing meaning in interaction. Ph.D. Dissertation, Tilburg University.
Petukhova, V. and H. Bunt (2009a). Dimensions in communication. TiCC Technical Report TR 2009-
003, Tilburg University.
Petukhova, V. and H. Bunt (2009b). The independence of dimensions in multidimensional dialogue act
annotation. In Proceedings NAACL HLT Conference, Boulder, Colorado.
Petukhova, V., H. Bunt, and A. Malchanau (2010). Empirical and theoretical constraints on dialogue act
combinations. In Proceedings 14th Workshop on the Semantics and Pragmatics of Dialogue, Poznan.
Poesio, M. and D. Traum (1998). Towards an axiomatisation of dialogue acts. In Proceedings of the
twente Workshop on the Semantics and Pragmatics of Dialogue, Enschede, pp. 207 ? 222.
Traum, D. and S. Larsson (2003). The information state approach to dialogue management. In Current
and New Directions in Discourse and Dialogue, Kluwer, Dordrecht, pp. 325 ? 345.
12
Appendix: The DIT++ taxonomy of communicative functions
General-purpose functions
HHHHHHHHHj
Information-transfer functions
Information-seeking functions
?
Question
    	
@@@@R?
?
Choice
Question
Propositional Q
Check Q
?
Set Q
?
Posi-Check Nega-Check
@@@@R
Action-discussion functions
@@@@R
@@@@R
    	
Information-providing
functions
Inform
    	
Answer
    	
@@@@R
Disconfirm Confirm
?
Agreement Disagreement
?
Correction
@@@@R
Commissives
?
@@@@R
Offer
?
Address
Suggestion
?
Accept
Suggestion
@@@@R
Decline
Suggestion
Promise
?
Address
Request
@@@@R
    	
Accept
Request
Decline
Request
Directives
@@@@R
    	
RequestSuggestion
?
Instruct
?
Address
Offer
    	
Decline
Offer
?
Accept
Offer
Figure 1: General-purpose functions
Dimension-specific functions9
)

    	 ?
@@@@R
HHHHHHHHj
PPPPPPPPPPPPq
XXXXXXXXXXXXXXXXz
Auto-Feedback
?
Positive
Negative
Pos. Attention
Pos. Perception
(...)
Pos. Execution
Neg. Attention
(...)
Neg. Execution
Allo-Feedback
?
Positive
Negative
Elicitation
(...)
Time
?
Stalling
Pausing
Contact
?
C-Indication
C-Check
PCM
?
Completion
Correct-
misspeaking
Turn
?    	
@@@@R
Turn-initial
?
Turn Accept
Turn Take
Turn Grab
Turn-final
?
Turn Assign
Turn Release
Turn Keep
OCM
?
Error sign.
Retract
Self-
correction
DS
?
Opening
Pre-
closing
(...)
SOM
?
I-Greeting
R-Greeting
Self-Intro
R-Self-Intro
Apology
Accept-Ap.
Thanking
Acc.-Thanking
I-Goodbye
R-Goodbye
Figure 2: Dimension-specific communicative functions
13
Incremental dialogue act understanding
Volha Petukhova
Tilburg Center for Creative Computing
Tilburg University, The Netherlands,
v.petukhova@uvt.nl
Harry Bunt
Tilburg Center for Creative Computing
Tilburg University, The Netherlands,
harry.bunt@uvt.nl
Abstract
This paper presents a machine learning-based approach to the incremental understanding of dia-
logue utterances, with a focus on the recognition of their communicative functions. A token-based
approach combining the use of local classifiers, which exploit local utterance features, and global
classifiers which use the outputs of local classifiers applied to previous and subsequent tokens, is
shown to result in excellent dialogue act recognition scores for unsegmented spoken dialogue. This
can be seen as a significant step forward towards the development of fully incremental, on-line meth-
ods for computing the meaning of utterances in spoken dialogue.
1 Introduction
When reading a sentence in a text, a human language understander obviously does not wait trying to
understand what he is reading until he has come to the end of the sentence. Similarly for participants
in a spoken conversation. There is overwhelming psycholinguistic evidence that human understanders
construct syntactic, semantic, and pragmatic hypotheses on the fly, while receiving the written or spoken
input. Dialogue phenomena such as backchannelling (providing feedback while someone else is speak-
ing), the completion of a partner utterance, and requests for clarification that overlap the utterance of the
main speaker, illustrate this. Evidence from the analysis of nonverbal behaviour in multimodal dialogue
lends further support to the claim that human understanding works incrementally, as input is being re-
ceived. Dialogue participants start to perform certain body movements and facial expressions that are
perceived and interpreted by others as dialogue acts (such as head nods, smiles, frowns) while another
participant is speaking, see e.g. Petukhova and Bunt (2009). As another kind of evidence, eye-tracking
experiments by Tanenhaus et al (1995), Sedivy et al (1999) and Sedivy (2003) showed that definite
descriptions are resolved incrementally when the referent is visually accessible.
Traditional models of language understanding for dialogue systems, by contrast, are pipelined, mod-
ular, and operate on complete utterances. Typically, such a system has an automatic speech recognition
module, a language understanding module responsible for syntactic and semantic analysis, an interpre-
tation manager, a dialogue manager, a natural language generation module, and a module for speech
synthesis. The output of each module is the input for another. The language understanding module typ-
ically performs the following tasks: (1) segmentation: identification of relevant segments in the input,
such as sentences;(2) lexical analysis: lexical lookup, possibly supported by morphological processing,
and by additional resources such as WordNet, VerbNet, or lexical ontologies; (3) parsing: construction
of syntactic interpretations; (4) semantic analysis: computation of propositional, referential, or action-
related content; and (5) pragmatic analysis: determination of speaker intentions.
Of these tasks, lexical analysis, being concerned with local information at word level, can be done
for each word as soon as it has been recognized, and is naturally performed as an incremental part
of utterance processing, but syntactic, semantic and pragmatic analysis are traditionally performed on
complete utterances. Tomita?s pioneering work in left-to-right syntactic parsing has shown that incre-
mental parsing can be much more efficient and of equal quality as the parsing of complete utterances
(Tomita (1986)). Computational approaches to incremental semantic and pragmatic interpretation have
235
been less successful (see e.g. Haddock (1989); Milward and Cooper (2009)), but work in computational
semantics on the design of underspecified representation formalisms has shown that such formalisms,
developed originally for the underspecified representation of quantifier scopes, can also be applied in
situations where incomplete input information is available (see e.g. Bos (2002); Bunt (2007), Hobbs
(1985), Pinkal (1999)) and as such hold a promise for incremental semantic interpretation.
Pragmatic interpretation, in particular the recognition of a speaker?s intentions in incoming dialogue
utterances, is another major aspect of language understanding for dialogue systems. Computational
modelling of dialogue behaviour in terms of dialogue acts aims to capture speaker intentions in the com-
municative functions of dialogue acts, and offers an effective integration with semantic content analysis
through the information state update approach (Poesio and Traum (1998)). In this approach, a dialogue
act is viewed as having as its main components a communicative function and a semantic content, where
the semantic content is the referential, propositional, or action-related information that the dialogue act
addresses, and the communicative function defines how an understander?s information state is to be up-
dated with that information.
Evaluation of a non-incremental dialogue system and its incremental counterpart reported in Aist
et al (2007) showed that the latter is faster overall than the former due to the incorporation of pragmatic
information in early stages of the understanding process. Since users formulate utterances incrementally,
partial utterances may be available for a substantial amount of time and may be interpreted by the system.
An incremental interpretation strategy may allow the system to respond more quickly, by minimizing the
delay between the time the user finishes and the time the utterance is interpreted DeVault and Stone
(2003).
This suggests that a dialogue system performance may benefit from reliable partial processing of
input. This paper is concerned with the automatic recognition of dialogue acts based on partially available
input and shows that in order to arrive at the best output prediction two different classification strategies
are needed: (1) local classification that is based on features observed in dialogue behaviour and that can
be extracted from the annotated data; and (2) global classification that takes the locally predicted context
into account.
This paper is structured as follows. In Section 2 we will outline performed experiments describing
the data, tagset, features, algorithms and evaluation metrics that have been used. Section 3 reports on the
experimental results, applying a variety of machine learning techniques and feature selection algorithms,
to assess the automatic recognition and classification of dialogue acts using simultaneous incremental
segmentation and dialogue act classification. In Section 4 we discuss strategies in management and
correction of the output of local classifies. Section 5 concludes.
2 Incremental understanding experiments
2.1 Related work
Nakano et al (Nakano et al (1999)) proposed a method for the incremental understanding of utterances
whose boundaries are not known. The Incremental Sentence Sequence Search (ISSS) algorithm finds
plausible boundaries of utterances, called significant utterances (SUs), which can be a full sentence or a
subsentential phrase, such as a noun phrase or a verb phrase. Any phrase that can change the belief state
is defined as a SU. In this sense an SU corresponds more or less with what we call a ?functional segment?,
which is defined as a minimal stretch of behaviour that has a communicative function (see Bunt et al
(2010)). ISSS maintains multiple possible belief states, and updates these each time a word hypothesis
is input. The ISSS approach does not deal with the multifunctionality of segments, however, and does
not allow segments to overlap.
Lendvai and Geertzen (Lendvai and Geertzen (2007)) proposed token-based dialogue act segmenta-
tion and classification, which was worked out in more detail in Geertzen (2009). This approach takes
dialogue data that is not segmented into syntactic or semantic units, but operates on the transcribed speech
as a stream of words and other vocal signs (e.g. laughs), including disfluent elements (e.g. abandoned
236
Dimension Frequency General-purpose function Frequency
Task 31.8 PropositionalQuestion 5.8
Auto-Feedback 20.5 Set Question 2.3
Allo-Feedback 0.7 Check Question 3.3
Turn Management 50.2 Propositional Answer 9.8
Social Obligation Management 0.5 Set Answer 3.9
Discourse Structuring 2.8 Inform 11.7
Own Communication Management 10.3 InformRhetorical 21.9
Time Management 26.7 Instruct 0.3
Partner Communication Management 0.3 Suggest 10.1
Contact Management 0.1 Request 5.6
Table 1: Distribution of functional tags across dimensions and general-purpose functions for the AMI corpus (in
%).
or interrupted words). Segmentation and classification of dialogue acts are performed simultaneously in
one step. Geertzen (2009) reports on classifier performance on this task for the DIAMOND data1 using
DIT++ labels. The success scores in terms of F-scores range from 47.7 to 81.7. It was shown that per-
forming segmentation and classification together results in better segmentation, but affects the dialogue
act classification negatively.
The incremental dialogue act recognition system proposed here takes the token-based approach for
building classifiers for the recognition (segmentation and classification) of multiple dialogue acts for each
input token, and adopts the ISSS idea for information-state updates based on partial input interpretation.
2.2 Tagset
The data selected for the experiments was annotated with the DIT++ tagset Release 42. The DIT tax-
onomy distinguishes 10 dimensions, addressing information about: the domain or task (Task), feedback
on communicative behaviour of the speaker (Auto-feedback) or other interlocutors (Allo-feedback), man-
aging difficulties in the speaker?s contributions (Own-Communication Management) or those of other
interlocutors (Partner Communication Management), the speaker?s need for time to continue the di-
alogue (Time Management), establishing and maintaining contact (Contact Management), about who
should have the next turn (Turn Management), the way the speaker is planning to structure the dialogue,
introducing, changing or closing a topic (Dialogue Structuring), and conditions that trigger dialogue acts
by social convention (Social Obligations Management), see Table 1.
For each dimension, at most one communicative function can be assigned, which is either a function
that can occur in this dimension alone (a dimension-specific (DS) function) or a function that can occur in
any dimension (a general-purpose (GP) function). Dialogue acts with a DS communicative function are
always concerned with a particular type of information, such as a Turn Grabbing act, which is concerned
with the allocation of the speaker role, or a Stalling act, which is concerned with the timing of utterance
production. GP functions, by contrast, are not specifically related to any dimension in particular, e.g.
one can ask a question about any type of semantic content, provide an answer about any type of content,
or request the performance of any type of action (such as Could you please close the door or Could you
please repeat that). These communicative functions include Question, Answer, Request, Offer, Inform,
and many other familiar core speech acts.
The tagset used in these studies contains 38 dimension-specific functions and 44 general-purpose
functions. A tag consists either of a pair consisting of a communicative function (CF ) and the addressed
dimension (D).
1For more information see Geertzen,J., Girard,Y., and Morante,R. 2004. The DIAMOND project. Poster at the 8th Work-
shop on the Semantics and Pragmatics of Dialogue (CATALOG 2004).
2For more information about the tagset and the dimensions that are identified, please visit:http://dit.uvt.nl/ or see
Bunt (2009).
237
Speaker Token Task Auto-F. Allo-F. TurnM. TimeM. ContactM. DS OCM PCM SOM
B it B;inf O O O O O O O O O
B has I:inf O O O O O O O O O
B to I:inf O O O O O O O O O
B look I:inf O O O O O O O O O
B you O O B:check O O O O O O O
B know O O E:check O O O O O O O
B cool I:inf O O O O O O O O O
D mmhmm O BE:positive O O O O O O O O
B and I:inf O O BE:t keep O O O O O O
B gimmicky E:inf O O O O O O O O O
Figure 1: Segment boundaries and dialogue act label encoding in different dimensions.
2.3 Features and data encoding
In the recognition experiments we used data from the AMI meeting corpus3. For training we used three
annotated AMI meetings that contain 17,335 tokens forming 3,897 functional segments. The distribution
of functional tags across dimensions is given in Table 1.
Features extracted from the data considered here relate to dialogue history: functional tags of the
10 previous turns; timing: token duration and floor-transfer offset4 computed in milliseconds; prosody:
minimum, maximum, mean, and standard deviation for pitch (F0 in Hz), energy (RMS), voicing (fraction
of locally unvoiced frames and number of voice breaks) and speaking rate (number of syllables per
second)5; and lexical information: token occurrence, bi- and trigram of those tokens. In total, 1,668
features are used for the AMI data.
To be able to identify segment boundaries, we assign to each token its communicative function label
and indicate whether a token starts a segment (B), is inside a segment (I), ends a segment (E), is out-
side a segment (O), or forms a functional segment on its own (BE). Thus, the class labels consist of a
segmentation prefix (IBOE) and a communicative function label, see example in Figure 1.
2.4 Classifiers and evaluation metrics
Awide variety of machine-learning techniques has been used for NLP tasks with various instantiations of
feature sets and target class encodings. For dialogue processing, it is still an open issue which techniques
are the most suitable for which task. We used two different types of classifiers to test their performance
on our dialogue data: a probabilistic one and a rule inducer.
As a probabilistic classifier we used Bayes Nets. This classifier estimates probabilities rather than
produce predictions, which is often more useful because this allows us to rank predictions. Bayes Nets
estimate the conditional probability distribution on the values of the class attributes given the values of
the other attributes.
As a rule induction algorithm we chose Ripper (Cohen (1995)). The advantage of a rule inducer is
that the regularities discovered in the data are represented as human-readable rules.
The results of all experiments were obtained using 10-fold cross-validation.7 As a baseline it is
common practice to use the majority class tag, but for our data sets such a baseline is not very useful
because of the relatively low frequencies of the tags in some dimensions. Instead, we use a baseline
3The A
?
ugmented M
?
ulti-party I
?
nteraction meeting corpus consists of multimodal task-oriented human-human multi-party
dialogues in English, for more information visit (http://www.amiproject.org/
4Difference between the time that a turn starts and the moment the previous turn ends.
5These features were computed using the PRAAT tool6. We examined both raw and normalized versions of these features.
Speaker-normalized features were obtained by computing z-scores (z = (X-mean)/standard deviation) for the feature, where
mean and standard deviation were calculated from all functional segments produced by the same speaker in the dialogues. We
also used normalizations by first speaker turn and by previous speaker turn.
7In order to reduce the effect of imbalances in the data, it is partitioned ten times. Each time a different 10% of the data is
used as test set and the remaining 90% as training set. The procedure is repeated ten times so that in the end, every instance has
been used exactly once for testing and the scores are averaged. The cross-validation was stratified, i.e. the 10 folds contained
approximately the same proportions of instances with relevant tags as in the entire dataset.
238
that is based on a single feature, namely, the tag of the previous dialogue utterance (see Lendvai et al
(2003))).
Several metrics have been proposed for the evaluation of a classifier?s performance: error metrics
and performance metrics. The word-based error rate metric, introduced in Ang et al (2005), measures
the percentage of words that were placed in a segment perfectly identical to that in the reference. The
dialogue act based metric (DER) was proposed in Zimmermann et al (2005). In this metric a word is
considered to be correctly classified if and only if it has been assigned the correct dialogue act type and
it lies in exactly the same segment as the corresponding word of the reference. We will use the combined
DERsc error metric to evaluate joint segmentation (s) and classification (c):
DERsc =
Tokens with wrong boundaries and/or function class
total number of tokens
? 100
To assess the quality of classification results, the standard F-score metric is used, which represents
the balance between precision and recall.
3 Classification results
Dialogue utterances are often multifunctional, having a function in more than one dimension (see e.g.
Bunt (2010)). This makes dialogue act recognition a complex task. Splitting up the output structure may
make the task more manageable; for instance, a popular strategy is to split a multi-class learning task
into several binary learning tasks. Sometimes, however, learning of multiple classes allows a learning
algorithm to exploit the interactions among classes. We will combine these two strategies. We have built
in total 64 classifiers for dialogue act recognition for the AMI data. Some of the tasks were defined as
binary ones, e.g. the dimension recognition task, others are multi-class learning tasks.
We first trained classifiers to recognize the boundaries of a segment and its communicative functions
(joint multi-class learning task) per dimension, see Table 2.
BL BayesNet Ripper
Dimensions F1 DERsc F1 DERsc F1 DERsc
Task 32.7 51.2 52.1 48.7 66.7 42.6
Auto-Feedback 43.2 84.4 62.7 33.9 60.1 45.6
Allo-Feedback 70.2 59.5 73.7 35.1 71.3 49.1
Turn Management:initial 34.2 95.2 57.0 58.4 54.3 81.3
Turn Management:close 33.3 92.7 54.2 46.9 49.3 87.3
Time Management 43.7 96.5 64.5 46.1 61.4 53.1
Discourse Structuring 41.2 35.1 72.7 19.9 50.2 30.9
Contact Management 59.9 53.2 71.4 49.9 83.3 37.2
Own Communication Management 36.5 87.9 68.3 51.3 58.3 76.8
Partner Communication Management 49.5 59.0 58.5 45.5 51.4 58.7
Social Obligation Management 34.5 47.5 86.5 35.9 83.3 44.3
Table 2: Overview of F-scores and DERsc for the baseline (BL) and the classifiers for joint segmentation and
classification for each DIT++ dimension, for the data of the AMI corpus.
The results show that both classifiers outperform the baseline by a broad margin. The Bayes Nets
classifier marginally outperforms the Ripper rule inducer, but shows no significant differences in overall
performance. Though the results obtained are quite encouraging, the performance on the joint segmen-
tation and classification task does not outperforms the two-step segmentation and classification task re-
ported in Geertzen et al (2007). There is a drop in F-scores compared to the results reported by Geertzen
et al (2007), which is explained by the fact that recall was quite low. This means that the classifiers
missed a lot of relevant cases. Looking more closely at the predictions made by the classifiers, we no-
ticed that beginnings and endings of many segments were not found. For example, the beginnings of Set
Questions are identified with perfect precision (100%), but about 60% of the segment beginnings were
not found. The reason that the classifiers still show a reasonable performance is that most tokens occur
239
inside segments and are better classified, e.g. the inside-tokens of Set Questions are classified with high
precision (83%) and reasonably high recall scores (76%). Still, this is rather worrying, since the correct
identification of, in particular, the start of a relevant segment is crucial for future decisions. These obser-
vations led us to the conclusion that the search space and the number of initially generated hypotheses
for classifiers should be reduced, and we split the classification task in such a way that a classifier needs
to learn one particular type of communicative function.
We trained a classifier for each general-purpose and dimension-specific function defined in the
DIT++ taxonomy, and observed that this has the effect that the various classifiers perform significantly
better. These functions were learned (1) in isolation; (2) as semantically related functions together, e.g.
all information-seeking functions (all types of questions) or all information-providing functions (all an-
swers and all informs). Both the recognition of communicative functions and that of segment boundaries
improves significantly. Table 3 gives an overview of the overall performance (best obtained scores) of
the trained classifiers after splitting the learning task.
BL BayesNet Ripper
Classification task F1 DERsc F1 DERsc F1 DERsc
General-purpose functions
Propositional Questions 47.0 39.1 94.9 3.9 75.8 23.5
Check Questions 43.8 56.4 68.5 19.6 61.3 33.1
Set Questions 44.8 52.1 74.1 18.6 76.3 17.7
Inform 45.8 39.9 79.8 18.7 66.5 30.5
Inform Rhetorical 37.2 38.9 69.1 13.4 68.7 23.9
Agreement 41.3 79.1 72.1 12.6 71.6 60.2
Propositional Answer 32.0 77.8 66.8 26.1 52.2 53.8
Set Answer 44.3 54.2 77.5 13.2 57.3 44.1
Suggest 45.8 38.4 65.6 17.3 48.8 35.6
Request 45.8 49.3 75.8 14.5 50.3 36.9
Instruct 46.3 49.3 60.5 14.5 46.3 36.9
Dimension-specific functions
Auto-Feedback 57.1 23.5 78.8 13.2 66.7 15.5
Allo-Feedback 89.3 4.4 95.1 2.9 94.3 3.9
Turn Management:initial 24.8 21.9 72.8 7.4 46.3 10.7
Turn Management:close 30.7 64.9 62.0 22.5 54.7 39.6
Time management 68.3 32.3 82.4 13.7 92.8 11.4
Discourse Structuring 40.7 13.6 72.6 2.5 74.5 1.7
Contact Management 21.4 48.6 89.2 5.7 92.3 3.6
Own Communication Management 26.7 48.6 78.0 11.6 68.1 20.0
Partner Communication Management 33.4 18.2 77.8 8.5 88.9 6.5
Social Obligation Management 60.0 18.7 88.9 8.3 90.1 5.5
Table 3: Overview of F-scores and DERsc for the baseline (BL) and the classifiers upon joint segmentation
and classification task for each DIT++ communicative function or cluster of functions. (Best scores indicated by
numbers in bold face.)
Segments having a general-purpose functions may address any of the ten DIT dimensions. The task
of dimension recognition can be approached in two ways. One approach is to learn segment boundaries,
communicative function label and dimension in one step (e.g. the class label B:task;inform). This task is
very complicated, however. First, it leads to data which are high dimensional and sparse, which will have
a negative influence on the performance of the trained classifiers. Second, in many cases the dimension
can be recognized reliably only with some delay; for the first few segment tokens it is often impossible
to say what the segment is about. For example:
(1) 1. What do you think who we?re aiming this at?
2. What do you think we are doing next?
3. What do you think Craig?
The three Set Questions in (1) start with exactly the same words, but they address different dimensions:
Question 1 is about the Task (in AMI - the design the television remote control); Question 2 serves the
240
purpose of Discourse Structuring; and Question 3 elicits feedback.
Another approach is to first recognize segment boundaries and communicative function, and define
dimension recognition as a separate classification task.
Tokens SetQuestion Task Auto-F. TurnM. Complex label (BIOE:D;CF)
label p label p label p label p label p
what B:setQ 0.85 O 0.71 O 1 O 0.68 O 0.933
you I:setQ 1 task 0.985 O 1 B:give 0.64 O 0.869
guys I:setQ 1 task 0.998 O 1 E:give 0.66 O 0.937
have I:setQ 1 task 0.997 O 1 O 1 I:task;setQ 0.989
already I:setQ 1 task 0.996 O 1 O 0.99 I:task;setQ 0.903
received I:setQ 1 task 0.987 O 1 O 1 I:task;setQ 0.813
um O 0.93 O 0.89 O 1 BE:keep 0.99 O 0.982
in I:setQ 1 task 0.826 O 1 O 0.89 I:task;setQ 0.875
your I:setQ 1 task 0.996 O 1 O 0.99 I:task;setQ 0.948
mails E:setQ 0.99 task 0.987 O 1 O 1 E:task;setQ 0.948
Figure 2: Predictions with indication of confidence scores (highest p class probability selected) for each token
assigned by five trained classifiers simultaneously.
We tested both strategies. The F-scores for the joint learning of complex class labels range from
23.0 (DERsc = 68.3) to 45.3 (DERsc = 63.8). For dimension recognition as a separate learning task
the F-scores are significantly higher, ranging from 70.6 to 97.7. The scores for joint segmentation and
function recognition in the latter case are those listed in Table 3. Figure 2 gives an example of predictions
made by five classifiers for the input what you guys have already received um in your mails.
4 Managing local classifiers
4.1 Global classification and global search
As shown in the previous section, given a certain input we obtain all possible output predictions (hypothe-
ses) from local classifiers. Some predictions are false, but once a local classifier has made a decision it
is never revisited. It is therefore important to base the decision on dialogue act labels not only on local
features of the input, but to take other parts of the output into account as well. For example, the partial
output predicted so far, i.e. the history of previous predictions, may be taken as features for the next
classification step, and helps to discover and correct errors. This is known as ?recurrent sliding window
strategy? (see Dietterich (2002)) when the true values of previous predictions are used as features. This
approach suffers from the label bias problem, however, when a classifier overestimates the importance
of certain features, and moreover does not apply in a realistic situation, since the true values of previous
predictions are not available to a classifier in real time. A solution proposed by Van den Bosch (1997) is
to apply adaptive training using the predicted output of previous steps as features.
We trained higher-level classifiers (often referred to as ?global?) that have, along with features ex-
tracted locally from the input data as described above, the partial output predicted so far from all local
classifiers. We used five previously predicted class labels, assuming that long distance dependencies
may be important, and taking into account that the average length of a functional segment in our data
is 4.4 tokens. Table 4 gives an overview of the results of applying these global classifiers. We see that
the global classifiers make more accurate predictions than the local classifiers, showing an improvement
of about 10% on average. The classifiers still make some incorrect predictions, because the decision
is sometimes based on incorrect previous predictions. An optimized global search strategy may lead to
further improvements of these results.
A strategy to optimize the use of output hypotheses, is to perform a global search in the output space
looking for best predictions. Our classifiers do not just predict the most likely class for an instance,
but also generate a distribution of output classes. Class distributions can be seen as confidence scores
of all predictions that led to a certain state. Our confidence models are constructed based on token
level information given the dialogue left-context (i.e. dialogue history, wording of the previous and
241
Classification task BayesNet Ripper
F1 DERsc F1 DERsc
Task 65.3 14.9 79.1 21.8
Auto-Feedback 72.9 8.1 77.8 7.2
Allo-Feedback 67.7 10.9 74.2 9.5
Turn Management:initial 72.2 11.5 69.5 11.4
Turn Management:close 82.7 5.0 83.0 4.9
Time Management 70.0 3.0 73.5 2.1
Discourse Structuring 72.3 4.9 63.7 3.6
Contact Management 79.1 4.5 84.3 4.6
Own Communication Management 66.0 2.4 68.3 2.3
Partner Communication Management 63.2 7.8 59.5 11.4
Social Obligation Management 88.4 0.9 81.6 1.7
Table 4: Overview of F-scores and DERsc of the global classifiers for the AMI data based on added previous
predictions of local classifiers.
currently produced functional segment). This is particular useful for dialogue act recognition because
the recognition of intentions should be based on the system?s understanding of discourse and not just on
the interpretation of an isolated utterance. Searching the (partial) output space for the best predictions
is not always the best strategy, however, since the highest-ranking predictions are not always correct
in a given context. A possible solution to this is to postpone the prediction until some (or all) future
predictions have been made for the rest of the segment. For training, the classifier then uses not only
previous predictions as additional features, but also some or all future predictions of local classifiers (till
the end of the current segment or to the beginning of the next segment, depending on what is recognized).
This forces the classifier to not immediately select the highest-ranking predictions, but to also consider
lower-ranking predictions that could be better in the context of the rest of the sequence.
Classification task BayesNet Ripper
F1 DERsc F1 DERsc
Task 82.6 9.5 86.1 8.3
Auto-Feedback 81.9 1.9 95.1 0.6
Allo-Feedback 96.3 0.6 95.7 0.5
Turn Management:initial 85.7 1.5 81.5 1.6
Turn Management:close 90.9 3.8 91.2 3.6
Time management 90.4 2.4 93.4 1.7
Discourse Structuring 82.1 1.7 78.3 1.8
Contact Management 87.9 1.2 94.3 0.6
Own Communication Management 78.4 2.2 81.6 2.0
Partner Communication Management 71.8 2.4 70.0 4.6
Social Obligation Management 98.6 0.4 98.6 0.5
Table 5: Overview of F-scores and DERsc of global classifiers for the AMI data per DIT++ dimension.
The results show the importance of optimal global classification for finding the best output prediction.
We performed similar experiments on the English MapTask data8 and obtained comparable results,
where F-scores on the global classification task range from 66.7 for Partner CommunicationManagement
and Discourse Structuring to 79.7 for Task and 91.2 for Allo-Feedback. For the MapTask corpus the
performance of human annotators on segmentation and classification has been assessed; standard kappa
scores reported in Bunt et al (2007) range between 0.92 and 1.00, indicating near perfect agreement
between two expert annotators9.
8For more information about the MapTask corpus see http://www.hcrc.ed.ac.uk/maptask/
9Note, however, that a slightly simplified version of the DIT++ tagset has been used here, called the LIRICS tagset, in
which the five DIT levels of processing in the Auto- and Allo-Feedback dimensions were collapsed into one.
242
5 Conclusions and future research
The incremental construction of input interpretation hypotheses is useful in a language understanding
system, since it has the effect that the understanding of a relevant input segment is already nearly ready
when the last token of the segment is received; when a dialogue act is viewed semantically as a recipe for
updating an information state, this means that the specification of the update operation is almost ready at
that moment, thus allowing an instantaneous response from the system. It may even happen that the con-
fidence score of a partially processed input segment is that high, that the systemmay decide to go forward
and update its information state without waiting until the end of the segment, and prepare or produce a
response based on that update. Of course, full incremental understanding of dialogue utterances includes
not only the recognition of communicative functions, but also that of semantic content. However, many
dialogue acts have no or only marginal semantic content, such as turn-taking acts, backchannels (m-hm)
and other feedback acts (okay), time management acts (Just a moment), apologies and thankings and
other social obligation management acts, and in general dialogue acts with a dimension-specific func-
tion; for these acts the proposed strategy can work well without semantic content analysis, and will
increase the system?s interactivity significantly. Moreover, given that the average length of a functional
segment in our data is no more than 4.4 tokens, the semantic content of such a segment tends not to be
very complex, and its construction therefore does not seem to require very sophisticated computational
semantic methods, applied either in an incremental fashion (see e.g. Aist et al (2007) and DeVault and
Stone (2003)) or to a complete segment.
Interactivity is however not the sole motivation for incremental interpretation. The integration of
pragmatic information obtained from the dialogue act recognition module, as proposed here, at early
processing stage can be beneficially used by the incremental semantic parser (but also syntactic parser
module). For instance, information about the communicative function of the incoming segment at early
processing stage can defuse a number of ambiguous interpretations, e.g. used for the resolution of
many anaphoric expressions. A challenge for future work is to integrate the incremental recognition of
communicative functions with incremental syntactic and semantic parsing, and to exploit the interaction
of syntactic, semantic and pragmatic hypotheses in order to understand incoming dialogue segments
incrementally in an optimally efficient manner.
Acknowledgments
This research was conducted within the project ?Multidimensional Dialogue Modelling?, sponsored by the Netherlands Organ-
isation for Scientific Research (NWO), under grant reference 017.003.090. We are also very thankful to anonymous reviewers
for their valuable comments.
References
Aist, G., J. Allen, E. Campana, C. Gomez Gallo, S. Stoness, M. Swift, and M. K. Tanenhaus (2007). Incremental
understanding in human-computer dialogue and experimental evidence for advantages over nonincremental
methods. In Proceedings of the 11th Workshop on the Semantics and Pragmatics of Dialogue, Trento, Italy, pp.
149?154.
Ang, J., Y. Liu, and E. Shriberg (2005). Automatic dialog act segmentation and classification in multiparty meet-
ings. In Proceedings of the ICASSP, Volume vol. 1, Philadelphia, USA, pp. 10611064.
Bos, J. (2002). Underspecification and resolution in discourse semantics. PhD Thesis. Saarbru?cken: Saarland
University.
Bunt, H. (2007). Semantic underspecification: which techniques for what purpose? In Computing Meaning, Vol.
3, pp. 55?85. Dordrecht: Springer.
Bunt, H. (2009). The DIT++ taxonomy for functional dialogue markup. In Proceedings of the AAMAS 2009
Workshop ?Towards a Standard Markup Language for Embodied Dialogue Acts? (EDAML 2009), Budapest.
Bunt, H. (2010). Multifunctionality in dialogue and its interpretation. Computer, Speech and Language, Special
issue on dialogue modeling.
243
Bunt, H., J. Alexandersson, J. Carletta, J.-W. Choe, A. Fang, K. Hasida, K. Lee, V. Petukhova, A. Popescu-Belis,
L. Romary, C. Soria, and D. Traum (2010). Language resource management ? Semantic annotation framework
? Part 2: Dialogue acts. ISO DIS 24617-2. Geneva: ISO Central Secretariat.
Bunt, H., V. Petukhova, and A. Schiffrin (2007). Lirics deliverable d4.4. multilingual test suites for semantically
annotated data. Available at http://lirics.loria.fr.
Cohen, W. (1995). Fast effective rule induction. In Proceedings of the 12th International Conference on Machine
Learning (ICML?95), pp. 115?123.
DeVault, D. and M. Stone (2003). Domain inference in incremental interpretation. In Proceedings of the Workshop
on Inference in Computational Semantics, INRIA Lorraine, Nancy, France.
Dietterich, T. (2002). Machine learning for sequential data: a review. In Proceedings of the Joint IAPR Interna-
tional Workshop on Structural, Syntactic, and Statistical Pattern Recognition, pp. 15?30.
Geertzen, J. (2009). Dialogue act recognition and prediction: exploration in computational dialogue modelling.
The Netherlands: Tilburg University.
Geertzen, J., V. Petukhova, and H. Bunt (2007, September). A multidimensional approach to utterance segmenta-
tion and dialogue act classification. In Proceedings of the 8th SIGdial Workshop on Discourse and Dialogue,
Antwerp, Belgium, pp. 140?149. Association for Computational Linguistics.
Haddock, N. (1989). Computational models of incremental semantic interpretation. Language and Cognitive
Processes Vol. 14 (3), SI337?SI380.
Hobbs, J. (1985). Ontological promiscuity. In Proceedings 23rd Annual Meeting of the ACL, Chicago, pp. 61?69.
Lendvai, P., v. d. A. Bosch, and E. Krahmer (2003). Machine learning for shallow interpretation of user utter-
ances in spoken dialogue systems. In Proceedings of EACL-03 Workshop on Dialogue Systems: interaction,
adaptation and styles of management, Budapest.
Lendvai, P. and J. Geertzen (2007). Token-based chunking of turn-internal dialogue act sequences. In Proceedings
of the 8th SIGdial Workshop on Discourse and Dialogue, Antwerp, Belgium, pp. 174?181.
Milward, D. and R. Cooper (2009). Incremental interpretation: applications, theory, and relationship to dynamic
semantics. In Proceedings COLING 2009, Kyoto, Japan, pp. 748?754.
Nakano, M., N. Miyazaki, J. Hirasawa, K. Dohsaka, and T. Kawabata (1999). Understanding unsegmented user ut-
terances in real-time spoken dialogue systems. In Proceedings of the 37th Annual Conference of the Association
of Computational Linguistics, ACL, pp. 200?207.
Petukhova, V. and H. Bunt (2009). Who?s next? speaker-selection mechanisms in multiparty dialogue. In Pro-
ceedings of the Workshop on the Semantics and Pragmatics of Dialogue, Stockholm,, pp. 19?26.
Pinkal, M. (1999). On semantic underspecification. In Computing Meaning, Vol. 1, pp. 33?56. Dordrecht: Kluwer.
Poesio, M. and D. Traum (1998). Towards an Axiomatization of Dialogue Acts. In Proceedings of the Twente
Workshop on the Formal Semantics and Pragmatics of Dialogue, Twente, pp. 309?347.
Sedivy, J. (2003). Pragmatic versus form-based accounts of referential contrast: Evidence for effects of informa-
tivity expectations. Journal of Psycolinguistic Research 32(1), 3?23.
Sedivy, J., M. Tanenhaus, C. Chambers, and G. Carlson (1999). Achieving incremental semantic interpretation
through contextual representation. Cognition 71, 109?147.
Tanenhaus, M., M. Spivey-Knowlton, K. Eberhard, and J. Sedivy (1995). Intergration of visual and linguistic
information in spoken language comprehension. Science 268, 1632?1634.
Tomita, M. (1986). Efficient parsing for natural language. Dordrecht: Kluwer.
Van den Bosch, A. (1997). Learning to pronounce written words: A study in inductive language learning. PhD
thesis. The Netherlands: Maastricht University.
Zimmermann, M., Y. Lui, E. Shriberg, and A. Stolcke (2005). Toward joint segmentation and classification of
dialog acts in multiparty meetings. In Proceedings of the Multimodal Interaction and Related Machine Learning
Algorithms Workshop (MLMI05), pp. 187?193. Springer.
244
Proceedings of the Workshop on Innovative Hybrid Approaches to the Processing of Textual Data (Hybrid2012), EACL 2012, pages 61?68,
Avignon, France, April 23 2012. c?2012 Association for Computational Linguistics
Collaborative Annotation of Dialogue Acts:  
Application of a New ISO Standard to the Switchboard Corpus 
Alex C. Fang1, Harry Bunt2, Jing Cao3, and Xiaoyue Liu4 
1,3,4The Dialogue Systems Group, Department of Chinese, Translation and Linguistics 
City University of Hong Kong, Hong Kong, SAR  
2Tilburg Centre for Cognition and Communication  
Tilburg University, The Netherlands 
3School of Foreign Languages, Zhongnan University of Economics and Law, China 
E-mail: {1acfang, 3cjing3, 4xyliu0}@cityu.edu.hk, 2harry.bunt@uvt.nl  
Abstract 
This article reports some initial results from the collaborative work on converting SWBD-DAMSL annotation scheme used in the 
Switchboard Dialogue Act Corpus to ISO DA annotation framework, as part of our on-going research on the interoperability of 
standardized linguistic annotations. A qualitative assessment of the conversion between the two annotation schemes was performed to 
verify the applicability of the new ISO standard using authentic transcribed speech. The results show that in addition to a major part of 
the SWBD-DAMSL tag set that can be converted to the ISO DA scheme automatically, some problematic SWBD-DAMSL tags still 
need to be handled manually. We shall report the evaluation of such an application based on the preliminary results from automatic 
mapping via machine learning techniques. The paper will also describe a user-friendly graphical interface that was designed for manual 
manipulation. The paper concludes with discussions and suggestions for future work. 
 
 
 
1. Introduction 
This article describes the collaborative work on applying 
the newly proposed ISO standard for dialogue act 
annotation to the Switchboard Dialogue Act (SWBD-DA) 
Corpus, as part of our on-going effort to promote 
interoperability of standardized linguistic annotations 
with the ultimate goal of developing shared and open 
language resources.  
Dialogue acts (DA) play a key role in the 
interpretation of the communicative behaviour of 
dialogue participants and offer valuable insight into the 
design of human-machine dialogue systems (Bunt et al, 
2010). More recently, the emerging ISO DIS 24617-2 
(2010) standard for dialogue act annotation defines 
dialogue acts as the ?communicative activity of a 
participant in dialogue interpreted as having a certain 
communicative function and semantic content, and 
possibly also having certain functional dependence 
relations, rhetorical relations and feedback dependence 
relations? (p. 3). The semantic content specifies the 
objects, relations, events, etc. that the dialogue act is 
about; the communicative function can be viewed as a 
specification of the way an addressee uses the semantic 
content to update his or her information state when he or 
she understands the corresponding stretch of dialogue. 
Continuing efforts have been made to identify and 
classify the dialogue acts expressed in dialogue utterances 
taking into account the empirically proven 
multifunctionality of utterances, i.e., the fact that 
utterances often express more than one dialogue act (see 
Bunt, 2009 and 2011). In other words, an utterance in 
dialogue typically serves several functions. See Example 
(1) taken from the SWBD-DA Corpus 
(sw_0097_3798.utt). 
 
(1) A: Well, Michael, what do you think about, uh, 
funding for AIDS research? Do you? 
B:   Well, uh, uh, that?s something I?ve thought a lot 
about.  
 
With the first utterance, Speaker A performs two 
dialogue acts: he (a) assigns the next turn to the 
participant Michael, and (b) formulates an open question. 
Speaker B, in his response, (a) accepts the turn, (b) stalls 
for time, and (c) answers the question by making a 
statement.  
Our concern in this paper is to explore the 
applicability of the new ISO Standard to the existing 
Switchboard corpus with joint efforts of automatic and 
manual mapping. In the rest of the paper, we shall first 
describe the Switchboard Dialogue Act (SWBD-DA) 
Corpus and its annotation scheme (i.e. SWBD-DAMSL). 
We shall then describe the new ISO Standard and explain 
our mapping of SWBD-DAMSL to the ISO DIS 24617-2 
DA tag set. In addition, machine learning techniques are 
employed for automatic DA classification on the basis of 
lexical features to evaluate the application of the new ISO 
DA scheme using authentic transcribed speech. We shall 
then introduce the user interface designed for manual 
mapping and explain the annotation guidelines. Finally, 
the paper will conclude with discussions and suggestions 
for future work.  
2. Corpus Resource 
This study uses the Switchboard Dialog Act (SWBD-DA) 
Corpus as the corpus resource, which is available online 
from the Linguistic Data Consortium 1 . The corpus 
                                                          
1 http://www.ldc.upenn.edu/ 
61
contains 1,155 5-minute conversations2, orthographically 
transcribed in about 1.5 million word tokens. It should be 
noted that the minimal unit of utterances for DA 
annotation in the SWBD Corpus is the so called ?slash 
unit? (Meteer and Taylor, 1995), defined as ?maximally a 
sentence but can be smaller unit? (p. 16), and ?slash-units 
below the sentence level correspond to those parts of the 
narrative which are not sentential but which the annotator 
interprets as complete? (p. 16). See Table 1 for the basic 
statistics of the SWBD-DA Corpus. 
 
Table 1: Basic Statistics of the SWBD-DA Corpus 
 
Altogether, the corpus comprises 223,606 slash-units and 
each is annotated for its communicative function 
according to a set of dialogue acts specified in the 
SWBD-DAMSL scheme (Jurafsky et al, 1997) and 
assigned a DA tag. See Example (2) taken from 
sw_0002_4330.utt, where qy is the DA tag for yes/no 
questions.  
 
(2) qy   A.1 utt1: {D Well, } {F uh, } does the company 
you work for test for drugs? /   
 
A total of 303 different DA tags are identified throughout 
the corpus, which is different from the total number of 
220 tags mentioned in Jurafsky et al (1997: 3). To ensure 
enough instances for the different DA tags, we also 
conflated the DA tags together with their secondary 
carat-dimensions, and yet we did not use the seven special 
groupings by Jurafsky et al (1997) as we kept them as 
separate DA types (see Section 4 for further explanations). 
In the end, the 303 tags were clustered into 60 different 
individual communicative functions. See Table 2 for the 
basic statistics of the 60 DA clusters.  
According to Table 2, we observe that the 60 DA 
clusters range from 780,570 word tokens for the 
top-ranking statement-non-opinion to only 4 word 
                                                          
2 Past studies (e.g. Stolcke et al, 2000; Jurafsky et al, 
1997; Jurafsky et al, 1998a; Jurafsky et al, 1998b) have 
been focused on only 1115 conversations in the 
SWBD-DA Corpus as the training set. As there is no clear 
description which 40 conversations have been used as the 
testing set or for future use, we use all the 1155 
conversations.   
tokens for you?re-welcome. In Table 2, the Token % 
column lists the relative importance of DA types 
measured as the proportion of the word tokens in the 
SWBD-DA corpus as whole. It can be observed that, as 
yet another example to illustrate the uneven use of DA 
types, statement-opinion accounts for 21.04% of the 
total number of word tokens in the corpus.  
 
60 DAs Tokens Token % Cum % 
Statement-non-opinion 780,570 51.79 51.79 
Statement-opinion 317,021 21.04 72.83 
Segment-(multi-utterance) 135,632 9.00 81.83 
Acknowledge-(backchannel) 40,696 2.70 84.53 
Abandoned 35,214 2.34 86.87 
Yes-no-question 34,817 2.31 89.18 
Accept 20,670 1.37 90.55 
Statement-expanding-y/n-answer 14,479 0.96 91.51 
Wh-question 14,207 0.94 92.45 
Appreciation 13,957 0.93 93.38 
Declarative-yes-no-question 10,062 0.67 94.05 
Conventional-closing 9,017 0.60 94.65 
Quoted-material 7,591 0.50 95.15 
Summarize/reformulate 6,750 0.45 95.60 
Action-directive 5,860 0.39 95.99 
Rhetorical-questions 5,759 0.38 96.37 
Hedge 5,636 0.37 96.74 
Open-question 4,884 0.32 97.06 
Affirmative-non-yes-answers 4,199 0.28 97.34 
Uninterpretable 4,138 0.27 97.61 
Yes-answers 3,512 0.23 97.84 
Completion 2,906 0.19 98.03 
Hold-before-answer/agreement 2,860 0.19 98.22 
Or-question 2,589 0.17 98.39 
Backchannel-in-question-form 2,384 0.16 98.55 
Acknowledge-answer 2,038 0.14 98.69 
Negative-non-no-answers 1,828 0.12 98.81 
Other-answers 1,727 0.11 98.92 
No-answers 1,632 0.11 99.03 
Or-clause 1,623 0.11 99.14 
Other 1,578 0.10 99.24 
Dispreferred-answers 1,531 0.10 99.34 
Repeat-phrase 1,410 0.09 99.43 
Reject 891 0.06 99.49 
Transcription-errors:-slash-units 873 0.06 99.55 
Declarative-wh-question 855 0.06 99.61 
Signal-non-understanding 770 0.05 99.66 
Self-talk 605 0.04 99.70 
Offer 522 0.03 99.73 
Conventional-opening 521 0.03 99.76 
3rd-party-talk 458 0.03 99.79 
Accept-part 399 0.03 99.82 
Downplayer 341 0.02 99.84 
Apology 316 0.02 99.86 
Exclamation 274 0.02 99.88 
Commit 267 0.02 99.90 
Thanking 213 0.01 99.91 
Double-quote 183 0.01 99.92 
Reject-part 164 0.01 99.93 
Tag-question 143 0.01 99.94 
Maybe 140 0.01 99.95 
Sympathy 80 0.01 99.96 
Explicit-performative 78 0.01 99.97 
Open-option 76 0.01 99.98 
Other-forward-function 42 0.00 99.98 
Correct-misspeaking 37 0.00 99.98 
No-plus-expansion 26 0.00 99.98 
Yes-plus-expansion 22 0.00 99.98 
You?re-welcome 4 0.00 99.98 
Double-labels 2 0.00 100.00 
 Total 1,507,079 100.00 100.00 
Table 2: Basic Statistics of the 60 DAs 
 
If the cumulative proportion (Cum%) is considered, we 
Folder 
# of 
Conversations 
# of 
Slash-units 
# of 
Tokens 
sw00  99 14,277 103,045 
sw01 100 17,430 119,864 
sw02 100 20,032 132,889 
sw03 100 18,514 127,050 
sw04 100 19,592 132,553 
sw05 100 20,056 131,783 
sw06 100 19,696 135,588 
sw07 100 20,345 136,630 
sw08 100 19,970 134,802 
sw09 100 20,159 133,676 
sw10 100 22,230 143,205 
sw11  16   3,213   20,493 
sw12  11   2,773   18,164 
sw13  29   5,319   37,337 
Total      1,155   223,606 1,507,079 
62
see that the top 10 DA types alone account for 93.38% of 
the whole corpus, suggesting again the uneven occurrence 
of DA types in the corpus and hence the disproportional 
use of communication functions in conversational 
discourse.  
It is particularly worth mentioning that 
segment-(multi-utterance) is not really a DA type 
indicating communicative function and yet it is the third 
most frequent DA tag in SWBD-DAMSL.  As a matter of 
fact, the SWBD-DAMSL annotation scheme contains 
quite a number of such non-communicative DA tags, such 
as abandoned, and quoted-material. 
3. ISO DIS 24617-2 (2010) 
A basic premise of the emerging ISO standard for 
dialogue act annotation, i.e., ISO DIS 24617-2 (2010), is 
that utterances in dialogue are often multifunctional; 
hence the standard supports so-called ?multidimensional 
tagging?, i.e., the tagging of utterances with multiple DA 
tags. It does so in two ways: First of all, it defines nine 
dimensions to which a dialogue act can belong: 
? Task 
? Auto-Feedback 
? Allo-Feedback 
? Turn Management 
? Time Management 
? Discourse Structuring 
? Social Obligations Management 
? Own Communication Management 
? Partner Communication Management 
Secondly, it takes a so-called ?functional segment? as 
the unit in dialogue to be tagged with DA information, 
defined as a ?minimal stretch of communicative behavior 
that has one or more communicative functions? (Bunt et 
al., 2010). A functional segment is allowed to be 
discontinuous, and to overlap with or be included in 
another functional segment. A functional segment may be 
tagged with at most one DA tag for each dimension. 
Another important feature is that an ISO DA tag 
consists not only of a communicative function encoding, 
but also of a dimension indication, with optional attributes 
for representing certainty, conditionality, sentiment, and 
links to other dialogue units expressing semantic, 
rhetorical and feedback relations. 
Thus, two broad differences can be observed between 
SWBD-DAMSL and ISO. The first concerns the 
treatment of the basic unit of analysis. While in 
SWBD-DAMSL this is the slash-unit, ISO DIS 24617-2 
(2010) employs the functional segment, which serves well 
to emphasise the multifunctionality of dialogue utterances. 
An important difference here is that the ISO scheme 
identifies multiple DAs per segment and assigns multiple 
tags via the stand-off annotation mechanism. 
The second difference is that each slash-unit (or 
utterance) in the SWBD-DA Corpus is annotated with one 
SWBD-DAMSL label, while each DA tag in the ISO 
scheme is additionally associated with a dimension tag 
and, when appropriate, with function qualifiers and 
relations to other dialogue units. See the following 
example taken from the Schiphol Corpus. 
 
(3) A: I?m most grateful for your help 
 
While the utterance in Example (3) would be annotated 
with only a functional tag in SWBD-DAMSL, it is 
annotated to contain the communicative function ?inform? 
and in addition the dimension of social obligation 
management:  
 
    communicativeFunction = ?inform? 
  dimension = ?socialObligationManagement? 
4. Mapping SWBD-DAMSL to ISO  
4.1 Data Pre-processing 
For the benefit of the current study and potential 
follow-up work, the banners between folders were 
removed and each slash-unit was extracted to create a set 
of files. See Example (4), the tenth slash-unit taken from 
the file sw_0052_4378.utt in the folder sw00.    
 
(4) sd     B.7 utt1: {C And,} {F uh,} <inhaling> we?ve  
                             done <sigh> lots to it. /  
 
The following set of files is created: 
 
sw00-0052-0010-B007-01.txt  the original utterance 
sw00-0052-0010-B007-01-S.da  SWBD-DAMSL tag 
 
In the .txt file, there is the original utterance:  
 
     {C And,} {F uh,} <inhaling> we?ve                             
done <sigh> lots to it. /  
 
While the *-S.da file only contains the DA label: sd^t. 
Still another one or more files (depending on the number 
of dimensions) will be added to this set after converting 
the SWBD-DAMSL to the ISO tag sets.  Take Example (4) 
for instance. Two more files will be created, namely,   
 
sw00-0052-0010-B007-01-ISO-0.da  ISO DA tag 
sw00-0052-0010-B007-01-ISO-1.da  ISO DA tag 
 
The *-ISO-0.da file will contain in this case:  
 
   communicativeFunction = ?inform? 
   dimension = ?task?3 
 
and the *-ISO-1.da file will contain4:  
 
   communicativeFunction = ?stalling? 
   dimension = ?timeManagement? 
                                                          
3 The same function Inform have been observed to occur 
in different dimensions. See ISO DIS 24617-2 (2010) for 
detailed description.  
4 See Section 4.2 for more explanation of the multi-layer 
annotations in ISO standard.  
63
4.2 Assessment of the Conversion 
When mapping SWBD-DAMSL tags to functional ISO 
tags, it is achieved in terms of semantic contents rather 
than the surface labels. To be more exact, four situations 
were identified in the matching process.  
The first is what is named as ?exact matches?. It is 
worth mentioning that since we are not matching the 
labels in the two annotation schemes, even for the exact 
matches, the naming in SWBD-DAMSL is not always the 
same as that in the ISO scheme, but they have the same or 
very similar meaning. Table 3 lists the exact matches. 
 
SWBD-DAMSL ISO 
Open-question Question  
Dispreferred answers Disconfirm 
Offer Offer 
Commit Promise 
Open-option Suggest 
Hold before answer/ agreement Stalling 
Completion Completion 
Correct-misspeaking CorrectMisspeaking 
Apology Apology 
Downplayer AcceptApology 
Thanking Thanking 
You?re-welcome AcceptThanking 
Signal-non-understanding AutoNegative 
Conventional-closing InitialGoodbye 
Table 3: Exact Matches 
It can also be noted that in the previous study on the 42 
DA types in SWBD-DAMSL, open-option (oo), 
offer (co), commit (cc) are treated as one DA type. In 
the current study, they are treated as individual DA types, 
which makes more sense especially when mapping to the 
ISO DA tag sets since each of them corresponds to a 
different ISO tag, suggest, offer, and promise 
respectively.   The same is also true for the 
you?re-welcome (fw) and correct-misspeaking 
(bc), which are combined together in SWBD-DAMSL 
and correspond to different ISO DA label.  
 
SWBD-DAMSL ISO 
Wh-question; Declarative wh-question SetQuestion 
Or-question; Or-clause ChoiceQuestion 
Yes-no-question;  
Backchannel in question form PropositionalQuestion 
Tag-question;  
Declarative Yes-no-question CheckQuestion 
Statement-non-opinion;  
Statement-opinion;  
Rhetorical-question;  
Statement expanding y/n answer; Hedge 
Inform 
Maybe; Yes-answer;  
Affirmative non-yes answers;  
Yes plus expansion; No-answer;  
Negative non-no answers;  
No plus expansion 
Answer 
Acknowledge (backchannel); 
Acknowledge answer; Appreciation; 
Sympathy; Summarize/reformulate;  
Repeat-phrase 
AutoPositive 
Accept-part; Reject-part Correction 
Table 4: Many-to-one Matches 
The second situation is where more than one 
SWBD-DAMSL tags can be matched to the one ISO DA 
type, as defined as many-to-one matches. Table 4 shows 
the many-to-one matches. Such matches occur because 
semantically identical functions are sometimes given 
different names in SWBD-DAMSL in order to distinguish 
differences in lexical or syntactic form. For example, an 
affirmative non-yes answer is defined as an 
affirmative answer that does not contain the word yes or 
one of its variants (like yeah and yep). 
 The most complex issue is with the one-to-many 
matches, where a DA function in SWBD-DAMSL is too 
general and corresponds to a set of different DAs in the 
ISO scheme. Consider the DA type of accept in 
SWBD-DAMSL. It is a broad function applicable to a 
range of different situations. For instance, accept 
annotated as aa in Example (5) taken from 
sw_0005_4646.utt corresponds to Agreement in ISO 
DIS 24617-2 (2010). 
 
(5) sd    A.25 utt1: {C Or } people send you there as a  
                                  last resort. / 
     aa     B.26 utt1: Right,  / 
 
However, accept (aa) in Example (6) taken from 
sw_0098_3830.utt actually corresponds to 
acceptOffer in ISO/DIS 24617-2 (2010).  
 
(6) co    B.26 utt1: I can tell you my last job or --/ 
      aa    A.27 utt1: Okay,  / 
 
As a matter of fact, accept in SWBD-DAMSL may 
correspond to several different DAs in the ISO tag set 
such as: 
? Agreement  
? AcceptRequest (addressRequest) 
? AccpetSuggestion (addressSuggestion) 
? AcceptOffer (addressOffer) 
? etc. 
 
Other cases include reject, action-directive and 
other answers.  
Finally, the remaining tags are unique to 
SWBD-DAMSL, including  
 
? quoted material 
? uninterpretable 
? abandoned 
? self-talk 
? 3rd-party-talk 
? double labels  
? explicit-performative  
? exclamation 
? other-forward-function 
 
It is not difficult to notice that 6 out of the 9 DA types 
mainly concern the marking up of other phenomena than 
dialogue acts. The last three unique DA types only 
account for a marginal portion of the whole set, about 
0.03% all together (See Table 2).  
64
In addition, multi-layer annotations of ISO can be 
added to the original markup of SWBD (Meteer and 
Taylor 1995), especially in cases such as Stalling and 
Self-Correction. See Example (7) taken from 
sw_0052_4378.utt. 
 
(7) sd   A.12  utt2 : [ I, + {F uh, } two months ago I ]  
                               went to Massachusetts -- /  
 
According to Meteer and Taylor (1995), the {F ?} is 
used to mark up ?filler? in utterances, which corresponds 
to Stalling in ISO DIS 24617-2 (2010). In addition, the 
markup of [ ? + ?] indicates the repairs (Meteer and 
Taylor, 1995), which suits well the definition of 
Self-correction in the ISO standard. As a result, the 
utterance in Example (7) is thus annotated in three 
dimensions:  
communicativeFunction = ?inform? 
dimension = ?task? 
 
communicativeFunction = ?stalling? 
dimension = ?timeManagement? 
 
communicativeFunction = ?self-correction? 
dimension = ?ownCommManagement? 
4.3 Mapping Principles 
Given the four setting of the matching, there major 
principles were made:  
1) Cases in both ?exact matches? and ?many-to-one 
matches? can be automatically mapped to ISO tags by 
programming. 
2) Tags that are unique to SWBD-DAMSL would not 
be considered at the current stage due to the absence of 
ISO counterparts and their marginal proportion. 
3) Cases in ?one-to-many matches? are more complex 
and call for manual mapping, which will be further 
discussed in Section 6.  
4) Different DA dimensions will be also automatically 
added accordingly to each utterance in the format of 
stand-off annotation.  
5. Application Verification 
To evaluate the applicability of mapping SWBD-DAMSL 
tag set to the new ISO standard (ISO DIS 24617-2, 2010), 
machine learning techniques are employed, based on the 
preliminary results from the automatic mapping, to see 
how well the SWBD-ISO DA tags can be automatically 
identified and classified based on lexical features. The 
result is also compared with that obtained from the 
Top-15 SWBD-DAMSL tags. It will be particularly 
interesting to find out whether the emerging ISO DA 
annotation standard will produce better automatic 
prediction accuracy. In this paper, we evaluate the 
performance of automatic DA classification in the two DA 
annotation schemes by employing the unigrams as the 
feature set.  
Two classification tasks were then identified 
according to the two DA annotation schemes. Task 1 is to 
automatically classify the DA types in the 
SWBD-DAMSL. Based on the observations mentioned 
above, it was decided to use the top 15 DA types to 
investigate the distribution of word types in order to 
ascertain the lexical characteristics of DAs. Furthermore, 
since segment-(multi-utterance), abandoned, and 
quoted-material do not relate to dialogue acts per se, 
these three were replaced with rhetorical-questions, 
open-question and 
affirmative-non-yes-answers. We thus derive 
Table 6 below, showing that the revised list of top 15 DA 
types account for 85.13% of the SWBD corpus. The DA 
types are arranged according to Token% in descending 
order.  
 
Top-15 SWBD-DAMSL DAs Tokens Token % Cum % 
Statement-non-opinion 780,570 51.79 51.79 
Statement-opinion 317,021 21.04 72.83 
Acknowledge-(backchannel) 40,696 2.70 75.53 
Yes-no-question 34,817 2.31 77.84 
Accept 20,670 1.37 79.21 
Statement-expanding-y/n-answer 14,479 0.96 80.17 
Wh-question 14,207 0.94 81.11 
Appreciation 13,957 0.93 82.04 
Declarative-yes-no-question 10,062 0.67 82.71 
Conventional-closing 9,017 0.60 83.31 
Summarize/reformulate 6,750 0.45 83.76 
Action-directive 5,860 0.39 84.15 
Rhetorical-questions 5,759 0.38 84.53 
Open-question 4,884 0.32 84.85 
Affirmative-non-yes-answers 4,199 0.28 85.13 
Total 1,282,948 85.13  
Table 6: Top-15 SWBD-DAMSL DA types 
Next, accordingly, task 2 is to classify the top 15 ISO 
DAs based on the results from the automatic mapping. It 
should be pointed out that only one layer of annotation in 
the ISO DA tags is considered in order to make the result 
comparable to that from SWBD-DAMSL, and the 
dimension of task is the priority when it comes to 
multi-layer annotations.  
 
Top-15 SWBD-ISO DAs Tokens Token % Cum % 
Inform 1,117,829   74.17 74.17 
AutoPositive 64,851 4.30 78.47 
PropositionalQuestion 37,201 2.47 80.94 
SetQuestion 15,062 1.00 81.94 
Answer 11,171 0.74 82.68 
CheckQuestion 10,062 0.67 83.35 
InitialGoodbye 9,017 0.60 83.95 
Question 4,884 0.32 84.27 
ChoiceQuestion 4,212 0.28 84.55 
Completion 2,906 0.19 84.75 
Stalling 2,860 0.19 84.94 
Disconfirm 1,531 0.10 85.04 
AutoNegative 770 0.05 85.09 
Offer 522 0.03 85.12 
AcceptApology 341 0.02 85.15 
Total 1,283,219   85.15  
Table 7: Top-15 SWBD-ISO DA types 
The Na?ve Bayes Multinomial classifier was 
employed, which is available from Waikato Environment 
for Knowledge Analysis, known as Weka (Hall et al, 
2009). 10-fold cross validation was performed and the 
65
results evaluated in terms of precision, recall and F-score 
(F1). 
Table 8 presents the results for classification task 1. 
The SWBD-DAMSL DAs are arranged according to 
F-score in descending order. 
 
Top 15 SWBD-DAMSL DAs Precision Recall F1 
Acknowledge-(backchannel) 0.821 0.968 0.888 
Statement-non-opinion 0.732 0.862 0.792 
Appreciation 0.859 0.541 0.664 
Statement-opinion 0.538 0.584 0.560 
Conventional-closing 0.980 0.384 0.552 
Accept 0.717 0.246 0.367 
Yes-no-question 0.644 0.204 0.309 
Wh-question 0.760 0.189 0.303 
Open-question 0.932 0.084 0.154 
Action-directive 1.000 0.007 0.013 
Statement-expanding-y/n-answer 0.017 0 0.001 
Declarative-yes-no-question 0 0 0 
Summarize/reformulate 0 0 0 
Rhetorical-questions 0 0 0 
Affirmative-non-yes-answers 0 0 0 
Weighted Average 0.704 0.725 0.692 
Table 8: Results from Task 1 
As can be noted, the weighted average F-score is 69.2%. 
To be more specific, acknowledge-(backchannel) 
achieves the best F-score of 0.888, followed by 
statement-non-opinion with an F-score of 0.792. 
Surprisingly, the action-directive has the highest 
precision of 100%, but has the second lowest recall of 
over 0.7%. It can also be noted that the last four types of 
DAs cannot be classified with the F-score of 0%.  
 
Top 15 SWBD-ISO DAs Precision Recall F1 
Inform 0.879 0.987 0.930 
Answer 0.782 0.767 0.775 
AutoPositive 0.711 0.507 0.592 
InitialGoodbye 0.972 0.351 0.516 
PropositionalQuestion 0.521 0.143 0.224 
SetQuestion 0.668 0.120 0.203 
Question 0.854 0.051 0.097 
AutoNegative 0.889 0.026 0.051 
ChoiceQuestion 0.286 0.008 0.015 
Stalling 0.400 0.003 0.007 
CheckQuestion 0.042 0.001 0.001 
AcceptApology 0 0 0 
Completion 0 0 0 
Disconfirm 0 0 0 
Offer 0 0 0 
Weighted Average 0.832 0.865 0.831 
Table 9: Results from Task 2 
Table 9 presents the results for classification task 2. 
The DAs are arranged according to F-score in descending 
order. As can be noted, the weighted average F-score is 
83.1%, over 10% higher than task 1. To be more specific, 
Inform achieves the best F-score of 0.93, followed by 
Answer with an F-score of 0.775. The DA 
InitialGoodbye has the highest precision, of about 
97%, whereas Inform has the highest recall of over 98%. 
Similar to the results obtained in Task 1, the last four types 
of DAs in Task 2 also cannot be classified with the 
F-score of 0%. 
Meanwhile, as mentioned earlier, when the data size 
for each DA type is taken into consideration, Task 2 may 
be more challenging than Task 1 in that 6 out of the 15 
SWBD-ISO DA types has a total number of word tokens 
fewer than 4,000 whereas all the 15 SWBD-DAMSL DA 
types has a total number of over 4,000. Therefore, the 
much higher average F-score suggests that the application 
of ISO standard DA scheme could lead to better 
classification performance, suggesting that the ISO DA 
standard represents a better option for automatic DA 
classification. 
To sum up, with a comparable version of the 
SWBD-DA Corpus, results from the automatic DA 
classification tasks show that the ISO DA annotation 
scheme produces better automatic prediction accuracy, 
which encourages the completion of the manual mapping. 
6. Manual Mapping 
6.1 Analysis of Problematic DA Types 
As mentioned earlier, there are mainly four problematic 
SWBD-DAMSL tags, namely, accept (aa), reject 
(ar), action-directive (ad) and other answers 
(no). They are problematic in that they carry a broad 
function applicable to a range of different situations 
according to the new ISO standard, as evidenced in the 
case of accept discussed in Section 4.2. Consequently, to 
map the problematic SWBD-DAMSL tags to the ISO tags 
calls for manual manipulation. 
A close look into those four types shows that the 
mapping could be further divided into two setting. Again, 
take accept (aa) for example. In the first setting, a 
sub-division of accept (aa) can also be automatically 
matched according to the previous utterance by the other 
speaker in the adjacent pair. See Example (8) taken from 
sw_0001_4325.utt.  
 
(8) sv     A.49 utt3: take a long time to find the right  
                                 place / 
      x      A.49 utt4: <laughter>. 
      aa     B.50 utt1: Yeah,  / 
 
Here accept (aa) corresponds to Agreement because of 
the DA type in A.49 utt3 but not the immediate previous 
DA as in A.49 utt4. With this principle, the particular 
sub-groups for automatic mapping were identified for 
accept (aa). See Table 10. 
 
SWBD-DAMSL 
ISO 
Previous DA Current DA 
Statement-non-opinion; 
Statement-opinion; Hedge 
Rhetorical-question;  
Statement expanding y/n answer,  
accept 
Agreement 
Offer AcceptOffer 
Open-option AcceptRequest 
Thanking AcceptThanking 
Apology AcceptApology 
Table 10: Sub-groups of accept for Auto Mapping 
The remaining cases, in the second setting, call for 
manual annotation. For instance, when the previous DA 
type is also a problematic one, annotators need to decide 
66
the corresponding ISO DA tag for the previous 
SWBD-DAMSL one before converting the accept (aa).  
See Example (9) taken from sw_0423_3325.utt.  
 
(9) ad    B.128 utt2: {C so } we'll just wait. / 
      aa    A.129 utt1: Okay,  / 
 
Here, action-directive (ad) is first decided as a 
suggestion, and therefore accept (aa) turns out to 
actually correspond to acceptSuggestion 
(addressSuggestion) in ISO/DIS 24617-2 (2010).  
6.2 Design of a User Interface 
Given the analysis of those four DA tags, a user-friendly 
interface was then designed to assist annotators to 
maximize the inter-annotator agreement.  See Figure 1.  
 
Figure 1: User Interface 
 
Figure 1 shows the screenshot when the targeted 
SWBD-DAMSL type is accept (aa). As can be noted 
above, the basic functional bars have been designed, 
including: 
? Input: the path of the input 
? Automatch: to filter out the sub-groups that can be 
automatically matched 
? DA Tag: the targeted problematic DAs, namely, 
? aa (accept) 
? ar (reject) 
? ad (action-directive) and 
? no (other answers) 
? Previous: to go back to the previous instance of the 
targeted DA type 
? Next: to move on to the next instance of the targeted 
DA type 
? Current: the extraction of the adjacent turns 
? Previous5T: the extraction of the previous five turns 
when necessary 
? PreviousAll: the extraction of all the previous turns 
when necessary 
? MatchInfo: Bars for mapping information with five 
options: 
? Four pre-defined ISO DA types 
? Other: a user-defined mapping with a 
two-fold function: for user defined ISO DA 
type and for extra pre-defined ISO DA types 
(since the pre-defined DA types differ for 
the four targeted SWBD-DAMSL types).  
? Output: the path of the output 
? Result: export the results to the chosen path 
 
With this computer-aided interface, three annotators are 
invited to carry out the manual mapping. They are all 
postgraduates with linguistic background. After a month 
of training on the understanding of the two annotation 
schemes (in process), they will work on the 
SWBD-DAMSL DA instances from 115 randomly chosen 
files, and map them into ISO DA tags independently. The 
kappa value will be calculated to measure the 
inter-annotator agreement.  
 
7. Conclusion 
 
In this paper, we reported our efforts in applying the 
ISO-standardized dialogue act annotations to the 
Switchboard Dialogue Act (SWBD-DA) Corpus. In 
particular, the SWBD-DAMSL tags employed in the 
SWBD-DA Corpus were analyzed and mapped onto the 
ISO DA tag set (ISO DIS 24617-2 2010) according to 
their communicative functions and semantic contents. 
Such a conversion is a collaborative process involving 
both automatic mapping and manual manipulation.  With 
the results from the automatic mapping, machine learning 
techniques were employed to evaluate the applicability of 
the new ISO standard for dialogue act annotation in 
practice. With the encouraging results from the evaluation, 
the manual mapping was carried out. A user-friendly 
interface was designed to assist annotators. The 
immediate future work would be finish the manual 
mapping and thus to  produce a comparable version of the 
SWBD-DA Corpus was produced so that the two 
annotation schemes (i.e. SWBD-DAMSL vs. SWBD-ISO) 
can be effectively compared on the basis of empirical data. 
Furthermore, with the newly built resource, i.e., 
SWBD-ISO, we plan to examine the effect of 
grammatical and syntactic cues on the performance of DA 
classification, with a specific view on whether dialogue 
acts exhibit differentiating preferences for grammatical 
and syntactic constructions that have been overlooked 
before.  
 
 
8. Acknowledgements 
Research described in this article was supported in part by 
grants received from City University of Hong Kong 
(Project Nos 7008002, 9610188, 7008062 and 6454005). 
It was also partially supported by the General Research 
Fund of the Research Grants Council of Hong Kong 
(Project No 142711). 
9. References 
 
Bunt, H. (2009). Multifunctionality and multidimensional 
dialogue semantics. In Proceedings of DiaHolmia 
Workshop on the Semantics and Pragmatics of 
67
Dialogue, Stockholm, 2009.  
Bunt, H. (2011). Multifunctionality in dialogue and its 
interpretation. Computer, Speech and Language, 25 (2), 
pp. 225--245.  
Bunt, H., Alexandersson, J., Carletta, J., Choe, J.-W., 
Fang, A.C., Hasida, K., Lee, K., Petukhova, V., 
Popescu-Belis, A., Romary, L., Soria, C. and Traum, D. 
(2010). Towards an ISO standard for dialogue act 
annotation. In Proceedings of the Seventh International 
Conference on Language Resources and Evaluation. 
Valletta, MALTA, 17-23 May 2010. 
Hall, M., Frank, E., Holmes, G., Pfahringer, B., 
Reutemann, P. and Witten, I. H. (2009). The WEKA 
data mining software: an update. SIGKDD 
Explorations, 11 (1), pp. 10--18. 
ISO DIS 24617-2. (2010). Language resource 
management ? Semantic annotation framework 
(SemAF), Part 2: Dialogue acts. ISO, Geneva, January 
2010. 
Jurafsky, D., Shriberg, E. and Biasca, D. (1997). 
Switchboard SWBD-DAMSL 
shallow-discourse-function annotation coders manual, 
Draft 13.  University of Colorado, Boulder Institute of 
Cognitive Science Technical Report 97-02. 
Jurafsky, D., Bates, R., Coccaro, N., Martin, R., Meteer, 
M., Ries, K., Shriberg, E., Stolcke, A., Taylor,  P. and 
Ess-Dykema, C. V. (1998a). Switchbaod Discourse 
Language Modeling Project and Report. Research Note 
30, Center for Language and Speech Processing, Johns 
Hopkins University, Baltimore, MD, January. 
Jurafsky, D., Shriberg, E., Fox B. and Curl, T. (1998b).  
Lexical, prosodic, and syntactic cues for dialog acts. 
ACL/COLING-98 Workshop on Discourse Relations 
and Discourse Markers.  
Meeter, M., Taylor, A. (1995). Dysfluency annotation 
stylebook for the Switchboard Corpus. Available at 
ftp://ftp.cis.upenn.edu/pub/treebank/swbd/doc/DFL-bo
ok.ps. 
Stolcke, A., Ries, K., Coccaro, N., Shriberg, E., Bates, R., 
Jurfsky, D., Taylor, P., Martin, R., Ess-Dykema, C.V. 
and Meteer, M.  (2000). Dialogue Act Modeling for 
Automatic Tagging and Recognition of Conversational 
Speech. Computational Linguistics, 26 (3), pp. 
339--373.  
68
