Proceedings of SPEECHGRAM 2007, pages 1?8,
Prague, Czech Republic, June 2007. c?2007 Association for Computational Linguistics
Speech Recognition Grammar Compilation in Grammatical Framework
Bjo?rn Bringert
Department of Computer Science and Engineering
Chalmers University of Technology and Go?teborg University
SE-412 96 Go?teborg, Sweden
bringert@cs.chalmers.se
Abstract
This paper describes how grammar-based
language models for speech recognition sys-
tems can be generated from Grammatical
Framework (GF) grammars. Context-free
grammars and finite-state models can be
generated in several formats: GSL, SRGS,
JSGF, and HTK SLF. In addition, semantic
interpretation code can be embedded in the
generated context-free grammars. This en-
ables rapid development of portable, multi-
lingual and easily modifiable speech recog-
nition applications.
1 Introduction
Speech recognition grammars are used for guid-
ing speech recognizers in many applications. How-
ever, there are a number of problems associated
with writing grammars in the low-level, system-
specific formats required by speech recognizers.
This work addresses these problems by generat-
ing speech recognition grammars and semantic in-
terpretation components from grammars written in
Grammatical Framework (GF), a high-level, type-
theoretical grammar formalism. Compared to exist-
ing work on compiling unification grammars, such
as Regulus (Rayner et al, 2006), our work uses a
type-theoretical grammar formalism with a focus on
multilinguality and modular grammar development,
and supports multiple speech recognition grammar
formalisms, including finite-state models.
We first outline some existing problems in the de-
velopment and maintenance of speech recognition
grammars, and describe how our work attempts to
address these problems. In the following two sec-
tions we introduce speech recognition grammars and
Grammatical Framework. The bulk of the paper
then describes how we generate context-free speech
recognition grammars, finite-state language models
and semantic interpretation code from GF gram-
mars. We conclude by giving references to a number
of experimental dialogue systems which already use
our grammar compiler for generating speech recog-
nition grammars.
Expressivity Speech recognition grammars are
written in simple formalisms which do not have
the powerful constructs of high-level grammar for-
malisms. This makes speech recognition grammar
writing labor-intensive and error prone, especially
for languages with more inflection and agreement
than English.
This is solved by using a high-level grammar for-
malism with powerful constructs and a grammar
library which implements the domain-independent
linguistic details.
Duplicated work When speech recognition gram-
mars are written directly in the low-level format re-
quired by the speech recognizer, other parts of the
system, such as semantic interpretation components,
must often be constructed separately.
This duplicated work can be avoided by gener-
ating all the components from a single declarative
source, such as a GF grammar.
Consistency Because of the lack of abstraction
mechanisms and consistency checks, it is difficult
1
to modify a system which uses hand-written speech
recognition grammars. The problem is multiplied
when the system is multilingual. The developer
has to modify the speech recognition grammar and
the semantic interpretation component manually for
each language. A simple change may require touch-
ing many parts of the grammar, and there are no au-
tomatic consistency checks.
The strong typing of the GF language enforces
consistency between the semantics and the concrete
representation in each language.
Localization With hand-written grammars, it is
about as difficult to add support for a new language
as it is to write the grammar and semantic interpre-
tation for the first language.
GF?s support for multilingual grammars and the
common interface implemented by all grammars in
the GF resource grammar library makes it easier to
translate a grammar to a new language.
Portability A grammar in any given speech recog-
nition grammar format cannot be used with a speech
recognizer which uses another format.
In our approach, a GF grammar is used as the
canonical representation which the developer works
with, and speech recognition grammars in many for-
mats can be generated automatically from this rep-
resentation.
2 Speech Recognition Grammars
To achieve acceptable accuracy, speech recognition
software is guided by a language model which de-
fines the language which can be recognized. A lan-
guage model may also assign different probabilities
to different strings in the language. A language
model can either be a statistical language model
(SLM), such as an n-gram model, or a grammar-
based language model, for example a context-free
grammar (CFG) or a finite-state automaton (FSA).
In this paper, we use the term speech recogni-
tion grammar (SRG) to refer to all grammar-based
language models, including context-free grammars,
regular grammars and finite-state automata.
3 Grammatical Framework
Grammatical Framework (GF) (Ranta, 2004) is a
grammar formalism based on constructive type the-
ory. In GF, an abstract syntax defines a seman-
tic representation. A concrete syntax declares how
terms in an abstract syntax are linearized, that is,
how they are mapped to concrete representations.
GF grammars can be made multilingual by having
multiple concrete syntaxes for a single abstract syn-
tax.
3.1 The Resource Grammar Library
The GF Resource Grammar Library (Ranta et al,
2006) currently implements the morphological and
syntactic details of 10 languages. This library is in-
tended to make it possible to write grammars with-
out caring about the linguistic details of particular
languages. It is inspired by library-based software
engineering, where complex functionality is imple-
mented in reusable software libraries with simple in-
terfaces.
The resource grammar library is used through
GF?s facility for grammar composition, where the
abstract syntax of one grammar is used in the imple-
mentation of the concrete syntax of another gram-
mar. Thus, an application grammar writer who uses
a resource grammar uses its abstract syntax terms
to implement the linearizations in the application
grammar.
The resource grammars for the different lan-
guages implement a common interface, i.e. they
all have a common abstract syntax. This means
that grammars which are implemented using re-
source grammars can be easily localized to other
languages. Localization normally consists of trans-
lating the application-specific lexical items, and ad-
justing any linearizations which turn out to be uni-
diomatic in the language in question. For example,
when the GoTGoDiS (Ericsson et al, 2006) appli-
cation was localized to Finnish, only 3 out of 180
linearization rules had to be changed.
3.2 An Example GF Grammar
Figure 1 contains a small example GF abstract syn-
tax. Figure 2 defines an English concrete syntax
for it, using the resource grammar library. We will
use this grammar when we show examples of speech
recognition grammar generation later.
In the abstract syntax, cat judgements introduce
syntactic categories, and fun judgements declare
constructors in those categories. For example, the
2
abstract Food = {
cat Order; Items; Item;Number;Size;
fun order : Items? Order;
and : Items? Items? Items;
items : Item? Number? Size? Items;
pizza,beer : Item;
one, two :Number;
small, large :Size;
}
Figure 1: Food.gf: A GF abstract syntax module.
concrete FoodEng of Food = open English in {
flags startcat = Order;
lincat Order = Utt; Items = NP;
Item = CN;Number = Det;
Size = AP;
lin order x = mkUtt x;
and x y = mkNP and Conj x y;
items x n s = mkNP n (mkCN s x);
pizza = mkCN (regN ?pizza?);
beer = mkCN (regN ?beer?);
one = mkDet one Quant;
two = mkDet n2;
small = mkAP (regA ?small?);
large = mkAP (regA ?large?);
}
Figure 2: FoodEng.gf: English concrete syntax for
the abstract syntax in Figure 1.
items constructor makes an Items term from an Item,
aNumber and a Size. The term items pizza two small
is an example of a term in this abstract syntax.
In the concrete syntax, a lincat judgement de-
clares the type of the concrete terms generated from
the abstract syntax terms in a given category. The
linearization of each constructor is declared with a
lin judgement. In the concrete syntax in Figure 2,
library functions from the English resource gram-
mar are used for the linearizations, but it is also pos-
sible to write concrete syntax terms directly. The
linearization of the term items pizza two small is
{s= ?two small pizzas?}, a record containing a sin-
gle string field.
By changing the imports and the four lexical
items, this grammar can be translated to any other
language for which there is a resource grammar.
For example, in the German version, we replace
(regN ?beer?) with (reg2N ?Bier? ?Biere? neuter)
and so on. The functions regN and reg2N implement
paradigms for regular English and German nouns,
respectively. This replacement can be formalized
using GF?s parameterized modules, which lets one
write a common implementation that can be instan-
tiated with the language-specific parts. Note that the
application grammar does not deal with details such
as agreement, as this is taken care of by the resource
grammar.
4 Generating Context-free Grammars
4.1 Algorithm
GF grammars are converted to context-free speech
recognition grammars in a number of steps. An
overview of the compilation pipeline is show in Fig-
ure 3. The figure also includes compilation to finite-
state automata, as described in Section 5. Each step
of the compilation is described in more detail in the
sections below.
Conversion to CFG The GF grammar is first
converted into a context-free grammar annotated
with functions and profiles, as described by
Ljunglo?f (2004).
Cycle elimination All directly and indirectly
cyclic productions are removed, since they cannot be
handled gracefully by the subsequent left-recursion
elimination. Such productions do not contribute to
the coverage to the grammar, only to the set of pos-
sible semantic results.
Bottom-up filtering Productions whose right-
hand sides use categories for which there are no pro-
ductions are removed, since these will never match
any input.
Top-down filtering Only productions for cate-
gories which can be reached from the start category
are kept. This is mainly used to remove parts of the
grammar which are unused because of the choice
of start category. One example where this is useful
is when a speech recognition grammar is generated
from a multimodal grammar (Bringert et al, 2005).
In this case, the start category is different from the
start category used by the parser, in that its lineariza-
tion only contains the speech component of the in-
3
GF grammar
CFG conversion
Cycle elimination
Bottom-up filtering
Top-down filtering
Left-recursion
elimination
Identical category
elimination
EBNF compaction
SRGS/JSGF/GSL
Regular
approximation
FSA compilation
Minimization
SLF
Figure 3: Grammar compilation pipeline.
put. Top-down filtering then has the effect of ex-
cluding the non-speech modalities from the speech
recognition grammar.
The bottom-up and top-down filtering steps are it-
erated until a fixed point is reached, since both these
steps may produce new filtering opportunities.
Left-recursion elimination All direct and indi-
rect left-recursion is removed using the LCLR trans-
form described by Moore (2000). We have modi-
fied the LCLR transform to avoid adding productions
which use a category A?X when there are no pro-
ductions for A?X .
Identical category elimination In this step, the
categories are grouped into equivalence classes by
their right-hand sides and semantic annotations. The
categories A1 . . .An in each class are replaced by a
single category A1+. . .+An throughout the grammar,
discarding any duplicate productions. This has the
effect of replacing all categories which have identi-
cal sets of productions with a single category. Con-
crete syntax parameters which do not affect inflec-
tion is one source of such redundancy; the LCLR
transform is another.
EBNF compaction The resulting context-free
grammar is compacted into an Extended Backus-
Naur Form (EBNF) representation. This reduces the
size and improves the readability of the final gram-
mar. The compaction is done by, for each cate-
gory, grouping all the productions which have the
same semantic interpretation, and the same sequence
of non-terminals on their right-hand sides, ignoring
any terminals. The productions in each group are
merged into one EBNF production, where the ter-
minal sequences between the non-terminals are con-
verted to regular expressions which are the unions of
the original terminal sequences. These regular ex-
pressions are then minimized.
Conversion to output format The resulting non-
left-recursive grammar is converted to SRGS, JSGF
or Nuance GSL format.
A fragment of a SRGS ABNF grammar generated
from the GF grammar in Figure 2 is shown below.
The left-recursive and rule was removed from the
grammar before compilation, as the left-recursion
elimination step makes it difficult to read the gen-
erated grammar. The fragment shown here is for the
singular part of the items rule.
$FE1 = $FE6 $FE9 $FE4;
$FE6 = one;
$FE9 = large | small;
$FE4 = beer | pizza;
The corresponding fragment generated from the
German version of the grammar is more complex,
since the numeral and the adjective must agree with
the gender of the noun.
$FG1 = $FG10 $FG13 $FG6 | $FG9 $FG12 $FG4;
$FG9 = eine; $FG10 = ein;
$FG12 = gro?e | kleine;
$FG13 = gro?es | kleines;
$FG4 = Pizza; $FG6 = Bier;
4.2 Discussion
The generated grammar is an overgenerating ap-
proximation of the original GF grammar. This is
inevitable, since the GF formalism is stronger than
4
context-free grammars, for example through its sup-
port for reduplication. GF?s support for dependently
typed and higher-order abstract syntax is also not
yet carried over to the generated speech recogni-
tion grammars. This could be handled in a subse-
quent semantic interpretation step. However, that
requires that the speech recognizer considers mul-
tiple hypotheses, since some may be discarded by
the semantic interpretation. Currently, if the abstract
syntax types are only dependent on finite types, the
grammar can be expanded to remove the dependen-
cies. This appears to be sufficient for many realistic
applications.
In some cases, empty productions in the gener-
ated grammar could cause problems for the cycle
and left-recursion elimination, though we have yet
to encounter this in practice. Empty productions can
be removed by transforming the grammar, though
this has not yet been implemented.
For some grammars, the initial CFG generation
can generate a very large number of productions.
While the resulting speech recognition grammars
are of a reasonable size, the large intermediate gram-
mars can cause memory problems. Further opti-
mization is needed to address this problem.
5 Finite-State Models
5.1 Algorithm
Some speech recognition systems use finite-state au-
tomata rather than context-free grammars as lan-
guage models. GF grammars can be compiled to
finite-state automata using the procedure shown in
Figure 3. The initial part of the compilation to
a finite-state model is shared with the context-free
SRG compilation, and is described in Section 4.
Regular approximation The context-free gram-
mar is approximated with a regular grammar, us-
ing the algorithm described by Mohri and Neder-
hof (2001).
Compilation to finite-state automata The reg-
ular grammar is transformed into a set of non-
deterministic finite automata (NFA) using a modi-
fied version of the make fa algorithm described by
Nederhof (2000). For realistic grammars, applying
the original make fa algorithm to the whole gram-
mar generates a very large automaton, since a copy
of the sub-automaton corresponding to a given cate-
gory is made for every use of the category.
Instead, one automaton is generated for each cat-
egory in the regular grammar. All categories which
are not in the same mutually recursive set as the
category for which the automaton is generated are
treated as terminal symbols. This results in a set
of automata with edges labeled with either terminal
symbols or the names of other automata.
If desired, the set of automata can be con-
verted into a single automaton by substituting each
category-labeled edge with a copy of the corre-
sponding automaton. Note that this always termi-
nates, since the sub-automata do not have edges la-
beled with the categories from the same mutually re-
cursive set.
Minimization Each of the automata is turned into
a minimal deterministic finite automaton (DFA) by
using Brzozowski?s (1962) algorithm, which min-
imizes the automaton by performing two deter-
minizations and reversals.
Conversion to output format The resulting finite
automaton can be output in HTK Standard Lattice
Format (SLF). SLF supports sub-lattices, which al-
lows us to convert our set of automata directly into a
set of lattices. Since SLF uses labeled nodes, rather
than labeled edges, we move the labels to the nodes.
This is done by first introducing a new labeled node
for each edge, and then eliminating all internal un-
labeled nodes. Figure 4 shows the SLF model gen-
erated from the example grammar. For clarity, the
sub-lattices have been inlined.
and one
two
pizzas
beers
pizza
beersmall
large
small
large
ENDSTART
Figure 4: SLF model generated from the grammar
in Figure 2.
5
5.2 Discussion
Finite-state models are even more restrictive than
context-free grammars. This problem is handled
by approximating the context-free grammar with
an overgenerating finite-state automaton. This may
lead to failure in a subsequent parsing step, which,
as in the context-free case, is acceptable if the rec-
ognizer can return all hypotheses.
6 Semantic Interpretation
Semantic interpretation can be done as a separate
parsing step after speech recognition, or it can be
done with semantic information embedded in the
speech recognition grammar. The latter approach re-
sembles the semantic actions used by parser genera-
tors for programming languages. One formalism for
semantic interpretation is the proposed Semantic In-
terpretation for Speech Recognition (SISR) standard.
SISR tags are pieces of ECMAScript code embed-
ded in the speech recognition grammar.
6.1 Algorithm
The GF system can include SISR tags when gen-
erating speech recognitions grammars in SRGS
and JSGF format. The SISR tags are generated
from the semantic information in the annotated
CFG (Ljunglo?f, 2004). The result of the semantic
interpretation is an abstract syntax term.
The left-recursion elimination step makes it
somewhat challenging to produce correct abstract
syntax trees. We have extended Moore?s (2000)
LCLR transform to preserve the semantic interpreta-
tion. The LCLR transform introduces new categories
of the form A?X where X is a proper left corner of
a category A. The new category A?X can be under-
stood as ?the category A, but missing an initial X?.
Thus the semantic interpretation for a production in
A?X is the semantic interpretation for the original A-
production, abstracted (in the ?-calculus sense) over
the semantic interpretation of the missing X . Con-
versely, where-ever a category A?X is used, its re-
sult is applied to the interpretation of the occurrence
of X .
6.2 Discussion
As discussed in Section 4.2, the semantic interpre-
tation code could be used to implement the non-
context-free features of GF, but this is not yet done.
The slot-filling mechanism in the GSL format
could also be used to build semantic representations,
by returning program code which can then be ex-
ecuted. The UNIANCE grammar compiler (Bos,
2002) uses that approach.
7 Related Work
7.1 Unification Grammar Compilation
Compilation of unification grammars to speech
recognition grammars is well described in the liter-
ature (Moore, 1999; Dowding et al, 2001). Regu-
lus (Rayner et al, 2006) is perhaps the most ambi-
tious such system. Like GF, Regulus uses a general
grammar for each language, which is specialized to a
domain-specific one. Ljunglo?f (Ljunglo?f, 2007b) re-
lates GF and Regulus by showing how to convert GF
grammars to Regulus grammars. We carry composi-
tional semantic interpretation through left-recursion
elimination using the same idea as the UNIANCE
grammar compiler (Bos, 2002), though our version
handles both direct and indirect left-recursion.
The main difference between our work and the
existing compilers is that we work with type-
theoretical grammars rather than unification gram-
mars. While the existing work focuses on GSL
as the output language, we also support a number
of other formats, including finite-state models. By
using the GF resource grammars, speech recogni-
tion language models can be produced for more lan-
guages than with previous systems. One shortcom-
ing of our system is that it does not yet have support
for weighted grammars.
7.2 Generating SLMs from GF Grammars
Jonson (2006) has shown that in addition to gener-
ating grammar-based language models, GF can be
used to build statistical language models (SLMs). It
was found that compared to our grammar-based ap-
proach, use of generated SLMs improved the recog-
nition performance for out-of-grammar utterances
significantly.
8 Results
Speech recognition grammars generated from GF
grammars have already been used in a number of
research dialogue systems.
6
GOTTIS (Bringert et al, 2005; Ericsson et al,
2006), an experimental multimodal and multilingual
dialogue system for public transportation queries,
uses GF grammars for parsing multimodal input.
For speech recognition, it uses GSL grammars gen-
erated from the speech modality part of the GF
grammars.
DJ-GoDiS, GoDiS-deLUX, and GoTGoDiS (Er-
icsson et al, 2006) are three applications which use
GF grammars for speech recognition and parsing
together with the GoDiS implementation of issue-
based dialogue management (Larsson, 2002). GoT-
GoDiS has been translated to 7 languages using the
GF resource grammar library, with each new transla-
tion taking less than one day (Ericsson et al, 2006).
The DICO (Villing and Larsson, 2006) dialogue
system for trucks has recently been modified to
use GF grammars for speech recognition and pars-
ing (Ljunglo?f, 2007a).
DUDE (Lemon and Liu, 2006) and its extension
REALL-DUDE (Lemon et al, 2006b) are environ-
ments where non-experts can develop dialogue sys-
tems based on Business Process Models describing
the applications. From keywords, prompts and an-
swer sets defined by the developer, the system gen-
erates a GF grammar. This grammar is used for pars-
ing input, and for generating a language model in
SLF or GSL format.
The Voice Programming system by Georgila and
Lemon (Georgila and Lemon, 2006; Lemon et al,
2006a) uses an SLF language model generated from
a GF grammar.
Perera and Ranta (2007) have studied how GF
grammars can be used for localization of dialogue
systems. A GF grammar was developed and local-
ized to 4 other languages in significantly less time
than an equivalent GSL grammar. They also found
the GSL grammar generated by GF to be much
smaller than the hand-written GSL grammar.
9 Conclusions
We have shown how GF grammars can be compiled
to several common speech recognition grammar for-
mats. This has helped decrease development time,
improve modifiability, aid localization and enable
portability in a number of experimental dialogue
systems.
Several systems developed in the TALK and
DICO projects use the same GF grammars for
speech recognition, parsing and multimodal fu-
sion (Ericsson et al, 2006). Using the same gram-
mar for multiple system components reduces devel-
opment andmodification costs, and makes it easier
to maintain consistency within the system.
The feasibility of rapid localization of dialogue
systems which use GF grammars has been demon-
strated in the GoTGoDiS (Ericsson et al, 2006) sys-
tem, and in experiments by Perera and Ranta (2007).
Using speech recognition grammars generated by
GF makes it easy to support different speech rec-
ognizers. For example, by using the GF grammar
compiler, the DUDE (Lemon and Liu, 2006) system
can support both the ATK and Nuance recognizers.
Implementations of the methods described in this
paper are freely available as part of the GF distribu-
tion1.
Acknowledgments
Aarne Ranta, Peter Ljunglo?f, Rebecca Jonson,
David Hjelm, Ann-Charlotte Forslund, Ha?kan Bur-
den, Xingkun Liu, Oliver Lemon, and the anony-
mous referees have contributed valuable comments
on the grammar compiler implementation and/or
this article. We would like to thank Nuance Com-
munications, Inc., OptimSys, s.r.o., and Opera Soft-
ware ASA for software licenses and technical sup-
port. The code in this paper has been typeset using
lhs2TeX, with help fromAndres Lo?h. This work has
been partly funded by the EU TALK project, IST-
507802.
References
Johan Bos. 2002. Compilation of unification grammars
with compositional semantics to speech recognition
packages. In Proceedings of the 19th international
conference on Computational linguistics, pages 1?7,
Morristown, NJ, USA. Association for Computational
Linguistics.
Bjo?rn Bringert, Robin Cooper, Peter Ljunglo?f, and Aarne
Ranta. 2005. Multimodal Dialogue System Gram-
mars. In Proceedings of DIALOR?05, Ninth Workshop
on the Semantics and Pragmatics of Dialogue, pages
53?60.
1http://www.cs.chalmers.se/?aarne/GF/
7
Janusz A. Brzozowski. 1962. Canonical regular expres-
sions and minimal state graphs for definite events. In
Mathematical theory of Automata, Volume 12 of MRI
Symposia Series, pages 529?561. Polytechnic Press,
Polytechnic Institute of Brooklyn, N.Y.
John Dowding, Beth A. Hockey, Jean M. Gawron, and
Christopher Culy. 2001. Practical issues in compil-
ing typed unification grammars for speech recognition.
In ACL ?01: Proceedings of the 39th Annual Meeting
on Association for Computational Linguistics, pages
164?171, Morristown, NJ, USA. Association for Com-
putational Linguistics.
Stina Ericsson, Gabriel Amores, Bjo?rn Bringert, Ha?kan
Burden, Ann C. Forslund, David Hjelm, Rebecca Jon-
son, Staffan Larsson, Peter Ljunglo?f, Pilar Mancho?n,
David Milward, Guillermo Pe?rez, and Mikael Sandin.
2006. Software illustrating a unified approach to mul-
timodality and multilinguality in the in-home domain.
Technical Report 1.6, TALK Project.
Kallirroi Georgila and Oliver Lemon. 2006. Program-
ming by Voice: enhancing adaptivity and robustness
of spoken dialogue systems. In BRANDIAL?06, Pro-
ceedings of the 10th Workshop on the Semantics and
Pragmatics of Dialogue, pages 199?200.
Rebecca Jonson. 2006. Generating Statistical Lan-
guage Models from Interpretation Grammars in Dia-
logue Systems. In Proceedings of EACL?06.
Staffan Larsson. 2002. Issue-based Dialogue Manage-
ment. Ph.D. thesis, Go?teborg University.
Oliver Lemon and Xingkun Liu. 2006. DUDE: a
Dialogue and Understanding Development Environ-
ment, mapping Business Process Models to Informa-
tion State Update dialogue systems. In EACL 2006,
11st Conference of the European Chapter of the Asso-
ciation for Computational Linguistics.
Oliver Lemon, Kallirroi Georgila, David Milward, and
Tommy Herbert. 2006a. Programming Devices and
Services. Technical Report 2.3, TALK Project.
Oliver Lemon, Xingkun Liu, Daniel Shapiro, and Carl
Tollander. 2006b. Hierarchical Reinforcement Learn-
ing of Dialogue Policies in a development environment
for dialogue systems: REALL-DUDE. In BRAN-
DIAL?06, Proceedings of the 10th Workshop on the Se-
mantics and Pragmatics of Dialogue, pages 185?186,
September.
Peter Ljunglo?f. 2004. Expressivity and Complexity of
the Grammatical Framework. Ph.D. thesis, Go?teborg
University, Go?teborg, Sweden.
Peter Ljunglo?f. 2007a. Personal communication, March.
Peter Ljunglo?f. 2007b. Converting Grammatical Frame-
work to Regulus.
Mehryar Mohri and Mark J. Nederhof. 2001. Regu-
lar Approximation of Context-Free Grammars through
Transformation. In Jean C. Junqua and Gertjan van
Noord, editors, Robustness in Language and Speech
Technology, pages 153?163. Kluwer Academic Pub-
lishers, Dordrecht.
Robert C. Moore. 1999. Using Natural-Language
Knowledge Sources in Speech Recognition. In K. M.
Ponting, editor, Computational Models of Speech Pat-
tern Processing, pages 304?327. Springer.
Robert C. Moore. 2000. Removing left recursion from
context-free grammars. In Proceedings of the first
conference on North American chapter of the Associ-
ation for Computational Linguistics, pages 249?255,
San Francisco, CA, USA. Morgan Kaufmann Publish-
ers Inc.
Mark J. Nederhof. 2000. Regular Approximation of
CFLs: A Grammatical View. In Harry Bunt and Anton
Nijholt, editors, Advances in Probabilistic and other
Parsing Technologies, pages 221?241. Kluwer Aca-
demic Publishers.
Nadine Perera and Aarne Ranta. 2007. An Experiment in
Dialogue System Localization with the GF Resource
Grammar Library.
Aarne Ranta, Ali El Dada, and Janna Khegai. 2006. The
GF Resource Grammar Library, June.
Aarne Ranta. 2004. Grammatical Framework: A Type-
Theoretical Grammar Formalism. Journal of Func-
tional Programming, 14(2):145?189, March.
Manny Rayner, Beth A. Hockey, and Pierrette Bouil-
lon. 2006. Putting Linguistics into Speech Recogni-
tion: The Regulus Grammar Compiler. CSLI Publica-
tions, Ventura Hall, Stanford University, Stanford, CA
94305, USA, July.
Jessica Villing and Staffan Larsson. 2006. Dico: A
Multimodal Menu-based In-vehicle Dialogue System.
In BRANDIAL?06, Proceedings of the 10th Workshop
on the Semantics and Pragmatics of Dialogue, pages
187?188.
8
Proceedings of the EACL 2009 Demonstrations Session, pages 9?12,
Athens, Greece, 3 April 2009. c?2009 Association for Computational Linguistics
Grammatical Framework Web Service
Bjo?rn Bringert? and Krasimir Angelov and Aarne Ranta
Department of Computer Science and Engineering
Chalmers University of Technology and University of Gothenburg
{bringert,krasimir,aarne}@chalmers.se
Abstract
We present a web service for natural language
parsing, prediction, generation, and translation
using grammars in Portable Grammar Format
(PGF), the target format of the Grammatical
Framework (GF) grammar compiler. The web
service implementation is open source, works
with any PGF grammar, and with any web
server that supports FastCGI. The service ex-
poses a simple interface which makes it pos-
sible to use it for interactive natural language
web applications. We describe the function-
ality and interface of the web service, and
demonstrate several applications built on top
of it.
1 Introduction
Current web applications often consist of JavaScript
code that runs in the user?s web browser, with server-
side code that does the heavy lifting. We present a web
service for natural language processing with Portable
Grammar Format (PGF, Angelov et al, 2008) gram-
mars, which can be used to build interactive natural lan-
guage web applications. PGF is the back-end format
to which Grammatical Framework (GF, Ranta, 2004)
grammars are compiled. PGF has been designed to al-
low efficient implementations.
The web service has a simple API based solely on
HTTP GET requests. It returns responses in JavaScript
Object Notation (JSON, Crockford, 2006). The server-
side program is distributed as part of the GF software
distribution, under the GNU General Public License
(GPL). The program is generic, in the sense that it can
be used with any PGF grammar without any modifica-
tion of the program.
2 Grammatical Framework
Grammatical Framework (GF, Ranta, 2004) is a type-
theoretical grammar formalism. A GF grammar con-
sists of an abstract syntax, which defines a set of ab-
stract syntax trees, and one or more concrete syntaxes,
which define how abstract syntax trees are mapped to
(and from) strings. The process of producing a string
?Now at Google Inc.
(or, more generally, a feature structure) from an ab-
stract syntax tree is called linearization. The oppo-
site, producing an abstract syntax tree (or several, if the
grammar is ambiguous) from a string is called parsing.
In a small, semantically oriented application gram-
mar, the sentence ?2 is even? may correspond to the
abstract syntax tree Even 2. In a larger, more syn-
tactically oriented grammar, in this case the English
GF resource grammar (Ranta, 2007), the same sen-
tence can correspond to the abstract syntax tree PhrUtt
NoPConj (UttS (UseCl (TTAnt TPres ASimul)
PPos (PredVP (UsePN (NumPN (NumDigits (IDig
D 2)))) (UseComp (CompAP (PositA even A))))))
NoVoc.
2.1 Portable Grammar Format (PGF)
Portable Grammar Format (PGF, Angelov et al, 2008)
is a low-level format to which GF grammars are com-
piled. The PGF Web Service loads PGF files from disk,
and uses them to serve client requests. These PGF files
are normally produced by compiling GF grammars, but
they could also be produced by other means, for exam-
ple by a compiler from another grammar formalism.
Such compilers currently exist for context-free gram-
mars in BNF and EBNF formats, though they compile
via GF.
2.2 Parsing and Word Prediction
For each concrete syntax in a PGF file, there is a pars-
ing grammar, which is a Parallel Multiple Context Free
Grammar (PMCFG, Seki et al, 1991). The PGF inter-
preter uses an efficient parsing algorithm for PMCFG
(Angelov, 2009) which is similar to the Earley algo-
rithm for CFG. The algorithm is top-down and incre-
mental which makes it possible to use it for word com-
pletion. When the whole sentence is known, the parser
just takes the tokens one by one and computes the chart
of all possible parse trees. If the sentence is not yet
complete, then the known tokens can be used to com-
pute a partial parse chart. Since the algorithm is top-
down it is possible to predict the set of valid next tokens
by using just the partial chart.
The prediction can be used in applications to guide
the user to stay within the coverage of the grammar. At
each point the set of valid next tokens is shown and the
user can select one of them.
9
Figure 1: Translator interface. This example uses
the Bronzeage grammar, which consists of simple
syntactic rules along with lexica based on Swadesh
lists. Demo at http://digitalgrammars.com/
translate.
The word prediction is based entirely on the gram-
mar and not on any additional n-gram model. This
means that it works with any PGF grammar and no ex-
tra work is needed. In addition it works well even with
long distance dependencies. For example if the subject
is in a particular gender and the verb requires gender
agreement, then the the correct form is predicted, inde-
pendently on how far the verb is from the subject.
3 Applications
Several interactive web applications have been built
with the PGF Web Service. They are all JavaScript pro-
grams which run in the user?s web browser and send
asynchronous HTTP requests to the PGF Web Service.
3.1 Translator
The simplest application (see Figure 1) presents the
user with a text field for input, and drop-down boxes for
selecting the grammar and language to use. For every
change in the text field, the application asks the PGF
Web Service for a number of possible completions of
the input, and displays them below the text field. The
user can continue typing, or select one of the sugges-
tions. When the current input can be parsed completely,
the input is translated to all available languages.
3.2 Fridge Poetry
The second application is similar in functionality to the
first, but it presents a different user interface. The in-
terface (see Figure 2) mimics the popular refrigerator
magnet poetry sets. However, in contrast to physical
fridge magnets, this application handles inflection au-
tomatically and only allows the construction of gram-
matically correct sentences (as defined by the selected
grammar). It also shows translations for complete in-
puts and allows the user to switch languages.
Figure 2: Fridge poetry screenshot. Demo at http:
//digitalgrammars.com/fridge.
Figure 3: Reasoning screenshot. Demo at http://
digitalgrammars.com/mosg.
3.3 Reasoning
Another application is a natural language reasoning
system which accepts facts and questions from the
users, and tries to answer the questions based on the
facts given. The application uses the PGF Web Service
to parse inputs. It uses two other web services for se-
mantic interpretation and reasoning, respectively. The
semantic interpretation service uses a continuation-
based compositional mapping of abstract syntax terms
to first-order logic formulas (Bringert, 2008). The rea-
soning service is a thin layer on top of the Equinox the-
orem prover and the Paradox model finder (Claessen
and So?rensson, 2003).
4 API
Below, we will show URI paths for each function,
for example /pgf/food.pgf/parse. Arguments
to each function are given in the URL query string,
in application/x-www-form-urlencoded
(Raggett et al, 1999) format. Thus, if the service is
running on example.com, the URI for a request to
parse the string ?this fish is fresh? using the FoodEng
concrete syntax in the food.pgf grammar would
10
be: http://example.com/pgf/food.pgf/
parse?input=this+fish+is+fresh&from=
FoodEng. The functions described below each accept
some subset of the following arguments:
from The name of the concrete syntax to parse with
or translate from. Multiple from arguments can
be given, in which case all the specified languages
are tried. If omitted, all languages (that can be
used for parsing) are used.
cat The name of the abstract syntax category to parse
or translate in, or generate output in. If omitted,
the start category specified in the PGF file is used.
to The name of the concrete syntax to linearize or
translate to. Multiple to arguments can be given,
in which case all the specified languages are used.
If omitted, results for all languages are returned.
input The text to parse, complete or translate. If
omitted, the empty string is used.
tree The abstract syntax tree to linearize.
limit The maximum number of results to return.
All results are returned in UTF-8 encoded JSON or
JSONP format. A jsonp argument can be given to
each function to invoke a callback function when the
response is evaluated in a JavaScript interpreter. This
makes it possible to circumvent the Same Origin Policy
in the web browser and call the PGF Web Service from
applications loaded from another server.
4.1 Grammar List
/pgf retrieves a list of the available PGF files.
4.2 Grammar Info
/pgf/grammar.pgf, where grammar.pgf is the
name of a PGF file on the server, retrieves information
about the given grammar. This information includes
the name of the abstract syntax, the categories in the
abstract syntax, and the list of concrete syntaxes.
4.3 Parsing
/pgf/grammar.pgf/parse parses an input string
and returns a number of abstract syntax trees. Optional
arguments: input, from, cat.
4.4 Completion
/pgf/grammar.pgf/complete returns a list of
predictions for the next token, given a partial input.
Optional arguments: input, from, cat, limit. If
limit is omitted, all results are returned.
4.5 Linearization
/pgf/grammar.pgf/linearize accepts an ab-
stract syntax tree, and returns the results of lineariz-
ing it to one or more languages. Mandatory arguments:
tree. Optional arguments: to.
4.6 Random Generation
/pgf/grammar.pgf/random generates a number
of randomly generated abstract syntax trees for the se-
lected grammar. Optional arguments: cat, limit. If
limit is omitted, one tree is returned.
4.7 Translation
/pgf/grammar.pgf/translate performs text
to text translation. This is done by parsing, followed
by linearization. Optional arguments: input, from,
cat, to.
5 Application to Controlled Languages
The use of controlled languages is becoming more pop-
ular with the development of Web and Semantic Web
technologies. Related projects include Attempto (At-
tempto, 2008), CLOnE (Funk et al, 2007), and Com-
mon Logic Controlled English (CLCE) (Sowa, 2004).
All these projects provide languages which are subsets
of English and have semantic translations into first or-
der logic (CLCE), OWL (CLOnE) or both (Attempto).
In the case of Attempto, the translation is into first order
logic and if it is possible to the weaker OWL language.
The general idea is that since the controlled language
is a subset of some other language it should be under-
standable to everyone without special training. The op-
posite is not true - not every English sentence is a valid
sentence in the controlled language and the user must
learn how to stay within its limitations. Although this
is a disadvantage, in practice it is much easier to re-
member some subset of English phrases rather than to
learn a whole new formal language. Word suggestion
functionality such as that in the PGF Web Service can
help the user stay within the controlled fragment.
In contrast to the above mentioned systems, GF is
not a system which provides only one controlled lan-
guage, but a framework within which the developer can
develop his own language. The task is simplified by the
existence of a resource grammar library (Ranta, 2007)
which takes care of all low-level details such as word
order, and gender, number or case agreement. In fact,
the language developer does not have to be skilled in
linguistics, but does have to be a domain expert and
can concentrate on the specific task.
Most controlled language frameworks are focused
on some subset of English while other languages re-
ceive very little or no attention. With GF, the con-
trolled language does not have to be committed to only
one natural language but could have a parallel grammar
with realizations into many languages. In this case the
user could choose whether to use the English version
or, for example, the French version, and still produce
the same abstract representation.
6 Implementation
The PGF Web Service is a FastCGI program written in
Haskell. The program is a thin layer on top of the PGF
11
interpreter, which implements all the PGF functional-
ity, such as parsing, completion and linearization. The
web service also uses external libraries for FastCGI
communication, and JSON and UTF-8 encoding and
decoding.
The main advantage of using FastCGI instead of
plain CGI is that the PGF file does not have to be
reloaded for each request. Instead, each PGF file is
loaded the first time it is requested, and after that, it is
only reloaded if the file on disk is changed.
7 Performance
The web service layer introduces minimal overhead.
The typical response time for a parse request with a
small grammar, when running on a typical current PC,
is around 1 millisecond. For large grammars, response
times can be on the order of several seconds, but this is
entirely dependent on the PGF interpreter implementa-
tion.
The server is multi-threaded, with one lightweight
thread for each client request. A single instance of the
server can run threads on all cores of a multi-core pro-
cessor. Since the server maintains no state and requires
no synchronization, it can be easily replicated on mul-
tiple machines with load balancing. Since all requests
are cacheable HTTP GET requests, a caching proxy
could be used to improve performance if it is expected
that there will be repeated requests for the same URI.
8 Future Work
The abstract syntax in GF is based on Martin
Lo?f?s (1984) type theory and supports dependent types.
They can be used go beyond the pure syntax and to
check the sentences for semantic consistency. The cur-
rent parser completely ignores dependent types. This
means that the word prediction will suggest comple-
tions which might not be semantically meaningful.
In order to improve performance for high-traffic ap-
plications that use large grammars, the web service
could cache responses. As long as the grammar is not
modified, identical requests will always produce iden-
tical responses.
9 Conclusions
We have presented a web service for grammar-based
natural language processing, which can be used to build
interactive natural language web applications. The web
service has a simple API, based on HTTP GET requests
with JSON responses. The service allows high levels of
performance and scalability, and has been used to build
several applications.
References
Krasimir Angelov. 2009. Incremental Parsing with Par-
allel Multiple Context-Free Grammars. In European
Chapter of the Association for Computational Lin-
guistics.
Krasimir Angelov, Bjo?rn Bringert, and Aarne
Ranta. 2008. PGF: A Portable Run-Time For-
mat for Type-Theoretical Grammars. Journal
of Logic, Language and Information, submit-
ted. URL http://www.cs.chalmers.se/
?bringert/publ/pgf/pgf.pdf.
Attempto. 2008. Attempto Project Homepage -
http://attempto.ifi.uzh.ch/site/. URL http://
attempto.ifi.uzh.ch/site/.
Bjo?rn Bringert. 2008. Delimited Contin-
uations, Applicative Functors and Natu-
ral Language Semantics. URL http:
//www.cs.chalmers.se/?bringert/
publ/continuation-semantics/
continuation-semantics.pdf.
Koen Claessen and Niklas So?rensson. 2003. New
Techniques that Improve MACE-style Model Find-
ing. In Workshop on Model Computation
(MODEL). URL http://www.cs.chalmers.
se/?koen/pubs/model-paradox.ps.
Douglas Crockford. 2006. The application/json Media
Type for JavaScript Object Notation (JSON). RFC
4627 (Informational). URL http://www.ietf.
org/rfc/rfc4627.txt.
Adam Funk, Valentin Tablan, Kalina Bontcheva,
Hamish Cunningham, Brian Davis, and Siegfried
Handschuh. 2007. CLOnE: Controlled Language for
Ontology Editing. In Proceedings of the Interna-
tional Semantic Web Conference (ISWC 2007). Bu-
san, Korea.
Per Martin-Lo?f. 1984. Intuitionistic Type Theory. Bib-
liopolis, Naples.
Dave Raggett, Arnaud Le Hors, and Ian Jacobs.
1999. HTML 4.01 Specification. Technical report,
W3C. URL http://www.w3.org/TR/1999/
REC-html401-19991224/.
Aarne Ranta. 2004. Grammatical Framework: A
Type-Theoretical Grammar Formalism. Jour-
nal of Functional Programming, 14(2):145?189.
URL http://dx.doi.org/10.1017/
S0956796803004738.
Aarne Ranta. 2007. Modular Grammar Engineering
in GF. Research on Language and Computation,
5(2):133?158. URL http://dx.doi.org/10.
1007/s11168-007-9030-6.
Hiroyuki Seki, Takashi Matsumura, Mamoru Fujii,
and Tadao Kasami. 1991. On multiple context-
free grammars. Theoretical Computer Science,
88(2):191?229. URL http://dx.doi.org/
10.1016/0304-3975(91)90374-B.
John Sowa. 2004. Common Logic Controlled En-
glish. Draft. URL http://www.jfsowa.com/
clce/specs.htm.
12
Proceedings of the EACL 2009 Demonstrations Session, pages 57?60,
Athens, Greece, 3 April 2009. c?2009 Association for Computational Linguistics
Grammar Development in GF
Aarne Ranta and Krasimir Angelov and Bjo?rn Bringert?
Department of Computer Science and Engineering
Chalmers University of Technology and University of Gothenburg
{aarne,krasimir,bringert}@chalmers.se
Abstract
GF is a grammar formalism that has a
powerful type system and module system,
permitting a high level of abstraction and
division of labour in grammar writing. GF
is suited both for expert linguists, who
appreciate its capacity of generalizations
and conciseness, and for beginners, who
benefit from its static type checker and,
in particular, the GF Resource Grammar
Library, which currently covers 12 lan-
guages. GF has a notion of multilingual
grammars, enabling code sharing, linguis-
tic generalizations, rapid development of
translation systems, and painless porting
of applications to new languages.
1 Introduction
Grammar implementation for natural languages is
a challenge for both linguistics and engineering.
The linguistic challenge is to master the complex-
ities of languages so that all details are taken into
account and work seamlessly together; if possible,
the description should be concise and elegant, and
capture the linguist?s generalizations on the level
of code. The engineering challenge is to make
the grammar scalable, reusable, and maintainable.
Too many grammars implemented in the history of
computational linguistics have become obsolete,
not only because of their poor maintainability, but
also because of the decay of entire software and
hardware platforms.
The first measure to be taken against the ?bit
rot? of grammars is to write them in well-defined
formats that can be implemented independently
of platform. This requirement is more or less an
axiom in programming language development: a
?Now at Google Inc.
language must have syntax and semantics specifi-
cations that are independent of its first implemen-
tation; otherwise the first implementation risks to
remain the only one.
Secondly, since grammar engineering is to a
large extent software engineering, grammar for-
malisms should learn from programming language
techniques that have been found useful in this re-
spect. Two such techniques are static type sys-
tems and module systems. Since grammar for-
malism implementations are mostly descendants
of Lisp and Prolog, they usually lack a static type
system that finds errors at compile time. In a com-
plex task like grammar writing, compile-time er-
ror detection is preferable to run-time debugging
whenever possible. As for modularity, traditional
grammar formalisms again inherit from Lisp and
Prolog low-level mechanisms like macros and file
includes, which in modern languages like Java and
ML have been replaced by advanced module sys-
tems akin in rigour to type systems.
Thirdly, as another lesson from software en-
gineering, grammar writing should permit an in-
creasing use of libraries, so that programmers can
build on ealier code. Types and modules are essen-
tial for the management of libraries. When a new
language is developed, an effort is needed in creat-
ing libraries for the language, so that programmers
can scale up to real-size tasks.
Fourthly, a grammar formalism should have a
stable and efficient implementation that works
on different platforms (hardware and operating
systems). Since grammars are often parts of larger
language-processing systems (such as translation
tools or dialogue systems), their interoperability
with other components is an important issue. The
implementation should provide compilers to stan-
dard formats, such as databases and speech recog-
nition language models. In addition to interoper-
ability, such compilers also help keeping the gram-
mars alive even if the original grammar formalism
57
ceases to exist.
Fifthly, grammar formalisms should have rich
documentation; in particular, they should have
accessible tutorials that do not demand the read-
ers to be experts in a linguistic theory or in com-
puter programming. Also the libraries should be
documented, preferably by automatically gener-
ated documentation in the style of JavaDoc, which
is guaranteed to stay up to date.
Last but not least, a grammar formalism, as well
its documentation, implementation, and standard
libraries, should be freely available open-source
software that anyone can use, inspect, modify, and
improve. In the domain of general-purpose pro-
gramming, this is yet another growing trend; pro-
prietary languages are being made open-source or
at least free of charge.
2 The GF programming language
The development of GF started in 1998 at Xe-
rox Research Centre Europe in Grenoble, within a
project entitled ?Multilingual Document Author-
ing? (Dymetman & al. 2000). Its purpose was
to make it productive to build controlled-language
translators and multilingual authoring systems,
previously produced by hard-coded grammar
rules rather than declarative grammar formalisms
(Power & Scott 1998). Later, mainly at Chalmers
University in Gothenburg, GF developed into a
functional programming language inspired by ML
and Haskell, with a strict type system and oper-
ational semantics specified in (Ranta 2004). A
module system was soon added (Ranta 2007), in-
spired by the parametrized modules of ML and
the class inheritance hierarchies of Java, although
with multiple inheritance in the style of C++.
Technically, GF falls within the class of so-
called Curry-style categorial grammars, inspired
by the distinction between tectogrammatical and
phenogrammatical structure in (Curry 1963).
Thus a GF grammar has an abstract syntax defin-
ing a system of types and trees (i.e. a free algebra),
and a concrete syntax, which is a homomorphic
mapping from trees to strings and, more generally,
to records of strings and features. To take a simple
example, the NP-VP predication rule, written
S ::= NP VP
in a context-free notation, becomes in GF a pair of
an abstract and a concrete syntax rule,
fun Pred : NP -> VP -> S
lin Pred np vp = np ++ vp
The keyword fun stands for function declara-
tion (declaring the function Pred of type NP ->
VP -> S), whereas lin stands for linearization
(saying that trees of form Pred np vp are con-
verted to strings where the linearization of np is
followed by the linearization of vp). The arrow
-> is the normal function type arrow of program-
ming languages, and ++ is concatenation.
Patterns more complex than string concatena-
tion can be used in linearizations of the same pred-
ication trees as the rule above. Thus agreement
can be expressed by using features passed from the
noun phrase to the verb phrase. The noun phrase
is here defined as not just a string, but as a record
with two fields?a string s and an agreement fea-
ture a. Verb-subject inversion can be expressed by
making VP into a discontinuous constituent, i.e.
a record with separate verb and complement fields
v and c. Combining these two phenomena, we
write
vp.v ! np.a ++ np.s ++ vp.c
(For the details of the notation, we refer to doc-
umentation on the GF web page.) Generalizing
strings into richer data structures makes it smooth
to deal accurately with complexities such as Ger-
man constituent order and Romance clitics, while
maintaining the simple tree structure defined by
the abstract syntax of Pred.
Separating abstract and concrete syntax makes
it possible to write multilingual grammars,
where one abstract syntax is equipped with several
concrete syntaxes. Thus different string configura-
tions can be mapped into the same abstract syntax
trees. For instance, the distinction between SVO
and VSO languages can be ignored on the abstract
level, and so can all other {S,V,O} patterns as well.
Also the differences in feature systems can be ab-
stracted away from. For instance, agreement fea-
tures in English are much simpler than in Arabic;
yet the same abstract syntax can be used.
Since concrete syntax is reversible between lin-
earization and parsing (Ljunglo?f 2004), multilin-
gual grammars can be used for translation, where
the abstract syntax works as interlingua. Experi-
ence from translation projects (e.g. Burke and Jo-
hannisson 2005, Caprotti 2006) has shown that the
interlingua-based translation provided by GF gives
good quality in domain-specific tasks. However,
GF also supports the use of a transfer component if
the compositional method implied by multilingual
grammars does not suffice (Bringert and Ranta
58
2008). The language-theoretical strenght of GF is
between mildly and fully context-sensitive, with
polynomial parsing complexity (Ljunglo?f 2004).
In addition to multilingual grammars, GF is
usable for more traditional, large-scale unilin-
gual grammar development. The ?middle-scale?
resource grammars can be extended to wide-
coverage grammars, by adding a few rules and
a large lexicon. GF provides powerful tools for
building morphological lexica and exporting them
to other formats, including Xerox finite state tools
(Beesley and Karttunen 2003) and SQL databases
(Forsberg and Ranta 2004). Some large lexica
have been ported to the GF format from freely
available sources for Bulgarian, English, Finnish,
Hindi, and Swedish, comprising up to 70,000 lem-
mas and over two million word forms.
3 The GF Resource Grammar Library
The GF Resource Grammar Library is a com-
prehensive multilingual grammar currently imple-
mented for 12 languages: Bulgarian, Catalan,
Danish, English, Finnish, French, German, Italian,
Norwegian, Russian, Spanish, and Swedish. Work
is in progress on Arabic, Hindi/Urdu, Latin, Pol-
ish, Romanian, and Thai. The library is an open-
source project, which constantly attracts new con-
tributions.
The library can be seen as an experiment on how
far the notion of multilingual grammars extends
and how GF scales up to wide-coverage gram-
mars. Its primary purpose, however, is to provide
a programming resource similar to the standard li-
braries of various programming languages. When
all linguistic details are taken into account, gram-
mar writing is an expert programming task, and
the library aims to make this expertise available to
non-expert application programmers.
The coverage of the library is comparable to the
Core Language Engine (Rayner & al. 2000). It has
been developed and tested in applications ranging
from a translation system for software specifica-
tions (Burke and Johannisson 2005) to in-car dia-
logue systems (Perera and Ranta 2007).
The use of a grammar as a library is made pos-
sible by the type and module system of GF (Ranta
2007). What is more, the API (Application Pro-
grammer?s Interface) of the library is to a large ex-
tent language-independent. For instance, an NP-
VP predication rule is available for all languages,
even though the underlying details of predication
vary greatly from one language to another.
A typical domain grammar, such as the one in
Perera and Ranta (2007), has 100?200 syntactic
combinations and a lexicon of a few hundred lem-
mas. Building the syntax with the help of the li-
brary is a matter of a few working days. Once it
is built for one language, porting it to other lan-
guages mainly requires writing the lexicon. By
the use of the inflection libraries, this is a matter of
hours. Thus porting a domain grammar to a new
language requires very effort and also very little
linguistic knowledge: it is expertise of the appli-
cation domain and its terminology that is needed.
4 The GF grammar compiler
The GF grammar compiler is usable in two ways:
in batch mode, and as an interactive shell. The
shell is a useful tool for developers as it provides
testing facilities such as parsing, linerization, ran-
dom generation, and grammar statistics. Both
modes use PGF, Portable Grammar Format,
which is the ?machine language? of GF permit-
ting fast run-time linearization and parsing (An-
gelov & al. 2008). PGF interpreters have been
written in C++, Java, and Haskell, permitting an
easy embedding of grammars in systems written
in these languages. PGF can moreover be trans-
lated to other formats, including language mod-
els for speech recognition (e.g. Nuance and HTK;
see Bringert 2007a), VoiceXML (Bringert 2007b),
and JavaScript (Meza Moreno and Bringert 2008).
The grammar compiler is heavily optimizing, so
that the use of a large library grammar in small
run-time applications produces no penalty.
For the working grammarian, static type check-
ing is maybe the most unique feature of the GF
grammar compiler. Type checking does not only
detect errors in grammars. It also enables aggres-
sive optimizations (type-driven partial evaluation),
and overloading resolution, which makes it pos-
sible to use the same name for different functions
whose types are different.
5 Related work
As a grammar development system, GF is compa-
rable to Regulus (Rayner 2006), LKB (Copestake
2002), and XLE (Kaplan and Maxwell 2007). The
unique features of GF are its type and module sys-
tem, support for multilingual grammars, the large
number of back-end formats, and the availability
of libraries for 12 languages. Regulus has resource
59
grammars for 7 languages, but they are smaller in
scope. In LKB, the LinGO grammar matrix has
been developed for several languages (Bender and
Flickinger 2005), and in XLE, the Pargram gram-
mar set (Butt & al. 2002). LKB and XLE tools
have been targeted to linguists working with large-
scale grammars, rather than for general program-
mers working with applications.
References
[Angelov et al2008] K. Angelov, B. Bringert, and
A. Ranta. 2008. PGF: A Portable Run-Time Format
for Type-Theoretical Grammars. Chalmers Univer-
sity. Submitted for publication.
[Beesley and Karttunen2003] K. Beesley and L. Kart-
tunen. 2003. Finite State Morphology. CSLI Publi-
cations.
[Bender and Flickinger2005] Emily M. Bender and
Dan Flickinger. 2005. Rapid prototyping of scal-
able grammars: Towards modularity in extensions
to a language-independent core. In Proceedings of
the 2nd International Joint Conference on Natural
Language Processing IJCNLP-05 (Posters/Demos),
Jeju Island, Korea.
[Bringert and Ranta2008] B. Bringert and A. Ranta.
2008. A Pattern for Almost Compositional Func-
tions. The Journal of Functional Programming,
18(5?6):567?598.
[Bringert2007a] B. Bringert. 2007a. Speech Recogni-
tion Grammar Compilation in Grammatical Frame-
work. In SPEECHGRAM 2007: ACL Workshop on
Grammar-Based Approaches to Spoken Language
Processing, June 29, 2007, Prague.
[Bringert2007b] Bjo?rn Bringert. 2007b. Rapid Devel-
opment of Dialogue Systems by Grammar Compi-
lation. In Simon Keizer, Harry Bunt, and Tim Paek,
editors, Proceedings of the 8th SIGdial Workshop on
Discourse and Dialogue, Antwerp, Belgium, pages
223?226. Association for Computational Linguis-
tics, September.
[Bringert2008] B. Bringert. 2008. Semantics of the GF
Resource Grammar Library. Report, Chalmers Uni-
versity.
[Burke and Johannisson2005] D. A. Burke and K. Jo-
hannisson. 2005. Translating Formal Software
Specifications to Natural Language / A Grammar-
Based Approach. In P. Blache and E. Stabler and
J. Busquets and R. Moot, editor, Logical Aspects
of Computational Linguistics (LACL 2005), volume
3492 of LNCS/LNAI, pages 51?66. Springer.
[Butt et al2002] M. Butt, H. Dyvik, T. Holloway King,
H. Masuichi, and C. Rohrer. 2002. The Parallel
Grammar Project. In COLING 2002, Workshop on
Grammar Engineering and Evaluation, pages 1?7.
URL
[Caprotti2006] O. Caprotti. 2006. WebALT! Deliver
Mathematics Everywhere. In Proceedings of SITE
2006. Orlando March 20-24.
[Copestake2002] A. Copestake. 2002. Implementing
Typed Feature Structure Grammars. CSLI Publica-
tions.
[Curry1963] H. B. Curry. 1963. Some logical aspects
of grammatical structure. In Roman Jakobson, edi-
tor, Structure of Language and its Mathematical As-
pects: Proceedings of the Twelfth Symposium in Ap-
plied Mathematics, pages 56?68. American Mathe-
matical Society.
[Dymetman et al2000] M. Dymetman, V. Lux, and
A. Ranta. 2000. XML and multilingual docu-
ment authoring: Convergent trends. In COLING,
Saarbru?cken, Germany, pages 243?249.
[Forsberg and Ranta2004] M. Forsberg and A. Ranta.
2004. Functional Morphology. In ICFP 2004,
Showbird, Utah, pages 213?223.
[Ljunglo?f2004] P. Ljunglo?f. 2004. The Expressivity
and Complexity of Grammatical Framework. Ph.D.
thesis, Dept. of Computing Science, Chalmers Uni-
versity of Technology and Gothenburg University.
[Meza Moreno and Bringert2008] M. S. Meza Moreno
and B. Bringert. 2008. Interactive Multilingual
Web Applications with Grammarical Framework. In
B. Nordstro?m and A. Ranta, editors, Advances in
Natural Language Processing (GoTAL 2008), vol-
ume 5221 of LNCS/LNAI, pages 336?347.
[Perera and Ranta2007] N. Perera and A. Ranta. 2007.
Dialogue System Localization with the GF Resource
Grammar Library. In SPEECHGRAM 2007: ACL
Workshop on Grammar-Based Approaches to Spo-
ken Language Processing, June 29, 2007, Prague.
[Power and Scott1998] R. Power and D. Scott. 1998.
Multilingual authoring using feedback texts. In
COLING-ACL.
[Ranta2004] A. Ranta. 2004. Grammatical Frame-
work: A Type-Theoretical Grammar Formal-
ism. The Journal of Functional Programming,
14(2):145?189.
[Ranta2007] A. Ranta. 2007. Modular Grammar Engi-
neering in GF. Research on Language and Compu-
tation, 5:133?158.
[Rayner et al2000] M. Rayner, D. Carter, P. Bouillon,
V. Digalakis, and M. Wire?n. 2000. The Spoken
Language Translator. Cambridge University Press,
Cambridge.
[Rayner et al2006] M. Rayner, B. A. Hockey, and
P. Bouillon. 2006. Putting Linguistics into Speech
Recognition: The Regulus Grammar Compiler.
CSLI Publications.
60
Coling 2008: Proceedings of the workshop on Speech Processing for Safety Critical Translation and Pervasive Applications, pages 5?8
Manchester, August 2008
Speech Translation with Grammatical Framework
Bj
?
orn Bringert
Department of Computer Science and Engineering
Chalmers University of Technology and University of Gothenburg
bringert@chalmers.se
Abstract
Grammatical Framework (GF) is a gram-
mar formalism which supports interlingua-
based translation, library-based grammar
engineering, and compilation to speech
recognition grammars. We show how these
features can be used in the construction
of portable high-precision domain-specific
speech translators.
1 Introduction
Speech translators for safety-critical applications
such as medicine need to offer high-precision
translation. One way to achieve high precision
is to limit the coverage of the translator to a spe-
cific domain. The development of such high-
precision domain-specific translators can be re-
source intensive, and require rare combinations of
developer skills. For example, consider developing
a Russian?Swahili speech translator for the ortho-
pedic domain using direct translation between the
two languages. Developing such a system could
require an orthopedist programmer and linguist
who speaks Russian and Swahili. Such people may
be hard to find. Furthermore, developing transla-
tors for all pairs of N languages requires O(N
2
)
systems, developed by an equal number of bilin-
gual domain experts.
The language pair explosion and the need for
the same person to possess knowledge about the
source and target languages can be avoided by
using an interlingua-based approach. The re-
quirement that developers be both domain ex-
perts and linguists can be addressed by the use of
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
grammar libraries which implement the domain-
independent linguistic details of each language.
Grammatical Framework (GF) (Ranta, 2004)
is a type-theoretic grammar formalism which
is well suited to high-precision domain-specific
interlingua-based translation (Khegai, 2006), and
library-based grammar engineering (Ranta, 2008).
GF divides grammars into abstract syntax and con-
crete syntax. The abstract syntax defines what can
be said in the grammar, and the concrete syntax de-
fines how it is said in a particular language. If one
abstract syntax syntax is given multiple concrete
syntaxes, the abstract syntax can be used as an in-
terlingua. Given an abstract and a concrete syn-
tax, GF allows both parsing (text to abstract syn-
tax) and linearization (abstract syntax to text). This
means that interlingua-based translation is just a
matter of parsing in one language and linearizing
to another.
The GF resource grammar library (Ranta, 2008)
implements the domain-independent morphologi-
cal and syntactic details of eleven languages. A
grammar writer can use functions from a resource
grammar when defining the concrete syntax of an
application grammar. This is made possible by
GF?s support for grammar composition, and frees
the grammar writer from having to implement lin-
guistic details such as agreement, word order etc.
In addition to parsing and linearization, the
declarative nature of GF grammars allows them to
be compiled to other grammar formats. The GF
speech recognition grammar compiler (Bringert,
2007) can produce context-free grammars or finite-
state models which can be used to guide speech
recognizers.
These components, interlingua-based transla-
tion, grammar libraries, and speech recognition
grammar compilation, can be used to develop
5
domain-specific speech translators based on GF
grammars. Figure 1 shows an overview of a min-
imal unidirectional speech translator which uses
these components. This is a proof-of-concept sys-
tem that demonstrates how GF components can
be used for speech translation, and as such it can
hardly be compared to a more complete and mature
system such as MedSLT (Bouillon et al, 2005).
However, the system has some promising features
compared to systems based on unification gram-
mars: the expressive power of GF?s concrete syn-
tax allows us to use an application-specific inter-
lingua without any transfer rules, and the wide lan-
guage support of the GF Resource Grammar li-
brary makes it possible to quickly port applications
to new languages.
In Section 2 we show a small example grammar
for a medical speech translator. Section 3 briefly
discusses how a speech translator can be imple-
mented. Section 5 describes some possible ex-
tensions to the proof-of-concept system, and Sec-
tion 6 offers some conclusions.
2 Example Grammar
We will show a fragment of a grammar for a med-
ical speech translator. The example comes from
Khegai?s (2006) work on domain-specific transla-
tion with GF, and has been updated to use the cur-
rent version of the GF resource library API.
The small abstract syntax (interlingua) shown
in Figure 2 has three categories (cat): the start
category Prop for complete utterances, Patient
for identifying patients, and Medicine for iden-
tifying medicines. Each category contains a
single function (fun). There are the nullary
functions ShePatient and PainKiller, and the bi-
nary NeedMedicine, which takes a Patient and a
Medicine as arguments, and produces a Prop. This
simple abstract syntax only allows us to construct
the term NeedMedicine ShePatient PainKiller.
A larger version could for example include cat-
egories for body parts, symptoms and illnesses,
and more functions in each category. An example
of a term in such an extended grammar could be
And (Injured TheyPatient Foot) (NeedMedicine
HePatient Laxative).
For this abstract syntax we can use the En-
glish resource grammar to write an English con-
crete syntax, as shown in Figure 3. The resource
grammar category NP is used as the linearization
type (lincat) of the application grammar categories
abstract Health = {
flags startcat = Prop;
cat Patient;Medicine;Prop;
fun
ShePatient : Patient;
PainKiller : Medicine;
NeedMedicine : Patient ? Medicine ? Prop;
}
Figure 2: Example abstract syntax.
Patient and Medicine, and S is used for Prop. The
linearizations (lin) of each abstract syntax function
use overloaded functions from the resource gram-
mar, such as mkCl and mkN which create clauses
and nouns, respectively.
concrete HealthEng of Health =
open SyntaxEng,ParadigmsEng in {
lincat Patient,Medicine = NP;Prop = S;
lin
ShePatient = mkNP she Pron;
PainKiller =
mkNP indefSgDet (mkN ?painkiller?);
NeedMedicine p m =
mkS (mkCl p (mkV2 (mkV ?need?)) m);
}
Figure 3: English concrete syntax.
Figure 4 shows a Swedish concrete syntax cre-
ated in the same way. Note that PainKiller in
Swedish uses a mass noun construction rather than
the indefinite article.
concrete HealthSwe of Health =
open SyntaxSwe,ParadigmsSwe in {
lincat Patient,Medicine = NP;Prop = S;
lin
ShePatient = mkNP she Pron;
PainKiller =
mkNP massQuant
(mkN ?sm?artstillande?);
NeedMed p m =
mkS (mkCl p
(mkV2 (mkV ?beh?over?)) m);
}
Figure 4: Swedish concrete syntax.
6
Grammar development
Resource grammar library
Application grammar
Speech translator
PGF interpreter
Speech 
recognizer
(L
1
)
Speech 
synthesizer
(L
2
)
Parser
(L
1
)
Linearizer
(L
2
)
Speech
(L
1
)
Text
(L
2
)
Text
(L
1
)
Speech recognition
grammar (L
1)
Speech recognition 
grammar compiler
Grammar 
compiler
PGF
Speech
(L
2
)
User
(L
1
)
User 
(L
2
)
Abstract
syntax term
PGF
Abstract syntax
Concrete syntax 
(L
1
)
Concrete syntax 
(L
2
)
Resource grammar 
(L
1
)
Resource grammar 
(L
2
)
Figure 1: Overview of a GF-based speech translator. The developer writes a multilingual application
grammar using the resource grammar library. This is compiled to a PGF (Portable Grammar Format)
grammar used for parsing and linearization, and a speech recognition grammar. Off-the-shelf speech
recognizers and speech synthesizers are used together with a PGF interpreter in the running system.
3 Speech Translator Implementation
The GF grammar compiler takes grammars in
the GF source language used by programmers,
and produces grammars in a low-level language
(Portable Grammar Format, PGF (Angelov et
al., 2008)) for which interpreters can be eas-
ily and efficiently implemented. There are cur-
rently PGF implementations in Haskell, Java and
JavaScript. The GF speech recognition gram-
mar compiler (Bringert, 2007) targets many differ-
ent formats, including Nuance GSL, SRGS, JSGF
and HTK SLF. This means that speech transla-
tors based on GF can easily be implemented on
almost any platform for which there is a speech
recognizer and speech synthesizer. We have run
Java-based versions under Windows using Nuance
Recognizer and RealSpeak or FreeTTS, Haskell-
based versions under Linux using Nuance Recog-
nizer and RealSpeak, and JavaScript-based proto-
types in the Opera XHTML+Voice-enabled web
browser on Zaurus PDAs and Windows desktops.
The speech translation system itself is domain-
independent. All that is required to use it in a new
domain is an application grammar for that domain.
4 Evaluation
Since we have presented a proof-of-concept sys-
tem that demonstrates the use of GF for speech
translation, rather than a complete system for any
particular domain, quantitative translation perfor-
mance evaluation would be out of place. Rather,
we have evaluated the portability and speed of pro-
totyping. Our basic speech translators written in
Java and Haskell, using existing speech compo-
nents and PGF interpreters, require less than 100
lines of code each. Developing a small domain for
the translator can be done in under 10 minutes.
5 Extensions
5.1 Interactive Disambiguation
The concrete syntax for the source language may
be ambiguous, i.e. there may be sentences for
which parsing produces multiple abstract syntax
7
terms. The ambiguity can sometimes be preserved
in the target language, if all the abstract syntax
terms linearize to the same sentence.
In cases where the ambiguity cannot be pre-
served, or if we want to force disambiguation for
safety reasons, we can use a disambiguation gram-
mar to allow the user to choose an interpretation.
This is a second concrete syntax which is com-
pletely unambiguous. When the user inputs an
ambiguous sentence, the system linearizes each of
the abstract syntax terms with the disambiguation
grammar, and prompts the user to select the sen-
tence with the intended meaning. If only some
of the ambiguity can be preserved, the number
of choices can be reduced by grouping the ab-
stract syntax terms into equivalence classes based
on whether they produce the same sentences in the
target language. Since all terms in a class produce
the same output, the user only needs to select the
correct class of unambiguous sentences.
Another source of ambiguity is that two abstract
syntax terms can have distinct linearizations in the
source language, but identical target language lin-
earizations. In this case, the output sentence will
be ambiguous, even though the input was unam-
biguous. This could be addressed by using unam-
biguous linearizations for system output, though
this may lead to the use of unnatural constructions.
5.2 Bidirectional Translation
Since GF uses the same grammar for parsing and
linearization, the grammar for a translator from L
1
to L
2
can also be used in a translator from L
2
to
L
1
, provided that the appropriate speech compo-
nents are available. Two unidirectional translators
can be used as a bidirectional translator, something
which is straightforwardly achieved using two
computers. While PGF interpreters can already be
used for bidirectional translation, a single-device
bidirectional speech translator requires multiplex-
ing or duplicating the sound hardware.
5.3 Larger Input Coverage
GF?s variants feature allows an abstract syntax
function to have multiple representations in a given
concrete syntax. This permits some variation in
the input, while producing the same interlingua
term. For example, the linearization of PainKiller
in the English concrete syntax in Figure 3 could be
changed to:
mkNP indefSgDet (variants{
mkN ?painkiller?;mkN ?analgesic?});
6 Conclusions
Because it uses a domain-specific interlingua, a
GF-based speech translator can achieve high pre-
cision translation and scale to support a large num-
ber of languages.
The GF resource grammar library reduces the
development effort needed to implement a speech
translator for a new domain, and the need for the
developer to have detailed linguistic knowledge.
Systems created with GF are highly portable to
new platforms, because of the wide speech recog-
nition grammar format support, and the availability
of PGF interpreters for many platforms.
With additional work, GF could be used to im-
plement a full-scale speech translator. The ex-
isting GF components for grammar development,
speech recognition grammar compilation, parsing,
and linearization could also be used as parts of
larger systems.
References
Angelov, Krasimir, Bj?orn Bringert, and Aarne
Ranta. 2008. PGF: A Portable Run-Time
Format for Type-Theoretical Grammars.
Manuscript, http://www.cs.chalmers.
se/
?
bringert/publ/pgf/pgf.pdf.
Bouillon, P., M. Rayner, N. Chatzichrisafis, B. A.
Hockey, M. Santaholma, M. Starlander, H. Isahara,
K. Kanzaki, and Y. Nakao. 2005. A generic Multi-
Lingual Open Source Platform for Limited-Domain
Medical Speech Translation. pages 5?58, May.
Bringert, Bj?orn. 2007. Speech Recognition Grammar
Compilation in Grammatical Framework. In Pro-
ceedings of the Workshop on Grammar-Based Ap-
proaches to Spoken Language Processing, pages 1?
8, Prague, Czech Republic.
Khegai, Janna. 2006. Grammatical Framework (GF)
for MT in sublanguage domains. In Proceedings
of EAMT-2006, 11th Annual conference of the Eu-
ropean Association for Machine Translation, Oslo,
Norway, pages 95?104, June.
Ranta, Aarne. 2004. Grammatical Framework: A
Type-Theoretical Grammar Formalism. Journal of
Functional Programming, 14(2):145?189, March.
Ranta, Aarne. 2008. Grammars as software libraries.
In Bertot, Yves, G?erard Huet, Jean-Jacques L?evy,
and Gordon Plotkin, editors, From semantics to com-
puter science: essays in honor of Gilles Kahn. Cam-
bridge University Press.
8
