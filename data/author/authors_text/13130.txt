Coling 2010: Poster Volume, pages 1515?1523,
Beijing, August 2010
Active Deep Networks for Semi-Supervised                              
Sentiment Classification 
Shusen Zhou, Qingcai Chen and Xiaolong Wang 
Shenzhen Graduate School, Harbin Institute of Technology 
zhoushusen@hitsz.edu.cn, qincai.chen@hitsz.edu.cn, 
wangxl@insun.hit.edu.cn 
 
 
Abstract 
This paper presents a novel semi-
supervised learning algorithm called Ac-
tive Deep Networks (ADN), to address 
the semi-supervised sentiment classifica-
tion problem with active learning. First, 
we propose the semi-supervised learning 
method of ADN. ADN is constructed by 
Restricted Boltzmann Machines (RBM) 
with unsupervised learning using labeled 
data and abundant of unlabeled data. 
Then the constructed structure is fine-
tuned by gradient-descent based super-
vised learning with an exponential loss 
function. Second, we apply active learn-
ing in the semi-supervised learning 
framework to identify reviews that 
should be labeled as training data. Then 
ADN architecture is trained by the se-
lected labeled data and all unlabeled data. 
Experiments on five sentiment classifica-
tion datasets show that ADN outper-
forms the semi-supervised learning algo-
rithm and deep learning techniques ap-
plied for sentiment classification. 
1 Introduction 
In recent years, sentiment analysis has received 
considerable attentions in Natural Language 
Processing (NLP) community (Blitzer et al, 
2007; Dasgupta and Ng, 2009; Pang et al, 2002). 
Polarity classification, which determine whether 
the sentiment expressed in a document is posi-
tive or negative, is one of the most popular tasks 
of sentiment analysis (Dasgupta and Ng, 2009). 
Sentiment classification is a special type of text 
categorization, where the criterion of classifica-
tion is the attitude expressed in the text, rather 
than the subject or topic. Labeling the reviews 
with their sentiment would provide succinct 
summaries to readers, which makes it possible to 
focus the text mining on areas in need of im-
provement or on areas of success (Gamon, 2004) 
and is helpful in business intelligence applica-
tions, recommender systems, and message filter-
ing (Pang, et al, 2002). 
While topics are often identifiable by key-
words alone, sentiment classification appears to 
be a more challenge task (Pang, et al, 2002). 
First, sentiment is often conveyed with subtle 
linguistic mechanisms such as the use of sar-
casm and highly domain-specific contextual 
cues (Li et al, 2009). For example, although the 
sentence ?The thief tries to protect his excellent 
reputation? contains the word ?excellent?, it tells 
us nothing about the author?s opinion and in fact 
could be well embedded in a negative review. 
Second, sentiment classification systems are typ-
ically domain-specific, which makes the expen-
sive process of annotating a large amount of data 
for each domain and is a bottleneck in building 
high quality systems (Dasgupta and Ng, 2009). 
This motivates the task of learning robust senti-
ment models from minimal supervision (Li, et 
al., 2009).  
Recently, semi-supervised learning, which 
uses large amount of unlabeled data together 
with labeled data to build better learners (Raina 
et al, 2007; Zhu, 2007), has drawn more atten-
tion in sentiment analysis (Dasgupta and Ng, 
2009; Li, et al, 2009). As argued by several re-
searchers (Bengio, 2007; Salakhutdinov and 
Hinton, 2007), deep architecture, composed of 
multiple levels of non-linear operations (Hinton 
et al, 2006), is expected to perform well in 
semi-supervised learning because of its capabili-
ty of modeling hard artificial intelligent tasks. 
Deep Belief Networks (DBN) is a representative 
1515
deep learning algorithm achieving notable suc-
cess for semi-supervised learning (Hinton, et al, 
2006).  Ranzato and Szummer (2008) propose an 
algorithm to learn text document representations 
based on semi-supervised auto-encoders that are 
combined to form a deep network. 
Active learning is another way that can mi-
nimize the number of required labeled data 
while getting competitive result. Usually, the 
training set is chosen randomly. However, active 
learning choose the training data actively, which 
reduce the needs of labeled data (Tong and 
Koller, 2002). Recently, active learning had 
been applied in sentiment classification 
(Dasgupta and Ng, 2009). 
Inspired by the study of semi-supervised 
learning, active learning and deep architecture, 
this paper proposes a novel semi-supervised po-
larity classification algorithm called Active 
Deep Networks (ADN) that is based on a repre-
sentative deep learning algorithm Deep Belief 
Networks (DBN) (Hinton, et al, 2006) and ac-
tive learning (Tong and Koller, 2002). First, we 
propose the ADN architecture, which utilizes a 
new deep architecture for classification, and an 
exponential loss function aiming to maximize 
the separability of the classifier. Second, we 
propose the ADN algorithm. It firstly identifies a 
small number of manually labeled reviews by an 
active learner, and then trains the ADN classifier 
with the identified labeled data and all of the 
unlabeled data.  
Our paper makes several important contribu-
tions: First, this paper proposes a novel ADN 
architecture that integrates the abstraction ability 
of deep belief nets and the classification ability 
of backpropagation strategy. It improves the ge-
neralization capability by using abundant unla-
beled data, and directly optimizes the classifica-
tion results in training dataset using back propa-
gation strategy, which makes it possible to 
achieve attractive classification performance 
with few labeled data. Second, this paper pro-
poses an effective active learning method that 
integrates the labeled data selection ability of 
active learning and classification ability of ADN 
architecture. Moreover, the active learning is 
also based on the ADN architecture, so the la-
beled data selector and the classifier are based 
on the same architecture, which provides an uni-
fied framework for semi-supervised classifica-
tion task. Third, this paper applies semi-
supervised learning and active learning to senti-
ment classification successfully and gets com-
petitive performance. Our experimental results 
on five sentiment classification datasets show 
that ADN outperforms previous sentiment clas-
sification methods and deep learning methods. 
The rest of the paper is organized as follows. 
Section 2 gives an overview of sentiment classi-
fication. The proposed semi-supervised learning 
method ADN is described in Section 3. Section 
4 shows the empirical validation of ADN by 
comparing its classification performance with 
previous sentiment classifiers and deep learning 
methods on sentiment datasets. The paper is 
closed with conclusion. 
2 Sentiment Classification 
Sentiment classification can be performed on 
words, sentences or documents, and is generally 
categorized into lexicon-based and corpus-based 
classification method (Wan, 2009). The detailed 
survey about techniques and approaches of 
sentiment classification can be seen in the book 
(Pang and Lee, 2008). In this paper we focus on 
corpus-based classification method. 
Corpus-based methods use a labeled corpus to 
train a sentiment classifier (Wan, 2009). Pang et 
al. (2002) apply machine learning approach to 
corpus-based sentiment classification firstly. 
They found that standard machine learning tech-
niques outperform human-produced baselines. 
Pang and Lee (2004) apply text-categorization 
techniques to the subjective portions of the sen-
timent document. These portions are extracted 
by efficient techniques for finding minimum cuts 
in graphs. Gamon (2004) demonstrate that using 
large feature vectors in combination with feature 
reduction, high accuracy can be achieved in the 
very noisy domain of customer feedback data. 
Xia et al (2008) propose the sentiment vector 
space model to represent song lyric document, 
assign the sentiment labels such as light-hearted 
and heavy-hearted. 
Supervised sentiment classification systems 
are domain-specific and annotating a large scale 
corpus for each domain is very expensive 
(Dasgupta and Ng, 2009). There are several so-
lutions for this corpus annotation bottleneck.   
The first type of solution is using old domain 
labeled examples to new domain sentiment clas-
1516
sification. Blitzer et al (2007) investigate do-
main adaptation for sentiment classifiers, which 
could be used to select a small set of domains to 
annotate and their trained classifiers would 
transfer well to many other domains. Li and 
Zong (2008) study multi-domain sentiment clas-
sification, which aims to improve performance 
through fusing training data from multiple do-
mains. 
The second type of solution is semi-
supervised sentiment classification. Sindhwani 
and Melville (2008) propose a semi-supervised 
sentiment classification algorithm that utilizes 
lexical prior knowledge in conjunction with un-
labeled data. Dasgupta and Ng (2009) firstly 
mine the unambiguous reviews using spectral 
techniques, and then exploit them to classify the 
ambiguous reviews via a novel combination of 
active learning, transductive learning, and en-
semble learning. 
The third type of solution is unsupervised sen-
timent classification. Zagibalov and Carroll 
(2008) describe an automatic seed word selec-
tion for unsupervised sentiment classification of 
product reviews in Chinese. 
However, unsupervised learning of sentiment 
is difficult, partially because of the prevalence of 
sentimentally ambiguous reviews (Dasgupta and 
Ng, 2009). Using multi-domain sentiment cor-
pus to sentiment classification is also hard to 
apply, because each domain has a very limited 
amount of training data, due to annotating a 
large corpus is difficult and time-consuming (Li 
and Zong, 2008). So in this paper we focus on 
semi-supervised approach to sentiment classifi-
cation. 
3 Active Deep Networks 
In this part, we propose a semi-supervised 
learning algorithm, Active Deep Networks 
(ADN), to address the sentiment classification 
problem with active learning. Section 3.1 
formulates the ADN problem. Section 3.2 
proposes the semi-supervised learning of ADN 
without active learning. Section 3.3 proposes the 
active learning method of ADN. Section 3.4 
gives the ADN procedure. 
3.1 Problem Formulation 
There are many review documents in the dataset. 
We preprocess these reviews to be classified, 
which is similar with Dasgupta and Ng (2009).  
Each review is represented as a vector of uni-
grams, using binary weight equal to 1 for terms 
present in a vector. Moreover, the punctuations, 
numbers, and words of length one are removed 
from the vector. Finally, we sort the vocabulary 
by document frequency and remove the top 
1.5%. It is because that many of these high doc-
ument frequency words are stopwords or domain 
specific general-purpose words. 
After preprocess, every review can be 
represented by a vector. Then the dataset can be 
represented as a matrix: 
? ?
1 2
1 1 1
1 2
1 2 2 2 2
1 2
, , ,
, , ,
, , , 1
, , ,
, , ,
R T
R T
R T
R T
D D D
x x x
x x x
x x x
?
?
?
?
? ?
? ?
? ?? ?? ?? ? ? ?
? ?
? ?? ?
X x x x
?
?
?
? ? ? ?
?
 
where R is the number of training samples, T is 
the number of test samples, D is the number of 
feature words in the dataset. Every column of X 
corresponds to a sample x, which is a representa-
tion of a review. A sample that has all features is 
viewed as a vector in D, where the ith coordi-
nate corresponds to the ith feature. 
The L labeled samples are chosen randomly 
from R training samples, or chosen actively by 
active learning, which can be seen as: 
? ? ? ?1 2, [ , ,..., ] 1 2L R L is s s s R? ? ? ?X X S S 
where S is the index of selected training reviews 
to be labeled manually. 
Let Y be a set of labels corresponds to L la-
beled training samples and is denoted as: 
? ?
1 2
1 1 1
1 2
1 2 2 2 2
1 2
, , ,
, , ,
, , , 3
, , ,
, , ,
L
L
L L
L
C C C
y y y
y y y
y y y
? ?
? ?
? ?? ?? ?? ? ? ?
? ?
? ?? ?
Y y y y
?
?
?
? ? ? ?
?
 
where C is the number of classes. Every column 
of Y is a vector in C, where the jth coordinate 
corresponds to the jth class.  
? ?thth1    if  class 4-1  if  class
i
i
j i
jy j
? ??? ? ???
x
x  
For example, if a review x is positive, y=[1, -
1]?; else, y = [-1, 1]?. 
We intend to seek the mapping function 
L L?X Y  using the L labeled data and R+T-L 
unlabeled data. After training, we can determine 
y by the trained ADN while a new sample x is 
fed. 
1517
3.2 Semi-Supervised Learning 
To address the problem formulated in section 3.1, 
we propose a novel deep architecture for ADN 
method, as show in Figure 1. The deep architec-
ture is a fully interconnected directed belief nets 
with one input layer h0, N hidden layers h1, 
h2, ?, hN, and one label layer at the top. The 
input layer h0 has D units, equal to the number of 
features of sample data x. The label layer has C 
units, equal to number of classes of label vector 
y. The numbers of units for hidden layers, cur-
rently, are pre-defined according to the expe-
rience or intuition. The seeking of the mapping 
function L L?X Y , here, is transformed to the 
problem of finding the parameter space W={w1, 
w2,?,wN} for the deep architecture. 
The semi-supervised learning method based 
on ADN architecture can be divided into two 
stages: First, AND architecture is constructed by 
greedy layer-wise unsupervised learning using 
RBMs as building blocks. All the unlabeled data 
together with L labeled data are utilized to find 
the parameter space W with N layers. Second, 
ADN architecture is trained according to the ex-
ponential loss function using gradient descent 
method. The parameter space W is retrained by 
an exponential loss function using L labeled data.  
 
x
1
x
2
x
D
? ? ? ? ?
? ? ? ?
RBM
h
0
h
1
w
1
? ? ?h
2
RBMw
2
?
 
?
 
?
 
? ?h
N
f(h
N
(x), y)
? ?
y
1
y
2
y
C
labels
Minimize 
Loss
Figure 1. Architecture of Active Deep Networks 
 
For unsupervised learning, we define the 
energy of the state (hk-1, hk) as: 
? ?
? ?
1
1
1
1 1
1 1
1 1
, ;
5
k k
k k
D D
k 1 k k k k
st s t
s t
D D
k k k k
s s t t
s t
E w h h
b h c h
?
?
?
? ?
? ?
? ?
? ?
? ?
? ?
??
? ?
h h
where ? ?cbw ,,??  are the model parameters: 
kstw is the symmetric interaction term between 
unit s in the layer hk-1 and unit t in the layer hk, k 
=1,?, N-1. 
1ksb ? is the s
th bias of layer hk-1 and 
ktc  
is the tth bias of layer hk. Dk is the number of unit 
in the kth layer.  
The probability that the model assigns to hk-1 
is: 
? ? ? ? ? ?? ? ? ?1 11; exp , ; 6kk k kP EZ? ??? ?? ??hh h h
 
? ? ? ?? ? ? ?1 1exp , ; 7k k k kZ E? ?? ?? ???h h h h
 
where ? ??Z  denotes the normalizing constant. 
The conditional distributions over hk and hk-1 are: 
? ? ? ? ? ?1 1| | 8k k k kttp p h? ???h h h
 
? ? ? ? ? ?1 1| | 9k k k kssp p h? ???h h h
 
the probability of turning on unit t is a logistic 
function of the states of hk-1 and 
kstw : 
? ? ? ?1 11| sigm 10k k k k kt t st ssp h c w h? ?? ?? ? ?? ?? ??h
 
the probability of turning on unit s is a logistic 
function of the states of hk and 
kstw : 
 
? ? ? ?1 11| sigm 11k k k k ks s st ttp h b w h? ?? ?? ? ?? ?? ??h
 
where the logistic function is: 
? ? ? ?sigm 1 1 12e ?? ?? ? 
The derivative of the log-likelihood with re-
spect to the model parameter wk can be obtained 
by the CD method (Hinton, 2002): 
? ?
0
1 1 1log ( ) 13
M
k k k k ks t s tP Pst
p h h h hw
? ? ?? ? ??
h
 
where 
0P?
denotes an expectation with respect to 
the data distribution and  
MP?
denotes a distribu-
tion of samples from running the Gibbs sampler 
initialized at the data, for M full steps. 
The above discussion is based on the training 
of the parameters between two hidden layers 
with one sample data x. For unsupervised learn-
ing, we construct the deep architecture using all 
labeled data with unlabeled data by inputting 
them one by one from layer h0, train the parame-
ter between h0 and h1. Then h1 is constructed, we 
1518
can use it to construct the up one layer h2. The 
deep architecture is constructed layer by layer 
from bottom to top, and in each time, the para-
meter space wk is trained by the calculated data 
in the k-1th layer. 
According to the wk calculated above, the 
layer hk can be got as below when a sample x is 
fed from layer h0: 
 
? ?
1
1
1
( ) sigm( )    1, ,
1, , 1 14
kD
k k k k
t t st s k
s
h c w h t D
k N
?
?
?
? ? ?
? ?
?x x ?
?
? ? 
The parameter space wN is initialized random-
ly, just as backpropagation algorithm. Then 
ADN architecture is constructed. The top hidden 
layer is formulated as: 
? ?1 1
1
( ) 1, , 15NDN N N Nt t st s Nsh c w h t D
? ?
?
? ? ??x x ?? ?
 
For supervised learning, the ADN architecture 
is trained by L labeled data. The optimization 
problem is formulized as: 
? ?? ? ? ?harg min f h , 16N N L LX Y
 
where 
? ?? ? ? ?? ? ? ?
1 1
f h , T h 17L CN L L N i ij ji j y? ????X Y x
  
and the loss function is defined as 
? ?T( ) exp( ) 18r r? ?  
In the supervised learning stage, the stochastic 
activities are replaced by deterministic, real va-
lued probabilities. We use gradient-descent 
through the whole deep architecture to retrain 
the weights for optimal classification. 
3.3 Active Learning 
Semi-supervised learning allows us to classify 
reviews with few labeled data. However, anno-
tating the reviews manually is expensive, so we 
want to get higher performance with fewer la-
beled data. Active learning can help to choose 
those reviews that should be labeled manually in 
order to achieving higher classification perfor-
mance with the same number of labeled data. 
For such purpose, we incorporate pool-based 
active learning with the ADN method, which 
accesses to a pool of unlabeled instances and 
requests the labels for some number of them 
(Tong and Koller, 2002). 
Given an unlabeled pool XR and a initial la-
beled data set XL (one positive, one negative), 
the ADN architecture hN  will decide which in-
stance in XR to query next. Then the parameters 
of hN are adjusted after new reviews are labeled 
and inserted into the labeled data set. The main 
issue for an active learner is the choosing of next 
unlabeled instance to query. In this paper, we 
choose the reviews whose labels are most uncer-
tain for the classifier. Following previous work 
on active learning for SVMs (Dasgupta and Ng, 
2009; Tong and Koller, 2002), we define the 
uncertainty of a review as its distance from the 
separating hyperplane. In other words, reviews 
that are near the separating hyperplane are cho-
sen as the labeled training data.  
After semi-supervised learning, the parame-
ters of ADN are adjusted. Given an unlabeled 
pool XR, the next unlabeled instance to be que-
ried are chosen according to the location of 
hN(XR). The distance of a point hN(xi) and the 
classes separation line 
1 2N Nh h? is: 
? ? ? ? ? ?1 2 2 19i N i N ih h? ?d x x 
The selected training reviews to be labeled 
manually are given by:  
? ?? ? ? ?: min 20js j? ?d d 
We can select a group of most uncertainty re-
views to label at each time.  
The experimental setting is similar with 
Dasgupta & Ng (2009). We perform active 
learning for five iterations and select twenty of 
the most uncertainty reviews to be queried each 
time. Then the ADN is re-trained on all of la-
beled and unlabeled reviews so far with semi-
supervised learning. At last, we can decide the 
label of reviews x according to the output hN(x) 
of the ADN architecture as below: 
? ? ? ?? ?
? ? ? ?? ? ? ?
1    if max
21
-1  if max
N N
j
j N N
j
h
y
h
? ??? ? ???
x h x
x h x
 
As shown by Tong and Koller (2002), the Ba-
lanceRandom method, which randomly sample 
an equal number of positive and negative in-
stances from the pool, has much better perfor-
mance than the regular random method. So we 
incorporate this ?Balance? idea with ADN me-
thod. However, to choose equal number of posi-
tive and negative instances without labeling the 
entire pool of instances in advance may not be 
practicable. So we present a simple way to ap-
proximate the balance of positive and negative 
reviews. At first, count the number of positive 
and negative labeled data respectively. Second, 
1519
for each iteration, classify the unlabeled reviews 
in the pool and choose the appropriate number of 
positive and negative reviews to let them equally. 
3.4 ADN Procedure 
The procedure of ADN is shown in Figure 2. For 
the training of ADN architecture, the parameters 
are random initialized with normal distribution. 
All the training data and test data are used to 
train the ADN with unsupervised learning. The 
training set XR can be seen as an unlabeled pool. 
We randomly select one positive and one nega-
tive review in the pool to input as the initial la-
beled training set that are used for supervised 
learning. The number of units in hidden layer 
D1?DN and the number of epochs Q are set ma-
nually based on the dimension of the input data 
and the size of training dataset. The iteration 
times I and the number G of active choosing da-
ta for each iteration can be set manually based 
on the number of labeled data in the experiment. 
For each iteration, the ADN architecture is 
trained by all the unlabeled data and labeled data 
in existence with unsupervised learning and su-
pervised learning firstly. Then we choose G re-
views from the unlabeled pool based on the dis-
tance of these data from the separating line. At 
last, label these data manually and add them to 
the labeled data set. For the next iteration, the 
ADN architecture can be trained on the new la-
beled data set. At last, ADN architecture is re-
trained by all the unlabeled data and existing 
labeled data. After training, the ADN architec-
ture is tested based on Equation (21). 
The proposed ADN method can active choose 
the labeled data set and classify the data with the 
same architecture, which avoid the barrier be-
tween choosing and training with different archi-
tecture. More importantly, the parameters of 
ADN are trained iteratively on the label data se-
lection process, which improve the performance 
of ADN. For the ADN training process: in unsu-
pervised learning stage, the reviews can be ab-
stracted; in supervised learning stage, ADN is 
trained to map the samples belong to different 
classes into different regions. We combine the 
unsupervised and supervised learning, and train 
parameter space of ADN iteratively. The proper 
data that should be labeled are chosen in each 
iteration, which improves the classification per-
formance of ADN. 
 
 
Figure 2. Active Deep Networks Procedure. 
4 Experiments 
4.1 Experimental Setup 
We evaluate the performance of the proposed 
ADN method using five sentiment classification 
datasets. The first dataset is MOV (Pang, et al, 
2002), which is a widely-used movie review da-
taset. The other four dataset contain reviews of 
four different types of products, including books 
(BOO), DVDs (DVD), electronics (ELE), and 
kitchen appliances (KIT) (Blitzer, et al, 2007; 
Dasgupta and Ng, 2009). Each dataset includes 
1,000 positive and 1,000 negative reviews. 
Similar with Dasgupta and Ng (2009), we di-
vide the 2,000 reviews into ten equal-sized folds 
randomly and test all the algorithms with cross-
validation. In each folds, 100 reviews are ran-
dom selected as training data and the remaining 
100 data are used for test. Only the reviews in 
the training data set are used for the selection of 
labeled data by active learning.   
The ADN architecture has different number of 
hidden units for each hidden layer. For greedy 
Active Deep Networks Procedure 
 
Input:  data X 
number of units in every hidden layer D1?DN   
number of epochs Q 
number of training data R 
number of test data T 
number of iterations I 
number of active choose data for every iteration G 
Initialize: W = normally distributed random numbers 
                  XL = one positive and one negative reviews 
 
for i = 1 to I 
Step 1. Greedy layer-wise training hidden layers using RBM 
for  n = 1 to N-1 
for  q = 1 to Q 
    for k = 1 to R+T 
      Calculate the non-linear positive and negative phase 
according to (10) and (11). 
        Update the weights and biases by (13). 
    end for 
end for  
end for  
Step 2. Supervised learning the ADN with gradient descent  
Minimize f(hN(X),Y) on labeled data set XL, update the  
parameter space W according to (16). 
Step 3. Choose instances for labeled data set 
Choose G instances which near the separating line by (20) 
Add  G instances into the labeled data set XL 
end 
Train ADN with Step 1 and Step 2. 
 
Output: ADN  hN(x) 
1520
layer-wise unsupervised learning, we train the 
weights of each layer independently with the 
fixed number of epochs equal to 30 and the 
learning rate is set to 0.1. The initial momentum 
is 0.5 and after 5 epochs, the momentum is set to 
0.9. For supervised learning, we run 10 epochs, 
three times of linear searches are performed in 
each epoch.  
We compare the classification performance of 
ADN with five representative classifiers, i.e., 
Semi-supervised spectral learning (Spectral) 
(Kamvar et al, 2003), Transductive SVM 
(TSVM), Active learning (Active) (Tong and 
Koller, 2002), Mine the Easy Classify the Hard 
(MECH) (Dasgupta and Ng, 2009), and Deep 
Belief Networks (DBN) (Hinton, et al, 2006). 
Spectral learning, TSVM, and Active learning 
method are three baseline methods for sentiment 
classification. MECH is a new semi-supervised 
method for sentiment classification (Dasgupta 
and Ng, 2009). DBN (Hinton, et al, 2006) is the 
classical deep learning method proposed recent-
ly.  
4.2 ADN Performance 
For MOV dataset, the ADN structure used in 
this experiment is 100-100-200-2, which 
represents the number of units in output layer is 
2, in 3 hidden layers are 100, 100, and 200 re-
spectively. For the other four data sets, the ADN 
structure is 50-50-200-2. The number of unit in 
input layer is the same as the dimensions of each 
datasets. All theses parameters are set based on 
the dimension of the input data and the scale of 
the dataset. Because that the number of vocabu-
lary in MOV dataset is more than other four da-
tasets, so the number of units in previous two 
hidden layers for MOV dataset are more than 
other four datasets. We perform active learning 
for 5 iterations. In each iteration, we select and 
label 20 of the most uncertain points, and then 
re-train the ADN on all of the unlabeled data  
and labeled data annotated so far. After 5 itera-
tions, 100 labeled data are used for training. 
The classification accuracies on test data in 
cross validation for five datasets and six me-
thods are shown in Table 1. The results of pre-
vious four methods are reported by Dasgupta 
and Ng (2009). For ADN method, the initial two 
labeled data are selected randomly, so we repeat 
thirty times for each fold and the results are av-
eraged. For the randomness involved in the 
choice of labeled data, all the results of other 
five methods are achieved by repeating ten times 
for each fold and then taking average on results.  
Through Table 1, we can see that the perfor-
mance of DBN is competitive with MECH. 
Since MECH is the combination of spectral clus-
tering, TSVM and Active learning, DBN is just a 
classification method based on deep neural net-
work, this result proves the good learning ability 
of deep architecture. ADN is a combination of 
semi-supervised learning and active learning 
based on deep architecture, the performance of 
ADN is better than all other five methods on five 
datasets. This could be contributed by: First, 
ADN uses a new architecture to guide the output 
vector of samples belonged to different regions 
of new Euclidean space, which can abstract the 
useful information that are not accessible to oth-
er learners; Second, ADN use an exponential 
loss function to maximize the separability of 
labeled data in global refinement for better dis-
criminability; Third, ADN fully exploits the em-
bedding information from the large amount of 
unlabeled data to improve the robustness of the 
classifier; Fourth, ADN can choose the useful 
training data actively, which also improve the 
classification performance. 
 
Type MOV KIT ELE BOO DVD 
Spectral 67.3 63.7 57.7 55.8 56.2 
TSVM 68.7 65.5 62.9 58.7 57.3 
Active 68.9 68.1 63.3 58.6 58.0 
MECH 76.2 74.1 70.6 62.1 62.7 
DBN 71.3 72.6 73.6 64.3 66.7 
ADN 76.3 77.5 76.8 69.0 71.6 
 
Table 1. Test Accuracy with 100 Labeled Data 
for Five Datasets and Six Methods. 
4.3 Effect of Active Learning 
To test the performance of our proposed active 
learning method, we conduct following addi-
tional experiments.  
Passive learning: We random select 100 re-
views from the training fold and use them as 
labeled data. Then the proposed semi-supervised 
1521
learning method of ADN is used to train and test 
the performance. Because of randomness, we 
repeat 30 times for each fold and take average 
on results. The test accuracies of passive learn-
ing for five datasets are shown in Table 2. In 
comparison with ADN method in Table 1, we 
can see that the proposed active learning method 
yields significantly better results than randomly 
chosen points, which proves effectiveness of 
proposed active learning method. 
Fully supervised learning: We train a fully 
supervised classifier using all 1,000 training re-
views based on the ADN architecture, results are 
also shown in Table 2. Comparing with the 
ADN method in Table 1, we can see that em-
ploying only 100 active learning points enables 
us to almost reach fully-supervised performance 
for three datasets. 
 
Type MOV KIT ELE BOO DVD 
Passive 72.2 75.0 75.0 66.0 67.9 
Supervised 77.2 79.4 79.1 69.3 72.1 
 
Table 2. Test Accuracy of ADN with different 
experiment setting for Five Datasets. 
4.4 Semi-Supervised Learning with Va-
riance of Labeled Data 
To verify the performance of semi-supervised 
learning with different number of labeled data, 
we conduct another series of experiments on five 
datasets and show the results on Figure 3. We 
run ten-fold cross validation for each dataset. 
Each fold is repeated ten times and the results 
are averaged. 
We can see that ADN can also get a relative 
high accuracy even by using just 20 labeled re-
views for training. For most of the sentiment 
datasets, the test accuracy is increasing slowly 
while the number of labeled review is growing. 
This proves that ADN reaches good performance 
even with few labeled reviews. 
5 Conclusions  
This paper proposes a novel semi-supervised 
learning algorithm ADN to address the senti-
ment classification problem with a small number 
of  labeled  data.   ADN  can  choose  the  proper  
 
 
20 30 40 50 60 70 80 90 100
60
62
64
66
68
70
72
74
76
78
80
Number of labeled review
T
e
s
t
 
a
c
c
u
r
a
c
y
 
(
%
)
 
 
MOV
KIT
ELE
BOO
DVD
 
Figure 3. Test Accuracy of ADN with Different 
Number of Labeled Reviews for Five Datasets. 
 
training data to be labeled manually, and fully 
exploits the embedding information from the 
large amount of unlabeled data to improve the 
robustness of the classifier. We propose a new 
architecture to guide the output vector of sam-
ples belong to different regions of new Eucli-
dean space, and use an exponential loss function 
to maximize the separability of labeled data in 
global refinement for better discriminability. 
Moreover, ADN can make the right decision 
about which training data should be labeled 
based on existing unlabeled and labeled data. By 
using unsupervised and supervised learning ite-
ratively, ADN can choose the proper training 
data to be labeled and train the deep architecture 
at the same time. Finally, the deep architecture is 
re-trained using the chosen labeled data and all 
the unlabeled data. We also conduct experiments 
to verify the effectiveness of ADN method with 
different number of labeled data, and demon-
strate that ADN can reach very competitive clas-
sification performance just by using few labeled 
data. This results show that the proposed ADN 
method, which only need fewer manual labeled 
reviews to reach a relatively higher accuracy, 
can be used to train a high performance senti-
ment classification system. 
Acknowledgement 
This work is supported in part by the National 
Natural Science Foundation of China (No. 
60703015 and No. 60973076). 
1522
References 
Bengio, Yoshua. 2007. Learning deep architectures 
for AI. Montreal: IRO, Universite de Montreal. 
Blitzer, John, Mark Dredze, and Fernando Pereira. 
2007. Biographies, Bollywood, Boom-boxes and 
Blenders: Domain Adaptation for Sentiment 
Classification. In 45th Annual Meeting of the 
Association of Computational Linguistics.  
Dasgupta, Sajib, and Vincent Ng. 2009. Mine the 
Easy, Classify the Hard: A Semi-Supervised 
Approach to Automatic Sentiment Classification. 
In Joint Conference of the 47th Annual Meeting of 
the Association for Computational Linguistics and 
4th International Joint Conference on Natural 
Language Processing of the Asian Federation of 
Natural Language Processing.  
Gamon, Michael. 2004. Sentiment classification on 
customer feedback data: noisy data, large feature 
vectors, and the role of linguistic analysis. In 
International Conference on Computational 
Linguistics.  
Hinton, Geoffrey E. . 2002. Training products of 
experts by minimizing contrastive divergence. 
Neural Computation, 14(8): 1771-1800. 
Hinton, Geoffrey E. , Simon Osindero, and Yee-
Whye Teh. 2006. A Fast Learning Algorithm for 
Deep Belief Nets. Neural Computation, 18: 1527-
1554. 
Kamvar, Sepandar, Dan Klein, and Christopher 
Manning. 2003. Spectral Learning. In 
International Joint Conferences on Artificial 
Intelligence.  
Li, Shoushan, and Chengqing Zong. 2008. Multi-
domain Sentiment Classification. In 46th Annual 
Meeting of the Association of Computational 
Linguistics.  
Li, Tao, Yi Zhang, and Vikas Sindhwani. 2009. A 
Non-negative Matrix Tri-factorization Approach to 
Sentiment Classification with Lexical Prior 
Knowledge. In Joint Conference of the 47th 
Annual Meeting of the Association for 
Computational Linguistics and 4th International 
Joint Conference on Natural Language Processing 
of the Asian Federation of Natural Language 
Processing.  
Pang, Bo, and Lillian Lee. 2004. A Sentimental 
Education: Sentiment Analysis Using Subjectivity 
Summarization Based on Minimum Cuts. In 42th 
Annual Meeting of the Association of 
Computational Linguistics.  
Pang, Bo, and Lillian Lee. 2008. Opinion mining and 
sentiment analysis (Vol. 2). 
Pang, Bo, Lillian Lee, and Shivakumar 
Vaithyanathan. 2002. Thumbs up? Sentiment 
Classification using Machine Learning Techniques. 
In Conference on Empirical Methods in Natural 
Language Processing.  
Raina, Rajat, Alexis Battle, Honglak Lee, Benjamin 
Packer, and Andrew Y. Ng. 2007. Self-taught 
learning: transfer learning from unlabeled data. In 
International conference on Machine learning.  
Ranzato, Marc'Aurelio, and Martin Szummer. 2008. 
Semi-supervised learning of compact document 
representations with deep networks. In 
International Conference on Machine learning.  
Salakhutdinov, Ruslan, and Geoffrey E. Hinton. 2007. 
Learning a Nonlinear Embedding by Preserving 
Class Neighbourhood Structure. In Proceedings of 
Eleventh International Conference on Artificial 
Intelligence and Statistics.  
Sindhwani, Vikas, and Prem Melville. 2008. 
Document-Word Co-regularization for Semi-
supervised Sentiment Analysis. In International 
Conference on Data Mining.  
Tong, Simon, and Daphne Koller. 2002. Support 
vector machine active learning with applications to 
text classification. Journal of Machine Learning 
Research, 2: 45-66. 
Wan, Xiaojun. 2009. Co-Training for Cross-Lingual 
Sentiment Classification. In Joint Conference of 
the 47th Annual Meeting of the Association for 
Computational Linguistics and 4th International 
Joint Conference on Natural Language Processing 
of the Asian Federation of Natural Language 
Processing.  
Xia, Yunqing, Linlin Wang, Kam-Fai Wong, and 
Mingxing Xu. 2008. Lyric-based Song Sentiment 
Classification with Sentiment Vector Space Model. 
In 46th Annual Meeting of the Association of 
Computational Linguistics.  
Zagibalov, Taras, and John Carroll. 2008. Automatic 
Seed Word Selection for Unsupervised Sentiment 
Classification of Chinese Text. In International 
Conference on Computational Linguistics.  
Zhu, Xiaojin. 2007. Semi-supervised learning 
literature survey. University of Wisconsin 
Madison. 
1523
Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,
pages 1341?1349, Dublin, Ireland, August 23-29 2014.
Hybrid Deep Belief Networks for
Semi-supervised Sentiment Classification
Shusen Zhou
?
Qingcai Chen
?
Xiaolong Wang
?
Xiaoling Li
?
?
School of Information and Electrical Engineering, Ludong University, Yantai 264025, China.
?
Shenzhen Graduate School, Harbin Institute of Technology, Shenzhen 518055, China.
zhoushusen@gmail.com, qingcai.chen@hitsz.edu.cn
wangxl@insun.hit.edu.cn, appleling@live.cn
Abstract
In this paper, we develop a novel semi-supervised learning algorithm called hybrid deep be-
lief networks (HDBN), to address the semi-supervised sentiment classification problem with
deep learning. First, we construct the previous several hidden layers using restricted Boltzmann
machines (RBM), which can reduce the dimension and abstract the information of the reviews
quickly. Second, we construct the following hidden layers using convolutional restricted Boltz-
mann machines (CRBM), which can abstract the information of reviews effectively. Third, the
constructed deep architecture is fine-tuned by gradient-descent based supervised learning with an
exponential loss function. We did several experiments on five sentiment classification datasets,
and show that HDBN is competitive with previous semi-supervised learning algorithm. Ex-
periments are also conducted to verify the effectiveness of our proposed method with different
number of unlabeled reviews.
1 Introduction
Recently, more and more people write reviews and share opinions on the World Wide Web, which present
a wealth of information on products and services (Liu et al., 2010). These reviews will not only help other
users make better judgements but they are also useful resources for manufacturers of products to keep
track and manage customer opinions (Wei and Gulla, 2010). However, there are large amount of reviews
for every topic, it is difficult for a user to manually learn the opinions of an interesting topic. Sentiment
classification, which aims to classify a text according to the expressed sentimental polarities of opinions
such as ?positive? or ?negtive?, ?thumb up? or ?thumb down?, ?favorable? or ?unfavorable? (Li et al., 2010),
can facilitate the investigation of corresponding products or services.
In order to learn a good text classifier, a large number of labeled reviews are often needed for training
(Zhen and Yeung, 2010). However, labeling reviews is often difficult, expensive or time consuming
(Chapelle et al., 2006). On the other hand, it is much easier to obtain a large number of unlabeled reviews,
such as the growing availability and popularity of online review sites and personal blogs (Pang and Lee,
2008). In recent years, a new approach called semi-supervised learning, which uses large amount of
unlabeled data together with labeled data to build better learners (Zhu, 2007), has been developed in the
machine learning community.
There are several works have been done in semi-supervised learning for sentiment classification, and
get competitive performance (Li et al., 2010; Dasgupta and Ng, 2009; Zhou et al., 2010). However, most
of the existing semi-supervised learning methods are still far from satisfactory. As shown by several re-
searchers (Salakhutdinov and Hinton, 2007; Hinton et al., 2006), deep architecture, which composed of
multiple levels of non-linear operations, is expected to perform well in semi-supervised learning because
of its capability of modeling hard artificial intelligent tasks. Deep belief networks (DBN) is a represen-
tative deep learning algorithm achieving notable success for text classification, which is a directed belief
nets with many hidden layers constructed by restricted Boltzmann machines (RBM), and refined by a
gradient-descent based supervised learning (Hinton et al., 2006). Ranzato and Szummer (Ranzato and
This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer
are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/
1341
Szummer, 2008) propose an algorithm to learn text document representations based on semi-supervised
auto-encoders that are combined to form a deep network. Zhou et al. (Zhou et al., 2010) propose a nov-
el semi-supervised learning algorithm to address the semi-supervised sentiment classification problem
with active learning. The key issue of traditional DBN is the efficiency of RBM training. Convolutional
neural networks (CNN), which are specifically designed to deal with the variability of two dimensional
shapes, have had great success in machine learning tasks and represent one of the early successes of
deep learning (LeCun et al., 1998). Desjardins and Bengio (Desjardins and Bengio, 2008) adapt RBM
to operate in a convolutional manner, and show that the convolutional RBM (CRBM) are more efficient
than standard RBM.
CRBM has been applied successfully to a wide range of visual and audio recognition tasks (Lee et al.,
2009a; Lee et al., 2009b). Though the success of CRBM in addressing two dimensional issues, there
is still no published research on the using of CRBM in textual information processing. In this paper,
we propose a novel semi-supervised learning algorithm called hybrid deep belief networks (HDBN), to
address the semi-supervised sentiment classification problem with deep learning. HDBN is a hybrid of
RBM and CRBM deep architecture, the bottom layers are constructed by RBM, and the upper layers are
constructed by CRBM, then the whole constructed deep architecture is fine tuned by a gradient-descent
based supervised learning based on an exponential loss function.
The remainder of this paper is organized as follows. In Section 2, we introduce our semi-supervised
learning method HDBN in details. Extensive empirical studies conducted on five real-world sentiment
datasets are presented in Section 3. Section 4 concludes our paper.
2 Hybrid deep belief networks
2.1 Problem formulation
The sentiment classification dataset composed of many review documents, each review document com-
posed of a bag of words. To classify these review documents using corpus-based approaches, we need to
preprocess them in advance. The preprocess method for these reviews is similar with (Zhou et al., 2010).
We tokenize and downcase each review and represent it as a vector of unigrams, using binary weight
equal to 1 for terms present in a vector. Moreover, the punctuations, numbers, and words of length one
are removed from the vector. Finally, we combine all the words in the dataset, sort the vocabulary by
document frequency and remove the top 1.5%, because many of these high document frequency words
are stopwords or domain specific general-purpose words.
After preprocess, each review can be represented as a vector of binary weight x
i
. If the j
th
word of
the vocabulary is in the i
th
review, x
i
j
= 1; otherwise, x
i
j
= 0. Then the dataset can be represented as a
matrix:
X =
[
x
1
,x
2
, . . . ,x
R+T
]
=
?
?
?
?
?
x
1
1
, x
2
1
, . . . , x
R+T
1
x
1
2
, x
2
2
, . . . , x
R+T
2
.
.
. ,
.
.
. , . . . ,
.
.
.
x
1
D
, x
2
D
, . . . , x
R+T
D
?
?
?
?
?
(1)
where R is the number of training reviews, T is the number of test reviews, D is the number of feature
words in the dataset. Every column of X corresponds to a sample x, which is a representation of a
review. A sample that has all features is viewed as a vector in R
D
, where the i
th
coordinate corresponds
to the i
th
feature.
The L labeled reviews are chosen randomly from R training reviews, or chosen actively by active
learning, which can be seen as:
X
L
= X
R
(S) , S = [s
1
, ..., s
L
], 1 ? s
i
? R (2)
where S is the index of selected training reviews to be labeled manually.
1342
x1 x2 xD
? ? ? ? ?
? ? ? ?
RBM
h0
h1
w1
? ? ?hM
?
 
?
 
?
 
? ?
wM+1
hM+1
CRBM
? ?hN
?
 
?
 
?
 
f(hN(x), y)
y1
Minimize 
Loss
? ?labels
yCy2
?
?
Figure 1: Architecture of HDBN.
The L labels correspond to L labeled training reviews is denoted as:
Y
L
=
[
y
1
,y
2
, . . . ,y
L
]
=
?
?
?
?
?
y
1
1
, y
2
1
, . . . , y
L
1
y
1
2
, y
2
2
, . . . , y
L
2
.
.
. ,
.
.
. , . . . ,
.
.
.
y
1
C
, y
2
C
, . . . , y
L
C
?
?
?
?
?
(3)
where C is the number of classes. Every column of Y is a vector in R
C
, where the j
th
coordinate
corresponds to the j
th
class.
y
i
j
=
{
1 if x
i
? j
th
class
?1 if x
i
/? j
th
class
(4)
For example, if a review x
i
is positive, y
i
= [1,?1]
?
; otherwise, y
i
= [?1, 1]
?
.
We intend to seek the mapping function X? Y using the L labeled data and all unlabeled data. After
training, we can determine y using the mapping function when a new sample x comes.
2.2 Architecture of HDBN
In this part, we propose a novel semi-supervised learning method HDBN to address the problem for-
mulated in Section 2.1. The sentiment datasets have high dimension (about 10,000), and computation
complexity of convolutional calculation is relatively high, so we use RBM to reduce the dimension of
review with normal calculation firstly. Fig. 1 shows the deep architecture of HDBN, a fully intercon-
nected directed belief nets with one input layer h
0
, N hidden layers h
1
,h
2
, ...,h
N
, and one label layer at
the top. The input layer h
0
has D units, equal to the number of features of sample review x. The hidden
1343
wk
hk-1
hk ??
Group 1
1 0 ?
Group Gk
0 1
??
Group 1
0 1 ?
Group Gk-1
1 0
? ?
1Gk
wkGk-11
?
Figure 2: Architecture of CRBM.
layer hasM layers constructed by RBM andN?M layers constructed by CRBM. The label layer has C
units, equal to the number of classes of label vector y. The numbers of hidden layers and the number of
units for hidden layers, currently, are pre-defined according to the experience or intuition. The seeking
of the mapping function X ? Y, here, is transformed to the problem of finding the parameter space
W = {w
1
,w
2
, . . . ,w
N
} for the deep architecture.
The training of the HDBN can be divided into two stages:
1. HDBN is constructed by greedy layer-wise unsupervised learning using RBMs and CRBMs as
building blocks. L labeled data and all unlabeled data are utilized to find the parameter space W
with N layers.
2. HDBN is trained according to the exponential loss function using gradient descent based supervised
learning. The parameter space W is refined using L labeled data.
2.3 Unsupervised learning
As show in Fig. 1, we construct HDBN layer by layer using RBMs and CRBMs, the details of RBM can
be seen in (Hinton et al., 2006), and CRBM is introduced below.
The architecture of CRBM can be seen in Fig. 2, which is similar to RBM, a two-layer recurrent
neural network in which stochastic binary input groups are connected to stochastic binary output groups
using symmetrically weighted connections. The top layer represents a vector of stochastic binary hidden
feature h
k
and the bottom layer represents a vector of binary visible data h
k?1
, k = M + 1, ..., N . The
k
th
layer consists of G
k
groups, where each group consists of D
k
units, resulting in G
k
? D
k
hidden
units. The layer h
M
is consist of 1 group andD
M
units. w
k
is the symmetric interaction term connecting
corresponding groups between data h
k?1
and feature h
k
. However, comparing with RBM, the weights
of CRBM between the hidden and visible groups are shared among all locations (Lee et al., 2009a), and
the calculation is operated in a convolutional manner (Desjardins and Bengio, 2008).
We define the energy of the state (h
k?1
,h
k
) as:
E
(
h
k?1
,h
k
; ?
)
= ?
G
k?1
?
s=1
G
k
?
t=1
(w?
k
st
? h
k?1
s
) ? h
k
t
?
G
k?1
?
s=1
b
k?1
s
D
k?1
?
u=1
h
k?1
s
?
G
k
?
t=1
c
k
t
D
k
?
v=1
h
k
t
(5)
where ? = (w,b, c) are the model parameters: w
k
st
is a filter between unit s in the layer h
k?1
and unit t
in the layer h
k
, k = M + 1, ..., N . The dimension of the filter w
k
st
is equal to D
k?1
?D
k
+ 1. b
k?1
s
is
the s
th
bias of layer h
k?1
and c
k
t
is the t
th
bias of layer h
k
. A tilde above an array (w?) denote flipping
the array, ? denote valid convolution, and ? denote element-wise product followed by summation, i.e.,
A ?B = trA
T
B (Lee et al., 2009a).
Similar to RBM, Gibbs sampler can be performed based on the following conditional distribution.
1344
The probability of turning on unit v in group t is a logistic function of the states of h
k?1
and w
k
st
:
p
(
h
k
t,v
= 1|h
k?1
)
= sigm
(
c
k
t
+ (
?
s
w?
k
st
? h
k?1
s
)
v
)
(6)
The probability of turning on unit u in group s is a logistic function of the states of h
k
and w
k
st
:
p
(
h
k?1
s,u
= 1|h
k
)
= sigm
(
b
k?1
s
+ (
?
t
w
k
st
? h
k
t
)
u
)
(7)
A star ? denote full convolution.
2.4 Supervised learning
In HDBN, we construct the deep architecture using all labeled reviews with unlabeled reviews by in-
putting them one by one from layer h
0
. The deep architecture is constructed layer by layer from bottom
to top, and each time, the parameter space w
k
is trained by the calculated data in the k ? 1
th
layer.
Algorithm 1: Algorithm of HDBN
Input: data X, Y
L
number of training data R; number of test data T ;
number of layers N ; number of epochs Q;
number of units in every hidden layer D
1
...D
N
;
number of groups in every convolutional hidden layer G
M
...G
N
;
hidden layer h
1
, . . . ,h
M
;
convolutional hidden layer h
M+1
, . . . ,h
N?1
;
parameter space W = {w
1
, . . . ,w
N
};
biases b, c; momentum ? and learning rate ?;
Output: deep architecture with parameter space W
1. Greedy layer-wise unsupervised learning
for k = 1; k ? N ? 1 do
for q = 1; q ? Q do
for r = 1; r ? R+ T do
Calculate the non-linear positive and negative phase:
if k ?M then
Normal calculation.
else
Convolutional calculation according to Eq. 6 and Eq. 7.
end
Update the weights and biases:
w
k
st
= ?w
k
st
+ ?
(
?
h
k?1
s,r
h
k
t,r
?
P
0
?
?
h
k?1
s,r
h
k
t,r
?
P
1
)
end
end
end
2. Supervised learning based on gradient descent
arg min
W
L
?
i=1
C
?
j=1
exp(?h
N
(x
i
j
)y
i
j
)
According to the w
k
calculated by RBM and CRBM, the layer h
k
, k = 1, . . . ,M can be computed as
following when a sample x inputs from layer h
0
:
h
k
t
(x) = sigm
(
c
k
t
+
D
k?1
?
s=1
w
k
st
h
k?1
s
(x)
)
, t = 1, . . . , D
k
(8)
1345
When k = M + 1, . . . , N ? 1, the layer h
k
can be represented as:
h
k
t
(x) = sigm
?
?
c
k
t
+
G
k?1
?
s=1
w?
k
st
? h
k?1
s
(x)
?
?
, t = 1, . . . , G
k
(9)
The parameter space w
N
is initialized randomly, just as backpropagation algorithm.
h
N
t
(x) = c
N
t
+
G
N?1
?D
N?1
?
s=1
w
N
st
h
N?1
s
(x), t = 1, . . . , D
N
(10)
After greedy layer-wise unsupervised learning, h
N
(x) is the representation of x. Then we useL labeled
reviews to refine the parameter space W for better discriminative ability. This task can be formulated as
an optimization problem:
arg min
W
f
(
h
N
(
X
L
)
,Y
L
)
(11)
where
f
(
h
N
(
X
L
)
,Y
L
)
=
L
?
i=1
C
?
j=1
T
(
h
N
j
(
x
i
)
y
i
j
)
(12)
and the loss function is defined as
T (r) = exp(?r) (13)
We use gradient-descent through the whole HDBN to refine the weight space. In the supervised
learning stage, the stochastic activities are replaced by deterministic, real valued probabilities.
2.5 Classification using HDBN
The training procedure of HDBN is given in Algorithm 1. For the training of HDBN architecture, the
parameters are random initialized with normal distribution. All the reviews in the dataset are used to
train the HDBN with unsupervised learning. After training, we can determine the label of the new data
through:
arg
j
maxh
N
(x) (14)
3 Experiments
3.1 Experimental setup
We evaluate the performance of the proposed HDBN method using five sentiment classification datasets.
The first dataset is MOV (Pang et al., 2002), which is a classical movie review dataset. The other four
datasets contain products reviews come from the multi-domain sentiment classification corpus, including
books (BOO), DVDs (DVD), electronics (ELE), and kitchen appliances (KIT) (Blitzer et al., 2007). Each
dataset contains 1,000 positive and 1,000 negative reviews.
The experimental setup is same as (Zhou et al., 2010). We divide the 2,000 reviews into ten equal-
sized folds randomly, maintaining balanced class distributions in each fold. Half of the reviews in each
fold are random selected as training data and the remaining reviews are used for test. Only the reviews
in the training data set are used for the selection of labeled reviews by active learning. All the algorithms
are tested with cross-validation.
We compare the classification performance of HDBN with four representative semi-supervised learn-
ing methods, i.e., semi-supervised spectral learning (Spectral) (Kamvar et al., 2003), transductive SVM
(TSVM) (Collobert et al., 2006), deep belief networks (DBN) (Hinton et al., 2006), and person-
al/impersonal views (PIV) (Li et al., 2010). Spectral learning, TSVM methods are two baseline methods
for sentiment classification. DBN (Hinton et al., 2006) is the classical deep learning method proposed
recently. PIV (Li et al., 2010) is a new sentiment classification method proposed recently.
1346
Table 1: HDBN structure used in experiment.
Dataset Structure
MOV 100-100-4-2
KIT 50-50-3-2
ELE 50-50-3-2
BOO 50-50-5-2
DVD 50-50-5-2
Table 2: Test accuracy with 100 labeled reviews for semi-supervised learning.
Type MOV KIT ELE BOO DVD
Spectral 67.3 63.7 57.7 55.8 56.2
TSVM 68.7 65.5 62.9 58.7 57.3
DBN 71.3 72.6 73.6 64.3 66.7
PIV - 78.6 70.0 60.1 49.5
HDBN 72.2 74.8 73.8 66.0 70.3
3.2 Performance of HDBN
The HDBN architecture used in all our experiments have 2 normal hidden layer and 1 convolutional
hidden layer, every hidden layer has different number of units for different sentiment datasets. The deep
structure used in our experiments for different datasets can be seen in Table 1. For example, the HDBN
structure used in MOV dataset experiment is 100-100-4-2, which represents the number of units in 2
normal hidden layers are 100, 100 respectively, and in output layer is 2, the number of groups in 1
convolutional hidden layer is 4. The number of unit in input layer is the same as the dimensions of each
datasets. For greedy layer-wise unsupervised learning, we train the weights of each layer independently
with the fixed number of epochs equal to 30 and the learning rate is set to 0.1. The initial momentum
is 0.5 and after 5 epochs, the momentum is set to 0.9. For supervised learning, we run 30 epochs, three
times of linear searches are performed in each epoch.
The test accuracies in cross validation for five datasets and five methods with semi-supervised learning
are shown in Table 2. The results of previous two methods are reported by (Dasgupta and Ng, 2009).
The results of DBN method are reported by (Zhou et al., 2010). Li et al. (Li et al., 2010) reported the
results of PIV method. The result of PIV on MOV dataset is empty, because (Li et al., 2010) did not
report it. HDBN is the proposed method.
Through Table 2, we can see that HDBN gets most of the best results except on KIT dataset, which is
just slight worse than PIV method. However, the preprocess of PIV method is much more complicated
than HDBN, and the PIV results on other datasets are much worse than HDBN method. HDBN method
is adjusted by DBN, all the experiment results on five datasets for HDBN are better than DBN. This
could be contributed by the convolutional computation in HDBN structure, and proves the effectiveness
of our proposed method.
3.3 Performance with variance of unlabeled data
To verify the contribution of unlabeled reviews for our proposed method, we did several experiments
with fewer unlabeled reviews and 100 labeled reviews.
The test accuracies of HDBN with different number of unlabeled reviews and 100 labeled reviews
on five datasets are shown in Fig. 3. The architectures for HDBN used in this experiment are same
as Section 3.2 too, which can be seen in Table 1. We can see that the performance of HDBN is much
worse when just using 400 unlabeled reviews. However, when using more than 1200 unlabeled reviews,
the performance of HDBN is improved obviously. For most of review datasets, the accuracy of HDBN
with 1200 unlabeled reviews is close to the accuracy with 1600 and 2000 unlabeled reviews. This proves
that HDBN can get competitive performance with just few labeled reviews and appropriate number of
1347
400 600 800 1000 1200 1400 1600 1800 200060
62
64
66
68
70
72
74
76
78
80
Number of unlabeled review
Te
st a
ccu
rac
y (%
)
 
 
MOV
KIT
ELE
BOO
DVD
Figure 3: Test accuracy of HDBN with different number of unlabeled reviews on five datasets.
unlabeled reviews. Considering the much time needed for training with more unlabeled reviews and less
accuracy improved for HDBN method, we suggest using appropriate number of unlabeled reviews in real
application.
4 Conclusions
In this paper, we propose a novel semi-supervised learning method, HDBN, to address the sentiment clas-
sification problem with a small number of labeled reviews. HDBN seamlessly incorporate convolutional
computation into the DBN architecture, and use CRBM to abstract the review information effectively.
To the best of our knowledge, HDBN is the first work that uses convolutional neural network to improve
sentiment classification performance. One promising property of HDBN is that it can effectively use the
distribution of large amount of unlabeled data, together with few label information in a unified frame-
work. In particular, HDBN can greatly reduce the dimension of reviews through RBM and abstract the
information of reviews through the cooperate of RBM and CRBM. Experiments conducted on five senti-
ment datasets demonstrate that HDBN outperforms state-of-the-art semi-supervised learning algorithms,
such as SVM and DBN based methods, using just few labeled reviews, which demonstrate the effective
of deep architecture for sentiment classification.
Acknowledgements
This work is supported in part by National Natural Science Foundation of China (No. 61300155, No.
61100115 and No. 61173075), Natural Science Foundation of Shandong Province (No. ZR2012FM008),
Science and Technology Development Plan of Shandong Province (No. 2013GNC11012), Science and
Technology Research and Development Funds of Shenzhen City (No. JC201005260118A and No.
JC201005260175A), and Scientific Research Fund of Ludong University (LY2013004).
References
John Blitzer, Mark Dredze, and Fernando Pereira. 2007. Biographies, bollywood, boom-boxes and blenders:
Domain adaptation for sentiment classification. In Annual Meeting of the Association of Computational Lin-
guistics, pages 440?447, Prague, Czech Republic. Association for Computational Linguistics.
Olivier Chapelle, Bernhard Scholkopf, and Alexander Zien. 2006. Semi-supervised learning. MIT Press, USA.
Ronan Collobert, Fabian Sinz, Jason Weston, and Leon Bottou. 2006. Large scale transductive svms. Journal of
Machine Learning Research, 7:1687?1712.
Sajib Dasgupta and Vincent Ng. 2009. Mine the easy, classify the hard: A semi-supervised approach to automatic
sentiment classfication. In Joint Conference of the 47th Annual Meeting of the Association for Computational
1348
Linguistics and 4th International Joint Conference on Natural Language Processing of the Asian Federation of
Natural Language Processing, pages 701?709, Stroudsburg, PA, USA. Association for Computational Linguis-
tics.
Guillaume Desjardins and Yoshua Bengio. 2008. Empirical evaluation of convolutional rbms for vision. Technical
report.
Geoffrey E. Hinton, Simon Osindero, and Yee-Whye Teh. 2006. A fast learning algorithm for deep belief nets.
Neural Computation, 18:1527?1554.
Sepandar Kamvar, Dan Klein, and Christopher Manning. 2003. Spectral learning. In International Joint Confer-
ences on Artificial Intelligence, pages 561?566, Catalonia, Spain. AAAI Press.
Yann LeCun, Leon Bottou, Yoshua Bengio, and Patrick Haffner. 1998. Gradient-based learning applied to docu-
ment recognition. Proceedings of the IEEE, 86(11):2278?2324.
Honglak Lee, Roger Grosse, Rajesh Ranganath, and Andrew Y. Ng. 2009a. Convolutional deep belief networks
for scalable unsupervised learning of hierarchical representations. In International Conference on Machine
Learning, pages 609?616, Montreal, Canada. ACM.
Honglak Lee, Yan Largman, Peter Pham, and Andrew Y. Ng. 2009b. Unsupervised feature learning for audio
classification using convolutional deep belief networks. In Advances in Neural Information Processing Systems,
pages 1096?1103, Vancouver, B.C., Canada. NIPS Foundation.
Shoushan Li, Chu-Ren Huang, Guodong Zhou, and Sophia Yat Mei Lee. 2010. Employing personal/impersonal
views in supervised and semi-supervised sentiment classification. In Annual Meeting of the Association for
Computational Linguistics, pages 414?423, Uppsala, Sweden. Association for Computational Linguistics.
Yang Liu, Xiaohui Yu, Xiangji Huang, and Aijun An. 2010. S-plasa+: Adaptive sentiment analysis with applica-
tion to sales performance prediction. In International ACM SIGIR Conference on Research and Development
in Information Retrieval, pages 873?874, New York, NY, USA. ACM.
Bo Pang and Lillian Lee. 2008. Opinion Mining and Sentiment Analysis, volume 2 of Foundations and Trends in
Information Retrieval.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up? sentiment classification using machine
learning techniques. In Conference on Empirical Methods in Natural Language Processing, pages 79?86,
Stroudsburg, PA, USA. Association for Computational Linguistics.
Marc?Aurelio Ranzato and Martin Szummer. 2008. Semi-supervised learning of compact document representa-
tions with deep networks. In International Conference on Machine Learning, pages 792?799, Helsinki, Finland.
ACM.
Ruslan Salakhutdinov and Geoffrey E. Hinton. 2007. Learning a nonlinear embedding by preserving class neigh-
bourhood structure. Journal of Machine Learning Research, 2:412?419.
Wei Wei and Jon Atle Gulla. 2010. Sentiment learning on product reviews via sentiment ontology tree. In Annual
Meeting of the Association for Computational Linguistics, pages 404?413, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Yi Zhen and Dit-Yan Yeung. 2010. Sed: Supervised experimental design and its application to text classification.
In International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 299?
306, Geneva, Switzerland. ACM.
Shusen Zhou, Qingcai Chen, and Xiaolong Wang. 2010. Active deep networks for semi-supervised sentiment
classification. In International Conference on Computational Linguistics, pages 1515?1523, Beijing, China.
Coling 2010 Organizing Committee.
Xiaojin Zhu. 2007. Semi-supervised learning literature survey. Ph.D. thesis.
1349
Proceedings of the Joint Conference on EMNLP and CoNLL: Shared Task, pages 76?82,
Jeju Island, Korea, July 13, 2012. c?2012 Association for Computational Linguistics
A Mixed Deterministic Model for Coreference Resolution 
         
Bo Yuan1, Qingcai Chen, Yang Xiang, Xiaolong Wang2 
Liping Ge, Zengjian Liu, Meng Liao, Xianbo Si 
Intelligent Computing Research Center, Key Laboratory of Network Oriented Intelligent 
Computation, Computer Science and technology Department, Harbin Institute of Technology 
Shenzhen graduate School, Shenzhen, Guangdong, 518055, China 
{yuanbo.hitsz1, windseedxy, qingcai.chen, geliping123, 
autobotsonearth, dream2009gd, sixianbo}@gmail.com 
wangxl@insun.hit.edu.cn2 
 
 
 
Abstract 
This paper presents a mixed deterministic 
model for coreference resolution in the 
CoNLL-2012 shared task. We separate the 
two main stages of our model, mention 
detection and coreference resolution, into 
several sub-tasks which are solved by 
machine learning method and  
deterministic rules based on multi-filters, 
such as lexical, syntactic, semantic, gender 
and number information. We participate in 
the closed track for English and Chinese, 
and also submit an open result for Chinese 
using tools to generate the required features. 
Finally, we reach the average F1 scores 
58.68, 60.69 and 61.02 on the English 
closed task, Chinese closed and open tasks.  
1 Introduction 
The coreference resolution task is a complicated 
and challenging issue of natural language 
processing. Although many sub-problems, such as 
noun phrase to noun phrase and pronouns to noun 
phrase, are contained in this issue, it is interesting 
that humans do not get too confused when they 
determine whether two mentions refer to the same 
entity. We also believe that automatic systems 
should copy the human behavior (Kai-Wei et al, 
2011). In our understanding, the basis for human 
making judgment on different sub-problems is 
different and limited. Although there are some 
complicated and ambiguous cases in this task, and 
we are not able to cover all the prior knowledge of 
human mind, which plays a vital role in his 
solution, the mixed deterministic model we 
constructed can solve a big part of this task. We 
present a mixed deterministic model for 
coreference resolution in the CoNLL-2012 shared 
task (Sameer et al, 2011). 
Different methods such as Relaxation labeling 
(Emili et al, 2011), Best-Link (Kai-Wei et al, 
2011), Entropy Guided Transformation Learning 
(Cicero et al, 2011) and deterministic models 
(Heeyoung et al, 2011), were attempted in the 
CoNLL-2011 shared task (Sameer et al, 2011). 
The system performance reported by the task 
shows that a big part of this task has been solved 
but some sub-problems need more exploration. 
We also participate in the Chinese closed and 
open tracks. However, the lack of linguistic 
annotations makes it more difficult to build a 
deterministic model. Basic solutions such as Hobbs 
Algorithm and Center Theory have been listed in 
(Wang et al, 2002; Jun et al, 2007). The recent 
research on Chinese contains non-anaphors 
detection using a composite kernel (Kong Fang, et 
al., 2012(a)) and a tree kernel method to anaphora 
resolution of pronouns (Kong Fang et al, 2012(b)). 
We accept the thought of Stanford (Karthik et al, 
2010; Heeyoung et al, 2011). In Stanford system 
the coreference resolution task is divided into 
several problems and each problem is solved by 
rule based methods. For English we did some 
research on mention detection which uses Decision 
Tree to decide whether the mention ?it? should 
refer to some other mention. For Chinese we 
submit closed and open result. The lack of gender, 
76
number and name entities make it more difficult 
for the Chinese closed task and we try to extract 
information from the training data to help enhance 
the performance. For the open task, we use some 
dictionaries such as appellation dictionary, gender 
dictionary, geographical name dictionary and 
temporal word dictionary (Bo et al, 2009), and 
some tools such as conversion of pinyin-to-
character and LTP which is a Chinese parser that 
can generate the features such as Part-of-Speech, 
Parse bit, Named Entities (Liu et al, 2011) to 
generate the similar information. 
We describe the system architecture in section 2. 
Section 3 illustrates the mention detection process. 
Section 4 describes the core process of coreference 
resolution. In section 5, we show the results and 
discussion of several experiments. Finally, we give 
the conclusion of our work in section 6.  
2 System Architecture 
Our system mainly contains mention detection and 
coreference resolution. Recall is the determining 
factor in mention detection stage. The reason is 
that if some mention is missed in this stage, the 
coreference resolution part will miss the chains 
which contain this mention. Yet some mentions 
still need to be distinguished because in some cases 
they refer to no entity. For example ?it?, in the 
sentence ?it + be + weather/ time?, ?it? should refer 
to no entity. But the ?it? in the phrase ?give it to 
me? might refer to some entity. The coreference 
resolution module of our system follows the idea 
of Stanford. In the English task we did some more 
exploration on mention detection, pronoun 
coreference and partial match of noun phrases. The 
Chinese task is more complicated and because 
gender, number and name entities are not provided, 
the feature generation from the training data has to 
be added before the coreference resolution process. 
Some Chinese idiomatic usages are also considered 
in this stage.  
3 Mention detection  
All the NPs, pronouns and the phrases which are 
indexed as named entities are selected as 
candidates. NPs are extracted from the parse tree. 
Yet some mentions do not refer to any entity in 
some cases. In our system we attempt to 
distinguish these mentions in this stage. The reason 
is that the deterministic rules in coreference 
resolution part are not complete to distinguish 
these mentions. The methods below can also be 
added to the coreference resolution part as a pre-
processing. For the conveniences of system design, 
we finish this work in this stage. 
For English, the pronoun ?it? and NPs ?this, that, 
those and these? need to be distinguished. We take 
?it? as an example to illustrate the process. First we 
use regular expressions to select ?it?, which refers 
to no entity, such as ?it + be + weather/ time?, ?it 
happened that? and ?it makes (made) sense that?.  
Second we use Decision Tree (C4.5) to classify the 
two kinds of ?it? based on the training data. The 
features contain the Part-of-Speech, Parse bit, 
Predicate Arguments of ?it?, the word before and 
after ?it?. The number of total ?it? is 9697 and 4043 
of them have an entity to refer to in the training 
data. 
 
Category Precision Recall F 
no entity refered 
entity refered 
0.576 
0.747 
0.596 
0.731 
0.586
0.739
total 0.682 0.679 0.68
 
Table 1: Results of ?it? classification using C4.5 
 
Table 1 shows the classification result of ?it? in 
the development data v4. The number of total ?it? 
is 1401 and 809 of them have an entity to refer to. 
The result is not perfect but can help enhance the 
performance of coreference resolution. However, 
the results of ?this, that, those and these? are not 
acceptable and we skip over these words. We did 
not do any process on ?verb? mention detection and 
coreference resolution. 
In addition, we divide mentions into groups in 
which they are nested in position. And for 
mentions which have the same head word in one 
group, only the mentions with the longest span 
should be left (for the English task and a set of 
Chinese articles). For some Chinese articles of 
which names contain ?chtb?, both in the training 
data and the development data, the nest is 
permitted based on the statistic results.  
For Chinese we also attempt to train a model for 
pronouns ???(you) and ???(that). However, the 
results are not acceptable either since the features 
we select are not enough for the classifier. 
After the mentions have been extracted, the 
related features of each mention are also extracted. 
We transform the ?conll? document into mention 
77
document. Each mention has basic features such as 
position, part-of-speech, parse tree, head word, 
speaker, Arguments, and the gender and number of 
head word. The head word feature is very 
important and regular expression can almost 
accomplish the process but not perfectly. Firstly, 
we extract the key NPs of a mention based on 
parse feature. Then the regular expressions are to 
extract the head word. For example, the mention: 
 (NP (DNP (LCP (NP (NP (NR ??)) (NP (NN ??))) 
(LC ?)) (DEG ?)) (NP (NR ??)) (NP (NN ??))) (NP 
(DNP (LCP (NP (NP (NR ??)) (NP (NN ??))) (LC ?)) 
(DEG ?)) (NP (NR ??)) (NP (NN ??)))  
The key NPs of this mention is: 
(NP (NR ??)) (NP (NN ??)) .The head word of 
this mention is: NN ?? 
However, there are still some cases that need to 
be discussed. For example, the head word of ?the 
leader of people? should be ?leader?, while the head 
word of ?the city of Beijing? should be ?city? and 
?Beijing? for the mentions of ?the city? and 
?Beijing? both have the same meaning with ?the 
city of Beijing?. Finally, we only found the words 
of ?city? and ?country? should be processed. 
4 Coreference resolution  
The deterministic rules are the core methods to 
solve the coreference resolution task. All the 
mentions in the same part can be seen as a list. The 
mentions which refer to the same entity will be 
clustered based on the deterministic rules. After all 
the clusters have generated, the merge program 
will merge the clusters into chains based on the 
position information. The mentions in one chain 
cannot be reduplicative in position. Basically the 
nested mentions are not allowed. 
The process contains two parts NP-NP and NP-
pronoun. Each part has several sub-problems to be 
discussed. First, the same process of English task 
and Chinese task will be illustrated. Then the 
different parts will be discussed separately. 
4.1 NP-NP 
Exact match: the condition of exact match is the 
two NP mentions which have no other larger 
parent mentions in position are coreferential if they 
are exactly the same. The stop words such as ?a?, 
?the?, ?this? and ?that? have been removed.  
Partial match: there are two conditions for 
partial match which are the two mentions have the 
same head word and one of them is a part of the 
other in form simultaneously.  
Alias and abbreviation: some mentions have 
alias or abbreviation. For example the mentions 
?USA? and ?America? should refer to the mention 
?the United States?. 
Similar match:  there are three forms of this 
match. The first one is all the modifiers of two NPs 
are same and the head words are similar based on 
WordNet1 which is provided for the English closed 
task. We only use the English synonym sets of the 
WordNet to solve the first form. The second one is 
the head words are same and the modifiers are not 
conflicted. The third form is that the head words 
and modifiers are all different. The result of similar 
match may be reduplicative with that of exact 
match and partial match. This would be eliminated 
by the merge process. 
4.2 Pronoun - NP 
There are seven categories of pronoun to NP in our 
system. For English second person, it is difficult to 
distinguish the plural form from singular form and 
we put them in one deterministic rule. For each 
kind of pronouns shown below, the first cluster is 
the English form and the second cluster is the 
Chinese form.  
First Person (singular) = {'I', 'my', 'me', 'mine', 
'myself'}{???} 
Second Person= {'you', 'your', 'yours', 'yourself', 
'yourselves'}{???? ????} 
Third Person (male) = {'he', 'him', 'his', 
'himself'}{???} 
Third Person (female) = {'she', 'her', 'hers', 
'herself'}{???} 
Third Person (object) = {'it', 'its', 'itself'}{???} 
First Person (plural) = {'we', 'us', 'our', 'ours', 
'ourselves'}{????} 
Third Person (plural) = {'they', 'them', 'their', 
'theirs', 'themselves'}{????? ?????????} 
In the Chinese task the possessive form of 
pronoun is not considered. For example, the 
mention ???  ? ?(our) is a DNP in the parse 
feature and it contains two words ???? and ???. 
We only selected the NP ????as a mention. The 
reflexive pronouns are composed by two words 
which are the pronoun itself and the word ????. 
                                                          
1 http://wordnet.princeton.edu/ 
78
For example, the mention ??  ???(myself) is 
processed as ???(I or me).  
Gender, number and distance between pronoun 
and NP are the most important features for this part 
(Shane et al, 2006). We only allow pronoun to 
find NPs at first. We find out the first mention of 
which all the features are satisfied ahead of the 
pronoun. If there is no matching mention, search 
backward from the pronoun. For the first person 
and second person, we merged all the pronouns 
with the same form and the same speaker. If the 
context is a conversation of two speakers, the 
second person of a speaker should refer to the first 
person of the other speaker. The scene of multi-
speakers conversation is too difficult to be solved. 
In the Chinese task there are some other 
pronouns. The pronoun ????(both sides) should 
refer to a plural mention which contain ???(and) 
in the middle. The pronoun ?? ? has similar 
meaning of third person and refers to the largest 
NP mention before it. The pronouns ?? ?(this), 
?? ?(that), ??? ?(here), ??? ?(there) are not 
processed for we did not find a good solution.  
However in some cases the provided gender and 
number are not correct or missing and we had to 
label these mentions based on the appellation 
words of the training data. For example, if the 
appellation word of a person is ?Mr.? or ?sir?, the 
gender should be male.  
4.3 Chinese closed task  
For the Chinese closed task NE, the gender and 
number are not provided. We used regular patterns 
to generate these features from the training data. 
In the NE (named entities) feature ?PERSON? is 
a very important category because most pronouns 
will refer to the person entity. To extract 
?PERSON?, we build a PERSON dictionary which 
contains all the PERSON mentions in training data, 
such as ????(Mr.) and ????(Professor).  If the 
same mention appears in the test data, we believe it 
is a person entity. However, the PERSON 
dictionary cannot cover all the PERSON mentions. 
The appellation words are extracted before or after 
the person entity. When some appellation word 
appears in the test data, the NP mention before or 
after the appellation word should be a person entity, 
if they compose a larger NP mention.  
The Gender feature was generated at the same 
time of the ?PERSON? generation. We separate the 
?PERSON? dictionary and appellation dictionary 
into male cluster and female cluster by the 
pronouns in the same chain.  
The generation of number feature is a little 
complicated. Since the Chinese word does not have 
plural form, the numerals and the quantifiers of the 
mention are the main basis to extract the number 
feature. We extract the numerals and the 
quantifiers from the training data and built regular 
expressions for determine the number feature of a 
mention in test data. Other determinative rules for 
number feature extraction are shown below: 
If the word ??? appears in a mention tail, this 
mention is plural. For example ????(student) is 
singular and ?????(students) is plural. 
If the word ???(and) appears in the middle of a 
mention A, and the two parts separated by ??? are 
sub-mentions of A,  mention A should be plural. 
Other words which have the similar meaning of 
???, such as ???, ??? and ???, are considered.  
The time and date coreference resolution is also 
considered. The NP mentions which contain 
temporal words are processed separately since 
these categories of name entity are not provided. 
These temporal words are also extracted from 
training data. Since the head words of these 
mentions are themselves, the two time or date 
mentions are coreferential if they are the same or 
one must be a part of the other?s tail. For example 
??????(this September) and ????(September) 
which are not nested should be coreferential. 
4.4 Chinese open task 
For the Chinese open task we use several tools to 
generate features we need. 
NE generation: LTP is a Chinese parser that can 
generate the features such as Part-of-Speech, Parse 
bit, Named Entities (Liu et al, 2011). We only use 
LTP for the NE generation. However, the NE 
labels of LTP are different with that provided by 
the gold training data and need to be transformed. 
The difference of word segmentation between LTP 
and the provided data also made some errors. At 
last we find the NE feature from LTP does not 
perform well and it will be discussed in section 5. 
The conversion of pinyin-to-character is also 
used in the Chinese open task. The speaker 
provided in the training data is given in pinyin 
form. The speaker might be the ?PERSON? 
mention in the context. When we determine the 
79
pronoun coreference, we need to know whether the 
speaker and the ?PERSON? mention are same.  
Other tools used in open task contain appellation 
dictionary, gender dictionary, geographical name 
dictionary and temporal word dictionary (Bo et al, 
2009). These dictionaries are more complete than 
those used in the closed task, although the 
enhancements are also limited. 
5 Results and Discussion  
Table 2 to table 4 show the results of English 
coreference resolution on the gold and auto 
development and the test data. The results of the 
auto development data and the test data are close 
and lower than that of the gold data. Since the 
deterministic rules can not cover all the cases, 
there is still an improvement if we could make the 
deterministic rules more complete. 
 
Measure R  P F1 
Mention detection 
MUC 
B3 
77.7 
65.1 
69.2 
71.8 
62.9 
70.9 
74.6
64 
70.1
CEAF(E) 
(CEAF(E)+MUC+B3)/3 
46.4 48.9 47.6
60.6
 
Table 2: Results of the English gold development 
data  
 
Measure R  P F1 
Mention detection 
MUC 
B3 
72.4 
62.3 
66.7 
71.5 
62.8 
71.8 
72 
62 
69.1
CEAF(E) 
(CEAF(E)+MUC+B3)/3 
46.4 44.9 45.6
58.9
 
Table 3: Results of the English auto development 
data  
 
Measure R P F1 
Mention detection 
MUC 
B3 
73.2 
62.1 
66.2 
71.9
63 
70.5
72.53
63 
68.3
CEAF(E) 
CEAF(M) 
 BLANC 
(CEAF(E)+MUC+B3)/3 
45.7 
57.3 
72.1 
44.7
57.3
76.9
45.2
57.3
74.2
58.68
 
Table 4: Results of English test data  
 
The results of the closed Chinese performance 
on the gold and auto development and the test data 
are shown in table 5 to table 7. The performance of 
the auto development data and the test data has 
about 4% decline to that of the gold development 
on F1 of coreference resolution. It means the 
Chinese results are also partly affected by the parse 
feature. In fact we attempted to revise the parse 
feature of the auto development data using regular 
expressions. Yet the complicacy and unacceptable 
results made us abandon that.  
 
Measure R  P F1 
Mention detection 
MUC 
B3 
 82.3 
71.6 
76.7 
69.8
64.3
74.2
75.5 
67.7 
75.4 
CEAF(E)
(CEAF(E)+MUC+B3)/3
49 56.5 52.5 
65.2 
 
Table 5: Closed results of the Chinese gold 
development data  
 
Measure R P  F1 
Mention detection 
MUC 
B3 
74.2 
63.6 
73.1 
66 
60 
73.5
70 
61.7 
73.3 
CEAF(E)
(CEAF(E)+MUC+B3)/3
47.3 50.6 48.9 
61.3 
 
Table 6: Closed results of the Chinese auto 
development data 
 
Measure R P F1 
Mention detection 
MUC 
B3 
72.8 
62.4 
73.1 
64.1 
58.4 
72.7 
68.15
60.3
72.9
CEAF(E) 
CEAF(M) 
BLANC 
(CEAF(E)+MUC+B3)/3
47.1 
59.6 
73.7 
50.7 
59.6 
78.2 
48.8
59.6
75.8
60.69
 
Table 7: Closed results of the Chinese test data  
 
The results of the open Chinese performance on 
the gold and auto development and the test data are 
shown in table 8 to table 10. The performance is 
similar with that of the closed task. However, the 
improvement between F1 of the open task and F1 
of the closed task is limited. We also get the F1 of 
the closed and open test results using gold parser 
which are 66.46 and 66.38. The open result is even 
80
lower. This can be explained. The performance 
enhanced by the dictionaries we used for the open 
task are limited because the open dictionaries 
information which appears in the test data is not 
much more than that of the closed dictionaries 
which generated from the training data, although 
the total information of the former is much larger.  
The named entities generated by LTP have some 
errors such as person identification errors and will 
caused coreferential errors in Pronoun-NP stage. 
For the time we did not use LTP well and some 
other open tools such as Wikipedia and Baidu 
Baike should be applied in the open task.  
  
Measure R P F1 
Mention detection 
MUC 
B3 
82.4 
72.3 
77.7 
69.3
63.8
73.3
75.3 
67.8 
75.4 
CEAF(E) 
(CEAF(E)+MUC+B3)/3 
48.3 56.8 52.2 
65.1 
 
Table 8: Open results of the Chinese gold 
development data  
 
Measure R  P F1 
Mention detection 
MUC 
B3 
75.1 
64.9 
74.2 
65.7
59.9
72.6
70.1 
62.3 
73.4 
CEAF(E) 
(CEAF(E)+MUC+B3)/3 
46.7 51.5 49 
61.6 
 
Table 9: Open results of the Chinese auto 
development data 
 
Measure R P F1 
Mention detection 
MUC 
B3 
73.7 
63.7 
74 
64 
58.5
72.2
68.49
61 
73.1 
CEAF(E) 
CEAF(M) 
BLANC 
(CEAF(E)+MUC+B3)/3 
60.1 
46.8 
74.3 
60.1
51.5
78 
60.1 
49 
76 
61.02
 
Table 10: Open results of the Chinese test data  
 
The results of the gold-mention-boundaries and 
gold-mentions data of the English and Chinese 
closed task are shown in table 11 and 12. Although 
the mention detection stage is optimized by the 
gold-mention-boundaries and gold-mentions data 
and the final performance is enhanced, there is still 
space to enhance in the coreference resolution 
stage. The recall of mention detection of gold-
mentions is 99.8. This problem will be explored in 
our future work.  
 
Data R P F1 
Mention detection(A) 
gold-mention-boundaries
Mention detection(B) 
gold-mentions 
75.7 
 
80 
70.8
 
100
73.2 
59.50
88.91
69.88
 
Table 11: Results of the English closed gold-
mention-boundaries and gold-mentions data, (A) is 
the mention detection score of the gold-mention-
boundaries and (B) is the score of the gold-
mentions. 
 
Data R P F1 
Mention detection(A) 
gold-mention-boundaries
Mention detection(B) 
gold-mentions 
82.9 
 
81.7 
66.9
 
99.8
74.02
64.42
89.85
76.05
 
Table 12: Results of the Chinese closed gold-
mention-boundaries and gold-mentions data  
6 Conclusion 
In this paper we described a mixed deterministic 
model for coreference resolution of English and 
Chinese. We start the mention detection from 
extracting candidates based on the parse feature. 
The pre-processing which contains static rules and 
decision tree is applied to remove the defective 
candidates. In the coreference resolution stage the 
task is divided into several sub-problems and for 
each sub-problem the deterministic rules are 
constructed based on limited features. For the 
Chinese closed task we use regular patterns to 
generate named entities, gender and number from 
the training data. Several tools and dictionaries are 
applied for the Chinese open task. The result is not 
as good as we supposed since the feature errors 
caused by these tools also made the coreferential 
errors.  
However, a deeper error analysis is needed in 
the construction of deterministic rules. The feature 
of the predicate arguments is not used well. 
Although the open performance of the Chinese 
task is not good, we still believe that complete and 
accurate prior knowledge can help solve the task.  
81
Acknowledgement 
This work is supported in part by the National 
Natural Science Foundation of China (No. 
61173075 and 60973076), ZTE Foundation and 
Science and Technology Program of Shenzhen.  
References  
Bo Yuan, Qingcai Chen, Xiaolong Wang, Liwei Han. 
2009. Extracting Event Temporal Information based 
on Web. 2009 Second International Symposium on 
Knowledge Acquisition and Modeling, pages.346-
350  
Cicero Nogueira dos Santos, Davi Lopes Carvalho. 
2011. Rule and Tree Ensembles for Unrestricted 
Coreference Resolution. Proceedings of the 15th 
Conference on Computational Natural Language 
Learning: Shared Task, pages 51?55.  
Emili Sapena, Llu??s Padr?o and Jordi Turmo. 2011. 
RelaxCor Participation in CoNLL Shared Task on 
Coreference Resolution. Proceedings of the 15th 
Conference on Computational Natural Language 
Learning: Shared Task, pages 35?39. 
Heeyoung Lee, Yves Peirsman, Angel Chang, 
Nathanael Chambers, Mihai Surdeanu, Dan Jurafsky. 
2011. Stanford?s Multi-Pass Sieve Coreference 
Resolution System at the CoNLL-2011 Shared Task. 
Proceedings of the 15th Conference on 
Computational Natural Language Learning: Shared 
Task, pages 28?34, Portland, Oregon. 
Liu Ting, Che Wanxiang, Li Zhenghua. 2011. Language 
Technology Platform. Journal of Chinese 
Information Processing. 25(6): 53-62 
Jun Lang, Bing Qin, Ting Liu, Sheng Li. 2007. Intra-
document Coreference Resolution: The state of the 
art. Journal of Chinese Language and Computing. 17 
(4):227-253 
Kai-Wei Chang Rajhans Samdani. 2011. Inference 
Protocols for Coreference Resolution. Proceedings of 
the 15th Conference on Computational Natural 
Language Learning: Shared Task, pages 40?44, 
Portland, Oregon. 
Karthik Raghunathan, Heeyoung Lee, Sudarshan 
Rangarajan, Nathanael Chambers, Mihai Surdeanu, 
Dan Jurafsky, Christopher Manning. 2010. A Multi-
Pass Sieve for Coreference Resolution. In EMNLP. 
Kong Fang, Zhu Qiaoming and Zhou Guodong. 2012(a). 
Anaphoricity determination for coreference 
resolution in English and Chinese languages. 
Computer Research and Development (Chinese).  
Kong Fang and Zhou Guodong. 2012(b). Tree kernel-
based pronoun resolution in English and Chinese 
languages. Journal of Software (Chinese). Accepted: 
23(8).  
Sameer Pradhan, Lance Ramshaw, Mitchell Marcus, 
Martha Palmer, Ralph Weischedel and Nianwen 
Xue.2011. CoNLL-2011 Shared Task: Modeling 
Unrestricted Coreference in OntoNotes. Proceedings 
of the Fifteenth Conference on Computational 
Natural Language Learning (CoNLL 2011). Portland, 
OR. 
Sameer Pradhan and Alessandro Moschitti and Nianwen 
Xue and Olga Uryupina and Yuchen Zhang. 2012. 
CoNLL-2012 Shared Task: Modeling Multilingual 
Unrestricted Coreference in OntoNotes. Proceedings 
of the Sixteenth Conference on Computational 
Natural Language Learning (CoNLL 2012). Jeju, 
Korea. 
Shane Bergsma and Dekang Lin. 2006. Bootstrapping 
Path-Based Pronoun Resolution Proceedings of the 
21st International Conference on Computational 
Linguistics and 44th Annual Meeting of the ACL, 
pages 33?40, Sydney 
Wang Houfeng. 2002. Survey: Computational Models 
and Technologies in Anaphora Resolution. Journal of 
Chinese Information Processing. 16(6): 9-17. 
82
