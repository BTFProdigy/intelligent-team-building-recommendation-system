Modeling sentence processing in ACT-R
Shravan Vasishth
Department of Computational Linguistics
Saarland University, PO Box 15 11 05
66041 Saarbru?cken, Germany
vasishth@acm.org
Richard L. Lewis
Department of Psychology
University of Michigan
Ann Arbor, MI, USA
rickl@umich.edu
Abstract
We present a series of simulations of behavioral data
by casting a simple parsing model in the cognitive
architecture ACT-R. We show that constraints de-
fined in ACT-R, specifically those relating to acti-
vation, can account for a range of facts about hu-
man sentence processing. In doing so, we argue
that resource limitation in working memory is bet-
ter defined as an artefact of very general and in-
dependently motivated principles of cognitive pro-
cessing.
1 Introduction
Although language processing may be a specialized
cognitive faculty, it is possible that it is nevertheless
shaped by general constraints on the human cog-
nitive architecture. This point has been addressed
extensively in the connectionist literature, but we
present a somewhat different approach to this prob-
lem by casting parsing within the cognitive architec-
ture ACT-R (Anderson et al, 2002) and directly us-
ing the constraints provided in ACT-R to account for
several interesting cross-linguistic facts: the well-
known sentential complement/relative clause asym-
metry (Gibson, 2000; Grodner and Gibson, 2003)
and the subject/object relative clause asymmetry in
English (Homes and O?Regan, 1981); and some re-
cent results (Vasishth, 2003) involving Hindi center
embeddings, including a principled account of indi-
vidual variation in subject behavior.
In developing this approach, we argue that re-
source limitation in working memory is better de-
fined as an artefact of very general constraints on
information processing ? specifically, rehearsal and
activation ? rather than as an inherent numerical
bound on memory capacity (cf. (Gibson, 2000;
Hawkins, 1994); also see Section 3.5).
In the rest of this paper, we first introduce the
ACT-R architecture. Then we present the results
of several simulations of experiments available in
the psycholinguistic literature. The paper concludes
with a discussion of the potential advantages and
shortcomings of this approach, and of the broader
consequences of modeling parsing within a cogni-
tive architecture.
2 A brief introduction to the cognitive
architecture ACT-R
ACT-R is a theory of the human cognitive archi-
tecture. It allows the development of computa-
tional models that can closely simulate experimental
methodologies such as eye-tracking and self-paced
reading, and has been used to model a wide array of
behavioral data from learning and memory, problem
solving and decision making, language and commu-
nication, perception and attention, cognitive devel-
opment, and individual differences (Anderson et al,
2002).
The ACT-R architecture is attractive as a model-
ing tool for three reasons. First, it is based on a wide
array of empirical results in various domains of cog-
nitive psychology. Second, it is flexible enough to
permit the modeler to add their own assumptions
and theories about the specific task to be modeled.
Finally, ACT-R models yield dependent measures
such as reading time in much the same way as hu-
mans performing the experiment; e.g., the system
can easily be programmed to simulate key presses
after it processes material presented on the screen.
As shown in Figure 1, the architecture consists of
several MODULES such as Declarative, Visual, and
Manual. Each module is associated with a BUFFER
which temporarily stores information for a given ac-
tion. For example, the visual buffer is used to store
an item ?seen? by the system in the environment be-
fore it is used in the service of some task.
The module that is especially important for the
present paper is the Declarative (henceforth, DM).
DM represents permanent memory: every fact that
is assumed to be known is encoded as a CHUNK in
declarative memory. A chunk is an attribute-value
list structure with a special attribute, ISA, which de-
fines its type. The attributes are also referred to as
slots. The value of a chunk?s slot is also (by defi-
nition) a chunk, unless it is double-quoted or is the
Intentional Module Declarative module
Environment
Visual module Manual module
Visual buffer Manual buffer
Matching
Selection
Execution
Retrieval bufferGoal buffer
Pr
od
uc
tio
ns
Figure 1: This is a schematic view of the ACT-R
system. ?Environment? is the outside world that
ACT-R is programmed to interact with. The arrows
show the possible flows of information. Productions
and the central box with the boxes labeled ?Match-
ing?, ?Selection?, and ?Execution? are intended to
represent a set of central executive mechanisms and
processes.
lisp primitive ?nil?.
Each DM chunk has an activation that determines
its speed of retrieval, and the probability that it will
be retrieved; the initial activation for a given chunk
can be set manually.
There is a GOAL BUFFER that holds a current goal
under consideration (there can be only one goal at
one time); this goal is a chunk with a given type and
possibly instantiated slots.
The control structure for modeling a sequence of
events is a set of PRODUCTIONS; a production is
simply an if-then statement of the following general
form: for a given state of one or more buffers and/or
DM, execute some actions. Examples of executing
actions are retrieving something from DM; chang-
ing a value in one of the goal?s slots; repositioning
the hand over a keyboard; a visual shift of attention;
changing the goal to a new one, etc. If the goal is
changed, then this new goal now occupies the goal
buffer.
Building an ACT-R model is essentially a defi-
nition of possible sequences of actions for a given
state of affairs. Events like retrievals from DM are
triggered by looking at the contents of one or more
buffers. For example, the ACT-R system ?sees? an
item/object on the screen and then encodes it as a vi-
sual chunk. This chunk can then be harvested from
the visual buffer; it includes (as slot-value specifi-
cations) information about the content of the item
seen, its x-y coordinates, etc. One can define an ac-
tion based on this information, such as retrieving a
chunk from DM.
3 Modeling sentence parsing in ACT-R
Previous research suggests that humans employ
some variant of left-corner parsing (see, e.g.,
(Resnik, 1992)), which in essence involves a
bottom-up and a top-down (predictive) step. We
adopt this parsing strategy in the simulations. In
order to model the prediction of syntactic struc-
ture based on incrementally appearing input, we as-
sume that sentence structure templates are available
in declarative memory as underspecified chunks.
These chunks are retrieved every time a new word is
integrated into the structure, as are prior arguments
necessary for semantic integration.
We illustrate the parsing process with a simple
example (Figure 2). Suppose that the sentence to be
parsed is The girl ran, and suppose that we are sim-
ulating self-paced reading (Just et al, 1982). When
the word the is seen, a bottom-up and top-down
structure building step results in a sentence with an
intransitive verb being predicted. This structure be-
comes the current goal. Then the word girl is seen
and processed, i.e., its lexical entry is retrieved from
declarative memory. The noun slot in the goal is
then instantiated with that lexical entry. In the next
step, if the word ran is seen the relevant lexical item
for the verb is retrieved and instantiated with the
verb slot of the goal; here, the verb?s argument is
also retrieved and integrated with the subcategoriza-
tion frame of the verb. If, instead of ran the word
that appears, a new goal is created, with any pre-
viously instantiated slots of the preceding goal be-
ing passed on to the new goal, and parsing proceeds
from there.
Each retrieval of a goal from memory results in
a surge in its activation, so that repeated retrievals
result in increased activation; and the higher the ac-
tivation of an item the faster it is processed. At the
same time, activation decays according to the power
law of forgetting (Anderson et al, 2002). In the
same way that the goals undergo decay and reacti-
vation, so do the previously seen words. This means
that the speed of retrieval of a previously seen argu-
ment at a verb will be determined by the activation
level of that argument. Thus, the activation of both
the goals (predicted structures) and the arguments
affect processing.
In our simulations, for simplicity we code in the
exact steps that ACT-R takes for particular sen-
tences. Although it is feasible to build a very gen-
Det N V1
the
S
ran
Det N
girl
S
that
t V2
V1
the
NP NP
NP
NP
Det N V1
girlthe
S
Det N V1
girlthe
S
S?
S
Figure 2: A simple illustration of parsing steps in
the ACT-R simulations presented.
eral parser in pure ACT-R, before doing this we
wanted to first establish whether ACT-R?s reacti-
vation mechanisms can account for a reasonable
array of facts from the sentence processing litera-
ture. In (Lewis and Vasishth, An activation-based
model of sentence processing as skilled memory re-
trieval, (tentative title; in preparation)) we provide
a detailed description of a model employing mech-
anisms similar to those described here, but one that
behaves more like a standard parser.
3.1 English subject versus object relative
clauses
It is well known (Homes and O?Regan, 1981) that
English subject relatives are easier to process that
object relatives (1). In the parsing model outlined
above, we can model this result without changing
any ACT-R parameters at all (i.e., we use the default
settings for the parameters).
(1) a. The reporter who sent the photographer
to the editor hoped for a good story.
b. The reporter who the photographer sent
to the editor hoped for a good story.
The explanation comes from the decay of the ar-
guments of the verb sent: in object relatives the
argument reporter decays much more than in the
subject relative by the time it is integrated with the
verb?s subcategorization frame (Figure 3). This is
because more time elapses between the argument
being first seen and its retrieval at the verb.1
1A reviewer points out that several head-final languages
such as German and Dutch also have a subject relative pref-
erence and in these languages the activation level cannot be the
explanation. We do not claim that decay is the only constraint
operating in parsing; frequency effects (greater preference for
30
0
40
0
50
0
60
0
70
0
80
0
90
0
10
00
Position
M
ea
n 
R
ea
di
ng
 T
im
e 
(m
se
c)
1 2 3 4 5 6 7 8 9 10 11 12 13
Object Relative
Subject Relative
The reporter
who
sent
The reporter
who
the
photographer
sent
Figure 3: The reading times provided by the model.
Retrieval of reporter at sent is harder in the object
relative because of increased argument decay.
3.2 The SC/RC asymmetry in English
It is also well-known (Gibson, 2000) that a senten-
tial complement (SC) followed by a relative clause
(RC) is easier to process than an RC followed by an
SC:
(2) a. The fact that the employee who the
manager hired stole office supplies wor-
ried the executive.
b. #The executive who the fact that the
employee stole office supplies worried
hired the manager.
As in the previous discussion about relative
clauses, in the harder case the decay of the argument
executive at the verb worried is greater compared
to the decay of the argument employee at hired in
the easier-to-process sentence. In addition, the to-
tal reading time for the harder sentence is about 120
msec longer.2
3.3 Hindi center embeddings
Previous work (Hakes, 1972), (Konieczny, 2000)
has shown that if argument-verb distance is in-
creased, processing is easier at the verb. (Vasishth,
more frequently occurring subject relatives) etc. could certainly
dominate where the amount of decay is constant in subject and
object relatives. It is an open empirical question whether fre-
quency alone can account for the subject/object asymmetry in
English, but given that we have independent empirical justi-
fication for decay (see Section 3.5), the above is a plausible
explanation.
2As a reviewer points out, ?the account in terms of acti-
vation decay suggests that the SC/RC asymmetry can be an-
nihilated or even reversed by inserting longer or shorter NPs
between the critical verbs (worried, hired) and their arguments
(executive, employee). This seems unrealistic.? This is surely
an empirical question that needs to be verified experimentally;
we intend to pursue this very interesting issue in future work.
400
500
600
700
800
900
the fac
t
tha
t
the
em
plo
ye
e
w
ho the
m
an
ag
er
hir
ed
sto
le
off
ice
 su
pp
lie
s
w
or
rie
d
the
ex
ec
uti
ve
SC/RC (easy); total RT = 7482 msec
the
ex
ec
uti
ve
w
ho the fac
t
tha
t
the
em
plo
ye
e
sto
le
off
ice
sup
pli
es
w
or
rie
d
hir
ed the
m
an
ag
er
RC/SC (hard); total RT = 7605 msec
R
ea
di
ng
 T
im
e 
(m
se
c)
RC/SC
SC/RC
Figure 4: Model?s behavior in the complement-
clause/relative-clause contrast.
2003) presented similar results in Hindi. The Hindi
experiment manipulated distance by comparing the
baseline condition (3a) with the case where an ad-
verb intervened (3b), a verb-modifying PP inter-
vened (3c), and relative clause intervened that mod-
ified the preceding NP (3d).
(3) a. Siitaa-ne
Sita-erg
Hari-ko
Hari-dat
Ravi-ko
Ravi-dat
[kitaab-ko
book-acc
khariid-neko]
buy-inf
bol-neko
tell-inf
kahaa
told
?Sita told Hari to tell Ravi to buy the
book.?
b. Siitaa-ne
Sita-erg
Hari-ko
Hari-dat
Ravi-ko
Ravi-dat
[kitaab-ko
book-acc
jitnii-jaldii-ho-sake
as-soon-as-possible
khariid-neko]
buy-inf
bol-neko
tell-inf
kahaa
told
?Sita told Hari to tell Ravi to buy the
book as soon as possible.?
c. Siitaa-ne
Sita-erg
Hari-ko
Hari-dat
Ravi-ko
Ravi-dat
[kitaab-ko
book-acc
ek bar
.
hiya dukaan se
from-a-good-shop
khariid-neko]
buy-inf
bol-neko
tell-inf
kahaa
told
?Sita told Hari to tell Ravi to buy the
book from a good shop.?
d. Siitaa-ne
Sita-erg
Hari-ko
Hari-dat
Ravi-ko
Ravi-dat
[kitaab-ko
book-acc
jo-mez-par-thii
that-was-on-a-table
khariid-neko]
buy-inf
bol-neko
tell-inf
kahaa
told
?Sita told Hari to tell Ravi to buy the
book that was lying on a/the table.?
In all the ?insertion? cases a statistically signifi-
cant speedup was observed at the verb, compared to
the baseline condition.
This experiment?s results were replicated in the
ACT-R system; the replication is based on the as-
sumption that the goal (predicted syntactic struc-
ture) is reactivated each time it (i.e., the entire pre-
dicted structure) is modified. The intervening items
result in an extra retrieval compared to the base-
line, resulting in faster processing at the verb. In
this model, one parameter was changed: the rate of
decay of items. We justify this change in the next
sub-section.
The modeling results are shown in Figure 5.
? Adv PP RC
Data
R
ea
di
ng
 ti
m
es
 (m
se
c)
0
20
0
40
0
60
0
80
0
10
00
? Adv PP RC
Model
R
ea
di
ng
 ti
m
es
 (m
se
c)
0
20
0
40
0
60
0
80
0
10
00
Figure 5: Reading times from data versus model, at
the first verb.
3.4 Individual variation in Hindi center
embedding data
In the Hindi experiment, there was a further varia-
tion in the data when individual subjects? data were
considered: only about 48% of subjects showed a
speedup at the verb. About 21% showed a slow-
down and there was only a few milliseconds differ-
ence (essentially no difference) in the reading times
for about 31% of the subjects. The observed varia-
tion was a systematic trend in the sense that the 47%
of the subjects who showed a speedup or slowdown
in adverb-insertion case also showed the same trend
in the PP- and RC-inserted cases ? the probability of
this happening is considerably below chance level.
The rate of decay defined in ACT-R?s rehearsal
equation can systematically explain this variation.
Consider the situation where a chunk   with an ini-
tial activation of  is retrieved. The activation is
0
20
0
40
0
60
0
80
0
10
00
12
00
14
00
d=0.01
R
ea
di
ng
 T
im
e 
at
 fi
rs
t v
er
b 
(m
se
c)
Data Model
No Adverb
Adverb
Figure 6: Modeling speedup.
0
20
0
40
0
60
0
80
0
10
00
12
00
14
00
d=0.5
R
ea
di
ng
 T
im
e 
at
 fi
rs
t v
er
b 
(m
se
c)
Data Model
No Adverb
Adverb
Figure 7: Modeling slowdown.
0
20
0
40
0
60
0
80
0
10
00
12
00
14
00
d=0.16
R
ea
di
ng
 T
im
e 
at
 fi
rs
t v
er
b 
(m
se
c)
Data Model
No Adverb
Adverb
Figure 8: Modeling no difference in reading time.
recalculated each time a retrieval occurs, according
to the following equation.
(4)    	




Here,  is the number of times the chunk   was
successfully retrieved,


 is the time elapsed since
the  -th retrieval, and  is a decay rate that defaults
to Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 5?8,
Columbus, Ohio, USA, June 2008. c?2008 Association for Computational Linguistics
Surprising parser actions and reading difficulty
Marisa Ferrara Boston, John Hale
Michigan State University
USA
{mferrara,jthale}@msu.edu
Reinhold Kliegl, Shravan Vasishth
Potsdam University
Germany
{kliegl,vasishth}@uni-potsdam.de
Abstract
An incremental dependency parser?s proba-
bility model is entered as a predictor in a
linear mixed-effects model of German read-
ers? eye-fixation durations. This dependency-
based predictor improves a baseline that takes
into account word length, n-gram probabil-
ity, and Cloze predictability that are typically
applied in models of human reading. This
improvement obtains even when the depen-
dency parser explores a tiny fraction of its
search space, as suggested by narrow-beam
accounts of human sentence processing such
as Garden Path theory.
1 Introduction
A growing body of work in cognitive science char-
acterizes human readers as some kind of probabilis-
tic parser (Jurafsky, 1996; Crocker and Brants, 2000;
Chater and Manning, 2006). This view gains sup-
port when specific aspects of these programs match
up well with measurable properties of humans en-
gaged in sentence comprehension.
One way to connect theory to data in this man-
ner uses a parser?s probability model to work out
the surprisal or log-probability of the next word.
Hale (2001) suggests this quantity as an index
of psycholinguistic difficulty. When the transi-
tion from previous word to current word is low-
probability, from the parser?s perspective, the sur-
prisal is high and the psycholinguistic claim is that
behavioral measures should register increased cog-
nitive difficulty. In other words, rare parser ac-
tions are cognitively costly. This basic notion has
proved remarkably applicable across sentence types
and languages (Park and Brew, 2006; Demberg and
Keller, 2007; Levy, 2008).
The present work uses the time spent looking at
a word during reading as an empirical measure of
sentence processing difficulty. From the theoretical
side, we calculate word-by-word surprisal pre-
dictions from a family of incremental depen-
dency parsers for German based on Nivre (2004);
these parsers differ only in the size k of the beam
used in the search for analyses of longer and longer
sentence-initial substrings. We find that predictions
derived even from very narrow-beamed parsers im-
prove a baseline eye-fixation duration model. The
fact that any member of this parser family derives
a useful predictor shows that at least some syn-
tactic properties are reflected in readers? eye fixa-
tion durations. From a cognitive perspective, the
utility of small k parsers for modeling comprehen-
sion difficulty lends credence to the view that the
human processor is a single-path analyzer (Frazier
and Fodor, 1978).
2 Parsing costs and theories of reading
difficulty
The length of time that a reader?s eyes spend fix-
ated on a particular word in a sentence is known
to be affected by a variety of word-level factors
such as length in characters, n-gram frequency and
empirical predictability (Ehrlich and Rayner, 1981;
Kliegl et al, 2004). This last factor is the one mea-
sured when human readers are asked to guess the
next word given a left-context string.
Any role for parser-derived syntactic factors
5
Figure 1: Dependency structure of a PSC sentence.
would have to go beyond these word-level influ-
ences. Our methodology imposes this requirement
by fitting a kind of regression known as a lin-
ear mixed-effects model to the total reading times
associated with each sentence-medial word in the
Potsdam Sentence Corpus (PSC) (Kliegl et al,
2006). The PSC records the eye-movements of 272
native speakers as they read 144 German sentences.
3 The Parsing Model
The parser?s outputs define a relation on
word pairs (Tesnie`re, 1959; Hays, 1964). The
structural description in Figure 1 is an example
output that depicts this dependency relation using
arcs. The word near the arrowhead is the dependent,
the other word its head (or governor).
These outputs are built up by monotonically
adding to an initially-empty set of dependency re-
lations as analysis proceeds from left to right. To
arrive at Figure 1 the Nivre parser passes through
a number of intermediate states that aggregate four
data structures, detailed below in Table 1.
? A stack of already-parsed unreduced words.
? An ordered input list of words.
h A function from dependent words to heads.
d A function from dependent words to arc types.
Table 1: Parser configuration.
The stack ? holds words that could eventually be
connected by new arcs, while ? lists unparsed words.
h and d are where the current set of dependency arcs
reside. There are only four possible transitions
from configuration to configuration. Left-Arc
and Right-Arc transitions create dependency re-
Error type Amount
Noun attachment 4.2%
Prepositional Phrase attachment 3.0%
Conjunction 1.9%
Adverb ambiguity 1.8%
Other 1.1%
Total error 12.1%
Table 2: Parser errors by category.
lations between the top elements in ? and ? , while
Shift and Reduce transitions manipulate ?.
When more than one transition is applicable, the
parser decides between them by consulting a proba-
bility model derived from the Negra and Tiger news-
paper corpora (Skut et al, 1997; Ko?nig and Lezius,
2003). This model is called Stack3 because it con-
siders only the parts-of-speech of the top three el-
ements of ? along with the top element of ? . On
the PSC this model achieves 87.9% precision and
79.5% recall for unlabeled dependencies. Most of
the attachments it gets wrong (Table 2) represent al-
ternative readings that would require semantic guid-
ance to rule out.
To compare ?serial? human sentence processing
models against ?parallel? models, our implemen-
tation does beam search in the space of Nivre-
configurations. The number of configurations main-
tained at any point is a changeable parameter k.
3.1 Surprisal
In Figure 1 the thermometer beneath the Ger-
man preposition ?in? graphically indicates a
high surprisal prediction derived from the depen-
dency parser. Greater cognitive effort, reflected in
reading time, should be observed on ?in? as com-
6
pared to ?alte.? The difficulty prediction at ?in? ul-
timately follows from the frequency of verbs tak-
ing prepositional complements that follow nominal
complements in the training data. Equation 1 ex-
presses the general theory: the surprisal of a word,
on a language model, is the logarithm of the pre-
fix probability eliminated in the transition from one
word to the next.
surprisal(n) = log2
(?n?1
?n
)
(1)
The prefix-probability ?n of an initial substring is
the total probability of all grammatical analyses that
derive w = w1...wn as a left-prefix (Equation 2).
?n =
?
d?D(G,wv)
Prob(d) (2)
In a complete parser, every member of D is in cor-
respondence with a state transition sequence. In the
beam-search approximation, only the top k config-
urations are retained from prefix to prefix, which
amounts to choosing a subset of D.
4 Study
The study addresses whether surprisal is a signif-
icant predictor of reading difficulty and, if it is,
whether the beam-size parameter k affects the use-
fulness of the calculated surprisal values in account-
ing for reading difficulty.
Using total reading time as a dependent measure,
we fit a baseline linear mixed-effects model (Equa-
tion 3) that takes into account word-level predictors
log frequency (lf), log bigram frequency (bi), word
length (len), and human predictability given the left
context (pr).
log (TRT ) = (3)
5.4? 0.02lf ? 0.01bi ? 0.59len?1 ? 0.02pr
All of the word-level predictors were statistically
significant at the ? level 0.05.
Beyond this baseline, we fitted ten other lin-
ear mixed-effects models. To the inventory of word-
level predictors, each of the ten regressions uniquely
added the surprisal predictions calculated from a
parser that retains at most k=1...9,100 analyses at
each prefix. We evaluated the change in relative
quality of fit due to surprisal with the Deviance In-
formation Criterion (DIC) discussed in Spiegelhal-
ter et al (2002). Whereas the more commonly ap-
plied Akaike Information Criterion (1973) requires
the number of estimated parameters to be deter-
mined exactly, the DIC facilitates the evaluation of
mixed-effects models by relaxing this requirement.
When comparing two models, if one of the models
has a lower DIC value, this means that the model fit
has improved.
4.1 Results and Discussion
Table 3 shows that the linear mixed-effects model of
German reading difficulty improves when surprisal
values from the dependency parser are used as pre-
dictors in addition to the word-level predictors. The
coefficients on the baseline predictors remained un-
changed (Equation 3) when any of the parser-based
predictors was added.
Table 3 also suggests the returns to be had in
accounting for reading time are greatest when the
beam is limited to a handful of parses. Indeed,
a parser that handles a few analyses at a time
(k=1,2,3) is just as valuable as one that spends far
greater memory resources (k=100). This observa-
tion is consistent with Brants and Crocker?s (2000)
observation that accuracy can be maintained even
when restricted to 1% of the memory required for
exhaustive parsing. The role of small k depen-
dency parsers in determining the quality of statisti-
cal fit challenges the assumption that cognitive func-
tions are global optima. Perhaps human parsing is
boundedly rational in the sense of the bound im-
posed by Stack3 (Simon, 1955).
5 Conclusion
This study demonstrates that surprisal calculated
with a dependency parser is a significant predictor of
reading times, an empirical measure of cognitive dif-
ficulty. Surprisal is a significant predictor even when
examined alongside the more commonly used pre-
dictors, word length, predictability, and n-gram fre-
quency. The viability of parsers that consider just a
small number of analyses at each increment is con-
sistent with conceptions of the human comprehender
that incorporate that restriction.
7
Model Coefficient Std. Error t value DIC
Baseline - - - 144511.1
k=1 0.033691 0.002285 15 143964.9
k=2 0.038573 0.002510 15 143946.2
k=3 0.037320 0.002693 14 143990.4
k=4 0.041035 0.002853 14 143975.7
k=5 0.048692 0.002953 16 143910.9
k=6 0.046580 0.003063 15 143951.6
k=7 0.045008 0.003118 14 143974.4
k=8 0.042039 0.003165 13 144006.4
k=9 0.040657 0.003225 13 144023.9
k=100 0.029467 0.003878 8 144125.4
Table 3: Coefficients and standard errors from the multiple regressions using different versions of surprisal (baseline
predictors? coefficients are not shown for space reasons). t values > 2 are statistically significant at ? = 0.05. The
table also shows DIC values for the baseline model (Equation 3) and the models with baseline predictors plus surprisal.
References
H. Akaike. 1973. Information theory and an extension
of the maximum likelihood principle. In B. N. Petrov
and F. Caski, editors, 2nd International Symposium on
Information Theory, pages 267?281, Budapest, Hun-
gary.
T. Brants and M. Crocker. 2000. Probabilistic pars-
ing and psychological plausibility. In Proceedings of
COLING 2000: The 18th International Conference on
Computational Linguistics.
N. Chater and C. Manning. 2006. Probabilistic mod-
els of language processing and acquisition. Trends in
Cognitive Sciences, 10:287?291.
M. W. Crocker and T. Brants. 2000. Wide-coverage
probabilistic sentence processing. Journal of Psy-
cholinguistic Research, 29(6):647?669.
V. Demberg and F. Keller. 2007. Data from eye-tracking
corpora as evidence for theories of syntactic process-
ing complexity. Manuscript, University of Edinburgh.
S. F. Ehrlich and K. Rayner. 1981. Contextual effects
on word perception and eye movements during read-
ing. Journal of Verbal Learning and Verbal Behavior,
20:641?655.
L. Frazier and J. D. Fodor. 1978. The sausage machine: a
new two-stage parsing model. Cognition, 6:291?325.
J. Hale. 2001. A probabilistic Earley parser as a psy-
cholinguistic model. In Proceedings of 2nd NAACL,
pages 1?8. Carnegie Mellon University.
D.G. Hays. 1964. Dependency theory: A formalism and
some observations. Language, 40:511?525.
D. Jurafsky. 1996. A probabilistic model of lexical and
syntactic access and disambiguation. Cognitive Sci-
ence, 20:137?194.
R. Kliegl, E. Grabner, M. Rolfs, and R. Engbert. 2004.
Length, frequency, and predictability effects of words
on eye movements in reading. European Journal of
Cognitive Psychology, 16:262?284.
R. Kliegl, A. Nuthmann, and R. Engbert. 2006. Track-
ing the mind during reading: The influence of past,
present, and future words on fixation durations. Jour-
nal of Experimental Psychology: General, 135:12?35.
E. Ko?nig and W. Lezius. 2003. The TIGER language -
a description language for syntax graphs, Formal def-
inition. Technical report, IMS, Universita?t Stuttgart,
Germany.
R. Levy. 2008. Expectation-based syntactic comprehen-
sion. Cognition, 106(3):1126?1177.
J. Nivre. 2004. Incrementality in deterministic depen-
dency parsing. In Incremental Parsing: Bringing En-
gineering and Cognition Together, Barcelona, Spain.
Association for Computational Linguistics.
J. Park and C. Brew. 2006. A finite-state model of hu-
man sentence processing. In Proceedings of the 21st
International Conference on Computational Linguis-
tics and the 44th Annual Meeting of the ACL, pages
49?56, Sydney, Australia.
H. Simon. 1955. A behavioral model of rational choice.
The Quarterly Journal of Economics, 69(1):99?118.
W. Skut, B. Krenn, T. Brants, and H. Uszkoreit. 1997.
An annotation scheme for free word order languages.
In Proceedings of the Fifth Conference on Applied
Natural Language Processing ANLP-97, Washington,
DC.
D. J. Spiegelhalter, N. G. Best, B. P. Carlin, and
A. van der Linde. 2002. Bayesian measures of model
complexity and fit (with discussion). Journal of the
Royal Statistical Society, 64(B):583?639.
L. Tesnie`re. 1959. Ele?ments de syntaxe structurale. Edi-
tions Klincksiek, Paris.
8
