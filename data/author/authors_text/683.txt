BioNLP 2007: Biological, translational, and clinical language processing, pages 33?40,
Prague, June 2007. c?2007 Association for Computational Linguistics
An Unsupervised Method for Extracting Domain-specific Affixes in
Biological Literature
Haibin Liu Christian Blouin Vlado Kes?elj
Faculty of Computer Science, Dalhousie University, Canada, {haibin,cblouin,vlado}@cs.dal.ca
Abstract
We propose an unsupervised method to au-
tomatically extract domain-specific prefixes
and suffixes from biological corpora based
on the use of PATRICIA tree. The method is
evaluated by integrating the extracted affixes
into an existing learning-based biological
term annotation system. The system based
on our method achieves comparable experi-
mental results to the original system in locat-
ing biological terms and exact term match-
ing annotation. However, our method im-
proves the system efficiency by significantly
reducing the feature set size. Additionally,
the method achieves a better performance
with a small training data set. Since the af-
fix extraction process is unsupervised, it is
assumed that the method can be generalized
to extract domain-specific affixes from other
domains, thus assisting in domain-specific
concept recognition.
1 Introduction
Biological term annotation is a preparatory step in
information retrieval in biological science. A bi-
ological term is generally defined as any technical
term related to the biological domain. Consider-
ing term structure, there are two types of biologi-
cal terms: single word terms and multi-word terms.
Many systems (Fukuda et al, 1998; Franzn et al,
2002) have been proposed to annotate biological
terms based on different methodologies in which de-
termining term boundaries is usually the first task. It
has been demonstrated (Jiampojamarn et al, 2005a),
however, that accurately locating term boundaries
is difficult. This is so because of the ambiguity of
terms, and the peculiarity of the language used in
biological literature.
(Jiampojamarn et al, 2005b) proposed an auto-
matic biological term annotation system (ABTA)
which applies supervised learning methods to an-
notate biological terms in the biological litera-
ture. Given unstructured texts in biological research,
the annotation system first locates biological terms
based on five word position classes, ?Start?, ?Mid-
dle?, ?End?, ?Single? and ?Non-relevant?. There-
fore, multi-word biological terms should be in a con-
sistent sequence of classes ?Start (Middle)* End?
while single word terms will be indicated by the
class ?Single?. Word n-grams (Cavnar and Tren-
kle, 1994) are used to define each input sentence
into classification instances. For each element in
an n-gram, the system extracts feature attributes as
input for creating the classification model. The ex-
tracted feature attributes include word feature pat-
terns(e.g., Greek letters, uppercase letters, digits and
other symbols), part-of-speech (POS) tag informa-
tion, prefix and suffix characters. Without using
other specific domain resources, the system achieves
comparable results to some other state-of-the-art
systems (Finkel et al, 2004; Settles, 2004) which
resort to external knowledge, such as protein dictio-
naries. It has been demonstrated (Jiampojamarn et
al., 2005b) that the part-of-speech tag information
is the most effective attribute in aiding the system
to annotate biological terms because most biologi-
cal terms are partial noun phrases.
The ABTA system learns the affix feature by
recording only the first and the last n characters (e.g.,
n = 3) of each word in classification instances, and
the authors claimed that the n characters could pro-
vide enough affix information for the term annota-
tion task. Instead of using a certain number of char-
acters to provide affix information, however, it is
more likely that a specific list of typically used pre-
fixes and suffixes of biological words would provide
more accurate information to classifying some bio-
logical terms and boundaries. We hypothesize that
33
a more flexible affix definition will improve the per-
formance of the taks of biological term annotation.
Inspired by (Jiampojamarn et al, 2005b), we
propose a method to automatically extract domain-
specific prefixes and suffixes from biological cor-
pora. We evaluate the effectiveness of the extracted
affixes by integrating them into the parametrization
of an existing biological term annotation system,
ABTA (Jiampojamarn et al, 2005b), to evaluate the
impact on performance of term annotation. The pro-
posed method is completely unsupervised. For this
reason, we suggest that our method can be gener-
alized for extracting domain-specific affixes from
many domains.
The rest of the paper is organized as follows: In
section 2, we review recent research advances in bi-
ological term annotation. Section 3 describes the
methodology proposed for affix extraction in detail.
The experiment results are presented and evaluated
in section 4. Finally, section 5 summarizes the paper
and introduces future work.
2 Related Work
Biological term annotation denotes a set of proce-
dures that are used to systematically recognize per-
tinent terms in biological literature, that is, to differ-
entiate between biological terms and non-biological
terms and to highlight lexical units that are related to
relevant biology concepts (Nenadic and Ananiadou,
2006).
Recognizing biological entities from texts allows
for text mining to capture their underlying meaning
and further extraction of semantic relationships and
other useful information. Because of the importance
and complexity of the problem, biological term an-
notation has attracted intensive research and there is
a large number of published work on this topic (Co-
hen and Hersh, 2005; Franzn et al, 2003).
Current approaches in biological term annota-
tion can be generalized into three main categories:
lexicon-based, rule-based and learning-based (Co-
hen and Hersh, 2005). Lexicon-based approaches
use existing terminological resources, such as dic-
tionaries or databases, in order to locate term oc-
currences in texts. Given the pace of biology re-
search, however, it is not realistic to assume that a
dictionary can be maintained up-to-date. A draw-
back of lexicon-based approaches is thus that they
are not able to annotate recently coined biological
terms. Rule-based approaches attempt to recover
terms by developing rules that describe associated
term formation patterns. However, rules are often
time-consuming to develop while specific rules are
difficult to adjust to other types of terms. Thus, rule-
based approaches are considered to lack scalability
and generalization.
Systems developed based on learning-based ap-
proaches use training data to learn features useful for
biological term annotation. Compared to the other
two methods, learning-based approaches are theo-
retically more capable to identify unseen or multi-
word terms, and even terms with various writing
styles by different authors. However, a main chal-
lenge for learning-based approaches is to select a set
of discriminating feature attributes that can be used
for accurate annotation of biological terms. The fea-
tures generally fall into four classes: (1) simple de-
terministic features which capture use of uppercase
letters and digits, and other formation patterns of
words, (2) morphological features such as prefix and
suffix, (3) part-of-speech features that provide word
syntactic information, and (4) semantic trigger fea-
tures which capture the evidence by collecting the
semantic information of key words, for instances,
head nouns or special verbs.
As introduced earlier, the learning-based biologi-
cal term annotation system ABTA obtained an 0.705
F-score in exact term matching on Genia corpus
(v3.02)1 which contains 2,000 abstracts of biolog-
ical literature. In fact, the morphological features
in ABTA are learned by recording only the first and
the last n characters of each word in classification
instances. This potentially leads to inaccurate affix
information for the term annotation task.
(Shen et al, 2003) explored an adaptation of a
general Hidden Markov Model-based term recog-
nizer to biological domain. They experimented with
POS tags, prefix and suffix information and noun
heads as features and reported an 0.661 F-score in
overall term annotation on Genia corpus. 100 most
frequent prefixes and suffixes are extracted as can-
didates, and evaluated based on difference in likeli-
hood of part of a biological term versus not. Their
method results in a modest positive improvement in
recognizing biological terms. Two limitations of this
method are: (1) use of only a biological corpus, so
1http://www-tsujii.is.s.u-tokyo.ac.jp/GENIA/
34
that the general domain-independent affixes are not
removed, and (2) a supervised process of choosing a
score threshold that is used in affix selection.
(Lee et al, 2003) used prefix and suffix fea-
tures coupled with a dictionary-based refinement of
boundaries of the selected candidates in their exper-
iments for term annotation. They extracted affix fea-
tures in a similar way with (Shen et al, 2003). They
also reported that affix features made a positive ef-
fect on improving term annotation accuracy.
In this project, we consider the quality of domain-
specific affix features extracted via an unsupervised
method. Successful demonstration of the quality of
this extraction method implies that domain-specific
affixes can be identified for arbitrary corpora without
the need to manually generate training sets.
3 PATRICIA-Tree-based Affix Extraction
3.1 PATRICIA Tree
The method we propose to extract affixes from bio-
logical words is based on the use of PATRICIA tree.
?PATRICIA? stands for ?Practical Algorithm To Re-
trieve Information Coded In Alphanumeric?. It was
first proposed by (Morrison, 1968) as an algorithm
to provide a flexible means of storing, indexing, and
retrieving information in a large file. PATRICIA
tree uses path compression by grouping common se-
quences into nodes. This structure provides an ef-
ficient way of storing values while maintaining the
lookup time for a key of O(N) in the worst case,
where N is the length of the longest key. Meanwhile,
PATRICIA tree has little restriction on the format of
text and keys. Also it does not require rearrange-
ment of text or index when new material is added.
Because of its outstanding flexibility and efficiency,
PATRICIA tree has been applied to many large in-
formation retrieval problems (Morrison, 1968).
In our project, all biological words are inserted
and stored in a PATRICIA tree, using which we can
efficiently look up specific biological word or extract
biological words that share specified affixes and cal-
culated required statistics.
3.2 Experiment Design
In this work, we have designed the experiments to
extract domain-specific prefixes and suffixes of bio-
logical words from a biological corpus, and investi-
gate whether the extracted affix information could
facilitate better biological term annotation. The
overall design of our experiments consists of three
major processes: affix extraction, affix refining and
evaluation of experimental results. It is seen that
every node in PATRICIA tree contains exactly one
string of 1 or more characters, which is the preced-
ing substring of its descendant nodes. Meanwhile,
every word is a path of substrings from the root node
to a leaf. Therefore, we propose that every substring
that can be formed from traversing the internal nodes
of the tree is a potential affix.
In the affix extraction process, we first populate a
PATRICIA tree using all words in the combined cor-
pus(CC) of a Biological Corpus (BC) and a General
English Corpus (GEC). GEC is used against BC in
order to extract more accurate biological affix infor-
mation. Two PATRICIA trees are populated sepa-
rately for extracting prefixes and suffixes. The suffix
tree is based on strings derived by reversing all the
input words from the combined corpus. All the po-
tential prefixes and suffixes are then extracted from
the populated PATRICIA trees.
In the affix refining process, for each extracted
potential affix, we compute its joint probability of
being both an English affix and a biological affix,
P (D = Biology, A = Yes|PA), where D stands
for Domain, A stands for Affix and PA represents
Potential Affix. This joint probability can be fur-
ther decomposed as shown in Eq.(1). In the for-
mula, P (A = Yes|PA) denotes the probability that
a given potential affix is a true English affix while
P (D = Biology|A = Yes,PA) refers to the proba-
bility that a given English affix is actually a biologi-
cal affix.
P (D = Biology, A = Yes|PA) =
P (D=Biology|A=Yes,PA)? P (A=Yes|PA) (1)
To calculate P (A = Yes|PA), the probabilities of
prefixes and suffixes are measured separately. In
linguistics, a prefix is described as a type of affix
that precedes the morphemes to which it can attach
(Soanes and Stevenson, 2004). Simply speaking, a
prefix is a substring that can be found at the begin-
ning of a word. Our functional definition of a prefix
is a substring which precedes words existing in the
English language. This can be done by enumerating,
for each node, all descendant substring and assess-
ing their existence as stand-alone words. For exam-
ple, ?radioimmunoassay?, ?radioiodine? and ?radio-
35
labeled? are three words and have a common start-
ing string ?radio?. If we take out the remaining part
of each word, three new strings are obtained, ?im-
munoassay?, ?iodine? and ?labeled?. Since all the
input words are already stored in PATRICIA tree,
we lookup these three strings in PATRICIA tree and
find that ?immunoassay?, ?iodine? and ?labeled? are
also meaningful words in the tree. This indicates
that ?radio? is a prefix among the input words. On
the other hand, it is obvious that ?radioimmunoas-
say? and ?radioiodine? share another string ?radioi?.
However, ?mmunoassay? and ?odine? are not mean-
ingful words due to their absence in the PATRICIA
tree. This suggests that ?radioi? is not a prefix.
For each extracted potential prefix,
P (A = Yes|PA) is computed as the proportion of
strings formed by traversing all descendant nodes
that are meaningful terms. In our experiments,
the measure of determining a string meaningful
is to look up whether the string is an existing
word present in the built prefix PATRICIA tree.
Algorithm 1 shows the procedure of populating a
PATRICIA tree and calculating P (A = Yes|PA)
for each potential prefix.
Algorithm 1 P (A = Yes|PA) for Prefix
Input: words (w) ? Combined Corpus (CC)
Output: P (A = Yes|PA) for each potential prefix
PT = ? //PT : Patricia Trie
for all words w ? CC do
PT ? Insert(w) //Populating Patricia Trie
for all nodes ni ? PT do
PA? String(ni) //Concatenate strings
// in nodes from root to ni,
// which is a potential prefix
TPA ? PrefixSearch(PA)
//TPA : all words w ? CC beginning with PA
score ? 0
for all words w ? TPA do
if Extrstr(PA,w) in PT then
//Extrstr() returns the remaining string
// of w without PA
score ++
P (A = Yes|PA) ? score/|TPA|
//|TPA| is the number of words in TPA
Likewise, in linguistics a suffix is an affix that
follows the morphemes to which it can attach
(Soanes and Stevenson, 2004). Simply speaking,
a suffix of a word is a substring exactly match-
ing the last part of the word. Similar to the idea
of calculating P (A = Yes|PA) for potential pre-
fix, we conjecture that the extracted potential suf-
fix could be a reasonable English suffix if the in-
verted strings formed from traversing the descen-
dant nodes of the potential suffix in the suffix PA-
TRICIA tree are meaningful words. For instance,
?Calcium-dependent?, ?Erythropoietin-dependent?
and ?Ligand-dependent? share a common ending
string ?-dependent?. Since the remaining strings of
each word, ?Calcium?, ?Erythropoietin? and ?Lig-
and? can be found in the ?forward? PATRICIA tree,
?-dependent? is a potentially useful suffix.
However, it is often observable that some English
words do not begin with another meaningful word
but a typical prefix, for example, ?alpha-bound? and
?pro-glutathione?. It is known that ?-bound?and
?-glutathione? are good suffixes in biology. ?al-
pha? and ?pro?, however, are not meaningful words
but typical prefixes, and in fact have been extracted
when calculating P (A = Yes|PA) for potential pre-
fix. Therefore, in order to detect and capture such
potential suffixes, we further assume that if a word
begins with a recognized prefix instead of another
meaningful word, the remaining part of the word
still has the potential to be an informative suffix.
Therefore, strings ?-bound? and ?-glutathione? can
be successfully extracted as potential suffixes. In our
experiments, an extracted potential prefix is consid-
ered a recognized prefix if its P (A = Yes|PA) is
greater than 0.5.
To calculate P (D = Biology|A = Yes, PA), it
is necessary to first determine true English affixes
from extracted potential affixes. In our experiments,
we consider that an extracted potential prefix or suf-
fix is a recognized affix only if its P (A = Yes|PA)
is greater than 0.5. It is also necessary to consider
the biological corpus BC and the general English
corpus GEC separately. It is assumed that a biol-
ogy related affix tends to occur more frequently in
words of BC than GEC. Eq.(2) is used to estimate
P (D = Biology|A = Yes, PA).
P (D = Biology|A = Yes, PA) =
(#Words with PA in BC/Size (BC))/
(#Words with PA in BC/Size (BC) +
#Words with PA in GEC/Size (GEC)), (2)
36
where only PA with P (A = Yes|PA) greater than
0.5 are used, and the number of words with a certain
PA is further normalized by the size of each corpus.
Finally, the joint probability of each potential af-
fix, P (D = Biology, A = Yes|PA), can be used to
parametrize a word beginning or ending with PA.
In the evaluation process of our experiments, the
prefix-suffix pair with maximum joint probability
values is used to parametrize a word. Therefore,
each word in BC has exactly two values as affix fea-
ture: a joint probability value for its potential prefix
and a joint probability value for its potential suffix.
We then replace the original affix feature of ABTA
system with our obtained joint probability values,
and investigate whether these new affix information
leads to equivalent or better term annotation on BC.
4 Results and Evaluation
4.1 Dataset and Environment
For our experiments, it is necessary to use a corpus
that includes widely used biological terms and com-
mon English words. This dataset, therefore, will al-
low us to accurately extract the information of bi-
ology related affixes. As a proof-of-concept proto-
type, our experiments are conducted on two widely
used corpora: Genia corpus (v3.02) and Brown cor-
pus2.The Genia version 3.02 corpus is used as the
biological corpus BC in our experiments. It contains
2,000 biological research paper abstracts. They were
selected from the search results in the MEDLINE
database3, and each biological term has been an-
notated into different terminal classes based on the
opinions of experts in biology. Used as the general
English corpus GEC, Brown corpus includes 500
samples of common English words, totalling about
a million words drawn from 15 different text cate-
gories.
All the experiments were executed on a Sun So-
laris server Sun-Fire-880. Our experiments were
mainly implemented using Perl and Python.
4.2 Experimental Results
We extracted 15,718 potential prefixes and 21,282
potential suffixes from the combined corpus of Ge-
nia and Brown. Among them, there are 2,306 poten-
tial prefixes and 1,913 potential suffixes with joint
2http://clwww.essex.ac.uk/w3c/corpus ling/
3http://www.ncbi.nlm.nih.gov/PubMed/
probability value P (D = Biology, A = Yes|PA)
greater than 0.5. Table 1 shows a few examples
of extracted potential affixes whose joint probabil-
ity value is equal to 1.0. It is seen that most of
these potential affixes are understandable biological
affixes which directly carry specific semantic mean-
ings about certain biological terms. However, some
substrings are also captured as potential affixes al-
though they may not be recognized as ?affixes? in
linguistics, for example ?adenomyo? in prefixes, and
?mopoiesis? in suffixes. In Genia corpus, ?adeno-
myo? is the common beginning substring of biologi-
cal terms ?adenomyoma?, ?adenomyosis? and ?ade-
nomyotic? , while ?plasias? is the common ending
substring of biological terms ?neoplasias? and ?hy-
perplasias?. The whole list of extracted potential af-
fixes is available upon request.
In order to investigate whether the extracted af-
fixes improves the performance of biological term
annotation, it is necessary to obtain the experimen-
tal results of both original ABTA system and the
ABTA system using our extracted affix information.
In ABTA, the extraction of feature attributes is per-
formed on the whole 2000 abstracts of Genia cor-
pus, and then 1800 abstracts are used as training
set while the rest 200 abstracts are used as testing
set. The evaluation measures are precision, recall
and F-score. C4.5 decision tree classifier (Alpay-
din, 2004) is reported as the most efficient classi-
fier which leads to the best performance among all
the classifiers experimented in (Jiampojamarn et al,
2005b). Therefore, C4.5 is used as the main clas-
sifier in our experiments. The experimental results
of ABTA system with 10 fold cross-validation based
on different combinations of the original features are
presented in Table 2 in which feature ?WFP? is short
for Word Feature Patterns, feature ?AC? denotes Af-
fix Characters, and feature ?POS? refers to POS tag
information. The setting of parameters in the exper-
iments with ABTA is: the word n-gram size is 3, the
number of word feature patterns is 3, and the number
of affix characters is 4. We have reported the F-score
and the classification accuracy of the experiments in
the table. It is seen that there is a tendency with the
experimental performance that for a multi-word bi-
ological term, the middle position is most difficult
to detect while the ending position is generally eas-
ier to be identified than the starting position. The
assumed reason for this tendency is that for multi-
37
Potential Prefixes Potential Suffixes
13-acetate
B-cell
endotoxin
I-kappaB
macrophage
adenomyo
Rel/NF-kappaB
anti-CD28
VitD3
cytokine
3-kinase
CD28
HSV-1
ligand
N-alpha-tosyl-L
platelet
pharmaco
adenovirus
chromatin
hemoglobin
-T-cell
-coated
-expressed
-inducer
plasias
-alpha-activated
mopoiesis
-nonresponsive
coagulant
-soluble
cytoid
-bearing
-kappaB-mediated
-globin-encoding
-immortalized
-methyl
lyse
-receptor
glycemia
racrine
Table 1: Examples of Extracted Potential Affixes with Joint Probability Value 1.0
word biological terms, many middle words of are
seemingly unrelated to biology domain while many
ending words directly indicate their identity, for in-
stances, ?receptor?, ?virus? or ?expression?.
Table 3 shows the experimental results of ABTA
system after replacing the original affix feature with
our obtained joint probability values for each word
in Genia corpus. ?JPV? is used to denote Joint Prob-
ability Values. It is seen that based on all three
features the system achieves a classification accu-
racy of 87.5%, which is comparable to the results
of the original ABTA system. However, the size of
the feature set of the system is significantly reduced,
and the classification accuracy of 87.5% is achieved
based on only 18 parameters, which is 1/2 of the size
of the original feature set. Meanwhle, the execution
time of the experiments generally reduces to nearly
half of the original ABTA system (e.g., reduces from
4 hours to 1.7 hours). Furthermore, when the feature
set contains only our extracted affix information, the
system reaches a classification accuracy of 81.46%
based on only 6 parameters. It is comparable with
the classification accuracy achieved by using only
POS information in the system. In addition, Table 3
also presents the experimental results when our ex-
tracted affix information is used as an addtional fea-
ture to the original feature set. It is expected that the
system performance is further improved when the
four features are applied together. However, the size
of the feature set increases to 42 parameters, which
increases the data redundancy. This proves that the
extracted affix information has a positive impact on
locating biological terms, and it could be a good re-
placement of the original affix feature.
Moreover, we also evaluated the performance of
the exact matching biological term annotation based
on the obtained experimental results of ABTA sys-
tem. The exact matching annotation in ABTA sys-
tem is to accurately identify every biological term,
including both multi-word terms and single word
terms, therefore, all the word position classes of
a term have to be classified correctly at the same
time. An error occurring in any one of ?Start? ?Mid-
dle? and ?End? classes leads the system to annotate
multi-word terms incorrectly. Consequently, the ac-
cumulated errors will influence the exact matching
annotation performance. Table 4 presents the exact
matching annotation results of different combination
of features based on 10 fold cross-validation over
Genia corpus. It is seen that after replacing the orig-
inal affix feature of ABTA system with our obtained
joint probability values for each word in Genia cor-
pus, the system achieves an 0.664 F-score on exact
matching of biological term annotation, compara-
ble to the exact matching performance of the orig-
inal ABTA system. In addition, when the feature
set contains only our extracted affix information, the
system reaches an 0.536 F-score on exact matching.
Although it is a little lower than the exact matching
performance achieved by using only the original af-
fix features in the system, the feature set size of the
system is significantly reduced from 24 to 6.
In order to further compare our method with the
original ABTA system, we attempted eleven differ-
ent sizes of training data set to run the experiments
separately based on our method and the original
ABTA system. They can then be evaluated in terms
of their performance on each training set size. These
eleven different training set sizes are: 0.25%, 0.5%,
1%, 2.5%, 5%, 7.5%, 10%, 25%, 50%, 75% and
90%. For instance, 0.25% denotes that the train-
ing data set is 0.25% of Genia corpus while the
rest 99.75% becomes the testing data set for exper-
iments. It is observed that there are about 21 paper
abstracts in training set when its size is 1% , and 52
abstracts when its size is 2.5%. It is expected that
larger training set size leads to better classification
accuracy of experiments.
For each training set size, we randomly extracted
10 different training sets from Genia corpus to run
the experiments. We then computed the mean clas-
sification accuracy (MCA) of 10 obtained classifi-
cation accuracies. Figure 1 was drawn to illustrate
the distribution of MCA of each training set size
38
Feature F-Measure Classification #
sets Start Middle End Single Non Accuracy (%) Parameters
WFP 0.467 0.279 0.495 0.491 0.864 74.59 9
AC 0.709 0.663 0.758 0.719 0.932 85.67 24
POS 0.69 0.702 0.775 0.67 0.908 83.96 3
WFP+AC 0.717 0.674 0.762 0.730 0.933 86.02 33
WFP+POS 0.726 0.721 0.793 0.716 0.923 85.96 12
AC+POS 0.755 0.741 0.809 0.732 0.930 87.14 27
WFP+AC+POS 0.764 0.745 0.811 0.749 0.933 87.59 36
Table 2: Experimental Results of Original ABTA System
Feature F-Measure Classification #
sets Start Middle End Single Non Accuracy (%) Parameters
JPV 0.652 0.605 0.713 0.602 0.898 81.46 6
WFP+JPV 0.708 0.680 0.756 0.699 0.919 84.84 15
JPV+POS 0.753 0.740 0.805 0.722 0.928 86.92 9
WFP+JPV+POS 0.758 0.749 0.809 0.74 0.933 87.50 18
WFP+AC+POS+JPV 0.767 0.746 0.816 0.751 0.934 87.77 42
Table 3: Experimental Results of ABTA System with Extracted Affix Information
for both methods, with the incremental proportion of
training data. It is noted in Figure 1 that the change
patterns of MCA obtained by our method and the
original ABTA system are similar. It is also seen
that our method achieves marginally better classifi-
cation performance when the proportion of training
data is under 2.5%.
Figure 1: MCA Distribution
In order to determine if the classification perfor-
mance difference between our method and the origi-
nal ABTA system is statistically significant, we per-
formed one-tailed t-Test (Alpaydin, 2004) on the
classification results with our hypothesis that MCA
of our proposed method is higher than MCA of orig-
inal ABTA system. The significance level ? is set
to be the conventional value 0.05. As a result, the
classification performance difference between two
methods is statistically significant when the propor-
tion of training data is 0.25%, 0.5%, 1% or 2.5%.
Table 5 shows the P values of t-Test results for the
various training set sizes. This demonstrates that
the ABTA system adopting our method outperforms
the original ABTA system in classification accuracy
when the proportion of training data is lower than
2.5% of Genia corpus, and achieves comparable
classification performance with the original ABTA
system when the proportion continuously increases.
One-tailed Training set size
t-Test 0.25% 0.5% 1% 2.5%
P value 0.0298 0.0006 0.0002 0.0229
Table 5: One-tailed t-Test Results
5 Conclusions
In this paper, we have presented an unsupervised
method to extract domain-specific prefixes and suf-
fixes from the biological corpus based on the use
of PATRICIA tree. The ABTA system (Jiampoja-
marn et al, 2005b) adopting our method achieves
an overall classification accuracy of 87.5% in locat-
ing biological terms, and derives an 0.664 F-score in
exact term matching annotation, which are all com-
parable to the experimental results obtained by the
original ABTA system. However, our method helps
the system significantly reduce the size of feature set
and thus improves the system efficiency. The sys-
tem also obtains a classification accuracy of 81.46%
based only on our extracted affix information. This
39
Feature Exact Matching Annotation #
sets Precision Recall F-score Parameters
AC 0.548 0.571 0.559 24
WFP+AC+POS 0.661 0.673 0.667 36
JPV 0.527 0.545 0.536 6
WFP+JPV+POS 0.658 0.669 0.664 18
Table 4: Exact Matching Annotation Performance
demonstates that the affix information acheived by
the proposed method is important to accurately lo-
cating biological terms.
We further explored the reliability of our method
by gradually increasing the proportion of training
data from 0.25% to 90% of Genia corpus. One-tailed
t-Test results confirm that the ABTA system adopt-
ing our method achieves more reliable performance
than the original ABTA system when the training
corpus is small. The main result of this work is thus
that affix features can be parametrized from small
corpora at no cost in performance.
There are some aspects in which the proposed
method can be improved in our future work. We
are interested in investigating whether there exists
a certain threshold value for the joint probability
which might improve the classification accuracy of
ABTA system to some extent. However, this could
import supervised elements into our method. More-
over, we would like to incorporate our method into
other published learning-based biological term an-
notation systems to see if better system performance
will be achieved. However, superior parametriza-
tion will improve the annotation performance only
if the affix information is not redundant with other
features such as POS.
References
Ethem Alpaydin. 2004. Introduction to Machine Learning.
MIT Press.
William B. Cavnar and John M. Trenkle. 1994. N-gram-based
text categorization. In Proc. SDAIR-94, 3rd Ann. Symposium
on Doc. Analysis and Inf. Retr., pages 161?175, Las Vegas,
USA.
Aaron Michael Cohen and William R. Hersh. 2005. A sur-
vey of current work in biomedical text mining. Briefings in
Bioinformatics, 5(1):57?71.
Jenny Finkel, Shipra Dingare, Huy Nguyen, Malvina Nissim,
Gail Sinclair, and Christopher Manning. 2004. Exploiting
context for biomedical entity recognition: From syntax to
the web. In Joint wsh. on NLP in Biomedicine and its Appli-
cations (JNLPBA-2004).
Kristofer Franzn, Gunnar Eriksson, Fredrik Olsson, Lars
Asker Per Lidn, and Joakim Cster. 2002. Protein names
and how to find them. International Journal of Medical In-
formatics special issue on NLP in Biomedical Applications,
pages 49?61.
Kristofer Franzn, Gunnar Eriksson, Fredrik Olsson, Lars
Asker Per Lidn, and Joakim Cster. 2003. Mining the Bio-
medical Literature in the Genomic Era: An Overview. J.
Comp. Biol., 10(6):821?855.
K. Fukuda, T. Tsunoda, A. Tamura, and T. Takagi. 1998. To-
ward information extraction: Identifying protein names from
biological papers. In the Pacific Symposium on Biocomput-
ing, pages 707?718.
Sittichai Jiampojamarn, Nick Cercone, and Vlado Kes?elj.
2005a. Automatic Biological Term Annotation Using N-
gram and Classification Models. Master?s thesis, Faculty of
Comp.Sci., Dalhousie University.
Sittichai Jiampojamarn, Nick Cercone, and Vlado Kes?elj.
2005b. Biological Named Entity Recognition using N-
grams and Classification Methods. In Conf. of the Pacific
Assoc. for Computational Linguistics, PACLING?05, Tokyo,
Japan.
Ki-Joong Lee, Young-Sook Hwang, and Hae-Chang Rim.
2003. Two-phase biomedical NE recognition based on
SVMs. In Proc. of the ACL 2003 workshop on Natural lan-
guage processing in biomedicine, pages 33?40, Morristown,
NJ, USA. ACL.
Donald R. Morrison. 1968. Patricia - Practical Algorithm To
Retrieve Information Coded in Alphanumeric. Journal of
the ACM, 15(4):514?534.
Goran Nenadic and Sophia Ananiadou. 2006. Mining semanti-
cally related terms from biomedical literature. ACM Trans-
actions on Asian Language Information Processing (TALIP),
5(1):22 ? 43.
Burr Settles. 2004. Biomedical named entity recognition using
conditional random fields and novel feature sets. In Joint
wsh. on NLP in Biomedicine and its Applications (JNLPBA-
2004).
Dan Shen, Jie Zhang, Guodong Zhou, Jian Su, and Chew-Lim
Tan. 2003. Effective adaptation of a Hidden Markov Model-
based named entity recognizer for biomedical domain. In
Proc. of the ACL 2003 wsh. on NLP in Biomedicine, pages
49?56, Morristown, NJ, USA.
Catherine Soanes and Angus Stevenson. 2004. Oxford Dictio-
nary of English. Oxford University Press.
40
Proceedings of the Workshop on BioNLP, pages 133?141,
Boulder, Colorado, June 2009. c?2009 Association for Computational Linguistics
Identifying Interaction Sentences from Biological Literature Using
Automatically Extracted Patterns
Haibin Liu
Faculty of Computer Science
Dalhousie University
Halifax, NS, Canada
haibin@cs.dal.ca
Christian Blouin
Faculty of Computer Science
Dalhousie University
Halifax, NS, Canada
cblouin@cs.dal.ca
Vlado Kes?elj
Faculty of Computer Science
Dalhousie University
Halifax, NS, Canada
vlado@cs.dal.ca
Abstract
An important task in information retrieval is to
identify sentences that contain important relation-
ships between key concepts. In this work, we
propose a novel approach to automatically extract
sentence patterns that contain interactions involv-
ing concepts of molecular biology. A pattern is
defined in this work as a sequence of specialized
Part-of-Speech (POS) tags that capture the struc-
ture of key sentences in the scientific literature.
Each candidate sentence for the classification task
is encoded as a POS array and then aligned to
a collection of pre-extracted patterns. The qual-
ity of the alignment is expressed as a pairwise
alignment score. The most innovative component
of this work is the use of a Genetic Algorithm
(GA) to maximize the classification performance
of the alignment scoring scheme. The system
achieves an F-score of 0.834 in identifying sen-
tences which describe interactions between bio-
logical entities. This performance is mostly af-
fected by the quality of the preprocessing steps
such as term identification and POS tagging.
1 Introduction
Recent research in information extraction (IE) in bio-
logical science has focused on extracting information
about interactions between biological entities from re-
search communications. The type of interaction of in-
terest includes protein-protein, protein-DNA, gene reg-
ulations and other interactions between macromole-
cules. This work broadens the definition of the term
?interaction? to include other types of concepts that
are semantically related to cellular components and
processes. This contrasts with the past efforts focus-
ing strictly on molecular interactions (Blaschke et al,
1999; Ono et al, 2001). We anticipate that identifying
the relationships between concepts of molecular biol-
ogy will facilitate the building of knowledge models,
improve the sensitivity of IE tasks and ultimately facil-
itate the formulation of new hypothesis by experimen-
talists.
The extraction of interactions is based on the heuris-
tic premise that interacting concepts co-occur within
a given section of text. The challenge is that co-
occurrence certainly does not guarantee that a passage
contains an interaction(Jang et al, 2006; Skusa et al,
2005). Co-occurrence is highly dependent on the de-
finition of the section of text within which the target
terms are expected to be found. A thorough compari-
son on the prediction of protein-protein interaction be-
tween abstract-level co-occurrence and sentence-level
co-occurrence was undertaken (Raychaudhuri, 2006).
It is demonstrated that abstract co-occurrence is more
sensitive but less specific for interactions. At the cost
of wide coverage, sentence co-occurrence increases the
accuracy of interaction prediction. Since the ultimate
goal of IE is to extract knowledge and accuracy is the
most important aspect in evaluating the performance
of such systems, it makes sense to focus the effort
in seeking interaction sentences rather than passages
or abstracts. Not every co-occurrence in sentences
implies a relationship that expresses a fact. In the
2005 Genomics Track dataset, 50% of all sentence co-
occurrences of entities correspond to definite relation-
ships while the rest of the co-occurrences only convey
some possible relationships or contain no relationship
of interest (Li et al, 2005). Therefore, more sophisti-
cated text mining strategies are required to classify sen-
tences that describe interactions between co-occurring
concepts.
In the BioCreative II challenge 1, teams were asked
to determine whether a given passage of text contained
information about the interaction between two proteins.
This classification task worked at the abstract level and
the interacting protein pairs were not required to be ex-
tracted. The task for the Learning Language in Logic
1http://biocreative.sourceforge.net/
133
(LLL?05) challenge 2 was to build systems that ex-
tract interactions between genes or proteins from bio-
logical literature. From individual sentences annotated
with agent-target relations, patterns or models had to be
learned to extract these interactions. The task focused
on extracting only the interacting partners. The context
of an interaction may also be critical to the validity of
the extracted knowledge since not all statements found
in the literature are always true.
In this work, we propose an approach to automati-
cally extract patterns containing relevant interaction be-
tween biological concepts. This extraction is based on
the assumption that biological interactions are articu-
lated by a limited number of POS patterns embedded
in sentences where entities/concepts are co-occurring.
The extracted patterns are then applied to identify inter-
action sentences which describe interactions between
biological entities. Our work aims to identify precise
sentences rather than passages. Because of the nature
of the patterns, we hope that some of the contextual in-
formation present in interaction sentences also play a
role in the classification task.
The rest of the paper is organized as follows: In Sec-
tion 2, we review recent research advances in extracting
biological interactions. Section 3 describes an experi-
mental system designed for our work. Sections 4, 5
and 6 elaborate the approaches and algorithms. Per-
formance is evaluated in Section 7. Finally, Section 8
summarizes the paper and introduces future work.
2 Related work
Early on, Blaschke (Blaschke et al, 1999) employed
patterns to predict the presence of a protein-protein in-
teraction. A series of patterns was developed manu-
ally to cover the most obvious descriptions of protein
functions. This process was based on a set of key-
words, including interaction verbs, that are commonly
used to describe this type of interaction. A sentence ex-
traction system BioIE (Divoli and Attwood, 2005) also
uses patterns to extract entire sentences related to pro-
tein families, protein structures, functions and diseases.
The patterns were manually defined and consisted of
single words, word pairs, and small phrases.
Although systems relying on hand-coded patterns
have achieved some success in extracting biological in-
teractions, the strict requirement of dedicated expert
work is problematic. Moreover, each type of interac-
tion may require a definition of many different patterns
including different arrangements and different variants
2http://genome.jouy.inra.fr/texte/LLLchallenge/
of the same keyword. Manually encoding all patterns
encountered in a corpus is time-consuming and poten-
tially impractical in real applications. Thus, automati-
cally learning such patterns is an attractive solution.
An approach which combines dynamic program-
ming and sequence alignment algorithms as normally
used for the comparison between nucleotide sequences
was introduced by Huang et al (Huang et al, 2004).
This approach is designed to generate patterns useful
for extracting protein-protein interactions. The main
problem with this approach is that the scoring scheme
that is required to implement the alignment algorithm is
difficult to define and contains a potentially large num-
ber of free parameters. We propose a method based
on Genetic Algorithm (GA) heuristics to maximize the
alignment procedure for the purpose of classification.
GAs were also used as a learning strategy to train finite
state automata for finding biological relation patterns
in texts(Plake et al, 2005). It was reported (Bunescu et
al., 2005; Hakenberg et al, 2005) that automatically
learned patterns identify biological interactions even
more accurately than hand-coded patterns.
3 Overview of system design
In this work, we have designed an experimental sys-
tem to facilitate the automatic extraction of biological
interaction patterns and the identification of interaction
sentences. It consists of three major modules: biolog-
ical text preprocessing, interaction pattern extraction,
and interaction sentence identification.
Biological text preprocessing reformats the original
biological texts into candidate sentences. A pattern
learning method is then proposed to automatically ex-
tract the representative patterns of biological interac-
tions. The obtained patterns are further used to iden-
tify instances that evidently describe biological inter-
actions. Poor performance during preprocessing will
have detrimental effects on later stages. In the follow-
ing sections, we will describe each component.
4 Biological text preprocessing
4.1 Sentence preparation
A heuristic method is implemented to detect sentence
boundaries (Mikheev, 2002) based on the assumption
that sentences are usually demarcated by some indica-
tive delimiting punctuation marks in order to segment
the biological texts into sentence units. Captions and
headings that are not grammatically valid sentences are
therefore detected and further eliminated for our work.
134
4.2 Part-of-Speech tagging
POS tagging is then performed to associate each word
in a sentence with its most likely POS tag. Because
subsequent processing steps typically depend on the
tagger?s output, high performance at this level is cru-
cial for success in later stages. A statistical tagger Lin-
gua::EN::Tagger 3 is used to perform this task.
4.3 Biological term annotation
A learning-based biological term annotation system,
ABTA (Jiampojamarn et al, 2005), is embedded in our
system. The type of terms includes molecules, such
as genes, proteins and cell lines, and also biological
processes. Examples of biological processes as entities
are: ?T cell activation? and ?IL-2 gene transcription?.
We consider that a broader definition of biological term
will include more facts from literature, thus leading to
more general use of interaction patterns for IE tasks.
ABTA considers the longest expression and ignores
embedded entities. Further, instead of distinguishing
terms from their relevant biology concepts, a unified
tag ?BIO? is assigned to all the identified terms. We
aim to discover patterns of the general interactions be-
tween biological concepts, not only the interactions be-
tween molecules, e.g., protein-protein interaction.
Tags like NN (noun) and VB (verb) are typically used
to define entities and the action type of interactions,
and thus they are indispensable. However, tags such
as JJ (adjective) and RB (adverb) could occur at differ-
ent positions in a sentence. We decided to remove these
tags to prevent the combinatorial effect that these would
induce within the set of extracted patterns.
4.4 Text chunking
Next, a rule-based text chunker (Ramshaw and Mar-
cus, 1995) is applied on the tagged sentences to fur-
ther identify phrasal units, such as base noun phrases
NP and verbal units VB. This allows us to focus on the
holistic structure of each sentence. Text chunking is not
applied on the identified biological terms. In order to
achieve more generalized interaction patterns, a unified
tag ?VB? is used to represent every verbal unit instead
of employing different tags for various tenses of verbs.
As a result of preprocessing, every sentence is rep-
resented by its generalized form as a sequence of cor-
responding tags consisting of POS tags and predefined
tags. Table 1 summarizes the main tags in the system.
A biological interaction tends to involve at least three
objects: a pair of co-occurring biological entities con-
3http://search.cpan.org/?acoburn
Tag name Tag description Tag type
BIO Biological entity Predefined
NP Base noun phrase Predefined
VB Verbal unit Predefined
IN Preposition POS
CC Coordinating conjunction POS
TO to POS
PPC Punctuation comma POS
PRP Possessive 2nd determiner POS
DET Determiner POS
POS Possessive POS
Table 1: Main tags used in the system
nected by a verb which specifies the action type of the
interaction. Thus, a constraint is applied that only sen-
tences satisfying form ?BioEntity A ? Verb ? BioEn-
tity B? will be preserved as candidate sentences to be
further processed in the system. It is possible that the
presence of two entities in different sentence structures
implies a relationship. However, this work assumes the
underlying co-occurrence of two concepts and a verb in
the interest of improving the classification accuracy.
The obtained candidate sentences are split into train-
ing and testing sets. The training set is used to ex-
tract the representative patterns of biological interac-
tions. The testing set is prepared for identifying sen-
tences that evidently describe biological interactions.
5 Interaction pattern extraction
5.1 PATRICIA trees
The method we propose to extract interaction patterns
from candidate sentences is based on the use of PATRI-
CIA trees (Morrison, 1968). A PATRICIA tree uses
path compression by grouping common sequences into
nodes. This structure provides an efficient way of stor-
ing values while maintaining the lookup time for a key
of O(N). It has been applied to many large information
retrieval problems (Chien, 1997; Chen et al, 1998).
In our work, a PATRICIA tree is used for the first
time to facilitate the automatic extraction of interaction
patterns. All training sentences are inserted and stored
in a generic PATRICIA tree from which the common
patterns of POS tags can be efficiently stored and the
tree structure used to compute relevant usage statistics.
5.2 Potential pattern extraction
Patterns of straightforward biological interactions are
frequently encountered in a range of actual sentences.
Conversely, vague relationships or complex interac-
tions patterns are seldom repeated. Therefore, the
135
premise of this work is that there is a set of frequently
occurring interaction patterns that matches a majority
of stated facts about molecular biology. In this work, a
biological interaction pattern is defined as follows:
Definition 5.1. A biological interaction pattern bip
is a sequence of tags defined in Table 1 that captures an
aggregate view of the description of certain types of bi-
ological interactions based on the consistently repeated
occurrences of this sequence of tags in different inter-
action sentences. BIP = {bip1, bip2, ? ? ? , bipk} repre-
sents the set of biological interaction patterns.
We first extract potential interaction patterns by
populating a PATRICIA tree using training sentences.
Every node in the tree contains one or more system
tags, which is the preceding tag sequence of its descen-
dant nodes in each sentence. Every sentence is com-
posed of a path of system tags from the root to a leaf.
Hence, we propose that the sequence of system tags
that can be formed from traversing the nodes of the tree
is a potential pattern of biological interactions. At the
same time, the occurrence frequency of each pattern is
also retrieved from the traversal of tree nodes.
A predefined frequency threshold fmin is used as
a constraint to filter out patterns that occur less than
fmin times. It has been demonstrated that if an interac-
tion is well recognized, it will be consistently repeated
(Blaschke et al, 1999; Ono et al, 2001). The general-
ization and the usability of patterns can be controlled by
tuning fmin. Further, some filtering rules are adapted
to control the form of a pattern and enhance the quality
of the discovered patterns, such as if a pattern ends with
a tag IN, VB, CC or TO, the pattern will be rejected.
Flexibility in setting this threshold can be applied to
meet special demands. Algorithm 1 shows our pattern
learning method which has a time complexity of O(n)
in the size of candidate sentences, n.
Algorithm 1 Patricia-Tree-based Extraction of Biolog-
ical Interaction Patterns
Input: Candidate Sentences CS ? Biological text; a prede-
fined threshold fmin; a set of filtering rules FR
Output: BIP : Set of biological interaction patterns
BIP ? ?; PT ? ? //PT : Patricia Trie
for all sentences s ? CS do
PT ? Insert(s) //Populating Patricia Tree
for all nodes ni ? PT do
bipi ? Pattern(ni) //Concatenating tags in nodes
from root to ni, which is a potential pattern
if Count(bipi) ? fmin and bipi does not meet FR
then
//Count(bipi) returns No. of occurrences of bipi;
BIP ? bipi
5.3 Interaction verb mining
Although the obtained patterns are derived from the
candidate sentences possessing the form ?BioEntity A
? Verb ? BioEntity B?, some of them may not contain
facts about biological interactions. This is possible if
the action verbs do not describe an interaction. Quite a
few verbs, such as ?report?, ?believe?, and ?discover?,
only serve a narrative discourse purpose. Therefore,
mining the correct interaction verbs becomes an impor-
tant step in the automatic discovery of patterns. We de-
cided to perform the method applied in (Huang et al,
2004) to mine a list of interaction verbs. This will be
used to further improve the relevance of achieved pat-
terns by filtering out patterns formed by the sentences
in which the action verbs are not on the list.
6 Interaction sentence identification
Once the biological interaction patterns are obtained,
we perform interaction sentence identification on test-
ing sentences. For our work, they are partitioned into
two sets: interaction sentences which explicitly discuss
interactions between entities, and non-interaction sen-
tences which do not describe interactions, or merely
imply some vague relationships between entities. The
task of interaction sentence identification is treated as a
classification problem to differentiate between interac-
tion sentences and non-interaction sentences.
6.1 Pattern matching scoring
We first perform pattern matching by iteratively apply-
ing the interaction patterns to each testing sentence.
This is done using sequence alignment which calculates
the degree of the similarity of a sentence to an inter-
action pattern. Since patterns capture various ways of
expressing interactions among sentences, a high simi-
larity between an interaction sentence and a pattern is
expected. Therefore, we conjecture that the alignment
scores can be used to discriminate some type of inter-
action sentences from other types of sentences.
The scoring scheme involved in the pattern match-
ing consists of penalties for introducing gaps, match re-
wards and mismatch penalties for different system tag
pairs. Table 2 presents an example scoring scheme for
main tags. Penalties and rewards are denoted respec-
tively by negative and positive values.
As a variation of global alignment, an end-space free
alignment algorithm is implemented to facilitate the
alignment between patterns and testing sentences. The
shortest pattern is always preferred for a sentence in
case that same alignment score is achieved by multiple
136
Tag Gap Match Mismatch
BIO -10 +8 -3
NP -8 +6 -3
VB -7 +7 -3
IN -6 +5 -1
CC -6 +5 -1
TO -1 +5 -1
PPC -1 +3 -1
PRP -1 +3 -1
DET -1 +3 -1
POS -1 +3 -1
Table 2: An alignment scoring scheme for system tags
patterns. As a result, each sentence is assigned to its
most appropriate pattern along with a maximum align-
ment score. Therefore, an interaction sentence will be
highlighted with a high alignment score by its most
similar interaction pattern, while a non-interaction sen-
tence will be characterized by a low alignment score
indicating rejections by all patterns. Essentially, this
procedure can be seen as a variation of the well-known
k Nearest Neighbors classification method, with k = 1.
6.2 Performance evaluation
We then evaluate whether the alignment scores can be
used to classify the testing sentences. We have pro-
posed two independent evaluation measures: statistical
analysis (SA) and classification accuracy (AC).
SA measures whether the scoring difference be-
tween the mean of interaction sentences and the mean
of non-interaction sentences is statistically significant.
If the difference is significant, there will be a tendency
that interaction sentences outscore non-interaction sen-
tences in alignment. Hence, it would be reliable to
use alignment scores to classify testing sentences. Al-
though non-interaction sentences could come from the
same documents as interaction sentences and discuss
concepts that are associated with the target interac-
tions, we assume that interaction sentences and non-
interaction sentences are two independent samples.
The statistical two-sample z test (Freund and Per-
les, 2006) is performed with the null hypothesis that
there is no scoring difference between the means of
interaction and non-interaction sentences. A compar-
atively large z will lead to the rejection of the null
hypothesis. Naturally, the increase of z value will in-
crease the difference between the means and therefore
conceptually keep pushing the overall scoring distrib-
utions of two samples further away from each other.
Consequently, interaction sentences can be separated
from non-interaction sentences according to alignment
scores. In reality, the distinction between interaction
and non-interaction sentences is not absolute. Thus,
the scoring distributions of two samples can only be
distanced by a certain maximum value of z depending
on the scoring scheme applied in pattern matching.
Conversely, AC measures the proportion of correctly
classified testing sentences, including both interaction
and non-interaction sentences, to the total testing sen-
tences. An appropriate threshold T is determined for
obtained alignment scores to differentiate between in-
teraction and non-interaction sentences, and to facili-
tate the calculation of classification accuracy.
It is not possible to evaluate the performance without
correctly pre-labeled testing sentences. We decided to
manually classify the testing sentences in advance by
assigning each sentence an appropriate label of inter-
action or non-interaction. This work was done by two
independent experts, both with Ph.D. degrees in mole-
cular biology or a related discipline.
6.3 Scoring scheme optimization
The scoring scheme applied in pattern matching has a
crucial impact on the performance of interaction sen-
tence identification. An interesting problem is whether
there exists an optimal scoring scheme covering the
costs of gap, match and mismatch for different sys-
tem tags in the pattern matching alignment, which is
destined to achieve the best performance on classify-
ing testing sentences. To the best of our knowledge,
no efforts have been made to investigate this problem.
Instead, an empirical or arbitrary scoring scheme was
adopted in previous research for the pairwise align-
ments (Huang et al, 2004; Hakenberg et al, 2005). We
have proved that the problem is NP-hard by reducing a
well-known NP-hard problem 3-SAT to this problem.
The proof is not presented in this work.
A genetic algorithm (GA) is used as a heuristic
method to optimize parameters of the scoring scheme
for sentence classification. The costs of penalties and
rewards for different system tags are encoded by inte-
ger values within two predefined ranges: [-50, 0) and
(0, 50], and assembled as a potential solution of scor-
ing scheme, which consists of 30 parameters covering
the costs for tags in the alignment as listed in Table 2.
The two evaluation measures SA and AC are used as
the fitness function for GA respectively with the goal
of maximizing z value or classification accuracy.
GA is set up to evolve for 100 generations, each of
which consists of a population of 100 potential solu-
tions of scoring scheme. GA starts with a randomly
137
generated population of 100 potential solutions and
proceeds until 100 generations are reached. The num-
ber of generations and the population size are decided
with consideration of the runtime cost of evaluating the
fitness function, which requires running the scoring al-
gorithm with each sentence. A large number of gener-
ations or a large population size would incur an expen-
sive runtime cost of evaluation.
In addition, we further divide the labeled set of can-
didate sentences into two subsets: The first dataset is
used to optimize parameters of the scoring scheme,
while the second dataset, testing set, is used to test the
achieved scheme on the task of sentence classification.
7 Results and evaluation
7.1 Dataset
Our experiments have been conducted on Genia cor-
pus (v3.02) 4, the largest, publicly available corpus in
molecular biology domain. It consists of 2,000 biolog-
ical research paper abstracts and is intended to cover
biological reactions concerning transcription factors in
human blood cells. The information of sentence seg-
mentation, word tokenization, POS tagging and biolog-
ical term annotation is also encoded in the corpus.
7.2 Biological text preprocessing results
Evaluated using the inherently equipped annotation in-
formation, our system achieves nearly 99% accuracy
on segmenting sentences. Further, it obtains an overall
POS tagging accuracy of 91.0% on 364,208 individ-
ual words. We noticed that the tagging information en-
coded in Genia corpus is not always consistent through-
out the whole corpus, thus introducing detrimental ef-
fects on the tagging performance. Also, considering
that the tagger is parameterized according to the gen-
eral English domain, porting this tagger to the biology
domain is accompanied by some loss in performance.
The system reaches an F-score of 0.705 on annotat-
ing all biological terms including both multi-word and
single word terms. After performing text chunking, the
system produces a set of candidate sentences. We fur-
ther perform text chunking on Genia corpus based on
its encoded annotations and use the resulting set of sen-
tences for the subsequent experiments to provide a gold
standard to which results produced based on our system
annotations can be compared. Table 3 presents some
statistics of the preprocessed dataset. For each type of
annotations, we randomized the candidate sentence set
4http://www-tsujii.is.s.u-tokyo.ac.jp/GENIA/
and chose 12,525 candidate sentences as the training
set to extract biological interaction patterns. The rest
of candidate sentences are prepared as the testing set.
Attributes Genia Our system
Total preprocessed sentences 18,545 18,355
Candidate sentences 16,272 17,525
Training set sentences 12,525 12,525
Testing set sentences 6,020 5,000
Table 3: Statistics of experimental dataset
7.3 Interaction pattern extraction results
fmin = 5 is used to filter out the potential patterns
that appear less than 5 times in the training set. Eval-
uated by domain experts, lists of 300 interaction verbs
and 700 non-interaction verbs are obtained from 12,525
training sentences with Genia annotations. Inflectional
variants of the verbs are also added into the lists.
Refined by the filtering rules and the interaction
verbs, a final set of representative patterns of biological
interactions are obtained from Algorithm 1. We per-
formed our proposed pattern learning method on train-
ing sentences of both the GENIA and our own anno-
tations. There are respectively 241 and 329 potential
patterns. Of these, 209 and 302 were extracted. Inter-
estingly, only 97 extracted patterns are common to both
annotation schemes.
Table 4 lists the 10 most frequent interaction patterns
based on Genia annotations. For instance, a training
sentence conforming to the second pattern is ?The ex-
pression of the QR gene is regulated by the transcrip-
tion factor AP-1.? (MEDLINE: 96146856).
Pattern count Pattern
264 BIO VB BIO IN BIO
261 NP IN BIO VB IN BIO
182 NP IN BIO VB BIO
162 BIO IN BIO VB IN BIO
160 BIO VB IN BIO IN BIO
143 NP IN BIO VB IN NP IN BIO
142 NP VB IN BIO VB BIO
138 PRP VB IN BIO VB BIO
126 BIO VB NP IN BIO IN BIO
121 NP IN BIO VB NP IN BIO
Table 4: Extracted Biological Interaction Patterns
7.4 Interaction sentence identification results
Since the total testing sentence set is large, we decided
to randomly extract 400 sentences from it as the sam-
ple set for our task. The 400 sentences were manu-
138
Figure 1: AC comparison between two measures
ally pre-labeled into two classes: interaction and non-
interaction. Further, a subset of 300 testing sentences
was used by GA to optimize parameters of the scor-
ing scheme, while the remaining 100 sentences were
prepared to test the achieved scheme on sentence clas-
sification. The distribution of class labels of the sample
sentences is shown in Table 5.
Class label 300 sentences 100 sentences
No. % No. %
Interaction 158 52.67 53 53
Non-interaction 142 47.33 47 47
Table 5: Class distribution of sample sentences
7.4.1 Comparison between two measures
We applied the evaluation measures, SA and AC,
respectively to the subset of 300 testing sentences as
the fitness function for GA, and recorded the scoring
scheme of every generation resulted from GA. Figure 1
presents the distribution of achieved classification ac-
curacy in terms of each scoring scheme optimized by
GA. This comparison is done with respect to the gener-
ation and evaluated on 300 testing sentences using the
annotations from the Genia corpus.
The achieved classification accuracy for AC gen-
erally outperforms the classification accuracy derived
by SA. It reaches its highest classification accuracy
80.33% from the 91th generation. Therefore, AC is
considered more efficient with the system and becomes
our final choice of fitness function for GA.
7.4.2 Results of sentence identification
GA results in an optimized performance on the 300
sentences. It also results in an optimized scoring
scheme along with its associated scoring threshold T ,
which are then applied together to the other 100 test-
ing sentences. Table 6 and 7 present the system perfor-
mance on the two sets respectively to both annotations.
Experimental Genia Our system
Results Interaction Non Interaction Non
Precision 0.757 0.887 0.704 0.702
Recall 0.928 0.665 0.761 0.640
F-score 0.834 0.750 0.731 0.670
Overall AC(%) 80.33 70.33
Table 6: Performance on 300 testing sentences
Experimental Genia Our system
Results Interaction Non Interaction Non
Precision 0.739 0.762 0.676 0.697
Recall 0.792 0.723 0.755 0.638
F-score 0.765 0.742 0.713 0.666
Overall AC(%) 75.96 70.00
Table 7: Performance on 100 testing sentences
Table 6 shows that when using the Genia annota-
tions the system achieves an 0.834 F-score in identify-
ing interaction sentences and an overall AC of 80.33%,
which is much higher than the proportion of either in-
teraction or non-interaction sentences in the 300 sen-
tence subset. This indicates that the system performs
well on both classes. In 100 generations GA is not able
to evolve a scoring scheme that leads to an AC above
80.33%. Moreover, our system annotations achieve
a lower performance than Genia annotations. We at-
tribute the difference to the accuracy loss of our system
annotations in the preprocessing steps as inaccurate an-
notations will lead to inappropriate patterns, thus harm-
ing the performance of sentence identification. For Ge-
nia annotations, the performance on the 100 testing sen-
tences suggests an overfitting problem.
There are a number of preprocessing steps that affect
the final classification performance. However, even as-
suming an ideal preprocessing of the unstructured text,
our method relies on the assumption that all interac-
tion sentences are articulated by a set of POS patterns
that are distinct to all other types of sentences. The
manual annotation of the training/testing set was a dif-
ficult task, so it is reasonable to assume that this will
also be difficult for the classifier. The use of passive
voice and the common use of comma splicing within
patterns makes sentence-level classification an espe-
cially difficult task. Another source of interactions that
our system cannot identify are implied and assume a
deeper semantic understanding of the concepts them-
139
selves. Other sentences are long enough that the inter-
action itself is merely a secondary purpose to another
idea. All of these factors pose interesting challenges
for future development of this work.
Moreover, we also experimented with 10 empirical
scoring schemes derived from previous experiments on
the 300 sentences respectively, including the scheme in
the Table 2. Several fixed thresholds were attempted for
obtained alignment scores to differentiate between in-
teraction and non-interaction sentences. Without using
GA to optimize parameters of the scoring scheme, the
best performance of 10 empirical schemes is an overall
AC of 65.67%, which is outperformed at the 3rd gen-
eration of the GA optimization with Genia annotations.
7.5 System performance comparison
Within the framework of our system, we further con-
ducted experiments on the same dataset for sentence
identification using interaction patterns generated by
another pattern generating algorithm (PGA) (Huang et
al., 2004) in order to compare with the performance of
patterns obtained by our pattern learning method.
In our implementation, PGA iterates over all pairs
of candidate sentences in the training set and calculates
the best alignment for each pair in terms of the cost
scheme of gap penalties proposed (Huang et al, 2004).
Each consensus sequence from the optimal alignment
of each pair forms a pattern. The filter rules proposed
are also applied. PGA has a time complexity of O(n2)
in the size of candidate sentences, n. Hence, our pro-
posed pattern learning method is much more efficient
when dealing with large collections of biological texts.
PGA produces a large number of patterns, even with
fmin = 5 and other filtering criteria. There are 37,319
common patterns between two types of annotations.
Attributes Genia Our system
Potential patterns (fmin = 5) 476,600 387,302
Extracted patterns (fmin = 5) 176,082 88,800
Table 8: Pattern extraction results of PGA
In order to make a direct comparison, we decided to
experiment with the same number of interaction pat-
terns. For Genia annotations, we chose the most fre-
quent 209 patterns generated by PGA to compare with
the 209 patterns by our method. For our system annota-
tions, two sets of 302 patterns are employed. Further, it
is found that there are 96 common patterns between the
two sets of 209 patterns for Genia annotations, and 153
common patterns between the two sets of 302 patterns
for our system annotations. Table 9 and 10 present the
results of sentence identification of PGA. The results
show that patterns generated by PGA do not perform
as well as patterns obtained by our method.
Experimental Genia Our system
Results Interaction Non Interaction Non
Precision 0.721 0.869 0.663 0.699
Recall 0.918 0.606 0.785 0.556
F-score 0.808 0.714 0.719 0.619
Overall AC(%) 77.00 67.67
Table 9: Performance of PGA on 300 testing sentences
Experimental Genia Our system
Results Interaction Non Interaction Non
Precision 0.664 0.796 0.698 0.635
Recall 0.849 0.574 0.566 0.766
F-score 0.745 0.667 0.625 0.694
Overall AC(%) 71.98 66.00
Table 10: Performance of PGA on 100 testing sentences
8 Conclusion and future work
In this paper, a novel approach is presented to auto-
matically extract the representative patterns of biologi-
cal interactions, which are used to detect sentences that
describe biological interactions. We conducted the ex-
periments on our designed system based on the Ge-
nia corpus. By means of a genetic algorithm, the sys-
tem achieves an 0.834 F-score using Genia annotations
and an 0.731 F-score using our system annotations in
identifying interaction sentences by evaluating 300 sen-
tences. By applying the optimized scoring scheme to
another set of 100 sentences, the system achieves com-
parable results for both types of annotations. Further-
more, by comparing with another pattern generating al-
gorithm, we infer that our proposed method is more ef-
ficient in producing patterns to identify interaction sen-
tences.
In our future work, we would like to employ the ob-
tained interaction patterns to guide the extraction of
specific interactions. The matching between patterns
and sentences will be performed and the matched parts
of each sentence will be extracted as candidate interac-
tions. Further reasoning processes can be performed
by means of available biological ontologies, such as
UMLS Semantic Network (Mccray and Bodenreider,
2002) and Gene Ontology (Consortium, 2001), to in-
fer new relations from the initial interactions. Such
processes can be employed to derive additional biolog-
ical knowledge from existing knowledge, or test for bi-
ological consistency of the newly entered data.
140
References
Christian Blaschke, Miguel A. Andrade, Christos Ouzounis,
and Alfonso Valencia. 1999. Automatic extraction of bi-
ological information from scientific text: Protein-protein
interactions. In Proceedings of the Seventh International
Conference on Intelligent Systems for Molecular Biology,
pages 60?67. AAAI Press.
Razvan Bunescu, Ruifang Ge, Rohit J Kate, Edward M Mar-
cotte, Raymond J Mooney, Arun K Ramani, and Yuk W
Wong. 2005. Comparative experiments on learning infor-
mation extractors for proteins and their interactions. Arti-
ficial Intelligence in Medicine, 33(2):139?155.
Keh-Jiann Chen, Wen Tsuei, and Lee-Feng Chien. 1998.
Pat-trees with the deletion function as the learning device
for linguistic patterns. In Proceedings of the 17th inter-
national conference on Computational linguistics, pages
244?250, Morristown, NJ, USA. Association for Compu-
tational Linguistics.
Lee-Feng Chien. 1997. Pat-tree-based keyword extrac-
tion for chinese information retrieval. SIGIR Forum,
31(SI):50?58.
Gene Ontology Consortium. 2001. Creating the gene ontol-
ogy resource: design and implementation. Genome Re-
search, 11(8):1425?1433.
Anna Divoli and Teresa K. Attwood. 2005. Bioie: extract-
ing informative sentences from the biomedical literature.
Bioinformatics, 21(9):2138?2139.
John E. Freund and Benjamin M. Perles. 2006. Modern
Elementary Statistics. Prentice Hall.
Jorg Hakenberg, Conrad Plake, Ulf Leser, Harald Kirsch,
and Dietrich Rebholz-Schuhmann. 2005. Lll?05 chal-
lenge: Genic interaction extraction with alignments and
finite state automata. In Proceedings of Learning Lan-
guage in Logic Workshop (LLL?05) at ICML, page 38C45,
Bonn, Germany.
Minlie Huang, Xiaoyan Zhu, Yu Hao, Donald G. Payan,
Kunbin Qu, and Ming Li. 2004. Discovering patterns to
extract protein-protein interactions from full texts. Bioin-
formatics, 20:3604?3612.
Hyunchul Jang, Jaesoo Lim, Joon-Ho Lim, Soo-Jun Park,
Kyu-Chul Lee, and Seon-Hee Park. 2006. Finding the ev-
idence for protein-protein interactions from pubmed ab-
stracts. Bioinformatics, 22(14):e220?e226.
Sittichai Jiampojamarn, Nick Cercone, and Vlado Kes?elj.
2005. Biological Named Entity Recognition using N-
grams and Classification Methods. In Proceedings of the
Conference Pacific Association for Computational Lin-
guistics, PACLING?05, Tokyo, Japan.
Jiao Li, Xian Zhang, Yu Hao, Minlie Huang, and Xiaoyan
Zhu. 2005. Learning domain-specific knowledge from
context?thuir at trec2005 genomics track. In Proceed-
ings of 14th Text Retrireval Conference (TREC2005),
Gaithersburg, USA.
Alexa T. Mccray and Olivier Bodenreider. 2002. A concep-
tual framework for the biomedical domain. In Semantics
of Relationships, Kluwer, pages 181?198. Kluwer Acad-
emic Publishers.
Andrei Mikheev. 2002. Periods, capitalized words, etc.
Comput. Linguist., 28(3):289?318.
Donald R. Morrison. 1968. Patricia ? Practical Algorithm
To Retrieve Information Coded in Alphanumeric. Jour-
nal of the ACM, 15(4):514?534.
Toshihide Ono, Haretsugu Hishigaki, Akira Tanigami, and
Toshihisa Takagi. 2001. Automated extraction of infor-
mation on protein-protein interactions from the biological
literature. Bioinformatics, 17(2):155?161.
Conrad Plake, Jorg Hakenberg, and Ulf Leser. 2005. Learn-
ing patterns for information extraction from free text. In
Proceedings of AKKD 2005, Karlsruhe, Germany.
Lance Ramshaw and Mitch Marcus. 1995. Text chunking
using transformation-based learning. In Proceedings of
the Third Workshop on Very Large Corpora, pages 82?94,
Somerset, New Jersey.
Soumya Raychaudhuri. 2006. Computational Text Analy-
sis: For Functional Genomics and Bioinformatics. Ox-
ford University Press.
Andre Skusa, Alexander Ruegg, and Jacob Kohler. 2005.
Extraction of biological interaction networks from scien-
tific literature. Brief Bioinform, 6(3):263?276.
141
