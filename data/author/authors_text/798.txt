The NICE Fairy-tale Game System1 
 
 
Joakim Gustafson, Linda Bell, Johan Boye, Anders Lindstr?m and Mats Wir?n 
TeliaSonera AB, 12386 Farsta, Sweden 
firstname.lastname@teliasonera.com 
 
                                                          
1 The work described in this paper was supported by the EU/HLT funded project NICE (IST-2001-35293), www.niceproject.com 
Abstract 
This paper presents the NICE fairy-tale game 
system, in which adults and children can 
interact with various animated characters in a 
3D world. Computer games is an interesting 
application for spoken and multimodal 
dialogue systems. Moreover, for the 
development of future computer games, 
multimodal dialogue has the potential to 
greatly enrichen the user?s experience. In this 
paper, we also present some requirements that 
have to be fulfilled to successfully integrate 
spoken dialogue technology with  a computer 
game application. 
1 Introduction 
The goal of the NICE project is to allow users of all 
ages to interact with lifelike conversational characters 
in a fairy-tale world inspired by the Danish author     
H C Andersen. To make these characters convincing 
in a computer game scenario, they have to possess 
conversational skills as well as the ability to perform  
physical actions in an interactive 3D world.  
What primarily distinguishes the NICE fairy-tale 
game system from other spoken dialogue systems is 
that the human-computer dialogue takes place within 
the context of an interactive computer game. 
However, spoken and multimodal dialogue is not 
supposed to be just an ?add-on? to the game, but the 
user?s primary means of progression through the 
story. The rationale for this is the great potential for 
more natural interaction we see in making methods 
from multimodal dialogue systems available in 
controlling gameplay. Potentially, spoken and 
multimodal interaction will make it possible to create 
a more engaging and immersive experience, or even 
facilitate the development of new kinds of computer 
games.    
Secondly, what makes NICE differ from typical 
spoken dialogue systems is the attempt to move away 
from strictly task-oriented dialogue. Instead, the 
interaction with the characters is domain-oriented. 
This means that the dialogue concerns different 
subplots in the fairy-tales, but without a clear goal-
orientation and without other demands than it being 
entertaining to the user. Furthermore, social 
interaction plays an important role in the fairy-tale 
world where the game takes place. By engaging in 
socializing with the animated characters, the user will 
find out things necessary to overcome various 
obstacles and enable progression through the story.  
Thirdly, a feature that differentiates NICE from 
other systems is that the main target user group of the 
system is children and young users. Previous studies 
have indicated that children employ partly different 
strategies when interacting with dialogue systems 
than adults do, and that there are also differences 
between age groups. For instance, younger children 
use less overt politeness markers and verbalize their 
frustration more than older children do (Arunachalam 
et al 2001). It has also been shown that children?s 
user experience is improved if they can communicate 
with a system with a ?personality? and that they 
benefit from being able to choose from several input 
modalities (Narayanan and Potamianos 2002). 
Furthermore, since many young people have a lot of 
experience with computer games, the believability of 
the dialogue characters and natural expressions will 
be critical aspects for the system?s success.  
Thus, computer games provide an excellent 
application area for research in spoken dialogue 
technology, requiring an advance of the state-of-the-
art in several fronts. Perhaps more importantly, game 
players will have a lot to gain from a successful 
incorporation of spoken dialogue technology into 
computer games. Today?s computer games are 
limited by the user?s input options, which are often 
restricted to direct manipulation and simple 
commands. In the development of the next generation 
of computer games, we believe that multimodal 
dialogue has the potential to greatly enrichen the 
user?s experience. For instance, spoken interaction 
makes it possible to refer to past events and objects 
currently not visible on the screen. Social interaction, 
which is already part of popular games such as SIMS, 
can be improved with spoken dialogue. Furthermore, 
speech and multimodal interaction supports 
cooperative games, where the user and character 
works together in solving a mutual problem.  
2 Spoken dialogue systems 
Spoken dialogue systems have so far mostly been 
designed with an overall goal to carry out a specific 
task, e.g. accessing time table information or ordering 
tickets (e.g. Zue et al 1991; Aust et al 1995). With 
task-oriented systems, it is possible to build domain 
models that can be used to predefine the language 
models and dialogue rules. The existence of 
predefined tasks makes it rather straight-forward to 
evaluate the performance of the dialogue system.  
Recent developments have made it possible to 
modify and extend the goals of spoken dialogue 
systems. Explorative dialogues, in which users are 
encouraged to browse through information without 
pursuing a specific task, have been presented by 
(Cassell et al 1999; Bell et al 2001). These 
dialogues still contain tasks to be solved during the 
interaction, e.g. giving constraints or receiving 
information about objects. However, explorative 
dialogue systems cannot be evaluated using merely 
the number of turns between different user 
interactions. A user who continues speaking with the 
system for a long time may do so because she is 
finding a lot of interesting information.  
Yet another type of dialogue system aims to 
present its users with an engaging and entertaining 
experience, without the presence of an external 
predetermined task. Conversational kiosks, such as 
August (Gustafson and Bell 2000) and MACK 
(Cassell et al 2002), encourage users to engage in 
social dialogues with embodied characters. Such 
dialogues are amenable to handling by a correctly 
designed dialogue system, since they primarily bring 
up features from the shared context. 
3 Interactive storytelling   
Interactivity has been defined as ?a kind of drama 
where the audience can modify the course of the 
actions [?] thus having an active role? (Szilas 1999). 
In interactive scenarios, the user helps the story 
unfold and may affect its course depending on his or 
her active participation. It has been argued that 
interactive storytelling will change computer 
entertainment by introducing better narrative content 
and allowing users to interfere with the progression 
of the storyline (Cavazza et al 2002). However, 
Young (2001) suggests that the drama manager of the 
system should put a limit to the user?s actions by not 
allowing interference that violates the overall 
narrative plan. Most interactive games developed so 
far allow users to intervene in the storytelling by 
acting on physical objects on the screen using direct 
maniputation (Young 2001; Cavazza et al 2002). 
Moreover, some systems allow users to interact with 
characters by means of written text input (Mateas and 
Stern 2002). In addition, Cavazza et al (2002) 
explored using a speech interface that handled 
isolated utterances from the user.  
4 The NICE fairy-tale game scenario  
The overall goal of the project is to provide users 
with an immersive dialogue experience in a 3D fairy-
tale world, see Figure 1. To this end, we have chosen 
to make spoken and multimodal dialogue the user?s 
primary vehicle of progressing through the story. It is 
also by verbal and non-verbal communication that the 
user can gain access to the goals and desires of the 
fairy-tale characters. This will be critical as the 
characters will ask the users to help them in solving 
problems. These problems either relate to objects that 
have to be manipulated or information that has to be 
retrieved from other fairy-tale characters.  
 
Figure 1. Cloddy Hans in the fairy-tale world. 
The fairy-tale domain was chosen because of its 
classic themes and stereotypical characters, well-
known to most adults as well as children. Some of 
these familiar characters are shown in Figure 2. 
 
Figure 2. The fairy-tale characters. 
To facilitate the progression through the story, we 
introduce Cloddy Hans, the user?s faithful assistant.  
Cloddy Hans?s character is conveyed to the users in 
the following way: he is a bit slow to understand, or 
so it seems. He sometimes appears hard of hearing 
and only understands spoken utterances and graphical 
gestures at a rather simple level. Cloddy Hans does 
not take a lot of initiatives, but is honest and anxious 
to try to help the user. In spite of his limited 
intellectual and perceptual capabilities, he may 
sometimes provide important clues through sudden 
flashes of insight.  
The user can ask Cloddy Hans to manipulate objects 
by referring to them verbally and/or by using the 
mouse. To understand the reason for not allowing 
users to directly manipulate objects on the screen, we 
have to recall what distinguishes NICE from other 
games, namely, spoken multimodal dialogue. We 
thus want to ensure that multimodal dialogue is 
appreciated by the user not just as an ?add-on? but as 
the primary means of progressing in the game. Our 
key to achieving this is to deliberately limit the 
capabilities of the key actors ? the user and Cloddy 
Hans ? in such a way that they can succeed only by 
cooperating through spoken multimodal dialogue. In 
other words, the user is intelligent but cannot himself 
affect objects in the world; Cloddy Hans on the other 
hand is a bit slow but capable of physical action 
according to what he gets told (and he may 
occasionally also provide tips to the user). 
The fairy-tale game will start with an introductory 
dialogue, in which the user meets Cloddy Hans in H C 
Andersen?s fairy-tale laboratory, see Figure 3. The 
simple task the user and Cloddy have to solve 
together is to take fairy-tale objects from a shelf and 
put them in the appropriate slot in a fairy-tale 
machine. Each slot is labelled with a symbol, which 
denotes the type of object supposed to go there, but 
since Cloddy Hans is not very bright, he needs help 
understanding these labels.  
 
Figure 3. Cloddy Hans in the fairy-tale lab 
The initial scenario is a ?grounding game? set in the 
context of a narrow task. In other words, its real 
purpose is a training session in which the user and 
Cloddy Hans agree on what different objects can be 
used for and how they can be referred to. This 
process also lets the player find out (by trial-and-
error) how to adapt in order to make it easier for the 
system to understand him or her. Moreover, Cloddy 
Hans sometimes explicitly instructs the user. For 
example, one lesson might be that it is sometimes 
more efficient to use multimodal input instead of just 
spoken utterances.  
The subsequent game in the fairy-tale world 
depends on what objects have been chosen by the 
user in the initial scenario. The advantage of this is 
that the objects are already grounded; for example, a 
sack of gold will be visually recognized by the player 
and there is an already agreed way of referring to it. 
5 System characteristics  
The game scenario as presented in the preceding 
section puts a number of requirements on the system. 
The scenario involves several animated characters, 
each with its own intended distinct personality. These 
personalities must be made explicit for the game 
player, and manifest themselves on all levels: from 
the appearance of the characters, their gestures and 
voices, choice of words, to their long-term behavior 
and overall role in the fairy-tale world. Furthermore, 
the characters need to be responsive, and be able to 
engage in conversation which makes sense to the 
player of the game. 
On the surface level, then, we need to have 
beautifully crafted animated characters and 
environments (these have been designed by the 
computer-game company Liquid Media). Each 
character must have its own voice that conveys the 
nature of that character?s personality, and be able to 
use prosodic cues to signal mood and emotions. To 
this end, a unit-selection speech synthesizer has been 
developed. Cloddy Hans has been given a slow, deep 
voice that goes along with his intended dunce 
personality. His repertoire of gestures and his style of 
walking also amplifies the impression of a slow-
witted but friendly person.  
On the input side, we need to recognize 
continuous, unconstrained speech for users of all 
ages. Previous studies have shown that children?s 
speech is associated with elevated error rates 
(Potamianos et al 1997; Oviatt and Adams 2000), 
making it necessary for Scansoft to retrain the NICE 
recognizer?s acoustic models. In addition, we need to 
take into account the disfluent speech patterns that 
are likely to arise, most probably because the users 
are unused to the situation or distracted by the virtual 
environment. On the other hand, not all input needs 
to be adequately interpreted. Much of the socializing 
utterances from the user can be handled in a 
satisfactory way by using shallow methods. 
Furthermore, the interpretation of the goal oriented 
interactions is simplified by the fact that the system 
knows which objects are visible on the screen and, 
more importantly, since it already knows what 
problems the fairy-tale characters has asked the user 
to help them to solve. Finally, the user also has the 
possibility of referring to objects using a pointing 
device. The software for the interpretation of this 
graphical input has been developed by LIMSI.  
The above characteristics have led us to design the 
system?s interpretation of user input in the following 
way. The system is implemented as a set of event-
driven processes that communicate via message-
passing. The architecture is essentially an extension 
of the one described in (Bell et al 2001). This 
architecture allows, among other things, for highly 
flexible turn-taking. When the user speaks, the 
system first tries to categorize the utterance as either 
social (needing only shallow interpretation) or goal-
oriented (needing further analysis). 
Finally, the long-term behavior of a character is 
decided by its set of internal goals and rules. A goal 
is essentially a predicate (that can be either true or 
false) concerning of the state of the virtual world. For 
instance, a character may have a goal to acquire a 
certain object or visit a certain place. If a given goal 
is not fulfilled (the predicate is false), the character 
will try to fulfill it. To this end it will use its set of 
rules, that define actions and dialogue acts that are 
likely to contribute to reaching the goal. 
6  Evaluation issues  
Task-oriented spoken dialogue systems are usually 
evaluated in terms of objective and subjective 
features. Objective criteria include the technical 
robustness and core functionality of the system 
components as well as system performance measures 
such as task completion rate. Subjective usability 
evaluations estimate features like naturalness and 
quality of the interactions, as well as user satisfaction 
reported in post-experimental interviews. However, 
many of these measures are simply not relevant for 
entertainment-type applications, where user 
satisfaction increases rather than decreases with task 
completion time. It can even be difficult to define 
what the completion of the task would be. In practice, 
computer games are usually evaluated by 
professional game reviewers and by the users in 
terms of number of copies sold.  
In the evaluation of the NICE fairy-tale game sales 
figures will not be possible to use, and several of the 
traditional objective measures are less relevant due to 
the domain. Instead, subjective measures involving 
features like ?narrative progression?, ?character 
believability?, and ?entertainment value?, will be 
used. They will be obtained off-line, by interviewing 
the users after their interactions and asking them to 
fill out questionnaires. Users will be asked how they 
perceived the quality of the actual interaction, as well 
as the personality of the fairy-tale characters. Expert 
evaluators, who will be able to replay the user 
interactions and inspect the system logs, will also be 
employed. Examples of evaluation questions to the 
experts include: ?Do the characters display 
meaningful roles and believable personalities that 
contribute to the story??, ?Do they succeed in 
signaling their level of understanding?, ?To what 
extent is the user able to affect the plot?? 
In order to be able to replay the user interactions with 
the fairy-tale system, all communication between the 
system modules are logged with time stamps. This 
will be a valuable tool both in the iterative system 
development and for system evaluations. At present, 
we are in the process of collecting data with the 
introductory game scenario. The data collected will 
be used to develop the subsequent scenarios in the 
fairy-tale game.  
References 
Arunachalam, S., D. Gould, E. Andersen, D. Byrd and S. S. 
Narayanan. (2001). Politeness and frustration language 
in child-machine interactions. Proceedings of 
Eurospeech: 2675-2678. 
Aust, H., M. Oerder, F. Seide and V. Steinbiss (1995). The 
Philips automatic train timetable information system. 
Speech Communication 17(3-4): 249-262. 
Bell, L., J. Boye and J. Gustafson (2001). Real-time 
handling of fragmented utterances. Proc. NAACL 2001 
workshop on Adaptation in Dialogue Systems. 
Cassell, J., T. Bickmore, M. Billinghurst, L. Campbell, K. 
Chang, H. Vilhj?lmsson and H. Yan (1999). 
Embodiment in conversational interfaces: Rea. 
Proceedings of CHI: 520-527. 
Cassell, J., T. Stocky, T. Bickmore, Y. Gao, Y. Nakano, K. 
Ryokai, D. Tversky, C. Vaucelle and H. Vilhjlmsson 
(2002). MACK: Media lab Autonomous 
Conversational Kiosk. Imagina 02. Monte Carlo. 
Cavazza, M., F. Charles and S. J. Mead (2002). Character-
based interactive storytelling. IEEE Intelligent 
Systems, Special issue on AI in Interactive 
Entertainment: 17-24. 
Gustafson, J. and L. Bell (2000). Speech technology on 
trial - Experiences from the August system. Natural 
Language Engineering 6(3-4): 273-286. 
Mateas, M. and A. Stern (2002). Architecture, authorial 
idioms and early observations of the interactive drama 
Facade. Technical report CM-CS-02-198. 
Narayanan, S. and A. Potamianos (2002). Creating 
conversational interfaces for children. IEEE 
Transactions on Speech and Audio Proc. 10(2): 65-78. 
Oviatt, S. and B. Adams (2000). Designing and evaluating 
conversational interfaces with animated characters. 
Embodied Conversational Agents. J. Cassell, J. 
Sullivan, S. Prevost and E. Churchill. MIT Press. 
Potamianos, A., S. Narayanan and S. Lee (1997). 
Automatic speech recognition for children. 
Proceedings of Eurospeech. 5: 2371-2374. 
Szilas, N. (1999). Interactive drama on the computer: 
beyond linear narrative. AAAI 1999 Fall Symposium 
on Narrative Intelligence. 
Young, R. M. (2001). An Overview of the Mimesis 
Architecture: Integrating Intelligent Narrative Control 
into an Existing Gaming Environment. Working Notes 
of the AAAI Spring Symposium on Artificial 
Intelligence and Interactive Entertainment. 
Zue, V., J. Glass, D. Goodline, H. Leung, M. Phillips, J. 
Polifroni and S. Seneff (1991). Integration of speech 
recognition and natural language processing in the 
MIT voyager system. Proc. ICASSP'91. Toronto. 
Bridging the Gap: Academic and Industrial Research in Dialog Technologies Workshop Proceedings, pages 68?75,
NAACL-HLT, Rochester, NY, April 2007. c?2007 Association for Computational Linguistics
Multi-slot semantics for natural-language call routing systems 
 
 
Johan Boye and Mats Wir?n  
TeliaSonera R&D 
Vitsandsgatan 9 
SE-123 86 Farsta, Sweden 
johan.boye@teliasonera.com, mats.wiren@teliasonera.com 
 
 
 
 
Abstract 
Statistical classification techniques for 
natural-language call routing systems 
have matured to the point where it is pos-
sible to distinguish between several hun-
dreds of semantic categories with an 
accuracy that is sufficient for commercial 
deployments. For category sets of this 
size, the problem of maintaining consis-
tency among manually tagged utterances 
becomes limiting, as lack of consistency 
in the training data will degrade perform-
ance of the classifier. It is thus essential 
that the set of categories be structured in a 
way that alleviates this problem, and en-
ables consistency to be preserved as the 
domain keeps changing. In this paper, we 
describe our experiences of using a two-
level multi-slot semantics as a way of 
meeting this problem. Furthermore, we 
explore the ramifications of the approach 
with respect to classification, evaluation 
and dialogue design for call routing sys-
tems. 
1 Introduction 
Call routing is the task of directing callers to a ser-
vice agent or a self-service that can provide the 
required assistance. To this end, touch-tone menus 
are used in many call centers, but such menus are 
notoriously difficult to navigate if the number of 
destinations is large, resulting in many misdirected 
calls and frustrated customers. Natural-language 
call routing provides an approach to come to terms 
with these problems. The caller gets the opportu-
nity to express her reasons for calling using her 
own words, whereupon the caller?s utterance is 
automatically categorized and routed. 
This paper focuses on experiences obtained 
from the deployment of a call-routing application 
developed for the TeliaSonera residential customer 
care.1 The application was launched in 2006, re-
placing a previous system based on touch-tone 
menus. The customer care annually handles some 
14 million requests and questions concerning a 
wide range of products in fixed telephony, mobile 
telephony, modem-connected Internet, broadband, 
IP telephony and digital TV.  
The crucial step in any call routing application is 
classification, that is, the mapping of natural-
language utterances to categories that correspond 
to routing destinations. Early systems used quite 
small numbers of categories. For example, the 
original ?How May I Help You? system had 15 
categories (Gorin et al 1997), the system of Chu-
Carroll and Carpenter (1999) had 23 categories, 
and Cox and Shahshahani (2001) had 32. Nowa-
days, it is possible to distinguish between several 
hundreds of categories with high accuracy (see, for 
example, Speech Technology Magazine 2004). 
The TeliaSonera system currently distinguishes 
between 123 categories with an accuracy of 85% 
(using a speech recognizer and classifier developed 
by Nuance2). Moreover, according to our experi-
ments the same classification technology can be 
                                                          
1
 TeliaSonera (www.teliasonera.com) is the largest telecom operator in the 
Nordic?Baltic region in Europe. 
2
  www.nuance.com.  
68
used to distinguish between 1,500 categories with 
80% accuracy.3 
For large category sets like these, the problem of 
maintaining consistency among manually tagged 
utterances becomes limiting, as lack of consistency 
in the training data will degrade performance of the 
classifier. The problem is exacerbated by the fact 
that call-routing domains are always in a state of 
flux: Self-services are being added, removed, 
modified, split and merged. Organizational 
changes and product development regularly call for 
redefinitions of human expertise areas. All of these 
changes must be accommodated in the category 
set. Hence, it must be possible to update this set 
efficiently and at short intervals. 
To meet this problem, it is crucial that the set of 
categories be structured in a way that facilitates the 
task of manual tagging and enables consistency to 
be preserved. However, in spite of the fact that the 
size of category sets for call routing have increased 
dramatically since the original ?How May I Help 
You? system, we are not aware of any papers that 
systematically discuss how such large sets should 
be structured in order to be efficiently maintain-
able. Rather, many papers in the call-routing litera-
ture consider the call routing problem as an 
abstract classification task with atomic categories 
at a single level of abstraction. Such atomic cate-
gories are typically taken to correspond to depart-
ments and self-services of the organization to 
which the call center belongs. In a real-life imple-
mentation, the situation is often more complicated. 
At TeliaSonera, we have adopted a two-level 
multi-slot semantics as a way of maintaining 
modularity and consistency of a large set of cate-
gories over time. 
The aim of this paper is to share our experiences 
of this by providing a detailed description of the 
approach and its implications for classification, 
dialogue design and evaluation. The rest of the pa-
per is organized as follows: Section 2 describes the 
multi-slot category system. Sections 3?5 outline 
consequences of the multi-slot semantics for dis-
ambiguation, classification and evaluation, respec-
tively. Section 6 concludes. 
 
 
 
                                                          
3
 In both cases, the classifier was trained on 60,000 utterances. 
2 What?s in a category? 
2.1 Motivation 
As pointed out above, call-routing domains are 
always to some extent moving targets because of 
constant changes with respect to products and or-
ganization. It would be cumbersome to manually 
re-tag old data each time the category set is up-
dated. Retagging the training data for the statistical 
classifier might introduce inconsistencies into the 
training set and degrade classifier performance. 
Thus, it is a good idea to define two sets of catego-
ries at different levels; one set of semantic catego-
ries reflecting the contents of the utterance, and 
one set of application categories reflecting how the 
call should be handled. These two sets of catego-
ries are related by means of a many-to-one map-
ping from the semantic domain to the application 
domain. Figure 1 gives the general picture. 
 
 
 
Figure 1: Mapping between semantic categories and 
application categories. 
 
The utterances in the training set for the auto-
matic classifier are manually categorized using 
semantic categories. The automatic classifier can 
be trained to work either in the semantic domain or 
in the application domain (see further Section 4). 
 
 
Semantic categories Application categories 
69
2.2 Semantic categories 
In the TeliaSonera system, semantic categories are 
triples of the form 
 
( family, intention, object ) 
 
where family is the general product family which 
the call concerns (e.g. fixed telephony, mobile te-
lephony, broadband, etc.), intention represents the 
nature of the request (e.g. order, want-info, 
change-info, activate, want-support, report-error, 
etc.), and object represents more specifically what 
the call is about (e.g. particular names of products, 
or concepts like ?telephone number?, ?SIM card?, 
or ?password?). Currently there are 10 families, 
about 30 intentions, and about 170 objects that 
span the semantic domain.  
Some (in fact, the majority) of the possible tri-
ples are disallowed because they are nonsensical. 
For instance, it is not meaningful to combine 
?fixed telephony? in the family slot with ?SIM 
card? in the object slot. To cater for this, we have 
defined a set of combination rules weeding out the 
illegal combinations of values. These rules disal-
low about 80% of the possible combinations, leav-
ing about 10,000 permissible semantic triples. Of 
these 10,000 triples, about 1,500 have actually 
turned up in real data.  
The three-slot structure of categories is very use-
ful when performing manual tagging of the train-
ing material for the statistical classifier. Although 
there are 10,000 categories, the person performing 
the tagging needs only to keep track of about 210 
concepts (10 families + 30 intentions + 170 ob-
jects). In contrast, it is safe to say that an unstruc-
tured category system containing 10,000 atomic 
categories would be quite impractical to use.  
In addition, the combination rules can further al-
leviate the manual tagging task. It is straightfor-
ward to implement a tagging tool that allows the 
human tagger to select a value for one semantic 
slot, and then restrict the selection for the other 
slots only to include the possible values. For ex-
ample, if ?fixed telephony? is chosen for the family 
slot, ?SIM card? would not appear among the pos-
sible values for the object slot. This approach has 
been successfully adopted in the project. 
 
 
2.3 Application categories 
There is one application category for each type of 
action from the system. Actions come in two fla-
vors; either the call is routed (in the cases where 
the caller has given sufficient information), or the 
system asks a counter-question in order to extract 
more information from the caller. That is, applica-
tion categories can be labeled either as routing 
categories or disambiguation categories. For con-
venience, names of application categories are also 
triples, chosen among the set of semantic triples 
that map to that application category.  
2.4 Information ordering 
Each slot in a semantic triple can take the value 
unknown, representing the absence of information. 
For instance, the most accurate semantic category 
for the caller utterance ?Broadband?4 is (broad-
band, unknown, unknown), since nothing is known 
about the intention of the caller or the specific 
topic of the request. Thus, in the information order-
ing, ?unknown? is situated below all other values.  
There are also some intermediate values in the 
information ordering. The value telephony repre-
sents ?either fixed telephony or mobile telephony?, 
and has been incorporated in the category set since 
many callers tend not be explicit about this point. 
In the same vein, internet represents ?either broad-
band or modem-connected internet?, and billing 
represents the disjunction of a whole range of bill-
ing objects, some of which can be handled by a 
self-service and some can not. 
 
 
 
 
Figure 2: Parts of the semantic information ordering. 
 
 
The information ordering extends naturally to 
triples. In particular, the triple (unknown, unknown, 
                                                          
4
 Many callers express themselves in this telegraphic fashion. 
unknown 
telephony internet 
modemConnected broadband fixed mobile 
70
unknown) represents complete absence of informa-
tion. 
3 Disambiguation 
The caller?s request might be ambiguous in one 
sense or another, in which case the system will 
need to perform disambiguation by asking a fol-
low-up question. This might either be a general 
question encouraging the user to describe his re-
quest in greater detail, or a directed question of the 
type ?Would that be fixed telephony or mobile te-
lephony?? 
Ambiguous utterances might be represented in 
at least two fundamentally different ways. In vec-
tor-based approaches, routing destinations and in-
put utterances alike are represented by vectors in a 
multi-dimensional space. An input utterance is 
routed to a specific destination if the vector repre-
sentation of the utterance is close to that of the des-
tination. An ambiguous utterance is characterized 
by the fact that the Euclidean distances from the 
utterance vector to the n closest routing destination 
vectors are roughly the same.  
Chu-Carroll and Carpenter (1999) describe a 
method of disambiguation, where disambiguation 
questions are dynamically constructed on the basis 
of an analysis of the differences among the closest 
routing destination vectors. However, it is not clear 
that the disambiguation questions produced by 
their proposed method would make sense in all 
possible situations. Furthermore, their method does 
not take into account the fact that some ambiguities 
tend to be more important and arise more often 
than others. We think it is worthwhile to concen-
trate on these important cases (in terms of prompt 
design, speech recognition grammar construction, 
etc.), rather than trying to solve every conceivable 
ambiguity, most of which would never appear in 
real life.  
As previously mentioned, in the TeliaSonera 
system we have chosen another way of treating 
ambiguities, namely that certain application cate-
gories are disambiguation categories; they repre-
sent foreseen, frequently occurring, ambiguous 
input utterances. The three-slot structure of catego-
ries provides a handy way of identifying ambigu-
ous cases; they are represented by triples where 
one or more slots are unknown, or where some slot 
has an intermediate value, like telephony or inter-
net. Examples of such ambiguous utterances are 
?broadband? (broadband-unknown-unknown) and 
?I want to have a telephone subscription? (teleph-
ony-order-subscription). All categories that repre-
sent ambiguities have pre-prepared disambiguation 
questions, speech recognition grammars, and dia-
logue logic to handle the replies from the callers. 
Of course, there are still problematic cases 
where an utterance can not be assigned any unique 
category with any tolerable level of confidence, 
neither a routing category nor a disambiguation 
category. In those cases, the system simply re-
phrases the question: ?Sorry, I didn?t quite under-
stand that. Could you please rephrase??  
4 Classification 
4.1 Atomic vs. multi-slot classification 
For the purpose of automatic classification of ut-
terances, there are at least two different views one 
may adopt. In one view, the ?atomic? view, the 
three-slot structure of category names is considered 
as merely a linguistic convention, convenient only 
when manually tagging utterances (as discussed in 
Section 2.1). When adopting this view, we still 
regard the categories to be distinct atomic entities 
as concerns automatic classification. For instance, 
to the human eye it is obvious that two categories 
like (internet, order, subscription) and (broadband, 
order, subscription) are related, but the automatic 
classifier just considers them to be any two catego-
ries, each with its separate set of training examples.  
An alternative view, the ?multi-slot view?, is to 
see the category as actually consisting of three 
slots, each of which should be assigned a value 
independently. This means that a separate classifier 
is needed for each of the three slots. 
It is not clear which view is preferable. An ar-
gument in favor of the multi-slot view is the fol-
lowing: If some categories have the same value in 
one slot, then these categories are semantically 
related in some way. Most likely this semantic re-
lation is reflected by the use of common words and 
phrases; for instance, expressions like ?order? and 
?get a new? presumably are indicative for all cate-
gories having the value order in the intention slot. 
Therefore, classifying each slot separately would 
be a way to take a priori semantic knowledge into 
account.  
  To this, proponents of the atomic view may re-
spond that such similarities between categories 
71
would emerge anyway when using a single classi-
fier that decides the entire semantic triple in one go 
(provided that enough training data is available). In 
addition, if each slot is categorized separately, it is 
not certain that the resulting three values would 
constitute a permissible semantic triple (as men-
tioned in Section 2.1, about 80% of the possible 
combinations are illegal). In contrast, if a single 
classifier is used, the result will always be a legal 
triple, since only legal triples appear in the training 
material. 
The statistical classifier actually used in the live 
call routing system treats categories as atomic enti-
ties and, as mentioned in the introduction, it works 
well. The encouraging numbers bear out that the 
?atomic? view is viable when lots of data is at 
hand. On the other hand, if training data is sparse, 
one might consider using a hand-written, rule-
based classifier, and in these cases the multi-slot 
view seems more natural.  
4.2 Rule-based multi-slot classification 
To obtain a baseline for the performance of the 
statistical classifier used in the live system, we im-
plemented an alternative classifier that solves the 
classification task using hand-written rules. Thus, 
the purpose of this was to investigate the perform-
ance of a na?ve classification method, and use that 
for comparison with other methods. In addition, 
the rule-based classifier provides an example of 
how the multi-slot approach can support the inclu-
sion of human a priori domain knowledge into the 
classification process. 
The rule-based classifier has three kinds of 
rules: Firstly, phrase-spotting rules associate a 
word or a phrase with a value for a semantic slot 
(i.e. a family, an intention, or an object). Rules of 
the second kind are domain axioms that encode 
invariant relationships, such as the fact that ob-
ject=SIMcard implies family=mobileTelephony. 
Finally, rules of the third kind specify how seman-
tic values can be combined into a legal semantic 
triple (these rules are also used for manual tagging, 
as mentioned in Section 2.1). Each semantic value 
is also (manually) given a score that reflects its 
information content; a higher score means that the 
value contains more information. For instance, the 
value subscription has a lower information score 
than have the names of specific subscription types 
that TeliaSonera offers its customers.  
The classifier works in three phases, which we 
will demonstrate on a running example. In the first 
phase, it applies the phrase-spotting rules to the 
input sentence, returning a list of slot-value pairs. 
For instance, the input sentence ?I want to order a 
new SIM card? would yield the list [ inten-
tion=order, object=SIMcard ], using rules trigger-
ing on the phrases ?order? and ?SIM card? in the 
input sentence.  
Secondly, the classifier adds semantic compo-
nents as a result of applying the domain axioms to 
members of the list. Using the domain axiom men-
tioned above, the semantic component fam-
ily=mobileTelephony would be added to the list, 
due to the presence of object=SIMcard. Thus, after 
the two first phases, the intermediate result in this 
example is [intention=order, object=SIMcard,  
family=mobileTelephony]. 
In the final phase, semantic components are se-
lected from the list to form a semantic triple. In the 
example, this step is straightforward since the list 
contains exactly one value for each component, 
and these values are combinable according to the 
combination rules. The final result is: 
 
( mobileTelephony, order, SIMcard ) 
 
In cases where the semantic values in the list are 
not combinable (a situation often originating from 
a speech recognition error), one or several values 
have got to be relaxed to unknown. According to 
our experiments, the best heuristic is to first relax 
the object component and then the intention com-
ponent. For example, in the list [family = fixed-
Telephony, intention=order, object=SIMcard], the 
first and third elements are not combinable; thus 
this list yields the triple: 
 
( fixedTelephony, order, unknown ) 
 
In the case where some slots are not filled in 
with a value, the values of those slots are set to 
unknown.  Thus, the list [ family=fixedTelephony, 
intention=order ] would also yield the semantic 
triple above. 
 Finally, consider the case where the input list 
contains more than one value for one or several 
slots. In this case, the algorithm picks the value 
with the highest information content score. For 
instance, consider the utterance ?I want to have a 
broadband subscription, this eh ADSL I?ve read 
72
about?. After the first two phases, the algorithm 
has found family=broadband, intention=order, 
and two possible values for the object slot, namely 
object=subscription and object=ADSL. Since the 
latter has higher information score, the final result 
is: 
 
( broadband, order, ADSL ) 
 
The rule-based classifier was developed in about 
five man-weeks, and contains some 3,000 hand-
written rules. When evaluated on a set of 2,300 
utterances, it classified 67% of the utterances cor-
rectly. Thus, not surprisingly, its performance is 
significantly below the statistical classifier used in 
the deployed system. Still, the rule-based approach 
might be a viable alternative in less complex do-
mains. It might also be usable for data collection 
purposes in early prototypes of natural-language 
call routing systems. 
5 Evaluation of call-routing dialogues 
5.1 Motivation 
An important issue in the development of any dia-
logue system is the selection of an evaluation met-
ric to quantify performance improvements. In the 
call-routing area, there have been many technical 
papers specifically comparing the performance of 
classifiers, using standard metrics such as accuracy 
of the semantic categories obtained over a test cor-
pus (see e.g. Kuo and Lee, 2000, and Sarikaya et 
al., 2005). Accuracy is then stated as a percentage 
figure showing the degree of the categories that 
have been completely correctly classified, given 
that categories are atomic. There have also been 
some design-oriented papers that try to assess the 
effects of different prompt styles by looking at the 
proportion of routable versus unroutable calls 
given callers? first utterances. Thus, both of these 
strands of work base their evaluations on binary 
divisions between correct/incorrect and rout-
able/unroutable, respectively. Furthermore, they 
both constitute utterance-based metrics in the sense 
that they focus on the outcome of a single system?
caller turn. 
An excellent example of a design-oriented call-
routing paper is Williams and Witt (2004), which 
among other things compares open and directed 
prompt styles in the initial turn of the dialogue. 
Williams and Witt divide callers? responses into 
Routable (if the utterance contained sufficient in-
formation for the call to be routed) or Failure (if 
the utterance did not contain sufficient information 
for routing). Depending on why a call is not rout-
able, Williams and Witt further subdivide instances 
of Failure into three cases: Confusion (utterances 
such as ?Hello?? and ?Is this a real person??), 
Agent (the caller requests to speak to a human 
agent), and Unroutable (which corresponds to ut-
terances that need disambiguation). Thus, Williams 
and Witt?s performance metric uses altogether four 
labels. (In addition, they have three labels related 
to non-speech events: silence, DTMF and hang-up. 
Since such events are not handled by the classifier, 
they fall outside of the scope of this paper.) 
Although all of Williams? and Witt?s measures 
are needed in evaluating call-routing dialogue, the 
field clearly needs more in-depth evaluation. In 
particular, we need more fine-grained metrics in 
order to probe more exactly to what extent Failure 
actually means that the dialogue is off track. Fur-
thermore, given that call-routing dialogues typi-
cally consist of between one and (say) five turns, 
we need not just utterance-based metrics, but also 
dialogue-based metrics ? in other words, being 
able to evaluate the efficiency of an overall dia-
logue. 
5.2 Utterance-based metrics 
When assessing the performance of classification 
methods, it is perfectly reasonable to use the binary 
distinction correct/incorrect if only few categories 
are used. In such a context it can be assumed that 
different categories correspond to different de-
partments of the organization, and that a misclassi-
fication would lead the call being routed the wrong 
way. However, with a richer category system, it is 
important to realize that the classifier can be par-
tially correct. For instance, if the caller expresses 
that he wants technical support for his broadband 
connection, then the information that the purpose 
of the call has something to do with broadband is 
surely better than no information at all. If the sys-
tem obtains this information, it could ask a directed 
follow-up question: OK broadband. Please tell me 
if your call concerns an order, billing, deliveries, 
support, error report, or something else, or some-
thing to that effect. Otherwise, the system can only 
restate the original question. 
73
In the field of task-oriented dialogue, several 
evaluation metrics have been put forward that go 
beyond a simple division into correct/incorrect. In 
particular, concept accuracy (Boros et al 1996) is 
an attempt to find a semantic analogue of word 
accuracy as used in speech recognition. Basically, 
the idea is to compute the degree of correctness of 
a semantic analysis based on a division of the rep-
resentation into subunits, and by taking into ac-
count insertions, deletions and replacements of 
these subunits. 
Making use of our multi-slot semantics, we can 
take subunits to correspond to semantic slot values. 
An insertion has occurred if the classifier spuri-
ously has added information to some slot value 
(e.g. if the classifier outputs the value broadband 
for the family slot, when the correct value is inter-
net or unknown). Conversely, a deletion has oc-
curred when semantic triple output from the 
classifier contains a slot value which is situated 
lower than the correct value in the information or-
dering (a part of which is depicted in Figure 2). 
Finally, a replacement has occurred when the com-
puted slot value and the correct slot value are unre-
lated in the information ordering. 
By using concept accuracy as an evaluation met-
ric for classifiers rather than the binary distinction 
correct/incorrect, we can arrive at more informa-
tive assessments. This possibility is brought about 
by the multi-slot structure of categories.  
5.3 Dialogue-based metrics 
In the literature, there have also been proposals for 
dialogue-based metrics. In particular, Glass et al 
(2000) put forward two such metrics, query density 
(QD) and concept efficiency (CE). Query density is 
the mean number of new ?concepts? introduced 
per user query, assuming that each concept corre-
sponds to a slot?filler pair in the representation of 
the query. For example, a request such as ?I?d like 
a flight from Stockholm to Madrid on Sunday af-
ternoon? would introduce three new concepts, cor-
responding to departure, destination and time. 
Query density thus measures the rate at which the 
user communicates content. In contrast, concept 
efficiency measures the average number of turns it 
takes for a concept to be successfully understood 
by the system. Concept efficiency thus measures 
the rate at which the system understands content.  
Using the multi-slot semantics, we can adapt the 
notions of query density and concept efficiency in 
order to arrive at a more fine-grained performance 
metric for call routing. The basic idea is to regard 
every element in the semantic triple as one ?con-
cept?. We can then obtain a measure of how in-
formation increases in the dialogue by computing 
the difference between triples in each user utter-
ance, where ?difference? means that the values of 
two corresponding elements are not equal. 
An example of computing query density is given 
below. We assume that the value of the semantic 
triple is initially (unknown, unknown, unknown). 
 
System: Welcome to TeliaSonera. How may I help 
you? 
Caller: Fixed telephony. 
 (fixedTelephony, unknown, unknown) 
1 new concept 
System: Could you tell me some more about what 
you want to do? 
Caller: I can?t use my broadband while I?m speak-
ing on the phone.(broadband, reportProb-
lem, lineOrPhone) 
3 new concepts 
 
Note that query density and concept efficiency 
are both applicable on a per-utterance basis as well 
as on the whole dialogue (or indeed arbitrary 
stretches of the dialogue). To compute these meas-
ures for the whole dialogue, we simply compute 
the mean number of new concepts introduced per 
user utterance and the average number of turns it 
takes for a concept to be successfully understood, 
respectively. 
The principal application of this methodology is 
to measure the effectiveness of system utterances. 
When using a fine-grained system of categories, it 
is important that callers express themselves at a 
suitable level of detail. Too verbose user utterances 
are usually difficult to analyse, but too telegraphic 
user utterances are not good either, as they most 
often do not contain enough information to route 
the call directly. Therefore it is very important to 
design system utterances so as to make users give 
suitably expressive descriptions of their reasons for 
calling.  
By using the query density metric it is possible 
to asses the effectiveness (in the above sense) of 
different alternative system utterances at various 
points in the dialogue, most notably the first sys-
74
tem utterance. Again, this possibility is brought 
about by the multi-slot structure of categories. It is 
also possible to evaluate more general dialogue 
strategies over longer stretches of dialogue (e.g. 
the use of general follow-up questions like ?Could  
you please tell me some more about what you want 
to do? as opposed to more directed questions like 
?Please tell me if your call concerns an order, bill-
ing, deliveries, support, error report, or something 
else?). By calculating the average query density 
over a number of consecutive utterances, it is pos-
sible to compare the relative merits of different 
such dialogue strategies. 
We have not yet adopted this metric for evalua-
tion of dialogues from the live system. However, 
elsewhere we have applied it to dialogues from the 
initial Wizard-of-Oz data collection for the Telia-
Sonera call routing system (Wir?n et al 2007). 
Here, we used it to compare two styles of disam-
biguation prompts, one completely open and one 
more directed. 
6 Concluding remarks 
In the literature, the natural-language call routing 
problem is often presented as the problem of clas-
sifying spoken utterances according to a set of 
atomic categories. The hypothesis underlying this 
paper is that this view is inadequate, and that there 
is a need for a more structured semantics. We base 
our claims on experiences gathered from the de-
velopment and deployment of the TeliaSonera call 
center, for which we developed a multi-slot system 
of categories. 
A multi-slot semantics offers several advan-
tages. First of all, it makes the set of categories 
manageable for human taggers, and provides a 
means to break down the tagging task into sub-
tasks. Furthermore, we have shown how multi-slot 
semantics for call-routing systems allows straight-
forward division of categories into routing catego-
ries and disambiguation categories, the possibility 
of multi-slot categorization, and the use of more 
fine-grained evaluation metrics like concept accu-
racy and query density. 
Acknowledgements 
This work has benefited greatly from discussions 
on category systems and classification with Marco 
Petroni, Linda Brostr?m, Per-Olof G?llstedt, Alf 
Bergstrand and Erik Demmelmaier, and we thank 
them all. We would also like to thank Robert 
Sandberg and Erik N?slund for their support of this 
work. 
References  
Boros, M., Eckert, W., Gallwitz, F., G?rz, G., Han-
rieder, G. and Niemann, H. (1996). Towards under-
standing spontaneous speech: Word accuracy vs. 
concept accuracy. Proc. Fourth International Con-
ference on Spoken Language Processing (ICSLP), 
pp. 1009?1012.  
Chu-Carroll, J. and Carpenter, B. (1999) Vector-based 
natural language call routing. Computational linguis-
tics, 25(3), pp. 361-388. 
Cox, S. and Shahshahani, B. (2001). A comparison of 
some different techniques for vector based call-
routing. Proc. Eurospeech, Aalborg, Denmark. 
Glass, J., Polifroni, J., Seneff, S. and Zue, V. Data col-
lection and performance evaluation of spoken dia-
logue systems: The MIT experience. In Proc. Sixth 
International Conference on Spoken Language Proc-
essing (ICSLP), Beijing, China. 
Gorin, A., Riccardi, G., and Wright, J. (1997) How may 
I help you?. Journal of Speech Communication, 23, 
pp. 113-127. 
Kuo, H-K J. and Lee, C-H. (2000)  Discriminative train-
ing in natural language call routing. Proc. Sixth In-
ternational Conference on Spoken Language 
Processing (ICSLP), Beijing, China. 
Sarikaya, R, Kuo, H-K J., Goel, V. and Gao, Y. (2005) 
Exploiting unlabeled data using multiple classifiers 
for improved natural language call-routing. Proc. In-
terspeech, Lisbon, Portugal. 
Speech Technology Magazine (2004) Q&A with Bell 
Canada?s Belinda Banks, senior associate director, 
customer care. Speech Technology Magazine, vol 9, 
no 3.  
Williams, Jason D. and Witt, Silke M. (2004). A com-
parison of dialog strategies for call routing. Interna-
tional Journal of Speech Technology 7(1), pp. 9?24. 
Wir?n, M., Eklund, R., Engberg, F. and Westermark, J. 
(2007). Experiences of an in-service Wizard-of-Oz 
data collection for the deployment of a call-routing 
application. Proc. Bridging the gap: Academic and 
industrial research in dialog technology. NAACL 
workshop, Rochester, New York, USA. 
 
 
75
 
	ffPlug and Play Speech Understanding
Manny Rayner, Ian Lewin
& Genevieve Gorrell
netdecisions Ltd
Wellington House,
East Road, Cambridge CB1 1BH, UK
manny.raynerjian.lewinjgenevieve.gorrell
@netdecisions.com
Johan Boye
Telia Research
S-123 86 Farsta, Sweden
johan.boye@trab.se
Abstract
Plug and Play is an increasingly im-
portant concept in system and network
architectures. We introduce and de-
scribe a spoken language dialogue sys-
tem architecture which supports Plug
and Playable networks of objects in its
domain. Each device in the network car-
ries the linguistic and dialogue manage-
ment information which is pertinent to it
and uploads it dynamically to the rele-
vant language processing components in
the spoken language interface. We de-
scribe the current state of our plug and
play demonstrator and discuss theoreti-
cal issues that arise from our work. Plug
and Play forms a central topic for the
DHomme project.
1 Introduction
The notion of Plug and Play nds its most natu-
ral home in the world of networked home devices,
where it oers at least the following two important
properties
 the network of devices is dynamically recon-
gurable as devices are brought online or dis-
appear oine
 zero re-conguration by the user is required
Frameworks for achieving Plug and Play gener-
ally address this by including at least the following
 devices announce themselves on the network
when they are plugged into it (and also dis-
cover the existence of others)
 devices describe their own capabilities, pro-
vide a means for accessing them and can
query and access the capabilities of others
 devices should support, where possible, seam-
less interaction with other devices.
Plug and Play is, not surprisingly, viewed as
a pre-requisite for the commercial success of net-
worked devices in the home. There are already
several promising candidate platforms for achiev-
ing the necessary functionality, including Univer-
sal Plug and Play (UPnP) (Microsoft, 2000) and
Jini (Oaks and Wong, 2000). In this paper, we
address the requirements on spoken dialogue in-
terfaces that arise from a plug and play domain.
We also present the current state of our English
language plug and play demonstrator for control-
ling lamps, dimmers and sensors, previously de-
scribed in (Rayner et al, 2001b). (There is also a
Swedish instantiation).
First, however, we need briey to distinguish
our notion from other notions of plug and play
and recongurability.
The notion of Plug and Play has been used
for dialogue system toolkits in which the various
dierent language processing components them-
selves (e.g. recognition, parsing, generation and
dialogue management) can be plugged in and
out. The most prominent instance of this is
the Darpa Communicator architecture (Goldschen
and Loehr, 1999), which denes interoperability
standards for language processing components.
The intention is simply that researchers and de-
velopers can experiment with systems containing
dierent instantiations of the language process-
ing components. The Communicator Architec-
ture is not designed to address the special require-
ments of a plug and play domain. In fact, the
Communicator architecture does not support the
dynamic re-conguration of language processing
components while the system is running.
At a more general level, simple re-conguration
of spoken language dialogue systems has of course
long been a goal of language engineering. But
such re-conguration is nearly always viewed as
the problem of cross-domain or possibly cross-
language porting, e.g. (Glass, 1999). Once one
has a cinema ticket booking service, for example,
one may examine the eort required for book-
ing train tickets, or for e-shopping in general or
even the \database access" scenario. There are
various toolkits, architectures and methodologies
for rapidly and/or semi-expertly generating new
instances of dialogue systems, e.g. by abstract-
ing away from domain or application dependent
features of particular systems, e.g. (Fraser and
Thornton, 1995; Kolzer, 1999), or `bottom-up' by
aggregation of useful re-congurable components
, e.g. (Sutton et al 1998; Larsson and Traum,
2000). The automated within-domain recongu-
ration required for a plug and play domain, has
not, to our knowledge, been described previously.
Pursuit of plug and play functionality (and its
realization in strong and weak forms - discussed in
section 3) forms a central theme of the DHomme
project.
1
In the rest of this paper, we begin by detail-
ing our concrete Plug and Play scenario - device
control in the home - with an example dialogue
from our demonstrator and an outline of the main
dialogue processing elements. In section 3, we dis-
tinguish strong and weak notions of Plug and Play
and their applicability to spoken language inter-
faces. In section 4, we discuss the strong plug
and play capability we have built into the recogni-
tion, parsing and (context independent) semantic
interpretation system components of our demon-
strator. In section 5, we discuss some future work
for Plug and Play dialogue management. Section
6 contains our conclusions.
2 A Plug and Play Scenario
In this section we present example dialogues from
our current demonstrator and briey outline the
main processing elements. The domain is net-
worked home devices, an area where plug and play
is already in a reasonably advanced state of devel-
opment and speech control looks highly attractive.
2.1 Plug and Play Examples
Figure 1 displays an example dialogue from our
current demonstrator.
In U1, the user asks for the TV to be switched
on. The system reports (S1) that it simply does
not understand the user. (If it possessed \TV"
in its recognition vocabulary and knew something
about the concept of TVs it could have reported
I don't know of any TV). When a TV is plugged
into the network (following U2), the system is able
to understand, and act on the user's repeated re-
quest to switch on the TV. The system reports on
1
This work is supported by EU 5th Framework
project IST-2000-26280 { see Acknowledgments
its action (S3). S4 illustrates another type of \er-
ror" message. When another TV is plugged into
the network, the system must now engage in dis-
ambiguation behaviour whereas previously it had
no need to (S7).
S10 illustrates that, in the absence of dimmable
lights, \Dim" is not understood, and, possibly,
not even recognized. When a dimmable light is
plugged in (or, at least, knowledge of dimmable
lights is plugged in), then a more helpful error
message can be given in S12. Finally, when the
grammar is increased to cover new commands, the
system may begin to make mistakes that it did not
make originally (S13).
2.2 The current demonstrator
Our demonstrator expects devices of three main
types: switchable, dimmable and sensors. Switch-
able devices are binary state devices that can be
set or queried. Dimmable devices have a state
varying on a single scalar dimension which can be
set, changed, or queried. Sensors are similar but
can only be queried.
Formally, these commands and queries are en-
coded by a 4-ary slot-value structure and De-
vice Grammars must generate semantic values
containing these slots. (Not all slots are re-
quired for every utterance, of course.) The
four slots are: op (lled by command or query);
level; change and dir (on or o). In or-
der to identify devices, there are 4 other slots:
device (light, tv . . . ), loc (bathroom, kitchen . . . ),
device-spec (all, the . . . ) and pronoun (it, them
. . . ). For example, Is the light in the hall on?
translates to h op=query dir=on device=light
device-spec=the loc=hall i. Dim everything by
ten percent translates to h op=command dir=o
device-spec=everything change=10 i. Switch
the hall and kitchen lights o translates to h
op=command dir=o level=0 device=light h
loc=kitchen loc=hall ii.
Dialogue interpretation contains three stages.
First, conjunctions in the input (which are treated
as just packed representations) are unpacked into
a set of (7-ary) slot-structures. Secondly, a form of
ellipsis resolution, \sticky defaults", takes place in
which missing slots are lled in from their previ-
ous values. A fragmentary semantic value is sim-
ply pasted over the corresponding parts of the last
one. Thus And in the bathroom translates to h
loc=bathroomi but the other required slots (e.g.
device) are supplied from the previous represen-
tation. Finally reference resolution tries to deter-
mine device identiers for pronouns and denitely
described devices. Currently, devices are identi-
ed only by their location and type so a simple
matching procedure can be used.
Following contextual interpretation, either a
program (a command or sequence of such) or an
`error' condition (e.g. resolution failed to identify
a device) will have been generated. The system
must then execute the program and/or generate
feedback. Knowledge of how to execute these pro-
grams, e.g. that it is an `error' to try to switch on
a light that is already on, and possible feedback
messages are simply hardcoded into the Dialogue
Manager. There is a pre-dened set of feedback
message structures associated with each underly-
ing action and their possible results. Some exam-
ple paraphrases of message structures are \The X
is now on", \The X is already on", \The X is now
at Y percent", \There is no X in the Y".
3 Strong and Weak Plug and Play
In its weakest form, Plug and Play refers only to
the ability to add a device to a network with-
out manual conguration. Knowledge distribu-
tion is not included. Standard Plug and Play for
PC peripherals simply automates the matching up
of physical devices with software device-specic
drivers in the PC. Communication links between
them are established by reserving resources such
as shared memory and interrupt request numbers.
The weak sense is very useful. Users need not
congure their hardware via jumper switches or
software drivers by entering `magic' numbers in
conguration les.
In the strong sense, Plug and Play can refer
also to modular, distributed knowledge. Devices
not only set up network communications but pub-
lish information about themselves over it. Other
devices can obtain and use it. In Jini, for exam-
ple, a new printer device can register its printing
service (and java code for invoking methods on it)
on the network. Then, a word-processing applica-
tion can nd it and congure itself to use it. In
UPnP, devices publish XML descriptions of their
interfaces.
The strong-weak contrast is not a sharp or bi-
nary one. The word-processor might know the
industry agreed printer interface and so display
a greyed-out print button if no printer is net-
worked. When a new type of printer is net-
worked, it might supply additional print options
(e.g. \print colour") that the processor knows
nothing about.
One desirable Plug and Play property in both
strong and weak forms is commutativity, i.e. the
system understands the same commands in the
same way no matter which device is connected
rst. It is less obvious whether disconnecting de-
vice X should be the inverse operation of connect-
ing device X. This seems reasonable in a weak plug
and play system, but in the strong case it would
mean that the recognizer would cease to under-
stand the word \TV" as soon as the TV were dis-
connected. This might be confusing for the user.
The strong and weak senses of plug and play
apply to spoken language dialogue interfaces. In
the weakest sense, the dialogue system might be
entirely pre-congured to deal with all possible
devices and device-combinations. The required
knowledge is already present in the network. Plug
and Play then consists of identifying which partic-
ular devices are currently networked and estab-
lishing communication channels with them. In
the stronger sense, the components of the spoken
language dialogue interface acquire the knowledge
pertinent to particular devices from those devices.
So, as in example S1 above, the speech recognizer
may not have the word \TV" in its vocabulary
until a TV is plugged into the network. The di-
alogue manager may not be capable of uttering
\That device is not dimmable" until a dimmable
device is plugged into the network. A strongly
Plug and Play system may therefore be distin-
guishable from a weaker one by its behaviour in
the absence of certain device specic knowledge.
If the relevant knowledge is present, one cannot be
certain whether it was pre-congured or uploaded
\on demand".
Plug and Play also enforces a certain sort of
modularity on the system. Since devices must de-
clare the information required to update the dia-
logue components, a clear interface is provided for
re-conguring the system for new types of device
as well as a clearer picture of the internal structure
of those dialogue components. Indeed, it is really
just a design choice whether device knowledge is in
fact installed only when the device is plugged in.
One may, for example, choose to optimize recog-
nition performance on the set of devices actually
installed by not loading information about other
devices. Alternatively, one might prefer to rec-
ognize the names of devices not installed so that
helpful error messages can be delivered.
Potentially, each component in a spoken lan-
guage interface (recognizer, parser, interpreter, di-
alogue manager etc.) can be updated by informa-
tion from a device in a Plug and Play domain. Dif-
ferent components might support dierent degrees
of strength of the Plug and Play notion. Further-
more, dierent instantiations of these components
may require very dierent sorts of update. To
take a very simple example, if recognition is car-
ried out by a statistically trained language model,
then updating this with information pertinent to a
particular device will evidently be a signicantly
dierent task from updating a recognizer which
uses a grammar-based language model.
Our current demonstrator program instantiates
a Plug and Play capability for recognition, parsing
and context independent semantic analysis and is
built on top of the Nuance toolkit (Nuance Com-
munications, 1999). The next section discusses
the capability in detail. Section 5 discusses and
makes some proposals for Plug and Play Dialogue
Management.
4 Distributed Grammar
4.1 Introduction
In this section, we will describe how we have ad-
dressed the issues that arise when we attempt to
apply the (strong) Plug and Play scenario to the
tasks of speech recognition and language process-
ing. Each device will provide the knowledge that
the speech interface needs in order to recognise the
new types of utterance relevant to the device in
question, and convert these utterances into well-
formed semantic representations.
Let's start by considering what this means in
practice. There are in fact a whole range of pos-
sible scenarios to consider, depending on how the
speech understanding module is congured. If the
module's construction is simple enough, there may
be no signicant problems involved in extending
it to oer Plug and Play functionality. For ex-
ample, the command vocabulary oered by the
speech interface may just consist of a list of xed
phrases. In this case, Plug and Play speech recog-
nition becomes trivial: each device contributes the
phrases it needs, after which they can be com-
bined into a single grammar. An approach of
this kind fails however to scale up to an interface
which supports complex commands, in particular
commands which combine within the same utter-
ance language referring to two or more dierent
devices. For example, a command may address
several devices at once (\turn on the radio and the
living room light"); alternately, several commands
may be combined into a single utterance (\switch
on the cooker and switch o the microwave"). Our
experience with practical spoken device interfaces
suggests that examples like these are by no means
uncommon.
Another architecture relatively easy to com-
bine with Plug and Play is doing recognition
through a general large-vocabulary recogniser,
and language-processing through device-specic
phrase-spotting (Milward, 2000). The recogniser
stays the same irrespective of how many devices
are connected, so there are by denition no prob-
lems at the level of speech recognition, and it is in
principle possible to support complex commands.
The main drawback, however, is that recognition
quality is markedly inferior compared to a system
in which recognition coverage is limited to the do-
main dened by the current set of devices.
Modern speech interfaces supporting complex
commands are typically specied using a rule-
based grammar formalism dened by a platform
like Nuance (Nuance Communications, 1999) or
SpeechWorks (Inc, 2001). The type of grammar
supported is some subset of full CFG, extended to
include semantic annotations. Grammar rules de-
ne the language model that constrains the recog-
nition process, tuning it to the domain in order to
achieve high performance. (They also supply the
semantic rules that dene the output representa-
tion; we will return to this point later). If we want
to implement an ambitious Plug and Play speech
recognition module within this kind of framework,
we have two top-level goals. On the one hand, we
want to achieve high-quality speech recognition.
At the same time, standard software engineering
considerations suggest that we want to minimize
the overlap between the rule-sets contributed by
each device: ideally, the device will only upload
the specic lexical items relevant to it.
It turns out that our software engineering ob-
jectives conict to some extent with our initial
goal of achieving high-quality speech recognition.
Consider a straightforward solution, in which the
grammatical information contributed by each de-
vice consists purely of lexical entries, i.e. entries
of the form
<Nonterminal> --> <Terminal>
In a CFG-based framework, this implies that we
have a central device-independent CFG grammar,
which denes the other rules which link together
the nonterminals that appear on the left-hand-
sides of the lexical rules. The crucial question is
what these lexical non-terminal symbols will be.
Suppose, for concreteness, that we want our set
of devices to include lights with dimmer switches,
which will among other things accept commands
like \dim the light". We might achieve this by
making the device upload lexical rules of the rough
form
TRANSITIVE_VERB --> dim
NOUN --> light
where the LHSs are conventional grammatical cat-
egories. (We will for the moment skip over the
question of how to represent semantics). The lex-
ical rules might combine with general grammar
rules of the form
COMMAND --> TRANSITIVE_VERB NP
NP --> DET NOUN
DET --> the
This kind of solution is easy to understand, but ex-
perience shows that it leads to poor speech recog-
nition. The problem is that the language model
produced by the grammar is underconstrained: it
will in particular allow any transitive verb to com-
bine with any NP. However, a verb like \dim" will
only combine with a restricted range of possible
NPs, and ideally we would like to capture this
fact. What we really want to do is parameterise
the language model. In the present case, we want
to parameterise the TRANSITIVE VERB \dim" with
the information that it only combines with object
NPs that can be used to refer to dimmable de-
vices. We will parameterise the NP and NOUN
non-terminals similarly. The obvious way to do
this within the bounds of CFG is to specialise the
rules approximately as follows:
COMMAND --> TRANS_DIM_VERB DIMMABLE_NP
DIMMABLE_NP --> DET DIMMABLE_NOUN
TRANS_DIM_VERB --> dim
DIMMABLE_NOUN --> light
DET --> the
Unfortunately, however, this defeats the original
object of the exercise, since the \general" rules
now make reference to the device-specic concept
of dimming. What we want instead is a more
generic treatment, like the following:
COMMAND -->
TRANSITIVE_VERB:[sem_obj_type=T]
NP:[sem_type=T]
NP:[sem_type=T] -->
DET NOUN:[sem_type=T]
DET --> the
TRANSITIVE_VERB:[sem_obj_type=dimmable]
--> dim
NOUN:[sem_type=dimmable] --> light
This kind of parameterisation of a CFG is not
in any way new: it is simply unication gram-
mar (Pullum and Gazdar, 1982; Gazdar et al,
1985). Thus our rst main idea is to raise the
level of abstraction, formulating the device gram-
mar at the level of unication grammars, and
compiling these down into the underlying CFG
representation. There are now a number of sys-
tems which can perform this type of compilation
(Moore, 1998; Kiefer and Krieger, 2000); the ba-
sic methods we use in our system are described
in detail elsewhere (Rayner et al, 2001a). Here,
we focus on the aspects that are required for \dis-
tributed" unication grammars needed for Plug
and Play.
4.2 \Unication grammars meet
object-oriented programming".
Our basic idea is to start with a general device-
independent unication grammar, which imple-
ments the core grammar rules. In our prototype,
there are 34 core rules. Typical examples are
the NP conjunction and PP modications rules,
schematically
NP --> NP CONJ NP
NP --> NP PP
which are likely to occur in connection with any
kind of device. These rules are parameterised by
various features. For example, the set of features
associated with the NP category includes gram-
matical number (singular or plural), WH (plus or
minus) and sortal type (multiple options).
Each individual type of device can extend the
core grammar in one of three possible ways:
New lexical entries A device may add lexical
entries for device-specic words and phrases;
e.g., a device will generally contribute at least
one noun used to refer to it.
New grammar rules A device may add device-
specic rules; e.g., a dimmer switch may in-
clude rules for dimming and brightening, like
\another X percent" or \a bit brighter".
New feature values Least obviously, a device
may extend the range of values that a gram-
matical feature can take (see further below).
For usual software engineering reasons, we nd it
convenient to divide the distributed grammar into
modules; the grammatical knowledge associated
with a device may reside in more than one module.
The grammar in our current demonstrator con-
tains 21 modules, including the \core" grammar
described above. Each device typically requires
between two and ve modules. For example, an
on/o light switch loads three modules: the core
grammar, the general grammar for on/o switch-
able devices, and the grammar specically for
on/o switchable lights. The core grammar, as al-
ready explained, consists of linguistically oriented
device-independent grammar rules. The mod-
ule for on/o switchable devices contains gram-
mar rules specic to on/o switchable behaviour,
which in general make use of the framework es-
tablished by the general grammar. For example,
there are rules of the schematic form
QUESTION -->
is
NP:[sem_type=device]
ON_OFF_PHRASE
PARTICLE_VERB:[particle_type=onoff]
--> switch
Finally, the module for on/o switchable lights is
very small, and just consists of a handful of lexi-
cal entries for nouns like \light", dening these as
nouns referring to on/o switchable devices. The
way in which nouns of this kind can combine is
however dened entirely by the on/o switchable
device grammar and core grammar.
The pattern here turns out to be the usual one:
the grammar appropriate to a device is composed
of a chain of modules, each one depending on the
previous link in the chain and in some way special-
ising it. Structurally, this is similar to the organ-
isation of a piece of normal object-oriented soft-
ware, and we have been interested to discover that
many of the standard concepts of object-oriented
programming carry over naturally to distributed
unication grammars. In the remainder of the sec-
tion, we will expand on this analogy.
If we think in terms of Java or a similar main-
stream OO language, a major grammatical con-
stituent like S, NP or PP has many of the prop-
erties of an OO interface. Grammar rules in one
module can make reference to these constituents,
letting rules in other modules implement their
denition. For example, the temperature sen-
sor grammar module contains a small number of
highly specialised rules, e.g.
QUESTION -->
what is the temperature
PP:[pp_type=location]
QUESTION -->
how many degrees is it
PP:[pp_type=location]
The point to note here is that the temperature
sensor grammar module does not dene the loca-
tive PP construction; this is handled elsewhere,
currently in the core grammar module. The up-
shot is that the temperature sensor module is able
to dene its constructions without worrying about
the exact nature of the locative PP construction.
As a result, we were for instance able to upgrade
the PP rules to include conjoined PPs (thus allow-
ing e.g. \what is the temperature in the kitchen
and the living room") without in any way alter-
ing the grammar rules in the temparature sensor
module
2
2
An ambitious treatment of conjunction might ar-
guably also necessitate changes in the dialogue man-
agement component specic to the temperature sen-
sor device. In the implemented system, conjunction
is uniformly treated as distributive, so \what is the
temperature in the kitchen and the living room" is au-
In order for the scheme to work, the \interfaces"
{ the major categories { naturally need to be well-
dened. In practice, this implies restrictions on
the way we handle three things: the set of syntac-
tic features associated with a category, the range
of possible values (the domain) associated with
each feature, and the semantics of the category.
We consider each of these in turn.
Most obviously, we need to standardise the
feature-set for the category. At present, we de-
ne most major categories in the core grammar
module, to the extent of specifying there the full
range of features associated with each category.
It turns out, however, that it is sometimes desir-
able not to x the domain of a feature in the core
grammar, but rather to allow this domain to be
extended as new modules are added. The issues
that arise here are interesting, and we will discuss
them in some detail.
The problems occur primarily in connection
with features mediating sortal constraints. As
we have already seen in examples above, most
constituents will have at least one sortal fea-
ture, encoding the sortal type of the constituent;
there may also be further features encoding the
sortal types of possible complements and ad-
juncts. For example, the V category has a fea-
ture vtype encoding the sortal type of the V it-
self, a feature obj sem np type encoding the sor-
tal type of a possible direct object, and a feature
vp modifiers type encoding the sortal type of a
possible postverbal modier.
Features like these pose two interrelated prob-
lems. First, the plug and play scenario implies
that we cannot know ahead of time the whole do-
main of a sortal feature. It is always possible that
we will connect a device whose associated gram-
mar module requires denition of a new sortal
type, in order to enforce appropriate constraints in
the language model. The second problem is that
it is still often necessary to dene grammar rules
referring to sortal features before the domains of
these features are known: in particular, the core
module will contain many such rules. Even before
knowing the identity of any specic devices, gen-
eral grammar rules may well want to distinguish
between \device" NPs and \location" NPs. For
example, the general \where-question" rule has
the form
QUESTION --> where is NP
Here, we prefer to constrain the NP so as to make
it refer only to devices, since the system currently
tomatically interpreted as equivalent to \what is the
temperature in the kitchen and what is the tempera-
ture in the living room'.
has no way to interpret a where question referring
to a room, e.g. \where is the bathroom".
We have addressed these issues in a natural way
by adapting the OO-oriented idea of inheritance:
specically, we dene a hierarchy of possible fea-
ture values, allowing one feature value to inherit
from another. In the context of the \where is
NP" rule above, we dene the rule in the core
module; in this module, the sortal NP feature
sem np type may only take the two values device
and location, which we specify with the declara-
tion
3
domain(sem_np_type, [location, device])
This allows us to write the constrained \where is"
rule as
QUESTION -->
where is NP:[sem_np_type=device]
Suppose now that we add modules for both on/o
switchable and dimmable devices; we would like
to make these into distinct sortal types, called
switchable device and dimmable device. We
do this by including the following declarations in
the \switchable" module:
domain(sem_np_type,
[location,
device,
switchable_device])
specialises(switchable_device, device)
and correspondingly in the \dimmable" module:
domain(sem_np_type,
[location,
device,
dimmable_device])
specialises(dimmable_device, device)
When all these declarations are combined at
compile-time, the eect is as follows. The do-
main of the sem np type feature is now the
union of the domains specied by each compo-
nent, and is thus the set flocation, device,
switchable device, dimmable deviceg. Since
switchable device and dimmable device are
the precise values specialising device, the com-
piler systematically replaces the original feature
value device with the disjunction
switchable_device \/ dimmable_device
Thus the \where is" rule now becomes
QUESTION -->
where is
NP:[sem_np_type=switchable_device \/
dimmable_device]
3
We have slightly simplied the form of the decla-
ration for expository purposes.
If new modules are added which further specialise
switchable device, then the rule will again be
adjusted by the compiler so as to include appropri-
ate new elements in the disjunction. The impor-
tant point to notice here is that no change is made
to the original rule denition; in line with nor-
mal OO thinking, the feature domain information
is distributed across several independent modules,
and the changes occur invisibly at compile-time
4
.
We have so far said nothing about how we deal
with semantics, and we conclude the section by
sketching our treatment. In fact, it is not clear
to us that the demands of supporting Plug and
Play greatly aect semantics. If they do, the
most important practical consideration is proba-
bly that plug and play becomes easier to realise
if the semantics are kept simple. We have at any
rate adopted a minimal semantic representation
scheme, and the lack of problems we have experi-
enced with regard to semantics may partly be due
to this.
The annotated CFG grammars produced by our
compiler are in normal Nuance Grammar Speci-
cation Language (GSL) notation, which includes
semantics; unication grammar rules encode se-
mantics using the distinguished feature sem, which
translates into the GSL return construction. So
for example the unication grammar rules
DEVICE_NOUN:[sem=light] --> light
DEVICE_NOUN:[sem=heater] --> heater
translates into the GSL rule
DEVICE_NOUN
[ light {return(light)}
heater {return(heater)}]
Unication grammar rules may contain variables,
translating down into GSL variables; so for exam-
ple,
NP:[sem=[D, N]] -->
DET:[sem=D]
NOUN:[sem=N]
translates into the GSL rule
NP (DET:d NOUN:n) {return(($d $n))}
Our basic semantic representation is a form of fea-
ture/value notation, extended to allow handling
4
Readers familiar with OO methodology may
be disturbed by the fact that the rule appears
to have been attached to the daughter nodes
(switchable device dimmable device, etc), rather
than to the mother device node. We would argue that
the rule is still conceptually attached to the device
node, but that the necessity of eventually realising it
in CFG form implies that it must be compiled in this
way, so that it can later be expanded into a separate
CFG rule for each daughter.
of conjunction. We allow four types of semantic
construction:
 Simple values, e.g. light, heater. Typically
associated with lexical entries.
 Feature/value pairs expressed in list no-
tation, e.g. [device, light], [location,
kitchen]. These are associated with nouns,
adjectives and similar constituents.
 Lists of feature/value pairs, e.g. [[device,
light], [location, kitchen]]. These are
associated with major constituents such as
NP, PP, VP and S.
 Conjunctions of lists of feature/value pairs,
e.g. [and, [[device, light]], [[device,
heater]]] These represent conjoined con-
stituents, e.g. conjoined NPs, PPs and Ss.
This scheme makes it straightforward to write the
semantic parts of grammar rules. Most often, the
rule just concatenates the semantic contributions
of its daughters: thus for example the semantic
features of the nominal PP rule are simply
NP:[sem=concat(Np, Pp)] -->
NP:[sem=Np]
PP:[sem=Pp]
The semantic output of a conjunction rule is typ-
ically the conjunction of its daughters excluding
the conjunction itself, e.g.
NP:[sem=[and, Np1, Np2]] -->
NP:[sem=Np1]
and
NP:[sem=Np2]
5 Future Plug & Play work
In the future, we intend to move to a system
in which all dialogue components can be recon-
gured by devices. For example, in a complete
Plug and Play scenario, the possible device ac-
tions themselves should be declared by devices
perhaps following UPNP standards in which de-
vices publish all interface commands in the form
actionname(arg
1
...arg
i
) plus an internal state
model of a simple vector of values. In this section
we start with some very general observations on
Plug and Play dialogue management and the role
of inference. Then we outline a proposal for a rule
based formalism.
At a very general level of course, indirections
between executable actions and linguistic contents
can arise at several levels: the speech act level
(\It's too warm in here"), the content level (\How
warm is it?"), as well through underdetermination
of contents either through pronominal or ellipti-
cal constructions. At the moment, our pronom-
inal and elliptical resolution methods depend on
very simple `matching' algorithms. In general, one
might at least want some sort of consistency check
between the linguistic properties expressed in an
utterance and those of candidate objects referred
to. One might expect that inferential elements in
contextual interpretation should be strongly Plug
and Play - they will depend, for correctness and
e?ciency, on tailoring to the current objects in
the domain. The research project of uploading
relevant axioms and meaning postulates from a
device to a general purpose inference engine that
can be invoked in contextual resolution looks very
exciting.
Evidently, higher pragmatic relations between
what the user \strictly says" and possible device
operations are also very heavily inference based.
At the moment, we simply encode any neces-
sary inferences directly into the device grammars
and this su?ces to deal with certain simple be-
haviours. However, the requirement to encapsu-
late all device behaviour in a Plug and Play man-
ner imposes a signicant requirement. For ex-
ample, the most natural interaction with a ther-
mometer is, for example, \How warm is it?" or
\What is the temperature?" and not \Query the
thermometer". In our demonstrator, the (gram-
mar derived) semantic values simply reect di-
rectly the relevant device operations: h op=query
device=thermometeri. The strategy supports the
simple natural interactions it is designed to. It
even interacts tolerably well with our ellipsis and
reference resolution methods. \What is the tem-
perature in the hall? And in the living room?"
and \What is the temperature in the hall? What
is it in the living room?" can both be correctly
interpreted. Other interactions are less natural.
The default output when resolution cannot iden-
tify a device N is \I don't know which N you
mean". However, asking for the temperature in a
room with several thermometers should probably
not result in \I don't know which temperature you
mean". It follows that prescribing all behaviour in
a Plug and Play fashion is a signicant constraint.
Indeed, a more general point can be made here.
A problem has arisen because the inference from
service required to service provider has become in-
secure in the presence of other service providers.
In the highly networked homes of the future, more
sophisticated inference may be required just be-
cause service level concepts will predominate over
device level concepts.
5.1 A Rule based formalism
In this section we assume that semantic
values consist of 5-ary slot-structure with
slots device class (dimmable light, TV . . . ),
device attributes (kitchen, blue . . . ), pronoun
(as before) and device-specifier (as before)
and operation. An operation is the action
the user wants carried out, e.g. switch on,
set level(X), where X is a real number (for
dimmable lights), set program(Y) etc. (for Hi-
Fis, TVs), and so on. As in the grammar, device
classes are ordered in a hierarchy in a standard
object-oriented way. Thus \dimmable light" is a
subclass of \dimmable device" and inherits from
it.
For strong plug and play, at least the follow-
ing information must be loaded by a device into
the dialogue manager: the device interface (e.g.
that the \switchable light" class has a switch on
method; the feedback to the user; the update to
the system's device model generated by executing
the command. Clearly, behaviour can also depend
on the current state. Reaction to \switch on the
kitchen light" depends on whether the lamp is o,
on, and whether there is a kitchen light. We write
a rule as command(A,B,C,D) where A is a com-
mand, B is a class of devices for which A is appli-
cable, C is a list of device attributes whose values
must be known in order to execute A, D is a list of
items describing how the system should react on
A. Each item has the following components:
precondition(X) | X is an executable proce-
dure that tests the network state and returns
true or false. If true, the item can `re'.
action(Y) | Y is the procedure to execute
feedback(Z,R) | Z is the feedback for the user
and can depend on R, the return value from
the device operation
upd(W,R) | W describes how the system's
model of the network state should be up-
dated. Also W can depend on R.
For example switching on
a light might be encoded as
command(switch; switchable light; [id = ID]; D)
where D is a list of items in the above form of
which one describes behaviour when the light is
already o thus:
[ precondition(light off(ID));
action(switch on light(ID));
feedback(light now on(ID); success);
feedback(could not switch(ID); error);
upd([dev update(ID; status= 1)]; success);
upd([]; failure) ]
light off and switch on light are procedures
provided by the lamp. The feedback to the user
and the update rules depend on the result of the
switch on light procedure.
6 Conclusion
Applying the idea of plug and play to spoken di-
alogue interfaces poses a number of interesting
and important problems. Since the linguistic and
dialogue management information is distributed
throughout the network, a plug and play system
must update its speech interface whenever a new
device is connected. In this paper, we have fo-
cussed in particular on distributed grammars for
plug and play speech recognition which we have
integrated into our demonstrator system. We have
also examined some issues and described a possi-
ble approach to distributed dialogue management
which we plan to undertake in further work.
Acknowledgments
We are very grateful to our partners in the
DHomme project for discussion of the above ideas
- especially on the importance and role of dier-
ing strengths of Plug and Play. The DHomme
project partners include netdecisions Ltd, SRI In-
ternational, Telia Research AB, and the Universi-
ties of Edinburgh, Gothenburg and Seville.
References
N.M. Fraser and J.H.S. Thornton. 1995. Vocalist:
A robust, portable spoken language dialogue
system for telephone applications. In Proc. of
Eurospeech '95, pages 1947{1950, Madrid.
Gerald Gazdar, Ewan Klein, Georey Pullum,
and Ivan Sag. 1985. Generalized Phrase Struc-
ture Grammar. Harvard University Press, Cam-
bridge, MA.
J.R Glass. 1999. Challenges for spoken dialogue
systems. In Proc. IEEE ASRU Workshop, Key-
stone, CO.
A. Goldschen and D Loehr. 1999. The role of the
darpa communicator architecture as a human
computer interface for distributed simulations.
In 1999 SISO Spring Simulation Interoperabil-
ity Workshop, Orlando, Florida, March 1999.
SpeechWorks Int Inc, 2001. SpeechWorks.
http://www.speechworks.com. As at 31/01/01.
B. Kiefer and H. Krieger. 2000. A context-free
approximation of head-driven phrase structure
grammar. In Proceedings of 6th Int. Workshop
on Parsing Technologies, pages 135{146.
A. Kolzer. 1999. Universal dialogue specication
for conversational systems. In Proceedings of
IJCAI'99 Workshop on Knowledge & Reason-
ing In Practical Dialogue Systems, Stockholm.
S. Larsson and D. Traum. 2000. Information state
and dialogue management in the trindi dialogue
move engine toolkit. Nat.Lang. Engineering, 6.
Microsoft, 2000. Universal Plug and Play Device
Architecture. http://www.upnp.org. Version
1.0, 8 June 2000.
D. Milward. 2000. Distributing representation for
robust interpretation of dialogue utterances. In
Proc. of 38th ACL, Hong Kong, pages 133{141.
R. Moore. 1998. Using natural language knowl-
edge sources in speech recognition. In Proceed-
ings of the NATO Advanced Studies Institute.
Nuance Communications, 1999. Nuance Speech
Recognition System Developer's Manual version
6.2. 1380 Willow Road, Menlo Park, CA 94025.
S. Oaks and H. Wong. 2000. Jini in a Nutshell.
O'Reilly.
Georey K. Pullum and Gerald Gazdar. 1982.
natural languages and context-free languages.
Llinguistics and Philosophy, 4:471{504.
M. Rayner, J. Dowding, and B.A. Hockey. 2001a.
A baseline method for compiling typed unica-
tion grammars into context free language mod-
els. Proc. Eurospeech 2001, Aalborg.
M. Rayner, G. Gorrell, B.A. Hockey, J. Dowding,
and J. Boye. 2001b. Do cfg based language
models need agreement constraints? In Pro-
ceedings of 2nd NAACL, Pittsburgh.
S. Sutton et al 1998. Universal speech tools: The
cslu toolkit. In Proc. ICSLP-98, pages 3221{
3224.
Figure 1 - Example Dialogue
Network status: There is no TV. There is a VCR
in the TV room.
U1 Switch on the television
S1 Sorry, try again
U2 Add new component (this must precede
device installation)
Now, a TV is plugged into the living room. Cur-
rently we simulate this in a simple text interface,
where devices and rooms are chosen from prede-
ned lists. The speech interface is then automati-
cally recongured (this currently takes 29 seconds)
U3 Switch on the television
S3 The TV is now on
U4 Switch on the television
S4 The TV is already on
U5a Add new component
Now, another TV is plugged into the kitchen. No
speech interface reconguration required this time
U5 Switch on the television
S5 The living-room TV is already on
U6 Switch on the VCR
S6 The VCR is now on
U7 Switch on the television
S7 Sorry, I don't know which TV you mean
U8 The television in the kitchen
S8 The kitchen TV is now on
U9a Add new component
Now, on-o lights are installed in the hall and
bathroom. Reconguration time is 27 seconds
U9 Switch on the light in the hall
S9 The hall light is now on
U10 Dim the light to fty percent
S10 Sorry, try again.
U11a Add new component
Now, a dimmable light is installed in the kitchen.
Reconguration time is 39 seconds
U11 Dim the kitchen light to 50 percent
S11 The light in the kitchen is now on at fty
percent
U12 Dim the light in the hall
S12 I'm sorry, the hall light can only be on or
o
U13 Turn on the light in the kitchen (misheard
as \increase the light in the kitchen")
S13 The kitchen light is now on at sixty per-
cent
Proceedings of the 2010 Workshop on Companionable Dialogue Systems, ACL 2010, pages 37?42,
Uppsala, Sweden, 15 July 2010. c?2010 Association for Computational Linguistics
?How was your day??
S. G. Pulman, J. Boye
University of Oxford
sgp@clg.ox.ac.uk
M. Cavazza, C. Smith
Teesside University
m.o.cavazza@tees.ac.uk
R. S. de la Ca?mara
Telefonica I+D
e.rsai@tid.es
Abstract
We describe a ?How was your day??
(HWYD) Companion whose purpose is to
establish a comforting and supportive rela-
tionship with a user via a conversation on
a variety of work-related topics. The sys-
tem has several fairly novel features aimed
at increasing the naturalness of the interac-
tion: a rapid ?short loop? response primed
by the results of acoustic emotion anal-
ysis, and an ?interruption manager?, en-
abling the user to interrupt lengthy or ap-
parently inappropriate system responses,
prompting a replanning of behaviour on
the part of the system. The ?long loop?
also takes into account the emotional state
of the user, but using more conventional
dialogue management and planning tech-
niques. We describe the architecture and
components of the implemented prototype
HWYD system.
1 Introduction
As the existence of this workshop shows, there is a
good deal of interest in a type of spoken language
dialogue system distinct from the traditional task-
based models used for booking airline tickets and
the like. The purpose of these ?social agent? sys-
tems is to be found in the relationship they can
establish with human users, rather than on the as-
sistance the agent can provide in giving informa-
tion or solving a problem. Designing such agents
provides many significant technical challenges, re-
quiring progress in the integration of linguistic
communication and non-verbal behaviour for af-
fective dialogue (Andre? et al 2004). In this pa-
per, we present the implementation of a Compan-
ion Embodied Conversational Agent (ECA) which
integrates emotion and sentiment detection with
more traditional dialogue components.
2 From Dialogue to Conversation
Most spoken language dialogue systems are ?task-
based?: they aim at getting from the user values for
a fixed number of slots in some template. When
enough values have been found, the filled tem-
plate is sent off to some back-end system so that
the task in question - ordering a pizza, booking a
ticket etc. - can be carried out. However, a so-
cial Companion agent assumes a kind of conver-
sation not necessarily connected to any immediate
task, and which may not follow the conventions
associated with task-driven dialogues, for exam-
ple, the relatively strict turn-taking of task-based
dialogue. In everyday life, many interhuman con-
versations see one of the participants producing
lengthy descriptions of events, without this corre-
sponding to any specific request or overall con-
versational purpose. Our objective was to sup-
port such free conversation, whilst still obtaining
meaningful answers from the agent, in the form of
advice appropriate both to the affective and infor-
mational content of the conversation. In order to
balance the constraints of free conversation with
those of tractability, we have deliberately opted
for a single-domain conversation, in contrast with
both small talk (Bickmore and Cassell, 1999) and
?chatterbot? approaches. Our HWYD domain in-
volves typical events and topics of conversation in
the workplace, ranging from the relatively mun-
dane - meeting colleagues, getting delayed by traf-
fic, project deadlines - to rather more important -
promotions, firings, arguments, office politics - de-
signed to evoke stronger emotions and hence more
affective dialogues.
However, our HWYD Companions retains
some features of a typical task based system, in
that each of these subtopics can be thought of as a
task or information extraction template. Unfilled
slots will drive the dialogue manager to question
the user for possible values. When enough slots
37
are filled, the initiative will be passed to an ?affec-
tive strategy? module, which will generate a longer
response designed to empathise appropriately with
the user over that particular topic.
3 System Overview and Architecture
The HWYD Companion integrates 15 different
software components, covering at least to some
degree all the necessary aspects of multimodal af-
fective input and output: including speech recog-
nition (ASR, using Dragon Naturally Speaking),
emotional speech recognition (AA: the EmoVoice
system (Vogt et al 2008)), turn detection (ATT),
Dialogue Act segmentation and tagging (DAT),
Emotional modelling (EM), Sentiment Analy-
sis (SA) (Moilanen et al 2007), Natural Lan-
guage Understanding (NLU), Dialogue Manage-
ment (DM), user modelling and a knowledge
base (KB/UM), an ?Affective Strategy Module?
(ASM) generating complex system replies, Natu-
ral Language Generation (NLG), Speech Synthe-
sis (TTS), an avatar (ECA), and Multimodal con-
trol of the ECA persona (MFM): gesture and fa-
cial expression, supported by the Haptek anima-
tion toolkit. Clearly the use of Naturally Speaking
imposes on us speaker dependence, since the sys-
tem needs training: in the scenario we have chosen
this is in fact not too unrealistic an assumption, but
this is merely a practical decision - we are not do-
ing research on speech recognition as such in this
project and so want to get as good a recognition
rate as possible.
The software architecture of the prototype re-
lies on the Inamode Framework developed by
Telefnica I+D. Communication between modules
follows a blackboard-like paradigm, in which cen-
tral hubs broadcast any incoming message from
any module to all of the other modules that are
connected to it. Figure 1 below shows the system
architecture, and Figure 2 shows one version of
what is on the screen when the system is running.
4 Emotional Feedback Loops
Recognising and responding appropriately to dif-
ferent emotions is an important aspect of a social
agent. In our HWYD Companion, emotion and
sentiment are used in two ways: firstly, to pro-
vide immediate feedback to a user utterance (given
that there will inevitably be some delay in the re-
sponse from natural language and dialogue pro-
cessing modules) and secondly to inform the more
extended responses given by the system when it
has learned enough about the current sub-topic.
There are two feedback loops: the ?short loop?
(response time < 700 ms) provides an immedi-
ate backchannel, and its main purpose is to main-
tain contact and keep the communication alive and
realistic. This is achieved by matching the non-
verbal response (gesture, facial expression) of the
avatar to the emotional speech parameters detected
by EmoVoice prior to affective fusion (where the
emotion detected from speech and the sentiment
value detected from the corresponding text are
merged: see below), and occasionally including
an appropriate verbal acknowledgement, on a ran-
dom basis to avoid acknowledging all user utter-
ances. The short loop essentially aligns the ECA
response to the user?s attitude, thus showing empa-
thy. (We should also use SA for this, but currently
processing speed is not fast enough).
The ?major loop? (response time < 3000 ms) in-
volves the ECA?s full response to the user utter-
ance in terms of both verbal and non-verbal be-
haviour. There are effectively two sources of sys-
tem output: the dialogue manager engages with
the user to find out what happened during their
work day, and will ask questions, or drop into
clarificatory sub-dialogues, gradually building up
a complex event description along with an assess-
ment of the prevailing emotions of the speaker.
When sufficient information has been gathered,
control is passed to an ?affective strategy module?
which will produce a longer output, typically ad-
vice or warning in response to the user?s recollec-
tion of his daily events.
The system also includes an interruption man-
ager which detects interruption and barge-in by the
user, resulting in the immediate suspension of the
current system utterance, triggering the process-
ing of any content specific to the interrupting ut-
terance, and consequent replanning on the part of
other modules to produce an appropriate response.
Such an interruption is illustrated in Figure 1. The
design of such an interruption manager in a sys-
tem with so many separate modules is quite chal-
lenging, in fact: the system is described further in
Crook et al (2010).
The ECA listens sympathetically to the user?s
account of work difficulties, whilst also reacting to
apparent discrepancies between perceived mood
and the affective content of the recognised events.
In the following example from a real conversation,
38
Figure 1: Overview of the System Architecture illustrating the information flow between modules.
Figure 2: The HWYD Companion in operation: the central portion of the screen traces the dialogue, whilst the right-hand
one displays which current software module is activated.
39
the user announces a company restructuring, but in
a rather cheerful tone. Notice that some of the En-
glish is a little strange: the generator produces a
mixture of genuinely generated output along with
some canned text.
User: I have just learnt that my department is going to be
merged with the Barcelona one (EMOTION FUSION: POS-
ITIVE ACTIVE)
System: You seem a bit too ecstatic! I?m doubtful that your
workload could be maintained.
Every time the Companion has gathered suffi-
cient information it will try to respond more glob-
ally to the situation at hand. In the following ex-
ample (see also Figure 2), after the user has ex-
pressed different sorts of concerns, the Companion
picks on the latest (positive) information to sum-
marise the few positive elements it picked from the
conversation:
User: yes but one good thing anyway we had a new
coffee machine arrived today (EMOTION FUSION: POSI-
TIVE ACTIVE)
System: it?s always reassuring to hear good news! It?s right
to feel good about such a good situation. I am quite fond of
getting new stuff. I?m happy that your mood improves. It?s
worth remembering you should take time to enjoy the good
things when they happen.
5 Emotional Modelling and Fusion
Two different modules analyse the emotional con-
tent of user utterances: an emotional speech recog-
nition system (EmoVoice (Vogt et al 2008) which
returns information indicating both the arousal and
valence of the acoustic properties of the user?s
speech as negative passive, negative-active, neu-
tral, positive-active or positive-passive, and a text-
based Sentiment Analysis module which operates
on the utterance transcript after its recognition by
the ASR module. The SA module operates in
a compositional way and is able to classify lin-
guistic units of any syntactic type: noun phrases,
clauses, sentences etc. It is also able to assign
a ?strength? of the sentiment expressed. In the
current implementation it simply classifies clauses
as either negative, neutral or positive. These two
emotional inputs are then merged by a fusion pro-
cedure, whose purpose is to provide an aggregate
emotional category to be attached to the event de-
scription template produced by the NLU and DM
module. Essentially, the mechanism for affective
fusion consists in overriding the valence category
of EmoVoice with the one obtained by SA every
time the confidence score attached to EmoVoice
is below a preset value (depending on the com-
peting valence categories). Fusion is currently an
underdeveloped module: for example, detecting
mismatches between speech and language emo-
tion and sentiment values could lead to the recog-
nition of irony, sarcasm etc. (Tepperman et al
2006). Saying an intrinsically negative thing in a
positive and cheerful way, or the other way round,
suggests that the speaker is trying for some special
effect.
6 Natural Language Understanding and
Dialogue Management
The task of the NLU module is to recognise a spe-
cific set of events reported by the user within ut-
terances which can be of significant length (> 50
words) and which can be difficult to parse due to
speech recognition errors. This led us to follow an
Information Extraction (IE) approach to dialogue
analysis (see Jo?nsson et al 2004), using shallow
syntactic and semantic processing to find instan-
tiations of event templates. The NLU component
of the HWYD Companion demonstration system
takes the 1-best output from the speech recogniser
(currently: work in progress will take n-best),
which has already been segmented into dialogue-
act sized utterances (by the DAT module which si-
multaneously segments and labels the recogniser
output: see Figure 1). So, for example, a sequence
like ?It was okay there are not many projects at the
moment so it is very quiet would be segmented
into three separate dialogue acts. The utterances
are then part-of-speech tagged and chunked into
Noun Phrase (NP) and Verb Group (VG) units.
VGs consist of a main verb and any auxiliary verbs
or semantically important adverbs. Both of these
stages are carried out by a Hidden Markov Model
trained on the Penn Treebank, although some cus-
tomisation has been carried out for this applica-
tion: relevant vocabulary added and some proba-
bilities re-estimated to reflect properties of the ap-
plication. NP and VG chunks are then classified
into ?Named Entity? classes, some of which are
the usual person, organisation, time etc. but oth-
ers of which are specific to the scenario, as is tradi-
tional in IE: e.g. salient work events, expressions
of emotion, organisational structure etc. Named
Entity classification, in the absence of domain spe-
cific training data, is carried out via hand-written
pattern matching rules and gazetteers. Each chunk
40
is further annotated with features encoding the
head word, stem form, polarity, agreement fea-
tures, relevant modifiers, etc. for later syntac-
tic and semantic processing. The NPs and VGs
are represented as unification grammar categories
containing information about the internal structure
of the constituents.
The next stage applies unification based syn-
tax rules which combine NP and VG chunks into
larger constituents. These rules are of two types:
most are syntactically motivated and are attempt-
ing to build a parse tree from which main gram-
matical relations (subject, object, etc.) can be
recognised. These have coverage of the main syn-
tactic constructs of English. But within the same
formalism we add domain specific Information
Extraction type patterns, looking out for particular
constellations of entities and events relevant to the
HWYD scenario, for example ?argument at work
between X and Y?, or ?meeting with X about Y?.
Processing is non-deterministic and so sentences
will get many analyses. We use a ?shortest path
through the chart heuristic to select an interpre-
tation. This is far from perfect, and we are cur-
rently working on a separate more motivated dis-
ambiguation module.
The final stage of processing before the Dia-
logue Manager takes over is to perform reference
resolution for pronouns and definite NPs. This
module is based partly on the system described
by Kennedy and Boguraev 1996, with the various
weighting factors based on theirs, but designed so
that the weights can be trained given appropriate
data. Currently we are collecting such data and
the present set of weights are taken from Kennedy
and Boguraev but with additional salience given
to the domain-specific named entity classes. Each
referring NP gives rise to a discourse referent, and
these are grouped into coreference classes based
on grammatical, semantic, and salience properties.
The DMmaintains an information state contain-
ing all objects mentioned during the conversation,
and uses this information to decide whether the
objects referred to in the utterance are salient or
not. The DM also uses type information to inter-
pret elliptical answers to questions (System: ?Who
was at the meeting?? User: ?Nigel.?). After the
user?s utterance has been interpreted in its dia-
logue context and the information state has been
updated, the dialogue manager decides on the ap-
propriate response. If a new object has been intro-
duced by the user, the DM adds a goal to its agenda
to talk about that object. For instance, if a new per-
son is mentioned, the DM will ask questions about
the user?s relation to that person, etc.
For each turn of the dialogue, the DM chooses
which topic to pursue next by considering all the
currently un-satisfied goals on the agenda and
heuristically rating them for importance. The
heuristics employed use factors such as recency in
the dialogue history, general importance, and emo-
tional value associated with the goal. We are cur-
rently exploring the use of reinforcement learning
with a reward function based on the results of SA
on the users input to choose goals in a more natural
way. The DM also has the option of invoking the
ASM (described below) to generate an appropri-
ate answer, in the cases where the user says some-
thing highly emotive. Again, this is a decision that
could involve reinforcement learning, and we are
exploring this in our current work.
The joint operation of the NLU and the DM
hence supports a kind of IE or task-specific
template-filling: the content of the user?s utter-
ances, prompted by questions from the DM, pro-
vides the information necessary to fill a template
to the point where the ASM can take over. The
number of templates for domain events is signifi-
cantly higher than in traditional IE or task-based
dialogue systems, however, since the HWYD
Companion currently instantiates more than 30
templates, and will eventually cover around 50.
7 Affective Dialogue Strategies
Once the NLU and DM have a sufficiently in-
stantiated template, which also records emotional
value, it is passed to the ASM. This controls the
generation of longer ECA narrative replies which
aim at influencing the user by providing advice or
reassurance. Our overall framework for influence
is inspired by the work of Bremond 1973. The
narrative is constituted by a set of argumentative
statements which can be based on emotional op-
erators (e.g. show-empathy) or specific commu-
nicative operators. The ASM is based on a Hier-
archical Task Network (HTN) planner (Nau et al
2004), which works through recursive decompo-
sition of a high level task into sub-tasks until we
reach a plan of sub-tasks that can be directly ex-
ecuted. The operators constituting the plan gen-
erated by the HTN implement Bremond?s the-
ory of influence by emphasising the determinants
41
of the event reported by the user. For instance,
various operators can emphasise or play down
the event consequences (emphasise-outcome-
importance, emphasise-outcome-justification,
emphasise-outcome-warning) or comment on
additional factors that may affect the course
of events (commend-enabler, reassure-helper).
The planner uses a set of 25 operators, each of
which can be in addition instantiated to incorpo-
rate specific elements of the event. Overall this
supports the generation of hundreds of signifi-
cantly different influencing strategies.
8 Results and Conclusions
We have described an initial, fully-implemented
prototype of a Companion ECA supporting free
conversation, including affective aspects, over a
variety of everyday work-related topics. The sys-
tem has been demonstrated extensively outside of
its development group and was regularly able to
sustain consistent dialogues with an average du-
ration exceeding 20 minutes. The Companion
ECA recently won the best demonstration prize
at AAMAS 2010,the 9th International Conference
on Autonomous Agents and Multiagent Systems,
Toronto, which is some subjective indication at
least that its behaviour is of some interest outside
of the project which developed it.
However, we have not yet systematically evalu-
ated the ECA, although this task has begun (Webb
et al 2010). The question of evaluation for sys-
tems like this is in fact a rather difficult one, since
unlike task-based systems there is no simple mea-
sure of success. In our current work we aim to
conduct extensive trials with real users and via
interview and questionnaires to get some useful
measure of how natural and ?companionable? the
system is perceived to be.
In other current work we are, as mentioned
above, experimenting with reinforcement learning
where the reward function is based on the emo-
tion and sentiment detected in the user?s input. We
are collecting data via Amazon?s Mechanical Turk
and hope to be able to show how the ECA can de-
velop different ?personalities? depending on how
this reward function is defined. For example, we
could imagine using simulated dialogues to pro-
duce a Companion that was relentlessly cheerful,
producing positive outputs whatever the input. Al-
ternatively, we could produce a ?mirror? Compan-
ion which simply reflected the mood of the user.
We could even produce a ?misery loves company?
Companion which, instead of trying to cheer the
user up when recognising negative sentiment or
emotion, could reply in an equally negative man-
ner.
Acknowledgements
This work was funded by the Companions project
(http://www.companions-project.org) sponsored by the Euro-
pean Commission as part of the Information Society Tech-
nologies (IST) programme under EC grant number IST-FP6-
034434. The EmoVoice system has been used courtesy of
the Multimedia Concepts and Applications Group of the Uni-
versity of Augsburg. Other contributors to the prototype de-
scribed in this paper are Karo Moilanen, and from the COM-
PANIONS consortium: David Benyon, Jay Bradley, Daniel
Charlton, WeiWei Cheng, Morena Danieli, Simon Dobnik,
Carlos Sanchez Fernandez, Debora Field, Mari Carmen Ro-
driguez Gancedo, Jose Relano Gil, Ramon Granell, Jaakko
Hakulinen, Preben Hansen, Sue Harding, Topi Hurtig, Oli
Mival, Roger Moore, Olov Stahl, Markku Turunen, Enrico
Zovato.
References
Andre?, E., Dybkjr, L., Minker, W., and Heisterkamp, P.
(Eds.), 2004, Affective Dialogue Systems Lecture Notes in
Computer Science 3068, Springer.
Bickmore, T., and Cassell, J., 1999. Small Talk and Con-
versational Storytelling in Embodied Interface Agents. Pro-
ceedings of the AAAI Fall Symposium on Narrative Intelli-
gence, pp. 87-92. November 5-7, Cape Cod, MA.
Bremond, C., 1973, Logique du Re?cit, Paris: Editions du
Seuil.
Cavazza, M., Pizzi, D., Charles, F., Vogt, T. And Andre?,
E. 2009, Emotional input for character-based interactive sto-
rytelling. International Joint Conference on Autonomous
Agents and Multi-Agents Systems 2009, pp. 313-320.
Nigel Crook, Cameron Smith, Marc Cavazza, Stephen
Pulman, Roger Moore, Johan Boye, 2010, Handling User In-
terruptions in an Embodied Conversational Agent Proceed-
ings of International Workshop on Interacting with ECAs as
Virtual Characters, AAMAS 2010.
Jo?nsson, A., Ande?n, F., Degerstedt, L., Flycht-Eriksson,
A., Merkel, M., and Norberg, S., 2004, Experiences from
combining dialogue system development with information ex-
traction techniques, in: Mark T. Maybury (Ed), New Direc-
tions in Question Answering, AAAI/MIT Press.
Kennedy and B. Boguraev, 1996, Anaphora for everyone:
Pronominal anaphora resolution without a parser. Proceed-
ings of the 16th International Conference on Computational
Linguistics, Copenhagen, ACL, pp 113-118.
Moilanen, K. and Pulman, S. G. , 2007, Sentiment Compo-
sition, Proceedings of the Recent Advances in Natural Lan-
guage Processing International Conference (RANLP-2007),
pp 378?382.
Nau, D., Ghallab, M., Traverso, P., 2004,Automated Plan-
ning: Theory and Practice, Morgan Kaufmann Publishers
Inc., San Francisco, CA.
J Tepperman, D Traum, and S Narayanan, 2006, ?Yeah
right?: Sarcasm recognition for spoken dialogue systems, In-
terspeech 2006, Pittsburgh, PA, 2006.
Vogt, T., Andre?, E. and Bee, N., 2008 EmoVoice - A frame-
work for online recognition of emotions from voice. In: Pro-
ceedings of Workshop on Perception and Interactive Tech-
nologies for Speech-Based Systems, Springer, Kloster Irsee,
Germany, (June 2008).
Webb, N., D. Benyon, P. Hansen and O. Mival, 2010,
Evaluating Human-Machine Conversation for Appropriate-
ness, in proceedings of the 7th International Conference on
Language Resources and Evaluation (LREC2010), Valletta,
Malta.
42
Proceedings of the SIGDIAL 2014 Conference, pages 2?11,
Philadelphia, U.S.A., 18-20 June 2014. c?2014 Association for Computational Linguistics
Crowdsourcing Street-level Geographic Information Using a 
Spoken Dialogue System 
 
 
 Raveesh Meena Johan Boye Gabriel Skantze Joakim Gustafson 
KTH Royal Institute of Technology 
School of Computer Science and Communication  
Stockholm, Sweden 
{raveesh, jboye}@csc.kth.se, {gabriel, jocke}@speech.kth.se 
 
  
 
Abstract 
We present a technique for crowd-
sourcing street-level geographic infor-
mation using spoken natural language. In 
particular, we are interested in obtaining 
first-person-view information about what 
can be seen from different positions in 
the city. This information can then for 
example be used for pedestrian routing 
services. The approach has been tested in 
the lab using a fully implemented spoken 
dialogue system, and has shown promis-
ing results. 
1 Introduction 
Crowdsourcing is increasingly being used in 
speech processing for tasks such as speech data 
acquisition, transcription/labeling, and assess-
ment of speech technology, e.g. spoken dialogue 
systems (Parent & Eskenazi, 2011). However, 
we are not aware of any attempts where a dia-
logue system is the vehicle for crowdsourcing 
rather than the object of study, that is, where a 
spoken dialogue system is used to collect infor-
mation from a large body of users.  A task where 
such crowdsourcing dialogue systems would be 
useful is to populate geographic databases. While 
there are now open databases with geographic 
information, such as OpenStreetMap (Haklay & 
Weber, 2008), these are typically intended for 
map drawing, and therefore lack detailed street-
level information about city landmarks, such as 
colors and height of buildings, ornamentations, 
facade materials, balconies, conspicuous signs, 
etc. Such information could for example be very 
useful for pedestrian navigation (Tom & Denis, 
2003; Ross et al., 2004). With the current grow-
ing usage of smartphones, we might envisage a 
community of users using their phones to con-
tribute information to geographic databases, an-
notating cities to a great level of detail, using 
multi-modal method including speech. The key 
reason for using speech for map annotation is 
convenience; it is easy to talk into a mobile 
phone while walking down the street, so a user 
with a little experience will not be slowed down 
by the activity of interacting with a database. 
This way, useful information could be obtained 
that is really hard to add offline, sitting in front 
of one?s PC using a map interface, things like: 
Can you see X from this point? Is there a big 
sign over the entrance of the restaurant? What 
color is the building on your right? 
Another advantage of using a spoken dialogue 
system is that the users could be asked to freely 
describe objects they consider important in their 
current view. In this way, the system could learn 
new objects not anticipated by the system de-
signers, and their associated properties.   
In this paper we present a proof-of-concept 
study of how a spoken dialogue system could be 
used to enrich geographic databases by 
crowdsourcing. To our knowledge, this is the 
first attempt at using spoken dialogue systems 
for crowdsourcing in this way. In Section 2, we 
elaborate on the need of spoken dialogue systems 
for crowdsourcing geographic information. In 
Section 3 we describe the dialogue system im-
plementation. Section 4 presents our in-lab 
crowdsourcing experiment. We present an analy-
sis of crowd-sourced data in Section 5, and dis-
cuss directions for future work in Section 6. 
2 The pedestrian routing domain 
Routing systems have been around quite some 
time for car navigation, but systems for pedestri-
2
an routing are relatively new and are still in their 
nascent stage (Bartie & Mackaness, 2006; Krug 
et al., 2003; Janarthanam et al., 2012; Boye et al., 
2014). In the case of pedestrian navigation, it is 
preferable for way-finding systems to base their 
instructions on landmarks, by which we under-
stand distinctive objects in the city environment. 
Studies have shown that the inclusion of land-
marks into system-generated instructions for a 
pedestrian raises the user?s confidence in the sys-
tem, compared to only left-right instructions 
(Tom & Denis, 2003; Ross et al., 2004).  
Basing routing instructions on landmarks 
means that the routing system would, for exam-
ple, generate an instruction ?Go towards the red 
brick building? (where, in this case, ?the red 
brick building? is the landmark), rather than 
?Turn slightly left here? or ?Go north 200 me-
ters?. This strategy for providing instructions 
places certain requirements on the geographic 
database: It has to include many landmarks and 
many details about them as well, so that the sys-
tem can generate clear and un-ambiguous in-
structions. However, the information contained 
in current databases is still both sparse and 
coarse-grained in many cases.  
Our starting point is a pedestrian routing sys-
tem we designed and implemented, using the 
landmark-based approach to instruction-giving 
(Boye et al., 2014). The system performs visibil-
ity calculations whenever the pedestrian ap-
proaches a waypoint, in order to compute the set 
of landmarks that are visible for the user from his 
current position. OpenStreetMap (Haklay & We-
ber, 2008) is used as the data source. Figure 1 
shows a typical situation in pedestrian routing 
session. The blue dot indicates the user?s position 
and the blue arrow her direction. Figure 2 shows 
the same situation in a first-person perspective. 
The system can now compute the set of visible 
landmarks, such as buildings and traffic lights, 
along with distances and angles to those land-
marks. The angle to a building is given as an in-
terval in degrees relative to the direction of the 
user (e.g. 90? left to 30? left). This is exemplified 
in Figure 1, where four different buildings are in 
view (with field of view marked with numbers 
1?4). Landmarks that are not buildings are con-
sidered to be a single point, and hence the rela-
tive angle can be given as a single number. 
When comparing the map with the street view 
picture, it becomes obvious that the ?SEB? bank 
office is very hard to see and probably not very 
suitable to use as a landmark in route descrip-
tions. On the other hand, the database does not 
contain the fact that the building has six stories 
and a fa?ade made of yellow bricks, something 
that would be easily recognizable for the pedes-
trian. This is not due to any shortcoming of the 
OpenStreetMap database; it just goes to show 
that the database has been constructed with map 
drawing in mind, rather than pedestrian routing. 
There are also some other notable omissions in 
the database; e.g. the shop on the corner, visible 
right in front of the user, is not present in the da-
tabase. Since OpenStreetMap is crowd-sourced, 
there is no guarantee as to which information 
will be present in the database, and which will 
not. This also highlights the limitation of existing 
approaches to crowd-sourcing geographic infor-
mation: Some useful information is difficult to 
add off-line, using a map interface on a PC. On 
the other hand, it would be a straightforward 
matter given the kind of crowd-sourcing spoken 
dialogue system we present next. 
 
 
 
Figure 1: A pedestrian routing scenario 
  
 
 
Figure 2: The visual scene corresponding to the 
pedestrian routing scenario in Figure 1 
3 A dialogue system for crowd-sourcing 
To verify the potential of the ideas discussed 
above, we implemented a spoken dialogue sys-
tem that can engage in spoken conversation with 
3
users and learn details about landmarks in visual 
scenes (such as Figure 2). To identify the kind of 
details in a visual scene that the system could 
potentially ask the users, we first conducted a 
preliminary informal crowd-sourcing dialogue: 
one person (the receiver), was instructed to seek 
information that could be useful for pedestrian 
navigation from the other person (the giver).  
The receiver only had access to information 
available in the maps from OpenStreetMap, as in 
Figure 1, but without any marking of field of 
views, whereas the giver only had access to the 
corresponding visual scene (as in Figure 2). In-
teraction data from eight such dialogues (from 
four participants, and four different visual 
scenes) suggested that in a city environment, 
buildings are prominent landmarks and much of 
the interaction involves their properties such as 
color, number of stories, color of roof, signs or 
ornamentations on buildings, whether it has 
shops, etc. Seeking further details on mentioned 
signs, shops, and entities (whether mapped or 
unmapped) proved to be a useful strategy to ob-
tain information. We also noted that asking for 
open-ended questions, such as ?Is there anything 
else in this scene that I should be aware of?? 
towards the end has the potential of revealing 
unknown landmarks and details in the map.  
Obtaining specific details about known objects 
from the user corresponds to slot-filling in a dia-
logue system, where the dialogue system seeks a 
value for a certain slot (= attribute). By engaging 
in an open-ended interaction the system could 
also obtain general details to identify new slot-
value pairs. Although slots could be in some cas-
es be multi-valued (e.g., a building could have 
both color red and yellow), we have here made 
the simplifying assumption that they are single 
valued. Since users may not always be able to 
specify values for slots we treat no-value as a 
valid slot-value for all type of slots.  
We also wanted the system to automatically 
learn the most reliable values for the slots, over 
several interactions. As the system interacts with 
new users, it is likely that the system will obtain 
a range of values for certain slots. The variability 
of the answers could appear for various reasons: 
users may have differences in perception about 
slot-values such as colors, some users might 
misunderstand what building is being talked 
about, and errors in speech recognition might 
result in the wrong slot values. Some of these 
values may therefore be in agreement with those 
given by other users, while some may differ 
slightly or be in complete contradiction. Thus the 
system should be able to keep a record of all the 
various slot-values obtained (including the dis-
puted ones), identify slot-values that need to be 
clarified, and engage in a dialogue with users for 
clarification. 
In view of these requirements, we have de-
signed our crowd-sourcing dialogue system to be 
able to (1) take and retain initiative during the 
interactions for slot-filling, (2) behave as a re-
sponsive listener when engaging in open-ended 
dialogue, and (3) ask wh? and yes?no questions 
for seeking and clarifying slot-values, respective-
ly. Thus when performing the slot-filling task, 
the system mainly asks questions, acknowledges, 
or clarifies the concepts learned for the slot-
values. Apart from requesting repetitions, the 
user cannot ask any questions or by other means 
take the initiative. A summary of all the attrib-
utes and corresponding system prompts is pre-
sented in Appendix A. 
The top half of Figure 3 illustrates the key 
components of the dialogue system. The Dia-
logue Manager queries the Scene Manager (SM) 
for slots to be filled or slot-values to be clarified, 
engages in dialogue with users to learn/clarify 
slot-values, and informs the SM about the values 
obtained for these slots. The SM manages a list 
of scenes and the predefined slots ? for each type 
of landmark in visual scenes ? that need to be 
filled, maintains a record of slot-values obtained 
from all the users, and identifies slot-values with 
majority vote as the current reliable slot-value. 
To achieve these objectives, the scene manager 
uses an XML representation of visual scenes. In 
this representation, landmarks (e.g., buildings, 
junctions, etc.) ? automatically acquired through 
the OpenStreetMap database and the visibility 
computations mentioned in Section 2  ? are 
stored as scene-objects (cf. Figure 4). 
 
 
 
Figure 3: Dialogue system architecture 
 
The Dialogue Manager (DM) uses scene-
object attributes, such as type, angle or interval 
of a building, to generate referential expressions, 
such as ?Do you see a building on the far left?? 
4
or ?Do you see a shop on the left?? to draw the 
users? attention to the intended landmark in the 
scene. During the course of interaction, the Sce-
ne Manager (SM) extends scene-objects with a 
set of predefined attributes (= slots) that we iden-
tified in the preliminary study, along with their 
various slot-values (cf. Figure 5). For each slot, 
the SM keeps a record of slot-values obtained 
through wh? questions as well as the ones dis-
puted by the users in yes?no questions (cf. ob-
tained and disputed tags in the XML), and 
uses their tally to identify the slot-value in major-
ity. The system assumes this slot-value (or one of 
them in case of a tie) as its best estimate of a 
slot-value pair, which it could clarify with anoth-
er user using a yes?no query. During the slot-
filling mode the DM switches to open-ended in-
teraction mode to seek general details (using 
prompts such as ?Could you describe it/them??), 
if the user suggests/agrees that there are signs 
on/at a scene-object, or a building has shops or 
restaurants. Once all the slots for all the scene-
objects in a visual scene have been queried, the 
DM once again switches to the open-ended inter-
action mode and queries the users whether there 
are any other relevant signs or landmarks that the 
system may have missed and should be aware of. 
On completion of the open-ended queries the SM 
selects the next visual scene, and the DM engag-
es in a new dialogue.  
 
<scene xmlns="cityCS.scene" name=" view7.jpg" lat="59.34501" 
lon="18.0614" fovl="-60" fovr="60" bearing="320" dist="100"> 
    <scene-object> 
        <id>35274588</id> <type>building</type> 
        <from>-60</from> <end>-39</end> 
    </scene-object> 
    <scene-object> 
        <id>538907080</id> <type>shop</type> 
        <distance>34.82</distance> 
        <angle>-39</angle> <bearing>281</bearing> 
    </scene-object> 
    <scene-object> 
        <id>280604</id> <type>building</type> 
        <from>-38</from> <end>6</end> 
    </scene-object> 
    <scene-object> 
        <id>193906</id> <type>traffic_signals</type> 
        <distance>40.77</distance> 
        <angle>-14</angle> <bearing>306</bearing> 
    </scene-object> 
    ... 
</scene> 
Figure 4: XML representation of visual scenes 
 
For speech recognition and semantic interpre-
tation the system uses a context-free grammar 
with semantic tags (SRGS1), tailored for the do-
main. The output of semantic interpretation is a 
concept. If the concept type matches the type of 
the slot, the dialogue manager informs the scene 
manager about the obtained slot-value. If the 
                                                 
1 http://www.w3.org/TR/speech-grammar/ 
concept type is inappropriate the DM queries the 
user once more (albeit using different utterance 
forms). If still no appropriate concept is learned 
the DM requests the SM for the next slot and 
proceeds with the dialogue. For speech synthesis, 
we use the CereVoice system developed by 
CereProc2. The dialogue system has been imple-
mented using the IrisTK framework (Skantze & 
Al Moubayed, 2012). 
 
<scene-object> 
    <id>35274588</id> <type>building</type> 
    <from>-60</from> <end>-39</end> 
    <slot slotName="VISIBLE">?    </slot> 
    <slot slotName="COLOR"> 
     <obtained> 
       <value slotValue="Green"> 
         <userlist> 
           <usrDtls uid="u01" asrCnf="0.06" qType="WH"/> 
         </userlist> 
       </value> 
       <value slotValue="no-value"> 
         <userlist> 
           <usrDtls uid="u02" asrCnf="0.46" qType ="WH"/> 
         </userlist> 
       </value> 
       <value slotValue="Gray"> 
         <userlist> 
           <usrDtls uid="u03" asrCnf="0.19" qType ="WH"/> 
         </userlist> 
       </value> 
     </obtained> 
     <disputed> 
       <value slotValue="Green"> 
         <userlist> 
           <usrDtls uid="u02" asrCnf="0.92" qType ="YN"/> 
         </userlist> 
       </value> 
     </disputed> 
    </slot> 
    <slot slotName="STORIES">?    </slot> 
    <slot slotName="ROOF_COLOR">?    </slot> 
    ? 
</scene-object> 
 
Figure 5: Every slot-value is recorded  
 
In contrast to the slot-filling mode, when en-
gaging in an open-ended interaction, the system 
leaves the initiative to the user and behaves as a 
responsive listener. That is, the system only pro-
duces feedback responses, such as backchannels 
(e.g., okay, mh-hmm, uh-huh), repetition requests 
for longer speaker turns (e.g., could you repeat 
that?), or continuation prompts such as ?any-
thing else?? until the user is finished speaking. 
Unless the system recognized an explicit closing 
statement from the user (e.g., ?I can?t?), the sys-
tem encourages the user to continue the descrip-
tions for 2 to 4 turns (chosen randomly). 
To detect appropriate locations in users? 
speech where the system should give feedback 
response, the system uses a trained data-driven 
model (Meena et al., 2013). When the voice ac-
tivity detector detects a silence of 200 ms in us-
ers? speech, the model uses prosodic, contextual 
and lexico-syntactic features from the preceding 
speech segment to decide whether the system 
                                                 
2 https://www.cereproc.com/ 
5
should produce a feedback response. The lower 
half of Figure 3 shows the additional components 
of the dialogue system used in open-ended inter-
action mode. In this mode, the ASR system uses 
a language model that is trained on interactions 
from a related domain (verbal route descrip-
tions), in parallel to the SRGS grammar.  
4 In-lab crowd-sourcing experiment  
Nine visual scenes (wide-angle pictures in first-
person perspective and taken in Stockholm city, 
cf. Figure 2) were used for the task of 
crowdsourcing. Fifteen human participants (4 
females and 11 males) participated in the 
crowdsourcing exercise. All participants either 
studied or worked at the School of Computer 
Science and Communication, KTH, Stockholm. 
Participants were placed in front of a computer 
display and were told that the system will engage 
them in a spoken conversation to seek or clarify 
details about landmarks and other objects in vis-
ual scenes. They were told that the details would 
be used for pedestrian routing and therefore they 
are free to choose and specify details (in open-
ended questions) that they thought would be use-
ful when giving route instructions to another per-
son. 
Each participant did the nine visual scenes in 
the same order, with a 1 minute pause between 
each of them. The first visual scene was used as 
a trial in order to familiarize participants with the 
interaction scenario. For this reason, the trial in-
teraction was specifically designed to engage the 
participants in both wh? and yes?no type ques-
tions. We also wanted to investigate whether the 
use of wh? or yes?no questions alone has any 
impact on the interactions. For the remaining 
eight interactions, the dialogue system therefore 
alternatively used wh? and yes?no questions 
throughout the whole dialogue. The order of que-
ry types was switched for each successive partic-
ipant. Thus visual scenes presented with wh? 
queries to a participant pi were presented to par-
ticipant pi+1 with only yes?no queries, and vice-
versa. After each interaction participants were 
asked (1) whether the system appeared to be fa-
miliar with the visual scene; and (2) whether the 
interactions went smoothly. 
An example of a conversation with wh?type 
queries is presented in Table 1. The second col-
umn indicates the various types of utterances 
(dialogue acts) used by the system during this 
interaction. Note that during the slot-filling 
mode, the system has the initiative, whereas in 
the open-ended queries (cf. rows 15?22 in Table 
1) the system gives the initiative to the partici-
pant and only produces feedback responses. Ta-
ble 2 presents a conversation with yes?no queries 
following the conversation in Table 1. In a con-
versation with only yes?no  queries, a wh? query 
may be presented if a slot has been observed 
with no-value (cf. rows 9?10 in Table 1) or when 
the participant disputes the system?s current best 
estimate (cf. rows 6?9 in Table 2).  
 
S Introduction Could you help me with some de-
tails about this view? 
P  Yes 
S wh? query Do you see a building on the far 
left? 
P  Yes 
S Backchannel Mh-hmm 
S wh? query What color does the building have? 
P  Cream color [Green color] 
S Reprise Green 
S wh? query How many floors is this building? 
P  I don?t know [I do no] 
 ?  
S wh? query Are there any important signs in 
this scene that I may have missed? 
P  No 
S Backchannel Uh-huh 
S wh? query Is there anything peculiar in this 
scene that I should be familiar with 
P  There is a bike painted on street 
just in front of me 
[ is the right pink university in front 
of may ] 
S Backchannel Anything else? 
P  Yeah its white paint [Yes light pink] 
S Backchannel Mh-hmm 
P  That?s it [that that] 
S Backchannel Ehm 
P  I am done [okay] 
S Ending Okay, thanks 
 
Table 1: An example interaction with wh? que-
ries for the visual scene in Figure 2. S: system, P: 
participant (here, u01 from Figure 5). ASR re-
sults are shown within square brackets. 
 
S Introduction Could you help me with some details 
about this view? 
P  Yes 
S yes?no  
query 
Is the building on the far left visible to 
you? 
P  Yes 
S Backchannel Mh-hmm 
S yes?no  
query 
Does this building have green color? 
P  No 
S Backchannel Uh-huh 
S wh? query But than what color is the building? 
6
P  white [light] 
S Repeat Sorry, what color did you say? 
P  white [light] 
S wh? query How many stories is this building? 
P  I don?t know [I do rental] 
S Backchannel Ehm 
 ?  
S wh? query Are there any important signs in this 
scene that I may have missed? 
P  Ehm no [nine no] 
S Backchannel Ehm 
S yes?no  
query 
I am informed that there are other 
important landmarks or structures in 
this scene that I should be aware of, 
is it true? 
P  No 
S Backchannel uh-huh 
S Ending Okay, thanks 
 
Table 2: An example interaction with yes?no 
queries corresponding to the visual scene in Fig-
ure 2. S: system, P: participant (here u02 from 
Figure 5). ASR results are shown within square 
brackets. 
5 Data analysis 
We analyzed the data (15 8 interactions) col-
lected from the experiment along the following 
tracks: first, we compare the majority value of 
the slots to the ground truth as given by a human 
annotator; second, we explore how the ground 
truth of slot-values could be estimated automati-
cally; third, we also analyzed the instances where 
the participants disputed the system?s current 
estimate of slot-values; and fourth, we examined 
the post-experimental questionnaires.  
5.1 Rate of learning slot-values 
A total of 197 slots were learned in the exper-
iment. We analyzed how many slot-values had 
been correctly retrieved after 1, 2? 15 users. In 
Figure 6, the curve ?Majority? illustrates the 
fraction of slot-values correctly learned with 
each new user, under the assumption that the 
slot-values with majority votes ? from all the 15 
users ? constitute the ground truth. Thus after 
interacting with the first user the system had ob-
tained 67.0% of slot-values correctly (according 
to the majority) and 96.4% of slot-values after 
interacting with the first six users. Another eight 
users, or fourteen in total, were required to learn 
all the slot-values correctly. The progression 
curve thus provides an estimate of how many 
users are required to achieve a specific percent-
age of slot-values correctly if majority is to be 
considered the ground truth. The curve ?Not-in-
Majority? indicates the number of slot with val-
ues that were not in the majority. Thus after in-
teracting with the first user 20.8% of slot-values 
the system had obtained were not in majority and 
could be treated as incorrect. Note that the curves 
Majority and Not-in-Majority do not sum up to 
100%, this is because we consider no-value as a 
valid slot-value, and treat the slot as unfilled. For 
example, 12.2% of the slots remained unfilled 
after interacting with the first user.  
 
 
 
Figure 6: Rate of learning slot-values with two differ-
ent estimates of ground truth 
 
We also investigated how close the majority is 
to the actual truth. A human annotator (one of the 
coauthors) labeled all the obtained slot-values as 
either sensible or insensible, based on the com-
bined knowledge from the corresponding maps, 
the visual scenes, and the set of obtained values. 
Thus a slot could have many sensible values. For 
example, various parts of a building could be 
painted in different colors. The progression 
curves ?Sensible? and ?Insensible? in Figure 6 
illustrate the fraction of total slots for which the 
learned values were actually correct and incor-
rect, respectively. While the curve for sensible 
values follows the same pattern as the progres-
sion curve for majority as the estimate of ground 
truth, the percent of slot-values that were actually 
correct is always lower than the majority as 
ground truth, and it never reached 100%. The 
constant gap between the two curves suggests 
that some slot-values learned by the majority 
were not actually the ground truth. What led the 
majority into giving incorrect slot-values is left 
as a topic for future work. 
As mentioned earlier, much of the slot-filling 
interaction involved buildings and their proper-
ties. Figure 7 illustrates that sensible values for 
most slots, pertaining to whether a building is 
visible, whether it is residential, whether it has 
shops, and the color of roof were obtained by 
interacting with only few participants. In con-
trast, properties such as color of the building and 
7
number of stories required many more partici-
pants. This could be attributed to the fact that 
participants may have differences in perception 
about slot-values. As regards to whether there are 
signs on buildings, we observed that the recall is 
relatively low. This is largely due to lack of 
common ground among participants about what 
could be considered a sign. Our intentions with 
designing this prompt was to retrieve any peculi-
ar detail on the building that is easy to locate: for 
us a sign suggesting a name of restaurant is as 
useful as the knowledge that the building has 
blue sunshade on the windows. Some partici-
pants understood this while other didn?t. 
 
 
 
Figure 7: Learning rate of various slots for land-
mark type building  
5.2 Estimated ground truth of slot-values 
The 15 subjects in the in-lab experiment were all 
asked for the same information. In a real applica-
tion, however, we want the system to only ask 
for slots for which it has insufficient or conflict-
ing information. If the ground truth of a certain 
slot-value pair can be estimated with a certainty 
exceeding some threshold (given the quality re-
quirements of the database, say 0.8), the system 
can consider the matter settled, and need not ask 
about that slot again. We therefore want to esti-
mate the ground truth of slot-values along with a 
certainty measure. To this end, we use the 
CityCrowdSource Trust software package 
(Dickens & Lupu, 2014), which is based on the 
probabilistic approach for supervised learning 
when we have multiple annotators providing la-
bels (possibly noisy) but no absolute gold stand-
ard, presented in Raykar et al. (2009). 
Using this approach, a question concerning the 
color of a building, say with ID 24, (e.g. ?What 
color is the building??) would be translated into 
several binary predicates COLOR_Red(24), 
COLOR_Brown(24), COLOR_Orange(24), etc. 
The justification for this binary encoding is that 
the different color values are not mutually exclu-
sive: A building might of course have more than 
one color, and in many cases more than one color 
name might be appropriate even though the 
building has only one dominating color (e.g. to 
describe the color either as ?brown? and ?red? 
might be acceptable to most people). Figure 8 
shows the incremental estimates for different 
colors for a certain building (OpenStreetMap ID 
163966736) after 1, 2? 15 subjects had been 
asked. The answer from the first subject was er-
roneously recognized as ?pink?. The next 9 sub-
jects all referred to the building as ?brown?. 
Among the final subjects, 3 subjects referred to 
building as ?red?, and 2 subjects as ?brown?. The 
final truth estimates are 0.98 for ?brown?, 0.002 
for ?red?, and 0.00005 for ?pink?. The diagram 
shows that if the certainty threshold is set to 0.8, 
the value ?brown? would have been established 
already after 4 subjects. 
 
 
 
Figure 8: Probabilities of different estimated ground 
truth values for the color of a certain building 
5.3 Disputed slot-values 
We also examined all system questions of 
yes?no type that received negative answers, i.e. 
instances where the participants disputed the sys-
tem?s current best estimate (based on majority 
vote) of a slot-value. Among the 95 such in-
stances, the system?s current best estimate was 
actually insensible only on 43 occasions. In 30 of 
these instances the participants provided a recti-
fied slot-value that was sensible. For the remain-
ing 13 instances the new slot-values proposed by 
the participant were actually insensible. There 
were 52 instances of false disputations, i.e. the 
system?s current estimate of a slot-value was 
sensible, but the participants disputed it. 6 of the-
se occurrences were due to errors in speech 
recognition, but for the remaining 46 occasions, 
error in grounding the intended landmark (15), 
users? perception of slot-values (3), and ambigui-
ty in what the annotator terms as sensible slot-
values (28), (e.g. whether there are signs on a 
building (as discussed in Section 5.1)) were iden-
8
tified as the main reasons. This suggests that 
slots (i.e. attributes) that are often disputed may 
not be easily understood by users. 
5.4 Post-experimental questionnaire 
As described above, the participants filled in a 
questionnaire after each interaction. They were 
asked to rate the system?s familiarity with the 
visual scene based on the questions asked. A 
Mann?Whitney U test suggests that participants? 
perception of the system?s familiarity with the 
visual scene was significantly higher for interac-
tions with yes?no queries than interactions with 
wh? queries (U=1769.5, p= 0.007). This result 
has implications for the design choice for sys-
tems that provide as well as ask for information 
from users. For example, a pedestrian routing 
system can already be used to offer routing in-
structions as well as crowdsourcing information. 
The system is more likely to give an impression 
of familiarity with the surrounding, to the user, 
by asking yes?no type questions than wh?
questions. This may influence a user?s confi-
dence or trust in using the routing system.  
Since yes?no questions expect a ?yes? or 
?no? in response, we therefore hypothesized that 
interactions with yes?no questions would be per-
ceived smoother in comparison to interactions 
with wh? questions. However, a Mann?Whitney 
U test suggests that the participants perceived no 
significant difference between the two interac-
tion types (U=1529.0, p= 0.248). Feedback 
comments from participants suggest that abrupt 
ending of open-ended interactions by the system 
(due to the simplistic model of detecting whether 
the user has anything more to say) gave users an 
impression that the system is not allowing them 
to speak. 
6 Discussion and future work 
We have presented a proof-of-concept study on 
using a spoken dialogue system for crowd-
sourcing street-level geographic information. To 
our knowledge, this is the first attempt at using 
spoken dialogue systems for crowdsourcing in 
this way. The system is fully automatic, in the 
sense that it (i) starts with minimal details ? ob-
tained from OpenStreetMap ? about a visual sce-
ne, (ii) prompts users with wh? questions to ob-
tain values for a predefined set of attributes; and 
(iii) assumes attribute-values with majority vote 
as its beliefs, and engages in yes?no questions 
with new participants to confirm them. In a data 
collection experiment, we have observed that 
after interacting with only 6 human participants 
the system acquires more than 80% of the slots 
with actually sensible values. 
We have also shown that the majority vote (as 
perceived by the system) could also be incorrect. 
To mitigate this, we have explored the use of the 
CityCrowdSource Trust software package 
(Dickens & Lupu, 2014) for obtaining the proba-
bilistic estimate of the ground truth of slot-values 
in a real crowd-sourcing system. However, it is 
important not only to consider the ground truth 
probabilities per se, but also on how many con-
tributing users the estimate is based and the qual-
ity of information obtained. We will explore the-
se two issues in future work. 
We have observed that through open-ended 
prompts, the system could potentially collect a 
large amount of details about the visual scenes. 
Since we did not use any automatic interpretation 
of these answers, we transcribed key concepts in 
participants? speech in order to obtain an esti-
mate of this. However, it is not obvious how to 
quantify the number of concepts. For example, 
we have learned that in Figure 2, at the junction 
ahead, there is: a traffic-sign, a speed-limit sign, 
a sign with yellow color, a sign with red color, a 
sign with red boarder, a sign that is round, a sign 
with some text, the text says 50. These are details 
obtained in pieces from various participants. 
Looking at Figure 2 one can see that these pieces 
when put together refer to the speed-limit sign 
mounted on the traffic-signal at the junction. 
How to assimilate these pieces together into a 
unified concept is a task that we have left for fu-
ture work. 
Acknowledgement 
We would like to thank the participants of the in-
lab crowd-sourcing experiment. This work is 
supported by the EIT KIC project 
?CityCrowdSource?, and the Swedish research 
council (VR) project Incremental processing in 
multimodal conversational systems (2011-6237).  
Reference 
Bartie, P. J., & Mackaness, W. A. (2006). Develop-
ment of a Speech-Based Augmented Reality Sys-
tem to Support Exploration of Cityscape. Transac-
tions in GIS, 10(1), 63-86. 
Boye, J., Fredriksson, M., G?tze, J., Gustafson, J., & 
K?nigsmann, J. (2014). Walk This Way: Spatial 
Grounding for City Exploration. In Mariani, J., 
Rosset, S., Garnier-Rizet, M., & Devillers, L. 
9
(Eds.), Natural Interaction with Robots, Knowbots 
and Smartphones (pp. 59-67). Springer New York. 
Dickens, L., & Lupu, E. (2014). Trust service final 
deliverable report. Technical Report, Imperial Col-
lege, UK. 
Haklay, M., & Weber, P. (2008). OpenStreetMap: 
User-Generated Street Maps. IEEE Pervasive 
Computing, 7(4), 12-18. 
Janarthanam, S., Lemon, O., Liu, X., Bartie, P., 
Mackaness, W., Dalmas, T., & Goetze, J. (2012). 
Integrating Location, Visibility, and Question-
Answering in a Spoken Dialogue System for Pe-
destrian City Exploration. In Proceedings of the 
13th Annual Meeting of the Special Interest Group 
on Discourse and Dialogue (pp. 134-136). Seoul, 
South Korea: Association for Computational Lin-
guistics. 
Krug, K., Mountain, D., & Phan, D. (2003). Webpark: 
Location-based services for mobile users in pro-
tected areas.. GeoInformatics, 26-29. 
Parent, G., & Eskenazi, M. (2011). Speaking to the 
Crowd: Looking at Past Achievements in Using 
Crowdsourcing for Speech and Predicting Future 
Challenges. In INTERSPEECH (pp. 3037-3040). 
ISCA. 
Raykar, V. C., Yu, S., Zhao, L. H., Jerebko, A., Flor-
in, C., Valadez, G. H., Bogoni, L., & Moy, L. 
(2009). Supervised Learning from Multiple Ex-
perts: Whom to Trust when Everyone Lies a Bit. In 
Proceedings of the 26th Annual International Con-
ference on Machine Learning (pp. 889-896). New 
York, NY, USA: ACM. 
Ross, T., May, A., & Thompson, S. (2004). The Use 
of Landmarks in Pedestrian Navigation Instructions 
and the Effects of Context. In Brewster, S., & Dun-
lop, M. (Eds.), Mobile Human-Computer Interac-
tion - MobileHCI 2004 (pp. 300-304). Springer 
Berlin Heidelberg. 
Skantze, G., & Al Moubayed, S. (2012). IrisTK: a 
statechart-based toolkit for multi-party face-to-face 
interaction. In Proceedings of ICMI. Santa Monica, 
CA. 
Tom, A., & Denis, M. (2003). Referring to Landmark 
or Street Information in Route Directions: What 
Difference Does It Make?. In Kuhn, W., Worboys, 
M., & Timpf, S. (Eds.), Spatial Information Theo-
ry. Foundations of Geographic Information Sci-
ence (pp. 362-374). Springer Berlin Heidelberg. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
10
Appendix A 
The table below lists slots (= landmark attributes) and the corresponding wh? and yes?no system questions. For 
attributes marked with * the dialogue manager switches to open-ended interaction mode. 
 
Slot (=attribute ) System wh? questions System yes?no questions 
Visible: whether a particular 
landmark is visible from this 
view. 
? Do you see a building on the far left? 
? Do you see another building in front of 
you? 
? Is there a junction on the right? 
? Do you see a traffic-signal ahead? 
? Is the building on the far right visible to 
you? 
? I think there is another building in front of 
you, do you see it? 
? Can you see the junction on the right? 
? Are you able to see the traffic-signal 
ahead? 
Color of the building 
? What color does the building have? 
? What color is the building? 
? I think this building is red in color, what do 
you think? 
? Does this building have red color? 
Size of the building (in num-
ber of stories) 
? How many floors do you think are 
there in this building 
? How many stories is this building 
? I think there are six floors in this building, 
what do you think? 
? Is this building six storied? 
Color of the building?s roof 
? What color does the roof of this build-
ing have? 
? What color is the roof of this building? 
? I think the roof of this building is orange in 
color, what do you think? 
? Do you think that the roof of this building 
is orange? 
Signs or ornamentation on the 
building 
? Do you see any signs or decorations 
on this building? 
? I think there is a sign or some decoration 
on this building, do you see it? 
? There may be a sign or a name on this 
building, do you see it? 
Shops or restaurants in the 
building 
? Are there any shops or restaurants in 
this building? 
? I am informed that there are some shops or 
restaurants in this building, is it true? 
? I think there are some shops or restaurants 
in this building, what do you think? 
Signs at landmarks 
? Are there any important signs at the 
junction/crossing? 
? I believe there is a sign at this junc-
tion/crossing, do you see it? 
? Do you see the sign at this junc-
tion/crossing? 
*Description of sign  
? Could you describe this sign? 
? What does this sign look like? 
? Does the sign say something? 
? Could you describe this sign? 
? What does this sign look like? 
? Does the sign say something? 
*Signs in the visual scene 
 
? Are there any important signs in this 
scene that I may have missed? 
? Have I missed any relevant signs in 
this scene? 
? There are some important signs in this 
scene that could be useful for my 
knowledge, am I right? 
? I am informed that there are some signs in 
this scene that are relevant for me, is it 
true? 
*Landmarks in the visual sce-
ne 
 
? Are there any other important build-
ings or relevant structures in this scene 
that I should be aware of? 
? Is there anything particular in this 
scene that I should be familiar with? 
? Have I missed any relevant buildings 
or landmarks in this scene? 
? I am informed that there are some im-
portant landmarks or structures in this sce-
ne that I should be aware of, is it true? 
? I have been told that there are some other 
things in this scene that I are relevant for 
me, is it true? 
? I believe I have missed some relevant 
landmarks in this scene, am I right? 
*Description of unknown 
landmarks e.g. shop, restau-
rant, building, etc. 
? Could you describe it? 
? Could you describe them? 
? How do they look like? 
? Could you describe it? 
? Could you describe them? 
? How do they look like? 
 
11
