Relations between Inflectional and Derivation Patterns
Karel Pala
Faculty of Informatics
Masaryk University Brno
pala@fi.muni.cz
Radek Sedla?c?ek
Faculty of Informatics
Masaryk University Brno
rsedlac@fi.muni.cz
Marek Veber
Faculty of Informatics
Masaryk University Brno
mara@fi.muni.cz
Abstract
One of the main goals of this paper is
to describe a formal procedure linking
inflectional and derivational processes
in Czech and to indicate that they can
be, if appropriate tools and resources
are used, applied to other Slavonic lan-
guages. The tools developed at the NLP
Laboratory FI MU, have been used,
particularly the morphological analyser
ajka and the program I par for pro-
cessing and maintaining the morpholog-
ical database.
1 Introduction
In this paper we report on an exploration of the
relations between inflection and word derivation
(WD) in Czech. At first the inflectional morphol-
ogy has to be mentioned which deals with forma-
tion of word forms by inflection, i. e. by mor-
phological processes like the declension of nouns,
adjectives, pronouns and numerals, the conjuga-
tion of verbs, and also forming degrees of ad-
jectives and adverbs. The inflectional morphol-
ogy (in Czech) is formally quite well described
and at present we have reliable software tools at
our disposal that make it possible both to generate
and recognise arbitrary Czech word forms. They
are ajka a morphological analyser and genera-
tor (Sedla?c?ek and Smrz?, 2001) and I par a pro-
gram for morphological database (Veber, 2002).
The second area is derivational morphology,
i. e. word derivation as such ? it describes the pro-
cesses of the derivation of new words (one word
expressions) as distinct from basic ones (word
bases). These processes operate on the morpheme
level whose results follow from the ways of com-
bining morphemes (prefixes, stems or roots, in-
fixes, suffixes) using suffixation, prefixation and
stem alterations (infixation). We have to bear in
mind that the consequences of these formal pro-
cesses have a semantic nature.
The relations between the WD processes and in-
flectional morphology have been extensively stud-
ied in Czech linguistic literature, see e. g. (Dokulil,
1962; Karl??k et al, 1995; Petr, 1986) where one
may find informal descriptions of the WD pro-
cesses using terms like ?fundace? (basic deriva-
tion), as well as mutation, transposition, modifi-
cation, adaptation, and others.
The most interesting linguistic analyses link the
derivation patterns with the inflectional ones. For
example, in Karl??k (1995) it is pointed out that the
nouns with the suffix -tel having agentive meaning
belong to the inflectional paradigm muz? (man). In
other words, it is possible to say that some inflec-
tional patterns determine the sets of derivational
suffixes forming semantically consistent groups of
nouns.
In this paper we set it as our task to map the re-
lations between inflectional and word derivational
patterns. In comparison with previous research
we present the exploration of a large collection
of data: our stem dictionary for Czech contains
385,066 items. The association of selected in-
flectional and WD patterns has been performed
semi-automatically with the tool I par and the
Czech morphological database which contains all
the necessary information about the inflectional
paradigms in Czech (2,042 paradigms for all 10
POS).
The WD relations as they are described in the
linguistic WD theories can be, after some modifi-
cations, appropriately linked to the semantic rela-
tions as they are used in contemporary ontologies
and then applied within the inference engines that
form a necessary part of the natural language pro-
cessing mechanisms.
However, it is true that algorithmic descriptions
of WD relations have been worked out only re-
cently and they do not cover the WD processes in
all their complexity but just at the basic level.
2 Inflectional analysis
The inflectional analysis is a part of the complex
morphemic decomposition of a word and its first
task is to identify in a given word form the stem
and ending. If the word form is not a lemma (ba-
sic form of the word) it is necessary to associate
the stem with its respective ending.
It has to be kept in mind that the derivational anal-
ysis deals only with lemmata and not with the in-
dividual word forms.
For the purpose of this work we perform
inflectional analysis with the tool (program)
ajka (Sedla?c?ek, 1999) which is further devel-
oped in the NLP Laboratory (Sedla?c?ek and Smrz?,
2001) at FI MU. It is also used as a standard tool
for lemmatization (identification of the basic word
forms) and as a morphological tagger.
3 The Basic WD Relation = ?fundace?
In the Czech WD theory all words belonging to a
given word stock are classified either as motivated
or non-motivated.
For motivated words we are able to describe
their meaning using another word or words, e. g.
cvic?is?te? (exercising ground, drill square) is a place
where exercising is done. Non-motivated words
cannot be described in the same way. Their mean-
ing consists only in signifying the thing, which
is why they are sometimes called words-signs, as
e. g. stu?l (table), tra?va (grass). Thus it is obvious
that when making WD analyses we are more inter-
ested in motivated words, since only they display
the derivational structure from which we are able
to reconstruct the process of their formation.
Formation of motivated word follows the ba-
sic WD relation called ?fundace? (Dokulil, 1962).
When we find the ?fundace?-relation for all moti-
vated words we obtain a complex of relations that
form a hierarchical structure. In WD theory this
structure is usually called word derivation nest,
word derivation lattice and word derivation se-
quence. Word derivation nests (WDN) will be our
principal focus.
WDN can be defined as a set of all related
words that gather around a common stem. The
core of WDN is a root of the non-motivated word
and other words in WDN are derived from it ei-
ther directly as in led (ice)?led-ovy? (icy) or indi-
rectly through another related word. In this way
word derivation sequences are created, such as led
(ice)?led-ovy? (icy)?ledov-ec (glacier)?ledovc-
ovy? (glacial).
The appropriate formal apparatus for repre-
senting these relations and structures are graphs.
For this purpose the special types of graphs (see
Fig. 1), particularly graph-trees are used which
further link up into forests. Strictly speaking we
are dealing mainly with forests.
The tree nodes are labelled with lemmata, and
the next node is created dependent on its predeces-
sor. The individual trees then represent the WDN,
the WD unions have just one level, subtrees and
sequence correspond to the paths in the graph.
4 The Semantic Aspects of the Basic WD
Relation
The semantic component of the ?fundace?-
relation consists in the fact that meaning of
?funded? words can be derived from the mean-
ing of the ?funding? one, that they are semanti-
cally linked and that language users know these
relations and use them in understanding language
and also in enriching their knowledge about the
universe. Thus uc?itel (teacher) je ten, kdo uc??? (is
the one who teaches), zoubek (small tooth) je maly?
zub (is a tooth of small size). The meaning that
follows from the WD relations is usually labelled
as word derivation or internal meaning. This is a
rather narrow point of view, typical of linguistic
WD theories, since there is no reason to introduce
separate semantic relations ? they are the same as
other semantic relations, for example the Internal
Language Relations defined within EuroWordNet
1, 2 (Vossen, 1998).
For the computer processing of the word mean-
ings, it is necessary to bear in mind that seman-
tic relations have a common nature irrespective of
the forms by which they are expressed. From this
point of view, it is obvious that there is no rele-
vant difference between WD meaning and ?nor-
mal? lexical meaning as it is treated within the
framework of semantic networks that are nowa-
days so popular in NLP and Language Engineer-
ing. Thus WDN can be understood as semantic
networks of a special sort that will soon become
relevant in the area of knowledge representation.
5 Word Derivation Analysis
The purpose of WD analysis is to find out the WD
structure of the ?funded? word by applying the ba-
sic WD relation, i. e. to find out its WD base and
the respective formant (see below).
WD base can be defined as the part of the
?funded? word that is taken over from the ?fund-
ing? word. Typically it is an identical string that
occurs in both ?funded? and ?funding? word ?
various phonological alternations can take place
here, of course. For example, pole (field)?pol-n??
(field-ADJ).
The procedure works in the following way: an
element is added to the WD base of the word (typ-
ically root or stem) and together they form a new
word. The added element is usually called formant
in Czech WD theory (Dokulil, 1962) and can be
formed by one or more morphemes. A formant
can be
? a suffix kotel-na (boiler room), which classi-
fies a word as belonging to a more general se-
mantic group (here the Czech suffix -na with
the inflectional morpheme -a at its end cre-
ates the names of places),
? the ending zka?z-a (destruction) where the in-
flectional morpheme also operates as deriva-
tional morpheme or the derivational mor-
pheme can be considered to be empty,
? prefix s-lepit (glue back together) which just
modifies the meaning of the word but does
not change its POS and inflectional paradigm.
Compound formants are also possible, and may
consist either of a prefix combined with suffix,
e. g. in pr???-ruc?-n?? (reference) or prefix combined
with an ending pr?ed-me?st-?? (suburb).
6 Relations between Inflection and
Derivation
The data that can be found in the existing re-
sources, e. g. (Karl??k et al, 1995) are limited in
number ? they contain selected examples only and
show only the main types of WD processes. In-
formation about the functional load of the individ-
ual suffixes is either missing or is only outlined by
means of expressions like ?very frequent?, ?fre-
quent?, ?less frequent? without giving any num-
bers.
To explore the situation more adequately we
used a more representative collection of data, par-
ticularly the morphological database I par to-
gether with the stem dictionary which is a part of
the morphological analyser ajka.
In other words, all the items in the stem dic-
tionary are associated with their respective inflec-
tional paradigm(s), e. g. for nouns there are 746 in-
flectional paradigms that presently cover 131,188
noun stems. The number of the noun paradigms
looks quite large but one should bear in mind that
in our algorithmic description of Czech inflection
we deal with a detailed hierarchical subclassifica-
tion of the noun paradigms which, however, is just
based on the 14 main paradigms as they are given
in standard grammars of Czech.
The present data allow us to find the functional
load defined as the number of nouns with the given
suffix and particular semantic feature, e. g. agen-
tive, instrument or property etc. First we have to
know for a certain suffix how many lemmata oc-
cur with the given suffix, Table 1 shows that -a?k
has 1,379 occurrences. However, it is more im-
portant to know the specific semantic features that
indicate which semantic classes the nouns ending
with -a?k belong to ? this is obtained in the pro-
cess of finding which nouns belong in which in-
flectional paradigms. If we look at the tags we can
see that Czech nouns with the suffix -a?k fall into
two large groups ? those denoting agentives and
other animate beings (total 733 nouns) and those
denoting inanimate things such as instruments and
others (total 633, not classified 13). In the case
of -a?k its functional load is distributed evenly.
freq. % pattern gender sem. feature
641 47.1 vlk MANIM. agentives
326 23.6 flok MINAN.
263 19.1 krk MINAN.
77 5.6 ?Ste?rba?k MANIM. family names
16 1.2 dupa?k MINAN.
10 0.7 Azte?k MANIM. names of tribes
10 0.7 hr?iba?k MINAN.
7 0.5 pulc???k MINAN. names of fungi
6 0.4 koza?k MINAN.
5 0.4 duba?k MINAN.
5 0.4 Batak MANIM. ethnic groups
13 1.0 various not classified
? 1,379
Table 1: SUBST MASK, suffix: -a?k
freq. % pattern gender sem. feature
908 93.9 uc?itel MANIM. agentives
15 1.6 bez MINAN. not classified
11 1.1 mocnitel MINAN. math. expr.
8 0.8 souc?initel MINAN. math. expr.
7 0.7 hotel MINAN. hotels
5 0.5 c??l MINAN. not classified
4 0.4 stroj MINAN. not classified
4 0.4 soute?z? FEMIN. not classified
3 0.3 obyvatel MANIM. inhabitants
2 0.2 stras?pytel MANIM. not classified
? 967
Table 2: SUBST, suffix: -tel
7 Rules for WD Processes
So far we have been talking about the derivation of
word forms in terms of morphemes, stems, roots,
lemmata, etc. More formally, WD processes em-
ploy strings of letters (morphemes) carrying gram-
matical and lexical information. It can be observed
that the WD processes have quite a regular nature,
thus one can express them by means of certain
rules (WD patterns)
WD is a hierarchically structured process,
which will be reflected in the construction of the
rules (WD patterns) ? we will build them as cas-
cades going from simpler to more complicated
patterns.
We start from a linguist?s hypothesis which de-
fines a pattern capturing the changes between the
word forms and other constraints on the form
of grammatical tags associated with the searched
entries. Then we can automatically look up n-
The following n-tuple has to be searched for:
form POS-tag condition
1. S-zace SUBST FEM
2. S-sticky? ADJ
3. S-sta SUBST MAS ANIMAL
4. S-smus SUBST MAS UNANIMAL
where ?S-? is arbitrary but has to be an identical
string for all members of the n-tuple
Table 3: searching the relations, verifying hy-
potheses
tuples of the entries in the existing morphological
database (using the I par tool), where
1. all the members (=entries) exist in the
database;
2. the members of n-tuple fulfil the required hy-
pothesis, i. e. the changes between the strings
belonging to the individual members of the
n-tuple are described in given pattern and en-
tries correspond to the additional constraints.
Suppose that there is an algorithm (see Sec-
tion 7.1) which in the respective morphological
database will find the n-tuples (see Table 4) match-
ing the hypothesis formulated by a linguist (see
Table 3). The linguist can take the derived list of
n-tuples and determine which n-tuples are correct
and which not. The list of the positive examples
will arise together with the list of exceptions not
matching the formulated hypothesis, e. g. pr???t ?
pr???tel, word form pr???tel (friend) is derived from
?pr?a?t (to wish sb well)?, not ?pr???t se (to argue
with sb)?.
It is now clear that by using a hierarchical con-
nection of the new pattern to the original one (for
the individual members of the n-tuple) it is pos-
sible to derive from a single entry not only the
neighbouring entries in the n-tuple but also other
word forms (generated from the entries included
in the n-tuple by means of the respective original
patterns).
If the changes in the word form put into effect
by the (new) pattern express1 a well-defined se-
mantic relation, the entries can be ?virtualized?,
1for the newly generated word form it is also possible to
derive algorithmically (infer) lexical meaning
1st member 2nd member 3rd member 4th member
Patterns: ru?z?e otrocky? P husita P komunismus
realizace realisticky? realista realismus
centralizace centralisticky? centralista centralismus
humanizace humanisticky? humanista humanismus
idealizace idealisticky? idealista idealismus
komunizace komunisticky? komunista komunismus
. . . . . . . . . . . .
Patterns: ru?z?e staror?ecky? P husita P komunismus
romanizace romanisticky? romanista romantismus
spiritualizace spiritualisticky? spiritualista spiritualismus
synchronizace synchronisticky? synchronista synchronismus
kolektivizace kolektivisticky? kolektivista kolektivismus
modernizace modernisticky? modernista modernismus
. . . . . . . . . . . .
Table 4: searching of the relations, verifying hypotheses, output
thus we do not need to keep all entries in the lex-
icon but only those entries which are basic (moti-
vating) word forms for the neighbouring entries of
the found n-tuples.
The entries that are thereby eliminated from the
lexicon can be constructed according to the new
pattern from the basic (motivating) word form.
The original word forms can be determined algo-
rithmically and their original lexical meaning can
be inferred as well.
We will reduce the lexicon using the description
of the WD process which yields the predictable
changes in the semantics of the derived entries.
The WD process can be illustrated by the Fig. 1.
It can be seen that the sub-entries humanizace (hu-
manisation), humanisticky (humanistically ADV),
humanisticky? (humanistic ADJ), humanistc?in (hu-
manist?s FEM POSS ADJ), humanistka (human-
ist FEM), humanistu?v (humanist?s MAS POSS
ADJ), humanista (humanist MAS), humanismus
(humanism), can be assigned:
1. either to the respective infl. paradigms:
humanizace:ru?z?e
humanisticky:otrocky
humanisticky?:otrocky?
humanistc?in:matc?in
humanistka:matka
humanistu?v:otcu?v
humanista:husita
humanismus:komunismus
2. or to:
humanizace:ru?z?e
humanisticky?:otrocky? P
humanista:husita P
humanismus:komunismus
3. or to a deriv. pattern (meta-pattern):
humanismus:komunismus P
In the second and third cases, the reduction
of the lexicon can be observed. The pattern
komunismus P derives the word forms by ex-
changing the string at the end of the basic (moti-
vating) word form:
smus ? zace, sticky, sta, smus
and the corresponding change of the attributes of
the constructed tag.
For an implementation of these WD patterns, a
parallel with Finite State Automata (FST) is use-
ful. The property of chaining (Roche and Schabes,
1997) is very suitable here ? it allows us to build
WD patterns as hierarchical modules. This prop-
erty makes it possible to limit the duplicity of the
stored information and increase their lucidity.
7.1 WD Relation Mining
We explained how to extend the morphological
database employing the regular changes of word
forms that can be observed in the course of the
WD processes (Osolsobe? et al, 2002). We have
shown that if the WD processes are described by
the rules it is possible to reduce our stem dictio-
nary and eventually to obtain a dictionary of roots.
To make the process of searching for the dis-
crete description of WD processes simpler we
have implemented an algorithm that looks up the
relations between the strings corresponding to the
individual entries in the morphological database.
The input for the algorithm is a description of
the variations of the individual word forms to-
gether with conditions placed on the attributes of
the respective grammatical tags.
komunismus P
humani?smus
komunismus
humanismus
husita P
humanist?a
husita
humanista
otcu?v
humanistu?v
matka P
humanist?ka
matka
humanistka
matc?in
humanistc?in
otrocky? P
humanistick?y?
otrocky?
humanisticky?
otrocky
humanisticky
ru?z?e
humanizace
.....................................................................
..
smus
.........................
.sta
................................
..
a
..........................
.u?v
.........
.........
.........
......
..ka .....................................
ka
..............
.........
..c?in
....
....
....
....
.........sticky
.................
.
y?
.................
.y
....
....
....
....
....
....
....
....
....
....
....
....
....
....
....
....
.......
zace
Figure 1: Using the derivational pattern to reduce the stem dictionary
To describe the variations of the word forms we
will use:
? variables $1, $2, . . . (values ? ??),
? constants / ?affixes? : A1,1, A1,2, . . . ? ??
? concatenation operator ?
? strings Si ? {Ai,1, Ai,2, . . .$1,$2, . . .}?
? conditions ? constraints on the values of
given attributes, eventually a determination
whether the given word form has to be
present in the database: C1, C2, . . .
7.1.1 Input
The task assumes:
? n . . . number of the word forms searched for,
? n-tuple: (S1, C1) . . . (Sn, Cn).
The Si strings should be written in such a way
so as not to contain the pairs constant ? constant,
variable ? variable standing adjacent.
? two neighbouring constants can be merged
into one
? two variables can be separated by  constant
(empty string).
? if the variable at beginning is required, or at
the end of the string, then we set Ai,1, or Ai,m
? 
Each string Si thus can be given without loosing
any generality in the following way:
Si ? Ai,1 ? $1?Ai,2 ? $2?
Ai,3 ? . . .? $m?Ai,m+1 (1)
We know that Ai,j are constants and $j vari-
ables which can take values from ??. For an arbi-
trary string Si, a regular grammar can be written
(see Eq. 2).
S ? Ai,1$1N1
N1 ? Ai,2$2N2
. . .
Nm ? Ai,m+1
$1| . . . |$m ? E
E ? a|aE|b|bE| . . .
where E ? ??
(2)
It can be seen that for each string Si a non-
deterministic transducer can be constructed that
takes a word form on the input and on the output,
it produces a set of all acceptable evaluations of
the variables $1 . . .$m, i. e. a set (possibly empty)
of the m-tuples of members of set ??.
7.1.2 The Algorithm
First we have to select the pairs (Si, Ci) for
which the requirement in the condition states that
their corresponding word forms have to occur in
the database. Those word forms, strings and pairs
will be called located. The word forms that we
can determine from the located ones after substi-
tution values for the variables in the strings will be
labelled as inferred.
We can speak here about free and bound occur-
rences of the variables. Free variables will be de-
termined during the computation of the same au-
tomaton in which they take place. Bound vari-
ables are dependent on the computation of other
automata. The values are instantiated for bound
variables before the computing the automaton in
which the variables occur. Thus we can work with
them in a given automaton as with the constants ?
this simplifies the automaton.
When a given word form is accepted by the
transducer (for string Si) we obtain the respective
evaluation variables included in Si as an output. If
the same variables occur also in other strings they
can be substituted (instantiated) by the values.
Thus step by step we will construct the respec-
tive FS automata for located strings Si using the
instantiation of the variables. If the automaton
does not contain any free variables it is obvious
that the respective pair is inferred (it can be lo-
cated at the same time) ? these will be labelled as
inferred+located).
The order in which the individual automata will
be applied can be optimised. A certain part of the
state space being searched can be eliminated in ad-
vance based on conditions Ci, i. e. it is enough
to search/eliminate entries associated with the pat-
terns which guarantee/eliminate some attributes of
the tag.
We suppose that by means of located strings all
the variables used in the inferred strings can be in-
stantiated in such a way that we will be able to de-
termine correctly inferred word forms relying only
on the knowledge of the located word forms, i. e.
in the cases where the inferred strings do not con-
tain free variables. In the opposite case the algo-
rithm has to stop prematurely.
The optimisation will determine the order in
which the individual automata containing free
variables will be applied.
We will start with the first automaton following
the order determined by the optimisation. Step by
step we will go through all the entries and then
for all possible evaluations we will instantiate the
variables and continue with searching the entries
acceptable for the next automaton (according to
the given ordering), i. e. we look for the next ele-
ment of the respective n-tuple.
If we succeed in the instantiation of all vari-
ables and determine all inferred word forms and if
all inferred+located word forms are found in the
database then the currently determined n-tuple can
be sent to the output.
8 The First Results from our Data
Table 5 displays the individual steps taken dur-
ing forming the respective WD nest. The step A
(see Table 5) consisted in the derivation of mas-
culine possessives using suffix -u?v. It is obvious
that this derivation is regular, the number of lem-
mata has not changed ? all of them have been as-
signed to the paradigm for the possessives otcu?v
(father?s). In the step B the gender of noun is
changed from masculine to feminine using suf-
fix -ka. Moreover, in this step the paradigms
neume?tel a Koca?b nM have been removed. Also
the number of lemmata assigned to the paradigm
uc?itel (teacher) has been reduced to half, i. e. from
908 to 454. This means that according to our data
(our morphological database) half of the agentives
cannot form the feminine counterpart and this re-
sult can be expected to be confirmed by examin-
ing a larger corpus. The step C is again regu-
lar ? it consists in the derivation of feminine pos-
sessives using suffix -in with a number of lem-
mata not being changed. In the step D the ad-
jectives are formed by means of suffix -sky? and
this process is less regular. From the possible 454
lemmata belonging to the paradigm uc?itel the ad-
jectives are derived only from 113+21+16=150.
Moreover, these adjectives split into three adjec-
tive paradigms praz?sky? (Prague), spolec?ensky? (so-
cial) and kremz?sky? (Crems) depending on whether
they form a comparative and adverb or not. The
following step is again regular ? it involves the
derivation of adverbs from adjectives by shorten-
ing the last vowel from y? to y. It can be seen
that from the adjectives belonging to the paradigm
kremz?sky? such adverbs cannot be formed at all.
The step E is irregular as well and it involves the
derivation of the nouns from the respective adjec-
tives by replacing the suffix -sky? for -stv??.
9 Conclusions
The purpose of the paper is to show how se-
lected word derivation relations in Czech can be
described using the morphological analyser ajka
and the program I par which works with the
Czech morphological database. The Czech data
necessary for this description are: stem dictionary
used by ajka containing 385,066 Czech stems
908 uc?itel,otcu?v
3 obyvatel,otcu?v
2 pr???tel,otcu?v
1 neume?tel,otcu?v
1 Koca?b nM,otcu?v
A
?
454 uc?itel,otcu?v,matka
2 obyvatel,otcu?v,matka
2 pr???tel,otcu?v,matka B?
454 uc?itel,otcu?v,matka,matc?in
2 obyvatel,otcu?v,matka,matc?in
2 pr???tel,otcu?v,matka,matc?in
C ?
113 uc?itel,otcu?v,matka,matc?in,praz?sky?,praz?sky
21 uc?itel,otcu?v,matka,matc?in,spolec?ensky?,spolec?ensky
2 obyvatel,otcu?v,matka,matc?in,praz?sky?,praz?sky
D
?
113 uc?itel,otcu?v,matka,matc?in,praz?sky?
21 uc?itel,otcu?v,matka,matc?in,spolec?ensky?
16 uc?itel,otcu?v,matka,matc?in,kremz?sky?
2 obyvatel,otcu?v,matka,matc?in,praz?sky?
E ?
46 uc?itel,otcu?v,matka,matc?in,praz?sky?,praz?sky,staven??
19 uc?itel,otcu?v,matka,matc?in,spolec?ensky?,spolec?ensky,staven??
Table 5: WD nest for -tel
belonging to the 10 parts of speech, the Czech
morphological database comprising 2,042 inflec-
tional paradigms and the set of the Czech suffixes
mentioned in this paper (-tel, -a?k, -u?v, -ka, -in,
-sky?, -cky?, -sky, -cky, -stv??, -ismus, -ista, -izace).
Within this task we also demonstrated, using the
selected examples, how the inflectional paradigms
can be employed to create more general but less
regular word derivation patterns, how both can be
linked together and how WD patterns can be used
to describe the selected WD processes in an algo-
rithmic way. This we regard as a relevant contribu-
tion to the theory. In our opinion these examples
are general enough to show that the whole WD
system for Czech can be grasped successfully in
this way.
In this research we are working with Czech data
only, but we firmly believe that if similar data for
Russian, Slovak, Croatian or Serbian etc., were
supplied similar results would be arrived at. It is,
of course, obvious that different WD rules have to
be formulated for other Slavonic languages but if a
similar system of inflectional paradigms were used
and the corresponding groups of suffixes as well,
using tools like ajka and I par would enable
the mapping of word derivation relations accord-
ingly.
The continuation of this research will lead to
building a Czech Derivation Dictionary integrated
with WD rules and thus later yielding a WD au-
tomaton for Czech.
Acknowledgement
This work was supported by Ministry of Educa-
tion, Research Program CEZ:J07/98:143300003.
References
Milos? Dokulil. 1962. Tvor?en?? slov v c?es?tine? 1 (Word
Derivation in Czech). Nakladatelstv?? ?CSAV, Praha.
In Czech.
Petr Karl??k, Marek Nekula, and Zdenka Rus??nova?.
1995. Pr???ruc?n?? mluvnice c?es?tiny (Reference Gram-
mar of Czech). Nakladatelstv?? Lidove? noviny, Praha.
In Czech.
Lauri Karttunen and Kent Wittenburg. 1983. A Two-
Level Morphological Analysis of English. In Texas
Linguistic Forum, volume 22, pages 217?228.
Kla?ra Osolsobe?, Karel Pala, Radek Sedla?c?ek, and
Marek Veber. 2002. A Procedure for Word Deriva-
tional Processes Concerning Lexicon Extension in
Highly Inflected Languages. In Proceedings of the
Conference LREC2002, volume 3, pages 998?1003,
Las Palmas, May 29-31. ELRA.
Jan Petr. 1986. Mluvnice c?es?tiny II. (Grammar of
Czech). Academia, Praha. In Czech.
Emmanuel Roche and Yves Schabes, editors. 1997.
Finite-State Language Processing. MIT Press.
Radek Sedla?c?ek. 1999. Morfologicky? analyza?tor
c?es?tiny (Morphological Analyser of Czech). Mas-
ter?s thesis, FI MU, Brno. In Czech.
Radek Sedla?c?ek and Pavel Smrz?. 2001. A New Czech
Morphological Analyser ajka. In Proceedings of
TSD 2001, pages 100?107, Berlin. Springer-Verlag.
Marek Veber. 2002. Na?stroje pro textove? korpusy a
morfologicke? databa?ze (Tools for Text Corpora and
Morphological Databases). Ph.D. thesis, FI MU,
Brno. In Czech.
Piek Vossen. 1998. Set of Common Base Concepts in
EuroWordNet-2. Technical Report 2D001, Depart-
ment of Computational Linguistics, Amsterodam,
October.
Proceedings of the 5th Workshop on Important Unresolved Matters, pages 97?104,
Ann Arbor, June 2005. c?2005 Association for Computational Linguistics
Verb Valency Semantic Representation for Deep Linguistic Processing 
 Ale? Hor?k1, Karel Pala1, Marie Du??2, Pavel Materna1  
 1: Faculty of Informatics, Masaryk University 
Botanicka 68a 
602 00 Brno 
Czech Republic 
{hales,pala}@fi.muni.cz 
2: VSB-Technical University of Ostrava 
17.listopadu 15 
708 33 Ostrava-Poruba 
Czech Republic 
marie.duzi@vsb.cz 
 
 
 
Abstract 
In the paper, we describe methods for 
exploitation of a new lexical database of 
valency frames (VerbaLex) in relation to 
Transparent Intensional Logic (TIL). We 
present a detailed description of the 
Complex Valency Frames (CVF) as they 
appear in VerbaLex including basic 
ontology of the VerbaLex semantic roles. 
TIL is a typed logical system developed for 
natural language semantic representation 
using TIL logical forms known as 
constructions. TIL is well suited to handle 
the difficult language phenomena such as 
temporal relations, intensionality and 
propositional attitudes. Here we make use 
of the long-term development of the 
Normal Translation Algorithm aimed at 
automatic translation of natural language 
sentences into TIL constructions. 
We examine the relations between CVFs 
and TIL constructions of predicate-
argument structures and discuss the 
procedure of automatic acquisition of the 
verbal object constructions. The 
exploitation of CVFs in the syntactic 
parsing is also briefly mentioned. 
1 Introduction 
In the paper we propose a method to integrate the 
logical analysis of sentences with the linguistic 
approach to semantics, exploiting the complex 
valency frames (CVFs) in the VerbaLex verb 
valency lexicon, see (Hlav??kov?, Hor?k, Kadlec 
2006). To this end we first present a brief survey of 
the logic we are going to use, namely Transparent 
Intensional Logic (TIL), which was originated by 
P. Tich? (Tich? 1988). Theoretical aspects of TIL 
were further developed in particular by P. Materna 
(Materna 1998) and also by co-authors of this 
paper (see, Materna, Du?? 2005, Hor?k 2002). A 
question may be asked why we do not exploit first 
order predicate logic (PL1) where some of the 
presented problems have already been explored 
and PL1 has been used to represent logical forms. 
It is a well established fact that PL1 is not able to 
handle systematically the phenomena like 
propositional verbs (which, of course, appear in 
our valency frames), grammatical tenses and 
modalities (modal verbs and modal particles in 
natural language). On the other hand, since TIL 
works with types these problems either do not arise 
or they can be solved in an intuitive way (see Ti-
ch? 1988). 
In the second linguistic section we present CVFs 
by means of which the semantics of verbs in 
natural language such as Czech or English can be 
described.  
In Section 3 we show how CVFs describe the 
surface valencies of verbs (i.e. their respective 
morphological cases in Czech) as well as the 
semantics of their predicate-argument structure. 
Concerning the latter we make use of the deep 
semantic roles expressed by two-level labels based 
partly on the Top Ontology (EuroWordNet) and 
partly on the selected literals from Princeton 
WordNet. 
Since so far these two ways of description, namely 
the logical and linguistic one, have been treated 
separately, the task we set is to propose a method 
97
of their interrelation and coordination. Needless to 
say that both ways of description of verb semantics 
are useful.  
Hence we are going to show how to combine a 
logical description using mostly terms like types, 
individuals, classes, relations, propositions, or, in 
general, constructions of these entities, with the  
linguistic framework capturing the idiosyncratic 
semantic features of the verbs such as 
SUBS(liquid:1) or AG(person:1|animal:1).  
In Section 4 we adduce an example of the analysis 
of selected English and Czech verbs for which the 
above mentioned integration has been proposed.  
   
2 Basics of Transparent Intensional 
Logic 
In this Section we provide an introductory 
explanation of the main notions of Transparent 
Intensional Logic (TIL). For exact definitions and 
details see, e.g., Tich? (1988), Tich? (2004), 
Materna (1998), Materna (2004) and Materna, 
Du?? (2005). TIL  approach to knowledge 
representation can be characterised as the ?top-
down approach?. TIL ?generalises to the hardest 
case? and obtains the ?less hard cases? by lifting 
various restrictions that apply only higher up. This 
way of proceeding is opposite to how semantic 
theories tend to be built up. The standard approach 
(e.g. predicate logic) consists in beginning with 
atomic sentences, then proceeding to molecular 
sentences formed by means of truth-functional 
connectives or by quantifiers, and from there to 
sentences containing modal operators and, finally, 
attitudinal operators. 
Thus, to use a simple case for illustration, once a 
vocabulary and rules of formation have been laid 
down, semantics gets off the ground by analysing 
an atomic sentence as follows: 
 (1) ?Charles is happy?: Fa 
And further upwards: 
 (2) ?Charles is happy, and Thelma is 
grumpy?: Fa ? Gb 
 (3) ?Somebody is happy?: ?x (Fx) 
 (4) ?Possibly, Charles is happy?:  (Fa) 
 (5) ?Thelma believes that Charles is happy?: 
Bb (Fa). 
In non-hyperintensional (i.e., non-procedural) 
theories of formal semantics, attitudinal operators 
are swallowed by the modal ones. But when they 
are not, we have three levels of granularity: the 
coarse level of truth-values, the fine-grained level 
of truth-conditions (propositions, truth-values-in-
intension), and the very fine-grained level of 
hyper-propositions, i.e., constructions of 
propositions. TIL operates with these three levels 
of granularity. We start out by analysing sentences 
from the uppermost end, furnishing them with a 
hyperintensional1 semantics, and working our way 
downwards, furnishing even the lowest-end 
sentences (and other empirical expressions) with a 
hyperintensional semantics. That is, the sense of a 
sentence such as ?Charles is happy? is a hyper-
proposition, namely the construction of the 
denoted proposition (i.e., the instruction how to 
evaluate the truth-conditions of the sentence in any 
state of affairs). 
When assigning a construction to an expression as 
its meaning, we specify a procedural know-how, 
which must not be confused with the respective 
performancy know-how. Distinguishing 
performatory know-how from procedural know-
how, the latter could be characterised ?that a 
knower x knows how A is done in the sense that x 
can spell out instructions for doing A.? For 
instance, to know what Goldbach Conjecture 
means is to understand the instruction to find 
whether ?all positive even integers ? 4 can be 
expressed as the sum of two primes?. It does not 
include either actually finding out (whether it is 
true or not by following a procedure or by luck) or 
possessing the skill to do so.2  
Furthermore, the sentence ?Charles is happy? is an 
?intensional context?, in the sense that its logical 
analysis must involve reference to empirical 
parameters, in this case both possible worlds and 
instants of time. Charles is only contingently 
happy; i.e., he is only happy at some worlds and 
only sometimes. The other reason is because the 
analysans must be capable of figuring as an 
argument for functions whose domain are 
propositions rather than truth-values. Construing 
?Fa? as a name of a truth-value works only in the 
case of (1), (2) and (3). It won?t work in (5), since 
truth-values are not the sort of thing that can be 
                                                           
1  The term ?hyperintensional? has been introduced by 
Max Cresswell in Cresswell (1975). See also 
Cresswell (1985). 
2  For details on TIL handling knowledge see Du??, 
Jespersen, M?ller (2005). 
98
believed. Nor will it work in (4), since truth-values 
are not the sort of thing that can be possible. 
Constructions are procedures, or instructions, 
specifying how to arrive at less-structured entities. 
Being procedures, constructions are structured 
from the algorithmic point of view, unlike set-
theoretical objects. The TIL ?language of 
constructions? is a modified hyper-intensional 
version of the typed ?-calculus, where Montague-
like ?-terms denote, not the functions constructed, 
but the constructions themselves. Constructions 
qua procedures operate on input objects (of any 
type, even on constructions of any order) and yield 
as output (or, in well defined cases fail to yield) 
objects of any type; in this way constructions 
construct partial functions, and functions, rather 
than relations, are basic objects of our ontology.  
By claiming that constructions are algorithmically 
structured, we mean the following: a construction 
C ? being an instruction ? consists of particular 
steps, i.e., sub-instructions (or, constituents) that 
have to be executed in order to execute C. The 
concrete/abstract objects an instruction operates on 
are not its constituents, they are just mentioned. 
Hence objects have to be supplied by another 
(albeit trivial) construction. The constructions 
themselves may also be only mentioned: therefore 
one should not conflate using constructions as 
constituents of composed constructions and 
mentioning constructions that enter as input into 
composed constructions, so we have to strictly 
distinguish between using and mentioning 
constructions. Just briefly: Mentioning is, in 
principle, achieved by using atomic constructions. 
A construction is atomic if it is a procedure that 
does not contain any other construction as a used 
subconstruction (a constituent). There are two 
atomic constructions that supply objects (of any 
type) on which complex constructions operate: 
variables and trivializations.  
Variables are constructions that construct an object 
dependently on valuation: they v-construct, where 
v is the parameter of valuations. When X is an 
object (including constructions) of any type, the 
Trivialization of X, denoted 0X, constructs X 
without the mediation of any other construction. 0X 
is the atomic concept of X: it is the primitive, non-
perspectival mode of presentation of X. 
There are three compound constructions, which 
consist of other constructions: Composition, 
Closure and Double Execution. Composition [X Y1 
? Ym] is the procedure of applying a function f v-
constructed by X to an argument A v-constructed 
by Y1,?,Ym, i.e., the instruction to apply f to A to 
obtain the value (if any) of f at A. Closure 
[?x1?xm Y] is the procedure of constructing a 
function by abstracting over variables, i.e., the 
instruction to do so. Finally, higher-order 
construction X can be used twice over as a 
constituent of a composed construction. This is 
achieved by the fifth construction called Double 
Execution 2X.  
TIL constructions, as well as the entities they 
construct, all receive a type. On the ground level of 
the type-hierarchy, there are entities unstructured 
from the algorithmic point of view belonging to a 
type of order 1. Given a so-called epistemic (or 
?objectual?) base of atomic types  (?-truth values, 
?-individuals, ?-time moments / real numbers, ?-
possible worlds), mereological complexity is 
increased by the induction rule for forming partial 
functions: where ?, ?1,?,?n are types of order 1, 
the set of partial mappings from ?1 ??? ?n to ?, 
denoted (??1??n), is a type of order 1 as well. 
Constructions that construct entities of order 1 are 
constructions of order 1. They belong to a type of 
order 2, denoted by *1. Inductively we define type 
of order n, *n.  
TIL is specific in a precise solution for intensions 
as non-empirical objects of the real world. 
Intensions are qualified as functions of a type 
((??)?), i.e., functions from possible worlds to 
chronologies of the type ? (in symbols: ???), 
where a chronology is a function of type (??). 
Some important kinds of intensions are:  
Propositions, type ??? (shortened as ?). They are 
denoted by empirical (declarative) sentences. 
Properties of members of a type ?, or simply ?-
properties, type (??)??.3 General terms (some 
substantives, intransitive verbs) denote properties, 
mostly of individuals. 
Relations-in-intension, type (??1??m)??. For 
example transitive empirical verbs, also attitudinal 
verbs denote these relations. Omitting ?? we get the 
type (??1??m) of relations-in-extension (to be met 
mainly in mathematics). 
                                                           
3  Collections, sets, classes of ??-objects? are members 
of type (??); TIL handles classes (subsets of a type) 
as characteristic functions. Similarly relations (-in-
extension) are of type(s) (??1??m). 
99
?-roles or offices, type ???, where ? ? (??). 
Frequently ??? (an individual office). Often denoted 
by concatenation of a superlative and a noun (?the 
highest mountain?). Individual roles correspond to 
what Church calls an ?individual concept?. 
 
3 The Complex Valency Frames 
Valency frames have been built in several projects 
(VALLEX for Czech PDT (?abokrtsk? 2005) or 
VerbNet (Kipper et al2006)). Motivation for the 
VerbaLex project came from comparing Czech 
WordNet verb frames with VALLEX. The main 
goal of VerbaLex is an automatic processing of 
verb phrases exploiting explicit links to Princeton 
WordNet. The complex valency frames we are 
working with can be characterized as data 
structures (tree graphs) describing predicate-
argument structure of a verb which contains the 
verb itself and the arguments determined by the 
verb meaning (their number usually varies from 1-
5). The argument structure also displays the 
semantic preferences on the arguments. On the 
syntactic (surface) level the arguments are most 
frequently expressed as noun or pronominal groups 
in one of the seven cases (in Czech) and also as 
prepositional cases or adverbials.  
An example of a complex valency frame for the 
verb zab?t (kill) looks like: 
usmrtit:1/zab?t:1/dostat:11 (kill:1) 
-frame: AG<person:1|animal:1>who_nomobl   
 VERBobl   
 PAT<person:1|animal:1>whom_accobl   
 INS<instrument:1>with_what_insopt    
-example: vrah zabil svou ob?? no?em (A murderer 
has killed the victim with a knife). 
-synonym: 
-use: prim 
More examples of CVFs for some selected verbs 
can be found below in Section 4. 
The semantics of the arguments is typically labeled 
as belonging to a given semantic role (or deep 
case), which represents a general role plus 
subcategorization features (or selectional 
restrictions). Thus valency frames in Verbalex 
include information about:  
1. the syntactic (surface) information about 
the syntactic valencies of a verb, i.e. what 
morphological cases (direct and 
prepositional ones in highly inflected 
languages such as Czech) are associated 
with (required by) a particular verb, and 
also adverbials, 
2. semantic roles (deep cases) that represent 
the integration of the general labels with 
subcategorization features (or selectional 
restrictions) required by the meaning of the 
verb.   
The inventory of the semantic roles is partly 
inspired by the Top Ontology and Base Concepts 
as they have been defined within EuroWordNet 
project. Thus we work with the general or ?large? 
roles like AG, ART(IFACT), SUBS(TANCE), 
PART, CAUSE, OBJ(ECT) (natural object), 
INFO(RMATION), FOOD, GARMENT, 
VEHICLE and others. They are combined with the 
literals from Princeton WordNet 2.0 where literals 
represent subcategorization features allowing us to 
climb down the hypero/hyponymical trees to the 
individual lexical units. For example, we have 
AG(person:1|animal:1) or SUBS(liquid:1) that can 
be used within the individual CVFs. 
The verb entries are linked to the Czech and 
Princeton WordNet 2.0, i.e. they are organized 
around the respective lemma in synsets with 
numbered senses.  
The Czech lexical resource being now developed is 
then a list of Czech CVFs ? this work is going on 
within the Verbalex project at FI MU (Hlav??kov?, 
Hor?k, 2005). Verbalex now contains approx. 
11000 verb literals organized in synsets. The 
current goal is to enlarge the lexicon to 15 000 
verbs. 
The inventory of the semantic roles we work with 
clearly represents a sort of ontology which tries to 
cover word stock of Czech verbs and can be used 
as a base for a semantic classification and 
subclassification of the verbs. The ontologies 
represent theoretical constructs designed from the 
?top? and as such they are not directly based on the 
empirical evidence, i.e. corpus data. Thus there is a 
need to confront the ontologies and the inventories 
of the semantic roles that can be derived from them 
with the corpus data and see how well they can 
correspond to them. For this purpose we are 
experimenting with the corpus data obtained from 
the Word Sketch Engine (Kilgarriff, Rychl?,  
Smr?, Tugwell 2006). 
 
100
4 Logical Analysis Using CVFs 
In this section we describe the translation of 
VerbaLex CVFs into a verb phrase, which is a core 
of a sentence logical analysis.  
TIL comes with a dissociation of significant verbs 
into two groups according to the classification of 
their meaning: 
1. by attributive verbs we ascribe qualities or 
properties to objects. Attributive verbs are 
typically expressed by the respective form 
of the verb ?to be? combined with an 
expression denoting a property; examples: 
?to be red? or ?to be mellow? or with a 
general substantive like ?to be a traitor?, ?to 
be a tree?. 
2. episodic verbs, on the other hand, specify 
actions performed by a subject. 
An episodic verb does not describe its subject's 
state in any moment of time, it rather describes an 
episode of doing something at the certain time 
moment (and necessarily some time before that 
moment plus the expectation that it will last also in 
the next few moments, at least). TIL provides a 
complex handling of episodic verbs including the 
verb tense, aspect (perfective/imperfective) or 
active/passive state. All these features are 
concentrated around the so called verbal object, the 
construction of which (i.e., the meaning of a 
particular verb phrase) is the application of (the 
construction of) the verb to (the constructions of) 
the verb's arguments. 
Since the analysis of attributive verbs is usually 
quite simple, we will concentrate in the following 
text on the examples of selected episodic verbs 
from VerbaLex and their logical analysis using the 
complex valency frames. 
The TIL type of episodic verbal objects is 
(?(??)(??))?, where ? is the type of propositions 
(???). See (Hor?k 2002, pp. 64-73) and (Tich? 
1980) for detailed explanation. Our analysis is 
driven by a linguistic (syntactic) context that 
signals the semantic fact that there is always a 
function involved here, so that we have to ascribe 
types to its arguments and value. 
 
4.1 Examples of Logical Analysis 
We have chosen cca 10 verbs with their verb 
frames from VerbaLex and we will use them as 
examples of the algorithm for determining the verb 
type in the TIL logical analysis procedure. 
 
d?t (give) 
d?t:2 / d?vat:2 / darovat:1 / v?novat:1 (give:8, 
gift:2, present:7) 
-frame: DON<organization:1>what_nomobl VERBobl  
OBJ<object:1>what_accobl  
BEN<person:1>to_whom_datobl 
-example: firma v?novala zam?stnanc?m nov? auta 
(a company gave new cars to the employees) 
-use: prim 
The verb arguments in this frame are: who, to 
whom, what (all obligatory) with (at least) two 
options: a) to whom  is an individual, b) to whom is 
a class of individuals. The respective verb types 
are ad a): ((?(??)(??))????),  
ad b): ((?(??)(??))??(??)?).  
For example to whom = to the employees of a 
given institution. To be an employee of the 
institution XY is a property, say Z / (??)??. So ?The 
company gave to the employees of XY??, not 
taking into account grammatical tenses and 
omitting trivializations we get ?w?t [Givewt XY 
Zwt etc.] (XY has the type ? here, being a collective 
rather than a class.) 
With this example, we can show that CVFs are 
used not only for determining the verbal object 
type, but also for stating additional prerequisities 
(necessary conditions) for the sentence 
constituents. The full analysis using the verb frame 
above thus contains, except the verb phrase part, 
the conditions saying that ?X gives Y to Z ? 
organization(X)  ? object(Y) ? person(Z)?. The 
predicates organization, object and person here 
represent the properties denoted by the 
corresponding terms in the wordnet hypero-
hyponymical hierarchy. 
 
d?t:15 / d?vat:15 / nab?dnout:3 / nab?zet:3 
(give:37) 
-frame: AG<person:1>who_nomobl VERBobl   
ABS<abstraction:1>what_accobl
 REC<person:1>to_whom_datobl 
-example: dal j? sv? slovo (he gave her his word) 
-example: nab?dl j? sv? srdce (he offered her his 
heart) 
-use: fig 
 
Here we have an idiom (?to give word?), which 
corresponds to an (episodic) relation between two 
101
individuals. Thus the type of the verb is 
((?(??)(??))???), the second ? corresponds to to 
whom. 
 
 
br?nit (prevent) 
br?nit:1 / zabr?nit:2 / zabra?ovat:2 / zamezit:2 / 
zamezovat:2 (prevent:2, keep:4) 
-frame: AG<person:1>who_nomobl  VERBobl 
PAT<person:1>to_whom_datobl   ACT<act:1>infobl  
-example: zabr?nila mu uhodit syna (she prevented 
him from hitting the son) 
-use: prim 
 
br?nit:1 / zabr?nit:2 / zabra?ovat:2 / zamezit:2 / 
zamezovat:2 (prevent:2, keep:4) 
-frame: AG<institution:1>what_nomobl VERBobl   
PAT<person:1>to_whom_datobl
 ACT<act:2>in_what_locopt 
-example: policie mu zabr?nila v cest? do zahrani?? 
(police prevented him from going abroad) 
-use: prim 
 
Here, arguments of the verb correspond to the 
phrases who, to whom, in (from). The third 
argument has the type of an activity given, of 
course, by an episodic verb hit the son, travel 
abroad (the substantive form travelling abroad can 
be construed as that activity). The type of the verb 
is ((?(??)(??))???((?(??)(??))?)). 
 
??ct (say) 
??ct:1 / ??kat:1 / ??ci:1 / ??kat:1 / pravit:1 (say:6) 
-frame: AG<person:1>who_nomobl   VERBobl   
COM<speech act:1>what_acc,that,dspobl   
ADR<person:1>to_whom_datopt 
-example: ??ct kolegovi dobr? den (say hello to a 
colleague) 
-example: ?ekl, ?e to plat? (he said that it holds) 
-example: pravil: "Dobr? den" (he said: ?Good 
day?) 
-use: prim 
 
The case questions for the corresponding 
arguments of the verb ??ct are a) who, what1, 
b) who, what2, c) who, to whom, what1, and d) who, 
to whom, what2. Examples of instantiated 
sentences can be a) Charles says ?Hello?, 
b) Charles says that he is ill, c) Charles says to his 
colleague ?Hello?, or d) Charles says to his 
colleague that he is ill.  
The quotation context (ad a), c)) is normally 
impossible to type. Unless we want to go into some 
deep analyses we can ascribe to any quoted 
expression the type of individual. The relation to 
and unquoted subordinate clause is analysed as a 
general construction of type ?n.  The resulting 
types of verbs are then  
a) ((?(??)(??))???),  
b) ((?(??)(??))???n),  
c) ((?(??)(??))????),  
d) ((?(??)(??))????n). 
 
bre?et1 (cry) because of something, for 
something 
bre?et:1 / plakat:1 (cry:2, weep:1) 
-frame: AG<person:1>who_nomobl   VERBobl   
CAUSE<cause:4>due+to+what_dat,over+what_ins,for+what_accobl    
-example: bre?ela kv?li zni?en?m ?at?m (she cried 
for spoiled clothes) 
-example: plakal nad svou chudobou (he cried over 
his poverty) 
-example: plakal pro sv? h??chy (he cried for his 
sins) 
-use: prim 
 
bre?et2 (cry) for somebody 
bre?et:1 / plakat:1 (cry:2, weep:1) 
-frame: AG<person:1>who_nomobl VERBobl  
ENT<person:1>for+whom_accobl  
-example: plakala pro mil?ho (she cried for her 
boy) 
-use: prim 
 
If I cry because of, for etc., then the role of causing 
is played by this because of. Crying is an episodic 
verb, whereas because of etc. is a relation between 
propositions, often between events. We have 
therefore because of / (???)??, where the first 
?(=???) belongs to the proposition denoted, e.g., by 
clothes have been spoiled or that the respective 
individual is poor, sinful etc., and the second ? to 
the proposition that the respective individual cries.  
In case of to cry for somebody the respective type 
is again a ?relation? ((?(??)(??))???), although this 
for hides some cause, which is, however, not 
mentioned.  
With this verb, we will describe the analysis of 
verb entailment handling in TIL. If we analyse a 
general case of the above mentioned meanings of 
cry (cry1-because of something, cry2-for 
102
somebody) simply to cry, (He cries all the time). 
This verb?s type is a verbal object without 
arguments, (?(??)(??))?. In addition to this the 
following rule holds: If X cries because of? or X 
cries for?, then X cries. In this way the semantic 
dependence between the three cases of crying is 
given; otherwise we would not be able to detect 
this connection, e.g. between bre?et1 and bre?et2. 
 
absolvovat (undergo) 
absolvovat:2 / pro??t:1 / pro??vat:1 (experience:1, 
undergo:2, see:21, go through:1) 
-frame: AG<person:1>who_nomobl VERBobl  
EVEN<experience:3>what_accobl  
LOC<location:1>in_what_locopt  
-example: absolvoval vy?et?en? na psychiatrick? 
klinice (he went through investigation in a 
psychiatric clinic) 
-use: prim 
In general it is an episodic relation to an event 
(type ?)4, so the type is ((?(??)(??))???). In some 
cases we may also use a relation to an episode 
(specific class of events, type (??)), then the type 
is ((?(??)(??))??(??)), and investigation in a clinic 
has to be defined as a sequence of events. 
 
akceptovat (accept) 
akceptovat:3 / p?ijmout:6 / p?ij?mat:6 (accept:4) 
-frame: AG<person:1|social group:1>who_nomobl 
VERBobl  
STATE<state:4>|EVEN<event:1>|INFO<info:1>wh
at_acc
obl 
-example: akceptujeme jeho povahu (we accept his 
character) 
-example: lid? p?ijali nov? z?kon s nad?en?m 
(people accepted new law with enthusiasm) 
-use: prim 
We can accept nearly anything. Here we meet the 
problem of type-theoretical polymorphism, which 
is handled here as a type scheme ((?(??)(??))???), 
for an arbitrary type ?. A quintessence of such a 
polymorphism: think on (about) ? one can think 
of an object of any kind. 
 
u?it (teach) 
nau?it:1 / u?it:2 / vyu?ovat:1 (teach:1, learn:5, 
instruct:1) 
                                                           
4 see (Hor?k 2002, p. 65) and (Tich? 1980). 
-frame: AG<person:1>who_nomobl VERBobl  
PAT<person:1>whom_accopt   
KNOW<subject:3>what_acc,to_what_datobl 
-example: nau?il d?t? abecedu (he educated a 
children in the alphabet)  
-example: u?? studenty matematiku (he teaches 
mathematics for students) 
-example: vyu?uje d?jepisu (he/she teaches 
history) 
-use: prim 
If understood as in ?What does (s)he live off? (S)he 
teaches.? it is the case of cry3 (see above). To 
teach understood as in ?He teaches history, 
maths?, etc., the analysis depends on which type is 
given to the school subjects, disciplines. One 
possibility is to analyse them as properties of a set 
of propositions, (?(??))??. Then to teach receives 
the type ((?(??)(??))??(?(??))??). If ?teaches 
alphabet? is the case then we have to decide what 
we mean by alphabet. Here the point is to teach 
(learn) to associate symbols and sounds 
(phonemes?), so the respective type of alphabet is 
(??), where ? is the type of symbols, ? the type of 
sounds. In the analysis of ?to educate somebody in 
something? the verb takes an individual as its 
additional argument: ((?(??)(??))????), where ? is 
the type of the discipline. 
In all the examples, we have displayed the 
relations between the two-level semantic roles used 
in the VerbaLex verb frames and the resulting 
logical analysis types of the verbal object as the 
main part of the clause?s logical construction. The 
algorithmisation of this procedure uses a list of all 
roles used in the lexicon (there are about 200 roles 
used) with the corresponding (ambiguous) logical 
types of the constituents. In this way we can form a 
basic skeleton of the automatic translation of text 
to logical constructions. 
5 Conclusions 
The paper presented a first outline of comparison 
and integration of the two approaches, namely 
logical and linguistic, to the semantics of verbs in a 
natural language (English and Czech). We are 
aware that this work is still in a great progress and 
the results so presented rather fragmentary. Still, 
we are convinced that the research project we aim 
at is a relevant contribution to the semantics of 
natural language. 
103
We have shown that pursuing such a research is 
reasonable and comes up with a new viewpoint to 
the meaning of verbs. In this way we extend our 
knowledge in the important way. Actually, we are 
dealing with two deep levels of the meaning 
description and a question may be asked which one 
is deeper and better. Our answer is, do not contrast 
the two levels, and make use of both of them. In 
this way we believe to integrate them into one 
compact whole and perhaps obtain a unique data 
structure. The results of the presented research can 
be immediately applied in the area of knowledge 
representation and in the long-term Normal 
Translation System project that is being prepared. 
We have not tackled the other deep descriptions, 
such as the method that exploits the 
tectogramatical level as it is presently applied in 
PDT (Haji? 2004). This, obviously, is a topic of 
another paper.  
 
Acknowledgments 
This work has been supported by the Academy of 
Sciences of the Czech Republic, project No. 
T100300414, by the Ministry of Education                
of CR within the Center of basic research LC536, 
by the program ?Information Society? of Czech 
Academy of Sciences, project No. 1ET101940420 
"Logic and Artificial Intelligence for multi-agent 
systems", and by the Czech Science Foundation 
under the project 201/05/2781. 
References 
 
Cresswell, M.J. (1975): ?Hyperintensional Logic?. 
Studia Logica 34, pp.25-38. 
Cresswell, M.J. (1985): Structured meanings. MIT 
Press, Cambridge, Mass. 
Du??, M., Jespersen, B., M?ller, J. (2005): Epistemic 
Closure and Inferable Knowledge. The Logica 
Yearbook 2004, ed. L. B?hounek, M. B?lkov?, 
Filosofia Prague, pp. 125-140. 
Fellbaum, C., editor. 1998. WordNet: An Electronic 
Lexical Database. The MIT Press, Cambridge, 
Massachusetts, London, England. 
Haji?, Jan (2004): Complex Corpus Annotation: The 
Prague Dependency Treebank, Jazykovedny Ustav 
L.Stura, Bratislava, Slovakia, 2004. 
Hlav??kov?, Dana - Hor?k, Ale? - Kadlec, Vladim?r 
(2006). Exploitation of the VerbaLex Verb Valency 
Lexicon in the Syntactic Analysis of Czech. Lecture 
Notes in Artificial Intelligence, Proceedings of Text, 
Speech and Dialogue 2006, Berlin, Heidelberg : 
Springer, 2006. 
Hor?k, Ale? (2002). The Normal Translation Algorithm 
in  Transparent Intensional Logic for Czech, Ph.D. 
Dissertation, Masaryk University, Brno, 2002. 
Kilgarriff, Adam - Rychl?, Pavel - Smr?, Pavel - 
Tugwell, David (2006). The Sketch Engine. In 
Proceedings of the Eleventh EURALEX 
International Congress. Lorient, France : Universite 
de Bretagne-Sud, pp. 105-116, 2004. 
Karin Kipper, Anna Korhonen, Neville Ryant, and 
Martha Palmer (2006): Extensive Classifications of 
English verbs. Proceedings of the 12th EURALEX 
International Congress. Turin, Italy. September, 
2006. 
Materna, P. (1998): Concepts and Objects. Acta 
Philosophica Fennica, Vol. 63, Helsinki.  
Materna, P. (2004): Conceptual Systems. Logos Verlag, 
Berlin. 
Materna, P., Du??, M. (2005): Parmenides Principle. 
Philosophia, vol. 32 (1-4), pp. 155-180. 
Tich?, P. (1988): The Foundations of Frege?s Logic, 
Berlin, New York: DeGruyter. 
Tich?, P. (1980): The Semantics of Episodic Verbs, 
Theoretical Linguistics 7, pp. 263-296, 1980. 
Tich?, P. (2004): Collected Papers in Logic and 
Philosophy, V. Svoboda, B. Jespersen, C. Cheyne 
(eds.), Prague: Filosofia, Czech Academy of 
Sciences, and Dunedin: University of Otago Press 
?abokrtsk?, Z. (2005): Valency Lexicon of Czech Verbs. 
Ph.D. Thesis, Faculty of Mathematics and Physics, 
Charles University in Prague, 2005. 
104
Balto-Slavonic Natural Language Processing 2007, June 29, 2007, pages 75?81,
Prague, June 2007. c?2007 Association for Computational Linguistics
Derivational Relations in Czech WordNet
Karel Pala
Faculty of Informatics
Masaryk University Brno 
Czech Republic
               pala@fi.muni.cz
Dana Hlav??kov?
Faculty of Informatics
Masaryk University Brno
Czech Republic
ydana@aurora.fi.muni.cz
Abstract
In the paper we describe enriching Czech 
WordNet  with  the  derivational  relations 
that  in  highly  inflectional  languages  like 
Czech  form  typical  derivational  nests  (or 
subnets). Derivational relations are mostly 
of  semantic  nature  and their  regularity in 
Czech allows us to add them to the Word-
Net alost automatically. For this purpose 
we  have  used  the  derivational  version  of 
morphological analyzer Ajka that is able to 
handle  the  basic  and  most  productive 
derivational  relations  in  Czech.  Using  a 
special derivational interface developed in 
our NLP Lab we have explored the seman-
tic nature of the selected noun derivational 
suffixes and established a set of the seman-
tically  labeled  derivational  relations  ? 
presently 14. We have added them to the 
Czech WordNet and in this way enriched it 
with approx. 30 000 new Czech synsets. A 
similar enrichment for Princeton WordNet 
has  been  reported  in  its  recently released 
version 3.0, we will comment on the partial 
similarities and differences.  
1 Introduction
WordNets  as  such  represent  huge  semantic  net-
works  in  which  the  basic  units  ?  synsets  ?  are 
linked with the ?main? semantic relations like syn-
onymy, near_synony my, antonymy, hypero/hy-
ponymy, meronymy and others. In the EuroWord-
Net project (cf.  Vossen, 2003) Internal Language 
Relations  (ILR)  have  been  introduced  such  as 
Role_Agent, Agent_Involved or Role_Patient, Pa-
tient_Involved etc., as well as the relation Deriva-
tive  capturing  derivational  relations  between 
synsets.  The semantic nature  of  the derivational 
relations,  however,  was  not  systematically  ana-
lyzed and labeled in EuroWordNet project.
If we try to label the derivational relations se-
mantically and include them in WordNet as a re-
sult we get two level network where on the higher 
level  we have the ?main? semantic  relations  be-
tween  synsets  such  as  synonymy,  near_syn-
onymy, antonymy, hypero/hyponymy,  meronymy 
and others and on the lower level there are rela-
tions like the derivational ones that hold rather be-
tween literals than between synsets.
In the highly inflectional languages the deriva-
tional relations represent a system of semantic re-
lations that definitely reflects cognitive structures 
that may be related to a language ontology. Such 
ontology undoubtedly exists but according to our 
knowledge it has not been written down yet. How-
ever, for language users derivational affixes (mor-
phemes) function as formal means by which they 
express  semantic  relations  necessary  for  using 
language as a vehicle  of  communication.  In our 
view, the derivational relations should be consid-
ered as having semantic nature though a question 
may be asked what kind of semantics we are deal-
ing with (see Sect. 3). It has to be remarked that 
grammatical categories such as gender or number 
display a clear semantic nature. 
2 Derivational Morphology in Czech
In Czech words are regularly inflected (declined, 
conjugated) as they express different grammatical 
categories  (gender,  number,  case,  person,  tense, 
aspect  etc.)  using affixes.  This is what is  called 
75
formal morphology in Czech grammars and its de-
scription mostly deals  with the system of the in-
flectional paradigms. Then there is a  derivational  
morphology which deals with deriving words from 
other  words,  e.g.  nouns  from  verbs,  adjectives 
from nouns or verbs etc. using affixes again. The 
derivations  are  closely related  to  the  inflectional 
paradigms in a specific way:  we can speak about 
derivational paradigms as well (cf. Pala, Sedl??ek, 
Veber,  2003). 
For Czech inflectional morphology there are au-
tomatic tools ? morphological analyzers exploiting 
the formal description of the inflection paradigms 
?  we  work  with  the  analyzer  called  Ajka  (cf. 
Sedl??ek, Smr?, 2003) and developed in our NLP 
Lab.  Its  list  of  stems  contains  approx.  400  000 
items, up to 1600 inflectional paradigms and it is 
able to generate approx. 6 mil. Czech word forms.
We are using it for lemmatization and tagging, 
as a module for syntactic  analyzer,  etc.  We have 
also developed a derivational version of Ajka (D-
Ajka) that is  able to work with the main  regular 
derivational  relations  in  Czech  ?  it  can  generate 
new word forms derived from the stems. Together 
with D-Ajka an MWE preprocessing module with 
the  database  containing  approx.  100 000 colloca-
tions is exploited as well.
2.1 Derivational relations in Czech
The  derivational  relations  (D-relations)  in  Czech 
cover a large part of the word stock (up to 70 %). 
Thus we are interested in describing derivational 
processes (see examples) by which new words are 
formed from the corresponding word bases (roots, 
stems).  In  Czech  grammars  (Mluvnice  ?e?tiny, 
1986) we can find at least the following main types 
(presently 14) of the derivational processes:
1.  mutation:   noun  ->  noun derivation,  e.g. 
ryba -ryb-n?k  (fish -> pond), semantic relation 
expresses location ? between an object and its 
typical location, 
2.  transposition  (existing  between  different 
POS):  noun -> adjective  derivation,  e.g. den 
-> den-n? (day ->daily), semantically the rela-
tion expresses property,
3. agentive relation (existing between different 
POS): verb -> noun  e.g. u?it -> u?i-tel (teach 
-> teacher), semantically the relation  exists 
between action and its agent,
4. patient relation: verb -> noun, e.g.  trestat  
-> trestanec (punish ->convict), semantically 
it expresses a relation between an action and 
the object (person) impacted by it,
5. instrument (means) relation: verb -> noun, 
e.g.  dr?et  ->  dr??k (hold ->holder), 
semantically it expresses a tool (means) used 
when performing an action,  
6.  action relation  (existing between different 
POS):  verb  ->  noun, e.g.  u?it  ->  u?e-n-? 
(teach -> teaching), usually the derived nouns 
are charaterized as deverbatives, semantically 
both  members  of  the  relation  denote  action 
(process),  
7.  property-va  relation  (existing  between 
different  POS):  verb  ->  adjective,  e.g. 
vypracovat  ->  vypracova-n?  (work  out  -> 
worked out),   usually the derived adjectives 
are labelled as de-adjectives, semantically it is 
a relation between action and its property,
8.  property-aad  relation  (existing  between 
different  POS):  adjective  ->  adverb,  e.g. 
rychl?  ->  rychl-e (quick  ->  quickly), 
semantically we can speak about property, 
9.  property-an  (existing  between  different 
POS): adjective -> noun, e.g. rychl? -> rychl-
ost (fast -> speed), semantically the relation 
expresses property in both cases,   
10. gender change relation: noun -> noun,   
e.g. in?en?r -> in?en?r-ka   (engineer -> she 
engineer), semantically the only difference is 
in sex of the persons denoted by these nouns, 
11.  diminutive  relation:  noun   ->  noun  -> 
noun,  e.g.  d?m  ->  dom-ek  ->  dom-e?ek 
(house -> small house -> very little house or 
a house to which a speaker has an emotional  
attitude), in Czech the diminutive relation can 
be binary or ternary,
12. augmentative relation: noun -> noun, e.g. 
b?ba  ->  bab-izna (beldame  ->  hag), 
semantically it  expresses different  emotional 
attitudes to a person,  
13.  prefixation: verb -> verb,  e.g myslet  -> 
vy-myslet (think  ->  invent),  semantically 
prefixes  in  Czech  denote  a  number  of 
76
different  relations  such  as  distributive, 
location,  time, measure and some others.  We 
will not be dealing with this topic here, it calls 
for a separate examination (project), 
14.  possessive  relation  (existing  between 
different  POS):  noun   ->  adjective  otec  -> 
otc?v (father  -> father?s), semantically it is a 
relation  between  an  object  (person)  and  its 
possession.
We should mention two more relations that are 
sometimes  regarded  inflectional  but  in  our  view 
they belong here as well: gerund relation - verb  -> 
adjective: (bojovat   ->bojuj?c?, fight  -> fighting) 
and passive relation ? verb   -> adjective (passive 
participle): (u?it  -> u?en, teach  -> taught). 
These  14  (+2)  relations  have  been  taken  as  a 
starting point for including derivational relations in 
Czech Wordnet.  The main condition for their  in-
cluding is  whether  they can be generated by the 
derivational  version of the analyzer  Ajka.  In this 
way we have been able to obtain automatically a 
precise  specification  what  literals  are  linked  to-
gether. It was also necessary to introduce the labels 
for  the  individual  relations  in  a  more systematic 
way.  As a result  we have obtained the following 
list of 10 derivational relations with their semantic 
labels that are given in the brackets and hold be-
tween the indicated POS: 
          1. deriv-na: noun -> adjective (property)
2. deriv-ger: verb ->  adjective (property)
3. deriv-dvrb: verb -> noun (activity as a noun)
          4. deriv-pos: noun -> adjective (possessive  
              relation)
5. deriv-pas: verb -> adjective (passive relation)
          6. deriv-aad: adjective -> adverb (property of 
              property)
7. deriv-an: adjective -> noun (property)
8. deriv-g: noun -> noun (gender relation)
9. deriv-ag: verb -> noun (agentive relation)
   10. deriv-dem: noun -> noun (diminutive relation)
The location and patient relation will be included 
in CzWn when the D-Ajka will be able to handle 
them (in the near future). 
2.2 Derivational nests ? subnets
If  we have a look at  the data,  i.e.  at  the list  of 
Czech stems and affixes and try to see how the 
just described relations work we obtain the typical 
derivational clusters ? we will prefer to call them 
derivational  nests  (subnets).  To  illustrate  their 
regularity we adduce an example of such nest for 
the Czech roots ? pr?c/prac- (work). The main re-
lations holding between these roots and the corre-
sponding suffixes are: 
roots: -pr?c-/-prac-e- 
         deriv-act - prac-ova-t (to work)
         deriv-loc1- prac-ov-i?t? (workplace)
         deriv-loc2 - prac-ov-na (study) 
         deriv-ag1- prac-ov-n?k (worker), 
         deriv-g - prac-ovn-ice (she-worker), 
         deriv-ag2 - prac-ant (plodder)
         deriv-ger - prac-uj-?c? (working - person)
         deriv-pro - prac-ov-n? (professional,  working)
         deriv-pro - prac-ov-i-t-? (diligent,  hardworking) 
          deriv-pro - prac-ov-i-t-ost (diligence)
The proposed labels are not final yet ? the num-
ber  of  the  productive  derivational  relations  that 
have to be examined in Czech is larger, certainly 
up to 15. Number of the derivational suffixes in 
Czech is higher ? more than 80.
At the moment the derivational Ajka is not able 
to  generate  the  full  nests  automatically  but  we 
continue processing the remaining Czech deriva-
tional suffixes for this purpose.
2.3 Processing derivational suffixes
So far we have not said much about the affixes, 
i.e.  prefixes,  stem-forming  infixes  and  suffixes 
used in derivations. In this analysis we pay atten-
tion  mainly  to  the  suffixes,  prefixes  are  related 
mostly to verbs and in this sense they represent a 
separate and rather complicated derivational sys-
tem.  Infixes  or  intersegments  are  basically cov-
ered by the list of stems ? instead writing rules for 
changes in stems we just use  more variants of one 
77
stem. But the root analysis  is possible and if we 
want  to  describe  the  derivational  processes  in 
Czech as completely as possible we have to return 
to them. 
As  starting  data  we  have  used  a  list  of  noun 
stems taken from the stem dictionary of the D-Ajka 
analyzer  ?  their  number is  approx.  126 000.  The 
derivations  have been analyzed  by means  of  the 
web  interface  developed  just  for  this  purpose. 
Noun derivations are performed in the three basic 
steps: 
1. a set of words is defined by means of the (pre-
fix), suffix and morphological tag;
2. defining a derivational rule ? typically a substi-
tution of morphemes  (suffixes)  at  the end of the 
word;  
3. manual modification of the results ? usually cor-
recting or deleting cases that cannot be regarded as 
properly derived forms though they may follow the 
given rule. 
An  example  of  the  derivational  analysis  for 
Czech sufix ??k: it occurs with the nouns denoting 
agent or instrument (means), e.g. zed-n-?k (brick-
layer) or  kapes-n?k (hankerchief).
First we want to derive agentive nouns: so we 
enter the suffix ??k and tag k1gM (noun, masculine 
animate) and generate the list of all words ending 
with -?k. The output is a list of 1210 nouns includ-
ing proper names (from the original list of 126 000 
Czech nouns). To obtain instrument nouns we in-
put the tag k1gI (noun, masculine inanimate).  As 
an output result we get a list of 715 nouns includ-
ing proper names. The number of all words ending 
with suffix  -?k (disregarding the grammatical  tag) 
in stem dictionary of Ajka is 1830. The difference 
in the given numbers follows from the homonymy, 
for  instance,  some nouns can  be  both  masculine 
animate  and  masculine  inanimate (e.g.  n??eln?k 
can denote ? chief  as well as ?elenka ? headband. 
Such cases have been checked manually.
In a similar way we have processed 22 Czech 
derivational  suffixes and as a result  we have ob-
tained  a  detailed  classification  of  the  indicated 
derivations capturing agentive, instrumental, loca-
tion  and  also  resultative  relations,  for  instance 
sp?lit  -> sp?lenina  (to burn ->  a burn) which has 
not been mentioned before. At the same time the 
complete lists of all stems with the indicated suf-
fixes together with labeling their semantic relations 
between the stems and respective suffixes was ob-
tained as well. For the processed suffixes the cov-
erage  is  complete  (with  regard  to  the  list  of 
126 000 of the Czech noun stems).
Thus using the described procedure we are try-
ing to find pairs of the word forms in which the 
first one is considered basic and the second one 
derived. The direction of the derivations is not al-
ways  unambiguous  but  the  most  important 
goal is to establish the relation itself not its direc-
tion. The cases when changes in stem take place 
have to be checked and added manually. 
2.4 D-relations in Czech and English WordNet
In Figure 1 we show how the D. relations are im-
plemented in Czech Wordnet. As an example we 
show
 Figure1:  D-relations in Czech WordNet
  
verbal  synset  {u?it:1,  vyu?ovat:  prob?rat:1, 
br?t:2}and the similar English one  {teach:1, in-
struct:1}). It can be seen that there is a derivation-
al  subnet  with  five  D-relations  associated  to 
78
{u?it:1, ...} (in fact 14 but they are repeating with 
other literals in the synset as well). Each D-relation 
is labeled semantically so we have here the follow-
ing  D-relations:  agentive,  location,  deverbative, 
gerund, passive ? the last two may be characterized 
as more morphological (surface, see Sect. 2.1) than 
the first three.  
In Princeton WordNet 3.0 we can observe the 
following  three  D-relations  associated  with  the 
synset {teach:1, learn:5, instruct:1} 
S: (v) teach, learn, instruct (impart skills or knowl-
edge to)  "I taught  them French";  "He instructed  
me in building a boat"
derivationally related form 
? W:   (adj) teachable [Related to: teach] 
(ready and willing to be taught) "docile  
pupils eager for instruction"; "teachable 
youngsters"
? W:   (n) teacher [Related to: teach] (a per-
son whose occupation is teaching) 
? W:   (n) teacher [Related to: teach] (a per-
sonified abstraction that teaches) "books 
were his teachers"; "experience is a de-
manding teacher"
? W:   (n) teaching [Related to: teach] (the ac-
tivities of educating or instructing; activi-
ties that impart knowledge or skill) "he re-
ceived no formal education"; "our instruc-
tion was carefully programmed"; "good 
classroom teaching is seldom rewarded"
? W:   (adj) instructive [Related to: instruct] 
(serving to instruct or enlighten or inform) 
? W:   (n) instruction [Related to: instruct] 
(the activities of educating or instructing; 
activities that impart knowledge or skill) 
"he received no formal education"; "our 
instruction was carefully programmed";  
"good classroom teaching is seldom re-
warded"
? W:   (n) instructor [Related to: instruct] (a 
person whose occupation is teaching) 
It is not surprising that the full agreement between 
Czech  and English  D-relations  includes  only the 
agentive relation (teach -> teacher) and gerund re-
lation  (teach  ->  teaching).  The relation  teach  -> 
teachable is not included among Czech relations at 
the moment but it will be easy to add it. The loca-
tion relation is missing in English and also some 
others characterized usually as morphological. We 
included them in Czech WordNet ? they belong to 
the set of the Czech derivational relations.
If we compare semantic labeling of the D-rela-
tions in both Wordnets we observe that they are 
more  explicitly  formulated  in  Czech  Wordnet. 
The question that remains to be answered is how 
the different senses may be or are reflected in the 
individual derivations. In PWN 3.0 the derivation 
teach ? teacher is given twice because there are 
two different senses of  teach in PWN 3.0. In our 
view, it is enough to give this derivational relation 
just once because it is agentive in both cases. Of 
course,  in  Czech  there  are  frequent  cases  like 
dr?et -> dr??k (hold -> holder) and dr?et -> dr?i-
tel  (hold  -> holder) where the first one is instru-
ment  relation  and  the  second  agentive  but  in 
Czech the different suffixes have to be used (-?k 
vs.  -tel) indicating a difference in gender as well 
(masculine inanimate vs. masculine animate).
3 What is the nature of the D-relations?
In the previous sections we have introduced the 
labeling  of  the  Czech D-relations.  The  question 
may be asked what is the real  nature of D-rela-
tions, whether it is semantic or rather morphologi-
cal (formal). The D-relations exist between mor-
phemes, typically between stems and correspond-
ing suffixes. This formal feature makes them dif-
ferent  from the  relations  between sentence  con-
stituents,  as  e.g.  between  verbs  and  their  argu-
ments.  However,  the  main  criterion  for  us  is 
whether the particular relation affects meaning ir-
respective of its formal realization.                
If we apply this criterion to the D-relations dis-
cussed above, such as deriv-ag, deriv-loc, deriv-
instr, deriv-g, deriv-dem, deriv-pos, deriv-pro, we 
definitely come to the conclusion that their nature 
is semantic. 
Then there are relations like deriv-an, deriv-na, 
deriv-dvrb, deriv-ger, deriv-aad, deriv-pas that are 
sometimes  characterized  as  morphological  only 
and their semantics is left aside. The first two re-
lations  hold  between  nouns  and  adjectives  and 
both  denote  properties  (e.g.  deriv-an:  nov?  -> 
novost  (new -> newness)),  but  we have to  take 
into account that there is something that may be 
called semantics of the parts of speech, i.e. in one 
case  property is  expressed  by the  adjective  and 
then by the noun which is derived from the adjec-
79
tive. Deriv-na denotes property as well but here the 
adjective  is  derived  from noun as  in  boj  -> bo-
jovn?    (fight  -> combative). The relation deriv-
dvrb exists between a verb and noun, e.g. u?it  -> 
u?en?  (teach  -> teaching),  and it  denotes action 
which is first expressed by the verb and then by the 
deverbative noun. We can say that in these cases 
the only difference lies in the optics of the individ-
ual  parts  of  speech but  this  difference should be 
understood as semantic as well. However, it should 
be remarked once more that quite often the differ-
ences in the semantics of the parts of speech are 
not treated as truly semantic.
If we have  look what standard Czech grammars 
(see e.g. Karl?k et al 1995) say about the semantics 
of  the  parts  of  speech  we  find  the  formulations 
such as:   nouns  denote independent entities,  i.e. 
persons, animals and things and also properties and 
actions. Verbs then denote states and their changes 
and processes (actions) and their mutations. These 
descriptions certainly refer to the semantics of the 
nouns and verbs. They are usually followed by the 
explanations  about  morphological  processes,  i.  e. 
usually derivations by which some parts of speech 
are formed from the others, as we have described 
them above. What is relevant and what is missing 
in the standard grammars are more detailed and ex-
tensive semantic classifications of nouns, verbs, as 
well as adjectives and numerals. They are begin-
ning to appear only recently and have the form of 
ontologies ? the standard grammars do not use this 
term at all.
Until we have such semantic classifications de-
scribing semantic relations between the individual 
parts of speech we can hardly have a full picture 
that  is  necessary for  automatic processing of the 
derivational relations.
This issue certainly calls for a more detailed ex-
amination, which would be a topic for another pa-
per.   
          
4 The  implementation  of  D-relations  in 
Czech WordNet
The existing software tools (e.g.Visdic, cf. Hor?k, 
Smr?, 2004 ) used for building Wordnet databases 
standardly work  with  semantic  relations  between 
synsets and they treat them as atomic units. In fact, 
the synsets are not atomic as such and they consist 
of the smaller units called literals, i.e. for instance 
the synset {teach:1, instruct:1} contains two liter-
als (lemmas).    
If  we want to deal  with the D-relations auto-
matically  we  immediately  face  a  problem:  be-
cause of their  nature they typically hold not be-
tween synsets  but between literals that as a rule 
belong to  the  different  synsets,  e.g.  teach:1  and 
teacher:1. Therefore we need a tool that is able to 
define  and create  derivational  links  between the 
literals. According to our knowledge the only tool 
that can do this is DEBVisdic editor and browser 
developed at our NLP Lab at FI MU (cf. Hor?k, 
Pala, 2006, it can be downloaded from: http://nlp.-
fi.muni.cz/projekty/deb2/clients/).       
We have used it for the implementation of the 
D-relations  in  Czech  WordNet  (the  result  is 
shown in Sect. 2.4). The DEBVisdic tool is now 
used for representing and storing all the semantic 
relations including the D-relations. It  is  also ex-
ploited for building Wordnets in other languages 
such as Polish, Slovenian, Hungarian and others.  
              In our view, the way in which the D-relations 
(and  other  relations  as  well)  are  represented 
relevantly  depends  on  the  software  tools  used. 
This  can  be  demonstrated  if  we  compare  the 
representation  of  the  Czech  D-relations  in 
DEBVisdic with the one in PWN 3.0 (see Sect. 
2.4) which appears to be less explicit and rather 
verbose. This  also means  that the representation 
used in PWN 3.0 will be probably less suitable for 
possible applications.  
          
5 The results
As we said above after processing all D-relations 
by the derivational Ajka we have added the de-
rived  literals  (lemmas)  to  the  Czech  WordNet. 
The final result ? the number of the literals gener-
ated from the individual D-relations is given be-
low together with their semantic labels:
deriv-na ???? 641 (property, noun -> adj)
deriv-ger ???..1951 (property, verb -> adj)
deriv-dvrb ???5041 (action, verb -> noun)
deriv-pos ???.4073 (possessive, noun -> adj)
deriv-pas ???.9801 (passive, verb -> adj)
deriv-aad ............1416  (property, adj -> adverb)
80
deriv-an ???...1930 (property, adj -> noun)
deriv-g ????.2695 (gender, noun -> noun)
deriv-ag ????.186 (agentive, verb -> noun)
deriv-dem ???3695 (diminutive, noun -> noun)
Total ????  31429 literals 
These numbers also tell us how productive the 
particular relations are. Note that the most frequent 
is passive relation which is followed by the dever-
bative (action) relation. The third most frequent re-
lation is a possessive one. It would be interesting to 
examine what these facts can tell us about semantic 
structure of texts. 
6    Conclusions
In the paper we present the first results of compu-
tational analysis of the basic and most regular D-
relations in Czech using derivational version of the 
morphological analyzer Ajka.
Though the analysis is far from complete at the 
moment the number of the generated items has led 
us to the decision to include them in Czech Word-
Net and enrich it considerably with the derivational 
nests  (subnets).  In our view,  this  kind of enrich-
ment  makes  Czech  WordNet  more  suitable  for 
some applications, namely for searching. 
    The second and even more important reason for 
doing all this is a belief that the derivational rela-
tions and derivational subnets created by them re-
flect basic cognitive structures existing in natural 
language. More effort is needed for exploring them 
from the point of view of now so popular ontolo-
gies ? they certainly offer a formal  ground (they 
are  expressed  by  the  individual  morphemes)  for 
natural language based ontologies.   
     We have also included a brief comparison with 
the recently released Princeton WordNet 3.0 which 
now contains derivational links for English as well. 
As  we  expected  the  comparison  confirms  the 
known fact that English as an analytic language is 
much poorer with regard to the derivational rela-
tions than the inflectional ones. 
From the technical point of view PWN 3.0 is still 
not  using  the  representation  in  XML format  (as 
DebVisdic does) and this, we think, in certain de-
gree limits the possibilities to express some of the 
links in a standard way. The present web interface 
where  Princeton  WordNet  3.0  can  be  browsed: 
http://wordnet.princeton.edu/perl/webwn)   does 
not seem to be able to work directly with the links 
between literals. 
On  the  other  hand,  we  are  well  aware  that 
adding D-relations to PWN 3.0 is very stimulating 
and useful  though it will  be quite demanding to 
establish  the  derivational  links  between  English 
and other languages (through Interlingual Index). 
This  makes  it  a  new  challenge  for  the  whole 
WordNet community. 
Acknowledgements
The research was supported by the grant projects 
GA  201/05/2871,  1ET100300419  and  NPVII 
2C06009.
References 
Hor?k  A.,  Pala  K.,  Rambousek  A.,  and Povoln? M. 
2006.  First  version  of  new  client-server  wordnet 
browsing  and  editing  tool.  In  Proceedings  of  the 
Third  International  WordNet  Conference  ?  GWC 
2006, p. 325-328, Jeju, South Korea, Masaryk Uni-
versity, Brno.
Hor?k A.,  Smr?  P.  2004.  Visdic  ?  WordNet  Editing 
and Browsing Tool,  Proceedings of the 2nd GWC, 
Brno, Masaryk University.
Karl?k P. et al 1995, P??ru?n? mluvnice ?e?tiny (Every 
day Czech Grammar),  Nakladatelstv?  Lidov? Nov-
iny,  Prague, pp. 229, 310.
Pala  K.,  Sedl??ek  R.,  Veber  M.  2003.  Relations 
between  Inflectional  and  Derivation  Patterns, 
Proceedings of EACL, Budapest.
Petr  J.  et  al.  1986.  Mluvnice  ?e?tiny  1, Praha: 
Academia. 
Sedl??ek R., Smr? P. 2001.  A New Czech Morpholo-
gical Analyser Ajka. Proceedings of the 4th Interna-
tional  Conference  on  Text,  Speech  and  Dialogue, 
Springer Verlag, Berlin, s.100-107.
Vossen  P.  2003.  EuroWordNet  General  Document, 
Version 3, University of Amsterdam.
Web address of the Princeton WordNet 3.0: 
http://wordnet.princeton.edu/perl/webwn.
81
