Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural
Language Learning, pages 1379?1388, Jeju Island, Korea, 12?14 July 2012. c?2012 Association for Computational Linguistics
Part-of-Speech Tagging for Chinese-English Mixed Texts
with Dynamic Features
Jiayi Zhao? Xipeng Qiu? Shu Zhang? Feng Ji? Xuanjing Huang?
School of Computer Science, Fudan University, Shanghai, China ? ?
Fujitsu Research and Development Center, Beijing, China?
zjy.fudan@gmail.com?
{xpqiu,fengji,xjhuang}@fudan.edu.cn?
zhangshu@cn.fujitsu.com ?
Abstract
In modern Chinese articles or conversations,
it is very popular to involve a few English
words, especially in emails and Internet liter-
ature. Therefore, it becomes an important and
challenging topic to analyze Chinese-English
mixed texts. The underlying problem is how
to tag part-of-speech (POS) for the English
words involved. Due to the lack of specially
annotated corpus, most of the English words
are tagged as the oversimplified type, ?foreign
words?. In this paper, we present a method
using dynamic features to tag POS of mixed
texts. Experiments show that our method
achieves higher performance than traditional
sequence labeling methods. Meanwhile, our
method also boosts the performance of POS
tagging for pure Chinese texts.
1 Introduction
Nowadays, Chinese-English mixed texts are
prevalent in modern articles or emails. More and
more English words are used in Chinese texts as
names of organizations, products, terms and abbre-
viations, such as ?eBay?, ?iPhone?, ?GDP?, ?An-
droid? etc. On the other hand, it is also a common
phenomenon to use Chinese-English mixed texts
in daily conversation, especially in communication
among employers in large international corporations.
There are some challenges for analyzing Chinese-
English mixed texts:
1. How to define the POS tags for English words
in these mixed texts. Since the standard of
POS tags for English and Chinese are different,
we cannot use English POS to tag the English
words in mixed texts.
2. Due to lack of annotated corpus for mixed texts,
most of the English words are tagged as ?for-
eign words?, which is oversimplified. So we
cannot use them in further processing for the
syntactic and semantic analysis.
3. Most English words used in mixed texts are of-
ten out-of-vocabulary (OOV), which thus in-
creases the difficulties to tag them.
Currently, the mainstream method of Chinese
POS tagging is joint segmentation & tagging with
cross-labels, which can avoid the problem of error
propagation and achieve higher performance on both
subtasks(Ng and Low, 2004). Each label is the cross-
product of a segmentation label and a tagging la-
bel, e.g. {B-NN, I-NN, E-NN, S-NN, ...}. The fea-
tures are generated by position-based templates on
character-level.
Since the main part of mixed texts is in Chinese
and the role of English word is more like Chinese,
we use Chinese POS tags (Xia, 2000) to tag English
words. Since the categories of the most commonly
used English words are nouns, verbs and adjectives,
we can use ?NN?, ?NR?, ?VV?, ?VA?, ?JJ? to label
their POS tags.
For the English proper nouns and verbs, there
are no significant differences in Chinese and En-
glish POS tags except that English features plural
and tense forms.
For the English nouns, these are some English
nouns used as verbs, such as ??? [fan/VV]??(I
adore him very much.)? where ?fan? means ?adore?
and is used as a verb.
For the English adjectives, there are two corre-
sponding Chinese POS tags ?VA? and ?JJ?. For ex-
ample, the roles of some English words in Table 1,
1379
Table 1: The POS tags of English Adjectives in Mixed
Texts
Chinese English
? ? ? [profes-
sional/VA]?
I am very profes-
sional.
??? [high/VA]? Feel very high.
?? [super/JJ] [star/NN] He is a super star.
such as ?professional? and ?high?, are different with
their original ones.
Therefore, the POS tagging for mixed texts cannot
be settled with simple methods, such as looking up
in a dictionary.
One of the main differences between Chinese and
English in POS tagging is that the two languages
have character-based features and word-based fea-
tures respectively. To ensure the consistency of tag-
ging models, we prefer to use word-level informa-
tion in Chinese, which is both useful for Chinese-
English mixed texts and Chinese-only texts. For in-
stance, in a sentence ?X ?? Y ... (X or Y ...)?,
the word Y ought to have the same POS tag as the
word X . Another example is that the word follow-
ing a pronoun is usually a verb, and adjectives of-
ten describe nouns. Some related works show that
word-level features can improve the performance of
Chinese POS tagging (Jiang et al 2008; Sun, 2011).
In this paper, we propose a method to tag mixed
texts with dynamic features. Our method combines
these dynamic features, which are dynamically gen-
erated at the decoding stage, with traditional static
features. For Chinese-English mixed texts, the tra-
ditional features cannot yield a satisfied result due to
lack of training data. The proposed dynamic features
can improve the performance by using the informa-
tion of a word, such as POS tag or length of the whole
word, which is proven effective by experiments.
The rest of the paper is organized as follows: In
section 2, we introduce the sequence labeling mod-
els, thenwe describe our method of dynamic features
in section 3 and analyze its complexity in section 4.
Section 5 describes the training method. The exper-
imental results are manifested in section 6. Finally,
We review the relevant research works in section 7
and conclude our work in section 8.
2 Sequence Labeling Models
Sequence labeling is the task of assigning labels
y = y1, . . . , yn to an input sequence x = x1, . . . , xn.
Given a sample x, we define the feature ?(x, y).
Thus, we can label x with a score function,
y? = argmax
y
F (w,?(x, y)), (1)
where w is the parameter of function F (?).
For sequence labeling, the feature can be denoted
as?k(yi, yi?1, x, i), where i stands for the position in
the sequence and k stands for the number of feature
templates.
we use online Passive-Aggressive (PA) algorithm
(Crammer and Singer, 2003; Crammer et al 2006)
to train the model parameters. Following (Collins,
2002), the average strategy is used to avoid the over-
fitting problem.
3 Dynamic Features
The form of traditional features is shown in Table
2, where C represents a Chinese character, and T
represents the character-based tag. The subscript i
indicates its position related to the current character.
Table 2: Traditional Feature Templates
Ci, T0(i = ?2,?1, 0, 1, 2)
Ci, Cj , T0(i, j = ?2,?1, 0, 1, 2 and i ?= j)
T?1, T0
Traditional features are generated by position-
fixed templates. Since the length of Chinese word
is unfixed, their meanings are incomplete. We cat-
egorize them as ?static? features since they can be
calculated before tagging (except ?T?1, T0?).
The form of dynamic features is shown in Table
3, where WORD represents a Chinese word, and
POS (LEN ) is the POS tag (length) of the word.
The subscript of dynamic feature template indicates
its position related to the current word.
Table 4 shows an example. If the current posi-
tion is ? Apple?, then {POS?1=CC, POS?2=NR,
WORD?1=???, LEN?2=2}. Since these features
are unavailable before tagging, we call them ?dy-
namic? features.
1380
Table 3: Examples of Dynamic Feature Templates
POSi, POSj , T0(i, j = ?2,?1, 0 and i ?= j)
POSi,WORDj , T0(i, j = ?2,?1, 0)
WORDi, LENj , POSk, T0(i, j, k = ?2,?1, 0)
?
Dynamic features are more flexible because the
number of involved characters is dependent on the
length of previous words. Unlike static features, dy-
namic features do not merely rely on the input se-
quence C1:n, so the weights of dynamic features, in
which POS/LEN are involved, can be trained by
Chinese-only texts and used by mixed texts, which
resolve the problem of the lack of training data.
4 Tagging with Dynamic Features
In the tagging stage, we use the current best result
to approximately calculate the unknown tag infor-
mation. For an input sequence C1:n, the current best
tags from index 0 to i?1 can be calculated by Viterbi
algorithm and they can be used to generate dynamic
features for index i. The specific algorithm is shown
in Algorithm 1.
Here is an example to explain the time com-
plexity of the dynamic features. Normal template
xi?2xi?1yi requires to look for the positions of
i ? 2 and i ? 1 related to the current character
xi, but dynamic template posi?2posi?1yi needs to
know the pos tags of two words. If the length of
wordi?1/wordi?2 is 2, then the positions of i?4, i?
3, i?2, i?1 are needed to generate the dynamic fea-
tures.
For all dynamic features, it is unnecessary to
repetitively calculate the POS/WORD/LEN ar-
ray. Apart from that one time calculation of the ar-
ray, no distinction can be found between the time
complexity of the dynamic features and the tradi-
tional features. For input C1:n, the time complexity
isO(n?[O(op.2)+(Ts.num+Td.num)?O(op.1)+
O(op.4)]), n.b. O(op.1) = O(op.3). Universally
the dynamic features only require the information of
position i ? 2 and i ? 1, so the time complexity of
calculating the POS/WORD/LEN array can be
ignored as compared with the complexity of Viterbi
algorithm and feature extraction. The approximate
algorithm is thus faster than the Brute-Force way by
input : character sequence C1:n
static templates Ts
dynamic templates Td
number of labelsm
trans matrixM
output: resultsMax & Vp
Initialize: weight matrixW (n?m)
viterbi score matrix Vs (n?m)
viterbi path matrix Vp (n?m)
the index of current best labelMax
for i = 1 ? ? ?n do
for ts in Ts do
// create feature string Fs (Op.1)
Fs = createFeature(C1:n, ts);
W [i] += getWeightVector(Fs);
end
// create a list of <posk,wordk,lenk>
// (k = 0,?1,?2 . . .) (Op.2)
dList = getCurrentBestPath(Max, Vp);
for td in Td do
// create dynamic features string Fd
// (Op.3)
Fd = createFeature(C1:n, td, dList);
W [i] += getWeightVector(Fd);
end
// Update Vs[i], Vp[i] (Op.4)
viterbi_OneStep(Vs[i? 1],W [i],M );
Max = argmaxi(Vs[i]) ;
end
Algorithm 1: Tagging Algorithm with Dynamic
Features
using word-level information.
5 Training
Given an example (x, y), y? are denoted as the in-
correct labels with the highest score
y? = argmax
z ?=y
wT?(x, z). (2)
The margin ?(w; (x, y)) is defined as
?(w; (x, y)) = wT?(x, y)? wT?(x, y?). (3)
Thus, we calculate the hinge loss ?(w; (x, y), (ab-
breviated as ?w) by
1381
Table 4: Example for Chinese-English Mixed POS Tagging
? ? ? Apple ? OS ? ? ? ? ?
B-NR E-NR S-CC S-NR S-DEG S-NN B-NN E-NN B-VA E-VA S-PU
?w =
{
0, ?(w; (x, y)) > 1
1? ?(w; (x, y)), otherwise (4)
In round k, the new weight vector wk+1 is calcu-
lated by
wk+1 = argminw
1
2
||w? wk||2 + C ? ?,
s.t. ?(w; (xk, yk)) <= ? and ? >= 0 (5)
where ? is a non-negative slack variable, and C is
a positive parameter which controls the influence of
the slack term on the objective function.
Following the derivation in PA (Crammer et al
2006), we can get the update rule,
wk+1 = wk + ?k(?(xk, yk)? ?(xk, y?k)), (6)
where
?k = min(C,
?wk
??(xk, yk)? ?(xk, y?k)?2
) (7)
Our algorithm based on PA algorithm is shown in
Algorithm 2.
6 Experiments
We implement our system based on FudanNLP1.
We employ the commonly used label set {B, I, E,
S} for the segmentation part of cross-labels. {B,
I, E} represent Begin, Inside, End of a multi-node
segmentation respectively, and S represents a Single
node segmentation.
The F1 score is used for evaluation, which is the
harmonic mean of precision P (percentage of pre-
dict phrases that exactlymatch the reference phrases)
and recallR (percentage of reference phrases that re-
turned by system).
The feature templates, which are used to extract
features, are listed in Table 5. We set traditional
method (static features) as the baseline. The detailed
experimental settings and results are reported in the
following subsections.
1Available at http://code.google.com/p/fudannlp/
input : training data sets:
(xi, yi), i = 1, ? ? ? , N , and parameters:
C,K
output: wK
Initialize: wTemp? 0,w? 0;
for k = 0 ? ? ?K ? 1 do
for i = 1 ? ? ?N do
receive an example (xi, yi);
predict: y?i = argmax
y
?wk,?(xi, y)?;
if y?i ?= yi then
update wk+1 with Eq. 6;
end
end
wTemp = wTemp+ wk+1 ;
end
wK = wTemp/K ;
Algorithm 2: Training Algorithm
Table 5: Feature Templates
Static
xi?2yi, xi?1yi, xiyi, xi+1yi, xi+2yi
xi?1xiyi, xi+1xiyi, xi?1xi+1yi,
yi?1yi
Dynamic
posi?2posi?1yi, posi?1posiyi
posi?2wordi?1yi, posi?1wordiyi
posi?1wordi?1yi, posiwordiyi
wordi?2wordi?1yi, wordi?1wordiyi
wordileniyi
6.1 POS Tagging for Chinese-only Texts
Before the experiments onChinese-Englishmixed
texts, we evaluate the performance of our method on
Chinese-only texts. We use the CTB dataset from
the POS tagging task of the Fourth International Chi-
nese Language Processing Bakeoff (SIGHAN Bake-
off 2008)(Jin and Chen, 2008). The details are
shown in Table 6.
The performance comparison on joint segmenta-
tion & POS tagging is shown in Table 7. Our method
obtains an error reduction of 6.7% over the baseline.
The reason is that our dynamic features can utilize
1382
Table 6: POS Tagging Dataset in SIGHAN Bakeoff 2008
Train Set Test Set
(number) (number)
Sentence 23444 2079
Word
Total 642246 59955
NN 168896 16793
NR 42906 3970
VV 92887 8641
VA 9106 649
JJ 15640 1581
word-level information effectively and the feature
templates are more flexible.
Table 7: Performances of POS Tagging on Chinese-only
Texts with Static and Dynamic Features
Method P R F1
Baseline 89.68 89.60 89.64
Our 90.35 90.31 90.33
6.2 POS Tagging for Chinese-English Mixed
Texts
Without annotated corpus for Chinese-English
mixed texts, we use synthetic data as the alternative.
In Chinese-English mixed texts, English words of
noun(NN/NR), verb(VV/VA) and adjective(JJ) cat-
egories are the most commonly used, so we ran-
domly transform a certain percentage of Chinese
words with these POS tags in the SIGHAN Bakeoff
2008 dataset(Jin and Chen, 2008) into their English
counterparts.
6.2.1 Synthetic Data
Before trying out an experiment, we first study
how to generate the data of mixed texts.
We use two ways to produce the synthetic data:
?Respective Replacement? and ?Unified Replace-
ment?.
Respective Replacement We replace the selected
Chinese words into their corresponding English
counterparts.
Unified Replacement We replace the selected Chi-
nese words with a unified labelENG. The rea-
son we use the labelENG instead of real words
is that we want to consider the context of these
words but not the words themselves and over-
come the problem of out-of-vocabulary (OOV)
English words.
For our experiments, we just select 5% of the Chi-
nese nouns and verbs from SIGHAN dataset, and re-
place them in the above two ways. After replace-
ment, the training and test data have 12780 and 1254
English words, respectively. 5189 words are gener-
ated by way of ?Respective Replacement?. In the
test data, 326words are OOV, which comprises 25%
of the whole vocabulary. The information of gener-
ated data is shown in Table 8.
Table 8: The Synthetic Chinese-English Mixed Dataset
H
Dataset Numbers of ENGNN VV
H Train Set 8191 4589Test Set 842 412
We use H1 to represent the dataset generated by
way of ?Respective Replacement?, and H2 for the
dataset by way of with ?Unified Replacement?. The
experimental results on these two datasets are shown
in Table 9.
Table 9: Performances of POS Tagging on Dataset H1
and H2
Method Dataset ENG OOV TotalF1 F1oov F1
Baseline H1 73.60 54.91 88.93H2 77.59 73.93 89.11
Our H1 75.60 54.60 89.79H2 79.82 77.61 89.81
From Table 9, we can see that the ?Unified
Replacement? way is better than the ?Respective
Replacement? way for both the baseline and our
method. The main reason is that the ?Unified Re-
placement? way can greatly improve the tagging per-
formance of OOV words.
6.2.2 Detail Comparisons
For detail comparisons of all situations of
mixed texts, we design six synthetic datasets,
A/B/C/D1/D2/E by randomly selecting 10% or
15% of Chinese words (?NN/NR/VV/VA/JJ?) in the
1383
above SIGHANBakeoff 2008 dataset, and replacing
them with English label ENG.
The differences of these datasets are as following:
? Dataset A only contains English words with
tags ?NN/VV?.
? Dataset B contains English words with tags
?NN/VV/VA?.
? Dataset C contains one more tag ?NR? than
Dataset B.
? Datasets D1 and D2 contain one more tag ?JJ?
than Dataset B. The difference between D1
andD2 is thatD2 has about 50%more English
words than D1 in training set.
? Dataset E contains English words with all the
tags ?NN/NR/VV/VA/JJ?.
The detailed information of datasets
A/B/C/D1/D2/E is shown in Table 10.
Table 10: The Synthetic Chinese-English Mixed Dataset
Dataset Numbers of ENGNN NR VV VA JJ
A Train 16302 0 9007 0 0Test 1675 0 841 0 0
B Train 16116 0 8882 906 0Test 1573 0 830 58 0
C Train 16312 4057 9067 899 0Test 1549 400 795 61 0
D1
Train 16042 0 8957 855 1539
Test 1588 0 845 58 150
D2
Train 23705 0 13154 1300 2211
Test 1588 0 845 58 150
E Train 16066 4162 9156 886 1547Test 1647 415 809 57 141
The results are shown in Table 11. On dataset E,
our method achieves 6.78% higher performance on
tagging ENG labels than traditional static features.
This result is reasonable because our model can use
more flexible feature templates to extract features
and reduce the problem of being dependent on spe-
cific English words.
Tables 12/13/14/15/16/17 show the detailed re-
sults on datasets A/B/C/D1/D2/E.
Table 11: Performances of POS Tagging on Datasets
A/B/C/D1/D2/E
Dataset Method ENG labels TotalF1 F1
A Baseline 80.25 88.74Our 83.03 89.72
B Baseline 76.72 88.51Our 80.54 89.55
C Baseline 68.16 88.13Our 70.34 88.99
D1
Baseline 71.30 88.33
Our 74.02 89.15
D2
Baseline 69.59 88.09
Our 74.10 89.15
E Baseline 61.58 87.71Our 68.36 88.83
Experiment on dataset A gets the best result be-
cause ?NN? and ?VV? can be easily distinguished by
its context. Sometimes, ?VA? has the similar context
with ?VV?, experiment on datasetB shows its influ-
ence. The performances on datasetsB/C/E descend
in turn. The reason is that words with tag ?NN? or
?NR/JJ? have the similar usage/contexts in Chinese.
Since we use the same form ENG instead of real
words, there are no differences between these words,
which leads to some errors. Though the datasets is
generated randomly, we can see our method perform
better on every dataset than the baseline.
Table 12: Performances on Dataset A
POS tag Method P R F1
NN Baseline 84.36 86.33 85.33Our 85.37 89.91 87.58
VV Baseline 71.45 68.13 69.75Our 77.53 69.32 73.20
Table 13: Performances on Dataset B
POS tag Method P R F1
NN Baseline 84.89 80.36 82.56Our 83.51 88.87 86.11
VV Baseline 65.90 72.65 69.11Our 75.75 67.35 71.30
VA Baseline 36.84 36.21 36.52Our 51.02 43.10 46.73
1384
Table 14: Performances on Dataset C
POS tag Method P R F1
NN Baseline 73.77 78.24 75.94Our 76.84 77.99 77.41
VV Baseline 61.67 66.79 64.13Our 64.94 67.80 66.34
NR Baseline 55.22 37.00 44.31Our 55.65 50.50 52.95
VA Baseline 63.64 34.43 44.68Our 60.00 39.34 47.52
Table 15: Performances on DatasetD1
POS tag Method P R F1
NN Baseline 77.15 81.42 79.23Our 76.70 88.54 82.20
VV Baseline 67.53 64.50 65.98Our 79.65 59.76 68.29
JJ Baseline 25.00 18.00 20.93Our 22.92 14.67 17.89
VA Baseline 36.00 31.03 33.33Our 28.57 37.93 32.59
Table 16: Performances on DatasetD2
POS tag Method P R F1
NN Baseline 79.11 74.87 76.93Our 79.29 82.68 80.95
VV Baseline 55.77 72.78 65.64Our 69.17 70.89 70.02
JJ Baseline 27.27 12.00 16.67Our 34.38 22.00 26.83
VA Baseline 37.21 27.59 31.68Our 52.17 20.69 29.63
6.3 POS Tagging for Mixed Texts with a Real
Dataset
To investigate the actual performance, we collect
a real dataset from Web, which consists of 142 rep-
resentative Chinese-English mixed sentences. This
dataset contains 4, 238 Chinese characters and 275
English words. Since we focus on the performance
for English words, we only label the POS tags of the
English words. Table 18 shows some examples in
the real dataset of mixed texts.
Table 17: Performances on Dataset E
POS tag Method P R F1
NN Baseline 72.41 68.85 70.59Our 71.18 84.88 77.43
VV Baseline 63.65 59.09 61.28Our 76.19 55.38 64.14
JJ Baseline 28.57 25.53 26.97Our 30.21 20.57 24.47
VA Baseline 44.83 45.61 45.22Our 60.42 50.88 55.24
NR Baseline 38.03 52.05 43.95Our 52.01 46.75 49.24
Table 18: Examples in Real Dataset of Mixed Texts
?? [Ninja Cloud/NR] ????? [Ninja
Blocks/NR] ? ? [Facebook/NR]? [Twit-
ter/NR]?[Dropbox/NR]??????
By using [Ninja Cloud/NR], [Ninja
Blocks/NR] can connect to [Facebook/NR],
[Twitter/NR], [Dropbox/NR].
?? [follow/VV]?????????
You should [follow/VV] this man?s work.
?????????? [COOL/VA]?
... very [COOL/VA]!
The information of the real dataset is shown in Ta-
ble 19. If all involved English words are tagging as
?NN?, the precision is just 56%.
Table 19: The Numbers of English Words with Different
Tags in Dataset R
Dataset NN VV VA NR
R 154 58 28 35
Since there is no noun-modifier ?JJ? in our col-
lected data. We use the models trained on dataset
B and C to tag the real data. The results are shown
in Table 20. The difference between model B and
C is that model B regards all words with tag ?NR?
as ?NN?. Since it is difficult to distinguish between
?NR? and ?NN? merely according to the context,
model B performs better than model C.
The detail results of model B and C are shown in
Table 21 and 22.
1385
Table 20: Performances of POS Tagging on R
Model Method ENGF1
B Baseline 74.91Our 82.55
C Baseline 70.91Our 74.91
Table 21: Performances of Model B on Dataset R
POS tag Method P R F1
NN Baseline 88.62 78.31 83.15Our 91.67 87.30 89.43
VV Baseline 48.31 74.14 58.50Our 60.53 79.31 68.66
VA Baseline 78.95 53.57 63.83Our 84.21 57.14 68.09
Table 22: Performances of Model C on Dataset R
POS tag Method P R F1
NN Baseline 80.25 81.82 81.03Our 84.56 81.82 83.17
VV Baseline 54.88 77.59 64.29Our 61.25 84.48 71.01
VA Baseline 84.62 39.29 53.66Our 88.24 53.57 66.67
NR Baseline 56.52 37.14 44.83Our 55.17 45.71 50.00
7 Related Works
In recent years, POS tagging has undergone great
development. The mainstream method is to regard
POS tagging as sequence labeling problems (Ra-
biner, 1990; Xue, 2003; Peng et al 2004; Ng and
Low, 2004).
However, the analysis of Chinese-English mixed
texts is rarely involved in previous literature. In
the aspect of the general multilingual POS tagging,
most works focus on modeling cross-lingual corre-
lations and tagging multilingual POS on respective
monolingual texts, not on mixed texts (Cucerzan and
Yarowsky, 2002; Yarowsky et al 2001; Naseem et
al., 2009).
Since we choose to use dynamic word-level fea-
tures to improve the performance of POS tagging,
we also review some works on word-level features.
Semi-Markov Conditional Random Fields (semi-
CRF) (Sarawagi and Cohen, 2004) is a model in
which segmentation task is implicitly included into
the decoding algorithm. In this model, feature rep-
resentation would be more flexible than traditional
CRFs, since features can be extracted from the previ-
ous/the next segmentation within a window of vari-
able size. The problem of this approach lies in that
the decoding algorithm depends on the predefined
window size to exploit the boundaries of segmenta-
tions but not the real length of words.
Bunescu (2008) presents an improved pipeline
model in which the output of the previous subtasks
are considered as hidden variables, and the hidden
variables together with their probabilities denoting
the confidence are used as probabilistic features in
the next subtasks. One shortcoming of this method
is inefficiency caused by the calculation of marginal
probabilities of features. The other disadvantages
of the pipeline method are error propagation and the
need of separate training of different subtasks in the
pipeline. Another disadvantage of pipeline method
is error propagation.
Jiang et al(2008) proposes a cascaded linear
model for joint Chinese word segmentation and POS
tagging. With a character-based perceptron as the
core, combinedwith real-valued features such as lan-
guage models, the cascaded model can efficiently
utilize knowledge sources that are inconvenient to
incorporate into the perceptron directly. However,
they use POS tags or word information in a Brute-
Force way, which may suffer from the problem of
time complexity.
Sun (2011) presents a stacked sub-word model for
joint Chinese word segmentation and POS tagging.
By merging the outputs of the three predictors (in-
cluding one word-based segmenter) into sub-word
sequences, rich contextual features can be approx-
imately derived. The experiments are conducted to
show the effectiveness of using word-based informa-
tion.
The difference between the above methods and
ours is that our word-level features are dynamically
generated in the decoding stage without exhaustive
or preprocessed word segmentation.
1386
8 Conclusion
In this paper, we focus on Chinese-English mixed
texts and use dynamic features for POS tagging.
To overcome the problem of the lack of annotated
corpus on mixed texts, our features use both lo-
cal and non-local information and take advantage of
the characteristics of Chinese-English mixed texts.
The experiments demonstrate the effectiveness of
our method. It should be noted that our method is
also effective for the mixed texts of Chinese and any
foreign languages since we use ?Unified Replace-
ment?.
For future works, we plan to improve our approx-
imate tagging algorithm to reduce error propagation.
In addition, we will refer to an English dictionary
to generate some useful features to distinguish be-
tween ?NR? and ?NN? in Chinese-English mixed
texts and add some statistical features derived from
English resources, such as the most common tag of
each English word. We would also like to investi-
gate these features in more applications of natural
language processing, such as name entity recogni-
tion, information extraction, etc.
Acknowledgements
We would like to thank the anonymous reviewers
for their valuable comments. We also thanks Amy
Zhou for her help in spell and grammar checking.
This work was funded by NSFC (No.61003091 and
No.61073069), 863 Program (No.2011AA010604)
and 973 Program (No.2010CB327900).
References
Razvan C. Bunescu. 2008. Learning with probabilistic
features for improved pipeline models. In EMNLP,
pages 670?679. ACL.
Michael Collins. 2002. Discriminative training methods
for hidden markov models: theory and experiments
with perceptron algorithms. In Proceedings of the
ACL-02 conference on Empirical methods in natural
language processing - Volume 10, EMNLP ?02, pages
1?8, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.
Koby Crammer and Yoram Singer. 2003. Ultraconser-
vative online algorithms for multiclass problems. J.
Mach. Learn. Res., 3:951?991, March.
Koby Crammer, Ofer Dekel, Joseph Keshet, Shai
Shalev-Shwartz, and Yoram Singer. 2006. Online
passive-aggressive algorithms. J. Mach. Learn. Res.,
7:551?585, December.
Silviu Cucerzan and David Yarowsky. 2002. Boot-
strapping a multilingual part-of-speech tagger in one
person-day. In proceedings of the 6th conference on
Natural language learning - Volume 20, COLING-
02, pages 1?7, Stroudsburg, PA, USA. Association for
Computational Linguistics.
Wenbin Jiang, Liang Huang, Qun Liu, and Yajuan L?.
2008. A cascaded linear model for joint chinese word
segmentation and part-of-speech tagging. In Kath-
leen McKeown, Johanna D. Moore, Simone Teufel,
James Allan, and Sadaoki Furui, editors, ACL, pages
897?904. The Association for Computer Linguistics.
C. Jin and X. Chen. 2008. The fourth international chi-
nese language processing bakeoff: Chinese word seg-
mentation, named entity recognition and chinese pos
tagging. In Sixth SIGHAN Workshop on Chinese Lan-
guage Processing, page 69.
T. Naseem, B. Snyder, J. Eisenstein, and R. Barzilay.
2009. Multilingual part-of-speech tagging: Two unsu-
pervised approaches. Journal of Artificial Intelligence
Research, 36(1):341?385.
H.T. Ng and J.K. Low. 2004. Chinese part-of-speech
tagging: One-at-a-time or all-at-once? word-based or
character-based. In Proceedings of EMNLP, volume
2004, page 277.
Fuchun Peng, Fangfang Feng, and Andrew McCallum.
2004. Chinese segmentation and new word detection
using conditional random fields. In Proceedings of the
20th international conference on Computational Lin-
guistics, COLING ?04, Stroudsburg, PA, USA. Asso-
ciation for Computational Linguistics.
Lawrence R. Rabiner. 1990. Readings in speech recog-
nition. chapter A tutorial on hidden Markov mod-
els and selected applications in speech recognition,
pages 267?296. Morgan Kaufmann Publishers Inc.,
San Francisco, CA, USA.
Sunita Sarawagi and William W. Cohen. 2004. Semi-
markov conditional random fields for information ex-
traction. In NIPS.
Weiwei Sun. 2011. A stacked sub-word model for
joint chinese word segmentation and part-of-speech
tagging. In Dekang Lin, Yuji Matsumoto, and Rada
Mihalcea, editors, ACL, pages 1385?1394. The Asso-
ciation for Computer Linguistics.
F. Xia. 2000. The part-of-speech tagging guidelines for
the Penn Chinese Treebank (3.0).
N. Xue. 2003. Chinese word segmentation as character
tagging. Computational Linguistics and Chinese Lan-
guage Processing, 8(1):29?48.
D. Yarowsky, G. Ngai, and R. Wicentowski. 2001. In-
ducing multilingual text analysis tools via robust pro-
jection across aligned corpora. In Proceedings of
1387
the first international conference on Human language
technology research, pages 1?8. Association for Com-
putational Linguistics.
1388
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 658?668,
Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational Linguistics
Joint Chinese Word Segmentation and POS Tagging on
Heterogeneous Annotated Corpora with Multiple Task Learning
Xipeng Qiu, Jiayi Zhao, Xuanjing Huang
Fudan University, 825 Zhangheng Road, Shanghai, China
xpqiu@fudan.edu.cn, zjy.fudan@gmail.com, xjhuang@fudan.edu.cn
Abstract
Chinese word segmentation and part-of-
speech tagging (S&T) are fundamental
steps for more advanced Chinese language
processing tasks. Recently, it has at-
tracted more and more research interests
to exploit heterogeneous annotation cor-
pora for Chinese S&T. In this paper, we
propose a unified model for Chinese S&T
with heterogeneous annotation corpora.
We first automatically construct a loose
and uncertain mapping between two rep-
resentative heterogeneous corpora, Penn
Chinese Treebank (CTB) and PKU?s Peo-
ple?s Daily (PPD). Then we regard the
Chinese S&T with heterogeneous corpora
as two ?related? tasks and train our model
on two heterogeneous corpora simultane-
ously. Experiments show that our method
can boost the performances of both of the
heterogeneous corpora by using the shared
information, and achieves significant im-
provements over the state-of-the-art meth-
ods.
1 Introduction
Currently, most of statistical natural language
processing (NLP) systems rely heavily on manu-
ally annotated resources to train their statistical
models. The more of the data scale, the better
the performance will be. However, the costs are
extremely expensive to build the large scale re-
sources for some NLP tasks. Even worse, the ex-
isting resources are often incompatible even for a
same task and the annotation guidelines are usu-
ally different for different projects, since there
are many underlying linguistic theories which
explain the same language with different per-
spectives. As a result, there often exist multi-
ple heterogeneous annotated corpora for a same
task with vastly different and incompatible an-
notation philosophies. These heterogeneous re-
sources are waste on some level if we cannot fully
exploit them.
However, though most of statistical NLP
methods are not bound to specific annota-
tion standards, almost all of them cannot deal
simultaneously with the training data with
different and incompatible annotation. The
co-existence of heterogeneous annotation data
therefore presents a new challenge to utilize
these resources.
The problem of incompatible annotation stan-
dards is very serious for many tasks in NLP,
especially for Chinese word segmentation and
part-of-speech (POS) tagging (Chinese S&T). In
Chinese S&T, the annotation standards are of-
ten incompatible for two main reasons. One is
that there is no widely accepted segmentation
standard due to the lack of a clear definition
of Chinese words. Another is that there are no
morphology for Chinese word so that there are
many ambiguities to tag the parts-of-speech for
Chinese word. For example, the two commonly-
used corpora, PKU?s People?s Daily (PPD) (Yu
et al, 2001) and Penn Chinese Treebank (CTB)
(Xia, 2000), use very different segmentation and
POS tagging standards.
For example, in Table 1, it is very different
to annotate the sentence ?????????
?? (Liu Xiang reaches the national final in
China)? with guidelines of CTB and PDD. PDD
breaks some phrases, which are single words in
658
Liu Xiang reachs China final
CTB ??/NR ??/VV ???/NN ???/NN
PDD ?/nrf ?/nrg ??/v ??/ns ?/n ?/b ??/vn
Table 1: Incompatible word segmentation and POS tagging standards between CTB and PDD
CTB, into two words. The POS tagsets are also
significantly different. For example, PDD gives
diverse tags ?n? and ?vn? for the noun, while
CTB just gives ?NN?. For proper names, they
may be tagged as ?nr?, ?ns?, etc in PDD, while
they are just tagged as ?NR? in CTB.
Recently, it has attracted more and more re-
search interests to exploit heterogeneous anno-
tation data for Chinese word segmentation and
POS tagging. (Jiang et al, 2009) presented a
preliminary study for the annotation adapta-
tion topic. (Sun and Wan, 2012) proposed a
structure-based stacking model to fully utilize
heterogeneous word structures. They also re-
ported that there is no one-to-one mapping be-
tween the heterogeneous word classification and
the mapping between heterogeneous tags is very
uncertain.
These methods usually have a two-step pro-
cess. The first step is to train the preliminary
taggers on heterogeneous annotations. The sec-
ond step is to train the final taggers by using
the outputs of the preliminary taggers as fea-
tures. We call these methods as ?pipeline-
based? methods.
In this paper, we propose a method for joint
Chinese word segmentation and POS tagging
with heterogeneous annotation corpora. We re-
gard the Chinese S&T with heterogeneous cor-
pora as two ?related? tasks which can improve
the performance of each other. Since it is impos-
sible to establish an exact mapping between two
annotations, we first automatically construct a
loose and uncertain mapping the heterogeneous
tagsets of CTB and PPD. Thus we can tag a sen-
tence in one style with the help of the ?related?
information in another heterogeneous style. The
proposed method can improve the performances
of joint Chinese S&T on both corpora by using
the shared information of each other, which is
proven effective by experiments.
There are three main contributions of our
model:
? First, we regard these two joint S&T tasks
on different corpora as two related tasks
which have interdependent and peer rela-
tionship.
? Second, different to the pipeline-based
methods, our model can be trained simul-
taneously on the heterogeneous corpora.
Thus, it can also produce two different
styles of POS tags.
? Third, our model do not depend on the
exactly correct mappings between the two
heterogeneous tagsets. The correct map-
ping relations can be automatically built in
training phase.
The rest of the paper is organized as follows:
We first introduce the related works in section 2
and describe the background of character-based
method for joint Chinese S&T in section 3. Sec-
tion 4 presents an automatic method to build
the loose mapping function. Then we propose
our method on heterogeneous corpora in 5 and
6. The experimental results are given in section
7. Finally, we conclude our work in section 8.
2 Related Works
There are some works to exploit heteroge-
neous annotation data for Chinese S&T.
(Gao et al, 2004) described a transformation-
based converter to transfer a certain annotation-
style word segmentation result to another style.
However, this converter need human designed
transformation templates, and is hard to be gen-
eralized to POS tagging.
(Jiang et al, 2009) proposed an automatic
adaptation method of heterogeneous annotation
standards, which depicts a general pipeline to in-
tegrate the knowledge of corpora with different
659
TaggerPPD
TaggerCTB
Input: x
Output: f(x)
Output: CTB-style Tags
z=f(x)
y=h(x,f(x))
Figure 1: Traditional Pipeline-based Strategy for
Heterogeneous POS Tagging
underling annotation guidelines. They further
proposed two optimization strategies, iterative
training and predict-self re-estimation, to fur-
ther improve the accuracy of annotation guide-
line transformation (Jiang et al, 2012).
(Sun and Wan, 2012) proposed a structure-
based stacking model to fully utilize heteroge-
neous word structures.
These methods regard one annotation as the
main target and another annotation as the com-
plementary/auxiliary purposes. For example, in
their solution, an auxiliary tagger TaggerPPD
is trained on a complementary corpus PPD, to
assist the target CTB-style TaggerCTB. To re-
fine the character-based tagger, PPD-style char-
acter labels are directly incorporated as new
features. The brief sketch of these methods is
shown in Figure 1.
The related work in machine learning liter-
ature is multiple task learning (Ben-David and
Schuller, 2003), which learns a problem together
with other related problems at the same time,
using a shared representation. This often leads
to a better model for the main task, because
it allows the learner to use the commonality
among the tasks. Multiple task learning has
been proven quite successful in practice and has
been also applied to NLP (Ando and Zhang,
2005). We also preliminarily verified that mul-
tiple task learning can improve the performance
on this problem in our previous work (Zhao et
al., 2013), which is a simplified case of the work
in this paper and has a relative low complexity.
Different with the multiple task learning,
whose tasks are actually different labels in the
same classification task, our model utilizes the
shared information between the real different
tasks and can produce the corresponding differ-
ent styles of outputs.
3 Joint Chinese Word Segmentation
and POS Tagging
Currently, the mainstream method of Chi-
nese POS tagging is joint segmentation & tag-
ging with character-based sequence labeling
models(Lafferty et al, 2001), which can avoid
the problem of segmentation error propagation
and achieve higher performance on both sub-
tasks(Ng and Low, 2004; Jiang et al, 2008; Sun,
2011; Qiu et al, 2012).
The label of each character is the cross-
product of a segmentation label and a tagging
label. If we employ the commonly used label set
{B, I, E, S} for the segmentation part of cross-
labels ({B, I, E} represent Begin, Inside, End of
a multi-node segmentation respectively, and S
represents a Single node segmentation), the la-
bel of character can be in the form of {B-T}(T
represents POS tag). For example, B-NN indi-
cates that the character is the begin of a noun.
4 Automatically Establishing the
Loose Mapping Function for the
Labels of Characters
To combine two human-annotated corpora,
the relationship of their guidelines should be
found. A mapping function should be estab-
lished to represent the relationship between two
different annotation guidelines. However, the
exact mapping relations are hard to establish.
As reported in (Sun and Wan, 2012), there is
no one-to-one mapping between their heteroge-
neous word classification, and the mapping be-
tween heterogeneous tags is very uncertain.
Fortunately, there is a loose mapping
can be found in CTB annotation guide-
line1 (Xia, 2000). Table 2 shows some
1Available at http://www.cis.upenn.edu/ ?chi-
660
CTB?s Tag PDD? Tag1
Total tags 33 26
verbal noun NN v[+nom]
proper noun NR n
? (shi4) VC v
? (you3) VE, VV v
conjunctions CC, CS c
other verb VV, VA v, a, z
number CD, OD m
1 The tag set of PDD just includes the 26 broad
categories in the mapping table. The whole tag set
of PDD has 103 sub categories.
Table 2: Examples of mapping between CTB and
PDD?s tagset
mapping relations in CTB annotation guide-
line. These loose mapping relations are
many-to-many mapping. For example, the
mapping may be ?NN/CTB?{n,nt,nz}/PDD?,
?NR/CTB?{nr,ns}/PDD?, ?v/PDD?{VV,
VA}/CTB? and so on.
We define T1 and T2 as the tag sets for two
different annotations, and t1 ? T1 and t2 ? T2
are the corresponding tags in two tag sets re-
spectively.
We first establish a loose mapping function
m : T1 ? T2 ? {0, 1} between the tags of CTB
and PDD.
m(t1, t2) =
{
1 if t1 and t2 have mapping relation
0 else
(1)
The mapping relations are automatically
build from the CTB guideline (Xia, 2000). Due
to the fact that the tag set of PPD used in
the CTB guideline is just broad categories, we
expand the mapping relations to include the
sub categories. If a PPD?s tag is involved
in the mapping, all its sub categories should
be involved. For example, for the mapping
?NR/CTB?nr/PDD?, the relation of NR and
nrf/nrg should be added in the mapping rela-
tions too (nrf/nrg belong to nr).
Since we use the character-based joint S&T
model, we also need to find the mapping func-
tion between the labels of characters.
nese/posguide.3rd.ch.pdf
In this paper, we employ the commonly used
label set {B, I, E, S} for the segmentation part
of cross-labels and the label of character can be
in the form of {B-T}(T represents POS tag).
Thus, each mapping relation t1 ? t2 can be
automatically transformed to four forms: B-
t1 ?B-t2, I-t1 ?I-t2, E-t1 ?E-t2 and S-t1 ?S-
t2. (?B-NR/CTB?{B-nr,B-ns}/PPD? for ex-
ample).
Beside the above transformation, we also
give a slight modification to adapt the dif-
ferent segmentation guidelines. For in-
stance, the person name ??? (Mo Yan)?
is tagged as ?B-NR, E-NR? in CTB but
?S-nrf, S-nrg? in PPD. So, some spe-
cial mappings may need to be added like
?B-NR/CTB?S-nrf/PPD?, ?E-NR/CTB?{S-
nrg, E-nrg}/PPD?, ?M-NR/CTB?{B-nrg, M-
nrg}/PPD? and so on. Although these spe-
cial mappings are also established automatically
with an exhaustive solution. In fact, we give seg-
mentation alignment only to proper names due
to the limitation of computing ability.
Thus, we can easily build the loose bidirec-
tional mapping function m? for the labels of
characters. An illustration of our construction
flowchart is shown in Figure 2.
Finally, total 524 mappings relationships are
established.
5 Joint Chinese S&T with
Heterogeneous Data with Multiple
Task Learning
Inspired by the multiple task learning (Ben-
David and Schuller, 2003), we can regard the
joint Chinese S&T with heterogeneous data as
two ?related? tasks, which can improve the
performance of each other simultaneously with
shared information.
5.1 Sequence Labeling Model
We first introduce the commonly used se-
quence labeling model in character-based joint
Chinese S&T.
Sequence labeling is the task of assigning la-
bels y = y1, . . . , yn(yi ? Y) to an input sequence
x = x1, . . . , xn. Y is the set of labels.
661
PPD-style
CTB-style NR
nr
NR
nrf nrg
B-NR S-NR...
B-nrf B-nrg S-nrgS-nrg...
mapping function m() 
between tags
mapping function m() 
between labels
~
Figure 2: An Illustration of Automatically Establishing the Loose Mapping Function
Given a sample x, we define the feature
?(x,y). Thus, we can label x with a score func-
tion,
y? = arg max
y
S(w,?(x,y)), (2)
where w is the parameter of score function S(?).
The feature vector ?(x,y) consists of lots of
overlapping features, which is the chief benefit of
discriminative model. Different algorithms vary
in the definition of S(?) and the corresponding
objective function. S(?) is usually defined as lin-
ear or exponential family function.
For first-order sequence labeling, the feature
can be denoted as ?k(x, yi?1:i), where i stands
for the position in the sequence and k stands for
the number of feature templates. For the linear
classifier, the score function can be rewritten in
detail as
y? = arg max
y
L
?
i=1
(?u, f(x, yi)?+ ?v,g(x, yi?1:i)?) ,
(3)
where yi:j denotes label subsequence
yiyi+1 ? ? ? yj ; f and g denote the state and
transition feature vectors respectively, u and v
are their corresponding weight vectors; L is the
length of x.
5.2 The Proposed Model
Different to the single task learning, the het-
erogeneous data have two sets of labels Y and
Z.
The heterogeneous datasets Ds and Ds con-
sist of {xi,yi}(i = 0, ? ? ? ,m) and {xi, zi}(i =
0, ? ? ? , n) respectively.
For a sequence x = x1, . . . , xL with length
L. , there may have two output sequence labels
y = y1, . . . , yL and z = z1, . . . , zL, where yi ? Y
and zi ? Z.
We rewrite the loose mapping function m? be-
tween two label sets into the following forms,
?(y) = {z|m?(y, z) = 1}, (4)
?(z) = {y|m?(y, z) = 1}, (5)
where ?(z) ? Y and ?(y) ? Z are the subsets
of Y and Z. Give a label y(or z) in an annota-
tion, the loose mapping function ? returns the
corresponding mapping label set in another het-
erogeneous annotation.
Our model for heterogeneous sequence label-
ing can be write as
y? = arg max
y,yi?Y
L
?
i=1
(
?u, f(x, yi)?
+ ?s,
?
z??(yi)
h(x, z)?
+ ?v1,g1(x, yi?1:i)?
+ ?v2,
?
zi?1??(yi?1)
zi??(yi)
g2(x, zi?1:i)?
)
, (6)
and
z? = arg max
z,zi?Z
L
?
i=1
(
?u,
?
y??(zi)
f(x, y)?+
?s,h(x, zi)?
+ ?v1,
?
yi?1??(zi?1)
yi??(zi)
g1(x, yi?1:i)?
+ ?v2,g2(x, zi?1:i)?
)
, (7)
where f and h represent the state feature vectors
on two label sets Y and Z respectively.
In Eq.(6) and (7), the score of the label of
every character is decided by the weights of the
corresponding mapping labels and itself.
662
Input sequence: x
Output: PPD-style Tags
TaggerPPD TaggerCTBSharedInformation
Output: CTB-style Tags
Figure 3: Our model for Heterogeneous POS Tagging
The main challenge of our model is the effi-
ciency of decoding algorithm, which is similar to
structured learning with latent variables(Liang
et al, 2006) (Yu and Joachims, 2009). Most
methods for structured learning with latent vari-
ables have not expand all possible mappings.
In this paper, we also only expand the map-
ping that with highest according to the current
model.
Our model is shown in Figure 3 and the
flowchart is shown in Algorithm 1. If given the
output type of label T , we only consider the la-
bels in T to initialize the Viterbi matrix, and
the score of each node is determined by all the
involved heterogeneous labels according to the
loose mapping function.
input : character sequence x1:L
loose mapping function ?
output type: T (T ? {Ty, Tz})
output: label sequence ls
if T == Ty then
calculate ls using Eq. (6);
else if T == Tz then
calculate ls using Eq. (7) ;
else
return null;
end
return ls
Algorithm 1: Flowchart of the Tagging pro-
cess of the proposed model
6 Training
We use online Passive-Aggressive (PA) algo-
rithm (Crammer and Singer, 2003; Crammer et
al., 2006) to train the model parameters. Fol-
lowing (Collins, 2002), the average strategy is
used to avoid the overfitting problem.
For the sake of simplicity, we merge the Eq.(6)
and (7) into a unified formula.
Given a sequence x and the expect type of
tags T , the merged model is
y? = arg max
y
t(y)=T
?w,
?
z??(y)
?(x, z)?, (8)
where t(y) is a function to judge the type of
output tags; ?(y) represents the set {?(y1) ?
?(y2) ? ? ? ? ? ?(yL)} ? {y}, where ? means
Cartesian product; w = (uT , sT ,vT1 ,vT2 )T and
? = (fT ,hT ,gT1 ,gT2 )T .
We redefine the score function as
S(w,x,y) = ?w,
?
z??(y)
?(x, z)?. (9)
Thus, we rewrite the model into a unified for-
mula
y? = arg max
y
t(y)=T
S(w,x,y). (10)
Given an example (x,y), y? is denoted as the
incorrect label sequence with the highest score
y? = arg max
y? ?=y
t(y?)=t(y)
S(w,x, y?). (11)
The margin ?(w; (x,y)) is defined as
?(w; (x,y)) = S(w,x,y)? S(w,x, y?). (12)
Thus, we calculate the hinge loss
?(w; (x,y)), (abbreviated as ?w) by
?w =
{
0, ?(w; (x,y)) > 1
1? ?(w; (x,y)), otherwise
(13)
In round k, the new weight vector wk+1 is
calculated by
wk+1 = arg min
w
1
2 ||w?wk||
2 + C ? ?,
s.t. ?(w; (xk,yk)) <= ? and ? >= 0 (14)
663
where ? is a non-negative slack variable, and C
is a positive parameter which controls the influ-
ence of the slack term on the objective function.
Following the derivation in PA (Crammer et
al., 2006), we can get the update rule,
wk+1 = wk + ?kek, (15)
where
ek =
?
z??(yk)
?(xk, z)?
?
z??(y?k)
?(xk, z),
?k = min(C,
?wk
?ek?2
).
As we can see from the Eq. (15), when we up-
date the weight vector, the update information
includes not only the features extracted from
current input, but also that extracted from the
loose mapping sequence of input. For each fea-
ture, the weights of its corresponding related
features derived from the loose mapping func-
tion will be updated with the same magnitude
as well as itself.
Our method regards two annotations to be in-
terdependence and peer relationship. Therefore,
the two heterogeneous annotated corpora can be
simultaneously used as the input of our training
algorithm. Because of the tagging and training
algorithm, the weights and tags of two corpora
can be used separately with the only dependent
part built by the loose mapping function.
Our training algorithm based on PA is shown
in Algorithm 2.
6.1 Analysis
Although our mapping function between two
heterogeneous annotations is loose and uncer-
tain, our online training method can automat-
ically increase the relative weights of features
from the beneficial mapping relations and de-
crease the relative weights of features from the
unprofitable mapping relations.
Consider an illustrative loose mapping re-
lation ?NN/CTB?n,nt,nz/PDD?. For an in-
put sequence x and PDD-style output is ex-
pected. If the algorithm tagging a charac-
ter as ?n/PDD?(with help of the weight of
?NN/CTB?) and the right tag isn?t one of
input : mixed heterogeneous datasets:
(xi,yi), i = 1, ? ? ? , N ;
parameters: C,K;
loose mapping function: ? ;
output: wK
Initialize: wTemp? 0,w? 0;
for k = 0 ? ? ?K ? 1 do
for i = 1 ? ? ?N do
receive an example (xi,yi);
predict: y?i with Eq.(11);
if hinge loss ?w > 0 then
update w with Eq. (15);
end
end
wTemp = wTemp + w ;
end
wK = wTemp/K ;
Algorithm 2: Training Algorithm
?n,nt,nz/PDD?, the weight of ?NN/CTB? will
also be decreased, which is reasonable since
it is beneficial to distinguish the right tag.
And if the right tag is one of ?n,nt,nz/PDD?
but not ?n/PDD? (for example, ?nt/PDD?),
which means it is a ?NN/CTB?, the weight of
?NN/CTB? will remain unchanged according to
the algorithm (updating ?n/PDD? changes the
?NN/CTB?, but updating ?nt/PDD? changes it
back).
Therefore, after multiple iterations, useful fea-
tures derived from the mapping function are
typically receive more updates, which take rela-
tively more responsibility for correct prediction.
The final model has good parameter estimates
for the shared information.
We implement our method based on Fu-
danNLP(Qiu et al, 2013).
7 Experiments
7.1 Datasets
We use the two representative corpora men-
tioned above, Penn Chinese Treebank (CTB)
and PKU?s People?s Daily (PPD) in our ex-
periments.
664
Dataset Partition Sections Words
CTB-5
Training 1?270 0.47M
400?931
1001?1151
Develop 301?325 6.66K
Test 271?300 7.82K
CTB-S Training 0.64MTest - 59.96K
PPD Training - 1.11MTest - 0.16M
Table 3: Data partitioning for CTB and PD
7.1.1 CTB Dataset
To better comparison with the previous
works, we use two commonly used criterions to
partition CTB dataset into the train and test
sets.
? One is the partition criterion used in (Jin
and Chen, 2008; Jiang et al, 2009; Sun and
Wan, 2012) for CTB 5.0.
? Another is the CTB dataset from the
POS tagging task of the Fourth Interna-
tional Chinese Language Processing Bake-
off (SIGHAN Bakeoff 2008)(Jin and Chen,
2008).
7.1.2 PPD Dataset
For the PPD dataset, we use the PKU dataset
from SIGHAN Bakeoff 2008.
The details of all datasets are shown in Table
3. Our experiment on these datasets may lead to
a fair comparison of our system and the related
works.
7.2 Setting
We conduct two experiments on CTB-5 +
PPD and CTB-S + PPD respectively.
The form of feature templates we used is
shown in Table 7.2, where C represents a Chi-
nese character, and T represents the character-
based tag. The subscript i indicates its position
related to the current character.
Our method can be easily combined with
some other complicated models, but we only use
the simple one for the purpose of observing the
Ci, T0(i = ?2,?1, 0, 1, 2)
Ci, Ci+1, T0(i = ?1, 0)
T?1, T0
Table 4: Feature Templates
sole influence of our unified model. The parame-
ter C is tested on develop dataset, and we found
that it just impact the speed of convergence and
have no effect on the accuracy. Moreover, since
we use the averaged strategy, we wish more iter-
ations to avoid overfitting and set a small value
0.01 to it. The maximum number of iterations
K is 50.
The F1 score is used for evaluation, which is
the harmonic mean of precision P (percentage of
predict phrases that exactly match the reference
phrases) and recall R (percentage of reference
phrases that returned by system).
7.3 Evaluation on CTB-5 + PPD
The experiment results on the heterogeneous
corpora CTB-5 + PPD are shown in Table
5. Our method obtains an error reductions of
24.08% and 90.8% over the baseline on CTB-5
and PDD respectively.
Our method also gives better performance
than the pipeline-based methods on heteroge-
neous corpora, such as (Jiang et al, 2009) and
(Sun and Wan, 2012).
The reason is that our model can utilize the
information of both corpora effectively, which
can boost the performance of each other.
Although the loose mapping function are bidi-
rectional between two annotation tagsets, we
may also use unidirectional mapping. Therefore,
we also evaluate the performance when we use
unidirectional mapping. We just use the map-
ping function ?PDD?CTB, which means we ob-
tain the PDD-style output without the informa-
tion from CTB in tagging stage. Thus, in train-
ing stage, there are no updates for the weights of
CTB-features for the instances from PDD cor-
pus, while instances from CTB corpus can result
to updates for PDD-features.
Surprisedly, we find that the one-way map-
ping can also improve the performances of both
corpora. The results are shown in Table 7. The
665
Method Training Dataset Test Dataset P R F1
(Jiang et al, 2009) CTB-5, PDD CTB-5 - - 94.02
(Sun and Wan, 2012) CTB-5, PDD CTB-5 94.42 94.93 94.68
Our Model CTB-5 CTB-5 93.28 93.35 93.31
Our Model PDD PDD 89.41 88.58 88.99
Our Model CTB-5, PDD CTB-5 94.74 95.11 94.92
Our Model CTB-5, PDD PDD 90.25 89.73 89.99
Table 5: Performances of different systems on CTB-5 and PPD.
Method Training Dataset Test Dataset P R F1
Our Model CTB-S CTB-S 89.11 89.16 89.13
Our Model PDD PDD 89.41 88.58 88.99
Our Model CTB-S, PDD CTB-S 89.86 90.02 89.94
Our Model CTB-S, PDD PDD 90.5 89.82 90.16
Table 6: Performances of different systems on CTB-S and PPD.
modelPPD?CTB obtains an error reductions of
14.63% and 6.12% over the baseline on CTB-5
and PDD respectively.
Method P R F1
ModelS on CTB-5 93.86 94.73 94.29
ModelS on PDD 90.05 89.28 89.66
?ModelS? is the model which is trained on both CTB-
5 and PDD training datasets with just just using the
unidirectional mapping function ?PDD?CTB.
Table 7: Performances of unidirectional PPD?CTB
mapping on CTB-5 and PPD.
7.4 Evaluation on CTB-S + PPD
Table 6 shows the experiment results on the
heterogeneous corpora CTB-S + PPD. Our
method obtains an error reductions of 7.41% and
10.59% over the baseline on CTB-S and PDD re-
spectively.
7.5 Analysis
As we can see from the above experiments,
our proposed unified model can improve the
performances of the two heterogeneous corpora
with unidirectional or bidirectional loose map-
ping functions. Different to the pipeline-based
methods, our model can use the shared infor-
mation between two heterogeneous POS tag-
gers. Although the mapping function is loose
and uncertain, it is still can boost the perfor-
mances. The features derived from the wrong
mapping function take relatively less responsi-
bility for prediction after multiple updates of
their weights in training stage. The final model
has good parameter estimates for the shared in-
formation.
Another phenomenon is that the performance
of one corpus can gains when the data size of an-
other corpus increases. In our two experiments,
the training set?s size of CTB-S is larger than
CTB-5, so the performance of PDD is higher in
latter experiment.
8 Conclusion
We proposed a method for joint Chinese word
segmentation and POS tagging with heteroge-
neous annotation data. Different to the previous
pipeline-based works, our model is learned on
heterogeneous annotation data simultaneously.
Our method also does not require the exact
corresponding relation between the standards
of heterogeneous annotations. The experimen-
tal results show our method leads to a signif-
icant improvement with heterogeneous annota-
tions over the best performance for this task.
Although our work is for a specific task on joint
Chinese word segmentation and POS, the key
idea to leverage heterogeneous annotations is
very general and applicable to other NLP tasks.
666
In the future, we will continue to refine the
proposed model in two ways: (1) We wish to use
the unsupervised method to extract the loose
mapping relation between the different annota-
tion standards, which is useful to the corpora
without loose mapping guideline. (2) We will
analyze the shared information (weights of the
features derived from the tags which have the
mapping relation) in detail and propose a more
effective model. Besides, we would also like to
investigate for other NLP tasks which have dif-
ferent annotation-style corpora.
Acknowledgments
We would like to thank the anonymous re-
viewers for their valuable comments. This
work was funded by NSFC (No.61003091), Key
Projects in the National Science & Technol-
ogy Pillar Program (2012BAH18B01), Shang-
hai Municipal Science and Technology Com-
mission (12511504500), Shanghai Leading Aca-
demic Discipline Project (B114) and 973 Pro-
gram (No.2010CB327900).
References
Rie Kubota Ando and Tong Zhang. 2005. A frame-
work for learning predictive structures from mul-
tiple tasks and unlabeled data. J. Mach. Learn.
Res., 6:1817?1853, December.
S. Ben-David and R. Schuller. 2003. Exploiting task
relatedness for multiple task learning. Learning
Theory and Kernel Machines, pages 567?580.
Michael Collins. 2002. Discriminative training meth-
ods for hidden markov models: Theory and experi-
ments with perceptron algorithms. In Proceedings
of the 2002 Conference on Empirical Methods in
Natural Language Processing.
K. Crammer and Y. Singer. 2003. Ultraconservative
online algorithms for multiclass problems. Journal
of Machine Learning Research, 3:951?991.
Koby Crammer, Ofer Dekel, Joseph Keshet, Shai
Shalev-Shwartz, and Yoram Singer. 2006. Online
passive-aggressive algorithms. Journal of Machine
Learning Research, 7:551?585.
J. Gao, A. Wu, M. Li, C.N. Huang, H. Li, X. Xia,
and H. Qin. 2004. Adaptive chinese word segmen-
tation. In Proceedings of ACL-2004.
W. Jiang, L. Huang, Q. Liu, and Y. Lu. 2008. A cas-
caded linear model for joint Chinese word segmen-
tation and part-of-speech tagging. In In Proceed-
ings of the 46th Annual Meeting of the Association
for Computational Linguistics. Citeseer.
W. Jiang, L. Huang, and Q. Liu. 2009. Automatic
adaptation of annotation standards: Chinese word
segmentation and POS tagging: a case study. In
Proceedings of the Joint Conference of the 47th
Annual Meeting of the ACL and the 4th Inter-
national Joint Conference on Natural Language
Processing, pages 522?530.
Wenbin Jiang, Fandong Meng, Qun Liu, and Ya-
juan L?. 2012. Iterative annotation transfor-
mation with predict-self reestimation for Chinese
word segmentation. In Proceedings of the 2012
Joint Conference on Empirical Methods in Natu-
ral Language Processing and Computational Nat-
ural Language Learning, pages 412?420, Jeju Is-
land, Korea, July. Association for Computational
Linguistics.
C. Jin and X. Chen. 2008. The fourth interna-
tional Chinese language processing bakeoff: Chi-
nese word segmentation, named entity recognition
and Chinese pos tagging. In Sixth SIGHAN Work-
shop on Chinese Language Processing, page 69.
John D. Lafferty, Andrew McCallum, and Fernando
C. N. Pereira. 2001. Conditional random fields:
Probabilistic models for segmenting and labeling
sequence data. In Proceedings of the Eighteenth
International Conference on Machine Learning.
Percy Liang, Alexandre Bouchard-C?t?, Dan Klein,
and Ben Taskar. 2006. An end-to-end discrimi-
native approach to machine translation. In Pro-
ceedings of the 21st International Conference on
Computational Linguistics and the 44th annual
meeting of the Association for Computational Lin-
guistics, pages 761?768. Association for Computa-
tional Linguistics.
H.T. Ng and J.K. Low. 2004. Chinese part-of-speech
tagging: one-at-a-time or all-at-once? word-based
or character-based. In Proceedings of EMNLP,
volume 4.
Xipeng Qiu, Feng Ji, Jiayi Zhao, and Xuanjing
Huang. 2012. Joint segmentation and tagging
with coupled sequences labeling. In Proceedings
of COLING 2012, pages 951?964, Mumbai, India,
December. The COLING 2012 Organizing Com-
mittee.
Xipeng Qiu, Qi Zhang, and Xuanjing Huang. 2013.
FudanNLP: A toolkit for Chinese natural language
processing. In Proceedings of ACL.
Weiwei Sun and Xiaojun Wan. 2012. Reducing
approximation and estimation errors for Chinese
lexical processing with heterogeneous annotations.
In Proceedings of the 50th Annual Meeting of the
667
Association for Computational Linguistics, pages
232?241.
W. Sun. 2011. A stacked sub-word model for joint
Chinese word segmentation and part-of-speech
tagging. In Proceedings of the 49th Annual Meet-
ing of the Association for Computational Lin-
guistics: Human Language Technologies, pages
1385?1394.
F. Xia, 2000. The part-of-speech tagging guidelines
for the penn Chinese treebank (3.0).
Chun-Nam John Yu and Thorsten Joachims. 2009.
Learning structural svms with latent variables. In
Proceedings of the 26th Annual International Con-
ference on Machine Learning, pages 1169?1176.
ACM.
S. Yu, J. Lu, X. Zhu, H. Duan, S. Kang, H. Sun,
H. Wang, Q. Zhao, and W. Zhan. 2001. Process-
ing norms of modern Chinese corpus. Technical
report, Technical report.
Jiayi Zhao, Xipeng Qiu, and Xuanjing Huang. 2013.
A unified model for joint chinese word segmen-
tation and pos tagging with heterogeneous anno-
tation corpora. In International Conference on
Asian Language Processing, IALP.
668
