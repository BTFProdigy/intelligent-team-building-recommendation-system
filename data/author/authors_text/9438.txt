Coling 2008: Companion volume ? Posters and Demonstrations, pages 67?70
Manchester, August 2008
Modelling Multilinguality in Ontologies 
Elena Montiel-Ponsoda, Guadalupe Aguado de Cea, 
Asunci?n G?mez-P?rez 
Ontology Engineering Group 
Universidad Polit?cnica de Madrid 
emontiel@delicias.dia.fi.upm.es, 
{lupe,asun}@fi.upm.es 
Wim Peters 
Sheffield Natural Language 
Processing Group 
University of Sheffield 
w.peters@dcs.shef.ac.uk 
Abstract 
Multilinguality in ontologies has become 
an impending need for institutions 
worldwide with valuable linguistic re-
sources in different natural languages. 
Since most ontologies are developed in 
one language, obtaining multilingual on-
tologies implies to localize or adapt them 
to a concrete language and culture com-
munity. As the adaptation of the ontology 
conceptualization demands considerable 
efforts, we propose to modify the ontol-
ogy terminological layer, and provide a 
model called Linguistic Information Re-
pository (LIR) that associated to the on-
tology meta-model allows terminological 
layer localization.  
1 Introduction 
Multilinguality in ontologies is nowadays de-
manded by institutions worldwide with a huge 
number of resources in different languages. One 
of these institutions is the FAO 1 . Within the 
NeOn project2, the FAO is currently leading a 
case study on fishery stocks in order to improve 
the interoperability of its information systems. 
The FAO, as an international organization with 
five official languages -English, French, Spanish, 
Arabic and Chinese- deals with heterogeneous 
and multilingual linguistic resources with differ-
ent granularity levels. This scenario is an illustra-
tive example of the need for semantically orga-
nizing great amounts of multilingual data. When 
providing ontologies with multilingual data, one 
of the activities identified in the NeOn ontology 
                                                 
? 2008. Licensed under the Creative Commons Attri-
bution-Noncommercial-Share Alike 3.0 Unported 
license (http://creativecommons.org/licenses/by-nc-
sa/3.0/). Some rights reserved. 
1 http://www.fao.org/ 
2 http://www.neon-project.org/ 
network development process is the Ontology 
Localization Activity, that consists in adapting 
an ontology to a concrete language and culture 
community, as defined in (Su?rez-Figueroa et al, 
2007). In particular, our aim is to obtain multi-
lingual ontologies by localizing its terminologi-
cal layer (terms or labels that name ontology 
classes), rather than modifying its conceptualiza-
tion. Thus, we propose to link ontologies with a 
linguistic model, called LIR, whose main feature 
is that it is holistic in the sense that it (1) pro-
vides a complete and complementary amount of 
linguistic data that allows localization of ontol-
ogy concepts to a specific linguistic and cultural 
universe, and, (2) provides a unified access to 
aggregated multilingual data. The model we pre-
sent in this paper is an enhanced version of the 
one introduced in (Peters et al, 2007). 
2 Related work 
The most widespread modality for introducing 
multilingual data in ontology meta-models con-
sists in using some ontology properties 
(rdfs:label and rdfs:comment3)that define 
labels and descriptions in natural language of 
ontology classes. In this system, information is 
embedded in the ontology. In a similar way, the 
Simple Knowledge Organization System 
(SKOS4) data model for semantically structuring 
thesauri, taxonomies, etc., permits the labelling 
of ontology classes with multilingual strings, and 
even the establishment of some relations between 
labels (preferred label against the alternative 
one). In any case, however, both modelling mo-
dalities restrict the amount of linguistic data that 
can be included in the ontology, and assume full 
synonym relations among the multilingual labels 
associated to one and the same concept.  
A further multilingual model is one adopted by 
the general purpose lexicon EuroWordNet 5 
                                                 
3 www.w3.org/TR/rdf-schema/ 
4 http://www.w3.org/2004/02/skos/specs 
5 http://www.illc.uva.nl/EuroWordNet/ 
67
(EWN). EWN consists of monolingual ontolo-
gies, each one reflecting the linguistic and cul-
tural specificities of a certain language, linked to 
each other through an interlingual set of common 
concepts that allows building equivalences 
among ontologies. Although concept equiva-
lences among localized ontologies are reliable 
and reflect cultural differences, the quantity of 
linguistic information is also limited to labels and 
definitions attached to concepts.  
Finally, we come to the upward trend in recent 
research for providing ontologies with linguistic 
data, which is the association of the ontology 
meta-model to a linguistic model keeping both 
separate. The model for representing and orga-
nizing the linguistic information can be a data 
base (as in GENOMA-KB6 or OncoTerm7), or an 
ontology (as in the case of LingInfo (Buitelaar et 
al., 2006) or LexOnto (Cimiano et al 2007)). 
The main advantage of this modeling modality is 
that it allows the inclusion of as much linguistic 
information as wished, as well as the possibility 
of establishing relations among linguistic ele-
ments. Thus, conceptual information is greatly 
enriched with linguistic data. Additionally, these 
systems are considered domain independent, and 
can be linked to any domain ontology.  
The differentiating aspect among the men-
tioned systems is determined by the kind of lin-
guistic classes that make up each model. De-
pending on the linguistic needs of the end user, 
some models will be more suitable than others. 
LingInfo or LexOnto can offer not only multilin-
gual strings to classes and properties of the on-
tology, but also a deeper morphosyntactic de-
composition of linguistic elements, in the case of 
LingInfo, or a greater focus on syntactic struc-
tures by means of subcategorization frames, in 
LexOnto. Our LIR model, however, is more in 
the line of GENOMA-KB or OncoTerm, in the 
sense that they follow localization or transla-
tional approaches. The main objective of the LIR 
is to localize a certain ontology category to the 
linguistic and cultural universe of a certain natu-
ral language and to capture translation specifici-
ties among languages. Morphosyntactic informa-
tion is left in the background, although interop-
erability with ISO standards for representing that 
sort of information is foreseen. Contrary to GE-
NOMA-KB or OncoTerm, the LIR is represented 
as an ontology and will be provided with the 
necessary infrastructure to access external re-
                                                 
6 http://genoma.iula.upf.edu:8080/genoma 
7 http://www.ugr.es/~oncoterm/alpha-index.html 
sources for obtaining linguistic data and main-
taining links to supplier resources (cf. 5). 
2.1 Interoperability with existing standards 
Lexical knowledge is expressed in various ways 
in terminological and linguistic resources. There 
is a wealth of proposals for enhancing the inter-
operability of lexical knowledge by encoding it 
following standard models. As the most impor-
tant initiatives we take into account two ISO (In-
ternational Organization for Standardization 8 ) 
standards: The Terminological Markup Frame-
work (TMF9) (and the associated TermBase eX-
change format; TBX10), which captures the un-
derlying structure and representation of comput-
erized terminologies, and the Lexical Markup 
Framework (LMF) (Francopoulo et al, 2006), an 
abstract meta-model that provides a common, 
standardized framework for the construction of 
computational lexicons.  
The LIR model adopts a number of data cate-
gories from these standards in order to guarantee 
interoperability with them. For instance, the no-
tion of lexical entry or lexeme, in itself a well 
known central linguistic notion of a unit of form 
and meaning, has been taken from LMF, whereas 
the attribute term type, which covers representa-
tional aspects such as full forms versus abbrevia-
tions,  has been taken from TMF.  
3 Linguistic Information Repository 
As shown in Figure 1, the linguistic information 
captured in the LIR is organized around the 
LexicalEntry class. A lexical entry is a unit of 
form and meaning in a certain language (Saloni 
et al, 1990). Therefore, it is associated to the 
classes Language, Lexicalization and 
Sense. A set of related lexicalizations or term 
variants shares the same meaning within the spe-
cific context of a certain cultural and linguistic 
universe. E.g., Food and Agriculture Organiza-
tion and FAO would be two lexicalizations 
linked to the same sense. Thanks to the expres-
siveness of the hasVariant relation, it is possi-
ble to say that the one is acronym of the other.  
The Language class at the LexicalEntry 
level allows launching searches in which just 
those lexical entries related to one natural lan-
guage are shown to the user, thus displaying the 
ontology in the selected language.  
                                                 
8 www.iso.org 
9 http://www.loria.fr/projets/TMF/ 
10 http://www.lisa.org/standards/tbx/ 
68
Sense is considered a language-specific unit 
of intensional lexical semantic description 
(ibidem), which comes to fruition through the 
Definition class expressed in natural lan-
guage. Therefore, Sense is an empty class real-
ized by means of the Definition. By keeping 
senses in the linguistic model independent from 
ontology concepts, we allow capturing cultural 
specificities that may slightly differ from the 
concept expressed in the ontology. Definition 
has a pointer to the linguistic resource it has been 
obtained from. In this way reliability and author-
ity of definitions are guaranteed.  
Then, Lexicalization is related to its 
Source or provenance, to a Note class and to a 
UsageContext class. The Source class aims 
again at being a pointer to the resource where the 
information has been extracted from. Note is 
here linked to Lexicalization, but it could be 
linked to any other class in the model. It allows 
the inclusion of supplemental information; e.g., 
usage specificities of a certain lexicalization 
within its language system. By linking Note to 
the Sense or Definition classes we could 
make explicit possible differences among senses 
in different languages. The UsageContext class 
provides information about the behaviour of a 
certain lexicalization within the language system 
it belongs to. Finally, lexical semantic equiva-
lences are established among lexical entries 
within the same language (hasSynonym or 
hasAntonym), or across languages (hasTrans-
lation). Note that we use the latter label to es-
tablish equivalences between lexicalizations in 
different languages, although it is assumed that 
words identified as translation equivalents are 
rarely identical in sense. As Hirst (2004) stated, 
more usually they are merely cross-lingual near-
synonyms, but this approach is adopted for the 
practical reason of providing multilinguality. 
The LIR is linked to the OntologyElement 
class of the OWL meta-model permitting in this 
way the association of multilingual information 
to any element of the ontology. Finally, it is left 
to say that the rationale underlying LIR is not to 
design a lexicon for different natural languages 
and then establish links to ontology concepts, but 
to associate multilingual linguistic knowledge to 
the conceptual knowledge represented by the 
ontology. What the LIR does is to associate word 
senses ?as defined by Hirst (2004)- in different 
languages to ontology concepts, although word 
senses and concepts can not be said to overlap 
since they are tightly related to the particular vi-
sion of a language and its culture, whereas ontol-
ogy concepts try to capture objects of the real 
world, and are defined and organized according 
to expert criteria agreed by consensus.  
4 Application of the LIR in NeOn 
The LIR has been developed within the NeOn 
project and is currently being implemented. In 
order to check its suitability, it was evaluated 
against the linguistic requirements of the use 
cases participating in this project (see Note 2): 
the Spanish pharmaceutical industry, and the 
Fisheries Stock system of the FAO. Both use 
cases are working in the development of ontolo-
gies for organizing the information they have in 
several languages. As a consequence, one of the 
requirements for the NeOn architecture was to 
support multilingual ontologies.  
As already introduced, the LIR not only pro-
vides multilingual information to any ontology 
element, but it also enables unified access to ag-
gregated multilingual data, previously scattered 
in heterogeneous resources. In that way, it inte-
grates the necessary linguistic information from 
use case resources and offers a complete and 
complementary amount of linguistic data.  
Regarding the FAO use case, the LIR was 
evaluated against the recent developed model for 
the AGROVOC thesaurus, the AGROVOC Con-
cept Server (Liang et al, 2008). This is a con-
cept-based multilingual repository, which, com-
pared to a traditional Knowledge Organization 
System, allows the representation of more se-
mantics such as specific relationships between 
concepts and relationships between multilingual 
lexicalizations. It serves as a pool of agricultural 
concepts and is a starting point in the develop-
ment of domain ontologies. The adequacy of the 
LIR model was positively evaluated against the 
linguistic requirements of the Concept Server in 
terms of flexible association of language specific 
lexicalizations with agricultural domain con-
cepts, and compatibility with TBX.  
5 Conclusions and future research 
In this contribution we have raised the impending 
need of international organizations dealing with 
multilingual information for representing multi-
linguality in ontologies. In order to obtain multi-
lingual ontologies, we have proposed the associa-
tion of the ontology meta-model to a linguistic   
69
 
Figure 1. LIR model. 
model, the LIR. The LIR has proven to be a ho-
listic linguistic information repository with the 
following benefits:  
? Provision of a complete and complementary 
set of linguistic elements in each language for 
localizing ontology elements 
? Homogeneous access to linguistic information 
distributed in heterogeneous resources with dif-
ferent granularity 
? Establishment of relations between linguistic 
elements, and solution to conceptualization mis-
matches among different cultures 
Besides, within NeOn there is a current research 
regarding the integration of the LIR with the La-
belTranslator tool (Espinoza et al, 2007), that 
allows: (1) quick access to external multilingual 
resources, (2) an automatic translation of the on-
tology terminological layer, (3) an automatic 
storage of the resulting multilingual information 
in the LIR, and (4) convenient editing possibili-
ties for users in distributed environments. 
Acknowlegements. This research was supported 
by the NeOn project (FP6-027595)  
References 
Buitelaar, P., M. Sintek, M. Kiesel. 2006. A Multi-
lingual/Multimedia Lexicon Model for Ontologies. 
In Proc. of  ESWC, Budva, Montenegro.  
Cimiano, P., P. Haase, M. Herold, M. Mantel, P. Bui-
telaar. 2007. LexOnto: A Model for Ontology Lexi-
cons for Ontology-based NLP. Proc. of OntoLex.  
Espinoza, M., A. G?mez-P?rez, and E. Mena. 2008. 
Enriching an Ontology with Multilingual Informa-
tion. Proc. of ESWC, Tenerife, Spain.  
Francopoulo, G, M. George, N. Calzolari, M. 
Monachini, N. Bel, M. Pet, C. Soria. 2006. Lexical 
Markup Framework (LMF). Proc. of LREC. 
Hirst, G. 2004. Ontology and the Lexicon. In S. Staab, 
and R. Studer (eds.) Handbook on Ontologies and 
Information Systems. Springer, Berlin.  
Liang, A.C., B. Lauser, M. Sini, J. Keizer, S. Katz. 
2008. From AGROVOC to the Agricultural Ontol-
ogy Service/Concept Server. An OWL model for 
managing ontologies in the agricultural domain. In 
Proc. of the ?OWL: Experiences and Directions? 
Workshop, Mancherter, U.K.  
Peters, W., E. Montiel-Ponsoda, G. Aguado de Cea. 
2007.Localizing Ontologies in OWL.Proc. OntoLex 
Saloni, Z., S. Szpakowicz, M. Swidzinski. 1990. The 
Design of a Universal Basic Dictionary of Con-
temporary Polish. International Journal of Lexi-
cography, vol. 3 no1. Oxford University Press.  
Su?rez-Figueroa, M.C. (coord.) 2007. NeOn Devel-
opment Process and Ontology Life Cycle. NeOn 
Project D5.3.1 
70
RDF(S)/XML LINGUISTIC ANNOTATION 
OF SEMANTIC WEB PAGES 
Guadalupe Aguado de Cea 
DLACT1 
Fac. Inform?tica, UPM 
Madrid, Spain, 28660 
lupe@fi.upm.es 
Inmaculada ?lvarez-de-Mon 
DLACT 
E.U.I.T. Inform?ticos, UPM 
Madrid, Spain, 28031 
ialvarez@euitt.upm.es 
Antonio Pareja-Lora 
DSIP2 
Fac. Inform?tica, UCM 
Madrid, Spain, 28040 
apareja@sip.ucm.es 
Rosario Plaza-Arteche 
DLACT 
Fac. Inform?tica, UPM 
Madrid, Spain, 28660 
rplaza@fi.upm.es 
 
 
ABSTRACT12 
Although with the Semantic Web initiative 
much research on web page semantic annotation 
has already been done by AI researchers, 
linguistic text annotation, including the semantic 
one, was originally developed in Corpus 
Linguistics and its results have been somehow 
neglected by AI. The purpose of the research 
presented in this proposal is to prove that 
integration of results in both fields is not only 
possible, but also highly useful in order to make 
Semantic Web pages more machine-readable. A 
multi-level (possibly multi-purpose and multi-
language) annotation model based on EAGLES 
standards and Ontological Semantics, 
implemented with last generation Semantic Web 
languages (RDF(S)/XML) is being developed to fit 
the needs of both communities; the present paper 
focuses on its semantic level. 
INTRODUCTION 
All of us are by now accustomed to making 
extensive use of the so-called World Wide Web 
(WWW) which we might consider a great source 
of information, accessible through computers but, 
hitherto, only understandable to human beings. In 
its beginning, web pages were hand made, 
intended and oriented to the exchange of 
information among human beings. Due to the 
astonishing growth of Internet use, new 
technologies emerged and, with them, machine-
aided web page generation appeared. Up to that 
point, the structure and the edition of these pages 
fitted only human needs ? and this, only to some 
extent. All of these documents contained a huge 
amount of text, images and even sounds, 
meaningless to a computer. In this way, they put 
                                                     
1 Dept. of Languages Applied to Science and Technology. 
2 Dept. of Computer Systems and Programming. 
on the reader the burden of extracting and 
interpreting the relevant information in them. 
Currently, web page presentation in the WWW 
is being handled independently from its content, 
mainly through the use of XML (Bray et al, 
1998) or other resource-oriented languages as 
XOL (Karp et al, 1999), SHOE (Luke et al, 
2000), OML (Kent, 1998), RDF (Lassila et al, 
1999), RDF Schema (Brickley et al, 2000), OIL 
(Horrocks et al, 2000) or DAML+OIL (Horrocks 
et al, 2001). But even though the automatic 
process of information is being eased, the above 
mentioned tasks ? relevant information access, 
extraction and interpretation ? cannot be wholly 
performed by computers yet. Hence, the goal of 
enabling computers to understand the meaning 
(the semantics) of written texts and web pages to 
make it explicit to computers is gaining a growing 
relevance. That is the main pillar sustaining the 
development of what we understand by Semantic 
Web: "the conceptual structuring of the web in an 
explicit machine-readable way" (Berners-Lee et 
al., 1999). In this context, the semantic annotation 
of texts makes meaning explicit, and has become a 
key topic. Thus, great efforts are being devoted to 
the design and application of models and 
formalisms for the semantic annotation of web 
pages to make these documents more machine-
readable. 
Following the guidelines of the Semantic Web 
initiative, much research has already been carried 
out by AI researchers on the semantic annotation 
of web pages (Luke et al, 2000), (Benjamins et 
al., 1999), (Motta et al, 1999), (Staab et al, 
2000). However, these researchers have neglected, 
somehow, the decades of work and the results 
obtained in the field of Corpus Linguistics on 
corpus annotation, not only in the semantic level, 
but also in other linguistic levels. These other 
linguistic levels, whilst not being intrinsically 
semantic, can also add some semantic information 
and help a computer understand a text or, in our 
case, web pages. 
This paper will show the results of our research 
on how linguistic annotation can help computers 
understand the text contained in a document ? a 
Semantic Web document, for example. Special 
efforts are devoted to finding a way of bringing 
together and identifying complementarities 
between the semantic annotation models from AI 
and the annotations proposed by Corpus 
Linguistics. As stated in this paper, far from being 
irreconcilable, they are more than close and may 
be considered complementary. 
This paper is organised as follows: firstly, an 
introduction to the state of the art in text semantic 
annotation in corpus linguistics is presented 
(section 1). Secondly, in section 2, some brief 
notes on the use of ontologies in semantic 
annotation is sketched. Thirdly, in section 3, an 
example of the integration of both paradigms 
(AI?s and Corpus Linguistics?) is presented in the 
scope of our project goals. The main advantages 
of this integration is analysed afterwards ? section 
4 ? and some conclusions are stated ? section 5 ?, 
followed by the acknowledgments section and, 
finally, the references. 
1. TEXT ANNOTATION IN CORPUS 
LINGUISTICS 
The idea of text annotation was originally 
developed in Corpus Linguistics. Traditionally, 
linguists have defined corpus as "a body of 
naturally occurring (authentic) language data 
which can be used as a basis for linguistic 
research" (Leech, 1997). Following McEnery & 
Wilson (2001), Corpus Linguistics was first 
applied to research on language acquisition, to the 
teaching of a second language or to the 
elaboration of descriptive grammars, etc.. With 
the arrival of computers, the number of potential 
studies to which corpora could be applied 
increased exponentially. So, nowadays, the term 
corpus is being applied to "a body of language 
material which exists in electronic form, and 
which may be processed by computer for various 
purposes such as linguistic research and language 
engineering" (Leech, 1997). An annotated 
corpus "may be considered to be a repository of 
linguistic information [...] made explicit through 
concrete annotation" (McEnery & Wilson, 2001). 
The benefit of such an annotation is clear: it 
makes retrieving and analysing information about 
what is contained in the corpus quicker and easier. 
In Leech (1997), a list of the different (possible) 
levels of linguistic annotation can be found. As 
Leech himself states, for the time being, no corpus 
includes all of them, but only two or, at most, 
three of them. Some of them were only in their 
first stage of conception at the time of writing his 
paper. A smaller but more realistic list of 
annotation levels is included in EAGLES (1996a) 
namely: lemma, morpho-syntactic, syntactic, 
semantic and discourse annotation. Standard 
recommendations on morpho-syntactic and 
syntactic annotation of corpora can be found in 
(EAGLES, 1996a) and (EAGLES, 1996b). A 
complementary list of general criteria that should 
be considered when elaborating an annotation 
scheme can be found in one of the results of the 
EAGLES project work, the Corpus Encoding 
Standard (CES, 2000) which are being taken into 
account in the elaboration of our model (Aguado 
de Cea, 2002). With respect to the previous and 
well-known standardization initiative, TEI3, all 
these works mentioned are TEI-compliant. Thus, 
for the sake of brevity, we will focus on semantic 
annotation henceforth. 
As asserted in McEnery & Wilson (2001), two 
broad types of semantic annotation may be 
identified: 
A. The marking of semantic relationships 
between items in the text (for example, the 
agents or patients of particular actions). This 
type of annotation has scarcely begun to be 
applied.  
B. The marking of semantic features of words in 
a text, essentially the annotation of word 
senses in one form or another. This trend has 
quite a longer history but there is no universal 
agreement in semantics about which features 
of words should be annotated4. 
Although some preliminary recommendations 
on lexical semantic encoding have already been 
posited (EAGLES, 1999), no EAGLES semantic 
corpus annotation standard has yet been 
published; nevertheless, for the second type of 
semantic annotation enunciated, a set of reference 
criteria has been proposed by Schmidt and 
                                                     
3 http://etext.virginia.edu/TEI.html 
4 See, for example, the controversies within the SENSEVAL 
initiative meetings ? (Kilgarriff, 1998), (Kilgarriff & Rosenzweig, 
2000). 
 
mentioned in Wilson & Thomas (1997) for 
choosing or devising a corpus semantic field5 
annotation system. These criteria can be 
summarized as follows6:  
1. It should make sense in linguistic or 
psycholinguistic terms.  
2. It should be able to account exhaustively for 
the vocabulary in the corpus, not just for a 
part of it.  
3. It should be sufficiently flexible. 
4. It should operate at an appropriate level of 
granularity (or delicacy of detail). 
5. It should, where appropriate, possess a 
hierarchical structure.  
6. It should conform to a standard, if one exists7. 
2. ONTOLOGIES AND SEMANTIC WEB 
ANNOTATIONS. 
AI researchers have found in ontologies 
(Gruber, 1993), (Guarino et al, 1995), (Studer et 
al., 1998) the ideal knowledge model to formally 
describe web resources and its vocabulary and, 
hence, to make explicit in some way the 
underlying meaning of the concepts included in 
web pages. With Ontological Semantics 
(Niremburg & Raskin, 2001) as a support theory8, 
the annotation of these web resources with 
ontological information should allow intelligent 
access to them, should ease searching and 
browsing within them and should exploit new web 
inference approaches from them. The influential 
WordNet and EuroWordNet (Fellbaum, 2001) 
ontologies should be mentioned as valuable 
resources for this purpose. Many systems and 
projects have been developed towards this aim 
hitherto: SHOE (Luke et al, 2000) proposes 
HTML page semantic annotation with a Horn 
clause-based language also called SHOE; the 
(KA)2 initiative (Benjamins et al, 1999) seeks to 
annotate HTML documents with ontological 
information, taking Knowledge Acquisition 
Community ontologies as a basis; PlanetOnto 
(Motta et al, 1999) aims at automatically 
annotating the HTML news pages of an 
organisation by means of the information obtained 
from an event-ontology based knowledge base; 
finally, within the Semantic Community Web 
Portals project (Staab et al, 2000) an ontology-
based architecture for editing and maintaining 
web portals in an easier way is being developed. 
Besides, a number of semantic annotation tools 
have also been developed so far: COHSE 
(COHSE, 2002), MnM (Vargas-Vera et al, 2001), 
OntoMat-Annotizer (OntoMat, 2002), SHOE 
Knowledge Annotator (SHOE, 2002) and 
AeroDAML (AeroDAML, 2002). 
3. INTEGRATION OF PARADIGMS: AN 
EXAMPLE 
The model here shown, OntoTag, is developed 
within ContentWeb, a Ministry funded project, 
which aims at creating an ontology-based 
platform to enable users to query e-commerce 
applications by using natural language, 
performing the automatic retrieval of information 
from web documents annotated with ontological 
and linguistic information. Besides, a prototype in 
the entertainment domain will be developed. 
ContentWeb objectives can be found in (Aguado 
de Cea, 2002). 
Within the elaboration of OntoTag, a first 
exploration phase has been performed. A short 
example of this first phase is presented next. It has 
been implemented in RDF(S), but an XML 
version was also developed and the possibility of 
using any other language has a priori not been 
discarded. In the annotation example given below, 
two different morpho-syntactic tools were 
applied: Conexor (Conexor, 2002) and MBT 
(MBT, 2002). Some other tools are being 
evaluated for further use and the XML and 
RDF(S) annotation tools and wrappers are being 
designed at the moment. 
                                                     
5 A semantic field (sometimes also called a conceptual field, a 
semantic domain or a lexical domain) is a theoretical construct 
which groups together words that are related by virtue of their 
being connected ? at some level of generality ? with the same 
mental concept (Wilson & Thomas, 1997). 
6  For a more detailed explanation, see (Aguado de Cea, 2002). 
7 Once again the SENSEVAL initiatives must be mentioned: they 
reveal the demand for semantic standardization in the field of word 
sense disambiguation (Kilgarriff, 1998), (Kilgarriff & Rosenzweig, 
2000). 
 8 Ontological Semantics (Niremburg & Raskin, 2001) is a theory of 
meaning in natural language and an approach to natural language 
processing (NLP) which uses a constructed world model ? the 
ontology ? as the central resource for extracting and representing 
meaning of natural language texts, reasoning about knowledge 
derived from texts as well as generating natural language texts 
based on representations of their meaning. 
 
 
 
 
 
Figure 1: Morpho-Syntactic Annotation 
Excerpt. 
3.1. RDF(S) EXAMPLE 
DESCRIPTION 
In Figure 1, Figure 2and Figure 3, 
we can see the annotation of the 
following Spanish sentence in the 
first three levels ?Tras cinco a?os de 
espera y despu?s de muchas 
habladur?as, llega a nuestras 
pantallas la pel?cula m?s esperada 
de los ?ltimos tiempos.?9  
In the morpho-syntactic level 
(Figure 1) every word or lexical 
token is given a different Uniform 
Resource Identifier (URI henceforth) 
and three possible categorisations are 
included, according to the three 
different tagsets and systems we 
want to evaluate. Each tagset has 
been assigned a different class in the 
morphAnnot namespace: TradAnnot 
(CRATER tagset), MBTAnnot (MBT 
tagset) and ConstrAnnot (Constraint 
Grammar ? CONEXOR FDG tagset). 
For the sake of space saving, just the 
annotation of the article ?la? has been 
included in the figure. 
In the syntactic level (Figure 2) 
every syntactic relationship between 
morpho-syntactic items is given a new 
URI, so that it can be referenced in 
higher-level relationships or by other 
levels of the annotation model (i.e. 
<synAnnot:Chunk rdf:ID="1_510">). 
Again for the sake of space saving, just 
the annotation of the phrase ?la 
pel?cula m?s esperada de los ?ltimos 
tiempos? has been included in the 
figure. 
In the semantic level (see Figure 3) 
some components of lower level 
annotations are annotated with 
semantic references to the concepts, 
attributes and relationships determined 
by our (domain) ontology, implemented 
in DAML+OIL. 
 
                                                     
<contentWeb:FilmReview> 
<contentWeb:text>Tras cinco a?os de espera y despu?s de 
 muchas habladur?as, llega a nuestras pantallas la pel?cula 
  m?s esperada de los ?ltimos tiempos.</contentWeb:text> 
</contentWeb:FilmReview> 
<!-- Morpho-syntactic annotation excerpt --> 
<morphAnnot:Word rdf:ID="1_16"> 
<morphAnnot:surface_form>la</morphAnnot:surface_form> 
<morphAnnot:TradAnnot rdf:about="#trad_ann_info_1_16"/> 
<morphAnnot:MBTAnnot rdf:about="#mbt_ann_info_1_16"/> 
<morphAnnot:ConstrAnnot rdf:about="#constr_ann_info_1_16"/> 
</morphAnnot:Word> 
<morphAnnot:TradAnnot rdf:ID="trad_ann_info_1_16"> 
<trad:tag> ARTDFS </trad:tag> 
<morphAnnot:lemma> el </morphAnnot:lemma> 
</morphAnnot:TradAnnot> 
<morphAnnot:MBTAnnot rdf:ID="mbt_ann_info_1_16"> 
<mbt:tag> TDFS0 </mbt:tag> 
<morphAnnot:lemma> el </morphAnnot:lemma> 
</morphAnnot:MBTAnnot> 
<morphAnnot:ConstrAnnot rdf:ID="constr_ann_info_1_16"> 
<constr:tag> DET </constr:tag> 
<constr:genus>FEM</constr:genus> 
<constr:numerus>SG</constr:numerus> 
<morphAnnot:lemma>la</morphAnnot:lemma> 
<constr:synfunction>DN&gt;</constr:synfunction> 
</morphAnnot:ConstrAnnot> 
<!-- Syntactic annotation excerpt --> 
<synAnnot:Chunk rdf:ID="1_510"> 
<synAnnot:synfunction>NP</synAnnot:synfunction> 
<synAnnot:hasChild rdf:about="#1_21">los</synAnnot:hasChild> 
<synAnnot:hasChild rdf:about="#1_22">?ltimos</synAnnot:hasChild> 
<synAnnot:hasChild rdf:about="#1_23">tiempos</synAnnot:hasChild> 
</synAnnot:Chunk> 
<synAnnot:Chunk rdf:ID="1_511"> 
<synAnnot:synfunction>PP</synAnnot:synfunction> 
<synAnnot:hasChild rdf:about="#1_20">de</synAnnot:hasChild> 
<synAnnot:hasChild rdf:about="#1_510"> los ?ltimos tiempos 
</synAnnot:hasChild> 
</synAnnot:Chunk> 
<synAnnot:Chunk rdf:ID="1_512"> 
<synAnnot:synfunction>AdjP</synAnnot:synfunction> 
<synAnnot:hasChild rdf:about="#1_18">m?s</synAnnot:hasChild> 
<synAnnot:hasChild rdf:about="#1_19">esperada</synAnnot:hasChild>
<synAnnot:hasChild rdf:about="#1_511">de los ?ltimos tiempos 
</synAnnot:hasChild> 
</synAnnot:Chunk> 
<synAnnot:Chunk rdf:ID="1_513"> 
<synAnnot:synfunction>NP</synAnnot:synfunction> 
<synAnnot:hasChild rdf:about="#1_16">la</synAnnot:hasChild> 
<synAnnot:hasChild rdf:about="#1_17">pel?cula</synAnnot:hasChild> 
<synAnnot:hasChild rdf:about="#1_512">m?s esperada de los ?ltimos 
tiempos </synAnnot:hasChild> 
</synAnnot:Chunk> 
Figure 2: Syntactic Annotation Excerpt. 9 After five years of expectation and gossiping, here comes the most 
expected film for the time being. 
<!-- Semantic annotation excerpt --> 
 
<onto:PremiereEvent rdf:ID="_anon27"> 
<semSynAnnot:includes rdf:about="#1_13">llega</semSynAnnot:includes> 
<semSynAnnot:includes rdf:about="#1_509">a nuestras pantallas</semSynAnnot:includes> 
<onto:hasFilm rdf:about="#_anon30"/> 
</onto:PremiereEvent> 
 
<onto:Film rdf:ID="_anon30"> 
        <semAnnot:includes rdf:about="#1_18">pel?cula</semAnnot:includes> 
        <onto:comment rdf:about="#_anon40"> 
        <onto:comment rdf:about="#_anon41"> 
</onto:Film> 
 
<onto:ControversialFilm rdf:ID="_anon40"> 
<semSynAnnot:includes rdf:about="#1_506">despu?s de muchas habladur?as</semSynAnnot:includes> 
</onto:ControversialFilm> 
 
<onto:AwaitedFilm rdf:ID="_anon41"> 
<semSynAnnot:includes rdf:about="#1_503">Tras cinco a?os de espera</semSynAnnot:includes> 
<semSynAnnot:includes rdf:about="#1_512">m?s esperada de los ?ltimos tiempos</semSynAnnot:includes> 
</onto:ControversialFilm> 
 
<onto:Film rdf:about="#_anon30"> 
<semSynAnnot:includes rdf:about="#3_507">El Se?or de los Anillos</semSynAnnot:includes> 
<onto:filmTitle>El Se?or de los Anillos</onto:filmTitle> 
</onto:Film> 
Figure 3:  Semantic Annotation Excerpt. 
Further elements susceptible of semantic 
annotation are being sought and research is being 
done towards their determination by the linguist 
team
Onto
the p
the ex
3.2. 
In
raw t
URI 
after,
inser
the s
synta
Th
XML
union
(a S
confo
devel
tagge
based
syntactic part. The tool that produced a particular 
annotation is tagged with <Traditional>, <MBT> 
and <Constraint>, respectively. Lemma 
ribute 
space 
 data 
 TEI 
tactic 
(more 
. This 
tactic 
ations 
, the 
nt_on, 
nt one 
which 
 them 
s the 
in a 
 now 
tactic 
ing of 
mmar 
GLES 
        
10 http: in our project. The pragmatic counterpart of 
Tag has not yet been tackled at this phase of 
roject and, thus, this level is not included in 
ample. 
THE XML DATA MODEL 
 our XML data model, every token from the 
ext is labelled with a <Word> tag and a RDF 
specified by the attribute rdf:ID. Immediately 
 nested, a <surface_form> tag will be 
ted, introducing the token as it appeared in 
ource text; then come the morpho-syntactic, 
ctic and semantic annotations for this token. 
e tagset associated to our morpho-syntactic 
 data model (namespace pos) includes the 
 of those three others defined for CRATER10 
panish POS tagset, TEI and EAGLES 
rmant, applied also in SonIsa, the tagger 
oped in our laboratory), MBT (a web-based 
r, also EAGLES conformant) and the web-
 version of CONEXOR FDG parser morpho-
information is annotated by means of an att
lemma, associated to the tag of the name
pos. 
The syntactic counterpart of our XML
model (namespace syn) contains, in a
conformant manner, only the syn
information given by FDG at the moment 
tags may be added as the model is refined)
syntactic information covers EAGLES syn
layers (c) and (d): showing dependency rel
and indicating functional labels. Thus
attributes defined at this level are: depende
which shows the token on which the prese
depends (via its rdf:ID);  dependency, 
describes the kind of dependency between
both and surface_syn_tag, which denote
surface syntactic function of the token 
Constraint Grammar approach. We are
studying the best way to cover EAGLES syn
layers (a) and (b) ? bracketing and labell
segments ? from a Constraint Gra
perspective, not developed in the EA
syntactic guidelines aforementioned.                                               
//arxiv.org/ps/cmp-lg/9406023  
The semantic counterpart of our XML data 
model (namespace sem) is ontology-based and 
defined by means of the tags given in the 
DAML+OIL implementation of our domain 
ontologies. 
4. ADVANTAGES OF THE INTEGRATED 
MODEL 
As shown in the previous section example, it 
seems that AI and Corpus Linguistics, far from 
being irreconcilable, can join together to give 
birth to an integrated annotation model. This 
conjunct annotation scheme would be very useful 
and valuable in the development of the Semantic 
Web and would benefit from the results of both 
disciplines in many ways, not restricted to the 
semantic level, below analysed. A particular 
subsection is dedicated to multi-functionality 
4.1. AT THE SEMANTIC LEVEL 
Let us now see the benefits at the semantic 
level of a hybrid annotation model, first from a 
linguistic point of view and, then, from an 
ontological point of view. 
4.1.1. Regarding ontologies from a linguistic 
point of view 
Taking a closer view to sections 1 and 2, and 
comparing the proposals from both Corpus 
Linguistics and AI, we find out that the use of 
ontologies as a basis for a semantic annotation 
scheme fits perfectly and accomplishes the criteria 
posited by Schmidt. Clearly, its mostly 
hierarchical structure fulfils by itself criterion (5) 
and, as a side effect, criteria (2) and (4), since the 
former is related to the capacity of an ontology to 
grow horizontally (in breadth) and the latter to the 
capacity of an ontology to grow vertically (in 
depth or in specification). Hence, the end user can 
decide the level of specificity needed. Criterion 
(3) is also satisfied by an ontology-based semantic 
annotation scheme, since we can always specialise 
the concepts in the ontology according to specific 
periods, languages, registers and textbases. 
Ontologies are, by definition, consensual and, 
thus, are closer to becoming a standard than many 
other models and formalisms or, as criteria (6) 
requires, at least they lay a framework of 
properties and axioms (principles) and major 
categories that can be modified to some extent to 
fit individual needs. Concerning criterion (1), 
quite a lot of groups developing ontologies are 
characterized by a strong interdisciplinary 
approach that combines Computer Science, 
Linguistics and (sometimes) Philosophy; thus, an 
ontology-based approach should also make sense 
in linguistic terms. 
4.1.2. Regarding linguistic annotations from 
an ontological point of view 
The main drawback for AI researchers to adopt 
a linguistically motivated annotation model would 
lie on the statement in section 1 that says, ?there is 
no universal agreement in semantics about which 
features of words should be annotated? or on that 
other statement in Schmidt?s criterion 1, in the 
same section, that says, ?still an exhaustive set of 
categories is to be determined?. 
But ontology researchers are trying to fill this 
gap with initiatives such as the UNSPSC 
(UNSPSC, 2002) or RosettaNet (RosettaNet, 
2002) in specific domains (i.e. e-commerce). In 
any case, linguistic annotations at the semantic 
level are more ambitious and potentially wider 
than the strictly ontology-based ones. Establishing 
a link between semantic annotation and discourse 
annotation and text construction following the 
RST approach, which has already been applied in 
text generation (Mann & Thomson, 88), seems a 
fairly promising linguistic enhancement. 
So far, we have seen how ontologies can fit in 
the semantic annotation of texts; let us see in the 
next subsections how linguistic annotations in all 
of its levels can improve the potential of Semantic 
Web Pages. 
4.2. MULTI-FUNCTIONALITY 
The need for (shallow) parsing in semantic 
processing is found in Vargas-Vera et al (2001) 
and also in Kietz et al(2000): most information 
extraction systems (as well as other NLP 
applications) use some form of shallow parsing11 
to recognise syntactic constructs or, in other 
words, to syntactically identify some fragments of 
the sentences. A chunker12 called Marmot is 
included in the annotation process presented in the 
                                                     
11 Without generating a complete parse tree for each sentence. Such 
partial parsing has the advantages of greater speed and robustness. 
12 A chunker is a natural language (pre)processing tool that separates 
and segments sentences into its subconstituents, i.e. noun, verb and 
prepositional phrases, etc. 
 
former. Even though this need for lower levels of 
linguistic analysis mentioned hitherto applies to 
information extraction systems, it is not restricted 
to this kind of NLP applications. Since the 
proposed annotation model adds overt linguistic 
information to any kind of document, then it can 
be used for a wide range of purposes that require a 
linguistic or semantic analysis or processing (i.e. 
machine-aided translation, information retrieval, 
etc.). 
5. CONCLUSIONS 
We have seen that, even though AI researchers 
are devoting many efforts to finding an optimal 
model for the semantic annotation of web pages, 
the decades of work and the results obtained in the 
field of Corpus Linguistics on corpus annotation 
have been, somehow, neglected. This paper shows 
the results of the research carried out on how 
linguistic annotation can help computers 
understand the text contained in a document ? a 
Semantic Web page ? bringing together semantic 
annotation models from AI and the annotations 
proposed for every linguistic level from Corpus 
Linguistics. 
The integration of these two approaches 
(Corpus Linguistics and AI) entails many 
advantages for language engineering and AI 
applications. First of all, language resources will 
be more reusable: many of the projects involving 
the use of semantically annotated (web) 
documents must also parse to some extent the 
information and, prior to that, must determine 
somehow the grammatical category associated to 
every word in the document. Introducing the 
annotation of these two levels into the document, 
hence re-using one of the tools already developed 
for this purpose, prevents this whole process of 
document text tokenisation and parsing or 
chunking from being unnecessarily repeated each 
time the document is processed (reusing the 
annotation). Since parsing, for example, is a high 
time-consuming task, we can have an additional 
advantage, that is, reducing our overall Semantic 
Web page processing time. The second main 
advantage is that the meaning of a page with 
explicit semantic annotation can be reinforced by 
the meaning contribution provided by all of the 
linguistic levels; semantic analysis can also 
benefit from the invaluable work done so far on 
the development of ontologies as conceptual and 
consensual models. 
However, the main disadvantage lies in the 
limitations imposed by current technologies: 
obtaining automatically compact, readable and 
verifiable pages is a task hard to be fully specified 
and delimited, but the work being done in our 
laboratory tries to bring some light upon it. 
ACKNOWLEDGEMENTS 
The research described in this paper is 
supported by MCyT (Spanish Ministry of Science 
and Technology) under the project name: 
ContentWeb: ?PLATAFORMA TECNOL?GICA 
PARA LA WEB SEM?NTICA: ONTOLOG?AS, 
AN?LISIS DE LENGUAJE NATURAL Y 
COMERCIO ELECTR?NICO? ? TIC2001-2745 
("ContentWeb: Semantic Web Technologic 
Platform: Ontologies, Natural Language Analysis 
and E-Business"). 
We would also like to thank ?scar Corcho, 
Socorro Bernardos and Mariano Fern?ndez for 
their help with the ontological aspects of this 
paper. 
REFERENCES 
AeroDAML (2002) http://ubot.lockheedmartin.com/ 
ubot/hotdaml/aerodaml.html 
Aguado de Cea, G., ?lvarez de Mon, I., G?mez-P?rez, 
A., Pareja-Lora, A., Plaza-Arteche, R. (2002) A 
Semantic Web Page Linguistic Annotation Model. 
?AAAI 2002 Workshop: Semantic Web Meets 
Language Resources?. Edmonton, Alberta, Canada. 
(To appear) 
Benjamins, V.R., Fensel, D., Decker, S., G?mez-P?rez, 
A. (1999) (KA)2: Building Ontologies for the 
Internet: a Mid Term Report. IJHCS, International 
Journal of Human Computer Studies, 51, pp. 687?
712.  
Berners-Lee, T., Fischetti, M. (1999) Weaving the 
Web: The Original Design and Ultimate Destiny of 
the World Wide Web by its Inventor. Harper. San 
Francisco. 
Bray, T., Paoli, J., Sperberg, C. (1998) 
http://www.w3.org/TR/REC-xml. 
Brickley, D., Guha, R.V. (2000) http://www.w3.org/ 
TR/PR-rdf-schema.  
CES (2000) http://www.cs.vassar.edu/CES/ 
COHSE (2002) http://cohse.semanticweb.org/ 
Conexor OY (2002) http://www.conexoroy.com/ 
products.htm  
 
 EAGLES (1996a) ftp://ftp.ilc.pi.cnr.it/pub/eagles/ 
corpora/annotate.ps.gz 
EAGLES (1996b) ftp://ftp.ilc.pi.cnr.it/pub/eagles/ 
corpora/sasg1.ps.gz 
EAGLES (1999) http://www.ilc.pi.cnr.it/EAGLES/ 
EAGLESLE.PDF  
Fellbaum, C., Palmer, M., Trang Dang, H., Delfs, L., 
Wolff, S. (2001) Manual and Automatic Semantic 
Annotation with WordNet. In ?Proceedings of the 
NAACL Workshop on WordNet and Other Lexical 
Resources: Applications, Customizations?. 
Carnegie Mellon University, Pittsburg, PA. 
Gruber, R. (1993) A Translation Approach To Portable 
Ontology Specification. Knowledge Acquisition, 5, 
pp. 199?220. 
Guarino, N., Giaretta, P. (1995) Ontologies and 
Knowledge Bases: Towards a Terminological 
Clarification. In ?Towards Very Large Knowledge 
Bases: Knowledge Building and Knowledge 
Sharing?, N. Mars, ed., IOS Press, Amsterdam, pp. 
25?32.  
Horrocks, I., Fensel, D., Harmelen, F., Decker, S., 
Erdmann, M., Klein, M. (2000) OIL in a Nutshell. 
In ?12th International Conference in Knowledge 
Engineering and Knowledge Management, Lecture 
Notes in Artificial Intelligence?, Springer-Verlag, 
Berlin, Germany, pp. 1?16. 
Horrocks, I., Van Harmelen, F. (2001) 
http://www.daml.org/2000/12/reference.html  
Karp, R., Chaudhri, V., Thomere, J. (1999) 
http://www.ai.sri.com/~pkarp/xol/xol.html  
Kent, R. (1998) Conceptual Knowledge Markup 
Language (version 0.2). http://sern.ucalgary.ca/KSI/ 
KAW/KAW99/papers/Kent1/CKML.pdf 
Kietz, J-U., Maedche, A., Volz, R. (2000) A Method 
for Semi-Automatic Ontology Acquisition from a 
Corporate Intranet. In ?Proceedings of the 
EKAW'00 Workshop on Ontologies and Text?, 
Juan-Les-Pines, France. 
Kilgarriff, A. (1998) SENSEVAL: An Exercise in 
Evaluating Word Sense Disambiguation Programs. 
In ?Proceedings of LREC?, Granada, Spain, pp. 
581?588. 
Kilgarriff, A. & Rosenzweig, J. (2000) English 
SENSEVAL: Report and Results. In ?Proceedings of 
LREC?. Athens, Greece.  
Lassila, O., Swick, R. (1999) http://www.w3.org/TR/ 
PR-rdf-syntax  
Leech, G. (1997) Introducing corpus annotation. In 
?Corpus Annotation: Linguistic Information from 
Computer Text Corpora?, R. Garside, G. Leech & 
A. M. McEnery, ed., Longman, London. 
Luke S., Heflin J. (2000)  http://www.cs.umd.edu/ 
projects/plus/SHOE/spec1.01.htm 
Mann, W & Thomson, S.  (1988) Rhetorical Structure 
Theory: Toward a functional theory of text 
organization. Text Vol.18, 3, pp. 243?281. 
MBT (2002) http://ilk.kub.nl/~zavrel/tagtest.html  
McEnery, A. M., Wilson, A. (2001) Corpus 
Linguistics: An Introduction. Edinburgh University 
Press, Edinburgh. 
Motta, E., Buckingham Shum, S. Domingue, J. (1999) 
Case Studies in Ontology-Driven Document 
Enrichment. In ?Proceedings of the 12th Banff 
Knowledge Acquisition Workshop?, Banff, 
Alberta, Canada. 
Nirenburg, S. and Raskin, V. (2001) 
http://crl.nmsu.edu/Staff.pages/Technical/sergei/bo
ok/index-book.html  
OntoMat (2002) http://annotation.semanticweb.org/ 
ontomat.html 
RosettaNet (2002) http://www.rosettanet.org/  
SHOE (2002) http://www.cs.umd.edu/projects/plus/ 
SHOE/KnowledgeAnnotator.html 
Staab, S., Angele, J., Decker, S., Erdmann, M., Hotho, 
A., M?dche, A., Schnurr, H.-P., Studer, R. (2000) 
Semantic Community Web Portals. WWW?9. 
Amsterdam. 
Studer, R., Benjamins, R., Fensel, D. (1998) 
Knowledge Engineering: Principles and Methods. 
DKE 25(1-2), pp 161-197. 
UNSPSC (2002) http://www.unspsc.org/  
Vargas-Vera, M., Motta, E., Domingue, J., Shum, S. 
B., Lanzoni, M. (2001) Knowledge Extraction by 
Using an Ontology-based Annotation Tool. In 
?Proceedings of the K-CAP'01 Workshop on 
Knowledge Markup and Semantic Annotation?, 
Victoria B.C., Canada. 
Wilson, A., Thomas, J. (1997) Semantic Annotation. In 
?Corpus Annotation: Linguistic Information from 
Computer Text Corpora?, R. Garside, G. Leech & 
A. M. McEnery, ed., Longman, London. 
 
Proceedings of SSST-5, Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 116?125,
ACL HLT 2011, Portland, Oregon, USA, June 2011. c?2011 Association for Computational Linguistics
Combining statistical and semantic approaches to the translation of
ontologies and taxonomies
John McCrae
AG Semantic Computing
Universita?t Bielefeld
Bielefeld, Germany
jmccrae@cit-ec.uni-bielefeld.de
Mauricio Espinoza
Universidad de Cuenca
Cuenca, Ecuador
mauricio.espinoza@ucuenca.edu.ec
Elena Montiel-Ponsoda, Guadalupe Aguado-de-Cea
Ontology Engineering Group
Universidad Polite?cnica de Madrid
Madrid, Spain
{emontiel, lupe}@fi.upm.es
Philipp Cimiano
AG Semantic Computing
Universita?t Bielefeld
Bielefeld, Germany
cimiano@cit-ec.uni-bielefeld.de
Abstract
Ontologies and taxonomies are widely used to
organize concepts providing the basis for ac-
tivities such as indexing, and as background
knowledge for NLP tasks. As such, trans-
lation of these resources would prove use-
ful to adapt these systems to new languages.
However, we show that the nature of these
resources is significantly different from the
?free-text? paradigm used to train most sta-
tistical machine translation systems. In par-
ticular, we see significant differences in the
linguistic nature of these resources and such
resources have rich additional semantics. We
demonstrate that as a result of these linguistic
differences, standard SMT methods, in partic-
ular evaluation metrics, can produce poor per-
formance. We then look to the task of leverag-
ing these semantics for translation, which we
approach in three ways: by adapting the trans-
lation system to the domain of the resource;
by examining if semantics can help to predict
the syntactic structure used in translation; and
by evaluating if we can use existing translated
taxonomies to disambiguate translations. We
present some early results from these experi-
ments, which shed light on the degree of suc-
cess we may have with each approach.
1 Introduction
Taxonomies and ontologies are data structures that
organise conceptual information by establishing re-
lations among concepts, hierarchical and partitive
relations being the most important ones. Nowadays,
ontologies have a wide range of uses in many do-
mains, for example, finance (International Account-
ing Standards Board, 2007), bio-medicine (Col-
lier et al, 2008) (Ashburner et al, 2000) and li-
braries (Mischo, 1982). These resources normally
attach labels in natural language to the concepts and
relations that define their structure, and these la-
bels can be used for a number of purposes, such
as providing user interface localization (McCrae et
al., 2010), multilingual data access (Declerck et al,
2010), information extraction (Mu?ller et al, 2004)
and natural language generation (Bontcheva, 2005).
It seems natural that for applications that use such
ontologies and taxonomies, translation of the natu-
ral language descriptions associated with them is re-
quired in order to adapt these methods to new lan-
guages. Currently, there has been some work on
this in the context of ontology localisation, such
as Espinoza et al (2008) and (2009), Cimiano et
al. (2010), Fu et al (2010) and Navigli and Pen-
zetto (2010). However, this work has focused on the
case in which exact or partial translations are found
in other similar resources such as bilingual lexica.
Instead, in this paper we look at how we may gain an
adequate translation using statistical machine trans-
lation approaches that also utilise the semantic in-
formation beyond the label or term describing the
concept, that is relations among the concepts in the
ontology, as well as the attributes or properties that
describe concepts, as will be explained in more de-
tail in section 2.
Current work in machine translation has shown
that word sense disambiguation can play an im-
portant role by using the surrounding words as
context to disambiguate terms (Carpuat and Wu,
2007) (Apidianaki, 2009). Such techniques have
116
been extrapolated to the translation of taxonomies
and ontologies, in which the ?context? of a taxon-
omy or ontology label corresponds to the ontology
structure that surrounds the label in question. This
structure, which is made up of the lexical informa-
tion provided by labels and the semantic informa-
tion provided by the ontology structure, defines the
sense of the concept and can be exploited in the dis-
ambiguation process (Espinoza et al, 2008).
2 Definition of Taxonomy and Ontology
Translation
2.1 Formal Definition
We define a taxonomy as a set of concepts, C, with
equivalence (synonymy) links, S, subsumption (hy-
pernymy) links, H , and a labelling function l that
maps each concept to a single label from a language
??. Formally we define a taxonomy, T , as a set of
tuples (C, S,H, l) such that S ? P(C ? C) and
H ? P(C ? C) and l is a function in C ? ??. We
also require that S is a transitive, symmetric and re-
flexive relation, and H is transitive. While we note
here that this abstraction does not come close to cap-
turing the full expressive power of many ontologies
(or even taxonomies), it is sufficient for this paper to
focus on the use of only equivalence and subsump-
tion relationships for translation.
2.2 Analysis of ontology labels
Another important issue to note here is that the
kind of language used within ontologies and tax-
onomies is significantly different from that found
within free text. In particular, we observe that the
terms used to designate concepts are frequently just
noun phrases and are significantly shorter than a
usual sentence. In the case of the relations between
concepts (dubbed object properties) and attributes
of concepts (data type properties), these are occa-
sionally labelled by means of verbal phrases. We
demonstrate this by looking at three widely used on-
tologies/taxonomies.
1. Friend of a friend: The Friend of a Friend
(FOAF) ontology is used to describe social
networks on the Semantic Web (Brickley and
Miller, 2010). It is a small taxonomy with very
short labels. Labels for concepts are compound
words made up of up to three words.
2. Gene Ontology: The Gene Ontology (Ash-
burner et al, 2000) is a very large database of
terminology related to genetics. We note that
while some of the terms are technical and do
not require translation, e.g., ESCRT-I, the ma-
jority do, e.g., cytokinesis by cell plate forma-
tion.
3. IFRS 2009: The IFRS taxonomy (International
Accounting Standards Board, 2007) is used for
providing electronic financial reports for audit-
ing. The terms contained within this taxon-
omy are frequently long and are entirely noun
phrases.
We applied tokenization and manual phrase anal-
ysis to the labels in these resources and the results
are summarized in table 1. As can be observed,
the variety of types of labels we may come across
when linguistically analysing and translating ontol-
ogy and taxonomy labels is quite large. We can
identify the two following properties that may influ-
ence the translation process of taxonomy and ontol-
ogy labels. Firstly, the length of terms ranges from
single words to highly complex compound phrases,
but is still generally shorter than a sentence. Sec-
ondly, terms are frequently about highly specialized
domains of knowledge.
For properties in the ontology we also identify
terms which consist of:
? Noun phrases identifying concepts.
? Verbal phrases that are only made up of the
verb with an optional preposition.
? Complex verbal phrases that include the predi-
cate.
? Noun phrases that indicate possession of a par-
ticular characteristic (e.g., interest meaning X
has an interest in Y).
3 Creation of a corpus for taxonomy and
ontology translation
For the purpose of training systems to work on the
translation of ontologies and taxonomies, it is nec-
essary to create a corpus that has similar linguistic
structure to that found in ontologies and taxonomies.
We used the titles of Wikipedia1 for the following
1http://www.wikipedia.org
117
Size Mean tokens per label Noun Phrases Verb Phrases
FOAF 79 1.57 94.9% 8.9%
Gene Ontology 33795 4.45 100.0% 0.0%
IFRS 2009 2757 8.39 100.0% 0.0%
Table 1: Lexical Analysis of labels
Link Direct Fragment Broken
German 487372 484314 1735 1323
Spanish 347953 346941 330 682
Table 2: Number of translation for pages in Wikipedia
reasons:
? Links to articles in different languages can be
viewed as translations of the page titles.
? The titles of articles have similar properties to
the ontologies labels mentioned above with an
average of 2.46 tokens.
? There are a very large number of labels. In fact
we found that there were 5,941,8902 articles of
which 3,515,640 were content pages (i.e., not
special pages such as category pages)
We included non-content pages (in particular, cat-
egory pages) in the corpus as they were generally
useful for translation, especially the titles of cat-
egory pages. In table 2 we see the number of
translations, which we further grouped according to
whether they actually corresponded to pages in the
other languages, as it is also possible that the trans-
lations links pointed to subsections of an article or
to missing pages.
Wikipedia also includes redirect links that allow
for alternative titles to be mapped to a given con-
cept. These can be useful as they contain synonyms,
but also introduce a lot more noise into the corpus
as they also include misspelled and foreign terms.
To evaluate the effectiveness of including these data
for creating a machine translation corpus, we took
a random sample of 100 pages which at least one
page redirects to (there are 1,244,647 of these pages
in total). We found that these pages had a total
of 242 extra titles from the redirect page of which
2All statistics are based on the dump on 17th March 2011
204 (84.3%) where true synonyms, 19 (7.9%) were
misspellings, 8 (3.3%) were foreign names for con-
cepts (e.g., the French name for ?Zeebrugge?), and
11 (4.5%) were unrelated. As such, we conclude
that these extra titles were useful for constructing the
corpus, increasing the size of the corpus by approx-
imately 50% across all languages. There are sev-
eral advantages to deriving a corpus fromWikipedia,
for example it is possible to provide some hierarchi-
cal links by the use of the category that a page be-
longs to, such as has been performed by the DBpedia
project (Auer et al, 2007).
4 Evaluation metrics for taxonomy and
ontology translation
Given the linguistic differences in taxonomy and
ontology labels, it seems necessary to investigate
the effectiveness of various metrics for the evalua-
tion of translation quality. There are a number of
metrics that are widely used for evaluating trans-
lation. Here we will focus on some of the most
widely used, namely BLEU (Papineni et al, 2002),
NIST (Doddington, 2002), METEOR (Banerjee and
Lavie, 2005) and WER (McCowan et al, 2004).
However, it is not clear which of these methods cor-
relate best with human evaluation, particularly for
the ontologies with short labels. To evaluate this
we collected a mixture of ontologies with short la-
bels on the topics of human diseases, agriculture,
geometry and project management, producing 437
labels. These were translated with web transla-
tion services from English to Spanish, in particu-
lar Google Translate3, Yahoo! BabelFish4 and SDL
FreeTranslation5. Having obtained translations for
each label in the ontology we calculated the evalua-
tion scores using the four metrics mentioned above.
We found that the source ontologies had an average
3http://translate.google.com
4http://babelfish.yahoo.com
5http://www.freetranslation.com
118
BLEU NIST METEOR WER
Evaluator 1,
Fluency 0.108 0.036 0.134 0.122
Evaluator 1,
Adequacy 0.209 0.214 0.303 0.169
Evaluator 2,
Fluency 0.183 0.062 0.266 0.164
Evaluator 2,
Adequacy 0.177 0.111 0.251 0.194
Evaluator 3,
Fluency 0.151 0.067 0.210 0.204
Evaluator 3,
Adequacy 0.143 0.129 0.221 0.120
Table 3: Correlation between manual evaluation results
and automatic evaluation scores
label length of 2.45 tokens and the translations gen-
erated had an average length of 2.16 tokens. We then
created a data set by mixing the translations from the
web translation services with a number of transla-
tions from the source ontologies, to act as a control.
We then gave these translations to 3 evaluators, who
scored them for adequacy and fluency as described
in Koehn (2010). Finally, we calculated the Pearson
correlation coefficient between the automatic scores
and the manual scores obtained. These are presented
in table 3 and figure 1.
As we can see from these results, one metric,
namely METEOR, seems to perform best in evaluat-
ing the quality of the translations. In fact this is not
surprising as there is a clear mathematical deficiency
that both NIST and BLEU have for evaluating trans-
lations for very short labels like the ones we have
here. To illustrate this, we recall the formulation of
BLEU as given in (Papineni et al, 2002):
BLEU = BP ? exp(
N
?
n=1
wn log pn)
WhereBP is a brevity penalty, wn a weight value
and pn represents the n-gram precision, indicating
how many times a particular n-gram in the source
text is found among the target translations. We note,
however, that for very short labels it is highly likely
that pn will be zero. This creates a significant issue,
as from the equation above, if any of the values of pn
are zero, the overall score, BLEU, will also be zero.
Figure 1: Correlation between manual evaluation results
and automatic evaluation scores
For the results above we chose N = 2, and cor-
rected for single-word labels. However, the scores
were still significantly worse, similar problems af-
fect the NIST metric. As such, for the taxonomy
and ontology translation task we do not recommend
using BLEU or NIST as an evaluation metric. We
note that METEOR is a more sophisticated method
than WER and, as expected, performs better.
5 Approaches for taxonomy and ontology
translation
5.1 Domain adaptation
It is generally the case that many ontologies and tax-
onomies focus on only a very specific domain, thus
it seems likely that adaptation of translation systems
by use of an in-domain corpus may improve trans-
lation quality. This is particularly valid in the case
of ontologies which frequently contain ?subject? an-
notations6 for not only the whole data structure but
often individual elements. To demonstrate this we
tried to translate the IFRS 2009 taxonomy using
the Moses Decoder (Koehn et al, 2007), which we
trained on the EuroParl corpus (Koehn, 2005), trans-
lating from Spanish to English. As the IFRS taxon-
omy is on the topic of finance and accounting, we
6For example from the Dublin Core vocabulary: see http:
//dublincore.org/
119
Baseline With domain adaptation
WER? 0.135 0.138
METEOR 0.324 0.335
NIST 1.229 1.278
BLEU 0.090 0.116
Table 4: Results of domain-adapted translation. ?Lower
WER scores are better
chose all terms from our Wikipedia corpus which
belonged to categories containing the words: ?fi-
nance?, ?financial?, ?accounting?, ?accountancy?,
?bank?, ?banking?, ?economy?, ?economic?, ?in-
vestment?, ?insurance?and ?actuarial? and as such
we had a domain corpus of approximately 5000
terms. We then proceeded to recompute the phrase
table using the methodology as described in Wu et
al, (2008), computing the probabilities as follows for
some weighting factor 0 < ? < 1:
p(e|f) = ?p1(e|f) + (1? ?)pd(e|f)
Where p1 is the EuroParl trained probability and pd
the scores on our domain subset. The evaluation for
these metrics is given in table 4. As can be seen
with the exception of the WER metric, the domain
adaption does seem to help in translation, which cor-
roborates the results obtained by other authors.
5.2 Syntactic Analysis
One key question to figure out is: if we have a se-
mantic model can this be used to predict the syntac-
tic structure of the translation to a significant degree?
As an example of this we consider the taxonomic
term ?statement?, which is translated by Google
Translate7 to German as ?Erkla?rung?, whereas the
term ?annual statement? is translated as ?Jahresab-
schluss?. However, if the taxonomy contains a sub-
sumption (hypernymy) relationship between these
terms we can deduce that the translation ?Erkla?rung?
is not correct and the translation ?Abschluss? should
be preferred. We chose to evaluate this idea on the
IFRS taxonomy as the labels it contains are much
longer and more structured than some of the other
resources. Furthermore, in this taxonomy the origi-
nal English labels have been translated into ten lan-
guages, so that it is already a multilingual resource
7Translations results obtained 8th March 2011
P (syn|s) P (syn|p) P (syn|n)
English 0.147 0.012 0.001
Dutch 0.137 0.011 0.001
German 0.125 0.007 0.001
Spanish 0.126 0.012 0.001
Table 5: Probability of syntactic relationship given a se-
mantic relationship in IFRS labels
that can be used as gold standard. Regarding the
syntax of labels, it is often the case that one term is
derived from another by addition of a complemen-
tary phrase. For example the following terms all ex-
ist in the taxonomy:
1. Minimum finance lease payments receivable
2. Minimum finance lease payments receivable, at
present value
3. Minimum finance lease payments receivable, at
present value, end of period not later than one
year
4. Minimum finance lease payments receivable, at
present value, end of period later than one year
and not later than five years
A high-quality translation of these terms would
ideally preserve this same syntactic structure in the
target language.We attempt to answer how useful
ontological structure is by trying to deduce if there
is a semantic relationship between terms then is it
more likely that there is a syntactic relationship. We
started by simplifying the idea of syntactic depen-
dency to the following: we say that two terms are
syntactically related if one label is a sub-string of
another, so that in the example above the first label
is syntactically related to the other three and the sec-
ond is related to the last two. For English, we found
that there were 3744 syntactically related terms ac-
cording to this criteria, corresponding to 0.1% of all
label pairs within the taxonomy, for all languages.
For ontology structure we used the number of rela-
tions indicated in the taxonomy, of which there are
1070 indicating a subsumption relationship and 987
indicating a partitive relationship8. This means that
8IFRS includes links for calculating certain values, i.e., that
?Total Assets? is a sum of values such as ?Total Assets in Prop-
120
e ? f P (synf |syne, s) P (synf |syne, p) P (synf |syne, n)
English ? Spanish 0.813 ? 0.059 0.750 ? 0.205 0.835 ? 0.013
English ? German 0.835 ? 0.062 0.417 ? 0.212 0.790 ? 0.013
English ? Dutch 0.875 ? 0.063 0.833 ? 0.226 0.898 ? 0.013
Average 0.841 ? 0.035 0.665 ? 0.101 0.841 ? 0.008
Table 6: Probability of cross-lingual preservation of syntax given semantic relationship in IFRS. Note here s refers to
the source language and t to the target language. Error values are 95% of standard deviation.
0.08% of label pairs were semantically related. We
then examined if the semantic relation could predict
whether there was a syntactic relationship between
the terms in a single language. We define Ns as the
number of label pairs with a subsumption relation-
ship and similarly define Np, Nn and Nsyn for parti-
tive, semantically unrelated and syntactically related
pairs. We also define Ns?syn, Np?syn and Nn?syn
for label pairs with both subsumption, partitive or no
semantic relation and a syntactic relationships. As
such we define the following values
P (syn|s) = Ns?syn
Ns
Similarly we define P (syn|p) and P (syn|n) and
present these values in table 5 for four languages.
As we can see from these results, it seems that
both subsumption and partitive relationships are
strongly indicative of syntactic relationships as we
might expect. The second question is: is it more
likely that we see a syntactic dependency in trans-
lation if we have a semantic relationship, i.e., is the
syntax more likely to be preserved if these terms are
semantically related. We define Nsyne as the value
of Nsyn for a language e, e.g., Nsynen is the num-
ber of syntactically related English label pairs in the
taxonomy. As each label has exactly one transla-
tion we can also define Nsyne?synf?s as the number
of concepts whose labels are syntactically related in
both language e and f and are semantically related
by a subsumption relationship; similarly we define
Nsyne?synf?p and Nsyne?synf?n. Hence we can de-
fine
P (synf |syne, s) =
Nsynf?syne?s
Nsyne?s
erty, Plant and Equipment?, we view such a relationship as se-
mantically indicative that one term is part of another, i.e., as
partitive or meronymic
And similarly define P (synf |syne, p) and
P (synf |syne, n). We calculated these values on
the IFRS taxonomies, the results of which are
represented in table 6.
The partitive data was very sparse, due to the fact
that only 15 concepts in the source taxonomy had a
partitive relationship and were syntactically related,
so we cannot draw any strong conclusions from it.
For the subsumption relationship we have a clearer
result and in fact averaged across all language pairs
we found that the likelihood of the syntax being pre-
served in the translation was nearly exactly the same
for semantically related and semantically unrelated
concepts. From this result we can conclude that
the probability of syntax given either subsumptive or
partitive relationship is not very large, at least from
the reduced syntactic model we used here. While
our model reduces syntax to n-gram overlap, we
believe that if there was a stronger correlation us-
ing a more sophisticated syntactic model, we would
still see some noticable effect here as we did mono-
lingually. We also note that we applied this to only
one taxonomy and it is possible that the result may
be different in a different resource. Furthermore,
we note there is a strong relationship between se-
mantics and syntax in a mono-lingual context and
as such adaption of a language model to incorporate
this bias may improve the translation of ontologies
and taxonomies.
5.3 Comparison of ontology structure
Our third intuition in approaching ontology trans-
lation is that the comparison of ontology or taxon-
omy structures containing source and target labels
may help in the disambiguation process of transla-
tion candidates. A prerequisite in this sense is the
availability of equivalent (or similar) ontology struc-
tures to be compared.
121
Figure 2: Two approaches to translate ontology labels.
From a technical point of view, we consider the
translation task as a word sense disambiguation task.
We identify two methods for comparing ontology
structures, which are illustrated in Figure 2.
The first method relies on a multilingual resource,
i.e., a multilingual ontology or taxonomy. The on-
tology represented on the left-hand side of the fig-
ure consists of several monolingual conceptualiza-
tions related to each other by means of an inter-
lingual index, as is the case in the EuroWordNet lex-
icon (Vossen, 1999). For example, if the original
label is chair for seat in English, several translations
for it are obtained in Spanish such as: silla (for seat),
ca?tedra (for university position), presidente (for per-
son leading a meeting). Each of these correspond
to a sense in the English WordNet, and hence each
translation selects a hierachical structure with En-
glish labels. The next step is to compare the input
structure of the original ontology containing chair
against the three different structures in English rep-
resenting the several senses of chair and obtain the
corresponding label in Spanish.
The second method relies on a monolingual re-
source, i.e., on monolingual ontologies in the tar-
get language, which means that we need to compare
structures documented with labels in different lan-
guages. As such we obtain a separate translated on-
tologies for each combination of label translations
suggested by the baseline system. Selecting the cor-
rect translations is then clearly a hard optimization
problem.
For the time being, we have only experimented
with the first approach using EuroWordNet. Sev-
eral solutions have been proposed in the context of
ontology matching in a monolingual scenario (see
(Shvaiko and Euzenat, 2005) or (Giunchiglia et al,
2006)). The ranking method we use to compare
structures relies on an equivalence probability mea-
sure between two candidate structures, as proposed
in (Trillo et al, 2007).
We assume that we have a taxonomy or ontology
entity o1 and we wish to deduce if it is similar to
another taxonomy or ontology entity o2 from a ref-
erence taxonomy or ontology (i.e., EuroWordNet) in
the same language. We shall make a simplifying as-
sumption that each ontology entity is associated with
a unique label, e.g., lo1 . As such we wish to deduce
if o1 represents the same concept as o2 and hence if
lo2 is a translation for lo1 . Our model relies on the
Vector Space Model (Raghavan and Wong, 1986)
to calculate the similarity between different labels,
which essentially involves calculating a vector from
the bag of words contained within each labels and
then calculating the cosine similarity between these
vectors. We shall denotes this as v(o1, o2). We then
use four main features in the calculation of the sim-
ilarity
? The VSM-similarity between the labels of enti-
ties, o1, o2.
? The VSM-similarity between any glosses (de-
scriptions) that may exist in the source or refer-
ence taxonomy/ontology.
? The hypernym similarity given to a fixed depth
d, given that set of hypernyms of an entity oi is
given as a set
hO(oi) = {h|(oi, h) ? H}
Then we calculate the similarity for d > 1 re-
cursively as
122
sh(o1, o2, d) =
?
h1?hO(o1),h2?hO(o2) ?(h1, h2, d)
|hO(o1)||hO(o2)|
?(h1, h2, d) = ?v(h1, h2)+(1??)sh(h1, h2, d?1)
And for d = 1 it is given as
sh(o1, o2, 1) =
?
h1?hO(o1),h2?hO(o2) v(h1, h2)
|hO(o1)||hO(o2)|
? The hyponym similarity, calculated as the hy-
pernym similarity but using the hyponym set
given by
HO(oi) = {h|(h, oi) ? H}
We then incorporate these factors into a vector x
and calculate the similarity of two entities as
s(o1, o2) = wTx
Where w is a weight vector of non-negative reals
and satisfies ||w|| = 1, which we set manually.
We then applied this to the FOAF ontol-
ogy (Brickley and Miller, 2010), which was manu-
ally translated to give us a reference translation. Af-
ter that, we collected a set of candidate translations
obtained by using the web translation resources ref-
erenced in section 3, along with additional candi-
dates found in our multilingual resource. Finally,
we used EuroWordNet (Vossen, 1999) as the refer-
ence taxonomy and ranked the translations accord-
ing to the score given by the metric above. In table
7, we present the results where our system selected
the candidate translation with the highest similarity
to our source ontology entity. In the case that we
could not find a reference translation we split the la-
bel into tokens and found the translation by select-
ing the best token. We compared these results to a
baseline method that selected one of the reference
translations at random.
These results are in all cases significantly stronger
than the baseline results showing that by compar-
ing the structure of ontology elements it is possible
to significantly improve the quality of translation.
These results are encouraging and we believe that
more research is needed in this sense. In particular,
we would like to investigate the benefits of perform-
ing a cross-lingual ontology alignment in which we
measure the semantic similarity of terms in different
languages.
Baseline Best Translation
WER? 0.725 0.617
METEOR 0.089 0.157
NIST 0.070 0.139
BLEU 0.103 0.187
Table 7: Results of selecting translation by structural
comparison. ?Lower WER scores are better
6 Conclusion
In this paper we presented the problem of ontology
and taxonomy translation as a special case of ma-
chine translation that has certain extra characteris-
tics. Our examination of the problem showed that
the main two differences are the presence of struc-
tured semantics and shorter, hence more ambiguous,
labels. We demonstrated that as a result of this lin-
guistic nature, some machine translation metrics do
not perform as well as they do in free-text trans-
lations. We then presented the results of early in-
vestigations into how we may use the special fea-
tures of taxonomy and ontology translation to im-
prove quality of translation. The first of these was
domain adaptation, which in line with other authors
is useful for texts in a particular domain. We also in-
vestigated the possibility of using the link between
syntactic similarity and semantic similarity to help,
however although we find that mono-lingually there
was a strong correspondence between syntax and se-
mantics, this result did not seem to extend well to a
cross-lingual setting. As such we believe there may
only be slight benefits of using techniques, however
further investigation is needed. Finally, we looked at
using word sense disambiguation by comparing the
structure of the input ontology to that of an already
translated reference ontology. We found this method
to be very effective in choosing the best translations.
However it is dependent on the existence of a mul-
tilingual resource that already has such terms. As
such, we view the topic of taxonomy and ontology
translation as an interesting sub-problem of machine
translation and believe there is still much fruitful
work to be done to obtain a system that can cor-
rectly leverage the semantics present in these data
structures in a way that improves translation quality.
123
References
Marianna Apidianaki. 2009. Data-driven semantic anal-
ysis for multilingual WSD and lexical selection in
translation. In Proceedings of the 12th Conference of
the European Chapter of the Association for Compu-
tational Linguistics (EACL).
Michael Ashburner, Catherine Ball, Judith Blake, David
Botstein, Heather Butler, J. Michael Cherry, Allan
Davis, et al 2000. Gene ontology: tool for the uni-
fication of biology. The Gene Ontology Consortium.
Nature genetics, 25(1):25?29.
So?ren Auer, Christian Bizer, Georgi Kobilarov, Jens
Lehmann, Richard Cyganiak, and Zachary Ives. 2007.
Dbpedia: A nucleus for a web of open data. The Se-
mantic Web, 4825:722?735.
Satanjeev Banerjee and Alon Lavie. 2005. METEOR:
An automatic metric for MT evaluation with improved
correlation with human judgments. Intrinsic and Ex-
trinsic Evaluation Measures for Machine Translation
and/or Summarization, page 65.
Kalina Bontcheva. 2005. Generating tailored textual
summaries from ontologies. In The Semantic Web:
Research and Applications, pages 531?545. Springer.
Dan Brickley and Libby Miller, 2010. FOAF Vocabulary
Specification 0.98. Accessed 3 December 2010.
Marine Carpuat and Dekai Wu. 2007. Improving Sta-
tistical Machine Translation using Word Sense Disam-
biguation. In Proceedings of the 2007 Joint Confer-
ence on Empirical Methods in Natural Language Pro-
cessing and Computational Natural Language Learn-
ing (EMNLP-CoNLL 2007).
Philipp Cimiano, Elena Montiel-Ponsoda, Paul Buite-
laar, Mauricio Espinoza, and Asuncio?n Go?mez-Pe?rez.
2010. A note on ontology localization. Journal of Ap-
plied Ontology (JAO), 5:127?137.
Nigel Collier, Son Doan, Ai Kawazoe, Reiko Matsuda
Goodwin, Mike Conway, Yoshio Tateno, Quoc-Hung
Ngo, Dinh Dien, Asanee Kawtrakul, Koichi Takeuchi,
Mika Shigematsu, and Kiyosu Taniguchi. 2008. Bio-
Caster: detecting public health rumors with a Web-
based text mining system. Oxford Bioinformatics,
24(24):2940?2941.
Thierry Declerck, Hans-Ullrich Krieger, Susan Marie
Thomas, Paul Buitelaar, Sean O?Riain, Tobias Wun-
ner, Gilles Maguet, John McCrae, Dennis Spohr, and
Elena Montiel-Ponsoda. 2010. Ontology-based Mul-
tilingual Access to Financial Reports for Sharing Busi-
ness Knowledge across Europe. In Jo?zsef Roo?z and
Ja?nos Ivanyos, editors, Internal Financial Control As-
sessment Applying Multilingual Ontology Framework,
pages 67?76. HVG Press Kft.
George Doddington. 2002. Automatic evaluation of ma-
chine translation quality using n-gram co-occurrence
statistics. In Proceedings of the second interna-
tional conference on Human Language Technology
Research, pages 138?145. Morgan Kaufmann Publish-
ers Inc.
Mauricio Espinoza, Asuncio?n Go?mez-Pe?rez, and Ed-
uardo Mena. 2008. Enriching an Ontology with
Multilingual Information. In Proceedings of the 5th
Annual of the European Semantic Web Conference
(ESWC08), pages 333?347.
Mauricio Espinoza, Elena Montiel-Ponsoda, and
Asuncio?n Go?mez-Pe?rez. 2009. Ontology Local-
ization. In Proceedings of the 5th International
Conference on Knowledge Capture (KCAP09), pages
33?40.
Bo Fu, Rob Brennan, and Declan O?Sullivan. 2010.
Cross-Lingual Ontology Mapping and Its Use on the
Multilingual Semantic Web. In Proceedings of the
1st Workshop on the Multilingual Semantic Web, at
the 19th International World Wide Web Conference
(WWW 2010).
Fausto Giunchiglia, Pavel Shvaiko, and Mikalai Yatske-
vich. 2006. Discovering missing background knowl-
edge in ontology matching. In Proceeding of the 17th
European Conference on Artificial Intelligence, pages
382?386.
International Accounting Standards Board, 2007. Inter-
national Financial Reporting Standards 2007 (includ-
ing International Accounting Standards (IAS) and In-
terpretations as at 1 January 2007).
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, et al 2007. Moses: Open source toolkit for sta-
tistical machine translation. In Proceedings of the 45th
Annual Meeting of the ACL on Interactive Poster and
Demonstration Sessions, pages 177?180.
Philipp Koehn. 2005. Europarl: A parallel corpus for
statistical machine translation. In Proceedings of the
Tenth Machine Translation Summit.
Philipp Koehn. 2010. Statistical Machine Translation.
Cambridge University Press.
Iain McCowan, Darren Moore, John Dines, Daniel
Gatica-Perez, Mike Flynn, Pierre Wellner, and Herve?
Bourlard. 2004. On the use of information retrieval
measures for speech recognition evaluation. Technical
report, IDIAP.
John McCrae, Jesu?s Campana, and Philipp Cimiano.
2010. CLOVA: An Architecture for Cross-Language
Semantic Data Querying. In Proceedings of the First
Mutlilingual Semantic Web Workshop.
William Mischo. 1982. Library of Congress Subject
Headings. Cataloging & Classification Quarterly,
1(2):105?124.
124
Hans-Michael Mu?ller, Eimear E Kenny, and Paul W
Sternberg. 2004. Textpresso: An ontology-based in-
formation retrieval and extraction system for biologi-
cal literature. PLoS Biol, 2(11):e309.
Roberto Navigli and Simone Paolo Ponzetto. 2010. Ba-
belnet: Building a very large multilingual semantic
network. In Proceedings of the 48th Annual Meet-
ing of the Association for Computational Linguistics,
pages 216?225.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic eval-
uation of machine translation. In Proceedings of the
40th annual meeting on association for computational
linguistics, pages 311?318. Association for Computa-
tional Linguistics.
V.Vijay Raghavan and S.K.M. Wong. 1986. A criti-
cal analysis of vector space model for information re-
trieval. Journal of the American Society for Informa-
tion Science, 37(5):279?287.
Pavel Shvaiko and Jerome Euzenat. 2005. A survey of
schema-based matching approaches. Journal on Data
Semantics IV, pages 146?171.
Fabian Suchanek, Gjergji Kasneci, and Gerhard Weikum.
2007. Yago: a core of semantic knowledge. In Pro-
ceedings of the 16th international conference on World
Wide Web, pages 697?706.
Raquel Trillo, Jorge Gracia, Mauricio Espinoza, and Ed-
uardo Mena. 2007. Discovering the semantics of user
keywords. Journal of Universal Computer Science,
13(12):1908?1935.
Piek Vossen. 1999. EuroWordNet a multilingual
database with lexical semantic networks. Computa-
tional Linguistics, 25(4).
Hua Wu, Haifeng Wang, and Chengqing Zong. 2008.
Domain adaptation for statistical machine translation
with domain dictionary and monolingual corpora. In
Proceedings of the 22nd International Conference
on Computational Linguistics-Volume 1, pages 993?
1000. Association for Computational Linguistics.
125
