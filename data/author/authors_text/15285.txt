Proceedings of the ACL-HLT 2011 Student Session, pages 1?5,
Portland, OR, USA 19-24 June 2011. c?2011 Association for Computational Linguistics
Word Alignment Combination over Multiple Word Segmentation 
 
 
Ning Xi, Guangchao Tang, Boyuan Li, Yinggong Zhao 
State Key Laboratory for Novel Software Technology, 
Department of Computer Science and Technology, 
Nanjing University, Nanjing, 210093, China 
 {xin,tanggc,liby,zhaoyg}@nlp.nju.edu.cn 
 
 
 
 
 
 
Abstract 
In this paper, we present a new word alignment 
combination approach on language pairs where 
one language has no explicit word boundaries. 
Instead of combining word alignments of dif-
ferent models (Xiang et al, 2010), we try to 
combine word alignments over multiple mono-
lingually motivated word segmentation. Our 
approach is based on link confidence score de-
fined over multiple segmentations, thus the 
combined alignment is more robust to inappro-
priate word segmentation. Our combination al-
gorithm is simple, efficient, and easy to 
implement. In the Chinese-English experiment, 
our approach effectively improved word align-
ment quality as well as translation performance 
on all segmentations simultaneously, which 
showed that word alignment can benefit from 
complementary knowledge due to the diversity 
of multiple and monolingually motivated seg-
mentations. 
1 Introduction 
Word segmentation is the first step prior to word 
alignment for building statistical machine transla-
tions (SMT) on language pairs without explicit 
word boundaries such as Chinese-English.  Many 
works have focused on the improvement of word 
alignment models. (Brown et al, 1993; Haghighi et 
al., 2009; Liu et al, 2010). Most of the word 
alignment models take single word segmentation 
as input. However, for languages such as Chinese, 
it is necessary to segment sentences into appropri-
ate words for word alignment. 
A large amount of works have stressed the im-
pact of word segmentation on word alignment. Xu 
et al (2004), Ma et al (2007), Chang et al (2008), 
and Chung et al (2009) try to learn word segmen-
tation from bilingually motivated point of view; 
they use an initial alignment to learn word segmen-
tation appropriate for SMT. However, their per-
formance is limited by the quality of the initial 
alignments, and the processes are time-consuming. 
Some other methods try to combine multiple word 
segmentation at SMT decoding step (Xu et al, 
2005; Dyer et al, 2008; Zhang et al, 2008; Dyer et 
al., 2009; Xiao et al, 2010). Different segmenta-
tions are yet independently used for word align-
ment. 
Instead of time-consuming segmentation optimi-
zation based on alignment or postponing segmenta-
tion combination late till SMT decoding phase, we 
try to combine word alignments over multiple 
monolingually motivated word segmentation on 
Chinese-English pair, in order to improve word 
alignment quality and translation performance for 
all segmentations. We introduce a tabular structure 
called word segmentation network (WSN for short) 
to encode multiple segmentations of a Chinese sen-
tence, and define skeleton links (SL for short) be-
tween spans of WSN and words of English 
sentence. The confidence score of a SL is defined 
over multiple segmentations. Our combination al-
gorithm picks up potential SLs based on their con-
fidence scores similar to Xiang et al (2010), and 
then projects each selected SL to link in all seg-
mentation respectively. Our algorithm is simple, 
efficient, easy to implement, and can effectively 
improve word alignment quality on all segmenta-
tions simultaneously, and alignment errors caused 
1
by inappropriate segmentations from single seg-
menter can be substantially reduced. 
Two questions will be answered in the paper: 1) 
how to define the link confidence over multiple 
segmentations in combination algorithm? 2) Ac-
cording to Xiang et al (2010), the success of their 
word alignment combination of different models 
lies in the complementary information that the 
candidate alignments contain. In our work, are 
multiple monolingually motivated segmentations 
complementary enough to improve the alignments? 
The rest of this paper is structured as follows: 
WSN will be introduced in section 2. Combination 
algorithm will be presented in section 3. Experi-
ments of word alignment and SMT will be reported 
in section 4. 
2  Word Segmentation Network 
We propose a new structure called word segmenta-
tion network (WSN) to encode multiple segmenta-
tions. Due to space limitation, all definitions are 
presented by illustration of a running example of a 
sentence pair: 
 
???? (xia-yu-lu-hua)  
Road is slippery when raining 
 
We first introduce skeleton segmentation. Given 
two segmentation S1 and S2 in Table 1, the word 
boundaries of their skeleton segmentation is the 
union of word boundaries (marked by ?/?) in S1 
and S2. 
 
 Segmentation 
S1 ? / ? / ?? 
S2 ?? / ? / ? 
skeleton ? / ? / ? / ? 
 
Table 1: The skeleton segmentation of two seg-
mentations S1 and S2. 
 
The WSN of S1 and S2 is shown in Table 2.  As 
is depicted, line 1 and 2 represent words in S1 and 
S2 respectively, line 3 represents skeleton words. 
Each column, or span, comprises a skeleton word 
and words of S1 and S2 with the skeleton word as 
their morphemes at that position. The number of 
columns of a WSN is equal to the number of skele-
ton words. It should be noted that there may be 
words covering two or more spans, such as ???? 
in S1, because the word ???? in S1 is split into 
two words ??? and ??? in S2.  
S1 ? 1 ? 2 ?? 3 
S2 ?? 1 ? 2 ? 3 
skeleton ? 1 ? 2 ? 3 ? 4 
 
Table 2:  The WSN of Table 1. Subscripts 
indicate indexes of words. 
 
The skeleton word can be projected onto words 
in the same span in S1 and S2. For clarity, words in 
each segmentation are indexed (1-based), for ex-
ample, ???? in S1 is indexed by 3. We use a pro-
jection function       to denote the index of the 
word onto which the j-th skeleton word is project-
ed in the k-th segmentation, for example,       
  and        . 
In the next, we define the links between spans of 
the WSN and English words as skeleton links (SL), 
the subset of all SLs comprise the skeleton align-
ment (SA). Figure 1 shows an SA of the example. 
 
Figure 1: An example alignment between WSN in 
Table 2 and English sentence ?Road is slippery 
when raining?. (a) skeleton link; (b) skeleton 
alignment. 
 
Each span of the WSN comprises words from 
different segmentations (Figure 1a), which indi-
cates that the confidence score of a SL can be de-
fined over words in the same span. By projection 
function, a SL can be projected onto the link for 
each segmentation. Therefore, the problem of 
combining word alignment over different segmen-
tations can be transformed into the problem of se-
lecting SLs for SA first, and then project the 
selected SLs onto links for each segmentation re-
spectively. 
3  Combination Algorithm 
Given k alignments    over segmentations    
respectively         ), and       is the pair 
Road  
  
? 1 ? 2 ?? 3 
?? 1 ? 2 ? 3 
? 1 ? 2 ? 3 ? 4 
 
(a) 
  
(b) 
 
?? 3 
? 2 
? 3 
 
Road is slippery when raining  
2
of the Chinese WSN and its parallel English sen-
tence. Suppose     is the SL between the j-th span 
   and i-th English word   ,    
   is the link between 
the j-th Chinese word   
  in    and   . Inspired by 
Huang (2009), we define the confidence score of 
each SL as follows 
 (   |   )  ?             
           (1) 
 
where          
       is the confidence score of the 
link        
 , defined as 
 (       
 |   )
 ?    (       
 |   )              
       
(2) 
where c-to-e link posterior probability is defined as 
    (       
 |   )  
            
  
?               
   
    
  
 (3) 
and I is the length of  . E-to-c link posterior prob-
ability     (       
 |   )  can be defined similarly,  
Our alignment combination algorithm is as fol-
lows.  
1. Build WSN for Chinese sentence. 
2. Compute the confidence score for each SL 
based on Eq. (1). A SL     gets a vote from    
if        
  appears in             . Denote 
the set of all SLs getting at least one vote by 
  . 
3. All SLs in    are sorted in descending order 
and evaluated sequentially. A SL     is includ-
ed if its confidence score is higher than a tuna-
ble threshold  , and one of the following is 
true1: 
? Neither    nor    is aligned so far; 
?    is not aligned and its left or right neigh-
boring word is aligned to    so far; 
?    is not aligned and its left or right 
neighboring word is aligned to    so far. 
4. Repeat 3 until no more SLs can be included. 
All included SLs comprise   . 
5. Map SLs in    on each    to get k new align-
ments   
  respectively, i.e.   
          
      
   2         . For each  , we sort all 
                                                          
1 SLs getting   votes are forced to be included without further 
examination. 
2 Two or more SLs in    may be projected onto one links in 
  
 , in this case, we keep only one in   
 . 
links in   
  in ascending order and evaluated 
them sequentially  Compare   
  and   , A link 
    
  is removed from   
  if it is not appeared in 
  , and one of the following is true: 
? both   
 and    are aligned in   
 ; 
? There is a word which is neither left nor 
right neighboring word of    but aligned 
to   
  in   
 ; 
? There is a word which is neither left nor 
right neighboring word of   
  but aligned 
to    in   
 . 
The heuristic in step 3 is similar to Xiang et al 
(2010), which avoids adding error-prone links. We 
apply the similar heuristic again in step 5 in each 
  
            to delete error-prone links. The 
weights in Eq. (1) and   can be tuned in a hand-
aligned dataset to maximize word alignment F-
score on any   
  with hill climbing algorithm. 
Probabilities in Eq. (2) and Eq. (3) can be estimat-
ed using GIZA. 
4 Experiment 
4.1   Data 
Our training set contains about 190K Chinese-
English sentence pairs from LDC2003E14 corpus. 
The NIST?06 test set is used as our development 
set and the NIST?08 test set is used as our test set. 
The Chinese portions of all the data are prepro-
cessed by three monolingually motived segmenters 
respectively. These segmenters differ in either 
training method or specification, including 
ICTCLAS (I)3, Stanford segmenters with CTB (C) 
and PKU (P) specifications4 respectively. We used 
a phrase-based MT system similar to (Koehn et al, 
2003), and generated two baseline alignments us-
ing GIZA++ enhanced by gdf heuristics (Koehn et 
al., 2003) and a linear discriminative word align-
ment model (DIWA) (Liu et al, 2010) on training 
set with the three segmentations respectively. A 5-
gram language model trained from the Xinhua por-
tion of Gigaword corpus was used.  The decoding 
weights were optimized with Minimum Error Rate 
Training (MERT) (Och, 2003). We used the hand-
aligned set of 491 sentence pairs in Haghighi et al 
(2009), the first 250 sentence pairs were used to 
tune the weights in Eq. (1), and the other 241 were 
                                                          
3 http://www.ictclas.org/ 
4 http://nlp.stanford.edu/software/segmenter.shtml 
3
[???] [?] [380] [?] [??] [???] 
relief funds worth 3.8 million us dollars from the national foodstuff department 
[??] [??] [???] [??] [??] 
chief executive in the hksar  
[???] [?] [380] [?] [??] [???] [??] [??] [???] [??] [??] 
Figure 2: Two examples (left and right respectively) of word alignment on segmentation C. Baselines 
(DIWA) are in the top half, combined alignments are in the bottom half. The solid line represents the cor-
rect link while the dashed line represents the bad link. Each word is enclosed in square brackets. 
used to measure the word alignment quality. Note 
that we adapted the Chinese portion of this hand-
aligned set to segmentation C. 
4.2 Improvement of Word Alignment 
We first evaluate our combination approach on the 
hand-aligned set (on segmentation C). Table 3 
shows the precision, recall and F-score of baseline 
alignments and combined alignments. 
As shown in Table 3, the combination align-
ments outperformed the baselines (setting C) in all 
settings in both GIZA and DIWA. We notice that 
the higher F-score is mainly due to the higher pre-
cision in GIZA but higher recall in DIWA. In 
GIZA, the result of C+I and C+P achieve 8.4% and 
9.5% higher F-score respectively, and both of them 
outperformed C+P+I, we speculate it is because 
GIZA favors recall rather than DIWA, i.e. GIZA 
may contain more bad links than DIWA, which 
would lead to more unstable F-score if more 
alignments produced by GIZA are combined, just 
as the poor precision (69.68%) indicated. However, 
DIWA favors precision than recall (this observa-
tion is consistent with Liu et al (2010)), which 
may explain that the more diversified segmenta-
tions lead to better results in DIWA. 
 
 GIZA DIWA 
setting P R F P R F 
C 61.84 84.99 71.59 83.12 78.88 80.94 
C+P 80.16 79.80 79.98 84.15 79.41 81.57 
C+I 82.96 79.28 81.08 84.41 81.69 83.03 
C+I+P 69.68 85.17 77.81 83.38 82.98 83.18 
 
Table 3: Alignment precision, recall and F-score.  
C: baseline, C+I: Combination of C and I. 
 
Figure 2 gives baseline alignments and com-
bined alignments on two sentence pairs in the 
training data. As can be seen, alignment errors 
caused by inappropriate segmentations by single 
segmenter were substantially reduced.  For exam-
ple, in the second example, the word ??????
?? hksar? appears in segmentation I of the Chi-
nese sentence, which benefits the generation of the 
three correct links connecting for words ??
?? ,????, ????? respectively in the com-
bined alignment. 
4.3   Improvement in MT performance 
We then evaluate our combination approach on the 
SMT training data on all segmentations. For effi-
ciency, we just used the first 50k sentence pairs of 
the aligned training corpus with the three segmen-
tations to build three SMT systems respectively. 
Table 4 shows the BLEU scores of baselines and 
combined alignment (C+P+I, and then projected 
onto C, P, I respectively). Our approach achieves 
improvement over baseline alignments on all seg-
mentations consistently, without using any lattice 
decoding techniques as Dyer et al (2009).  The 
gain of translation performance purely comes from 
improvements of word alignment on all segmenta-
tions by our proposed word alignment combination. 
 
 GIZA DIWA 
Segmentation B Comb B Comb 
C 19.77 20.9 20.18 20.71 
P 20.5 21.16 20.41 21.14 
I 20.11 21.14 20.46 21.30 
 
Table 4: Improvement in BLEU scores. B:Baseline 
alignment, Comb: Combined alignment. 
4
5 Conclusion 
We evaluated our word alignment combination 
over three monolingually motivated segmentations 
on Chinese-English pair. We showed that the com-
bined alignment significantly outperforms the 
baseline alignment with both higher F-score and 
higher BLEU score on all segmentations. Our work 
also proved the effectiveness of link confidence 
score in combining different word alignment mod-
els (Xiang et al, 2010), and extend it to combine 
word alignments over different segmentations. 
Xu et al (2005) and Dyer et al (2009) combine 
different segmentations for SMT. They aim to 
achieve better translation but not higher alignment 
quality of all segmentations. They combine multi-
ple segmentations at SMT decoding step, while we 
combine segmentation alternatives at word align-
ment step. We believe that we can further improve 
the performance by combining these two kinds of 
works. We also believe that combining word 
alignments over both monolingually motivated and 
bilingually motivated segmentations (Ma et al, 
2009) can achieve higher performance. 
In the future, we will investigate combining 
word alignments on language pairs where both 
languages have no explicit word boundaries such 
as Chinese-Japanese. 
Acknowledgments 
This work was supported by the National Natural 
Science Foundation of China under Grant No. 
61003112, and the National Fundamental Research 
Program of China (2010CB327903). We would 
like to thank Xiuyi Jia and Shujie Liu for useful 
discussions and the anonymous reviewers for their 
constructive comments. 
 
References  
Peter F. Brown, Stephen A. Della Pietra, Vincent J. Del-
la Peitra, Robert L. Mercer. 1993. The Mathematics 
of statistical machine translation: parameter estima-
tion. Computational Linguistics, 19(2):263-311. 
Pi-Chuan Chang, Michel Galley, and Christopher D. 
Manning. 2008. Optimizing Chinese word segmenta-
tion for machine translation performance.  In Pro-
ceedings of third workshop on SMT, Pages:224-232. 
Tagyoung Chung and Daniel Gildea. 2009. Unsuper-
vised tokenization for machine translation. In Pro-
ceedings of EMNLP, Pages:718-726. 
Christopher Dyer, Smaranda Muresan, and Philip Res-
nik. 2008. Generalizing word lattice translation. In 
Proceedings of ACL, Pages:1012-1020. 
Christopher Dyer. 2009. Using a maximum entropy 
model to build segmentation lattices for mt. In Pro-
ceedings of NAACL, Pages:406-414. 
Franz Josef Och. 2003. Minimum error rate training in 
statistical machine translation. In Proceedings of 
ACL, Pages:440-447. 
Aria Haghighi, John Blitzer, John DeNero, and Dan 
Klein. 2009. Better word alignments with supervised 
ITG models. In Proceedings of ACL, Pages: 923-931. 
Fei Huang. 2009. Confidence measure for word align-
ment. In Proceedings of ACL, Pages:932-940. 
Philipp Koehn, Franz Josef Och and Daniel Marcu. 
2003. Statistical phrase-based translation. In Pro-
ceedings of HLT-NAACL, Pages:48-54. 
Yang Liu, Qun Liu, Shouxun Lin. 2010. Discriminative 
word alignment by linear modeling. Computational 
Linguistics, 36(3):303-339. 
Yanjun Ma, Nicolas Stroppa, and Andy Way. 2007. 
Bootstrapping word alignment via word packing. In 
Proceedings of ACL, Pages:304-311. 
Yanjun Ma and Andy Way. 2009. Bilingually motivated 
domain-adapted word segmentation for statistical 
machine translation. In Proceedings of EACL, Pag-
es:549-557. 
Bing Xiang, Yonggang Deng, and Bowen Zhou. 2010. 
Diversify and combine: improving word alignment 
for machine translation on low-resource languages. 
In Proceedings of ACL, Pages:932-940. 
Xinyan Xiao, Yang Liu, Young-Sook Hwang, Qun Liu, 
Shouxun Lin. 2010.  Joint tokenization and transla-
tion. In Proceedings of COLING, Pages:1200-1208. 
Jia Xu, Richard Zens, and Hermann Ney. 2004. Do we 
need Chinese word segmentation for statistical ma-
chine translation?  In Proceedings of the ACL 
SIGHAN Workshop, Pages: 122-128. 
Jia Xu, Evgeny Matusov, Richard Zens, and Hermann 
Ney. 2005. Integrated Chinese word segmentation in 
statistical machine translation. In Proceedings of 
IWSLT. 
Ruiqiang Zhang, Keiji Yasuda, and Eiichiro Sumita. 
2008. Improved statistical machine translation by 
multiple Chinese word segmentation. In Proceedings 
of the Third Workshop on SMT, Pages:216-223. 
5
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 285?290,
Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational Linguistics
Enhancing Statistical Machine Translation with Character Alignment 
 
Ning Xi, Guangchao Tang, Xinyu Dai, Shujian Huang, Jiajun Chen 
State Key Laboratory for Novel Software Technology, 
Department of Computer Science and Technology, 
Nanjing University, Nanjing, 210046, China 
{xin,tanggc,dxy,huangsj,chenjj}@nlp.nju.edu.cn 
 
  
Abstract 
The dominant practice of statistical machine 
translation (SMT) uses the same Chinese word 
segmentation specification in both alignment 
and translation rule induction steps in building 
Chinese-English SMT system, which may suf-
fer from a suboptimal problem that word seg-
mentation better for alignment is not necessarily 
better for translation. To tackle this, we propose 
a framework that uses two different segmenta-
tion specifications for alignment and translation 
respectively: we use Chinese character as the 
basic unit for alignment, and then convert this 
alignment to conventional word alignment for 
translation rule induction. Experimentally, our 
approach outperformed two baselines: fully 
word-based system (using word for both 
alignment and translation) and fully charac-
ter-based system, in terms of alignment quality 
and translation performance. 
1 Introduction 
Chinese Word segmentation is a necessary step in 
Chinese-English statistical machine translation 
(SMT) because Chinese sentences do not delimit 
words by spaces. The key characteristic of a Chi-
nese word segmenter is the segmentation specifi-
cation1. As depicted in Figure 1(a), the dominant 
practice of SMT uses the same word segmentation 
for both word alignment and translation rule induc-
tion. For brevity, we will refer to the word seg-
mentation of the bilingual corpus as word segmen-
tation for alignment (WSA for short), because it 
determines the basic tokens for alignment; and refer 
to the word segmentation of the aligned corpus as 
word segmentation for rules (WSR for short), be-
cause it determines the basic tokens of translation 
                                                          
1 We hereafter use ?word segmentation? for short. 
rules2, which also determines how the translation 
rules would be matched by the source sentences. 
It is widely accepted that word segmentation with 
a higher F-score will not necessarily yield better 
translation performance (Chang et al, 2008; Zhang 
et al, 2008; Xiao et al, 2010). Therefore, many 
approaches have been proposed to learn word 
segmentation suitable for SMT. These approaches 
were either complicated (Ma et al, 2007; Chang et 
al., 2008; Ma and Way, 2009; Paul et al, 2010), or 
of high computational complexity (Chung and 
Gildea 2009; Duan et al, 2010). Moreover, they 
implicitly assumed that WSA and WSR should be 
equal. This requirement may lead to a suboptimal 
problem that word segmentation better for align-
ment is not necessarily better for translation. 
To tackle this, we propose a framework that uses 
different word segmentation specifications as WSA 
and WSR respectively, as shown Figure 1(b). We 
investigate a solution in this framework: first, we 
use Chinese character as the basic unit for align-
ment, viz. character alignment; second, we use a 
simple method (Elming and Habash, 2007) to 
convert the character alignment to conventional 
word alignment for translation rule induction. In the 
                                                          
2 Interestingly, word is also a basic token in syntax-based rules. 
Word alignment 
Bilingual Corpus 
Aligned Corpus 
WSA
Translation Rules
WSA 
WSR 
Rule induction 
Decoding 
Translation Results WSR
Word alignment 
Bilingual Corpus 
Aligned Corpus 
WSA
Translation Rules 
WSA
WSR
Rule induction 
Decoding 
Translation Results WSR
Aligned Corpus 
WSR
Conversion 
(b) WSA?WSR 
Figure 1. WSA and WSR in SMT pipeline
(a)  WSA=WSR 
285
experiment, our approach consistently outper-
formed two baselines with three different word 
segmenters: fully word-based system (using word 
for both alignment and translation) and fully char-
acter-based system, in terms of alignment quality 
and translation performance. 
The remainder of this paper is structured as fol-
lows: Section 2 analyzes the influences of WSA and 
WSR on SMT respectively; Section 3 discusses 
how to convert character alignment to word align-
ment; Section 4 presents experimental results, fol-
lowed by conclusions and future work in section 5. 
2 Understanding WSA and WSR 
We propose a solution to tackle the suboptimal 
problem: using Chinese character for alignment 
while using Chinese word for translation. Character 
alignment differs from conventional word align-
ment in the basic tokens of the Chinese side of the 
training corpus3. Table 1 compares the token dis-
tributions of character-based corpus (CCorpus) and 
word-based corpus (WCorpus). We see that the 
WCorpus has a longer-tailed distribution than the 
CCorpus. More than 70% of the unique tokens ap-
pear less than 5 times in WCorpus. However, over 
half of the tokens appear more than or equal to 5 
times in the CCorpus.  This indicates that modeling 
word alignment could suffer more from data 
sparsity than modeling character alignment.  
Table 2 shows the numbers of the unique tokens 
(#UT) and unique bilingual token pairs (#UTP) of 
the two corpora. Consider two extensively features, 
fertility and translation features, which are exten-
sively used by many state-of-the-art word aligners. 
The number of parameters w.r.t. fertility features 
grows linearly with #UT while the number of pa-
rameters w.r.t. translation features grows linearly 
with #UTP. We compare #UT and #UTP of both 
corpora in Table 2. As can be seen, CCorpus has 
less UT and UTP than WCorpus, i.e. character 
alignment model has a compact parameterization 
than word alignment model, where the compactness 
of parameterization is shown very important in sta-
tistical modeling (Collins, 1999). 
Another advantage of character alignment is the 
reduction in alignment errors caused by word seg- 
                                                          
3 Several works have proposed to use character (letter) on both 
sides of the parallel corpus for SMT between similar (European) 
languages (Vilar et al, 2007; Tiedemann, 2009), however, 
Chinese is not similar to English. 
Frequency Characters (%) Words (%) 
1 27.22 45.39 
2 11.13 14.61 
3 6.18 6.47 
4 4.26 4.32 
5(+) 50.21 29.21 
Table 1 Token distribution of CCorpus and WCorpus 
 
Stats. Characters Words 
#UT 9.7K 88.1K 
#UTP 15.8M 24.2M 
Table 2 #UT and #UTP in CCorpus and WCorpus 
 
mentation errors. For example, ??? (Cheney)? 
and ?? (will)? are wrongly merged into one word 
???  by the word segmenter, and ??? 
wrongly aligns to a comma in English sentence in 
the word alignment; However, both ? and ? align 
to ?Cheney? correctly in the character alignment. 
However, this kind of errors cannot be fixed by 
methods which learn new words by packing already 
segmented words, such as word packing (Ma et al, 
2007) and Pseudo-word (Duan et al, 2010). 
As character could preserve more meanings than 
word in Chinese, it seems that a character can be 
wrongly aligned to many English words by the 
aligner. However, we found this can be avoided to a 
great extent by the basic features (co-occurrence 
and distortion) used by many alignment models. For 
example, we observed that the four characters of the 
non-compositional word ????? (Arafat)? align 
to Arafat correctly, although these characters pre-
serve different meanings from that of Arafat. This 
can be attributed to the frequent co-occurrence (192 
times) of these characters and Arafat in CCorpus. 
Moreover,?  usually means France in Chinese, 
thus it may co-occur very often with France in 
CCorpus. If both France and Arafat appear in the 
English sentence, ? may wrongly align to France. 
However, if ? aligns to Arafat, ? will probably 
align to Arafat, because aligning ? to Arafat could 
result in a lower distortion cost than aligning it to 
France. 
Different from alignment, translation is a pattern 
matching procedure (Lopez, 2008). WSR deter-
mines how the translation rules would be matched 
by the source sentences. For example, if we use 
translation rules with character as WSR to translate 
name entities such as the non-compositional word 
????, i.e. translating literally, we may get a 
wrong translation. That?s because the linguistic 
286
knowledge that the four characters convey a spe-
cific meaning different from the characters has been 
lost, which cannot always be totally recovered even 
by using phrase in phrase-based SMT systems (see 
Chang et al (2008) for detail). Duan et al (2010) 
and Paul et al, (2010) further pointed out that 
coarser-grained segmentation of the source sen-
tence do help capture more contexts in translation. 
Therefore, rather than using character, using 
coarser-grained, at least as coarser as the conven-
tional word, as WSR is quite necessary. 
3 Converting Character Alignment to Word 
Alignment 
In order to use word as WSR, we employ the same 
method as Elming and Habash (2007)4 to convert 
the character alignment (CA) to its word-based 
version (CA?) for translation rule induction. The 
conversion is very intuitive: for every Eng-
lish-Chinese word pair ??, ?? in the sentence pair, 
we align ? to ? as a link in CA?, if and only if there 
is at least one Chinese character of ? aligns to ? in 
CA.  
Given two different segmentations A and B of the 
same sentence, it is easy to prove that if every word 
in A is finer-grained than the word of B at the cor-
responding position, the conversion is unambiguity 
(we omit the proof due to space limitation). As 
character is a finer-grained than its original word, 
character alignment can always be converted to 
alignment based on any word segmentation. 
Therefore, our approach can be naturally scaled to 
syntax-based system by converting character 
alignment to word alignment where the word seg-
mentation is consistent with the parsers. 
We compare CA with the conventional word 
alignment (WA) as follows: We hand-align some 
sentence pairs as the evaluation set based on char-
acters (ESChar), and converted it to the evaluation 
set based on word (ESWord) using the above con-
version method. It is worth noting that comparing 
CA and WA by evaluating CA on ESChar and 
evaluating WA on ESWord is meaningless, because 
the basic tokens in CA and WA are different. 
However, based on the conversion method, com-
paring CA with WA can be accomplished by evalu-
ating both CA? and WA on ESWord. 
                                                          
4 They used this conversion for word alignment combination 
only, no translation results were reported. 
4 Experiments 
4.1 Setup 
FBIS corpus (LDC2003E14) (210K sentence pairs) 
was used for small-scale task. A large bilingual 
corpus of our lab (1.9M sentence pairs) was used for 
large-scale task. The NIST?06 and NIST?08 test sets 
were used as the development set and test set re-
spectively. The Chinese portions of all these data 
were preprocessed by character segmenter (CHAR), 
ICTCLAS word segmenter 5  (ICT) and Stanford 
word segmenters with CTB  and PKU specifica-
tions6 respectively. The first 100 sentence pairs of 
the hand-aligned set in Haghighi et al (2009) were 
hand-aligned as ESChar, which is converted to 
three ESWords based on three segmentations re-
spectively. These ESWords were appended to 
training corpus with the corresponding word seg-
mentation for evaluation purpose. 
Both character and word alignment were per-
formed by GIZA++ (Och and Ney, 2003) enhanced 
with gdf heuristics to combine bidirectional align-
ments (Koehn et al, 2003). A 5-gram language 
model was trained from the Xinhua portion of 
Gigaword corpus. A phrase-based MT decoder 
similar to (Koehn et al, 2007) was used with the 
decoding weights optimized by MERT (Och, 2003). 
4.2 Evaluation 
We first evaluate the alignment quality. The method 
discussed in section 3 was used to compare char-
acter and word alignment. As can be seen from 
Table 3, the systems using character as WSA out-
performed the ones using word as WSA in both 
small-scale (row 3-5) and large-scale task (row 6-8) 
with all segmentations. This gain can be attributed 
to the small vocabulary size (sparsity) for character 
alignment. The observation is consistent with 
Koehn (2005) which claimed that there is a negative 
correlation between the vocabulary size and trans-
lation performance without explicitly distinguish-
ing WSA and WSR. 
We then evaluated the translation performance. 
The baselines are fully word-based MT systems 
(WordSys), i.e. using word as both WSA and WSR, 
and fully character-based systems (CharSys). Table  
 
                                                          
5 http://www.ictclas.org/ 
6 http://nlp.stanford.edu/software/segmenter.shtml 
287
  Word alignment Character alignment 
  P R F P R F 
S 
CTB 76.0 81.9 78.9 78.2 85.2 81.8 
PKU 76.1 82.0 79.0 78.0 86.1 81.9 
ICT 75.2 80.8 78.0 78.7 86.3 82.3 
L 
CTB 79.6 85.6 82.5 82.2 90.6 86.2 
PKU 80.0 85.4 82.6 81.3 89.5 85.2 
ICT 80.0 85.0 82.4 81.3 89.7 85.3 
Table 3 Alignment evaluation. Precision (P), recall (R), 
and F-score (F) with ? ? 0.5 (Fraser and Marcu, 2007) 
 
 WSA WSR CTB PKU ICT 
S word word 21.52 20.99 20.95char word 22.04 21.98 22.04
L word word 22.07 22.86 22.23 char word 23.41 23.51 23.05 
Table 4 Translation evaluation of WordSys and pro-
posed system using BLEU-SBP (Chiang et al, 2008) 
 
4 compares WordSys to our proposed system. Sig-
nificant testing was carried out using bootstrap 
re-sampling method proposed by Koehn (2004) 
with a 95% confidence level. We see that our pro-
posed systems outperformed WordSys in all seg-
mentation specifications settings. Table 5 lists the 
results of CharSys in small-scale task. In this setting, 
we gradually set the phrase length and the distortion 
limits of the phrase-based decoder (context size) to 
7, 9, 11 and 13, in order to remove the disadvantage 
of shorter context size of using character as WSR 
for fair comparison with WordSys as suggested by 
Duan et al (2010). Comparing Table 4 and 5, we 
see that all CharSys underperformed WordSys. This 
observation is consistent with Chang et al (2008) 
which claimed that using characters, even with 
large phrase length (up to 13 in our experiment) 
cannot always capture everything a Chinese word 
segmenter can do, and using word for translation is 
quite necessary. We also see that CharSys under-
performed our proposed systems, that?s because the 
harm of using character as WSR outweighed the 
benefit of using character as WSA, which indicated 
that word segmentation better for alignment is not 
necessarily better for translation, and vice versa. 
We finally compared our approaches to Ma et al 
(2007) and Ma and Way (2009), which proposed 
?packed word (PW)? and ?bilingual motivated 
word (BS)? respectively. Both methods iteratively 
learn word segmentation and alignment alterna-
tively, with the former starting from word-based 
corpus and the latter starting from characters-based 
corpus. Therefore, PW can be experimented on all 
segmentations. Table 6 lists their results in small- 
Context Size 7 9 11 13 
BLEU 20.90 21.19 20.89 21.09 
Table 5 Translation evaluation of CharSys. 
 
System WSA WSR CTB PKU ICT 
WordSys word word 21.52 20.99 20.95
Proposed char word 22.04 21.98 22.04
PW PW PW 21.24 21.24 21.19 
Char+PW char PW 22.46 21.87 21.97 
BS BS BS 19.76 
Char+BS char BS 20.19 
Table 6 Comparison with other works 
 
scale task, we see that both PW and BS underper-
formed our approach. This may be attributed to the 
low recall of the learned BS or PW in their ap-
proaches. BS underperformed both two baselines, 
one reason is that Ma and Way (2009) also em-
ployed word lattice decoding techniques (Dyer et al, 
2008) to tackle the low recall of BS, which was 
removed from our experiments for fair comparison. 
Interestingly, we found that using character as 
WSA and BS as WSR (Char+BS), a moderate gain 
(+0.43 point) was achieved compared with fully 
BS-based system; and using character as WSA and 
PW as WSR (Char+PW), significant gains were 
achieved compared with fully PW-based system, 
the result of CTB segmentation in this setting even 
outperformed our proposed approach (+0.42 point). 
This observation indicated that in our framework, 
better combinations of WSA and WSR can be found 
to achieve better translation performance. 
5 Conclusions and Future Work 
We proposed a SMT framework that uses character 
for alignment and word for translation, which im-
proved both alignment quality and translation per-
formance. We believe that in this framework, using 
other finer-grained segmentation, with fewer am-
biguities than character, would better parameterize 
the alignment models, while using other coars-
er-grained segmentation as WSR can help capture 
more linguistic knowledge than word to get better 
translation. We also believe that our approach, if 
integrated with combination techniques (Dyer et al, 
2008; Xi et al, 2011), can yield better results. 
 
Acknowledgments 
We thank ACL reviewers. This work is supported 
by the National Natural Science Foundation of 
China (No. 61003112), the National Fundamental 
Research Program of China (2010CB327903). 
288
References  
Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della 
Peitra, and Robert L. Mercer. 1993. The mathematics 
of statistical machine translation: parameter estima-
tion. Computational Linguistics, 19(2), pages 
263-311. 
Pi-Chuan Chang, Michel Galley, and Christopher D. 
Manning. 2008. Optimizing Chinese word segmenta-
tion for machine translation performance.  In Pro-
ceedings of third workshop on SMT, pages 224-232. 
David Chiang, Steve DeNeefe, Yee Seng Chan and 
Hwee Tou Ng. 2008. Decomposability of Translation 
Metrics for Improved Evaluation and Efficient Algo-
rithms. In Proceedings of Conference on Empirical 
Methods in Natural Language Processing, pages 
610-619. 
Tagyoung Chung and Daniel Gildea. 2009. Unsuper-
vised tokenization for machine translation. In Pro-
ceedings of Conference on Empirical Methods in 
Natural Language Processing, pages 718-726. 
Michael Collins. 1999. Head-driven statistical models 
for natural language parsing. Ph.D. thesis, University 
of Pennsylvania. 
Xiangyu  Duan, Min Zhang,  and  Haizhou Li. 2010. 
Pseudo-word for phrase-based machine translation. In 
Proceedings of the Association for Computational 
Linguistics, pages 148-156. 
Christopher Dyer, Smaranda Muresan, and Philip Resnik. 
2008. Generalizing word lattice translation. In Pro-
ceedings of the Association for Computational Lin-
guistics, pages 1012-1020. 
Jakob Elming and Nizar Habash. 2007. Combination of 
statistical word alignments based on multiple pre-
processing schemes. In Proceedings of the Associa-
tion for Computational Linguistics, pages 25-28. 
Alexander Fraser and Daniel Marcu. 2007. Squibs and 
Discussions: Measuring Word Alignment Quality for 
Statistical Machine Translation. In Computational 
Linguistics, 33(3), pages 293-303. 
Aria Haghighi, John Blitzer, John DeNero, and Dan 
Klein. 2009. Better word alignments with supervised 
ITG models. In Proceedings of the Association for 
Computational Linguistics, pages 923-931. 
Phillip Koehn, H. Hoang, A. Birch, C. Callison-Burch, 
M. Federico, N. Bertoldi, B. Cowan,W. Shen, C. 
Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin, E. 
Herbst. 2007. Moses: Open source toolkit for statis-
tical machine translation. In Proceedings of the Asso-
ciation for Computational Linguistics, pages 177-180.  
Philipp Koehn. 2004. Statistical significance tests for 
machine translation evaluation. In Proceedings of the 
Conference on Empirical Methods on Natural Lan-
guage Processing, pages 388-395. 
Philipp Koehn. 2005. Europarl: A parallel corpus for 
statistical machine translation. In Proceedings of the 
MT Summit. 
Adam David Lopez. 2008. Machine translation by pat-
tern matching. Ph.D. thesis, University of Maryland. 
Yanjun Ma, Nicolas Stroppa, and Andy Way. 2007. 
Bootstrapping word alignment via word packing. In 
Proceedings of the Association for Computational 
Linguistics, pages 304-311. 
Yanjun Ma and Andy Way. 2009. Bilingually motivated 
domain-adapted word segmentation for statistical 
machine translation. In Proceedings of the Conference 
of the European Chapter of the ACL, pages 549-557. 
Franz Josef Och. 2003. Minimum error rate training in 
statistical machine translation. In Proceedings of the 
Association for Computational Linguistics, pages 
440-447. 
Franz Josef Och and Hermann  Ney. 2003. A systematic 
comparison of various statistical alignment models. 
Computational Linguistics, 29(1), pages 19-51. 
Michael Paul, Andrew Finch and Eiichiro Sumita. 2010. 
Integration of multiple bilingually-learned segmenta-
tion schemes into statistical machine translation. In 
Proceedings of the Joint Fifth Workshop on Statistical 
Machine Translation and MetricsMATR, pages 
400-408. 
J?rg Tiedemann. 2009. Character-based PSMT for 
closely related languages. In Proceedings of the An-
nual Conference of the European Association for 
machine Translation, pages 12-19. 
David Vilar, Jan-T. Peter and Hermann Ney. 2007. Can 
we translate letters? In Proceedings of the Second 
Workshop on Statistical Machine Translation, pages 
33-39. 
Xinyan Xiao, Yang Liu, Young-Sook Hwang, Qun Liu 
and Shouxun Lin. 2010.  Joint tokenization and 
translation. In Proceedings of the 23rd International 
Conference on Computational Linguistics, pages 
1200-1208. 
Ning  Xi, Guangchao  Tang,  Boyuan  Li, and  Yinggong 
Zhao. 2011. Word alignment combination over mul-
tiple word segmentation. In Proceedings of the ACL 
2011 Student Session, pages 1-5. 
Ruiqiang Zhang, Keiji Yasuda, and Eiichiro Sumita. 
2008. Improved statistical machine translation by 
multiple Chinese word segmentation. In Proceedings 
289
of the Third Workshop on Statistical Machine Trans-
lation, pages 216-223. 
 
290
First Joint Conference on Lexical and Computational Semantics (*SEM), pages 519?523,
Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational Linguistics
NJU-Parser: Achievements on Semantic Dependency Parsing 
Guangchao Tang1 Bin Li1,2 Shuaishuai Xu1 Xinyu Dai1 Jiajun Chen1 
1 State Key Lab for Novel Software Technology, Nanjing University 
2 Research Center of Language and Informatics, Nanjing Normal University 
Nanjing, Jiangsu, China 
{tanggc, lib, xuss, dxy, chenjj}@nlp.nju.edu.cn 
 
Abstract 
In this paper, we introduce our work on 
SemEval-2012 task 5: Chinese Semantic De-
pendency Parsing. Our system is based on 
MSTParser and two effective methods are 
proposed: splitting sentence by punctuations 
and extracting last character of word as lemma. 
The experiments show that, with a combina-
tion of the two proposed methods, our system 
can improve LAS about one percent and final-
ly get the second prize out of nine participat-
ing systems. We also try to handle the multi-
level labels, but with no improvement. 
1 Introduction 
Task 5 of SemEval-2012 tries to find approaches to 
improve Chinese sematic dependency parsing 
(SDP). SDP is a kind of dependency parsing. Cur-
rently, there are many dependency parsers availa-
ble, such as Eisner?s probabilistic dependency 
parser (Eisner, 1996), McDonald?s MSTParser 
(McDonald et al 2005a; McDonald et al 2005b) 
and Nivre?s MaltParser (Nivre, 2006). 
Despite of elaborate models, lots of problems 
still exist in dependency parsing. For example, sen-
tence length has been proved to show great impact 
on the parsing performance. (Li et al, 2010) used a 
two-stage approach based on sentence fragment for 
high-order graph-based dependency parsing. Lack-
ing of linguistic knowledge is also blamed. 
Three methods are promoted in this paper try-
ing to improve the performance: splitting sentence 
by commas and semicolons, extracting last charac-
ter of word as lemma and handling multi-level la-
bels. Improvements could be achieved through the 
first two methods while not for the third. 
2 Overview of Our System 
Our system is based on MSTParser which is one of 
the state-of-the-art parsers. MSTParser tries to ob-
tain the maximum spanning tree of a sentence. For 
projective parsing task, it takes Eisner?s algorithm 
(Eisner, 1996) to get the dependency tree in O(n3) 
time. Meanwhile, Chu-Liu-Edmond?s algorithm 
(Chu and Liu, 1965) is applied for non-projective 
task, which takes O(n2) time. 
Three methods are adopted to MSTParser in our 
system: 
1) Sentences are split into sub-sentences by 
commas and semicolons, for which there 
are two ways. Splitting sentences by all 
commas and semicolons is used in our 
primary system. In our contrast system, we 
use a classifier to determine whether a 
comma or semicolon can be used to split 
the sentence. In the primary and contrast 
system, the proto sentences and the sub-
sentences are trained and tested separately 
and the outputs are merged in the end. 
2) In a Chinese word, the last character usual-
ly contains main sense or semantic class. 
We treat the last character of the word as 
word lemma and find it gets a slightly im-
provement in the experiment. 
3) An experiment trying to solve the problem 
of multi-level labels was conducted by 
parsing different levels separately and con-
sequently merging the outputs together. 
The experiment results have shown that the first 
two methods could enhance the system perfor-
mance while further improvements could be ob-
tained through a combination of them in our sub-
submitted systems. 
519
 
a) The proto sentence from train data 
                       
b) The first sub sentence of a)                         c) The second sub sentence of a) 
Figure 1. An example of the split procedure. 
 
3 Experiments 
3.1 Split sentences by commas and semicolons 
It is observed that the performance decreases as 
the length of the sentences increases. Table 1 
shows the statistical analysis on the data including 
SemEval-2012, Conll-07?s Chinese corpus and a 
subset extracted from CTB using Penn2Malt. Long 
sentence can be split into sub-sentences to get bet-
ter parsing result.  
 
Items 
SemEval
-2012 
Conll-
07 CN 
CTB 
Postages count 35 13 33 
Dependency 
labels count 
122 69 12 
Average sentence 
length 
30.15 5.92 25.89 
Average 
dependency length 
4.80 1.71 4.36 
LAS 61.37 82.89 67.35 
UAS 80.18 87.64 79.90 
Table 1. Statistical analysis on the data. The CTB data is 
a subset extracted from CTB using Penn2Malt. 
 
Our work can be described as following steps: 
Step 1: Use MSTParser to parse the data. We 
name the result as ?normal output?. 
Step 2: Split train and test data by all commas 
and semicolons. The delimiters are removed in the 
sub sentences. For train data, a word?s dependency 
relation is kept if the word?s head is under the cov-
er of the sub sentence. Otherwise, its head will be 
set to root and its label will be set to ROOT (ROOT 
is the default label of dependency arcs whose head 
is root). We define the word as ?sentence head? if 
its head is root. ?Sub-sentence head? indicates the 
sentence head of a sub-sentence. After splitting, 
there may be more than one sub-sentence heads in 
a sub-sentence. Figure 1 shows an example of the 
split procedure. 
Step 3: Use MSTParser to parse the data gener-
ated in step 2. We name the parsing result ?split 
output?. In split output, there may be more than 
one sub-sentences corresponding to a single sen-
tence in normal output. 
Step 4: Merge the split output and the normal 
output. The outputs of sub-sentences are merged 
with delimiters restored. Dependency relations are 
recovered for all punctuations and sub-sentence 
heads in split output with relations in normal out-
put. The sentence head of normal output is kept in 
final output. The result is called ?merged split out-
put?. This step need to be consummated because it 
may result in a dependency tree not well formed 
with several sentence heads or even circles. 
The results of experiments on develop data and 
test data are showed in table 2. For develop data, 
an improvement of 0.85 could be obtained while 
0.93 for test data, both on LAS. 
In step 2, there is an alternative to split the sen-
tences, i.e., using a classifier to determine which 
comma and semicolon can be split. This method is 
taken in the contrast system. When applying the 
classifier, all commas and semicolons in train data 
520
are labeled with S-IN or S-STOP while other 
words with NULL. If the sub sentence before the 
comma or semicolon has only one sub-sentence 
head, it is labeled with S-STOP, otherwise with S-
IN. A model is built from train data with CRF++ 
and test data is evaluated with it. Features used are 
listed in table 3. Only commas and semicolons 
with label S-STOP can be used to split the sen-
tence in step 2. Other steps are the same as above. 
The result is also shown in table 2 as ?merged split 
output with CRF++?. 
 
Data Methods LAS UAS 
Develop 
data 
normal output 61.37 80.18 
merged split output 62.22 80.56 
merged split output 
with CRF++ 
61.97 80.73 
lemma output 61.64 80.47 
primary system output 62.41 80.96 
contrast system output 62.05 80.90 
Test 
 data 
normal output 60.63 79.37 
merged split output 61.56 80.17 
merged split output 
with CRF++ 
61.42 80.20 
lemma output 60.88 79.42 
primary system output 61.63 80.35 
contrast system output 61.64 80.29 
Table 2. Results of the experiments. 
 
w-4,w-3,w-2,w-1,w,w+1,w+2,w+3,w+4 
p-4,p-3,p-2,p-1,p,p+1,p+2,p+3,p+4 
wp-4,wp-3,wp-2,wp-1,wp wp+1,wp+2,wp+3,wp+4 
w-4|w-3,w-3|w-2,w-2|w-1,w-1|w, 
w|w+1,w+1|w+2,w+2|w+3,w+3|w+4 
p-4|p-3,p-3|p-2,p-2|p-1,p-1|p, 
p|p+1,p+1|p+2,p+2|p+3,p+3|p+4 
first word of sub-sentence before the delimiter 
Table 3. Features used in CRF++. w represents for word 
and p for PosTag. +1 means the index after current 
while -1 means before. 
3.2 Extract last character of word as lemma 
In Chinese, the last character of a word usually 
contains main sense or semantic class, which indi-
cates that it may represent the whole word. For 
example, ? ? ?(country) can represent ? ?
? ?(China) and ?? ?(love) can represent ??
??(crazy love).  
The last character is used as lemma in the ex-
periment, with an improvement of 0.27 for LAS on 
develop data and 0.24 on test data. Details of the 
scores are listed in table 2 as ?lemma output?. 
3.3 Multi-level labels experiment 
A notable characteristic of SemEval-2012?s da-
ta is multi-level labels. It introduces four kinds of 
multi-level labels which are s-X, d-X, j-X and r-X. 
The first level represents the basic semantic rela-
tion of the dependency while the second level 
shows the second import, except that s-X repre-
sents sub-sentence relation.  
The r-X label means that a verb modifies a 
noun and the relation between them is reverse. For 
example, in phrase ???(poor) ??(born) ? ?
?(star)?, ???? is headed to ???? with label r-
agent. It means that ???? is the agent of ????. 
When a verbal noun is the head word and its 
child has indirect relation to it, the dependency is 
labeled with j-X. In phrase ???(school) ??
(construction)?, ???? is the head of ???? with 
label j-content. ???? is the content of ????. 
The d-X label means that the child modifies the 
head with an additional relation. For example, in 
phrase ???(technology) ??(enterprise)?, ??
?? modifies ???? and the domain of ???? is 
????. 
A heuristic method is tried in the experiment. 
The multi-level labels of d-X, j-X and r-X are sep-
arated into two parts for each level. For example, 
?d-content? will be separated to ?d? and ?content?. 
For each part, MSTParser is used to train and test. 
We call the outputs ?first-level output? and ?se-
cond-level output?. The outputs of each level and 
normal output are merged then. 
In our experiments, only the word satisfies the 
following conditions need to be merged: 
a) The dependency label in normal output is 
started with d-, j- or r-. 
b) The dependency label in first-level output is 
d, j or r. 
c) The heads in first-level output and second-
level output are of the same. 
Otherwise, the dependency relation in normal 
output will be kept. There are also three ways in 
merging outputs: 
a) Label in first-level output and label in se-
cond-level output are merged. 
b) First level label in normal output and label 
in second-level output are merged. 
c) Label in first-level output and second level 
label in normal output are merged. 
521
Experiment has been done on develop data. In 
the experiment, 24% of the labels are merged and 
92% of the new merged labels are the same as 
original. The results of three ways are listed in ta-
ble 4. All of them get decline compared to normal 
output. 
 
outputs LAS UAS 
normal output 61.37 80.18 
way a) 61.18 80.18 
way b) 61.25 80.18 
way c) 61.25 80.18 
Table 4. Results of multi-level labels experiment on 
develop data. 
3.4 Combined experiment on split and lemma 
Improvements are achieved by first two meth-
ods in the experiment while a further enhancement 
is made with a combination of them in the submit-
ted systems. The split method and lemma method 
are combined as primary system. The split method 
with CRF++ and lemma method are combined as 
contrast system. When combining the two methods, 
last character of the word is firstly extracted as 
lemma for train data and test data. Then the split or 
split with CRF++ method is used. 
The outputs of the primary system and contrast 
system are listed in table 2.  
4 Analysis and Discussion 
The contrast system presented in this paper finally 
got the second prize among nine systems. The pri-
mary system gets the third. There is an improve-
ment of about one percent for both primary and 
contrast system. The following conclusions can be 
made from the experiments: 
1) Parsing is more effective and accurate on 
short sentences. A word prefers to depend 
on another near to it. A sentence can be 
split to several sub sentences by commas 
and semicolons to get better parsing output. 
Result may be improved with a classifier to 
determine whether a comma or semicolon 
can be used to split the sentence. 
2) Last character of word is a useful feature. 
In the experiment, the last character is 
coarsely used as lemma and a minor im-
provement is achieved. Much more lan-
guage knowledge can be used in parsing. 
3) The label set of the data is worthy to be re-
viewed. The meanings of the labels are not 
given in the task. Some of them are confus-
ing especially the multi-level labels. The 
trying of training and testing multi-level la-
bels separately by levels fails with a slight-
ly decline of the score. Multi-level also 
causes too many labels: any single-level la-
bel can be prefixed to form a new multi-
level label. It?s a great problem for current 
parsers. Whether the label set is suitable to 
Chinese semantic dependency parsing 
should be discussed. 
5 Conclusion and Future Work 
Three methods applied in NJU-Parser are de-
scribed in this paper: splitting sentences by com-
mas and semicolons, taking last character of word 
as lemma and handling multi-level labels. The first 
two get improvements in the experiments. Our 
primary system is a combination of the first two 
methods. The contrast system is the same as prima-
ry system except that it has a classifier implement-
ed in CRF++ to determine whether a comma or a 
semicolon should be used to split the sentence. 
Both of the systems get improvements for about 
one percent on LAS. 
In the future, a better classifier should be devel-
oped to split the sentence. New method should be 
applied in merging split outputs to get a well 
formed dependency tree. And we hope there will 
be a better label set which are more capable of de-
scribing semantic dependency relations for Chi-
nese. 
Acknowledgments 
This paper is supported in part by National Natural 
Science Fund of China under contract 61170181, 
Natural Science Fund of Jiangsu under contract 
BK2011192, and National Social Science Fund of 
China under contract 10CYY021. 
References 
Y.J. Chu and T.H. Liu. 1965. On the shortest arbores-
cence of a directed graph. Science Sinica, 14:1396?
1400. 
MSTParser: 
http://www.seas.upenn.edu/~strctlrn/MSTParser/MS
TParser.html 
522
J. Eisner. 1996. Three new probabilistic models for de-
pendency parsing: An exploration. In Proc. COLING. 
J. Nivre. 2006. Inductive Dependency Parsing. Springer. 
R. McDonald, K. Crammer, and F. Pereira. 2005. 
Online Large-Margin Training of Dependency 
Parsers. 43rd Annual Meeting of the Association for 
Computational Linguistics (ACL 2005). 
R. McDonald, F. Pereira, K. Ribarov, and J. Haji?. 2005. 
Non-projective Dependency Parsing using Spanning 
Tree Algorithms. Proceedings of HLT/EMNLP 2005. 
Zhenghua Li, Wanxiang Che, Ting Liu. 2010. Improv-
ing Dependency Parsing Using Punctuation. Interna-
tional Conference on Asian Language 
Processing(IALP) 2010. 
523
