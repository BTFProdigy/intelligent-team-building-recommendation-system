Proceedings of the NAACL HLT Workshop on Innovative Use of NLP for Building Educational Applications, pages 55?63,
Boulder, Colorado, June 2009. c?2009 Association for Computational Linguistics
KSC-PaL: A Peer Learning Agent that Encourages Students to take the
Initiative?
Cynthia Kersey and Barbara Di Eugenio
Department of Computer Science
University of Illinois at Chicago
Chicago, IL 60607 USA
ckerse2@uic.edu
bdieugen@cs.uic.edu
Pamela Jordan and Sandra Katz
Learning Research and Development Center
University of Pittsburgh
Pittsburgh, PA 15260 USA
pjordan+@pitt.edu
katz+@pitt.edu
Abstract
We present an innovative application of dis-
course processing concepts to educational
technology. In our corpus analysis of peer
learning dialogues, we found that initiative
and initiative shifts are indicative of learn-
ing, and of learning-conducive episodes. We
are incorporating this finding in KSC-PaL, the
peer learning agent we have been developing.
KSC-PaL will promote learning by encourag-
ing shifts in task initiative.
1 Introduction
Collaboration in dialogue has long been researched
in computational linguistics (Chu-Carroll and Car-
berry, 1998; Constantino-Gonza?lez and Suthers,
2000; Jordan and Di Eugenio, 1997; Lochbaum and
Sidner, 1990; Soller, 2004; Vizca??no, 2005), how-
ever, the study of peer learning from a computa-
tional perspective is still in the early stages. This
is an important area of study because peer learning
has been shown to be an effective mode of learn-
ing, potentially for all of the participants (Cohen et
al., 1982; Brown and Palincsar, 1989; Birtz et al,
1989; Rekrut, 1992). Additionally, while there has
been a focus on using natural language for intelli-
gent tutoring systems (Evens et al, 1997; Graesser
et al, 2004; VanLehn et al, 2002), peer to peer in-
teractions are notably different from those of expert-
novice pairings, especially with respect to the rich-
ness of the problem-solving deliberations and ne-
gotiations. Using natural language in collaborative
?This work is funded by NSF grants 0536968 and 0536959.
learning could have a profound impact on the way
in which educational applications engage students in
learning.
Previous research has suggested several mecha-
nisms that explain why peer learning is effective for
all participants. Among them are: self-directed ex-
plaining(Chi et al, 1994), other-directed explaining
(Ploetzner et al, 1999; Roscoe and Chi, 2007) and
Knowledge Co-construction ? KCC for short (Haus-
mann et al, 2004). KCC episodes are defined as
portions of the dialogue in which students are jointly
constructing a shared meaning of a concept required
for problem solving. This last mechanism is the
most interesting from a peer learning perspective be-
cause it is a truly collaborative construct and also be-
cause it is consistent with the widely accepted con-
structivist view of learning.
Since KCC is a high-level concept that is not eas-
ily recognized by an artificial agent we collected
peer learning interactions from students and stud-
ied them to identify features that might be useful in
identifying KCC. We found that linguistically based
initiative shifts seem to capture the notion of col-
laborative construction. A more thorough analysis
found a strong relationship between KCC and initia-
tive shifts and moderate correlations between initia-
tive shifts and learning.
The results of this analysis are being incorporated
into KSC-PaL, an artificial agent that can collaborate
with a human student via natural-language dialogue
and actions within a graphical workspace. KSC-PaL
has been developed in the last two years. Dialogue-
wise, its core is TuTalk (Jordan et al, 2007), a dia-
logue management system that supports natural lan-
55
guage dialogue in educational applications. As we
will describe, we have already developed its user
interface and its student model and have extended
TuTalk?s planner to provide KSC-PaL with the abil-
ity to induce initiative shifts. For the version of
KSCPal we will present in this paper, we wanted to
focus on the question of whether this style of inter-
action helps learning; and we were concerned that
its limitations in disambiguating the student?s input
could impact this interaction. Hence, this round of
experiments employs a human ?helper? that is given
a list of concepts the input may match, and chooses
the most appropriate one.
The work presented in this paper is part of a larger
research program: we analyze different paradigms ?
tutoring dialogues and peer-learning dialogues? in
the same basic domain, devise computational mod-
els for both, and implement them in two separate
SW systems, an ITS and the peer-learning system
we present here. For our work on the tutoring dia-
logue corpus and the ITS please see (Fossati et al,
accepted for publication 2009).
Our domain in both cases is problem solving in
basic data structure and algorithms, which is part of
foundations of Computer Science. While in recent
years, interest in CS in the US has dropped dramat-
ically, CS is of enormous strategic interest, and is
projected to foster vast job growth in the next few
years (AA. VV., 2006). We believe that by support-
ing CS education in its core we can have the largest
impact on reversing the trend of students? disinter-
est. Our belief is grounded in the observation that
the rate of attrition is highest at the earliest phases
of undergraduate CS curricula. This is due in part
to students? difficulty with mastering basic concepts
(Katz et al, 2003), which require a deep understand-
ing of static structures and the dynamic procedures
used to manipulate them (AA. VV., 2001). These
concepts also require the ability to move seamlessly
among multiple representations, such as text, pic-
tures, pseudo-code, and real code in a specific pro-
gramming language.
Surprisingly, few educational SW systems ad-
dress CS topics, e.g. teaching a specific program-
ming language like LISP (Corbett and Anderson,
1990) or database concepts (Mitrovic? et al, 2004).
Additionally, basically they are all ITSs, where the
relationship between the system and the student
is one of ?subordination?. Only two or three of
these ITSs address foundations, including: Autotu-
tor (Graesser et al, 2004) addresses basic literacy,
but not data structures or algorithms; ADIS (Waren-
dorf and Tan, 1997) tutors on basic data structures,
but its emphasis is on visualization, and it appears to
have been more of a proof of concept than a work-
ing system; ProPL (Lane and VanLehn, 2003) helps
novices design their programs, by stressing problem
solving and design skills.
In this paper, we will first discuss the collection
and analysis of peer learning interactions. Then, we
discuss the design of our peer agent, and how it is
guided by the results of our analysis. We conclude
by briefly describing the user experiments we are
about to undertake, and whose preliminary results
will be available at the time of the workshop.
2 Data collection
We have collected peer learning interactions from 15
pairs of students solving problems in the domain of
computer science data structures. Students were re-
cruited from introductory courses on data structures
and algorithms. Each problem involved one of three
types of data structures: linked-lists, stacks and bi-
nary search trees. Each problem was either a debug-
ging problem where the students were asked to work
together to identify errors in the code or an explana-
tion problems in which the students jointly created
an explanation of a segment of code.
The students interacted using a computer me-
diated interface1 where they could communicate
via text-based chat, drawing and making changes
to code (see Figure 1). The graphical workspace
(drawing and coding areas) was shared such that
changes made by one student were propagated to
his/her partner?s workspace. Access to this graph-
ical workspace was controlled so that only one stu-
dent was allowed to draw or make changes to code
at any point in time.
Each pair was presented with a total of 5 prob-
lems, although not all pairs completed all prob-
lems due to time limitations. The interactions for
each pair were subdivided into separate dialogues
1Using text to communicate versus face-to-face interactions
should be comfortable for most students given the prevalence
of communication methods such as text messaging and instant
messengers.
56
Figure 1: The data collection / KSC-PaL interface
for each problem. Thus, we collected a corpus con-
sisting of a total of 73 dialogues.
In addition to collecting problem solving data,
we also presented each student with a pre-test prior
to problem solving and an identical post-test at the
conclusion of problem solving in order to measure
learning gains. A paired t-test of pre- and post-test
scores showed that students did learn during collab-
orative problem solving (t(30)=2.83; p=0.007). The
interactions produced an average normalized learn-
ing gain of 17.5 (possible total points are 50).
3 Analysis of Peer Learning Interactions
Next, we undertook an extensive analysis of the cor-
pus of peer learning interactions in order to deter-
mine the behaviors with which to endow KSC-PaL.
3.1 Initiative: Annotation
Given the definition of KCC, it appeared to us that
the concept of initiative from discourse and dialogue
processing should play a role: intuitively, if the stu-
dents are jointly contructing a concept, the initiative
cannot reside only with one, otherwise the partner
would just be passive. Hence, we annotated the dia-
logues for both KCC and initiative.
The KCC annotation involved coding the dia-
logues for KCC episodes. These are defined as a
series of utterances and graphical actions in which
students are jointly constructing a shared meaning of
a concept required for problem solving (Hausmann
et al, 2004). Using this definition, an outside anno-
tator and one of the authors coded 30 dialogues (ap-
proximately 46% of the corpus) for KCC episodes.
This entailed marking the beginning utterance and
the end utterance of such episodes, under the as-
sumption that all intervening utterances do belong to
the same KCC episode (otherwise the coder would
mark an earlier end for the episode). The result-
ing intercoder reliability, measured with the Kappa
statistic(Carletta, 1996), is considered excellent (? =
0.80).
Our annotation of initiative was two fold. Since
there is disagreement in the computational lin-
guistics community as to the precise definition of
57
initiative(Chu-Carroll and Carberry, 1998; Jordan
and Di Eugenio, 1997), we annotated the dialogues
for both dialogue initiative, which tracks who is
leading the conversation and determining the cur-
rent conversational focus, and task initiative, which
tracks the lead in problem solving.
For dialogue initiative annotation, we used the
well-known utterance-based rules for allocation of
control from (Walker and Whittaker, 1990). In
this scheme, each utterance is tagged with one of
four dialogue acts (assertion, command, question or
prompt) and control is then allocated based on a set
of rules. The dialogue act annotation was done au-
tomatically, by marking turns that end in a question
mark as questions, those that start with a verb as
commands, prompts from a list of commonly used
prompts (e.g. ok, yeah) and the remaining turns as
assertions. To verify that the automatic annotation
was good, we manually annotated a sizable portion
of the dialogues with those four dialogue acts. We
then compared the automatic annotation against the
human gold standard, and we found an excellent ac-
curacy: it ranged from 86% for assertions and ques-
tions, to 97% for prompts, to 100% for commands.
Once the dialogue acts had been automatically an-
notated, two coders, one of the authors and an out-
side annotator, coded 24 dialogues (1449 utterances,
approximately 45% of the corpus) for dialogue ini-
tiative, by using the four control rules from (Walker
and Whittaker, 1990):
1. Assertion: Control is allocated to the speaker
unless it is a response to a question.
2. Command: Control is allocated to the speaker.
3. Question: Control is allocated to the speaker,
unless it is a response to a question or a com-
mand.
4. Prompt: Control is allocated to the hearer.
The resulting intercoder reliability on dialogue ini-
tiative was 0.77, a quite acceptable level of agree-
ment. We then experimented with automatically an-
notating dialogue initiative according to those con-
trol rules. Since the accuracy against the gold stan-
dard was 82%, the remaining 55% of the corpus was
also automatically annotated for dialogue initiative,
using those four control rules.
As concerns task initiative, we define it as any ac-
tion by a participant to either achieve a goal directly,
decompose a goal or reformulate a goal (Guinn,
1998; Chu-Carroll and Brown, 1998). Actions in
our domain that show task initiative include:
? Explaining what a section of code does.
? Identifying that a section of code as correct or
incorrect.
? Suggesting a correction to a section of code
? Making a correction to a section of code prior
to discussion with the other participant.
The same two coders annotated for task initiative
the same portion of the corpus already annotated for
dialogue initiative. The resulting intercoder reliabil-
ity for task initiative is 0.68, which is high enough
to support tentative conclusions. The outside coder
then manually coded the remaining 55% of the cor-
pus for task initiative.
3.2 KCC, initiative and learning
In analyzing the annotated dialogues, we used mul-
tiple linear regression to identify correlations of the
annotated features and post-test score. We used pre-
test score as a covariate because of its significant
positive correlations with post-test score. Due to
variations in student ability in the different problem
types, our analysis focused only on a portion of the
collected interactions. In the tree problem there was
a wide variation in experience level of the students
which would inhibit KCC. In the stack problem, the
students had a better understanding of stacks prior
to problem solving and spent less time in discussion
and problem solving. Thus, our analysis focused
only on the linked-list problems.
We started by analyzing the relationship between
KCC and learning. As a measurement of KCC we
used KCC actions which is the number of utter-
ances and graphical actions that occur during KCC
episodes. This analysis showed that KCC does have
a positive correlation with learning in our corpus. In
Table 1, the first row shows the benefit for the dyad
overall by correlating the mean post-test score with
the mean pre-test score and the dyad?s KCC actions.
The second row shows the benefit for individuals by
58
correlating individual post-test scores with individ-
ual pre-test scores and the dyad?s KCC actions. The
difference in the strength of these correlations sug-
gests that members of the dyads are not benefitting
equally from KCC. If the subjects are divided into
two groups, those with a pre-test score below the
mean score ( n=14) and those with a pre-test score
above the mean score ( n=16) , it can be seen that
those with a low pre-test score benefit more from
the KCC episodes than do those with a high pre-test
score (rows 3 and 4 in Table 1).
KCC actions predict ? R2 p
Mean post-test score 0.43 0.14 0.02
Individual post-test score 0.33 0.08 0.03
Individual post-test score 0.61 0.37 0.03
(low pre-test subjects)
Individual post-test score 0.33 0.09 ns
(high pre-test subjects)
Table 1: KCC Actions as Predictor of Post-test Score
Next, we explored the relationship between learn-
ing and the number of times initiative shifted be-
tween the students. Intuitively, we assumed that fre-
quent shifts of initiative would reflect students work-
ing together to solve the problem. We found there
was a significant correlation between post-test score
(after removing the effects of pre-test scores) and the
number of shifts in dialogue initiative and the num-
ber of shifts in task initiative (see Table 2). This
analysis excluded two dyads whose problem solving
collaboration had gone awry.
Predictor of Post-test ? R2 p
Dialogue initiative shifts 0.45 0.20 0.00
Task initiative shifts 0.42 0.20 0.01
Table 2: Initiative Predictors of Post-test Score
We then computed a second measure of KCC that
is meant to reflect the density of the KCC episodes.
KCC initiative shifts is the number of task initiative
shifts that occur during KCC episodes. Many task
initiative shifts reflect more active KCC.
Table 3 uses KCC initiative shifts as the measure
of co-construction. It shows similar results to ta-
ble 1, where KCC actions was used. Note that when
the outlier dyads were removed the correlation with
learning is much stronger for the low pre-test score
subjects when KCC initiative shifts are used as the
measure of KCC (R2 = 0.45, p = 0.02) than when
KCC actions are used.
KCC initiative shifts predict ? R2 p
Mean post-test score 0.46 0.15 0.01
Individual post-test score 0.35 0.09 0.02
Individual post-test score 0.67 0.45 0.02
(low pre-test subjects)
Individual post-test score 0.10 0.01 ns
(high pre-test subjects)
Table 3: KCC Initiative Shifts Predictors of Post-test
Score
Lastly we investigated the hypothesis that KCC
episodes involve frequent shifts in initiative, as both
participants are actively participating in problem
solving. To test this hypothesis, we calculated
the average initiative shifts per line during KCC
episodes and the average initiative shifts per line
during problem solving outside of KCC episodes for
each dyad. A paired t-test was then used to verify
that there is a difference between the two groups.
The t-test showed no significant difference in aver-
age dialogue initiative shifts in KCC episodes com-
pared with non-KCC problem solving. However,
there is a significant difference between average task
initiative shifts in KCC episodes compared with the
rest of the dialogue ( t(57) = 3.32, p = 0.0016). The
effect difference between the two groups (effect size
= 0.65 ) shows that there is a meaningful increase in
the number of task initiative shifts in KCC episodes
compared with problem solving activity outside of
the KCC episodes.
3.3 Indicators of task initiative shifts
Since our results show that task initiative shifts are
conducive to learning, we want to endow our soft-
ware agent with the ability to encourage a shift in
initiative from the agent to the student, when the
student is overly passive. The question is, what are
natural indicators in dialogue that the partner should
take the initiative? We explored two different meth-
ods for encouraging initiative shifts. One is that stu-
dent uncertainty may lead to a shift in initiative. The
other consists of cues for initiative shifts identified
59
in related literature(Chu-Carroll and Brown, 1998;
Walker and Whittaker, 1990).
Intuitively, uncertainty by a peer might lead to his
partner taking the initiative. One possible identi-
fier of student uncertainty is hedging. To validate
this hypothesis, we annotated utterances in the cor-
pus with hedging categories as identified in (Bhatt
et al, 2004). Using these categories we were unable
to reliably annotate for hedging. But, after collaps-
ing the categories into a single binary value of hedg-
ing/not hedging we arrived at an acceptable agree-
ment (? = 0.71).
Another identifier of uncertainty is a student?s re-
quest for feedback from his partner. When uncertain
of his contribution, a student may request an evalua-
tion from his peer. So, we annotated utterances with
?request for feedback? and were able to arrive at an
excellent level of intercoder reliability (? = 0.82).
(Chu-Carroll and Brown, 1998) identifies cues
that may contribute to the shift of task and dialogue
initiative. Since task initiative shifts appear to iden-
tify KCC episodes, we chose to explore the follow-
ing cues that potentially result in the shift of task
initiative.
? Give up task. These are utterances where
the student explicitly gives up the task using
phrases like ?Any other ideas??.
? Pause. A pause may suggest that the speaker
has nothing more to say in the current turn and
intends to give up his initiative.
? Prompts. A prompt is an utterance that has no
propositional content.
? Invalid statements. These are incorrect state-
ments made by a student.
Using hedging, request for feedback and initia-
tive cues, we were able to identify 283 shifts in task
initiative or approximately 67% of all task initiative
shifts in the corpus. The remaining shifts were likely
an explicit take over of initiative without a preceding
predictor.
Since we found several possible ways to predict
and encourage initiative shifts, the next step was to
identify which of these predictors more often re-
sulted in an initiative shift; and, for which predic-
tors the resulting initiative shift more often led to an
increase in the student?s knowledge level. Table 4
shows the percentage of instances of each predictor
that resulted in an initiative shift.
Percent of instances that
Cue/Identifier led to initiative shift
Hedge 23.94%
Request feedback 21.88%
Give-up task 20.00%
Pause 25.27%
Prompt 29.29%
Invalid statement 38.64%
Table 4: Cues for Shifts in Initiative
Along with the likelihood of a predictor leading
to an initiative shift, we also examined the impact
of a shift of task initiative on a student?s level of
knowledge, measured using knowledge score, cal-
culated on the basis of the student model (see Sec-
tion 4). This is an important characteristic since we
want to encourage initiative shifts in an effort to in-
crease learning. First, we analyzed initiative shifts
to determine if they resulted in an increase in knowl-
edge score. We found that in our corpus, an initiative
shift leads to an increase in a student?s knowledge
level in 37.0% of task initiative shifts, a decrease
in knowledge level in 5.2% of shifts and unchanged
in 57.8% of shifts. Even though over one-half of
the time knowledge scores were not impacted, in
only a small minority of instances did a shift have
a negative impact on a student?s level of knowledge.
Therefore, we more closely examined the predictors
to see which more frequently led to an increase in
student knowledge. The results of that analysis is
show in table 5.
Percent of shifts where
Predictor knowledge level increased
Hedge 23.52%
Request feedback 17.65%
Give-up task 0.00%
Prompt 32.93%
Pause 14.22%
Invalid statement 23.53%
Table 5: Task Initiative Shifts/Knowledge Level Change
60
4 KSC-PaL, a software peer
Our peer-learning agent, KSC-PaL, has at its core
the TuTalk System(Jordan et al, 2007), a dialogue
management system that supports natural language
dialogue in educational applications. Since TuTalk
does not include an interface or a student model, we
developed both in previous years. We also needed to
extend the TuTalk planner to recognize and promote
initiative shifts.
The user interface is structured similarly to the
one used in data collection(see Figure 1). How-
ever, we added additional features to allow a stu-
dent to effectively communicate with the KSC-PaL.
First, all drawing and coding actions of the student
are interpreted and passed to the agent as a natural
language utterance. Graphical actions are matched
to a set of known actions and when a student sig-
nals that he/she has finished drawing or coding ei-
ther by ceding control of the graphical workspace or
by starting to communicate through typed text, the
interface will attempt to match what the student has
drawn or coded with its database of known graphi-
cal actions. These graphical actions include not only
correct ones but also anticipated misconceptions that
were collected from the data collection interactions.
The second enhancement to the interface is a spell
corrector for ?chat slang?. We found in the corpus,
that students often used abbreviations that are com-
mon to text messaging. These abbreviations are not
recognized by the English language spell corrector
in the TuTalk system, so a chat slang interpretation
module was added.
KSC-PaL requires a student model to track the
current state of problem solving as well as esti-
mate the student?s knowledge of concepts involved
in solving the problem in order to guide its behav-
ior. Our student model incorporates problem solu-
tion graphs (Conati et al, 2002). Solution graphs
are Bayesian networks where each node represents
either an action required to solve the problem, a
concept required as part of problem solving or an
anticipated misconception. A user?s utterances and
actions are then matched to these nodes. A knowl-
edge score can be calculated at any point in time by
taking a sum of the probabilities of all nodes in the
graph, except the misconception nodes. The sum of
the probabilities of the misconception nodes are sub-
tracted from the total to arrive at a knowledge score.
This score is then normalized by dividing it by the
maximum possible knowledge score for the solution
graph.
4.1 KSC-PaL and initiative
Since our corpus study showed that the level of task
initiative can be used to identify when KCC and
potentially learning is occurring, we have endowed
KSC-PaL with behaviors to manipulate shifts in task
initiative in order to encourage KCC and learning.
This required three enhancements: first, the ability
to recognize the initiative holder in each utterance
or action; second, the ability to encourage the shift
of initiative from the agent to the student; and three,
extending the TuTalk planner so that it can process
task initiative shifts.
As concerns the first step, that the agent recog-
nize the initiative holder in each utterance or action,
we resorted to machine learning. Using the Weka
Toolkit(Witten and Frank, 2005), we explored var-
ious machine learning algorithms and feature sets
that could reliably identify the holder of task initia-
tive. We found that the relevant features of an ac-
tion in the graphical workspace were substantially
different from those of a natural language utterance.
Therefore, we trained and tested separate classifiers
for each type of student action. After examining a
wide variety of machine learning algorithms we se-
lected the following two classifiers: (1) K* (Cleary
and Trigg, 1995), a clustering algorithm, for clas-
sifying natural language utterances which correctly
classified 71.7699% of utterance and (2) JRip (Co-
hen, 1995), a rule-based algorithm, for classifying
drawing and coding actions which correctly classi-
fied 86.971% of the instances.
As concerns the second step, encouraging initia-
tive shifts so that the student assumes the task initia-
tive, we use the results of our analysis of the indica-
tors of task initiative shifts from Section 3.3. KSC-
PaL will use prompts, request feedback and make
invalid statements in order to encourage initiative
shifts and promote learning.
Finally, we augmented the TuTalk planner so that
it selects scripts to manage task initiative shifts. Two
factors will determine whether a script that encour-
ages initiative shifts will be selected: the current
level of initiative shifts and the change in the stu-
61
dent?s knowledge score. Task initiative shifts will be
tracked using the classifier described above. Scripts
will be selected to encourage initiative shifts when
the average level of initiative shifts is less than the
mean initiative shifts in KCC episodes (calculated
from the corpus data) and the student?s knowledge
level has not increased since the last time a script
selection was requested. The scripts are based on
the analysis of methods for encouraging initiative
shifts described above. Specifically, KSC-PaL will
encourage initiative shifts by responding to student
input using prompts, requesting feedback from the
student and encouraging student criticism by inten-
tionally making errors in problem solving.
We are now poised to run user experiments. We
will run subjects in two conditions with KSC-PaL:
in the first condition (control), KSC-PaL will not en-
courage task initiative shifts and act more as a tutor;
in the second condition, KSC-PaL will encourage
task initiative shifts as we just discussed. One final
note: because we do not want our experiments to be
affected by the inability of the agent to interpret an
utterance, given current NLU technology, the inter-
face will ?incorporate? a human interpreter. The in-
terpreter will receive student utterances along with a
list of possible matching concepts from TuTalk. The
interpreter will select the most likely matching con-
cept, thus assisting TuTalk in natural language in-
terpretation. Note that the interpreter has a limited,
predetermined sets of choices, corresponding to the
concepts TuTalk knows about. In this way, his / her
intervention is circumscribed.
5 Conclusions
After an extensive analysis of peer-learning interac-
tions, we have found that task initiative shifts can
be used to determine when students are engaged
in knowledge co-construction. We have embed-
ded this finding in a peer-learning agent, KSC-PaL,
that varies its behavior to encourage initiative shifts
and knowledge co-construction in order to promote
learning. We are poised to run our user experiments,
and we will have preliminary results available by the
workshop time.
References
AA. VV. 2001. Computer Science, Final Report, The
Joint Task Force on Computing Curricula. IEEE Com-
puter Society and Association for Computing Machin-
ery, IEEE Computer Society.
AA. VV. 2006. US bureau of labor statistics
http://www.bls.gov/oco/oco20016.htm.
Khelan Bhatt, Martha Evens, and Shlomo Argamon.
2004. Hedged responses and expressions of affect in
human/human and human computer tutorial interac-
tions. In Proceedings Cognitive Science.
M. W. Birtz, J. Dixon, and T. F. McLaughlin. 1989. The
effects of peer tutoring on mathematics performance:
A recent review. B. C. Journal of Special Education,
13(1):17?33.
A. L. Brown and A. S. Palincsar, 1989. Guided, cooper-
ative learning and individual knowledge acquisition,
pages 307?226. Lawrence Erlbaum Associates, Hills-
dale, NJ.
Jean Carletta. 1996. Assessing agreement on classifi-
cation tasks: the kappa statistic. Comput. Linguist.,
22(2):249?254.
M.T.H. Chi, N. De Leeuw, M.H. Chiu, and C. LaVancher.
1994. Eliciting self-explanations improves under-
standing. Cognitive Science, 18(3):439?477.
Jennifer Chu-Carroll and Michael K. Brown. 1998. An
evidential model for tracking initiative in collabora-
tive dialogue interactions. User Modeling and User-
Adapted Interaction, 8(3?4):215?253, September.
Jennifer Chu-Carroll and Sandra Carberry. 1998. Col-
laborative response generation in planning dialogues.
Computational Linguistics, 24(3):355?400.
John G. Cleary and Leonard E. Trigg. 1995. K*: An
instance-based learner using an entropic distance mea-
sure. In Proc. of the 12th International Conference on
Machine Learning, pages 108?114.
P.A. Cohen, J.A. Kulik, and C.C. Kulik. 1982. Educa-
tion outcomes of tutoring: A meta-analysis of findings.
American Education Research Journal, 19(2):237?
248.
William W. Cohen. 1995. Fast effective rule induction.
In Machine Learning: Proceedings of the Twelve In-
ternational Conference.
Cristina Conati, Abigail Gertner, and Kurt Vanlehn.
2002. Using bayesian networks to manage uncer-
tainty in student modeling. User Modeling and User-
Adapted Interaction, 12(4):371?417.
Mar??a de los Angeles Constantino-Gonza?lez and
Daniel D. Suthers. 2000. A coached collaborative
learning environment for entity-relationship modeling.
Intelligent Tutoring Systems, pages 324?333.
Albert T. Corbett and John R. Anderson. 1990. The ef-
fect of feedback control on learning to program with
the LISP tutor. In Proceedings of the Twelfth Annual
Conference of the Cognitive Science Society, pages
796?803.
62
Martha W. Evens, Ru-Charn Chang, Yoon Hee Lee,
Leem Seop Shim, Chong Woo Woo, Yuemei Zhang,
Joel A. Michael, and Allen A. Rovick. 1997. Circsim-
tutor: an intelligent tutoring system using natural lan-
guage dialogue. In Proceedings of the fifth conference
on Applied natural language processing, pages 13?14,
San Francisco, CA, USA. Morgan Kaufmann Publish-
ers Inc.
Davide Fossati, Barbara Di Eugenio, Christopher Brown,
Stellan Ohlsson, David Cosejo, and Lin Chen. ac-
cepted for publication, 2009. Supporting Computer
Science curriculum: Exploring and learning linked
lists with iList. EEE Transactions on Learning Tech-
nologies, Special Issue on Real-World Applications of
Intelligent Tutoring Systems.
Arthur C. Graesser, Shulan Lu, George Tanner Jackson,
Heather Hite Mitchell, Mathew Ventura, Andrew Ol-
ney, and Max M. Louwerse. 2004. Autotutor: A tutor
with dialogue in natural language. Behavior Research
Methods, Instruments, & Computers, 36:180?192(13),
May.
Curry I. Guinn. 1998. An analysis of initiative selection
in collaborative task-oriented discourse. User Model-
ing and User-Adapted Interaction, 8(3-4):255?314.
Robert G.M. Hausmann, Michelene T.H. Chi, and Mar-
guerite Roy. 2004. Learning from collaborative prob-
lem solving: An analysis of three hypothesized mech-
anisms. In K.D Forbus, D. Gentner, and T. Regier, edi-
tors, 26th Annual Conference of the Cognitive Science
Society, pages 547?552, Mahwah, NJ.
Pamela W. Jordan and Barbara Di Eugenio. 1997. Con-
trol and initiative in collaborative problem solving di-
alogues. In Working Notes of the AAAI Spring Sympo-
sium on Computational Models for Mixed Initiative,
pages 81?84, Menlo Park, CA.
Pamela W Jordan, Brian Hall, Michael A. Ringenberg,
Yui Cue, and Carolyn Penstein Rose?. 2007. Tools for
authoring a dialogue agent that participates in learning
studies. In Artificial Intelligence in Education, AIED
2007, pages 43?50.
S. Katz, J. Aronis, D. Allbritton, C. Wilson, and M.L.
Soffa. 2003. Gender and race in predicting achieve-
ment in computer science. Technology and Society
Magazine, IEEE, 22(3):20?27.
H. Chad Lane and Kurt VanLehn. 2003. Coached pro-
gram planning: dialogue-based support for novice pro-
gram design. SIGCSE Bull., 35(1):148?152.
Karen E. Lochbaum and Candace L Sidner. 1990. Mod-
els of plans to support communication: An initial re-
port. In Proceedings of the Eighth National Confer-
ence on Artificial Intelligence, pages 485?490. AAAI
Press.
A. Mitrovic?, P. Suraweera, B. Martin, and A. Weeras-
inghe. 2004. DB-Suite: Experiences with Three In-
telligent, Web-Based Database Tutors. Journal of In-
teractive Learning Research, 15(4):409?433.
R. Ploetzner, P. Dillenbourg, M. Preier, and D. Traum.
1999. Learning by explaining to oneself and to others.
Collaborative learning: Cognitive and computational
approaches, pages 103?121.
M. D. Rekrut. 1992. Teaching to learn: Cross-age tutor-
ing to enhance strategy instruction. American Educa-
tion Research Association.
Rod D. Roscoe and Michelene T. H. Chi. 2007.
Understanding tutor learning: Knowledge-building
and knowledge-telling in peer tutors? explanations
and questions. Review of Educational Research,
77(4):534?574.
Amy Soller. 2004. Computational modeling and analysis
of knowledge sharing in collaborative distance learn-
ing. User Modeling and User-Adapted Interaction,
Volume 14(4):351?381, January.
Kurt VanLehn, Pamela W. Jordan, Carolyn Penstein
Rose?, Dumisizwe Bhembe, Michael Bo?ttner, Andy
Gaydos, Maxim Makatchev, Umarani Pappuswamy,
Michael A. Ringenberg, Antonio Roque, Stephanie
Siler, and Ramesh Srivastava. 2002. The architec-
ture of why2-atlas: A coach for qualitative physics es-
say writing. In ITS ?02: Proceedings of the 6th Inter-
national Conference on Intelligent Tutoring Systems,
pages 158?167, London, UK. Springer-Verlag.
Aurora Vizca??no. 2005. A simulated student can im-
prove collaborative learning. International Journal of
Artificial Intelligence in Education, 15(1):3?40.
Marilyn Walker and Steve Whittaker. 1990. Mixed ini-
tiative in dialogue: an investigation into discourse seg-
mentation. In Proceedings of the 28th annual meeting
on Association for Computational Linguistics, pages
70?78, Morristown, NJ, USA. Association for Com-
putational Linguistics.
Kai Warendorf and Colin Tan. 1997. Adis-an animated
data structure intelligent tutoring system or putting an
interactive tutor on the www. In Intelligent Educa-
tional Systems on the World Wide Web (Workshop Pro-
ceedings), at the Eight International Conference on
Artficial Intellignece in Education.
Ian H. Witten and Eibe Frank. 2005. Data Mining: Prac-
tical machine learning tools and techniques. Morgan
Kaufmann, San Francisco.
63
Proceedings of the NAACL HLT 2010: Demonstration Session, pages 17?20,
Los Angeles, California, June 2010. c?2010 Association for Computational Linguistics
KSC-PaL: A Peer Learning Agent that Encourages Students to take the
Initiative?
Cynthia Kersey
Lewis University
Romeoville, IL 60446 USA
kerseycy@lewisu.edu
Barbara Di Eugenio
University of Illinois at Chicago
Chicago, IL 60607 USA
bdieugen@cs.uic.edu
Pamela Jordan and Sandra Katz
University of Pittsburgh
Pittsburgh, PA 15260 USA
pjordan+@pitt.edu
katz+@pitt.edu
Abstract
We present an innovative application of dia-
logue processing concepts to educational tech-
nology. In a previous corpus analysis of peer
learning dialogues, we found that initiative
and initiative shifts are indicative of learning,
and of learning-conducive episodes. We have
incorporated this finding in KSC-PaL, a peer
learning agent. KSC-PaL promotes learning
by encouraging shifts in task initiative.
1 Introduction
Collaborative learning has been shown to be an ef-
fective mode of learning for potentially all partic-
ipants (Brown and Palincsar, 1989; Fisher, 1993;
Tin, 2003). While collaboration in dialogue has long
been researched in computational linguistics (Chu-
Carroll and Carberry, 1998; Constantino-Gonza?lez
and Suthers, 2000; Jordan and Di Eugenio, 1997;
Soller, 2004), the study of peer learning from a com-
putational perspective is still in the early stages.
Previous research has suggested several mecha-
nisms that explain why peer learning is effective.
Among them are: self-directed explaining (Chi et
al., 1994), other-directed explaining (Ploetzner et
al., 1999; Roscoe and Chi, 2007) and Knowledge
Co-construction ? KCC for short (Hausmann et al,
2004). KCC episodes are defined as portions of the
dialogue in which students are jointly constructing
a shared meaning of a concept required for problem
solving. This last mechanism is the most interesting
from a peer learning perspective because it is a truly
?This work is funded by NSF grants 0536968 and 0536959.
collaborative construct and also because it is consis-
tent with the widely accepted constructivist view of
learning.
In our previous work (Kersey et al, 2009) we de-
rived a model of peer interactions that operational-
izes KCC via the notion of initiative shifts in dia-
logue. This model was based on an extensive corpus
analysis in which we found a strong relationship be-
tween initiative shifts and KCC episodes. A paired t-
test showed that there were significantly more initia-
tive shifts in the annotated KCC episodes compared
with the rest of the dialogue ( t(57) = 3.32, p =
0.0016). The moderate effect difference between
the two groups (effect size = 0.49 ) shows that there
is a meaningful increase in the number of initia-
tive shifts in KCC episodes compared with problem
solving activity outside of the KCC episodes. Addi-
tionally, we found moderate correlations of learning
with both KCC (R2 = 0.14, p = 0.02) and with
initiative shifts (R2 = 0.20, p = 0.00).
We have incorporated this model in an innovative
peer learning agent, KSC-PaL, that is designed to
collaborate with a student to solve problems in the
domain of computer science data structures.
2 KSC-PaL
KSC-PaL, has at its core the TuTalk System (Jordan
et al, 2007), a dialogue management system that
supports natural language dialogue in educational
applications. In developing KSC-PaL we extended
TuTalk in three ways.
The first extension is a user interface (see Fig-
ure 1) which manages communication between
TuTalk and the student. Students interact with KSC-
17
Figure 1: The KSC-PaL interface
PaL using natural language and graphical actions.
The student input is processed by the interface and
its related modules into an appropriate format and
passed to TuTalk. Since TuTalk?s interpretation
module is not able to appropriately handle all stu-
dent utterances, a human interpreter assists in this
process. The interpreter receives a student utterance
along with a list of possible matching concepts from
TuTalk (see Figure 4). The interpreter then selects
the most likely matching concepts from TuTalk thus
assisting in natural language interpretation. If the
student utterance doesn?t match any of these con-
cepts, a second list of concepts, containing student
initiative utterances, are presented to the interpreter.
If none of these match then all known concepts are
presented to the interpreter for matching. Note that
the interpreter has a limited, predetermined set of
choices, corresponding to the concepts that TuTalk
is aware of. In this way, his/her intervention is cir-
cumscribed.
The second addition is the incorporation of a stu-
dent model that allows the KSC-PaL to track the
current state of problem solving and the student?s
knowledge in order to guide its behavior. TuTalk?s
student model was replaced with one that incorpo-
rates problem solution graphs (Conati et al, 2002).
Solution graphs are Bayesian networks where each
node represents either an action required to solve the
problem or a concept required as part of problem
solving. A user?s utterances and actions are then
matched to these nodes. This provides KSC-PaL
with information related to the student?s knowledge
of problem solving concepts as well as the current
topic under discussion.
Thirdly, a planning module was added to TuTalk
to make decisions on implementation of problem
solving goals and responses to student initiative in
order to manage shifts in initiative. The planning
module includes an initiative tracker that codes turns
with with either student initiative or agent initiative
using one classifier for natural language utterances
and a separate classifier for drawing and coding ac-
tions. Once a turn is classified, it is determined
whether a shift in initiative has occurred by compar-
18
ing the current classification with the classification
of the previous turn. An average level of initiative
shifts is then computed by dividing the number of
initiative shifts by the total number of turns. Based
on the initiative level, KSC-PaL encourages initia-
tive shifts by using prompts, hedging, requesting
feedback from the student and encouraging student
criticism by intentionally making errors in problem
solving.
Our evaluation of KSC-PaL (Kersey et al, June
2010) found that students learned using the agent
and that KSC-PaL was was successful in encourag-
ing shifts in initiative.
3 Demonstration Outline
We will demonstrate a problem solving episode with
KSC-PaL where a user will interact with the agent as
a student. Specifically we will show how KSC-PaL
attempts to manage the level of initiative and how
KSC-PaL reacts to student initiative.
1. Amy: hi there, are you ready
to start?
2. Mary: sure
3. Amy: where to begin?
4. Mary: i don?t know
5. Amy: maybe we should draw this
6. Amy: do you want to draw it?
7. Mary: ok
8. Amy: so, line 1 ...
9. Mary: how?s that?
10. Amy: hmmm
11. Amy: line 2: first.next=
second.next
(Mary diagrams the code segment)
12. Mary: there i finished it
13. Amy: looks good
14. Amy: i think we?re done drawing
15. Mary: yes
16. Amy: basically, it switches the
first and second elements
17. Mary: right
18. Amy: ill write the explanation
19. Mary: ok
Figure 2: Problem Solving Example
Figure 2 shows an excerpt from a typical prob-
lem solving session. Amy, the agent, attempts to
maintain a balanced level of initiative either by en-
couraging the student (Mary) to take initiative, or by
taking initiative. In lines 10 and 11, the agent uses a
prompt followed by repetition of the problem solv-
ing goal to encourage the student to retain the initia-
tive. However, in line 16 the agent takes initiative by
proposing a solution to the problem.
KSC-PaL is also able to manage the situation
where the student takes initiative in the dialogue in
an unanticipated manner, as shown in Figure 3. In
line 3, Mary asks a question that is not expected
at this point in the problem solving process and the
agent responds appropriately in line 4. KSC-PaL is
able to respond to a set of student initiations derived
from corpus data, such as the one in this excerpt.
Additionally, the agent responds in a generic man-
ner to other unanticipated initiations and directs the
student back to problem solving.
1. Mary: let?s look at the code
2. Amy: so, i think first and
second both equal bat
3. Mary: is second a reference or
a node?
4. Amy: second is a reference
Figure 3: Student Initiative Example
References
A. L. Brown and A. S. Palincsar, 1989. Guided, cooper-
ative learning and individual knowledge acquisition,
pages 307?226. Lawrence Erlbaum Associates, Hills-
dale, NJ.
M.T.H. Chi, N. De Leeuw, M.H. Chiu, and C. LaVancher.
1994. Eliciting self-explanations improves under-
standing. Cognitive Science, 18(3):439?477.
Jennifer Chu-Carroll and Sandra Carberry. 1998. Col-
laborative response generation in planning dialogues.
Computational Linguistics, 24(3):355?400.
Cristina Conati, Abigail Gertner, and Kurt VanLehn.
2002. Using Bayesian networks to manage uncer-
tainty in student modeling. User Modeling and User-
Adapted Interaction, 12(4):371?417.
Mar??a de los Angeles Constantino-Gonza?lez and
Daniel D. Suthers. 2000. A coached collaborative
learning environment for entity-relationship modeling.
Intelligent Tutoring Systems, pages 324?333.
19
Figure 4: The interface for the human interpreter
E. Fisher. 1993. Distinctive features of pupil-pupil class-
room talk and their relationship to learning: How dis-
cursive exploration might be encouraged. Language
and Education, 7:239?257.
Robert G.M. Hausmann, Michelene T.H. Chi, and Mar-
guerite Roy. 2004. Learning from collaborative prob-
lem solving: An analysis of three hypothesized mech-
anisms. In K.D Forbus, D. Gentner, and T. Regier, edi-
tors, 26th Annual Conference of the Cognitive Science
Society, pages 547?552, Mahwah, NJ.
Pamela W. Jordan and Barbara Di Eugenio. 1997. Con-
trol and initiative in collaborative problem solving di-
alogues. In Working Notes of the AAAI Spring Sympo-
sium on Computational Models for Mixed Initiative,
pages 81?84, Menlo Park, CA.
Pamela W Jordan, Brian Hall, Michael A. Ringenberg,
Yui Cue, and Carolyn Penstein Rose?. 2007. Tools for
authoring a dialogue agent that participates in learning
studies. In Artificial Intelligence in Education, AIED
2007, pages 43?50.
Cynthia Kersey, Barbara Di Eugenio, Pamela Jordan, and
Sandra Katz. 2009. KSC-PaL: a peer learning agent
that encourages students to take the initiative. In Pro-
ceedings of the Fourth Workshop on Innovative Use of
NLP for Building Educational Applications, pages 55?
63. Association for Computational Linguistics.
Cynthia Kersey, Barbara Di Eugenio, Pamela Jordan, and
Sandra Katz. June 2010. KSC-PaL: A peer learning
agent. In ITS 2010, The 10th International Conference
on Intelligent Tutoring Systems, Pittsburgh, PA.
R. Ploetzner, P. Dillenbourg, M. Preier, and D. Traum.
1999. Learning by explaining to oneself and to others.
Collaborative learning: Cognitive and computational
approaches, pages 103?121.
Rod D. Roscoe and Michelene T. H. Chi. 2007.
Understanding tutor learning: Knowledge-building
and knowledge-telling in peer tutors? explanations
and questions. Review of Educational Research,
77(4):534?574.
Amy Soller. 2004. Computational modeling and analysis
of knowledge sharing in collaborative distance learn-
ing. User Modeling and User-Adapted Interaction,
Volume 14(4):351?381, January.
Tan Bee Tin. 2003. Does talking with peers help learn-
ing? the role of expertise and talk in convergent group
discussion tasks. Journal of English for Academic
Purposes, 2(1):53?66.
20
INLG 2012 Proceedings of the 7th International Natural Language Generation Conference, pages 95?99,
Utica, May 2012. c?2012 Association for Computational Linguistics
Reformulating student contributions in tutorial dialogue?
Pamela Jordan1
pjordan@pitt.edu
Sandra Katz1
katz@pitt.edu
Patricia Albacete1
palbacet@pitt.edu
Michael Ford2
mjford@pitt.edu
Christine Wilson1
clwilson@pitt.edu
University of Pittsburgh
Learning Research & Development Center1
School of Education2
Pittsburgh PA 15260, USA
Abstract
While some recent work in tutorial dialogue
has touched upon tutor reformulations of stu-
dent contributions, there has not yet been an
attempt to characterize the intentions of refor-
mulations in this educational context nor an
attempt to determine which types of reformu-
lation actually contribute to student learning.
In this paper we take an initial look at tutor
reformulations of student contributions in nat-
uralistic tutorial dialogue in order to charac-
terize the range of pedagogical intentions that
may be associated with these reformulations.
We further outline our plans for implementing
reformulation in our tutorial dialogue system,
Rimac, which engages high school physics
students in post problem solving reflective dis-
cussions. By implementing reformulations in
a tutorial dialogue system we can begin to test
their impact on student learning in a more con-
trolled way in addition to testing whether our
approximation of reformulation is adequate.
1 Introduction
In the current study of tutorial dialogue we describe
here, we seek to identify the most pedagogically
valuable ways in which a tutor incorporates a stu-
dent?s contribution into his turn so that we can im-
plement these in a tutorial dialogue system. In edu-
cational research, two teaching techniques that have
?The research reported here was supported by the Institute
of Education Sciences, U.S. Department of Education, through
Grant R305A100163 to the University of Pittsburgh. The opin-
ions expressed are those of the authors and do not represent the
views of the Institute or the U.S. Department of Education.
been shown to benefit students, Accountable Talk
(O?Connor and Michaels, 1993) and Questioning
the Author (Beck et al, 1996), both train teach-
ers to make use of a number of discussion moves
that react to student contributions. One such move
that is shared by both teaching techniques is revoic-
ing. Revoicing is characterized as a reformulation
of what the student said with the intention of ex-
pressing it in a way that most of the student?s fellow
classmates will be able to make sense of it and elab-
orate upon it. In the case of Accountable Talk it also
includes the intent that the teacher attempt to relin-
quish authority on the topic under discussion. This is
done by not evaluating the student contribution and
instead inviting the student to assess the teacher?s
reformulation. In tutorial dialogue, the pedagogical
intention of revoicing cannot be exactly the same.
However, a reformulation that invites the student to
assess it may retain some of the benefits of class-
room revoicing. This is something we intend to test
as part of our research. A step we are taking towards
such a test is to look at what reformulations appear
in tutorial dialogue and then attempt to character-
ize the tutor intentions that may be associated with
them.
In some applied contexts, such as second lan-
guage learning, reformulations are more narrowly
defined as using different words while keeping the
content semantically equivalent. However, research
in pragmatics takes a broader view of reformulation.
In a corpus study of lectures that examined reformu-
lation markers such as ?in other words,? ?that is? and
?i.e.? and also endeavored to consolidate the find-
ings from previous linguistics studies, the range of
95
intentions identified include, among others, defini-
tion, denomination, specification, explanation, cor-
rection and consequence (Murillo, 2008). In our pre-
liminary characterization of reformulations in nat-
uralistic tutorial dialogue, we will use this broader
definition and will test whether a tutor contribution
is a reformulation of what the student said by check-
ing the felicity of inserted reformulation markers
such as ?in other words.?
Two recent studies of tutorial dialogue specifi-
cally recognize revoicing. The first study (Chi and
Roy, 2010) examines face to face naturalistic tutorial
dialogue in which a tutor is helping a student work
through a physics problem. They suggest that when
the tutor repeats part of what the student said, it is
often done with the intention of providing positive
feedback for correct answers and call this revoicing
as with the excerpt below which is repeated from
(Chi and Roy, 2010) .
S: First the gravity is pulling down
T: Pulling it down. [Tutor revoiced.]
S: Weight is..the mass times..acceleration due
to gravity and that?s force.
T: Right. Right.
S: Ok.
T: So weight is the force. [Tutor revoiced.]
Given the limited context of these transcribed ex-
cerpts it is difficult to argue that these are revoicings
in the sense of Accountable Talk (AT). There are
no implicit or explicit invitations, such as a question
mark, to assess the tutor?s contributions.
While it is possible in the first example that the
tutor understood the student to be making a generic
statement and was adding ?it? to apply it to the par-
ticular problem under discussion, it is also possible
they have the shared goal of identifying and sum-
ming all the forces on a particular object and the tu-
tor is just acknowledging understanding.
The second example seems to draw attention to
what is most important in what the student just said.
In AT and Questioning the Author (QtA), this type
of move is called marking instead of revoicing. A
marking is a reformulation that emphasizes what is
most important in what the student said and attempts
to direct the student to focus his/her continued dis-
cussion on the reformulation.
Although neither of these examples are revoicings
in the sense of AT and the first seems more like a
repetition to acknowledge rather than reformulate,
both are still important to consider for tutorial dia-
logue. They may help lessen the student?s cognitive
load (Walker, 1996) by drawing attention to what is
most important in what the student said (Becker et
al., 2011).
The other recent study of tutorial dialogue that
considers revoicing collected a corpus using human
tutors who were trained to use QtA and who fill in
for a conversational virtual tutor in a science educa-
tion system (Becker et al, 2011). This corpus has
been annotated along multiple dimensions. Two dis-
cussion moves from QtA, revoicing and marking,
which are noted to be frequent in this corpus, are
included in the dialogue act dimension along with
other more general speech acts. However, there is no
stated goal to annotate other reformulations. So we
do not know what other intentions associated with
reformulations may appear in the corpus.
In addition, the authors? description of revoicing
differs from that used in AT. Here, it is a reformula-
tion that is meant to help a student who is struggling
with a particular concept. As shown in the annotated
example of revoicing repeated below from (Becker
et al, 2011), authority is not relinquished and the
student is not invited to assess the reformulation.
S33: well when you scrub the the paperclip to
the magnet the paperclip is starting to be a mag-
net [Answer/Describe/Process]
T34: very good, so if the magnet gets
close to the paperclip it picks it up [Feed-
back/Positive/None, Revoice/None/None]
A range of reformulations are recognized in other
work on tutorial dialogue and have been incorpo-
rated into tutorial dialogue systems. In AutoTutor
(Person et al, 2003), elaboration and summary in-
volve reformulation. In Circsim-Tutor (Freedman,
2000), student answers that are close to correct ex-
cept for terminology trigger a reformulation. Fi-
nally, in Beetle II (Dzikovska et al, 2008), restate-
ments of correct and near correct answers involve
reformulations. In our work we wish to identify a
more comprehensive set of reformulation types and
intentions and determine which of these types are
most beneficial to emulate.
96
In this paper we examine a corpus of natural-
istic human tutorial dialogues for tutor reformula-
tions. We further outline our plans for implementing
revoicing and reformulation in our tutorial dialogue
system, Rimac (Katz et al, 2011), which engages
high school physics students in post problem solv-
ing reflective discussions. By implementing refor-
mulations and revoicings we can begin to test their
impact on student learning in a more controlled way
in addition to testing whether our approximations of
them are adequate.
First, we will describe the corpus of human tu-
torial dialogues we are analyzing and then we will
present examples of some of the reformulations we
have found in the corpus and speculate upon pos-
sible tutor intentions for these reformulations. We
will then outline our plans for implementing certain
types of reformulation by first describing the current
tutorial dialogue system and the planned modifica-
tions for implementing tutor reformulations.
2 The Corpus
The corpus of human tutorial dialogues we are an-
alyzing was collected during a study (Katz et al,
2003) on the effectiveness of reflection questions af-
ter a physics problem-solving session with the An-
des physics tutoring system (VanLehn et al, 2005).
The tutors in this corpus were graduate teaching
assistants who had experience in tutoring physics.
The students were recruited from introductory un-
dergraduate physics courses.
The students first solved a problem using the
Andes system and afterwards they were presented
with a deep-reasoning reflection question which they
needed to answer. After typing their answer, they
then engaged in a typed dialogue with a human tutor
to follow up on their answer. This dialogue contin-
ued until the tutor was satisfied that the student un-
derstood the correct answer. Three to eight reflection
questions were asked per problem solved in Andes.
There were 12 Andes problems in all.
3 Characterizing Reformulations in
Reflective Tutorial Dialogue
As part of our analysis of the corpus described in
the previous section, we have been annotating cases
of repetition and reformulation across immediately
adjacent tutor-student and student-tutor turns (Katz
et al, 2011). While this effort is still ongoing and
we cannot yet fully characterize the reformulations
found, we can show examples of some of the re-
formulations we have identified and speculate upon
what the tutor?s intentions may have been. Our goal
in this section is to show the variety of intentions one
can attribute to these reformulations. Due to space
limitations we cannot include examples of the full
range of intentions we have found.
The first example, shown below, reformulates
what the student said (in italics) by using terminol-
ogy that is typical to mathematics/physics (in bold).
Arguably, ?I would call that? may act as a reformu-
lation marker in this example. At the end of a re-
formulation, we list in square brackets the pragmat-
ics labels we believe best characterize the reformu-
lation.
T: what direction (in words) is the displace-
ment?
S: downwards/towards the negative y-axis
T: right: I would call that the -y direction [de-
nomination]
The next example, shown below, reformulates
what the student said in terms of a more fully spec-
ified definition. Inserting ?in other words? after
?Right? seems felicitous.
T: What is speed?
S: it is velocity without direction
T: Right, The (instantaneous) speed is the
magnitude of the (instantaneous) velocity.
[specification/definition]
The next example, shown below, reformulates
some of what the student said so that it is correct.
Here we can insert the marker ?you mean? in front
of ?the mass and acceleration are related to forces?
and arguably ?as you point out? could be serving as
an explicit reformulation marker. In this case the tu-
tor seems to be correcting an implied ?equated to?
to ?related to.?
S: the mass and the acceleration push the man
into the airbag
S: so aren?t they considered forces?
T: the mass and acceleration are related to
97
forces as you point out, but in Newtonian me-
chanics are not considered forces. [correction]
And finally, the example shown below is a refor-
mulation that is a revoicing. In this case the student
may be struggling to explain but seems to have a cor-
rect conceptual understanding. The tutor attempts to
summarize in a clearer way what he thinks the stu-
dent meant and invites a student assessment with ?I
think I see what you mean? and the question mark.
S: no gravity is no effecting x directly, but if it
did not effect y, it would go on forever, and x
would countinue to grow as well, but since y
has a bound, so does the x
T: I think I see what you mean. That when
gravity pulls the ball back to the earth, that
the earth then affects the horizontal mo-
tion (by direct contact), which wouldn?t have
happened without gravity? [summary]
S: gravity is needed to bring y back to 0 so that
the d x comp is = d
4 The Rimac Tutorial Dialogue System
To understand how we propose to implement re-
formulations, we must begin with a high level de-
scription of the current Rimac system. To build Ri-
mac, we used the TuTalk (Jordan et al, 2007) nat-
ural language (NL) tutorial dialogue toolkit. This
toolkit enables system developers to focus on de-
veloping the content to be presented to students
and rapidly developing an end-to-end system for
conducting experiments that determine what con-
tent and presentation is most pedagogically effec-
tive. Tutorial dialogue system developers can grad-
ually transition towards a more principled dialogue
system as questions of pedagogical effectiveness are
answered, since core modules such as NL under-
standing and generation are designed to be replaced
or supplemented as needed.
The simplest dialogue one can write using this
toolkit can be represented as a finite state machine.
Each state represents a tutor turn. The arcs leaving
the state correspond to all classifications of a stu-
dent?s response turn. When creating a state, the au-
thor enters the NL text for a tutor?s turn and enters
the NL text that defines several classes of student re-
sponses as transition arcs, and indicates which state
each arc leads to. An arc can also push to another
finite state network.
In this toolkit, the NL text associated with a state
or an arc is represented by a concept definition. In
the simplest case, a concept is a set of NL phrases.
For instance, the set for a concept labelled NEG-
ACK might be ?Not quite,? ?Well, not exactly,?
?No.? When a student turn is received, the dialogue
manager sends a request to the understanding mod-
ule to determine what concepts it best represents and
determines transitions on the basis of the concept la-
bels returned. Likewise when a concept is to be ex-
pressed, the dialogue manager asks the generation
module to determine how to best express it in NL.
In the next section we outline an initial approach
for rapidly testing which reformulations matter to
student learning.
5 Implementing Reformulation in Rimac
and Future Work
In our preliminary approach for emulating some of
the types of reformulation we have found in the
corpus, if there is a more preferred phrasing for a
matched concept, regardless of whether the student?s
response is considered correct or incorrect, then a re-
formulation with the preferred phrasing is presented
to the student. How the reformulation is presented
depends on the quality or confidence of the concept
match. If the student turn is a poor match for a con-
cept, but it is the best available match then the sys-
tem will revoice the student response; e.g.:
S: the distance of the hailstone
T: Are you saying ?distance the hailstone
travels??
In this example, we assume that ?distance of the
hailstone? is a poor match for the expected cor-
rect concept and it does not match any other con-
cepts that represent an incorrect response. Further,
we assume that the author indicated ?distance the
hailstone travels? as one of the most highly ranked
phrases for expressing the correct concept. So the
tutor?s response revoices using the preferred phras-
ing. In this example, the tutor?s question invites the
student to confirm the system?s reformulation of her
response or try again.
However, if the student?s response is a high qual-
ity match for a concept but the author ranked this
98
phrasing as a less preferred way of expressing the
concept, then the system will reformulate using the
most preferred phrasing for the concept; e.g.:
S: the height of the cloud and the starting place
for the hailstone
T: Good. You could have also said ?the mag-
nitude of the displacement of the hailstone?.
Note that we are not yet attempting to distinguish
the intentions behind reformulations. Instead we are
focusing on when to revoice vs. reformulate. Here,
revoicing is similar to the confirmation/clarification
questions used in spoken dialogue systems when
recognition of the user?s speech is uncertain.
We have also implemented a standalone prototype
of simple repetitions using the XSLT approach de-
scribed in (Wilcock, 2001). By this we mean that the
system will incorporate part of a student?s answer
into correctness feedback; e.g. for positive feedback
as found in (Chi and Roy, 2010; Dzikovska et al,
2008):
T: in which direction is the acceleration?
S: it is [to the right|eastward]
T: Yes, it is [to the right|eastward]
and, in addition, for negative feedback similar to
splicing in (Person et al, 2003); e.g.:
T: in which direction is the acceleration?
S: it is [to the right|eastward]
T: No, if it were [to the right|eastward] then
the velocity would be increasing instead of de-
creasing.
We are currently in the process of completing our
analysis of reformulations and are just beginning to
implement the approach for revoicing and reformu-
lation we outlined for the Rimac system.
References
I. Beck, M. McKeown, C. Sandora, L. Kucan, and J. Wor-
thy. 1996. Questioning the author: A yearlong class-
room implementation to engage students with text.
The Elementary School Journal, 96(4):385?413.
L. Becker, W. Ward, S. Van Vuuren, and M. Palmer.
2011. Discuss: A dialogue move taxonomy layered
over semantic representations. In IWCS 2011: The
9th International Conference on Computational Se-
mantics, Oxford, England, January.
M. T. H. Chi and M. Roy. 2010. How adaptive is an
expert human tutor? In Intelligent Tutoring Systems
Conference, ITS 2010, pages 401?412.
M. Dzikovska, G. Campbell, C. Callaway, N. Stein-
hauser, E. Farrow, J. Moore, L. Butler, and C. Math-
eson. 2008. Diagnosing natural language answers to
support adaptive tutoring. In Proc. of International
FLAIRS Conference.
R. Freedman. 2000. Using a reactive planner as the basis
for a dialogue agent. In Proc. of International FLAIRS
Conference.
P. Jordan, B. Hall, M. Ringenberg, Y. Cui, and C.P. Rose?.
2007. Tools for authoring a dialogue agent that partic-
ipates in learning studies. In Proc. of AIED 2007.
S. Katz, D. Allbritton, and J. Connelly. 2003. Going
beyond the problem given: How human tutors use
post-solution discussions to support transfer. Interna-
tional Journal of Artificial Intelligence and Education,
13(1):79?116.
S. Katz, P. Albacete, P. Jordan, and D. Litman. 2011.
Dialogue analysis to inform the development of a
natural-language tutoring system. In Proc. of SemDial
2011 (Los Angelogue) Workshop on the Semantics and
Pragmatics of Dialogue.
S. Murillo. 2008. The role of reformulation markers in
academic lectures. In A.M. Hornero, M.J. Luzo?n, and
S. Murillo, editors, Corpus Linguistics: Applications
for the Study of English, pages 353?364. Peter Lang
AG.
M.C. O?Connor and S. Michaels. 1993. Aligning aca-
demic task and participation status through revoicing:
Analysis of a classroom discourse strategy. Anthropol-
ogy & Education Quarterly, 24(4):318?335.
N. Person, A. Graesser, R. Kreuz, and V. Pomeroy. 2003.
Simulating human tutor dialog moves in autotutor. In-
ternational Journal of Artificial Intelligence in Educa-
tion, 12(23-39).
K. VanLehn, C. Lynch, K. Schultz, J. A. Shapiro, R. H.
Shelby, and L. Taylor. 2005. The Andes physics tutor-
ing system: Lessons learned. International Journal of
Artificial Intelligence and Education, 3(15):147?204.
M. A. Walker. 1996. The effect of resource limits and
task complexity on collaborative planning in dialogue.
Artificial Intelligence Journal, 85(1-2):181?243.
G. Wilcock. 2001. Pipelines, templates and transforma-
tions: Xml for natural language generation. In 1st NLP
and XML Workshop, page 18.
99
