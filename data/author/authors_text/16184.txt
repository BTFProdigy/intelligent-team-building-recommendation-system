Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 43?48,
Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational Linguistics
LetsMT!: A Cloud-Based Platform for Do-It-Yourself  
Machine Translation 
 
  
Andrejs Vasi?jevs Raivis Skadi?? J?rg Tiedemann 
TILDE TILDE Uppsala University 
Vienbas gatve 75a, Riga Vienbas gatve 75a, Riga Box 635, Uppsala 
LV-1004, LATVIA LV-1004, LATVIA SE-75126, SWEDEN 
andrejs@tilde.com raivis.skadins@ 
tilde.lv 
jorg.tiedemann@ 
lingfil.uu.se 
 
 
 
Abstract 
To facilitate the creation and usage of custom 
SMT systems we have created a cloud-based 
platform for do-it-yourself MT. The platform is 
developed in the EU collaboration project 
LetsMT!. This system demonstration paper 
presents the motivation in developing the 
LetsMT! platform, its main features, 
architecture, and an evaluation in a practical use 
case. 
1 Introduction 
Current mass-market and online MT systems are of 
a general nature and perform poorly for smaller 
languages and domain specific texts. The 
European Union ICT-PSP Programme project 
LetsMT! develops a user-driven MT ?factory in 
the cloud? enabling web users to get customised 
MT that better fits their needs. Harnessing the huge 
potential of the web together with open statistical 
machine translation (SMT) technologies, LetsMT! 
has created an online collaborative platform for 
data sharing and MT building.  
The goal of the LetsMT! project is to facilitate 
the use of open source SMT tools and to involve 
users in the collection of training data. The 
LetsMT! project extends the use of existing state-
of-the-art SMT methods by providing them as 
cloud-based services. An easy-to-use web interface 
empowers users to participate in data collection 
and MT customisation to increase the quality, 
domain coverage, and usage of MT.  
The LetsMT! project partners are companies 
TILDE (coordinator), Moravia, and SemLab, and 
the Universities of Edinburgh, Zagreb, 
Copenhagen, and Uppsala. 
2 LetsMT! Key Features 
The LetsMT! platform 1  (Vasi?jevs et al, 2011) 
gathers public and user-provided MT training data 
and enables generation of multiple MT systems by 
combining and prioritising this data. Users can 
upload their parallel corpora to an online 
repository and generate user-tailored SMT systems 
based on data selected by the user.  
Authenticated users with appropriate 
permissions can also store private corpora that can 
be seen and used only by this user (or a designated 
user group). All data uploaded into the LetsMT! 
repository is kept in internal format, and only its 
metadata is provided to the user. Data cannot be 
downloaded or accessed for reading by any means. 
The uploaded data can only be used for SMT 
training. In such a way, we encourage institutions 
and individuals to contribute their data to be 
publicly used for SMT training, even if they are 
not willing to share the content of the data. 
A user creates SMT system definition by 
specifying a few basic parameters like system 
name, source/target languages, domain, and 
choosing corpora (parallel for translation models or 
monolingual for language models) to use for the 
particular system. Tuning and evaluation data can 
be automatically extracted from the training 
corpora or specified by the user. The access level 
of the system can also be specified - whether it will 
be public or accessible only to the particular user  
or user group. 
                                                          
1 http://letsmt.com 
43
When the system is specified, the user can begin 
training it. Progress of the training can be 
monitored on the dynamic training chart (Figure 1). 
It provides a detailed visualisation of the training 
process showing (i) steps queued for execution of a 
particular training task, (ii) current execution status 
of active training steps, and (iii) steps where any 
errors have occurred. The training chart remains 
available after the training to facilitate analysis of 
the performed trainings. The last step of the 
training task is automatic evaluation using BLEU, 
NIST, TER, and METEOR scores. 
A successfully trained SMT system can be 
started and used for translation in several ways: 
? on the translation webpage of LetsMT! for 
testing and short translations; 
? using LetsMT! plug-ins in computer-
assisted translation (CAT) tools for 
professional translation;  
? integrating the LetsMT! widget for web-
site translation;  
? using LetsMT! plug-ins for IE and FireFox 
to integrate translation into the browsers; 
? using LetsMT! API for MT integration into 
different applications.  
LetsMT! allows for several system instances to 
run simultaneously to speed up translation and 
balance the workload from numerous translation 
requests. 
LetsMT! user authentication and authorisation 
mechanisms control access rights to private 
training data, trained models 
and SMT systems, per-
missions to initiate and 
manage training tasks, run 
trained systems, and access 
LetsMT! services through 
external APIs. 
The LetsMT! platform is 
populated with initial SMT 
training data collected and 
prepared by the project 
partners. It currently contains 
more than 730 million 
parallel sentences in almost 
50 languages. In the first 4 
months since launching the 
invitation only beta version 
of the platform, 82 SMT 
systems have been 
successfully trained. 
3 SMT Training and Decoding Facilities 
The SMT training and decoding facilities of 
LetsMT! are based on the open source toolkit 
Moses. One of the important achievements of the 
project is the adaptation of the Moses toolkit to fit 
into the rapid training, updating, and interactive 
access environment of the LetsMT! platform. 
The Moses SMT toolkit (Koehn et al, 2007) 
provides a complete statistical translation system 
distributed under the LGPL license. Moses 
includes all of the components needed to pre-
process data and to train language and translation 
models. Moses is widely used in the research 
community and has also reached the commercial 
sector. While the use of the software is not closely 
monitored, Moses is known to be in commercial 
use by companies such as Systran (Dugast et al, 
2009), Asia Online, Autodesk (Plitt and Masselot, 
2010), Matrixware2, Adobe, Pangeanic, Logrus3, 
and Applied Language Solutions (Way et al, 
2011). 
The SMT training pipeline implemented in 
Moses involves a number of steps that each require 
a separate program to run. In the framework of 
                                                          
2 Machine Translation at Matrixware: http://ir-facility.net/ 
downloads/mxw_factsheet_smt_200910.pdf 
3 TDA Members doing business with Moses: 
http://www.tausdata.org/blog/2010/10/doing-business-with-
moses-open-source-translation/ 
Figure 1. Training chart providing dynamic representation of training steps. 
44
LetsMT!, this process is streamlined and made 
automatically configurable given a set of user-
specified variables (training corpora, language 
model data, tuning sets). SMT training is 
automated using the Moses experiment mana-
gement system (Koehn, 2010). Other impro-
vements of Moses, implemented by the University 
of Edinburgh as part of LetsMT! project, are: 
? the incremental training of SMT models 
(Levenberg et al, 2010); 
? randomised language models (Levenberg 
et al, 2009); 
? a server mode version of the Moses 
decoder and multithreaded decoding; 
? multiple translation models; 
? distributed language models (Brants et al, 
2007).  
Many improvements in the Moses experiment 
management system were implemented to speed up 
SMT system training and to use the full potential 
of the HPC cluster. We revised and improved 
Moses training routines (i) by finding tasks that are 
executed sequentially but can be executed in 
parallel and (ii) by splitting big training tasks into 
smaller ones and executing them in parallel. 
4 Multitier Architecture 
The LetsMT! system has a multitier architecture 
(Figure 2). It has (i) an interface layer implemen-
ting the user interface and APIs with external 
systems, (ii) an application logic layer for the 
system logic, (iii) a data storage layer consisting of 
file and database storage, and (iv) a high 
performance computing (HPC) cluster. The 
LetsMT! system performs various time and 
resource consuming tasks; these tasks are defined 
by the application logic and data storage and are 
sent to the HPC cluster for execution. 
The Interface layer provides interfaces between 
the LetsMT! system and external users. The system 
has both human and machine users. Human users 
can access the system through web browsers by 
using the LetsMT! web page interface. External 
systems such as Computer Aided Translation 
(CAT) tools and web browser plug-ins can access 
the LetsMT! system through a public API. The 
public API is available through both REST/JSON 
and SOAP protocol web services. An HTTPS 
protocol is used to ensure secure user 
authentication and secure data transfer. 
The application logic layer contains a set of 
modules responsible for the main functionality and 
logic of the system. It receives queries and 
commands from the interface layer and prepares 
answers or performs tasks using data storage and 
the HPC cluster. This layer contains several 
modules such as the Resource Repository Adapter, 
the User Manager, the SMT Training Manager, etc. 
The interface layer accesses the application logic 
layer through the REST/JSON and SOAP protocol 
web services. The same protocols are used for 
communication between modules in the 
application logic layer.  
Figure 2. The LetsMT! system architecture 
The data is stored in one central Resource 
Repository (RR). As training data may change (for 
example, grow), the RR is based on a version-
controlled file system (currently we use SVN as 
the backend system). A key-value store is used to 
keep metadata and statistics about training data and 
trained SMT systems. Modules from the 
application logic layer and HPC cluster access RR 
through a REST-based web service interface.  
A High Performance Computing Cluster is used 
to execute many different computationally heavy 
data processing tasks ? SMT training and running, 
corpora processing and converting, etc. Modules 
from the application logic and data storage layers 
45
create jobs and send them to the HPC cluster for 
execution. The HPC cluster is responsible for 
accepting, scheduling, dispatching, and managing 
remote and distributed execution of large numbers 
of standalone, parallel, or interactive jobs. It also 
manages and schedules the allocation of distributed 
resources such as processors, memory, and disk 
space. The LetsMT! HPC cluster is based on the 
Oracle Grid Engine (SGE). 
The hardware infrastructure of the LetsMT! 
platform is heterogeneous. The majority of 
services run on Linux platforms (Moses, RR, data 
processing tools, etc.). The Web server and 
application logic services run on a Microsoft 
Windows platform.  
The system hardware architecture is designed to 
be highly scalable. The LetsMT! platform contains 
several machines with both continuous and on-
demand availability: 
? Continuous availability machines are used 
to run the core frontend and backend 
services and the HPC grid master to 
guarantee stable system functioning; 
? On-demand availability machines are used 
(i) to scale up the system by adding more 
computing power to training, translation, 
and data import services (HPC cluster 
nodes) and (ii) to increase  performance of 
frontend and backend server instances. 
To ensure scalability of the system, the whole 
LetsMT! system including the HPC cluster is 
hosted by Amazon Web Services infrastructure, 
which provides easy access to on-demand 
computing and storage resources. 
5 Data Storage and Processing Facilities 
As a data sharing and MT platform, the LetsMT! 
system has to store and process large amounts of 
SMT training data (parallel and monolingual 
corpora) as well as trained models of SMT 
systems. The Resource Repository (RR) software 
is fully integrated into the LetsMT! Platform and 
provides the following major components: 
? Scalable data storage based on version-
controlled file systems; 
? A flexible key-value store for metadata; 
? Access-control mechanisms defining three 
levels of permission (private data, public 
data, shared data); 
? Data import modules that include tools for 
data validation, conversion and automatic 
sentence alignment for a variety of popular 
document formats. 
The general architecture of the Resource 
Repository is illustrated in Figure 3. It is 
implemented in terms of a modular package that 
can easily be installed in a distributed environment. 
RR services are provided via Web API?s and 
secure HTTP requests. Data storage can be 
distributed over several servers as is illustrated in 
Figure 3. Storage servers communicate with the 
central database server that manages all metadata 
records attached to resources in the RR. Data 
resources are organised in slots that correspond to 
file systems with user-specific branches. Currently, 
the RR package implements two storage backends: 
a plain file system and a version-controlled file 
system based on subversion (SVN). The latter is 
the default mode, which has several advantages 
over non-revisioned data storage. Revision control 
systems are designed to handle dynamically 
growing collections of mainly textual data in a 
multi-user environment. Furthermore, they keep 
track of modifications and file histories to make it 
possible to backtrack to prior revisions. This can 
be a strong advantage, especially in cases of shared 
data access. Another interesting feature is the 
possibility to create cheap copies of entire 
branches that can be used to enable data 
modifications by other users without 
compromising data integrity for others. Finally, 
SVN also naturally stores data in a compressed 
format, which is useful for large-scale document 
collections. In general, the RR implementation is 
modular, other storage backends may be added 
later, and each individual slot can use its own 
backend type. 
Another important feature of the RR is the 
support of a flexible database for metadata. We 
decided to integrate a modern key-value store into 
the platform in order to allow a maximum of 
flexibility. In contrast to traditional relational 
databases, key-value stores allow the storage of 
arbitrary data sets based on pairs of keys and 
values without being restricted to a pre-defined 
schema or a fixed data model. Our implementation 
relies on TokyoCabinet4, a modern implementation 
of schema-less databases that supports all of our 
                                                          
4 https://fallabs/tokyocabinet 
46
requirements in terms of flexibility and efficiency. 
In particular, we use the table mode of 
TokyoCabinet that supports storage of arbitrary 
data records connected to a single key in the 
database. We use resource URL?s in our repository 
to define unique keys in the database, and data 
records attached to these keys may include any 
number of key-value pairs. In this way, we can add 
any kind of information to each addressable 
resource in the RR. The software also supports 
keys with unordered lists of values, which is useful 
for metadata such as languages (in a data 
collection) and for many other purposes. 
Moreover, TokyoCabinet provides powerful query 
language and software bindings for the most 
common programming languages. It can be run in 
client-server mode, which ensures robustness in a 
multi-user environment and natively supports data 
replication. Using TokyoCabinet as our backend, 
we implemented a key-value store for metadata in 
the RR that can easily be extended and queried 
from the frontend of the LetsMT! Platform via 
dedicated web-service calls. 
Yet another important feature of the RR is the 
collection of import modules that take care of 
validation and conversion of user-provided SMT 
training material. Our main goal was to make the 
creation of appropriate data resources as painless 
as possible. Therefore, we included support for the 
most common data formats to be imported into 
LetsMT!. Pre-aligned parallel data can be uploaded 
in TMX, XLIFF, and Moses formats. Monolingual 
data can be provided in plain text, PDF, and MS 
Word formats. We also support the upload of 
compressed archives in zip and tar format. In the 
future, other formats 
can easily be 
integrated in our 
modular implemen-
tation. 
Validation of such 
a variety of formats is 
important. Therefore 
among others, we 
included XML/DTD 
validation, text en-
coding detection soft-
ware, and language 
identification tools 
with pre-trained mo-
dels for over 60 lan-
guages. 
Furthermore, our system also includes tools for 
automatic sentence alignment. Import processes 
automatically align translated documents with each 
other using standard length-based sentence 
alignment methods (Gale and Church, 1993; Varga 
et al, 2005). 
Finally, we also integrated a general batch-
queuing system (SGE) to run off-line processes 
such as import jobs. In this way, we further 
increase the scalability of the system by taking the 
load off repository servers. Data uploads 
automatically trigger appropriate import jobs that 
will be queued on the grid engine using a dedicated 
job web-service API. 
6 Evaluation for Usage in Localisation 
One of the usage scenarios particularly targeted by 
the project is application in the localisation and 
translation industry. Localisation companies 
usually have collected significant amounts of 
parallel data in the form of translation memories. 
They are interested in using this data to create 
customised MT engines that can increase 
productivity of translators. Productivity is usually 
measured as an average number of words 
translated per hour. For this use case, LetsMT! has 
developed plug-ins for integration into CAT tools. 
In addition to translation candidates from 
translation memories, translators receive 
translation suggestions provided by the selected 
MT engine running on LetsMT!. 
As part of the system evaluation, project partner 
Moravia used the LetsMT! platform to train and 
 Figure 3. Resource repository overview 
47
evaluate SMT systems for Polish and Czech. An 
English-Czech engine was trained on 0.9M parallel 
sentences coming from Moravia translation 
memories in the IT and tech domain part of the 
Czech National Corpus. The resulting system 
increased translator productivity by 25.1%. An 
English-Polish system was trained on 1.5M 
parallel sentences from Moravia production data in 
the IT domain. Using this system, translator 
productivity increased by 28.5%. 
For evaluation of English-Latvian translation, 
TILDE created a MT system using a significantly 
larger corpus of 5.37M parallel sentence pairs, 
including 1.29M pairs in the IT domain. 
Additional tweaking was made by manually 
adding a factored model over disambiguated 
morphological tags. The resulting system 
increased translator productivity by 32.9% 
(Skadi?? et al, 2011). 
7 Conclusions 
The results described in this paper show that the 
LetsMT! project is on track to fulfill its goal to 
democratise the creation and usage of custom SMT 
systems. LetsMT! demonstrates that the open 
source SMT toolkit Moses is reaching maturity to 
serve as a base for large scale and heavy use 
production purposes. The architecture of the 
platform and Resource Repository enables 
scalability of the system and very large amounts of 
data to be handled in a variety of formats. 
Evaluation shows a strong increase in translation 
productivity by using LetsMT! systems in IT 
localisation. 
Acknowledgments 
The research within the LetsMT! project has 
received funding from the ICT Policy Support 
Programme (ICT PSP), Theme 5 ? Multilingual 
web, grant agreement 250456. 
References  
L. Dugast, J. Senellart, P. Koehn. 2009. Selective 
addition of corpus-extracted phrasal lexical rules to a 
rule-based machine translation system. Proceedings 
of MT Summit XII. 
T. Brants, A.C.  Popat, P.  Xu, F.J  Och, J. Dean. 2007. 
Large Language Models in Machine Translation. 
Proceedings of the 2007 Joint Conference on 
Empirical Methods in Natural Language Processing 
and Computational Natural Language Learning 
(EMNLP-CoNLL), 858-867. Prague, Czech Republic 
W. A. Gale, K. W. Church. 1993. A Program for 
Aligning Sentences in Bilingual Corpora. 
Computational Linguistics 19 (1): 75?102 
P. Koehn, M. Federico, B. Cowan, R. Zens, C. Duer, O. 
Bojar, A. Constantin, E. Herbst. 2007. Moses: Open 
Source Toolkit for Statistical Machine Translation. 
Proceedings of the ACL 2007 Demo and Poster 
Sessions, 177-180. Prague. 
P. Koehn. 2010. An experimental management system. 
The Prague Bulletin of Mathematical Linguistics, 94.  
A. Levenberg, M. Osborne. 2009. Stream-based Ran-
domised Language Models for SMT. Proceedings of 
the 2009 Conference on Empirical Methods in 
Natural Language Processing. 
A. Levenberg, C. Callison-Burch, M. Osborne. 2010. 
Stream-based Translation Models for Statistical 
Machine Translation. Human Language 
Technologies: The 2010 Annual Conference of the 
North American Chapter of the Association for 
Computational Linguistics (HLT '10) 
M. Plitt, F. Masselot. 2010. A Productivity Test of 
Statistical Machine Translation Post-Editing in a 
Typical Localisation Context. The Prague Bulletin of 
Mathematical Linguistics, 93(January 2010): ?16 
R. Skadi??, M. Puri??, I. Skadi?a, A. Vasi?jevs. 2011. 
Evaluation of SMT in localization to under-resourced 
inflected language. Proceedings of the 15th 
International Conference of the European 
Association for Machine Translation EAMT 2011, 
35-40. Leuven, Belgium 
A. Vasi?jevs, R. Skadi??, I. Skadi?a. 2011. Towards 
Application of User-Tailored Machine Translation in 
Localization. Proceedings of the Third Joint 
EM+/CNGL Workshop ?Bringing MT to the User: 
Research Meets Translators? JEC 2011, 23-31. 
Luxembourg 
D. Varga, L. N?meth, P. Hal?csy, A. Kornai, V. Tr?n, 
V. Nagy. 2005. Parallel corpora for medium density 
languages. Recent Advances in Natural Language 
Processing IV Selected papers from RANLP05, 590-
596 
A. Way, K. Holden, L. Ball, G. Wheeldon. 2011. 
SmartMATE: online self-serve access to state-of-the-
art SMT.  Proceedings of the Third Joint EM+/CNGL 
Workshop ?Bringing MT to the User: Research 
Meets Translators? (JEC ?11), 43-52. Luxembourg 
48
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 91?96,
Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational Linguistics
ACCURAT Toolkit for Multi-Level Alignment and  
Information Extraction from Comparable Corpora 
 
M?rcis Pinnis1, Radu Ion2, Dan ?tef?nescu2, Fangzhong Su3, 
Inguna Skadi?a1, Andrejs Vasi?jevs1, Bogdan Babych3 
 1Tilde, Vien?bas gatve 75a, Riga, Latvia 
{marcis.pinnis,inguna.skadina,andrejs}@tilde.lv 
 
2Research Institute for Artificial Intelligence, Romanian Academy 
{radu,danstef}@racai.ro 
 
3Centre for Translation Studies, University of Leeds 
{f.su,b.babych}@leeds.ac.uk 
 
 
Abstract 
The lack of parallel corpora and linguistic 
resources for many languages and domains is 
one of the major obstacles for the further 
advancement of automated translation. A 
possible solution is to exploit comparable 
corpora (non-parallel bi- or multi-lingual text 
resources) which are much more widely 
available than parallel translation data. Our 
presented toolkit deals with parallel content 
extraction from comparable corpora. It consists 
of tools bundled in two workflows: (1) 
alignment of comparable documents and 
extraction of parallel sentences and (2) 
extraction and bilingual mapping of terms and 
named entities. The toolkit pairs similar 
bilingual comparable documents and extracts 
parallel sentences and bilingual terminological 
and named entity dictionaries from comparable 
corpora. This demonstration focuses on the 
English, Latvian, Lithuanian, and Romanian 
languages. 
Introduction 
In recent decades, data-driven approaches have 
significantly advanced the development of 
machine translation (MT). However, lack of 
sufficient bilingual linguistic resources for many 
languages and domains is still one of the major 
obstacles for further advancement of automated 
translation. At the same time, comparable corpora, 
i.e., non-parallel bi- or multilingual text resources 
such as daily news articles and large knowledge 
bases like Wikipedia, are much more widely 
available than parallel translation data.  
While methods for the use of parallel corpora in 
machine translation are well studied (Koehn, 
2010), similar techniques for comparable corpora 
have not been thoroughly worked out. Only the 
latest research has shown that language pairs and 
domains with little parallel data can benefit from 
the exploitation of comparable corpora (Munteanu 
and Marcu, 2005; Lu et al, 2010; Smith et al, 
2010; Abdul-Rauf and Schwenk, 2009 and 2011). 
In this paper we present the ACCURAT 
toolkit1 - a collection of tools that are capable of  
analysing comparable corpora and extracting 
parallel data which can be used to improve the 
performance of statistical and rule/example-based 
MT systems. 
Although the toolkit may be used for parallel 
data acquisition for open (broad) domain systems, 
it will be most beneficial for under-resourced 
languages or specific domains which are not 
covered by available parallel resources. 
The ACCURAT toolkit produces: 
? comparable document pairs with 
comparability scores, allowing to estimate 
the overall comparability of corpora; 
? parallel sentences which can be used as 
additional parallel data sources for 
statistical translation model learning; 
                                                          
1 http://www.accurat-project.eu/ 
91
? terminology dictionaries ? this type of 
data is expected to improve domain-
dependent translation; 
? named entity dictionaries. 
The demonstration showcases two general use 
case scenarios defined in the toolkit: ?parallel data 
mining from comparable corpora? and ?named 
entity/terminology extraction and mapping from 
comparable corpora?. 
The next section provides a general overview of 
workflows followed by descriptions of methods 
and tools integrated in the workflows. 
1 Overview of the Workflows 
The toolkit?s tools are integrated within two 
workflows (visualised in Figure 1). 
 
  
Figure 1. Workflows of the ACCURAT toolkit. 
 
The workflow for parallel data mining from 
comparable corpora aligns comparable corpora in 
the document level (section 2.1). This step is 
crucial as the further steps are computationally 
intensive. To minimise search space, documents 
are aligned with possible candidates that are likely 
to contain parallel data. Then parallel sentence 
pairs are extracted from the aligned comparable 
corpora (section 2.2). 
The workflow for named entity (NE) and 
terminology extraction and mapping from 
comparable corpora extracts data in a dictionary-
like format. Providing a list of document pairs, the 
workflow tags NEs or terms in all documents using 
language specific taggers (named entity 
recognisers (NER) or term extractors) and 
performs multi-lingual NE (section 2.3) or term 
mapping (section 2.4), thereby producing bilingual 
NE or term dictionaries. The workflow also 
accepts pre-processed documents, thus skipping 
the tagging process. 
Since all tools use command line interfaces, task 
automation and workflow specification can be 
done with simple console/terminal scripts. All 
tools can be run on the Windows operating system 
(some are also platform independent). 
2 Tools and Methods 
This section provides an overview of the main 
tools and methods in the toolkit. A full list of tools 
is described in ACCURAT D2.6. (2011). 
2.1 Comparability Metrics 
We define comparability by how useful a pair of 
documents is for parallel data extraction. The 
higher the comparability score, the more likely two 
documents contain more overlapping parallel data. 
The methods are developed to perform lightweight 
comparability estimation that minimises search 
space of relatively large corpora (e.g., 10,000 
documents in each language). There are two 
comparability metric tools in the toolkit: a 
translation based and a dictionary based metric. 
The Translation based metric (Su and Babych, 
2012a) uses MT APIs for document translation 
into English. Then four independent similarity 
feature functions are applied to a document pair: 
? Lexical feature ? both documents are pre-
processed (tokenised, lemmatised, and 
stop-words are filtered) and then 
vectorised. The lexical overlap score is 
calculated as a cosine similarity function 
over the vectors of two documents. 
? Structural feature ? the difference of 
sentence counts and content word counts 
(equally interpolated). 
? Keyword feature ? the cosine similarity 
of top 20 keywords. 
? NE feature ? the cosine similarity of NEs 
(extracted using Stanford NER). 
These similarity measures are linearly combined in 
a final comparability score. This is implemented by 
a simple weighted average strategy, in which each 
92
type of feature is associated with a weight 
indicating its relative confidence or importance. 
The comparability scores are normalised on a scale 
of 0 to 1, where a higher comparability score 
indicates a higher comparability level. 
The reliability of the proposed metric has been 
evaluated on a gold standard of comparable 
corpora for 11 language pairs (Skadi?a et al, 
2010). The gold standard consists of news articles, 
legal documents, knowledge-base articles, user 
manuals, and medical documents. Document pairs 
in the gold standard were rated by human judges as 
being parallel, strongly comparable, or weakly 
comparable. The evaluation results suggest that the 
comparability scores reliably reflect comparability 
levels. In addition, there is a strong correlation 
between human defined comparability levels and 
the confidence scores derived from the 
comparability metric, as the Pearson R correlation 
scores vary between 0.966 and 0.999, depending 
on the language pair.  
The Dictionary based metric (Su and Babych, 
2012b) is a lightweight approach, which uses 
bilingual dictionaries to lexically map documents 
from one language to another. The dictionaries are 
automatically generated via word alignment using 
GIZA++ (Och and Ney, 2000) on parallel corpora. 
For each word in the source language, the top two 
translation candidates (based on the word 
alignment probability in GIZA++) are retrieved as 
possible translations into the target language. This 
metric provides a much faster lexical translation 
process, although word-for-word lexical mapping 
produces less reliable translations than MT based 
translations. Moreover, the lower quality of text 
translation in the dictionary based metric does not 
necessarily degrade its performance in predicting 
comparability levels of comparable document 
pairs. The evaluation on the gold standard shows a 
strong correlation (between 0.883 and 0.999) 
between human defined comparability levels and 
the confidence scores of the metric. 
2.2 Parallel Sentence Extractor from 
Comparable Corpora 
Phrase-based statistical translation models are 
among the most successful translation models that 
currently exist (Callison-Burch et al, 2010). 
Usually, phrases are extracted from parallel 
corpora by means of symmetrical word alignment 
and/or by phrase generation (Koehn et al, 2003). 
Our toolkit exploits comparable corpora in order to 
find and extract comparable sentences for SMT 
training using a tool named LEXACC (?tef?nescu 
et al, 2012). 
LEXACC requires aligned document pairs (also 
m to n alignments) for sentence extraction. It also 
allows extraction from comparable corpora as a 
whole; however, precision may decrease due to 
larger search space. 
LEXACC scores sentence pairs according to five 
lexical overlap and structural matching feature 
functions. These functions are combined using 
linear interpolation with weights trained for each 
language pair and direction using logistic 
regression. The feature functions are: 
? a lexical (translation) overlap score for 
content words (nouns, verbs, adjectives, 
and adverbs) using GIZA++ (Gao and 
Vogel, 2008) format dictionaries; 
? a lexical (translation) overlap score for 
functional words (all except content 
words) constrained by the content word 
alignment from the previous feature; 
? the alignment obliqueness score, a measure 
that quantifies the degree to which the 
relative positions of source and target 
aligned words differ; 
? a score indicating whether strong content 
word translations are found at the 
beginning and the end of each sentence in 
the given pair; 
? a punctuation score which indicates 
whether the sentences have identical 
sentence ending punctuation. 
For different language pairs, the relevance of 
the individual feature functions differ. For 
instance, the locality feature is more important for 
the English-Romanian pair than for the English-
Greek pair. Therefore, the weights are trained on 
parallel corpora (in our case - 10,000 pairs). 
LEXACC does not score every sentence pair in 
the Cartesian product between source and target 
document sentences. It reduces the search space 
using two filtering steps (?tef?nescu et al, 2012). 
The first step makes use of the Cross-Language 
Information Retrieval framework and uses a search 
engine to find sentences in the target corpus that 
are the most probable translations of a given 
sentence. In the second step (which is optional), 
93
the resulting candidates are further filtered, and 
those that do not meet minimum requirements are 
eliminated.  
To work for a certain language pair, LEXACC 
needs additional resources: (i) a GIZA++-like 
translation dictionary, (ii) lists of stop-words in 
both languages, and (iii) lists of word suffixes in 
both languages (used for stemming). 
The performance of LEXACC, regarding 
precision and recall, can be controlled by a 
threshold applied to the overall interpolated 
parallelism score. The tool has been evaluated on 
news article comparable corpora. Table 1 shows 
results achieved by LEXACC with different 
parallelism thresholds on automatically crawled 
English-Latvian corpora, consisting of 41,914 
unique English sentences and 10,058 unique 
Latvian sentences. 
 
Threshold Aligned pairs Precision 
Useful 
pairs 
0.25 1036 39.19% 406 
0.3 813 48.22% 392 
0.4 553 63.47% 351 
0.5 395 76.96% 304 
0.6 272 84.19% 229 
0.7 151 88.74% 134 
0.8 27 88.89% 24 
0.9 0 - 0 
 
Table 1. English-Latvian parallel sentence extraction 
results on a comparable news corpus. 
 
Threshold Aligned pairs Precision Useful pairs
0.2 2324 10.32% 240 
0.3 1105 28.50% 315 
0.4 722 53.46% 386 
0.5 532 89.28% 475 
0.6 389 100% 389 
0.7 532 100% 532 
0.8 386 100% 386 
0.9 20 100% 20 
 
Table 2. English-Romanian parallel sentence extraction 
results on a comparable news corpus. 
Table 2 shows results for English-Romanian on 
corpora consisting of 310,740 unique English and 
81,433 unique Romanian sentences. 
Useful pairs denote the total number of parallel 
and strongly comparable sentence pairs (at least 
80% of the source sentence is a translation in the 
target sentence). The corpora size is given only as 
an indicative figure, as the amount of extracted 
parallel data greatly depends on the comparability 
of the corpora. 
2.3 Named Entity Extraction and Mapping 
The second workflow of the toolkit allows NE and 
terminology extraction and mapping. Starting with 
named entity recognition, the toolkit features the 
first NER systems for Latvian and Lithuanian 
(Pinnis, 2012). It also contains NER systems for 
English (through an OpenNLP NER2 wrapper) and 
Romanian (NERA). In order to map named entities, 
documents have to be tagged with NER systems 
that support MUC-7 format NE SGML tags.  
The toolkit contains the mapping tool NERA2. 
The mapper requires comparable corpora aligned 
in the document level as input. NERA2 compares 
each NE from the source language to each NE 
from the target language using cognate based 
methods. It also uses a GIZA++ format statistical 
dictionary to map NEs containing common nouns 
that are frequent in location names. This approach 
allows frequent NE mapping if the cognate based 
method fails, therefore, allowing increasing the 
recall of the mapper. Precision and recall can be 
tuned with a confidence score threshold. 
2.4 Terminology Mapping 
During recent years, automatic bilingual term 
mapping in comparable corpora has received 
greater attention in light of the scarcity of parallel 
data for under-resourced languages. Several 
methods have been applied to this task, e.g., 
contextual analysis (Rapp, 1995; Fung and 
McKeown, 1997) and compositional analysis 
(Daille and Morin, 2008). Symbolic, statistical, and 
hybrid techniques have been implemented for 
bilingual lexicon extraction (Morin and 
Prochasson, 2011). 
Our terminology mapper is designed to map 
terms extracted from comparable or parallel 
                                                          
2 Open NLP - http://incubator.apache.org/opennlp/. 
94
documents. The method is language independent 
and can be applied if a translation equivalents table 
exists for a language pair. As input, the application 
requires term-tagged bilingual corpora aligned in 
the document level. 
The toolkit includes term-tagging tools for 
English, Latvian, Lithuanian, and Romanian, but 
can be easily extended for other languages if a 
POS-tagger, a phrase pattern list, a stop-word list, 
and an inverse document frequency list (calculated 
on balanced corpora) are available. 
The aligner maps terms based on two criteria 
(Pinnis et al, 2012; ?tef?nescu, 2012): (i) a 
GIZA++-like translation equivalents table and (ii) 
string similarity in terms of Levenshtein distance 
between term candidates.  For evaluation, Eurovoc 
(Steinberger et al, 2002) was used. Tables 4 and 5 
show the performance figures of the mapper for 
English-Romanian and English-Latvian. 
 
Threshold P R F-measure
0.3 0.562 0.194 0.288 
0.4 0.759 0.295 0.425 
0.5 0.904 0.357 0.511 
0.6 0.964 0.298 0.456 
0.7 0.986 0.216 0.359 
0.8 0.996 0.151 0.263 
0.9 0.995 0.084 0.154 
 
Table 3. Term mapping performance for English-
Romanian. 
 
Threshold P R F-measure 
0.3 0.636 0.210 0.316 
0.4 0.833 0.285 0.425 
0.5 0.947 0.306 0.463 
0.6 0.981 0.235 0.379 
0.7 0.996 0.160 0.275 
0.8 0.996 0.099 0.181 
0.9 0.997 0.057 0.107 
 
Table 4. Term mapping performance for English-
Latvian. 
3 Conclusions and Related Information 
This demonstration paper describes the 
ACCURAT toolkit containing tools for multi-level 
alignment and information extraction from 
comparable corpora. These tools are integrated in 
predefined workflows that are ready for immediate 
use. The workflows provide functionality for the 
extraction of parallel sentences, bilingual NE 
dictionaries, and bilingual term dictionaries from 
comparable corpora. 
The methods, including comparability metrics, 
parallel sentence extraction and named entity/term 
mapping, are language independent. However, they 
may require language dependent resources, for 
instance, POS-taggers, Giza++ translation 
dictionaries, NERs, term taggers, etc.3 
 The ACCURAT toolkit is released under the 
Apache 2.0 licence and is freely available for 
download after completing a registration form4.  
Acknowledgements 
The research within the project ACCURAT 
leading to these results has received funding from 
the European Union Seventh Framework 
Programme (FP7/2007-2013), grant agreement no 
248347. 
References  
Sadaf Abdul-Rauf and Holger Schwenk. On the use of 
comparable corpora to improve SMT performance. 
EACL 2009: Proceedings of the 12th conference of 
the European Chapter of the Association for 
Computational Linguistics, Athens, Greece, 16-23. 
Sadaf Abdul-Rauf and Holger Schwenk. 2011. Parallel 
sentence generation from comparable corpora for 
improved SMT. Machine Translation, 25(4): 341-
375. 
ACCURAT D2.6 2011. Toolkit for multi-level 
alignment and information extraction from 
comparable corpora (http://www.accurat-project.eu). 
Dan Gusfield. 1997. Algorithms on strings, trees and 
sequences. Cambridge University Press. 
Chris Callison-Burch, Philipp Koehn, Christof Monz, 
Kay Peterson, Mark Przybocki and Omar Zaidan. 
2010. Findings of the 2010 Joint Workshop on 
Statistical Machine Translation and Metrics for 
Machine Translation. Proceedings of the Joint Fifth 
Workshop on Statistical Machine Translation and 
MetricsMATR, 17-53. 
B?atrice Daille and Emmanuel Morin. 2008. Effective 
compositional model for lexical alignment. 
Proceedings of the 3rd International Joint Conference 
                                                          
3 Full requirements are defined in the documentation of each 
tool (ACCURAT D2.6, 2011). 
4 http://www.accurat-project.eu/index.php?p=toolkit 
95
on Natural Language Processing, Hyderabad, India, 
95-102. 
Franz Josef Och and Hermann Ney. 2000. Improved 
statistical alignment models. Proceedings of the 38th 
Annual Meeting of the Association for 
Computational Linguistics, 440-447. 
Pascale Fung and Kathleen Mckeown. 1997. Finding 
terminology translations from non-parallel corpora. 
Proceedings of the 5th Annual Workshop on Very 
Large Corpora, 192-202. 
Qin Gao and Stephan Vogel. 2008. Parallel 
implementations of a word alignment tool. 
Proceedings of ACL-08 HLT: Software Engineering, 
Testing, and Quality Assurance for Natural Language 
Processing, June 20, 2008. The Ohio State 
University, Columbus, Ohio, USA, 49-57. 
Philipp Koehn, Franz Josef Och, and Daniel Marcu. 
2003. Statistical phrase-based translation. 
Proceedings of the Human Language Technology and 
North American Association for Computational 
Linguistics Conference (HLT/NAACL), May 27-
June 1, Edmonton, Canada. 
Philip Koehn. 2010. Statistical machine translation, 
Cambridge University Press. 
Bin Lu, Tao Jiang, Kapo Chow and Benjamin K. Tsou. 
2010. Building a large English-Chinese parallel 
corpus from comparable patents and its experimental 
application to SMT. Proceedings of the 3rd workshop 
on building and using comparable corpora: from 
parallel to non-parallel corpora, Valletta, Malta, 42-
48. 
Drago? ?tefan Munteanu and Daniel Marcu. 2006. 
Extracting parallel sub-sentential fragments from 
nonparallel corpora. ACL-44: Proceedings of the 21st 
International Conference on Computational 
Linguistics and the 44th annual meeting of the 
Association for Computational Linguistics, 
Morristown, NJ, USA, 81-88. 
Emmanuel Morin and Emmanuel Prochasson. 2011. 
Bilingual lexicon extraction from comparable 
corpora enhanced with parallel corpora. ACL HLT 
2011, 27-34. 
M?rcis Pinnis. 2012. Latvian and Lithuanian named 
entity recognition with TildeNER. Proceedings of the 
8th international conference on Language Resources 
and Evaluation (LREC 2012), Istanbul, Turkey. 
M?rcis Pinnis, Nikola Ljube?i?, Dan ?tef?nescu, Inguna 
Skadi?a, Marko Tadi?, Tatiana Gornostay. 2012. 
Term extraction, tagging, and mapping tools for 
under-resourced languages. Proceedings of the 10th 
Conference on Terminology and Knowledge 
Engineering (TKE 2012), June 20-21, Madrid, Spain. 
Reinhard Rapp. 1995. Identifying word translations in 
non-parallel texts. Proceedings of the 33rd annual 
meeting on Association for Computational 
Linguistics, 320-322.  
Jason R. Smith, Chris Quirk, and Kristina Toutanova. 
2010.  Extracting parallel sentences from comparable 
corpora using document level alignment. Proceedings 
of NAACL 2010, Los Angeles, USA. 
Dan ?tef?nescu. 2012. Mining for term translations in 
comparable corpora. Proceedings of the 5th 
Workshop on Building and Using Comparable 
Corpora (BUCC 2012) to be held at the 8th edition of 
Language Resources and Evaluation Conference 
(LREC 2012), Istanbul, Turkey, May 23-25, 2012. 
Ralf Steinberger, Bruno Pouliquen and Johan Hagman. 
2002. Cross-lingual document similarity calculation 
using the multilingual thesaurus Eurovoc. 
Proceedings of the 3rd International Conference on 
Computational Linguistics and Intelligent Text 
Processing (CICLing '02), Springer-Verlag London, 
UK, ISBN:3-540-43219-1. 
Inguna Skadi?a, Ahmet Aker, Voula Giouli, Dan Tufis, 
Rob Gaizauskas, Madara Mieri?a and Nikos 
Mastropavlos. 2010. Collection of comparable 
corpora for under-resourced languages. In 
Proceedings of the Fourth International Conference 
Baltic HLT 2010, IOS Press, Frontiers in Artificial 
Intelligence and Applications, Vol. 219, pp. 161-168. 
Fangzhong Su and Bogdan Babych. 2012a. 
Development and application of a cross-language 
document comparability metric. Proceedings of the 
8th international conference on Language Resources 
and Evaluation (LREC 2012), Istanbul, Turkey.  
Fangzhong Su and Bogdan Babych.  2012b. Measuring 
comparability of documents in non-parallel corpora 
for efficient extraction of (semi-) parallel translation 
equivalents. Proceedings of  EACL'12 joint 
workshop on Exploiting Synergies between 
Information Retrieval and Machine Translation 
(ESIRMT) and Hybrid Approaches to Machine 
Translation (HyTra), Avignon, France.  
Dan ?tef?nescu, Radu Ion and Sabine Hunsicker. 2012. 
Hybrid parallel sentence mining from comparable 
corpora. Proceedings of the 16th Conference of the 
European Association for Machine Translation 
(EAMT 2012), Trento, Italy.  
96
