Proceedings of the 5th International Workshop on Health Text Mining and Information Analysis (Louhi) @ EACL 2014, pages 106?115,
Gothenburg, Sweden, April 26-30 2014. c?2014 Association for Computational Linguistics
Detecting drugs and adverse events from Spanish health social media streams 
  Isabel Segura-Bedmar, Ricardo Revert, Paloma Mart?nez Computer Science Department,  Carlos III University of Madrid, Spain {isegura,rrevert,pmf}@inf.uc3m.es     Abstract 
To the best of our knowledge, this is the first work that does drug and adverse event detection from Spanish posts collected from a health social media. First, we created a gold-standard corpus annotated with drugs and adverse events from social media. Then, Textalytics, a multilingual text analysis engine, was applied to identify drugs and possible adverse events. Overall recall and precision were 0.80 and 0.87 for drugs, and 0.56 and 0.85 for adverse events. 1 Introduction 
It is well-known that adverse drug reactions (ADRs) are an important health problem. Indeed, ADRs are the 4th cause of death in hospitalized patients (Wester et al., 2008). Thus, the field of pharmacovigilance has received a great deal of attention due to the high and growing incidence of drug safety incidents (Bond and Raehl, 2006) as well as to their high associated costs (van Der Hooft et al., 2006). Since many ADRs are not captured during clinical trials, the major medicine regulatory agencies such as the US Food and Drug Administration (FDA) or the European Medicines Agency (EMA) require healthcare professionals to report all suspected adverse drug reactions. However, some studies have shown 
that ADRs are under-estimated due to the fact that they are reported by voluntary reporting systems (Bates et al., 2003; van Der Hooft et al., 2006; McClellan, 2007). In fact, it is estimated that only between 2 and 10 per cent of ADRs are reported (Rawlins, 1995). Healthcare professionals must perform many tasks during their workdays and thus finding the time to use these surveillance reporting systems is very difficult. Also, healthcare professionals tend to report only those ADRs on which they have absolute certainty of their existence. Several medicines agencies have implemented spontaneous patient reporting systems in order for patients to report ADRs themselves. Some of these systems are the MedWatch from the FDA, the Yellow Cards  from the UK Medicines agency (MHRA) or the website1 developed by the Spanish Agency of Medicines and Medical devices (AEMPS). Unlike reports from healthcare professionals, patient reports often provide more detailed and explicit information about ADRs (Herxheimer et al., 2010). Another important contribution of spontaneous patient reporting systems is to achieve patients having a more central role in their treatments. However, despite the fact that these systems are well-established, the rate of spontaneous patient reporting is very low probably because many                                                             
1 https://www.notificaram.es/  
106
patients are still unaware of their existence and even may feel embarrassed when describing their symptoms.  In this study, our hypothesis is that health-related social media can be used as a complementary data source to spontaneous reporting systems in order to detect unknown ADRs and thereby to increase drug safety. In recent days, social media on health information, just like has happened in other areas, have seen a tremendous growth (Hill et al., 2013). Examples of social media sites include blogs, online forums, social networking, and wikis, among many others. In this work, we focus on health forums where patients often exchange information about their personal medical experiences with other patients who suffer the same illness or receive similar treatment. Some patients may feel more comfortable sharing their medical experiences with each other rather than with their healthcare professionals. These forums contain a large number of comments describing patient experiences that would be a fertile source of data to detect unknown ADRs. Although there have been several research efforts devoted to developing systems for extracting ADRs from social media, all studies have focused on social media in English, and none of them have addressed the extraction from Spanish social media. Moreover, the problem is that these studies have not been compared with each other, and hence it is very difficult to determine the current ?state-of-art? of the techniques for ADRs extraction from social media. This comparison has not been performed due to the lack of a gold-standard corpus for ADRs. Thus, the goal of our work is twofold: i) to create a gold-standard corpus annotated with drugs and adverse events and ii) to develop a system to automatically extract mentions of drugs and adverse events from Spanish health-related social media sites. The corpus is composed by patients? comments from Forumclinic2, a health online networking website                                                             
2 http://www.forumclinic.org  
in Spanish. This is the first corpus of patient comments annotated with drugs and adverse events in Spanish. Also, we believe that this corpus will facilitate comparison for future ADRs detection from Spanish social media.  This is a preliminary work, in which we have only focused on the automatic detection of mentions of drugs and adverse events. Our final goal will be to develop a system to automatically extract drugs and their side effects. We hope our system will be beneficial to AEMPS as well as to the pharmaceutical industry in the improvement of their pharmacovigilance systems. 2 Related Work In recent years, the application of Natural Language Processing (NLP) techniques to mine adverse reactions from texts has been explored with promising results, mainly in the context of drug labels (Gurulingappa et al., 2013; Li et al., 2013; Kuhn et al., 2010), biomedical literature (Xu and Wang, 2013), medical case reports (Gurulingappa et al., 2012) and health records (Friedman, 2009; Sohn et al., 2011). However, as it will be described below, the extraction of adverse reactions from social media has received much less attention. In general, medical literature, such as scientific publications and drug labels, contains few grammatical and spelling mistakes. Another important advantage is that this type of texts can be easily linked to biomedical ontologies. Similarly, clinical records present specific medical terminology and can also be mapped to biomedical ontologies and resources. Meanwhile social media texts are markedly different from clinical records and scientific articles, and thereby the processing of social media texts poses additional challenges such as the management of meta-information included in the text (for example as tags in tweets) (Bouillot et al., 2013), the detection of typos and unconventional spelling, word shortenings (Neunedert et al, 2013; Moreira et al., 2013) and slang and emoticons (Balahur, 2013), among others. Moreover, these texts are often very short 
107
and with an informal nature, making the processing task extremely challenging. Regarding the identification of drug names in text, during the last four years there has been significant research efforts directed to encourage the development of systems for detecting these entities. Concretely, shared tasks such as DDIExtraction 2013 (Segura-Bedmar et al., 2013), CHEMDNER 2013 (Krallinger et al., 2013) or the i2b2 Medication Extraction challenge (Uzuner et al., 2010) have been held for the advancement of the state of the art in this problem. However, most of the work on recognizing drugs concerns either biomedical literature (for example, MedLine articles) or clinical records, thus leaving unexplored this task in social media streams.  Leaman et al., (2010) developed a system to automatically recognize adverse effects in user comments. A corpus of 3,600 comments from the DailyStrength health-related social network was collected and manually annotated with a total of 1,866 drug conditions, including beneficial effects, adverse effects, indications and others. To identify the adverse effects in the user comments, a lexicon was compiled from the following resources: (1) the COSTART vocabulary (National Library of Medicine, 2008), (2) the SIDER database (Kuhn et al., 2010), (3) MedEffect3 and (4) a list of colloquial phrases which were manually collected from the DailyStrength comments. The final lexicon consisted of 4,201 concepts (terms with the same CUI were grouped in the same concept). Finally, the terms in the lexicon were mapped against user comments to identify the adverse effects. In order to distinguish adverse effects from the other drug conditions (beneficial effects, indications and others), the systems used a list of verbs denoting indications (for example, help, work, prescribe). Drug name recognition was not necessary because the evaluation focused only on a set of four drugs: carbamazepine, olanzapine,                                                             
3 http://www.hc-sc.gc.ca/dhp-mps/medeff/index-eng.php 
trazodone and ziprasidone. The system achieved a good performance, with a precision of 78.3% and a recall of 69.9%.  An extension of this system was accomplished by Nikfarjam and Gonzalez (2011). The authors applied association rule mining to extract frequent patterns describing opinions about drugs. The rules were generated using the Apriori tool4, an implementation of the Apriori algorithm (Agrawal and Srikant, 1994) for association rule mining. The system was evaluated using the same corpus created for their previous work (Leaman et al., 2010), and which has been described above. The system achieved a precision of 70.01% and a recall of 66.32%. The main advantage of this system is that it can be easily adapted for other domains and languages. Another important advantage of this approach over a dictionary based approach is that the system is able to detect terms not included in the dictionary.  Benton et al., (2011) created a corpus of posts from several online forums about breast cancer, which later was used to extract potential adverse reactions from the most commonly used drugs to treat this disease: tamoxifen, anastrozole, letrozole and axemestane. The authors collected a lexicon of lay medical terms from websites and databases about drugs and adverse events. The lexicon was extended with the Consumer Health Vocabulary (CHV)5, a vocabulary closer to the lay terms, which patients usually use to describe their medical experiences. Then, pairs of terms co-occurring within a window of 20 tokens were considered. The Fisher?s exact test (Fisher, 1922) was used to calculate the probability that the two terms co-occurred independently by chance. To evaluate the system, the authors focused on the four drugs mentioned above, and then collected their adverse effects from their drug labels. Then, precision and recall were calculated by comparing the adverse effects from drug labels and the adverse effects obtained by the system.                                                             
4 http://www.borgelt.net/apriori.html 5 http://consumerhealthvocab.org 
108
The system obtained an average precision of 77% and an average recall of 35.1% for all four drugs.  UDWarning (Wu et al., 2012) is an ongoing prototype whose main goal is to extract adverse drug reactions from Google discussions. A knowledge base of drugs and their adverse effects was created by integrating information from different resources such as SIDER, DailyMed6, Drugs.com7 and MedLinePlus. The authors hypothesized that unknown adverse drug effects would have a high volume of discussions over the time. Thus, the systems should monitor the number of relevant discussions for each adverse drug effect. However, to the best of our knowledge, the UDWarning?s component devoted to the detection of unrecognized adverse drug effects has not been developed yet.  Bian et al., (2012) developed a system to detect tweets describing adverse drug reactions. The systems used a SVM classifier trained on a corpus of tweets, which were manually labeled by two experts. MetaMap (Aronson and Lang, 2010) was used to analyze the tweets and to find the UMLS concepts present in the tweets. The system produced poor results, mainly because tweets are riddled with spelling and grammar mistakes. Moreover, MetaMap is not a suitable tool to analyze this type of texts since patients do not usually use medical terminology to describe their medical experiences.  As it was already mentioned, the recognition of drugs in social media texts has hardly been tackled and little research has been conducted to extract relationships between drugs and their side effects, since most systems were focused on a given and fixed set of drugs. Most systems for extracting ADRs follow a dictionary-based approach. The main drawback of these systems is that they fail to recognize terms which are not included in the dictionary.  In addition, the dictionary-based approach is not able to handle the large number of spelling and grammar errors in social media texts. Moreover, the detection of                                                             
6 http://dailymed.nlm.nih.gov/dailymed/ 7 http://www.drugs.com/ 
ADRs has not been attempted for languages other than English. Indeed, automatic information extraction from Spanish-language social media in the field of health remains largely unexplored. Additionally, to the best of our knowledge, there is no corpus annotated with ADRs in social media texts available today. 3 Method  3.1 Corpus creation In order to create the first corpus in Spanish annotated with drugs and adverse events, we reviewed the main health-related social networks in Spanish language to select the most appropriate source of user comments. This corpus will be used to evaluate our system. Twitter was initially our preferred option due to the tremendous amount of tweets published each day (nearly 400 millions). However, we decided to discard it because Twitter does not seem to be the preferred source for users to describe their ADRs. Gonzalez et al. (2013) gathered a total of 42,327 in a one-month period, from which only 216 described ADRs. Although Facebook is the most popular social media and many Facebook groups dedicated to specific diseases have emerged in the last years, we discarded it because most of these groups usually have restricted access to their members.  Online health-related forums are an attractive source of data for our corpus due to their high dynamism, their great number of users as well as their easy access. After reviewing the main health forums in Spanish, we chose ForumClinic, an interactive program for patients, whose main goal is to provide rigorous information about specific diseases (such as breast cancer, HIV, bipolar disorder, depression, schizophrenia, ischemic heart disease, among others) and their treatments. Also, this platform aims to increase the participation of patients maintaining a discussion forum where patients can exchange information about their experiences. Figure 1 shows the distribution of user comments across the main twelve categories defined in the forum. We 
109
implemented a web crawler to gather all user comments published in ForumClinic to date. 
 Figure 1 Distribution of user comments. Then, we randomly selected a sample of 400 comments that were manually labeled with drugs and adverse events by two annotators with expertise in Pharmacovigilance. It should be noted that adverse events and ADRs do not refer to the same: while an adverse event may or may not be caused by a drug, an ADR is an adverse event that is suspected to be caused by a drug. A drug is a substance used in the treatment, cure, prevention or diagnosis of diseases. The corpus includes generic and brand drugs as well as drug families. Disagreements between the annotators were discussed and reconciled during the harmonization process, where a third annotator helped to make the final decision (some examples are shown in Table 1). All the mentions of drugs and adverse events were annotated, even those containing spelling or grammatical errors (for example, hemorrajia). Nominal anaphoric expressions, which refer to previous adverse events or drugs in the comment, were also included in the annotation. The annotators found 187 drugs (from which 40 were nominal anaphors and 14 spelling errors) and 636 adverse events (from which 48 were nominal anaphors and 17 spelling errors). The corpus is available for academic purposes8. To measure the inter-annotator agreement we used the F-measure metric. This metric approximates the kappa coefficient (Cohen, 1960) 
                                                            
8 http://labda.inf.uc3m.es/SpanishADRCorpus 
when the number of true negatives (TN) is very large (Hripcsak and Rothschild, 2005). In our case, we can state that the number of TN is very high since TN are all the terms that are not true positives, false positives nor false negatives. The F-measure was calculated by comparing the two corpora created by the two first annotators. The corpus labelled by the first annotator was considered the gold-standard. As it was expected, drugs exhibit a high IAA (0.89), while adverse events point to moderate agreement (0.59). As drugs have specific names and there are a limited number of them, it is possible to create a limited and controlled vocabulary to gather many of the existing drugs. On the other hand, patients can express their adverse events in many different ways due to the variability and richness of natural language. Sentence Final Decision 
De entre los distintos antiretrovirales, transcriptasa inversa, proteasa, integrasa y fusi?n, qu? grupo ser?a el m?s potente y cual el menos. 
Names in bold type refer to four families of inhibitors (that is, drug families), and thereby, they should be annotated. 
Como complemento proteico recomendamos el de los laboratorio Vegenat. Si compras los complementos del Decathlon, aseg?rate que contenga prote?nas. 
The mention ?complementos del Decathlon? should not be annotated as a drug since it is not a brand-marked drug.   
Table 1: Some examples of disagreements between annotators  3.2 Constructing a dictionary for drugs and adverse events Since our goal is to identify drugs and adverse events from user comments, the first challenge is to create a dictionary that contains all of the drugs and known adverse events.  CIMA9 is an online information center about medicines that provides all the daily updated official information about drugs. CIMA is                                                             
9 http://www.aemps.gob.es/cima/ 
110
maintained by the Spanish Agency for Medicines and Health Products (AEMPS). It includes information on all drugs authorized in Spain and their current authorization status. CIMA contains a total of 16,418 brand drugs and 2,228 generic drugs. Many brand drug names include additional information such as dosages, mode and route of administration, laboratory, among others (for example, ?ESPIDIFEN 400 mg GRANULADO PARA SOLUCION ORAL SABOR ALBARICOQUE? or ?ESPIDIFEN 600 mg GRANULADO PARA SOLUCION ORAL SABOR LIMON EFG, 20 sobres?). Since it is unlikely that these long names are used by patients, we implemented a method to shorten them by removing their additional information (for example, ?ESPIDIFEN?). After applying this method, the resulting list of brand drug names consisted of 3,662 terms. The main limitation of CIMA is that it only provides information about drugs authorized in Spain. That is, CIMA does not contain information about drugs approved only in Latin America. CIMA is free and offers a downloadable version in XML format. Thus, it provides the information in a well-structured format that makes it possible to directly extract generic and brand drug names as well as other related information such as their ATC codes, their pharmaceutical company, among others.  Unfortunately, CIMA does not provide information about drug groups. For this reason, we decided to consider the WHO ATC system10, a classification system of drugs, as an additional resource to obtain a list of drug groups.  MedDRA 11  is a medical terminology dictionary about events associated with drugs. It is a multilingual terminology, which includes the following languages: Chinese, Czech, Dutch, French, German, Hungarian, Italian, Japanese, Portuguese and Spanish. Its main goal is to provide a classification system for efficient communication of ADRs data between countries. The main advantage of MedDRA is that its                                                             
10 http://www.whocc.no/atc_ddd_index/ 11 http://www.meddra.org/ 
structured format allows easily obtaining a list of possible adverse events. MedDRA is composed of a five levels hierarchy. We collected the terms from the most specific level, "Lowest Level Terms" (LLTs)?. This level contains a total of 72,072 terms, which express how information is communicated in practice.  By analyzing the information from these resources, we found that none of them contained all of the drugs and adverse events. Patients usually use lay terms to describe their symptoms and their treatments. Unfortunately, many of these lay terms are not included in the above mentioned resources. Therefore, we decided to integrate additional information from other resources devoted to patients to build a more complete and comprehensive dictionary. There are several online websites that provide information to patients on drugs and their side effects in Spanish language. For example, MedLinePlus and Vademecum contain information about drugs and their side effects. These websites allow users to browse by generic or drug name, providing an information leaflet for each drug in a HTML page. Since these leaflets are unstructured, the extraction of drugs and their adverse effects is a challenging task. While drug names are often located in specific fields (such as title), their adverse events are usually descriptions of harmful reactions in natural language. We only developed a web crawler to browse and download pages related to drugs from Vademecum since this website provided an easier access to its drug pages than MedLinePlus. We plan to augment the list of drugs and adverse events by crawling MedLinePlus in future work.  After extracting drugs and adverse events from these different resources, we created a dictionary of drugs and adverse events. Table 2 shows the statistics of our final dictionary. 
Resource Total 
Generic drugs from CIMA 2,228 
Brand drugs from CIMA 3,662   
111
Drug group names from the ATC system 466 
Drug names (which are not in CIMA) from Vademecum 1,237 
Total Drugs: 7,593 
Table 2: Number of drugs in the dictionary. Resource Total 
Adverse events from MedDRA 72,072 
Adverse events from Vademecum (which are not in MedDRA) 2,793 
Total adverse events: 74,865 
Table 3: Number of adverse events in the dictionary. 3.3 Using Textalytics and gazetteers to identify drugs and adverse events Textalytics 12  is a multilingual text analysis engine to extract information from any type of texts such as tweets, posts, comments, news, contracts, etc. This tool offers a wide variety of functionalities such as text classification, entity recognition, concept extraction, relation extraction and sentiment analysis, among others. We used a plugin that integrates Textalytics with GATE. In this paper, we applied entity recognition provided by Textalytics, which follows a dictionary-based approach to identify entities in texts. We created a dictionary for drugs and adverse events from CIMA and MedDRA. This dictionary was integrated into Textalytics. Additionally, the lists of drugs and adverse events collected from the others resources (ATC system and Vademecum) were used to create GATE gazetteers.  4 Results and error analysis We evaluated the system on the corpus annotated with drugs and adverse events.  The results of this study show a precision of 87% for drugs and 85% for adverse events, and a recall of 80% for drugs and 56% for adverse events.  
                                                            
12 https://textalytics.com/ 
We performed an analysis to determine the main sources of error in the system. A sample of 50 user comments were randomly selected and analyzed. Regarding the detection of adverse events, the major cause of false negatives was the use of colloquial expressions to describe an adverse event. Phrases like ?me deja ko (it makes me KO)? or ?me cuesta m?s levantarme (it?s harder for me to wake up)? were used by patients for expressing their adverse events. These phrases are not included in our dictionary. A possible solution may be to create a lexicon containing this kind of idiomatic expressions. The second highest cause of false negatives for adverse events was due to the different lexical variations of the same adverse event. For example, ?depresi?n (depression)? is included in our dictionary, but their lexical variations such as ?depremido (depress)?, ?me deprimo (I get depressed)?, ?depresivo (depressive)? or ?deprimente (depressing)? were not detected by our system since they are not in our dictionary. Nominalization may be used to identify all the possible lexical variations of a same adverse event. Another important error source of false negatives was spelling mistakes (eg. hemorrajia instead of hemorragia). Many users have great difficulty in spelling unusual and complex technical terms. This error source may be handled by a more advanced matching method capable of dealing with the spelling error problem. The use of abbreviations (?depre? is an abbreviation for ?depression?) also produces false negatives. Techniques such as lemmatization and stemming may help to resolve this kind of abbreviations.  False positives for adverse events were mainly due to the inclusion of MedDRA terms referring to procedures (such as therapeutic, preventive or laboratory procedures) and tests in our dictionary. MedDRA includes terms for diseases, signs, abnormalities, procedures and tests.  We should have not included those terms referring to procedures and tests since they do not represent adverse events.  
112
The main source of false negatives for drugs seems to be that users often misspelled drug names. Some generic and brand drugs have complex names for patients. Some examples of misspelled drugs are avilify (Abilify) or rivotril (ribotril). Another important cause of false negatives was due to the fact that our dictionary does not include drugs approved in other countries than Spain (for example, Clorimipramina, Ureadin or Paxil). However, ForumClinic has a large number of users in Latin America. It is possible that these users have posted comments about some drugs that have only been approved in their countries. The third largest source of errors was the abbreviations for drug families. For instance, benzodiacepinas (benzodiazepine) is commonly used as benzos, which is not included in our dictionary. An interesting source of errors to point out is the use of acronyms referring to a combination of two or more drugs. For instance, FEC is a combination of Fluorouracil, Epirubicin and Cyclophosphamide, three chemotherapy drugs used to treat breast cancer. This combination of drugs is not registered in the resources (CIMA and Vademecum) used to create our dictionary. Most false positives for drugs were due to a lack of ambiguity resolution. Some drug names are common Spanish words such as ?All?? (a slimming drug) or ?Puntual? (a laxative). These terms are ambiguous and resolve to multiple senses, depending on the context in which they are used. Similarly, some drug names such as ?alcohol? or ?oxygen? can take a meaning different than the one of pharmaceutical substance. Another important cause of false positives is due to the use of drug family names as adjectives that specify an effect. This is the case of sedante (sedative) or antidepresivo (antidepressant), which can refer to a family of drugs, but also to the definition of an effect or disorder caused by a drug (sedative effects). 5 Conclusion  In this research, we created the first Spanish corpus of health user comments annotated with drugs and adverse events. The corpus is available 
for research. In this work, we only focused on the detection of the mentions of drugs and adverse events, but not the relationships among them. In future work, we plan to extend the system to detect the relationships between drugs and their side effects. Also, we would like to identify their indications and beneficial effects.  Acknowledgments This work was supported by the EU project TrendMiner [FP7-ICT287863], by the project MULTIMEDICA [TIN2010-20644-C03-01], and by the Research Network MA2VICMR [S2009/TIC-1542]. References  Rakesh Agrawal and Ramakrishnan Srikant. 1994. Fast algorithms for mining association rules. In Proc. 20th Int. Conf. Very Large Data Bases, 1215:487-499. Alan R Aronson and Francois-Michel Lang. 2010. An overview of MetaMap: historical perspective and recent advances. Journal of the American Medical Informatics Association, 17(3):229-236.  Alexandra Balahur. 2013. Sentiment Analysis in Social Media Texts. WASSA 2013, 120. David W. Bates, R Scott Evans, Harvey Murff, Peter D. Stetson, Lisa Pizziferri and George Hripcsak. 2003. Detecting adverse events using information technology. Journal of the American Medical Informatics Association, 10(2):115-128. Adrian Benton, Lye Ungar, Shawndra Hill, Sean Hennessy, Jun Mao, Annie Chung, Charles E. Leonarda and John H. Holmes. 2011. Identifying potential adverse effects using the web: A new approach to medical hypothesis generation. Journal of biomedical informatics, 44(6): 989-996. Jiang Bian, Umit Topaloglu and Fan Yu. 2012. Towards large-scale twitter mining for drug-related adverse events. In Proceedings of the 2012 international workshop on Smart health and wellbeing, 25-32. CA. Bond and Cynthia L. Raehl. 2006. Adverse drug reactions in United States hospitals. Pharmacotherapy: The Journal of Human Pharmacology and Drug Therapy, 26(5):601-608.  
113
Jacob Cohen. 1960. A coefficient of agreement for nominal scales. Educational and Psychol Meas ;20:37e46. Ronald A. Fisher. 1922. On the interpretation of ? 2 from contingency tables, and the calculation of P. Journal of the Royal Statistical Society, 85(1):87-94. Flavien Bouillot, Phan N. Hai, Nicolas B?chet, Sandra Bringay, Dino Ienco, Stan Matwin, Pascal Poncelet, Mathiue Roche and Maguelonne Teisseire. 2013. How to Extract Relevant Knowledge from Tweets?. Communications in Computer and Information Science.  Carol Friedman. 2009. Discovering novel adverse drug events using natural language processing and mining of the electronic health record. In Artificial Intelligence in Medicine. LNAI 5651:1 -5. Graciela H. Gonzalez, Matthew L Scotch and Garrick L Wallstrom. Mining Social Network Postings for Mentions of Potential Adverse Drug Reactions. HHS-NIH-NLM (9/10/2012 - 8/31/2016). Harsha Gurulingappa, Abdul Mateen-??Rajput and Luca Toldo. 2012. Extraction of potential adverse drug events from medical case reports. Journal of biomedical semantics. 3(1):15. Harsha Gurulingappa, Luca Toldo, Abdul Mateen-Rajput, Jan A. Kors, Adel Taweel and Yorki Tayrouz. 2013. Automatic detection of adverse events to predict drug label changes using text and data mining techniques. Pharmacoepidemiology and drug safety, 22(11):1189-1194. A Herxheimer, MR Crombag and TL Alves. 2010. Direct patient reporting of adverse drug reactions. A twelve-country survey & literature review. Health Action International (HAI). Europe. Paper Series Reference 01-2010/01. Shawndra Hill, Raina Merchant and Lile Ungar. (2013). Lessons Learned About Public Health from Online Crowd Surveillance. Big Data, 1(3):160-167.  George Hripcsak and Adam S. Rothschild. 2005. Agreement, the F-measure, and reliability in information retrieval. J Am Med Inform Assoc.12:296e8.  Martin Krallinger, Florian Leitner, Obdulia Rabal, Miguel Vazquez, Julen Oyarzabal and Alfonso Valencia. 2013. Overview of the chemical compound and drug name recognition 
(CHEMDNER) task. In BioCreative Challenge Evaluation Worksho. 2:2-33. Michael Kuhn, Monica Campillos, Ivica Letunic, Lars J. Jensen and Peer Bork. 2010. A side effect resource to capture phenotypic effects of drugs. Molecular systems biology, 6(343):1-6. Robert Leaman, Laura Wojtulewicz, Ryan Sullivan, Annie Skariah, Jian Yang and Graciela Gonzalez. 2010. Towards internet-age pharmacovigilance: extracting adverse drug reactions from user posts to health-related social networks. In Proceedings of the 2010 workshop on biomedical natural language processing. 117-125. Association for Computational Linguistics. Anne J. Leendertse, Antoine C. Egberts, Lennar J. Stoker, & Patricia M.L.A. van den Bemt. 2008. Frequency of and risk factors for preventable medication-related hospital admissions in the Netherlands. Archives of internal medicine, 168(17), 1890.  Qi Li, Louise Deleger, Todd Lingren, Haijun Zhai, Megan Kaiser, Laura Stoutenborough Anil G Jegga, Kevin B Cohen and Imre Solti. 2013. Mining FDA drug labels for medical conditions. BMC medical informatics and decision making, 13(1):53. Mark McClellan. 2007. Drug Safety Reform at the FDA-Pendulum Swing or Systematic Improvement?. New England Journal of Medicine, 356(17):1700-1702. Silvio Moreira, Joao Filgueiras, Bruno Martins, Francisco Couto and Mario J. Silva. 2013. REACTION: A naive machine learning approach for sentiment classification. In 2nd Joint Conference on. Lexical and Computational Semantics. 2:490-494.  Melanie Neunerdt, Michael Reyer and Rudolf Mathar. 2013. A POS Tagger for Social Media Texts trained on Web Comments. Polibits, 48:59-66. Azadeh Nikfarjam and Graciela H. Gonzalez. 2011. Pattern mining for extraction of mentions of adverse drug reactions from user comments. In AMIA Annual Symposium Proceedings, 2011:1019-1026. American Medical Informatics Association.  Isabel Segura-Bedmar, Paloma Mart?nez and Mar?a Herrero-Zazo. 2013. SemEval-2013 Task 9: Extraction of Drug-Drug Interactions from 
114
Biomedical Texts (DDIExtraction 2013). 3206(65): 341-351. Cornelis S. van Der Hooft, Miriam CJM Sturkenboom, Kees van Grootheest, Herre J. Kingma and Bruno HCh Stricker. 2006. Adverse drug reaction-related hospitalisations. Drug Safety, 29(2):161-168.  Hamish Cunningham. 2002. GATE, a general architecture for text engineering. Computers and the Humanities, 36(2):223-254. M Rawlins. 1995. Pharmacovigilance: paradise lost, regained or postponed? The William Withering Lecture 1994. Journal of the Royal College of Physicians of London, 29(1): 41-49.  Sunghwan Sohn, Jean-Pierre A. Kocher, Christopher G. Chute and Guergana K. Savova. 2011. Drug side effect extraction from clinical narratives of 
psychiatry and psychology patients. Journal of the American Medical Informatics Association, 18(Suppl 1):i144-i149. ?zlem Uzuner, Imre Solti and Eithon Cadag. 2010. Extracting medication information from clinical text. Journal of the American Medical Informatics Association. 17(5):514-518. Rong Xu and QuanQiu Wang. 2013. Large-scale extraction of accurate drug-disease treatment pairs from biomedical literature for drug repurposing. BMC Bioinformatics, 14(1):181. Karin Wester, Anna K. J?nsson, Olav Spigset, Henrik Druid and Staffan H?gg. 2008. Incidence of fatal adverse drug reactions: a population based study. British journal of clinical pharmacology, 65(4):573-579.  
115
Proceedings of the 2014 Workshop on Biomedical Natural Language Processing (BioNLP 2014), pages 98?106,
Baltimore, Maryland USA, June 26-27 2014.
c?2014 Association for Computational Linguistics
Extracting drug indications and adverse drug reactions from Spanish
health social media
Isabel Segura-Bedmar, Santiago de la Pe
?
na, Paloma Mart??nez
Computer Science Department
Carlos III University of Madrid, Spain
{isegura|spena|pmf}@inf.uc3m.es
Abstract
In this paper, we present preliminary re-
sults obtained using a system based on co-
occurrence of drug-effect pairs as a first
step in the study of detecting adverse drug
reactions and drug indications from social
media texts. To the best of our knowl-
edge, this is the first work that extracts
this kind of relationships from user mes-
sages that were collected from an online
Spanish health-forum. In addition, we also
describe the automatic construction of the
first Spanish database for drug indications
and adverse drug reactions.
1 Introduction
The activity of Pharmacovigilance (science de-
voted to the detection and prevention of any possi-
ble drug-related problem, including adverse drug
effects) has gained significant importance in the
recent decades, due to the growing number of drug
safety incidents (Bond and Raehl, 2006) as well as
to their high associated costs (van Der Hooft et al.,
2006).
Nowadays, the major medicine regulatory agen-
cies such as the US Food and Drug Administra-
tion (FDA) or the European Medicines Agency
(EMA) are working to create policies and prac-
tices to facilitate the reporting of adverse drug re-
actions (ADRs) by healthcare professionals and
patients. However, several studies have shown that
ADRs are under-estimated because many health-
care professionals do not have enough time to use
the ADR reporting systems (Bates et al., 2003;
van Der Hooft et al., 2006; McClellan, 2007) .
In addition, healthcare professionals tend to re-
port only those ADRs on which they have abso-
lute certainty of their existence. Unlike reports
from healthcare professionals, patient reports of-
ten provide more detailed and explicit information
about ADRs (Herxheimer et al., 2010). Neverthe-
less, the rate of ADRs reported by patients is still
very low probably because many patients are still
unaware of the existence of ADR reporting sys-
tems. In addition, patients may feel embarrassed
when describing their symptoms.
In this paper, we pose the hypothesis that
health-related social media can be used as a com-
plementary data source to the ADR reporting sys-
tems. In particular, health forums contain a large
number of comments describing patient experi-
ences that would be a fertile source of data to de-
tect unknown ADRs.
Several systems have been developed for ex-
tracting ADRs from social media (Leaman et al.,
2010; Nikfarjam and Gonzalez, 2011). However
to the best of our knowledge, only one work in the
literature has focused on the detection of ADRs
from social media in Spanish (Segura-Bedmar et
al., 2014). Indeed, it is only concerned with the
detection of mentions of drugs and their effects,
without dealing with the extraction of the relation-
ships between them. In this paper, we extend this
existing work in order to extract drug indications
and adverse drug reactions from user comments in
a Spanish health-forum.
The remaining of this paper is structured as fol-
lows: the next section surveys related work on
ADR detection from social media. Section 3 de-
scribes the creation of a gold-standard corpus we
used for our experiments. Sections 4 and 5 re-
spectively describe the techniques employed and
their results. Lastly, some conclusive remarks and
future perspectives are given in Section 6.
2 Related Work
In recent years, the application of Natural Lan-
guage Processing (NLP) techniques to mine drug
indications and adverse drug reactions from texts
has been explored with promising results, mainly
in the context of drug labels (Gurulingappa et al.,
98
2013; Li et al., 2013; Kuhn et al., 2010; Fung et al.,
2013), biomedical literature (Xu and Wang, 2013),
medical case reports (Gurulingappa et al., 2012)
and health records (Friedman, 2009; Sohn et al.,
2011). However, as it will be described below, the
extraction of these drug relationships from social
media has received much less attention.
To date, most of research on drug name recogni-
tion concerns either biomedical literature (Segura-
Bedmar et al., 2013; Krallinger et al., 2013) or
clinical records (Uzuner et al., 2010), thus leaving
unexplored this task in social media texts.
To our knowledge, there is no work in the lit-
erature that addresses the extraction of drug in-
dications from social media texts. Regarding the
detection of ADRs, Leaman et al., (2010) devel-
oped a system to automatically recognize adverse
effects in user comments from the DailyStrength
1
health-related social network. A corpus of 3,600
comments was manually annotated with a total
of 1,866 drug conditions, including beneficial ef-
fects, adverse effects, indications and others. This
study focused only on a set of four drugs, and
thereby, drug name recognition was not addressed.
The system used a dictionary-based approach to
identify adverse effects and a set of keywords in
order to distinguish adverse effects from the other
drug conditions. The dictionary consisted of 4,201
concepts, which were collected from several re-
sources such as the COSTART vocabulary (FDA,
1970), the SIDER database (Kuhn et al., 2010),
the MedEffect database
2
and a list of colloquial
phrases manually collected from the comments.
The system achieved a precision of 78.3% and a
recall of 69.9% (an f-measure of 73.9%).
Later, Nikfarjam and Gonzalez (2011) applied
association rule mining to extract frequent pat-
terns describing opinions about drugs. The rules
were generated using the Apriori tool, an imple-
mentation of the Apriori algorithm (Agrawal et al.,
1994) for association rule mining. The main ad-
vantage of this approach over the dictionary based
approach is that the system is able to detect terms
not included in the dictionary. The results of this
study were 70.01% precision and 66.32% recall,
for an f-measure of 67.96%.
Benton et al.,(2011) collected a lexicon of lay
medical terms from websites and databases about
drugs and their adverse effects to identify drug ef-
1
http://www.dailystrength.org/
2
http://www.hc-sc.gc.ca/dhp-mps/medeff/index-eng.php
fects. Then, the authors applied the Fishers exact
test (Fisher, 1922) to find all the drug-effect pairs
that co-occurred independently by chance in a cor-
pus of user comments. To evaluate the system, the
authors focused only on the four most commonly
used drugs to treat breast cancer. Precision and
recall were calculated by comparing the adverse
effects from their drug labels and the adverse ef-
fects obtained by the system. The system obtained
an average precision of 77% and an average recall
of 35.1% for all four drugs.
To the best of our knowledge, the system de-
scribed in (Segura-Bedmar et al., 2014) is the only
one that has dealt with the detection of drugs and
their effects from Spanish social media streams.
The system used the Textalytics tool
3
, which fol-
lows a dictionary-based approach to identify en-
tities in texts. The dictionary was constructed
based on the following resources: CIMA
4
and
MedDRA
5
. CIMA is an online information center
maintained by the Spanish Agency for Medicines
and Health Products (AEMPS). CIMA provides
information on all drugs authorized in Spain,
though it does not include drugs approved only in
Latin America. CIMA contains a total of 16,418
brand drugs and 2,228 generic drugs. Many brand
drugs have very long names because they include
additional information such as dosages, mode and
route of administration, laboratory, among oth-
ers (for example, ESPIDIFEN 400 mg GRANU-
LADO PARA SOLUCION ORAL SABOR ALBARI-
COQUE). For this reason, brand drug names were
simplified before being included in the dictionary.
After removing the additional information, the re-
sulting list of brand drug names consisted of 3,662
terms. Thus, the dictionary contained a total of
5,890 drugs. As regards to the effects, the au-
thors decided to use MedDRA, a medical multi-
lingual terminology dictionary about events asso-
ciated with drugs. MedDRA is composed of a five
levels hierarchy. A total of 72,072 terms from the
most specific level, ?Lowest Level Terms? (LLTs),
were integrated into the dictionary. In addition,
several gazetteers including drugs and effects were
collected from websites such as Vademecum
6
, a
Spanish online website that provides information
to patients on drugs and their side effects, and
3
https://textalytics.com/
4
http://www.aemps.gob.es/cima/
5
http://www.meddra.org/
6
http://www.vademecum.es/
99
the ATC system
7
, a classification system of drugs.
Thus, the dictionary and the two gazetteers con-
tained a total of 7,593 drugs and 74,865 effects.
The system yielded a precision of 87% for drugs
and 85% for effects, and a recall of 80% for drugs
and 56% for effects.
3 The SpanishADR corpus
Segura-Bedmar et al., (2014) created the first
Spanish corpus of user comments annotated with
drugs and their effects. The corpus consists of
400 comments, which were gathered from Fo-
rumClinic
8
, an interactive health social platform,
where patients exchange information about their
diseases and their treatments. The texts were man-
ually annotated by two annotators with expertise
in Pharmacovigilance. All the mentions of drugs
and effects were annotated, even those contain-
ing spelling or grammatical errors (for example,
hemorrajia (haemorrhage)). An assessment of the
inter-annotator agreement (IAA) was based on the
F-measure metric, which approximates the kappa
coefficient (Cohen, 1960) when the number of true
negatives (TN) is very large (Hripcsak and Roth-
schild, 2005). This assessment revealed that while
drugs showed a high IAA (0.89), their effects point
to moderate agreement (0.59). This may be due
to drugs have specific names and there are a lim-
ited number of them, however their effects are ex-
pressed by patients in many different ways due to
the variability and richness of natural language.
The corpus is available for academic purposes
9
.
In this paper, we extend the Spanish corpus to
incorporate the annotation of the relationships be-
tween drugs and their effects. In particular, we
annotated drug indications and adverse drug reac-
tions. These relationships were annotated at com-
ment level rather than sentence level, because de-
termining sentence boundaries in this kind of texts
can be problematic since many users often write
ungrammatical sentences. Guidelines were cre-
ated by two annotators (A1, A2) and a third an-
notator (A3) was trained on the annotation guide-
lines. Then, we split the corpus in three subsets,
and each subset was annotated by one annotator.
Finally, IAA was measured using kappa-statistic
on a sample of 97 documents randomly selected.
These documents were annotated by the three an-
7
http://www.whocc.no/atc ddd index/
8
http://www.forumclinic.org/
9
http://labda.inf.uc3m.es/SpanishADRCorpus
notators and annotation differences were analysed.
As Table 1 shows, the resulting corpus has 61
drug indications and 103 adverse drug reactions.
The average size of a comment is 72 tokens. The
average size of a text fragment describing a drug
indication is 34.7 tokens and 28.2 tokens for ad-
verse drug reactions.
Annotation Size
drugs 188
effect 545
drug indication 61
adverse drug reaction 103
Table 1: Size of the extended SpanishADR corpus.
As it is shown in Table 2, the IAA figures clearly
suggest that the annotators have high agreement
among them. We think that the IAA figures were
lower with the third annotator because he did not
participate in the guidelines development process,
and maybe, he was not trained well enough to per-
form the task. The main source of disagreement
among the annotators could arise from consider-
ing whether a term refers to a drug effect or not.
This is due to some terms are too general (such as
trastorno (upset), enfermedad (disease), molestia
(ache)). The annotators A1 and A2, in general,
ruled out all the relation instances where these
general terms occur, however they were consid-
ered and annotated by the third annotator.
A2 A3
A1 0.8 0.69
A2 - 0.68
Table 2: Pairwise IAA for each combination of
two annotators. IAA was measured using Cohens?
kappa statistic
4 Methods
In this contribution, some refinements to the sys-
tem (Segura-Bedmar et al., 2014) are proposed.
The error analysis performed in (Segura-Bedmar
et al., 2014) showed that most of false positives
for drug effects were mainly due to the inclu-
sion of MedDRA terms referring to procedures
and tests in the dictionary. MedDRA includes
terms for diseases, signs, abnormalities, proce-
dures and tests. Therefore, we decided not to in-
clude terms corresponding to the ?Procedimientos
100
m?edicos y quir?urgicos? and ?Exploraciones com-
plementarias? categories since they do not repre-
sent drug effects. Thus, we created a new dic-
tionary that only includes those terms from Med-
DRA that actually refer to drug effects. As in the
system (Segura-Bedmar et al., 2014), we applied
the Textalytics tool, which follows a dictionary-
based approach, to identify drugs and their ef-
fects occurring in the messages. We created a
GATE
10
pipeline application integrating the Tex-
talytic module and the gazetteers collected from
the Vademecum website and the ATC system pro-
posed in (Segura-Bedmar et al., 2014).
In addition, we created an additional gazetteer
in order to increase the coverage. We developed a
web crawler to browse and download pages related
to drugs from the MedLinePlus website
11
. Un-
like Vademecum, which only contains information
for drugs approved in Spain, MedLinePlus also
includes information about drugs only approved
in Latin America. Terms describing drug effects
were extracted by regular expressions from these
pages and then were incorporated into a gazetteer.
Then, the new gazetteer was also integrated into
the GATE pipeline application to identify drugs
and effects. Several experiments with different
settings of this pipeline are described in the fol-
lowing section.
The main contribution of this paper is to pro-
pose an approach for detecting relationships be-
tween drugs and their effects from user comments
in Spanish. The main difficulty in this task is that
although there are several English databases such
as SIDER or MedEffect with information about
drugs and their side effects, none of them are avail-
able for Spanish. Moreover, these resources do
not include drug indications. Thus, we have au-
tomatically built the first database, SpanishDrug-
EffectBD, with information about drugs, their drug
indications as well as their adverse drug reactions
in Spanish. Our first step was to populate the
database with all drugs and effects from our dic-
tionary. Figure 1 shows the database schema.
Active ingredients are saved into the Drug ta-
ble, and their synonyms and brand names into the
DrugSynset table. Likewise, concepts from Med-
DRA are saved into the Effect table and their syn-
onyms are saved into the EffectSynset table. As
it is shown in Figure 1, the database is also de-
10
http://gate.ac.uk/
11
http://www.nlm.nih.gov/medlineplus/spanish/
signed to store external ids from other databases.
Thus, drugs and effects can be linked to external
databases by the tables has externalIDDrug and
has externalIDDrug, respectively.
To obtain the relationships between drugs
and their effects, we developed several web
crawlers in order to gather sections describing
drug indications and adverse drug reactions from
drug package leaflets contained in the follow-
ing websites: MedLinePlus, Prospectos.Net
12
and
Prospectos.org
13
. Once these sections were down-
loaded, their texts were processed using the Text-
Alyticis tool to recognize drugs and their effects.
As each section (describing drug indications or ad-
verse drug effects) is linked to one drug, we de-
cided to consider the effects contained in the sec-
tion as possible relationships with this drug. The
type of relationship depends on the type of section:
drug indication or adverse drug reaction. Thus for
example, a pair (drug, effect) from a section de-
scribing drug indications is saved into the DrugEf-
fect table as a drug indication relationship, while if
the pair is obtained from a section describing ad-
verse drug reactions, then it is saved as an adverse
drug reaction. This database can be used to au-
tomatically identify drug indications and adverse
drug reactions from texts. Table 3 shows the num-
ber of drugs, effects and their relationships stored
into the database.
Concepts Synonyms
drugs 3,244 7,378
effects 16,940 52,199
drug indications 4,877
adverse drug reactions 58,633
Table 3: Number of drugs, effects, drug indica-
tions and adverse drug effects in the SpanishDrug-
EffectBD database.
As regards to the extraction of the relationships
between drugs and their effects occurring in the
corpus, first of all, texts were automatically an-
notated with drugs and effects using the GATE
pipeline application. Then, in order to generate
all possible relation instances between drugs and
their effects, we considered several sizes of win-
dow: 10, 20, 30, 40 and 50. Given a size n, any
pair (drug, effect) co-occurring within a window
of n-tokens are treated as a relation instance. Af-
12
http://www.prospectos.net/
13
http://prospectos.org/
101
Figure 1: The SpanishDrugEffectBD database schema
terwards, each relation instance is looked up in the
DrugEffect table in order to determine if it is a pos-
itive instance and if this is the case, its type: drug
indication or adverse drug reaction.
5 Experiments
Several experiments have been performed in order
to evaluate the contribution of the proposed meth-
ods and resources. Table 4 shows the results for
the named entity recognition task of drugs and ef-
fects using the dictionary integrated into the Tex-
tAlytic tool. The first row shows the results with
the dictionary built from the CIMA and MedDRA
resources, while the second one shows the results
obtained using the new dictionary in which those
MedDRA terms corresponding to ?Procedimien-
tos m?edicos y quir?urgicos? and ?Exploraciones
complementarias? categories were ruled out. As
it can be seen in this table, the new dictionary per-
mits to obtain a significant improvement with re-
spect to the original dictionary. For effect type,
precision was increased almost a 40% and re-
call a 7%. As regards to the contribution of the
gazetteers, the coverage for effects improves al-
most a 6% but with significant decrease in preci-
sion of almost 21%. Regarding to the detection of
drugs, the use of gazetteers improves slightly the
precision and achieves a significant improvement
in the recall of almost 35%.
The major cause of false negatives for drug ef-
fects was the use of colloquial expressions (such
as ?me deja ko? (it makes me ko)) to describe an
adverse effect. These phrases are not included in
our dictionary. Another important cause was the
dictionary and gazetteers do not cover all the lex-
ical variations of a same effect (for example de-
presi?on (depression), depresivo (depress), me de-
primo (I get depressed)). In addition, many false
negatives were due to spelling mistakes (for ex-
ample hemorrajia instead of hemorragia (haemor-
rhage)) and abbreviations (depre is an abbreviation
for depresi?on (depression)).
Regarding to the results for the relation extrac-
tion task, Table 5 shows the overall results ob-
tained using a baseline system, which considers
all pairs (drug, effect) occurring in messages as
positive relation instances, and a second approach
using the SpanishDrugEffectBD database (a rela-
tion instance is positive only if it is found into the
database). In both experiments, a window size of
250 tokens was used. The database provides a high
precision but with a very low recall of only 15%.
102
Approach Entity P R F1
Dictionary
drugs 0.84 0.46 0.60
effect 0.45 0.38 0.41
New dictionary
drugs 0.84 0.46 0.60
effect 0.84 0.45 0.59
New dictionary plus gazetteers
drugs 0.86 0.81 0.84
effect 0.63 0.51 0.57
Table 4: Precision, Recall and F-measure for named entity recognition task.
As it can be seen in Table 6, when the type of the
relationship is considered, the performance is even
lower.
Approach P R F1
Baseline 0.31 1.00 0.47
SpanishDrugEffectBD 0.83 0.15 0.25
Table 5: Overall results for relation extraction task
(window size of 250 tokens).
Relation P R F1
Drug indication 0.50 0.02 0.03
Adverse drug reaction 0.65 0.11 0.18
Table 6: Results for drug indications and adverse
drug reactions using only the database (window
size of 50 tokens).
Figure 2 shows an example of the output of our
system using the database. The system is able to
detect the relationship of indication between al-
prazolman and ansiedad (anxiety), but fails in de-
tecting the adverse drug reaction between alpra-
zolman and dependencia (dependency). The ad-
verse drug reaction between lamotrigina and ver-
tigo is detected.
The co-occurrence approach provides better re-
sults than the use of the database. Table 7 shows
the results for different size of windows. As it was
expected, small sizes provide better precision but
lower recall.
6 Conclusion
In this paper we present the first corpus where
400 user messages from a Spanish health social
network have been annotated with drug indica-
tions and adverse drug reactions. In addition, we
present preliminary results obtained using a very
simple system based on co-occurrence of drug-
effect pairs as a first step in the study of detecting
Size of window P R F1
10 0.71 0.24 0.36
20 0.59 0.53 0.56
30 0.52 0.69 0.59
40 0.47 0.77 0.58
50 0.44 0.84 0.58
Table 7: Overall results for relation extraction task
using the co-occurrence approach considering dif-
ferent window sizes.
adverse drug reactions and drug indications from
social media streams. Results show that there is
still much room for improvement in the identifica-
tion of drugs and effects, as well as in the extrac-
tion of drug indications and adverse drug rections.
As it was already mentioned in Section 2, the
recognition of drugs in social media texts has
hardly been tackled since most systems were fo-
cused on a given and fixed set of drugs. Moreover,
little research has been conducted to extract rela-
tionships between drugs and their effects from so-
cial media. Most systems for extracting ADRs fol-
low a dictionary-based approach. The main draw-
back of these systems is that they fail to recog-
nize terms which are not included in the dictio-
nary. In addition, the dictionary-based approach
is not able to handle the large number of spelling
and grammar errors in social media texts. More-
over, the detection of ADRs and drug indications
has not been attempted for languages other than
English. Indeed, automatic information extraction
from Spanish-language social media in the field of
health remains largely unexplored.
Social media texts pose additional challenges
to those associated with the processing of clin-
ical records and medical literature. These new
challenges include the management of meta-
information included in the text (for example as
tags in tweets)(Bouillot et al., 2013), the detection
of typos and unconventional spelling, word short-
103
Figure 2: An example of the output of the system using the database.
enings (Neunerdt et al., 2013; Moreira et al., 2013)
and slang and emoticons (Balahur, 2013), among
others. Another challenge that should be taken
into account is that while clinical records and med-
ical literature can be mapped to terminological re-
sources or biomedical ontologies, lay terminology
used by patients to describe their treatments and
their effects, in general, is not collected in any ter-
minological resource, which would facilitate the
automatic processing of this kind of texts.
In this paper, we also describe the automatic
creation of a database for drug indications and ad-
verse drug reactions from drug package leaflets.
To the best of our knowledge, this is the first
database available for Spanish. Although the use
of this database did not improve the results due
to its limited coverage, we think that the database
could be a valuable resource for future efforts.
Thus, we plan to translate the database into an on-
tology and to populate it with more entities and re-
lationships. As future work, we plan the following
tasks:
? To create a lexicon containing idiomatic ex-
pressions used by patients to express drug ef-
fects.
? To use techniques such as lemmatization and
stemming to cope with the problem of lexical
variability and to resolve abbreviations.
? To integrate advanced matching methods ca-
pable of dealing with the spelling error prob-
lem.
? To increase the size of the corpus.
? To apply a SVM classification approach to
extract relationships between drugs and their
effects.
We hope our research will be beneficial to
AEMPS as well as to the pharmaceutical indus-
try in the improvement of their pharmacovigilance
systems. Both the corpus and the database are
freely available online
14
for research purposes.
Acknowledgments
This work was supported by the EU project Trend-
Miner [FP7-ICT287863], by the project MUL-
TIMEDICA [TIN2010-20644-C03-01], and by
the Research Network MA2VICMR [S2009/TIC-
1542].
References
Rakesh Agrawal, Ramakrishnan Srikant, et al. 1994.
Fast algorithms for mining association rules. In
Proc. 20th int. conf. very large data bases, VLDB,
volume 1215, pages 487?499.
Alexandra Balahur. 2013. Sentiment analysis in social
media texts. WASSA 2013, page 120.
David W Bates, R Scott Evans, Harvey Murff, Peter D
Stetson, Lisa Pizziferri, and George Hripcsak. 2003.
Detecting adverse events using information technol-
ogy. Journal of the American Medical Informatics
Association, 10(2):115?128.
Adrian Benton, Lyle Ungar, Shawndra Hill, Sean Hen-
nessy, Jun Mao, Annie Chung, Charles E Leonard,
and John H Holmes. 2011. Identifying potential
adverse effects using the web: A new approach to
14
http://labda.inf.uc3m.es/SpanishADRCorpus
104
medical hypothesis generation. Journal of biomedi-
cal informatics, 44(6):989?996.
CA Bond and Cynthia L Raehl. 2006. Adverse drug
reactions in united states hospitals. Pharmacother-
apy: The Journal of Human Pharmacology and
Drug Therapy, 26(5):601?608.
Flavien Bouillot, Phan Nhat Hai, Nicolas B?echet, San-
dra Bringay, Dino Ienco, Stan Matwin, Pascal Pon-
celet, Mathieu Roche, and Maguelonne Teisseire.
2013. How to extract relevant knowledge from
tweets? In Information Search, Integration and Per-
sonalization, pages 111?120. Springer.
Jacob Cohen. 1960. A coefficient of agreement
for nominal scales. Educational and Psychological
Measurement, 20(1):37?46.
FDA. 1970. National adverse drug reaction directory:
Costart (coding symbols for thesaurus of adverse re-
action terms). Rock-Irvine, Charles F, Sharp,) r,
MD, Huntington Memorial Hospital, Stuart l, Sil-
verman, MD, University of California, los Angeles,
West los Angeles-Veterans Affairs Medical Center,
Osteoporosis Medical Center.
Ronald A Fisher. 1922. On the interpretation of chi-
squared from contingency tables, and the calcula-
tion of p. Journal of the Royal Statistical Society,
85(1):87?94.
Carol Friedman. 2009. Discovering novel adverse
drug events using natural language processing and
mining of the electronic health record. In Artificial
Intelligence in Medicine, pages 1?5. Springer.
Kin Wah Fung, Chiang S Jao, and Dina Demner-
Fushman. 2013. Extracting drug indication infor-
mation from structured product labels using natural
language processing. Journal of the American Med-
ical Informatics Association, 20(3):482?488.
Harsha Gurulingappa, Abdul Mateen-Rajput, Luca
Toldo, et al. 2012. Extraction of potential adverse
drug events from medical case reports. J Biomed
Semantics, 3(1):15.
Harsha Gurulingappa, Luca Toldo, Abdul Mateen Ra-
jput, Jan A Kors, Adel Taweel, and Yorki Tayrouz.
2013. Automatic detection of adverse events to pre-
dict drug label changes using text and data min-
ing techniques. Pharmacoepidemiology and drug
safety, 22(11):1189?1194.
A Herxheimer, MR Crombag, and TL Alves. 2010.
Direct patient reporting of adverse drug reactions. a
twelve-country survey & literature review. Health
Action International (HAI)(Europe). Amsterdam.
George Hripcsak and Adam S Rothschild. 2005.
Agreement, the f-measure, and reliability in infor-
mation retrieval. Journal of the American Medical
Informatics Association, 12(3):296?298.
Martin Krallinger, Florian Leitner, Obdulia Rabal,
Miguel Vazquez, Julen Oyarzabal, and Alfonso Va-
lencia. 2013. Overview of the chemical compound
and drug name recognition (chemdner) task. In
BioCreative Challenge Evaluation Workshop vol. 2,
page 2.
Michael Kuhn, Monica Campillos, Ivica Letunic,
Lars Juhl Jensen, and Peer Bork. 2010. A side ef-
fect resource to capture phenotypic effects of drugs.
Molecular systems biology, 6(1).
Robert Leaman, Laura Wojtulewicz, Ryan Sullivan,
Annie Skariah, Jian Yang, and Graciela Gonzalez.
2010. Towards internet-age pharmacovigilance: ex-
tracting adverse drug reactions from user posts to
health-related social networks. In Proceedings of
the 2010 workshop on biomedical natural language
processing, pages 117?125. Association for Compu-
tational Linguistics.
Qi Li, Louise Deleger, Todd Lingren, Haijun Zhai,
Megan Kaiser, Laura Stoutenborough, Anil G Jegga,
Kevin Bretonnel Cohen, and Imre Solti. 2013. Min-
ing fda drug labels for medical conditions. BMC
medical informatics and decision making, 13(1):53.
Mark McClellan. 2007. Drug safety reform at
the fdapendulum swing or systematic improvement?
New England Journal of Medicine, 356(17):1700?
1702.
Silvio Moreira, Joao Filgueiras, and Bruno Martins.
2013. Reaction: A naive machine learning approach
for sentiment classification. In Proceedings of the
7th InternationalWorkshop on Semantic Evaluation
(SemEval 2013), page 490.
Melanie Neunerdt, Michael Reyer, and Rudolf Mathar.
2013. A pos tagger for social media texts trained on
web comments. Polibits, 48:59?66.
Azadeh Nikfarjam and Graciela H Gonzalez. 2011.
Pattern mining for extraction of mentions of adverse
drug reactions from user comments. In AMIA An-
nual Symposium Proceedings, volume 2011, page
1019. American Medical Informatics Association.
Isabel Segura-Bedmar, Paloma Mart??nez, and Mar?a
Herrero-Zazo. 2013. Semeval-2013 task 9: Ex-
traction of drug-drug interactions from biomedical
texts (ddiextraction 2013). Proceedings of Semeval,
pages 341?350.
Isabel Segura-Bedmar, Ricardo Revert, and Paloma
Martnez. 2014. Detecting drugs and adverse events
from spanish social media streams. In Proceedings
of the 5th International Louhi Workshop on Health
Document Text Mining and Information Analysis
(Louhi 2014).
Sunghwan Sohn, Jean-Pierre A Kocher, Christopher G
Chute, and Guergana K Savova. 2011. Drug side ef-
fect extraction from clinical narratives of psychiatry
and psychology patients. Journal of the American
Medical Informatics Association, 18(Suppl 1):i144?
i149.
105
?Ozlem Uzuner, Imre Solti, and Eithon Cadag. 2010.
Extracting medication information from clinical
text. Journal of the American Medical Informatics
Association, 17(5):514?518.
Cornelis S van Der Hooft, Miriam CJM Sturkenboom,
Kees van Grootheest, Herre J Kingma, and Bruno
H Ch Stricker. 2006. Adverse drug reaction-related
hospitalisations. Drug Safety, 29(2):161?168.
Rong Xu and QuanQiu Wang. 2013. Large-scale
extraction of accurate drug-disease treatment pairs
from biomedical literature for drug repurposing.
BMC bioinformatics, 14(1):181.
106
