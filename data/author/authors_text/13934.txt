Proceedings of the ACL-08: HLT Student Research Workshop (Companion Volume), pages 55?60,
Columbus, June 2008. c?2008 Association for Computational Linguistics
A Subcategorization Acquisition System for French Verbs
Ce?dric Messiant
Laboratoire d?Informatique de Paris-Nord
CNRS UMR 7030 and Universite? Paris 13
99, avenue Jean-Baptiste Cle?ment, F-93430 Villetaneuse France
cedric.messiant@lipn.univ-paris13.fr
Abstract
This paper presents a system capable of auto-
matically acquiring subcategorization frames
(SCFs) for French verbs from the analysis of
large corpora. We applied the system to a large
newspaper corpus (consisting of 10 years of
the French newspaper ?Le Monde?) and ac-
quired subcategorization information for 3267
verbs. The system learned 286 SCF types for
these verbs. From the analysis of 25 represen-
tative verbs, we obtained 0.82 precision, 0.59
recall and 0.69 F-measure. These results are
comparable with those reported in recent re-
lated work.
1 Introduction
Many Natural Language Processing (NLP) tasks
require comprehensive lexical resources. Hand-
crafting large lexicons is labour-intensive and error-
prone. A growing body of research focuses therefore
on automatic acquisition of lexical resources from
text corpora.
One useful type of lexical information for NLP is
the number and type of the arguments of predicates.
These are typically expressed in simple syntac-
tic frames called subcategorization frames (SCFs).
SCFs can be useful for many NLP applications, such
as parsing (John Carroll and Briscoe, 1998) or in-
formation extraction (Surdeanu et al, 2003). Au-
tomatic acquisition of SCFs has therfore been an
active research area since the mid-90s (Manning,
1993; Brent, 1993; Briscoe and Carroll, 1997).
Comprehensive subcategorization information is
currently not available for most languages. French
is one of these languages: although manually built
syntax dictionaries do exist (Gross, 1975; van den
Eynde and Mertens, 2006; Sagot et al, 2006) none
of them are ideal for computational use and none
also provide frequency information important for
statistical NLP.
We developed ASSCI, a system capable of ex-
tracting large subcategorization lexicons for French
verbs from raw corpus data. Our system is based on
a approach similar to that of the well-known Cam-
bridge subcategorization acquisition system for En-
glish (Briscoe and Carroll, 1997; Preiss et al, 2007).
The main difference is that unlike the Cambridge
system, our system does not employ a set of pre-
defined SCF types, but learns the latter dynamically
from corpus data.
We have recently used ASSCI to acquire
LexSchem ? a large subcategorization lexicon for
French verbs ? from a raw journalistic corpus. and
have made the resulting resource freely available to
the community on the web (Messiant et al, 2008).
We describe our SCF acquisition system in sec-
tion 2 and explain the acquisition of a large subcat-
egorization lexicon for French and its evaluation in
section 3. We finally compare our study with work
previously achieved for English and French in sec-
tion 4.
2 ASSCI: The Acquisition System
Our SCF acquisition system takes as input corpus
data and produces a list of frames for each verb that
occurred more than 200 times in the corpus. It the
first system that automatically induces a large-scale
SCF information from raw corpus data for French.
55
Previous experiments focussed on a limited set of
verbs (Chesley and Salmon-Alt, 2006), or were
based on treebanks or on substantial manual work
(Gross, 1975; Kups?c?, 2007).
The system works in three steps:
1. verbs and surrounding phrases are extracted
from parsed corpus data;
2. tentative SCFs are built dynamically, based on
morpho-syntactic information and relations be-
tween the verb and its arguments;
3. a statistical filter is used to filter out incorrect
frames.
2.1 Preprocessing
When aiming to build a large lexicon for general
language, the input data should be large, balanced
and representative enough. Our system tags and
lemmatizes input data using TreeTagger (Schmid,
1994) and then syntactically analyses it using Syn-
tex (Bourigault et al, 2005). The TreeTagger is a
statistical, language independent tool for the auto-
matic annotation of part-of-speech and lemma in-
formation. Syntex is a shallow parser for extract-
ing lexical dependencies (such as adjective/noun or
verb/noun dependencies). Syntex obtained the best
precision and F-measure for written French text in
the recent EASY evaluation campaign1.
The dependencies extracted by the parser include
both arguments and adjuncts (such as location or
time phrases). The parsing strategy is based on
heuristics and statistics only. This is ideal for us
since no lexical information should be used when
the task is to acquire it. Syntex works on the general
assumption that the word on the left side of the verb
is the subject, where as the word on the right is the
object. Exceptions to this assumption are dealt with
a set of rules.
(2) Ces proprie?taires exploitants
ache`tent ferme le carburant la
1http://www.limsi.fr/Recherche/CORVAL/
easy
The scores and ranks of Syntex at this evaluation campaign
are available at http://w3.univ-tlse2.fr/erss/
textes/pagespersos/bourigault/syntex.html#
easy
compagnie .
(These owners buy fast the fuel to
the company.)
(3) is the preprocessed ASSCI input for sentence
(2) (after the TreeTagger annotation and Syntex?s
analysis).
(3) DetMP|ce|Ces|1|DET;3|
AdjMP|proprie?taire|proprie?taires|2|ADJ;3|
NomMP|exploitant|exploitants|3||DET;1,ADJ;2
VCONJP|acheter|ache`tent|4||ADV;5,OBJ;7,PREP;8
Adv|ferme|ferme|5|ADV;11|
DetMS|le|le|6|DET;7|
NomMS|carburant|carburant|7|OBJ;4|DET;6
Prep|a`|a`|8|PREP;4|NOMPREP;10
DetFS|le|la|9|DET;10|
NomFS|compagnie|compagnie|10|NOMPREP;8|DET;9
Typo|.|.|11||
2.2 Pattern Extractor
The pattern extraction module takes as input the
syntactic analysis of Syntex and extracts each verb
which is sufficiently frequent (the minimum of 200
corpus occurrences) in the syntactically analysed
corpus data, along with surrounding phrases. In
some cases, this module makes deeper use of the
dependency relations in the analysis. For example,
when a preposition is part of the dependencies, the
pattern extractor examines whether this preposition
is followed by a noun phrase or an infinitive clause.
(4) is the output of the pattern extractor for (3).
(4) VCONJP|acheter
NomMS|carburant|OBJ Prep|a`+SN|PREP
Note that +SN marks that the ?a`? preposition is
followed by a noun phrase.
2.3 SCF Builder
The next module examines the dependencies accord-
ing to their syntactic category (e.g., noun phrase)
and their relation to the verb (e.g., object), if any.
It constructs frames dynamically from the following
features: a nominal phrase; infinitive clause; prepo-
sitional phrase followed by a noun phrase; prepo-
sitional phrase followed by an infinitive clause;
subordinate clause and adjectival phrase. If the
verb has no dependencies, its SCF is ?intransitive?
(INTRANS). The number of occurrences for each
56
SCF and the total number of occurrences with each
verb are recorded.
This dynamic approach to SCF learning was
adopted because no sufficiently comprehensive list
of SCFs was available for French (most previous
work on English (e.g., (Preiss et al, 2007)) employs
a set of predefined SCFs because a relatively com-
prehensive lists are available for English).
The SCF candidate built for sentence (2) is
shown in (5)2.
(5) SN SP[a`+SN]
2.4 SCF Filter
The final module filters the SCF candidates. A fil-
ter is necessary since the output of the second mod-
ule is noisy, mainly because of tagging and parsing
errors but also because of the inherent difficulty of
argument-adjunct distinction which ideally requires
access to the lexical information we aim to acquire,
along with other information and criteria which cur-
rent NLP systems (and even humans) find it difficult
to identify. Several previous works (e.g., (Briscoe
and Carroll, 1997; Chesley and Salmon-Alt, 2006))
have used binomial hypothesis testing for filtering.
Korhonen et al (2000) proposes to use the maxi-
mum likelihood estimate and shows that this method
gives better results than the filter based on binomial
hypothesis testing. This method employs on a sim-
ple threshold over the relative frequencies of SCFs
candidates. (The maximum likehood estimate is still
an option in the current Cambridge system but an
improved version calculates it specific to different
SCFs - a method which we left for future work).
The relative frequency of the SCF i with the verb
j is calculated as follows:
rel freq(scfi, verbj) =
|scfi, verbj |
|verbj |
|scfi, verbj | is the number of occurrences of the
SCF i with the verb j and |verbj | is the total number
of occurrences of the verb j in the corpus.
These estimates are compared with the threshold
value to filter out low probability frames for each
verb. The effect of the choice of the threshold on the
results is discussed in section 3.
2SN stands for a noun phrase and SP for a prepositional
phrase
3 Experimental Evaluation
3.1 Corpus
In order to evaluate our system on a large corpus,
we gathered ten years of the French newspaper Le
Monde (two hundred millions words). It is one of
the largest corpus for French and ?clean? enough to
be easily and efficiently parsed. Because our aim
was to acquire a large general lexicon, we require
the minimum of 200 occurrences per each verb we
analysed using this system.
3.2 LexSchem: The Acquired Lexicon
3267 verbs were found with more than 200 oc-
currences in the corpus. From the data for these
verbs, we induced 286 distinct SCF types. We have
made the extracted lexicon freely available on the
web (http://www-lipn.univ-paris13.
fr/?messiant/lexschem.html) under the
LGPL-LR (Lesser General Public License For
Linguistic Resources) license. An interface which
enables viewing the SCFs acquired for each verb
and the verbs taking different SCFs is also available
at the same address. For more details of the lexicon
and its format, see (Messiant et al, 2008).
3.3 Gold Standard
Direct evaluation of subcategorization acquisition
performance against a gold standard based on a
manmade dictionary is not ideal (see e.g. (Poibeau
and Messiant, 2008)). However, this method is still
the easiest and fastest way to get an idea of the per-
formance of the system. We built a gold standard
using the SCFs found in the Tre?sor de la Langue
Franc?aise Informatise? (TFLI), a large French dictio-
nary available on the web3. We evaluated 25 verbs
listed in Appendix to evaluate our system. These
verbs were chosen for their heterogeneity in terms
of semantic and syntactic features, but also because
of their varied frequency in the corpus (from 200 to
100.000 occurences).
3.4 Evaluation Measures
We calculated type precision, type recall and F-
measure for these 25 verbs. We obtain the best
results (0.822 precision, 0.587 recall and 0.685 f-
measure) with the MLE threshold of 0.032 (see fig-
3http://atilf.atilf.fr/
57
Figure 1: The relation of the threshold on the F-Measure
Figure 2: The relation between precision and recall
ure 1). Figure 2 shows that even by substantially
lowering recall we cannot raise precision over 0.85.
Table 1 shows a comparison of three versions of
ASSCI for our 25 verbs:
? Unfiltered: the unfiltered output of ASSCI;
? ASSCI-1: one single threshold fixed to 0.0325;
? ASSCI-2: one INTRANS-specific threshold
(0.08) and the 0.0325-threshold for all other
cases.
These results reveal that the unfiltered version of
the lexicon is very noisy indeed (0.01 precision).
System Precision Recall F-Measure
Unfiltered 0.010 0.921 0.020
ASSCI-1 0.789 0.595 0.679
ASSCI-2 0.822 0.587 0.685
Table 1: Comparison of different versions of ASSCI
A simple threshold on the relative frequencies im-
proves the results dramatically (ASSCI-1).
Each step of the acquisition process generates er-
rors. For example, some nouns are tagged as a verb
by TreeTagger (e.g., in the phrase ?Le programme
d?armement (weapons program)?, ?programme? is
tagged verb). Syntex generates errors when identi-
fying dependencies: in some cases, it fails to iden-
tify relevant dependencies; in other cases incorrect
dependencies are generated. The SCF builder is an-
other source of error because of the ambiguity or the
lack of sufficient information to build some frames
(e.g. those involving pronouns). Finally, the filtering
module rejects some correct SCFs and accept some
incorrect ones. We could reduce these errors by im-
proving the filtering method or refining the thresh-
olds.
Many of the errors involve intransitive SCFs. We
tried to address this problem with an INTRANS-
specific threshold which is higher than others (see
the results for ASSCI-2). This improves the preci-
sion of the system slightly but does not substantially
reduce the number of false negatives. The intran-
sitive form of verbs is very frequent in corpus data
but it doesn?t appear in the gold standard. A better
evaluation (e.g., a gold standard based on manual
analysis of the corpus data and annotation for SCFs)
should not yield these errors. In other cases (e.g.
interpolated clauses), the parser is incapable of find-
ing the dependencies. In subsequent work we plan to
use an improved version of Syntex which deals with
this problem.
Our results (ASSCI-2) are similar with those ob-
tained by the only directly comparable work for
French (Chesley and Salmon-Alt, 2006) (0.87 pre-
cision and 0.54 recall). However, the lexicons show
still room for improvement, especially with recall.
In addition to the improvements in the method and
evaluation suggested above, we plan to evaluate
whether lexicons resulting from our system are use-
58
ful for NLP tasks and applications. For example,
John Carroll & al. shows that a parser can be signif-
icantly improved by using a SCF lexicon despite a
high error rate (John Carroll and Briscoe, 1998).
4 Related Work
4.1 Manual or Semi-Automatic Work
Most previous subcategorization lexicons for French
were built manually. For example, Maurice Gross
built a large French dictionnary called ?Les Tables
du LADL? (Gross, 1975). This dictionary is not easy
to employ for NLP use but work in progress is aimed
at addressing this problem (Gardent et al, 2005).
The Lefff is a morphological and syntactic lexicon
that contains partial subcategorization information
(Sagot et al, 2006), while Dicovalence is a manually
built valency dictionnary based on the pronominal
approach (van den Eynde and Blanche-Benveniste,
1978; van den Eynde and Mertens, 2006). There are
also lexicons built using semi-automatic approaches
e.g., the acquisition of subcategorization informa-
tion from treebanks (Kups?c?, 2007).
4.2 Automatic Work
Experiments have been made on the automatic
acquisition of subcategorization frames since mid
1990s (Brent, 1993; Briscoe and Carroll, 1997).
The first experiments were performed on English but
since the beginning of 2000s the approach has been
successfully applied to various other languages. For
example, (Schulte im Walde, 2002) has induced a
subcategorization lexicon for German verbs from a
lexicalized PCFG. Our approach is quite similar to
the work done in Cambridge. The Cambridge sys-
tem has been regularly improved and evaluated; and
it represents the state-of-the-art perfomance on the
task (Briscoe and Carroll, 1997; Korhonen et al,
2000; Preiss et al, 2007). In the latest paper, the au-
thors show that the method can be successfully ap-
plied to acquire SCFs not only for verbs but also for
nouns and adjectives (Preiss et al, 2007). A major
difference between these related works and ours is
the fact that we do not use a predefined set of SCFs.
Of course, the number of frames depends on the
language, the corpus, the domain and the informa-
tion taken into account (for example, (Preiss et al,
2007) used a list of 168 predefined frames for En-
glish which abstract over lexically-governed prepo-
sitions).
As far as we know, the only directly compara-
ble work on subcategorization acquisition for French
is (Chesley and Salmon-Alt, 2006) who propose
a method for acquiring SCFs from a multi-genre
corpus in French. Their work relies on the VISL
parser which have an ?unevaluated (and potentially
high) error rate? while our system relies on Syntex
which is, according to the EASY evaluation cam-
paign, the best parser for French (as evaluated on
general newspaper corpora). Additionally, we ac-
quired a large subcategorization lexicon (available
on the web) (286 distinct SCFs for 3267 verbs)
whereas (Chesley and Salmon-Alt, 2006) produced
only 27 SCFs for 104 verbs and didn?t produce any
lexicon for public release.
5 Conclusion
We have introduced a system which we have devel-
oped for acquiring large subcategorization lexicons
for French verbs. When the system was applied to
a large French newspaper corpus, it produced a lex-
icon of 286 SCFs corresponding to 3267 verbs. We
evaluated this lexicon by comparing the SCFs it pro-
duced for 25 test verbs to those included in a manu-
ally built dictionary and obtained promising results.
We made the automatically acquired lexicon freely
available on the web under the LGPL-LR license
(and through a web interface).
Future work will include improvements of the fil-
tering module (using e.g. SCF-specific thresholds
or statistical hypothesis testing) and exploration of
task-based evaluation in the context of practical NLP
applications and tasks such as the acquisition of se-
mantic classes from the SCFs (Levin, 1993).
Acknowledgements
Ce?dric Messiant?s PhD is funded by a DGA/CNRS
Grant. The research presented in this paper was also
supported by the ANR MDCO ?CroTal? project and
the British Council and the French Ministry of For-
eign Affairs -funded ?Alliance? grant.
References
Didier Bourigault, Marie-Paule Jacques, Ce?cile Fabre,
Ce?cile Fre?rot, and Sylwia Ozdowska. 2005. Syntex,
59
analyseur syntaxique de corpus. In Actes des 12e`mes
journe?es sur le Traitement Automatique des Langues
Naturelles, Dourdan.
Michael R. Brent. 1993. From Grammar to Lexicon:
Unsupervised Learning of Lexical Syntax. Computa-
tional Linguistics, 19:203?222.
Ted Briscoe and John Carroll. 1997. Automatic Ex-
traction of Subcategorization from Corpora. In Pro-
ceedings of the 5th ACL Conference on Applied Nat-
ural Language Processing, pages 356?363, Washing-
ton, DC.
Paula Chesley and Susanne Salmon-Alt. 2006. Au-
tomatic extraction of subcategorization frames for
French. In Proceedings of the Language Resources
and Evaluation Conference (LREC), Genua (Italy).
Claire Gardent, Bruno Guillaume, Guy Perrier, and In-
grid Falk. 2005. Maurice Gross? Grammar Lexicon
and Natural Language Processing. In 2nd Language
and Technology Conference, Poznan.
Maurice Gross. 1975. Me?thodes en syntaxe. Hermann,
Paris.
Guido Minnen John Carroll and Ted Briscoe. 1998.
Can subcategorisation probabilities help a statistical
parser? In Proceedings of the 6th ACL/SIGDAT Work-
shop on Very Large Corpora, Montreal (Canada).
Anna Korhonen, Genevieve Gorrell, and Diana Mc-
Carthy. 2000. Statistical filtering and subcategoriza-
tion frame acquisition. In Proceedings of the Confer-
ence on Empirical Methods in Natural Language Pro-
cessing and Very Large Corpora, Hong Kong.
Anna Kups?c?. 2007. Extraction automatique de cadres
de sous-cate?gorisation verbale pour le franc?ais a` par-
tir d?un corpus arbore?. In Actes des 14e`mes journe?es
sur le Traitement Automatique des Langues Naturelles,
Toulouse, June.
Beth Levin. 1993. English Verb Classes and Alter-
nations: a preliminary investigation. University of
Chicago Press, Chicago and London.
Christopher D. Manning. 1993. Automatic Acquisition
of a Large Subcategorization Dictionary from Cor-
pora. In Proceedings of the Meeting of the Association
for Computational Linguistics, pages 235?242.
Ce?dric Messiant, Anna Korhonen, and Thierry Poibeau.
2008. LexSchem : A Large Subcategorization Lex-
icon for French Verbs. In Language Resources and
Evaluation Conference (LREC), Marrakech.
Thierry Poibeau and Ce?dric Messiant. 2008. Do We Still
Need Gold Standard For Evaluation ? In Proceedings
of the Language Resources and Evaluation Conference
(LREC), Marrakech.
Judita Preiss, Ted Briscoe, and Anna Korhonen. 2007. A
System for Large-Scale Acquisition of Verbal, Nom-
inal and Adjectival Subcategorization Frames from
Corpora. In Proceedings of the Meeting of the Associ-
ation for Computational Linguistics, pages 912?918,
Prague.
Beno??t Sagot, Lionel Cle?ment, Eric de La Clergerie, and
Pierre Boullier. 2006. The Lefff 2 syntactic lexicon
for French: architecture, acquisition, use. In Proceed-
ings of the Language Resources and Evaluation Con-
ference (LREC), Genua (Italy).
Helmut Schmid. 1994. Probabilistic Part-of-Speech Tag-
ging Using Decision Trees. In International Con-
ference on New Methods in Language Processing,
Manchester, UK. unknown.
Sabine Schulte im Walde. 2002. A Subcategorisation
Lexicon for German Verbs induced from a Lexicalised
PCFG. In Proceedings of the 3rd Conference on Lan-
guage Resources and Evaluation, volume IV, pages
1351?1357, Las Palmas de Gran Canaria, Spain.
Mihai Surdeanu, Sanda M. Harabagiu, John Williams,
and Paul Aarseth. 2003. Using Predicate-Argument
Structures for Information Extraction. In Proceed-
ings of the Association of Computational Linguistics
(ACL), pages 8?15.
Karel van den Eynde and Claire Blanche-Benveniste.
1978. Syntaxe et me?canismes descriptifs :
pre?sentation de l?approche pronominale. Cahiers
de Lexicologie, 32:3?27.
Karel van den Eynde and Piet Mertens. 2006. Le dictio-
nnaire de valence Dicovalence : manuel d?utilisation.
Manuscript, Leuven.
Appendix ? List of test verbs
compter donner apprendre
chercher possder comprendre
concevoir proposer montrer
rendre s?abattre jouer
offrir continuer ouvrir
aimer croire exister
obtenir refuser programmer
acheter rester s?ouvrir
venir
60
Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 1056?1064,
Beijing, August 2010
Investigating the cross-linguistic potential of VerbNet -style classification
Lin Sun and Anna Korhonen
Computer Laboratory
University of Cambridge
ls418,alk23@cl.cam.ac.uk
Thierry Poibeau
LaTTiCe, UMR8094
CNRS & ENS
thierry.poibeau@ens.fr
Ce?dric Messiant
LIPN, UMR7030
CNRS & U. Paris 13
cedric.messiant@lipn.fr
Abstract
Verb classes which integrate a wide range
of linguistic properties (Levin, 1993) have
proved useful for natural language pro-
cessing (NLP) applications. However,
the real-world use of these classes has
been limited because for most languages,
no resources similar to VerbNet (Kipper-
Schuler, 2005) are available. We apply
a verb clustering approach developed for
English to French ? a language for which
no such experiment has been conducted
yet. Our investigation shows that not only
the general methodology but also the best
performing features are transferable be-
tween the languages, making it possible
to learn useful VerbNet style classes for
French automatically without language-
specific tuning.
1 Introduction
A number of verb classifications have been built to
support natural language processing (NLP) tasks
(Grishman et al, 1994; Miller, 1995; Baker et al,
1998; Palmer et al, 2005; Kipper-Schuler, 2005;
Hovy et al, 2006). These include both syntactic
and semantic classifications, as well as ones which
integrate aspects of both. Classifications which in-
tegrate a wide range of linguistic properties can
be particularly useful for NLP applications suffer-
ing from data sparseness. One such classification
is VerbNet (Kipper-Schuler, 2005). Building on
the taxonomy of Levin (1993), VerbNet groups
verbs (e.g. deliver, post, dispatch) into classes
(e.g. SEND) on the basis of their shared mean-
ing components and syntactic behaviour, identi-
fied in terms of meaning preserving diathesis al-
ternations. Such classes can be identified across
the entire lexicon, and they may also apply across
languages, since their meaning components are
said to be cross-linguistically applicable (Jack-
endoff, 1990).
Offering a powerful tool for generalization, ab-
straction and prediction, VerbNet classes have
been used to support many important NLP
tasks, including e.g. computational lexicography,
parsing, word sense disambiguation, semantic
role labeling, information extraction, question-
answering, and machine translation (Swier and
Stevenson, 2004; Dang, 2004; Shi and Mihalcea,
2005; Abend et al, 2008). However, to date their
exploitation has been limited because for most
languages, no Levin style classification is avail-
able.
Since manual classification is costly (Kipper
et al, 2008) automatic approaches have been pro-
posed recently which could be used to learn novel
classifications in a cost-effective manner (Joanis
et al, 2008; Li and Brew, 2008; O? Se?aghdha
and Copestake, 2008; Vlachos et al, 2009; Sun
and Korhonen, 2009). However, most work on
Levin type classification has focussed on English.
Large-scale research on other languages such as
German (Schulte im Walde, 2006) and Japanese
(Suzuki and Fukumoto, 2009) has focussed on se-
mantic classification. Although the two classifica-
tion systems have shared properties, studies com-
paring the overlap between VerbNet and WordNet
(Miller, 1995) have reported that the mapping is
only partial and many to many due to fine-grained
nature of classes based on synonymy (Shi and Mi-
halcea, 2005; Abend et al, 2008).
Only few studies have been conducted on Levin
style classification for languages other than En-
glish. In their experiment involving 59 verbs and
three classes, Merlo et al (2002) applied a su-
pervised approach developed for English to Ital-
ian, obtaining high accuracy (86.3%). In an-
other experiment with 60 verbs and three classes,
1056
they showed that features extracted from Chinese
translations of English verbs can improve English
classification. These results are promising, but
those from a later experiment by Ferrer (2004)
are not. Ferrer applied a clustering approach de-
veloped for English to Spanish, and evaluated it
against the manual classification of Va?zquez et al
(2000), constructed using criteria similar (but not
identical) to Levin?s. This experiment involving
514 verbs and 31 classes produced results only
slightly better than the random baseline.
In this paper, we investigate the cross-linguistic
potential of Levin style classification further. In
past years, verb classification techniques ? in par-
ticular unsupervised ones ? have improved con-
siderably, making investigations for a new lan-
guage more feasible. We take a recent verb clus-
tering approach developed for English (Sun and
Korhonen, 2009) and apply it to French ? a ma-
jor language for which no such experiment has
been conducted yet. Basic NLP resources (cor-
pora, taggers, parsers and subcategorization ac-
quisition systems) are now sufficiently developed
for this language for the application of a state-of-
the-art verb clustering approach to be realistic.
Our investigation reveals similarities between
the English and French classifications, support-
ing the linguistic hypothesis (Jackendoff, 1990)
and the earlier result of Merlo et al (2002)
that Levin classes have a strong cross-linguistic
basis. Not only the general methodology but
also best performing features are transferable be-
tween the languages, making it possible to learn
useful classes for French automatically without
language-specific tuning.
2 French Gold Standard
The development of an automatic verb classifi-
cation approach requires at least an initial gold
standard. Some syntactic (Gross, 1975) and se-
mantic (Vossen, 1998) verb classifications exist
for French, along with ones which integrate as-
pects of both (Saint-Dizier, 1998). Since none of
these resources offer classes similar to Levins?,
we followed the idea of Merlo et al (2002) and
translated a number of Levin classes from English
to French. As our aim was to to investigate the
cross-linguistic applicability of classes, we took
an English gold standard which has been used to
evaluate several recent clustering works ? that of
Sun et al (2008). This resource includes 17 fine-
grained Levin classes. Each class has 12 member
verbs whose predominant sense in English (ac-
cording to WordNet) belongs to that class.
Member verbs were first translated to French.
Where several relevant translations were identi-
fied, each of them was considered. For each can-
didate verb, subcategorization frames (SCFs) were
identified and diathesis alternations were consid-
ered using the criteria of Levin (1993): alterna-
tions must result in the same or extended verb
sense. Only verbs sharing diathesis alternations
were kept in the class.
For example, the gold standard class 31.1
AMUSE includes the following English verbs:
stimulate, threaten, shock, confuse, upset, over-
whelm, scare, disappoint, delight, exhaust, in-
timidate and frighten. Relevant French transla-
tions were identified for all of them: abattre,
accabler, briser, de?primer, consterner, ane?antir,
e?puiser, exte?nuer, e?craser, ennuyer, e?reinter, inon-
der. The majority of these verbs take similar SCFs
and diathesis alternations, e.g. Cette affaire e?crase
Marie (de chagrin), Marie est e?crase?e par le cha-
grin, Le chagrin e?crase Marie. However, stim-
uler (stimulate) and menacer (threaten) do not,
and they were therefore removed.
40% of translations were discarded from
classes because they did not share the same aler-
nations. The final version of the gold stan-
dard (shown in table 1) includes 171 verbs in 16
classes. Each class is named according to the
original Levin class. The smallest class (30.3) in-
cludes 7 verbs and the largest (37.3) 16. The aver-
age number of verbs per class is 10.7.
3 Verb Clustering
We performed an experiment where we
? took a French corpus and a SCF lexicon au-
tomatically extracted from that corpus,
? extracted from these resources a range of fea-
tures (lexical, syntactic and semantic) ? a
representative sample of those employed in
recent English experiments,
1057
Class No Class Verbs
9.1 PUT accrocher, de?poser, mettre, placer, re?partir, re?inte?grer, empiler, emporter, enfermer,
inse?rer, installer
10.1 REMOVE o?ter, enlever, retirer, supprimer, retrancher, de?barrasser, soustraire, de?compter, e?liminer
11.1 SEND envoyer, lancer, transmettre, adresser, porter, expe?dier, transporter, jeter, renvoyer, livrer
13.5.1 GET acheter, prendre, saisir, re?server, conserver, garder, pre?server, maintenir, retenir, louer,
affre?ter
18.1 HIT cogner, heurter, battre, frapper, fouetter, taper, rosser, brutaliser, e?reinter, maltraiter,
corriger,
22.2 AMALGAMATE incorporer, associer, re?unir, me?langer, me?ler, unir, assembler, combiner, lier, fusionner
29.2 CHARACTERIZE appre?hender, concevoir, conside?rer, de?crire, de?finir, de?peindre, de?signer, envisager,
identifier, montrer, percevoir, repre?senter, ressentir
30.3 PEER regarder, e?couter, examiner, conside?rer, voir, scruter, de?visager
31.1 AMUSE abattre, accabler, briser, de?primer, consterner, ane?antir, e?puiser, exte?nuer, e?craser, en-
nuyer, e?reinter, inonder,
36.1 CORRESPOND coope?rer, participer, collaborer, concourir, contribuer, prendre part, s?associer, travaille
37.3 MANNER OF
SPEAKING
ra?ler, gronder, crier, ronchonner, grogner, bougonner, maugre?er, rouspe?ter, grommeler,
larmoyer, ge?mir, geindre, hurler, gueuler, brailler, chuchoter
37.7 SAY dire, re?ve?ler, de?clarer, signaler, indiquer, montrer, annoncer, re?pondre, affirmer, certifier,
re?pliquer
43.1 LIGHT EMIS-
SION
briller, e?tinceler, flamboyer, luire, resplendir, pe?tiller, rutiler, rayonner., scintiller
45.4 CHANGE OF
STATE
me?langer, fusionner, consolider, renforcer, fortifier, adoucir, polir, atte?nuer, tempe?rer,
pe?trir, fac?onner, former
47.3 MODES OF BE-
ING
trembler, fre?mir, osciller, vaciller, vibrer, tressaillir, frissonner, palpiter, gre?siller, trem-
bloter, palpiter
51.3.2 RUN voyager, aller, se promener, errer, circuler, se de?placer, courir, bouger, naviguer, passer
Table 1: A Levin style gold standard for French
? clustered the features using a method which
has proved promising in both English and
German experiments: spectral clustering,
? evaluated the clusters both quantitatively (us-
ing the gold standard) and qualitatively,
? and compared the performance to that re-
cently obtained for English in order to gain
a better understanding of the cross-linguistic
and language-specific properties of verb clas-
sification
This work is described in the subsequent sections.
3.1 Data: the LexSchem Lexicon
We extracted the features for clustering from
LexSchem (Messiant et al, 2008). This large sub-
categorization lexicon provides SCF frequency in-
formation for 3,297 French verbs. It was acquired
fully automatically from Le Monde newspaper
corpus (200M words from years 1991-2000) us-
ing ASSCI ? a recent subcategorization acquisi-
tion system for French (Messiant, 2008). Systems
similar to ASSCI have been used in recent verb
classification works e.g. (Schulte im Walde, 2006;
Li and Brew, 2008; Sun and Korhonen, 2009).
Like these other systems, ASSCI takes raw corpus
data as input. The data is first tagged and lemma-
tized using the Tree-Tagger and then parsed us-
ing Syntex (Bourigault et al, 2005). Syntex is
a shallow parser which employs a combination
of statistics and heuristics to identify grammati-
cal relations (GRs) in sentences. ASSCI considers
GRs where the target verbs occur and constructs
SCFs from nominal, prepositional and adjectival
phrases, and infinitival and subordinate clauses.
When a verb has no dependency, its SCF is con-
sidered as intransitive. ASSCI assumes no pre-
defined list of SCFs but almost any combination
of permitted constructions can appear as a candi-
date SCF. The number of automatically generated
SCF types in LexSchem is 336.
Many candidate SCFs are noisy due to process-
ing errors and the difficulty of argument-adjunct
distinction. Most SCF systems assume that true
arguments occur in argument positions more fre-
quently than adjuncts. Many systems also inte-
grate filters for removing noise from system out-
put. When LexSchem was evaluated after filter-
1058
ing its F-measure was 69 ? which is similar to
that of other current SCF systems (Messiant et al,
2008) We used the unfiltered version of the lexi-
con because English experiments have shown that
information about adjuncts can help verb cluster-
ing (Sun et al, 2008).
4 Features
Lexical entries in LexSchem provide a variety of
material for verb clustering. Using this material,
we constructed a range of features for experimen-
tation. The first three include basic information
about SCFs:
F1: SCFs and their relative frequencies with indi-
vidual verbs. SCFs abstract over particles and
prepositions.
F2: F1, with SCFs parameterized for the tense
(the POS tag) of the verb.
F3: F2, with SCFs parameterized for prepositions
(PP).
The following six features include informa-
tion about the lexical context (co-occurrences)
of verbs. We adopt the best method of Li and
Brew (2008) where collocations (COs) are ex-
tracted from the window of words immediately
preceding and following a lemmatized verb. Stop
words are removed prior to extraction.
F4, F6, F8: COs are extracted from the window
of 4, 6 and 8 words, respectively. The relative
word position is ignored.
F5, F7, F9: F4, F6 and F8 with the relative word
position recorded.
The next four features include information
about lexical preferences (LP) of verbs in argu-
ment head positions of specific GRs associated
with the verb:
F10: LP(PREP): the type and frequency of prepo-
sitions in the preposition (PREP) relation.
F11: LP(SUBJ): the type and frequency of nouns
in the subject (SUBJ) relation.
F12: LP(IOBJ): the type and frequency of nouns
in the object (OBJ) and indirect object (IOBJ)
relation.
F13: LP(ALL): the combination of F10-F13.
The final two features refine SCF features with
LPs and semantic information about verb selec-
tional preferences (SP):
F14-F16: F1-F3 parameterized for LPs.
F17: F3 refined with SPs.
We adopt a fully unsupervised approach to SP
acquisition using the method of Sun and Korho-
nen (2009), with the difference that we determine
the optimal number of SP clusters automatically
following Zelnik-Manor and Perona (2004). The
method is introduced in the following section. The
approach involves (i) taking the GRs (SUBJ, OBJ,
IOBJ) associated with verbs, (ii) extracting all the
argument heads in these GRs, and (iii) clustering
the resulting N most frequent argument heads into
M classes. The empirically determined N 200
was used. The method produced 40 SP clusters.
5 Clustering Methods
Spectral clustering (SPEC) has proved promising
in previous verb clustering experiments (Brew
and Schulte im Walde, 2002; Sun and Korho-
nen, 2009) and other similar NLP tasks involv-
ing high dimensional feature space (Chen et al,
2006). Following Sun and Korhonen (2009) we
used the MNCut spectral clustering (Meila and
Shi, 2001) which has a wide applicability and
a clear probabilistic interpretation (von Luxburg,
2007; Verma and Meila, 2005). However, we ex-
tended the method to determine the optimal num-
ber of clusters automatically using the technique
proposed by (Zelnik-Manor and Perona, 2004).
Clustering groups a given set of verbs V =
{vn}Nn=1 into a disjoint partition of K classes.
SPEC takes a similarity matrix as input. All our
features can be viewed as probabilistic distribu-
tions because the combination of different fea-
tures is performed via parameterization. Thus we
use the Jensen-Shannon divergence (JSD) to con-
struct the similarity matrix. The JSD between
1059
two feature vectors v and v? is djsd(v, v?) =
1
2D(v||m)+ 12D(v?||m) where D is the Kullback-Leibler divergence, and m is the average of the v
and v?.
The similarity matrix W is constructed where
Wij = exp(?djsd(v, v?)). In SPEC, the simi-
larities Wij are viewed as the connection weight
ij of a graph G over V . The similarity matrix
W is thus the adjacency matrix for G. The de-
gree of a vertex i is di = ?Nj=1 wij . A cut be-
tween two partitions A and A? is defined to be
Cut(A,A?) =?m?A,n?A? Wmn.
The similarity matrix W is normalized into a
stochastic matrix P .
P = D?1W (1)
The degree matrix D is a diagonal matrix where
Dii = di.
It was shown by Meila and Shi (2001) that if P
has the K leading eigenvectors that are piecewise
constant1 with respect to a partition I? and their
eigenvalues are not zero, then I? minimizes the
multiway normalized cut(MNCut):
MNCut(I) = K ??Kk=1 Cut(Ik,Ik)Cut(Ik,I)
Pmn can be interpreted as the transition proba-
bility between vertices m,n. The criterion can
thus be expressed as MNCut(I) = ?Kk=1(1 ?
P (Ik ? Ik|Ik)) (Meila, 2001), which is the sum
of transition probabilities across different clusters.
This criterion finds the partition where the random
walks are most likely to happen within the same
cluster. In practice, the leading eigenvectors of P
are not piecewise constant. But we can extract the
partition by finding the approximately equal ele-
ments in the eigenvectors using a clustering algo-
rithm like K-Means.
As the value of K is not known beforehand, we
use Zelnik-Manor and Perona (2004)?s method to
estimate it. This method finds the optimal value
by minimizing a cost function based on the eigen-
vector structure of W .
Like Brew and Schulte im Walde (2002), we
compare SPEC against a K-Means baseline. We
used the Matlab implementation with euclidean
distance as the distance measure.
1The eigenvector v is piecewise constant with respect to
I if v(i) = v(j)?i, j ? Ik and k ? 1, 2...K
6 Experimental Evaluation
6.1 Data and Pre-processing
The SCF-based features (F1-F3 and F14-F17)
were extracted directly from LexSchem. The CO
(F4-F9) and LP features (F10-F13) were extracted
from the raw and parsed corpus sentences, respec-
tively, which were used for creating the lexicon.
Features that only appeared once were removed.
Feature vectors were normalized by the sum of the
feature values before clustering. Since our clus-
tering algorithms have an element of randomness,
we repeated clustering multiple times. We report
the results that minimize the distortion (the dis-
tance to cluster centroid).
6.2 Evaluation Measures
We employ the same measures for evaluation as
previously employed e.g. by O? Se?aghdha and
Copestake (2008) and Sun and Korhonen (2009).
The first measure is modified purity (mPUR) ?
a global measure which evaluates the mean preci-
sion of clusters. Each cluster is associated with its
prevalent class. The number of verbs in a cluster
K that take this class is denoted by nprevalent(K).
Verbs that do not take it are considered as errors.
Clusters where nprevalent(K) = 1 are disregarded
as not to introduce a bias towards singletons:
mPUR =
?
nprevalent(ki)>2
nprevalent(ki)
number of verbs
The second measure is weighted class accuracy
(ACC): the proportion of members of dominant
clusters DOM-CLUSTi within all classes ci.
ACC =
?C
i=1 verbs in DOM-CLUSTi
number of verbs
mPUR and ACC can be seen as a measure of pre-
cision(P) and recall(R) respectively. We calculate
F measure as the harmonic mean of P and R:
F = 2 ? mPUR ? ACCmPUR + ACC
The random baseline (BL) is calculated as fol-
lows: BL = 1/number of classes
7 Evaluation
7.1 Quantitative Evaluation
In our first experiment, we evaluated 116 verbs ?
those which appeared in LexSchem the minimum
1060
of 150 times. We did this because English exper-
iments had shown that due to the Zipfian nature
of SCF distributions, 150 corpus occurrences are
typically needed to obtain a sufficient number of
frames for clustering (Sun et al, 2008).
Table 2 shows F-measure results for all the fea-
tures. The 4th column of the table shows, for com-
parison, the results of Sun and Korhonen (2009)
obtained for English when they used the same fea-
tures as us, clustered them using SPEC, and evalu-
ated them against the English version of our gold
standard, also using F-measure2.
As expected, SPEC (the 2nd column) outper-
forms K-Means (the 3rd column). Looking at the
basic SCF features F1-F3, we can see that they per-
form significantly better than the BL method. F3
performs the best among the three features both
in French (50.6 F) and in English (63.3 F). We
therefore use F3 as the SCF feature in F14-F17
(the same was done for English).
In French, most CO features (F4-F9) outper-
form SCF features. The best result is obtained
with F7: 55.1 F. This is clearly better than the
best SCF result 50.6 (F3). This result is interesting
since SCFs correspond better than COs with fea-
tures used in manual Levin classification. Also,
SCFs perform considerably better than COs in the
English experiment (we only have the result for F4
available, but it is considerably lower than the re-
sult for F3). However, earlier English studies have
reported contradictory results (e.g. Li and Brew
(2008) showed that CO performs better than SCF
in supervised verb classification), indicating that
the role of CO features in verb classification re-
quires further investigation.
Looking at the LP features, F13 produces the
best F (52.7) for French which is slightly better
than the best SCF result for the language. Also
in English, F13 performs the best in this feature
group and yields a higher result than the best SCF-
based feature F3.
Parameterizing the best SCF feature F3 with LPs
(F14-16) and SPs (F17) yields better performance
2Note that the results for the two languages are not mu-
tually comparable due to differences in test sets, data sizes,
and feature extraction systems (see Section 8 for discussion).
The results for English are included so that we can compare
the relative performance of individual features in the two lan-
guages in question.
in French. F15 and F17 have the F of 54.5 and
54.6, respectively. These results are so close to
the result of the best CO feature F7 (55.1 ? which
is the highest result in this experiment) that the
differences are not statistically significant. In En-
glish, the results of F14-F17 are similarly good;
however, only F17 beats the already high perfor-
mance of F13.
On the basis of this experiment, it is difficult to
tell whether shallow CO features or more sophisti-
cated SCF-based features are better for French. In
the English experiment sophisticated features per-
formed better (the SCF-SP feature was the best).
However, the English experiment employed a
much larger dataset. These more sophisticated
features may suffer from data sparseness in our
French experiment since although we required the
minimum of 150 occurrences per verb, verb clus-
tering performance tends to improve when more
data is available, and given the fine-grained nature
of LexShem SCFs it is likely that more data is re-
quired for optimal performance.
We therefore performed another experiment
with French on the full set of 147 verbs, using
SPEC, where we investigated the effect of instance
filtering on the performance of the best features
from each feature group: F3, F7, F13 and F17.
The results shown in Table 3 reveal that the perfor-
mance of the features remains fairly similar until
the instance threshold of 1000. When 2000 occur-
rences per verb are used, the differences become
clearer, until at the threshold of 4000, it is obvious
that the most sophisticated SCF-SP feature F17 is
by far the best feature for French (65.4 F) and the
SCF feature F3 the second best (60.5 F). The CO-
feature F7 and the LP feature F13 are not nearly as
good (53.4 and 51.0 F).
Although the results at different thresholds are
not comparable due to the different number of
verbs and classes (see columns 2-3), the results
for features at the same threshold are. Those re-
sults suggest that when 2000 or more occurrences
per verb are used, most features perform like they
performed for English in the experiment of Sun
and Korhonen (2009), with CO being the least in-
formative3 and SCF-SP being the most informa-
3However, it is worth noting that CO is not a useless fea-
ture. As table 3 shows, when 150 or fewer occurrences are
1061
SPEC K Eng.
BL 6.7 6.7 6.7
F1 SCF 42.4 39.3 57.8
F2 SCF(POS) 45.9 40.3 46.7
F3 SCF(PP) 50.6 36.9 63.3
F4 CO(4) 50.3 38.2 40.9
F5 CO(4+loc) 48.8 26.3 -
F6 CO(6) 52.7 29.2 -
F7 CO(6+loc) 55.1 33.8 -
F8 CO(8) 54.2 36.4 -
F9 CO(8+loc) 54.6 37.2 -
F10 LP(PREP) 35.5 32.8 49.0
F11 LP(SUBJ) 33.7 23.6 -
F12 LP(OBJ) 50.1 33.3 -
F13 LP(ALL) 52.7 40.1 74.6
F14 SCF+LP(SUBJ) 50.3 40.1 71.7
F15 SCF+LP(OBJ) 54.5 35.6 74.0
F16 SCF+LP(SUBJ+OBJ) 53.4 36.2 73.0
F17 SCF+SP 54.6 39.8 80.4
Table 2: Results for all the features for French
(SPEC and K-means) and English (SPEC)
THR Verbs Cls F3 F7 F13 F17
0 147 15 43.7 57.5 43.3 50.1
50 137 15 47.9 56.1 44.8 49.1
100 125 15 49.2 54.3 44.8 49.5
150 116 15 50.6 55.1 52.7 54.6
200 110 15 54.9 52.9 49.7 52.5
400 96 15 52.7 52.9 43.9 53.2
1000 71 15 51.4 54.0 44.8 54.5
2000 59 12 52.3 45.9 42.7 53.5
3000 51 12 55.7 49.0 46.8 59.2
4000 43 10 60.5 53.4 51.0 65.4
Table 3: The effect of verb frequency
tive feature. The only exception is the LP feature
which performed better than CO in English.
7.2 Qualitative Evaluation
We conducted qualitative analysis of the clusters
for French: those created using SPEC with F17
and F3. Verbs in the gold standard classes 29.2,
36.1, 37.3, 37.7 and 47.3 (Table 1) performed
particularly well, with the majority of member
verbs found in the same cluster. These verbs
are ideal for clustering because they have distinc-
tive syntactic-semantic characteristics. For exam-
ple, verbs in 29.2 CHARACTERIZE class (e.g. con-
cevoir, conside?rer, de?peindre) not only have a very
specific meaning but they also take high frequency
SCFs involving the preposition comme (Eng. as)
available for a verb, CO outperforms all the other features in
French, compensating for data sparseness.
which is not typical to many other classes. Inter-
estingly, Levin classes 29.2, 36.1, 37.3, and 37.7
were among the best performing classes also in
the supervised verb classification experiment of
Sun et al (2008) because these classes have dis-
tinctive characteristics also in English.
The benefit of sophisticated features which
integrate also semantic (SP) information (F17)
is particularly evident for classes with non-
distinctive syntactic characteristics. For example,
the intransitive verbs in 43.1 LIGHT EMISSION
class (e.g. briller, e?tinceler, flamboyer) are diffi-
cult to cluster based on syntax only, but semantic
features work because the verbs pose strong SPs
on their subjects (entities capable of light emis-
sion). In the experiment of Sun et al (2008), 43.1
was the worst performing class, possibly because
no semantic features were used in the experiment.
The most frequent source of error is syntac-
tic idiosyncracy. This is particularly evident
for classes 10.1 REMOVE and 45.4 CHANGE OF
STATE. Although verbs in these classes can take
similar SCFs and alternations, only some of them
are frequent in data. For example, the SCF o?ter X
a` Y is frequent for verbs in 10.1, but not o?ter X
de Y. Although class 10.1 did not suffer from this
problem in the English experiment of Sun et al
(2008), class 45.4 did. Class 45.4 performs par-
ticularly bad in French also because its member
verbs are low in frequency.
Some errors are due to polysemy, caused partly
by the fact that the French version of the gold stan-
dard was not controlled for this factor. Some verbs
have their predominant senses in classes which are
missing in the gold standard, e.g. the most fre-
quent sense of retenir is memorize, not keep as in
the gold standard class 13.5.1. GET.
Finally, some errors are not true errors but
demonstrate the capability of clustering to learn
novel information. For example, the CHANGE
OF STATE class 45.4 includes many antonyms
(e.g. weaken vs. strenghten). Clustering (us-
ing F17) separates these antonyms, so that verbs
adoucir, atte?nuer and tempe?rer appear in one clus-
ter and consolider and renforcer in another. Al-
though these verbs share the same alternations,
their SPs are different. The opposite effect can be
observed when clustering maps together classes
1062
which are semantically and syntactically related
(e.g. 36.1 CORRESPOND and 37.7 SPEAK). Such
classes are distinct in Levin and VerbNet, al-
though should ideally be related. Cases such as
these show the potential of clustering in discover-
ing novel valuable information in data.
8 Discussion and Conclusion
When sufficient corpus data is available, there is
a strong correlation between the types of features
which perform the best in English and French.
When the best features are used, many individ-
ual Levin classes have similar performance in the
two languages. Due to differences in data sets
direct comparison of performance figures for En-
glish and French is not possible. When consid-
ering the general level of performance, our best
performance for French (65.4 F) is lower than the
best performance for English in the experiment of
Sun and Korhonen (2009). However, it does com-
pare favourably to the performance of other state-
of-the-art (even supervised) English systems (Joa-
nis et al, 2008; Li and Brew, 2008; O? Se?aghdha
and Copestake, 2008; Vlachos et al, 2009). This
is impressive considering that we experimented
with a fully unsupervised approach originally de-
veloped for another language.
When aiming to improve performance further,
employing larger data is critical. Most recent ex-
periments on English have employed bigger data
sets, and unlike us, some of them have only con-
sidered the predominant senses of medium-high
frequency verbs. As seen in section 7.1, such dif-
ferences in data can have significant impact on
performance. However, parser and feature ex-
traction performance can also play a big role in
overall accuracy, and should therefore be inves-
tigated further (Sun and Korhonen, 2009). The
relatively low performance of basic LP features
in French suggests that at least some of the cur-
rent errors are due to parsing. Future research
should investigate the source of error at different
stages of processing. In addition, it would be in-
teresting to investigate whether language-specific
tuning (e.g. using language specific features such
as auxiliary classes) can further improve perfor-
mance on French.
Earlier works most closely related to ours are
those of Merlo et al (2002) and Ferrer (2004).
Our results contrast with those of Ferrer who
showed that a clustering approach does not trans-
fer well from English to Spanish. However, she
used basic SCF and named entity features only,
and a clustering algorithm less suitable for high
dimensional data. Like us, Merlo et al (2002) cre-
ated a gold standard by translating Levin classes
to another language (Italian). They also applied a
method developed for English to Italian, and re-
ported good overall performance using features
developed for English. Although the experiment
was small (focussing on three classes and a few
features only) and involved supervised classifica-
tion, the results agree with ours.
These experiments support the linguistic hy-
pothesis that Levin style classification can be
cross-linguistically applicable. A clustering tech-
nique such as the one presented here could be used
as a tool for investigating whether classifications
are similar across a wider range of more diverse
languages. From the NLP perspective, the fact that
an unsupervised technique developed for one lan-
guage can be applied to another language with-
out the need for substantial tuning means that au-
tomatic techniques could be used to hypothesise
useful Levin style classes for further languages.
This, in turn, could facilitate the creation of mul-
tilingual VerbNets in the future.
9 Acknowledgement
Our work was funded by the Royal Society Uni-
versity Research Fellowship (AK), the Dorothy
Hodgkin Postgraduate Award (LS), the EPSRC
grants EP/F030061/1 and EP/G051070/1 (UK)
and the EU FP7 project ?PANACEA?.
References
Omri Abend, Roi Reichart, and Ari Rappoport. A
supervised algorithm for verb disambiguation into
VerbNet classes. In Proc. of COLING, pages 9?16,
2008.
Collin F. Baker, Charles J. Fillmore, and John B. Lowe.
The Berkeley FrameNet Project. In COLING-ACL,
pages 86?90, 1998.
Didier Bourigault, Marie-Paule Jacques, Ce?cile Fabre,
Ce?cile Fre?rot, and Sylwia Ozdowska. Syntex,
analyseur syntaxique de corpus. In Actes des
1063
12e`mes journe?es sur le Traitement Automatique des
Langues Naturelles, 2005.
Chris Brew and Sabine Schulte im Walde. Spectral
clustering for German verbs. In Proc. of EMNLP,
pages 117?124, 2002.
Jinxiu Chen, Dong-Hong Ji, Chew Lim Tan, and
Zheng-Yu Niu. Unsupervised relation disambigua-
tion using spectral clustering. In Proc. of COL-
ING/ACL, pages 89?96, 2006.
Hoa Trang Dang. Investigations into the Role of Lexi-
cal Semantics in Word Sense Disambiguation. PhD
thesis, CIS, University of Pennsylvania, 2004.
Eva Esteve Ferrer. Towards a semantic classification of
Spanish verbs based on subcategorisation informa-
tion. In Proc. of ACL Student Research Workshop,
2004.
Ralph Grishman, Catherine Macleod, and Adam Mey-
ers. Comlex syntax: building a computational lexi-
con. In Proc. of COLING, pages 268?272, 1994.
Maurice Gross. Me?thodes en syntaxe. Hermann, Paris,
1975.
Eduard Hovy, Mitch Marcus, Martha Palmer,
L. Ramshaw, and R. Weischedel. Ontonotes: The
90% solution. In HLT/NAACL, 2006.
Ray Jackendoff. Semantic Structures. The MIT Press,
Cambridge, MA, 1990.
Eric Joanis, Suzanne Stevenson, and David James. A
general feature space for automatic verb classifica-
tion. Nat. Lang. Eng., 14(3):337?367, 2008.
Karin Kipper, Anna Korhonen, Neville Ryant, and
Martha Palmer. A large-scale classification of En-
glish verbs. Language Resources and Evaluation,
42:21?40, 2008.
Karin Kipper-Schuler. VerbNet: A broad-coverage,
comprehensive verb lexicon. University of Pennsyl-
vania, PA, 2005.
Beth. Levin. English verb classes and alternations: A
preliminary investigation. Chicago, IL, 1993.
Jianguo Li and Chris Brew. Which Are the Best Fea-
tures for Automatic Verb Classification. In Proc. of
ACL, pages 434?442, 2008.
Marina. Meila. The multicut lemma. Technical report,
University of Washington, 2001.
Marina Meila and Jianbo Shi. A random walks view of
spectral segmentation. In AISTATS, 2001.
Paola Merlo, Suzanne Stevenson, Vivian Tsang, and
Gianluca Allaria. A multilingual paradigm for auto-
matic verb classification. In Proc. of ACL, 2002.
Ce?dric Messiant. ASSCI : A subcategorization frames
acquisition system for French. In Proc. of ACL Stu-
dent Research Workshop, pages 55?60, 2008.
Ce?dric Messiant, Thierry Poibeau, and Anna Korho-
nen. LexSchem: a Large Subcategorization Lexicon
for French Verbs. In Proc. of LREC, 2008.
George A. Miller. WordNet: a lexical database for En-
glish. Communications of the ACM, 1995.
Diarmuid O? Se?aghdha and Ann Copestake. Semantic
classification with distributional kernels. In Proc. of
COLING, pages 649?656, 2008.
Martha Palmer, Daniel Gildea, and Paul Kingsbury.
The proposition bank: An annotated corpus of se-
mantic roles. Computational Linguistics, 3(1):71?
106, 2005.
Patrick Saint-Dizier. Verb Semantic Classes Based on
?alternations? and WordNet-like criteria . In P. Saint-
Dizier, editor, Predicative Forms in Natural lan-
guage and lexical Knowledge Bases , pages 247?
279. Kluwer Academic, 1998.
Sabine Schulte im Walde. Experiments on the Auto-
matic Induction of German Semantic Verb Classes.
Computational Linguistics, 2006.
Lei Shi and Rada Mihalcea. Putting pieces together:
Combining FrameNet, VerbNet and WordNet for ro-
bust semantic parsing. In Proc. of CICLing, pages
100?111, 2005.
Lin Sun and Anna Korhonen. Improving verb cluster-
ing with automatically acquired selectional prefer-
ences. In Proc. of EMNLP, pages 638?647, 2009.
Lin Sun, Anna Korhonen, and Yuval Krymolowski.
Verb class discovery from rich syntactic data. LNCS,
4919:16, 2008.
Yoshimi Suzuki and Fumiyo Fukumoto. Classify-
ing Japanese Polysemous Verbs based on Fuzzy C-
means Clustering. In Proc. of TextGraphs-4, pages
32?40, 2009.
Robert Swier and Suzanne Stevenson. Unsupervised
semantic role labelling. In Proc. of EMNLP, 2004.
Gloria Va?zquez, Ana Ferna?ndez, Irene Castello?n, and
M. Antonia Mart??. Clasificacio?n verbal: Alternan-
cias de dia?tesis. In Quaderns de Sintagma. Univer-
sitat de Lleida, 2000.
Deepak Verma and Marina Meila. A comparison of
spectral clustering algorithms. Technical report, De-
partment of CSE University of Washington Seattle,
2005.
Andreas Vlachos, Anna Korhonen, and Zoubin
Ghahramani. Unsupervised and Constrained Dirich-
let Process Mixture Models for Verb Clustering. In
Proc. of the Workshop on on GEMS, pages 74?82,
2009.
Ulrike von Luxburg. A tutorial on spectral clustering.
STAT COMPUT, 17:395 ? 416, 2007.
Piek Vossen. EuroWordNet: A Multilingual Database
with Lexical Semantic Networks. Kluwer Academic
Publishers, Dordrecht, 1998.
Lihi Zelnik-Manor and Pietro Perona. Self-tuning
spectral clustering. NIPS, 17(1601-1608):16, 2004.
1064
