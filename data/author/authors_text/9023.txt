A Unified Statistical Model for the Identification of English
BaseNP
Endong Xun
Microsoft Research China
No. 49 Zhichun Road Haidian District
100080, China,
i-edxun@microsoft.com
Ming Zhou
Microsoft Research China
No. 49 Zhichun Road Haidian District
100080, China,
Mingzhou@microsoft.com
Changning Huang
Microsoft Research China
No. 49 Zhichun Road Haidian District
100080, China,
cnhuang@microsoft.com
Abstract
This paper presents a novel statistical
model for automatic identification of
English baseNP. It uses two steps: the N-
best Part-Of-Speech (POS) tagging and
baseNP identification given the N-best
POS-sequences. Unlike the other
approaches where the two steps are
separated, we integrate them into a unified
statistical framework. Our model also
integrates lexical information. Finally,
Viterbi algorithm is applied to make
global search in the entire sentence,
allowing us to obtain linear complexity for
the entire process. Compared with other
methods using the same testing set, our
approach achieves 92.3% in precision and
93.2% in recall. The result is comparable
with or better than the previously reported
results.
1 Introduction
Finding simple and non-recursive base Noun
Phrase (baseNP) is an important subtask for
many natural language processing applications,
such as partial parsing, information retrieval and
machine translation. A baseNP is a simple noun
phrase that does not contain other noun phrase
recursively, for example, the elements within
[...] in the following example are baseNPs,
where NNS, IN VBG etc are part-of-speech tags
[as defined in M. Marcus 1993].
[Measures/NNS] of/IN [manufacturing/VBG
activity/NN] fell/VBD more/RBR than/IN
[the/DT overall/JJ measures/NNS] ./.
Figure 1: An example sentence with baseNP
brackets
A number of researchers have dealt with the
problem of baseNP identification (Church 1988;
Bourigault 1992; Voutilainen 1993; Justeson &
Katz 1995). Recently some researchers have
made experiments with the same test corpus
extracted from the 20th section of the Penn
Treebank Wall Street Journal (Penn Treebank).
Ramshaw & Markus (1998) applied transform-
based error-driven algorithm (Brill 1995) to
learn a set of transformation rules, and using
those rules to locally updates the bracket
positions. Argamon, Dagan & Krymolowski
(1998) introduced a memory-based sequences
learning method, the training examples are
stored and generalization is performed at
application time by comparing subsequence of
the new text to positive and negative evidence.
Cardie & Pierce (1998 1999) devised error
driven pruning approach trained on Penn
Treebank. It extracts baseNP rules from the
training corpus and prune some bad baseNP by
incremental training, and then apply the pruned
rules to identify baseNP through maximum
length matching (or dynamic program
algorithm).
 Most of the prior work treats POS tagging and
baseNP identification as two separate
procedures. However, uncertainty is involved in
both steps. Using the result of the first step as if
they are certain will lead to more errors in the
second step. A better approach is to consider the
two steps together such that the final output
takes the uncertainty in both steps together. The
approaches proposed by Ramshaw & Markus
and Cardie&Pierce are deterministic and local,
while Argamon, Dagan & Krymolowski
consider the problem globally and assigned a
score to each possible baseNP structures.
However, they did not consider any lexical
information.
This paper presents a novel statistical approach
to baseNP identification, which considers both
steps together within a unified statistical
framework. It also takes lexical information into
account. In addition, in order to make the best
choice for the entire sentence, Viterbi algorithm
is applied. Our tests with the Penn Treebank
showed that our integrated approach achieves
92.3% in precision and 93.2% in recall. The
result is comparable or better that the current
state of the art.
In the following sections, we will describe the
detail for the algorithm, parameter estimation
and search algorithms in section 2. The
experiment results are given in section 3. In
section 4 we make further analysis and
comparison. In the final section we give some
conclusions.
2 The statistical approach
In this section, we will describe the two-pass
statistical model, parameters training and Viterbi
algorithm for the search of the best sequences of
POS tagging and baseNP identification. Before
describing our algorithm, we introduce some
notations we will use
2.1 Notation
Let us express an input sentence E  as a word
sequence and a sequence of POS respectively as
follows:
nn wwwwE 121 ... ?=
nn ttttT 121 ... ?=
Where n  is the number of words in the
sentence, it  is the POS tag of the word iw .
Given E, the result of the  baseNP identification
is assumed to be a sequence, in which some
words are grouped into baseNP as follows
...]...[... 111 ++? jjiii wwwww
The corresponding tag sequence is as follows:
(a)
mjjiijjiii nnntbttttttB ............]...[... 211,1111 === +?++?
In which jib ,  corresponds to the tag sequence of
a baseNP: ]...[ 1 jii ttt + . jib ,   may also be
thought of as a baseNP rule. Therefore B is a
sequence of both POS tags and baseNP rules.
Thus ??? innm ,1 (POS tag set ?  baseNP
rules set), This is the first expression of a
sentence with baseNP annotated. Sometime, we
also use the following equivalent form:
(b)
njjjjiiiiii qqqbmtbmtbmtbmtbmtQ ...)...,(),()...,(),(),...( 21111111 == ++++??
Where each POS tag it  is associated with its
positional information ibm  with respect to
baseNPs. The positional information is one of
},,,,{ SOEIF . F, E and I mean respectively
that the word is the left boundary, right
boundary of a baseNP, or at another position
inside a baseNP. O means that the word is
outside a baseNP. S marks a single word
baseNP. This second expression is similar to that
used in [Marcus 1995].
For example, the two expressions of the example
given in Figure 1 are as follows:
(a)  B= [NNS] IN [VBG NN] VBD RBR IN [DT JJ NNS]
(b)  Q=(NNS S) (IN O) (VBG F) (NN E) (VBD O) (RBR
O) (IN O) (DT F) (JJ I) (NNS E) (. O)
2.2 An ?integrated? two-pass
procedure
The principle of our approach is as follows. The
most probable baseNP sequence *B  may be
expressed generally as follows:
))|((maxarg* EBpB
B
=
We separate the whole procedure into two
passes, i.e.:
)),|()|((maxarg* ETBPETPB
B
??         (1)
In order to reduce the search space and
computational complexity, we only consider the
N best POS tagging of E, i.e.
))|((maxarg)(
,...,1
ETPbestNT
NTTT=
=?
       (2)
Therefore, we have:
)),|()|((maxarg
,...,,
*
1
ETBPETPB
NTTTB
??
=
        (3)
Correspondingly, the algorithm is composed of
two steps: determining the N-best POS tagging
using Equation (2). And then determining the
best baseNP sequence from those POS
sequences using Equation (3). One can see that
the two steps are integrated together, rather that
separated as in the other approaches. Let us now
examine the two steps more closely.
2.3 Determining the N best POS
sequences
The goal of the algorithm in the 1st pass is to
search for the N-best POS-sequences within the
search space (POS lattice). According to Bayes?
Rule, we have
)(
)()|()|(
EP
TPTEPETP ?=
Since )(EP  does not affect the maximizing
procedure of )|( ETP , equation (2) becomes
))()|((maxarg))|((maxarg)(
,...,,..., 11
TPTEPETPbestNT
NN TTTTTT
?==?
==
 (4)
We now assume that the words in E are
independent. Thus
?
=
?
n
i
ii twPTEP
1
)|()|(
                           (5)
We then use a trigram model as an
approximation of )(TP , i.e.:
?
=
??
?
n
i
iii tttPTP
1
12 ),|()(                          (6)
Finally we have
))|((maxarg)(
,...,1
ETPbestNT
NTTT=
=?
)),|()|((maxarg 12
1,...,1
??
=
=
?= ? iii
n
i
ii
TTT
tttPtwP
N
 (7)
In Viterbi algorithm of N best search, )|( ii twP
is called lexical generation (or output)
probability, and ),|( 12 ?? iii tttP  is called
transition probability in Hidden Markov Model.
2.3.1 Determining the baseNPs
As mentioned before, the goal of the 2nd pass is
to search the best baseNP-sequence given the N-
best POS-sequences.
Considering E ,T  and B as random variables,
according to Bayes? Rule, we have
)|(
),|()|(),|(
TEP
TBEPTBPETBP ?=
Since )(
)()|()|(
TP
BPBTPTBP ?=  we have,
)()|(
)()|(),|(),|(
TPTEP
BPBTPTBEPETBP
?
??
=       (8)
Because we search for the best baseNP sequence
for each possible POS-sequence of  the given
sentence E, so
constTEPTPTEP =?=? )()()|( ,
Furthermore from the definition of B, during
each search procedure, we have
?
=
==
n
i
jiji bttPBTP
1
,
1)|,...,()|( . Therefore, equation
(3) becomes
)),|()|((maxarg
,...,,
*
1
ETBPETPB
NTTTB
?=
=
))(),|()|((maxarg
,...,, 1
BPTBEPETP
NTTTB
??=
=
 (9)
using the independence assumption, we have
?
=
?
n
i
iii bmtwPTBEP
1
),|(),|(
                  (10)
With trigram approximation of )(BP , we have:
?
=
??
?
m
i
iii nnnPBP
1
12 ),|()(                          (11)
Finally, we obtain
)),|(),|()|((maxarg
,1
12
1,..,
*
1
??
=
??
=
=
??=
mi
iii
n
i
iii
TTTB
nnnPtbmwPETPB
N
    12 
To summarize, In the first step, Viterbi N-best
searching algorithm is applied in the POS
tagging procedure, It determines a path
probability tf  for each POS sequence calculated
as follows:
?
=
??
?=
ni
iiiiit tttptwpf
,1
12 ),|()|( .
In the second step, for each possible POS
tagging result, Viterbi algorithm is applied again
to search for the best baseNP sequence. Every
baseNP sequence found in this pass is also
asssociated with a path probability
??
=
??
=
?=
mi
iii
n
i
iiib nnnpbmtwpf
,1
12
1
),|(),|( .
The integrated probability of a baseNP sequence
is determined by bt ff ?? , where?  is a
normalization coefficient (?  4.2=  in our
experiments). When we determine the best
baseNP sequence for the given sentence E , we
also determine the best POS sequence of E ,
which corresponds to the best baseNP of E .
Now let us illustrate the whole process through
an example:  ?stock was down 9.1 points
yesterday morning.?.  In the first pass, one of the
N-best POS tagging result of the sentence is: T =
NN VBD RB CD NNS NN NN. For this POS
sequence, the 2nd pass will try to determine the
baseNPs as  shown in Figure 2. The details of
the path in the dash line are given in Figure 3, Its
probability calculated in the second pass is as
follows ( ?  is pseudo variable):
),|(),|(),|(),|(),|( BCDNUMBERpORBdownpOVBDwaspSNNstockpETBP ???=
).,|(.),|(),|(),|int( OpENNmorningpBNNyesterdaypENNSspop ????
),|]([)],[|(])[,|(),|]([ RBVBDNNSCDpVBDNNRBpNNVBDpNNp ???????
])[],[|(.])[,|]([ NNNNNNSCDpNNSCDRBNNNNp ??
Figure 2:  All possible brackets of  "stock was down 9.1 points yesterday morning"
Figure 3:  the transformed form of  the path with dash line for the second pass processing
2.4 The statistical parameter
training
In this work, the training and testing data were
derived from the 25 sections of Penn Treebank.
We divided the whole Penn Treebank data into
two sections, one for training and the other for
testing.
As required in our statistical model, we have to
calculate the following four probabilities:
(1) ),|( 12 ?? iii tttP , (2) )|( ii twP ,
(3) )|( 12 ?? iii nnnP  and (4) ),|( iii bmtwP . The
first and the third parameters are trigrams of T
and B respectively.  The second and the fourth
are lexical generation probabilities. Probabilities
(1) and (2) can be calculated from POS tagged
data with following formulae:
? ??
??
??
=
j
jii
iii
iii tttcount
tttcount
tttp )(
)(),|(
12
12
12
  (13)
)(
)()|(
i
ii
ii tcount
ttagwithwcount
twp =  (14)
As each sentence in the training set has both
POS tags and baseNP boundary tags, it can be
converted to the two sequences as B (a) and Q
(b) described in the last section. Using these
sequences, parameters (3) and (4) can be
calculated, The calculation formulas are similar
with equations (13) and (14) respectively.
Before training trigram model (3), all possible
baseNP rules should be extracted from the
training corpus. For instance, the following three
sequences are among the baseNP rules extracted.
There are more than 6,000 baseNP rules in the
Penn Treebank. When training trigram model
(3), we treat those baseNP rules in two ways. (1)
Each baseNP rule is assigned a unique identifier
(UID). This means that the algorithm considers
the corresponding structure of each baseNP rule.
(2) All of those rules are assigned to the same
identifier (SID). In this case, those rules are
grouped into the same class. Nevertheless, the
identifiers of baseNP rules are still different
from the identifiers assigned to POS tags.
We used the approach of Katz (Katz.1987) for
parameter smoothing, and build a trigram model
to predict the probabilities of parameter (1) and
(3). In the case that unknown words are
encountered during baseNP identification, we
calculate parameter  (2) and (4) in the following
way:
2)),((max
),(),|(
ijj
ii
iii tbmcount
tbmcount
tbmwp =  (15)
2))((max
)()|(
jj
i
ii tcount
tcount
twp =      (16)
Here, jbm  indicates all possible baseNP labels
attached to it , and jt  is a POS tag guessed for
the unknown word iw .
3 Experiment result
We designed five experiments as shown in Table
1. ?UID? and ?SID? mean respectively that an
identifier is assigned to each baseNP rule or the
same identifier is assigned to all the baseNP
rules. ?+1? and ?+4? denote the number of beat
POS sequences retained in the first step. And
?UID+R? means the POS tagging result of the
given sentence is totally correct for the 2nd step.
This provides an ideal upper bound for the
system. The reason why we choose N=4 for the
N-best POS tagging can be explained in Figure
4, which shows how the precision of POS
tagging changes with the number N.
96. 95
97. 00
97. 05
97. 10
97. 15
97. 20
97. 25
97. 30
97. 35
97. 40
97. 45
1 2 3 4 5 6
Figure 4:  POS tagging precision with respect to
different number of N-best
In the experiments, the training and testing sets
are derived from the 25 sections of Wall Street
Journal distributed with the Penn Treebank II,
and the definition of baseNP is the same as
Ramshaw?s, Table 1 summarizes the average
performance on both baseNP tagging and POS
tagging, each section of the whole Penn
Treebank was used as the testing data and the
other 24 sections as the training data, in this way
we have done the cross validation experiments
25 times.
Precision
( baseNP %)
Recall
( baseNP %)
F-Measure
( baseNP %) 2
RP +
( baseNP %)
Precision
(POS %)
UID+1 92.75 93.30 93.02 93.02 97.06
UID+4 92.80 93.33 93.07 93.06 97.02
SID+1 86.99 90.14 88.54 88.56 97.06
SID+4 86.99 90.16 88.55 88.58 97.13
UID+R 93.44 93.95 93.69 93.70 100
Table 1  The average performance of the five experiments
88. 00
88. 50
89. 00
89. 50
90. 00
90. 50
91. 00
91. 50
92. 00
92. 50
93. 00
1 2 3 4 5 6
UI D+1
UI D+4
UI D+R
Figure 5:  Precision under different training sets
and different POS tagging results
91. 60
91. 80
92. 00
92. 20
92. 40
92. 60
92. 80
93. 00
93. 20
93. 40
93. 60
1 2 3 4 5 6
UI D+1
UI D+4
UI D+R
Figure 6:  Recall under different training sets
and different POS tagging results
96. 80
96. 85
96. 90
96. 95
97. 00
97. 05
97. 10
97. 15
97. 20
1 2 3 4 5 6
Vi t er bi
UI D+4
SI D+4
Figure 7:  POS tagging precision under different
training sets
Figure 5 -7 summarize the outcomes of our
statistical model on various size of the training
data, x-coordinate denotes the size of the
training set, where "1" indicates that the training
set is from section 0-8th of Penn Treebank, "2"
corresponds to the corpus that add additional
three sections 9-11th  into "1" and so on. In this
way the size of the training data becomes larger
and larger. In those cases the testing data is
always section 20 (which is excluded from the
training data).
From Figure 7, we learned that the POS tagging
and baseNP identification are influenced each
other. We conducted two experiments to study
whether the POS tagging process can make use
of baseNP information. One is UID+4, in which
the precision of POS tagging dropped slightly
with respect to the standard POS tagging with
Trigram Viterbi search. In the second
experiment SID+4, the precision of POS tagging
has increase slightly. This result shows that POS
tagging can benefit from baseNP information.
Whether or not the baseNP information can
improve the precision of POS tagging in our
approach is determined by the identifier
assignment of the baseNP rules when training
trigram model of ),|( 12 ?? iii nnnP . In the
future, we will further study optimal baseNP
rules clustering to further improve the
performances of both baseNP identification and
POS tagging.
4 Comparison with other
approaches
To our knowledge, three other approaches to
baseNP identification have been evaluated using
Penn Treebank-Ramshaw & Marcus?s
transformation-based chunker, Argamon et al?s
MBSL, and Cardie?s Treebank_lex in Table 2,
we give a comparison of our method with other
these three. In this experiment, we use the
testing data prepared by Ramshaw (available at
http://www.cs.biu.ac.il/~yuvalk/MBSL), the
training data is selected from the 24 sections of
Penn Treebank (excluding the section 20). We
can see that our method achieves better result
than the others
.
Transformation-Based
(Training data: 200k)
Treebank_Lex MBSL Unified Statistical
Precision (%) 91.8 89.0 91.6 92.3
Recall (%) 92.3 90.9 91.6 93.2
F-Measure (%) 92.0 89.9 91.6 92.7
2
RP + 92.1 90.0 91.6 92.8
Table 2: The comparison of our statistical method with three other approaches
Transforamtion-Based Treebank_Lex MBSL Unified Statistical
Unifying POS &
baseNP NO NO NO YES
Lexical Information YES YES NO YES
Global Searching NO NO YES YES
Context YES NO YES YES
Table 3: The comparison of some characteristics of our statistical method with three other approaches
Table 3 summarizes some interesting aspects of
our approach and the three other methods. Our
statistical model unifies baseNP identification
and POS tagging through tracing N-best
sequences of POS tagging in the pass of baseNP
recognition, while other methods use POS
tagging as a pre-processing procedure. From
Table 1, if we reviewed 4 best output of POS
tagging, rather that only one, the F-measure of
baseNP identification is improved from 93.02 %
to 93.07%. After considering baseNP
information, the error ratio of POS tagging is
reduced by 2.4% (comparing SID+4 with
SID+1).
The transformation-based method (R&M 95)
identifies baseNP within a local windows of
sentence by matching transformation rules.
Similarly to MBSL, the 2nd pass of our algorithm
traces all possible baseNP brackets, and makes
global decision through Viterbi searching. On
the other hand, unlike MSBL we take lexical
information into account. The experiments show
that lexical information is very helpful to
improve both precision and recall of baseNP
recognition. If we neglect the probability of
?
=
n
i
iii bmtwP
1
),|(  in the 2nd pass of our model,
the precision/recall ratios are reduced to
90.0/92.4% from 92.3/93.2%. Cardie?s approach
to Treebank rule pruning may be regarded as the
special case of our statistical model, since the
maximum-matching algorithm of baseNP rules
is only a simplified processing version of our
statistical model. Compared with this rule
pruning method, all baseNP rules are kept in our
model. Therefore in principle we have less
likelihood of failing to recognize baseNP types
As to the complexity of algorithm, our approach
is determined by the Viterbi algorithm approach,
or )(nO , linear with the length.
5 Conclusions
This paper presented a unified statistical model
to identify baseNP in English text. Compared
with other methods, our approach has following
characteristics:
(1) baseNP identification is implemented in two
related stages: N-best POS taggings are first
determined, then baseNPs are identified given
the N best POS-sequences. Unlike other
approaches that use POS tagging as pre-
processing, our approach is not dependant on
perfect POS-tagging, Moreover, we can apply
baseNP information to further increase the
precision of POS tagging can be improved.
These experiments triggered an interesting
future research challenge: how to cluster certain
baseNP rules into certain identifiers so as to
improve the precision of both baseNP and POS
tagging. This is one of our further research
topics.
(2) Our statistical model makes use of more
lexical information than other approaches. Every
word in the sentence is taken into account during
baseNP identification.
(3) Viterbi algorithm is applied to make global
search at the sentence level.
Experiment with the same testing data used by
the other methods showed that the precision is
92.3% and the recall is 93.2%. To our
knowledge, these results are comparable with or
better than all previously reported results.
References
Eric Brill and Grace Ngai. (1999) Man vs. machine:
A case study in baseNP learning. In Proceedings of
the 18th International Conference on Computational
Linguistics, pp.65-72. ACL?99
S. Argamon, I. Dagan, and Y. Krymolowski  (1998)
A memory-based approach to learning shallow
language patterns. In Proceedings of the 17th
International Conference on Computational
Linguistics, pp.67-73. COLING-ACL?98
Cardie and D. Pierce (1998) Error-driven pruning of
treebank grammas for baseNP identification. In
Proceedings of the 36th  International Conference
on Computational Linguistics, pp.218-224.
COLING-ACL?98
Lance A. Ramshaw and Michael P. Marcus ( In
Press). Text chunking using transformation-based
learning. In Natural Language  Processing Using
Very large Corpora. Kluwer. Originally appeared
in The second workshop on very large corpora
WVLC?95, pp.82-94.
Viterbi, A.J. (1967) Error bounds for convolution
codes and asymptotically optimum decoding
algorithm. IEEE Transactions on Information
Theory IT-13(2): pp.260-269, April, 1967
S.M. Katz.(1987) Estimation of probabilities from
sparse data for the language model component of
speech recognize. IEEE Transactions on Acoustics,
Speech and Signal Processing. Volume ASSP-35,
pp.400-401, March 1987
Church, Kenneth. (1988) A stochastic parts program
and noun phrase parser for unrestricted text. In
Proceedings of the Second Conference on Applied
Natural Language Processing, pages 136-143.
Association of Computational Linguistics.
M. Marcus, M. Marcinkiewicx, and B. Santorini
(1993) Building a large annotated corpus of
English: the Penn Treebank. Computational
Linguistics, 19(2): 313-330
PENS: A Machine-aided English Writing System
for Chinese Users
Ting Liu1 Ming Zhou Jianfeng Gao Endong Xun Changning Huang
Natural Language Computing Group, Microsoft Research China, Microsoft Corporation
5F, Beijing Sigma Center
100080 Beijing, P.R.C.
{ i-liutin, mingzhou, jfgao, i-edxun, cnhuang@microsoft.com }
Abstract
Writing English is a big barrier for most
Chinese users. To build a computer-aided system
that helps Chinese users not only on spelling
checking and grammar checking but also on
writing in the way of native-English is a
challenging task. Although machine translation is
widely used for this purpose, how to find an
efficient way in which human collaborates with
computers remains an open issue. In this paper,
based on the comprehensive study of Chinese
users requirements, we propose an approach to
machine aided English writing system, which
consists of two components: 1) a statistical
approach to word spelling help, and 2) an
information retrieval based approach to
intelligent recommendation by providing
suggestive example sentences. Both components
work together in a unified way, and highly
improve the productivity of English writing. We
also developed a pilot system, namely PENS
(Perfect ENglish System). Preliminary
experiments show very promising results.
Introduction
With the rapid development of the Internet,
writing English becomes daily work for
computer users all over the world. However, for
Chinese users who have significantly different
culture and writing style, English writing is a big
barrier. Therefore, building a machine-aided
English writing system, which helps Chinese
users not only on spelling checking and grammar
checking but also on writing in the way of
native-English, is a very promising task.
Statistics shows that almost all Chinese
users who need to write in English1 have enough
knowledge of English that they can easily tell the
difference between two sentences written in
Chinese-English and native-English, respectively.
Thus, the machine-aided English writing system
should act as a consultant that provide various
kinds of help whenever necessary, and let users
play the major role during writing. These helps
include:
1) Spelling help: help users input hard-to-spell
words, and check the usage in a certain
context simultaneously;
2) Example sentence help: help users refine the
writing by providing perfect example
sentences.
Several machine-aided approaches have
been proposed recently. They basically fall into
two categories, 1) automatic translation, and 2)
translation memory. Both work at the sentence
level. While in the former, the translation is not
readable even after a lot of manually editing. The
latter works like a case-based system, in that,
given a sentence, the system retrieve similar
sentences from translation example database, the
user then translates his sentences by analogy. To
build a computer-aided English writing system
that helps Chinese users on writing in the way of
native-English is a challenging task. Machine
translation is widely used for this purpose, but
how to find an efficient way in which human
collaborates well with computers remains an
open issue. Although the quality of fully
automatic machine translation at the sentence
level is by no means satisfied, it is hopeful to
1 Now Ting Liu is an associate professor in Harbin
Institute of Technology, P.R.C.
provide relatively acceptable quality translations
at the word or short phrase level. Therefore, we
can expect that combining word/phrase level
automatic translation with translation memory
will achieve a better solution to machine-aided
English writing system [Zhou, 95].
In this paper, we propose an approach to
machine aided English writing system, which
consists of two components: 1) a statistical
approach to word spelling help, and 2) an
information retrieval based approach to
intelligent recommendation by providing
suggestive example sentences. Both components
work together in a unified way, and highly
improve the productivity of English writing. We
also develop a pilot system, namely PENS.
Preliminary experiments show very promising
results.
The rest of this paper is structured as follows.
In section 2 we give an overview of the system,
introduce the components of the system, and
describe the resources needed. In section 3, we
discuss the word spelling help, and focus the
discussion on Chinese pinyin to English word
translation. In addition, we describe various
kinds of word level help functions, such as
automatic translation of Chinese word in the form
of either pinyin or Chinese characters, and
synonym suggestion, etc. We also describe the
user interface briefly. In section 4, an effective
retrieval algorithm is proposed to implement the
so-called intelligent recommendation function. In
section 5, we present preliminary experimental
results. Finally, concluding remarks is given in
section 6.
1 System Overview
1.1 System Architecture
Figure 1 System Architecture
There are two modules in PENS. The first is
called the spelling help. Given an English word,
the spelling help performs two functions, 1)
retrieving its synonym, antonym, and thesaurus;
or 2) automatically giving the corresponding
translation of Chinese words in the form of
Chinese characters or pinyin. Statistical machine
translation techniques are used for this translation,
and therefore a Chinese-English bilingual
dictionary (MRD), an English language model,
and an English-Chinese word- translation model
(TM) are needed. The English language model is
a word trigram model, which consists of
247,238,396 trigrams, and the vocabulary used
contains 58541 words. The MRD dictionary
contains 115,200 Chinese entries as well as their
corresponding English translations, and other
information, such as part-of-speech, semantic
classification, etc. The TM is trained from a
word-aligned bilingual corpus, which occupies
approximately 96,362 bilingual sentence pairs.
The second module is an intelligent
recommendation system. It employs an effective
sentence retrieval algorithm on a large bilingual
corpus. The input is a sequence of keywords or a
short phrase given by users, and the output is
limited pairs bilingual sentences expressing
relevant meaning with users? query, or just a few
pairs of bilingual sentences with syntactical
relevance.
1.2 Bilingual Corpus Construction
We have collected bilingual texts extracted
from World Wide Web bilingual sites,
dictionaries, books, bilingual news and
magazines, and product manuals. The size of the
corpus is 96,362 sentence pairs. The corpus is
used in the following three cases:
1) Act as translation memory to support the
Intelligent Recommendation Function;
2) To be used to acquire English-Chinese
translation model to support translation at
word and phrase level;
3) To be used to extract bilingual terms to enrich
the Chinese-English MRD;
To construct a sentence aligned bilingual
corpus, we first use an alignment algorithm doing
the automatic alignment and then the alignment
result are corrected.
There have been quite a number of recent
papers on parallel text alignment. Lexically based
techniques use extensive online bilingual
lexicons to match sentences [Chen 93]. In
contrast, statistical techniques require almost no
prior knowledge and are based solely on the
lengths of sentences, i.e. length-based alignment
method. We use a novel method to incorporate
both approaches [Liu, 95]. First, the rough result
is obtained by using the length-based method.
Then anchors are identified in the text to reduce
the complexity. An anchor is defined as a block
that consists of n successive sentences. Our
experiments show best performance when n=3.
Finally, a small, restricted set of lexical cues is
applied to obtain for further improvement.
1.3 Translation Model Training
Chinese sentences must be segmented
before word translation training, because written
Chinese consists of a character stream without
space between words. Therefore, we use a
wordlist, which consists of 65502 words, in
conjunction with an optimization procedure
described in [Gao, 2000]. The bilingual training
process employs a variant of the model in [Brown,
1993] and as such is based on an iterative EM
(expectation-maximization) procedure for
maximizing the likelihood of generating the
English given the Chinese portion. The output of
the training process is a set of potential English
translations for each Chinese word, together with
the probability estimate for each translation.
1.4 Extraction of Bilingual
Domain-specific Terms
A domain-specific term is defined as a string
that consists of more than one successive word
and has certain occurrences in a text collection
within a specific domain. Such a string has a
complete meaning and lexical boundaries in
semantics; it might be a compound word, phrase
or linguistic template. We use two steps to extract
bilingual terms from sentence aligned corpus.
First we extract Chinese monolingual terms from
Chinese part of the corpus by a similar method
described in [Chien, 1998], then we extract the
English corresponding part by using the word
alignment information. A candidate list of the
Chinese-English bilingual terms can be obtained
as the result. Then we will check the list and add
the terms into the dictionary.
2 Spelling Help
The spelling help works on the word or
phrase level. Given an English word or phrase, it
performs two functions, 1) retrieving
corresponding synonyms, antonyms, and
thesaurus; and 2) automatically giving the
corresponding translation of Chinese words in
the form of Chinese characters or pinyin. We will
focus our discussion on the latter function in the
section.
To use the latter function, the user may input
Chinese characters or just input pinyin. It is not
very convenient for Chinese users to input
Chinese characters by an English keyboard.
Furthermore the user must switch between
English input model and Chinese input model
time and again. These operations will interrupt
his train of thought. To avoid this shortcoming,
our system allows the user to input pinyin instead
of Chinese characters. The pinyin can be
translated into English word directly.
Let us take a user scenario for an example to
show how the spelling help works. Suppose that a
user input a Chinese word ?? in the form of
pinyin, say ?wancheng?, as shown in figure1-1.
PENS is able to detect whether a string is a
pinyin string or an English string automatically.
For a pinyin string, PENS tries to translate it into
the corresponding English word or phrase
directly. The mapping from pinyin to Chinese
word is one-to-many, so does the mapping from
Chinese word to English words. Therefore, for
each pinyin string, there are alternative
translations. PENS employs a statistical approach
to determine the correct translation. PENS also
displays the corresponding Chinese word or
phrase for confirmation, as shown in figure 1-2.
Figure 1-1
Figure 1-2
If the user is not satisfied with the English
word determined by PENS, he can browse other
candidates as well as their bilingual example
sentences, and select a better one, as shown in
figure 1-3.
Figure 1-3
2.1 Word Translation Algorithm
based on Statistical LM and TM
Suppose that a user input two English words,
say EW1 and EW2, and then a pinyin string, say
PY. For PY, all candidate Chinese words are
determined by looking up a Pinyin-Chinese
dictionary. Then, a list of candidate English
translations is obtained according to a MRD.
These English translations are English words of
their original form, while they should be of
different forms in different contexts. We exploit
morphology for this purpose, and expand each
word to all possible forms. For instance,
inflections of ?go? may be ?went?, and ?gone?.
In what follows, we will describe how to
determine the proper translation among the
candidate list.
Figure 2-1: Word-level Pinyin-English
Translation
As shown in Figure 2-1, we assume that the
most proper translation of PY is the English word
with the highest conditional probability among
all leaf nodes, that is
According to Bayes? law, the conditional
probability is estimated by
),|(
),|(),,|(
),,|(
21
2121
21
EWEWPYP
EWEWEWPEWEWEWPYP
EWEWPYEWP
ijij
ij
?
= (2-1)
Since the denominator is independent of EWij, we
rewrite (2-1) as
),|(),,|(
),,|(
2121
21
EWEWEWPEWEWEWPYP
EWEWPYEWP
ijij
ij
?
? (2-2)
Since CWi is a bridge which connect the pinyin
and the English translation, we introduce Chinese
word CWi into
We get
),,,|(
),,,|(),,|(
),,|(
21
2121
21
EWEWEWPYCWP
EWEWEWCWPYPEWEWEWCWP
EWEWEWPYP
iji
ijiiji
ij
?
=
(2-3)
For simplicity, we assume that a Chinese word
doesn?t depends on the translation context, so we
can get the following approximate equation:
)|(),,|( 21 ijiiji EWCWPEWEWEWCWP ?
We can also assume that the pinyin of a Chinese
word is not concerned in the corresponding
English translation, namely:
)|(),,,|( 21 iiji CWPYPEWEWEWCWPYP ?
It is almost impossible that two Chinese words
correspond to the same pinyin and the same
English translation, so we can suppose that:
1),,,|( 21 ?EWEWEWPYCWP iji
Therefore, we get the approximation of (2-3) as
follows:
)|()|(
),,|( 21
iiji
ij
CWPYPEWCWP
EWEWEWPYP
?
= (2-4)
According to formula (2-2) and (2-4), we get:
),|()|()|(
),,|(
21
21
EWEWEWPCWPYPEWCWP
EWEWPYEWP
ijiiji
ij
??
= (2-5)
where P(CWi |EWij) is the translation model, and
can be got from bilingual corpus, and P(PY | CWi)
),,|( 21 EWEWEWPYP ij
is the polyphone model, here we suppose
P(PY|CWi) = 1, and P(EWij | EW1, EW2) is the
English trigram language model.
To sum up, as indicated in (2-6), the spelling help
find the most proper translation of PY by
retrieving the English word with the highest
conditional probability.
),|()|(maxarg
),,|(maxarg
21
21
EWEWEWPEWCWP
EWEWPYEWP
ijiji
EW
EW
ij
ij
?
=
(2-6)
3 Intelligent Recommendation
The intelligent recommendation works on
the sentence level. When a user input a sequence
of Chinese characters, the character string will be
firstly segmented into one or more words. The
segmented word string acts as the user query in
IR. After query expansion, the intelligent
recommendation employs an effective sentence
retrieval algorithm on a large bilingual corpus,
and retrieves a pair (or a set of pairs) of bilingual
sentences related to the query. All the retrieved
sentence pairs are ranked based on a scoring
strategy.
3.1 Query Expansion
Suppose that a user query is of the form CW1,
CW2, ? , CWm. We then list all synonyms for
each word of the queries based on a Chinese
thesaurus, as shown below.
mmnnn
m
m
CWCWCW
CWCWCW
CWCWCW
???
????????????
???
???
21 21
22212
12111
We can obtain an expanded query by
substituting a word in the query with its synonym.
To avoid over-generation, we restrict that only
one word is substituted at each time.
Let us take the query ?? for an example.
The synonyms list is as follows:
 =	??
 =
??.
The query consists of two words. By substituting
the first word, we get expanded queries, such as
??????, etc, and by
substituting the second word, we get other
expanded queries, such as ? 
??
???, etc.
Then we select the expanded query, which is
used for retrieving example sentence pairs, by
estimating the mutual information of words with
the query. It is indicated as follows
?
?
=
m
ik
k
ijk
ji
CWCWMI
1,
),(maxarg
where CWk is a the kth Chinese word in the query,
and CWij is the jth synonym of the i-th Chinese
word. In the above example, ? ? is
selected. The selection well meets the common
sense. Therefore, bilingual example sentences
containing ?? will be retrieved as well.
3.2 Ranking Algorithm
The input of the ranking algorithm is a
query Q, as described above, Q is a Chinese
word string, as shown below
Q= T1,T2,T3,?Tk
The output is a set of relevant bilingual
example sentence pairs in the form of,
S={(Chinsent, Engsent) | Relevance(Q,Chinsent)
>Relevance(Q,Engsent) >
where Chinsent is a Chinese sentence, and
Engsent is an English sentence, and 

For each sentence, the relevance score is
computed in two parts, 1) the bonus which
represents the similarity of input query and the
target sentence, and 2) the penalty, which
represents the dissimilarity of input query and the
target sentence.
The bonus is computed by the following formula:
Where