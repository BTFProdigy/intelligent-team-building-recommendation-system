R. Dale et al (Eds.): IJCNLP 2005, LNAI 3651, pp. 438 ? 449, 2005. 
? Springer-Verlag Berlin Heidelberg 2005 
A Rule Based Syllabification Algorithm for Sinhala 
Ruvan Weerasinghe, Asanka Wasala, and Kumudu Gamage 
Language Technology Research Laboratory, University of Colombo School of Computing,  
35, Reid Avenue, Colombo 7, Sri Lanka 
arw@ucsc.cmb.ac.lk, {awasala, kgamage}@webmail.cmb.ac.lk 
Abstract. This paper presents a study of Sinhala syllable structure and an algo-
rithm for identifying syllables in Sinhala words. After a thorough study of the 
Syllable structure and linguistic rules for syllabification of Sinhala words and a 
survey of the relevant literature, a set of rules was identified and implemented 
as a simple, easy-to-implement algorithm. The algorithm was tested using 
30,000 distinct words obtained from a corpus and compared with the same 
words manually syllabified. The algorithm performs with 99.95 % accuracy. 
1   Introduction 
Syllabification algorithms are mainly used in text-to-speech (TTS) systems in produc-
ing natural sounding speech, and in speech recognizers in detecting out-of-vocabulary 
words. The key objectives of this study are to identify the syllable structures in modern 
Sinhala language and to define an algorithm to syllabify a given Sinhala word to be 
used in our TTS system. Syllabification algorithms have been proposed for different 
languages including English, German, Spanish and Hindi, among others. Although a 
few researchers have documented attempts at syllabifying modern Sinhala words in the 
Linguistics literature, this is the first known documented algorithm for Sinhala syllabi-
fication and certainly the first evaluation of any syllabification scheme for Sinhala. 
Languages differ considerably in the syllable structures that they permit. For most 
languages, syllabification can be achieved by writing a set of declarative grammatical 
rules which explain the location of syllable boundaries of words step-by-step. It has 
been identified that most of these rules adhere to well known theories such as the 
Maximum Onset Principle and the Sonority Profile. The association of consonants 
with the syllable nucleus is derived by the Maximum Onset Principle (MOP). 
Maximum Onset Principal: First make the onset as long as it legitimately can be; then 
form a legitimate coda [2].  
Sonority Profile: The sonority of a syllable increases from the beginning of the sylla-
ble onward, and decreases from the beginning of the peak onwards [2]. 
Sonority is related to the acoustic intensity of a sound. Thus, by measuring the 
acoustic intensities of sounds, the sonority of a sound can be estimated [1]. The 
classes of vowel and consonant sounds (segments) that are usually distinguished 
along this dimension are listed in the order of increasing sonority, and this list is re-
ferred to as the Sonority Scale [2]. 
 A Rule Based Syllabification Algorithm for Sinhala 439 
Sonority Scale:  
Obstruents ? Nasals ? Liquids ([l, r] etc.) ? Glides ([w, j]) etc.) ? Vowels 
Many syllabification algorithms have been developed based on these two theories. 
For example, the Festival Speech Synthesis System (the framework we use in our 
Sinhala TTS) by default syllabifies words by finding the minimum sonorant position 
between vowels [3]. Another sonority scale based syllabification algorithm is pre-
sented in detail in [4]. The sonority theory of the syllable does not, however, account 
for all the phenomena observed in language. Many examples have been provided in 
the literature to demonstrate this [1], [2]. To avoid the difficulties encountered when 
using the sonority profile, most of the language specific syllabication schemes are 
modeled by using finite state machines or neural networks. A multilingual syllabifica-
tion algorithm using weighted finite-state transducers has been proposed in [5]. 
In this research, an algorithm to divide Sinhala words into syllables is proposed. 
The algorithm was tested by using a text corpus containing representative words for 
each grammatical rule, and its performance was then measured in terms of the per-
centage of correctly syllabified words. The rest of this paper is organized as follows: 
Section 2 gives an overview of the Sinhala Phonemic Inventory and Section 3 briefly 
reviews the linguistic background of modern Sinhala word syllabification including 
issues we identified and our proposed solutions. Section 4 describes the implementa-
tion of the algorithm. The paper concludes with the results & discussion in Section 5. 
2   The Sinhala Phonemic Inventory 
Sinhala is one of the official languages of Sri Lanka and the mother tongue of the ma-
jority (about 74%) of its population. Spoken Sinhala contains 40 segmental pho-
nemes; 14 vowels and 26 consonants as classified below in Table 1 and Table 2 [6]. 
There are two nasalized vowels occurring in two or three words in Sinhala. They are 
/a ~/, /a~:/, /?~/, and /?~~:/ [6]. Spoken Sinhala also contains the following Diph-
thongs, /iu/, /eu/, /?u/, /ou/, /au/, /ui/, /ei/, /?i/, /oi/, and /ai/ [7]. 
A separate letter for vowel /\/ has not been provided by the Sinhala writing sys-
tem. In terms of distribution, the vowel /\/ does not occur at the beginning of a syl-
lable except in the conjugational variants of verbs formed from the verbal stem 
/k\r\/ (to do.). In contrast to this, though the letter ? ? exists in Sinhala writing sys-
tem (corresponding to the consonant sound /j~/), it is not considered a phoneme in 
Sinhala.  
Table 1. Spoken Sinhala vowel classification 
Front  Central Back 
 
Short Long Short Long Short Long 
High i      i:       u     u:     
Mid e    e:   \ \: o     o:     
Low ?   ?:   a a:   
?
440 R. Weerasinghe, A. Wasala, and K. Gamage 
Table 2. Spoken Sinhala consonant classification 
 
Labial Dental Alveolar Retroflex Palatal Velar Glottal 
Voiceless p    t      ?      k      Stops 
 Voiced b    d     ?      ?      
Voiceless     c      Affricates 
Voiced     j       
Pre-nasalized 
voiced stops 
b~    d~     ?~      ~?      
Nasals m    n      ?    ?      
Trill   r         
Lateral   l         
Spirants f     s       s`    h    
Semivowels v       y      
3   Syllable Structure  
3.1   Methodology 
The methodology adopted in this study was to first examine the Sinhala syllable struc-
ture from the Linguistics literature to gather the views of scholars from the various 
linguistic traditions. It was expected that this study would reveal the main issues re-
lated to the syllabification of Sinhala and how these issues are addressed by scholars 
in the literature. This was then subjected to the scrutiny of an algorithm in order to se-
lect from among alternative theories. 
3.2   Sinhala Syllable Structure 
3.2.1   Background 
Words in the Sinhala language can be divided in to three groups namely Nishpanna, 
Thadbhava and Thathsama as described below: 
Nishpanna: Words that are of local origin.  
Thathsama: Words borrowed from other languages in their (near) original form.  
Thadbhava: Words derived from other languages but modified to be incorporated to 
Sinhala (mainly from Sanskrit and Pali). 
The high impact of Sanskrit in Sinhala vocabulary formation is due to the fact that, 
Sinhala and Sanskrit belong to the same Indo-Aryan language family. Further, as the 
vehicle of Buddhism to Sri Lanka, the Pali (spoken) language has also significantly 
influenced the vocabulary of Sinhala. Due to various cultural, historical and socio-
linguistic factors, other languages such as Tamil, Portuguese, Dutch and English have 
also impacted the structure and vocabulary of Sinhala.  
It is important to note that the Thathsama, and Thadbhava, categories of words are 
available in modern Sinhala and are indistinguishable to the layman from words in  
the Nishpanna Category. While no documented evidence exists, it is thought that the 
 A Rule Based Syllabification Algorithm for Sinhala 441 
percentage of words in the Nispanna category is less than 5%, while the percentage of 
words in the Thathsama and Thadbhava categories in Sinhala (the remaining > 95%), 
are more or less equal.  However, for words in the Thathsama and Thadbhava catego-
ries, no official syllable structures were found in literature. This puts the onus on any 
TTS researcher dealing with Sinhala syllabification to pay urgent attention to the 
study of the Thathsama and Thadbhava categories of words. 
3.2.2   Syllabification of Words Belonging to the Nishpanna Category 
It has been identified that there are four legal syllable structures in Sinhala, namely V, 
VC, CV and CVC for words which belong to the Nishpanna category [7]. This can 
also be represented using the expression: (C)V(C). Though a large number of exam-
ples for syllabified words belonging to each of the above structures are presented in 
the literature [7], the methodology or grammatical rules describing how to syllabify a 
given word has not been presented. A word can be syllabified in many ways retaining 
the permitted structures, but only a single correct combination of structures is ac-
cepted in a properly syllabified word.  
For example, a word having the consonant-vowel structure VCVCVC can be syl-
labified in the following different ways, retaining the valid syllable structures de-
scribed in the literature: (V)(CVC)(VC), (VC)(VC)(VC), (VC)(V)(CVC). However, 
only one of these forms represents the properly syllabified word. 
The determination of a proper mechanism leading to the identification of the cor-
rect combination and sequence of syllable structures in syllabifying a given word be-
came the major challenge in this research.  
Further review of the literature and empirical observation led to the following 
model with regard to Sinhala syllabification; 
1. A fundamental assumption that the accurately syllabified form of a word can be 
uniquely obtained by formulating a set of rules. 
2. That the following set of rules can be empirically shown to be effective. 
Syllabification Procedure for the Nishpanna Category 
a. Reach the first vowel of the given word and then, 
1. If the phoneme next to this vowel is a consonant followed by another vowel, 
then mark the syllable boundary just after the first vowel. (Rule #1) 
i.e. a word having a consonant-vowel structure xVCV? Should be syllabified 
as (xV)(CV?), where x denotes either a single consonant or zero consonant. 
2. If the phoneme next to this vowel is a consonant followed by another consonant 
and a vowel, then mark the syllable boundary just after the first consonant. 
(Rule #2) 
i.e. a word having a consonant-vowel structure xVCCV? should be syllabified 
as (xVC)(CV?), where x denotes either a single consonant or zero consonant. 
3. If the phoneme next to this vowel is another vowel, then mark the syllable 
boundary just after the first vowel. (Rule #3) 
i.e. a word having a consonant-vowel structure xVV? should be syllabified as 
(xV)(V?), where x denotes either a single consonant or zero consonant. Only a 
few words were found in Sinhala having two consecutive vowels in a single 
word. e.g. ?giriullt\? (Name of city.), ?aa:v\? (Alphabet). The syllable structure 
(V) mostly occurs at the beginning of the word, except for this type of rare word. 
442 R. Weerasinghe, A. Wasala, and K. Gamage 
b. Having marked the first syllable boundary, continue the same procedure for the  
rest of the phonemes as in the case of a new word. 
i.e. Repeat the step (a) for the rest of the word, until the whole word is syllabified. 
The accuracy of this model was first tested by calculating the syllable boundaries 
using the examples given in the literature. Convinced that the results were consistent 
with the descriptive treatment of the subject in the literature, it was concluded that the 
above set of rules could describe an accurate syllabification algorithm for words be-
longing to the Nishpanna category. 
3.2.3   Syllabification of Words of the Thathsama and Thadbhava Categories 
In the syllabification of foreign words, it has been observed that words borrowed from 
Sanskrit play a major role compared to those borrowed from other languages. The rea-
son behind this is the presence of a large number of Sanskrit words in Sinhala (about 
75% of the Thathsama category [8]), and the complexity of codas and onsets of these 
words when they intermix with the Sinhala phonetic inventory. Defining proper syl-
labic structures for words borrowed or derived from Sanskrit therefore became a pri-
mary focus in this study due to this reason. For this purpose, a carefully chosen list of 
words in this category (see Appendix A) was presented to recognized scholars of Sin-
hala and Sanskrit for syllabification and recommendations. A careful analysis of the in-
formation and views gathered, led to the identification of a new set of rules distinct 
from those defined in previous section, on how to syllabify these borrowed Sanskrit 
words. It is proposed that Syllabic structures for words originating from Sanskrit can 
be represented using the consonant-vowel pattern (C)(C)(C)V(C)(C)(C). It is also 
noteworthy to mention that the syllabic structures for words belong to the category of 
Nishpanna i.e. (C)V(C) is in fact a subset of this structure.  
Languages are unique in syllable structures. Syllabification of words belonging to 
the categories of Thathsama and Thadbhava do not completely adhere to the syllabi-
fication rules imposed in the language from which the word originated. Syllabifica-
tion of such words will naturally be altered according to the phonetic inventory and 
existing syllable structures of the host language, Sinhala in this case. This view was 
expressed by all of the scholars whom we consulted regarding the syllabification of 
foreign words. In support of this observation, it was evident that the syllabification of 
almost all  the words borrowed from languages other than Sanskrit (e.g. Pali, Tamil 
and English) are also consistent with the above set of syllabification rules and syllabic 
structures produced by them. An algorithm to capture this feature of the language is 
presented below: 
Syllabification Procedure for Thathsama and Thadbhava Category 
a. Reach the first vowel of the given word and then, 
1. If the vowel is preceded by a consonant cluster of 3, followed by a vowel, 
? If the consonant preceded by the last vowel is /r/ or /y/ then mark the syl-
lable boundary after the first consonant of the consonant cluster. (Rule #4) 
i.e. a word having a consonant-vowel structure xVCC[/r/ or /y/]V.., 
should be syllabified as (xVC)(C[/r/ or /y/]V?), where x denotes zero or 
any number of consonants.  
 A Rule Based Syllabification Algorithm for Sinhala 443 
? In the above rule, if the consonant preceded by the last vowel is a phoneme 
other than /r/ or /y/ then,  
? If the first two consonants in the consonant cluster are both stop conso-
nants, then mark the syllable boundary after the first consonant of the con-
sonant cluster. (Rule #5) 
i.e. a word having a consonant-vowel structure xV[C-Stop][C-Stop]CV..., 
should be syllabified as (xVC)(CCV...), where x denotes zero or any number 
of consonants. 
? In other situations, mark the syllable boundary after the second consonant 
of the consonant cluster. (Rule #6) 
i.e. a word having a consonant-vowel structure xVCCCV?, should be syl-
labified as (xVCC)(CV...), where x denotes zero or any number of conso-
nants. 
2. If  this vowel is preceded by a consonant cluster of more than  3 consonants ,  
? If the consonant just before the last vowel is /r/ or /y/ then, mark the syl-
lable boundary before 2 consonants from the last vowel. (Rule #7) 
i.e. a word having a consonant-vowel structure xVCCC?[/r/ or /y/]V... 
should be syllabified as (xVCCC?)(C[/r/ or /y/]V..), where x denotes 
zero or any number of consonants. 
? In other situations, mark the syllable boundary just after the minimum sono-
rant consonant phoneme of the consonant cluster. (Rule #8) 
i.e. a word having a consonant-vowel structure xVCCC?CV..., should be 
syllabified just next to the minimum sonorant consonant in the consonant 
cluster. 
b. Having marked the first syllable boundary, continue the same procedure for the  
rest of the phonemes as in a new word. 
i.e. Repeat the step (a) for the rest of the word, until the whole word is syllabified. 
The words with consonant clusters of more than 3 consonants are rarely found in 
Sinhala, and to avoid the confusion of syllabification of words in such situations, the 
algorithm makes use of the universal sonority hierarchy in deciding the proper posi-
tion to mark the syllable boundary. In these situations, the syllable boundary is 
marked next to the first occurrence of a minimum sonorant consonant. 
3.2.4   Ambisyllabic Words in Sinhala 
Some ambisyllabic words are also found in Sinhala. This situation arises due to the 
fact that some words with complex coda or onset can be syllabified in several ways.  
For example, a word such as /sampre:k?\n\/ (transmit)  the /p/ can be interpreted 
as a coda with respect to the preceding vowel, as in /samp/re:k/?\/n\/or as an on-
set with respect to the following vowel, as in /sam/pre:k/?\/n\/. 
More examples for this kind of word include, /mats/y\/, /mat/sy\/ (fish); 
 /sank/ya:/,  /san/kya:/ (number) and /lak?/y\/,/lak/?y\/(point). 
Some Sanskrit loan words in Sinhala (including word internal clusters ending in /r/ 
and preceding a vowel) can either be syllabified by reduplicating the first consonant 
sound of the cluster or by retaining the original word as in the following examples. 
444 R. Weerasinghe, A. Wasala, and K. Gamage 
/kr\/mak/r\/m\/y\/? /kr\/mak/kr\/m\/y\/ (gradually) 
/ap/r\/ma:/n\/? /ap/pr\/ma:/n\/ (unlimited) 
/ja/yag/ra:/hi:/? /ja/yag/gra:/hi:/ (victory) 
This description demonstrates that the rules and procedures determined above are 
complied with even by ambisyllabic words. It is important to note that while both 
forms are acceptable, one of these will be provided by the algorithm stated above. 
4   The Syllabification Algorithm 
The rules identified in sections 3.2.2 and 3.2.3 are sensitive to the sequence since they 
interact with each other. In this section, the Sinhala syllabification rules identified 
above are presented in the form of a formal algorithm. The function syllabify() ac-
cepts an array of phonemes generated by our Letter-To-Sound module1 for a particular 
word, along with a variable called current_position which is used to determine the 
position of the given array currently being processed by the algorithm.  
Initially the current_position variable will be initialized to 0. The syllabify() func-
tion is called recursively until all phonemes in the array are processed. The function 
mark_syllable_boundary(postion) will mark the syllable boundaries of an accepted ar-
ray of phonemes. The other functions used within the syllabify() function are de-
scribed below. 
? no_of_vowels(phonemes): accepts an array of phonemes and returns the number of  
vowels contained in that array. 
? is_a_vowel(phoneme): accepts a phoneme and returns true if the given phoneme is 
a vowel. 
? count_no_of_consonants_upto_next_vowel(phonemes, position): accepts an array 
of phonemes and a starting position; and returns the count of consonants from the 
starting position of the given array until the next vowel is found. 
? is_a_stop(phoneme):   returns true if the accepted phoneme is a stop consonant. 
? find_min_sonority_position(phonemes, position): returns the minimum sonorant 
position of a given array of phonemes, by starting the search from the given  posi-
tion. 
A complete listing of the algorithm is provided in Appendix B. 
5   Results and Discussion 
Our algorithm was tested on 30,000 distinct words extracted from the (unbalanced) 
UCSC Sinhala Corpus BETA, and compared with correctly hand syllabified words. 
Text obtained from the category ?News Paper > Feature Auricles > Other? was cho-
sen for testing the algorithm due to the heterogeneous nature of these texts and hence 
the perceived better representation of the language in this section of the corpus2. A list 
                                                          
1
 Discussed in another paper in preparation. 
2
 This accounts for almost two-thirds of the size of this version of the corpus. 
 A Rule Based Syllabification Algorithm for Sinhala 445 
of distinct words was first extracted, and the 30,000 most frequently occurring words 
chosen for testing our algorithm.  
The 30,000 words yielded some 78,775 syllables which were distributed as follows 
among the 8 rules of the algorithm given: Rule #1: 67,350; Rule #2: 10,899; Rule #3: 
71; Rule #4: 324; Rule #5: 28; Rule #6: 77; Rule #7: 21 and Rule #*: 5. Note however 
that owing to the syllable structure of words in the Nishpanna category being a subset 
of those of the Thathsama and Thadbhava categories, nothing can be inferred about 
the actual percentages of words in each category from this analysis alone. 
The algorithm achieves an overall accuracy of 99.95% when compared with the 
same words manually syllabified by an expert. An error analysis revealed the follow-
ing two types of errors: 
1. Words composed by joining two or more words (i.e. Single words formed by com-
bining 2 or more distinct words; such as in the case of the English word  ?thereaf-
ter?). In this case, syllabification needs to be carried out separately for each word 
of the compound word, and then concatenated to form a single syllabified word. 
2. Foreign (mainly English) words directly encoded in Sinhala. 
A detailed study of Sinhala syllabification is presented in the research above. 
Though a great number of diverse algorithms have been proposed for syllabification 
in different languages, to the best of our knowledge this is the first such study for Sin-
hala syllabification proposing a formal algorithm describing the process.  The initial 
study of the literature revealed certain unresolved issues which this study resolved 
with the aid of scholars. A significant task was carried out in identifying valid syllable 
structures for words borrowed from Sanskrit.  A major effort was also made in identi-
fying and defining a formal set of linguistic rules for syllabification, and then translat-
ing same into a simple and easy-to-implement algorithm. Finally, the effectiveness of 
the proposed algorithm was demonstrated using a set of words extracted from a Sin-
hala corpus. 
Syllabification is an important component of many speech and language processing 
systems, and this algorithm is expected to be a significant contribution to the field, 
and especially to researchers working on various aspects of the Sinhala language. 
Acknowledgement 
This work has been supported through the PAN Localization Project, (http://www. 
PANL10n.net) grant from the International Development Research Center (IDRC), 
Ottawa, Canada, administered through the Center for Research in Urdu Language 
Processing, National University of Computer and Emerging Sciences, Pakistan. The 
authors are indebted to Sinhala Language scholars, Prof. Wimal G. Balagalle, Prof. 
S.A.G. Wijesinghe, Prof. R.M.W. Rajapaksha, and Prof. J.B. Dissanayake for their 
invaluable support and advice throughout the study. We also wish to acknowledge the 
contribution of Mr. Viraj Welgama, Mr. Dulip Herath, and Mr. Nishantha Medagoda 
of Language Technology Research Laboratory of the University of Colombo School 
of Computing, Sri Lanka. 
446 R. Weerasinghe, A. Wasala, and K. Gamage 
References 
1. Ladeforged, P., A Course In Phonetics, 3rd  edn., Harcourt Brace Jovanovich College Pub-
lishers, 301, Commerce Street, Suite 3700, Fort Worth TX 76102 (1993) 
2. Gussenhoven, C., Jacobs, H., Understanding Phonology, Oxford University Press Inc, 198, 
Madison Avenue, New York, NY 10016 (1998) 
3. Black, A.W., Taylor, P., Caley R., The Festival Speech Synthesis System: System Docu-
mentation, University of Edinburgh, Edinburgh (1999) 
4. Brasington, R., ?A simple syllabifier?, (LOGO and natural language), Available: 
http://www.personal.rdg.ac.uk/~llsling1/Logo.WWW/Sound.patterns/Simple.syllabifier.htm
l,(Accessed: 2005, February, 02) 
5. Kiraz, G.A., Mobius, B., "Multilingual Syllabification Using Weighted Finite-State Trans-
ducers", Bell Labs ? Lucent Technologies, Murray Hill, NJ 07974, USA, In Proceedings of 
the Third ESCA Workshop on Speech Synthesis (Jenolan Caves, Australia, 1998) (1998) 
6. Karunatillake, W.S., An introduction to spoken Sinhala, 3rd edn., M.D. Gunasena & Co. ltd., 
217, Olcott Mawatha, Colombo 11 (2004) 
7. Disanayaka, J.B., The structure of spoken Sinhala, National Institute of Education, Ma-
haragama (1991) 
8. Jayathilake, K., Nuthana Sinhala Vyakaranaye Mul Potha, Pradeepa Publications, 34/34, 
Lawyers? Office Complex, Colombo 12, (1991) 
Appendix A: Word-List 
   k u: t o: p a k k r \ m \ 
 
p r u t a g j a n \  
 
k r \ m a k k r \ m \ y e n  
 
s t r i: n 
 
v i d y a: j ? \ y a: 
 
k r u m i y a: 
 
p i: t t r u: n 
  s a u b a: g y \ 
 
k a: v y o: p \ d e: ? \ y \ 
 
a v i d y a: v \ 
 
p r a j ? a: v \ 
  k o ? s t a n t i n o: p \ l \ y \ 
 
s v a p  n \ 
 
? a l y \ k a r m \ 
 
p a: r l i m e: n t u w \ 
 
d v a n d v \ 
 
h \ r d \ s p a n d \ n \ y \ 
 
s a m p r e: k  ? \ n \ 
 
?  e: ? t r \ 
 
p r \ v u r t i 
 
p r \ v u r j ya: 
 A Rule Based Syllabification Algorithm for Sinhala 447 
 
p r \ ? r a b d i y \ 
 
s a n s k r u t\ 
springs s p r i ? g s  
scratched s k r ? c ? 
straights s t r e: i t s 
strength s t r e n t s 
postscript p o: s t s k r i p t 
area e: r i a: 
Appendix B: Syllabification Algorithm 
function syllabify (phonemes, current_position) 
 if no_of_vowels(phonemes) is 1 then  
  mark_syllable_boundary(at_the_end_of_phonemes) 
 else 
  if is_a_vowel(phonemes[current_position]) is true    
  then 
   no_of_consonants= 
   count_no_of_consonants_upto_next_vowel 
   (phonemes,current_position) 
   if no_of_consonants is 0 then 
    if is_a_vowel(phonemes[current_position+1]) is    
    true then 
     mark_syllable_boundary(current_position) % Rule#3 
     syllabify(phonemes, current_position+1) 
    end if 
   else  
    if no_of_consonants is 1 then 
     mark_syllable_boundary(current_position) % Rule#1 
     syllabify(phonemes, current_position+2) 
    end if 
    if no_of_consonants are 2 then 
     mark_syllable_boundary(current_position+1) 
     syllabify(phonemes, current_position+3) % Rule#2 
    end if 
    if no_of_consonants are 3 then 
448 R. Weerasinghe, A. Wasala, and K. Gamage 
     if phonemes[current_position+3] is 
     ( ?r? or ?y?) then  
       mark_syllable_boundary(current_position+1) 
       % Rule#4 
       syllabify(phonemes, current_position+4) 
     else 
   if is_a_stop(phonemes[current_posi+1]) is  
   true and is_a_stop(phonemes[current_posi+2])) is  
   true then 
       mark_syllable_boundary(current_position+1) 
      % Rule#5 
syllabify(phonemes, current_position+4)  
         else 
   mark_syllable_boundary(current_position+2) 
% Rule#6 
 syllabify(phonemes, current_position+4)  
 end if      
         end if 
        end if 
      if no_of_consonants are greater than 3 then 
       if phonemes[current_position+no_of_consonants]  
       is( ?r? or ?y?) then  
         mark_syllable_boundary 
         (current_position+no_of_consonants-2) % Rule#7 
         Syllabify 
         (phonemes, current_position  
         +no_of_consonants-1)       else 
        syllable_boundary=find_min_sonority_position 
                         (phonemes,current_postion) 
         mark_syllable_boundary(syllable_boundary) 
 % Rule#8 
         Syllabify 
         (phonemes, syllable_boundary+1)  
       end if 
      end if  
 A Rule Based Syllabification Algorithm for Sinhala 449 
     end if 
    else 
     temp=current_postion 
     repeat 
      temp = temp + 1; 
     until(is_a_vowel(phonemes[temp]) is true 
     syllabify(phonemes,temp) 
    end if 
 end if 
NLP Applications of Sinhala: TTS & OCR 
Ruvan Weerasinghe, Asanka Wasala, Dulip Herath and Viraj Welgama 
Language Technology Research Laboratory,  
University of Colombo School of Computing, 
35, Reid Avenue, Colombo 00700, Sri Lanka 
 {arw,raw,dlh,wvw}@ucsc.cmb.ac.lk 
 
 
Abstract 
This paper brings together the practical ap-
plications and the evaluation of the first 
Text-to-Speech (TTS) system for Sinhala 
using the Festival framework and an Opti-
cal Character Recognition system for Sin-
hala. 
1 Introduction 
Language Technology Research Laboratory ? 
(LTRL) of the University of Colombo School of 
Computing (UCSC), was established in 2004 
evolving from work engaged in by academics of 
the university since the early 1990?s in local lan-
guage computing in Sri Lanka. 
Under the scope of the laboratory, numerous 
Natural Language Processing projects are being 
carried out with the relevant national bodies, inter-
national technology partners, local industry and the 
wider regional collaboration particularly within the  
PAN Localization Initiative*. The Sri Lankan com-
ponent of the PAN Localization Project concen-
trated on developing some of the fundamental re-
sources needed for language processing and some 
software tools for immediate deployment at the 
end of the project. Among the resources produced 
is a Sinhala Language Corpus of 10m words, and a 
tri-lingual Sinhala-English-Tamil lexicon. The two 
main software tools developed include a Sinhala 
Text-to-Speech (TTS) system and an Optical Char-
acter Recognition (OCR) system for recognizing 
commonly used Sinhala publications.  
                                                 
? See website: http://www.ucsc.cmb.ac.lk/ltrl 
* See project website: http://www.panl10n.net 
This paper focuses primarily on the end-user ap-
plications developed under the above project; Sin-
hala TTS system and OCR system. The paper de-
scribes the practical applications of these tools and 
evaluates it in the light of experience gained so far. 
The rest of this paper is organized as follows: 
Section 2 gives an overview of the Sinhala TTS 
system; Section 3 describes the Sinhala OCR sys-
tem. A summary along with future research direc-
tions and improvements are discussed in the last 
section. 
2 Sinhala Text-to-Speech System 
Sighted computer users spend a lot of time reading 
items on-screen to do their regular tasks such as 
checking email, fill out spreadsheets, gather infor-
mation from internet, prepare and edit documents, 
and much more. However visually impaired people 
cannot perform these tasks without an assistance 
from other, or without using assistive technologies. 
A TTS (text-to-speech) system takes computer 
text and converts the words into audible speech 
(Dutoit, 1997). With a TTS engine, application, 
and basic computer hardware, one can listen to 
computer text instead of reading it. A Screen 
Reader (2007) is a piece of software that attempts 
to identify and read-aloud what is being displayed 
on the screen. The screen reader reads aloud text 
within a document, and it also reads aloud infor-
mation within dialog boxes and error messages. In 
other words, the primary function of any-screen 
reading system is to become the ?eye? of the visu-
ally impaired computer user. These technologies 
enable blind or visually impaired people to do 
things that they could not perform before by them-
963
selves. As such, text-to-speech synthesizers make 
information accessible to the print disabled. 
Within Sri Lanka, there is a great demand for a 
TTS system in local languages, particularly a 
screen reader or web browser for visually impaired 
people. In the case of the Tamil language, work 
done in India could be used directly. Until the 
LTRL of UCSC initiatives were launched in 2004, 
there was no viable TTS system found developed 
for Sinhala, the mother tongue of 74 % Sri 
Lankans (Karunatillake, 2004). 
A project was launched to develop a ?commer-
cial grade? Sinhala text-to-speech system in UCSC 
in year 2004. Later, it was extended to develop a 
Screen Reader which can be used by visually im-
paired persons for reading Sinhala texts. 
The Sinhala TTS system was implemented 
based on the Festival speech synthesizer (Taylor et 
al., 1998). The Festival speech synthesis system is 
an open-source, stable and portable multilingual 
speech synthesis system developed at Center for 
Speech Technology Research (CSTR), University 
of Edinburgh (Taylor et al, 1998, Black and 
Lenzo, 2003). TTS systems have been developed 
using the Festival framework for different lan-
guages, including English, Japanese, Welsh, Turk-
ish, Hindi, and Telugu (Black and Lenzo, 2003). 
However, efforts are still continuing to develop a 
standard Sinhala speech synthesizer in Sri Lanka.  
The Sinhala text-to-speech system is developed 
based on the diphone concatenation approach. 
Construction of a diphone database and implemen-
tation of the natural language processing modules 
were key research areas explored in this project. In 
this exercise, 1413 diphones were determined. The 
diphones were extracted from nonsensical words, 
and recordings were carried out in a professional 
studio. Moreover, language specific scripts (phone, 
lexicon, tokenization) and speaker specific scripts 
(duration and intonation) were defined for Sinhala. 
It is worthy to mention the development of con-
text-sensitive letter-to-sound conversion rule set 
for Sinhala. Incorporation of a high accuracy na-
tive syllabification routine (Weerasinghe et al, 
2005) and implementation of comprehensive text 
analysis facilities (capable of producing the accu-
rate pronunciation of the elements such as num-
bers, currency symbols, ratios, percentages, abbre-
viations, Roman numerals, time expressions, num-
ber ranges, telephone numbers, email addresses, 
English letters and various other symbols) have 
been found unique for the language (Weerasinghe 
et al, 2007). Despite the Festival's incomplete 
support for UTF-8, the above rules were re-
writtenin UTF-8 multi-byte format following the 
work done for Telugu language (Kamisetty, 2006). 
The current Sinhala TTS engine accepts Sinhala 
Unicode text and converts it into Speech. A male 
voice has been incorporated. Moreover, the system 
has been engineered to be used in deferent plat-
forms, operating systems (i.e. Linux and Windows) 
and by different software applications (Weeras-
inghe et al, 2007).  
2.1 Applications of TTS Synthesis Engine 
Sinhala text is made accessible via two interfaces, 
by the TTS engine. A standalone software named 
?Katha Baha? primarily reads documents in Sin-
hala Unicode text format aloud. The same applica-
tion can also be used to record the synthesized 
speech.  
In this way, local language news papers and text 
books can be easily transformed into audio materi-
als such as CDs. This software provides a conven-
ient way to disseminate up-to-date news and in-
formation for the print disabled. e.g. Newspaper 
company may podcast their news paper, enabling 
access for print disabled and everyone else. Fur-
thermore, the same application can be utilized to 
produce Sinhala digital talking books. To ensure 
the easy access by print disabled, keyboard short 
cuts are provided.  
Owing to the prevalent use of Windows among 
the visually impaired community in Sri Lanka, it 
becomes essential that a system is developed 
within the Windows environment which offers 
Sinhala speech synthesis to existing applications. 
The standard speech synthesis and recognition in-
terface in Microsoft Windows is the Microsoft 
Speech Application Programming Interface (MS-
SAPI) (Microsoft Corporation, n.d.). MS-SAPI 
enabled applications can make use of any MS-
SAPI enabled voice that has been installed in Win-
dows. Therefore, steps were taken to integrate Sin-
hala voice into MS-SAPI. As a result, the MS-
SAPI compliant Sinhala voice is accessible via any 
speech enabled Windows application. The Sinhala 
voice is proved to work well with ?Thunder?? a 
freely available screen reader for Windows. Addi-
tionally, steps were taken to translate and integrate 
                                                 
? Available from: http://www.screenreader.net/ 
964
common words found related to Thunder screen 
reader (e.g. link=????????, list item= ????????? 
??????) (Weerasinghe et al, 2007).  
Since most Linux distributions now come with 
Festival pre-installed, the integration of Sinhala 
voice in such platforms is very convenient. Fur-
thermore, the Sinhala voice developed here was 
made accessible to GNOME-Orca and Gnoperni-
cus - powerful assistive screen reader software for 
people with visual impairments. 
It is noteworthy to mention that for the first time 
in Sri Lankan history, the print disabled commu-
nity will be able to use computers in their local 
languages by using the current Sinhala text-to-
speech system. 
2.2 Evaluation of the Text-to-Speech  Synthe-
sis Engine 
Text-to-speech systems have been compared and 
evaluated with respect to intelligibility (under-
standability of speech), naturalness, and suitability 
for used application (Lemmetty, 1999). As the 
Sinhala TTS system is a general-purpose synthe-
sizer, a decision was made to evaluate it under the 
intelligibility criterion. Specially, the TTS system 
is intended to be used with screen reader software 
by visually impaired people. Therefore, intelligibil-
ity is a more important feature than the naturalness. 
A Modified Rhyme Test (MRT) (Lemmetty, 
1999), was designed to test the Sinhala TTS sys-
tem. The test consists of 50 sets of 6 one or two 
syllable words which makes a total set of 300 
words. The words are chosen to evaluate phonetic 
characteristics such as voicing, nasality, sibilation, 
and consonant germination. Out of 50 sets, 20 sets 
were selected for each listener.  The set of 6 words 
is played one at the time and the listener marks the 
synthesized word. The overall intelligibility of the 
system measured from 20 listeners was found to be 
71.5% (Weerasinghe et al, 2007). 
3 Optical Character Recognition System 
Optical Character Recognition (OCR) technology 
is used to convert information available in the 
printed form into machine editable electronic text 
form through a process of image capture, process-
ing and recognition (Optical Character Recogni-
tion, 2007).  
There are three essential elements to OCR tech-
nology. Scanning ? acquisition of printed docu-
ments as optical images using a device such as 
flatbed scanner. Recognition- involves converting 
these images to character streams representing let-
ters of recognized words and the final element in-
volves accessing or storing the converted text. 
Many OCR systems have been developed for 
recognizing Latin characters (Weerasinghe et al, 
2006). Some OCR systems have been reported to 
have a very high accuracy and most of such sys-
tems are commercial products. Leaving a land 
mark, a Sinhala OCR system has been developed 
at UCSC (Weerasinghe et al, 2006).  
Artificial Neural Network (ANN) and Template 
Matching are two popular and widely used algo-
rithms for optical character recognition. However, 
the  application of above algorithms to a highly 
inflected languages such as Sinhala is arduous due 
to the high number of input classes. Empirical es-
timation of least number of input classes needed 
for  training a neural net for Sinhala character rec-
ognition suggested about  400 classes (Weeras-
inghe et al, 2006). Therefore, less-complicated K-
nearest neighbor algorithm (KNN) was employed 
for the purpose of Sinhala character recognition.  
The current OCR system is the first ever re-
ported OCR system for Sinhala and is capable of 
recognizing printed Sinhala letters typed using 
widely used fonts in the publishing industry. The 
recognized content is presented as editable Sinhala 
Unicode text file (Weerasinghe et al, 2006). 
A large volume of information is available in the 
printed form. The current OCR system will expe-
dite the process of digitizing this information. 
Moreover, the information available via printed 
medium is inaccessible to the print disabled, and 
the OCR system, especially when coupled with 
Sinhala TTS, will provide access to these informa-
tion for the print disabled.  
3.1 Evaluation of the Optical Character Rec-
ognition System 
The performance of the Sinhala OCR system has 
been evaluated using 18000 sample characters for 
Sinhala. These characters have been extracted from 
various books and newspapers (Weerasinghe et al, 
2006). Performance of the system has been evalu-
ated with respect to different best supportive fonts. 
The results have been summarized in the Table 1 
(Weerasinghe et al, 2006). 
 
 
965
Font FM DL Lakbima Letter 
% Recog. 97.17 96.26 89.89 95.81
Table 1. Experimental Results of Classification* 
 
From this evaluation it can be concluded that the 
current Sinhala OCR has average accuracy of 95% 
(Weerasinghe et al, 2006). 
4 Conclusion and Future Work 
This paper brings together the development of a 
diphone voice for Sinhala based on the Festival 
speech synthesis system and an Optical Character 
Recognizer for Sinhala. 
Future work on the Sinhala TTS engine will 
mainly focus on improving the prosody modules. 
A speech corpus containing 2 hours of speech has 
been already recorded. The material is currently 
being segmented, and labeled. We are also 
planning to improve the duration model using the 
data obtained from the annotated speech corpus. It 
is also expected to develop a female voice in near 
future. The current Sinhala OCR system is font 
dependent. Work is in progress to make the OCR 
system font independent and to improve the accu-
racy. Sinhala OCR and the TTS systems, which are 
currently two separate applications, will be inte-
grated enabling the user friendliness to the print 
disabled. 
A number of other ongoing projects are aimed at 
developing resources and tools such as a POS tag 
set, a POS tagger and a tagged corpus for Sinhala, 
an on-the-fly web page translator, a translation 
memory application and several language teaching 
-learning resources for Sinhala, Tamil and English. 
All resources developed under this project are 
made available (under GNU General Public Li-
cense) through the LTRL website.  
Acknowledgement 
This work was made possible through the PAN 
Localization Project, (http://www.PANL10n.net) a 
grant from the International Development Re-
search Center (IDRC), Ottawa, Canada, adminis-
tered through the Center for Research in Urdu 
Language Processing, National University of 
Computer and Emerging Sciences, Pakistan.  
                                                 
*  FM ? ?FM Abhaya?, DL ? ?DL Manel Bold?, Letter ? 
?Letter Press? 
References 
Alan W. Black and Kevin A. Lenzo. 2003. Building 
Synthetic Voices, Language Technologies Institute, 
Carnegie Mellon University and Cepstral LLC. Re-
trieved from http://festvox.org/bsv/. 
Microsoft Corporation. (n.d.). Microsoft Speech SDK 
Version 5.1. Retrieved from:  
http://msdn2.microsoft.com/en-/library/ms990097.aspx 
T. Dutoit. 1997.  An Introduction to Text-to-Speech Syn-
thesis, Kluwer Academic Publishers, Dordrecht, 
Netherlands. 
C. Kamisetty, S.M. Adapa. 2006. Telugu Festival Text-
to-Speech System. Retrieved from:  
http://festival-te.sourceforge.net/wiki/Main_Page 
W.S. Karunatillake. 2004. An Introduction to Spoken 
Sinhala, 3rd edn., M.D. Gunasena & Co. ltd., 217, 
Olcott Mawatha, Colombo 11. 
Sami Lemmetty. 1999. Review of Speech Synthesis 
Technology, MSc. thesis, Helsinki University of 
Technology. 
Screen Reader. 2007. Screen Reader. Retrieved from: 
http://en.wikipedia.org/wiki/Screen_reader. 
Optical Character Recognition. 2007. Optical Character 
Recognition. Retrieved from: 
http://en.wikipedia.org/wiki/Optical_character_recog
nition 
P.A Taylor, A.W. Black, R.J. Caley. 1998. The Archi-
tecture of the Festival Speech Synthesis System, 
Third ESCA Workshop in Speech Synthesis, Jenolan 
Caves, Australia. 147-151. 
Ruvan Weerasinghe, Asanka Wasala, Kumudu Gamage. 
2005. A Rule Based Syllabification Algorithm for 
Sinhala, Proceedings of 2nd International Joint Con-
ference on Natural Language Processing (IJCNLP-
05). Jeju Island, Korea.  438-449. 
Ruvan Weerasinghe, Dulip Lakmal Herath, N.P.K. 
Medagoda. 2006. A KNN based Algorithm for 
Printed Sinhala Character Recognition, Proceedings 
of 8th International Information Technology Confer-
ence, Colombo, Sri Lanka 
Ruvan Weerasinghe, Asanka Wasala, Viraj Welgama 
and Kumudu Gamage. 2007.  Festival-si: A Sinhala 
Text-to-Speech System, Proceedings of 10th Interna-
tional Conference on Text, Speech and Dialogue 
(TSD 2007), Pilse?, Czech Republic, September 3-7, 
2007. 472-479  
966
Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 890?897,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Sinhala Grapheme-to-Phoneme Conversion and  
Rules for Schwa Epenthesis 
 
 
Asanka Wasala, Ruvan Weerasinghe and Kumudu Gamage 
Language Technology Research Laboratory 
University of Colombo School of Computing 
35, Reid Avenue, Colombo 07, Sri Lanka 
{awasala,kgamage}@webmail.cmb.ac.lk, arw@ucsc.cmb.ac.lk 
 
  
 
Abstract 
This paper describes an architecture to 
convert Sinhala Unicode text into pho-
nemic specification of pronunciation. The 
study was mainly focused on disambigu-
ating schwa-/\/ and /a/ vowel epenthesis 
for consonants, which is one of the sig-
nificant problems found in Sinhala. This 
problem has been addressed by formulat-
ing a set of rules. The proposed set of 
rules was tested using 30,000 distinct 
words obtained from a corpus and com-
pared with the same words manually 
transcribed to phonemes by an expert. 
The Grapheme-to-Phoneme (G2P) con-
version model achieves 98 % accuracy. 
1 Introduction 
The conversion of Text-to-Speech (TTS) in-
volves many important processes. These proc-
esses can be divided mainly in to three parts; text 
analysis, linguistic analysis and waveform gen-
eration (Black and Lenzo, 2003). The text analy-
sis process is responsible for converting the non-
textual content into text. This process also in-
volves tokenization and normalization of the 
text. The identification of words or chunks of 
text is called text-tokenization. Text normaliza-
tion establishes the correct interpretation of the 
input text by expanding the abbreviations and 
acronyms. This is done by replacing the non-
alphabetic characters, numbers, and punctuation 
with appropriate text strings depending on the 
context. The linguistic analysis process involves 
finding the correct pronunciation of words, and 
assigning prosodic features (eg. phrasing, intona-
tion, stress) to the phonemic string to be spoken. 
The final process of a TTS system is waveform 
generation which involves the production of an 
acoustic digital signal using a particular synthesis 
approach such as formant synthesis, articulatory 
synthesis or waveform concatenation (Lemmetty, 
1999). The text analysis and linguistic analysis 
processes together are known as the Natural 
Language Processing (NLP) component, while 
the waveform generation process is known as the 
Digital Signal Processing (DSP) component of a 
TTS System (Dutoit, 1997). 
Finding correct pronunciation for a given 
word is one of the first and most significant tasks 
in the linguistic analysis process. The component 
which is responsible for this task in a TTS sys-
tem is often named the Grapheme-To-Phoneme 
(G2P), Text-to-Phone or Letter-To-Sound (LTS) 
conversion module. This module accepts a word 
and generates the corresponding phonemic tran-
scription. Further, this phonemic transcription 
can be annotated with appropriate prosodic 
markers (Syllables, Accents, Stress etc) as well. 
In this paper, we describe the implementation 
and evaluation of a G2P conversion model for a 
Sinhala TTS system. A Sinhala TTS system is 
being developed based on Festival, the open 
source speech synthesis framework. Letter to 
sound conversion for Sinhala usually has simple 
one to one mapping between orthography and 
phonemic transcription for most Sinhala letters. 
However some G2P conversion rules are pro-
posed in this paper to complement the generation 
of more accurate phonemic transcription. 
The rest of this paper is organized as follows: 
Section 2 gives an overview of the Sinhala pho-
nemic inventory and the Sinhala writing system, 
Section 3 briefly discusses G2P conversion ap-
proaches. Section 4 describes the schwa epenthe-
sis issue peculiar to Sinhala and Section 5 ex-
plains the Sinhala G2P conversion architecture. 
890
Section 6 gives experimental results and our dis-
cussion on it. The work is summarized in the 
final section. 
2 Sinhala Phonemic Inventory and 
Writing System 
2.1 The Sinhala Phonemic Inventory 
Sinhala is the official language of Sri Lanka and 
the mother tongue of the majority - 74% of its 
population. Spoken Sinhala contains 40 segmen-
tal phonemes; 14 vowels and 26 consonants as 
classified below in Table 1 and Table 2 (Ka-
runatillake, 2004). 
There are two nasalized vowels occurring in 
two or three words in Sinhala. They are /a~/, /a~:/, 
/?~/ and /?~~:/ (Karunatillake, 2004). Spoken Sin-
hala also has following Diphthongs; /iu/, /eu/, 
/?u/, /ou/, /au/, /ui/, /ei/, /?i/, /oi/ and /ai/  
(Disanayaka, 1991).  
 
Front Central Back  
Short Long Short Long Short Long 
High i     i:      u    u:    
Mid e   e:   \ \: o    o:     
Low ?   ?:   a a:   
 
Table 1. Spoken Sinhala Vowel Classification. 
 
 Lab.Den. Alv.Ret.Pal. Vel.Glo.
Voiceless p    t      ?     k     Stops 
 Voiced b    d    ?     ?     
Voiceless     c      
Affricates
Voiced     ?      
Pre-nasalized 
voiced stops 
b~   d~    ?~     ?~     
Nasals m    n     ?   ?     
Trill   r         
Lateral   l         
Spirants f     s       ?    h    
Semivowels w       j      
 
Table 2*. Spoken Sinhala Consonant  
Classification. 
 
A separate sign for vowel /\/ is not provided by 
the Sinhala writing system. In terms of distribu-
tion, the vowel /\/ does not occur at the begin-
ning of a syllable except in the conjugational 
variants of verbs formed from the verbal stem 
/k\r\/ (to do). In contrast to this, though the letter 
                                                 
* Lab. ? Labial, Den. ? Dental, Alv. ? Alveolar, Ret. ?
Retroflex, Pal. ? Palatal, Vel. ? Velar and Glo. ? Glottal. 
???, which symbolizes the consonant sound /?~/ 
exists, it is not considered a phoneme in Sinhala. 
2.2 The Sinhala Writing System 
The Sinhala character set has 18 vowels, and 42 
consonants as shown in Table 3. 
 
Vowels and corresponding vowel modifiers 
(within brackets): 
?  ?(??) ?(??)  ?(??) ?(?)? ?(?)? ?(?)? ?(?)? ?(??) 
?(??) ?(??) ?(??) ?(??) ?(???) ?(??) 
?(???)  ? (???)  ?(???) 
 
Consonants: 
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?? ??  
 
Special symbols: ??    ??     ?   ? 
Inherent vowel remover (Hal marker): ? ?  
 
Table 3. Sinhala Character Set. 
 
Sinhala characters are written left to right in 
horizontal lines. Words are delimited by a space 
in general. Vowels have corresponding full-
character forms when they appear in an absolute 
initial position of a word. In other positions, they 
appear as ?strokes? and, are used with consonants 
to denote vowel modifiers. All vowels except 
??? /iru:/, are able to occur in word initial posi-
tions (Disanayaka, 1995). The vowel /?/ and /?:/ 
occurs only in loan words of English origin. 
Since there are no special symbols to represent 
them, frequently the ??? vowel is used to sym-
bolize them (Karunatillake, 2004). 
All consonants occur in word initial position 
except /?/ and nasals (Disanayaka, 1995). The 
symbols ???, and ??? represent the retroflex 
nasal /?/ and the retroflex lateral /?/ respectively. 
But they are pronounced as their respective 
alveolar counterparts ???-/n/ and ???-/l/. 
Similarly, the symbol ??? representing the 
retroflex sibilant /?/, is pronounced as the palatal 
sibilant ???-/?/. The corresponding aspirated 
symbols of letters ?, ?, ?, ?, ?, ?, ?, ?, ?, ? 
namely ?, ?, ?, ?, ?, ?, ?, ?, ? respectively 
are pronounced like the corresponding un-
aspirates (Karunatillake, 2004). When conso-
nants are combined with /r/ or /j/, special con-
junct symbols are used. ????-/r/ immediately fol-
lowing a consonant can be marked by the symbol 
???? added to the bottom of the consonant preced-
ing it. Similarly, ????-/j/, immediately following 
consonant can be marked by the symbol ???? 
891
added to the right-hand side of the consonant 
preceding it (Karunatillake, 2004). ??? /ilu/ and 
??? /ilu:/ do not occur in contemporary Sinhala 
(Disanayaka, 1995). Though there are 60 sym-
bols in Sinhala (Disanayaka, 1995), only 42 
symbols are necessary to represent Spoken Sin-
hala (Karunatillake, 2004). 
3 G2P Conversion Approaches 
The issue of mapping textual content into pho-
nemic content is highly language dependent. 
Three main approaches of G2P conversion are; 
use of a pronunciation dictionary, use of well 
defined language-dependent rules and data-
driven methods (El-Imam and Don, 2005). 
One of the easiest ways of G2P conversion is 
the use of a lexicon or pronunciation dictionary. 
A lexicon consists of a large list of words to-
gether with their pronunciation. There are several 
limitations to the use of lexicons. It is practically 
impossible to construct such to cover the whole 
vocabulary of a language owing to Zipfian phe-
nomena. Though a large lexicon is constructed, 
one would face other limitations such as efficient 
access, memory storage etc. Most lexicons often 
do not include many proper names, and only 
very few provide pronunciations for abbrevia-
tions and acronyms. Only a few lexicons provide 
distinct entries for morphological productions of 
words. In addition, pronunciations of some 
words differ based on the context and their parts-
of-speech. Further, an enormous effort has to be 
made to develop a comprehensive lexicon. In 
practical scenarios, speech synthesizers as well 
as speech recognizers need to be able to produce 
the pronunciation of words that are not in the 
lexicon. Names, morphological productivity and 
numbers are the three most important cases that 
cause the use of lexica to be impractical (Juraf-
sky and Martin, 2000).  
To overcome these difficulties, rules can be 
specified on how letters can be mapped to pho-
nemes. In this way, the size of the lexicon can be 
reduced as only to contain exceptions to the 
rules. In contrast to the above fact, some systems 
rely on using very large lexicons, together with a 
set of letter-to-sound conversion rules to deal 
with words which are not found in the lexicon 
(Black and Lenzo, 2003). 
These language and context dependent rules 
are formulated using phonetic and linguistic 
knowledge of a particular language. The com-
plexity of devising a set of rules for a particular 
language is dependent on the degree of corre-
spondence between graphemes and phonemes. 
For some languages such as English and French, 
the relationship is complex and require large 
numbers of rules (El-Imam and Don, 2005; 
Damper et al, 1998), while some languages such 
as Urdu (Hussain, 2004), and Hindi (Ramakish-
nan et al, 2004; Choudhury, 2003) show regular 
behavior and thus pronunciation can be modeled 
by defining fairly regular simple rules. 
Data-driven methods are widely used to avoid 
tedious manual work involving the above ap-
proaches. In these methods, G2P rules are cap-
tured by means of various machine learning 
techniques based on a large amount of training 
data. Most previous data-driven approaches have 
been used for English. Widely used data-driven 
approaches include, Pronunciation by Analogy 
(PbA), Neural Networks (Damper et al, 1998), 
and Finite-State-Machines (Jurafsky and Martin, 
2000). Black et al (1998) discussed a method for 
building general letter-to-sound rules suitable for 
any language, based on training a CART ? deci-
sion tree. 
4 Schwa Epenthesis in Sinhala 
G2P conversion problems encountered in Sinhala 
are similar to those encountered in the Hindi lan-
guage (Ramakishnan et al, 2004). All consonant 
graphemes in Sinhala are associated with an in-
herent vowel schwa-/?/ or /a/ which is not repre-
sented in orthography. Vowels other than /?/ and 
/a/ are represented in orthographic text by plac-
ing specific vowel modifier diacritics around the 
consonant grapheme. In the absence of any 
vowel modifier for a particular consonant graph-
eme, there is an ambiguity of associating /?/ or 
/a/ as the vowel modifier. The inherent vowel 
association in Sinhala can be distinguished from 
Hindi. In Hindi the only possible association is 
schwa vowel where as in Sinhala either of 
vowel-/a/ or schwa-/?/ can be associated with a 
consonant. Native Sinhala speakers are naturally 
capable of choosing the association of the appro-
priate vowel (/?/ or /a/) in context. Moreover, 
linguistic rules describing the transformation of 
G2P, is rarely found in literature, with available 
literature not providing any precise procedure 
suitable for G2P conversion of contemporary 
Sinhala. Automating the G2P conversion process 
is a difficult task due to the ambiguity of choos-
ing between /?/ and /a/. 
A similar phenomenon is observed in Hindi 
and Malay as well. In Hindi, the ?deletion of the 
schwa vowel (in some cases)? is successfully 
892
solved by using rule based algorithms (Choud-
hury 2003; Ramakishnan et al, 2004). In Malay, 
the character ?e? can be pronounced as either 
vowel /e/ or /?/, and rule based algorithms are 
used to address this ambiguity (El-Imam and 
Don, 2005). 
In our research, a set of rules is proposed to 
disambiguate epenthesis of /a/ and /?/, when as-
sociating with consonants. Unlike in Hindi, in 
Sinhala, the schwa is not deleted, instead always 
inserted. Hence, this process is named ?Schwa 
Epenthesis? in this paper. 
5 Sinhala G2P Conversion Architecture 
An architecture is proposed to convert Sinhala 
Unicode text into phonemes encompassing a set 
of rules to handle schwa epenthesis. The G2P 
architecture developed for Sinhala is identical to 
the Hindi G2P architecture (Ramakishnan et al, 
2004). The input to the system is normalized 
Sinhala Unicode text. The G2P engine first maps 
all characters in the input word into correspond-
ing phonemes by using the letter-to-phoneme 
mapping table below (Table 4).  
 
?  /a/ ? ,???  /o/ ? /?~/ ? /f/ 
?,?? /a:/ ?,??? /o:/ ?,? /t/ ?? /ru:/ 
?,?? /?/ ?,??? /ou/ ?,? /d/    
?,?? /?:/ ?,? /k/ ? /d~/   
? ,? ? /i/ ?,? /?/ ?,? /p/   
?,? ? /i:/ ?,??  /?/ ?,? /b/   
?,? ? /u/ ? /?~/ ? /m/   
?.? ? /u:/ ?,? /c/ ? /b~/   
??  /ri/ ?,? /?/ ? /j/   
??  /ru/ ? /?/ ? /r/   
? /ilu/ ? /j?/ ?,? /l/   
? /ilu:/ ? /?~/ ? /w/   
? ,??  /e/ ?,? /?/ ?,? /?/   
?,??? /e:/ ?,? /?/ ? /s/   
?,?? /ai/ ?,? /n/ ?,?? /h/   
 
Table 4. G2P Mapping Table 
 
The mapping procedure is given in section 5.1. 
Then, a set of rules are applied to this phonemic 
string in a specific order to obtain a more accu-
rate version. This phonemic string is then com-
pared with the entries in the exception lexicon. If 
a matching entry is found, the correct pronuncia-
tion form of the text is obtained from the lexicon, 
otherwise the resultant phonemic string is re-
turned. Hence, the final output of G2P model is 
the phonemic transcription of the input text. 
5.1 G2P Mapping Procedure 
Each tokenized word represented by Unicode 
normalization form is analyzed by individual 
graphemes from left to right. By using the G2P 
mapping table (Table 4), corresponding pho-
nemes are obtained. As in the given example   
Figure 1, no mappings are required for the Zero-
Width-Joiner and diacritic Hal marker ???? (Ha-
lant) which is used to remove the inherent vowel 
in a consonant. 
 
  
  
  
  
  
  
  
  
  
Figure 1. G2P Mapping (Example). 
 
The next step is epenthesis of schwa-/?/ for 
consonants. In Sinhala, the tendency of associat-
ing a /?/ with consonant is very much higher than 
associating vowel /a/. Therefore, initially, all 
plausible consonants are associated with /?/. To 
obtain the accurate pronunciation, the assigned 
/?/ is altered to /a/ or vice versa by applying the 
set of rules given in next section. However, when 
associating /?/ with consonants, /?/ should asso-
ciate only with consonant graphemes excluding 
the graphemes ????, ??? and ????, which do not 
contain any vowel modifier or diacritic Hal 
marker. In the above example, only /n/ and first 
/j/ are associated with schwa, because other con-
sonants violate the above principle. When schwa 
is associated with appropriate consonants, the 
resultant phonemic string for the given example 
(section 5.1) is; /n?mj?ji/. 
5.2 G2P Conversion Rules 
It is observed that resultant phoneme strings 
from the above procedure should undergo several 
modifications in terms of schwa assignments into 
vowel /a/ or vice versa, in order to obtain the ac-
curate pronunciation of a particular word. 
Guided by the literature (Karunatillake, 2004), it 
was noticed that these modifications can be car-
ried out by formulating a set of rules.  
The G2P rules were formulated with the aid of 
phonological rules described in the linguistic 
literature (Karunatillake, 2004) and by a com-
prehensive word search analysis using the UCSC 
893
Sinhala corpus BETA (2005). Some of these ex-
isting phonological rules were altered in order to 
reflect the observations made in the corpus word 
analysis and to achieve more accurate results. 
The proposed new set of rules is empirically 
shown to be effective and can be conveniently 
implemented using regular expressions. 
Each rule given below is applied from left to 
right, and the presented order of the rules is to be 
preserved. Except for rule #1, rule #5, rule #6 
and rule #8, all other rules are applied repeatedly 
many times to a single word until the conditions 
presented in the rules are satisfied. 
Rule #1: If the nucleus of the first syllable is a 
schwa, the schwa should be replaced by vowel 
/a/ (Karunatillake, 2004), except in the following 
situations;   
(a) The syllable starts with /s/  followed by /v/.   
(ie. /sv/)  
(b) The first syllable starts with /k/ where as, 
/k/ is followed by /?/ and subsequently /?/ is pre-
ceded by /r/.  (ie. /k?r/) 
(c) The word consists of a single syllable having 
CV structure (eg. /d?/ ?) 
Rule #2: 
(a) If /r/ is preceded by any consonant, followed 
by /?/ and subsequently followed by /h/, then /?/ 
should be replaced by /a/. 
(/[consonant]r?h/->/[consonant]rah/ ) 
(b) If /r/ is preceded by any consonant, followed 
by /?/ and subsequently followed by any conso-
nant other than /h/, then /?/ should be replaced by 
/a/. 
(/[consonant]r?[!h]/->/[consonant]ra[!h]/ ) 
(c) If /r/ is preceded by any consonant, followed 
by /a/ and subsequently followed by any conso-
nant other than /h/, then /a/ should be replaced by 
/?/. 
(/[consonant]ra[!h]/->/[consonant]r?!h]/) 
(d) If /r/ is preceded by any consonant, followed 
by /a/ and subsequently followed by /h/, then /a/ 
is retained. 
(/[consonant]ra[h]/->/[consonant]ra[h]/) 
Rule #3: If any vowel in the set {/a/, /e/, /?/, /o/, 
/\/} is followed by /h/ and subsequently /h/ is 
preceded by schwa, then schwa should replaced 
by vowel /a/. 
Rule #4: If schwa is followed by a consonant 
cluster, the schwa should be replaced by /a/ (Ka-
runatillake, 2004). 
Rule #5: If /?/ is followed by the word final con-
sonant, it should be replaced by /a/, except in the 
situations where the word final consonant is /r/, 
/b/, /?/ or /?/. 
Rule #6: At the end of a word, if schwa precedes 
the phoneme sequence /ji/, the schwa should be 
replaced by /a/ (Karunatillake, 2004). 
Rule #7: If the /k/ is followed by schwa, and 
subsequent phonemes are /r/ or /l/ followed by 
/u/, then schwa should be replaced by phoneme 
/a/. (ie. /k?(r|l)u/->/ka(r|l)u/) 
Rule #8: Within the given context of following 
words, /a/ found in phoneme sequence /kal/, (the 
left hand side of the arrow) should be changed to 
/?/ as shown in the right hand side.  
? /kal(a:|e:|o:)y/->/k?l(a:|e:|o:)y/ 
? /kale(m|h)(u|i)/->/k?le(m|h)(u|i)/ 
? /kal?h(u|i)/->/k?leh(u|i)/ 
? /kal?/->/k?l?/ 
The above rules handle the schwa epenthesis 
problem. The corresponding diphthongs (refer 
section 2) are then obtained by processing the 
resultant phonetized string. This string is again 
analyzed from left to right, and the phoneme se-
quences given in the first column of Table 5 are 
replaced by the diphthong, represented in the 
second column. 
 
Phoneme Sequence Diphthong 
/i/ /w/ /u/ /iu/ 
/e/ /w/ /u/   /eu/ 
/?/ /w/ /u/ /?u/ 
/o/ /w/ /u/   /ou/ 
/a/ /w/ /u/  /au/ 
/u/ /j/ /i/   /ui/ 
/e/ /j/ /i/   /ei/ 
/?/ /j/ /i/   /?i/ 
/o/ /j/ /i/   /oi/ 
/a/ /j/ /i/   /ai/ 
 
Table 5. Diphthong Mapping Table. 
 
The application of the above rules for the 
given example (section 5.1) is illustrated in Fig-
ure 2. 
 
 
Figure 2. Application of G2P Rules ? An Exam-
ple. 
894
6  Results and Discussion 
Text obtained from the category ?News Paper> 
Feature Articles > Other? of the UCSC Sinhala 
corpus was chosen for testing due to the hetero-
geneous nature of these texts and hence per-
ceived better representation of the language in 
this part of the corpus*. A list of distinct words 
was first extracted, and the 30,000 most fre-
quently occurring words chosen for testing.  
The overall accuracy of our G2P module was 
calculated at 98%, in comparison with the same 
words correctly transcribed by an expert.  
Since this is the first known documented work 
on implementing a G2P scheme for Sinhala, its 
contribution to the existing body of knowledge is 
difficult to evaluate. However, an experiment 
was conducted in order to arrive at an approxi-
mation of the scale of this contribution. 
It was first necessary, to define a baseline 
against which this work could be measured. 
While this could be done by giving a single de-
fault letter-to-sound mapping for any Sinhala 
letter, owing to the near universal application of 
rule #1 in Sinhala words (22766 of the 30000 
words used in testing), the baseline was defined 
by  the application of this rule in addition to the 
?default mapping?. This baseline gives us an er-
ror of approximately 24%. Since the proposed 
solution reduces this error to 2%, this work can 
claim to have improved performance by 22%. 
An error analysis revealed the following types 
of errors (Table 6): 
 
Error description # of 
words 
Compound words- (ie. Single words 
formed by combining 2 or more distinct 
words; such as in the case of the English 
word ?thereafter?).  
382 
 
Foreign (mainly English) words directly 
encoded in Sinhala. eg. ????? - fashion, 
??????? - campus. 
116 
Other  118 
 
Table 6. Types of Errors. 
 
The errors categorized as ?Other? are given 
below with clarifications: 
? The modifier used to denote long vowel 
??? /a:/ is ???? which is known as ?Aela-
pilla?. eg. consonant ???? /k/ associates 
with ???? /a:/ to produce grapheme ???? is 
pronounced as /ka:/. The above exercise 
                                                 
* This accounts for almost two-thirds of the size of this ver-
sion of the corpus. 
revealed some 37 words end without 
vowel modifier ????, but are usually pro-
nounced with the associated long vowel 
/a:/. In the following examples, each input 
word is listed first, followed by the erro-
neous output of G2P conversion, and cor-
rect transcription.   
??????(mother) -> /amm?/ -> /amma:/ 
??????(sister) -> /akk?/ -> /akka:/ 
??????(taken)-> /gatt?/ -> /gatta:/ 
? There were 27 words associated with er-
roneous conversion of words having the 
letter ???, which corresponds to phoneme 
/h/. The study revealed this letter shows an 
unusual behavior in G2P conversion. 
? The modifier used to denote vowel ??? 
- ???? is known as ?Geta-pilla?. When 
this vowel appears as the initial letter of a 
word, it is pronounced as /ri/ as in ???? 
/rin?/ (minus). When the corresponding 
vowel modifier appears in a middle of a 
word most of the time it is pronounced as 
/ru/ (Disanayaka, 2000). eg. ??????? 
(book)is pronounced as /krutij?/, ???????? 
(surface) - /pru??\j\/, ?????????? (excel-
lent)-/utkru??\/. But 13 words were found 
as exceptions of this general rule. In those 
words, the ???? is pronounced as /ur/ 
rather than /ru/. eg. ????????? (news)- 
/pr?wurti/,?????????(prosperity)-/samurdi/, 
??????? (opened) - /wiwurt?/. 
? In general, vowel modifiers ???? (Adha-
pilla), ???? (Diga Adha-pilla) symbolizes 
the vowel ??? /?/ and ??? /?:/ respec-
tively. eg. consonant ???? /k/ combines 
with vowel modifier ???? to create ???? 
which is pronounced as /k?/. Few words 
were found where this rule is violated. In 
such words, the vowel modifiers ???? and  
???? represent vowels ???- /u/, and ???- 
/u:/ respectively.  eg. ???????? (legend) - 
/?an??ruti/, ????? (cruel) - /kru:r\/.  
? The verbal stem ???? (to do) is pro-
nounced as /k?r?/. Though there are many 
words starting with the same verbal stem, 
there are a few other words differently 
pronounced as /kar?/ or /kara/. eg. 
???????? (cart) /karatt?y?/, ?????? 
(dried fish)  /kar?v?l?/. 
895
? A few of the remaining errors are due to 
homographs; ???? - /van?/, /v?n?/; ???? 
-/kal?/, /k?l?/; ????  - /kar?/, /k?r?/. 
The above error analysis itself shows that the 
model can be extended. Failures in the current 
model are mostly due to compound words and 
foreign words directly encoded in Sinhala 
(1.66%). The accuracy of the G2P model can be 
increased significantly by incorporating a 
method to identify compound words and tran-
scribe them accurately. If the constituent words 
of a compound word can be identified and sepa-
rated, the same set of rules can be applied for 
each constituent word, and the resultant pho-
netized strings combined to obtain the correct 
pronunciation. The same problem is observed in 
the Hindi language too. Ramakishnan et al 
(2004) proposed a procedure for extracting com-
pound words from a Hindi corpus. The utiliza-
tion of compound word lexicon in their rule-
based G2P conversion module improved the ac-
curacy of G2P conversion by 1.6% (Ramakish-
nan et al, 2004). In our architecture, the most 
frequently occurring compound words and for-
eign words are dealt with the aid of an excep-
tions lexicon. Homographs are also disambigu-
ated using the most frequently occurring words 
in Sinhala. Future improvements of the architec-
ture will include incorporation of a compound 
word identification and phonetization module.  
7 Conclusion 
In this paper, the problem of Sinhala grapheme-
to-phoneme conversion is addressed with a spe-
cial focus on dealing with the schwa epenthesis. 
The proposed G2P conversion mechanism will 
be useful in various applications in the speech 
domain. To the best of our knowledge no other 
documented evidence has been reported for Sin-
hala grapheme-to-phoneme conversion in the 
literature. There are no other approaches avail-
able for the transcription of Sinhala text that pro-
vides a platform for comparison of the proposed 
rule-based method. The empirical evidence from 
a wide spectrum Sinhala corpus indicates that the 
proposed model can account for nearly 98% of 
cases accurately. 
The proposed G2P module is fully imple-
mented in Sinhala TTS being developed at Lan-
guage Technology Research Lab, UCSC. A 
demonstration tool of the proposed G2P module 
integrated with Sinhala syllabification algorithm 
proposed by Weerasinghe et al (2005) is avail-
able for download from: 
http://www.ucsc.cmb.ac.lk/ltrl/downloads.html 
Acknowledgement 
This work has been supported through the PAN 
Localization Project, (http://www.PANL10n.net) 
grant from the International Development Re-
search Center (IDRC), Ottawa, Canada, adminis-
tered through the Center for Research in Urdu 
Language Processing, National University of 
Computer and Emerging Sciences, Pakistan. The 
authors would like to thank Sinhala Language 
scholars Prof. R.M.W. Rajapaksha, and Prof. J.B. 
Dissanayake for their invaluable support and ad-
vice throughout the study. Special thanks to Dr. 
Sarmad Hussain (NUCES, Pakistan) for his 
guidance and advices. We also wish to acknowl-
edge the contribution of Mr. Viraj Welgama, Mr. 
Dulip Herath, and Mr. Nishantha Medagoda of 
Language Technology Research Laboratory of 
the University of Colombo School of Comput-
ing, Sri Lanka. 
References 
Alan W. Black and Kevin A. Lenzo. 2003. Building 
Synthetic Voices, Language Technologies Insti-
tute, Carnegie Mellon University and Cepstral 
LLC. Retrieved from http://festvox.org/bsv/ 
Alan W. Black, Kevin Lenzo, and Vincent Pagel. 
1998. Issues in Building General Letter to Sound 
Rules. In Proc. of the 3rd ESCA Workshop on 
Speech Synthesis, pages 77?80. 
Monojit Choudhury. 2003. Rule-Based Grapheme to 
Phoneme Mapping for Hindi Speech Synthesis, 
presented at the 90th Indian Science Congress 
of the International Speech Communication 
Association (ISCA), Bangalore. 
R.I. Damper, Y. Marchand, M.J. Adamson and K. 
Gustafson. 1998. Comparative Evaluation of Let-
ter-to-Sound Conversion Techniques for English 
Text-to-Speech Synthesis. In Proc. Third 
ESCA/COCOSDA Workshop on Speech Syn-
thesis, pages 53- 58, Blue Mountains, NSW, Aus-
tralia. 
J.B. Disanayaka. 1991. The Structure of Spoken 
Sinhala, National Institute of Education, Ma-
haragama.  
J.B. Disanayaka. 2000. Basaka Mahima: 2, Akuru 
ha pili, S. Godage & Bros., 661, P. D. S. 
Kularathna Mawatha, Colombo 10. 
J.B. Disanayaka. 1995. Grammar of Contemporary 
Literary Sinhala - Introduction to Grammar, 
896
Structure of Spoken Sinhala, S. Godage & Bros., 
661, P. D. S. Kularathna Mawatha, Colombo 10. 
T. Dutoit. 1997.  An Introduction to Text-to-
Speech Synthesis, Kluwer Academic Publishers, 
Dordrecht,  Netherlands. 
Yousif A. El-Imam and Zuraidah M. Don. 2005. 
Rules and Algorithms for Phonetic Transcription of 
Standard Malay, IEICE Trans Inf & Syst, E88-D 
2354-2372. 
Sarmad Hussain. 2004. Letter-to-Sound Conversion 
for Urdu Text-to-Speech System, Proceedings of 
Workshop on "Computational Approaches to 
Arabic Script-based Languages," COLING 
2004, p. 74-49, Geneva, Switzerland. 
Daniel Jurafsky and James H. Martin. 2000. Speech 
and Language Processing: An Introduction to 
Natural Language Processing, Computational 
Linguistics, and Speech Recognition. Pearson 
Education (Singapore) Pte. Ltd, Indian Branch, 482 
F.I.E. Patparganj, Delhi 110 092, India. 
W.S. Karunatillake. 2004. An Introduction to Spo-
ken Sinhala, 3rd  edn., M.D. Gunasena & Co. ltd., 
217, Olcott Mawatha, Colombo 11. 
Sami Lemmetty. 1999. Review of Speech Synthesis 
Technology, MSc. thesis, Helsinki University of 
Technology. 
A.G. Ramakishnan, Kalika Bali, Partha Pratim Taluk-
dar N. and Sridhar Krishna. 2004. Tools for the 
Development of a Hindi Speech Synthesis System, 
In 5th ISCA Speech Synthesis Workshop, Pitts-
burgh. pages 109-114. 
Ruvan Weerasinghe, Asanka Wasala and Kumudu 
Gamage. 2005. A Rule Based Syllabification Algo-
rithm for Sinhala, Proceedings of 2nd Interna-
tional Joint Conference on Natural Language 
Processing (IJCNLP-05), p. 438-449, Jeju Is-
land, Korea. 
UCSC Sinhala Corpus BETA. 2005. Retrieved Au-
gust 30, 2005, from University of Colombo School 
of Computing, Language Technology Research 
Laboratory Web site: 
http://www.ucsc.cmb.ac.lk/ltrl/downloads.html 
 
897
Proceedings of the 3rd Workshop on the People?s Web Meets NLP, ACL 2012, pages 15?19,
Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational Linguistics
Collaboratively Building Language Resources while Localising the Web 
Asanka Wasala, Reinhard Sch?ler, Ruvan Weerasinghe* and Chris Exton 
Centre for Next Generation Localisation/Localisation Research Centre 
CSIS Department, University of Limerick, Limerick, Ireland 
*University of Colombo School of Computing, 35, Reid Avenue, Colombo 00700, Sri Lanka 
{Asanka.Wasala, Reinhard.Schaler, Chris.Exton}@ul.ie, 
*arw@ucsc.cmb.ac.lk 
 
 
Abstract 
In this paper, we propose the collaborative 
construction of language resources (transla-
tion memories) using a novel browser exten-
sion-based client-server architecture that 
allows translation (or ?localisation?) of web 
content capturing and aligning source and tar-
get content produced by the ?power of the 
crowd?. The architectural approach chosen 
enables collaborative, in-context, and real-
time localisation of web content supported by 
the crowd and high-quality language resources. 
To the best of our knowledge, this is the only 
practical web content localisation methodolo-
gy currently being proposed that incorporates 
the collaborative construction and use of TMs. 
The approach also supports the building of re-
sources such as parallel corpora ? resources 
that are still not available for many, and espe-
cially not for underserved languages. 
1 Introduction 
A vast amount of knowledge is available on the 
web, primarily in English. There are millions of 
people worldwide, who cannot assimilate this 
knowledge mainly due the language service barrier. 
Although English is still dominating the web, the 
situation is changing. Non-English content is 
growing rapidly (Large and Moukdad, 2000; Dan-
iel Brandon, 2001; Wasala and Weerasinghe,  
2008).  
Localisation is the translation and adaptation of 
digital content. Localisation of a website involves 
?translating text, content and adjusting graphical 
and visual elements, content and examples to make 
them culturally appropriate? (Stengers et al, 2004). 
However, the scope of our research is limited to 
the translation of text, which is arguably the most 
crucial component of web content localisation. 
The study of web content localisation is a rela-
tively new field within academia (Jim?nez-Crespo, 
2011). The only reported approaches to website 
localisation are human (Daniel Brandon, 2001) and 
machine-based translation (Large and Moukdad, 
2000; Daniel Brandon, 2001; Wasala and We-
erasinghe, 2008), with only very basic collabora-
tive (Horvat, 2012) or first in-context approaches 
(Boxma, 2012) attempted. Although researchers 
have reported on the use of Machine Translation 
(MT) in web content localisation (Gaspari, 2007), 
the low quality of the MT-based website transla-
tion solutions is known to have been a significant 
drawback (Large and Moukdad, 2000; Daniel 
Brandon, 2001). Moreover, the research and de-
velopment of MT systems for less-resourced lan-
guages is still in its infancy (Wasala and 
Weerasinghe, 2008). Therefore, MT-based web 
content localisation solutions are clearly not viable 
for less-resourced languages. 
Undoubtedly, Web 2.0 and the constant in-
crease of User Generated Content (UGC) lead to a 
higher demand for translation. The trend of crowd-
sourcing/social translation came into play only in 
the last few years. In this paper, we focus on 
crowdsourcing translation, i.e. when the crowd or a 
motivated part of it, participates in an open call to 
translate some content, creating highly valuable 
language resources in the process. 
Browser extensions enhance the functionality of 
web browsers. Various browser extensions already 
exist that are capable of utilising existing Machine 
Translation (MT) services to translate web content 
into different languages. We exploit the power of 
15
browser extensions to design a conceptual localiza-
tion layer for the web. Our research is mainly in-
spired by the works of Exton et al (2009) on real-
time localisation of desktop software using the 
crowd, Wasala and Weerasngihe (2008) on brows-
er based pop-up dictionary extension, and Sch?ler 
on information sharing across languages (2012a) as 
well as social localisation (2012b). 
The proposed architecture enables in-context 
real-time localisation of web content by communi-
ties sharing not just their content but also their lan-
guage skills. The ultimate aim of this work is the 
collaborative creation of TMs which will allow for 
the automatic translation of web content based on 
reviewed and quality-checked, human produced 
translations. To the best of the authors? knowledge, 
this is the first effort of its kind to utilise the power 
of browser extensions along with TMs to build a 
website independent conceptual localisation layer 
with the aid of crowdsourcing. 
The rest of the paper is organized as follows: 
Section 2 describes the architecture of the pro-
posed system in detail; the development of the pro-
totype is discussed in section 3; section 4 discusses 
key outstanding challenges and constraints of the 
proposed architecture; and finally, this paper con-
cludes with a summary and discussion of future 
research directions. 
2 System Architecture 
In this section, the main functionalities of the pro-
posed system architecture are described in detail. 
The proposed system architecture is based on 
earlier work by Exton et al (2009). They proposed 
a client-server architecture known as Update-Log-
Daemon (UpLoD) for the localisation of applica-
tions? User Interface (UI) by the crowd. However, 
in our architecture, clients (browsers) connect to 
the central server via a browser extension. The 
browser extension implements the UpLoD archi-
tecture, which acts as a proxy between the browser 
and the central server. 
We also extend the functionality of the central 
server in this architecture by equipping it with a 
component to maintain TMs for different language 
pairs.  
2.1  Content Retrieval and Rendering Process 
When the browser extension is installed and ena-
bled, it allows a user to select the preferred locale. 
When a new URL is typed in, the browser will 
download the page. As soon as the content is 
downloaded, the browser extension will consult the 
central server for any TM matches in the user?s 
preferred locale for the relevant URL. The TM 
matches will be retrieved with the contextual in-
formation. The next step is to replace the original 
content with the retrieved TM matches. With the 
aid of contextual hints that it received, the TM 
matches (i.e. target strings) will be replaced with 
the source strings. Finally, the content will be ren-
dered in the browser. The contextual information 
may include: URL, last update date/time stamp, 
surrounding text with and without tags, XPath lo-
cation of the segment, CSS properties among oth-
ers as this information will helpful to precisely 
locate HTML elements in a web page (Selenium 
2012). For replacing the original text with target 
strings, techniques such as Regular-expressions 
matching and XPath queries may be utilized. 
2.2 Content Translation Process 
The browser extension also facilitates the in-
context translation of source content. Right click-
ing on a selected text will bring up a contextual 
menu where a ?Translate? sub-menu can be found. 
The extension allows in-context translation of 
the selected content segment in an editing envi-
ronment similar to Wikipedia. Once the translation 
is completed, the extension sends the translated 
segment, original content and contextual infor-
mation including URL to the central sever. Upon 
receiving translations from a client, the central 
server stores all the information that it retrieves in 
a TM.  
The central server can be scheduled to periodi-
cally leverage translations as the TMs grow. Fur-
thermore, later on, MT systems can be trained from 
the TM data and these trained MT systems can 
feed back into the system to speed up the trans-
lation process as well as to translate the content 
where TM matches are not found. 
2.3 Translation Editing and Voting Process 
As in the case of software localisation (Exton et al, 
2009), a mechanism has to be built to choose the 
most appropriate translation of a given text seg-
ment. To assist in selecting the best translation for 
a given segment, a voting mechanism is proposed. 
16
However, human intervention (mainly the opinions 
of experts) is essential to solve potential conflicts. 
Right clicking on a translated segment brings 
up a context menu, where the current translation 
along with the top 3 alternative translations is dis-
played. The votes for each translation will also be 
displayed next to the translation. The users are giv-
en the opportunity to edit the current translation 
and/or to vote any of the alternative translations. 
Furthermore, clicking on an alternative transla-
tion will take the user to a web page where the user 
can see all the alternative translations that are pro-
posed for the selected segment. In that page users 
can vote for any of the alternate translations. 
Considering the motivation factors related to 
crowdsourcing, a simple ?thumbs up, thumbs 
down? voting is proposed over complex and con-
fusing rating systems. If the user wishes to edit the 
existing translation, they can simply go to the in-
context edit mode and edit the content. Once edit-
ing has been performed, the new translation is sent 
back to the central server. The central server com-
pares the new changes with the existing transla-
tions and includes it as an alternative translation.  
The central server needs to keep track of the 
votes as well as the voters. By keeping track of 
voters, users can be encouraged to vote for addi-
tional translations using ranking systems similar to 
those implemented in games.  
3 Development of the Prototype 
To test the above architecture, we developed a pro-
totype with the aid of two open source Firefox 
Add-ons: 
 
1. Ingiya ? a pop-up dictionary Firefox add-on 
similar to the add-on described by Wasala and 
Weerasinghe (2008); 
2. FoxReplace ? a Firefox add-on that can au-
tomatically replace textual content with the aid 
of a predefined substitution list. 
 
Ingiya, a non-intrusive add-on, shows Sinhala 
definitions of English terms when the mouse 
pointer is hovered on top of English words in a 
web site. It is also capable of temporarily replacing 
Sinhala definitions with English words (i.e. as soon 
as the page is refreshed, the translations disappear). 
Currently, the Ingiya add-on only supports indi-
vidual words. The dictionary entries are stored 
within a local database.  
The add-on was first modified to support 
phrases (selected text segments) in addition to in-
dividual words and to be able to collect translations 
for a selected phrase from the user. We submitted 
the selected text segment, user?s translations and 
the URL of the active tab of the browser via Ingiya 
add-on to the central server as a RESTful call. We 
encoded the above data using the Punycode algo-
rithm prior to submission.  
We then implemented the central server using 
PHP. In this prototype, the server mainly performs 
three functions: 1) It accepts data sent via browser 
add-ons, decode the data and stores in it?s local 
database 2) Upon a request from a client, it trans-
forms and sends the data in its local database into a 
XML based format understood by FoxReplace ad-
don, 3) It can transform and sends data in it?s local 
database into an XML Localisation Interchange 
File Format (XLIFF) file that can be used as a TM. 
The FoxReplace add-on is capable of retrieving 
a regular expression-based source and target sub-
stitution list encoded in a specific XML format and 
replacing text in a web page. Different substitu-
tions can be defined for different URLs. The Fox-
Replace add-on was configured to retrieve 
translations (i.e. substitution list) from the central 
server.  When combined, these two add-ons along 
with the central server are able to implement and 
demonstrate the UpLoD architecture described in 
the pervious section. The exception is the voting 
mechanism which has not yet been implemented 
but is part of on-going work by the research group. 
4 Discussion: Outstanding Challenges 
While most of the issues and challenges empha-
sised in the UpLoD-based architecture (Exton et al, 
2009) are common to the architecture proposed in 
this article, web content localisation also faces ad-
ditional, unique technical challenges. 
Web pages consist of not only text, but also 
non-textual content such as images, audio clips, 
videos and various embedded objects (e.g. Java, 
Flash, PDF or Silverlight content) (Daniel Brandon 
2001; Stengers et al, 2004). Textual content repre-
sented in graphics such as banners is also very 
common in web sites. The current architecture 
however does not deal with localisation of non-
textual content found in websites. Even with the 
17
textual content, font and rendering problems may 
surface in the localised version.  
Another issue that can occur in a crowdsourced 
localisation model as noted by Exton et al (2009) 
is the primary focus on translation of the frequently 
used content by the crowd. This issue is likely to 
surface in the web content localisation scenario as 
well. It will result in untranslated content of infre-
quently visited sections of the web sites. 
Issues related to translation voting, especially 
the 'thrashing' scenarios as described by Exton et al 
(2009) need to be addressed in this scenario too. 
The optimum human translation rating mecha-
nisms, as well as motivations for rating these, have 
to be explored further. 
Another important factor is the design of a 
methodology for coping with constant updates of 
websites. We would expect that a large TM might 
help to alleviate the above problem to a certain 
degree.  
One of the advantages of the above methodolo-
gy is that, once the entire web page is completely 
translated, the translated page can be cached in the 
central server for improved performance. On the 
other hand, the localisation layer is only accessible 
via the browser extension. Therefore, users are not 
able to interact with the website using their native 
language, nor would these pages be indexed by 
search engines (i.e. the localised version).  
In addition to various technical issues discussed 
above, legal issues could potentially be encoun-
tered which need to be thoroughly examined, iden-
tified and addressed prior to the deployment of the 
proposed solution. The first question that needs to 
be answered is if people have a right to localise 
websites without the consent of the web site own-
ers. Moreover, the TMs (for each language pair) 
will keep on growing once the crowd starts using 
this framework. Legal implications around the 
TMs have to be thoroughly considered. For exam-
ple, questions such as who owns the TMs needs to 
be addressed.  
The accuracy of the translations is one of the 
crucial aspects that need to be considered. It is es-
sential to investigate necessary steps to prevent 
possible misuse. Misuse of the service can be alle-
viated to a certain extent by developing a log-on 
mechanism where users have to be authenticated 
by the central server to access the localisation ser-
vice. Furthermore, individuals who contribute 
translations as well as individuals who vote for 
translations can be tracked and rewarded. Thus, 
these individuals can be further motivated with the 
use of public announcements and ranking (or med-
al offering) systems as in games. 
Website localisation is not just the translation of 
text in a website. Various ethical, cultural and re-
gional issues have to be taken into account when 
localising a website. Therefore, a reviewing mech-
anism such as observed in the Wikipedia commu-
nity has to be built in to this model. 
5  Conclusions and Future Work 
In this paper, we have discussed the development 
of a browser extension-based website independent 
client-server architecture that facilitates the collab-
orative creation of TMs used for the localisation of 
web content. As this approach uses TMs construct-
ed with the aid of the crowd and reviewed by ex-
perts where necessary, rather than an MT system, 
better quality translations can be expected. The 
development of the prototype has proven the via-
bility of the proposed approach. Future research 
will focus mainly on addressing the issues related 
to central server services discussed above. Moreo-
ver, the development of a (single) Firefox add-on 
encompassing all the functionalities described in 
section 3 has already shown good results.  
To the best of our knowledge, this is the only 
practical web content localisation approach pro-
posed which is based on the collaborative con-
struction of TMs utilising the power of browser 
extensions combined with micro-crowdsourcing. 
The current architecture will be especially useful in 
the case of less-resourced languages where MT 
systems are not (yet) viable. The proposed system 
focuses on the building of language resources, such 
as translation memories but also parallel corpora, 
which could be used for the development of MT 
systems in the future. 
Acknowledgments 
This research is supported by the Science Founda-
tion Ireland (Grant 07/CE/I1142) as part of the 
Centre for Next Generation Localisation at the 
University of Limerick. The prototype was imple-
mented based on Ingiya and FoxReplace add-ons. 
The authors would like to thank the authors of and 
the contributors to the above add-ons. 
References 
18
Boxma, H. (2012). RIGI Localization Solutions  
Retrieved April 01, 2012, from 
https://sites.google.com/a/rigi-ls.com/www/home  
Daniel Brandon, J. (2001). Localization of web content. 
J. Comput. Small Coll., 17(2), 345-358.  
Exton, C., Wasala, A., Buckley, J., & Sch?ler, R. (2009). 
Micro Crowdsourcing: A new Model for Software 
Localisation. Localisation Focus, 8(1), 81-89.  
Gaspari, F. (2007). The Role of Online MT in Webpage 
Translation. Doctor of Philosophy, University of 
Manchester, Manchester, Retrieved June 28, 2011, 
from 
http://www.localisation.ie/resources/Awards/Theses/F_Gaspari_T
hesis.pdf   
Horvat, M. (2012). Live Website Localization. W3C 
Workshop: The Multilingual Web ? The Way Ahead, 
Luxembourg, Retrieved April 01,  2012, from 
http://mozeg.com/pontoon-mlw.html 
Jim?nez-Crespo, M. A. (2011). To adapt or not to adapt 
in web localization: a contrastive genre-based study 
of original and localised legal sections in corporate 
websites. JoSTrans (The Journal of Special 
Translation)(15).  
Large, A., & Moukdad, H. (2000). Multilingual access 
to web resources: an overview. Program: Electronic 
Library and Information Systems, 34(1), 43 - 58. doi: 
10.1108/EUM0000000006938 
Sch?ler, R. (2012a). Information Sharing Across 
Languages Computer-Mediated Communication 
across Cultures: International Interactions in Online 
Environments (pp. 215-234): IGI Global. 
Sch?ler, R. (2012b). Introducing Social Localisation. 
Workshop. Localization World, Silicon Valley,. 
Retrieved April 02, 2012 from 
http://www.slideshare.net/TheRosettaFound/social-localisation 
Selenium Project. (2012). Selenium-IDE - Locating 
Elements. Retreived May 14, 2012 from: 
http://seleniumhq.org/docs/02_selenium_ide.html#locating-
elements 
Stengers, H., Troyer, O. D., Baetens, M., Boers, F., & 
Mushtaha, A. N. (2004). Localization of Web Sites: 
Is there still a need for it? Paper presented at the 
International Workshop on Web Engineering (held in 
conjunction with the ACM HyperText 2004 
Conference), Santa Cruz, USA.  
Wasala, A., & Weerasinghe, R. (2008). EnSiTip: A Tool 
to Unlock the English Web. Paper presented at the 
11th International Conference on Humans and 
Computers, Nagaoka University of Technology, 
Japan.  
 
19
