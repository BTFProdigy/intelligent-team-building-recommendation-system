Evaluating Cross-Language Annotation Transfer in the MultiSemCor Corpus  
Luisa BENTIVOGLI, Pamela FORNER, Emanuele PIANTA 
ITC-irst 
Via Sommarive, 18 
38050 Povo ? Trento 
 Italy 
{bentivo, forner, pianta}@itc.it 
 
Abstract 
In this paper we illustrate and evaluate an approach 
to the creation of high quality linguistically 
annotated resources based on the exploitation of 
aligned parallel corpora. This approach is based on 
the assumption that if a text in one language has 
been annotated and its translation has not, 
annotations can be transferred from the source text 
to the target using word alignment as a bridge. The 
transfer approach has been tested in the creation of 
the MultiSemCor corpus, an English/Italian 
parallel corpus created on the basis of the English 
SemCor corpus. In MultiSemCor texts are aligned 
at the word level and semantically annotated with a 
shared inventory of senses. We present some 
experiments carried out to evaluate the different 
steps involved in the methodology. The results of 
the evaluation suggest that the cross-language 
annotation transfer methodology is a promising 
solution allowing for the exploitation of existing 
(mostly English) annotated resources to bootstrap 
the creation of annotated corpora in new (resource-
poor) languages with greatly reduced human effort.  
1 Introduction 
Large-scale language resources play a crucial role 
for a steady progress in the field of Natural 
Language Processing (NLP), as they are essential 
for carrying out basic research and for building 
portable and robust systems with broad coverage. 
More specifically, given the advances of machine 
learning statistical methods for NLP, with 
supervised training methods leading the way to 
major improvements in performance on different 
tasks, a particularly valuable resource is now 
represented by large linguistically annotated 
corpora. 
Up until some years ago, linguistically annotated 
corpora were only produced through manual 
annotation, or by manual check of automatically 
produced annotations. Unfortunately, manual 
annotation is a very difficult and time-consuming 
task, and this fact has led to a shortage of manual-
quality annotated data. The scarcity of large size 
annotated corpora is more acute for languages 
different from English, for which even minimal 
amounts of data are still missing. This state of 
affairs makes it clear that any endeavour aiming at 
reducing the human effort needed to produce 
manual-quality labelled data will be highly 
beneficial to the field. 
Recent studies have shown that a valuable 
opportunity for breaking the annotated resource 
bottleneck is represented by parallel corpora, 
which can be exploited in the creation of resources 
for new languages via projection of annotations 
available in another language. This paper 
represents our contribution to the research in this 
field. We present a novel methodology to create a 
semantically annotated corpus by exploiting 
information contained in an already annotated 
corpus, using word alignment as a bridge. The 
methodology has been applied in the creation of 
the MultiSemCor corpus. MultiSemCor is an 
English/Italian parallel corpus which is being 
created on the basis of the English SemCor corpus 
and where the texts are aligned at the word level 
and semantically annotated with a shared inventory 
of senses.  
Given the promising results of a pilot study 
presented in (Bentivogli and Pianta, 2002), the 
MultiSemCor corpus is now under development. In 
this paper we focus on a thorough evaluation of the 
steps involved in the transfer methodology. We 
evaluate the performance of a new version of the 
word alignment system and the final quality of the 
annotations transferred from English to Italian. In 
Section 2 we lay out the annotation transfer 
methodology and summarize some related work. In 
Section 3 we discuss some problematic issues 
related to the methodology which will be 
extensively tested and evaluated in Section 4. In 
Section 5 we report about the state of development 
of the MultiSemCor corpus and, finally, in Section 
6 we present conclusions and our thoughts on 
future work. 
2 The Annotation Transfer Methodology 
The MultiSemCor project (Bentivogli and Pianta, 
2002) aims at building an English/Italian parallel 
corpus, aligned at the word level and annotated 
with PoS, lemma and word sense. The parallel 
corpus is created by exploiting the SemCor corpus 
(Landes et al, 1998), which is a subset of the 
English Brown corpus containing about 700,000 
running words. In SemCor all the words are tagged 
by PoS, and more than 200,000 content words are 
also lemmatized and sense-tagged with reference 
to the WordNet lexical database1 (Fellbaum, 1998).  
The main hypothesis underlying this 
methodology is that, given a text and its translation 
into another language, the semantic information is 
mostly preserved during the translation process. 
Therefore, if the texts in one language have been 
semantically annotated and their translations have 
not, annotations can be transferred from the source 
language to the target using word alignment as a 
bridge.  
The first problem to be solved in the creation of 
MultiSemCor was the fact that the Italian 
translations of the SemCor texts did not exist. Our 
solution was to have the translations made by 
professional translators. Given the high costs of 
building semantically annotated corpora, requiring 
specific skills and very specialized training, we 
think that manually translating the annotated 
corpus and automatically transferring the 
annotations may be preferable to hand-labelling a 
corpus from scratch. Not only are translators more 
easily available than linguistic annotators, but 
translations may be a more flexible and durable 
kind of annotation. Moreover, the annotation 
transfer methodology has the further advantage of 
producing a parallel corpus.  
With respect to a situation in which the 
translation of a corpus is already available, a 
corpus translated on purpose presents the 
advantage that translations can be ?controlled?, 
i.e. carried out following criteria aiming at 
maximizing alignment and annotation transfer. Our 
professional translators are asked to use, 
preferably, the same dictionaries used by the word 
aligner, and to maximize, whenever possible, the 
lexical correspondences between source and target 
texts. The translators are also told that the 
controlled translation criteria should never be 
followed to the detriment of a good Italian prose. 
Controlled translations cost the same as free 
translations, while having the advantage of 
                                                     
1
 WordNet is an English lexical database, developed 
at Princeton University, in which nouns, verbs, 
adjectives, and adverbs are organized into sets of 
synonyms (synsets) and linked to each other by means 
of various lexical and semantic relationships. In the last 
years, within the NLP community WordNet has become 
the reference lexicon for almost all tasks involving word 
sense disambiguation (see, for instance, the Senseval 
competition). 
 
enhancing the performances of the annotation 
transfer procedure. 
Once the SemCor texts have been translated, the 
strategy for creating MultiSemCor consists of (i) 
automatically aligning Italian and English texts at 
the word level, and (ii) automatically transferring 
the word sense annotations from English to the 
aligned Italian words. The final result of the 
MultiSemCor project is an Italian corpus annotated 
with PoS, lemma and word sense, but also an 
aligned parallel corpus lexically annotated with a 
shared inventory of word senses. More 
specifically, the sense inventory used is 
MultiWordNet (Pianta et al, 2002), a multilingual 
lexical database in which the Italian component is 
strictly aligned with the English WordNet. 
2.1 Related Work 
The idea of obtaining linguistic information about 
a text in one language by exploiting parallel or 
comparable texts in another language has been 
explored in the field of Word Sense 
Disambiguation (WSD) since the early 90?s, the 
most representative works being (Brown et al, 
1991), (Gale et al, 1992), and (Dagan and Itai, 
1994).  
In more recent years, Ide et al (2002) present a 
method to identify word meanings starting from a 
multilingual corpus. A by-product of applying this 
method is that once a word in one language is 
word-sense tagged, the translation equivalents in 
the parallel texts are also automatically annotated. 
Cross-language tagging is the goal of the work 
by Diab and Resnik (2002), who present a method 
for word sense tagging both the source and target 
texts of parallel bilingual corpora with the 
WordNet sense inventory.  
Parallel to the studies regarding the projection of 
semantic information, more recently the NLP 
community has also explored the possibility of 
exploiting translation to project more syntax-
oriented annotations. Yarowsky et al (2001) 
describe a successful method consisting of (i) 
automatic annotation of English texts, (ii) cross-
language projection of annotations onto target 
language texts, and (iii) induction of noise-robust 
taggers for the target language. A further step is 
made in (Hwa et al, 2002) and (Cabezas et al, 
2001), which address the task of acquiring a 
dependency treebank by bootstrapping from 
existing linguistic resources for English. Finally, in 
(Riloff et al, 2002) a method is presented for 
rapidly creating Information Extraction (IE) 
systems for new languages by exploiting existing 
IE systems via cross-language projection. 
The results of all the above mentioned studies 
show how previous major investments in English 
annotated corpora and tool development can be 
effectively leveraged across languages, allowing 
the development of accurate resources and tools in 
other languages without comparable human effort. 
3 Quality Issues 
The MultiSemCor project raises a number of 
theoretical and practical issues. For instance: is 
translational language fully representative of the 
general use of language in the same way as 
original language is? To what extent are the lexica 
of different languages comparable? These 
theoretical issues have already been presented in 
(Pianta and Bentivogli, 2003) and will not be 
discussed here. In the following, we address the 
issue of the quality of the annotation resulting from 
the application of the methodology.  
As opposed to automatic word sense 
disambiguation tasks, the MultiSemCor project 
specifically aims at producing manual-quality 
annotated data. Therefore, a potential risk which 
needs to be faced is represented by the possible 
degradation of the Italian annotation quality 
through the various steps of the annotation transfer 
procedure. A number of factors must be taken into 
account. First, annotation errors can be found in 
the original English texts. Then, the word aligner 
may align words incorrectly, and finally the 
transfer of the semantic annotations may not be 
applicable to certain translation pairs.  
SemCor quality. The English SemCor corpus has 
been manually annotated. However, some 
annotation errors can be found in the texts (see 
Fellbaum et al, 1998, for SemCor taggers? 
confidence ratings). As an example, the word 
pocket in the sentence ?He put his hands on his 
pockets? was incorrectly tagged with the WordNet 
synset {pouch, sac, sack, pocket -- an enclosed 
space} instead of the correct one {pocket -- a small 
pouch in a garment for carrying small articles}. 
Word alignment quality. The feasibility of the 
entire MultiSemCor project heavily depends on the 
availability of an English/Italian word aligner with 
very good performance in terms of recall and, 
more importantly, precision.  
Transfer quality. Even when both the original 
English annotations and the word alignment are 
correct, a number of cases still remain for which 
the transfer of the annotation is not applicable. An 
annotation is not transferable from the source 
language to the target when the translation 
equivalent does not preserve the lexical meaning of 
the source language. In these cases, if the 
alignment process puts the two expressions in 
correspondence, then the transfer of the sense 
annotation from the source to the target language is 
not correct.  
The first main cause of incorrect transfer is 
represented by translation equivalents which are 
not cross-language synonyms of the source 
language words. For example, in a sentence of the 
corpus the English word meaning is translated with 
the Italian word motivo (reason, grounds) which is 
suitable in that specific context but is not a 
synonymic translation of the English word. In this 
case, if the two words are aligned, the transfer of 
the sense annotation from English is not correct as 
the English sense annotation is not suitable for the 
Italian word. A specific case of non-synonymous 
translation occurs when a translation equivalent 
does not belong to the same lexical category of the 
source word. For example, the English verb to 
coexist in the sentence ?the possibility for man to 
coexist with animals? has been translated with the 
Italian noun coesistenza (coexistence) in ?le 
possibilit? di coesistenza tra gli uomini e gli 
animali?. Even if the translation is suitable for that 
context, the English sense of the verb cannot be 
transferred to the Italian noun. Sometimes, non-
synonymous translations are due to errors in the 
Italian translation, as in pull translated as spingere 
(push).  
A second case which offers challenge to the 
sense annotation transfer is phrasal 
correspondence, occurring when a target phrase 
has globally the same meaning as the 
corresponding source phrase, but the single words 
of the phrase are not cross-language synonyms of 
their corresponding source words. For example, the 
expression a dreamer sees has been translated as 
una persona sogna (a person dreams). The Italian 
translation maintains the synonymy at the phrase 
level but the single component words do not. 
Therefore, if the single words were aligned any 
transfer from English to Italian would be incorrect. 
Another example of phrasal correspondence, in 
which the semantic equivalence between words in 
the source and target phrase is even fuzzier, is 
given by the English phrase the days would get 
shorter and shorter translated as imminente fine 
dei tempi (imminent end of times). 
Another controversial cause of possible incorrect 
transfer is represented by the case in which the 
translation equivalent is indeed a cross-language 
synonym of the source expression but it is not a 
lexical unit. This usually happens with lexical 
gaps, i.e. when a language expresses a concept 
with a lexical unit whereas the other language 
expresses the same concept with a free 
combination of words, as for instance the English 
word successfully which can only be translated 
with the Italian free combination of words con 
successo (with success). However, it can also be 
the result of a choice made by the translator who 
decides to use a free combination of words instead 
of a possible lexical unit, as in empirically 
translated as in modo empirico (in an empirical 
manner) instead of empiricamente. In these cases 
the problem arises because in principle if the target 
expression is not a lexical unit it cannot be 
annotated as a whole. On the contrary, each 
component of the free combination of words 
should be annotated with its respective sense. 
In the next Section we will address these quality 
issues in order to assess the extent to which they 
affect the cross-language annotation transfer 
methodology. 
4 Evaluation of the Annotation Transfer 
Methodology 
A number of experiments have been carried out in 
order to test the various steps involved in the 
annotation transfer methodology. More precisely, 
we evaluated the performances of the word 
alignment system and the quality of the final 
annotation of the Italian corpus. 
4.1 Word Alignment 
Word alignment is the first crucial step in the 
methodology applied to build MultiSemCor. The 
word aligner used in the project is KNOWA 
(KNOwledge-intensive Word Aligner), an 
English/Italian word aligner, developed at ITC-irst, 
which relies mostly on information contained in 
the Collins bilingual dictionary, available in 
electronic format. KNOWA also exploits a 
morphological analyzer and a multiword 
recognizer for both English and Italian. For a 
detailed discussion of the characteristics of this 
tool, see (Pianta and Bentivogli, 2004). 
Some characteristics of the MultiSemCor 
scenario make the alignment task easier for 
KNOWA. First, in SemCor all multiwords 
included in WordNet are explicitly marked. Thus 
KNOWA does not need to recognize English 
multiwords, although it still needs to recognize the 
Italian ones. Second, within MultiSemCor word 
alignment is done with the final aim of transferring 
lexical annotations from English to Italian. Since 
only content words have word sense annotations in 
SemCor, it is more important that KNOWA 
behaves correctly on content words, which are 
easier to align than functional words. 
To evaluate the word aligner performance on the 
MultiSemCor task we created a gold standard 
composed of three English unseen texts (br-f43, 
br-l10, br-j53) taken randomly from the 
SemCor corpus. For each English text both a 
controlled and a free translation were made. Given 
the expectation that free translations are less 
suitable for word alignment, we decided to test 
KNOWA also on them in order to verify if the 
annotation transfer methodology can be applied to 
already existing parallel corpora. 
The six resulting pairs of texts were manually 
aligned following a set of alignment guidelines 
which have been defined taking into account the 
work done in similar word alignment projects 
(Melamed, 2001). Annotators were asked to align 
different kinds of units (simple words, segments of 
more than one word, parts of words) and to mark 
different kinds of semantic correspondence 
between the aligned units, e.g. full correspondence 
(synonymic), non synonymic, changes in lexical 
category, phrasal correspondence. Inter-annotator 
agreement was measured with the Dice coefficient 
proposed in (V?ronis and Langlais, 2000) and can 
be considered satisfactory as it turned out to be 
87% for free translations and 92% for controlled 
translations. As expected, controlled translations 
produced a better agreement rate between 
annotators. 
For assessing the performance of KNOWA, the 
standard notions of Precision, Recall, and 
Coverage have been used following (V?ronis and 
Langlais, 2000). See (Och and Ney, 2003) and 
Arenberg et al, 2000) for different evaluation 
metrics. The performance of KNOWA applied to 
the MultiSemCor gold standard in a full-text 
alignment task is shown in Table 1. These results, 
which compare well with those reported in the 
literature (V?ronis, 2000) show that, as expected, 
controlled translations allow for a better alignment 
but also that free translations may be satisfactorily 
aligned.  
The evaluation of KNOWA with respect to the 
English content words which have a semantic tag 
in SemCor is reported in Tables 2 and 3, for both 
free and controlled translations and broken down 
by Part of Speech.  
 Precision Recall Coverage 
Free 83.5 57.9 60.0 
Controlled 88.4 67.5  74.9 
Table 1: KNOWA on Full-text  
 Precision Recall Coverage 
Nouns 93.7 81.1 86.5 
Verbs 85.6 70.3 82.1 
Adjectives 95.6 64.7 67.7 
Adverbs 88.4 38.5 43.5 
Total 91.2 68.2 74.8 
Table 2: KNOWA on sense-tagged words only 
(Free translations)  
 Precision Recall Coverage 
Nouns 95.9 82.5 86.1 
Verbs 90.7 76.8 84.7 
Adjectives 95.2 69.9 73.5 
Adverbs 90.4 51.6 57.1 
Total 93.9 74.6 79.5 
Table 3: KNOWA on sense-tagged words only 
(Controlled translations) 
We can see that ignoring function words the 
performance of the word aligner improves in both 
precision and recall. 
4.2 Italian Annotation Quality 
As pointed out in Section 3, even in the case of a 
perfect word alignment the transfer of the 
annotations from English to the correctly aligned 
Italian words can still be a source of errors in the 
resulting Italian annotations. In order to evaluate 
the quality of the annotations automatically 
transferred to Italian, a new gold standard was 
created starting from SemCor text br-g11. The 
English text, containing 2,153 tokens and 1,054 
semantic annotations, was translated into Italian in 
a controlled modality. The resulting Italian text is 
composed of 2,351 tokens, among which 1,085 are 
content words to be annotated. The English text 
and its Italian translation were manually aligned 
and the Italian text was manually semantically 
annotated taking into account the annotations of 
the English words. Each time an English 
annotation was appropriate for the Italian 
corresponding word, the annotator used it also for 
Italian. Otherwise, the annotator did not use the 
original English annotation for the Italian word and 
looked in WordNet for a suitable annotation. 
Moreover, when the English annotations were 
not suitable for annotating the Italian words, the 
annotator explicitly distinguished between wrong 
English annotations and English annotations that 
could not be transferred to the Italian translation 
equivalents. The errors in the English annotations 
amount to 24 cases. Non-transferable annotations 
amount to 155, among which 143 are due to lack 
of synonymy at lexical level and 12 to translation 
equivalents which are not lexical units. 
The differences between the English and Italian 
text with respect to the number of tokens and 
annotations have also been analysed. The Italian 
text has about 200 tokens and 31 annotated words 
more than the English text. The difference in the 
number of tokens is due to various factors. First, 
there are grammatical characteristics specific to the 
Italian language, such as a different usage of 
articles, or a greater usage of reflexive verbs which 
leads to a higher number of clitics. For example, 
the English sentence ?as cells coalesced? must be 
translated into Italian as ?quando le cellule si 
unirono?. Then, we have single English words 
translated into Italian with free combinations of  
words (ex: down translated as verso il basso) and 
multiwords which are recognized in English and 
not recognized in Italian (e.g. one token for 
nucleic_acid in the English text and two tokens in 
the Italian text, one for acido and one for 
nucleico). As regards content words to be 
annotated, we would have expected that their 
number was the same both in English and Italian. 
In fact, the difference we found is much lower than 
the difference between tokens. This difference is 
explained by the fact that some English content 
words have not been annotated. For example, 
modal and auxiliary verbs (to have, to be, can, 
may, to have to, etc.) and partitives (some, any) 
where systematically left unannotated in the 
English text whereas they have been annotated for 
Italian. 
The automatic procedures for word alignment 
and annotation transfer were run on text br-g11 
and evaluated against the gold standard. The total 
number of transferred senses amounts to 879. 
Among them, 756 are correct and 123 are incorrect 
for the Italian words. Table 4 summarizes the 
results in terms of precision, recall and coverage 
with respect to both English annotations available 
(1,054) and Italian words to be annotated (1,085).  
We can see that the final quality of the Italian 
annotations is acceptable, the precision amounting 
to 86.0%. The annotation error rate of 14.0% has 
been analyzed in order to classify the different 
factors affecting the transfer methodology. Table 5 
reports the data about the composition of the 
incorrect transfer. 
Comparing the number of annotation errors in 
the English source, as marked up during the 
creation of the gold standard (24), with the number 
of errors in the Italian annotation due to errors in 
the original annotation (22), we can see that almost 
all of the source errors have been transferred, 
contributing in a consistent way to the overall 
Italian annotation error rate. 
As regards word alignment, br-g11 was a 
relatively easy text as the performance of KNOWA 
(i.e. 96.5%) is higher than that obtained with the 
test set (see Table 3). 
 Precision Recall Coverage 
Wrt English 86.0 71.7 83.4 
Wrt Italian 86.0 69.7 81.0 
Table 4: Annotation evaluation on text br-g11 
 # % 
English annotation errors 22 2.5 
Word alignment errors 31 3.5 
Non-transferable annotations 70 8.0 
Total incorrect transfers 123 14.0 
Table 5: Composition of the incorrect transfer  
The last source of annotation errors is 
represented by words which have been correctly 
aligned but whose word sense annotation cannot be 
transferred. This happens with (i) translation 
equivalents which are lexical units but are not 
cross-language synonyms, and (ii) translation 
equivalents which are cross-language synonyms 
but are not lexical units. In practice, given the 
difficulty in deciding what is a lexical unit and 
what is not, we decided to accept the transfer of a 
word sense from an English lexical unit to an 
Italian free combination of words (see for instance 
occhiali da sole annotated with the sense of 
sunglasses). Therefore, only the lack of synonymy 
at lexical level has been considered an annotation 
error. 
The obtained results are encouraging. Among 
the 143 non-synonymous translations marked in 
the gold standard, only 70 have been aligned by the 
word alignment system, showing that KNOWA is 
well suited to the MultiSemCor task. The reason is 
that it relies on bilingual dictionaries where non-
synonymous translations are quite rare. This can be 
an advantage with respect to statistics-based word 
aligners, which are expected to be able to align a 
great number of non-synonymous translations, thus 
introducing more errors in the transfer procedure.  
A final remark about the evaluation concerns the 
proportion of non-transferable word senses with 
respect to errors in the original English 
annotations. It is sometimes very difficult to 
distinguish between annotation errors and non-
transferable word senses, also because we are not 
English native speakers. Thus, we preferred to be 
conservative in marking English annotations as 
errors unless in very clear cases. This approach 
may have reduced the number of the errors in the 
original English corpus and augmented the number 
of non-transferable word senses, thus penalizing 
the transfer procedure itself. 
Summing up, the cross-language annotation 
transfer methodology produces an Italian corpus 
which is tagged with a final precision of 86.0%. 
After the application of the methodology 19.0% of 
the Italian words still need to be annotated (see the 
annotation coverage of 81.0%). We think that, 
given the precision and coverage rates obtained 
from the evaluation, the corpus as it results from 
the automatic procedure can be profitably used. 
However, even in the case that a manual revision is 
envisaged, we think that hand-checking the 
automatically tagged corpus and manually 
annotating the remaining 19% still results to be 
cost effective with respect to annotating the corpus 
from scratch. 
5 The MultiSemCor Corpus Up to Now 
We are currently working at the extensive 
application of the annotation transfer methodology 
for the creation of the MultiSemCor corpus. Up to 
now, MultiSemCor is composed of 29 English 
texts aligned at the word level with their 
corresponding Italian translations. Both source and 
target texts are annotated with POS, lemma, and 
word sense. More specifically, as regards English 
we have 55,935 running words among which 
29,655 words are semantically annotated (from 
SemCor). As for Italian, the corpus amounts to 
59,726 running words among which 23,095 words 
are annotated with word senses that have been 
automatically transferred from English. 
MultiSemCor can be a useful resource for a 
variety of tasks, both as a monolingual 
semantically annotated corpus and as a parallel 
aligned corpus. As an example, we are already 
using it to automatically enrich the Italian 
component of MultiWordNet, the reference lexicon 
of MultiSemCor. As a matter of fact, out of the 
23,095 Italian words automatically sense-tagged, 
5,292 are not yet present in MultiWordNet and will 
be added to it. Moreover, the Italian component of 
MultiSemCor is being used as a gold standard for 
the evaluation of Word Sense Disambiguation 
systems working on Italian. Besides NLP 
applications, MultiSemCor is also suitable to be 
consulted by humans through a Web interface 
(Ranieri et al, 2004) which is available at: 
http://tcc.itc.it/projects/multisemcor.  
6 Conclusion and future directions 
We have presented and evaluated an approach to 
the creation of high quality semantically annotated 
resources based on the exploitation of aligned 
parallel corpora. The results obtained from the 
thorough evaluation of the different steps involved 
in the methodology confirm the feasibility of the 
MultiSemCor project. The cross-lingual annotation 
transfer methodology is going to be applied also to 
the remaining 157 SemCor texts, which are 
currently being translated into Italian. 
As regards future research directions within the 
transfer annotation paradigm, it would be 
interesting to extend the methodology to other 
languages, e.g. Spanish, for which a WordNet 
exists and can be aligned with MultiWordNet. 
Moreover, as the Brown Corpus, used to create 
SemCor, has been syntactically annotated within 
the English Penn Treebank, the syntactic 
annotations of the SemCor texts are also available. 
We are planning to explore the possibility of 
transferring the syntactic annotations from the 
English to the Italian texts of MultiSemCor. 
References  
L. Ahrenberg, M. Merkel, H. Sagvall and A. J. 
Tiedemann. 2000. Evaluation of word alignment 
systems. In Proceedings of LREC 2000, Athens, 
Greece. 
L. Bentivogli and E. Pianta. 2002. Opportunistic 
Semantic Tagging. In Proceedings of LREC-
2002, Las Palmas, Canary Islands, Spain. 
P. F. Brown, S. A. Della Pietra, V. J. Della Pietra, 
and R. L. Mercer. 1991. Word-Sense 
Disambiguation using Statistical Methods. In 
Proceedings of ACL?91, Berkeley, California, 
USA. 
C. Cabezas, B. Dorr and P. Resnik. 2001. Spanish 
Language Processing at University of Maryland: 
Building Infrastructure for Multilingual 
Applications. In Proceedings of the 2nd  
International Workshop on Spanish Language 
Processing and Language Technologies, Jaen, 
Spain. 
I. Dagan and A. Itai. 1994. Word Sense 
Disambiguation Using a Second Language 
Monolingual Corpus. Computational Linguistics: 
20(4):563-596. 
M. Diab and P. Resnik. 2002. An unsupervised 
method for word sense tagging using parallel 
corpora. In In Proceedings of ACL 2002, 
Philadelphia, USA . 
C. Fellbaum, J. Grabowski and S. Landes. 1998. 
Performance and confidence in a semantic 
annotation task. In Fellbaum, C. (ed.). 1998. 
WordNet: An Electronic Lexical Database. The 
MIT Press, Cambridge (Mass.). 
C. Fellbaum (ed.). 1998. WordNet: An Electronic 
Lexical Database. The MIT Press, Cambridge 
(Mass.). 
W. A. Gale, K. W. Church and D. Yarowsky. 
1992. Using Bilingual Materials to Develop 
Word Sense Disambiguation Methods. In 
Proceedings of the Fourth International 
Conference on Theoretical and Methodological 
Issues in Machine Translation. Montreal, 
Canada. 
R. Hwa, P. Resnik and A. Weinberg. 2002. 
Breaking the Resource Bottleneck for 
Multilingual Parsing. In Proceedings of the 
LREC-2002 Workshop on "Linguistic Knowledge 
Acquisition and Representation: Bootstrapping 
Annotated Language Data'', Las Palmas, Canary 
Islands, Spain. 
N. Ide, T. Erjavec, and D. Tufis. 2002. Sense 
Discrimination with Parallel Corpora. In 
Proceedings of ACL'02 Workshop on Word 
Sense Disambiguation: Recent Successes and 
Future Directions, Philadelphia, USA.  
S. Landes C. Leacock, and R.I. Tengi. 1998. 
Building semantic concordances. In Fellbaum, C. 
(ed.) (1998) WordNet: An Electronic Lexical 
Database. The MIT Press, Cambridge (Mass.). 
I. D. Melamed. 2001. Empirical Methods for 
Exploiting Parallel Texts. The MIT Press, 
Cambridge (Mass.).  
F.J. Och and H. Ney. 2003. A systematic 
comparison of various statistical alignment 
models. Computational Linguistics, 29(1):19-53. 
E. Pianta and L. Bentivogli. 2004. Knowledge 
intensive word alignment with KNOWA. In 
Proceedings of Coling 2004, Geneva, 
Switzerland. 
E. Pianta and L. Bentivogli. 2003. Translation as 
Annotation. In Proceedings of the AI*IA 2003 
Workshop ?Topics and Perspectives of Natural 
Language Processing in Italy?, Pisa, Italy. 
E. Pianta, L. Bentivogli and C. Girardi. 2002. 
MultiWordNet: developing an aligned 
multilingual database. In Proceedings of the 
First Global WordNet Conference, Mysore, 
India.  
M. Ranieri, E. Pianta and L. Bentivogli. 2004. 
Browsing Multilingual Information with the 
MultiSemCor Web Interface. In Proceedings of 
the LREC-2004 Workshop ?The amazing utility 
of parallel and comparable corpora?, Lisbon, 
Portugal. 
E. Riloff, C. Schafer and D. Yarowsky. 2002. 
Inducing information extraction systems for new 
languages via cross-language projection. In 
Proceedings of Coling 2002, Taipei, Taiwan. 
J. V?ronis and  P. Langlais. 2000. Evaluation of 
parallel text alignment systems. In V?ronis, J. 
(ed.). 2000. Parallel Text Processing, Kluwer 
Academic Publishers, Dordrecht. 
J. V?ronis (ed.). 2000. Parallel Text Processing. 
Kluwer Academic Publishers, Dordrecht. 
D. Yarowsky, G. Ngai and R. Wicentowski. 2001. 
Inducing Multilingual Text Analysis Tools via 
Robust Projection across Aligned Corpora. In 
Proceedings of HLT 2001, San Diego, 
California, USA.  
Revising the WORDNET DOMAINS Hierarchy: semantics, coverage and 
balancing 
Luisa Bentivogli, Pamela Forner, Bernardo Magnini, Emanuele Pianta 
ITC-irst ? Istituto per la Ricerca Scientifica e Tecnologica 
Via Sommarive 18, Povo ? Trento, Italy, 38050 
email:{bentivo, forner, magnini, pianta}@itc.it 
 
Abstract 
The continuous expansion of the multilingual 
information society has led in recent years to a pressing 
demand for multilingual linguistic resources suitable to 
be used for different applications.  
In this paper we present the WordNet Domains 
Hierarchy (WDH), a language-independent resource 
composed of 164, hierarchically organized, domain 
labels (e.g. Architecture, Sport, Medicine). Although 
WDH has been successfully applied to various Natural 
Language Processing tasks, the first available version 
presented some problems, mostly related to the lack of a 
clear semantics of the domain labels. Other correlated 
issues were the coverage and the balancing of the 
domains. We illustrate a new version of WDH 
addressing these problems by an explicit and systematic 
reference to the Dewey Decimal Classification. The new 
version of WDH has a better defined semantics and is 
applicable to a wider range of tasks. 
1 Introduction 
The continuous expansion of the multilingual 
information society with a growing number of new 
languages present on the Web has led in recent 
years to a pressing demand for multilingual 
applications. To support such applications, 
multilingual language resources are needed, which 
however require a lot of human effort to be built. 
For this reason, the development of language-
independent resources which factorize what is 
common to many languages, and are possibly 
linked to the language-specific resources, could 
bring great advantages to the development of the 
multilingual information society. 
A language-independent resource, usable in 
many automatic and human applications, is 
represented by domain hierarchies. The notion of 
domain is related to similar notions such as 
semantic field, subject matter, broad topic, subject 
code, subject domain, category. These notions are 
used, sometimes interchangeably, sometimes with 
significant distinctions, in various fields such as 
linguistics, lexicography, cataloguing, text 
categorization. As far as this work is concerned, 
we define a domain as an area of knowledge which 
is somehow recognized as unitary. A domain can 
be characterized by the name of a discipline where 
a certain knowledge area is developed (e.g. 
chemistry) or by the specific object of the 
knowledge area (e.g. food). Although objects of 
knowledge and disciplines that study them are 
clearly related, the relation between these two 
points of view on domains is sometimes blurred 
and may be a source of uncertainty on their exact 
definition. 
Another interesting duality when speaking about 
domains is related to the fact that knowledge 
manifests itself in both words and texts. So the 
notion of domain can be applied both to the study 
of words, where a domain is the area of knowledge 
to which a certain lexical concept belongs, or to the 
study of texts, where the domain of a text is its 
broad topic. In this work we will assume that also 
these two points of view on domains are strictly 
intertwined.  
By their nature, domains can be organized in 
hierarchies based on a relation of specificity. For 
instance we can say that TENNIS is a more specific 
domain than SPORT, or that ARCHITECTURE is more 
general than TOWN PLANNING. 
Domain hierarchies can be usefully integrated 
into other linguistic resources and are also 
profitably used in many Natural Language 
Processing (NLP) tasks such as Word Sense 
Disambiguation (Magnini et al 2002), Text 
Categorization (Schutze, 1998), Information 
Retrieval (Walker and Amsler, 1986).  
As regards the usage of Domain hierarchies in 
the field of multilingual lexicography, an example 
is given by the EuroWordNet Domain-ontology, a 
language independent domain hierarchy to which 
interlingual concepts (ILI-records) can be assigned 
(Vossen, 1998). In the same line, see also the 
SIMPLE domain hierarchy (SIMPLE, 2000).  
Large domain hierarchies are also available on 
the Internet, mainly meant for classifying web 
documents. See for instance the Google and Yahoo 
directories. 
A large-scale application of a domain hierarchy 
to a lexicon is represented by WORDNET DOMAINS 
(Magnini and Cavagli?, 2000). WORDNET 
DOMAINS is a lexical resource developed at ITC-
irst where each WordNet synset (Fellbaum, 1998) 
is annotated with one or more domain labels 
selected from a domain hierarchy which was 
specifically created to this purpose. As the 
WORDNET DOMAINS Hierarchy (WDH) is 
language-independent, it has been possible to 
exploit it in the framework of MultiWordNet 
(Pianta et al, 2002), a multilingual lexical database 
developed at ITC-irst in which the Italian 
component is strictly aligned with the English 
WordNet. In MultiWordNet, the domain 
information has been automatically transferred 
from English to Italian, resulting in a Italian 
version of WORDNET DOMAINS. For instance, as 
the English synset {court, tribunal, judicature} was 
annotated with the domain LAW, also the Italian 
synset {corte, tribunale}, which is aligned with the 
corresponding English synset, results automatically 
annotated with the LAW domain. This procedure 
can be applied to any other WordNet (or part of it) 
aligned with Princeton WordNet (see for instance 
the Spanish WordNet). 
It is worth noticing that two of the main on-
going projects addressing the construction of 
multilingual resources, that is MEANING (Rigau 
et al 2002) and BALKANET (see web site), make 
use of WORDNET DOMAINS. Finally, WORDNET 
DOMAINS is being profitably used by the NLP 
community mainly for Word Sense 
Disambiguation tasks in various languages. 
Another application of domain hierarchies can 
be found in the field of corpus creation. In many 
existing corpora (see for instance the BNC, the 
ANC, the Brown and LOB Corpora) domain is one 
of the most used criteria for text selection and/or 
classification. Given that a domain hierarchy is 
language independent, if the same domain 
hierarchy is used to build reference corpora for 
different languages, then it would be easy to create 
(a first approximation of) comparable corpora by 
putting in correspondence corpora sections 
belonging to the same domain. 
An example of a corpus in which the complete 
representation of domains is pursued in a 
systematic way is represented by the MEANING 
Italian corpus, a large size corpus of written 
contemporary Italian in which a subset of the 
WDH labels has been chosen as the fundamental 
criterion for the selection of the texts to be 
included in the corpus (Bentivogli et al, 2003). 
Given the relevance of language-independent 
domain hierarchies for multilingual applications, it 
is of primary importance that these resources have 
a well-defined semantics and structure in order to 
be useful in various application fields. This paper 
reports the work done to improve the WDH so that 
it complies with such requirements. In particular, 
the WDH revision has been carried out with 
reference to the Dewey Decimal Classification. 
The paper is organized as follows. Section 2 
briefly introduces the WORDNET DOMAINS 
Hierarchy and its main characteristics, with a short 
overview of the Dewey Decimal Classification 
system. Section 3 describes features and properties 
of the revision. Finally, in section 4, conclusions 
are reported. 
2 The WordNet Domains Hierarchy 
The first version of the WDH was composed of 
164 domain labels selected starting from the 
subject field codes used in current dictionaries, and 
the subject codes contained in the Dewey Decimal 
Classification (DDC), a general knowledge 
organization tool which is the most widely used 
taxonomy for library organization purposes. 
Domain labels were organized in five main trees, 
reaching a maximum depth of four. Figure 1 shows 
a fragment of one of the five main trees in the 
WORDNET DOMAINS original hierarchy. 
Doctrines
Psychology
Art
Religion
Psychoanalysis
Dance
Drawing
Music
Photography
Plastic Arts
Sculpture
Numismatics
Jewellery
Painting
Philately
Philosophy
Theatre
Mythology
Occultism
Roman Catholic
Theology
Figure 1: Fragment of the original WDH 
Domain labels were initially conceived to be 
application-oriented, that is, they have been 
integrated in WordNet with the main purpose of 
allowing the categorization of word senses and to 
provide useful information during the 
disambiguation process. 
The second level of WDH, where the so-called 
Basic Domains are represented, includes labels 
such as ART, SPORT, RELIGION and HISTORY, 
while in the third level a degree of major 
specialization is reproduced, and domains, like for 
example, DRAWING, PAINTING, TENNIS, 
VOLLEYBALL, and ARCHAEOLOGY can be found. For 
NLP tasks, the set of Basic Domains has proved to 
possess a suitable level of abstraction and 
granularity. 
Although the first version of WDH found many 
applications in different scenarios, it presented 
some problems. First, the domain labels did not 
have a defined semantics. The content of the labels 
could be suggested by the lexical meaning of their 
name, but there was no explicit indication about 
their intended interpretation. 
Second, it was not clear whether the Basic 
Domains met certain requirements such as 
knowledge coverage and balancing. In fact, the 
Basic Domains are supposed to possess a 
comparable degree of granularity and, at the same 
time, to cover all human knowledge. However, 
they did not always posses such characteristics. For 
instance VETERINARY was put at the same level as 
ECONOMY, although these two domains obviously 
do not posses the same level of granularity. 
Moreover not all branches of human knowledge 
were represented (see for instance the HOME 
domain). 
The purpose of the work presented here was, 
therefore, to find a solution for such problems, in 
order to improve the applicability of WDH in a 
wider range of fields. The solution we propose is 
crucially based on the Dewey Decimal 
Classification (edition 21), which has been used as 
a reference point for defining a clear semantics, 
preventing overlapping among domains, and 
assessing the Basic Domains coverage and 
granularity issues.  
2.1 The Dewey Decimal Classification (DDC)  
The Dewey Decimal Classification (DDC) system 
(Mitchell et al 1996) is the most widely used 
taxonomy for library classification purposes 
providing a logical system for the organization of 
every item of knowledge through well-defined 
subject codes hierarchically organized. The 
semantics of each subject code is determined by a 
numeric code, a short lexical description associated 
to it, and by the hierarchical relations with the 
other subject codes. Another characteristic of the 
DDC is that a handbook is available explaining 
how texts should be classified under subject codes. 
The DDC is not just for organizing book 
collections; it has also been licensed for 
cataloguing internet resources (see for example 
BUBL http://bubl.ac.uk/link/) and it was conceived 
to accommodate the expansion and evolution of 
the body of human knowledge.  
The DDC hierarchy is arranged by disciplines 
(or fields of study), and this entails that a subject 
may appear in more than one discipline, depending 
on the aspect of the topic discussed.  
The DDC hierarchical structure allows a topic to 
be defined as part of the broader topic above it, and 
that determines the meaning of the class and its 
relation to other classes. At the broadest level, 
called Main Classes (or First summary), the DDC 
is composed of ten mutually exclusive main 
classes, which together cover the entire world of 
knowledge. Each main class is sub-divided into ten 
divisions, (the Hundred Divisions, or Second 
Summary) and each division is split into ten 
sections (the Thousand Section, also called Third 
Summary). 
Each category in the DDC is represented by a 
numeric code as the example below shows.  
 
700  Art 
 730  Plastic Arts 
  736 Carving 
   736.2 Precious Stones 
    736.23 Diamonds 
    736.25 Sapphires 
   736.4 Wood 
  738 Ceramic Arts 
  739 Art Metalwork 
 740  Drawing 
 750  Painting 
 
The first digit of the numbers indicates the main 
class, (700 is used for all Arts) the second digit 
indicates the hundred division, (730 corresponds to 
Plastic arts, 740 to Drawing, 750 to Painting) and 
the third digit indicates the section (736 represents 
Carving, 738 Ceramic arts, 739 Art metalwork). 
Moreover, almost all sub-classes are further 
subdivided. A decimal point follows the third digit 
until the degree of specification needed (736.23 
Diamonds, 736.25 Sapphires).  
3 The Revision of the WDH 
The revision of the first version of the WDH aimed 
at satisfying the following properties and 
characteristics:  
 
o semantics: each WDH label should have an 
explicit semantics and should be 
unambiguously identified; 
o disjunction: the interpretation of all WDH 
labels should not overlap; 
o basic coverage: all human knowledge should 
be covered  by the Basic Domains; 
o basic balancing: most Basic Domains should 
have a comparable degree of granularity. 
 
In the following sections we are going to show 
how a systematic mapping between WDH and 
DDC can be used to enforce each of the above 
characteristics.  
3.1 Semantics 
To give the domain labels a clear semantics so that 
they can be unambiguously identified and 
interpreted, we decided to associate each domain 
label to one or more DDC codes as shown below in 
Table 1.  
WDH Domains 
 
DDC Codes 
 
 Art 
 
[700-(790-(791.43,792,793.3), 
          710,720,745.5)] 
       Plastic arts 730 
                   Sculpture [731:735] 
                   Numismatics 737 
       Jewellery 739.27 
       Drawing [740-745.5] 
       Painting 750 
       Graphic arts 760 
                   Philately 769.56 
       Photography 770 
       Music 780 
       Cinema 791.43 
       Theatre [792-792.8] 
       Dance [792.8,793.3] 
Table 1: Fragment of the new WDH with the 
respective DDC codes 
In many cases we found a one-to-one mapping 
between a WDH label and a DDC code (e.g. 
PAINTING mapped onto 750 or CINEMA onto 
791.43). When one-to-one mappings were not 
found, artificial DDC codes were created. An 
artificial code, represented within square brackets, 
is created with reference to various DDC codes or 
parts of them. To describe artificial nodes, certain 
conventions have been adopted.  
(i) A series of non-consecutive codes is listed 
separated by a comma (see DANCE). 
(ii) A series of consecutive codes is indicated by a 
range. For instance, the series [731, 732, 733, 734, 
735] is abbreviated as [731:735] (see SCULPTURE). 
(iii) A part of a tree is represented as the difference 
between a tree and one or more of its subtrees, 
where the tree and the subtrees are identified by 
their roots (see DRAWING). 
(iv) The square brackets should be interpreted as 
meaning ?the generalities? of the composition of 
codes contained in the brackets. So, for instance, 
[731:735] should be interpreted as the generalities 
of the codes going from 731 to 735. In the original 
DDC, generalities are identified by the 0 decimal. 
For instance, the code 700 refers to the generalities 
of the codes from 710 to 790. 
To establish a mapping between labels and codes 
we exploited the names of the DDC categories and 
their description in the DDC manual. This worked 
pretty well in most cases, but there are some 
exceptions. Take for instance the TOURISM domain. 
Apparently tourism does not occur as a category in 
the DDC. On a closer inspection it came out that 
the categories which are most clearly related to 
tourism are 910.202:World travel guides and 
910.4:Accounts of travel. 
Note that a WDH domain can be mapped onto 
codes included in different DDC main classes, i.e. 
disciplines. For example ARTISANSHIP 
(745.5:Handicrafts, 338.642:Small business) maps 
onto categories located partly under 700:Art and 
partly under 300:Social Sciences. The same 
happens with SEXUALITY, a domain that following 
the DDC is studied by many different disciplines, 
e.g. philosophy, medicine, psychology, body care. 
As a consequence of the systematic specification 
of the semantics of the WDH domains, some of 
them have been re-labeled with regard to the 
previous version of the hierarchy. For instance, the 
domain BOTANY has been changed to PLANTS, 
ZOOLOGY to ANIMALS, and ALIMENTATION to FOOD. 
This change of focus from the name of the 
discipline to the name of the object of the 
discipline is not only in compliance with the new 
edition of the DDC, but it also reflects current and 
international usage (see, for example, Google 
categories). In some cases the change of the 
domain name comes along with a change of its 
intended interpretation. For instance, we have 
decided to enlarge the semantics of the domain 
ZOOTECHNICS and to call it ANIMAL HUSBANDRY, a 
more generic domain which was missing in the 
previous hierarchy.  
In most cases the hierarchical relations between 
the WDH domains are the same as the relations 
holding between the corresponding DDC codes: 
MUSIC is more specific than ART in the same way 
as 780:Music is more specific than 700:The Arts. 
To reinforce the hierarchical parallelism between 
the WDH and the DCC, we re-located some 
domains with regard to the previous WDH 
hierarchy. For example, OCCULTISM, which was 
placed under RELIGION in the old hierarchy, has 
been moved under the newly created domain 
PARANORMAL. Also, TOPOGRAPHY, previously placed 
under ASTRONOMY, has now been moved under 
GEOGRAPHY.  
In a few cases however we did not respect the 
hierarchical relations specified by the DDC, as in 
the case of the ARCHITECTURE domain shown in 
Table 2. ARCHITECTURE has been mapped onto 
720:Architecture and TOWN PLANNING onto 
710:Civic & landscape art.  
WDH Domains DDC Codes 
 Architecture  [645,690,710,720] 
 
Town Planning 710 
 
Buildings 690 
 
Furniture 645 
Table 2: A fragment of WDH for ARCHITECTURE 
However, whereas the 710 code is sibling of 720 
in the DDC, TOWN PLANNING is child of 
ARCHITECTURE in WDH. Also, ARCHITECTURE and 
TOWN PLANNING should be under ART according to 
the DDC, but they have been placed under 
APPLIED SCIENCE in WDH. 
3.2 Disjunction 
This property requires that no DDC code is 
associated to more than one WDH label. In only 
one case this requirement has not been met. 
Apparently, the DDC does not distinguish between 
the disciplines of Sociology and Anthropology, 
and reserves the codes that go from 301 to 307 to 
both of them. Although these two disciplines are 
strictly connected, it seems to us that in the current 
practice they are considered as distinct. So the 
WDH contains two distinct domains for 
SOCIOLOGY and ANTHROPOLOGY, which partially 
overlap because they both map onto the same DDC 
codes 301:307. 
3.3 Basic Coverage 
The term basic coverage refers to the ideal 
requirement that all human knowledge be covered 
by the totality of the Basic Domains (i.e. the 
domains composing the second level of WDH). 
Also in this case, we used the DDC as a gold 
standard to measure the coverage of WDH. Given 
the fact that the DDC has been used for more than 
a century to classify books and written documents 
all over the world, we can assume that the DDC 
guarantees a complete representation of all 
branches of knowledge. So the basic coverage has 
been manually checked by verifying that all (or 
almost all) the DDC categories can be assigned to 
at least one Basic Domain.  
From a practical point of view, it would be very 
complicated to check all the thousands of codes 
contained in the DDC. Thus, our check relied on 
two assumptions. First, when the Basic Domains 
are taken as a stand alone set, the semantics of a 
Basic Domain is given by its specific code together 
with the codes of its subdomains. Second, once a 
DDC code is covered by a Basic Domain, 
inductively, all the more specific categories are 
covered as well. These assumptions allowed us to 
actually check only the topmost DDC codes. For 
example, let?s take the 300 main class of the DDC. 
Table 3 below shows that all the sub-codes of the 
300 class are covered by one or more domains.  
In order to improve the overall WDH coverage, 
5 completely new domains have been introduced 
(the first three are Basic): PARANORMAL, HOME, 
HEALTH, FINANCE and GRAPHIC ARTS. 
Codes DDC Categories WDH Domains 
300 ? Social sciences 
? SOCIAL SCIENCE 
? SOCIOLOGY 
? ANTHROPOLOGY 
310 ? General statistics ? SOCIOLOGY 
320 ? Political science ? POLITICS 
330 ? Economics ? ECONOMY 
340 ? Law ? LAW 
350 ? Public administration & military service 
? ADMINISTRATION  
? MILITARY 
360 ? Social problems & 
services 
? SOCIOLOGY 
? ECONOMY 
? SEXUALITY 
370 ? Education ? PEDAGOGY 
380 
? Commerce, 
communication, 
transport 
? COMMERCE  
? TELECOMMUNICATION  
? TRANSPORT 
390 ? Customs, etiquette, folklore 
? FASHION  
? ANTHROPOLOGY 
? SEXUALITY  
Table 3: Coverage of the 300 DDC class 
We can now assume that the domain-coverage of 
the new version of WDH is almost equivalent to 
that of the DDC, thus ensuring the complete 
representation of all branches of knowledge. 
The new WDH allowed us to fix a number of 
synset classifications that were unsatisfactory in 
the previous version of WORDNET DOMAINS. For 
instance, in the first version of WORDNET 
DOMAINS the English/Italian synset {microwave 
oven, microwave}/{forno a microonde, 
microonde} was annotated with the FURNITURE 
domain, while the synset {detergent}/{detersivo} 
was annotated with FACTOTUM (i.e. no specific 
domain) as no better solution was available. The 
new WDH hierarchy allows for a more appropriate 
classification of both synsets within the new HOME 
domain. 
A few DDC codes are not covered by the new 
list of domains either. These are the codes under 
the 000:Generalities class which includes 
disciplines such as 010:Bibliography, 020:Library 
& information sciences, 030:Encyclopedic works, 
080:General collections. This section has been 
specifically created for cataloguing general and 
encyclopedic works and collections. So it is a 
idiosyncratic category which is not based on 
subject but on the genre of texts. 
Another set of codes which remains not covered 
by WDH are those going from 420 to 490 and from 
810 to 890. These DDC codes are devoted to 
specific languages and literatures of different 
countries, for example, 430:Germanic Languages, 
440:Romance Languages, 810:American Literature 
in English, etc. These codes are undoubtedly 
relevant for the classification of books, but are not 
compatible with the rationale of WDH, which is 
meant to be a language-independent resource. 
3.4 Basic Balancing 
The requirement about basic balancing is meant to 
assure that all Basic Domains have a comparable 
degree of granularity. 
Defining a granularity metrics for domains is a 
complex issue, for which only a tentative solution 
is provided here. At a first glance, three aspects 
could be taken into consideration: the number of 
publications about a domain, the number of sub-
codes in the DDC, and the relevance of a domain 
in the social life.  
As a first attempt, balancing could be evaluated 
referring to the number of publications classified 
under each Basic Domain. In fact, data are 
available about the number of texts classified 
under each of the DDC codes. Unfortunately, the 
number of books published under a certain 
category may not be indicative of its social 
relevance: very specialized domains may include a 
high number of publications, which however 
circulate in a restricted circle, with low social 
impact. For example, the number of texts classified 
in the History domain turns out to be more then ten 
times the number of texts catalogued under the 
Computer Science domain. However, if one looks 
at the number of HTML pages available on the 
Internet, or the number of magazines sold in a 
newspaper stand, or the number of terms used in 
everyday life, one cannot maintain that History is 
ten times more relevant than Computer Science. 
Another approach for evaluating the granularity 
of domains could be to take into account the 
number of DDC sub-codes corresponding to each 
Basic Domain. Unfortunately, also this approach 
gives results which are far from being satisfactory. 
The fact that a discipline has many subdivisions 
seems not to be clearly correlated with its 
relevance. For instance in the DDC manual 
(version 21) 105 pages can be put in 
correspondence with the ENGINEERING domain, 
whereas only 26 correspond to SPORT. It should 
also be said that there is no correlation between the 
number of publications and the number of sub-
categories in the DDC. For instance, 
ARCHITECTURE has a great number of publications 
classified under it, but on the contrary, the number 
of sub-categories in the DDC is very limited. 
The third criterion to evaluate the granularity of 
domains is their social relevance, which seems not 
to be captured adequately by the previous two 
criteria. Of course, social relevance is very difficult 
to evaluate. We tentatively took into consideration 
the organization of Internet hierarchies such as the 
Google and Yahoo directories, which seem to be 
closer than the DDC to represent the current social 
relevance of certain domains. See for instance the 
huge number of HTML pages classified in Google 
under the topic Television Programs. Of course 
Internet is only a partial view of the organization 
of human knowledge, so we cannot simply rely on 
the Internet to evaluate the granularity of the 
domains. 
None of the approaches analyzed so far seems to 
fit our needs. Thus we took into consideration a 
fourth criterion, which is based on the DDC as 
well. Instead of counting the number of 
subdivisions under a certain DDC code, we 
measured the depth of the code from the top of the 
hierarchy. For instance we can say that 700:Art has 
depth 1, 780:Music has depth 2, 782:Vocal Music 
has depth 3, and so on. We make the assumption 
that two DDC codes with the same depth have the 
same granularity. For instance we assume that 
782:Vocal Music and 382:Foreign Trade have the 
same granularity (both have depth 3).  
In order to evaluate the granularity of the Basic 
Domains against the DDC, we can compare WDH 
labels and DDC codes with the same depth. Given 
that the Basic Domains have depth 2, we should 
compare them to the so called Hundred Divisions 
(000, 010, 020, 030, ?, 100, 110, 120, etc.). 
Summing up, we will say that the Basic Domains 
are balanced if they can all be mapped onto the 
Hundred Divisions. Also, in the comparison we 
should take into account that the Basic Domains 
are 45, whereas the Hundred Divisions are 100. So, 
we expect that in the average, one Basic Domain 
maps onto two Hundred Divisions with a small 
degree of variance with respect to the average.  
What we have obtained from the analysis of the 
new WDH is the following: out of 45 Basic 
Domains 
 
o 4 domains map onto a Main Class (depth 1) 
o 18 domains are mapped at the Hundred 
Divisions level (depth 2) 
o 6 domains are mapped at different DDC levels, 
with the majority of DDC codes at depth 2 
o 17 domains map onto subdivisions of depth 3 
and 4. 
 
As for the average number of DDC codes 
covered by each Basic Domain, the variance is 
quite high. Certain Basic Domains cover a big 
number of codes from the Hundred Divisions. For 
instance HISTORY, and ART cover 6 codes each. 
Instead, in  most cases, one Basic Domain covers 
only one DDC code (e.g. LAW and 340:Law). 
The evaluation of the granularity of the Basic 
Domains according to the proposed criterion can 
be considered satisfactory even if the results 
diverge somewhat from what expected in principle.  
To explain this partial divergence in the 
granularity of domains, one should take into 
consideration that the DDC has been created 
relying heavily on the academic organization of 
knowledge disciplines. On the other side, in the 
practical WDH reorganization process we tried to 
balance somehow this discipline-oriented 
approach, by taking into account also the social 
relevance of domains. This has been done by 
relying on the organization of Internet directories 
and on our personal intuitions. 
Such an approach led us to put at the Basic level 
WDH labels corresponding to DDC codes with 
depth higher than 2 (more specific than the 
Hundreds Divisions). See for instance the 
positioning of RADIO+TV, FOOD, HEALTH, and 
ENVIRONMENT at the Basic level, even if they 
correspond to DDC codes of level 3 and 4.  
Instead, ANIMALS and PLANTS were not Basic in 
the previous version of WDH, but have been 
promoted to the Basic level in accordance with the 
granularity level they have in the DDC.  
Other domain labels have been placed at a lower 
level then expected with reference to the DDC. For 
instance PHILOSOPHY, ART, RELIGION, and 
LITERATURE have been put at the Basic Level, 
even if they correspond to DDC codes belonging to 
the Main Classes (depth 1). On the other side 
ASTROLOGY, ARCHAEOLOGY,  BODY CARE, and  
VETERINARY which were Basic in the previous 
version of the WDH, have been demoted at a lower 
level in accordance with the granularity they have 
in the DDC. Only in one case this process of 
demotion has led to the elimination of a sub-
domain, that is TEXTILE.  
4 Conclusions 
In this paper we described the revision of the 
WORDNET DOMAINS Hierarchy (WDH), with the 
aim of providing it with a clear semantics, and 
evaluating the coverage and balancing of a subset 
of the WDH, called Basic Domains. This has been 
done mostly by relying on the information 
available in the Dewy Decimal Classification 
(DDC). A semantics has been provided to the 
WDH labels by defining one or more pointers to 
DDC codes. The coverage of the Basic Domains 
has been evaluated by checking that each DDC 
code is covered by at least one Basic Domain. 
Finally, balancing has been evaluated mostly by 
comparing the granularity of the Basic Domains 
with the granularity of a subset of the DDC called 
the Hundred Divisions. Balancing is the aspect of 
the Basic Domains which diverges more clearly 
from the DDC. This is explained by the fact that 
we took in higher consideration the social 
relevance of domains. 
We think that the new version of the WDH is 
better suited to act as a useful language-
independent resource in the fields of computational 
lexicography, corpus building, and various NLP 
applications.  
5 Acknowledgements 
Thanks to Alfio Gliozzo for his useful comments 
and suggestions about how to improve the 
WORDNET DOMAINS Hierarchy. 
References  
BALKANET http://www.ceid.upatras.gr/Balkanet/ 
L. Bentivogli, C. Girardi and E. Pianta. 2003. The 
MEANING Italian Corpus. In Proceedings of the 
Corpus Linguistics 2003 Conference. Lancaster, 
United Kingdom. 
C. Fellbaum. 1998. WordNet. An Electronic 
Lexical Database. The MIT Press, Boston. 
B. Magnini and G. Cavagli?. 2000. Integrating 
Subject Field Codes into WordNet. In 
Proceedings of LREC-2000. Athens, Greece. 
B. Magnini, C. Strapparava, G. Pezzulo and A. 
Gliozzo. 2002. The Role of Domain Information 
in Word Sense Disambiguation. Journal of 
Natural Language Engineering (Special Issue on 
evaluating Word Sense Disambiguation 
Systems), 9(1):359:373. 
J.S. Mitchell, J. Beall, W.E. Matthews and G.R. 
New (eds). 1996. Dewey Decimal Classification  
Edition 21 (DDC 21). Forest Press, Albany, New 
York. 
E. Pianta, L. Bentivogli and C. Girardi. 2002. 
MultiWordNet: developing an aligned 
multilingual database. In Proceedings of the 
First Global WordNet Conference. Mysore, 
India. 
G. Rigau, B. Magnini, E. Agirre, P. Vossen and J. 
Carrol. 2002. MEANING: a Roadmap to 
Knowledge Technologies. In Proceedings of the 
COLING-2002 workshop "A Roadmap for 
Computational Linguistics". Taipei, Taiwan. 
H. Schutze. 1998. Automatic Word Sense 
Discrimination. Computational Linguistics, 
24(1):97-123. 
SIMPLE. 2000. Linguistic Specifications. 
Deliverable D2.1, March 2000.  
P. Vossen (ed). 1998. Computers and the 
Humanities (Special Issue on EuroWordNet), 
32(2-3). 
D.E. Walker and R.A. Amsler. 1986. Analyzing 
Language in Restricted Domain. Sublanguage 
description and Processing. Lawrence Earlbaum, 
Hillsdale NJ.  
Appendix : The first two levels of the WDH new version with the corresponding DDC codes 
 
TOP-LEVEL BASIC DOMAINS DDC 
Humanities   
 History [920:990] 
 Linguistics 410 
 Literature [800, 400] 
 Philosophy [100-(130, 150, 176)] 
 Psychology 150 
 Art [700-(710, 720, 745.5, 790-(791.43, 792, 793.3))] 
 Paranormal 130 
 Religion 200 
   
Free_Time  [790-(791.43, 792, 793.3)] 
 Radio-Tv [791.44, 791.45] 
 Play [793.4:795-794.6] 
 Sport [794.6, 796:799] 
   
Applied_Science  600 
 Agriculture [338.1, 630] 
 Food [613.2, 613.3, 641, 642] 
 Home [640-(641, 642, 645)] 
 Architecture [645, 690, 710, 720] 
 Computer_Science [004:006] 
 Engineering 620 
 Telecommunication [383, 384] 
 Medicine [610-(611, 612, 613)] 
   
Pure_Science  500 
 Astronomy  520 
 Biology [570-577, 611, 612-612.6] 
 Animals  590 
 Plants 580 
 Environment  577 
 Chemistry  540 
 Earth  [550, 560, 910-(910.4, 910.202)] 
 Mathematics 510 
 Physics  530 
   
Social_Science  [300.1:300.9] 
 Anthropology [301:307, 395, 398] 
 Health [613-(613.2, 613.3, 613.8, 613.9)] 
 Military [355:359] 
 Pedagogy 370 
 Publishing 070 
 Sociology [301:319-(305.8, 306.7), 360-(363.4, 368)] 
 Artisanship [338.642, 745.5] 
 Commerce [381, 382] 
 Industry [338-(338.1, 338.642), 660, 670, 680] 
 Transport [385:389] 
 Economy [330-(334, 338), 368, 650] 
 Administration [351:354] 
 Law 340 
 Politics 320 
 Tourism [910.202, 910.4] 
 Fashion [390-(392.6, 395, 398), 687] 
 Sexuality [155.3, 176, 306.7, 363.4, 392.6, 612.6, 613.96] 
   
 Factotum  
 
 
Proceedings of the 2nd Workshop on ?Collaboratively Constructed Semantic Resources?, Coling 2010, pages 19?27,
Beijing, August 2010
Extending English ACE 2005 Corpus Annotation with Ground-truth
Links to Wikipedia
Luisa Bentivogli
FBK-Irst
bentivo@fbk.eu
Pamela Forner
CELCT
forner@celct.it
Claudio Giuliano
FBK-Irst
giuliano@fbk.eu
Alessandro Marchetti
CELCT
amarchetti@celct.it
Emanuele Pianta
FBK-Irst
pianta@fbk.eu
Kateryna Tymoshenko
FBK-Irst
tymoshenko@fbk.eu
Abstract
This paper describes an on-going annota-
tion effort which aims at adding a man-
ual annotation layer connecting an exist-
ing annotated corpus such as the English
ACE-2005 Corpus to Wikipedia. The an-
notation layer is intended for the evalua-
tion of accuracy of linking to Wikipedia in
the framework of a coreference resolution
system.
1 Introduction
Collaboratively Constructed Resources (CCR)
such as Wikipedia are starting to be used for a
number of semantic processing tasks that up to
few years ago could only rely on few manually
constructed resources such as WordNet and Sem-
Cor (Fellbaum, 1998). The impact of the new re-
sources can be multiplied by connecting them to
other existing datasets, e.g. reference corpora. In
this paper we will illustrate an on-going annota-
tion effort which aims at adding a manual anno-
tation layer connecting an existing annotated cor-
pus such as the English ACE-2005 dataset1 to a
CCR such as Wikipedia. This effort will produce
a new integrated resource which can be useful for
the coreference resolution task.
Coreference resolution is the task of identify-
ing which mentions, i.e. individual textual de-
scriptions usually realized as noun phrases or pro-
nouns, refer to the same entity. To solve this
task, especially in the case of non-pronominal co-
reference, researchers have recently started to ex-
ploit semantic knowledge, e.g. trying to calculate
1http://projects.ldc.upenn.edu/ace/
the semantic similarity of mentions (Ponzetto and
Strube, 2006) or their semantic classes (Ng, 2007;
Soon et al, 2001). Up to now, WordNet has been
one of the most frequently used sources of se-
mantic knowledge for the coreference resolution
task (Soon et al, 2001; Ng and Cardie, 2002). Re-
searchers have shown, however, that WordNet has
some limits. On one hand, although WordNet has
a big coverage of the English language in terms
of common nouns, it still has a limited coverage
of proper nouns (e.g. Barack Obama is not avail-
able in the on-line version) and entity descrip-
tions (e.g. president of India). On the other hand
WordNet sense inventory is considered too fine-
grained (Ponzetto and Strube, 2006; Mihalcea and
Moldovan, 2001). In alternative, it has been re-
cently shown that Wikipedia can be a promising
source of semantic knowledge for coreference res-
olution between nominals (Ponzetto and Strube,
2006).
Consider some possible uses of Wikipedia.
For example, knowing that the entity men-
tion ?Obama? is described on the Wikipedia
page Barack_Obama2, one can benefit from
the Wikipedia category structure. Categories as-
signed to the Barack_Obama page can be used
as semantic classes, e.g. ?21st-century presidents
of the United States?. Another example of a
useful Wikipedia feature are the links between
Wikipedia pages. For instance, some Wikipedia
pages contain links to the Barack_Obama page.
Anchor texts of these links can provide alterna-
2The links to Wikipedia pages are given displaying only
the last part of the link which corresponds to the title of the
page. The complete link can be obtained adding this part to
http://en.wikipedia.org/wiki/.
19
tive names of this entity, e.g. ?Barack Hussein
Obama? or ?Barack Obama Junior?.
Naturally, in order to obtain semantic knowl-
edge about an entity mention from Wikipedia
one should link this mention to an appropriate
Wikipedia page, i.e. to disambiguate it using
Wikipedia as a sense inventory. The accuracy
of linking entity mentions to Wikipedia is a very
important issue. For example, such linking is a
step of the approach to coreference resolution de-
scribed in (Bryl et al, 2010). In order to evaluate
this accuracy in the framework of a coreference
resolution system, a corpus of documents, where
entity mentions are annotated with ground-truth
links to Wikipedia, is required.
The possible solution of this problem is to ex-
tend the annotation of entity mentions in a corefer-
ence resolution corpus. In the recent years, coref-
erence resolution systems have been evaluated on
various versions of the English Automatic Content
Extraction (ACE) corpus (Ponzetto and Strube,
2006; Versley et al, 2008; Ng, 2007; Culotta et
al., 2007; Bryl et al, 2010). The latest publicly
available version is ACE 20053.
In this paper we present an extension of ACE
2005 non-pronominal entity mention annotations
with ground-truth links to Wikipedia. This exten-
sion is intended for evaluation of accuracy of link-
ing entity mentions to Wikipedia pages. The an-
notation is currently in progress. At the moment
of writing this paper we have completed around
55% of the work. The extension can be exploited
by coreference resolution systems, which already
use ACE 2005 corpus for development and testing
purposes, e.g. (Bryl et al, 2010). Moreover, En-
glish ACE 2005 corpus is multi-purpose and can
be used in other information extraction (IE) tasks
as well, e.g. relation extraction. Therefore, we
believe that our extension might also be useful for
other IE tasks, which exploit semantic knowledge.
In the following we start by providing a brief
overview of the existing corpora annotated with
links to Wikipedia. In Section 3 we describe some
characteristics of the English ACE 2005 corpus,
which are relevant to the creation of the extension.
Next, we describe the general annotation princi-
3http://www.ldc.upenn.edu/Catalog/
CatalogEntry.jsp?catalogId=LDC2006T06
ples and the procedure adopted to carry out the
annotation. In Section 4 we present some anal-
yses of the annotation and statistics about Inter-
Annotator Agreement.
2 Related work
Recent approaches to linking terms to Wikipedia
pages (Cucerzan, 2007; Csomai and Mihalcea,
2008; Milne and Witten, 2008; Kulkarni et al,
2009) have used two kinds of corpora for eval-
uation of accuracy: (i) sets of Wikipedia pages
and (ii) manually annotated corpora. In Wikipedia
pages links are added to terms ?only where
they are relevant to the context?4. Therefore,
Wikipedia pages do not contain the full annotation
of all entity mentions. This observation applies
equally to the corpus used by (Milne and Wit-
ten, 2008), which includes 50 documents from the
AQUAINT corpus annotated following the same
strategy5. The corpus created by (Cucerzan, 2007)
contains annotation of named entities only6. It
contains 756 annotations, therefore for our pur-
poses it is limited in terms of size.
Kulkarni et al (2009) have annotated 109 doc-
uments collected from homepages of various sites
with as many links as possible7. Their annotation
is too extensive for our purposes, since they do not
limit annotation to the entity mentions. To tackle
this issue, one can use an automatic entity mention
detector, however it is likely to introduce noise.
3 Creating the extension
The task consists of manually annotating the
non-pronominal mentions contained in the En-
glish ACE 2005 corpus with links to appropriate
Wikipedia articles. The objective of the work is
to create an extension of ACE 2005, where all the
mentions contained in the ACE 2005 corpus are
disambiguated using Wikipedia as a sense reposi-
tory to point to. The extension is intended for the
4http://en.wikipedia.org/wiki/
Wikipedia:Manual_of_Style
5http://www.nzdl.org/wikification/
docs.html
6http://research.microsoft.com/en-us/
um/people/silviu/WebAssistant/TestData/
7http://soumen.cse.iitb.ac.in/?soumen/
doc/CSAW/
20
evaluation of accuracy of linking to Wikipedia in
the framework of a coreference resolution system.
3.1 The English ACE 2005 Corpus
The English ACE 2005 corpus is composed of
599 articles assembled from a variety of sources
selected from broadcast news programs, newspa-
pers, newswire reports, internet sources and from
transcribed audio. It contains the annotation of a
series of entities (person, location, organization)
for a total of 15,382 different entities and 43,624
mentions of these entities. A mention is an in-
stance of a textual reference to an object, which
can be either named (e.g. Barack Obama), nom-
inal (e.g. the president), or pronominal (e.g. he,
his, it). An entity is an aggregate of all the men-
tions which refer to one conceptual entity. Beyond
the annotation of entities and mentions, ACE 05
contains also the annotation of local co-reference
for the entities; this means that mentions which
refer to the same entity in a document have been
marked with the same ID.
3.2 Annotating ACE 05 with Wikipedia
Pages
For the purpose of our task, not all the
ACE 05 mentions are annotated, but only the
named (henceforth NAM) and nominal (hence-
forth NOM) mentions. The resulting additional
annotation layer will contain a total of 29,300
mentions linked to Wikipedia pages. As specif-
ically regards the annotation of NAM mentions,
information about local coreference contained in
ACE 05 has been exploited in order to speed up
the annotation process. In fact, only the first
occurrence of the NAM mentions in each doc-
ument has been annotated and the annotation is
then propagated to all the other co-referring NAM
mentions in the document.
Finally, it must be noted that in ACE 05, given
a complex entity description, both the full ex-
tent of the mention (e.g. president of the United
States) and its syntactic head (e.g. ?president?)
are marked. In our Wikipedia extension only the
head of the mention is annotated, while the full ex-
tent of the mention is available from the original
ACE 05 corpus.
3.3 General Annotation Principles
Depending on the mention type to be annotated,
i.e. NAM or NOM, a different annotation strategy
has been followed. Each mention of type NAM
is annotated with a link to a Wikipedia page de-
scribing the referred entity. For instance, ?George
Bush? is annotated with a link to the Wikipedia
page George_W._Bush.
NOM mentions are annotated with a link to the
Wikipedia page which provides a description of
its appropriate sense. For instance, in the exam-
ple ?I was driving Northwest of Baghdad and I
bumped into these guys going around the capi-
tal? the mention ?capital? is linked to the page
which provides a description of its meaning, i.e.
Capital_(political). Note that the object
of linking is the textual description of an entity,
and not the entity itself. In the example, even
though from the context it is clear that the mention
?capital? refers to Baghdad, we provide a link to
the concept of capital and not to the entity Bagdad.
As a term can have both a more generic sense
and a more specific one, depending on the context
in which it occurs, mentions of type NOM can of-
ten be linked to more than one Wikipedia page.
Whenever possible, the NOM mentions are anno-
tated with a list of links to appropriate Wikipedia
pages in the given context. In such cases, links
are sorted in order of relevance, where the first
link corresponds to the most specific sense for that
term in its context, and therefore is regarded as the
best choice. For instance, for the NOM mention
head ?President? which in the context identifies
the United States President George Bush the an-
notation?s purpose is to provide a description of
the item ?President?, so the following links are
selected as appropriate: President_of_the_
United_States and President.
The correct interpretation of the term is strictly
related to the context in which the term occurs.
While performing the annotation, the context of
the entire document has always been exploited in
order to correctly identify the specific sense of the
mention.
3.4 Annotation Procedure
The annotation procedure requires that the men-
tion string is searched in Wikipedia in order to
21
find the appropriate page(s) to be used for anno-
tating the mention. In the annotation exercise, the
annotators have always taken into consideration
the context where a mention occurs, searching for
both the generic and the most specific sense of the
mention disambiguated in the context. In fact, in
the example provided above, not only ?President?,
but also ?President of the United States? has been
queried in Wikipedia as required by the context.
Not only the context, but also some features of
Wikipedia must be mentioned as they affect the
annotation procedure:
a. One element which contributes to the choice
of the appropriate Wikipedia page(s) for
one mention is the list of links proposed in
Wikipedia?s Disambiguation pages. Disam-
biguation pages are non-article pages which
are intended to allow the user to choose from
a list of Wikipedia articles defining different
meanings of a term, when the term is am-
biguous. Disambiguation pages cannot be
used as links for the annotation as they are
not suitable for the purposes of this task. In
fact, the annotator?s task is to disambiguate
the meaning of the mention, so one link,
pointing to a specific sense, is to be cho-
sen. Disambiguation pages should always be
checked as they provide useful suggestions
in order to reach the appropriate link(s).
b. In the same way as Disambiguation pages,
Wikitionary cannot be used as linking page,
as it provides a list of possible senses for a
term and not only one specific sense which is
necessary to disambiguate the mention.
c. In Wikipedia, terms may be redirected to
other terms which are related in terms of
morphological derivation; i.e. searching for
the term ?Senator? you are automatically
redirected to ?Senate?; or querying ?citizen?
you are automatically redirected to ?citizen-
ship?. Redirections have always been con-
sidered appropriate links for the term.
Some particular rules have been followed in order
to deal with specific cases in the annotation, which
are described below:
1. As explained before in Section 3.2, as a gen-
eral rule the head of the ACE 05 mention
is annotated with Wikipedia links. In those
cases where the syntactic head of the men-
tion is a multiword lexical unit, the ACE 05
practice is to mark as head only the rightmost
item of the multiword. For instance, in the
case of the multiword ?flight attendant? only
?attendant? is marked as head of the men-
tion, although ?flight attendant? is clearly a
multiword lexical unit that should be anno-
tated as one semantic whole. In our anno-
tation we take into account the meaning of
the whole lexical unit; so, in the above exam-
ple, the generic sense of ?attendant? has not
been given, whereas Flight_attendant
is considered as the appropriate link.
2. In some cases, in ACE 2005 pronouns like
?somebody?, ?anybody?, ?anyone?, ?one?,
?others?, were incorrectly marked as NOM
(instead of PRO). Such cases, which amount
to 117, have been marked with the tag ?No
Annotation?.
3. When a page exists in Wikipedia for a given
mention but not for the specific sense in that
context the ?Missing sense? annotation has
been used. One example of ?Missing sense?
is for instance the term ?heart? which has 29
links proposed in the ?Disambiguation page?
touching different categories (sport, science,
anthropology, gaming, etc.), but there is no
link pointing to the sense of ?center or core of
something?; so, when referring to the heart
of a city, the term has been marked as ?Miss-
ing sense?.
4. When no article exists in Wikipedia for a
given mention, the tag ?No page? has been
adopted.
5. Nicknames, i.e. descriptive names used
in place of or in addition to the official
name(s) of a person, have been treated as
NAM. Thus, even if nicknames look like de-
scriptions of individuals (and their reference
should not be solved, following the general
rule), they are actually used and annotated as
22
Number of annotated mentions 16310
Number of single link mentions 13774
Number of multi-link mentions 1458
Number of ?No Page? annotations 481
Number of ?Missing Sense? 480
annotations
Number of ?No Annotation? 117
annotations
Total number of links 16851
Total number of links in multi-link 3077
mentions
Table 1: Annotation data
proper names aliases. For example, given the
mention ?Butcher of Baghdad?, whose head
?Butcher? is to be annotated, the appropriate
Wikipedia link is Saddam_Hussein, auto-
matically redirected from the searched string
?Butcher of Baghdad?. The link Butcher
is not appropriate as it provides a description
of the mention. It is interesting the fact that
Wikipedia itself redirects to the page of Sad-
dam Hussein.
4 The ACE05-WIKI Extension
Up to now, the 55% of the markable men-
tions have been annotated by one annotator,
amounting to 16,310 mentions. This annotation
has been carried out by CELCT in a period
of two months from February 22 to April 30,
2010, using the on-line version of Wikipedia,
while the remaining 45% of the ACE mentions
will be annotated during August 2010. The
complete annotation will be freely available
at: http://www.celct.it/resources.
php?id_page=acewiki2010, while the
ACE 2005 corpus is distributed by LDC8.
4.1 Annotation Data Analysis
Table 1 gives some statistics about the overall
annotation. In the following sections, mentions
annotated with one link are called ?single link?,
whereas, mentions annotated with more than one
link are named ?multi-link?.
These data refer to the annotation of each sin-
gle mention. It is not possible to give statis-
tics at the entity level, as mentions have differ-
8http://www.ldc.upenn.edu/Catalog/
CatalogEntry.jsp?catalogId=LDC2006T06
Annotation Mention Type
NAM NOM
Single link mentions 6589 7185
Multi-link mentions 79 1379
Missing sense 96 384
No Page 440 41
Table 2: Distinction of NAM and NOM in the an-
notation
ent ID depending on the documents they belong
to, and the information about the cross-document
co-reference is not available. Moreover, mentions
of type NOM are annotated with different links
depending on their disambiguated sense, making
thus impossible to group them together.
Most mentions have been annotated with only
one link; if we consider multi-link mentions, we
can say that each mention has been assigned an
average of 2,11 links (3,077/1,458).
Data about ?Missing sense? and ?No page?
are important as they provide useful information
about the coverage of Wikipedia as sense in-
ventory. Considering both ?Missing sense? and
?No page? annotations, the total number of men-
tions which have not been linked to a Wikipedia
page amounts to 6%, equally distributed between
?Missing sense? and ?No page? annotations. This
fact proves that, regarded as a sense inventory,
Wikipedia has a broad coverage. As Table 2
shows, the mentions for which more than one link
was deemed appropriate are mostly of type NOM,
while NAM mentions have been almost exclu-
sively annotated with one link only. The very few
cases in which a NAM mention is linked to more
than one Wikipedia page are primarily due to (i)
mistakes in the ACE 05 annotation (for example,
the mention ?President? was erroneously marked
as a NAM); (ii) or to cases where nouns marked
as NAM could also be considered as NOMs (see
for instance the mention ?Marine?, to mean the
Marine Corps).
Table 2 provides also statistics about the ?Miss-
ing sense? and ?No page? cases provided on men-
tions divided among the NAM and NOM type.
The ?missing sense? annotation concerns mostly
the NOM category, whereas the NAM category
is hardly affected. This attests the fact that per-
sons, locations and organizations are well repre-
23
sented in Wikipedia. This is mainly due to the
encyclopedic nature of Wikipedia where an arti-
cle may be about a person, a concept, a place,
an event, a thing etc.; instead, information about
nouns (NOM) is more likely to be found in a
dictionary, where information about the meanings
and usage of a term is provided.
4.2 Inter-Annotator Agreement
About 3,100 mentions, representing more than
10% of the mentions to be annotated, have been
annotated by two annotators in order to calculate
Inter-Annotator Agreement.
Once the annotations were completed, the
two annotators carried out a reconciliation phase
where they compared the two sets of links pro-
duced. Discrepancies in the annotation were
checked with the aim of removing only the more
rough errors and oversights. No changes have
been made in the cases of substantial disagree-
ment, which has been maintained.
In order to measure Inter-Annotator Agree-
ment, two metrics were used: (i) the Dice coeffi-
cient to measure the agreements on the set of links
used in the annotation9 and (ii) two measures of
agreement calculated at the mention level, i.e. on
the group of links associated to each mention.
The Dice coefficient is computed as follows:
Dice = 2C/(A + B)
where C is the number of common links chosen by
the two annotators, while A and B are respectively
the total number of links selected by the first and
the second annotator. Table 3 shows the results
obtained both before and after the reconciliation
9The Dice coefficient is a typical measure used to com-
pare sets in IR and is also used to calculate inter-annotator
agreement in a number of tasks where an assessor is allowed
to select a set of labels to apply to each observation. In fact,
in these cases measures such as the widely used K are not
good to calculate agreement. This is because K only offers
a dichotomous distinction between agreement and disagree-
ment, whereas what is needed is a coefficient that also allows
for partial disagreement between judgments. In fact, in our
case we often have a partial agreement on the set of links
given for each mention. Also considering only the mentions
for which a single link has been chosen, it is not possible
to calculate K statistics in a straightforward way as the cate-
gories (i.e. the possible Wikipedia pages) in some cases can-
not be determined a priori and are different for each mention.
Due to these factors chance agreement cannot be calculated
in an appropriate way.
BEFORE AFTER
reconciliation reconciliation
DICE 0.85 0.94
Table 3: Statistics about Dice coefficient
BEFORE AFTER
reconciliation reconciliation
Complete 77.98% 91.82%
On first link 84.41% 95.58%
Table 4: Agreement at the mention level
process. Agreement before reconciliation is satis-
factory and shows the feasibility of the annotation
task and the reliability of the annotation scheme.
Two measures of agreement at the mention
level are also calculated. To this purpose, we
count the number of mentions where annotators
agree, as opposed to considering the agreement on
each link separately. Mention-level agreement is
calculated as follows:
Number of mentions with annotation in agreement
Total number of annotated mentions
We calculate both ?complete? agreement and
agreement on the first link. As regards the first
measure, a mention is considered in complete
agreement if (i) it has been annotated with the
same link(s) and (ii) in the case of multi-link men-
tions, links are given in the same order. As for the
second measure, there is agreement on a mention
if both the annotators chose the same first link (i.e.
the one judged as the most appropriate), regard-
less of other possible links assigned to that men-
tion. Table 4 provides data about both complete
agreement and first link agreement, calculated be-
fore and after the annotators reconciliation.
4.3 Disagreement Analysis
Considering the 3,144 double-annotated men-
tions, the cases of disagreements amount to 692
(22,02%) before the reconciliation while they are
reduced to 257 (8,18%) after that process. It is in-
teresting to point out that the disagreements affect
the mentions of type NOM in most of the cases,
whereas mentions of type NAM are involved only
in 3,8% of the cases.
Examining the two annotations after the recon-
ciliation, it is possible to distinguish three kinds
of disagreement which are shown in Table 5 to-
24
Number of
Disagreement type Disagreements
1) No matching in the link(s)
proposed
105 (40,85%)
2) No matching on the first link,
but at least one of the other links
is the same
14 (5,45%)
3) Matching on the first link and
mismatch on the number of ad-
ditional links
138 (53,70%)
Total Disagreements 257
Table 5: Types of disagreements
gether with the data about their distribution. An
example of disagreement of type (1) is the anno-
tation of the mention ?crossing?, in the following
context: ?Marines from the 1st division have se-
cured a key Tigris River Crossing?. Searching for
the word ?river crossing? in the Wikipedia search-
box, the Disambiguation Page is opened and a
list of possible links referring to more specific
senses of the term are offered, while the generic
?river crossing? sense is missing. The annota-
tors are required to choose just one of the possi-
ble senses provided and they chose two different
links pointing to pages of more specific senses:
{Ford_%28river%29} and {Bridge}.
Another example is represented by the annota-
tion of the mention ?area? in the context : ?Both
aircraft fly at 125 miles per hour gingerly over en-
emy area?. In Wikipedia no page exists for the
specific sense of ?area? appropriate in the con-
text. Searching for ?area? in Wikipedia, the page
obtained is not suitable, and the Disambiguation
page offers a list of various possible links to either
more specific or more general senses of the term.
One annotator judged the more general Wikipedia
page Area_(subnational_entity) as ap-
propriate to annotate the mention, while the sec-
ond annotator deemed the page not suitable and
thus used the ?Missing sense? annotation.
Disagreement of type (2) refers to cases where
at least one of the links proposed by the annota-
tors is the same, but the first (i.e. the one judged
as the most suitable) is different. Given the fol-
lowing context: ?Tom, You know what Liber-
als want?, the two annotation sets provided for
the mention ?Liberal? are: {Liberalism} and
{Liberal_Party, Modern_liberalism_
in_the_United_States, Liberalism}.
The first annotator provided only one link for
the mention ?liberal?, which is different from the
first link provided by second annotator. However,
the second annotator provided also other links,
among which there is the link provided by the first
annotator.
Another example is represented by the annota-
tion of the mention ?killer?. Given the context:
?He?d be the 11th killer put to death in Texas?, the
two annotators provided the following link sets:
{Assassination, Murder} and {Murder}.
Starting from the Wikipedia disambiguation page,
the two annotators agreed on the choice of one of
the links but not on the first one.
Disagreement of type (3) refers to cases where
both annotators agree on the first link, correspond-
ing to the most specific sense, but one of them
also added link(s) considered appropriate to an-
notate the mention. Given the context: ?7th Cav-
alry has just taken three Iraqi prisoners?, the an-
notations provided for the term ?prisoners? are:
{Prisoner_of_war} and {Prisoner_of_
war, Incarceration}. This happens when
more than one Wikipedia pages are appropriate to
describe the mention.
As regards the causes of disagreement, we see
that the cases of disagreement mentioned above
are due to two main reasons:
a. The lack of the appropriate sense in
Wikipedia for the given mention
b. The different interpretation of the context in
which the mention occurs.
In cases of type (a) the annotators adopted differ-
ent strategies to perform their task, that is:
i. they selected a more general sense (i.e.
?area? which has been annotated with
Area_(subnational_entity)),
ii. they selected a more specific sense (see for
example the annotations of the mentions
?river crossing?).
iii. they selected the related senses proposed by
the Wikipedia Disambiguation page (as in
the annotation of ?killer? in the example
above).
25
Disagreement Reas. a Reas. b Tot
type (see above)
1) No match 95 10 105
2) No match on 4 10 14
first link
3) Mismatch on 138 138
additional links
Total 99 158 257
(38,5%) (61,5%)
Table 6: Distribution of disagreements according
to their cause
iv. they used the tag ?Missing sense?.
As Wikipedia is constantly evolving, adding
new pages and consequently new senses, it is
reasonable to think that the considered elements
might find the appropriate specific/general link as
time goes by.
Case (b) happens when the context is ambigu-
ous and the information provided in the text al-
lows different possible readings of the mention
to be annotated, making thus difficult to disam-
biguate its sense. These cases are independent
from Wikipedia sense repository but are related to
the subjectivity of the annotators and to the inher-
ent ambiguity of text.
Table 6 shows the distribution of disagreements
according to their cause. Disagreements of type 1
and 2 can be due to both a and b reasons, while
disagreements of type 3 are only due to b.
The overall number of disagreements shows
that the cases where the two annotators did not
agree are quite limited, amounting only to 8%.
The analyses of the disagreements show some
characteristics of Wikipedia considered as sense
repository. As reported in Table 8, in the 61,5%
of the cases of disagreement, the different anno-
tations are caused by the diverse interpretation
of the context and not by the lack of senses in
Wikipedia. It is clear that Wikipedia has a good
coverage and it proves to be a good sense disam-
biguation tool. In some cases it reveals to be too
fine-grained and in other cases it remains at a more
general level.
5 Conclusion
This paper has presented an annotation work
which connects an existing annotated corpus such
as the English ACE 2005 dataset to a Collabo-
ratively Constructed Semantic Resource such as
Wikipedia. Thanks to this connection Wikipedia
becomes an essential semantic resource for the
task of coreference resolution. On one hand, by
taking advantage of the already existing annota-
tions, with a relatively limited additional effort,
we enriched an existing corpus and made it useful
for a new NLP task which was not planned when
the corpus was created. On the other hand, our
work allowed us to explore and better understand
certain characteristics of the Wikipedia resource.
For example we were able to demonstrate in quan-
titative terms that Wikipedia has a very good cov-
erage, at least as far as the kind of entity men-
tions which are contained in the ACE 2005 dataset
(newswire) is concerned.
Acknowledgments
The research leading to these results has re-
ceived funding from the ITCH project (http://
itch.fbk.eu), sponsored by the Italian Min-
istry of University and Research and by the Au-
tonomous Province of Trento and the Copilosk
project (http://copilosk.fbk.eu), a Joint
Research Project under Future Internet - Internet
of Content program of the Information Technol-
ogy Center, Fondazione Bruno Kessler.
We thank Giovanni Moretti from CELCT for
technical assistance.
References
Bryl, Volha, Claudio Giuliano, Luciano Serafini, and
Kateryna Tymoshenko. 2010. Using background
knowledge to support coreference resolution. In
Proceedings of the 19th European Conference on
Artificial Intelligence (ECAI 2010), August.
Csomai, Andras and Rada Mihalcea. 2008. Linking
documents to encyclopedic knowledge. IEEE Intel-
ligent Systems, 23(5):34?41.
Cucerzan, Silviu. 2007. Large-scale named entity
disambiguation based on Wikipedia data. In Pro-
ceedings of the 2007 Joint Conference on Empirical
Methods in Natural Language Processing and Com-
putational Natural Language Learning (EMNLP-
CoNLL), pages 708?716, Prague, Czech Republic,
June. Association for Computational Linguistics.
26
Culotta, Aron, Michael L. Wick, and Andrew McCal-
lum. 2007. First-order probabilistic models for
coreference resolution. In Human Language Tech-
nology Conference of the North American Chap-
ter of the Association of Computational Linguistics,
pages 81?88.
Fellbaum, Christiane, editor. 1998. WordNet: an elec-
tronic lexical database. MIT Press.
Kulkarni, Sayali, Amit Singh, Ganesh Ramakrishnan,
and Soumen Chakrabarti. 2009. Collective anno-
tation of wikipedia entities in web text. In KDD
?09: Proceedings of the 15th ACM SIGKDD inter-
national conference on Knowledge discovery and
data mining, pages 457?466, New York, NY, USA.
ACM.
Mihalcea, Rada and Dan I. Moldovan. 2001.
Ez.wordnet: Principles for automatic generation of
a coarse grained wordnet. In Russell, Ingrid and
John F. Kolen, editors, FLAIRS Conference, pages
454?458. AAAI Press.
Milne, David and Ian H. Witten. 2008. Learning
to link with wikipedia. In CIKM ?08: Proceed-
ing of the 17th ACM conference on Information and
knowledge management, pages 509?518, New York,
NY, USA. ACM.
Ng, Vincent and Claire Cardie. 2002. Improving ma-
chine learning approaches to coreference resolution.
In ACL ?02: Proceedings of the 40th Annual Meet-
ing on Association for Computational Linguistics,
pages 104?111.
Ng, Vincent. 2007. Semantic class induction and
coreference resolution. In ACL 2007, Proceed-
ings of the 45th Annual Meeting of the Association
for Computational Linguistics, June 23-30, 2007,
Prague, Czech Republic, pages 536?543.
Ponzetto, S. P. and M. Strube. 2006. Exploiting se-
mantic role labeling, WordNet and Wikipedia for
coreference resolution. Proceedings of the main
conference on Human Language Technology Con-
ference of the North American Chapter of the As-
sociation of Computational Linguistics, pages 192?
199.
Soon, Wee Meng, Hwee Tou Ng, and Daniel
Chung Yong Lim. 2001. A machine learning ap-
proach to coreference resolution of noun phrases.
Computational Linguistic, 27(4):521?544.
Versley, Yannick, Simone Paolo Ponzetto, Massimo
Poesio, Vladimir Eidelman, Alan Jern, Jason Smith,
Xiaofeng Yang, and Alessandro Moschitti. 2008.
Bart: a modular toolkit for coreference resolution.
In Proceedings of the 46th Annual Meeting of the
Association for Computational Linguistics on Hu-
man Language Technologies, pages 9?12.
27
