Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 820?828,
Honolulu, October 2008. c?2008 Association for Computational Linguistics
Integrating Multi-level Linguistic Knowledge with a Unified Framework for
Mandarin Speech Recognition
Xinhao Wang, Jiazhong Nie, Dingsheng Luo, Xihong Wu?
Speech and Hearing Research Center,
Key Laboratory of Machine Perception (Ministry of Education),
School of Electronics Engineering and Computer Science,
Peking University, Beijing, 100871, China
{wangxh,niejz,wxh,dsluo}@cis.pku.edu.cn
Abstract
To improve the Mandarin large vocabulary
continuous speech recognition (LVCSR), a
unified framework based approach is intro-
duced to exploit multi-level linguistic knowl-
edge. In this framework, each knowledge
source is represented by a Weighted Finite
State Transducer (WFST), and then they are
combined to obtain a so-called analyzer for in-
tegrating multi-level knowledge sources. Due
to the uniform transducer representation, any
knowledge source can be easily integrated into
the analyzer, as long as it can be encoded
into WFSTs. Moreover, as the knowledge in
each level is modeled independently and the
combination is processed in the model level,
the information inherently in each knowledge
source has a chance to be thoroughly ex-
ploited. By simulations, the effectiveness
of the analyzer is investigated, and then a
LVCSR system embedding the presented ana-
lyzer is evaluated. Experimental results reveal
that this unified framework is an effective ap-
proach which significantly improves the per-
formance of speech recognition with a 9.9%
relative reduction of character error rate on
the HUB-4 test set, a widely used Mandarin
speech recognition task.
1 Introduction
Language modeling is essential for large vocabu-
lary continuous speech recognition (LVCSR), which
aims to determine the prior probability of a supposed
word string W , p(W ). Although the word-based n-
gram language model remains the mainstream for
?Corresponding author: Xihong Wu
most speech recognition systems, the utilization of
linguistic knowledge is too limited in this model.
Consequently, many researchers have focused on
introducing more linguistic knowledge in language
modeling, such as lexical knowledge , syntax and
semantics of language (Wang and Vergyri, 2006;
Wang et al, 2004; Charniak, 2001; Roark, 2001;
Chelba, 2000; Heeman, 1998; Chelba et al, 1997).
Recently, structured language models have been
introduced to make use of syntactic hierarchi-
cal characteristics (Roark, 2001; Charniak, 2001;
Chelba, 2000). Nevertheless, the computational
complexity of decoding will be heavily increased, as
they are parser-based models. In contrast, the class-
based language model groups the words that have
similar functions of syntax or semantics into mean-
ingful classes. As a result, it handles the questions of
data sparsity and generalization of unseen event. In
practice, the part-of-speech (POS) information, cap-
turing the syntactic role of words, has been widely
used in clustering words (Wang and Vergyri, 2006;
Maltese et al, 2001; Samuelsson and Reichl, 1999).
In Heeman?s POS language model (Heeman, 1998),
the joint probability of word sequence and associ-
ated POS sequence was estimated directly, which
has been demonstrated to be superior to the condi-
tional probability previously used in the class-based
models (Johnson, 2001). Moreover, a SuperARV
language model was presented (Wang and Harper,
2002), in which lexical features and syntactic con-
straints were tightly integrated into a linguistic struc-
ture of SuperARV serving as a class in the model.
Thus, these knowledge was integrated in the rep-
resentation level, and then the joint probabilities
820
of words and corresponding SuperARVs were esti-
mated. However, in the class-based language mod-
els, words are taken as the model units, while other
units smaller or larger than words are unfeasible for
modeling simultaneously, such as the Chinese char-
acters for Chinese names.
Usually, speech recognition systems can only rec-
ognize the words within a predefined dictionary.
With the increase of unknown words, i.e., out-of-
vocabulary (OOV) words, the performance will de-
grade dramatically. This is because not only those
unknown words cannot be recognized correctly, but
the words surrounding them will be affected. Thus,
many efforts have been made to deal with the is-
sue of OOV words (Martins et al, 2006; Galescu,
2003; Bazzi and Glass, 2001), and various model
units smaller than words have been examined to rec-
ognize OOVs from speech, such as phonemes (Bazzi
and Glass, 2000a), variable-length phoneme se-
quence (Bazzi and Glass, 2001), syllable (Bazzi and
Glass, 2000b) and sub-word (Galescu, 2003). Since
the proper name is a typical category of OOV words
and usually takes a very large proportion among all
kinds of OOV words, it has been specially addressed
in (Hu et al, 2006; Tanigaki et al, 2000).
All those attempts mentioned above succeed in
utilizing linguistic knowledge in language modeling
in some degree respectively. In this study, a uni-
fied framework based approach, which aims to ex-
ploit information from multi-level linguistic knowl-
edge, is presented. Here, the Weighted Finite State
Transducer (WFST) turns to be an ideal choice for
our purpose. WFSTs were formerly introduced to
simplify the integration of models in speech recog-
nition, including acoustic models, phonetic mod-
els and word n-gram (Mohri, 1997; Mohri et al,
2002). In recent years, the WFST has been suc-
cessfully applied in several state-of-the-art speech
recognition systems, such as systems developed by
the AMI project (Hain et al, 2006), IBM (Saon et
al., 2003) and AT&T (Mohri et al, 1996), and in
various fields of natural language processing, such
as smoothed n-gram model, partial parsing (Abney,
1996), named entities recognition (Friburger and
Maurel, 2004), semantic interpretation (Raymond et
al., 2006) and machine translation (Tsukada and Na-
gata, 2004). In (Takaaki Hori and Minami, 2003),
the WFST has been further used for language model
adaptation, where language models of different vo-
cabularies that represented different styles were in-
tegrated through the framework of speech transla-
tion. In WFST-based systems, all of the models are
represented uniformly by WFSTs, and the general
composition algorithm (Mohri et al, 2000) com-
bines these representations flexibly and efficiently.
Thereby, rather than integrating the models step by
step in decoding stage, a complete search network is
constructed in advance. The combined WFST will
be more efficient by optimizing with determiniza-
tion, minimization and pushing algorithms of WF-
STs (Mohri, 1997). Besides, the researches on opti-
mizing the search space and improving WFST-based
speech recognition has been carried out, especially
on how to perform on-the-fly WFSTs composition
more efficiently (Hori et al, 2007; Diamantino Ca-
seiro, 2002).
In this study, we extend the linguistic knowledge
used in speech recognition. As WFSTs provide a
common and natural representation for lexical con-
straints, n-gram language model, Hidden Markov
Model models and context-dependency, multi-level
knowledge sources can be encoded into WFSTs un-
der the uniform transducer representation. Then this
group of WFSTs is flexibly combined together to
obtain an analyzer representing knowledge of per-
son and location names as well as POS information.
Afterwards, the presented analyzer is incorporated
into LVCSR to evaluate the linguistic correctness of
recognition candidates by an n-best rescoring.
Unlike other methods, this approach holds two
distinct features. Firstly, as all multi-level knowl-
edge sources are modeled independently, the model
units such as character, words, phrase, etc., can be
chosen freely. Meanwhile, the integration of these
information sources is conducted in the model level
rather than the representation level. This setup will
help to model each knowledge source sufficiently
and may promote the accuracy of speech recogni-
tion. Secondly, under this unified framework, it is
easy to combine additional knowledge source into
the framework with the only requirement that the
new knowledge source can be represented by WF-
STs. Moreover, since all knowledge sources are fi-
nally represented by a single WFST, additional ef-
forts are not required for decoding the new knowl-
edge source.
821
The remainder of this paper is structured as fol-
lows. In section 2, we introduce our analyzer in de-
tail, and incorporate it into a Mandarin speech recog-
nition system. In section 3, the simulations are per-
formed to evaluate the analyzer and test its effective-
ness when being applied to LVCSR. The conclusion
appears in section 4.
2 Incorporation of Multi-level linguistic
knowledge in LVCSR
In this section, we start by giving a brief descrip-
tion on WFSTs. Then some special characteristics
of Chinese are investigated, and the model units are
fixed. Afterwards, each knowledge source is rep-
resented with WFSTs, and then they are combined
into a final WFST, so-called analyzer. At last, this
analyzer is incorporated into Mandarin LVCSR.
2.1 Weighted Finite State Transducers
The Weighted Finite State Transducer (WFST) is the
generalization of the finite state automata, in which,
besides of an input label, an output label and a
weight are also placed on each transition. With these
labels, a WFST is capable of realizing a weighted re-
lation between strings. In our system, log probabili-
ties are adopted as transition weights and the relation
between two strings is associated with a weight indi-
cating the probability of the mapping between them.
Given a group of WFSTs, each of which models a
stage of a mapping cascade, the composition opera-
tion provides an efficient approach to combine them
into a single one (Mohri et al, 2002; Mohri et al,
1996). In particular, for two WFSTs R and S, the
composition T = RoS represents the composition
of relations realized by R and S. The combination
is performed strictly on R?s output and S?s input. It
means for each path in T, mapping string r to string
s, there must exist a path mapping r to some string
t in R and a path mapping t to s in S. Decoding on
the combined WFST enables to find the joint opti-
mal results for multi-level weighted relations.
2.2 Model Unit Selection
This study primarily takes the person and location
names as well as the POS information into account.
To deal with Chinese OOV words, different from
the western language in which the phoneme, sylla-
ble or sub-word are used as the model units (Bazzi
and Glass, 2000a; Bazzi and Glass, 2000b; Galescu,
2003), Chinese characters are taken as the basic
units. In general, a person name of Han nation-
ality consists of a surname and a given name usu-
ally with one or two characters. Surnames com-
monly come from a fixed set that has been histori-
cally used. According to a recent investigation on
surnames involving 296 million people, 4100 sur-
names are found, and 129 most used surnames ac-
count for 87% (conducted by the Institute of Genet-
ics and Developmental Biology, Chinese Academy
of Sciences). In contrast, the characters used in
given names can be selected freely, and in many situ-
ations, some commonly used words may also appear
in names, such as ???? (victory) and ???? (the
Changjiang River). Therefore, both Chinese charac-
ters and words are considered as model units in this
study, and a word re-segmentation process on recog-
nition hypotheses is necessary, where an n-gram lan-
guage model based on word classes is adopted.
2.3 Representation and Integration of
Multi-level Knowledge
In this work, we ignore the word boundaries of n-
best hypotheses and perform a word re-segmentation
for names recognition. Given an input Chinese
character, it is encoded by a finite state acceptor
FSAinput. For example, the input ???????
(while synthesizing molecule) is represented as in
Figure 1(a). Then a dictionary is represented by a
50 321
0
?:??:?
?:??
?:?
(a)
(b)
4
?:?
?:? ?:? ?:?
?:??
?:?
?:?
?:?
?:? ?:?
?:??
?:??
?? ? ? ?
1 3
6
5
4
2
10
9
8
7
Figure 1: (a) is an example of the FSA representing a
given input; (b) is the FST representing a toy dictionary.
822
transducer with empty weights, denoted as FSTdict.
Figure 1(b) illustrates a toy dictionary listed in Ta-
ble 1, in which a successful path encodes a mapping
from a Chinese character sequence to some word
in the dictionary. In practice, all Chinese charac-
Chinese Words English Words
?? synthesize
?? element
?? molecule
?? the period of the day from11 p.m.to l a.m.
? together
? present
Table 1: The Toy dictionary
ters should appear in the dictionary for further in-
corporating models of names. Then the combination
of FSAinput and FSTdict, FSTseg = FSAinput ?
FSTdict, will result in a WFST embracing all the
possible candidate segmentations. Afterwards an n-
gram language model based on word classes is used
to weight the candidate segmentations. As in Fig-
ure 2, a toy bigram with three words is depicted by
WFSTn?gram, and the word classes are defined in
Table 2. Here, both in the training and test stages,
0
w1/un(w1)
w2/un(w2)
w3/un(w3)
4
w3/un(w3)
?/back(w1)
w1/un(w1)
?/back(w3)
w2/un(w2)
?/back(w2)
w1/bi(w2,w1)
w2/bi(w3,w2)
w2/bi(w1,w2)
w3/bi(w2,w3)
w1/bi(w3,w1)
w3/bi(w1,w3)
2
3
1
Figure 2: The WFST representing a toy bigram language
model, in which un(w1) denotes the unigram of w1;
bi(w1, w2) and back(w1) respectively denotes the bi-
gram of w2 and the backoff weight given the word history
w1.
the strings of numbers or letters in sentences are ex-
Classes Description
wi Each word wi listed in the dictionary
CNAME Person names of Han nationality
TNAME Translated person names
LOC Location names
NUM Number expressions
LETTER Letter strings
NON Other non Chinese character strings
BEGIN Beginning of sentence
END End of sentence
Table 2: The Definition of word classes
tracted according to the rules, and then substituted
with the class tags, ?NUM? and ?LETTER? respec-
tively. At the same time, the words, such as ????
and ?A??, are replaced with ?NUM?? and ?LET-
TER?? in the dictionary. In addition, name classes,
including ?CNAME?, ?TNAME? and ?LOC?, will
be set according to names recognition.
Hidden Markov Models (HMMs) are adopted
both for names recognition and POS tagging. Here,
each HMM is represented with two WFSTs. Tak-
ing the POS tagging as an example, the toy POS
WFSTs with 3 different tags are illustrated in Fig-
ure 3. The emission probability of a word by a POS,
(P (word/pos)), is represented as in Figure 3(a),
and the bigram transition probabilities between POS
tags are represented as in Figure 3(b), similar to the
word n-gram. In terms of names recognition, the
HMM states correspond to 30 role tags of names,
some for model units of Chinese characters, such as
surname, the first or second character of a given per-
son name with two characters, the first or last charac-
ter of a location name and so on, but others for model
units of words, such as the word before or after a
name, the words in a name and so on. When rec-
ognizing the person names, since there is a big dif-
ference between the translated names and the names
of Han nationality, two types of person names are
modeled separately, and substituted with two differ-
ent class tags in the segmentation language model,
as ?TNAME? and ?CNAME?. Some rules, which
can be encoded into WFSTs, are responsible for the
transformation from a role sequence to correspond-
ing name class (for example, a role sequence might
consist of the surname, the first character of the
823
0pos1/un(pos1)
pos2/un(pos2)
pos3/un(pos3)
pos1/bi(pos2,pos1)
pos3/bi(pos2,pos3)
pos2/bi(pos1,pos2)
pos3/bi(pos1,pos3)
pos1/bi(pos3,pos1)pos2/bi(pos3,pos2)
(a)
(b)
word: pos/p(word/pos)
3
2
1
0
Figure 3: The toy POS WFSTs. (a) is the WFST rep-
resenting the relationship between the word and the pos;
(b) is the WFSA representing the bigram transition prob-
abilities between POS tags
given name, and the second character of the given
name, which will be transformed to ?CNAME? in
FSTseg). Hence, taking names recognition into ac-
count, a WFST, including all possible segmentations
as well as recognized candidates of names, can be
obtained as below, denoted as WFSTwords:
FSAinput ? FSTdict ?WFSTne ?WFSAn?gram
(1)
POS information is integrated as follows.
(? ?WFSTwords) ?WFSTPOS (2)
Consequently, the desired analyzer, a combined
WFST that represents multi-level linguistic knowl-
edge sources, has been obtained.
2.4 Incorporation in LVCSR
The presented analyzer models linguistic knowledge
at different levels, which will be useful to find an
optimal words sequence among a large number of
speech recognition hypotheses. Thus in this re-
search, the analyzer is incorporated after the first
pass recognition, and the n-best hypotheses are
reranked according to the total path scores adjusted
with the analyzer scores as follows.
W? = argmax
W
?
??
log (PAM (O|W ))
+? ? log (PLM (W ))
+? ? log (PAnalyzer (W ))
?
??
(3)
where PAM (O|W ) and PLM (W ) are the acoustic
and language scores produced in first pass decoding,
and PAnalyzer (W ) reflects the linguistic correctness
of one hypothesis scored by the analyzer. Through
the reranking paradigm, a new best sentence hypoth-
esis is obtained.
3 Simulation
Under the unified framework, multi-level linguistic
knowledge is represented by the analyzer as men-
tioned above. To guarantee the effectiveness of
the introduced framework in integrating knowledge
sources, the analyzer is evaluated in this section.
Then the experiments using an LVCSR system in
which the analyzer is embedded are performed.
3.1 Analyzer Evaluation
Considering the function of the analyzer, cascaded
subtasks of word segmentation, names recognition
and POS tagging can be processed jointly, while
they are traditionally handled in a pipeline manner.
Hence, a comparison between the analyzer and the
pipeline system can be used to evaluate the effec-
tiveness of the introduced framework for knowledge
integration. As illustrated in Figure 4, two systems
based on the presented analyzer and the pipeline
manner are constructed respectively.
The evaluation data came from the People?s Daily
of China in 1998 from January to June (annotated by
the Institute of Computational Linguistics of Peking
University1), among which the January to May data
was taken as the training set, and the June data was
taken as the test set (consisted of 21,143 sentences
and about 1.2 million words). The first two thou-
sand sentences from the June data were extracted
as the development set, used to fix the composition
weight ? in equation 2. A dictionary including about
113,000 words was extracted from the training data,
1http://icl.pku.edu.cn/icl res/
824
input d ict ne n gramF SA F ST W F ST W F ST q q q
Decode
The best segmentation
posWFST
CCompose ompose
Decode Decode
Pipeline System Presented Analyzer
output output
Figure 4: The pipeline system vs The analyzer
in which a person or location name was accounted
as a word in vocabulary, only when the number of
its appearances was no less than three.
In Figure 5, the analyzer is compared with the
pipeline system, where the analyzer outperforms the
pipeline manner on all the subtasks in terms of F1-
score metric. Furthermore to detect the differences,
the statistical significance test using approximate
randomization approach (Yeh, 2000) is done on the
word segmentation results. Since there are more
than 21,000 sentences in the test set, which is not
appropriate for approximate randomization test, ten
sets (500 sentences for each) are randomly selected
from the test corpus. For each set, we run 1048576
shuffles twice and calculate the significance level p-
value according to the shuffled results. It has been
shown that all p-value are less than 0.001 on the ten
sets. Accordingly the improvement is statistically
significant. Actually, this significant improvement
is reasonable, since the joint processing avoids error
propagation and provides the opportunity of shar-
ing information between different level knowledge
sources. The superiority of this analyzer also shows
that the integration of multi-level linguistic knowl-
edge under the unified framework is effective, which
may lead to improved LVCSR.
95.9
91.1
89.9
96.8
91.8
88.5
90.9
88
92
96 Pipeline Analyzer
Integrated Analyzer
83.3
80
84
Word Segmentation POS Tagging Person Name Recognition Location Name Recognition
Figure 5: The Performance comparison between the
pipeline system and the analyzer. The system perfor-
mances are measured with the F1-score in the tasks
of word segmentation, POS tagging, the person names
recognition and the location names recognition.
3.2 Experimental Setup for Mandarin Speech
Recognition
In the baseline speech recognition system, the
acoustic models consisted of context-dependent
Initial-Final models, in which the left-to-right model
topology was used to represent each unit. Accord-
ing to the phonetic structures, the number of states
in each model was set to 2 or 3 for initials, and 4
or 5 for tonal finals. Each state was trained to have
32 Gaussian mixtures. The used 39-dimension fea-
ture vector comprised 12 MFCC coefficients, en-
ergy, and their first-order and second-order deltas.
Since in this work we focused on modeling knowl-
edge of language in Mandarin LVCSR, only clean
male acoustic models were trained with a speech
database that contained about 360 hours speech of
over 750 male speakers. This training data was
picked up from three continuous Mandarin speech
corpora: the 863-I, 863-II and Intel corpora. The
brief information about these three speech corpora
was listed in Table 3. As in this work, the eval-
uation data was the 1997 HUB-4 Mandarin broad-
cast news evaluation data (HUB-4 test set), to bet-
ter fit this task, the acoustic models were adapted
by the approach of maximum a posterior (MAP)
adaptation. The adaption data was drawn from the
HUB4 training set, excluding the HUB-4 develop-
825
Corpus Speakers Amount of Speech
(hours)
863-I (male) 83 56.67
863-II(male) 120 78.08
Intel (male) 556 227.30
total 759 362.05
Table 3: The information of the speech training data
ing set, where only the cleaned male speech data
(data under condition f0 defined as (Doddington,
1996)) was used. The partition for the clean data
was done with the acoustic segmentation software
CMUseg 0.52 (Siegler et al, 1997), and finally 8.6
hours adaptation data was obtained.
The language model was a word-based trigram
built on 60,000 words entries and trained with a cor-
pus about 1.5 billion characters. The training set
consisted of broadcast news data from the Xinhua
News Agency released by LDC (Xinhua part of Chi-
nese Gigaword), seven years data of People?s Daily
of China from 1995 to 2002 released by People?s
Daily Online3, and some other data from news web-
sites, such as yahoo, sina and so on.
In addition, the analyzer incorporated in speech
recognition was trained with a larger corpus from
People?s Daily of China, including the data in 1998
from January to June and the data in 2000 from
January to November (annotated by the Institute
of Computational Linguistics of Peking University).
The December data in 2000 was taken as the devel-
opment set used to fix the composition weight ? in
equation 2.
3.3 Experimental Results
In our experiments, the clean male speech data from
the Hub-4 test set was used, and 238 sentences were
finally extracted for testing. The weight of the ana-
lyzer was empirically derived from the development
set, including 649 clean male sentences from the de-
vSet of HUB-4 Evaluation. The recognition results
are shown in Table 4. The baseline system has a
character error rate (CER) of 14.85%. When the an-
alyzer is incorporated, a 9.9% relative reduction is
2Acoustic segmentation software downloaded from
http://www.nist.gov/speech/tools/CMUseg 05targz.htm.
3http://www.people.com.cn
System Err. Sub. Del. Ins.
Baseline 14.85 13.02 0.76 1.07
Analyzer 13.38 11.78 1.00 0.60incorporation
Table 4: The Speech recognition results
achieved. Furthermore, we ran the statistical signif-
icance test to detect the performance improvement,
in which the approximate randomization approach
(Yeh, 2000) was modified to output the significance
level, p-value, for the CER metric. The p-levels pro-
duced through two rounds of 1048576 shuffles are
0.0058 and 0.0057 respectively, both less than 0.01.
Thus the performance improvement imposed by the
utilization of the analyzer is statistically significant.
4 Conclusion
Addressing the challenges of Mandarin large vocab-
ulary continuous speech recognition task, within the
unified framework of WFSTs, this study presents
an analyzer integrating multi-level linguistic knowl-
edge. Unlike other methods, model units, such as
characters and words, can be chosen freely in this
approach since multi-level knowledge sources are
modeled independently. As a consequence, the fi-
nal analyzer can be derived from the combination
of better optimized models based on proper model
units. Along with two level knowledge sources, i.e.,
the person and location names as well as the part-of-
speech information, the analyzer is built and evalu-
ated by a comparative simulation. Further evaluation
is also conducted on an LVCSR system in which the
analyzer is embedded. Experimental results consis-
tently reveal that the approach is effective, and suc-
cessfully improves the performance of speech recog-
nition by a 9.9% relative reduction of character error
rate on the HUB-4 test set. Also, the unified frame-
work based approach provides a property of integrat-
ing additional linguistic knowledge flexibly, such as
organization name and syntactic structure. Further-
more, the presented approach has a benefit of ef-
ficiency that additional efforts are not required for
decoding as new knowledge comes, since all knowl-
edge sources are finally encoded into a single WFST.
826
Acknowledgments
The work was supported in part by the National
Natural Science Foundation of China (60435010;
60535030; 60605016), the National High Tech-
nology Research and Development Program of
China (2006AA01Z196; 2006AA010103), the Na-
tional Key Basic Research Program of China
(2004CB318005), and the New-Century Training
Program Foundation for the Talents by the Ministry
of Education of China.
References
Steven Abney. 1996. Partial parsing via finite-state cas-
cades. Natural Language Engineering, 2(4):337?344.
Issam Bazzi and James R. Glass. 2000a. Modeling out-
of-vocabulary words for robust speech recognition. In
Proc. of 6th International Conference on Spoken Lan-
guage Processing, pages 401?404, Beijing, China, Oc-
tober.
Issam Bazzi and James Glass. 2000b. Heterogeneous
lexical units for automatic speech recognition: prelim-
inary investigations. In Proc. of ICASSP, pages 1257?
1260, Istanbul, Turkey, June.
Issam Bazzi and James Glass. 2001. Learning units
for domain-independent out-of-vocabulary word mod-
elling. In Proc. of EUROSPEECH, pages 61?64, Aal-
borg, Denmark, September.
Eugene Charniak. 2001. Immediate-head parsing for
language models. In Proc. of ACL, pages 116?123,
Toulouse, France, July.
Ciprian Chelba, David Engle, Frederick Jelinek, Vic-
tor Jimenez, Sanjeev Khudanpur, Lidia Mangu, Harry
Printz, Eric Ristad, Ronald Rosenfeld, Andreas Stol-
cke, and Dekai Wu. 1997. Structure and performance
of a dependency language model. In Proc. of EU-
ROSPEECH, pages 2775?2778, Rhodes, Greece.
Ciprian Chelba. 2000. Exploiting Syntactic Structure for
Natural Language Modeling. Ph.D. thesis, Johns Hop-
kins University.
Isabel Trancoso Diamantino Caseiro. 2002. Using dy-
namic WFST composition for recognizing broadcast
news. In Proc. of ICSLP, pages 1301?1304, Denver,
Colorado, USA, September.
George Doddington. 1996. The 1996 hub-
4 annotation specification for evaluation of
speech recognition on broadcast news. In
ftp://jaguar.ncsl.nist.gov/csr96/h4/h4annot.ps.
N. Friburger and D. Maurel. 2004. Finite-state trans-
ducer cascades to extract named entities in texts. The-
oretical Computer Science, 313(1):93?104.
Lucian Galescu. 2003. Recognition of out-of-vocabulary
words with sub-lexical language models. In Proc.
of EUROSPEECH, pages 249?252, Geneva, Switzer-
land, September.
Thomas Hain, Lukas Burget, John Dines, Giulia Garau,
Martin Karafiat, Mike Lincoln, Jithendra Vepa, and
Vincent Wan. 2006. The AMI meeting transcription
system: Progress and performance. In Proc. of Rich
Transcription 2006 Spring Meeting Recognition Eval-
uation.
Peter A. Heeman. 1998. Pos tagging versus classes in
language modeling. In Proc. of the 6th Workshop on
very large corpora, pages 179?187, Montreal, Canada.
Takaaki Hori, Chiori Hori, Yasuhiro Minami, and At-
sushi Nakamura. 2007. Efficient WFST-based one-
pass decoding with on-the-fly hypothesis rescoring in
extremely large vocabulary continuous speech recog-
nition. IEEE Transactions on audio, speech, and lan-
guage processing, 15(4):1352?1365.
Xinhui Hu, Hirofumi Yamamoto, Genichiro Kikui, and
Yoshinori Sagisaka. 2006. Language modeling of
chinese personal names based on character units for
continuous chinese speech recognition. In Proc. of
INTERSPEECH, pages 249?252, Pittsburgh, USA,
September.
Mark Johnson. 2001. Joint and conditional estimation of
tagging and parsing models. In Proc. of ACL, pages
322 ? 329, Toulouse, France.
G. Maltese, P. Bravetti, H. Cr?py, B. J. Grainger, M. Her-
zog, and F. Palou. 2001. Combining word- and
class-based language models: A comparative study in
several languages using automatic and manual word-
clustering techniques. In Proc. of EUROSPEECH,
pages 21?24, Aalborg, Denmark, September.
Ciro Martins, Antonio Texeira, and Joao Neto. 2006.
Dynamic vocabulary adaptation for a daily and real-
time broadcast news transcription system. In Proc. of
Spoken Language Technology Workshop, pages 146?
149, December.
Mehryar Mohri, Fernando Pereira, and Michael Riley.
1996. Weighted automata in text and speech process-
ing. In ECAI-96 Workshop.
Mehryar Mohri, Fernando Pereira, and Michael Riley.
2000. The design principles of a weighted finite-
state transducer library. Theoretical Computer Sci-
ence, 231(1):17?32.
Mehryar Mohri, Fernando Pereira, and Michael Ri-
ley. 2002. Weighted finite-state transducers in
speech recognition. Computer Speech and Language,
16(1):69?88.
Mehrya Mohri. 1997. Finite-state transducers in lan-
guage and speech processing. Computational Linguis-
tics, 23(2):269?311.
827
Christan Raymond, Fre de ric Be chet, Renato D. Mori,
and Ge raldine Damnati. 2006. On the use of finite
state transducers for semantic interpretation. Speech
Communication, 48(3-4):288?304.
Brian Roark. 2001. Probabilistic top-down parsing
and language modeling. Computational Linguistics,
27(2):249?276.
Christer Samuelsson and Wolfgang Reichl. 1999. A
class-based language model for large-vocabulary
speechrecognition extracted from part-of-speech
statistics. In Proc. of ICASSP, pages 537?540,
Phoenix, Arizona, USA, March.
George Saon, Geoffrey Zweig, Brain KingsBury, Lidia
Mangu, and Upendra Canudhari. 2003. An architec-
ture for rapid decoding of large vocabulary conversa-
tional speech. In Proc. of Eurospeech, pages 1977?
1980, Geneva, Switzerland, September.
Matthew A. Siegler, Uday Jain, Bhiksha Raj, and
Richard M. Stern. 1997. Automatic segmentation,
classification and clustering of broadcast news audio.
In Proc. of DARPA Speech Recognition Workshop,
pages 97?99, Chantilly, Virginia, February.
Daniel Willett Takaaki Hori and Yasuhiro Minami.
2003. Language model adaptation using WFST-based
speaking-style translation. In Proc. of ICASSP, pages
I.228?I.231, Hong Kong, April.
Koichi Tanigaki, Hirofumi Yamamoto, and Yoshinori
Sagisaka. 2000. A hierarchical language model incor-
porating class-dependent word models for oov words
recognition. In Proc. of 6th International Conference
on Spoken Language Processing, pages 123?126, Bei-
jing, China, October.
Hajime Tsukada and Masaaki Nagata. 2004. Efficient
decoding for statistical machine translation with a fully
expanded WFST model. In Proc. of EMNLP, pages
427?433, Barcelona, Spain, July.
Wen Wang and Mary P. Harper. 2002. The superarv lan-
guage model: investigating the effectiveness of tightly
integrating multiple knowledge sources. In Proc. of
EMNLP, pages 238?247, Philadelphia, USA, July.
Wen Wang and Dimitra Vergyri. 2006. The use of word
n-grams and parts of speech for hierarchical cluster
language modeling. In Proc. of ICASSP, pages 1057?
1060, Toulouse, France, May.
Wen Wang, Andreas Stolcke, and Mary P. Harper. 2004.
The use of a linguistically motivated language model
in conversational speech recognition. In Proc. of
ICASSP, pages 261?264, Montreal, Canada, May.
Alexander Yeh. 2000. More accurate tests for the sta-
tistical significance of result differences. In Proc. of
COLING, pages 947?953, Saarbr?cken, August.
828
Coling 2010: Poster Volume, pages 692?700,
Beijing, August 2010
Contextual Recommendation based on Text Mining
Yize Li, Jiazhong Nie, Yi Zhang
School of Engineering
University of California Santa Cruz
{yize,niejiazhong,yiz}@soe.ucsc.edu
Bingqing Wang
School of Computer Science Technology
Fudan University
wbq@fudan.edu.cn
Baoshi Yan, Fuliang Weng
Research and Technology Center
Robert Bosch LLC
Baoshi.Yan@us.bosch.com
Fuliang.Weng@us.bosch.com
Abstract
The potential benefit of integrating con-
textual information for recommendation
has received much research attention re-
cently, especially with the ever-increasing
interest in mobile-based recommendation
services. However, context based recom-
mendation research is limited due to the
lack of standard evaluation data with con-
textual information and reliable technol-
ogy for extracting such information. As
a result, there are no widely accepted con-
clusions on how, when and whether con-
text helps. Additionally, a system of-
ten suffers from the so called cold start
problem due to the lack of data for train-
ing the initial context based recommenda-
tion model. This paper proposes a novel
solution to address these problems with
automated information extraction tech-
niques. We also compare several ap-
proaches for utilizing context based on
a new data set collected using the pro-
posed solution. The experimental results
demonstrate that 1) IE-based techniques
can help create a large scale context data
with decent quality from online reviews,
at least for restaurant recommendations;
2) context helps recommender systems
rank items, however, does not help pre-
dict user ratings; 3) simply using context
to filter items hurts recommendation per-
formance, while a new probabilistic latent
relational model we proposed helps.
1 Introduction
In the information retrieval community, one ma-
jor research focus is developing proactive re-
trieval agent that acts in anticipation of informa-
tion needs of a user and recommends information
to the user without requiring him/her to issue an
explicit query. The most popular examples of such
kind of proactive retrieval agent are recommender
systems. Over the last several years, research
in standard recommender systems has been im-
proved significantly, largely due to the availability
of large scale evaluation data sets such as Netflix.
The current research focus goes beyond the stan-
dard user-item rating matrix. As researchers start
to realize that the quality of recommendations de-
pends on time, place and a range of other rele-
vant users? context, how to integrate contextual
information for recommendation is becoming an
ever increasingly important topic in the research
agenda (Adomavicius and Ricci, 2009).
One major challenge in context-aware recom-
mendation research is the lack of large scale an-
notated data set. Ideally, a good research data
set should contain contextual information besides
users? explicit ratings on items. However, such
kinds of data sets are not readily available for
researchers. Previous research work in context
based recommendation usually experiments on a
small data set collected through user studies. Al-
though undoubtedly useful, this approach is lim-
ited because 1) user studies are usually very ex-
pensive and their scales are small; 2) it is very hard
for the research community to repeat such study;
and 3) a personalized contextual system may not
692
1 I was very excited to try this place and my wife took me here on my birthday. . .
We ordered a side of the brussell sprouts and they were the highlight of the night.
2 A friend of mine suggested we meet up here for a night of drinks. . . This actually
a restaurant with a bar in it, but when we went it was 10pm and . . .
Table 1: Examples of the restaurant reviews
succeed until a user has interacted with it for a
long period of time to enable context based rec-
ommendation models well trained.
On the other hand, a large amount of re-
view documents from web sites such as tri-
padvisor.com, yelp.com, cnet.com, amazon.com,
are available with certain contextual information,
such as time and companion, implicitly in the re-
views (see Table 1 for examples). This offers us an
opportunity to apply information extraction tech-
niques for obtaining contextual information from
the review texts. Together with users? explicit rat-
ings on items, this might lead to a large research
data set for context based recommendation and
consequently address the cold start issue in the
recommender systems. This paper describes the
methods that extract the contextual information
from online reviews and their impact on the rec-
ommendation quality at different accuracy levels
of the extraction methods.
Another challenge is how to integrate contex-
tual information into existing recommendation al-
gorithms. Existing approaches can be classified
into three major categories: pre-filtering, post-
filtering and the modeling based approaches (Oku
et al, 2007; Adomavicius and Tuzhilin, 2008).
Pre-filtering approaches utilize contextual infor-
mation to select data for that context, and then pre-
dict ratings using a traditional recommendation
method on the selected data (Adomavicius et al,
2005). Post-filtering approaches first predict rat-
ings on the whole data using traditional methods,
then use the contextual information to adjust re-
sults. Both methods separate contextual informa-
tion from the rating estimation process and leads
to unsatisfying findings. For example, Adomavi-
cious et al (2005) found neither standard col-
laborative filtering nor contextual reduction-based
methods dominate each other in all the cases. In
the modeling based approaches, contextual infor-
mation is used directly in the rating prediction
process. For example, Oku et al (2007) propose
a context-aware SVM-based predictive model to
classify restaurants into ?positive? and ?negative?
classes, and contextual information is included as
additional input features for the SVM classifier.
However, treating recommendation as classifica-
tion is not a common approach, and does not take
advantage of the state of art collaborative filtering
techniques. In this paper, we propose a new prob-
abilistic model to integrate contextual information
into the state of art factorization based collabora-
tive filtering approach, and compare it with sev-
eral baselines.
2 Mining Contextual Information from
Textual Opinions
The context includes any information that can be
used to characterize the situation of entities. Ex-
amples of context are: location, identity and state
of people, companions, time, activities of the cur-
rent user, the devices being used etc. (Lee et
al., 2005). Without loss of generality, we looked
into widely available restaurant review data. More
specifically, we investigated four types of contex-
tual information for a dining event, as they might
affect users? dining decisions, and they have not
been studied carefully before. The four types of
contextual information are: Companion (whether
a dining event involves multiple people), Occa-
sion (for what occasions the event is), Time (what
time during the day) and Location (in which city
the event happens).
2.1 Text Mining Approaches
We developed a set of algorithms along with exist-
ing NLP tools (GATE (Cunningham et al, 2002)
etc.) for this task. More detailed description of
these algorithms is given below.
Time: we classified the meal time into the
following types: ?breakfast?, ?lunch?, ?dinner?,
?brunch?, ?morning tea?, ?afternoon tea?. We
693
compiled a list of lexicons for these different types
of meal times, and used a string matching method
to find the explicit meal times from reviews. Here,
the meal time with an expression, such as ?6pm?,
was extracted using ANNIE?s time named entity
recognition module from the GATE toolkit. For
example, if a user says, ?When we went there, it
was 10pm?, we infer that it was for dinner.
Occasion: The ANNIE?s time named en-
tity recognition module recognizes certain special
days from text. We augmented ANNIE?s lookup
function with a list of holidays in the United States
from Wikipedia1 as well as some other occasions,
such as birthdays and anniversaries.
Location: Ideally, a location context would be
a user?s departure location to the selected restau-
rant. However, such information rarely exists in
the review texts. Therefore, we used the location
information from a user?s profile to approximate.
Companion: Extracting a companion?s infor-
mation accurately from review data is more diffi-
cult. We utilized two methods to address the chal-
lenge:
Companion-Baseline: This is a string match-
ing based approach. First, we automatically gen-
erated a lexicon of different kinds of compan-
ion words/phrases by using prepositional patterns,
such as ?with my (our) NN (NNS)?. We extracted
the noun or noun phrases from the prepositional
phrases as the companion terms, which were then
sorted by frequency of occurrence and manually
verified. This led to a lexicon of 167 entries.
Next, we grouped these entries into 6 main cate-
gories of companions: ?family?, ?friend?, ?cou-
ple?, ?colleague?, ?food-buddy? and ?pet?. Fi-
nally, the review is tagged as one or more of the
companion categories if it contains a correspond-
ing word/phrase in that lexicon.
Companion-Classifier: In order to achieve bet-
ter precision, we sampled and annotated 1000
sentences with companion terms from the corpus
and built three classifiers: 1) a MaxEnt classi-
fier with bag-of-words features, 2) a rule-based
classifier, 3) a hybrid classifier. For the rule-
based classifier, we looked into the structural as-
pects of the window where companion terms oc-
1http://en.wikipedia.org/wiki/List of holidays by
country#United States of America
curred, specifically, the adjacent verbs and prepo-
sitions associated with those terms. We collected
high frequency structures including verbs, verb-
proposition combinations, and verb-genitive com-
binations from the whole corpus, and then con-
structed a list of rules to decide whether a compan-
ion context exists based on these structures. For
the hybrid classifier, we used the patterns identi-
fied by the rule-based classifier as features for the
MaxEnt model (Ratnaparkhi, 1998). To train the
classifier, we also included features such as POS
tags of the verb and of the candidate companion
term, the occurrence of a meal term (e.g. ?lunch?,
?dinner?), the occurrence of pronouns (e.g. ?we?
or ?us?) and the genitive of the companion term.
Based on the evaluation results (using 5-fold cross
validation) shown in Table 2, the hybrid classifier
is the best performing classifier and it is used for
the subsequent experiments in the paper.
Words Rule Hybrid
Precision 0.7181 0.7238 0.7379
Recall 0.8962 0.8947 0.9143
F-Score 0.7973 0.8003 0.8167
Table 2: Evaluation results for the bag-of-words-
based classifier (Words), the rule-based classifier
(Rule) and the hybrid classifier (Hybrid)
3 Recommendation based on Contextual
Information
Next we consider how to integrate various con-
textual information into recommender systems.
Assume there are N items and M users. Each
user reviews a set of items in the system. The
data set can be represented as a set of quadruplet
D = (y, i, j, c), where i is the index of user, j is
the index of item, c is a vector describing the con-
text of this rating data, and y is the rating value.
Let c = (c1, ..., ck), where each component ck
represents a type of context, such as ?dinner time?
or ?location=San Jose?. The observed features
(meta data) of user i and item j are represented
as vectors fi and fj respectively, where each com-
ponent in the vector represents a type of feature,
such as ?gender of the user? or ?price range of
the restaurant?. In the rest of this paper, we in-
694
tegrate context c into the user?s observed features
fi. This makes fi a dynamic feature vector, which
will change with different context. The goal is
to predict ratings for candidate items given user i
and context c, and recommend the top items. We
present two recommendation models for integrat-
ing contextual information in this section.
3.1 Boolean Model
The Boolean Model filters out items that do not
match the context. The Boolean model itself re-
turns an item set instead of a ranked list. We fur-
ther rank the items by predicted rating values. We
score items by the Boolean model as follows:
s(j) =
{
sm(j) if item j matches the context
?? otherwise
(1)
where sm(j) is the predicted rating computed us-
ing a rating prediction method m, such as a Col-
laborative Filtering model without using context.
3.2 Probabilistic Latent Relational Model
We propose a novel Probabilistic Latent Rela-
tional Model (PLRM) for integrating contextual
information. In a context-aware recommender
system, a user?s interest for item is influenced by
two factors: (1) the user?s long-term preference,
which can be learned from users? rating history;
(2) the current context (how the item matches the
current context). To capture the two factors si-
multaneously, we introduce a new probabilistic
model by assuming the rating value yi,j,c follows
a Gaussian distribution with mean ui,j,c and vari-
ance 1/?(y):
yi,j,c ? N (ui,j,c, 1/?(y)) (2)
ui,j,c = uTi Avj + (Wufi)T (Wvfj) (3)
where ui and vj are the hidden representations of
user i and item j to be learned from rating data,
and Wu and Wv are feature transformation matri-
ces for users and items respectively. In Equation
(3), the first term uTi Avj is the estimation based
on user? long term preferences, where A = {a} is
a matrix modeling the interaction between ui and
vj .2 The second term (Wufi)T (Wvfj) is the esti-
2We introduce A matrix so that the model can also
be used to model multiple different types of relation-
mation based on current context and the observed
features of users and items, since the context c is
integrated into user?s observed features fi.
{U, V,A,W} are the parameters of the model
to be estimated from the training data set D,
where W = {Wu,Wv} = {w} , U =
{u1,u2, ...uN} and V = {v1,v2, ...vM}. We as-
sume the prior distribution of the parameters fol-
low the Gaussian distributions centered on 0. We
use 1/?(u),1/?(v), 1/?(w) and 1/?(a) to represent
the variance of the corresponding Gaussian distri-
butions. The effect of the prior distribution is sim-
ilar to the ridge regression (norm-2 regularizer)
commonly used in machine learning algorithms to
control model complexity and avoid overfitting.
The proposed model is motivated by well per-
forming recommendation models in the literature.
It generalizes several existing models. If we set A
to the identity matrix and Wu,Wv to zero matri-
ces, the model presented in Equation (3) is equiv-
alent to the well known norm-2 regularized singu-
lar value decomposition, which performs well on
the Netflix competition(Salakhutdinov and Mnih,
2007). If we set A to zero matrix and Wu to iden-
tity matrix, the Model (3) becomes the bilinear
model that works well on Yahoo news recommen-
dation task (Chu and Park, 2009).
Based on the above model assumption, the joint
likelihood of all random variables (U , V , A, W
and D) in the system is:
P (U, V,A,W,D) =?
(i,j,c,y)?D
P (yi,j,c|ui,vj , fi, fj , A,Wu,Wv)
?
i
P (ui)
?
j
P (vj)P (A)P (Wu)P (Wv)(4)
3.3 Parameter Estimation
We use a modified EM algorithm for parame-
ter estimation to find the posterior distribution of
(U, V ) and max a posterior (MAP) of (A,W ).
The estimation can be used to make the final pre-
ships/interactions jointly, where each type of relationship
corresponds to a different A matrix. For the task in this pa-
per, A is not required and can be set to the identity matrix
for simplicity. However, we leave A as parameters to be es-
timated in the rest of this paper for generality.
695
dictions as follows:
y?i,j,c =
?
ui,vj
P (ui)P (vj)(uTi Avj
+(Wufi)TWvfj)duidvj
E Step: the Variational Bayesian approach is used
to estimate the posterior distributions of U and V .
Assuming (A,W ) are known, based on Equation
4, we have
P (U, V |A,W,D) ?
?
(y,i,j,c)?D
N (uTi Avj + (Wufi)TWvfj , 1/?(y))
?
M?
i=1
N (ui|0, 1/?(u)I)
N?
j=1
N (vj |0, 1/?(v)I)
Deriving the exact distribution and use it to predict
y will result in intractable integrals. Thus we ap-
proximate the posterior with a variational distribu-
tion Q(U, V ) = ?Mi=1Q(ui)
?N
j=1Q(vj). Q(ui)
and Q(vj) are restricted to Gaussian distributions
so that predicting y using Bayesian inference with
Q(U, V ) will be straightforward. Q(U, V ) can be
estimated by minimizing the KL-divergence be-
tween it and P (U, V |A,W,D). Since Q(U, V ) is
factorized into individual Q(ui) and Q(vj), we
can first focus on one Q(ui) (or Q(vj)) at a time
by fixing/ignoring other factors. For space consid-
erations, we omit the derivation in this paper. The
optimal Q(ui) is N (u?i,?i), where u?i = ?idi,
??1i =
?
(y,i,j,c)?D
?(y)A(v?jv?Tj + ?j)AT
+ ?(u)I
di =
?
(y,i,j,c)?D
?(y)y?Av?j
Similarly, the optimal Q(vj) isN (v?j,?j), where
v?j = ?jej ,
??1j =
?
(y,i,j,c)?D
?(y)AT (u?iu?Ti + ?i)A
+ ?(v)I
ej =
?
(y,i,j,c)?D
?(y)y?AT v?j
M Step: Based on the approximate pos-
terior estimation Q(U, V ) derived in the E
step, the maximum a posteriori estimation
of {A,W} can be found by maximizing
the expected posterior likelihood {A?, W?} =
argmaxA,W EQ(U,V )(logP (A,W,U, V |D)).
This can be done using the conjugate gradient
descent method, and the gradient of A,Wu,Wv
can be calculated as follows:
??
?A =
?
(y,i,j,c)?D
?(y)((y? ? y)u?iv?Tj
+ u?iu?Ti A?j + ?iAv?jv?Tj + ?iA?j)
+ ?(a)A
??
?Wu
=
?
(y,i,j,c)?D
?(y)(y? ? y)WvfjfTi
+ ?(w)Wu
??
?Wv
=
?
(y,i,j,c)?D
?(y)(y? ? y)WufifTj
+ ?(w)Wv
where ? = EQ(U,V )(logP (A,W,U, V |D)) and
y? = u?Ti Av?j + (Wufi)TWvfj .
4 Experimental Methodology
4.1 Data Collection
We collected an evaluation data set from a pop-
ular review web site where users review ser-
vices/products and provide integer ratings from 1
to 5. The user profile and the description of items,
such as user gender and the category of restau-
rants are also collected. The data set used in this
paper includes the restaurants in Silicon Valley
(Bay area) and the users who ever reviewed these
restaurants. We extract context from the review
texts. The four kinds of context considered in our
paper are described in Section 2.1. For each type
of context, we create a subset, in which all reviews
contain the corresponding contextual information.
Finally we construct four sub data sets and each
data set is described by the corresponding con-
text type: Time, Location, Occasion and Compan-
ion. We use ?All? to represent the whole data set.
Statistics about each data set are described in Ta-
ble 3.
696
(a) Time (b) Location (c) Occasion
(d) Companion (e) All
Figure 1: Performance on the top-K recommendation task. The plots focus on the top 20% ranking
region.
Dataset #Ratings #Users #Items
All 756,031 82,892 12,533
Location 583,051 56,026 12,155
Time 229,321 49,748 10,561
Occasion 22,732 12,689 4,135
Companion 196,000 47,545 10,246
Table 3: Statistics of data
4.2 Experimental Setup
We design the experiments to answer the follow-
ing questions: 1) Does including contextual in-
formation improve the recommendation perfor-
mance? 2) How does the probabilistic latent re-
lational modeling approach compare with pre-
filtering or post-filtering approaches? 3) How
does the extraction quality of the contextual infor-
mation affect the recommendation performance?
To answer the first question, we compare the
performance of the Probabilistic Latent Relational
Model on a standard collaborative filtering setting
where only rating information is considered, in-
dicated by Nocontext. We also evaluate the per-
formance of the Probabilistic Latent Relational
Model when integrating contextual information,
indicated by Context-X, where X represents the
type of contextual information considered. To
answer the second question, we compare the
performance of Context-X with the pre-filtering
Boolean Model, which first uses the context to se-
lect items and then ranks them using scores com-
puted by Nocontext. To answer the third question,
we compare the recommendation performance for
different extraction precision. The performance
on the following two recommendation tasks are
reported in this paper:
Top-K Recommendation: We rank the items
by the predicted rating values and retrieve the top
K items. This task simulates the scenario where
a real recommender system usually suggests a list
of ranked K items to a user. To simulate the sce-
nario that we only want to recommend the 5-star
items to users, we treat 5-star rating data in testing
data as relevant. Ideally, classic IR measures such
as Precision and Recall are used to evaluate the
recommendation algorithms. However, without
complete relevance judgements, standard IR eval-
uation is almost infeasible. Thus we use a varia-
tion of the evaluation method proposed by Koren
(Koren, 2008).
Rating Prediction: Given an active user i and a
target item j, the system predicts the rating of user
697
Training on Sub Data set Training on the Whole Data set
Testing Data ItemAvg Nocontext Context ItemAvg Nocontext Context
Time 1.1517 1.0067 1.0067 1.1052 0.9829 0.9822
Companion 1.2657 1.0891 1.0888 1.2012 1.0693 1.0695
Occasion 1.2803 1.1381 1.1355 1.2121 1.0586 1.0583
Location 1.1597 1.0209 1.0206 1.1597 1.0183 1.0183
All context - - - 1.1640 1.0222 1.0219
Table 4: RMSE on the rating prediction task
Time CompanionBaseline CompanionClassifier Occasion
#Reviews 300 300 300 200
#Contexts 115 148 114 207
Precision 84.4% 62.2% 77.1% -
Recall 80.2% 95.8% 91.7% -
F-Score 82.2% 75.4% 83.8% Accuracy 78.3%
Table 5: Performance of the context extraction module
i on item j. The prediction accuracy is measured
by Root Mean Square Error (RMSE), which is
commonly used in collaborative filtering research.
This task simulates the scenario that we need to
guess a user?s rating about an item, given that the
user has already purchased/selected the item.
For each data set (Time, Companion, Location,
Occasion and All), we randomly sample 10% for
testing, 80% for training and 10% for validation.
5 Experimental Results
5.1 Performance on Top-K Recommendation
Figure 1(a)-(e) shows the ranking performance on
each data set. The x-axis is the rank and the y-axis
is the portion of relevant products covered by this
level of rank. The results across all data sets are
consistent. With contextual information, PLRM
Context-X outperforms Nocontext, whereas using
context to pre-filter items (Boolean) does not help.
It means that contextual information can help if
used appropriately, however improperly utilizing
context, such as simply using it as a boolean filter,
may hurt the recommendation performance. Our
proposed PLRM is an effective way to integrate
contextual information.
5.2 Performance on Rating Prediction Task
Table 4 summaries the RMSE results of differ-
ent approaches on the rating prediction task. The
RMSE of simply using item?s average rating value
as the prediction is also reported as a reference
since it is a commonly used approach by non per-
sonalized recommender systems. For each con-
text, we can either train the model only on the sub-
set that consists of rating data with related context,
or train on a bigger data set by adding the rating
data without related context. The results on both
settings are reported here. Table 4 shows that uti-
lizing context does not affect the prediction accu-
racy. We may wonder why the effects of adding
context is so different on the rating task compared
with the ranking task. One possible explanation
is that the selection process of a user is influenced
by context, while how the user rates an item after
selecting it is less relevant to context. For exam-
ple, when a user wants to have a breakfast, he may
prefer a cafeteria rather than a formal restaurant.
However, how the user rates this cafeteria is more
based on user?s experiences in the cafeteria, such
as quality of services, food, price, environment,
etc.
5.3 How does Text Mining Accuracy Affect
Recommendation
To evaluate the extraction performance on ?Com-
panion?, ?Time? and ?Occasion?, we randomly
sample some reviews and evaluate the perfor-
698
mance on the samples3. The results are shown in
Table 5. Compared with other contexts, the ex-
traction of companion context is more challenging
and the string matching baseline algorithm pro-
duces significantly inferior results. However, by
using a MaxEnt classifier with features selection,
we can boost the precision of the companion con-
text extraction to a level comparable to other con-
texts.
To further investigate the relationship between
the quality of the extracted context and the perfor-
mance of the recommender system, we compare
the recommendation performance of Companion-
Baseline and Companion-Classifier in Figure
1(d). It shows that improving the quality of the
extraction task leads to a significant improvement
on the recommender systems? top-K ranking task.
6 Conclusions
Reviews widely available online contain a large
amount of contextual information. This paper
proposes to leverage information extraction tech-
niques to help recommender systems to train
better context-aware recommendation models by
mining reviews. We also introduce a probabilis-
tic latent relation model for integrating the cur-
rent context and the user?s long term preferences.
This model takes the advantages of traditional col-
laborative filtering approaches (CF). It also cap-
tures the interaction between contextual informa-
tion and item characteristics. The experimental
results demonstrate that context is an important
factor that affects user choices. If properly used,
contextual information helps ranking based rec-
ommendation systems, probably because context
influences users? purchasing decisions. Besides,
more accurate contextual information leads to bet-
ter recommendation models. However, contextual
information does not help the user rating predic-
tion task significantly, probably because context
doesn?t matter much given the user has already
chosen a restaurant.
As the first step towards using the information
3We sample 300 reviews for ?Time? and ?Companion?
evaluation. Due to the extremely low probability of occur-
rence of Occasion context, we futher sample 200 reviews
containing Occasion-related expressions and only evaluate
extraction accuracy on these samples
extraction techniques to help contextual recom-
mendation, the techniques used in this paper are
far from optimal. In the future, we will research
more effective text mining techniques for contex-
tual extraction(Mazur and Dale, 2008; McCallum
et al, 2000; Lafferty et al, 2001) at the same time
increasing the amount of annotated review data
for better classifier performance through actively
learning (Laws and Schu?tze, 2008). We also plan
to work towards a better understanding of con-
textual information in recommender systems, and
explore other types of contextual information in
different types of recommendation tasks besides
restaurant recommendations.
7 Acknowledgements
Part of this research is funded by National Sci-
ence Foundation IIS-0713111 and the Institute of
Education Science. Any opinions, findings, con-
clusions or recommendations expressed in this pa-
per are the authors?, and do not necessarily reflect
those of the sponsors. Bingqing Wang?s work is
done during his stay in the Research and Technol-
ogy Center, Robert Bosch LLC.
References
Adomavicius, Gediminas and Francesco Ricci. 2009.
Recsys?09 workshop 3: workshop on context-aware
recommender systems, cars-2009. In Proceedings
of the 3rd ACM Conference on Recommender Sys-
tems, RecSys 2009, pages 423?424.
Adomavicius, Gediminas and Alexander Tuzhilin.
2008. Context-aware recommender systems. In
Proceedings of the 2nd ACM Conference on Rec-
ommender Systems, RecSys 2008, pages 335?336.
Adomavicius, Gediminas, Ramesh Sankaranarayanan,
Shahana Sen, and Alexander Tuzhilin. 2005.
Incorporating contextual information in recom-
mender systems using a multidimensional approach.
ACM Transactions on Information Systems (TOIS),
23(1):103?145.
Chu, Wei and Seung-Taek Park. 2009. Personalized
recommendation on dynamic content using predic-
tive bilinear models. In Proceedings of the 18th In-
ternational Conference on World Wide Web, WWW
2009, pages 691?700.
Cunningham, Hamish, Diana Maynard, Kalina
Bontcheva, and Valentin Tablan. 2002. A frame-
work and graphical development environment for
699
robust nlp tools and applications. In Proceedings of
the 40th Anniversary Meeting of the Association for
Computational Linguistics, ACL 2002, pages 168?
175.
Koren, Yehuda. 2008. Factorization meets the
neighborhood: a multifaceted collaborative filtering
model. In Proceedings of the 14th ACM SIGKDD
International Conference on Knowledge Discovery
and Data Mining, SIGKDD 2008, pages 426?434.
Lafferty, John D., Andrew McCallum, and Fernando
C. N. Pereira. 2001. Conditional random fields:
Probabilistic models for segmenting and labeling
sequence data. In Proceedings of the 18th Inter-
national Conference on Machine Learning, ICML
2001, pages 282?289.
Laws, Florian and Hinrich Schu?tze. 2008. Stopping
criteria for active learning of named entity recogni-
tion. In Proceedings of the 22nd International Con-
ference on Computational Linguistics, Coling 2008,
pages 465?472, August.
Lee, Hong Joo, Joon Yeon Choi, and Sung Joo Park.
2005. Context-aware recommendations on the mo-
bile web. In On the Move to Meaningful Internet
Systems 2005: OTM 2005 Workshops, pages 142?
151.
Mazur, Pawel and Robert Dale. 2008. What?s the
date? high accuracy interpretation of weekday
names. In Proceedings of the 22nd International
Conference on Computational Linguistics, Coling
2008, pages 553?560.
McCallum, Andrew, Dayne Freitag, and Fernando
C. N. Pereira. 2000. Maximum entropy markov
models for information extraction and segmenta-
tion. In Proceedings of the 17th International Con-
ference on Machine Learning, ICML 2000, pages
591?598.
Oku, Kenta, Shinsuke Nakajima, Jun Miyazaki, and
Shunsuke Uemura. 2007. Investigation for design-
ing of context-aware recommendation system using
svm. In Proceedings of the International MultiCon-
ference of Engineers and Computer Scientists 2007,
IMECS 2007, pages 970?975.
Ratnaparkhi, A. 1998. MAXIMUM ENTROPY MOD-
ELS FOR NATURAL LANGUAGE AMBIGUITY
RESOLUTION. Ph.D. thesis, University of Penn-
sylvania.
Salakhutdinov, Ruslan and Andriy Mnih. 2007. Prob-
abilistic matrix factorization. In Advances in Neural
Information Processing Systems 20, Proceedings of
the 21st Annual Conference on Neural Information
Processing Systems, NIPS 2007, pages 1257?1264.
700
